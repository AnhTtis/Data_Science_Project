\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2021}
\usepackage{times}
\usepackage{latexsym}
\renewcommand{\UrlFont}{\ttfamily\small}

\usepackage{microtype}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\usepackage[normalem]{ulem}
\newcommand{\rep}[2]{{\textcolor{green!50!black}{\sout{#1}}}{\textcolor{blue!50!black}{#2}}}
% \newcommand{\rep}[2]{#2}
\newcommand{\del}[1]{\rep{#1}{}}
\newcommand{\ins}[1]{\rep{}{#1}}

\usepackage{multirow}
\usepackage{graphicx}

\newcommand{\mps}[1]{\textcolor{blue}{\textsf{MPS: #1}}}
\newcommand{\vg}[1]{\textcolor{green}{\textsf{VG: #1}}}




\title{Predicting When a Conversation Derails}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\}

\date{}

\begin{document}
\maketitle
% \rxi{}
\mps{hyphens: see my advice pages}


\begin{abstract}
Evaluating the quality of an ongoing conversation among online users as it develops could provide valuable real-time insights to the interlocutors as well as to moderators. 
Existing approaches for conversation evaluation provide a binary prediction of whether a conversation will derail in the end.
These approaches do not make fine-grained predictions and fail to incorporate conversation structural information. 
In contrast, we propose to measure the quality of a conversion based on the distance between the current utterance and the utterance where the conversation derails. 
This metric provides richer information regarding conversation development than a binary measure. 

We propose a new hierarchical transformer-based framework that encodes token-level and utterance-level information to capture fine-grained contextual information.  \mps{Insert a sentence or two about the approach} 
We evaluate our framework on two canonical conversation derailment datasets and achieve \vg{do not use such words because its hard to define competitive}competitive\mps{comparable?} F1 score on the prediction of derailment on short conversations and better \vg{better than whom?} accuracy on long conversations. In addition, \mps{Insert a sentence about the results? Is it the standard error of when a conversation ends? -- can't be because the other approaches are binary. Is it the binary prediction accuracy as in other approaches?} 
Our framework could be adapted to other conversation evaluation tasks, such as predicting the trajectory of a conversation.
\end{abstract}


\begin{figure}[t]
    \centering
    \includegraphics[width=1\columnwidth]{example.png}
    \caption{arc}
    \label{fig:arccc}
\end{figure}

\section{Introduction}
    Online social platforms provide great opportunities for users from different background to communicate and develop constructive conversations, facilitating exchange of ideas and collaboration of work. However, antisocial behaviors such as personal attacks have largely impeded the progress of building healthy and thriving online communities. The wide proliferation of such behaviors is partially due to the obscurity \vg{do you mean anonimity?} of online user identity \vg{have any literature to back up this claim?}, which has placed great obstacles for platform administrator to maintain a clean and civil environment. Recently, progresses from the natural language processing community have offered another direction to mitigate the problem in a computational way. A great amount of work has focused on identifying and classifying various types of antisocial behavior, such as toxicity, hate speech, bullying, misogyny, and general personal attack \vg{must cite papers here}. However, most of the previous research only aims at detecting antisocial behavior when the misconduct has occurred. This post hoc identification posts limits on the possibility and power of platform moderators \vg{seems little vague. be specific in what you say}. \par
    
    
    What most platform moderators do after the detection of antisocial behavior is to remove the toxic content or suspend the user account. However, the damage would have been done to the involving parties who may be discouraged from participating in the future conversations. Another practical problem is that lots of toxic content could be overlooked by the moderator \vg{if there is already enough work for toxic identification, how is this a problem?}. A more beneficial strategy would be to provide an early warning or interfere with the conversation as the conversation is developing. For example, the moderator may advocate for morality or stress the rules of the platform when it \vg{he or she} senses potential derailment of an ongoing conversation, which could stop the personal attack from happening \vg{this line is not clear}. Achieving such strategy requires the model to learn and predict the dynamics of developing conversations, as opposed to the static and post hoc classification of unchanging contents. Forecasting conversation trajectory could lead to multiple potential use cases not limited to personal attacks. For example, the model could predict whether a conversation which persuades people to donate for charity will likely succeed or not, whether a goal-oriented conversation is on the right track towards its goal. \par

    There are a couple of inherent difficulties associated with conversation modelling and forecasting. The first challenge is that there are complex dynamics on both the utterance level and the conversation level. The semantics of each individual utterance is collectively determined by a sequence of words. The semantics of the entire conversation is affected by the interaction between utterances, where latter utterances reply on both the semantics of and structural relation to previous utterances. The dynamics could change abruptly because of the newly emerging utterances. The second challenge is the unknown number of utterances that will occur. The conversation could stop at any time and the personal attack could happen at any moment as the conversation unfolds. An earlier warning is obviously better than a warning that comes up right before the attack but may lead to lower accuracy. When should the model make a prediction and how to tradeoff between time aspect and accuracy? The third challenge arises from the fact that, unlike casual chatty dialogues, online conversations tend to have a much longer text length, which causes a problem for apply modern deep neutral network. Previous work has tried different approaches to resolve these challenges but most of only focus on one aspect at a time. For example, [][][] mostly reply on hand-crafted to model the conversation. [][][] applies the LSTM architecture to capture the dynamics and only consider the first 80 tokens for each utterance.  However, previous work solely replies on textual semantics without considering auxiliary information inherent in conversations such as conversation structure and user identity. \par

    In this work \vg{whatever you are writing is a part of this work :) so remove this phrase}, we propose a hierarchical transformer framework to counter these challenges leveraging \vg{are challeges leveraging models? or your approach leveraging models?} pretrained language model. We design different ways to integrate various source of information and explore how each attribute other than textual content contribute to the modelling of ongoing conversations. Specifically, we propose the multi-task training scheme to leverage the time factor for conversation to derail, a pretraining scheme to utilize conversational structure and an encoding scheme to capture speaker identity. Our approach is not limited to predicting conversational personal attacks, and can be easily adapted to other conversation forecasting tasks. 

\section{Related Work}
\subsection{Antisocial behavior in cyberspace}
A great deal of research has made efforts to define and detect various aspects of antisocial behaviors in online platforms. There are many different forms of antisocial behaviors, such as toxicity, hate speech, trolling, offense, racism. Earlier work primarily relies on hand-craft features, whereas recent work takes advantage of deep neural networks and has made great progress. However, most of the past work only focuses on classifying the type of antisocial behavior retrospectively with a single piece of text without considering the context. XXX proposes a new task to predict whether an ongoing conversation will evolve into a personal attack as it develops. [Toxicity Detection: Does Context Really Matter?] proposes to detect and measure toxicity in context by considering the parent of the comment. Our work is a natural extension of the previous work focusing on exploiting inherent contextual information to make fine-grained predictions of the trajectory of ongoing conversations. 

\subsection{Conversation Modeling}
The research community has paid great attention to dialogue systems and their application in various business scenarios has demonstrated its merit. One such research direction is the classification of dialogue acts, which gives a predefined act type to each utterance. However, this type of classification focuses on utterance level modeling. X proposes a widely adapted architecture for conversation modeling, which applies a hierarchical recurrent neural network for encoding utterance and context respectively. Xxx leverage the same architecture and pretrain the model with over 1 million domain data. Our work explores new ways of modeling conversation data by leveraging pre-trained languages models. Another contribution of our work is that we propose a new pretraining goal to integrate the inherent tree structure of conversations into the model and evaluate its effectiveness. 
\subsection{Domain Adaptive Pretraining}
The natural language processing community has gone through several computing paradigms, the evolvement of which embodies the progression of NLP techniques. Since the advent of the BERT model, the pretraining-then-finetuning paradigm has been widely adopted not only in NLP but also in the deep learning community in general. The adoption of pretrained language models has greatly boosted the performance on almost all NLP tasks. However, in some domain-specific tasks, the paradigm does not work very well due to the lack of annotated data. Therefore, another advanced computing paradigm, pretraining - domain adaptive pretraining – finetuning, has been proposed to leverage the unlabeled domain-specific data. During the domain adaptive pretraining, the training scheme is usually the same as the general pretraining stage, that is, using a masked language model. In our work, we follow the line of thinking but propose to pretrain the model to identify the parent comment each utterance replies to.  


\section{Methodology}
    In this section, we describe our model for evaluating and forecasting conversation development \vg{break the sentence here into 2 sentences} which is capable of integrating multi-source information with respect to the conversation. We experiment with four different settings where additional information is being consolidated during training: (a) a base hierarchical transformer model which encode both the utterance level and conversation level information. (b) on top of the base setting, we leverage the distance from each utterance to the derailment utterance as an auxiliary training objective. The hypothesis is that the distance till derailment can provide fine-grained signal to the model prediction. (c) we propose to utilize the inherent utterance structure, which is the reply-to attribute for each utterance. The whole conversation could be viewed as a tree structure. We set up a pre-training objective to predict the parent of each utterance. (d) speaker identity is usually an important source of information. We propose a new way to encode speaker identity which doesn’t reply on the number of speakers participating the conversation. Figure [] shows an overview of the architecture we proposed. 
    
    \subsection{Problem formulation}
	We now define our problem in a formal way. We represent a conversation as a sequence of utterance. $C = \{u_1, \dots, u_N\}$, $N$ is the total number of turns in the conversation. Each utterance consists of an order of words. $U = \{w_1, \dots, w_M\}$, $M$ is the total number of words. Each conversation comes with a label $1$ or $0$. $1$ means there is a personal attack at utterance $u_N$. $0$ means the entire conversation is civil. It is important to note that all utterances before the derailing utterance are civil. That is, we don't consider what happens after a personal attack.  The prediction is then done in a dynamic way. That is, the model will make a binary prediction $p_1$ for input $u_1$, and make a prediction $p_2$ for input $(u_1, u_2)$. The model will stop whenever a positive prediction $1$ is made, which means the model believes that the conversation is going to derail. For a negative prediction, the model then would have to make $N-1$ negative predictions given $(u_1), (u_1, u_2), \dots, (u1, u2, \dots, u_{N-1})$.
	
    \subsection{Utterance Level Encoder}
    For each individual utterance $u = {w_1, \dots, w_M}$, we leverage pretrained language model to capture rich semantic information. Specifically, we use a transformer-based model with the same configuration as Roberta-base, initialized with the pretrained weights from huggingface. RoBERTa is an optimized variant of the BERT model and improves over BERT by employing dynamic masking and ten times more training data during the unsupervised pretraining. We follow the preprocessing step to tokenize the utterance and append a special token [CLS] at the front and [SEP] at the end. Before feeding the token embedding into the first layer transformer, we also need to add pretrained positional embedding to each token. The maximum input length for RoBERTa is 512 and we cut off extra tokens if the tokenized utterance length exceeds the limit. Finally, we take the embedding of the special token [CLS] from last layer’s output as the utterance representation, which can capture the semantics of the entire utterance.  
    
    \subsection{Conversational Context Encoder}
    The derailment should not be considered as a singular attribute of the utterance as it is the result of an evolving conversation. Therefore, we need to consider the accumulative effect of previous utterances. For each conversation $C = {u_1, \dots, u_N}$, we obtain the utterance embedding U from the first level transformer. We then apply another transformer model on the sequence of utterance embedding to get a contextual representation of the conversation. Similarly, we use the [CLS] embedding from the last layer as a representation of the entire conversation and feed it to the classifier. The classifier is made up of one fully connected linear layer and a binary classification head. The reason we chose a transformer model over an LSTM model is because multi-head attention mechanism has an edge over the traditional LSTM model. However, to reduce computational cost, instead of applying a full transformer model, we only use 4 layers transformer following the setting of previous work ([]). 

\subsection{Multi-task training with distance }
    
    Previous approach on conversational derailment makes the prediction in a dynamic fashion. In inference time, the model is fed with ${(u_1), (u_1, u_2), (u_1, u_2, u_3) \dots}$ one by one and makes a prediction for each sequence. When the model makes a positive prediction, the process is stopped, and the conversation is deemed to derail. In training time, however, the model is only trained with the full sequences up to the derailing utterance. Consider a sample pair ${(0_{11},0_{12},0_{13},0_{14}), (0_{21},0_{22},0_{23},0_{24},1_{25})}$ where $0$ presents civil utterance and $1$ represents personal attack, the pair $\{(0_{11},0_{12},0_{13}), 0\},  \{(0_{21},0_{22},0_{23},0_{24}), 1\}$ is used as a positive and negative pair sample. We observe that the distance from each civil utterance to the derailing utterance could provide additional and richer information for the model to learn. By predicting the distance to derail, another benefit is we expand the training set by a factor of the average conversation length. For the same sample, we can train on $\{(0_{21}), 4\}, \{(0_{21},0_{22}), 3\}, \{(0_{21},0_{22},0_{23}), 2\}$, $\{(0_{21},0_{22},0_{23},0_{24}), 1\}$ for the negative sample. For positive sample, we simply apply the longest length of conversation in the dataset as the target for each utterance. We add another regression head following the fully connected linear layer. Our new loss function becomes $L = \alpha L_{cls} + (1-\alpha)L_{reg}$. 
    
    \begin{figure}[t]
    \centering
    \includegraphics[width=1\columnwidth]{Model.png}
    \caption{arc}
    \label{fig:arc}
\end{figure}

\subsection{Conversation structure pretraining}
    Conversations between a group of people on social media platform usually come with an inherent tree structure. Some platforms such as reddit, Wikipedia talk page, twitter have a clearly defined “reply-to” attribute for each comment. Previous works pay less attention to this structure when they model the conversations. In order to investigate whether such conversational structures play a role in conversation development, we propose a scheme to pretrain our model on such structure in an unsupervised way. Specifically, we feed a sequence of utterance embedding {u1, …, uN} to the second level transformer model as usual, and the output from the last layer will be followed by a classifier with a SoftMax activation function to predict the parent of each utterance. We apply masked attention as show in Fig. during the forward passing and each utterance effectively only attends to its ancestors. We use the longest conversation length in the dataset as the total number of classification classes. For the initial utterance, we denote its parent as itself. Fig show a sample conversation structure, and the ground truth for this conversation should be ${(1, 0, 0, 0), (1, 0, 0, 0), (0, 1, 0, 0), (0, 1, 0, 0)}$. 

\subsection{Data augmentation strategy}

One advantage of the multi-task training and conversation structure pretraining is that the dataset can be augmented by a factor of the average length of the conversations. Each data sample {u1, u2, …un} can be extended to a sequence of samples {{u1}, {u1, u2}, …, {u1, u2, …, un-1}}. This straightforward strategy, however, may not produce the best results. After examining some conversations, we notice that for longer conversations, the first few utterances have weak indications of derailment, which may confuse the model. The assumption is that the derailment is the result of the accumulative effect of several exchanges. Therefore, we apply a different augmentation strategy to keep at least half of the previous utterance. Now each data sample will be extended to a sequence of samples {}. Our experiment shows that this strategy works better. 


\section{Experiments and Results}
    We evaluate our model on two canonical conversation derailment datasets, which was introduced by (Zhang et al., 2018) and extended by (Change et al., 2019)
    \subsection{Datasets}
    \textbf{Wikipedia talk page (WTP)}
    The WTP dataset was initially introduced by (Zhang et al., 2018) and then expanded by [] using the same procedure. Every Wikipedia article is associated with a Wikipedia talk page where editors of Wikipedia discuss the editing of Wikipedia articles. The goal is to select conversations that start off as civil but detail into personal attacks in the end. A toxicity classifier which was trained on Wikipedia talk page comments is used to provide a toxicity score for all the comments. Two types of conversation are preselected following (a) conversations are civil throughout, i.e., all comments in the conversation have a toxicity score less than $0.4$. (b) conversations are civil for the first exchange (2 comments), but turn toxic afterwards, i.e., there is a comment with toxicity score larger than $0.6$. Conversations with personal attacks only preserve comments up to where the attack happens. To avoid the model from capturing spurious correlations such as conversation topics or length, a series of controls are crowdsourced to make sure that each derailing conversation is paired with a civil conversation from the same talk page with similar length. This procedure produces a dataset which contains $2094$ pairs of conversations, splitting into $60-20-20$ segments. Formally, we denote 1 as personal attack comment and 0 as civil comment, then a sample data pair can be represented as ${(0,0,0,0), (0,0,0,0,1)}$. Therefore, the classes are perfectly balanced.

    \textbf{Reddit ChangeMyView view (CMV)}
    The Reddit CMV dataset was crafted by (Change et al., 2019). ChangeMyView is a subreddit where reddit users post their opinions and challenge other user to change his/her views. The reason why this subreddit is chosen is because there is a specific rule stating “Rule 2: Don’t be rude or hostile to other users”. The platform moderator will delete any comment that are likely to have personal attacks. This can be used as a proxy label for each comment. To apply the topic and length control pairing as in the WTP datasets, each positive and negative pair with similar length is chosen from the same top-level post. The deleted comment is guaranteed to come from a user who previous participated in the conversation. This procedure produces a dataset of $3421$ pairs of conversations, which is also split into $60-20-20$ parts. One thing to note is that there is no post-hoc annotation and examination for the dataset. Therefore, there is no guarantee that for either positive or negative conversations, all comment prior to the last one would be civil. Intuitively, the CMV dataset may contain more noise compared to the WPT dataset. 

\begin{table*}[ht]
  \centering
  \begin{tabular}{|c c c c c c c c c c c|} 
  \hline
  
 \hline
  & Acc & Prec & Rec & FPR & F1 & Acc & Prec & Rec & FPR & F1\\ [0.5ex] 
 \hline
 1 & 6 & 87837 & 787 \\ 
 2 & 7 & 78 & 5415 \\
 3 & 545 & 778 & 7507 \\
 4 & 545 & 18744 & 7560 \\
 5 & 88 & 788 & 6344 \\ [1ex] 
 \hline
\end{tabular}
\caption{Table to test captions and labels.}
\label{table:1}
\end{table*}


\subsection{Experimental Setup}
\textbf{Baseline} The dataset was proposed and organized by xxx in 2018, and the most recent paper evaluating the dataset is from xxx. We follow the results reported in xxx and compare our performance with them. In addition, we also compare the performance with a straightforward bag of words model, which simply concatenates all utterances and converts into a bag of word vector. Therefore, this approach only captures syntactical cues without consider sequential relations between utterances. \par


\textbf{Training process} In order to facilitate the learning process, we experimented with different configurations. We implemented our models with the Hugging Face library and setup the learning rate to be 1e-5 with batch size 64 for the multitask learning part. The model was trained with the Adam optimization algorithm. With the experiment, we notice that using only the first or second utterance as inputs would have a negative impact on the performance, possibly due to the fact the first or second utterance doesn’t provide enough cues for the model to predict derailment. Therefore, we adopt a sampling strategy that starts with floor (length / 2) utterances. That is, for conversations of length 4 and 5, we sample from 2 utterances, and for length 6/7, we sample from 3 utterances. With this strategy, the target for the distance loss is limited to 1-5. During the training, we evaluate the performance on the dev split every 100 iterations and only save the checkpoint if the performance of the current iteration is better than that from the last checkpoints. For the PSM adaptive pretraining module, as the goal of the training is to enable the model to be able to capture general structural information exiting in the conversation, we don’t face such a lack of semantic information problem. Therefore, for each conversation sample, we split into Length(conversation)-1 samples and train with batch size 64. \par


\textbf{Evaluation} Following xxx, we evaluate the performance of the model with acc(accuracy), prec(precision), rec(recall), FPR (false positive rate), and F1 score. To have a fair comparison, during evaluation, we only look at the outcome from the binary prediction head and ignore the prediction from the distance-to-break head. The evaluation was done in a progressive manner. That is, for a conversation of length L, whenever the model makes a positive prediction when feeding with utterance sequence {u1, u1u2, …, u1u2..uL-1}, it counts as a derailment prediction. If all the preceding sequence is predicted as negative, the conversation is deemed to not detailed. 


\subsection{Results and Analysis}

Table 2 shows the result of our various model variants, together with these models from previous research. HT-B is our base model of the hierarchy transformer, which only consists of one binary prediction head without data augmenting. HT-M is the multi-task learning model, which has two prediction heads and uses data augmentation during training. HT-MR represents the pretraining with structural information process followed by the HT-M model. Overall, our models achieve better performance regarding most of the metrics. Within our own variant, the result is mixed. 

One of the main differences between our architecture and the previous models is that we leverage the power of pre-trained language models and self-attention mechanisms. Both CRAFT and HRED consist of two LSTM layers, and they pretrained the model over 1m conversations with autoregressive language model objective to get the best performance, which is a heavy cost and requires gathering a large amount of data from the same domain. It’s also not easy to adapt the pretrained language model to other tasks.  As we can see, all three of our variant models achieved better F1 scores on both the WTP and CMV datasets. HRED has the lowest false positive rate score on the WTP dataset while CRAFT has the highest recall scores on the same dataset. For all other metrics on both datasets, our models have significantly higher performance. 

Comparing the three different variants of our model, the multi-task learning architecture has the best F1 scores among all models on both datasets, which demonstrates the effectiveness of our multi-task learning and data augmentation strategy. One thing to notice from our experiment is that, if we change our data augmentation strategy from ratio sampling to full sampling, the performance decreases, which indicates that the model needs more context to learn the factors leading to derailment. On the other side, the base version of HT has a lower false-positive rate compared to HT-M on the CMV dataset, which implied that the distance to break information does encourage the model to make positive predictions. This is also echoed by the fact that the HT-M model has a higher recall rate. 

Contrary to our expectations, adding the reply-to pretraining process does not yield positive impacts on the performance. There might be three reasons for this. The first reason is that we didn’t pretrain our model on other data within the same domain, but only limited our pretraining within the two datasets. Although the dataset is augmented by a factor of conversation length, the total number of data points is far less than the amount of data that is used in previous research. The second reason might be that the reply-to relation between the utterance in these two datasets doesn’t align well with the semantics of the utterances. The third reason might be that derailment may not relate too much to the semantics of each utterance. One observation we have is most derailments happen due to direct tone and impoliteness. The conversation topics in both datasets are very diverse and the pretraining may cause the model to capture some noises in the dataset.


\section{Conclusion and Future Work}


In this paper, we focus on a new preventive perspective regarding detecting and moderating toxic and abusive behaviors in online forum conversations. Rather than predicting whether a conversation contains toxic content retrospectively, we try to predict whether an ongoing conversation will break down as it develops. We propose a hierarchical transformer architecture to capture both utterance level and conversation level semantics leveraging the power of the pre-trained language models. On top of this, we propose new ways to integrate conversational structure and the distance to derailment information into our model and achieve better F1 scores on two canonical conversation derailments datasets.

Although the model we proposed mainly addresses the problem of predicting conversation derailment dynamically, it can be easily adapted to solve other related conversation development prediction tasks, such as foreseeing whether a goal-oriented conversation would succeed in the end. In addition to a simple binary prediction, our distance-to-derailment prediction could provide extra time-sensitive information. For tasks where the inherent conversation structure matters, our model provides one way to exploit such structure information. We expect to see the application of our approach in other related conversation prediction tasks in future work. 

With all the strengths that come with our approach, we also discover several limitations during our experiments. The first limitation is that we have limited our reply-to structure pretraining to the two datasets we evaluate, which doesn’t seem to provide enough data for this kind of pretraining. Therefore, to leverage the structure information, we could continue to train the model on any conversations that happened within the same forum. Another option is to utilize a better model, such as graph neural networks, which are specifically designed for capturing tree-like structure information. The second direction to improve our model is to capture speaker identity. For most conversations, there might be a pattern where certain types of users are more inclined to attack other people. The ability to model different speaker types may play an important role in such kinds of conversation prediction tasks.
\citep{zhang-etal-2018-conversations} 
\citep{10.1145/2806416.2806493}
\citep{he-etal-2021-speaker-turn}


\bibliography{Jiaqing}
\bibliographystyle{acl_natbib}

%\appendix



\end{document}
