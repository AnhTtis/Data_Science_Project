{
    "arxiv_id": "2303.13536",
    "paper_title": "Help the Blind See: Assistance for the Visually Impaired through Augmented Acoustic Simulation",
    "authors": [
        "Alexander Mehta",
        "Ritik Jalisatgi"
    ],
    "submission_date": "2023-02-09",
    "revised_dates": [
        "2023-03-30"
    ],
    "latest_version": 1,
    "categories": [
        "cs.HC",
        "cs.CV",
        "cs.SD",
        "eess.AS"
    ],
    "abstract": "An estimated 253 million people have visual impairments. These visual impairments affect everyday lives, and limit their understanding of the outside world. This can pose a risk to health from falling or collisions. We propose a solution to this through quick and detailed communication of environmental spatial geometry through sound, providing the blind and visually impaired the ability to understand their spatial environment through sound technology. The model consists of fast object detection and 3D environmental mapping, which is communicated through a series of quick sound notes. These sound notes are at different frequencies, pitches, and arrangements in order to precisely communicate the depth and location of points within the environment. Sounds are communicated in the form of musical notes in order to be easily recognizable and distinguishable. A unique algorithm is used to segment objects, providing minimal accuracy loss and improvement from the normal O(n2 ) to O(n) (which is significant, as N in point clouds can often be in the range of 105 ). In testing, we achieved an R-value of 0.866 on detailed objects and an accuracy of 87.5% on an outdoor scene at night with large amounts of noise. We also provide a supplementary video demo of our system.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13536v1"
    ],
    "publication_venue": null
}