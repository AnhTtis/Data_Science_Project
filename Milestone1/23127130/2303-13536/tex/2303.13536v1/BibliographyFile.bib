%This is your bibliography file.
%It can be edited with a text editor, or with the BibTeX editor.
%It is in a very specific format, so make changes carefully.

@article{himmelsbach2010fast,
	title={Fast segmentation of 3d point clouds for ground vehicles},
	author={Himmelsbach, Michael and Hundelshausen, Felix V and Wuensche, H-J},
	booktitle={Intelligent Vehicles Symposium (IV), 2010 IEEE},
	pages={560--565},
	year={2010},
	organization={IEEE}
}
@article{nuscenes,
	title={nuScenes: A multimodal dataset for autonomous driving},
	author={Holger Caesar and Varun Bankiti and Alex H. Lang and Sourabh Vora and 
	Venice Erin Liong and Qiang Xu and Anush Krishnan and Yu Pan and 
	Giancarlo Baldan and Oscar Beijbom}, 
	booktitle={CVPR},
	year=2020

}
@Article{pmid31550277,
	Author="Van Hedger, S. C.  and Heald, S. L. M.  and Nusbaum, H. C. ",
	Title="{{A}bsolute pitch can be learned by some adults}",
	Journal="PLoS One",
	Year="2019",
	Volume="14",
	Number="9",
	Pages="e0223047"
}

@article{discussion_a,
	doi = {10.1371/journal.pone.0062927},
	author = {Bijveld, Mieke M. C. AND van Genderen, Maria M. AND Hoeben, Frank P. AND Katzin, Amir A. AND van Nispen, Ruth M. A. AND Riemslag, Frans C. C. AND Kappers, Astrid M. L.},
	journal = {PLOS ONE},
	publisher = {Public Library of Science},
	title = {Assessment of Night Vision Problems in Patients with Congenital Stationary Night Blindness},
	year = {2013},
	month = {05},
	volume = {8},
	url = {https://doi.org/10.1371/journal.pone.0062927},
	pages = {1-11},
	abstract = {Congenital Stationary Night Blindness (CSNB) is a retinal disorder caused by a signal transmission defect between photoreceptors and bipolar cells. CSNB can be subdivided in CSNB2 (rod signal transmission reduced) and CSNB1 (rod signal transmission absent). The present study is the first in which night vision problems are assessed in CSNB patients in a systematic way, with the purpose of improving rehabilitation for these patients. We assessed the night vision problems of 13 CSNB2 patients and 9 CSNB1 patients by means of a questionnaire on low luminance situations. We furthermore investigated their dark adapted visual functions by the Goldmann Weekers dark adaptation curve, a dark adapted static visual field, and a two-dimensional version of the “Light Lab”. In the latter test, a digital image of a living room with objects was projected on a screen. While increasing the luminance of the image, we asked the patients to report on detection and recognition of objects. The questionnaire showed that the CSNB2 patients hardly experienced any night vision problems, while all CSNB1 patients experienced some problems although they generally did not describe them as severe. The three scotopic tests showed minimally to moderately decreased dark adapted visual functions in the CSNB2 patients, with differences between patients. In contrast, the dark adapted visual functions of the CSNB1 patients were more severely affected, but showed almost no differences between patients. The results from the “2D Light Lab” showed that all CSNB1 patients were blind at low intensities (equal to starlight), but quickly regained vision at higher intensities (full moonlight). Just above their dark adapted thresholds both CSNB1 and CSNB2 patients had normal visual fields. From the results we conclude that night vision problems in CSNB, in contrast to what the name suggests, are not conspicuous and generally not disabling.},
	number = {5},
	
}

@misc{alternative,


	doi = {10.48550/ARXIV.2212.00004},
	
	url = {https://arxiv.org/abs/2212.00004},
	
	author = {Sarwar, Savera and Turab, Muhammad and Channa, Danish and Chandio, Aisha and Sohu, M. Uzair and Kumar, Vikram},
	
	keywords = {Human-Computer Interaction (cs.HC), Computer Vision and Pattern Recognition (cs.CV), Sound (cs.SD), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
	
	title = {Advanced Audio Aid for Blind People},
	
	publisher = {arXiv},
	
	year = {2022},
	
	copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{objectdataset,
	author = {Zhou, Qian-Yi and Koltun, Vladlen},
	year = {2013},
	month = {07},
	pages = {},
	title = {Dense Scene Reconstruction with Points of Interest},
	volume = {32},
	journal = {ACM Transactions on Graphics},
	doi = {10.1145/2461912.2461919}
}
@article{10.1371/journal.pone.0020162,
    doi = {10.1371/journal.pone.0020162},
    author = {Thaler, Lore AND Arnott, Stephen R. AND Goodale, Melvyn A.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Neural Correlates of Natural Human Echolocation in Early and Late Blind Echolocation Experts},
    year = {2011},
    month = {05},
    volume = {6},
    url = {https://doi.org/10.1371/journal.pone.0020162},
    pages = {1-16},
    abstract = {Background A small number of blind people are adept at echolocating silent objects simply by producing mouth clicks and listening to the returning echoes. Yet the neural architecture underlying this type of aid-free human echolocation has not been investigated. To tackle this question, we recruited echolocation experts, one early- and one late-blind, and measured functional brain activity in each of them while they listened to their own echolocation sounds.   Results When we compared brain activity for sounds that contained both clicks and the returning echoes with brain activity for control sounds that did not contain the echoes, but were otherwise acoustically matched, we found activity in calcarine cortex in both individuals. Importantly, for the same comparison, we did not observe a difference in activity in auditory cortex. In the early-blind, but not the late-blind participant, we also found that the calcarine activity was greater for echoes reflected from surfaces located in contralateral space. Finally, in both individuals, we found activation in middle temporal and nearby cortical regions when they listened to echoes reflected from moving targets.   Conclusions These findings suggest that processing of click-echoes recruits brain regions typically devoted to vision rather than audition in both early and late blind echolocation experts.},
    number = {5},

}


@article{10.1371/journal.pone.0199389,
    doi = {10.1371/journal.pone.0199389},
    author = {Massiceti, Daniela AND Hicks, Stephen Lloyd AND van Rheede, Joram Jacob},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Stereosonic vision: Exploring visual-to-auditory sensory substitution mappings in an immersive virtual reality navigation paradigm},
    year = {2018},
    month = {07},
    volume = {13},
    url = {https://doi.org/10.1371/journal.pone.0199389},
    pages = {1-32},
    abstract = {Sighted people predominantly use vision to navigate spaces, and sight loss has negative consequences for independent navigation and mobility. The recent proliferation of devices that can extract 3D spatial information from visual scenes opens up the possibility of using such mobility-relevant information to assist blind and visually impaired people by presenting this information through modalities other than vision. In this work, we present two new methods for encoding visual scenes using spatial audio: simulated echolocation and distance-dependent hum volume modulation. We implemented both methods in a virtual reality (VR) environment and tested them using a 3D motion-tracking device. This allowed participants to physically walk through virtual mobility scenarios, generating data on real locomotion behaviour. Blindfolded sighted participants completed two tasks: maze navigation and obstacle avoidance. Results were measured against a visual baseline in which participants performed the same two tasks without blindfolds. Task completion time, speed and number of collisions were used as indicators of successful navigation, with additional metrics exploring detailed dynamics of performance. In both tasks, participants were able to navigate using only audio information after minimal instruction. While participants were 65% slower using audio compared to the visual baseline, they reduced their audio navigation time by an average 21% over just 6 trials. Hum volume modulation proved over 20% faster than simulated echolocation in both mobility scenarios, and participants also showed the greatest improvement with this sonification method. Nevertheless, we do speculate that simulated echolocation remains worth exploring as it provides more spatial detail and could therefore be more useful in more complex environments. The fact that participants were intuitively able to successfully navigate space with two new visual-to-audio mappings for conveying spatial information motivates the further exploration of these and other mappings with the goal of assisting blind and visually impaired individuals with independent mobility.},
    number = {7},

}



@article{10.3389/fphys.2013.00098,
  
AUTHOR={Thaler, Lore},   
	 
TITLE={Echolocation may have real-life advantages for blind people: an analysis of survey data},      
	
JOURNAL={Frontiers in Physiology},      
	
VOLUME={4},           
	
YEAR={2013},      
	  
URL={https://www.frontiersin.org/articles/10.3389/fphys.2013.00098},       
	
DOI={10.3389/fphys.2013.00098},      
	
ISSN={1664-042X},   
   
ABSTRACT={Some people can echolocate by making sonar emissions (e.g., mouth-clicks, finger snaps, feet shuffling, humming, cane tapping, etc.) and listening to the returning echoes. To date there are no statistics available about how many blind people use echolocation, but anecdotal reports in the literature suggest that perhaps between 20 and 30% of totally blind people may use it, suggesting that echolocation affords broad functional benefits. Consistent with the notion that blind individuals benefit from the use of echolocation, previous research conducted under controlled experimental conditions has shown that echolocation improves blind people's spatial sensing ability. The current study investigated if there is also evidence for functional benefits of echolocation in real life. To address this question the current study conducted an online survey. Thirty-seven blind people participated. Linear regression analyses of survey data revealed that, while statistically controlling for participants' gender, age, level of visual function, general health, employment status, level of education, Braille skill, and use of other mobility means, people who use echolocation have higher salary, and higher mobility in unfamiliar places, than people who do not use echolocation. The majority of our participants (34 out of 37) use the long cane, and all participants who reported to echolocate, also reported to use the long cane. This suggests that the benefit of echolocation that we found might be conditional upon the long cane being used as well. The investigation was correlational in nature, and thus cannot be used to determine causality. In addition, the sample was small (N = 37), and one should be cautious when generalizing the current results to the population. The data, however, are consistent with the idea that echolocation offers real-life advantages for blind people, and that echolocation may be involved in peoples' successful adaptation to vision loss.}
}



@article{thaler2016echolocation,
  title={Echolocation in humans: an overview},
  author={Thaler, Lore and Goodale, Melvyn A},
  journal={Wiley Interdisciplinary Reviews: Cognitive Science},
  volume={7},
  number={6},
  pages={382--393},
  year={2016},
  publisher={Wiley Online Library}
}
@article{blindsee,
	author = {Jiang, Rui and Lin, Qian and Qu, Shuhui},
	year = {2016},
	month = {03},
	pages = {},
	title = {Let Blind People See: Real-Time Visual Recognition with Results Converted to 3D Audio}
}

@article{6907298,  author={Lai, Kevin and Bo, Liefeng and Fox, Dieter},  booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)},   title={Unsupervised feature learning for 3D scene labeling},   year={2014},  volume={},  number={},  pages={3050-3057},  abstract={This paper presents an approach for labeling objects in 3D scenes. We introduce HMP3D, a hierarchical sparse coding technique for learning features from 3D point cloud data. HMP3D classifiers are trained using a synthetic dataset of virtual scenes generated using CAD models from an online database. Our scene labeling system combines features learned from raw RGB-D images and 3D point clouds directly, without any hand-designed features, to assign an object label to every 3D point in the scene. Experiments on the RGB-D Scenes Dataset v.2 demonstrate that the proposed approach can be used to label indoor scenes containing both small tabletop objects and large furniture pieces.},  keywords={},  doi={10.1109/ICRA.2014.6907298},  ISSN={1050-4729},  month={May}}


@article{6094649,  author={Tombari, Federico and Di Stefano, Luigi and Giardino, Simone},  booktitle={2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},   title={Online learning for automatic segmentation of 3D data},   year={2011},  volume={},  number={},  pages={4857-4864},  abstract={We propose a method to perform automatic segmentation of 3D scenes based on a standard classifier, whose learning model is continuously improved by means of new samples, and a grouping stage, that enforces local consistency among classified labels. The new samples are automatically delivered to the system by a feedback loop based on a feature selection approach that exploits the outcome of the grouping stage. By experimental results on several datasets we demonstrate that the proposed online learning paradigm is effective in increasing the accuracy of the whole 3D segmentation thanks to the improvement of the learning model of the classifier by means of newly acquired, unsupervised data.},  keywords={},  doi={10.1109/IROS.2011.6094649},  ISSN={2153-0866},  month={Sep.}}


@article{Karpathy_ICRA2013,
	author = {Andrej Karpathy and Stephen Miller, and Li Fei-Fei},
	title = {Object Discovery in 3D Scenes via Shape Analysis},
	booktitle = {International Conference on Robotics and Automation (ICRA)},
	year = {2013},
}


@article{s17030565,
	AUTHOR = {Elmannai, Wafa and Elleithy, Khaled},
	TITLE = {Sensor-Based Assistive Devices for Visually-Impaired People: Current Status, Challenges, and Future Directions},
	JOURNAL = {Sensors},
	VOLUME = {17},
	YEAR = {2017},
	NUMBER = {3},
	ARTICLE-NUMBER = {565},
	URL = {https://www.mdpi.com/1424-8220/17/3/565},
	ISSN = {1424-8220},
	ABSTRACT = {The World Health Organization (WHO) reported that there are 285 million visuallyimpaired people worldwide. Among these individuals, there are 39 million who are totally blind. There have been several systems designed to support visually-impaired people and to improve the quality of their lives. Unfortunately, most of these systems are limited in their capabilities. In this paper, we present a comparative survey of the wearable and portable assistive devices for visuallyimpaired people in order to show the progress in assistive technology for this group of people. Thus, the contribution of this literature survey is to discuss in detail the most significant devices that are presented in the literature to assist this population and highlight the improvements, advantages, disadvantages, and accuracy. Our aim is to address and present most of the issues of these systems to pave the way for other researchers to design devices that ensure safety and independent mobility to visually-impaired people.},
	DOI = {10.3390/s17030565}
}

@article{de2004different,
	title={Different aspects of visual impairment as risk factors for falls and fractures in older men and women},
	author={de Boer, Michiel R and Pluijm, Saskia MF and Lips, Paul and Moll, Annette C and V{\"o}lker-Dieben, Hennie J and Deeg, Dorly JH and van Rens, Ger HMB},
	journal={Journal of bone and Mineral Research},
	volume={19},
	number={9},
	pages={1539--1547},
	year={2004},
	publisher={Wiley Online Library}
}
@article{gillespie2003interventions,
	title={Interventions for preventing falls in elderly people},
	author={Gillespie, Lesley D and Gillespie, William J and Robertson, M Clare and Lamb, Sarah E and Cumming, Robert G and Rowe, Brian H},
	journal={Cochrane database of systematic reviews},
	number={4},
	year={2003},
	publisher={John Wiley \& Sons, Ltd}
}
@article{Crews2016,
	doi = {10.15585/mmwr.mm6517a2},
	url = {https://doi.org/10.15585/mmwr.mm6517a2},
	year = {2016},
	month = may,
	publisher = {Centers for Disease Control {MMWR} Office},
	volume = {65},
	number = {17},
	pages = {433--437},
	author = {John E. Crews and Chiu-Fung Chou and Judy A. Stevens and Jinan B. Saaddine and},
	title = {Falls Among Persons Aged $\geq$65 Years With and Without Severe Vision Impairment {\textemdash} United States,  2014},
	journal = {{MMWR}. Morbidity and Mortality Weekly Report}
}

@ARTICLE{Ackland2017-uo,
	title    = "World blindness and visual impairment: despite many successes,
	the problem is growing",
	author   = "Ackland, Peter and Resnikoff, Serge and Bourne, Rupert",
	journal  = "Community Eye Health",
	volume   =  30,
	number   =  100,
	pages    = "71--73",
	year     =  2017,
	language = "en"
}
@ARTICLE{Steinman2011-kw,
	title    = "Falls-prevention interventions for persons who are blind or
	visually impaired",
	author   = "Steinman, Bernard A and Nguyen, Anna Q D and Pynoos, Jon and
	Leland, Natalie E",
	abstract = "The purpose of this article is to describe four main areas of
	falls-prevention intervention for older adults who are blind or
	visually impaired. When integrated into multifactorial programs,
	interventions pertaining to education, medical assessment,
	exercise and physical activity, and environmental assessment and
	modification have been shown to be effective in falls reduction.
	These areas of intervention are discussed with respect to
	specific concerns of older adults who are blind or visually
	impaired. In describing these areas of intervention, the
	increasing need for cross-disciplinary falls-prevention programs
	designed specifically for older persons with vision loss, as well
	as research demonstrating the efficacy of multidisciplinary
	programs designed for this group, are emphasized.",
	journal  = "Insight",
	volume   =  4,
	number   =  2,
	pages    = "83--91",
	year     =  2011,
	keywords = "blindness; multifactorial falls prevention; older adults; vision
	impairment",
	language = "en"
}

