\pdfsuppresswarningpagegroup=1
%% bare_jrnl_comsoc.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% Communications Society journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



% \documentclass[journal,comsoc]{IEEEtran}
\documentclass[lettersize,journal]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal,comsoc]{../sty/IEEEtran}


\usepackage[T1]{fontenc}% optional T1 font encoding


% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
% \usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
% Do NOT use the amsbsy package under comsoc mode as that feature is
% already built into the Times Math font (newtxmath, mathtime, etc.).
% 
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath


% Select a Times math font under comsoc mode or else one will automatically
% be selected for you at the document start. This is required as Communications
% Society journals use a Times, not Computer Modern, math font.
\usepackage[cmintegrals]{newtxmath}
% The freely available newtxmath package was written by Michael Sharpe and
% provides a feature rich Times math font. The cmintegrals option, which is
% the default under IEEEtran, is needed to get the correct style integral
% symbols used in Communications Society journals. Version 1.451, July 28,
% 2015 or later is recommended. Also, do *not* load the newtxtext.sty package
% as doing so would alter the main text font.
% http://www.ctan.org/pkg/newtx
%
% Alternatively, you can use the MathTime commercial fonts if you have them
% installed on your system:
%\usepackage{mtpro2}
%\usepackage{mt11p}
%\usepackage{mathtime}


%\usepackage{bm}
% The bm.sty package was written by David Carlisle and Frank Mittelbach.
% This package provides a \bm{} to produce bold math symbols.
% http://www.ctan.org/pkg/bm





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and 
% Axel Sommerfeldt. This package may be useful when used in conjunction with 
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/pkg/endfloat
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

% *** PERSONALIZED PACKAGES ***

\usepackage{cite}
\usepackage{amsmath}
\let\openbox\undefined
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{algorithmic}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{bm}
\usepackage{enumitem}
\usepackage{subfigure}
\usepackage{url}
\usepackage{hyperref}
 \usepackage{ulem}
%  % add ORCID
% \usepackage{tikz,xcolor}
% \usepackage[implicit=false]{hyperref}
%\usepackage[colorlinks,
%linkcolor=red,
%anchorcolor=blue,
%citecolor=green
%]{hyperref}

\newtheorem{property}{Property}
\newtheorem{assumption}{Assumption}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{contribution}{Contribution}

\newcommand{\etal}{\textit{et al}.}
\newcommand{\ie}{\textit{i}.\textit{e}.}
\newcommand{\eg}{\textit{e}.\textit{g}.}
\newcommand{\bfw}{{\theta}}
\newcommand{\bfx}{\mathrm{x}}
\newcommand{\bfy}{\mathrm{y}}
\newcommand{\mli}[1]{\mathit{#1}}
\newcommand{\algname}[1]{{\textrm{#1}}}

\allowdisplaybreaks[4]

% solve the "underfull" warning
% \raggedbottom

% set the spacing between floats and the text
%\setlength{\textfloatsep}{20pt plus 2.0pt minus 2.0pt}
\setlength{\dbltextfloatsep}{5pt plus 2.0pt minus 2.0pt}
\setlength{\dblfloatsep}{5pt plus 2.0pt minus 2.0pt}
\setlength{\floatsep}{5pt plus 2.0pt minus 2.0pt}
\setlength{\intextsep}{5pt plus 2.0pt minus 2.0pt}
\setlength{\abovecaptionskip}{1.5pt plus 2.0pt minus 2.0pt}
\setlength{\belowcaptionskip}{1.5pt plus 2.0pt minus 2.0pt}

\newboolean{showcomments}
\setboolean{showcomments}{true}
\newcommand{\comment}[1]{\ifthenelse{\boolean{showcomments}}
	{\textcolor{red}{(Comment: #1)}}
	{}
}
\newcommand{\red}[1]{\ifthenelse{\boolean{showcomments}}
	{\textcolor{red}{#1}}
	{}
}

\newboolean{showanswers}
\setboolean{showanswers}{true}
\newcommand{\answer}[1]{\ifthenelse{\boolean{showanswers}}
	{\textcolor{blue}{(Answer: #1)}}
	{}
}


\newtheorem{remark}{Remark} 
\SetKwRepeat{Do}{do}{while}


\begin{document}


\title{PoPeC: PAoI-Centric Task Offloading with Priority over Unreliable Channels\vspace{-0pt}}
\author{
        Nan~Qiao,~\IEEEmembership{Student Member,~IEEE},
        % \textit{OCID: 0000-0001-2345-6789},
        Sheng~Yue,~\IEEEmembership{Student Member,~IEEE},
        Yongmin~Zhang,~\IEEEmembership{Senior Member,~IEEE},
        ~
        Ju Ren,~\IEEEmembership{Senior Member,~IEEE}
    \IEEEcompsocitemizethanks{\IEEEcompsocthanksitem Nan Qiao and Yongmin Zhang are with the School of Computer and Engineering, Central South University, Changsha, Hunan, 410083 China. E-mails: \{nan.qiao, zhangyongmin\}@csu.edu.cn.
    \IEEEcompsocthanksitem Sheng Yue and Ju Ren are with the Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, 100084 China. E-mails: shengyue@mail.tsinghua.edu.cn and renju@tsinghua.edu.cn.
    \IEEEcompsocthanksitem Corresponding author: \textit{Dr. Ju Ren}.
    }  
}
        
\maketitle




% \onecolumn
%abstract
% \IEEEtitleabstractindextext{
\begin{abstract}
Freshness-aware computation offloading has garnered great attention recently in the edge computing arena, with the aim of promptly obtaining up-to-date information and minimizing the transmission of outdated data. However, most of the existing work assumes that wireless channels are reliable and neglect the dynamics and stochasticity thereof. In addition, varying priorities of offloading tasks along with heterogeneous computing units also pose significant challenges in effective task scheduling and resource allocation. 
% Additionally, the mismatch between task requirements and available compute resources due to the lack of coordination among heterogeneous computing units can lead to local server overload.
To address these challenges, we cast the freshness-aware task offloading problem as a multi-priority optimization problem, considering the unreliability of wireless channels, the heterogeneity of edge servers, and prioritized users. 
% for users with multi-class priority in unreliable channels and for servers with collaboration.
Based on the nonlinear fractional programming and ADMM-Consensus method, we propose a joint resource allocation and task offloading algorithm to solve the original problem iteratively. To improve communication efficiency, we further devise a distributed asynchronous variant for the proposed algorithm. We rigorously analyze the performance and convergence of the proposed algorithms and conduct extensive simulations to corroborate their efficacy and superiority over the existing baselines.
% Specifically, we perform various transformations, such as fractional programming, and use ADMM to solve several special cases.
% Subsequently, building upon these methods and conclusions drawn earlier, we use an iterative solution algorithm to obtain the solution to the original problem.
% Furthermore, we propose an asynchronous non-convex ADMM method with a sublinear rate of communication defects and discuss the theoretical performance improvement due to the multi-priority mechanism.
%simulaiton
% Finally, simulation results demonstrate the performance gain.
\end{abstract}
\begin{IEEEkeywords}
		distributed task offloading, edge computing, channel allocation, system freshness
\end{IEEEkeywords}
% }






%introduction
\section{Introduction}
\label{sec:introduction}

%background
%importance of task offloading

Edge computing is an attractive computing paradigm in the era of the Internet of Things (IoT) \cite{mao2017mobile,luo2021resource,liu2019survey}. By enabling end devices to offload computation-intensive tasks to nearby edge nodes, edge computing is envisioned to provide real-time computing services, thereby facilitating the deployment of a wide range of intelligent applications (e.g., smart homes, smart cities, and autonomous vehicles) \cite{tran2018joint}.
%It is anticipated to offer real-time computing services by enabling end devices to offload their computation-intensive tasks to nearby edge nodes. 
%Thus, it can benefit a wide range of practical applications (e.g., smart home/city and autonomous vehicles \cite{tran2018joint}).
For these applications, it is of paramount importance to promptly obtain up-to-date information and minimize the transmission of outdated and worthless data \cite{zou2021minimizing}. 
To this end, a great number of offloading solutions have been proposed to achieve timely status updates and rapid delivery of tasks from information sources, in order to enhance the \textit{freshness} performance \cite{guo2021scheduling,sun2021age,li2021task,bedewy2020optimizing,pan2021minimizing}.

%the research community has shown considerable interest in developing solutions that can achieve timely status updates and rapid delivery of tasks from information sources, in order to enhance the \textit{freshness} performance \cite{guo2021scheduling,sun2021age,li2021task,bedewy2020optimizing,pan2021minimizing}.

% how to enable timely status updates and rapid delivery of tasks from information sources, in order to achieve excellent freshness performance has received a lot of attention \cite{guo2021scheduling,sun2021age,li2021task,bedewy2020optimizing,pan2021minimizing}.


% Recently, the Age of Information (AoI) and Peak Age of Information (PAoI) have been recognized as crucial indicators of information freshness, which refers to how long it has been since a user's last packet has been received \cite{yates2021age}.
Recently, the Age of Information (AoI) and Peak Age of Information (PAoI) 
have been recognized as important metrics for evaluating information freshness,
which characterizes the elapsed time since the reception of a user's most recent data packet \cite{yates2021age}.
Based on AoI and PAoI, recent research has been focused on freshness-aware offloading methods.
% Many works take into account effective channel allocation to enable users to efficiently and concurrently transmit freshness-sensitive information to a local server over a set of wireless channels
% \cite{hu2022age,liu2021aion,li2021scheduling,moon2015minimax,pan2021minimizing,zou2021minimizing,sun2021age,guo2021scheduling,bedewy2020optimizing}.
Some works aim to optimize the allocation of wireless channels for efficient and concurrent transmission of freshness-sensitive information to a local server \cite{hu2022age,li2021task,liu2021aion,li2021scheduling,moon2015minimax,pan2021minimizing,zou2021minimizing,sun2021age,guo2021scheduling,bedewy2020optimizing}.
Other studies investigate offloading strategies for distributing fresh tasks from multiple sources to a collection of edge servers \cite{lv2021strategy,yates2018status,bedewy2016optimizing,li2020waiting}.

% focus on how to offload fresh tasks from multiple sources to a collection of edge servers \cite{lv2021strategy,yates2018status,bedewy2016optimizing,li2020waiting}.

Unfortunately, several obstacles still need to be overcome for achieving effective freshness-aware offloading. First, many existing works assume channel homogeneity \cite{sun2019closed,bedewy2020optimizing} or perfect knowledge of channel states \cite{pan2021minimizing,sombabu2020age}, overlooking the dynamics and stochasticity of the limited wireless channels in the real world. As a result, such methods easily suffer from package loss or failure due to unreliable communication \cite{moon2015minimax}. Second, computing resources on edge servers are typically constrained and heterogeneous. It is of importance to appropriately assign heterogeneous computing units to offloading tasks, whereas often being neglected in literature \cite{bedewy2020optimizing, hsu2019scheduling, karabulut2018spatial, zeng2015optimized}. More importantly, designing a \textit{prioritized offloading strategy} is crucial since users may have diverse freshness requirements. For example, safety-sensitive devices like temperature sensors in the Industrial Internet of Things and Automatic Emergency Braking (AEB) in autopilot require prompt offloading and processing to meet their high freshness demands. However, most existing methods struggle with measuring and handling the situations where the offloading tasks have different priorities. In light of these considerations, this work seeks to answer the key question: \textit{``How to design an efficient task offloading algorithm that can optimize the system information freshness while effectively handling prioritized users, unreliable channels, and heterogeneous edge servers?''} 
% This includes a variety of mobile edge computing (MEC) servers with different computation and transmission power, as well as diverse types and sizes of offloading tasks generated from end devices
% One major challenge is the limited and unreliable nature of communication channels, which can result in packet loss or failure and ultimately impede the transmission of information \cite{moon2015minimax}. Therefore, existing strategies operating synchronously and in parallel can result in significant communication costs due to repeated attempts \cite{pan2021minimizing,zou2021minimizing,sun2021age,guo2021scheduling}. Another challenge arises from the constrained resources and complex heterogeneous nature of the offloading environment. This includes a variety of mobile edge computing (MEC) servers with different computation and transmission power, as well as diverse types and sizes of offloading tasks generated from end devices \cite{bedewy2020optimizing, hsu2019scheduling, karabulut2018spatial, zeng2015optimized}. 
% It can easily suffer from large communication costs since the property of unreliable communication forced previous simultaneous iterative algorithms to require repeated communication tries from a device before each iteration was successful. 
% Second, the offloading environment usually contains limited computation, communication, and particularly embedded heterogeneous resources, such as a variety of MEC servers with diverse computation and transmission power, as well as the types/sizes of offloading tasks that vary from end devices.The constraints of constrained resources and the complexity of the heterogeneous problem pose challenges for efficient offloading schemes \cite{bedewy2020optimizing, hsu2019scheduling, karabulut2018spatial, zeng2015optimized}. % More importantly, we are exploring the implementation of a priority system on the edge server to accommodate the needs of different freshness-sensitive users.

% More importantly, since different users often have diverse freshness requirements, the design of a \textit{prioritized offloading strategy} is also crucial. --
% For example, safety-sensitive devices, such as temperature sensors used in the Industrial Internet of Things and Automatic Emergency Braking (AEB) used in autopilot, must be promptly offloaded to edge servers and processed first to meet their high freshness requirements. 
% However, existing methods struggle to measure and handle scenarios where users have different priorities during offloading.
% Therefore, a significant but unresolved challenge is task offloading based on the priority class of the users and the capacity to meet the resource constraints of the tasks with the minimum possible freshness. The preceding considerations motivate us to pose the following key question: \textit{How to design a communication-efficient task offloading algorithm capable of optimizing system freshness while dealing with priority users and heterogeneous unreliable channels? }
% \begin{itemize}
%     \item \textbf{PoSiP:}\underline{P}AoI-Centric Task \underline{O}ffloading with \underline{Si}ngle-Class \underline{P}riority.
%     \item \textbf{PoMiP:}\underline{P}AoI-Centric Task \underline{O}ffloading with \underline{M}ult\underline{i}-Class \underline{P}riority.
%     \item \textbf{PoMiS:}\underline{P}AoI-Centric Task \underline{O}ffloading with Multi-Class Priority in \underline{M}ult\underline{i}-\underline{S}erver.
% \end{itemize}

% \textbf{Challenge}\
To this end, we cast the freshness-aware task offloading problem as a multi-priority optimization problem, considering the unreliability of wireless channels, the heterogeneity of edge servers, and the interdependence of multiple users with varying priorities. As optimizing this problem directly is highly nontrivial, we first examine two special cases of the original problem. We exploit nonlinear fractional programming to transform the problems into tractable forms and then develop ADMM-Consensus-based solutions for both cases. Built upon these solutions, an iterative algorithm is devised for resolving the original problem effectively. We further discuss a distributed asynchronous variant of the proposed algorithm, capable of alleviating the overhead caused by unreliable iterations during the offloading policy acquisition process.
%To answer this question, we model the task offloading problem for users with multi-class priority in unreliable channels. Due to the unreliability of wireless channels, the heterogeneity of devices and servers, and the coupling of multi-class priority users, this problem, which has been demonstrated to be NP-Hard, is difficult to address directly. To this end, we decompose the problem into three subproblems that are solved step by step. We convert such complex problems using nonlinear fractional programming, and then employ the ADMM-Consensus method to address them. 
Theoretical analysis is carried out to establish the convergence property of the proposed algorithm and demonstrate the improvement in performance brought by the multi-priority mechanism.
%We theoretically analyze the performance improvement brought by the multi-class priority mechanism
% \sout{The efficacy and efficiency of the proposed algorithms are validated through extensive simulation experiments.} %Finally, we conduct extensive simulation experiments to confirm the performance and efficiency of the proposed algorithms.
% \textbf{Contribution}\\
In a nutshell, our main contributions can be summarized as follows.
\begin{itemize}
    \item %We cast an offloading problem based on PAoI with heterogeneous users and unreliable channels. We transform the primary problem into a convex form and propose an ADMM-Consensus algorithm to resolve it efficiently in a distributed manner.
    We consider an M/G/1 offloading system and derive the precise Peak Age of Information (PAoI) expression for each user to characterize their information freshness. Then, we formulate the freshness-aware multi-priority task offloading problem under heterogeneous users and unreliable channels. 
    % To solve this problem, we transform the primary problem into a convex form and propose an efficient distributed solution using the ADMM-Consensus algorithm.
    \item Based on nonlinear fractional programming and ADMM-Consensus method, we propose a joint resource allocation, service migration, and task offloading algorithm to solve the original problem effectively. We further devise a distributed asynchronous variant for the proposed algorithm to improve the communication efficiency.
    % We assign different priority classes to users based on their sensitivity to freshness and formulate the task offloading problem as an M/G/1 system with multi-class priority. We derive the precise PAoI expression and propose an efficient distributed solution to optimize the problem. Furthermore, we carry out a large number of simulation experiments to demonstrate the effectiveness of the priority system.
    %We assign different priority classes to users based on their sensitivity regarding freshness. We formulate this task offloading problem with priority as an M/G/1 system with multi-class priority, derive its precise PAoI expression, and solve it efficiently in a distributed manner.
    \item %For the communication iteration problem of algorithms over unreliable channels, we propose a distributed asynchronous algorithm that iterates with limited information at each iteration. We establish the guarantees for the performance and convergence of the algorithm, and empirically show that its convergence rate is higher than those of the existing synchronous distributed algorithms.
    % We propose a distributed asynchronous algorithm for the communication iteration problem over unreliable channels. 
    % Our algorithm iterates with limited information at each iteration and 
    We establish theoretical guarantees for the proposed algorithms, in terms of performance and convergence. Extensive experiments are carried out and show that our algorithm can significantly improve the performance over the existing methods.
    % \item %To embed task offloading into the multi-server scenario, we propose a resource allocation problem that captures the trade-off between convergence, local offloading, and service migration. We propose a joint task offloading and service migration algorithm. Theoretical analysis and extensive experimental results show that we can solve the problem efficiently.
    % We propose a resource allocation problem that captures the trade-off between convergence, local offloading, and service migration to embed task offloading into the multi-server case. In addition, we propose a joint task offloading and service migration algorithm. Theoretical analysis and extensive experimental results demonstrate the algorithm's efficiency in solving the problem.
\end{itemize}


%The rest of the paper is organized as follows: Section \ref{sec:RelatedWork} demonstrates some similar existing work.Section \ref{sec:system_model} is dedicated to the system model where the required definitions and the relevant model are presented. In Section \ref{sec:PoPeC}, we gradually describe the three scenarios eventually proposing effective algorithms to tackle the PoPeC problem.In Section \ref{sec:Discussion}, we discussed the benefits of the multi-class priority mechanism and proposed an asynchronous parallel algorithm to make the algorithm more communication efficient.Simulation results that corroborate these findings are laid out in Section \ref{sec:simulation} while the paper is concluded in Section \ref{sec:conclusion}.  
The remainder of the paper is organized as follows: Section \ref{sec:RelatedWork} briefly reviews the related work. Section \ref{sec:system_model} introduces the system model, including relevant definitions and models. In Section \ref{sec:PoPeC}, we describe some special cases and propose algorithms to tackle the PoPeC problem. Section \ref{sec:Discussion} proposes an asynchronous parallel algorithm to improve communication efficiency and discusses the benefits of the multi-class priority mechanism. 
Section \ref{sec:simulation} presents the simulation results, followed by a conclusion drawn in Section \ref{sec:conclusion}.





\section{Related Work}\label{sec:RelatedWork}
%freshness
% Numerous task offloading methods have been introduced based on delay in edge computing \cite{zhang2021joint, halder2022dynamic, saleem2020mobility, al2020task, wang2020multi}. In real-time networks, particularly, decreasing delay alone would not be adequate for successful edge computing since the system might not be able to completely ensure users' timely updates and information freshness \cite{kosta2017age,yates2021age}. Some suitable metrics of information freshness are AoI and PAoI, which have been thoroughly examined in recent work \cite{liu2021aion,li2021scheduling,zou2021optimizing,zou2021minimizing,guo2021scheduling,sun2021age,li2021task,bedewy2020optimizing,pan2021minimizing}. We shall address the numerous aspects of task offloading freshness in this study, including unreliable channels and multiple priority users. Unfortunately, the literature in existence does not provide enough viable remedies to this problem \cite{pan2021minimizing,guo2021scheduling,li2021task,zou2021minimizing,sun2021age,abd2022age,li2021age,sun2019closed,bedewy2020optimizing,abd2020reinforcement, hsu2019scheduling,karabulut2018spatial,zeng2015optimized}.

A great number of task offloading methods have been proposed to minimize the response delay in edge computing \cite{zhang2021joint,halder2022dynamic,saleem2020mobility,al2020task, wang2020multi}. However, reducing delay solely may not be sufficient for effective real-time computation offloading as it hardly guarantees the information freshness for users \cite{kosta2017age,yates2021age}. Recently, many freshness-aware methods have been developed based on the metrics of AoI and PAoI \cite{liu2021aion,li2021scheduling,zou2021optimizing,zou2021minimizing,guo2021scheduling,sun2021age,li2021task,bedewy2020optimizing,pan2021minimizing}, which can be divided into the following two aspects.

% This study aims to address various aspects of task offloading freshness including unreliable channels and multiple priority users. Unfortunately, existing literature does not provide adequate solutions to this problem  \cite{pan2021minimizing,guo2021scheduling,li2021task,zou2021minimizing,sun2021age,abd2022age,li2021age,sun2019closed,bedewy2020optimizing,abd2020reinforcement, hsu2019scheduling,karabulut2018spatial,zeng2015optimized}.

%priority
Part of the recent work focus on computation offloading with regard to various user types and needs.  \cite{pan2021minimizing,guo2021scheduling,zou2021minimizing,sun2021age,abd2022age,li2021age,huang2015optimizing,liu2021anti,maatouk2020status,maatouk2019age,kaul2018age,xu2020peak}. Zou \etal~\cite{zou2021minimizing} address the accurate specification of indexing problems in heterogeneous multi-user multi-channel systems by introducing a unique partial-index approach. They also propose SWIM, which employs maximum weights to obtain the allocation strategy of heterogeneous resources. 
Sun \etal~\cite{sun2021age} design an age-aware scheduling strategy for diverse users based on the Lyapunov optimization method and provide upper and lower bounds on the age that can satisfy the throughput constraint. 
Nevertheless, these works overlook the priorities of users, which is crucial for practical prioritized systems \cite{pan2021minimizing,guo2021scheduling,zou2021minimizing,sun2021age,abd2022age,li2021age}. 
Liu \etal~\cite{liu2021anti} improve the performance of message state freshness from a single server queue considering preemptive and priority message scheduling.
Maatouk \etal~\cite{maatouk2019age} propose three scheduling strategies for AoI, a measure of information freshness, and propose optimization schemes such as advanced AoI strategies for preemption, strategies for service preemption, and strategies for information update.
Xu \etal~\cite{xu2020peak} investigated the system using four different service rules with different priorities and determined the exact PAoI values or upper bounds for various users. By conducting theoretical analysis, they identified the optimal service rule. 
 However, most of these studies lack analysis of heterogeneous users and focus on the case of a single edge server, which cannot meet the individual heterogeneous computing needs \cite{huang2015optimizing,liu2021anti,maatouk2020status,maatouk2019age,kaul2018age,xu2020peak}. 
% Furthermore, previous studies mostly focus on the case of a single edge server and rely heavily on the assumptions of exponential service time.
% To address the issue that indexing cannot be accurately specified in heterogeneous multi-channel systems, Zou \etal introduced a unique partial-index approach. They also designed SWIM with the idea of maximum weight to obtain the allocation strategy of heterogeneous resources \cite{zou2021minimizing}.
% Sun \etal designed an age-aware scheduling strategy based on the Lyapunov method, and give the upper and lower bounds that age can satisfy when the throughput constraint is satisfied\cite{sun2021age}.
% %priority
% However, none of these studies took into account the user's priority, which is crucial for real-time and priority systems and thus has received more attention to \cite{huang2015optimizing,liu2021anti,maatouk2020status,maatouk2019age,kaul2018age,xu2020peak}.
% Liu \etal considered the disadvantages of age and reveals that among various aspects 
% in the system with priorities under different service rules without heterogeneity \cite{liu2021anti}.
% Maatouk \etal conducted an optimal scheme to minimize AoI  with exponential service times \cite{maatouk2019age}.
% Additionally, the majority of earlier research ignored the possibility of heterogeneous servers and made a strong assumption about exponential service time \cite{maatouk2020status,maatouk2019age,kaul2018age}.

%channel
Existing works also provide several comprehensive descriptions of various channel features.
The majority of earlier analyses have assumed a homogeneous channel or the unloading of two separate channels in the broadcast network with random arrival \cite{sun2019closed,pan2021minimizing,bedewy2020optimizing}. 
%single,double,homo.
This assumption only offers a few expansions to the case of a single channel, hence it was not the best choice for heterogeneous channels, in practice.
%reliable 
In addition, Adb \etal~\cite{abd2020reinforcement} and Hse \etal~\cite{hsu2019scheduling} investigate real-time monitoring systems in reliable multiple  channels.
The aforementioned suggest methods did not work for systems with unstable channel circumstances, which were formerly brought on by antenna beamforming, position-dependent fading, and frequency selectivity \cite{karabulut2018spatial,zeng2015optimized}.
%on-off
To replace the setting of the unreliable channel, Pan \etal~\cite{pan2021minimizing} and Sombabu \etal~\cite{sombabu2020age} propose the ON/OFF strategy in the system. This technique made the harsh assumption that the channels were trustworthy and that the conditions of the channel had been understood prior to the decision being made.
%iteration
More notably, many similar studies believe that the distributed method would make the procedure less time-consuming, whereas they all disregard the synchronous parallel iterative algorithm's substantial communication cost on the unreliable channel \cite{sun2021age,zou2021minimizing,guo2021scheduling}.
%difference
This paper differs 
from \cite{sun2019closed,pan2021minimizing,bedewy2020optimizing} in that we focus on multiple heterogeneous channels system, 
from \cite{abd2020reinforcement, hsu2019scheduling} in that we consider the channel is unreliable, 
from \cite{pan2021minimizing,sombabu2020age} in that we address the scheduling decision when the channel states were unknown,
and from \cite{sun2021age,zou2021minimizing,guo2021scheduling} in that we analyze how the synchronous parallel algorithm's significant iteration overhead in the unreliable channel might be resolved and offer an asynchronous parallel algorithm as a possible alternative.



% \subsubsection{Unreliable Channel}
% Most studies that deal with the issue of data availability assume that a single channel is used to transmit information. However, this assumption is not ideal for multiple sources as it only provides a few extensions to the case of a single channel. A recent study conducted on a homogeneous channel model shows that the user-channel pairs have equal ON/OFF probability.
% Unfortunately, the solutions presented in these studies are not applicable to systems that have heterogeneous channel conditions, such as multiple priority sources and the heterogeneous channels. These factors are mainly caused by the frequency selectivity, location-dependent fading, and antenna beamforming.
% The convergence and utility performance of the current work are not optimal
% In this paper, we propose a new scheduling strategy for heterogeneous and unreliable multi-channel systems, and obtain the optimal solution by transforming the problem into a convex problem through a series of mathematical variations.
% \subsubsection{User with Priority}
% In order to minimize the impact of these factors on the availability of information, a concept known as lexicographic age optimality was introduced in 2012. It states that scheduling multiple flows with varying priority levels should be performed according to the optimal policies. This method can reduce the AoI of the high priority flows while preserving the minimum AoI of the low-priority ones.
% \subsubsection{Task Migration}



% See table \ref{table:comparison}.

% \begin{table*}[ht]
% 	\caption{Comparison with related works.}
% 	\label{table:comparison}
% 	\vspace{-0.5em}
% 	\centering
% 	\renewcommand\arraystretch{0.75}
% 	\resizebox{\textwidth}{!}{
% 		\begin{tabular}{c:ccccccc}
% 		\hline
% 		\textbf{Paper} & 
% 		\multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Heterogeneous\\ Users\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Heterogeneous\\ Channels\end{tabular}}}& 
% 		\multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Heterogeneous\\ servers\end{tabular}}}&
% 		\multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Prioritized\\ Streams\end{tabular}}}& 
% 		\multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Asynchronous\\ Algorithm\end{tabular}}}& \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Distributed\\ Algorithm\end{tabular}}} \\ 
% 		\hline
% 		%channel
%         {\cite{sun2019closed}}& {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{pan2021minimizing}}& \CheckmarkBold & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{bedewy2020optimizing}}& {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{abd2020reinforcement}}& {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{hsu2019scheduling}}& {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{karabulut2018spatial}}& {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{zeng2015optimized}}& {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{sombabu2020age}}& {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         %user
%         {\cite{guo2021scheduling}}& \CheckmarkBold & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & \CheckmarkBold\\
%         {\cite{zou2021minimizing}}& \CheckmarkBold & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & \CheckmarkBold\\
%         {\cite{sun2021age}}& \CheckmarkBold & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & \CheckmarkBold\\
%         {\cite{abd2022age}}& \CheckmarkBold & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{li2021age}}& \CheckmarkBold & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         %priority
%         {\cite{huang2015optimizing}}& {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{liu2021anti}}& {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{maatouk2020status}}& {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{maatouk2019age}}& {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{kaul2018age}}& {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\
%         {\cite{xu2020peak}}& {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush} & \CheckmarkBold & {\color{gray}\XSolidBrush} & {\color{gray}\XSolidBrush}\\

% 		\rowcolor[HTML]{96FFFB} 
% 		{This paper}& \CheckmarkBold & \CheckmarkBold & \CheckmarkBold & \CheckmarkBold & \CheckmarkBold & \CheckmarkBold\\ 
% 		\hline
% 	\end{tabular}
% 	}
% % 	\vspace{-1.0em}
% \end{table*}





%system model
\section{System Model}\label{sec:system_model}
% In this section, our focus is on the Mobile Edge Computing (MEC) architecture for task scheduling in edge scenarios, encompassing task offloading and transmission models, as well as addressing the common limitations arising from resource constraints.  To supplement the limitations of the MEC architecture in practical situations, we present the capacity model with confidence evaluation.  We also delve into the information freshness model and problem formulation.

In this section, we focus on the Mobile Edge Computing (MEC) architecture, including task offloading, transmission models, capacity models, and confidence evaluation. Based on this, we present the information freshness model and problem formulation.

% In this section, we focus on the MEC architecture for task scheduling in edge scenarios, such as task offloading and transmission models, as well as certain common limitations.
% Due to resource constraints, we additionally present the capacity model with confidence evaluation to supplement the limitations of the MEC architecture in actual circumstances.
% Furthermore, we focus on the information freshness model and problem formulation.
\begin{figure}[ht!]
    \vspace{-0cm} 
    \setlength{\abovecaptionskip}{-0cm} 
    \setlength{\belowcaptionskip}{-0cm} 
    \centering
	\includegraphics[width=0.5\textwidth]{./figure/system-model.pdf}
    \vspace{-0pt}
	\caption{System Model}
	\label{fig:system-model}
    % \vspace{-18pt}
\end{figure}
\subsection{MEC Architecture}
As shown in Fig.\ref{fig:system-model}, we consider a wireless network system consisting of a set of $M$ mobile edge servers (denoted by $\mathcal{M}$). Each server $m\in\mathcal{M}$ can serve a set of $N_m$ users ($\mathcal{N}_m$). Each user $n\in\mathcal{N}$ can offload their tasks to its corresponding server $m_n$ via a limited number of wireless channels (denoted by $\mathcal{C} \doteq \{1,\dots, C\}$). Considering the effects of frequency-selective fading \cite{zou2021minimizing}, we define $p_{n,c}$ as the probability of a successful transmission from user $n$ through channel $c$ to server $m_n$. In this context, users have varying offloading priorities, which we represent as $\Delta\doteq\{1,2,\dots, \delta_\mathit{max}\}$. 
Let $\mathcal{N}^{\delta}_m$ denote the set of users served by server $m$ with priority $\delta\in\Delta$. It satisfies $\bigcup_{m\in\mathcal{M}}\bigcup_{\delta\in\Delta} \mathcal{N}^{\delta}_m = \bigcup_{m\in\mathcal{M}} \mathcal{N}_m = \mathcal{N}$. In addition, we represent $\mathcal{N}^{\delta} \doteq \bigcup_{m\in\mathcal{M}} \mathcal{N}^{\delta}_m$ as the set of users with priority $\delta$ across all servers. To simplify notation, we denote the priority of user $n$ as $\delta(n)$ and the set of users with a same or higher priority as $\Delta(\delta(n))$.

% \sout{That is, users will offload tasks to a local server first.}  
% \comment{what's the meaning?} 
% \answer{We want to emphasize that task offloading occurs first from the user to its local server and has been merged with the previous sentence.}
% \sout{Also, the local server for user $n$ is denoted by $m(n)$.} 
% \comment{place this to where $m(n)$ is used}
% \answer{We've done that.}
%In addition, we assume that the probability of user $n$ successfully reaching the destination in order through channel $c$ is $p_{n,c}$, independent of all other transmissions, due to channel instability with frequency selective fading resulting in  packet errors \cite{zou2021minimizing}.

%Denote the set of priorities as $\Delta\doteq\{1,2,\dots, \delta_\mathit{max} \}$ and the set of users with priority $\delta\in\Delta$ as $\mathcal{N}^{\delta}$ which satisfies $\bigcup^{}_{\delta\in\Delta} \mathcal{N}^{\delta} = \mathcal{N}$. With slight abuse of notation, we denote $\delta(n)$ as the priority of user $n$  and $\Delta(\delta(n))$ as the set of users with the same or higher priority than that of $n$.

%$(\delta(n)-1)$ represents the priority level with priority $\delta(n)$ one level higher.

%Furthermore, with multi-class priorities mentioned, we specify some additional variables. For simplicity, 
% Meanwhile,  and we have .For convenience, we denote $N = |\mathcal{N}|$, $N_m = |\mathcal{N}_m|$, $N^{\delta} = |\mathcal{N}^{\delta}|$, $C = |\mathcal{C}|$, and $M = |\mathcal{M}|$, with the superscript `u' and `s' distinguishing between user-side and server-side variables, respectively.

\subsubsection{Task Offloading} 

Each user has a set of offloading tasks, which arrive according to a Poisson process with an expected arrival rate of $\lambda_{n}$. We use $\eta^u_{n,c}$ to denote the probability of user $n$ accessing channel $c$ for offloading the tasks, which should satisfy the following constraint:
\begin{equation}
\label{eq:c1}
    0 \le \eta^u_{n,c} \le 1 , \quad \forall n \in \mathcal{N},~c \in \mathcal{C}. 
\end{equation}
It is clear that the number of tasks offloaded by user $n$ through channel $c$ follows a Poisson progress with an expected value of $\eta^u_{n,c}\cdot\lambda_{n}$. Besides, the following constraint must be met:
\begin{equation}
\label{eq:c2}
    \sum_{c\in\mathcal{C}}\eta^u_{n,c} \le 1 , \quad \forall n \in \mathcal{N}.
\end{equation}
The inequality in Eq. \eqref{eq:c2} being true indicates that user $n$ does not offload any tasks.

% The reason why the above inequality holds is that the package loss may occur on the user side due to the violation of the freshness constraints.

%that need to be offloaded to the local edge server, and the arrivals of these tasks from user $n$ at the local server are distributed according to a Poisson process with an expected arrival rate of $\lambda_{n}$.
% Each user offloads a number of computing tasks onto the local edge server when needed.
% We assume that the number of offloading tasks for each user is independent, and their arrivals from user $n$ at the local server are distributed according to a Poisson distribution with an expected value of
% $\lambda_{n}$. 
%denote the offloading decision variable for user $n$ as $\eta^u_{n,c}$, indicating the probability of accessing channel $c$ to offload the tasks and thus satisfying
% In the meanwhile, we consider the probability of tasks requiring offloading to channel $c$, characterized by a local offloading decision variable for users, $\eta^u_{n,c}\in [0,1]$.
%We have the expected value of tasks offloaded from user $n$ via channel $c$, it is $\eta^u_{n,c}\lambda_{n}$.
%According to the preceding, tasks of user $n$ offloaded via $c$ follow a Poisson distribution with an expected value of $\eta^u_{n,c}\lambda_{n}$. 

% \answer{Due to limit of quantity, it is reasonable that $\eta^u_{n,c}$ is bounded, \ie
% } \comment{this constraint doesn't make any sense}

% To improve information age performance, not all tasks generated by the user $n$ need to be offloaded or executed.It is clear that $\lambda_{n} - \sum_{c\in\mathcal{C}}\eta^u_{n,c}\lambda_{n} \ge 0$, which is

% {\color{pink}It is worth mentioning that a low value of $(\lambda_{n} - \sum_{c\in\mathcal{C}}\eta^u_{n,c}\lambda_{n})$ is likewise unacceptable since update frequency is a crucial factor for the information freshness.} \comment{meaning?}
% \answer{We want to explain why it is possible to "drop packets" because update frequency is an important metric in PAoI and can be used as a penalty term}

% \subsubsection{Task Migration} 
% {\color{pink}The number of offloading tasks for each user is assumed to be independent.} \comment{what's meaning?}
Edge servers are connected to each other via a wired network and can collaborate to execute offloaded tasks by assigning a portion of tasks from one server to another. We use $\eta^s_{m, m'}$ to denote the proportion of tasks delivered from server $m$ to server $m'$, and we have 
\begin{equation}
\label{eq:c3a}
    0 \leq \eta^s_{m,m'} \leq 1, \quad \forall m, m' \in \mathcal{M}. 
\end{equation}
It is easy to see the following constraint should also be met:
\begin{equation}
\label{eq:c5a}
     \sum_{m' \in \mathcal{M}} \eta^s_{m,m'} = 1 , \quad \forall m \in \mathcal{M}.
\end{equation}
Accordingly, the number of computational tasks with priority $\delta$ delivered from server $m$ to $m'$ can be expressed as $\eta^s_{m,m'}\cdot \lambda^{s}_{\delta,m}$, where 
\begin{equation}
\label{eq:lambda-s}
\lambda^{s}_{\delta,m}\doteq\sum_{n\in\mathcal{N}^{\delta}_m}\sum_{c\in\mathcal{C}} p_{n,c} \lambda_{n,c}
\end{equation}
denotes the total number of received tasks with priority $\delta$ at server $m$. Since the total number of tasks arrived at each server cannot exceed its maximum capacity (denoted by $\lambda^{s,\mathit{max}}_m$), we have
\begin{equation}
\label{eq:c4a}
    \sum_{\delta \in \Delta}\sum_{m' \in \mathcal{M}} \eta^s_{m',m} \lambda^{s}_{\delta,m'} \leq \lambda^{s,\mathit{max}}_m, \quad \forall m \in \mathcal{M}. 
\end{equation}
%Thus, from $m$ to $m'$, the number of delivered tasks with $\delta$-th priority is $\eta^s_{m,m'} \lambda^{s}_{\delta,m}$, where $\lambda^{s}_{\delta,m}=\sum_{n\in\mathcal{N}^{\delta}_m}\sum_{c\in\mathcal{C}} p_{n,c} \lambda_{n,c}$ denote the total number of received tasks with $\delta$-th priority at server $m$.
% For server collaboration, scheduling tasks with priority level $\delta$ from server $m$ to $m'$ is represented by  $\eta^s_{m,m'} \lambda^{s}_{\delta,m}$. 

\subsubsection{Transmission Model}
% \subsubsection{Communication between user and server}

We assume that the channel contention and waiting time follow the M/M/1 queuing model, as in \cite{ren2022efficient}.\footnote{The contention and queuing process for multiple tasks  for each channel can be modeled as an M/M/1 process, where task arrivals to a certain channel follow a Poisson process, and the channel transmission time (service time) for each task follows an exponential distribution.} The arrival rate of channel $c$ is denoted as $\lambda_c$, which is calculated as the sum of the offloading arrival rates of all users accessing channel $c$, i.e.,  $\lambda_c=\sum_{n\in\mathcal{N}}\eta^u_{n,c}\lambda_{n}$. 
% is the rate at which tasks are offloaded through channel $c$.
The service rate of channel $c$ is $r_c/S$, where $r_c$ and $S$ represent the communication rate and the size of each package transmitted through channel $c$, respectively. As the wireless communication rate approaches the Shannon limit \cite{ghanem2020resource,zhang2022distributed}, the achievable rate can be expressed as $r_c = B_c \log \bigl(R_c + 1 \bigr)$, where $B_c$ and $R_c$ are the bandwidth and the signal-to-noise ratio of channel $c$, respectively. Thus, if user $n$ accesses channel $c$, the induced transmission time is
	\begin{equation}  
	\label{eq:TransmissionDelay-Channel}
		T^\mathit{tr}_{n,c} = \left\{
		\begin{array}{ll}
		 \frac{1}{r_c/S - \lambda_c} + t_{n,c}, &\quad \frac{r_c}{S} - \lambda_c > 0,\\
		 \infty , &\quad \mathit{otherwise},
		\end{array}
		\right.	
	\end{equation}
where $\frac{1}{r_c/S - \lambda_c}$ is the channel contention time, and $t_{n,c}$ is the transmission delay of the offloading tasks \cite{lin2020distributed}. As in \cite{mao2017survey}, since MEC servers are linked via wired core networks, we assume that the transmission delay between servers $m$ and $m'$ is a constant, denoted by $t^\mathit{tr}_{m, m'}$.
% from user $n$ via channel $c$ to local server.	
 
% \subsubsection{Communication between servers}


\subsection{Limited Capacity Model with Confidence Evaluation\label{subsec:capacity_model}}
\subsubsection{Channel Capacity}
% The effective re-consumption of the channel by competing activities often results in a decrease in the freshness of the information in many applications with high real-time needs. We provide channel confidence to lessen the possible issue of excessive task inflow and to distribute tasks more equally across many heterogeneous channels since the in-channel arrival tasks follow a Poisson distribution. 

Due to the limited channel capacity, the total number of tasks transmitted through a channel cannot exceed its maximum capacity ($M_c^\mathit{max}$). Based on the properties of the cumulative distribution function of the Poisson distribution \cite{patil2012comparison}, we use the following constraint to ensure that each channel is conflict-free with confidence level $1-\alpha$  \cite{zhou2018channel,guo2021scheduling}:
\begin{equation}
    \frac{z^2_1}{2} +  z_2\cdot\left(\sum_{n\in\mathcal{N}} \eta^u_{n,c}\lambda_{n} + \frac{z^2_2}{4}\right)^\frac{1}{2} + \sum_{n\in\mathcal{N}} \eta^u_{n,c}\lambda_{n}  \le M_c^\mathit{max},
    % , \quad \forall c. 
    \label{eq:c7a}
\end{equation}
where $z_1$ and $z_2$ are two statistics standardized from a normal distribution, satisfying 
% $P\{\alpha < z_1\} = 1 - \Phi ((2\alpha - \lambda^{\mathit{chl}}_c)/\sqrt{\lambda^{\mathit{chl}}_c})$
$z_1 = (\alpha/2 - \lambda^{\mathit{chl}}_c)/\sqrt{\lambda^{\mathit{chl}}_c}$
and 
$z_2 = (1-\alpha/2 - \lambda^{\mathit{chl}}_c)/\sqrt{\lambda^{\mathit{chl}}_c}$,
respectively. 
Here, $\lambda^{\mathit{chl}}_c \doteq \sum_{n\in\mathcal{N}} \eta^u_{n,c}\lambda_{n}$ represents the total number of tasks transmitted through channel $c$. 
% \comment{Revise notations}

% where $\alpha_1 = \alpha/2$, $\alpha_2 = 1 - \alpha/2$, and $z(\alpha)$ is a statistic standardized from a normal distribution, satisfying $P\{\alpha < z(\alpha)\} = 1 - \Phi ((\alpha - \lambda^{\mathit{chl}}_c)/\sqrt{\lambda^{\mathit{chl}}_c})$ with $\lambda^{\mathit{chl}}_c = \sum_{n\in\mathcal{N}} \eta^u_{n,c}\lambda_{n}$.

% $z(\alpha) = (\alpha - \lambda^{\mathit{chl}}_c)/\sqrt{\lambda^{\mathit{chl}}_c}$ with $\lambda^{\mathit{chl}}_c = \sum_{n\in\mathcal{N}} \eta^u_{n,c}\lambda_{n}$
%Since the number of offloading tasks varies over time according to a Poisson distribution, number of tasks transmitted over channel $c$ cannot exceed its maximum capacity (denoted by $M_c^\mathit{max}$), we have $\sum_{n\in\mathcal{N}} \eta^u_{n,c} \leq M_c^\mathit{max}$. 
%However, this value is not constant over time due to the Poisson distribution governing the number of packets transmitted over the channel. 
%this value varies over time since the number of packets offloaded to the channel follows a Poisson distribution. Thus, to ensure that at each slot $t$, the maximum channel capacity is not less than the current number of tasks, we need to have $\sum_{n\in\mathcal{N}} \eta^u_{n,c} \leq M_c^\mathit{max}$.
% {\color{pink}this value varies over time since the number of packets offloaded to the channel follows a Poisson distribution. Thus, to ensure that at each slot $t$, the maximum channel capacity is not less than the current number of tasks, we need to have $\sum_{n\in\mathcal{N}} \eta^u_{n,c} \leq M_c^\mathit{max}$.} \comment{meaning?}
% There is no doubt that the number of tasks arriving in channel c is no more than the maximum capacity $M^c {max}$ of the channel $c$, \ie $\sum_{n\in\mathcal{N}} \eta^u_{n,c} \leq M_c^\mathit{max}$.
% However, it is a value that fluctuates over time, since the number of packets  offloaded to the channel obeys a Poisson distribution.
% Therefore, in order to guarantee that, at each slot $t$, there is a maximum capacity of the channel that is not smaller than the current moment, \ie $\sum_{n\in\mathcal{N}} \eta^u_{n,c} \leq M_c^\mathit{max}$.
%According to the properties of the cumulative distribution function of the Poisson distribution \cite{patil2012comparison}, the channel is almost conflict-free with confidence level $1-\alpha$ if it satisfies
% The above implies that the channel is practically conflict-free with $(1-\alpha)$ probability when the task correlation function inside the arrival channel is not more than $M_c^\mathit{max}$.

\begin{figure*}[t]
\begin{align}
% \begin{split}
    \mathbb{E}[W_{n}] =\,& \frac{\frac{1}{2}\sum_{\delta\in\Delta}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\eta^u_{n',c}\lambda_{n'}\nu_{n'}}{\left(1-\sum_{\delta\in\Delta(\delta(n))}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\frac{\eta^u_{n',c}\lambda_{n'}}{\mu_{n'}}\right)\left(1-\sum_{\delta\in\Delta(\delta(n)-1)}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\frac{\lambda_{n',c}}{\mu_{n'}}\right)}\label{eq:paoi-priority-waitingtime-expectation}\\\nonumber\\
    \pi_{n,m}(\bm\eta^s) \doteq\,& \frac{\sum_{\delta\in\Delta} \eta^s_{m_n,m} \lambda^{s}_{\delta,m_n}}{\sum_{\delta\in\Delta} \sum_{m'\in\mathcal{M}} \eta^s_{m_n,m'} \lambda^{s}_{\delta,m_n}} \cdot
    \left(
    t^\mathit{tr}_{m_n,m} + \frac{1}{\mu_{n,m}}+\frac{1}{1-\sum_{\delta\in{\Delta(\delta(n))}}\sum_{m'\in\mathcal{M}} \eta^s_{m',m} \lambda^{s}_{\delta,m'} \frac{1}{\mu_{n,m}}}\right.\nonumber\\
    &\left.\cdot\frac{\frac{1}{2}\sum_{\delta\in\Delta} \sum_{m'\in\mathcal{M}} \eta^s_{m',m} \lambda^{s}_{\delta,m'} \nu_{n,m} }{1-\sum_{\delta\in{\Delta(\delta(n)-1)}}\sum_{m'\in\mathcal{M}} \eta^s_{m',m} \lambda^{s}_{\delta,m'} \frac{1}{\mu_{n,m}}}\right)
% \end{split}
\label{eq:multi-server-DataMigration}
\end{align}
\noindent\makebox[\linewidth]{\rule{\textwidth}{0.5pt}}
\end{figure*}

\subsubsection{Computation Capacity} 
% Considering the dynamic changes in the computing power of each server \comment{polish it},
Due to the fluctuation in servers' computing capacity, we assume that server $m$'s processing time for user $n$'s tasks follows a general distribution with mean $1/\mu_{n,m}$ and second moment $\nu_{n,m}$ \cite{huang2015optimizing}. To simplify notations, we use $1/\mu_n$ and $\nu_n$ to represent $1/\mu_{n,m_n}$ and $\nu_{n,m_n}$, respectively.
% We let $\frac{1}{\mu_n}$ and $\nu_n$ represent the mean and second moment of the general distribution of tasks performed on the local server, respectively. \comment{?}
% we assume that each task offloaded by user $n$ is executed according to an unknown distribution with mean $\frac{1}{\mu_n}$ and second moment $\nu_n$. 
We impose the following constraint to ensure that each task can be executed with a confidence level of $1 - \beta$:
%Analogous to channel capacity, we provide the following constraint to guarantee that the task can be executed with a confidence level of $(1 - \beta)$:
% Without loss of generality, we assume that the processing time of each update packet from entity $n$ obeys general distribution with mean $\frac{1}{\mu_n}$ and second moment $\nu_n$.
% Similarly, we have constraints in order to ensure that the task can be completed with a confidence level of $(1 - \beta)$.
\begin{equation}
    \label{eq:c8a}
\begin{split}
     \frac{z^2_{3}}{2} &+ z_{4}\cdot\left(\sum_{n\in\mathcal{N}} \sum_{c\in\mathcal{C}} p_{n,c}\cdot \frac{\eta^u_{n,c}\lambda_{n}}{\mu_n} +\frac{ z^2_{4}}{4}\right)^\frac{1}{2} \\    &+\sum_{n\in\mathcal{N}} \sum_{c\in\mathcal{C}} p_{n,c}\cdot \frac{\eta^u_{n,c}\lambda_{n}}{\mu_n}  <1,
\end{split}
\end{equation}
\noindent where $z_3$ and $z_4$ are two statistics standardized from a normal distribution, satisfying $z_3 = (\beta/2 - \lambda^{\mathit{comp}}_c)/\sqrt{\lambda^{\mathit{comp}}_c}$
and 
$z_4 = (1-\beta/2 - \lambda^{\mathit{comp}}_c)/\sqrt{\lambda^{\mathit{comp}}_c}$,
respectively. Here, $\lambda^{\mathit{comp}} = \sum_{n\in\mathcal{N}} \sum_{c\in\mathcal{C}} p_{n,c}\cdot \eta^u_{n,c}\lambda_{n}/\mu_n$ represents the total number of reliable tasks that actually arrive at the server $m(n)$. 

% where $\beta_1 = \beta/2$, $\beta_2 = 1 - \beta/2$,
% $\lambda^{\mathit{comp}} = \sum_{n\in\mathcal{N}} \sum_{c\in\mathcal{C}} p_{n,c}\cdot \eta^u_{n,c}\lambda_{n}/\mu_n$
% and $P\{\beta < z(\beta)\} = 1 - \Phi ((\beta - \lambda^{\mathit{comp}})/\sqrt{\lambda^{\mathit{comp}}})$. \comment{Revise according to the above}





% \begin{figure*}[t]
%     \begin{align}
%     \label{eq:paoi-priority-waitingtime-expectation}
%     \mathbb{E}[W^{p}_{n}] = \frac{\frac{1}{2}\sum_{\delta\in\Delta}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\eta^u_{n',c}\lambda_{n'}\nu_{n'}}{\left(1-\sum_{\delta\in\Delta(\delta(n))}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\frac{\eta^u_{n',c}\lambda_{n'}}{\mu_{n'}}\right)\left(1-\sum_{\delta\in\Delta(\delta(n)-1)}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\frac{\lambda_{n',c}}{\mu_{n'}}\right)}
%     \end{align}
% % \noindent\makebox[\linewidth]{\rule{\textwidth}{0.5pt}}
% \end{figure*}


\subsection{Freshness Model and Problem Formulation}
We characterize the information freshness using the PAoI metric. The PAoI of user $n$'s message, denoted by $A_{n}$, is determined by four key factors: transmission time $T_{n}$, arrival interval $I_{n}$, waiting time $W_{n}$, and processing time $Y_{n}$ \cite{zou2021minimizing}, \ie, 
\begin{align}
    \label{eq:paoi-expectation2}
    \mathbb{E}[A_{n}] &= \mathbb{E}[T_{n}]+\mathbb{E}[I_{n}]+\mathbb{E}[W_{n}]+\mathbb{E}[Y_{n}].
\end{align}
% $\mathbb{E}[T_{n}] = T^\mathit{tr}_{n,c}$ \comment{revise}
% It is straightforward to figure out that 
It is evident that
$\mathbb{E}[T_{n}] = \sum_{c\in\mathcal{C}} \eta^u_{n,c} T^\mathit{tr}_{n,c}$ 
and $\mathbb{E}[I_{n}] = 1/\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}$. 
However, the expressions of $\mathbb{E}[W_{n}]$ and $\mathbb{E}[Y_{n}]$ depend on the way in which user $n$'s tasks are executed. To establish their precise expressions, we first use binary variable $y_{m}$ to denote the migration decision of server $m$, i.e., 
\begin{equation}
\label{eq:c-y}
    y_m \in \{0,1\}, \quad \forall m \in \mathcal{M}.
\end{equation}
%local offloading 
If $y_m$ comes to 0, server $m$ will execute its tasks locally; 
otherwise, server $m$ will resort to the other servers for collaboration. When $y_{m_n}$ is equal to 0, it is evident that $\mathbb{E}[Y^{p}_{n}]=1/\mu_n$. Due to the M/G/1 queuing model, the expectation of waiting time $\mathbb{E}[W_{n}]$ can be expressed as \eqref{eq:paoi-priority-waitingtime-expectation} (please see Appendix \ref{app:pro:paoi_mg1_pri} of technical report \cite{Nan2023} for more details). When $y_{m_n}$ comes to 1, some tasks from user $n$ will be migrated from server $m_n$ to other servers. According to Little's Law\footnote{Little's law in queuing theory states that the average number of customers in a stationary system equals the product of arrival rate and waiting time \cite{kim2013statistical}.}, we can derive:
\begin{equation}
    \mathbb{E}[W^s_{n}]+\mathbb{E}[Y^s_{n}]=\sum_{m\in\mathcal{M}} \pi_{n,m}(\bm\eta^s),
\end{equation}
where $\bm\eta^s\doteq\{\eta^s_{m, m'}\}_{m, m'\in \mathcal{M}}$ and $\pi_{n,m}(\bm\eta^s)$ is defined in \eqref{eq:multi-server-DataMigration}. Based on this, the expected PAoI of user $n$ can be specified as follows:
\begin{align}
\label{eq:pomis}
    \mathbb{E}[A_{n}]
    =  (1 - y_{m_n})\cdot\mathbb{E}[A_{n}|y_{m_n}=0] + y_{m_n}\cdot\mathbb{E}[A_{n}|y_{m_n}=1]
    % = & (1 - y_{m_n})\mathbb{E}[A^p_{n}] + y_{m_n}\mathbb{E}[A^s_{n}].
\end{align}
% Next, we establish the precise expression for $\mathbb{E}[A_{n}]$.
% where 
% $\mathbb{E}[T_{n}]$, $\mathbb{E}[I_{n}]$, $\mathbb{E}[W_{n}]$ and $\mathbb{E}[Y_{n}]$ are the expected transmission time, arrival interval, waiting time and processing time (on servers) of user $n$'s tasks, respectively.

% being the expected transmission time of user $n$'s tasks,
% the maximum transmission time over all possible channels, 
% $\mathbb{E}[I_{n}]$ the arrival interval of the tasks of user $n$ to the local server \comment{To the local server?},
% $\mathbb{E}[W_{n}]$ the expected waiting time of user $n$'s tasks,
% and $\mathbb{E}[Y_{n}]$ the expected processing time of user $n$'s tasks on servers.
% with $\mathbb{E}[Y_{n}]=1/\mu_n$ being the processing time \comment{what processing time?}, $\mathbb{E}[T_{n}]=T^\mathit{tr}_{n,c}$  the maximum transmission time over all possible channels, $\mathbb{E}[I_{n}] = 1/\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}$ the arrival interval \comment{arrival interval?}, and $\mathbb{E}[W_{n}]$ the waiting time.


% . Packet arrival rate for successful passage over unreliable channels is $\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}$. The arrival interval is $\mathbb{E}[I_{n}] = \frac{1}{\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}}$.
% The formula and value of the waiting time $\mathbb{E}[W_{n}]$ heavily depend on the service rules of the system.

% Since executing all offloaded tasks on one server could outweigh its capability, servers can migrate the offloading tasks to other servers for assistance. 

% edge servers with high loads, adopting a multi-server collaboration approach makes sense, which involves idle servers providing assistance to heavily loaded servers. In particular, the server $m$ needs to choose whether to join this approach or not, with this decision being represented by the variable $y_{m}$.
% $\bm y = \{y_{m}\}$.
% The constraints for this variable are subject to
    
% in Proposition \ref{pro:paoi_mg1_pri}.
% \begin{proposition}
% \label{pro:paoi_mg1_pri}
%     Based on the \eqref{eq:paoi-expectation2}, the expectation of PAoI for user $n$, with multi-class priority, who offloads its tasks to a local server, can be expressed as
%     \begin{align}
% 	    \label{eq:paoi-localoffloading-expectation}
%         \mathbb{E}[A^p_{n}] & =\mathbb{E}[T^p_{n}]+\mathbb{E}[I^p_{n}]+\mathbb{E}[W^p_{n}]+\mathbb{E}[Y^p_{n}],
%     \end{align}
%     where $[T^{p}_{n}]=T^\mathit{tr}_{n,c}$, $\mathbb{E}[I^{p}_{n}] = 1/\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}$, and $\mathbb{E}[Y^{p}_{n}]=1/\mu_n$ have been investigated by the previous work \cite{yates2021age}.
%     % We derive the user $n$'s PAoI expectation $\mathbb{E}[A^p_{n}]$ in multi-class priority user local offloading scenario, which is
%     % \begin{align}
%     % \label{eq:paoi-localoffloading-expectation}
%     %         \mathbb{E}[A^p_{n}] 
%     %         & = T^\mathit{tr}_{n,c} + \frac{1}{\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}} + \mathbb{E}[W^p_{n}]
% 	   %      + \frac{1}{\mu_n}.
%     %     \end{align}
%     % The waiting time is an essential component of PAoI.
%     Furthermore, the waiting time $\mathbb{E}[W^{p}_{n}]$ based on an M/G/1 queue with multi-class priority holds \eqref{eq:paoi-priority-waitingtime-expectation}, following formula derivations in Appendix \ref{app:pro:paoi_mg1_pri}.
% \begin{figure*}[!t]
%     \begin{align}
%     \label{eq:paoi-priority-waitingtime-expectation}
%     \mathbb{E}[W^{p}_{n}] = \frac{\frac{1}{2}\sum_{\delta\in\Delta}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\eta^u_{n',c}\lambda_{n'}\nu_{n'}}
% 	    {(1-\sum_{\delta\in\Delta(\delta(n))}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\frac{\eta^u_{n',c}\lambda_{n'}}{\mu_{n'}})
% 	    (1-\sum_{\delta\in\Delta(\delta(n)-1)}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\frac{\lambda_{n',c}}{\mu_{n'}})}.
%     \end{align}
% \noindent\makebox[\linewidth]{\rule{\textwidth}{0.5pt}}
% \end{figure*}
% \end{proposition}
% \begin{proof}
%     See Appendix \ref{app:pro:paoi_mg1_pri}.
% \end{proof}
% The user $n$'s PAoI expectation $\mathbb{E}[A^s_{n}]$ in local offloading scenario satisfies
%server collaboration

% Proposition \ref{pro:paoi_mg1_pri} gives the PAoI expectation in a scenario where multiple users offload to the same server.

% However, considering that only local offloading will cause a significant load on some edge servers, we attempted to expand to a multi-server collaboration scenario.
% Therefore, the local server $m$ of user $n$ attempts to choose whether to join the mechanism of multi-server collaboration or not. The join decision variable is given by $\bm y = \{y_{m(n)}\}$ with constraints
% \begin{equation}
% \label{eq:c-y}
%     y_{m(n)} \in \{0,1\}, \quad \forall n \in \mathcal{N},
% \end{equation}
% where $m(n)$ denotes the local server for user $n$.

% When $y_{m_n}=0$, based on the M/G/1 queue, the expectation of waiting time $\mathbb{E}[W^{p}_{n}]$ can be expressed as Eq. \eqref{eq:paoi-priority-waitingtime-expectation} (please see Appendix \ref{app:pro:paoi_mg1_pri} for more details). 
% Combining \eqref{eq:paoi-priority-waitingtime-expectation} with the conclusion of previous work \cite{yates2021age}, 
% we get each user's PAoI expectation 
%     \begin{align}
% 	    \label{eq:paoi-localoffloading-expectation}
%         \mathbb{E}[A^p_{n}] & =\mathbb{E}[T^p_{n}]+\mathbb{E}[I^p_{n}]+\mathbb{E}[W^p_{n}]+\mathbb{E}[Y^p_{n}],
%     \end{align}
% where $\mathbb{E}[T^{p}_{n}]=\mathbb{E}[T_{n}]$, $\mathbb{E}[I^{p}_{n}] = \mathbb{E}[I_{n}]$, and $\mathbb{E}[Y^{p}_{n}]=1/\mu_n$.

% When $y_{m_n}$ comes to 1, some tasks from user $n$ will be migrated from local servers to other free servers and may not be executed on the local server $m_n$.
% As a result, the waiting and service time are reduced, which would therefore have an impact on the freshness.
% According to Little's Law \footnote{Little's law in queueing theory states that the average number of customers in a stationary system equals the product of arrival rate and waiting time \cite{kim2013statistical}.} and average service time, we have
% \begin{equation}
%     \mathbb{E}[W^s_{n}]+\mathbb{E}[Y^s_{n}]=\sum_{m\in\mathcal{M}} \pi_{n,m}(\bm\eta^s),
% \end{equation}
% where $\pi_{n,m}(\bm\eta^s)$ holds \eqref{eq:multi-server-DataMigration} with server collaboration decision variables $\bm\eta^s:=\{\eta^s_{m, m'}\}_{m, m'\in \mathcal{M}}$.
% The user $n$'s PAoI expectation $\mathbb{E}[A^s_{n}]$ in server collaboration scenario holds
% \begin{equation}
% \begin{split}
%     \mathbb{E}[A^s_{n}] = \mathbb{E}[T^s_{n}]+\mathbb{E}[I^s_{n}]
%     +\mathbb{E}[W^s_{n}]+\mathbb{E}[Y^s_{n}].
%     % +  \sum_{m\in\mathcal{M}} \pi_{n,m}(\bm\eta^s),
% \end{split}
% \end{equation}
% where $\mathbb{E}[T^{s}_{n}]=\mathbb{E}[T_{n}]$ and $\mathbb{E}[I^{s}_{n}] = \mathbb{E}[I_{n}]$.


% \begin{figure*}[!h]
% \begin{align}
% % \begin{split}
%     \pi_{n,m}(\bm\eta^s) &= \frac{\sum_{\delta\in\Delta} \eta^s_{m(n),m} \lambda^{s}_{\delta,m(n)}}{\sum_{\delta\in\Delta} \sum_{m'\in\mathcal{M}} \eta^s_{m(n),m'} \lambda^{s}_{\delta,m(n)}} 
%     \Big(
%     t^\mathit{tr}_{m(n),m} + \frac{1}{\mu_{n,m}}\nonumber\\
%     &+\frac{\frac{1}{2}\sum_{\delta\in\Delta} \sum_{m'\in\mathcal{M}} \eta^s_{m',m} \lambda^{s}_{\delta,m'} \nu_{n,m} }{(1-\sum_{\delta\in{\Delta(\delta(n))}}\sum_{m'\in\mathcal{M}} \eta^s_{m',m} \lambda^{s}_{\delta,m'} \frac{1}{\mu_{n,m}})(1-\sum_{\delta\in{\Delta(\delta(n)-1)}}\sum_{m'\in\mathcal{M}} \eta^s_{m',m} \lambda^{s}_{\delta,m'} \frac{1}{\mu_{n,m}})}
%     \Big).
% % \end{split}
% \label{eq:multi-server-DataMigration}
% \end{align}
% \noindent\makebox[\linewidth]{\rule{\textwidth}{0.5pt}}
% \end{figure*}

Given the aforementioned constraints, our objective is to find the optimal offloading decision for users and collaboration decision for servers to minimize the average expected PAoI across all users. Consequently, the problem of \underline{P}AoI-Centric Task \underline{O}ffloading with \underline{P}riority over Unr\underline{e}liable \underline{C}hannels (PoPeC) is described below:
\begin{equation}
\label{eq:P}
\begin{split}
    &\textbf{(PoPeC)}~\mathop{\min}_{\bm\eta^u, \bm\eta^s, \bm y}
    \frac{1}{N}\sum_{n\in\mathcal{N}} \mathbb{E}[A_n] \\
    &\qquad\quad\text{s.t.}~ \eqref{eq:c1}\textrm{--}\eqref{eq:c4a},
    % \eqref{eq:c6},
    \eqref{eq:c7a},\eqref{eq:c8a},\eqref{eq:c-y}
\end{split}
\end{equation}
where $\bm\eta^u\doteq\{\eta^u_{n,c}\}_{n\in \mathcal{N}, c\in \mathcal{C}}$ denotes the offloading decision, and $\bm\eta^s=\{\eta^s_{m, m'}\}_{m, m'\in \mathcal{M}}$ along with $\bm{y}\doteq\{y_m\}_{m\in\mathcal{M}}$ is the collaboration decision.

% \begin{equation}
% \label{eq:P}
% \begin{split}
%     \textbf{(PoPeC)}~&\mathop{\min}_{\bm\eta^u, \bm\eta^s, \bm y}
%     \frac{1}{N}\sum_{n\in\mathcal{N}} F_n(\bm\eta^u, \bm y, \bm\eta^s) \\
%     \text{s.t.}&~ \eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c3a},\eqref{eq:c5a},\eqref{eq:c4a},
%     % \eqref{eq:c6},
%     \eqref{eq:c7a},\eqref{eq:c8a},\eqref{eq:c-y},
% \end{split}
% \end{equation}

% where $F_n(\bm\eta^u, \bm y, \bm\eta^s)=(1 - y_{m_n}) f^p_n(\bm\eta^u) + y_{m_n} f^s_n(\bm\eta^u, \bm\eta^s)$, $\bm y = \{y_{m}\}$, $f^p_n(\bm\eta^u) = \mathbb{E}[A^p_n]$, and $f^s_n(\bm\eta^s) = \mathbb{E}[A^s_n]$.



% \begin{figure*}[t]
% 	\centering
% 	\subfigure[PoSiP]{\label{fig:partA}\includegraphics[width=0.26\textwidth]{./figure/SystemFig1-a.pdf}}
% 	\subfigure[PoMiP]{\label{fig:partB}\includegraphics[width=0.35\textwidth]{./figure/SystemFig1-b.pdf}}
% 	\subfigure[PoMiS]{\label{fig:partC}\includegraphics[width=0.35\textwidth]{./figure/SystemFig1-c.pdf}}
% 	\caption{Exemplary illustrations of three scenarios based on the edge network model.}
% 	\label{fig:SystemModel}
% \end{figure*}


\section{PoPeC: PAoI-Centric Task Offloading with Priority over Unreliable Channels}\label{sec:PoPeC}

In light of the difficulty in directly solving the offloading problem, this section begins by examining two special cases in Sections \ref{subsec:POSIP} and \ref{subsec:POMIP}, i.e., priority-free and multi-priority task scheduling with no server collaboration. Based on their solutions, we devise the algorithm for optimizing the original problem in Section \ref{subsec:POMIS}.
% where server collaboration is not considered ($\bm y=\bm 0$) to gain valuable insights.
% Specifically, we examine the priority-free case with $|\Delta|=1$ as detailed in Section \ref{subsec:POSIP}, and the multi-class priority case with $|\Delta|\ge 1$ as discussed in Section \ref{subsec:POMIP}.
% Based on our findings and efficient algorithms, 
% we then extend our research to the case of multi-class priority and multi-server collaboration, which is presented in Section \ref{subsec:POMIS}.
%  We present efficient algorithms for each scenario based on our findings.
% In light of the difficulty in directly solving the offloading problem, we adopt a step-by-step approach to address the problem in three different scenarios, as depicted in Fig.\ref{fig:SystemModel}. 
% In Fig.\ref{fig:partA}, we start with a situation where several users offload work to the local server over certain unreliable channels, which is \underline{P}AoI-Centric Task \underline{O}ffloading with \underline{Si}ngle \underline{P}riority
% (PoSiP).
% Second, in the 
% \underline{P}AoI-Centric Task \underline{O}ffloading with \underline{M}ult\underline{i}-\underline{P}riority 
% (PoMiP) scenario,
% we offer various priority options so that users with different levels of freshness sensitivity can be given higher attention, as seen in Fig.\ref{fig:partB}.
% Based on our findings and efficient algorithms, we subsequently generalize the research to the case of multi-server collaboration, which is \underline{P}AoI-Centric Task \underline{O}ffloading with multi-class priority in \underline{M}ult\underline{i}-\underline{S}erver (PoMiS) and as shown in Fig.\ref{fig:partC}.
%  We present efficient algorithms for each scenario based on our findings.

% In the edge network of scenarios PoSiP, PoMiP, and PoMiS, the system models for task offloading are each depicted in Fig.\ref{fig:SystemModel}, respectively.
% Fig.\ref{fig:partA} shows a situation where several users offload work to the local server over certain unreliable channels.
% Besides, as seen in Fig.\ref{fig:partB}, we offer various priority options so that users with different levels of freshness sensitivity can be given higher attention.
% Multi-server collaboration is further shown in the third scenario, which lets the local server exploit the computational power of other idle servers, as shown in Fig.\ref{fig:partC}.
% Considering the fact that it is difficult to solve PoMiS directly in this part, we first tackle the offloading problem in two scenarios, PoSiP and PoMiP, step by step. Based on our findings and efficient parallel algorithms, we subsequently suggest a scheduling strategy contained PAoI minimization problem to PoMiS.
% Under the above setup, we pursue a PAoI-efficient POSIP designed by considering scheduling strategy contained PAoI minimization problem


% Considering the fact that it is difficult to solve the PoPeC problem directly in this part, we tackle the offloading problem in three scenarios step by step, as shown in Fig.\ref{fig:SystemModel}.
% In Fig.\ref{fig:partA}, we start by a situation where several users offload work to the local server over certain unreliable channels, which is \underline{P}AoI-Centric Task \underline{O}ffloading with \underline{Si}ngle \underline{P}riority
% (PoSiP).
% Second, in the 
% \underline{P}AoI-Centric Task \underline{O}ffloading with \underline{M}ult\underline{i}-\underline{P}riority 
% (PoMiP) scenario,
% we offer various priority options so that users with different levels of freshness sensitivity can be given higher attention, as seen in Fig.\ref{fig:partB}.
% Based on our findings and efficient algorithms, we subsequently generalize the research to the case of multi-server collaboration, which is \underline{P}AoI-Centric Task \underline{O}ffloading with Multi-Priority in \underline{M}ult\underline{i}-\underline{S}erver (PoMiS) and as shown in Fig.\ref{fig:partC}.


\subsection{Priority-Free Task Scheduling
}{\label{subsec:POSIP}}
\subsubsection{Problem Transformation}

The antecedent problem of the original problem pertains to a special case, where tasks belong to the same type with no priorities, and solely focus on the tasks offloading to the \textit{local} server. To tackle this problem, we first determine the expected PAoI of each user in this case.
% considering only the process of user offloading to the local server. In this case, it makes sense to first find out what each user's PAoI expectation is for the system.
% The usual situation with no priority is equal to such a priority-free scenario.
% Across such a priority-free and local-server-only example, tasks from various but priority-neutral users are delivered to the local server in a series of heterogeneous and unreliable channels.
% In this situation, finding out what each user's PAoI expectations are for the system is of relevance.
Since each user's task arrivals follow a Poisson distribution and task execution times follow a general distribution, we can re-evaluate the waiting time based on \eqref{eq:paoi-priority-waitingtime-expectation} as follows: 
\begin{equation}
    \mathbb{E}[W_{n}]=\frac{\sum_{n\in\mathcal{N}}\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}\nu_n}{2\cdot\left(1-\sum_{n\in\mathcal{N}}\sum_{c\in\mathcal{C}}p_{n,c}\cdot\frac{\eta^u_{n,c}\lambda_{n}}{\mu_n}\right)}
\end{equation}
We introduce an auxiliary variable, denoted by $\hat t^\mathit{tr}_n$ ($\hat t^\mathit{tr}_n>0$), to represent the upper bound of user $n$'s transmission time through all the available channels, \ie
\begin{equation}
\label{eq:c6}
    \hat t^\mathit{tr}_n \ge  T^\mathit{tr}_{n,c} , \quad \forall c \in \mathcal{C}. 
\end{equation}
% Intuitively, it holds 
%  $\mathbb{E}[T_{n}]=\hat t^\mathit{tr}_n$.
Similar to \cite{he2016optimal,du2017computation}, we can transform the original problem into a tractable form, \ie, optimizing a tight upper bound of user $n$'s expected PAoI: 
\begin{equation}
\label{eq:P1}
\begin{aligned}
    \textbf{(P1)}~~&\mathop{\min}_{\hat t^\mathit{tr}_n,\bm\eta^u} \frac{1}{N}\sum_{n\in\mathcal{N}} f_n(\hat t^\mathit{tr}_n,\bm\eta^u) \\
    \text{s.t.}&~ \eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c7a},\eqref{eq:c8a},\eqref{eq:c6}
\end{aligned}
\end{equation}
where $f_n(\hat t^\mathit{tr}_n,\bm\eta^u)$ is defined as:
\begin{align}
\label{eq:paoi-expectation1.1}
    f_n(\hat t^\mathit{tr}_n,\bm\eta^u)\doteq\,&\frac{\sum_{n\in\mathcal{N}}\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}\nu_n}{2\cdot\left(1-\sum_{n\in\mathcal{N}}\sum_{c\in\mathcal{C}}p_{n,c}\cdot\frac{\eta^u_{n,c}\lambda_{n}}{\mu_n}\right)}\nonumber\\
    &+ \hat t^\mathit{tr}_n + \frac{1}{\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}} + \frac{1}{\mu_n}
\end{align}
In the same spirit of min-max optimization, we can increase the communication efficiency across all channels by minimizing $\hat{t}^\mathrm{tr}_n$ instead of $\mathbb{E}[T_n]$, thereby enhancing the robustness of our proposed solution.

% This implies that all of $T^\mathit{tr}_{n,c}$, for any $c$, are the same as possible
% Intuitively, one of the goals of \textbf{P1} appears to be to minimize the upper bound of $T^\mathit{tr}_{n,c}$.   This implies that all of $T^\mathit{tr}_{n,c}$, for any $c$, are the same as possible, and $t^\mathit{tr}_n$  become a tight upper bound on $\mathbb{E}[T_{n}]$ \cite{he2016optimal,du2017computation}. Thus, $f_n(\hat t^\mathit{tr}_n,\bm\eta^u)$ is regarded as a tight upper bound on $\mathbb{E}[A_n]$, as well.
% \cite{ren2022efficient}.
% and become the objective function of \textbf{P1}.
% It is clear that $\mathbb{E}[A_n]\le f_n(\hat t^\mathit{tr}_n,\bm\eta^u)$. 
% Intuitively, \comment{Add explanation.}
% Since only constraints related to local offloading are considered, the PAoI minimization problem in Case 1 is formulated as
% where $f_n(\hat t^\mathit{tr}_n,\bm\eta^u) = \mathbb{E}[A^{1}_n]$. % The decision variables include $t^\mathit{tr}_n$ and $\bm\eta^u:=\{\eta^u_{n,c}\}_{n\in \mathcal{N}, c\in \mathcal{C}}$.
% Such a goal problem is to optimize all users' freshness performance to the greatest extent possible. Moreover, the inherent properties of PAoI also prevent situations in which one user monopolizes all resources \cite{yates2021age}.


% Without loss of generality, updates from any users are provided at the service rate of $\mu$ and a second moment of $\nu$, which are enough to describe systems where the users deliver tasks with uniformly distributed lengths but various timeliness demands \cite{yates2018age}.
% According to \eqref{eq:paoi-expectation1.1}, where the PAoI expectation of each user has been extensively addressed, the PAoI minimization problem shown by \textbf{P1-1} can be rewritten as follows
% \begin{equation}
% \label{eq:P1-2}
% \begin{aligned} 
%         \textbf{(P1-1)}~~&\mathop{\min}_{\hat t^\mathit{tr}_n, \bm\eta^u} \frac{1}{N}\sum_{n\in\mathcal{N}} \left( \hat t^\mathit{tr} + \frac{1}{\Psi_n(\bm\eta^u)}
% 	    + \frac{\upsilon_n(\bm\eta^u)}{\phi_n(\bm\eta^u)}
% 	    + \frac{1}{\mu}\right) \\
% 	   \text{s.t.}&~ \eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c7a},\eqref{eq:c8a},\eqref{eq:c6}.
% \end{aligned}
% \end{equation}

    % Furthermore, in light of the inherent complexity and non-convex nature of problem \textbf{P1}, it is necessary to undertake certain transformations to arrive at an optimal solution efficiently.

The nature of \eqref{eq:c7a} and \eqref{eq:c8a} suggests that \textbf{P1} is a non-convex problem. To identify well-structured solutions, we first transform this constraints into equivalent convex ones.

% In order to identify well-structured solutions, it is necessary to undertake certain transformations and assumptions on \textbf{P1}. Due to the non-convex nature of \eqref{eq:c7a} and \eqref{eq:c8a}, \textbf{P1} does not seem to be a convex problem in the current form.
\begin{lemma}
\label{lemma:P1-1_convex_problem}
% We apply some equivalent alterations to convert the constraints, \eqref{eq:c7a} and \eqref{eq:c8a}, into convex set \eqref{eq:c7b} and \eqref{eq:c8b} via some equivalent transformations.
In Problem \textbf{P1}, Constraints \eqref{eq:c7a} and \eqref{eq:c8a} are equivalent to Constraints \eqref{eq:c7b} and \eqref{eq:c8b}, \ie,
\begin{align}
    &\sum_{n\in\mathcal{N}} \eta^u_{n,c}\lambda_{n} \le M_c^\mathit{max} + \frac{z^2_{2}}{2} - \frac{z^2_{1}}{2} - z_{2}\cdot\left(M_c^\mathit{max} + \frac{z^2_{2}}{2} - \frac{z^2_{1}}{2}\right)^\frac{1}{2},
    \label{eq:c7b}\\
    &\sum_{n\in\mathcal{N}} \sum_{c\in\mathcal{C}} p_{n,c} \frac{\eta^u_{n,c}\lambda_{n}}{\mu_n} \leq 1 + \frac{z^2_{4}}{2} - \frac{z^2_{3}}{2} - z_{4}\cdot\left(1 + \frac{z^2_{4}}{2} - \frac{z^2_{3}}{2}\right).
    \label{eq:c8b}
\end{align}
% where $\frac{z^2_{2}}{2} - \frac{z^2_{1}}{2} = \frac{z^2_{2}}{2} - \frac{z^2_{1}}{2}$ and $\frac{z^2_{4}}{2} - \frac{z^2_{3}}{2} = \frac{z^2_{4}}{2} - \frac{z^2_{3}}{2}$
\end{lemma}
\begin{proof}
  The detailed proof can be found in Appendix \ref{app:lemma:P1-1_convex_problem} of technical report \cite{Nan2023}.
\end{proof}

According to Lemma \ref{lemma:P1-1_convex_problem}, Constraints \eqref{eq:c7b} and \eqref{eq:c8b} restrict the decision variables to convex sets. 
% Besides, we assume updates from any users are provided at the service time of $1/\mu$ and a second moment of $\nu$.
% This assumption is sufficient to describe systems where the users deliver tasks with uniformly distributed lengths but various timeliness demands \cite{yates2018age}.
Therefore, Problem \textbf{P1} can be rewritten as:
\begin{equation}
\label{eq:P1-1}
\begin{aligned}
    \textbf{(P1-1)}~~&\mathop{\min}_{\hat t^\mathit{tr}_n, \bm\eta^u} \frac{1}{N}\sum_{n\in\mathcal{N}} \left( \hat t^\mathit{tr} + \frac{1}{\Psi_n(\bm\eta^u)}
	    + \frac{\upsilon_n(\bm\eta^u)}{\phi_n(\bm\eta^u)}
	    + \frac{1}{\mu}\right) \\
    \text{s.t.}&~ \eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c6},\eqref{eq:c7b},\eqref{eq:c8b}
\end{aligned}
\end{equation}
where we denote $\upsilon_n(\bm\eta^u) \doteq \frac{1}{2}\sum_{n'\in\mathcal{N}}\sum_{c\in\mathcal{C}}p_{n',c}\cdot\eta^u_{n',c}\lambda_{n'}\nu$, $\phi_n(\bm\eta^u) \doteq 1-\sum_{n'\in\mathcal{N}}\sum_{c\in\mathcal{C}}p_{n',c}\cdot\eta^u_{n',c}\lambda_{n'}/\mu$, 
    % $\bm\eta^u:=\{\eta^u_{n,c}|n\in \mathcal{N}, c\in \mathcal{C}, \eta^u_{n,c} \in [0,1]\}$,
    and $\Psi_n(\bm\eta^u)\doteq\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}$.

\begin{theorem}
\label{thm:admm-consensus}
    Problem \textbf{P1-1} is a convex problem. 
    % We can obtain the optimal solution to the \textbf{P1-2} problem by solving \textbf{P1-3} in a distributed manner with the ADMM-Consensus algorithm.
\end{theorem}
\begin{proof}
    The constraints of \textbf{P1-1} are convex sets because they are affine sets. 
    Furthermore, we demonstrate the convexity of all sub-functions in Appendix \ref{app:lemma:paoi_mg1} of technical report \cite{Nan2023}.
\end{proof}
% Theorem \ref{thm:admm-consensus} implies that we can take advantage of the fact that the sub-problems are all convex and adopt the ADMM method to solve the problem \textbf{P1-1}.
% Based on the above, we have the following part.
Based on the convexity of Problem \textbf{P1-1}, we can employ the ADMM technique to solve this problem, which is discussed in the following section.



% \begin{align}
% \label{eq:P1-2}
%     \textbf{(P1-1)}~&\mathop{\min}_{\hat t^\mathit{tr},\bm x}\frac{1}{N}\sum_{n\in\mathcal{N}} f_n(\hat t^\mathit{tr},\bm x) \\
%     \text{s.t.}&~ \eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c6},\eqref{eq:c7b},\eqref{eq:c8b}
% \end{align}
% In other word, \textbf{(P1-1)} is equivalent to \textbf{(P1)}. 
    
\subsubsection{Problem Decomposition and Solving}\label{subsubsec:POSIP2}
Built upon the transformed problem \textbf{P1-1}, we define $g_n(\bm x)$ as follows:
\begin{align}
\label{eq:feasible_solution1}
    g_n(\bm x) \doteq \left\{\begin{array}{ll}
    \hat t^\mathit{tr} + \frac{1}{\Psi_n(\bm\eta^u)}
	    + \frac{\upsilon_n(\bm\eta^u)}{\phi_n(\bm\eta^u)}
	    + \frac{1}{\mu}, & \bm x \in \Omega, \\
    \infty, & \text {otherwise.}
    \end{array}\right.
\end{align}
where 
$\bm x \doteq \{\hat t^\mathit{tr}, \bm\eta^u\}$ denotes the decision variables, and $\Omega\doteq\{\bm x|\eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c6},\eqref{eq:c7b},\eqref{eq:c8b}\}$ is the feasible set of Problem \textbf{P1-1}. 
% In addition, we use the subscripts `n' and `o' to indicate whether the variable $\bm x$ is controlled on the user $n$ side or the server side, respectively.
Thus, \textbf{P1-1} is equivalent to the following consensus problem:
\begin{align}
    \label{PB:P1-2}
    \textbf{(P1-2)}~\mathop{\min}_{\{\bm x_n\}}~~&\sum_{n\in\mathcal{N}} g_n(\bm x_n) \\
    \label{eq:P1-2-consensus}
    \text{s.t.}&~\bm x_n = \bm x_{o}
\end{align}
According to Theorem \ref{thm:admm-consensus}, it is clear that the well-known ADMM-Consensus algorithm can be used to obtain the optimal solution of Problem \textbf{P1-2}\cite{boyd2011distributed}. For a detailed description of the algorithm, please refer to Appendix \ref{app:det:admm-consensus} of technical report \cite{Nan2023}.
    % since the objective function is convex and the feasible constraint is convex set, \textbf{P1-3} is a convex problem. According to \cite{boyd2011distributed}, we can obtain the optimal solution distributively by means of the ADMM-Consensus algorithm. 
    



\subsection{Multi-Priority Task Scheduling\label{subsec:POMIP}}
\subsubsection{Problem Transformation with Nonlinear Fractional Programming}
\label{subsubsec:NFP}
Different from priority-free task scheduling in the previous section, we delve deeper into the multi-priority task scheduling problem in this section.
% Based on their unique characteristics, users with multi-class priority are divided into different priority classes.
In this case, according to the priorities of received tasks, servers will execute the tasks with higher priorities more promptly. Since the multi-priority task scheduling in this case is indeed NP-Hard (see \cite{moghadas2011queueing}), 
% Due to the NP-Hardness of the M/G/1 model with multi-class priorities \cite{moghadas2011queueing}, we cannot ignore the need to address it. 
similar to Problem \textbf{P1}, we aim to minimize a tight upper bound for the average expected PAoI of multi-priority users, as follow:
% In this subsection, we delve deeper into the task offloading problem of users with multi-class priority over unreliable channels.  With the concept of multi-class priority, users are categorized into distinct priority classes based on their unique characteristics.  This enables the system to prioritize and complete tasks from high-priority users promptly.  Since users with different priorities have statistically significant differences in their task types, the execution times of tasks performed by different users are distributed independently but differently.  Using the problem formulation in the system model and taking into account multi-class priority, we arrive at the problem in Case 2 as follows
% In this subsection, we further investigate the task offloading problem of multi-class priority users in unreliable channels.
% In the light of multi-class priority, users are regarded as distinct classes priority based on their unique features and characteristics.
% Thanks to this mechanism, tasks from high-class priority users will be completed as promptly as possible.
% Given that the task types of users with varying priorities are statistically significantly inconsistent, the execution times of tasks performed by different users are distributed independently but differently.
% Based on the discussion of multi-class priority and problem formulation in the system model, we obtain the problem in PoMiP as
\begin{equation}
\label{eq:P2}
\begin{aligned}
    \textbf{(P2)}~~&\mathop{\min}_{\bm x} \frac{1}{N}\sum_{n\in\mathcal{N}} f^p_n(\bm x) \\
    \text{s.t.}&~ \eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c7a},\eqref{eq:c8a},\eqref{eq:c6},
\end{aligned}
\end{equation}
where 
% $\bm x = \{\hat t^\mathit{tr}_n,\bm\eta^u\}$,
$f^{p}_n(\bm x) = \hat t^\mathit{tr} 
+\frac{1}{\mu_n} 
+ \frac{1}{\Psi_n(\bm x)}
+ \frac{\Upsilon(\bm x)}
{\Phi_{\delta(n)}(\bm x)
\Phi_{\delta(n)-1}(\bm x)}$ is the upper bound of $\mathbb{E}[A_n]$,
$\bm x = \{\hat t^\mathit{tr},\bm\eta^u\}$ denotes the decision variables,
$\Phi_{\delta(n)}(\bm x) = 1-\sum_{\delta\in\Delta(\delta(n))}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\eta^u_{n',c}\lambda_{n'}/\mu_{n'}$,
$\Upsilon(\bm x) = \frac{1}{2}\sum_{\delta\in\Delta}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\eta^u_{n',c}\lambda_{n'}\nu_{n'}$, and
$\Psi_n(\bm x)=\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}$.
% Note that while the PoMiP's problem formulation is nearly identical to PoSiP's, it differs slightly, and the multi-class priority mechanism modifies the objective function relatively slightly.
 To obtain the effective offloading decision in this case, we next transform the original problem and 
decouple users' offloading decisions.

% Due to the coupling of multi-class priority user offloading decisions, some mathematical transformations of the objective function are necessary.
% Such M/G/1 with priority problem has been shown to be an NP-Hard problem\cite{moghadas2011queueing}.
% Due to the coupling of multi-class priority user offloading decisions, some mathematical transformations of the objective function are necessary in order to generate efficient solutions.
% Obviously, $\frac{1}{\mu_n}$ is not a decision variable and has no impact on the solution of $\bm x = \{\hat t^\mathit{tr},\bm\eta^u\}$ in  \textbf{P2}.
First, we define $\theta_n \doteq f^{p,u}_n(\bm x_n)/f^{p,l}_n(\bm x_n) =  f^{p}_n(\bm x_n) - 1/\mu_n$, and thus we obtain:
\begin{align} 
    \mathop{\min}_{\boldsymbol{\theta}}\sum_{n\in\mathcal{N}}\theta_n
    = \mathop{\min}_{\bm x}\sum_{n\in\mathcal{N}}\frac{f^{p,u}_n(\bm x_n)}{f^{p,l}_n(\bm x_n)}
    % \nonumber\\
   = \sum_{n\in\mathcal{N}}\frac{f^{p,u}_n(\bm x_n^*)}{f^{p,l}_n(\bm x_n^*)},
\label{eq:NFP-theta}
\end{align}
where $\bm x_n^*$ is the optimal solution and $f^{p,u}_n,f^{p,l}_n$ are defined by
% $f^{p,u}_n$ and $f^{p,l}_n$, which are \eqref{eq:NFP-upperfunction} and \eqref{eq:NFP-lowerfunction}.
\begin{align}
\label{eq:NFP-upperfunction}
    f^{p,u}_n(\bm x_n)   =\; & \Phi_{\delta(n)}(\bm x_n)\Phi_{\delta(n)-1}(\bm x_n) + \Upsilon(\bm x_n)\Psi_n(\bm x_n)\nonumber\\
    &+\hat t^\mathit{tr}\Psi_n(\bm x_n)\Phi_{\delta(n)}(\bm x_n)\Phi_{\delta(n)-1}(\bm x_n),\\
\label{eq:NFP-lowerfunction}
    f^{p,l}_n(\bm x_n)   =\; & \Psi_n(\bm x_n)\Phi_{\delta(n)}(\bm x_n)\Phi_{\delta(n)-1}(\bm x_n).
\end{align}

% Define $\theta_n = \frac{f^{p,u}_n(\bm x_n)}{f^{p,l}_n(\bm x_n)}$ and $\boldsymbol{\theta} = \{\theta_n| n\in \mathcal{N}\}$. 
% Furthermore, $\Theta$ can be expressed as



\begin{proposition}
\label{pro:npl-mp}
Problem \textbf{P2} can be recast into an equivalent problem as follows:
    \begin{equation}
    \begin{split}
    \label{eq:P2-1}
        \textbf{\textrm{(P2-1)}}~&\mathop{\min}_{\{\bm x_n\}} \sum_{n\in\mathcal{N}} f^{p,u}_n(\bm x_n) - \theta^{*}_n f^{p,l}_n(\bm x_n) \\
        \text{s.t.}&~~\eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c6},\eqref{eq:c7b},\eqref{eq:c8b}
    \end{split} 
\end{equation}
where $\theta^{*}_n$ is the minimum value of $f^{p,u}_n(\bm x_n)/f^{p,l}_n(\bm x_n)$ with regard to $\bm x_n$.
\end{proposition}
\begin{proof}
The detailed proof can be found in Appendix \ref{app:pro:npl-mp} of technical report \cite{Nan2023}.
\end{proof}

Proposition \ref{pro:npl-mp} demonstrates that problem transformation can be employed to address nonlinear fractional programming problems such as \textbf{P2-1}. Specifically, the iterative Dinkelbach technique, outlined in Algorithm \ref{alg:NFP}, can be applied to solve these types of problems effectively, as shown in \cite{dinkelbach1967nonlinear}.
% we utilized the iterative Dinkelbach technique to solve the nonlinear fractional programming problem, \ie \textbf{P2-1}, which is shown by Algorithm \ref{alg:NFP}.
Algorithm \ref{alg:NFP} updates the value of $\tilde{\theta}_n$ in each iteration based on the current $\tilde{\bm x}^k_n$, i.e.,
\begin{equation}
    \tilde{\theta}^{k+1}_n = \frac{f^{p,u}_n(\tilde{\bm x}^{k+1}_n)}{f^{p,l}_n(\tilde{\bm x}^{k+1}_n))}.
\end{equation}
This process continues until:
% every iteration $k$ of Algorithm \ref{alg:NFP} changes the new value of $\tilde{\theta}^{k+1}_n = \frac{f^{p,u}_n(\tilde{\bm x}^{k+1}_n)}{f^{p,l}_n(\tilde{\bm x}^{k+1}_n))}$  until:
\begin{equation}
     f^{p,u}_n(\tilde{\bm x}^{k+1}_n) - \tilde{\theta}^{k}_n f^{p,l}_n(\tilde{\bm x}^{k+1}_n)) > \epsilon^{ck},
\end{equation}
where $\epsilon^{ck}$ represents the stop criteria for iterations.

\begin{algorithm}[t]
	\caption{Nonlinear fractional programming based on ADMM-Consensus (NFPA)}
	\label{alg:NFP}
	\LinesNumbered
	\tcp{CheckPointing Algorithm - NFP}
	\KwIn{$\epsilon^{ck}$, $\{\tilde{\theta}^0_n\}$, $k$}
	\For{$n = 1$ \KwTo $N$}{
	{Convergence = False}\\
    \While{Convergence = False}{
        {Apply Algorithm \ref{alg:nonconvexadmm} or \ref{alg:AsynchronousADMM} with $\tilde{\bm x}^k_n$ and $\tilde{\theta}^k_n$ to obtain the solution $\tilde{\bm x}^{k+1}_n$}\\
        \eIf{$f^{p,u}_n(\tilde{\bm x}^{k+1}_n) - \tilde{\theta}^{k}_n f^{p,l}_n(\tilde{\bm x}^{k+1}_n)) > \epsilon^{ck}$}{
        {Select $\tilde{\theta}^{k+1}_n = \frac{f^{p,u}_n(\tilde{\bm x}^{k+1}_n)}{f^{p,l}_n(\tilde{\bm x}^{k+1}_n))}$}\\
        {Convergence = True}}
	    {{Convergence = False}\\}
	    {Update $s = s+1$}\\
	}
	{Select $\bm x^{p,*}_n = \tilde{\bm x}^{k}_n$}\\
	{Select $\theta^{p,*}_n = \tilde{\theta}^{k}_n$}\\
	{Calculate \textbf{PAoI} according to \eqref{eq:P2}}\\
	\KwOut{$\bm x^{p,*}_n$ and \textbf{PAoI}}
}	
\end{algorithm}

\subsubsection{ADMM-Consensus Based Solution}
\label{subsubsec:nonconvex-admm}
The procedure mentioned above can be considered as a checkpointing algorithm. We employ non-convex ADMM-Consensus methods to determine the new value of $\{\bm x_n\}$. As discussed in section \ref{subsec:POSIP}, the consensus problem for \textbf{P2-1} can be expressed as:
\begin{equation}
\label{eq:P2-2}
    \begin{split}
    \textbf{(P2-2)}~\mathop{\min}_{\{\bm x_n\}}~~&\sum_{n\in\mathcal{N}} g^{p}_n(\bm x_n) \\
    \text{s.t.}&~\bm x_n = \bm x_{o}
    \end{split}
\end{equation}
where
\begin{align}
\label{eq:feasible_solution2}
    g^{p}_n(\bm x_n) = \left\{\begin{array}{ll}
    f^{p,u}_n(\bm x_n) - \theta^{*}_nf^{p,l}_n(\bm x_n), &\bm x\in \Omega, \\
    \infty, &\text{otherwise.}
    \end{array}\right.
\end{align}
It means that if the solution and $\bm x\in \Omega$ are feasible, then the augmented Lagrangian for Problem \textbf{P2-2} can be expressed as:
\begin{align}
\label{eq:PLadmm-lagrange}
    L^{p}(\{\bm x_n\}, \bm x_{o}, \{\bm\sigma_n\})
   = \sum_{n\in\mathcal{N}}L^{p}_{n}(\bm x_n, \bm x_{o}, \bm\sigma_n)\nonumber\\
   = \sum_{n\in\mathcal{N}}\left(g^{p}_n(\bm x_n) + \langle\bm\sigma_n, \bm x_n - \bm x_{o} \rangle
    + \frac{\rho_n}{2}\|\bm x_n - \bm x_{o}\|^2_2\right)
    % \\ \text{s.t.}  \mathcal{C} = \{(\bm x_1, \ldots, \bm x_N)|\bm x_1 = \ldots = \bm x_N\},
\end{align}
where $\rho_n$ is a positive penalty parameter with respect to Problem \textbf{P2-2}.
Based on the non-convex ADMM-Consensus algorithm, we update the variables in each iteration $t$ as follows:
% Therefore, we can obtain the efficient solution $\{\bm x_n\}$ to  Algorithm \ref{alg:NFP} via internal circulation ADMM-Consensus method (\ie Algorithm \ref{alg:nonconvexadmm}).
\begin{align}
    \label{eq:PLadmm2-relax-i} 
    \bm x^{t+1}_n & = \arg\min_{\bm x_n}L^p_n(\{\bm x_n\}, \bm x^t_{o}, \{\bm\sigma^t_n\})
    \\
    % \{g^{p}_n(\bm x^t_n)\nonumber\\
    % & + \langle\bm\sigma^t_n, \bm x^t_n - \bm x^t_{o}\rangle + \frac{\rho_n}{2}\|\bm x^t_n - \bm x^t_{o}\|^2_2\} \\ 
    \label{eq:PLadmm2-relax-o}
    \bm x^{t+1}_{o} & = \frac{\sum_{n\in\mathcal{N}}(\rho_n \bm x^{t+1}_n + \sigma^{t}_n)}{\sum_{n\in\mathcal{N}}\rho_n} \\
    \label{eq:PLadmm2-relax-sigma}
    \sigma^{t+1}_n & = \sigma^{t}_n + \rho_n(\bm x^{t+1}_n - \bm x^{t+1}_{o}).
 \end{align}

\begin{proposition}
\label{theorem:NFP_Problem}
The first-order derivative of $g^{p}_n$ is Lipschitz continuous with constant $\ell_n$, which is defined as
\begin{align}
    \ell_n=\frac{\lambda^2_{max}}{\mu^2_\mathit{min}}\Big(
	        \sum_{n_1\in \mathcal{N}} \frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}
	        + (1+\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}})|\mathcal{N}_1|
	        + \theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}|\mathcal{N}_2|\Big),
\end{align}
where $\mu_\mathit{min} = \mathop{\min}_{n} \{\mu_n\}$,
$\lambda_{max} = \mathop{\max}_n \lambda_{n}$,
$\mathcal{N}_1 = \{\mathcal{N}^{\delta}|\delta<\delta(n)\}\bigcup \{n\}$, $\mathcal{N}_2 = \{\mathcal{N}^{\delta}|\delta\leq\delta(n)\}$.
% and $\{\leq\delta(n)\} = \{\delta|\delta\leq\delta(n)\}$.

% Based on this, we can apply the non-convex ADMM-Consensus method to acquire solution $\{\bm x_n\}$ of \textbf{P2-2}.
\end{proposition}
\begin{proof}
    % For more detailed information, please refer to
    The detailed proof can be found in Appendix \ref{app:theorem:NFP_Problem} of technical report \cite{Nan2023}.
\end{proof}

According to the fact in Proposition \ref{theorem:NFP_Problem}, we adopt  the non-convex ADMM-Consensus method to solve Problem \textbf{P2-2}, with given $\left(\{\bm x^0_n\}, \{\theta^*_n\}\right)$ (as outlined in Algorithm \ref{alg:NFP}).

\begin{algorithm}[ht]
	\caption{Non-Convex ADMM-Consensus (NAC)}
	\label{alg:nonconvexadmm}
	\LinesNumbered
	\KwIn{$\epsilon^{ac}$, $t$ and $\left(\{\bm x^0_n\}, \{\theta^*_n\}\right)$ from Algorithm \ref{alg:NFP}}
    \tcp{Internal Circulation - ADMM}
    \Do{$\eta\left(\bm x^t, \bm\sigma^t\right) \ge \epsilon^{ac}$}{
        {Calculate $\bm x^{t+1}_{o}$ in \textbf{MEC}, according to \eqref{eq:PLadmm2-relax-o}}\\
    	{Calculate $\bm x^{t+1}_n$ in \textbf{user}, simultaneously according to \eqref{eq:PLadmm2-relax-i}}\\
        {Calculate $\sigma^{t+1}_n$ in \textbf{user}, simultaneously according to \eqref{eq:PLadmm2-relax-sigma}}\\
        {Update $t = t + 1$}\\
	    }
	\KwOut{$\bm x^{t}_n$}
\end{algorithm}
It is worth mentioning that the value of $\rho_n$ and convergence of the Algorithm \ref{alg:nonconvexadmm} differ from those in the Convex ADMM-Consensus method. Since Algorithm \ref{alg:nonconvexadmm} is for problems with non-convex objective functions, we design a special gap functions that can characterize the convergence of NAC as follows:
\begin{equation}
    \eta\left(\bm x^t, \bm\sigma^t\right)=\left\|\tilde{\nabla} L^{p}\left(\left\{\bm x^t_{n}\right\}, \bm x^t_{o}, \bm\sigma^t\right)\right\|^{2}+\sum_{n\in\mathcal{N}}\left\|\bm x^t_{n}-\bm x^t_{o}\right\|^{2},
\end{equation}
where 
\begin{align*}
    \tilde{\nabla} L^{p}\left(\left\{\bm x_{n}\right\}, \bm x_{o}, \bm\sigma^t\right)
   =\left[\begin{array}{c}
    \nabla_{\bm x_{o}} L^{p}\left(\left\{\bm x_{n}\right\}, \bm x_{o}, \bm\sigma^t\right)  \\
    \nabla_{\bm x_{1}} L^{p}\left(\left\{\bm x_{n}\right\}, \bm x_{o}, \bm\sigma^t\right) \\
    \vdots \\
    \nabla_{\bm x_{N}} L^{p}\left(\left\{\bm x_{n}\right\}, \bm x_{o}, \bm\sigma^t\right)
    \end{array}\right].
\end{align*}
% When $\lim_{t \to \infty} \eta\left(\bm x^t, \bm\sigma^t\right)=0$, we have the limit solution is a stable solution.
When $\eta\left(\bm x^t, \bm\sigma^t\right) < \epsilon^{ac}$, the limit solution is a stable solution, where $\epsilon^{ac}$ is the criterion for stopping the iterations of Algorithm \ref{alg:nonconvexadmm}.

% Obviously, above algorithm is too ideal, since the network system is in a unreliable channel and every single communication has the potential to fail. To accommodate this complexity, we propose an algorithm that does not have to iterate all the nodes together at each iteration, at the cost of possibly losing accuracy.

\begin{theorem}
	\label{theorem:innerConvergence1}
    If $\rho_n>2\ell_n$, Algorithm \ref{alg:nonconvexadmm} converge to an $\epsilon^{ac}$-stationary point within $O(1/(p^\mathit{sysn}\epsilon^\mathit{ac}))$,
    where $\epsilon^{ac}$ is a positive iteration factor and $p^\mathit{sysn} = \Pi_{n\in\mathcal{N}}(\frac{1}{C} \sum_{c\in\mathcal{C}}p_{n,c})$ is the probability of successfully completing a synchronous update. 
    % \begin{equation}
    %     \Gamma^{sysn}<\frac{k^{\Gamma}(L^{p}\left(\left\{\bm x_{n}^{1}\right\}, \bm x_{o}^{1}, \bm \sigma^{1}\right)-\underline{G^{p}})}{\epsilon^{ac} p^\mathit{sysn}},
    % \end{equation}
    % where  
    % $\epsilon^{ac}$ is a positive iteration factor, 
    % $k^{\Gamma}$ is a constant, 
    % $p^\mathit{sysn} = \Pi_{n\in\mathcal{N}}(\frac{1}{C} \sum_{c\in\mathcal{C}}p_{n,c})$ probability of successfully completing a synchronous update,
    % $\underline{G^{p}}$ is the lower bound of $\sum_{n\in\mathcal{N}} g^{p}_n(\bm x_n)$,
    % % \ie $\underline{G^{p}} = \inf_{\bm x_n} \sum_{n\in\mathcal{N}} g^{p}_n(\bm x_n)$,
    % and $\Gamma^{sysn}$ is number of iterations, \ie 
    % $\Gamma^{sysn} = \min \left\{t\mid \eta\left(\bm x^t, \bm\sigma^t\right) \leq \epsilon, t \geq 0\right\}$.
\end{theorem}
\begin{proof}
    The detailed proof can be found in Appendix \ref{app:theorem:innerConvergence1} of technical report \cite{Nan2023}.
\end{proof}

Since the iteration will continue if the parameters given by Algorithm \ref{alg:nonconvexadmm} do not satisfy the stop condition of Algorithm \ref{alg:NFP}, we can use Algorithm \ref{alg:NFP} as a condition for Algorithm \ref{alg:nonconvexadmm} to terminate.




\subsection{Multi-Priority Task Scheduling and Multi-Server Collaboration\label{subsec:POMIS}}
\subsubsection{Problem Decomposition}
Different from Section \ref{subsec:POSIP} and Section \ref{subsec:POMIP}, which concentrate solely on a single server, we further study multi-priority and multi-server collaboration-based offloading in this subsection. 
In order to resolve the original problem,  we first derive the expression of the optimal migration decision variable $\bm y^*$.
\begin{theorem}
\label{thm:single-or-multi}
    The optimal migration decision is
    \begin{equation}  
	\label{eq:opy-y}
		y_{m_n} = \left\{
		\begin{array}{ll}
		 1, &\quad  \phi^{in}(\bm \eta^s)+\phi^{out}(\bm \eta^s)> 0,\\
		 0 , &\quad otherwise,
		\end{array}
		\right.	
	\end{equation}
	where $\phi^{in}(\bm \eta^s) = \sum_{m'\in\mathcal{M}/m_n} \eta^s_{m',m_n} \sum_{\delta \in \Delta} \lambda^{s}_{\delta,m'}$ and $\phi^{out}(\bm \eta^s)$ $= \sum_{m'\in\mathcal{M}/m_n} \eta^s_{m_n,m'} \sum_{\delta \in \Delta} \lambda^{s}_{\delta,m_n}$.
\end{theorem}
\begin{proof}
    The detailed proof can be found in Appendix \ref{app:thm:single-or-multi-A} of technical report \cite{Nan2023}.
\end{proof}
    % Combining Theorem \ref{thm:single-or-multi} and discussion of constraints, there is a comparable solution
    % $\hat{\bm y^*} = \bm 1$.
    % which holds $\sum_{n\in\mathcal{N}} F_n(\bm x, \bm y^{*}, \bm z)=\sum_{n\in\mathcal{N}} F_n(\bm x, \hat{\bm y^{*}}, \bm z)$.
    % Hence, we have 
    % \begin{equation}
    % \label{eq:fn=f1n}
    %     \sum_{n\in\mathcal{N}} F_n(\bm x, \hat{\bm y^{*}}, \bm z) \leq \sum_{n\in\mathcal{N}} F_n(\bm x, \bm y, \bm z),
    % \end{equation}

Combining Theorem \ref{thm:single-or-multi} and Appendix \ref{app:thm:single-or-multi-B} \cite{Nan2023}, one alternative for \textbf{(PoPeC)} is
\begin{equation}
\label{eq:P3}
\begin{split}
    \textbf{(P3)}~&\mathop{\min}_{\bm x, \bm z}
    \frac{1}{N}\sum_{n\in\mathcal{N}} F^1_n(\bm x, \bm z) \\
    \text{s.t.}&~ 
    \eqref{eq:c1},\eqref{eq:c2},%to
    \eqref{eq:c3a},\eqref{eq:c5a},\eqref{eq:c4a},%tm
    \eqref{eq:c6},%transmission
    % \eqref{eq:c-y}, %y
    \eqref{eq:c7b},\eqref{eq:c8b}, %capacity
\end{split}
\end{equation}
where $F^1_n(\bm x, \bm z) = \hat t^\mathit{tr}_n + \frac{1}{\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}} + \sum_{m\in\mathcal{M}} \pi_{n,m}(\bm z)$,
$\bm x = \{\hat t^\mathit{tr}, \bm\eta^u\}$ and $\bm z = \bm\eta^s$.
The main challenge in resolving the \textbf{P3} is that the function $\sum_{n\in\mathcal{N}} F^1_n(\bm x, \bm z)$ is a non-convex and the variable $\bm x$ is intricately connected to $\bm z$.
\begin{lemma}
    \label{lemma:Transform-DataMigration-ChannelAllocation}
Problem \textbf{P3} can be equivalently transformed into the \textbf{Channel Allocation} subproblem,  \textbf{P3-1}, and the \textbf{Server Collaboration} subproblem, \textbf{P3-2}, which are shown as follow:
\begin{align}
    \textbf{(P3-1)}~&\mathop{\min}_{\bm x}\frac{1}{N}\sum_{n\in\mathcal{N}} F^2_n(\bm x) \nonumber\\
    \text{s.t.}&~ \eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c6},\eqref{eq:c7b},\eqref{eq:c8b},\nonumber\\
    \label{eq:DataMigration-AuxiliaryInequality}
    &\sum_{n \in \mathcal{N}^{\delta}_m}\sum_{c \in C} p_{n,c} \eta^u_{n,c}\lambda_{n} \leq \lambda^{s}_{\delta,m},
\end{align}
\begin{equation}
\begin{split}
    \textbf{(P3-2)}~&\mathop{\min}_{\bm z}\frac{1}{N}\sum_{n\in\mathcal{N}} F^3_n(\bm z, \bm \lambda^s) \\
    \text{s.t.}&~ \eqref{eq:c3a},\eqref{eq:c5a},\eqref{eq:c4a},
\end{split}
\label{eq:P3-2}
\end{equation}
where we define $F^2_n(\bm x) \doteq \hat t^\mathit{tr}_n + \frac{1}{\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}}$,  $F^3_n(\bm z, \bm \lambda^s) \doteq \sum_{m\in\mathcal{M}} \pi_{n,m}(\bm z)$,
and $\lambda^{s}_{\delta,m} \doteq  \sum_{m' \in \mathcal{M}}  \eta^s_{m,m'} \lambda^{s}_{\delta,m}$.
\end{lemma}
\begin{proof}
    The detailed proof can be found in Appendix \ref{app:lemma:Transform-DataMigration-ChannelAllocation} of technical report \cite{Nan2023}.
\end{proof}


Next, we develop solutions to these problems that iteratively address the Channel Allocation \textbf{P3-1} on the user side and Server Collaboration \textbf{P3-2} problems on the server side.

 


\subsubsection{Channel Allocation} 
The goal of the Channel Allocation problem is to address the problem of channel allocation for each local server and each user it serves,
Based on Lemma \ref{lemma:Transform-DataMigration-ChannelAllocation}, this sub-problem is transformed and 
we can obtain the optimal solution
     \begin{equation}
        \label{eq:opt-x}
        \begin{split}
            \bm x^{*}=\{\bm x^{*}_m\},
        \end{split}
     \end{equation}
where $\bm x^{*}_m$ can be derived from 
\begin{align}
    \textbf{(P3-3)} \mathop{\min}_{\bm x_m}  \sum_{n\in\mathcal{N}_m} F^2_n(\bm x_m, \bm \lambda^s)~\nonumber\\
    \text{s.t.} \eqref{eq:c1},\eqref{eq:c2}, \eqref{eq:c6},\eqref{eq:c7b},\eqref{eq:c8b}, \eqref{eq:DataMigration-AuxiliaryInequality}.
\end{align}
    
\begin{lemma}
\label{lemma:DataMigration-ChannelAllocation}
% \begin{align}
% \label{eq:P3-4}
%     \textbf{(P3-4)}~&\mathop{\min}_{\bm x_m}\sum_{n\in\mathcal{N}_m} F^2_n(\bm x_m) \nonumber\\
%     \text{s.t.}&~ \eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c6},\eqref{eq:c7b},\eqref{eq:c8b},
%     \eqref{eq:DataMigration-AuxiliaryInequality},
% \end{align}
    Problem \textbf{P3-2} is a convex problem. 
    \end{lemma}
    \begin{proof}
        We can easily obtain the convexity of $F^1_n$ from Appendix \ref{app:lemma:paoi_mg1} of technical report \cite{Nan2023}.
        Thus, this is a convex problem where both the sub-function and the constraints are convex. 
    \end{proof}
    Based on Lemma \ref{lemma:DataMigration-ChannelAllocation} and the solution of \ref{subsec:POSIP}, \textbf{P3-2} can be resolved by the existing method AC in Algorithm \ref{alg:admm}.
    % Specifically, we can leverage the ADMM-Consnesus method to gain more insights into the structure of the solution.
    The details can be found in Section \ref{subsubsec:POSIP2} and Appendix \ref{app:det:admm-consensus} of technical report \cite{Nan2023}.
    Each local server first finds an optimal solution $\bm x^{*}_m$ for all users it covers, and then the collection of these $\bm x^{*}_m$ is the optimal channel allocation solution $\bm x^{*}$, which is shown by \eqref{eq:opt-x}.
    
\subsubsection{Server Collaboration}
    Problem \textbf{P3-2} seeks to address the problem of multi-server collaboration between various servers in order to lessen the load on overhead servers and speed up task execution to decrease PAoI for multi-priority users, which has been shown to be an NP-Hard problem in section \ref{subsec:POMIP}.
    However, we develop an effective migration strategy,
    % which necessitates the waiting and execution of priority user task requests on various servers in each region as well as considering server-to-server communication.
    based on Lemma \ref{thm:single-or-multi}, the server collaboration strategy is
    $\bm z^* = \mathop{\arg \min}_{\bm z} \{\frac{1}{N} \sum_{n\in\mathcal{N}} \sum_{m\in\mathcal{M}} \pi_{n,m}(\bm z) ~ \text{s.t.}~\eqref{eq:c3a},\eqref{eq:c5a},\eqref{eq:c4a} \}$.
    
    \begin{proposition}
    \label{proposition:DataMigration-MigrationAllocation1}
    Given $\bm \lambda^s$, Problem \textbf{P3-2}  is equivalent to the following problem:
    \begin{align}
        \textbf{(P3-4)}~&\mathop{\min}_{\{\bm z_{n,m}\}} \sum_{n\in\mathcal{N}} \sum_{m\in\mathcal{M}} \{\pi^{u}_{n,m}(\bm z_{n,m}) - \vartheta^{*}_{n,m} \pi^{l}_{n,m}(\bm z_{n,m})\}\nonumber \\
        \text{s.t.}&~~\eqref{eq:c1},\eqref{eq:c2},
        \eqref{eq:c7a},
        \eqref{eq:c8a},
        \eqref{eq:c6},
        \label{eq:P3-4}
    \end{align}
Given $\bm z_{n,m}$, $\vartheta^{*}_{n,m}$ is the minimum of $\frac{\pi^{u}_{n,m}(\bm z_{n,m})}{\pi^{l}_{n,m}(\bm z_{n,m})}$, where
$\pi^{l}_{n,m}(\bm z)$ $=\Phi^{\pi}_{\delta(n),m}(\bm z)\Phi^{\pi}_{\delta(n)-1,m}(\bm z)\sum_{m'\in\mathcal{M}} \Psi_{n, m'}^{\pi}(\bm z)$ and
$\pi^{u}_{n,m}(\bm z)=\Lambda_{n,m}\Psi_{n,m}^{\pi}(\bm z)\Phi^{\pi}_{\delta(n),m}(\bm z)\Phi^{\pi}_{\delta(n)-1,m}(\bm z)+\Psi_{n,m}^{\pi}(\bm z)\Upsilon^{\pi}(\bm z)$. Here, $\Upsilon^{\pi}_{n,m}(\bm z) = \frac{1}{2}\sum_{\delta\in\Delta} \sum_{m'\in\mathcal{M}} \eta^s_{m',m} \lambda^{s}_{\delta,m'} \nu_{n,m}$,
% Additionally, it should be noted that
$\Lambda_{n,m} = t^\mathit{tr}_{m_n,m} + \frac{1}{\mu_{n,m}}$,
$\Phi^{\pi}_{\delta(n),m}(\bm z) = 1-\sum_{\delta\in{\Delta(\delta(n))}}\sum_{m'\in\mathcal{M}} \eta^s_{m',m} \lambda^{s}_{\delta,m'} \frac{1}{\mu_{n,m}}$,
and
$\Psi_{n,m}^{\pi}(\bm z)=\sum_{\delta\in\Delta} \eta^s_{m_n,m} \lambda^{s}_{\delta,m_n}$.

% As for \textbf{P3-4}, we can utilize the ADMM-Consensus method to derive an efficient solution $\{\bm z_{n,m}\}$.
\end{proposition}
\begin{proof}
Due to ${\pi^{u}_{n,m}(\bm z)}$ and ${\pi^{l}_{n,m}(\bm z)}$ as the polynomial functions of the numerator and denominator on the fraction $\pi_{n,m}(\bm z)$,
problem \textbf{P3-2} with given $\bm \lambda^s$ from  can be recast into an equivalent problem as \textbf{P3-4},
with applying nonlinear fractional programming.
For more detailed problem tranformation, please refer to Appendix \ref{app:proposition:DataMigration-MigrationAllocation1} of technical report \cite{Nan2023}.
\end{proof}
Combining Proposition \ref{proposition:DataMigration-MigrationAllocation1} and Section \ref{subsubsec:NFP}, we can apply NFP in Algorithm \ref{alg:NFP} to convert \textbf{P3-2} to \textbf{P3-4}.
After transforming the problem in Proposition \ref{proposition:DataMigration-MigrationAllocation1}, we obtain problem \textbf{P3-4}, which has a cubic polynomial objective function. Nevertheless, deriving the closed-form solution for \textbf{P3-4} is still challenging, we instead provide an iterative algorithm as follows.
\begin{lemma}
\label{lemma:DataMigration-MigrationAllocation2}
    In \textbf{P3-4}, the first-order derivative of $\pi^{u}_{n,m}(\bm z_{n,m}) - \vartheta^{*}_{n,m} \pi^{l}_{n,m}(\bm z_{n,m})$ is Lipschitz continuous.
\end{lemma}
\begin{proof}
    The detailed proof can be found in Appendix \ref{app:lemma:DataMigration-MigrationAllocation2} of technical report \cite{Nan2023}.
\end{proof}
Based on Lemma \ref{lemma:DataMigration-MigrationAllocation2} and Section \ref{subsubsec:nonconvex-admm}, we use NAC and NFP in Algorithm \ref{alg:nonconvexadmm} to gain an efficient solution of \textbf{P3-4}. 
In this case, the complexity of the method is $O(1/\epsilon^{ac})$, which can be proved by Appendix \ref{app:proof:DataMigration-MigrationAllocation3} \cite{Nan2023}.

% Therefore, we can utilize the NFP and NAC method, shown by Section \ref{subsec:POMIP}, to gain an efficient solution of \textbf{P3-4}. 

% \begin{lemma}
%     \label{lemma:DataMigration-MigrationAllocation}
%          Given an fixed $\bm x$, we can solve the server collaboration strategy $\widetilde{\bm z}$ by Algorithm \ref{alg:NFP} and Algorithm \ref{alg:nonconvexadmm}, due to reliable communication and iteration between servers. Especially, if this has only a Priority-Free, we can obtain the optimal solution.
% \end{lemma}
% \begin{proof}
%     See Appendix \ref{app:lemma:DataMigration-MigrationAllocation}.
% \end{proof}

% \end{itemize}

% The function $F^2_n(\bm x)=\hat t^\mathit{tr}_n + \frac{1}{\Psi_n(\bm x)} + \pi(\bm z_o)$ is a convex function, based on Lemma \ref{lemma:paoi_mg1}.


% \begin{lemma}
% \label{lemma:compare-convergence}    
%     Denote $\widetilde{s}_{m} = \sum_{n\in\mathcal{N}_m}\sum_{c\in\mathcal{C}} p_{n,c} \lambda_{n,c}$ as an auxiliary variable. We have $\widetilde{s}_{m} q^s_{m,m'} = \widetilde{s}_{m,m'}$. Denote $\widetilde{\bm z} = \{\widetilde{s}_{m,m'}\}$.  
%     We have $F_n(\bm x^*, \bm z_o) \geq F_n(\bm x^*, \widetilde{\bm z})$
% \end{lemma}

\subsubsection{Iterative Solution}
We design an iterative solution algorithm that first obtains the initial $\bm x_o$ inside each local server with a given $\bm y$. In the algorithm, $\bm x^t$ and $\bm z^t$ are solved alternately to obtain the solution. In the following, we establish the convergence guarantee for the proposed algorithm.


\begin{algorithm}[htbp]
	\caption{Iterative Solution (IS)}
	\label{alg:IS}
	\LinesNumbered
	\KwIn{$t=0$, $\lambda^{s,0}_{\delta,m} = \lambda^{s,\mathit{max}}_m$}
    \While{not done}{
        {Compute $\bm x^{t+1}$ according to \eqref{eq:opt-x}} by Lemma \ref{lemma:DataMigration-ChannelAllocation}\\
        {Compute $\bm \lambda^{s,t+1}$ according to \eqref{eq:lambda-s}}\\
        {Compute $\bm z^{t+1}$ according to \eqref{eq:P3-4}} by Lemma \ref{lemma:DataMigration-MigrationAllocation2}\\
        {Update $t = t + 1$}\\
	    }
	{Compute $\bm y^*$ by \eqref{eq:opy-y};}\\
	\KwOut{$\bm x^*=\bm x^{t}$,$\bm y^*$,$\bm z^*=\bm z^{t}$}
\end{algorithm}

\begin{theorem}
\label{thm:DataMigration-Convergence}
If we solve \textbf{P3} by Algorithm \ref{alg:IS}, $F_n(\bm x^t, \bm z^t)$
monotonically decreases and converges to a unique point.
\end{theorem}
\begin{proof}
    The detailed proof can be found in Appendix \ref{app:thm:DataMigration-Convergence} of technical report \cite{Nan2023}.
\end{proof}



\section{Discussion}\label{sec:Discussion}

\subsection{Asynchronous Parallel Algorithm}
\begin{algorithm}[htbp]
    \label{alg:AsynchronousADMM}
	\caption{Asynchronous Non-Convex ADMM-Consensus (ANAC)}
	\LinesNumbered   
    \BlankLine
	{/* MEC Side */}\\
	\KwIn{$\epsilon^{ac}$, $\tau_{o}$ and $\left(\{\bm x^0_n\}, \{\theta^*_n\}\right)$ from Algorithm \ref{alg:NFP}}
	{Convergence = False}\\
	\While{Convergence == False}{
        {Calculate $\bm x^{\tau_{o}+1}_{o} = \arg\min_{\bm x_{o} \in \Omega} L^p\left(\{\bm x^0_n\}, \bm x_{o}, \{\bm\sigma^0_n\}\right)$}
        % = \arg\min_{\bm x_{o} \in \Omega} \frac{\sum^{\mathcal{N}}\rho_n}{2} \| \bm x_{o} - \frac{\sum^{\mathcal{N}}\rho_n \bm x^{\tau_{o}}_n + \sum^{\mathcal{N}}\bm\sigma^{\tau_{o}}_n}{\sum^{\mathcal{N}}\rho_n}\|^2$.}\\
        \eIf{$\eta\left(\bm x^{\tau_{o}}, \bm\sigma^{\tau_{o}}\right) < \epsilon^{ac}$}{
        {Convergence = True}\\
        {Send $\bm x^{\tau_{o}+1}_{o}$ and Convergence to all \textbf{users}}}
        {{Send $\bm x^{\tau_{o}+1}_{o}$ and Convergence to all \textbf{users}}\\
        {Wait for some fixed period of time}\\
        {Receive all the gradients $\{x^{\tau^r_n}_{n}\}$ and all the local time $\{\bm\tau^r_n\}$ from \textbf{users}}\\
        {Record the received users in $\mho^{\tau_{o}+1}$}\\
	    \eIf{$n \in \mho^{\tau_{o}+1}$}{
        {Select $\tau_n = \min \{\bm\tau^r_n\}$ and $\nabla G^{p,\tau_{o}+1}_n = x^{\tau^r_n}_{n}$}}
	{{Select $\nabla G^{p,\tau_{o}+1}_n = \nabla G^{p,\tau_{o}}_n$}}
	    
        {Calculate $\bm x^{\tau_{o}+1}_n = \bm x^{\tau_{o}+1}_o - \frac{1}{\rho_n} (\nabla G^{p,\tau_{o}+1}_n + \bm\sigma^{\tau_{o}}_n)$}\\
        {Calculate $\bm\sigma^{\tau_{o}+1}_n = \bm\sigma^{\tau_{o}}_n + \rho_n (\bm x^{\tau_{o}+1}_n + \bm x^{\tau_{o}+1}_o)$}\\
        {Update $\tau_{o} = \tau_{o} + 1$}}
	    }
	\KwOut{$\bm x^{\tau_{o}}_{o}$}
	    
	{/* USER Side */}\\
	\For{user $n\in\mathcal{N}$}{
	    {Initialize $\tau_n = 0$}\\
    	\While{Receive $\bm x^r$ and Convergence from \textbf{MEC}}{
    	\eIf{Convergence == False}{
    	{Select $\bm x^{\tau_{n}+1}_n = \bm x^r$}\\
    	{Calculate $\nabla g^{p}_n(\bm x^{\tau_{n}+1}_n)$}\\
        % according to Eq.\eqref{eq:FunctionGpnFirstOrder}
    	{Send $\nabla g^{p}_n(\bm x^{\tau_{n}+1}_n)$ and $(\tau_{n}+1)$} to \textbf{MEC} via the most reliable channel\\
    	{Update $\tau_{n} = \tau_{n} + 1$}\\}
    	{{Select $\bm x_n = \bm x^r$}\\
    	\KwOut{$\bm x_n$}}
    	}
	}
	 
\end{algorithm}
In the previous study, we proposed several synchronous parallel algorithms. Nevertheless, the reliability and effectiveness of these algorithms can be severely affected by communication failures and chaos resulting from faulty communication networks. Theorem \ref{theorem:innerConvergence1} reveals that Algorithm \ref{alg:nonconvexadmm} has a slow convergence speed, highlighting the need to replace it with a more communication-efficient alternative.
% In the work mentioned above, we developed numerous synchronous parallel algorithms. However, issues like chaos and communication loss brought on by faulty communication networks can lead to iterations in parallel algorithms failing, which has a significant impact on the robustness and effectiveness of the algorithms.
% According to the Lemma \ref{theorem:innerConvergence1}, the convergence speed of Algorithm \ref{alg:nonconvexadmm} is slow, and it is urgent to replace it with a communication-efficient algorithm.

% Instead of the Algorithm \ref{alg:nonconvexadmm}, Algorithm \ref{alg:AsynchronousADMM} guarantees that the iteration can still be successfully completed even if the server only collects updates from a limited number of users, which reduces complexity caused by unreliable channels.

First, the channel with the highest reliability rate is chosen to make sure that the iteration achieves the highest success rate (\ie $p^\mathit{max}_n = \max_c\{p_{n,c}\}$), in new Algorithm.
In doing so, the risk of communication iteration loss is intuitively reduced.
To ensure successful iterations in an asynchronous algorithm, there needs to be a limit on the number of communications required for each communication unit.
In order to satisfy the delay bound of iterations needed for successful communication $\Gamma_n$, we have $(1-p^\mathit{max}_n)^{\Gamma_n}<\epsilon^{a}$, where  $\epsilon^{a}$ is the maximum tolerance for asynchronous iterative communication. 
Both sides are logarithmic at the same time, it is $\Gamma_n \geq  \frac{ln(\epsilon^{a})}{ln(1-p^\mathit{max}_n)}$.
% Thus, we derive $\Gamma_n = \lceil \frac{ln(\epsilon^{a})}{ln(1-p^\mathit{max}_n)} \rceil$.
    \begin{assumption}
	\label{assumption:finiteCommunication}
	     The upper bound on the number of communications to complete a successful iteration satisfies
	    \begin{equation}
	        \Gamma_n = \left\lceil \frac{ln(\epsilon^{a})}{ln(1-p^{\mathit{max}}_n)} \right\rceil
	    \end{equation}
        where $\lceil x \rceil$  is the ceiling function of $x$.
    \end{assumption}
    % \item \textbf{Users with Limited Computing Resources}. 
    % Considering the possible computational resource constraints of users, we believe in assigning as few computational tasks as possible or designing them to be as simple as possible.
    % Since computational resources are limited, we aim to design as few tasks as possible while still taking into account the limitations of the users.
% \end{itemize}

% In addition, we give the asynchronous Algorithm \ref{alg:AsynchronousADMM} according to Algorithm \ref{alg:nonconvexadmm}, where for each iteration, each user computes the gradient based on the most recent information received from the server and sends it to the local server. The server collects all available iterations, finds the new value of $\bm x$, etc., and passes the latest information to the user. 
% Furthermore, considering the possible computational resource limitation of the user, we advocate assigning as few computational tasks as possible or designing as simple as possible.
Furthermore, we present an asynchronous variant of Algorithm \ref{alg:nonconvexadmm} as Algorithm \ref{alg:AsynchronousADMM}.  In each iteration, each user computes the gradient based on the most recently received information from the server and sends it to the local server.  
The server collects all available iterations, updates the value of $\bm x$, and passes the latest information back to the user.  
This asynchronous approach can help reduce communication overhead and improve convergence speed.
In addition, we recognize that users may have limited computational resources, and thus, we suggest assigning a minimal number of computational tasks or designing the tasks to be as simple as possible.

\textbf{Convergence Analysis:}
If Assumption \ref{assumption:finiteCommunication} is satisfied and we set $\rho_n>\max\{7\ell_n, \ell_n(\Gamma^2_n + \frac{3}{7}(\Gamma_n + 1)^2)\}$, the sequence $\{\{\bm x_n\}, \bm x\}$ in Algorithm \ref{alg:AsynchronousADMM} converges to the set of stationary solutions of problem, based on \cite[Theorem 3.1]{hong2017distributed}.
Moreover, for $\epsilon^{ac}>0$, we obtain
    \begin{equation}
        p^{\mathit{asysn}}\Gamma^{\mathit{asysn}}\epsilon^{ac} <k^{\Gamma}(L^{p}\left(\left\{\bm x_{n}^{1}\right\}, \bm x_{o}^{1}, \bm \sigma^{1}\right)-\underline{G}^{p}),
    \end{equation}
    where  
    $\epsilon^{ac}$ is a positive iteration factor, 
    $k^{\Gamma}$ is a constant, 
    % $p^\mathit{sysn} = \Pi_{n\in\mathcal{N}}(\frac{1}{C} \sum_{c\in\mathcal{C}}p_{n,c})$ probability of successfully completing a synchronous update,
    $\underline{G^{p}}$ is the lower bound of $\sum_{n\in\mathcal{N}} g^{p}_n(\bm x_n)$,
    % \ie $\underline{G^{p}} = \inf_{\bm x_n} \sum_{n\in\mathcal{N}} g^{p}_n(\bm x_n)$,
    $\Gamma^{sysn}$ is number of iterations, \ie,  
    $\Gamma^{sysn} = \min \left\{t\mid \eta\left(\bm x^t, \bm\sigma^t\right) \leq \epsilon, t \geq 0\right\}$, $p^{\mathit{asysn}} = 1 - \Pi_{n\in\mathcal{N}}(1-p^{\mathit{max}}_n)$ denote the probability that at least one communication unit communicates successfully in an iteration and
$p^{\mathit{asysn}}\Gamma^{\mathit{asysn}}$ represents the number of successful iterations.
Thus, we have
    \begin{equation}
         \Gamma^{\mathit{asysn}}<\frac{k^{\Gamma}(L^{p}\left(\left\{\bm x_{n}^{1}\right\}, \bm x_{o}^{1}, \bm \sigma^{1}\right)-\underline{G}^{p})}{\epsilon^{ac}p^{\mathit{asysn}}},
    \end{equation}
which means Algorithm \ref{alg:AsynchronousADMM} converge to an $\epsilon^{ac}$-stationary point within $O(1/(p^\mathit{asysn}\epsilon^\mathit{ac}))$.
Therefore, we derive that the asynchronous parallel algorithm is approximately $p_\mathit{asysn}/p_\mathit{sysn}$ times faster, in comparison to the synchronous parallel approach according to Theorem \ref{theorem:innerConvergence1}.
The value of $p_\mathit{asysn}/p_\mathit{sysn}$ is greater than 1, and it increases as the channel quality declines.
    % If $\rho_n>\max\{7\ell_n, \ell_n\left(\Gamma^2_n + \frac{3}{7}(\Gamma_n + 1)^2\right)\}$, the non-convex ADMM-Consensus method in Algorithm \ref{alg:AsynchronousADMM} converges and achieves global sub-linear convergence rate
    % \begin{equation}
    %     \Gamma^{\mathit{asysn}}<\frac{k^{\Gamma}(L^{p}\left(\left\{\bm x_{n}^{1}\right\}, \bm x_{o}^{1}, \bm \sigma^{1}\right)-\underline{G^{p}})}{\epsilon^{ac} p^{\mathit{asysn}}},
    % \end{equation}
    % where $p^{\mathit{asysn}} = 1 - \Pi_{n\in\mathcal{N}}(1-p^{\mathit{max}}_n)$.
    % For more detailed information, please refer to Appendix \ref{app:theorem:innerConvergence2}.
    

Convergence analysis shows that Algorithm \ref{alg:AsynchronousADMM} converges faster than Algorithm    \ref{alg:nonconvexadmm}, particularly when transmission reliability is low.
Furthermore, we demonstrate the effectiveness of the asynchronous algorithm through numerous simulation experiments.

% \textbf{Complexity}
% Here, we define $N^{ec}$ as the required number of iterations by the checkpointing algorithm to reach convergence. According to Lemma \ref{theorem:innerConvergence2}, $\frac{1}{\epsilon_\mathit{min}}$ is the number of iterations in the inner convergence, where $\epsilon_\mathit{min} = \mathop{\min}_{n} \{\epsilon_{n}\}$. It means that we can obtain the strategy via Algorithm \ref{alg:NFP} and Algorithm \ref{alg:AsynchronousADMM} with the worst complexity of $O(\frac{N^{ec}}{\epsilon_\mathit{min}})$.
% The complexity of the overall algorithm discussed as follows. The iterative algorithm for sloving \textbf{P2} via the external (\ie Algorithm \ref{alg:NFP})  and internal circulation (\ie Algorithm \ref{alg:AsynchronousADMM}) .
% \subsubsection{Task Migration in Multi-Servers\label{subsubsec:Data-Migration}}
% To minimize the age of the information, we will migration task from the local MEC to other free MEC.

\subsection{Why Multi-Class Priority?}
% Many multi-priority efforts focus on scenarios where each user has a predetermined level of priority \cite{huang2015optimizing,xu2020peak,maatouk2019age}. While this approach appears straightforward and easy to implement, it has certain limitations that may result in the unjust treatment of users with similar priorities.
% Consider, for instance, situations where users who should be treated equally are given lower priorities. This would go against the principles of fairness and equality that multi-priority systems are intended to uphold.

% To ensure fairness in allocation, our multi-priority user model can handle different scenarios, including cases where users have unequal priorities or where multiple users share the same priority level.  This type of model is known as a multi-class priority model.
% Specifically, when each user has a distinct level of priority, it can be considered a subset or special case of multi-class priority.  In such cases, our model aims to prevent unfair treatment of users with similar priorities by allocating available resources more equitably.

Many multi-priority systems focus on scenarios where each user has a predetermined priority level, which can lead to the unjust treatment of users with similar priorities \cite{huang2015optimizing,xu2020peak,maatouk2019age}. This may undermine the principles of fairness and equality that these systems are intended to uphold. However, our multi-priority model can extend to handle different scenarios to promote fair allocation, including cases where users have unequal priorities or where multiple users share the same priority level. This model, known as a multi-class priority, aims to prevent unfair treatment of users with similar priorities by allocating resources equitably.
Next, we intend to discuss what are the benefits of our proposed multi-class priority mechanism compared to the common multi-priority and no-priority mechanisms.

% The unique priority of each user in multi-priority events has been extensively studied in the existing literature \cite{xu2020peak}. 
% But clearly, this is unfair to various users who should have been given equal priority but are given relatively low priorities. 
    % Each user in the system has a unique priority in multi-priority events, a situation that has been covered in existing literature \cite{xu2020peak}. But clearly, this is unfair to various users who ought to be given equal priority but are given relatively low priorities. We, therefore, take this issue into account when talking about the multi-class priority case. In turn, multi-priority can be considered as a special case of multi-class priority.
% \end{remark}
% Specifically, we compare the information freshness of users with different priority levels and users with a single priority (\ie no-priority mechanism) using the same offloading strategy.
% \begin{lemma}
% \label{proof:sp-mp}
The PAoI of user $n*$, who are set to the highest priority, has more optimal information freshness than the priority-free case under the same offloading strategy, which is
\begin{align}
    &\mathbb{E}[A_{n^*}] - \mathbb{E}[A^{p}_{n^*}]\nonumber\\
    = &\Upsilon(\bm\eta^u) \frac{\zeta_{\Delta}(\bm\eta^u)-\zeta_{\delta(n^*)}(\bm\eta^u)}{(1-\zeta_{\Delta}(\bm\eta^u))(1-\zeta_{\delta(n^*)}(\bm\eta^u))}
    \geq 0.
\end{align}
where 
$\zeta_{\delta(n^*)}(\bm\eta^u) =\sum_{\delta\in\Delta(\delta(n^*))}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\frac{\eta^u_{n',c}\lambda_{n'}}{\mu_{n'}}$,  
$\zeta_{\Delta}(\bm\eta^u) =\sum_{\delta\in\Delta}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\frac{\eta^u_{n',c}\lambda_{n'}}{\mu_{n'}}$,  and
$\Upsilon(\bm\eta^u) = \frac{1}{2}\sum_{\delta\in\Delta}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\eta^u_{n',c}\lambda_{n'}\nu_{n'}$.
Similarly, the PAoI of user $n_*$, who is set to have the lowest priority, has a worse PAoI than the priority-free case. Thus, we gain
\begin{align}
    &\mathbb{E}[A_{n_*}] - \mathbb{E}[A^{p}_{n_*}] \nonumber\\
    =& \frac{\Upsilon(\bm\eta^u)} {1-\zeta_{\Delta}(\bm\eta^u)}(1-\frac{1}{1-\zeta_{\delta(n)-1}(\bm\eta^u)})
    \leq 0.
\end{align}

Furthermore, multiple users are assumed to have the same priority level, but are instead assigned priorities of $\delta^0$ and $\delta^0-\hat\delta$ in the multi-priority scenario, the resulting difference in freshness can be substantial and unfair:
\begin{align}
    &\mathbb{E}[A^{p}_{n}|\delta(n)=\delta^0] - \mathbb{E}[A^{p}_{n}|\delta(n)=\delta^0-\hat\delta]\nonumber\\
    \ge& \frac{\Upsilon(\bm\eta^u)(\zeta_{\delta^0}(\bm\eta^u)-\zeta_{\delta^0 - \hat\delta - 1}(\bm\eta^u))}{(1-\zeta_{\delta^0}(\bm\eta^u))(1-\zeta_{\delta^0 - 1}(\bm\eta^u))(1-\zeta_{\delta^0 - \hat\delta - 1}(\bm\eta^u))}\nonumber\\
    % &- \frac{\Upsilon(\bm\eta^u)}{(1-\zeta_{\delta^0 - \hat\delta}(\bm\eta^u))(1-\zeta_{\delta^0 - \hat\delta - 1}(\bm\eta^u))} \nonumber\\
    \geq& 0.
\end{align}

% \end{lemma}
For more proof details, please refer to Appendix \ref{app:proof:sp-mp} of technical report \cite{Nan2023}.
% \end{proof}
This subsection shows that user $n$ can get superior performance as compared to priority-free by allocating it a high priority. 
Giving user $n$ a greater priority in multi-class priority also enhances its performance.




\section{Simulation}\label{sec:simulation}
In this section, we evaluate our proposed algorithm by answering the following questions:
\begin{enumerate}
    \item What is its achievable utility in task scheduling?
    \item Can it schedule multi-priority tasks effectively?
    % \item How does PoPeC perform with different quality of service (\S \ref{subsec:Exp-ServiceQuality})?
    % \item Can PoPeC obtain the scheduling policy efficiently and reliably in heterogeneous unreliable channels(\S \ref{subsec:Exp-ServiceQuality})?
    \item Can it deal with heterogeneous and  unreliable channels effectively?
\end{enumerate}





\subsection{Experimental Setup}\label{subsec:Exp-Setup}

\textit{\textbf{Experimental setup.}}
% We conducted extensive simulations to assess the efficacy, performance, and computational efficiency of our proposed method.  To this end, we considered a priority-free case consisting of $M = 10$ servers and $N = 200$ users within their respective coverage regions.  For the multi-priority case, we considered a minimum of three priorities, and users were allocated to different priority levels.  
In this section, we carry out simulations to  evaluate the effectiveness, performance, and computational efficiency of our proposed method. In the priority-free case, we consider 10 servers and 200 users within their respective coverage areas. For the multi-priority case, we examine at least three priorities, allocating users to different priority levels. 
Moreover, we model the transmission success probability of the channel as a Gaussian distribution $N(0.5,1)$, following \cite{scutari2008asynchronous}.  We set the number of available channels $C$ to be 30, with a bandwidth of $B = 5 MHz$, and channel gains were set to unity as in \cite{balasubramanian2009energy}.  
% Given the heterogeneity of users and servers, the service time of tasks was assumed to follow a general distribution, where the mean and variance of the distribution were determined by the types of users and servers.  
To account for the heterogeneity of users and servers, the service time of tasks followed a general distribution, where the mean and variance of the distribution are determined by the types of users and servers. Specifically, we set the value of the mean and variance of the general distribution to follow the uniform distribution $U(1,5)$ and $U(1,25)$, respectively.
% We use extensive simulations to evaluate the cost, performance, and computation time of our method. 
% We consider a priority-free case with $M = 10$ servers and $N = 200$ users in its coverage regions. In the multi-class priority case, there are at least three priorities, and users are divided into various priorities. Moreover, the transmission success probability of the channel is regarded as a Gauss distribution $N(0.5,1)$\cite{scutari2008asynchronous}.
% We set the number of channels $C$ as 30. Furthermore, the channel bandwidth is set to $B = 5 MHz$, and the channel gains are set to 1 \cite{balasubramanian2009energy}. Due to the heterogeneity of users and servers, the service time of tasks should follow a general distribution, and the mean and variance of the general distribution are related to the types of users and servers. We set the mean and variance of the general distribution to follow $U(1,5)$ and $U(1,25)$, respectively.

\begin{table}[htpb]
	\caption{Parameters in Simulation}
	\label{table:parameters}
	\centering
	\renewcommand\arraystretch{1.25}
	\resizebox{\columnwidth}{!}{
	\begin{tabular}{l|l}
		\hline
		\textbf{Parameter} & \textbf{Value}\\ 
		\hline
		\# users ($N$) & an integer varying between $[1,200]$\\
		\# channels ($C$) & an integer varying between $[1,30]$\\
		\# servers ($M$) & an integer varying between $[1,10]$\\
		the channel condition & 
		    \begin{tabular}[c]{@{}l@{}}
		        channel bandwidth ($B$) as 5MHz\\
		        channel gains ($R_c$) as 1\\
		    \end{tabular} \\
		the service time & 
		    \begin{tabular}[c]{@{}l@{}}
		        obey the general distribution\\
		        with the mean $\mu$ following $U(1,5)$, \\ 
		        and the variance $\nu$ following $U(1,25)$, respectively
		    \end{tabular} \\                  
		the transmission rates  & real numbers (Mbit/slot) varying between $[0,0.5]$\\
		task generation rates & real numbers (Mbit/slot) following $U(0.5,1.5)$ \\                                           \hline
	\end{tabular}
	}
\end{table}

\textit{\textbf{Baselines.}}
We compare our proposed algorithm with existing algorithms in the literature to perform a comprehensive analysis. Specifically, we compare our method with the Age-Aware Policy (AAP) algorithm which utilizes throughput constraints through the Lyapunov optimization method \cite{sun2021age}. We also consider the Greedy Control Algorithm (GA), which selects the most reliable channel among the unreliable channels. Additionally, to account for the lack of priority mechanism in AAP and GA, we compare our algorithm with the Priority Scheduling method of Peak Age of Information in Priority Queueing Systems (PAUSE) \cite{xu2020peak} and the Rate and Age of Information (RAI) method \cite{abdollahi2022rate}.
To ensure a fair comparison, we assume that each user sends the maximum possible number of tasks to the edge server, and the edge server completes the tasks in a First-Come-First-Serve (FCFS) manner.
% We compare our proposed algorithm with the algorithm which develops an Age-Aware Policy (AAP) with throughput constraints based on the Lyapunov optimization method in \cite{sun2021age}. We also consider a greedy control algorithm (GA) to select the most reliable channel in each unreliable channel. Consider the case where each user sends as many tasks as possible to the edge server, and the edge server completes the task with FCFS. Due to the lack of priority mechanism in AAP and GA, we also refer to the priority scheduling method of Peak Age of Information in Priority Queueing Systems (PAUSE) \cite{xu2020peak} and Rate and Age of Information (RAI)\cite{abdollahi2022rate}.

\textit{\textbf{Implementation.}}
The simulation platform is Matlab R2019a and all the simulations are performed on a laptop with 2.5 GHz Intel Core i7 and 16 GB RAM.

\subsection{Overall Utility}\label{subsec:Exp-Utility}
In the assessment of the overall utility, we conducted an analysis of various metrics, such as PAoI and throughput, under different methods, and examined their performance in various settings, including priority allocation and server collaboration.

Firstly, as depicted in Fig.\ref{fig:PTvsN} and \ref{fig:PTvsM}, our evaluation shows that the number of users $N$ and channel capacity $M$ significantly impact the PAoI value and throughput. Our proposed algorithm (OUR) outperforms both the Greedy Control Algorithm (GA) and the Age-Aware Policy (AAP) algorithm, especially in terms of PAoI. However, in resource-constrained environments, specifically in Fig.\ref{fig:PTvsM}, our algorithm's throughput performance is slightly inferior since it does not have the same higher needs and throughput constraints as the (AAP) algorithm.
% In the analysis of overall utility, we not only evaluated the differences in various metrics (such as PAoI and throughput) under different methods but also investigated the performance in various settings (including priority allocation, and server collaboration).

% First, as can be shown in Fig.\ref{fig:PTvsN} and \ref{fig:PTvsM}, the number of users $N$ and the channel capacity $M$ both significantly affect the PAoI value and throughput.
% Our algorithm (OUR) performs noticeably better in terms of PAoI and throughput compared to (GA) and (AAP) algorithms, especially for PAoI.
% However, in the situation of constrained resources, particularly in Fig.\ref{fig:PTvsM}, our approach's throughput performance is marginally worse since it does not have the same higher needs and throughput constraints as the (AAP) algorithm.
\begin{figure}[ht!]
	\centering
	\subfigure[PAoI \& Throughout vs. $N$]{\label{fig:PTvsN}\includegraphics[width=0.225\textwidth]{./figure/Graph2-3.pdf}}
	\subfigure[PAoI \& Throughout vs. $M$]{\label{fig:PTvsM}\includegraphics[width=0.225\textwidth]{./figure/Graph2-4.pdf}}
	\caption{Impact of different methods on various metrics.}
    % \vspace{-4pt}
\end{figure}

In the second analysis, we conducted a simulation for the multi-priority case, as illustrated in Fig.\ref{fig:PAoIvsMu}. Here, $\Delta$ denotes the degree of priority breakdown, with $\Delta=1$ indicating no priority distinction and $\Delta=6$ indicating six priority classes. The simulation results show that the average PAoI of the system is mainly determined by the computing power of the server ($\mu$, task execution time), and the priority division level has little influence on it.
Furthermore, we investigated multi-server collaboration cases and found that multi-server coordination is feasible and can significantly reduce the task execution time without affecting the update frequency. Fig.\ref{fig:PAoIvsN} presents the results for both single-server execution and multi-server collaboration cases, showing that multi-server collaboration outperforms the single-server case regardless of the number of users. This advantage is more prominent as the number of users increases.

% Secondly, for the multi-class priority scenario, the simulation in Fig.\ref{fig:PAoIvsMu} generalizes the algorithm to the multi-class first scenario. The value of $\Delta$ represents the degree of priority breakdown, with $\Delta=1$ indicating no priority distinction and $\Delta=6$ indicating six priority classes. The final results show that the average PAoI of the system is related to the computing power of the server ($\mu$, task execution time), and  has little to do with the priority division level.
% For multi-server collaboration scenarios, multi-server coordination is actually feasible because it significantly reduces the task execution time without affecting the update frequency.  
% In Fig.\ref{fig:PAoIvsN}, we consider two cases: single-server execution and multi-server collaboration, in which can be found that regardless of the number of users, the multi-server collaboration is always better than the single-server case, and the advantage is more obvious as the number of users increases.

\begin{figure}[ht!]
	\centering
	\subfigure[PAoI vs. $\mu$ in different priority allocation case]{\label{fig:PAoIvsMu}\includegraphics[width=0.225\textwidth]{./figure/Graph2-1.pdf}}
	\subfigure[PAoI vs. $N$ in the case of whether servers are collaborating]{\label{fig:PAoIvsN}\includegraphics[width=0.225\textwidth]{./figure/Graph2-2.pdf}}
	\caption{The performance in various settings.}
    % \vspace{-4pt}
\end{figure}


% \begin{figure}[ht!]
%     \vspace{-0cm} 
%     \setlength{\abovecaptionskip}{-0cm} 
%     \setlength{\belowcaptionskip}{-0cm} 
%     \centering
%     \includegraphics[width=0.275\textwidth]{./figure/Graph2-2.pdf}
%     \vspace{-0pt}
%     \caption{PAoI vs. $N$}
%     \label{fig:2.2}
%     \vspace{-18pt}
% \end{figure}




\subsection{Performance of Priority Users}\label{subsec:Exp-Priority}

Simulation results show that the proposed algorithm can be extended to multi-class priority scenarios.
We set three priority classes ($\delta$ lower, higher priority) and randomly assigned them to a number of users in our simulation Fig.\ref{fig:PAoIvsNinServers}.
As the iterations of our algorithm proceed, the average PAoI values of users with various priority levels steadily increase and eventually tend to stabilize, and the offloading rate gradually decreases and eventually tends to be stable.
We discover that users with higher priority always receive more channel allocations, which results in higher offloading rates.
Additionally, high-priority users' PAoI values are lower since they are more likely to finish their tasks promptly.

\begin{figure}[ht!]
	\centering
	\subfigure[Performance of users with different priorities]{\label{fig:PAoIvsNinServers}\includegraphics[width=0.25\textwidth]{./figure/Graph3-1.pdf}}
	\subfigure[Comparison of high priority users in different algorithms]{\label{fig:mp-compare}\includegraphics[width=0.205\textwidth]{./figure/Graph3-2.pdf}}
	\caption{Performance of Priority Users}
    % \vspace{-4pt}
\end{figure}

% \begin{figure}[ht!]
%     \vspace{-0cm} 
%     \setlength{\abovecaptionskip}{-0cm} 
%     \setlength{\belowcaptionskip}{-0cm} 
%     \centering
% 	\includegraphics[width=0.275\textwidth]{./figure/Graph3-1.pdf}
% 	\caption{Performance of users with different priorities}
%     \vspace{-0pt}
%     \label{fig:PAoIvsNinServers}
%     \vspace{-9pt}
% \end{figure}

With three types of priorities (high priority, medium priority, low priority), we compare the proposed multi-class priority method (OUR) with other algorithms (GA, PAUSE, RAI), and we pay special attention to the promotion effect of our algorithm for high-priority users, as shown in Fig.\ref{fig:mp-compare}.
The (GA) algorithm is one that does not consider priorities, the (PAUSE) algorithm focuses on the discussion of multiple priorities rather than multiple classes of priorities, and the (RAI) algorithm only considers two classes of priorities.
The PAoI values of the high-priority users all decrease in the simulation as the server processing rate $\mu$ rises, clearly stating that the suggested strategy (OUR) is the best one.

% \begin{figure}[ht!]
%     \vspace{-0cm} 
%     \setlength{\abovecaptionskip}{-0cm} 
%     \setlength{\belowcaptionskip}{-0cm} 
%     \centering
% 	\includegraphics[width=0.275\textwidth]{./figure/Graph3-2.pdf}
% 	\caption{Compare with different algorithms in multi-class priority case}
%     \vspace{-0pt}
%     \label{fig:mp-compare}
%     \vspace{-9pt}
% \end{figure}



% \subsection{The Impact of Service Quality}\label{subsec:Exp-ServiceQuality}

\subsection{Convergence Rate of the Algorithm in Unreliable Channels}\label{subsec:Exp-Converge}
In this part, our experiments study the influence of the unreliable channel on the PAoI value and the convergence performance of different algorithms including (NFPA-NAC) and (NFPA-ANAC) in the unreliable channel.

Both NFPA-NAC in Fig.\ref{fig:NFPA-NAC} and NFPA-ANAC in Fig.\ref{fig:NFPA-ANAC} are advantageous for implementing powerful edge servers due to their ability to allocate channel and task scheduling resources efficiently. 
However, the lack of communication resources can prevent the development of more efficient systems.
We show the performance of algorithms NFPA-NAC and NFPA-ANAC in different channel conditions ($p=0.3, 0.5, 0.7, 0.9$) in Fig.\ref{fig:NFPA-NAC} and Fig.\ref{fig:NFPA-ANAC} without repeated experiments.
We observe that the PAoI values gradually decline and eventually stabilize as the iterations proceed.
Moreover, the lower the value of channel condition $p$, the slower the convergence rate.
Additionally, it can be observed that PAoI can be more optimal with better channel conditions because users have more options for offloading.
We note that in our simulations the algorithm NFPA-NAC cannot successfully iterate in each iteration, while NFPA-ANAC can successfully iterate using the limited information in each iteration. 


\begin{figure}[ht!]
	\centering
	\subfigure[NFPA-NAC]{\label{fig:NFPA-NAC}\includegraphics[width=0.235\textwidth]{./figure/Graph5-sysn.pdf}}
	\subfigure[NFPA-ANAC]{\label{fig:NFPA-ANAC}\includegraphics[width=0.235\textwidth]{./figure/Graph5-asysn.pdf}}
	\caption{The influence of the unreliable channel on the PAoI}
	\label{fig:5}
\end{figure}

To illustrate the difference between the two algorithms NFPA-NAC and NFPA-ANAC more systematically,
Fig.\ref{fig:compare} with various channel conditions ($p=0.7, 0.8, 0.9, 0.99$) compares the convergence of the two algorithms.
In contrast to Fig.\ref{fig:5}, we choose a better initial value, more users, and a large number of repeated experiments to help explain the convergence characteristics.
Both methods have similar rates of convergence in acceptable channels ($p=0.9, 0.99$).
However, the convergence rate advantage of algorithm NFPA-ANAC, however, is fairly apparent in the ($p=0.7, 0.8$) channel because of the poorer channel quality.

\begin{figure}[ht!]
    \vspace{-0cm} 
    \setlength{\abovecaptionskip}{-0cm} 
    \setlength{\belowcaptionskip}{-0cm} 
    \centering
	\includegraphics[width=0.45\textwidth]{./figure/Graph5-compare.pdf}
    \vspace{-0pt}
	\caption{Compare with different algorithms}
	\label{fig:compare}
    % \vspace{-18pt}
\end{figure}







% \subsection{The impact of channel reliability and channel capacity on channel assignment}
% % \begin{figure}[ht!]
% % 	\centering
% % 	\subfigure[Channel assignment in sufficient channel capacity.]{\label{fig:Graph-sinP-enC}\includegraphics[width=0.225\textwidth]{./figure/Graph-sinP-enC.pdf}}
% % 	\subfigure[Channel assignment in insufficient channel capacity.]{\label{fig:Graph-sinP-noC}\includegraphics[width=0.225\textwidth]{./figure/Graph-sinP-noC.pdf}}
% % 	\caption{Channel assignment in priority-free users}
% % 	\label{fig:1}
% % \end{figure}

% \textbf{Channel Reliability}
% We set four heterogeneous channels with their average channel reliability of 0.3,0.5,0.7,0.9. Without loss of generality, the channel reliability varies for different users. As shown in Fig. 1(a), with sufficient channel capacity, there is a tendency to give the task with greater probability to the channel with high channel reliability, but different users are directly assigned with basically equal probability.

% \textbf{Channel Capacity}
% In the comparison between Fig. 1(a) and Fig. 1(b), if it is found that there exists insufficient channel capacity to satisfy all users, although the logic of users in channel selection is the same as in the scenario of sufficient channel capacity, the competition for the same channel among different users is more intense due to the channel limitation.



% \subsection{The impact of multi-priority users in channel assignment}
% % \begin{figure}[ht!]
% % 	\centering
% % 	\subfigure{\label{subfig:comp_utility}\includegraphics[width=0.225\textwidth]{./figure/Graph-mulP.pdf}}
% % 	\caption{Channel assignment in multi-priority users.}
% % 	\label{fig:2}
% % \end{figure}


% \subsection{Utility performance in the multi-priority scenarios}








% \subsection{The performance of different algorithms}


\section{Conclusion}\label{sec:conclusion}
In this paper, we proposed a scheduling method that considered multi-priority users and multi-server collaboration to address the limitations of unreliable channels in current real-time systems and the individual needs of users.
We derived the utility function of priority scheduling based on PAoI and designed a set of distributed optimization methods.
Specifically, we first consider two simplified problems for the original problem and employ the fractional programming as well as ADMM to obtain their solutions. Building upon these solutions and conclusions drawn therein, we develop an iterative algorithm to solve the original problem. Furthermore, we proposed an distributed asynchronous approach with a sublinear rate of communication defects and discuss the theoretical performance improvement due to the multi-priority mechanism. We implemented the method and conducted extensive simulations to compare it with the existing age-based scheduling strategies. Our results demonstrated the effectiveness and superiority of our method in addressing the requirements of freshness-sensitive users over unreliable channels.
% In this paper, we point out the limitations of unreliable channels in current real-time systems and introduce PoPeC, a scheduling method under multi-class priority and multi-server cooperation.
% We prove and derive the utility function of priority scheduling based on PAoI, and design a set of distributed optimization methods, that is, using a fractional programming transformation problem and ADMM response solution mechanism, to obtain the scheduling strategy. In order to reduce the loss caused by the unreliable channel iteration, we designed the asynchronous ADMM algorithm and proved that its convergence property is better than the conventional ADMM.
% We implemented PoPeC and conducted an extensive evaluation to show how PoPeC compares to other current age-based scheduling strategies.

% \twocolumn

% \clear
\normalem
\bibliographystyle{IEEEtran}
\bibliography{reference}



%\vskip -20pt plus -1fil



\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{./author-photos/nanqiao.jpg}}]{Nan Qiao}
received the B.Sc. in Computer Science from Central South University, China. Since Sept. 2021, he has been pursuing the Ph.D. degree in Computer Science from Central South University, China. His research interests include wireless communications, distributed optimization, and Internet-of-Things.
\end{IEEEbiography}
\vskip -20pt plus -1fil

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{./author-photos/shengyue.jpg}}]{Sheng Yue}
received his B.Sc. in mathematics (2017) and Ph.D. in computer science (2022), from Central South University, China. Currently, he is a postdoc with the Department of Computer Science and Technology, Tsinghua University, China. His research interests include network optimization, distributed learning, and reinforcement learning.
\end{IEEEbiography}
\vskip -20pt plus -1fil

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{./author-photos/yongminzhang.jpg}}]{Yongmin Zhang} 
(Senior Member, IEEE) received the PhD degree in control science and engineering in 2015, from Zhejiang University, Hangzhou, China. From 2015 to 2019, he was a postdoctoral research fellow in the Department of Electrical and Computer Engineering at the University of Victoria, BC, Canada. He is currently a Professor in the School of Computer Science and Engineering at the Central South University, Changsha, China. His research interests include IoTs, Smart Grid, and Mobile Computing. He won the best paper award of IEEE PIMRC 2012 and the IEEE Asia-Pacific (AP) outstanding paper award 2018.
\end{IEEEbiography}
\vskip -20pt plus -1fil

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{./author-photos/juren.jpg}}]{Ju Ren}
(Senior Member, IEEE) received the B.Sc. (2009), M.Sc. (2012), Ph.D. (2016) degrees all in computer science, from Central South University, China. Currently, he is an associate professor with the Department of Computer Science and Technology, Tsinghua University, China. His research interests include Internet-of-Things, edge computing, edge intelligence, as well as security and privacy. 

He currently serves as an associate editor for many journals, including IEEE Transactions on Cloud Computing and IEEE Transactions on Vehicular Technology, etc. He also served as the general co-chair for IEEE BigDataSE20, the TPC co-chair for IEEE BigDataSE19, the publicity co-chair for IEEE ICDCS22, the poster co-chair for IEEE MASS18, a symposium co-chair for IEEE/CIC ICCC23\&19, I-SPAN18 and IEEE VTC17 Fall, etc. He received many best paper awards from IEEE flagship conferences, including IEEE ICC19 and IEEE HPCC19, etc., the IEEE TCSC Early Career Researcher Award (2019), and the IEEE ComSoc Asia-Pacific Best Young Researcher Award (2021). He was recognized as a highly cited researcher by Clarivate (2020-2022).
\end{IEEEbiography}
\vskip -20pt plus -1fil

\clearpage
% \onecolumn
\begin{appendices}
% \section{A Proof of Lemma \ref{lemma:confidence_interval}}\label{app:lemma:confidence_interval}
% We prove Lemma \ref{lemma:confidence_interval} here.
% \begin{proof}
%     Since the number of packets offloaded to the channel obeys a Poisson distribution, it is not a stable value. But in order to guarantee that, at each slot t, there is a maximum capacity of the channel that is not smaller than the current moment, \ie $\chi_{c}(t) < M_c^\mathit{max}$
%     According to the properties of the cumulative distribution function of the Poisson distribution \cite{patil2012comparison}, we have $\sum_{n\in\mathcal{N}} \eta^u_{n,c}\lambda_{n} + z^2_{1}/2 + z_{2}\sqrt{\sum_{n\in\mathcal{N}} \eta^u_{n,c}\lambda_{n} + z^2_{2}/4} \le M_c^\mathit{max}$. The proof is completed.
% \end{proof}

\section{}\label{app:pro:paoi_mg1_pri}
    % We prove Proposition \ref{pro:paoi_mg1_pri} here.

    The previous have investigated $\mathbb{E}[T^{p}_{n}]$, $\mathbb{E}[I^{p}_{n}]$ and $\mathbb{E}[Y^{p}_{n}]$ too much, 
    with $\mathbb{E}[Y^{p}_{n}]=1/\mu_n$ being the processing time, $\mathbb{E}[T^{p}_{n}]=T^\mathit{tr}_{n,c}$  the maximum transmission time over all possible channels, 
    and $\mathbb{E}[I^{p}_{n}] = 1/\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}$ the arrival interval \cite{yates2021age}.
    % remain the same values as \eqref{eq:paoi-expectation2}.
    Also, some studies discuss the waiting time $\mathbb{E}[W]$ in the condition multi-class M/G/1\cite{huang2015optimizing} or M/G/1 with priority\cite{xu2020peak}. However, we focus more on the value of $\mathbb{E}[W]$ in multi-class M/G/1 with priority, which means there are a number of different types of users in a unified priority in the M/G/1 system.
    According to Little's Law,
    \begin{align}
        \mathbb{E}[L_{i}] = \lambda_i \mathbb{E}[W_{i}].
    \end{align}
    For the highest priority users \ie $\delta=1$, it holds
    \begin{align}
        \mathbb{E}[W_{\delta=1}] 
        &= \sum_{i \in \mathcal{N}^{1}} \frac{\mathbb{E}[L_i]}{\mu_i} + \sum_{i \in \mathcal{N}} \rho_i \mathbb{E}[\nu^{2}_i]\nonumber\\
        &= \sum_{i \in \mathcal{N}^{1}} \rho_i \mathbb{E}[W_i] + \sum_{i \in \mathcal{N}} \rho_i \mathbb{E}[\nu^{2}_i]
    \end{align}
    where $\mathbb{E}[W_{\delta=1}] = \mathbb{E}[W_i], ~ \forall ~ \delta(i) = 1$. Accordingly, we obtain
    \begin{align}
    \label{eq:WaitingTime-HPU}
        \mathbb{E}[W_{\delta=1}] 
        = \frac{\sum_{i \in \mathcal{N}} \rho_i \mathbb{E}[\nu^{2}_i]}{1 - \sum_{i \in \mathcal{N}^{1}} \rho_i}
    \end{align}

     We separate $\mathbb{E}[W]$ into different components in order to break it down into smaller parts.  The first component consists of all high-priority or identically prioritized jobs that are in the queue when the current task arrives.  The waiting time for this component is $\mathbb{E}[S^1]$.  The second component, consisting of all high-priority users who arrived at the same time as the first component was executed, has a waiting time of $\mathbb{E}[S^2]$.  We continue to split the remaining portions in the same way.
    % We separate $\mathbb{E}[W]$ into several portions. The total number of high-priority or identically prioritized jobs in the queue at the moment the current task arrived makes up the first component, and its waiting time is $\mathbb{E}[S^1]$. The second portion has a waiting time of $\mathbb{E}[S^2]$ and is made up of all high-priority users who arrived at the same time as the first part was executed. The succeeding contents are also split in this manner.
    
    % We divide $\mathbb{E}[W]$ into several parts. The first part consists of the sum of all tasks of high priority or the same priority waiting in the queue at the time of arrival of the current task, and its waiting time is $\mathbb{E}[S^1]$. The second part consists of the sum of all users of high priority arriving at the time of execution of the first part, and its waiting time is $\mathbb{E}[S^2]$. The subsequent parts are divided according to similar way. Thus, we have
    \begin{align}
        \mathbb{E}[W_i] = \mathbb{E}[S^1_i + S^2_i + S^3_i + \cdots] = \sum^{\infty}_{k} \mathbb{E}[S^k_i]
    \end{align}
    
    Based on the above discussion, we derive the waiting time for the first part,
    \begin{align}
        \mathbb{E}[S^1_i] = \sum_{p=1}^{\delta(i)} \sum_{j  \in \mathcal{N}^{p}} \rho_j \mathbb{E}[W_j] + \sum_{j \in \mathcal{N}} \rho_j \mathbb{E}[\nu^{2}_j]
    \end{align}
    The waiting time for the other part is as follows,
    \begin{align}
        E[S^{k+1}_i] &=\int_{s=0}^{\infty} E[S^{k+1}_i \mid S^{k}_i=s] f_{k}(s) d s \nonumber\\
        &=\int_{s=0}^{\infty} \sum_{p=1}^{\delta(i)-1} \sum_{j  \in \mathcal{N}^{p}}  \rho_j s  f_{k}(s) d s \nonumber\\
        &=\left(\sum_{p=1}^{\delta(i)-1} \sum_{j  \in \mathcal{N}^{p}}  \rho_j\right) E[S^{k}_i] \nonumber\\
        &=\left(\sum_{p=1}^{\delta(i)-1} \sum_{j  \in \mathcal{N}^{p}}  \rho_j\right)^k E[S^{1}_i]
    \end{align}
    Thus, we derive
    \begin{align}
        \mathbb{E}[W_i] &= \frac{\mathbb{E}[S^1_i]}{1 - \sum_{p=1}^{\delta(i)-1} \sum_{j  \in \mathcal{N}^{p}}  \rho_j}\nonumber\\ 
        &= \frac{\sum_{p=1}^{\delta(i)} \sum_{j  \in \mathcal{N}^{p}} \rho_j \mathbb{E}[W_j] + \sum_{j \in \mathcal{N}} \rho_j \mathbb{E}[\nu^{2}_j]}{1 - \sum_{p=1}^{\delta(i)-1} \sum_{j  \in \mathcal{N}^{p}}  \rho_j}
    \end{align}
    which can be transformed into
    \begin{align}
        \mathbb{E}[W_i](1 - \sum_{p=1}^{\delta(i)-1} \sum_{j \in \mathcal{N}^{p}}  \rho_j)\nonumber\\
        = \sum_{p=1}^{\delta(i)} \sum_{j  \in \mathcal{N}^{p}} \rho_j \mathbb{E}[W_j] + \sum_{j \in \mathcal{N}} \rho_j \mathbb{E}[\nu^{2}_j]
    \end{align}
    and
    \begin{align}
        \mathbb{E}[W_{\delta=\delta(i)}](1 - \sum_{p=1}^{\delta(i)} \sum_{j  \in \mathcal{N}^{p}}  \rho_j)\nonumber\\
        = \sum_{p=1}^{\delta(i)-1} \sum_{j  \in \mathcal{N}^{p}} \rho_j \mathbb{E}[W_j] + \sum_{j \in \mathcal{N}} \rho_j \mathbb{E}[\nu^{2}_j]\nonumber\\
        = \mathbb{E}[W_{\delta=\delta(i)-1}](1 - \sum_{p=1}^{\delta(i)-2} \sum_{j  \in \mathcal{N}^{p}}  \rho_j)
    \end{align}
    
    In other words, it holds,
    \begin{align}
        &\mathbb{E}[W_{\delta=\delta(i)}](1 - \sum_{p=1}^{\delta(i)} \sum_{j  \in \mathcal{N}^{p}}  \rho_j)(1 - \sum_{p=1}^{\delta(i)-1} \sum_{j  \in \mathcal{N}^{p}}  \rho_j)\\
        =& \mathbb{E}[W_{\delta=\delta(i)-1}](1 - \sum_{p=1}^{\delta(i)-1} \sum_{j  \in \mathcal{N}^{p}}  \rho_j)(1 - \sum_{p=1}^{\delta(i)-2} \sum_{j  \in \mathcal{N}^{p}}  \rho_j)\nonumber
    \end{align}
    
    Combine with \eqref{eq:WaitingTime-HPU}, we obtain
    \begin{align}
        &\mathbb{E}[W_{\delta=\delta(i)}]
        = \frac{\mathbb{E}[W_{\delta=1}](1 - \sum_{j \in \mathcal{N}^{1}}  \rho_j)}{(1 - \sum_{p=1}^{\delta(i)} \sum_{j  \in \mathcal{N}^{p}}  \rho_j)(1 - \sum_{p=1}^{\delta(i)-1} \sum_{j  \in \mathcal{N}^{p}}  \rho_j)}\nonumber\\
        &= \frac{\sum_{i \in \mathcal{N}} \rho_j \mathbb{E}[\nu^{2}_j]}{(1 - \sum_{p=1}^{\delta(i)} \sum_{j  \in \mathcal{N}^{p}}  \rho_j)(1 - \sum_{p=1}^{\delta(i)-1} \sum_{j  \in \mathcal{N}^{p}}  \rho_j)}
    \end{align}
    which merges the value of $\mathbb{E}[T^{p}_{n}]$, $\mathbb{E}[I^{p}_{n}]$ and $\mathbb{E}[Y^{p}_{n}]$ to complete the proof

\section{A Proof of Lemma \ref{lemma:P1-1_convex_problem}}\label{app:lemma:P1-1_convex_problem}
    First, we should prove that \eqref{eq:c7a} and \eqref{eq:c8a} are not convex sets. 
    Take \eqref{eq:c7a} as an example, 
    if it was a convex set, we should have obtained 
    \begin{equation}
        (1-r)h(\bm\eta^u_{c_1}) + r h(\bm\eta^u_{c_2}) \mathop{\ge}^{(a)} h((1-r)\bm\eta^u_{c_1} + r\bm\eta^u_{c_2}),
    \end{equation}
    where $h(\bm\eta^u_c) = \langle\bm\lambda, \bm\eta^u_c\rangle + z_{2}\sqrt{\langle\bm\lambda, \bm\eta^u_c\rangle + z^2_{2}/4} + z^2_{1}/2 - M_c^\mathit{max}$, $\bm\lambda := \{\lambda_{n}\}_{n\in\mathcal{N}}$, $\bm\eta^u_c := \{\eta^u_{n,c}|\}_{n\in\mathcal{N}}$, $\forall r\in[0,1]$, 
    $\{c1, c2 \in \mathcal{C}\}$,
    $h(\bm\eta^u_{c_1})\leq 0$ and $h(\bm\eta^u_{c_2})\leq 0$.
    Moreover, inequality (a) is equivalent to
    \begin{equation}
    \label{eq:lemma-(a)}
    r (r-1) (\sqrt{\langle\bm\lambda, \bm\eta^u_{c_1}\rangle} + \sqrt{\langle\bm\lambda, \bm\eta^u_{c_2}\rangle})^2 \ge 2 r (1-r) z^2_{2}/4.
    \end{equation}
    However, if $r \ne 0~or~1$, inequality \eqref{eq:lemma-(a)} does not hold since the right term is higher than zero and the left term of the inequality is less than zero.
    Hence, \eqref{eq:c7a} is a nonconvex set.
     A comparable procedure in \eqref{eq:c8a} can lead to the same conclusion.

 
    % with $r\in[0,1]$, $\forall \eta^a_{n,c}, \eta^b_{n,c}\in\bm \eta^u$, $a = \sum_{n\in\mathcal{N}} \eta^a_{n,c}\lambda_{n}$ and $b = \sum_{n\in\mathcal{N}} \eta^b_{n,c}\lambda_{n}$, we obtain
    % if $\bm x^a$ and $\bm x^b$ satisfy. Let $\eta^a_{n,c}\lambda_{n}\in\bm x^a$ and $\eta^b_{n,c}\lambda_{n}\in\bm x^b$. We have 
    % \begin{equation}
    % \begin{split}
    % (1-r)a + (1-r)\mathcal{Z}_{\alpha}\sqrt{a+c} 
    %  + rb + r\mathcal{Z}_{\alpha}\sqrt{b+c} \\
    % \mathop{\leq}^{(a)} \left((1-r)a + rb\right)
    % + \mathcal{Z}_{\alpha}\sqrt{\left((1-r)a 
    % + rb + c\right)}\\
    % (1-r)\sqrt{a+c}+ r\sqrt{b+c} \leq  \sqrt{\left((1-r)a + rb + c\right)}\\
    % \left( (1-r)a + rb\right) - \left((1-r)^2 a + r^2 b + 2r(1-r) \sqrt{a b}\right)\\
    % \le c-(1-r)^2 c - r^2c,
    % \end{split}
    % \end{equation}
    Next, we will demonstrate that \eqref{eq:c7a} and \eqref{eq:c8a} are comparable to \eqref{eq:c7b} and \eqref{eq:c8b} and are convex sets.
    Again, let's take the example of \eqref{eq:c7a}, which is equivalent to
    \begin{align}
        % \begin{split}
            &\langle\bm\lambda, \bm\eta^u_{c}\rangle + z^2_{1}/2 + z_{2}\sqrt{\langle\bm\lambda, \bm\eta^u_{c}\rangle + z^2_{2}/4} \le M_c^\mathit{max},\nonumber\\
            &(z_{2}/2 + \sqrt{\langle\bm\lambda, \bm\eta^u_{c}\rangle + z^2_{2}/4})^2 
            \le M_c^\mathit{max} - z^2_{1}/2  + z^2_{2}/4,\nonumber\\
            &\langle\bm\lambda, \bm\eta^u_{c}\rangle \le M_c^\mathit{max} + \frac{z^2_{2}}{2} - \frac{z^2_{1}}{2} - z_{2}\sqrt{M_c^\mathit{max} + \frac{z^2_{2}}{2} - \frac{z^2_{1}}{2}},
        % \end{split}
    \end{align}
    which means that the constraint \eqref{eq:c7a} is transformed mathematically into \eqref{eq:c7b}, which is an affine set and a kind of convex set.
    \eqref{eq:c8b} can be obtained in a similar way.
    
    % \begin{align}
    % \textbf{C7-b}&~~
    % \label{eq:constraint-channelcapacity}
    %     \sum_{n\in\mathcal{N}} \eta^u_{n,c}\lambda_{n} \le M_c^\mathit{max} + \frac{z^2_{2}}{2} - \frac{z^2_{1}}{2} - z_{2}\sqrt{M_c^\mathit{max} + \frac{z^2_{2}}{2} - \frac{z^2_{1}}{2}}, \quad \forall c \\
    % \textbf{C8-b}&~~
    % \label{eq:constraint-calculatedcapacity}
    %     \sum_{n\in\mathcal{N}} \sum_{c\in\mathcal{C}} p_{n,c} \frac{\eta^u_{n,c}\lambda_{n}}{\mu} \leq 1 + \frac{z^2_{4}}{2} - \frac{z^2_{3}}{2} - z_{4}\sqrt{1 + \frac{z^2_{4}}{2} - \frac{z^2_{3}}{2}}
    % \end{align}

\section{A Proof of Theorem \ref{thm:admm-consensus}}\label{app:lemma:paoi_mg1}
% \noindent
% \textbf{Proof of Convex Function $F_n$}\\
    The objective function that needs to be proven convexity is
    \begin{equation}
        f_n(\hat t^\mathit{tr},\bm\eta^u) = F^T_n(\hat t^\mathit{tr}_n,\bm\eta^u) + F^I_n(\hat t^\mathit{tr}_n,\bm\eta^u)+F^W_n(\hat t^\mathit{tr}_n,\bm\eta^u)+F^Y_n(\hat t^\mathit{tr}_n,\bm\eta^u),\nonumber
    \end{equation}
    where
        $F^I_n(\hat t^\mathit{tr}_n,\bm\eta^u)=F^I_n(\bm\eta^u) = \frac{1}{\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}}$, 
        $F^T_n(\hat t^\mathit{tr}_n,\bm\eta^u) = \hat t^\mathit{tr}_n$,
        $F^Y_n(\hat t^\mathit{tr}_n,\bm\eta^u) = \frac{1}{\mu}$,
        and
        $F^W_n(\hat t^\mathit{tr}_n,\bm\eta^u)=F^W_n(\bm\eta^u) = (\frac{1}{2}\sum_{n'=1}^{\mathcal{N}}\sum_{c\in\mathcal{C}}p_{n',c}\eta^u_{n',c}\lambda_{n'}\nu)/(1-\sum_{n'=1}^{\mathcal{N}}\sum_{c\in\mathcal{C}}p_{n',c}\frac{\eta^u_{n',c}\lambda_{n'}}{\mu})$.
    \begin{enumerate}
        \item Due to properties of linear functions, it is obvious that \underline{$\nabla^{2} F^T_n(\hat t^\mathit{tr}_n,\bm\eta^u) \succeq 0$}.

        
        \item Due to properties of constant functions, it holds that \underline{$\nabla^{2} F^Y_n(\hat t^\mathit{tr}_n,\bm\eta^u) \succeq 0$}.
        
        \item Furthermore, we have $\{n, m, m_1, m_2 \in \mathcal{N} | n = m \& n \neq m_1 \& n \neq m_2\}$ , $\{c, d, d_1, d_2 \cdots d_\mathit{max} \in \mathcal{C}\}$, $\boldsymbol p_n = \{p_{n,1} \cdots p_{n,C}\}$, and $\boldsymbol p = \{\boldsymbol p_n|n\in \mathcal{N}\}$.
        % We obtain some first-order derivatives.
        % \begin{align}
        % \label{eq:paoi-function-arrival-firstorderderivative}
        %     &\frac{\partial F^I_n(\bm\eta^u)}{\partial \lambda_{m,c}} = - \frac{p_{n,c}}{(\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n})^2},
        %     &\frac{\partial F^I_n(\bm\eta^u)}{\partial \lambda_{m_1,c}} = 0.
        % \end{align}
        We list some key second-order derivatives.
        \begin{align}
        % \label{eq:paoi-function-arrival-secondorderderivative}
            \label{eq:sod-1}
            \frac{\partial^2 F^I_n(\bm\eta^u)}{\partial \lambda^2_{m,c}} &= \frac{2p^2_{m,c}}{(\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n})^3},\\
            \label{eq:sod-2}
            \frac{\partial^2 F^I_n(\bm\eta^u)}{\partial \lambda_{m,d_1} \partial \lambda_{m,d_2}} &= \frac{2p_{n,d_1}p_{n,d_2}}{(\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n})^3},\\
            \label{eq:sod-3}
            \frac{\partial^2 F^I_n(\bm\eta^u)}{\partial \lambda_{m,c} \partial \lambda_{m_1,c}} &= 
            \frac{\partial^2 F^I_n(\bm\eta^u)}{\partial \lambda_{m_1,c} \partial \lambda_{m_2,c}} = 
            \frac{\partial^2 F^I_n(\bm\eta^u)}{\partial \lambda^2_{n_1,c}} = 0.
        \end{align}
        Combining Eq.\eqref{eq:sod-1}, Eq.\eqref{eq:sod-2}, and Eq.\eqref{eq:sod-3}, the Hessian matrix of $F^I_n(\bm\eta^u)$ is described as
        \begin{align}
        \label{eq:paoi-function-arrival-hessian}
            \mathbf{H}^I_n(\bm\eta^u)           
           =\left[\begin{array}{c|c}
            \boldsymbol A & \boldsymbol B\\
            \hline
            \boldsymbol C & \boldsymbol D
           \end{array}\right]
        \end{align}
        where $\boldsymbol D = \boldsymbol{O}^{(N-1)C}$, $\boldsymbol B = \boldsymbol C^T = \boldsymbol{O}^{C \times (N-1)C}$ and 
        $\boldsymbol A=\left[\begin{array}{ccc}
            \frac{\partial^2 F^I_n(\bm\eta^u)}{\partial \lambda^2_{m,d_1}} & \cdots & \frac{\partial^2 F^I_n(\bm\eta^u)}{\partial\lambda_{m,d_1} \partial\lambda_{m,d_\mathit{max}}}\\
            \vdots & \ddots & \vdots\\
            \frac{\partial^2 F^I_n(\bm\eta^u)}{\partial\lambda_{m,d_\mathit{max}} \partial\lambda_{m,d_1}} & \cdots & \frac{\partial^2 F^I_n(\bm\eta^u)}{\partial\lambda^2_{m,d_\mathit{max}}}
          \end{array}\right]^{C \times C}
         = \frac{\boldsymbol p^T_n \times \boldsymbol p_n}{(\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n})^3}
          $ 
        denotes second-order derivative matrix at $m = n$, \ie $\boldsymbol A \succeq 0$.
        The leading Principle Submatrix of $\mathbf{H}^I_n(\bm\eta^u)$ are all greater than 0, \ie \underline{$\nabla^{2} F^I_n(\hat t^\mathit{tr},\bm\eta^u) \succeq 0$}.
        
        \item As for $F^W_n(\bm\eta^u)$, it holds
        \begin{align}
	        \frac{\partial^2 F^W_n(\bm\eta^u)}{\partial \lambda_{m_1,d_1}\partial \lambda_{m_2,d_2}} = \boldsymbol p_{m_1,d_1} \boldsymbol p_{m_2,d_2}\frac{\nu/\mu}{(1-\sum_{m=1}^{\mathcal{N}}\sum_{c\in\mathcal{C}}p_{m,c}\frac{\lambda_{m,c}}{\mu})^3}
	    \end{align}
        The hessian matrix is described as 
        \begin{align}
        \nabla^{2}F^W_n(\bm\eta^u)=\boldsymbol p^T \times \boldsymbol p \frac{\nu/\mu}{(1-\sum_{m=1}^{\mathcal{N}}\sum_{c\in\mathcal{C}}p_{m,c}\frac{\lambda_{m,c}}{\mu})^3}
        \end{align}
        Thus, we derive \underline{$\nabla^{2} F^W_n(\hat t^\mathit{tr},\bm\eta^u) \succeq 0$}.
        \end{enumerate}
        
        Above all, $\nabla^{2} f_n(\hat t^\mathit{tr},\bm\eta^u) \succeq 0$. The proof is completed.
    % \end{proof}
   
   
% \section{A Proof of Lemma \ref{lemma:P1-1_convex_problem}}\label{app:lemma:P1-1_convex_problem}
%     We prove Lemma \ref{lemma:P1-1_convex_problem} here. 
% \begin{proof}
%     \eqref{eq:c8a} and \eqref{eq:c7a} are not convex set. Take \eqref{eq:confidenceinterval_channelcapacity} as an example, if $\bm x^a$ and $\bm x^b$ satisfy. Let $\eta^a_{n,c}\lambda_{n}\in\bm x^a$ and $\eta^b_{n,c}\lambda_{n}\in\bm x^b$. We have $r\sum_{n\in\mathcal{N}} \eta^a_{n,c}\lambda_{n} + (1-r)\sum_{n\in\mathcal{N}} \eta^b_{n,c}\lambda_{n} + r\mathcal{Z}_{\alpha}\sqrt{\sum_{n\in\mathcal{N}} \eta^a_{n,c}\lambda_{n}} + (1-r)\mathcal{Z}_{\alpha}\sqrt{\sum_{n\in\mathcal{N}} \eta^b_{n,c}\lambda_{n}} - M_c^\mathit{max} \ge r\sum_{n\in\mathcal{N}} \eta^a_{n,c}\lambda_{n} + (1-r)\sum_{n\in\mathcal{N}} \eta^b_{n,c}\lambda_{n} + \mathcal{Z}_{\alpha}\sqrt{r\sum_{n\in\mathcal{N}} \eta^a_{n,c}\lambda_{n} + (1-r)\sum_{n\in\mathcal{N}} \eta^b_{n,c}\lambda_{n}} - M_c^\mathit{max}$, with $r\in[0,1]$. Thus, this is a non-convex set. After a mathematical transformation, the constraints \eqref{eq:c7a} and \eqref{eq:c8a} become affine set as \eqref{eq:c7a} and \eqref{eq:c8a}, respectively.
    
%     % \begin{align}
%     % \textbf{C7-b}&~~
%     % \label{eq:constraint-channelcapacity}
%     %     \sum_{n\in\mathcal{N}} \eta^u_{n,c}\lambda_{n} \le M_c^\mathit{max} + \frac{z^2(\alpha_2)}{2} - \frac{z^2(\alpha_1)}{2} - z(\alpha_2)\sqrt{M_c^\mathit{max} + \frac{z^2(\alpha_2)}{2} - \frac{z^2(\alpha_1)}{2}}, \quad \forall c \\
%     % \textbf{C8-b}&~~
%     % \label{eq:constraint-calculatedcapacity}
%     %     \sum_{n\in\mathcal{N}} \sum_{c\in\mathcal{C}} p_{n,c} \frac{\eta^u_{n,c}\lambda_{n}}{\mu} \leq 1 + \frac{z^2(\beta_2)}{2} - \frac{z^2(\beta_1)}{2} - z(\beta_2)\sqrt{1 + \frac{z^2(\beta_2)}{2} - \frac{z^2(\beta_1)}{2}}
%     % \end{align}
% \end{proof}

\section{Details of Optimal Solution to \textbf{P1-3}}\label{app:det:admm-consensus}
    The augmented Lagrangian for problem \textbf{P1-3} can be expressed as,
\begin{align}
% \label{eq:PLadmm-lagrange}
    L_{\rho}(\{\bm x_n\}, \bm x_{o}, \{\bm\sigma_n\})
   &= \sum_{n\in\mathcal{N}}(g_n(\bm x_n) + \langle\bm\sigma_n, \bm x_n - \bm x_{o}\rangle\nonumber\\
   &+ (\rho/2)\|\bm x_n - \bm x_{o}\|^2_2
\end{align}
where $\bm\sigma_n = \{\sigma^n_{m,c}|c\in \mathcal{C}, m\in \mathcal{N}\}$ are the associated Lagrangian multiplier with respect to the problem \textbf{P3} and $\rho$ is a positive penalty parameter.

\begin{align}
    \Longrightarrow 
    \label{eq:PLadmm1-relax-i} 
    \bm x^{t+1}_n & = \arg\min_{\bm x_n} (G_n(\bm x_n) + \langle\bm\sigma^t_n, \bm x_n - \bm x_{o}\rangle\nonumber\\
    &+ (\rho/2)\|\bm x_n - \bm x^t_{o}\|^2_2) \\ 
    \label{eq:PLadmm1-relax-o} 
    \bm x^{t+1}_{o} & = \frac{1}{N}\sum_{n\in\mathcal{N}}(\bm x^{t+1}_n + (\frac{1}{\rho}\bm\sigma^{t}_n)) \\ 
    \label{eq:PLadmm1-relax-sigma} 
    \bm\sigma^{t+1}_n & = \bm\sigma^{t}_n + \rho(\bm x^{t+1}_n - \bm x^{t+1}_{o})
\end{align}
The specific method is described in Algorithm \ref{alg:admm}


\begin{algorithm}[ht]
    \label{alg:admm}
	\caption{ADMM-Consensus (AC)}
	\label{AOHC}
	\LinesNumbered
	\For{$n = 1$ \KwTo $N$}{
	\KwIn{$\epsilon^{Primal}$, $\epsilon^{Dual}$, $\theta$, $\bm x_n$, $s$, $k$}
    \While{$\|\bm x^{t+1}_n - \bm x^{t+1}_{o}\|^2_2 > \epsilon^{Primal}$ or $\rho\|(\bm x^{t+1}_{o}) - \bm x^{t}_{o})\|^2_2 > \epsilon^{Dual}$}{
    	{Calculate $\bm x^{t+1}_n$, simultaneously according to \eqref{eq:PLadmm1-relax-i}}\\
    	{Calculate $\bm x^{t+1}_{o}$, according to \eqref{eq:PLadmm1-relax-o}}\\
        {Calculate $\sigma^{t+1}_n$, according to \eqref{eq:PLadmm1-relax-sigma}}\\
        {Update $k = k + 1$}\\
	}
	{Set $\bm x^{*}_n = \bm x^{t+1}_n$}\\
	\KwOut{$\bm x^{*}_n$}
}	
\end{algorithm}

    
\section{A Proof of Proposition \ref{pro:npl-mp}}
\label{app:pro:npl-mp}
    A brief idea of the proof is given as follows. 
    According to nonlinear fractional programming \cite{dinkelbach1967nonlinear}, $\theta^{*}_n$ is achieved if and only if
	\begin{align}
	\mathop{\min}_{\bm x_n} f^{p,u}_n(\bm x_n) - \theta^{*}_n f^{p,l}_n(\bm x_n)
	\nonumber\\ 
       = f^{p,u}_n(\bm x_n^*) - \theta^{*}_nf^{p,l}_n(\bm x_n^*) = 0.
    \label{eq:NFP-optimal-theta}
    \end{align}
which outlines the necessary and sufficient criteria in order to reach $\theta^{*}_n$.
In light of this, $\{\bm x_n\}$ can be acquired by resolving the following transformation problem.


\section{A Proof of Proposition \ref{theorem:NFP_Problem}}\label{app:theorem:NFP_Problem}
Here is a concise proof followed by a comprehensive one.
\subsection{A Concise Proof}
\begin{enumerate}  
\item Given the complexity of the proof, we will only provide a brief overview of the main idea here. We begin by computing the Hessian matrix of the entire function. Due to differing priority attributes ($\delta(n_1)> \delta(n_2)$, $\delta(n_1)=\delta(n_2)$, n1=n2,$\delta(n_1)< \delta(n_2)$), we need to examine the second derivative of the function in at least 16 cases.

\item Through analyzing the properties of the Hessian matrix, we observe that the function is Lipschitz smooth or gradient Lipschitz continuous as long as the values in the Hessian matrix are finite. 

\item We can also obtain the value of $\ell_n$in $\ell_n I \succeq \nabla^{2}F$
 based on the characteristics of the Hessian matrix.
\end{enumerate}
\subsection{A Comprehensive Proof}
    For computational convenience, we present some functions, where
    $\Phi_{\delta(n)}(\bm x) = 1-\sum_{\delta=1}^{\delta(n)}\sum_{n'=1}^{\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\frac{\eta^u_{n',c}\lambda_{n'}}{\mu_{n'}}$,
    $\Phi_0(\bm x) = 1$,
    $\Upsilon(\bm x) = \frac{1}{2}\sum_{\delta=1}^{\Delta}\sum_{n'=1}^{\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\eta^u_{n',c}\lambda_{n'}\nu_{n'}$,
    and $\Psi_n(\bm x)=\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}$.
    We also give some useful parameters in advance, where
    $\{n_1, n_2 \in \mathcal{N}\}$, $\{c_1, c_2\in \mathcal{C}\}$,
    $\kappa_{1}=\frac{p_{n_1,c_1}}{\mu_{n_1}}>0$, 
    $\kappa^1_\mathit{max}=\frac{1}{\mu_\mathit{min}}>0$,
    and $p_{n,c}\in[0,1]$.
    % and $\kappa_{1}\kappa_{2}=\kappa_{1}\kappa_{2}$
    % $\kappa^2_\mathit{max}=\frac{1}{\mu^2_\mathit{min}}>0$.
    Additionally, since $\nabla_{\{t^\mathit{tr} \in \bm x\}} g^{p}_n(\bm x) = 0$, we just ignore it.
    Due to $\nabla^2_{\eta_{n_1,c_1}\eta_{n_2,c_2}} g^{p}_n(\bm x) = \lambda_{n_1}\lambda_{n_2}\nabla^2_{\lambda_{n_1,c_1}\lambda_{n_2,c_2}} g^{p}_n(\bm x)$, we have
\subsubsection{Hessian Matrix}
    We first analyze the function $f^{p,u}_n(\bm x)$,
    \begin{align}
        f^{p,u}_n(\bm x)  & = \Phi_{\delta(n)}(\bm x)\Phi_{\delta(n)-1}(\bm x) + \Upsilon(\bm x)\Psi_n(\bm x).
    \end{align}


    \noindent{\bf Case I)} If $\delta(n_1)<\delta(n)$, we obtain first-order derivative.
    \begin{align}
    \frac{\partial f^{p,u}_n(\bm x)}{\partial \lambda_{n_1,c_1}} &= -\frac{p_{n_1,c_1}}{\mu_{n_1}}(\Phi_{\delta(n)}(\bm x) + \Phi_{\delta(n)-1}(\bm x))\nonumber\\
    &+ \frac{1}{2}p_{n_1,c_1}\nu_{n_1}\Psi_n(\bm x)
    \end{align}
    We obtain some second-order derivatives.
    \begin{equation}  
		\frac{\partial^2 f^{p,u}_n(\bm x)}{\partial\lambda_{n_1,c_1} \partial\lambda_{n_2,c_2}}\\
		= \left\{
		\begin{array}{ll}
		 2\frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}}, \quad \delta(n_2)<\delta(n)\\
		 \frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}}+\frac{1}{2}p_{n_1,c_1}p_{n_2,c_2}\nu_{n_1},
		\quad n_2 = n\\
		 \frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}},
		\quad \delta(n_2) = \delta(n), \quad n_2 \ne n\\
		 0, \quad \delta(n_2)>\delta(n)\\
		\end{array}
		\right..
	\end{equation}
    
    \noindent{\bf Case II)} If $\delta(n_1)=\delta(n)~\&~n_1 = n$, we obtain first-order derivative.
    \begin{align}
    \frac{\partial f^{p,u}_n(\bm x)}{\partial \lambda_{n_1,c_1}} &= -\frac{p_{n_1,c_1}}{\mu_{n_1}}\Phi_{\delta(n)-1}(\bm x) + p_{n_1,c_1}\Upsilon(\bm x)\nonumber\\
    &+\frac{1}{2}p_{n_1,c_1}\nu_{n_1}\Psi_n(\bm x)
    \end{align}
    We obtain some second-order derivatives.
    \begin{equation}  
		\frac{\partial^2 f^{p,u}_n(\bm x)}{\partial\lambda_{n_1,c_1} \partial\lambda_{n_2,c_2}} = \left\{
		\begin{array}{ll}
		& \frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}}+\frac{1}{2}p_{n_1,c_1}p_{n_2,c_2}\nu_{n_2},\nonumber\\
		&\quad \delta(n_2)<\delta(n)\\
		& \frac{1}{2}p_{n_1,c_1}p_{n_2,c_2}\nu_{n_1}+\frac{1}{2}p_{n_1,c_1}p_{n_2,c_2}\nu_{n_2},\nonumber\\  
		&\quad n_2 = n\\
		& \frac{1}{2}p_{n_1,c_1}p_{n_2,c_2}\nu_{n_2},  \quad \delta(n_2) = \delta(n), \nonumber\\ 
		&\quad n_2 \ne n\\
		& \frac{1}{2}p_{n_1,c_1}p_{n_2,c_2}\nu_{n_2}, \quad \delta(n_2)>\delta(n)\\
		\end{array}
		\right..
	\end{equation}
	
	\noindent{\bf Case III)} If $\delta(n_1)=\delta(n)~\&~n_1 \ne n$, we obtain first-order derivative.
    \begin{align}
    \frac{\partial f^{p,u}_n(\bm x)}{\partial \lambda_{n_1,c_1}} = -\frac{p_{n_1,c_1}}{\mu_{n_1}}\Phi_{\delta(n)-1}(\bm x) +\frac{1}{2}p_{n_1,c_1}\nu_{n_1}\Psi_n(\bm x)
    \end{align}
    We obtain some second-order derivatives.
    \begin{equation}  
		\frac{\partial^2 f^{p,u}_n(\bm x)}{\partial\lambda_{n_1,c_1} \partial\lambda_{n_2,c_2}} = \left\{
		\begin{array}{ll}
		& \frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}}, \quad \delta(n_2)<\delta(n)\\
		& \frac{1}{2}p_{n_1,c_1}p_{n_2,c_2}\nu_{n_1},  \quad n_2 = n\\
		& 0,  \quad \delta(n_2) = \delta(n), \quad n_2 \ne n\\
		& 0, \quad \delta(n_2)>\delta(n)\\
		\end{array}
		\right..
	\end{equation}
	
    \noindent{\bf Case IV)} If $\delta(n_1)>\delta(n)$, we obtain first-order derivative.
    \begin{align}
    \frac{\partial f^{p,u}_n(\bm x)}{\partial \lambda_{n_1,c_1}} =\frac{1}{2}p_{n_1,c_1}\nu_{n_1}\Psi_n(\bm x)
    \end{align}
    We obtain some second-order derivatives.
    \begin{equation}  
		\frac{\partial^2 f^{p,u}_n(\bm x)}{\partial\lambda_{n_1,c_1} \partial\lambda_{n_2,c_2}} = \left\{
		\begin{array}{ll}
		& 0, \quad \delta(n_2)<\delta(n)\\
		& \frac{1}{2}p_{n_1,c_1}p_{n_2,c_2}\nu_{n_1},  \quad n_2 = n\\
		& 0,  \quad \delta(n_2) = \delta(n), \quad n_2 \ne n\\
		& 0, \quad \delta(n_2)>\delta(n)\\
		\end{array}
		\right..
	\end{equation}
	
	
	As for $f^{p,l}_n(\bm x)$, we have some different cases, as follows.
	\begin{align}
    f^{p,l}_n(\bm x)  & = \Psi_n(\bm x)\Phi_{\delta(n)}(\bm x)\Phi_{\delta(n)-1}(\bm x).
    \end{align}   
    
    \noindent{\bf Case I)} If $\delta(n_1)<\delta(n)$, we obtain first-order derivative.
    \begin{align}
    \frac{\partial f^{p,l}_n(\bm x)}{\partial \lambda_{n_1,c_1}} = -\frac{p_{n_1,c_1}}{\mu_{n_1}}(\Phi_{\delta(n)}(\bm x)+\Phi_{\delta(n)-1}(\bm x))\Psi_n(\bm x)
    \end{align}
    We obtain some second-order derivatives.
    \begin{equation}  
		\noindent\frac{\partial^2 f^{p,l}_n(\bm x)}{\partial\lambda_{n_1,c_1} \partial\lambda_{n_2,c_2}}\nonumber
	\end{equation}
    \begin{equation}  
		= \left\{
		\begin{array}{ll}
		& 2\frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}}\Psi_n(\bm x), \quad \delta(n_2)<\delta(n)\\
		& \frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}}(\Psi_n(\bm x)-\frac{\nu_{n_2}}{2\mu_{n_2}}\Phi_{\delta(n)}(\bm x)-\frac{\nu_{n_2}}{2\mu_{n_2}}\Phi_{\delta(n)-1}(\bm x)),\\
		& ~~~\quad n_2 = n\\
		& \frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}}\Psi_n(\bm x),\quad \delta(n_2) = \delta(n), \quad n_2 \ne n\\
		& 0, \quad \delta(n_2)>\delta(n)\\
		\end{array}
		\right..
	\end{equation}
    
    \noindent{\bf Case II)} If $\delta(n_1)=\delta(n)~\&~n_1 = n$, we obtain first-order derivative.
    \begin{align}
    \frac{\partial f^{p,l}_n(\bm x)}{\partial \lambda_{n_1,c_1}} &= p_{n_1,c_1}\Phi_{\delta(n)}(\bm x)\Phi_{\delta(n)-1}(\bm x)\nonumber\\
    &-\frac{p_{n_1,c_1}}{\mu_{n_1}}\Psi_n(\bm x)\Phi_{\delta(n)-1}(\bm x)
    \end{align}
    We obtain some second-order derivatives.
    \begin{equation}  
		\frac{\partial^2 f^{p,l}_n(\bm x)}{\partial\lambda_{n_1,c_1} \partial\lambda_{n_2,c_2}}\nonumber
		\end{equation}
    \begin{equation}  
     = \left\{
		\begin{array}{ll}
		& \frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}}(\Psi_n(\bm x)-\frac{\nu_{n_2}}{2\mu_{n_2}}\Phi_{\delta(n)}(\bm x)-\frac{\nu_{n_2}}{2\mu_{n_2}}\Phi_{\delta(n)-1}(\bm x)),\\
		&\quad \delta(n_2)<\delta(n)\\
		& -\frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}}(\frac{\nu_{n_1}}{2\mu_{n_1}}+\frac{\nu_{n_2}}{2\mu_{n_2}})\Phi_{\delta(n)-1}(\bm x),  \quad n_2 = n\\
		& -\frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}}\frac{\nu_{n_2}}{2\mu_{n_2}}\Phi_{\delta(n)-1}(\bm x),  \quad \delta(n_2) = \delta(n), \quad n_2 \ne n\\
		& 0, \quad \delta(n_2)>\delta(n)\\
		\end{array}
		\right..
	\end{equation}
	
	\noindent{\bf Case III)} If $\delta(n_1)=\delta(n)~\&~n_1 \ne n$, we obtain first-order derivative.
    \begin{align}
    \frac{\partial f^{p,l}_n(\bm x)}{\partial \lambda_{n_1,c_1}} = -\frac{p_{n_1,c_1}}{\mu_{n_1}}\Psi_n(\bm x)\Phi_{\delta(n)-1}(\bm x)
    \end{align}
    We obtain some second-order derivatives.
    \begin{equation}  
		\frac{\partial^2 f^{p,l}_n(\bm x)}{\partial\lambda_{n_1,c_1} \partial\lambda_{n_2,c_2}} = \left\{
		\begin{array}{ll}
		& \frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}}\Psi_n(\bm x), \quad \delta(n_2)<\delta(n)\\
		& -\frac{p_{n_1,c_1}p_{n_2,c_2}}{\mu_{n_1}\mu_{n_2}}\frac{\nu_{n_2}}{2\mu_{n_2}}\Phi_{\delta(n)-1}(\bm x),  \quad n_2 = n\\
		& 0, \quad n_2 \ne n\\
		& 0, \quad \delta(n_2)>\delta(n)\\
		\end{array}
		\right..
	\end{equation}
	
    \noindent{\bf Case IV)} If $\delta(n_1)>\delta(n)$, we obtain first and second-order derivative.
    \begin{align}
    &\frac{\partial f^{p,l}_n(\bm x)}{\partial \lambda_{n_1,c_1}} =0
    &\frac{\partial^2 f^{p,l}_n(\bm x)}{\partial\lambda_{n_1,c_1} \partial\lambda_{n_2,c_2}} = 0.
    \end{align}
    
    Above all, we have the first-order derivative and the second-order derivative information of $g^{p}_n(\bm x) = f^{p,u}_n(\bm x) - \theta^{*}_n f^{p,l}_n(\bm x)$.
% 	\begin{equation}  
% 	\label{eq:FunctionGpnFirstOrder}
% 		\frac{\partial g^{p}_n(\bm x)}{\partial\lambda_{n_1,c_1}} = \left\{
% 		\begin{array}{lll}
% 		& \kappa_{1}\left(-\Phi_{\delta(n)}(\bm x) - \Phi_{\delta(n)-1}(\bm x) + \frac{1}{\mu_{n_1}}\Psi_n(\bm x) + \theta^{*}_n \left(\Phi_{\delta(n)}(\bm x)+\Phi_{\delta(n)-1}(\bm x)\right)\Psi_n(\bm x)\right) , \quad \delta(n_1)<\delta(n)\\
% 		& \kappa_{1}\left( -\Phi_{\delta(n)-1}(\bm x) + \mu_{n_1}\Upsilon(\bm x)+\frac{1}{\mu_{n_1}}\Psi_n(\bm x) + \theta^{*}_n\left(-\frac{\nu_{n_2}}{2\mu_{n_2}}\Phi_{\delta(n)}(\bm x)+\Psi_n(\bm x)\right)\Phi_{\delta(n)-1}(\bm x)\right) , \quad n_1 = n\\
% 		& \kappa_{1}\left(-\Phi_{\delta(n)-1}(\bm x) +\frac{1}{\mu_{n_1}}\Psi_n(\bm x) + \theta^{*}_n \Psi_n(\bm x)\Phi_{\delta(n)-1}(\bm x)\right), \quad \delta(n_1) = \delta(n), \quad n_1 \ne n\\
% 		& \kappa_{1}\Psi_n(\bm x), \quad \delta(n_1)>\delta(n)
% 		\end{array}
% 		\right..
% 	\end{equation}
	
% 	\begin{equation}  
% 	\label{eq:FunctionGpnSecondOrder}
% 		\frac{\partial^2 g^{p}_n(\bm x)}{\partial\lambda_{n_1,c_1} \partial\lambda_{n_2,c_2}} = \left\{
% 		\begin{array}{lll}
% 		%a
% 		& 2\kappa_{1}\kappa_{2}(1-\theta^{*}_n\Psi_n(\bm x)), \quad \delta(n_1)<\delta(n), \quad \delta(n_2)<\delta(n)\\
% 		& \kappa_{1}\kappa_{2}(1+\frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}+\theta^{*}_n(\frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)}(\bm x)+\frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)-1}(\bm x))-\Psi_n(\bm x)), \quad \delta(n_1)<\delta(n),  \quad n_2 = n\\
% 		& \kappa_{1}\kappa_{2}(1-\theta^{*}_n\Psi_n(\bm x)), \quad \delta(n_1)<\delta(n),  \quad \delta(n_2) = \delta(n), \quad n_2 \ne n\\
% 		& 0, \quad \delta(n_1)<\delta(n), \quad \delta(n_2)>\delta(n)\\
% 		%b
% 		& \kappa_{1}\kappa_{2}(1+\frac{\nu_{n}}{2\mu_{n}\mu_{n_2}}+\theta^{*}_n(\frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)}(\bm x)+\frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)-1}(\bm x))-\Psi_n(\bm x)), \quad n_1 = n, \quad \delta(n_2)<\delta(n)\\
% 		& 2\kappa_{1}\kappa_{2}(1+\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)-1}(\bm x)), \quad n_1 = n, \quad n_2 = n\\
% 		& \kappa_{1}\kappa_{2}(\frac{\nu_{n}}{2\mu_{n}\mu_{n_2}}+\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)}(\bm x)), \quad n_1 = n,  \quad \delta(n_2) = \delta(n), \quad n_2 \ne n\\
% 		& \kappa_{1}\kappa_{2}\cdot\frac{\nu_{n}}{2\mu_{n}\mu_{n_2}}, \quad n_1 = n, \quad \delta(n_2)>\delta(n)\\
% 		%c
% 		& \kappa_{1}\kappa_{2}(1-\theta^{*}_n\Psi_n(\bm x)), \quad \delta(n_1)=\delta(n), \quad n_1 \ne n, \quad \delta(n_2)<\delta(n)\\
% 		& \kappa_{1}\kappa_{2}(\frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}+\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)}(\bm x)), \quad \delta(n_1)=\delta(n), \quad n_1 \ne n,  \quad n_2 = n\\
% 		& 0, \quad \delta(n_1)=\delta(n), \quad n_1 \ne n,  \quad \delta(n_2) = \delta(n), \quad n_2 \ne n\\
% 		& 0, \quad \delta(n_1)=\delta(n), \quad n_1 \ne n, \quad \delta(n_2)>\delta(n)\\
% 		%d
% 		& 0, \quad \delta(n_1)>\delta(n), \quad \delta(n_2)<\delta(n)\\
% 		& \kappa_{1}\kappa_{2}\cdot\frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}, \quad \delta(n_1)>\delta(n),  \quad n_2 = n\\
% 		& 0, \quad \delta(n_1)>\delta(n),  \quad \delta(n_2) = \delta(n), \quad n_2 \ne n\\
% 		& 0, \quad \delta(n_1)>\delta(n), \quad \delta(n_2)>\delta(n)
% 		\end{array}
% 		\right..
% 	\end{equation}

\subsubsection{The Relationship between Hessian Matrix and Lipschitz Smooth}
	Obviously, for any $n$, $g^{p}_n(\bm x)$ is a smooth function.
	
	On the other hand, the twice differentiable function $g^{p}_n(\bm x)$ has a Lipschitz continuous gradient with modulus $\ell_n$ if and only if its Hessian satisfies $\ell_n I \succeq \nabla^{2} g^{p}_n(\bm x)$. We have $\ell_n$ is equal to the maximum eigenvalue of $\nabla^{2} g^{p}_n(\bm x)$,\cite{zhang2020fedpd}.
	
	In order to obtain the maximum eigenvalue, we ought to get the maximum value of the sum of the absolute values of the elements of the column of the matrix $\nabla^{2} g^{p}_n(\bm x)$, which is because that if $\xi$ is the eigenvector of matrix $\mathcal{A}$ with respect to eigenvalue $\omega$. 
	
	According to the basic property, we have $\sum_{j=1}^{n} A_{i j} \xi_{j}=\omega \xi_{i}$, \ie $\sum_{j=1}^{n}\left|A_{i j} \right|\left|\xi_{j}\right| \geq|\omega |\left|\xi_{i}\right|$.
	
	Summing over both sides, it is 
	\begin{align}
	    \sum_{i=1}^{n}\sum_{j=1}^{n}\left|A_{i j} \right|\left|\xi_{j}\right| \geq\sum_{i=1}^{n}|\omega |\left|\xi_{i}\right|
	\end{align}
	
	Let $M=\max_{1 \leq j \leq n} \sum_{i=1}^{n}\left|A_{i j}\right|$, we have
	\begin{align}
	    M \sum_{j=1}^{n}\left|\xi_{j}\right| \geq \sum_{j=1}^{n}\left|\xi_{j}\right| \sum_{i=1}^{n}\left|A_{i j}\right| \geq \sum_{i=1}^{n}|\omega |\left|\xi_{i}\right| \geq|\omega | \sum_{i=1}^{n}\left|\xi_{i}\right|
	\end{align}
	
	
	Since $\xi$ is not a zero vector, we obtain 
	\begin{align}
	    |\omega | \leq \max_{1 \leq j \leq n} \sum_{i=1}^{n}\left|A_{i j}\right|
	\end{align}

	
\subsubsection{Solve for the value of $\ell_n$}
    Upper bound on the sum of the absolute values of the elements in the columns of the matrix $\nabla^{2}_{\bm\eta^u} g^{p}_n(\bm x)$ is expressed as $\varphi(\bm x)\lambda^2_{max}$ with $\lambda_{max}=\mathop{\max}_n {\lambda_n}$:
	
	\begin{align}
        \label{eq:hessian}
	    \varphi(\bm x) &\leq \mathop{\max} \Big\{\inf |\varphi_1(\bm x)|, \inf |\varphi_2(\bm x)|, \inf |\varphi_3(\bm x)|, \inf |\varphi_4(\bm x)| \Big\} \nonumber\\
	    &\mathop{\leq}^{(a)} \mathop{\max} \Big\{\inf |\varphi_1(\bm x)|, \inf |\varphi_2(\bm x)|, \inf |\varphi_3(\bm x)| \Big\}\nonumber\\
	    &\mathop{\leq}^{(b)} \mathop{\max} \Big\{\inf |\varphi_1(\bm x)|, \inf |\varphi_3(\bm x)| \Big\}\nonumber\\
	    &\mathop{\leq}^{(c)} \mathop{\max} \Big\{\inf |\varphi_3(\bm x)| \Big\}\nonumber\\
	    &\mathop{\leq}^{(d)} \frac{1}{\mu^2_\mathit{min}}\Big(
	        \sum_{n_1\in \mathcal{N}} |\frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}|
	        + \sum_{n_1\in \{<\delta(n)\}\bigcup \{n\}}|1+\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}|\nonumber\\
	        &~~~~+ \sum_{n_1\in \{\leq\delta(n)\}}|\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}|\Big),
	\end{align}
    where $\varphi_1(\bm x)$, $\varphi_2(\bm x)$, $\varphi_3(\bm x)$, and $\varphi_4(\bm x)$ are
    
	\noindent{\bf Case I)} If $\delta(n_2)<\delta(n)$, we have
	\begin{align}
	    \varphi_1(\bm x)
	   &= \overbrace{\sum_{n_1\in \{<\delta(n)\}}\mid 2\kappa_{1}\kappa_{2}(1-\theta^{*}_n\Psi_n(\bm x))\mid}^{\varphi_{1a}(\bm x)}\nonumber\\
	    &+ \overbrace{\sum_{n_1\in \{n\}}\mid \kappa_{1}\kappa_{2}(1+\frac{\nu_{n}}{2\mu_{n}\mu_{n_2}}+\theta^{*}_n(\frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)}(\bm x)\mid }^{\varphi_{1b}(\bm x)} \nonumber\\
	    &+\frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)-1}(\bm x))-\Psi_n(\bm x))\nonumber\\
	    &+ \overbrace{\sum_{n_1\in \{=\delta(n)\}/n}\mid  \kappa_{1}\kappa_{2}(1-\theta^{*}_n\Psi_n(\bm x))\mid }^{\varphi_{1c}(\bm x)} \nonumber\\
	    &+ \overbrace{\sum_{n_1\in \{>\delta(n)\}} 0 }^{\varphi_{1d}(\bm x)} .
	\end{align}
	
	\noindent{\bf Case II)} If $\delta(n_2)=\delta(n)~\&~n_2\ne n$, we derive
	\begin{align}
	    \varphi_2(\bm x)
	   &= \overbrace{\sum_{n_1\in \{<\delta(n)\}}\mid \kappa_{1}\kappa_{2}(1-\theta^{*}_n\Psi_n(\bm x))\mid }^{\varphi_{2a}(\bm x)}\nonumber\\
	    &+ \overbrace{\sum_{n_1\in \{n\}}\mid \kappa_{1}\kappa_{2}(\frac{\nu_{n}}{2\mu_{n}\mu_{n_2}}+\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)}(\bm x))\mid }^{\varphi_{2b}(\bm x)} \nonumber\\
	    &+ \overbrace{\sum_{n_1\in \{=\delta(n)\}/n}\mid \kappa_{1}\kappa_{2}(1-\theta^{*}_n\Psi_n(\bm x))\mid }^{\varphi_{2c}(\bm x)}\nonumber\\
	    &+ \overbrace{\sum_{n_1\in \{>\delta(n)\}} 0 }^{\varphi_{2d}(\bm x)}.
	\end{align}
	
	\noindent{\bf Case III)} If $n_2 = n$, we obtain
	\begin{align}
	    \varphi_3(\bm x)
	   &= \overbrace{\sum_{n_1\in \{<\delta(n)\}}\mid \kappa_{1}\kappa_{2}(1+\frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}+\theta^{*}_n(\frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)}(\bm x)}^{\varphi_{3a}}\nonumber\\
          &+\frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)-1}(\bm x))(\bm x)
	   -\Psi_n(\bm x))\mid \nonumber\\
	    &+ \overbrace{\sum_{n_1\in \{n\}}\mid 2\kappa_{1}\kappa_{2}(1+\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)-1}(\bm x))\mid }^{\varphi_{3b}(\bm x)}\nonumber\\
	    &+ \overbrace{\sum_{n_1\in \{=\delta(n)\}/n}\mid  \kappa_{1}\kappa_{2}(\frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}+\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}\Phi_{\delta(n)}(\bm x))\mid }^{\varphi_{3c}(\bm x)}\nonumber\\
	    &+ \overbrace{\sum_{n_1\in \{>\delta(n)\}}\mid \kappa_{1}\kappa_{2}\frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}\mid }^{\varphi_{3d}(\bm x)}.
	\end{align}
	
	\noindent{\bf Case IV)} If $\delta(n_2)>\delta(n)$, we gain
	\begin{align}
	    \varphi_4(\bm x)
	   &= \overbrace{\sum_{n_1\in \{<\delta(n)\}} 0 }^{\varphi_{4a}(\bm x)}+ \overbrace{\sum_{n_1\in \{n\}}\mid \kappa_{1}\kappa_{2}\frac{\nu_{n}}{2\mu_{n}\mu_{n_2}}\mid }^{\varphi_{4b}(\bm x)}\nonumber\\
	    &+ \overbrace{\sum_{n_1\in \{=\delta(n)\}/n} 0 }^{\varphi_{4c}(\bm x)}
	    + \overbrace{\sum_{n_1\in \{>\delta(n)\}} 0 }^{\varphi_{4d}(\bm x)}.
	\end{align}
	

    Eq.\eqref{eq:hessian} holds because:
	\begin{itemize}
	    \item  (a) holds because $\varphi_2(\bm x)>\varphi_4(\bm x)$.
	
    	\item  (b) holds because $\inf | \varphi_{2}(\bm x) | < \inf | \varphi_{1}(\bm x) |$
	    
	    \item  (c) holds because $\inf | \varphi_{1}(\bm x) | < \inf | \varphi_{3}(\bm x) |$
	    
	    \item  (d) holds because
	    
	    \begin{align}
         	\inf |\varphi_3(\bm x)| 
	        \leq |\kappa^2_\mathit{max}|\Big(\sum_{n_1\in \{<\delta(n)\}}| 1+\frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}+2\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}|\nonumber\\
	        + \sum_{n_1\in \{n\}}| 2(1+\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}})|
	        + \sum_{n_1\in \{=\delta(n)\}/n}| \frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}+\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}|\nonumber\\
	        + \sum_{n_1\in \{>\delta(n)\}}| \frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}| \Big)\nonumber\\
	        = \frac{1}{\mu^2_\mathit{min}}\Big(
	        \sum_{n_1\in \mathcal{N}} |\frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}|
	        + \sum_{n_1\in \{<\delta(n)\}\bigcup \{n\}}|1+\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}|\nonumber\\
	        + \sum_{n_1\in \{\leq\delta(n)\}}|\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}|\Big)
	    \end{align}
	\end{itemize}
    
    Let $\omega^{G}$ denote the the eigenvalue of $\nabla^{2} g^{p}_n$, 
    \begin{align}
        &|\omega^{G}|\nonumber\\
        \leq& \frac{\lambda^2_\mathit{max}}{\mu^2_\mathit{min}}\Big(
	        \sum_{n_1\in \mathcal{N}} |\frac{\nu_{n}}{2\mu_{n}\mu_{n_1}}|
	        + \sum_{n_1\in \{<\delta(n)\}\bigcup \{n\}}|1+\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}|\nonumber\\
	        &+ \sum_{n_1\in \{\leq\delta(n)\}}|\theta^{*}_n \frac{\nu_{n}}{2\mu_{n}}|\Big)\nonumber\\
	=& K_n,
    \end{align}
    where $\mu_{min} = \mathop{\min}_n \mu_{n}$ and $\lambda_{max} = \mathop{\max}_n \lambda_{n}$.
    Thus, if $\ell_n = K_n$ are limited, $\ell_n I \succeq \nabla^{2} g^{p}_n(\bm x)$ and $g^{p}_n(\bm x)$ is Lipschiz smooth.
    
    % In the meanwhile, since $\frac{1}{\mu_\mathit{min}}$ and $\mu_n$ are limited, $\nabla^{2} g^{p}_n(\bm x) \succeq \gamma_n I$, \ie $\gamma_n = -K_n$.

        % \onecolumn
\section{A Proof of Theorem \ref{theorem:innerConvergence1}}\label{app:theorem:innerConvergence1}    
\subsection{convergence Analysis}
    % We prove Lemma \ref{theorem:innerConvergence1} here.
    First, we prove the convergence of Algorithm \ref{alg:nonconvexadmm}.
    There are some properties in $g^{p}_n\left(\bm\lambda \right)$, as follows,
    \begin{enumerate}
        \item there exists a positive constant $\ell_n>0$, it has
        $\left\|\nabla g^{p}_n\left(\bm\lambda \right)-\nabla g^{p}_n\left(\bm x^{'} \right)\right\| \leq \ell_n\left\|\bm\lambda-\bm x^{'} \right\| \quad \forall \bm\lambda, \bm x^{'}$
        \item for any $n$, the $\rho_{n}$ chosen is large enough, 
        $\rho_{n}>\max \left\{\frac{2 \ell_n^{2}}{\varepsilon_{n}}, \ell_n\right\}$, 
        where $\varepsilon_{n}$ satisfies $\varepsilon_{n}I \preceq \nabla^2 L^{p}_n(\bm x)$
        \item $\mathop{\min}_{\bm x\in \Omega} g^{p}_n(\bm x)>-\infty$ 
    \end{enumerate}
    
    Proof of Property 1), Proposition \ref{theorem:NFP_Problem} has proven there exists a positive constant $\ell_n>0$ satisfies $\ell_n I \succeq \nabla^{2} g^{p}_n(\bm x)$, \ie $\left\|\nabla g^{p}_n\left(\bm\lambda \right)-\nabla g^{p}_n\left(\bm x^{'} \right)\right\| \leq \ell_n\left\|\bm\lambda-\bm x^{'} \right\| \quad \forall \bm\lambda, \bm x^{'}$.
    
    Proof of Property 2), obviously, since $\varepsilon_{n}I \preceq \nabla^2 L^{p}_n(\bm x)$, $\varepsilon_{n} = -\ell_n+\rho_n$. Due to $\rho_n>2\ell_n$ and $\rho_n>0$, $(\rho_n-2\ell_n)(\rho_n+\ell_n)>0$. Thus, $\rho_{n}>\max \left\{\frac{2 \ell_n^{2}}{\varepsilon_{n}}, \ell_n\right\}$.
    
    Proof of Property 3), when $\bm x\in \Omega$, we have,
    \begin{align}
        & g^{p}_n(\bm x) = f^{p,u}_n(\bm x) - \theta^{*}_n f^{p,l}_n(\bm x) \nonumber\\
        &= \Phi_{\delta(n)}(\bm x)\Phi_{\delta(n)-1}(\bm x) + \Upsilon(\bm x)\Psi_n(\bm x)\nonumber\\
        &- \theta^{*}_n\Psi_n(\bm x)\Phi_{\delta(n)}(\bm x)\Phi_{\delta(n)-1}(\bm x) \nonumber\\
        & \geq - \theta^{*}_n\lambda_n >-\infty
    \end{align}
    where $\theta^{*}_n$ and $\lambda_n$ are constant, $\Phi_{\delta(n)}(\bm x), \Phi_{\delta(n)-1}(\bm x) \in [0,1]$, $\Psi_n(\bm x) \in [0,\lambda_n]$ and $\Upsilon(\bm x) > 0$
    
    \begin{itemize}
        \item \textbf{Dual variable convergence} $L^{p}_n(x;y)$ will increase after each dual.\cite{boyd2011distributed}
        \item \textbf{Consensus convergence} The consensus constraint is satisfied eventually $\lim_{t \rightarrow \infty}\left\|\bm x_{n}^{t+1}-\bm x_{o}^{t+1}\right\|=0, \forall n$.
        \item \textbf{Objective Function convergence} Above the property 1) and 2), we have    
    \begin{align}
        &L^{p}_n\left(\left\{\bm x_{n}^{t+1}\right\}, \bm x_{o}^{t+1} ; y^{t+1}\right)-L^{p}_n\left(\left\{\bm x^t_{n}\right\}, \bm x^t_{o} ; \bm\sigma^t\right)\nonumber\\
        &\leq \sum_{n\in\mathcal{N}}\left(\frac{L_{n}^{2}}{\rho_{n}}-\frac{\varepsilon_{n}}{2}\right)\left\|\bm x_{n}^{t+1}-\bm x^t_{n}\right\|^{2}\nonumber\\
        &-\frac{\sum_{n\in\mathcal{N}}\rho_{n}}{2}\left\|\bm x_{o}^{t+1}-\bm x^t_{o}\right\|^{2}<0
    \end{align}
    according to \cite{hong2016convergence}.
    Thus, $L^{p}_n(x;y)$ will decrease after each dual.
    Furthermore, according to property 3), we obtain $L^{p}_n\left(\left\{\bm x_{n}^{t+1}\right\}, \bm x_{o}^{t+1} ; y^{t+1}\right)$ is limited.
    \end{itemize}
    
    Thus, the Algorithm \ref{alg:nonconvexadmm} will converge to the set of stationary solutions.
    
    \subsection{Convergence Rate}
    We have proven some properties in $g^{p}_n\left(\bm\lambda \right)$ and the convergence of Algorithm \ref{alg:nonconvexadmm}.
    Based on [\cite{hong2016convergence}, Theorem 2.5.], we have
    \begin{equation}
        \epsilon^{ac} <\frac{k^{\Gamma}(L^{p}\left(\left\{\bm x_{n}^{1}\right\}, \bm x_{o}^{1}, \bm \sigma^{1}\right)-\underline{G^{p}})}{p^\mathit{sysn}\Gamma^{sysn}},
    \end{equation}
    where $p^\mathit{sysn}\Gamma^{sysn}$ means the number of successful iterations.
    Therefore, we have
    \begin{equation}
        \Gamma^{sysn}<\frac{k^{\Gamma}(L^{p}\left(\left\{\bm x_{n}^{1}\right\}, \bm x_{o}^{1}, \bm \sigma^{1}\right)-\underline{G^{p}})}{\epsilon^{ac} p^\mathit{sysn}},
    \end{equation}
    where  
    $\epsilon^{ac}$ is a positive iteration factor, 
    $k^{\Gamma}$ is a constant, 
    $p^\mathit{sysn} = \Pi_{n\in\mathcal{N}}(\frac{1}{C} \sum_{c\in\mathcal{C}}p_{n,c})$ probability of successfully completing a synchronous update,
    $\underline{G^{p}}$ is the lower bound of $\sum_{n\in\mathcal{N}} g^{p}_n(\bm x_n)$,
    % \ie $\underline{G^{p}} = \inf_{\bm x_n} \sum_{n\in\mathcal{N}} g^{p}_n(\bm x_n)$,
    and $\Gamma^{sysn}$ is number of iterations, \ie 
    $\Gamma^{sysn} = \min \left\{t\mid \eta\left(\bm x^t, \bm\sigma^t\right) \leq \epsilon, t \geq 0\right\}$.

    Above all, we derive that Algorithm \ref{alg:nonconvexadmm} converge to an $\epsilon^{ac}$-stationary point within $O(1/(p^\mathit{sysn}\epsilon^\mathit{ac}))$.
    

\section{}\label{app:thm:single-or-multi}    
\subsection{A Proof of Theorem \ref{thm:single-or-multi}}\label{app:thm:single-or-multi-A}
If the amount of migration tasks from the local server to other servers is 0, \ie $\phi^{out}(\bm \eta^s) = \sum_{m'\in\{\mathcal{M}/m_n\}} \eta^s_{m_n,m'} \sum_{\delta \in \Delta} \lambda^{s}_{\delta,m_n}$, 
and the amount of migration tasks from other servers to the local server is 0, \ie $\phi^{in}(\bm \eta^s) = \sum_{m'\in\{\mathcal{M}/m_n\}} \eta^s_{m',m_n} \sum_{\delta \in \Delta} \lambda^{s}_{\delta,m'}$,
 the migration decision variableis $y_{m_n} = 0$.
Otherwise, vice versa.
Thus, we obtain
    \begin{equation}  
	% \label{eq:opy-y}
		y_{m_n} = \left\{
		\begin{array}{ll}
		 1, &\quad  \phi^{in}(\bm \eta^s)+\phi^{out}(\bm \eta^s)> 0\\
		 0 , &\quad otherwise,
		\end{array}
		\right..	
	\end{equation}

\subsection{An Alternative Problem for \textbf{(PoPeC)}}\label{app:thm:single-or-multi-B}
If  $\phi^{in}(\bm \eta^s)+\phi^{out}(\bm \eta^s) = 0$,
we derive $f^p_n(\hat t^\mathit{tr}_n,\bm\eta^u) = f^s_n(\hat t^\mathit{tr}_n,\bm\eta^u, \bm\eta^s)$.
In other words, if  $\phi^{in}(\bm \eta^s)+\phi^{out}(\bm \eta^s) = 0$, we can derive the obtained results can cover all the results of Server Collaboration, no matter what $y_{m_n}$ is.
That is $\frac{1}{N}\sum_{n\in\mathcal{N}} F_n(\bm x, \bm y, \bm z) \geq \frac{1}{N}\sum_{n\in\mathcal{N}} F_n(\bm x, \bm 1, \bm z)$, where $F_n(\bm x, \bm y, \bm z) = \mathbb{E}[A_n]$.

Combining Theorem \ref{thm:single-or-multi} and discussion of constraints, there is a comparable solution
    $\hat{\bm y^*} = \bm 1$.
    which holds $\sum_{n\in\mathcal{N}} F_n(\bm x, \bm y^{*}, \bm z)=\sum_{n\in\mathcal{N}} F_n(\bm x, \hat{\bm y^{*}}, \bm z)$.
Hence, we have 
    \begin{equation}
    \label{eq:fn=f1n}
        \sum_{n\in\mathcal{N}} F_n(\bm x, \hat{\bm y^{*}}, \bm z) \leq \sum_{n\in\mathcal{N}} F_n(\bm x, \bm y, \bm z)\leq \sum_{n\in\mathcal{N}} F_n(\bm x, \bm y, \bm z).
    \end{equation}


% Hence, we have $\hat{\bm y^{*}} = \bm 1$, which represents $$\sum_{n\in\mathcal{N}} F_n(\bm x, \hat{\bm y^{*}}, \bm z) = \sum_{n\in\mathcal{N}} F_n(\bm x, \bm y^{*}, \bm z) \leq \sum_{n\in\mathcal{N}} F_n(\bm x, \bm y, \bm z).$$

% Another benefit is that if we set $y_{m_n} = 1, \forall n$, we ignore servers that only perform local task offloading without server coordination.
Similar to Problem \textbf{P1} and \textbf{P2}, we aim to minimize a highly accurate upper bound for the average expected PAoI of multi-priority users through the following approach.
Thus, one alternative for \textbf{(PoPeC)} is
\begin{equation}
\label{eq:P3-proof}
\begin{split}
    \textbf{(P3)}~&\mathop{\min}_{\bm x, \bm z}
    \frac{1}{N}\sum_{n\in\mathcal{N}} F^1_n(\bm x, \bm z) \\
    \text{s.t.}&~ 
    \eqref{eq:c1},\eqref{eq:c2},%to
    \eqref{eq:c3a},\eqref{eq:c5a},\eqref{eq:c4a},%tm
    \eqref{eq:c6},%transmission
    % \eqref{eq:c-y}, %y
    \eqref{eq:c7b},\eqref{eq:c8b}, %capacity
\end{split}
\end{equation}
where $F^1_n(\bm x, \bm z) = \hat t^\mathit{tr}_n + \frac{1}{\sum_{c\in\mathcal{C}}p_{n,c}\eta^u_{n,c}\lambda_{n}} + \sum_{m\in\mathcal{M}} \pi_{n,m}(\bm z)$,
$\bm x = \{\hat t^\mathit{tr}, \bm\eta^u\}$ and $\bm z = \bm\eta^s$.


\section{A Proof of Lemma \ref{lemma:Transform-DataMigration-ChannelAllocation}}\label{app:lemma:Transform-DataMigration-ChannelAllocation}  
\textbf{P3} is
\begin{equation}
\label{eq:P3-copy}
\begin{split}
    &\mathop{\min}_{\bm x, \bm z}
    \frac{1}{N}\sum_{n\in\mathcal{N}} F^1_n(\bm x, \bm z) \\
    =&\mathop{\min}_{\bm x, \bm z}
    \frac{1}{N}\sum_{n\in\mathcal{N}}( F^2_n(\bm x) +F^3_n(\bm z, \bm \lambda^s))\\
    \text{s.t.}&~ 
    \eqref{eq:c1},\eqref{eq:c2},%to
    \eqref{eq:c3a},\eqref{eq:c4a},%tm
    \eqref{eq:c6},%transmission
    % \eqref{eq:c-y}, %y
    \eqref{eq:c7b},\eqref{eq:c8b},\\ %capacity\\
    \sum_{m' \in \mathcal{M}} &  \eta^s_{m,m'} \lambda^{s}_{\delta,m}=\sum_{n \in \mathcal{N}^{\delta}_m}\sum_{c \in C} p_{n,c} \eta^u_{n,c}\lambda_{n},
\end{split}
\end{equation}
If you decompose the problem in terms of different variables,
$\sum_{m' \in \mathcal{M}}  \eta^s_{m,m'} \lambda^{s}_{\delta,m}$ and $\sum_{n \in \mathcal{N}^{\delta}_m}\sum_{c \in C} p_{n,c} \eta^u_{n,c}\lambda_{n}$ will always remain consistent due to the presence of the constraint \eqref{eq:c5a}
which is equivalent to
\begin{equation}
\label{eq:c-to&tm}
    \lambda^{s}_{\delta,m} \sum_{m' \in \mathcal{M}} \eta^s_{m,m'}  = \sum_{n \in \mathcal{N}^{\delta}_m}\sum_{c \in C} p_{n,c} \eta^u_{n,c}\lambda_{n},
    % = \sum_{\delta \in \Delta} \lambda^{s}_{\delta,m}
    , \quad \forall m \in \mathcal{M}.
\end{equation}
This makes it simpler to solve for the best $\bm x$ and $\bm z$ because their values don't change when they are solved iteratively.
Therefore, in addition to decomposing the objective functions and constraints as
\begin{align}
    \textbf{(sp1)}~&\mathop{\min}_{\bm x}\frac{1}{N}\sum_{n\in\mathcal{N}} F^2_n(\bm x) \nonumber\\
    \text{s.t.}&~ \eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c5a},\eqref{eq:c6},\eqref{eq:c7b},\eqref{eq:c8b},
\end{align}

\begin{equation}
\begin{split}
    \textbf{(sp2)}~&\mathop{\min}_{\bm z}\frac{1}{N}\sum_{n\in\mathcal{N}} F^3_n(\bm z, \bm \lambda^s) \\
    \text{s.t.}&~ \eqref{eq:c3a},\eqref{eq:c5a},\eqref{eq:c4a},
\end{split}
\end{equation}
constraint \eqref{eq:c5a} in \textbf{sp1} is replaced by the auxiliary inequality \eqref{eq:DataMigration-AuxiliaryInequality2} as shown in \textbf{P3-1},
% to guarantee a better solution of \textbf{P3} 
    \begin{align}
        \label{eq:DataMigration-AuxiliaryInequality2}
             \sum_{n \in \mathcal{N}^{\delta}_m}\sum_{c \in C} p_{n,c} \eta^u_{n,c}\lambda_{n} &\leq \sum_{m' \in \mathcal{M}}  \eta^s_{m,m'} \lambda^{s}_{\delta,m}
    \end{align}
which leads to a better solution for $\bm x$, the reason is as follows
 
    Denote $\bm x_1$, $\bm x_2$, $\bm x_3$ as
    \begin{align}
        \bm x_1 = \mathop{\arg \min}_{\bm x} \Big\{ \sum_{n\in\mathcal{N}} F^2_n(\bm x)  ~ \text{s.t.} ~ \eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c6},\eqref{eq:c7b},\eqref{eq:c8b},\nonumber\\
        \{\sum_{n \in \mathcal{N}^{\delta}_m}\sum_{c \in C} p_{n,c} \eta^u_{n,c}\lambda_{n} \leq \sum_{m' \in \mathcal{M}}  \eta^s_{m,m'} \lambda^{s}_{\delta,m}\} \Big\}\nonumber
    \end{align}
    \begin{align}
        \bm x_2 = \mathop{\arg \min}_{\bm x} \Big\{ \sum_{n\in\mathcal{N}} F^2_n(\bm x)  ~ \text{s.t.} ~ \eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c6},\eqref{eq:c7b},\eqref{eq:c8b},\nonumber\\
        \{\sum_{n \in \mathcal{N}^{\delta}_m}\sum_{c \in C} p_{n,c} \eta^u_{n,c}\lambda_{n} = \sum_{m' \in \mathcal{M}}  \eta^s_{m,m'} \lambda^{s}_{\delta,m}\} \Big\}\nonumber
    \end{align}
    \begin{align}
        \bm x_3 = \mathop{\arg \min}_{\bm x} \Big\{ \sum_{n\in\mathcal{N}} F^2_n(\bm x)  ~ \text{s.t.} ~ \eqref{eq:c1},\eqref{eq:c2},\eqref{eq:c6},\eqref{eq:c7b},\eqref{eq:c8b},\nonumber\\
        \{\sum_{n \in \mathcal{N}^{\delta}_m}\sum_{c \in C} p_{n,c} \eta^u_{n,c}\lambda_{n} < \sum_{m' \in \mathcal{M}}  \eta^s_{m,m'} \lambda^{s}_{\delta,m}\} \Big\}\nonumber
    \end{align}
    
    Obviously, 
    \begin{equation}
        \sum_{n\in\mathcal{N}} F_n(\bm x_1) = \min \{\sum_{n\in\mathcal{N}} F_n(\bm x_2), \sum_{n\in\mathcal{N}} F_n(\bm x_3)\}.\nonumber
    \end{equation}
Meanwhile, the constraint \eqref{eq:c5a} in \textbf{sp2} is unchanged as shown in \textbf{P3-2}, in order to ensure that constraint \eqref{eq:c5a} of \textbf{P3} is satisfied.
    
    



\section{}\label{app:DataMigration-MigrationAllocation}
\subsubsection{Problem Transform}\label{app:proposition:DataMigration-MigrationAllocation1}
First, $\bm \lambda^s$ can be obtained by $\lambda^{s}_{\delta,m}=\sum_{n\in\mathcal{N}^{\delta}_m}\sum_{c\in\mathcal{C}} p_{n,c} \lambda_{n,c}$ according to system model.
With given $\bm \lambda^s$, transforming the problem from \textbf{P3-2} to \textbf{3-5}, a similar proof is already discussed in Proposition \ref{pro:npl-mp}.
$\theta^{*}_n$ is achieved if and only if
	\begin{align}
	\mathop{\min}_{\{\bm z_{n,m}\}} \{\pi^{u}_{n,m}(\bm z_{n,m}) - \vartheta^{*}_{n,m} \pi^{l}_{n,m}(\bm z_{n,m})\}
	\nonumber\\ 
       = \pi^{u}_{n,m}(\bm z^*_{n,m}) - \vartheta^{*}_{n,m} \pi^{l}_{n,m}(\bm z^*_{n,m}) = 0.
    \label{eq:NFP-optimal-theta2}
    \end{align}
This is a necessary and sufficient condition.

We can also use Algorithm \ref{alg:NFP} (NFPA) to transform this problem with a slight modification.

\subsubsection{Problem Solving}\label{app:lemma:DataMigration-MigrationAllocation2}
Problems \textbf{P35} are challenging to solve since they are still non-convex, but it is simple to identify that they are cubic function problems with a finite range of independent variables taking values. Alternatively put, this is a Lipschitz smooth function with constant $\ell_{n,m}$ satisfying
\begin{equation}
    \ell_{n,m} I \succeq \nabla^{2} \big(\pi^{u}_{n,m}(\bm z_{n,m}) - \vartheta^{*}_{n,m} \pi^{l}_{n,m}(\bm z_{n,m})\big),
\end{equation}
which is like $g^{p}_n$ in Proposition \ref{theorem:NFP_Problem}. 

As a result, we can likewise efficiently handle $\{\bm z_{n,m}\}$ using Algorithm 2 with a few slight adjustments.
\subsubsection{Convergence Analysis}\label{app:proof:DataMigration-MigrationAllocation3}
    A  similar instead of the same result of Convergence Analysis can be obtained by Theorem \ref{theorem:innerConvergence1}.
    If $\rho_n>2\ell_n$, Algorithm \ref{alg:nonconvexadmm} converge to an $\epsilon^{ac}$-stationary point within $O(1/(p^\mathit{sysn}\epsilon^\mathit{ac}))$.
    However, in a network with wired communication, the reliability rate of synchronous iterative communication is $p^\mathit{sysn}=1$
    Thus, we derive the NAC algorithm converges within $O(1/\epsilon^{ac}) in this case$.

 

\section{A Proof of Theorem \ref{thm:DataMigration-Convergence}}\label{app:thm:DataMigration-Convergence}
    % We prove Theorem \ref{thm:DataMigration-Convergence} here.
    
    First, we see the equivalent optimal solution of the migration $\hat{\bm y^{*}}$ from Theorem \ref{thm:single-or-multi}. Hence, we have these two inequalities as
    \begin{align}
    \begin{split}
        &\frac{1}{N}\sum_{n\in\mathcal{N}} F_n(\bm x^t, \hat{\bm y^{*}}, \bm z^t) \\
        \mathop{=}^{(a)} &\frac{1}{N}\sum_{n\in\mathcal{N}} F^1_n(\bm x^t, \bm z^t) \\
        \mathop{=}^{(b)} &\frac{1}{N}\sum_{n\in\mathcal{N}} (F^2_n(\bm x^{t})+F^3_n(\bm z^{t}, \bm \lambda^{s,t}))\\
        \mathop{\ge}^{(c)} &\frac{1}{N}\sum_{n\in\mathcal{N}} (F^2_n(\bm x^{t+1})+F^3_n(\bm z^{t}, \bm \lambda^{s,t}))\\
        \mathop{\ge}^{(d)} &\frac{1}{N}\sum_{n\in\mathcal{N}} (F^2_n(\bm x^{t+1})+F^3_n(\bm z^{t}, \bm \lambda^{s,t+1}))\\
        \mathop{\ge}^{(e)} &\frac{1}{N}\sum_{n\in\mathcal{N}} (F^2_n(\bm x^{t+1})+F^3_n(\bm z^{t+1}, \bm \lambda^{s,t+1}))\\
        \mathop{=}^{(f)} &\frac{1}{N}\sum_{n\in\mathcal{N}} F^1_n(\bm x^{t+1},\bm z^{t+1})\\
        \mathop{=}^{(g)} &\frac{1}{N}\sum_{n\in\mathcal{N}} F_n(\bm x^{t+1}, \hat{\bm y^{*}}, \bm z^{t+1}).
    \end{split}
    \end{align}
    where 
    (a) and (g) hold according to \eqref{eq:fn=f1n},
    (b) and (f) hold according to Lemma \ref{lemma:Transform-DataMigration-ChannelAllocation},
    (c) holds according to Lemma \ref{lemma:DataMigration-ChannelAllocation},
    (e) holds according to Lemma \ref{lemma:DataMigration-MigrationAllocation2} and the convergence of the NAC algorithm,
    (d) holds and the reason is as follows.
    According to \eqref{eq:DataMigration-AuxiliaryInequality}, we obtain 
    \begin{equation}
    \lambda^{s,t}_{\delta,m}\ge\lambda^{s,t+1}_{\delta,m}, \quad, \forall \delta \in \Delta, \forall m \in \mathcal{M}.
    \end{equation}
    % $\forall \delta \in \Delta, \forall m \in \mathcal{M},~ $.
    In addition, it is easy to get that 
    \begin{equation}
         \frac{\partial F^3_n(\bm z^{t}, \bm \lambda^{s,t})}{\partial \lambda^{s,t}_{\delta,m}}>0,\quad,\forall \delta \in \Delta, \forall m \in \mathcal{M},
    \end{equation}
    in the domain of the definition of $\bm \lambda^s$.
    Thus, we have $F^3_n(\bm z^{t}, \bm \lambda^{s,t})\ge F^3_n(\bm z^{t}, \bm \lambda^{s,t+1})$.

    
    Based on the inequalities, we obtain
    \begin{align}
        \frac{1}{N}\sum_{n\in\mathcal{N}} F_n(\bm x^t, \hat{\bm y^{*}}, \bm z^t) \ge \frac{1}{N}\sum_{n\in\mathcal{N}} F_n(\bm x^{t+1}, \hat{\bm y^{*}}, \bm z^{t+1})
    \end{align}
    $F_n(\bm x, \bm y, \bm z)$ is a function with positive values and a lower bound.
    Therefore, $F_n(\bm x, \bm y, \bm z)$ monotonically decreases and converges to a unique point.
\end{appendices}

\section{Why Multi-Class }\label{app:proof:sp-mp}  
For highest-class priority user $n^*$, we have
\begin{align}
    &\mathbb{E}[A_{n^*}] - \mathbb{E}[A^{p}_{n^*}] \nonumber\\
    =& (\mathbb{E}[T_{n^*}]+\mathbb{E}[I_{n^*}]+\mathbb{E}[W_{n^*}]+\mathbb{E}[Y_{n^*}])\nonumber\\
    &-(\mathbb{E}[T^{p}_{n^*}]+\mathbb{E}[I^{p}_{n^*}]+\mathbb{E}[W^{p}_{n^*}]+\mathbb{E}[Y^{p}_{n^*}])\nonumber\\
    \mathop{=}^{(a)}& \mathbb{E}[W_{n^*}]-\mathbb{E}[W^{p}_{n^*}]\nonumber\\
    =& \Upsilon(\bm\eta^u) \frac{\zeta_{\Delta}(\bm\eta^u)-\zeta_{\delta(n^*)}(\bm\eta^u)}{(1-\zeta_{\Delta}(\bm\eta^u))(1-\zeta_{\delta(n^*)}(\bm\eta^u))} \nonumber\\
    \mathop{\geq}^{(b)}& 0.
\end{align}
where 
$\zeta_{\delta(n^*)}(\bm\eta^u) =\sum_{\delta\in\Delta(\delta(n^*))}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\frac{\eta^u_{n',c}\lambda_{n'}}{\mu_{n'}}$,  
$\zeta_{\Delta}(\bm\eta^u) =\sum_{\delta\in\Delta}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\frac{\eta^u_{n',c}\lambda_{n'}}{\mu_{n'}}$,  and
$\Upsilon(\bm\eta^u) = \frac{1}{2}\sum_{\delta\in\Delta}\sum_{n'\in\mathcal{N}^{\delta}}\sum_{c\in\mathcal{C}}p_{n',c}\eta^u_{n',c}\lambda_{n'}\nu_{n'}$.

(a) holds because we are contrasting in the context of the same strategy and at this point $\mathbb{E}[T_{n^*}]=\mathbb{E}[T^p_{n^*}]$, $\mathbb{E}[Y_{n^*}]=\mathbb{E}[Y^p_{n^*}]$ and $\mathbb{E}[I_{n^*}]=\mathbb{E}[I^p_{n^*}]$.

Inequality (b) holds because $\zeta_{\delta(n^*)}(\bm\eta^u)\leq \zeta_{\Delta}(\bm\eta^u)$ and equality sign achieves if and only if $\Delta=\Delta(\delta(n^*))$.

For lowest-class priority user $n_*$, we derive
\begin{align}
    &\mathbb{E}[A_{n_*}] - \mathbb{E}[A^{p}_{n_*}] \nonumber\\
    =& (\mathbb{E}[T_{n_*}]+\mathbb{E}[I_{n_*}]+\mathbb{E}[W_{n_*}]+\mathbb{E}[Y_{n_*}])\nonumber\\
    &-(\mathbb{E}[T^{p}_{n_*}]+\mathbb{E}[I^{p}_{n_*}]+\mathbb{E}[W^{p}_{n_*}]+\mathbb{E}[Y^{p}_{n_*}])\nonumber\\
    \mathop{=}^{}& \mathbb{E}[W_{n_*}]-\mathbb{E}[W^{p}_{n_*}]\nonumber\\
    =& \frac{\Upsilon(\bm\eta^u)}{1-\zeta_{\Delta}(\bm\eta^u)}(1-\frac{1}{1-\zeta_{\delta(n)-1}(\bm\eta^u)})\nonumber\\
    \mathop{\leq}^{(c)}& 0.
\end{align}
Inequality (c) holds because $\zeta_{\delta(n^*)}(\bm\eta^u), \zeta_{\Delta}(\bm\eta^u) \in (0,1)$ and equality sign achieves if and only if $\Delta=\Delta(\delta(n^*))$.

For user $n$ who belong to the priority level from $\delta^0$ to $\delta^0-\hat\delta$, we obtain
\begin{align}
    &    \mathbb{E}[A^{p}_{n}|\delta(n)=\delta^0] - \mathbb{E}[A^{p}_{n}|\delta(n)=\delta^0-\hat\delta] \nonumber\\
    =& \mathbb{E}[W^{p}_{n}|\delta(n)=\delta^0] - \mathbb{E}[W^{p}_{n}|\delta(n)=\delta^0-\hat\delta]\nonumber\\
    =& \frac{\Upsilon(\bm\eta^u)}{(1-\zeta_{\delta^0}(\bm\eta^u))(1-\zeta_{\delta^0 - 1}(\bm\eta^u))}\nonumber\\
    &- \frac{\Upsilon(\bm\eta^u)}{(1-\zeta_{\delta^0 - \hat\delta}(\bm\eta^u))(1-\zeta_{\delta^0 - \hat\delta - 1}(\bm\eta^u))} \nonumber\\
    \ge& \frac{\Upsilon(\bm\eta^u)(\zeta_{\delta^0}(\bm\eta^u)-\zeta_{\delta^0 - \hat\delta - 1}(\bm\eta^u))}{(1-\zeta_{\delta^0}(\bm\eta^u))(1-\zeta_{\delta^0 - 1}(\bm\eta^u))(1-\zeta_{\delta^0 - \hat\delta - 1}(\bm\eta^u))}\nonumber\\
    % &- \frac{\Upsilon(\bm\eta^u)}{(1-\zeta_{\delta^0 - \hat\delta}(\bm\eta^u))(1-\zeta_{\delta^0 - \hat\delta - 1}(\bm\eta^u))} \nonumber\\
    \mathop{\geq}^{(d)}& 0.
\end{align}
where holds because $\zeta_{\delta^0}(\bm\eta^u)\geq\zeta_{\delta^0 - \hat\delta}(\bm\eta^u)$ and $\zeta_{\delta^0 - 1}(\bm\eta^u)\geq\zeta_{\delta^0 - \hat\delta -1}(\bm\eta^u)$.

% \section{A Proof of Lemma \ref{theorem:innerConvergence2}}\label{app:theorem:innerConvergence2}    
% We have proven some properties in $g^{p}_n\left(\bm\lambda \right)$ and set $\rho_n>\max\{7\ell_n, \ell_n\left(\Gamma^2_n + \frac{3}{7}(\Gamma_n + 1)^2\right)\}$.
% Based on [\cite{hong2017distributed}, Theorem 3.1], the sequence $\{\{\bm x_n\}, \bm x\}$ converges to the set of stationary solutions of problem.

% Additionally, $p^{\mathit{asysn}}\Gamma^{\mathit{asysn}}$ represents the number of successful iterations.
% For $\epsilon^{ac}>0$, we have
%     \begin{equation}
%         p^{\mathit{asysn}}\Gamma^{\mathit{asysn}}\epsilon^{ac} <k^{\Gamma}(L^{p}\left(\left\{\bm x_{n}^{1}\right\}, \bm x_{o}^{1}, \bm \sigma^{1}\right)-\underline{G^{p}}),
%     \end{equation}
%     Therefore, we derive that the asynchronous parallel algorithm is approximate $p_\mathit{asysn}/p_\mathit{sysn}$ times faster, in comparison to the synchronous parallel approach according to Lemma \ref{theorem:innerConvergence1}.
%     \begin{equation}
%          \Gamma^{\mathit{asysn}}<\frac{k^{\Gamma}(L^{p}\left(\left\{\bm x_{n}^{1}\right\}, \bm x_{o}^{1}, \bm \sigma^{1}\right)-\underline{G^{p}})}{\epsilon^{ac}p^{\mathit{asysn}}},
%     \end{equation}
    % We prove Lemma \ref{theorem:innerConvergence2} here.
    % The result of Corollary 2 can be obtained via combining [\cite{hong2017distributed}, Theorem 3.1], [\cite{hong2016convergence}, Lemma 2.3] and [\cite{chang2016asynchronous}, Theorem 1] with the proof of Lemma 1.




\end{document}
