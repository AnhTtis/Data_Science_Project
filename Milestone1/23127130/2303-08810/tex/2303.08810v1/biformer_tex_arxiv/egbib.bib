@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



%  vit
@inproceedings{vit,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  booktitle = {International Conference on Learning Representations, {ICLR} 2021,
               2021},
  year      = {2021},
  url       = {https://openreview.net/forum?id=YicbFdNTTy},
  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/DosovitskiyB0WZ21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{detr,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European Conference on Computer Vision},
  pages={213--229},
  year={2020}
}


@inproceedings{swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}

@inproceedings{cswin,
  title={Cswin transformer: A general vision transformer backbone with cross-shaped windows},
  author={Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12124--12134},
  year={2022}
}

@inproceedings{wang2021crossformer,
  title = {CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention},
  author = {Wang, Wenxiao and Yao, Lu and Chen, Long and Lin, Binbin and Cai, Deng and He, Xiaofei and Liu, Wei},
  booktitle = {International Conference on Learning Representations, {ICLR}},
  url = {https://openreview.net/forum?id=_PHymLIxuI},
  year = {2022}
}

@inproceedings{wang2021pvt,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={568--578},
  year={2021}
}

@inproceedings{xia2022dat,
  title={Vision transformer with deformable attention},
  author={Xia, Zhuofan and Pan, Xuran and Song, Shiji and Li, Li Erran and Huang, Gao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4794--4803},
  year={2022}
}

@inproceedings{dai2017deformable_conv,
  title={Deformable convolutional networks},
  author={Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={764--773},
  year={2017}
}

@inproceedings{tu2022maxvit,
  title={MaxViT: Multi-Axis Vision Transformer},
  author={Tu, Zhengzhong and Talebi, Hossein and Zhang, Han and Yang, Feng and Milanfar, Peyman and Bovik, Alan and Li, Yinxiao},
  booktitle={ECCV},
  year={2022},
}

%  NLP
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{radford2018gpt,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018}
}

@inproceedings{devlin2018bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    pages = "4171--4186",
}

@article{reddy2021dalle,
  title={Dall-e: Creating images from text},
  author={Reddy, Mr D Murahari and Basha, Mr Sk Masthan and Hari, Mr M Chinnaiahgari and Penchalaiah, Mr N},
  year={2021}
}


@article{child2019generating,
  title={Generating long sequences with sparse transformers},
  author={Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal={arXiv:1904.10509},
  year={2019}
}

@article{wang2020linformer,
  title={Linformer: Self-attention with linear complexity},
  author={Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv:2006.04768},
  year={2020}
}

@inproceedings{dai2019transformerxl,
  author    = {Zihang Dai and
               Zhilin Yang and
               Yiming Yang and
               Jaime G. Carbonell and
               Quoc Viet Le and
               Ruslan Salakhutdinov},
  editor    = {Anna Korhonen and
               David R. Traum and
               Llu{\'{\i}}s M{\`{a}}rquez},
  title     = {Transformer-XL: Attentive Language Models beyond a Fixed-Length Context},
  booktitle = {Proceedings of the Conference of the Association for Computational
               Linguistics, {ACL} 2019, Volume 1: Long Papers},
  pages     = {2978--2988},
  year      = {2019}
}

@inproceedings{zeng2022tcformer,
  title={Not All Tokens Are Equal: Human-centric Visual Analysis via Token Clustering Transformer},
  author={Zeng, Wang and Jin, Sheng and Liu, Wentao and Qian, Chen and Luo, Ping and Ouyang, Wanli and Wang, Xiaogang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11101--11111},
  year={2022}
}

@inproceedings{chen2021dpt,
  title={Dpt: Deformable patch-based transformer for visual recognition},
  author={Chen, Zhiyang and Zhu, Yousong and Zhao, Chaoyang and Hu, Guosheng and Zeng, Wei and Wang, Jinqiao and Tang, Ming},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={2899--2907},
  year={2021}
}

@inproceedings{zhu2020deformable_detr,
  author    = {Xizhou Zhu and
               Weijie Su and
               Lewei Lu and
               Bin Li and
               Xiaogang Wang and
               Jifeng Dai},
  title     = {Deformable {DETR:} Deformable Transformers for End-to-End Object Detection},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=gZ9hCDWe6ke},
  timestamp = {Tue, 12 Apr 2022 21:46:12 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/ZhuSLLWD21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{touvron2021deit,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

@article{jiang2021token_labeling,
  title={All tokens matter: Token labeling for training better vision transformers},
  author={Jiang, Zi-Hang and Hou, Qibin and Yuan, Li and Zhou, Daquan and Shi, Yujun and Jin, Xiaojie and Wang, Anran and Feng, Jiashi},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18590--18602},
  year={2021}
}


@misc{nvidia_blog,
  title = {How to Access Global Memory Efficiently in CUDA C/C++ Kernels},
  author={Nvidia},
  howpublished = {\url{https://developer.nvidia.com/blog/how-access-global-memory-efficiently-cuda-c-kernels/}},
  note = {Accessed: 2022-10-25}
}

@article{tay2020transformer_survey,
  title={Efficient transformers: A survey},
  author={Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler, Donald},
  journal={ACM Computing Surveys (CSUR)},
  year={2020},
  publisher={ACM New York, NY}
}

@inproceedings{tang2022quadtree,
  author    = {Shitao Tang and
               Jiahui Zhang and
               Siyu Zhu and
               Ping Tan},
  title     = {Quadtree Attention for Vision Transformers},
  booktitle = {The International Conference on Learning Representations, {ICLR}
               2022, 2022},
  year      = {2022},
  url       = {https://openreview.net/forum?id=fR-EnKWL\_Zb},
  timestamp = {Tue, 18 Oct 2022 08:35:29 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/TangZZT22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{gupta2021topk,
  author    = {Ankit Gupta and
               Guy Dar and
               Shaya Goodman and
               David Ciprut and
               Jonathan Berant},
  editor    = {Nafise Sadat Moosavi and
               Iryna Gurevych and
               Angela Fan and
               Thomas Wolf and
               Yufang Hou and
               Ana Marasovic and
               Sujith Ravi},
  title     = {Memory-efficient Transformers via Top-k Attention},
  booktitle = {Proceedings of the Workshop on Simple and Efficient Natural
               Language Processing, 2021},
  pages     = {39--52},
  year      = {2021},
  url       = {https://doi.org/10.18653/v1/2021.sustainlp-1.5},
  doi       = {10.18653/v1/2021.sustainlp-1.5},
  timestamp = {Mon, 01 Aug 2022 16:27:39 +0200},
  biburl    = {https://dblp.org/rec/conf/emnlp/GuptaDGCB21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  booktitle={Proceedings of Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{huang2019ccnet,
  title={Ccnet: Criss-cross attention for semantic segmentation},
  author={Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={603--612},
  year={2019}
}

@article{li2022uniformer,
  title={Uniformer: Unified transformer for efficient spatiotemporal representation learning},
  author={Li, Kunchang and Wang, Yali and Gao, Peng and Song, Guanglu and Liu, Yu and Li, Hongsheng and Qiao, Yu},
  journal={arXiv:2201.04676},
  year={2022}
}

@article{chu2021twins,
  title={Twins: Revisiting the design of spatial attention in vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Wang, Yuqing and Zhang, Bo and Ren, Haibing and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={9355--9366},
  year={2021}
}

@inproceedings{ren2022shunted,
  title={Shunted Self-Attention via Multi-Scale Token Aggregation},
  author={Ren, Sucheng and Zhou, Daquan and He, Shengfeng and Feng, Jiashi and Wang, Xinchao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10853--10862},
  year={2022}
}

@inproceedings{chen2021regionvit,
  author    = {Chun{-}Fu Chen and
               Rameswar Panda and
               Quanfu Fan},
  title     = {RegionViT: Regional-to-Local Attention for Vision Transformers},
  booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
               2022, Virtual Event, April 25-29, 2022},
  publisher = {OpenReview.net},
  year      = {2022},
  url       = {https://openreview.net/forum?id=T\_\_V3uLix7V},
  timestamp = {Sat, 20 Aug 2022 01:15:42 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/0001PF22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{yao2022wavevit,
  title={Wave-vit: Unifying wavelet and transformers for visual representation learning},
  author={Yao, Ting and Pan, Yingwei and Li, Yehao and Ngo, Chong-Wah and Mei, Tao},
  booktitle={European Conference on Computer Vision},
  pages={328--345},
  year={2022},
  organization={Springer}
}

@article{wang2022pvtv2,
  title={Pvt v2: Improved baselines with pyramid vision transformer},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  journal={Computational Visual Media},
  volume={8},
  number={3},
  pages={415--424},
  year={2022},
  publisher={Springer}
}

@inproceedings{radosavovic2020regnet,
  title={Designing network design spaces},
  author={Radosavovic, Ilija and Kosaraju, Raj Prateek and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10428--10436},
  year={2020}
}

@inproceedings{he2016resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={770--778},
  year={2016}
}

@article{ScalableViT,
  title={ScalableViT: Rethinking the context-oriented generalization of vision transformer},
  author={Yang, Rui and Ma, Hailong and Wu, Jie and Tang, Yansong and Xiao, Xuefeng and Zheng, Min and Li, Xiu},
  journal={arXiv:2203.10790},
  year={2022}
}

% sparse attention 

@inproceedings{ramachandran2019stand_slidingattn,
  title={Stand-alone self-attention in vision models},
  author={Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jon},
  booktitle={Proceedings of Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{ho2019seqaxial,
  title={Axial attention in multidimensional transformers},
  author={Ho, Jonathan and Kalchbrenner, Nal and Weissenborn, Dirk and Salimans, Tim},
  journal={arXiv:1912.12180},
  year={2019}
}

@inproceedings{hanruiwang2020hat,
    title     = {HAT: Hardware-Aware Transformers for Efficient Natural Language Processing},
    author    = {Wang, Hanrui and Wu, Zhanghao and Liu, Zhijian and Cai, Han and Zhu, Ligeng and Gan, Chuang and Han, Song},
    booktitle = {Annual Conference of the Association for Computational Linguistics},
    year      = {2020}
}

%  dataset

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={248--255},
  year={2009}
}

@article{zhou2019ade20k,
  title={Semantic understanding of scenes through the ade20k dataset},
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Xiao, Tete and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  journal={International Journal of Computer Vision},
  volume={127},
  number={3},
  pages={302--321},
  year={2019},
  publisher={Springer}
}

@inproceedings{lin2014coco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

% exp related

@article{chen2019mmdetection,
  title={MMDetection: Open mmlab detection toolbox and benchmark},
  author={Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and Liu, Ziwei and Xu, Jiarui and others},
  journal={arXiv:1906.07155},
  year={2019}
}

@inproceedings{yun2019cutmix,
  title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
  author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6023--6032},
  year={2019}
}

@inproceedings{zhang2017mixup,
  author    = {Hongyi Zhang and
               Moustapha Ciss{\'{e}} and
               Yann N. Dauphin and
               David Lopez{-}Paz},
  title     = {mixup: Beyond Empirical Risk Minimization},
  booktitle = {International Conference on Learning Representations, {ICLR} 2018},
  year      = {2018},
  url       = {https://openreview.net/forum?id=r1Ddp1-Rb},
  timestamp = {Thu, 25 Jul 2019 14:25:50 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/ZhangCDL18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{goyal2017accurate_warmup,
  title={Accurate, large minibatch sgd: Training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv:1706.02677},
  year={2017}
}

@inproceedings{cubuk2020randaugment,
  title={Randaugment: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition workshops},
  pages={702--703},
  year={2020}
}

@inproceedings{huang2016stochastic_depth,
  title={Deep networks with stochastic depth},
  author={Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian},
  booktitle={European Conference on Computer Vision},
  pages={646--661},
  year={2016}
}

@inproceedings{lin2017retinanet,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2980--2988},
  year={2017}
}

@inproceedings{he2017maskrcnn,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2961--2969},
  year={2017}
}

@inproceedings{loshchilov2017adamw,
  author    = {Ilya Loshchilov and
               Frank Hutter},
  title     = {Decoupled Weight Decay Regularization},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=Bkg6RiCqY7},
  timestamp = {Thu, 25 Jul 2019 14:26:04 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/LoshchilovH19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kirillov2019semanticfpn,
  title={Panoptic feature pyramid networks},
  author={Kirillov, Alexander and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6399--6408},
  year={2019}
}

@inproceedings{xiao2018upernet,
  title={Unified perceptual parsing for scene understanding},
  author={Xiao, Tete and Liu, Yingcheng and Zhou, Bolei and Jiang, Yuning and Sun, Jian},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={418--434},
  year={2018}
}

@misc{contributors2020mmseg,
  title={OpenMMLab Semantic Segmentation Toolbox and Benchmark},
  author={Contributors, MMSegmentation},
  howpublished = {\url{https://github.com/open-mmlab/mmsegmentation}},
  year={2020}
}

@misc{rw2019timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}


% supp
@article{li2022vitdet,
  title={Exploring plain vision transformer backbones for object detection},
  author={Li, Yanghao and Mao, Hanzi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2203.16527},
  year={2022}
}

@article{chen2022vitadapter,
  title={Vision Transformer Adapter for Dense Predictions},
  author={Chen, Zhe and Duan, Yuchen and Wang, Wenhai and He, Junjun and Lu, Tong and Dai, Jifeng and Qiao, Yu},
  journal={arXiv preprint arXiv:2205.08534},
  year={2022}
}