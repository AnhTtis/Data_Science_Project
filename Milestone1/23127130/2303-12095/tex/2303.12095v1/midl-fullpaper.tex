\documentclass{midl} % Include author names
%\documentclass[anon]{midl} % Anonymized submission

% The following packages will be automatically loaded:
% jmlr, amsmath, amssymb, natbib, graphicx, url, algorithm2e
% ifoddpage, relsize and probably more
% make sure they are installed with your latex distribution

\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{siunitx}
\usepackage{caption}

%\captionsetup{skip=5pt}

\usepackage{mwe} % to get dummy images
\jmlrvolume{-- Under Review}
\jmlryear{2023}
\jmlrworkshop{Full Paper -- MIDL 2023 submission}
\editors{Under Review for MIDL 2023}

\title[Interpretable prediction of IBD disease features using WSL]{Interpretable histopathology-based prediction of disease relevant features in Inflammatory Bowel Disease biopsies using weakly-supervised deep learning}

 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address
 % \midlauthor{\Name{Author Name1} \Email{abc@sample.edu}\and
 %  \Name{Author Name2} \Email{xyz@sample.edu}\\
 %  \addr Address}

 % Three or more authors with the same address:
 % \midlauthor{\Name{Author Name1} \Email{an1@sample.edu}\\
 %  \Name{Author Name2} \Email{an2@sample.edu}\\
 %  \Name{Author Name3} \Email{an3@sample.edu}\\
 %  \addr Address}


% Authors with different addresses:
% \midlauthor{\Name{Author Name1} \Email{abc@sample.edu}\\
% \addr Address 1
% \AND
% \Name{Author Name2} \Email{xyz@sample.edu}\\
% \addr Address 2
% }

%\footnotetext[1]{Contributed equally}

% More complicate cases, e.g. with dual affiliations and joint authorship
\midlauthor{\Name{Ricardo Mokhtari\nametag{$^{1}$}} \Email{ricardo.mokhtari@astrazeneca.com}\\
\Name{Azam Hamidinekoo\nametag{$^{1}$}} \Email{azam.hamidinekoo@astrazeneca.com}\\
\Name{Daniel Sutton\nametag{$^{1}$}} \Email{daniel.sutton@astrazeneca.com}\\
\Name{Arthur Lewis\nametag{$^{1}$}} \Email{arthur.lewis@astrazeneca.com}\\
\Name{Bastian R. Angermann\nametag{$^{2}$}} \Email{bastian.angermann@astrazeneca.com}\\
\Name{Ulf Gehrmann\nametag{$^{2}$}} \Email{ulf.gehrmann@astrazeneca.com}\\
\Name{P\r{a}l Lundin\nametag{$^{3}$}} \Email{pal.lundin1@astrazeneca.com}\\
\Name{Hibret Adissu\nametag{$^{4}$}} \Email{hibret.adissu@astrazeneca.com}\\
\Name{Junmei Cairns\nametag{$^{2}$}} \Email{junmei.cairns@astrazeneca.com}\\
\Name{Jessica Neisen\nametag{$^{2}$}} \Email{jessica.neisen@astrazeneca.com}\\
\Name{Emon Khan\nametag{$^{5}$}} 
\Email{emon.khan@astrazeneca.com}\\
\Name{Daniel Marks\nametag{$^{3}$}} \Email{daniel.marks@astrazeneca.com}\\
\Name{Nia Khachapuridze\nametag{$^{2,3}$}} \Email{nia.khachapuridze@astrazeneca.com}\\
\Name{Talha Qaiser\nametag{$^{1}$}} \Email{talha.qaiser1@astrazeneca.com}\\
\Name{Nikolay Burlutskiy\nametag{$^{1}$}} \Email{nikolay.burlutskiy@astrazeneca.com}\\
\addr $^{1}$ Imaging and Data Analytics, AstraZeneca, Cambridge, UK \\
\addr $^{2}$ Translational Science and Experimental Medicine, AstraZeneca, Gothenburg, Sweden \\
\addr $^{3}$ Early Clinical Development, AstraZeneca, Cambridge, UK \\
\addr $^{4}$ Respiratory and Immunology Safety Pathology, AstraZeneca, Gaithersburg, USA\\
\addr $^{5}$ Late Respiratory and Immunology, AstraZeneca, Cambridge, UK
}

\begin{document}

\maketitle

\begin{abstract}
Crohn's Disease (CD) and Ulcerative Colitis (UC) are the two main Inflammatory Bowel Disease (IBD) types. We developed interpretable deep learning models to identify histological disease features for both CD and UC using only endoscopic labels. We explored fine-tuning and end-to-end training of two state-of-the-art self-supervised models for predicting three different endoscopic categories (i) CD vs UC (AUC=0.87), (ii) normal vs lesional (AUC=0.81), (iii) low vs high disease severity score (AUC=0.80). With the support of a pathologist, we explored the relationship between endoscopic labels, model predictions and histological evaluations qualitatively and quantitatively and identified cases where the pathologist's descriptions of inflammation were consistent with regions of high attention. In parallel, we used a model trained on the Colon Nuclei Identification and Counting (CoNIC) dataset to predict and explore 6 cell populations. We observed consistency between areas enriched with the predicted immune cells in biopsies and the pathologist's feedback on the attention maps. Finally, we identified several cell level features indicative of disease severity in CD and UC. These models can enhance our understanding about the pathology behind IBD and can shape our strategies for patient stratification in clinical trials.
\end{abstract}

% This  tendency of histological presentation to be more severe than endoscopic presentation was previously published in the literature.

%We produced visual attention maps to interpret what the models learned and validated them with the support of a pathologist, where we observed a strong association between the models' predictions and histopathological inflammatory features of the disease. Additionally, we identified several cases where the model incorrectly predicted normal samples as lesional but were correct on the microscopic level when reviewed by the pathologist. This  tendency of histological presentation to be more severe than endoscopic presentation was previously published in the literature. In parallel, we utilised a model trained on the Colon Nuclei Identification and Counting (CoNIC) dataset to predict and explore 6 cell populations. We observed correlation between areas enriched with the predicted immune cells in biopsies and the pathologist's feedback on the attention maps. Finally, we identified several cell level features indicative of disease severity in CD and UC. These models can enhance our understanding about the pathology behind IBD and can shape our strategies for patient stratification in clinical trials.


\begin{keywords}
Weakly supervised learning, self-supervised learning, attention maps, IBD.
\end{keywords}

\newpage

\section{Introduction}

Inflammatory bowel diseases (IBD) are chronic, relapsing-remitting inflammatory disorders of the gastrointestinal (GI) tract. Crohn's disease (CD) and Ulcerative colitis (UC) represent the two main types of IBD. Both result from a complex interplay of several factors, including abnormal immune responses, genetics, microbiome and environmental triggers \cite{baumgart2007inflammatory}. CD can affect any region of the gut, and is characterised by segmental mucosal ulceration, transmural inflammation, fissures, fibrosis, and stricture formation. In contrast, UC principally involves the colon, and manifests as continuous mucosal inflammation extending from the rectum proximally, with variable extent, and a more superficial inflammatory infiltrate. CD and UC share similar symptoms, but are pathophysiologically distinct diseases \cite{shanahan2001inflammatory}. 

% However, in approximately 10\% of cases the observed clinical and pathological features are insufficient to reliably distinguish between the two diagnoses, and such patients are diagnosed with IBD-unclassified (IBD-U). 

IBD is diagnosed based on a combination of clinical presentation, radiographic, endoscopic and histopathological findings \cite{deroche2014histological}. Defining the extent and severity of inflammation in IBD can influence treatment decisions and support prediction of a patient’s prognosis. While endoscopic evaluation assesses the macroscopic tissue, histopathological evaluation assesses the microscopic tissue and is typically carried out through a trained pathologist's visual inspection of a Haematoxylin \& Eosin (H\&E)-stained tissue, digitised into a whole slide image (WSI). While there is a strong correlation between endoscopic and histopathological assessment \cite{irani2018correlation}, the relationship between these two data modalities (especially the relationship of endoscopic scores to histopathology) is not completely understood \cite{lemmens2013correlation} and can potentially be improved through the development of interpretable machine learning models that predict endoscopic categories from H\&E stained WSIs coupled with the interpretation of model predictions by a pathologist.

% These models, once trained, can be used to rank WSIs by disease severity so that pathologists can prioritise the most severe tissues first.

%Several histopathological indices have been developed for IBD \cite{reddy2019predicting, abbas2019biomarker, popa2020machine}, but their relative complexity hinders the development of AI algorithms without large-scale labour-intensive manual annotations by pathologists. We, therefore, aimed to develop tools to assist decoding the complex histopathological disease features for both CD and UC. This will inform understanding of disease pathology and patient stratification to support clinical trial recruitment strategies.

In this paper we demonstrate that applying self-supervised learning coupled with weakly-supervised learning to H\&E-stained IBD biopsies can accurately distinguish disease type, macroscopic tissue appearance, and endoscopic scores. Specifically, we trained two recent state-of-the-art architectures, including Dual-Stream Multiple Instance Learning (DSMIL) \cite{li2021dual} and  Hierarchical Image Pyramid Transformer (HIPT) \cite{chen2022scaling} on the large SPARC IBD dataset containing 1394 WSIs, and explored two training strategies - fine-tuning and end-to-end (E2E) training. We explored the relationship between endoscopic prediction and histology through pathologist collaboration, where we found that the high attention regions identified by the models were confirmed, qualitatively, to contain epithelial and stromal morphological/structural features consistent with inflammation. We further validated these models by leveraging a model trained on the publicly available Colon Nuclei Identification and Counting (CoNIC) dataset \cite{graham2021conic}, which can segment and classify 6 types of cells. These predictions were compared with the attention maps produced by the weakly-supervised models. 

%\footnote{https://www.crohnscolitisfoundation.org/research/current-research-initiatives/sparc-ibd}

These models have applications in clinical trials since they can speed up the workflow of pathologists by ranking WSIs by disease severity so that pathologists can prioritise the most severe tissues first as well as drawing their attention to the most diseased regions in the WSI. To our knowledge, this is the first work on exploring and validating weakly-supervised methods to associate endoscopic appearance with H\&E morphology for large-scale IBD biopsies. Our code is available online at \href{https://github.com/AstraZeneca/ibd-interpret}{https://github.com/AstraZeneca/ibd-interpret}.

\section{Related work}

%WSI classification using only slide-level labels is commonly framed as a multiple instance learning (MIL) problem~\cite{augustine2022weakly}. MIL algorithms can be \textit{instance-level}~\cite{ilse2018attention} where a convolutional neural network (CNN) is trained by assigning each instance a pseudo-label followed by aggregating top-k instances, and \textit{embedding-level}~\cite{chikontwe2020multiple}, where each patch in the slide is mapped to a fixed-length embedding followed by aggregation of all embeddings by an operator, for example by max-pooling.

WSI classification using only slide-level labels is commonly framed as a multiple instance learning (MIL) problem~\cite{augustine2022weakly} in which image patches are mapped to fixed-length embeddings followed by aggregation by an operator, for example max-pooling. However, these MIL methods suffer from several limitations that have been recently addressed by the research community. For example, MIL methods are prone to misclassifications in the case of an unbalanced number of positive instances when using a simple aggregation operation such as max-pooling \cite{li2021dual}. This can be addressed by utilising attention-based aggregation where each instance is given a specific attention weight during training \cite{tomita2019attention}. Additionally, MIL methods can ignore the correlation among different instances across the WSI, which can be mitigated by using transformers to consider morphological and spatial information \cite{shao2021transmil} as well as generating attention maps for improved interpretability. Attention map interpretability was further improved by incorporating non-local attention into a dual-stream MIL (DSMIL) architecture to calculate an attention weight for each patch \cite{li2021dual}. MIL models often use fixed patch-based features extracted by a CNN or only features extracted by a fine-tuned model since end-to-end training is expensive and time-demanding for large slides. These sub-optimal extracted features can be improved by incorporating a multi-resolution feature fusion mechanism to leverage varied-size tissue features such as glands vs cells \cite{li2021multi}. Recently, HIPT \cite{chen2022scaling} extended multi-resolution feature fusion by introducing hierarchical pre-training, enabling a bottom-up aggregation of tissue features from cells to tissue morphology.

% Another common drawback of MIL models is over-fitting and difficulty in extracting salient feature representations caused by the weak supervisory signal, which was addressed by~\citet{ciga2022self} and \citet{fashi2022self} by using self-supervised contrastive learning for extracting efficient representation of WSIs in a latent space.

Following these advancements, we leverage DSMIL \cite{li2021dual} and HIPT \cite{chen2022scaling} due to their superior performance over the aforementioned methods on large public H\&E classification datasets such as The Cancer Genome Atlas (TCGA). DSMIL achieves strong performance by combining self-supervised pre-training using SimCLR \cite{chen2020simple} with a dual-stream attention-based MIL aggregator. Since both local and global contexts are important for WSI classification, DSMIL takes patches extracted at multiple magnifications with the same resolution as input. This is disadvantageous since fine details are lost at low magnification. By contrast, HIPT extracts patches at a fixed high magnification but with a relatively large resolution, such that fine and coarse-grained details are captured at the same resolution.

In this paper, we predict clinically relevant IBD endoscopic categories including disease types, macroscopic appearances, and endoscopic scores from H\&E biopsies which, to our knowledge, has not been addressed previously. Prior work mostly focused on electronic health records \cite{reddy2019predicting}, genomics, metagenomics \cite{abbas2019biomarker}, biological and clinical parameters for predicting endoscopic scores in UC patients \cite{popa2020machine}. Recently a fully supervised approach using H\&E images to predict remission and the Nancy Histological Index scores for UC was investigated by~\citet{najdawi2022artificial}. In contrast, we consider both CD and UC and use weakly supervised methods with macroscopic patient level labels, without any detailed pathologist annotations at the microscopic level, which are inexpensive relative to the supervised method. %Finally, we are the first, to our knowledge, to apply the state-of-the-art HIPT approach and compare it to DSMIL on a large non-cancer biopsy dataset. 

\section{Methodology}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{images/pipeline_v2.pdf}
    \caption{Overview of the implemented pipeline.}
    \label{fig:pipeline}
\end{figure}

The proposed methodology is summarised in Figure \ref{fig:pipeline}. First, we used an image quality control (QC) algorithm and extracted patches for training DSMIL and HIPT to predict 3 clinically relevant endoscopic categories and generate visual attention maps. A cell classification model was also applied to all slides and the individual cell predictions were aggregated into heatmaps for comparison with the weakly-supervised attention maps. Finally, attention maps and cell heatmaps were visualised in HALO Link for discussion with the pathologist. More details on these steps are in the subsections below.

% \footnote{https://indicalab.com/halolink/}

\subsection{Patch Extraction and Quality Control (QC)}

To process gigapixel WSIs using deep learning models, we first split each WSI into many small, non-overlapping image patches using the Histolab \cite{histolab} and CLAM \cite{lu2021data} Python packages.
We trained a QC model based on DenseNet~\cite{huang2017densely} to automatically identify and remove regions from the WSIs with imaging and/or tissue artefacts such as overstaining, tissue folds, debris, out-of-focus areas and variations in contrast and hue markings. The QC model provided readouts at the slide-level, identifying how much of the slide was rejected as a proportion of the tissue. These readouts were used to exclude slides containing large areas of rejected tissue (e.g. $>$50\%). The QC model was also integrated into the patch extraction pipeline  to save individual patches containing $>$50\% accepted tissue (see Appendix \ref{experimental design and intermediate results}).

\subsection{Self-Supervised Pre-training and Weakly-Supervised Classification}

In the following sections, we briefly outline how we distinguish self-supervised pre-training and weakly-supervised classification in DSMIL and HIPT - further details are provided in Section \ref{experimental_setup} and Appendix \ref{experimental design and intermediate results}.

\textbf{Self-supervised Pre-training.} We only consider the self-supervised representation learning components of DSMIL and HIPT. For DSMIL, this involves the SimCLR component, while for HIPT, this involves the ViT$_{16}-256$ and ViT$_{256}-4096$ components, which learn to output embeddings at the patch level. These self-supervised components, once trained, are used to generate patch embeddings for all WSIs, which are subsequently used for training the weakly-supervised classification components.

\textbf{Weakly-supervised classification.} We only consider the weakly-supervised components of DSMIL and HIPT for predicting 3 endoscopic categories. For DSMIL the attention-based MIL aggregator, and for HIPT the ViT$_{4096}-\text{WSI}$ component were considered.



\subsection{Interpretation of Model Predictions}

Following weakly-supervised training, we generated visual attention maps, which facilitated optimal collaboration with the pathologist to interrogate the models' predictions.

\textbf{DSMIL attention maps} are visualised using the per-patch attention weights of MIL aggregator as a heatmap overlay on the WSI \cite{li2021dual}. A weight value close to 1.0 indicates that the patch contributes heavily to the final prediction compared with a patch that has a score close to 0.0. We generated these attention maps for all WSIs in our dataset.

%During MIL aggregation, an embedding for each WSI is computed, which is a weighted sum over all patch embeddings produced by SimCLR. The weights are computed based on the similarity between the embedding of the critical patch and all other embeddings - the higher the similarity, the higher the weight. These weights were scaled to be in the range [0.0, 1.0] and visualised as a heatmap overlay on the WSI. A weight value for patch close to 1.0 indicates that the patch contributes heavily to the WSI embedding and has a larger effect on the final prediction compared with a patch that has a score close to 0.0. We generate these attention maps for all WSIs in our datasets.


\textbf{HIPT attention maps} are a natural part of HIPT due to its transformer backbone \cite{chen2022scaling}. The attention maps in the original paper demonstrated that they can highlight unique cancer-relevant tissue morphologies. Therefore, we also sought to understand what IBD-relevant tissue morphologies HIPT could learn.

\textbf{HALO Link Integration} was used to make the attention map review process interactive and straightforward for the pathologist. HALO is an image analysis platform for quantitative tissue analysis in digital pathology. We used HALO Link for sharing the WSIs and our predictions with the pathologists. The pathologist was not aware of any slide level endoscopic labels prior to assessment. For each slide, we asked the pathologist to describe the critical histopathological features for each slide including identification of inflammatory regions cellular composition, and morphological/structural features of the epithelium and stroma.  We used HALO Link\footnote{https://indicalab.com/halolink/} to compare the attention maps and the pathologist comments side by side to interpret features learnt by the models. 

% For this task, inter-observer reliability is excellent between pathologists \cite{allende2014inter}, hence only one pathologist assessor in this study is sufficient.

A \textbf{cell prediction model} for detection and classification of six cell types trained on the publicly available annotated CoNIC H\&E dataset \cite{graham2021conic} was used for understanding 6 cell populations. The CoNIC dataset was part of a grand medical challenge with the aim of predicting six types of cells on H\&E slides, including epithelial cells, neutrophils, lymphocytes, plasma cells, connective cells, and eosinophils. We aggregated the cell predictions into statistics per patch and then visualised these as the heatmaps (Appendix \ref{cell model appendix}). The heatmaps were compared with the attention maps produced by DSMIL and HIPT and several representative examples were reviewed by the pathologist. Finally, several human interpretable features (HIFs) were calculated from the readouts and correlated with the endoscopic scores for both CD and UC. 

% uncomment if we can use brazi
%\textbf{External dataset validation.} In order to assess the generalisability of our models, we applied our trained models, both weakly supervised and supervised cell level models, to another H\&E biopsies dataset from Brazikumab clinical trial [ref]. Then we calculated the performance of the models using AUCs, generated attention maps and cellular level heatmaps, as well as involved the pathologist and asked for their feedback on the composition of the tissue morphology.

\section{Experimental Setup}
\label{experimental_setup}

We included 1394 H\&E-stained biopsies from 418 CD and 218 UC patients enrolled in a multi-centred longitudinal Study of a Prospective Adult Research Cohort with IBD (SPARC IBD). The samples reside in the IBD Plexus database, provided with informed consent by the Crohn's and Colitis Foundation \cite{raffals2022development}. The total tissue area in 1394 biopsies is $\approx$7500µm$^2$ whereas the TCGA-lung resection dataset used to train DSMIL in the original work \cite{li2021dual} has a total area of $\approx$65000µm$^2$ across 1054 slides, making SPARC IBD a relatively challenging dataset for classification.

We used 3 clinically-relevant labels from the SPARC IBD dataset that were acquired from endoscopy to define weakly-supervised classification tasks. These included: i) disease diagnosis (num. WSIs: CD=903 vs UC=491), ii) macroscopic tissue appearance (num. WSIs: normal=922 vs lesional=472), and iii) CD and UC-specific endoscopic severity scores (num. WSIs: low (CD=714, UC=134) vs high (CD=281, UC=131) score) - see Appendix \ref{experimental design and intermediate results} for more details on the exact splits. We used 4 NVIDIA A100 GPUs for training.

The QC model was trained on representative subset of 19 WSIs. We reserved a set of 10 WSIs for testing on which the Dice score of the QC model in segmenting background, good tissue and artefacts was 0.730. The QC model was then applied to all SPARC IBD WSIs. We excluded 11 slides with $>$50\% rejected tissue and then DSMIL and HIPT were trained on patches extracted at 40x (Appendix \ref{experimental design and intermediate results}). 

In training, we initially used DSMIL and HIPT models, which were pre-trained on the TCGA dataset and fine-tuned on our dataset, in order to assess the transferability of knowledge from TCGA cancer resections to IBD biopsies. In fine-tuning, the weights of the self-supervised components of both models (SimCLR in DSMIL and ViT$_{16}-256$ \& ViT$_{256}-4096$ in HIPT) were frozen and only the weakly-supervised classification components (MIL aggregator in DSMIL and ViT$_{4096}-\text{WSI}$ in HIPT) were trained to predict the weakly-supervised classification tasks in SPARC IBD. We labelled the models that were fine-tuned on SPARC IBD as DSMIL-F and HIPT-F.

We also explored training DSMIL and HIPT end-to-end (E2E) on SPARC IBD. The self-supervised and weakly-supervised components of both models were trained on SPARC IBD from scratch to compare with the performance of fine-tuned models mentioned previously. We labeled the models that were trained end-to-end on SPARC IBD as DSMIL-E2E and HIPT-E2E (see Appendix \ref{experimental design and intermediate results}). In self-supervised and weakly-supervised training, we closely followed the training settings in the original papers~\cite{li2021dual, chen2022scaling}. 


In weakly-supervised training, we performed 5-fold cross validation, with an 80:20 split in all three prediction categories stratified on patients and ensuring that distributions of disease diagnosis, macroscopic appearance, biopsy location and the target label were consistent across all training and testing splits (more details in Appendix \ref{experimental design and intermediate results}). The same cross-validation splits were used for both DSMIL and HIPT models in all experiments. We used area under the receiver-operator characteristic curve (AUROC) to measure predictive performance.
For further evaluation, the visual attention maps for all slides were generated and compared with the cell prediction heatmaps from the CoNIC model. To obtain a quantitative evaluation within reasonable pathologist effort, we sorted the WSIs by tissue size and selected 10 WSIs from CD and UC patients, each containing 5 normal and 5 lesional.

\section{Results and Discussion}
\label{results-discussion}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{images/10627861HE1_maps.pdf}
    \caption{H\&E image, Attention maps, cell level predictions and pathologist comments for UC patient with lesional macroscopic appearance and high endoscopic score.}
    \label{fig:10627861HE1_maps}
\end{figure}


\begin{table}[h!]
\floatconts
    {tab:auc_performance}
    {\caption{Mean AUROC ± standard error (5-fold cross validation) of trained models across different prediction tasks.}}
    {\begin{tabular}{p{0.15\linewidth}|p{0.16\linewidth}|p{0.16\linewidth}|p{0.16\linewidth}|p{0.16\linewidth}}
    \toprule
    \bfseries Model       & \bfseries Disease \newline Diagnosis & \bfseries Macroscopic \newline Appearance & \bfseries Endoscopic Score (CD) & \bfseries Endoscopic Score (UC) \\
    \midrule
        DSMIL-F     & 0.656±0.007  & 0.522±0.008 & 0.528±0.016 & 0.592±0.007         \\
        DSMIL-E2E   & 0.692±0.010   & 0.750±0.006 & 0.740±0.009 & 0.634±0.017     \\
        HIPT-F      & 0.825±0.017   & 0.780±0.012 & 0.766±0.026 & 0.788±0.034     \\
        \bfseries HIPT-E2E    & \bfseries 0.865±0.019   & \bfseries 0.814±0.008 & \bfseries 0.786±0.017 & \bfseries 0.802±0.014 \\
    \bottomrule
    \end{tabular}}
\end{table}

\begin{table}[h!]
    \floatconts
    {tab:extra_experiments}
    {\caption{Performance of DSMIL-E2E and HIPT-E2E trained on clinically-relevant subsets of SPARC IBD for the task of predicting macroscopic appearance.}}
    {\begin{tabular}{p{0.137\linewidth}|p{0.135\linewidth}|p{0.135\linewidth}|p{0.135\linewidth}|p{0.135\linewidth}|p{0.135\linewidth}}
    \toprule
    \bfseries Model       & \bfseries All data & \bfseries Just CD & \bfseries Just UC & \bfseries Just Ileum & \bfseries Just Colon \\
    \midrule
        DSMIL-E2E     & 0.750±0.006  & 0.689±0.010 & 0.808±0.013 & 0.586±0.010 & 0.775±0.019         \\
        HIPT-E2E & 
        0.814±0.008 & 0.804±0.010 & 0.837±0.015 & 0.739±0.032 &  0.823±0.036    \\
    \bottomrule
    \end{tabular}}
\end{table}

\textbf{Model Performance.} In Table \ref{tab:auc_performance} we compare the performance of end-to-end and fine-tuned DSMIL and HIPT models for predicting 3 weakly-supervised tasks in SPARC IBD.  HIPT-E2E significantly outperforms DSMIL-E2E across all tasks (two-tailed t-test: diagnosis - p$<$0.0001, macroscopic appearance - p$<$0.0005, endoscopic scores (CD) - p$<$0.05 and (UC) - p$<$0.0001). It is likely that both the spatial patterns among cells and the context of the tissue microenvironment are well captured by HIPT's transformer backbone, leading to improved performance. In addition, we found that E2E training on SPARC IBD was the optimal strategy for both DSMIL and HIPT training across all tasks. We suggest that the embeddings learned by E2E models through self-supervised pre-training on SPARC IBD were more useful for downstream prediction tasks than pre-trained embeddings from TCGA. This difference can be attributed to the differences between IBD and cancer morphologies as well as the difference between TCGA resections vs IBD biopsies.

% Furthermore, vision transformers have been shown to outperform CNNs as dataset size scales \cite{dosovitskiy2020image}.

\textbf{Pathologist Evaluation.} Through the pathologist evaluation of 20 WSIs, there were 8 TP, 7 TN, 4 FP and 1 FN when using the endoscopic labels whereas there were 9 TP, 7 TN, 3 FP and 1 FN when using the pathologist's evaluation as ground truth. Therefore, while not perfectly related, endoscopic and histological labels are strongly correlated, and the model was able to learn histologically relevant features via supervised training on endoscopic labels. Additionally, we obtained pathologist annotations of inflammatory regions for 1 WSI (Figure \ref{fig:10627861HE1_maps}) and computed the Dice coefficient between the annotation and the thresholded attention map, obtaining 0.625, suggesting that inflammatory infiltrate was well localised in this WSI.

%Then we selected an additional 10 WSIs that were FP predictions from DSMIL-E2E. For all 10 slides the pathologist confirmed that the tissue was lesional (contrary to endoscopic label of normal) indicating that the model's FPs were correct from the point of view of histopathology. Finally, the pathologist confirmed that the attention maps could reveal disease relevant features in IBD such as inflammation. For instance, there were X out of 20 WSIs where the pathologist's description of inflammatory regions in the WSI were consistent, qualitatively, with the high attention regions of DSMIL and HIPT - 2 visual examples are shown in (Figure~\ref{fig:10537857_maps} and Appendix~\ref{additionl attention maps}). However, further quantitative assessment of this relationship is required and will be addressed in follow up works. 


%We demonstrated that endoscopic labels can allow H\&E models to learn disease features at the microscopic level (Table \ref{tab:auc_performance}). Then we explored both false positive and false negative WSIs from DSMIL-E2E in predicting macroscopic appearance. The WSIs were evaluated by the pathologist blinded to the macroscopic classifications who identified several cases where slides classified as ``normal'' in endoscopy labels had extensive inflammation at the microscopic H\&E level (Figure \ref{fig:misclassified}). This ``misclassificaiton'' corresponds to a previously observed tendency of histological presentation in UC to be more severe than endoscopic presentation~\cite{endohisto2019}. DSMIL-E2E was still able to localise areas of inflammation in these slides where endoscopic and histopathology finding determined by the pathologist differed.

\textbf{Cell Prediction Model.} From the cell model's predictions, we found that the most indicative HIF in UC was the ratio of neutrophils to all cells in the tissue (p=0.0007), while in CD it was the ratio of eosinophils to all cells in the tissue (p=0.0002). The additional HIFs are listed in Appendix \ref{cell model appendix}. These findings are reflected in \citet{alhmoud2020cells}. 
Qualitatively, there are similarities between the cell prediction maps and the pathologist's description of inflammation (for example, Figure \ref{fig:10537857_maps}). However, the quantitative performance at the cell level must be explored further. As this is a labor-intensive and time-consuming task for pathologists, we suggest combining weakly-supervised learning with supervised models is an alternative, more efficient, approach.


\textbf{Applications.} The trained models can be used to automatically rank biopsies by disease severity allowing pathologists to save time by prioritising more severe biopsies. This is important since the majority of biopsies received by pathologists are within normal limits. For biopsies outside of normal limits, the attention maps can be used for guiding the pathologist during microscopic evaluation of potentially malignant areas. We intend to quantitatively assess the speed up of pathologist workflow in future works. For clinical applications, we explored training DSMIL and HIPT using only CD or only UC biopsies as well as exclusively ileum or colon biopsies for predicting macroscopic appearance since disease features can present differently within these subsets (Table \ref{tab:extra_experiments}). We found that model performance can be improved by training on just UC and just colon subsets, while performance decreases when training on just ileum, suggesting that this is a more difficult task due to fewer ileum biopsies. We consider these types of modifications critical in applying these models to clinical trials and will be further explored in future works.

\vspace{-0.2cm}
\section{Conclusion and Future Work}

We demonstrated that weakly supervised learning can produce accurate models trained on H\&E-stained biopsies with endoscopic labels only.  We observed potential in the publicly available CoNIC model and the attention maps. However, further quantitative and qualitative assessment of their generalisability is needed. Through reviewing the attention maps with pathologists, we can potentially better understand the relationship between histological and endoscopic labels. We plan to validate the trained SPARC IBD models with the corresponding attention maps on external IBD datasets from clincal trials.


%Acknowledgments---Will not appear in anonymized version
\midlacknowledgments{We would like to thank AstraZeneca for sponsoring and supporting this research and Crohn's \& Colitis Foundation for providing the SPARC IBD dataset.}

\bibliography{references}

\newpage

\appendix

%\section{SPARC IBD Dataset}
%\label{SPARC IBD Dataset}

% additional information about ibd plexus dataset can go here - patient populations, demographics etc. Also cross validation specifics can go here - number of patients, slides, distributions across train and test sets, datasets for DSMIL and HIPT

% additional information about brazi dataset can go here - patients, demographics, ethics etc

\section{Supplementary Methods}
\label{experimental design and intermediate results}

\subsection{QC and Patch Extraction}

From applying our QC model to all 1394 WSIs, we found that 6, 11, and 40 slides had, respectively,  $>$75, $>$50, and  $>$25\% rejected  areas  (Figure \ref{fig:qc_results}). Following QC, patches were extracted at 40x for training DSMIL-E2E (224 by 244 resolution) and HIPT-E2E (4096 by 4096 resolution), following the methods of \cite{li2021dual} and \cite{chen2022scaling}. 2,054,901 patches were extracted for DSMIL and 13,952 patches were extracted for HIPT.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{images/QC.pdf}
    \caption{QC summary statistics on SPARC IBD and QC result on an additional slide}
    \label{fig:qc_results}
\end{figure}

\subsection{Cross-Validation}

5-fold cross validation is performed on in all weakly-supervised classification tasks in SPARC IBD. Splits are performed at the patient level, maintaining the distributions of biopsy location, disease diagnosis and the target label - see Figure \ref{fig:cross_validation} for the exact splits for all tasks. This was done to ensure that models are tested on a representative distribution of biopsies. The same cross validation splits are used for both DSMIL and HIPT experiments to allow them to be compared. For predicting macroscopic appearance, the ``erosions/ulcers'' and ``inflammation'' labels were combined into a ``lesional'' class. For endoscopic score, the median of SES score for CD and modified Mayo endoscopic score for UC were 0, so we treated the negative class as a score of 0 and positive class as score $>$0.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{images/CV_splits.pdf}
    \caption{Proportion of patients (n=638) in original, train and test sets across 5 cross validation folds and across biopsy location, disease diagnosis and macroscopic appearance for all tasks. Proportions of patients in each category are kept consistent across all train and test splits.}
    \label{fig:cross_validation}
\end{figure}

\subsection{Model Training}

%DSMIL is a two stage model where the first stage utilises the SimCLR framework for self-supervised representation learning of extracted patches, in which a ResNet CNN is trained to output embeddings for each patch. The embeddings are then passed to an attention-based MIL aggregator, which is trained to predict downstream weakly-supervised classification tasks.

The hyperparameters used in self-supervised pretraining and weakly-supervised training for all DSMIL and HIPT models are shown in Table \ref{tab:dsmil_hipt_parameters}. To follow closely the methods of \cite{li2021dual} and \cite{chen2022scaling}, we use the default parameters for both models across the board, but for HIPT we found that self-supervised pretraining converged after 30 epochs and in weakly-supervised learning we use only 1 transformer encoder layer. The same cross validation splits are used for both DSMIL and HIPT in all experiments.


\begin{table}[h!]
    \floatconts
    {tab:dsmil_hipt_parameters}
    {\caption{Hyperparameters used to train DSMIL and HIPT models.}}
    {\begin{tabular}{l|p{0.38\linewidth}|p{0.38\linewidth}}
    \toprule
    \bfseries Model       & \bfseries Self-supervised pretraining & \bfseries Weakly-supervised training \\
    \midrule
        DSMIL-F & Frozen from TCGA &  epochs: 200; embedding size: 512; learning rate: 0.0002; weight decay: 0.005 \\ \midrule
        DSMIL-E2E & epochs: 100; learning rate: 0.001; weight decay: 0.000001; batch size: 1024; arch: ResNet18 & epochs: 200; embedding size: 512; learning rate: 0.0002; weight decay: 0.005 \\ \toprule \toprule
        HIPT-F & Frozen from TCGA & epochs: 20; layers: 1; heads: 3; dropout: 0.25, learning rate: 0.0003 \\ \midrule
        HIPT-E2E & epochs: 30; weight decay: 0.04; learning rate: 0.0005, warmup epochs: 10 & epochs: 20; layers: 1; heads: 3; dropout: 0.25, learning rate: 0.0003\\
    \bottomrule
    \end{tabular}}
\end{table}


%HIPT takes a hierarchical approach, in which a pipeline of 3 vision transformers (ViTs) are trained on patches at different sizes. HIPT receives as input large patches that are recursively unrolled first into smaller patches what are unrolled into even smaller ones (add the reference to the paper). HIPT performs a bottom-up aggregation of these patches during training, using a different transformer at each patch resolution - see Appendix X.

%HIPT performs a bottom-up aggregation of these patches during training, using a different transformer at each patch resolution. Specifically, HIPT defines a ViT$_{l}-L$ as working on an image of size $L$ with $l \times l$ tokens. Therefore, in HIPT, ViT$_{16}-256$ works on the 256x256 patches with 16x16 tokens, ViT$_{256}-4096$ works on the 4096x4096 patches with 256x256 tokens and ViT$_{4096}-\text{WSI}$ works on the WSI with 4096x4096 tokens. Critically, the [CLS] tokens outputted by ViT$_{16}-256$ are used as input to ViT$_{256}-4096$, whose [CLS] token outputs are finally passed as input to ViT$_{4096}-\text{WSI}$. Therefore, the full HIPT model is expressed as:

%\begin{equation}
%\label{eq:HIPT_model}
%\begin{aligned}
%    \text{HIPT}(\textbf{x}_{\text{WSI}}) = ViT_{4096}-\text{WSI}(\{ \text{CLS}_{4096}^{(k)} \}^{M}_{k=1}) \\
%    \rightarrow \text{CLS}_{4096}^{(k)} = ViT_{256}-4096(\{ \text{CLS}_{256}^{(j)} \}^{256}_{j=1}) \\
%    \rightarrow \text{CLS}_{256}^{(j)} = ViT_{16}-256(\{ \textbf{x}_{16}^{(i)} \}^{256}_{i=1}) \\
%\end{aligned}
%\end{equation}

%To learn meaningful representations and each resolution, HIPT employs the DINO framework \cite{caron2021emerging} for hierarchical pretraining of ViT$_{16}-256$ and ViT$_{256}-4096$. In hierarchical pretraining DINO is first used to pretrain ViT$_{16}-256$ with the 256x256 patches as input. Once this is complete, the weights of ViT$_{16}-256$ are frozen and the [CLS] tokens for each 256x256 patch are extracted. The [CLS] tokens are then reshaped into a feature grid that is used to in a second round of DINO pretraining for ViT$_{256}-4096$. After hierarchical pretraining is complete, a lightweight ViT$_{4096}-\text{WSI}$ is finetuned to predict downstream weakly-supervised tasks.

\newpage

\section{Additional Experiments}
\label{add experiments appendix}
% we can put stuff like just colon, just liuem, just UC/CD stuff here, different hyperparameters, different magnifications etc

% any additional hipt experiments, different architectures, hyperparameters

Since DSMIL can take as input patches extracted at different magnifications, we assessed the performance of DSMIL in predicting disease diagnosis with different magnification datasets. These results are summarised in Table \ref{tab:dsmil_mag_experiments}. In order to be consistent with HIPT we used 40x patches to train DSMIL-E2E for all main experiments (Table \ref{tab:auc_performance}). However, we find that for predicting macroscopic appearance, slightly improved performance can be achieved with lower magnifications, although there is no statistically significant difference between these models trained at different magnifications and HIPT-E2E still significantly outperforms DSMIL-E2E at all magnifications.

\begin{table}[h!]
    \floatconts
    {tab:dsmil_mag_experiments}
    {\caption{Comparison of DSMIL-E2E trained on different magnifications in predicting macroscopic appearance.}}
    {\begin{tabular}{l|c}
    \toprule
    \bfseries Dataset       & \bfseries AUROC ± 1 SE \\
    \midrule
        5x & 0.645±0.008 \\
        10x & 0.752±0.006 \\
        20x &  0.758±0.006  \\
        40x & 0.750±0.006 \\
    \bottomrule
    \end{tabular}}
\end{table}




\newpage

\section{Additional Attention Maps and Pathologist Feedback}
\label{additionl attention maps}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{images/10537857_maps.pdf}
    \caption{H\&E image, lymphocytes density by the cell level model, attention maps from two models, at WSI level and cell level resolutions, and pathologist comments.}
    \label{fig:10537857_maps}
\end{figure}

% more HIPT heatmap examples can go here, explanations for the different attention heads

\newpage

\section{Misclassified Cases}
\label{misclassified appendix}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{images/misclassified.png}
    \caption{Two slides classified as ``normal'' from macroscopic appearance but predicted as ``lesional'' by DSMIl-E2E. Both slides were confirmed by the pathologist to contain inflammation and hence should  be considered  ``lesional''.}
    \label{fig:misclassified}
\end{figure}


\newpage

\section{Supervised Cell Model}
\label{cell model appendix}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.75\linewidth]{images/conic_predictions.png}
    \caption{Six cell types predictions overlaid over two CoNIC patches.. CoNIC examples have ground truth, annotations by pathologists available in the dataset.}
    \label{fig:conic_cells_example}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{images/conic/10537857HE101.png}
    \caption{Four immune cell density heatmaps overlaid over an IBDplexus WSI.}
    \label{fig:conic_heatmaps_example}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{images/cell_example.pdf}
    \caption{An example how human interpretable features (HIFs) are calculated from six class cells predictions.}
    \label{fig:cells_counts}
\end{figure}

\iffalse
\begin{table}[htbp] 
\centering
\begin{subtable}{\linewidth}
\subcaption{Statistically significant HIFs for IBD Plexus UC patients.}
%\vspace*{-20px}
 % The first argument is the label.
 % The caption goes in the second argument, and the table contents
 % go in the third argument.
\floatconts
  {tab:ibdplexus_uc_conic}%

  {\begin{tabular}{|p{12cm}|p{1.5cm}|}
  \bfseries Feature & \bfseries p value\\

                                                          ratio of neutrophils to all cells in all area &   0.0007 \\
                                                              density of neutrophils in all tissue area &   0.0022 \\

                                                              density of eosinophils in all tissue area &   0.0111 \\

                                                          ratio of lymphocytes to all cells in all area &   0.0125 \\
                                                              density of lymphocytes in all tissue area &   0.0150 \\
                                                          ratio of eosinophils to all cells in all area &   0.0187 \\

                                                           ratio of epithelial cells to all cells in all area &   0.0234 \\
            
                                                               density of connective cells in all tissue area &   0.0416 \\ 
  \end{tabular}\end{subtable}{\textwidth}

\begin{subtable}{\textwidth}
\subcaption{Statistically significant HIFs for IBD Plexus CD patients.}
\vspace*{-20px}
 % The first argument is the label.
 % The caption goes in the second argument, and the table contents
 % go in the third argument.
\floatconts
  {tab:ibdplexus_cd_conic}%
  
  {\begin{tabular}{|p{12cm}|p{1.5cm}|}
  \bfseries Feature & \bfseries p value\\

                                                          ratio of eosinophils to all cells in all area &   0.00002 \\

                                                              density of eosinophils in all tissue area &   0.0001 \\

                                                          ratio of neutrophils to all cells in all area &   0.0018 \\

                                                              density of neutrophils in all tissue area &   0.0057 \\

                                                                   density of plasma cells in all tissue area &   0.0170 \\

                                                          ratio of lymphocytes to all cells in all area &   0.0294 \\
                                                               ratio of plasma cells to all cells in all area &   0.0341 \\ %\hline

  \end{tabular}}
\end{subtable}{\textwidth}
{\caption{HIFs for IBDplexus UC (a) and CD (b). The patients are split into two groups by Mayo endoscopic subscore of zero (n93) and more than zero (n84) for UC and by SES CD endoscopic subscore of zero (n193) and more than zero (n150).}}%
\end{table}
\fi

\end{document}
