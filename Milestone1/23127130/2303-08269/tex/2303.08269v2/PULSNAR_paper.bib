@inproceedings{pulsnar_1,
  title={A modified logistic regression for positive and unlabeled learning},
  author={Jaskie, Kristen and Elkan, Charles and Spanias, Andreas},
  booktitle={2019 53rd Asilomar Conference on Signals, Systems, and Computers},
  pages={2007--2011},
  year={2019},
  organization={IEEE}
}

@inproceedings{pulsnar_2,
  title={Learning classifiers from only positive and unlabeled data},
  author={Elkan, Charles and Noto, Keith},
  booktitle={Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={213--220},
  year={2008}
}

@article{pulsnar_3,
  title={Learning from positive and unlabeled data: A survey},
  author={Bekker, Jessa and Davis, Jesse},
  journal={Machine Learning},
  volume={109},
  number={4},
  pages={719--760},
  year={2020},
  publisher={Springer}
}

@article{pulsnar_4,
  title={Building classifiers to predict the start of glucose-lowering pharmacotherapy using belgian health expenditure data},
  author={Claesen, Marc and De Smet, Frank and Gillard, Pieter and Mathieu, Chantal and De Moor, Bart},
  journal={arXiv preprint arXiv:1504.07389},
  year={2015}
}




@inproceedings{pulsnar_5,
  title     = "{XGBoost}: A Scalable Tree Boosting System",
  booktitle = "Proceedings of the 22nd {ACM} {SIGKDD} International Conference
               on Knowledge Discovery and Data Mining",
  author    = "Chen, Tianqi and Guestrin, Carlos",
  pages     = "785--794",
  year      =  2016
}


@article{pulsnar_6,
  title={Model selection and psychological theory: a discussion of the differences between the Akaike information criterion (AIC) and the Bayesian information criterion (BIC).},
  author={Vrieze, Scott I},
  journal={Psychological methods},
  volume={17},
  number={2},
  pages={228},
  year={2012},
  publisher={American Psychological Association}
}

@article{pulsnar_7,
  title={A data-driven approach to predict the success of bank telemarketing},
  author={Moro, S{\'e}rgio and Cortez, Paulo and Rita, Paulo},
  journal={Decision Support Systems},
  volume={62},
  pages={22--31},
  year={2014},
  publisher={Elsevier}
}



@article{pulsnar_8,
  title     = "{KDD-Cup} 2004: results and analysis",
  author    = "Caruana, Rich and Joachims, Thorsten and Backstrom, Lars",
  abstract  = "This paper summarizes and analyzes the results of the 2004
               KDD-Cup. The competition consisted of two tasks from the areas
               of particle physics and protein homology detection. It focused
               on the problem of optimizing supervised learning to different
               performance measures (accuracy, cross-entropy, ROC area, SLAC-Q,
               squared error, average precision, top 1, and rank of last). A
               total of 102 groups participated in the competition, 6 of which
               received awards or honorable mentions. Their approaches are
               described in other papers in this issue of SIGKDD Explorations.
               In this paper we do not analyze any particular approach, but
               give insight into the performance of the field of competitors as
               a whole. We study what fraction of the participants found good
               solutions, how well participants were able to optimize to
               different performance measures, how homogeneous their submitted
               predictions are, and if the best submissions represent the
               maximal performances that could reasonably be achieved. We are
               keeping the KDD-Cup 2004 WWW site open and have added an
               automatic scoring system for new submissions in order to
               encourage further research in this area.",
  journal   = "SIGKDD Explor. Newsl.",
  publisher = "Association for Computing Machinery",
  volume    =  6,
  number    =  2,
  pages     = "95--108",
  month     =  dec,
  year      =  2004,
  address   = "New York, NY, USA"
}


@misc{pulsnar_9,
  title        = "University of California Irvine (UCI) Machine Learning Repository: Statlog (Shuttle) Data Set",
  author       = "{UCI ML Repository}",
  howpublished = "\url{https://archive.ics.uci.edu/ml/datasets/Statlog+(Shuttle)}",
  year         = 2022,
  note         = "Accessed: 2022-06-30"
}

@misc{pulsnar_10,
  title        = "University of California Irvine (UCI) Machine Learning Repository: Internet Firewall Data Set",
  author       = "{UCI ML Repository}",
  howpublished = "\url{https://archive.ics.uci.edu/ml/datasets/Internet+Firewall+Data}",
  year         = 2022,
  note         = "Accessed: 2022-06-30"
}

@article{pulsnar_11,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@article{pulsnar_12,
  title={PEBL: Web page classification without negative examples},
  author={Yu, Hwanjo and Han, Jiawei and Chang, KC-C},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={16},
  number={1},
  pages={70--81},
  year={2004},
  publisher={IEEE}
}

@article{pulsnar_13,
  title={Single-class classification with mapping convergence},
  author={Yu, Hwanjo},
  journal={Machine Learning},
  volume={61},
  number={1},
  pages={49--69},
  year={2005},
  publisher={Springer}
}

@article{pulsnar_14,
  title={PSoL: a positive sample only learning algorithm for finding non-coding RNA genes},
  author={Wang, Chunlin and Ding, Chris and Meraz, Richard F and Holbrook, Stephen R},
  journal={Bioinformatics},
  volume={22},
  number={21},
  pages={2590--2596},
  year={2006},
  publisher={Oxford University Press}
}

@article{pulsnar_15,
  title={Text classification without negative examples revisit},
  author={Fung, Gabriel Pui Cheong and Yu, Jeffrey Xu and Lu, Hongjun and Yu, Philip S},
  journal={IEEE transactions on Knowledge and Data Engineering},
  volume={18},
  number={1},
  pages={6--20},
  year={2005},
  publisher={IEEE}
}

@inproceedings{pulsnar_16,
  title={Learning with positive and unlabeled examples using weighted logistic regression},
  author={Lee, Wee Sun and Liu, Bing},
  booktitle={ICML},
  volume={3},
  pages={448--455},
  year={2003}
}

@incollection{pulsnar_17,
  title={Partially supervised classification: based on weighted unlabeled samples support vector machine},
  author={Liu, Zhigang and Shi, Wenzhong and Li, Deren and Qin, Qianqing},
  booktitle={Data Warehousing and Mining: Concepts, Methodologies, Tools, and Applications},
  pages={1216--1230},
  year={2008},
  publisher={IGI Global}
}


@article{pulsnar_20,
  title={Class prior estimation from positive and unlabeled data},
  author={Du Plessis, Marthinus Christoffel and Sugiyama, Masashi},
  journal={IEICE TRANSACTIONS on Information and Systems},
  volume={97},
  number={5},
  pages={1358--1362},
  year={2014},
  publisher={The Institute of Electronics, Information and Communication Engineers}
}

@article{pulsnar_21,
  title={Nonparametric semi-supervised learning of class proportions},
  author={Jain, Shantanu and White, Martha and Trosset, Michael W and Radivojac, Predrag},
  journal={arXiv preprint arXiv:1601.01944},
  year={2016}
}

@inproceedings{pulsnar_22,
  title={Mixture proportion estimation via kernel embeddings of distributions},
  author={Ramaswamy, Harish and Scott, Clayton and Tewari, Ambuj},
  booktitle={International conference on machine learning},
  pages={2052--2060},
  year={2016},
  organization={PMLR}
}

@article{pulsnar_23,
  title={Estimating the class prior in positive and unlabeled data through decision tree induction},
  author={Bekker, Jessa and Davis, Jesse},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{pulsnar_24,
  title={Dedpul: Difference-of-estimated-densities-based positive-unlabeled learning},
  author={Ivanov, Dmitry},
  booktitle={2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA)},
  pages={782--790},
  year={2020},
  organization={IEEE}
}

@article{pulsnar_25,
  title={Confident learning: Estimating uncertainty in dataset labels},
  author={Northcutt, Curtis and Jiang, Lu and Chuang, Isaac},
  journal={Journal of Artificial Intelligence Research},
  volume={70},
  pages={1373--1411},
  year={2021}
}

@inproceedings{pulsnar_26,
  title={Multi-Positive and Unlabeled Learning.},
  author={Xu, Yixing and Xu, Chang and Xu, Chao and Tao, Dacheng},
  booktitle={IJCAI},
  pages={3182--3188},
  year={2017}
}

@article{pulsnar_27,
  title={SMOTE: synthetic minority over-sampling technique},
  author={Chawla, Nitesh V and Bowyer, Kevin W and Hall, Lawrence O and Kegelmeyer, W Philip},
  journal={Journal of artificial intelligence research},
  volume={16},
  pages={321--357},
  year={2002}
}


@article{pulsnar_28, title={Oversampling for Imbalanced Data via Optimal Transport}, volume={33}, url={https://ojs.aaai.org/index.php/AAAI/article/view/4503}, DOI={10.1609/aaai.v33i01.33015605}, abstractNote={&lt;p&gt;The issue of data imbalance occurs in many real-world applications especially in medical diagnosis, where normal cases are usually much more than the abnormal cases. To alleviate this issue, one of the most important approaches is the oversampling method, which seeks to synthesize minority class samples to balance the numbers of different classes. However, existing methods barely consider global geometric information involved in the distribution of minority class samples, and thus may incur distribution mismatching between real and synthetic samples. In this paper, relying on optimal transport (Villani 2008), we propose an oversampling method by exploiting global geometric information of data to make synthetic samples follow a similar distribution to that of minority class samples. Moreover, we introduce a novel regularization based on synthetic samples and shift the distribution of minority class samples according to loss information. Experiments on toy and real-world data sets demonstrate the efficacy of our proposed method in terms of multiple metrics.&lt;/p&gt;}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Yan, Yuguang and Tan, Mingkui and Xu, Yanwu and Cao, Jiezhang and Ng, Michael and Min, Huaqing and Wu, Qingyao}, year={2019}, month={Jul.}, pages={5605-5612} }

@inproceedings{pulsnar_29,
  title={Calibrating probability with undersampling for unbalanced classification},
  author={Dal Pozzolo, Andrea and Caelen, Olivier and Johnson, Reid A and Bontempi, Gianluca},
  booktitle={2015 IEEE symposium series on computational intelligence},
  pages={159--166},
  year={2015},
  organization={IEEE}
}

@article{pulsnar_30,
  title={Exploratory undersampling for class-imbalance learning},
  author={Liu, Xu-Ying and Wu, Jianxin and Zhou, Zhi-Hua},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  volume={39},
  number={2},
  pages={539--550},
  year={2008},
  publisher={IEEE}
}

@inproceedings{pulsnar_31,
  title={Positive-Unlabeled Learning from Imbalanced Data.},
  author={Su, Guangxin and Chen, Weitong and Xu, Miao},
  booktitle={IJCAI},
  pages={2995--3001},
  year={2021}
}

@article{pulsnar_33,
  title={A taxonomy of attacks and a survey of defence mechanisms for semantic social engineering attacks},
  author={Heartfield, Ryan and Loukas, George},
  journal={ACM Computing Surveys (CSUR)},
  volume={48},
  number={3},
  pages={1--39},
  year={2015},
  publisher={ACM New York, NY, USA}
}

@article{pulsnar_34,
  title={Common mental health disorders: identification and pathways to care},
  author={National Collaborating Centre for Mental Health (Great Britain) and National Institute for Health and Clinical Excellence (Great Britain) and British Psychological Society and Royal College of Psychiatrists},
  year={2011},
  publisher={RCPsych Publications}
}

@article{pulsnar_35,
  title={Particle size distributions from electron microscopy images: avoiding pitfalls},
  author={Alxneit, Ivo},
  journal={The Journal of Physical Chemistry A},
  volume={124},
  number={48},
  pages={10075--10081},
  year={2020},
  publisher={ACS Publications}
}

@inproceedings{pulsnar_36,
  title={Knee point detection in BIC for detecting the number of clusters},
  author={Zhao, Qinpei and Hautamaki, Ville and Fr{\"a}nti, Pasi},
  booktitle={International conference on advanced concepts for intelligent vision systems},
  pages={664--673},
  year={2008},
  organization={Springer}
}

@article{pulsnar_37,
  title={Electronic phenotyping with APHRODITE and the Observational Health Sciences and Informatics (OHDSI) data network},
  author={Banda, Juan M and Halpern, Yoni and Sontag, David and Shah, Nigam H},
  journal={AMIA Summits on Translational Science Proceedings},
  volume={2017},
  pages={48},
  year={2017},
  publisher={American Medical Informatics Association}
}

@article{pulsnar_38,
  title={Beta kernel estimators for density functions},
  author={Chen, Song Xi},
  journal={Computational Statistics \& Data Analysis},
  volume={31},
  number={2},
  pages={131--145},
  year={1999},
  publisher={Elsevier}
}

@incollection{pulsnar_39,
  title={Measures of geometrical complexity in classification problems},
  author={Ho, Tin Kam and Basu, Mitra and Law, Martin Hiu Chung},
  booktitle={Data complexity in pattern recognition},
  pages={1--23},
  year={2006},
  publisher={Springer}
}

@inproceedings{pulsnar_40,
  title={Irrelevant features, class separability, and complexity of classification problems},
  author={Skrypnyk, Iryna},
  booktitle={2011 IEEE 23rd International Conference on Tools with Artificial Intelligence},
  pages={998--1003},
  year={2011},
  organization={IEEE}
}

@ARTICLE{pulsnar_41,
  author  = {Virtanen, Pauli and others},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@inproceedings{pulsnar_42,
  title={Beyond the selected completely at random assumption for learning from positive and unlabeled data},
  author={Bekker, Jessa and Robberechts, Pieter and Davis, Jesse},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={71--85},
  year={2019},
  organization={Springer}
}

@article{pulsnar_43, title={Recovering the Propensity Score from Biased Positive Unlabeled Data}, volume={36}, url={https://ojs.aaai.org/index.php/AAAI/article/view/20624}, DOI={10.1609/aaai.v36i6.20624},
abstractNote={Positive-Unlabeled (PU) learning methods train a classifier to distinguish between the positive and negative classes given only positive and unlabeled data. While traditional PU methods require the labeled positive samples to be an unbiased sample of the positive distribution, in practice the labeled sample is often a biased draw from the true distribution. Prior work shows that if we know the likelihood that each positive instance will be selected for labeling, referred to as the propensity score, then the biased sample can be used for PU learning. Unfortunately, no prior work has been proposed an inference strategy for which the propensity score is identifiable. In this work, we propose two sets of assumptions under which the propensity score can be uniquely determined: one in which no assumption is made on the functional form of the propensity score (requiring assumptions on the data distribution), and the second which loosens the data assumptions while assuming a functional form for the propensity score. We then propose inference strategies for each case. Our empirical study shows that our approach significantly outperforms the state-of-the-art propensity estimation methods on a rich variety of benchmark datasets.},
number={6},
journal={Proceedings of the AAAI Conference on Artificial Intelligence},
author={Gerych, Walter and Hartvigsen, Thomas and Buquicchio, Luke and Agu, Emmanuel and Rundensteiner, Elke}, year={2022},
month={Jun.},
pages={6694-6702} }


@article{pulsnar_44,
  title={Learning from positive and unlabeled data with arbitrary positive shift},
  author={Hammoudeh, Zayd and Lowd, Daniel},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13088--13099},
  year={2020}
}

@inproceedings{pulsnar_45,
  title={BurstPU: Classification of Weakly Labeled Datasets with Sequential Bias},
  author={Gerych, Walter and Buquicchio, Luke and Chandrasekaran, Kavin and Alajaji, Abdulaziz and Mansoor, Hamid and Murphy, Aidan and Rundensteiner, Elke and Agu, Emmanuel},
  booktitle={2020 IEEE International Conference on Big Data (Big Data)},
  pages={147--154},
  year={2020},
  organization={IEEE}
}

@inproceedings{pulsnar_46,
  title={Deep generative positive-unlabeled learning under selection bias},
  author={Na, Byeonghu and Kim, Hyemi and Song, Kyungwoo and Joo, Weonyoung and Kim, Yoon-Yeong and Moon, Il-Chul},
  booktitle={Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
  pages={1155--1164},
  year={2020}
}


@article{pulsnar_47, title={PULNS: Positive-Unlabeled Learning with Effective Negative Sample Selector}, volume={35}, url={https://ojs.aaai.org/index.php/AAAI/article/view/17064}, abstractNote={Positive-unlabeled learning (PU learning) is an important case of binary classification where the training data only contains positive and unlabeled samples. The current state-of-the-art approach for PU learning is the cost-sensitive approach, which casts PU learning as a cost-sensitive classification problem and relies on unbiased risk estimator for correcting the bias introduced by the unlabeled samples. However, this approach requires the knowledge of class prior and is subject to the potential label noise. In this paper, we propose a novel PU learning approach dubbed PULNS, equipped with an effective negative sample selector, which is optimized by reinforcement learning. Our PULNS approach employs an effective negative sample selector as the agent responsible for selecting negative samples from the unlabeled data. While the selected, likely negative samples can be used to improve the classifier, the performance of classifier is also used as the reward to improve the selector through the REINFORCE algorithm. By alternating the updates of the selector and the classifier, the performance of both is improved. Extensive experimental studies on 7 real-world application benchmarks demonstrate that PULNS consistently outperforms the current state-of-the-art methods in PU learning, and our experimental results also confirm the effectiveness of the negative sample selector underlying PULNS.}, number={10}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Luo, Chuan and Zhao, Pu and Chen, Chen and Qiao, Bo and Du, Chao and Zhang, Hongyu and Wu, Wei and Cai, Shaowei and He, Bing and Rajmohan, Saravanakumar and Lin, Qingwei}, year={2021}, month={May}, pages={8784-8792} }


@article{pulsnar_48,
  title={Instance-dependent positive and unlabeled learning with labeling bias estimation},
  author={Gong, Chen and Wang, Qizhou and Liu, Tongliang and Han, Bo and You, Jane and Yang, Jian and Tao, Dacheng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={8},
  pages={4163--4177},
  year={2021},
  publisher={IEEE}
}

@article{pulsnar_49,
  title={Direct implementation of asynchronous control units},
  author={Hollaar, Lee A.},
  journal={IEEE Transactions on Computers},
  volume={31},
  number={12},
  pages={1133--1141},
  year={1982},
  publisher={IEEE Computer Society}
}

@inproceedings{pulsnar_50,
  title={Positive and unlabeled learning algorithms and applications: A survey},
  author={Jaskie, Kristen and Spanias, Andreas},
  booktitle={2019 10th International Conference on Information, Intelligence, Systems and Applications (IISA)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}


@article{pulsnar_51,
  title={Mixture proportion estimation and pu learning: a modern approach},
  author={Garg, Saurabh and Wu, Yifan and Smola, Alexander J and Balakrishnan, Sivaraman and Lipton, Zachary},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8532--8544},
  year={2021}
}


@inproceedings{pulsnar_52,
  title={Learning from positive and unlabeled data with a selection bias},
  author={Kato, Masahiro and Teshima, Takeshi and Honda, Junya},
  booktitle={International conference on learning representations},
  year={2018}
}