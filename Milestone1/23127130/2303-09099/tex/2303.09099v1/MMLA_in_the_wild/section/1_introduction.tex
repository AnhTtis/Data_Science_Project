\section{Introduction}
Multimodal Learning Analytics (MMLA) is a relatively new area that formally emerged as such in 2012 at the ACM International Conference of Multimodal Interaction \citep{scherer20121st}. Since then, MMLA innovations have been opening exciting new avenues for supporting and generating a deep understanding of 
human learning by embracing the complexity of learners and their learning activities. MMLA systems are pushing the boundaries in educational research by de-emphasising the computational analysis of student interactions via online learning systems based on input devices such as the mouse and the keyboard \citep{worsley2021new}. In contrast, MMLA emphasises the many ways in which students interact with other students -- fully mediated \citep{vrzakova2020focused}, partly mediated \citep{schneider2018leveraging} or unmediated \citep{sumer2021multimodal} by technology -- with both teachers \citep{dmello2015multimodal}, and with physical learning environments \citep{yan2021footprints}. MMLA research also investigates learner attributes that are hard to automatically analyse without the use of specialised sensing systems, such as student emotions \citep{gorson2022using}, cognitive states \citep{mangaroska2022exploring}, distraction \citep{LIAO2022104599} and stress \citep{ronda2021towards}. In practice, MMLA endeavours often make use of sensors, such as eye-trackers, positioning systems, wearable microphones and physiological writs/chest bands, and advanced audio and video processing algorithms \citep{yan2022scalability,Alwahaby2022} that generate large amounts of multimodal data that can be analysed to gain a more holistic view of intrinsically complex human learning phenomena such as problem-based learning \citep{ma2022detecting}, effective collocated collaboration \citep{spikol2017estimation, Schneider16} and teamwork \citep{fernandez2021can}, self-regulated learning  \citep{azevedo2019analyzing}, engagement in adaptive online learning \citep{papamitsiou2020utilizing}, socially-shared regulated learning \citep{noroozi2019multimodal}, effective public speech \citep{ochoa2020controlled}, motor learning \citep{di2021keep}, and classroom teaching \citep{prieto2018multimodal,Ahuja2019EDU}. In a sense, MMLA aims at crystallising Mark Weiser's vision \citep{weiser1991computer} in educational contexts by creating learning spaces enhanced with ubiquitous computing capabilities to augment teachers' and students' activities. This can be achieved by creating applications that automate the capture of the lived experiences occuring in the learning space to allow later  access to those expierences by educational stakeholders \citep{Abowd2000} for the purpose of supporting reflection and learning \citep{Brotherton04}. Yet, enhancing learning environments with such sensing capabilities can easily impose practical challenges such as elevating the cost of implementation and making it harder to scale up the MMLA deployments in relation to fully digital learning analytics (LA) solutions.  


Although recent literature reviews suggest that most MMLA solutions rely on video and audio analysis \citep{yan2022scalability, Alwahaby2022} (which should not be, in principle, too costly), MMLA researchers consistently report that most current MMLA systems only reach the prototype stage \citep{ochoa_multimodal_2022,cukurova2020promise}. Several practical challenges have been identified as potential threats to the broader adoption of MMLA that can ultimately impact the effectiveness of such innovations in supporting teaching and learning. Challenges include those related to the complexity of some sensor installation requirements and lack of technology readiness to enable full-scale deployments \citep{ochoa_multimodal_2022,cornide2019introducing}; lack of maturity from an analysis perspective to find causal relationships in multimodal data that can translate into actual improvements in learning outcomes \citep{Alwahaby2022}; misalignment between the technological MMLA innovation and the learning design \citep{sharma2020multimodal}; and ethical concerns that can ultimately dissuade educational stakeholders from adopting such complex solutions \citep{crescenzi2020multimodal,Alwahaby2022, cukurova2020promise}. While the number of small-scale laboratory studies -- conducted under controlled conditions -- is similar to the number of small-scale ecological (authentic) studies that have deployed sensors at the classroom level \citep{chua2019technologies}, the majority of MMLA studies (more than two thirds according to a recent literature review by \citet{yan2022scalability}) do not report enough methodological details to allow other researchers to replicate or learn from such deployments. Moreover, there is a lack of relatively large-scale studies conducted under authentic conditions that close the "data loop", that is, transitioning from multimodal data collection and analysis to the provision of some form of end-user interface \cite{yan2022scalability}, which is  one of the ultimate goals in LA research \cite{wise2021makes}. This makes it hard for MMLA researchers to fully understand the extent of the challenges involved in deploying MMLA innovations \textit{"in-the-wild" }(i.e., a deployment that is as naturalistic as possible). In-the-wild studies are commonly conducted in human-computer interaction (HCI) research with the aim of investigating the implications of embedding new technology interventions in everyday situations \citep{rogers2017research,crabtree2013introduction}. Conducting MMLA in-the-wild studies can thus contribute to understanding the challenges that need to be addressed to maximise adoption of MMLA innovations.



This paper addresses the above knowledge gap by synthesising a set of lessons learnt from a large human-centred MMLA study conducted in-the-wild (e.g., see Figure \ref{fig:space}). To the best of our knowledge, and according to the most recent MMLA systematic literature review \cite{yan2022scalability}, this is the first large, complex MMLA study that closes the LA loop by providing direct feedback to students on a group task using MMLA-based visual interfaces. A total of 399 consenting undergraduate students and 17 teachers participated in the study as a part of their regular classes. A range of sensing devices to capture multimodal data was used, namely, video recorders, microphones, physiological sensors, positioning sensors and an educator's logging system. The study spanned two years in which two deployment iterations were conducted. The first iteration focused on collecting multimodal data for research and design purposes. The second iteration focused on the deployment of a MMLA dashboard interface to support teacher-led, team reflection in the classroom. Evidence about the deployment included a set of interviews, surveys and focus groups with teachers, students and researchers to understand more about the practical challenges that emerged. 

   \begin{figure}[t]
  \centering
  \includegraphics[width=1\linewidth]{figures/space.PNG}
  \caption{Sensors deployed in the high-fidelity simulation with a team of four students and two educators enacting the roles of a patient's relative and a doctor who provides some information.}
  \label{fig:space}
  \Description{}
\end{figure}

