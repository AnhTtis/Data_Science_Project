\section{Study in the wild}

\subsection{Context}
The study presented in this paper followed a human-centred learning analytics approach \citep{BuckinghamShum2019}. A partnership between a team of four teachers (\textit{senior teaching team}) and four LA researchers (\textit{researcher team}) was forged to progressively co-create a MMLA innovation to be embedded into the regular classes of an undergraduate course of the Bachelor of Nursing program at Monash University. Students were also consulted to understand i) the extent to which their lived learning experiences can be impacted by the use of sensing technologies, ii) their ethical and privacy concerns, and iii) the extent to which the data insights can effectively support their learning. While details about the co-creation process go beyond the scope of this paper, and can be found elsewhere \cite{Huceta22,fernandez2022beyond}, key information about educators' and students' involvement is provided below. 

In the targeted course, high-fidelity, immersive team simulations are typically conducted to help students develop effective collaboration and communication skills while learning from errors in a safe environment \citep{Sarcevic2012}. High-fidelity simulation is a healthcare education methodology, conducted in a realistic but simulated health setting environment, where clinical situations that students may encounter in the workplace are reproduced using sophisticated manikins as patients \citep{maran2003low}. In these simulations, students are often posed with a situation that they need to address without the instruction of a teacher, followed by a reflective \textit{debrief}, facilitated by a senior teacher, in which students reflect on their actions and learning. The educational goal of the MMLA deployment was decided by the senior teaching team, and aimed at improving the provision of feedback to students in the debrief.  


\subsection{Study iterations and participants}
The MMLA study had two iterations. The first, conducted in 2021, focused on i) collecting a rich multimodal dataset, ii) enhancing the understanding of the senior teaching team about the possibilities enabled by the multimodal data, and iii) asking students about envisaged uses of their data and potential concerns regarding the use of sensors in their regular learning spaces. The second, conducted in 2022, focused on i) closing the LA loop by deploying MMLA visual interfaces to support the reflective debrief, and ii) expanding the multimodal dataset. Both iterations were conducted under almost identical conditions: the same course, learning goals, senior teaching team, and lesson design.

A total of 399 students consented to participate in the study (261 -- 196 females -- consenting out of 461 enrolled students in iteration 1; and 138 -- 114 females -- out 358 in iteration 2). Some students were invited to follow-up activities for them to provide their feedback based on their lived experiences (see details in the next section). Besides the four senior teachers, another 13 teachers were involved in both years facilitating the lesson plan of the simulations.

%CONSENTING STUDENTS
% 2021 = 261
% 2022 = 138
%TOTAL = 399
% ENROLMENTS
% 2021 NUR2212  Clayton 242 Peninsula 219 = 461
% 2022 NUR2212  Clayton 184 Peninsula 174 = 358
% TEACHERS
% 2021 = 16 (3 part of the senior team)
% 2022 = 11 (4 part of the senior team)
% 12 students per session/class - 8 participants and 4 observers (Occasionally we added 1-2 extra students into the group making 5-6 observers, but this was rare.)

\subsection{The authentic learning situation}
Each 3-hour class was typically attended by 10-15 students and was conducted across two learning spaces: a regular classroom and the specialised simulation classroom. The latter featured four beds with a patient manikin in each of them as shown in Figure \ref{fig:space}. Two consecutive simulations would be conducted during the class, both focused on prioritising care and identifying the deteriorating patient who required urgent attention. Students were given important information called a \textit{handover} before commencing, and then asked to provide care in teams according to the assessment they conducted on each manikin.  Each team was made up of four students who volunteered to play either a graduate or ward nurse. These students were also asked to optionally consent to be part of the study. Two teachers enacted the roles of a patientâ€™s family member and a doctor assisting with patient care after students identified a problem.  Other students were invited to be observers, watching the simulation unfold. Immediately after each simulation, a whole class debrief conversation was led by a teacher in the regular classroom.

%Two consecutive simulations were conducted in each class, both posing particular challenges for students to identify which patient needed more urgent attention based on the minimum information provided to them. Teachers asked students to voluntarily form two teams of four members to enact the roles of graduate and ward nurses in the simulations. These students were also asked to optionally consent to be part of the study. Two teachers enacted the roles of a patient's family member and a doctor that performs an initial brief handover. Other students were invited to be observers. Immediately after each simulation, a whole class debrief was led by a teacher in the regular classroom. 

%The goal of students was to gather information from the physical space, the actors enacting roles and the digital devices spread in the simulated hospital ward in order to apply their clinical and communication skills according to the requirements of the situation. No further direct instruction was provided.  

\begin{figure}[t]
   \centering
   \includegraphics[width=\textwidth]{figures/sensors.PNG}
   \caption{Multimodal Learning Analytics (MMLA) deployed in an authentic healthcare education setting. Left: Illustration of a student wearing the sensors during a team simulation. Right: Each sensor set to be worn by each student within a team (A--an indoor positioning locator inside a belly bag, B--a wireless microphone and C--a physiological wristband) was placed by the teaching team on coloured trays to enable easy access to and organisation of the sensors during and between classes.} 
   %Right: a teacher leading a team debrief using positioning and audio data in a MMLA dashboard.}
   %\Description{TODO}
   \label{fig:equipment}
 \end{figure}

\subsection{Apparatus}
Before entering the simulation classroom, consenting students were asked to wear a number of devices, namely, a wireless headset with an unidirectional microphone; a physiological Empatica E4 wristband, with built-in sensors that capture heart rate variability, electrodermal skin activity among other physiological measures; and a Pozyx indoor positioning locator, with built-in sensors that capture \textit{x-y} position and body orientation of each student in the learning space (see Figure \ref{fig:equipment}). Each set of sensors was colour-coded according to the role enacted by each student (i.e., red and blue for graduate nurses, and yellow and green for ward nurses). The simulation room was already equipped with a set of built-in video cameras, and an additional 180-degree video camera was added to the set up. All the data (except those captured by the wristbands due to limitations of the software vendor, to be discussed later in the lessons learnt) were captured and synchronised in \textit{real-time} using our open-source MMLA infrastructure called \href{https://teamwork-analytics.github.io/yarn-sense}{YarnSense}.

It should be noted that despite these devices, this experience was not completely novel to students, since these simulations are commonly video recorded and students often wear lapel microphones for the rest of the class to observe the simulation from the regular classroom. After each simulation, the reflective debrief was conducted with both the team who participated in the simulation and the rest of the class in the regular classroom. A dashboard displaying representations of the multimodal data collected during the simulation was deployed in the debriefs as detailed next. 



\subsection{The MMLA dashboard}
Figure \ref{fig:dashboard} depicts the MMLA dashboard deployed in the second iteration of the in-the-wild study. This interface was automatically loaded after each simulation and shown in the main screen of the regular classroom (Figure \ref{fig:dashboard} left), to be used by teachers to support the reflective debrief. A set of three MMLA visualisations was designed with the senior teaching team, each using more than one modality of data. For example, Figure \ref{fig:dashboard} (right) illustrates the dashboard showing one of such visualisations. This shows the locations of each colour-coded student in the simulation space where they were speaking with each other or with the patient, by automatically triangulating coordinate data from the positioning sensors and outputs using a voice activity detection algorithm applied on the multi-channel microphone signals. Each hexagonal data point summarises which student was in that position doing most of the talking. %The aim for the particular visualisation was to invite students to reflect on whether the team identified what was the patient that required to be prioritised (in Bed 4) and whether most of the attention was posed on that patient. 
Two other visualisations included a bar chart to summarise positioning data coded according to the particularities of the team task; and a sociogram (a network based chart) focused on depicting the extent of verbal communication among team members, the patient and the other actors. Further details about these go beyond the purpose of this paper which is focused on reporting the lessons learnt from the iterative deployment as a whole. Nonetheless, details and the source-code can also be found in our \href{https://teamwork-analytics.github.io/yarn-sense}{YarnSense} repository.
%The next section describes the sources of evidence used to illustrate our lessons learnt from the two-year MMLA deployment. 



\begin{figure}[h]
   \centering
   \includegraphics[width=\textwidth]{figures/dashboard.PNG}
   \caption{Left: A teacher leading a team debrief using positioning and audio data in the MMLA dashboard. Right: The MMLA dashboard providing a menu of visualisations at the top. The selected example visualisation shows whether students, according to their role/colour, were speaking or not at certain positions of the learning space (see hexagons filled with student's colour or in grey, respectively).}
   %\Description{TODO}
   \label{fig:dashboard}
 \end{figure}