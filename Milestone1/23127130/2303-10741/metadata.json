{
    "arxiv_id": "2303.10741",
    "paper_title": "Computer Vision Estimation of Emotion Reaction Intensity in the Wild",
    "authors": [
        "Yang Qian",
        "Ali Kargarandehkordi",
        "Onur Cezmi Mutlu",
        "Saimourya Surabhi",
        "Mohammadmahdi Honarmand",
        "Dennis Paul Wall",
        "Peter Washington"
    ],
    "submission_date": "2023-03-19",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.LG"
    ],
    "abstract": "Emotions play an essential role in human communication. Developing computer vision models for automatic recognition of emotion expression can aid in a variety of domains, including robotics, digital behavioral healthcare, and media analytics. There are three types of emotional representations which are traditionally modeled in affective computing research: Action Units, Valence Arousal (VA), and Categorical Emotions. As part of an effort to move beyond these representations towards more fine-grained labels, we describe our submission to the newly introduced Emotional Reaction Intensity (ERI) Estimation challenge in the 5th competition for Affective Behavior Analysis in-the-Wild (ABAW). We developed four deep neural networks trained in the visual domain and a multimodal model trained with both visual and audio features to predict emotion reaction intensity. Our best performing model on the Hume-Reaction dataset achieved an average Pearson correlation coefficient of 0.4080 on the test set using a pre-trained ResNet50 model. This work provides a first step towards the development of production-grade models which predict emotion reaction intensities rather than discrete emotion categories.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10741v1"
    ],
    "publication_venue": null
}