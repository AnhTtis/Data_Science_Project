\newcommand{\yes}[0]{\gren{yes}}
\newcommand{\no}[0]{\tred{no}}

\begin{table*}[t]
\begin{small}
\begin{tabular}{l|c|ccc|c}
% \begin{tabular}{l|>{\columncolor{greenish}}c>{\columncolor{greenish}}c>{\columncolor{redish}}c|c}
\toprule
\textbf{Method} & \textbf{Type} & \textbf{Storage} & \textbf{Memory} & \textbf{Backprop} & \textbf{Inference overhead} \\
\midrule
Adapters          \cite{adapters}                & \ad     & \yes & \yes & \no  & Extra FFN                    \\
AdaMix            \cite{adamix}                  & \ad     & \yes & \yes & \no  & Extra FFN                    \\
SparseAdapter     \cite{sparse_adapter}          & \ad \se & \yes & \yes & \no  & Extra FFN                    \\
Cross-Attn tuning \cite{cross_attention_tuning}  & \se     & \yes & \yes & \no  & \gren{No overhead}           \\
BitFit            \cite{bitfit}                  & \se     & \yes & \yes & \no  & \gren{No overhead}           \\
DiffPruning       \cite{diff_pruning}            & \se     & \yes & \no  & \no  & \gren{No overhead}           \\
Fish-Mask         \cite{fish_mask}               & \se     & \yes & \orange{maybe}\footnotemark[5] & \no  & \gren{No overhead} \\
LT-SFT            \cite{lottery_ticket_tuning}   & \se     & \yes & \orange{maybe}\footnotemark[5] & \no  & \gren{No overhead} \\
Prompt Tuning     \cite{prompt_tuning}           & \ad     & \yes & \yes & \no  & Extra input                  \\
Prefix-Tuning     \cite{prefix_tuning}           & \ad     & \yes & \yes & \no  & Extra input                  \\
Spot              \cite{spot}                    & \ad     & \yes & \yes & \no  & Extra input                \\
IPT               \cite{ipt}                     & \ad     & \yes & \yes & \no  & Extra FFN and input \\
MAM Adapter       \cite{parallel_adapter}        & \ad     & \yes & \yes & \no  & Extra FFN and input          \\
Parallel Adapter  \cite{parallel_adapter}        & \ad     & \yes & \yes & \no  & Extra FFN                    \\
\footnotesize{Intrinsinc SAID} \cite{intrinsic_said} & \rp & \no  & \no & \no  & \gren{No overhead}            \\
LoRa              \cite{lora}                    & \rp     & \yes & \yes & \no  & \gren{No overhead}           \\
% DyLoRa            \cite{dylora}                  & \rp     & \yes & \yes & \no  & \gren{No overhead}         \\
UniPELT           \cite{unipelt}                 & \ad \rp & \yes & \yes & \no  & Extra FFN and input          \\
\footnotesize{Compacter}         \cite{compacter}               & \ad \rp & \yes & \yes & \no  & Extra FFN                    \\
\footnotesize{PHM Adapter} \cite{compacter}      & \ad \rp & \yes & \yes & \no  & Extra FFN                    \\
KronA             \cite{krona}                   &     \rp & \yes & \yes & \no  & \gren{No overhead}           \\
KronA$^B_{res}$   \cite{krona}                   & \ad \rp & \yes & \yes & \no  & Extra  linear layer          \\
(IA)$^3$          \cite{t_few}                   & \ad     & \yes & \yes & \no  & Extra gating                 \\
% \footnotesize{WARP \cite{Hambardzumyan2021WARPWA}} & \ad   & \yes & \yes & \no  & Extra input                \\
% IPT               \cite{ipt}                     & \ad     & \yes & \yes & \no  & Extra input                  \\
Attention Fusion  \cite{attention_fusion}        & \ad     & \yes & \yes & \yes & Extra decoder         \\
LeTS              \cite{lets}                    & \ad     & \yes & \yes & \yes & Extra FFN                    \\
Ladder Side-Tuning \cite{ladder_side_tuning}     & \ad     & \yes & \yes & \yes & Extra decoder                \\
FAR               \cite{far_edge}                & \se     & \yes & \orange{maybe}\footnotemark[6] & \no  & \gren{No overhead}           \\
S4-model          \cite{design_spaces}           &\ad \rp \se& \yes & \yes & \no  & Extra FFN and input          \\
\bottomrule
% Meta-Adapters     \cite{meta_adapters}           & A      & \yes & \yes & \no  & Extra FFN                  \\
% Priming           \cite{}                        & A      & \yes & \yes & \no  &                              \\
% Prompt Mapping    \cite{prompt_mapping}          & A      & \yes & \yes & \no  & Extra input                \\
% Polyhistor        \cite{polyhistor}              & A      & \yes & \yes & \no  &                              \\
% PETT              \cite{pett}                    & \rped{?}& \yes & \yes & \no  &                              \\
\end{tabular}
\end{small}
\caption{Comparing \peft{} methods across storage efficiency, memory efficiency, and computational efficiency in terms of reducing backpropagation costs and having inference overhead. Method types: \textbf{\ad} -- additive, \textbf{\se} -- selective, \textbf{\rp} -- reparametrization-based.
% Note that S4-model has smaller inference overhead than other methods that combine Adapters and Prefix-tuning, because it uses differnt combinations of \peft{} methods on different layer (Section \rpef{sec:s4}). FishMask and FAR memory efficiency depend on weight pruning method. FishMask can significantly benefint from sparse operations hardware support (Section \rpef{sec:fishmask}).
% ^* Kronerker layer is a linear layer where weight matrix is constructed as a kroneker product of
}
\label{tab:efficiency}
\end{table*}
