\section{Preliminaries and Baseline}
\label{sec:preliminaries}
%
We design an end-to-end distributed system for effective and scalable embedding of large graphs via random walks.
To this end, we first discuss relevant works on random walk-based sequential graph embedding (\S \ref{sec:randGembedding}) and
distributed systems for random walks on graphs (\S \ref{sec:dRand}). Then, we propose a baseline distributed system for
random walk-based graph embedding by combining the above two methods (\S \ref{sec:HUGED}), discuss its limitations
and scopes of improvements, which leads to introducing our ultimate system, {\sf DistGER}
in \S \ref{sec:DistGER} and \S \ref{sec:learning}.
Table~\ref{tab:Notations_paper} explains the most important notations.
%For simplicity, we consider an undirected, unweighted input graph; however, our method also works for directed and weighted graphs.
{\sf DistGER} handles undirected and unweighted graphs by default,
but can support directed and weighted  graphs (higher edge weights imply stronger connectivity). {\sf DitsGER} uses the {\em Compressed Sparse Row} (CSR) \cite{csr_format}
format to store graph data, where directed edges are stored with their source nodes and undirected edges are stored twice for both directions.
For each weighted edge, CSR stores a tuple containing its destination node and edge weight.
%
\begin{table}[tb!]
\footnotesize
\centering
\begin{center}
  \caption{\small Frequently used notations}
  \label{tab:Notations_paper}
  \begin{tabular}{l||l} %\hline
  \textbf{Notation}   & \textbf{Meaning} \\ \hline \hline
    $G = (V, E)$ & $G$: undirected, unweighted graph; $V$: set of nodes; $E$: set of edges\\
    $\varphi(u)$ & embedding or vector representation of node $u$, having dimension $d$ \\
    %$d$          & dimension of vector representation\\
    $w$          & window size of context in the {\sf Skip-Gram}\\
%    $deg(u)$     & degree of node $u$\\
    $N(u)$       & neighbors of node $u$ \\
%    $Cm(u,v)$    & common neighbors of nodes $u$ and $v$\\
%    $\alpha(u,v)$& un-normalized probability of selecting node $v$ as the next-hop node of $u$\\
    $L$          & random walk length starting from a node\\
    $r$          & number of random walks per node\\
    $H(X)$       & entropy of random variable $X$ with possible values {$x_1, x_2, \ldots, x_n$} \\
%    $D(q\rVert p)$ & discrepancy between the two distributions $p$ and $q$ via relative entropy\\
%    $\mu$        & parameter for estimating the walk length \\
%    $\delta$     & parameter for estimating the number of walks per node\\
  %\hline
\end{tabular}
\end{center}
\end{table}
%
\subsection{Random-walks Based Graph Embedding}
\label{sec:randGembedding}
These graph embedding algorithms are inspired by the well-known natural language processing model, {\sf word2vec} \cite{word2vec_2013}:
They transform a graph into a set of random walks through sampling methods, treat each random walk as a sentence,
and then adopt {\sf word2vec} ({\sf Skip-Gram}) to generate node embeddings from the sampled walks.

\spara{Node2vec.}
A most representative algorithm in the aforementioned category is {\sf node2vec} \cite{node2vec_2016}, as given below.
%It considers higher-order properties of nodes and defines a flexible notion of neighborhoods in a biased random walk procedure,
%thus efficiently capturing homophily and structural equivalences features.

\underline{Random walk method.}
Given a graph $G=(V, E)$, two nodes $u, v \in  V$, and we suppose a walker is currently at node $u$.
{\sf Node2vec} defines the transition probability from $u$ to $v$ as $P(u,v)= \frac{\pi_{uv}}{Z}$,
%
% \begin{small}
% \begin{equation}
% \vspace{-1mm}
%  P(u,v)= \left\{
% \begin{aligned}
% \frac{\pi_{uv}}{Z}&, & if (u,v)\in E\\
% 0&, &otherwise
% \end{aligned}
% \right.
% \end{equation}
% \end{small}
%
where $\pi_{uv}$ is the unnormalized transition probability from $u$ to $v$, and $Z$ is the normalization constant defined as $\sum_{v\in N(u)} \pi_{uv}$.
{\sf Node2vec} defines a second-order random walk. %with two parameters $p$ and $q$, which guide the walk.
%, providing more flexibility in discovering representations conforming to different equivalences. To simulate this procedure,
Assume that a walker just traversed node $t$ and now resides at node $u$ ($u$ is a neighbor of $t$).
Next, it will select a node $v$ from $u$'s neighbors.
%the candidates ($v1, v2, v3, v4, t$) as shown in Fig.~\ref{example_graph_random_walk},
The un-normalized transition probability $\pi_{uv}$
%denoted as $\pi_{uv} = \alpha_{pq}(t,v)%\cdot w_{uv}
%$, is as follows:
is defined by $d_{tv}$, which is the shortest path distance between nodes $t$ and $v$:
If $d_{tv}$ is 0, 1, 2, respectively, then the corresponding $\pi_{uv}$ is $1/p$, $1$, $1/q$.
%\begin{figure}
%  \begin{center}
%  \includegraphics[width= 1.8 in]{example_random_walk.eps}
% \caption{An example of the random walk procedure in node2vec. The walk just transitioned from $t$ to $u$ and is now evaluating its next-hop vertex from candidate set ($v1, v2, v3, v4, t$). Edge labels indicate unnormalized transition probability $\alpha$.}
%  \label{example_graph_random_walk}
%  \end{center}
%\end{figure}
%
%\begin{small}
%\begin{equation}
%\label{node2vec_eq}
% \alpha_{pq}(t,v) = \left\{
%\begin{aligned}
%\frac{1}{p}&, & if\ d_{tv}=0\\
%1&, & if\ d_{tv}=1\\
%\frac{1}{q}&, & if\ d_{tv}=2
%\end{aligned}
%\right.
%\end{equation}
%\end{small}
%%
%Here, $d_{tv}$ denotes the shortest path distance between nodes $t$ and $v$;
%$w_{uv}$ is the edge weight of the $(u,v)$ (In case of unweighted graphs $w_{uv} = 1$),
Hyperparameters $p$ and $q$ are called return and in-out parameters, respectively.
$d_{tv} = 0$ means that $t$ and $v$ are the same node, i.e., the
walker goes back to $t$, which is a BFS-like exploration, thus setting a small $p$ obtains
a ``local view" in the graph with respect to the start node.
$d_{tv} = 1$ means that $v$ is a neighbor of $t$, %such as $v1$ and $v4$,
and $d_{tv} = 2$ denotes a DFS-like exploration % such as $v2$ and $v3$,
to get a ``global view" in the graph, which can be attained by a small $q$.

\underline{Features learning for graph embedding.}
Features learning maps $\varphi: V \to R^d $ from nodes to feature representations (node embeddings).
%where $d$ is the number of dimensions for feature representations and $\varphi(u)$ is the embedding vector of vertex $u$.
Since {\sf node2vec} captures node representations based on the {\sf Skip-Gram} model \cite{word2vec_2013}
%which is a natural language processing model
that maximizes the co-occurrence probability
between words within a window $w$ in a sentence, %for each given node $u_j$, %the optimization for
the objective is:
%
\begin{small}
\begin{equation}
%\max_{\varphi} \sum_{u \in V}log Pr(N_S(u)\mid\varphi(u))
\operatorname*{argmax}_\varphi \frac{1}{|V|}\sum\limits_{j=1}^{|V|}\sum\limits_{-w\leq i\leq w}\log{p(u_{j+i}| u_j)}
\label{skim_gram_eq}
\end{equation}
\end{small}
%
The generated walks are used as a corpus with vocabulary $V$,
where $u_{j+i}$ denotes a context node in a window $w$, and $p(u_{j+i}| u_j)$ indicates the probability to predict the context node.
The basic {\sf Skip-Gram} formulates $p(u_j| u_{j+i})$ as the softmax function.
 %is estimated by:
%
%Skip-Gram . Assuming that the predicting nodes in a context are independent of one another, the conditional probability in Equation~\ref{skim_gram_eq} can be approximated by:
%
%\begin{small}
%\begin{equation}
%Pr(N_S(u)\mid\varphi(u)) = \prod_{n_i \in N_{S(u)}} Pr(n_i\mid\varphi(u))
%\end{equation}
%\end{small}
%
%Since neighboring nodes are symmetrical to each other in the feature space, it use the softmax unit to model the conditional likelihood for each source-neighbor node pair as:
%
%\begin{small}
%\begin{equation}
%\label{context_probablity}
%p(u_j| u_{j+i}) = \frac{\exp(\varphi_{in}(u_{j+i})\cdot\varphi_{out}(u_{j}))}{\sum_{v \in V}\exp(\varphi_{in}(u_{j+i})\cdot\varphi_{out}(v))}
%\end{equation}
%\end{small}
%
%The function $\sum_{v \in V}\exp(\varphi_{in}(u_{j+i})\cdot\varphi_{out}(v))$ is expensive,
%since its cost is proportional to $|V|$, which is often very large.
%To reduce the overhead,
Existing methods generally
speed-up training %by approximating the log of Eq.~\ref{context_probablity}
with negative sampling \cite{negative_sampling_2013}.
%
\begin{small}
\begin{equation}
\label{negative_sampling_Eq}
\begin{aligned}
\log p(u_j| u_{j+i}) &\approx \log\sigma(\varphi_{in}(u_{j+i})\cdot\varphi_{out}(u_{j})) \\
&+\sum\limits_{k=1}^{K}\mathbb{E}_{u_k \sim Pn(u)}[\log\sigma(-\varphi_{in}(u_{j+i})\cdot\varphi_{out}(u_{k}))]
\end{aligned}
\end{equation}
\end{small}
%
Here, $\sigma(x)=\frac{1}{1+exp(-x)}$ is the sigmoid function, and the expectations
are computed by drawing random nodes from a sampling distribution $Pn(u)$, $\forall u \in V$.
Typically, the number of negative samples $K$ is much smaller than $|V|$ (e.g., $K\in[5,20]$).%, and hence roughly a $V/K$ times of speed-up

\underline{Complexity analysis.}
Assume that the number of walks per node is $r$, walk length $L$, embedding dimensions $d$, window size $w$,
and the number of negative samples $K$. The time complexity of {\sf node2vec} random-walk procedure
is $\bigO(r\cdot L\cdot |V|)$.
For feature learning, the corpus size $C = r\cdot L$. Let us denote the complexity of the unit operation of predicting and updating one node's
embedding as $o$. The {\sf Skip-Gram} with the negative sampling only needs $K+1$ words to obtain a probability distribution
(Eq.~\ref{negative_sampling_Eq}), thus the time complexity of
{\sf node2vec} feature learning is $\bigO(C \cdot w \cdot (K+1) \cdot o)$. %, which is related to corpus size under the condition that other factors are
Since each node in the {\sf Skip-Gram} model needs to maintain two embeddings $\varphi_{in}$ and $\varphi_{out}$
for the parameter updates, the space complexity of {\sf node2vec}, which refers to the parameter sizes, is $O(|V|d)$.

\underline{Drawbacks.}
Despite the flexibility in exploring node representations (local-view vs. global-view),
{\sf node2vec} incurs high time overhead. %to laboriously tune hyperparameters.
It leverages a routine random walk configuration (usually, $L$=80 and $r$=10)
to generate walks, similar to most existing random walk-based graph embedding methods, which limits the efficiency and scalability on large-scale graphs. Indeed, this {\em one-size-fits-all}
strategy cannot meet the specific requirements of different real-world graphs. %It is also simplistic to use the same configuration for different nodes due to their different properties.
For instance, the high-degree nodes are usually located in dense areas of a graph, they might require longer and more random walks to capture more comprehensive features; while for the low-degree nodes, if treated equally, it may introduce redundancy into generated walks, thus limiting the scalability.
%of random-walk sampling and learning.
%
%The study from an information theory in \cite{HuGE_2021} reveals that using $L=80$ introduces large amount of redundancy into the generated walking paths, and the number of rounds required for the vertex occurrence counts distribution to converge in a generated corpus is usually greater or less than the routine value $r=10$.

\spara{HuGE.}
The recent work, {\sf HuGE} \cite{HuGE_2021} attempts to resolve the routine random walk issue of {\sf node2vec} and proposes a novel information-oriented random walk mechanism to achieve a concise and comprehensive representation in the sampling procedure.

\underline{Random walk method.}
First, {\sf HuGE} leverages a hybrid random walk strategy, which considers both node degree and the number of common neighbors in each walking step. %This is because
Common neighbors represent potential information between nodes, e.g., node similarity \cite{ Line_2015}. %High-degree nodes, on the other hand, play important roles in a graph, e.g., information spreading in social networks and epidemics control in disease networks.
For random walks, high-degree nodes are revisited more, and walks starting from them can obtain richer information by traveling around their local neighbors \cite{ common_neighbor_aware_icde_2019}.
%Formally, %suppose a walker is currently at node $u$,
%{\sf HuGE} defines
The un-normalized transition probability from node $u$ to the next-hop node $v$ is:
%
\begin{small}
\begin{equation}
\alpha(u,v) = \frac{1}{deg(u)-Cm(u, v)} \times \max \left\{\frac{deg(u)}{deg(v)}, \frac{deg(v)}{deg(u)} \right\}
\label{accept_CNHRW}
\end{equation}
\end{small}
%
where $deg(u)$ is the degree of $u$, and $Cm(u, v)$ denotes the number of their common neighbors. Thus, $\frac{1}{deg(u)-Cm(u, v)}$ indicates the similarity between the current node $u$ and the next-hop node $v$, the ratio grows with higher $Cm(u, v)$, since $deg(u)$ is fixed. The $\max$ function assigns a weight to the transition probability from $u$ to $v$, indicating the influence of a high degree node on its neighbors.
%In this fashion, HRW is arguably capable of both identifying similarity property and ensuring the exploration of richer information in the random walking. To limit the computation overhead, HRW leverages a commonly used stra teg}y, walking-backtracking \cite{common_neighbor_aware_icde_2019}, to determine the next-hop in each walking step, it only accesses the accepted vertex instead of traversing all vertices in $N(u)$ in each step. Formally, the transition probability from $u$ to $v$ can be written as:
%
%Specifically,

At the current node $u$, {\sf HuGE} randomly chooses $v$ from $N(u)$ as a candidate node, the acceptance probability for $v$ as the next-hop node is $P(u,v)$, and if $v$ is rejected, which happens with probability $1-P(u,v)$, the walker backtracks to $u$ and repeats a random selection again from $N(u)$, known as the {\em walking-backtracking} strategy \cite{ common_neighbor_aware_icde_2019}. $P(u,v)$ is defined as $Z\left(\alpha(u,v)\right)$,
%
% \begin{small}
% \begin{equation}
% P(u,v)=Z\left(\alpha(u,v)\right),  \quad if (u, v) \in E
% % P(u,v)=\begin{cases}Z\left(\alpha(u,v)\right),  &\quad if (u, v) \in E \\
% % 0,  &\quad otherwise
% % \end{cases}
% \label{probability_CNHRW}
% \end{equation}
% \end{small}
%
where {\sf HuGE} normalizes $\alpha(u,v)$ via $Z(x) = \frac{e^x-e^{-x}}{e^x+e^{-x}}$, which is widely-applied in machine learning. %and satisfies walking-backtracking.
For edge weight $w(u,v)$, we define $P(u,v)=Z\left(\alpha(u,v) \cdot w(u, v)\right)$.

Second, in contrast to a one-size-fits-all strategy, {\sf HuGE} proposes a heuristic walk length strategy to measure the effectiveness of information during walk based on entropy ($H$).
%{\sf HuGE} measures the variation of entropy with respect to the walk length ($L$), which initially increases with $L$, and when this becomes stable, as quantified by the coefficient of determination ($R^2$) between $H$ and $L$, the random walk is stopped.
Mathematically, let us denote the random walk starting at the source node $u$ as $W_u^L = \{ v_u^1, v_u^2, v_u^3, \ldots,v_u^L \}$, where $v_u^k$ denotes the $k$-th node on the walk. The probability of
the occurrence of a specific node $v$ on the walk is $\frac{n(v)}{L}$, where $n(v)$ is the number of occurrences of $v$ on the generated walk. The information entropy of the generated walk is:
%
\begin{small}
\begin{equation}
H\left(W_u^L\right) = -\sum_{v \in W_u^L}\frac{n(v)}{L}\log\frac{n(v)}{L}
\label{path_entropy}
\end{equation}
\end{small}
%
With increasing $L$, as the occurrence probability for a specific node in a generated walk gradually stabilizes, $H\left(W_u^L\right)$ initially grows with $L$ until it converges. {\sf HuGE} characterizes the correlation between $H\left(W_u^L\right)$ and $L$ by linear regression and calculates the coefficient of determination ($R^2$) to determine the termination of a random walk.
%
\begin{footnotesize}
\begin{equation}
R\left(H(W_u^L),L\right) = \frac{\sum_{i=1}^{L^*}\left(H\left(W_u^{L(i)}\right)-\overline{H(W_u^L)}\right)\left(L(i)-\overline{L}\right)}{\sqrt{\sum_{i=1}^{L^*}\left(H\left(W_u^{L(i)}\right)-\overline{H(W_u^L)}\right)^2}\sqrt{\sum_{i=1}^{L^*}\left(L(i)-\overline{L}\right)^2}}
\label{path_corr}
\end{equation}
\end{footnotesize}
%
$\overline{H\left(W_u^L\right)}$ and $\overline{L}$ are the mean of the respective series for $1 \leq i\leq L^*$, and $L^*$ is the optimal walk length for the current walk. As $L$ grows and $H(W_u^L)$ stabilizes, $R^2{(H,L)}$ also decreases and converges to 0, since their linear correlation diminishes. {\sf HuGE} sets  $R^2(H,L) < \mu$ as the walk termination condition. %(i.e.,  when the walk stops).
Setting a smaller $\mu$ generates longer walks, %but it destroys the linear relationship,
introducing redundant information; while too large $\mu$ may not ensure good coverage of graph properties during sampling, since too short walks are generated. Based on our experimental results, good quality walk lengths are attained with $\mu=0.995$.
%
%\begin{algorithm}[tb!]
%\footnotesize
%\caption{\small {\sf Node2vec} walking procedure in KnightKing}
%\label{node2vec_knightking}
%\begin{algorithmic}[1]
%\Require current node $u$, candidate node $v$, walker $W$
%\Ensure walker state updates
%
%%\State
%{\bf sendStateQuery($u$, $v$, $W$)} %//{submit the walker-to-node query \textcolor{red}{messages and process state queries}}
%%\State return $v$, $W$, $W.prev$
%\If {$W.steps$ != 0} //{$u$ is not the starting node of $W$}
%%\If {d($W.prev,v$)==0}  // $W.prev$ and $v$ same node
%%\State $\pi_{uv}=1/p$
%%\ElsIf {d($W.prev,v$)==1}  //$v$ is a neighbor of $W.prev$
%%\State $\pi_{uv}=1$
%%\Else  { }  //distance between $W.prev$ and $v$ is 2
%%\State $\pi_{uv}=1/q$
%%\EndIf
%\State {{\bf if} d($W.prev,v$)==1 \bf {return} $\pi_{uv}=1$}
%\State {{\bf else}  {\bf return} $\pi_{uv}$ = d($W.prev,v$)==0 $?$ $1/p$ : $1/q$}
%\EndIf
%%\setcounter{AlgoLine}{0}
%%\State
%
%{\bf getStateQueryResult($W, \pi_{uv}$)} %//{\textcolor{red}{return results to walkers about their states, and then decide based on the sampling outcome}}
%\State randomly sample a point $(x,y)$ in the rectangular area covered by the lines $y =Q(u)$ and $x = |N(u)|$
%\If {$\frac{\pi_{uv}}{Z}$ $\geq$ $y$}
%\State accept($v$)
%\State $W.prev$ = $u$, $W.cur$ = $v$, $W.steps$++
%\State generate a candidate node $t$ for $v$
%\State sendStateQuery($v$, $t$, $W$)
%\Else
%\State reject($v$)
%\State generate another candidate node $v'$ for $u$
%\State sendStateQuery($u$, $v'$, $W$)
%%\State getStateQueryResult($W, \pi_{uv'}$)
%\EndIf
%%
%%\For {all partition $i = 0$ to $n-1$}
%%\State{$\omega(P_i)$ = $1-\frac{|P_i|}{\gamma \times \sum \limits_{i=1}^{n} |P_i|}\times n$}
%%\State $|PS_1(v, P_i)|$ = Galloping($|P_i \cap N(v)|$)
%%\For {u in $P_i \cap N(v)$}
%%\State {$|PS_2(v, P_i)|$ += $|Cm(u)\cap Cm(v)|$}
%%\EndFor
%%\State {$PS(i)$ = $(|PS_1(v, P_i)|$ + $|PS_2(v, P_i)|$ + $\varepsilon )\times \omega(P_i)$ }
%%\EndFor
%%\State{\Return return argmax($PS(i))$}
%\end{algorithmic}
%\end{algorithm}

Third, {\sf HuGE} also proposes a heuristic number of walks strategy. The corpus is generated by multiple ($r$) random walks from each node. Following \cite{DeepWalk_2014}, if the degree distribution of a connected graph follows power-law, the frequency in which nodes appear in short random walks will also follow a power-law distribution. Inspired by this observation, {\sf HuGE} empirically analyzes the similarity between the two distributions via relative entropy. %The similarity initially increases with more random walks, and when it converges, no new random walk is conducted from the source nodes.
Formally, the node degree distribution is expressed as $p(v) = \frac{deg(v)}{\sum_{v\in V}deg(v)}$. We denote the number of occurrences of $v$ in the generated corpus as $ocn(v)$. The probability distribution for such appearances in the corpus is $q(v) = ocn(v)/\sum_{v\in V}ocn(v)$. The relative entropy from $p$ to $q$ is:
%
\begin{small}
\begin{equation}
\begin{aligned}
D(p\rVert q)
&=\sum_{i=1}^{r^*}\frac{deg(v)}{\sum deg(v)}\log\frac{{deg(v)}{\sum ocn(v)}}{{ocn(v)}{\sum deg(v)}}
\end{aligned}
\end{equation}
\end{small}
%
Here, $r^*$ is the optimal number of walks from a source node. With increasing
$r$, the difference $D_r(p \rVert q)$ gradually converges, which means that the probability distribution of nodes' occurrences in the generated corpus has stabilized.
%
\begin{small}
\begin{equation}
\Delta D_r(p \rVert q)= |D_r(p\rVert q)-D_{r-1}(p\rVert q)|
\end{equation}
\end{small}

{\sf HuGE} leverages $\Delta D_r(p \rVert q) \leq \delta$ as the termination condition. Based on our experimental results, $\delta=0.001$ usually produces
a good number of random walks per source node.
%
%
%\begin{scriptsize}
%\begin{equation}
%\Delta D_r(q \rVert p)= |D_r(q(v_i)\rVert p(v_i))-D_{r-1}(q(v_i)\rVert p(v_i))|, r>1
%\end{equation}
%\end{scriptsize}

\underline{Features learning for graph embedding.} The features learning uses the {\sf Skip-Gram} model, and similar to {\sf node2vec}, %the objective function is optimized with
follows Eq.~\ref{skim_gram_eq} and~\ref{negative_sampling_Eq}.

\underline{Complexity analysis.}
The time complexity of {\sf HuGE} random-walk procedure is $\bigO(r'\cdot L'\cdot |V|)$, where
the optimal number of walks per node is $r'$ (decided by $\Delta D_r(q \rVert p) \leq \delta$) and
the average walk length is $L'$ (decided by $R^2(H,L) < \mu$ for each walk).
However, the complexity of measuring $H(W)$ and $R\left(H(W),L\right)$ at each step of a walk
is $\bigO(L)$, where $L$ is the current walk length.
Thus, the overall computational workload of {\sf HuGE}
becomes quadratic in the walk length, though the average walk length
can be smaller than that in {\sf Node2Vec}.
% \textcolor{red}{H, R?}
The time complexity of the feature learning phase remains $\bigO(C' \cdot w \cdot (K+1) \cdot o)$,
but the average corpus size $C'=r'\cdot L'$ is smaller, since generally $r'<r$ and $L'<L$.

%The HWL strategy for random walk length is related to the walking path effectiveness estimator
%and thus its complexity is related to the walk length estimator $\mu$ and number of walks per node estimator $\delta$, and is denoted as $O(\frac{|V|}{\mu \delta})$,
%in practices, the walk length actually generated in HuGE is much smaller than the routine methods.

\underline{Drawbacks.} The workload of {\sf HuGE} is quadratic in the walk length. Moreover, {\sf HuGE} \cite{HuGE_2021} embedding method is sequential, and there is yet no end-to-end distributed system to support graph embedding via information-oriented random walks. Being sequential, {\sf HuGE} requires more than one week to learn embeddings for a billion-edge Twitter graph on a modern server.
%
%
\subsection{Distributed Random Walks on Graphs}
\label{sec:dRand}
{\sf KnightKing} \cite{KnighKing_2019} is a recent general-purpose, distributed graph random walk engine. Its key components are introduced below.
%
\begin{algorithm} [tb!]
\footnotesize
\caption{\small {\sf HuGE-D} walking procedure}
\label{HuGE-D_walk}
\begin{algorithmic}[1]
\Require current node $u$, candidate node $v$, Walker $W$, {\sf HuGE} parameter $\mu$
\Ensure walker state updates
%\State
{\flushleft{{\bf sendStateQuery($u$, $v$, $W$)}}} %//{submit the walker-to-vertex query messages and process the state queries}
%\State return $v$, $W$, $W.prev$
%\If {$W.steps$ != 0}
%\State {$u=W.cur$}
\State{$P(u,v) = Z\left(\frac{1}{deg(u)-Cm(u, v)}\cdot \max \left\{\frac{deg(u)}{deg(v)}, \frac{deg(v)}{deg(u)} \right\} \right)$} // Eq.~\ref{accept_CNHRW}

{\flushleft{{\bf getStateQueryResult($W, P(u,v)$)}}} %// {return results to querying walkers for retrieving the state and decide sampling outcome}
%\If {$v$ is local vertex}
\State{generate a random number $\eta \in\left[0,1\right]$}
\If{$P(u,v)> \eta $}
\State{$W.path$.append($v$), $W.cur$ = $v$, $W.steps$ ++}
%\State{Generate a random number p$\in\left[0,1\right]$}
%\If{$p> Z\left(\frac{1}{deg(u)-Cm(u, v)}\cdot \left\{ I(v)\cdot\triangle H_{W_u^L} \right\} \right)$}
%\State{Append $curr$ to $walk$}
%\EndIf
\State{$L$ = $W.steps$}
\State compute $H(W)$ and $R\left(H(W),L\right)$ // Eq.~\ref{path_entropy}, \ref{path_corr}
%\For {$v_i$ in $W.path$} // unique $v_i$ in walk path
%\State{$p_{v_i} = \frac{n(v_i)}{\sum_{v_i \in W.path}n(v_i)}$}
%\EndFor
%\State{$H$.append($-\sum p_{v_i}log p_{v_i}$)}
%State{$R_{(H,L)}^2$ = Squared of $r_{(H,L)}$}
%\Else
%\State Emit message ($v$, $W$) to target computing node
%\State Measure effectiveness of $W.path$ with lines 5-13
%\EndIf
\If{$R^2(H(W),L) < \mu$}
\State terminate the walk
\Else
\State{generate another candidate node $t$ of $v$}
\State{sendStateQuery($v$, $t$, $W$)}
\EndIf
\Else
\State{backtrack to $u$ and generate another candidate node $v'$ of $u$}
%\State{generate another candidate node $v'$ of $u$}
\State{sendStateQuery($u$, $v'$, $W$)}
%\State{getStateQueryResult($W, P(u,v')$)}
\EndIf
%\EndWhile
%\State{\Return $W.path$}
\end{algorithmic}
\end{algorithm}

\underline{Walker-centric programming model.}
For higher-order walks (e.g., second-order random walks in {\sf node2vec}),
%Existing graph processing frameworks focus on updating the state of vertices along edges by a vertex- or edge-centric computation mechanism, usually using push/pull updates and performing vertex state updates through one round of vertex-to-vertex messages. For the random walk algorithms implementation, the walker for random walk task has to be handled as messages in these systems, when handling higher-order walks, since each walker's next move depends on its recent walk history, such as in the case of node2vec, to check whether the previous stop $t$ is adjacent to a candidate stop $v$, as shown in Fig.~\ref{example_graph_random_walk}, the walker just transitioned from $t$ to $u$ and is now evaluating its next-hop vertex $v$ from candidate set, the unnormalized transition probability $\pi_{uv}$ is related by the shortest path distance $d_{tv}$ between vertices $t$ and $v$, thus each walker needs to perform vertex selection based on vertices it recently visited, but the generated one round of vertex-to-vertex messages do not have the capability of tracking/optimizing walker state updates, it just performs push/pull update propagation along all/active edges. Therefore,
{\sf KnightKing} assumes a walker-centric view. %, supporting the walker's state updates and walk-related operations in
%its walker-centric programming model.
%instead of the vertex state updates required in existing graph engines.
%Algorithm~\ref{node2vec_knightking} shows the walking procedure of {\sf node2vec}
%in this model.
{\sf KnightKing} implements each step of %higher-order
walks by two rounds of message passing,
one round for walkers to submit the walker-to-node query messages
% ({\bf sendStateQuery})
to check the distance between the previous node $W.prev$ and the candidate node $v$ %based on their local sampling candidate(s)
and to generate the un-normalized transition probability $\pi_{uv}$;
%(Lines 1-3)
another round of message passing
%({\bf getStateQueryResult})
returns results to walkers about their states, and then
the walkers decide the next steps based on the sampling outcome.
 %(Lines 4-13)
 %In this fashion, the framework provides an intuitive
%``think-like-a-walker'' view to update the walkers' states and supports high-order walks.




{\sf KnightKing} coordinates many walkers simultaneously
%in iterative computation
based on the Bulk Synchronous Parallel ({\sf BSP}) model \cite{BSP_1990}. Walkers are assigned to some computing machine/thread. %, which is similar to traditional graph engines that coordinate updates at many vertices (along many edges) in iterations. But the obvious difference is the probabilistic walk along sampled edges used in the walker-centric model. In the sense that the computation of edge transition probability is critical to efficiency for walk forwarding.
{\sf KnightKing} leverages rejection sampling to %strategy to exact sampling,
eliminate the need of scanning all out-edges at the walker's current node.  %to recalculate their transition probabilities.
Suppose a walker is currently at node $u$, the sampling method generates a candidate node $v$ (a neighbor of $u$) with a transition probability $p(u,v)$. The key idea of rejection sampling is to find an envelop $Q(u)=max(\frac{1}{p}, 1, \frac{1}{q})$: %that converts the 1-D sampling problem among the vertices into a 2-D one,
Within the rectangular area covered by the lines $y =Q(u)$ and $x =|N(u)|$,
it randomly samples a location $(x, y)$ from this area,  if $p(u,v) \geq y$, $v$ is accepted as a successfully sampled node,
otherwise, $v$ is rejected, and the method conducts more sampling trials until success. %(Lines 10-19, Algorithm~\ref{node2vec_knightking}).
%For {\sf Node2vec}, {\sf KnightKing} %replaces the alias method with this strategy to optimize the random walk forwarding process, which
%sets $Q(u)$ as $max(\frac{1}{p}, 1, \frac{1}{q})$.
%
\begin{figure*}
   \centering
   \includegraphics[width= 6 in]{./Figures/DistGER__framework_1_1.eps}
   \caption{\small The workflow of our proposed system: {\sf DistGER}}
   \label{HuGER_framework}
 \end{figure*}
%

\underline{Workload-balancing graph partition.}
{\sf KnightKing} adopts a node-partitioning scheme -- each node (together with its edges)
is assigned to one computing machine in a distributed setting.
%Considering to achieve even memory consumption,
It roughly estimates the workload as the sum of the number %of nodes and
of edges in each
computing machine, and ensures a balance of workloads across computing machines by
appropriately distributing the nodes. % incident edges.
%
% node, and performs 1-D partition that leverages the $total\_workload$ (all edges in the graph)
%divide the number of partitions ($partition\_num$) balancing this sum across nodes, ensuring the balance in each computing node, which is defined as:
%
%\begin{small}
%\begin{equation}
%\label{knightking_partition}
%work\_load = \frac{total\_workload+partition\_num - 1}{partition\_num}
%\end{equation}
%\end{small}

\underline{Complexity analysis.} For walk forwarding, %process, %since the rejection-based sampling allows one to sample first, then check whether the sampling can be accepted, instead of $O(E_u)$ examination at the current vertex $u$ to update the relative probability for sampling edges, in
each trial of rejection sampling %method, it just
needs $\bigO(1)$ time. %to check the actual transition probability $p(u,v)$ for only the sampled vertex $v$ whether less or greater than the defined envelope $Q(u)$,
With a reasonable $Q(u)$, there is a good chance for the sampling to succeed within a few trials,
thus the walk forwarding computation for one step can
be achieved in near $\bigO(1)$ complexity.
For communication, each message consists of
[$walk\_id$, $steps$, $node\_id$, $previous\_node\_id$] for {\sf node2vec}.
When a walk crosses a computing machine, it sends $M(1)$, i.e.,
one constant-length message to another machine. In a distributed environment,
assuming $P$ processors and the network bandwidth $B$, as analyzed in {\sf node2vec},
the total workload for {\sf KnightKing} is $\bigO(r\cdot L\cdot |V|)$, with near $\bigO(1)$ computation
complexity for each step. Thus, the average time spent in each processor is
$\bigO(r\cdot L\cdot |V|/P)$. The communication cost is $\bigO(N\cdot M(1)/B)$,
where $N$ is the count of cross-machine messages.
Thus, the time spent for {\sf KnightKing} %in a distributed setting
is: $\bigO(r\cdot L\cdot |V|/P + N\cdot M(1)/B)$.

\underline{Drawbacks.} %Although
{\sf KnightKing}
%brings up several orders of magnitude improvement and exhibits well scalability, it focuses on optimizing the random walk forwarding process and
provides distributed system support for traditional random walks, e.g., the one in {\sf node2vec}. For information-oriented random walks in {\sf HuGE}, the walkers need to additionally maintain the generated walking path at each step, %such as in the case of walk length measurement, it needs to calculate the information entropy to adjust the walk length based on the generated walking path at each step,
and thus the message requires to carry the path information. %: [$walk\_id$, $steps$, $node\_ id$, $path\_information$].
The message length increases with the length of the walks, thus the efficiency of {\sf KnightKing} reduces due to extra overheads of computation and communication (elaborated in \S \ref{sec:HUGED}). %Besides,
%for the workload-balancing partition mechanism, since the key of the performance of graph partitions is to trade-off for the edge or vertex cuts and the load balancing,
The purely load-balancing partition scheme in {\sf KnightKing} also introduces high communication cost. %Specifically, the randomness inherent in random walks exacerbates the performance due to cross-machine communications.
%The disadvantages are elaborated when we next introduce our baseline, {\sf HuGE-D} (\S \ref{sec:HUGED}).
%
\subsection{Baseline: HuGE-D}
\label{sec:HUGED}
Our distributed baseline approach, {\sf HuGE-D} %is a distributed implementation of {\sf HuGE} using the {\sf KnightKing} framework.
%It
replaces the traditional random walking method in {\sf KnightKing} with the information-oriented scheme of {\sf HuGE},
and leverages a full-path computation mechanism. %based on the walker-centric model of {\sf KnightKing}.
%
%\begin{figure}[h]
%  \centering
%  \includegraphics[width= 3 in]{computation_analysis_for_path.eps}
%  \caption{The computation mechanism by full path information of HuGE-D in two computing nodes.}
%  \label{full_path_mechanism}
%\end{figure}
%

\underline{Full-path computation mechanism.}
As previously stated, to meet the information measurement requirements,
{\sf HuGE-D} stores the full-path in the message, in addition to the necessary fields
such as $walk\_id$, $steps$, and $node\_id$. Algorithm~\ref{HuGE-D_walk} shows the
walking procedure, where we retain the {\em walking-backtracking} strategy of
{\sf HuGE}, which is similar to rejection sampling in {\sf KnightKing}.
%
%analyzed in KnightKing, the information-centric random walk-based HuGE can not
%be straightforward deployed on the walker-centric computing mechanism in distributed
%settings, to implement a distributed HuGE, the walker needs to additionally consider
%the information measurement for the generated walking path at each iteration, regardless
%of whether in local node or across nodes, and thus we design a full-path measurement
%computation mechanism based on this walker-centric model. In KnightKing, it leverages
%the walker as message passing to track and update the walker states in random walk,
%along this direction, at each iterations, to meet the information-centric measurement requirements,
%HuGE-D maintains extra generated walking path in the message, in addition to the necessary fields
%including the $walk\_id$, $steps$ and $vertex\_id$. As shown in Fig.~\ref{full_path_mechanism} and
%Algorithm~\ref{HuGE-D_walk}, the raw graph is partitioned into two computing nodes (Node 1 and Node 2), for graph data allocated in the local Node 1, a candidate vertex $v$ is selected from the neighbors of current vertex $walker.vertex$ denoted as $u$ (e.g., $v_2$ is selected from the green candidate sets for $v_1$ in Fig.~\ref{full_path_mechanism}), and then the walker submits the walker-to-vertex query message and generated the transition probability $P(u,v)$ from $u$ to $v$ based on the hybrid-property heuristic random walk (HRW) (in lines 1 to 3), then message passing will return result to querying walker for retrieving the state and decide sampling outcome, as shown in lines 4 to 17, if $v$ is accepted, it will be added into the walking path and updated the walker state (in lines 5 to 9), then adopts the heuristic walk length (HWL) to measure the information effectiveness of the generated walking path at each step (in lines 10 and 16), e.g., $H_1$ in Fig.~\ref{full_path_mechanism} is measured for generated walking path $[v_1, v_2]$, the information measurement is defined in Equation~\ref{HWL_EQ}, with the $L$ variation, the probability of vertex $v_i$ occurrence in the generated path will be calculated or updated for each step (in lines 11 to 13) until triggering the termination condition of the random walk, mathematically, the dynamic measurements are obtained with the full-path information. If a walker needs to across a computing node (such as the walker stays at $v_5$ in Fig.~\ref{full_path_mechanism}), the message requires to carry the walking path generated by Node 1 (here is $[v_1, v_2, v_3, v_4, v_5]$) to Node 2 to synchronize the path information as shown in the right panel of Fig.~\ref{full_path_mechanism}, and then remeasuring the effectiveness of the new generated path in another sampling trail.

\underline{Complexity analysis.}
{\sf HuGE-D} measures the information effectiveness of generated walks at each step.
The complexity of measuring $H(W)$ and $R\left(H(W), L\right)$ at each step
is $\bigO(L)$, where $L$ is the current walk length. For the communication cost due to messages, {\sf HuGE-D}
additionally requires carrying the generated walking path information in contrast to {\sf KnightKing},
so the message cost is also linear in the walk length $L$, which we denote as $M(L)$.
Similar to {\sf KnightKing}, since the total workload is related to the average walk length $L'$
and the optimal number of walks per node $r'$, the time spent for {\sf HuGE-D} in distributed setting is:
$\bigO(r'\cdot (L')^2\cdot |V|/P + N\cdot M(L')/B)$,
where $P$, $B$, and $N$ are the number of processors, network bandwidth,
and the count of cross-machine messages, respectively.
%%
%
%\begin{table}
%\setlength{\abovecaptionskip}{0.cm}
%\setlength{\belowcaptionskip}{-0.cm}
%\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
%  \caption{Running time (seconds) comparison between KnightKing and HuGE-D on BlogCatalog graph ($|V|$ =10312, $|E|$=333983) as the number of walks per node increases.}
%  \label{HuGE-D_walking}
%  \begin{center}
%  \footnotesize
%  \begin{tabular}{ccccc}
%    \hline
%    {\bfseries walks}&{\bfseries $1\times|V|$}&{\bfseries $5\times|V|$}&{\bfseries $10\times|V|$}&{\bfseries $20\times|V|$}\\
%    \hline
%    KnightKing& 16.967 &17.897 & 18.601 &20.093 \\
%    HuGE-D &5.058 &13.888 &25.055 &47.040 \\
%  \hline
%\end{tabular}
%\end{center}
%\end{table}
%\begin{figure*}[tb!]
%  \centering
%  \includegraphics[width= 6 in]{DistGER__framework_1.eps}
%  \vspace{-2mm}
%  \caption{\small \textcolor{red}{update} The workflow of our proposed system: {\sf DistGER}}
%  \label{HuGER_framework}
%  \vspace{-5mm}
%\end{figure*}

\underline{Drawbacks.}
%The disadvantages of {\sf HuGE-D}, compared to {\sf KnightKing}, are threefold.
%Table~\ref{HuGE-D_walking} exhibits the performance with a side-by-side comparison between HuGE-D and KnightKing on the BlogCatalog graph. Our experiment shows, with the number of walks per vertex increasing, HuGE-D exhibits exponential growth compared to linearly varying KnightKing, indicating the scalable information-centric random walk methods cannot bring positive gains via the current equipped framework. We explore the inefficiency of HuGE-D from the following aspects:
{\bf (1) Computation:} %the key difference between KnightKing and HuGE-D is whether using a information-centric random walk during sampling procedure, as analyzed above, under the full-path computation mechanism,
{\sf HuGE-D} measures the effectiveness of generated walks at each step, which
has $\bigO(L)$ complexity, where $L$ is the current walk length. Thus, unlike {\sf KnightKing}, the computational workload of {\sf HuGE-D}
is quadratic in walk length.
%
%More seriously, if a walker crosses a computing node, such as the generated walking path $[v_1, v_2, v_3, v_4, v_5]$ from Node 1 to Node 2 in Fig.~\ref{full_path_mechanism}, since the number of vertex occurrences needs to be updated in the new computing node, it should be recomputed the probability of vertex occurrence for the walking path $W(L_i)$ ($1\leq i\leq L$, lines 11 to 13 in Algorithm~\ref{HuGE-D_walk}) and then generated the corresponding information entropy $H_i$ at each step (line 14 in in Algorithm~\ref{HuGE-D_walk}). A consequent, it can be inferred that the number of computations for the generated path $W(L_i)$ ranged in $L_i$ to $L_i(L_i+1)/2$, which means that the best case is that all vertices in $W(L_i)$ are at the local node, and the worst case is that adding a vertex to $W(L_i)$ at each step triggers cross-node computation, obviously, there are large amount redundant computations in this procedure. An example as shown in Fig.~\ref{computation_all_path} is the number of computations for each step on BlogCatalog graph, each line denotes the random walk starting at a source node, with the $L$ increasing, the effectiveness measurement for $W(L_i)$ introduces a large amount of computations and is close to the worst case, while KnightKing just takes near $O(1)$ complexity for walk forwarding process without measuring the quality of sampling. {\bfseries
{\bf (2) Communication:} {\sf KnightKing} only sends constant-length messages, e.g.,
for {\sf node2vec} each message has [$walk\_id$, $steps$, $node\_id$, $prev\_node\_id$],
but the messages in {\sf HuGE-D} carry the full-path
information (i.e., [$walk\_id$, $steps$, $node\_ id$, $path\_info$])
for information measurements, thus the message cost is linear in the walk length.
%Given 8 Byte space to store each variable, {\sf KnightKing} only spends 32 Bytes for each message,
%while{\sf HuGE-D} needs $24+8L$ Bytes, e.g., if $L\approx$ 80,
%the cost of one message passing in {\sf HuGE-D} is up to 20.7x higher than that in {\sf KnightKing}.
{\bf (3) Partitioning:} The workload-balancing partition in {\sf KnightKing}
fails to consider the large amount of cross-machine communications introduced by the randomness inherent in random walks.
%,
%which is also not favorable to {\sf HuGE-D}. %, since it already has higher computation and communication costs
%produced by information measurements.
%as analyzed in (1) and (2). Table.~\ref{KnightKing_cross_inner_num} exhibits the number of corss-nodes and inner-node computation during sampling procedure in HuGE-D on four real-world graphs with increasing scale, the ratio of inner-node computations to cross-nodes computations goes from 1.08 to 0.27, further indicating the efficiency of this engine is bogged down by the inefficient graph partition mechanism.
%
%\begin{figure}
%  \centering
%  \includegraphics[width= 3 in]{HuGE_computation_analysis_all_path.eps}
%  \caption{The number of computations to measure the walk path effectiveness for each step in BlogCatalog graph.}
%  \label{computation_all_path}
%\end{figure}
%
%\begin{table}
%\setlength{\abovecaptionskip}{0.cm}
%\setlength{\belowcaptionskip}{-0.cm}
%\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
%  \caption{Number of cross-nodes and inner-node computation during sampling procedure in HuGE-D on four real-world graphs. $(M=1\times10^6)$}
%  \label{KnightKing_cross_inner_num}
%  \begin{center}
%  \footnotesize
%  \begin{tabular}{cccc}
%    \hline
%    {graph }&{\bfseries cross\_num }&{\bfseries inner\_num }&{\bfseries inner/cross}\\
%    \hline
%    Wiki-Vote& 0.50M &0.54M &1.08   \\
%    Youtube& 123.68M &139.31M &1.13   \\
%    soc-Pokec &168.99M &105.32M &0.62  \\
%    LiveJournal &222.32M &59.74M &0.27 \\
%  \hline
%\end{tabular}
%\end{center}
%\end{table}

