\section{Practical Termination Algorithms} \label{sec:alg}
%


We first present the algorithm $\mathsf{IsChaseFinite[SL]}$ that accepts as input a database $D$ and a set $\dep$ of simple-linear TGDs, and checks whether $\dep$ is $D$-weakly-acyclic, which is equivalent to say that the instance $\chase{D}{\dep}$ is finite.
%
Note that a naive search for a ``bad'' cycle in a dependency graph will be too costly since we may have to go through exponentially many cycles. Thus, $\mathsf{IsChaseFinite[SL]}$ relies on a refined machinery that searches for {\em strongly connected components} with a special edge.
%
We then proceed to give an analogous algorithm, dubbed $\mathsf{IsChaseFinite[L]}$, for linear TGDs, which essentially simplifies the given database $D$ and set $\dep$ of linear TGDs, and then checks whether $\simple{\dep}$ is $\simple{D}$-weakly-acyclic, which is equivalent to say that $\chase{D}{\dep}$ is finite.
%; the latter check is done by calling $\mathsf{IsChaseFinite[SL]}$.
%
Note, however, that $\mathsf{IsChaseFinite[L]}$ relies on a refined notion of simplification that {\em dynamically simplifies} $\dep$ by leveraging the given database $D$, instead of doing it statically as in Definition~\ref{def:simplification} without taking any database into account. The goal of the dynamic simplification is to keep only TGDs of $\simple{\dep}$ that are really needed for checking whether the chase instance is finite.
%
Note that in this section we present the above algorithms at a high-level without delving into implementation details; the latter will be the subject of Section~\ref{sec:implementation}. 


\subsection{Simple-Linear TGDs}\label{sec:slinear}

Before presenting $\mathsf{IsChaseFinite[SL]}$, we need to introduce a couple of auxiliary notions. A {\em strongly connected component} (SCC) in a directed graph $G$ is a maximal subgraph of $G$ in which there is a (directed) path between every pair of nodes. A {\em special SCC} in a dependency graph is an SCC with at least one special edge. We are now ready to discuss $\mathsf{IsChaseFinite[SL]}$, which is depicted in Algorithm~\ref{alg:slinear}.
%
It starts by building the dependency graph $G$ of the input set $\dep$ of simple-linear TGDs (line~\ref{ln:graph}).
%
It then collects the special SCCs of $G$ in a set $S$ (line~\ref{ln:bcycles}), which can clearly form ``bad'' cycles that violate the condition underlying non-uniform weak-acyclicity. Of course, for the latter to happen, some nodes (i.e,., predicate positions) in a special SCC must be supported by the given database $D$ as defined in Section~\ref{sec:prel}. To check this, the algorithm first collects exactly one node $v_C$ from each special SCC $C$ of $G$ in a set $P$ (line~\ref{ln:initP}); note that it is not important how $v_C$ is selected. It then checks if $D$ supports any of the nodes of $P$ (line~\ref{ln:return_f}). If this is the case, then there is a $D$-supported cycle in $G$ with a special edge, and thus the algorithm returns \false; otherwise, it returns \true. The implementation details of \textsf{BuildDepGraph}, \textsf{FindSpecialSCC}, and \textsf{Supports} are discussed in Sections~\ref{sec:bgarph}, \ref{sec:scc}, and \ref{sec:support}, respectively.
%
The correctness of $\mathsf{IsChaseFinite[SL]}$ follows by Theorem~\ref{the:characterization-simple-linear}:

\begin{lemma}\label{lm:simple}
	Consider a database $D$ and a set $\dep \in \class{SL}$ of TGDs. It holds that $\mathsf{IsChaseFinite}[\class{SL}](D,\dep) = \true$ iff $\chase{D}{\dep}$ is finite.
\end{lemma}



\begin{algorithm}[t]
\KwIn{A database $D$ and a set $\dep \in \class{SL}$ of TGDs}
\KwOut{\true if $\chase{D}{\dep}$ is finite and \false otherwise}

\medskip

$G \leftarrow \textsf{BuildDepGraph}(\dep)$;\label{ln:graph}\\
$S \leftarrow \textsf{FindSpecialSCC}(G)$;\label{ln:bcycles}\\
$P \leftarrow \bigcup_{C \in S}{\{v_C\}}$;\label{ln:initP}\\
\lIf{$\mathsf{Supports}(D,P,G)$}{\KwRet{\false}\label{ln:return_f}}
\KwRet{\true}\label{ln:return_t}
\caption{$\mathsf{IsChaseFinite[SL]}$}\label{alg:slinear}
\end{algorithm}




\subsection{Linear TGDs}\label{sec:linear}
%

Although the algorithm $\mathsf{IsChaseFinite[SL]}$ together with the simplification technique (see Definition~\ref{def:simplification}) immediately give rise to a simple algorithm for checking the finiteness of the chase instance for linear TGDs, a naive implementation of the simplification technique leads to poor performance. Indeed, we performed exploratory experiments on real-world sets of linear TGDs and observed that a naive implementation is not scalable as the algorithm quickly runs out of memory when dealing with large sets of TGDs. This is because by statically simplifying a set of linear TGDs $\dep$, without taking into account the underlying database, leads to an exponentially large set of simple-linear TGDs; in particular, the size of the set $\simple{\dep}$ is exponential in the maximum arity of the predicates in $\sch{\dep}$. Thus, the algorithm $\mathsf{IsChaseFinite[SL]}$ becomes impractical due to the very large size of the dependency graph of $\simple{\dep}$, which exceeds the capacity of the main memory.



\medskip

\noindent
\textbf{Dynamic Simplification.}
We refine the notion of simplification by taking into account the underlying database, which leads to the technique of dynamic simplification. In particular, given a database $D$ and a set $\dep$ of linear TGDs, the goal is to define a set $\dsimple{D}{\dep}$, which is a subset of $\simple{\dep}$, that enjoys two crucial properties:
\begin{enumerate}
	\item It holds that the instance $\chase{\simple{D}}{\simple{\dep}}$ is finite iff the instance $\chase{\simple{D}}{\dsimple{D}{\dep}}$ is finite, which essentially tells us that the technique of dynamic simplification preserves the finiteness of the chase.
	\item The set $\dsimple{D}{\dep}$ is, in general, orders of magnitude smaller than the set $\simple{\dep}$ obtained by statically simplifying $\dep$.
\end{enumerate}
Item (1) is established by Lemma~\ref{lm:dyn-simplification} below. Item (2) cannot be mathematically proved as there are cases where both static and dynamic simplification build the same set of linear TGDs. However, we have experimentally verified that for existing databases and sets of TGDs coming from the literature (in fact, those used in Section~\ref{sec:rw-kb}), the size of the dynamically simplified sets of TGDs is, on average, 5 times smaller than the size of the corresponding statically simplified sets of TGDs. The absolute difference varies with the dynamically simplified sets being up to 1000 times smaller in the best case.

The key idea of dynamic simplification is to exploit the shapes of the atoms occurring in the given database to guide the simplification.
%
More precisely, given a database $D$ and a set $\dep$ of linear TGDs, we first collect the shapes that can be derived from $\shape{D}$ using the TGDs of $\dep$; we denote this set as $\dep(\shape{D})$. Then, $\dsimple{D}{\dep}$ keeps from the set $\simple{\dep}$ only those simple-linear TGDs such that the predicate of their body-atom belongs to $\dep(\shape{D})$, as these are the only TGDs that can be applied during the construction of the instance $\chase{\simple{D}}{\simple{\dep}}$. All the other TGDs of $\simple{\dep}$ are superfluous whenever the input database is $D$ in the sense that they will never be applied during the construction of $\chase{\simple{D}}{\simple{\dep}}$. We proceed to formalize this idea. To this end, we need to introduce some auxiliary notions.


For a schema $\ins{S}$, let $\shape{\ins{S}}$ be the set of all shapes mentioning a predicate of $\ins{S}$, that is, the finite set of shapes
\[
\shape{\ins{S}}\ =\ \left\{R_{\id{}{\bar t}} \mid R \in \ins{S} \textrm{ and } \bar t \in \left(\ins{C}^{\arity{R}} \cup \ins{V}^{\arity{R}}\right)\right\}.
\]
For a set of shapes $S \subseteq \shape{\ins{S}}$, the {\em database induced by $S$}, denoted $\mi{DB}[S]$, is the database $\{R(\id{}{\bar t}) \mid R_{\id{}{\bar t}} \in S\}$. For example, assuming that $S = \{R_{(1,2)}, P_{(1,1,2)}\}$, then 
$\mi{DB}[S] = \{R(1,2),P(1,1,2)\}$.
%
Consider now a linear TGD $\sigma = 
R(x_1,\ldots,x_n) \ra \exists \bar z\, \psi(\bar y,\bar z)$
and let $h$ be a homomorphism from $\{R(x_1,\ldots,x_n)\}$ to $\{R(i_1,\ldots,i_n)\} \subseteq \mi{DB}[\shape{\{R\}}]$. The {\em $h$-specialization} of the tuple $(x_1,\ldots,x_n)$ is the (unique) specialization $f$ of $(x_1,\ldots,x_n)$ such that $f(x_i) = f(x_j)$ iff $h(x_i) = h(x_j)$, for every $i,j \in [n]$. For example, assuming that $h$ is a homomorphism from $\{R(x,y,x,z)\}$ to $\{R(1,1,1,2)\}$, the $h$-specialization of $(x,y,x,z)$ is the function $f$ such that $f(x)=x$, $f(y)=x$, and $f(z)=z$.
%
We can now proceed with the formalization of dynamic simplification.



Consider a set $\dep$ of linear TGDs and a set of shapes $S \subseteq \shape{\dep}$; for brevity, we write $\shape{\dep}$ for $\shape{\sch{\dep}}$. A shape $R_{\id{}{\bar t}} \in \shape{\dep}$ is an {\em immediate consequence} of $S$ and $\dep$ if:
\begin{enumerate}
	\item $R_{\id{}{\bar t}} \in S$, or
	\item there is a TGD $R(\bar x) \ra \exists \bar z\, \psi(\bar y,\bar z)$ in $\dep$ and a homomorphism $h$ from $\{R(\bar x)\}$ to $\mi{DB}[S]$ such that $R_{\id{}{\bar t}}$ occurs in the head of the simplification of $\sigma$ induced by the $h$-specialization of $\bar x$.
	%\item there exists a TGD in $\simple{\dep}$ of the form
	%\[
	%R'_{\id{}{\bar t'}}(\bar x)\ \ra\ \exists \bar z \, \ldots,R_{\id{}{\bar t}}(\bar y),\ldots
	%\] 
	%such that the shape $R'_{\id{}{\bar t'}}$ belongs to $S$.
\end{enumerate}
In simple words, item (2) tells us that there exists a TGD in $\simple{\dep}$ of the form $R'_{\id{}{\bar t'}}(\bar x)\ \ra\ \exists \bar z \, \ldots,R_{\id{}{\bar t}}(\bar y),\ldots$ with $R'_{\id{}{\bar t'}} \in S$.
%
The {\em immediate consequence operator} of $\dep$ is the function $\Gamma_{\dep} : 2^{\shape{\dep}} \ra 2^{\shape{\dep}}$
(as usual, $2^X$ denotes the powerset of a set $X$) such that
\[
\Gamma_{\dep}(S)\ =\ \left\{R_{\id{}{\bar t}} \mid R_{\id{}{\bar t}} \text{ is an immediate consequence of } S \text{ and } \dep\right\}.
\]
By iterative applications of the above operator, we can compute the shapes that can be derived from $S$ using the TGDs of $\dep$. Formally,
\[
\Gamma_{\dep}^{0}(S)\ =\ S \qquad \text{and} \qquad \Gamma_{\dep}^{i}(S)\ =\ \Gamma_{\dep}(\Gamma_{\dep}^{i-1}(S)) \,\, \text{ for } \,\, i > 0
\]
and we finally let
\[
\dep(S)\ =\ \bigcup_{i \geq 0} \Gamma_{\dep}^{i}(S).
\]
At first glance, the construction of $\dep(S)$ requires infinitely many iterations. However, since $\dep(S) \subseteq \shape{\dep}$, in the worst-case $\dep(S)$ is obtained after $|\shape{\dep}|$ iterations. It is actually easy to verify that $\dep(S) = \Gamma_{\dep}^{|\simple{\dep}|}(S)$. Therefore, since $\shape{\dep}$ is finite, we conclude that $\dep(S)$ can be obtained after finitely many steps.
%
We now have all the ingredients to formally define dynamic simplification.


\begin{definition}\label{def:dyn-simplification}
	Consider a database $D$ and a set $\dep$ of linear TGDs.\footnote{We assume, without loss of generality, that the atoms of $D$ mention only predicates of $\sch{\dep}$, and thus, $\shape{D} \subseteq \shape{\dep}$. Indeed, the atoms of $D$ with a predicate not in $\sch{\dep}$ do not affect in any way the size of the instance $\chase{D}{\dep}$.} The {\em dynamic simplification of $\dep$ relative to $D$} (or {\em $D$-simplification of $\dep$}), denoted $\dsimple{D}{\dep}$, is defined as the set
	\begin{multline*}
	\big\{	\simple{R(f(\bar x))} \rightarrow \exists \bar z\, \simple{\psi(f(\bar y),\bar z)} \mid\\
	R(\bar x) \ra \exists \bar z\, \psi(\bar y,\bar z) \in \dep \text{ and } f \text{ is the $h$-specialization of } \bar x\\
	\text{ for some homomorphism } h \text{ from } \{R(\bar x)\} \text{ to } \mi{DB}(\dep(\shape{D}))\big\}
	\end{multline*}
	consisting only of simple-linear TGDs. \hfill\markfull
\end{definition}

It is not difficult to verify that the $D$-simplification of $\dep$ essentially collects all the TGDs of $\simple{\dep}$ such that the predicate of their body-atom belongs to $\dep(\shape{D})$.
%
\ignore{
\begin{definition}\label{def:dyn-simplification}
	Consider a database $D$ and a set $\dep$ of linear TGDs.\footnote{We assume, without loss of generality, that the atoms of $D$ mention only predicates of $\sch{\dep}$, and thus, $\shape{D} \subseteq \shape{\dep}$. Indeed, the atoms of $D$ with a predicate not in $\sch{\dep}$ do not affect in any way the size of the instance $\chase{D}{\dep}$.} The {\em dynamic simplification of $\dep$ relative to $D$} (or {\em $D$-simplification of $\dep$}), denoted $\dsimple{D}{\dep}$, is defined as the set
	\[
	\left\{R_{\id{}{\bar t}}(\bar x) \ra \exists \bar z \, \psi(\bar y,\bar z) \in \simple{\dep} \mid R_{\id{}{\bar t}} \in \dep(\shape{D})\right\}.
	\]
	consisting only of simple-linear TGDs. \hfill\markfull
\end{definition}
}
%
We now proceed to show that indeed dynamic simplification preserves the finiteness of the chase.

\begin{lemma}\label{lm:dyn-simplification}
	Consider a database $D$ and a set $\dep \in \class{L}$ of TGDs. The following are equivalent:
	\begin{enumerate}
		\item $\chase{\simple{D}}{\simple{\dep}}$ is finite.
		\item $\chase{\simple{D}}{\dsimple{D}{\dep}}$ is finite.
	\end{enumerate}
\end{lemma}



\begin{proof}
	Since, by definition, $\dsimple{D}{\dep} \subseteq \simple{\dep}$, it is clear that (1) implies (2). The interesting direction is (2) implies (1).
	%
	\ignore{
	We start by observing that $(1)$ holds iff $\chase{\simple{D}}{\simple{\dep^+}}$ is finite, and $(2)$ holds iff $\chase{\simple{D}}{\dsimple{D}{\dep^+}}$ is finite, where $\dep^+$ is obtained from $\dep$ by replacing each TGD with an empty frontier of the form
	$R(x_1,\ldots,x_n) \ra \exists z \, \psi(\bar z)$ with the TGD $R(x_1,\ldots,x_n,y) \ra \exists z \, \psi(\bar z,y)$ with a non-empty frontier; $\psi(\bar z,y)$ is obtained from $\psi(\bar z)$ by simply replacing each atom $P(\bar u)$ with $P(\bar u,y)$.
	%
	Therefore, it suffices to show that if $\chase{\simple{D}}{\dsimple{D}{\dep^+}}$ is finite, then $\chase{\simple{D}}{\simple{\dep^+}}$ is finite. As we shall see, it is more convenient to work with $\dep^+$ instead of $\dep$ since the following is guaranteed: whenever a predicate $P$ is reachable from a predicate $R$ (w.r.t.~$\dep^+$), i.e., $R \reach{\dep^+} P$, then there exists a path in the dependency graph of $\dep^+$ starting from a node $(R,i)$ and ending at a node $(P,j)$; the latter is not true whenever we have TGDs with an empty frontier. 
}
	We proceed to establish the contrapositive of the implication in question, that is, if the instance $\chase{\simple{D}}{\simple{\dep}}$ is infinite, then the instance $\chase{\simple{D}}{\dsimple{D}{\dep}}$ is also infinite. To this end, we first show an auxiliary technical lemma:
	
	\begin{lemma}\label{lm:aux-dyn-simplification}
		Consider a path $(R_1,i_1),\ldots,(R_n,i_n)$ in the dependency graph of $\simple{\dep}$ such that there is an atom of the form $R_1(\bar c)$ in $\simple{D}$. It holds that $\{R_1,\ldots,R_n\} \subseteq \dep(\shape{D})$.
	\end{lemma}

	\begin{proof}
		We proceed by induction on the length $n$ of the path.
				
		\textbf{Base Case.} Clearly, $\shape{D} \subseteq \dep(\shape{D})$. Since $\shape{D}$ coincides with the set of predicates used by the atoms of $\simple{D}$ and, by hypothesis, $R_1$ is used by an atom of $\simple{D}$, we get that $R_1 \in \dep(\shape{D})$, as needed.
				
		\textbf{Inductive Step.} Consider a path $(R_1,i_1),\ldots,(R_n,i_n)$ in the dependency graph of $\simple{\dep}$ with $R_1$ being a predicate used by an atom of $\simple{D}$. By induction hypothesis, $\{R_1,\ldots,R_{n-1}\} \subseteq \dep(\shape{D})$. It remains to show that $R_n \in \dep(\shape{D})$.
		%
		Assume that $\sigma$ is the TGD witnessing the edge $((R_{n-1},i_{n-1}),(R_{n},i_{n}))$ in the dependency graph of $\simple{\dep}$. There is $i \geq 0$ such that $R_{n-1} \in \Gamma_{\dep}^{i}(\shape{D})$. Since $R_{n-1}$ is the predicate of the body-atom of $\sigma$, $R_n \in \Gamma_{\dep}^{i+1}(\shape{D})$. Thus, $R_n \in \dep(\shape{D})$.
	\end{proof}

	We can now show the desired implication. Since, by hypothesis, $\chase{\simple{D}}{\simple{\dep}}$ is infinite, Theorem~\ref{the:characterization-simple-linear} allows us to conclude that there exists a $\simple{D}$-supported cycle with a special edge in the dependency graph of $\simple{\dep}$. Let
	\[
	(R_1,i_1),\ldots,(R_n,i_n),
	\]
	with $(R_1,i_1) = (R_n,i_n)$, be such a cycle. Since this cycle is $\simple{D}$-supported, there exists an atom $P(\bar c) \in D$ and a node $(R_j,i_j)$ in the cycle such that $P \reach{\dep} R_j$. Since the TGDs of $\dep$ have a non-empty frontier, in the dependency graph of $\simple{\dep}$ there exists a path 
	\[
	(P_1,k_1),\ldots,(P_m,k_m)
	\]
	with $P_1 = P$ and $(P_m,k_m) = (R_j,i_j)$. Summing up, in the dependency graph of $\simple{\dep}$, there exists a path of the form
	\begin{align*}
	& (P_1,k_1),\ldots,(P_{m-1},k_{m-1}),\\
	&\hspace{10mm}(R_j,i_j),\ldots,(R_{n-1},i_{n-1}),
	(R_1,i_1),\ldots,(R_{j-1},i_{j-1}),(R_j,i_j).
	\end{align*}
	Assume that this path is witnessed by the TGDs $\sigma_1,\ldots,\sigma_{n+m-2}$. By Lemma~\ref{lm:aux-dyn-simplification}, $\{P_1,\ldots,P_{m-1},R_1,\ldots,R_{n-1}\} \subseteq \dep(\shape{D})$. By the definition of dynamic simplification (see Definition~\ref{def:dyn-simplification}), we get that the TGDs $\sigma_1,\ldots,\sigma_{n+m-2}$ belong to $\dsimple{D}{\dep}$. Therefore, the above $\simple{D}$-supported cycle with a special edge also occurs in the dependency graph of $\dsimple{D}{\dep}$. Hence, by Theorem~\ref{the:characterization-simple-linear}, $\chase{\simple{D}}{\dsimple{D}{\dep}}$ is infinite, and the claim follows.
\end{proof}



Another crucial property of dynamic simplification, which will help us to further improve the performance of the termination algorithm for linear TGDs, is that the $\simple{D}$-weak-acyclicity of $\dsimple{D}{\dep}$ coincides with the weak-acyclicity of $\dsimple{D}{\dep}$. This holds since, by construction, all the predicates occurring in the TGDs of $\dsimple{D}{\dep}$ are reachable from a predicate occurring in $\simple{D}$, and thus, each cycle with a special edge in the dependency graph of $\dsimple{D}{\dep}$ is trivially $\simple{D}$-supported.
%
The above property immediately implies Lemma~\ref{lm:avoid-simplification} below since checking for the finiteness of $\chase{\simple{D}}{\dsimple{D}{\dep}}$, which is equivalent to the $\simple{D}$-weak-acyclicity of $\dsimple{D}{\dep}$ by Theorem~\ref{the:characterization-linear}, boils down to checking if $\dsimple{D}{\dep}$ is weakly-acyclic, without having to explicitly check for $\simple{D}$-supportedness, and thus, avoiding the expensive task of simplifying $D$. 


\begin{lemma}\label{lm:avoid-simplification}
	Consider a database $D$ and a set $\dep \in \class{L}$ of TGDs. The following are equivalent:
	\begin{enumerate}
	\item $\chase{\simple{D}}{\dsimple{D}{\dep}}$ is finite.
	\item $\dsimple{D}{\dep}$ is weakly-acyclic.
	\end{enumerate}
\end{lemma}







\begin{algorithm}[t]
	\KwIn{A database $D$ and a set $\dep \in \class{L}$ of TGDs}
	\KwOut{The $D$-simplification of $\dep$}
	
	\medskip
	
	$S \leftarrow \mathsf{FindShapes}(D)$;\label{ln:shapes}\\
	$\Sigma_s \leftarrow \emptyset$;\label{ln:empty}\\
	$\Delta S \leftarrow S$;\label{ln:delta}\\
	\While{$\Delta S\neq \emptyset$\label{ln:while}}{
		$\dep_{\mi{aux}} \leftarrow \mathsf{Applicable}(\Delta S,\Sigma)$;\label{ln:tgdsaux}\\
		$S_{\mi{aux}} \leftarrow \big\{R_{\id{}{\bar t}} \in \shape{\dep} \mid \text{ there exists a TGD } \sigma \in \dep_{\mi{aux}} \text{ such that } R_{\id{}{\bar t}} \text{ occurs in } \head{\sigma}\big\}$;\label{ln:shapesaux}\\
		$\Sigma_s \leftarrow \Sigma_s \cup \dep_{\mi{aux}}$;\label{ln:tgds}\\
		$\Delta S \leftarrow S_{\mi{aux}} \setminus S$;\label{ln:deltaS}\\
		$S \leftarrow S\cup \Delta S$\label{ln:S};
	}
	\KwRet{$\Sigma_s$;}\label{ln:returnD}
	\caption{$\mathsf{DynSimplification}$}\label{alg:dsimplify}
\end{algorithm}


\ignore{
\begin{algorithm}[t]
	\KwIn{A database $D$ and a set $\dep \in \class{L}$ of TGDs}
	\KwOut{The $D$-simplification of $\dep$}
	
	\medskip
	
	$S \leftarrow \mathsf{FindShapes}(D)$;\label{ln:shapes}\\
	$\Delta S \leftarrow S$;\label{ln:delta}\\
	$\Sigma' \leftarrow \emptyset$;\label{ln:empty}\\
	\While{$\Delta S\neq \emptyset$\label{ln:while}}{
		$\Sigma'\leftarrow \Sigma'\cup \mathsf{Applicable}(\Delta S,\Sigma)$;\label{ln:tgds}\\
		$\Delta S \leftarrow \Gamma_\Sigma(\Delta S) \setminus S$;\label{ln:deltaS}\\
		$S \leftarrow S\cup \Delta S$\label{ln:S};
	}
	\KwRet{$\Sigma'$;}\label{ln:returnD}
	\caption{$\mathsf{DynSimplification}$}\label{alg:dsimplify}
\end{algorithm}
}

\medskip
\noindent \textbf{An Algorithm for Dynamic Simplification.}
Dynamic simplification indeed allow us to filter out from the set obtained by statically simplifying a set of linear TGDs superfluous simple-linear TGDs by exploiting the given database. It remains, however, to provide a concrete algorithm that performs the dynamic simplification of a set of linear TGDs that is amenable to an efficient implementation. To this end, we proceed to present the algorithm $\mathsf{DynSimplification}$, depicted in Algorithm~\ref{alg:dsimplify}, that takes as input a database $D$ and a set $\dep$ of linear TGDs, and constructs the $D$-simplification of $\dep$.
%
The algorithm starts by finding the shapes of the atoms occurring in $D$, namely it computes the set $\shape{D}$ (line~\ref{ln:shapes}). It then initializes the set of simplified TGDs $\Sigma_s$ (line~\ref{ln:empty}) and the set of new shapes $\Delta S$ (line~\ref{ln:delta}).
%
Then, the algorithm iteratively generates simplified TGDs and collects the new shapes that are added to $\Delta S$,
%applies the immediate consequence operator $\Gamma_\Sigma$ to generate new shapes that are added to $\Delta S$, 
and continues this until a fixpoint is reached, i.e., $\Delta S =\emptyset$ (line~\ref{ln:while}). 
%
In particular, at each iteration, the algorithm computes simplified TGDs that are not superfluous, i.e., they can be applied during the construction of $\chase{\simple{D}}{\simple{\dep}}$, that are added to $\Sigma_s$ (lines~\ref{ln:tgdsaux} and~\ref{ln:tgds}). This is done via the procedure $\mathsf{Applicable}$, which takes as input a set of shapes $\hat{S}$ and a set of linear TGDs $\hat{\dep}$, and returns the set
\begin{multline*}
\big\{	\simple{R(f(\bar x))} \rightarrow \exists \bar z\, \simple{\psi(f(\bar y),\bar z)} \mid\\
R(\bar x) \ra \exists \bar z\, \psi(\bar y,\bar z) \in \hat{\dep} \text{ and } f \text{ is the $h$-specialization of } \bar x\\
\text{ for some homomorphism } h \text{ from } \{R(\bar x)\} \text{ to } \mi{DB}[\hat{S}]\big\}.
\end{multline*}
In essence, the procedure $\mathsf{Applicable}$ computes the set of TGDs of $\simple{\hat{\dep}}$ such that the predicate of their body belongs to $\hat{S}$.
%\[
%\left\{R_{\id{}{\bar t}}(\bar x) \ra \exists \bar z \, \psi(\bar y,\bar z) \in \simple{\hat{\dep}} \mid R_{\id{}{\bar t}} \in \hat{S}\right\}.
%\]
The algorithm also collects the newly generated shapes, that is, the predicates occurring in the head of the TGDs of $\mathsf{Applicable}(\Delta S,\dep)$, that are added to $\Delta S$ (lines~\ref{ln:shapesaux} and~\ref{ln:deltaS}).
\ignore{
While finding the new shapes, the algorithm also computes the simplified TGDs that are not superfluous, i.e., they can be applied during the construction of $\chase{\simple{D}}{\simple{\dep}}$, and are added to $\Sigma'$ (line~\ref{ln:tgds}). This is done via the procedure $\mathsf{Applicable}$, which takes as input a set of shapes $\hat{S}$ and a set of linear TGDs $\hat{\dep}$, and returns the set
\[
\left\{R_{\id{}{\bar t}}(\bar x) \ra \exists \bar z \, \psi(\bar y,\bar z) \in \simple{\hat{\dep}} \mid R_{\id{}{\bar t}} \in \hat{S}\right\}.
\]
}
Note that at each iteration, the algorithm applies the TGDs on $\Delta S$, not on $S$, with the exception of the first iteration where $S = \Delta S$. This works because there are no new applicable TGDs on $S$ after the first iteration since the TGDs are linear (only one body-atom) and all the applicable TGDs on $S$ are applied during the first iteration.
%
The implementation details of \textsf{FindShapes} and \textsf{Applicable} are discussed in Sections~\ref{sec:bgarph} and \ref{sec:scc}, respectively.
%
$\mathsf{DynSimplification}$ is correct by construction:


\begin{lemma}\label{lm:dyn-simplification-algorithm}
	Consider a database $D$ and a set $\dep \in \class{L}$ of TGDs. It holds that $\mathsf{DynSimplification}(D,\dep) = \dsimple{D}{\dep}$.
\end{lemma}



\begin{algorithm}[t]
	\KwIn{A database $D$ and a set $\dep \in \class{L}$ of TGDs}
	\KwOut{\true if $\chase{D}{\dep}$ is finite and \false otherwise}
	
	\medskip
	
	$\dep_s \leftarrow \mathsf{DynSimplification}(D,\Sigma)$;\label{ln:d-simplify}\\
	$G \leftarrow \textsf{BuildDepGraph}(\dep_s)$;\\	\lIf{$\mathsf{FindSpecialSCC}(G) \neq \emptyset$}{\KwRet{\false}}
	\KwRet{\true}
	%\KwRet{$\mathsf{IsChaseFinite[SL]}(\simple{D},\dep_s)$}\label{ln:return-3}
	\caption{$\mathsf{IsChaseFinite[L]}$}\label{alg:dterm}
\end{algorithm}


\medskip

\noindent
\textbf{Termination Algorithm.} Having in place 
%both $\mathsf{IsChaseFinite[SL]}$ and 
$\mathsf{DynSimplification}$, it is now straightforward to devise the algorithm $\mathsf{IsChaseFinite[L]}$, depicted in Algorithm~\ref{alg:dterm}, that checks for the finiteness of the chase in the case of linear TGDs.
%
The correctness of $\mathsf{DynSimplification}$, Theorem~\ref{the:characterization-linear}, Lemma~\ref{lm:dyn-simplification}, and Lemma~\ref{lm:avoid-simplification}, imply the correctness of the algorithm $\mathsf{IsChaseFinite[L]}$, and the next lemma follows:


\begin{lemma}\label{lm:linear} Given a database $D$ and a set $\dep \in \class{L}$ of TGDs, it holds that $\mathsf{IsChaseFinite[L]}(D,\dep) = \true$ iff $\chase{D}{\dep}$ is finite.
\end{lemma}