% Notes: 1- moving the discussion about using the tools to the scenarios. 2- clarifying the predicates are decided for an entire set of tgds, 3- the predicates in each set of tgds are selected from a pool of predicates (the pool is input to the rule generator), 4- Explain the rate of existential rules as a tuning parameter, not a fixed rate, 5- A scenario: <profile (a subset of ontologies in the pool),5 dbs>, time and shapes, 



% 6- Experimental Setting (short intro)
% 6.1- Data generator
% 6.2- Rule generator
% 6.3- Datasets (database and the ontology pool)
% 6.4- Experimental Setup (hardware and software config)

% 7- Experimental Evaluation

%2022/10/4:
% Multi-head tgds do not change termination


\section{Experimental Infrastructure}\label{sec:setting}
%

Our goal is to experimentally evaluate the behaviour of the termination algorithms presented in Section~\ref{sec:implementation} with the aim of clarifying whether they can be applied in a practical context, and if not, reveal their limitations. To this end, we are going to conduct extensive experiments with synthetic data and sets of TGDs. Therefore, we need a way to generate databases and sets of TGDs that are suitable for such an experimental evaluation. We proceed to discuss our tools for generating data (Section~\ref{sec:synth-data}) and sets of TGDs (Section~\ref{sec:synth-rule}). 
%
Let us clarify that in the rest of the paper, whenever we say that we randomly select an element from a certain space of elements, we actually mean that we select such an element uniformly at random.
%
%Finally, in Section~\ref{sec:ex-setting}, we give details about the experimental setup.




%\subsection{Data Generator and Rule Generator}\label{sec:generators}

\subsection{Data Generator}\label{sec:synth-data}

%We implement a data generator and a rule generator to generate synthetic ontologies, including sets of synthetic tgds and a synthetic database, that we use for stress-testing the algorithms in Sections~\ref{sec:alg} and \ref{sec:implementation}.


There are freely available data generators such as TPC-H\footnote{\href{https://www.tpc.org/tpch/}{https://www.tpc.org/tpch/}} and DataFiller\footnote{\href{https://github.com/memsql/datafiller}{https://github.com/memsql/datafiller}}. However, none of the existing tools is suitable for our purposes. To effectively evaluate the dynamic simplification procedure presented above, which is a key component of the termination algorithm for linear TGDs, we need to make sure that the generated database contains a variety of shapes. This is precisely the limitation of the existing data generators as they do not allow us to control the shape of the generated atoms. Hence, we had to implement our own data generator that overcomes the above limitation.




Our data generator has tuning parameters that allow us to determine key properties of the generated database $D$: the number of predicates in $D$, the minimum and maximum arity of those predicate, the size of the database domain (i.e., the number of values in $\adom{D}$), and the number of tuples in each relation of $D$.
%
In particular, the generator takes as input a tuple of integer values for the tuning parameters $(\mi{preds},\mi{min},\mi{max},\mi{dsize},\mi{rsize})$, and constructs a database $D$ such that, with $\ins{S} = \{R \mid R(\bar c) \in D\}$, $|\ins{S}| = \mi{preds}$, the predicates of $\ins{S}$ have arity between $\mi{min}$ and $\mi{max}$, $|\adom{D}| = \mi{dsize}$, and, for each $R \in \ins{S}$, $|\{\bar c \mid R(\bar c) \in D\}| = \mi{rsize}$.
%
To this end, it first generates a set $\ins{S}$ consisting of $\mi{preds}$ different predicates, and it randomly selects an arity for each such predicate from the range $[\mi{min},\mi{max}]$. It then generates a database by adding $\mi{rsize}$ tuples to each predicate of $\ins{S}$ that are formed using $\mi{dsize}$ different constant values. Now, to ensure that the obtained database contains different shapes, each tuple is generated by randomly selecting a shape and filling the positions by randomly picking values from the database domain of size $\mi{dsize}$ without repetition, that is, a shape determines how many times the same value is repeated in a tuple.




%Our data generator has tuning parameters that allow us to specify key properties of the underlying schema, that is, the number of predicates and the minimum/maximum arity of those predicate. We can also specify the size of the database domain and the number of tuples in each relation. Finally, to ensure that the generated database contains different shapes, each tuple is generated by randomly selecting a shape and filling the positions by randomly picking values from the database domain without repetition, that is, a shape determines how many times the same value appears in a tuple.
%
%Let us clarify that throughout the section, whenever we say that we randomly select an element from a certain space of elements, we mean that we select such an element uniformly at random.


\subsection{TGD Generator}\label{sec:synth-rule}
%

As for the data generator, existing TGD generators (see, for example,~\cite{arocena2015ibench,benedikt2017benchmarking}) are not suitable for our purposes since they do not allow us to control the shape of the atoms occurring in the bodies of the generated TGDs, which is crucial for generating sets of TGDs that are suitable for our experiments. Thus, we had to implement our own TGD generator that supports this key feature.


Our TGD generator has tuning parameters that allows us to determine key properties of the generated set $\dep$ of TGDs: the size of the schema (that is, the size of $\sch{\dep}$), the minimum and maximum arity of the predicates of $\sch{\dep}$, the number of TGDs in $\dep$, and the underlying class of $\dep$ (that is, whether $\dep$ is a set of simple-linear or just linear TGDs). 
%
In particular, the TGD generator takes as input a set $\ins{S}$ of predicates and a tuple of values for the tuning parameters $(\mi{ssize},\mi{min},\mi{max},\mi{tsize},\mi{tclass})$, and constructs a set $\dep$ of TGDs such that $\sch{\dep} \subseteq \ins{S}$, $|\sch{\dep}| = \mi{ssize}$, the predicates of $\sch{\dep}$ have arity between $\mi{min}$ and $\mi{max}$, $|\dep| = \mi{tsize}$, and $\dep$ falls in the class $\mi{tclass}$.
%
To this end, it first chooses a subset $\ins{S}'$ of $\ins{S}$ such that $|\ins{S}'| = \mi{ssize}$ and its predicates have arity between $\mi{min}$ and $\mi{max}$, and then generates the desired set of simple-linear or linear TGDs using all the predicates of $\ins{S}'$; the actual generation is described below.


Let us stress that in our experiments we consider only single-head TGDs, that is, TGDs with only one head-atom, despite the fact that our termination algorithms work with multi-head TGDs, that is, TGDs that have several atoms in their heads.
%
This is because the number of atoms occurring in the head of a TGD is typically negligible compared to the number of TGDs, and having several atoms in the heads of TGDs does not affect the number of shapes occurring in the database.
%
As we shall see in Sections~\ref{sec:slinear-ex} and~\ref{sec:linear-ex}, the number of TGDs and the number of database shapes are the main parameters impacting the runtime of the algorithms, and thus, our experimental evaluation provides conclusive results even if we consider single-head TGDs. Hence, for clarity, our TGD generator described below is designed to generate single-head TGDs.

% The pool has relation schemas with different syntactic properties to satisfy the parameters

%Why do we use our own rule generator?  Controlling the shape of a rule's body [cite iwarded (does not tune the shapes), other tools for weakly acyclic -> benchmark the chase (the goal is to generate deep tgds)]

\medskip
\noindent \underline{\textbf{Simple-Linear TGDs}}
\smallskip

\noindent To generate a simple-linear TGD, the generator randomly selects two predicates from $\ins{S}'$ that will be used for forming the body- and the head-atom, respectively. The random selection is with repetition to allow the same predicate to appear in both the body and the head of the TGD. Since we target a simple-linear TGD, we use different variables to fill the positions in the body-atom. Now, for the head-atom, we fill each position with either an existentially quantified variable, or a universally quantified variable that has been already used in the body-atom. In particular, for each position $\pi$ of the head-atom, the generator classifies $\pi$ as an existential position with probability $10\%$. In this case, $\pi$ is filled with a fresh variable that does not appear in the body-atom; otherwise, it is filled with a randomly selected variable from the body-atom.

\medskip
\noindent \underline{\textbf{Linear TGDs}}
\smallskip

\noindent Generating linear TGDs is done in the same way as for simple-linear TGDs with the crucial difference that, after randomly selecting the predicates of the body- and the head-atom, the generator randomly chooses a shape for the body-atom and then applies similar steps as for simple-linear TGDs to fill the positions of the body- and the head-atom. Note that the selection of the body-variables is guided by the chosen shape, which in turn allows for the repetition of variables in the body-atom of the generated linear TGD.

\medskip

We are now ready to proceed with our experimental evaluation. Note that for the experiments we used a server with an Intel Core i5 3.00GHz CPU and 16GB RAM, all the databases in our experiments are stored in a PostgreSQL 11.5 instance, and the termination algorithms in question have been implemented in Java SE 11. 




%In the rule generator and our experiments, we only use tgds with a single atom in their head, despite that our algorithms in Section~\ref{sec:alg} work with both single- and multi-head tgds. We do not consider multi-head tgds in the experiments because having multiple atoms in the tgd heads does not change the number of tgds and the number of shapes in the extensional database as the main parameters impacting the runtime of the chase algorithms as discussed in Sections~\ref{sec:slinear-ex} and~\ref{sec:linear-ex}.

%\subsection{Experimental Scenarios}\label{sec:scenarios}

% Explain ($0.1$ in the scenarios in Section~\ref{sec:scenarios})

 

%\subsection{Experimental Setup} \label{sec:ex-setting}

%We implemented our algorithms in Java SE 11 and used PostgreSQL 11.5 for managing the extensional databases in our experiments. We run the experiments on a server with an Intel Core i5 3.00GHz CPU and 16 GBs of RAM. 

