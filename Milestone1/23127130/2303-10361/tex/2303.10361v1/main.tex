%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,9pt]{acmart}
% \documentclass[sigconf]{acmart}
% \documentclass{sig-alternate-10pt}
% \settopmatter{authorsperrow=4}
% \settopmatter{printacmref=false}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.

\acmYear{2023}\copyrightyear{2023}
\setcopyright{acmlicensed}
\acmConference{Arxiv}
\acmBooktitle{Preprint}
% \acmPrice{}
% \acmDOI{10.1145/nnnnnnn.nnnnnnn}

\renewcommand\footnotetextcopyrightpermission[1]{}
\settopmatter{printacmref=false} %remove ACM reference format


%%
%% These commands are for a JOURNAL article.
% \acmJournal{POMACS}
% \acmVolume{37}
% \acmNumber{4}
% \acmArticle{111}
% \acmMonth{8}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.


\usepackage{enumitem}
\usepackage{booktabs,siunitx}
\usepackage{caption}
%\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{ulem}
%\usepackage{algpseudocode}
\usepackage[noend]{algpseudocode}
\usepackage{makecell}

\usepackage{multicol}
\usepackage{multirow}
\usepackage{subfigure}
\usepackage{bbding}

%% algorithms
% \usepackage{algorithm}
% \usepackage{algorithmic}
% \usepackage{xpatch}
% \makeatletter
% \xpatchcmd{\algorithmic}% <cmd>
%   {\newcommand{\State}{\ALC@it}}% <search>
%   {\newcommand{\State}{\@ifstar\STATEstar\STATEnostar}}% <replace>
%   {}{}% <success><failure>
% \newcommand{\Statestar}{\item[]}
% \newcommand{\Statenostar}{\ALC@it}

\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.

\title{DC-CCL: Device-Cloud Collaborative Controlled Learning for Large Vision Models}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{Yucheng Ding}
\email{yc.ding@sjtu.edu.cn}
\affiliation{%
  \institution{Shanghai Jiao Tong University}
  \country{China}
}

\author{Chaoyue Niu}
\email{rvince@sjtu.edu.cn}
\affiliation{%
  \institution{Shanghai Jiao Tong University}
  \country{China}
}

\author{Fan Wu}
\email{wu-fan@sjtu.edu.cn}
\affiliation{%
  \institution{Shanghai Jiao Tong University}
  \country{China}
}

\author{Shaojie Tang}
\email{shaojie.tang@utdallas.edu}
\affiliation{%
  \institution{University of Texas at Dallas}
  \country{USA}
}

\author{Chengfei Lyu}
\email{chengfei.lcf@alibaba-inc.com}
\affiliation{%
  \institution{Alibaba Group}
  \country{China}
}

\author{Guihai Chen}
\email{gchen@cs.sjtu.edu.cn}
\affiliation{%
  \institution{Shanghai Jiao Tong University}
  \country{China}
}



\begin{abstract}
Many large vision models have been deployed on the cloud for real-time services. Meanwhile, fresh samples are continuously generated on the served mobile device. How to leverage the device-side samples to improve the cloud-side large model becomes a practical requirement, but falls into the dilemma of no raw sample up-link and no large model down-link. Specifically, the user may opt out of sharing raw samples with the cloud due to the concern of privacy or communication overhead, while the size of some large vision models far exceeds the mobile device's runtime capacity. In this work, we propose a device-cloud collaborative controlled learning framework, called DC-CCL, enabling a cloud-side large vision model that cannot be directly deployed on the mobile device to still benefit from the device-side local samples. In particular, DC-CCL vertically splits the base model into two submodels, one large submodel for learning from the cloud-side samples and the other small submodel for learning from the device-side samples and performing device-cloud knowledge fusion. Nevertheless, on-device training of the small submodel requires the output of the cloud-side large submodel to compute the desired gradients. DC-CCL thus introduces a light-weight model to mimic the large cloud-side submodel with knowledge distillation, which can be offloaded to the mobile device to control its small submodel's optimization direction. Given the decoupling nature of two submodels in collaborative learning, DC-CCL also allows the cloud to take a pre-trained model and the mobile device to take another model with a different backbone architecture. We extensively evaluate DC-CCL over 5 public datasets and 6 common models, demonstrating its effectiveness and efficiency in approaching the performance of ideally leveraging the large model, as well as its remarkable advantage over the baseline of exploiting only the cloud-side samples or adopting only a device-affordable small model.

\end{abstract}
\keywords{device-cloud collaborative learning, mobile computer vision applications, large vision models, vertical model decoupling}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\input{01Introduction}
\input{02Background}
\input{03-1Principle}
\input{03-2Framework}
\input{04Evaluation}
\input{05RelatedWork}
\input{06Conclusion}
\input{07Appendix}

\clearpage
\bibliographystyle{ACM-Reference-Format}
\bibliography{dc-ccl-ref}

\end{document}
\endinput
%%
%% End of file `sample-acmlarge.tex'.
