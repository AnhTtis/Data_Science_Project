\yellow{\section{Results \& Analysis}}\label{sec:results}\label{commentR1C2b}






\begin{figure*}[t!]
\centering
\includegraphics[]{graphs/legend1-cropped.pdf}\\
\includegraphics[]{graphs/ca_mlp_c_ArAc.pdf}
\includegraphics[]{graphs/ca_mlp_r_ArAc.pdf}
\includegraphics[]{graphs/ca_svm_c_ArAc.pdf}
\includegraphics[]{graphs/ca_svm_r_ArAc.pdf}\\
\includegraphics[]{graphs/rw_mlp_c_ArAc.pdf}
\includegraphics[]{graphs/rw_mlp_r_ArAc.pdf}
\includegraphics[]{graphs/rw_svm_c_ArAc.pdf}
\includegraphics[]{graphs/rw_svm_r_ArAc.pdf}\\
\includegraphics[]{graphs/ww_mlp_c_ArAc.pdf}
\includegraphics[]{graphs/ww_mlp_r_ArAc.pdf}
\includegraphics[]{graphs/ww_svm_c_ArAc.pdf}
\includegraphics[]{graphs/ww_svm_r_ArAc.pdf}\\
\includegraphics[]{graphs/se_mlp_c_ArAc.pdf}
\includegraphics[]{graphs/se_mlp_r_ArAc.pdf}
\includegraphics[]{graphs/se_svm_c_ArAc.pdf}
\includegraphics[]{graphs/se_svm_r_ArAc.pdf}\\
\includegraphics[]{graphs/bs_mlp_c_ArAc.pdf}
\includegraphics[]{graphs/bs_mlp_r_ArAc.pdf}
\includegraphics[]{graphs/bs_svm_c_ArAc.pdf}
\includegraphics[]{graphs/bs_svm_r_ArAc.pdf}\\
\includegraphics[]{graphs/v3_mlp_c_ArAc.pdf}
\includegraphics[]{graphs/v3_mlp_r_ArAc.pdf}
\includegraphics[]{graphs/v3_svm_c_ArAc.pdf}
\includegraphics[]{graphs/v3_svm_r_ArAc.pdf}\\
\caption{Accuracy vs normalized area Pareto space. ML models examined: MLP-C, MLP-R, SVM-C, SVM-R for Cardio (a-d), RedWine (e-h), WhiteWine (i-l), Seeds (m-p), Balance Scale (q-t), Verterbal Column 3C (u-x), respectively.
}
\label{fig:dse}
\end{figure*}

\begin{figure*}[t!]
\centering
\includegraphics[]{graphs/legend_fig8.pdf}\\
\includegraphics[]{graphs/ca_mlp_c_PwAc.pdf}
\includegraphics[]{graphs/ca_mlp_r_PwAc.pdf}
\includegraphics[]{graphs/ca_svm_c_PwAc.pdf}
\includegraphics[]{graphs/ca_svm_r_PwAc.pdf}\\
\includegraphics[]{graphs/rw_mlp_c_PwAc.pdf}
\includegraphics[]{graphs/rw_mlp_r_PwAc.pdf}
\includegraphics[]{graphs/rw_svm_c_PwAc.pdf}
\includegraphics[]{graphs/rw_svm_r_PwAc.pdf}\\
\includegraphics[]{graphs/ww_mlp_c_PwAc.pdf}
\includegraphics[]{graphs/ww_mlp_r_PwAc.pdf}
\includegraphics[]{graphs/ww_svm_c_PwAc.pdf}
\includegraphics[]{graphs/ww_svm_r_PwAc.pdf}\\
\includegraphics[]{graphs/se_mlp_c_PwAc.pdf}
\includegraphics[]{graphs/se_mlp_r_PwAc.pdf}
\includegraphics[]{graphs/se_svm_c_PwAc.pdf}
\includegraphics[]{graphs/se_svm_r_PwAc.pdf}\\
\includegraphics[]{graphs/bs_mlp_c_PwAc.pdf}
\includegraphics[]{graphs/bs_mlp_r_PwAc.pdf}
\includegraphics[]{graphs/bs_svm_c_PwAc.pdf}
\includegraphics[]{graphs/bs_svm_r_PwAc.pdf}\\
\includegraphics[]{graphs/v3_mlp_c_PwAc.pdf}
\includegraphics[]{graphs/v3_mlp_r_PwAc.pdf}
\includegraphics[]{graphs/v3_svm_c_PwAc.pdf}
\includegraphics[]{graphs/v3_svm_r_PwAc.pdf}\\
\caption{Accuracy vs Normalized Power Pareto fronts for all evaluated techniques. ML models examined: MLP-C, MLP-R, SVM-C, SVM-R for Cardio (a-d), RedWine (e-h), WhiteWine (i-l), Seeds (m-p), Balance Scale (q-t), Vertebral Column 3C (u-x), respectively.
}
\label{fig:power}
\end{figure*}



This section an extensive evaluation of our work using the 24 ML classifiers presented in Table~\ref{tab:baselines}. 
First, we investigate and highlight the impact of approximate computing and specifically of our proposed cross-layer approximation in the design of printed ML classifiers.
Then, we evaluate our framework under varying battery constraints.
%we evaluate the efficiency of our proposed framework in reducing the area and power complexity and we investigate the impact of approximate computing on printed ML circuits.

Fig.~\ref{fig:dse} presents the Accuracy-Area Pareto space for all the printed ML circuits examined (see Table~\ref{tab:baselines}).
% Since area gains originate only from the coefficient approximation and netlist pruning, VOS impact is not depicted in this analysis.
% Area is reported as a normalized value w.r.t. the area of the respective baseline bespoke circuit. Identical results are obtained for the power consumption.
% Due to space limitations, we present the area reduction since it is our primary optimization goal in printed circuits.
In Fig.~\ref{fig:dse}, the black squares represent the baseline bespoke designs.
The red star is the design that applies only our proposed coefficient approximation.
The green dots are the designs that apply both Coefficient Approximation \& Pruning (``CoA\&Pr'').
In addition, Fig.~\ref{fig:dse} also presents in gray `x' the designs that use Only Pruning (``Only Pr'').
Only Pruning approximate circuits apply our pruning method directly on the baseline circuit and not on the coefficient approximated ones.
% In other words, the green dots are pruned derivatives of the red start while the gray `x' are pruned derivatives of the black square.
To obtain the Coefficient Approximation \& Pruning and the Only Pruning circuits, we performed a full-search design exploration.
Note that the number of the explored designs is circuit dependent.
As aforementioned, our pruning framework uses $80$\% $\leq \tau_c \leq$ $99$\% for all circuits but the explored $\phi_c$ values are circuit and $\tau_c$ dependent.
In total, to generate Fig.~\ref{fig:dse}, we evaluated more than $6000$ designs.

Overall, it is observed that approximate computing can effectively be employed to decrease the area complexity of the printed ML circuits since all the approximate designs feature lower area than the corresponding exact one (i.e., black square).
For example, for most circuits, more than $51$\% area reduction can be achieved for less than $5$\% accuracy loss.
\yellow{As shown in Fig.~\ref{fig:dse}, our coefficient approximation, by algorithmically balancing the positive and negative errors,
delivers\label{commentR2C2a} $22$\% average area reduction for almost identical accuracy with the exact baseline for all the examined circuits.}
In most cases it outperforms significantly the standalone gate-level pruning approximation.
% Note that the aforementioned area reduction is slightly decreased from our preliminary work~\cite{DATE22:Armen}, since three new datasets have now been included and due to high ``sensitivity'' of 2 models, we had to decrease the neighbouring threshold $e$ of our CoA approximation from 4 to 3 (see Section~\ref{sec:coa}). 
In addition, designs generated using Coefficient Approximation \& Pruning (green dots) constitute mainly the area-optimal designs since they mainly form the Pareto front in all the sub-figures of Fig.~\ref{fig:dse}.
\yellow{It is also noteworthy that overall regressors are  more resilient to pruning than the respective classifiers.
The latter is explained by the $\phi$ parameter.
In the case of regressors a small $\phi$ results in some error in the least significant decimal digits that mainly have minimal impact on the selected class.
On the other hand, in classifiers even a smaller $\phi$ may break an inequality and, thus, directly lead to erroneous classification.
}\label{commentR2C2}

\input{table_results}

Fig.~\ref{fig:power} assesses the Accuracy-Power trade-off of the approximate printed ML classifiers.
As a result, VOS is considered in Fig.~\ref{fig:power}.
%shows the complete design space in terms of normalized power reduction of our approximate designs, including this time our circuit-level approximation of VOS.
% The black squares are the baseline bespoke circuits.
Green dots and gray ``x'' represent now only the respective Pareto-optimal designs, while the golden squares form the Pareto-front design when considering our holistic model-to-circuit cross-approximation that comprises coefficient approximation, netlist pruning, and VOS (Ours).
Finally, blue ``tri down'' points are the voltage over-scaled circuits derived from the exact design.
%Blue dots are the Pareto fronts of CoA\&Pr and Only Pr approximations (cyan 'tri\_down'), while golden squares constitute the optimal designs derived from our framework (i.e., Cross-approximation).
%For better visualisation, non-optimal (\emph{dominated}) solutions of our Cross approximation are not depicted in Fig.~\ref{fig:power} and we instead present only the \emph{non-dominated} ones.
Each Pareto front is obtained through an exhaustive design space exploration, i.e., we evaluated the accuracy and power consumption of all the circuits of Fig.~\ref{fig:dse} for all the voltage values considered (i.e., $\forall V_{dd} \in [0.6V, 1.0V]$, with a $20mV$ step). As shown in Fig.~\ref{fig:power}, the power savings of the approximate circuits that don't apply VOS (gray ``x''), follow a similar trend as the area gains in Fig.~\ref{fig:dse}.
As demonstrated by the full-search exploration of Fig.~\ref{fig:power}, our cross-approximation delivers the optimal results in terms of accuracy-power trade-off. 
Our approximate circuits feature $56\%$ power reduction for almost identical accuracy ($<0.01$) with the baseline circuits.
\yellow{Note also that VOS mainly affects the MSBs and, thus, when VOS errors occur they are high in magnitude~\cite{vosim:zervakis}, leading to poor prediction for regressors. 
On the other hand, in classifiers correct classification may be still obtained due to the argmax function that breaks the relation between numerical and classification accuracy and may potentially absorb the impact of such large errors.}\label{commentR2C2b}
%our Cross approximation, which includes approximate designs at different voltage operation, boosts the power savings of all approximate circuits and achieves on average $56\%$ power reduction, for almost identical accuracy with our baseline models.
%For a wider accuracy loss threshold, i.e. 2\% and 5\%, this power reduction increases up to 60\% and 66\% on average, respectively.

\input{table_batteries}

Table~\ref{tab:threshold}, considers a conservative accuracy loss threshold (i.e., only $1$\%) and 
% summarizes the findings of Fig.~\ref{fig:dse} and~\ref{fig:power}. Specifically, Table~\ref{tab:threshold} 
reports the area and power gains of the area-power-optimal circuits for each approximation technique.
As shown, compared to the baseline bespoke~\cite{Mubarik:MICRO:2020:printedml} implementations, Coa\&Pr delivers on average $38\%$ and $34\%$ area and power reduction, respectively.
The corresponding values of CoA only are $22\%$ and $20\%$.
Ony pruning approximation achieves only $17\%$ and $16\%$ average area and power reduction, respectively.
% The presented gains of our Cross approximation (i.e., CoA+Pr+VOS) corresponds to $>70\%$ optimality (see Eq.~\eqref{eq:opt}), so that the total execution of our framework requires a reasonable small amount of time (i.e., less than 2.5h on average) to find near-optimal solutions.
% Indicatively, most of the examined models in Table~\ref{tab:threshold} derived from our proposed methodology presents same area gains with our Coefficient Approximation \& Pruning (minimum possible area), while power gains are always higher and specifically $17\%$ more, on average.
On the other hand, our framework features $38\%$ area and $56\%$ power reduction.
It is noteworthy that the delay gain due to logic and algorithmic approximation (coefficient approximation and netlist pruning) enables operating the approximate circuits down to $0.74V$ (on average) while still satisfying tight accuracy loss constraints (i.e., $1$\%).
Hence, compared to Coa\&Pr~\cite{DATE22:Armen}, our cross approximation delivers an additional $22\%$ power reduction and same area savings. 
%It is also noteworthy that these gains are provided at $0.76V$ voltage operation on average, which emphasize the impact of our circuit-level approximation, as well.



%Finally, we also evaluate our genetic algorithm by enabling this time power $P$ and accuracy $T$ constraints that help pruning the whole space and speeding up the exploration (see Section~\ref{sec:dse}).
Next, we evaluate our framework in generating battery-constrained approximate printed ML classifiers of high accuracy.
%Since printed applications often target batteries with specific maximum output power, we perform three evaluations targeting power lower than 30mW, 15mW and 6mW (Molex, Zinergy and Blue Spark batteries, respectively) with an accuracy loss up to 15\%.
%Note, that if more than one circuits satisfy these constraints, the design with the highest accuracy is selected.
For this evaluation we consider three different printed batteries: Molex 30mW, Zinergy 15mW, and Blue Spark 6mW.
In addition, we search for solutions with up to 15\% accuracy loss.
Table~\ref{tab:batteries} presents the accuracy loss and area reduction of the cross-approximate circuits generated by our framework.
The corresponding values are calculated over the respective baseline circuits.
%The obtained approximate printed circuits with their accuracy loss and area reduction compared to their baseline models are presented in Table~\ref{tab:batteries}.
Approximate circuits of very high accuracy (accuracy loss $\leq1\%$ ) are highlighted in green.
%Overall, the proposed framework that applies our model-to-circuit cross-layer approximation enables 19/24 battery powered printed ML classifiers with almost identical accuracy with baseline models~\cite{Mubarik:MICRO:2020:printedml}.
For the Molex battery our framework generated approximate circuits with less than 15\% accuracy loss for all the examined models.
Specifically, 19 out of the 24 circuits feature negligible accuracy loss ($\leq1\%$ ).
Similarly, for the Zinergy battery 23 out of the 24 ML circuits can be battery powered while 11 exhibit less than $1\%$ accuracy loss.
% Finally, even in the case of the small Blue Spark battery (only 6mW) 7 out of the 24 circuits can be battery powered.
Our framework enables battery operation of complex printed ML circuits, while the state-of-the-art only simple ML models~\cite{Mubarik:MICRO:2020:printedml,DATE22:Armen}.
In~\cite{Mubarik:MICRO:2020:printedml} only Decision Trees and SVM-Rs are used, while for example considering the Zinergy battery,~\cite{DATE22:Armen} supports only MLP-Rs with up to 24 coefficients.
On the other hand, our framework can power MLP-Rs with 48 coefficients as well as MLP-Cs.
%For the first time, high-quality MLPs can now be powered by a Zinergy battery of 15mW, while several printed SVMs can operate at a minimal power consumption of 6mW.
%Similarly, the significant gains in area can now enable the practical and realistic printed applications (see unattainable area of the exact designs in Table~\ref{tab:baselines}).
%However, the majority of examined circuits cannot reach the ultra-low power operation required by Blue Spark or smaller batteries. 
%\emph{This inadequacy highlights the need for more optimizations in order to realize even more complex models for ultra-resource constrained smart printed applications.}


% Finally, to put these gains into perspective, we highlight in Table~\ref{tab:threshold} the circuits that can now be powered by two commonly used printed batteries.
% % that even their exact bespoke baseline~\cite{Mubarik:MICRO:2020:printedml} were unable.
% Overall, our cross-layer approximation enables, for the first time, printed MLP-C with $3$ hidden nodes and $21$ coefficients in total, printed MLP-R with $4$ hidden nodes and $72$ coefficients, and SVM-C with $15$ classifiers and $66$ coefficients.
% Moreover, our cross-layer approximation enables 15/24 battery powered printed classifiers, while 8/24 can use a Zinergy $15mW$ battery.


% \input{table_exec}

% Power and area reduction of sub-optimal approximate circuits obtained in each epoch $n$ of our framework, normalized against optimal's ones. Evaluation is performed for RedWine dataset, targeting a Molex battery ($<~30$mW) with 1\% accuracy loss constraint. 


% Fig.~\ref{fig:exectime} shows this trade-off for a medium-complexity dataset, i.e., RedWine.
% It is observed that only 10 epochs are required on average to obtain circuits with more than 80\% of the area and power reduction achieved by optimal circuit (Cross).
% Thus, our framework enables a fine-granularity process termination that allows the user to select the desired optimality of the implemented circuit based on the different time-to-market application requirements.

Finally, Fig.~\ref{fig:exectime} evaluates the time complexity of our framework.
First, Fig.~\ref{fig:exectime}a shows the reduction of the design space of tentative solutions implemented in our framework (see Section~\ref{sec:dse}).
To generate Fig.~\ref{fig:exectime}a, the Zinergy 15mW battery is targeted and maximum 15\% accuracy loss is considered.
As shown, the $91\%$ on average of the design space of MLPs is pruned, while in SVMs the corresponding value becomes $48\%$.
As a result, when high design space pruning ratio is achieved, our genetic algorithm can cover most of the space and \yellow{converges promisingly to near-optimal solutions fast-enough (withing only a few epochs).}\label{commentR1C1b} 
It should be noted that, in case of SVM-Rs the design space reduction ranges from 7\% to 55\%.
This is attributed to the fact that the less complex models feature reduced power overheads and thus many cross-approximation solutions can satisfy the given battery constraint.
However, as we will explain later the evaluation of such solutions is very fast (due to the decreased circuit complexity) and thus, we can increase the number of epochs in our optimization without any significant execution time overhead.
Indicatively, the results of Table~\ref{tab:batteries} for the Zinergy 15mW battery are obtained with only 4 epochs for MLPs and 8 epochs for SVMs.
Fig.~\ref{fig:exectime}b presents the \yellow{the average execution time required for one epoch for each examined ML circuit, after repeating each experiment 100 times.
}
The aforementioned execution times refer to a dual-CPU Intel Xeon Gold 6138 server, using only $20$ threads since we are limited by the number of available EDA licenses.
As shown, the average execution time per epoch is only \yellow{$22$} minutes.
The execution time goes up to 57 minutes for several MLP-C that feature however a highly pruned design space.
On the other hand, the SVM-R, that attained low design space reduction, requires only \yellow{10} minutes on average.
\yellow{For some classifiers (e.g., V3 MLP-C and SVM-C) their execution time is lower than that of the respective regressors.
This is explained by the fact that these classifiers are more error resilient compared to the respective regressors and could endure more approximation for the same accuracy loss constraint.
In addition, the respective exact classifiers and regressors feature similar area complexity.
Hence, our genetic algorithm had to explore less complex designs during its optimization phase, leading to reduced simulation times.
}\label{commentR2C1}

\begin{figure}[t!]
\includegraphics[]{graphs/pruned_space_percent.pdf} \\
\includegraphics[]{graphs/time_per_epoch2.pdf}
\caption{
a) Percentage of pruned space achieved by our genetic algorithm's optimizations when evaluating each examined model with 15mW power and 15\% accuracy constraints (see Table~\ref{tab:batteries}).
\yellow{b) Average execution time for 1 epoch of our genetic algorithm for each examined model.}
}
\label{fig:exectime}
\end{figure}


% Since printed applications require on-demand and a point-of-use fabrication process, our genetic algorithm can provide sub-optimal solutions, but in far less epochs than required by full exploration.
% Indicatively, results of Table~\ref{tab:batteries} and Zinergy 15mW battery were obtained after only 4 epochs for MLPs and 8 epochs for SVMs, avoiding thus exploring the whole design space.
% Note that each epoch performs 20 VOS-aware simulations (i.e., size of population).
% Fig.~\ref{fig:exectime}a shows the percentage of the total design space that is pruned by our genetic algorithm's optimization, i.e., estimating and discarding designs that do not satisfy a power constraint (see Section~\ref{sec:dse}).
% When the algorithm targets complex ML circuits such as MLPs, the pruned space reaches as high as $91\%$ on average, while in simpler designs that satisfy effortless the defined constraints, the corresponding value becomes $48\%$.
% Finally, the execution time needed for each epoch of genetic algorithm is depicted in Fig.~\ref{fig:exectime}b.
% The aforementioned execution times refer to a dual-CPU Intel Xeon Gold 6138 server, using a limited number of total threads (i.e., $20$), that is the limit of available licenses.
% As shown, the average execution time per epoch is only $21$ minutes, while at the worst case several MLP-C required up to 57 minutes.
% Thus, our framework enables a fine-granularity process termination that allows the user to select different number of epochs, depending the various time-to-market application requirements and the desired output quality.

% Finally, in Table~\ref{tab:exectime} we utilized the design space exploration methodology when targeting only area optimization (i.e., Coefficient Approximation \& Pruning technique).
% % report the overall execution time of our framework.
% % As aforementioned due to the on-demand and point-of-use fabrication process, it is critical that the design time overhead due to approximation is kept to minimum.
% As shown in Table~\ref{tab:exectime}, the average execution time is only $8$min while its median value is $7$min.
% % At the worst case, our framework required only $48$min for the Pendigits MLP-C, that is however very large to be considered for a printed circuit.
% Note that the times in Table~\ref{tab:exectime} refer to the full design exploration, i.e., all the green dots in each subfigure of Fig.~\ref{fig:dse}.
% Due to the on-demand and point-of-use fabrication process, it is critical that the design time overhead due to approximation is kept to minimum.
% For this reason, when VOS approximation is included, our methodology due to the optimality parameter that terminates earlier the exploration, saves a huge amount of time compared to full VOS exploration, providing still high-quality approximate circuits.
% Fig.~\ref{fig:exectime} shows this trade-off for a medium-complexity examined dataset.
% As we can see, the overall execution time of our framework is less than $2.5h$ on average for $>70\%$ optimality, while this number almost doubles for only $20\%$ optimality increase.
% % As a result, the Pareto front is obtained and the user may select a Pareto-optimal point based on the requirements (e.g., area-accuracy) of the printed application.
% As a result, Pareto front is obtained and based on the requirements (e.g., area, power, accuracy) of the printed application and the available design time, the user may select a Pareto/near-Pareto optimal point.

