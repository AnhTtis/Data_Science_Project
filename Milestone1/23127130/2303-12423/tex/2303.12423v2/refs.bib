@String(PAMI  = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence})
@String(IJCV  = {International Journal of Computer Vision})
@String(CVPR  = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition})
@String(ICCV  = {{IEEE/CVF} International Conference on Computer Vision})
@String(ECCV  = {European Conference on Computer Vision})
@String(NIPS  = {Advances in Neural Information Processing Systems})
@String(ICPR  = {International Conference on Pattern Recognition})
@String(BMVC  =	{The British Machine Vision Conference})
@String(TOG   = {{ACM} Transactions on Graphics})
@String(TIP   = {{IEEE} Transactions on Image Processing})
@String(TVCG  = {{IEEE} Transactions on Visualization and Computer Graphics})
@String(TMM   =	{{IEEE} Transactions on Multimedia})
@String(ACMMM = {{ACM} International Conference on Multimedia})
@String(ICME  =	{{IEEE} International Conference on Multimedia & Expo})
@String(ICASSP=	{{IEEE} International Conference on Acoustics, Speech, and Signal Processing})
@String(ICIP  = {{IEEE} International Conference on Image Processing})
@String(ACCV  = {Asian Conference on Computer Vision})
@String(ICLR  = {International Conference on Learning Representations})
@String(IJCAI = {International Joint Conferences on Artificial Intelligence})
@String(PR = {Pattern Recognition})
@String(AAAI = {Association for the Advancement of Artificial Intelligence})
@String(CVPRW = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition Workshop})
@String(CSVT = {{IEEE} Transactions on Circuits and Systems for Video Technology})
@String(ACL = {Annual Meeting of the Association for Computational Linguistics})
@String(ICCL = {International Conference on Computational Linguistics})
@String(TACL = {Transactions of the Association for Computational Linguistics})
@String(CoNLL = {Conference on Computational Natural Language Learning})
@String(WACV = {{IEEE} Winter Conference on Applications of Computer Vision})
@String(ICML = {International Conference on Machine Learning})


@inproceedings{wlt,
  author    = {Tanzila Rahman and
               Bicheng Xu and
               Leonid Sigal},
  title     = {Watch, Listen and Tell: Multi-Modal Weakly Supervised Dense Event
               Captioning},
  booktitle = ICCV,
  pages     = {8907--8916},
  year      = {2019},
}
@article{HMN,
  author    = {Hanhua Ye and
               Guorong Li and
               Yuankai Qi and
               Shuhui Wang and
               Qingming Huang and
               Ming{-}Hsuan Yang},
  title     = {Hierarchical Modular Network for Video Captioning},
  booktitle = CVPR,
  pages = {17939--17948},
  year      = {2022},
}
@inproceedings{Actbert,
  author    = {Linchao Zhu and
               Yi Yang},
  title     = {ActBERT: Learning Global-Local Video-Text Representations},
  booktitle = CVPR,
  pages     = {8743--8752},
  year      = {2020},
}

@inproceedings{MVC,
  author    = {Paul Hongsuck Seo and
               Arsha Nagrani and
               Anurag Arnab and
               Cordelia Schmid},
  title     = {End-to-end Generative Pretraining for Multimodal Video Captioning},
  booktitle = CVPR,
  pages     = {17938--17947},
  year      = {2022}
}


@inproceedings{Mart,
  author    = {Jie Lei and
               Liwei Wang and
               Yelong Shen and
               Dong Yu and
               Tamara L. Berg and
               Mohit Bansal},
  title     = {{MART:} Memory-Augmented Recurrent Transformer for Coherent Video
               Paragraph Captioning},
  booktitle = ACL,
  pages     = {2603--2614},
  year      = {2020},
}

@article{univl,
  author    = {Huaishao Luo and
               Lei Ji and
               Botian Shi and
               Haoyang Huang and
               Nan Duan and
               Tianrui Li and
               Xilin Chen and
               Ming Zhou},
  title     = {UniViLM: {A} Unified Video and Language Pre-Training Model for Multimodal
               Understanding and Generation},
  journal   = {CoRR},
  volume    = {abs/2002.06353},
  year      = {2020}
}

@inproceedings{ERNIE,
  author    = {Zhengyan Zhang and
               Xu Han and
               Zhiyuan Liu and
               Xin Jiang and
               Maosong Sun and
               Qun Liu},
  title     = {{ERNIE:} Enhanced Language Representation with Informative Entities},
  booktitle = ACL,
  pages     = {1441--1451},
  year      = {2019},
}

@inproceedings{CoLake,
  author    = {Tianxiang Sun and
               Yunfan Shao and
               Xipeng Qiu and
               Qipeng Guo and
               Yaru Hu and
               Xuanjing Huang and
               Zheng Zhang},
  title     = {CoLAKE: Contextualized Language and Knowledge Embedding},
  booktitle = ICCL,
  pages     = {3660--3670},
  year      = {2020},
}


@article{KEPLER,
  author    = {Xiaozhi Wang and
               Tianyu Gao and
               Zhaocheng Zhu and
               Zhengyan Zhang and
               Zhiyuan Liu and
               Juanzi Li and
               Jian Tang},
  title     = {{KEPLER:} {A} Unified Model for Knowledge Embedding and Pre-trained
               Language Representation},
  journal   = TACL,
  volume    = {9},
  pages     = {176--194},
  year      = {2021}
}

@article{KELM,
  author    = {Yinquan Lu and
               Haonan Lu and
               Guirong Fu and
               Qun Liu},
  title     = {{KELM:} Knowledge Enhanced Pre-Trained Language Representations with
               Message Passing on Hierarchical Relational Graphs},
  journal   = {CoRR},
  volume    = {abs/2109.04223},
  year      = {2021}
}

@inproceedings{JAKET,
  author    = {Donghan Yu and
               Chenguang Zhu and
               Yiming Yang and
               Michael Zeng},
  title     = {{JAKET:} Joint Pre-training of Knowledge Graph and Language Understanding},
  booktitle = AAAI,
  pages     = {11630--11638},
  year      = {2022}
}

@inproceedings{MGRMP,
  author    = {Shaoxiang Chen and
               Yu{-}Gang Jiang},
  title     = {Motion Guided Region Message Passing for Video Captioning},
  booktitle = ICCV,
  pages     = {1523--1532},
  year      = {2021},
}

@inproceedings{SGN,
  author    = {Hobin Ryu and
               Sunghun Kang and
               Haeyong Kang and
               Chang D. Yoo},
  title     = {Semantic Grouping Network for Video Captioning},
  booktitle = AAAI,
  pages     = {2514--2522},
  year      = {2021},
}

@inproceedings{ORG-TRL,
  author    = {Ziqi Zhang and
               Yaya Shi and
               Chunfeng Yuan and
               Bing Li and
               Peijin Wang and
               Weiming Hu and
               Zheng{-}Jun Zha},
  title     = {Object Relational Graph With Teacher-Recommended Learning for Video
               Captioning},
  booktitle = CVPR,
  pages     = {13275--13285},
  year      = {2020},
}

@inproceedings{SAAT,
  author    = {Qi Zheng and
               Chaoyue Wang and
               Dacheng Tao},
  title     = {Syntax-Aware Action Targeting for Video Captioning},
  booktitle = CVPR,
  pages     = {13093--13102},
  year      = {2020},
}

@inproceedings{STG-KD,
  author    = {Boxiao Pan and
               Haoye Cai and
               De{-}An Huang and
               Kuan{-}Hui Lee and
               Adrien Gaidon and
               Ehsan Adeli and
               Juan Carlos Niebles},
  title     = {Spatio-Temporal Graph for Video Captioning With Knowledge Distillation},
  booktitle = CVPR,
  pages     = {10867--10876},
  year      = {2020},
}

@inproceedings{GRU-EVE,
  author    = {Nayyer Aafaq and
               Naveed Akhtar and
               Wei Liu and
               Syed Zulqarnain Gilani and
               Ajmal Mian},
  title     = {Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding
               for Video Captioning},
  booktitle = CVPR,
  pages     = {12487--12496},
  year      = {2019},
}

@inproceedings{MGSA,
  author    = {Shaoxiang Chen and
               Yu{-}Gang Jiang},
  title     = {Motion Guided Spatial Attention for Video Captioning},
  booktitle = AAAI,
  pages     = {8191--8198},
  year      = {2019},
}

@inproceedings{POS-CG,
  author    = {Bairui Wang and
               Lin Ma and
               Wei Zhang and
               Wenhao Jiang and
               Jingwen Wang and
               Wei Liu},
  title     = {Controllable Video Captioning With {POS} Sequence Guidance Based on
               Gated Fusion Network},
  booktitle = ICCV,
  pages     = {2641--2650},
  year      = {2019},
}

@inproceedings{OA-BTG,
  author    = {Junchao Zhang and
               Yuxin Peng},
  title     = {Object-Aware Aggregation With Bidirectional Temporal Graph for Video
               Captioning},
  booktitle = CVPR,
  pages     = {8327--8336},
  year      = {2019},
}

@inproceedings{MARN,
  author    = {Wenjie Pei and
               Jiyuan Zhang and
               Xiangrong Wang and
               Lei Ke and
               Xiaoyong Shen and
               Yu{-}Wing Tai},
  title     = {Memory-Attended Recurrent Network for Video Captioning},
  booktitle = CVPR,
  pages     = {8347--8356},
  year      = {2019},
}


@inproceedings{pickNet,
  author    = {Yangyu Chen and
               Shuhui Wang and
               Weigang Zhang and
               Qingming Huang},
  title     = {Less Is More: Picking Informative Frames for Video Captioning},
  booktitle = ECCV,
  pages     = {367--384},
  year      = {2018},
}

@inproceedings{RecNet,
  author    = {Bairui Wang and
               Lin Ma and
               Wei Zhang and
               Wei Liu},
  title     = {Reconstruction Network for Video Captioning},
  booktitle = CVPR,
  pages     = {7622--7631},
  year      = {2018},
}

@inproceedings{Transformer-XL,
  author    = {Zihang Dai and
               Zhilin Yang and
               Yiming Yang and
               Jaime G. Carbonell and
               Quoc Viet Le and
               Ruslan Salakhutdinov},
  title     = {Transformer-XL: Attentive Language Models beyond a Fixed-Length Context},
  booktitle = ACL,
  pages     = {2978--2988},
  year      = {2019},
}

@inproceedings{Transformer-XLRG,
  author    = {Jie Lei and
               Liwei Wang and
               Yelong Shen and
               Dong Yu and
               Tamara L. Berg and
               Mohit Bansal},
  title     = {{MART:} Memory-Augmented Recurrent Transformer for Coherent Video
               Paragraph Captioning},
  booktitle = ACL,
  pages     = {2603--2614},
  year      = {2020},
}

@inproceedings{MaskedTrans,
  author    = {Luowei Zhou and
               Yingbo Zhou and
               Jason J. Corso and
               Richard Socher and
               Caiming Xiong},
  title     = {End-to-End Dense Video Captioning With Masked Transformer},
  booktitle = CVPR,
  pages     = {8739--8748},
  year      = {2018},
}

@article{S3D,
  author    = {Saining Xie and
               Chen Sun and
               Jonathan Huang and
               Zhuowen Tu and
               Kevin Murphy},
  title     = {Rethinking Spatiotemporal Feature Learning For Video Understanding},
  journal   = {CoRR},
  volume    = {abs/1712.04851},
  year      = {2017}
}

@inproceedings{VideoBERT,
  author    = {Chen Sun and
               Austin Myers and
               Carl Vondrick and
               Kevin Murphy and
               Cordelia Schmid},
  title     = {VideoBERT: {A} Joint Model for Video and Language Representation Learning},
  booktitle = ICCV,
  pages     = {7463--7472},
  year      = {2019},
}

@article{VideoASMT,
  author    = {Bruno Korbar and
               Fabio Petroni and
               Rohit Girdhar and
               Lorenzo Torresani},
  title     = {Video Understanding as Machine Translation},
  journal   = {CoRR},
  volume    = {abs/2006.07203},
  year      = {2020}
}

@inproceedings{AT,
  author    = {Jack Hessel and
               Bo Pang and
               Zhenhai Zhu and
               Radu Soricut},
  title     = {A Case Study on Combining {ASR} and Visual Features for Generating
               Instructional Video Captions},
  booktitle = CoNLL,
  pages     = {419--429},
  year      = {2019},
}

@inproceedings{DPC,
  author    = {Botian Shi and
               Lei Ji and
               Yaobo Liang and
               Nan Duan and
               Peng Chen and
               Zhendong Niu and
               Ming Zhou},
  title     = {Dense Procedure Captioning in Narrated Instructional Videos},
  booktitle = ACL,
  pages     = {6382--6391},
  year      = {2019},
}

@inproceedings{DECEM,
  author    = {Zineng Tang and
               Jie Lei and
               Mohit Bansal},
  title     = {DeCEMBERT: Learning from Noisy Instructional Videos via Dense Captions
               and Entropy Minimization},
  booktitle = {Conference of the North American Chapter of
               the Association for Computational Linguistics},
  pages     = {2415--2426},
  year      = {2021},
}

@inproceedings{Swinbert,
  author    = {Kevin Lin and
               Linjie Li and
               Chung{-}Ching Lin and
               Faisal Ahmed and
               Zhe Gan and
               Zicheng Liu and
               Yumao Lu and
               Lijuan Wang},
  title     = {SwinBERT: End-to-End Transformers with Sparse Attention for Video
               Captioning},
  booktitle = CVPR,
  pages     = {17928--17937},
  year      = {2022}
}

@inproceedings{bad,
  author    = {Jingyi Hou and
               Xinxiao Wu and
               Xiaoxun Zhang and
               Yayun Qi and
               Yunde Jia and
               Jiebo Luo},
  title     = {Joint Commonsense and Relation Reasoning for Image and Video Captioning},
  booktitle = AAAI,
  pages     = {10973--10980},
  year      = {2020},
}

@inproceedings{image,
  author    = {Yimin Zhou and
               Yiwei Sun and
               Vasant G. Honavar},
  title     = {Improving Image Captioning by Leveraging Knowledge Graphs},
  booktitle = WACV,
  pages     = {283--293},
  year      = {2019},
}

@inproceedings{DBLP:conf/iccv/KrishnaHRFN17,
  author    = {Ranjay Krishna and
               Kenji Hata and
               Frederic Ren and
               Li Fei{-}Fei and
               Juan Carlos Niebles},
  title     = {Dense-Captioning Events in Videos},
  booktitle = ICCV,
  pages     = {706--715},
  year      = {2017}
}

@inproceedings{DBLP:conf/aaai/ZhouXC18,
  author    = {Luowei Zhou and
               Chenliang Xu and
               Jason J. Corso},
  title     = {Towards Automatic Learning of Procedures From Web Instructional Videos},
  booktitle = AAAI,
  pages     = {7590--7598},
  year      = {2018}
}

@inproceedings{DBLP:conf/iccv/MiechZATLS19,
  author    = {Antoine Miech and
               Dimitri Zhukov and
               Jean{-}Baptiste Alayrac and
               Makarand Tapaswi and
               Ivan Laptev and
               Josef Sivic},
  title     = {How{T}o100{M}: Learning a Text-Video Embedding by Watching Hundred Million
               Narrated Video Clips},
  booktitle = ICCV,
  pages     = {2630--2640},
  year      = {2019}
}

@inproceedings{DBLP:conf/cvpr/XuMYR16,
  author    = {Jun Xu and
               Tao Mei and
               Ting Yao and
               Yong Rui},
  title     = {{MSR-VTT:} {A} Large Video Description Dataset for Bridging Video
               and Language},
  booktitle = CVPR,
  pages     = {5288--5296},
  year      = {2016}
}

@inproceedings{VLM,
  author    = {Hu Xu and
               Gargi Ghosh and
               Po{-}Yao Huang and
               Prahal Arora and
               Masoumeh Aminzadeh and
               Christoph Feichtenhofer and
               Florian Metze and
               Luke Zettlemoyer},
  title     = {{VLM:} Task-agnostic Video-Language Model Pre-training for Video Understanding},
  booktitle = {Findings of the Association for Computational Linguistics},
  pages     = {4227--4239},
  year      = {2021},
}

@inproceedings{COOT,
  author    = {Simon Ging and
               Mohammadreza Zolfaghari and
               Hamed Pirsiavash and
               Thomas Brox},
  title     = {{COOT:} Cooperative Hierarchical Transformer for Video-Text Representation
               Learning},
  booktitle = NIPS,
  year      = {2020}
}

@inproceedings{Glove,
  author    = {Jeffrey Pennington and
               Richard Socher and
               Christopher D. Manning},
  title     = {Glove: Global Vectors for Word Representation},
  booktitle = {Conference on Empirical Methods in Natural
               Language Processing},
  pages     = {1532--1543},
  year      = {2014}
}

@inproceedings{MFT,
  author    = {Yilei Xiong and
               Bo Dai and
               Dahua Lin},
  title     = {Move Forward and Tell: {A} Progressive Generator of Video Descriptions},
  booktitle = ECCV,
  pages     = {489--505},
  year      = {2018},
}

@inproceedings{HSE,
  author    = {Bowen Zhang and
               Hexiang Hu and
               Fei Sha},
  title     = {Cross-Modal and Hierarchical Modeling of Video and Text},
  booktitle = ECCV,
  pages     = {385--401},
  year      = {2018},
}

@inproceedings{GVD,
  author    = {Luowei Zhou and
               Yannis Kalantidis and
               Xinlei Chen and
               Jason J. Corso and
               Marcus Rohrbach},
  title     = {Grounded Video Description},
  booktitle = CVPR,
  pages     = {6578--6587},
  year      = {2019},
}

@inproceedings{BLEU,
  author    = {Kishore Papineni and
               Salim Roukos and
               Todd Ward and
               Wei{-}Jing Zhu},
  title     = {Bleu: a Method for Automatic Evaluation of Machine Translation},
  booktitle = ACL,
  pages     = {311--318},
  year      = {2002},
}

@inproceedings{METEOR,
  author    = {Michael J. Denkowski and
               Alon Lavie},
  title     = {Meteor Universal: Language Specific Translation Evaluation for Any
               Target Language},
  booktitle = {Proceedings of the Ninth Workshop on Statistical Machine Translation},
  pages     = {376--380},
  year      = {2014},
}

@inproceedings{CIDEr,
  author    = {Ramakrishna Vedantam and
               C. Lawrence Zitnick and
               Devi Parikh},
  title     = {CIDEr: Consensus-based Image Description Evaluation},
  booktitle = CVPR,
  pages     = {4566--4575},
  year      = {2015},
}

@inproceedings{ROUGE,
  title = {Rouge: A Package for Automatic Evaluation of Summaries},
  author = {Lin, Chin-Yew},
  booktitle = ACL,
  pages = {74--81},
  year = {2004}
}

@inproceedings{Re,
  title = {Move forward and tell: A progressive generator of video descriptions},
  author = {Xiong, Yilei and Dai, Bo and Lin, Dahua},
  booktitle = ECCV,
  pages = {468--483},
  year = {2018}
}

@article{VG,
  title = {Visual Genome: Connecting Language and Vision using Crowdsourced Dense Image Annotations},
  author = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal = IJCV,
  volume = {123},
  number = {1},
  pages = {32--73},
  year = {2017}
}

@inproceedings{CLIP,
  author    = {Alec Radford and
               Jong Wook Kim and
               Chris Hallacy and
               Aditya Ramesh and
               Gabriel Goh and
               Sandhini Agarwal and
               Girish Sastry and
               Amanda Askell and
               Pamela Mishkin and
               Jack Clark and
               Gretchen Krueger and
               Ilya Sutskever},
  title     = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle = ICML,
  pages     = {8748--8763},
  year      = {2021},
}

@inproceedings{DBLP:journals/corr/abs-1810-04805,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  editor    = {Jill Burstein and
               Christy Doran and
               Thamar Solorio},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  booktitle = {Conference of the North American Chapter of
               the Association for Computational Linguistics},
  pages     = {4171--4186},
  year      = {2019}
}

@article{VidSWIN,
  author    = {Ze Liu and
               Jia Ning and
               Yue Cao and
               Yixuan Wei and
               Zheng Zhang and
               Stephen Lin and
               Han Hu},
  title     = {Video Swin Transformer},
  journal   = {CoRR},
  volume    = {abs/2106.13230},
  year      = {2021},
}

@inproceedings{howto100,
  author    = {Antoine Miech and
               Dimitri Zhukov and
               Jean{-}Baptiste Alayrac and
               Makarand Tapaswi and
               Ivan Laptev and
               Josef Sivic},
  title     = {HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million
               Narrated Video Clips},
  booktitle = ICCV,
  pages     = {2630--2640},
  year      = {2019},
}

@inproceedings{Clip4caption,
  author    = {Mingkang Tang and
               Zhanyu Wang and
               Zhenhua Liu and
               Fengyun Rao and
               Dian Li and
               Xiu Li},
  title     = {CLIP4Caption: {CLIP} for Video Caption},
  booktitle = ACMMM,
  pages     = {4858--4862},
  year      = {2021},
}

@article{asr,
  author    = {William Chan and
               Navdeep Jaitly and
               Quoc V. Le and
               Oriol Vinyals},
  title     = {Listen, Attend and Spell},
  year      = {2015},
}

@inproceedings{ConceptNet,
  author    = {Robyn Speer and
               Joshua Chin and
               Catherine Havasi},
  title     = {ConceptNet 5.5: An Open Multilingual Graph of General Knowledge},
  booktitle = AAAI,
  pages     = {4444--4451},
  year      = {2017},
}


@inproceedings{sbert,
  author    = {Nils Reimers and
               Iryna Gurevych},
  editor    = {Kentaro Inui and
               Jing Jiang and
               Vincent Ng and
               Xiaojun Wan},
  title     = {Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  booktitle = {EMNLP-IJCNLP},
  pages     = {3980--3990},
  year      = {2019}
}

@article{lavender,
  author    = {Linjie Li and
               Zhe Gan and
               Kevin Lin and
               Chung{-}Ching Lin and
               Zicheng Liu and
               Ce Liu and
               Lijuan Wang},
  title     = {{LAVENDER:} Unifying Video-Language Understanding as Masked Language
               Modeling},
  year      = {2022},
}

@inproceedings{DBLP:conf/acl/ChenD11,
  author    = {David L. Chen and
               William B. Dolan},
  editor    = {Dekang Lin and
               Yuji Matsumoto and
               Rada Mihalcea},
  title     = {Collecting Highly Parallel Data for Paraphrase Evaluation},
  booktitle = ACL,
  year      = {2011}
}

@inproceedings{LXMERT,
  author    = {Hao Tan and
               Mohit Bansal},
  editor    = {Kentaro Inui and
               Jing Jiang and
               Vincent Ng and
               Xiaojun Wan},
  title     = {{LXMERT:} Learning Cross-Modality Encoder Representations from Transformers},
  booktitle = {EMNLP-IJCNLP},
  pages     = {5099--5110},
  year      = {2019}
}

@inproceedings{ViLBERT,
  author    = {Jiasen Lu and
               Dhruv Batra and
               Devi Parikh and
               Stefan Lee},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations
               for Vision-and-Language Tasks},
  booktitle = NIPS,
  pages     = {13--23},
  year      = {2019}
}

@article{UNITER,
  author    = {Yen{-}Chun Chen and
               Linjie Li and
               Licheng Yu and
               Ahmed El Kholy and
               Faisal Ahmed and
               Zhe Gan and
               Yu Cheng and
               Jingjing Liu},
  title     = {{UNITER:} Learning UNiversal Image-TExt Representations},
  journal   = {CoRR},
  year      = {2019}
}

@inproceedings{UNIMO,
  author    = {Wei Li and
               Can Gao and
               Guocheng Niu and
               Xinyan Xiao and
               Hao Liu and
               Jiachen Liu and
               Hua Wu and
               Haifeng Wang},
  editor    = {Chengqing Zong and
               Fei Xia and
               Wenjie Li and
               Roberto Navigli},
  title     = {{UNIMO:} Towards Unified-Modal Understanding and Generation via Cross-Modal
               Contrastive Learning},
  booktitle = {ACL-IJCNLP},
  pages     = {2592--2607},
  year      = {2021}
}

@inproceedings{Unicoder-VL,
  author    = {Gen Li and
               Nan Duan and
               Yuejian Fang and
               Ming Gong and
               Daxin Jiang},
  title     = {Unicoder-VL: {A} Universal Encoder for Vision and Language by Cross-Modal
               Pre-Training},
  booktitle = AAAI,
  pages     = {11336--11344},
  year      = {2020}
}

@inproceedings{Unified-VL,
  author    = {Luowei Zhou and
               Hamid Palangi and
               Lei Zhang and
               Houdong Hu and
               Jason J. Corso and
               Jianfeng Gao},
  title     = {Unified Vision-Language Pre-Training for Image Captioning and {VQA}},
  booktitle = AAAI,
  pages     = {13041--13049},
  year      = {2020}
}

@inproceedings{Frozen,
  author    = {Max Bain and
               Arsha Nagrani and
               G{\"{u}}l Varol and
               Andrew Zisserman},
  title     = {Frozen in Time: {A} Joint Video and Image Encoder for End-to-End Retrieval},
  booktitle = ICCV,
  pages     = {1708--1718},
  year      = {2021}
}

@inproceedings{DBLP:conf/nips/VaswaniSPUJGKP17,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  editor    = {Isabelle Guyon and
               Ulrike von Luxburg and
               Samy Bengio and
               Hanna M. Wallach and
               Rob Fergus and
               S. V. N. Vishwanathan and
               Roman Garnett},
  title     = {Attention is All you Need},
  booktitle = NIPS,
  pages     = {5998--6008},
  year      = {2017}
}

@inproceedings{DBLP:journals/corr/KingmaB14,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = ICLR,
  year      = {2015}
}

@inproceedings{incev2,
  author    = {Christian Szegedy and
               Sergey Ioffe and
               Vincent Vanhoucke and
               Alexander A. Alemi},
  editor    = {Satinder Singh and
               Shaul Markovitch},
  title     = {Inception-v4, Inception-ResNet and the Impact of Residual Connections
               on Learning},
  booktitle = AAAI,
  year      = {2017},
}

@inproceedings{c3d,
  author    = {Kensho Hara and
               Hirokatsu Kataoka and
               Yutaka Satoh},
  title     = {Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?},
  booktitle = CVPR,
  pages     = {6546--6555},
  year      = {2018},
}

@inproceedings{resnet,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  booktitle = CVPR,
  pages     = {770--778},
  year      = {2016},
}

@inproceedings{BN,
  author    = {Sergey Ioffe and
               Christian Szegedy},
  editor    = {Francis R. Bach and
               David M. Blei},
  title     = {Batch Normalization: Accelerating Deep Network Training by Reducing
               Internal Covariate Shift},
  booktitle = ICML,
  pages     = {448--456},
  year      = {2015}
}

@article{fasterrcnn,
  author    = {Shaoqing Ren and
               Kaiming He and
               Ross B. Girshick and
               Jian Sun},
  title     = {Faster {R-CNN:} Towards Real-Time Object Detection with Region Proposal
               Networks},
  pages     = {1137--1149},
  year      = {2017},
}

@article{DBLP:journals/corr/abs-2111-02114,
  author    = {Christoph Schuhmann and
               Richard Vencu and
               Romain Beaumont and
               Robert Kaczmarczyk and
               Clayton Mullis and
               Aarush Katta and
               Theo Coombes and
               Jenia Jitsev and
               Aran Komatsuzaki},
  title     = {{LAION-400M:} Open Dataset of CLIP-Filtered 400 Million Image-Text
               Pairs},
  journal   = {CoRR},
  year      = {2021}
}

@inproceedings{cmvc,
  author    = {Bang Yang and
               Tong Zhang and
               Yuexian Zou},
  title     = {{CLIP} Meets Video Captioning: Concept-Aware Representation Learning
               Does Matter},
  booktitle = {Pattern Recognition and Computer Vision - 5th Chinese Conference,
               {PRCV} 2022, Shenzhen, China, November 4-7, 2022, Proceedings, Part
               {I}},
  year      = {2022} 
}

@article{tkg,
  title={Image captioning with transformer and knowledge graph},
  author={Zhang, Yu and Shi, Xinyu and Mi, Siya and Yang, Xu},
  journal={Pattern Recognition Letters},
  volume={143},
  pages={43--49},
  year={2021},
  publisher={Elsevier}
}

@article{BEIC,
  author    = {Wentian Zhao and
               Yao Hu and
               Heda Wang and
               Xinxiao Wu and
               Jiebo Luo},
  title     = {Boosting Entity-aware Image Captioning with Multi-modal Knowledge
               Graph},
  journal   = {CoRR},
  year      = {2021}
}

@inproceedings{ICiek,
  author    = {Feicheng Huang and
               Zhixin Li and
               Shengjia Chen and
               Canlong Zhang and
               Huifang Ma},
  title     = {Image Captioning with Internal and External Knowledge},
  booktitle = {{CIKM} '20: The 29th {ACM} International Conference on Information
               and Knowledge Management, Virtual Event, Ireland, October 19-23, 2020},
  pages     = {535--544},
  publisher = {{ACM}},
  year      = {2020},
}

@inproceedings{value,
  author    = {Linjie Li and
               Jie Lei and
               Zhe Gan and
               Licheng Yu and
               Yen{-}Chun Chen and
               Rohit Pillai and
               Yu Cheng and
               Luowei Zhou and
               Xin Wang and
               William Yang Wang and
               Tamara L. Berg and
               Mohit Bansal and
               Jingjing Liu and
               Lijuan Wang and
               Zicheng Liu},
  
  title     = {{VALUE:} {A} Multi-Task Benchmark for Video-and-Language Understanding
               Evaluation},
  booktitle = {Proceedings of the Neural Information Processing Systems Track on
               Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December
               2021, virtual},
  year      = {2021}
}

@article{DST,
  author    = {Xin Gu and
               Hanhua Ye and
               Guang Chen and
               Yufei Wang and
               Libo Zhang and
               Longyin Wen},
  title     = {Dual-Stream Transformer for Generic Event Boundary Captioning},
  year      = {2022},
  journal   = {CoRR},
}