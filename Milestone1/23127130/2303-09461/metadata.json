{
    "arxiv_id": "2303.09461",
    "paper_title": "ChatGPT Participates in a Computer Science Exam",
    "authors": [
        "Sebastian Bordt",
        "Ulrike von Luxburg"
    ],
    "submission_date": "2023-03-08",
    "revised_dates": [
        "2023-03-17"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CL",
        "cs.CY"
    ],
    "abstract": "We asked ChatGPT to participate in an undergraduate computer science exam on ''Algorithms and Data Structures''. We evaluated the program on the entire exam as posed to the students. We hand-copied its answers onto an exam sheet, which was subsequently graded in a blind setup alongside those of 200 participating students. We find that ChatGPT narrowly passed the exam, obtaining 20.5 out of 40 points. This impressive performance indicates that ChatGPT can indeed succeed in challenging tasks like university exams. At the same time, the tasks in our exam are structurally similar to those on other exams, solved homework problems, and teaching materials that can be found online. Therefore, it would be premature to conclude from this experiment that ChatGPT has any understanding of computer science. The transcript of our conversation with ChatGPT is available at \\url{https://github.com/tml-tuebingen/chatgpt-algorithm-exam}, and the entire graded exam is in the appendix of this paper.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09461v1"
    ],
    "publication_venue": null
}