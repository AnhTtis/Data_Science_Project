
\documentclass{article} % For LaTeX2e
\usepackage{iclr2023_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage[hyphens]{url}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{fontawesome}
\usepackage{graphicx}
\usepackage{longtable}


\title{Privacy-preserving machine learning for healthcare: open challenges and future perspectives}

\author{Alejandro Guerra-Manzanares\thanks{Equal contributions.}, \hspace{1mm} L. Julian Lechuga Lopez$^*$, \\ \textbf{Michail Maniatakos} \textbf{and} \textbf{Farah E. Shamout}\\
Department of Computer Engineering, New York University Abu Dhabi\\
\texttt{\{ag9454, ljl5178, mm6446, fs999\}@nyu.edu}}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

% define some gap in the abstract, as a motivation to conduct this review article
% enumerate challenges and future research directions in the abstract
\begin{abstract}
Machine Learning (ML) has recently shown tremendous success in modeling various healthcare prediction tasks, ranging from disease diagnosis and prognosis to patient treatment. Due to the sensitive nature of medical data, privacy must be considered along the entire ML pipeline, from model training to inference. In this paper, we conduct a review of recent literature concerning Privacy-Preserving Machine Learning (PPML) for healthcare. We primarily focus on privacy-preserving training and inference-as-a-service, and perform a comprehensive review of existing trends, identify challenges, and discuss opportunities for future research directions. The aim of this review is to guide the development of private and efficient ML models in healthcare, with the prospects of translating research efforts into real-world settings.
\end{abstract}

\section{Introduction}
\label{introduction}
%P1: Artificial intelligence, its general success, and success in healthcare
% Artificial intelligence (AI) systems have an enormous potential for improving human development and expanding knowledge. 
Machine Learning (ML) and Deep Learning (DL) have shown great promise in many domains, leveraging the use of large datasets. Some notable contributions include \emph{AlphaFold} \citep{alphafold} for the prediction of protein structures and \emph{Transformers} \citep{attention} for natural language processing. Healthcare is one of the domains in which ML is expected to provide substantial improvements in the delivery of patient care worldwide \citep{who}. Given the rapid growth in the number of models over the last couple of years \citep{ravi2016deep, miotto2018deep, kaul2022deep, javaid2022significance}, healthcare applications deserve special consideration considering the sensitive nature of the data that is required to train the models and the safety-critical nature of medical decision-making.

%P2: Privacy issues related to AI in healthcare
In this regard, real-world implementation of such models is still hampered by ethical and legal constraints. Legal frameworks have been developed and enforced to guarantee the transparency and privacy of ML-based healthcare solutions, such as the \emph{Health Insurance Portability and Accountability Act (HIPAA)} in the United States \citep{hipaa} and the \emph{General Data Protection Regulation (GDPR)} in Europe \citep{gdpr}. Therefore, there is a crucial need for Privacy-Preserving Machine Learning (PPML) in healthcare to enable the implementation of trustworthy systems in the future. The main goal of this review is to provide a comprehensive overview of state-of-the-art PPML in healthcare and encourage the development of new methodologies that tackle specific challenges relevant to the nature of the domain.

%P3 Summary of previous reviews
\textbf{Motivation.} 
There exist several related literature reviews that focus on a specific subset of PPML for healthcare. Several highlight recent advancements in federated learning \citep{xu2021federated, ali2022federated, joshi2022federated, nguyen2022federated}, cryptographic techniques \citep{zalonis2022report}, or security aspects of ML models, such as adversarial attacks \citep{liu2021machine}. Existing review articles cover a wide range of applications related to health and input data modalities, ranging from IoT sensors to medical images \citep{qayyum2020secure}. Compared to existing work, our review has three main contributions with the intent of bridging between research pertaining to ML for healthcare and cybersecurity. First, we distinguish between PPML for training and inference, i.e., \emph{ML-as-a-service}. Second, we focus on state-of-the-art (SOTA) literature published in the last three years, considering the high proliferation of ML in healthcare and recent methodological advancements in ML and DL (e.g., network architectures, model pre-training, etc.). Third, we consider studies that develop or apply methodologies using two popular modalities based on publicly available datasets and state-of-the-art in ML for healthcare, namely medical images and data extracted from Electronic Health Records (EHR) \citep{kaul2022deep}.Despite the use of other input modalities in medical applications, such as video \citep{ouyang2020video} or text \citep{srivastava2019effect}, our review exclusively focuses on medical images and EHR as they are the most prevalent input modalities in diagnostic and prognostic settings \citep{shehab2022machine}. Lastly, although we acknowledge the importance of security for ML models, it is out of the scope of this paper since we primarily focus on privacy.  

% Second, , and \textbf{(iii)} the proposal of recommendations for future research work to address current gaps. We provide a comprehensive review of recent studies on PPML for healthcare, covering a wide range of methodologies used for private training and private inference , and focusing

To this end, we review papers that meet the following inclusion criteria: 

\begin{enumerate}
\setlength\itemsep{0.5mm}
    \item We include recently published work i.e., publication year $\geq 2020$.
    \item We include articles that focus on the application or development of PPML either for model training and/or inference, including but not restricted to homomorphic encryption, differential privacy, federated learning, and multi-party secure computation.
    \item We include articles that consider clinical tasks involving medical images and/or EHR data.
\end{enumerate} 

In Section \ref{background}, we provide background knowledge about concepts and terminology concerning PPML. In Section \ref{sota}, we provide an overview of the state-of-the-art pertaining to PPML for training (Section \ref{training}) and for inference (Section \ref{inference}). Later in Section \ref{future}, we discuss open challenges and derive future directions. Finally, we provide concluding remarks in Section \ref{conclusions}. 

%focus is on the investigation of methods ensuring data privacy along the whole ML pipeline, thus the security of ML algorithms against adversarial inputs is out of the scope of this paper.

 % Although we acknowledge the importance of security for ML algorithms, our focus remains on the investigation of methods ensuring data privacy along the entire ML pipeline, which consider adversarial inputs out of the scope of this paper.

\section{Privacy-preserving machine learning: background \& terminology}
\label{background}

% This section provides an overview of relevant key concepts and terminology related to commonly used privacy-preserving approaches for AI-driven solutions.

\subsection{Federated Learning}
Since medical data is highly sensitive, data sharing is difficult, and subject to ethical restrictions and legal constraints if at all possible. Federated learning (FL) \citep{mcmahan2017communication} aims to overcome the challenges of data sharing by enabling collaborative training, which does not require that the involved parties share their training data. Therefore, the data remains private to each local node within the FL network, such that only the model updates are shared and integrated in a centralized model. 


Federated averaging \citep{mcmahan2017communication} is the most common form of FL. In this setting, a centralized server is connected to $N$ entities, which have their own training data. The central server orchestrates the collaborative training process as follows: (1) the initial model is distributed amongst all entities, (2) each entity performs a training iteration on their local model using their own training data, typically one epoch, and shares its resulting model parameters with the central server, (3) the server averages the model parameters shared by all entities and distributes the resulting (averaged) model amongst all entities, and (4) steps (2) and (3) are repeated sequentially until a performance threshold or a specific number of training iterations is achieved. FL has proven to be very efficient in training models with strong performance, while avoiding the need for data sharing \citep{mcmahan2017communication}. However, FL might be vulnerable to privacy issues such as reconstruction attacks \citep{liu2022threats}, thus requiring that it is combined with other privacy-preserving methods to ensure robust privacy guarantees \citep{nguyen2022federated}.

%%% until here

\subsection{Differential Privacy}

Differential Privacy (DP) has its origins in statistical analysis of databases. Its main aim is to address the paradox of learning nothing about specific individuals, while learning useful information about the general population \citep{dwork2014algorithmic}. In the FL context, it is usually incorporated in the form of additive noise to model updates, either artificially or using a differentiable private optimizer, prior to transferring the updates from the entities to the central server \citep{abadi2016deep}. The amount of artificial noise added is directly proportional to the degree of privacy desired (i.e., privacy budget) \citep{zhang2021adaptive}. DP can successfully make privacy attacks fail, such as reconstruction attacks, as the added noise hinders the inference of actual knowledge about the training data by the attacker. However, adding too much noise (i.e., high privacy budget) can hamper learning and negatively impact the model accuracy \citep{A44}.

\subsection{Homomorphic Encryption}

In mathematics, the term \emph{homomorphic} refers to the transformation of a given set into another while preserving the relation between the elements in both sets. Thus, Homomorphic Encryption (HE) refers to the conversion of plaintext into ciphertext while preserving the structure of the data. Consequently, specific operations applied to the ciphertext will provide the same results as if they were applied to the plaintext but without compromising the encryption \citep{acar2018survey}. That is, the plaintext data is never accessed nor decrypted as the operations are directly applied to the encrypted data. The result of the transformations on the ciphertext can only be decrypted back to plaintext by the encryption key owner. 

Despite the benefit of provable privacy guarantees, the range of operations available in HE is restricted to addition and multiplication i.e., \emph{fully} homomorphic encryption. This limits the set and number of transformations applicable to the data and requires the use of approximations for more complex operations (e.g., HE-ReLU is the polynomial approximation of the ReLU function \citep{yue2021privacy}). This also significantly increases the computational time needed to process encrypted text compared to plaintext by several orders of magnitude \citep{popescu2021privacy}.

\subsection{Secure Multi-party Computation}

Secure Multi-Party Computation (SMPC) \citep{goldreich1998secure} provides a framework in which two or more parties jointly compute a public function with their data while keeping the inputs private and hidden from other parties using cryptographic protocols. Most protocols used for SMPC with more than two parties are based on Secret Sharing (SS). In SS, a portion of the secret input is shared among a number of other parties. Most ML methods use Shamirâ€™s SS and additive SS \citep{singh2021privacy}. Although these methods are considered information-theoretic secure cryptosystems, recent studies show that leakage of global data properties can occur in some scenarios \citep{zhang2021leakage}. While both FL and SMPC rely on collaborative training via knowledge sharing and keep the end-point data private, their implementation differs significantly. SMPC involves cryptography and can be used for training and inference, whereas FL does not involve cryptography nor provides strong privacy guarantees, and is only used for model training.

\section{Overview of state-of-the-art}
\label{sota}

Following the inclusion criteria described in Section \ref{introduction}, we summarize existing work on PPML for healthcare based on whether the work focuses on model training (Table~\ref{table:1}) or model inference (Table~\ref{table:3}). For each study (row) we describe several attributes. \emph{Use case} provides a succinct summary of the objective of the study. \emph{Model} reports the ML or DL architecture that was employed to model the task. \emph{Medical datasets} summarizes the datasets that were used for model training and evaluation. Additionally, we use the * symbol to indicate the use of a private dataset. \emph{ML task} describes the nature of the prediction task (e.g., binary or multi-class classification). \emph{Input modality} reports the nature of the model's input data, which could either be \emph{I} for medical images or \emph{E} for EHR data. In the \emph{Validation} column, we report whether the trained model was internally and/or externally evaluated, with \faCheck 
 indicating the use of internal validation i.e., test set from the same distribution of the training data, and \faCheck \faCheck indicating the assessment of the generalization of the model on an external test dataset. Lastly, \emph{Metrics} lists the evaluation metrics used to describe the performance of the proposed model.
 
\subsection{Privacy-preserving training for healthcare}
\label{training}
%Typically, a centralized entuty As proved by \citet{mcmahan2017communication}, using this framework, model aggregation based on collaborative training can result in high performance models that require fewer training rounds than centralized models. Besides, as the model is trained on each individual dataset, the final model is trained in more data than each individual model which also results in more generalizable models \citep{mcmahan2017communication}.

%Table summarizing works based on analysis of the literature (see work plan point 3) and description of main points from it.

\begin{table}[h!]
    \caption{\small\textbf{Summary of PPML in healthcare for model training.} We summarize studies that focus on developing PPML in the context of model training. We group them based on the methodology considered, i.e. federated learning, homomorphic encryption, and differential privacy.}
    \label{table:1}
    \smallskip
    \smallskip
    \tiny
    \centering
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{l c c c c c c c}
        \toprule
        \bf \multirow{1}{*}[0.5em]{Reference}
        & \bf \multirow{1}{*}[0.5em]{Use case} & \bf \multirow{1}{*}[0.5em]{Model} & \bf \shortstack{Medical \\ dataset/s}  &\bf \multirow{1}{*}[0.5em]{ML task} & \bf \shortstack{Input \\ modality} & \bf \multirow{1}{*}[0.5em]{Validation} & \bf \multirow{1}{*}[0.5em]{Metrics} \\
        
        \midrule
            \multicolumn{8}{c}{\bf FEDERATED LEARNING} \\

        \midrule
        \multirow{1}{*}[0.5em]{\citet{A32}} & \shortstack{COVID-19 Computed \\ Tomography (CT) analysis} &\multirow{1}{*}[0.5em]{RetinaNet} &\shortstack{ Multi-institution \\ lung CT data*} &\multirow{1}{*}[0.5em]{\shortstack{Object detection}} &\multirow{1}{*}[0.5em]{I} &\multirow{1}{*}[0.5em]{\faCheck \faCheck} &\shortstack{mAP, Specifity, \\ Recall, AUROC}\\

        \midrule
        \multirow{1}{*}[.5em]{\citet{A55}} &\shortstack{Cardiovascular admission \\ after lung cancer treatment} & \multirow{1}{*}[.5em]{Logistic regression} &\shortstack{ Multi-institution \\ lung CT data*} &\multirow{1}{*}[.5em]{Risk prediction} &\multirow{1}{*}[.5em]{I+E} &\multirow{1}{*}[.5em]{\faCheck} &\multirow{1}{*}[.5em]{AUROC, C-index}\\

        \midrule
        \multirow{1}{*}[1em]{\citet{A73}} &\multirow{1}{*}[1.75em]{\shortstack{FL benchmarking and \\ reliability in healthcare}} &\shortstack{Neural Network, \\LSTM, \\CNN} &\multirow{1}{*}[1.75em]{\shortstack{MIMIC-III, \\ PhysioNet ECG}} &\shortstack{Mortality prediction, \\Multi-class \\ classification} &\multirow{1}{*}[1.3em]{I+E} &\multirow{1}{*}[1.3em]{\faCheck} &\multirow{1}{*}[1.75em]{\shortstack{AUROC, AUPRC, \\ F1-score}} \\

        \midrule
        \multirow{1}{*}[1.75em]{\citet{A75}} &\multirow{1}{*}[3em]{\shortstack{FL benchmarking \\ and monetary cost \\ in healthcare}} &\multirow{1}{*}[3em]{\shortstack{Transformer, \\EfficientNet-B0, \\ResNet-NC-SE}} &\shortstack{eICU, \\ISIC19, \\HAM10000, \\PhysioNet ECG} &\shortstack{Mortality prediction, 
        \\ Length of stay, \\Discharge time, \\ Acuity prediction} &\multirow{1}{*}[1.75em]{I+E} &\multirow{1}{*}[1.75em]{\faCheck} &\multirow{1}{*}[1.75em]{\shortstack{AUROC, AUPRC}}\\

        \midrule
        \multirow{1}{*}[1.75em]{\citet{A77}} &\multirow{1}{*}[3em]{\shortstack{FL benchmarking vs. \\ centralized learning\\ in healthcare}} & \multirow{1}{*}[3.2em]{\shortstack{Logistic regression, \\ Neural Network, \\ Generalized linear model}} &\shortstack{UCI Heart failure, \\MIMIC-III, \\Malignancy in SARS- \\ CoV-2 infection} &\multirow{1}{*}[2em]{Risk prediction} &\multirow{1}{*}[2em]{E} &\multirow{1}{*}[2em]{\faCheck} &\multirow{1}{*}[2em]{AUROC}\\

        \midrule
        \multirow{1}{*}[.5em]{\citet{J19}} &\shortstack{COVID-19 \\ detection} &\multirow{1}{*}[.5em]{DenseNet} &\shortstack{Multi-institution \\ COVID-19 X-ray*} & \shortstack{Binary \\ classification} &\multirow{1}{*}[.5em]{I} &\multirow{1}{*}[.5em]{\faCheck \faCheck} &\multirow{1}{*}[.5em]{\shortstack{AUROC, AUPRC}} \\

        \midrule
        \multirow{1}{*}[.5em]{\citet{J21}} &\shortstack{Coronary artery \\ calcification (CAC) forecast} &\multirow{1}{*}[.5em]{\shortstack{Random Forest}} &\multirow{1}{*}[.5em]{CAC risk factors*} &\multirow{1}{*}[.5em]{Risk prediction} &\multirow{1}{*}[.5em]{E} &\multirow{1}{*}[.5em]{\faCheck} &\multirow{1}{*}[.5em]{\shortstack{Recall, Specificity}} \\

        \midrule
        \multirow{1}{*}[1.5em]{\citet{J23}} &\multirow{1}{*}[1.8em]{\shortstack{Cancer inference \\ via gene expression}} &\multirow{1}{*}[1.8em]{\shortstack{Gradient Boosting \\ Decision Tree}} &\multirow{1}{*}[1.5em]{iDASH 2020} &\multirow{1}{*}[1.8em]{\shortstack{Multi-class \\ classification}} &\multirow{1}{*}[1.5em]{E} &\multirow{1}{*}[1.5em]{\faCheck} &\shortstack{Accuracy, AUC, \\Recall, Precision, \\F1-score}\\

        \midrule
        \multirow{1}{*}[.5em]{\citet{J34}} &\shortstack{Diabetic kidney\\  risk prediction} &\shortstack{Logistic regression,\\ MLP} &\shortstack{ CERNER Health \\ Facts} &\multirow{1}{*}[.5em]{Risk prediction} &\multirow{1}{*}[.5em]{E} &\multirow{1}{*}[.5em]{\faCheck} &\multirow{1}{*}[.5em]{F1-score}\\
        
        \midrule
        
        \multirow{1}{*}[.5em]{\citet{J30}} &\shortstack{Lung cancer post- \\ treatment 2-year survival} &\multirow{1}{*}[.5em]{\shortstack{Logistic regression}} &\shortstack{Multi-institution  \\ lung cancer EHR*} &\multirow{1}{*}[.5em]{Mortality prediction} &\multirow{1}{*}[.5em]{E} &\multirow{1}{*}[.5em]{\faCheck} &\shortstack{RMSE, Accuracy, \\ AUROC}\\

        \midrule

        % **********************************************************************
        % POSTREVIEW PAPER 1
        \multirow{1}{*}[1.75em]{\citet{postreview1}} &\multirow{1}{*}[2em]{\shortstack{COVID-19 \\ detection}} &\multirow{1}{*}[3em]{\shortstack{Transformer with \\ DenseNet, TransUNet\\and RetinaNet}} &\shortstack{Multi-institution \\ COVID-19 X-ray \\ (public and \\ private datasets)} &\shortstack{Multi-task: \\ classification, \\ segmentation, \\ object detection} &\multirow{1}{*}[1.75em]{I} &\multirow{1}{*}[1.75em]{\faCheck \faCheck} &\multirow{1}{*}[2em]{\shortstack{AUC, mAP, \\Dice coefficient}} \\ 
        % **********************************************************************
        
        \midrule
        % **********************************************************************
        % POSTREVIEW PAPER 2
        \multirow{1}{*}[1.25em]{\citet{postreview2}} &\multirow{1}{*}[2em]{\shortstack{Multiple medical \\ prediction tasks}} &\multirow{1}{*}[2em]{\shortstack{Self-supervised \\ vision transformer}} &\shortstack{ COVID-19 X-ray,  \\ Kaggle Diabetic Retinopathy, \\Dermatology ISIC} & \shortstack{Binary/multi-class \\ classification, \\Object detection} &\multirow{1}{*}[1.25em]{I} &\multirow{1}{*}[1.25em]{\faCheck \faCheck} &\multirow{1}{*}[1.75em]{\shortstack{Accuracy, \\ F1-score}}\\
        % **********************************************************************
        
        \midrule
        
        \multicolumn{8}{c}{\bf HOMOMORPHIC ENCRYPTION} \\
        \midrule
        \multirow{1}{*}[.5em]{\citet{A27}} &\shortstack{COVID-19 \\ detection} &\multirow{1}{*}[.5em]{MobileNet-V2} &\multirow{1}{*}[.5em]{COVID-19 X-ray} &\shortstack{Multi-class \\ classification} &\multirow{1}{*}[.5em]{I} &\multirow{1}{*}[.5em]{\faCheck} &\shortstack{Accuracy, Recall, \\ Precision, F1-score}\\

        \midrule
        \multirow{1}{*}[0.5em]{\citet{A49}} &\shortstack{Heart and thyroid \\ disease classification} &\multirow{1}{*}[0.5em]{XGBoost} &\shortstack{ UCI Heart Disease, \\ Kaggle Hypothyroid} & \shortstack{Binary \\ classification} &\multirow{1}{*}[0.5em]{E} &\multirow{1}{*}[0.5em]{\faCheck} &\multirow{1}{*}[0.5em]{Accuracy}\\

        \midrule
        \multirow{1}{*}[.5em]{\citet{A52}} &\shortstack{Intensive Care Unit \\ patient outcome} &\multirow{1}{*}[.5em]{LSTM} &\multirow{1}{*}[.5em]{MIMIC-III} &\shortstack{Binary \\ classification} &\multirow{1}{*}[.5em]{E} &\multirow{1}{*}[.5em]{\faCheck} &\shortstack{Recall, AUROC, \\ Precision}\\

        \midrule

        \multirow{1}{*}[0.5em]{\citet{J29}} &\shortstack{Dermatology \\ diagnostics} &\multirow{1}{*}[0.5em]{SVM} &\multirow{1}{*}[0.5em]{UCI Dermatology} & \shortstack{Multi-class \\ classification} &\multirow{1}{*}[0.5em]{E} &\multirow{1}{*}[0.5em]{\faCheck} & \multirow{1}{*}[0.5em]{Accuracy}\\

        \midrule
        
        \multirow{1}{*}[.5em]{\citet{extra4}} &\shortstack{COVID-19 \\ detection} &\shortstack{AlexNet,\\ SqueezeNet} &\shortstack{COVID-19 X-ray, \\ COVID-19 CT} &\shortstack{Multi-class \\ classification} &\multirow{1}{*}[.5em]{I} &\multirow{1}{*}[.5em]{\faCheck} &\shortstack{Accuracy, F1-score}\\

        % ENDING OF FEDERATED LEARNING
        
        \midrule
        \multicolumn{8}{c}{\bf DIFFERENTIAL PRIVACY}\\
        \midrule
        \multirow{1}{*}[.5em]{\citet{A10}} &\shortstack{Thoracic pathology \\ detection} &\multirow{1}{*}[.5em]{DenseNet-121} &\multirow{1}{*}[.5em]{ CheXpert } &\shortstack{Multi-class \\ classification} &\multirow{1}{*}[.5em]{I+E} &\multirow{1}{*}[.5em]{\faCheck} &\shortstack{AUROC, \\ Accuracy}\\

        \midrule
        \multirow{1}{*}[0.5em]{\citet{A44}} &\shortstack{COVID-19 \\ detection} &\multirow{1}{*}[0.5em]{EfficientNet-B2} &\multirow{1}{*}[0.5em]{COVID-19 X-ray} & \shortstack{Binary \\ classification} &\multirow{1}{*}[0.5em]{I} &\multirow{1}{*}[0.5em]{\faCheck} &\multirow{1}{*}[0.5em]{Accuracy}\\

        \midrule
        \multirow{1}{*}[2em]{\citet{A67}} &\multirow{1}{*}[2.5em]{\shortstack{Multiple medical \\ prediction tasks}} &\shortstack{CNN, \\ DenseNet-121, \\ Logistic regression, \\ GRU-D} &\multirow{1}{*}[3em]{\shortstack{MNIST\\ NIH Chest X-ray, \\ MIMIC-III}} &\multirow{1}{*}[3em]{\shortstack{Binary, \\ Multi-class \\ classification}} &\multirow{1}{*}[2em]{I+E} &\multirow{1}{*}[2em]{\faCheck} &\multirow{1}{*}[2em]{AUROC}\\
        % END OF DIFFERENTIAL PRIVACY

        \bottomrule
    \end{tabular}
    }
\end{table}

\begin{table}[ht]
\renewcommand\thetable{1 Continued} 
    \caption{\small\textbf{Continued summary of PPML in healthcare for model training.} We summarize here studies that use a combination of federated learning and other privacy-preserving techniques, blockchain, Secure Multi-Party Computation (SMPC), image encryption, and image modification.}
    \label{table:2}
    \smallskip
    \smallskip
    \tiny
    \centering
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{l c c c c c c c}
        \toprule
            \bf \multirow{1}{*}[0.5em]{Reference}
        & \bf \multirow{1}{*}[0.5em]{Use case} & \bf \multirow{1}{*}[0.5em]{Model} & \bf \shortstack{Medical \\ dataset/s}  &\bf \multirow{1}{*}[0.5em]{ML task} & \bf \shortstack{Input \\ modality} & \bf \multirow{1}{*}[0.5em]{Validation} & \bf \multirow{1}{*}[0.5em]{Metrics} \\
    
        \midrule
        \multicolumn{8}{c}{\bf FEDERATED LEARNING + DIFFERENTIAL PRIVACY} \\
        \midrule

        \multirow{1}{*}[0.5em]{\citet{A46}} & \shortstack{Cardiomyopathy \\ risk prediction} &\shortstack{Random Forest, \\ Naive Bayes} &\shortstack{iDASH 2021, \\ Breast Cancer TCGA} &\shortstack{Risk \\ prediction} &\multirow{1}{*}[0.5em]{E} &\multirow{1}{*}[0.5em]{\faCheck} &\multirow{1}{*}[0.5em]{AUROC}\\

        \midrule
        \multirow{1}{*}[.7em]{\citet{A71}} &\shortstack{In-hospital \\ mortality prediction} &\multirow{1}{*}[.7em]{CNN} &\shortstack{Premier Healthcare \\ Database*} &\shortstack{Mortality \\ prediction} &\multirow{1}{*}[.7em]{E} &\multirow{1}{*}[.7em]{\faCheck} &\shortstack{AUROC, \\ Overhead} \\

        \midrule
        \multirow{1}{*}[.5em]{\citet{A72}} & \shortstack{COVID-19 \\ patient triage} &\shortstack{ResNet-34 \\DeepCrossNet} & \shortstack{Multi-institution \\chest x-ray and EHR*} &\shortstack{Risk \\ prediction} &\multirow{1}{*}[.5em]{I+E} &\multirow{1}{*}[.5em]{\faCheck \faCheck} &\shortstack{AUROC, Recall, \\ Specificity}\\
        
        \midrule

        \multicolumn{8}{c}{\bf BLOCKCHAIN} \\
        \midrule
        \multirow{1}{*}[0.5em]{\citet{A19}} &\shortstack{Distributed \\ training} &\multirow{1}{*}[0.5em]{ResNet-18} &\multirow{1}{*}[0.5em]{NSCLC-Radiomics} & \shortstack{Binary \\ classification} &\multirow{1}{*}[0.5em]{I} &\multirow{1}{*}[0.5em]{\faCheck \faCheck} &\multirow{1}{*}[0.5em]{AUROC}\\

        \midrule
        \multirow{1}{*}[0.5em]{\citet{A23}} &\shortstack{Disease \\ classification} &\multirow{1}{*}[0.5em]{Neural Network} &\multirow{1}{*}[0.5em]{ Blood transcriptomes*} &\shortstack{Binary \\ classification} &\multirow{1}{*}[0.5em]{E} &\multirow{1}{*}[0.5em]{\faCheck} &\shortstack{Accuracy \\ {}}\\

        \midrule

        \multicolumn{8}{c}{\bf FEDERATED LEARNING+HOMOMORPHIC ENCRYPTION} \\
        \midrule
        \multirow{1}{*}[1.2em]{\citet{extra3}} &\multirow{1}{*}[1.7em]{\shortstack{COVID-19 \\ detection}} &\multirow{1}{*}[1.2em]{CNN} &\multirow{1}{*}[1.2em]{COVID-19 X-ray} &\multirow{1}{*}[1.7em]{\shortstack{Binary \\ classification}} &\multirow{1}{*}[1.2em]{I} &\multirow{1}{*}[1.2em]{\faCheck} &\shortstack{Accuracy, Recall \\ Precision, F1 score, \\ Execution time}\\


        \midrule
        \multicolumn{8}{c}{\bf FEDERATED LEARNING+HOMOMORPHIC ENCRYPTION+SMPC} \\
        \midrule
        
        \multirow{1}{*}[.5em]{\citet{A69}} &\shortstack{Skin cancer \\ classification} &\multirow{1}{*}[.5em]{CNN} &\multirow{1}{*}[.5em]{HAM10000} &\shortstack{Multi-class \\ classification} &\multirow{1}{*}[.5em]{I} &\multirow{1}{*}[.5em]{\faCheck} &\shortstack{Accuracy, \\ Overhead}\\
        
        \midrule
        \multicolumn{8}{c}{\bf SMPC} \\
        \midrule
        
        \multirow{1}{*}[0.5em]{\citet{J10}} &\shortstack{Tumor \\ detection} &\multirow{1}{*}[.5em]{\shortstack{Logistic regression}} &\multirow{1}{*}[.5em]{iDASH 2019} &\shortstack{Binary \\ classification} &\multirow{1}{*}[.5em]{E} &\multirow{1}{*}[.5em]{\faCheck} &\shortstack{Accuracy, \\ Overhead}\\

        \midrule
        \multicolumn{8}{c}{\bf IMAGE ENCRYPTION} \\
        \midrule
        
        \multirow{1}{*}[0.5em]{\citet{A12}} &\shortstack{Brain tumor,  \\ COVID-19} &\shortstack{ DenseNet-121, \\ XceptionNet} &\shortstack{ MRI Brain Tumor, \\ COVID-19 X-ray} & \shortstack{Multi-class \\ classification} &\multirow{1}{*}[0.5em]{I} &\multirow{1}{*}[0.5em]{\faCheck} &\multirow{1}{*}[0.5em]{F1-score}\\

        \midrule
        \multicolumn{8}{c}{\bf IMAGE MODIFICATION} \\
        \midrule
        
        \multirow{1}{*}[0.5em]{\citet{A64}} &\shortstack{Glaucoma \\ recognition} &\shortstack{\shortstack{VGAN-based \\ CNN}} &\shortstack{Warsaw-BioBase \\ Disease-Iris v2.1} &\shortstack{Binary \\ classification} &\multirow{1}{*}[0.5em]{I} &\multirow{1}{*}[0.5em]{\faCheck} &\shortstack{F1-score, \\ Accuracy}\\

        \bottomrule
    \end{tabular}
    }
\end{table}

As observed in Table \ref{table:1}, 
 the most commonly used privacy-preserving approach for model training is FL, either independently or in combination with DP.
% In FL, two or more data owners (e.g., medical institutions) collaborate in the induction of a shared/public model. The learning process is orchestrated by a central entity and does not require the share of the training data by any party (i.e., only the model weight updates are shared). The resulting model will be utilized by the parties for inference on their own data.
DP is added to increase the privacy of the FL training updates i.e., adding noise to the shared weights, thus making the system more robust to privacy threats, such as reconstruction attacks by an external actor intercepting the communication channel or an \emph{honest-but-curious} central server \citep{nguyen2022federated}. 

The second most commonly investigated approach for private training is HE, which leverages encryption schemes to provide privacy with provable mathematical guarantees. However, as described in the previous section, training ML models on encrypted data significantly increases the computational complexity and the processing overhead by several orders of magnitude \citep{extra3, A69}. It also adds noise to the training process due to the approximations of activation functions, especially in large models. 

% In this scenario, the private data of an entity is encrypted and shared with another entity that performs model training using the encrypted data (i.e., cyphertexts) without decrypting them at any training stage. Despite its provable mathematical privacy guarantees, training AI models on encrypted data increases the processing overhead by several orders of magnitude \cite{A10}, the computational resources needed and adds noise to the training process (i.e., especially for large models). 

The third most common approach is standalone DP, which is less computationally demanding and provides strong privacy guarantees. However, the increase in privacy guarantees is negatively correlated with model accuracy, as it is associated with an increase in the quantity of noise applied. Therefore, the trade-off between privacy (i.e., privacy budget) and model accuracy is a relevant factor to take into account for the inclusion of DP in any ML solution. There are other PPML approaches for model training that have been evaluated in related work, including the addition of a blockchain ledger to avoid the centralization of training (i.e., fully distributed learning), image modification to increase data privacy in the context of model explainability, and SMPC as an alternative encryption scheme to HE.

Most of the reviewed studies use a single source of input data i.e., image or EHR and only one medical dataset. Although some studies train their models on several datasets, including popular computer vision benchmarks, the vast majority restrict their evaluation to one input modality from the same dataset.


This limits the generalization of the results and neglects the potential improvement in predictive performance that could result from combining different data sources in multi-modal learning settings \citep{multimodal}. Furthermore, most studies perform internal validation, such that the test sets are from the same distribution as the training dataset. This is generally a common challenge in healthcare applications considering distribution shifts across different hospitals, for example due to differences in patient demographics. Finally, most existing work focuses on convolutional neural networks to handle computer vision tasks. However, validation schemes and metrics reported are not consistent, making the comparison among them very difficult. Due to these reasons and the lack of medical benchmark datasets, a fair comparison of the approaches is difficult, and therefore we do not assess performance metrics results in this review and defer it to future work.

% \textbf{Challenges.} 

\subsection{Privacy-preserving inference for healthcare}
\label{inference}

% Based on the paper inclusion criteria described in Section \ref{introduction}, 
We now focus on the literature employing PPML methods for inference, as summarized in Table~\ref{table:3}. We frame PPML for inference as providing private \emph{machine-learning-as-a-service} (MLaaS) or \emph{inference-as-a-service} (IaaS) \citep{lins2021artificial}. In this scenario, a model with strong performance is controlled by a single party (i.e., model owner), and other external parties (i.e., clients) would like the model to perform inference on their own data. The external parties can share data samples with the model owner and their predictions are sent back. Due to legal and/or ethical constraints related to privacy, clients cannot disclose their data with the model owner, thus requiring the use of PPML to maintain the privacy of the data they wish to share. 

\begin{table}[t]
\renewcommand\thetable{2}
\caption{\small\textbf{Summary of PPML in healthcare for model inference.} We summarize studies that focus on developing PPML in the context of model inference. We group them based on the methodology considered, i.e. homomorphic encryption, combination of federated learning and Secure Multi-Party Computation (SMPC), differential privacy and SMPC, federated learning with blockchain and SMPC, and finally federated learning with differential privacy and homomorphic encryption.}
\label{table:3}
    \smallskip
    \smallskip
    \tiny
    \centering
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{l c c c c c c c c c c}
        \toprule
        \bf \multirow{1}{*}[0.5em]{Reference}
        & \bf \multirow{1}{*}[0.5em]{Use case} & \bf \multirow{1}{*}[0.5em]{Model} & \bf \shortstack{Medical \\ dataset/s}  &\bf \multirow{1}{*}[0.5em]{ML task} & \bf \shortstack{Input \\ modality} & \bf \multirow{1}{*}[0.5em]{Validation} & \bf \multirow{1}{*}[0.5em]{Metrics} \\
        
        \midrule

        \multicolumn{8}{c}{\bf HOMOMORPHIC ENCRYPTION} \\
        \midrule

        \multirow{1}{*}[1.25em]{\citet{A26}} &\shortstack{Breast and \\ cervical cancer \\ classification} &\multirow{1}{*}[1.5em]{\shortstack{Convolutional \\LSTM}} &\multirow{1}{*}[1.6em]{\shortstack{Cervigram Image, \\BreaKHis}} &\shortstack{Binary, \\ Multi-class \\ classification} &\multirow{1}{*}[1.25em]{I} &\multirow{1}{*}[1.25em]{\faCheck} &\multirow{1}{*}[1.25em]{AUROC}\\
        \midrule

        \multirow{1}{*}[1.25em]{\citet{A83}} &\multirow{1}{*}[1.8em]{\shortstack{Breast cancer \\ classification}}  &\multirow{1}{*}[1.8em]{\shortstack{Neural Network, \\SVM}} &\multirow{1}{*}[1.8em]{\shortstack{UCI IRIS,\\UCI Breast Cancer}} &\shortstack{Binary, \\ Multi-class \\ classification} &\multirow{1}{*}[1.25em]{E} &\multirow{1}{*}[1.25em]{\faCheck} &\shortstack{Accuracy,\\ Privacy budget, \\ Overhead}\\

        \midrule

        \multirow{1}{*}[1.2em]{\citet{A65}} &\multirow{1}{*}[1.7em]{\shortstack{Cancer inference \\ via gene expression}} &\shortstack{SVM, \\ Logistic regression, \\ Neural Network} &\multirow{1}{*}[1.2em]{iDASH 2020} &\multirow{1}{*}[1.7em]{\shortstack{Multi-class \\ classification}} &\multirow{1}{*}[1.2em]{E} &\multirow{1}{*}[1.2em]{\faCheck \faCheck} &\multirow{1}{*}[1.2em]{Accuracy, AUROC} \\
        \midrule

         \multirow{1}{*}[1.2em]{\citet{A7}} &\shortstack{Coronary\\ angiography view \\ classification} &\multirow{1}{*}[1.2em]{CNN} &\multirow{1}{*}[2em]{\shortstack{X-ray coronary \\ angiography*}} &\shortstack{Binary, \\ Multi-class \\ classification} &\multirow{1}{*}[1.2em]{I} &\multirow{1}{*}[1.2em]{\faCheck} &\multirow{1}{*}[1.5em]{Accuracy}\\
        \midrule

        \multicolumn{8}{c}{\bf FEDERATED LEARNING + SMPC} \\
        \midrule
        
        \shortstack{\citet{A1}, \\ \citet{A4}+} &\shortstack{Paediatric chest \\X-ray classification}  & \multirow{1}{*}[0.5em]{ResNet-18} &\multirow{1}{*}[0.5em]{Chest X-ray*} & \shortstack{Multi-class \\ classification} & \multirow{1}{*}[0.5em]{I} &\multirow{1}{*}[0.5em]{\faCheck \faCheck} &\multirow{1}{*}[0.5em]{AUROC, Latency} \\
        %\midrule
        %\multirow{1}{*}[1.25em]{\citet{A4}+} &\shortstack{Pediatric chest \\x-ray classification \\{}} &\multirow{1}{*}[1.25em]{ResNet-18} &\shortstack{ Optical Coherence \\ Tomography,\\ Chest X-Ray} &\multirow{1}{*}[1.25em]{Multi-class} &\multirow{1}{*}[1.25em]{I} &\multirow{1}{*}[1.25em]{\faCheck \faCheck} &\shortstack{AUROC \\ Latency \\{}}\\
        \midrule

        \multicolumn{8}{c}{\bf DIFFERENTIAL PRIVACY + SMPC} \\
        \midrule
        \multirow{1}{*}[0.6em]{\citet{A50}} &\shortstack{Pneumonia \\ detection} &\shortstack{CNN, \\ VGG-16} &\shortstack{Kaggle X-ray \\ Pneumonia} &\shortstack{Binary \\ classification} &\multirow{1}{*}[0.6em]{I} &\multirow{1}{*}[0.6em]{\faCheck} &\multirow{1}{*}[0.6em]{Accuracy}\\
        
        \midrule
        \multirow{1}{*}[1.2em]{\citet{A82}} &\multirow{1}{*}[1.7em]{\shortstack{Accuracy-privacy \\ trade-off analysis}} &\multirow{1}{*}[1.2em]{Neural Network} &\multirow{1}{*}[1.7em]{\shortstack{Kaggle IDC, \\MIMIC-III}} &\shortstack{Binary, \\ Multi-class \\ classification} &\multirow{1}{*}[1.2em]{I} &\multirow{1}{*}[1.2em]{\faCheck} &\multirow{1}{*}[1.7em]{\shortstack{Accuracy, Recall \\ Precision, Privacy}} \\
        \midrule

        \multicolumn{8}{c}{\bf FEDERATED LEARNING + BLOCKCHAIN + SMPC} \\
        \midrule
        
        \multirow{1}{*}[1.25em]{\citet{A57}} &\multirow{1}{*}[1.75em]{\shortstack{Multiple medical image \\ datasets classification}} &\multirow{1}{*}[1.25em]{CNN} &\shortstack{MedMNIST (CXR, \\ Breast, Hand, ChestCT, \\ Abdomen, HeadCT)} &\multirow{1}{*}[1.75em]{\shortstack{Multi-class \\ classification}} &\multirow{1}{*}[1.25em]{I} &\multirow{1}{*}[1.25em]{\faCheck} &\multirow{1}{*}[1.25em]{Accuracy}\\
        
        \midrule

        \multicolumn{8}{c}{\bf FEDERATED LEARNING + DIFFERENTIAL PRIVACY + HOMOMORPHIC ENCRYPTION} \\
        \midrule
        
        \multirow{1}{*}[1.25em]{\citet{A80}} &\multirow{1}{*}[1.7em]{\shortstack{Multiple medical image \\ datasets classification}} &\multirow{1}{*}[1.25em]{CNN} &\multirow{1}{*}[1.7em]{\shortstack{MedMNIST (Pneumonia \\ Breast, Retina, Blood)}}
        &\multirow{1}{*}[1.7em]{\shortstack{Multi-class \\ classification}} &\multirow{1}{*}[1.25em]{I} &\multirow{1}{*}[1.25em]{\faCheck} &\shortstack{ Accuracy, \\ Execution time, \\ Bandwidth}\\
        
        \bottomrule
        \multicolumn{8}{l}{+ \citet{A4} is an extension of \citet{A1}.}
    \end{tabular}
    }%\vspace{-5mm}
\end{table}


% As it can be seen from Table \ref{table:3}, 
Compared to the number of studies addressing PPML for training, a relatively fewer number have explored PPML for inference. Most studies within the theme of PPML for inference, focus on the deployment of the trained model as a service and its use by third parties. The most common approach for delivering PPML IaaS is HE, which ensures with provable mathematical guarantees that neither the model owner nor any intermediate party are able to inspect the original data nor the detection result i.e., both are encrypted and can only be decrypted by the data owner. Another common approach is SMPC, which also leverages encryption schemes, being used in combination with other privacy-preserving collaborative approaches such as FL, DP and blockchain. 
 %The main distinction between the work of this section and the studies from Section \ref{training} is the focus of the research. While work included in both sections perform training and validation/inference steps, as required by the ML development cycle, studies in Section \ref{training} focus on model induction, whereas studies included in this section focus on 

Similar to PPML for training, most studies here use a single source of input data (i.e., images in most cases), neglecting many other diverse medical modalities of varying characteristics. The lack of use of benchmark medical datasets and inconsistent validation schemes and metrics hinders the generalization of the proposed approaches.

%\vspace{-5mm}
\subsection{Open challenges}
% Create subsections here!
\textbf{There is no \emph{one-size-fits-all} PPML approach for model training or inference by design.} We observe that previous work pick and choose PPML approaches based on the intended clinical use case. Currently, there is no consensus on what different ``privacy models" look like in healthcare. Since the methodology depends on the use case, we also observe a clear trade-off between privacy and accuracy, based on the availability of computational resources. For instance, standalone FL is computationally faster than HE, but it does not provide strong privacy guarantees. On the other hand, HE and DP can provide strong privacy guarantees but they add noise to the model both for private training and private inference resulting in less accurate solutions. For HE, this is especially critical for model training where successive layers of approximations are needed to perform operations that are not supported, such as \emph{softmax}, or that are computationally inefficient, such as max pooling. In general, encryption-based options are provably secure but computationally inefficient, since they increase the processing overhead of training using cyphertext compared to plaintext data.

Additionally, the availability of computational resources is a decisive factor in choosing a particular PPML methodology. For instance, in the HE scenario, sending data over a communication channel does not require infrastructure for model training but still requires handling the encryption/decryption process appropriately. In the FL context, it requires that the entity has allocated resources for model training.

\textbf{The centralization of model training in FL poses an additional security threat.} Relying on a single central server entails a single point of failure that is highly susceptible to security attacks such as Denial-of-Service. Although blockchain has been proposed to achieve fully distributed training and mitigate this threat, it increases the complexity of the information technology infrastructure significantly, requiring dedicated resources for the implementation of the distributed ledger and modeling framework.

\textbf{Most existing work use a single dataset and do not conduct external validation, thus arising concerns about the generalization of the results.} We observe that existing work focus on a limited set of medical datasets. Additionally, some work only evaluate their solutions on computer vision benchmark datasets (e.g., \emph{MNIST} or \emph{CIFAR-10}) inferring that good performance on these datasets will provide similar results on medical image data \citep{festag2020privacy, andrew2020efficient}. However, this assumption is not empirically supported by work that uses both medical and non-medical datasets \citep{A67, A10, A80, A82, A7} and must, therefore, be avoided.

\textbf{MLaaS for healthcare has not been explored thoroughly.} As demonstrated by the limited literature on this topic, we observe that the literature is highly skewed towards PPML for training. Considering disparities in technical capabilities and expertise, information technology resources, and availability of data across medical institutions, the case in which an entity does not have enough resources to perform model training independently is highly likely. Thus, the usage of third-party models as inference systems that can run on proprietary data is a prominent scenario that has not been thoroughly explored and should be considered in future research. MLaaS can provide access to models with strong performance, enabling full preservation of data privacy using PPML methods. This makes it a more efficient solution for small-scale or low-resource medical entities to access and leverage third-party knowledge.


% As a result, PPML for medical inference is an actual and relevant domain that has not attracted the required attention by the research community. 
% Further research is also needed on the optimization of encryption-based solutions which are computationally intensive resulting in a large time overhead. A major issue if results need to be delivered fast. 
% However, MLaaS for healthcare is not technically challenging for client institutions and 

\section{Future research directions}
\label{future}
%The previous sections have introduced and summarized the state-of-the-art (SOTA) in privacy-preserving methods applied to the healthcare domain. 
% Based on our extensive review, we have 
%Having identified research gaps and methodological challenges faced by the state-of-the-art, in this section, we suggest relevant future research directions for the healthcare research community. %. Our aim is that 
%that ca serve as guidelines
% for researchers to set and update their objectives in line with current research gaps and challenges, 
%to address privacy-related issues as an essential element 
% for the success of real implementations. %n the following paragraphs we describe future research directions to enhance privacy-preserving healthcare applications. 
%to develop powerful ML systems that ensure private, secure, and efficient solutions for the different areas of medical delivery.

\subsection{Comprehensive evaluation on diverse medical datasets}

% We have discussed that the use of medical datasets presents a lot of challenges, mainly because of increased regulations related to the use of sensitive patient data. With this point in mind, we observe that the research groups included in this review show a clear trend in the type, and specially the amount, of medical datasets used in their methods. We consider that there is a lot of improvement to be done in terms of external evaluations of the research methods via more diverse and heterogeneous medical datasets. 

%We have identified some of the most popular datasets used for training AI models within different areas of medical research. In particular, we note the recurrent use of the UCI Machine Learning Repository \citet{uci}, the Chest X-ray imaging datasets popularized by research efforts during the COVID19 pandemic, the Physio Net ECG datasets \citet{physionet}, the MIMIC-III clinical database \citet{mimiciii} which contains multimodal data, the \href{http://www.humangenomeprivacy.org/2022/about.html}{NIH iDASH} gene expression datasets and the dermatology dataset HAM10000 \citet{eljamon}. 

For the sake of comparison and generalization of results, studies should complement their internal dataset evaluation with additional extensive evaluation on benchmark medical datasets. This is due to the fact that most of the existing work use a single dataset and do not perform external validation. The number of studies that use external datasets for validation is marginal. Only 9 out of the 40 studies considered validated their results with an independent test set. 
%, which would enable the comparison of methodologies and results across studies. 
 %external dataset. %, be it for inference or training. 
This hampers model generalization and hinders performance comparison among approaches built for the same medical task.
%Besides, the usage of common benchmark datasets  to expand the validation of the proposed solutions and enable direct comparison. 
%To develop robust systems, medical data benchmarks must be applied broadly to methodologies for privacy-preserving healthcare systems. However, most works presented in this review of the state-of-the-art, perform a very limited validation of their algorithms. 
For benchmarking, %We note the recent publication of the medical dataset 
we suggest \emph{MedMNIST} \citep{medmnist}, which contains curated datasets for different medical tasks and modalities. %Thus,
Therefore, similar to \emph{MNIST} or \emph{CIFAR-10} for computer vision models, this medical dataset could be employed as a common benchmark for medical applications. 

%Lastly, some medical datasets such as MIMIC-III and others included in the UCI repository are relatively old (i.e., some dating back to 20-30 years), which challenges the validity of the results and its detection capabilities on actual data.   

%Even though the assessment of quality of open source medical datasets is out of the scope of this study, we must note that the medical datasets contained in the UCI Machine Learning Repository have the disadvantage of containing data from the previous 2 or 3 decades. In terms of MIMIC-III, the official website states the following: "We highly recommend researchers starting new studies to use the above modules in MIMIC-IV. We will maintain MIMIC-III for a short period to allow researchers to transition.". This clearly raises doubts, not necessarily about the validity of results, but about the pertinence of using outdated information to deal with current problematic, the bias this may incur in order to ensure the development of high performing machine learning systems.

 % Certainly, the use of imaging in health care is one of the main modalities for correct assesment of different pathologies. However, for a lot of research groups, the use of this particular CXR dataset was mainly focus on the validation of the privacy-preserving methods using a well know ResNet18 architecture which is a staple model for computer vision problems. Validation, benchmarks, MedMNIST, not just CXR or simulated, potential for bias

%Making use of datasets that cover a broad spectrum of pathologies and data modalities provides an extensive evaluation a correct focus on the performance of the healthcare applications and not just traditional benchmarks for machine learning models.

\subsection{Multi-modal models}
% tradeoffs in terms of privacy
Current advances in ML for healthcare are moving towards multi-modal learning, where several sources of information are combined to improve performance \citep{multimodal, multimodal2}. This approach not only tends to provide better performance but also ensures a comprehensive understanding of the different physiological variables involved in studying and modeling the development of human biology and pathology. As observed in Sections \ref{training} and \ref{inference}, most work is restricted to a single modality. To develop robust and strong ML models, the use of different data sources to develop multi-modal systems is paramount. Notwithstanding that, the use of more clinical data entails more privacy concerns (e.g., individuals may be identified using correlated data) and requires more training resources due to increased model complexity. Therefore, additional privacy and computational constraints must be considered in the design of these algorithms.


%there is a trade-off between the performance of privacy methods and the use different data modalities. 

%Hardware and algorithmic constraints are the main reason for studies to choose single-modality datasets for their models. However, future research should focus in developing multi-modal solutions that correctly quantify, benchmark and adapt to the trade-off between the complexity of using multi-modal data and the performance metrics of privacy-preserving methods.

\subsection{Machine learning as a service (MLaaS)}

The deployment of PPML within MLaaS is a very promising opportunity to access strong proprietary models by less resourceful institutions. Indeed, one of the main objectives of ML in healthcare is to develop efficient and scalable solutions that improve healthcare delivery. In addition to lack of resources, the deployment of these systems in medical settings can also be highly challenging \citep{mlopsgral, mlopshealth}. The development of MLaaS is significantly less investigated than PPML for model training. Therefore, further research on this topic is required to provide secure, private and efficient data sharing between third-party model providers and client institutions. Reducing obstacles for clinical institutions to access powerful inference systems could lead to a major improvement in healthcare delivery across regions, bypassing physical barriers. It can also lead to an increase in the confidence and widespread adoption of ML in healthcare. It is important to note that the success of MLaaS is dependent on improvements in model generalizability and fairness in external datasets.

% There is very little work within the scope of MLaaS in order to simplify the life cycle of machine learning systems deployed, not only in the healthcare domain

% Federated Learning (FL) is the mainstream approach for adopting privacy-preserving machine learning for healthcare. Most of the studies listed, make use of a variation of FL  which involves different software engineering considerations in order to be correctly implemented.

% most papers focus on FL (if you rely on central service)

\subsection{Integration of SOTA and advances in deep learning}

% usage of transformer and other advancements in deep learning in the applications
 
Future work should also investigate the integration of recent advances in DL and ML models in healthcare, considering that most of the current PPML work focuses on convolutional neural networks. For instance, the \emph{Transformer} architecture and its variants \citep{dosovitskiy2020image}, which are considered the current SOTA for many computer vision or natural language processing tasks, are only adopted by \citet{postreview1}, \citet{A75}, and \citet{postreview2} in the current related literature. %considered in only one of the works included in Section \ref{training} and Section \ref{inference} used this type of architecture in their methodology \citep{A75}, 
 Adopting SOTA architectures can take advantage of the latest advances in research, both in terms of optimizing hardware and software, to maintain performance improvements in clinical prediction tasks.

%Solutions developed using the newest models and architectures can optimize the resources at their disposal while ensuring higher (and usually better) performance for medical inference. 
%which shows the little adoption of novel methods in the design and test of PPML methods for healthcare applications e.g., most image-based solutions use custom convolutional neural networks, neglecting the SOTA for computer vision, the \emph{Vision Transformer} .

\subsection{Global and local explainability}
Transparency and model explainability are essential for trustworthy artificial intelligence \citep{transparency}. However, PPML methods, such as data encryption or noise addition, hinder global model and local prediction explainability. The collision between two key principles for trustworthy artificial intelligence, secure and PPML \citep{secure} and explainability, highlights an important research problem that is currently under-investigated. Only \citet{A64} attempt to address this problem, which should encourage future work in this research direction.


%The so-called foundation models \citep{foundational}, which do not represent novel architectures but rather models trained on broad data and are applicable to a large set of different tasks, have been greatly improved by the implementation of the Transformer architecture \citep{attention}. 
%In this regard, only 

%Traditional ML algorithms like logistic regression and SVM and mainstream deep learning algorithms, such as CNNs and ResNets, can certainly provide excellent overall performance on specific tasks. However, 


\section{Conclusion}
\label{conclusions}
In this paper, we introduce and summarize recent literature concerning PPML for model training and inference in the healthcare domain. We highlight trends, challenges and promising future research directions. In conclusion, we recognize the lack of consensus when it comes to defining the requirements of privacy-preserving frameworks in healthcare. This requires collaboration between machine learning scientists, healthcare practitioners, and privacy and security experts. From the perspective of advancing ML approaches, we encourage researchers to perform comprehensive evaluation of proposed algorithms on diverse medical datasets to increase generalization, to investigate the constraints of PPML in multi-modal learning settings, to further consider the promise of MLaaS in healthcare as a catalyst for improved healthcare delivery, and to adopt state-of-the-art advances in deep learning architectures to enhance model performance. Our suggestions aim to address research gaps and guide future research in PPML to facilitate the future adoption of trustworthy and private ML for healthcare.



% \subsubsection*{Acknowledgments}
% Use unnumbered third level headings for the acknowledgments. All
% acknowledgments, including those to funding agencies, go at the end of the paper.
\newpage
\bibliography{iclr2023_conference}
\bibliographystyle{iclr2023_conference}

%\appendix
%\section{Appendix}
%You may include other additional sections here.

\end{document}
