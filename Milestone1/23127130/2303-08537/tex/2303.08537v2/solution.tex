\section{Methodology}
\label{sec:solution}
In this section, we elaborate the technical details of our proposed \model\ framework, whose workflow is depicted in Figure~\ref{fig:framework}.

% introduce our proposed \model\ framework, which conducts contrastive knowledge distillation (KD) to alleviate the over-smoothing issue and improving model efficiency for graph-based CF models. The framework of \model\ is illustrated in Fig~\ref{fig:framework}.
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{figs/framework.pdf}
    \vspace{-0.15in}
    \caption{Model architecture of the proposed \model\ framework.}
    \vspace{-0.1in}
    \label{fig:framework}
    \Description{The architecture of the proposed \model\ model, consisting the GNN teacher, the MLP student, and the bi-level alignment: the prediction-level and the embedding-level knowledge distillation.}
\end{figure*}

\subsection{Contrastive Knowledge Distillation}
For the model design, we are motivated by the advantages of i) GNNs in learning structure-aware node embeddings, and ii) efficient MLPs in preventing over-smoothing issue. Towards this end, we propose to distill knowledge from a GNN-based teacher model to a MLP-based student model. Specifically, the teacher model is a lightweight Graph Convolutional Network (GCN)~\cite{he2020lightgcn,wu2021self,cailightgcl} whose embedding process is shown with the following propagation:
\begin{align}
    \textbf{H}^{(t)}=\sum_{l=0}^L\textbf{H}^{(t)}_{l},~~~ \textbf{H}^{(t)}_{l+1} = \textbf{D}^{-\frac{1}{2}} (\bar{\textbf{A}} + \textbf{I} )\textbf{D}^{-\frac{1}{2}}\cdot \textbf{H}^{(t)}_{l}
\end{align}
where $\textbf{H}^{(t)}\in\mathbb{R}^{(I+J)\times d}$ denotes the embedding matrix given by the teacher model. Index $l$ indicates the number of graph neural iterations (totally $L$ iterations). $\bar{\textbf{A}}\in\mathbb{R}^{(I+J)\times (I+J)}$ denotes the symmetric adjacent matrix for graph $\mathcal{G}$ generated from the interaction matrix $\textbf{A}$ ~\cite{wang2019neural}. $\textbf{I}$ denotes the identity matrix, and $\textbf{D}$ denotes the diagonal degree matrix of $\bar{\textbf{A}}$. The iteration is initialized by $\textbf{H}^{(t)}_{0}=\bar{\textbf{H}}^{(t)}$.
The student model uses a shared MLP network to extract features from the initial embeddings for both users and items. For user $u_i$, the embedding layer is formally presented as follows:
\begin{align}
    \textbf{h}^{(s)}_i=\textbf{FC}^{L'}(\bar{\textbf{h}}^{(s)}_i),~~~~ \textbf{FC}(\bar{\textbf{h}}^{(s)}_i)=\delta(\textbf{W} \bar{\textbf{h}}^{(s)}_i) + \bar{\textbf{h}}^{(s)}_i
\end{align}
\noindent where $\textbf{h}_i^{(s)}, \bar{\textbf{h}}_i^{(s)}\in\mathbb{R}^d$ denotes embeddings for $u_i$ given by the student. $\textbf{FC}(\cdot)$ denotes the fully-connected layer. $L'$ is the number of FC layers. An FC layer is configured with one transformation $\textbf{W}\in\mathbb{R}^{d\times d}$. LeakyReLU activation $\delta(\cdot)$, and a residual connection~\cite{he2016deep} are applied. Item-side embedding layer is built analogously.

\subsubsection{\bf Prediction-Level Distillation}
To distill knowledge from the teacher model to the student model, \model\ first follows the paradigm of KL-divergence-based KD~\cite{hinton2015distilling} to align the predictive outputs between the teacher and student models. Inspired by the success of ranking-oriented BPR loss~\cite{rendle2009bpr} in recommender systems, \model\ aligns the two models on the task of ranking user preference. Specifically, in each training step, we randomly sample a batch of triplets $\mathcal{T}_1=\{(u_i,v_j,v_k)\}$, where $u_i, v_j, v_k$ are individually sampled from the holistic user and item set with uniform probability. Then \model\ calculates the preference difference between $(u_i, v_j)$ and $(u_i, v_k)$ for both models, as follows:
\begin{align}
    \label{eq:difference}
    z_{i,j,k} = y_{i,j}-y_{i,k}= \textbf{h}_{i}^{\top}\textbf{h}_{j} - \textbf{h}_{i}^\top\textbf{h}_{k}
\end{align}
where $z_{i,j,k}\in\mathbb{R}$ denotes the difference scores of user preferences for triplet $(u_i, v_j, v_k)$. We denote the score given by the student model as $z_{i,j,k}^{(s)}$ and denote the score given by the teacher model as $z_{i,j,k}^{(t)}$. Then, the prediction-oriented distillation is conducted by minimizing the following loss function:
\begin{align}
    \label{eq:l1}
    \mathcal{L}_1=&\sum\limits_{(u_i,v_j,v_k)\in\mathcal{T}_1}-\left(\bar{z}_{i,j,k}^{(t)} \cdot \log\bar{z}_{i,j,k}^{(s)} + (1 - \bar{z}_{i,j,k}^{(t)}) \cdot \log(1 - \bar{z}_{i,j,k}^{(s)})\right)\nonumber\\
    &\bar{z}_{i,j,k}^{(t)}=\text{sigm}(z_{i,j,k}^{(t)} / \tau_1),~~~~~
    \bar{z}_{i,j,k}^{(s)}=\text{sigm}(z_{i,j,k}^{(s)} / \tau_1)
\end{align}
\noindent where $\bar{z}_{i,j,k}^{(t)}, \bar{z}_{i,j,k}^{(s)}$ are preference differences processed by sigmoid function $\text{sigm}(\cdot)$ with temperature factor $\tau_1$. Here, $z_{i,j,k}^{(t)}$ is given by well-trained teacher model and does not back-propagate gradients. With the help of prediction-oriented distillation $\mathcal{L}_1$, simple MLPs learn to mimic the predictions of advanced GNN models and thus directly generate recommendation results. Through this end-to-end supervision, the parameters of student model are optimized to preserve the knowledge distilled from the teacher model.

It is worth noting that, our prediction-level KD differs from vanilla KD in its training sample enrichment for deep \emph{dark knowledge} learning~\cite{saputra2019distilling, clark2019bam} in CF. Specifically, vanilla KD for multi-class classification~\cite{hinton2015distilling} mines dark knowledge from not only the class with highest score, but also from the ranks for all classes. However, treating CF as multi-classification is problematic, as there are too many classes (items), such that the soft labels easily approach zero and become hard to rank. 
To solve it, our prediction-level KD adopts the pair-wise ranking task instead, and excavates the dark knowledge by distilling from \emph{enriched samples}. Unlike BPR-based model training which pairs each positive item with one negative item, our KD scheme learns from the teacher's predictions on $v_j, v_k$ individually sampled from the holistic item set. Here $v_j, v_k$ are not fixed to be positive or negative. This greatly enriches the training set for our KD and facilitate deeper dark knowledge distillation.

\subsubsection{\bf Embedding-Level Distillation}
Despite the efficacy, the above prediction-level distillation only supervises the model outputs, but ignores the potential difference of embedding distributions between the student and teacher. As both models follow the embedding and prediction schema in Eq~\ref{eq:cf}, we extend the KD paradigm in \model\ with an embedding-level knowledge transferring based on contrastive learning. Specifically, we sample a batch of users and items $\mathcal{T}_2=\{u_i, v_j\}$ from the observed interactions in each training step. Then, we apply the following contrastive loss on the corresponding user/item embeddings:
\begin{align}
    \label{eq:l2}
    \mathcal{L}_2&=
    % \sum_{u_i,v_j\in\mathcal{T}_2} 
    \sum_{u_i\in\mathcal{T}_2}
    -\log\frac{\exp\left(\cos(\textbf{h}^{(s)}_i, \sum_{l=2}^L\textbf{h}^{(t)}_{i,l})/ \tau_2\right)}{\sum_{u_{i'}\in\mathcal{U}}\exp\left(\cos(\textbf{h}^{(s)}_{i'}, \sum_{l=2}^L\textbf{h}^{(t)}_{i,l}) / \tau_2\right)}\nonumber\\
    & +\sum_{v_j\in\mathcal{T}_2}
    -\log\frac{\exp\left(\cos(\textbf{h}^{(s)}_j, \sum_{l=2}^L\textbf{h}^{(t)}_{j,l})/ \tau_2 \right)}{\sum_{v_{j'}\in\mathcal{V}}\exp\left(\cos(\textbf{h}^{(s)}_{j'}, \sum_{l=2}^L\textbf{h}^{(t)}_{j,l})/ \tau_2\right)}
\end{align}
\noindent where $\cos(\cdot)$ denotes the cosine similarity function. $\tau_2$ represents the temperature hyperparameter. To force the student model to learn more from the high-order patterns which MLP-based CF lacks, here we only use the high-order node embeddings from the teacher. Embeddings of the teacher are well-trained and fixed in parameter optimization. Through directly regularizing the hidden embeddings with this embedding-oriented distillation, \model\ not only further improves the performance of student model, but also greatly accelerates the cross-model distillation, which has been validated in our empirical evaluations.

\subsection{Adaptive Contrastive Regularization}
To prevent transferring over-smoothed signals from the GNN-based teacher to the student model, \model\ proposes to regularize the embedding learning of the student by universally minimizing the node-wise similarity. Specially, \model\ adaptively locates which nodes are more likely being over-smoothed by comparing the gradients of distillation tasks with the main task gradients. In particular, we reuse the sampled users and items $\mathcal{T}_2$ from the embedding-level distillation, and apply the following adaptive contrastive regularization for node embeddings of the student model:
\begin{align}
    \label{eq:l3}
    \mathcal{L}_3=&\sum_{u_i\in\mathcal{T}_2}\varphi(u_i, \mathcal{U}, \omega_i) + \varphi(u_i, \mathcal{V}, \omega_i) + \sum_{v_j\in\mathcal{T}_2}\varphi(v_j, \mathcal{V}, \omega_j)\nonumber\\
    &\varphi(u_i, \mathcal{U},\omega_i) = \omega_i \cdot \log\sum_{u_{i'}\in\mathcal{U}} \exp (\textbf{h}_i^{(s)\top} \textbf{h}_{i'}^{(s)} / \tau_3)
\end{align}
\noindent where the loss $\mathcal{L}_3$ is composed of three terms ($\varphi(\cdot)$) that pushes away the user-user distance, the user-item distance, and the item-item distance, respectively. The first term $\varphi(u_i, \mathcal{U}, \omega_i)$ minimizes the dot-product similarity between the embedding of $u_i$ and the embedding of each user $u_{i'}$ in $\mathcal{U}$, with a weighting factor $\omega_i$. Here, the similarity score is adjusted with the temperature hyperparameter $\tau_3$. The $\phi(\cdot)$ functions for user-item relations and item-item relations work analogously. The weighting factor $\omega_i, \omega_j$ correspond to $u_i, v_j$ respectively, and the weight is calculated as follows:
\begin{align}
    \label{eq:omega}
    \omega_i=\left\{
    \begin{aligned}
        &1-\varepsilon~~~~~\text{if} \bigtriangledown_i^{1,2\top}\bigtriangledown_i^\text{rec}>\bigtriangledown_i^{1^\top}\bigtriangledown_i^2\\
        &1+\varepsilon~~~~~\text{otherwise}
    \end{aligned}
    \right.~~~~~
    &\bigtriangledown_i^{\text{rec}}=\frac{\partial\mathcal{L}_\text{rec}}{\partial\textbf{h}_i^{(s)}}
    \nonumber\\
    \bigtriangledown_i^{1,2}=\frac{\partial(\mathcal{L}_1+\mathcal{L}_2)}{\partial\textbf{h}_i^{(s)}},~~~~~~
    \bigtriangledown_i^{1}=\frac{\partial\mathcal{L}_1}{\partial\textbf{h}_i^{(s)}}, ~~~~~~
    &\bigtriangledown_i^{2}=\frac{\partial\mathcal{L}_2}{\partial\textbf{h}_i^{(s)}}
\end{align}
\noindent where $\omega_i\in\mathbb{R}$ adjusts the weight of contrastive regularization for user $u_i$. In brief, $\omega_i$ has the larger value (\ie, $1+\epsilon$) when the gradients given by distillation tasks (which may over-smooth) contradict to the gradients generated by the main task (which hardly over-smooth). Here, $0<\epsilon<1$ is a hyperparameter. $\bigtriangledown_i\in\mathbb{R}^d$ denotes the gradients for the embedding vector $\textbf{h}_i$ \wrt, different optimization tasks. For example, $\bigtriangledown_i^{1,2}$ denotes the compound gradients of the two distillation task objectives $\mathcal{L}_1$ and $\mathcal{L}_2$. $\bigtriangledown_i^\text{rec}$ denotes gradient of the recommendation task, which is independent to the GNN-based teacher and thus has no risk of over-smoothing. The task $\mathcal{L}_\text{rec}$ will be elaborated later. The similarity between the gradients is estimated using dot-product. When the similarity between the distillation tasks and the recommendation task, is larger than the similarity between two distillation tasks, we can assume that the difference in optimization between the distillation and the recommendation is small enough to weaken the regularization.

\subsection{Parameter Learning of \model}
Following the training paradigm of knowledge distillation, our \model\ first trains the GNN-based teacher model until convergence. In each step, \model\ samples a batch of triplets $\mathcal{T}_\text{bpr} = \{(u_i,v_j,v_k)|a_{i,j}=1, a_{i,k}=0\}$ where $u_i$ denotes anchor user. $v_j$ and $v_k$ denotes positive item and negative item, respectively. The BPR loss function~\cite{rendle2009bpr} is applied on the sampled data as follows:
\begin{align}
    \label{eq:teacher_bpr}
    \mathcal{L}^{(t)}=-\sum_{(u_i,v_j,v_k)\in\mathcal{T}_\text{bpr}}\log\text{sigm}(y^{(t)}_{i,j}-y^{(t)}_{i,k}) + \lambda^{(t)}\|\bar{\textbf{H}}^{(t)}\|_\text{F}^2
\end{align}
\noindent where the last term denotes the weight-decay regularization with weight $\lambda^{(t)}$ for preventing over-fitting.

Then, \model\ conducts joint training to optimize the parameters of the MLP-based student, during which the structure-aware node representations are distilled from advanced GNNs to over-smoothness-resistant MLPs. The training process is elaborated in~\ref{sec:learn_alg}. Strengthened by the two distillation tasks and the regularization terms, the overall optimization objective is presented:
\begin{align}
    \mathcal{L}^{(s)}&=\mathcal{L}_\text{rec} + \lambda_1\cdot \mathcal{L}_1 + \lambda_2\cdot \mathcal{L}_2 + \lambda_3\cdot \mathcal{L}_3 + \lambda_4\cdot\mathcal{L}_4\nonumber\\
    \mathcal{L}_\text{rec} &= -\sum\nolimits_{(u_i,v_j)\in\mathcal{T}_2} y_{i,j},~~~~~~~
    \mathcal{L}_4 = \|\bar{\textbf{H}}^{(s)}\|_\text{F}^2% + \|\textbf{W}\|_\text{F}^2
\end{align}
\noindent where $\lambda_1, \lambda_2, \lambda_3, \lambda_4$ are weights for different optimization terms. $\mathcal{T}_2$ denotes the aforementioned set containing user-item pairs sampled from the observed interactions $\mathcal{E}$. As the contrastive regularization $\mathcal{L}_3$ minimizes the similarity between negative user-item pairs, the recommendation objective $\mathcal{L}_\text{rec}$ only maximizes the similarity between positive user-item pairs. $\mathcal{L}_4$ denotes the weight-decay regularization for the MLP neural network.

\subsection{Further Discussion of \model}
\subsubsection{\bf Adaptive High-Order Smoothing via KD}
\label{sec:highorder_smoothing}
An important strength of GNN-based CF lies in its ability to smooth user/item embeddings using their high-order neighbors. Through derivation, we show our method is able to perform the high-order smoothing in an adaptive manner. Detailed derivations are presented in~\ref{sec:embed_analysis}. In brief, for our light-weight GCN teacher, the embedding parameters $\bar{\textbf{h}}_i^{(t)}, \bar{\textbf{h}}_j^{(t)}$ of two nodes $n_i, n_j$ (either user or item nodes) are smoothed using each other, when minimizing the following terms from the BPR loss $\mathcal{L}^{(t)}$ in Eq~\ref{eq:teacher_bpr}:
% we show that not only can our distillation-based method also fulfills the high-order smoothing, it can even do it in a learnable and more adaptive manner. Detailed derivations are presented in~\ref{sec:embed_analysis}. In brief, for our light-weight GCN teacher, the embedding parameters $\bar{\textbf{h}}_i^{(t)}, \bar{\textbf{h}}_j^{(t)}$ of two nodes $n_i, n_j$ (either user or item nodes) are smoothed using each other, when minimizing the following terms from the BPR loss $\mathcal{L}^{(t)}$ in Eq~\ref{eq:teacher_bpr}:
\begin{align}
    \label{eq:gcn_gradient}
    \frac{\partial\mathcal{L}^{(t)}_{i,j}}{\partial\bar{\textbf{h}}_i^{(t)}} &= \sum_{v_k}- \sigma \cdot
    \Big(\sum_{\mathcal{P}_{i,j}^{2L}} \prod_{(n_a,n_b)\in\mathcal{P}_{i,j}^{2L}} \frac{1}{\sqrt{d_a d_b}}\Big)\cdot
    \frac{\partial\bar{\textbf{h}}_i^{(t)\top}\bar{\textbf{h}}_j^{(t)}}{\partial \bar{\textbf{h}}_i^{(t)}}
\end{align}
\noindent where $\mathcal{L}_{i,j}^{(t)}$ denotes the terms that pull close the embeddings of $n_i$ and $n_j$ in loss $\mathcal{L}^{(t)}$. $\sigma\in(0,1)$ is a BPR-relevant factor. $\mathcal{P}_{i,j}^{2L}$ represents a possible path between $n_i$ and $n_j$ with maximum length $2L$. $d_a, d_b$ denotes the node degrees of $n_a$ and $n_b$, respectively. Eq~\ref{eq:gcn_gradient} reveals that GCNs smooth embeddings for high-order nodes with weighted gradients. The weights (\ie, the bracketed part) encode how closely nodes are connected via multi-hop graph walks.
Similarly, we analyze the gradients from our prediction-level KD $\mathcal{L}_1$ over embedding parameters $\textbf{h}_i^{(s)}$, as follows:
\begin{align}
    \label{eq:pd_gradient}
    \frac{\partial\mathcal{L}_{i,j}^{(1)}}{\partial{\textbf{h}}_i^{(s)}} = \sum_{v_k} -\frac{1}{\tau_1} \cdot (\bar{z}_{i,j,k}^{(t)} - \bar{z}_{i,j,k}^{(s)}) \cdot \frac{\partial\textbf{h}_i^{(s)\top} \textbf{h}_j^{(s)}}{\partial\textbf{h}_i^{(s)}}
\end{align}
\noindent where $\mathcal{L}_{i,j}^{(1)}$ denotes the part from $\mathcal{L}_1$ that maximizes the similarity between the embeddings of $n_i$ and $n_j$. Eq~\ref{eq:pd_gradient} shows that, by utilizing the prediction-level KD, our MLP-based student can also be supercharged with high-order embedding smoothing without the cumbersome holistic-graph information propagation. Furthermore, the weights for different node pairs (\ie, the bracketed part) are derived from a well-trained GCN model, instead of depending on handcrafted heuristic manners as in Eq~\ref{eq:gcn_gradient}. This makes our KD framework robust to be the noise of observed graph structures.

% adaptive to the inaccuracy in observed graph structures due to noises and incompleteness.


\subsubsection{\bf Enriched Supervision Augmentation via KD}
Recent works~\cite{wu2021self, lin2022improving, xia2022hypergraph} propose to address the noise and the sparsity problems of CF by provising self-supervision signals using contrastive learning (CL) techniques. We show that our KD approach can provide even more additional supervisions. Specifically, we list the pull-close gradients from both InfoNCE-based CL loss, and our KD loss $\mathcal{L}_1$, \wrt, a single node embedding $\textbf{h}_i$, as follows:
\begin{align}
    \label{eq:overall_loss}
    \frac{\partial\mathcal{L}_\text{CL}}{\partial\textbf{h}_i} &= -\frac{1}{\tau} \cdot
    \frac{\partial \textbf{h}_i^{'\top} \textbf{h}''_i / (\|\textbf{h}'_i\|_2 \|\textbf{h}''_i\|_2)}{\partial \textbf{h}_i}\nonumber\\
    \frac{\partial\mathcal{L}_{1}}{\partial{\textbf{h}}_i^{(s)}} &= \sum_{v_j}\frac{\partial\mathcal{L}_{i,j}^{(1)}}{\partial{\textbf{h}}_i^{(s)}} = \sum_{v_j, v_k} -w_{i,j,k} \cdot \frac{\partial\textbf{h}_i^{(s)\top} \textbf{h}_j^{(s)}}{\partial\textbf{h}_i}
\end{align}
\noindent where $w_{i,j,k}$ represents the factors for simplicity. Shown by the second equation, our KD generates $|\{v_j,v_k|(u_i,v_j,v_k)\in\mathcal{T}_2\}|$ pull-close optimization terms for each node $u_i$, while CL method only generates one training sample. This evidently shows that our KD-based scheme can enrich the supplementary supervision signals, even without the data augmentation in CL~\cite{yu2022graph}.

\subsubsection{\bf Complexity Analysis}
We analyze the complexity of \model\ to answer the following questions: i) How do GCNs compared to MLPs in efficiency? ii) How is the efficiency of our KD paradigm compared to state-of-the-art methods? Detailed analysis is presented in~\ref{sec:complexity_analysis}. In concise, the computational complexity of the MLP network in \model\ is $\mathcal{O}(|\mathcal{T}_2|\times L' \times d^2)$, and the complexity of the GCN teacher is $\mathcal{O}(|\mathcal{E}|\times \mathcal{L}\times d)$. The MLP student is more efficient to the GNN teacher. For the second question, the supplementary losses in \model\ takes $\mathcal{O}(|\mathcal{T}_2|\times (I+J)\times d)$ complexity, which is comparable to existing SSL collaborative filtering methods.
