\newcommand{\gradient}[2]{
    \ifdimcomp{#1pt}{>}{\maxval pt}{#1}{
    \ifdimcomp{#1pt}{<}{\minval pt}{#1}{
         \pgfmathparse{min(int(round( ((abs(#1 - #2))) * 3 )), 100)}
        \xdef\tempa{\pgfmathresult}
        \colorbox{high!\tempa!low!\opacity}{{ }#1{ }}
    }}
 }

\newcommand{\gradientdeep}[2]{
    \ifdimcomp{#1pt}{>}{\maxval pt}{#1}{
    \ifdimcomp{#1pt}{<}{\minval pt}{#1}{
         \pgfmathparse{min(int(round( ((abs(#1 - #2))) * 5 )), 100)}
        \xdef\tempa{\pgfmathresult}
        \colorbox{high!\tempa!low!\opacity}{{ }#1{ }}
    }}
 }
 
\begin{table*}[ht!]
\centering
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{l >{\centering\arraybackslash}p{2.5cm} >{\centering\arraybackslash}p{2.5cm} >{\centering\arraybackslash}p{2.5cm} >{\centering\arraybackslash}p{2.5cm} }
\toprule
& \multicolumn{3}{c}{\textbf{LEX}} & \\
\textbf{Model (Token Removal Set)} & Subj $\rightarrow$ Obj Proper & Prim $\rightarrow$ Obj Proper & Prim $\rightarrow$ Subj Proper & \textbf{Overall} \\
\midrule
LSTM & 5.3\std{[1.4, 9.3]} & {\phsz}21.9\std{[10.9, 32.9]} & 69.0\std{[51.6, 86.3]} & 32.1\std{[28.2, 36.0]} \\
+ Tokens Removal (\{\lf{x} \lf{\_}\}) & {\phsz}5.1\std{[0.2, 10.0]} & 18.1\std{[8.7, 27.4]} & 76.5\std{[60.9, 92.0]} & 34.9\std{[31.5, 38.2]} \\
+ Tokens Removal (\{\lf{x} \lf{\_} \lf{(} \lf{)}\}) & {\phsz}7.2\std{[1.6, 12.9]} & {\phsz}24.6\std{[14.5, 34.8]} & 88.1\std{[78.2, 98.1]} & 39.6\std{[36.7, 42.5]} \\
+ Tokens Removal (\{\lf{x} \lf{\_} \lf{(} \lf{)} \lf{,}\}) & 5.5\std{[1.2, 9.8]} & 14.7\std{[5.8, 23.6]} & 65.4\std{[45.6, 85.3]} & 36.5\std{[32.8, 40.2]} \\
\midrule
Transformer & 74.4\std{[71.9, 76.9]} & {\phsz}62.4\std{[60.1, 64.6]} & 97.6\std{[96.4, 98.8]} & 81.3\std{[80.7, 81.9]} \\
+ Tokens Removal (\{\lf{x} \lf{\_}\}) & 91.9\std{[90.0, 93.9]} & {\phsz}81.1\std{[74.5, 87.7]} & 99.2\std{[98.6, 99.7]} & 83.6\std{[82.9, 84.3]} \\
+ Tokens Removal (\{\lf{x} \lf{\_} \lf{(} \lf{)}\}) & 86.0\std{[83.2, 88.9]} & {\phsz}71.2\std{[61.3, 81.1]} & {\phsz}97.8\std{[95.5, 100.2]} & 82.8\std{[82.1, 83.4]} \\
+ Tokens Removal (\{\lf{x} \lf{\_} \lf{(} \lf{)} \lf{,}\}) & 88.3\std{[84.4, 92.2]} & {\phsz}73.4\std{[65.8, 81.0]} & 99.0\std{[98.7, 99.4]} & 83.4\std{[82.8, 84.0]} \\
\bottomrule
\end{tabular}}
\caption{Results on the COGS lexical generalization splits for different token removal scheme. We report means (over 20 evaluations) with bootstrapped 95\% confidence intervals.}
\label{tab:cogs-results-token}
\end{table*}

