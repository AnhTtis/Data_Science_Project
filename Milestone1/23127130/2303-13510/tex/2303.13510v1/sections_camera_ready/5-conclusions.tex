\section{Conclusions}

In this paper, we introduce the Masked Voxel Jigsaw and Reconstruction (MV-JAR) pre-training method for LiDAR detectors. MV-JAR captures both point and voxel distributions of LiDAR point clouds, enabling models to learn effective and generic representations. We also develop a Reversed-Furthest-Voxel-Sampling strategy to address the uneven distribution of LiDAR points. Comprehensive experiments on the Waymo and KITTI datasets show that our method consistently and significantly enhances the detector's performance across different data scale regimes. MV-JAR offers a promising alternative for LiDAR-based self-supervised pre-training through Masked Voxel Modeling. Additionally, we establish a new data-efficient benchmark on the Waymo dataset, incorporating fine-tuning splits with diverse data variations. This benchmark effectively assesses the impact of pre-training on downstream tasks with varying amounts and diversities of labeled data.

\noindent\textbf{Acknowledgements.}\quad This project is funded in part by the Shanghai AI Laboratory, CUHK Interdisciplinary AI Research Institute, and the Centre for Perceptual and Interactive Intelligence (CPII) Ltd. under the Innovation and Technology Commission (ITC)'s InnoHK.