{
    "arxiv_id": "2303.09746",
    "paper_title": "Detecting Out-of-distribution Examples via Class-conditional Impressions Reappearing",
    "authors": [
        "Jinggang Chen",
        "Xiaoyang Qu",
        "Junjie Li",
        "Jianzong Wang",
        "Jiguang Wan",
        "Jing Xiao"
    ],
    "submission_date": "2023-03-17",
    "revised_dates": [
        "2023-03-20"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "cs.CV"
    ],
    "abstract": "Out-of-distribution (OOD) detection aims at enhancing standard deep neural networks to distinguish anomalous inputs from original training data. Previous progress has introduced various approaches where the in-distribution training data and even several OOD examples are prerequisites. However, due to privacy and security, auxiliary data tends to be impractical in a real-world scenario. In this paper, we propose a data-free method without training on natural data, called Class-Conditional Impressions Reappearing (C2IR), which utilizes image impressions from the fixed model to recover class-conditional feature statistics. Based on that, we introduce Integral Probability Metrics to estimate layer-wise class-conditional deviations and obtain layer weights by Measuring Gradient-based Importance (MGI). The experiments verify the effectiveness of our method and indicate that C2IR outperforms other post-hoc methods and reaches comparable performance to the full access (ID and OOD) detection method, especially in the far-OOD dataset (SVHN).",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09746v1"
    ],
    "publication_venue": "Accepted by ICASSP 2023"
}