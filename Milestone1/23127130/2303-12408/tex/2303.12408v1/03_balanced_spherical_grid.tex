\section{Feature Grid Representation for EgoNeRF}
\label{sec:feature_grid}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/method_overview_v1.pdf}
    \caption{Overview of our method. (a) We represent radiance fields as features stored in balanced feature grids $\mathcal{G}_\sigma\text{, } \mathcal{G}_a$, (b) which are further decomposed into vector and matrix components. (c) The hierarchical sampling is conducted by obtaining a coarse density grid from the density feature grid on the fly during optimization. (d) The balanced feature grids are optimized with photometric loss.}
    \label{fig:method_overview}
\end{figure*}

EgoNeRF utilizes feature grids to accelerate the neural volume rendering of NeRF.
Feature grids in previous works employ a Cartesian coordinate system, which regularly partition the volume in $xyz$ axis~\cite{liu2020neural, yu2021plenoctrees, hedman2021baking}.
To better express the egocentric views captured from omnidirectional videos, we use a spherical coordinate system.
We modify the spherical coordinate in both angular and radial partitions to efficiently express outward views of the surrounding environment, as described in \cref{subsec:grid_description}.
For rendering and training, the values are interpolated from the feature grid, which can be further factorized to reduce the memory and accelerate the learning~\cite{chen2022tensorf} (\cref{subsec:grid_NeRF}).
With our balanced feature grid, individual cells produce a uniform hitting rate of rays.

\subsection{Balanced Spherical Grid}
\label{subsec:grid_description}

Our balanced spherical grid is composed of the angular partition and the radial partition.
% \vspace{-0.5em}
\paragraph{Angular Partitions}
The desirable angular partition should result in regular shapes and be easily parameterized.
When we regularly partition on the angle parameters, the na\"ive spherical coordinate system results in irregular grid partitions, which severely distort the two polar regions.
Existing regular partitions do not maintain orthogonal axis parameterization~\cite{greger1998irradiance}, which hinders further factorization.

As a simple resolution, we only use the quasi-uniform half of the ordinary spherical coordinate system and combine two of them~\cite{kageyama2004yin}.
The two grids are referred to as the Yin grid and Yang grid, respectively, which have identical shapes and sizes as shown in \cref{fig:teaser} (b) and \cref{fig:method_overview} (a).
Together they can cover the entire sphere with minimal overlap, similar to the two regions of a tennis ball.


The Yin grid is defined as:
\begin{equation}
    (\pi/4 \leq \theta \leq 3\pi/4) \cap (-3\pi/4 \leq \phi \leq 3\pi/4),
\end{equation}
where $\theta$ is colatitude and $\phi$ is longitude.
The axis of another component grid, namely the Yang grid, is located at the equator of the Yin grid:
\begin{equation}
    \begin{bmatrix}x^{\text{Yin}}\\ y^{\text{Yin}}\\ z^{\text{Yin}}\end{bmatrix} = M \begin{bmatrix}x^{\text{Yang}}\\ y^{\text{Yang}}\\ z^{\text{Yang}}\end{bmatrix},
    M =
    \begin{bmatrix}
        -1 & 0 & 0\\
        0 & 0 & 1\\
        0 & 1 & 0
    \end{bmatrix}.
\end{equation}
%
We discretize the angular grid of Yin and Yang grid by $N_\theta^y$ and $N_\phi^y$ partitions for $\theta^y, \phi^y$ axis respectively, where $y\in\{\text{Yin}, \text{Yang}\}$.
The partition is uniform in angles leading to the grid size of
% \vspace{-0.5em}
\begin{equation}
    \Delta \theta^y = {\pi\over 2} {1\over N_\theta^y}, \; \Delta \phi^y = {3\pi\over 2} {1\over N_\phi^y}.
% \vspace{-0.5em}
\end{equation}
% \vspace{-1em}


\paragraph{Radial Partitions}
By adopting the spherical coordinate system, the grid cells cover larger regions as $r$ increases.
This is desired in the egocentric setup, as the panoramic image capture more detailed close-by views of central objects while distant objects occupy a small area on the projected images.
We further make the grid along the $r$ axis increase exponentially for far regions such that the resulting cell exhibit similar lengths in the angular and radial direction.

Specifically, if we denote the radial scales of both the Yin and Yang grids as $r^y$,
\begin{equation}
    r_i^y = r_0 k^{i-1}, \; R_{\text{max}} = r_0 k^{N_r^y - 1},
\end{equation}
where $R_{\text{max}}$ is the radius of the scene bounding sphere and constant value $r_0$ is the radius of the first spherical shell.
We set the grid interval to $r_0$ for the grid interval less than $r_0$.

We can optionally use the environment map for outdoor or large indoor environments. 
Our spherical grid is still bounded by $R_\text{max}$, limiting the size of the environment.
The environment map denoted as $\mathcal{E} \in \mathbb{R}^{H\times W \times 3}$, is a simple equirectangular image and represents what is visible at an almost infinite distance.

\if 0
In this section, we would first introduce our coordinate system and discrete grid suited for the egocentric setup.
Then we describe our radiance field representation, namely geometric and appearance feature grids with vector-matrix decomposed formulation.

%\subsection{Coordinate System}
%\label{subsec:coordinate_system}
The coordinate system and discrete grid for egocentric scene representation should 1) assign higher spatial resolution near the center 2) have uniform grid size on the plane orthogonal to $r$ direction.
The latitude-longitude grid in the spherical polar coordinate satisfies the first condition since the volume of spherical frustum increases along $+r$ direction.
On the other hand, the grid convergence near the pole makes the basic spherical grid not satisfy the second condition.
Therefore we adopt the Yin-Yang grid~\cite{kageyama2004yin} which is an effectively quasi-uniform on the sphere.

The Yin-Yang grid has two component grids, namely Yin grid and Yang grid, which have identical shape and size as shown in \todo{Fig.X}.
Each component grid is a part of latitude-longitude grid and the Yin grid is defined as:
\begin{equation}
    (\pi/4 \leq \theta \leq 3\pi/4) \cap (-3\pi/4 \leq \phi \leq 3\pi/4)
\end{equation}
where $\theta$ is colatitude and $\phi$ is longitude.
The axis of another component grid, namely Yang grid, is located in the equator of the Yin grid and the relation between Yin coordinates and Yang coordinates in the Cartesian coordinates can be expressed with matrix form below:
\begin{equation}
    \begin{bmatrix}x^{\text{Yin}}\\ y^{\text{Yin}}\\ z^{\text{Yin}}\end{bmatrix} = M \begin{bmatrix}x^{\text{Yang}}\\ y^{\text{Yang}}\\ z^{\text{Yang}}\end{bmatrix},
    M =
    \begin{bmatrix}
        -1 & 0 & 0\\
        0 & 0 & 1\\
        0 & 1 & 0
    \end{bmatrix}.
\end{equation}

We discretize the Yin and Yang grid with resolution of $N_r^y$, $N_\theta^y$, $N_\phi^y$ for $r^y, \theta^y, \phi^y$ axis respectively, where $y\in\{\text{Yin}, \text{Yang}\}$.
For $\theta^y$ and $\phi^y$ axis, we divide the grid uniformly.
Namely, the grid size for both Yin and Yang grid becomes
\begin{equation}
    \Delta \theta^y = {\pi\over 2} {1\over N_\theta^y}, \; \Delta \phi^y = {3\pi\over 2} {1\over N_\phi^y}.
\end{equation}
For $r^y$ direction, we increases the grid size exponentially.
When $r_i^y$ is the radius of $i$th spherical shell,
\begin{equation}
    r_i^y = r_0 k^{i-1}, \; R_{\text{max}} = r_0 k^{N_r^y - 1},
\end{equation}
where $R_{\text{max}}$ is the radius of the scene bounding sphere and $r_0$ is the radius of the first spherical shell which is a constant value.
To ensure the monotonically increasing grid size along $+r^y$ direction, we set the grid interval to $r_0$ for the grid interval less than $r_0$.
\fi

\subsection{Feature Grid as Radiance Field}
\label{subsec:grid_NeRF}
Now we describe our radiance field representation with the balanced spherical feature grid.
Given a set of egocentric images with corresponding camera parameters, EgoNeRF aims to reconstruct 3D scene representation and synthesize novel view images.
Instead of regressing for the volume density $\sigma$ and color $c$ from MLP~\cite{mildenhall2021nerf}, we build explicit feature grids of the density $\mathcal{G}_\sigma$ and the appearance $\mathcal{G}_a$ which serve as the mapping function.
Both grids are composed of our balanced spherical grids of resolution $2N_r^y\times N_\theta^y \times N_\phi^y$, as defined in~\cref{subsec:grid_description}.
The density grid $\mathcal{G}_\sigma \in \mathbb{R}^{2N_r^y\times N_\theta^y \times N_\phi^y}$ has a single channel which stores the explicit volume density value, and the appearance grid $\mathcal{G}_a \in \mathbb{R}^{2N_r^y \times N_\theta^y \times N_\phi^y \times C}$ stores $C$-dimensional neural appearance features.
The volume density and color at position $\mathbf{x}$ and viewing direction $\mathbf{d}$ are obtained by
\begin{equation}
    \sigma(\mathbf{x}) = \mathcal{T}(\mathcal{G}_\sigma, \mathbf{x}), \, c(\mathbf{x}, \mathbf{d}) = f_{\text{MLP}}(\mathcal{T}(\mathcal{G}_a , \mathbf{x}), \mathbf{d}),
    \label{eq:querying}
\end{equation}
where $\mathcal{T}$ denotes a trilinear interpolation, and $f_{\text{MLP}}$ is a tiny MLP that decodes the neural feature to color.

Inspired by~\cite{chen2022tensorf}, we further decompose the feature tensor into vectors and matrices as shown in \cref{fig:method_overview} (b):
% to reduce horizontal space
\newcommand{\seq}{\,{=}\!} 
\newcommand{\sotimes}{\,{\otimes}\,} 
\newcommand{\ssplus}{\!{+}\,} 
\newcommand{\splus}{\,{+}\,}
\small
\begin{align}
    \mathcal{G}_\sigma^y &\seq \sum_{n=1}^{N_\sigma} \mathbf{v}_{\sigma, n}^{y, R} \sotimes \mathbf{M}_{\sigma, n}^{y, \Theta \Phi} \ssplus \mathbf{v}_{\sigma, n}^{y, \Theta} \sotimes \mathbf{M}_{\sigma, n}^{y, \Phi R} \ssplus \mathbf{v}_{\sigma, n}^{y, \Phi} \sotimes \mathbf{M}_{\sigma, n}^{y, R \Theta} \nonumber \\
    &\seq \sum_{n=1}^{N_\sigma} \sum_{m\in{R\Theta\Phi}} \mathcal{A}_{\sigma, n}^{y, m}\text{,}
\end{align}
\begin{equation}
    \mathcal{G}_a^y  \seq \sum_{n=1}^{N_a} \mathcal{A}_{a, n}^{y, R}\sotimes \mathbf{b}_{3n-2}^y \splus \mathcal{A}_{a, n}^{y, \Theta}\sotimes \mathbf{b}_{3n-1}^y \splus \mathcal{A}_{a, n}^{y, \Phi}\sotimes \mathbf{b}_{3n}^y\text{,}
\end{equation}
\begin{equation}
    \mathcal{G}_\sigma = \bigcup\limits_{y\in Y} \mathcal{G}_\sigma^y, \mathcal{G}_a = \bigcup\limits_{y\in Y} \mathcal{G}_a^y, Y = \{\text{Yin, Yang}\}\text{,}
\end{equation}
\normalsize
where $\otimes$ represents the outer product and  $\mathbf{v}, \mathbf{b}, \mathbf{M}$ represents vector and matrix factors.
% \todo{TODO: need more descriptions for $\textbf{v}, \textbf{M}, \textbf{b}$.}
This low-rank tensor factorization significantly reduces the space complexity from $\mathcal{O}(n^3)$ to $\mathcal{O}(n^2)$.
With the minimal overhead of storing two grids, we can maintain regular angular components and yet factorize the grid using spherical parameterization.
The full decomposed formulation is described in the supplementary material.
% We describe the detailed vector-matrix decomposed formulation and efficient interpolation strategy in supplementary material.

% \todo{trilinear interpolation and B matrix $\rightarrow$ supplementary}
% efficient trilinear interpolation --> bilinear interpolation + linear interpolation

\if 0
%\subsection{Feature grid as Radiance Field}
%\label{subsec:radiance_feature_grid}
Now, we describe our radiance field representation with explicit feature grid.
Original NeRF~\cite{mildenhall2021nerf} models radiance field as a mapping function with MLP which takes input as 5D coordinate and outputs volume density $\sigma$ and color $c$.
% Then they obtain pixel values by volume rendering technique with querying $\sigma$ and $c$ along camera rays.
We use density grid $\mathcal{G}_\sigma$ and appearance grid $\mathcal{G}_a$ as a mapping function where both are our balanced spherical grid defined in~\cref{subsec:coordinate_system}.
3D tensor $\mathcal{G}_\sigma \in \mathbb{R}^{2N_r\times N_\theta \times N_\phi}$ has a single-channel which stores the volume density value, 4D tensor $\mathcal{G}_a \in \mathbb{R}^{2N_r \times N_\theta \times N_\phi \times C}$ stores $C$-dimensional neural appearance features.
Specifically, the volume density and color from position $\mathbf{x}$ and viewing direction $d$ are obtained from:
\begin{equation}
    \sigma(\mathbf{x}) = \mathcal{T}(\mathcal{G}_\sigma(\mathbf{x})), \, c(\mathbf{x}, d) = f_{\text{MLP}}(\mathcal{T}(\mathcal{G}_a (\mathbf{x}, d)))\texxt{,}
    \label{eq:querying}
\end{equation}
where $\mathcal{T}$ is trilinear interpolation operator, $f_{\text{MLP}}$ is a tiny MLP that decodes neural feature to color.

Inspired from~\cite{chen2022tensorf}, we further decompose the feature tensor into vectors and matrices:
% to reduce horizontal space
\newcommand{\seq}{\,{=}\!} 
\newcommand{\sotimes}{\,{\otimes}\,} 
\newcommand{\ssplus}{\!{+}\,} 
\newcommand{\splus}{\,{+}\,}
\begin{align}
    \mathcal{G}_\sigma^y &\seq \sum_{n=1}^{N_\sigma} \mathbf{v}_{\sigma, n}^{y, R} \sotimes \mathbf{M}_{\sigma, n}^{y, \Theta \Phi} \ssplus \mathbf{v}_{\sigma, n}^{y, \Theta} \sotimes \mathbf{M}_{\sigma, n}^{y, \Phi R} \ssplus \mathbf{v}_{\sigma, n}^{y, \Phi} \sotimes \mathbf{M}_{\sigma, n}^{y, R \Theta} \nonumber \\
    &\seq \sum_{n=1}^{N_\sigma} \sum_{m\in{R\Theta\Phi}} \mathcal{A}_{\sigma, n}^{y, m}\text{,}
\end{align}
\begin{equation}
    \mathcal{G}_a^y  \seq \sum_{n=1}^{N_a} \mathcal{A}_{a, n}^{y, R}\sotimes \mathbf{b}_{3n-2} \splus \mathcal{A}_{a, n}^{y, \Theta}\sotimes \mathbf{b}_{3n-1} \splus \mathcal{A}_{a, n}^{y, \Phi}\sotimes \mathbf{b}_{3n}
\end{equation}
\begin{equation}
    \mathcal{G}_\sigma = \bigcup\limits_{y\in Y} \mathcal{G}_\sigma^y\text{,} \mathcal{G}_a = \bigcup\limits_{y\in Y} \mathcal{G}_a^y, Y = \{\text{Yin, Yang}\}\text{,}
\end{equation}
where $\otimes$ represents cross product and  $\mathbf{v}, \mathbf{b}, \mathbf{M}$ represents vector and matrix factors.
% \todo{TODO: need more descriptions for $\textbf{v}, \textbf{M}, \textbf{b}$.}
This low-rank tensor factorization strategy significantly reduces the space complexity from $\mathcal{O}(n^3)$ to $\mathcal{O}(n^2)$.
% efficient trilinear interpolation --> bilinear interpolation + linear interpolation
\fi