\section{Conclusion}

We present EgoNeRF, an efficient adaptation of the NeRF into large-scale scenes with casual input. 
We utilize a balanced spherical feature grid and maintain uniform ray hit rates for individual cells for scenes captured with a short video of omnidirectional cameras.
Together with factorization and resampling techniques, we can achieve fast and high-quality rendering of various indoor and outdoor environments.

%\paragraph{Limitations}
Although EgoNeRF significantly outperforms the prior works in terms of visual quality and our approach converges much faster than MLP-based methods, we have some limitations.
In this paper, we do not consider all the challenges that come from real-world scenarios such as photometric variation from automatic camera exposure.
EgoNeRF sometimes shows noisy artifacts when the camera poses are not correct in the real-world \textit{Ricoh360} dataset, while MLP-based algorithms output blurred images.
Further analysis of the impact of camera parameter error is provided in the supplementary material.
% This is because our approach optimizes multiple grids for fine structure when camera poses are wrong, but MLP-based methods output interpolated value by MLP.
One can resolve this by jointly optimizing the camera parameters as in~\cite{Lin_2021_ICCV, wang2021nerf, Jeong_2021_ICCV}.
Furthermore, like other NeRF-based models, we assume that scenes are static.