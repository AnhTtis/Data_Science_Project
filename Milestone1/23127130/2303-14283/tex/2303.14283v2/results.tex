\section{Experiments and Results}
We implemented Algorithms \ref{algo:lmksample}-\ref{algo:reinit} in Python by blending our in-house code of particle filters and the Gaussian solver provided by the GTSAM library. In addition, we applied explicit regularization to the Gaussian solver by adding large-covariance priors on new non-Gaussian landmarks. These prior factors were not involved in the sampling or re-initialization and were removed once the corresponding landmarks were removed from non-Gaussian landmarks. We perform two sets of experiments: 1) we validate our solutions for distribution and point estimations using range-only SLAM experiments, and 2) we demonstrate the generalizability and scalability of our method using object-based bearing-only SLAM experiments. All experiments were conducted on a laptop with a 2.30GHz Intel Core i7-10875H CPU running Ubuntu 20.04.4 LTS.

\subsection{Range-only SLAM} \label{sec:range-only-slam}
\subsubsection{Datasets and methods for comparison}
The performance of GAPSLAM is evaluated by comparing it with other methods on a range-only SLAM dataset, as range measurements can easily lead to highly non-Gaussian/multi-modal posteriors. We use the Plaza 1 dataset \cite{djugash2009navigating} which provides time-stamped range and odometry measurements collected by a mobile robot in a planar environment. Ranges between the robot and four landmarks were measured by an ultra-wide band ranging system so each range measurement was tagged with the identity of the landmark. Two methods were used for comparison: 1) NSFG \cite{huang2021reference}, which directly draws samples from the joint posterior using nested sampling methods \cite{skilling2006nested, speagle2020dynesty} and is considered as reference solutions at the expense of computational burden, and 2) RBPF-SOG \cite{blanco2008efficient}, which models landmark conditionals as sum-of-Gaussians (SOGs) in the RBPF framework, updates the SOGs using multi-hypothesis EKFs, and attains real-time operation. We present two sets of results: 1) marginal posteriors for demonstrating how the Gaussian approximation helps particle filters to draw landmark samples, and 2) point estimates for validating the use of particle filters in re-initializing the Gaussian approximation.

\subsubsection{Results on marginal posteriors}
We present the posteriors of early time steps, which are expected to be strongly non-Gaussian (e.g., multi-modal). Fig.~\ref{fig:ro-samples} shows samples drawn by different methods to represent the posteriors. GAPSLAM shows good consistency with the reference samples by NSFG, while RBPF-SOG overestimates the uncertainty in the posteriors, as indicated by spurious modes of landmark $L_3$ samples (blue dots in the last column of Fig. \ref{fig:ro-samples}). The excessive number of modes is an expected result of tracking multiple hypotheses in SOGs. Although we applied the strategy suggested in \cite{blanco2008efficient} to prune hypotheses with negligible weights, as shown by the decreasing blue line in the bottom of Fig. \ref{fig:ro-perform}b, the averaged number of modes per landmark is still 11 at time step 21.

\setlength\textfloatsep{10pt}
\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{figs/roslam_sample_tworows.png}
    \caption{Samples from marginal posteriors by three methods at two time steps. The robot moves from $(0,0)$ to pose $X_{21}$ or $X_{24}$, observing 4 landmarks $L_{0-3}$. Black lines and markers indicate the ground truth. Measurements are shown as dashed lines (accumulated measurements are shown in the middle column). Gray dots indicate robot position samples while colored dots denote landmark samples. Green ellipses in GAPSLAM represent confidence intervals (2$\sigma$) of the Gaussian approximation.}
    \label{fig:ro-samples}
%\vspace{-10pt}
\end{figure}

In order to explain how GAPSLAM draws the samples in Fig. \ref{fig:ro-samples} and when the re-initialization occurs, we can start by looking at the green confidence intervals, which represent the Gaussian approximation. Samples of robot positions and Gaussian landmarks are drawn from the Gaussian. At time step 21, $L_0$ and $L_3$ are non-Gaussian landmarks, and we use the method described in Sec. \ref{sec:marginal-posterior} and Algorithm \ref{algo:lmksample} to draw their samples. Following \eqref{eq:reinit}, these samples are then used for re-initialization across time steps 21 and 24, which is reflected by the increased computation time for re-initialization in Fig. \ref{fig:ro-perform}a. Because the set of Gaussian landmarks extends from $(L_1, L_2)$ at time step 21 to all landmarks at time step 24, the number of non-Gaussian landmarks drops to zero, as shown in the bottom of Fig. \ref{fig:ro-perform}b.

\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{figs/roslam_perform.pdf}
    \caption{Performance comparison at early time steps in the Plaza1: (a) computational time for updating probabilistic models, (b) computational time for posterior samples of landmarks, the number of non-Gaussian landmarks in GAPSLAM, and the averaged number of modes per landmark in RBPF-SOG, and (c) the root mean square error (RMSE) of point estimates and the maximum mean discrepancy (MMD) \cite{gretton2012kernel} of landmark samples. The MMD is a distance between two distributions represented by samples. We compute the MMD between the reference samples and samples by GAPSLAM (or RBPF-SOG), so a lower MMD means samples that describe the posterior better. Error bands indicate the mean and standard deviation across 6 runs with different random seeds. }
    \label{fig:ro-perform}
\vspace{-5pt}
\end{figure*}

Fig. \ref{fig:ro-perform}a illustrates the computation time of different methods for updating their probabilistic models. Note that the computation time for drawing dense samples ($K=200,M=100$ in \eqref{eqn:estimate-marginal}) of landmarks shown in Fig. \ref{fig:ro-samples} is separately shown in the top of Fig. \ref{fig:ro-perform}b. There are two reasons for excluding it from Fig. \ref{fig:ro-perform}a: 1) sampling landmark posteriors can be implemented as a parallel process, and 2) RBPF-SOG does not need landmark samples to update the SOGs, and GAPSLAM only needs sparse samples to assist the re-initialization to the Gaussian approximation. For the sparse samples (i.e., `update samples' in Fig. \ref{fig:ro-perform}a), we draw landmark samples given only the current mean of the robot path (i.e., $K=1$ in \eqref{eqn:estimate-marginal}). While sampling landmark posteriors consumes slightly more computation time than updating models in GAPSLAM before time step 24, the sampling still supports an update frequency of at least 30 Hz. After time step 24, there are no non-Gaussian landmarks, so GAPSLAM is just the Gaussian solver with additional functions for sampling Gaussian marginals, which enjoys significantly faster speeds.


Fig. \ref{fig:ro-perform}c presents the performance evaluation of point estimates and distribution estimation using the root mean square error (RMSE) and maximum mean discrepancy (MMD) \cite{gretton2012kernel}, respectively. We compute the MMD between samples by GAPSLAM (or RBPF-SOG) and the reference samples by NSFG. The MMD is a distance between two distributions represented by samples, so a lower MMD here indicates a more accurate set of samples for representing posteriors. The results show that GAPSLAM significantly outperforms RBPF-SOG in terms of MMD, especially after time step 21 when the spurious modes in SOGs become more prominent, providing quantitative evidence of the superior accuracy of GAPSLAM in sampling posteriors. Additionally, it is worth noting that the RMSE of GAPSLAM only slightly outperforms that of RBPF-SOG at these early time steps. \highlight{This indicates that MMD is a more suitable evaluation metric than RMSE for \emph{full posterior inference}, especially in highly non-Gaussian settings}.

\subsubsection{Results on point estimates}
Table \ref{table:rmse-recall} presents the errors of point estimates for the entire Plaza1 sequence. RBPF-SOG incurs less accurate and consistent results due to the particle depletion issue. GAPSLAM without re-initialization is essentially the Gaussian solver with additional priors on landmarks. However, only 58$\%$ of runs without re-initialization return solutions despite having RMSE values comparable to those of GAPSLAM. The superior performance of GAPSLAM supports the effectiveness of the sample-based, uncertainty-aware re-initialization.

\begin{table}[t]
\vspace{+0.3cm}
\caption{Point estimates for the full sequence of the Plaza1 dataset. The RMSE is presented by the mean $\pm$ standard deviation across 50 runs with different random seeds \highlight{which lead to different random initial values in the Gaussian solver}. The case `GAP. w/o reinit.' serves as an ablation study and is configured by disabling the non-Gaussian landmarks set and operations for re-initialization and sampling, which is essentially just GTSAM with the explicit regularization treatment (large-covariance priors). The RMSE in this case is computed on 29 out of 50 runs (i.e., $58\%$ success rate) that were not ceased by \highlight{the GTSAM error, indeterminant linear system. The GTSAM error is expected because, in this problem, bad initial values may incur near-singular linear systems}.}
\label{table:rmse-recall}
\begin{tabularx}{\linewidth}{@{} p{1.9cm} p{0.5cm} l l l @{}}%{@{} l p{1.0cm} l l p{2.0cm} @{}}
\toprule
Metric  
& Odom. & GAPSLAM & RBPF-SOG & GAP. w/o reinit.\\ 
\midrule
RMSE (cm) & 639.6   & $\mathbf{34.4\pm 0.0}$ & $56.0\pm 5.4$ & $34.5\pm 0.0$ \\ 
Success rate (\%) &- & $\mathbf{100}$     & $\mathbf{100}$        & 58  \\ 
\bottomrule
\end{tabularx}
\vspace{-5pt}
\end{table}


\subsection{Object-based bearing-only SLAM} \label{sec:obj-slam}
\subsubsection{Datasets and real-world experiments} We estimate 6DOF camera poses and a map of object locations, using visual odometry and object detections from RGB videos. We aim to demonstrate the scalability of GAPSLAM to three-dimensional (3D) environments and its ability to fuse other types of measurements such as bearing-only. We test GAPSLAM using RGB data from the RGB-D Scenes Dataset v2 \cite{lai2014unsupervised} and a video collected by a monocular camera in our office area. For visual odometry, we use camera poses of key frames computed by ORB-SLAM3 \cite{ORBSLAM3_TRO}, while object classes and masks in the key frames are detected using the Detic detector \cite{zhou2022detecting}. \highlight{Camera poses are optimized using both visual odometry and measurements to objects.}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{figs/objslam_plot.pdf}
    \caption{Estimates made by GAPSLAM for the realworld RGB sequence: (a,b,c) samples or confidence intervals (3$\sigma$) of object locations in 3D and their reprojection in images at key frames 10, 20, and 30, (d) final estimates of camera poses and samples and confidence intervals of object locations (we show samples of only 5 non-Gaussian landmarks to avoid clutter), and (e) a comparison of trajectory estimates with the pseudo ground truth. ORBSLAM3 did not close the big loop between `leave' and `return' due to the large change ($\sim$180 degrees) in viewing angles.}
    \label{fig:obj-realworld}
\vspace{-5pt}
\end{figure*}

\subsubsection{Pre-processing object detections} We treat the center $z_k$ of an object mask on an image as a projection factor that models the reprojection error $h(x_i,l_j;K)-z_i$, where $h(\cdot)$ denotes the reprojection of 3D object center $l_j$ in the image with pose $x_i$ and camera intrinsics $K$. This measurement $z_k$ is either associated with an existing landmark or yields a new landmark, depending on the semantic and geometric information of the map. Thus wrong semantic labels may affect data association or spawn spurious landmarks. On the other hand, partial views of objects, which are often caused by occlusions or objects on image edges, lead to 2D mask centers that significantly deviate from the object center in 3D. To address these issues, we pre-process object detections as follows:
\begin{itemize}
%\setlength{\itemindent}{-0.2cm}
\item Rejecting object detections that are potentially occluded by other detections on the image. Specifically, for any pair of detections (say $i$ and $j$) whose bounding boxes intersect, one of the detections (say $i$) will be discarded if any of the following conditions is satisfied:
\begin{itemize}
\item The object mask of detection $i$ is smaller than a fraction (e.g., $10\%$ in our experiments) of the mask of detection $j$. This condition is for rejecting very small masks.
\item The area of mask $i$ within the bounding-box intersection is smaller than that of mask $j$ and the area ratio between the intersection and the mask $i$ is greater than a fraction (e.g., $10\%$ in our experiments). This condition is for rejecting object detections that may be occluded by large bounding-box intersections.
\end{itemize}

\item Increasing uncertainty in noise models of object mask centers that are close to image edges. Let us denote the relative position of the center of an object mask on an image as $(r_x,r_y) \in [-1,1]^2$ so $r_x=0$ and $r_y=0$ indicate a mask center located at the image center and $|r_x|$ or $|r_y|$ that approaches 1 indicates a mask center that is close to image edges. Thus we define standard deviations in the noise model as
\begin{align}
\sigma_{x} &= \delta_{x}(1-|r_x|) + \text{max}(\delta_{x}, \delta_{y}) |r_x|,\label{eqn:noise}\\
\sigma_{y} &= \delta_{y}(1-|r_y|) + \text{max}(\delta_{x}, \delta_{y}) |r_y| \label{eqn:noise2}
\end{align}
where $\delta_{x}$ and $\delta_{y}$ denote standard deviations of the mask in pixels.

\item Rejecting any object detection which cannot be associated with landmarks in the same class via the maximum likelihood (ML) data association \cite{kaess2009covariance, neira2001data} but passes the data association with landmarks that belong to different classes. This step intends discarding detections with wrong object classes. See the following section about the data association.
\end{itemize}

\subsubsection{Data association and creation of new landmarks}\label{sec:da}
We choose to implement the ML data association with some additional treatment for exploiting semantic information in object detections and posterior samples in GAPSLAM. For a mask center $z_k$ labeled by an object class and observed from pose $x_i$, we first compute its Mahalanobis distances to reprojections of any landmark $l_j$ in the same class, as defined in 
\begin{align}
D^{2}_{kj} = \lVert h(\hat{\mathbf{x}})-z_k \rVert^2_{C}
\end{align}
where $\mathbf{x}=(x_i, l_j)$ and
\begin{align}
C = \frac{\partial h}{\partial \mathbf{x}} \bigg|_{\hat{\mathbf{x}}} \Sigma \frac{\partial h}{\partial \mathbf{x}} \bigg|_{\hat{\mathbf{x}}}^{T} + \Gamma.
\end{align}
$\Sigma$ is the covariance between $x_i$ and $l_j$ in the Gaussian approximation of the posterior. $\Gamma$ is the covariance of measurement noise model (e.g., \eqref{eqn:noise} and \eqref{eqn:noise2}). The measurement is associated with $l_j$ if $D^{2}_{kj}$ is the smallest among landmarks in the same class and passes the chi-square test, $D^{2}_{kj} < \mathcal{X}^2_{d,\alpha}$, where $d$ is the dimension of the measurement and $\alpha$ is the desired confidence level.

Note that the quality of the Gaussian approximation affects the ML data association so, if the ML data association does not accept any landmark, we then perform another round of data association using landmark samples. For any landmark $l_j$ in the same class as detection $z_k$, we reproject samples of $l_j$ onto the image and count the percent $p_{kj}$ of samples that fall in the bounding box of the detection. The detection is associated with $l_j$ if $p_{kj}$ is the highest among landmarks in the same class and higher than a threshold (e.g., $10\%$ in our experiments).

If the sample-based data association does not accept any landmark either, we create a new landmark in the map.

\subsubsection{Results}
Fig. \ref{fig:obj-realworld} shows qualitative results on our realworld sequence. We set the Detic detector to recognize only a certain number of classes: cup, cereal box, trash can, skateboard, office chair, football, bottle, traffic cone, and toy car since they are quite common in our office and we found Detic worked with good recall and precision for these classes. Figs. \ref{fig:obj-realworld}a, b, and c show how marginal posteriors of object locations evolve over key frames 10, 20, and 30, which occur before the `leave' arrow on the path in Fig. \ref{fig:obj-realworld}e. The trash can in Fig. \ref{fig:obj-realworld}b and the chair in Fig. \ref{fig:obj-realworld}c have been identified as Gaussian landmarks by GAPSLAM so we draw confidence intervals (3$\sigma$) of their locations using the Gaussian approximation in lieu of samples.

There are 415 camera poses and 100 landmarks being created in the end. Fig. \ref{fig:obj-realworld}d visualizes all camera poses and landmarks marginals in 3D. Fig. \ref{fig:obj-realworld}e compares the pseudo ground truth and the estimated trajectories by GAPSLAM and ORBSLAM3. ORBSLAM3 fails to close the big loop between `leave' and `return' since the camera returns from an opposite viewing angle, and the bag-of-word approach in ORBSLAM3 does not recognize the return. The trajectory by GAPSLAM is aligned with the pseudo ground truth much better since object detections introduce many loop closures along the path. We found object detections by Detic performed consistently well under big changes of viewing angles. In GAPSLAM, the big loop between `leave' and `return' is successfully closed when the camera returns to and recognizes chairs and trash cans that appeared at early key frames (Figs. \ref{fig:obj-realworld}a, b, and c). The pseudo ground truth is the early portion of ORBSLAM3 results on a longer video, which circles our office three times along the same path, so the early portion has been corrected by loop closures introduced in the later portion.

Table~\ref{table-object-rmse} shows the RMSEs of estimated trajectories on the Scenes v2 sequences and our realworld sequence. GAPSLAM attains lowest errors in all the sequences. \highlight{We attribute this accuracy to two reasons: 1) extra constraints introduced by object-based measurements, and 2) functions in the GAPSLAM algorithm.} We disable some functions in the GAPSLAM algorithm to demonstrate their contributions to the estimation of the path. We find the pre-processing makes the biggest impact to the estimation while the re-initialization ranks the second and the sample-based data association ranks the third. Disabling all of them incurs significant estimation errors in some of the sequences (e.g., seqs. 9 and realwrold).

\begin{table}[t]
\vspace{+0.5cm}
\caption{Root mean square error (cm) of estimated paths under different settings. Each row below GAPSLAM serves as an ablation study that disables one (or three) of the functions in the object-based SLAM system.}
\label{table-object-rmse}
\begin{tabularx}{\linewidth}{@{} l *{6}{L} l @{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{6}{l}{Sequences in RGB-D Scenes Dataset v2} & \multirow{2}{*}{\stackanchor{Real}{world}}\\ \cline{2-7} 
                        & 1   & 2   & 3   & 4      & 9   & 10   &\\ \midrule
ORBSLAM3                & 1.9 & 2.2 & 2.0 & 2.0    & 2.6 & 3.7   & 14.0\\
GAPSLAM                 & \bf{0.9} & \bf{1.0} & \bf{0.7} & \bf{1.2}    & \bf{0.7} & \bf{2.6}     & \textbf{5.2}\\
- no pre-processing       & 1.0 & \bf{1.0} & 0.8 & 1.4    & 2.4 & 2.7      & 6.6\\
- no sample-based DA    & \bf{0.9} & \bf{1.0} & \bf{0.7} & \bf{1.2}    & 0.8 & \bf{2.6}      & 5.8\\
- no reinitialization            & \bf{0.9} & \bf{1.0} & 0.8 & 1.3    & \bf{0.7} & \bf{2.6}     & 6.6\\
- disable all above     & 1.0 & 2.2 & 0.9 & 1.3    & 4.2 & 2.7      & 9.5\\
\bottomrule
\end{tabularx}
\end{table}
\setlength\floatsep{15pt}
\begin{table}[t]
\caption{Runtime profiling of the object-based SLAM system and specifics for different datasets.}
\label{table-object-time}
\begin{tabularx}{\linewidth}{@{} l *{6}{L} l @{}}
\toprule
\multirow{2}{*}{Items} & \multicolumn{6}{l}{Sequences in RGB-D Scenes Dataset v2} & \multirow{2}{*}{\stackanchor{Real}{world}}\\ \cline{2-7} 
                            & 1    & 2    & 3    & 4    & 9    & 10   &\\ \midrule
Time/frame (ms)              & 43.2 & 28.6 & 29.7 & 32.1 & 23.9 & 19.7 & 63.3\\
- pre-processing            & 4.2  & 2.7  & 2.2  & 3.0  & 1.5  & 1.1  & 9.0\\
- data association 		    & 6.2  & 4.6  & 7.6  & 7.2  & 7.0  & 4.8  & 9.8\\
- GAPSLAM                   & 32.8 & 21.3 & 21.2 & 21.9 & 15.4 & 13.9  & 44.4\\
\hspace{5pt} - reinit.      & 3.2  & 2.4  & 1.6  & 1.4  & 1.0  & 1.3  & 6.1\\
\hspace{5pt} - GA           & 8.8  & 6.1  & 7.6  & 8.8  & 4.8  & 3.7  & 13.9\\
\hspace{5pt} - samples      & 13.6 & 8.0  & 6.8  & 6.2  & 4.7  & 5.5  & 17.1\\ \midrule
Obj. det./frame (-)   		& 5.1  & 5.0  & 5.2  & 5.0  & 2.8  & 3.0  & 5.3\\
Key frames (-)      		& 99   & 95   & 108  & 109  & 96   & 87  & 415\\
$\#$ of landmarks (-)      	& 8    & 7    & 8    & 8    & 4    & 3   & 100\\
\bottomrule
\end{tabularx}
\end{table}

Fig. \ref{fig:obj-runtime} shows the runtime of our system for the realworld sequence. The system implemented in Python supports an update frequency of 6 Hz for the slowest key frames and, on average, affords an update frequency of 16 Hz. We are confident that the runtime can be greatly optimized by an improved implementation. Given that we only process key frames, GAPSLAM is able to support real-time operation. Table~\ref{table-object-time} shows the runtime profiling of our system and specifics of different datasets. The runtime on Scenes v2 sequences is expected to be faster since the sequences involve fewer poses and objects. The crux of averaged runtime is on steps for updating samples and the Gaussian approximation. However, Fig. \ref{fig:obj-runtime} shows that updating samples only dominates the runtime in early key frames, when many non-Gaussian landmarks had just been created. Revisiting objects at later key frames reduces the uncertainty in the posteriors of object locations, so more and more objects are moved to the set of Gaussian landmarks. Thus the computation burden gradually transfers to updating the Gaussian approximation. The scalability of updating the Gaussian approximation can be improved via many strategies such as fix-lag smoothing \cite{dellaert2017factor}.

\begin{figure}[t!]
    \centering
    \includegraphics[width=1.0\linewidth]{figs/obj_runtime.png}
    \caption{Runtime profiling of the object-based SLAM system (in Python).}
    \label{fig:obj-runtime}
\end{figure}