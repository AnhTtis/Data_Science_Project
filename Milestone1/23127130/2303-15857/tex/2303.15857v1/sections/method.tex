%
In this section, we present our proposed 3D spectral domain visual servoing method. As mentioned earlier, the main basis of our approach is the model registration schema using spectrally transformed point clouds. To this extent, we first introduce the representation used by our method followed by the concepts of phase correlation in the Cartesian space and on the unit-sphere. Finally, the derived control law is presented.
%----
\subsection{Point Cloud Representation}
% --- 
The first step of our 3D visual servoing pipeline is to represent the points and the surface normals of the point cloud as a voxel grid and as an Extended Gaussian Image (EGI), respectively.
%
\subsubsection{Points as voxel grid}
The discretisation of a point cloud is a straightforward process. Given a point cloud composed of $N$ points, a 3D voxel grid of resolution $r \in \mathbb{R}^+$ can be constructed. For each point $p = (x, y, z)$ of the point cloud, the voxel indices of the point $p_{ijk}= (i, j, k)$ are computed as:
%
\begin{equation}
\label{eq:voxel_index}
i = [x/r]\qquad
    j = [y/r]\qquad
    k = [z/r]
\end{equation}
%
where, the operation $[./.]$ represents integer division, \textit{i.e.}, only the integer part of the division is retained.

Let $v_t: \mathbb{R}^3 \rightarrow \mathbb{N}^3$ be the mapping between the Cartesian coordinates and the voxel indices. The voxel grid function\footnote{The subscript $t$ indicates that the function is used for translation estimation, in the same way, the subscript $r$ will be used for functions related to rotation estimation.} $f_t : \mathbb{R}^3 \rightarrow \mathbb{N}$ of a point cloud can be defined as:
%
\begin{equation}
f_t(p) = f_t(x, y, z) = v_{ijk}
\label{eq:voxel}
\end{equation}
%
where, $v_{i,j,k} \in [0,1]$. Here, $v_{i,j,k}=1$ if at least one point of the point cloud has indices equal to $v_T(p) = (i,j,k)$ and $v_{ijk} = 0$ otherwise. Our method uses a voxel grid with binary values; however, a voxel grid with real values can also be used in the same way. The Local Contact Moments (LoCoMo) metric presented in~\cite{adjigble2018model} can be a good candidate for enhancing the information contained in the voxel grid.

\subsubsection{Surface normals as Extended Gaussian Image}
The EGI is a popular representation of functions expressed in the unit-sphere. It has extensively been used in the literature as a shape descriptor for object surface normals \cite{little1985extended,nayar1990specular,lowekamp2002exploring,adjigble2021spectgrasp}. Changing the representation of a surface normal $n = (n_x, n_y, n_z) \in \mathbb{R}^3$ from Euclidean to spherical coordinates $n = (r, \theta, \phi)$ using \eqref{eq:spherical_coordinates}, allows expressing the surface normal on the unit-sphere. 
%
\begin{equation}
\label{eq:spherical_coordinates}
\begin{gathered}
    r      = \sqrt{n_x^2 + n_y^2 + n_z^2} \qquad
    \theta = \arctan{\frac{\sqrt{n_x^2 + n_y^2}}{n_z}} \\
   \phi    = \arctan(\frac{n_y}{n_x}) 
\end{gathered}
\end{equation}
%

The radial distance $r = 1$ for all surface normals as they are unitary vectors. Thus, the set $(\theta, \phi)$ is sufficient to describe the distribution of surface normals on the unit-sphere.
A discrete representation of the sphere is required to perform numerical computations. The following discretisation along the longitude and latitude is used: $\theta_j = \frac{\pi(2j + 1)}{4B}$ and $\phi_k = \frac{\pi k}{B}$  , $(j, k) \in \mathbb{N}$ with the constraint $0  \leq j, k < 2B$ and $B \in \mathbb{N}$ is the bandwidth. The value of the bandwidth is usually chosen as a power of $2$, meaning that $B=2^n, n \in \mathbb{N}^+$.
The EGI of the surface normals of a given point cloud can then be expressed as the function $f_r : \bm{S}^2 \rightarrow \mathbb{N}$:
%
\begin{equation}
f_r(\theta, \phi) = c_r({\theta_j, \phi_k})
\label{eq:egi}
\end{equation}
%
where, $c_r \in \mathbb{N}$ is the count that represents the number of surface normals in the point cloud with discrete longitude and latitude equal to $(\theta_j, \phi_k)$. In this case, count values are used instead of binary values. The advantage is that a distribution of surface normals on the unit-sphere provides more information on the geometry of the object compared to a simple binary distribution. Fig.~\ref{fig:fig2_egi} shows sample EGIs of an object and a clutter scene represented as point clouds.
%.
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/Fig2.pdf}
    \caption{EGIs of (top) "mug" object and (bottom) cluttered scene, which are represented as point clouds with surface normals (small green arrows).}
    \label{fig:fig2_egi}
\end{figure}
%
% ------
\subsection{Translation Estimation via Fourier Analysis on $\mathbb{R}^3$}
% ------
The translation between the target and reference point clouds is estimated using 3D phase correlation in the spectral domain with Fourier analysis. The main advantage is that Fourier analysis-based methods are robust to noisy measurements \cite{bulow2012spectral,marturi2016image}. The phase correlation method is based on the Fourier shift property and maps translations in the Cartesian space to phase shift in the spectral domain. 

 Let $f_t : \mathbb{R}^3 \rightarrow \mathbb{N}$ be the voxel representation of the point cloud of an object or a scene. The Fourier coefficients of $f_t$ are computed as:
%
\begin{equation}
F_t(u, v, w) = \sum_{x=0}^{M-1}\sum_{y=0}^{N-1}\sum_{z=0}^{L-1}f_t(x,y,z)e^{-i2\pi(\frac{u}{M}x + \frac{v}{N}y + \frac{w}{L}z)}
\label{eq:fourier_coefs}
\end{equation}
%
where, $M, N, L \in N^+$ are the maximum degree of expansion of the Fourier coefficients in the $X$, $Y$, and $Z$ axes, respectively and $(u, v, w)$ are the frequency domain coordinates. Suppose the object or scene is translated by $T = (\tau_x,\tau_y, \tau_z) \in \mathbb{R}^3$, and let $g_t : \mathbb{R}^3 \rightarrow \mathbb{N}$ be the new voxel representation of the translated point cloud. Based on the Fourier shift property, the Fourier coefficients $G_t$ of $g_t$ can be computed by:
%
\begin{equation}
G_t(u, v, w) = F_t(u, v, w)e^{-i2\pi(\frac{u}{M}\tau_x + \frac{v}{N}\tau_y + \frac{w}{L}\tau_z)}
\label{eq:fourier_shift_theorem}
\end{equation}
%

The aim of the translation estimation is to find $T$ given $f_t$ and $g_t$. This can be efficiently done by first computing the normalized cross-power spectrum $\mathcal{C}_t$ of $F_t$ and $G_t$, and applying the inverse Fourier transform by \eqref{eq:cross_power_spectrum}. 
%
\begin{equation}
\begin{aligned}
\mathcal{C}_t(u,v,w) &= \frac{F_t(u,v,w)\overline{G_t(u,v,w)}}{|F_t(u,v,w)\overline{G_t(u,v,w)}|} \\
\delta(\tau_x,\tau_y, \tau_z) &= \mathcal{F}^{-1}(\mathcal{C}_t(u,v,w)) 
\label{eq:cross_power_spectrum}
\end{aligned}
\end{equation}
%
where, $\overline{G_t}$ is the complex conjugate of $G_t$, and $\mathcal{F}^{-1}$ is the inverse Fourier transform. The result $\delta$ is the \emph{Dirac delta function} whose peak location corresponds to the translation $T$. Therefore, $T$ can be found by maximizing the $\delta$.

%
\begin{equation}
\begin{aligned}
T &= \nabla_{glob} T = \mathrm{argmax}\{\delta(\tau_x,\tau_y, \tau_z)\}
\label{eq:fourier_shift_solution}
\end{aligned}
\end{equation}
%
Even though the global solution $\nabla_{glob} T$ for the translation can be found directly, in the context of 3D visual servoing, only a small step $\nabla T = \lambda_t\nabla_{glob} T$, with $\lambda_t \in \mathbb{R}^+$ and $\lambda_t < 1$, will be taken at each iteration. This allows the translation and rotation to be estimated concurrently, but also to control the dynamics of the controller. The following cost-function $J_t(T)$ can be formulated to evaluate the performance of the translation estimation algorithm on $\mathbb{R}^3$:
%
\begin{equation}
\begin{aligned}
J_t(T) = \frac{1}{2}||g_t(x) - f_t(x + T)||^2 \\
\end{aligned}
\label{eq:translation_cost_function}
\end{equation}
%
%
\subsection{Rotation Estimation via Fourier Analysis on $\bm{S}^2$}
Similarly to the translation, the rotation between the target and reference point clouds can also be estimated by using spectral analysis. Here, the unitary representation of signals expressed on the unit-sphere is used to encode the information of the object's surface normals. The same advantage as for the translation estimation applies, \emph{i.e.}, robustness to noise. In this case, we estimate the global rotation via EGI correlation. It is possible to find the optimal rotation directly by searching for the rotation maximizing the correlation, but this involves performing a double integration which can be computationally expensive. Instead, the analytical gradient of the correlation is used to iteratively compute the rotation that maximizes the correlation.
%
\subsubsection{Fourier transform on $\bm{S}^2$ and $\bm{SO}(3)$}
Let $f_r : \bm{S}^2 \rightarrow \mathbb{N}$ be the EGI of the surface normals of an object. Because $f_r$ has values in $\mathbb{N} \subset \mathbb{R}$, real harmonic analysis on $\bm{SO(3)}$, introduced in~\cite{lee2018real}, can be used to compute the Fourier parameters. Given a bandwidth $B$, the Fourier transform of $f_r$ on $\bm{S}^2$ is expressed as:
%
\begin{equation}
f_r(\theta, \phi) = \sum_{l=0}^{B-1}(F^l_r)^TS^l(\theta, \phi)
\label{eq:real_fourier_transform_fr}
\end{equation}
%
where, $F^l_r \in \mathbb{R}^{(2l+1)\times1}$ are the Fourier parameters and $S^l \in \mathbb{R}^{2l+1}$ are the orthogonal basis for real-value functions on $\bm{S}^2$. The vector $S^l$ is constructed from the real spherical harmonics $Y^l(\theta, \phi$), and a matrix $T^l \in \mathbb{C}^{(2l+1)\times(2l+1)}$ of complex coefficients as:
%
\begin{equation}
S^l(\theta, \phi) = T^lY^l(\theta, \phi)
\label{eq:real_fourier_transform}
\end{equation}
%
Refer \cite{lee2018real, blanco1997evaluation} for more details on spherical harmonics.

Let us suppose that the point cloud is rotated around its center of mass by a rotation $R \in SO(3)$ parameterized by the $ZYZ$ Euler angles $\alpha, \gamma \in [0,2\pi[$ and $\beta \in [0, \pi]$, with $g_r : \bm{S}^2 \rightarrow \mathbb{N}$ being the EGI of the rotated point cloud. Thereby, the rotation matrix $R$ can be expressed as:
%
\begin{equation}
R = R(\alpha, \beta, \gamma) = \exp(\alpha\hat{e}_z)\exp(\beta\hat{e}_y)\exp(\gamma\hat{e}_z)
\label{eq:euler_representation}
\end{equation}
%
where, $e_y$ and $e_z$ are the vectors $(0,1,0)$ and $(0,0,1)$, respectively. The operator $\hat{.}: \mathbb{R}^3 \rightarrow \mathfrak{so}(3)$ transforms a 3D vector into its $3\times3$ skew-symmetric matrix via the Lie algebra $\mathfrak{so}(3) = \{S \in R^{3\times3} | S + S^T = 0\}$.
Even though the representation in \eqref{eq:euler_representation} presents inherent singularities, it is extremely convenient for the computation of the Fourier transform on $\bm{SO(3)}$. Same as in \eqref{eq:real_fourier_transform_fr}, the Fourier transform of $g_r$ is given as:
%
\begin{equation}
g_r(\theta, \phi) = \sum_{l=0}^{B-1}(G^l_r)^TS^l(\theta, \phi) 
\label{eq:real_fourier_transform_gr}
\end{equation}
%
where $G^l_r \in \mathbb{R}^{(2l+1)\times1}$ are the Fourier parameters.

Considering that $g_r$ is a rotated version of $f_r$ and thus~\eqref{eq:gr} holds, the Fourier transform of $g_r$ can be computed using the Fourier parameter of $f_r$ by~\eqref{eq:real_fourier_transform_gr_simplified}.
%
\begin{equation}
g_r(\theta, \phi) = f_r(R^T(\theta, \phi))
\label{eq:gr}
\end{equation}
%
$R^T(\theta, \phi)$ is a notation shortcut for the expression $M_{s2c}^{-1}(R^TM_{s2c}(\theta, \phi))$, where $M_{s2c}:\bm{S}^2 \rightarrow \mathbb{R}^3$ is the function converting spherical to Cartesian coordinates, and $M_{s2c}^{-1}:\mathbb{R}^3 \rightarrow \bm{S}^2$, its inverse can be obtained using~\eqref{eq:spherical_coordinates}. Rewriting \eqref{eq:gr},
%
\begin{equation}
\begin{aligned}
g_r(\theta, \phi) &= \sum_{l=0}^{B-1}(F^l_r)^TS^l(R^T(\theta, \phi)) \\
&= \sum_{l=0}^{B-1}(U^l(R)F^l_r)^TS^l(\theta, \phi)
\end{aligned}
\label{eq:real_fourier_transform_gr_simplified}
\end{equation}
%
where, $U^l(R)=\overline{T^l}D^l(R)(T^l)^T$. $\overline{T^l}$ is the complex conjugate of $T^l$ and $D^l$ is the Wigner D-matrix. The expansion of \eqref{eq:real_fourier_transform_gr_simplified} is possible as rotations are expressed as Wigner D-Matrices in the spectral domain and applying a rotation to the basis functions $S^l$ is equivalent to applying a linear transformation of the basis functions by the equivalent Wigner D-Matrix. From \eqref{eq:real_fourier_transform_gr} and \eqref{eq:real_fourier_transform_gr_simplified}, it can be noticed that $G^l_r = U^l(R)F^l_r$. Thus, $G^l_r$ is obtained by applying the transformation $U^l(R)$ to the Fourier coefficients of $f_r$. More details on commonly used properties of the Winger D-matrix can be found in \cite{lee2018real, blanco1997evaluation, kostelec2008ffts}. %Authors of~\cite{lee2018real, blanco1997evaluation, kostelec2008ffts} provide more detail on the derivation of~\eqref{eq:real_fourier_transform_gr_simplified} as well as commonly used properties of the Winger D-matrix. 
The goal of the rotation estimation is to find $R$ given $f_r$ and $g_r$.

\subsubsection{Correlation over $\bm{SO}(3)$ and its derivatives}
The correlation of $f_r$ and $g_r$ on $\bm{SO}(3)$ is computed as:
%
\begin{equation}
\mathcal{C}_r(R) = corr(f_r,g_r) = \frac{1}{4\pi}\sum_{l=0}^{B-1}(G^l_r)^TU^l(R)F^l_r
\label{eq:correlation_rotation}
\end{equation}
%

This result is obtained after simplification, by replacing $f_r$ and $g_r$ by their Fourier representations expressed in~\eqref{eq:real_fourier_transform_fr} and~\eqref{eq:real_fourier_transform_gr_simplified}, using the convolution theorem of the Fourier transform\footnote{convolution in the spatial domain is equivalent to the multiplication of the Fourier coefficients in the spectral domain}, and the orthogonality principle of basis $S^l$. The relation $\langle S^l(\theta, \phi), (S^l(R^T(\theta, \phi))^T)\rangle=\frac{1}{4\pi}U^l(R)$ directly results from the orthogonality of the basis vectors $S^l$, where the operation $\langle . \rangle$ is the inner product on $\mathcal{L}^2(SO(3))$. In~\eqref{eq:correlation_rotation}, only $U^l$ depends on the rotation $R$, so the derivative of $\mathcal{C}_r$ can be obtained by computing the derivative of $U^l$. The derivative of $U^l$ at $R$ with respect to an elementary rotation $R_{\epsilon} = \exp(\epsilon \hat{\eta})$ ($\epsilon \approx 0$ and $\eta \in \mathbb{R}^3$) is computed as:
%
\begin{equation}
\left.\frac{d}{d \epsilon}\right|_{\epsilon=0} U^l(R \exp (\epsilon \hat{\eta}))= U^l(R)\left.\frac{d}{d \epsilon}\right|_{\epsilon=0} U^l(\exp (\epsilon \hat{\eta}))
\label{eq:ul_derivative}
\end{equation}

In the previous equation, the homomorphism property of $U^l$ is used, \emph{i.e}, $U^l(R_1R_2) = U^l(R_1)U^l(R_2)$ for $R_1, R_2 \in \bm{SO}(3)$. Then, the derivative of $\mathcal{C}_r$ is then computed by:
%
\begin{equation}
\begin{aligned}
\left.\frac{d}{d \epsilon}\right|_{\epsilon=0} \mathcal{C}_r(\exp(\epsilon\hat{\eta})) &= \frac{1}{4\pi}\sum_{l=0}^{B-1}(G^l_r)^TU^l(R)u^l(\eta)F^l_r \cdot \eta \\
&=\nabla \mathcal{C}_r(R, \eta) \cdot \eta
\end{aligned}
\label{eq:pre_cr_derivative}
\end{equation}
%
where, $\nabla \mathcal{C}_r(R, \eta) \in \mathbb{R}^3$ is the gradient of $\mathcal{C}_r(R)$ around the axis $\eta$ and $u^l(\eta) = \left.\frac{d}{d \epsilon}\right|_{\epsilon=0} U^l(\exp (\epsilon \hat{\eta}))$. Evaluating the gradient $\nabla \mathcal{C}_r(R, \eta)$ at $\eta = e_x, e_y, e_z$ allows finding the elementary rotation which applied to $R$ increases the correlation $\mathcal{C}_r$. More formally:
%
\begin{equation}
\left.\nabla \mathcal{C}_r(R, e_k)\right|_{k\in \{x, y, z\}} = \frac{1}{4\pi}\sum_{l=0}^{B-1}(G^l_r)^TU^l(R)u^l(e_k)F^l_r
\label{eq:cr_derivative}
\end{equation}
%

The computation of $u^l(e_k)$ is straightforward as it is a direct differentiation of the entries of the Wigner D-matrix for which an analytic derivative can be computed as in~\cite{lee2018real}. 

We can now use a gradient ascent method to iteratively find the ideal rotation. The following cost-function can be formulated to evaluate the performance of the rotation estimation algorithm on $\bm{SO}(3)$:
%
\begin{equation}
J_r(R) = \frac{1}{2}||g_r(\theta, \phi) - f_r(R^T(\theta, \phi))||^2
\label{eq:rotation_cost_function}
\end{equation}
%
%
% \subsection{Spectral Features for Visual Servoing}
%
\subsection{Controller}
To estimate the transformation $H = (R, T) \in \bm{SO}(3)\times\mathbb{R}^3$ between current and reference point clouds, the control law given in ~\eqref{eq:control_law} is used.
%
\begin{equation}
\begin{aligned}
T &= T + \lambda_t\nabla_{glob} T \\
R &= R\exp{(\lambda_r \widehat{\nabla \mathcal{C}_r})}
\end{aligned}
\label{eq:control_law}
\end{equation}
%
where, $\lambda_t, \lambda_r \in \mathbb{R}^+$ and $\lambda_t, \lambda_r <1$. $\nabla_{glob} T$ and $\nabla \mathcal{C}_r$ are computed from~\eqref{eq:fourier_shift_solution} and \eqref{eq:cr_derivative}, respectively. At the first iteration, $R$ and $T$ can be initialised randomly or set to identity and zero. %The update rule is applied until convergence, \textit{i.e.}, 
The controller converges when
\begin{equation}
    ||\nabla_{glob} T|| + ||\nabla \mathcal{C}_r|| < \epsilon_g
    \label{eq:updaterule}
\end{equation}
with $\epsilon_g \in \mathbb{R}^+$ being the tolerance. %The translation and rotational costs evolution is depicted in Fig.~\ref{fig:costs}. 
For commanding the robot, the following control law is used 
% we use the control laws in \eqref{eq:control_law} to obtain the relation 
% \begin{equation}
%     \dot{X} = \left [ \dot{\mathbf{p}}\quad{\mathbf{\omega}} \right]^T=\mathbf{\mathcal{J}}\dot {\mathbf{q}} \label{eq:control_equation}
% \end{equation}
% in which $\dot{\mathbf{p}}$ is the linear velocity obtained directly from \eqref{eq:control_law}, $\mathbf{\omega}$ is the angular velocity, $\mathbf{\mathcal{J}}$ is the robot Jacobian and $\dot{{\mathbf{q}}}$ the vector of joint velocities. Noting that the derivative of a rotation matrix can be expressed as $\dot{\mathbf{R}} = S(\mathbf{\omega})\mathbf{R}$, with $S(\cdot)$ being the hat map, we can use From \eqref{eq:control_law} to obtain the angular velocity input. That is,  $S(\mathbf{\omega})=\mathbf{R}\exp{(\lambda_r \widehat{\nabla \mathcal{C}_r})}\mathbf{R}^T$. Then, from \eqref{eq:control_equation} we can obtain the control law
\begin{equation}
    \dot {\mathbf{q}} = \mathcal{\bm{J}}_c^+\dot{X_c}
    \label{eq:robot_controller}
\end{equation}
with $\mathcal{\bm{J}}_c^+$ being the robot Jacobian pseudoinverse expressed in the camera frame, $\dot{{\mathbf{q}}}$ the vector of robot joint velocities and $\dot{X_c}$ the camera velocities, derived from \eqref{eq:control_law}. The complete control algorithm is presented in Alg.~\ref{alg:algorithm}.
%
% \begin{figure}
%     \centering
%     \includegraphics[width=\columnwidth]{figures/dummy3.pdf}
%     \caption{Illustration of translation and rotational costs convergence domains.}
%     \label{fig:costs}
% \end{figure}
%
\begin{algorithm}[t]
\label{alg:algorithm}
 \caption{3D spectral domain visual servoing}
  Initialise $R$ to identity\\
  Initialise $T$ to zero\\
  Initialise the step sizes $\lambda_t, \lambda_r$ and the tolerance
  $\epsilon_g$ \\
  Compute $f_t$ \eqref{eq:voxel}, $f_r$ \eqref{eq:egi}, $F_t$ \eqref{eq:fourier_coefs}, $F^l_r$ of the target cloud \\
%   \vspace{2mm} \\
  \While{$||\nabla_{glob} T|| + ||\nabla \mathcal{C}_r|| >= \epsilon_g$}{
  Capture the scene point cloud
  Compute $g_t$ \eqref{eq:voxel}, $g_r$ \eqref{eq:egi}, $G_t$ \eqref{eq:fourier_coefs}, $G^l_r$ of the reference cloud \\
  Compute $\nabla_{glob} T$ \eqref{eq:fourier_shift_solution} and $\nabla \mathcal{C}_r$ \eqref{eq:cr_derivative} \\
  Apply the update rule \eqref{eq:control_law} \\
  Compute the cost $J = J_t(T) + J_r(R)$ \\
   Command the robot using \eqref{eq:robot_controller}\\
  }
  Get final transformation $H = (R, T)$ \\

\end{algorithm}
%

%\bt{A first vision-based controller close to a robotic iterative registration task is used to perform the experimental validations. Thus, using the estimated translation $T$ and rotation $R$ from~\eqref{} }
%
% \naresh{Equations for robot control will go here...}



