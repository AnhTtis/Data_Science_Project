\section{Top-$k$ Attack}
\label{app:exp_top_k}



\AlgoNameTop is our efficient method that selects the Top-$k$ predictions from the classifier. This approach speeds up processing but might be vulnerable to adaptive attacks that exploit this specific mechanism, such as the Top-$k$ attack aimed at excluding the true class from the classifier’s Top-$k$ predictions. Typical attacks like PGD \cite{madry2017towards} focus on reducing the probability of the correct class as much as possible, which can sometimes result in outcomes similar to a Top-$k$ attack. However, achieving this is not their explicit design.

To address this, we introduce two additional adaptive attacks specifically designed to exploit the Top-$k$ vulnerability. The first, Top PGD Out (TPO), performs targeted PGD by iteratively sampling a class ranked outside of the Top-$k$ predictions and attacking towards it. The second, Top PGD In Out (TPIO), extends TPO by also removing the probability of the correct class entirely from the model’s predictions, further intensifying the attack’s focus on reducing Top-$k$ accuracy. In addition to these attacks, the RCE attack, proposed by Zhang \emph{et al.} \cite{zhang2022investigating}, is specifically designed to remove the correct class from the Top-$k$ predictions by using normalized cross-entropy loss to update logits in the direction of maximizing the rank distance. This makes RCE a suitable baseline for our evaluation alongside TPO and TPIO.


In \cref{table:top_k}, we compare the RCE attack, TPO, and TPIO to the PGD attack, specifically evaluating their effectiveness as Top-$k$ attacks by assessing the mean accuracy of the correct class appearing among the Top-$k$ predictions, rather than general model accuracy. This distinction is crucial, as the reported values reflect Top-$k$ accuracy, not the standard accuracy of the classifier in predicting the most likely class (Top-$1$ accuracy).

For example, the model by Rebuffi \cite{rebuffi2021fixing} under PGD achieves a $99.05\%$ Top-$80$ accuracy, meaning that even under a PGD attack, the true class has a $99.05\%$ likelihood of being among the top $80$ predictions of the classifier. Our results demonstrate that for k=1, the PGD attack more effectively reduces Top-$1$ accuracy, achieving a lower Top-$1$ accuracy compared to the RCE, TPO, and TPIO attacks. For higher k values, RCE perform better, evidenced by slightly lower Top-$k$ accuracy.

We want to emphasize that, despite using standard attacks for all experiments involving \AlgoNameTopNoSpace, rather than specialized Top-$k$ attacks, our results are consistently reliable. We acknowledge the potential risk that a standard attack may not fully exploit the Top-$k$ vulnerability. However, our findings clearly demonstrate that even adaptive attacks such as RCE, TPO, and TPIO, specifically designed to target Top-$k$ vulnerabilities, fail to undermine our defense.





\input{tables/top_k}


