\section{Our method}
\label{sec:our_method}
In this section, we supply an overview of our method.
Next, we offer a detailed explanation that goes through the motivation and each part of our algorithm. 
Finally, we present an efficient alternative for our method.


\begin{figure*}[th]
    \centering
    \includegraphics[width=\textwidth]{images/method.pdf}
    \caption{
      \textbf{A Comparison Between the Classifier and \AlgoName Decision Rules}
    The background color of the image describes the classifier's classification rules, and the intensity describes the classifier's certainty.
    The clean image (green dot) is attacked (red dot), leading to a wrong classification.
    In contrast, \AlgoName predicts based on the shortest transformation.
    It operates in two steps: First, it class conditioned transform (dotted arrow) the attacked image towards each one of the datasets's classes (blue dots). 
    Next, prediction is made based on the shortest distance between the attacked image and the transformed images, highlighted by a red dotted circle.
    }
    \label{fig:method}
\end{figure*}

\subsection{Method Overview}
We propose a test-time classification method that enhances an AT classification model for seen and unseen attacks.
Our method does not operate in the standard classification methodology $f : x \rightarrow y$, where $f(\cdot)$ is the classifier, $x\in R^{H\text{x}W\text{x}3}$ is the input image, $y \in [0,1]^N$ is the prediction probability vector, and $N$ is the number of classes of the dataset.

Instead, our method operates through two phases, as illustrated in \cref{fig:method}: 
First, we get an input image (which can be either clean or attacked) and transform it $N$ times, each time to a different class of the dataset.
The transformation utilizes the PAG property of the AT classifier and, hence, does not require additional architecture or additional training. 
The transformation is performed through an iterative class-conditioned regularized optimization process.
For every class, we perform $M$ such optimization steps, in each step we follow two objectives.
First, maximizing the classifier probability towards the current class.
Second, regularizing the transformation so the transformed image will stay close to the input image $x$.



\begin{algorithm*}[t!]
    \caption{CODIP}
    \label{alg:CODIP}
    \hspace*{\algorithmicindent}\textbf{Input} \text{   }classifier $f(\cdot)$, input image $x$, step size $\alpha$, regularization coefficient $\gamma$, \\ \hspace*{\algorithmicindent}\hspace*{\algorithmicindent} \hspace*{\algorithmicindent} number of iterations $M$, number of dataset's classes $N$ 
    \begin{algorithmic}[1]
    \Procedure{CODIP}{}
        \For{\texttt{$i \in  C = \{1,\dots, N\}$}} \Comment{Iterate over \# classes} \label{alg:loop_over_classes}
            \State $\mathbf{T}_{i 0} \gets 0$  \Comment{Initialize the $i^{th}$ transformation} \label{alg:CODIP_init}
            \For{\texttt{$j$ in $0:M-1$}} \Comment{Iterate over \# steps}
                \State $\mathbf{G}_{ij} \gets \nabla_{\mathbf{T}_{ij}}\left[ L_{CE}\left( f \left( x+ \mathbf{T}_{ij} \right), i \right) + \gamma \, \| \mathbf{T}_{ij} \|_2^2 \right]$ \label{alg:CODIP_calc_grad}
                \State $\mathbf{T}_{ij+1} \gets \Pi \left( \mathbf{T}_{ij} - \alpha \, \frac{\mathbf{G}_{ij}}{\| \mathbf{G}_{ij} \|_2 } \right)$ \label{alg:CODIP_update_trans}
            \EndFor
        \EndFor
    \State $\mathbf{d} \gets \|\mathbf{T}_{1:N M}\|_{2}$ \Comment{Update the transformation distances for each class} \label{alg:CODIP_clac_distance}
    \State $\hat{y} = \mathrm{arg}\min_{i=1,\dots,N} \mathbf{d}_i$ \Comment{Classify based on the shortest distance} \label{alg:CODIP_prediction}
    \State \Return $\hat{y}$
    \EndProcedure
    
    \end{algorithmic}
    The operator $\Pi(z)$ projects $z$ onto the image domain $\mathbb{R}^{H \times W \times 3} \in [0,1]^{H  \times W \times 3}$ by clipping its values. 
\end{algorithm*}


\subsection{\AlgoName}
In what follows, we detail our method summarized in \cref{alg:CODIP}:
We perform $N$ transformations towards each one of the dataset's classes, and we initialize the $i^{th}$ class transformation to zero $\mathbf{T}_{i0}$, in \cref{alg:CODIP_init}. 
Next, we start the transformation, which operates through $M$ gradient descent steps. 
In each iteration, we calculate the gradient of our objective and store it in $\mathbf{G}_{ij}$ in \cref{alg:CODIP_calc_grad}. 
Next, in \cref{alg:CODIP_update_trans}, we perform a gradient descent step in the direction of $\mathbf{G}_{ij}$, the step of size $\alpha$ which is a hyper-parameter. 
It is essential to normalize the gradient step since we want to make an even progress in each step, regardless of the gradient size.
Without normalization, the step size might be very small, which will prevent us from making progress during the transformation.
Before finishing the update step, in \cref{alg:CODIP_update_trans}, we perform a projection back to the image domain to $R^{H \times W \times 3} \in [0,1]^{H \times W \times 3}$. 
When finishing the transformation's iterations, we calculate the transformation distance using $\ell_2$ over the $M^{th}$ column of the transformation matrix, and we store it in the distance vector $\mathbf{d}$, in \cref{alg:CODIP_clac_distance}. 
Finally, when the process is over we predict according to the shortest transformation. 


\input{tables/cifar10_cifar100}

\begin{figure}[h!]
    
  \begin{center}
    \includegraphics[width=0.4\textwidth]{images/gamma_effect.pdf}
  \end{center}
  \vspace{-15pt}
  \caption{
    \textbf{Impact of $\gamma$ on Clean-Robust Accuracy Trade-off } We present three $\alpha$ working points on the ImageNet dataset using an AT model $L_2,\epsilon = 3.0$.
    }
  \label{fig:gamma_tradeoff}
\end{figure}

\AlgoNameNoSpace's objective, which appears in \cref{alg:CODIP_calc_grad}, weights two targets: 
The first term, $L_{CE} \left(f \left(x + \mathbf{T}_{ij}\right), i \right)$, is a cross entropy loss between the classifier's prediction $f(\cdot)$ over the $j^{th}$ step of the $i^{th}$ transformation $x + \mathbf{T}_{ij}$, and the current class $i$. 
The goal of this term is to measure the classifier's error towards class $i$ and to transform the image so it semantically looks like class $i$.
The goal of the second term, $\gamma \| \mathbf{T}_{ij} \|_2 $, is to regularize the transformation to stay close to the input image $x$. 
This regularization is needed since we desire to change the input image toward class $i$ with minimal semantic changes.
Without this term, the transformation could turn the image into any instance of class $i$. 
Even in the case where $i$ is the true class, we can change the image into a completely different instance of the class, ultimately nullifying the efficacy of our method.
To conclude, balancing between the two terms, which is determined by the hyper-parameter $\gamma$, influences the class-similarity transformation balance, hence, it is essential.%for the success.% of the classification.
We demonstrate the impact of changing this value in \cref{fig:gamma_tradeoff}, and discuss it further in Appendix H.









\subsection{\AlgoNameTopNoSpace}
While \AlgoName is an effective algorithm that significantly enhances the classifier robustness, its inference time grows with the number of datasets' classes. 
To mitigate this issue, we propose \AlgoNameTopNoSpace, which reduces the inference time significantly by filtering out the classes with the lowest probability.


The classifier predicts the probability of the input image belonging to each class $f(x) \rightarrow \mathbb{R}^N \in [0,1]^N$. 
One way to speed up our algorithm is by limiting our prediction only to the most probable classes predicted by the classifier.
More specifically, we choose a group of $k$ classes $C_k \subset C=\{1, \dots, N\}$ containing the top-$k$ most probable prediction made by the classifier.
Next, we modify our method, which is presented in \cref{alg:CODIP}, by adapting \cref{alg:loop_over_classes} to transform only towards the most probable classes $C_k$.


