\section{$\gamma$ Effect on Clean-Robust Accuracy Trade-off}
\label{app:gamma_tradeoff}



As demonstrated in Fig. 3, the hyperparameter $\gamma$ plays a critical role in controlling the clean-robust accuracy trade-off across different values of $\alpha$. Both $\alpha$ and $\gamma$ contribute to restricting the transformation in order to maintain the accuracy of the model. While $\alpha$ primarily governs the magnitude of the perturbation, $\gamma$ regularizes the transformation by ensuring that it remains subtle enough to preserve the natural characteristics of the image while successfully changing its class, even in the presence of small-norm perturbations.



When $\gamma = 0$, the transformation is unregularized, leading to a situation where both clean and robust accuracy suffer significantly. Without the restriction provided by $\gamma$, the transformation can deviate excessively from the input image, negatively impacting both clean accuracy and robustness. This issue is illustrated in \cref{fig:CODIP_vs_PGD}, where we compare transformations produced by \AlgoName and targeted PGD. The image transformed by \AlgoName (right) maintains a closer resemblance to the original input image, while the image generated by targeted PGD (left) appears unnatural and distorted. The $\ell_2$ distances further highlight this: \AlgoName achieves a much lower distance (11.22) compared to targeted PGD (42.97). In addition, in Fig. 3, we show that both robust and clean accuracy metrics are substantially worse when $\gamma = 0$, emphasizing that an unregularized transformation fails to achieve the desired balance between robustness and preserving the integrity of the original input.


To achieve the optimal balance between clean and robust accuracy, it is essential to carefully tune $\gamma$. In Fig. 3, we present three graphs that illustrate the impact of different $\gamma$ values across various $\alpha$ settings. In each experiment, increasing $\gamma$ initially improves clean accuracy. For larger $\alpha$ values, increasing $\gamma$ significantly enhances robustness, though after a certain threshold, clean accuracy may begin to slightly decrease. For smaller $\alpha$, robust accuracy increases slightly before eventually decreasing. These findings demonstrate that while careful tuning of $\gamma$ is necessary, it remains a critical parameter for managing the clean-robust trade-off, as it controls how closely the transformation adheres to the original image, especially under varying perturbation magnitudes. Specifically, we show its pivotal role in controlling clean accuracy

% As demonstrated in Fig. 3, the hyperparameter $\gamma$ plays a crucial role in regulating the clean-robust accuracy trade-off across different values of $\alpha$. While both $\alpha$ and $\gamma$ seem to serve a similar purpose—restricting the transformation to maintain accuracy—$\gamma$ proves essential even when $\alpha$ is small. Specifically, for small $\alpha$, increasing $\gamma$ significantly improves clean accuracy without substantially affecting robustness. This is because the conditioned transformation remains necessary even for small-norm transformations to prevent excessive changes to the input.

% For larger $\alpha$, $\gamma$ enhances both robustness and clean accuracy initially, but eventually, over-regularization leads to a slight decline in clean accuracy. This behavior shows that $\gamma$ must be carefully tuned, even when $\alpha$ is small, to ensure the transformation stays effective without compromising the clean-robust trade-off. Thus, $\gamma$ is key for modulating the transformation across various $\alpha$ values, particularly in maintaining clean accuracy in scenarios where small-norm transformations are applied.



% In the next experiment, we emphasize the transformation benefits of \AlgoName, as we compare our method to targeted PGD on \cref{fig:CODIP_vs_PGD}.
% Both targeted PGD and \AlgoName change the image's appearance, trying to change its predicted class. 
% However, targeted PGD  creates an image that does not look natural,
% while \AlgoName creates a natural-looking image, as it keeps the transformed image pixel-wise close to the input image.







\begin{figure*}[h!]
  \begin{center}
  \vspace{-12pt}
    \includegraphics[width=0.4\textwidth]{images/CODIP_vs_PGD.pdf}
  \end{center}
  \vspace{-10pt}
  \caption{
    \textbf{\AlgoName vs. Targeted PGD} A comparison between \AlgoName and targeted PGD class conditioned transformations. 
    An image of \emph{lorikeet} is transformed into a \emph{toucan} using \AlgoName and targeted PGD. A $\ell_2$ distance between the clean image and the transformed ones is stated beneath the attack name.
}
  \label{fig:CODIP_vs_PGD}
\end{figure*}
