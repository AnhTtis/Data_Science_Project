\setlength{\tabcolsep}{4pt}
\begin{table}[ht!]
\begin{center}

\begin{tabular}{lcccc}
\hline\noalign{\smallskip}\hline

\multirow{1}{*}{Method} & \multirow{1}{*}{Architecture} & \multirow{1}{*}{TTM} & \multirow{1}{*}{Inference time}\\


\hline\noalign{\smallskip}\hline\noalign{\smallskip}

Rebuffi et al. \cite{rebuffi2021fixing} & \multirow{3}{*}{WRN28-10} & \multirow{3}{*}{$L_{inf}, \epsilon=8/255$} & $\times 1$\\

DRQ \cite{schwinn2022improving} & & & $\times 686 $\\

FETRA & & & $\times 27$\\

\hline\noalign{\smallskip}

Gowal et al. \cite{gowal2020uncovering} & \multirow{3}{*}{WRN70-16} & \multirow{3}{*}{$L_{\infty}, \epsilon=8/255$} & $\times 1$\\

DRQ \cite{schwinn2022improving} & & & $\times 1380$\\

FETRA & & & $\times 121$\\


\hline\noalign{\smallskip}\hline\noalign{\smallskip}
\end{tabular}
\caption{Inference time comparison over CIFAR100. In this table we perform an inference time comparison between 3 defense methods. For every base classifier, we report three consecutive lines of inference time. One for the base method, next we present DRQ, and finally TETRA. In the first column we present the method name. Next we present the architecture, and the trained threat model (TTM), and finally we present the inference time. This value stands for how much time it takes for every method to perform.}
\label{table:cifar100_runtime}
\end{center}
\end{table}
