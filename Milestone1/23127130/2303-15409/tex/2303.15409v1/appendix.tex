\appendix
\onecolumn

\section{Experimental setup}
\label{app:exp_setup}

In this part, we provide some details about our methods. We are performing AutoAttack \cite{croce2020reliable} on the base classifier, then performing our defense method. Similar to previous works such as \cite{schwinn2022improving}. We use $N=30$ steps of TETRA and perform hyperparameter tuning, finding the best step size $\alpha$ and $\gamma$ for every classifier. We use these parameters for all the evaluations, clean images and all of the attacks. We state both $\alpha$ and $\gamma$ for every dataset in \cref{table:cifar10_param,table:cifar100_param,table:imagenet_param}. 

We evaluated the other test-time defense, DRQ \cite{schwinn2022improving}, with the official code using the reported parameters.

\input{tables/cifar10_param}

\input{tables/cifar100_param}

\input{tables/imagenet_param}



\clearpage
\section{RPGD analysis}
\label{app:RPGD}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{images/RPGD_cifar10.pdf}
    \caption{CIFAR10 top $k$ accuracy comparison PGD vs RPGD. the x-axis of the left figure represents the top $k$ group size that we select, using Madry et al. \cite{madry2017towards} $\ell_{2}, \epsilon=0.5$. The y-axis represents the top $k$ accuracy, the probability that the true label is contained in the top $k$ group. On the right figure, we present the difference between the two graphs of the left figure, $PGD - RPGD$.}
    \label{fig:RPGD_cifar10}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{images/RPGD_cifar100.pdf}
    \caption{CIFAR100 top $k$ accuracy comparison PGD vs RPGD. the x-axis of the left figure represents the top $k$ group size that we select, using Madry et al. \cite{rebuffi2021fixing} $\ell_{\infty}, \epsilon=8/255$. The y-axis represents the top $k$ accuracy, the probability that the true label is contained in the top $k$ group. On the right figure, we present the difference between the two graphs of the left figure, $PGD - RPGD$.}
    \label{fig:RPGD_cifar100}
\end{figure}





\clearpage
\section{Ablation study}
\label{app:ablation}


In this part, we discuss the ablations that we performed in order to better understand the contribution of different parts of our method. In \cref{app:vanila} we discuss the necessity of the PAG property in the TETRA algorithm, next in \cref{app:distances} we discuss different options for the distance metric used for classification.








\subsection{Vanila classifier}
\label{app:vanila}

TETRA can be applied to any differentiable classifier. We claim, however, that it enhances the classifier robustness only over classifiers that possess PAG. In this part, we empirically support this claim. 

In \cref{table:cifar10_vanila}, we present TETRA accuracy on CIFAR10 dataset, where the classifier is vanilla trained. As we can see, TETRA achieves an accuracy of around $1\%$ for all of the attacks. When applying TETRA to PAG classifiers, it achieves much better results, as presented in \cref{table:cifar10}. Meaning that TETRA performs well only when applied to classifiers that possess the PAG property. The reason is that our method heavily relies on the generative power of PAG, which does not exist in vanilla-trained classifiers.

\input{tables/cifar10_vanila}




\clearpage
\subsection{Distance metrics}
\label{app:distances}

In TETRA's second phase, we calculate the distance between the input image and the transformed images, and we classify based on the shortest one. Hence, the distance metric that we use for the classification is important. Different metrics have different properties, and we aim at a distance metric that is able to measure the semantic distance between images. 

We compare $\ell_{2}$, $\ell_{1}$ and LPIPS \cite{zhang2018unreasonable} distances over CIFAR10 dataset, and presente the results in \cref{table:cifar10_distances}. We compare the results using the following defense methods \cite{madry2017towards,rebuffi2021fixing,gowal2020uncovering}. As demonstrated, $\ell_{2}$ distance metric performs better, therefore is a favorable choice.


\input{tables/cifar10_distances}

% \input{tables/cifar10_LPIPS} - transformation using LPIPS


% \subsection{Transformation process}
% \label{app:transformation_process}



\clearpage
\section{Runtime analysis}
In this part, we compare the inference time of the test-time methods that we used, over CIFAR10 and CIFAR100. For CIFAR10 we compare TETRA to DRQ \cite{schwinn2022improving}, and for CIFAR100 we compare FETRA to DRQ \cite{schwinn2022improving}. As can be seen, for both of the datasets, our method is slower than the baseline. Our method, however, is faster than DRQ \cite{schwinn2022improving}. These experiments were performed using one GeForce RTX 3080 with batch size $=1$.

\label{app:runtime}
\input{tables/cifar10_runtime}
\input{tables/cifar100_runtime}




