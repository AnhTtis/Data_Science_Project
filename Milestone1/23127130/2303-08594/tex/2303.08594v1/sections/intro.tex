% \vspace{-2mm}
\section{Introduction}

Instance segmentation aims to segment all objects of interest in an image. The mainstream methods like Mask R-CNN~\cite{he2017mask,huang2019mask,chen2019hybrid,liu2018path} follow the design of detection-then-segmentation. Despite being simple and intuitive, those methods generate a lot of duplicate region proposals that introduce redundant computations. To improve efficiency, many single-stage methods~\cite{yolact-plus-tpami2020,lee2020centermask,chen2019tensormask,wang2020solov2} built upon Fully Convolutional Networks (FCNs)~\cite{long2015fully} appear. They segment objects end-to-end without region proposals. The inference speed of such methods is appealing, especially in real-time scenes. 
However, due to the dense predictions, the classical single-stage methods still rely on manually-designed post-processing steps like non-maximum suppression (NMS).

\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{figures/trade-off.pdf}
	\caption{\textbf{Speed-performance trade-off on COCO \texttt{test-dev}.} All models employ ResNet-50~\cite{he2016deep} as the backbone except OrienMask with DarkNet-53~\cite{redmon2018yolov3}. Our \modelname surpasses most \sota real-time instance segmentation algorithms in both speed and accuracy. To keep the speed and accuracy in a similar order, Mask2Former here takes the pyramid pooling module-based~\cite{zhao2017pspnet} FPN as the pixel decoder, the same as FastInst and SparseInst. }
	\label{fig:tradeoff}
	\vspace{-5mm}
\end{figure}

Recently, with the success of DETR~\cite{detr} in object detection, query-based single-stage instance segmentation methods~\cite{li2021panopticsegformer,cheng2021maskformer,cheng2021mask2former, wu2022efficient} have emerged. Instead of convolution, they exploit the versatile and powerful attention mechanism~\cite{vaswani2017attention} combined with a sequence of learnable queries to infer the object class and segmentation mask. For example, Mask2Former~\cite{cheng2021mask2former} simplifies the workflow of instance segmentation by adding a pixel decoder and a masked-attention Transformer decoder on top of a backbone. Unlike previous methods~\cite{he2017mask,wang2020solov2}, Mask2Former does not require additional handcrafted components, such as training target assignment and  NMS post-processing. While being simple, Mask2Former has its own issues: 
(1) it requires a large number of decoder layers to decode the object queries since its queries are learned static and need a lengthy process to refine; 
(2) It relies upon a heavy pixel decoder, \eg, multi-scale deformable attention Transformer (MSDeformAttn)~\cite{zhu2021deformable}, because its object segmentation mask straightforwardly depends on the output of the pixel decoder, which is used as a per-pixel embedding feature for distinguishing different objects;
(3) masked attention restricts the receptive field of each query, which may cause the Transformer decoder to fall into a suboptimal query update process. 
Although Mask2Former achieves outstanding performance, its superiority on fast, efficient instance segmentation has not been well demonstrated, which yet is critical for many real-world applications such as self-driving cars and robotics.
In fact, due to the lack of prior knowledge and the high computational complexity of the attention mechanism, the efficiency of query-based models is generally unsatisfactory ~\cite{cheng2021mask2former, li2021panopticsegformer,hu2021istr}. 
The efficient real-time instance segmentation benchmarks are still dominated by classical convolution-based models~\cite{cheng2022sparseInst,wang2020solov2}.

In this paper, we fill this gap by proposing \modelname, a concise and effective query-based framework for real-time instance segmentation. We demonstrate that the query-based model can achieve outstanding performance on the instance segmentation task while maintaining a fast speed, showing great potential in efficient instance segmentation algorithm design. 
As an example, our designed fastest query-based model with ResNet-50~\cite{he2016deep} backbone achieves 35.6 AP at 53.8 FPS (frames-per-second) on the COCO~\cite{lin2014coco} \texttt{test-dev}, evaluated on a single V100 GPU (see \figref{fig:tradeoff});
moreover, our best trade-off model can execute at a real-time speed, \ie, 32.5 FPS, while yielding an AP of more than 40, \ie, 40.5 AP, which to the best of our knowledge, has not yet been achieved in previous methods. 

Specifically, our model follows the meta-architecture of  Mask2Former~\cite{cheng2021mask2former}. To achieve efficient real-time instance segmentation, we have proposed three key techniques.
% Specifically, our model is built upon Mask2Former framework~\cite{cheng2021mask2former}. Three key improvements have been proposed to improve efficiency. 
First, we use instance activation-guided queries, which dynamically pick the pixel embeddings with high semantics from the underlying feature map as the initial queries for the Transformer decoder. Compared with static zero~\cite{detr} or learnable~\cite{cheng2021maskformer,cheng2021mask2former} queries, these picked queries contain rich embedding information about potential objects and reduce the iteration update burden of the Transformer decoder. 
%A location-sensitive Hungarian loss is designed to help identify the sparse representative embeddings of objects. 
Second, we adopt a dual-path architecture in the Transformer decoder where the query features and the pixel features are updated alternately. Such a design enhances the representational ability of pixel features and saves us from the heavy pixel decoder design. Moreover, it makes a direct communication between query features and pixel features, which speeds up the iterative update convergence and effectively reduces the dependence on the number of decoder layers.
Third, to prevent the masked attention from falling into a suboptimal query update process, we introduce ground truth mask-guided learning. We replace the mask used in the standard masked attention with the last-layer bipartite matched ground truth mask to forward the Transformer decoder again and use a fixed matching assignment to supervise the outputs. This guidance allows each query to see the whole region of its target predicted object during training and helps masked attention attend within a more appropriate foreground region.

We evaluate \modelname on the challenging MS COCO dataset~\cite{lin2014coco}. As shown in \figref{fig:tradeoff}, \modelname obtains strong performance on the COCO benchmark while staying fast, surpassing most of the previous \sota methods. We hope \modelname can serve as a new baseline for real-time instance segmentation and advance the development of query-based instance segmentation models.

