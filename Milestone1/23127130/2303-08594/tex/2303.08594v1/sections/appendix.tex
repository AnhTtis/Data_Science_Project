We first provide several additional ablation studies for \modelname in \appref{app:ablations}. Then, we demonstrate the performance of \modelname on a different dataset, \ie, Cityscapes~\cite{Cordts2016Cityscapes}, in \appref{app:datasets}, and show its unified segmentation ability in \appref{app:unified}. Finally, we visualize many predictions of \modelname on the COCO~\cite{lin2014coco} validation set in \appref{app:vis}.

\section{Additional ablation studies}
\label{app:ablations}

\subsection{Improvements on original Mask2Former}

Considering that the proposed \modelname is developed based on Mask2Former, we investigate the improvements of three proposed key components, \ie, instance activation-guided queries, dual-path update strategy, and ground truth mask-guided learning, on the original Mask2Former. The results are shown in \tabref{tab:ablation:mask2former}. Dual-path update strategy improves Mask2Former's efficiency the most, not only accelerating its inference speed but also reducing the model parameters dramatically. GT-mask guided learning also performs well on the original Mask2Former. The instance activation-guided queries improve the original Mask2Former little since the original Mask2Former already has enough Transformer decoder layers (\ie, nine layers), and the learnable queries can also be decoded well. Note that IA-guided queries contribute to the 3-layer dual-path Transformer decoder.


\subsection{Effect of location cost on deformable convolutional networks}
We employ Hungarian loss~\cite{detr} with a location cost during training to supervise the auxiliary classification head.
The location cost restricts the matched pixels inside the object region,  which reduces the matching space and, thus, accelerates training convergence.
\tabref{tab:ablation:loc} shows that this location cost is also effective for \modelname with the backbone that employs deformable convolutional networks (DCNs)~\cite{zhu2019deformable}. DCNs add 2D offsets to the regular grid sampling locations in the standard convolution and enable the pixels not located in the object region to have a chance of being activated for the segmentation. Despite this, the pixels outside the object region are not good IA-guided query candidates since they rely on precise offset predictions.
\figref{fig:vis_dcn_query_points} visualizes the distributions of IA-guided queries with/without the location cost in a FastInst-D1 model with DCNs. The location cost helps produce more concentrated and higher-quality IA-guided queries.

\subsection{Effect of local-maximum-first selection strategy}
During prediction, we first select the pixel embeddings in E$_4$ with $p_{i,k_i}$ that is the local maximum in the corresponding class plane and then pick the ones with the top foreground probabilities. Such a local-maximum-first selection strategy prevents the selected IA-guided queries from focusing on some salient objects.
\tabref{tab:ablation:ms} demonstrates the effectiveness of the local-maximum-first selection strategy. It improves the performance, especially when the IA-guided query number is small.
\figref{fig:vis_q10_query_points} shows the influence of the local-maximum-first selection strategy on the selected IA-guided queries. Without the local-maximum-first selection strategy, two selected queries fall on the same salient object (\ie, handbag), which hurts the recall of other instances.


\begin{table}[t]
	\centering
	\scriptsize
  \setlength\tabcolsep{1.7mm}
  % \setlength{\abovecaptionskip}{0.5mm}
	%\setlength{\belowcaptionskip}{-3.5mm}
	\begin{tabular}{lccccccccccc}
	A & & & & & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark\\
   B & & \checkmark & & \checkmark & & \checkmark & & \checkmark & \checkmark\\
   C & & & \checkmark & \checkmark & & & \checkmark & \checkmark & \checkmark\\
   E & & & & & & & & & \checkmark \\
   \hline
   Param.(M) & 40.9 & 41.4 & 40.9 & 41.4 & \textbf{33.5} & 34.1 & \textbf{33.5} & 34.1 & 34.2 \\
   FPS & 25.3 & 24.5 & 25.3 & 24.5 & 34.3 & 32.9 & 34.3 & 32.9 & \textbf{35.5} \\
   AP$^\texttt{val}_{coco}$ & 37.2 & 37.3 & 37.6 & 37.6 & 36.9 & 37.3 & 37.5 & 37.8 & \textbf{37.9} \\
	\end{tabular}
	\caption{\textbf{Improvements on original Mask2Former.} A: 3-layer dual-path Transformer decoder (including little head change). B: IA-guided queries. C: GT mask-guided learning. E: learnable positional embeddings and auxiliary queries. The baseline is Mask2Former with PPM-FPN and 9 Transformer decoder layers. With A, B, C, and E, we achieve our FastInst-D3 model (R50 backbone).}
   \label{tab:ablation:mask2former}
\end{table}


\begin{table}[t]
	\centering
	\tablestyle{2pt}{1.2}
	\scriptsize
	\begin{tabular}{p{53px} | x{42} | x{25} x{20} x{20}x{20}|x{23}}
		& backbone & \phantom{0}\apm$^\texttt{val}$ & \aps & FPS \\
		\shline
		%w/o location cost & R50 & 34.0 & 12.5 & 36.9 & 55.1 & 48.8 \\
		%\textbf{w/  location cost} & R50 & \textbf{35.6}\tiny(\gain{+1.6}) & \textbf{14.3} & \textbf{38.8} & \textbf{56.6} & 48.8 \\
		%\hline\hline
		w/o location cost & R50-d-DCN & 36.5 & 14.8 & 39.6 & 59.2 & 43.3 \\
		\textbf{w/  location cost} & R50-d-DCN & \textbf{38.1}\tiny(\gain{+1.6}) & \textbf{16.2} & \textbf{41.5} & \textbf{60.6} & 43.3 \\
		\hline
	\end{tabular}
	\caption{\textbf{Effect of location cost on DCNs.} The location cost is also important for \modelname with the backbone that employs DCNs. We conduct ablation studies on the \modelname-D1-640 model.}
	\vspace{-3mm}
	\label{tab:ablation:loc}
\end{table}

\begin{table}[t]
	\centering
	\tablestyle{2pt}{1.2}
	\scriptsize
	\begin{tabular}{p{75px} | x{20} | x{25} x{20} x{20}x{20}|x{23}}
		& $N_a$ & \phantom{0}\apm$^\texttt{val}$ & \aps & FPS \\
		\shline
		w/o local-maximum-first & 10 & 28.6 & 9.0 & 30.0 & 49.3 & 53.5\\
		\textbf{w/  local-maximum-first} & 10 & \textbf{30.0}\tiny(\gain{+1.4}) & \textbf{9.8} & \textbf{32.1} & \textbf{51.3} & 52.9 \\
		\hline\hline
		w/o local-maximum-first & 50 & 34.4 & 13.9 & 36.9 & 55.3 & 51.3 \\
		\textbf{w/  local-maximum-first} & 50 & \textbf{34.8}\tiny(\gain{+0.4}) & \textbf{14.2} & \textbf{37.6} & \textbf{55.7} & 51.0 \\
    \hline\hline
		w/o local-maximum-first & 100 & 35.3 & \textbf{14.6} & 38.2 & 56.3 & 49.0 \\
		\textbf{w/  local-maximum-first} & 100 & \textbf{35.6}\tiny(\gain{+0.3}) & 14.3 & \textbf{38.8} & \textbf{56.6} & 48.8 \\
    \hline
	\end{tabular}
	\caption{\textbf{Effect of local-maximum-first selection strategy.} The local-maximum-first selection strategy is effective, especially when the IA-guided query number (\ie, $N_a$) is small. We conduct ablation studies on \modelname-D1-640 with ResNet-50 backbone.}
	\label{tab:ablation:ms}
\end{table}


\begin{figure}[!t]
  \centering
  \begin{adjustbox}{width=\linewidth}
  \bgroup
  \def\arraystretch{0.2}
  \setlength\tabcolsep{0.2pt}
  \begin{tabular}{cc}
  \includegraphics[width=0.49\linewidth]{figures/visualization/ablations/dcn_query_points_without_loc/000000001268} &
  \includegraphics[width=0.49\linewidth]{figures/visualization/ablations/dcn_query_points_with_loc/000000001268} \\
  \end{tabular} \egroup
  \end{adjustbox}
  \caption{
    \textbf{Effect of location cost on IA-guided queries with DCNs.} Left: not use the location cost. Right: use the location cost. We visualize the distributions of IA-guided queries in \modelname-D1-640 with a ResNet-50-d-DCN backbone. A few IA-guided queries are located in the padding area (for the size divisibility of 32) and not shown in the figure.
}
\label{fig:vis_dcn_query_points}
\end{figure}

\begin{figure}[!t]
  \centering
  \begin{adjustbox}{width=\linewidth}
  \bgroup
  \def\arraystretch{0.2}
  \setlength\tabcolsep{0.2pt}
  \begin{tabular}{ccc}
  \includegraphics[width=0.33\linewidth]{figures/visualization/ablations/q10_without_ms/000000001268.jpg} &
  \includegraphics[width=0.33\linewidth]{figures/visualization/ablations/q10_with_ms/000000001268.jpg} &
  \includegraphics[width=0.33\linewidth]{figures/visualization/ablations/000000001268_gt.jpg} \\
  \end{tabular} \egroup
  \end{adjustbox}
  \caption{
    \textbf{Effect of local-maximum-first selection strategy on IA-guided queries.} We visualize the IA-guided query distributions in \modelname-D1 without (left) and with (middle) the local-maximum-first selection strategy. Here $N_a=10$. The right figure shows the ground truth.
}
\label{fig:vis_q10_query_points}
\end{figure}


\subsection{Auxiliary query analysis}

We visualize the cross-attention maps of three auxiliary learnable queries in the last Transformer decoder layer of FastInst-D3 (R50 backbone) in \figref{fig:vis_aux_query}. As seen, auxiliary queries attend to general information such as edges (including background edge) and class-agnostic foreground objects.

\begin{figure}
  \centering
  % \setlength{\abovecaptionskip}{0.25mm}
  % \setlength{\belowcaptionskip}{0mm}
  \includegraphics[width=1.0\linewidth]{figures/rebuttal/000000001268_vis_attn.png}
  \caption{\textbf{Visualization of cross-attention maps of auxiliary learnable queries.} (a) Ground truth. (b-d) Cross-attention maps of three (of eight) auxiliary learnable queries in the last Transformer decoder layer of FastInst-D3. The auxiliary queries in (b) and (c) attend to general edges, including background edges. The auxiliary query in (d) attends to class-agnostic foreground objects.}
  \label{fig:vis_aux_query}
\end{figure}



\section{Additional datasets}
\label{app:datasets}
\subsection{Cityscapes}
Cityscapes~\cite{Cordts2016Cityscapes} is a high-resolution ($1024\!\times\!2048$ pixels) street-view dataset that contains 2975 training, 500 validation, and 1525 testing images. We evaluate the performance of FastInst in terms of instance segmentation AP over eight semantic classes of the dataset.

\noindent\textbf{Training settings.}
We use a batch size of 16 and train the model for 90K iterations. We set the initial learning rate as 0.0001 and drop it by multiplying 0.1 at 0.9 and 0.95 fractions of the total number of training steps. During training, we randomly resize the image to a shorter edge from 800 to 1024 pixels with a step of 32 pixels, followed by a crop size of $512\!\times\!1024$. During inference, we operate on the full image with a resolution of $1024\!\times\!2048$.

\noindent\textbf{Results.} \tabref{tab:ablation:cityscapes} shows the result of \modelname on Cityscapes \texttt{val} set. We also report the result of Mask2Former~\cite{cheng2021mask2former} that uses the same pixel decoder, \ie, the pyramid pooling module~\cite{zhao2017pspnet}-based FPN (PPM-FPN) and the same training settings. \modelname outperforms the Mask2Former by a large margin (\ie, 4.1 AP) with a similar speed, showing good efficiency in instance segmentation tasks.


\begin{table}[t]
	\centering
	\tablestyle{2pt}{1.2}
	\scriptsize
	\begin{tabular}{p{60px} | x{40} | x{35} x{30} |x{35}}
		& backbone & \phantom{0}\apm$^\texttt{val}$ & AP$_\text{50}$ & FPS \\
		\shline
		Mask2Former$^{\text{\textdagger}}$ & R50 & 31.4 & 55.9 & 9.2 \\
    \hline
		\textbf{\modelname-D3} (ours) & R50 & \textbf{35.5}\tiny(\gain{+4.1}) & \textbf{59.0} & 9.2 \\
    \hline
	\end{tabular}
	\caption{\textbf{Instance segmentation results on Cityscapes \texttt{val}.} Mask2Former$^{\text{\textdagger}}$ denotes a light version of Mask2Former~\cite{cheng2021mask2former} that uses the same pixel decoder and training settings as \modelname.}
	\label{tab:ablation:cityscapes}
\end{table}


\begin{table}[t]
	\centering
	\scriptsize
  %\setlength\tabcolsep{1.3mm}
  %\setlength{\abovecaptionskip}{0.5mm}
	%\setlength{\belowcaptionskip}{-3.5mm}
	\begin{tabular}{l|c|ccc|cc}
   \multirow{2}{*}{} & \multirow{2}{*}{backbone} & \multicolumn{3}{c|}{Cityscapes \texttt{val}} & \multirow{2}{*}{\#Param. (M)} \\
   & & AP & PQ & mIoU & \\
   \shline
   Mask2Former$^{\text{\textdagger}}$ & R50 & 31.4 & 53.9 & 74.4 & 40.9 \\
   \textbf{FastInst-D3} & R50 & \textbf{35.5} & \textbf{56.4} & \textbf{74.7} & \textbf{34.2} \\
	\end{tabular}
	\caption{\textbf{Panoptic (PQ) and semantic (mIoU) segmentation results on Cityscapes \texttt{val}.} Model and training settings are the same as instance segmentation (see Appendix \ref{app:datasets}). FastInst performs better in instance-level segmentation than Mask2Former.}
   \label{tab:ablation:unified}
\end{table}


\section{Unified Segmentation}
\label{app:unified}

According to the practice of Mask2Former, FastInst can be easily transferred to other segmentation tasks. We show the panoptic and semantic segmentation results on Cityscapes in \tabref{tab:ablation:unified}.


\section{Visualization}
\label{app:vis}
We visualize some predictions of the \modelname-D3 model with ResNet-50-d-DCN~\cite{he2016deep,he2019bag,zhu2019deformable} backbone on the COCO~\cite{lin2014coco} \texttt{val2017} set (40.1 AP) in \figref{fig:vis_insseg1} and \figref{fig:vis_insseg2}. \figref{fig:vis_insseg_failure_cases} shows two typical failure cases.


\begin{figure*}[!t]
    \centering
    \begin{adjustbox}{width=\textwidth}
    \bgroup
    \def\arraystretch{0.2}
    \setlength\tabcolsep{0.2pt}
    \begin{tabular}{cccc}
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000002473_gt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000002473_dt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000011760_gt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000011760_dt.jpg} \\
    \end{tabular} \egroup
    \end{adjustbox}

    \begin{adjustbox}{width=\textwidth}
    \bgroup
    \def\arraystretch{0.2}
    \setlength\tabcolsep{0.2pt}
    \begin{tabular}{cccc}
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000018380_gt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000018380_dt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000031296_gt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000031296_dt.jpg} \\
    \end{tabular} \egroup
    \end{adjustbox}

    \begin{adjustbox}{width=\textwidth}
    \bgroup
    \def\arraystretch{0.2}
    \setlength\tabcolsep{0.2pt}
    \begin{tabular}{cccc}
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000116068_gt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000116068_dt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000148957_gt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000148957_dt.jpg} \\
    \end{tabular} \egroup
    \end{adjustbox}

    \begin{adjustbox}{width=\textwidth}
    \bgroup
    \def\arraystretch{0.2}
    \setlength\tabcolsep{0.2pt}
    \begin{tabular}{cccc}
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000159311_gt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000159311_dt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000263594_gt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000263594_dt.jpg} \\
    \end{tabular} \egroup
    \end{adjustbox}

    \begin{adjustbox}{width=\textwidth}
    \bgroup
    \def\arraystretch{0.2}
    \setlength\tabcolsep{0.2pt}
    \begin{tabular}{cccc}

    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000274460_gt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000274460_dt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000285894_gt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000285894_dt.jpg} \\
    \end{tabular} \egroup
    \end{adjustbox}

    \begin{adjustbox}{width=\textwidth}
    \bgroup
    \def\arraystretch{0.2}
    \setlength\tabcolsep{0.2pt}
    \begin{tabular}{cccc}
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000289393_gt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000289393_dt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000349837_gt.jpg} &
    \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000349837_dt.jpg} \\
    \end{tabular} \egroup
    \end{adjustbox}

  \caption{
  \textbf{Visualization of some predictions on the COCO dataset.} We use \modelname-D3 with a ResNet-50-d-DCN backbone that achieves 40.1 AP on the validation set with a speed of 32.5 FPS on a single V100 GPU. The first and third columns show the ground truth, and the second and fourth columns show the predictions. We set the confidence threshold to 0.5.
  }
  \label{fig:vis_insseg1}
\end{figure*}


\begin{figure*}[!t]
  \centering


  \begin{adjustbox}{width=\textwidth}
  \bgroup
  \def\arraystretch{0.2}
  \setlength\tabcolsep{0.2pt}
  \begin{tabular}{cccc}
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000389451_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000389451_dt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000580418_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000580418_dt.jpg} \\
  \end{tabular} \egroup
  \end{adjustbox}

  \begin{adjustbox}{width=\textwidth}
  \bgroup
  \def\arraystretch{0.2}
  \setlength\tabcolsep{0.2pt}
  \begin{tabular}{cccc}
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000461405_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000461405_dt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000473974_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000473974_dt.jpg} \\
  \end{tabular} \egroup
  \end{adjustbox}

  \begin{adjustbox}{width=\textwidth}
  \bgroup
  \def\arraystretch{0.2}
  \setlength\tabcolsep{0.2pt}
  \begin{tabular}{cccc}
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000493284_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000493284_dt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000505565_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000505565_dt.jpg} \\
  \end{tabular} \egroup
  \end{adjustbox}

  \begin{adjustbox}{width=\textwidth}
  \bgroup
  \def\arraystretch{0.2}
  \setlength\tabcolsep{0.2pt}
  \begin{tabular}{cccc}
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000521259_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000521259_dt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000528862_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000528862_dt.jpg} \\
  \end{tabular} \egroup
  \end{adjustbox}

  \begin{adjustbox}{width=\textwidth}
  \bgroup
  \def\arraystretch{0.2}
  \setlength\tabcolsep{0.2pt}
  \begin{tabular}{cccc}

  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000542625_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000542625_dt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000553221_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000553221_dt.jpg} \\
  \end{tabular} \egroup
  \end{adjustbox}

  \begin{adjustbox}{width=\textwidth}
  \bgroup
  \def\arraystretch{0.2}
  \setlength\tabcolsep{0.2pt}
  \begin{tabular}{cccc}
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000569273_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000569273_dt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000577149_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000577149_dt.jpg} \\
  \end{tabular} \egroup
  \end{adjustbox}

\caption{
  \textbf{Visualization of another group of predictions on the COCO dataset.} We use \modelname-D3 with a ResNet-50-d-DCN backbone that achieves 40.1 AP on the validation set with a speed of 32.5 FPS on a single V100 GPU. The first and third columns show the ground truth, and the second and fourth columns show the predictions. We set the confidence threshold to 0.5.
}
\label{fig:vis_insseg2}
\end{figure*}


\begin{figure*}[!t]
  \centering


  \begin{adjustbox}{width=\textwidth}
  \bgroup
  \def\arraystretch{0.2}
  \setlength\tabcolsep{0.2pt}
  \begin{tabular}{cccc}
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000565853_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000565853_dt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000061171_gt.jpg} &
  \includegraphics[height=2cm]{figures/visualization/instance_predictions/000000061171_dt.jpg} \\
  \end{tabular} \egroup
  \end{adjustbox}

\caption{
\textbf{Visualization of two typical failure cases on the COCO dataset.} Left: duplicate predictions (\eg, the person in the center). Right: over segmentation (\eg, the cow in the upper right corner). Also, there are a few false positive and false negative predictions (see the left sample result). Here the first and third columns are the ground truth, and the second and fourth columns are the failure predictions. The confidence threshhold is set to 0.5, as in \figref{fig:vis_insseg1} and \figref{fig:vis_insseg2}.
}
\label{fig:vis_insseg_failure_cases}
\end{figure*}