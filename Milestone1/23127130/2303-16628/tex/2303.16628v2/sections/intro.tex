
\section{Introduction}
% 1. the important of camera-based 3D object detection, why camera-based solution;
% 2. Recent work leverage the temporal information to improve 3D detection;
% 3. However, does not model the object motion; while dynamic objects is common in driving scenes;
% 4. To alleviate this issue, we xxx;
% 5. We xxx.

\begin{figure}
    \centering
    \includegraphics[width=0.98\columnwidth]{figures/teaser.pdf}
    % \vspace{-6mm}
    %\caption{Visualization of the localization results obtained from different object motion (\textit{i.e.} assumed static, inaccurate motion, and ground truth object motion) in the temporal correspondence framework.
    %The assumed static and inaccurate object motion generate inaccurate temporal corresponding, leading to inaccurate depth results.}
    \caption{Visualization of object localization from temporal correspondence. 
    Previous work ignores the motion of moving objects, which leads to imprecise localization. Our work progressively refines the object's location and motion so that the preceding features can be precisely aggregated.}
    
    % When the object motion is inaccurate (assumed static or inaccurate estimation), the temporal correspondence would derive inaccurate location results. Unlike previous methods, our work takes the object motion into temporal correspondence and can progressively refine them to accurate location and motion results. }
    \label{fig:fig1}
    \vspace{-5mm}
\end{figure}

% 3D object detection aims at identifying and localizing objects of interest in the 3D space, which plays a significant role in many practical applications, such as autonomous driving, augmented reality, \textit{etc}. 
% Compared to the LiDAR and stereo-based methods, the monocular-based sensing solution draws increasing attention due to its easy-to-maintain and low-cost properties.
% However, the ill-posed 2D-3D projection problem limits the depth recovery ability in monocular-based detectors, leading to unreliable localization results for deployment. 

% % To alleviate the ill-posed 2D-3D projection, recent methods~\cite{li2020jst, wang2022dfm, huang2021bevdet4d, li2022bevstereo, wang2022sts} leverage temporal frames to augment the single view observation. 
% % % correspondence to generate cost volume as additional features for 3D detection.
% % Specifically, they~\cite{wang2022dfm,huang2021bevdet4d} utilize the temporal correspondence to generate cost volumes as additional localization features for 3D detection.
% % % warp the cross-view features to calculatefor each candidate correspondence
% % % generate location features by sample candidate correspondence to construct the cross-view cost volume.
% % The derived temporal correspondence assumes objects are static across frames,  however, the driving scenarios contain lots of moving objects.
% % In Fig~\ref{fig:fig1}, we provide an intuitive example to show that the inaccurate object motion would contribute to a wrong location results. 

% % In particular, the static assumption would generate inaccurate multi-view stereo cues for object localization. 
% % In Fig, we provide displays different object motions (\textit{i.e.} assumed static, inaccurate motion, gt motion) that would lead to different location results.
% % This problem is more critical when the object moves to the ego car. In this situation, the depth obtained from assumed static would indicate a farther location, which may lead to catastrophic collision accidents.
% % % This may mislead the system to treat an close object with a larger distance, leading to catastrophic collision accident. 


% To alleviate the ill-posed 2D-3D projection, recent methods~\cite{li2020jst, wang2022dfm, huang2021bevdet4d, li2022bevstereo, wang2022sts, li2022bevformer} leverage temporal frames to augment the single view observation. 
% Specifically, DfM, BEVDet4D and their follows up~\cite{wang2022dfm,huang2021bevdet4d} utilize the temporal correspondence to generate cost volumes as additional localization features for 3D detection.
% \jiangmiao{Be more clear and state the specific methods? Such as DfM ***, BEVFormer **, by clarify how these methods exploit temporal information.}
% However, the derived temporal correspondence assumes objects are static across frames, which may contribute to misleading localization features for moving objects.
% In Fig~\ref{fig:fig1}, we provide an intuitive example to show that the inaccurate object motion could derive a wrong location results. 
% This problem is more critical when the object moves to the ego car. In this situation, the depth obtained from assumed static would indicate a farther location, which may lead to catastrophic collision accidents.

% \jiangmiao{Note: the current paper only contains 7 pages, still 1 paper to fill. }

Multi-camera 3D object detection is critical to robotic systems such as autonomous vehicles. 
As object depth estimation from a single image is naturally ill-posed, 
recent works use large-scale depth pre-trained models~\cite{dd3d} and leverage geometric relationships~\cite{RTM3D,MonoFlex,wang2021PGD,wang2022dfm} to alleviate the problem.
Because stereo correspondence exists in consecutive frames, some works resort to temporal information for accurate depth predictions. 
For example, BEVDet4D~\cite{huang2021bevdet4d} and BEVFormer~\cite{li2022bevformer} warp preceding features to the current frame to enrich the single-frame BEV representations. 
DfM~\cite{wang2022dfm} constructs temporal cost volumes that explicitly establish the stereo correspondence.
However, these cross-frame feature aggregations do not consider the motion of moving objects and assume all the objects are static, which results in serious 3D localization bias.  
% However, these methods directly warp the preceding features to the current frame that ignore the motion of moving objects.  
% The ignorance of object motion will result in inaccurate localization from the temporal correspondence. 

% As shown in , with the inaccurate object motion (\textit{e.g.} assumed static, or a smaller one), the temporal correspondence would derive an inaccurate object location.
In this paper, we first provide a theoretical and empirical analysis to reveal the negative effects of inaccurate object motion to object depth (Fig~\ref{fig:fig1}).
In particular, if the object is moving toward or backward to the ego-car, the incorrect correspondence would derive a farther or closer depth.
In the driving scenarios, it is critical that a misleading farther depth is estimated, which might reduce the reaction time of the decision system, leading to catastrophic collision accidents. 
This motivates us to devise an explicit mechanism to involve object motion estimation in the temporal-based 3D object detection pipeline.
% This motivates us to explicitly devise a mechanism to rectify object motion into the temporal-based 3D object detection. 

% However, these methods typically directly aggregate the features in nearby frames that ignore the dynamic object motion. 
% Inaccurate motion modeling will result in inaccurate depth estimation. As shown in Fig~\ref{fig:fig1}, \jiangmiao{In detail state the motion errors, how if assume static, how if wrong, far or near, also be more clear why highlight the case the object is moving to the ego car}
% % derived temporal correspondence assumes objects are static across frames, which may contribute to misleading localization features for moving objects.
% In Fig~\ref{fig:fig1}, we provide an intuitive example to show that the inaccurate object motion could derive a wrong location results. 
% This problem is more critical when the object moves to the ego car. In this situation, the depth obtained from assumed static would indicate a farther location, which may lead to catastrophic collision accidents.

% % introduce dfm and bevdet, state their problem. 
% In multi-view geometry~\cite{Hartley_mvg}, predicting 3D object motion and location is a chicken and egg problem.
% % \jiangmiao{Technically and intuitively say why, not only the conclusion.}
% In multi-view geometry~\cite{Hartley_mvg}, predicting 3D object motion and location from a monocular camera is an ill-posed problem, where current multi-view correspondence can be solved by infinite combinations of object motion and location. This ill-posed problem causes simultaneously modeling object motion and location be a chicken and egg problem, where only with accurate motion can obtain the accurate location from temporal correspondence and vice versa.


Modeling dynamic objects in this context has several challenges: (1) We need a flexible object-wise representation for potential object-wise operations based on motion modeling.
(2) Jointly estimating object location and motion is an inherent chicken and egg problem~\cite{Hartley_mvg}:
The temporal correspondence can derive accurate object location only when accurate object motion is given and vice versa.
(3) Simultaneously predicting object location and motion from only two frames is also an ill-posed problem theoretically, and thus involving right-body assumption and more frames in the framework to pose reasonable constraints is desired.

To address these problems, we model \textbf{D}ynamic \textbf{O}bjects in \textbf{R}ecurren\textbf{T} (DORT) that simultaneously estimates object motion and location, and then progressively refines them for accurate 3D object detection. 
It benefits from a local 3D volume representation that not only extracts object-wise 3D features but also alleviates the heavy computational costs of global BEV in previous methods~\cite{wang2022dfm, li2022bevformer, huang2021bevdet}.
% The extracted object-wise BEV representation are
% \jiangmiao{logic line, can discuss, draw the forward flow of your method}.
Based on the object-wise 3D volume, temporal cost volumes are constructed by warping the volumes from the preceding frame to the current frame according to the object motion. 
% warping the preceding volume to 
% The extracted object-wise 3D representation is used to construct a cross-view cost volume by utilizing the candidate object motion to warp the object-wise features from the preceding frame to current frame.
Then the obtained cost volumes act as the features for updating the candidate location and motion. We model this estimation and update pipeline as a recurrent process to alleviate the aforementioned chicken and egg problem.
In addition, our framework can take into more than two frames and pose constraints to the object motion across different frames. It inherently provides a feasible solution to avoid the ill-posed dilemma of estimating object location and motion from only a single pair of correspondence observations.
% To combine the results from different frames, we predict the confidence of the estimation from each paired frames and combine them to obtain a more stable results.}
As there is object motion prediction in the loop, the framework is naturally capable of joint object detection and tracking by
utilizing object motion to align the detection results into the same timestamp.
It also can be plugged into most camera-based 3D object detectors for flexible and practical use.
% associating objects according to nearest center distances. 

% \jiangmiao{revise this paradigm according to the abstract, also say we can plug in most camera-based detectors}
We validate the effectiveness of our framework on the nuScenes detection and tracking benchmarks. Benefiting from the dynamic objects modeling, DORT outperforms all
the previous methods with a large margin, leading to 62.5\% nuScenes detection metric (NDS) and 57.6\% and average multi-object tracking accuracy (AMOTA), respectively. 

% % temporal information to the temporal information
% % introduce dfm and bevdet, state their problem. 
% \jiangmiao{list the contributions in four points many omit the local bev, which I think is a important contribution to highlight. Try to use a logic flow for the contribution statement?}
% To handle both static and moving objects, we propose DORT, a framework that models the \textbf{D}ynamic \textbf{O}bjects in \textbf{R}ecurren\textbf{T}. 
% In particular, DORT simultaneously models object location and motion and progressively refines them by looking up the corresponding cost volume.
% %  in temporal-based paradigm.
% DORT improves previous temporal-based methods by the following four main components: 
% (1) A lightweight local volume that utilizes the candidate bounding box to extract object-wise features for location and motion modeling. 
% (2) A cost-view correlation module that takes both the ego-motion and object-motion to obtain the temporal-based localization features. 
% (3) A recurrent module that iteratively updates the object location and motion by looking up the corresponding cost volume features.
% (4) A multi-estimation fusion module that fuses the multi-frame results and improve the robustness of object motion.
% % compensates for inaccurate object motion.

% % The recurrent designed is motivated by the optimization paradigm in traditional work~\cite{}
% As discussed in~\cite{Hartley_mvg}, estimating 3D object motion and location is a chicken and egg problem, where precise motion would lead to precise location and vice versa.% Polish counterpart.
% Hence, we draw inspiration from the optimization-based methods~\cite{yao2019recurrent, zachary2020raft, li2020jst} and design a recurrent paradigm to progressively refine the object location and motion by querying the correspondence cost volume.
% With precise location and motion results, our framework also can associate objects across frames, leading to monocular 4D object detection (joint detection and tracking in 3D space).

% Based on the designed framework, our detector can obtain precise object location and motion, which also can be extend to achieve monocular 4D object detection (joint detection and tracking in 3D space).
% We conduct experiments on the challenging nuScenes dataset, where we first demonstrate that current framework can obtain better detection results. Then we leverage 


% Then we validate the effectiveness of our framework in estimating object motion and location. Based on accurate object motion, our framework can achieve simultaneously 3D object detection and tracking across with state-of-the-art performance. 

% With strong motion estimation ability, the accompanied 3D object tracker also achieve state-of-the-art results on the nuScenes tracking benchmark.
% objects modeling, our framework also can effectively associate object with a simple xxx tracker, leading to state-of-the-art performance on the nuScenes tracking benchmark. 

% with can better localize and associate objects across frames, leading to state-of-the-art detection and tracking performance. 
% \jiangmiao{highlight the performance. Generally, I do not like state the contributions in points. If the writing is clear, our contributions are clear, and do not need to list.}

% Our contributions can be summarized as follows:
% \begin{itemize}
% \item We first conduct a thorough analysis to demonstrate the necessity of modeling object motion in providing effective temporal visual cues for 3D detection. 
% \item Then, We propose a framework that models dynamic objects in recurrent, in which both the object motion and location are recurrently updated to obtain more accurate temporal features. 
% \item Our experimental results on the nuScenes 3D object detection and tracking benchmark demonstrate the effectiveness of the proposed dynamic objects modeling framework.
% %demonstrate the effectiveness of the proposed method.
% \end{itemize}