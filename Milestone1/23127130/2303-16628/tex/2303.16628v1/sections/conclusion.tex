\section{Conclusion}
This work proposes a novel framework to better leverage temporal information for camera-only 3D detection by modeling dynamic objects.
We first designed an object-wise local volume to save the computation time and maintain a object-wise representation for motion and detection modeling.
Then we propose a recurrent module to tackle the challenging motion and location modeling problem.
Specifically, we progressively update the motion and location results from the concurrently updated corresponding 3D volume features thereon.
As the object motion and location results are tightly coupled in the recurrent stage, we also demonstrate the framework can naturally achieve 3D object tracking. 
Based on dynamic objects motion, our method achieves state-of-the-art performance on both the nuScenes detection and tracking benchmarks.