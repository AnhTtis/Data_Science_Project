@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@inproceedings{skill_human, 
title={Building machines that learn and think like people},
volume={40}, 
booktitle={Behavioral and Brain Sciences}, 
author={Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
year={2017}, 
pages={e253}}

@inproceedings{stacknmn,
  title={Explainable Neural Computation via Stack Neural Module Networks},
  author={Ronghang Hu and Jacob Andreas and Trevor Darrell and Kate Saenko},
  booktitle={ECCV},
  pages="55--71",
  year={2018}
}

@inproceedings{nsm,
 author = {Hudson, Drew and Manning, Christopher D},
 booktitle = {NeurIPS},
 pages = {},
 title = {Learning by Abstraction: The Neural State Machine},
 volume = {32},
 year = {2019}
}

@InProceedings{xnm,
author = {Shi, Jiaxin and Zhang, Hanwang and Li, Juanzi},
title = {Explainable and Explicit Visual Reasoning Over Scene Graphs},
booktitle = {CVPR},
pages={8368-8376},
year = {2019}
}

@inproceedings{mcb,
    title = "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding",
    author = "Fukui, Akira  and
      Park, Dong Huk  and
      Yang, Daylen  and
      Rohrbach, Anna  and
      Darrell, Trevor  and
      Rohrbach, Marcus",
    booktitle = {EMNLP},
    year = "2016",
    pages = "457--468",
}

@InProceedings{mfb,
author = {Yu, Zhou and Yu, Jun and Fan, Jianping and Tao, Dacheng},
title = {Multi-Modal Factorized Bilinear Pooling With Co-Attention Learning for Visual Question Answering},
booktitle = {ICCV},
pages={1839-1848},
year = {2017}
}

@inproceedings{mlb,
author = {Kim, Jin-Hwa and On, Kyoung Woon and Lim, Woosang and Kim, Jeonghee and Ha, Jung-Woo and Zhang, Byoung-Tak},
booktitle = {ICLR},
title = {Hadamard Product for Low-rank Bilinear Pooling},
year = {2017}
}


@InProceedings{updown,
author = {Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
title = {Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering},
booktitle = {CVPR},
year = {2018},
pages={6077-6086},
}

@inproceedings{ban,
author = {Kim, Jin-Hwa and Jun, Jaehyun and Zhang, Byoung-Tak},
booktitle = {NeurIPS},
title = {Bilinear Attention Networks},
pages = {1571--1581},
year = {2018}
}

@inproceedings{lxmert,
    title = "{LXMERT}: Learning Cross-Modality Encoder Representations from Transformers",
    author = "Tan, Hao  and
      Bansal, Mohit",
    booktitle = {EMNLP},
    year = 2019,
    pages = "5100--5111",
}

@inproceedings{vilbert,
 author = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
 booktitle = {NeurIPS},
 pages = {13--23},
 title = {ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},
 volume = {32},
 year = {2019}
}

@inproceedings{visualbert,
    title = "What Does {BERT} with Vision Look At?",
    author = "Li, Liunian Harold  and
      Yatskar, Mark  and
      Yin, Da  and
      Hsieh, Cho-Jui  and
      Chang, Kai-Wei",
    booktitle = {ACL},
    year = "2020",
    pages = "5265--5275",
}

@InProceedings{vqa1,
author = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},
title = {{VQA}: {V}isual {Q}uestion {A}nswering},
booktitle = {ICCV},
pages={2425-2433},
year = {2015},
}

@InProceedings{vqa2,
author = {Yash Goyal and Tejas Khot and Douglas Summers{-}Stay and Dhruv Batra and Devi Parikh},
title = {Making the {V} in {VQA} Matter: Elevating the Role of Image Understanding in {V}isual {Q}uestion {A}nswering},
booktitle = {CVPR},
pages={6325-6334},
year = {2017},
}

@inproceedings{vcr,
  author = {Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  title = {From Recognition to Cognition: Visual Commonsense Reasoning},
  booktitle = {CVPR},
  pages={6713-6724},
  year = {2019}
}

@InProceedings{clevr,
author = {Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C. and Girshick, Ross},
title = {{CLEVR}: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
booktitle = {CVPR},
pages={1988-1997},
year = {2017}
}

@InProceedings{gqa,
author = {Hudson, Drew A. and Manning, Christopher D.},
title = {{GQA:} A New Dataset for Real-World Visual Reasoning and Compositional Question Answering},
booktitle = {CVPR},
pages={6693-6702},
year = {2019}
}

@InProceedings{zero_shot_empirical,
author = {Ramakrishnan, Santhosh K. and Pal, Ambar and Sharma, Gaurav and Mittal, Anurag},
title = {An Empirical Evaluation of Visual Question Answering for Novel Objects},
booktitle = {CVPR},
pages={7312-7321},
year = {2017}
}

@InProceedings{exemplar_att,
author = {Moshiur R. Farazi and Salman H. Khan and Nick Barnes},
title = {From known to the unknown: Transferring knowledge to answer questions about novel visual and semantic concepts},
booktitle = {Image and Vision Computing},
 volume = {103},
pages={103985},
year = {2020}
}

@article{zero_shot_vqa_task,
  author    = {Damien Teney and
               Anton van den Hengel},
  title     = {Zero-Shot Visual Question Answering},
  journal   = {Arxiv},
  year      = {2016},
}

@InProceedings{vqa_meta_learning,
author = {Teney, Damien and van den Hengel, Anton},
title = {Visual Question Answering as a Meta Learning Task},
booktitle = {ECCV},
pages={229-245},
year = {2018}
}

@INPROCEEDINGS{skill_concept,
  author={Whitehead, Spencer and Wu, Hui and Ji, Heng and Feris, Rogerio and Saenko, Kate},
  booktitle={CVPR}, 
  title={Separating Skills and Concepts for Novel Visual Question Answering}, 
  year={2021},
  volume={},
  number={},
  pages={5628-5637},
  }
  
 @inproceedings{mscoco,
title = {Microsoft COCO: Common Objects in Context},
author = {Tsung-Yi Lin and Michael Maire and Serge Belongie and James Hays and Pietro Perona and Deva Ramanan and Piotr Dollár and C. Lawrence Zitnick},
year = {2014},
pages="740--755",
booktitle = {ECCV},
}

@InProceedings{scene_text_qa,
author = {Biten, Ali Furkan and Tito, Ruben and Mafla, Andres and Gomez, Lluis and Rusinol, Marcal and Valveny, Ernest and Jawahar, C.V. and Karatzas, Dimosthenis},
title = {Scene Text Visual Question Answering},
booktitle = {ICCV},
pages={4290-4300},
year = {2019}
}

@InProceedings{visualcomet,
  author = {Park, Jae Sung and Bhagavatula, Chandra and Mottaghi, Roozbeh and Farhadi, Ali and Choi, Yejin},
  title = {VisualCOMET: Reasoning about the Dynamic Context of a Still Image},
  booktitle = {ECCV},
  pages="508--524",
  year = {2020}
}

@InProceedings{okvqa,
author = {Kenneth Marino and Mohammad Rastegari and Ali Farhadi and Roozbeh Mottaghi},
title = {OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge},
booktitle = {CVPR},
pages={3190-3199},
year = {2019},
}

@inproceedings{mac,
title={Compositional Attention Networks for Machine Reasoning},
author={Drew Arad Hudson and Christopher D. Manning},
booktitle={ICLR},
year={2018},
}

@InProceedings{oscar,
author="Li, Xiujun
and Yin, Xi
and Li, Chunyuan
and Zhang, Pengchuan
and Hu, Xiaowei
and Zhang, Lei
and Wang, Lijuan
and Hu, Houdong
and Dong, Li
and Wei, Furu
and Choi, Yejin
and Gao, Jianfeng",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks",
booktitle="ECCV",
year="2020",
pages="121--137",
}

@inproceedings{zero_shot_learning,
author = {Larochelle, Hugo and Erhan, Dumitru and Bengio, Y.},
year = {2008},
pages = {646-651},
title = {Zero-data Learning of New Tasks.},
volume = {2},
booktitle = {AAAI}
}

@inproceedings{glove,
  author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle = {EMNLP},
  pages = {1532--1543},
  title = {Glove: Global Vectors for Word Representation.},
  volume = 14,
  year = 2014
}

@INPROCEEDINGS{vqa_machine,
  author={Wang, Peng and Wu, Qi and Shen, Chunhua and van den Hengel, Anton},
  booktitle={CVPR}, 
  title={The VQA-Machine: Learning How to Use Existing Vision Algorithms to Answer New Questions}, 
  year={2017},
  volume={},
  number={},
  pages={3909-3918},
}

@INPROCEEDINGS{transferrable_proto,
  author={Pan, Yingwei and Yao, Ting and Li, Yehao and Wang, Yu and Ngo, Chong-Wah and Mei, Tao},
  booktitle={CVPR}, 
  title={Transferrable Prototypical Networks for Unsupervised Domain Adaptation}, 
  year={2019},
  volume={},
  number={},
  pages={2234-2242},
}

@inproceedings{proto_few_shot,
 author = {Snell, Jake and Swersky, Kevin and Zemel, Richard},
 booktitle = {NeurIPS},
 pages = {4080–4090},
 title = {Prototypical Networks for Few-shot Learning},
 volume = {30},
 year = {2017}
}

@inproceedings{att_proto,
author = {Gao, Tianyu and Han, Xu and Liu, Zhiyuan and Sun, Maosong},
title = {Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification},
pages={6407–6414},
year = {2019},
booktitle = {AAAI},
}

@INPROCEEDINGS{proto_fine_grained,
author = {Chen, Chaofan and Li, Oscar and Tao, Chaofan and Barnett, Alina Jade and Su, Jonathan and Rudin, Cynthia},
title = {This Looks like That: Deep Learning for Interpretable Image Recognition},
year = {2019},
booktitle = {NeurIPS},
pages={8930–8941}
}

@INPROCEEDINGS{srn_multi_label,
  author={Zhu, Feng and Li, Hongsheng and Ouyang, Wanli and Yu, Nenghai and Wang, Xiaogang},
  booktitle={CVPR}, 
  title={Learning Spatial Regularization with Image-Level Supervisions for Multi-label Image Classification}, 
  year={2017},
  volume={},
  number={},
  pages={2027-2036},
}

@InProceedings{loss_multi_label,
    author    = {Ridnik, Tal and Ben-Baruch, Emanuel and Zamir, Nadav and Noy, Asaf and Friedman, Itamar and Protter, Matan and Zelnik-Manor, Lihi},
    title     = {Asymmetric Loss for Multi-Label Classification},
    booktitle = {ICCV},
    year      = {2021},
    pages     = {82-91}
}

@INPROCEEDINGS{graph_multi_label,
  author={Chen, Zhao-Min and Wei, Xiu-Shen and Wang, Peng and Guo, Yanwen},
  booktitle={CVPR}, 
  title={Multi-Label Image Recognition With Graph Convolutional Networks}, 
  year={2019},
  volume={},
  number={},
  pages={5172-5181},
}

@InProceedings{explicit_xnm,
    author    = {Zhang, Yifeng and Jiang, Ming and Zhao, Qi},
    title     = {Explicit Knowledge Incorporation for Visual Reasoning},
    booktitle = {CVPR},
    year      = {2021},
    pages     = {1356-1365}
}

@inproceedings{adam,
  title     = {Adam: {A} Method for Stochastic Optimization},
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  year      = {2015},
  booktitle = {ICLR}
}

@inproceedings{visual_genome,
  title={Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalanditis, Yannis and Li, Li-Jia and Shamma, David A and Bernstein, Michael and Fei-Fei, Li},
  booktitle = {IJCV},
  volume={123},
  number={},
  pages={32-73},
  year = {2017},
}

@InProceedings{kmeans,
  author={Lloyd, S.},
  booktitle={IEEE Transactions on Information Theory}, 
  title={Least squares quantization in PCM}, 
  year={1982},
  volume={28},
  number={2},
  pages={129-137},
}

@InProceedings{explicit_bias,
author = {Manjunatha, Varun and Saini, Nirat and Davis, Larry S.},
title = {Explicit Bias Discovery in Visual Question Answering Models},
booktitle = {CVPR},
pages={9554-9563},
year = {2019}
}

@INPROCEEDINGS{tbd_net,
  author={Mascharka, David and Tran, Philip and Soklaski, Ryan and Majumdar, Arjun},
  booktitle={CVPR}, 
  title={Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning}, 
  year={2018},
  volume={},
  number={},
  pages={4942-4950},
}

@inproceedings{closure,
  author    = {Harm De Vries and
               Dzmitry Bahdanau and
               Shikhar Murty and
               Aaron C. Courville and
               Philippe Beaudoin},
  title     = {{CLOSURE:} Assessing Systematic Generalization of {CLEVR} Models},
  booktitle = {NeurIPS Workshop},
  year      = {2019},
}

@InProceedings{air,
author = {Chen, Shi and Jiang, Ming and Yang, Jinhui and Zhao, Qi},
title = {AiR: Attention with Reasoning Capability},
booktitle = {ECCV},
pages="91--107",
year = {2020}
}

@inproceedings{prototype_interpretable,
author = {Li, Oscar and Liu, Hao and Chen, Chaofan and Rudin, Cynthia},
title = {Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network That Explains Its Predictions},
year = {2018},
booktitle = {AAAI},
articleno = {432},
numpages = {8},
}

@INPROCEEDINGS{nmn,
  author={Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  booktitle={CVPR}, 
  title={Neural Module Networks}, 
  year={2016},
  volume={},
  number={},
  pages={39-48},
}

@InCollection{fallacy,
	author       =	{Barker, Stephen Francis.},
	title        =	{Chapter 6: Fallacies},
	booktitle    =	{The Elements of Logic},
    pages={160-169},
	year         =	{2003},
}

@InProceedings{vqa_cp,
author = {Agrawal, Aishwarya and Batra, Dhruv and Parikh, Devi and Kembhavi, Aniruddha},
title = {Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering},
booktitle = {CVPR},
pages={4971-4980},
year = {2018}
}

@InProceedings{gqa_ood,
    author    = {Kervadec, Corentin and Antipov, Grigory and Baccouche, Moez and Wolf, Christian},
    title     = {Roses Are Red, Violets Are Blue... but Should VQA Expect Them To?},
    booktitle = {CVPR},
    year      = {2021},
    pages     = {2776-2785}
}

@InProceedings{hint,
author = {Selvaraju, Ramprasaath R. and Lee, Stefan and Shen, Yilin and Jin, Hongxia and Ghosh, Shalini and Heck, Larry and Batra, Dhruv and Parikh, Devi},
title = {Taking a {HINT}: Leveraging Explanations to Make Vision and Language Models More Grounded},
booktitle = {ICCV},
pages={2591-2600},
year = {2019}
}

@InProceedings{self_cirtical_vqa,
author = {Wu, Jialin and Mooney, Raymond J.},
title = {Self-Critical Reasoning for Robust Visual Question Answering},
pages={8604–8614},
year = {2019},
booktitle = {NeurIPS},
}


@InProceedings{adv_reg,
  author    = {Sainandan Ramakrishnan and
               Aishwarya Agrawal and
               Stefan Lee},
  title     = {Overcoming Language Priors in Visual Question Answering with Adversarial
               Regularization},
  year = {2018},
  booktitle = {NeurIPS},
  pages = {1548-1558},
}

@article{rubi,
  title={RUBi: Reducing Unimodal Biases for Visual Question Answering},
  author={Cadene, Remi and Dancette, Corentin and Cord, Matthieu and Parikh, Devi and others},
  journal={NeurIPS},
  pages={841-852},
  year={2019}
}

@inproceedings{lmh_entropy,
 author = {Gat, Itai and Schwartz, Idan and Schwing, Alexander and Hazan, Tamir},
 booktitle = {NeurIPS},
 pages = {3197--3208},
 title = {Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies},
 year = {2020}
}


@inproceedings{lmh,
    title = "Don{'}t Take the Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases",
    author = "Clark, Christopher  and
      Yatskar, Mark  and
      Zettlemoyer, Luke",
    booktitle = "EMNLP",
    year = "2019",
    pages = "4069--4082",
}

@INPROCEEDINGS{grad_ensemble,
  author={Han, Xinzhe and Wang, Shuhui and Su, Chi and Huang, Qingming and Tian, Qi},
  booktitle={ICCV}, 
  title={Greedy Gradient Ensemble for Robust Visual Question Answering}, 
  year={2021},
  volume={},
  number={},
  pages={1564-1573},
}

@inproceedings{ood_shortcoming,
 author = {Teney, Damien and Abbasnejad, Ehsan and Kafle, Kushal and Shrestha, Robik and Kanan, Christopher and van den Hengel, Anton},
 booktitle = {NeurIPS},
 pages = {407--417},
 title = {On the Value of Out-of-Distribution Testing: An Example of Goodhart\textquotesingle s Law},
 year = {2020}
}

@INPROCEEDINGS{css,
  author={Chen, Long and Yan, Xin and Xiao, Jun and Zhang, Hanwang and Pu, Shiliang and Zhuang, Yueting},
  booktitle={CVPR}, 
  title={Counterfactual Samples Synthesizing for Robust Visual Question Answering}, 
  year={2020},
  volume={},
  number={},
  pages={10797-10806},
}

@inproceedings{mutant,
    title = "{MUTANT}: A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering",
    author = "Gokhale, Tejas  and
      Banerjee, Pratyay  and
      Baral, Chitta  and
      Yang, Yezhou",
    booktitle = "EMNLP",
    year = "2020",
    pages = "878--892",
}

@inproceedings{contrast_vqa,
    title = "Learning to Contrast the Counterfactual Samples for Robust Visual Question Answering",
    author = "Liang, Zujie  and
      Jiang, Weitao  and
      Hu, Haifeng  and
      Zhu, Jiaying",
    booktitle = "EMNLP",
    year = "2020",
    pages = "3285--3292",
}

@inproceedings{x_bert,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and Kholy, Ahmed El and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={ECCV},
  pages = "104-120",
  year={2020}
}

@article{vtt,
author = {Donald Geman  and Stuart Geman  and Neil Hallonquist  and Laurent Younes },
title = {Visual Turing test for computer vision systems},
journal = {Proceedings of the National Academy of Sciences},
volume = {112},
number = {12},
pages = {3618-3623},
year = {2015},
}

@article{deductive_reasoning,
author = {Johnson-Laird, P. N.},
title = {Deductive Reasoning},
journal = {Annual Review of Psychology},
volume = {50},
number = {1},
pages = {109-135},
year = {1999},
}

@ARTICLE{ann_binding,
      title={On the Binding Problem in Artificial Neural Networks}, 
      author={Klaus Greff and Sjoerd van Steenkiste and Jürgen Schmidhuber},
      year={2020},
     journal = {Arxiv},
}

@ARTICLE{multi_label_survey,
  author={Zhang, Min-Ling and Zhou, Zhi-Hua},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A Review on Multi-Label Learning Algorithms}, 
  year={2014},
  volume={26},
  number={8},
  pages={1819-1837},
}

@book{aristotle_logic,
	year = {1989},
	publisher = {Oxford University Press},
	author = {Aristotle},
	title = {Aristotle's Prior Analytics}
}
