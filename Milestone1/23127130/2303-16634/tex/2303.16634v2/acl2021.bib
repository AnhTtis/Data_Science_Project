@article{sener2017active,
  title={Active learning for convolutional neural networks: A core-set approach},
  author={Sener, Ozan and Savarese, Silvio},
  journal={arXiv preprint arXiv:1708.00489},
  year={2017}
}

@article{gpt35,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{deng2021compression,
  title={Compression, Transduction, and Creation: A Unified Framework for Evaluating Natural Language Generation},
  author={Deng, Mingkai and Tan, Bowen and Liu, Zhengzhong and Xing, Eric and Hu, Zhiting},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={7580--7605},
  year={2021}
}

@inproceedings{cao2018faithful,
  title={Faithful to the original: Fact aware neural abstractive summarization},
  author={Cao, Ziqiang and Wei, Furu and Li, Wenjie and Li, Sujian},
  booktitle={thirty-second AAAI conference on artificial intelligence},
  year={2018}
}


@inproceedings{kryscinski2020evaluating,
  title={Evaluating the Factual Consistency of Abstractive Text Summarization},
  author={Kry{\'s}ci{\'n}ski, Wojciech and McCann, Bryan and Xiong, Caiming and Socher, Richard},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={9332--9346},
  year={2020}
}

@inproceedings{cao2020factual,
  title={Factual Error Correction for Abstractive Summarization Models},
  author={Cao, Meng and Dong, Yue and Wu, Jiapeng and Cheung, Jackie Chi Kit},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={6251--6258},
  year={2020}
}
@inproceedings{durmus2020feqa,
  title={FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization},
  author={Durmus, Esin and He, He and Diab, Mona},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={5055--5070},
  year={2020}
}

@inproceedings{wang2020asking,
  title={Asking and Answering Questions to Evaluate the Factual Consistency of Summaries},
  author={Wang, Alex and Cho, Kyunghyun and Lewis, Mike},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={5008--5020},
  year={2020}
}

@article{zhong2022towards,
  title={Towards a Unified Multi-Dimensional Evaluator for Text Generation},
  author={Zhong, Ming and Liu, Yang and Yin, Da and Mao, Yuning and Jiao, Yizhu and Liu, Pengfei and Zhu, Chenguang and Ji, Heng and Han, Jiawei},
  journal={arXiv preprint arXiv:2210.07197},
  year={2022}
}

@article{fabbri2021summeval,
  title={Summeval: Re-evaluating summarization evaluation},
  author={Fabbri, Alexander R and Kry{\'s}ci{\'n}ski, Wojciech and McCann, Bryan and Xiong, Caiming and Socher, Richard and Radev, Dragomir},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={391--409},
  year={2021},
  publisher={MIT Press}
}



@article{mehri2020usr,
  title={USR: An unsupervised and reference free evaluation metric for dialog generation},
  author={Mehri, Shikib and Eskenazi, Maxine},
  journal={arXiv preprint arXiv:2005.00456},
  year={2020}
}

@article{kocmi2023large,
  title={Large language models are state-of-the-art evaluators of translation quality},
  author={Kocmi, Tom and Federmann, Christian},
  journal={arXiv preprint arXiv:2302.14520},
  year={2023}
}

@article{yuan2021bartscore,
  title={Bartscore: Evaluating generated text as text generation},
  author={Yuan, Weizhe and Neubig, Graham and Liu, Pengfei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{zhao2019moverscore,
  title={MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance},
  author={Zhao, Wei and Peyrard, Maxime and Liu, Fei and Gao, Yang and Meyer, Christian M and Eger, Steffen},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={563--578},
  year={2019}
}

@article{zhang2019bertscore,
  title={Bertscore: Evaluating text generation with bert},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={arXiv preprint arXiv:1904.09675},
  year={2019}
}

@inproceedings{clark2019sentence,
  title={Sentence mover’s similarity: Automatic evaluation for multi-sentence texts},
  author={Clark, Elizabeth and Celikyilmaz, Asli and Smith, Noah A},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={2748--2760},
  year={2019}
}
@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4171--4186},
  year={2019}
}

@article{raffel2020exploring,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of Machine Learning Research},
  volume={21},
  pages={1--67},
  year={2020}
}


@inproceedings{DBLP:conf/acl/LewisLGGMLSZ20,
  author    = {Mike Lewis and
               Yinhan Liu and
               Naman Goyal and
               Marjan Ghazvininejad and
               Abdelrahman Mohamed and
               Omer Levy and
               Veselin Stoyanov and
               Luke Zettlemoyer},
  editor    = {Dan Jurafsky and
               Joyce Chai and
               Natalie Schluter and
               Joel R. Tetreault},
  title     = {{BART:} Denoising Sequence-to-Sequence Pre-training for Natural Language
               Generation, Translation, and Comprehension},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational
               Linguistics, {ACL} 2020, Online, July 5-10, 2020},
  pages     = {7871--7880},
  publisher = {Association for Computational Linguistics},
  year      = {2020},
  timestamp = {Fri, 08 Jan 2021 21:20:33 +0100},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{https://doi.org/10.48550/arxiv.2301.13848,
  url = {https://arxiv.org/abs/2301.13848},
  author = {Zhang, Tianyi and Ladhak, Faisal and Durmus, Esin and Liang, Percy and McKeown, Kathleen and Hashimoto, Tatsunori B.},
  title = {Benchmarking Large Language Models for News Summarization},
  publisher = {arXiv},
  year = {2023},
}
@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}
@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}
@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}
@inproceedings{kusner2015word,
  title={From word embeddings to document distances},
  author={Kusner, Matt and Sun, Yu and Kolkin, Nicholas and Weinberger, Kilian},
  booktitle={International conference on machine learning},
  pages={957--966},
  year={2015},
  organization={PMLR}
}

@article{kasai2021bidimensional,
  title={Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand},
  author={Kasai, Jungo and Sakaguchi, Keisuke and Bras, Ronan Le and Dunagan, Lavinia and Morrison, Jacob and Fabbri, Alexander R and Choi, Yejin and Smith, Noah A},
  journal={arXiv preprint arXiv:2112.04139},
  year={2021}
}
@article{reiter2009investigation,
  title={An Investigation into the Validity of Some Metrics for Automatically Evaluating Natural Language Generation Systems},
  author={Reiter, Ehud and Belz, Anja},
  journal={Computational Linguistics},
  volume={35},
  number={4},
  pages={529--558},
  year={2009}
}
@inproceedings{stent2005evaluating,
  title={Evaluating evaluation methods for generation in the presence of variation},
  author={Stent, Amanda and Marge, Matthew and Singhai, Mohit},
  booktitle={Proceedings of the 6th international conference on Computational Linguistics and Intelligent Text Processing},
  pages={341--351},
  year={2005}
}
@article{fu2023gptscore,
  title={GPTScore: Evaluate as You Desire},
  author={Fu, Jinlan and Ng, See-Kiong and Jiang, Zhengbao and Liu, Pengfei},
  journal={arXiv preprint arXiv:2302.04166},
  year={2023}
}

@inproceedings{dziri2019evaluating,
  title={Evaluating Coherence in Dialogue Systems using Entailment},
  author={Dziri, Nouha and Kamalloo, Ehsan and Mathewson, Kory and Zaiane, Osmar R},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={3806--3812},
  year={2019}
}
@inproceedings{ye2021towards,
  title={Towards Quantifiable Dialogue Coherence Evaluation},
  author={Ye, Zheng and Lu, Liucun and Huang, Lishan and Lin, Liang and Liang, Xiaodan},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={2718--2729},
  year={2021}
}
@article{wei2022chain,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}
@article{wang2023chatgpt,
  title={Is ChatGPT a Good NLG Evaluator? A Preliminary Study},
  author={Wang, Jiaan and Liang, Yunlong and Meng, Fandong and Shi, Haoxiang and Li, Zhixu and Xu, Jinan and Qu, Jianfeng and Zhou, Jie},
  journal={arXiv preprint arXiv:2303.04048},
  year={2023}
}

@article{hermann2015teaching,
  title={Teaching machines to read and comprehend},
  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}
@inproceedings{narayan2018don,
  title={Don’t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization},
  author={Narayan, Shashi and Cohen, Shay B and Lapata, Mirella},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={1797--1807},
  year={2018}
}