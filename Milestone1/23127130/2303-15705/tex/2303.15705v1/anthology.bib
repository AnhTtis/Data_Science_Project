% Please download the latest anthology.bib from
%
% http://aclweb.org/anthology/anthology.bib.gz
% newest vc 
@inproceedings{gagast,
    title = "Automatic Song Translation for Tonal Languages",
    author = "Guo, Fenfei  and
      Zhang, Chen  and
      Zhang, Zhirui  and
      He, Qixin  and
      Zhang, Kejun  and
      Xie, Jun  and
      Boyd-Graber, Jordan",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.60",
    doi = "10.18653/v1/2022.findings-acl.60",
    pages = "729--743",
    abstract = "This paper develops automatic song translation (AST) for tonal languages and addresses the unique challenge of aligning words{'} tones with melody of a song in addition to conveying the original meaning. We propose three criteria for effective AST{---}preserving meaning, singability and intelligibility{---}and design metrics for these criteria. We develop a new benchmark for English{--}Mandarin song translation and develop an unsupervised AST system, Guided AliGnment for Automatic Song Translation (GagaST), which combines pre-training with three decoding constraints. Both automatic and human evaluations show GagaST successfully balances semantics and singability.",
}
@article{LMD,
author = {Yu, Yi and Srivastava, Abhishek and Canales, Simon},
title = {Conditional LSTM-GAN for Melody Generation from Lyrics},
year = {2021},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1},
issn = {1551-6857},
url = {https://doi.org/10.1145/3424116},
doi = {10.1145/3424116},
abstract = {Melody generation from lyrics has been a challenging research issue in the field of artificial intelligence and music, which enables us to learn and discover latent relationships between interesting lyrics and accompanying melodies. Unfortunately, the limited availability of a paired lyrics–melody dataset with alignment information has hindered the research progress. To address this problem, we create a large dataset consisting of 12,197 MIDI songs each with paired lyrics and melody alignment through leveraging different music sources where alignment relationship between syllables and music attributes is extracted. Most importantly, we propose a novel deep generative model, conditional Long Short-Term Memory (LSTM)–Generative Adversarial Network for melody generation from lyrics, which contains a deep LSTM generator and a deep LSTM discriminator both conditioned on lyrics. In particular, lyrics-conditioned melody and alignment relationship between syllables of given lyrics and notes of predicted melody are generated simultaneously. Extensive experimental results have proved the effectiveness of our proposed lyrics-to-melody generative model, where plausible and tuneful sequences can be inferred from lyrics.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {apr},
articleno = {35},
numpages = {20},
keywords = {Lyrics-conditioned melody generation, conditional LSTM-GAN}
}
@inproceedings{songmass,
  title={Songmass: Automatic song writing with pre-training and alignment constraint},
  author={Sheng, Zhonghao and Song, Kaitao and Tan, Xu and Ren, Yi and Ye, Wei and Zhang, Shikun and Qin, Tao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={15},
  pages={13798--13805},
  year={2021}
}
@inproceedings{diffsinger,
  title={Diffsinger: Singing voice synthesis via shallow diffusion mechanism},
  author={Liu, Jinglin and Li, Chengxi and Ren, Yi and Chen, Feiyang and Zhao, Zhou},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={10},
  pages={11020--11028},
  year={2022}
}
@inproceedings{nsvb,
    title = "Learning the Beauty in Songs: Neural Singing Voice Beautifier",
    author = "Liu, Jinglin  and
      Li, Chengxi  and
      Ren, Yi  and
      Zhu, Zhiying  and
      Zhao, Zhou",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.549",
    doi = "10.18653/v1/2022.acl-long.549",
    pages = "7970--7983",
    abstract = "We are interested in a novel task, singing voice beautification (SVB). Given the singing voice of an amateur singer, SVB aims to improve the intonation and vocal tone of the voice, while keeping the content and vocal timbre. Current automatic pitch correction techniques are immature, and most of them are restricted to intonation but ignore the overall aesthetic quality. Hence, we introduce Neural Singing Voice Beautifier (NSVB), the first generative model to solve the SVB task, which adopts a conditional variational autoencoder as the backbone and learns the latent representations of vocal tone. In NSVB, we propose a novel time-warping approach for pitch correction: Shape-Aware Dynamic Time Warping (SADTW), which ameliorates the robustness of existing time-warping approaches, to synchronize the amateur recording with the template pitch curve. Furthermore, we propose a latent-mapping algorithm in the latent space to convert the amateur vocal tone to the professional one. To achieve this, we also propose a new dataset containing parallel singing recordings of both amateur and professional versions. Extensive experiments on both Chinese and English songs demonstrate the effectiveness of our methods in terms of both objective and subjective metrics. Audio samples are available at \url{https://neuralsvb.github.io}. Codes: \url{https://github.com/MoonInTheRiver/NeuralSVB}.",
}
@inproceedings{liu-etal-2022-learning-beauty,
    title = "Learning the Beauty in Songs: Neural Singing Voice Beautifier",
    author = "Liu, Jinglin  and
      Li, Chengxi  and
      Ren, Yi  and
      Zhu, Zhiying  and
      Zhao, Zhou",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.549",
    doi = "10.18653/v1/2022.acl-long.549",
    pages = "7970--7983",
    abstract = "We are interested in a novel task, singing voice beautification (SVB). Given the singing voice of an amateur singer, SVB aims to improve the intonation and vocal tone of the voice, while keeping the content and vocal timbre. Current automatic pitch correction techniques are immature, and most of them are restricted to intonation but ignore the overall aesthetic quality. Hence, we introduce Neural Singing Voice Beautifier (NSVB), the first generative model to solve the SVB task, which adopts a conditional variational autoencoder as the backbone and learns the latent representations of vocal tone. In NSVB, we propose a novel time-warping approach for pitch correction: Shape-Aware Dynamic Time Warping (SADTW), which ameliorates the robustness of existing time-warping approaches, to synchronize the amateur recording with the template pitch curve. Furthermore, we propose a latent-mapping algorithm in the latent space to convert the amateur vocal tone to the professional one. To achieve this, we also propose a new dataset containing parallel singing recordings of both amateur and professional versions. Extensive experiments on both Chinese and English songs demonstrate the effectiveness of our methods in terms of both objective and subjective metrics. Audio samples are available at \url{https://neuralsvb.github.io}. Codes: \url{https://github.com/MoonInTheRiver/NeuralSVB}.",
}
@article{act,
  title={Adaptive computation time for recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1603.08983},
  year={2016}
}
@inproceedings{backtrans,
    title = "Improving Neural Machine Translation Models with Monolingual Data",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1009",
    doi = "10.18653/v1/P16-1009",
    pages = "86--96",
}
@inproceedings{backtrans-noise,
    title = "Understanding Back-Translation at Scale",
    author = "Edunov, Sergey  and
      Ott, Myle  and
      Auli, Michael  and
      Grangier, David",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1045",
    doi = "10.18653/v1/D18-1045",
    pages = "489--500",
    abstract = "An effective method to improve neural machine translation with monolingual data is to augment the parallel training corpus with back-translations of target language sentences. This work broadens the understanding of back-translation and investigates a number of methods to generate synthetic source sentences. We find that in all but resource poor settings back-translations obtained via sampling or noised beam outputs are most effective. Our analysis shows that sampling or noisy synthetic data gives a much stronger training signal than data generated by beam or greedy search. We also compare how synthetic data compares to genuine bitext and study various domain effects. Finally, we scale to hundreds of millions of monolingual sentences and achieve a new state of the art of 35 BLEU on the WMT{'}14 English-German test set.",
}
@article{telemelody,
  author    = {Zeqian Ju and
               Peiling Lu and
               Xu Tan and
               Rui Wang and
               Chen Zhang and
               Songruoyao Wu and
               Kejun Zhang and
               Xiangyang Li and
               Tao Qin and
               Tie{-}Yan Liu},
  title     = {TeleMelody: Lyric-to-Melody Generation with a Template-Based Two-Stage
               Method},
  journal   = {CoRR},
  volume    = {abs/2109.09617},
  year      = {2021},
  url       = {https://arxiv.org/abs/2109.09617},
  eprinttype = {arXiv},
  eprint    = {2109.09617},
  timestamp = {Wed, 27 Apr 2022 19:47:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2109-09617.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{pdaugment,
  title={PDAugment: Data Augmentation by Pitch and Duration Adjustments for Automatic Lyrics Transcription},
  author={Zhang, Chen and Yu, Jiaxing and Chang, LuChin and Tan, Xu and Chen, Jiawei and Qin, Tao and Zhang, Kejun},
  journal={arXiv preprint arXiv:2109.07940},
  year={2021}
}
@inproceedings{ren2020deepsinger,
  title={Deepsinger: Singing voice synthesis with data mined from the web},
  author={Ren, Yi and Tan, Xu and Qin, Tao and Luan, Jian and Zhao, Zhou and Liu, Tie-Yan},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1979--1989},
  year={2020}
}
@article{low_2003,
author = {Low, Peter},
year = {2003},
month = {01},
pages = {87-103},
title = {Singable translations of songs},
volume = {11},
journal = {Perspectives: Studies in Translatology},
doi = {10.1080/0907676X.2003.9961466}
}
@article{nmt,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={In Proceedings of the Inter-national Conference on Learning Representations},
  year={2015}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{hassan2018achieving,
  title={Achieving human parity on automatic chinese to english news translation},
  author={Hassan, Hany and Aue, Anthony and Chen, Chang and Chowdhary, Vishal and Clark, Jonathan and Federmann, Christian and Huang, Xuedong and Junczys-Dowmunt, Marcin and Lewis, William and Li, Mu and others},
  journal={arXiv preprint arXiv:1803.05567},
  year={2018}
}
@inproceedings{pndm,
    title={Pseudo Numerical Methods for Diffusion Models on Manifolds},
    author={Luping Liu and Yi Ren and Zhijie Lin and Zhou Zhao},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=PlKWVd2yBkY}
}
@inbook{low_2022, place={Cambridge}, series={Cambridge Handbooks in Language and Linguistics}, title={Translating the Texts of Songs and Other Vocal Music}, DOI={10.1017/9781108616119.026}, booktitle={The Cambridge Handbook of Translation}, publisher={Cambridge University Press}, author={Low, Peter}, editor={Malmkjær, KirstenEditor}, year={2022}, pages={499–518}, collection={Cambridge Handbooks in Language and Linguistics}}
@article{low2008translating,
  title={Translating songs that rhyme},
  author={Low, Peter},
  journal={Perspectives: Studies in translatology},
  volume={16},
  number={1-2},
  pages={1--20},
  year={2008},
  publisher={Taylor \& Francis}
}
@article{three_d_of_singability,
  title={Three dimensions of singability. An approach to subtitled and sung translations},
  author={Franzon, Johan},
  journal={Text and Tune. On the Association of Music and Lyrics in Sung Verse. Bern: Peter Lang},
  pages={333--346},
  year={2015}
}
@article{trans_of_music,
  title={Translation of music},
  author={Desblache, Lucile},
  journal={An encyclopedia of practical translation and interpreting},
  pages={297--324},
  year={2018}
}
@article{interplay_lyrics_melody,
  title={The materiality of music: interplay of lyrics and melody in song translation},
  author={Riku Haapaniemi and Emma Laakkonen},
  journal={Translation Matters},
  year={2019}
}
@inproceedings{bart,
    title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.703",
    doi = "10.18653/v1/2020.acl-main.703",
    pages = "7871--7880",
    abstract = "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance.",
}
@inproceedings{li-etal-2020-rigid,
    title = "Rigid Formats Controlled Text Generation",
    author = "Li, Piji  and
      Zhang, Haisong  and
      Liu, Xiaojiang  and
      Shi, Shuming",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.68",
    doi = "10.18653/v1/2020.acl-main.68",
    pages = "742--751",
    abstract = "Neural text generation has made tremendous progress in various tasks. One common characteristic of most of the tasks is that the texts are not restricted to some rigid formats when generating. However, we may confront some special text paradigms such as Lyrics (assume the music score is given), Sonnet, SongCi (classical Chinese poetry of the Song dynasty), etc. The typical characteristics of these texts are in three folds: (1) They must comply fully with the rigid predefined formats. (2) They must obey some rhyming schemes. (3) Although they are restricted to some formats, the sentence integrity must be guaranteed. To the best of our knowledge, text generation based on the predefined rigid formats has not been well investigated. Therefore, we propose a simple and elegant framework named SongNet to tackle this problem. The backbone of the framework is a Transformer-based auto-regressive language model. Sets of symbols are tailor-designed to improve the modeling performance especially on format, rhyme, and sentence integrity. We improve the attention mechanism to impel the model to capture some future information on the format. A pre-training and fine-tuning framework is designed to further improve the generation quality. Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates significantly better results in terms of both automatic metrics and the human evaluation.",
}
@inproceedings{lakew-etal-2019-controlling,
    title = "Controlling the Output Length of Neural Machine Translation",
    author = "Lakew, Surafel Melaku  and
      Di Gangi, Mattia  and
      Federico, Marcello",
    booktitle = "Proceedings of the 16th International Conference on Spoken Language Translation",
    month = nov # " 2-3",
    year = "2019",
    address = "Hong Kong",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2019.iwslt-1.31",
    abstract = "The recent advances introduced by neural machine translation (NMT) are rapidly expanding the application fields of machine translation, as well as reshaping the quality level to be targeted. In particular, if translations have to fit some given layout, quality should not only be measured in terms of adequacy and fluency, but also length. Exemplary cases are the translation of document files, subtitles, and scripts for dubbing, where the output length should ideally be as close as possible to the length of the input text. This pa-per addresses for the first time, to the best of our knowledge, the problem of controlling the output length in NMT. We investigate two methods for biasing the output length with a transformer architecture: i) conditioning the output to a given target-source length-ratio class and ii) enriching the transformer positional embedding with length information. Our experiments show that both methods can induce the network to generate shorter translations, as well as acquiring inter- pretable linguistic skills.",
}
@inproceedings{saboo-baumann-2019-integration,
    title = "Integration of Dubbing Constraints into Machine Translation",
    author = "Saboo, Ashutosh  and
      Baumann, Timo",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-5210",
    doi = "10.18653/v1/W19-5210",
    pages = "94--101",
    abstract = "Translation systems aim to perform a meaning-preserving conversion of linguistic material (typically text but also speech) from a source to a target language (and, to a lesser degree, the corresponding socio-cultural contexts). Dubbing, i.e., the lip-synchronous translation and revoicing of speech adds to this constraints about the close matching of phonetic and resulting visemic synchrony characteristics of source and target material. There is an inherent conflict between a translation{'}s meaning preservation and {`}dubbability{'} and the resulting trade-off can be controlled by weighing the synchrony constraints. We introduce our work, which to the best of our knowledge is the first of its kind, on integrating synchrony constraints into the machine translation paradigm. We present first results for the integration of synchrony constraints into encoder decoder-based neural machine translation and show that considerably more {`}dubbable{'} translations can be achieved with only a small impact on BLEU score, and dubbability improves more steeply than BLEU degrades.",
}
@inproceedings{spanish_verse,
  title={WASP: Evaluation of Different Strategies for the Automatic Generation of Spanish Verse},
  author={Pablo Gerv{\'a}s},
  year={2002}
}
@inproceedings{lee-etal-2019-icomposer,
    title = "i{C}omposer: An Automatic Songwriting System for {C}hinese Popular Music",
    author = "Lee, Hsin-Pei  and
      Fang, Jhih-Sheng  and
      Ma, Wei-Yun",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-4015",
    doi = "10.18653/v1/N19-4015",
    pages = "84--88",
    abstract = "In this paper, we introduce iComposer, an interactive web-based songwriting system designed to assist human creators by greatly simplifying music production. iComposer automatically creates melodies to accompany any given text. It also enables users to generate a set of lyrics given arbitrary melodies. iComposer is based on three sequence-to-sequence models, which are used to predict melody, rhythm, and lyrics, respectively. Songs generated by iComposer are compared with human-composed and randomly-generated ones in a subjective test, the experimental results of which demonstrate the capability of the proposed system to write pleasing melodies and meaningful lyrics at a level similar to that of humans.",
}
@article{Chen2020MelodyConditionedLG,
  title={Melody-Conditioned Lyrics Generation with SeqGANs},
  author={Yihao Chen and Alexander Lerch},
  journal={2020 IEEE International Symposium on Multimedia (ISM)},
  year={2020},
  pages={189-196}
}
@inproceedings{ai_lyricist,
author = {Ma, Xichu and Wang, Ye and Kan, Min-Yen and Lee, Wee Sun},
title = {AI-Lyricist: Generating Music and Vocabulary Constrained Lyrics},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474085.3475502},
doi = {10.1145/3474085.3475502},
abstract = {We propose AI-Lyricist: a system to generate novel yet meaningful lyrics given a required vocabulary and a MIDI file as inputs. This task involves multiple challenges, including automatically identifying the melody and extracting a syllable template from multi-channel music, generating creative lyrics that match the input music's style and syllable alignment, and satisfying vocabulary constraints. To address these challenges, we propose an automatic lyrics generation system consisting of four modules: (1) A music structure analyzer to derive the musical structure and syllable template from a given MIDI file, utilizing the concept of expected syllable number to better identify the melody, (2) a SeqGAN-based lyrics generator optimized by multi-adversarial training through policy gradients with twin discriminators for text quality and syllable alignment, (3) a deep coupled music-lyrics embedding model to project music and lyrics into a joint space to allow fair comparison of both melody and lyric constraints, and a module called (4) Polisher, to satisfy vocabulary constraints by applying a mask to the generator and substituting the words to be learned. We trained our model on a dataset of over 7,000 music-lyrics pairs, enhanced with manually annotated labels in terms of theme, sentiment and genre. Both objective and subjective evaluations show AI-Lyricist's superior performance against the state-of-the-art for the proposed tasks.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {1002–1011},
numpages = {10},
keywords = {adversarial training, music, language learning, lyrics generation},
location = {Virtual Event, China},
series = {MM '21}
}
@inproceedings{xue-etal-2021-deeprapper,
    title = "{D}eep{R}apper: Neural Rap Generation with Rhyme and Rhythm Modeling",
    author = "Xue, Lanqing  and
      Song, Kaitao  and
      Wu, Duocai  and
      Tan, Xu  and
      Zhang, Nevin L.  and
      Qin, Tao  and
      Zhang, Wei-Qiang  and
      Liu, Tie-Yan",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.6",
    doi = "10.18653/v1/2021.acl-long.6",
    pages = "69--81",
    abstract = "Rap generation, which aims to produce lyrics and corresponding singing beats, needs to model both rhymes and rhythms. Previous works for rap generation focused on rhyming lyrics, but ignored rhythmic beats, which are important for rap performance. In this paper, we develop DeepRapper, a Transformer-based rap generation system that can model both rhymes and rhythms. Since there is no available rap datasets with rhythmic beats, we develop a data mining pipeline to collect a large-scale rap dataset, which includes a large number of rap songs with aligned lyrics and rhythmic beats. Second, we design a Transformer-based autoregressive language model which carefully models rhymes and rhythms. Specifically, we generate lyrics in the reverse order with rhyme representation and constraint for rhyme enhancement, and insert a beat symbol into lyrics for rhythm/beat modeling. To our knowledge, DeepRapper is the first system to generate rap with both rhymes and rhythms. Both objective and subjective evaluations demonstrate that DeepRapper generates creative and high-quality raps with rhymes and rhythms.",
}
@inproceedings{zou_controllable,
author = {Zou, Xu and Yin, Da and Zhong, Qingyang and Yang, Hongxia and Yang, Zhilin and Tang, Jie},
title = {Controllable Generation from Pre-Trained Language Models via Inverse Prompting},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467418},
doi = {10.1145/3447548.3467418},
abstract = {Large-scale pre-trained language models have demonstrated strong capabilities of generating realistic texts. However, it remains challenging to control the generation results. Previous approaches such as prompting are far from sufficient, and lack of controllability limits the usage of language models. To tackle this challenge, we propose an innovative method, inverse prompting, to better control text generation. The core idea of inverse prompting is to use generated text to inversely predict the prompt during beam search, which enhances the relevance between the prompt and the generated text and thus improves controllability. Empirically, we pre-train a large-scale Chinese language model to perform a systematic study using human evaluation on the tasks of open-domain poem generation and open-domain long-form question answering. Results demonstrate that our proposed method substantially outperforms the baselines and that our generation quality is close to human performance on some of the tasks.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery; Data Mining},
pages = {2450–2460},
numpages = {11},
keywords = {language modeling, controllable generation, beam search, poem generation, machine question answering},
location = {Virtual Event, Singapore},
series = {KDD '21}
}
@inproceedings{hokamp-liu-2017-lexically,
    title = "Lexically Constrained Decoding for Sequence Generation Using Grid Beam Search",
    author = "Hokamp, Chris  and
      Liu, Qun",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1141",
    doi = "10.18653/v1/P17-1141",
    pages = "1535--1546",
    abstract = "We present Grid Beam Search (GBS), an algorithm which extends beam search to allow the inclusion of pre-specified lexical constraints. The algorithm can be used with any model which generates sequences token by token. Lexical constraints take the form of phrases or words that must be present in the output sequence. This is a very general way to incorporate auxillary knowledge into a model{'}s output without requiring any modification of the parameters or training data. We demonstrate the feasibility and flexibility of Lexically Constrained Decoding by conducting experiments on Neural Interactive-Predictive Translation, as well as Domain Adaptation for Neural Machine Translation. Experiments show that GBS can provide large improvements in translation quality in interactive scenarios, and that, even without any user input, GBS can be used to achieve significant gains in performance in domain adaptation scenarios.",
}
@inproceedings{Manurung2004AnEA,
  title={An evolutionary algorithm approach to poetry generation},
  author={Hisar Maruli Manurung},
  year={2004}
}
@article{He_Zhou_Jiang_2012, title={Generating Chinese Classical Poems with Statistical Machine Translation Models}, volume={26}, url={https://ojs.aaai.org/index.php/AAAI/article/view/8344}, DOI={10.1609/aaai.v26i1.8344}, abstractNote={This paper describes a statistical approach to generation of Chinese classical poetry and proposes a novel method to automatically evaluate poems. The system accepts a set of keywords representing the writing intents from a writer and generates sentences one by one to form a completed poem. A statistical machine translation (SMT) system is applied to generate new sentences, given the sentences generated previously. For each line of sentence a specific model specially trained for that line is used, as opposed to using a single model for all sentences. To enhance the coherence of sentences on every line, a coherence model using mutual information is applied to select candidates with better consistency with previous sentences. In addition, we demonstrate the effectiveness of the BLEU metric for evaluation with a novel method of generating diverse references.}, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={He, Jing and Zhou, Ming and Jiang, Long}, year={2012}, month={Sep.}, pages={1650-1656} }
@inproceedings{ghazvininejad-etal-2016-generating,
    title = "Generating Topical Poetry",
    author = "Ghazvininejad, Marjan  and
      Shi, Xing  and
      Choi, Yejin  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D16-1126",
    doi = "10.18653/v1/D16-1126",
    pages = "1183--1191",
}
@inproceedings{ghazvininejad-etal-2017-hafez,
    title = "{H}afez: an Interactive Poetry Generation System",
    author = "Ghazvininejad, Marjan  and
      Shi, Xing  and
      Priyadarshi, Jay  and
      Knight, Kevin",
    booktitle = "Proceedings of {ACL} 2017, System Demonstrations",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-4008",
    pages = "43--48",
}
@inproceedings{ghazvininejad-etal-2018-neural,
    title = "Neural Poetry Translation",
    author = "Ghazvininejad, Marjan  and
      Choi, Yejin  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-2011",
    doi = "10.18653/v1/N18-2011",
    pages = "67--71",
    abstract = "We present the first neural poetry translation system. Unlike previous works that often fail to produce any translation for fixed rhyme and rhythm patterns, our system always translates a source text to an English poem. Human evaluation of the translations ranks the quality as acceptable 78.2{\%} of the time.",
}