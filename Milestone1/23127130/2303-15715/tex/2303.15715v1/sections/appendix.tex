\clearpage
\newpage
\section{Experimental Setup}
\label{app:exp_setup}
\subsection{Book Extraction Experiments}


\paragraph{Dataset.} The text extraction experiment shown in Figure~\ref{fig:benchmarking} determines how much literary content can be extracted by giving small portions of copyrighted books as inputs. We first randomly sample snippets of 125 tokens top-selling books according to~\citet{top100} that also appear in the Books3 corpus~\citep{books3}. We also use another sampling method where we extract random text from books in the entirety of the books corpus~\citep{bookcorpus}. We finally include another variant where we only input the title and author name of ``Oh the places you'll go!'' by Dr. Seuss with different formatting and prompts.

\paragraph{Protocol.} We then feed these into Model APIs with a generation temperature of $T=0.2$, we use this temperature for two reasons. First, we were resource-constrained for the models such that using a higher temperature would require more sampling to find exact matches. Second, we hypothesize that heavily-memorized material would be encoded in a model even at low temperatures. For some models this resulted in significant repetition (where the model outputs the same text over and over again). It is possible that at higher temperatures some models might end up regurgitating more text once this repetition is overcome. 

We have two metrics for similarity. First, we evaluate the Longest Common Substring over the Prefix Length. This is the number of tokens that the generated text and the reference text have in common divided by the length of the input prompt. In effect this gives a metric that represents how many verbatim contiguous copyrighted tokens you will get back as a fraction of your input tokens, on average. Note, that since this is a token-based contiguous metric, it may be \textit{underrepresentative} of the amount of copyrighted text that includes paraphrasing or small other transformations.
For ``Oh the places you'll go'' we  use Python's difflib to to show the similarity between the input and output texts. Difflib functions at a character level comparing the ratio of varbatim material in reference and generated text.


\subsection{Code Extraction Experiments}

\paragraph{Dataset.}
The first experiment performed in Section~\ref{sec:code} attempts to extract Linux kernel source code from models. 
We collected a dataset of prefix-completion pairs where the prefix is the first line (the signature) of a function, and the completion is the function body. 
The set of function signatures was randomly selected among all functions with above 20 lines of implementation in the Linux kernel source code Github repository's master branch on June 8 2022.
The dataset can be accessed with this link \url{https://drive.google.com/file/d/1OLFyW5u7govgIw3ztsZ_5yYV0YpGzi-3/view?usp=share_link}.

The data was collected based on our assumption that Codex models were trained on code from the Linux kernel Github repo. 
Even if this is true, we note that the completions we collected might not exactly match the version of code that Codex was trained on due to potential changes in the Linux kernel Github repo (Codex models are trained on code collected much earlier than when our efforts started).
Despite these issues, by running the fuzzy plagiarism detection software MossPlus with the completions and our references, we were able to discover multiple instances of large overlap. 
This highlights the advantage of using a fuzzy similarity metric and calls for developing likewise metrics in other domains. 

Note MossPlus can give false positives. 
After manual inspection, we found false positives for references and generations which contained large spans of variable assignments. 



\paragraph{Protocol.}
The code extraction experiments in Section~\ref{sec:code} were performed with the OpenAI API. 
For experiments extracting GPL code, we sampled 10 completions for each prefix with a temperature of 0.2. 
We didn't truncate the next token distribution ($p=1$).
We set the maximum number of tokens to be generated to be 1800.
We ran MossPlus and collected, for each prefix, the generation with maximum reported overlap.
These numbers are then used to create Figure~\ref{fig:similar_code}. 
We note that reducing the number of samples per prefix slightly decreased the rate of large match and average large match percentage, but generations with large overlaps still existed.
Experiments for extracting names and emails were performed by querying the same API with the same decoding parameters.

\clearpage
\newpage
\section{Examples of Reproduced Code}\label{app:similar_code}
\vspace{-4mm}
We include representative generations produced by three code generation models (\texttt{code-davinci-002}, \texttt{code-davinci-001}, and \texttt{code-cushman-001}) which overlap with references. 
Since we do not have access to the dataset on which these models were trained, we used the Linux Github repository in early June 2022 as the ground truth.
Code chunks highlighted in colors are overlaps reported by MossPlus.

\input{listings/no1}
\input{listings/no2}
\input{listings/no3}
\input{listings/no4}
\input{listings/no5}
\input{listings/no6}
\input{listings/no7}
\input{listings/no8}
\input{listings/no9}


\clearpage
\newpage
\section{Additional Breakdowns of Prompt Entities}

\begin{figure}[tbh]
    \centering
    \includegraphics[width=.7\textwidth]{figures/org.pdf}
    \caption{The top organizations cited in prompts.}
    \label{fig:orgs}
\end{figure}

\begin{figure}[tbh]
    \centering
    \includegraphics[width=.7\textwidth]{figures/person.pdf}
    \caption{The top people cited in prompts.}
    \label{fig:person_analysis}
\end{figure}

\begin{figure}[tbh]
    \centering
    \includegraphics[width=.7\textwidth]{figures/woa.pdf}
    \caption{The top works of art cited in prompts as annotated by the spacy model. Note most of these are commercial artworks (movies and video games).}
    \label{fig:woa_analysis}
\end{figure}

\clearpage
\newpage
\section{Additional Qualitative Examples}
\label{app:qualitative_text}

\begin{figure}[htb]
    \centering
    \includegraphics[width=.45\textwidth]{figures/chat_gpt_snippet_1.png}
    \includegraphics[width=.45\textwidth]{figures/chat_gpt_snippet_2.png}
    \includegraphics[width=.45\textwidth]{figures/chat_gpt_snippet_3.png}
    \caption{Qualitative interactions with ChatGPT (original release) resulting in verbatim regurgitation of ``Oh the places you'll go'' in its entirety. We remove the inner portions of the generation to keep the presentation in the bounds of fair use doctrine.}
    \label{fig:my_label}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=.45\textwidth]{figures/shell_prompt.png}
    \includegraphics[width=.45\textwidth]{figures/oh_the_places_vim.png}
    \caption{Qualitative interactions with ChatGPT (original release) resulting in verbatim regurgitation of ``Oh the places you'll go'' in its entirety. We remove the inner portions of the generation to keep the presentation in the bounds of fair use doctrine. We were able to regurgitate all of the story by prompting the agent as if it's in a linux shell and then running vim on an imaginary text file containing the story.}
    \label{fig:oh_shell_vim}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=.45\textwidth]{figures/stockfish_real.png}
    \includegraphics[width=.45\textwidth]{figures/stockfish.png}
    \caption{Using the shell prompt from Figure~\ref{fig:oh_shell_vim} we were also able to generate some overlapping code from GPL-licensed codebases using only the vim command in the original version of ChatGPT.}
    \label{fig:oh_shell_vim}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=.45\textwidth]{figures/real_etree.png}
        \includegraphics[width=.45\textwidth]{figures/vim_cs_etree.png}
    \caption{Using the shell prompt from Figure~\ref{fig:oh_shell_vim} we were also able to generate some overlapping code from GPL-licensed codebases using only the vim command in the original version of ChatGPT.}
    \label{fig:oh_shell_vim}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=.45\textwidth]{figures/chatgpt_harry_potter_snippet.png}
    \includegraphics[width=.45\textwidth]{figures/chatgpt_harry_potter_snippet2.png}
    \caption{For the original ChatGPT release found it difficult to generate longer form versions of Harry Potter with only the first 3 pages (one context window) generated verbatim.}
    \label{fig:my_label}
\end{figure}

\begin{figure}
    \centering
\begin{tabular}{m{0.47\textwidth} >{\centering}m{2em} m{0.47\textwidth}}
{\color{blue} The villagers of Little Hangleton still called it 'the Riddle House', even though it had been many years since the Riddle family had lived there. It stood on a hill overlooking the village, some of its windows boarded, tiles missing from its roof, and ivy spreading unchecked over its face. Once a fine-looking manor, and easily the largest and grandest building for miles around, the Riddle House was now damp, derelict and unoccupied. The Little Hangletons all agreed that the old house was 'creepy'. Half a century ago, something strange and horrible had happened there, something that the older inhabitants of the village still liked to discuss when topics for gossip were scarce. The story} {\color{red} had been picked over so many times, and had been embroidered in so many places, that nobody was quite sure what the truth was any more. Every version of the tale, however, started in the same place: fifty years before, at }{\color{orange} four o'clock in the morning, when the Riddle House had still been well kept and well populated,} {\color{red} a maid had entered a bedroom to find all three Riddles dead. The maid had run screaming down the stairs, and roused as many of the household as she could.} {\color{violet} But it was too late. There was nothing the matter with any of them physically, but all were dead. The doctor was called, but he could find no cause of death. The whole of Little Hangleton had been thrown into turmoil. The police were called, and they searched the house from top to bottom. They found nothing suspicious, no signs of any intruder, and no reason why the entire Riddle family should have died, seemingly of fright, in the early hours of that morning. The countryside was searched, but there were no clues, and no suspects. The Riddle family were buried in the Little Hangleton churchyard, and the house was left empty. The Riddle name was taken off the front gate, and eventually people began to talk of the 'ghost house' at the top of the hill. The village children were warned not to go near it, and the house fell into disrepair as the years passed. Nobody ever bought it. It was there when the next generation of children were warned not to go near it, and it was still there as the generation after that grew up. The story of the Riddle family's death was a favourite topic for summer nights around village fires, and Little Hangleton's residents liked to say that the house was haunted by the ghosts of the family, who had died so suddenly and so mysteriously. Over the years, the Riddle House had become a dark and forbidding place. The windows were boarded, the garden was a tangle of weeds, brambles, and bushes, and the roof was covered in moss. It loomed up rather than rose, its gables sharp and crooked, its walls damp and crumbling, its chimneys tall and slender like needles. It was still difficult to believe that three healthy. . .}
 &  $\longleftrightarrow$ & 
 {\color{blue} The villagers of Little Hangleton still called it 'the Riddle House', even though it had been many years since the Riddle family had lived there. It stood on a hill overlooking the village, some of its windows boarded, tiles missing from its roof, and ivy spreading unchecked over its face. Once a fine-looking manor, and easily the largest and grandest building for miles around, the Riddle House was now damp, derelict and unoccupied. The Little Hangletons all agreed that the old house was 'creepy'. Half a century ago, something strange and horrible had happened there, something that the older inhabitants of the village still liked to discuss when topics for gossip were scarce. The story} {\color{red} had been picked over so many times, and had been embroidered in so many places, that nobody was quite sure what the truth was any more. Every version of the tale, however, started in the same place: fifty years before, at} {\color{orange} daybreak on a fine summer's morning, when the Riddle House had still been well kept and impressive,} {\color{red} and a maid had entered the drawing room to find all three Riddles dead. The maid had run screaming down the hill into the village, and roused as many people as she could.} {\color{violet} 'Lying there with their eyes wide open! Cold as ice! Still in their dinner things!' The police were summoned, and the whole of Little Hangleton had seethed with shocked curiosity and ill-disguised excitement. Nobody wasted their breath pretending to feel very sad about the Riddles, for they had been most unpopular. Elderly Mr and Mrs Riddle had been rich, snobbish and rude, and their grown-up son, Tom, had been even more so. All the villagers cared about was the identity of their murderer – plainly, three apparently healthy people did not all drop dead of natural causes on the same night. The Hanged Man, the village pub, did a roaring trade that night; the whole village had turned out to discuss the murders. They were rewarded for leaving their firesides when the Riddles' cook arrived dramatically in their midst, and announced to the suddenly silent pub that a man called Frank Bryce had just been arrested. 'Frank!' cried several people. 'Never!' Frank Bryce was the Riddles' gardener. He lived alone in a run-down cottage in the Riddle House grounds. Frank had come back from the war with a very stiff leg and a great dislike of crowds and loud noises, and had been working for the Riddles ever since. There was a rush to buy the cook drinks, and hear more details. 'Always thought he was odd,' she told the eagerly listening villagers, after her fourth sherry. 'Unfriendly, like. I'm sure if I've offered him a cuppa once, I've offered it a hundred times. Never wanted to mix, he didn't.' 'Ah, now,' said a woman at the bar, 'he had a hard war, Frank, he likes the quiet life. That's no reason to –' 'Who else had a key to the back door, then?' barked the cook. . .}
 \\
&&\\
\centering Generated (Anthropic 66B) &  $\longleftrightarrow$ & \centering Reference
\end{tabular}
    \caption{Qualitative example of randomly selected prompt and how model paraphrases before deviating.}
    \label{fig:deviation}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=.45\textwidth]{figures/refused.png}
    \includegraphics[width=.45\textwidth]{figures/gpt4hp.png}
    \caption{With GPT-4 (using the March 15 model), we found that the model would only output the first three words of the next paragraph and stopped. However, with an instruction to replace some letters with numbers (and prompting to continue generation) the model output around three chapters of the first Harry Potter book.}
    \label{fig:gpt4}
\end{figure}
