\clearpage
\appendix
\noindent\textbf{Supplementary Material}
\section{Details of Experimental Settings and Additional Results}

\subsection{Detailed Extraction Attack Setting}
\label{apx:setting}
For the surrogate model training, we use SGD optimizer with a learning rate of 0.02 for 200 epochs. The learning rate is multiplied by a factor of 0.2 at epochs 60, 120 and 160.
For Craft-ME, we craft an equal number of small-loss instances  for each class. We use the Adam optimizer with a learning rate of 0.1 and set the total number of steps~(iterations) to 20 or 50 to craft each image. For GAN-ME, we use a conditional-GAN model as the generator, its detailed architecture is given in Appendix~\ref{sec:cgan}. For the generator training, we use Adam optimizer with a learning rate of 1e-4 and apply the divergence-aware regularization \cite{yang2019diversity} with a factor of 50 to mitigate the mode collapse problem. For GM-ME, we query with the entire training dataset (i.e. 50K) of each auxiliary dataset (CIFAR-10, SVHN and MNIST). For Train-ME and SoftTrain-ME, we apply standard data augmentation techniques including random rotating and horizontal flipping, during the surrogate model training. For SoftTrain-ME, we train the surrogate model with both the hard labels and gradient-based soft labels with $\alpha$ parameter of 0.9. Data augmentation is disabled if training uses soft labels. 

% \subsection{Illustration of the Attack Workflow}
% \label{apx:attack_illustrate}
% The workflow of five proposed attacks are illustrated in \cref{fig:attack_explained}. During SFL training, a malicious client (the attacker) can deploy either of five ME attacks depending on its data assumption. 

% For the no-data case, the attacker can use either Craft-ME or GAN-ME. Here the gradients are used to generate crafted data or update the conditional GAN as data generator. These two attacks require a longer preparation step,  where the crafted data and data generator are derived, prior to the surrogate model training.

% For all five attacks, the surrogate model is trained using the known client-side model as the initial model. For Train-ME, Craft-ME and GAN-ME, the standard cross-entropy loss is used. 
% For GM-ME, the gradient matching loss is used, and for SoftTrain-ME, the gradient-based soft labels are used.

% \begin{figure*}[htbp]
% \centering
%   \centering
%   \includegraphics[width=0.9\linewidth]{attack_explained.pdf}
% \vspace{-0.0em}
% \caption{Detailed illustration of five proposed Model Extraction (ME) attacks in SFL. After preparation phase (if necessary), the attack completes by training the surrogate model till its convergence.}
% \vspace{-0.5em}
% \label{fig:attack_explained}
% \end{figure*}

\subsection{Gradient-based Attack Performance with Consistent Gradient Access}
\label{apx:ideal_case}
We did extensive experiments for ME attacks in different settings with consistent gradient query access and present the results here. These are in addition to what was presented in Section~\ref{sec:fine-tune}. The query budget is set at 1K, 10K and 100K. Results for all five ME attacks with different settings are shown separately in~\cref{fig:stable_figures} (a), (b), (c), (d) and (e). The victim VGG-11 model has 91.89\% validation accuracy on CIFAR-10 dataset.
For GM-ME, we CIFAR-100, SVHN, and MNIST as the auxiliary dataset. 

\textbf{Conclusion.} We observe all ME attacks are equally successful for small $N$. Among different settings, Craft-ME performs better with 20 steps compared to 50 steps. This is possibly because for the same query budget, fewer steps results in more images being crafted.
%and it seems number matters more than quality. 
GAN-ME performance is much better with a larger query budget since a generator model needs more iterations of training to converge. GM-ME's performance heavily depends on the similarity of the auxiliary dataset. Because the victim model is on CIFAR-10, it performs well when CIFAR-100 is set as the auxiliary dataset while performing badly when MNIST is used. Moreover, attacks with training data perform much better than ME attacks without training data. Compared to Train-ME, SoftTrain-ME achieves better accuracy and fidelity when $N\geq6$.


\begin{figure*}[htbp]
\centering
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=0.99\linewidth]{stable_figure1.pdf}
  \label{fig:stable_sub1}
\vspace{-1.0em}
\caption{}
\end{subfigure}%
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=0.99\linewidth]{stable_figure2.pdf}
  \label{fig:stable_sub2}
\vspace{-1.0em}
\caption{}
\end{subfigure}
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=0.99\linewidth]{stable_figure3.pdf}
  \label{fig:stable_sub3}
\vspace{-1.0em}
\caption{}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
  \centering
  \includegraphics[width=0.99\linewidth]{stable_figure4.pdf}
  \label{fig:stable_sub4}
\vspace{-0.5em}
\caption{}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
  \centering
  \includegraphics[width=0.99\linewidth]{stable_figure5.pdf}
  \label{fig:stable_sub5}
\vspace{-0.5em}
\caption{}
\end{subfigure}
\caption{Additional results for \textbf{fine-tuning} SFL case. \textbf{Top row:} ME attacks without training data with different settings. (a) Craft-ME with different number of crafting steps and query budgets. (b) GAN-ME with different query budgets. (c) GM-ME with different auxiliary datasets and query budgets. 
\textbf{Bottom row:} ME attacks with training data with different settings. (d) Train-ME with 1K/10K training data. (e) SoftTrain-ME with 1K/10K training data with different query budgets.}
\vspace{-0.5em}
\label{fig:stable_figures}
\vspace{-0.5em}
\end{figure*}

\subsection{Gradient-based Attack Performance with Inconsistent Gradient Access}
\label{apx:practical_case}
% Next, we investigate the attack performance for the training-from-scratch setting, where the gradient is inconsistent since the model keeps getting updated. 
Here, we provide results for ME attacks for training-from-scratch settings with inconsistent gradient query access; a subset of these results was presented in Section~\ref{sec:practical}.
We launch the attack by feeding malicious inputs at late epochs, specifically, epochs 120 or 160, for the case when the number of training epochs is 200. The attacker starts to collect gradients after the attack is launched till the the end of training (epoch 200). 
We start the gradient collection from later epochs since by then the model has achieved near-optimal accuracy and hence is valuable as an attack target.  Also the model updating is slower because of application of learning rate decay to make the gradients more consistent.

In multi-client SFL, the original 50K training data is divided equally to 5 or 10 benign clients, denoted as ``5-client'' and ``10-client'' case, respectively. The attacker is an additional client without training data so a 5-client SFL really has 6 clients (5 benign clients and 1 malicious client). All clients, including the attacker, perform an equal number of queries in each epoch.
The performance of five ME attacks with inconsistent gradient queries are shown separately in~\cref{fig:unstable_figures}~(a), (b), (c), (d) and (e). Because of the poisoning effect, the final model accuracy of the victim model is reduced by 2 $\sim$ 3\%. For GM-ME, we use CIFAR-100 as the auxiliary dataset, and we only use the latest gradients to perform  gradient matching instead of using all collected gradients. We use ``late50'' to denote only gradients collected in 50 latest training steps are used. This restriction greatly reduces the number of gradients being available but makes them much more consistent.

\textbf{Conclusion.} Attacks without training data (Craft, GAN, GM MEs) work poorly with inconsistent gradient queries. For Craft-ME, taking 20 steps also seems to work better in both 5-client and 10-client cases. Collecting gradients starting later at epoch 160 gets better performance than starting early at epoch 120  because of more consistent gradients. The starting-later rule also holds for GAN-ME and GM-ME, where we can see starting later achieves consistently better ME attack performance. For GM-ME, it only gets meaningful accuracy if only the latest gradients (within 10 training steps to the end of training) are used, showing that it is extremely sensitive to gradient consistency. For attacks with training data, we notice Train-ME attack performance is not affected because it does not rely on gradients. However, SoftTrain-ME performs much worse because of the poisoning effect and inconsistent gradients.

\begin{figure*}[htbp]
\centering
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=0.99\linewidth]{unstable_figure1.pdf}
  \label{fig:unstable_sub1}
\vspace{-1.0em}
\caption{}
\end{subfigure}%
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=0.99\linewidth]{unstable_figure2.pdf}
  \label{fig:unstable_sub2}
\vspace{-1.0em}
\caption{}
\end{subfigure}
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=0.99\linewidth]{unstable_figure3.pdf}
  \label{fig:unstable_sub3}
\vspace{-1.0em}
\caption{}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
  \centering
  \includegraphics[width=0.99\linewidth]{unstable_figure4.pdf}
  \label{fig:unstable_sub4}
\vspace{-0.5em}
\caption{}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
  \centering
  \includegraphics[width=0.99\linewidth]{unstable_figure5.pdf}
  \label{fig:unstable_sub5}
\vspace{-0.5em}
\caption{}
\end{subfigure}
\caption{Additional results for \textbf{training-from-scratch} SFL case. \textbf{Top row:} ME attacks without training data with different settings. (a) Craft-ME with different steps and starting epochs. (b) GAN-ME with different starting epochs. (c) GM-ME uses the latest gradients with different restrictions. 
\textbf{Bottom row:} ME attacks with training data with different settings. (d) Train-ME with 10K/5K training data. (e) SoftTrain-ME with 10K/5K training data with different starting epochs.}
\vspace{-0.5em}
\label{fig:unstable_figures}
\vspace{-0.5em}
\end{figure*}
% \begin{table*}[htbp]


\subsection{Accuracy Impact of Defensive Methods}
\label{apx:impact_defenses}

We provide original accuracy, ME attack performance, as well as model inversion attack performance in addition to what was presented in the main paper in section~\ref{sec:discussion}. As shown in Table~\ref{tab:defense_detail},
L1 regularization works well for $N=5$ where it reduces extraction performance a lot while slightly affecting original accuracy, and at the same time also improves the resistance to model inversion attack (better data protection). 

\begin{table*}[htbp]
\caption{Detailed defensive performance of L1 regularization (L1Reg) of VGG-11 model on CIFAR-10. Extraction performance of Train-ME with 1K training data is shown. Resistance to model inversion attack is shown by MSE.}
\label{tab:defense_detail}
\begin{center}
\begin{small}
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{lc|cccc|cccc} 
 \toprule
 \multirow{2}{*}{Regularization}& \multirow{2}{*}{Strength}&\multicolumn{4}{c}{\textbf{N=4}} & \multicolumn{4}{c}{\textbf{N=5}}\\
  & &Orig. Accu. & Accuracy & Fidelity & MSE &Orig. Accu. & Accuracy & Fidelity & MSE\\
 \midrule
 None &0.0 &91.45&91.02&96.94&0.0217&91.71&90.23&94.73&0.0114\\
 L1Reg &5e-5 &90.66&89.44&95.03&0.0274&90.43&87.45&91.10&0.0270\\
 L1Reg &1e-4 &87.90&86.24&93.68&0.0280&88.37&82.18&86.01&0.0239\\
 L1Reg &2e-4 &82.96&80.56&89.98&0.0262&85.00&76.45&80.78&0.0145\\
%  InvDistCorr &5.0  &90.84&88.70&93.40&0.0110&90.90&89.19&93.57&0.0107\\
%  InvDistCorr &10.0 &90.67&88.34&93.04&0.0117&90.30&88.65&93.05&0.0096\\
%  InvDistCorr &20.0 &89.66&86.90&92.10&0.0101&89.69&87.35&92.02&0.0083\\
%  InvDistCorr &50.0 &88.41&84.03&89.28&0.0093&87.97&84.55&89.15&0.0075\\
 \bottomrule
\end{tabular}
}
\end{small}
\end{center}
\end{table*}

% \newpage
% \subsection{Attack performance for attacks with training data.}

%  Results for Trian-ME and SoftTrain-ME with stable/unstable gradient query are shown separately in Table.~\ref{tab:train_vgg11_cifar10}, Table.~\ref{tab:softtrain_vgg11_cifar10_ideal} and Table.~\ref{tab:softtrain_vgg11_cifar10_practical}. We can observe that if gradient query is stable, SoftTrain-ME only has better accuracy and fidelity at large $N$ (greater than 6). For unstable gradient query case, SoftTrain-ME performs much worse than Train-ME.

\subsection{Extraction Performance under Non-IID data distribution}
\label{apx:noniid}

We demonstrate the  ME attack performance in a Non-IID setting, where the attacker only has access to training data from a subset of classes ($C$).
The new set of results corresponding to Train-ME attack are shown in Table~\ref{tab:noniid_brief}. We observe for $C$ smaller than 5, attacker performance degrades badly for both CIFAR-10 and CIFAR-100 datasets.

\begin{table}[htbp]
\caption{Under Non-IID data distribution, model extraction performance of Train-ME attack on VGG-11 model on CIFAR-10 and CIFAR-100 dataset with Original Accuracy of 91.89\% and 68.64\%, respectively.}
\label{tab:noniid_brief}
\begin{center}
\begin{small}
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{lcccccc} 
 \toprule
 \multirow{2}{*}{Method} & \multicolumn{3}{c}{\textbf{CIFAR-10 Accuracy}} & \multicolumn{3}{c}{\textbf{CIFAR-100 Accuracy}}\\
  &N=2 &N=5 &N=8 &N=2 &N=5 &N=8\\
 \midrule
  C = 1  &47.58	&46.75	&38.42	&6.79	&6.79	&6.13\\
  C = 2  &82.45	&79.30	&58.69	&13.18	&13.36	&11.25\\
  C = 5  &91.70	&88.90	&65.70	&32.77	&29.65	&17.90\\
 \bottomrule
\end{tabular}
}
\end{small}
\end{center}
\end{table}


\subsection{Adversarial Attack Performance}
\label{apx:adversarial}
We demonstrate that with proper model IP protection, adversarial attacks can be mitigated. We assume the attacker uses the strongest Train-ME attack (with 1K data) to obtain a high-fidelity surrogate model to perform transfer adversarial attacks on the victim model with different IP protection strengths (SFL with different $N$). We use FGSM \cite{goodfellow2014explaining}, and targeted-PGD attack \cite{madry2017towards} to perform the transfer adversarial attack. We set the $e$ for FGSM at 0.1, and PGD-target at 0.002 for 50 iterations (the attacker randomly chooses the original and target label). We report the average Attack Success Rate (ASR) - the percentage of samples that are transferred successfully - to show the attacking performance. The new set of results is shown in Table~\ref{tab:advattack_brief}. We see that both adversarial attacks achieve very high ASR for small $N$, where model IP protection is weak. On a SFL scheme with large $N$, adversarial attack performance degrades significantly using the surrogate model with less fidelity.

\begin{table}[htbp]
\caption{Adversarial Attack ASR performance based on the surrogate model obtained using Train-ME attack, on VGG-11 model on CIFAR-10 with different $N$ setting.}
\label{tab:advattack_brief}
\begin{center}
\begin{small}
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{lccccccc} 
 \toprule
 \multirow{2}{*}{Attack} & \multicolumn{7}{c}{Number of Server-side Layer ($N$)}\\
  &N=2 &N=3 &N=4 &N=5 &N=6 &N=7 &N=8\\
 \midrule
  FGSM  &82.7	&82.3	&77.9	&77.3	&63.1	&56.9 &37.7\\
%   PGD  &82.1	&82.1	&79.6	&81.5	&73.4	&83.7 &89.8\\
  PGD-target& 100	&100	&99.8	&100	&99.5	&73.4 &34.2\\
 \bottomrule
\end{tabular}
}
\end{small}
\end{center}
\end{table}

\subsection{Surrogate Architecture Performance}
\label{apx:diff_arch}

To investigate the impact on model extraction attacks caused by the surrogate model's architecture difference, we designed four variants of the true server-side model, and used them as surrogate model architecture to perform model extraction attacks. We fixed the settings to  $N = 5$ SFL and  consistent gradient query budget to 10K. The new set of results are shown in Table~\ref{tab:diff_surrogate_arch} for VGG-11 model on CIFAR-10 dataset.
For most attacks, architecture does not make a huge difference, and longer or wider surrogate architecture can achieve even better accuracy and fidelity. The exception is GM-ME, which achieves much higher extraction performance with the surrogate model having the same architecture.

\textbf{Longer Architecture.}
Surrogate model has one extra fully connected layer compared to the original true server-side model.

\textbf{Shorter Architecture.}
Surrogate model has one less fully connected layer compared to the original true server-side model.

\textbf{Wider Architecture.}
Surrogate model has channel size that is 2 times of the original true server-side model

\textbf{Thinner Architecture.}
Surrogate model has channel size half of the original channel size of the true server-side model.

\begin{table*}[htbp]
\caption{Extraction attack performance on surrogate models having slightly different architectures from the true architecture of the server-side model. $N$ is fixed at 5, gradients are consistent and the query budget is 10K.}
\label{tab:diff_surrogate_arch}
\begin{center}
\begin{small}
\resizebox{0.9\linewidth}{!}{
\begin{tabular}{lccccc|ccccc} 
 \toprule
 \multirow{2}{*}{Attacks} & \multicolumn{5}{c}{\textbf{Accuracy (\%)}} & \multicolumn{5}{c}{\textbf{Fidelity (\%)}}\\
 &same &longer &shorter &wider &thinner &same &longer &shorter &wider &thinner\\
 \midrule
 Craft-ME &76.67 &75.05 &77.90	&79.00	&74.86	&78.38 &76.70	&79.72	&81.04 &74.74\\
 GAN-ME&80.57 &75.95   &76.66	&74.27	&65.69	&82.66 &78.13	&78.54	&76.11 &67.58\\
 GM-ME&65.77 &11.41    &18.04	&14.77	&14.42	&69.60 &11.22	&18.61	&14.90 &14.35\\
 Train-ME& 90.82 &90.33    &90.76	&90.72	&90.10	&94.84 &94.47	&94.84	&94.79 &93.94\\
 SoftTrain-ME&90.57&90.43   &90.66	&90.62	&90.10	&94.76 &94.62	&94.84	&94.59 &94.13\\
 \bottomrule
\end{tabular}
}
\end{small}
\end{center}
\end{table*}


\begin{table*}[htbp]
\caption{Model extraction performance of gradient-based ME attacks with consistent gradient query (100K query budget) and inconsistent gradient query for 10-client SFL on \textbf{VGG-11 model CIFAR-100 dataset}. Original Accuracy is 68.64\%. We use 20 crafting steps for the Craft-ME for both cases. For the inconsistent case, we launch ME attack at epoch 160, and use the ``late10'' setting for GM-ME.}
\label{tab:other_vgg11_cifar100}
\begin{center}
\begin{small}
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{clcccc|cccc} 
 \toprule
 \multirow{2}{*}{Case} & \multirow{2}{*}{Method} & \multicolumn{4}{c}{\textbf{Accuracy (\%)}} & \multicolumn{4}{c}{\textbf{Fidelity (\%)}}\\
  & &N=2 &N=3 &N=4 &N=5 &N=2 &N=3 &N=4 &N=5\\
 \midrule
  \multirow{3}{*}{\makecell{Fine-tuning}} &Craft-ME &66.44	&64.68	&35.37	&15.4	&86.97	&81.37	&40.35	&16.7\\
  &GAN-ME   &56.54	&46.53	&13.11	&6.69	&69.91	&55.56	&14.86	&7.11\\
  &GM-ME    &68.76	&68.4	&57.87	&1.28	&99.11	&94.46	&71.5	&1.26\\
 \midrule
  \multirow{3}{*}{\makecell{Train-from-scratch}} &Craft-ME &11.53	&8.49	&2.61	&2.41	&13.67	&10.15	&2.71	&2.45\\
  &GAN-ME   &49.4	&41.9	&22.1	&10.75	&60.04	&49.29	&25.46	&12.55\\
  &GM-ME    &4.05	&1.47	&1.37	&1.23	&4.92	&1.79	&1.54	&1.19\\
 \bottomrule
\end{tabular}
}
\end{small}
\end{center}
\end{table*}


\begin{table*}[htbp]
\caption{Model extraction performance of gradient-based ME attacks with consistent gradient query (100K query budget) on \textbf{VGG-11 model FEMNIST dataset}. Original Accuracy is 74.62\%. We use 50 crafting steps for the Craft-ME for both cases.}
\label{tab:other_vgg11_femnist}
\begin{center}
\begin{small}
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{clcccc|cccc} 
 \toprule
 \multirow{2}{*}{Case} & \multirow{2}{*}{Method} & \multicolumn{4}{c}{\textbf{Accuracy (\%)}} & \multicolumn{4}{c}{\textbf{Fidelity (\%)}}\\
  & &N=2 &N=3 &N=4 &N=5 &N=2 &N=3 &N=4 &N=5\\
 \midrule
  \multirow{5}{*}{\makecell{Fine-tuning}} &Craft-ME &53.20	&43.57	&43.04	&40.50	&59.28	&48.10	&46.58	&42.11\\
  &GAN-ME   &10.59	&7.19	&5.27	&4.02	&11.39	&7.35	&5.20	&3.80\\
  &GM-ME    &56.67	&22.53	&9.87	&3.78	&69.70	&25.14	&10.10	&3.68\\
  &Train-ME   &70.32 &68.47   &68.80  &67.70	&82.56	&77.52	&75.61	&71.97\\
  &SoftTrain-ME    &75.70	&74.93	&74.42	&74.46	&83.87	&81.24	&77.39	&76.30\\
%  \midrule
%   \multirow{3}{*}{\makecell{Train-from-scratch}} &Craft-ME &78.55	&63.04	&61.77	&58.76	&80.8	&64.87	&63.35	&60.07\\
%   &GAN-ME   &77.08	&38.2	&35.08	&32.49	&79.43	&38.87	&35.6	&33.11\\
%   &GM-ME    &31.23	&11.25	&15.25	&17.81	&32.73	&11.46	&15.14	&17.9\\
 \bottomrule
\end{tabular}
}
\end{small}
\end{center}
\end{table*}


\begin{table*}[htbp]
\caption{Model extraction performance of gradient-based ME attacks with consistent gradient query (100K query budget) and inconsistent gradient query for 10-client SFL on \textbf{MobilenetV2 model CIFAR-10 dataset}. Original Accuracy is 93.82\%. We use 20 crafting steps for the Craft-ME for both cases. For the inconsistent case, we launch ME attack at epoch 160, and use the ``late10'' setting for GM-ME.}
\label{tab:other_mob_cifar10}
\begin{center}
\begin{small}
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{clcccc|cccc} 
 \toprule
 \multirow{2}{*}{Case} & \multirow{2}{*}{Method} & \multicolumn{4}{c}{\textbf{Accuracy (\%)}} & \multicolumn{4}{c}{\textbf{Fidelity (\%)}}\\
  & &N=2 &N=3 &N=4 &N=5 &N=2 &N=3 &N=4 &N=5\\
 \midrule
  \multirow{3}{*}{\makecell{Fine-tuning}} &Craft-ME &92.29	&76.74	&72.74	&61.08	&96.04	&77.86	&73.24	&61.46\\
  &GAN-ME   &92.67	&79.17	&68.92	&57.61	&96.46	&80.35	&69.7	&58.25\\
  &GM-ME    &93.2	&92.82	&92.39	&91.86	&97.83	&96.87	&95.74	&94.74\\
 
 \midrule
  \multirow{3}{*}{\makecell{Train-from-scratch}} &Craft-ME &78.55	&63.04	&61.77	&58.76	&80.8	&64.87	&63.35	&60.07\\
  &GAN-ME   &77.08	&38.2	&35.08	&32.49	&79.43	&38.87	&35.6	&33.11\\
  &GM-ME    &31.23	&11.25	&15.25	&17.81	&32.73	&11.46	&15.14	&17.9\\
 \bottomrule
\end{tabular}
}
\end{small}
\end{center}
\end{table*}


\subsection{Other Empirical Results}
\label{apx:other_empirical}
In this section, we present more empirical results for ME attacks without training data to show that our claims can generalize to other architecture and datasets. The list of experiments are:

\begin{itemize}
    \item 1. ME attack performance (without training data only) of VGG-11 on CIFAR-100 (Table~\ref{tab:other_vgg11_cifar100}). An interesting observation is GAN-ME performs worse than Craft-ME for consistent gradient cases for the increasing number of classes (100) makes the generator even harder to converge. While for the inconsistent gradient case, GAN-ME performs much better than Craft-ME because its generator can adapt to the inconsistent gradients and Craft-ME cannot.
    \item 2. ME attack Performance (without training data only) of Vgg11 on 5\% subset of FEMNIST dataset (62-class), following the same setting as leaf benchmark \cite{caldas2018leaf}' online document (Table~\ref{tab:other_vgg11_femnist}). We observe a similar trend as in VGG-11 on CIFAR-10 experiments.
    \item 3. ME attack Performance (without training data only) of MobileNetV2 on CIFAR-10 (Table~\ref{tab:other_mob_cifar10}). We observe a similar trend as in VGG-11 on CIFAR-10 experiments.
\end{itemize}




\subsection{Time Cost Evaluation}

We evaluate time cost of five attacks on VGG-11 CIFAR-10 model (fine-tuning case).
%to provide a sense of how much time it takes to perform the attack. 
The time cost measurement is done on a PC with a R7-5800X CPU and a single RTX-3090 GPU.

\begin{table}[htbp]
\caption{Time costs of proposed five attacks of attacking VGG-11 on CIFAR-10 (N=8) in fine-tuning case.}
\label{tab:time_requirement}
\begin{center}
\begin{small}
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{lccccc} 
 \toprule
 Time Cost (s) & Craft &GAN &GM &Train &SoftTrain \\
 \midrule
  Preparation  &317.8	&44.5	&30.7	&4.7	&18.9\\
  Surrogate Training& 381.2	&339.3	&5523.1 &313.4	&949.5\\
  Total& 699.0	&383.8	&5553.8	&318.1	&968.4\\
 \bottomrule
\end{tabular}
}
\end{small}
\end{center}
\end{table}

\cref{tab:time_requirement} provides time cost breakdown for two phases, namely, preparation phase and training the surrogate model phase. The preparation phase includes crafting inputs in Craft-ME, fitting conditional GAN in GAN-ME, and crafting soft labels in SoftTrain-ME. From the results, we can see the Craft-ME needs the most preparation time and GAN-ME ranks the second. Both require generating crafted data and training the generator using collected gradients. For  training the surrogate model, GM-ME method requires the most time as solving the gradient matching involves  computation of second-order derivatives. Soft-Train method also spends more time compared to Craft-, GAN- and Train-ME because the soft-labels are used as the second objective.

In all the cases, the time cost of the proposed ME attacks is dominated by the cost of training the surrogate model. This heavily depends on the network topology, the number of iterations, and input size and vary from application to application, making it difficult to provide a comprehensive time complexity analysis.
%This is the main reason we do not provide a complete time complexity analysis.

\subsection{Conditional-GAN Architecture}
\label{sec:cgan}
The detailed architecture of the conditional-GAN for GAN-ME attack is shown in Fig.~\ref{fig:cgan_arch}.

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.8\linewidth]{cgan_arch.pdf}
\caption{Architecture detail of the c-GAN in GAN-ME.}
\vspace{-1.0em}
\label{fig:cgan_arch}
\end{figure*}

\newpage
\section{Model Inversion Attack Implementation}


\subsection{Model Inversion Attack Setting}
\label{apx:MI_attack}

The degree of how well client's data is protected in SFL is evaluated using Mean Squared Error (MSE) between ground-truth images and reconstructed images in Model Inversion Attack~(MIA). For MIA, we follow the same model-based attack methodology as in \cite{vepakomma2020nopeek, li2022ressfl}. 
The MIA flow is shown in Fig.~\ref{fig:MI_attack}. We assume the honest-but-curious attacker (this time, the server) has access to the 10K validation dataset of CIFAR-10. We use the L3 inversion model in \cite{li2022ressfl} to perform MIA, and use the trained L3 inversion model to reconstruct the raw image from the intermediate activation sent by benign clients.


\begin{figure*}[htbp]
\centering
\includegraphics[width=1.0\linewidth]{MI_attack.pdf}
\caption{Details of model inversion attack using L3 inversion model and the available validation dataset, done by an honest-but-curious server. (a) Train the inversion model on the validation dataset. (b) Use the inversion model to invert intermediate activation sent by clients.}
\vspace{-1.0em}
\label{fig:MI_attack}
\end{figure*}


