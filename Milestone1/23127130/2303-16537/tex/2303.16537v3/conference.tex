
\documentclass{article} % For LaTeX2e
\usepackage{conference}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{makecell}
\usepackage{inconsolata}
\usepackage{amsmath,bm,amssymb}
\usepackage{microtype}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{todonotes}
\usepackage{float}
\usepackage{comment}
\usepackage{nameref}
\usepackage{wrapfig}
\usepackage[most]{tcolorbox}
\usepackage{lipsum}
\usepackage{xcolor} 
\usepackage{caption}
\usepackage{pifont}
\usepackage{tikz}
\usepackage{multirow} 
\usepackage{wrapfig}
\usepackage{subcaption}




\definecolor{softGray}{HTML}{FFFFFF}
\definecolor{deepBlue}{HTML}{003366}
\definecolor{darkGray}{HTML}{333333}
\definecolor{highlightBackground}{HTML}{E0DBE8}
\newcommand{\highlight}[1]{\colorbox{highlightBackground}{#1}}

\newtcolorbox{stage1}{
    colback=softGray, % Soft Gray
    colframe=deepBlue, % Deep Blue
    coltext=darkGray, % Dark Gray
    % fonttitle=\bfseries,
    title=Instruction for Generating Explanation,
    fontupper=\fontsize{8pt}{1pt}\selectfont,
}

\definecolor{nb}{HTML}{006EB8}
\usepackage{hyperref}
\hypersetup{
  colorlinks   = true,    % Colours links instead of ugly boxes
  urlcolor     = nb,    % Colour for external hyperlinks
  linkcolor    = nb,    % Colour of internal links
  citecolor    = nb      % Colour of citations
}

\usepackage[ruled,lined,linesnumbered]{algorithm2e}
\newcommand{\methodname}{{\tt{LMExplainer}}}
\definecolor{lightgreen}{HTML}{D5DE56}
\definecolor{lightblue}{HTML}{D1E9EC}
\definecolor{black}{HTML}{000000}

\newcommand{\zc}[1]{{\color{black} #1}}


\title{LMExplainer: Grounding Knowledge and Explaining Language Models}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \colmfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.
\colmfinalcopy
\author{Zichen Chen \\
UC Santa Barbara\\
\texttt{\{zichen\_chen\}@ucsb.edu} \\
\And
Jianda Chen, Yuanyuan Chen, Han Yu \\
Nanyang Technological University \\
\texttt{\{jianda001,yuanyuan.chen,han.yu\}@ntu.edu.sg} \\
\And
Ambuj Singh, Misha Sra \\
UC Santa Barbara\\
\texttt{\{ambuj,sra\}@ucsb.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\colmfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}


Language models (LMs) like GPT-4 are important in AI applications, but their opaque decision-making process reduces user trust, especially in safety-critical areas.
We introduce \methodname{}, a novel knowledge-grounded explainer that clarifies the reasoning process of LMs through intuitive, human-understandable explanations. By leveraging a graph attention network (GAT) with a large-scale knowledge graph (KG), \methodname{} not only precisely narrows the reasoning space to focus on the most relevant knowledge but also grounds its reasoning in structured, verifiable knowledge to reduce hallucinations and enhance interpretability. 
% precisely narrows the reasoning space, focusing on the most relevant knowledge and explains how LMs arrive at their conclusions. 
\methodname{} effectively generates human-understandable explanations to enhance transparency and streamline the decision-making process. Additionally, by incorporating debugging into the  explanation, it offers expertise suggestions that improve LMs from a developmental perspective. 
Thus, \methodname{} stands as an enhancement in making LMs more accessible and understandable to users.
We evaluate \methodname{} on benchmark datasets such as CommonsenseQA and OpenBookQA, demonstrating that it outperforms most existing methods. By comparing the explanations generated by \methodname{} with those of other models, we show that our approach offers more comprehensive and clearer explanations of the reasoning process.
\methodname{} provides a deeper understanding of the inner workings of LMs, advancing towards more reliable, transparent, and equitable AI. 

\end{abstract}

\input{Main/intro}
\input{Main/related_work}
\input{Main/method}
\input{Main/eval}
\input{Main/conclusion}

\bibliography{conference}
\bibliographystyle{conference}

\newpage
\appendix
\input{Main/appendix}

\end{document}
