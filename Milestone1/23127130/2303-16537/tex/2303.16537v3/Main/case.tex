\begin{figure}[h!]
\centering
% \resizebox{0.95\textwidth}{!}{%
\begin{stage1}
\textbf{Basis:} Given a LM augmented with a graph attention network to extract key reasoning elements for decision-making. 
The task is \highlight{[TASK\_TYPE]}.

\textbf{Input:} The question is: \highlight{[$q$]}. The Answer Options are: \highlight{[$\mathcal{A}$]}

\textbf{Output:} The model predicted choice \highlight{[$y'$]}. Based on the Ranked Reason-elements: \highlight{[$\mathcal{Q}$]}

\textbf{Explanation (Stage 1):} 
Explain the LM's reasoning process for selecting \highlight{[$y'$]} over the other options. Provide concise explanations for why each reason-element supports \highlight{[$y'$]} as the predicted choice. Focus on the LM's behavior and the significance of the Ranked Reason-elements. Your response should be short and concise.

\textbf{Explanation (Stage 2):} Based on the \highlight{[$E_0$]}, explain why this LM makes the other options less likely \highlight{[$\mathcal{A}\setminus\{y'\}$]}. Your response should be short and concise.
\end{stage1}
% }
\caption{The instructions for explanation generators.}
\label{fig:instructions}
\end{figure}


