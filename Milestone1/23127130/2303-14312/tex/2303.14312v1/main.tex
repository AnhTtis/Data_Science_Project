\documentclass[lettersize,journal, 10pt]{IEEEtran}
% \documentclass[12pt, onecolumn, draftclsnofoot]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{amssymb}
\usepackage{array}
% \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage[dvipsnames]{xcolor}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Newly added, not sure whether could work %%%%%%%%
% \usepackage{caption}
\usepackage{subfigure}
% \usepackage{subcaption}
%%%%%% Newly added, not sure whether could work %%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{soul} % text manipulation
\usepackage[normalem]{ulem} %underlining
\definecolor{hgreen}{rgb}{0, 0.5, 0}%myGreen
\newcommand{\hazem}[1]{{\color{hgreen}[hazem: #1]}}
\usepackage{soul}

\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
% updated with editorial comments 8/9/2021

\begin{document}
\pagenumbering{arabic}
\title{GAN-RXA: A Practical Scalable Solution to Receiver-Agnostic Transmitter Fingerprinting}

\author{
Tianyi Zhao, %~\IEEEmembership{Student Member,~IEEE,}
Shamik Sarkar,~\IEEEmembership{Member,~IEEE,}
Enes Krijestorac, ~\IEEEmembership{Student Member,~IEEE,}
and Danijela Cabric, ~\IEEEmembership{Fellow,~IEEE}
        % <-this % stops a space
\thanks{This work was supported by SpectrumX, which is an NSF Spectrum
Innovation Center funded via Award 2132700.}% <-this % stops a space
\thanks{The authors are with the Electrical and Computer Engineering Department,
University of California at Los Angeles, Los Angeles, CA 90095 USA (e-mail:
zhaotianyi@ucla.edu; shamiksarkar@g.ucla.edu; enesk@ucla.edu;  danijela@ee.ucla.edu).}}

% The paper headers
% \markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2021}%
% {Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}

% \IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

\begin{abstract}
Radio frequency
% (RF)
fingerprinting
% based on deep learning algorithms
has been proposed for device identification. % and identification.
% Many prior works have shown the potential of RF fingerprinting in such tasks.
However, experimental studies also demonstrated its sensitivity to %changes in the setup and environment. 
deployment changes.
Recent works have addressed channel impacts by developing robust algorithms accounting for time and location variability,
%addressed the impacts of wireless channel variation and developed robust algorithms to account for time and location variability,
but the impacts of receiver impairments on transmitter fingerprints are yet to be solved.
%but they neglected the impact of receiver impairments on the transmitter fingerprints. 
In this work, we investigat the
% practical 
receiver-agnostic transmitter fingerprinting problem, and propose a novel two-stage supervised learning framework (RXA) to address it. In the first stage, our approach calibrates a receiver-agnostic transmitter feature-extractor.
%using a large number of transceivers.
We also propose two deep-learning approaches (SD-RXA and GAN-RXA) in this first stage to improve the receiver-agnostic property of the RXA framework. In the second stage, the calibrated feature-extractor is utilized to train a transmitter classifier with only one receiver.
%train a classifier on a set of unseen transmitters with only one receiver.
We evaluate the proposed approaches on transmitter identification problem using a large-scale WiFi dataset. We show that when a trained transmitter-classifier is deployed on new receivers, the RXA framework can improve the classification accuracy by $19.5\%$, and the outlier detection rate by $10.0\%$ compared to a naive approach without calibration.
% We showed that compared to a naive approach without calibration, the proposed framework (RXA) can improve the closed-set classification accuracy by $45.1\%$, and the open-set outlier detection rate by $26.7\%$ when a trained transmitter-classifier is deployed on receivers not used in training.
Moreover, GAN-RXA can further increase the closed-set classification accuracy by $5.0\%$, and the
%open-set
outlier detection rate by $7.5\%$ compared to the RXA approach.
\end{abstract}

\begin{IEEEkeywords}
Receiver-Agnostic RF Fingerprinting, Deep Learning, Transmitter Identification, Open-Set Recognition, Generative Adversarial Network
\end{IEEEkeywords}

\section{Introduction}
\subsection{Motivation}
%  \hazem{I would call it Motivation}
%Wireless communication is important and indispensable in modern society. 
In wireless communication, a transmitter encodes its messages into electrical signals, converts them to electromagnetic signals (commonly radio frequency signals), and transmits over the air. The receiver captures the radio frequency (RF) signals, performs the same operations as the transmitter in reverse order, and extracts the original message. In this process, the RF signals are distorted due to the wireless channel and transceiver hardware imperfections. In other words, transmitters, channels, and receivers can implant their fingerprints in RF signals. 
Hence, these fingerprints are commonly known as `RF fingerprints.'
While these RF fingerprints are unintentionally embedded in the signals, they can also reveal additional information about the transceivers or the environment. 
%The goal of \emph{RF fingerprinting} is to utilize the RF fingerprints to leverage the additionally embedded information.
The goal of \emph{RF fingerprinting} is to extract the RF fingerprints 
%in order to 
and leverage the additionally embedded information for different applications.

Prior works have demonstrated the viability of leveraging RF fingerprints for a variety of applications \cite{p20}. For example, channel induced fingerprints can be utilized for applications such as localization \cite{p53}, channel prediction \cite{p14}, and radio map reconstruction \cite{p27}. In another direction, researchers have exploited transmitter fingerprints to perform device identification \cite{p54, p15, p17, p29, p33, p36, p47, p51, p1},
% \cite{p7, p13, p21, p28, p34, p37, p38, p50, p39}
which is also our focus in this paper. Transmitter fingerprints typically come from radio hardware impairments as a result of manufacturing nuances and are inevitable due to non-ideal physical components. Consequently, each transmitter has its own unique fingerprints. The idea of wireless device identification 
%or specific emitter identification (SEI) 
using 
%RF fingerprinting
transmitter fingerprints, which is a physical layer authentication (PLA) technique, 
has 
%advantages due to robustness 
the advantage of being robust against spoofing attacks \cite{p29} while saving computational overheads \cite{p30}.

Device identification using transmitter fingerprints, which we call \emph{transmitter fingerprinting}, can be performed in two different settings: closed-set and open-set.
% A closed-set problem is to classify among a known set of transmitters based on a captured RF signal, whereas an open-set problem has to recognize whether the RF signal originates from a known or unknown transmitter. 
In a closed-set setting, the problem is to identify a transmitter among a known set of transmitters based on the captured RF signals.
On the other hand, in an open-set setting, the additional problem is to identify whether the captured RF signal originates from a known or unknown transmitter.
% In both settings, the device identification problem is a classification task based on transmitter features, which capture the unique fingerprints of the transmitters. These features are either explicitly or implicitly extracted from the received RF signals.
In both settings, the 
%device 
transmitter fingerprinting problem can be framed as a classification task.
The classification must be done based on features that accurately capture the unique fingerprints of the transmitters.
These features are either explicitly or implicitly extracted from the received RF signals.
Thus, reliable classification requires robust transmitter feature extraction.

As RF signals also suffer from channel and receiver fingerprints, it is reasonable to consider their impacts on the extracted transmitter features. In fact, transmitter fingerprinting is sensitive to deployment variability as a result of variable channels and different receivers.
These
%, and the 
variations can lead to significant degradation in the transmitter-classification performance \cite{p10, p11, p26, p22, p31}. Recent studies have proposed channel-agnostic transmitter fingerprinting \cite{p5} \cite{p12}, and these techniques have demonstrated the ability to suppress channel fingerprints. However, in the context of transmitter fingerprinting, the problem of suppressing receiver fingerprints has not been sufficiently investigated. This is a crucial problem as receivers are often replaced due to malfunctioning or upgrades, and different receivers will have distinct receiver fingerprints. Thus, to make transmitter fingerprinting practical, it is necessary to provide receiver-agnostic solutions for transmitter fingerprinting. 

Some existing works address the receiver-agnostic transmitter fingerprinting problem partially in \cite{p47}, \cite{p19}, and \cite{p46}. For example, the approach in \cite{p46} requires extensive signal collection in the training stage for every new deployment. Similarly, the approach in \cite{p19} requires additional training in the testing stage. 
%Moreover, 
The approach in \cite{p47} requires the collaboration of multiple receivers in the testing stage. In contrast, in this work, we 
%will 
address the receiver-agnostic transmitter fingerprinting problem with a more practical and scalable deep learning approach. Specifically, our approach only
requires minimal signal collection on only one receiver for training in each new deployment (we call this attribute of our solution \emph{practical}), and accurate transmitter fingerprinting can be done on a new receiver without any additional retraining or tuning (we call this attribute of our solution \emph{scalable}).

% \hazem{repetitive}

% Many works have established a variety of techniques to demonstrate the viability of RF fingerprinting \cite{p2} \cite{p3} \cite{p29} \cite{p13} \hazem{This is very vague. Maybe specify in which context/applications}. However, the signal used for authentication based on transmitter RF fingerprints is also affected by wireless channel and receiver imperfections. Similar to transmitter RF fingerprints, receivers also suffer from manufacturing variability. 

% Due to such receiver variations or fingerprints, transferring a well-trained transmitter-classifier to an unseen receiver can be problematic and also lead to significant degradation in classification accuracy \cite{p4}. To address this issue, a naive solution is to increase the number of receivers in the training set. However, using a large number of training receivers can be expensive or impractical, because it requires a re-collection of a large-scale training data every time when a new set of targeted transmitters are introduced. As a result, although this naive solution can alleviate the performance degradation problem, it is not scalable in realistic scenarios. Therefore, it is necessary to investigate the RF fingerprinting problem considering the effects of receivers together with the metrics to evaluate the possible solutions. \hazem{I got lost reading this paragraph. You start with the need for RF fingerprints, then you go to the different factors that affects RF fingerprints, then you talk about training and scalability. Try to set a virtual title to each paragraph. It will make it easier to keep paragraphs focused.}
% a form of signal intelligence \hazem{what is signal intelligence?} that utilizes the hardware intrinsic characteristics \hazem{RF fingerprints are also influenced by the channel. You make it sound like it’s only about hardware} of the transmitters which are unintentionally embedded in the transmitted waveform \cite{p20}. The applications of RF fingerprinting include but are not limited to device localization, detection, and also identification and authentication \hazem{I would add REFs}.
% While wireless device authentication can happen at different layers \hazem{such as?}, it is typically implemented using software. However, identifiers such as MAC addresses are easy to spoof, and cryptography based algorithms have high computational overheads, which make them not suitable for low cost, power constrained hardware such as the Internet of Things (IoT) devices. Radio frequency (RF) fingerprinting utilizes the hardware intrinsic characteristics of the transmitters which are unintentionally embedded in the transmitted waveform \cite{p20}. The transmitter patterns which lead to RF fingerprints exist due to variability in manufacturing of transmitter components, such as power amplifiers. The authentication with RF fingerprinting is passive Physical Layer Authentication (PLA), which relies on the receiver processing of captured RF signals from the transmitter and does not require any additional signaling or protocol overhead \cite{p1}. 

%The market of IoT is rapidly spreading, reaching a multitude of different domains, including personal health care, environmental monitoring, home automation, smart mobility, and Industry 4.0 \cite{p30}. Therefore, with this fast-growth of the IoT market, 

%RF fingerprinting due to its applicability to any wireless transmitting device and robustness to adversarial attacks becomes practical and promising solution for IoT applications \cite{p30}. 
% \hazem{The flow of the paragraph is very hard to follow. You start from a specific point (RF fingerprint) and then go to a general topic (IoT). I would propose to start from the problem in IoT and then narrow it do to the need for RF fingerprints.}



%RF fingerprinting can be applied in many IoT applications, such as where a receiver needs to classify among the transmitters: smart city, smart agriculture, smart home, etc \hazem{I don't understand why did you mention smart city, etc? Are these applications? Also, it's repetitive, as you have already motivated why RF fingerprints are useful in the first paragraph.}. 


%While these nuances are undesirable and can distort generated RF signals, researchers find they can also embed additional information in the signals. Many works have addressed the potential problems of RF fingerprinting. \cite{p20} discusses many different applications of it: RF device identification and authentication, localization, tracking, navigation, intrusion detection, etc. The scalability of While RF fingerprinting can be applied towards these many scenarios, in this work, we focus on the classification problem of device identification and authentication \hazem{double check this sentence}. \hazem{This para better presented at the end of the motivation or first subsection in the intro. It's not really about related work!}
% In the meanwhile, to maximize the utilization of handcrafted features, some works also take advantages of the hardware nuances and manually inject features into the devices \cite{p21} \cite{p35}.
% Need to explain the authentication is a classification problem, and the classification uses either RF signals directly or some features.


% Many works have focused on the extraction of transmitter-features, or the channel impacts,  but a very few have addressed the receivers effects. In fact, receivers also have their own hardware nuances due to manufacturing variability, and thus impose their fingerprints on the received RF signals as well. Studies have shown Moreover, receivers can have much more complicated reasons for the impairments than transmitters. Due to the complexity in reasoning and handling receiver distortions, while receivers can contribute a lot to the RF signal distortions, this receiver problem is insufficiently investigated in the RF fingerprinting field.

% Furthermore, while the prior works tackled the receiver distortion problem of RF fingerprinting tasks, they did not formulate an explicit task. In our work, we establish a specific problem regarding the receiver-agnostic fingerprinting problem, which discusses its practicality, difficulty and also metrics describe the quality of a possible solution. 

% define closed-set and openset problems

% As many works have addressed, a transmitter fingerprint typically comes from the unique hardware impairments in each specific device. Due to the hardware nuances, each transmitter can distort its generated RF signals in a subtle but unique way. The observation and retrieval of the unique transmitter-specific patterns from the RF signals are of great research interests. However, just like transmitters, receivers also have hardware manufacturing imperfections. Such receiver imperfections can also distort received RF signals as well as the embedded transmitter fingerprints. Furthermore, since RF signals are transmitted over the air before being received, the transmitter fingerprints can also suffer distortions due to the wireless channel and interference. In other words, the unique patterns of the transmitter fingerprints embedded in the RF signals can be easily distorted before any identification or pattern-recognition specific processing \hazem{all previous in Repetitive from the intro!}.

% The motivation for our RATF problem formulation is subtle but crucial. In reality, collecting signals in a field can be time-consuming and expensive. Therefore, we want to utilize the minimum necessary amount of signals to build an effective authenticator for each new field. In other words, the developing process of the authenticator needs to be scalable in each new field. Besides, once an authenticator is developed and deployed in a specific field, it is common to introduce new receivers into the same field and perform the authentication task on the same set of transmitters $\{\mathcal{T}_i\}$ as shown in Figure \ref{field}. For example, a possible scenario is when the original running receiver becomes defective and needs to be replaced. In this case, we do not want to stop the running service and collect new training data for a new receiver. At the same time, as mentioned above, a new receiver can has its unique fingerprints and thus distort the transmitter fingerprints severely. Therefore, we want to make sure each authenticator can be easily transferred to a new receiver while maintaining the capability to perform the original authentication task. In other words, the developed authenticator needs to be easily deployable. \hazem{This is more about the motivation of the work. And again it's something that can be introduced in the intro.} 
% \hazem{I finished the section and didn't see any concrete formulation. I feel the section is more of a System model rather than a formulation. If you mean equation (1) then be careful since you mentioned that the formulation is one of the contributions of the paper..}

\subsection{Related Work}
% , and then perform classification with statistical or machine learning methods such as likelihood ratio test or support vector machine (SVM)
As discussed in the previous section, transmitter fingerprinting involves two steps, transmitter feature extraction and classification. Traditional approaches focus on the design of handcrafted features for transmitters and then perform the classification using statistical methods such as the likelihood ratio test. Additionally, in recent years, deep learning has been widely applied in transmitter fingerprinting and its efficacy has been demonstrated in both feature extraction and classification tasks.

\subsubsection{Handcrafted Feature Extraction Approaches}
% Handcrafted features usually use models of transmitter impairments. The physical components in the circuits contributing to the fingerprints are analyzed to extract features. 
These approaches rely on models of transmitter impairments and analyze the physical components in the circuits contributing to the transmitter fingerprints for extracting features. 
For example, prior works have shown that transmitters can be identified by fingerprints due to power amplifiers (PAs) and mixers. The authors in \cite{p33} model the nonlinear characteristics in PAs with Volterra series representation and use it as the transmitter features.
% and then use the likelihood ratio test to perform classification.
The authors in \cite{p36} exploit the mixer imperfection and model the drifting oscillator offsets to use it as transmitter features.
% and use hypothesis testing to authenticate legitimate transmitters. 
% The authors in \cite{p50} exploit the non-linear memory effect
% mixers \cite{p36}, oscillators \cite{p34}, transients \cite{p37}, etc.
While individual physical components can provide their distinct fingerprints, it is natural to consider their collective contributions, which can form more comprehensive fingerprints for the different transmitters. Hence, more advanced feature representations for transmitter identification have been proposed to utilize the collective fingerprints better. For example, the authors in \cite{p17} present a Differential Constellation Trace Figure (DCTF) as the extracted features of a transmitter, which can retain IQ imbalance and carrier frequency offset (CFO). The authors in \cite{p51} present CepH, a feature representation exploiting the unintentional modulation of the pulse (UMOP) based on cepstrum analysis of the RF signals. As the feature representations become more complicated, the extraction of handcrafted features depends on a comprehensive analysis of the received signals. To deal with this challenge, deep learning approaches can be used as effective tools since they can save the efforts in handcrafted feature extraction and learn directly from the raw data without any 
%heavy-duty
complicated preprocessing.

\subsubsection{Deep Learning Approaches}
% In recent years, deep learning has demonstrated its effectiveness in many fields, such as computer vision and natural language processing. Inspired by its success in a variety of fields, recent researchers have started investigating the applications of deep learning in RF signal processing.
As deep learning typically has the capability of learning complicated models, it is hypothesized that deep learning can extract transmitter features without an explicit impairment model. Several works have demonstrated the validity of this hypothesis. At the same time, deep learning can also be applied in the classification stage when the extracted features are complicated. For example, Convolutional Neural Network (CNN) is applied in \cite{p15} and \cite{p54}, and the proposed model can directly extract features from IQ samples and classify the transmitters with minimal pre-processing. At the same time, CNN is also applied in \cite{p17} to classify the generated DCTFs and thus their corresponding transmitters.
% Besides, CNN is also applied in both \cite{p54} and \cite{p15}, and the proposed models are able to directly classify the transmitters from IQ samples with minimal pre-processing.
% For example, , and demonstrates its validity in the transmitter fingerprinting task.

% At the same time, deep learning can also be applied in the classification stage when the extracted features are complicated.


% For example, a complex-valued Variational Autoencoder with Gaussian Mixture prior (GMVAE) is presented in \cite{p7}, which extracts transmitter features with data-driven deep learning techniques.
% The authors in \cite{p15} presents Optimized Radio clAssification through ConvolutionaL neural nEtworks (ORACLE), an end-to-end CNN architecture that can directly classify the transmitters from IQ samples.
% \cite{p26} compares raw IQ data versus the frequency-domain data (result of fast-fourier transformation on the IQ data) as the input. Furthermore, since the IQ data are actually complex numbers, 

% , \cite{p23} considers different backbone architectures.
    % At the same time, while handcrafted features depend on comprehensive analysis of the received signals \hazem{You didn't mention this above!}, 
    % deep learning approaches can save the efforts and directly learn on the raw data without any heavy-duty pre-processing.
% Many works have shown the superiority of deep learning approaches in the RF fingerprinting problems \cite{p7} \cite{p15}. In the meanwhile, the input fed into the deep neural networks is also of research interests. 
% \cite{p26} compares raw IQ data versus the frequency-domain data (result of fast-fourier transformation on the IQ data) as the input. Furthermore, since the IQ data are actually complex numbers, \cite{p8} keeps the input in its original space and evaluates it with the aid of complex-valued CNN. Regarding the sequential nature of the RF signal, \cite{p23} considers different backbone architectures. Finally, some works also incorporate the handcrafted features, and fed those extracted yet still complicated features into the neural networks \cite{p17}.

%RF fingerprints typically come from radio impairments as a result of manufacturing nuances that are inevitable due to production imperfections \cite{p28}. Since these impairments appear in non-ideal physical components, it is hard to avoid their effects. A transmitter can have fingerprints due to imperfect amplifiers \cite{p33} \cite{p50}, mixers \cite{p36}, oscillators \cite{p34}, transients \cite{p37}, etc. \hazem{repetitive}


% In the RF device identification and authentication problem, the extraction of trustworthy transmitter-features plays an important role. In fact, many works have investigated various methods for the transmitter-feature extraction. The feature-extraction methods can be divided into two major types: handcrafted approaches and deep learning based approaches.
% \begin{enumerate}
%     \item
    % Hand-crafted feature extraction approaches:
    
    % As the device features usually come from unintentional variability during manufacturing, they are in general subtle and hard to model. Therefore, a lot of works focus on the handcrafted transmitter-features. The handcrafted features usually involve the exploitation of the hardware characteristics such as IQ imbalance \hazem{Is IQ imbalance a hardware characteristic? And where does it come from? Elaborate } and carrier frequency offset (CFO). Based on the straightforward yet naturally occurring characteristics, many works design advanced features, which can involve additional processing on the raw data, such as \cite{p41} \cite{p38} \cite{p39} \cite{p51}. All these works demonstrate the effectiveness and explanability of handcrafted-features. However, those features are heavily dependent on prior knowledge, and due to the complicated nature of the RF fingerprints, handcrafted features can also fail to capture some essential information. \hazem{I read this but still don’t understand how fingerprinting is done? You just explain how features are obtained }
    
    % \item
    % Deep learning approaches:
    
% \end{enumerate}
\subsubsection{Channel-Agnostic Transmitter Fingerprinting}
% While a simple transmitter fingerprinting task can be solved with deep learning, more challenges occur in realistic settings due to uncertainties.
% % For example, the transmitters may transmit in different bands with different protocols. The authors in \cite{p8} present RF-DCN, a Deep Complex-valued Neural Network (DCN) that operates on raw RF signals and is agnostic of the underlying applications and protocols.
% Substantial obstacles still exist due to the channel and receiver variations and fingerprints.
In realistic settings, the task of transmitter fingerprinting must overcome the challenges of channel variations and receiver fingerprints.
Studies have been conducted on channel-agnostic transmitter fingerprinting. The authors in \cite{p5} present ChaRRNets, a complex-valued CNN-based architecture for RF fingerprinting, which is robust to channel variations. ChaRRNets first applies Short Time Fourier Transform (STFT) on the signals and obtain spectra. Then, it sends the spectra into a channel-equivariant convolution layer followed by an invariant distance layer and obtains a channel-robust representation of the signals. Finally, it feeds the channel-robust representations into a 1-Dimensional (1D) real-valued CNN, which performs the classification. The authors in \cite{p12} also present a deep-learning based framework, together with a channel-independent spectrogram as the representation of received RF signals. The channel-independent spectrogram is generated by removing channel effect on STFT with the assumption that the channel remains constant within short time. Then, the spectrogram is fed into a CNN with triplet loss to obtain pairwise Euclidean distances. Finally, classification is completed by the K Nearest Neighbor (KNN) algorithm.

\subsubsection{Receiver-Agnostic Transmitter Fingerprinting}
As the channel fingerprints can be suppressed by the aforementioned techniques, the remaining problem is to address the receiver fingerprint, which has not been sufficiently investigated. Some works have studied the problem of receiver effects in the transmitter fingerprinting task. The authors in \cite{p19} propose to calibrate each receiver with a neural network-based transformation, to address the substantial classification performance degradation due to different receivers used for training and testing. This calibration method is efficient in classifier training, as it allows effective training with only a single receiver. However, each newly deployed receiver still needs to collect new signals and learn its own transformation function.
% and no retraining on a new receiver. However, the repeated signal collection is still required on each newly deployed receiver.
A crowdsourced measurement method is presented in \cite{p47}, which utilizes a collective set of receivers to identify transmitters during testing. This method also partially solves the receiver fingerprint problem, because it may not be applicable under scenarios where multiple receivers are not available during the testing stage. The authors in \cite{p46} propose an algorithm based on adversarial training to address the receiver fingerprint problem. This algorithm enables effective transmitter classification on newly deployed receivers without retraining. However, it still requires extensive signal collection on multiple receivers in each new deployment during the training stage. In summary, existing works each solve the receiver fingerprint problem partially, with practical limitations on either training or testing stages. In this paper, we propose to solve the problem in a practical and scalable manner. The proposed approach does not require extensive signal collection for training in each new deployment or retraining on any new receiver. 

% This algorithm allows free retraining on each new receiver deployed but still needs a collective of receivers Furthermore, while the prior works tackled the receiver distortion problem of RF fingerprinting tasks, they did not formulate an explicit task. In our work, we establish a specific problem regarding the receiver-agnostic fingerprinting problem, which discusses its practicality, difficulty and also metrics describe the quality of a possible solution. 
% The first method is using multiple receivers during training, and the second method is calibrating each receiver with a neural network based transformation. Moreover, \cite{p19} further emphasizes the second method over the first method because it does not require multiple receivers for training.
% , and presented effective solutions to suppress the receiver biases in some scenarios \cite{p19} \cite{p46} \cite{p47}. However, all of those approaches require repeated signal collection and calibration on each new receiver to deploy.
% Besides, \cite{p46} and \cite{p47} also require collaboration of multiple receivers at the inference stage, which causes the model hard to be scaled in various application scenarios.


% Extraction of transmitter RF fingerprints is not sufficient for robust device authentication, due to other impairments and variability in authentication using signals captured over the air \cite{p31} \cite{p26}. In \cite{p10} and \cite{p22} the impact of biases introduced by wireless channel is analyzed, and in \cite{p5} and \cite{p12} channel robust fingerprinting methods are devised.  %These works have extensively explored the channel-related RF fingerprinting problems and the techniques, therefore in this work we do not put an emphasis on the analysis on those factors such as channels.



%Besides \hazem{you used besides so many times}, while the identification usually refers to closed-set classification, the general authentication task can be more challenging, since it also involves the openset problem \cite{p1} \cite{p9}. In this work, we evaluate our solution in both usecases. \hazem{This has to be introduced earlier.} \hazem{The focus of the paper is kind of scattered all over the intro, which makes it very hard to follow what is the paper proposing. Try to introduce the focus of the paper in one paragraph in the intro.}

\subsection{Contributions}

% In this paper, we first formulate the receiver-agnostic transmitter fingerprinting (RATF) problem. We define the necessary metrics to evaluate any techniques addressing the receiver fingerprint problem. Then, we propose a novel deep learning based framework to address the problem. Finally, we evaluate our approach with extensive experiments on real signals captured over the air.
Our contributions can be summarized as follows:

\begin{itemize}
\item We formulate the receiver-agnostic transmitter-fingerprinting (RATF) problem, as to build a practically scalable transmitter-authenticator that can be easily deployed in new environments and easily transferred to different receivers. We stress that besides classification accuracy, the practicality and cost of scalability of the solution
% the cost of scalability and the transferrability
are the major concerns in realistic scenarios.
\item We propose a novel two-stage supervised learning framework (RXA) to address the aforementioned RATF problem. In the first stage, our approach calibrates a transmitter feature extractor, which is robust against receiver fingerprints, in a controlled environment. Then, in the second stage, this feature extractor is applied to a new receiver that aims to authenticate a set of unseen transmitters in a targeted field. We use a deep learning based classifier for the authentication, which can be applied in both closed-set and open-set scenarios. We claim that this two-stage framework is able to address the RATF problem in a practical and scalable manner.
% both the easy deployment problem and the scalability problem.
With this approach, only one receiver is required to collect training data from different transmitters in the second stage, and each new receiver is able to classify the targeted transmitters without any further signal collection or retraining. 
\item We develop two deep learning based approaches for the receiver agnostic transmitter feature extractor (SD-RXA and GAN-RXA) in the first learning stage. We design the loss functions and deep neural network architectures so that the feature extractors are able to distinguish among transmitters while being insensitive to receiver differences. We also discuss the trade-offs between our two proposed approaches.
% We show that the approaches can enhance the receiver-agnostic property of the calibrated transmitter feature-extractor.
% \hazem{Why did you propose two then? Which one should we use and when? What is the difference between these two approaches?} \hazem{Maybe better make one point for stage one and then another point to stage two.}
\item We evaluate our proposed approach with extensive experiments on WiSig, a large-scale WiFi dataset \cite{p4} captured over the air. We show that our proposed framework can improve both the closed-set and open-set problem performances. Specifically, our proposed approach can improve closed-set transmitter classification accuracy by $24.5\%$ and open-set transmitter outlier detection rate by $17.5\%$, compared to a naive approach without calibration, where a classifier trained on a single receiver is applied on another receiver.
\end{itemize}

The rest of the paper is organized as follows. Section \ref{pf} formulates the RATF problem. Section \ref{ap} explains the proposed approaches to solve the RATF problem. Section \ref{ds} discusses the dataset and the pre-processing of the data used in the experiments. Section \ref{ee} presents the experimental setup and results for the proposed approaches. Finally, section \ref{conclusion} concludes the paper.
% several benchmarks under multiple application scenarios. 

% \hazem{What happens in the second stage?}

% \hazem{In general the intro is very hard to follow. I miss a structure when reading it. Also you mainly focus on WHAT does the paper propose but not on WHY.}

\section{Problem Formulation} \label{pf}

In this section, we first discuss the RATF problem statement together with the essential %practical
concerns in solving it, and then we define the necessary metrics in evaluating a solution.

% As mentioned in the previous section, in the problem of transmitter fingerprinting, the channel and receiver distortions on the RF signals are non-negligible.

First, we consider the following model for received RF signals: assuming a perfectly generated signal $x$, the received signal $y$ is modeled as 

% Therefore, to effectively evaluate the transmitter patterns in the RF signals, we need to take all these confounding and comprehensive factors into account \hazem{elaborate. What factors?}. As a result, we consider the following received RF signal model: assuming a perfectly generated signal $x$, the received signal $y$ is modeled as
% \hazem{as} \sout{in Equation \eqref{signal_model}},
\begin{equation}
y=f_{R_j}(f_{H_c}(f_{T_i}(x)))
\label{signal_model}
\end{equation}
where $f_{T_i}$ represents the unique fingerprint of a transmitter $T_i$, $f_{H_c}$ represents the channel fingerprint of a random channel $H_c$, and $f_{R_j}$ represents the unique fingerprint of a receiver $R_j$.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{plots/field.png}
    \caption{A demonstration of a field, where a solid blue arrow represents the flow of RF signals, a solid green arrow represents the transfer of a build authenticator, and a dashed green arrow represents possible RF signal transmssions. In each field, the building process of an authenticator needs to be practical, and the transfer of a built authenticator across different receivers needs to be scalable.
    % In each field, the building process of an authenticator needs to be scalable, and a built authenticator needs to be transferable across different receivers.
    }
    % \hazem{What is $k$ and $j$? how is $X$ and $Y$ different from the ones in Equation (1)?}}
    \label{field}
\end{figure}

With the received RF signal model established, we now consider the formulation of the RATF problem. %First,
We refer to a deployment scenario as a field, as shown in Figure \ref{field}. In each field, we want to develop a deep learning based authenticator for a specific set of transmitters $\{\mathcal{T}_i\}$. To develop such an authenticator, we need to collect training RF signals $Y$ captured on a set of receivers $\{\mathcal{R}_j\}$. %Finally, 
When the authenticator is developed, it will be deployed on a set of receivers $\{\mathcal{R}_k\}$ different from $\{\mathcal{R}_j\}$.

From a practical perspective, the authenticator in a given field should be developed using a reasonable amount of training data and a viable training procedure. Furthermore, a developed authenticator should be scalably transferred to different receivers that were not used during the training procedure.
% To be more specific, $\{\mathcal{R}_j\} \cap \{\mathcal{R}_k\} = \varnothing$.
Finally, the transferred authenticator should work correctly and identify the transmitters with reasonable accuracy on the newly deployed receivers. To summarize, we formulate the RATF problem, which takes the following aspects into consideration:
% is to effectively build a practical authenticator while taking the following aspects into consideration.

\begin{enumerate}
    \item Performance:
    When a developed authenticator is transferred to a new receiver, its performance on the new receiver is always the first metric to consider. In the task of transmitter fingerprinting, the performance is evaluated by the classification accuracy in a closed-set scenario. In an open-set scenario, besides the classification accuracy, the outlier detection rate is also considered to evaluate the performance.
    \item Practicality:
    The process of developing an authenticator needs to be practical in each given field. Collecting signals from multiple receivers is expensive and impractical in the field. Therefore, minimizing the number of training receivers $\{\mathcal{R}_j\}$ is essential in building a pratical solution.
    \item Cost of scalability:
    % The process of developing an authenticator needs to be scalable in each given field. Collecting signals from multiple receivers is expensive and sometimes impractical in the field. Therefore, minimizing the number of training receivers $\{\mathcal{R}_j\}$ is essential in reducing the cost of scalability.
    % \item Transferability:
    % A developed authenticator needs to be transferrable across different receivers.
    As shown in Figure \ref{field}, an authenticator trained on signals collected on receiver set $\{\mathcal{R}_j\}$ will be transferred and deployed on a different set of receivers $\{\mathcal{R}_k\}$. To reduce the cost of scalability, a transferred authenticator should not require any additional retraining or tuning, while still being able to work correctly.
    % Moreover, the transferred authenticator should work correctly and identify the transmitters with reasonable accuracy. 
    % For each developed authenticator, we should be able to conveniently transfer and effectively deploy it on different receivers. As shown in Figure \ref{field}, an authenticator trained on signals collected on receiver set $\{\mathcal{R}_j\}$ can be directly transferred and deployed on a different set of receivers $\{\mathcal{R}_k\}$ without additional training or tuning. t to minimize $|\{\mathcal{R}_j\}|$. 
    % For each given field, we should be able to build an authenticator with minimal amount
    % % \hazem{What is reasonable? Maybe say minimize or quantify}
    % of training data and practically viable training procedure. As the bottleneck of data collection usually comes from increasing the number of receivers \cite{p4}, we want to minimize the number of training receivers in each field. As shown in Figure \ref{field}, we wan
\end{enumerate}

In this work, we consider the RATF problem in both closed-set and open-set scenarios. In both scenarios, we evaluate the performance of the approaches according the the above metrics. At the same time, we use only one receiver ($|\{\mathcal{R}_j\}|=1$) for field training, to enhance the practicality. Besides, an authenticator is directly applied on new receivers without further tuning
%, and the performance is evaluated 
to reduce the cost of scalability.
% In the closed-set case, we evaluate the performance by classification accuracy. In the open-set case, we evaluate the performance by both the outlier detection rate and the classification accuracy within the known transmitters.


% The motivation for the RATF problem formulation is subtle but crucial. In reality, collecting signals from different receivers can be time-consuming and expensive. Therefore, we 
% Therefore, we want to utilize the minimum necessary amount of signals to build an effective authenticator for each new field. In other words, the developing process of the authenticator needs to be scalable in each new field. Besides, once an authenticator is developed and deployed in a specific field, it is common to introduce new receivers into the same field and perform the authentication task on the same set of transmitters $\{\mathcal{T}_i\}$ as shown in Figure \ref{field}. For example, a possible scenario is when the original running receiver becomes defective and needs to be replaced. In this case, we do not want to stop the running service and collect new training data for a new receiver. At the same time, as mentioned above, a new receiver can has its unique fingerprints and thus distort the transmitter fingerprints severely. Therefore, we want to make sure each authenticator can be easily transferred to a new receiver while maintaining the capability to perform the original authentication task. In other words, the developed authenticator needs to be easily deployable. \hazem{This is more about the motivation of the work. And again it's something that can be introduced in the intro.} 
% \hazem{I finished the section and didn't see any concrete formulation. I feel the section is more of a System model rather than a formulation. If you mean equation (1) then be careful since you mentioned that the formulation is one of the contributions of the paper..}



% With the received RF signal model established, we can now consider the practical impairments in the RF fingerprinting. Although recognizing the transmitter fingerprints embedded in the RF signals is usually the ultimate goal, the inevitable distortions due to the channels and receivers are the major realistic obstacles. As the channels can be estimated with traditional signal processing techniques \cite{p52}
% % \hazem{REF}
% , and many other works \cite{p5} \cite{p12} \cite{p22} have extensively discussed the channel variation problems, we focus on the receivers' effects within the scope of this work \hazem{This is something that can be introduced in the intro. On why do we need receiver agnostic fingerprinting at all}.

% In this work, we mainly consider the transmitter authentication and identification problem \hazem{Did you mention the identification in the intro and the contribution?}. We define a deployment scenario as a field. In each field, receivers can collect RF signals from transmitters and then perform the authentication. We consider following two tasks:
% \begin{enumerate}
%     \item Closed-set identification: In this case, there exists a known set of transmitters in a given field. The task is to decide the source transmitter corresponding to the captured RF signal.
%     \item Open-set authentication: In this case, there exists a set of unknown (unseen) transmitters in addition to the known transmitters. The task is to first recognize whether the RF signal originates from known or unknown transmitters, and then for signals from the known transmitter set perform a closed-set identification.
% \end{enumerate}



% Without loss of generality, we refer to the deliverable deployed in the field as a (transmitter) authenticator \hazem{Is this authenticator just a set of receivers? or a centralized server? elaborate} in this work. From the practical perspective, the authenticator in a given field should be developed using a reasonable amount of training data and viable training procedure. Furthermore, a developed authenticator should be easily transferable to different receivers in a given field that have not been used during training procedure. To summarize, we formulate the RATF problem, which is to effectively build a practical authenticator while taking the following aspects into consideration, as shown in Figure \ref{field}:



%  The intuition of the RATF problem is non-trivial.


\section{Approach} \label{ap}

% The first training stage is effectively building a receiver-agnostic transmitter-feature-extractor, and the second stage is to train a simple transmitter-classifier based on the pre-trained feature-extractor. The concept is to go through the first training stage only once in the lab, and then for each set of transmitters to be deployed in the field, we are able to train a simple but functional classifier with limited data collected with any random receiver.

% We assume transmitters and receivers have asymmetric features and independent distributions. Therefore, we 

% While transceivers can also distort RF signals, channels and interference usually play the most import roles in the total impairments.
% Although the practical model is formed as in \eqref{signal_model}, the channel effects could be effectively estimated with traditional signal processing methods. Therefore, within the scope of this work, we assume the channel effects could be eliminated by channel estimation and recovery, before any deep learning methods are used in the fingerprint extraction process. Detailed discussion about the channel effects is presented in section \ref{dataset}.
% Due to practical restrictions, we want to build a deliverable which is portable and scalable. In other words, we want it to be easily deployed in different fields as well as easily applied to different receivers within one field, as shown in Figure .

% Deep learning here becomes the feasible tool for transmitter fingerprinting tasks, which originate from the manufacturing variability that are hard to model, because of its capability to learn complicated structures in signals. However, such a data-driven method usually requires a huge amount of training data, which is hard to acquire, and can be extremely vulnerable against biases in the training set, such as the receiver-specific distortions. Therefore, to accommodate the aforementioned challenges, we propose to develop a general feature extractor that extracts receiver-invariant features from a signal, so that it can:
% \begin{itemize}
%     \item Allow a transmitter classifier trained on one receiver to work on a new receiver without retraining, and
%     \item Decouple the problem into two phases, so that the training of classifier for deployment only needs small dataset.
% \end{itemize}
In this section, we first discuss the pre-processing of the received RF signals. Then, we propose our two-stage framework to solve the RATF problem. 
%Furthermore, 
We present two deep learning based approaches that can be applied in the first stage of our framework and can
%further 
improve the receiver-agnostic property of the calibrated feature extractor (FE). After that, we discuss the classifiers used in different scenarios. Finally, we provide details on the neural network architectures used in our approach.

\subsection{Pre-Processing} \label{preprocessing}
As modeled in Equation \eqref{signal_model}, an RF signal is impaired by three factors: the transmitter, the channel and the receiver. While this work focuses on removing receiver fingerprints in the transmitter fingerprinting problem, the effect of channel fingerprints cannot be ignored. Therefore, we need to account for the channel effects in the pre-processing step.

Given a received RF signal $y$, we first estimate the channel as $f_{H'}$, and then equalize the signals accordingly, as shown in Equation \eqref{estimate_model}.
\begin{equation}
\begin{split}
y' &= f_{H'^{-1}}(f_R(f_H(f_T(x)))) \\
   &= f_{R'}(f_T(x))
\end{split}
\label{estimate_model}
\end{equation}

% Due to the natural non-linearities in each step, the best way to recover the original signal $x$ is to define the effects in each step in the reverse order. However, 
% However, while transceivers usually minorly distort the RF signals, channels usually impair the signals significantly.

% To perform such channel equalization, we follow the procedure as in \cite{p4}, which is detailed as follows. First, we downsample a packet to change its sampling rate from 25 Msps to 20 Msps, which is the nominal sampling rate for WiFi, and apply autocorrelation on the L-STF to accurately detect a packet start. Then, we estimate the frequency offset and correct it accordingly. After that, we estimate and equalize the channel using minimum mean-square error (MMSE) on L-LTF. After this step, since the frequency offset can contribute to the fingerprints for both receivers and transmitters, we reapply it to the signal. Finally, we upsample the signals back to 25Msps. The signal processing for detection and channel estimation is applied using MATLAB R2019b WLAN toolbox with the default parameters.

% It can be observed that in Equation \eqref{estimate_model}, we do not follow the exact reverse order of the impairment components. We use equalized data for all experiments, as it has been shown to outperform unequalized data \cite{p4}. 
% The reason for 

It is shown in \cite{p4} that channel equalization can indeed significantly improve the transmitter fingerprinting performance. However, it is not a solution to receiver fingerprints, and different receivers for training and testing can still lead to a huge performance gap even in the presence of channel equalization, which is also shown in \cite{p4}. The reason for that may come from the different impairment models due to channel effects and receiver imperfections. The details of channel equalization steps are provided in Section \ref{ds}. We can safely equalize the signals since the technique is simple and only requires minimal amount of signal processing. It should be noted that we can perform channel equalization only on RF signals under certain protocols such as WiFi. For other protocols without training fields, such as Bluetooth, we can directly use raw IQ data without equalization, or refer to channel-agnostic fingerprinting techniques such as those mentioned in \cite{p5} and \cite{p12}.

\subsection{Two-Stage Framework: RXA} \label{3b}

After removing channel fingerprints in the pre-processing, we can consider the problem of receiver fingerprints. As shown in Equation \eqref{estimate_model}, we need to eliminate the receiver fingerprint $f_{R'}$ and estimate transmitter fingerprint $f_{T}$ from an equalized signal $y'$.
% want to learn the receiver fingerpritns from the  the actual receiver fingerprints from $y'$ with the estimation of $f_{R'}$.
% Since the design of transmitters and receivers are not exactly symmetric,their features are indeed asymmetric and able to be decoupled.
Therefore, we propose an approach that can extract the transmitter-specific features $f_T$ from $y'$, regardless of the effects due to $f_{R'}$. However, due to the practical limitation of the RATF problem as mentioned in Section \ref{pf}, it is infeasible to collect a large-scale dataset in each targeted field. Therefore, we want to do an apriori calibration for transmitter-specific feature extractors.

We propose a two-stage supervised learning framework as shown in Figure \ref{lab}. Our proposed framework aims to train receive-agnostic (RXA) transmitter classifiers and is composed of the following two stages:
\begin{enumerate}
\item \textbf{Receiver-Agnostic Feature-Extractor Calibration}:
As stated in the problem formulation in the previous section, a field has a limitation in the number of receivers available for collecting the training signals for developing a transmitter authenticator due to practical reasons. Therefore, inspired by transfer learning, we can instead pre-train a transmitter feature-extractor (FE) before developing a field-specific transmitter authenticator for any field. For pre-training, we can have less limitation on the number of transceivers, so that the FE can leverage multiple receivers for learning. In other words, in the first stage, we calibrate a transmitter FE that is agnostic to receiver fingerprints in a controlled environment, represented by the lab in Figure \ref{lab}. The FE $f_{tx}$ needs to be trained on a large dataset, which includes signals from a large number of transmitters $\mathcal{T}_{lab}$ and received on several receivers $\mathcal{R}_{lab}$. $f_{tx}$ is trained to extract transmitter-specific features that are not impacted by receiver fingerprints. Once the FE is calibrated, we can use it in any targeted field as explained next.
\item \textbf{Classifier Training}: With the help of the pre-trained FE, each field can train its own authenticator with limited training signals. The authenticator in a field is trained on signals collected on receivers $\mathcal{R}_{field}$ and transmitted by transmitters $\mathcal{T}_{field}$. $\mathcal{R}_{field}$ has a practical limitation in its size and $\mathcal{T}_{field}$ is the specific set of transmitters to authenticate. Therefore, $|\mathcal{R}_{field}|$ is typically much smaller than $|\mathcal{R}_{lab}|$, and $|\mathcal{T}_{field}|$ is limited by the actual size of authentication task.
Within the scope of this work, an authenticator performs a classification task with or without the functionality of rejecting outliers. Therefore, we refer to the authenticator specifically as a classifier in the rest of the paper. Since the calibrated FE is agnostic to receiver fingerprints, a trained classifier, once developed, can be deployed on any unseen receiver without additional training. While each field needs to train its own classifier, the receiver-agnostic FE calibrated in the previous stage is not field-specific and can be reused as many times as necessary.
\end{enumerate}

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{plots/lab.png}
    \caption{Demonstration of the two-stage learning process. The orange square shows Stage 1, feature-extractor (FE) calibration, which is performed on RF signals transmitted between transceivers $\mathcal{T}_{lab}$ and $\mathcal{R}_{lab}$. A calibrated feature-extractor (FE) is sent to each field, and each field can develop its own authenticator based on the transmitters to classify. A blue square shows Stage 2, classifier tuning, where each square represents a specific field. In each field, a classifier is developed based on both FE and RF signals collected on $\mathcal{R}_{field}$ and transmitted by $\mathcal{T}_{field}$. Finally, a trained classifier will be deployed on a different set of receivers $\mathcal{\Tilde{R}}_{field}$ to evaluate its performance.
    % \hazem{Can you show on the figure what is stage one and what is stage two?}
    }
    \label{lab}
\end{figure*}

As shown in Figure \ref{lab}, there are two different sets of transmitters and three different sets of receivers involved in the entire process, including both the training and deploying stages. In reality, the FE calibration stage is only performed once in the lab, and the calibrated FE can be sent to as many fields as needed. Therefore, it is natural to assume the transceivers deployed in fields are entirely different from the transceivers used in the lab. Hence, we consider the transceiver sets in different stages are mutually exclusive. In other words, we need to have $\mathcal{T}_{lab} \cap \mathcal{T}_{field} = \emptyset$, $\mathcal{R}_{lab} \cap \mathcal{R}_{field} = \emptyset$,  $\mathcal{R}_{field} \cap \mathcal{\Tilde{R}}_{field} = \emptyset$ and $\mathcal{R}_{lab} \cap \mathcal{\Tilde{R}}_{field} = \emptyset$.

In our proposed framework, we can see that the performance of a classifier depends on the quality of the FE, which is responsible for the receiver-agnostic property of the classifier. In particular, the design target of the FE is to obtain enough distinguishing capability among transmitters while being agnostic to the variances of receivers. Therefore, calibrating an effective FE in the first stage is essential, and the performance should be improved if we are able to enhance the receiver-agnostic property of the transmitter FE. In the following, we propose two approaches, which can be applied in the FE calibration stage to improve the receiver-agnostic property.

\subsection{SD-RXA}
Due to the asymmetry in receiver and transmitter features, it is natural to consider the receiver and transmitter feature distribution differences. Based on this intuition, we propose a statistical distance-based receiver-agnostic (SD-RXA) approach to improve the receiver-agnostic property in RXA. First, we assume the feature distributions of transmitters and receivers are uncorrelated. This assumption is based on the fact that receivers and transmitters have asymmetric features, and any signal capture should come from a random pair of transceivers. Based on this assumption, then, we extract the receiver features and transmitter features simultaneously for each captured RF signal. Finally, we optimize the FE so that the extracted receiver features and transmitter features tend to come from distributions with large statistical distance. The proposed architecture of SD-RXA is shown in Figure \ref{sd-RXA}.
% The intuition of the SD-RXA approach is to enlarge the statistical distance between these two distributions.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{plots/sd-RXA.png}
    \caption{The SD-RXA approach architecture. A solid arrow represents the direction of a forward pass, and a dashed arrow represents the correspondence between a loss function and its targeted network for update through backpropagation. After the training converges, all the gray blocks are discarded. Only the orange-colored transmitter FE will be kept after the calibration.}
    \label{sd-RXA}
\end{figure}

As shown in Figure \ref{sd-RXA}, the SD-RXA approach has two parallel branches to process a single batch of input simultaneously. Both branches have the same structure: an FE is concatenated with a classifier. The top branch in Figure \ref{sd-RXA} extracts receiver features and classifies between receivers $\mathcal{R}_{lab}$, and the bottom branch in Figure \ref{sd-RXA} extracts transmitter features and classifies between transmitters $\mathcal{T}_{lab}$. Each branch is optimizing its corresponding FE and classifier by a crossentropy loss as presented in Equations \eqref{ce_tx} and \eqref{ce_rx}, where $L_{rx}$ and $L_{tx}$ correspond to the losses of receiver-branch and transmitter-branch, respectively. The crossentropy losses are applied to ensure the FEs are extracting effective receiver and transmitter features.

\begin{equation}
L_{tx} = -\frac{1}{N} \sum_{i=1}^N \sum_{c=1}^{C_{tx}} y_{i, c}\log{\hat{y}_{i, c}}, 
\label{ce_tx}
\end{equation}

\begin{equation}
L_{rx} = -\frac{1}{N} \sum_{i=1}^N \sum_{c=1}^{C_{rx}} y_{i, c}\log{\hat{y}_{i, c}}, 
\label{ce_rx}
\end{equation}

where $N$ is the number of samples per mini-batch, $\hat{y}_{i, c}$ is the predicted probability for the $c$-th class of the $i$-th training signal in a mini-batch, and $y_{i, c}$ is the corresponding ground-truth label. $C_{tx}=|\{\mathcal{T}_{lab}\}|$ and $C_{rx}=|\{\mathcal{R}_{lab}\}|$ are the numbers of classes of transmitters and receivers, respectively.

Beyond the two classifiers, we want to then measure and maximize the distance between the distributions of receiver features and transmitter features. In a practical realization, we can obtain the corresponding distributions for mini-batches of signals during training. To maximize such distance, we add an additional distance loss $L_{dist}$, which is optimized only aiming to update the two FEs. $L_{dist}$ measures the statistical distance between the batch distributions of receiver features and transmitter features. We use the correlation coefficient as the metric $L_{dist}$ as shown in Equation \eqref{dist_loss}.
% While there are many statistical distance metrics, such as Wasserstein distance \cite{p55}, most of them can be computationally inefficient.
% Therefore, for the ease of computation, we choose the correlation coefficient as the metric $L_{dist}$ which can be expressed as \ref{dist_loss}.

\begin{equation}
L_{dist} = -\frac{1}{T^2}\sum_{t1=1}^T\sum_{t2=1}^T
||A_{tx, t1, t2} - A_{rx, t1, t2}||_2^2
\label{dist_loss}
\end{equation}
where $T$ is the length of a feature vector.

As shown in Equation \eqref{dist_loss}, $L_{dist}$ is the average element-wise $L_2$ distance between $A_{rx}^{T \times T}$ and $A_{tx}^{T \times T}$. $A_{rx}^{T \times T}$ and $A_{tx}^{T \times T}$ are the batch self-covariance matrices of the receiver features and transmitter features, respectively. For example, $A_{tx}$ is a $T \times T$ self-covariance matrix of transmitter features, and $A_{tx, t1, t2}$ corresponds to the entry at $t1-th$ row and $t2-th$ column in matrix $A_{tx}$. A single self-covariance matrix $A^{T \times T}$ for a receiver or transmitter is obtained as shown in Equation \eqref{A}.

\begin{equation}
A^{T \times T} = 
\begin{pmatrix}
cov_{h_1, h_1} & cov_{h_1, h_2} &\hdots & cov_{h_1, h_T}\\
cov_{h_2, h_1} & cov_{h_2, h_2} &\hdots & cov_{h_2, h_T}\\
\vdots & \vdots &\vdots &\vdots \\
cov_{h_T, h_1} & cov_{h_T, h_2} &\hdots & cov_{h_T, h_T}\\
\end{pmatrix},
\label{A}
\end{equation}
where $h=f(y)$ is a feature vector produced by its corresponding feature extractor.

Finally, the overall loss function of SD-RXA is the combination of the crossentropy losses and the distance losses described above, as presented in Equation \eqref{sd-loss}. It should be noted that while the two FEs are trained using the overall loss, $L_{dist}$ does not affect the two classifiers.

\begin{equation}
L_{SD-RXA} = L_{tx} + \alpha*L_{rx} + \beta*L_{dist}
\label{sd-loss}
\end{equation}
where $\alpha$ and $\beta$ are the hyperparameters 
%compensating 
for the weightings of the different losses. $L_{tx}$ and $L_{rx}$ are the crossentropy losses as shown in Equations \eqref{ce_tx} and \eqref{ce_rx}, and $L_{dist}$ is the distance loss as shown in Equation \eqref{dist_loss}.

After completing the training procedure, the transmitter FE $f_{tx}$ is fixed and will be sent to different fields for deployment.

\subsection{GAN-RXA}
While the SD-RXA approach can effectively take the receiver features into account, we also discovered the following challenges while experimenting with it. First, measuring and maximizing the statistical distance between the distributions of receiver features and transmitter features is nontrivial and even tricky in some cases \cite{p27}. It is nontrivial because it is hard to measure the exact similarity between the receiver and transmitter features. It is also hard to decide what is an appropriate distance between the two distributions. Therefore, there does not exist a global optimum value for the total loss.
% Furthermore, the selection of the hyperparameters $\alpha$ and $\beta$ in the loss function \eqref{sd-loss} is important, since a suboptimal selection may lead to trivial results or even divergence.
Finally, we cannot explicitly evaluate the effectiveness of the receiver-agnostic property of the transmitter FE during the training process. As a result, we want to improve beyond SD-RXA approach and thus propose the GAN-RXA approach. The GAN-RXA is inspired by GAN \cite{p42} and its structure is shown in Figure \ref{gan-RXA}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{plots/gan-RXA.png}
    \caption{The architecture of the GAN-RXA approach. A solid arrow represents the direction of a forward pass, and a dashed arrow represents the correspondence between a loss function and its targeted component for update through backpropagation. Only the orange-colored FE will be kept after the calibration.}
    \label{gan-RXA}
\end{figure}

As shown in Figure \ref{gan-RXA}, the proposed GAN-RXA approach consists of 3 major components: the transmitter FE $f_{tx}$, a transmitter classifier $c_{tx}$ and a ``discriminator" $d_{rx}$. During the training stage, $c_{tx}$ learns to classify between the transmitters in the set $\mathcal{T}_{lab}$, and $d_{rx}$ learns to classify between the receivers in the set $\mathcal{R}_{lab}$. GAN-RXA takes each received RF signal $y$ as input and passes it through the FE $f_{tx}$ to extract feature vectors $f_{tx}(y)$. Then the feature vectors are fed into classifier $c_{tx}$ and the discriminator $d_{rx}$. $c_{tx}$ and $d_{rx}$ output vectors of probabilities $P_{tx}$ and $P_{rx}$, respectively. Each entry in $P_{tx}$ or $P_{rx}$ corresponds to the predicted probability for that transmitter or receiver. The intuition of this model is such that $f_{tx}$ learns to extract transmitter features that can be correctly classified by $c_{tx}$, and at the same time, the features cannot be correctly distinguished by $d_{rx}$. In this manner, the FE learns to extract transmitter-specific features without receiver-specific patterns. The loss functions $L_{tx}$ and $L_{rx}$ are crossentropy losses as shown in Equations \eqref{ce_tx} and \eqref{ce_rx}, respectively. The crossentropy losses are minimized to update $c_{tx}$ and $d_{rx}$, as well as $f_{tx}$. An additional loss $L_{disc}$, as shown in Equation \eqref{disc_loss}, aims to remove the receiver-specific information embedded in the extracted transmitter-features $f_{tx}(Y)$, so that a well-trained discriminator fails to distinguish between receivers.

\begin{equation}
L_{disc} = \frac{1}{NC_{rx}} \sum_{i=1}^N \sum_{c=1}^{C_{rx}} \{\exp{[(\hat{y}_{i, c} - z_{i, c})^2]} - 1 \}
\label{disc_loss}
\end{equation}
where $N$ is the number of samples per mini-batch, $C_{rx} = |\mathcal{R}_{lab}|$ is the number of receivers in the lab, $\hat{y}_{i, c}$ is the predicted probability for the $c$-th receiver $r_c \in \mathcal{R}_{lab}$ for the $i$-th training signal in a mini-batch, and $z_{i, c}$ is the ground-truth distribution of occurrence of $r_c$. The ground-truth distribution frequency of a specific receiver $r_c$ is its frequency of occurrence in the entire training set.

Finally, the loss function $L_{GAN-RXA}$ is presented in Equation \eqref{gan-loss}. $L_{GAN-RXA}$ is minimized only to update the FE, as shown in Figure \ref{gan-RXA}.

\begin{equation}
L_{GAN-RXA} = L_{disc} + \gamma * L_{tx}
\label{gan-loss}
\end{equation}
where $\gamma$ is a hyperparameter coefficient to ensure the transmitter-distinguishability. Ideally, $f_{tx}$ should generate features so that $d_{rx}$ can only output random guesses for the receiver labels. However, in practice, if $L_{disc}$ updates $f_{tx}$ too aggressively, $f_{tx}$ loses the capability to distinguish between transmitters at the same time. Therefore, $L_{GAN-RXA}$ includes $L_{tx}$ additional to $L_{disc}$ with a small weighting $\gamma$, to serve as a constraint on the transmitter-distinguishability.

The complete training of this approach is divided into two parts, wherein the first part all three components $f_{tx}$, $d_{rx}$, and $c_{tx}$ are updated. Then, in the second part, only $f_{tx}$ and $d_{rx}$ are updated. The pseudo-code to train the model is provided below in Algorithm \ref{gan-RXA-alg}.
\begin{algorithm}
    \caption{GAN-RXA Update}
    \label{gan-RXA-alg}
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \begin{algorithmic}[1]
        \REQUIRE mini-batch of received signals $x$
        \ENSURE transmitter-feature-extractor $f_{tx}$
        \STATE Initialize $f_{tx}$, $c_{tx}$ and $d_{rx}$ with random weights
        \WHILE{$L_{tx}$ is still decreasing}
            \FOR{$E_1$ epochs}
                \STATE freeze $d_{rx}$
                \STATE Train $f_{tx}$ and $c_{tx}$ with $L_{tx}$
            \ENDFOR
            \FOR{$E_2$ epochs}
                \STATE Freeze $f_{tx}$ and $c_{tx}$
                \STATE Train $d_{rx}$ with $L_{rx}$
            \ENDFOR
            \FOR{$E_3$ epochs}
                \STATE Freeze $d_{rx}$ and $c_{tx}$
                \STATE Train $f_{tx}$ with $L_{GAN-RXA}$
            \ENDFOR
        \ENDWHILE
        
        \STATE Freeze $c_{tx}$
        
        \WHILE{$d_{rx}$ is able to distinguish $\{\mathcal{R}_{lab}\}$}
            \IF{this training stage is looped over $L$ times}
                \STATE BREAK
            \ENDIF
            \FOR{$E_4$ epochs}
                \STATE Freeze $f_{tx}$
                \STATE Train $d_{rx}$ with $L_{rx}$
            \ENDFOR
            \FOR{$E_5$ epochs}
                \STATE Freeze $d_{rx}$
                \STATE Train $f_{tx}$ with $L_{GAN-RXA}$
            \ENDFOR
        \ENDWHILE

        \RETURN $f_{tx}$
    \end{algorithmic}
\end{algorithm}

It can be observed that in the first part, the whole structure is updated step by step, to achieve an optimal possible transmitter-distinguishability. Then, in the second part, the model focuses on removing the receiver fingerprints in $f_{tx}$, while retaining the power of distinguishing transmitters. The intuition behind the second part is such that $L_{GAN-RXA}$ is not yet optimized after the first part converges. It should be noted that the learning rate in the second part needs to be small enough so that the $f_{tx}$ is still able to extract effective transmitter features and $c_{tx}$ can still work properly.
% after the first stage, the gan-rxa loss might not be optimized yet/ experiments show that adding the second stage can further improve the receiver-agnostic property/ the 

% Besides, the principle to choose the set of epochs $E_k$, where $k \in \{1, 2, 3, 4, 5\}$, is to decide what is the acceptable performance for each step, to enable the next step to learn enough meaningful information, while not introducing too much bias. In other words, $f_{tx}$ first needs to extract some coarse but meaningful features for $d_{rx}$ to learn receiver distributions, and $d_{rx}$ needs to output approximately accurate probability predictions, to in turn allow $f_{tx}$ to get rid of those biases.

\subsection{Classifiers} \label{cls}

After an FE is calibrated in the first learning stage, it is sent to every field which requires a classifier. In a given field, the possible classification tasks include both closed-set and open-set scenarios, the classifiers also have two architectures accordingly.

\begin{enumerate}
    \item Closed-set Classifier:
    In a closed-set scenario, a classifier needs to output predictions of transmitter classes. In fact, it performs the same task as a classifier and discriminator used in the FE calibration stage. Therefore, it should have the same architecture as them. To be more specific, a closed-set classifier has $C_{tx}$ output classes, where $C_{tx} = |\mathcal{T}_{field}|$ is the number of transmitters to be authenticated in the field. For each given input $y$, the classifier outputs a set of probabilities $P_{tx}$ for all classes, where $Pr(\hat{y}=c_i|y)$ is the predicted probability that $y$ is transmitted from transmitter $c_i$. Finally, the classifier decides the transmitter class $c_i$ which has the highest predicted probability, as shown in Equation \eqref{closedset}.
    \item Open-set Classifier:
    For open-set problems, the FE does not change, and we only need to slightly change the classifier in the field training stage. According to the results in \cite{p1}, one-versus-all (OVA) is the best performing classifier in open-set tasks. Therefore, we train a distinct OVA classifier for each class $c_i$, and each classifier has exactly two outputs for each input $y$: $\hat{y} = c_i$ and $\hat{y} \neq c_i$. Therefore, the classifier will have a set of probabilities $P_{tx}$. Similar to the closed-set scenario, $Pr(\hat{y}=c_i|y)$ is the predicted probability that $y$ is transmitted from transmitter $c_i$. Therefore, we will have $C_{tx}=|\mathcal{T}_{field}|$ classifiers, where $|\mathcal{T}_{field}|$ is the number of known transmitters in the field. Then, we reject a signal $y$ as outlier if the classifier fails to confidently choose a predicted class for it, with an experimentally chosen threshold $\tau$. Specifically, if the classifier yields probabilities as in Equation \eqref{openset}, it will decide the input $y$ as a signal from an outlier transmitter. $\tau$ is chosen so that an acceptable percentage of signals from known transmitters are classified as outliers. More details are provided in Section \ref{ops}.
\end{enumerate}

\begin{equation}
    \max_{c_i} Pr(\hat{y}=c_i|y), \; \forall c_i \in \mathcal{T}_{field}
    \label{closedset}
\end{equation}

\begin{equation}
    Pr(\hat{y}=c_i|y)<\tau, \; \forall c_i \in \mathcal{T}_{field}
    \label{openset}
\end{equation}


\subsection{Network Architecture}
% Following our previous work \cite{p1}, w
We use modified ResNet-18 \cite{p43} as the backbone of the FE. The architecture is modified only to fit the input shape. Besides, a classifier or discriminator should be able to capture potential non-linearities within a feature vector while preventing overfitting. Therefore, without loss of generality, we use the same architecture, consisting of two concatenated dense layers, for both the classifier $c_{tx}$ and the discriminator $d_{rx}$.

A detailed implementation of the model is illustrated in Figure \ref{nn}. To be more specific, the architecture of an FE is shown in Figure \ref{nn} (a), the architecture of a ResBlock, which is a building block in an FE is shown in   Figure \ref{nn} (b), and a classifier (discriminator) architecture is shown in  Figure \ref{nn} (c). For the classifier, the output classes vary according to its task, as explained in Section \ref{cls}. 



% For openset problems, the feature-extractor doesn't change, and we only need to slightly change the classifier in the second training stage (field training/deployment stage). According to previous work \cite{p1}, one-versus-all (OVA) is the best performing classifier in openset tasks. Therefore, we use OVA as the openset classifier, which has the same architecture as shown in Figure \ref{nn} (c). We train a distinct OVA classifier for each class $c_i$, and each classifier has exactly two outputs for each input $y$: $\hat{y} = c_i$ and $\hat{y} \neq c_i$. Therefore, we will have $C=|\mathcal{T}_{field}|$ classifiers, which is the same number of in-field (known) transmitters. Then, we reject a signal $y$ as outlier if the model fails to confidently choose a predicted class for it, with an experimentally chosen threshold . Specifically, if a model yields probabilities as in Equation \eqref{openset}, it will decide the input $y$ as a signal from an outlier transmitter.

\begin{figure}
    \centering
    \subfigure[Architecture of a feature-extractor (FE). The output is a feature vector of length $T$.]
    {\includegraphics[width=2.5cm]{plots/fe.png}}
    \hfill
    \subfigure[\centering Architecture of a ResBlock with $f$ filters A ResBlock is a building block in an FE.]
    {\includegraphics[width=2.5cm]{plots/resblock.png}}
    \hfill
    \subfigure[\centering Architecture of a classifier and discriminator. The output size $n$ is number of classes to classify between depending on the specific task.]
    {\includegraphics[width=2.5cm]{plots/classifier.png}}
    \caption{The neural net architecture of each component in the proposed model. A notation $(f, s_1, s_2)$ represents $f$ filters of size $(s_1, s_2)$.}
    \label{nn}
\end{figure}

\section{Dataset}\label{ds}

WiSig is a large-scale WiFi dataset containing 10 million packets captured from 174 off-the-shelf WiFi transmitters and 41 USRP receivers over 4 captures spanning a month \cite{p4}. The size of the entire dataset is too large for efficient loading and processing, so we only use a subset from it in our experiments.

For the purpose of the experiments in this paper, we use over 2 million signals from 50 Atheros WiFi transmitters and 28 USRP receivers captured in 4 days. The transmitters include 49 AR5212/AR5213's and 1 AR9580, and the receivers include 3 B210's, 9 X310's and 16 N210's. The transceiver pairs are selected so that each receiver has successful receptions from at least 50\% of the transmitters. To 
%best 
eliminate the biases possibly introduced by the messages carried by a signal, we use exactly same partial preambles \cite{p44} in a WiFi packet for all signals, so that each signal contains the entire Legacy Long Training Field (L-LTF) and Legacy Short Training Field (L-STF) sampled at 25MHZ and has $400 \times 2$ IQ samples.

As mentioned in Section \ref{preprocessing}, the only pre-processing we perform on the raw data is channel equalization. It is worth noting that in this work, we use equalized data for all experiments, as it has been shown to outperform unequalized data \cite{p4}. To perform such channel equalization, we follow the procedure as in \cite{p4}, which is detailed as follows. First, we downsample a signal capture to change its sampling rate from 25 Msps to 20 Msps, which is the nominal sampling rate for WiFi, and apply autocorrelation on the L-STF to accurately detect a packet start. Then, we estimate the frequency offset and correct it accordingly. After that, we estimate and equalize the channel using minimum mean-square error (MMSE) on L-LTF. After this step, since the frequency offset can contribute to the fingerprints for both receivers and transmitters, we reapply it to the signal. Finally, we upsample the signals back to 25Msps. The signal processing for detection and channel estimation is applied using MATLAB R2019b WLAN toolbox with the default parameters.


\begin{table}
\caption{Dataset Separation}
\centering
  \begin{tabular}{|c|c|c|c|}
  \hline
        & $\mathcal{R}_{lab}$, $\mathcal{T}_{lab}$
        & $\mathcal{R}_{field}$, $\mathcal{T}_{field}$
        & $\mathcal{\Tilde{R}}_{field}$, $\mathcal{T}_{field}$\\
    \hline
     Day & Feature-Extractor &  & \\
     1, 2 & $f_{tx}$ Training &  & \\
    \hline
     Day & & Field Classifier & \\
     3 && Training &\\
    \hline
     Day & &  & Field Classifier\\
     4 &&& Testing \\
    \hline
  \end{tabular}
  \label{data}
\end{table}

We divide the dataset into 3 parts, as shown in Table \ref{data}. The training data and testing data come from different sets of transceivers and different days to minimize shared information between the training and testing signals. We use the signals from day 1 and day 2 for feature-extractor $f_{tx}$ training in the lab, signals from day 3 for operational field classifier training, and signals from day 4 for testing. The lab training dataset has the largest size to enhance receiver-agnostic property. The field training dataset only has limited size, with $|\mathcal{R}_{field}|=1$. $20\%$ signals randomly sampled from each training dataset are reserved for validation purpose.


\section{Experiments and Evaluations} \label{ee}
% \subsection{Procedures}
In this section, we first introduce the baseline approaches. Next, we evaluate the approaches according to the metrics of the RATF problem that were defined in Section \ref{pf}.
% Next, we define the metrics to evaluate different approaches.
Then, we evaluate the factors that can impact the quality of the FE. Finally, we consider the openset problem and evaluate our proposed approaches as well as the baseline approaches for this problem.
% As stated in the formulation of the RATF problem, the receiver differences can introduce a significant performance drop in the transmitter classification task. Therefore, to demonstrate that it is non-trivial to consider such a problem, we will


For each experiment, we specify the number of receivers and transmitters in different sets of our framework as described in Section \ref{3b}, and then randomly select the transceiver sets. Each setting is repeated 5 times with different randomization, and the average performance is reported. Unless additionally specified, all approaches are trained and tested on exactly the same sets of transceivers and signals.

\subsection{Baselines}
\begin{enumerate}
    \item Naive approach: This approach is a simple transmitter classifier trained and tested in the field. It does not have the access to lab calibration. To ensure comparability, the architecture of this approach 
    %is exactly the same as other approaches used in the field. It 
    has the same FE and classifier structure as shown in Figures \ref{sd-RXA} and \ref{gan-RXA}, but only with the transmitter-branch. Although it has the FE, the FE is only trained in the field without any prior calibration, as it does not have access to the large training dataset. This approach is used to demonstrate the effectiveness of the proposed two-stage RXA framework.
    \item Exhaustive approach: This approach is similar to the naive approach but without FE since it also has no access to the lab calibration stage. However, it has access to a considerably large set of receivers in the field. In other words, this approach is impractical in reality. This approach is used to demonstrate the practicality of the proposed approaches. 
    \item Basic-RXA: This approach has exactly the same structure as the naive approach: an FE together with a classifier. However, it has access to the entire calibration process in the lab. Therefore, its FE is pre-trained in the lab and delivered to fields. In other words, this approach incorporates the two-stage learning framework. While this approach itself can show the rationality of the proposed two-stage learning framework, it also serves as the baseline to demonstrate the effectiveness of the proposed SD-RXA and GAN-RXA approaches in their improved receiver-agnostic properties.
\end{enumerate}

% \subsection{Feature Extractor Insights}
% While the necessity of a calibrated (pre-trained) FE needs to be demonstrated, the comparison among different FEs is also important. In this section, we will compare different FEs both analytically and experimentally, by considering the SD-RXA approach and GAN-RXA approaches against the two baselines, naive and basic-RXA approaches.

% The intuition of an FE calibration stage is to suppress receiver effects in transmitter classifier. However, as the data is not collected with $100\%$ transmission rate, they can introduce some additional biases or correlation between transceiver pairs. In this case, we may need a more carefully designed training procedure to avoid those additional biases. Both SD-RXA and GAN-RXA are proposed based on such assumption.

% We analyzed and compared the training processes of different FEs theoretically in Approach section. In this section, we will investigate them experimentally by visualizing the clusterings of different FEs. Without loss of generality, we use the same NN architecture for all approaches, as described in Approach section. Since the feature vectors are embedded in high-dimensional space, we need to reduce the dimension for visualization. We use UMAP \cite{p45} for dimension-reduction and visualization, since it can retain spacial distances in manifolds. 

% \begin{figure*}
%     \centering
%     \subfigure[Naive approach.]{\includegraphics[width=7cm]{plots/umap_naive.png}}
%     \hfill
%     \subfigure[\centering Basic-RXA approach.]{\includegraphics[width=7cm]{plots/umap_basic.png}}
%     \hfill
%     \subfigure[\centering SD-RXA approach.]{\includegraphics[width=7cm]{plots/umap_sd.png}}
%     \hfill
%     \subfigure[\centering GAN-RXA approach.]{\includegraphics[width=7cm]{plots/umap_gan.png}}
%     \caption{An example visualizations of feature vectors for different approaches. The RXA approaches have FEs calibrated with 40 TXs and 25 RXs in lab. All approaches use 1 RX and 10 TXs in the field for training a classifier, and 2 RXs in the field for visualizing. All figures are presenting the signals with the same set of transceivers. The shown TX classes are ground-truth labels.}
%     \label{umap}
% \end{figure*}
% As shown in Figure \ref{umap}, for the naive approach, we can observe that although it yields some clusters for different classes, most of them are overlapped. Therefore, we can conclude that the naive FE can still capture similarities within most transmitters, but it cannot effectively distinguish among them. For the basic-RXA approach, the clusters are better distinguished, suggesting the classification accuracy is potentially higher than the naive approach. However, in the meanwhile, we can also observe that many classes have two clusters. This is reasonable since the testing signals are collected from two receivers. Therefore, this distribution can suggest that this basic-RXA FE is still sensitive to receiver differences. For the SD-RXA approach, it can be observed that instead of tight clusters, it yields some thin "lines", such as classes 1, 2 and 3 as shown in the Figure \ref{umap}. This result can be attributed to the loss function of the SD-RXA approach. While this approach minimizes the total loss presented in Equation \eqref{sd-RXA}, it is maximizing the distance between two distributions, as presented in Equation \eqref{dist_loss}. Therefore, the FE tends to generate feature vectors with larger distances against each other, which lead to larger variances within each cluster as well. Finally, for the GAN-RXA approach, we can observe a figure similar the basic-RXA approach, but with smaller clusters, indicating smaller intra-cluster distances and thus more robust transmitter-distinguishability.

% In conclusion, unlike the naive approach, all three approaches with our proposed two-stage learning framework can obtain observable transmitter distinguishability even on a different receiver. Even with a relatively lower testing classification accuracy, the calibrated feature-extractors are still able to capture the transmitter-wise differences, proving the effectiveness of the two-stage learning framework. Besides, the GAN-RXA approach shows best clustering strength, indicating the best receiver-agnostic property.

\subsection{Performance Comparison}

\begin{table}
\caption{Metrics and Different Approaches Comparison}
\centering
  \begin{tabular}{|c|c|c|c|}
  \hline
        & Practicality
        & Cost of Scalability
        & Performance \\
    \hline
     Naive & \textbf{High} & \textbf{Low} & Bad  \\
    \hline
     Exhaustive & Low & \textbf{Low} & \textbf{Good} \\
    \hline
     RXA & \textbf{High} & \textbf{Low} & \textbf{Good} \\
     \hline
    %  \cite{p47} & High & High & Requires multiple receivers during testing\\
    % \hline
    %  \cite{p19} & High & High & Requires retraining on transferred classifiers\\
    %  \hline
    %  \cite{p46} & Low & Low & Requires multiple receivers during field training\\
    %  \hline
  \end{tabular}
  \label{metric}
\end{table}

% \begin{table*}
% \caption{Metrics and Different Approaches Comparison}
% \centering
%   \begin{tabular}{|c|c|c|c|}
%   \hline
%         & Practicality
%         & Cost of Scalability
%         & Limitation \\
%     \hline
%      Naive & High & - & The cost of scalability cannot be evaluated because of classifier not working properly.  \\
%     \hline
%      Exhaustive & Low & Low & Requires multiple receivers during field training \\
%     \hline
%      RXA & High & Low & - \\
%      \hline
%     %  \cite{p47} & High & High & Requires multiple receivers during testing\\
%     % \hline
%     %  \cite{p19} & High & High & Requires retraining on transferred classifiers\\
%     %  \hline
%     %  \cite{p46} & Low & Low & Requires multiple receivers during field training\\
%     %  \hline
%   \end{tabular}
%   \label{metric}
% \end{table*}

\begin{table}
\caption{Results}
\centering
  \begin{tabular}{|c|c|c|c|}
  \hline
        & Closed-set
        & Outlier
        & Open-set \\

        & Accuracy
        & Detection Rate
        & Accuracy \\
    \hline
     Naive & 43.6\% & 27.6\% &
     59.8\%  \\
    \hline
     Basic-RXA & 63.1\% & 37.6\%
     & 72.4\%  \\
    \hline
     SD-RXA & 66.6\% & 37.6\%
     & 74.2\% \\
     \hline
     GAN-RXA & \textbf{68.1\%} 
     & \textbf{45.1\%}
     & \textbf{85.8\%} \\
    \hline
  \end{tabular}
  \label{results}
\end{table}

To evaluate different approaches, other than accuracy, we also use the metrics as shown in Table \ref{metric}. As discussed in Section II, these aspects of an approach must be considered for realistic solutions. All the approaches considered here have a low cost of scalability, since none of them requires retraining on testing receivers.
% Additionally, these approaches do not require multiple receivers during testing \cite{p47}.
We can see that the exhaustive approach is impractical because it always require a large number of receivers in the field to train the classifier. On the other hand, while the naive approach is practical, it cannot yield classifiers that are transferable across receivers, since it does not take the receiver's fingerprints into account. To evaluate the performances, a quantitative and more detailed experimental comparison of the approaches is presented in the following.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{plots/all_approach.png}
    \caption{Comparison of proposed approaches vs baselines. All RXA approaches use $|\mathcal{R}_{lab}|=25$ and $|\mathcal{T}_{lab}|=40$. All approaches use $|\mathcal{R}_{field}|=1$, $|\mathcal{T}_{field}|=10$ and $|\mathcal{\tilde{R}}_{field}|=2$.} 
    \label{allap}
\end{figure}
In Figure \ref{allap}, we present the overall classification accuracy of the proposed approaches as well as the naive approach.
%on all available transceivers. 
We show that a calibrated FE brings $19.5\%$ improvement in field testing classification accuracy, SD-RXA increases another $3.5\%$ accuracy, and GAN-RXA finally boosts the accuracy by $1.5\%$.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{plots/exhaustive.png}
    \caption{Comparison of proposed approach vs exhaustive approach with a different number of receivers (RXs). The GAN-RXA approach uses $|\mathcal{R}_{lab}|=25$, $|\mathcal{T}_{lab}|=40$ and $|\mathcal{R}_{field}|=1$. For the exhaustive approach,  different numbers of receivers are used in the field (see the X-axis of the figure). All approaches use $|\mathcal{T}_{field}|=10$ and $|\mathcal{\tilde{R}}_{field}|=2$.}
    \label{exhaustive}
\end{figure}
In Figure \ref{exhaustive}, we illustrate that GAN-RXA outperforms the exhaustive approach with 5 receivers and has a comparable performance with the exhaustive approach with 10 receivers. This result shows our proposed GAN-RXA approach significantly shrinks the number of receivers in the field to build an accurate transmitter classifier. While the exhaustive approach can have better classification accuracy when the number of in-field training receivers is large, it also becomes impractical in realistic 
%daily 
scenarios. Therefore, the GAN-RXA approach makes the receiver-agnostic classifier a practical solution. Besides, the exhaustive approach reaches a saturation level in terms of classification accuracy with 15 receivers, and the performance stops improving.

In summary, the experiments show that the two-stage RXA framework brings substantial improvement to the performance of a transmitter classifier which is trying to be receiver-agnostic.
%outperforming the other considered approaches. 
Besides, it also demonstrates feasibility to solve the RATF problem due to its practicality and low cost of scalability. Finally, the GAN-RXA approach is shown to further improve the receiver-agnostic property of the calibrated FE and brings additional $5.0\%$ improvement compared to Basic-RXA in the field testing classification accuracy as shown in Figure \ref{allap}.

\subsection{Impacting factors}

As we have shown the superiority of the proposed approaches, in this subsection we consider how different experimental settings can affect the quality of the FE. At the same time, we want to assess the important factors in calibrating an effective FE. We vary $|\mathcal{T}_{lab}|$ and $|\mathcal{R}_{lab}|$ respectively and evaluate the results.We also investigate how $|\mathcal{T}_{field}|$ can affect classification accuracy.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{plots/number_txs_lab.png}
    \caption{Comparison of $|\mathcal{T}_{lab}|$ vs performance.
    % for proposed approaches.
    All RXA approaches use $|\mathcal{R}_{lab}|=25$ and varying $|\mathcal{T}_{lab}|$. All approaches use $|\mathcal{R}_{field}|=1$, $|\mathcal{T}_{field}|=10$ and $|\mathcal{\tilde{R}}_{field}|=2$.}
    \label{txs}
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{plots/number_rxs.png}
    \caption{Comparison of $|\mathcal{R}_{lab}|$ vs performance. All RXA approaches use $|\mathcal{T}_{lab}|=40$ and varying $|\mathcal{R}_{lab}|$. All approaches use $|\mathcal{R}_{field}|=1$, $|\mathcal{T}_{field}|=10$ and $|\mathcal{\tilde{R}}_{field}|=2$.}
    \label{rxs}
\end{figure}
In Figure \ref{txs}, we conduct the experiments with a fixed number of in-lab receivers %together 
with a varying number of in-lab transmitters.
In contrast, in Figure \ref{rxs}
%, in the contrary, 
we conduct the experiments with a fixed number of in-lab transmitters 
%together 
with a varying number of in-lab receivers. 
From
%In 
both 
%experiments
figures, we can observe that the performance of the naive approach is always fluctuating at a relatively low level and is always inferior to other approaches. Since the naive approach does not have the FE calibration stage, its performance indeed provides a baseline for each random combination of field transceivers.
% regardless of the increasing transmitter or receiver numbers,
On the other hand, all three RXA approaches tend to improve as the number of transceivers increases in general. Besides, in both experiments, the GAN-RXA approach provides the highest testing classification accuracy for all the considered number of transceivers.

In the experiment which varies $|\mathcal{T}_{lab}|$, as shown in Figure \ref{txs}, GAN-RXA always has observable accuracy improvement compared to the Basic-RXA approach. The second best approach is the SD-RXA approach, and its performance is upper bounded by GAN-RXA and lower bounded by Basic-RXA. Its instability in performance might be the result of suboptimal statistical distance between the transmitter and receiver feature distributions in some cases.
% Its instability in performance is possibly attributed to its loss function as described in the Feature Extractor Insights section. 

In the experiment which varies $|\mathcal{R}_{lab}|$, as shown in Figure \ref{rxs}, GAN-RXA still has the highest classification accuracy in all experiments. When $|\mathcal{T}_{lab}|=10$ and $|\mathcal{T}_{lab}|=15$, we can see that GAN-RXA has similar accuracy as Basic-RXA. However, GAN-RXA still has smaller variances across different randomizations. Therefore, we can conclude our proposed GAN-RXA approach demonstrates the best stability across different experiments as well. 

% In the experiment which varies $|\mathcal{R}_{lab}|$, as shown in Figure \ref{rxs}, the basic-RXA approach doesn't seem to gain pronounced improvement when the number of $|\mathcal{R}_{lab}|>10$, while both GAN-RXA and SD-RXA approaches keep improving as the RX number increases.

% For the Basic-RXA approach, as the transmitters or receivers in lab grow to a certain number, such as $|\mathcal{T}_{lab}|\geq 25$ and $|\mathcal{R}_{lab}|\geq 10$, simply adding in more transceivers may not necessarily improve the performance. In this case, the possible correlation between the $\mathcal{T}_{lab}$ and $\mathcal{R}_{lab}$ can be a possible factor that is affecting the classification accuracy. In other words, the lab setting may introduce artificial biases between the RX and TX pairings when the number of transceivers in lab increases. However, the GAN-RXA approach shows more stable improvement as the number of transceivers in lab increases, and the reason is possibly such that it is more robust to such biases.

In Figure \ref{txs-field}, we conduct the experiments with a fixed number of in-lab transceivers 
%together 
with a varying number of in-field transmitters. We 
%can 
observe that the performances of all 3 approaches degrade as the number of transmitters in the field increases. This is a natural trend since a classifier is more likely to have a wrong decision on an 
%uncertain 
input when there are more transmitters to be classified. The GAN-RXA outperforms all other approaches again in this experiment, achieving $94.4\%$ accuracy in small-scale in-field transmitter settings.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{plots/number_txs_field.png}
    \caption{Comparison of $|\mathcal{T}_{field}|$ vs performance. All RXA approaches use $|\mathcal{R}_{lab}|=25$ and $|\mathcal{T}_{lab}|=40$. All approaches use $|\mathcal{R}_{field}|=1$, $|\mathcal{T}_{field}|=10$ and $|\mathcal{\tilde{R}}_{field}|=2$.}
    \label{txs-field}
\end{figure}

% In Figure \ref{rxs-field}, we conduct the experiments with fixed number of transceivers, and show how a different combination of receivers in $\mathcal{R}_{lab}$, $\mathcal{R}_{field}$, $\tilde{\mathcal{R}}_{field}$ can affect the result. In ideal case, if the FE is perfectly receiver-agnostic, different combinations of receivers should not lead to non-trivial differences in testing classification accuracy. However, all approaches have fluctuating accuracies across different receivers. The naive approach has the lowest average classification accuracy and largest variance, and the GAN-RXA has the highest average accuracy and smallest variance. Besides, what is noticeable in this experiment is that the optimal curve also has some extent of instabilty. While the classifier is trained and tested on different days, the changes in the environment, such as interference, which are not sufficiently compensated can be another reason responsible for the instability. In summary, although not ahieving the optimal performance, GAN-RXA still demonstrates the best stability as well as average classification accuracy, and the proposed approaches indeed help with the receiver-agnostic property in the FE.

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.5\textwidth]{plots/number_rxs_field.png}
%     \caption{Impacts of different in-field RXs vs performance for proposed approaches. All RXA approaches use 25RXs and 40 TXs in lab to train the FE. All approaches use 1 RX and 10 TXs in the field for training a classifier, and 2 RXs in the field for testing. This figure shows the testing classification accuracy on each different in-field RXs set. The optimal curve represents the accuracy when a naive approach is trained and tested on the same set of receivers.}
%     \label{rxs-field}
% \end{figure}

\subsection{Openset Tasks} \label{ops}
Openset problems can 
%have 
provide different insights from closed-set problems. Therefore, we %want to 
investigate the open-set problem in this section.
%our proposed approaches in these problems as well.

The first important task in openset problems is outlier detection. In Figure \ref{op1}, we look into this aspect and present the averaged confusion matrices for different approaches. In the confusion matrices, each number $p_{i, j}$ represents the percentage as shown in Equation \eqref{percent}, where labels $i$ and $j$ are either known or outlier transmitters. While we need to choose a specific threshold $\tau$ as the decision probability for rejection, the threshold, in general, does not affect the relative performance across different approaches. For consistency, we choose a different $\tau$ for different approaches so that all approaches have approximately $30\%$ signals from the known transmitter set $\mathcal{T}_{field}$ are rejected. As the task is to detect and reject outlier transmitters, we define an outlier signal as positive sample and authenticated (known) signal as negative sample. Therefore, a true positive signal have both true label and predicted label to be outlier. Similarly, a true negative signal have both true label and predicted label to be known.

\begin{equation}
    p_{i, j} = \frac{\text{number of labels predicted to be } l_i}{\text{number of labels with ground truth } l_j}
    \label{percent}
\end{equation}

From Figure \ref{op1}, we can observe that the naive approach tends to accept all signals, yielding a high acceptance rate and a low rejection rate for the outliers. Therefore, this approach does not effectively function as an openset authenticator. 
%Besides, 
Basic-RXA and SD-RXA approaches have similar performance, with almost the same true positive (outliers) and true negative (authenticated transmitters) percentages. Finally, the GAN-RXA approach has the highest true positive rate without sacrificing the true negative rate, indicating the best outlier detection capability. GAN-RXA can improve the outlier detection rate by $17.5\%$ from the naive approach, and by $7.5\%$ from the Basic-RXA approach.
% add an equation
In fact, all approaches have relatively low outlier detection rate. This rate is based on success of all the individual prediction branches, as shown in Equation \eqref{outlier}.

\begin{equation}
    Pr(\hat{y} \in \text{\{Outliers\}}|y)
    = \prod_{c_i \in \mathcal{T}_{field}} {Pr(\hat{y}=c_i|y)<\tau}
    \label{outlier}
\end{equation}

\begin{figure}
    \centering
    \subfigure[Naive approach.]{\includegraphics[width=3.9cm]{plots/op_naive_2.png}}
    \hfill
    \subfigure[\centering Basic-RXA approach.]{\includegraphics[width=3.9cm]{plots/op_basic_2.png}}
    \hfill
    \subfigure[\centering SD-RXA approach.]{\includegraphics[width=3.9cm]{plots/op_sd_2.png}}
    \hfill
    \subfigure[\centering GAN-RXA approach.]{\includegraphics[width=3.9cm]{plots/op_gan_2.png}}
    \caption{Openset outlier detection: Confusion matrices of anomaly detection for different approaches. All RXA approaches use $|\mathcal{R}_{lab}|=25$ and $|\mathcal{T}_{lab}|=40$. All approaches use$|\mathcal{R}_{field}|=1$ and $|\mathcal{\tilde{R}}_{field}|=2$. $|\mathcal{T}_{field}|=6$ is used as known set for training, and 4 different transmitters are introduced in the testing phase as outliers. We use the probability threshold $\tau$ as the decision boundary so that all approaches have approximately $30\%$ signals from the known transmitter set $\mathcal{T}_{field}$ are rejected. Each number $p_{i, j}$ represents the percentage as shown in Equation \eqref{percent}.}
    \label{op1}
\end{figure}

Beyond the outlier detection task, the classification accuracy in authenticated sets is also important. Therefore, we continue the experiment and find average classification accuracy among the correctly accepted transmitters, and the result is shown in Figure \ref{op2}. In the Figure, we can observe the Basic-RXA and SD-RXA approaches have similar performance again. Besides that, the RXA-approaches still outperform the naive approach significantly, and GAN-RXA demonstrates much higher accuracy than all other approaches.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{plots/op_all.png}
    \caption{Openset transmitter classification: classification accuracy among correctly accepted transmitters for different approaches. All RXA approaches use $|\mathcal{R}_{lab}|=25$ and $|\mathcal{T}_{lab}|=40$. All approaches use$|\mathcal{R}_{field}|=1$ and $|\mathcal{\tilde{R}}_{field}|=2$. $|\mathcal{T}_{field}|=6$ is used as known set for training, and 4 different transmitters are introduced in the testing phase as outliers. We use the probability threshold $\tau$ as the decision boundary so that all approaches have approximately $30\%$ signals from the known transmitter set $\mathcal{T}_{field}$ are rejected.}
    \label{op2}
\end{figure}

For all the approaches evaluated, we can observe performance improvement from Figure \ref{txs-field} ($|\mathcal{T}_{field}|=6$) to Figure \ref{op2}. The reason for this improvement could be the rejection of the uncertain signals in the open-set scenario. This result also suggests that we can improve the closed-set classification accuracy by rejecting signals with lower decision confidence. In this experiment, we can observe that while the Basic-RXA and SD-RXA approaches perform similarly, the GAN-RXA approach significantly outperforms other approaches. Therefore, we can conclude that the RXA approaches indeed improve the performance in openset tasks as well, and GAN-RXA remains best choice among all considered approaches in the openset problems.


\section{Conclusion} \label{conclusion}
In this work, we 
%discussed 
addressed the problem of receiver effects in the transmitter fingerprinting problems. We first formulated the RATF problem. We stress that in the problem of transferring classifiers across different receivers, while transmitter classification performance is the basic requirement, practicality and cost of scalability are two important metrics in evaluating a solution. Then, we proposed a practical and scalable two-stage learning framework (RXA) to address the RATF problem. We further proposed two deep-learning-based approaches, SD-RXA and GAN-RXA, to improve the receiver-agnostic property of the 
RXA framework.
%calibrated FE. 
We evaluated the proposed approaches under different use cases, which involve both closed-set and openset authentication scenarios. We showed that the proposed RXA approach can bring substantial improvement to both tasks, and our proposed GAN-RXA approach can further enhance the performance on top of Basic-RXA.

In the closed-set scenario, the two-stage learning framework improved the classification accuracy by $19.5\%$ compared to the naive approach, and GAN-RXA increases it by another $5.0\%$ compared to Basic-RXA. In summary, 
in a closed set problem,
GAN-RXA brought a total improvement of $24.5\%$ over the naive approach. In the openset scenario, the two-stage learning framework improved the outlier detection rate by $10.0\%$, and also improved the classification accuracy on correctly accepted transmitters by $12.6\%$ compared to the naive approach. The GAN-RXA approach additionally improved the outlier detection rate by $7.5\%$ and the classification accuracy by $13.4\%$ compared to Basic-RXA. In summary, in openset problem, 
GAN-RXA brought a total improvement of $17.5\%$ in outlier detection rate and $26.0\%$ in classification accuracy over the naive approach. In both cases, we have demonstrated the effectiveness of the proposed approaches.

While our proposed approach has significantly improved the classifier performance, it is still not as good as a classifier trained and tested on a same receiver \cite{p4}. One direction for future work is the enhancement of the receiver-agnostic feature-extractors. In addition, it would be valuable to 
% investigate the reasoning behind transceiver fingerprints,
 understand how the GAN-RXA deep learning model works. An interpretable deep learning model can help in improving the overall goals of transmitter fingerprinting.

% To further dig into the possibilities in the similarity metric selection, Wasserstein distance or MMD are potential choices.
\section*{Acknowledgments}
We thank Dr. Hazem Sallouha (KU Leuven, Belgium) for his insightful comments and suggestion throughout this paper.



% {\appendix[Proof of the Zonklar Equations]
% Use $\backslash${\tt{appendix}} if you have a single appendix:
% Do not use $\backslash${\tt{section}} anymore after $\backslash${\tt{appendix}}, only $\backslash${\tt{section*}}.
% If you have multiple appendixes use $\backslash${\tt{appendices}} then use $\backslash${\tt{section}} to start each appendix.
% You must declare a $\backslash${\tt{section}} before using any $\backslash${\tt{subsection}} or using $\backslash${\tt{label}} ($\backslash${\tt{appendices}} by itself
%  starts a section numbered zero.)}



%{\appendices
%\section*{Proof of the First Zonklar Equation}
%Appendix one text goes here.
% You can choose not to have a title for an appendix if you want by leaving the argument blank
%\section*{Proof of the Second Zonklar Equation}
%Appendix two text goes here.}

\bibliographystyle{ieeetr}
\bibliography{ref}

% \section{References Section}
% You can use a bibliography generated by BibTeX as a .bbl file.
%  BibTeX documentation can be easily obtained at:
%  http://mirror.ctan.org/biblio/bibtex/contrib/doc/
%  The IEEEtran BibTeX style support page is:
%  http://www.michaelshell.org/tex/ieeetran/bibtex/
 

 % argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% \section{Simple References}
% You can manually copy in the resultant .bbl file and set second argument of $\backslash${\tt{begin}} to the number of references
%  (used to reserve space for the reference number labels box).

% \begin{thebibliography}{1}
% \bibliographystyle{IEEEtran}

% \bibitem{ref1}
% {\it{Mathematics Into Type}}. American Mathematical Society. [Online]. Available: https://www.ams.org/arc/styleguide/mit-2.pdf

% \bibitem{ref2}
% T. W. Chaundy, P. R. Barrett and C. Batey, {\it{The Printing of Mathematics}}. London, U.K., Oxford Univ. Press, 1954.

% \bibitem{ref3}
% F. Mittelbach and M. Goossens, {\it{The \LaTeX Companion}}, 2nd ed. Boston, MA, USA: Pearson, 2004.

% \bibitem{ref4}
% G. Gr\"atzer, {\it{More Math Into LaTeX}}, New York, NY, USA: Springer, 2007.

% \bibitem{ref5}M. Letourneau and J. W. Sharp, {\it{AMS-StyleGuide-online.pdf,}} American Mathematical Society, Providence, RI, USA, [Online]. Available: http://www.ams.org/arc/styleguide/index.html

% \bibitem{ref6}
% H. Sira-Ramirez, ``On the sliding mode control of nonlinear systems,'' \textit{Syst. Control Lett.}, vol. 19, pp. 303--312, 1992.

% \bibitem{ref7}
% A. Levant, ``Exact differentiation of signals with unbounded higher derivatives,''  in \textit{Proc. 45th IEEE Conf. Decis.
% Control}, San Diego, CA, USA, 2006, pp. 5585--5590. DOI: 10.1109/CDC.2006.377165.

% \bibitem{ref8}
% M. Fliess, C. Join, and H. Sira-Ramirez, ``Non-linear estimation is easy,'' \textit{Int. J. Model., Ident. Control}, vol. 4, no. 1, pp. 12--27, 2008.

% \bibitem{ref9}
% R. Ortega, A. Astolfi, G. Bastin, and H. Rodriguez, ``Stabilization of food-chain systems using a port-controlled Hamiltonian description,'' in \textit{Proc. Amer. Control Conf.}, Chicago, IL, USA,
% 2000, pp. 2245--2249.

% \end{thebibliography}


\newpage

% \section{Biography Section}
% If you have an EPS/PDF photo (graphicx package needed), extra braces are
%  needed around the contents of the optional argument to biography to prevent
%  the LaTeX parser from getting confused when it sees the complicated
%  $\backslash${\tt{includegraphics}} command within an optional argument. (You can create
%  your own custom macro containing the $\backslash${\tt{includegraphics}} command to make things
%  simpler here.)
 
% \vspace{11pt}

% \bf{If you include a photo:}\vspace{-33pt}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig1}}]{Michael Shell}
% Use $\backslash${\tt{begin\{IEEEbiography\}}} and then for the 1st argument use $\backslash${\tt{includegraphics}} to declare and link the author photo.
% Use the author name as the 3rd argument followed by the biography text.
% \end{IEEEbiography}

% \vspace{11pt}

% \bf{If you will not include a photo:}\vspace{-33pt}
% \begin{IEEEbiographynophoto}{John Doe}
% Use $\backslash${\tt{begin\{IEEEbiographynophoto\}}} and the author name as the argument followed by the biography text.
% \end{IEEEbiographynophoto}




\vfill

\end{document}


