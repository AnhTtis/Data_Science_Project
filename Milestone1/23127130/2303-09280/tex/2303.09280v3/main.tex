\documentclass[reprint,superscriptaddress]{revtex4-2}

\usepackage{graphicx}
\usepackage{amsmath,amsfonts,amssymb,amsthm,color}
\usepackage[normalem]{ulem}  % for strikeout \st{}
\usepackage{multirow}
\usepackage{booktabs} % enables toprule, etc
\allowdisplaybreaks
%\renewcommand\Affilfont{\itshape\small}
%\usepackage{epstopdf,epsfig}
%\usepackage{newtxtext}
%\usepackage{newtxmath}
%\usepackage[square,numbers]{natbib}

\usepackage{hyperref}
\hypersetup{
    colorlinks = true,
    urlcolor   = blue,
    citecolor  = black,
}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newcommand{\RomanNumeralCaps}[1]

%\usepackage{float}
%\usepackage{caption}
%\captionsetup{justification=justified,width=\textwidth}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

\begin{document}

\title{Detecting hidden structures from a static loading experiment: \\ topology optimization meets physics-informed neural networks}

\author{Saviz Mowlavi}
 \email{mowlavi@merl.com}
\affiliation{Mitsubishi Electric Research Laboratories, Cambridge, MA 02139, USA}
\affiliation{Department of Mechanical Engineering, MIT, Cambridge, MA 02139, USA}
\author{Ken Kamrin}%
 \email{kkamrin@mit.edu}
\affiliation{Department of Mechanical Engineering, MIT, Cambridge, MA 02139, USA}
\affiliation{Department of Mechanical Engineering, UC Berkeley, Berkeley, CA 94720, USA}

\begin{abstract}
Most noninvasive imaging techniques utilize electromagnetic or acoustic waves originating from multiple locations and directions to identify hidden geometrical structures. 
Surprisingly, it is also possible to image hidden voids and inclusions buried within an object using a single static thermal or mechanical loading experiment by observing the response of the exposed surface of the body, but this problem is challenging to invert. 
Although physics-informed neural networks (PINNs) have shown promise as a simple-yet-powerful tool for problem inversion, they have not yet been applied to \textcolor{black}{imaging} problems with a priori unknown topology. 
Here, we introduce a topology optimization framework based on PINNs that identifies concealed geometries using exposed surface data from a single loading experiment, without prior knowledge of the number or types of shapes. 
We allow for arbitrary solution topology by representing the geometry using a material density field combined with a novel eikonal regularization technique. 
We validate our framework by detecting the number, locations, and shapes of hidden voids and inclusions in many example cases, in both 2D and 3D, and we demonstrate the method's robustness to noise and sparsity in the data. 
Our methodology opens a pathway for PINNs to solve \textcolor{black}{geometry optimization problems in engineering}.
\end{abstract}

\maketitle

Noninvasive detection of hidden geometries is desirable in countless applications including medical imaging and diagnosis \citep{suetens2017}, nondestructive evaluation of materials \citep{hellier2013}, or mine detection \cite{robledo2009}. Common noninvasive imaging methods, such as computed tomography \citep{withers2021}, ultrasonic testing \citep{krautkramer2013}, and magnetic resonance imaging \citep{mcrobbie2017}, rely upon electromagnetic or acoustic waves sent from multiple directions and positions to detect the locations and shapes of structures hidden inside a given body \citep{kasban2015}.
%As they travel through the body and interact with hidden structures, these waves will be reflected off, partially absorbed, or generate new waves. By detecting the waves that exit the body, the locations and shapes of these internal structures can therefore be inferred \citep{griffiths2001,krautkramer2013,adler2021}. 
%The locations and shapes of hidden structures are then identified by detecting the waves emitted back from the body as they are transmitted through, reflected off, or excited by these structures \citep{griffiths2001,adler2021}.
These noninvasive imaging techniques often require costly specialized equipment and long data acquisition procedures, limiting their applicability in cost- or time-sensitive applications \citep{de2014}.

It is known that \textcolor{black}{for} a two-dimensional \textcolor{black}{(2D)} elastic body containing one void, a \textit{single} mechanical experiment provides sufficient data to uniquely identify the shape and location of the void, by utilizing the physics governing the problem \citep{ang1999}. In practice, this involves subjecting the body to a boundary traction, measuring the resulting surface displacement over a finite portion of the boundary, and solving a physics-constrained inverse problem for the geometry of the void. We show here that this uniqueness result can, remarkably, be generalized to any number of voids or solid inclusions in three-dimensional \textcolor{black}{(3D)} bodies, and any type of experiment where the physics is governed by linear or nonlinear elliptic partial differential equations (PDEs), such as heat conduction or large-deformation elasticity. This opens the door to a new noninvasive imaging paradigm where buried voids or inclusions are detected from surface measurements acquired in a single loading experiment, with the potential to accelerate the data acquisition process in time-critical applications. However, the inverse problem is extremely challenging to solve due to the unknown topology, the limited amount of measurements, and the complexity of the underlying physical laws \citep{bonnet2005,colton2019}.

In the present paper, we introduce a novel and simple topology optimization (TO) method that leverages physics-informed neural networks (PINNs) for accurately reconstructing the shapes and locations of concealed objects using surface data obtained from a single experiment along with knowledge of the physics. Previous attempts to solve related inverse problems rely on more complicated methods such as adjoint-based optimization
%as they combine PDE discretization methods with adjoint techniques to evaluate the sensitivity of the error residual with respect to the shape or the topology, and gradient descent-based optimization algorithms to update the geometry at every iteration.
%Furthermore, these techniques call for carefully chosen regularization schemes 
and do not always yield satisfactory results, especially in the presence of sparse measurements acquired by only one or a few sets of experiments \citep{lee2000,ameur2004,mei2016,mei2021}. %For example, in the mechanical loading case, past studies limit themselves to simple shapes like squares and circles, or fail to find the right number of shapes \citep{lee2000,ameur2004,mei2016,mei2021}.

PINNs have emerged in recent years as a robust tool for problem inversion across disciplines and over a range of model complexity \citep{dissanayake1994,lagaris1998,raissi2019,sun2020}. Their ability to seamlessly blend measurement data or design objectives with governing PDEs in nontrivial geometries has enabled practitioners to solve easily a range of inverse problems involving identification or design of unknown properties in fields ranging from mechanics to optics and medicine \citep{raissi2020,sahli2020,lu2021,haghighat2021,chen2022,mowlavi2023,joglekar2023dmf,jeong2023complete,qiu2023}. Encouraged by these early successes, we adopt PINNs as the foundation of our TO framework for geometry detection. Building on the strength of PINNs, our approach leverages both the measurements and the governing PDEs, is straightforward to implement regardless of the complexity of the physical model, and produces accurate results without requiring a training dataset, unlike purely data-based machine learning approaches to solve related inverse problems \citep{ni2021,yang2023,crocker2023}. To the best of our knowledge, the present work marks the first time that PINNs have been applied to \textcolor{black}{imaging} problems involving \textit{a priori} unknown topology and geometry.

Using data from a single loading experiment, our PINN-based TO framework identifies complex concealed shapes without any prior knowledge on the number and types of shapes. We allow for arbitrary solution topology by representing the geometry using a material density field equal to 0 in one phase and 1 in the other. The material density is parameterized through a neural network, which needs to be regularized in order to push the material density towards 0 or 1 values. Thus, one key ingredient in our framework is a novel eikonal regularization, inspired from fast-marching level-set methods \citep{adalsteinsson1995,osher2004} and neural signed distance functions \citep{gropp2020}, that promotes a constant thickness of the interface region where the material density transitions between 0 and 1, leading to well-defined boundaries throughout the domain. 
This eikonal regularization enters as an additional term in the standard PINN loss, which is then used to train the neural networks underlying the material density and physical quantities to yield a solution to the geometry detection problem. 

As an illustration, we apply our framework to \textcolor{black}{2D and 3D} cases involving elastic bodies under mechanical \textcolor{black}{or} thermal loading, and discover the topology, locations, and shapes of hidden structures for a variety of geometries and materials. Finally, comparisons with other regularization methods commonly employed in TO show that the eikonal regularization consistently yields the most accurate results in these applications.

\section*{Results} 

\subsection*{Problem formulation}

We consider noninvasive geometry detection problems of the following \textcolor{black}{general} form. Suppose we have a continuous body $\mathcal{B}$ \textcolor{black}{in 2D or 3D} containing an unknown number of hidden voids or inclusions, with unknown shapes and at unknown locations within the body. The material properties are assumed to be known and homogeneous within the body and the inclusions. We then apply a certain type of loading (e.g.~mechanical or thermal) on the body's external boundary $\partial \mathcal{B}^\mathrm{ext}$, which produces a response within the body that can be described by a set of $n$ physical quantities (e.g.~displacements, stresses, temperature, etc). These physical quantities can be lumped into a vector field $\boldsymbol{\psi} : \mathcal{B} \rightarrow \mathbb{R}^n$ and satisfy a known set of governing PDEs \textcolor{black}{and applied boundary conditions (BCs)}. The goal of the inverse problem is to identify the number, locations, and shapes of the voids or inclusions based on measurements \textcolor{black}{of the boundary data that arises along a finite connected segment} of $\partial \mathcal{B}^\mathrm{ext}$. The $\boldsymbol{\psi}$ output one measures on the boundary is the data ``conjugate'' to the prescribed BCs; e.g.~if the problem were elastic and surface stresses were applied one would measure the surface displacements that emerge, or if the problem were thermal and surface temperatures were prescribed one would measure the resulting normal heat flux.

\textcolor{black}{\textbf{Theorem.} As long as the governing PDEs are elliptic, this inverse problem has a unique solution. The proof is provided in the Supplementary Materials. This uniqueness result provides an essential motivation for the PINN-based TO framework that we introduce in the next section.}

As a concrete example, consider two \textcolor{black}{2D prototypical} plane-strain elasticity inverse problems.
%%%%
\begin{figure}[tb]
\centering
\includegraphics[width=0.5\textwidth]{Figures/NCS_Geometry}
\caption{\textbf{Setup of two \textcolor{black}{prototypical} geometry identification problems in elastic bodies under mechanical loading.} \textbf{a}, A square elastic matrix with hidden voids or inclusions is pulled by a known uniform traction on two opposite sides. The goal is to identify the number, locations, and shapes of the voids or inclusions within using measurements of the displacement occurring along the outer boundary of the matrix. \textbf{b}, An elastic layer on top of a hidden rigid substrate is compressed from the top by a uniform pressure. The goal is to identify the shape of the substrate using measurements of the displacement of the top surface.}
\label{fig:Geometry}
\end{figure}
%%%%
In the first case, a square elastic matrix with hidden voids or inclusions is pulled by a uniform traction $P_o$ on two sides (Fig.~\ref{fig:Geometry}a). The goal of the inverse problem is to identify the number, locations, and shapes of the voids or inclusions using discrete measurements of the displacement of the outer boundary of the matrix. In the second case, an elastic layer on top of a hidden rigid substrate is compressed from the top by a uniform pressure $P_o$, with periodic lateral BCs (Fig.~\ref{fig:Geometry}b). The goal is to identify the shape of the substrate using discrete measurements of the displacement of the top surface. For both cases, \textcolor{black}{the governing PDEs, applied BCs, and} the constitutive properties of all materials are assumed to be known. We consider two different types of constitutive laws: compressible linear elasticity, which characterizes the small deformation of any compressible elastic material, and incompressible nonlinear hyperelasticity, which models the large deformation of rubber-like materials. \textcolor{black}{We also presume that the discrete measurements are closely distributed in order to capture the continuous displacement field along the corresponding surface.}

\textcolor{black}{As in} density-based TO methods \citep{sigmund2013}, we avoid any restriction on the number and shapes of hidden structures by parameterizing the geometry of the elastic body $\mathcal{B}$ through a discrete-valued material density function $\rho : \Omega \rightarrow \{0,1\}$, where $\Omega$ is a global domain comprising both $\mathcal{B}$ and the hidden voids or inclusions. The material density is defined to be equal to 1 in the elastic body $\mathcal{B}$ and 0 in the voids or inclusions. 
The physical quantities $\boldsymbol{\psi}$ can then be extended to the global domain $\Omega$ by introducing an explicit $\rho$-dependence in their governing PDEs, leading to equations of the form 
\begin{subequations}
\begin{align}
\mathbf{r}(\boldsymbol{\psi}(\mathbf{x}),\rho(\mathbf{x})) &= 0, \quad \mathbf{x} \in \Omega, \label{eq:GoverningPDEs} \\
\mathbf{b}(\boldsymbol{\psi}(\mathbf{x})) &= 0, \quad \mathbf{x} \in \partial \Omega, \label{eq:AppliedBCs}
\end{align}
\end{subequations}
\textcolor{black}{where $\mathbf{r}$ contains the PDE residuals and $\mathbf{b}$ encodes the applied} BCs defined on the external boundary $\partial \Omega = \partial \mathcal{B}^\mathrm{ext}$. \textcolor{black}{Both} $\mathbf{r}$ and $\mathbf{b}$ may contain partial derivatives of $\boldsymbol{\psi}$ and $\rho$. The inverse problem is now to find the distribution of material density $\rho$ in $\Omega$ so that the corresponding solution for $\boldsymbol{\psi}$ matches surface measurements $\boldsymbol{\psi}_i^m$ at discrete locations $\mathbf{x}_i \in \partial \Omega^m \subset \partial \Omega$, that is,
\begin{equation}
\boldsymbol{\psi}(\mathbf{x}_i) = \boldsymbol{\psi}_i^m, \quad \mathbf{x}_i \in \partial \Omega^m.
\label{eq:Measurements}
\end{equation}
In practice, we might only measure select quantities in $\boldsymbol{\psi}$ at some of the locations, but we do not write so explicitly to avoid overloading the notation.

For the \textcolor{black}{prototypical} elasticity problems considered as an example \textcolor{black}{in Fig.~\ref{fig:Geometry}}, $\boldsymbol{\psi} = (\mathbf{u},\boldsymbol{\sigma})$ where $\mathbf{u}(\mathbf{x})$ and $\boldsymbol{\sigma}(\mathbf{x})$ are displacement and stress fields, respectively, and the governing PDEs \textcolor{black}{\eqref{eq:GoverningPDEs}} comprise equilibrium relations $\sum_j\partial \sigma_{ij}/\partial x_j = 0$ and a constitutive law $F(\boldsymbol{\sigma}, \nabla \mathbf{u}, \rho) = 0$, both defined over $\Omega$. The presence of $\rho$ in the constitutive law specifies different material behaviors \textcolor{black}{between} the elastic solid phase and the void or rigid inclusion phase. 
% The applied BCs \textcolor{black}{\eqref{eq:AppliedBCs}} take the form $\mathbf{u} = \bar{\mathbf{u}}$ on $\partial \Omega_u$ and $\boldsymbol{\sigma} \mathbf{n} = \bar{\mathbf{t}}$ on $\partial \Omega_t$, where $\partial \Omega_u$ and $\partial \Omega_t$ are partitions of the external boundary with applied displacements and applied tractions, respectively, and $\mathbf{n}$ is the outward unit normal. In the case of the elastic layer, the outer boundary also comprises a portion $\partial \Omega_p$ with periodic BCs on the displacement and traction. 
The applied BCs \textcolor{black}{\eqref{eq:AppliedBCs}} take the form $\boldsymbol{\sigma} \mathbf{n} = \bar{\mathbf{t}}$ on boundary segments $\partial \Omega_t$ subject to applied tractions ($\mathbf{n}$ is the outward unit normal), $\mathbf{u} = \bar{\mathbf{u}}$ on boundary segments $\partial \Omega_u$ subject to applied displacements, and periodic conditions for $\mathbf{u}$ and $\boldsymbol{\sigma}$ on boundary segments $\partial \Omega_p$. \textcolor{black}{Last, since surface displacements are measured, the constraint \eqref{eq:Measurements}} is $\mathbf{u}(\mathbf{x}_i) = \mathbf{u}_i^m$ for $\mathbf{x}_i \in \partial \Omega^m$. 
% See \textcolor{black}{SI} for a detailed formulation of the governing PDEs and BCs for \textcolor{black}{the two prototypical problems depicted in Fig.~\ref{fig:Geometry}}.

\textcolor{black}{Finally, we relax the binary constraint on} the material density \textcolor{black}{$\rho$ by allowing intermediate values} between 0 and 1, \textcolor{black}{which} renders the problem amenable to gradient-based optimization. \textcolor{black}{However, this requires adding an appropriate} regularization mechanism \textcolor{black}{to promote convergence of $\rho$} towards 0 \textcolor{black}{or} 1, \textcolor{black}{a key yet challenging task \citep{benning2018, bertero2021}.} As we will show in the discussion, common strategies employed in \textcolor{black}{computational imaging and} TO \citep{dorn2006,sigmund2013} do not yield satisfactory results in our PINN-based framework. Thus, we have developed a novel eikonal regularization scheme that we will describe after the general framework.

\subsection*{General \textcolor{black}{PINN-based TO} framework}
\label{sec:GeneralFramework}

%%%%
\begin{figure*}
\centering
\includegraphics[width=\textwidth]{Figures/NCS_Framework}
\caption{\textbf{TO framework for noninvasive detection of hidden geometries.} The geometry of the system, which is initially unknown, is parameterized by a material density field given through a level-set function and equal to 1 in the elastic body and 0 in the voids or inclusions. The level-set function and the physical quantities describing the problem are approximated with deep neural networks designed to inherently satisfy the applied BCs. These neural networks are then trained to minimize a loss function that drives the material density and physical quantities towards satisfying the governing equations of the problem while matching discrete surface measurements. A crucial eikonal regularization term in the loss function ensures that the material density transitions between 0 and 1 over a prescribed length scale and avoids settling on intermediate values. By the end of the optimization, the converged material distribution reveals the location and shapes of the hidden structures.}
\label{fig:Framework}
\end{figure*}
%%%%

We propose a TO framework based on PINNs for solving noninvasive geometry detection problems (Fig.~\ref{fig:Framework}). At the core of the framework are several deep neural networks that approximate the physical quantities $\boldsymbol{\psi}(\mathbf{x})$ describing the problem and the material density $\rho(\mathbf{x})$. For the physical quantities, each neural network maps the spatial location $\mathbf{x} = (x_1,x_2)$ to one of the variables in $\boldsymbol{\psi} = (\psi_1, \cdots, \psi_n)$; this can be expressed as $\psi_i = \bar{\psi}_i(\mathbf{x}; \boldsymbol{\theta}_i)$ where $\bar{\psi}_i$ is the map defined by the $i$th neural network and its trainable parameters $\boldsymbol{\theta}_i$ (see \textcolor{black}{SI}). For the material distribution, we first define a neural network with trainable parameters $\boldsymbol{\theta}_\phi$ that maps $\mathbf{x}$ to a scalar variable $\phi = \bar{\phi}(\mathbf{x}; \boldsymbol{\theta}_\phi)$. A sigmoid function is then applied to $\phi$ to yield $\rho = \mathrm{sigmoid}(\phi/\delta) = \mathrm{sigmoid}(\bar{\phi}(\mathbf{x}; \boldsymbol{\theta}_\phi)/\delta)$, which we simply write as $\rho = \bar{\rho}(\mathbf{x},\boldsymbol{\theta}_\phi)$. This construction ensures that the material density $\rho$ remains between 0 and 1, and $\delta$ is a transition length scale that we will comment on later. We define the phase transition to occur at $\rho = 0.5$ so that the zero level-set of $\phi$ delineates the boundary between the two material phases, hence $\phi$ is hereafter referred to as a level-set function \citep{osher1988,osher2004}.

We now seek the parameters $\boldsymbol{\theta}_{\boldsymbol{\psi}} = \{\boldsymbol{\theta}_1, \dots, \boldsymbol{\theta}_n\}$ and $\boldsymbol{\theta}_\phi$ so that the neural network approximations for $\boldsymbol{\psi}(\mathbf{x})$ and $\rho(\mathbf{x})$ satisfy the governing PDEs \eqref{eq:GoverningPDEs} and applied BCs \eqref{eq:AppliedBCs} while matching the surface measurements \eqref{eq:Measurements}. This is achieved by constructing a loss function of the form
\begin{align}
\mathcal{L}(\boldsymbol{\theta}_{\boldsymbol{\psi}}, \boldsymbol{\theta}_\phi) &= \lambda_\mathrm{meas} \mathcal{L}_\mathrm{meas}(\boldsymbol{\theta}_{\boldsymbol{\psi}}) + \lambda_\mathrm{gov} \mathcal{L}_\mathrm{gov}(\boldsymbol{\theta}_{\boldsymbol{\psi}}, \boldsymbol{\theta}_\phi) \nonumber \\ 
&\quad + \lambda_\mathrm{reg} \mathcal{L}_\mathrm{eik}(\boldsymbol{\theta}_\phi), \label{eq:TotalLoss}
\end{align}
where $\mathcal{L}_\mathrm{meas}$ and $\mathcal{L}_\mathrm{gov}$ measure the degree to which the neural network approximations do not satisfy the measurements and governing PDEs, respectively, $\mathcal{L}_\mathrm{eik}$ is a crucial regularization term that drives $\rho$ towards 0 or 1 values and that we will explain below, and the $\lambda$'s are scalar weights. The measurement loss takes the form
\begin{equation}
\mathcal{L}_\mathrm{meas}(\boldsymbol{\theta}_{\boldsymbol{\psi}}) = \frac{1}{|\partial \Omega^m|} \sum_{\mathbf{x}_i \in \partial \Omega^m} |\bar{\boldsymbol{\psi}}(\mathbf{x}_i;\boldsymbol{\theta}_{\boldsymbol{\psi}})-\boldsymbol{\psi}_i^m|^2,
\end{equation}
where $|\partial \Omega^m|$ denotes the size of the set $\partial \Omega^m$. A trivial modification of this expression is necessary in the case where only select quantities in $\boldsymbol{\psi}$ are measured. The PDE loss takes the form
\begin{equation}
\mathcal{L}_\mathrm{gov}(\boldsymbol{\theta}_{\boldsymbol{\psi}}, \boldsymbol{\theta}_\phi) = \frac{1}{|\Omega^d|} \sum_{\mathbf{x}_i \in \Omega^d} |\mathbf{r}(\bar{\boldsymbol{\psi}}(\mathbf{x}_i;\boldsymbol{\theta}_{\boldsymbol{\psi}}),\bar{\rho}(\mathbf{x}_i;\boldsymbol{\theta}_\phi))|^2,
\label{eq:LossGov}
\end{equation}
where $\Omega^d$ is a set of collocation points in $\Omega$, and we use automatic differentiation to calculate in a mesh-free fashion the spatial derivatives contained in $\mathbf{r}$. We design the architecture of our neural networks in such a way that they inherently satisfy the \textcolor{black}{applied} BCs (see \textcolor{black}{Supplementary Materials}).

Finally, the optimal parameters $\boldsymbol{\theta}_{\boldsymbol{\psi}}^*$ and $\boldsymbol{\theta}_\phi^*$ that solve the problem can be obtained by training the neural networks to minimize the loss \eqref{eq:TotalLoss} using stochastic gradient descent-based optimization. The corresponding physical quantities $\bar{\boldsymbol{\psi}}(\mathbf{x};\boldsymbol{\theta}_{\boldsymbol{\psi}}^*)$ will match the discrete surface measurements while satisfying the governing equations of the problem, while the corresponding material density $\bar{\rho}(\mathbf{x};\boldsymbol{\theta}_\phi^*)$ will reveal the number, locations, and shapes of the hidden voids or inclusions.

\subsection*{\textcolor{black}{Eikonal} regularization}
\label{sec:MaterialDensityRegularization}

We now describe the key ingredient that ensures the success of our framework. As mentioned above, the main challenge is to promote the material density $\rho(\mathbf{x})$ to converge towards 0 or 1 away from the material phase boundaries defined by the zero level-set $\phi = 0$. Moreover, we desire the thickness of the transition region along these boundaries, where $\rho$ goes from 0 to 1, to be uniform everywhere in order to ensure consistency of physical laws across the interface (e.g.~stress jumps). 

%%%%
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{Figures/NCS_LevelSet}
\caption{\textbf{Eikonal regularization of the material density.} $\mathbf{a}$, A random level-set function $\phi$ yields a material density $\rho = \mathrm{sigmoid}(\phi/\delta)$ with large regions of values between 0 and 1, due to the nonuniformity of the gradient $|\nabla \phi|$ along the material boundaries defined by the zero level-set of $\phi$ (black lines). $\mathbf{b}$, Constraining $\phi$ to solve the eikonal equation $\nabla \phi = 1$ in a narrow band $\Omega_\mathrm{eik}$ of thickness $w$ (delineated by the dashed lines) along the material boundaries results in a uniform transition thickness of $\rho$ from 0 to 1, without large regions of intermediate density values. $\mathbf{c}$, The loss $\mathcal{L}_\mathrm{eik}$ implements the eikonal regularization in the PINN-based TO framework by penalizing violations of the constraint $|\nabla \phi| = 1$ in a subset of collocation points $\Omega_\mathrm{eik}^d \subset \Omega_d$ that approximates the true narrow band $\Omega_\mathrm{eik}$.}
\label{fig:LevelSet}
\end{figure}
%%%%

To visualize what happens in the absence of regularization, consider a random instance of the neural network $\phi = \bar{\phi}(\mathbf{x},\boldsymbol{\theta}_\phi)$ (Fig.~\ref{fig:LevelSet}a, left) and the corresponding material distribution $\rho = \mathrm{sigmoid}(\phi/\delta)$ with $\delta = 0.01$ (Fig.~\ref{fig:LevelSet}a, center). The sigmoid transformation ensures that $\rho$ never drops below 0 or exceeds 1, leading to large regions corresponding to one phase or the other. However, the thickness of the transition region where $\rho$ goes from 0 to 1 is not everywhere uniform, resulting in large zones where $\rho$ assumes nonphysical values between 0 and 1 (Fig.~\ref{fig:LevelSet}a, center). This behavior stems from the non-uniformity of the gradient norm $|\nabla \phi|$ along the material boundaries $\phi = 0$, with small and large values of $|\nabla \phi|$ leading to wide and narrow transition regions, respectively (Fig.~\ref{fig:LevelSet}a, right).

We propose to regularize the material density by forcing $|\nabla \phi|$ to be unity in a narrow band $\Omega_\mathrm{eik}$ of width $w$ along the material boundaries defined by $\phi = 0$. In this way, $\phi$ becomes a signed distance function to the material boundary in the narrow band, thereby constraining the gradient of $\rho$ to be constant along the interface. To ensure that the narrow band covers the near-entirety of the transition region where $\rho$ goes from 0 to 1, we choose $w = 10 \delta$ so that $\rho = \mathrm{sigmoid}(\pm w/2\delta) = \mathrm{sigmoid}(\pm 5) \simeq 0$ or $1$ along the edge of the narrow band. To illustrate the effect of such regularization, we consider the previous random instance of the neural network $\phi = \bar{\phi}(\mathbf{x},\boldsymbol{\theta}_\phi)$ and enforce the constraint $|\nabla \phi| = 1$ in the narrow band $\Omega_\mathrm{eik}$ along its zero level-set (Fig.~\ref{fig:LevelSet}b, left and right). The zero level-set is kept fixed to facilitate comparison with the unregularized case (Fig.~\ref{fig:LevelSet}a). With $\phi$ now behaving like a signed-distance function in the narrow band, a uniform transition thickness for $\rho$ along all material boundaries is achieved, without large regions of intermediate density values (Fig.~\ref{fig:LevelSet}b, center).

In practice, we implement this regularization into our PINN-based TO framework by including an `eikonal' loss term $\mathcal{L}_\mathrm{eik}$ in \eqref{eq:TotalLoss}, which takes the form
\begin{equation}
\mathcal{L}_\mathrm{eik}(\boldsymbol{\theta}_\phi) = \frac{1}{|\Omega_\mathrm{eik}^d|} \sum_{\mathbf{x}_i \in \Omega_\mathrm{eik}^d} \left(| \nabla \phi (\mathbf{x}_i)| - 1 \right)^2,
\label{eq:EikonalLoss}
\end{equation}
where $\Omega_\mathrm{eik}^d = \{\mathbf{x}_i \in \Omega^d : |\phi(\mathbf{x}_i)| < w/2\}$. The aim of this term is to penalize deviations away from the constraint $|\nabla \phi| = 1$ in the narrow band $\Omega_\mathrm{eik}$ of width $w$ along the interface defined by the zero level-set $\phi = 0$. Because finding the subset of collocation points $\mathbf{x}_i$ in $\Omega^d$ belonging to the true narrow band of width $w$ at every step of the training process would be too expensive, we instead relax the domain over which the constraint $|\nabla \phi| = 1$ is active by utilizing the subset $\Omega_\mathrm{eik}^d$ of collocation points that satisfy $|\phi(\mathbf{x}_i)| < w/2$. As the constraint $|\nabla \phi| = 1$ is progressively better satisfied during the training process, $\Omega_\mathrm{eik}^d$ will eventually overlap the true narrow band of width $w$ along the zero level-set of $\phi$ (Fig.~\ref{fig:LevelSet}c). 

We call this approach eikonal regularization, since the constraint $|\nabla \phi| = 1$ in the narrow band takes the form of an eikonal equation. \textcolor{black}{However, in contrast to the way the eikonal equation is employed in classical level-set methods \citep{adalsteinsson1995,osher2004} and recent works on neural signed distance functions \citep{gropp2020}, our eikonal regularization does not require $\phi$ to vanish on a specified boundary. That is, we do not enforce an explicit boundary condition $\phi = 0$ along a given curve (in 2D) or surface (in 3D), which is typically needed to solve the eikonal equation.} Rather, we let the zero level-set of $\phi$ freely evolve during the training process, eventually revealing the material boundaries delineating the hidden voids or inclusions. \textcolor{black}{To our knowledge, this is the first time that the eikonal equation is used without an explicit boundary condition.}

\subsection*{Setup of numerical experiments}
\label{sec:SetupNumericalExperiments}

We evaluate our TO framework on \textcolor{black}{numerous} challenging test cases \textcolor{black}{in 2D and 3D involving different types of physics (mechanical and thermal), several shapes and materials for the body $\mathcal{B}$, and various numbers and shapes of hidden voids and inclusions. These test cases are described in Materials and Methods, and listed in Tabs.~\ref{tab:ElasticMatrixCases}, \ref{tab:ElasticLayerCases}, \ref{tab:ThermalMatrixCases}. As a substitute for real experiments, we use the finite-element method (FEM) software Abaqus to compute the response of the body to the applied loading} and generate the measurement data for each case; \textcolor{black}{details are provided in the Materials and Methods}. Using this \textcolor{black}{synthetic} measurement data, we run our TO framework to discover the number, locations, and shapes of the hidden voids or rigid inclusions. We then compare the obtained results with the ground truth -- the voids or inclusions originally fed into Abaqus -- to assess the efficacy of our framework. \textcolor{black}{A comprehensive description of the implementation details and the training procedure for the TO framework is provided in the Supplementary Materials.}

\subsection*{\textcolor{black}{Prototypical examples}}
\label{sec:PrototypicalExamples}

%%%%
\begin{figure*}
\centering
\includegraphics[width=\textwidth]{Figures/NCS_Ela.pdf}
\caption{\textbf{Identification of voids and inclusions in elastic matrices.} A linear elastic matrix containing voids (\textbf{a-d}): \textbf{a}, The various loss components that enforce the solution to match the surface measurement data, satisfy the governing equations, and obey the eikonal regularization, are being minimized during the training process. \textbf{b},\textbf{c}, The final level-set function $\phi$ and its gradient magnitude $|\nabla \phi|$ show the effect of the eikonal regularization, making $\phi$ a signed distance function in narrow band along the interface. \textbf{d}, The final material density $\rho$ reveals the number, locations, and shapes of the hidden voids, which are compared with the ground truth shown in dotted white lines. \textbf{e}, The final material density predictions in the case of a linear elastic matrix containing soft, stiff or rigid inclusions. \textbf{f}, The final material density predictions in the case of a nonlinear hyperelastic matrix containing voids subject to large stretches.}
\label{fig:NCS_Ela}
\end{figure*}
%%%%

\textcolor{black}{\textbf{Voids in square elastic matrix.}} We first apply our framework to \textcolor{black}{the 2D square linear elastic matrix setup of Fig.~\ref{fig:Geometry}a in the presence of hidden voids} (cases 1, 2, 4, 9, 11, 16, 18 in Tab.~\ref{tab:ElasticMatrixCases}). As the various loss components are minimized during training (Fig.~\ref{fig:NCS_Ela}a), the material density $\rho$ evolves and splits in a way that progressively reveals the number, locations, and shapes of the hidden voids (Fig.~S2 and \href{https://www.dropbox.com/s/tm26buzgn0w35s1/Movie1.mp4?dl=0}{Movie 1} in Supplementary Materials), without advance knowledge of their topology. By the end of the training, the transition regions where the material density goes from 0 to 1 have uniform thickness along all internal boundaries (Fig.~\ref{fig:NCS_Ela}d), thanks to the eikonal regularization that encourages the level-set gradient $\nabla \phi$ to have unit norm in a band along the material boundaries $\phi = 0$ (Fig.~\ref{fig:NCS_Ela}b,c). The agreement between the final inferred shapes and the ground truth is remarkable, with our framework able to recover intricate details such as the three lobes and the concave surfaces of the star-shaped void (Fig.~\ref{fig:NCS_Ela}d, second from left), or the exact aspect ratio and location of a thin slit (Fig.~\ref{fig:NCS_Ela}d, third from left). The stress and strain fields of the deformed matrix are also obtained as a byproduct of the solution process (Fig.~S3 in Supplementary Materials).

The only case that is not completely identified is the U-shaped void (Fig.~\ref{fig:NCS_Ela}d, first from right), which demonstrates an important limit of the generic inverse problem. In order to be uniquely identifiable theoretically, each void must be simply-connected (see Supplementary Materials).  Voids that are close to having disconnected material in their interior, such as the U, cause the inverse problem to be ill-conditioned, and thus challenging for numerical algorithms to solve. In the U-shaped void, this can be seen by the minuscule influence the inner lobe of the U exerts on the outer surface displacements, due to its negligible level of strain and stress (Fig.~S10 in Supplementary Materials).

\textcolor{black}{To investigate the effect of measurement noise on the accuracy of the results, we repeat cases 4, 9, and 18 in the presence of white Gaussian measurement noise of standard deviation $\sigma_\mathrm{noise}$, demonstrating strong robustness of the results with respect to noise (Fig.~S6 in Supplementary Materials). We also analyze quantitatively the relationship between noise level and results accuracy, resulting in some practical guidelines to minimize the effect of noise (see Supplementary Materials).} Finally, our framework maintains accurate results when reducing the number of surface measurement points or restricting measurements to a few surfaces (Figs.~S7, S8, S9 in Supplementary Materials).

\textcolor{black}{\textbf{Inclusions in square elastic matrix.}} Next, we consider cases involving linear elastic and rigid inclusions in the linear elastic matrix (cases 5, 6, 7, 12, 13, 14 in Tab.~\ref{tab:ElasticMatrixCases}). Our framework successfully identifies the inclusions in almost all cases (Fig.~\ref{fig:NCS_Ela}e). Inferred displacements and stresses of the deformed matrix (Fig.~S4 in Supplementary Materials) confirm the intuition that voids or soft inclusions soften the matrix while stiff or rigid inclusions harden the matrix. The U-shaped soft and stiff elastic inclusions (Fig.~\ref{fig:NCS_Ela}e, second and third from right) are better detected by the framework than their void or rigid counterparts (Fig.~\ref{fig:NCS_Ela}d, first from right and Fig.~\ref{fig:NCS_Ela}e, first from right), since an elastic inclusion induces some strain and stress on the inner lobe (Fig.~S10 in Supplementary Materials).

\textcolor{black}{\textbf{Voids in square hyperelastic matrix.} We} consider cases with the same void shapes considered previously, but this time embedded in a soft, incompressible neo-Hookean hyperelastic matrix (cases 3, 8, 10, 15, 17, 19 in Tab.~\ref{tab:ElasticMatrixCases}). 
The geometries are identified equally well (Fig.~\ref{fig:NCS_Ela}f) in this large deformation regime (\textcolor{black}{see the large strains in} Fig.~S5 in Supplementary Materials) as with linear elastic materials, which illustrates the ability of the framework to cope with nonlinear governing equations without any added complexity in the formulation or the implementation.

\textcolor{black}{\textbf{Rigid substrate under elastic layer.}} We finally apply our framework to the periodic elastic layer setup of Fig.~\ref{fig:Geometry}b, where a linear elastic material covers a hidden rigid substrate (cases 23, 24, 25 in Tab.~\ref{tab:ElasticLayerCases}).
%%%%
\begin{figure}
\centering
\includegraphics[width=0.49\textwidth]{Figures/NCS_PeriodicEla.pdf}
\caption{\textbf{Identification of substrate shape underneath a periodic linear elastic layer.} \textbf{a}, The various loss components that enforce the solution to match the surface measurement data, satisfy the governing equations, and obey the eikonal regularization, are being minimized during the training process. \textbf{b},\textbf{c}, The final level-set function $\phi$ and its gradient magnitude $|\nabla \phi|$ show the effect of the eikonal regularization, which makes $\phi$ a signed distance function in narrow band along the material boundary. \textbf{d}, The final material density $\rho$ reveals the shape of the buried rigid substrate.}
\label{fig:NCS_PeriodicEla}
\end{figure}
%%%%
Contrary to the matrix problem, this setup only provides access to measurements on the top surface, and the hidden geometry to be discovered is not completely surrounded by the elastic material. Our TO framework is nevertheless able to detect the correct depth and shape of the hidden substrate (Fig.~\ref{fig:NCS_PeriodicEla}), demonstrating its versatility.

\subsection*{\textcolor{black}{Advanced examples}}
\label{sec:AdvancedExamples}

%%%%
\begin{figure*}
\centering
\includegraphics[width=\textwidth]{Figures/NCS_Advanced.pdf}
\caption{\textcolor{black}{\textbf{Advanced examples. Top row: Identification of voids in a linear elastic half star.} \textbf{a}, Setup of the numerical experiment, where a half star is glued underneath a rigid plate and pulled by gravity. The measurements consist of the displacement along the wavy boundary as well as the resultant force and torque on the rigid plate. \textbf{b}, The final material density identified by our framework reveals the hidden voids. \textbf{Middle row: Identification of voids in a 3D linear elastic cube.} \textbf{a}, Setup of the numerical experiment, which is a 3D extension of the elastic square matrix example. The cube is pulled by a known uniform traction on two opposite sides, and the resulting displacement along the outer boundary is measured. \textbf{b}, The final material density identified by our framework reveals the hidden voids.} \textbf{\textcolor{black}{Bottom row:} Identification of a slender casting defect in a steel matrix.} \textbf{a}, Setup of the numerical experiment, which can be realized in practice with a temperature control unit and a thermal camera. \textbf{b}, The left side is heated to a constant temperature, modeled by a Dirichlet BC, while the remaining three sides are left exposed to air, modeled by a radiation BC. \textbf{c}, The measurements consist of the temperature profiles on the three sides exposed to air. \textbf{d}, The final material density identified by our framework reveals the slender void.}
\label{fig:Advanced}
\end{figure*}
%%%%

\textcolor{black}{Through several additional examples, we demonstrate how the versatility of PINNs allows our approach to be easily tailored} to various scenarios involving \textcolor{black}{complex object shapes,} 3D geometries, partial information, \textcolor{black}{and} other physical loading types. \textcolor{black}{For example, our framework successfully identifies hidden voids in a linear elastic half-star-shaped object pulled by gravity rather than applied surface stresses (Fig.~\ref{fig:Advanced}, top row; case 21 in Tab.~\ref{tab:ElasticMatrixCases}). For this case, we derived a new approach to implement hard-constrained traction-free BCs along curved boundaries in PINNs (see Supplementary Materials). We also applied our method to a 3D linear elastic cube pulled by opposite surface tractions (Fig.~\ref{fig:Advanced}, middle row; case 22 in Tab.~\ref{tab:ElasticMatrixCases}), successfully identifying the hidden cubical and spherical voids within. Moreover,} we demonstrate the practical applicability of our framework on a realistic and easily implementable \textcolor{black}{thermal imaging} setup in which we detect a casting defect in a hypothetical steel matrix by simply heating one side and measuring the temperature distribution on the remaining sides exposed to air with a thermal camera (Fig.~\ref{fig:Advanced}\textcolor{black}{, bottom row; case 26 in Tab.~\ref{tab:ThermalMatrixCases}}). \textcolor{black}{Finally,} in a separate \textcolor{black}{thermal imaging} setup, we identify a hidden inclusion in a nonlinearly conducting matrix \textcolor{black}{without knowing the BC or measurements along one side} (\textcolor{black}{Fig.~S11 in Supplementary Materials; cases 27, 28 in Tab.~\ref{tab:ThermalMatrixCases}}), which reveals our method's ability to \textcolor{black}{identify hidden objects despite the complete lack of information along an entire side}.  The ability to uniquely construct the hidden objects from data on only part of the boundary is guaranteed by the Theorem stated in the Problem formulation section.

% \textcolor{black}{\textbf{Voids in elastic half star.} We consider a half-star-shaped linear elastic matrix glued underneath a rigid plate and pulled by gravity (Fig.~\ref{fig:Advanced}a, top row; case 21 in Tab.~\ref{tab:ElasticMatrixCases}). The measurements consist of the displacement along the wavy boundary as well as the resultant force and torque acting on the rigid plate. Despite the complex geometry of the matrix, our framework is able to identify the voids (Fig.~\ref{fig:Advanced}b, top row). Note that for this case, we derived a novel approach to implement hard-constrained tensor BCs along curved boundaries in PINNs (see Supplementary Materials).}

% \textcolor{black}{\textbf{Voids in 3D elastic cube.} We consider a 3D linear elastic cube pulled by a known uniform traction on two opposite sides. (Fig.~\ref{fig:Advanced}a, middle row; case 22 in Tab.~\ref{tab:ElasticMatrixCases}). The measurements consist of the resulting displacement along the 6 faces of the cube. Not only are the cubical and spherical hidden voids successfully identified (Fig.~\ref{fig:Advanced}b, middle row), but we also highlight that implementing this case in our framework requires minimal extra effort compared to the prototypical 2D elastic matrix problem of Fig.~\ref{fig:Geometry}a.}

% \textcolor{black}{\textbf{Voids in thermally-conductive matrix.} We consider two noninvasive thermal imaging setups. In the first, a square matrix with constant conductivity is prescribed a known temperature on one side, while the remaining three sides are left exposed to air and their temperature is measured. In the other, a square matrix with a temperature-dependent conductivity is assigned different temperatures on two opposite faces and the remaining two sides are insulated. It is assumed that one side is completely inaccessible (no measurements and unknown BC), while temperature measurements are acquired on the remaining three sides.  a 3D linear elastic cube pulled by a known uniform traction on two opposite sides. (Fig.~\ref{fig:Advanced}a, middle row; case 22 in Tab.~\ref{tab:ElasticMatrixCases}).The measurements consist of the resulting displacement along the 6 faces of the cube. Our framework successfully identifies the cubical and spherical voids embedded within the elastic cube (Fig.~\ref{fig:Advanced}b, middle row).}

\section*{Discussion}

%%%%
\begin{figure*}
\centering
\includegraphics[width=\textwidth]{Figures/NCS_Reg.pdf}
\caption{\textbf{Comparison between eikonal regularization and alternative regularizations.} \textbf{a}, The eikonal regularization achieves a high IoU (intersection over union, a geometry detection accuracy metric equal to 1 in the perfect case) above 0.95 for any value of the regularization weight $\lambda_\mathrm{reg}$ within a range spanning three orders of magnitude. The results are consistent over 4 random initializations of the neural networks parameters, with the circles reporting the average value and the shade reporting the highest and lowest values. By contrast, the total variation diminishing (TVD), explicit penalization, and Solid Isotropic Material with Penalization (SIMP) regularizations never exceed IoU values above 0.93, with larger variability among realizations. \textbf{b}, The final material density $\rho$ obtained with each regularization mechanism for various values of the regularization weight $\lambda_\mathrm{reg}$ or exponent $p$ (shown in \textbf{a} by the shaded areas) demonstrates the efficacy of the eikonal regularization. The evolution of the solution during training using the eikonal regularization and $\lambda_\mathrm{reg} = 1$ is shown in \href{https://www.dropbox.com/s/ql1ko7e6kpf0cjr/Movie2.mp4?dl=0}{SI, Movie 2}.}
\label{fig:NCS_Reg}
\end{figure*}
%%%%

Like any material density-based TO method, the success of our PINN-based framework hinges on the presence of an appropriate regularization mechanism to penalize intermediate density values. Although we have shown that our novel eikonal regularization leads to consistently accurate results, other regularization approaches have been employed in classical adjoint-based TO methods \citep{dorn2006,sigmund2013}. These include the total variation diminishing (TVD) regularization \citep{chan2004,mei2016} that penalizes the $L_1$ norm of the density gradient $\nabla \rho$, the explicit penalization regularization \citep{allaire1993} that penalizes the integral over the domain of $\rho (1-\rho)$, and the Solid Isotropic Material with Penalization (SIMP) approach \citep{bendsoe1989} that relates material properties such as the shear modulus and the material density through a power-law with exponent $p$. The latter is the most popular regularization mechanism in structural optimization \citep{bendsoe2003}. However, when implemented in our PINN-based framework for the detection of hidden geometries, these methods yield inferior results to the eikonal regularization (Fig.~\ref{fig:NCS_Reg}). Indeed, we compare all four approaches on a challenging test case involving a linear elastic rectangular matrix pulled from the top and bottom and containing soft inclusions in the shape of the letters M, I, and T (case 20, Tab.~\ref{tab:ElasticMatrixCases}). {The measurements consist of the displacement along the outer boundary, similar to the previous square matrix examples.} We consider different values of the regularization weight $\lambda_\mathrm{reg}$ (for the eikonal, TVD and explicit penalization regularizations) and the exponent $p$ (for the SIMP regularization), and solve the inverse problem using four random initializations of the neural networks in each case. Not only was the eikonal regularization the only one to find the right shapes, it did so over three orders of magnitude of $\lambda_\mathrm{reg}$ \textcolor{black}{and consistently over all four trials}, demonstrating a desirable robustness with respect to $\lambda_\mathrm{reg}$ (Fig.~\ref{fig:NCS_Reg}). Finally, we note that adjoint-based methods using TVD or other types of regularization limit themselves to simple shapes like squares and circles, or fail to find the right number of shapes \citep{ameur2004,mei2016,mei2021}.

\textcolor{black}{The TO method that we have introduced uses PINNs to solve the inverse problem. Nonetheless, our proposed eikonal regularization is potentially applicable to other imaging frameworks relying on a material density parametrization of the geometry, including those based on adjoint methods. While these methods may offer greater computational efficiency \cite{mowlavi2023,du2023}, the ease of implementation of PINNs is a significant advantage that greatly enhances the practical applicability of our method. Naturally, PINNs are not devoid of challenges such as hyperparameter selection or difficult enforcement of singular BCs; but these challenges are to some extent shared by all optimization frameworks, and improvements to PINNs are continuously proposed (for example, see \cite{cho2024}). Moreover, PINNs capitalize on the inherent robustness of overparameterized neural networks to sparse and noisy data \cite{li2020,clark2023,molnar2023}, enabling our PINN-based framework to discover hidden shapes accurately even in the presence of sparse or noisy measurements (Figs.~S6, S7, S8, S9 in Supplementary Materials).}

Finally, some imaging methods assume the unknown geometry is comprised of elementary shapes like circles and ellipses as opposed to a material density field. This yields a simpler search space with a few scalar parameters defining the locations and sizes of these predefined shapes \citep{schnur1992,mellings1995,zhang2022}. Notably, Zhang et al.~\cite{zhang2022} implemented this approach with PINNs in order to detect elliptical voids and inclusions in linear-elastic rectangular bodies. The general applicability of this family of methods is limited by the requirement that the number and types of shapes be given ahead of time. Such a priori knowledge is not required in our proposed TO framework. % emphasize the similarity between Zhang's setup and ours

%[Option 2.] Such potential of PINNs for solving inverse imaging problems was also recognized by Zhang et al.~\cite{zhang2022}, who considered a similar setup as our prototypical matrix problem. Like some other methods \citep{schnur1992,mellings1995,zhang2022}, they parameterized the unknown geometry using elementary shapes like circles and ellipses as opposed to a material density field. This yields a simpler search space with a few scalar parameters defining the locations and sizes of these predefined shapes. The general applicability of this family of methods is limited by the requirement that the number and types of shapes be given ahead of time. Such a priori knowledge is not required in our proposed TO framework.

\textcolor{black}{A general limitation of the single-loading setup considered in this paper is that the material properties of the matrix and inclusions are assumed to be known ahead of time, which is a reasonable assumption in many applications. However, if such knowledge were unavailable, we expect from theoretical results on the Calder\'on problem that data from multiple loadings would enable the solver to simultaneously infer the material properties of the inclusions as well as their shapes, as realized for example in electrical impedance tomography \cite{cheney1999,adler2021}.}

In conclusion, we have presented a PINN-based TO framework with a novel eikonal regularization, which we have applied to the noninvasive detection of hidden inclusions. By representing the geometry through a material density field combined with the eikonal regularization, our framework is able to discover the number, shapes and locations of hidden structures, without any prior knowledge required regarding the number or the types of shapes to expect. Finally, \textcolor{black}{the introduction of the eikonal regularization opens a pathway for PINNs to be applied to a wide range of design optimization problems involving \textit{a priori} unknown topology and constrained by physical governing equations}. These include, for instance, the design of lenses that achieve targeted optical properties \citep{molesky2018,ma2021} or the design of structures and metamaterials that exhibit desirable mechanical, acoustic, or thermal properties \citep{bendsoe2003,zegard2016,kadic2019,kollmann2020,akerson2022,zhang2023fast,zhang2024chrono}.

\section*{Materials and methods}

\subsection*{List of experiments}

\textcolor{black}{To evaluate our TO framework, we study a wide range of test cases falling under three categories: an elastic matrix containing voids or inclusions, an elastic layer sitting on top of a rigid substrate, and a thermally conductive matrix containing a perfectly conductive or insulating inclusion. The precise mathematical formulation of the governing PDEs, applied BCs, and measurements corresponding to each case is provided in the Supplementary Materials.}

\textcolor{black}{\textbf{Elastic matrix.} The corresponding cases are listed in Tab.~\ref{tab:ElasticMatrixCases} and sorted according to the shape of the matrix, the number and shape of inclusions (to be discovered by the TO framework), and the constitutive properties of the matrix and inclusions. Cases 1 to 19 correspond to the 2D square matrix setup described in Fig.~\ref{fig:Geometry}a, where a traction is applied to the left and right sides of the matrix and displacement measurements are acquired along all four sides. Case 20 is a slight modification of that setup involving a rectangular matrix pulled from top and bottom. Case 21 is the setup described in the first row of Fig.~\ref{fig:Advanced}, where a half-star-shaped matrix is glued to a rigid plate and is pulled by gravity. The measurements consist of the displacement along the wavy boundary as well as the resultant force and torque on the rigid plate. Finally, case 22 is the setup described in the second row of Fig.~\ref{fig:Advanced}, where a 3D cube is subject to a traction on two opposite sides and displacement measurements are acquired along all six sides.}

\begin{table}
\centering
\setlength{\tabcolsep}{6pt}
\begin{tabular}{ l l l l l }
\toprule
Case & \multirow{2}{1cm}{Matrix shape} & \multirow{2}{1cm}{Inclusion shapes} & \multirow{2}{1cm}{Matrix material} & \multirow{2}{1cm}{Inclusion material} \\ \\
\toprule
1* & Square & \multirow{1}{2cm}{One circle} & LE & V \\
\midrule
2 & \multirow{2}{*}{Square} & \multirow{2}{2cm}{Two circles} & LE & V \\
3 & & & HE & V \\
\midrule
4*$^+$ & \multirow{5}{*}{Square} & \multirow{5}{2cm}{One star, one rectangle}  & LE & V \\
5 & & & LE & LE-soft \\
6 & & & LE & LE-stiff \\
7 & & & LE & R \\
8 & & & HE & V \\
\midrule
9*$^+$ & \multirow{2}{*}{Square} & \multirow{2}{2cm}{One slit} & LE & V \\
10 & & & HE & V \\
\midrule
11 & \multirow{5}{*}{Square} & \multirow{5}{2cm}{One U} & LE & V \\
12 & & & LE & LE-soft \\
13 & & & LE & LE-stiff \\
14 & & & LE & R \\
15 & & & HE & V \\
\midrule
16 & \multirow{2}{*}{Square} & \multirow{2}{2cm}{One T} & LE & V \\
17 & & & HE & V \\
\midrule
18$^+$ & \multirow{2}{*}{Square} & \multirow{2}{2cm}{Four circles} & LE & V \\
19 & & & HE & V \\
\midrule
\multirow{2}{*}{20} & \multirow{2}{*}{Rectangle} & \multirow{2}{2cm}{One M, one I and one T} &  \multirow{2}{*}{LE} & \multirow{2}{*}{LE-soft} \\ 
\\
\midrule
\multirow{2}{*}{21} & \multirow{2}{*}{Half-star} & \multirow{2}{2cm}{One circle, one rectangle} &  \multirow{2}{*}{LE} & \multirow{2}{*}{V} \\
\\
\midrule
\multirow{2}{*}{22} & \multirow{2}{*}{Cube (3D)} & \multirow{2}{2cm}{One sphere, one cube} &  \multirow{2}{*}{LE} & \multirow{2}{*}{V} \\
\\
\bottomrule
\end{tabular}
\caption{List of all elastic matrix cases, classified according to the geometry and elastic properties of the matrix and inclusions. LE: linear elastic with $E = E_0$ and $\nu = 0.3$; HE: incompressible neo-Hookoean hyperelastic with $\mu = 0.38$; LE-soft: linear elastic with $E = E_0/5$, $\nu = 0.3$; LE-stiff: linear elastic with $E = 5E_0$, $\nu = 0.3$; R: rigid; V: void. The star * and the plus $^+$ indicate that the corresponding case was evaluated using a varying number of surface measurement points and a non-zero amount of measurement noise, respectively. \label{tab:ElasticMatrixCases}}
\end{table}

\textcolor{black}{\textbf{Elastic layer.} The corresponding cases are listed in Tab.~\ref{tab:ElasticLayerCases} and sorted according to the shape of the bottom substrate (to be discovered by the TO framework). The general setup is shown Fig.~\ref{fig:Geometry}b, where the rigid substrate is hidden underneath a layer of elastic material in a periodic domain. A normal pressure is applied to the top of the layer and the resulting displacement of the top surface is measured. This case simulates the detection of large rigid structures buried underneath a compliant material, a situation encountered in diverse fields such as archaeology or medicine.}

\begin{table}
\setlength{\tabcolsep}{6pt}
\begin{tabular}{ l l l l }
\toprule
Case & Geometry & Layer & Substrate \\ 
\toprule
23 & Sinusoidal & LE & R \\
\midrule
24 & Pulse & LE & R \\
\midrule
25 & Random wave & LE & R \\
\bottomrule
\end{tabular}
\caption{List of all elastic layer cases, classified according to the shape of the substrate. LE: linear elastic with $E = E_0$ and $\nu = 0.3$; R: rigid. \label{tab:ElasticLayerCases}}
\end{table}

\textcolor{black}{\textbf{Thermally conductive matrix.} The corresponding cases are listed in Tab.~\ref{tab:ThermalMatrixCases} and sorted according to the type of thermal loading. Case 26 is the setup shown in the last row of Fig.~\ref{fig:Advanced}, where a square matrix with constant conductivity is prescribed a temperature on one side, while the remaining three sides are left exposed to air and their temperature is measured. This case aims to simulate the detection of a slender casting defect \cite{campbell2015} in a steel plate, using a heat transfer setup that is easily realisable experimentally with a temperature control unit and a thermal camera. The casting defect is modeled as a perfect insulator while the three exposed sides are modeled using a radiation BC, which takes the form of a nonlinear Robin BC. Cases 27 and 28 are the setup shown in Fig.~S11a of the Supplementary Materials, where a square matrix with temperature-dependent conductivity is assigned different temperatures on the left and right sides, and the top and bottom sides are insulated. It is assumed that one side is completely inaccessible in the sense that the applied BC and measurements are both unavailable, while temperature and flux measurements are acquired on the remaining three sides.}

\begin{table}
\centering
\setlength{\tabcolsep}{6pt}
\begin{tabular}{ l l l l l l }
\toprule
Case & \multirow{2}{1cm}{Loading type} & \multirow{2}{1cm}{Matrix shape} & \multirow{2}{1cm}{Inclusion shapes} & \multirow{2}{1cm}{Matrix material} & \multirow{2}{1cm}{Inclusion material} \\ \\
\toprule
26 & A & Square & One slit & C & PI \\
\midrule
27* & B & \multirow{2}{*}{Square} & \multirow{2}{*}{One slit}  & TD & PI \\
28* & B & & & TD & PC \\
\bottomrule
\end{tabular}
\caption{List of all thermal matrix cases, classified according to the loading type and thermal conductivity properties of the matrix and inclusions. A: Applied temperature difference between two opposite sides, remaining two sides are insulated. B: Applied temperature on one side, remaining three sides are left exposed to radiate heat. C: constant thermal conductivity; TD: temperature-dependent thermal conductivity; PI: perfectly insulating inclusion; PC: perfectly conductive inclusion. The star * indicates that the problem was solved assuming one of the four sides had unknown loading and no measurements. \label{tab:ThermalMatrixCases}}
\end{table}

\subsection*{FEM simulations}

\textcolor{black}{To obtain the measurement data for all cases considered in this paper, we perform FEM simulations in the software Abaqus, using its Standard (implicit) solver. Every 2D case is meshed using a linear density of 200 elements per unit length along each boundary, corresponding to between 25k to 80k total elements depending on domain size as well as number and shapes of voids or inclusions. For the mechanical loading experiments (Tabs.~\ref{tab:ElasticMatrixCases} and \ref{tab:ElasticLayerCases}), we employ bilinear quadrilateral CPE4 plain-strain elements for the cases involving a linear elastic material, and their hybrid constant-pressure counterpart CPE4H for the cases involving a hyperelastic material. For the thermal loading experiments (Tab.~\ref{tab:ThermalMatrixCases}), we employ biquadratic DC2D8 diffusive heat transfer elements.}

\subsection*{Acknowledgements}

The authors acknowledge the MIT SuperCloud and Lincoln Laboratory Supercomputing Center for providing computing resources.

% Bibliography
\bibliography{bibliography}

\end{document}
