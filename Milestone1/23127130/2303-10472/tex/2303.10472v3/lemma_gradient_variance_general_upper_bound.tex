
\begin{theoremEnd}[\keylemmaproofoption,category=upperboundkeylemmavariancegeneral]{lemma}\label{thm:gradient_variance_general_upper_bound}
  Let \(\vg_{M}\) be the \(M\)-sample gradient estimator of \(F\) (\cref{def:generic_elbo}) for some function \(f,h\) and let \(\rvvu\) be some random variable.
  Then, 
  {%
  \setlength{\belowdisplayskip}{1ex} \setlength{\belowdisplayshortskip}{1ex}%
  \setlength{\abovedisplayskip}{1ex} \setlength{\abovedisplayshortskip}{1ex}%
  \begin{align*}
    \mathbb{E} \norm{\vg_M }^2_2
    \leq
    \frac{1}{M} \mathbb{E}{ \norm{
      \nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)
      }_2^2
    }
    + \norm{ \nabla F\left(\vlambda\right) }^2_2.
  \end{align*}
  }%
\end{theoremEnd}
\vspace{-1ex}
%% \begin{proofsketch}
%%   We use the affine property of the variance,%
%%   {%
%%   \setlength{\belowdisplayskip}{1ex} \setlength{\belowdisplayshortskip}{1ex}%
%%   \setlength{\abovedisplayskip}{1ex} \setlength{\abovedisplayshortskip}{1ex}%
%%   \begin{align*}
%%     \mathrm{tr}\,\V{\textstyle \frac{1}{M} \sum_{m=1}^M \vg_m }
%%     =
%%     \frac{1}{M} \mathrm{tr}\,\V{
%%       \nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)
%%     }.
%%   \end{align*}
%%   }%
%%   This erases the effects of the deterministic elements of \(\vg\) (\textit{e.g.}, gradient of the regularization term), and simplifies the sample average.
%%   Also, this is the point where our proof can be further extended to data subsampling.
%% \end{proofsketch}
%\vspace{-2ex}
\begin{proofEnd}
  From the definition of variance,
  \begin{alignat}{2}
    &\mathbb{E} \norm{\vg_M }^2_2
    \nonumber
    \\
    &\;=
    \mathrm{tr}\,\V{ \vg_M } + \norm{\mathbb{E} \vg_M }^2_2,
    \nonumber
\shortintertext{following the definition in \cref{eq:def_gradient_M_est},}
    &\;=
    \mathrm{tr}\,\V{ \frac{1}{M} \sum_{m=1}^M \vg_m } + \norm{ \nabla F\left(\vlambda\right) }^2_2,
    \nonumber
\shortintertext{and then the definition in \cref{eq:def_gradient_m_est},}
    &\;=
    \mathrm{tr}\,\V{
      \frac{1}{M} \sum_{m=1}^M \nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu_m\right)\right) + \nabla h\left(\vlambda\right)
    }
    + \norm{ \nabla F\left(\vlambda\right) }^2_2,
    \nonumber
\shortintertext{by the linearity of variance,}
    &\;=
    \frac{1}{M} \mathrm{tr}\,\V{
      \nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)
    }
    + \norm{ \nabla F\left(\vlambda\right) }^2_2
    \nonumber
    \\
    &\;=
    \frac{1}{M} \left(
    \mathbb{E}{ \norm{\nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)}_2^2 }
    -
    \norm{ \mathbb{E}{ \nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)} }_2^2
    \right)
    \nonumber
    \\
    &\qquad+ \norm{ \nabla F\left(\vlambda\right) }^2_2
    \label{eq:thm_gradient_variance_general_definition}
    \\
    &\;\leq
    \frac{1}{M} \mathbb{E}{ \norm{
      \nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)
      }_2^2
    }
    + \norm{ \nabla F\left(\vlambda\right) }^2_2.
    \nonumber
  \end{alignat}
  % The regularization term is neglected since it is a deterministic function.
  % This means the bound holds for both the entropy form and the KL form.
  % The last inequality introduces some looseness when \(\norm{\mathbb{E}{ \nabla f\left(\vt_{\vlambda}\left(\rvvu\right)\right) }}_2^2\) is large.
  % This means that the variance bound is loose initially but will become tighter as we progress.
\end{proofEnd}

%%% Local Variables:
%%% TeX-master: "main"
%%% End:
