

\begin{restatable}[]{lemma}{prAtEndRestatex}\label{thm:prAtEndx}Let \(\vt _{\vlambda }: \mathbb {R}^d \mapsto \mathbb {R}^d\) be defined as in \cref {def:reparam} with parameters \(\vlambda = \left (\vm , \mC \right )\) such that \(\vm \in \mathbb {R}^d\) and \(\mC \in \mathbb {R}^{d \times d}\). Also, let \(\rvvu \sim \varphi \), where \(\varphi \) is defined as in \cref {assumption:symmetric_standard}. Then, \begin {alignat*}{2} \mathbb {E}\vt _{\vlambda }\left (\rvvu \right ) \left (1 + \norm {\rvvu }_2^2\right ) = \left (d + 1\right ) \vm . \end {alignat*}\end{restatable}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndx}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofx{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof]\phantomsection\label{proof:prAtEndx}Since \(\rvu _i\) follows a symmetric and standardized distribution, \(\mathbb {E}\rvu _i^3 = 0, \mathbb {E} \rvu _i^2 = 1\). Then, \begin {alignat*}{2} \mathbb {E}\vt _{\vlambda }\left (\rvvu \right ) \left (1 + \norm {\rvvu }_2^2\right ) &= \mathbb {E} \left (\mC \rvvu + \vm \right ) \left (1 + \norm {\rvvu }_2^2\right ) \\ &= \mC \, \mathbb {E} \rvvu \left (1 + \norm {\rvvu }_2^2\right ) + \vm \left (1 + \mathbb {E} \norm {\rvvu }_2^2\right ), \shortintertext {applying \cref {thm:u_identities},} &= \left ( \mathbb {E}\rvu _i^3 \right ) \mC \mathbf {1} + \vm \left (1 + d \, \mathbb {E} \rvu _i^2\right ), \shortintertext {and by~\cref {assumption:symmetric_standard},} &= \left (d + 1\right ) \vm . \end {alignat*}\end{proof}

\begin{restatable}[]{lemma}{prAtEndRestatexi}\label{thm:prAtEndxi}\label {thm:general_quad_reparam} Let \(\vt _{\vlambda }: \mathbb {R}^d \mapsto \mathbb {R}^d\) be defined as in \cref {def:reparam} with parameters \(\vlambda = \left (\vm , \mC \right )\) such that \(\vm \in \mathbb {R}^d\) and \(\mC \in \mathbb {R}^{d \times d}\). Also, let \(\mSigma \in \mathbb {R}^{d \times d}\) be some matrix, \(\vmu \in \mathbb {R}^d\) be some vector, and \(\rvvu \sim \varphi \) be a vector-valued random variable, where \(\varphi \) is defined as in \cref {assumption:symmetric_standard}. Then, \begin {align*} &\mathbb {E} \, {\left ( \vt _{\vlambda }\left (\rvvu \right ) - \vmu \right )}^{\top } \mSigma \left (\vt _{\vlambda }\left (\rvvu \right ) - \vmu \right ) \\ &\;= {\left (\vm - \vmu \right )}^{\top } \mSigma \left (\vm - \vmu \right ) + \mathrm {tr}\left ({\mSigma }^{-1} \mC \mC ^{\top }\right ). \end {align*}\end{restatable}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxi}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxi{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof]\phantomsection\label{proof:prAtEndxi}\begin {alignat}{2} &\mathbb {E} {\left ( \vt _{\vlambda }\left (\rvvu \right ) - \vmu \right )}^{\top } \mSigma \, \left (\vt _{\vlambda }\left (\rvvu \right ) - \vmu \right ) \nonumber \\ &\;= \mathbb {E}\, {\vt _{\vlambda }\left (\rvvu \right )}^{\top } \mSigma \, {\vt _{\vlambda }\left (\rvvu \right )} -2\, \vmu ^{\top } {\mSigma } \, \mathbb {E}\vt _{\vlambda }\left (\rvvu \right ) + \vmu ^{\top } {\mSigma } \, \vmu , \nonumber \shortintertext {where \(\mathbb {E}\vt _{\vlambda }\left (\rvvu \right ) = \mC \mathbb {E}{\rvvu } + \vm \), and by \cref {assumption:symmetric_standard},} &\;= \mathbb {E}\, {\vt _{\vlambda }\left (\rvvu \right )}^{\top } \mSigma \, {\vt _{\vlambda }\left (\rvvu \right )} -2\, \vmu ^{\top } {\mSigma } \, \vm + \vmu ^{\top } {\mSigma } \, \vmu .\label {eq:thm:general_quad_reparam_eq1} \end {alignat} Furthermore, \begin {alignat*}{2} &\mathbb {E} {\vt _{\vlambda }\left (\rvvu \right )}^{\top } \mSigma \, {\vt _{\vlambda }\left (\rvvu \right )} \\ &\;= \mathbb {E}{\left (\mC \rvvu + \vm \right )}^{\top } \mSigma \left (\mC \rvvu + \vm \right ) \\ &\;= \mathbb {E} \rvvu ^{\top } \mC ^{\top } \mSigma \, \mC \rvvu + \vm ^{\top } \mSigma \, \mC \, \mathbb {E} \rvvu + \mathbb {E} \rvvu ^{\top } \mC ^{\top } \mSigma \vm ^{\top } + \vm ^{\top } \mSigma \, \vm , \shortintertext {by \cref {assumption:symmetric_standard},} &\;= \mathbb {E} \rvvu ^{\top } \mC ^{\top } {\mSigma } \, \mC \rvvu + \vm ^{\top } \mSigma \, \vm , \shortintertext {invoking the trace trick,} &\;= \mathbb {E} \mathrm {tr}\left ( \rvvu ^{\top } \mC ^{\top } {\mSigma }\, \mC \rvvu \right ) + \vm ^{\top } \mSigma \, \vm , \shortintertext {pusing the expectation into the trace,} &\;= \mathrm {tr}\left (\mathbb {E} \rvvu \rvvu ^{\top } \mC ^{\top } {\mSigma }\, \mC \right ) + \vm ^{\top } \mSigma \, \vm , \shortintertext {invoking \cref {thm:u_identities},} &\;= \mathrm {tr}\left (\mC ^{\top } {\mSigma }\, \mC \right ) + \vm ^{\top } \mSigma \, \vm \\ &\;= \mathrm {tr}\left ({\mSigma } \, \mC \mC ^{\top }\right ) + \vm ^{\top } \mSigma \, \vm . \end {alignat*} Applying this to \cref {eq:thm:general_quad_reparam_eq1}, \begin {alignat*}{2} &\mathbb {E} {\left ( \vt _{\vlambda }\left (\rvvu \right ) - \vmu \right )}^{\top } {\mSigma }^{-1} \left (\vt _{\vlambda }\left (\rvvu \right ) - \vmu \right ) \\ &\;= \mathrm {tr}\left ({\mSigma }^{-1} \mC \mC ^{\top }\right ) + \vm ^{\top } \mSigma ^{-1} \vm -2\, \vmu ^{\top } {\mSigma }^{-1} \vm + \vmu ^{\top } {\mSigma }^{-1} \vmu \\ &\;= {\left (\vm - \vmu \right )}^{\top } {\mSigma }^{-1} \left (\vm - \vmu \right ) + \mathrm {tr}\left ({\mSigma }^{-1} \mC \mC ^{\top }\right ). \end {alignat*}\end{proof}

\begin{restatable}[]{corollary}{prAtEndRestatexii}\label{thm:prAtEndxii}\label {thm:q_quad_reparam} Let \(\vt _{\vlambda }: \mathbb {R}^d \mapsto \mathbb {R}^d\) be defined as in \cref {def:reparam} with parameters \(\vlambda = \left (\vm , \mC \right )\) such that \(\vm \in \mathbb {R}^d\) and \(\mC \in \mathbb {R}^{d \times d}\). Also, let \(\rvvu \sim \varphi \) be a vector-valued random variable, where \(\varphi \) is defined as in \cref {assumption:symmetric_standard}. Then, \begin {align*} \mathbb {E} \, {\left ( \vt _{\vlambda }\left (\rvvu \right ) - \vm \right )}^{\top } {\left (\mC \mC ^{\top }\right )}^{-1} \left (\vt _{\vlambda }\left (\rvvu \right ) - \vm \right ) = d. \end {align*}\end{restatable}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof]\phantomsection\label{proof:prAtEndxii}From, \cref {thm:general_quad_reparam} we have \begin {alignat*}{2} &\mathbb {E} \, {\left ( \vt _{\vlambda }\left (\rvvu \right ) - \vm \right )}^{\top } {\left (\mC \mC ^{\top }\right )}^{-1} \left (\vt _{\vlambda }\left (\rvvu \right ) - \vm \right ) \\ &\;= {\left (\vm - \vm \right )}^{\top } {\left (\mC \mC ^{\top }\right )}^{-1} \left (\vm - \vm \right ) + \mathrm {tr}\left ({\left ( \mC \mC ^{\top } \right )}^{-1} \mC \mC ^{\top }\right ) \\ &\;= \mathrm {tr}\left (\mI \right ) \\ &\;= d. \end {alignat*}\end{proof}

\begin{restatable}[]{lemma}{prAtEndRestatexiii}\label{thm:prAtEndxiii}\label {thm:general_grad_norm_reparam} Let \(\vt _{\vlambda }: \mathbb {R}^d \mapsto \mathbb {R}^d\) be defined as in \cref {def:reparam} with parameters \(\vlambda = \left (\vm , \mC \right )\) such that \(\vm \in \mathbb {R}^d\) and \(\mC \in \mathbb {R}^{d \times d}\). Also, let \(\mSigma _1, \mSigma _2 \in \mathbb {R}^{d \times d}\) be some matrices, \(\vmu _1, \vmu _2 \in \mathbb {R}^{d}\) be some vectors, and \(\rvvu = \left (\rvu _1, \ldots , \rvu _d \right )\) be a vector-valued random variable sampled as \(\rvvu \sim \varphi \), where \(\varphi \) is defined as in \cref {assumption:symmetric_standard} with kurtosis \(\kappa = \mathbb {E}\rvu _i^4\). Then, \begin {alignat*}{2} &\mathbb {E} {\left (\vt _{\vlambda }\left (\rvvu \right ) - \vmu _1\right )}^{\top } \mSigma _1 \mSigma _2 \left (\vt _{\vlambda }\left (\rvvu \right ) - \vmu _2\right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \\ &\;= \left (d + 1\right ) \vmu _1^{\top } \mSigma _1 \mSigma _2 \vmu _2 + \left (d + \kappa \right ) \mathrm {tr}\left (\mC \mC ^{\top } \mSigma _1 \mSigma _2 \right ). \end {alignat*}\end{restatable}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxiii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxiii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof]\phantomsection\label{proof:prAtEndxiii}\begin {alignat}{2} &\mathbb {E} {\left (\vt _{\vlambda }\left (\rvvu \right ) - \vmu _1\right )}^{\top } \mSigma _1 \mSigma _2 \left (\vt _{\vlambda }\left (\rvvu \right ) - \vmu _2\right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\;= \mathbb {E} {\vt _{\vlambda }\left (\rvvu \right )}^{\top } \mSigma _1 \mSigma _2 \, \vt _{\vlambda }\left (\rvvu \right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\qquad - \vmu _1^{\top } \mSigma _1 \mSigma _2 \, \mathbb {E} \vt _{\vlambda }\left (\rvvu \right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\qquad - \mathbb {E} {\left (\vt _{\vlambda }\left (\rvvu \right ) \left ( 1 + \norm {\rvvu }_2^2 \right )\right )}^{\top } \mSigma _1 \mSigma _2 \vmu _1 \nonumber \\ &\qquad + \vmu _1^{\top } \mSigma _1 \mSigma _2 \vmu _2 \, \mathbb {E}\left ( 1 + \norm {\rvvu }_2^2 \right ), \nonumber \shortintertext {invoking \cref {thm:u_identities},} &\;= \mathbb {E} {\vt _{\vlambda }\left (\rvvu \right )}^{\top } \mSigma _1 \mSigma _2 \, \vt _{\vlambda }\left (\rvvu \right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\qquad - \mathbb {E}\rvu _i^3 \, \vmu _1^{\top } \mSigma _1 \mSigma _2 \mathbf {1} \nonumber \\ &\qquad - \mathbb {E}\rvu _i^3 \, \mathbf {1}^{\top } \mSigma _1 \mSigma _2 \vmu _1 \nonumber \\ &\qquad + \left ( 1 + d\,\mathbb {E}\rvu _i^2 \right ) \vmu _1^{\top } \mSigma _1 \mSigma _2 \vmu _2, \nonumber \shortintertext {and due to \cref {assumption:symmetric_standard},} &\;= \mathbb {E} {\vt _{\vlambda }\left (\rvvu \right )}^{\top } \mSigma _1 \mSigma _2 \, \vt _{\vlambda }\left (\rvvu \right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \label {eq:general_grad_norm reparam_eq1} \\ &\qquad + \left ( 1 + d \right ) \vmu _1^{\top } \mSigma _1 \mSigma _2 \vmu _2.\label {eq:general_grad_norm reparam_eq2} \end {alignat} Now for \cref {eq:general_grad_norm reparam_eq1}, \begin {alignat}{2} &\mathbb {E} {\vt _{\vlambda }\left (\rvvu \right )}^{\top } \mSigma _1 \mSigma _2 \, \vt _{\vlambda }\left (\rvvu \right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\;= \mathbb {E} {\left (\mC \rvvu + \vm \right )}^{\top } \mSigma _1 \mSigma _2 \left (\mC \rvvu + \vm \right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\;= \mathbb {E} \mathrm {tr}\left ( \rvvu ^{\top } \mC ^{\top } \mSigma _1 \mSigma _2 \mC \rvvu \right ) \nonumber \\ &\qquad + \mathbb {E} \mathrm {tr}\left ( \rvvu ^{\top } \mC ^{\top } \mSigma _1 \mSigma _2 \mC \, \rvvu \rvvu ^{\top } \rvvu \right ) \label {eq:thm:general_grad_norm_reparam_eq1} \\ &\qquad + \vm ^{\top } \mSigma _1 \mSigma _2 \mC \, \mathbb {E} \rvvu \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\qquad + \mathbb {E} \rvvu ^{\top } \left ( 1 + \norm {\rvvu }_2^2 \right ) \mC ^{\top } \mSigma _1 \mSigma _2 \vm \nonumber \\ &\qquad + \vm ^{\top } \mSigma _1 \mSigma _2 \vm \, \mathbb {E} \rvvu \left ( 1 + \norm {\rvvu }_2^2 \right ), \nonumber \shortintertext {using the cyclic property of the trace on \cref {eq:thm:general_grad_norm_reparam_eq1},} &\;= \mathrm {tr}\left ( \mathbb {E} \rvvu \rvvu ^{\top } \mC ^{\top } \mSigma _1 \mSigma _2 \mC \right ) \nonumber \\ &\qquad + \mathrm {tr}\left ( \mC ^{\top } \mSigma _1 \mSigma _2 \mC \, \mathbb {E} \rvvu \rvvu ^{\top } \rvvu \rvvu ^{\top } \right ) \nonumber \\ &\qquad + \vm ^{\top } \mSigma _1 \mSigma _2 \mC \, \mathbb {E} \rvvu \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\qquad + \mathbb {E} \rvvu ^{\top } \left ( 1 + \norm {\rvvu }_2^2 \right ) \mC ^{\top } \mSigma _1 \mSigma _2 \, \vm \nonumber \\ &\qquad + \vm ^{\top } \mSigma _1 \mSigma _2 \vm \, \mathbb {E} \rvvu \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \shortintertext {invoking \cref {thm:u_identities},} &\;= \mathrm {tr}\left ( \left (\mathbb {E}\rvu _i^2\right ) \mI \mC ^{\top } \mSigma _1 \mSigma _2 \mC \right ) \nonumber \\ &\qquad + \mathrm {tr}\left ( \mC ^{\top } \mSigma _1 \mSigma _2 \mC \left (\left (d-1\right ) {\left (\mathbb {E}\rvu _i^2\right )}^2 + \mathbb {E}\rvu _i^4 \right ) \mI \right ) \nonumber \\ &\qquad + \vm ^{\top } \mSigma _1 \mSigma _2 \mC \, \left (\mathbb {E} \rvu _i^3\right ) \mathbf {1} \nonumber \\ &\qquad + \left (\mathbb {E} \rvu _i^3\right ) \mathbf {1}^{\top } \mC ^{\top } \mSigma _1 \mSigma _2 \vm \nonumber \\ &\qquad + \vm ^{\top } \mSigma _1 \mSigma _2 \vm \, \left ( \mathbb {E} \rvu _i^3 \right ) \mathbf {1}, \nonumber \shortintertext {and due to \cref {assumption:symmetric_standard},} &\;= \mathrm {tr}\left ( \mC ^{\top } \mSigma _1 \mSigma _2 \mC \right ) + \left (d - 1 + \kappa \right ) \mathrm {tr}\left ( \mC ^{\top } \mSigma _1 \mSigma _2 \mC \right ) \nonumber \\ &\;= \left (d + \kappa \right ) \mathrm {tr}\left (\mC ^{\top } \mSigma _1 \mSigma _2 \mC \right ) \nonumber \\ &\;= \left (d + \kappa \right ) \mathrm {tr}\left (\mC \mC ^{\top } \mSigma _1 \mSigma _2 \right ). \nonumber \end {alignat} Finally, applying this to \cref {eq:general_grad_norm reparam_eq2}, \begin {alignat*}{2} &\mathbb {E} \left (\vt _{\vlambda }\left (\rvvu \right ) - \vmu _1\right ) \mSigma _1 \mSigma _2 \left (\vt _{\vlambda }\left (\rvvu \right ) - \vmu _2\right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\;= \left (d + 1\right ) \vmu _1^{\top } \mSigma _1 \mSigma _2 \vmu _2 + \left (d + \kappa \right ) \mathrm {tr}\left (\mC \mC ^{\top } \mSigma _1 \mSigma _2 \right ). \end {alignat*}\end{proof}

\begin{restatable}[]{corollary}{prAtEndRestatexiv}\label{thm:prAtEndxiv}\label {thm:q_grad_norm_reparam} Let \(\vt _{\vlambda }: \mathbb {R}^d \mapsto \mathbb {R}^d\) be defined as in \cref {def:reparam} with parameters \(\vlambda = \left (\vm , \mC \right )\) such that \(\vm \in \mathbb {R}^d\) and \(\mC \in \mathbb {R}^{d \times d}\). Also, let \(\rvvu = \left (\rvu _1, \ldots , \rvu _d \right )\) be a vector-valued random variable sampled as \(\rvvu \sim \varphi \), where \(\varphi \) is defined as in \cref {assumption:symmetric_standard} with kurtosis \(\kappa = \mathbb {E}\rvu _i^4\). Then, \begin {alignat*}{2} &\mathbb {E} \left (\vt _{\vlambda }\left (\rvvu \right ) - \vm \right ) {\left ( \mC \mC ^{\top }\right )}^{-\top } {\left ( \mC \mC ^{\top }\right )}^{-1} \left (\vt _{\vlambda }\left (\rvvu \right ) - \vm \right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \\ &\;= \left (d + 1\right ) \vm ^{\top } {\left ( \mC \mC ^{\top }\right )}^{-\top } {\left ( \mC \mC ^{\top }\right )}^{-1} \vm + \left (d + \kappa \right ) \mathrm {tr}\left ( {\left ( \mC \mC ^{\top } \right )}^{-1} \right ). \end {alignat*}\end{restatable}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxiv}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxiv{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof]\phantomsection\label{proof:prAtEndxiv}From \cref {thm:general_grad_norm_reparam}, we have \begin {alignat}{2} &\mathbb {E} {\left (\vt _{\vlambda }\left (\rvvu \right ) - \vm \right )}^{\top } {\left ( \mC \mC ^{\top }\right )}^{-\top } {\left ( \mC \mC ^{\top }\right )}^{-1} \left (\vt _{\vlambda }\left (\rvvu \right ) - \vm \right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\;= \left (d + 1\right ) \vm ^{\top } {\left ( \mC \mC ^{\top }\right )}^{-\top } {\left ( \mC \mC ^{\top }\right )}^{-1} \vm \nonumber \\ &\quad + \left (d + \kappa \right ) \mathrm {tr}\left (\mC \mC ^{\top } {\left ( \mC \mC ^{\top }\right )}^{-\top } {\left ( \mC \mC ^{\top }\right )}^{-1}\right ).\label {thm:q_grad_norm_reparam_eq1} \end {alignat} Since, by the basic properties of the trace, \begin {alignat*}{2} \mathrm {tr}\left (\mC \mC ^{\top } {\left ( \mC \mC ^{\top }\right )}^{-\top } {\left ( \mC \mC ^{\top }\right )}^{-1}\right ) &= \mathrm {tr}\left ( {\left ( \mC \mC ^{\top }\right )}^{-1} \mC \mC ^{\top } {\left ( \mC \mC ^{\top }\right )}^{-\top } \right ) \\ &= \mathrm {tr}\left ( \mI \, {\left ( \mC \mC ^{\top }\right )}^{-\top } \right ) \\ &= \mathrm {tr}\left ( {\left ( \mC \mC ^{\top }\right )}^{-\top } \right ) \\ &= \mathrm {tr}\left ( {\left ( \mC \mC ^{\top } \right )}^{-1} \right ), \end {alignat*} \cref {thm:q_grad_norm_reparam_eq1} becomes \begin {alignat*}{2} &\mathbb {E} {\left (\vt _{\vlambda }\left (\rvvu \right ) - \vm \right )}^{\top } {\left ( \mC \mC ^{\top }\right )}^{-\top } {\left ( \mC \mC ^{\top }\right )}^{-1} \left (\vt _{\vlambda }\left (\rvvu \right ) - \vm \right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \\ &\;= \left (d + 1\right ) \vm ^{\top } {\left ( \mC \mC ^{\top }\right )}^{-\top } {\left ( \mC \mC ^{\top }\right )}^{-1} \vm + \left (d + \kappa \right ) \mathrm {tr}\left ( {\left ( \mC \mC ^{\top } \right )}^{-1} \right ). \end {alignat*}\end{proof}

\prAtEndRestatexv*

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxv}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxv{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof]\phantomsection\label{proof:prAtEndxv}\par The STL estimator is obtained by setting \begin {alignat*}{2} f\left ( \vz \right ) = -\log p\left (\vz , \vx \right ) + \log q_{\vgamma }\left ( \vz \right ) \lvert _{\vgamma = \vlambda }. \end {alignat*} We first consider the log joint likelihood of the model to be \begin {alignat*}{2} \log p\left (\vz , \vx \right ) = -\frac {1}{2} {\left (\vz - \vmu \right )}^{-1} \mSigma ^{-1} \left (\vz - \vmu \right ), \end {alignat*} which is the unnormalized log probability density of a multivariate normal distribution with mean \(\vmu \) and covariance \(\mSigma \). We also set the variational family to be multivariate normal with mean (location) \(\vm \) and covariance (scale) \(\mC \mC ^{\top }\). Given these, the objective function is \begin {alignat*}{2} F\left (\vlambda \right ) &= \mathbb {E} f\left (\vt _{\vlambda }\left (\rvvu \right )\right ) \\ &= \mathbb {E}\log p\left (\vt _{\vlambda }\left (\rvvu \right )\right ) - \mathbb {E}\log q_{\vgamma }\left (\vt _{\vlambda }\left (\rvvu \right )\right ) \big \lvert _{\vgamma = \vlambda } \end {alignat*} \par From~\cref {thm:general_quad_reparam}, the likelihood term is \begin {alignat*}{2} &\mathbb {E}\log p\left (\vt _{\vlambda }\left (\rvvu \right )\right ) \\ &\;= -\frac {1}{2} {\left (\vm - \vmu \right )}^{\top } \mSigma ^{-1} \left (\vm - \vmu \right ) - \frac {1}{2} \mathrm {tr}\left (\mSigma ^{-1} \mC \mC ^{\top } \right ), \end {alignat*} while from~\cref {thm:q_quad_reparam}, the entropy term is \begin {alignat*}{2} &\mathbb {E}\log q_{\vlambda }\left (\vt _{\vlambda }\left (\rvvu \right )\right ) \\ &\;= -\frac {1}{2} \mathbb {E} {\left ( \vt _{\vlambda }\left (\rvvu \right ) - \vm \right )}^{\top } \mS ^{-1} \left (\vt _{\vlambda }\left (\rvvu \right ) - \vm \right ) - \frac {1}{2}\log \abs {\mS } + Z, \\ &\;= -\frac {1}{2} d - \frac {1}{2}\log \abs {\mS } + Z, \end {alignat*} where, \(\mS = \mC \mC ^{\top }\) and \(Z\) is a constant independent of \(\vm \) and \(\mC \). The derivative of the \(f\) is given as \begin {alignat}{2} &\nabla f\left (\vt _{\vlambda }\left (\vu \right )\right ) \nonumber \\ &\;= -\nabla \log p\left (\vt _{\vlambda }\left (\vu \right )\right ) + \nabla \log q_{\vgamma }\left (\vt _{\vlambda }\left (\vu \right )\right ) \lvert _{\vgamma = \vlambda } \nonumber \\ &\;= \mSigma ^{-1} \left (\vt _{\vlambda }\left (\vu \right ) - \vmu \right ) - {\mS }^{-1} \left ( \vt _{\vgamma }\left (\vu \right ) - \vm \right ) \lvert _{\vgamma = \vlambda }.\label {eq:gradient_lower_bound_f_derivative} \end {alignat} \par Given \cref {thm:sample_mean_estimator}, the second moment of the \(M\)-sample gradient can be decomposed as \begin {alignat*}{2} \mathbb {E} \norm {\vg \left (\vlambda \right )}_2^2 = \frac {1}{M} \mathbb {E} \norm { \nabla _{\vlambda } f\left ( \vt _{\vlambda }\left (\rvvu \right ) \right ) }_2^2 + \frac {M-1}{M} \norm { \nabla F\left (\vlambda \right ) }_2^2 \end {alignat*} \par We now compute the expectation of the squared gradient norm. First, by starting from \cref {thm:variational_gradient_norm_identity}, \begin {alignat}{2} &\mathbb {E}\norm { \nabla _{\vlambda } f\left ( \vt _{\vlambda }\left (\rvvu \right ) \right ) }_2^2 \nonumber \\ &\;= \mathbb {E} \norm { \nabla f\left ( \vt _{\vlambda }\left (\rvvu \right ) \right ) }_2^2 \left ( 1 + \norm {\rvvu }_2^2 \right ), \nonumber \shortintertext {plugging in \cref {eq:gradient_lower_bound_f_derivative},} &\;= \mathbb {E} \norm {\, \mSigma ^{-1} \left (\vt _{\vlambda }\left (\vu \right ) - \vmu \right ) - {\mS }^{-1} \left ( \vt _{\vlambda }\left (\vu \right ) - \vm \right )\,}^2_2 \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\;= \mathbb {E} {\left (\vt _{\vlambda }\left (\vu \right ) - \vmu \right )}^{\top } \mSigma ^{-\top } \mSigma ^{-1} \left (\vt _{\vlambda }\left (\vu \right ) - \vmu \right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\qquad - 2\,\mathbb {E} {\left (\vt _{\vlambda }\left (\vu \right ) - \vmu \right )}^{\top } \mSigma ^{-\top } \mS ^{-1} \left (\vt _{\vlambda }\left (\vu \right ) - \vm \right ) \left ( 1 + \norm {\rvvu }_2^2 \right ) \nonumber \\ &\qquad + \mathbb {E} {\left (\vt _{\vlambda }\left (\vu \right ) - \vm \right )}^{\top } \mS ^{-\top } \mS ^{-1} \left (\vt _{\vlambda }\left (\vu \right ) - \vm \right ) \left ( 1 + \norm {\rvvu }_2^2 \right ), \nonumber \shortintertext {applying \cref {thm:general_grad_norm_reparam},} &\;= \left (d+1\right ) \vmu ^{\top } \mSigma ^{-\top } \mSigma ^{-1} \vmu + \left (d+\kappa \right ) \mathrm {tr}\left (\mS \mSigma ^{-\top } \mSigma ^{-1}\right ) \nonumber \\ &\qquad - 2 \, \left (d+1\right ) \vmu ^{\top } \mSigma ^{-\top } \mS ^{-1} \vm - 2\,\left (d+\kappa \right ) \mathrm {tr}\left (\mS \mSigma ^{-\top } \mS ^{-1}\right ) \nonumber \\ &\qquad + \left (d+1\right ) \vm ^{\top } \mS ^{-\top } \mS ^{-1} \vm + \left (d+\kappa \right ) \mathrm {tr}\left (\mS ^{-1}\right ), \nonumber \\ \shortintertext {and after regroupping the terms,} &\;= \left (d+1\right ) \left ( \vmu ^{\top } \mSigma ^{-\top } \mSigma ^{-1} \vmu - 2 \vmu ^{\top } \mSigma ^{-\top } \mS ^{-1} \vm + \vm ^{\top } \mS ^{-\top } \mS ^{-1} \vm \right ) \nonumber \\ &\qquad + \left (d+\kappa \right ) \left ( \mathrm {tr}\left (\mS \mSigma ^{-\top } \mSigma ^{-1}\right ) -2 \mathrm {tr}\left (\mS \mSigma ^{-\top } \mS ^{-1}\right ) + \mathrm {tr}\left (\mS ^{-1}\right ) \right ). \nonumber \end {alignat} This expression itself is not very convenient to work with due to the inner product term of \(\vmu \) and \(\vm \). Thus, we focus on the special case \(\vmu = \mathbf {0}\). Then, \begin {alignat}{2} &\mathbb {E}\norm { \nabla _{\vlambda } f\left ( \vt _{\vlambda }\left (\rvvu \right ) \right ) }_2^2 \nonumber \\ &\;= \left (d+1\right )\vm ^{\top } \mS ^{-\top } \mS ^{-1} \vm \nonumber \\ &\quad + \left (d+\kappa \right ) \left ( \mathrm {tr}\left (\mS \mSigma ^{-\top } \mSigma ^{-1}\right ) -2 \, \mathrm {tr}\left (\mSigma ^{-\top }\right ) + \mathrm {tr}\left (\mS ^{-1}\right ) \right ) \nonumber \\ &\;= \left (d+1\right )\vm ^{\top } \mS ^{-\top } \mS ^{-1} \vm \nonumber \\ &\quad + \left (d+\kappa \right ) \left ( \mathrm {tr}\left (\mS \mSigma ^{-\top } \mSigma ^{-1}\right ) + \mathrm {tr}\left (\mS ^{-1}\right ) \right ) \nonumber \\ &\quad - \underbrace { 2 \left (d+\kappa \right ) \mathrm {tr}\left (\mSigma ^{-\top }\right ) }_{\text {constant with respect to \(\vlambda \)}} \end {alignat} This also simplifies the suboptimality gap as \begin {alignat}{2} & F\left (\vlambda \right ) - F\left (\vlambda ^{*}\right ) \nonumber \\ &\;= \frac {1}{2} \vm ^{\top } \mSigma ^{-1} \vm + \frac {1}{2} \left ( \mathrm {tr}\left (\mSigma ^{-1} \mS \right ) + \mathrm {tr}\left (\mSigma ^{-1} \mS ^* \right ) \right ) \nonumber \\ &\qquad + \frac {1}{2} \left ( -\log \abs {\mS } + \log \abs {\mS ^*} \right ). \nonumber \\ &\;= \frac {1}{2} \vm ^{\top } \mSigma ^{-1} \vm + \frac {1}{2} \left ( \mathrm {tr}\left (\mSigma ^{-1} \mS \right ) - \log \abs {\mS } \right ) \nonumber \\ &\qquad - \underbrace {\frac {1}{2} \,\left (\mathrm {tr}\left (\mSigma ^{-1} \mS ^* \right ) - \log \abs {\mS ^*}\right )}_{\text {constant with respect to \(\vlambda \)}}. \nonumber \end {alignat} \par Showing \begin {alignat}{2} &\vm ^{\top } \mS ^{-\top } \mS ^{-1} \vm \; &&\succeq \; \vm ^{\top } \mSigma ^{-1} \vm \\ &\mathrm {tr}\left (\mS \mSigma ^{-\top } \mSigma ^{-1}\right ) \; &&\succeq \; \mathrm {tr}\left (\mSigma ^{-1} \mS \right ) \\ &\mathrm {tr}\left (\mS ^{-1}\right ) \; &&\succeq \; -\log \abs {\mS } \end {alignat}for proves the statement.\end{proof}
