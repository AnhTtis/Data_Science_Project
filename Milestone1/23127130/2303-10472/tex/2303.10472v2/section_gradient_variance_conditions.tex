
\section{Assumptions on the Gradient Variance}

\begin{definition}[\textbf{Expected Strong Growth; ESG}]
  \(\rvvg\) is said to satisfy the expected strong growth condition if 
  \begin{align*}
    \mathbb{E} \norm{\rvvg\left(\vlambda\right)}^2_2 \leq B \, \norm{ \nabla F\left(\vlambda\right) }^2
  \end{align*}
  for some finite \(B > 0\).
\end{definition}
This is a weaker version of the maximal strong growth condition~\citep{tseng_incremental_1998, schmidt_fast_2013}, where the bound is assumed to hold uniformly instead of in expectation.
Under ESG, for \(L\)-smooth non-convex objectives, \citet{vaswani_fast_2019} prove that SGD with a fixed stepsize of \(\gamma = \nicefrac{1}{B L}\) converges as \(\mathcal{O}\left(2 B L / T\right)\).

Arguably, the most widely recognized gradient condition is the relaxed strong growth by \citet{bottou_optimization_2018}.
\begin{definition}[\textbf{Relaxed Strong Growth; RSG}]
  \(\rvvg\) is said to satisfy the expected strong growth condition if 
  \begin{align*}
    \mathbb{E} \norm{\rvvg\left(\vlambda\right)}^2_2 \leq B \, \norm{ \nabla F\left(\vlambda\right) }^2_2 + C
  \end{align*}
  for some finite \(B, C > 0\).
\end{definition}
\citeauthor{bottou_optimization_2018} prove that, for \(L\)-smooth non-convex objectives and some additional regularity conditions, SGD with a fixed stepsize in \(\mathcal{O}\left(\nicefrac{1}{L B}\right)\) converges to a \(\mathcal{O}\left(\alpha L C\right)\) neighborhood in a rate of \(\mathcal{O}\left(\nicefrac{1}{T \alpha}\right) \).

\begin{definition}[\textbf{Convex Expected Smoothness; C-ES}]
  \(\rvvg\) is said to satisfy the expected strong growth condition if 
  \begin{align*}
    \mathbb{E} \norm{\rvvg\left(\vlambda\right) - \rvvg\left(\vlambda^*\right)}^2_2 \leq 2 A \left( F\left(\vlambda\right) - F\left(\vlambda^*\right) \right)
  \end{align*}
  for some finite \(A > 0\), where \(\vlambda^*\) is the global minimizer.
\end{definition}
This condition was first used by~\cite{gower_stochastic_2021} for studying the JacSketch algorithm  for strongly convex problems.

%%% Local Variables:
%%% TeX-master: "main"
%%% End: