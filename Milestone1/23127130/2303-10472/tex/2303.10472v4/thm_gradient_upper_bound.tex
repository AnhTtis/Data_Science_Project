
\begin{theoremEnd}[\theoremproofoption,category=upperboundtheorem]{theorem}\label{thm:gradient_upper_bound}
  Let \(\rvvg_{M}\) be an \(M\)-sample estimate of the gradient of the ELBO in entropy regularized form (\cref{def:entropy_form}).
  Also, assume that \cref{assumption:q,assumption:phi_lipschitz} hold,
%
  \begin{itemize}[leftmargin=3em]
    \vspace{-1.5ex}
    \setlength\itemsep{0ex}
    \item \(f_{\mathrm{H}}\) is \(L_{\mathrm{H}}\)-smooth, and
    \item \(f_{\mathrm{KL}}\) is \(\mu_{\mathrm{KL}}\)-quadratically growing.
    \vspace{-1.5ex}
  \end{itemize}
  %
  Then, 
  {\small%
  \setlength{\belowdisplayskip}{1ex} \setlength{\belowdisplayshortskip}{1ex}%
  \setlength{\abovedisplayskip}{1ex} \setlength{\abovedisplayshortskip}{1ex}%
  \begin{align*}
    \hspace{-1.5em}
    \mathbb{E}\norm{\rvvg_{M}}_2^2
    &\leq
    \frac{4 L^2_{\mathrm{H}}}{\mu_{\mathrm{KL}} M} C\left(d, \kappa\right) \left( F\left(\vlambda\right) - F^* \right)
    + \norm{ \nabla F\left(\vlambda\right) }_2^2
    \\
    &\quad+ \frac{2 L^2_{\mathrm{H}}}{M} C\left(d, \kappa\right) {\lVert \bar{\vzeta}_{\mathrm{KL}} - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2
    \\
    &\quad+ \frac{4 L^2_{\mathrm{H}}}{\mu_{\mathrm{KL}} M} C\left(d, \kappa\right) \left( F^* - f_{\mathrm{KL}}^* \right),
  \end{align*}
  }%
  where
  {\small%
  \setlength{\belowdisplayskip}{1ex} \setlength{\belowdisplayshortskip}{1ex}%
  \setlength{\abovedisplayskip}{1ex} \setlength{\abovedisplayshortskip}{1ex}%
  \begin{alignat*}{2}
    C\left(d, \kappa\right) &= 2 \kappa \sqrt{d} + 1 &&\;\text{for mean-field,} \\
    C\left(d, \kappa\right) &= d + \kappa          &&\;\text{for the Cholesky and matrix square root,}
  \end{alignat*}
  }
  \(\bar{\zeta}_{\mathrm{KL}}\), \(\bar{\zeta}_{\mathrm{H}}\) are the stationary points of \(f_{\mathrm{KL}}\), \(f_{\mathrm{H}}\), respectively,
  \(F^* = \inf_{\vlambda \in \mathbb{R}^p} F\left(\vlambda\right)\), and \(f_{\mathrm{KL}}^* = \inf_{\vzeta \in \mathbb{R}^d} f\left(\zeta\right)\).
\end{theoremEnd}
\vspace{-1ex}
\begin{proofsketch}
  From \cref{thm:gradient_variance_general_upper_bound}, we can see that the key quantity of upper bounding the gradient variance is to analyze \(\mathbb{E} \norm{ \nabla_{\vlambda} f_{\mathrm{H}} \left( \vt_{\vlambda}\left(\rvvu\right) \right) } \).
  The bird's eye view of the proof is as follows:
  \begin{enumerate}
  \vspace{-1ex}
    \setlength\itemsep{-.5ex}
    \item[\ding{182}] The relationship between \( \norm{ \nabla_{\vlambda} f_{\mathrm{H}} \left( \vt_{\vlambda}\left(\rvvu\right) \right) }_2^2 \) and \( \norm{ \nabla f_{\mathrm{H}} \left( \vt_{\vlambda}\left(\rvvu\right) \right) }_2^2 \) is established through \cref{thm:general_variational_gradient_norm_bound}.
    \item[\ding{183}] Then, the \(L_{\mathrm{H}}\)-smoothness of \(f_{\mathrm{H}}\) relates \( \norm{ \nabla f_{\mathrm{H}} \left( \vt_{\vlambda}\left(\rvvu\right) \right) }_2^2 \) with \( {\lVert \vt_{\vlambda}\left(\rvvu\right) - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2\), the average squared distance from \(f_{\mathrm{H}}\)'s stationary point.
    \item[\ding{184}] The average squared distance enables the simplification of stochastic terms through \cref{thm:meanfield_u_identity,thm:reparam_u_identity}. This step also introduces dimension dependence.
  \vspace{-1ex}
  \end{enumerate}
  From here, we are now left with the \(\mathbb{E} {\lVert \vt_{\vlambda}\left(\rvvu\right) - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2\) term.
  One might be tempted to assume the quadratic growth assumption on \(f_{\mathrm{H}}\) and proceed as
  {%
  \setlength{\belowdisplayskip}{1.ex} \setlength{\belowdisplayshortskip}{1.ex}%
  \setlength{\abovedisplayskip}{1.ex} \setlength{\abovedisplayshortskip}{1.ex}%
  \begin{align*}
    \mathbb{E} {\Vert \vt_{\vlambda}\left(\rvvu\right) - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2
    \leq \frac{2}{\mu} \left( f_{\mathrm{H}}\left(\vt_{\vlambda}\left(\rvvu\right)\right) - f^*_{\mathrm{H}}\right).
  \end{align*}
  }%
  However, for the entropy-regularized form, this soon runs into a dead end since in
  {%
  \setlength{\belowdisplayskip}{1ex} \setlength{\belowdisplayshortskip}{1ex}%
  \setlength{\abovedisplayskip}{1ex} \setlength{\abovedisplayshortskip}{1ex}%
  \begin{align*}
    \mathbb{E} f_{\mathrm{H}}\left(\vt_{\vlambda}\left(\rvvu\right)\right) - f^*_{\mathrm{H}}
    &= F\left(\vlambda\right) - h\left(\vlambda\right) - f^* \\
    &= \left( F\left(\vlambda\right) - F^* \right) + \left(F^* - f^*\right) - h_{\mathrm{H}}\left(\vlambda\right),
  \end{align*}
  }%
  the negative entropy term \(h_{\mathrm{H}}\) is not bounded unless we rely on assumptions that need modifications to the BBVI algorithms. (\textit{e.g.}, bounded support, bounded domain).
  Fortunately, the following inequality cleverly side-steps this problem:
  {%
  \setlength{\belowdisplayskip}{1.5ex} \setlength{\belowdisplayshortskip}{1.5ex}%
  \setlength{\abovedisplayskip}{1.5ex} \setlength{\abovedisplayshortskip}{1.5ex}%
  \begin{align}
    \hspace{-1.0em}
    \mathbb{E} {\Vert \vt_{\vlambda}\left(\rvvu\right) - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2
    &\leq
    2\,\mathbb{E} {\lVert \vt_{\vlambda}\left(\rvvu\right) - \bar{\vzeta}_{\text{KL}} \rVert}_2^2
    +
    2 \, {\lVert \bar{\vzeta}_{\text{KL}} - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2,
    \label{eq:thm_upper_bound_parallel}
  \end{align}
  }%
  albeit at the cost of some looseness.
  By converting the entropy-regularized form into the KL-regularized form, the regularizer term becomes \(h_{\mathrm{KL}} = \DKL{q_{\vlambda}}{p} \geq 0\), which is bounded below by definition, unlike the entropic-regularizer \(h_{\mathrm{H}}\). 
  The proof completes by 
  \begin{enumerate}
  \vspace{-1ex}
    \setlength\itemsep{-.5ex}
    \item[\ding{185}] applying the quadratic growth assumption to relate the parameter distance with the function suboptimality gap, and 
    \item[\ding{186}] upper bounding the KL regularizer term.
  \end{enumerate}
  \vspace{-4ex}
\end{proofsketch}
\vspace{-2ex}
\begin{proofEnd}
  The proof uses the \(L_{\mathrm{H}}\)-smoothness of \(f_{\mathrm{H}}\) such that 
  \begin{align}
    \mathbb{E} \norm{
    \nabla f_{\mathrm{H}}\left(\vt_{\vlambda}\left(\rvvu\right)\right)
    }_2^2
    &=
    \mathbb{E} {\lVert
    \nabla f_{\mathrm{H}}\left(\vt_{\vlambda}\left(\rvvu\right)\right)
    -
    \nabla f_{\mathrm{H}}\left(\bar{\vzeta}_{\mathrm{H}}\right)
    \rVert}_2^2
    \nonumber
    \\
    &\leq
    L^2_{\mathrm{H}}
    \mathbb{E} {\lVert
    \vt_{\vlambda}\left(\rvvu\right)
    -
    \bar{\vzeta}_{\mathrm{H}}
    \rVert}_2^2,
    \label{eq:thm_upper_bound_smoothness}
  \end{align}
  where \(\bar{\vzeta}_{\mathrm{H}}\) is a stationary point of \(f_{\mathrm{H}}\) such that \(\nabla f_{\mathrm{H}}\left(\bar{\vzeta}_{\mathrm{H}}\right) = \mathbf{0}\).
  These steps have been previously used by \citet[Theorem 3]{domke_provable_2019} to prove the special case for the matrix square root parameterization.

  For the mean-field parameterization, we start from \cref{thm:general_variational_gradient_norm_bound} and apply~\cref{eq:thm_upper_bound_smoothness} as
  \begin{align}
    &\mathbb{E} \norm{
      \nabla_{\vlambda} f_{\mathrm{H}}\left(\vt_{\vlambda}\left(\rvvu\right)\right)
    }_2^2 
    \nonumber
    \\
    &\;\leq
    \mathbb{E} \norm{
      \nabla f_{\mathrm{H}}\left(\vt_{\vlambda}\left(\rvvu\right)\right)
    }_2^2 \left(1 + \norm{\mathbfsfit{U}}_{\mathrm{F}}\right)
    \nonumber
    \\
    &\;\leq
    L^2_{\mathrm{H}} \,
    \mathbb{E} {\lVert
    \vt_{\vlambda}\left(\rvvu\right)
    +
    \bar{\vzeta}_{\mathrm{H}}
    \rVert}_2^2 \left(1 + \norm{\mathbfsfit{U}}_{\mathrm{F}}\right),
    \nonumber
\shortintertext{applying \cref{thm:meanfield_u_identity},}
    &\;\leq
    L^2_{\mathrm{H}}
    \left( \kappa \sqrt{d} + \sqrt{\kappa d} + 1 \right) {\lVert \vm - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2
    \nonumber
    \\
    &\;\;\quad+
    L^2_{\mathrm{H}} \left(2 \kappa \sqrt{d} + 1\right) \norm{\mC}_{\mathrm{F}}^2,
    \nonumber
\shortintertext{and since the kurtosis satisfies \(\kappa \geq 1\) and thus \(\kappa \geq \sqrt{\kappa}\),}
    &\;\leq
    L^2_{\mathrm{H}}
    \left( 2 \kappa \sqrt{d} + 1 \right) \left( {\lVert \vm - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2
    + \norm{\mC}_{\mathrm{F}}^2 \right).
    \label{eq:thm1_meanfield}
  \end{align}

  Similarly, for the full-rank parameterizations, we start from \cref{thm:general_variational_gradient_norm_bound} and apply~\cref{eq:thm_upper_bound_smoothness} as
  \begin{alignat}{2}
    &\mathbb{E} \norm{
      \nabla_{\vlambda} f_{\mathrm{H}}\left(\vt_{\vlambda}\left(\rvvu\right)\right)
    }_2^2 
    \\
    &\;\leq\mathbb{E}\norm{\nabla f_{\mathrm{H}}\left(\vt_{\vlambda}\left(\rvvu\right)\right)}_2^2 \left(1 + \norm{\rvvu}_2^2 \right),
    \nonumber
    \\
    &\;\leq
    L^2_{\mathrm{H}}\,\mathbb{E}{\lVert \vt_{\vlambda}\left(\rvvu\right) - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2 \left(1 + \norm{\rvvu}_2^2 \right),
    \nonumber
\shortintertext{applying \cref{thm:reparam_u_identity},}
    &\;=
    L^2_{\mathrm{H}}\left(\left(d + 1\right) {\lVert \vm - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2 + \left(d + \kappa\right) \norm{\mC}_{\mathrm{F}}^2 \right),
    \nonumber
\shortintertext{and since the kurtosis satisfies \(\kappa \geq 1\),}
    &\;\leq
    L^2_{\mathrm{H}}\left(d + \kappa\right) \left( {\lVert \vm - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2 + \norm{\mC}_{\mathrm{F}}^2 \right).
    \label{eq:thm1_fullrank}
  \end{alignat}
  
  Both \cref{eq:thm1_meanfield,eq:thm1_fullrank} can now be denoted as
  \begin{alignat}{2}
    \mathbb{E}\norm{\nabla_{\vlambda} f_{\mathrm{H}}\left(\vt_{\vlambda}\left(\rvvu\right)\right)}_2^2 
    &\leq
    L^2_{\mathrm{H}}\, C\left(d, \kappa\right)  \left( {\lVert \vm - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2 + \norm{\mC}_{\mathrm{F}}^2 \right),
    \nonumber
\shortintertext{where by \cref{thm:reparam_quadratic},}
    &=
    L^2_{\mathrm{H}}\, C\left(d, \kappa\right) \mathbb{E} {\Vert \vt_{\vlambda}\left(\rvvu\right) - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2,
    \label{eq:thm1_parameter_suboptimality_unified}
  \end{alignat}
  and the constants are \(C\left(d, \kappa\right) = \kappa \sqrt{d} + 1\) for mean-field and \(C\left(d, \kappa\right) = d + \kappa\) for the full-rank parameterizations.

  As mentioned in the sketch, it is necessary to convert the entropy-regularized form into the KL-regularized form through the following inequality:
  {%
  \setlength{\belowdisplayskip}{1ex} \setlength{\belowdisplayshortskip}{1ex}%
  \setlength{\abovedisplayskip}{1ex} \setlength{\abovedisplayshortskip}{1ex}%
  \begin{alignat*}{2}
    \hspace{-0.5em}
    \mathbb{E} {\Vert \vt_{\vlambda}\left(\rvvu\right) - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2
    &\leq
    2\,\mathbb{E} {\lVert \vt_{\vlambda}\left(\rvvu\right) - \bar{\vzeta}_{\text{KL}} \rVert}_2^2
    +
    2 \, {\lVert \bar{\vzeta}_{\text{KL}} - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2.
  \end{alignat*}
  }%
  where \(\bar{\vzeta}_{\mathrm{KL}} = \Pi_{f_{\mathrm{KL}}}\left(\bar{\vzeta}_{\mathrm{H}}\right)\) is a projection of \(\bar{\vzeta}_{\mathrm{H}}\) to the set of minimizers of \(f_{\mathrm{KL}}\).
  Note that the KL-regularized form does not need to be tractable; only its existence suffices.
  We can now apply the quadratic growth assumption as
  {%
  \setlength{\belowdisplayskip}{1ex} \setlength{\belowdisplayshortskip}{1ex}%
  \setlength{\abovedisplayskip}{1ex} \setlength{\abovedisplayshortskip}{1ex}%
  \begin{alignat}{2}
    \hspace{-1em}
    \mathbb{E} {\lVert \vt_{\vlambda}\left(\rvvu\right) - \bar{\vzeta}_{\text{KL}} \rVert}_2^2
    \nonumber
    &\leq
    \frac{2}{\mu_{\mathrm{KL}}} \left( \mathbb{E} f_{\text{KL}}\left(\vt_{\vlambda}\left(\rvvu\right)\right) - f^*_{\text{KL}} \right)
    \nonumber
    \\
    &=
    \frac{2}{\mu_{\mathrm{KL}}} 
    \left( F\left(\vlambda\right) - h_{\mathrm{KL}}\left(\vlambda\right) - f^*_{\text{KL}} \right),
    \nonumber
\shortintertext{and since \(-h_{\mathrm{KL}}\left(\vlambda\right) = -\DKL{q_{\vlambda}}{p} \leq 0\) by definition,}
    &\leq
    \frac{2}{\mu_{\mathrm{KL}}} 
    \left( F\left(\vlambda\right) - f^*_{\text{KL}} \right)
    \label{eq:thm_upper_bound_kl_upper_bound}
    \\
    &=
    \frac{2}{\mu_{\mathrm{KL}}} \left(
    \left( F\left(\vlambda\right) - F^* \right) 
    + \left( F^* - f^*_{\text{KL}} \right)
    \right).
    \label{eq:thm_upper_bound_f_quadratic}
  \end{alignat}
  }%
%
  Combining \cref{eq:thm1_parameter_suboptimality_unified} with \cref{eq:thm_upper_bound_parallel},
  {%\small
  \begin{align*}
    &\mathbb{E}\norm{\nabla_{\vlambda} f_{\mathrm{H}}\left(\vt_{\vlambda}\left(\rvvu\right)\right)}_2^2 
    \\
    &\;\leq
    2 \, L^2_{\mathrm{H}}\, C\left(d, \kappa\right) \mathbb{E} {\Vert \vt_{\vlambda}\left(\rvvu\right) - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2
    + 2 \, L^2_{\mathrm{H}}\, C\left(d, \kappa\right) {\lVert \bar{\vzeta}_{\text{KL}} - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2,
\shortintertext{and applying \cref{eq:thm_upper_bound_f_quadratic},}
    &\;\leq
    \frac{4 \, L^2_{\mathrm{H}}}{\mu_{\mathrm{KL}}} C\left(d, \kappa\right) \left(
    \left( F\left(\vlambda\right) - F^* \right) 
    +
    \left( F^* - f^*_{\text{KL}} \right)
    \right)
    \\
    &\;\quad+
    2 \, L^2_{\mathrm{H}}\, C\left(d, \kappa\right) {\lVert \bar{\vzeta}_{\text{KL}} - \bar{\vzeta}_{\mathrm{H}} \rVert}_2^2
  \end{align*}
  }%
  Plugging this into \cref{thm:gradient_variance_general_upper_bound} yields the result.
\end{proofEnd}

%%% Local Variables:
%%% TeX-master: "main"
%%% End:
