%!TEX root=main.tex

% \begin{theoremEnd}[\lemmaproofoption,category=lowerboundlemma]{lemma}
%   Let \(\vt_{\vlambda}: \mathbb{R}^d \mapsto \mathbb{R}^d\) be defined as in \cref{def:reparam} with parameters \(\vlambda = \left(\vm, \mC\right)\) such that \(\vm \in \mathbb{R}^d\) and \(\mC \in \mathbb{R}^{d \times d}\).
%   Also, let \(\rvvu \sim \varphi\), where \(\varphi\) is defined as in \cref{assumption:symmetric_standard}.
%   Then,
%   \begin{alignat*}{2}
%     \mathbb{E}\vt_{\vlambda}\left(\rvvu\right) \left(1 + \norm{\rvvu}_2^2\right)
%     = \left(d + 1\right) \vm.
%   \end{alignat*}
% \end{theoremEnd}
% \begin{proofEnd}
%   Since \(\rvu_i\) follows a symmetric and standardized distribution, \(\mathbb{E}\rvu_i^3 = 0, \mathbb{E} \rvu_i^2 = 1\).
%   Then,
%   \begin{alignat*}{2}
%     \mathbb{E}\vt_{\vlambda}\left(\rvvu\right) \left(1 + \norm{\rvvu}_2^2\right)
%     &=
%     \mathbb{E} \left(\mC \rvvu + \vm \right) \left(1 + \norm{\rvvu}_2^2\right)
%     \\
%     &=
%     \mC \, \mathbb{E} \rvvu \left(1 + \norm{\rvvu}_2^2\right) + \vm \left(1 + \mathbb{E} \norm{\rvvu}_2^2\right),
% \shortintertext{applying \cref{thm:u_identities},}
%     &=
%     \left( \mathbb{E}\rvu_i^3 \right) \mC \mathbf{1} + \vm \left(1 + d \, \mathbb{E} \rvu_i^2\right),
% \shortintertext{and by~\cref{assumption:symmetric_standard},}
%     &=
%     \left(d + 1\right) \vm.
%   \end{alignat*}
% \end{proofEnd}

% \begin{theoremEnd}[\lemmaproofoption,category=lowerboundlemma]{lemma}\label{thm:general_quad_reparam}
%   Let \(\vt_{\vlambda}: \mathbb{R}^d \mapsto \mathbb{R}^d\) be defined as in \cref{def:reparam} with parameters \(\vlambda = \left(\vm, \mC\right)\) such that \(\vm \in \mathbb{R}^d\) and \(\mC \in \mathbb{R}^{d \times d}\).
%   Also, let \(\mSigma \in \mathbb{R}^{d \times d}\) be some matrix, \(\vmu \in \mathbb{R}^d\) be some vector, and \(\rvvu \sim \varphi\) be a vector-valued random variable, where \(\varphi\) is defined as in \cref{assumption:symmetric_standard}.
%   Then,
%   \begin{align*}
%     &\mathbb{E} \, {\left( \vt_{\vlambda}\left(\rvvu\right) - \vmu \right)}^{\top} \mSigma \left(\vt_{\vlambda}\left(\rvvu\right) - \vmu\right)
%     \\
%     &\;= {\left(\vm - \vmu\right)}^{\top} \mSigma \left(\vm - \vmu\right)
%     + \mathrm{tr}\left({\mSigma}^{-1} \mC \mC^{\top}\right).
%   \end{align*}
% \end{theoremEnd}
% \begin{proofEnd}
%   \begin{alignat}{2}
%     &\mathbb{E} {\left( \vt_{\vlambda}\left(\rvvu\right) - \vmu \right)}^{\top} \mSigma \, \left(\vt_{\vlambda}\left(\rvvu\right) - \vmu \right)
%     \nonumber
%     \\
%     &\;=
%     \mathbb{E}\, {\vt_{\vlambda}\left(\rvvu\right)}^{\top} \mSigma \, {\vt_{\vlambda}\left(\rvvu\right)}
%     -2\, \vmu^{\top} {\mSigma} \, \mathbb{E}\vt_{\vlambda}\left(\rvvu\right)
%     + \vmu^{\top} {\mSigma} \, \vmu,
%     \nonumber
% \shortintertext{where \(\mathbb{E}\vt_{\vlambda}\left(\rvvu\right) = \mC \mathbb{E}{\rvvu} + \vm\), and by \cref{assumption:symmetric_standard},}
%     &\;=
%     \mathbb{E}\, {\vt_{\vlambda}\left(\rvvu\right)}^{\top} \mSigma \, {\vt_{\vlambda}\left(\rvvu\right)}
%     -2\, \vmu^{\top} {\mSigma} \, \vm
%     + \vmu^{\top} {\mSigma} \, \vmu.\label{eq:thm:general_quad_reparam_eq1}
%   \end{alignat}
%   Furthermore,
%   \begin{alignat*}{2}
%     &\mathbb{E} {\vt_{\vlambda}\left(\rvvu\right)}^{\top} \mSigma  \, {\vt_{\vlambda}\left(\rvvu\right)}
%     \\
%     &\;=
%     \mathbb{E}{\left(\mC \rvvu + \vm\right)}^{\top}  \mSigma \left(\mC \rvvu + \vm\right)
%     \\
%     &\;=
%     \mathbb{E} \rvvu^{\top} \mC^{\top} \mSigma \, \mC \rvvu
%     + \vm^{\top} \mSigma \, \mC \, \mathbb{E}  \rvvu 
%     + \mathbb{E} \rvvu^{\top} \mC^{\top} \mSigma \vm^{\top} 
%     + \vm^{\top} \mSigma \, \vm,
% \shortintertext{by \cref{assumption:symmetric_standard},}
%     &\;=
%     \mathbb{E} \rvvu^{\top} \mC^{\top} {\mSigma} \, \mC \rvvu
%     + \vm^{\top} \mSigma \, \vm,
% \shortintertext{invoking the trace trick,}
%     &\;=
%     \mathbb{E} \mathrm{tr}\left( \rvvu^{\top} \mC^{\top} {\mSigma}\, \mC \rvvu \right)
%     + \vm^{\top} \mSigma \, \vm,
% \shortintertext{pusing the expectation into the trace,}
%     &\;=
%     \mathrm{tr}\left(\mathbb{E} \rvvu  \rvvu^{\top} \mC^{\top} {\mSigma}\, \mC \right)
%     + \vm^{\top} \mSigma \, \vm,
% \shortintertext{invoking \cref{thm:u_identities},}
%     &\;=
%     \mathrm{tr}\left(\mC^{\top} {\mSigma}\, \mC \right)
%     + \vm^{\top} \mSigma \, \vm
%     \\
%     &\;=
%     \mathrm{tr}\left({\mSigma} \, \mC \mC^{\top}\right)
%     + \vm^{\top} \mSigma \, \vm.
%   \end{alignat*}
%   Applying this to \cref{eq:thm:general_quad_reparam_eq1},
%   \begin{alignat*}{2}
%     &\mathbb{E} {\left( \vt_{\vlambda}\left(\rvvu\right) - \vmu \right)}^{\top} {\mSigma}^{-1} \left(\vt_{\vlambda}\left(\rvvu\right) - \vmu \right)
%     \\
%     &\;=
%     \mathrm{tr}\left({\mSigma}^{-1} \mC \mC^{\top}\right)
%     + \vm^{\top} \mSigma^{-1} \vm
%     -2\, \vmu^{\top} {\mSigma}^{-1} \vm
%     + \vmu^{\top} {\mSigma}^{-1} \vmu
%     \\
%     &\;=
%     {\left(\vm - \vmu\right)}^{\top} {\mSigma}^{-1} \left(\vm - \vmu\right)
%     + \mathrm{tr}\left({\mSigma}^{-1} \mC \mC^{\top}\right).
%   \end{alignat*}
% \end{proofEnd}

% \begin{theoremEnd}[\lemmaproofoption,category=lowerboundlemma]{corollary}\label{thm:q_quad_reparam}
%   Let \(\vt_{\vlambda}: \mathbb{R}^d \mapsto \mathbb{R}^d\) be defined as in \cref{def:reparam} with parameters \(\vlambda = \left(\vm, \mC\right)\) such that \(\vm \in \mathbb{R}^d\) and \(\mC \in \mathbb{R}^{d \times d}\).
%   Also, let \(\rvvu \sim \varphi\) be a vector-valued random variable, where \(\varphi\) is defined as in \cref{assumption:symmetric_standard}.
%   Then,
%   \begin{align*}
%     \mathbb{E} \, {\left( \vt_{\vlambda}\left(\rvvu\right) - \vm \right)}^{\top} {\left(\mC \mC^{\top}\right)}^{-1} \left(\vt_{\vlambda}\left(\rvvu\right) - \vm\right) = d.
%   \end{align*}
% \end{theoremEnd}
% \begin{proofEnd}
%   From, \cref{thm:general_quad_reparam} we have
%   \begin{alignat*}{2}
%     &\mathbb{E} \, {\left( \vt_{\vlambda}\left(\rvvu\right) - \vm \right)}^{\top} {\left(\mC \mC^{\top}\right)}^{-1} \left(\vt_{\vlambda}\left(\rvvu\right) - \vm\right)
%     \\
%     &\;= {\left(\vm - \vm\right)}^{\top} {\left(\mC \mC^{\top}\right)}^{-1} \left(\vm - \vm\right)
%     + \mathrm{tr}\left({\left( \mC \mC^{\top} \right)}^{-1} \mC \mC^{\top}\right)
%     \\
%     &\;= \mathrm{tr}\left(\mI\right)
%     \\
%     &\;= d.
%   \end{alignat*}
% \end{proofEnd}

% \begin{theoremEnd}[\lemmaproofoption,category=lowerboundlemma]{lemma}\label{thm:general_grad_norm_reparam}
%   Let \(\vt_{\vlambda}: \mathbb{R}^d \mapsto \mathbb{R}^d\) be defined as in \cref{def:reparam} with parameters \(\vlambda = \left(\vm, \mC\right)\) such that \(\vm \in \mathbb{R}^d\) and \(\mC \in \mathbb{R}^{d \times d}\).
%   Also, let \(\mSigma_1, \mSigma_2 \in \mathbb{R}^{d \times d}\) be some matrices, \(\vmu_1, \vmu_2 \in \mathbb{R}^{d}\) be some vectors, and \(\rvvu = \left(\rvu_1, \ldots, \rvu_d \right)\) be a vector-valued random variable sampled as \(\rvvu \sim \varphi\), where \(\varphi\) is defined as in \cref{assumption:symmetric_standard} with kurtosis \(\kappa = \mathbb{E}\rvu_i^4\).
%   Then,
%   \begin{alignat*}{2}
%     &\mathbb{E} {\left(\vt_{\vlambda}\left(\rvvu\right) - \vmu_1\right)}^{\top} \mSigma_1 \mSigma_2 \left(\vt_{\vlambda}\left(\rvvu\right) - \vmu_2\right) \left( 1 + \norm{\rvvu}_2^2 \right)
%     \\
%     &\;=
%     \left(d + 1\right) \vmu_1^{\top} \mSigma_1 \mSigma_2 \vmu_2
%     +
%     \left(d + \kappa\right) \mathrm{tr}\left(\mC \mC^{\top} \mSigma_1 \mSigma_2 \right).
%   \end{alignat*}
% \end{theoremEnd}
% \begin{proofEnd}
%   \begin{alignat}{2}
%     &\mathbb{E} {\left(\vt_{\vlambda}\left(\rvvu\right) - \vmu_1\right)}^{\top} \mSigma_1 \mSigma_2 \left(\vt_{\vlambda}\left(\rvvu\right) - \vmu_2\right) \left( 1 + \norm{\rvvu}_2^2 \right)
%     \nonumber
%     \\
%     &\;=
%     \mathbb{E} {\vt_{\vlambda}\left(\rvvu\right)}^{\top} \mSigma_1 \mSigma_2 \, \vt_{\vlambda}\left(\rvvu\right) \left( 1 + \norm{\rvvu}_2^2 \right)
%     \nonumber
%     \\
%     &\qquad- \vmu_1^{\top} \mSigma_1 \mSigma_2 \, \mathbb{E} \vt_{\vlambda}\left(\rvvu\right) \left( 1 + \norm{\rvvu}_2^2 \right)
%     \nonumber
%     \\
%     &\qquad- \mathbb{E} {\left(\vt_{\vlambda}\left(\rvvu\right) \left( 1 + \norm{\rvvu}_2^2 \right)\right)}^{\top} \mSigma_1 \mSigma_2 \vmu_1  
%     \nonumber
%     \\
%     &\qquad+ \vmu_1^{\top} \mSigma_1 \mSigma_2 \vmu_2 \, \mathbb{E}\left( 1 + \norm{\rvvu}_2^2 \right),
%     \nonumber
% \shortintertext{invoking \cref{thm:u_identities},}
%     &\;=
%     \mathbb{E} {\vt_{\vlambda}\left(\rvvu\right)}^{\top} \mSigma_1 \mSigma_2 \, \vt_{\vlambda}\left(\rvvu\right) \left( 1 + \norm{\rvvu}_2^2 \right)
%     \nonumber
%     \\
%     &\qquad- \mathbb{E}\rvu_i^3 \, \vmu_1^{\top} \mSigma_1 \mSigma_2 \mathbf{1}
%     \nonumber
%     \\
%     &\qquad- \mathbb{E}\rvu_i^3 \, \mathbf{1}^{\top} \mSigma_1 \mSigma_2 \vmu_1  
%     \nonumber
%     \\
%     &\qquad+ \left( 1 + d\,\mathbb{E}\rvu_i^2 \right) \vmu_1^{\top} \mSigma_1 \mSigma_2 \vmu_2,
%     \nonumber
% \shortintertext{and due to \cref{assumption:symmetric_standard},}
%     &\;=
%     \mathbb{E} {\vt_{\vlambda}\left(\rvvu\right)}^{\top} \mSigma_1 \mSigma_2 \, \vt_{\vlambda}\left(\rvvu\right) \left( 1 + \norm{\rvvu}_2^2 \right)
%     \label{eq:general_grad_norm reparam_eq1}
%     \\
%     &\qquad+ \left( 1 + d \right) \vmu_1^{\top} \mSigma_1 \mSigma_2 \vmu_2.\label{eq:general_grad_norm reparam_eq2}
%   \end{alignat}
%   Now for \cref{eq:general_grad_norm reparam_eq1},
%   \begin{alignat}{2}
%     &\mathbb{E} {\vt_{\vlambda}\left(\rvvu\right)}^{\top} \mSigma_1 \mSigma_2 \, \vt_{\vlambda}\left(\rvvu\right) \left( 1 + \norm{\rvvu}_2^2 \right)
%     \nonumber
%     \\
%     &\;=
%     \mathbb{E} {\left(\mC \rvvu + \vm \right)}^{\top} \mSigma_1 \mSigma_2 \left(\mC \rvvu + \vm \right) \left( 1 + \norm{\rvvu}_2^2 \right)
%     \nonumber
%     \\
%     &\;=
%     \mathbb{E} \mathrm{tr}\left( \rvvu^{\top} \mC^{\top} \mSigma_1 \mSigma_2 \mC \rvvu \right)
%     \nonumber
%     \\
%     &\qquad+
%     \mathbb{E} \mathrm{tr}\left( \rvvu^{\top} \mC^{\top} \mSigma_1 \mSigma_2 \mC \, \rvvu \rvvu^{\top} \rvvu  \right)
%     \label{eq:thm:general_grad_norm_reparam_eq1}
%     \\
%     &\qquad+
%     \vm^{\top} \mSigma_1 \mSigma_2 \mC \, \mathbb{E} \rvvu \left( 1 + \norm{\rvvu}_2^2 \right)
%     \nonumber
%     \\
%     &\qquad+
%     \mathbb{E} \rvvu^{\top} \left( 1 + \norm{\rvvu}_2^2 \right) \mC^{\top} \mSigma_1 \mSigma_2 \vm
%     \nonumber
%     \\
%     &\qquad+
%     \vm^{\top} \mSigma_1 \mSigma_2 \vm \, \mathbb{E} \rvvu \left( 1 + \norm{\rvvu}_2^2 \right),
%     \nonumber
% %
% \shortintertext{using the cyclic property of the trace on \cref{eq:thm:general_grad_norm_reparam_eq1},}
% %
%     &\;=
%     \mathrm{tr}\left( \mathbb{E}  \rvvu \rvvu^{\top} \mC^{\top} \mSigma_1 \mSigma_2 \mC  \right)
%     \nonumber
%     \\
%     &\qquad+
%     \mathrm{tr}\left( \mC^{\top} \mSigma_1 \mSigma_2 \mC \, \mathbb{E} \rvvu \rvvu^{\top} \rvvu \rvvu^{\top} \right)
%     \nonumber
%     \\
%     &\qquad+
%     \vm^{\top} \mSigma_1 \mSigma_2 \mC \, \mathbb{E} \rvvu \left( 1 + \norm{\rvvu}_2^2 \right)
%     \nonumber
%     \\
%     &\qquad+
%      \mathbb{E} \rvvu^{\top} \left( 1 + \norm{\rvvu}_2^2 \right) \mC^{\top} \mSigma_1 \mSigma_2  \, \vm
%     \nonumber
%     \\
%     &\qquad+
%     \vm^{\top} \mSigma_1 \mSigma_2 \vm \, \mathbb{E} \rvvu \left( 1 + \norm{\rvvu}_2^2 \right)
%     \nonumber
% %
% \shortintertext{invoking \cref{thm:u_identities},}
% %
%     &\;=
%     \mathrm{tr}\left( \left(\mathbb{E}\rvu_i^2\right) \mI \mC^{\top} \mSigma_1 \mSigma_2 \mC  \right)
%     \nonumber
%     \\
%     &\qquad+
%     \mathrm{tr}\left( \mC^{\top} \mSigma_1 \mSigma_2 \mC \left(\left(d-1\right) {\left(\mathbb{E}\rvu_i^2\right)}^2 + \mathbb{E}\rvu_i^4 \right) \mI \right)
%     \nonumber
%     \\
%     &\qquad+
%     \vm^{\top} \mSigma_1 \mSigma_2 \mC \, \left(\mathbb{E} \rvu_i^3\right) \mathbf{1} 
%     \nonumber
%     \\
%     &\qquad+
%     \left(\mathbb{E} \rvu_i^3\right) \mathbf{1}^{\top} \mC^{\top} \mSigma_1 \mSigma_2  \vm
%     \nonumber
%     \\
%     &\qquad+
%     \vm^{\top} \mSigma_1 \mSigma_2 \vm \, \left( \mathbb{E} \rvu_i^3 \right) \mathbf{1},
%     \nonumber
% %
% \shortintertext{and due to \cref{assumption:symmetric_standard},}
% %
%     &\;=
%     \mathrm{tr}\left( \mC^{\top} \mSigma_1 \mSigma_2 \mC  \right)
%     +
%     \left(d - 1 + \kappa\right) \mathrm{tr}\left( \mC^{\top} \mSigma_1 \mSigma_2 \mC\right)
%     \nonumber
%     \\
%     &\;=
%     \left(d + \kappa\right) \mathrm{tr}\left(\mC^{\top} \mSigma_1 \mSigma_2 \mC \right)
%     \nonumber
%     \\
%     &\;=
%     \left(d + \kappa\right) \mathrm{tr}\left(\mC  \mC^{\top} \mSigma_1 \mSigma_2 \right).
%     \nonumber
%   \end{alignat}
%   Finally, applying this to \cref{eq:general_grad_norm reparam_eq2},
%   \begin{alignat*}{2}
%     &\mathbb{E} \left(\vt_{\vlambda}\left(\rvvu\right) - \vmu_1\right) \mSigma_1 \mSigma_2 \left(\vt_{\vlambda}\left(\rvvu\right) - \vmu_2\right) \left( 1 + \norm{\rvvu}_2^2 \right)
%     \nonumber
%     \\
%     &\;=
%     \left(d + 1\right) \vmu_1^{\top} \mSigma_1 \mSigma_2 \vmu_2
%     +
%     \left(d + \kappa\right) \mathrm{tr}\left(\mC \mC^{\top} \mSigma_1 \mSigma_2 \right).
%   \end{alignat*}
% \end{proofEnd}

% \begin{theoremEnd}[\lemmaproofoption,category=lowerboundlemma]{corollary}\label{thm:q_grad_norm_reparam}
%   Let \(\vt_{\vlambda}: \mathbb{R}^d \mapsto \mathbb{R}^d\) be defined as in \cref{def:reparam} with parameters \(\vlambda = \left(\vm, \mC\right)\) such that \(\vm \in \mathbb{R}^d\) and \(\mC \in \mathbb{R}^{d \times d}\).
%   Also, let \(\rvvu = \left(\rvu_1, \ldots, \rvu_d \right)\) be a vector-valued random variable sampled as \(\rvvu \sim \varphi\), where \(\varphi\) is defined as in \cref{assumption:symmetric_standard} with kurtosis \(\kappa = \mathbb{E}\rvu_i^4\).
%   Then,
%   \begin{alignat*}{2}
%     &\mathbb{E} \left(\vt_{\vlambda}\left(\rvvu\right) - \vm\right) {\left( \mC \mC^{\top}\right)}^{-\top} {\left( \mC \mC^{\top}\right)}^{-1} \left(\vt_{\vlambda}\left(\rvvu\right) - \vm\right) \left( 1 + \norm{\rvvu}_2^2 \right)
%     \\
%     &\;=
%     \left(d + 1\right) \vm^{\top} {\left( \mC \mC^{\top}\right)}^{-\top} {\left( \mC \mC^{\top}\right)}^{-1} \vm
%     +
%     \left(d + \kappa\right) \mathrm{tr}\left( {\left( \mC \mC^{\top} \right)}^{-1} \right).
%   \end{alignat*}
% \end{theoremEnd}
% \begin{proofEnd}
%   From \cref{thm:general_grad_norm_reparam}, we have
%   \begin{alignat}{2}
%     &\mathbb{E} {\left(\vt_{\vlambda}\left(\rvvu\right) - \vm\right)}^{\top} {\left( \mC \mC^{\top}\right)}^{-\top} {\left( \mC \mC^{\top}\right)}^{-1} \left(\vt_{\vlambda}\left(\rvvu\right) - \vm\right) \left( 1 + \norm{\rvvu}_2^2 \right)
%     \nonumber
%     \\
%     &\;=
%     \left(d + 1\right) \vm^{\top} {\left( \mC \mC^{\top}\right)}^{-\top} {\left( \mC \mC^{\top}\right)}^{-1} \vm
%     \nonumber
%     \\
%     &\quad+
%     \left(d + \kappa\right) \mathrm{tr}\left(\mC \mC^{\top} {\left( \mC \mC^{\top}\right)}^{-\top} {\left( \mC \mC^{\top}\right)}^{-1}\right).\label{thm:q_grad_norm_reparam_eq1}
%   \end{alignat}
%   Since, by the basic properties of the trace,
%   \begin{alignat*}{2}
%     \mathrm{tr}\left(\mC \mC^{\top} {\left( \mC \mC^{\top}\right)}^{-\top} {\left( \mC \mC^{\top}\right)}^{-1}\right)
%     &=
%     \mathrm{tr}\left( {\left( \mC \mC^{\top}\right)}^{-1} \mC \mC^{\top} {\left( \mC \mC^{\top}\right)}^{-\top} \right)
%     \\
%     &=
%     \mathrm{tr}\left( \mI \, {\left( \mC \mC^{\top}\right)}^{-\top} \right)
%     \\
%     &=
%     \mathrm{tr}\left( {\left( \mC \mC^{\top}\right)}^{-\top} \right)
%     \\
%     &=
%     \mathrm{tr}\left( {\left( \mC \mC^{\top} \right)}^{-1} \right),
%   \end{alignat*}
%   \cref{thm:q_grad_norm_reparam_eq1} becomes
%   \begin{alignat*}{2}
%     &\mathbb{E} {\left(\vt_{\vlambda}\left(\rvvu\right) - \vm\right)}^{\top} {\left( \mC \mC^{\top}\right)}^{-\top} {\left( \mC \mC^{\top}\right)}^{-1} \left(\vt_{\vlambda}\left(\rvvu\right) - \vm\right) \left( 1 + \norm{\rvvu}_2^2 \right)
%     \\
%     &\;=
%     \left(d + 1\right) \vm^{\top} {\left( \mC \mC^{\top}\right)}^{-\top} {\left( \mC \mC^{\top}\right)}^{-1} \vm
%     +
%     \left(d + \kappa\right) \mathrm{tr}\left( {\left( \mC \mC^{\top} \right)}^{-1} \right).
%   \end{alignat*}
% \end{proofEnd}


% \begin{assumption}[\textbf{Polyak-Łojasiewicz Condition; PL}]\label{assumption:pl}
%   If the gradient of a function \(f : \mathbb{R}^d \rightarrow \mathbb{R}\) satisfies
%   \begin{align*}
%     \frac{1}{2\mu}\norm{ \nabla f\left(\vz\right) }_2^2 \geq  f\left(\vz\right) - f^*
%   \end{align*}
%   for some constant $\mu > 0$, where \(f^* = \inf_{\vz \in \mathbb{R}^d} f\left(\vz\right)\), then $f$ is said to satisfy the Polyak-Łojasiewicz condition.
% \end{assumption}


\begin{theoremEnd}[\theoremproofoption,category=lowerboundtheorem]{theorem}\label{thm:gradient_lower_bound}
Let \(\rvvg_{M}\) be an \(M\)-sample estimator of the gradient of the ELBO in either the entropy- or KL-regularized form.
Also, let ~\cref{assumption:q} hold where the matrix square root parameterization is used.
Then, for all \(L\)-smooth and \(\mu\)-strongly convex functions \(f\) such that $\nicefrac{L}{\mu} < \sqrt{d + 1}$, the variance of \(\rvvg_{M}\) is bounded below by some strictly positive constant as
\begin{align*}
  \mathbb{E}\norm{\rvvg_M}_2^2
  &\geq
  \frac{2\mu^2 \left(d + 1\right) - 2 L^2}{ML} \left( F\left(\vlambda\right) - F^* \right) 
  + \norm{ \nabla F\left(\vlambda\right) }_2^2 \\
  &\quad+ \frac{2 \mu^2 \left(d + 1\right) - 2 L^2}{ML} \left(\mathbb{E}{f\left(\vt_{\vlambda^*}\left(\vu\right)\right)} - f^*\right),  
\end{align*}
as long as $\vlambda$ is in a local neighborhood around the unique global optimum $\vlambda^* = \argmin_{\vlambda \in \mathbb{R}^p} F\left(\vlambda\right)$, where \(F^* = F\left(\vlambda^*\right)\) and \(f^* = \argmin_{\vzeta \in \mathbb{R}^d} f\left(\vzeta\right)\).
\end{theoremEnd}
\vspace{-3ex}
\begin{proofsketch}
  We use the fact that, with the matrix square root parameterization, if \(f\) is \(L\)-smooth, $\mathbb{E} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)$ is also $L$-smooth~\citep{domke_provable_2020}.
  From this, the parameter suboptimality can be related to the function suboptimality as
  {%
  \setlength{\belowdisplayskip}{1ex} \setlength{\belowdisplayshortskip}{1ex}%
  \setlength{\abovedisplayskip}{1ex} \setlength{\abovedisplayshortskip}{1ex}%
  \begin{align*}
    {\lVert \vlambda - \bar{\vlambda} \rVert}^2_2
    \geq
    \left({2}/{L}\right)
    \left(
    \mathbb{E}{f\left(\vt_{\vlambda}\left(\rvvu\right)\right)} 
    - f^*
    \right),
  \end{align*}
  }%
  where \(\bar{\vlambda} = \left(\bar{\vzeta}, \boldupright{O}\right)\).
  For the entropy term, we circumvent the need to directly bound its value by restricting our interest to the neighborhood of the minimizer \(\vlambda^*\), where the contribution of \(h\left(\vlambda^*\right) - h\left(\vlambda\right)\) will be marginal enough for the lower bound to hold.
\end{proofsketch}

\vspace{-2ex}
\begin{proofEnd}
% Note that
% \begin{align*}
% \mathbb{E}\norm{ \vg_M }_2^2
%  = \frac{1}{M} \left(
% \mathbb{E}{ \norm{\nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)}_2^2 }
% -
% \norm{\mathbb{E}{ \nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)} }_2^2
% \right)
% + \norm{ \nabla F\left(\vlambda\right) }^2_2.
% \end{align*}
When using the matrix square root parameterization,~\citet{domke_provable_2020} have shown that if $f$ is $L$-smooth, $\mathbb{E} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)$ is also $L$-smooth.
Therefore, we have
\begin{align} 
    \norm{\mathbb{E}{ \nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)} }_2^2 \leq 2 L \left(\mathbb{E} f\left(\vt_{\vlambda}\left(\rvvu\right)\right) - f^*\right).
    \label{eq:thm_lower_bound_eq1}
\end{align}

Furthermore, let $\bar{\vzeta}$ be the minimizer of $f$, namely $f^* = f\left(\bar{\vzeta}\right)$.
From \cref{thm:variational_gradient_norm_identity}, we have
\begin{align*}
    \mathbb{E}{\norm{\nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)}_2^2} 
    & = \mathbb{E}{\norm{\nabla f\left(\vt_{\vlambda}\left(\rvvu\right)\right)}_2^2 \left(1 + \norm{\rvvu}_2^2\right)},
\shortintertext{by the \(\mu\)-strong convexity of \(f\),}
    & \geq 2 \mu \, \mathbb{E}{\left(f\left(\vt_{\vlambda}\left(\rvvu\right)\right) - f^*\right) \left(1 + \norm{\rvvu}_2^2\right)} \\
    & \geq \mu^2 \, \mathbb{E}{{\lVert\vt_{\vlambda}\left(\rvvu\right) - \bar{\vzeta}\rVert}^2_2 \left(1 + \norm{\rvvu}_2^2\right)},
\shortintertext{applying \Cref{thm:reparam_u_identity},}
    & = \mu^2 \, \left(\left(d + 1\right) {\lVert \vm - \bar{\vzeta} \rVert}^2_2 + \left(d + \kappa\right) \norm{\mC}_{\mathrm{F}}^2\right),
\shortintertext{and by the property of the kurtosis that \(\kappa \geq 1\),}
    & \geq \mu^2 \, \left(d + 1\right) {\lVert \vlambda - \bar{\vlambda} \rVert}^2_2,
\end{align*}
where $\bar{\vlambda} = \left(\bar{\vzeta}, \boldupright{O}\right)$.

Observe that $\bar{\vlambda}$ is the minimizer of $\mathbb{E}{f\left(\vt_{\vlambda}\left(\rvvu\right)\right)}$ 
 such that 
\[
   \mathbb{E}{f\left(\vt_{\bar{\vlambda}}\left(\rvvu\right)\right)} = f\left(\bar{\vzeta}\right) = f^* \leq \mathbb{E}{f\left(\vt_{\vlambda}\left(\rvvu\right)\right)}
\]
for any $\vlambda$.
Furthermore, from the $L$-smoothness of $\mathbb{E}{f\left(\vt_{\vlambda}\left(\rvvu\right)\right)}$, we have
\begin{align*}
    &\mu^2 \left(d + 1\right) {\lVert \vlambda - \bar{\vlambda} \rVert}^2_2 \\
    &\quad\geq \frac{2 \mu^2 \left(d + 1\right)}{L} \left(\mathbb{E}{f\left(\vt_{\vlambda}\left(\rvvu\right)\right)} - \mathbb{E}{f\left(\vt_{\bar{\vlambda}}\left(\rvvu\right)\right)}\right).
\end{align*}
Thus, we have
\begin{align}
    \mathbb{E}{\norm{\nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)}_2^2} 
    &\geq 
    \frac{2 \mu^2 \left(d + 1\right)}{L} \left(\mathbb{E}{f\left(\vt_{\vlambda}\left(\rvvu\right)\right)} - f^*\right).
    \label{eq:thm_lower_bound_eq2}
\end{align}

Now, from \cref{eq:thm_gradient_variance_general_definition},
\begin{align*}
\mathbb{E}\norm{ \vg_M }_2^2
  &= \frac{1}{M} \left(
        \mathbb{E}{ \norm{\nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)}_2^2 }
        -
        \norm{\mathbb{E}{ \nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)} }_2^2
    \right) \\
    &\qquad+ \norm{ \nabla F\left(\vlambda\right) }^2_2,
\shortintertext{applying \cref{eq:thm_lower_bound_eq1},}
  &\geq
  \frac{1}{M} 
  \left(
    \mathbb{E}{ \norm{\nabla_{\vlambda} f\left(\vt_{\vlambda}\left(\rvvu\right)\right)}_2^2 }
    -
    2 L^2 \left(\mathbb{E}{f\left(\vt_{\vlambda}\left(\rvvu\right)\right)} - f^*\right) 
  \right) \\
  &\qquad+ \norm{ \nabla F\left(\vlambda\right) }^2_2 
\shortintertext{applying \cref{eq:thm_lower_bound_eq2},}
  &\geq
  \frac{2 \mu^2 \left(d + 1\right) - 2L^2}{ML} 
  \left(\mathbb{E}{f\left(\vt_{\vlambda}\left(\rvvu\right)\right)} - f^*\right) \\
  &\qquad + \norm{ \nabla F\left(\vlambda\right) }^2_2 
  \\
  &\geq 
  \frac{2 \mu^2 \left(d + 1\right) - 2L^2}{ML} \left(F\left(\vlambda\right) - h\left(\vlambda\right) - f^*\right) \\
  &\qquad+ \norm{ \nabla F\left(\vlambda\right) }^2_2 
  \\
  &= \frac{2 \mu^2 \left(d + 1\right) - 2L^2}{ML} \left(F\left(\vlambda\right) - F^*\right) + \norm{ \nabla F\left(\vlambda\right) }^2_2  \\
  &\qquad+ \frac{2 \mu^2 \left(d + 1\right) - 2 L^2}{ML} \left(F^* - f^* - h\left(\vlambda\right) \right).
\end{align*}
The last term
\begin{align*}
    \frac{2 \mu^2 \left(d + 1\right) - 2 L^2}{ML} \left(F^* - f^* - h\left(\vlambda\right) \right)
\end{align*}
can be shown to be positive if $\vlambda$ is sufficiently close to the optimum.
Let $\vlambda^* = \argmin_{\vlambda} F\left(\vlambda\right)$ be the minimizer of $F$.
Then, we have
\begin{align*}
    F^* - f^* - h\left(\vlambda\right)  
    &= 
    \mathbb{E}{f\left(\vt_{\vlambda^*}\left(\vu\right)\right)} + h\left(\vlambda^*\right) - f^* - h\left(\vlambda\right) 
    \\
    &=
    \left(\mathbb{E}{f\left(\vt_{\vlambda^*}\left(\vu\right)\right)} - f^*\right) + \left(h\left(\vlambda^*\right) - h\left(\vlambda\right)\right),
\end{align*}
where the first term is strictly positive and the second term goes to zero as $\vlambda \to \vlambda^*$.
\end{proofEnd}

%%% Local Variables:
%%% TeX-master: "main"
%%% End:
