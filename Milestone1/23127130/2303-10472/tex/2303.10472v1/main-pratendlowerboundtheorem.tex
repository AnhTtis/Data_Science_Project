

\prAtEndRestatexiii*

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxiii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxiii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof]\phantomsection\label{proof:prAtEndxiii}When using the matrix square root parameterization,~\citet {domke_provable_2020} have shown that if $f$ is $L$-smooth, $\mathbb {E} f\left (\vt _{\vlambda }\left (\rvvu \right )\right )$ is also $L$-smooth. Therefore, we have \begin {align} \norm {\mathbb {E}{ \nabla _{\vlambda } f\left (\vt _{\vlambda }\left (\rvvu \right )\right )} }_2^2 \leq 2 L \left (\mathbb {E} f\left (\vt _{\vlambda }\left (\rvvu \right )\right ) - f^*\right ). \label {eq:thm_lower_bound_eq1} \end {align} \par Furthermore, let $\bar {\vzeta }$ be the minimizer of $f$, namely $f^* = f\left (\bar {\vzeta }\right )$. From \cref {thm:variational_gradient_norm_identity}, we have \begin {align*} \mathbb {E}{\norm {\nabla _{\vlambda } f\left (\vt _{\vlambda }\left (\rvvu \right )\right )}_2^2} & = \mathbb {E}{\norm {\nabla f\left (\vt _{\vlambda }\left (\rvvu \right )\right )}_2^2 \left (1 + \norm {\rvvu }_2^2\right )}, \shortintertext {by the \(\mu \)-strong convexity of \(f\),} & \geq 2 \mu \, \mathbb {E}{\left (f\left (\vt _{\vlambda }\left (\rvvu \right )\right ) - f^*\right ) \left (1 + \norm {\rvvu }_2^2\right )} \\ & \geq \mu ^2 \, \mathbb {E}{{\lVert \vt _{\vlambda }\left (\rvvu \right ) - \bar {\vzeta }\rVert }^2_2 \left (1 + \norm {\rvvu }_2^2\right )}, \shortintertext {applying \Cref {thm:reparam_u_identity},} & = \mu ^2 \, \left (\left (d + 1\right ) {\lVert \vm - \bar {\vzeta } \rVert }^2_2 + \left (d + \kappa \right ) \norm {\mC }_{\mathrm {F}}^2\right ), \shortintertext {and by the property of the kurtosis that \(\kappa \geq 1\),} & \geq \mu ^2 \, \left (d + 1\right ) {\lVert \vlambda - \bar {\vlambda } \rVert }^2_2, \end {align*} where $\bar {\vlambda } = \left (\bar {\vzeta }, \mO \right )$. \par Observe that $\bar {\vlambda }$ is the minimizer of $\mathbb {E}{f\left (\vt _{\vlambda }\left (\rvvu \right )\right )}$ such that \[ \mathbb {E}{f\left (\vt _{\bar {\vlambda }}\left (\rvvu \right )\right )} = f\left (\bar {\vzeta }\right ) = f^* \leq \mathbb {E}{f\left (\vt _{\vlambda }\left (\rvvu \right )\right )} \] for any $\vlambda $. Furthermore, from the $L$-smoothness of $\mathbb {E}{f\left (\vt _{\vlambda }\left (\rvvu \right )\right )}$, we have \begin {align*} &\mu ^2 \left (d + 1\right ) {\lVert \vlambda - \bar {\vlambda } \rVert }^2_2 \\ &\quad \geq \frac {2 \mu ^2 \left (d + 1\right )}{L} \left (\mathbb {E}{f\left (\vt _{\vlambda }\left (\rvvu \right )\right )} - \mathbb {E}{f\left (\vt _{\bar {\vlambda }}\left (\rvvu \right )\right )}\right ). \end {align*} Thus, we have \begin {align} \mathbb {E}{\norm {\nabla _{\vlambda } f\left (\vt _{\vlambda }\left (\rvvu \right )\right )}_2^2} &\geq \frac {2 \mu ^2 \left (d + 1\right )}{L} \left (\mathbb {E}{f\left (\vt _{\vlambda }\left (\rvvu \right )\right )} - f^*\right ). \label {eq:thm_lower_bound_eq2} \end {align} \par Now, from \cref {eq:thm_gradient_variance_general_definition}, \begin {align*} \mathbb {E}\norm { \vg _M }_2^2 &= \frac {1}{M} \left ( \mathbb {E}{ \norm {\nabla _{\vlambda } f\left (\vt _{\vlambda }\left (\rvvu \right )\right )}_2^2 } - \norm {\mathbb {E}{ \nabla _{\vlambda } f\left (\vt _{\vlambda }\left (\rvvu \right )\right )} }_2^2 \right ) \\ &\qquad + \norm { \nabla F\left (\vlambda \right ) }^2_2, \shortintertext {applying \cref {eq:thm_lower_bound_eq1},} &\geq \frac {1}{M} \left ( \mathbb {E}{ \norm {\nabla _{\vlambda } f\left (\vt _{\vlambda }\left (\rvvu \right )\right )}_2^2 } - 2 L^2 \left (\mathbb {E}{f\left (\vt _{\vlambda }\left (\rvvu \right )\right )} - f^*\right ) \right ) \\ &\qquad + \norm { \nabla F\left (\vlambda \right ) }^2_2 \shortintertext {applying \cref {eq:thm_lower_bound_eq2},} &\geq \frac {2 \mu ^2 \left (d + 1\right ) - 2L^2}{ML} \left (\mathbb {E}{f\left (\vt _{\vlambda }\left (\rvvu \right )\right )} - f^*\right ) \\ &\qquad + \norm { \nabla F\left (\vlambda \right ) }^2_2 \\ &\geq \frac {2 \mu ^2 \left (d + 1\right ) - 2L^2}{ML} \left (F\left (\vlambda \right ) - h\left (\vlambda \right ) - f^*\right ) \\ &\qquad + \norm { \nabla F\left (\vlambda \right ) }^2_2 \\ &= \frac {2 \mu ^2 \left (d + 1\right ) - 2L^2}{ML} \left (F\left (\vlambda \right ) - F^*\right ) + \norm { \nabla F\left (\vlambda \right ) }^2_2 \\ &\qquad + \frac {2 \mu ^2 \left (d + 1\right ) - 2 L^2}{ML} \left (F^* - f^* - h\left (\vlambda \right ) \right ). \end {align*} The last term \begin {align*} \frac {2 \mu ^2 \left (d + 1\right ) - 2 L^2}{ML} \left (F^* - f^* - h\left (\vlambda \right ) \right ) \end {align*} can be shown to be positive if $\vlambda $ is sufficiently close to the optimum. Let $\vlambda ^* = \argmin _{\vlambda } F\left (\vlambda \right )$ be the minimizer of $F$. Then, we have \begin {align*} F^* - f^* - h\left (\vlambda \right ) &= \mathbb {E}{f\left (\vt _{\vlambda ^*}\left (\vu \right )\right )} + h\left (\vlambda ^*\right ) - f^* - h\left (\vlambda \right ) \\ &= \left (\mathbb {E}{f\left (\vt _{\vlambda ^*}\left (\vu \right )\right )} - f^*\right ) + \left (h\left (\vlambda ^*\right ) - h\left (\vlambda \right )\right ), \end {align*} where the first term is strictly positive and the second term goes to zero as $\vlambda \to \vlambda ^*$.\end{proof}
