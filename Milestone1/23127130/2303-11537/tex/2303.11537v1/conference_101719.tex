\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{url}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{lipsum}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Interactive Geometry Editing of Neural Radiance Fields
}

\author{\IEEEauthorblockN{Shaoxu Li}
\IEEEauthorblockA{\textit{John Hopcroft Center for Computer Science} \\
\textit{Shanghai Jiao Tong University}\\
Shanghai, China \\
lishaoxu@sjtu.edu.cn}
\and
\IEEEauthorblockN{Ye Pan*}
\IEEEauthorblockA{\textit{John Hopcroft Center for Computer Science} \\
\textit{Shanghai Jiao Tong University}\\
Shanghai, China \\
whitneypanye@sjtu.edu.cn}
}

\twocolumn[{%
\renewcommand\twocolumn[1][]{#1}%
\maketitle
\begin{center}
    \centering
    \captionsetup{type=figure}
    \includegraphics[width=0.8\textwidth]{title.pdf}
    \captionof{figure}{Geometry editing results of our method. For a static neural radiance field(NeRF), users can explicitly edit the implicit representation of the scene, without leverage explicit 3D representation. Users can manipulate the scene by select two cages and transform the inner cage. Basic operations for cage include translation, rotation, scaling, moving the corners or edges. Complex deformation will can be achieved through users' multiple manipulation.}
\end{center}%
}]


%\maketitle

\begin{abstract}
In this paper, we propose a method that enables the interactive geometry editing for neural radiance fields manipulation. We use two cages(inner cage and outer cage) to enable editing of a scene. Various operations are applicable to the two cages. Operations on the inner cage lead to desired deformation of inner cage and adjustment of the outer cage. Operations on the outer cage lead to deformation without changing the rest space. Users can editing the scene with translation, rotation, scaling or any combination of these. And the operations on the corners and edges of the cage are also supported. Our method does not need any explicit 3D geometry representations. The interactive geometry editing applies directly to the implicit neural radiance fields. The deformation results demonstrate the effectiveness of our approach.
\end{abstract}

\begin{IEEEkeywords}
scene representation, scene manipulation, radiance field
\end{IEEEkeywords}

\section{Introduction}
Novel view synthesis has recently received increasing attention for its extensive application prospect, such as virtual and augmented reality, business and artistic creation. Recently, neural radiance field(NeRF)\cite{mildenhall2020nerf} has received increasing attention due to its high representation ability for 3D scene. Fruitful follow-up works emerged for the improvement and application of NeRF, such as acceleration\cite{yu2022Plenoxels,Chen2022TensoRF,mueller2022instant}, scene generation\cite{Schwarz2020GRAF,Niemeyer2021GIRAFFE,Eric2021piGAN}, dynamic scene rendering\cite{park2021hypernerf,kania2022conerf}, scene style transfer\cite{Chiang2021Stylizing3S,Huang2022StylizedNeRF,chen2022upstnerf}, large-scale scene rendering\cite{Tancik2022Block,li2022read}. However, as an implicit 3D representation method, the neural radiance field is hard to edit and manipulate. Some researchers leveraged the explicit 3D representation to accomplish the editing task\cite{Yuan22NeRFEditing,xu2022deforming,peng2021CageNeRF}, such as meshes. Users can intuitively edit the scene and accomplish shape deformation on the geometry. However, the transformation between NeRF and mesh is cumbersome and unexplored, which impedes the usability and quality. In this paper, we focus on the interactive geometry editing of neural radiance fields, no need to acquire explicit 3D models.

3D shape editing is a popular research topic because its applicability in games, movies, etc. Traditional 3D shape editing methods focus on the explicit 3D models. Attribute-based model editing focus on the attributes of the surface model. The geometry characteristics and semantic attributes are the mainly constraints for model editing. Geometry-based deformation methods optimize the energy functions to accomplish the deformation problem, such as Laplacian-Based Mesh Deformation\cite{}, As-rigid-as-possible\cite{}. Semantic constraints methods are  high-level editing
methods which edit multiple vertices at the same time, such as FFD\cite{}. Proxy-based deformation\cite{} use skeleton to guide the deformation of realistic animated characters. Cage-based deformation\cite{} use cages wrapped outside the model for users interactive editing. Data-Based Deformation leverage shape datasets to produce more natural deformation results, such as Mesh-Based Inverse Kinematics(MeshIK). Neural Shape Editing has been popular in recent years. Latent feature provide a convenient way for shape editing.


The direct manipulation of NeRF for some specific tasks has been researched. Given a set of images for specific target, such as human faces, 3D-aware image synthesis could be accomplished with generative methods, such as GRAF\cite{Schwarz2020GRAF}, GIRAFFE\cite{Niemeyer_2021_GIRAFFE}, pi-gan\cite{piGAN2021}. These methods can accomplish attribute editing and composition with 3D consistency for the target domain. For the human faces, some methods use face parameters to embed the latent codes\cite{hong2021headnerf,Gafni_2021_Dynamic}. Controllable face generation represented by neural radiance field can be accomplished. For videos input, some methods\cite{park2021hypernerf} project NeRF into high-dimensional space for dynamic neural radiance fields modeling, enabling the deformation of neural radiance fields. For the editing of universal neural radiance fields, some method leverage the explicit 3D representation to deform the scene. Existing researches\cite{Yuan22NeRFEditing,xu2022deforming,peng2021CageNeRF} extract meshes from the optimized radiance field, deform the meshes. And then the deformation meshes guide the generation of deformed radiance field. Although these methods above have made some achievements in radiance field manipulation, there is no methods can direct manipulate universal neural radiance field scenes with interactive operations.

To address the above issues, we propose a method for editing neural radiance field that interactive deform the space. Different from previous methods, our method does not need any explicit 3D geometry representations. Users can edit the neural radiance field through direct interaction. We propose to offer
two cages to the users for interactive geometry editing of neural radiance field. The two cages are inclusion relations. Users define the position of the two cages and manipulate the inner cage. The inner cage can be controlled with translation, rotation, scaling, and moving the corners or edges. The space inside the outer cage and outside the inner cage is adjusted with interpolation to promise the continuity of the scene. Users can accomplish simple deformation of the target scene. Complex deformation requires the users multiple manipulation.

We conducted extensive experiments with synthetic datasets and real-world datasets. Reasonable deformation and rendering results demonstrate the effectiveness of our method.

In summary, our contributions are listed as follows:
\begin{itemize} 
\item We proposed a new method to explicitly manipulate the radiance fields without any explicit 3D geometry representations.

\item We designed interactive mode with two cages and various operations for interactive geometry editing of radiance fields.

\item We conducted extensive experiments to execute operations we designed and the rendering results demonstrate the effectiveness of our approach.
\end{itemize}

\section{Related Work}
\noindent\textbf{Novel View Synthesis.}
Novel view synthesis is a significant task in computer vision. Traditional methods use explicit represent methods for 3D object or scene modeling, such as meshes and point clouds. Recently, neural rendering has received increasing attention. The neural radiance fields(NeRF)\cite{mildenhall2020nerf} is the representative work, which use a multilayer perception(MLP) to model the scene. 
The model learns the target scene from a set of images and output photo-realistic rendering with volume rendering. Plenty of follow-up works emerged for higher quality, faster speed, and more application. Although these works improve the quality and practicability of NeRF, editing of NeRF is still unexplored due to its an implicit method.


\noindent\textbf{Explicit 3D Geometry Deformation.}
Interactive geometry editing of 3D object is a vital task for artistic creation and production. For interactive geometry editing of explicit 3D models, many mature algorithms have been widely used in commercial software. Free-Form Deformation(FFD)\cite{Sederberg1986Free} is a basic mesh deformation method which embeds the 3D model into the deformation space and then the deformation space is manipulated to deform the embedded geometric model. FFD can not control large meshes and it does not consider the object morphology. Cage-based deformation(CBD)\cite{Joshi2007Harmonic,YifanNeuralCage2020} manipulates the vertices surrounding the object cage to deform the object. The new position of mesh points can be calculated form the relative transformation between cage and deformed cage coordinates. In our method, users use two nested cages for shape deformation. The control accuracy of our method is between the FFD\cite{Sederberg1986Free} and CBD\cite{Joshi2007Harmonic,YifanNeuralCage2020} for meshes.

\begin{figure*}[ht]
\centering
\includegraphics[width=\linewidth]{model.pdf}
\caption{The architecture of our method. Our approach uses two cages to execute interactive neural radiance field editing. Users setting two cages firstly. Then uses can edit the inner cage with predefined operations, including cage transformation(translation, rotation,
scaling), and cage deformation(move the corners or edges of
the cage). The radiance field inside the inner cage change with the cage. Two kinds of deformation can be chosen for the deforming of radiance fields. Discrete adjustment only adjusts the cage areas. Continuous adjustment use interpolation to promise the continuity of the radiance field.}
\label{fig:model}
\end{figure*}
\noindent\textbf{Neural Radiance Fields Deformation.} The editing an universal static NeRF scene is still unexplored. NeRF-Editing\cite{Yuan22NeRFEditing} extract an explicit triangular mesh representation from the
trained NeRF, and the explicit mesh representation is then intuitively deformed by the user. The deformation of the mesh propagates the deformation of the scene geometric surface to the spatial discrete deformation field. DRFC\cite{xu2022deforming} use a triangular mesh that encloses the foreground object called cage as an interface, and by manipulating the cage vertices, our approach enables the
free-form deformation of the radiance field. CageNeRF\cite{peng2021CageNeRF} perform the deformation on an enclosing polygon mesh with sparsely defined vertices
called cage inside the rendering space, where each point is projected into a novel
position based on the barycentric interpolation of the deformed cage vertices. NeRFshop\cite{Jambon2023NeRFshop} provides a scribble-based interface for interactive object selection in NeRFs and semi-automatic cage building. The user scribbles on the target object or volumetric region in space. NeRFshop reprojects the scribbles into the 3D volume, performs region growing, builds a cage and discretizes the volume using a tetrahedral mesh. Manipulating the corners of the cages accomplishes free-form editing of NeRF. All these methods with meshes above can edit NeRF with good quality. The meshes increase the complexity and time consuming of editing. We propose a novel interactive geometry editing method without mesh, which is more simple and faster.


\section{Method}
We deform the NeRF scene by manipulating the space. As shown in Fig.\ref{fig:model}, the first step is to select two cage box for deformation, inner cage for interactive manipulating and the outer for automatic adjustment. The inner cage is inside of the outer cage. Then, the user can manipulate the inner cage optionally, including translation, rotation, scaling, shearing or any combination of these. And the movement of corners and edges of the inner cage are also supported. The scenes update with the manipulation of users. Other regions in the outer cage is adjusted using interpolation algorithm. The regions outside of the outer cage remain unchanged.

\subsection{Neural Radiance fields}
For the scene to be edited, we first use a typical NeRF to optimize the radiance field. Neural Radiance fields(NeRF) proposes to use a multi-layer perceptron (MLP) to model a scene, given a set of images form different views. NeRF generates light rays from image pixels toward the scene, given camera parameters and positions. For the rays, NeRF sample points on the ray and embeds the points position $\bold{p}\in \mathbb{R}^3$ and ray direction $\bold{d}\in \mathbb{R}^3$ for volume rendering. The networks learns the mapping from embed features to the RGB color $\bold{c}\in \mathbb{R}^3$ and density $\sigma \in \mathbb{R}^3$ of the points:
\begin{equation}
    \bold{F}_\Theta : (\gamma(\bold{p}),\gamma(\bold{d})) \rightarrow (\bold{c},\sigma)
\end{equation}
where $\gamma(\cdot)$ is the position embedding function, $\Theta$ is the trainable parameters. Given the ray $\bold r$ from image pixels, photorealistic rendering can be accomplished with the color and density, using discrete integration.

Since the rendering is based on sampled points, the adjustment of the points coordinates acts on the rendering results. For NeRF manipulation, deforming the coordinates space is workable for deforming the NeRF scene.

\subsection{Interactive Operations} \label{Interactive Operations}
For deforming the neural radiance fields interactively, we propose to explicitly manipulate
the radiance fields without any explicit 3D models. We accomplish the manipulation with two cages, one inner cage and one outer cage. The inner cage is inside the outer cage. The two cages are manually set, and the inner cages can be moved or edited. When the inner cage is modified, the space inside the outer cage is adjusted accordingly. The space outside the pouter cage remain unchanged. The inner cage executes the deformation intentions of users, meanwhile the outer cage promises the continuity of the radiance field scene.

\subsubsection{Cage setting}
\label{Cage setting}
For interactive editing, users shall define two cages manually to confine the operation area. 
As shownm in Fig.\ref{fig:two_cages}, two cages wrap part of the radiance field. The edges of cages are rendered together with the neural radiance field. For later calculation, the two cages are denoted as $\boldsymbol{C}_{i}$ with vertices ${\bold{v}_{i}}$, $\boldsymbol{C}_{o}$ with vertices ${\bold{v}_{o}}$. And the two cages warp the radiance field space to be edited. In the cage setting process, all the transformation operations in Sec.\ref{Cage Transformation} are supported. The setting operations only transform the shape and position of the two cages, leaving the radiance field unchanged. The outer cage can be moved in the whole radiance field space, and refines the motion of the inner cage.
\begin{figure}[ht]
\centering
\includegraphics[width=0.6\linewidth]{two_cages.pdf}
\caption{Users shall define two cages manually. The outer cage warps the inner cage. In the cage setting process, the radiance field remain unchanged.}
\label{fig:two_cages}
\end{figure}
\subsubsection{Cage Transformation}
\label{Cage Transformation}
For the inner or the outer cage, users can move the cages with different operations, including translation, rotation, scaling or any combination of these. Since these operations shall take the cage center as the central, the coordinates shall be adjusted for transformation. For simplification, the center changes with translation, rotation, scaling operations. For the cage deformation operations in Sec.\ref{Cage Deformation}, the cage center remains unchanged. In this instance, the point coordinates adjustment is easy to implement. Given a cage $\boldsymbol{C}$ with vertices ${\bold{v}_{j}}$, points $\bold{p}\in \mathbb{R}^3$ in space can be adjusted to $\bold{p}_{c}\in \mathbb{R}^3$:

\begin{equation}
\label{equation:center adjust}
\bold{p}_{c}=\bold{p}-\frac{1}{6}\sum_{j} \bold{v}_{j}
\end{equation}
After adjustment, the translation, rotation, scaling could be accomplished through user interactions. We capture the user actions into transformation parameters, including translation vector $(t_x,t_y,t_z)$, rotation vector $(\theta_x,\theta_y,\theta_z)$ and scale vector $(s_x,s_y,s_z)$. $(t_x,t_y,t_z)$ denotes the translation along the $X,Y,Z$ axes. $(\theta_x,\theta_y,\theta_z)$ denotes the rotation angles along the $X,Y,Z$ axes. $(s_x,s_y,s_z)$ denotes the scale factor along the $X,Y,Z$ axes. For points $\bold{p}=(x,y,z)$ inside the cage, the adjusted coordinates are denoted as $\bold{p}_{c}=(x_c,y_c,z_c)$. The transformation are accomplished using Eq.\ref{equation:Transformation}.
\begin{equation}
\label{equation:Transformation}
\begin{bmatrix}
x_c'\\y_c'\\z_c'\\1
\end{bmatrix}
=
T R_x R_y R_z S
\begin{bmatrix}
x_c\\y_c\\z_c\\1
\end{bmatrix}
\end{equation}
where $(x_c',y_c',z_c')$ denotes the transformed coordinates, $T$ denotes the translation matrix, $R_x R_y R_z$ denote the rotation matrices, $S$ denote the scale matrix. These matrices are calculated using Eq.\ref{equation:translation},\ref{equation:rotation},\ref{equation:scaling}.
\begin{equation}
\label{equation:translation}
T=
\begin{bmatrix}
1&0&0&t_{x}\\
0&1&0&t_{y}\\
0&0&1&t_{z}\\
0&0&0&1
\end{bmatrix}
\end{equation}
\begin{equation}
\label{equation:rotation}
\begin{split}
R_x=
\begin{bmatrix}
1&0&0&0\\
0&cos\theta_x&-sin\theta_x&0\\
0&sin\theta_x&cos\theta_x&0\\
0&0&0&1
\end{bmatrix}\\
R_y=
\begin{bmatrix}
cos\theta_y&0&sin\theta_y&0\\
0&1&0&0\\
-sin\theta_y&0&cos\theta_y&0\\
0&0&0&1
\end{bmatrix}\\
R_z=
\begin{bmatrix}
cos\theta_z&sin\theta_z&0&0\\
-sin\theta&cos\theta_z&0&0\\
0&0&1&0\\
0&0&0&1
\end{bmatrix}
\end{split}
\end{equation}

\begin{equation}
\label{equation:scaling}
S=
\begin{bmatrix}
s_x&0&0&0\\
0&s_y&0&0\\
0&0&s_z&0\\
0&0&0&1
\end{bmatrix}
\end{equation}

\subsubsection{Cage Deformation}
\label{Cage Deformation}
Besides transforming the whole cage, the deformation of cage is also available. 
For the inner or the outer cage, users can deform the cage through move the corners or edges of the cages. Given a cage $\boldsymbol{C}$ with vertices ${\bold{v}_{j}}$, edges ${\bold{e}_{k}}$, users can drag the any visible vertices or edges to available positions. After deformation, the new vertices ${\bold{v}_{j}'}$ and edges ${\bold{e}_{k}'}$ constitute the new cages. 

The cage transformation does not change the shape of the two cages. The cage deformation manipulates the shape of the two cages. In the cage transformation, the coordinates transformation of points inside the cage is the same as the cage corners. In the cage deformation, the points coordinates inside the cage is calculated with interpolation
using the the cage corners coordinates.


\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{comparison.pdf}
\caption{Comparison with state of art methods. From left to right: original scenes, results of varying degrees of deformation, results of novel views. From top to bottom(each scene), DRFC, NeRFshop and ours.}
\label{fig:comparison}
\end{figure*}

\subsection{Deforming radiance fields}
In our method, users use two cages to deform the radiance fields, the inner cage and the outer cage. Users can manipulate the two cages with all the interactive operations in Sec.\ref{Interactive Operations}. For the cage setting process in Sec.\ref{Cage setting}, only the cage moves. For the deforming of radiance fields, the space is warped to achieve the desired editing. 

The deformed radiance field $\Psi$ can be divided into four parts depending on the space that: (1) outside the outer cage, (2) inside the outer cage but outside the canonical inner cage and transformed inner cage, (3) inside the canonical cage but outside the transformed inner cage, (4) inside the transformed inner cage. When editing the inner cage, two kinds of deformation can be chosen, the discrete and the continuous adjustment.



\subsubsection{Discrete adjustment}
For discrete adjustment, the operation with the inner cage only change the rendering results inside the inner cage. We denote the transformed-to-canonical mapping of spatial position and view direction as:
\begin{equation}
    \phi_\bold{p}:\bold{p}\rightarrow \bold{p}^c, \phi_\bold{d}:(\bold{p},\bold{d})\rightarrow \bold{d}^c, 
\end{equation}
where $\bold{p}^c$ can be obtained form operations in Sec.\ref{Cage Transformation} and \ref{Cage Deformation}. For cage transformation, the mapping is the transformation in Eq.\ref{equation:Transformation}. For cage deformation, the mapping is obtained with trilinear interpolation, whose control points are sampled from the surface of cages.

Given outer cage $\boldsymbol{C}_o$, canonical inner cage $\boldsymbol{C}_i^c$, transformed inner cage $\boldsymbol{C}_i$, the transformation function, 
\begin{equation}
    \Psi^D(\bold{p},\bold{d})=
        \begin{cases}
        \Psi^(\bold{p},\bold{d}), \bold{p} \in \mathbb R^3\backslash \mathbb V^o  \\ 
        \Psi^(\bold{p},\bold{d}), \bold{p} \in \mathbb V^o \backslash (\mathbb V^c \cup \mathbb V)\\
        (\textbf{0},0), \bold{p} \in \mathbb V^c \backslash (\mathbb V^c \cap \mathbb V)\\
       \Psi^(\phi_\bold{p}(\bold{p}),\phi_\bold{d}(\bold{p},\bold{d})), \bold{p} \in  \mathbb V\\
        \end{cases}
\end{equation}
where $\mathbb V^o,\mathbb V^c,\mathbb V \in \mathbb R^3$ denotes the space enclosed by $\boldsymbol{C}_o$, $\boldsymbol{C}_i^c$ and $\boldsymbol{C}_i$, respectively. The space inside the inner cage in the deformed radiance field is substituted by the space inside the inner cage in the canonical radiance field. For the areas the inner cage used to be, empty rendering results(zero density) are filled. The space outside the inner cage remains unchanged. In this way, the movement of the operation target is independent of the whole radiance field, which means disconnection may emerge with the operation.


\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{result1.pdf}
\caption{Results of different edits. The mic is a synthesis scene. The pinecone is a real scene. The red arrows indicate the editing details. For each edit of two scenes, we show the editing results form three views.}
\label{fig:operations}
\end{figure*}
\subsubsection{Continuous adjustment}
For continuous adjustment, the operation with the inner cage change the rendering results inside the whole outer cage. 

Given outer cage $\boldsymbol{C}_o$, canonical inner cage $\boldsymbol{C}_i^c$, transformed inner cage $\boldsymbol{C}_i$, the transformation function, 
\begin{equation}
    \Psi^D(\bold{p},\bold{d})=
        \begin{cases}
        \Psi^(\bold{p},\bold{d}), \bold{p} \in \mathbb R^3\backslash \mathbb V^o  \\ 
        \Psi^(\phi_\bold{p}(\bold{p}),\phi_\bold{d}(\bold{p},\bold{d})), \bold{p} \in \mathbb V^o \backslash (\mathbb V^c \cup \mathbb V)\\
        \Psi^(\phi_\bold{p}(\bold{p}),\phi_\bold{d}(\bold{p},\bold{d})), \bold{p} \in \mathbb V^c \backslash (\mathbb V^c \cap \mathbb V)\\
       \Psi^(\phi_\bold{p}(\bold{p}),\phi_\bold{d}(\bold{p},\bold{d})), \bold{p} \in  \mathbb V\\
        \end{cases}
\end{equation}
The space inside the inner cage in the deformed radiance field is substituted by the space inside the inner cage in the canonical radiance field. For the areas outside the inner cage but inside the outer cage, interpolation results are calculated according the the coordinates deformation in the surface of inner and outer cage. The space outside the inner cage remains unchanged. In this way, the continuity of the radiance field remains unchanged before and after the deformation.





\section{Experiments}
\label{sec:experiments}
In this section, we evaluate the effectiveness of our approach through a variety of scenes. We show the results of extensive ablation studies and then discuss the limitations of our approach. Our results are based on the original NeRF\cite{mildenhall2020nerf}. Since we only manipulate the points coordinates, our method apply to various modified NeRF methods. The code is accomplished using Pytorch on a single Nvidia 3080 GPU.
\subsection{Comparison}
For arbitrary scene editing, the ground truth results of the deformation are not available. For different NeRF editing methods, it's hard for users to accomplish duplicate operations. Consider this, we execute comparison on NeRF-Synthetic dataset\cite{mildenhall2020nerf} for basic editing operations. We compare our method with state of art methods DRFC\cite{xu2022deforming}, NeRFshop\cite{Jambon2023NeRFshop}. Similar editing operations are executed on the radiance field. Our method directly interacts with the radiance field, while DRFC and NeRFshop extract meshes, edit the meshes cages and then deforms the radiance fields. Fig.\ref{fig:comparison} shows the results. Two scenes are edited respectively. The original scene, the results of varying degrees of deformation, novel views of edited results are shown from left to right. For the Lego, the shovel moves from top to bottom and rotates with an angle. For the chair, the height decreases while the width increases.


\begin{figure*}[t]
\centering
\includegraphics[width=0.8\linewidth]{albation_resolution.pdf}
\caption{Impact of continuous adjustment and discrete adjustment.}
\label{fig:resolution_result}
\end{figure*}

The editing methods with mesh cages manipulate the scene with cage deformation. When moving the cage corners, these corners and the space inside each tetrahedron are adjusted. Since the cage is generated with algorithms, the adjustment is not always ideal. In our method, we maintain the space inside the inner cage relatively constant. As shown in the Lego results of DRFC and NeRFshop, different degrees of distortion have occurred with the shovel shape. In ours results for Lego, shape changes only with the joint space, and the shovel and loader body remain unchanged. Our method and DRFC are based on the original NeRF. The NeRFshop is based on the Instant-NGP, which uses a hash table to accomplish the position encoding. The method use occupancy grids to represent the scene and skips the empty areas in optimization process. For the empty space in the results of NeRFshop, color and density artifacts exist because of the occupancy grids, as shown in Fig.\ref{fig:comparison}.




\subsection{Operations}
To illustrate the effective of our method, we manually editing the scene with all the operations we defines. Two kinds of operations are supported in our method. The first is cage transformation, and the second is cage deformation. Fig.\ref{fig:operations} shows the novel view synthesis results of the original and deformed scene. Two scenes from \cite{} and Nerf360\cite{} are optimized and edited manually with different operations. The mic scene is a rendered scene from nerf synthesis dataset. The first line shows the rendering results of different views. The second to fourth lines show the editing results of scaling, rotation, translation of the receiver of the mic, separately. The pinecone scene is a real scene from nerfreal360 dataset. The first line shows the rendering images of different views. The second to fourth lines show the editing results of lower half scaling with top unchanged, top rotation with bottom unchanged, top translation with bottom unchanged of the pinecone, separately. 

\subsection{Discrete adjustment}
In cases above, we show the editing results with various operations on synthesis and real scenes. All the results above are continuous adjustment, which adjusts the space inside the outer cage for continuity between the inner cage and the space outside the outer cage.


\subsection{Ablation study}
\noindent\textbf{Impact of continuous adjustment and discrete adjustment.}
The deforming results of all the results in Sec.\ref{sec:experiments} are continuous adjustments. The surrounding space of the manipulation target is adjusted. For discrete adjustment, the manipulation only applies to the inner space. Fig.\ref{fig:discrete_result} shows the comparison between continuous adjustment and discrete adjustment. F User manipulate the Lego loader with a translation. Only the loader moves in the discrete translation. The floor had obvious displacement and deformation in the continuous translation. In our method, we use cube cages for illustration. For free editing, the cages is not restricted to typical shapes. And users can even indicate some control point for NeRF deformation. The core idea of our method is to define two space for deform and adjust the scene.


\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{albation_discrete.pdf}
\caption{Impact of continuous adjustment and discrete adjustment.}
\label{fig:discrete_result}
\end{figure}

\noindent\textbf{Impact of discretization resolution.}
The mapping from canonical-to-deformed stretches or compresses the space. For typical NeRF, high resolution leads to good rendering quality, while increases the computation time and space. Fig.\ref{fig:resolution_result} shows the synthesized results with different resolutions. For 64 resolution, significant discontinuities can be observed. With the increase of resolution, the discontinuities decrease.


\noindent\textbf{Impact of movement range.}



\section{Disscussion and Limitations}

\subsection{Disscussion} We propose the first interactive editing method for neural radiance field without mesh extraction. Compared with state-of-art NeRF editing methods with automatic mesh cage generation, we propose to allow users define simple cages freely. Although automatic mesh cage generation seems to make the users interaction easier, the generated cages are unfixed. The cages may be different in two cases for the same scene.

\subsection{Limitations}There are some limitations to our method.  Firstly, reasonable canonical radiance field space is desirable for deformation. In our method, the deformation results of the space inside the outer cage and outside the inner cage is interpolation. For some scenes with images from single side, parts of the scene are under-modeled due to occlusion. The modeling results are not match with reality space although the rendering in some views quality is satisfactory. Unideal canonical radiance field space may lead to bad deformation results. For example, the rotation leads to breakage in the skeleton, as shown in Fig.\ref{fig:broken_result}.
\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{broken_result.pdf}
\caption{result1}
\label{fig:broken_result}
\end{figure}

Secondly, we use to cages to accomplish the manipulation of space. Two cages is far from conforming the shape details of scene. That means the manipulation of our method is coarse. For delicate manipulation, users need to do multiple operations. And since our cage is cuboid, large scale deformation leads to unideal interpolation results.

Thirdly, the editing with deforming the space does not maintain the consistency of illustration.
\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{illu.pdf}
\caption{result1}
\label{fig:illu}
\end{figure}

\section{Conclusion}
In this paper, we propose the first method to support interactive controlling the shape deformation of neural radiance field without mesh extraction. By choosing the deformation area(inner cage) and the adjustment area(outer cage) with two cages, users can interactively edit the radiance field with various operations. Predefined operations include cage transformation(translation, rotation, scaling on the whole cage) and deformation(movement on the cage corners or edges). Discrete and continuous adjustment can be chosen. Discrete adjustment only move the deformation target, while continuous adjustment adjust the outer space for continuity. We demonstrate the effectiveness of our method on synthetic and real scenes, comparing with state-of-art methods. Our method is accomplish with the original NeRF, which applies to various modified NeRF methods.
% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{icme2023template}

\end{document}
