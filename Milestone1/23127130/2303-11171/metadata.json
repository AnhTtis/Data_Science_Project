{
    "arxiv_id": "2303.11171",
    "paper_title": "Naver Labs Europe (SPLADE) @ TREC NeuCLIR 2022",
    "authors": [
        "Carlos Lassance",
        "St√©phane Clinchant"
    ],
    "submission_date": "2023-03-10",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.IR"
    ],
    "abstract": "This paper describes our participation in the 2022 TREC NeuCLIR challenge. We submitted runs to two out of the three languages (Farsi and Russian), with a focus on first-stage rankers and comparing mono-lingual strategies to Adhoc ones. For monolingual runs, we start from pretraining models on the target language using MLM+FLOPS and then finetuning using the MSMARCO translated to the language either with ColBERT or SPLADE as the retrieval model. While for the Adhoc task, we test both query translation (to the target language) and back-translation of the documents (to English). Initial result analysis shows that the monolingual strategy is strong, but that for the moment Adhoc achieved the best results, with back-translating documents being better than translating queries.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11171v1"
    ],
    "publication_venue": "Notebook detailing our participation and analysis on the TREC NeuCLIR 2022"
}