
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries
@book{adams1995hitchhiker,
  title={The Hitchhiker's Guide to the Galaxy},
  author={Adams, D.},
  isbn={9781417642595},
  url={http://books.google.com/books?id=W-xMPgAACAAJ},
  year={1995},
  publisher={San Val}
}

@book{ir_manning,
 author = {Manning, Christopher D. and Raghavan, Prabhakar and Sch\"{u}tze, Hinrich},
 title = {Introduction to Information Retrieval},
 year = {2008},
 isbn = {0521865719, 9780521865715},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
} 

@book{ir_amini_gaussier,
  TITLE = {{Recherche d'Information - applications, mod{\`e}les et algorithmes}},
  AUTHOR = {Amini, Massih-Reza and Eric, Gaussier},
  URL = {https://hal.archives-ouvertes.fr/hal-00881257},
  NOTE = {I-XIX, 1-233},
  EDITOR = {Eyrolles},
  PUBLISHER = {{Eyrolles}},
  SERIES = {Algorithmes},
  PAGES = {1-233},
  YEAR = {2013},
  MONTH = Apr,
  KEYWORDS = {Recherche d'Information ; Classification documentaire ; Clustering ; Moteurs de recherche ; Big Data},
  HAL_ID = {hal-00881257},
  HAL_VERSION = {v1},
}

@inproceedings{axiomatic_clinchant,
 author = {Clinchant, St{\'e}phane and Gaussier, Eric},
 title = {Information-based Models for Ad Hoc IR},
 booktitle = {Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '10},
 year = {2010},
 isbn = {978-1-4503-0153-4},
 location = {Geneva, Switzerland},
 pages = {234--241},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1835449.1835490},
 doi = {10.1145/1835449.1835490},
 acmid = {1835490},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {burstiness, information-based models, log-logistic, power laws, pseudo-relevance feedback, retrieval constraints},
} 



@Article{early_years,
author="Onal, Kezban Dilek
and Zhang, Ye
and Altingovde, Ismail Sengor
and Rahman, Md Mustafizur
and Karagoz, Pinar
and Braylan, Alex
and Dang, Brandon
and Chang, Heng-Lu
and Kim, Henna
and McNamara, Quinten
and Angert, Aaron
and Banner, Edward
and Khetan, Vivek
and McDonnell, Tyler
and Nguyen, An Thanh
and Xu, Dan
and Wallace, Byron C.
and de Rijke, Maarten
and Lease, Matthew",
title="Neural information retrieval: at the end of the early years",
journal="Information Retrieval Journal",
year="2018",
month="Jun",
day="01",
volume="21",
number="2",
pages="111--182",
abstract="A recent ``third wave'' of neural network (NN) approaches now delivers state-of-the-art performance in many machine learning tasks, spanning speech recognition, computer vision, and natural language processing. Because these modern NNs often comprise multiple interconnected layers, work in this area is often referred to as deep learning. Recent years have witnessed an explosive growth of research into NN-based approaches to information retrieval (IR). A significant body of work has now been created. In this paper, we survey the current landscape of Neural IR research, paying special attention to the use of learned distributed representations of textual units. We highlight the successes of neural IR thus far, catalog obstacles to its wider adoption, and suggest potentially promising directions for future research.",
issn="1573-7659",
doi="10.1007/s10791-017-9321-y",
url="https://doi.org/10.1007/s10791-017-9321-y"
}

@article{neural_ir_review,
  author    = {Ye Zhang and
               Md. Mustafizur Rahman and
               Alex Braylan and
               Brandon Dang and
               Heng{-}Lu Chang and
               Henna Kim and
               Quinten McNamara and
               Aaron Angert and
               Edward Banner and
               Vivek Khetan and
               Tyler McDonnell and
               An Thanh Nguyen and
               Dan Xu and
               Byron C. Wallace and
               Matthew Lease},
  title     = {Neural Information Retrieval: A Literature Review},
  journal   = {CoRR},
  volume    = {abs/1611.06792},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.06792},
  archivePrefix = {arXiv},
  eprint    = {1611.06792},
  timestamp = {Mon, 13 Aug 2018 16:47:30 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhangRBDCKMABKM16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{intro_neural_ir,
author = {Mitra, Bhaskar and Craswell, Nick},
title = {An Introduction to Neural Information Retrieval},
booktitle = {},
year = {2018},
month = {April},
abstract = {Neural ranking models for information retrieval (IR) use shallow or deep neural networks to rank search results in response to a query. Traditional learning to rank models employ supervised machine learning (ML) techniques---including neural networks---over hand-crafted IR features. By contrast, more recently proposed neural models learn representations of language from raw text that can bridge the gap between query and document vocabulary. Unlike classical learning to rank models and non-neural approaches to IR, these new ML techniques are data-hungry, requiring large scale training data before they can be deployed. This tutorial introduces basic concepts and intuitions behind neural IR models, and places them in the context of classical non-neural approaches to IR. We begin by introducing fundamental concepts of retrieval and different neural and non-neural approaches to unsupervised learning of vector representations of text. We then review IR methods that employ these pre-trained neural vector representations without learning the IR task end-to-end. We introduce deep neural networks (DNNs) next, discussing popular architectures and implementations. Finally, we review supervised neural learning to rank models, including recent DNN architectures trained end-to-end for ranking tasks. We conclude with a discussion on potential future directions for neural IR.},
publisher = {Now Publishers},
url = {https://www.microsoft.com/en-us/research/publication/introduction-neural-information-retrieval/},
address = {},
pages = {1-117},
journal = {Foundations and Trends in Information Retrieval},
volume = {},
chapter = {},
isbn = {},
}

@inproceedings{axiomatic,
 author = {Fang, Hui and Zhai, ChengXiang},
 title = {An Exploration of Axiomatic Approaches to Information Retrieval},
 booktitle = {Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '05},
 year = {2005},
 isbn = {1-59593-034-5},
 location = {Salvador, Brazil},
 pages = {480--487},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1076034.1076116},
 doi = {10.1145/1076034.1076116},
 acmid = {1076116},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {TF-IDF weighting, asxiomatic model, constraints, formal models, retrieval heuristics},
} 

@inproceedings{verbosity_scope,
 author = {Robertson, S. E. and Walker, S.},
 title = {Some Simple Effective Approximations to the 2-Poisson Model for Probabilistic Weighted Retrieval},
 booktitle = {Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '94},
 year = {1994},
 isbn = {0-387-19889-X},
 location = {Dublin, Ireland},
 pages = {232--241},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=188490.188561},
 acmid = {188561},
 publisher = {Springer-Verlag New York, Inc.},
 address = {New York, NY, USA},
} 

@inproceedings{term_dep,
 author = {Metzler, Donald and Croft, W. Bruce},
 title = {A Markov Random Field Model for Term Dependencies},
 booktitle = {Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '05},
 year = {2005},
 isbn = {1-59593-034-5},
 location = {Salvador, Brazil},
 pages = {472--479},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1076034.1076115},
 doi = {10.1145/1076034.1076115},
 acmid = {1076115},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Markov random fields, information retrieval, phrases, term dependence},
} 

@article{local_and_distributed,
  author    = {Bhaskar Mitra and
               Fernando Diaz and
               Nick Craswell},
  title     = {Learning to Match Using Local and Distributed Representations of Text
               for Web Search},
  journal   = {CoRR},
  volume    = {abs/1610.08136},
  year      = {2016},
  url       = {http://arxiv.org/abs/1610.08136},
  archivePrefix = {arXiv},
  eprint    = {1610.08136},
  timestamp = {Mon, 13 Aug 2018 16:48:29 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/Mitra0C16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{pacrr,
  author    = {Kai Hui and
               Andrew Yates and
               Klaus Berberich and
               Gerard de Melo},
  title     = {A Position-Aware Deep Model for Relevance Matching in Information
               Retrieval},
  journal   = {CoRR},
  volume    = {abs/1704.03940},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.03940},
  archivePrefix = {arXiv},
  eprint    = {1704.03940},
  timestamp = {Mon, 13 Aug 2018 16:47:06 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HuiYBM17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{co_pacrr,
  author    = {Kai Hui and
               Andrew Yates and
               Klaus Berberich and
               Gerard de Melo},
  title     = {{RE-PACRR:} {A} Context and Density-Aware Neural Information Retrieval
               Model},
  journal   = {CoRR},
  volume    = {abs/1706.10192},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.10192},
  archivePrefix = {arXiv},
  eprint    = {1706.10192},
  timestamp = {Mon, 13 Aug 2018 16:47:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HuiYBM17a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{anmm,
  author    = {Liu Yang and
               Qingyao Ai and
               Jiafeng Guo and
               W. Bruce Croft},
  title     = {aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching
               Model},
  journal   = {CoRR},
  volume    = {abs/1801.01641},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01641},
  archivePrefix = {arXiv},
  eprint    = {1801.01641},
  timestamp = {Sun, 26 Aug 2018 16:17:45 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-01641},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{conv_knrm,
 author = {Dai, Zhuyun and Xiong, Chenyan and Callan, Jamie and Liu, Zhiyuan},
 title = {Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search},
 booktitle = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
 series = {WSDM '18},
 year = {2018},
 isbn = {978-1-4503-5581-0},
 location = {Marina Del Rey, CA, USA},
 pages = {126--134},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3159652.3159659},
 doi = {10.1145/3159652.3159659},
 acmid = {3159659},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {n-gram soft match, neural ir, relevance ranking},
} 

@inproceedings{glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}

@article{word2vec,
  author    = {Tomas Mikolov and
               Kai Chen and
               Greg Corrado and
               Jeffrey Dean},
  title     = {Efficient Estimation of Word Representations in Vector Space},
  journal   = {CoRR},
  volume    = {abs/1301.3781},
  year      = {2013},
  url       = {http://arxiv.org/abs/1301.3781},
  archivePrefix = {arXiv},
  eprint    = {1301.3781},
  timestamp = {Mon, 13 Aug 2018 16:48:33 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1301-3781},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{two_stage_ltr,
 author = {Dang, Van and Bendersky, Michael and Croft, W. Bruce},
 title = {Two-Stage Learning to Rank for Information Retrieval},
 booktitle = {Proceedings of the 35th European Conference on Advances in Information Retrieval},
 series = {ECIR'13},
 year = {2013},
 isbn = {978-3-642-36972-8},
 location = {Moscow, Russia},
 pages = {423--434},
 numpages = {12},
 url = {http://dx.doi.org/10.1007/978-3-642-36973-5_36},
 doi = {10.1007/978-3-642-36973-5_36},
 acmid = {2458228},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@ARTICLE{beyond_precision,
   author = {{Xiao}, Y. and {Guo}, J. and {Fan}, Y. and {Lan}, Y. and {Xu}, J. and 
	{Cheng}, X.},
    title = "{Beyond Precision: A Study on Recall of Initial Retrieval with Neural Representations}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1806.10869},
 primaryClass = "cs.IR",
 keywords = {Computer Science - Information Retrieval},
     year = 2018,
    month = jun,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180610869X},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@book{ltr,
 author = {Li, Hang},
 title = {Learning to Rank for Information Retrieval and Natural Language Processing},
 year = {2011},
 isbn = {1608457079, 9781608457076},
 publisher = {Morgan \& Claypool Publishers},
}

@techreport{lambda_rank,
author = {Burges, Chris J.C.},
title = {From RankNet to LambdaRank to LambdaMART: An Overview},
booktitle = {},
year = {2010},
month = {June},
abstract = {

LambdaMART is the boosted tree version of LambdaRank, which is based on RankNet. RankNet, LambdaRank, and LambdaMART have proven to be very successful algorithms for solving real world ranking problems: for example an ensemble of LambdaMART rankers won Track 1 of the 2010 Yahoo! Learning To Rank Challenge. The details of these algorithms are spread across several papers and reports, and so here we give a self-contained, detailed and complete description of them.


},
publisher = {},
url = {https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/},
address = {},
pages = {},
journal = {},
volume = {},
chapter = {},
isbn = {},
}

@article{salton,
 author = {Salton, G. and Wong, A. and Yang, C. S.},
 title = {A Vector Space Model for Automatic Indexing},
 journal = {Commun. ACM},
 issue_date = {Nov. 1975},
 volume = {18},
 number = {11},
 month = nov,
 year = {1975},
 issn = {0001-0782},
 pages = {613--620},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/361219.361220},
 doi = {10.1145/361219.361220},
 acmid = {361220},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {automatic indexing, automatic information retrieval, content analysis, document space},
} 

@proceedings{dssm,
author = {Huang, Po-Sen and He, Xiaodong and Gao, Jianfeng and Deng, Li and Acero, Alex and Heck, Larry},
title = {Learning Deep Structured Semantic Models for Web Search using Clickthrough Data},
booktitle = {},
year = {2013},
month = {October},
abstract = {Latent semantic models, such as LSA, intend to map a query to its relevant documents at the semantic level where keyword-based matching often fails. In this study we strive to develop a series of new latent semantic models with a deep structure that project queries and documents into a common low-dimensional space where the relevance of a document given a query is readily computed as the distance between them. The proposed deep structured semantic models are discriminatively trained by maximizing the conditional likelihood of the clicked documents given a query using the clickthrough data. To make our models applicable to large-scale Web search applications, we also use a technique called word hashing, which is shown to effectively scale up our semantic models to handle large vocabularies which are common in such tasks. The new models are evaluated on a Web document ranking task using a real-world data set. Results show that our best model significantly outperforms other latent semantic models, which were considered state-of-the-art in the performance prior to the work presented in this paper.},
publisher = {ACM International Conference on Information and Knowledge Management (CIKM)},
url = {https://www.microsoft.com/en-us/research/publication/learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data/},
address = {},
pages = {},
journal = {},
volume = {},
chapter = {},
isbn = {},
}

@article{rank_svm,
author = {Herbrich, Ralf and Graepel, Thore and Obermayer, Klaus},
year = {2000},
month = {01},
pages = {},
title = {Large margin rank boundaries for ordinal regression},
volume = {88},
booktitle = {Advances in Large Margin Classifiers}
}

@inproceedings{soft_rank,
author = {Taylor, Mike and Guiver, John and Robertson, Stephen and Minka, Tom},
title = {SoftRank: Optimising Non-Smooth Rank Metrics},
booktitle = {},
year = {2008},
month = {February},
abstract = {We address the problem of learning large complex ranking functions. Most IR applications use evaluation metrics that depend only upon the ranks of documents. However, most ranking functions generate document scores, which are sorted to produce a ranking. Hence IR metrics are innately non-smooth with respect to the scores, due to the sort. Unfortunately, many machine learning algorithms require the gradient of a training objective in order to perform the optimization of the model parameters, and because IR metricsare non-smooth, we need to find a smooth proxy objective that can be used for training. We present a new family of training objectives that are derived from the rankdistributions of documents, induced by smoothed scores. We call this approach SoftRank. We focus on a smoothed approximation to Normalized Discounted Cumulative Gain(NDCG), called SoftNDCG and we compare it with three other training objectives in the recent literature. We present two main results.},
publisher = {},
url = {https://www.microsoft.com/en-us/research/publication/softrank-optimising-non-smooth-rank-metrics/},
address = {},
pages = {},
journal = {},
volume = {},
chapter = {},
isbn = {},
}

@inproceedings{list_mle,
 author = {Xia, Fen and Liu, Tie-Yan and Wang, Jue and Zhang, Wensheng and Li, Hang},
 title = {Listwise Approach to Learning to Rank: Theory and Algorithm},
 booktitle = {Proceedings of the 25th International Conference on Machine Learning},
 series = {ICML '08},
 year = {2008},
 isbn = {978-1-60558-205-4},
 location = {Helsinki, Finland},
 pages = {1192--1199},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1390156.1390306},
 doi = {10.1145/1390156.1390306},
 acmid = {1390306},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@inproceedings{ndcg,
 author = {J\"{a}rvelin, Kalervo and Kek\"{a}l\"{a}inen, Jaana},
 title = {IR Evaluation Methods for Retrieving Highly Relevant Documents},
 booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '00},
 year = {2000},
 isbn = {1-58113-226-3},
 location = {Athens, Greece},
 pages = {41--48},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/345508.345545},
 doi = {10.1145/345508.345545},
 acmid = {345545},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@book{map,
 author = {Voorhees, Ellen M. and Harman, Donna K.},
 title = {TREC: Experiment and Evaluation in Information Retrieval (Digital Libraries and Electronic Publishing)},
 year = {2005},
 isbn = {0262220733},
 publisher = {The MIT Press},
} 

@inproceedings{medical_ir,
    title="A Full-Text Learning to Rank Dataset for Medical Information Retrieval",
    author = "Vera Boteva and Demian Gholipour and Artem Sokolov and Stefan Riezler",
    booktitle = "Proceedings of the European Conference on Information Retrieval ({ECIR})",
    location = "Padova, Italy",
    publisher = "Springer",
    year = 2016
}

@inproceedings{drmm_pacrr,
    title="Deep Relevance Ranking Using Enhanced Document-Query Interactions",
    author = "R. McDonald and G. Brokos and I. Androutsopoulos",
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2018)",
    location = "Brussels, Belgium",
    year = 2018
}


@inproceedings{regu_embeddings,
  title={A Comparative Study on Regularization Strategies for Embedding-based Neural Networks},
  author={Hao Peng and Lili Mou and Ge Li and Yunchuan Chen and Yangyang Lu and Zhi Jin},
  booktitle={EMNLP},
  year={2015}
}

@inproceedings{dropout_rnn,
 author = {Gal, Yarin and Ghahramani, Zoubin},
 title = {A Theoretically Grounded Application of Dropout in Recurrent Neural Networks},
 booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
 series = {NIPS'16},
 year = {2016},
 isbn = {978-1-5108-3881-9},
 location = {Barcelona, Spain},
 pages = {1027--1035},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=3157096.3157211},
 acmid = {3157211},
 publisher = {Curran Associates Inc.},
 address = {USA},
} 

@book{deep_learning,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@book{dl_with_python,
 author = {Chollet, Francois},
 title = {Deep Learning with Python},
 year = {2017},
 isbn = {1617294438, 9781617294433},
 edition = {1st},
 publisher = {Manning Publications Co.},
 address = {Greenwich, CT, USA},
} 

@article{macculloch,
  added-at = {2008-02-26T11:58:58.000+0100},
  author = {Mcculloch, Warren and Pitts, Walter},
  biburl = {https://www.bibsonomy.org/bibtex/26fbacb0ae04bc17d296d9265dfc90dff/schaul},
  citeulike-article-id = {2380493},
  description = {idsia},
  interhash = {3e8e0d06f376f3eb95af89d5a2f15957},
  intrahash = {6fbacb0ae04bc17d296d9265dfc90dff},
  journal = {Bulletin of Mathematical Biophysics},
  keywords = {evolutionary},
  pages = {127--147},
  priority = {2},
  timestamp = {2008-02-26T12:00:58.000+0100},
  title = {A Logical Calculus of Ideas Immanent in Nervous Activity},
  volume = 5,
  year = 1943
}

@ARTICLE{rosenblatt,
    author = {F. Rosenblatt},
    title = {The Perceptron: A Probabilistic Model for Information Storage and Organization in The Brain},
    journal = {Psychological Review},
    year = {1958},
    pages = {65--386}
}

@article{backprop,
  added-at = {2018-06-03T13:17:55.000+0200},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  biburl = {https://www.bibsonomy.org/bibtex/25d95851c0f627ab11747a2e481ecbad6/achakraborty},
  description = {Learning representations by back-propagating errors | Nature},
  interhash = {c354bc293fa9aa7caffc66d40a014903},
  intrahash = {5d95851c0f627ab11747a2e481ecbad6},
  journal = {Nature},
  keywords = {deep-learning nature neural-networks paper},
  month = oct,
  pages = {533--},
  publisher = {Nature Publishing Group},
  timestamp = {2018-06-03T13:17:55.000+0200},
  title = {Learning representations by back-propagating errors},
  url = {http://dx.doi.org/10.1038/323533a0},
  volume = 323,
  year = 1986
}

@incollection{Krizhevsky,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {1097--1105},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}

@inproceedings{sogou_qcl,
 author = {Zheng, Yukun and Fan, Zhen and Liu, Yiqun and Luo, Cheng and Zhang, Min and Ma, Shaoping},
 title = {Sogou-QCL: A New Dataset with Click Relevance Label},
 booktitle = {The 41st International ACM SIGIR Conference on Research \&\#38; Development in Information Retrieval},
 series = {SIGIR '18},
 year = {2018},
 isbn = {978-1-4503-5657-2},
 location = {Ann Arbor, MI, USA},
 pages = {1117--1120},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/3209978.3210092},
 doi = {10.1145/3209978.3210092},
 acmid = {3210092},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {document ranking, search evaluation, test collection},
} 

@inproceedings{berger,
 author = {Berger, Adam and Lafferty, John},
 title = {Information Retrieval As Statistical Translation},
 booktitle = {Proceedings of the 22Nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '99},
 year = {1999},
 isbn = {1-58113-096-1},
 location = {Berkeley, California, USA},
 pages = {222--229},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/312624.312681},
 doi = {10.1145/312624.312681},
 acmid = {312681},
 publisher = {ACM},
 address = {New York, NY, USA},
} 



@article{recall_neural_ir,
  author    = {Yan Xiao and
               Jiafeng Guo and
               Yixing Fan and
               Yanyan Lan and
               Jun Xu and
               Xueqi Cheng},
  title     = {Beyond Precision: {A} Study on Recall of Initial Retrieval with Neural
               Representations},
  journal   = {CoRR},
  volume    = {abs/1806.10869},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.10869},
  archivePrefix = {arXiv},
  eprint    = {1806.10869},
  timestamp = {Mon, 13 Aug 2018 16:47:18 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1806-10869},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{weak_supervision,
 author = {Dehghani, Mostafa and Zamani, Hamed and Severyn, Aliaksei and Kamps, Jaap and Croft, W. Bruce},
 title = {Neural Ranking Models with Weak Supervision},
 booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '17},
 year = {2017},
 isbn = {978-1-4503-5022-8},
 location = {Shinjuku, Tokyo, Japan},
 pages = {65--74},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3077136.3080832},
 doi = {10.1145/3077136.3080832},
 acmid = {3080832},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {ad-hoc retrieval, deep learning, deep neural network, ranking model, weak supervision},
} 

@book{
    click_models,
    Author = {Chuklin, Aleksandr and Markov, Ilya and de Rijke, Maarten},
    Publisher = {Morgan \& Claypool},
    Title = {Click Models for Web Search},
    Year = {2015},
    Isbn = {9781627056489},
    Doi = {10.2200/S00654ED1V01Y201507ICR043}
}

@article{pivoted_length_norm,
 author = {Singhal, Amit and Buckley, Chris and Mitra, Manclar},
 title = {Pivoted Document Length Normalization},
 journal = {SIGIR Forum},
 issue_date = {July 2017},
 volume = {51},
 number = {2},
 month = aug,
 year = {2017},
 issn = {0163-5840},
 pages = {176--184},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3130348.3130365},
 doi = {10.1145/3130348.3130365},
 acmid = {3130365},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@article{DFR,
 author = {Amati, Gianni and Van Rijsbergen, Cornelis Joost},
 title = {Probabilistic Models of Information Retrieval Based on Measuring the Divergence from Randomness},
 journal = {ACM Trans. Inf. Syst.},
 issue_date = {October 2002},
 volume = {20},
 number = {4},
 month = oct,
 year = {2002},
 issn = {1046-8188},
 pages = {357--389},
 numpages = {33},
 url = {http://doi.acm.org/10.1145/582415.582416},
 doi = {10.1145/582415.582416},
 acmid = {582416},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Aftereffect model, BM25, Bose--Einstein statistics, Laplace, Poisson, binomial law, document length normalization, eliteness, idf, information retrieval, probabilistic models, randomness, succession law, term frequency normalization, term weighting},
} 

@article{dropout,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  pages   = {1929-1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@article{resnet,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Mon, 13 Aug 2018 16:46:56 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{embeddings_as_facto,
  title={Neural Word Embedding as Implicit Matrix Factorization},
  author={Omer Levy and Yoav Goldberg},
  booktitle={NIPS},
  year={2014}
}

@inproceedings{statistical_significance,
 author = {Smucker, Mark D. and Allan, James and Carterette, Ben},
 title = {A Comparison of Statistical Significance Tests for Information Retrieval Evaluation},
 booktitle = {Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management},
 series = {CIKM '07},
 year = {2007},
 isbn = {978-1-59593-803-9},
 location = {Lisbon, Portugal},
 pages = {623--632},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1321440.1321528},
 doi = {10.1145/1321440.1321528},
 acmid = {1321528},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {bootstrap, hypothesis test, permutation, randomization, sign, statistical significance, student's t-test, wilcoxon},
} 

@article{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  journal   = {CoRR},
  volume    = {abs/1412.6980},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.6980},
  archivePrefix = {arXiv},
  eprint    = {1412.6980},
  timestamp = {Mon, 13 Aug 2018 16:47:35 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KingmaB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{deeprank,
  author    = {Liang Pang and
               Yanyan Lan and
               Jiafeng Guo and
               Jun Xu and
               Jingfang Xu and
               Xueqi Cheng},
  title     = {DeepRank: {A} New Deep Architecture for Relevance Ranking in Information
               Retrieval},
  journal   = {CoRR},
  volume    = {abs/1710.05649},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.05649},
  archivePrefix = {arXiv},
  eprint    = {1710.05649},
  timestamp = {Mon, 13 Aug 2018 16:48:06 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1710-05649},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{deeprank2,
  author    = {Yixing Fan and
               Jiafeng Guo and
               Yanyan Lan and
               Jun Xu and
               Chengxiang Zhai and
               Xueqi Cheng},
  title     = {Modeling Diverse Relevance Patterns in Ad-hoc Retrieval},
  journal   = {CoRR},
  volume    = {abs/1805.05737},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.05737},
  archivePrefix = {arXiv},
  eprint    = {1805.05737},
  timestamp = {Mon, 13 Aug 2018 16:48:49 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1805-05737},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{plsa,
 author = {Hofmann, Thomas},
 title = {Probabilistic Latent Semantic Analysis},
 booktitle = {Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence},
 series = {UAI'99},
 year = {1999},
 isbn = {1-55860-614-9},
 location = {Stockholm, Sweden},
 pages = {289--296},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=2073796.2073829},
 acmid = {2073829},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@article{lda,
 author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
 title = {Latent Dirichlet Allocation},
 journal = {J. Mach. Learn. Res.},
 issue_date = {3/1/2003},
 volume = {3},
 month = mar,
 year = {2003},
 issn = {1532-4435},
 pages = {993--1022},
 numpages = {30},
 url = {http://dl.acm.org/citation.cfm?id=944919.944937},
 acmid = {944937},
 publisher = {JMLR.org},
} 




@inproceedings{colbert,
author = {Khattab, Omar and Zaharia, Matei},
title = {ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401075},
doi = {10.1145/3397271.3401075},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {39–48},
numpages = {10},
keywords = {neural ir, efficiency, bert, deep language models},
location = {Virtual Event, China},
series = {SIGIR '20}
}

@inproceedings{RenningsAxiomaticApproachDiagnosing2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {An {Axiomatic} {Approach} to {Diagnosing} {Neural} {IR} {Models}},
	isbn = {978-3-030-15712-8},
	doi = {10/ggcmnb},
	abstract = {Traditional retrieval models such as BM25 or language models have been engineered based on search heuristics that later have been formalized into axioms. The axiomatic approach to information retrieval (IR) has shown that the effectiveness of a retrieval method is connected to its fulfillment of axioms. This approach enabled researchers to identify shortcomings in existing approaches and “fix” them. With the new wave of neural net based approaches to IR, a theoretical analysis of those retrieval models is no longer feasible, as they potentially contain millions of parameters. In this paper, we propose a pipeline to create diagnostic datasets for IR, each engineered to fulfill one axiom. We execute our pipeline on the recently released large-scale question answering dataset WikiPassageQA (which contains over 4000 topics) and create diagnostic datasets for four axioms. We empirically validate to what extent well-known deep IR models are able to realize the axiomatic pattern underlying the datasets. Our evaluation shows that there is indeed a positive relation between the performance of neural approaches on diagnostic datasets and their retrieval effectiveness. Based on these findings, we argue that diagnostic datasets grounded in axioms are a good approach to diagnosing neural IR models.},
	language = {en},
	booktitle = {Advances in {Information} {Retrieval}},
	publisher = {Springer International Publishing},
	author = {Rennings, Daniël and Moraes, Felipe and Hauff, Claudia},
	editor = {Azzopardi, Leif and Stein, Benno and Fuhr, Norbert and Mayr, Philipp and Hauff, Claudia and Hiemstra, Djoerd},
	year = {2019},
	note = {ZSCC: NoCitationData[s0]},
	keywords = {\#processed, axiomatic, information retrieval, neural information retrieval},
	pages = {489--503},
	file = {Rennings et al_2019_An Axiomatic Approach to Diagnosing Neural IR Models.pdf:/home/bpiwowar/Zotero/storage/XV8UHX5C/Rennings et al_2019_An Axiomatic Approach to Diagnosing Neural IR Models.pdf:application/pdf}
}

@article{lin2020IRBertReview,
	title = {Pretrained {Transformers} for {Text} {Ranking}: {BERT} and {Beyond}},
	shorttitle = {Pretrained {Transformers} for {Text} {Ranking}},
	url = {http://arxiv.org/abs/2010.06467},
	abstract = {The goal of text ranking is to generate an ordered list of texts retrieved from a corpus in response to a query. Although the most common formulation of text ranking is search, instances of the task can also be found in many natural language processing applications. This survey provides an overview of text ranking with neural network architectures known as transformers, of which BERT is the best-known example. The combination of transformers and self-supervised pretraining has, without exaggeration, revolutionized the fields of natural language processing (NLP), information retrieval (IR), and beyond. In this survey, we provide a synthesis of existing work as a single point of entry for practitioners who wish to gain a better understanding of how to apply transformers to text ranking problems and researchers who wish to pursue work in this area. We cover a wide range of modern techniques, grouped into two high-level categories: transformer models that perform reranking in multi-stage ranking architectures and learned dense representations that attempt to perform ranking directly. There are two themes that pervade our survey: techniques for handling long documents, beyond the typical sentence-by-sentence processing approaches used in NLP, and techniques for addressing the tradeoff between effectiveness (result quality) and efficiency (query latency). Although transformer architectures and pretraining techniques are recent innovations, many aspects of how they are applied to text ranking are relatively well understood and represent mature techniques. However, there remain many open research questions, and thus in addition to laying out the foundations of pretrained transformers for text ranking, this survey also attempts to prognosticate where the field is heading.},
	urldate = {2020-10-14},
	journal = {arXiv:2010.06467 [cs]},
	author = {Lin, Jimmy and Nogueira, Rodrigo and Yates, Andrew},
	month = oct,
	year = {2020},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 2010.06467},
	keywords = {\#overview, \#processed, \#important, neural information retrieval, self-attention networks},
	annote = {Extracted Annotations (10/15/2020, 5:46:07 PM)"This survey provides an overview of text ranking with neural network architectures known as transformers, of which BERT is the best-known example" (Lin et al 2020:1)"One obvious approach to bridge the gap between query and document terms is to enrich query representations with query expansion techniques" (Lin et al 2020:12)"Query expansion techniques, however, do not need to involve relevance feedback" (Lin et al 2020:12)"Another obvious approach to bridge the gap between query and document terms is to enrich document representations" (Lin et al 2020:12)},
	file = {arXiv.org Snapshot:/home/bpiwowar/Zotero/storage/E4WJLSHJ/2010.html:text/html;Lin et al_2020_Pretrained Transformers for Text Ranking.pdf:/home/bpiwowar/Zotero/storage/5Q8MH5A7/Lin et al_2020_Pretrained Transformers for Text Ranking.pdf:application/pdf}
}


@article{neural_hype,
   title={Critically Examining the “Neural Hype”},
   ISBN={9781450361729},
   url={http://dx.doi.org/10.1145/3331184.3331340},
   DOI={10.1145/3331184.3331340},
   journal={Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
   publisher={ACM},
   author={Yang, Wei and Lu, Kuang and Yang, Peilin and Lin, Jimmy},
   year={2019},
   month={Jul}
}

@misc{passage_ranking,
    title={Passage Re-ranking with BERT},
    author={Rodrigo Nogueira and Kyunghyun Cho},
    year={2019},
    eprint={1901.04085},
    archivePrefix={arXiv},
    primaryClass={cs.IR}
}

@inproceedings{knrm,
  author          = {{Xiong}, Chenyan and {Dai}, Zhuyun and {Callan}, Jamie and {Liu}, Zhiyuan and {Power}, Russell},
  title           = "{End-to-End Neural Ad-hoc Ranking with Kernel Pooling}",
  booktitle       = {Proceedings of the 40th International ACM SIGIR Conference on Research \& Development in Information Retrieval},
  organization    = {ACM},
  year            = 2017,
}

@InProceedings{cedr,
  author = {MacAvaney, Sean and Yates, Andrew and Cohan, Arman and Goharian, Nazli},
  title = {CEDR: Contextualized Embeddings for Document Ranking},
  booktitle = {SIGIR},
  year = {2019}
}

@article{dai_sigir,
  author    = {Zhuyun Dai and
               Jamie Callan},
  title     = {Deeper Text Understanding for {IR} with Contextual Neural Language
               Modeling},
  journal   = {CoRR},
  volume    = {abs/1905.09217},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.09217},
  archivePrefix = {arXiv},
  eprint    = {1905.09217},
  timestamp = {Wed, 29 May 2019 11:27:50 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-09217.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{t5,
      title={Document Ranking with a Pretrained Sequence-to-Sequence Model}, 
      author={Rodrigo Nogueira and Zhiying Jiang and Jimmy Lin},
      year={2020},
      eprint={2003.06713},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}


@inproceedings{tap,
author = {Yilmaz, Emine and Aslam, Javed A. and Robertson, Stephen},
title = {A New Rank Correlation Coefficient for Information Retrieval},
year = {2008},
isbn = {9781605581644},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1390334.1390435},
doi = {10.1145/1390334.1390435},
abstract = {In the field of information retrieval, one is often faced with the problem of computing the correlation between two ranked lists. The most commonly used statistic that quantifies this correlation is Kendall's Τ. Often times, in the information retrieval community, discrepancies among those items having high rankings are more important than those among items having low rankings. The Kendall's Τ statistic, however, does not make such distinctions and equally penalizes errors both at high and low rankings.In this paper, we propose a new rank correlation coefficient, AP correlation (Τap), that is based on average precision and has a probabilistic interpretation. We show that the proposed statistic gives more weight to the errors at high rankings and has nice mathematical properties which make it easy to interpret. We further validate the applicability of the statistic using experimental data.},
booktitle = {Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {587–594},
numpages = {8},
keywords = {evaluation, rank correlation, Kendall's tau, average precision},
location = {Singapore, Singapore},
series = {SIGIR '08}
}

@misc{zhan2020repbert,
      title={RepBERT: Contextualized Text Embeddings for First-Stage Retrieval}, 
      author={Jingtao Zhan and Jiaxin Mao and Yiqun Liu and Min Zhang and Shaoping Ma},
      year={2020},
      eprint={2006.15498},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@misc{xiong2020approximate,
      title={Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval}, 
      author={Lee Xiong and Chenyan Xiong and Ye Li and Kwok-Fung Tang and Jialin Liu and Paul Bennett and Junaid Ahmed and Arnold Overwijk},
      year={2020},
      eprint={2007.00808},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@article{bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  archivePrefix = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{bert_retrieval_heuristics,
author="C{\^a}mara, Arthur
and Hauff, Claudia",
editor="Jose, Joemon M.
and Yilmaz, Emine
and Magalh{\~a}es, Jo{\~a}o
and Castells, Pablo
and Ferro, Nicola
and Silva, M{\'a}rio J.
and Martins, Fl{\'a}vio",
title="Diagnosing BERT with Retrieval Heuristics",
booktitle="Advances in Information Retrieval",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="605--618",
abstract="Word embeddings, made widely popular in 2013 with the release of word2vec, have become a mainstay of NLP engineering pipelines. Recently, with the release of BERT, word embeddings have moved from the term-based embedding space to the contextual embedding space---each term is no longer represented by a single low-dimensional vector but instead each term and its context determine the vector weights. BERT's setup and architecture have been shown to be general enough to be applicable to many natural language tasks. Importantly for Information Retrieval (IR), in contrast to prior deep learning solutions to IR problems which required significant tuning of neural net architectures and training regimes, ``vanilla BERT'' has been shown to outperform existing retrieval algorithms by a wide margin, including on tasks and corpora that have long resisted retrieval effectiveness gains over traditional IR baselines (such as Robust04). In this paper, we employ the recently proposed axiomatic dataset analysis technique---that is, we create diagnostic datasets that each fulfil a retrieval heuristic (both term matching and semantic-based)---to explore what BERT is able to learn. In contrast to our expectations, we find BERT, when applied to a recently released large-scale web corpus with ad-hoc topics, to not adhere to any of the explored axioms. At the same time, BERT outperforms the traditional query likelihood retrieval model by 40{\%}. This means that the axiomatic approach to IR (and its extension of diagnostic datasets created for retrieval heuristics) may in its current form not be applicable to large-scale corpora. Additional---different---axioms are needed.",
isbn="978-3-030-45439-5"
}

@article{drmm,
  author    = {Jiafeng Guo and
               Yixing Fan and
               Qingyao Ai and
               W. Bruce Croft},
  title     = {A Deep Relevance Matching Model for Ad-hoc Retrieval},
  journal   = {CoRR},
  volume    = {abs/1711.08611},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.08611},
  archivePrefix = {arXiv},
  eprint    = {1711.08611},
  timestamp = {Mon, 13 Aug 2018 16:46:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-08611.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{prettr,
  author = {MacAvaney, Sean and Nardini, Franco Maria and Perego, Raffaele and Tonellotto, Nicola and Goharian, Nazli and Frieder, Ophir},
  title = {Efficient Document Re-Ranking for Transformers by Precomputing Term Representations},
  booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year = {2020},
  url = {https://arxiv.org/abs/2004.14255},
  doi = {10.1145/3397271.3401093},
  pages = {49--58}
}

@misc{mores,
      title={Modularized Transfomer-based Ranking Framework}, 
      author={Luyu Gao and Zhuyun Dai and Jamie Callan},
      year={2020},
      eprint={2004.13313},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@inproceedings{sentence_bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "http://arxiv.org/abs/1908.10084",
}

@misc{hofstatter2020improving,
      title={Improving Efficient Neural Ranking Models with Cross-Architecture Knowledge Distillation}, 
      author={Sebastian Hofstätter and Sophia Althammer and Michael Schröder and Mete Sertkan and Allan Hanbury},
      year={2020},
      eprint={2010.02666},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@inproceedings{identifiability_transformers_iclr20,
author = {Brunner, Gino and Liu, Yang and Pascual, Damian and Richter, Oliver and Ciaramita, Massimiliano and Wattenhofer, Roger},
year = {2020},
month = {02},
pages = {},
title = {On Identifiability in Transformers}
}

@proceedings{trec_2019,
  editor    = {Ellen M. Voorhees and
               Angela Ellis},
  title     = {Proceedings of the Twenty-Eighth Text REtrieval Conference, {TREC}
               2019, Gaithersburg, Maryland, USA, November 13-15, 2019},
  series    = {{NIST} Special Publication},
  volume    = {1250},
  publisher = {National Institute of Standards and Technology {(NIST)}},
  year      = {2019},
  url       = {https://trec.nist.gov/pubs/trec28/trec2019.html},
  timestamp = {Wed, 11 Mar 2020 12:49:27 +0100},
  biburl    = {https://dblp.org/rec/conf/trec/2019.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Camara_Axioms,
  author    = {Arthur C{\^{a}}mara and
               Claudia Hauff},
  editor    = {Joemon M. Jose and
               Emine Yilmaz and
               Jo{\~{a}}o Magalh{\~{a}}es and
               Pablo Castells and
               Nicola Ferro and
               M{\'{a}}rio J. Silva and
               Fl{\'{a}}vio Martins},
  title     = {Diagnosing {BERT} with Retrieval Heuristics},
  booktitle = {Advances in Information Retrieval - 42nd European Conference on {IR}
               Research, {ECIR} 2020, Lisbon, Portugal, April 14-17, 2020, Proceedings,
               Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {12035},
  pages     = {605--618},
  publisher = {Springer},
  year      = {2020},
  url       = {https://doi.org/10.1007/978-3-030-45439-5\_40},
  doi       = {10.1007/978-3-030-45439-5\_40},
  timestamp = {Thu, 14 May 2020 10:17:16 +0200},
  biburl    = {https://dblp.org/rec/conf/ecir/CamaraH20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{2020interpretable,
      title={Interpretable \& Time-Budget-Constrained Contextualization for Re-Ranking}, 
      author={Sebastian Hofstätter and Markus Zlabinger and Allan Hanbury},
      year={2020},
      eprint={2002.01854},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@inproceedings{tau_ap_python,
author = {Urbano, Juli\'{a}n and Marrero, M\'{o}nica},
title = {The Treatment of Ties in AP Correlation},
year = {2017},
isbn = {9781450344906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3121050.3121106},
doi = {10.1145/3121050.3121106},
abstract = {The Kendall tau and AP correlation coefficients are very commonly use to compare two rankings over the same set of items. Even though Kendall tau was originally defined assuming that there are no ties in the rankings, two alternative versions were soon developed to account for ties in two different scenarios: measure the accuracy of an observer with respect to a true and objective ranking, and measure the agreement between two observers in the absence of a true ranking. These two variants prove useful in cases where ties are possible in either ranking, and may indeed result in very different scores. AP correlation was devised to incorporate a top-heaviness component into Kendall tau, penalizing more heavily if differences occur between items at the top of the rankings, making it a very compelling coefficient in Information Retrieval settings. However, the treatment of ties in AP correlation remains an open problem. In this paper we fill this gap, providing closed analytical formulations of AP correlation under the two scenarios of ties contemplated in Kendall tau. In addition, we developed an R package that implements these coefficients.},
booktitle = {Proceedings of the ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {321–324},
numpages = {4},
keywords = {correlation, Kendall, evaluation, ties, average precision},
location = {Amsterdam, The Netherlands},
series = {ICTIR '17}
}


@misc{sparterm2020,
      title={SparTerm: Learning Term-based Sparse Representation for Fast Text Retrieval}, 
      author={Yang Bai and Xiaoguang Li and Gang Wang and Chaoliang Zhang and Lifeng Shang and Jun Xu and Zhaowei Wang and Fangshan Wang and Qun Liu},
      year={2020},
      eprint={2010.00768},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}


@misc{zhao2020sparta,
      title={SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval}, 
      author={Tiancheng Zhao and Xiaopeng Lu and Kyusong Lee},
      year={2020},
      eprint={2009.13013},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{louizos2018learning,
      title={Learning Sparse Neural Networks through $L_0$ Regularization}, 
      author={Christos Louizos and Max Welling and Diederik P. Kingma},
      year={2018},
      eprint={1712.01312},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{liang2020anchor,
      title={Anchor \& Transform: Learning Sparse Embeddings for Large Vocabularies}, 
      author={Paul Pu Liang and Manzil Zaheer and Yuan Wang and Amr Ahmed},
      year={2020},
      eprint={2003.08197},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{guu2020realm,
      title={REALM: Retrieval-Augmented Language Model Pre-Training}, 
      author={Kelvin Guu and Kenton Lee and Zora Tung and Panupong Pasupat and Ming-Wei Chang},
      year={2020},
      eprint={2002.08909},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}



@misc{2020crossdistill,
      title={Improving Efficient Neural Ranking Models with Cross-Architecture Knowledge Distillation}, 
      author={Sebastian Hofstätter and Sophia Althammer and Michael Schröder and Mete Sertkan and Allan Hanbury},
      year={2020},
      eprint={2010.02666},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@inproceedings{qu-etal-2021-rocketqa,
    title = "{R}ocket{QA}: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering",
    author = "Qu, Yingqi  and
      Ding, Yuchen  and
      Liu, Jing  and
      Liu, Kai  and
      Ren, Ruiyang  and
      Zhao, Wayne Xin  and
      Dong, Daxiang  and
      Wu, Hua  and
      Wang, Haifeng",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.466",
    doi = "10.18653/v1/2021.naacl-main.466",
    pages = "5835--5847",
    abstract = "In open-domain question answering, dense passage retrieval has become a new paradigm to retrieve relevant passages for finding answers. Typically, the dual-encoder architecture is adopted to learn dense representations of questions and passages for semantic matching. However, it is difficult to effectively train a dual-encoder due to the challenges including the discrepancy between training and inference, the existence of unlabeled positives and limited training data. To address these challenges, we propose an optimized training approach, called RocketQA, to improving dense passage retrieval. We make three major technical contributions in RocketQA, namely cross-batch negatives, denoised hard negatives and data augmentation. The experiment results show that RocketQA significantly outperforms previous state-of-the-art models on both MSMARCO and Natural Questions. We also conduct extensive experiments to examine the effectiveness of the three strategies in RocketQA. Besides, we demonstrate that the performance of end-to-end QA can be improved based on our RocketQA retriever.",
}


inproceedings{colbert,
author = {Khattab, Omar and Zaharia, Matei},
title = {ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401075},
doi = {10.1145/3397271.3401075},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {39–48},
numpages = {10},
keywords = {neural ir, efficiency, bert, deep language models},
location = {Virtual Event, China},
series = {SIGIR '20}
}

@misc{ma2020pretrainingIR,
      title={PROP: Pre-training with Representative Words Prediction for Ad-hoc Retrieval}, 
      author={Xinyu Ma and Jiafeng Guo and Ruqing Zhang and Yixing Fan and Xiang Ji and Xueqi Cheng},
      year={2020},
      eprint={2010.10137},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@inproceedings{aroca-ouellette-rudzicz-2020-losses,
    title = "{O}n {L}osses for {M}odern {L}anguage {M}odels",
    author = "Aroca-Ouellette, St{\'e}phane  and
      Rudzicz, Frank",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.403",
    pages = "4970--4981",
    abstract = "BERT set many state-of-the-art results over varied NLU benchmarks by pre-training over two tasks: masked language modelling (MLM) and next sentence prediction (NSP), the latter of which has been highly criticized. In this paper, we 1) clarify NSP{'}s effect on BERT pre-training, 2) explore fourteen possible auxiliary pre-training tasks, of which seven are novel to modern language models, and 3) investigate different ways to include multiple tasks into pre-training. We show that NSP is detrimental to training due to its context splitting and shallow semantic signal. We also identify six auxiliary pre-training tasks {--} sentence ordering, adjacent sentence prediction, TF prediction, TF-IDF prediction, a FastSent variant, and a Quick Thoughts variant {--} that outperform a pure MLM baseline. Finally, we demonstrate that using multiple tasks in a multi-task pre-training framework provides better results than using any single auxiliary task. Using these methods, we outperform BERTBase on the GLUE benchmark using fewer than a quarter of the training tokens.",
}

@inproceedings{snrm,
author = {Zamani, Hamed and Dehghani, Mostafa and Croft, W. Bruce and Learned-Miller, Erik and Kamps, Jaap},
title = {From Neural Re-Ranking to Neural Ranking: Learning a Sparse Representation for Inverted Indexing},
year = {2018},
isbn = {9781450360142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3269206.3271800},
doi = {10.1145/3269206.3271800},
abstract = {The availability of massive data and computing power allowing for effective data driven neural approaches is having a major impact on machine learning and information retrieval research, but these models have a basic problem with efficiency. Current neural ranking models are implemented as multistage rankers: for efficiency reasons, the neural model only re-ranks the top ranked documents retrieved by a first-stage efficient ranker in response to a given query. Neural ranking models learn dense representations causing essentially every query term to match every document term, making it highly inefficient or intractable to rank the whole collection. The reliance on a first stage ranker creates a dual problem: First, the interaction and combination effects are not well understood. Second, the first stage ranker serves as a "gate-keeper" or filter, effectively blocking the potential of neural models to uncover new relevant documents. In this work, we propose a standalone neural ranking model (SNRM) by introducing a sparsity property to learn a latent sparse representation for each query and document. This representation captures the semantic relationship between the query and documents, but is also sparse enough to enable constructing an inverted index for the whole collection. We parameterize the sparsity of the model to yield a retrieval model as efficient as conventional term based models. Our model gains in efficiency without loss of effectiveness: it not only outperforms the existing term matching baselines, but also performs similarly to the recent re-ranking based neural models with dense representations. Our model can also take advantage of pseudo-relevance feedback for further improvements. More generally, our results demonstrate the importance of sparsity in neural IR models and show that dense representations can be pruned effectively, giving new insights about essential semantic features and their distributions.},
booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
pages = {497–506},
numpages = {10},
keywords = {neural ranking models, semantic matching, document representation, sparse representation, weak supervision, ad-hoc retrieval, efficiency, inverted index},
location = {Torino, Italy},
series = {CIKM '18}
}

@article{faiss,
  author    = {Jeff Johnson and
               Matthijs Douze and
               Herv{\'{e}} J{\'{e}}gou},
  title     = {Billion-scale similarity search with GPUs},
  journal   = {CoRR},
  volume    = {abs/1702.08734},
  year      = {2017},
  url       = {http://arxiv.org/abs/1702.08734},
  archivePrefix = {arXiv},
  eprint    = {1702.08734},
  timestamp = {Mon, 13 Aug 2018 16:47:46 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/JohnsonDJ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{
Fan2020Reducing,
title={Reducing Transformer Depth on Demand with Structured Dropout},
author={Angela Fan and Edouard Grave and Armand Joulin},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SylO2yStDr}
}


@article{wang2020understanding,
  title={Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere},
  author={Wang, Tongzhou and Isola, Phillip},
  journal={arXiv preprint arXiv:2005.10242},
  year={2020}
}


@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9729--9738},
  year={2020}
}


@inproceedings{wang2020cross,
  title={Cross-Batch Memory for Embedding Learning},
  author={Wang, Xun and Zhang, Haozhi and Huang, Weilin and Scott, Matthew R},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6388--6397},
  year={2020}
}

@misc{verma2019mixup,
      title={Manifold Mixup: Better Representations by Interpolating Hidden States}, 
      author={Vikas Verma and Alex Lamb and Christopher Beckham and Amir Najafi and Ioannis Mitliagkas and Aaron Courville and David Lopez-Paz and Yoshua Bengio},
      year={2019},
      eprint={1806.05236},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{2020-bpedropout,
    title = "{BPE}-Dropout: Simple and Effective Subword Regularization",
    author = "Provilkov, Ivan  and
      Emelianenko, Dmitrii  and
      Voita, Elena",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.170",
    doi = "10.18653/v1/2020.acl-main.170",
    pages = "1882--1892",
    abstract = "Subword segmentation is widely used to address the open vocabulary problem in machine translation. The dominant approach to subword segmentation is Byte Pair Encoding (BPE), which keeps the most frequent words intact while splitting the rare ones into multiple tokens. While multiple segmentations are possible even with the same vocabulary, BPE splits words into unique sequences; this may prevent a model from better learning the compositionality of words and being robust to segmentation errors. So far, the only way to overcome this BPE imperfection, its deterministic nature, was to create another subword segmentation algorithm (Kudo, 2018). In contrast, we show that BPE itself incorporates the ability to produce multiple segmentations of the same word. We introduce BPE-dropout - simple and effective subword regularization method based on and compatible with conventional BPE. It stochastically corrupts the segmentation procedure of BPE, which leads to producing multiple segmentations within the same fixed BPE framework. Using BPE-dropout during training and the standard BPE during inference improves translation quality up to 2.3 BLEU compared to BPE and up to 0.9 BLEU compared to the previous subword regularization.",
}

@misc{karpukhin2020dense,
    title={Dense Passage Retrieval for Open-Domain Question Answering},
    author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
    year={2020},
    eprint={2004.04906},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{hofstatter2019let,
  title={Let's measure run time! Extending the IR replicability infrastructure to include performance aspects},
  author={Hofst{\"a}tter, Sebastian and Hanbury, Allan},
  journal={SIGIR Open-Source IR Replicability Challenge (OSIRRC)},
  year={2019}
}

@article{sobroza2019sparse,
  title={Sparse associative memory based on contextual code learning for disambiguating word senses},
  author={Sobroza, Max Raphael and Marra, Tales and Kim-Dufor, Deok-Hee and Berrou, Claude},
  journal={arXiv preprint arXiv:1911.06415},
  year={2019}
}

@inproceedings{
shu2018compressing,
title={Compressing Word Embeddings via Deep Compositional Code Learning},
author={Raphael Shu and Hideki Nakayama},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=BJRZzFlRb},
}

@inproceedings{chen2020differentiable,
  title={Differentiable product quantization for end-to-end embedding compression},
  author={Chen, Ting and Li, Lala and Sun, Yizhou},
  booktitle={International Conference on Machine Learning},
  pages={1617--1626},
  year={2020},
  organization={PMLR}
}

@misc{bengio2013estimating,
      title={Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation}, 
      author={Yoshua Bengio and Nicholas Léonard and Aaron Courville},
      year={2013},
      eprint={1308.3432},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{robertson2009probabilistic,
  added-at = {2010-06-21T16:51:15.000+0200},
  author = {Robertson, S.},
  biburl = {https://www.bibsonomy.org/bibtex/290c019a14b13159b029f7ac8dfc890c2/folke},
  interhash = {9e647a48e30bdde9976744b39db0fdc9},
  intrahash = {90c019a14b13159b029f7ac8dfc890c2},
  journal = {Foundations and Trends{\textregistered} in Information Retrieval},
  keywords = {bm25 information ir retrieval tutorial},
  number = 4,
  pages = {333--389},
  publisher = {Mike Casey},
  timestamp = {2010-06-21T16:51:15.000+0200},
  title = {{The Probabilistic Relevance Framework: BM25 and Beyond}},
  url = {http://scholar.google.de/scholar.bib?q=info:U4l9kCVIssAJ:scholar.google.com/&output=citation&hl=de&as_sdt=2000&as_vis=1&ct=citation&cd=1},
  volume = 3,
  year = 2009
}



@inproceedings{
medini2021solar,
title={{\{}SOLAR{\}}: Sparse Orthogonal Learned and Random Embeddings},
author={Tharun Medini and Beidi Chen and Anshumali Shrivastava},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=fw-BHZ1KjxJ}
}

@article{jegou2010product,
  title={Product quantization for nearest neighbor search},
  author={Jegou, Herve and Douze, Matthijs and Schmid, Cordelia},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={33},
  number={1},
  pages={117--128},
  year={2010},
  publisher={IEEE}
}

@inproceedings{
xiong2021approximate,
title={Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval},
author={Lee Xiong and Chenyan Xiong and Ye Li and Kwok-Fung Tang and Jialin Liu and Paul N. Bennett and Junaid Ahmed and Arnold Overwikj},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=zeFrfgyZln}
}




@inbook{sigir20_efficient_docreranking,
author = {MacAvaney, Sean and Nardini, Franco Maria and Perego, Raffaele and Tonellotto, Nicola and Goharian, Nazli and Frieder, Ophir},
title = {Efficient Document Re-Ranking for Transformers by Precomputing Term Representations},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401093},
abstract = {Deep pretrained transformer networks are effective at various ranking tasks, such as question answering and ad-hoc document ranking. However, their computational expenses deem them cost-prohibitive in practice. Our proposed approach, called PreTTR (Precomputing Transformer Term Representations), considerably reduces the query-time latency of deep transformer networks (up to a 42x speedup on web document ranking) making these networks more practical to use in a real-time ranking scenario. Specifically, we precompute part of the document term representations at indexing time (without a query), and merge them with the query representation at query time to compute the final ranking score. Due to the large size of the token representations, we also propose an effective approach to reduce the storage requirement by training a compression layer to match attention scores. Our compression technique reduces the storage required up to 95 and it can be applied without a substantial degradation in ranking performance.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {49–58},
numpages = {10}
}

  

@misc{curse20_denseindex,
      title={The Curse of Dense Low-Dimensional Information Retrieval for Large Index Sizes}, 
      author={Nils Reimers and Iryna Gurevych},
      year={2020},
      eprint={2012.14210},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@misc{dai2019contextaware,
      title={Context-Aware Sentence/Passage Term Importance Estimation For First Stage Retrieval}, 
      author={Zhuyun Dai and Jamie Callan},
      year={2019},
      eprint={1910.10687},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@misc{nogueira2019document,
      title={Document Expansion by Query Prediction}, 
      author={Rodrigo Nogueira and Wei Yang and Jimmy Lin and Kyunghyun Cho},
      year={2019},
      eprint={1904.08375},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@misc{docT5,
      title={From doc2query to docTTTTTquery}, 
      author={Rodrigo Nogueira and Jimmy Lin},
      year={2019},
      eurl={https://cs.uwaterloo.ca/~jimmylin/publications/Nogueira_Lin_2019_docTTTTTquery-v2.pdf}
}

@article{MacAvaney_2020,
   title={Expansion via Prediction of Importance with Contextualization},
   ISBN={9781450380164},
   url={http://dx.doi.org/10.1145/3397271.3401262},
   DOI={10.1145/3397271.3401262},
   journal={Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
   publisher={ACM},
   author={MacAvaney, Sean and Nardini, Franco Maria and Perego, Raffaele and Tonellotto, Nicola and Goharian, Nazli and Frieder, Ophir},
   year={2020},
   month={Jul}
}

@misc{paria2020minimizing,
      title={Minimizing FLOPs to Learn Efficient Sparse Representations}, 
      author={Biswajit Paria and Chih-Kuan Yeh and Ian E. H. Yen and Ning Xu and Pradeep Ravikumar and Barnabás Póczos},
      year={2020},
      eprint={2004.05665},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inbook{10.1145/3366423.3380258,
author = {Dai, Zhuyun and Callan, Jamie},
title = {Context-Aware Document Term Weighting for Ad-Hoc Search},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380258},
abstract = {Bag-of-words document representations play a fundamental role in modern search engines, but their power is limited by the shallow frequency-based term weighting scheme. This paper proposes HDCT, a context-aware document term weighting framework for document indexing and retrieval. It first estimates the semantic importance of a term in the context of each passage. These fine-grained term weights are then aggregated into a document-level bag-of-words representation, which can be stored into a standard inverted index for efficient retrieval. This paper also proposes two approaches that enable training HDCT without relevance labels. Experiments show that an index using HDCT weights significantly improved the retrieval accuracy compared to typical term-frequency and state-of-the-art embedding-based indexes. },
booktitle = {Proceedings of The Web Conference 2020},
pages = {1897–1907},
numpages = {11}
}

@inbook{10.1145/3397271.3401204,
author = {Dai, Zhuyun and Callan, Jamie},
title = {Context-Aware Term Weighting For First Stage Passage Retrieval},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401204},
abstract = {Term frequency is a common method for identifying the importance of a term in a document. But term frequency ignores how a term interacts with its text context, which is key to estimating document-specific term weights. This paper proposes a Deep Contextualized Term Weighting framework (DeepCT) that maps the contextualized term representations from BERT to into context-aware term weights for passage retrieval. The new, deep term weights can be stored in an ordinary inverted index for efficient retrieval. Experiments on two datasets demonstrate that DeepCT greatly improves the accuracy of first-stage passage retrieval algorithms.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1533–1536},
numpages = {4}
}

@misc{gao2020complementing,
      title={Complementing Lexical Retrieval with Semantic Residual Embedding}, 
      author={Luyu Gao and Zhuyun Dai and Tongfei Chen and Zhen Fan and Benjamin Van Durme and Jamie Callan},
      year={2020},
      eprint={2004.13969},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@article{craswell2020overview,
  title={Overview of the trec 2019 deep learning track},
  author={Craswell, Nick and Mitra, Bhaskar and Yilmaz, Emine and Campos, Daniel and Voorhees, Ellen M},
  journal={arXiv preprint arXiv:2003.07820},
  year={2020}
}

@inproceedings{lam2015numba,
  title={Numba: A llvm-based python jit compiler},
  author={Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
  booktitle={Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC},
  pages={1--6},
  year={2015}
}

@inproceedings{paszke2019pytorch,
  title={PyTorch: An Imperative Style, High-Performance Deep Learning Library.},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  booktitle={NeurIPS},
  year={2019}
}

@misc{wolf2020huggingfaces,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      eprint={1910.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@phdthesis{boytsov2018efficient,
  title={Efficient and Accurate Non-Metric k-NN Search with Applications to Text Matching},
  author={Boytsov, Leonid},
  year={2018},
  school={Carnegie Mellon University}
}

@inproceedings{tu2020approximate,
  title={Approximate Nearest Neighbor Search and Lightweight Dense Vector Reranking in Multi-Stage Retrieval Architectures},
  author={Tu, Zhengkai and Yang, Wei and Fu, Zihang and Xie, Yuqing and Tan, Luchen and Xiong, Kun and Li, Ming and Lin, Jimmy},
  booktitle={Proceedings of the 2020 ACM SIGIR on International Conference on Theory of Information Retrieval},
  pages={97--100},
  year={2020}
}

@inproceedings{10.1145/1008992.1009004,
author = {Fang, Hui and Tao, Tao and Zhai, ChengXiang},
title = {A Formal Study of Information Retrieval Heuristics},
year = {2004},
isbn = {1581138814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1008992.1009004},
doi = {10.1145/1008992.1009004},
abstract = {Empirical studies of information retrieval methods show that good retrieval performance is closely related to the use of various retrieval heuristics, such as TF-IDF weighting. One basic research question is thus what exactly are these "necessary" heuristics that seem to cause good retrieval performance. In this paper, we present a formal study of retrieval heuristics. We formally define a set of basic desirable constraints that any reasonable retrieval function should satisfy, and check these constraints on a variety of representative retrieval functions. We find that none of these retrieval functions satisfies all the constraints unconditionally. Empirical results show that when a constraint is not satisfied, it often indicates non-optimality of the method, and when a constraint is satisfied only for a certain range of parameter values, its performance tends to be poor when the parameter is out of the range. In general, we find that the empirical performance of a retrieval formula is tightly related to how well it satisfies these constraints. Thus the proposed constraints provide a good explanation of many empirical observations and make it possible to evaluate any existing or new retrieval formula analytically.},
booktitle = {Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {49–56},
numpages = {8},
keywords = {formal models, TF-IDF weighting, retrieval heuristics, constraints},
location = {Sheffield, United Kingdom},
series = {SIGIR '04}
}

@inproceedings{lin-etal-2021-batch,
    title = "In-Batch Negatives for Knowledge Distillation with Tightly-Coupled Teachers for Dense Retrieval",
    author = "Lin, Sheng-Chieh  and
      Yang, Jheng-Hong  and
      Lin, Jimmy",
    booktitle = "Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.repl4nlp-1.17",
    doi = "10.18653/v1/2021.repl4nlp-1.17",
    pages = "163--173",
    abstract = "We present an efficient training approach to text retrieval with dense representations that applies knowledge distillation using the ColBERT late-interaction ranking model. Specifically, we propose to transfer the knowledge from a bi-encoder teacher to a student by distilling knowledge from ColBERT{'}s expressive MaxSim operator into a simple dot product. The advantage of the bi-encoder teacher{--}student setup is that we can efficiently add in-batch negatives during knowledge distillation, enabling richer interactions between teacher and student models. In addition, using ColBERT as the teacher reduces training cost compared to a full cross-encoder. Experiments on the MS MARCO passage and document ranking tasks and data from the TREC 2019 Deep Learning Track demonstrate that our approach helps models learn robust representations for dense retrieval effectively and efficiently.",
}

@inproceedings{Hofstaetter2021_tasb_dense_retrieval,
 author = {Sebastian Hofst{\"a}tter and Sheng-Chieh Lin and Jheng-Hong Yang and Jimmy Lin and Allan Hanbury},
 title = {{Efficiently Teaching an Effective Dense Retriever with Balanced Topic Aware Sampling}},
 booktitle = {Proc. of SIGIR},
 year = {2021},
}

@inproceedings{gao-etal-2021-coil,
    title = "{COIL}: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List",
    author = "Gao, Luyu  and
      Dai, Zhuyun  and
      Callan, Jamie",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.241",
    doi = "10.18653/v1/2021.naacl-main.241",
    pages = "3030--3042",
}

@inproceedings{10.1145/3404835.3463030,
author = {Mallia, Antonio and Khattab, Omar and Suel, Torsten and Tonellotto, Nicola},
title = {Learning Passage Impacts for Inverted Indexes},
year = {2021},
isbn = {9781450380379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404835.3463030},
doi = {10.1145/3404835.3463030},
abstract = {Neural information retrieval systems typically use a cascading pipeline, in which
a first-stage model retrieves a candidate set of documents and one or more subsequent
stages re-rank this set using contextualized language models such as BERT. In this
paper, we propose DeepImpact, a new document term-weighting scheme suitable for efficient
retrieval using a standard inverted index. Compared to existing methods, DeepImpact
improves impact-score modeling and tackles the vocabulary-mismatch problem. In particular,
DeepImpact leverages DocT5Query to enrich the document collection and, using a contextualized
language model, directly estimates the semantic importance of tokens in a document,
producing a single-value representation for each token in each document. Our experiments
show that DeepImpact significantly outperforms prior first-stage retrieval approaches
by up to 17% on effectiveness metrics w.r.t. DocT5Query, and, when deployed in a re-ranking
scenario, can reach the same effectiveness of state-of-the-art approaches with up
to 5.1x speedup in efficiency.},
booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1723–1727},
numpages = {5},
keywords = {inverted index, term weighting, neural IR, query processing},
location = {Virtual Event, Canada},
series = {SIGIR '21}
}

@inproceedings{10.1145/3404835.3463098,
author = {Formal, Thibault and Piwowarski, Benjamin and Clinchant, St\'{e}phane},
title = {SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking},
year = {2021},
isbn = {9781450380379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404835.3463098},
doi = {10.1145/3404835.3463098},
abstract = {In neural Information Retrieval, ongoing research is directed towards improving the
first retriever in ranking pipelines. Learning dense embeddings to conduct retrieval
using efficient approximate nearest neighbors methods has proven to work well. Meanwhile,
there has been a growing interest in learning sparse representations for documents
and queries, that could inherit from the desirable properties of bag-of-words models
such as the exact matching of terms and the efficiency of inverted indexes. In this
work, we present a new first-stage ranker based on explicit sparsity regularization
and a log-saturation effect on term weights, leading to highly sparse representations
and competitive results with respect to state-of-the-art dense and sparse methods.
Our approach is simple, trained end-to-end in a single stage. We also explore the
trade-off between effectiveness and efficiency, by controlling the contribution of
the sparsity regularization.},
booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2288–2292},
numpages = {5},
keywords = {sparse representations, regularization, neural networks, indexing},
location = {Virtual Event, Canada},
series = {SIGIR '21}
}

@article{beir_2021,
  author    = {Nandan Thakur and
               Nils Reimers and
               Andreas R{\"{u}}ckl{\'{e}} and
               Abhishek Srivastava and
               Iryna Gurevych},
  title     = {{BEIR:} {A} Heterogenous Benchmark for Zero-shot Evaluation of Information
               Retrieval Models},
  journal   = {CoRR},
  volume    = {abs/2104.08663},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.08663},
  archivePrefix = {arXiv},
  eprint    = {2104.08663},
  timestamp = {Mon, 26 Apr 2021 17:25:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-08663.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{formal2021splade,
      title={SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval}, 
      author={Thibault Formal and Carlos Lassance and Benjamin Piwowarski and Stéphane Clinchant},
      year={2021},
      eprint={2109.10086},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@misc{gao2021rethink,
      title={Rethink Training of BERT Rerankers in Multi-Stage Retrieval Pipeline}, 
      author={Luyu Gao and Zhuyun Dai and Jamie Callan},
      year={2021},
      eprint={2101.08751},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@misc{craswell2021overview,
      title={Overview of the TREC 2020 deep learning track}, 
      author={Nick Craswell and Bhaskar Mitra and Emine Yilmaz and Daniel Campos},
      year={2021},
      eprint={2102.07662},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{wang2020minilm,
  title={Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers},
  author={Wang, Wenhui and Wei, Furu and Dong, Li and Bao, Hangbo and Yang, Nan and Zhou, Ming},
  journal={arXiv preprint arXiv:2002.10957},
  year={2020}
}

@article{clark2020electra,
  title={Electra: Pre-training text encoders as discriminators rather than generators},
  author={Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D},
  journal={arXiv preprint arXiv:2003.10555},
  year={2020}
}

@inproceedings{lin2021batch,
  title={In-batch negatives for knowledge distillation with tightly-coupled teachers for dense retrieval},
  author={Lin, Sheng-Chieh and Yang, Jheng-Hong and Lin, Jimmy},
  booktitle={Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)},
  pages={163--173},
  year={2021}
}

@misc{ren2021rocketqav2,
      title={RocketQAv2: A Joint Training Method for Dense Passage Retrieval and Passage Re-ranking}, 
      author={Ruiyang Ren and Yingqi Qu and Jing Liu and Wayne Xin Zhao and Qiaoqiao She and Hua Wu and Haifeng Wang and Ji-Rong Wen},
      year={2021},
      eprint={2110.07367},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zhang2021adversarial,
      title={Adversarial Retriever-Ranker for dense text retrieval}, 
      author={Hang Zhang and Yeyun Gong and Yelong Shen and Jiancheng Lv and Nan Duan and Weizhu Chen},
      year={2021},
      eprint={2110.03611},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{gao2021unsupervised,
  title={Unsupervised corpus aware language model pre-training for dense passage retrieval},
  author={Gao, Luyu and Callan, Jamie},
  journal={arXiv preprint arXiv:2108.05540},
  year={2021}
}

@misc{sciavolino2021simple,
      title={Simple Entity-Centric Questions Challenge Dense Retrievers}, 
      author={Christopher Sciavolino and Zexuan Zhong and Jinhyuk Lee and Danqi Chen},
      year={2021},
      eprint={2109.08535},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{arabzadeh2021shallow,
      title={Shallow pooling for sparse labels}, 
      author={Negar Arabzadeh and Alexandra Vtyurina and Xinyi Yan and Charles L. A. Clarke},
      year={2021},
      eprint={2109.00062},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@article{pp,
  title={From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective},
  author={Formal, Thibault and Lassance, Carlos and Piwowarski, Benjamin and Clinchant, St{\'e}phane},
  journal={arXiv preprint arXiv:2205.04733},
  year={2022}
}

@inproceedings{efficiency,
  title={An Efficiency Study for SPLADE Models},
  author={Lassance, Carlos and Clinchant, St{\'e}phane},
  booktitle={Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2220--2226},
  year={2022}
}

@techreport{rocchio,
  title={A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text Categorization.},
  author={Joachims, Thorsten},
  year={1996},
  institution={Carnegie-mellon univ pittsburgh pa dept of computer science}
}

@article{colbertv2,
  title={Colbertv2: Effective and efficient retrieval via lightweight late interaction},
  author={Santhanam, Keshav and Khattab, Omar and Saad-Falcon, Jon and Potts, Christopher and Zaharia, Matei},
  journal={arXiv preprint arXiv:2112.01488},
  year={2021}
}

@article{nogueira2020document,
  title={Document ranking with a pretrained sequence-to-sequence model},
  author={Nogueira, Rodrigo and Jiang, Zhiying and Lin, Jimmy},
  journal={arXiv preprint arXiv:2003.06713},
  year={2020}
}

@misc{https://doi.org/10.48550/arxiv.2210.10634,
  doi = {10.48550/ARXIV.2210.10634},
  
  url = {https://arxiv.org/abs/2210.10634},
  
  author = {Zhuang, Honglei and Qin, Zhen and Jagerman, Rolf and Hui, Kai and Ma, Ji and Lu, Jing and Ni, Jianmo and Wang, Xuanhui and Bendersky, Michael},
  
  keywords = {Information Retrieval (cs.IR), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {RankT5: Fine-Tuning T5 for Text Ranking with Ranking Losses},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@inproceedings{bassani2022ranx,
  title={ranx. fuse: A Python Library for Metasearch},
  author={Bassani, Elias and Romelli, Luca},
  booktitle={Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
  pages={4808--4812},
  year={2022}
}

@article{nair2022learning,
  title={Learning a Sparse Representation Model for Neural CLIR},
  author={Nair, Suraj and Yang, Eugene and Lawrie, Dawn and Mayfield, James and Oard, Douglas W},
  year={2022}
}

@article{bonifacio2021mmarco,
  title={mmarco: A multilingual version of the ms marco passage ranking dataset},
  author={Bonifacio, Luiz Henrique and Campiotti, Israel and Jeronymo, Vitor and Lotufo, Roberto and Nogueira, Rodrigo},
  journal={arXiv preprint arXiv:2108.13897},
  year={2021}
}

@article{zhang2021mr,
  title={Mr. TyDi: A multi-lingual benchmark for dense retrieval},
  author={Zhang, Xinyu and Ma, Xueguang and Shi, Peng and Lin, Jimmy},
  journal={arXiv preprint arXiv:2108.08787},
  year={2021}
}

@article{lassance2021colbert,
  title={A Study on Token Pruning for ColBERT},
  author={Lassance, Carlos and Maachou, Maroua and Park, Joohee and Clinchant, St{\'e}phane},
  journal={arXiv preprint arXiv:2112.06540},
  year={2021}
}

@article{Lawrie2022HC4,
  author = {Dawn Lawrie and James Mayfield and Douglas W. Oard and Eugene Yang},
  title = {HC4: A New Suite of Test Collections for Ad Hoc CLIR},
  booktitle = {{Advances in Information Retrieval. 44th European Conference on IR Research (ECIR 2022)}},
  year = {2022},
  month = apr,
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  site = {Stavanger, Norway},
  url = {https://arxiv.org/abs/2201.09992}
}

@misc{pretraining,
  doi = {10.48550/ARXIV.2301.10444},
  
  url = {https://arxiv.org/abs/2301.10444},
  
  author = {Lassance, Carlos and Déjean, Hervé and Clinchant, Stéphane},
  
  keywords = {Information Retrieval (cs.IR), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {An Experimental Study on Pretraining Transformers from Scratch for IR},
  
  publisher = {arXiv},
  
  year = {2023},
  
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}
