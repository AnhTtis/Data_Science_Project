In this paper, we detail our TREC 2022 NeuCLIR track submission, based on the latest improvements of the SPLADE model~\cite{efficiency,pp}, with the main factor being the MLM+FLOPS pretraining (for monolingual runs) and distillation (for the Adhoc runs). In total, we submitted 7 runs per language, being 3 baselines based solely on SPLADE (monolingual, Adhoc via query translation and Adhoc via document back-translation\footnote{Throughout this notebook we use back-translation as the translation from the target language to English}) and 4 main runs (divided into monolingual/Adhoc and reranked/ensemble of the first stage rankers). 

Compared to our TREC DL 2021 notebook, we decided to make this notebook more streamlined compared to last year (and more drafty). For a more thorough introduction of the models used here, we invite the reader to check the following articles: SPLADE training~\cite{pp}, MLM+FLOPS pretraining~\cite{efficiency}, ColBERT\cite{colbert}, Rocchio~\cite{rocchio}, Training style we used for our rerankers~\cite{gao2021rethink} and T5 based reranking~\cite{nogueira2020document}.