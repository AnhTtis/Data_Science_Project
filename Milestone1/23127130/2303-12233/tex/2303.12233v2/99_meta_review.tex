\iffalse

\setcounter{subsection}{0}
\subsection{Summary}
This work introduces a new attack method for data leakage in federated learning settings. The attack, called LOKI, reconstructs the training data by sending customized convolutional parameters to the clients.

\subsection{Scientific Contributions}
\begin{itemize}
\item Provides a Valuable Step Forward in an Established Field
\item Identifies an Impactful Vulnerability
\item Establishes a New Research Direction
\end{itemize}

\subsection{Reasons for Acceptance}
\begin{enumerate}
\item This paper provides a valuable step forward in an established field. Data reconstruction attacks are a real threat and understanding the potential avenues for exploitation in these attacks is an important research direction. The attack proposed here is scalable, effective, and allows for evaluation of data leakage in more realistic federated leaning settings.
\item This work identifies an impactful vulnerability. The techniques proposed here yield non-trivial improvements over prior methods and is capable of leaking up to $86\%$ of all data samples.
\item This work establishes a new research direction. While data reconstruction attacks have been previously researched, the methods proposed here highlight previously unconsidered avenues for exploitation. Specifically, the authors propose a unique and novel convolutional scaling factor approach.
\end{enumerate}

\subsection{Noteworthy Concerns}
All noteworthy concerns were addressed in the rebuttal phase.\\


\noindent {\bf Response from the authors:} We made the following changes for the camera-ready version of the paper, reflecting the changes we committed to in the rebuttal phase. 

\begin{enumerate}

    \item Added an experiment line to Figure~\ref{fig:scalability_rtf} for \name without model inconsistency along with discussion on the tradeoffs (no impact on reconstruction quality or scalability, a slight drop in leakage rate for more stealth).
    
    \item Switched the order of Section 3.1 (scalability problems) and Section 3.2 (model assumptions and attack scope) so that the threat model comes at the beginning of the methodology section.
    
    \item Clarified the range in the model caption of Figure~\ref{fig:model-inconsistency-size} (comparison in size overhead to RtF).
    
    \item Fixed additional typos and added clarifications as brought out in discussion with reviewers during rebuttal. 

\end{enumerate}

\iffalse
\subsection{Noteworthy Concerns} % Exclude if your meta-review does not have noteworthy concerns
\begin{enumerate} % Enumerate environment is not necessary if there is only one
\item [text]
\item [text]
\end{enumerate}
\fi

\section{Response to the Meta-Review} % Optional

\fi





\newpage % The Meta-Review should at least start on a new column

% Use \appendices and not \appendix due to IEEEtran.cls quirks
% \appendices % if not used earlier

\section{Meta-Review}

\subsection{Summary}
This work introduces a new attack method for data leakage in federated learning settings. The attack, called LOKI, reconstructs the training data by sending customized convolutional parameters to the clients.

\subsection{Scientific Contributions}
\begin{itemize}
    \item Provides a Valuable Step Forward in an Established Field
    \item Identifies an Impactful Vulnerability
    \item Establishes a New Research Direction
\end{itemize}

\subsection{Reasons for Acceptance}
\begin{enumerate}
    \item This paper provides a valuable step forward in an established field. Data reconstruction attacks are a real threat and understanding the potential avenues for exploitation in these attacks is an important research direction. The attack proposed here is scalable, effective, and allows for evaluation of data leakage in more realistic federated learning settings.
    \item This work identifies an impactful vulnerability. The techniques proposed here yield non-trivial improvements over prior methods and is capable of leaking up to $86\%$ of all data samples.
    \item This work establishes a new research direction. While data reconstruction attacks have been previously researched, the methods proposed here highlight previously unconsidered avenues for exploitation. Specifically, the authors propose a unique and novel convolutional scaling factor approach.
\end{enumerate}

\iffalse

\subsection{Noteworthy Concerns} All noteworthy concerns were addressed in the rebuttal phase.

\section{Response to the Meta-Review} We made the following changes for the camera-ready version of the paper, reflecting the changes we committed to in the rebuttal phase. 

\begin{enumerate}

    \item Added an experiment line to Figure~\ref{fig:scalability_rtf} for \name without model inconsistency along with discussion on the tradeoffs (no impact on reconstruction quality or scalability, a slight drop in leakage rate for more stealth).
    
    \item Switched the order of Section 3.1 (scalability problems) and Section 3.2 (model assumptions and attack scope) so that the threat model comes at the beginning of the methodology section.
    
    \item Clarified the range in the model caption of Figure~\ref{fig:model-inconsistency-size} (comparison in size overhead to RtF).
    
    \item Fixed additional typos and added clarifications as brought out in discussion with reviewers during rebuttal. 

\end{enumerate}

\fi