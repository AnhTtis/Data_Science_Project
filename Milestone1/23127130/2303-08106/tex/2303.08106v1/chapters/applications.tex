\section{Domain Generalization Applications in Wireless Communications}\label{sec:future-direction-applications}

When designing data-driven ML-based algorithms for solving wireless communication problems, it is crucial to ensure that the developed algorithms have guaranteed generalization capabilities. However, little effort has been devoted to investigating the DG issue despite the huge research effort in applying data-driven machine learning techniques to various wireless communication. The goal of this section is to overview the existing DG methodologies that were applied by the communication community, and summarize the learned lessons from their applications.


\subsection{Channel Decoding}

Iterative turbo/LDPC decoders \cite{DBLP:journals/tcom/BerrouG96,DBLP:journals/tit/RichardsonSU01} based on the belief-propagation (BP) framework \cite{pearl1988probabilistic} are recognized as state-of-the-art channel decoders because of their capacity approaching/achieving performance for relatively large block lengths. For this reason, they have been adopted in the 4G/5G communication standards.

Many deep learning studies have shown that data-driven ML techniques can decrease the BP decoding complexity especially for short-to-moderate block lengths \cite{DBLP:conf/iccchina/NiuDTG21}. For short-block-length polar codes \cite{DBLP:journals/tcom/Trifonov12} (e.g., 16 bits), DNN-based decoders were shown to exhibit near-optimal performance using maximum a posteriori (MAP) decoding \cite{DBLP:conf/ciss/GruberCHB17}. For larger block length codes (i.e., larger than 100 bits), the BP algorithm was unfolded into a DNN in which weights are assigned to each variable edge, thereby showing an improvement in comparison to the baseline BP method \cite{DBLP:conf/allerton/NachmaniBB16}. By varying the signal-to-noise ratio (SNR) values of the received signal, hypernetworks have been employed to generate the weight of a variable-node network in the Tanner graph \cite{DBLP:conf/nips/NachmaniW19}. Together, all the variable-node networks represent the graph neural network (GNN) on which message passing is performed. Meta-leaning algorithms have been explored in \cite{DBLP:conf/nips/LiBMK0LH21} as part of an end-to-end learning approach. There, meta-tasks were designed by varying the SNR to account for the task difficulty, under a convolutional encoder with a fixed coding rate of $1/2$.

Overall, the aforementioned ML-based channel decoding methods can be classified into two categories \cite{DBLP:conf/iccchina/NiuDTG21}:
\begin{itemize}
    \item \textit{Data-driven methods}: these methods promote end-to-end learning approaches by substituting all the BP decoding components with a DNN \cite{DBLP:conf/ciss/GruberCHB17}. Here, the structure of the code is ignored, and the channel decoding problem is regarded as a classification task from the input (i.e., received signal) to the output (i.e., decoded bits).    
    \item \textit{Model-driven methods}: the goal of this family of methods is to substitute the decoding components of the classical BP-based decoder (e.g., deinterleaver, log-likelihood ratio estimators) with trained DNNs without altering the classical sequence of decoding components \cite{DBLP:conf/nips/JiangKAKOV19,DBLP:journals/jstsp/NachmaniMLGBB18,DBLP:conf/ita/VasicXL18}.
\end{itemize}
Little attention has been, however, paid to studying how DG methodologies can be applied to both categories beyond the simple variation of the SNR values. Moreover, empirical and theoretical understanding of their potential for channel decoding is still lacking.

\subsection{Channel Estimation}

One of the crucial components of any wireless communication system is the channel estimator \cite{heath2018foundations}. A vast body of prior work made use of data-driven ML techniques for channel estimation to show the attractive features of DNNs such as the low computational complexity at inference time \cite{DBLP:journals/wcl/YeLJ18,DBLP:journals/twc/HuGZJL21,DBLP:journals/icl/SoltaniPMS19,gizzini2020deep}. None of these studies, however, did analyze the impact of the distribution shifts on the reported estimation performance. Indeed, little effort has been devoted to investigating the robustness of DG algorithms in estimating wireless channels.

Another channel estimation algorithm for wideband mmWave systems was proposed in \cite{CE-ISTA-hypernetworks} based on unfolding the iterative shrinkage thresholding algorithm with a few learnable parameters. This algorithm was further extended to include a hypernetwork for the sake of generalization to new environments. Given the SNR level and the number of resolvable paths, the hypernetwork generates suitable learnable parameters for the channel estimation model. Alternatively, in \cite{HypetNetCE}, the authors proposed to train a hypertnetwork to learn weighting factors so as to aggregate channel estimation models learned for three main scenarios: urban micro, urban macro, and suburban macro. Hypernetwork recurrent DNNs have also been used to track wireless channels over a wide range of Doppler values \cite{DBLP:conf/globecom/PratikABSW21}. For this multi-Doppler case, classical tracking methods make use of a bank of Kalman filters with an additional Doppler estimation step. Meta-learning was also adopted to train an encoder-decoder architecture to quickly adapt to new channel conditions by varying the number of pilot blocks preceding the payload in each transmission block \cite{DBLP:conf/spawc/ParkSK20}. For sparse MIMO channel estimation, the optimization/estimation modules of the approximate message passing (AMP) \cite{donoho2011design} and vector AMP (VAMP) \cite{DBLP:journals/tit/RanganSF19} algorithms were substituted by learnable DNNs \cite{DBLP:journals/tsp/BorgerdingSR17}. Specifically, DNNs did not neglect the ``Onsager correction'', which lies at the heart of the AMP paradigm, and was rather employed to construct the underlying DNNs. By doing so, it was shown that the Onsager correction is beneficial to train DNNs that $i)$ require fewer layers to reach a predefined level of accuracy and $ii)$ yield greater accuracy overall as compared to DNNs ignoring the Onsager correction term.

Designing multiple channel estimation tasks pertaining to distinct domains requires varying wireless transmission parameters to simulate different channel communication scenarios. As depicted in Fig.~\ref{fig:domain-randomization}, these parameters are categorized as:

\begin{itemize}
    \item \textit{Propagation parameters} which capture the different types of randomness in channel models \cite{heath2018foundations}. They are not under control in practical communication scenarios.
    \item \textit{System parameters} which govern multiple aspects of communication systems that are set by system designers such as the code rate, the number of transmit and receive antennas, the type and order of the modulation constellation, and the carrier frequency, etc.
\end{itemize}
\noindent It is worth noting that varying these parameters to generate different domains will lead to one or multiple types of distribution shifts. As one example, the design of a channel estimator for broadband communication has to generalize over the channel distributions. With the widely adopted strategy for bandwidth expansion, known as carrier aggregation \cite{DBLP:journals/cm/YuanZWY10}, the distribution of the channel coefficient shifts across multiple non-contiguous narrow frequency bands. For this reason, assuming that the channel is the output of a DNN, the DNN-based channel estimator has to account for the label shift of the estimated channel coefficients because their support changes as a function of the frequency band.

Other related studies focusing on continual learning (CL) benchmarked the performance of CL-based methods for MIMO channels estimation by varying the SNR and the coherence time of the channel \cite{akrout2022continual}. A continual learning minimum mean-square error (CL-MMSE) method has also been proposed in \cite{kumar2021continual} where the DNN adapts to different numbers of receive antennas between 8 and 128 to generate tasks with different difficulties.

\subsection{Beamforming}

Steering the main lobe of antenna array systems toward users in a real-time manner (i.e., beamforming) is a critical task to minimize interference and enhance the achievable rate of wireless communication systems. This is because, the antenna array processing in adaptive/reconfigurable digital signal processing algorithms assume no mismatch between the actual and expected array responses to the received signal \cite{monzingo2004introduction}. With the increase of the number of antenna elements in massive MIMO systems, a larger number of degrees of freedom is achieved at the cost of higher algorithmic complexity incurred when optimizing the beamformer weights \cite{heath2018foundations}. Since beamforming weights must be continuously computed under changing propagation environments, ML methods have been explored as a possible solution to low-complexity beamforming design \cite{DBLP:conf/temu/ZaharisYSXLMM16,zaharis2020effective}. For instance, the weighted minimum mean-square error (WMMSE) estimator of the transmit MISO beamforming vector was unfolded such that each estimation iteration corresponds to a DNN \cite{DBLP:journals/ojcs/PellacoBJ22}. By doing so, the matrix-inverse operation of the standard WMMSE estimator is avoided in addition to the advantage of a lower computational complexity without sacrificing the estimation performance. It was also reported that fully distributed reinforcement learning (RL) estimates the uplink beamforming matrix by dividing the beamforming computations among distributed access points without significant accuracy deterioration \cite{DBLP:journals/tccn/FredjAMAH22}. We refer the reader to \cite{DBLP:journals/access/KassirZLKYX22} for a comprehensive review of ML-based beamforming methods.

Few studies, however, have considered DG as an important ingredient to assess the performance of ML-aided beamforming solutions based on the meta-learning framework reviewed in Section \ref{subsec:meta-learning}. A meta-learning algorithm for weighted sum rate maximization was proposed for beamforming optimization in MISO downlink channels \cite{DBLP:conf/isit/XiaG21}. Instead of using the WMMSE algorithm iteratively to update each variable involved in the beamforming optimization problem, long-short-term-memory (LSTM) networks were used in the inner-loop of the meta-learning framework to learn the dynamic optimization strategy and hence update the optimization variables iteratively. The outer-loop of the meta-learning framework, however, makes use of the updated parameters to maximize the weighted sum rate. This strategy adaptively optimizes each variable with respect to the geometry of the sum-rate objective function, thereby achieving a better performance than the WMMSE algorithm. Another line of work employed the standard meta-learning MAML algorithm \cite{DBLP:conf/icml/FinnAL17}
for adaptive beamforming to new wireless environments \cite{DBLP:journals/twc/YuanZWOL21}. This work was further extended to reduce the complexity of the MAML algorithm by dedicating a DNN model as a transferable feature extractor for feature reuse across wireless channel realizations \cite{DBLP:journals/twc/ZhangYZKW22}. Self-supervised learning was used to map uplink sub-6 GHz channels into mmWave beamforming vectors without accessing labeled training datasets \cite{DBLP:journals/twc/ChafaaNBD22}. By exploiting a dataset containing pairs of uplink and downlink channels, DNNs learned implicitly and autonomously the data representations from correlations in the training data pairs to predict the beamforming vectors.

\subsection{Data Detection and Classification}

To decrease the computational complexity of classical data detection algorithms, ML techniques were proposed to detect communication signals under various conditions by reformulating bit/symbol detection as a conventional classification problem \cite{DBLP:journals/jstsp/DornerCHB18,DBLP:journals/corr/FarsadG17,DBLP:conf/spawc/SamuelDW17,al2019learning}. In this context, the various DG techniques reviewed in Sections \ref{sec:data-manipulation}--\ref{sec:learning-paradigms} can be leveraged to investigate the generalization capabilities of DNNs when applied to the data detection problem. For instance, DG demodulation methods for \textit{multiple} modulation schemes have to account for both concept and label shifts of the estimated symbols because the modulation constellation varies from one domain to another. This scenario corresponds to wireless transmissions with adaptive modulation and coding where the choice of modulation order and coding rate is based on the instantaneous channel quality indicator (CQI).

Recently, data detection in MIMO systems with spatially correlated channels has been extensively studied. Indeed, MMNet \cite{mmnet} proposed an unfolding algorithm based on approximate message passing augmented by learnable parameters to achieve state-of-the-art performance on correlated channels. However, this algorithm needs to be re-trained for each channel realization. To overcome this drawback, the authors proposed to use a hypernetwork to predict the learnable parameters based on perfect CSI and noise power knowledge \cite{HypernetSD}. The generalization of this framework was tested under different SNR levels and user mobility settings to simulate different channel spatial correlations. One drawback of this approach is that it assumes that the CSI and noise power are perfectly known at the receiver. Similarly, the unfolded version of the expectation propagation detector was proposed wherein damping factors are learned using meta-learning \cite{zhang2020metaEpNet}. This detector was also extended using hypernetworks to achieve generalization to new channel realizations and noise levels but for typical values of many other system parameters \cite{zhang2021EPNetHypernetwork}. The major drawback here is that DNN must be retrained for each set of new system parameters. A meta-learning strategy was also used to train the damping factors of the VAMP algorithm to improve its convergence speed and quickly adapt to new environments, thereby yielding more accurate signal detection performance \cite{DBLP:journals/twc/ZhangHLWJ21}.

Other similar types of detection/recognition tasks are also of the same classification nature such as modulation classification in non-cooperative communication systems \cite{o2016convolutional} and wireless transmitter classification \cite{youssef2018machine}. These works focus on improving the classification accuracy only, and the generalization ability of DNNs was studied in a few prior work only \cite{DBLP:journals/twc/LiuOP22}.


\subsection{Beam Prediction}

Since 6G and beyond communication systems are moving to higher frequency bands (e.g., mmWave and sub-terahertz), developing techniques for narrow directive beam management is critical to guarantee sufficient receive power. Existing solutions rely on leveraging the channel sparsity \cite{DBLP:journals/jstsp/HeathPRRS16a}, constructing adaptive beam codebooks \cite{DBLP:journals/tcom/AlrabeiahZA22}, and beam tracking \cite{DBLP:journals/icl/JayaprakasamMCK17}. Due to beam training overheads, these classical strategies, however, cannot meet the ever-increasing data rate demands of emerging applications for future systems with large antenna arrays serving highly-mobile users and latency-critical devices \cite{DBLP:journals/corr/abs-2111-11177}. For these reasons, the development of ML-aided methods can offer data-driven solutions for the beam management problem because the beam direction decision depends on the user location and the geometry of the surroundings about which sensory datasets can be collected.

A practical ML solution is expected to generalize to unseen scenarios and operate in realistic dense deployments. The fact that practical sensors do not normally provide accurate enough positions/orientations for narrow beam alignment motivates acquiring multi-modality datasets about the environment such as sub-6GHz channel information, LiDAR point clouds, and radar measurements \cite{DBLP:journals/corr/abs-2209-07519}. DG algorithms should be developed to leverage these datasets representing different domains in the same environment. For example, ideas from domain-invariant representations are beneficial to cope with distribution shift sources such as the quality of collected measurements (e.g, noise level, sensitivity to weather conditions), user mobility, and signal blockages. These factors lead to the acquisition of multiple data domains which can be exploited to learn both domain-invariant and domain-specific features to determine the index of the optimal beamforming vector from the codebook in a generalizable manner.

\subsection{RIS-Aided Wireless Communications}

Wireless communications aided by RISs has triggered a remarkable research effort in the last few years \cite{DBLP:journals/tsp/HuRE18a}. The possibility to purposely manipulate the electromagnetic propagation environment via the use of IRSs, incorporation of IRSs as integral part has pushed researchers to revisit fundamental wireless communication problems (e.g., beamforming, channel estimation) and incorporate the impact of RISs on the overall communication system performance measured in terms capacity, estimation accuracy, secrecy, outage, and energy efficiency. In this context, ML methods belonging to multiple learning paradigms (e.g., supervised/unsupervised learning, reinforcement learning, federated learning) have been also devised to account for the propagation effects of IRSs. We refer the reader to the survey in \cite{DBLP:journals/access/FaisalC22} for an exhaustive summary of ML approaches for RIS-aided communication.

In regard to DG, only a handful of studies have assessed the performance of ML methods from the perspective of accuracy-generalization tradeoff. The problem of channel estimation for RIS-aided communication has been investigated in \cite{DBLP:journals/icl/TsaiCTW22} where an adaptive shrinkage parameter
based on a hypernetwork was used instead of a fixed shrinkage parameter. Based on the current channel recovery status, the hypernetwork provides an updated shrinkage parameter thanks to which the IRS-aided channel estimation accuracy has been assessed over different iterations as well as SNR values ranging between -10 dB and 25 dB. This work does not study DG as a function of the wireless communication parameters but rather with respect to the algorithmic steps of the LAMP algorithm. The robustness to additional noise of RL algorithms when the CSI is perturbed has been examined in \cite{DBLP:journals/corr/abs-2107-08293} in the context of the optimization of RIS phase shifts. This work showed that RL methods exhibit resilience to different channel impairments as compared to classical optimization methods in the evaluation step only. In other words, DG training methodologies were not adopted and hence the work does not consider handling the domain shifts in estimating the phase shifts and only reports the performance degradation during inference.

\subsection{Applications in Edge Networks}

The domain shift problem arises naturally in IoT applications due to the heterogeneity in devices' behavior,  spatial and temporal information, etc. For healthcare IoT sensors, the work in \cite{iotalignmentcovid} applied a data alignment algorithm to learn and project accelerometer data from different users into a common feature space. The learned shared feature space is then used to track users' symptoms. 
For vehicule-to-everything (V2X) applications, a meta-learning approach for power allocation tasks has been proposed in \cite{DBLP:journals/tvt/YuanZWL21} to enhance DNNs to achieve fast adaption to new environments with limited interactions.

DL has been applied in human activity recognition to extract meaningful features from raw sensory data instead of hand-engineered ones. Human activity recognition usually involves multi-modal sensory data from multiple devices/subjects to predict one or multiple activity labels. For the same activity, sensor data can vary depending on the subjects' characteristics such as gender, age, and behavior. One solution to this intra-activity shift problem is to remove the user-specific feature from the sensory information and keep the common activity features across all users only. To do so, feature disentanglement is proposed to learn two groups of representations: the common activity features and user-specific representations \cite{su2022learning}. Another line of work focused on learning statistical features from sensory data using kernel-based techniques \cite{kernelHAR2, kernelHAR}. These studies, however, make use of kernel-based methods for more predictive feature extraction from raw sensory data only. The use of kernel-based methods to improve DG as explained in Section \ref{sec:representation-learning} was not explored.

 \subsection{Summary and Lessons Learned}
In the preceding sections, we reviewed different key applications in wireless communication where DG algorithms should be further investigated for the sake of robust generalization. Our observations and lessons learned are summarized below.
\begin{itemize}
    \item \textbf{Lack of DG algorithms for wireless}: To better judge the suitability of data-driven ML methods for real-world communication uses cases, it is crucial to determine the uncertainty of ML algorithms and analyze their ability to generalize in order to lay the ground for rigorous evaluation protocols. However, minimal effort has been dedicated by the communication community to initiate such an investigation. As one example, use cases in 3GPP Release 18 package such as CSI compression with autoencoders raise multiple interesting DG questions. Questions about the autoencoder training procedure, as well as, the different user traffic scenarios and urban areas should be considered before determining the source and target datasets.
    \item \textbf{One-sided focus on end-to-end DG}: Most DG algorithms are produced by the ML community and hence lack wireless communication knowledge in their designs. As a consequence, most DG communication papers make use of ML end-to-end techniques that are blind to the characteristics of the communication problem at hand. While this trend is worthwhile to assess the generalization performance of end-to-end learning methods, tailoring existing DG algorithms and devising new ones are essential research avenues that require further investigation.
    
    \item \textbf{Need for wireless DG benchmarks}: The number of DG benchmarks within the ML community has significantly increased over the last few years due to the need for algorithmic generalization evaluation (see \cite{DBLP:conf/ijcai/0001LLOQ21} for a comprehensive review). Unfortunately, with few exceptions \cite{DBLP:journals/corr/abs-2209-07519,DBLP:conf/nips/LiBMK0LH21}, the absence of a unified benchmarking in wireless communications renders the comparison of the different proposed DG algorithms impossible. Consequently, it is crucial to establish a unified framework to analyze the improvements of the research endeavors and henceforth design robust and efficient DG algorithms.    
\end{itemize}

