\section{DG Methods: Data Manipulation}\label{sec:data-manipulation}
In order to generalize to unseen scenarios, this category of methods manipulates the DNN input data. Two types of manipulations are possible either in the raw input space or in the latent input space: $i)$ data augmentation by adding random noise or transformation to the input data, and $ii)$ data generation which generates new training samples using generative models. The main objective of these methods is to increase the quantity and improve the diversity of the training dataset for better generalization capabilities without requiring manual labeling of datasets.

\noindent A data manipulation operation is represented by an arbitrary function $\mathcal{M}(\cdot)$ which transforms the input data $X$ to the manipulated data $X^\prime = \mathcal{M}(X)$. Given a DNN that is represented as an input-output function $g(\cdot)$, the learning objective of data manipulation for DG can be expressed as follows:
\begin{equation}\label{eq:data-manipulation-cost-function}
\min_{g}\,\underbrace{\mathbb{E}_{{\mathsf{X}},{\mathsf{Y}}}\big[\mathcal{L}(g(X),Y)\big]}_{\textrm{task loss}} + \underbrace{\mathbb{E}_{\mathsf{X}^{'},\mathsf{Y}}\big[\mathcal{L}(g(X^\prime),Y)\big]}_{\textrm{data manipulation loss}},
\end{equation}
where $\mathcal{L}(\cdot,\cdot)$ is the DNN cost function. It is worth noting that most data manipulation techniques proposed in the literature are geared towards computer vision applications where all datasets consist of images. In this section, we describe these methods within the context of vision applications and point out their potential use for wireless applications.

\subsection{Data Generation}
Generating new data samples using generative models is a popular technique to augment existing datasets so as to cover richer training scenarios, thereby enhancing the generalization capability of a DNN. The data manipulation function $\mathcal{M}(\cdot)$ in (\ref{eq:data-manipulation-cost-function}) can be represented by deep generative models such as variational auto-encoder (VAE) \cite{DBLP:journals/corr/KingmaW13} and generative adversarial network
(GAN) \cite{DBLP:journals/corr/GoodfellowPMXWOCB14}.

Various distribution distance metrics can be employed to generate high-quality samples including:
\begin{itemize}
    \item \textit{domain discrepancy measures} such as the maximum mean discrepancy (MMD) \cite{DBLP:journals/jmlr/GrettonBRSS12} to minimize the distribution divergence between real and generated data samples.
    \item \textit{the Wasserstein distance} between the prior distribution of the DNN input and a latent target distribution as carried out in Wasserstein auto-encoder (WAE) \cite{DBLP:journals/corr/abs-1711-01558}. This metric is a regularization that encourages the encoded training distribution of a WAE to match the data prior and hence preserves the semantic and domain transfer capabilities.
    \item \textit{semantic consistency loss functions} that maximize the difference between the source and the newly generated distributions, thereby creating new domains that augment the existing source domains \cite{DBLP:conf/eccv/ZhouYHX20}.
\end{itemize}

\noindent It is also possible to generate new domains instead of new data samples using adversarial training \cite{DBLP:conf/cvpr/LiGCHWMYLX21} where one or multiple generative models are trained to progressively generate unseen domains by learning relevant cross-domain invariant representations. Such an alternative involves an entire generative model pipeline composed of multiple DNNs trained in cascade or in parallel, and therefore has a significant computational cost. As one example for channel estimation problems, one can start by generating line-of-sight datasets and then progressively increase the rank of the estimated MIMO channel to multi-path models up to full-rank channels such as rich-scattering MIMO channels.

Furthermore, the data manipulation function $\mathcal{M}(\cdot)$ can also be defined without training generative models. In particular, it is possible to generate new data samples by linearly interpolating any two training samples and their associated labels as done in the low-complexity Mixup method \cite{DBLP:conf/iclr/ZhangCDL18}. More recently, many techniques have built upon Mixup for DG to $i)$ generate new data samples by interpolating either in the raw data space \cite{DBLP:conf/bmvc/WangL0K021,DBLP:conf/icassp/WangLK20,DBLP:conf/cvpr/ShuCW0L21}, or $ii)$ to build robust models with better generalisation capabilities by interpolating in the feature space \cite{DBLP:conf/iclr/ZhouY0X21,DBLP:conf/cvpr/Qiao021,DBLP:conf/cvpr/XuZ0W021}.

\subsection{Data Augmentation}

DNNs are heavily reliant on large datasets to enhance the generalization by avoiding overfitting \cite{DBLP:journals/jbd/ShortenK19}. Data augmentation methods provide a cheap way to augment training datasets. They artificially inflate the dataset size by transforming existing data samples while preserving labels. Data augmentation includes geometric and color transformations for visual tasks, random erasing and/or permutation, adversarial training, and neural style transfer. Every data augmentation operation can be considered as a data manipulation function $\mathcal{M}(\cdot)$ in (\ref{eq:data-manipulation-cost-function}). Here, we classify the data augmentation methods for DG into two categories:
\begin{itemize}
    \item \textit{domain randomization}: this family of methods creates a variety of datasets stemming from data generation processes (e.g., simulated environments) with randomized properties and trains a model that generalizes well across all of them.
    \item \textit{adversarial data augmentation}: this family of methods guides the augmentation by enhancing the diversity of the dataset while ensuring their reliability for better generalization capabilities.
\end{itemize}

\begin{figure*}[ht]
     \centering
         \centering
         \includegraphics[scale=0.65]{figures/domain-randomization.pdf}
         \vspace{0.15cm}
         \caption{Summary of the training and evaluation pipeline of machine learning models under data distribution shifts for communication applications.}
         \label{fig:domain-randomization}
\end{figure*}

\subsubsection{\textbf{Domain randomization}}\label{subsubsec:domain-randomization} The reality gap between the data domains resulting from simulations and real-world data collections often leads to failure due to distribution shifts. This gap is triggered by an inconsistency between the physical parameters of simulations (e.g., channel distribution, noise level) and, more fatally, the incorrect physical modeling (e.g., physical considerations of wireless communication \cite{DBLP:journals/tcas/IvrlacN10,akrout2022achievable}). To perceive how DNNs should be trained and evaluated under data distribution shifts for communication applications, Fig.~\ref{fig:domain-randomization} depicts the training and evaluation pipeline where datasets are generated through communication systems models. There, it is seen that source (i.e., training) and target (i.e., test) domains, $\mathcal{D}^{\textrm{train}}$ and $\mathcal{D}^{\textrm{test}}$, are obtained according to the training and test scenarios, $\mathcal{S}^{\textrm{train}}$ and $\mathcal{S}^{\textrm{test}}$. The latter are determined by defining a set of communication scenarios by varying one or multiple communication parameters of interest. The choice of these parameters dictates the data domains and hence provides a way to control and then analyze the impact of distribution shifts on the performance of DNNs. For instance, research efforts to design broadband ML-aided decoding algorithms should vary the signal frequency and assess the generalization capability of DNNs when trained on carriers in the sub-6 GHz band then evaluated on a different communication band. 

\noindent Domain randomization generates new data samples stemming from simulated dynamics of complex environments. For computer vision applications, the function $\mathcal{M}(\cdot)$ in (\ref{eq:data-manipulation-cost-function}) encloses different manual transformations such as altering object properties (e.g., shape, location, texture), scene editing (e.g., illumination, camera view), or random noise injection \cite{DBLP:conf/iros/TobinFRSZA17}. For real-valued data input vectors, augmentation involves scaling, pattern switching, and random perturbation \cite{pialla2022data}. These augmentation methods are particularly interesting for wireless communication applications because they handle general signal transmission scenarios that are tolerant to variations in the path-loss coefficient, synchronization delays, signal-to-noise ratio, etc.

\subsubsection{\textbf{Adversarial data augmentation}}
\noindent The fact that most domain randomization described in Section \ref{subsubsec:domain-randomization} is performed randomly indicates that there exist potential improvements to remove ineffective randomization that does not help with DNNs' generalization. This optimization is performed by adversarial data augmentation.

Toward this goal, research efforts have been dedicated to designing better strategies for non-random data augmentation. By modeling the dependence between the data sample $X$, its label $Y$, and the domain label $d$ (cf. Definition \ref{def:DG}), it has been shown that the input data can be perturbed along the direction of greatest domain change (i.e., domain gradient) while changing the class label as little as possible \cite{DBLP:conf/iclr/ShankarPCCJS18}. Another line of work devised an adaptive data augmentation procedure where adversarially perturbed samples in the feature space are iteratively added to the training dataset \cite{DBLP:conf/nips/VolpiNSDMS18}. It is also possible to train a dedicated transformation network for data augmentation by $i)$ maximizing the domain classification loss on the transformed data samples to tolerate domain generation differences, and $ii)$ minimizing the label classification loss to ensure that the learned augmentation does not affect the DNN performance \cite{DBLP:conf/aaai/ZhouYHX20}. While adversarial data augmentation can provide richer datasets and fill in data gaps against some adversarial examples, this comes at the cost of a more complex training procedure which is known to be less stable and computationally extensive.

When it comes to wireless communications applications, physics-based models are available to guide data augmentations that are consistent with the law of physics, beyond purely random strategies. For example, the study of the achievable rate of reconfigurable intelligent surface (RIS)-aided communication systems do exhibit the same performance regardless of the carrier frequency due to the scaling invariance property of Maxwell's equations when no source is present (i.e., passive RISs) \cite{jackson1999classical}. Another interesting implication stemming from the symmetry of Maxwell's equations is the frequency independence property of certain wideband antennas that display very similar radiation pattern, gain and impedance above a certain threshold frequency \cite{hohlfeld1999self}. This suggests that the generation of wireless datasets for far-field communication can be made independent of the carrier frequency for specific types of antennas.

From this perspective, data augmentation methods that are aware of the physics of wave propagation do not blindly generate source and target domains for different carrier frequencies. They should instead collapse the data augmentation process to scenarios that do enjoy the scaling invariance property. As a result, not only do data augmentation techniques become efficient but also physically consistent with the electromagnetic properties of RISs. 
