\section{Introduction}
\label{Sec:Intro}

\subsection{Motivation}

The envisioned design, standardization\footnote{See 3GPP Release 18 \cite[Section 9.2]{3GPPRelease18} for some potential use cases of ML in wireless.}, and deployment of ML in wireless networks require the establishment of evaluation guidelines to properly assess the true potential of data-driven methods. Nevertheless, almost all the openly published ML techniques for wireless systems have several limitations such as $i)$ difficulty to generalize under a \emph{distribution shift}, $ii)$ inability to continuously learn from different scenarios, and $iii)$ inability to \emph{quickly} adapt to unseen scenarios, to name a few. Their showcased performance seems over-fitted to a specific set of simulation settings or fixed datasets, thereby limiting their attractiveness to compete with classical methods at the moment. As one example, the linear minimum mean-square error (LMMSE) estimator of an arbitrary channel model is considered by the industry as one of the most robust estimators in practice. While it is always possible to beat the LMMSE estimator with deep neural network (DNNs) approximators \cite{DBLP:journals/wc/BelgiovineSBRC21}, this fact holds only for an \textit{a priori} known model that is used to generate training and test datasets on which DNNs are trained and also evaluated. When the distributions of training and test datasets are different (e.g., Ricean vs. Rayleigh, or sparse vs. rich-scattering channels), the performance of DNNs deteriorates appreciably due to domain distribution gaps. Furthermore, the lack of real-world wireless communication datasets aggravates the uncertainty toward the practical deployment of ML-based methods. This calls for the development of new ML training algorithms and the establishment of rigorous evaluation protocols to assess their OOD generalization.

In this work, we focus on generalization under domain shift. This includes any change in the distribution between the training (i.e., source) data and the target (i.e., test data). The most studied type of distribution shift is \emph{covariate} shift when the distribution of the model inputs (or features) changes between the source and the target domains \cite{DBLP:conf/ijcai/LiuHJHXOLFW21}. It was shown that the performance of DNNs degrades drastically due to small variations or perturbations in the training datasets \cite{DBLP:journals/corr/abs-1903-12261}. Thus, the acclaimed success of deep learning (DL) is mostly driven by the power of supervised learning. One straightforward idea to overcome domain shift is to adapt the model to the new domain via additional finetuning using techniques such as transfer learning \cite{DBLP:journals/pieee/ZhuangQDXZZXH21} and domain adaptation \cite{DBLP:journals/ijon/WangD18}. However, this is not always feasible in practice because $i)$ target \emph{labeled} data may not be available for finetuning and $ii)$ the finetuning or adaptation may take a long time in contrast to the ``real time'' requirement in most wireless applications. This motivates the DG problem \cite{DBLP:journals/corr/abs-2103-02503} to handle domain shift \textit{without} requiring target domain data. 

DG has been extensively studied in the last decade in the ML community which led to a broad spectrum of methodologies and learning techniques. Moreover, DG was examined in different applications, namely, computer vision \cite{DBLP:conf/iccv/LiYSH17,DBLP:conf/icml/LiYZH19}, natural language processing \cite{DBLP:conf/icml/MillerKRS20,DBLP:conf/acl/JoshiH22}, and medical imaging \cite{DBLP:journals/cbm/LiLMLQDHLY22}, etc. Here, we emphasize the importance of the DG problem in wireless applications to advance the current state-of-the-art research, and raise attention to the problem of domain shift which can seriously impede the success of ML techniques in wireless networks. Specifically, we highlight the importance of leveraging wireless communication domain knowledge to tailor or design more generalizable ML algorithms. 

This work provides a timely and comprehensive overview of the DG research landscape and insights into promising future research directions. The scope of this paper is limited to the DG problem as defined above. At the time of the writing, we have identified several DG variants proposed in the literature that we will briefly discuss but we focus on the standard definition of the DG problem. Other related fields such as domain adaptation, transfer learning, zero-shot learning, multi-task learning, and test time training are beyond the scope of this work. However, we will explain the difference between these fields and DG. In addition, we do distinguish between the terms ``generalization'' and ``robustness'', unlike most wireless communication papers which use them interchangeably. Here, generalization which is also known as \emph{model robustness} denotes the ability of DNNs to generalize to unseen scenarios under distribution shifts. Robustness, however, refers to the stability of DNNs' performance under noise and adversarial examples, i.e., \emph{adversarial robustness} \cite{DBLP:journals/corr/abs-2007-00753}.

\subsection{Contributions and Organization of the Paper}
The main contributions of this paper are summarized as
follows:
\begin{itemize}
    \item We define the DG problem and present four types of distribution shifts. We then contrast DG to existing research fields such as domain adaptation, transfer learning, continual learning, etc.
    \item We summarize different ML methodologies for DG which focus on the following three DNN training steps: (i) data manipulation to cover richer domains pertaining to a given dataset, (ii) representation learning to acquire domain-invariant features enabling generalization, and (iii) learning frameworks which go beyond the standard gradient-based DNN optimization.
    \item We also review the literature on previous attempts for applying ML techniques for DG in several wireless communications problems such as channel decoding, beamforming, multiple-input multiple-output (MIMO) channel estimation, and reconfigurable intelligent  surface (RIS)-aided communications. To the best of our knowledge, this is the first initiative to reconsider the existing applications of ML techniques in wireless research from the DG perspective.
    \item We present the main challenges facing the application of data-driven machine learning techniques in wireless communication under DG requirements and discuss their potential for improving the network performance.
\end{itemize}

The rest of the paper is organized as illustrated in Fig. \ref{fig:scope-paper}. In Section \ref{sec:background}, we introduce the DG problem formulation and show its key differences with related research fields. State-of-the-art algorithms for DG belonging to data manipulation, representation learning, and learning paradigms are reviewed in Sections \ref{sec:data-manipulation}, \ref{sec:representation-learning}, and \ref{sec:learning-paradigms}, respectively. Section \ref{sec:future-direction-applications} showcases the recent advances of the reviewed DG algorithms in several wireless communication problems, followed by a summary of the learned lessons from their applications. Finally, we outline in Section \ref{sec:future-direction} potential research directions, from which we draw out our concluding remarks in Section \ref{sec:conclusion}.

\begin{figure}[!ht]
     \centering
         \centering
         \includegraphics[scale=0.47]{figures/survey-organization.pdf}
         \caption{Scope of this work.}
         \label{fig:scope-paper}
\end{figure}
