\section{DG Methods: Representation Learning}\label{sec:representation-learning}
Generalizing to unseen scenarios is not solely dependent on the DNN prediction approximation function $g(\cdot)$ given in (\ref{eq:data-manipulation-cost-function}). It also depends on the data representations (i.e., features) learned by the DNN \cite{DBLP:journals/pami/BengioCV13}. To better isolate these two distinct tasks, one can view the overall DNN approximation function, $g(h(\cdot))$, as a composition of a prediction/classification function $g(\cdot)$ and a representation learning function $h(\cdot)$. Fig. \ref{fig:DL-rep-learning} depicts this decomposition, $h(X)$, as the output of the representation learning step. In theory, this representation in the feature space comprises two separate representations. The first one denoted by $h_{\textrm{inv}}(X)$ is a domain-invariant representation that is shared across domains (a.k.a., cross-domain representation) and is key to enabling generalization over multiple domains. The second representation $h_{\textrm{spe}}(X)$, however, is domain-specific and represents the variation pertaining to a specific domain. In practice, these two representations can either be non-separable or separable. For instance, several earlier research works \cite{DBLP:conf/icassp/OppenheimLKP79,oppenheim1981importance,hansen2007structural} have shown that in the Fourier spectrum of signals, the phase component predominantly carries low-level statistics whereas the amplitude component mainly contains high-level semantics. Hence, Fourier phase features represent domain-invariant features that cannot be easily affected by domain shifts when used for DG \cite{lu2022domaininvariant}.

\begin{figure}[th!]
     \centering
     %\vspace{-0.2cm}
%\rule{\textwidth}{0.4pt}\vspace{0.2cm}
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[scale=0.32]{figures/representation-learning1.pdf}
         \caption{without representation learning\vspace{0.5cm}}
         \label{fig:DL-standard}
     \end{subfigure}
     
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[scale=0.32]{figures/representation-learning2.pdf}
         \caption{with representation learning}
         \label{fig:DL-rep-learning}
     \end{subfigure}
    \caption{Illustration of ML-aided classification/prediction (a) without an explicit representation learning step (a.k.a. end-to-end learning), and (b) with a representation learning step.}
    \label{fig:with-without-rep-learning}
    %\vspace{-0.2cm}
\end{figure}

From a mathematical point of view, the optimization problem of representation learning can be written as follows:

\begin{equation}\label{eq:representation-learning-cost-function}
\min_{g,\,h}~\,\underbrace{\mathbb{E}_{{\mathsf{X}},{\mathsf{Y}}}\big[\mathcal{L}(g(h(X)),Y)\big]}_{\textrm{task loss}} + ~\lambda\,\hspace{-0.5cm}\underbrace{r(X)}_{\textrm{regularization loss}},
\end{equation}
where $r(X)$ is a regularization function and $\lambda$ is the associated regularization parameter.

\noindent Depending on the type of the regularization function $r(X)$ or the representation learning function $h(\cdot)$, it is possible to categorize representation learning for DG into two categories:
\begin{itemize}%[leftmargin=*]
    \item \textit{domain-invariant representation learning}: the goal of this family of methods is to learn features that are invariant across different domains. These features are transferable from one domain to another, hence their importance for domain generalization.
    
    \item \textit{feature disentanglement}: these methods decompose a feature representation into one or multiple sub-features, each of which is either domain-specific or domain-invariant.
\end{itemize}

\subsection{Data-Invariant Representation Learning}\label{subsec:data-invariant-representation-learning}

\subsubsection{\textbf{Kernel-based methods}}
Learning representation using kernel methods (e.g., support vector machines \cite{DBLP:journals/ml/CortesV95}, kernel component analysis \cite{scholkopf1997kernel}) is a classical problem in the ML literature. In such a setting, the representation learning function $h(\cdot)$ in (\ref{eq:representation-learning-cost-function}) maps the data samples to the feature space using kernel functions (e.g., radial basis function (RBF), Gaussian, and Laplacian kernels).

For domain generalization, several methods were devised to learn domain-invariant kernels to determine $h(\cdot)$ from the training dataset. Specifically, a positive semi-definite kernel learning approach for DG was proposed in \cite{DBLP:journals/jmlr/BlanchardDDLS21} by considering the conventional supervised learning problem where the original feature space is augmented to include the marginal distribution that generates the features. It is also possible to learn kernel functions by minimizing the distribution discrepancy between all the data samples in the feature space. This method is known as domain-invariant component analysis (DICA) \cite{DBLP:conf/icml/MuandetBS13} and is one of the classical kernel methods for DG.

For classification tasks, in presence of covariate shift only, a randomized kernel algorithm was devised in \cite{DBLP:conf/ijcai/ErfaniBMNLBR16} to extract features that minimize the difference between the marginal distributions across domains. Multi-domain discriminant analysis (MDA) and scatter component analysis (SCA) approaches were proposed in \cite{DBLP:conf/uai/Hu0CC19,DBLP:journals/pami/GhifaryBKZ17} to learn a domain-invariant feature transformation in presence of both covariate and conditional shifts across domains. This is done by jointly minimizing the divergence among domains within each class and maximizing the separability among classes.

\subsubsection{\textbf{Domain adversarial learning}}

Since the presence of spurious features in the data decreases the robustness of DNNs, adversarial learning is a widely used technique to learn invariant features by training generative adversarial networks (GANs). Specifically, the discriminator is trained to distinguish the domains while the generator is trained to fool the discriminator so as to learn domain invariant feature representations for DG \cite{DBLP:conf/cvpr/LiPWK18}. Another line of work in \cite{DBLP:conf/cvpr/GongLCG19} generated a continuous sequence of intermediate domains flowing from one domain to another to gradually reduce the domain discrepancy, and hence improve the DNN generalization ability on unseen target domains. Learning class-wise adversarial networks for DG was also  proposed in \cite{DBLP:conf/eccv/LiTGLLZT18} based on conditional invariant adversarial training when both covariate and conditional shifts coexist.

\subsubsection{Explicit feature alignment}\label{subsubsec:explicit-feature-alignment}

This family of methods learns domain-invariant representations by aligning the features across source domains using one of the following two mechanisms:
\begin{itemize}%[leftmargin=*]
    \item explicit feature distribution alignment through distance minimization or moment matching.
    \item feature normalization addressing data variations to avoid learning nonessential domain-specific features.
\end{itemize}

Feature distribution alignment methods were devised to impose a variety of distribution distances such as the maximum mean discrepancy (MMD) on latent feature distributions \cite{DBLP:conf/cvpr/LiPWK18,DBLP:journals/corr/TzengHZSD14}, and the label similarities for samples of the same classes from different domains using the Wasserstein distance \cite{DBLP:journals/ijon/ZhouJSWC21}. Moment matching for multi-source domain adaptation (M3SDA) was also introduced in \cite{DBLP:conf/iccv/PengBXHSW19} to transfer learned features from multiple labeled source domains to an unlabeled target domain by dynamically aligning moments of their feature distributions.


Feature normalization methods, however, focus on increasing the discrimination capability of DNNs. They do so by normalizing the features to eliminate domain-specific variation while keeping domain-invariant features to enhance generalization. In particular, instance normalization (IN) \cite{DBLP:conf/eccv/PanLST18} and batch instance normalization (BIN) \cite{DBLP:conf/nips/NamK18} have been proposed to enhance the generalization capabilities of convolutional neural networks (CNNs). Instance normalization has been applied in \cite{DBLP:journals/corr/abs-2111-15077} for DG where labels were missing in the training domains to acquire invariant and transferable features. It was also shown that adaptively learning the normalization technique can improve DG without predefining the normalization technique in the DNN architecture a priori \cite{DBLP:conf/cvpr/FanWKYGZ21}.

\subsubsection{\textbf{Invariant risk minimization}}
Another unique perspective on learning domain-invariant representations for DG is to constrain DNNs to have the same output across all domains. The motivation behind this constraint is that an optimal representation for prediction or classification is \textit{the cause} of the DNN output label. This causal relationship from the representation (i.e., the cause) to the label (i.e., the effect) should not be affected by other factors including the domain input. Therefore, the optimal representation is domain invariant and can be learned using invariant risk minimization (IRM) \cite{DBLP:journals/corr/abs-1907-02893}. Given $K$ different domains, the IRM problem can be formulated as follows:
\begin{subequations}\label{eq:IRM}
    \begin{align}
    &\min_{h\in\mathcal{H}}~ \sum\limits_{k=1}^{K}~\mathbb{E}_{\,\mathsf{X}_k,{\mathsf{Y}}_k}\big[\mathcal{L}(g(h(X_k)),Y_k)\big]\label{eq:IRM-1}\\
    &\textrm{subject to~} g \in \bigcap_{k=1}^{K}\,\argmin_{g'\in\,\mathcal{G}}~\mathbb{E}_{\,{\mathsf{X}}_k,{\mathsf{Y}}_k}\big[\mathcal{L}(g'(h(X_k)),Y_k)\big],\label{eq:IRM-2}
    \end{align}
\end{subequations}
where $\mathcal{H}$ and $\mathcal{G}$ are the learnable function classes for representation and task functions, $h(\cdot)$ and $g(\cdot)$, respectively. The optimization in (\ref{eq:IRM}) finds the optimal representation function $h(\cdot)$ that minimizes the sum of all the task losses in (\ref{eq:IRM-1}) given in (\ref{eq:representation-learning-cost-function}). This minimization is carried out under the constraint in (\ref{eq:IRM-2}) which ensures that all domains share
the same optimal representation function $h(\cdot)$.

The idea behind the IRM formulation has drawn significant attention. Specifically, the IRM optimization was extended to text classification \cite{DBLP:journals/corr/abs-2004-05007}, reinforcement learning \cite{DBLP:conf/l4dc/SonarPM21}, self-supervised settings \cite{DBLP:conf/iclr/MitrovicMWBB21}, and to the case of extrapolated task losses among source domains \cite{DBLP:conf/icml/KruegerCJ0BZPC21}. Moreover, it was shown in \cite{DBLP:conf/nips/AhujaCZGBMR21} that constraining the invariance to the task function $g(\cdot)$ only~--- as done in (\ref{eq:IRM})~--- is not enough to guarantee the causal relationship from the representation to the label. A new regularization has thus been proposed to ensure that the representation function $h(\cdot)$ cannot capture fully invariant features that break down the assumed causality as required by the IRM formulation.

\subsection{Feature Disentanglement}

Unlike domain-invariant representation learning, disentangled representation learning relies on DNNs to learn a function that maps a data sample to a feature vector, which factorizes into distinct feature sets as depicted in Fig. \ref{fig:disentangled-representation}. There, it is seen that the entire feature space can be decomposed into a set of feature subspaces. Each feature set is a representation pertaining to a specific feature subspace only. When the feature representation is decomposable into multiple non-overlapping feature subsets, the feature representation is said to be ``disentangled''.
\begin{figure}[h!]
     \centering
         \centering
         \includegraphics[scale=0.48]{figures/disentangled-representation.pdf}
         \caption{Illustration of how a trained neural network transforms a data sample into a disentangled representation vector that factorizes into $N$ small feature vectors.}
         \label{fig:disentangled-representation}
\end{figure}

\noindent The importance of disentanglement-based representation learning for DG stems from the fact that features can be explicitly decomposed into domain-invariant and domain-specific features. As a result, the representation function $h(\cdot)$ defined in (\ref{eq:representation-learning-cost-function}) can be decomposed into two distinct representation functions: $h_{\textrm{inv}}(\cdot)$ for domain-invariant representation and $h_{\textrm{spe}}(\cdot)$ for domain-specific representation. The disentanglement-based optimization can be formulated as follows:
\begin{equation}\label{eq:disentangled-representation-learning-cost-function}
\begin{aligned}
\hspace{-0.3cm}\min_{h_{\textrm{spe}},\,h_{\textrm{inv}},\,g}~&\,\underbrace{\mathbb{E}_{{\mathsf{X}},{\mathsf{Y}}}\big[\mathcal{L}(g(h_{\textrm{inv}}(X)),Y)\big]}_{\textrm{task loss}} +~ \lambda\,\hspace{-0.5cm}\underbrace{r(X)}_{\textrm{regularization loss}} \\
&\hspace{1cm}+ \mu\,\,\underbrace{\mathbb{E}_{{\mathsf{X}}}\big[\mathcal{L}(h_{\textrm{inv}}(X),h_{\textrm{spe}}(X),X)\big]}_{\textrm{reconstruction loss}},
\end{aligned}
\end{equation}
where $\lambda$ and $\mu$ are regularization parameters. In (\ref{eq:representation-learning-cost-function}), the regularization loss encourages the separation between domain-invariant and domain-specific features, while the reconstruction loss ensures that such separation does not lead to significant information loss. In other words, regularization and reconstruction losses are competing penalties that add up to the task loss, and it is the task of the ML designer to find the suitable trade-off that enhances the generalization of DNNs.

\subsubsection{\textbf{Multi-component analysis}}
Multi-component methods dedicate different sets of parameters to learn domain-invariant and domain-specific features. The method ``UndoBias'' proposed in \cite{DBLP:conf/eccv/KhoslaZMET12} learns dedicated SVM models. It represents the dedicated SVM parameters, $\bm{w}_k$, pertaining to the $k$th domain as a perturbation of the domain-invariant parameters $\bm{w}$ with the domain-specific parameters $\Delta\bm{w}_k$, i.e., $\bm{w}_k = \bm{w} + \Delta\bm{w}_k$. This method has been extended for multi-view vision tasks by introducing a regularization to minimize the mismatch between any two view representations \cite{DBLP:conf/iccv/NiuLX15} for better generalization. Neural networks have also been used to capture disentangled representations by learning domain-specific
networks for each domain and one domain-invariant network for all domains \cite{DBLP:journals/tip/DingF18}. Another line of work considered manually comparing specific areas of DNN's attention heatmaps from different domains which proved beneficial to learning disentangled representations and ensuring a more robust generalization \cite{DBLP:conf/cvpr/ZuninoBVS0SMS21}.

\subsubsection{\textbf{Generative modeling}}
Generating data samples whose feature representations are disentangled requires adapting the data generative process of generative models to new constraints. The latter can be incorporated in the loss functions of GANs to encourage feature disentanglement
by separating the domain-specific and domain-invariant features \cite{DBLP:journals/corr/abs-2109-05826}. An autoencoder-based variational approach was devised to disentangle the features by learning three independent latent subspaces, one for the domain, one for the class, and one for any residual variations \cite{DBLP:conf/midl/IlseTLW20}. To generate domains that are different from the source domain, the discrepancy between augmented and sources domains was maximized for out-of-domain augmentation using meta-learning under a semantic consistency constraint \cite{DBLP:conf/cvpr/QiaoZP20}.

For classification tasks, diversifying the inter-class
variation by modeling potential seen or unseen variations across classes was formulated as a disentanglement-constrained optimization problem \cite{DBLP:conf/cvpr/ZhangZLWSX22}. This was made possible by minimizing the discrepancy of the inter-class variation where both intra- and inter-domain variations are regarded as constraints.
