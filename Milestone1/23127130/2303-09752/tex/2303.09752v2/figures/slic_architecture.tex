\begin{figure}[t!]
    \centering
    \includegraphics[width=0.95\columnwidth]{images/slic_architecture}
    \caption{An overview of a \slic Transformer layer with conditional computation. All tokens are processed by light attention and MLP layers, while $q$ routed query tokens perform heavier attention over $v$ routed key-value tokens and $m$ routed tokens are processed by a heavier MLP.}
    \label{fig:slic}
\end{figure}