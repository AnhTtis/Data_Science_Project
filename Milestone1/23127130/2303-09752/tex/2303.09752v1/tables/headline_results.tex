\begin{table*}[t!]
\centering
\footnotesize
\begin{tabular}{l|c|cc|ccccccccc}
\toprule
\textbf{Model} & \textbf{Avg} & \multicolumn{2}{|c|}{\textbf{Speed}}& \textbf{TQA} & \textbf{NQA} &  \textbf{QAS} & \textbf{QuAL}  &\textbf{CNLI} & \textbf{arXiv} &  \textbf{SumS} & \textbf{QMS}  & \textbf{GovR}    \\
\midrule
 &  & \textbf{inf} & \textbf{fn} & \textbf{F1} & \textbf{F1} &  \textbf{F1} & \textbf{EM}  &\textbf{EM} & \textbf{R\textsubscript{gm}} &  \textbf{R\textsubscript{gm}} & \textbf{R\textsubscript{gm}}  & \textbf{R\textsubscript{gm}}    \\
\midrule
 \longt-B & 43.1 & 0.6 / 7.4&3.7   & 82.2 & 23.0 & 46.6 & 37.9 & 85.6 &  35.4 & 19.2 & 20.4 &  37.7  \\    
\slic-B & 42.4 & 11.2&6.5 & 82.4    & 23.3 & 42.1 & 36.5   & 86.5 & 35.3 & 18.7 & 18.4 & 37.9\\ 
\midrule
\longt-L  & 45.3 & 0.3 / 3.0&1.3  & 84.2 & 27.2 & 52.3 & 40.6 & 87.3 &  35.7 & 19.1 & 21.4 &  39.5  \\    
 \slic-L  & 45.3 & 5.0&2.0  & 84.5 & 27.7 & 49.8 &39.9 & {\bf 88.7} &  35.9 & {\bf 20.5} & 21.0 &  39.7  \\ 
\midrule
\longt-XL  & 46.6 & 0.2 / 1.2 &0.4  & 85.3 & 29.3 & 53.1 & 46.0 & 88.2 &  35.9 & 19.4 & 21.3 &  \textbf{40.5}  \\    
 \slic-XL & \textbf{47.4} & 2.3 & 0.5   & \textbf{86.1} & \textbf{31.1} & \textbf{53.9} & \textbf{48.1} & 88.4 & \textbf{36.1} & 20.0 & \textbf{22.5} &  \textbf{40.5}  \\  
    \bottomrule
\end{tabular}
\caption{Performance comparison of \slic and \longt Base, Large and XL models on question-answering datasets TriviaQA (TQA), NarrativeQA (NQA), QASPER (QAS), and QuALITY (QuAL), NLI dataset ContractNLI (CNLI), and summarization datasets arXiv, SummScreenFD (SumS), QMSum (QMS), and GovReport (GovR). SCROLLS results are on leaderboard test set where \slic-XL achieves SOTA. Average speed is reported in samples per second for inference (inf) and fine-tuning (fn). \longt does not use MQA but inference speed is reported without/with MQA for conservative baseline. R\textsubscript{gm} stands for the geometric mean of ROUGE-1,2,L.}
\label{table:headline_results}
\end{table*}