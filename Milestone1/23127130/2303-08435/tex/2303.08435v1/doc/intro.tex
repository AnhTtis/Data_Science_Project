\section{Introduction}
\label{sec:intro}

In modern chip manufacturing, lithography simulation is one of the most critical technologies which affects many other fabrication processes. %And the importance grows as the feature size continuously shrinks.
Traditional rigorous lithography methods model optical lithography numerically by multifold integrals of the mutual intensity of all contributing source points through the projection system from the illuminator~\cite{DFM-B2008-Mack}, which is computationally expensive and challenging, even when equipped with approximation algorithms.
Given a mask, lithography simulation generates an aerial image that is defined as the intensity distribution at the wafer plane, as depicted in \Cref{fig:litho}.
An estimate of the binary resist image can be obtained by applying an exposure-dose-dependent intensity threshold on an aerial image.

Considering the significance and challenges of lithography simulation, enormous advances in computing power and machine learning (ML) algorithms stimulate the growth of exploiting data-driven methods for lithography modeling.
Generally, ML-based methods apply groups of transformations and learnable parameters to fit a mask-to-aerial~\cite{ISPD-2020-TEMPO}  or mask-to-resist~\cite{DFM-DAC2019-Ye,OPC-TCAD-DAMO,DAC22-DOINN-Yang} mapping.
LithoGAN~\cite{DFM-DAC2019-Ye} is a lithography framework using conditional generative adversarial nets (cGAN) to predict the resist pattern of a cropped clip.
LithoGAN introduces an extra branch of convolution neural networks (CNN) to perform center coordinates regression for better accuracy, limiting it is only applicable to a single contact.
DAMO~\cite{OPC-TCAD-DAMO} exploits the UNet++ as the deep convolutional generative adversarial networks generator to engage the deep lithography simulator in a high-resolution manner, which can be further extended to processing full-chip scale.
Yang~\etal proposes a dual-band optics-inspired neural network (DOINN)~\cite{DAC22-DOINN-Yang} lithography model with Fourier Neural Operator (FNO) to properly leverage both high-frequency and global low-frequency components of mask-resist pairs.
The state-of-the-art (SOTA) aerial image model, TEMPO~\cite{ISPD-2020-TEMPO}, applies cGAN as a thick mask effect modeling framework capable of predicting 3D aerial images at different heights.


\begin{figure}
  \centering
  \subfloat[]{ \includegraphics[width=.56\linewidth]{lens} \label{fig:lens}}
  \subfloat[]{ \includegraphics[width=.28\linewidth]{litho_flow} \label{fig:litho_flow}}
  \caption{
    (a) Components of the lithography imaging system: illumination source, lenses, and pupil.
    (b) Lithography simulation flow using source- and pupil-dependent optical kernels.
  }
  \label{fig:litho}
\end{figure}
However, all these CNN-based image generation models still have some drawbacks for lithography modeling problems.
Since all previous arts are fitting a particular image-to-image mapping from massive training pairs instead of learning the true lithography behavior,
the learned parameters have a strong bias on the mask shapes, layer types, and training dataset distributions,
which fails to generalize on out-of-distribution (OOD) datasets.
In \Cref{fig:general}(a), we visualize the t-Distributed Stochastic Neighbor Embedding (t-SNE) of four datasets used in this work and DOINN~\cite{DAC22-DOINN-Yang}.
As depicted in \Cref{fig:general}(b), despite being well-trained, DOINN and TEMPO fail to generalize on OOD datasets.
A possible solution is to use larger models to fit different distributions.
However, it will increase computational cost exponentially while suffering from precision loss, thus is not a one-fit-all approach.



The generalization failure of a DNN model for lithography modeling will not be desired, given the fact that a real simulator can handle masks of different layers without any degradation.
If we revisit the lithography simulation model, as depicted in \Cref{fig:litho_flow}, it can be noticed that the intrinsic knowledge of a lithography system is in the optical kernel, which is almost ignored when conducting image-to-image mapping based on a neural network.
It motivates us to investigate the mystery of the optical kernel for fast and accurate lithography modeling.
The rigorous Hopkins lithography model~\cite{hopkins1953diffraction} separates the influence of the mask and the lithographic imaging system, including pupil function and illumination.
The latter is an intermediate variable often referred to as transmission cross-coefficient (TCC) $\mathcal{T}$,
which can be pre-computed and stored as optical kernels to improve the computing efficiency~\cite{Fhner2014ArtificialEF}.
Now we may ask: \textit{Can we train a deep neural network to replace the optical kernels for efficient lithography modeling?}
Nevertheless, this framework encounters several obstacles.
First, TCC kernels are hard to obtain and calibrate, making direct regression impractical.
We are seeking for a feasible alternative to decode the intermediate optical kernels from final imaging samples of mask images and aerial images.
Second, TCC-related computations are performed in the spatial frequency domain with complex values, which implies that the network needs to support complex-valued computations.

To handle the above issues, we attempt to use physical \textit{`resolution limits'} to design the TCC optical kernel dimensions.
Then, a set of differentiable complex-valued neuron layers are designed and implemented.
Last, optical kernels are location-dependent matrices.
Inspired by \textit{neural radiance field} (NeRF)~\cite{ECCV-2020-NeRF},
we design and implement a complex-valued multilayer perception ($\operatorname{\mathbb{C}MLP}$),
which only takes coordinates as input to perform optical kernel regression.
Moreover, a novel training procedure that separates mask processing and optical kernel prediction is proposed. % to generate the final aerial image  in \Cref{subsec:forward_training}.
To conclude, in this paper, we propose Nitho, a NeRF-inspired and physics-informed lithographic network optimizing complex-valued neural fields to predict the TCC spectrum as optical kernels,
which will be further multiplied with the mask spectrum to generate a high-accuracy aerial image.

The major contributions of this paper include:
\begin{enumerate}
  \item To the best of our knowledge, it is the first neural network-based framework predicting TCCs that models the true lithography behavior instead of learning an image-to-image black box mapping.
  \item Inspired by Hopkins model, Nitho abandons CNN-based architecture and creates a new training paradigm separating the influence of mask and lithography system using a simple coordinate-based complex-valued multilayer perception.
  \item Similar to industrial simulator, the physics-informed design maximizes Nitho's generalization capability on mixed types of mask data with no more specific treatment on different types of masks.
  \item The proposed Nitho framework can use 31\% model size on less training data to generate high-resolution aerial images while achieving $69\times$ smaller mean squared error and higher accuracy than SOTA.
Compared with traditional lithography simulator, Nitho can achieve $90\times$ speedup with less than 1\% accuracy loss.
\end{enumerate}

