\section{Experiment}



\subsection{Datasets}
In \Cref{tab:data}, our model is evaluated on both metal and via layer designs.
The t-SNE distribution of datasets is shown in \Cref{fig:general}(a).
\subsubsection{ICCAD-2013}
ICCAD 2013 CAD contest~\cite{OPC-ICCAD2013-Banerjee} provides ten 4$\mu m^2$ tiles for testing.
We obtain the training set from GAN-OPC~\cite{OPC-TCAD2020-Yang},
which contains 4K 4$\mu m^2$ tiles generated following the same design rules of the contest.
To test the robustness of the model, we also generate OPC'ed mask using MOSAIC~\cite{OPC-DAC2014-Gao}.
We apply the lithography simulator from~\cite{OPC-ICCAD2013-Banerjee} to obtain the golden aerial and resist images.
Different from previous art DOINN~\cite{DAC22-DOINN-Yang}, we directly use the highest resolution,
\ie 4$\mu m^2$ tiles are converted to $2000 \times 2000$-pixels images.

\subsubsection{ISPD-2019}
ISPD 2019 initial detailed routing contest~\cite{ispd2019-benchmark} provides designs synthesized with commercial placement and routing tools.
We randomly choose 4$\mu m^2$ tiles from ISPD-2019 designs for a fair comparison.
Unlike DOINN only tests its model on ISPD via layers, we choose both via layers and metal layers.
\begin{itemize}
  \item ISPD-2019 via layers: we apply the high-resolution settings from DOINN, 10K training set and 10K testing set with  4$\mu m^2$ tiles converted to
  $2000 \times 2000$ images.
  \item ISPD-2019 metal layers: we randomly select 1K metal patterns for training and 300 testing patterns.
  All metal patterns will be cropped into 4$\mu m^2$ tiles and converted to $2000\times 2000$ images.
\end{itemize}
The ground truth for ISPD metal and via layers are generated by commercial tool Mentor Calibre~\cite{TOOL-calibre} with $\lambda = 193 nm, N\!A=1.35$.

\begin{table}[tb!]
	\centering
	\caption{Details of the Dataset.}
	\label{tab:data}
	\setlength{\tabcolsep}{3pt}
	\renewcommand{\arraystretch}{.9}
	\begin{tabular}{l|l|cccc}
		\toprule
		\multicolumn{1}{c|}{Dataset}     & Alias &Train  & Test  & Tile Size  & Litho Engine \\ \midrule
		ICCAD-2013  & B1      & 4875  & 10    & 4$\mu m^2$ & Lithosim \cite{OPC-ICCAD2013-Banerjee}  \\
	  ICCAD-2013 (OPC) & B1opc & -     & 10    & 4$\mu m^2$ & Lithosim \cite{OPC-ICCAD2013-Banerjee}  \\
		ISPD-2019-metal & B2m     & 1000  & 300 & 4$\mu m^2$ & Calibre \cite{TOOL-calibre}  \\
		ISPD-2019-via   & B2v     & 10000 & 10000 & 4$\mu m^2$ & Calibre \cite{TOOL-calibre}  \\ \bottomrule
	\end{tabular}
\end{table}




\subsection{Results Comparison with State-of-the-Art}
\subsubsection{Model performance}

\input{doc/res/resist}
\input{doc/res/res_all.tex}

\begin{figure}[tb!]
  \centering
  \includegraphics[width=.8\linewidth]{bar-graph}
  \caption{
    Runtime comparison with SOTA.
  }
  \label{fig:runtime}
\end{figure}

We first compare Nitho with TEMPO~\cite{ISPD-2020-TEMPO}, DOINN~\cite{DAC22-DOINN-Yang}, which are SOTA models in aerial and resist stage.
Details are in \Cref{tab:results}, where ``MSE'', ``ME'', ``PSNR'', ``mPA'' and ``mIOU'' are introduced in \Cref{sec:prelim}.
We also merge the B2m and B2v datasets to be ``B2m$+$B2v'' dataset to evaluate our models' performance on larger distribution case.

As can be seen from \Cref{tab:results}, Nitho outperforms SOTA image learning-based models in both aerial and resist stage.
In aerial stage, we achieve 69$\times$ and 102$\times$ smaller MSE than DOINN and TEMPO, with 8$\times$, 15$\times$ smaller ME.
We achieve an average of 48.94dB PSNR compared with 39.26dB of DOINN and 27.10dB of TEMPO.
The results demonstrate the superior advantage of Nitho on high-resolution aerial image generation over previous SOTA.
In resist stage, we achieve above 99\% mPA and mIOU in all datasets with 99.45\%, 99.23\% average mPA and mIOU: 1\% better mPA and 2\% better mIOU than SOTA DOINN.
The improvement can be attributed to the accurate optical kernel regression, which generates high precision aerial images with richer information.
From the results on ``B2m+B2v'' dataset, we find that Nitho's high accuracy can still be maintained, while the performance of DOINN and TEMPO degrades badly in both aerial and resist stage.
It indicates that the image learning-based models have difficulty learning on more complex distributions, while Nitho can still accurately extract optical kernel information.
Result samples are visualized in \Cref{fig:vis_masks}.

\subsubsection{Generalization capability and robustness}
\input{doc/res/unseen.tex}
In \Cref{tab:unseen} and \Cref{fig:general}(b), we compare three models on out-of-distribution (OOD) datasets to verify the generalization performance.
Column ``train on'' means the model is trained on the referenced dataset but is tested on another dataset with a different mask shape and image distribution from the column ``test on''.
Row ``Drop'' denotes the difference of results between test results on the same distribution and OOD datasets,
with the direction of changes indicated by the up-down arrows $\uparrow, \downarrow$.
The results demonstrate that Nitho can still achieve remarkable accuracy when tested on OOD datasets,
while TEMPO and DOINN suffer strong performance degradation.

\Cref{fig:tnum} demonstrates that Nitho can use less training data to achieve better accuracy than previous art.
We list the average PSNR of B1, B2m, and B2v test sets in y-axis of \Cref{fig:tnum}, where the x-axis represents the training set percentage.
It can be concluded that when Nitho only uses 10\% of the training data, it is already more accurate than TEMPO and DOINN with 100\% of the training data.



\subsubsection{Model size and runtime comparison}
As shown in \Cref{tab:diff}, Nitho can use 31\% and 1\% parameters of DOINN and TEMPO to achieve better performance.
\Cref{fig:runtime} shows the runtime comparison of three models and traditional lithography simulators in terms of throughput ($\mu m^2/s$).
With a smaller model size and hierarchical GPU acceleration,
Nitho has 1.3$\times$ and 1.6$\times$ higher throughput than DOINN and TEMPO since no network inference is required.
Compared with traditional lithography simulators,
from which we obtain ground truth aerial and resist images,
Nitho achieves $\sim$90$\times$ speed up with less than 1\% accuracy loss.



\subsection{Ablation Study}
We also conduct experiments to verify our design on kernel dimensions and effectiveness of position encoding.
\subsubsection{Kernel dimensions with resolution limit}
In \Cref{fig:kw}, the x-axis is width/height of the kernel, \ie $(m, n)$ of $\mathcal{K} \in \mathbb{C}^{r \times n \times m}$, and $m = n$ in our settings.
The y-axis is PSNR on the corresponding dataset.
We can observe that as the kernel width/height increase,
the curve flattens out and stops growing.
This indicates that there is an optimal dimension,
and the network can not learn more information after the optimal dimension due to the \textit{resolution limit}.
The experimental results are consistent with the given optimal dimension in \Cref{eq:kernel_mn}.
On the other hand, if $\lambda$ and $N\!A$ of the lithography system are unknown, the optimal dimension can also be obtained through experiments by hyperparameter search.

\subsubsection{Positional encoding}
\input{doc/res/pe.tex}
% \subsubsection{Unseen data}
\Cref{tab:pe} illustrates that positional encoding is extremely critical to Nitho.
We first remove the positional encoding layer by using a simple Gaussian matrix.
As shown in the first line of \Cref{tab:pe}, PSNR in test set B1 goes down to 25.33 with worse MSE and ME than TEMPO and DOINN.
Then we apply NeRF's PE in \Cref{eq:nerf_pe} and our RFF PE in \Cref{eq:cplx_gaussian_pe},
we get $\sim$2$\times$ PSNR of 48.83 and 50.75 compared with Nitho without PE.




\begin{figure}[tb!]
  \centering
  \subfloat[]{\includegraphics[width=.47\linewidth]{tnum_wrapper} \label{fig:tnum}}
  \subfloat[]{\includegraphics[width=.47\linewidth]{kwh} \label{fig:kw}}
  \caption{
    (a) Comparison with SOTA on smaller training sets.
    (b) Ablation study on kernel size on different datasets.
  }
  \label{fig:kw_tnum}
\end{figure}


