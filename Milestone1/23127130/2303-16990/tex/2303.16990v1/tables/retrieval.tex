\begin{table}[t]
    \tablestyle{2pt}{1.05}
    \centering
    %\resizebox{1\columnwidth}{!}{
    \begin{tabular}{@{}l|c|c|cccc@{}}
    	\toprule
    	\multicolumn{3}{c}{} & \multicolumn{4}{c}{YouCook2} \\ 
    	\cmidrule(lr){4-7} 
    	Method &Modality &Visual Backbone & R@1 & R@5  & R@10 & Med. R  \\ 
    	\midrule
    	CoMMA* \cite{tan2021look}& VT& S3D-g& 1.2 & 5.9 & 9.7 & 120 \\
    	MMV \cite{alayrac2020self} &VAT& TSM-50x2 & 11.7 & 33.4 & 45.4 & 13 \\
    	MCN \cite{chen2021multimodal}&VAT& R152+RX101 & 18.1 & 35.5 & 45.2 & 12 \\
    	AVLNet \cite{rouditchenko2020avlnet} &VAT& R152+RX101 & 19.9 & 36.1 & 44.3 & 16 \\
    	MIL-NCE \cite{miech2020end}&VT&S3D-g & 15.1 & 38.0 & 51.2 & 10 \\
    	Ours&VAT&S3D-g & 13.1 & 35.2 & 47.3 & 12  \\
    	\bottomrule
    \end{tabular}
    %}
    \vspace{+0.3cm}
    \caption{\textbf{Text-to-Video retrieval on YouCook2}. Spatial-focused model CoMMA is not trained to learn temporal representations, which results in lower performance on retrieval. Our model is trained on much less computing resources compared with MIL-NCE, but achieved decent performance.
    \label{tab:retrieval}
    %
    }
    %\vspace{-0.8cm}
\end{table} 