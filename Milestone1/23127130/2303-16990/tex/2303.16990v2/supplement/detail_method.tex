\section{Method details}
\label{method_detail}


\subsection{Sinkhorn optimal transport}
\label{sinkhorn}

To acquire the optimal assignment from word features to video frames, an assignment matrix $\mathbf{Q}$ is computed from each video and ASR pair as shown in Figure \ref{fig:pipeline}(a). This cross-model optimal transport mechanism is applied to assignment $\mathbf{Q}$ from the projected cross-model similarity $\mathbf{P}$ between word tokens and each video frame, where $\mathbf{P}=g(\mathcal{S}) \bigotimes f(\mathcal{V})^\top \in \mathbb{R}^{K\times U}$.  
To compute the assignment matrix, the text and video projection layers from the global representation in Figure \ref{fig:pipeline}(c) are used to project multimodal features into a common space for feature similarity calculation.
To ensure that the word-to-frame assignment contains more diversity instead of just saturated assignments to a single video frame, we add a constraint that requires label assignments to be equally distributed across various video frames representing diverse object/action concepts. This is achieved by restricting $\mathbf{Q_v}$ to a \textit{transportation polytope} $\mathcal{Q}_v$: %where $\mathbf{Q} \mathbbm{1} = \frac{1}{K} \mathbbm{1}$:
%work on minibatches by restricting the transportation polytope to the minibatch:
%\vspace{-3mm}
\begin{equation}
  \resizebox{0.8\linewidth}{!}{$\mathcal{Q} = \left \{\mathbf{Q}\in\mathbb{R}_+^{U\times K} ~|~\mathbf{Q} \mathbf{1}_K = \frac{1}{U} \mathbf{1}_U, \mathbf{Q}^\top \mathbf{1}_U = \frac{1}{K} \mathbf{1}_K \right \}$},
  \label{eq:equal}
\end{equation}
which enforces the soft-assignment distribution $\mathbf{Q}$ to assign an equal marginal probability to each of the $U$ frames instead of converging to a single frame. The vector $\mathbf{1}_U$ represents one vector with dimension $U\times1$.

The next goal is to enforce this \textit{transportation polytope} $\mathcal{Q}$. %The projection $\mathbf{C}$ that is used to compute $\mathbf{P}$ is also shared across different batches and different modalities. This further allows the proposed multimodal clustering network to scale to large multimodal datasets and to perform clustering jointly across modalities. 
A solution for $\mathbf{Q}$ is now computed using the optimal transport Sinkhorn-Knopp algorithm~\citep{caron2020unsupervised,cuturi2013sinkhorn} as shown in Figure ~\ref{fig:pipeline}(b). The Sinkhorn-Knopp algorithm also normalizes the distribution of $\mathbf{P}$ as: 
\begin{equation}
\label{eq:qstar}
\resizebox{0.5\linewidth}{!}{$
   \mathbf{Q}= \text{Diag}(\mathbf{\alpha}) \exp\left(\frac{ \mathbf{P}}{\varepsilon} \right) \text{Diag}(\mathbf{\beta}),
   $}
\end{equation}
where $\mathbf{\alpha}$ and $\mathbf{\beta}$ are scaling vectors that restrict $\mathbf{Q}$ to have a uniform distribution across region assignment. $\varepsilon$ is a parameter that controls the smoothness of the mapping \citep{caron2020unsupervised}. %Pseudo-labels  $\mathbf{Q_a}$ and $\mathbf{Q_t}$ for the audio and text domains, are similarly computed using this procedure.

%Given that it is unlikely for semantic patterns to be always consistent across different modalities, we use soft labels to represent the probability distribution over labels instead of assigning various feature representations to a single label class, similar to \citep{caron2020unsupervised}. 
%We do this by preserving the soft pseudo-label $\mathbf{Q}^*$, which of computing a single hard label. 
%All the computations involved in this algorithm are matrix multiplications and hence can be efficiently implemented on GPUs. This additionally makes the technique scalable to large multimodal data compared to traditional k-means clustering \citep{arthur2006k}.
The $T$ frames are then selected by the corresponding assignment $\mathbf{Q}$ from the frames with top $T$  aggregated similarity sum over each word for further training. Note that the selection part $\mathbf{P}$ is from a trainable projection. While acquiring a better word-to-region projection during training, we hypothesize that the frame selection also benefits. The respective frame selection strategy is evaluated in Table~\ref{tab:frame_ablations}. 