\section{Framework} \label{sec:framework}

In this section, we describe the decentralized framework for detection of cyber attacks and faults to on-board positioning sensors and the recovery method by utilizing RSSI measurements from nearby agents (i.e., mobile landmarks) in the MAS to replace the compromised on-board sensor. The block diagram in Fig.~\ref{fig:architecture} summarizes the proposed framework followed by each agent in the swarm to recover from localization sensor/fault to maintain control performance within the formation. As an agent $i$ discovers anomalous behavior to its localization sensors, it switches to a recovery mode which relies on noisy RSSI measurements from nearby uncompromised agents to replace the unreliable on-board sensor measurements. Then, the agent adaptively updates its KF to accommodate the unknown RSSI-based position measurement covariance for improved control performance.
\begin{figure}[ht!]
\vspace{-5pt}
\centering
\includegraphics[width=0.44\textwidth]{Figures/ACC23_Architecture.png}
\vspace{-7pt}
\caption{Overall control architecture followed by each agent $i \in \mathcal{V}$ to remain resilient from localization (i.e., position) sensor attacks and/or faults.}
\label{fig:architecture}
\vspace{-13pt}
\end{figure}
% \begin{figure}[!b]
% \centering
% \includegraphics[width=0.48\textwidth]{Figures/ACC23_Architecture.png}
% \vspace{-17pt}
% \caption{Overall control architecture followed by each agent $i \in \mathcal{V}$ to remain resilient from localization (i.e., position) sensor attacks and/or faults.}
% \label{fig:architecture}
% \vspace{-8pt}
% \end{figure}

\subsection{Anomaly Detection} \label{sec:Detection}

Each agent $i \in \mathcal{V}$ in our proposed framework monitors for inconsistent behavior of both its on-board position sensor and position information from nearby agents. Let us define the {\em{measurement residual}} on an agent $i$:
\begin{equation} \label{eq:residual}
    \bm{\mathrm{r}}_i^{(k)} = \widetilde{\bm{\mathrm{y}}}_{i}^{(k)} - \bm{\mathrm{C}} \hat{\bm{\mathrm{x}}}^{(k|k-1)}_{i}
\end{equation}
as the difference between the measurements and the prediction. We can model the measurement residual covariance matrix (assuming the KF has converged to steady state) during attack-free conditions as $\bm{\Sigma}_i = \bm{\mathrm{C}}\bm{\mathrm{P}}_i^{(\infty)} \bm{\mathrm{C}}^{\mathsf{T}} + \bm{\mathrm{R}}$ where the steady state estimation covariance $\bm{\mathrm{P}}_i^{(\infty)}$ is found from the discrete Riccati equation.
% In nominal conditions (i.e., in the absence of sensor attacks and faults), each $s$th measurement residual element $r_{i,s}^{(k)}$ on an agent $i$ is Normally distributed with parameters:
% \begin{equation} \label{eq:individual_residuals_exp}
%     \E[r_{i,s}] = 0, \text{ } \;\;\; \V[r_{i,s}] = \sigma_{i,s}^2,
% \end{equation}
% where $\sigma_{i,s}^2$ is the $s$th diagonal element of the measurement residual covariance matrix \eqref{eq:Residual_Covariance}. 
Each agent $i$ monitors its $D$-dimensional position sensor measurements for anomalies by way of the commonly-used chi-squared scheme, which produces a scalar quadratic on-board \textit{test measure} computed by
\begin{equation} \label{eq:chisquare_testmeasure}
    \mathrm{z}_i^{(k)} = \big( \bm{\mathrm{r}}_{i,[1:D]}^{(k)} \big)^{\mathsf{T}} \bar{\bm{\Sigma}}_i^{-1} \hspace{1.5pt} \bm{\mathrm{r}}_{i,[1:D]}^{(k)}
\end{equation}
which has an expected chi-squared distribution $\mathrm{z}_i^{(k)} \sim \chi^2(D)$ with $D$ degrees of freedom. The matrix $\bar{\bm{\Sigma}}_i \in \R^{D \times D}$ represents the position sensor measurement covariance block within $\bm{\Sigma}_i =${\scriptsize \setlength\arraycolsep{2pt} $ \begin{bmatrix} \bar{\bm{\Sigma}}_i & * \\ *^{\mathsf{T}} & \breve{\bm{\Sigma}}_i \end{bmatrix}$}
% \begin{equation} \label{eq:pos_covariance}
%     \bm{\Sigma}_i = \begin{bmatrix} \bar{\bm{\Sigma}}_i & * \\[4pt] *^{\mathsf{T}} & \breve{\bm{\Sigma}}_i \end{bmatrix}.
% \end{equation}
where $ \breve{\bm{\Sigma}}_i$ represents the non-position covariance block corresponding to the remaining sensors.



Similarly, each agent monitors for expected behavior of nearby agents according to the control consensus model in \eqref{eq:consensus_control} that is followed by all agents. Each agent $i$ receives both state $\hat{\bm{\mathrm{x}}}^{(k)}_j$ and control input $\bm{\mathrm{u}}^{(k)}_j$ information from any agent $j \in \mathcal{V} \setminus \{i\}$. State evolution predictions $\hat{\bm{\mathrm{x}}}_{ij}^{(k+1)} \in \R^n$ for an agent $j$ are given as:
\begin{equation} \label{eq:neighbor_predict}
    \hat{\bm{\mathrm{x}}}_{ij}^{(k+1)} = \bm{\mathrm{A}} \hat{\bm{\mathrm{x}}}_{j}^{(k)} + \bm{\mathrm{B}} \bm{\mathrm{u}}_{j}^{(k)}
\end{equation}
which is computed by an agent $i$. At every time iteration $k \in \N$, an agent $i$ computes the \textit{inter-agent residual} \cite{Paul_TRO},
\begin{equation} \label{eq:prediction_residual}
    \bm{\mathrm{r}}_{ij}^{(k)} = \hat{\bm{\mathrm{x}}}_j^{(k)} - \hat{\bm{\mathrm{x}}}_{ij}^{(k)} \in \R^n.
\end{equation}
to monitor for consistent behavior of nearby agents.

If the agent $j$ is behaving in a nominal fashion, each inter-agent residual element $q = 1,\dots,n$ follows the distribution $\mathrm{r}_{ij,q}^{(k)} \sim \mathcal{N}(0,\sigma_{ij,q}^2)$ given $\sigma_{ij,q}^2 = \sum_{s=1}^{N_{\text{s}}} \big( \mathrm{K}_{(q,s)} \sigma_{j,s} \big)^2$ where
% \begin{equation} \label{eq:update_residual_distribution}
%     \E[r_{ij,q}] = 0, \;\;\;\; \mathrm{Var}[r_{ij,q}] = \sum_{s=1}^{N_s} \Big( K_{(q,s)} \sigma_{z,s} \Big)^2 ,
% \end{equation}
$\mathrm{K}_{(q,s)}$ represents the element of the $q$th row and $s$th column of the Kalman gain $\bm{\mathrm{K}}$, and $\sigma^2_{j,s}$ is the $s$th diagonal element in the known measurement covariance matrix $\bm{\Sigma}_j = \bm{\Sigma}_i$ \cite{Paul_TRO}. For ease, we construct the inter-agent covariance matrix $\bm{\Sigma}_{ij} \in \R^{n \times n}$ with diagonal elements equal to $\sigma^2_{ij,q}$, i.e. $\bm{\Sigma}_{ij} = \mathrm{diag}(\sigma^2_{ij,1},\dots,\sigma^2_{ij,n})$. In a similar fashion to the on-board test measure in \eqref{eq:chisquare_testmeasure}, the \textit{inter-agent test measure} is computed as 
\begin{equation} \label{eq:interagent_testmeasure}
    \mathrm{z}_{ij}^{(k)} = \big( \bm{\mathrm{r}}_{ij,[1:D]}^{(k)} \big)^{\mathsf{T}} \bar{\bm{\Sigma}}_{ij}^{-1} \hspace{1.5pt} \bm{\mathrm{r}}_{ij,[1:D]}^{(k)}
\end{equation}
by an agent $i$ to monitor for consistency of an agent $j$ where $\bar{\bm{\Sigma}}_{ij} \in \R^{D \times D}$ represents the inter-agent residual covariance block for position within $\bm{\Sigma}_{ij} =${\scriptsize \setlength\arraycolsep{2pt} $ \begin{bmatrix} \bar{\bm{\Sigma}}_{ij} & * \\[1pt] *^{\mathsf{T}} & \breve{\bm{\Sigma}}_{ij} \end{bmatrix}$}.

To monitor for expected behavior of either test measure in \eqref{eq:chisquare_testmeasure} and \eqref{eq:interagent_testmeasure}, simply denoted as $\mathrm{z}^{(k)}$, an agent $i$ creates an alarm-based mechanism when the test measure exceeds a user-defined threshold $\tau$ which follows:
\begin{equation} \label{eq:thresholding_alarm}
\begin{split}
    \zeta^{(k)} = \left\{ \begin{array}{ll}
	1, & \text{if } \mathrm{z}^{(k)} > \tau, \\
    0, & \text{if } \mathrm{z}^{(k)} \leq \tau.
    \end{array} \right.
\end{split}
\end{equation} 

The threshold parameter $\tau \in \R_{>0}$ is tuned to satisfy a user-defined desired false alarm rate $a^{\mathrm{des}} \in (0,1)$.
\begin{lemma}[Threshold] \label{prop:BD_threshold}
    Let us assume that the sensors on agent $i$ are free of cyber attacks and faults while considering the alarm procedure in \eqref{eq:thresholding_alarm} for the test measure $\mathrm{z}^{(k)} \sim \chi^2(D)$ with a threshold $\tau \in \R_{>0}$. To tune for a desired false alarm rate $a^{\mathrm{des}} \in (0,1)$, the threshold $\tau$ is found by
\begin{equation} \label{eq:BD_threshold}
    \tau = 2\Gamma^{-1} \Big( 1 - a^{\mathrm{des}}, \frac{D}{2} \Big)
\end{equation}
to achieve a desired alarm rate, where $\Gamma^{-1}(\cdot,\cdot)$ is the \textit{inverse regularized lower incomplete gamma function} \cite{statsbook}.
\end{lemma}

Formally, the probability $\PP(\cdot)$ that the test measure exceeds the user-defined threshold is described as $\PP(\mathrm{z}^{(k)} > \tau) \approx a^{\mathrm{des}}$. Each agent $i$ updates its alarm rate estimate $\hat{a}^{(k)}$ with the runtime update $\hat{a}^{(k)} = \hat{a}^{(k-1)} + \frac{\zeta^{(k)} - \hat{a}^{(k-1)}}{\ell}$
% \begin{equation} \label{eq:alarm_rate_estimate}
%     \hat{A}^{(k)} = \hat{A}^{(k-1)} + \frac{\zeta^{(k)} - \hat{A}^{(k-1)}}{\ell}
% \end{equation}
where $\hat{a}^{(0)} = a^{\mathrm{des}}$, $\ell > \N_+$, and the alarm rate estimate can be approximated to a Normal distribution with a variance that shares properties of the exponential moving average \cite{moving_average}.

\begin{corollary}[Detection Bounds] \label{cor:detection_bounds}
    Given the tuned threshold \eqref{eq:BD_threshold} for a desired false alarm rate $a^{\mathrm{des}} \in (0,1)$, the position sensor measurements are behaving as expected with a level of significance $\alpha \in (0,1)$ if the estimated alarm rate $\hat{a}^{(k)} \in [0,1]$ satisfies the detection bounds $\hat{a}^{(k)} \in [\Tau_-, \Tau_+]$.
%    \begin{equation} \label{eq:BD_magnitude_bounds}
%        \Upsilon_- \leq \hat{A}^{(k)}_i \leq \Upsilon_+.
%    \end{equation}
\end{corollary}

\begin{proof}
    We construct confidence intervals with a level of significance $\alpha \in (0,1)$ for a Normally distributed random variable with accompanying z-score $\big| \Phi^{-1} \big( \frac{\alpha}{2} \big) \big|$, that provide the detection bounds
    \begin{equation} \label{eq:BD_magnitude_bounds2}
        \Tau_{\pm} = a^{\mathrm{des}} \pm \Big| \Phi^{-1} \Big( \frac{\alpha}{2} \Big) \Big| \sqrt{\frac{ a^{\mathrm{des}} (1-a^{\mathrm{des}})}{2\ell -1}}
    \end{equation}
    where alarm rate estimates that go beyond these bounds are exhibiting anomalous behavior, thus concluding the proof.
\end{proof}

To summarize Corollary \ref{cor:detection_bounds}, when the estimated alarm rate $\hat{a}^{(k)}_i$ for detection of inconsistencies to the on-board test measure $\mathrm{z}_i^{(k)}$ no longer satisfies the detection bounds $\hat{a}_i^{(k)} \not\in [\Tau_-, \Tau_+]$,
% \begin{equation} \label{eq:anomaly_detect}
%     \hat{A}^{(k)} \not\in [\Omega_-, \Omega_+]  \longrightarrow  \textit{Anomaly Detect},
% \end{equation} 
agent $i$ detects that a cyber attack or fault to its positioning sensors is present.
In the case of inter-agent monitoring where $\hat{a}_{ij}^{(k)} \not\in [\Tau_-, \Tau_+]$, an agent $i$ deems an agent $j$ compromised and places the agent into a compromised agent set $\mathcal{V}_i^C \subset \mathcal{V}$, i.e., $j \in \mathcal{V}_i^C$.


\subsection{RSSI-based Position Measurements} \label{sec:Multilateration}

In this subsection, we discuss our localization method that leverages the modeled communication channel described in Section~\ref{sec:Communication_model} to replace the compromised/faulty sensor providing position measurements. Our proposed framework is performed by any compromised agent $i$ that utilizes noisy measured RSSI and received position information from uncompromised neighboring agent's communication broadcasts to compute RSSI-based position measurements. 
%and the weighted least squares (WLS) algorithm based on estimated distances to neighboring agents
%We present RSSI-based multilateration in MASs within $2$-dimensional environments (i.e., $D=2$).


Once an agent $i$ detects anomalous position sensor behavior, the agent no longer relies on the on-board position sensor and begins to measure RSSI from any trustworthy nearby agents. An agent $i$ utilizes estimated distances from RSSI measurements to each uncompromised mobile agent $m$ in the set $\mathcal{M}_i \subset \mathcal{C}_i \setminus \{ \mathcal{V}_i^C \cup i \}$ where the set $\mathcal{M}_i = \{ 1, 2, \dots, M \}$ represents the $M$ in-range uncompromised mobile agents (i.e., mobile landmarks). From the known communication model, the observed path loss $PL_{im}^{(k)}$ (in dB) by an agent $i$ of an agent $m \in \mathcal{M}_i$ from RSSI $P_{im,[\text{rx}]}^{(k)}$ (in dBm) is:
\begin{equation} \label{eq:observed_PL}
    PL_{im}^{(k)} = P_{[\text{tx}]} - P_{im,[\text{rx}]}^{(k)}.
\end{equation}

The estimated distance $\hat{\mathrm{d}}_{im}^{(k)}$ based on received (i.e., measured) signal strength of an agent $m$ that is computed by a compromised agent $i$ follows:
\begin{equation} \label{eq:estimated_distance}
    \hat{\mathrm{d}}_{im}^{(k)} = 10^{ \frac{PL_{im}^{(k)} - PL(\mathrm{d}_0)}{10 \beta} }.
\end{equation}

The RSSI-based distance estimate to an agent $m$ are log-normal random variables \cite{tarrio2011weighted}, provided the assumption that the communication channel follows a log-normal shadowing path loss model in \eqref{eq:comm_model}, \eqref{eq:observed_PL}, and \eqref{eq:estimated_distance}. Consequently, the distance estimate in \eqref{eq:estimated_distance} is a biased estimate. We leverage the assumed log-normal distribution to compensate for the biased estimate. The log-normal random variables are described by the parameters $\mu_{\mathrm{d}}$ and $\sigma_{\mathrm{d}}$ \cite{tarrio2011weighted}:
\begin{equation} \label{eq:lognormal_parameters}
    \mu_{\mathrm{d}} = \ln \mathrm{d}_{im}^{(k)}, \;\;\;\;\; \sigma_{\mathrm{d}} = \frac{\sigma_{\Lambda} \ln 10}{10 \beta}
\end{equation}
with an RSSI distance estimate expectation that follows
\begin{equation} \label{eq:exp_RSSI_meas}
    \E \big[\hat{\mathrm{d}}_{im}^{(k)} \big] = \exp \Big\{\mu_{\mathrm{d}} + \frac{\sigma_{\mathrm{d}}^2}{2} \Big\}
\end{equation}
and the expected estimation bias
\begin{equation} \label{eq:error_bias}
    \mathrm{e}_{im,\mathrm{e}}^{(k)} = \E \big[\hat{\mathrm{d}}_{im}^{(k)} \big] - \mathrm{d}_{im}^{(k)} \in \R_{>0}
\end{equation}
defined as the difference between the RSSI-based distance estimate expectation $\E \big[\hat{\mathrm{d}}_{im}^{(k)} \big]$ and the true distance $\mathrm{d}_{im}^{(k)}$. Given that the true distance $\mathrm{d}_{im}^{(k)}$ is unknown in \eqref{eq:lognormal_parameters}, an agent $i$ leverages the distance $\hat{\mathrm{d}}_{im}^{(k)} = \| \hat{\bm{\mathrm{p}}}_{i}^{(k)} - \hat{\bm{\mathrm{p}}}_{m}^{(k)} \|$ which is the estimated distance between agents $i$ and $m$ from the position estimate of agent $i$ and the received position estimate from an agent $m$. We can rewrite equation \eqref{eq:estimated_distance} to include compensation for the expected estimation bias \eqref{eq:error_bias} by
\begin{equation} \label{eq:estimated_distance2}
    \hat{\mathrm{d}}_{im}^{(k)} = 10^{ \frac{PL_{im}^{(k)} - PL(\mathrm{d}_0)}{10 \beta} } - \mathrm{e}_{im,\mathrm{d}}^{(k)}.
\end{equation}

Each $m$th agent's estimated distances are leveraged with their corresponding received positions $\hat{\bm{\mathrm{p}}}_{m}^{(k)} = [\hat{\mathrm{p}}_{m,\mathrm{x}}^{(k)} \; \hat{\mathrm{p}}_{m,\mathrm{y}}^{(k)}]^{\mathsf{T}}$ to find an optimal position $\bar{\bm{\mathrm{p}}}_i^{(k)} = [\bar{\mathrm{p}}_{i,\mathrm{x}}^{(k)} \; \bar{\mathrm{p}}_{i,\mathrm{y}}^{(k)}]^{\mathsf{T}}$ by minimizing the distance error residuals $\epsilon_m \in \R$ where $ m = 1,\dots,M$ using the following set of equations:
%An agent $i$ utilizes the estimated distances $\hat{d}_{ij}^{(k)}$ from RSSI measurements in \eqref{eq:estimated_distance} to each agent $j \in \mathcal{C}_i$ along with their received position information $\hat{\bm{p}}_{j}^{(k)} = [\hat{p}_{j,\mathrm{x}}^{(k)} \; \hat{p}_{j,\mathrm{y}}^{(k)}]^{\mathsf{T}}$ to perform multilateration for RSSI-based position measurements (in place of the compromised position sensor).
%An agent $i$ utilizes the received positions $\hat{\bm{p}}_{j}^{(k)} = [\hat{p}_{j,\mathrm{x}}^{(k)} \; \hat{p}_{j,\mathrm{y}}^{(k)}]^{\mathsf{T}}$ from the set of $M$ mobile landmarks (i.e., mobile agents within communication range) in the set $\mathcal{M} = \{ m_1, m_2, \dots, m_M \}$ with their estimated distances $\hat{d}_{ij}^{(k)}$ from RSSI measurements to each agent $j \in \mathcal{M}$ by
\begin{equation} \label{eq:distances_circles}
\begin{split}
    \left\{ \hspace{-5pt} \begin{array}{c}
	\hspace{-8pt} \hat{\mathrm{d}}_{i1}^{(k)} = \sqrt{ \big(\hat{\mathrm{p}}_{1,\mathrm{x}}^{(k)} - \bar{\mathrm{p}}_{i,\mathrm{x}}^{(k)} \big)^2 \hspace{-1pt} + \big(\hat{\mathrm{p}}_{1,\mathrm{y}}^{(k)} - \bar{\mathrm{p}}_{i,\mathrm{y}}^{(k)} \big)^2 + \epsilon_1} \\[2pt]
    \hspace{-8pt} \hat{\mathrm{d}}_{i2}^{(k)} = \sqrt{ \big(\hat{\mathrm{p}}_{2,\mathrm{x}}^{(k)} - \bar{\mathrm{p}}_{i,\mathrm{x}}^{(k)} \big)^2 \hspace{-1pt} + \big(\hat{\mathrm{p}}_{2,\mathrm{y}}^{(k)} - \bar{\mathrm{p}}_{i,\mathrm{y}}^{(k)} \big)^2 + \epsilon_2} \\[-2.5pt]
    \vdots \\
    \hat{\mathrm{d}}_{iM}^{(k)} = \sqrt{ \big(\hat{\mathrm{p}}_{M,\mathrm{x}}^{(k)} - \bar{\mathrm{p}}_{i,\mathrm{x}}^{(k)} \big)^2 \hspace{-1pt} + \big(\hat{\mathrm{p}}_{M,\mathrm{y}}^{(k)} - \bar{\mathrm{p}}_{i,\mathrm{y}}^{(k)} \big)^2 + \epsilon_M}
    \end{array} \right.
\end{split}
\end{equation} 
%where $\epsilon_m \in \R$, $ m = 1,\dots,M$ are distance error residuals.

Next, we subtract the first equation from the remaining equations to obtain a system of $M-1$ linear equations
\vspace{-.5pt}
\begin{equation} \label{eq:linear_equations}
    \bm{\Omega}_i \bar{\bm{\mathrm{p}}}_{i}^{(k)} = \bm{\phi}_i + \bm{\varepsilon}_i
\end{equation}
with $\bm{\Omega}_i \hspace{-.5pt} \in \hspace{-.5pt} \R^{(M-1) \times D}\hspace{-.5pt}$, $\bm{\phi}_i \hspace{-.5pt} \in \hspace{-.5pt} \R^{M-1} \hspace{-.5pt}$, and $\bm{\varepsilon}_i \hspace{-.5pt} \in \hspace{-.5pt} \R^{M-1} \hspace{-.5pt}$ found by:
\begin{equation} \label{eq:Omega}
    \hspace{-3pt} \bm{\Omega}_i = \begin{bmatrix} 2\big(\hat{\mathrm{p}}_{2,\mathrm{x}}^{(k)} - \hat{\mathrm{p}}_{1,\mathrm{x}}^{(k)} \big) & 2\big(\hat{\mathrm{p}}_{2,\mathrm{y}}^{(k)} - \hat{\mathrm{p}}_{1,\mathrm{y}}^{(k)} \big) \\[2pt] 2\big(\hat{\mathrm{p}}_{3,\mathrm{x}}^{(k)} - \hat{\mathrm{p}}_{1,\mathrm{x}}^{(k)} \big) & 2 \big(\hat{\mathrm{p}}_{3,\mathrm{y}}^{(k)} - \hat{\mathrm{p}}_{1,\mathrm{y}}^{(k)} \big) \\[-2.5pt] \vdots & \vdots \\[-1pt] 2 \big(\hat{\mathrm{p}}_{M,\mathrm{x}}^{(k)} - \hat{\mathrm{p}}_{1,\mathrm{x}}^{(k)} \big) & 2\big(\hat{\mathrm{p}}_{M,\mathrm{y}}^{(k)} - \hat{\mathrm{p}}_{1,\mathrm{y}}^{(k)} \big) \\ \end{bmatrix}
\end{equation}
\vspace{-1pt}
% \begin{equation} \label{eq:phi}
%     \bm{\phi}_i = \begin{bmatrix} \hat{p}_{2,\mathrm{x}}^2 - \hat{p}_{1,\mathrm{x}}^2 + \hat{p}_{2,\mathrm{y}}^2 - \hat{p}_{1,\mathrm{y}}^2 + \hat{d}_{i2}^2 - \hat{d}_{i1}^2 \\ \hat{p}_{3,\mathrm{x}}^2 - \hat{p}_{1,\mathrm{x}}^2 + \hat{p}_{3,\mathrm{y}}^2 - \hat{p}_{1,\mathrm{y}}^2 + \hat{d}_{i3}^2 - \hat{d}_{i1}^2 \\ \vdots \\ \hat{p}_{M,\mathrm{x}}^2 - \hat{p}_{1,\mathrm{x}}^2 + \hat{p}_{M,\mathrm{y}}^2 - \hat{p}_{1,\mathrm{y}}^2 + \hat{d}_{iM}^2 - \hat{d}_{i1}^2 \\ \end{bmatrix}
% \end{equation}
\begin{equation} \label{eq:phi}
    \hspace{-9pt} \bm{\phi}_i = \begin{bmatrix} \big(\hat{\mathrm{d}}_{i2}^{(k)}\big)^2 - \big(\hat{\mathrm{d}}_{i1}^{(k)}\big)^2 + \mathrm{b}_{2}^{(k)} - \mathrm{b}_{1}^{(k)} \\[2pt] \big(\hat{\mathrm{d}}_{i3}^{(k)}\big)^2 - \big(\hat{\mathrm{d}}_{i1}^{(k)}\big)^2 + \mathrm{b}_{3}^{(k)} - \mathrm{b}_{1}^{(k)} \\[-2pt] \vdots \\[-1pt] \big(\hat{\mathrm{d}}_{iM}^{(k)}\big)^2 - \big(\hat{\mathrm{d}}_{i1}^{(k)}\big)^2 + \mathrm{b}_{M}^{(k)} - \mathrm{b}_{1}^{(k)} \\ \end{bmatrix}
\end{equation}
\vspace{-1pt}
\begin{equation} \label{eq:epsilon}
    \hspace{-3pt} \bm{\varepsilon}_i = \begin{bmatrix} \epsilon_{2}-\epsilon_{1} & \epsilon_{3}-\epsilon_{1}  & \dots & \epsilon_{M}-\epsilon_{1} \end{bmatrix}^{\mathsf{T}}
\end{equation}
where $\mathrm{b}_{m}^{(k)} = \big(\hat{\mathrm{p}}_{m,\mathrm{x}}^{(k)}\big)^2 + \big( \hat{\mathrm{p}}_{m,\mathrm{y}}^{(k)}\big)^2$, $\forall m \in \mathcal{M}_i$. To optimize the position $\bar{\bm{\mathrm{p}}}_i^{(k)} \in \R^D$, we use the following objective function:
\begin{equation} \label{eq:sum_of_squares}
    J \big( \bar{\bm{\mathrm{p}}}_{i}^{(k)} \big) = {\arg \min} \bigg[ \Big\| \bm{\mathrm{W}}_i^{-\frac{1}{2}} \big( \bm{\Omega}_i \bar{\bm{\mathrm{p}}}_{i}^{(k)} - \bm{\phi}_i \big) \Big\|^2 \bigg]
\end{equation}
where $\bm{\mathrm{W}}_i \hspace{-.3pt} \in \hspace{-.3pt} \R^{(M-1) \times (M-1)}$ is a weighting matrix that minimizes the sum of squares of the distance error residual vector $\bm{\varepsilon}_i$. The optimal position is found by solving the objective function \eqref{eq:sum_of_squares} with a weighted least squares (WLS) estimator:
\begin{equation} \label{eq:WLS}
    \bar{\bm{\mathrm{y}}}_{i,[1:D]}^{(k)} = \bar{\bm{\mathrm{p}}}_i^{(k)} = ( \bm{\Omega}_i^{\mathsf{T}} \bm{\mathrm{W}}_i^{-1} \bm{\Omega}_i )^{-1} \bm{\Omega}_i^{\mathsf{T}} \bm{\mathrm{W}}_i^{-1} \bm{\phi}_i.
\end{equation}

This optimal position \eqref{eq:WLS} is equal to the compromised agent $i$'s RSSI-based position measurement $\bar{\bm{\mathrm{y}}}_{i,[1:D]}^{(k)}$.

\begin{proposition}
    An agent $i$ can compute a feasible solution for an RSSI-based position measurement \eqref{eq:WLS} if the number of nearby uncompromised mobile agents $M$ satisfies $M \geq D + 1$.
\end{proposition}

\begin{proof}
    Given the dimensions of the matrix $\bm{\Omega}_i \hspace{-.5pt} \in \hspace{-.5pt} \R^{(M-1) \times D}\hspace{-.5pt}$ and the resulting estimated position vector $\bar{\bm{\mathrm{p}}}_i^{(k)} \in \R^D$ within \eqref{eq:WLS}, we have a trivial proof, as under-determined systems have an infinite number of solutions due to linear dependency, i.e., $\mathrm{rank} \hspace{1pt}(\bm{\Omega}_i) < D$.
\end{proof}

% \begin{remark}
%     For an agent $i$ to compute a single feasible solution for an RSSI-based position measurement (from \eqref{eq:linear_equations} and \eqref{eq:WLS}), the number of nearby uncompromised mobile agents $M$ must satisfy $M \geq D + 1$. This is because under-determined systems have an infinite number of solutions.
% \end{remark}

Next, the weighting matrix $\bm{\mathrm{W}}_i$ is characterized to compute an optimal RSSI-based measurement error from \eqref{eq:WLS}.

%\NB{what are the assumptions on the number of compromised vehicles? What you are describing will probably not work if you have more than half vehicles compromised because RSSI is relative!}

% A weight least squares objective function can be expressed as:
% \begin{equation} \label{eq:WLS_OF}
%     J(\bm{y}_{i,[1:2]}) = (\bm{\Omega}_i \bm{y}_{i,[1:2]} - \bm{\phi}_i)^{\mathsf{T}} \bm{W}_i (\bm{\Omega}_i \bm{y}_{i,[1:2]} - \bm{\phi}_i)
% \end{equation}
% where $\bm{W}_i \in \R^{(M-1) \times (M-1)}$ is a weighting matrix. Then, the compromised agent's RSSI-based position measurement is found by the weighted least squares estimator:
% \begin{equation} \label{eq:WLS}
%     \bm{y}_{i,[1:2]} = ( \bm{\Omega}_i^{\mathsf{T}} \bm{W}_i^{-1} \bm{\Omega}_i )^{-1} \bm{\Omega}_i^{\mathsf{T}} \bm{W}_i^{-1} \bm{\phi}_i,
% \end{equation}


\subsection{Weighting Matrix} \label{sec:Hyperbolic}

To compute the weighting matrix, we first assume that the RSSI-based estimated distances $\hat{\mathrm{d}}_{im}^{(k)}$ from each uncompromised agent $m \in \mathcal{M}_i$ are independent from each other. Thus, the weighting matrix $\bm{\mathrm{W}}_i$ is the covariance of the vector $\bm{\phi}_i$ that can be calculated by a hyperbolic weighting matrix with each $(p_{\mathrm{w}},q_{\mathrm{w}})$th element (i.e., $\mathrm{w}_{p_{\mathrm{w}}q_{\mathrm{w}}}$) given as \cite{tarrio2011weighted}:
\begin{equation} \label{eq:weighting_matrix}
    \mathrm{w}_{p_{\mathrm{w}}q_{\mathrm{w}}} \hspace{-2pt}=\hspace{-1pt} \left\{ \hspace{-4pt} \begin{array}{ll}
	\V \hspace{-.5pt} \Big[ \hspace{-1.5pt}\big( \hat{\mathrm{d}}_{i1}^{(k)} \big)^2 \hspace{-1pt}\Big] \hspace{-1.3pt} + \hspace{-1pt} \V \hspace{-.5pt} \Big[ \hspace{-1.5pt}\big( \hat{\mathrm{d}}_{i{(p_{\mathrm{w}}+1)}}^{(k)} \big)^2 \hspace{-1pt}\Big] & \hspace{-3.5pt}\text{if } p_{\mathrm{w}} \hspace{-1pt} = \hspace{-1pt} q_{\mathrm{w}} \\[5pt]
    \V \hspace{-.5pt} \Big[ \hspace{-1.5pt}\big(\hat{\mathrm{d}}_{i1}^{(k)} \big)^2 \hspace{-1pt}\Big] & \hspace{-3.5pt}\text{if } p_{\mathrm{w}} \hspace{-1pt} \ne \hspace{-1pt} q_{\mathrm{w}}
    \end{array} \right.
\end{equation}
where the elements of the weighting matrix are inter-agent RSSI-based estimation variances $\V[\cdot]$. Given the log-normal shadowing path loss communication model in \eqref{eq:comm_model}, \eqref{eq:observed_PL}, and \eqref{eq:estimated_distance}, the RSSI-based estimated distances $\hat{\mathrm{d}}_{im}^{(k)}$ in \eqref{eq:estimated_distance2} are log-normal random variables where we can leverage the modeled variances. The estimation variances are computed by \cite{tarrio2011weighted}:
\begin{equation} \label{eq:estimated_variance}
    \V \big[ \big( \hat{\mathrm{d}}_{im}^{(k)} \big)^2 \big] = \E\big[ \big( \hat{\mathrm{d}}_{im}^{(k)} \big)^4 \big] - \big( \E \big[ \big( \hat{\mathrm{d}}_{im}^{(k)} \big)^2 \big] \big)^2
\end{equation}
which are found from the $c$th moment of a given log-normal distributed variable that is represented as $\E[(\hat{\mathrm{d}}_{im})^c] = \exp \big\{ {c\mu_{\mathrm{d}} + \frac{c^2\sigma^2_{\mathrm{d}}}{2}} \big\}$ with log-normal parameters. 
Therefore, the second and fourth moments from \eqref{eq:estimated_variance} are:
\begin{align} \label{eq:cth_moment2}
    \E\big[ \big( \hat{\mathrm{d}}_{im}^{(k)} \big)^2 \big] &= \exp \big\{ {2\mu_{\mathrm{d}} + 2\sigma^2_{\mathrm{d}}} \big\}, \\ 
    \label{eq:cth_moment4} \E \big[ \big( \hat{\mathrm{d}}_{im}^{(k)} \big)^4 \big] &= \exp \big\{ {4\mu_{\mathrm{d}} + 8\sigma^2_{\mathrm{d}}} \big\},
\end{align}
then substituting \eqref{eq:cth_moment2} and \eqref{eq:cth_moment4} into \eqref{eq:estimated_variance}, we result in
\begin{equation} \label{eq:covariance_elements}
    \V \big[ \big( \hat{\mathrm{d}}_{im}^{(k)} \big)^2 \big] = \exp \Big\{ {4\mu_{\mathrm{d}}} \Big( \exp \big\{ {8\sigma_{\mathrm{d}}^2} \big\} - \exp \big\{ {4\sigma_{\mathrm{d}}^2} \big\} \Big) \Big\}
\end{equation}
which are used in the construction of the weighting matrix \eqref{eq:weighting_matrix} to compute the optimized RSSI-based position measurement $\bar{\bm{\mathrm{y}}}_{i,[1:D]}^{(k)}$ by using the WLS algorithm \eqref{eq:WLS}.



% However, the modeled noises that perturb the vector $\bm{\psi}_i$ are non-zero mean, subsequently resulting in a biased solution of \eqref{eq:WLS}. The expected value of each $p$th element, $p = 1,\dots,M-1$, of $\bm{\psi}_i$ is characterized as:
% \begin{align} \label{eq:expected_phi_vector}
%     \E[\psi_{i,p}] \hspace{-1pt} &= \hspace{-1pt} \E \Big[ \hspace{-1pt} \big(\hat{d}_{i(p+1)}^{(k)}\big)^2 \hspace{-1pt} - \big(\hat{d}_{im_1}^{(k)}\big)^2 \hspace{-1pt} + b_{(p+1)}^{(k)} - b_{m_1}^{(k)} \Big] \\
%     &= \hspace{-1pt} \E \Big[ \hspace{-1pt} \big(\hat{d}_{i(p+1)}^{(k)}\big)^2 \Big] \hspace{-2pt} - \hspace{-1pt} \E \Big[ \hspace{-1pt} \big(\hat{d}_{im_1}^{(k)}\big)^2 \Big] \hspace{-2pt} + \hspace{-1pt} \E \Big[ b_{(p+1)}^{(k)} \Big] \hspace{-2pt} - \hspace{-1pt} \E \Big[ b_{m_1}^{(k)} \Big] \nonumber
% \end{align}
% consisting of the expectation of RSSI-based estimated distances between agents and also the nearby agent's expected

% where the elements of the weighting matrix are inter-agent RSSI-based measurement variances that are computed by $\V[\hat{d}_{ij}^2] = \E[\hat{d}_{ij}^4] - \big( \E[ \hat{d}_{ij}^2] \big)^2$. Given the assumption that the communication channel follows a log-normal shadowing path loss model \eqref{eq:comm_model}, the RSSI-based measurements distances $\hat{d}_{ij}$ \eqref{eq:estimated_distance} are log-normal random variables that are defined as:
% \begin{equation} \label{eq:random_d_distribution}
% \begin{split}
%     \hat{d}_{ij} &= d_{ij} \cdot 10^{ \frac{\mathcal{N}(0,\sigma^2_{\Lambda})}{10 \beta} } = 10^{ \mathcal{N} \big( \log_{10}(d_{ij}), \frac{\sigma^2_{\Lambda}}{10 \beta} \big)} \\
%     &= \mathrm{e}^{ \mathcal{N} \big( \log_{10}(d_{ij}), \frac{\sigma^2_{\Lambda}}{10 \beta} \big) \ln10} = \mathrm{e}^{ \mathcal{N} \big( \ln d_{ij}, \frac{\sigma^2_{\Lambda} \ln10}{10 \beta} \big) },
% \end{split}
% \end{equation}
% where $d_{ij}$ is the true distance between the agent $i$ and a nearby agent $j$. However, the true distances between the agents are unknown, therefore agents leverage the estimated distance $\hat{d}_{ij} = \big\| \bm{p}_i^{(k)} - \bm{p}_j^{(k)} \big\|$ instead of $d_{ij}$ to approximate the RSSI-based measurement variance. That is, the variables $\hat{d}_{ij}$ are log-normal distributed random variables with parameters:
% \begin{equation} \label{eq:lognormal_parameters2}
%     \mu_d = \ln \hat{d}_{ij}, \;\;\;\;\;\; \sigma^2_d = \frac{\sigma^2_{\Lambda} \ln 10}{10 \beta}.
% \end{equation}
% The $q$th moment of a given log-normal distributed variable with parameters $\mu_d$ and $\sigma_d$ from \eqref{eq:lognormal_parameters} is represented as $\E[\hat{d}_{ij}^q] = \mathrm{e}^{q\mu_d + \frac{q^2\sigma^2_d}{2}}$. Therefore,
% \begin{equation} \label{eq:qth_moment}
%     \E[\hat{d}_{ij}^4] = \mathrm{e}^{4\mu_d + 8\sigma^2_d}, \;\;\;\;\; \E[\hat{d}_{ij}^2] = \mathrm{e}^{2\mu_d + 2\sigma^2_d},
% \end{equation}

% From \eqref{eq:qth_moment}, the elements for variance within the weighting matrix $\bm{W}_i$ \eqref{eq:weighting_matrix} are computed by:
% \begin{equation} \label{eq:covariance_elements}
%     \V[\hat{d}_{ij}^2] = \E[\hat{d}_{ij}^4] - \big( \E[\hat{d}_{ij}^2] \big)^2 = \mathrm{e}^{4\mu_d} \big( \mathrm{e}^{8\sigma_d^2} - \mathrm{e}^{4\sigma_d^2} \big).
% \end{equation}
% that are then used in the weighted least squares algorithm \eqref{eq:WLS} to compute optimized RSSI-based position measurements.


\subsection{Robust Adaptive Noise Covariance Estimation} \label{sec:Adaptive_KF}

With the sensor model updated to replace nominal position sensor with RSSI-based position measurements, the measurement covariance matrix $\bm{\mathrm{R}}$ used during nominal conditions is no longer suitable for optimal state estimation. A compromised agent $i$ leverages the recursive KF process to allow for adaptive updates (i.e., time varying) of the measurement noise covariance matrix $\bm{\mathrm{R}}_i^{(k)}$. The adaptive KF can be described in three phases, as follows:

\subsubsection{Prediction} As in the same manner of a typical recursive KF, the following equations denote
\begin{align} \label{eq:state_predict}
	\hat{\bm{\mathrm{x}}}_{i}^{(k|k-1)} &= \bm{\mathrm{A}} \hat{\bm{\mathrm{x}}}^{(k-1|k-1)}_{i} + \bm{\mathrm{B}} \bm{\mathrm{u}}^{(k-1)}_{i}, \\
    \label{eq:covariance_predict}
	\bm{\mathrm{P}}^{(k|k-1)}_{i} &= \bm{\mathrm{A}} \bm{\mathrm{P}}^{(k-1|k-1)}_{i} \bm{\mathrm{A}}^{\mathsf{T}} + \bm{\mathrm{Q}},
\end{align}
the predicted state and estimation error covariance.
	
\subsubsection{Correction} 
In this work, we introduce a novel residual-based method to estimate the unknown covariance of the RSSI-based measurements. Due to attacks/faults to position sensors, the residual employed for estimation must omit the use of the unreliable position estimate $\hat{\bm{\mathrm{x}}}_{i,[1:D]}^{(k)}$; hence the commonly-used measurement residual vector \eqref{eq:residual} can not be utilized (such as in \cite{AdaptiveR_EKF,AdaptiveR_UKF}). To deal with this problem, we leverage the RSSI-based position measurements \eqref{eq:WLS}, system model \eqref{eq:dynamical_model} and \eqref{eq:output_vector}, and the remaining states in the state estimation vector $\hat{\bm{\mathrm{x}}}_{i,[(D+1):n]}^{(k)}$ to estimate the RSSI-based position measurement covariance in a robust manner. Furthermore, we leverage known properties from serial randomness over the sequence of data \cite{Paul_ACC} in measurement covariance estimation.

First, to reconfigure to RSSI-based position measurements, an agent $i$ updates the first $D$ rows of the output matrix $\bm{\mathrm{C}}$ to form the updated output matrix $\bar{\bm{\mathrm{C}}}_i$ by
\begin{equation} \label{eq:pos_outputMatrix}
    \bar{\bm{\mathrm{C}}}_{i,[1:D]} = \Big[ \; \bm{\mathrm{I}}_{D} \;\;\;\; \bm{0}_{D \times (N_{\mathrm{s}}-D)} \; \Big]
\end{equation}
where $\bm{\mathrm{I}}_{D} \hspace{-1pt} \in \hspace{-1pt} \R^{D \times D}$ denotes a $D$-dimension identity matrix, as the RSSI-based position measurements have a $1$:$1$ mapping with the position states (i.e., $\bar{\bm{\mathrm{y}}}_{i,[1:D]}^{(k)} \hspace{-1pt}= \hspace{-1pt} \bar{\bm{\mathrm{p}}}_{i}^{(k)}$ where $\bar{\bm{\mathrm{p}}}_{i}^{(k)}$ is the direct mapping of the state from the RSSI-based position measurement in \eqref{eq:WLS}). The updated output matrix used by the adaptive KF is denoted by $\bar{\bm{\mathrm{C}}}_i \hspace{-.6pt} \in \hspace{-.6pt} \R^{N_{\mathrm{s}} \times n}$ such that the first $D$ rows described in \eqref{eq:pos_outputMatrix} and the remaining $N_{\mathrm{s}}-D$ rows (if applicable) are the same as the output matrix $\bm{\mathrm{C}}$.
\begin{assumption}
    The RSSI-based position measurements can be approximated as a Gaussian distributed vector with covariance $\bar{\bm{\mathrm{R}}}_i^{(k)} \hspace{-1pt} \in \hspace{-1pt} \R^{D \times D}$ centered over the true position $\bm{\mathrm{p}}_i^{(k)}$ of the compromised agent $i$ (i.e., $\bar{\bm{\mathrm{y}}}_{i,[1:D]}^{(k)} \approx \mathcal{N}(\bm{\mathrm{p}}_i^{(k)}, \bar{\bm{\mathrm{R}}}_i^{(k)} ) $).
\end{assumption}

\begin{lemma}
    A compromised agent $i$ that has reconfigured its sensor model to incorporate RSSI-based position measurements $\bar{\bm{\mathrm{y}}}_{i,[1:D]}^{(k)}$ updates its covariance matrix for position measurements $\bar{\bm{\mathrm{R}}}_i^{(k)}$ such that $\bar{\bm{\mathrm{R}}}^{(k)}_{i} = \frac{ \bar{\bm{\Sigma}}^{(k)}_{i} - 2\bar{\bm{\mathrm{Q}}} }{2}$ to minimize its state estimation error.
\end{lemma}

\begin{proof}
We leverage properties of serial randomness to aid in updating the unknown covariance of RSSI-based position measurements (i.e., the observation of consecutive position measurements computed in \eqref{eq:WLS}). To begin, a compromised agent $i$ computes the \textit{RSSI-based measurement residual}
\begin{equation} \label{eq:pos_residual}
    \bar{\bm{\mathrm{r}}}_{i}^{(k)} = \bar{\bm{\mathrm{y}}}_{i,[1:D]}^{(k)} - \bar{\bm{\mathrm{C}}}_{i,[1:D]} \hat{\bar{\bm{\mathrm{x}}}}_{i}^{(k)}
\end{equation}
which is a comparison between the RSSI-based position measurement \eqref{eq:WLS} and a position prediction $\bar{\bm{\mathrm{C}}}_{i,[1:D]} \hat{\bar{\bm{\mathrm{x}}}}_{i}^{(k)}$. The prediction vector $\hat{\bar{\bm{\mathrm{x}}}}_{i}^{(k)}$ in \eqref{eq:pos_residual} is computed by
\begin{equation} \label{eq:meas_prediction}
    \hat{\bar{\bm{\mathrm{x}}}}_{i}^{(k)} = \bm{\mathrm{A}} \bar{\bm{\mathrm{x}}}_{i}^{(k-1)} + \bm{\mathrm{B}} \bm{\mathrm{u}}_i^{(k-1)}
\end{equation}
where $\bar{\bm{\mathrm{x}}}_{i}^{(k-1)} \in \R^n$ represents the previous state estimate vector used for correction at time $k-1$. The vector $\bar{\bm{\mathrm{x}}}_{i}^{(k-1)}$ used for correction is defined as:
\begin{equation} \label{eq:state_predict_update}
    \bar{\bm{\mathrm{x}}}_{i}^{(k-1)} = \big[ \big( \bar{\bm{\mathrm{p}}}_{i}^{(k-1)} \big)^{\mathsf{T}}  \hspace{5pt} \big( \hat{\bm{\mathrm{x}}}_{i,[(D+1):n]}^{(k-1|k-1)} \big)^{\mathsf{T}}  \big]^{\mathsf{T}}.
\end{equation}
which is composed of the state estimate vector with its position elements $\hat{\bm{\mathrm{x}}}_{i,[1:D]}^{(k-1|k-1)}$ replaced with the positions from the RSSI-based position measurement $\bar{\bm{\mathrm{y}}}_{i,[1:D]}^{(k-1)} = \bar{\bm{\mathrm{p}}}_{i}^{(k-1)}$.



At each time $k \in \N$ the difference (i.e., the residual in \eqref{eq:pos_residual}) $\bar{\bm{\mathrm{r}}}_{i}^{(k)} = \bar{\bm{\mathrm{p}}}_{i}^{(k)} - \hat{\bar{\bm{\mathrm{p}}}}_{i}^{(k)}$ where $\hat{\bar{\bm{\mathrm{p}}}}_{i}^{(k)} = \hat{\bar{\bm{\mathrm{x}}}}_{i,[1:D]}^{(k)}$ from \eqref{eq:meas_prediction} is monitored between two consecutive positions at times $k$ and $k-1$. The noise characteristics for the measured positions $\bar{\bm{\mathrm{y}}}_{i,[1:D]}^{(k)}$ are subject to both measurement noise $\bar{\bm{\mathrm{R}}}_i^{(k)}$ and process noise $\bar{\bm{\mathrm{Q}}}$ of the position, where $\bar{\bm{\mathrm{Q}}}$ is the noise covariance block within $\bm{\mathrm{Q}}$ that corresponds to the position states of the compromised sensors. Given these noise properties, the expectation of the RSSI measured residual are described as:
\begin{equation} \label{eq:E_RSSIresidual}
\begin{split}
    \E[\bar{\bm{\mathrm{r}}}_{i}^{(k)}] &= \E[\bm{\eta}_{i,[1:D]}^{(k)}] - \E[\bm{\eta}_{i,[1:D]}^{(k-1)}] \\ 
    & \;\;\; + \E[\bm{\nu}_{i,[1:D]}^{(k-1)}] - \E[\bm{\nu}_{i,[1:D]}^{(k-2)}] = \bm{0},
\end{split}
\end{equation}
\begin{equation} \label{eq:V_RSSIresidual}
\begin{split}
    \hspace{-33pt}\V[\bar{\bm{\mathrm{r}}}_{i,[1:D]}^{(k)}] &= \V[\bm{\eta}_{i,[1:D]}^{(k)}] + \V[\bm{\eta}_{i,[1:D]}^{(k-1)}] \\
    & \;\;\; + \V[\bm{\nu}_{i,[1:D]}^{(k-1)}] + \V[\bm{\nu}_{i,[1:D]}^{(k-2)}] \\
    &= 2 \bar{\bm{\mathrm{R}}}_i^{(k)} + 2\bar{\bm{\mathrm{Q}}} \approx \bar{\bm{\Sigma}}^{(k)}_{i}.
\end{split}
\end{equation}



The objective is to estimate the positive definite covariance matrix of the RSSI measurement residual
\begin{equation} \label{eq:update_cov_residual}
    \hspace{-5pt} \bar{\bm{\Sigma}}^{(k)}_{i} = \E \Big[ \bar{\bm{\mathrm{r}}}_{i}^{(k)} \big( \bar{\bm{\mathrm{r}}}_{i}^{(k)} \big)^{\mathsf{T}} \Big] \in \R^{D \times D}
\end{equation}
by using a rolling runtime estimate similar to \cite{AdaptiveR_EKF}
\begin{equation} \label{eq:update_R2}
    \bar{\bm{\Sigma}}^{(k)}_{i} = (1-\gamma) \bar{\bm{\Sigma}}^{(k-1)}_{i} + \gamma \Big( \bar{\bm{\mathrm{r}}}_{i}^{(k)} \big( \bar{\bm{\mathrm{r}}}_{i}^{(k)} \big)^{\mathsf{T}} \Big)
\end{equation}
where $\gamma \in (0,1)$ is a \textit{forgetting} parameter in adaptively updating the covariance\footnote{We note that a smaller $\gamma$ puts a greater weight on the previous RSSI measurement residual covariance estimate at time $k-1$, thus resulting in less variation in the updated estimate.}. From the approximated estimated covariance in \eqref{eq:V_RSSIresidual}, we can compute the estimated RSSI-based position measurement covariance block
\begin{equation} \label{eq:update_Rbar}
    \bar{\bm{\mathrm{R}}}^{(k)}_{i} = \frac{ \bar{\bm{\Sigma}}^{(k)}_{i} - 2\bar{\bm{\mathrm{Q}}} }{2}
\end{equation}
thus concluding the proof.
\end{proof}

The updated positioning covariance \eqref{eq:update_Rbar} is contained within the updated measurement covariance matrix
\begin{equation} \label{eq:Rpos_covariance}
    \bm{\mathrm{R}}_i^{(k)} = \begin{bmatrix} \bar{\bm{\mathrm{R}}}_i^{(k)} & \bm{0}_{ D \times (N_{\mathrm{s}}-D)} \\[4pt] \bm{0}_{ (N_{\mathrm{s}}-D) \times D} & \breve{\bm{\mathrm{R}}} \end{bmatrix}
\end{equation}
for all $N_{\mathrm{s}}$ sensors, where $\breve{\bm{\mathrm{R}}} \in \R^{(N_{\mathrm{s}}-D)\times (N_{\mathrm{s}}-D)}$ is the measurement covariance of the remaining non-position sensors.
	
\subsubsection{Update} We incorporate the correction phase that adaptively updated the position measurement covariance to optimize the state estimate, we then have the updates to:
\begin{align} \label{eq:Kalman}
	\bm{\mathrm{K}}^{(k)}_{i} &= \bm{\mathrm{P}}^{(k|k-1)}_{i} \bar{\bm{\mathrm{C}}}_i^{\mathsf{T}} \big( \bar{\bm{\mathrm{C}}}_i \bm{\mathrm{P}}^{(k|k-1)}_{i} \bar{\bm{\mathrm{C}}}_i^{\mathsf{T}} + \bm{\mathrm{\mathrm{R}}}_i^{(k)} \big)^{-1}, \\
    \label{eq:updated_estimate}
	 \hat{\bm{\mathrm{x}}}^{(k|k)}_{i} &= \hat{\bm{\mathrm{x}}}^{(k|k-1)}_{i} + \bm{\mathrm{K}}^{(k)}_{i} \big( \bar{\bm{\mathrm{y}}}^{(k)}_{i} - \bar{\bm{\mathrm{C}}}_i\hat{\bm{\mathrm{x}}}^{(k|k-1)}_{i} \big), \\
    \label{eq:updated_covariance}
	 \bm{\mathrm{P}}^{(k|k)}_{i} &= \big( \bm{\mathrm{I}}_n - \bm{\mathrm{K}}^{(k)}_{i} \bar{\bm{\mathrm{C}}}_i \big) \bm{\mathrm{P}}^{(k|k-1)}_{i},
\end{align}
the Kalman gain, state estimate, and estimation covariance.





% Next, we approximate the RSSI-based position measurements $\bar{\bm{y}}_{i,[1:D]}^{(k)}$ as Gaussian distributed random vector with unknown covariance $\bar{\bm{R}}_i \in \R^{D \times D}$ centered over the true position $\bm{x}_i^{(k)}$ of the compromised agent $i$ (i.e., $\bar{\bm{y}}_{i,[1:D]}^{(k)} \approx \mathcal{N}(\bm{x}_i^{(k)}, \bar{\bm{R}}_i) $).

% \begin{equation} \label{eq:update_R}
%     \widetilde{\bm{R}}^{(k)}_{i} = \E \Big[ \widetilde{\bm{r}}_{i}^{(k)} \big( \widetilde{\bm{r}}_{i}^{(k)} \big)^{\mathsf{T}} \Big] + \widetilde{\bm{C}}_{[1:D]} \bm{P}_{i}^{(k|k-1)} \widetilde{\bm{C}}_{[1:D]}^{\mathsf{T}},
% \end{equation}