    %\documentclass[wcp,gray]{jmlr} % test grayscale version
\documentclass[wcp]{jmlr}

% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e

%\usepackage{rotating}% for sideways figures and tables
\usepackage{longtable}% for long tables

% The booktabs package is used by this sample document
% (it provides \toprule, \midrule and \bottomrule).
% Remove the next line if you don't require it.
\usepackage{booktabs}
\usepackage{kotex}

% The siunitx package is used by this sample document
% to align numbers in a column by their decimal point.
% Remove the next line if you don't require it.
%\usepackage[load-configurations=version-1]{siunitx} % newer version
%\usepackage{siunitx}
%\usepackage{natbib}

% Do not comment the following commands:
\pagenumbering{gobble}
\newcommand{\cs}[1]{\texttt{\char`\\#1}}
\makeatletter
\let\Ginclude@graphics\@org@Ginclude@graphics 
\makeatother

\jmlrvolume{222}
\jmlryear{2023}
\jmlrworkshop{ACML 2023}

\title[Edit-A-Video: Single Video Editing with Object-Aware Consistency]{Edit-A-Video: Single Video Editing with Object-Aware Consistency}

 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}
\author{\Name{Chaehun Shin$^{*}$} \Email{chaehuny@snu.ac.kr}\\
\Name{Heeseung Kim$^{*}$} \Email{gmltmd789@snu.ac.kr}\\
\Name{Che Hyun Lee} \Email{saga1214@snu.ac.kr}\\
\Name{Sang-gil Lee} \Email{tkdrlf9202@snu.ac.kr}\\
\addr Data Science and AI Lab, ECE, Seoul National University, Seoul 08826, Korea\\
\Name{Sungroh Yoon$^{\dag}$} \Email{sryoon@snu.ac.kr}\\
\addr Data Science and AI Lab, ECE and  Interdisciplinary Program in AI, Seoul National University, Seoul 08826, Korea}
 % Two authors with the same address
 % \author{\Name{Author Name1} \Email{abc@sample.com}\and
 %  \Name{Author Name2} \Email{xyz@sample.com}\\
 %  \addr Address}

 % Three or more authors with the same address:
 % \author{\Name{Author Name1} \Email{an1@sample.com}\\
 %  \Name{Author Name2} \Email{an2@sample.com}\\
 %  \Name{Author Name3} \Email{an3@sample.com}\\
 %  \Name{Author Name4} \Email{an4@sample.com}\\
 %  \Name{Author Name5} \Email{an5@sample.com}\\
 %  \Name{Author Name6} \Email{an6@sample.com}\\
 %  \Name{Author Name7} \Email{an7@sample.com}\\
 %  \Name{Author Name8} \Email{an8@sample.com}\\
 %  \Name{Author Name9} \Email{an9@sample.com}\\
 %  \Name{Author Name10} \Email{an10@sample.com}\\
 %  \Name{Author Name11} \Email{an11@sample.com}\\
 %  \Name{Author Name12} \Email{an12@sample.com}\\
 %  \Name{Author Name13} \Email{an13@sample.com}\\
 %  \Name{Author Name14} \Email{an14@sample.com}\\
 %  \addr Address}


 % Authors with different addresses:
%  \author{\Name{Author Name1} \Email{abc@sample.com}\\
%  \addr Address 1
%  \AND
%  \Name{Author Name2} \Email{xyz@sample.com}\\
% \addr Address 2
% }

\editors{Berrin Yan{\i}ko\u{g}lu and Wray Buntine}

\begin{document}
% to be changed
\maketitle

\begin{abstract}
With advancements in text-to-image (TTI) models, text-to-video (TTV) models have recently been introduced.
Motivated by approaches on TTV models adapting from diffusion-based TTI models, we suggest the text-guided video editing framework given only a pretrained TTI model and a single $<$text, video$>$ pair, which we term \textbf{Edit-A-Video}.
The framework consists of two stages: (1) inflating the 2D model into the 3D model by appending temporal modules and tuning on the source video (2) inverting the source video into the noise and editing with target text through attention map injection.
Each stage enables the temporal modeling and preservation of semantic attributes of the source video.
One of the key challenges for video editing is a background inconsistency problem, where the regions unrelated to the edit suffer from undesirable and inconsistent temporal alterations.
To mitigate this issue, we also introduce a novel mask blending method, termed as temporal-consistent blending (TC Blending). 
We improve previous mask blending methods to reflect the temporal consistency, ensuring that the area where the editing is applied exhibits smooth transition while also achieving spatio-temporal consistency of the unedited regions.
We present extensive experimental results over various types of text and videos, and demonstrate the superiority of the proposed method compared to baselines in terms of background consistency, text alignment, and video editing quality. Our samples are available on \href{https://editavideo.github.io}{https://editavideo.github.io}.
\end{abstract}
\begin{keywords}
Diffusion-based Generative Model, Text-based Video Editing
\end{keywords}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}
% {\let\thefootnote\relax\footnotetext{$*$ Equal Contribution. $\dag$ Corresponding Author.}}
\footnotetext[1]{Equal Contribution, $\dag$. Corresponding Author.}
\renewcommand{\thefootnote}{\arabic{footnote}}

\input{sections/introduction}
\input{sections/background}
\input{sections/method}
\input{sections/experiments}
\input{sections/conclusion}

% \acks{This work was supported by Institute of Information \& Communications Technology Planning \& Evaluation (IITP) grant funded by the Korea government (MSIT) [NO.2021-0-01343, Artificial Intelligence Graduate School Program (Seoul National University)], the BK21 FOUR program of the Education and Research Program for Future ICT Pioneers, Seoul National University in 2023, and the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No.  2022R1A3B1077720).}
\acks{This work was supported by Institute of Information \& communications Technology Planning \& Evaluation grant funded by the Korea government (MSIT) [2021-0-01343, AI Graduate School Program (SNU)], National Research Foundation of Korea grant funded by MSIT (2022R1A3B1077720), and the BK21 FOUR program of the Education and Research Program for Future ICT Pioneers, SNU in 2023.}

\bibliography{main}

\clearpage
\newpage

{
\centering
\Large
\textbf{Edit-A-Video: Single Video Editing with Object-Aware Consistency} \\
\vspace{0.5em}-- Supplementary Materials --\\
\vspace{1.0em}
}

\appendix
\input{sections/appendix}

%\bibliographystyle{plain}
\end{document}
