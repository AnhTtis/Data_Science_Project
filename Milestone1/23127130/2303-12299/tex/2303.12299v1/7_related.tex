\section{Related Work}
\label{sec:related}

In this section, we review three lines of research that are most relevant to our work, i.e., (1) API recommendation, (2) mining API usage patterns, and (3) Mining Stack Overflow.

% There are several methods proposed for API recommendation leveraging \so posts, namely CLEAR~\cite{wei2022clear} and BIKER~\cite{huang2018api}. However, these approaches were built to generate an API set instead of API sequence. \method's approach which is designed to produce an API sequence recommendation cannot be compared fairly to the API set recommendation model.
% % Therefore, we excluded these approaches from the baselines.

\subsection{API Recommendation}
In recent years, a multitude of API recommendation methods have been proposed~\cite{chen2021holistic,zhou2021boosting,rahman2016rack,deepapi}.
As mentioned in Section~\ref{sec:intro}, there are generally two types of methods for API recommendation.
We review several recent works in this part.

\textbf{\textit{Query-based} API recommendation:} 
Zhou et al.~\cite{zhou2021boosting} have proposed a framework BRAID (Boosting RecommendAtion with Implicit FeeDback) to boost the performance of query-based API recommendation systems.
BRAID adopts the user selection history as feedback information.
Moreover, it leverages learning-to-rank to re-rank the recommendation results.
Active learning techniques have been incorporated to alleviate the ``cold start'' of the limited feedback information at the beginning.
In addition, active learning can also speed up feedback learning.
The experimental results demonstrate that this framework can boost the performance of the three API recommendation systems.

% RACK~\cite{rahman2016rack} exploits \so posts to recommend APIs.
% However, our work is different from RACK, since we use \so as query expansion.

\textbf{\textit{Code-based} API recommendation: }, they solve the task as the next-token prediction task. 
Xie et al.~\cite{xie2019hirec} propose HiRec, which is based on hierarchical context.
To generate hierarchical context, they use WALA~\cite{MainPage68:online} to generate call graphs of API methods and collect basic context from the call graphs.
They, we obtain a hierarchical structure of the surrounding project-specific code.
The final step is to combine both the basic context and hierarchical structure of surrounding project-specific code.
Another recent approach is APIRecX~\cite{kang2021apirecx}, which was proposed to handle the out-of-vocabulary issue of cross-library API recommendation.
It utilizes the GPT-based pre-trained subtoken language model.
At a high level, they use byte pair encoding~\cite{sennrich2016neural} to split each API call in each API sequence and pre-train a GPT-based language model.
By fine-tuning the pre-trained model, APIRecX can recommend APIs.
Different from them, our focus is to demonstrate that \so can be leveraged to boost query-based API recommendation.

\subsection{Mining API Usage Patterns}
Other than API recommendation, a similar long-researched topic is mining API usage patterns~\cite{xie2006mapo,zhong2009mapo,wang2013mining,fowkes2016parameter}.
MAPO is the first algorithm that has been proposed to mine API usage patterns from source code.
It was initially proposed by Xie and Pei~\cite{xie2006mapo} and further extended by Zhong et al.~\cite{zhong2009mapo}.
For a given query that describes the API, MAPO can leverage existing source code search engines to gather relevant source files and conduct data mining.
With the mined API usage patterns, MAPO has been extended to guide programmers in locating useful code snippets~\cite{zhong2009mapo}.
Wang et al.~\cite{wang2013mining} found that (1) there was a lack of metrics to measure the quality of mined API patterns, and (2) the API patterns mined by the prior approaches tend to be redundant.
Therefore, they focused on addressing these issues and proposed two quality metrics, i.e., succinctness and coverage, to measure the quality of mined API patterns.
Furthermore, they proposed an approach named Usage Pattern Miner (UP-Miner), which includes a two-step clustering strategy to mine succinct and high-coverage usage patterns of API methods from source code.
Similarly, Fowkes et al.~\cite{fowkes2016parameter} also identified the limitation of the prior approaches: the returned API calls tend to be large, redundant, and hard to understand.
To mitigate the issue, they propose PAM (Probabilistic API Miner), a near parameter-free probabilistic algorithm for mining the most interesting API call patterns. 

\subsection{Mining Stack Overflow}
As \so has been an essential part of software development, there is also rising research interest in mining \so posts.
Data from \so posts have been extensively used for multiple purposes.
Several studies have investigated leveraging \so as complementary of additional sources for specific tasks, such as augmenting API documentation~\cite{treude2016augmenting}, maintaining code~\cite{tang2021using}, and error fixing~\cite{wong2019syntax}.
Tang et al.~\cite{tang2021using} was the first to show that comment-edit pairs in \so can be potentially used for code maintenance.
They implemented an automated approach to link comments to code-snippet edits in \so.
Furthermore, they conducted a manual investigation of statistically representative random samples of the extracted comment-edit pairs.
They found that 50\% of the confirmed comment-edit pairs were general and related to correction, obsolete, flaw, and extension, which can be useful for general code maintenance tasks.
To demonstrate the potential use, they also leverage the confirmed comment-edit pairs to submit 15 pull requests to different GitHub repositories.
Among them, ten have been accepted.


Wong et al.~\cite{wong2019syntax} have focused on the syntax errors, and they extracted a Python dataset that contains human-made errors and their fixes from \so.
They first parse detected Python source snippet histories; second, they extract pairs of failed and fixed revisions; third, they validate pairs with interpreters; and finally, they record successfully evaluated pairs.
The resulting dataset is composed of real syntax errors made by developers, so it can potentially be used for the training and evaluation of code-related tasks, such as error detection.
By manual investigation, they found that errors made by \so users do not match errors made by student developers or random mutations.

Recently, Wu et al.~\cite{wu2023leveraging} focus on the task of identifying the relevant fragments of APIs.
They propose a new approach, SO2RT, to discover relevant tutorial fragments of APIs based on \so posts.
They utilize both the labeled information (relevance between \so Q\&A pairs and APIs) and unlabeled information (tutorial fragments and APIs).
They first automatically build two types of pairs, i.e., (1) relevant and irrelevant API and \so Q\&A pairs, and (2) API and tutorial fragment pairs.
They then train a semi-supervised transfer learning-based relevant fragment detection model, which aims to transfer the API usage knowledge in \so Q\&A pairs to tutorial fragments. 
Finally, the trained model can be used to infer relevant tutorial fragments of APIs.