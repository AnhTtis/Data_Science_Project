\begin{table}

\centering
\scriptsize
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}ll|llll@{}}
\toprule
Methods                         & Pretraining Data               & R-L & C   & S   & BertS \\ \midrule
ClipCap~\cite{mokady2021clipcap}  & CC3M   & 8.5 & 4.4 & 1.1 & 11.8  \\
CapDec*~\cite{nukrai2022text}     & AV-AD  & 8.2 & 6.7 & 1.4 & 14.3 \\
\midrule
AutoAD (ours)  & AV-AD            & {\textbf{12.1}} & {14.1}          & {4.2}  & {23.0} \\
AutoAD (ours)  & AV-AD \& WebVid  & {11.9}          & {\textbf{14.3}} & {\textbf{4.4}}           & \textbf{24.2} \\ \bottomrule
\end{tabular}
}
\vspace{-3mm}
\caption{Compared with other works on movie AD generation task on MAD-v2. 
We obtain results from other methods by finetuning their models 
on MAD-v2-\texttt{Named} dataset, and evaluated on MAD-eval-\texttt{Named}.
*CapDec~\cite{nukrai2022text} proposes text-only pretraining to adapt the style for text generation,
we pretrained their model on the text-only AudioVault-AD dataset 
then applied it to MAD-v2.
\label{tab:self}
\vspace{-2mm}
}

\end{table}