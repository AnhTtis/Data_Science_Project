\section{Results}
\label{Results}


Our analysis surfaced three high-level themes. First, we describe current attitudes and practices surrounding the anticipation of UCs (Section \ref{5.1}). We then discuss how the lack of a formal method inhibits the anticipation and reaction to UCs by researchers (Section \ref{5.2}). Finally, we show how academic practices strain efforts to anticipate UCs (Section \ref{5.3}). Participants are identified with a "P". For a small number of sensitive quotes, the specific research products are omitted to provide an additional layer of anonymity.

 \begin{figure*}[ht]
    \centering 
    \vskip 0.3cm
    \includegraphics[width=\textwidth]{figures/UC_in_research.pdf}
    \caption{Stages in the research process during which UCs should be considered based on our interview results. Our findings suggest that considering potential UCs should ideally occur throughout the research process (i.e., the dashed green arrow), but that it is currently only done in reaction (i.e., the dashed red arrow) when writing grant applications, IRB applications, and ethics statements, if at all.}
    \label{fig:overview}
    \Description{A timeline that lists the 7 stages of the research process: 1) Define the problem, 2) Define solutions, 3) Design prototype, 4) Deployment and/or testing, 5) Draft papers, 6) Publication, and 7) Post-publication deployment. The ideal time to consider potential UCs is depicted with a dashed arrow that extends through all seven stages of the research process, starting from "Define the problem" and ending at "Post-publication deployment." The reality of considering UCs is depicted with a grant application at the first stage labeled as "Define the problem", an IRB application at the second stage labeled as "Define solutions", an ethics statement at the fifth stage labeled as "Draft Papers", and a dashed line labeled as "React to occurrences of UCs" extending from the fourth stage labeled as "Deployment and/or testing" until the end of the research process.}
\end{figure*}

\subsection{Current Attitudes and Practices Surrounding UCs}
\label{5.1}

In our interviews, 18 out of 20 participants explicitly mentioned that they had at least one prior experience where their research innovations had UCs after deployment or testing. All 20 participants unanimously emphasized the importance and responsibility of researchers to consider UCs throughout the research processes. To illustrate when our participants suggested ideally considering UCs, we present an overview of the research process in~\autoref{fig:overview}. It shows that our participants indicated that UCs should ideally be considered throughout the research process, ranging from problem definition to publication and public deployment. In reality, we observed participants only anticipate UCs when they are required to do so, such as when writing  broader impacts statements for grants, IRB applications, or ethics statements for conferences. We will provide more details describing how participants told us how they use these artifacts for reflecting on UCs in later sections (Section \ref{5.1} and Section \ref{5.2}). 

Despite the ideal circumstances for considering UCs, our analysis showed that none of our participants proactively consider them in the research process. Hence, \textbf{while participants see the importance of anticipating UCs, they rarely take actions to do so}. In fact, 10 participants self-described that they ``do not spend enough time thinking about UCs,'' and 4 participants explicitly mentioned that they ``do not spend any time thinking about UCs.''

Despite not proactively anticipating UCs, our interviews revealed that \textbf{potential UCs are occasionally discussed through informal, serendipitous conversations, but there is no formal process}. Through our interviews, we found that researchers were sometimes made aware of potential UCs through informal conversations with their colleagues and collaborators. They recalled anticipating UCs during lab presentations or meetings, though infrequently. For example, P6 mentioned that collaborators sometimes share concerns, including potential UCs, on a case-by-case basis during project meetings. When asked when they think of UCs in their research, P6 remarked that they do so \emph{``on and off. I mean, the thought is generally there [...] because it's not like the research projects change so often.''} While giving informal research presentations in their lab, P1 welcomed feedback on potential UCs, but bewailed that \emph{``just talking about a research project doesn't necessarily provide an invitation for talking about UCs.''} 
%
Many researchers shared similar experiences of learning about potential UCs through informal conversations or presentations, but also receiving limited feedback (P1, P4, P6, P7, P9, P10, P12, P16-17). For example, P16 shared her experiences on how \emph{``[Talking about UCs] is kind of something that just happens, during meetings, when if somebody just has a question to discuss, `Oh, I don't know if that's a great idea because of this and that.' ''} However, P16 also expressed that such an approach is \emph{``not like a formal [discussion to] make sure that we're going through every aspect of this tool and making sure it's not going to have these negative consequences.''} Later P16 stated that the informal, or ``accidental,'' conversations on UCs are not an ideal solution. 

In addition to these informal conversations, \textbf{participants commonly react to UCs only after creating tangible research artifacts which can range from deployment and/or testing to post-publication.} Of the 18 participants that shared specific experiences, 13 specifically recounted how experiencing UCs impacted later research decisions, such as making adjustments to a current research project (P5, P7, P17), identifying a new research direction (P12, P14, P19), terminating a research project or idea (P10-11, P13), or consulting expert assistance (P2, P4, P6, P11, P18). For example, P2 shared their experience when testing a content-sharing application in a user evaluation. P2 realized that some audiences found \emph{``some content might not be appropriate for them.''} Therefore, they spent more time on content moderation than originally planned. Similarly, during post-publication, dissemination of results through methods such as social media may also heighten awareness that research innovations can have undesired societal impacts on researchers. For example, P10 told us:

\begin{quote}
    \emph{``People put that [my] research project on Reddit. And there was like, a whole bunch of comments on Reddit on my research video [...] Like, there was something that I didn’t think about [...] And it was kind of something that actually led me to change research topics.''} %[P10]
\end{quote}

P20 described their experience with a prototype system that received over 1 million adversarial examples from public auditing. They spent nights debugging the system, replying to users' critiques on Twitter, and issued a public disclaimer in the end. P20 recounted the outcome of their experience: 

\begin{quote}
    \emph{``When we initially released the archive paper [...], we didn't expect a lot of people would just play with a demo, because that's usually how these research prototypes are. [B]ut when we released the demo, suddenly, a lot of people played with it. So yeah, we never thought people would have had such an explosive discussion of this.''} %[P20]
\end{quote}

 As a result of reacting to UCs, participants became aware of the impact of their research products on users or society. While our participants took different actions to react to UCs, ranging from issuing public disclaimers (P6, P20), to debugging the system (P1-3, P5, P7-8, P14-16, P20), and shifting research direction (P2, P10), our interviews did not capture a standard procedure for anticipating UCs, such as a dedicated time and research procedure. Nonetheless, some participants regretted considering UCs only after a specific incident had occurred. As P5 put, \emph{``A lot of people do treat [UCs] as an afterthought. And it’s kind of unfortunate.''}

 We also found that many \textbf{participants unintentionally deflect responsibility for considering UCs, believing that their research is unlikely to cause enough harm to warrant serious consideration of UCs}. Under the following subtheme, we describe researchers’ acts of and justifications for this unintentional deflection.

 Although all participants recognized the significance of anticipating UCs, some questioned whether researchers were personally responsible for anticipating the UCs of their research. While none of our participants stated that they ignore UCs altogether, several of them described that they are familiar with colleagues in the research community who disregard their work's societal implications (P6-8). As P8 put it, \emph{``[Some colleagues might think] scientists are not responsible for broader impacts [...] They do research and then let policymakers or someone else think [about them].''} %[P8]
%
 Similarly, P6 asserted that \emph{``there are some machine learning people who think [...] I am going to focus on algorithms and not worry about social issues.''} 

 In contrast, some participants felt that researchers are responsible for the UCs of their work because they are the creators of new technologies. For example, P12 explained that:

\begin{quote}
    \emph{``Researchers and anyone who is bringing these ideas to light, I think they need to be responsible for what they're saying, or at least be able to say whether they have discussed or kind of attempted to figure out what kind of impacts or implications are for whatever information they're presenting to the world.''}
\end{quote}

 
 Despite the perceived responsibility of some participants, others worry that they lack the influence or foresight to engage with broader societal consequences. For example, P5 described working on a computer vision project that ultimately made it \emph{``easier for the NSA [National Security Agency] to spy on people,''} but they neither anticipated nor reacted to this specific incident. They reconciled themselves with working on it because \emph{``that is kind of why they were funding us.''} Similarly, P20 shared that it is \emph{``extremely difficult to predict what can go wrong without seeing how [the research product] works in the real world, as an NLP researcher.''} Moreover, some participants felt that how their research is used by others is beyond their own responsibility. To them, UCs were unfortunate, yet inevitable repercussions of research, but not necessarily a responsibility to consider or feasibly address. 


 We also found that the \textbf{Institutional Review Board (IRB) applications are mistakenly relied upon to alert researchers about the potential for UCs}. When asked about how they consider UCs in their research, some participants shared that they rely on the IRB application (P3, P8, P10-11, P13). P13 thought that \emph{``the [IRB] committee does a good job and eliminates most of the foreseeable negative effects [of their submitted research projects].''} Likewise, P16 expressed similar confidence in the IRB application: \emph{``The whole point of the IRB is that we’re doing things ethically, right? [...] So yeah, I think [considering unintended consequences] falls under the same jurisdiction of [the IRB].''}

 Others were well aware that the IRB process is not designed to anticipate UCs. For example, P10 noted that although the IRB considers \emph{``[unintended] consequences in terms of individual participants, it does not specifically consider general consequences and consequently leaves the responsibility of considering unintended consequences to individual [researchers] to do it}.'' 
%
 P15 explained that the IRB application might not properly address non-human subjects research and stated that \emph{``many AI projects where you don’t interact with participants''} are not even considered by the IRB. Although the IRB application considers participant ethics, it is not designed to anticipate UCs on society beyond those related to participants. The observation made intuitive sense as the Common Rule, which governs the IRBs in the U.S., specifically disallows review of UCs to human society~\cite{commonrule}.

 As noted above, all participants recognized the importance of considering UCs. Nevertheless, we observed that \textbf{\participants underestimated the potential UCs of their own research because the primary goal of most research is to produce societal benefit}. In general, researchers equated good intentions with producing less social harm. For example, P4 explained that \emph{``there is a pretty big distinction between [my] research [...], which tends to be very specifically targeted towards what hopefully will be societal good,''} and \emph{``technologies that have caused more problems,''} specifying that their intent to create technologies with social benefit lessens the need to scrutinize potential UCs. P16 explicitly stated that \emph{``researchers like us aren't trying to create something that could be harmful.''}
Similarly, P6 noted that:

\begin{quote}
\emph{``By design, my research is really geared towards mitigating the problem that's out there, so it doesn't make sense for me to worry about the negative consequences […] or think about the ethical concerns as much. Because it doesn't seem to apply.''}
\end{quote}

\rr{Although initially provided with a clarifying definition of UCs, multiple participants assumed that the positive, intended consequences of their research would reduce or eliminate its potential negative consequences, leading them to neglect considering UCs.}

Additionally, other participants felt that there was no need for them to consider potential UCs because \rr{they perceived their research as unlikely to be misused}. For example, P5 indicated that they are not as concerned with large-scale UCs because their work is mostly hidden from the public. As an NLP researcher, they explained that \emph{``if anyone wanted to, like really generate fake news, at scale, they probably wouldn't even have used our model.''}
%
Incidentally, many \participants across multiple sub-disciplines shared this sentiment, but none could explain at what stage their research would require investigating potential UCs. Nearly all researchers explained that because their research created developmental technologies that might lead to \emph{``future work''} [P20], they felt that any potential misuse of their research would not generate sufficient harm for them to need to consider UCs earlier on. In the words of P7, \emph{``because there are no consequences in academia, researchers have to get really worked up about [considering UCs].”}

In summary, we found that our participants perceive considering UCs to be important, but they rarely take proactive steps to address this issue. Instead, they react to UCs when they occur. As P19 said, ``I still think \emph{that's important, but} I just think it's really hard.'' Perhaps due to this attitude, many researchers unintentionally deflected responsibility for four key reasons: reliance on others to consider UCs, dependence on the IRB application to anticipate UCs, belief that research motives equated with reduced social harm, and doubt about the potential social impact of their work.

\subsection{Researchers Lack Formal Methods and Guidelines for Anticipating UCs}
\label{5.2}

Although participants understood the significance of anticipating and responding to UCs in their research, they generally felt unsure of how to approach this issue. Many participants reported that a lack of understanding and experience of UCs reduced their ability to anticipate and/or react to UCs. In this section, we delve into a list of barriers we identified from our interviews: a lack of systematic guidelines for anticipating UCs, a lack of experience and knowledge in UCs which hindered researchers' ability to anticipate and react to UCs, and a lack of opportunities to work with collaborators from diverse backgrounds and skill sets which also hindered efforts to anticipate UCs. 

Many researchers lamented \textbf{a lack of systematic guidelines for brainstorming about UCs and for knowing how to anticipate UCs}. P10 expressed that many conferences do not provide sufficient support --- such as \emph{``predefined infrastructure or scaffolding approach for thinking about them''}, despite requirements for broader impacts or ethics statements. As a result, researchers can feel that \emph{``it's really on the individuals to do [anticipate UCs].''} Compared to existing specific AI-related checklist ~\cite{datasheet, madaio2020co, micrsoft}, a guideline can inform \emph{``at what point you know if we could potentially have some very negative unintended consequences,'' ``who should we bring in,'' ``what kind of outside expert would be the most appropriate for this.'' [P3]} 

Many participants yearned for guidelines to assist with anticipating UCs. P16 noted how a checklist for anticipating UCs could help researchers confirm \emph{``that they thought about [UCs] thoroughly."} In addition, P8, who expected to release an open-source CV demo, expressed a \emph{``need to develop some type of guidelines and policy for how much evaluation is sufficient [before deploying public technologies].''}

Several participants also suggested the benefit of showcasing past UCs that others have anticipated or reacted. For example, P12 acknowledged how they had learned to anticipate UCs based on previous experiences, so \emph{``a resource of common problems [...] of the past might be helpful, so I don't make any of the mistakes that people have already made.''} P10 suggested several potential resources for anticipating UCs including \emph{``some model examples of papers that have done a good job, researchers or research groups that have done a good job, [...] guidelines for how to approach [UCs] to begin with, [...] and thought experiments in thinking about how to how to come up with [UCs].''} Similarly, P19 emphasized the impact of highlighting \emph{``very impactful paper[s] that include ethical statements and win an ACM award''} as a way to not only provide guidance on how to structure writing about UCs, but also serve as \emph{``exemplars of papers''} that demonstrate the importance of anticipating UCs to the academic community.

Similarly, \textbf{the broader impact or ethics statements --- in grant applications and paper submissions --- are insufficient in adequately accounting for UCs.} In grant applications, for example, P12 mentioned researchers might inaccurately portray the impact of their research, which \emph{``is typically framed in a positive light rather than a negative light,''} in an effort to receive funding. The broader ethics statement that some conferences require were also discussed multiple times in our interviews. Although our participants viewed ethics and impact statements as the first step to anticipating UCs, they considered them as “superficial” solutions. P14 explained that, to many researchers, broader impact statements felt more like formalities that \emph{``researchers [have] to do to get publications, because that's what helps them in their careers.''} The broader ethics statement may make researchers only \emph{``think about unintended consequences or these other societal issues when they are writing''}, rather than \emph{``when they are designing studies.''} [P17] Additionally, we note that \participants also feel conflicted about the effectiveness of these statements at guiding researchers to thoughtfully anticipate UCs throughout their research process. P12 worried that simply reporting UCs, rather than acting on them, does not sufficiently protect against the implications of negatively-impacting research. P8 added the limitation from a reviewer's perspective:

 \begin{quote}
 \emph{``[A broader impacts statement] doesn't really do anything, this is just like, a bandage on like a deeper wound of really investigating [...] whether or not a project should be pursued or not [...] Most reviewers when they read a paper to decide to accept to a conference or journal, won't really seriously considered the broader impacts when deciding to accept or reject the paper.''}
 \end{quote}

Moreover, many participants added that \textbf{a general lack of experience and knowledge in UCs hindered their ability to anticipate and react to UCs in their research}. Our interviews indicated that new faculty and junior researchers (e.g., graduate students, postdocs) were most likely to feel unsupported and ill-equipped when anticipating UCs. In particular, several participants shared their experiences with anticipating and addressing UCs as junior researchers. For example, P12 reflected on how, after experiencing a UC in their career, they realized that they did not have the research experience and foresight to anticipate any negative UCs, stating that they ``\emph{[were] overly optimistic [...] about what the realistic [consequences were] going to be [and] sort of unaware of the [potential unintended consequences].''} Other junior researchers also recognized how their limited research experiences prevent them from anticipating UCs; therefore, to anticipate UCs, these junior researchers depend on their advisors to account for potential UCs (P1, P9-10, P13, P17). For example, P13 recounted an interaction with their advisor at the beginning of their Ph.D. where their \emph{``PI basically turned [a research idea] down because it [could] have some negative use cases.''} Some junior researchers shared that they lack opportunities to consider UCs because of their mainly independent work. P1, a Ph.D. student, noted that their lack of collaborators led them to consult \emph{``mostly [the] advisors in [their] labs''} to receive feedback about UCs. Additionally, P17 also acknowledged that ``\emph{maybe others have seen multiple things, or you get more perspectives or more voices. But that's generally not the case for an average Ph.D. student, it's usually a one-to-one relationship with an advisor when they're starting [a Ph.D.]''} 

In particular, junior researchers’ limited research experiences and mostly independent research work often meant that they were unable to properly account for UCs without the assistance of their advisors. Therefore, junior researchers might assume that more senior faculty would have already anticipated negative consequences. For example, P17, a Ph.D. student, explained that his advisor played a large role in screening his proposals for any potential UCs that they were simply unaware of. They explained that:

\begin{quote}
\emph{``I think [advisors] have realized [what the possible unintended consequences are] already [because] they went through the process, through writing what they have seen in the community [...] And if you spend enough time in the community, you get to know those norms implicitly.''
    }%[P17]
\end{quote}

Further, several participants noted how new faculty also face difficulties when anticipating UCs. P18, a new faculty member, shared their thoughts on confronting UCs: \emph{
``I feel like there's a responsibility there, but I also feel so incredibly ill-equipped to do anything useful about it.''} P19, another junior faculty member, also commented on the knowledge-based limitations that new faculty face in anticipating UCs and questioned their ability to consider \emph{``the ethical reasoning about [a research project] if I'm not personally very educated on it.''} 

\rr{Ironically, several faculty members noted that most students now enroll in ethics courses, and they therefore believed that students are sufficiently prepared to confront ethical problems in their research [P4, P6, P16]. However, our observation indicated that students and even junior faculty members may feel unable and unempowered to approach UCs without the support of their advisors and peers. We recognize how throughout the research pipeline, many researchers — including graduate students and faculty members — face knowledge barriers when anticipating UCs. Ultimately, these findings illustrate the lack of knowledge-based resources that \textit{all} researchers face throughout the research pipeline. }

%We identified how junior researchers face knowledge barriers in anticipating UCs and therefore mainly rely on more experienced faculty advisors to identify potential UCs. %\rr{Moreover, we point out that students may feel unable and unempowered to approach UCs without the support of their peers and advisors.} Nonetheless, we also recognize how throughout the research pipeline, many researchers — including not only graduate students but also faculty members — face knowledge barriers when anticipating UCs. Ultimately, these findings call into question the lack of knowledge-based resources that all researchers face throughout the research pipeline.

Exacerbating these knowledge barriers, \textbf{sharing and learning from prior experiences in computer science is largely unsupported, both individually and at a research community level}. Participants stated that reporting UCs during or after publication made it difficult for other researchers to gain awareness of potential pitfalls others have encountered. For example, P11 shared their process for anticipating UCs and explained how they reviewed \emph{``other papers that do similar work to see how they've done if they documented anything, [but] a lot of times they don't.''} Similarly, P19 suggested \emph{``having checkpoints where you share sort of interim progress that you make with the community''} so that other researchers can identify and anticipate when potential UCs could occur during the research process. Notably, P14 and P16, who realized the UCs of their work only after publication and deployment, reported that they could not revise their papers without either retracting the work altogether or adding significantly more contributions to the original work. As P16 explained:

\begin{quote}
\emph{``And now [that] we're seeing that there are some unintended consequences, there should be a way for me as the researcher, so that I have the responsibility to go over to that, wherever it's published, and comment on it and be like, here's an update or whatever, so that the community knows.''}%[P16]
\end{quote}

To these researchers, reporting UCs was burdensome and potentially harmful to their careers, but they both felt willing and obligated to report these updates. Nonetheless, due to significant structural barriers, none of these researchers were able to share these contributions.

Lastly, many researchers suggested that \textbf{a lack of opportunities to work with collaborators from diverse backgrounds and skill sets also hindered efforts to anticipate UCs}. In general, many researchers believed that more opportunities to work with collaborators from diverse backgrounds and skill sets could better support anticipating UCs by enabling the exchange of different viewpoints (P1-2, P8, P11-12, P14-15). For example, P12 asserted the importance of \emph{``be[ing] able to get feedback from people with different life experiences and expertise.''} \rr{In contrast, several researchers reported attending ethics workshops at conferences enabled them to gain feedback about potential UCs from others (P1, P4, P17). For example, P9 specified that meeting with others at conference workshops allowed \emph{``leading researchers and also students [to] come together, [and] would help the community a lot in terms of figuring out [broader impacts].''} Additionally, two researchers mentioned their participation in university-level ethics board (P12, P18). In particular, P12 shared how their experience with volunteering at their university's ethics board enabled them to \emph{``identify problem[s] that a lot of people face...and provide a resource [of] people who had different research experience in diverse areas''} } P1 also expressed their enthusiasm for greater diversity in computer science labs: 
 
 \begin{quote}
 \emph{``I would [want] to have more people like even just people in my lab that have more diverse experiences and backgrounds. I think that we already do have that and that’s why I’m saying that I’ve noticed that this is super helpful when talking about unintended consequences.''
     }
 \end{quote}
 
\rr{Further, participants explained how several barriers (related to current academic practices, Section 5.3) prevented them from working with others. For example, P3 shared how they usually had enough time to ask for external help only to conduct ``sanity checks'' but otherwise lacked time to officially ``bring in outside experts.'' Other participants intentionally chose to collaborate within their own labs because it was assumed that their peers would offer sufficient feedback and suggest  potential UCs during lab meetings, P13 noted that their lab did not seek external collaborations. }

Participants also specified that diversity and inclusivity had directly impacted their research projects. In particular, P15, an accessibility researcher, shared how a recent collaboration \emph{``with a researcher with a disability''} helped their lab \emph{``[learn] a lot from their experience and [brought] in perspective from those communities.''} Additionally, P14 shared that lacking a diverse team of researchers on a past research experience led to a UC that users found \emph{``deeply offensive''}; P14 also highlighted how this experience led to future collaborations with more diverse teams and the use of participatory design methods. Generally, researchers agreed that diverse researchers could better help anticipate UCs by considering a greater variety of perspectives. 

 
\subsection{Academic Practices Strain Efforts to Anticipate UCs}
\label{5.3}

Despite growing attempts to encourage anticipating UCs in research, we found that \textbf{the ``move-fast'' academic practice strains efforts to consider UCs}. Under this theme, we identified a list of barriers to elaborate how existing academic practices influence researchers’ actions and attitudes towards UCs. In particular, we describe how academic pressures to publish frequently impacts researchers’ considerations of UCs.

First, several participants described that they did not have enough time to devote to thinking about UCs. Participants felt that \textbf{considering UCs was additional work that might conflict with their goals to publish quickly}. To fully consider the social impacts, participants need to balance between moving fast and slowing down to brainstorm the future. Usually researchers chose to move fast, despite their hope to slow down ethically. P3 described their attitudes towards considering UCs while working on research projects: \emph{``
I think we all have a tendency to try to move fast and [think] `Oh no, I don’t want to stop and think about [unintended consequences], I want to keep going [...] to get the results.'''}
%
For example, P1 described that they prioritized the \emph{``technical or theoretical hurdles''} and considering UCs is \emph{``never one of those hurdles [...] never something that you explicitly approached with.''} 

Participants frequently commented that this academic pressure created incentives for producing more publications, rather than promoting ethical considerations. To some participants like P8, the result of this incentives system is the widespread belief that UCs are non-essential and \emph{``just adds more burden on the researcher.''} P19 explained: \emph{``In academia, the incentives are lacking [and] misaligned, which kind of feeds into that broader system and whole obsession over count metrics, so people try as hard as possible to publish as much as fast as possible.''}
%
Similarly, P2 commented: \emph{``
Incentives within [academic] systems may lead [researchers] to prioritize or de-prioritize things based on what’s most valuable: so in academia that will be publications.''}
%
P14, an associate professor in HCI, also scrutinized the research practices of AI and ML researchers, who \emph{``can start a project at the first one month and have a written paper in three months.''} They continued that this oftentimes leads to \emph{``unethical work that have high citation rates and high rates of turning out publications.''}

\textbf{The ``move-fast'' academic practice makes junior researchers difficult to consider UCs.} P7, a full professor at an R1 university, elaborated:
 
 \begin{quote}
     \emph{``[J]unior faculty, sometimes they don't have the time, the mind space, or the clarity to think about these issues, because [they’re] just busy doing other things. I don't fault them for that. It's just [I] don't think we're creating an environment such that they have enough oxygen to think about these issues. So I think that's something for us as a community to think about is just how do we, how do we build a space? And how do we build the time such that people are educated about these issues, and then have the opportunity to develop nuanced thoughts on them?''}
\end{quote}

 Ultimately, these comments by our \participants revealed that the unfortunate by-product of the academic pressure to publish inadvertently encouraged a system where researchers may fail to have the time for, or even see the value of, considering UCs in their research. 
 
 On a positive note, while \participants expressed frustration with the academic system, some also mentioned how things might be slowly starting to change. P15 shared an experience where they worked with a student who pointed out significant ethical considerations that they had overlooked for a research project using information learned from \emph{``a particular [ethics] class that that [the student] took''}.

 As P6, a full professor in NLP, told us:
 
\begin{quote}
\emph{``I have more hope for the new generation, the new generation of students, because they tend to be more concerned about it in general, which might be to do with the fact that they somehow learned about it during their college education, for example, they may have had a class about ethics and inequality.''} %[P6]
\end{quote}

Hence, with an increase in ethics courses, a general increase in awareness, and with systemic changes that mitigate barriers for considering UCs, academics may become more conscientious and incentivized to think about societal impacts of their work in the future. 
