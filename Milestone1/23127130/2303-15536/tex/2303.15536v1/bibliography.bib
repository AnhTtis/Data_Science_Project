@online{heroku,
    title ={Heroku},
    year={2021},
    url = {https://www.heroku.com/},
    lastaccessed = {2021-09-08}
}

@misc{acl, year={2021}, title={ACL establishes its Ethics Committee}, author={Rada Mihalcea}, url={https://www.aclweb.org/portal/content/acl-establishes-its-ethics-committee}, journal={ACL Establishes Its Ethics Committee | ACL Member Portal}} 

@misc{cvpr2022, title={CVPR Ethics Guidelines}, year={2022}, author={CVPR}, url={https://cvpr2022.thecvf.com/ethics-guidelines}, journal={CVPR 2022}} 

@online{medical, 
  title={Ethics Consultations}, 
  year={2021},
  url={https://www.ama-assn.org/delivering-care/ethics/ethics-consultations}, 
  lastaccessed = {2021-09-14},
  organization = {American Medical Association}
} 

 @misc{blog_2016, title={Learning from Tay's introduction}, url={https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/}, journal={The Official Microsoft Blog}, publisher={Microsoft}, author={Lee, Peter}, year={2016}, month={Mar}} 

@misc{micrsoft, title={Microsoft's framework for building AI systems responsibly}, author={Natasha Crampton}, url={https://blogs.microsoft.com/on-the-issues/2022/06/21/microsofts-framework-for-building-ai-systems-responsibly/}, journal={Microsoft On the Issues}, year={2022}, month={Jun}}

@misc{IUI2022,
title={Reflecting on Societal Implications of IUI Research},
author={IUI Program Chairs 2022},
year={2021},
note={\url{https://iui.acm.org/2022/societal_impact.html}, last accessed: September 6, 2021}
}

@article{Abiteboul2019,
author = {Abiteboul, Serge and Stoyanovich, Julia},
title = {Transparency, Fairness, Data Protection, Neutrality: Data Management Challenges in the Face of New Regulation},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {1936-1955},
url = {https://doi.org/10.1145/3310231},
doi = {10.1145/3310231},
journal = {J. Data and Information Quality},
month = {jun},
articleno = {15},
numpages = {9},
keywords = {Transparency, data protection, responsible data science, fairness, neutrality}
}

@article{Abuhamad2020LikeAR,
  title={Like a Researcher Stating Broader Impact For the Very First Time},
  author={Grace Abuhamad and Claudel Rheault},
  journal={ArXiv},
  year={2020},
  volume={abs/2011.13032}
}

@misc{Adar2021,
title={Negative Potential in CS},
author={Adar, Eytan},
year={2018},
note={\url{https://medium.com/@eytanadar/negative-potential-in-cs-b26964b4f502}, last accessed: September 6, 2021}
}

@misc{tarotcards,
title={The Tarot Cards of Tech},
author={{Artefact Group}},
year={2017},
note={\url{http://tarotcardsoftech.artefactgroup.com/}, last accessed: September 6, 2021}
}

@article{ash2007categorizing,
  title={Categorizing the unintended sociotechnical consequences of computerized provider order entry},
  author={Ash, Joan S and Sittig, Dean F and Dykstra, Richard H and Guappone, Kenneth and Carpenter, James D and Seshadri, Veena},
  journal={International journal of medical informatics},
  volume={76},
  pages={S21--S27},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{Jonathan2021,
author = {Barbara, Jonathan and Koenitz, Hartmut and Bakk, \'{A}gnes Karolina},
title = {The Ethics of Virtual Reality Interactive Digital Narratives in Cultural Heritage},
year = {2021},
isbn = {978-3-030-92299-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-92300-6_27},
doi = {10.1007/978-3-030-92300-6_27},
abstract = {As IDNs are used to represent complex phenomena, we are bound to assess the ethical dimension of these representations in order to help IDN mature as a practice and a discipline. In this paper, we consider ethical aspects arising from applications of IDN in VR for Cultural Heritage experiences. Using a discussion of ethical aspects of cultural heritage and virtual reality as a foundation, and considering a range of IDN VR cultural heritage experiences, we derive a set of ethical questions for IDN design in general and for cultural heritage specifically as the basis for the development of standard ethics guidelines and help start a conversation on the topic in the community.},
booktitle = {Interactive Storytelling: 14th International Conference on Interactive Digital Storytelling, ICIDS 2021, Tallinn, Estonia, December 7–10, 2021, Proceedings},
pages = {288–292},
numpages = {5},
keywords = {Cultural heritage, Ethics, Virtual reality, Ethics guidelines, Interactive digital narratives},
location = {Tallinn, Estonia}
}

@inproceedings{Barbosa2019,
author = {Barbosa, Nat\~{a} M. and Chen, Monchu},
title = {Rehumanized Crowdsourcing: A Labeling Framework Addressing Bias and Ethics in Machine Learning},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300773},
doi = {10.1145/3290605.3300773},
abstract = {The increased use of machine learning in recent years led to large volumes of data being manually labeled via crowdsourcing microtasks completed by humans. This brought about dehumanization effects, namely, when task requesters overlook the humans behind the task, leading to issues of ethics (e.g., unfair payment) and amplification of human biases, which are transferred into training data and affect machine learning in the real world. We propose a framework that allocates microtasks considering human factors of workers such as demographics and compensation. We deployed our framework to a popular crowdsourcing platform and conducted experiments with 1,919 workers collecting 160,345 human judgments. By routing microtasks to workers based on demographics and appropriate pay, our framework mitigates biases in the contributor sample and increases the hourly pay given to contributors. We discuss potential extensions and how it can promote transparency in crowdsourcing.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {bias, machine learning, ethics, crowdsourcing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{Bardzell2010FeministHT,
author = {Bardzell, Shaowen},
title = {Feminist HCI: Taking Stock and Outlining an Agenda for Design},
year = {2010},
isbn = {9781605589299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753326.1753521},
doi = {10.1145/1753326.1753521},
abstract = {Feminism is a natural ally to interaction design, due to its central commitments to issues such as agency, fulfillment, identity, equity, empowerment, and social justice. In this paper, I summarize the state of the art of feminism in HCI and propose ways to build on existing successes to more robustly integrate feminism into interaction design research and practice. I explore the productive role of feminism in analogous fields, such as industrial design, architecture, and game design. I introduce examples of feminist interaction design already in the field. Finally, I propose a set of femi-nist interaction design qualities intended to support design and evaluation processes directly as they unfold.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1301–1310},
numpages = {10},
keywords = {feminist design qualities, design, interaction design, feminist HCI, feminist standpoint theory, HCI, gender, feminism},
location = {Atlanta, Georgia, USA},
series = {CHI '10}
}

@article{Behr2005,
author = {Behr, Katharina-Maria and Nosper, Andreas and Klimmt, Christoph and Hartmann, Tilo},
title = {Some Practical Considerations of Ethical Issues in VR Research},
year = {2005},
issue_date = {December 2005},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {14},
number = {6},
issn = {1054-7460},
url = {https://doi.org/10.1162/105474605775196535},
doi = {10.1162/105474605775196535},
abstract = {As scientific laboratories are an important domain of application of VR technology, ethical issues of VR have to be discussed with respect to research and the treatment of research subjects. Exposing participants to VR systems may raise ethical problems due to motion sickness, information overload, intensification of experience, and difficulties with reentry into the real world. The ethical guidelines which are typically applied to psychological research do not cover all of these problems in detail and have to be reconsidered, since they have not been developed with regard to the use of VR systems. Therefore, practical strategies to cope with the addressed ethical problems in VR research are recommended.},
journal = {Presence: Teleoper. Virtual Environ.},
month = {dec},
pages = {668–676},
numpages = {9}
}

 @article{bender2018data,
  title={Data statements for natural language processing: Toward mitigating system bias and enabling better science},
  author={Bender, Emily M and Friedman, Batya},
  journal={Transactions of the Association for Computational Linguistics},
  volume={6},
  pages={587--604},
  year={2018},
  publisher={MIT Press}
}









@article{Bernstein2021EthicsAS,
author = {Michael S. Bernstein  and Margaret Levi  and David Magnus  and Betsy A. Rajala  and Debra Satz  and Quinn Waeiss },
title = {Ethics and society review: Ethics reflection as a precondition to research funding},
journal = {Proceedings of the National Academy of Sciences},
volume = {118},
number = {52},
pages = {e2117261118},
year = {2021},
doi = {10.1073/pnas.2117261118},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2117261118},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2117261118},
abstract = {Researchers in areas as diverse as computer science and political science must increasingly navigate the possible risks of their research to society. However, the history of medical experiments on vulnerable individuals influenced many research ethics reviews to focus exclusively on risks to human subjects rather than risks to human society. We describe an Ethics and Society Review board (ESR), which fills this moral gap by facilitating ethical and societal reflection as a requirement to access grant funding: Researchers cannot receive grant funding from participating programs until the researchers complete the ESR process for their proposal. Researchers author an initial statement describing their proposed research’s risks to society, subgroups within society, and globally and commit to mitigation strategies for these risks. An interdisciplinary faculty panel iterates with the researchers to refine these risks and mitigation strategies. We describe a mixed-method evaluation of the ESR over 1 y, in partnership with an artificial intelligence grant program run by Stanford HAI. Surveys and interviews of researchers who interacted with the ESR found 100\% (95\% CI: 87 to 100\%) were willing to continue submitting future projects to the ESR, and 58\% (95\% CI: 37 to 77\%) felt that it had influenced the design of their research project. The ESR panel most commonly identified issues of harms to minority groups, inclusion of diverse stakeholders in the research plan, dual use, and representation in datasets. These principles, paired with possible mitigation strategies, offer scaffolding for future research designs.}}


@online{NeurIps2021,
organization={NeurIPS},
title = {Introducing the NeurIPS 2021 Paper Checklist},
author = {Beygelzimer, Alina and Dauphin, Yann and Liang, Percy and Vaughan, Jennifer Wortman},
year = {2021},
url = {https://neuripsconf.medium.com/introducing-the-neurips-2021-paper-checklist-3220d6df500b},
}

@inproceedings{bjorn2018research,
author = {Bjorn, Pernille and Fiesler, Casey and Muller, Michael and Pater, Jessica and Wisniewski, Pamela},
title = {Research Ethics Town Hall Meeting},
year = {2018},
isbn = {9781450355629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3148330.3154523},
doi = {10.1145/3148330.3154523},
abstract = {As technology and data access continue to evolve, research ethics in the areas of Human-Computer Interaction and social computing are becoming increasingly complex. Despite increasing interest among researchers, there is still a lack of consistent community norms around ethical gray areas. One charge of the SIGCHI ethics committee is to help develop these norms by facilitating open conversations with different stakeholders. This panel will be an opportunity to develop a collective understanding of diverse perspectives on ethics, and to gather input from the GROUP research community around the ethical challenges we face as researchers who study social and collaborative computing systems and those who use these systems.},
booktitle = {Proceedings of the 2018 ACM International Conference on Supporting Group Work},
pages = {393–396},
numpages = {4},
keywords = {research methods, research ethics, ethics, social norms, social computing},
location = {Sanibel Island, Florida, USA},
series = {GROUP '18}
}

@article{bourabain2021everyday,
  title={Everyday sexism and racism in the ivory tower: The experiences of early career researchers on the intersection of gender and ethnicity in the academic workplace},
  author={Bourabain, Dounia},
  journal={Gender, Work \& Organization},
  volume={28},
  number={1},
  pages={248--267},
  year={2021},
  publisher={Wiley Online Library}
}

@inproceedings{branham2014co,
author = {Branham, Stacy M. and Thieme, Anja and Nathan, Lisa P. and Harrison, Steve and Tatar, Deborah and Olivier, Patrick},
title = {Co-Creating I\&; Identity-Making in CSCW: Revisiting Ethics in Design Research},
year = {2014},
isbn = {9781450325417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556420.2558859},
doi = {10.1145/2556420.2558859},
abstract = {The evolving philosophies, methods, and products of CSCW design research are more collaborative and value-active than ever. Researchers and participants may co-construct designs, thus sharing power; they may share intimate life stories over design probes, thus pushing socio-cultural boundaries; they may seek personal fulfillment through the products or the process. How do these experiences affect researcher and co-creator identity in the moment of co-work? How do these changes reconfigure other relationships and encounters? This workshop invites discussants from across disciplines to consider phenomenological aspects of identity-making and to unpack ethical dilemmas that arise when we appreciate the potential for design research itself to significantly harm or help participants. At stake are CSCW policies, best practices, and collective understandings of what it means to be a design researcher.},
booktitle = {Proceedings of the Companion Publication of the 17th ACM Conference on Computer Supported Cooperative Work I\& Social Computing},
pages = {305–308},
numpages = {4},
keywords = {participatory design, experience-centered design, empathy, reflection, identity, critical design, ethics, design research},
location = {Baltimore, Maryland, USA},
series = {CSCW Companion '14}
}

@article{braun2006using,
title={Using thematic analysis in psychology},
author={Braun, Virginia and Clarke, Victoria},
journal={Qualitative research in psychology},
volume={3},
number={2},
pages={77--101},
year={2006},
publisher={Taylor \& Francis}
}

@inproceedings{brown2016five,
author = {Brown, Barry and Weilenmann, Alexandra and McMillan, Donald and Lampinen, Airi},
title = {Five Provocations for Ethical HCI Research},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858313},
doi = {10.1145/2858036.2858313},
abstract = {We present five provocations for ethics, and ethical research, in HCI. We discuss, in turn, informed consent, the researcher-participant power differential, presentation of data in publications, the role of ethical review boards, and, lastly, corporate-facilitated projects. By pointing to unintended consequences of regulation and oversimplifications of unresolvable moral conflicts, we propose these provocations not as guidelines or recommendations but as instruments for challenging our views on what it means to do ethical research in HCI. We then suggest an alternative grounded in the sensitivities of those being studied and based on everyday practice and judgement, rather than one driven by bureaucratic, legal, or philosophical concerns. In conclusion, we call for a wider and more practical discussion on ethics within the community, and suggest that we should be more supportive of low-risk ethical experimentation to further the field.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {852–863},
numpages = {12},
keywords = {ethics, human trials, research practice},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{brown2020language,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 address={NeurIPS 2020},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}


@inproceedings{bruckman2017cscw,
author = {Bruckman, Amy S. and Fiesler, Casey and Hancock, Jeff and Munteanu, Cosmin},
title = {CSCW Research Ethics Town Hall: Working Towards Community Norms},
year = {2017},
isbn = {9781450346887},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3022198.3022199},
doi = {10.1145/3022198.3022199},
abstract = {As technologies as well as research practice evolve, new ethical challenges emerge within the CSCW research community. Currently, norms around what constitutes ethical practice in research are scattered and inconsistent. We face a number of open ethical questions around issues such as informed consent, anonymization, Terms of Service, deleted content, and what constitutes public data. The SIGCHI Ethics Committee has been looking towards ways to encourage norm setting and mitigate ethical disagreement during the peer review process. This town hall style panel will be an opportunity to prompt community discussion and collect input into how we can further address these challenges.},
booktitle = {Companion of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
pages = {113–115},
numpages = {3},
keywords = {professional ethics, research ethics},
location = {Portland, Oregon, USA},
series = {CSCW '17 Companion}
}

@article{cabitza2017unintended,
  title={Unintended consequences of machine learning in medicine},
  author={Cabitza, Federico and Rasoini, Raffaele and Gensini, Gian Franco},
  journal={Jama},
  volume={318},
  number={6},
  pages={517--518},
  year={2017},
  publisher={American Medical Association}
}

@article{chivukula2021surveying,
  author    = {Shruthi Sai Chivukula and
               Ziqing Li and
               Anne C. Pivonka and
               Jingning Chen and
               Colin M. Gray},
  title     = {Surveying the Landscape of Ethics-Focused Design Methods},
  journal   = {CoRR},
  volume    = {abs/2102.08909},
  year      = {2021},
  url       = {https://arxiv.org/abs/2102.08909},
  eprinttype = {arXiv},
  eprint    = {2102.08909},
  pages = {1-23},
  timestamp = {Fri, 19 Feb 2021 11:02:14 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2102-08909.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


 @article{Chowdhery2022PaLMSL,
  title={PaLM: Scaling Language Modeling with Pathways},
  author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek B Rao and Parker Barnes and Yi Tay and Noam M. Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Benton C. Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garc{\'i}a and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Oliveira Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark D{\'i}az and Orhan Firat and Michele Catasta and Jason Wei and Kathleen S. Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.02311}
}

@inproceedings{cockburn2018hark,
author = {Cockburn, Andy and Gutwin, Carl and Dix, Alan},
title = {HARK No More: On the Preregistration of CHI Experiments},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173715},
doi = {10.1145/3173574.3173715},
abstract = {Experimental preregistration is required for publication in many scientific disciplines and venues. When experimental intentions are preregistered, reviewers and readers can be confident that experimental evidence in support of reported hypotheses is not the result of HARKing, which stands for Hypothesising After the Results are Known. We review the motivation and outcomes of experimental preregistration across a variety of disciplines, as well as previous work commenting on the role of evaluation in HCI research. We then discuss how experimental preregistration could be adapted to the distinctive characteristics of Human-Computer Interaction empirical research, to the betterment of the discipline.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {replication, p-fishing, harking, nhst controversy, experimental preregistration, file drawer effect},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@article{del2016spreading,
  title={The spreading of misinformation online},
  author={Del Vicario, Michela and Bessi, Alessandro and Zollo, Fabiana and Petroni, Fabio and Scala, Antonio and Caldarelli, Guido and Stanley, H Eugene and Quattrociocchi, Walter},
  journal={Proceedings of the National Academy of Sciences},
  volume={113},
  number={3},
  pages={554--559},
  year={2016},
  publisher={National Acad Sciences}
}

@incollection{d2018chapter,
  title={Chapter Seven: The Power Chapter},
  author={D'Ignazio, Catherine and Klein, Lauren},
  booktitle={Data Feminism},
  year={2018},
  publisher={PubPub}
}

@article{echeverri2018unintended,
  title={Unintended consequences on gender diversity of high-tech growth and labor market polarization},
  author={Echeverri-Carroll, Elsie L and Oden, Michael D and Gibson, David V and Johnston, Evan A},
  journal={Research Policy},
  volume={47},
  number={1},
  pages={209--217},
  year={2018},
  publisher={Elsevier}
}

@misc{eveleth_2018, 
title={Google Glass wasn't a failure. it raised crucial concerns}, 
url={https://www.wired.com/story/google-glass-reasonable-expectation-of-privacy/}, 
journal={Wired}, 
publisher={Conde Nast}, 
author={Eveleth, Rose}, 
year={2018}, 
month={Dec}} 
 
@inproceedings{fiesler2021sigchi,
author = {Fiesler, Casey and Densmore, Melissa and Muller, Michael and Munteanu, Cosmin},
title = {SIGCHI Research Ethics Committee Town Hall},
year = {2021},
isbn = {9781450384797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3462204.3483283},
doi = {10.1145/3462204.3483283},
abstract = {Since 2016, the SIGCHI Research Ethics Committee has been in place to advise CSCW and other SIGCHI conferences and communities on ethical issues that arise in the course of our research. This town hall style panel provides an annual opportunity to connect with the committee, which has a remit to report back to the HCI research community on issues that arise as our methods, technologies, and best practices evolve.},
booktitle = {Companion Publication of the 2021 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {232–233},
numpages = {2},
keywords = {research methods, research ethics, privacy, ethics, social computing},
location = {Virtual Event, USA},
series = {CSCW '21}
}

@inproceedings{fiesler2020we,
author = {Fiesler, Casey and Garrett, Natalie and Beard, Nathan},
title = {What Do We Teach When We Teach Tech Ethics? A Syllabi Analysis},
year = {2020},
isbn = {9781450367936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328778.3366825},
doi = {10.1145/3328778.3366825},
abstract = {As issues of technology ethics become more pervasive in the media and public discussions, there is increasing interest in what role ethics should play in computing education. Not only are there more standalone ethics classes being offered at universities, but calls for greater integration of ethics across computer science curriculum mean that a growing number of CS instructors may be including ethics as part of their courses. To both describe current trends in computing ethics coursework and to provide guidance for further ethics inclusion in computing, we present an in-depth qualitative analysis of 115 syllabi from university technology ethics courses. Our analysis contributes a snapshot of the content and goals of tech ethics classes, and recommendations for how these might be integrated across a computing curriculum.},
booktitle = {Proceedings of the 51st ACM Technical Symposium on Computer Science Education},
pages = {289–295},
numpages = {7},
keywords = {curriculum, syllabi, professional responsibility, ethics},
location = {Portland, OR, USA},
series = {SIGCSE '20}
}

@inproceedings{fiesler2015ethics,
author = {Fiesler, Casey and Young, Alyson and Peyton, Tamara and Bruckman, Amy S. and Gray, Mary and Hancock, Jeff and Lutters, Wayne},
title = {Ethics for Studying Online Sociotechnical Systems in a Big Data World},
year = {2015},
isbn = {9781450329460},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2685553.2685558},
doi = {10.1145/2685553.2685558},
abstract = {The evolution of social technology and research methods present ongoing challenges to studying people online. Recent high-profile cases have prompted discussion among both the research community and the general public about the ethical implications of researching humans, their information, and their activities in large-scale digital contexts. Examples of scientific and market research involving Facebook users and OKCupid clients exemplify the ethical complexities of both studying and manipulating online user behavior. When does data science become human subjects research, and what are our obligations to these subjects as researchers' Drawing from previous work around the ethics of digital research, one goal of this workshop is to work towards a set of guiding principles for CSCW scholars doing research online.},
booktitle = {Proceedings of the 18th ACM Conference Companion on Computer Supported Cooperative WorkI\& Social Computing},
pages = {289–292},
numpages = {4},
keywords = {big data, research ethics, sociotechnical systems, online communities},
location = {Vancouver, BC, Canada},
series = {CSCW'15 Companion}
}

@inproceedings{frauenberger2017research,
author = {Frauenberger, Christopher and Bruckman, Amy S. and Munteanu, Cosmin and Densmore, Melissa and Waycott, Jenny},
title = {Research Ethics in HCI: A Town Hall Meeting},
year = {2017},
isbn = {9781450346566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027063.3051135},
doi = {10.1145/3027063.3051135},
abstract = {As interactive technologies evolve and reach into every aspect of modern life, research practices in human-computer interaction (HCI) have changed. The methodological and epistemological foundations of the field are shifting to reflect the diversity of contexts in which rapidly changing digital technology is being used. Alongside these changes, new ethical challenges emerge for the HCI community, both in terms of research ethics and responsible research and innovation. Open dilemmas include issues such as the shifting meaning of informed consent, anonymisation or privacy in an always-online world. The SIGCHI Ethics Committee has been established to look into the processes, practices and structures at SIGCHI venues to deal with such ethical dilemmas and how they can be addressed in a transparent, consistent and open way. This town hall style panel will be an opportunity to prompt community discussion and collect input into how we can further address these challenges.},
booktitle = {Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
pages = {1295–1299},
numpages = {5},
keywords = {HCI, ethics},
location = {Denver, Colorado, USA},
series = {CHI EA '17}
}

@book{friedman2019value,
    address={Cambridge, MA, USA},
    author = {Friedman, Batya and Hendry, David G.},
    title = "{Value Sensitive Design: Shaping Technology with Moral Imagination}",
    publisher = {The MIT Press},
    year = {2019},
    month = {05},
    abstract = "{Using our moral and technical imaginations to create responsible innovations: theory, method, and applications for value sensitive design.Implantable medical devices and human dignity. Private and secure access to information. Engineering projects that transform the Earth. Multigenerational information systems for international justice. How should designers, engineers, architects, policy makers, and others design such technology? Who should be involved and what values are implicated? In Value Sensitive Design, Batya Friedman and David Hendry describe how both moral and technical imagination can be brought to bear on the design of technology. With value sensitive design, under development for more than two decades, Friedman and Hendry bring together theory, methods, and applications for a design process that engages human values at every stage.After presenting the theoretical foundations of value sensitive design, which lead to a deep rethinking of technical design, Friedman and Hendry explain seventeen methods, including stakeholder analysis, value scenarios, and multilifespan timelines. Following this, experts from ten application domains report on value sensitive design practice. Finally, Friedman and Hendry explore such open questions as the need for deeper investigation of indirect stakeholders and further method development.This definitive account of the state of the art in value sensitive design is an essential resource for designers and researchers working in academia and industry, students in design and computer science, and anyone working at the intersection of technology and society.}",
    isbn = {9780262351690},
    doi = {10.7551/mitpress/7585.001.0001},
    url = {https://doi.org/10.7551/mitpress/7585.001.0001},
}


@article{friedman2008value,
  title={Value sensitive design and information systems},
  author={Friedman, Batya and Kahn, Peter H and Borning, Alan},
  journal={The handbook of information and computer ethics},
  pages={69--101},
  year={2008},
  volume={1},
  number={1},
  publisher={Wiley Online Library},
  doi={10.1002/9780470281819.ch4}
}

@misc{EnvisioningCards,
title = {Envisioning Cards}, 
author={Friedman, Batya and Nathan, Lisa and Kane, Shaun and Lin, John},
url = {https://www.envisioningcards.com/},
year={2018}
}

@inproceedings{johnsonopen,
author = {G Johnson, Ian and Crivellaro, Clara},
title = {Opening Research Commissioning To Civic Participation: Creating A Community Panel To Review The Social Impact of HCI Research Proposals},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445113},
doi = {10.1145/3411764.3445113},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {597},
numpages = {17},
keywords = {HCI research, commissioning, Social justice HCI, design, participation},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{g2021co,
author = {G. Pillai, Ajit and Baki Kocaballi, A. and Wah Leong, Tuck and A. Calvo, Rafael and Parvin, Nassim and Shilton, Katie and Waycott, Jenny and Fiesler, Casey and C. Havens, John and Ahmadpour, Naseem},
title = {Co-Designing Resources for Ethics Education in HCI},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3441349},
doi = {10.1145/3411763.3441349},
abstract = {Due to the evolving nature of technology and its impact on individuals, communities and society, practitioners and designers in Human-Computer Interaction (HCI) are expected to consider ethics in their work. This role has inspired the development of a number of resources for practice, such as tools, frameworks and methods to tackle ethical issues in HCI. But these suffer from low adoption rate potentially because they are not yet part of the standard body of knowledge. To mitigate the issue, we argue that there is an urgent need for ethics education in HCI. Beyond defining ethics, an ethics curriculum must enable practitioners to reflect and allow consideration of intended and unintended consequences of the technologies they create from the ground up, rather than as a fix or an afterthought. In this co-design workshop, we aim to build upon existing practices and knowledge of ethics in HCI and work with the CHI community to enrich ethics curriculum. We will scaffold our collective understandings of the existing resources and create guidelines that support interactive educational experiences to support HCI ethics curriculum.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {109},
numpages = {5},
keywords = {Applied Ethics, HCI Education, Co-design},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@article{gebru2021datasheets,
  title={Datasheets for datasets},
  author={Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Iii, Hal Daum{\'e} and Crawford, Kate},
  journal={Communications of the ACM},
  volume={64},
  number={12},
  pages={86--92},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{datasheet,
  author    = {Timnit Gebru and
               Jamie Morgenstern and
               Briana Vecchione and
               Jennifer Wortman Vaughan and
               Hanna M. Wallach and
               Hal Daum{\'{e}} III and
               Kate Crawford},
  title     = {Datasheets for Datasets},
  journal   = {CoRR},
  volume    = {abs/1803.09010},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.09010},
  eprinttype = {arXiv},
  eprint    = {1803.09010},
  pages = {1-11},
  timestamp = {Mon, 20 Aug 2018 15:16:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-09010.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Gotterbarn2018ACMCO,
  title={ACM Code of Ethics and Professional Conduct},
  author={Donald Gotterbarn and Bo Brinkman and Catherine Flick and Michael S. Kirkpatrick and Keith W. Miller and Kate Vazansky and Marty J. Wolf},
  year={2018}
}

@inproceedings{grimpe2014towards,
author = {Grimpe, Barbara and Hartswood, Mark and Jirotka, Marina},
title = {Towards a Closer Dialogue between Policy and Practice: Responsible Design in HCI},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557364},
doi = {10.1145/2556288.2557364},
abstract = {Given the potent and pervasive nature of modern technologies, this paper lays out the complexities involved in achieving responsible design. In order to do this we will first compare an emerging policy-oriented programme of research known as RRI (Responsible Research and Innovation) with initiatives in HCI. A focus on the similarities and differences may highlight to what extent responsibility is already and successfully embedded within the concerns and practices of design and use, and what may yet need to be incorporated for responsible design. The paper then discusses the challenges of 'naturalising' the very ambitious programme of RRI within specific design activities and concerns, through the lens of four analytic concepts: reflexivity; responsiveness; inclusion; and anticipation. Finally, we make a case for a pragmatic, 'unromantic', but engaged reinterpretation of RRI for HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2965–2974},
numpages = {10},
keywords = {governance, value-sensitive design, responsible design, innovation, ethics, user-centered design, critical design, risk society, participatory design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{gray2019ethical,
author = {Gray, Colin M. and Chivukula, Shruthi Sai},
title = {Ethical Mediation in UX Practice},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300408},
doi = {10.1145/3290605.3300408},
abstract = {HCI scholars have become increasingly interested in describing the complex nature of UX practice. In parallel, HCI and STS scholars have sought to describe the ethical and value-laden relationship between designers and design outcomes. However, little research describes the ethical engagement of UX practitioners as a form of design complexity, including the multiple mediating factors that impact ethical awareness and decision-making. In this paper, we use a practice-led approach to describe ethical complexity, presenting three varied cases of UX practitioners based onin situ observations and interviews. In each case, we describe salient factors relating to ethical mediation, including organizational practices, self-driven ethical principles, and unique characteristics of specific projects the practitioner is engaged in. Using the concept of mediation from activity theory, we provide a rich account of practitioners' ethical decision making. We propose future work on ethical awareness and design education based on the concept of ethical mediation.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {mediation, practice-led research, applied ethics, ux design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@article{haimson2016constructing, title={Constructing and enforcing "authentic" identity online: Facebook, real names, and non-normative identities}, volume={21}, url={https://journals.uic.edu/ojs/index.php/fm/article/view/6791}, DOI={10.5210/fm.v21i6.6791}, abstractNote={I\&lt;pI\&gt;Despite the participatory and democratic promises of Web 2.0, many marginalized individuals with fluid or non-normative identities continue to struggle to represent themselves online. Facebook users, in particular, are told to use “authentic identities,” an idea reinforced throughout the site’s documentation, “real name” and other policies, and in public statements by company representatives. Facebook’s conception of authenticity and real names, however, has created problems for certain users, as demonstrated by the systematic deactivation of many accounts belonging to transgender and gender variant users, drag queens, Native Americans, abuse survivors, and others. In view of the struggles of marginalized users, Facebook policy appears paradoxical: the site simultaneously demands authenticity yet proscribes certain people from authentic self-presentation. In this work, we examine Facebook’s construction of “authenticity” and show how it excludes multifaceted, fluid, or non-normative identities. Using content analysis and close reading, we analyze site documentation and data from I\&lt;emI\&gt;The Zuckerberg FilesI\&lt;/emI\&gt; (an online archive of Facebook founder and CEO Mark Zuckerberg’s public remarks) to understand the platform’s mechanisms for enforcing authenticity. We find that Facebook positions itself as a type of administrative identity registrar, raising vital questions regarding the ethics and consequences of identity enforcement online today.I\&lt;/pI\&gt;}, number={6}, journal={First Monday}, author={Haimson, Oliver L. and Hoffmann, Anna Lauren}, year={2016}, month={Jun.}, pages={1-6}}

@inproceedings{hajian2016,
author = {Hajian, Sara and Bonchi, Francesco and Castillo, Carlos},
title = {Algorithmic Bias: From Discrimination Discovery to Fairness-Aware Data Mining},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2945386},
doi = {10.1145/2939672.2945386},
abstract = {Algorithms and decision making based on Big Data have become pervasive in all aspects of our daily lives lives (offline and online), as they have become essential tools in personal finance, health care, hiring, housing, education, and policies. It is therefore of societal and ethical importance to ask whether these algorithms can be discriminative on grounds such as gender, ethnicity, or health status. It turns out that the answer is positive: for instance, recent studies in the context of online advertising show that ads for high-income jobs are presented to men much more often than to women [Datta et al., 2015]; and ads for arrest records are significantly more likely to show up on searches for distinctively black names [Sweeney, 2013]. This algorithmic bias exists even when there is no discrimination intention in the developer of the algorithm. Sometimes it may be inherent to the data sources used (software making decisions based on data can reflect, or even amplify, the results of historical discrimination), but even when the sensitive attributes have been suppressed from the input, a well trained machine learning algorithm may still discriminate on the basis of such sensitive attributes because of correlations existing in the data. These considerations call for the development of data mining systems which are discrimination-conscious by-design. This is a novel and challenging research area for the data mining community.The aim of this tutorial is to survey algorithmic bias, presenting its most common variants, with an emphasis on the algorithmic techniques and key ideas developed to derive efficient solutions. The tutorial covers two main complementary approaches: algorithms for discrimination discovery and discrimination prevention by means of fairness-aware data mining. We conclude by summarizing promising paths for future research.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {2125–2126},
numpages = {2},
keywords = {discrimination prevention, algorithmic bias, discrimination discovery},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@article{hand2010citizen,
  title={Citizen science: People power},
  author={Hand, Eric},
  journal={Nature News},
  volume={466},
  number={7307},
  pages={685--687},
  year={2010},
  publisher={Nature Publishing Group}
}

@inproceedings{hankerson2016does,
author = {Hankerson, David and Marshall, Andrea R. and Booker, Jennifer and Elmimouni, Houda and Walker, Imani and Rode, Jennifer A.},
title = {Does Technology Have Race?},
year = {2016},
isbn = {9781450340823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851581.2892578},
doi = {10.1145/2851581.2892578},
abstract = {This paper started as a response to the "Black Lives Matter" campaign in the USA, and emerged as a critique of race more generally in technology design. This paper provides case studies of how technologies are often less usable by persons of color, and contextualizes this in light of intersectionalist theory. Finally, it discusses how the HCI community can ameliorate the situation, and our obligation to do so in light of the ACM code of ethics.},
booktitle = {Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
pages = {473–486},
numpages = {14},
keywords = {computing, racism, race, social justice},
location = {San Jose, California, USA},
series = {CHI EA '16}
}

@article{harrison2007unintended,
  title={Unintended consequences of information technologies in health care—an interactive sociotechnical analysis},
  author={Harrison, Michael I and Koppel, Ross and Bar-Lev, Shirly},
  journal={Journal of the American medical informatics Association},
  volume={14},
  number={5},
  pages={542--549},
  year={2007},
  publisher={BMJ Group BMA House, Tavistock Square, London, WC1H 9JR}
}

@article{Hecht2021ItsTT,
author    = {Brent J. Hecht and
               Lauren Wilcox and
               Jeffrey P. Bigham and
               Johannes Sch{\"{o}}ning and
               Ehsan Hoque and
               Jason Ernst and
               Yonatan Bisk and
               Luigi De Russis and
               Lana Yarosh and
               Bushra Anjum and
               Danish Contractor and
               Cathy Wu},
  title     = {It's Time to Do Something: Mitigating the Negative Impacts of Computing
               Through a Change to the Peer Review Process},
  journal   = {CoRR},
  volume    = {abs/2112.09544},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.09544},
  eprinttype = {arXiv},
  eprint    = {2112.09544},
  timestamp = {Thu, 17 Nov 2022 11:44:52 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-09544.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  pages={1-6}
}

@proceedings{ws-2017-acl,
    title = "Proceedings of the First {ACL} Workshop on Ethics in Natural Language Processing",
    editor = "Hovy, Dirk  and
      Spruit, Shannon  and
      Mitchell, Margaret  and
      Bender, Emily M.  and
      Strube, Michael  and
      Wallach, Hanna",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-1600",
    doi = "10.18653/v1/W17-16",
}

@article{huntington1971change,
  title={The change to change: Modernization, development, and politics},
  author={Huntington, Samuel P},
  journal={Comparative politics},
  volume={3},
  number={3},
  pages={283--322},
  year={1971},
  publisher={JSTOR}
}

@misc{icsme,
title={ICSME Registered Reports Track},
author={{ICSME 2021}},
year={2021},
note={\url{https://icsme2021.github.io/cfp/RegisteredReportsTrack.html}, last accessed: September 6, 2021}
}

@inproceedings{ingram2010,
author = {Ingram, Brandon and Jones, Daniel and Lewis, Andrew and Richards, Matthew and Rich, Charles and Schachterle, Lance},
title = {A Code of Ethics for Robotics Engineers},
year = {2010},
isbn = {9781424448937},
publisher = {IEEE Press},
abstract = {The future of robotics engineering is in the hands of engineers and must be handled to ensure the safety of all people and the reputation of the field. We are in the process of developing a code of ethics for professional robotics engineers to serve as a guideline for the ethical development of the field. This document contains the current version of this code and describes the methodology used in developing it.},
booktitle = {Proceedings of the 5th ACM/IEEE International Conference on Human-Robot Interaction},
pages = {103–104},
numpages = {2},
keywords = {code, robotics engineering, ethics},
address = {Osaka, Japan},
series = {HRI '10}
}

@inproceedings{irani2010postcolonial,
author = {Irani, Lilly and Vertesi, Janet and Dourish, Paul and Philip, Kavita and Grinter, Rebecca E.},
title = {Postcolonial Computing: A Lens on Design and Development},
year = {2010},
isbn = {9781605589299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753326.1753522},
doi = {10.1145/1753326.1753522},
abstract = {As our technologies travel to new cultural contexts and our designs and methods engage new constituencies, both our design and analytical practices face significant challenges. We offer postcolonial computing as an analytical orientation to better understand these challenges. This analytic orientation inspires four key shifts in our approach to HCI4D efforts: generative models of culture, development as a historical program, uneven economic relations, and cultural epistemologies. Then, through reconsideration of the practices of engagement, articulation and translation in other contexts, we offer designers and researchers ways of understanding use and design practice to respond to global connectivity and movement.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1311–1320},
numpages = {10},
keywords = {postcolonial theory, design methods, culture, sts, ict4d},
location = {Atlanta, Georgia, USA},
series = {CHI '10}
}

 @misc{jiang_2021, 
 title={Towards machine ethics and norms}, 
 url={https://blog.allenai.org/towards-machine-ethics-and-norms-d64f2bdde6a3}, 
 journal={Medium}, publisher={AI2 Blog}, 
 author={Jiang, Liwei}, 
 year={2021}, 
 month={Nov}}
 
 @article{johnson1985computer,
  title={Computer ethics},
  author={Johnson, Deborah G},
  journal={Englewood Cliffs (NJ)},
  volume={10},
  pages={102926},
  year={1985}
}

@article{kertysova2018artificial,
  title={Artificial Intelligence and Disinformation: How AI Changes the Way Disinformation is Produced, Disseminated, and Can Be Countered},
  author={Kertysova, Katarina},
  journal={Security and Human Rights},
  volume={29},
  number={1-4},
  pages={55--81},
  year={2018},
  publisher={Brill Nijhoff}
}

@article{Klein2002TheSC,
  title={The Social Construction of Technology: Structural Considerations},
  author={Hans K. Klein and Daniel Lee Kleinman},
  journal={Science, Technology, \& Human Values},
  year={2002},
  volume={27},
  pages={28 - 52}
}

@article{kling1991computerization,
  title={Computerization and social transformations},
  author={Kling, Rob},
  journal={Science, Technology, \& Human Values},
  volume={16},
  number={3},
  pages={342--367},
  year={1991},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@book{kling1996computerization,
  title={Computerization and controversy: Value conflicts and social choices},
  author={Kling, Rob},
  year={1996},
  address={Amsterdam, Netherlands},
  publisher={Elsevier}
}

@article{kling2007social,
  title={What is social informatics and why does it matter?},
  author={Kling, Rob},
  journal={The Information Society},
  volume={23},
  number={4},
  pages={205--220},
  year={2007},
  publisher={Taylor \& Francis}
}

@book{knight1921risk,
  title={Risk, uncertainty and profit},
  author={Knight, Frank Hyneman},
  volume={31},
  address={Wilmington, Delaware, USA},
  year={1921},
  publisher={Houghton Mifflin}
}

@article{koenecke2020racial,
  title={Racial disparities in automated speech recognition},
  author={Koenecke, Allison and Nam, Andrew and Lake, Emily and Nudell, Joe and Quartey, Minnie and Mengesha, Zion and Toups, Connor and Rickford, John R and Jurafsky, Dan and Goel, Sharad},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={14},
  pages={7684--7689},
  year={2020},
  publisher={National Acad Sciences}
}

@inproceedings{Koya2020MeasuringIO,
author = {Koya, Kushwanth and Chowdhury, Gobinda},
title = {Measuring Impact of Academic Research in Computer and Information Science on Society},
year = {2020},
isbn = {9781450376853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379310.3379312},
doi = {10.1145/3379310.3379312},
abstract = {Academic research in computer &amp; information science (CIS) has contributed immensely to all aspects of society. As academic research today is substantially supported by various government sources, recent political changes have created ambivalence amongst academics about the future of research funding. With uncertainty looming, it is important to develop a framework to extract and measure the information relating to impact of CIS research on society to justify public funding, and demonstrate the actual contribution and impact of CIS research outside academia. A new method combining discourse analysis and text mining of a collection of over 1000 pages of impact case study documents written in free-text format for the Research Excellence Framework (REF) 2014 was developed in order to identify the most commonly used categories or headings for reporting impact of CIS research by UK Universities (UKU). According to the research reported in REF2014, UKU acquired 83 patents in various areas of CIS, created 64 spin-offs, generated £857.5 million in different financial forms, created substantial employment, reached over 6 billion users worldwide and has helped save over £1 billion Pounds due to improved processes etc. to various sectors internationally, between 2008 and 2013.},
booktitle = {Proceedings of the 2020 2nd Asia Pacific Information Technology Conference},
pages = {78–85},
numpages = {8},
keywords = {research impact, information science, research funding, computer science},
location = {Bali Island, Indonesia},
series = {APIT 2020}
}

@article{kraut1998internet,
  title={Internet paradox: A social technology that reduces social involvement and psychological well-being?},
  author={Kraut, Robert and Patterson, Michael and Lundmark, Vicki and Kiesler, Sara and Mukophadhyay, Tridas and Scherlis, William},
  journal={American psychologist},
  volume={53},
  number={9},
  pages={1017},
  year={1998},
  publisher={American Psychological Association}
}

@misc{kurenkov_2022, title={Lessons from the gpt-4chan controversy}, url={https://thegradient.pub/gpt-4chan-lessons/}, journal={The Gradient}, publisher={The Gradient}, author={Kurenkov, Andrey}, year={2022}, month={Jun}} 
   
@article{Lindley2017ImplicationsFA,
  title={Implications for Adoption},
  author={Joseph Lindley and Paul Coulton and Miriam Sturdee},
  journal={Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
  year={2017}
}

@inproceedings{Linxen2021,
author = {Linxen, Sebastian and Sturm, Christian and Br\"{u}hlmann, Florian and Cassau, Vincent and Opwis, Klaus and Reinecke, Katharina},
title = {How WEIRD is CHI?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445488},
doi = {10.1145/3411764.3445488},
abstract = {Computer technology is often designed in technology hubs in Western countries, invariably making it “WEIRD”, because it is based on the intuition, knowledge, and values of people who are Western, Educated, Industrialized, Rich, and Democratic. Developing technology that is universally useful and engaging requires knowledge about members of WEIRD and non-WEIRD societies alike. In other words, it requires us, the CHI community, to generate this knowledge by studying representative participant samples. To find out to what extent CHI participant samples are from Western societies, we analyzed papers published in the CHI proceedings between 2016-2020. Our findings show that 73\% of CHI study findings are based on Western participant samples, representing less than 12\% of the world’s population. Furthermore, we show that most participant samples at CHI tend to come from industrialized, rich, and democratic countries with generally highly educated populations. Encouragingly, recent years have seen a slight increase in non-Western samples and those that include several countries. We discuss suggestions for further broadening the international representation of CHI participant samples.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {143},
numpages = {14},
keywords = {WEIRD, geographic diversity, sample bias, HCI research, generalizability},
location = {Yokohama, Japan},
series = {CHI '21}
}

@incollection{machidon2018societal,
  title={Societal implications of current and emerging “smart” technologies},
  author={Machidon, Octavian Mihai},
  booktitle={Smart Technologies: Breakthroughs in Research and Practice},
  pages={305--317},
  year={2018},
  address = {Country unknown/Code not available},
  publisher={IGI Global}
}

@inproceedings{mackay1995ethics,
author = {Mackay, Wendy E.},
title = {Ethics, Lies and Videotape…},
year = {1995},
isbn = {0201847051},
publisher = {ACM Press/Addison-Wesley Publishing Co.},
address = {USA},
url = {https://doi.org/10.1145/223904.223922},
doi = {10.1145/223904.223922},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {138–145},
numpages = {8},
location = {Denver, Colorado, USA},
series = {CHI '95}
}

@inproceedings{madaio2020co,
author = {Madaio, Michael A. and Stark, Luke and Wortman Vaughan, Jennifer and Wallach, Hanna},
title = {Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376445},
doi = {10.1145/3313831.3376445},
abstract = {Many organizations have published principles intended to guide the ethical development and deployment of AI systems; however, their abstract nature makes them difficult to operationalize. Some organizations have therefore produced AI ethics checklists, as well as checklists for more specific concepts, such as fairness, as applied to AI systems. But unless checklists are grounded in practitioners' needs, they may be misused. To understand the role of checklists in AI ethics, we conducted an iterative co-design process with 48 practitioners, focusing on fairness. We co-designed an AI fairness checklist and identified desiderata and concerns for AI fairness checklists in general. We found that AI fairness checklists could provide organizational infrastructure for formalizing ad-hoc processes and empowering individual advocates. We highlight aspects of organizational culture that may impact the efficacy of AI fairness checklists, and suggest future design directions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {checklists, ethics, ML, co-design, fairness, AI},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{mcmillan2013categorised,
author = {McMillan, Donald and Morrison, Alistair and Chalmers, Matthew},
title = {Categorised Ethical Guidelines for Large Scale Mobile HCI},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466245},
doi = {10.1145/2470654.2466245},
abstract = {The recent rise in large scale trials of mobile software using 'app stores' has moved current researcher practice beyond available ethical guidelines. By surveying this recent and growing body of literature, as well as established professional principles adopted in psychology, we propose a set of ethical guidelines for large scale HCI user trials. These guidelines come in two parts: a set of general principles and a framework into which individual app store-based trials can be assessed and ethical concerns exposed. We categorise existing literature using our scheme, and explain how researchers could use our framework to classify their future user trials to determine ethical responsibility, and the steps required to meet these obligations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1853–1862},
numpages = {10},
keywords = {mass participation, ethics, large-scale trials, app stores},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{Menking:2019,
 author = {Menking, Amanda and Erickson, Ingrid and Pratt, Wanda},
 title = {People Who Can Take It: How Women Wikipedians Negotiate and Navigate Safety},
 booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '19},
 year = {2019},
 isbn = {978-1-4503-5970-2},
 location = {Glasgow, Scotland Uk},
 pages = {472:1--472:14},
 articleno = {472},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/3290605.3300702},
 doi = {10.1145/3290605.3300702},
 acmid = {3300702},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {gender gap, online communities, participation, safe spaces, safety, wikipedia},
} 

@article{merton1936unanticipated,
  title={The unanticipated consequences of purposive social action},
  author={Merton, Robert K},
  journal={American sociological review},
  volume={1},
  number={6},
  pages={894--904},
  year={1936},
  publisher={JSTOR}
}

@article{metcalf2019owning,
  title={Owning Ethics: Corporate Logics, Silicon Valley, and the Institutionalization of Ethics},
  author={Metcalf, Jacob and Moss, Emanuel and others},
  journal={Social Research: An International Quarterly},
  volume={86},
  number={2},
  pages={449--476},
  year={2019},
  publisher={Johns Hopkins University Press}
}

@article{miller2020introducing,
  title={Introducing Foldit education mode},
  author={Miller, Josh Aaron and Khatib, Firas and Hammond, Haley and Cooper, Seth and Horowitz, Scott},
  journal={Nature Structural \& Molecular Biology},
  volume={27},
  number={9},
  pages={769--770},
  year={2020},
  publisher={Nature Publishing Group}
}

@inproceedings{mitchell2019model,
  title={Model cards for model reporting},
  author={Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={220--229},
  year={2019}
}

@article{mohammad2021ethics,
  title={Ethics sheets for AI tasks},
  author={Mohammad, Saif M},
  journal={arXiv preprint arXiv:2107.01183},
  year={2021}
}

@article{moor1985computer,
  title={What is computer ethics?},
  author={Moor, James H},
  journal={Metaphilosophy},
  volume={16},
  number={4},
  pages={266--275},
  year={1985},
  publisher={JSTOR}
}

@inproceedings{Moser:2016,
 author = {Moser, Carol and Schoenebeck, Sarita Y. and Reinecke, Katharina},
 title = {Technology at the Table: Attitudes About Mobile Phone Use at Mealtimes},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI)},
 series = {CHI '16},
 year = {2016},
 isbn = {978-1-4503-3362-7},
 location = {Santa Clara, California, USA},
 pages = {1881--1892},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2858036.2858357},
 doi = {10.1145/2858036.2858357},
 acmid = {2858357},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {attitudes, mealtimes, mobile phones, norms, social media},
} 

@inproceedings{Mumford1983DesigningHS,
  title={Designing Human Systems For New Technology: The Ethics Method},
  author={Enid Mumford},
  year={1983}
}

@inproceedings{munteanu2019sigchi,
author = {Munteanu, Cosmin and Bruckman, Amy and Muller, Michael and Frauenberger, Christopher and Fiesler, Casey and Kraut, Robert E. and Shilton, Katie and Waycott, Jenny},
title = {SIGCHI Research Ethics Town Hall},
year = {2019},
isbn = {9781450359719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290607.3311742},
doi = {10.1145/3290607.3311742},
abstract = {An ongoing challenge within the diverse HCI and social computing research communities is understanding research ethics in the face of evolving technology and methods. Building upon successful town hall meetings at CHI 2018, GROUP 2018 and CSCW 2018, this panel will be structured to facilitate audience discussion and to collect input about current challenges and processes. It will be led by members of the ACM SIGCHI Research Ethics Committee. We will pose open questions and invite audience discussion of practices centered on recent "hot topic" issues. For this year's town hall, the primary focus will be on paths to balancing the often-competing regulatory frameworks under which we operate (some of which having recently undergone significant revisions) with our community's efforts to reveal ethical challenges posed by new interactive technologies and new contexts of use. We will engage the audience in discussions on whether there is a non-colonial role for ethics education within the broad HCI community, how that may capture the cultural and disciplinary differences that are woven into CHI's fabric, and how research ethical issues should be handled in SIGCHI paper submission and review process.},
booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
location = {Glasgow, Scotland Uk},
series = {CHI EA '19}
}

@inproceedings{nanayakkara2021unpacking,
author = {Nanayakkara, Priyanka and Hullman, Jessica and Diakopoulos, Nicholas},
title = {Unpacking the Expressed Consequences of AI Research in Broader Impact Statements},
year = {2021},
isbn = {9781450384735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461702.3462608},
doi = {10.1145/3461702.3462608},
abstract = {The computer science research community and the broader public have become increasingly aware of negative consequences of algorithmic systems. In response, the top-tier Neural Information Processing Systems (NeurIPS) conference for machine learning and artificial intelligence research required that authors include a statement of broader impact to reflect on potential positive and negative consequences of their work. We present the results of a qualitative thematic analysis of a sample of statements written for the 2020 conference. The themes we identify broadly fall into categories related to how consequences are expressed (e.g., valence, specificity, uncertainty), areas of impacts expressed (e.g., bias, the environment, labor, privacy), and researchers' recommendations for mitigating negative consequences in the future. In light of our results, we offer perspectives on how the broader impact statement can be implemented in future iterations to better align with potential goals.},
booktitle = {Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {795–806},
numpages = {12},
keywords = {broader impacts, anticipatory governance, ai ethics, thematic analysis},
location = {Virtual Event, USA},
series = {AIES '21}
}

@inproceedings{Nathan2008,
author = {Nathan, Lisa P. and Friedman, Batya and Klasnja, Predrag and Kane, Shaun K. and Miller, Jessica K.},
title = {Envisioning Systemic Effects on Persons and Society throughout Interactive System Design},
year = {2008},
isbn = {9781605580029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1394445.1394446},
doi = {10.1145/1394445.1394446},
abstract = {The design, development, and deployment of interactive systems can substantively impact individuals, society, and the natural environment, now and potentially well into the future. Yet, a scarcity of methods exists to support long-term, emergent, systemic thinking in interactive design practice. Toward addressing this gap, we propose four envisioning criteria --- stakeholders, time, values, and pervasiveness -- distilled from prior work in urban planning, design noir, and Value Sensitive Design. We characterize how the criteria can support systemic thinking, illustrate the integration of the envisioning criteria into established design practice (scenariobased design), and provide strategic activities to serve as generative envisioning tools. We conclude with suggestions for use and future work. Key contributions include: 1) four envisioning criteria to support systemic thinking, 2) value scenarios (extending scenario-based design), and 3) strategic activities for engaging the envisioning criteria in interactive system design practice.},
booktitle = {Proceedings of the 7th ACM Conference on Designing Interactive Systems},
pages = {1–10},
numpages = {10},
keywords = {scenario-based design, values, urban planning, design methods, sustainability, value scenarios, envisioning, design noir, value sensitive design, ubiquitous computing},
location = {Cape Town, South Africa},
series = {DIS '08}
}

@article{nissenbaum1996accountability,
  title={Accountability in a computerized society},
  author={Nissenbaum, Helen},
  journal={Science and engineering ethics},
  volume={2},
  number={1},
  pages={25--42},
  year={1996},
  publisher={Springer}
}

@inproceedings{Norman1993ThingsTM,
  title={Things That Make Us Smart: Defending Human Attributes In The Age Of The Machine},
  author={Donald A. Norman},
  year={1993}
}

 @misc{openai_2022, 
 title={Dalle-2-preview/system-card.md at main · openai/dalle-2-preview}, 
 url={https://github.com/openai/dalle-2-preview/blob/main/system-card.md}, 
 journal={GitHub}, 
 author={Openai}, 
 year={2022}, 
 month={Jul}} 
 
@inbook{parker1995all,
author = {Parker, Donn B. and Swope, Susan and Baker, Bruce N. and Weiss, Eric A.},
title = {All in a Day's Work: Nine Provocative Examples in the Practice of Computing Professionals},
year = {1995},
isbn = {0124150403},
publisher = {Academic Press, Inc.},
address = {USA},
booktitle = {Computerization and Controversy (2nd Ed.): Value Conflicts and Social Choices},
pages = {870–875},
numpages = {6}
}

@article{parvin2020unintended,
  title={Unintended by Design: On the Political Uses of “Unintended Consequences”},
  author={Parvin, Nassim and Pollock, Anne},
  journal={Engaging Science, Technology, and Society},
  volume={6},
  pages={320--327},
  year={2020}
}	

@misc{pereidadiversity,
  title={Diversity in robotics: From diverse teams to diverse impact},
  author={Pereida, Karime and Greef, M},
  year={2020}
}

@article{prunkl2021institutionalizing,
  title={Institutionalizing ethics in AI through broader impact requirements},
  author={Prunkl, Carina EA and Ashurst, Carolyn and Anderljung, Markus and Webb, Helena and Leike, Jan and Dafoe, Allan},
  journal={Nature Machine Intelligence},
  volume={3},
  number={2},
  pages={104--110},
  year={2021},
  publisher={Nature Publishing Group}
}

@inproceedings{raji2020closing,
author = {Raji, Inioluwa Deborah and Smart, Andrew and White, Rebecca N. and Mitchell, Margaret and Gebru, Timnit and Hutchinson, Ben and Smith-Loud, Jamila and Theron, Daniel and Barnes, Parker},
title = {Closing the AI Accountability Gap: Defining an End-to-End Framework for Internal Algorithmic Auditing},
year = {2020},
isbn = {9781450369367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3351095.3372873},
doi = {10.1145/3351095.3372873},
abstract = {Rising concern for the societal implications of artificial intelligence systems has inspired a wave of academic and journalistic literature in which deployed systems are audited for harm by investigators from outside the organizations deploying the algorithms. However, it remains challenging for practitioners to identify the harmful repercussions of their own systems prior to deployment, and, once deployed, emergent issues can become difficult or impossible to trace back to their source.In this paper, we introduce a framework for algorithmic auditing that supports artificial intelligence system development end-to-end, to be applied throughout the internal organization development life-cycle. Each stage of the audit yields a set of documents that together form an overall audit report, drawing on an organization's values or principles to assess the fit of decisions made throughout the process. The proposed auditing framework is intended to contribute to closing the accountability gap in the development and deployment of large-scale artificial intelligence systems by embedding a robust process to ensure audit integrity.},
booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
pages = {33–44},
numpages = {12},
keywords = {accountability, algorithmic audits, machine learning, responsible innovation},
location = {Barcelona, Spain},
series = {FAT* '20}
}

@article{Ramirez2018,
author = {Ramirez, Erick Jose and Labarge, Scott},
title = {Real Moral Problems in the Use of Virtual Reality},
year = {2018},
issue_date = {December  2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {4},
issn = {1388-1957},
url = {https://doi.org/10.1007/s10676-018-9473-5},
doi = {10.1007/s10676-018-9473-5},
abstract = {In this paper, we argue that, under a specific set of circumstances, designing and employing certain kinds of virtual reality (VR) experiences can be unethical. After a general discussion of simulations and their ethical context, we begin our argument by distinguishing between the experiences generated by different media (text, film, computer game simulation, and VR simulation), and argue that VR experiences offer an unprecedented degree of what we call "perspectival fidelity" that prior modes of simulation lack. Additionally, we argue that when VR experiences couple this perspectival fidelity with what we call "context realism," VR experiences have the ability to produce "virtually real experiences." We claim that virtually real experiences generate ethical issues for VR technologies that are unique to the medium. Because subjects of these experiences treat them as if they were real, a higher degree of ethical scrutiny should be applied to any VR scenario with the potential to generate virtually real experiences. To mitigate this unique moral hazard, we propose and defend what we call "The Equivalence Principle." This principle states that "if it would be wrong to allow subjects to have a certain experience in reality, then it would be wrong to allow subjects to have that experience in a virtually real setting." We argue that such a principle, although limited in scope, should be part of the risk analysis conducted by any Institutional Review Boards, psychologists, empirically oriented philosophers, or game designers who are using VR technology in their work.},
journal = {Ethics and Inf. Technol.},
month = {dec},
pages = {249–263},
numpages = {15},
keywords = {Applied ethics, Moral psychology, Institutional review boards, Virtual Reality, Phenomenology, Media experience}
}

@article{reyns2013unintended,
  title={The unintended consequences of digital technology: Exploring the relationship between sexting and cybervictimization},
  author={Reyns, Bradford W and Burek, Melissa W and Henson, Billy and Fisher, Bonnie S},
  journal={Journal of Crime and Justice},
  volume={36},
  number={1},
  pages={1--17},
  year={2013},
  publisher={Taylor \& Francis}
}

@article{robertson2018,
author = {Robertson, Ronald E. and Jiang, Shan and Joseph, Kenneth and Friedland, Lisa and Lazer, David and Wilson, Christo},
title = {Auditing Partisan Audience Bias within Google Search},
year = {2018},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CSCW},
url = {https://doi.org/10.1145/3274417},
doi = {10.1145/3274417},
abstract = {There is a growing consensus that online platforms have a systematic influence on the democratic process. However, research beyond social media is limited. In this paper, we report the results of a mixed-methods algorithm audit of partisan audience bias and personalization within Google Search. Following Donald Trump's inauguration, we recruited 187 participants to complete a survey and install a browser extension that enabled us to collect Search Engine Results Pages (SERPs) from their computers. To quantify partisan audience bias, we developed a domain-level score by leveraging the sharing propensities of registered voters on a large Twitter panel. We found little evidence for the "filter bubble'' hypothesis. Instead, we found that results positioned toward the bottom of Google SERPs were more left-leaning than results positioned toward the top, and that the direction and magnitude of overall lean varied by search query, component type (e.g. "answer boxes"), and other factors. Utilizing rank-weighted metrics that we adapted from prior work, we also found that Google's rankings shifted the average lean of SERPs to the right of their unweighted average.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {148},
numpages = {22},
keywords = {search engine rankings, filter bubble, algorithm auditing, quantifying partisan bias, political personalization}
}

@article{rogers2021changing,
  title={Changing the world by changing the data},
  author={Rogers, Anna},
  journal={arXiv preprint arXiv:2105.13947},
  year={2021}
}

@article{Rogers1976NewPA,
  title={New Product Adoption and Diffusion},
  author={Everett M. Rogers},
  journal={Journal of Consumer Research},
  year={1976},
  volume={2},
  pages={290-301}
}

@inproceedings{sap2019risk,
    title = "The Risk of Racial Bias in Hate Speech Detection",
    author = "Sap, Maarten  and
      Card, Dallas  and
      Gabriel, Saadia  and
      Choi, Yejin  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1163",
    doi = "10.18653/v1/P19-1163",
    pages = "1668--1678",
    abstract = "We investigate how annotators{'} insensitivity to differences in dialect can lead to racial bias in automatic hate speech detection models, potentially amplifying harm against minority populations. We first uncover unexpected correlations between surface markers of African American English (AAE) and ratings of toxicity in several widely-used hate speech datasets. Then, we show that models trained on these corpora acquire and propagate these biases, such that AAE tweets and tweets by self-identified African Americans are up to two times more likely to be labelled as offensive compared to others. Finally, we propose *dialect* and *race priming* as ways to reduce the racial bias in annotation, showing that when annotators are made explicitly aware of an AAE tweet{'}s dialect they are significantly less likely to label the tweet as offensive.",
}

@article{sawyer2005social,
  title={Social informatics: Overview, principles and opportunities},
  author={Sawyer, Steve},
  journal={Bulletin of the American Society for Information Science and Technology},
  volume={31},
  number={5},
  pages={9--12},
  year={2005},
  publisher={Wiley Online Library}
}

@inproceedings{registration,
author = {Pang, Yuren and Reinecke, Katharina and Just, Ren\'{e}},
title = {Ap\'{e}ritif: Scaffolding Preregistrations to Automatically Generate Analysis Code and Methods Descriptions},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517707},
doi = {10.1145/3491102.3517707},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {207},
numpages = {15},
keywords = {Reproducibility, Preregistration, Experiment design, Data analysis},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{bates2019towards,
author = {Bates, Oliver and New, Kathy and Mitchell-Finnigan, Samantha and Mauriello, Matthew Louis and Remy, Christian and Bendor, Roy and Mann, Samuel and Chopra, Simran and Clear, Adrian K. and Preist, Chris},
title = {Towards a Responsible Innovation Agenda for HCI},
year = {2019},
isbn = {9781450359719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290607.3299017},
doi = {10.1145/3290607.3299017},
abstract = {In recent years responsible innovation has gained significant traction and can be seen to adorn a myriad of research platforms, education programs, and policy frameworks. In this workshop, we invite HCI researchers to discuss the relations between the CHI community and responsible innovation. This workshop looks to build provocations and principles for and with HCI researchers who are or wish to become responsible innovators. The workshop looks to do this by asking attendees to think about the social, environmental, and economic impacts of ICT and HCI and explore how research innovation frameworks speak to responsible HCI innovation. Through the workshop we look to examine 5 questions to develop a set of provocations and principles, which will help encourage HCI and computer science researchers, educators, and innovators to reflect on the impact of their research and innovation.},
booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {responsible innovation, social justice, climate change, global eco-innovation, ethics},
location = {Glasgow, Scotland Uk},
series = {CHI EA '19}
}

@inproceedings{shen2021value,
author = {Shen, Hong and Deng, Wesley H. and Chattopadhyay, Aditi and Wu, Zhiwei Steven and Wang, Xu and Zhu, Haiyi},
title = {Value Cards: An Educational Toolkit for Teaching Social Impacts of Machine Learning through Deliberation},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445971},
doi = {10.1145/3442188.3445971},
abstract = {Recently, there have been increasing calls for computer science curricula to complement existing technical training with topics related to Fairness, Accountability, Transparency and Ethics (FATE). In this paper, we present Value Cards, an educational toolkit to inform students and practitioners the social impacts of different machine learning models via deliberation. This paper presents an early use of our approach in a college-level computer science course. Through an in-class activity, we report empirical data for the initial effectiveness of our approach. Our results suggest that the use of the Value Cards toolkit can improve students' understanding of both the technical definitions and trade-offs of performance metrics and apply them in real-world contexts, help them recognize the significance of considering diverse social values in the development and deployment of algorithmic systems, and enable them to communicate, negotiate and synthesize the perspectives of diverse stakeholders. Our study also demonstrates a number of caveats we need to consider when using the different variants of the Value Cards toolkit. Finally, we discuss the challenges as well as future applications of our approach.},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {850–861},
numpages = {12},
keywords = {Machine Learning, Fairness, Deliberation, CS Education, Value Cards},
location = {Virtual Event, Canada},
series = {FAccT '21}
}

@article{Shilton2018ValuesAE,
  title={Values and Ethics in Human-Computer Interaction},
  author={Katie Shilton},
  journal={Found. Trends Hum. Comput. Interact.},
  year={2018},
  volume={12},
  pages={107-171}
}

@inproceedings{siangliulue15:toward,
	Acmid = {2675239},
	Address = {New York, NY, USA},
	Author = {Siangliulue, Pao and Arnold, Kenneth C. and Gajos, Krzysztof Z. and Dow, Steven P.},
	Booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work \& Social Computing},
	Date-Added = {2015-08-18 11:59:14 +0000},
	Date-Modified = {2016-01-31 15:27:11 +0000},
	Doi = {10.1145/2675133.2675239},
	Isbn = {978-1-4503-2922-4},
	Keywords = {collaborative ideation, creativity, inspirational examples},
	Location = {Vancouver, BC, Canada},
	Numpages = {9},
	Pages = {937--945},
	Publisher = {ACM},
	Series = {CSCW '15},
	Title = {Toward Collaborative Ideation at Scale: Leveraging Ideas from Others to Generate More Creative and Diverse Ideas},
	Url = {http://doi.acm.org/10.1145/2675133.2675239},
	Year = {2015},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2675133.2675239},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2675133.2675239}}

@article{starbird2017examining, title={Examining the Alternative Media Ecosystem Through the Production of Alternative Narratives of Mass Shooting Events on Twitter}, volume={11}, url={https://ojs.aaai.org/index.php/ICWSM/article/view/14878}, DOI={10.1609/icwsm.v11i1.14878}, abstractNote={ &lt;p&gt; This research explores the alternative media ecosystem through a Twitter lens. Over a ten-month period, we collected tweets related to alternative narratives — for example, conspiracy theories — of mass shooting events. We utilized tweeted URLs to generate a domain network, connecting domains shared by the same user, then conducted qualitative analysis to understand the nature of different domains and how they connect to each other. Our findings demonstrate how alternative news sites propagate and shape alternative narratives, while mainstream media deny them. We explain how political leanings of alternative news sites do not align well with a U.S. left-right spectrum, but instead feature an anti-globalist (versus globalist) orientation where U.S. Alt-Right sites look similar to U.S. Alt-Left sites. Our findings describe a subsection of the emerging alternative media ecosystem and provide insight in how websites that promote conspiracy theories and pseudo-science may function to conduct underlying political agendas. &lt;/p&gt; }, number={1}, journal={Proceedings of the International AAAI Conference on Web and Social Media}, author={Starbird, Kate}, year={2017}, month={May}, pages={230-239} }

@online{ACL2022, 
title={Guidelines for ethics reviewing}, url={https://aclrollingreview.org/ethicsreviewertutorial}, journal={ACL Rolling Review}, 
publisher={Association for Computational Linguistics}, organization={Association for Computational Linguistics}, 
author={Stent, Amanda}, 
editor={Baldwin, Tim and Rogers, Anna and Chang, Kai-Wei and Yang, DiyiEditors}, 
year={2022}
} 

@inproceedings{Stephanidis:1998p118,
author = {C. Stephanidis}, 
booktitle = {{Conference on Technology and Persons with Disabilities}},
title = {{Designing User Interfaces for All}},
year = {1998}
}

@article{stoyanovich2022responsible,
  title={Responsible data management},
  author={Stoyanovich, Julia and Abiteboul, Serge and Howe, Bill and Jagadish, HV and Schelter, Sebastian},
  journal={Communications of the ACM},
  volume={65},
  number={6},
  pages={64--74},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@inproceedings{sturdee2021,
author = {Sturdee, Miriam and Lindley, Joseph and Linehan, Conor and Elsden, Chris and Kumar, Neha and Dillahunt, Tawanna and Mandryk, Regan and Vines, John},
title = {Consequences, Schmonsequences! Considering the Future as Part of Publication and Peer Review in Computing Research},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3441330},
doi = {10.1145/3411763.3441330},
abstract = {Research in computing is becoming increasingly concerned with understanding and mitigating unintended consequences of technology developments. However, those concerns are rarely reflected in how we submit, review, and publish our own work. Specifically, in talking about how our new apps, devices, and algorithms will change the world, we focus almost exclusively on positive consequences. There have been calls to require some speculation about negative impacts as part of the peer review process. This workshop will explore how to think about and report potential negative consequences in our papers in a way that’s practical, inclusive, and achievable. The aim is to draw on scholarship around creative-yet-grounded speculation about technology futures and to consider how these might be applied to publication and peer review. The workshop aims to inspire the CHI conference and the computing research community to meaningfully consider and act upon the potential negative implications of their work.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {95},
numpages = {4},
keywords = {publication, peer review, consequences, ideation, futuring},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{Suchman1987PlansAS,
  title={Plans and situated actions - the problem of human-machine communication},
  author={Lucy A. Suchman},
  booktitle={Learning in doing: social,cognitive,and computational perspectives},
  year={1987}
}

@inproceedings{sveiby2009unintended,
  title={Unintended and undesirable consequences of innovation},
  booktitle={Unintended and undesirable consequences of innovation},
  author={Sveiby, Karl-Erik and Gripenberg, Pernilla and Segercrantz, Beata and Eriksson, Andreas and Aminoff, Alexander},
  publisher={XX ISPIM conference, The Future of Innovation. Vienna},
  pages={1},
  year={2009},
  address={Country unknown/Code not available}
}

@inproceedings{Tojo2022,
author = {Tojo, Naoya and Yoshida, Haruka and Oto, Tomoko and Niida, Sumaru},
title = {How Can We Expand Unintended Outcomes in Participatory Design?},
year = {2022},
isbn = {9781450396813},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3537797.3537873},
doi = {10.1145/3537797.3537873},
abstract = {This paper investigates the mechanisms by which design deliverables contribute to other design activities in unintended contexts in a participatory design (PD). Specifically, this paper focuses on the need-solution pair (NSP) problem-solving process, an emerging concept in organizational economics. We first briefly introduce this concept and then investigate the implication of a viable NSP search in relation to PD. This exploration is exemplified by a case study in the field of well-being, which presents the key elements of NSP problem solving in PD. The nature of PD such as democratic participation, empowerment, and respect for field sites can make the NSP search more effective and enriching, and the results of participatory NSP problem solving have the potential to integrate activities of participant groups in different contexts and reconfigure them as an ecosystem that makes them contribute to each other.},
booktitle = {Proceedings of the Participatory Design Conference 2022 - Volume 2},
pages = {191–195},
numpages = {5},
keywords = {participatory design, need-solution pair search, unintended aspect of solutions, problem solving, design context},
location = {Newcastle upon Tyne, United Kingdom},
series = {PDC '22}
}

 @book{toyama2015geek, address={New York, NY}, title={Geek heresy: Rescuing social change from the cult of Technology}, publisher={Pereus Books Group}, author={Toyama, Kentaro}, year={2015}} 

@article{Truong2017,
author = {Truong, Khai},
title = {Pilot Studies: When and How to Conduct Them When Conducting User Studies},
year = {2017},
issue_date = {October 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {4},
issn = {2375-0529},
url = {https://doi.org/10.1145/3081016.3081020},
doi = {10.1145/3081016.3081020},
abstract = {Evaluating an interactive system with users can be costly and timeconsuming. As a result, it can be extremely frustrating for evaluators whenever they are not able to use any of the data collected from the user evaluation of a system because of problems with how the study was designed or executed. In such instances, evaluators must learn from their mistakes and rerun the study a second time. However, the time, effort, and resources that went into completing the study the first time is still wasted. This problem can be minimized by first conducting a pilot study -- a small-scale version of the actual study -- prior to the final study, to identify, remove, and avoid any potential problems.},
journal = {GetMobile: Mobile Comp. and Comm.},
month = {apr},
pages = {8–11},
numpages = {4}
}

@inproceedings{unethically,
author = {van Leeuwen, Cora and Elprama, Shirley A. and Jacobs, An and Heyman, Rob and Pierson, Jo and Duysburgh, Pieter},
title = {Unethically Me: Explaining Artificial Intelligence’s Results by Being Unethical},
year = {2020},
isbn = {9781450375795},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419249.3420065},
doi = {10.1145/3419249.3420065},
abstract = {The goal of this workshop is to examine what is needed to explain artificial intelligence (AI) for lay end-users. In a full day workshop we want to engage with an interdisciplinary group of researchers to find best practices in explaining and interpreting results from AI for those with only with limited knowledge of AI.},
booktitle = {Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society},
articleno = {139},
numpages = {3},
keywords = {Explainability, HCI Design},
location = {Tallinn, Estonia},
series = {NordiCHI '20}
}


@inproceedings{vanderelst2018,
author = {Vanderelst, Dieter and Winfield, Alan},
title = {The Dark Side of Ethical Robots},
year = {2018},
isbn = {9781450360128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278721.3278726},
doi = {10.1145/3278721.3278726},
abstract = {Concerns over the risks associated with advances in Artificial Intelligence have prompted calls for greater efforts toward robust and beneficial AI, including machine ethics. Recently, roboticists have responded by initiating the development of so-called ethical robots. These robots would, ideally, evaluate the consequences of their actions and morally justify their choices. This emerging field promises to develop extensively over the next few years. However, in this paper, we point out an inherent limitation of the emerging field of ethical robots. We show that building ethical robots also inevitably enables the construction of unethical robots. In three experiments, we show that it is remarkably easy to modify an ethical robot so that it behaves competitively, or even aggressively. The reason for this is that the cognitive machinery required to make an ethical robot can always be corrupted to make unethical robots. We discuss the implications of this finding to the governance of ethical robots. We conclude that the risks that unscrupulous actors might compromise a robot's ethics are so great as to raise serious doubts over the wisdom of embedding ethical decision making in real-world safety-critical robots, such as driverless cars.},
booktitle = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {317–322},
numpages = {6},
keywords = {malicious use, machine ethics, ethical governance, cybersecurity, ethical robots},
location = {New Orleans, LA, USA},
series = {AIES '18}
}

@article{vieira2021understanding,
  title={Understanding the societal impacts of machine translation: a critical review of the literature on medical and legal use cases},
  author={Vieira, Lucas Nunes and O’Hagan, Minako and O’Sullivan, Carol},
  journal={Information, Communication \& Society},
  volume={24},
  number={11},
  pages={1515--1532},
  year={2021},
  publisher={Taylor \& Francis}
}

@article{vitak2017ethics,
  title={Ethics regulation in social computing research: Examining the role of institutional review boards},
  author={Vitak, Jessica and Proferes, Nicholas and Shilton, Katie and Ashktorab, Zahra},
  journal={Journal of Empirical Research on Human Research Ethics},
  volume={12},
  number={5},
  pages={372--382},
  year={2017},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@inproceedings{vitak2016beyond,
author = {Vitak, Jessica and Shilton, Katie and Ashktorab, Zahra},
title = {Beyond the Belmont Principles: Ethical Challenges, Practices, and Beliefs in the Online Data Research Community},
year = {2016},
isbn = {9781450335928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2818048.2820078},
doi = {10.1145/2818048.2820078},
abstract = {Pervasive information streams that document people and their routines have been a boon to social computing research. But the ethics of collecting and analyzing availableI\&-but potentially sensitive-online data present challenges to researchers. In response to increasing public and scholarly debate over the ethics of online data research, this paper analyzes the current state of practice among researchers using online data. Qualitative and quantitative responses from a survey of 263 online data researchers document beliefs and practices around which social computing researchers are converging, as well as areas of ongoing disagreement. The survey also reveals that these disagreements are not correlated with disciplinary, methodological, or workplace affiliations. The paper concludes by reflecting on changing ethical practices in the digital age, and discusses a set of emergent best practices for ethical social computing research.},
booktitle = {Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work I\& Social Computing},
pages = {941–953},
numpages = {13},
keywords = {big data, researchers, privacy, social computing, academia, Ethics, online data},
location = {San Francisco, California, USA},
series = {CSCW '16}
}


@inproceedings{Walsh2018,
author = {Walsh, Greg},
title = {Towards Equity and Equality in American Co-Design: A Case Study},
year = {2018},
isbn = {9781450351522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3202185.3202768},
doi = {10.1145/3202185.3202768},
abstract = {Co-design is considered a powerful tool to empower users to be part of the design process. In the United States, co-design with children is often associated with academic organizations. In one form of co-design, Cooperative Inquiry, children and adults design together in a lab environment. Unfortunately, children who live in non-affluent areas may have trouble participating in groups like this because they are unable to attend design sessions due to a combination of lack of transit options or parental involvement.This paper reflects on four years of co-design in an American, economically depressed city with the sole purpose of trying to include more voices in the design process. Working within and then beyond Cooperative Inquiry, the authors discuss the city's history of racial segregation and classism and how researchers can be more equitable and equal in their construction of co-design teams in urban environments. Shorter, more focused design sessions in locations easily accessible by children are the key to more inclusive co-design.},
booktitle = {Proceedings of the 17th ACM Conference on Interaction Design and Children},
pages = {434–440},
numpages = {7},
keywords = {co-design, equity, children, participatory design},
location = {Trondheim, Norway},
series = {IDC '18}
}

  @article{wang2018deep,
  title={Deep neural networks are more accurate than humans at detecting sexual orientation from facial images.},
  author={Wang, Yilun and Kosinski, Michal},
  journal={Journal of personality and social psychology},
  volume={114},
  number={2},
  pages={246},
  year={2018},
  publisher={American Psychological Association}
}

@inproceedings{waycott2016ethical,
author = {Waycott, Jenny and Munteanu, Cosmin and Davis, Hilary and Thieme, Anja and Moncur, Wendy and McNaney, Roisin and Vines, John and Branham, Stacy},
title = {Ethical Encounters in Human-Computer Interaction},
year = {2016},
isbn = {9781450340823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851581.2856498},
doi = {10.1145/2851581.2856498},
abstract = {In the HCI community, there is growing recognition that a reflective and empathetic approach is needed to conduct ethical research in sensitive settings with people who might be considered vulnerable or marginalized. At our CHI 2015 workshop on ethical encounters, researchers shared personal stories of the challenges and tensions they have faced when conducting HCI research in complex settings such as hospitals, with young mental health patients, in schools for children with disabilities, and with homeless people. These research contexts can present significant challenges for HCI researchers who would not typically receive the training that other professionals working in these environments would normally receive. From our discussions with attendees at the CHI 2015 workshop, we identified a number of ethical issues that researchers are grappling with. In this follow-up workshop we aim to build on the lessons learned and to generate pragmatic but sensitive solutions to manage complex ethical issues for HCI researchers working in challenging settings.},
booktitle = {Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
pages = {3387–3394},
numpages = {8},
keywords = {vulnerable participants, sensitive settings, ethics},
location = {San Jose, California, USA},
series = {CHI EA '16}
}

@inproceedings{wilson2011replichi,
author = {Wilson, Max L. and Mackay, Wendy and Chi, Ed and Bernstein, Michael and Russell, Dan and Thimbleby, Harold},
title = {RepliCHI - CHI Should Be Replicating and Validating Results More: Discuss},
year = {2011},
isbn = {9781450302685},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1979742.1979491},
doi = {10.1145/1979742.1979491},
abstract = {The replication of research findings is a cornerstone of good science. Replication confirms results, strengthens research, and makes sure progress is based on solid foundations. CHI, however, rewards novelty and is focused on new results. As a community, therefore, we do not value, facilitate, or reward replication in research, and often take the significant results of a single user study on 20 users to be true. This panel will address the issues surrounding replication in our community, and discuss: a) how much of our broad diverse discipline is 'science', b) how, if at all, we currently see replication of research in our community, c) whether we should place more emphasis on replication in some form, and d) how that should look in our community. The aim of the panel is to make a proposal to future CHI organizers (2 are on the panel) for how we should facilitate replication in the future.},
booktitle = {CHI '11 Extended Abstracts on Human Factors in Computing Systems},
pages = {463–466},
numpages = {4},
keywords = {research, replication, science, hci},
location = {Vancouver, BC, Canada},
series = {CHI EA '11}
}

@article{winner2017artifacts,
 ISSN = {00115266},
 URL = {http://www.jstor.org/stable/20024652},
 author = {Langdon Winner},
 journal = {Daedalus},
 number = {1},
 pages = {121--136},
 publisher = {The MIT Press},
 title = {Do Artifacts Have Politics?},
 urldate = {2022-09-10},
 volume = {109},
 year = {1980}
}

@book{winner2010whale,
  title={The Whale and the Reactor: A Search for Limits in an Age of High Technology},
  author={Winner, Langdon},
  year={1986},
  address={Chicago, IL},
  publisher={University of Chicago Press}
}

@inproceedings{Yoo:2018,
author = {Yoo, Daisy},
title = {Stakeholder Tokens: A Constructive Method for Value Sensitive Design Stakeholder Analysis},
year = {2017},
isbn = {9781450349918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3064857.3079161},
doi = {10.1145/3064857.3079161},
abstract = {Central to a value sensitive design approach is identifying key stakeholders and providing a rationale for their inclusion in the design process. Stakeholder analysis may require extensive conceptual and empirical work. Yet it is often unclear how to effectively do so. This paper introduces a new method for designers to better understand stakeholders and their dynamics -- the Stakeholder Tokens. Stakeholder Tokens present a playful and holistic approach to support stakeholder analyses by engaging hands-on design activities. The Tokens serve a multiplicity of purposes, including (a) generating a more complete set of stakeholders, (b) identifying key stakeholders, and (c) clarifying stakeholder dynamics. To illustrate the method, I report on a case study concerning contemporary issues tied to medical aid-in-dying in the USA, in which the Tokens were used to surface diverse (and often conflicting) stakeholders.},
booktitle = {Proceedings of the 2017 ACM Conference Companion Publication on Designing Interactive Systems},
pages = {280–284},
numpages = {5},
keywords = {end-of-life, value sensitive design, stakeholder analysis, creative toolkits, aid-in-dying},
location = {Edinburgh, United Kingdom},
series = {DIS '17 Companion}
}

@inproceedings{siangliulue2015toward,
author = {Siangliulue, Pao and Arnold, Kenneth C. and Gajos, Krzysztof Z. and Dow, Steven P.},
title = {Toward Collaborative Ideation at Scale: Leveraging Ideas from Others to Generate More Creative and Diverse Ideas},
year = {2015},
isbn = {9781450329224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2675133.2675239},
doi = {10.1145/2675133.2675239},
abstract = {A growing number of large collaborative idea generation platforms promise that by generating ideas together, people can create better ideas than any would have alone. But how might these platforms best leverage the number and diversity of contributors to help each contributor generate even better ideas? Prior research suggests that seeing particularly creative or diverse ideas from others can inspire you, but few scalable mechanisms exist to assess diversity. We contribute a new scalable crowd-powered method for evaluating the diversity of sets of ideas. The method relies on similarity comparisons (is idea A more similar to B or C) generated by non-experts to create an abstract spatial idea map. Our validation study reveals that human raters agree with the estimates of dissimilarity derived from our idea map as much or more than they agree with each other. People seeing the diverse sets of examples from our idea map generate more diverse ideas than those seeing randomly selected examples. Our results also corroborate findings from prior research showing that people presented with creative examples generated more creative ideas than those who saw a set of random examples. We see this work as a step toward building more effective online systems for supporting large scale collective ideation.},
booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work I\& Social Computing},
pages = {937–945},
numpages = {9},
keywords = {collaborative ideation, inspirational examples, creativity},
location = {Vancouver, BC, Canada},
series = {CSCW '15}
}

@misc{Greene2022AtomistOH,
  doi = {10.48550/ARXIV.2208.09174},
  
  url = {https://arxiv.org/abs/2208.09174},
  
  author = {Greene, Travis and Dhurandhar, Amit and Shmueli, Galit},
  
  keywords = {Computers and Society (cs.CY), Artificial Intelligence (cs.AI), Other Statistics (stat.OT), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Atomist or Holist? A Diagnosis and Vision for More Productive Interdisciplinary AI Ethics Dialogue},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

  
@online{bioethics, 
    title={Ethics committees and consultation}, 
    year={2021},
    organization={University of Washington},
    author={Robert A. Pearlman},
    url={https://depts.washington.edu/bhdept/ethics-medicine/bioethics-topics/detail/64},
    lastaccessed = {2021-09-14}
} 

 @online{commonrule, title={45 CFR 46}, url={https://www.hhs.gov/ohrp/regulations-and-policy/regulations/45-cfr-46/index.html}, 
 journal={HHS.gov}, author={Office for Human Research Protections (OHRP)}, organization={Office for Human Research Protections (OHRP)},
 year={2022}, 
 month={Jan}} 
 
 @article{Matthews2022EmbracingCV,
  title={Embracing critical voices},
  author={Jean Isabel Matthews},
  journal={Communications of the ACM},
  year={2022},
  volume={65},
  pages={7 - 7}
}

@article{stephanidis2019seven,
  title={Seven HCI grand challenges},
  author={Stephanidis, Constantine and Salvendy, Gavriel and Antona, Margherita and Chen, Jessie YC and Dong, Jianming and Duffy, Vincent G and Fang, Xiaowen and Fidopiastis, Cali and Fragomeni, Gino and Fu, Limin Paul and others},
  journal={International Journal of Human--Computer Interaction},
  volume={35},
  number={14},
  pages={1229--1269},
  year={2019},
  publisher={Taylor \& Francis}
}

@inproceedings{conseuqences,
author = {Sturdee, Miriam and Lindley, Joseph and Linehan, Conor and Elsden, Chris and Kumar, Neha and Dillahunt, Tawanna and Mandryk, Regan and Vines, John},
title = {Consequences, Schmonsequences! Considering the Future as Part of Publication and Peer Review in Computing Research},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3441330},
doi = {10.1145/3411763.3441330},
abstract = {Research in computing is becoming increasingly concerned with understanding and mitigating unintended consequences of technology developments. However, those concerns are rarely reflected in how we submit, review, and publish our own work. Specifically, in talking about how our new apps, devices, and algorithms will change the world, we focus almost exclusively on positive consequences. There have been calls to require some speculation about negative impacts as part of the peer review process. This workshop will explore how to think about and report potential negative consequences in our papers in a way that’s practical, inclusive, and achievable. The aim is to draw on scholarship around creative-yet-grounded speculation about technology futures and to consider how these might be applied to publication and peer review. The workshop aims to inspire the CHI conference and the computing research community to meaningfully consider and act upon the potential negative implications of their work.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {95},
numpages = {4},
keywords = {consequences, publication, peer review, ideation, futuring},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@article{starbird2019disinformation,
  title={Disinformation's spread: bots, trolls and all of us},
  author={Starbird, Kate},
  year={2019},
  url = {https://par.nsf.gov/biblio/10170694},
  journal={Nature},
  volume={571}, 
  number={449},
  pages={449},
  publisher={Macmillan Publishers Ltd., London, England}
}

@inproceedings{Baumer2018WhatWY,
author = {Baumer, Eric P.S. and Berrill, Timothy and Botwinick, Sarah C. and Gonzales, Jonathan L. and Ho, Kevin and Kundrik, Allison and Kwon, Luke and LaRowe, Tim and Nguyen, Chanh P. and Ramirez, Fredy and Schaedler, Peter and Ulrich, William and Wallace, Amber and Wan, Yuchen and Weinfeld, Benjamin},
title = {What Would You Do? Design Fiction and Ethics},
year = {2018},
isbn = {9781450355629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3148330.3149405},
doi = {10.1145/3148330.3149405},
abstract = {Design fiction can be highly effective at envisioning possible futures. That envisioning enables, among other things, considering ethical implications of possible technologies. This paper highlights that capacity through a curated collection of five short design fiction pieces, each accompanied by its own author statement. Spanning multiple genres, each piece highlights ethical issues in its own way. After considering the unique strategies that each piece uses to highlight ethical issues, the paper concludes with considerations of how design fiction can advance broader discussions of ethics in computing.},
booktitle = {Proceedings of the 2018 ACM International Conference on Supporting Group Work},
pages = {244–256},
numpages = {13},
keywords = {design fiction, ethics},
location = {Sanibel Island, Florida, USA},
series = {GROUP '18}
}

@article{Klassen2022RunWA,
  title={"Run Wild a Little With Your Imagination": Ethical Speculation in Computing Education with Black Mirror},
  author={Shamika Klassen and Casey Fiesler},
  journal={Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 1},
  year={2022}
}

@article{Burton2018HowTT,
  title={How to teach computer ethics through science fiction},
  author={Emanuelle Burton and J. Goldsmith and Nicholas Mattei},
  journal={Communications of the ACM},
  year={2018},
  volume={61},
  pages={54 - 64}
}

@inproceedings{Harrington2022AllTY,
author = {Harrington, Christina N. and Klassen, Shamika and Rankin, Yolanda A.},
title = {“All That You Touch, You Change”: Expanding the Canon of Speculative Design Towards Black Futuring},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502118},
doi = {10.1145/3491102.3502118},
abstract = {Traditional approaches to technology design have historically ignored Blackness in both who engages and conceptualizes future technologies. Design contributions of groups marginalized along race and class are often othered, and rarely considered the design standard. While frameworks have emerged to encourage attention to gender and social justice in design, little work has acknowledged evidence of the Black imaginary in this process. The current canon of design defines futuring and speculation as stemming from a narrow view of science fiction, one which does not include Black futurist perspectives. In this essay, we expand the canon of design by arguing that frameworks such as Afrofuturism, Afrofuturist feminism, and Black feminism be considered instrumental in design’s imagining of our future technological landscape. We contribute to the larger conversation of who gets to future in design, suggesting a dialogic relationship between those who conceptualize design and those who consider design’s societal impact.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {450},
numpages = {10},
keywords = {futuring, Afrofuturism, design canon, speculative design},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{Liu2022ExaminingRA,
author = {Liu, David and Nanayakkara, Priyanka and Sakha, Sarah Ariyan and Abuhamad, Grace and Blodgett, Su Lin and Diakopoulos, Nicholas and Hullman, Jessica R. and Eliassi-Rad, Tina},
title = {Examining Responsibility and Deliberation in AI Impact Statements and Ethics Reviews},
year = {2022},
isbn = {9781450392471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3514094.3534155},
doi = {10.1145/3514094.3534155},
abstract = {The artificial intelligence research community is continuing to grapple with the ethics of its work by encouraging researchers to discuss potential positive and negative consequences. Neural Information Processing Systems (NeurIPS), a top-tier conference for machine learning and artificial intelligence research, first required a statement of broader impact in 2020. In 2021, NeurIPS updated their call for papers such that 1) the impact statement focused on negative societal impacts and was not required but encouraged, 2) a paper checklist and ethics guidelines were provided to authors, and 3) papers underwent ethics reviews and could be rejected on ethical grounds. In light of these changes, we contribute a qualitative analysis of 231 impact statements and all publicly-available ethics reviews. We describe themes arising around the ways in which authors express agency (or lack thereof) in identifying or mitigating negative consequences and assign responsibility for mitigating negative societal impacts. We also characterize ethics reviews in terms of the types of issues raised by ethics reviewers (falling into categories of policy-oriented and non-policy-oriented), recommendations ethics reviewers make to authors (e.g., in terms of adding or removing content), and interaction between authors, ethics reviewers, and original reviewers (e.g., consistency between issues flagged by original reviewers and those discussed by ethics reviewers). Finally, based on our analysis we make recommendations for how authors can be further supported in engaging with the ethical implications of their work.},
booktitle = {Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {424–435},
numpages = {12},
keywords = {broader impact, ethics review, ai ethics, impact statements},
location = {Oxford, United Kingdom},
series = {AIES '22}
}

@inproceedings{Ashurst2022AIES,
author = {Ashurst, Carolyn and Hine, Emmie and Sedille, Paul and Carlier, Alexis},
title = {AI Ethics Statements: Analysis and Lessons Learnt from NeurIPS Broader Impact Statements},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533780},
doi = {10.1145/3531146.3533780},
abstract = {Ethics statements have been proposed as a mechanism to increase transparency and promote reflection on the societal impacts of published research. In 2020, the machine learning (ML) conference NeurIPS broke new ground by requiring that all papers include a broader impact statement. This requirement was removed in 2021, in favour of a checklist approach. The 2020 statements therefore provide a unique opportunity to learn from the broader impact experiment: to investigate the benefits and challenges of this and similar governance mechanisms, as well as providing an insight into how ML researchers think about the societal impacts of their own work. Such learning is needed as NeurIPS and other venues continue to question and adapt their policies. To enable this, we have created a dataset containing the impact statements from all NeurIPS 2020 papers, along with additional information such as affiliation type, location and subject area, and a simple visualisation tool for exploration. We also provide an initial quantitative analysis of the dataset, covering representation, engagement, common themes, and willingness to discuss potential harms alongside benefits. We investigate how these vary by geography, affiliation type and subject area. Drawing on these findings, we discuss the potential benefits and negative outcomes of ethics statement requirements, and their possible causes and associated challenges. These lead us to several lessons to be learnt from the 2020 requirement: (i) the importance of creating the right incentives, (ii) the need for clear expectations and guidance, and (iii) the importance of transparency and constructive deliberation. We encourage other researchers to use our dataset to provide additional analysis, to further our understanding of how researchers responded to this requirement, and to investigate the benefits and challenges of this and related mechanisms.},
booktitle = {2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {2047–2056},
numpages = {10},
keywords = {NeurIPS policies, broader impacts, ethics statements, conference policies, research ethics, AI governance},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}


@inbook{bleecker2022design,
author = {Bleecker, Julian},
publisher = {John Wiley I\& Sons, Ltd},
isbn = {New York, NY},
title = {Design Fiction},
booktitle = {Machine Learning and the City},
chapter = {24},
pages = {561-578},
doi = {https://doi.org/10.1002/9781119815075.ch47},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119815075.ch47},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119815075.ch47},
year = {2022},
address      = {Berlin},
keywords = {design fiction, material craftwork activities, science fiction, ubicomp},
abstract = {Design seems to be a notice that says there is some purposeful reflection and consideration going on expressed as the thoughtful, imaginative, and material craftwork activities of a designer. Science fiction can be understood as a kind of writing that creates prototypes of other worlds, other experiences, other contexts for life based on the creative insights of the author. Designed objects – or designed fictions – can be understood similarly. Design fiction is about creative provocation, raising questions, innovation, and exploration. The chapter reveals how the facts of ubicomp become entangled with science fiction. Ubicomp is a kind of fiction, working with and through science to project possible near-future worlds. In fact, it is a future that can only be effectively represented as science fiction. The design fiction role is crucial to achieving the goals and meeting the aspirations of the emerging ideas as much as any other first-class participant in the design process.}
}

@inproceedings{blythe2014research,
  title={Research through design fiction: narrative in real and imaginary abstracts},
  author={Blythe, Mark},
  booktitle={Proceedings of the SIGCHI conference on human factors in computing systems},
  pages={703--712},
  year={2014}
}

@inproceedings{soden2019chi4evil,
author = {Soden, Robert and Skirpan, Michael and Fiesler, Casey and Ashktorab, Zahra and Baumer, Eric P. S. and Blythe, Mark and Jones, Jasmine},
title = {CHI4EVIL: Creative Speculation on the Negative Impacts of HCI Research},
year = {2019},
isbn = {9781450359719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290607.3299033},
doi = {10.1145/3290607.3299033},
abstract = {The HCI community is experiencing a resurgence of interest in the ethical, social, and political dimensions of HCI research and practice. Despite increased attention to these issues is not always clear that our community has the tools or training to adequately think through some of the complex issues that these commitments raise. In this workshop, we will explore the creative use of HCI methods and concepts such as design fiction or speculative design to help anticipate and reflect on the potential downsides of our technology design, research, and implementation. How can these tools help us to critique some of the assumptions, metaphors, and patterns that drive our field forward? Can we, by intentionally adopting the personas of would-be evil-doers, learn something about how better to accomplish HCI for Good?},
booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {social justice, design fiction, ethics, unintended consequences, chi4good, speculative design, hci education},
location = {Glasgow, Scotland Uk},
series = {CHI EA '19}
}

@article{fiesler2019ethical,
  title={Ethical considerations for research involving (speculative) public data},
  author={Fiesler, Casey},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={3},
  number={GROUP},
  pages={1--13},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{wong2017eliciting,
  title={Eliciting values reflections by engaging privacy futures using design workbooks},
  author={Wong, Richmond Y and Mulligan, Deirdre K and Van Wyk, Ellen and Pierce, James and Chuang, John},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={1},
  number={CSCW},
  pages={1--26},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@inproceedings{Lindley2016PushingTL,
author = {Lindley, Joseph and Coulton, Paul},
title = {Pushing the Limits of Design Fiction: The Case For Fictional Research Papers},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858446},
doi = {10.1145/2858036.2858446},
abstract = {This paper considers how design fictions in the form of 'imaginary abstracts' can be extended into complete 'fictional papers'. Imaginary abstracts are a type of design fiction that are usually included within the content of 'real' research papers, they comprise brief accounts of fictional problem frames, prototypes, user studies and findings. Design fiction abstracts have been proposed as a means to move beyond solutionism to explore the potential societal value and consequences of new HCI concepts. In this paper we contrast the properties of imaginary abstracts, with the properties of a published paper that presents fictional research, Game of Drones. Extending the notion of imaginary abstracts so that rather than including fictional abstracts within a 'non-fiction' research paper, Game of Drones is fiction from start to finish (except for the concluding paragraph where the fictional nature of the paper is revealed). In this paper we review the scope of design fiction in HCI research before contrasting the properties of imaginary abstracts with the properties of our example fictional research paper. We argue that there are clear merits and weaknesses to both approaches, but when used tactfully and carefully fictional research papers may further empower HCI's burgeoning design discourse with compelling new methods.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {4032–4043},
numpages = {12},
keywords = {fictional papers, prototyping, design fiction, imaginary abstracts, research through design},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{Birhane2022PowerTT,
author = {Birhane, Abeba and Isaac, William and Prabhakaran, Vinodkumar and Diaz, Mark and Elish, Madeleine Clare and Gabriel, Iason and Mohamed, Shakir},
title = {Power to the People? Opportunities and Challenges for Participatory AI},
year = {2022},
isbn = {9781450394772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551624.3555290},
doi = {10.1145/3551624.3555290},
abstract = {Participatory approaches to artificial intelligence (AI) and machine learning (ML) are gaining momentum: the increased attention comes partly with the view that participation opens the gateway to an inclusive, equitable, robust, responsible and trustworthy AI. Among other benefits, participatory approaches are essential to understanding and adequately representing the needs, desires and perspectives of historically marginalized communities. However, there currently exists lack of clarity on what meaningful participation entails and what it is expected to do. In this paper we first review participatory approaches as situated in historical contexts as well as participatory methods and practices within the AI and ML pipeline. We then introduce three case studies in participatory AI. Participation holds the potential for beneficial, emancipatory and empowering technology design, development and deployment while also being at risk for concerns such as cooptation and conflation with other activities. We lay out these limitations and concerns and argue that as participatory AI/ML becomes in vogue, a contextual and nuanced understanding of the term as well as consideration of who the primary beneficiaries of participatory activities ought to be constitute crucial factors to realizing the benefits and opportunities that participation brings.},
booktitle = {Equity and Access in Algorithms, Mechanisms, and Optimization},
articleno = {6},
numpages = {8},
keywords = {Justice, Power, Participatory AI, Machine Learning},
location = {Arlington, VA, USA},
series = {EAAMO '22}
}

@inproceedings{widder,
author = {Widder, David Gray and Nafus, Dawn and Dabbish, Laura and Herbsleb, James},
title = {Limits and Possibilities for “Ethical AI” in Open Source: A Study of Deepfakes},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533779},
doi = {10.1145/3531146.3533779},
booktitle = {2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {2035–2046},
numpages = {12},
keywords = {deepfakes, responsibility, free software, open source, agency, ethics, interview},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@inproceedings{carolyn,
author = {Ashurst, Carolyn and Hine, Emmie and Sedille, Paul and Carlier, Alexis},
title = {AI Ethics Statements: Analysis and Lessons Learnt from NeurIPS Broader Impact Statements},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533780},
doi = {10.1145/3531146.3533780},
booktitle = {2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {2047–2056},
numpages = {10},
keywords = {ethics statements, broader impacts, NeurIPS policies, conference policies, AI governance, research ethics},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@article{Nanayakkara2020AnticipatoryEA,
  title={Anticipatory Ethics and the Role of Uncertainty},
  pages={1-4},
  author={Priyanka Nanayakkara and Nicholas A. Diakopoulos and Jessica R. Hullman},
  journal={ArXiv},
  year={2020},
  volume={abs/2011.13170}
}

@book{Dunne2013SpeculativeED,
 ISBN = {9780262019842},
 address ={NY, USA},
 URL = {http://www.jstor.org/stable/j.ctt9qf7j7},
 abstract = {Today designers often focus on making technology easy to use, sexy, and consumable. InSpeculative Everything, Anthony Dunne and Fiona Raby propose a kind of design that is used as a tool to create not only things but ideas. For them, design is a means of speculating about how things could be -- to imagine possible futures. This is not the usual sort of predicting or forecasting, spotting trends and extrapolating; these kinds of predictions have been proven wrong, again and again. Instead, Dunne and Raby pose "what if" questions that are intended to open debate and discussion about the kind of future people want (and do not want).Speculative Everythingoffers a tour through an emerging cultural landscape of design ideas, ideals, and approaches. Dunne and Raby cite examples from their own design and teaching and from other projects from fine art, design, architecture, cinema, and photography. They also draw on futurology, political theory, the philosophy of technology, and literary fiction. They show us, for example, ideas for a solar kitchen restaurant; a flypaper robotic clock; a menstruation machine; a cloud-seeding truck; a phantom-limb sensation recorder; and devices for food foraging that use the tools of synthetic biology. Dunne and Raby contend that if we speculate more -- about everything -- reality will become more malleable. The ideas freed by speculative design increase the odds of achieving desirable futures.},
 author = {Anthony Dunne and Fiona Raby},
 publisher = {The MIT Press},
 title = {Speculative Everything: Design, Fiction, and Social Dreaming},
 urldate = {2023-02-16},
 year = {2013}
}


@inproceedings{wong2021using,
author = {Wong, Richmond Y.},
title = {Using Design Fiction Memos to Analyze UX Professionals’ Values Work Practices: A Case Study Bridging Ethnographic and Design Futuring Methods},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445709},
doi = {10.1145/3411764.3445709},
abstract = {Multiple methods have been used to study how social values and ethics are implicated in technology design and use, including empirical qualitative studies of technologists’ work. Recently, more experimental approaches such as design fiction explore these themes through fictional worldbuilding. This paper combines these approaches by adapting design fictions as a form of memoing, a qualitative analysis technique. The paper uses design fiction memos to analyze and reflect on ethnographic interviews and observational data about how user experience (UX) professionals at large technology companies engage with values and ethical issues in their work. The design fictions help explore and articulate themes about the values work practices and relationships of power that UX professionals grapple with. Through these fictions, the paper contributes a case study showing how design fiction can be used for qualitative analysis, and provides insights into the role of organizational and power dynamics in UX professionals’ values work.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {93},
numpages = {18},
keywords = {UX professionals, ethnography, values in design, ethics, values work, UX practice, values, design fiction},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{wong2018when,
author = {Wong, Richmond Y. and Merrill, Nick and Chuang, John},
title = {When BCIs Have APIs: Design Fictions of Everyday Brain-Computer Interface Adoption},
year = {2018},
isbn = {9781450351980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196709.3196746},
doi = {10.1145/3196709.3196746},
abstract = {In this paper, we use design fiction to explore the social implications for adoption of brain-computer interfaces (BCI). We argue that existing speculations about BCIs are incomplete: they discuss fears about radical changes in types of control, at the expense of discussing more traditional types of power that emerge in everyday experience, particularly via labor. We present a design fiction in which a BCI technology creates a new type of menial labor, using workers' unconscious reactions to assist algorithms in performing a sorting task. We describe how such a scenario could unfold through multiple sites of interaction: the design of an API, a programmer's question on StackOverflow, an internal memo from a dating company, and a set of forum posts about laborers' experience using the designed system. Through these fictions, we deepen and expand conversations around what kinds of (everyday) futures BCIs could create.},
booktitle = {Proceedings of the 2018 Designing Interactive Systems Conference},
pages = {1359–1371},
numpages = {13},
keywords = {brain computer interface, design fiction, labor, platforms},
location = {Hong Kong, China},
series = {DIS '18}
}

@inproceedings{lindley2017implications,
author = {Lindley, Joseph and Coulton, Paul and Sturdee, Miriam},
title = {Implications for Adoption},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025742},
doi = {10.1145/3025453.3025742},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {265–277},
numpages = {13},
keywords = {implications for adoption., design fiction, adoptability, prototyping},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{labinthewild,
author = {Reinecke, Katharina and Gajos, Krzysztof Z.},
title = {LabintheWild: Conducting Large-Scale Online Experiments With Uncompensated Samples},
year = {2015},
isbn = {9781450329224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2675133.2675246},
doi = {10.1145/2675133.2675246},
booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work \& Social Computing},
pages = {1364–1378},
numpages = {15},
keywords = {replication, weird, uncompensated samples, online experimentation, crowdsourcing, social comparison},
location = {Vancouver, BC, Canada},
series = {CSCW '15}
}