\section{Analysis of prover evasion strategies}
\label{a.provertricks}
\subsection{Do the Prover's odds of evasion benefit from training for longer, across fewer chips?}
\label{a.traininglonger}
One concern is that a Prover might manage to evade detection of a large-scale training run by using a smaller number of chips over a long period of time. 
A hypothesis for why this might be beneficial is that using a smaller number of chips makes the likelihood of any one of them being sampled extremely small.
However, if the Prover uses $\frac{c}{k}$ chips, this increases the training run's length $\times k$, meaning that the number of rounds of sampling similarly increases $\times k$.
We explore which of these effects dominates.

This can be expressed in the following formula for $p_d(k)$, the probability of detection as a function of the multiple increase of the training length. (For simplicity, we assume that the snapshotting frequency $f$ is high enough that every sampled chip contains a snapshot.)
\[
p_d(k) = 1 - \left ( 1 - \frac{\rulecomputeflops}{\totalchips a \trainingperiod k}\right )^{ks}
\]
where $a$ is the chips' FLOPs per day, $\trainingperiod$ is the original training period, $\totalchips$ is the total size of the Prover's chip stockpile being sampled from, and $\rulecomputeflops$ is the quantity of compute required for a large-scale training run.

We assume that $s$ is set by the Verifier in order to achieve a particular detection probability $p$ assuming the original (un-extended) training period $T$, via the Equation \ref{eq:samplingrate}, reproduced here:
\[
s(p) = \frac{\log (1-p)}{\log \left (1 - \frac{\rulecomputeflops}{\totalchips a \trainingperiod}\right )}
\]

In Figure \ref{fig:longertimes}, we estimate how $p_d(k)$, the probability of detection given a $\times k$ longer run, changes with $k$ and other hyperparameters. For simplicity, we define $b = \rulecomputeflops/(\totalchips a T)$, where we know that $1>b>0$.

Somewhat surprisingly, $p_d(k)$ changes very little as $k$ increases, and this remains true for almost all values of $b$.
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/heatmap2.png}
    \caption{Ratio of $p_d(k)$ to original $p = p_d(1)$, setting $p=0.9$ and varying $k$ from $1$ to $100$ and $b = \rulecomputeflops/(\totalchips a \trainingperiod)$ from $0$ to $0.2$ (where the latter end corresponds to the Prover using 20\% of all chips, making such a large-scale training run easily catchable with even a dozen samples). Across all values, the Prover's reduction in probability of detection is less than 5\%, even when training for up to $100 \times$ longer.
    }
    \label{fig:longertimes}
\end{figure}
This means that, for nearly all training run sizes (affecting $b$) and desired Verifier confidence levels $p$, the Prover cannot meaningfully decrease their probability of having their rule-violating training run detected by the Verifier by simply using fewer chips for longer.

\subsection{Do the Prover's odds of evasion benefit from splitting training across more chips?}
\label{a.trainingshorter}

A Prover may also exploit each chip's low snapshotting frequency to train across more chips than necessary, with the knowledge that many of the used chips will not contain a single snapshot.
Thus, the Verifier might sample more chips that were involved in a rule-violating training run, but never detect their involvement.

However, since the total amount of compute-time stays constant, the total number of snapshots stays constant, and using more chips only \emph{increases} the probability of detection.
We formalize this intuition with the following proof.

\begin{theorem}
For a given firmware snapshotting frequency $f$ and maximum training time $\trainingperiod$, a Prover executing a rule-violating training run cannot reduce the probability of one of the training run's snapshots being detected (that is, of having at least one of the Verifier's sampled chips include a snapshot from the rule-violating training run) by splitting the training run across a greater number of chips, each processing for less time.
\end{theorem}

\begin{proof}

We prove this in the case where training is done for at most one monitoring period $\trainingperiod = \monitoringperiod$.
The extension to multiple monitoring periods proceeds automatically.

Let the total compute required for a rule-violating training run be $\rulecomputeflops$ FLOPs, and the total number of chips available to the Prover is $\totalchips$.
Given that each chip can process $a$ FLOPs per day, to complete the training run in $t$ time, we need to use $c(t) = \rulecomputeflops/(at)$ chips.

For a chip used in the training run for $t$ time, the probability $p_{ns}$ that no snapshot was saved is the CDF of a Poisson random variable with rate parameter $f$:
\[
p_{ns}(t) = e^{-ft}
\]
Let the Verifier's sampling rate be a total of $s$ chips, which we assume occurred after the end of the training run (to avoid complexity due to chip samples midway through the training run having a lower probability of having logged a snapshot than later samples in the same training run).

If $c(t)$ chips are used, each for $t$ time, then the overall probability of detection $p_d(t)$ is
\[
p_d(t) = 1 - \left (1 - \frac{c(t)}{\totalchips} \left (1 - p_{ns}(t) \right ) \right )^s = 1 - \left (1 - \frac{\rulecomputeflops}{a\totalchips t} \left (1 - e^{-ft} \right ) \right )^s
\]
We want to prove that if the training run uses more chips than necessary $c(t) > c(T)$, each for less time $t < T$, then detection is always more likely $p_d(t) \overset{?}{>} p_d(T)$.

Let $a = \frac{T}{t} \geq 1$, and let $b = e^{-fT}$. We know $1>b>0$ because $f$ and $T$ are positive.

\begin{lemma}
If $g \geq 1$ and $1>b>0$, then $f(a) = a \left (1-b^{\frac{1}{g}} \right ) - (1-b) \geq 0$.
\end{lemma}
\begin{proof}
\begin{align*}
f(0) &= (1-b) - (1-b) = 0 \\
\frac{df(g)}{dg} &= 1 - b^{\frac{1}{g}} + \frac{1}{g}b^{\frac{1}{g}} \\
&= 1 - \underbrace{\left (1 - \frac{1}{g} \right )}_{\leq 1}\underbrace{b^{\frac{1}{g}}}_{\leq 1} \\
&\geq 0
\end{align*}
Given that $f(g=0) \geq 0$ and its derivative is continuous and nonnegative thereafter, we know that $f(g) \geq 0$ for all $g \geq 1, 1>b>0$.
\end{proof}
Plugging in our earlier settings for $a$ and $b$, we have:
\begin{align*}
   g\left (1 - b^{\frac{1}{g}} \right ) - (1-b) &\geq 0 \\
   g\left (1 - b^{\frac{1}{g}} \right ) &\geq 1-b \\
   \frac{1}{t}\left(1 - e^{-ft}\right) &\geq \frac{1}{T}\left(1 - e^{-fT}\right ) \\
   \frac{\rulecomputeflops}{a \totalchips t}\left (1 - e^{-ft}\right ) &\geq
   \frac{\rulecomputeflops}{a \totalchips T}\left (1 - e^{-fT} \right ) \\
   1 - \left ( 1 - \frac{\rulecomputeflops}{a \totalchips t}\left (1 - e^{-ft} \right ) \right )^s &\geq 
   1 - \left ( 1 - \frac{\rulecomputeflops}{a \totalchips T}\left (1 - e^{-fT} \right ) \right )^s\\
   p_d(t) &\geq p_d(T)
\end{align*}
\end{proof}

Note that this proof applies whether the extra chips are being used simultaneously in parallel, or split across time (e.g. one group of chips for the first half of the training run, and a second group of chips for the second half).

While this result might seem to contradict the result from Subsection \ref{a.traininglonger}, the two findings are in fact consistent. The key assumption is that the snapshotting frequency $f$ is high enough for the chips to contain at least one logged snapshot per period $T$ with high probability.
Then Subsection \ref{a.trainingshorter} tells us that using fewer chips reduces the Prover's probability of detection, and Subsection \ref{a.traininglonger} tells us that this decrease in detection is small, and likely not worth it to the Prover given the resulting delay in the training run's completion.