\section{Case study in a possible circumvention: student-teacher retraining}
\copied{
        3. Similarly, doesn’t cover “student-teacher” transfer, but here we assume that the compute required for the student to learn from the teacher and then keep learning by itself is of a similar OOM to the original. (If Sorscher scaling laws hold up, this would cease to be true.)
            1. To analyze more, see this survey here: [https://arxiv.org/pdf/2004.05937.pdf](https://arxiv.org/pdf/2004.05937.pdf) 
            2. In practice, it seems like this sort of student-teacher distillation for peers (called self-distillation?) may indeed be possible, and reduce the number of training samples required. In particular, as the evil Prover, train a teacher, then train a student from the teacher’s data requiring much less compute, and then keep training this student on additional data (making it the new teacher for a subsequent model). Thus, each student appears to do a small amount of training (e.g. the distillation time + an equal amount of normal training), but cumulatively they result in a better and better model. In this way, a large training run can be hidden with a small amount of small training runs.
            3. Two counterpoints: (1) this finetuning is not infinitely-efficient: it still requires a bunch of compute. (2) the total training time across all the different teachers+students remains at least as large, probably larger. Thus, the guarantee shifts from “we can get the full training length of a model that used at least X compute” to “if a model used at least X compute, we can get its training dataset [which, per below bullet, is representative of the original training dataset] and know its performance on that dataset”. This is still useful because we can now in principle regulate models based on their predictive accuracy on their training dataset. (Need to do this on parts of the training dataset that haven’t yet been trained on and are thus “test data”, although in multi-epoch settings this may not be possible.)
}
