\section{Derivation of Sampling Rate}
\label{a.samplingderivation}
We provide a derivation of Equation \ref{eq:samplingrate}, the number of samples required for a Verifier to catch a weight snapshot from a rule-violating training run with a given probability $p$.
Let $\rulecomputeflops$ be the size of an ML training run that the Verifier is hoping to catch.
Let $\totalchips$ be the total number of chips the Prover possesses, and $a$ be the FLOPs/day for those chips. 
Let $f$ be the expected number of weight-snapshots saved by the chip per day; snapshots are Poisson distributed.
The Verifier wants to detect a rule-violating training run of length $\trainingperiod$ that was completed in the last $\monitoringperiod$ days, and will sample $s$ chips every $\monitoringperiod$.
We will assume that the Prover executes the training run over the course of $\trainingperiod$ days. 
(We show in Appendix \ref{a.provertricks} that changing $\trainingperiod$ only marginally affects our analysis.)

It is not enough that a chip involved in the training run be sampled by the Verifier; the chip needs to have also logged a weight-snapshot from this particular training run, in order for there to be something for the Verifier to discover.
The probability of a chip logging a weight-snapshot is uniform over time (Section \ref{s.onchip}). 
Assuming the training run began at the beginning of the first monitoring period of length $\monitoringperiod$, the probability that a snapshot was sampled is $1 - PoissonCDF_{T;f}(0) = 1 - e^{-fT}$, where $PoissonCDF_{T;f}$ is the CDF of a Poisson random variable with shape parameter $f$ and interval-length $T$.
If the training run lasted multiple monitoring periods, then each later period, each chip is strictly more likely to contain a snapshot than this first period.
\footnote{There are two edge cases.
First, the Prover could choose to use extra chips and thus shrink $\trainingperiod < \monitoringperiod$.
However, in Appendix \ref{a.trainingshorter}, we show this would not improve the likelihood of avoiding detection due to a snapshot not being included.
The other edge case is when $\trainingperiod$ is not perfectly divisible by $\monitoringperiod$, leading to the first round of samples occurring when each chip has participated in the training run for less than $\monitoringperiod$ time.
This means that the likelihood of each sample in that round containing a snapshot is slightly reduced, thus reducing the likelihood of detection in that round, and therefore of detection at any of the $\trainingperiod/\monitoringperiod$ periods of the training run.
At worst, this creates a delay of one extra monitoring period $\monitoringperiod$ after the training run ended, since each sample from that $\lceil \trainingperiod / \monitoringperiod \rceil$'th period is just as likely to contain a snapshot as the other periods.
That's because the weight snapshots remain on the chip even after the training run has ended.
We exclude this one-period fudge factor from our notation for brevity.}

Thus, we let the probability that a chip contains a snapshot be:

\[
p_w \geq 1 - e^{-fT}
\]

We assume that the Prover used the minimum number of chips possible to complete the training run within the time period, $\frac{\rulecomputeflops}{a\trainingperiod}$ chips.
Each time a Verifier samples a chip, the probability that it is one of the chips used in the training run is $\frac{\rulecomputeflops}{a \trainingperiod\totalchips}$.
The probability that the Verifier samples a chip, and that it is both used in the training run and contains a logged weight snapshot is $p_{\text{1-sample}} = \frac{\rulecomputeflops}{a\trainingperiod\totalchips} p_w $.

The probability that the Verifier \emph{fails} to sample a single involved chip with a logged snapshot during a single monitoring period that includes $s$ samples is equivalent to a weighted coin with $p_{\text{1-sample}}$ probability of heads coming up tails $s$ times:
\[
p_n = (1 - p_{\text{1-sample}})^s = \left( 1 - \frac{\rulecomputeflops}{aT\totalchips}\left(1 - e^{-fT} \right)\right)^s
\]

There are $\lceil\trainingperiod/\monitoringperiod\rceil$ rounds of sampling for each training run, including the last period (which may not include a full training run, but each chip will still store the relevant weight snapshot hashes).

This means the probability of successfully detecting a snapshot from a large-scale training run within $\monitoringperiod$ days of the training run's completion is $p = (1 - p_n)^{\lceil \trainingperiod/\monitoringperiod \rceil}$.

Rearranging terms, we get:
\begin{align*}
p &= 1 -\left( 1 - \frac{\rulecomputeflops}{a\trainingperiod\totalchips} p_w \right)^{\lceil \trainingperiod / \monitoringperiod \rceil s}
\geq 
1 -\left( 1 - \frac{\rulecomputeflops}{a\trainingperiod\totalchips}\left(1 - e^{-f\monitoringperiod} \right)\right)^ {\lceil \trainingperiod / \monitoringperiod \rceil s} \\
\log(1 - p) &\leq s 
\left \lceil \frac{\trainingperiod}{\monitoringperiod} \right \rceil 
\log\left( 1 - \frac{\rulecomputeflops}{a\trainingperiod\totalchips}\left(1 - e^{-f\monitoringperiod} \right)\right) \\
s &\leq \frac{ \log (1-p)}{\log\left( 1 - \frac{\rulecomputeflops}{a\trainingperiod\totalchips}\left(1 - e^{-f\monitoringperiod} \right)\right)}
\frac{1}{\left \lceil \frac{\trainingperiod}{\monitoringperiod} \right \rceil}
\end{align*}
To catch a rule-violating training run snapshot with probability $p$, a Verifier needs to sample no more than $s$ chips in each monitoring period $\monitoringperiod$.