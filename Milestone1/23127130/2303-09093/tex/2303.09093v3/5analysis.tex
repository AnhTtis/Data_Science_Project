\section{Analysis}
In this section, we investigate the following questions: (1) Which component is the main bottleneck for performance? (Section \ref{sec:per_stage}) and (2) Does our model suffer from label imbalance between types? (Section \ref{sec:imbalance})
\subsection{Per-Stage Performance}
\label{sec:per_stage}
\input{tables/exp_results_TR}
Our model \ours\ comprises three components: trigger identification, event type ranking, and event type classification. Table \ref{tab:main_results} shows precision, recall, and F1 scores for trigger identification, while Table \ref{tab:TR&TC} presents the performance of event type ranking and classification. 
We assess per-stage performance using Hit@k metrics for event type ranking on ground truth trigger spans and event type classification on event mentions where the ground truth event type appears in the ranked results by the type ranker.
The scores indicate that the primary bottleneck exists in the precision of trigger identification and the Hit@1 score of type classification.


\subsection{Type Imbalance}
\label{sec:imbalance} 
\input{figures/frequency_F1}
Figure \ref{fig:glen_data_longtail} illustrates the long-tailed label distribution in our dataset. To investigate whether our model is affected by this imbalance, we divided the event types into four groups separated at the quartiles based on their frequency and calculated the performance per group. The resulting figure is shown in Figure \ref{fig:frequency_f1}. While we do see that the most popular group has the highest F1 score, the remaining groups have comparable scores.
In fact, we see two factors at play in defining the dataset difficulty: the ambiguity of the event type and the frequency of the event type. Event types that are more popular are also often associated with rolesets that have a high level of ambiguity, which balances out the gains from frequency. 


\subsection{Error Categories}
\begin{figure}[th]
    \centering
    \includegraphics[width=\linewidth]{figures/error_analysis_twopies.pdf}
    \caption{Categorization of errors based on the relation between the predicted event type and the candidate set produced by the mapping (left) and the predicted event type and the ground truth event type on the event ontology hierarchy (right).}
    \label{fig:error_categories}
\end{figure}

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{m{6em}|m{23em} m{8em} m{8em}}
    \toprule 
      Error Category   & Context & Predicted & Gold  \\
    \midrule 
       Candidate & 3 workers set off a critical \textbf{reaction} in 990000 when they poured too much uranium into a precipitation tank. & reaction (response to stimulus) & chemical\_reaction \\ 
       \cmidrule{2-4}
       & France is urged to increase \textbf{research} funding and support for innovations as a way to deal with the problem. & research\_method & research (systematic study) \\
       \midrule 
       Extended Candidate & Regulators and research firms promised that the \$1.5 billion \textbf{settlement} would be finalized two months ago. & settlement(distortion of a building) & settlement(operations relating to the payment) \\
       \midrule 
       Child & People \textbf{working} for minimum wage are producing a large number of products or services. & work (activities performed as a means of support) & work (activity done by a person for economic gain) \\
       \midrule 
       Sibling & In the middle east \textbf{conflict}, do you think the United States should take Israel's side, take the Palestinians' side, or not take either side? & social\_conflict (struggle for agency or power in society) & armed\_conflict (conflict including violence) \\
       \midrule 
       Parent & Doctors will \textbf{examine} him for signs that the cancer may have come back while he awaiting trial in a Russian jail. & inspection & physical\_examination (process by medical professional) \\
       \midrule 
       Other 
       & Ironically, in the 90's, ``character matters'' became a \textbf{well-worn} slogan on the right. &  wears(clothing or accessory) & wear (damaging, gradual removal or deformation) \\
       & In theory, one could argue that the computer models are accurate and that the real \textbf{measurements} have some problems. & quantification & measurement \\
       \cmidrule{2-4} 
       & Though \textbf{funds} have already been allocated and voted on for the project, 
       Blair himself insists that things are still ``very much open''...
       & voting & fund \\
       \bottomrule 
    \end{tabular}
    \caption{Examples of erroneous type predictions. The trigger word (phrase) is shown in \textbf{bold}. 
    In some cases, the error falls into multiple categories. 
    We prioritize the XPO hierarchy-related categories since they are rarer. }
    \label{tab:error_cases}
\end{table*}


We categorize the type classification errors from the \ours\ model based on the relationship between our predicted event type and the ground truth event type as shown in Figure \ref{fig:error_categories} and Table \ref{tab:error_cases}.

Most of our errors come from the noisy annotation (\textbf{Candidate Set}): our model can predict an event type that falls within the set of candidate types associated with the ground truth PropBank roleset but fails to find the correct one. \textbf{Extended Roleset} refers to the predicted event being associated with a roleset that shares the same predicate as the ground truth. 
 The uncategorized errors are often due to the imperfect recall of our event ranking module (as in the second example in Table \ref{tab:error_cases} where the context is long and ``fund'' fails to be included in the top-10 ranked event types), or cases where our model prediction is related semantically to the ground truth but the event types have no connections in the hierarchy (as in the first example in Table \ref{tab:error_cases} where we predicted ``quantification'' instead of ``measurement''). 
 On the other hand, in another 22.9\% of the cases, we predict an event that is close to the ground truth on the XPO hierarchy, with the ground truth either being the child (\textbf{Child}), parent (\textbf{Parent}), or sibling node (\textbf{Sibling}) of our predicted type. This suggests that better modeling of the hierarchical relations within the ontology might be useful for performance improvement. 
 
 

