\section{Method}

In the event detection task, the goal is to find the trigger word offset and the corresponding event type for every event.
The main challenge for our dataset is the \textbf{large ontology size} and \textbf{partial labels} from distant supervision. 
To mitigate label noise, we first separate the trigger identification step from the event typing step, since trigger identification can be learned with clean data. Then, to handle the large ontology, we break the event typing task into two stages of type ranking and type classification to progressively narrow down the search space. Finally, in the type classification model, we adopt a self-labeling procedure to mitigate the effect of partial labels. 


\subsection{Trigger Identification}
In the trigger identification stage, the goal is to identify the location of event trigger words in the sentence. This step only involves the sentence and not the event types. 
We formulate the problem as span-level classification: to compute the probability of each span in sentence $s$ being an event trigger, we first obtain sentence token representations based on a pre-trained language model:

\begin{equation*}
    [\mathbf{s}_1\cdots \mathbf{s}_n]^T = \operatorname{PLM}(\text{\small{[CLS]}} s_1 \cdots s_n \text{\small{[SEP]}}) \in \mathbb{R}^{n\times h},
\end{equation*}
 where $\mathbf{s}_i$ is a $h$-dimensional representation vector of token $s_i$.
 
Then we compute the scores for each token being the start, end, and part of an event trigger individually as:
\begin{equation*}
    f_{\square}(s_i) = \mathbf{w}_{\square}^T\mathbf{s}_i, \quad
    \square \in \{\text{start}, \text{end}, \text{part}\},
\end{equation*} where $\mathbf{w}_\square \in \mathbb{R}^h$ is a learnable vector.
We then compute the probability of span $[s_i\cdots s_j]$ to be an event trigger as the sum of its parts:
\begin{equation*}
\begin{aligned}
    &p([s_i\cdots s_j])  \\
    &=\sigma (f_{\text{start}}(s_i) + f_{\text{end}}(s_j) + \sum_{k=i}^jf_{\text{part}}(s_k)).
\end{aligned}
\end{equation*}

The model is trained using a binary cross entropy loss on all of the candidate spans in the sentence. 

\subsection{Event Type Ranking}
In the next stage, we perform event type ranking over the entire event ontology for each sentence. Since our ontology is quite large, to improve efficiency we make two design decisions: (1) ranking is done for the whole sentence and not for every single trigger; (2) the sentence and the event type definitions are encoded separately. 

We use the same model architecture as ColBERT~\cite{Khattab2020ColBERT}, which is an efficient ranking model that matches the performance of joint encoders while being an order of  magnitude faster.

We first encode the sentence as:
\begin{equation}
\begin{aligned} 
    &\vec{\mathbf{s}} = \operatorname{PLM}(\text{\small{[CLS]}} \text{\small{[SENT]}} s_1 \cdots s_n \text{\small{[SEP]}}) \in \mathbb{R}^{(n+1)\times h} \\
    &[\mathbf{h}^1_s, \cdots, \mathbf{h}^m_s] = \operatorname{Norm}(\operatorname{1dConv}(\vec{\mathbf{s}})) \in \mathbb{R}^{m \times h}
\end{aligned} 
\end{equation}
\texttt{[SENT]} is a special token to indicate the input type. 
The one-dimensional convolution operator serves as a pooling operation and the normalization operation ensures that each vector in the bag of embeddings $\mathbf{h}_s$ has an L2 norm of 1. 

The event type definition is encoded similarly, only using a different special token \texttt{[EVENT]}.

Then the similarity score between a sentence and an event type is computed by the sum of the maximum similarity between the sentence embeddings and event embeddings: 
\begin{equation}
    \rho_{(e, s)} = \sum_{h_s} \max_{h_e} (\mathbf{h}_e^T \mathbf{h}_s)
\end{equation}


Our event type ranking model is trained using the distant supervision data using a margin loss since each instance has multiple candidate labels. This margin loss ensures that the best candidate is scored higher than all negative samples. 
\begin{equation}
\small 
    \mathcal{L} = \frac{1}{N}\sum_s \sum_{e^-} \max \{ 0, (\tau - \max_{e \in C_y} \rho_{(e, s)}+  \rho_{(e^-, s)}) \}
\end{equation}
$e^-$ denotes negative samples, $C_y$ is the set of candidate labels and $\tau$ is a hyperparameter representing the margin size.

\subsection{Event Type Classification}
Given the top-ranked event types from the previous stage and the detected event triggers, our final step is to classify each event trigger into one of the event types. 
Similar to \cite{lyu-etal-2021-zero}, we formulate this task as a Yes/No QA task to take advantage of pre-trained model knowledge. 
The input to the model is formatted as ``\texttt{$\langle$type$\rangle$ is defined as $\langle$definition$\rangle$. $\langle$sentence$\rangle$. Does $\langle$trigger $\rangle$ indicate a $\langle$type$\rangle$ event? [MASK]}''. We directly use a pretrained masked language model and take the probability of the model predicting ``yes'' or ``no'' for the \texttt{[MASK]} token, denoted as $P_{\text{MLM}}(w)$, where $w \in \{\text{``yes''}, \text{``no''}\}$. From these probabilities, we calculate the probability of the event type $e$ as follows:
\begin{equation}
\small
    P(e) =\frac{\exp(P_{\text{MLM}}(\text{``yes''}))}{\exp(P_{\text{MLM}}(\text{``yes''})) + \exp(P_{\text{MLM}}(\text{``no''}))}
\end{equation}
To train the model, we employ binary cross-entropy loss across pairs of event triggers and event types.
    
As mentioned in Section \ref{sec:data_cleaning}, our data contains label noise due to the many-to-one mapping from Qnodes to PropBank rolesets. 
We adopt an incremental self-labeling procedure to handle the partial labels. We start by training a base classifier on clean data labeled with PropBank rolesets that map to only one candidate event type. Despite being trained on only a subset of event types, the base model exhibits good generalization to rolesets with multiple candidate event types. 
We then use the base classifier to predict pseudo-labels for the noisy portion of the training data, selecting data with high confidence to train another classifier in conjunction with the clean data. 







