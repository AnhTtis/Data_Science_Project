{
    "arxiv_id": "2303.16898",
    "paper_title": "Bagging by Learning to Singulate Layers Using Interactive Perception",
    "authors": [
        "Lawrence Yunliang Chen",
        "Baiyu Shi",
        "Roy Lin",
        "Daniel Seita",
        "Ayah Ahmad",
        "Richard Cheng",
        "Thomas Kollar",
        "David Held",
        "Ken Goldberg"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-03-30"
    ],
    "latest_version": 1,
    "categories": [
        "cs.RO"
    ],
    "abstract": "Many fabric handling and 2D deformable material tasks in homes and industry require singulating layers of material such as opening a bag or arranging garments for sewing. In contrast to methods requiring specialized sensing or end effectors, we use only visual observations with ordinary parallel jaw grippers. We propose SLIP: Singulating Layers using Interactive Perception, and apply SLIP to the task of autonomous bagging. We develop SLIP-Bagging, a bagging algorithm that manipulates a plastic or fabric bag from an unstructured state, and uses SLIP to grasp the top layer of the bag to open it for object insertion. In physical experiments, a YuMi robot achieves a success rate of 67% to 81% across bags of a variety of materials, shapes, and sizes, significantly improving in success rate and generality over prior work. Experiments also suggest that SLIP can be applied to tasks such as singulating layers of folded cloth and garments. Supplementary material is available at https://sites.google.com/view/slip-bagging/.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16898v1"
    ],
    "publication_venue": null
}