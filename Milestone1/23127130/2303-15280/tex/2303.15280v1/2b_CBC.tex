\subsection{Methodology \#1: Counter Based Classification (CBC)} \label{subsec:one_stage_methodology}
\begin{figure*}[tb!]
  \centering
  \includegraphics[width = 0.65\textwidth]{figures/CBC_Micro2022.pdf}
  \caption{Overview of the CBC methodology.}
  \label{fig:one_stage_methodology}
\end{figure*}

The methodology proposed in this section consists of a single machine
learning stage followed by an aggregation procedure. An overview of
this methodology is shown in Figure~\ref{fig:one_stage_methodology}.

If the set of all the evaluated workloads is denoted by $W$ then,
for any given workload $w_i \in W$, we extract data from a set of
performance counters.  The counter data may be taken either from a
simulation or from the actual silicon chip.  The counters used are
those previously selected, using the methodology described in
Section~\ref{subsec:counter_selection}.

Although the automated counter selection can lead to a different
set of performance counters for each workload, CBC achieves better accuracy when every
model uses the super-set composed by the union of the counters
selected for each of the workloads.  This is because, for some
workloads, the selected counters do not contain any information
regarding specific units that might be affected by the performance
bug. Providing every workload with this larger counter set increases
the visibility the models have in all the units of the
system. Although using the union super-set significantly increases
the number of features per model by a factor of $\sim15\times$, this
merged set is still about $10\times$ smaller than the complete list
of available counters.

The data extracted from the performance counters is sampled and reset
every time a certain number of cycles have passed (\emph{e.g.}
every 100k cycles). Resetting the counters ensures 
that their value reflects only their
behavior in the current time-step, without keeping
track of its history. Therefore, the counter data for workload $w_i$ is
arranged as a time-series with $T_i$ elements. This time-series data is then feed into a 
ML classifier. 

In this work, we formulated the bug localization problem
as a multi-class classification task. Here, every 
microarchitectural unit where the bug
might be located corresponds to a class $u_j \in U$, where $U$ is the
set of all units.  To solve the multi-class classification task, some
common strategies in the ML community are one-vs-one (OvO)~\cite{ovo},
one-vs-all (OvA)~\cite{ova} or using a single multi-output model~\cite{bishop2006pattern}.  Although the usage of the latter
was evaluated, it did not achieve the desired
accuracy. A OvA strategy is followed, as it provides
good accuracy with a small fraction of the base classifiers that would be 
required
for a OvO strategy.  Here, a base classifier is a model to
classify if the bug exists in a specific unit for a workload.
With OvA, a total of $|W|\cdot|U|$ base models
(classifiers) are needed.

The base classifier for workload $w_i$ that flags the bug
in unit $u_j$ is denoted as $m_{i,j}$. Each $m_{i,j}$
produces a confidence score,
which is a soft classification in $[0,1]$ for workload $w_i$ to tell
if the bug is at unit $u_j$. Since the confidence scores from all
classifiers of a workload do not add up to one, they do not represent
probability. However, they serve as probability proxies, as higher
scores mean higher probability of the bug being in that unit. The
confidence scores for every unit across all the workloads are summed to
create a final score for each unit. The units with higher scores
have higher probability of the bug being present in
that unit. If sorted, the output provided by CBC represents a ranking of the
most likely units where the bug might be located.

Each base classifier $m_{i,j}$ is trained with data of workload $w_i$ from
one or more
legacy architectures. Samples from legacy architectures with bugs 
occurring at unit $u_j$ are considered ``positive'' cases for the model,
while bugs in any other unit are considered ``negative''. In this way,
the base classifier will learn to identify bugs exclusively on its 
corresponding unit. If available, samples from bug-free legacy architectures
can be used for training, and will be considered ``negative'' samples.

Because of the time-series format used for the performance counters, two different
methods to calculate the confidence score are evaluated and
contrasted:
\begin{compactenum}
\itemsep0em 
\item \emph{Per-trace classification}: Using neural networks that are
  able to take advantage of temporal locality, such as Convolutional
  Neural Networks (CNN)~\cite{lecun1995convolutional} or Long Short-Term
  Neural Networks (LSTM)~\cite{hochreiter1997lstm}, the complete time trace
  can be processed and a single score generated in the end. The
  proposed methodology uses CNNs, as LSTMs did not produce
  satisfactory results.

\item \emph{Per-time-step classification}: At every time-step $t_{i}$,
  a bug location prediction is performed by using the input features
  related to that specific time-step.  With this, a classification
  result per time-step is obtained, ultimately creating a
  ``classification trace''.  Previous time-steps could be added as
  input features in order to provide the models with information
  regarding counter history. However, we found that for the evaluated
  time-step size (100k cycles), adding these had no significant
  benefit.
  This method allows for other ML methods to be used, such as
  Multi-Layer Perceptrons~\cite{hornik1989multilayer}, Random
  Forest~\cite{breiman2001random} or Gradient Boosted Decision
  Trees (GBDT)~\cite{friedman2001greedy}.  Although all these methods were
  evaluated, the proposed methodology uses GBDT, as
  it was found the best performing.  Ultimately, to transform the
  prediction trace into a single value, the mean value
  of prediction scores
  across the
  whole time trace is used as the final score.
\end{compactenum}
