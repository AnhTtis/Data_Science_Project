% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{placeins}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm2e}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
% working title
\title{Probabilistic Domain Adaptation for Biomedical Image Segmentation}

% commented out for double blind submission
\author{Anwai Archit\inst{1, 2} \and Constantin Pape\inst{1, 2}}
\authorrunning{Archit et al.}
\institute{Georg-August-Universität Göttingen, Germany \and Campus Institute Data Science, Göttingen, Germany}
%\email{lncs@springer.com}\\
%\url{http://www.springer.com/gp/computer-science/lncs} \and
%ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
%\email{\{abc,lncs\}@uni-heidelberg.de}
%
\maketitle              % typeset the header of the contribution
%
\vspace{-0.5cm}
\begin{abstract}
Segmentation is a key analysis tasks in biomedical imaging. Given the many different experimental settings in this field, the lack of generalization limits the use of deep learning in practice. Domain adaptation is a promising remedy: it trains a model for a given task on a source dataset with labels and adapts it to a target dataset without additional labels. We introduce a probabilistic domain adaptation method, building on self-training approaches and the Probabilistic UNet. We use the latter to sample multiple segmentation hypothesis to implement better pseudo-label filtering. We further study joint and separate source-target training strategies and evaluate our method on three challenging domain adaptation tasks for biomedical segmentation.
% \keywords{Semantic Segmentation  \and Domain Adaptation.} % getting rid of the keywords for now; I assume we will need all the space we can get...
\end{abstract}

% VERSION 1; IN PRINCIPLE GOOD TO GO (could ofc use some more polishing, but not a priority)
\section{Introduction}

Deep learning has emerged as the standard approach for many image analysis tasks, including segmentation in biomedical imaging. However, its practical application is often hindered by the limited generalization and the need for large labeled training datasets in supervised learning. These drawbacks are particularly challenging in biomedical imaging, where many different experimental setups and modalities exist. Domain adaptation has emerged as a promising remedy:
It adapts a model that was trained on a labeled dataset ("source") for a specific task, for example cell segmentation, to solve the same task on a new dataset ("target") from a different domain. We present a novel domain adaptation method that combines self-training techniques with probabilistic segmentation and demonstrate its effectiveness for semantic segmentation in biomedical images. Our proposed method shows significant promise in improving generalization across domains and reducing the labeling effort in practice. 

Self-training for domain adaptation builds on ideas from semi-supervised learning. These approaches train a model jointly on the labeled and unlabeled data. On the unlabeled data, predictions from a version of the model (the teacher) are used as so-called pseudo-labels for the model (the student). A popular self-training method is \textit{Mean Teacher} \cite{tarvainen_mean_2018}, which uses the exponential moving average (EMA) of the student weights to compute the teacher weights. Recently \textit{FixMatch} \cite{sohn_fixmatch_2020} has gained popularity. Its teacher and student share weights, but weak and strong augmentations prevent collapse of the model predictions. Both approaches have been studied for semi-supervised classification as well as segmentation, for example in \textit{UniMatch} \cite{yang_revisiting_2022}. Self-training can be extended to domain adaptation, see for example \textit{AdaMatch} \cite{berthelot_adamatch_2022}.

We study three key design choices for applying self-training to domain adaptation: (i) how to generate the pseudo-labels, (ii) how to filter them and (iii) how to orchestrate source and target training. \textit{Mean Teacher}, \textit{FixMatch} and others have mostly focused on (i), by studying different student-teacher set-ups and different augmentation strategies. For (ii) most approaches either do not filter the pseudo-labels (e.g. \textit{MeanTeacher}), or filter them based on confidences derived from deterministic model predictions (e.g. \textit{FixMatch}). However, regular deep learning methods are known to be badly calibrated and hence their predictions do not yield reliable confidence estimates. Instead, we propose to use the \textit{Probabilistic UNet} (PUNet) \cite{kohl_probabilistic_2019}, a probabilistic segmentation method, to derive better confidence estimates, and use them to filter pseudo-labels. Fig.~\ref{fig1} shows an overview of our method. 
We also investigate two different strategies for (iii): separate source training and subsequent adaptation (two stages) versus joint training on source and target (single stage). We evaluate our method on three challenging domain adaptation tasks in biomedical segmentation: cell segmentation in livecell microscopy, mitochondria segmentation in electron microscopy (EM) and lung segmentation in X-Ray. Our method compares favorably to strong baselines. Code is available at \url{https://github.com/computational-cell-analytics/Probabilistic-Domain-Adaptation}.

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{figures/fig1.png}
  \caption{Self-training and probabilistic segmentation: the teacher predicts pseudo-labels, which are used to compute the loss with the student predictions. Multiple samples from the (prob.) teacher are used to filter the pseudo-labels. Student and teacher either share weights (\textit{FixMatch}, red) or the teacher weights are the EMA of the student weights (\textit{MeanTeacher, green}). Their inputs are transformed with different weak (\textit{MeanTeacher}) or weak and strong (\textit{FixMatch}) augmentations.}
  \label{fig1}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{figures/fig2.png}
  \caption{PUNet set-up: during training both prior and posterior encoder predict parameters for sampling latents. Features from the UNet are concatenated with the posterior latents for prediction. The KL divergence minimizes the distance between prior and posterior predictions, the dice loss between segmentation and labels. In inference the prior encoder is used for sampling.}
  \label{fig2}
\end{figure}

% PASSABLE DRAFT
\section{Related Work}

\paragraph{Self-training:} These methods are among the most popular approaches in semi-supervised learning; examples include \textit{Mean Teacher} \cite{tarvainen_mean_2018}, \textit{ReMixMatch} \cite{berthelot_remixmatch_2020} and \textit{FixMatch} \cite{sohn_fixmatch_2020}. They are often  studied for classification tasks, but have also been successfully applied to semantic segmentation, see for example \textit{PseudoSeg} \cite{zou_pseudoseg_2021} and \textit{UniMatch} \cite{yang_revisiting_2022}.
Similar methods have emerged for domain adaptation:a unified framework for semi-supervision and domain adaptation has recently been proposed by \textit{AdaMatch} \cite{berthelot_adamatch_2022}. Self-training methods for domain adaptation in segmentation have for example been introduced by Zou et al. \cite{zou_domain_2018}, who use class-balanced pseudo-labeling, and Mei et al. \cite{mei_instance_2020}, who use instance adaptive pseudo-labeling. Applications to segmentation in biomedical images include \textit{Shallow2Deep} \cite{matskevych2022shallow}, which uses intermediate predictions from a shallow learner for pseudo-labels, and \textit{SPOCO} \cite{wolny_sparse_2022}, which uses a per-instance loss and self-training to learn from sparse instance segmentation labels.

\paragraph{Probabilistic segmentation:} Probabilistic segmentation methods learn a distribution over segmentation results and enable sampling from it. Early approaches have implemented this through test-time dropout \cite{kendall2015bayesian}, recent approaches such as the PUNet \cite{kohl_probabilistic_2019} and its hierarchical extension \cite{kohl2019hierarchical}, use a conditional variational autoencoder.
Prior work has introduced strategies for filtering pseudo-labels using probabilistic segmentation for semi-supervised learning; either using the dropout approach \cite{yu_uncertainty-aware_2019,sedai2019uncertainty} or inconsistencies between different models \cite{shi_inconsistency-aware_2021}.
%Compared to the prior work, we extend probabilistic segmentation to domain adaptation, make use of modern probabilistic segmentation and self-training methods, and study different domain adaptation settings.

\section{Methods}

We propose a new approach to domain adaptation for semantic segmentation. We first introduce the self-training methodology (first paragraph), review its application to domain adaptation (second paragraph), review probabilistic segmentation (third paragraph), and explain how we combine these elements for probabilistic domain adaptation (fourth paragraph).  Exact definitions for all terms are given in App.~\ref{app_definitions}.

% PASSABLE DRAFT 
\paragraph{Self-training for semi-supervised learning:} Self-training approaches train a model using the labeled samples to compute a supervised loss term $L_s$ and the unlabeled samples to compute an unsupervised loss term $L_u$. The term $L_u$ is formulated based on a student-teacher set-up, which uses the teacher predictions as pseudo-labels. For the student the same model that is trained via $L_s$ is used, the teacher is derived from it (e.g. by weight sharing or EMA of the weights). To avoid over-fitting to the teacher predictions, the inputs to the student and teacher are transformed with different augmentations and the pseudo-labels are filtered and/or post-processed.  
Denoting the supervised inputs and labels as $x_s$ and $y_s$, the inputs without labels as $x_u$, the student and teacher model as $s$ and $t$, the augmentations for the student and teacher as $\tau_s$ and $\tau_t$, the function that filters the pseudo-labels as $f$ and the function that post-processes them as $p$, we can write the generation of pseudo-labels $\hat{y}_u$ and the combined loss $L$ as:
\begin{equation} \label{eq_pseudolabels}
    \hat{y}_u = p(t(\tau_t(x_u))),
\end{equation}
\begin{equation} \label{eq_loss}
    L = L_s(s(x_s), \, y_s) + L_u(f(s(\tau_s(x_u)), \, \hat{y}_u)).
\end{equation}
The operations in Eq.~\ref{eq_pseudolabels} are not taken into account for the gradient computation. We obtain \textit{MeanTeacher} \cite{tarvainen_mean_2018} from Eq.~\ref{eq_pseudolabels} and \ref{eq_loss} by choosing $\tau_s$ and $\tau_t$ to be weak augmentations from the same distribution, choosing both $f$ and $p$ to be the identity function (i.e. pseudo-labels are neither filtered nor post-processed), and computing the teacher weights $w_t$ as the EMA of the student weights $w_s$: $w_t = \alpha \, w_t + (1 - \alpha) \, w_s$ with $\alpha$ close to 1. We obtain \textit{FixMatch} \cite{sohn_fixmatch_2020} by choosing $\tau_s$ to be strong augmentations, $\tau_t$ to be weak augmentations, $t$ to share weights with $s$, $f$ to filter out predictions with a probability below a given threshold, and $p$ to set the predicted values to 1 if they are above that threshold. We apply \textit{MeanTeacher} and \textit{FixMatch} to semantic segmentation. Our modifications for this task, including the choices for $L_s$ and $L_u$, are given in the last paragraph.

% PASSABLE DRAFT
\paragraph{Self-training for domain adaptation:} There are two possible strategies for applying the self-training procedures from the previous paragraph to domain adaptation: in the \textit{joint strategy} the model is trained according to Eq.~\ref{eq_pseudolabels} and \ref{eq_loss} using the source data as labeled samples $(x_s, y_s)$ and the target data as unlabeled samples $x_u$. In the \textit{separate strategy} the model is pre-trained on the source domain, using the supervised loss $L_s$, and then adapted to the target domain, using the unsupervised loss $L_u$.
The \textit{joint strategy} is a direct extension of semi-supervised learning to domain adaptation, as \textit{AdaMatch} \cite{berthelot_adamatch_2022} has shown through a unified formulation of both learning paradigms.
In contrast, the \textit{separate strategy} requires two training stages, which complicates the set-up. However, it has the practical advantage that only a single model has to be pre-trained per task, which can then be fine-tuned for a new target dataset without access to the source data and with a small computational budget. In comparison, the \textit{joint strategy} requires training a model for each source-target pair, with access to the source data. Here, we compare both domain adaptation strategies.

% PASSABLE DRAFT
\paragraph{Probabilistic segmentation:} Probabilistic segmentation methods have been introduced to account for the inherent uncertainty of the segmentation tasks: in many cases there is not a single "true" segmentation solution, but rather a distribution. For example, in the case of radiology, lesions are often annotated differently by experts, without a definite consensus solution. To model this label uncertainty, probabilistic segmentation methods enable sampling diverse segmentation results instead of providing a deterministic result. 
Here, we use the PUNet \cite{kohl_probabilistic_2019}: it combines a UNet \cite{ronneberger2015u}, which learns deterministic features, with a conditional variational autoencoder \cite{NIPS2015_8d55a249} that enables sampling. During training it uses a prior encoder, which sees only the images, and a posterior encoder, which sees the images and labels. Both encoders map their respective inputs to the parameters of a multi-dimensional gaussian distribution; sampling from it yields representations in a latent space. The latent samples from the posterior and the UNet features are concatenated and passed to additional layers to obtain the segmentation result. The architecture is trained using a variational loss term $L_{var}$ that minimizes the distance between the distributions of the prior and posterior encoder, and a reconstruction loss term $L_{rec}$ that minimizes the difference between prediction and labels. For inference the prior encoder is used for sampling. See Fig.~\ref{fig2} for an overview of the PUNet architecture and training.

Here, we use the PUNet to sample diverse predictions and implement better pseudo-label filtering compared to thresholding the predictions of a deterministic model.
We introduce the \textit{consensus response} $C$. Given predictions $m(x_i)^k_j$ from a PUNet $m$ for pixel $i$, class $k$ and sample $j$, the per pixel response $c_i$ is:
\begin{equation} \label{eq_consensus}  % IMPROVE NOTATION!
    c_i = \frac{1}{N} \sum_j^N \, \{1 \, \textrm{if} \, t(x_i)^k_j \ge \theta \, \textrm{for any} \, k \in K\ \, \textrm{else} \, 0\}.
\end{equation}
Here, $\theta$ denotes the threshold parameter, $N$ the number of samples and $K$ the number of classes. This expression generalizes the thresholding approach for a single prediction, which is recovered for $N=1$. See the next paragraph for how $C$ is used for pseudo-label filtering.
% TODO can we add some result that shows how consensus masking improves impurity?

% PASSABLE
\paragraph{Probabilistic domain adaptation:} We combine the elements from the previous paragraphs into a family of methods for probabilistic domain adaptation. We follow the PUNet implementation of \cite{kohl_probabilistic_2019}, but use the dice score for $L_{rec}$ instead of the cross entropy. We use the same loss function ($L = L_{var} + L_{rec}$) for both $L_s$ and $L_u$ (see Eq.~\ref{eq_loss}). We do not use pseudo-label post-processing, i.e. $p$ is the identity (cf. Eq~\ref{eq_pseudolabels}).
We study two different settings for self-training: for \textit{MeanTeacher} $\tau_s$ and $\tau_t$ are both weak augmentations and the teacher weights are the EMA of the student weights. For \textit{FixMatch} $\tau_s$ are strong augmentations, $\tau_t$ are weak augmentations and the student and teacher share weights. We use the consensus response $C$ (Eq.~\ref{eq_consensus}) for filtering the reconstruction loss $L_{rec}$. Here, we explore three different settings: \textit{consensus masking}, which masks the pixels that do not fulfill $c_i = 1$, \textit{consensus weighting}, which weights the loss with the value of $c_i$, and no filtering. The set-up for unsupervised training is shown in Fig.\ref{fig1}. We also investigate both the \textit{joint} and \textit{separate} domain adaptation strategies. Tab.~\ref{tab_methods} gives an overview of the proposed methods and the corresponding abbreviations. Pseudo-code for the methods can be found in App~\ref{app_pseudocode}.
\vspace{-0.7cm}
\begin{table}[h]
\centering
\caption{Proposed probabilistic domain adaptation methods and abbreviations.}
\label{tab_methods}
\begin{tabular}{lcccccc}
\toprule
         & \multicolumn{3}{c}{FixMatch}           & \multicolumn{3}{c}{MeanTeacher}         \\
         & cons. masking & cons. weighting & none & cons. masking & cons. weighting & none  \\ 
\midrule
joint    & $FM^m_j$      & $FM^w_j$        &$FM_j$& $MT^m_j$      & $MT^w_j$        & $MT_j$\\
separate & $FM^m_s$      & $FM^w_s$        &$FM_j$& $MT^m_s$      & $MT^w_s$        & $MT_s$\\
\bottomrule
\end{tabular}
\end{table}

\vspace{-0.9cm}
\section{Results}

We perform experiments for three different domain adaptation settings: cell segmentation in livecell microscopy, mitochondria segmentation in EM and lung segmentation in X-Ray. Model implementation and hyperparameters are documented in detail in App.~\ref{app_method_details}, the datasets in App.~\ref{app_dataset_details}.

\vspace{-0.2cm}
\subsection{Domain Adaptation Results}

We perform comprehensive experiments for cell segmentation in livecell microscopy. We use data from LiveCELL \cite{edlund2021livecell}, which contains 5,000 images with cell instance labels for 8 different cell lines. We transform the instance labels to binary masks for semantic segmentation, treat each cell line as a different domain and evaluate the segmentation quality for all source target pairs. In Tab. ~\ref{tab1} the averaged dice scores for each source domain applied to the 7 corresponding target domains are given. We evaluate four of our approaches ($MT_s^m, MT_s, FM_j^m, FM_j$), a \textit{separate} and a \textit{joint} adaptation strategy, with and without masking. For the $MT$ approaches we use blurring and additive noise as augmentations, and for $FM$ stronger blurring, noise as and contrast shifts as strong augmentations. We compare to the following baselines: UNet ($UNet$), PUNet ($PUNet$) and the method from \cite{edlund2021livecell} (LiveCELL) are trained on source and applied directly to the target, $PUNet_{trg}$ is a simpler adaptation strategy that uses pseudo-labels predicted by the source PUNet for training from scratch, $PUNet_{trg}^m$ additionally uses masking. More results can be found in App.~\ref{app_livecell_results}.

%\vspace{-0.3cm}
\begin{table}[h]
\centering
\caption{Livecell segmentation results. Methods above the midline do not use adaptation, italic means trained by us and same network architecture.} \label{tab1}
\begin{tabular}{lrrrrrrrr}
\toprule
Method & A172 & BT474 & BV2 & Huh7 & MCF7 & SHSY5Y & SkBr3 & SKOV3 \\
\midrule
$UNet$ & 0.87 & 0.82 & 0.68 & 0.71 & 0.85 & 0.81 & 0.82 & 0.86 \\
$PUNet$ & 0.87 & 0.83 & 0.49 & 0.79 & 0.86 & 0.79 & 0.72 & 0.88 \\
LiveCELL & 0.84 & 0.81 & 0.30 & 0.79 & 0.75 & 0.79 & 0.81 & 0.87 \\
\midrule
$PUNet_{trg}$ & 0.88 & 0.84 & 0.51 & 0.81 & 0.86 & 0.79 & 0.73 & 0.88 \\
$PUNet_{trg}^m$ & 0.89 & 0.86 & 0.54 & 0.82 & 0.87 & 0.84 & 0.73 & 0.89 \\
$MT_s$ & 0.87 & 0.83 & 0.54 & 0.79 & 0.87 & 0.81 & 0.70 & 0.87 \\
$MT_s^m$ & 0.88 & 0.86 & 0.76 & 0.83 & 0.89 & 0.88 & 0.69 & 0.88 \\
$FM_j$ & 0.88 & 0.88 & 0.81 & 0.88 & 0.88 & 0.86 & 0.87 & 0.86 \\
$FM_j^m$ & 0.86 & 0.88 & 0.82 & 0.88 & 0.88 & 0.81 & 0.85 & 0.87 \\
\bottomrule
\end{tabular}
\end{table}
%\vspace{-0.3cm}

We see that some adaptation tasks (A172, BT474, SHSY5Y, SKOV3) are easy and all methods perform similar. For the more difficult tasks (BV2, Huh7, SkBr3) the self-training approaches, in particular $FM_j$ and $FM_j^m$, significantly improve the results. We see a clear advantage of masking for $MT$, but no significant effect on $PUNet_{trg}$ and $FM_j$. Qualitative results are shown in Fig.~\ref{fig_livecell}.

We demonstrate the potential of our approach for EM mitochondria segmentation, using \textit{MitoEM} \cite{wei2020mitoem} as source dataset. It contains two large volumes with instance labels that we binarize for semantic segmentation. We use the datasets from \textit{Lucchi} \cite{lucchi2012structured} and \textit{VNC} \cite{gerhard2013segmented} as targets and address 2d segmentation. Tab. ~\ref{tab2} shows the results. We only use the $MT_s$ approaches since joint training would take long due to the large source data. We include $UNet$ and $PUNet$ trained on \textit{MitoEM}. Our methods significantly improve results, in particular $MT_s^w$.   

%\vspace{-0.4cm}
\begin{figure}[hb]
    \centering
    \includegraphics[width=\textwidth]{figures/fig3.png}
    \caption{Qualtiative results for livecell segmentation: left image shows the source domain with labels, right shows the target domain, including predictions from four methods, PUNet trained on source, adapted to target, and two self-training approaches.}
    \label{fig_livecell}
\end{figure}
%\vspace{-0.4cm}

\begin{table}[h]
\parbox{.45\linewidth}{
\centering
\small{
\caption{EM Segmentation.} \label{tab2}
\begin{tabular}{lrr}
\toprule
Method & Lucchi & VNC \\
\midrule
$UNet$ & 0.86 & 0.59 \\
$PUNet$ & 0.80 & 0.46 \\
\midrule
$MT_s$ & 0.81 & 0.63 \\
$MT_s^m$ & 0.84 & 0.73 \\
$MT_s^w$ & 0.90 & 0.74 \\
\bottomrule
\end{tabular}
}
}
\parbox{.45\linewidth}{
\centering
\caption{X-Ray segmentation.} \label{tab3}
\small{
\begin{tabular}{lrrrr}
\toprule
Method & NIH & Montgomery & JSRT1 & JSRT2 \\
\midrule
$UNet$ & 0.77 & 0.78 & 0.72 & 0.08 \\
$PUNet$ & 0.76 & 0.75 & 0.73 & 0.12 \\
\midrule
$MT_s$ & 0.78 & 0.77 & 0.77 & 0.12 \\
$MT_s^m$ & 0.78 & 0.77 & 0.77 & 0.11 \\
$MT_j$ & 0.78 & 0.77 & 0.69 & 0.21 \\
$MT_j^m$ & 0.82 & 0.80 & 0.73 & 0.21 \\
\bottomrule
\end{tabular}
}
}
\end{table}
%\vspace{-0.4cm}

We also demonstrate the potential for medical imaging, using three datasets for X-Ray lung segmentation: \textit{NIH} \cite{tang2019xlsor}, \textit{Montgomery} \cite{jaeger2014two} and \textit{JSRT} \cite{shiraishi2000development}. The latter contains two set-ups, so we obtain 4 domains and study the adaptation between all pairs. We only study $MT$ methods, and compare to the source $UNet$ and $PUNet$ baselines. Our methods improve results for most settings, masking is beneficial for $MT_j$ and does not have a significant effect for $MT_s$. Note that \textit{JSRT2} consists of inverted XRay image and presents a hard adaptation task. While none of the methods succeed, $MT_j$ shows better relative performance.

\vspace{-0.4cm}
\subsection{Ablation Studies}

We study pseudo-label filtering (masking $m$, weighting $w$, no filtering) in more detail. Tab.~\ref{tab_weighting} shows the results for the difficult livecell adaptation settings. We see that filtering consistently improves results, except for $FM_j$ where it does not have a significant effect. In most cases masking yields better results than weighting, except for $MT_j$. In Tab.~\ref{tab_strategies} we investigate the two adaptation strategies. We see that joint training, in particular $FM_j$ yields overall better results, $FM_s$ yields inferior results and we have observed unstable training for this method.

\vspace{-0.6cm}
\begin{table}
\parbox{.45\linewidth}{
\centering
\caption{Pseudo-label filtering.}
\label{tab_weighting}
\small{
\begin{tabular}{lrrr}
\toprule
Method & BV2 & Huh7 & SkBr3 \\
\midrule
$MT_s$ & 0.54 & 0.79 & 0.70 \\
$MT_s^m$ & 0.76 & 0.83 & 0.69 \\
$MT_s^w$ & 0.65 & 0.79 & 0.74 \\
$MT_j$ & 0.64 & 0.68 & 0.59 \\
$MT_j^m$ & 0.83 & 0.75 & 0.63 \\
$MT_j^w$ & 0.78 & 0.85 & 0.81 \\
$FM_j$ & 0.81 & 0.88 & 0.87 \\
$FM_j^m$ & 0.82 & 0.88 & 0.85 \\
$FM_j^w$ & 0.69 & 0.77 & 0.86 \\
\bottomrule
\end{tabular}
}
}
\parbox{.45\linewidth}{
\centering
\caption{Domain adaptation strategies.}
\label{tab_strategies}
\small{
\begin{tabular}{lrrr}
\toprule
Method & BV2 & Huh7 & SkBr3 \\
\midrule
$MT_s$ & 0.54 & 0.79 & 0.70 \\
$MT_s^m$ & 0.76 & 0.83 & 0.69 \\
$MT_j$ & 0.64 & 0.68 & 0.59 \\
$MT_j^m$ & 0.83 & 0.75 & 0.63 \\
$FM_s$ & 0.43 & 0.74 & 0.74 \\
$FM_s^m$ & 0.52 & 0.79 & 0.70 \\
$FM_j$ & 0.81 & 0.88 & 0.87 \\
$FM_j^m$ & 0.82 & 0.88 & 0.85 \\
\bottomrule
\end{tabular}
}
}
\end{table}
\vspace{-0.8cm}

\section{Discussion}
\vspace{-0.3cm}

Among our probabilistic domain adaptation methods $FM_j$ shows the best overall performance, while $MT_s$ is competitive in may settings. It can be shipped as pre-trained model, a clear practical advantage. Pseudo-label filtering via \textit{consensus masking} improves quality in most cases, in particular for difficult adaptation tasks. It does not always yield better results; we hypothesize that this is due to low masking rates and plan to investigate mitigation strategies. 
We see the potential to improve our methods via better probabilistic segmentation (e.g. \cite{kohl_hierarchical_2019}) and better strong augmentations, e.g. \textit{CutMix} \cite{yun_cutmix_2019}, which has shown success in semi-supervision \cite{yang_revisiting_2022}. We envision that these improvements will yield competitive $MT_s$ or $FM_s$ strategies to build user friendly tools. Finally, we plan to extend our approach to instance segmentation see App.~\ref{app_instance_seg}.

\section{Acknowledgments}
We would like to express their gratitude to Sartorius AG for support of this re-
search through the Quantitative Cell Analytics Initiative (QuCellAI) and would
also like to extend our thanks to all partners involved in the initiative for their
contributions and valuable insights. We also gratefully acknowledge the com-
puting time granted by the Resource Allocation Board and provided on the
supercomputer Lise and Emmy at NHR@ZIB and NHR@Göttingen as part of
the NHR infrastructure. The calculations for this research were conducted with
computing resources under the project nim00007.

\FloatBarrier
% References
{
\footnotesize
\bibliographystyle{splncs04}
\bibliography{main}
}

%\clearpage
\appendix
\input{appendix}

\end{document}
