@book{aigner2011vot,
	title		= {{Visualization of Time-Oriented Data}},
	series		= {Human-Computer Interaction Series (HCIS)},
	author 		= {Wolfgang Aigner and Silvia Miksch and Heidrun Schumann and Christian Tominski},
	editor 		= {},
	edition 	= {1st},
	publisher	= {Springer London},
	year		= {2011},
	month		= "",
	language	= {english},
	url			= {https://doi.org/10.1007/978-0-85729-079-3},
	doi 		= {10.1007/978-0-85729-079-3},
	isbn		= {9780857290786},
	keywords	= {},
	abstract	= {Time is an exceptional dimension that is common to many application domains such as medicine, engineering, business, science, biography, history, planning, or project management. Understanding time-oriented data enables us to learn from the past in order to predict, plan, and build the future. Due to the distinct characteristics of time, appropriate visual and analytical methods are required to explore and analyze them.

	This book starts with an introduction to visualization and a number of historical examples of visual representations. At its core, the book presents and discusses a systematic view of the visualization of time-oriented data. This view is structured along three key questions. While the aspects of time and associated data describe what is being visualized, user tasks are related to the question why something is visualized. These characteristics and tasks determine how the visualization is to be designed. To support visual exploration, interaction techniques and analytical methods are required as well, which are discussed in separate chapters. The concepts explained in this book are illustrated with numerous examples.

	A large part of this book is devoted to a structured survey of existing techniques for visualizing time and time-oriented data. Overall, 101 different visualization techniques are presented on a per-page basis; each of these self-contained descriptions is accompanied by an illustration and corresponding references.  This survey serves as a reference for scientists conducting related research as well as for practitioners seeking information on how their time-oriented data can best be visualized in order to gain valuable insights.}
}

@book{andrienko2006eao,
	title		= {{Exploratory Analysis of Spatial and Temporal Data: A Systematic Approach}},
	series		= {},
	author 		= {Natalia Andrienko and Gennady Andrienko},
	editor 		= {},
	edition 	= {1st},
	publisher	= {Springer, Berlin, Heidelberg},
	year		= {2006},
	month		= "",
	language	= {english},
	url			= {https://doi.org/10.1007/3-540-31190-4},
	doi 		= {10.1007/3-540-31190-4},
	isbn		= {978-3-540-31190-4},
	keywords	= {},
	abstract	= {Exploratory data analysis (EDA) is about detecting and describing patterns, trends, and relations in data, motivated by certain purposes of investigation. As something relevant is detected in data, new questions arise, causing specific parts to be viewed in more detail. So EDA has a significant appeal: it involves hypothesis generation rather than mere hypothesis testing.

	The authors describe in detail and systemize approaches, techniques, and methods for exploring spatial and temporal data in particular. They start by developing a general view of data structures and characteristics and then build on top of this a general task typology, distinguishing between elementary and synoptic tasks. This typology is then applied to the description of existing approaches and technologies, resulting not just in recommendations for choosing methods but in a set of generic procedures for data exploration.

	Professionals practicing analysis will profit from tested solutions – illustrated in many examples – for reuse in the catalogue of techniques presented. Students and researchers will appreciate the detailed description and classification of exploration techniques, which are not limited to spatial data only. In addition, the general principles and approaches described will be useful for designers of new methods for EDA.}
}

@incollection{andriessen2003gp,
	author 		= {J. H. Erik Andriessen},
	title 		= {{Group Processes}},
	booktitle 	= {Working with {Groupware}: Understanding and Evaluating Collaboration Technology},
	series 		= {Computer Supported Cooperative Work (CSCW)},
	editor 		= {},
	pages		= {89--124},
	edition 	= {},
	publisher	= {Springer, London},
	year		= {2003},
	language	= {english},
	url			= {https://doi.org/10.1007/978-1-4471-0067-6_6},
	doi 		= {10.1007/978-1-4471-0067-6_6},
	isbn		= {978-1-4471-0067-6},
	keywords	= {Group Process, Interpersonal Communication, Context Awareness, Mediate Communication, Computer Mediate Communication},
	abstract	= {The previous chapter ended with the conclusion that group norms can be a powerful determinant of acceptance and use of tools and media. This argument is developed further in this chapter. Use of Collaboration technology is part and parcel of social activities and group dynamics. It is assumed to make interaction processes easier and more effective. Its main focus is not to support individual work but to support co-operative work. This chapter is devoted to answering the following questions: What is the essence of co-operative work? What is effective co-operative work and what is the role of collaboration technology in distributed co-operative work? A major part of this chapter is therefore devoted to an analysis of group dynamics and team effectiveness.}
}

@incollection{billinghurst2018cia,
	author 		= {Mark Billinghurst and Maxime Cordeil and Anastasia Bezerianos and Todd Margolis},
	title 		= {{Collaborative Immersive Analytics}},
	booktitle 	= {Immersive Analytics},
	series 		= {Lecture Notes in Computer Science (LNCS, volume 11190)},
	editor 		= {Kim Marriott and Falk Schreiber and Tim Dwyer and Karsten Klein and Nathalie Henry Riche and Takayuki Itoh and Wolfgang Stuerzlinger and Bruce H. Thomas},
	pages		= {221--257},
	edition 	= {First Online},
	publisher	= {Springer, Cham},
	year		= {2018},
	month		= "16~" # oct,
	language	= {english},
	url			= {https://doi.org/10.1007/978-3-030-01388-2_8},
	doi 		= {10.1007/978-3-030-01388-2_8},
	isbn		= {978-3-030-01388-2},
	keywords	= {},
	abstract	= {Many of the problems being addressed by Immersive Analytics require groups of people to solve. This chapter introduces the concept of Collaborative Immersive Analytics (CIA) and reviews how immersive technologies can be combined with Visual Analytics to facilitate co-located and remote collaboration. We provide a definition of Collaborative Immersive Analytics and then an overview of the different types of possible collaboration. The chapter also discusses the various roles in collaborative systems, and how to support shared interaction with the data being presented. Finally, we summarize the opportunities for future research in this domain. The aim of the chapter is to provide enough of an introduction to CIA and key directions for future research, so that practitioners will be able to begin working in the field.}
}

@inproceedings{butcher2019vaf,
	author		= {Peter W. S. Butcher and Nigel W. John and Panagiotis D. Ritsos},
	title		= {{{VRIA} - A Framework for {Immersive Analytics} on the Web}},
	booktitle	= {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (CHI EA 2019)},
	pages		= {LBW2615:1--6},
	address		= {Glasgow, Schotland, UK},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {2019},
	month		= "4--9~" # may,
	language	= {english},
	url			= {https://doi.org/10.1145/3290607.3312798},
	doi 		= {10.1145/3290607.3312798},
	isbn		= {978-1-4503-5971-9},
	keywords	= {},
	abstract	= {We report on the design, implementation and evaluation of <VRIA>, a framework for building immersive analytics (IA) solutions in Web-based Virtual Reality (VR), built upon WebVR, A-Frame, React and D3. The recent emergence of affordable VR interfaces have reignited the interest of researchers and developers in exploring new, immersive ways to visualize data. In particular, the use of open-standards web-based technologies for implementing VR in a browser facilitates the ubiquitous and platform-independent adoption of IA systems. Moreover, such technologies work in synergy with established visualization libraries, through the HTML document object model (DOM). We discuss high-level features of <VRIA> and present a preliminary user experience evaluation of one of our use cases.}
}

@article{casarin2018uau,
	author		= {Julien Casarin and Nicolas Pacqueriaud and Dominique Bechmann},
	title		= {{{UMI3D}: A {Unity3D} Toolbox to Support {CSCW} Systems Properties in Generic {3D User Interfaces}}},
	journal		= {Proceedings of the ACM on Human-Computer Interaction},
	pages		= {29:1--20},
	volume		= {2},
	number		= {CSCW},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {2018},
	month		= "" # nov,
	language	= {english},
	url			= {https://doi.org/10.1145/3274298},
	doi 		= {10.1145/3274298},
	keywords	= {UMI3D, collaborative virtual environments, computer-supported cooperative work, interaction design},
	abstract	= {UMI3D is a recent model which allows the generic description of 3D environments through a network. These generic environments can run outside of any device, on a server or on a separate computer. A unique dedicated application that we have named UMI3D client allows a VR, AR or MR device to interact with all the existing UMI3D environments. Moreover, the client-server architecture allows these environments to be collaborative. In this paper, we introduce a toolbox which allows the creation and running of UMI3D collaborative environments using Unity 3D. It contains tools to address the main concerns of computer-supported cooperative work (CSCW) systems in UMI3D environments. After introducing the contribution of this toolbox to the design of 3D CSCW systems, we present a user evaluation of an environment designed with this toolbox. Finally, we discuss the limits of the UMI3D model and the improvements that could be made to this model.}
}

@inproceedings{chen2018idm,
	author		= {Taizhou Chen and Yi-Shiun Wu and Kening Zhu},
	title		= {{Investigating Different Modalities of Directional Cues for Multi-task Visual-Searching Scenario in {Virtual Reality}}},
	booktitle	= {Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology (VRST 2018)},
	pages		= {41:1--5},
	address		= {Tokyo, Japan},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {2018},
	month		= "28~" # nov # "--" # "1~" # dec,
	language	= {english},
	url			= {https://doi.org/10.1145/3281505.3281516},
	doi 		= {10.1145/3281505.3281516},
	isbn		= {978-1-4503-6086-9},
	keywords	= {Directional cue, Vibration, Visual, Auditory, Multi-task, Virtual reality},
	abstract	= {In this study, we investigated and compared the effectiveness of visual, auditory, and vibrotactile directional cues on multiple simultaneous visual-searching tasks in an immersive virtual environment. Effectiveness was determined by the task-completion time, the range of head movement, the accuracy of the identification task, and the perceived workload. Our experiment showed that the on-head vibrotactile display can effectively guide users towards virtual visual targets, without affecting their performance on the other simultaneous tasks, in the immersive VR environment. These results can be applied to numerous applications (e.g. gaming, driving, and piloting) in which there are usually multiple simultaneous tasks, and the user experience and performance could be vulnerable.}
}

@article{churchill1998cve,
	author		= {Elizabeth F. Churchill and David Snowdon},
	title		= {{{Collaborative Virtual Environments}: An Introductory Review of Issues and Systems}},
	journal		= {Virtual Reality},
	pages		= {3--15},
	volume		= {3},
	number		= {1},
	publisher	= {Springer},
	year		= {1998},
	month		= "" # mar,
	language	= {english},
	url			= {https://doi.org/10.1007/BF01409793},
	doi 		= {10.1007/BF01409793},
	keywords	= {Virtual environments, Virtual spaces, Collaboration and communication, Virtual embodiments, Computer supported co-operative work (CSCW)},
	abstract	= {A Collaborative Virtual Environment or CVE is a distributed, virtual reality that is designed to support collaborative activities. As such, CVEs provide a potentially infinite, graphically realised digital landscape within which multiple users can interact with each other and with simple or complex data representations. CVEs are increasingly being used to support collaborative work between geographically separated and between collocated collaborators. CVEs vary in the sophistication of the data and embodiment representations employed and in the level of interactivity supported. It is clear that systems which are intended to support collaborative activities should be designed with explicit consideration of the tasks to be achieved and the intended users' social and cognitive characteristics. In this paper, we detail a number of existing systems and applications, but first discuss the nature of collaborative and cooperative work activities and consider the place of virtual reality systems in supporting such collaborative work. Following this, we discuss some future research directions.}
}

@incollection{clark1991gic,
	author 		= {Herbert H. Clark and Susan E. Brennan},
	title 		= {{Grounding in communication}},
	booktitle 	= {Perspectives on socially shared cognition},
	series 		= {},
	editor 		= {Lauren Resnick and John M. Levine and Stephanie D. Teasley},
	pages		= {127--149},
	edition 	= {},
	publisher	= {American Psychological Association},
	year		= {1991},
	language	= {english},
	url			= {https://doi.org/10.1037/10096-006},
	doi 		= {10.1037/10096-006},
	isbn		= {0-8058-4014-1},
	keywords	= {},
	abstract	= {}
}

@inproceedings{cordeil2019iai,
	author		= {Maxime Cordeil and Andrew Cunningham and Benjamin Bach and Christophe Hurter and Bruce H. Thomas and Kim Marriott and Tim Dwyer},
	title		= {{{IATK}: An {Immersive Analytics} Toolkit}},
	booktitle	= {Proceedings of the IEEE Conference on Virtual Reality and 3D User Interfaces (VR 2019)},
	pages		= {200--209},
	address		= {Osaka, Japan},
	publisher	= {Institute of Electrical and Electronics Engineers (IEEE)},
	year		= {2019},
	month		= "23--27~" # mar,
	language	= {english},
	url			= {https://doi.org/10.1109/VR.2019.8797978},
	doi 		= {10.1109/VR.2019.8797978},
	isbn		= {978-1-7281-1377-7},
	keywords	= {},
	abstract	= {We introduce IATK, the Immersive Analytics Toolkit, a software package for Unity that allows interactive authoring and exploration of data visualisation in immersive environments. The design of IATK was informed by interdisciplinary expert-collaborations as well as visual analytics applications and iterative refinement over several years. IATK allows for easy assembly of visualisations through a grammar of graphics that a user can configure in a GUI-in addition to a dedicated visualisation API that supports the creation of novel immersive visualisation designs and interactions. IATK is designed with scalability in mind, allowing visualisation and fluid responsive interactions in the order of several million points at a usable frame rate. This paper outlines our design requirements, IATK's framework design and technical features, its user interface, as well as application examples.}
}

@incollection{dwyer2018iai,
	author 		= {Tim Dwyer and Kim Marriott and Tobias Isenberg and Karsten Klein and Nathalie Henry Riche and Flak Schreiber and Wolfgang Stuerzlinger},
	title 		= {{{Immersive Analytics}: An Introduction}},
	booktitle 	= {Immersive Analytics},
	series 		= {Lecture Notes in Computer Science (LNCS, volume 11190)},
	editor 		= {Kim Marriott and Falk Schreiber and Tim Dwyer and Karsten Klein and Nathalie Henry Riche and Takayuki Itoh and Wolfgang Stuerzlinger and Bruce H. Thomas},
	pages		= {1--23},
	edition 	= {First Online},
	publisher	= {Springer, Cham},
	year		= {2018},
	month		= "16~" # oct,
	language	= {english},
	url			= {https://doi.org/10.1007/978-3-030-01388-2_1},
	doi 		= {10.1007/978-3-030-01388-2_1},
	isbn		= {978-3-030-01388-2},
	keywords	= {},
	abstract	= {Immersive Analytics is a new research initiative that aims to remove barriers between people, their data and the tools they use for analysis and decision making. Here we clarify the aims of immersive analytics research, its opportunities and historical context, as well as providing a broad research agenda for the field. In addition, we review how the term immersion has been used to refer to both technological and psychological immersion, both of which are central to immersive analytics research.}
}

@article{ens2019rct,
	author		= {Barrett Ens and Joel Lanir and Anthony Tang and Scott Bateman and Gun Lee and Thammathip Piumsomboon and Mark Billinghurst},
	title		= {{Revisiting collaboration through {Mixed Reality}: The evolution of {Groupware}}},
	journal		= {International Journal of Human-Computer Studies},
	pages		= {81--98},
	volume		= {131},
	number		= {},
	publisher	= {Elsevier Science Inc.},
	year		= {2019},
	month		= "" # nov,
	language	= {english},
	url			= {https://doi.org/10.1016/j.ijhcs.2019.05.011},
	doi 		= {10.1016/j.ijhcs.2019.05.011},
	keywords	= {Collaborative mixed reality, Mixed reality, Augmented reality, Computer supported cooperative work, Collaborative technology},
	abstract	= {Collaborative Mixed Reality (MR) systems are at a critical point in time as they are soon to become more commonplace. However, MR technology has only recently matured to the point where researchers can focus deeply on the nuances of supporting collaboration, rather than needing to focus on creating the enabling technology. In parallel, but largely independently, the field of Computer Supported Cooperative Work (CSCW) has focused on the fundamental concerns that underlie human communication and collaboration over the past 30-plus years. Since MR research is now on the brink of moving into the real world, we reflect on three decades of collaborative MR research and try to reconcile it with existing theory from CSCW, to help position MR researchers to pursue fruitful directions for their work. To do this, we review the history of collaborative MR systems, investigating how the common taxonomies and frameworks in CSCW and MR research can be applied to existing work on collaborative MR systems, exploring where they have fallen behind, and look for new ways to describe current trends. Through identifying emergent trends, we suggest future directions for MR, and also find where CSCW researchers can explore new theory that more fully represents the future of working, playing and being with others.}
}

@inproceedings{ens2021gci,
	author		= {Barrett Ens and Benjamin Bach and Maxime Cordeil and Ulrich Engelke and Marcos Serrano and Wesley Willett and Arnaud Prouzeau and Christoph Anthes and Wolfgang Büschel and Cody Dunne and Tim Dwyer and Jens Grubert and Jason H. Haga and Nurit Kirshenbaum and Dylan Kobayashi and Tica Lin and Monsurat Olaosebikan and Fabian Pointecker and David Saffo and Nazmus Saquib and Dieter Schmalstieg and Danielle {Albers Szafir} and Matt Whitlock and Yalong Yang},
	title		= {{Grand Challenges in {Immersive Analytics}}},
	booktitle	= {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI 2021)},
	pages		= {459:1--17},
	address		= {Yokohama, Japan},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {2021},
	month		= "8--13~" # may,
	language	= {english},
	url			= {https://doi.org/10.1145/3411764.3446866},
	doi 		= {10.1145/3411764.3446866},
	isbn		= {},
	keywords	= {Immersive analytics, grand research challenges, data visualisation, augmented reality, virtual reality},
	abstract	= {Immersive Analytics is a quickly evolving field that unites several areas such as visualisation, immersive environments, and human-computer interaction to support human data analysis with emerging technologies. This research has thrived over the past years with multiple workshops, seminars, and a growing body of publications, spanning several conferences. Given the rapid advancement of interaction technologies and novel application domains, this paper aims toward a broader research agenda to enable widespread adoption. We present 17 key research challenges developed over multiple sessions by a diverse group of 24 international experts, initiated from a virtual scientific workshop at ACM CHI 2020. These challenges aim to coordinate future work by providing a systematic roadmap of current directions and impending hurdles to facilitate productive and effective applications for Immersive Analytics.}
}

@article{fonnet2021soi,
	author		= {Adrien Fonnet and Yannick Prié},
	title		= {{Survey of {Immersive Analytics}}},
	journal		= {IEEE Transactions on Visualization and Computer Graphics},
	pages		= {2101--2122},
	volume		= {27},
	number		= {3},
	publisher	= {Institute of Electrical and Electronics Engineers (IEEE)},
	year		= {2021},
	month		= "1~" # mar,
	language	= {english},
	url			= {https://doi.org/10.1109/TVCG.2019.2929033},
	doi 		= {10.1109/TVCG.2019.2929033},
	keywords	= {Immersive analytics, survey, virtual environments, immersive environments, data visualization, information visualization, scientific visualization, visual data mining},
	abstract	= {Immersive analytics (IA) is a new term referring to the use of immersive technologies for data analysis. Yet such applications are not new, and numerous contributions have been made in the last three decades. However, no survey reviewing all these contributions is available. Here we propose a survey of IA from the early nineties until the present day, describing how rendering technologies, data, sensory mapping, and interaction means have been used to build IA systems, as well as how these systems have been evaluated. The conclusions that emerge from our analysis are that: multi-sensory aspects of IA are under-exploited, the 3DUI and VR community knowledge regarding immersive interaction is not sufficiently utilised, the IA community should focus on converging towards best practices, as well as aim for real life IA systems.}
}

@article{gutwin2002dfw,
	author		= {Carl Gutwin and Saul Greenberg},
	title		= {{A Descriptive Framework of Workspace Awareness for Real-Time {Groupware}}},
	journal		= {Computer Supported Cooperative Work (CSCW)},
	pages		= {411--446},
	volume		= {11},
	number		= {3},
	publisher	= {Kluwer Academic Publishers},
	year		= {2002},
	month		= "1~" # sep,
	language	= {english},
	url			= {https://doi.org/10.1023/A:1021271517844},
	doi 		= {10.1023/A:1021271517844},
	keywords	= {},
	abstract	= {Supporting awareness of others is an idea that holds promise forimproving the usability of real-time distributed groupware.However, there is little principled information available aboutawareness that can be used by groupware designers. In thisarticle, we develop a descriptive theory of awareness for thepurpose of aiding groupware design, focusing on one kind of groupawareness called workspace awareness. We focus on how smallgroups perform generation and execution tasks in medium-sizedshared workspaces -- tasks where group members frequently shiftbetween individual and shared activities during the work session.We have built a three-part framework that examines the concept ofworkspace awareness and that helps designers understand theconcept for purposes of designing awareness support in groupware.The framework sets out elements of knowledge that make upworkspace awareness, perceptual mechanisms used to maintainawareness, and the ways that people use workspace awareness incollaboration. The framework also organizes previous research onawareness and extends it to provide designers with a vocabularyand a set of ground rules for analysing work situations, forcomparing awareness devices, and for explaining evaluationresults. The basic structure of the theory can be used todescribe other kinds of awareness that are important to theusability of groupware.}
}

@inproceedings{hackathorn2016iab,
	author		= {Richard Hackathorn and Todd Margolis},
	title		= {{{Immersive Analytics}: Building Virtual Data Worlds for Collaborative Decision Support}},
	series 		= {},
	booktitle	= {2016 Workshop on Immersive Analytics (IA)},
	editor		= {},
	volume		= {},
	pages		= {44--47},
	address		= {Greenville, South Carolina, USA},
	publisher	= {Institute of Electrical and Electronics Engineers (IEEE)},
	year		= {2016},
	month		= "20~" # mar,
	language	= {english},
	url			= {https://doi.org/10.1109/IMMERSIVE.2016.7932382},
	doi 		= {10.1109/IMMERSIVE.2016.7932382},
	isbn		= {},
	keywords	= {},
	abstract	= {Immersive analytics is an emerging research area that blends analytical reasoning with immersive virtual space to enhance collaborative decision support. The intent of this position paper is to stimulate discussion and cooperation toward maturing immersive analytics. An open innovation community to build immersive data worlds has been established at ImmersiveAnalytics.com, to serve as a bridge and catalyst between academia and corporate communities. The paper outlines the objectives for analytical reasoning and immersive data spaces, followed by suggestions for the design and architecture of data worlds. Finally, current work for building data worlds is described.}
}

@article{hart2006ntl,
	author		= {Sandra G. Hart},
	title		= {{{Nasa-Task Load Index} ({NASA-TLX}); 20 Years Later}},
	journal		= {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	pages		= {904--908},
	volume		= {50},
	number		= {9},
	publisher	= {Human Factors and Ergonomics Society},
	year		= {2006},
	month		= "" # oct,
	language	= {english},
	url			= {https://doi.org/10.1177/154193120605000909},
	doi 		= {10.1177/154193120605000909},
	keywords	= {},
	abstract	= {NASA-TLX is a multi-dimensional scale designed to obtain workload estimates from one or more operators while they are performing a task or immediately afterwards. The years of research that preceded subscale selection and the weighted averaging approach resulted in a tool that has proven to be reasonably easy to use and reliably sensitive to experimentally important manipulations over the past 20 years. Its use has spread far beyond its original application (aviation), focus (crew complement), and language (English). This survey of 550 studies in which NASA-TLX was used or reviewed was undertaken to provide a resource for a new generation of users. The goal was to summarize the environments in which it has been applied, the types of activities the raters performed, other variables that were measured that did (or did not) covary, methodological issues, and lessons learned}
}

@inproceedings{heer2008dcf,
	author		= {Jeffrey Heer and Maneesh Agrawala},
	title		= {{Design Considerations for {Collaborative Visual Analytics}}},
	series 		= {},
	booktitle	= {2007 IEEE Symposium on Visual Analytics Science and Technology},
	editor		= {},
	volume		= {},
	pages		= {171--178},
	address		= {Sacramento, California, USA},
	publisher	= {Institute of Electrical and Electronics Engineers (IEEE)},
	year		= {2008},
	month		= "30~" # oct # "--" # "1~" # nov,
	language	= {english},
	url			= {https://doi.org/10.1109/VAST.2007.4389011},
	doi 		= {10.1109/VAST.2007.4389011},
	isbn		= {978-1-4244-1659-2},
	keywords	= {},
	abstract	= {Information visualization leverages the human visual system to support the process of sensemaking, in which information is collected, organized, and analyzed to generate knowledge and inform action. Though most research to date assumes a single-user focus on perceptual and cognitive processes, in practice, sensemaking is often a social process involving parallelization of effort, discussion, and consensus building. This suggests that to fully support sensemaking, interactive visualization should also support social interaction. However, the most appropriate collaboration mechanisms for supporting this interaction are not immediately clear. In this article, we present design considerations for asynchronous collaboration in visual analysis environments, highlighting issues of work parallelization, communication, and social organization. These considerations provide a guide for the design and evaluation of collaborative visualization systems.}
}

@inproceedings{heidicker2017ioa,
	author		= {Paul Heidicker and Eike Langbehn and Frank Steinicke},
	title		= {{Influence of Avatar Appearance on Presence in {Social VR}}},
	booktitle	= {Proceedings of the IEEE Symposium on 3D User Interfaces (3DUI 2017)},
	pages		= {233--234},
	address		= {Los Angeles, California, USA},
	publisher	= {Institute of Electrical and Electronics Engineers (IEEE)},
	year		= {2017},
	month		= "18--19~" # mar,
	language	= {english},
	url			= {https://doi.org/10.1109/3DUI.2017.7893357},
	doi 		= {10.1109/3DUI.2017.7893357},
	isbn		= {978-1-5090-6716-9},
	keywords	= {Collaborative interaction, perception, presence},
	abstract	= {Social virtual reality (VR) has enormous potential to allow several physically separated users to collaborate in an immersive virtual environment (IVE). These users and their actions are represented by avatars in the IVE. In question is how the appearance of those avatars influences communication and interaction. It might make a difference, if the avatar consists of a complete body representation or if only certain body parts are visible. Moreover, a one-to-one mapping of the user's movements to the avatar's movements might have advantages compared to pre-defined avatar animations. To answer these questions, we compared three different types of avatar appearances in a user study. For this, we used estimations of presence, social presence, and cognitive load. The evaluation showed that motion-controlled avatars with full representation of the avatar body lead to an increased sense of presence. Motion-controlled avatars as well as avatars which have only head and hands visible produced an increased feeling of co-presence and behavioral interdependence. This is interesting, since it states that we do not need a complete avatar body in social VR.}
}

@article{isenberg2011cvd,
	author		= {Petra Isenberg and Niklas Elmqvist and Jean Scholtz and Daniel Cernea and Kwan-Liu Ma and Hans Hagen},
	title		= {{{Collaborative Visualization}: Definition, challenges, and research agenda}},
	journal		= {Information Visualization},
	pages		= {310--326},
	volume		= {10},
	number		= {4},
	publisher	= {SAGE Publishing},
	year		= {2011},
	month		= "1~" # oct,
	language	= {english},
	url			= {https://doi.org/10.1177/1473871611412817},
	doi 		= {10.1177/1473871611412817},
	keywords	= {collaboration, visualization, computer-supported cooperative work, teamwork},
	abstract	= {The conflux of two growing areas of technology – collaboration and visualization – into a new research direction, collaborative visualization, provides new research challenges. Technology now allows us to easily connect and collaborate with one another – in settings as diverse as over networked computers, across mobile devices, or using shared displays such as interactive walls and tabletop surfaces. Digital information is now regularly accessed by multiple people in order to share information, to view it together, to analyze it, or to form decisions. Visualizations are used to deal more effectively with large amounts of information while interactive visualizations allow users to explore the underlying data. While researchers face many challenges in collaboration and in visualization, the emergence of collaborative visualization poses additional challenges, but it is also an exciting opportunity to reach new audiences and applications for visualization tools and techniques.


	The purpose of this article is (1) to provide a definition, clear scope, and overview of the evolving field of collaborative visualization, (2) to help pinpoint the unique focus of collaborative visualization with its specific aspects, challenges, and requirements within the intersection of general computer-supported cooperative work and visualization research, and (3) to draw attention to important future research questions to be addressed by the community. We conclude by discussing a research agenda for future work on collaborative visualization and urge for a new generation of visualization tools that are designed with collaboration in mind from their very inception.}
}

@article{isenberg2012ccv,
	author		= {Petra Isenberg and Danyel Fisher and Sharoda A. Paul and Meredith Ringel Morris and Kori Inkpen and Mary Czerwinski},
	title		= {{Co-Located {Collaborative Visual Analytics} around a {Tabletop Display}}},
	journal		= {IEEE Transactions on Visualization and Computer Graphics},
	pages		= {689--792},
	volume		= {18},
	number		= {5},
	publisher	= {Institute of Electrical and Electronics Engineers (IEEE)},
	year		= {2012},
	month		= "" # may,
	language	= {english},
	url			= {https://doi.org/10.1109/TVCG.2011.287},
	doi 		= {10.1109/TVCG.2011.287},
	keywords	= {},
	abstract	= {Co-located collaboration can be extremely valuable during complex visual analytics tasks. We present an exploratory study of a system designed to support collaborative visual analysis tasks on a digital tabletop display. Fifteen participant pairs employed Cambiera, a visual analytics system, to solve a problem involving 240 digital documents. Our analysis, supported by observations, system logs, questionnaires, and interview data, explores how pairs approached the problem around the table. We contribute a unique, rich understanding of how users worked together around the table and identify eight types of collaboration styles that can be used to identify how closely people work together while problem solving. We show how the closeness of teams' collaboration and communication influenced how they performed on the task overall. We further discuss the role of the tabletop for visual analytics tasks and derive design implications for future co-located collaborative tabletop problem solving systems.}
}

@inproceedings{isenberg2014aic,
	author		= {Tobias Isenberg},
	title		= {{An Interaction Continuum for Visualization}},
	booktitle	= {Proceedings of the VIS Workshop on ``Death of the Desktop: Envisioning Visualization without Desktop Computing''},
	editor 		= {Yvonne Jansen and Petra Isenberg and Jason Dykes and Sheelagh Carpendale and Dan Keefe},
	pages		= {1--3},
	address		= {Paris, France},
	publisher	= {},
	year		= {2014},
	month		= "9~" # nov,
	language	= {english},
	url			= {https://hal.inria.fr/hal-01095454},
	doi 		= {},
	isbn		= {},
	keywords	= {Display environments for interactive data exploration and visualization},
	abstract	= {It is the year 2039, the desktop is not dead, and it does not look like this situation will change for a while. In any practical application domain in which data visualization is used, the desktop remains to be one of the most important tools for data exploration, analysis, and processing. Since the year 2014, non-desktop platforms for data exploration including large displays, immersive environments, tangible controls, and mobile devices have found their place for data visualization applications—but they have not and will not replace the desktop in many practically relevant tasks. Instead, researchers have finally begun to work toward an interactive visualization continuum that allows researchers and data analysts to transition between the different platforms and to use the tools for those tasks they support best: the desktop for in-depth, single-user analysis and novel platforms for group discussions, mobile data access, and/or good spatial perception.}
}

@book{johansen1988gcs,
	title		= {{{GroupWare}: Computer Support for Business Teams}},
	author 		= {Robert Johansen and Jeff Charles and Robert Mittman and Paul Saffo},
	editor 		= {},
	publisher	= {The Free Press},
	year		= {1988},
	month		= "1~" # oct,
	language	= {english},
	url			= {},
	isbn		= {0029164915},
	keywords	= {},
	abstract	= {}
}

@article{kolence1973sup,
	author		= {Kenneth W. Kolence and Philip J. Kiviat},
	title		= {{{Software Unit Profiles} \& {Kiviat Figures}}},
	journal		= {ACM SIGMETRICS Performance Evaluation Review},
	pages		= {2--12},
	volume		= {2},
	number		= {3},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {1973},
	month		= "" # sep,
	language	= {english},
	url			= {https://doi.org/10.1145/1041613.1041614},
	doi 		= {10.1145/1041613.1041614},
	issn 		= {0163-5999},
	keywords	= {},
	abstract	= {In the June, 1973 issue of the Performance Evaluation Review, the concept of using circular graphs (called Kiviat graphs by Kolence) to present system performance data was introduced in the column The Software Empiricist. In this article we wish to report on some recent work in using such graphs to present system and program profiles in a strikingly visual way of potential use to all practitioners of computer measurement. In discussing this data, we find it necessary to comment on the meaning of the variables used for such profiles in a way which also should be of interest to practitioners.}
}

@inproceedings{kristoffersen1999mpt,
	author		= {Steinar Kristoffersen and Fredrik Ljungberg},
	title		= {{{``Making Place''} to Make {IT} work: Empirical Explorations of {HCI} for {Mobile CSCW}}},
	booktitle	= {Proceedings of the international ACM SIGGROUP conference on Supporting group work (GROUP 1999)},
	pages		= {276--285},
	address		= {Phoenix, Arizona, USA},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {1999},
	month		= "" # nov,
	language	= {english},
	url			= {https://doi.org/10.1145/320297.320330},
	doi 		= {10.1145/320297.320330},
	isbn		= {},
	keywords	= {},
	abstract	= {Co-located environments have long been considered ideal for many types of group work, such as planning, decision-making, and design, since they provide a rich communication environment (e.g. delay-free voice communication, face-to-face interaction, eye gaze, and non-verbal communication), as well as promote awareness and coordination through the use of shared artifacts. However, the recent move towards multi-device ecologies in co-located settings, such as the use of multiple personal devices (e.g., laptops, tablets) or multiple personal devices in conjunction with larger, shared displays, such as digital walls or tabletops, can interfere with these common co-located communication and collaboration strategies, as various group members mentally and/or physical shift their focus to their personal devices rather than to their collaborators or to any physically shared artifacts. Group communications and coordination can easily breakdown in these scenarios as the lack of a physically shared group focus of attention can limit awareness of other's activities and task progress. In this workshop, researchers and practitioners will explore design techniques that can be used to address this issue, and improve group awareness in these co-located multi-device ecologies. This will be accomplished through group presentations, brainstorming sessions, and small-group breakout sessions.}
}

@inproceedings{lacoche2017caf,
	author		= {Jérémy Lacoche and Nico Pallamin and Thomas Boggini and Jérôme Royan},
	title		= {{Collaborators Awareness for User Cohabitation in Co-located Collaborative Virtual Environments}},
	booktitle	= {Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology (VRST 2017)},
	pages		= {15:1--9},
	address		= {Gothenburg, Sweden},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {2017},
	month		= "8--10~" # nov,
	language	= {english},
	url			= {https://doi.org/10.1145/3139131.3139142},
	doi 		= {10.1145/3139131.3139142},
	isbn		= {978-1-4503-5548-3},
	keywords	= {},
	abstract	= {In a co-located collaborative virtual environment, multiple users share the same physical tracked space and the same virtual workspace. When the virtual workspace is larger than the real workspace, navigation interaction techniques must be deployed to let the users explore the entire virtual environment. When a user navigates in the virtual space while remaining static in the real space, his/her position in the physical workspace and in the virtual workspace are no longer the same. Thus, in the context where each user is immersed in the virtual environment with a Head-Mounted-Display, a user can still perceive where his/her collaborators are in the virtual environment but not where they are in real world. In this paper, we propose and compare three methods to warn users about the position of collaborators in the shared physical workspace to ensure a proper cohabitation and safety of the collaborators. The frst one is based on a virtual grid shaped as a cylinder, the second one is based on a ghost representation of the user and the last one displays the physical safe-navigation space on the foor of the virtual environment. We conducted a user-study with two users wearing a Head-Mounted-Display in the context of a collaborative First-Person-Shooter game. Our three methods were compared with a condition where the physical tracked space was separated into two zones, one per user, to evaluate the impact of each condition on safety, displacement freedom and global satisfaction of users. Results suggest that the ghost avatar and the cylinder grid can be good alternatives to the separation of the tracked space.}
}

@inproceedings{lee2015ftm,
	author		= {Charlotte P. Lee and Drew Paine},
	title		= {{From The Matrix to a {Model of Coordinated Action} ({MoCA}): A Conceptual Framework of and for {CSCW}}},
	series 		= {},
	booktitle	= {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work \& Social Computing (CSCW 2015)},
	editor		= {},
	volume		= {},
	pages		= {179--194},
	address		= {Vancouver, British Columbia, Canada},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {2015},
	month		= "14--18~" # mar,
	language	= {english},
	url			= {https://doi.org/10.1145/2675133.2675161},
	doi 		= {10.1145/2675133.2675161},
	isbn		= {978-1-4503-2922-4},
	keywords	= {conceptual frameworks, cscw, theory},
	abstract	= {The CSCW community is reliant upon technology-centric models of groupware and collaboration that frame how we examine and design for cooperative work. This paper both reviews the CSCW literature to examine existing models of collaborative work and proposes a new, expanded conceptual model: the Model of Coordinated Action (MoCA). MoCA is a broader framework for describing complex collaborative situations and environments including, but not limited to, collaborations that have diverse, high-turnover memberships or emerging practices. We introduce MoCA's seven dimensions of coordinative action and illustrate their connection to past and current CSCW research. Finally, we discuss some ramifications of MoCA for our understanding of CSCW as a sociotechnical design space.}
}

@book{nent2016gfr,
	title		= {{Guidelines For Research Ethics in Science and Technology}},
	series		= {},
	author 		= {{Norwegian National Committee For Research Ethics in Science and Technology}},
	editor 		= {},
	edition 	= {2nd},
	publisher	= {The Norwegian National Research Ethics Committees},
	year		= {2016},
	month		= "" # jun,
	language	= {english},
	url			= {https://www.forskningsetikk.no/en/guidelines/science-and-technology/guidelines-for-research-ethics-in-science-and-technology/},
	doi 		= {},
	isbn		= {9788276820751},
	keywords	= {},
	abstract	= {These guidelines for research ethics were prepared by the National Committee for Research Ethics in Science and Technology (NENT) in 2007 and revised in 2015. The guidelines supplement existing international guidelines on research ethics.[1] In interdisciplinary projects that include, for example, human medicine or social sciences, the research ethics guidelines applying to these disciplines must also be observed.

	Research institutions are responsible for ensuring that the guidelines are implemented and observed in their research communities and that they are routinely communicated to staff and students. The institutions should also establish procedures for preventing and dealing with scientific misconduct. They should moreover have mechanisms for addressing and resolving potential conflicts and cases of doubt relating to research ethics.}
}

@article{neumayr2018ddf,
	author		= {Thomas Neumayr and Hans-Christian Jetter and Mirjam Augstein and Judith Friedl and Thomas Luger},
	title		= {{{Domino}: A Descriptive Framework for Hybrid Collaboration and Coupling Styles in Partially Distributed Teams}},
	journal		= {Proceedings of the ACM on Human-Computer Interaction},
	pages		= {128:1--24},
	volume		= {2},
	number		= {CSCW},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {2018},
	month		= "" # nov,
	language	= {english},
	url			= {https://doi.org/10.1145/3274397},
	doi 		= {10.1145/3274397},
	keywords	= {Hybrid Collaboration, Descriptive Framework, Partially Distributed Teams},
	abstract	= {We present Domino, a descriptive framework for hybrid collaboration and hybrid coupling styles in partially distributed teams. Domino enables researchers to describe, analyze, and understand real-world hybrid collaboration practices, i.e., collaborative practices that involve simultaneous co-located and remote collaboration with phases of both synchronous and asynchronous work that spans multiple groupware applications and devices. It also helps to categorize collaborative activities based on yet undocumented hybrid coupling styles between the members of multiple partially distributed or co-located subgroups. Our Domino framework was derived from initial observations of real-world practice and refined by the detailed analysis of participants' behavior and working styles during a simulation of a complex hybrid collaboration task with six partially distributed teams of four users in our lab. The resulting framework allows researchers to view collaboration through a new analytical lens, use new analytical tools, and also derive implications for the design of collaborative tools.}
}

@inproceedings{peter2018vrg,
	author		= {Mark Peter and Robin Horst and Ralf Dörner},
	title		= {{{VR-Guide}: A Specific User Role for Aysmmetric {Virtual Reality} Setups in Distributed {Virtual Reality} Applications}},
	booktitle	= {Tagungsband 15. Workshop der GI-Fachgruppe VR/AR},
	series 		= {},
	editor 		= {},
	pages		= {83--94},
	address		= {Düsseldorf, Germany},
	publisher	= {Gesellschaft für Informatik (GI)},
	year		= {2018},
	language	= {english},
	isbn		= {},
	keywords	= {Virtual Reality, Asymmetric Virtual Reality Setups, User Roles, Attention Guidance, Distributed Virtual Reality Applications, Interaction Design},
	abstract	= {This paper focuses on multi-user virtual environments for collaborative tasks, that offer not all participants the same level of immersion and control over the virtual environment (VE). We propose a definition for a certain role within such an asymmetric setup – a ’VR-Guide’. In this paper, we present a dedicated tool to support VR-Guides and identify a rich set of features that can be categorized in view-related features, features related to the manipulation of virtual reality (VR) objects, features related to the meta-part of the VE, and features related to the monitoring of users. Moreover, we address how VR-Guides can guide the VR-user’s attention. We evaluated the tool within a user study and discuss the experiences of the users with a prototype of the proposed support-tool for VR-Guides.}
}

@inproceedings{reski2020eot,
	author		= {Nico Reski and Aris Alissandrakis and Andreas Kerren},
	title		= {{Exploration of Time-Oriented Data in Immersive {Virtual Reality} Using a {3D Radar Chart} Approach}},
	booktitle	= {Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society (NordiCHI 2020)},
	pages		= {33:1--11},
	address		= {Tallinn, Estonia},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {2020},
	month		= "25--29~" # oct,
	language	= {english},
	url			= {https://doi.org/10.1145/3419249.3420171},
	doi 		= {10.1145/3419249.3420171},
	diva 		= {http://urn.kb.se/resolve?urn=urn:nbn:se:lnu:diva-98671},
	isbn		= {9781450375795},
	keywords	= {immersive analytics, radar chart, time-oriented data, virtual reality, 3D gestural input},
	abstract	= {In this paper, we present an approach to interact with time-oriented data in Virtual Reality within the context of Immersive Analytics. We implemented a Virtual Reality application that enables its user to explore data in an immersive environment (head-mounted display, 3D gestural input), utilizing potential advantages of immersive technologies, for instance, depth cues for better spatial understanding, natural interaction, and user engagement. The visualization design is inspired by the overall concept of a radar chart, and using the third dimension to represent time-series related data. We conducted a user study with 15 participants, encouraging them to examine a representative dataset within an explorative analysis scenario with no time constraints. Based on the results of usability and user engagement scores, task completion analysis, observations, and interviews, we were able to empirically validate the approach in general, and gain insights in the users’ interaction and data analysis strategies.}
}

@article{reski2022aee,
	author		= {Nico Reski and Aris Alissandrakis and Andreas Kerren},
	title		= {{An Empirical Evaluation of Asymmetric Synchronous Collaboration Combining Immersive and Non-Immersive Interfaces Within the Context of {Immersive Analytics}}},
	journal		= {Frontiers in Virtual Reality},
	pages		= {743445:1--29},
	volume		= {2},
	number		= {},
	publisher	= {{Frontiers Media S.A.}},
	month		= "17~" # jan,
	year		= {2022},
	language	= {english},
	url			= {https://doi.org/10.3389/frvir.2021.743445},
	doi 		= {10.3389/frvir.2021.743445},
	diva 		= {http://urn.kb.se/resolve?urn=urn:nbn:se:lnu:diva-109309},
	issn		= {2673-4192},
	keywords	= {asymmetric user roles, computer-supported cooperative work, heterogeneous display and interaction technologies, immersive analytics, empirical evaluation, spatio-temporal data exploration, synchronous remote collaboration, virtual reality},
	abstract	= {Collaboration is an essential part of data analysis, allowing multiple users to combine their expertise and to debate about the interpretation of data discoveries using their contextual knowledge. The design of collaborative interfaces within the context of Immersive Analytics remains challenging, particularly due to the various user-centered characteristics of immersive technologies. In this article, we present the use case of a system that enables multiple users to synchronously explore the same data in a collaborative scenario that combines immersive and non-immersive interfaces in an asymmetric role setup. Such a setup allows for bridging the gap when applying heterogeneous display and interaction technologies, enabling each analyst to have an independent and different view of the data, while maintaining important collaborative aspects during the joint data exploration. We developed an immersive VR environment (head- mounted display, 3D gestural input) and a non-immersive desktop terminal (monitor, keyboard and mouse) centered around spatio-temporal data exploration. Supported through a real-time communication interface, synchronous collaborative features are integrated in both interfaces, facilitating the users in their ability to establish a shared context and to make spatio-temporal references. We conducted an empirical evaluation with five participant pairs (within-subject design) to investigate aspects of usability, user engagement, and collaboration during a confirmative analysis task. Synthesis of questionnaire results in combination with additional log file analysis, audio activity analysis, and observations, revealed good usability scores, high user engagement, as well as overall close and balanced collaboration of enthusiastic pairs during the task completion independent of their interface type, validating our system approach in general. Further supported through the self-constructed Spatio-Temporal Collaboration Questionnaire, we are able to contribute with discussion and considerations of the presented scenario and the synchronous collaborative features for the design of similar applications.}
}

@article{schmidt2002tpw,
	author		= {Kjeld Schmidt},
	title		= {{{The Problem with ``Awareness''}: Introductory Remarks on ``{Awareness in CSCW}''}},
	journal		= {Computer Supported Cooperative Work (CSCW)},
	pages		= {285--298},
	volume		= {11},
	number		= {},
	publisher	= {Springer Nature},
	year		= {2002},
	month		= "" # sep,
	language	= {english},
	url			= {https://doi.org/10.1023/A:1021272909573},
	doi 		= {10.1023/A:1021272909573},
	keywords	= {},
	abstract	= {}
}

@book{shneidermann2017dtu,
	title		= {{{Designing the User Interface}: Strategies for Effective {Human-Computer Interaction}}},
	series		= {Human-Computer Interaction Series (HCIS)},
	author 		= {Ben Shneiderman and Catherine Plaisant and Maxine Cohen and Steven Jacobs and Niklas Elmqvist and Nicholas Diakopoulos},
	editor 		= {},
	edition 	= {6th},
	publisher	= {Pearson},
	year		= {2017},
	month		= "20~" # jun,
	language	= {english},
	url			= {},
	doi 		= {},
	isbn		= {9781292153919},
	keywords	= {},
	abstract	= {The Sixth Edition of Designing the User Interface provides a comprehensive, authoritative, and up-to-date introduction to the dynamic field of human-computer interaction (HCI) and user experience (UX) design. This classic book has defined and charted the astonishing evolution of user interfaces for three decades. Students and professionals learn practical principles and guidelines needed to develop high quality interface designs that users can understand, predict, and control. The book covers theoretical foundations and design processes such as expert reviews and usability testing.

	By presenting current research and innovations in human-computer interaction, the authors strive to inspire students, guide designers, and provoke researchers to seek solutions that improve the experiences of novice and expert users, while achieving universal usability. The authors also provide balanced presentations on controversial topics such as augmented and virtual reality, voice and natural language interfaces, and information visualization.

	Updates include current HCI design methods, new design examples, and totally revamped coverage of social media, search and voice interaction. Major revisions were made to EVERY chapter, changing almost every figure (170 new color figures) and substantially updating the references.}
}

@article{sicat2019dxr,
	author		= {Ronell Sicat and Jiabao Li and JunYoung Choi and Maxime Cordeil and Won-Ki Jeong and Benjamin Bach and Hanspeter Pfister},
	title		= {{{DXR}: A Toolkit for Building Immersive Data Visualizations}},
	journal		= {IEEE Transactions on Visualization and Computer Graphics},
	pages		= {715--725},
	volume		= {25},
	number		= {1},
	publisher	= {Institute of Electrical and Electronics Engineers (IEEE)},
	year		= {2019},
	month		= "" # jan,
	language	= {english},
	url			= {https://doi.org/10.1109/TVCG.2018.2865152},
	doi 		= {10.1109/TVCG.2018.2865152},
	keywords	= {Augmented Reality, Virtual Reality, Immersive Visualization, Immersive Analytics, Visualization Toolkit},
	abstract	= {This paper presents DXR, a toolkit for building immersive data visualizations based on the Unity development platform. Over the past years, immersive data visualizations in augmented and virtual reality (AR, VR) have been emerging as a promising medium for data sense-making beyond the desktop. However, creating immersive visualizations remains challenging, and often require complex low-level programming and tedious manual encoding of data attributes to geometric and visual properties. These can hinder the iterative idea-to-prototype process, especially for developers without experience in 3D graphics, AR, and VR programming. With DXR, developers can efficiently specify visualization designs using a concise declarative visualization grammar inspired by Vega-Lite. DXR further provides a GUI for easy and quick edits and previews of visualization designs in-situ, i.e., while immersed in the virtual world. DXR also provides reusable templates and customizable graphical marks, enabling unique and engaging visualizations. We demonstrate the flexibility of DXR through several examples spanning a wide range of applications.}
}

@article{skarbez2019iat,
	author		= {Richard Skarbez and Nicholas F. Polys and J. Todd Oggle and Chris North and Doug A. Bowman},
	title		= {{{Immersive Analytics}: Theory and Research Agenda}},
	journal		= {Frontiers in Robotics and AI},
	pages		= {82:1--15},
	volume		= {6},
	number		= {},
	publisher	= {{Frontiers Media S.A.}},
	year		= {2019},
	month		= "10~" # sep,
	language	= {english},
	url			= {https://doi.org/10.3389/frobt.2019.00082},
	doi 		= {10.3389/frobt.2019.00082},
	keywords	= {immersive analytics, visual analytics, immersion, virtual reality, visualization, sensemaking, knowledge generation},
	abstract	= {Advances in a variety of computing fields, including “big data,” machine learning, visualization, and augmented/mixed/virtual reality, have combined to give rise to the emerging field of immersive analytics, which investigates how these new technologies support analysis and decision making. Thus far, we feel that immersive analytics research has been somewhat ad hoc, possibly owing to the fact that there is not yet an organizing framework for immersive analytics research. In this paper, we address this lack by proposing a definition for immersive analytics and identifying some general research areas and specific research questions that will be important for the development of this field. We also present three case studies that, while all being examples of what we would consider immersive analytics, present different challenges, and opportunities. These serve to demonstrate the breadth of immersive analytics and illustrate how the framework proposed in this paper applies to practical research.}
}

@incollection{snowdon2001cve,
	author 		= {Dave Snowdon and Elisabeth F. Churchill and Alan J. Munro},
	title 		= {{{Collaborative Virtual Environments}: Digital Spaces and Places for {CSCW}: An Introduction}},
	booktitle 	= {Collaborative Virtual Environments: Digital Places and Spaces for Interaction},
	series 		= {Computer Supported Cooperative Work (CSCW)},
	editor 		= {Elisabeth F. Churchill and David N. Snowdon and Alan J. Munro},
	pages		= {3--17},
	edition 	= {},
	publisher	= {Springer, London},
	year		= {2001},
	language	= {english},
	url			= {https://doi.org/10.1007/978-1-4471-0685-2_1},
	doi 		= {10.1007/978-1-4471-0685-2_1},
	isbn		= {978-1-4471-0685-2},
	keywords	= {Virtual Reality, Virtual Environment, Collaborative Work, Virtual Object, Collaborative Activity},
	abstract	= {In the late 1980s Virtual Reality (VR) burst onto the public stage propelled by a wave of media interest and related science fiction novels such as Neuromancer by William Gibson (Gibson, 1989). VR promised to revolutionize the way in which we experience and interact with computers, and research into the field mushroomed. More recently, the hype surrounding VR has died down and, although it is receiving less public attention, serious work is continuing with the aim of producing useful and usable technology. At the centre of current work related to VR is the field of Collaborative Virtual Environments (CVEs). This field has as its goal the provision of new, more effective means of using computers as tools for communication and information sharing with others. Many CVE systems have been constructed. Some of these are desktop systems and applications; but large public virtual spaces have also been constructed (such as Alpha World at http://www.activeworlds.com/; see Chapter 15). CVEs are also being used to experiment with new forms of art and interactive television (Benford et al., 1997a,b; Benford et al, 2000a).}
}

@inproceedings{stafford2006iog,
	author		= {Aaron Stafford and Wayne Piekarski and Bruce H. Thomas},
	title		= {{Implementation of God-like Interaction Techniques for Supporting Collaboration Between Outdoor {AR} and Indoor Tabletop Users}},
	booktitle	= {Proceedings of The Fifth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR 2006)},
	pages		= {165--172},
	address		= {Santa Barbara, California, USA},
	publisher	= {Institute of Electrical and Electronics Engineers (IEEE)},
	year		= {2006},
	month		= "22--25~" # oct,
	language	= {english},
	url			= {https://doi.org/10.1109/ISMAR.2006.297809},
	doi 		= {10.1109/ISMAR.2006.297809},
	isbn		= {1-4244-0650-1},
	issn		= {},
	keywords	= {Outdoor Augmented Reality, Video-Based Rendering, Table-Top Interfaces, Indoor-Outdoor Collaboration},
	abstract	= {This paper presents a new interaction metaphor we have termed "god-like interaction". This is a metaphor for improved communication of situational and navigational information between outdoor users, equipped with mobile augmented reality systems, and indoor users, equipped with tabletop projector display systems. Physical objects are captured by a series of cameras viewing a table surface indoors, the data is sent over a wireless network, and is then reconstructed at a real-world location for outdoor augmented reality users. Our novel god-like interaction metaphor allows users to communicate information using physical props as well as natural gestures. We have constructed a system that implements our god-like interaction metaphor as well as a series of novel applications to facilitate collaboration between indoor and outdoor users. We have extended a well-known video based rendering algorithm to make it suitable for use on outdoor wireless networks of limited bandwidth. This paper also describes the limitations and lessons learned during the design and construction of the hardware that supports this research.}
}

@incollection{steed2015cii,
	author 		= {Anthony Steed and Ralph Schroeder},
	title 		= {{Collaboration in Immersive and Non-immersive Virtual Environments}},
	booktitle 	= {Immersed in Media: Telepresence Theory, Measurement \& Technology},
	series 		= {},
	editor 		= {Matthew Lombard and Frank Biocca and Jonathan Freeman and Wijnand IJsselsteijn and Rachel J. Schaevitz},
	pages		= {263--282},
	edition 	= {1st},
	publisher	= {Springer, Cham},
	year		= {2015},
	month		= {},
	language	= {english},
	url			= {https://doi.org/10.1007/978-3-319-10190-3_11},
	doi 		= {10.1007/978-3-319-10190-3_11},
	isbn		= {978-3-319-10190-3},
	keywords	= {Synchronous collaboration, Collaborative Virtual Environments (CVE's), 3D Space Interaction, Social space, Immersive technologies, Co-presence},
	abstract	= {There is a huge variety of tools for synchronous collaboration including instant messaging, audio conferencing, videoconferencing and other shared spaces. One type of tool, collaborative virtual environments (CVEs), allows users to share a 3D space as if they are there together. Today, most experiences of virtual environments (VEs), including games and social spaces, are constrained by the form of non-immersive interfaces that they use. In this chapter we review findings about how people interact in immersive technologies, that is large-screen displays such as CAVE-like displays, and how they provide a number of advantages over non-immersive systems. We argue that modern immersive systems can already support effective co-presence in constrained situations and that we should focus on understanding of what is needed for effective and engaging collaboration in a broader range of applications. We frame this discussion by looking at the topics of co-presence, representations of users and modalities of interacting with the VE. Different types of immersive technologies offer quite distinct advantages, and we discuss the importance of these differences for the future of CVE development.}
}

@inproceedings{sugiura2018aac,
	author		= {Yuta Sugiura and Hikaru Ibayashi and Toby Chong and Daisuke Sakamoto and Natsuki Miyata and Mitsunori Tada and Takashi Okuma and Takeshi Kurata and Takashi Shinmura and Masaaki Mochimaru and Takeo Igarashi},
	title		= {{An Asymmetric Collaborative System for Architectural-scale Space Design}},
	booktitle	= {Proceedings of the 16th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry (VRCAI 2018)},
	pages		= {1--6},
	address		= {Tokyo, Japan},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {2018},
	month		= "" # dec,
	language	= {english},
	url			= {https://doi.org/10.1145/3284398.3284416},
	doi 		= {10.1145/3284398.3284416},
	isbn		= {978-1-4503-6087-6},
	keywords	= {},
	abstract	= {We present a system that facilitates asymmetric collaboration among users with two different viewpoints in the design of living or working spaces. One viewpoint is that of the space designers, who observe and alter the space from a top-down view using a large table-top interface. The other viewpoint is that of a space occupant, who observes the space through internal views using a head-mounted display. We conducted two studies to understand how our system support users in architectural-scale space design. One is about preliminary user study to observe general behavior to Dollhouse VR system, and the other one is a case study that users are actual employees of restaurant and discuss rearrangement of floor by moving tables and chairs in virtual environment. Results showed that the system supports a pair of interaction techniques that could facilitate communication between these two user viewpoints.}
}

@article{sun2019nsi,
	author		= {Yilu Sun and Omar Shaikh and Andrea {Stevenson Won}},
	title		= {{Nonverbal synchrony in virtual reality}},
	journal		= {PLoS ONE},
	pages		= {e0221803:1--28},
	volume		= {14},
	number		= {9},
	publisher	= {{PLOS ONE}},
	year		= {2019},
	month		= "16~" # sep,
	language	= {english},
	url			= {https://doi.org/10.1371/journal.pone.0221803},
	doi 		= {10.1371/journal.pone.0221803},
	keywords	= {},
	abstract	= {How might nonverbal synchrony naturally evolve in a social virtual reality environment? And how can avatar embodiment affect how participants coordinate nonverbally with each other? In the following pre-registered between-subjects experiment, we tracked the movements of pairs of users during a collaborative or competitive task in immersive virtual reality. Each conversational partner controlled either a customized avatar body or an abstract cube that responded to their movements. We compared the movements of the actual user pairs between the two conditions, and to an artificial “pseudosynchrony” dataset composed of the movements of randomly combined participant pairs who did not actually interact. We found stronger positive and negative correlations between real pairs compared to pseudosynchronous pairs, providing evidence for naturally occurring nonverbal synchrony between pairs in virtual reality. We discuss this in the context of the relationships between avatar appearance, task success, social closeness and social presence.}
}

@book{swedishresearchcouncil2017grp,
	title		= {{Good Research Practice}},
	series		= {},
	author 		= {{Swedish Research Council}},
	editor 		= {},
	edition 	= {2nd},
	publisher	= {Swedish Research Council, Vetenskapsrådet, Stockholm, Sweden},
	year		= {2017},
	month		= "12~" # jun,
	language	= {english},
	url			= {https://www.vr.se/english/analysis/reports/our-reports/2017-08-31-good-research-practice.html},
	doi 		= {},
	isbn		= {9789173073547},
	keywords	= {},
	abstract	= {This is a partially revised version of Good Research Practice, published in 2011. The revision covers areas such as changes in legislation.

	Research ethics is not static, neither as a discipline nor as a practice. When the scientific landscape changes, sometimes the debate about research ethics shifts as well. New principles may be added, and old ones may need to be reinterpreted or applied differently.

	Ethical considerations in research are largely a matter of finding a reasonable balance between various interests that are all legitimate. The quest for knowledge is one such interest. Individual privacy interests as well as protection against various forms of harm or risk of harm are other legitimate interests. Issues like the handling of integrity-sensitive material raise questions about the interests of the researcher, the study participants and other researchers, but also about what a researcher is able to promise participants and who owns research material.

	This book addresses relevant legislation and ethical requirements and recommendations against the background of questions that may arise in research work. The aim is to provide an orientation among the issues and problems, stimulate thought and contribute to the debate on responsibility and challenges. The book primarily addresses researchers, not least the younger generation, to help them make well-reasoned research ethical decisions.}
}

@inproceedings{tang2006cco,
	author		= {Anthony Tang and Melanie Tory and Barry Po and Petra Neumann and Sheelagh Carpendale},
	title		= {{Collaborative Coupling over Tabletop Displays}},
	booktitle	= {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2006)},
	pages		= {1181--1190},
	address		= {Montreal, Quebec, Canada},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {2006},
	month		= "22--27~" # apr,
	language	= {english},
	url			= {https://doi.org/10.1145/1124772.1124950},
	doi 		= {10.1145/1124772.1124950},
	isbn		= {1-59593-372-7},
	keywords	= {collaborative coupling, collaborative tabletop displays, coordination, mixed focus collaboration, single display groupware},
	abstract	= {Designing collaborative interfaces for tabletops remains difficult because we do not fully understand how groups coordinate their actions when working collaboratively over tables. We present two observational studies of pairs completing independent and shared tasks that investigate collaborative coupling, or the manner in which collaborators are involved and occupied with each other's work. Our results indicate that individuals frequently and fluidly engage and disengage with group activity through several distinct, recognizable states with unique characteristics. We describe these states and explore the consequences of these states for tabletop interface design.}
}

@inproceedings{wang2019avo,
	author		= {Xiyao Wang and Lonni Besançon and Florimond Gueéniat and Mickael Sereno and Mehdi Ammi and Tobias Isenberg},
	title		= {{A Vision of Bringing Immersive Visualization to Scientific Workflows}},
	booktitle	= {Proceedings of the 2019 ACM Conference on Human Factors in Computing Systems (CHI) - Workshop on Interaction Design \& Prototyping for Immersive Analytics},
	pages		= {8},
	address		= {Glasgow, Scotland, UK},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {2019},
	month		= "4--9~" # may,
	language	= {english},
	url			= {https://hal.archives-ouvertes.fr/hal-02053969},
	doi 		= {},
	isbn		= {},
	keywords	= {Immersive Analytics, Visualization, Interaction, Applications},
	abstract	= {The process of data exploration is becoming an essential part of today's scientific workflows. A large number of immersive visualization environments are being explored to help researchers and experts to better understand the data and to offer intuitive interaction. Despite these benefits, shown by prior research, it is still uncommon to find them being applied to realistic scientific workflows. We argue that immersive visualization techniques will not be adopted until they can be easily integrated in the workflow of domain experts, and that specific efforts should be made to help the integration of novel and immersive visualization techniques with classically used software.}
}

@inproceedings{welsford2020aib,
	author		= {Finn Welsford-Ackroyd and Andrew Chalmers and Rafael K. dos Anjos and Daniel Medeiros and Hyejin Kim and Taehyun Rhee},
	title		= {{Asymmetric Interaction between {HMD} Wearers and Spectators with a Large Display}},
	booktitle	= {Poster session at The 2020 IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR 2020)},
	pages		= {2},
	address		= {Atlanta, Georgia, USA},
	publisher	= {Institute of Electrical and Electronics Engineers (IEEE)},
	year		= {2020},
	month		= "22--26~" # mar,
	language	= {english},
	url			= {https://doi.org/10.13140/RG.2.2.34994.56006},
	doi			= {10.13140/RG.2.2.34994.56006}, 
	isbn		= {},
	abstract	= {HMDs provide an immersive VR experience, but make it difficult to communicate the experience with spectators not wearing HMDs. We propose a spectator-oriented approach for collaborative tasks and demonstrations. We render the virtual world in a large-scale tiled video wall, where the spectator can freely explore the environment independent from the HMD wearer. To improve collaboration, we implemented a pointer system where spectator is able to point at objects on the screen which maps directly onto the objects in the virtual world. This interaction enables spectators to effectively communicate and feel semi-immersed without the need to wear a HMD.}
}

@article{wu2021uaf,
	author		= {Yuanjie Wu and Yu Wang and Sungchul Jung and Simon Hoermann and Robert W. Lindeman},
	title		= {{Using a Fully Expressive Avatar to Collaborate in {Virtual Reality}: Evaluation of Task Performance, Presence, and Attraction}},
	journal		= {Frontiers in Virtual Reality},
	pages		= {641296:1--15},
	volume		= {2},
	number		= {},
	publisher	= {{Frontiers Media S.A.}},
	year		= {2021},
	month		= "7~" # apr,
	language	= {english},
	url			= {https://doi.org/10.3389/frvir.2021.641296},
	doi 		= {10.3389/frvir.2021.641296},
	keywords	= {avatar, virtual reality, shared virtual environment, communication, collaboration},
	abstract	= {Avatar-mediated collaboration in virtual environments is becoming more and more prevalent. However, current consumer systems are not suited to fully replicate real-world nonverbal communication. We present a novel avatar system for collaboration in virtual reality, which supports high levels of nonverbal expression by tracking behavior such as body movement, hand gesture, and facial expression. The system was built using camera tracking technology only. Therefore, in contrast to many other high-level tracking systems, it does not require users to wear additional trackers on their bodies. We compared our highly expressive system with a consumer setup extended with two body-worn trackers in a dyadic study. We investigated users’ performance, such as completion time and accuracy, as well as the presence and interpersonal attraction in a virtual charades game using an asymmetric control scheme. The results show that participants interacting with highly expressive avatars felt more social presence and attraction and exhibited better task performance than those interacting with partners represented using low-expressive avatars. Hence, we conclude that virtual reality avatar systems benefit from a higher level of nonverbal expressiveness, which can be achieved without additional body-worn trackers.}
}

@inproceedings{xi2018sef,
	author		= {Haijun Xia and Sebastian Herscher and Ken Perlin and Daniel Wigdor},
	title		= {{{Spacetime}: Enabling Fluid Individual and Collaborative Editing in {Virtual Reality}}},
	booktitle	= {Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology (UIST 2018)},
	pages		= {853--866},
	address		= {Berlin, Germany},
	publisher	= {Association for Computing Machinery (ACM)},
	year		= {2018},
	month		= "14--17~" # oct,
	language	= {english},
	url			= {https://doi.org/10.1145/3242587.3242597},
	doi 		= {10.1145/3242587.3242597},
	isbn		= {978-1-4503-5948-1},
	keywords	= {},
	abstract	= {Virtual Reality enables users to explore content whose physics are only limited by our creativity. Such limitless environments provide us with many opportunities to explore innovative ways to support productivity and collaboration. We present Spacetime, a scene editing tool built from the ground up to explore the novel interaction techniques that empower single user interaction while maintaining fluid multi-user collaboration in immersive virtual environment. We achieve this by introducing three novel interaction concepts: the Container, a new interaction primitive that supports a rich set of object manipulation and environmental navigation techniques, Parallel Objects, which enables parallel manipulation of objects to resolve interaction conflicts and support design workflows, and Avatar Objects, which supports interaction among multiple users while maintaining an individual users' agency. Evaluated by professional Virtual Reality designers, Spacetime supports powerful individual and fluid collaborative workflows.}
}
