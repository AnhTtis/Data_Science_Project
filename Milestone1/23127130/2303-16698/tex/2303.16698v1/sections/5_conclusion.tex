\section{Conclusion}
In this paper, we introduced a new method for inverse optimal control for systems with stochastic dynamics, partial observability, and missing control signals. We followed a probabilistic formulation of the problem, where the goal is formulated as maximizing the likelihood of the observed states given the parameters. As the exact evaluation of the likelihood for a general non-linear model is intractable, we developed an efficient approximation of the likelihood by linearizing the system locally around the given trajectories, as in popular approaches such as the extended Kalman filter or iLQG. By maintaining a Gaussian distribution that tracks the agent's state estimate, the proposed method is able to evaluate an approximate likelihood in closed form within a single forward pass.

Besides offering an efficient way to evaluate the likelihood, our proposed formulation is able to incorporate multiple sources of the stochasticity of the agent through an explicit model of the partial observability and by modelling control via a maximum causal entropy (MCE) policy. Our method thereby reconciles the theory of past MCE IOC algorithms \citep[e.g.,][]{ziebart2010modeling} and approaches where the agent's stochasticity stems from an explicit stochastic observation model \citep{schultheis2021inverse}.

We have applied our method to two stochastic variations of classical control tasks, the pendulum and cart pole, and to two human behavioral tasks, a reaching and navigation tasks. In the comparison to a MCE baseline, for which missing control signals need to be estimated, we have found our method to achieve lower estimation errors across all evaluated tasks. Further, it successfully inferred noise parameters of the system, which was not possible with the baseline. 

The limitations of our method are mainly due to the linearization of the dynamical system and the Gaussian approximations involved in the belief tracking formulation of the likelihood function. In more complex scenarios with belief distributions that are not well approximated by a Gaussian, e.g., multimodal beliefs, the method is likely to produce inaccurate results. This problem could be addressed by replacing the closed-form Gaussian approximation of the belief by particle-based methods \citep{doucet2001sequential}.
Further, we focused on tasks which could be solved well by applying controllers based on linearization and Gaussian approximation (iLQG and EKF), motivated by their popularity in applications in cognitive science and neuroscience.
High-dimensional problems that cannot be solved forward using iLQG, in contrast, are probably not directly solvable using our proposed method. While, in principle, our method is also applicable using other forward control methods that compute differentiable policies, it is unclear whether linearizing these policies leads to accurate approximate likelihoods and parameter estimates. 

A further limitation of our method is that it requires parametric models of the dynamics and noise structure. While single missing parameters can be determined using our method, in the case of completely unknown dynamics a model-free approach to IOC would be more suitable.

Lastly, while we have shown that inference of few parameters is feasible, the results probably do not scale to 
a large number of parameters.
One reason for this is that optimization in a high-dimensional non-linear space becomes difficult, and one can potentially get stuck in local minima. This problem could be relieved by using more advanced optimization methods.
A further, more fundamental, concern with a large number of parameters is that parameters are likely to become not unambiguously identifiable and there is no unique solution. 
However, in many scientific fields, knowledge about the structure and parametric models describing the agent's uncertainty and internal model are available or measurable, allowing our method to be used successfully. Moreover,
our probabilistic approach with a closed-form likelihood opens up the possibility of using Bayesian methods to investigate the identifiability of model parameters \citep{acerbi2014framework}. 

Our proposed method provides a tool for researchers interested in modeling sequential behavior, e.g., in sensorimotor domains, allowing to infer an agent's subjective costs and internal uncertainties. This will enable answering novel scientific questions about how these quantities are affected by different experimental conditions, deviate from intended task goals and provided task instructions, or how they vary between individuals. This is particularly relevant to a computational understanding of naturalistic behavior \citep{krakauer2017neuroscience,cisek2014challenges,miller2022natural}, for which subjective utilities are mostly unknown.
