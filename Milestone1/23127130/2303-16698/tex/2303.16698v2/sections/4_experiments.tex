\section{Experiments}
\label{sec:experiments}

We evaluated our method on two classic control tasks, i.e., Pendulum and Cart Pole, and two human behavioral tasks, manual reaching and navigation.
To evaluate the accuracy of the parameter estimates obtained by our method and to compare it against a baseline, we computed absolute relative errors per parameter, i.e., $\lvert (\theta - \hat{\theta}) / \theta \rvert$. This metric makes averages across parameters on different scales more interpretable compared to other metrics such as root mean squared errors.
For each task, we simulated 100 sets of parameters from a uniform distribution in logarithmic space. For each set of parameters, we simulated 50 trajectories.
We then maximized the log likelihood using gradient-based optimization with automatic differentiation \citep[L-BFGS algorithm;][]{zhu1997algorithm}.
See \cref{app:hyperparams} for a summary of the hyperparameters of our experiments.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/Fig-2.pdf}
    \vspace{-0.25cm}
    \caption{\textbf{IOC for non-linear reaching.} \textbf{A} Simulated trajectories for eight targets. Increasing the control cost and the motor noise affects the trajectories, since reaching the target becomes less important and variability increases. \textbf{B} IOC log likelihood for control cost $c_a$ and motor noise $\sigma_m$. The maximum likelihood estimate (pink cross) is close to the ground truth parameters (black dot). \mbox{\textbf{C} Simulated} trajectories using the MLEs from B. The simulations are visually indistinguishable from the ground truth data. \textbf{D} True parameters plotted against maximum likelihood estimates. Top row: our method, bottom row: MCE baseline. The columns contain the four different model parameters (control cost $c_a$, velocity cost $c_v$, motor noise $\sigma_m$, observation noise $\sigma_o$).}
    \label{fig:reaching-likelihood}
\end{figure}

All tasks we consider have four free parameters: control cost $c_a$, cost of final velocity $c_v$, motor noise $\sigma_m$, and observation noise $\sigma_o$ of the agent.
In the fully observable case, we leave out the observation noise parameter and only infer the three remaining parameters.
For concrete definitions of the parameters in each specific task, see \cref{app:tasks}.

\subsection{Baseline method}
For a comparison to previously proposed methods, we applied a baseline method based on the maximum causal entropy (MCE) approach \citep{ziebart2010modeling}. 
As for this approach, control signals of the observed trajectories are required, we use the estimates of the controls that we determine in our proposed method for the data-based linearization (\cref{sec:fixed_linearization}). 
Note that the baseline, representative for applicable past IOC methods, does not have an explicit model of partial observability.
Further note that past methods based on MCE are limited to estimating cost functions, so that parameters such as the agentâ€™s noise cannot be inferred. For the specific MCE linearization-based baseline we consider, it is actually straightforward to maximize the likelihood with respect to the noise parameters, which enables us to evaluate noise estimates. 
To show that this approach constitutes a suitable baseline, in \cref{app:results_controls}, we provide results for the case where the true control signals are known and there is no partial observability. More details of the baseline are provided in \cref{app:baseline}.

\subsection{Evaluation on manual reaching task}\label{sec:reaching}
We evaluate the method on a reaching task with a non-linear two-joint biomechanical arm model, which has been applied to reaching movements in the sensorimotor neuroscience literature \citep[e.g.,][]{nagengast2009optimal, knill2011flexible}. The agent's goal is to move its arm towards a target at position $\mathbf e^\star$ by controlling the torque to the two joints. This objective is expressed as a non-quadratic cost function of the joint angles,
\begin{align}
    J = \norm{\mathbf e_T - \mathbf e^*}^2 + c_v \norm{\dot{\mathbf e}_T}^2 + c_a \sum_{t=1}^{T-1} \norm{\mathbf u_t}^2,
\end{align}
since the final position and velocity of the hand $\mathbf e_T, \dot{\mathbf e}_T$ are non-linear functions of the joint angles. See \cref{app:reaching} for details.

We use a fully observable \citep{todorov2005generalized} and a partially observable version of the task \citep{li2007iterative}. 
\cref{fig:reaching-likelihood}~A shows simulations from the model with two different parameter settings. Evaluating the likelihood function for a grid of two of the parameters (\cref{fig:reaching-likelihood}~B) confirms that it has its maxima close to the true parameter values. Simulated data using the maximum likelihood estimates look indistinguishable from the ground truth data (\cref{fig:reaching-likelihood}~C).

In \cref{fig:reaching-likelihood}~D, we show maximum likelihood estimates and true values for repeated runs with different random parameter settings. The parameter estimates of our method closely align with the true parameter values, showing that we can successfully recover the parameters from data. The baseline method, in contrast, shows considerably worse performance, in particular for estimating noises due to the lacking explicit representation of partial observability.
Importantly, even when the true control signals are provided, the noise parameter estimates of the baseline are not well estimated (\cref{app:results_controls}).
Estimates for the fully observable case are provided in \cref{app:results_fullobs}.
The median absolute relative errors of our method were 0.11, while they were 0.93 for the baseline.
The influence of missing control signals and of the lack of an explicit observation model in the baseline can be observed by comparing the results to the fully observable case and the case of given control signals in \cref{app:results_fullobs} and \cref{app:results_controls}.

\subsection{Quantitative evaluation on other tasks}\label{sec:other-tasks}
To show that our method works for a range of different tasks, we evaluated it on the three other tasks (navigation, pendulum and cart pole).
In the navigation task, we consider an agent navigating to a target under non-linear dynamics while receiving noisy observations from a non-linear observation model. To reach the target, the agent can control the angular velocity of their heading direction and the acceleration with which they move forward. The agent observes noisy versions of the distance to the target and the target's bearing angle. We provide more details about the experiment in \cref{app:navigation}.
Maximum likelihood parameter estimates for the navigation task are shown for the partially observable case in \cref{fig:estimates_po_navigation} and for the fully observable case in \cref{fig:estimates_navigation}. As for the reaching task, our method provides parameter estimates close to the true ones, while the estimates of the baseline deviate for many trials. Median absolute relative errors of our method were 0.31, while they were 1.99 for the baseline (\cref{fig:results-aggregate}).

The two classic control tasks (Pendulum and Cart Pole) are based on the implementations in the \texttt{gym} library \citep{brockman2016openai}. Because these tasks are neither stochastic nor partially observable in their standard formulations, we introduce noise on the dynamics and turn them into partially observable problems by defining a stochastic observation function (see \cref{app:classic-control}).
In \cref{app:add_results}, we show the parameter estimates for the Pendulum (\cref{fig:estimates_po_pendulum}) and for the Cart Pole (\cref{fig:estimates_po_cartpole}) for the partially observable case, while \cref{fig:estimates_pendulum} and \cref{fig:estimates_cartpole} show the fully observable case, respectively. One can observe that the results are qualitatively similar to the ones in the reaching and navigation tasks, showing that our method provides accurate estimates of the parameters. Median absolute relative errors of our method were 0.12 and 0.41, while for the baseline they were 2.21 and 3.82 (\cref{fig:results-aggregate}).

\begin{figure}
    \centering
    \includegraphics[width=.95\linewidth]{figures/Fig-3.pdf}
    \caption{\textbf{Evaluation across tasks. } Absolute relative errors (log scale) for different tasks. Our method consistently outperforms the MCE baseline.}
    \label{fig:results-aggregate}
\end{figure}


\subsection{Information-seeking behavior in the light-dark domain}\label{sec:lightdark}

Finally, we investigate the ability of our method to disentangle sources of information-seeking behavior. In the light-dark domain \citep{platt2010belief}, an agent moves in a 2D space and receives noisy measurements of its position, whose standard deviation depends on the horizontal distance from a light source:
\begin{align}
    \obs_t = \state_t + \sigma \lvert x_{t,1} - 5\rvert \; \obsnoise_t,
\end{align}
where $\sigma$ governs the amount of perceptual uncertainty. This task is a common test for information-seeking behavior, because it requires the agent to move towards the light source and at the same time away from the target to reduce the uncertainty about its position relative to the target. When this uncertainty has been reduced, the agent can approach the target (see \cref{app:lightdark} for details).
The agent's goal is to reach the target's position $\mathbf{p}$ at the final time step, while minimizing control effort $\action_t^2$:
\begin{align}
    J = \underbrace{(\state_T - \mathbf{p})^2}_\text{final cost} + \underbrace{\textstyle\sum_{t=1}^{T-1} \frac{1}{2}\action_t^2 + c \, (x_{t,1} - 5)^2}_\text{running cost}.
\end{align}

\begin{wrapfigure}{r}{0.55\textwidth}
    \vspace{-0.5cm}
    \centering
    \includegraphics[width=\linewidth]{figures/Fig-4.pdf}
    \vspace{-0.5cm}
    \caption{\textbf{Light-dark domain.} Cost maps and perceptual uncertainty map plotted with true parameters (\textbf{A}) and inferred parameters using our method (\textbf{B}) and baseline (\textbf{C}). Mean trajectories with start point (circle) and target (cross) are shown in orange.} 
    \label{fig:lightdark}
    \vspace{-0.4cm}
\end{wrapfigure}

Different from the original problem formulation, we consider the case in which the agent may have an additional inherent desire to be close to the light, parameterized by $c$. 
We recover the original cost function \citep{platt2010belief} for $c=0$, but we can represent agents that seek light more than necessary to reduce uncertainty for reaching the goal state with $c>0$. %, or agents that are not reducing uncertainty enough for reaching the target with $c<0$.
Accordingly, both the reduction of perceptual uncertainty and state-dependent running cost could encourage the agent to move towards the light source before approaching the target. For an external observer, e.g., an experimenter, observing an agent moving towards the light might not reveal the different potential sources for this behavior. We now ask if it is possible to disentangle these two factors using our proposed IOC algorithm.

We simulated 100 trajectories of an iLQG agent \citep[partially observable version,][]{li2007iterative} with no inherent desire to be near the light source ($c=0$) and some perceptual uncertainty ($\sigma = 0.2$) depending on the distance to the light source. The agent first moves towards the light source and then reaches the target (\cref{fig:lightdark}~A). We inferred the parameters $\sigma$, $\mathbf{p}$, and $c$ using our method and the baseline. Both methods recover the target position. Our method in addition infers values close to the true $c$, and $\sigma$. It therefore correctly attributes the information-seeking behavior of the agent to the perceptual uncertainty (\cref{fig:lightdark}~B). The baseline method, however, does not infer the correct perceptual uncertainty. It instead attributes the agent's information-seeking behavior to an inherent desire to be in the right part of the room in the running cost (\cref{fig:lightdark}~C). This highlights the importance for IOC in partially observable domains to probabilistically take the agent's belief into account, if one is interested in inferring the correct cognitive mechanisms. For a quantitative evaluation of the maximum likelihood estimates in the light-dark domain, see \cref{app:lightdark-results}.
