\section{Conclusion}
In this paper, we introduced a new IOC method for partially observable systems with stochastic non-linear dynamics and missing control signals. Using a probabilistic approach, we formulate the IOC problem as maximizing the likelihood of the observed states given the parameters. As the exact evaluation of the likelihood for a general non-linear model is intractable, we developed an efficient approximate likelihood by linearizing the system locally around the given trajectories, as in popular approaches such as the EKF or iLQG. By maintaining a distribution that tracks the agent's belief, an approximate likelihood can be evaluated in closed form within a single forward pass and efficiently optimized.
Our proposed formulation is able to incorporate multiple sources of the stochasticity of the agent, reconciling the theory of past MCE IOC algorithms \citep[e.g.,][]{ziebart2010modeling} and approaches where the agent's stochasticity stems from an explicit stochastic observation and control model \citep{schultheis2021inverse}.

We evaluated our method on two stochastic variants of classic control tasks, pendulum and cart pole, and on two human behavioral tasks, a reaching and a navigation task. 
In comparison to an MCE baseline, we have found our method to achieve lower estimation errors across all tasks. Further, it successfully inferred noise parameters of the system, which was not possible with the baseline.
In the light-dark domain, we were able to infer costs and perceptual uncertainty parameters, two different causes of apparent information-seeking behavior that could lead to qualitatively similar trajectories. This means that our method is a first step towards distinguishing pragmatic from epistemic controls. 
To further investigate this, it would be fruitful to examine belief-space planning methods that explicitly include the agent's belief covariance in the policy \citep{van2012motion}.

The limitations of our method are mainly due to the linearization of the dynamical system and the Gaussian approximations involved in the belief tracking formulation of the likelihood function. In more complex scenarios with non-Gaussian belief distributions, e.g., multimodal beliefs, the method will likely produce inaccurate results. This problem could be addressed by replacing the closed-form Gaussian belief by particle-based methods \citep{doucet2001sequential}.
Further, we focused on tasks which could be solved well by control methods based on linearization and Gaussian approximation (iLQG and EKF), motivated by their popularity in applications in cognitive science and neuroscience. Forward problems that cannot be solved using iLQG are probably not directly solvable using our inverse method. While, in principle, our method is also applicable to other forward control methods that compute differentiable policies, it is an empirical question whether linearizing these policies leads to accurate approximate likelihoods and parameter estimates.
A further limitation of our method is that it requires parametric models of the dynamics and noise structure. While missing parameters can be determined using our method, in the case of completely unknown dynamics a model-free approach to IOC would be more suitable.
Lastly, while we have shown that inference is feasible, the results probably do not scale to high-dimensional parameter spaces. One reason for this is that optimization in a high-dimensional non-linear space can potentially get stuck in local minima. This problem could be relieved by using more advanced optimization methods.
A further, more fundamental, concern with higher-dimensional parameter spaces is that identifiability issues and ambiguous solutions arise.
However, our probabilistic approach with a closed-form likelihood opens up the possibility of using Bayesian methods to investigate the identifiability of model parameters \citep{acerbi2014framework}. 
For future work exploring the relationship to methods for learning world models in POMDPs might also be a fruitful direction \citep{hafner2019dream, taniguchi2023world}.

Our method provides a tool for researchers, e.g., in sensorimotor domains, to model sequential behavior by inferring an agent's subjective costs and internal uncertainties. This will enable answering novel scientific questions about how these quantities are affected by different experimental conditions, how they deviate from intended task goals and provided task instructions, or how they vary between individuals. 
This is particularly relevant to a computational understanding of naturalistic behavior \citep{krakauer2017neuroscience,cisek2014challenges,miller2022natural}, for which subjective utilities are mostly unknown.
