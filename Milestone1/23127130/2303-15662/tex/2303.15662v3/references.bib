@misc{openai_2022,
	author       = {OpenAI},
	year         = 2022,
	month        = {Nov},
	journal      = {Introducing ChatGPT},
	url          = {https://openai.com/blog/chatgpt}
}
@misc{hu_2023,
	title        = {ChatGPT sets record for fastest-growing user base - analyst note},
	author       = {Hu, Krystal},
	year         = 2023,
	month        = {Feb},
	journal      = {Reuters},
	publisher    = {Thomson Reuters},
	url          = {https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/}
}
@misc{ouyang2022training,
	title        = {Training language models to follow instructions with human feedback},
	author       = {Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and others},
	year         = 2022,
	eprint       = {2203.02155},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@book{shaker2016procedural,
	title        = {Procedural content generation in games},
	author       = {Shaker, Noor and Togelius, Julian and Nelson, Mark J},
	year         = 2016,
	publisher    = {Springer}
}
@misc{chowdhery2022palm,
	title        = {PaLM: Scaling Language Modeling with Pathways},
	author       = {Aakanksha Chowdhery and others},
	year         = 2022,
	eprint       = {2204.02311},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{smith2022using,
	title        = {Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model},
	author       = {Shaden Smith and others},
	year         = 2022,
	eprint       = {2201.11990},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{rae2022scaling,
	title        = {Scaling Language Models: Methods, Analysis \& Insights from Training Gopher},
	author       = {Jack W. Rae and others},
	year         = 2022,
	eprint       = {2112.11446},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{wei2022emergent,
	title        = {Emergent Abilities of Large Language Models},
	author       = {Jason We and others},
	year         = 2022,
	journal      = {Transactions on Machine Learning Research},
	issn         = {2835-8856},
	url          = {https://openreview.net/forum?id=yzkSU5zdwD},
	note         = {Survey Certification}
}
@article{Naumova2023,
	title        = {A mistake-find exercise: a teacher's tool to engage with information innovations, ChatGPT, and their analogs},
	author       = {Naumova, Elena N.},
	year         = 2023,
	month        = {Mar},
	day          = 13,
	journal      = {Journal of Public Health Policy},
	doi          = {10.1057/s41271-023-00400-1},
	issn         = {1745-655X},
	url          = {https://doi.org/10.1057/s41271-023-00400-1}
}
@article{info:doi/10.2196/45312,
	title        = {How Does ChatGPT Perform on the United States Medical Licensing Examination? The Implications of Large Language Models for Medical Education and Knowledge Assessment},
	author       = {Gilson, Aidan and others},
	year         = 2023,
	month        = {Feb},
	day          = 8,
	journal      = {JMIR Med Educ},
	volume       = 9,
	pages        = {e45312},
	doi          = {10.2196/45312},
	issn         = {2369-3762},
	url          = {http://www.ncbi.nlm.nih.gov/pubmed/36753318},
	keywords     = {natural language processing; NLP; MedQA; generative pre-trained transformer; GPT; medical education; chatbot; artificial intelligence; education technology; ChatGPT; conversational agent; machine learning},
	abstract     = {Background: Chat Generative Pre-trained Transformer (ChatGPT) is a 175-billion-parameter natural language processing model that can generate conversation-style responses to user input. Objective: This study aimed to evaluate the performance of ChatGPT on questions within the scope of the United States Medical Licensing Examination Step 1 and Step 2 exams, as well as to analyze responses for user interpretability. Methods: We used 2 sets of multiple-choice questions to evaluate ChatGPT's performance, each with questions pertaining to Step 1 and Step 2. The first set was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the user base. The second set was the National Board of Medical Examiners (NBME) free 120 questions. ChatGPT's performance was compared to 2 other large language models, GPT-3 and InstructGPT. The text output of each ChatGPT response was evaluated across 3 qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question. Results: Of the 4 data sets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBME-Free-Step2, ChatGPT achieved accuracies of 44{\%} (44/100), 42{\%} (42/100), 64.4{\%} (56/87), and 57.8{\%} (59/102), respectively. ChatGPT outperformed InstructGPT by 8.15{\%} on average across all data sets, and GPT-3 performed similarly to random chance. The model demonstrated a significant decrease in performance as question difficulty increased (P=.01) within the AMBOSS-Step1 data set. We found that logical justification for ChatGPT's answer selection was present in 100{\%} of outputs of the NBME data sets. Internal information to the question was present in 96.8{\%} (183/189) of all questions. The presence of information external to the question was 44.5{\%} and 27{\%} lower for incorrect answers relative to correct answers on the NBME-Free-Step1 (P<.001) and NBME-Free-Step2 (P=.001) data sets, respectively. Conclusions: ChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at a greater than 60{\%} threshold on the NBME-Free-Step-1 data set, we show that the model achieves the equivalent of a passing score for a third-year medical student. Additionally, we highlight ChatGPT's capacity to provide logic and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as an interactive medical education tool to support learning.}
}
@article{DOWLING2023103662,
	title        = {ChatGPT for (Finance) research: The Bananarama Conjecture},
	author       = {Michael Dowling and Brian Lucey},
	year         = 2023,
	journal      = {Finance Research Letters},
	volume       = 53,
	pages        = 103662,
	doi          = {https://doi.org/10.1016/j.frl.2023.103662},
	issn         = {1544-6123},
	url          = {https://www.sciencedirect.com/science/article/pii/S1544612323000363},
	keywords     = {ChatGPT, Artificial intelligence, Finance research, Ethics},
	abstract     = {We show, based on ratings by finance journal reviewers of generated output, that the recently released AI chatbot ChatGPT can significantly assist with finance research. In principle, these results should be generalisable across research domains. There are clear advantages for idea generation and data identification. The technology, however, is weaker on literature synthesis and developing appropriate testing frameworks. Importantly, we further demonstrate that the extent of private data and researcher domain expertise input, are key factors in determining the quality of output. We conclude by considering the implications, particularly the ethical implications, which arise from this new technology.}
}
@misc{sudhakaran2023mariogpt,
	title        = {MarioGPT: Open-Ended Text2Level Generation through Large Language Models},
	author       = {Shyam Sudhakaran and Miguel González-Duque and Claire Glanois and Matthias Freiberger and Elias Najarro and Sebastian Risi},
	year         = 2023,
	eprint       = {2302.05981},
	archiveprefix = {arXiv},
	primaryclass = {cs.AI}
}
@inproceedings{ferreira_2014_a,
	title        = {A Search-based Approach for Generating Angry Birds Levels},
	author       = {Lucas Ferreira and Claudio Toledo},
	year         = 2014,
	booktitle    = {Proceedings of the 9th IEEE International Conference on Computational Intelligence in Games},
	location     = {Dortmund, Germany},
	series       = {CIG'14}
}
@inproceedings{gravina2019procedural,
	title        = {Procedural content generation through quality diversity},
	author       = {Gravina, Daniele and Khalifa, Ahmed and Liapis, Antonios and Togelius, Julian and Yannakakis, Georgios N},
	year         = 2019,
	booktitle    = {2019 IEEE Conference on Games (CoG)},
	pages        = {1--8},
	organization = {IEEE}
}
@article{10.1145/3560815,
	title        = {Pre-Train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
	author       = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
	year         = 2023,
	month        = {jan},
	journal      = {ACM Comput. Surv.},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	volume       = 55,
	number       = 9,
	doi          = {10.1145/3560815},
	issn         = {0360-0300},
	url          = {https://doi.org/10.1145/3560815},
	issue_date   = {September 2023},
	abstract     = {This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x̂, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g., the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website including constantly updated survey and paperlist.},
	articleno    = 195,
	numpages     = 35,
	keywords     = {Pre-trained language models, prompting}
}
@misc{white2023prompt,
	title        = {A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT},
	author       = {Jules White and others},
	year         = 2023,
	eprint       = {2302.11382},
	archiveprefix = {arXiv},
	primaryclass = {cs.SE}
}
@article{Saravia_Prompt_Engineering_Guide_2022,
	title        = {{Prompt Engineering Guide}},
	author       = {Saravia, Elvis},
	year         = 2022,
	month        = 12,
	journal      = {https://github.com/dair-ai/Prompt-Engineering-Guide}
}
@misc{brown2020language,
	title        = {Language Models are Few-Shot Learners},
	author       = {Tom B. Brown and others},
	year         = 2020,
	eprint       = {2005.14165},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{wei2023chainofthought,
	title        = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
	author       = {Jason Wei and others},
	year         = 2023,
	eprint       = {2201.11903},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{kojima2023large,
	title        = {Large Language Models are Zero-Shot Reasoners},
	author       = {Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
	year         = 2023,
	eprint       = {2205.11916},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{wang2023selfconsistency,
	title        = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
	author       = {Xuezhi Wang and others},
	year         = 2023,
	eprint       = {2203.11171},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{liu2022generated,
	title        = {Generated Knowledge Prompting for Commonsense Reasoning},
	author       = {Jiacheng Liu and others},
	year         = 2022,
	eprint       = {2110.08387},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{zhou2023large,
	title        = {Large Language Models Are Human-Level Prompt Engineers},
	author       = {Yongchao Zhou and others},
	year         = 2023,
	eprint       = {2211.01910},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@misc{min2022rethinking,
	title        = {Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?},
	author       = {Sewon Min and others},
	year         = 2022,
	eprint       = {2202.12837},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{Gam2021,
	title        = {Deceptive Level Generation for Angry Birds},
	author       = {Gamage, Chathura and Pinto, Vimukthini and Renz, Jochen and Stephenson, Matthew},
	year         = 2021,
	booktitle    = {2021 IEEE Conference on Games (CoG)},
	pages        = {1--8},
	doi          = {10.1109/CoG52621.2021.9619031}
}
@inproceedings{tanabe2021Latent,
	title        = {Level Generation for Angry Birds with Sequential VAE and Latent Variable Evolution},
	author       = {Tanabe, Takumi and Fukuchi, Kazuto and Sakuma, Jun and Akimoto, Youhei},
	year         = 2021,
	booktitle    = {Proceedings of the Genetic and Evolutionary Computation Conference},
	location     = {Lille, France},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {GECCO '21},
	pages        = {1052–1060},
	doi          = {10.1145/3449639.3459290},
	isbn         = 9781450383509,
	url          = {https://doi.org/10.1145/3449639.3459290},
	abstract     = {Video game level generation based on machine learning (ML), in particular, deep generative models, has attracted attention as a technique to automate level generation. However, applications of existing ML-based level generations are mostly limited to tile-based level representation. When ML techniques are applied to game domains with non-tile-based level representation, such as Angry Birds, where objects in a level are specified by real-valued parameters, ML often fails to generate playable levels. In this study, we develop a deep-generative-model-based level generation for the game domain of Angry Birds. To overcome these drawbacks, we propose a sequential encoding of a level and process it as text data, whereas existing approaches employ a tile-based encoding and process it as an image. Experiments show that the proposed level generator drastically improves the stability and diversity of generated levels compared with existing approaches. We apply latent variable evolution with the proposed generator to control the feature of a generated level computed through an AI agent's play, while keeping the level stable and natural.},
	numpages     = 9,
	keywords     = {procedural content generation, AngryBirds, latent variable evolution, sequential VAE}
}
@inproceedings{ebin2022emot,
	title        = {Science Birds Gameplay With a Smile Interface to Promote the Spectator’s Emotion},
	author       = {Abdullah, Febri and Dewantoro, Mury F. and Thawonmas, Ruck and Bachtiar, Fitra A.},
	year         = 2022,
	booktitle    = {2022 IEEE Conference on Games (CoG)},
	pages        = {584--585},
	doi          = {10.1109/CoG51982.2022.9893545}
}
@inproceedings{matthew2017gen,
	title        = {Generating varied, stable and solvable levels for angry birds style physics games},
	author       = {Stephenson, Matthew and Renz, Jochen},
	year         = 2017,
	booktitle    = {2017 IEEE Conference on Computational Intelligence and Games (CIG)},
	pages        = {288--295},
	doi          = {10.1109/CIG.2017.8080448}
}
@techreport{vemprala2023chatgpt,
	title        = {ChatGPT for Robotics: Design Principles and Model Abilities},
	author       = {Vemprala, Sai and Bonatti, Rogerio and Bucker, Arthur and Kapoor, Ashish},
	year         = 2023,
	month        = {February},
	number       = {MSR-TR-2023-8},
	url          = {https://www.microsoft.com/en-us/research/publication/chatgpt-for-robotics-design-principles-and-model-abilities/},
	institution  = {Microsoft}
}
@misc{dosovitskiy2021image,
	title        = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
	author       = {Alexey Dosovitskiy and others},
	year         = 2021,
	eprint       = {2010.11929},
	archiveprefix = {arXiv},
	primaryclass = {cs.CV}
}
@inproceedings{ebin2019angry,
	title        = {An angry birds level generator with rube goldberg machine mechanisms},
	author       = {Febri Abdullah and Pujana Paliyawan and Ruck Thawonmas and Tomohiro Harada and Fitra A. Bachtiar},
	year         = 2019,
	booktitle    = {2019 IEEE Conference on Games (CoG)},
	pages        = {1--8},
	organization = {IEEE}
}
@inproceedings{kaidan2016procedural,
	title        = {Procedural generation of angry birds levels with adjustable difficulty},
	author       = {Kaidan, Misaki and Harada, Tomohiro and Chu, Chun Yin and Thawonmas, Ruck},
	year         = 2016,
	booktitle    = {2016 IEEE Congress on Evolutionary Computation (CEC)},
	pages        = {1311--1316},
	organization = {IEEE}
}
@inproceedings{ebin2020generating,
	title        = {Generating Angry Birds-Like Levels With Domino Effects Using Constrained Novelty Search},
	author       = {Abdullah, Febri and Paliyawan, Pujana and Thawonmas, Ruck and Bachtiar, Fitra A},
	year         = 2020,
	booktitle    = {2020 IEEE Conference on Games (CoG)},
	pages        = {698--701},
	organization = {IEEE}
}
@misc{openai_gpt35,
	author       = {OpenAI},
	journal      = {OpenAI API},
	url          = {https://platform.openai.com/docs/models/gpt-3-5}
}
@inproceedings{8080429,
	title        = {Procedural generation of angry birds fun levels using pattern-struct and preset-model},
	author       = {Jiang, Yuxuan and Harada, Tomohiro and Thawonmas, Ruck},
	year         = 2017,
	booktitle    = {2017 IEEE Conference on Computational Intelligence and Games (CIG)},
	volume       = {},
	number       = {},
	pages        = {154--161},
	doi          = {10.1109/CIG.2017.8080429}
}
@misc{todd2023level,
	title        = {Level Generation Through Large Language Models},
	author       = {Graham Todd and Sam Earle and Muhammad Umair Nasir and Michael Cerny Green and Julian Togelius},
	year         = 2023,
	eprint       = {2302.05817},
	archiveprefix = {arXiv},
	primaryclass = {cs.AI}
}
@article{8382283,
	title        = {Procedural Content Generation via Machine Learning (PCGML)},
	author       = {Summerville, Adam and Snodgrass, Sam and Guzdial, Matthew and Holmgård, Christoffer and Hoover, Amy K. and Isaksen, Aaron and Nealen, Andy and Togelius, Julian},
	year         = 2018,
	journal      = {IEEE Transactions on Games},
	volume       = 10,
	number       = 3,
	pages        = {257--270},
	doi          = {10.1109/TG.2018.2846639}
}
