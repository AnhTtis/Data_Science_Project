{
    "arxiv_id": "2303.15938",
    "paper_title": "fRegGAN with K-space Loss Regularization for Medical Image Translation",
    "authors": [
        "Ivo M. Baltruschat",
        "Felix Kreis",
        "Alexander Hoelscher",
        "Melanie Dohmen",
        "Matthias Lenga"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2023-03-29"
    ],
    "latest_version": 1,
    "categories": [
        "eess.IV",
        "cs.CV"
    ],
    "abstract": "Generative adversarial networks (GANs) have shown remarkable success in generating realistic images and are increasingly used in medical imaging for image-to-image translation tasks. However, GANs tend to suffer from a frequency bias towards low frequencies, which can lead to the removal of important structures in the generated images. To address this issue, we propose a novel frequency-aware image-to-image translation framework based on the supervised RegGAN approach, which we call fRegGAN. The framework employs a K-space loss to regularize the frequency content of the generated images and incorporates well-known properties of MRI K-space geometry to guide the network training process. By combine our method with the RegGAN approach, we can mitigate the effect of training with misaligned data and frequency bias at the same time. We evaluate our method on the public BraTS dataset and outperform the baseline methods in terms of both quantitative and qualitative metrics when synthesizing T2-weighted from T1-weighted MR images. Detailed ablation studies are provided to understand the effect of each modification on the final performance. The proposed method is a step towards improving the performance of image-to-image translation and synthesis in the medical domain and shows promise for other applications in the field of image processing and generation.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15938v1"
    ],
    "publication_venue": null
}