\section{Related Works}
% \FZ{can rw be shortened a bit?}\WW{removed a few sentences, will come back and remove more if needed}

\paragraph{Neural Radiance Fields} 
NeRF~\cite{nerf} is a 5D plenoptic function that models volume density and view-dependent appearance. Its differentiable volume rendering allows robust image-based 3D reconstruction and motivated an explosion of related works in areas including high-quality novel view synthesis~\cite{mipnerf360, refnerf, hdrnerf, nerf++}, 3D asset synthesis~\cite{gram, graf}, and efficient reconstruction and rendering~\cite{instantNGP, kilonerf, plenoxels, directvoxgo, plenoctrees}. Despite their outstanding novel view synthesis performance, many analyses suggest their geometry tends to produce artifacts such as sparse density floaters and inner volume~\cite{mipnerf360, refnerf, nerf++}. 
% Marching cube~\cite{marching_cube} 
Direct surface extraction on the density field hence suffers from those artifacts, whereas the depth extraction method does not guarantee watertight surfaces and requires additional surface reconstruction \cite{tsdf, alpha_shape, poisson_recon}
% such as TSDF fusion~\cite{tsdf}, poison surface reconstruction~\cite{poisson_recon} or alpha shapes~\cite{alpha_shape}
. UNISURF~\cite{UNISURF} attempts to mitigate this issue by gradually transiting from volume rendering to surface rendering, but its surface is tightly coupled as a fixed level set on the opacity field and it still only works on solid objects. Our approach deviates from this by using a separate implicit surface field with decoupled opacity to model semi-transparent and thin surfaces.

\vspace{-5pt}
\paragraph{SDF For Multi-view 3D Reconstruction} 
% To reconstruct well-defined surfaces from multi-view images, SDF has been widely utilized with various differentiable rendering techniques, which map 3D representations into 2D images in a differentiable way and therefore allow optimization via photometric loss.
SDF has been extensively employed with differentiable rendering methods to reconstruct surfaces from multi-view images. 
SDFDiff~\cite{sdfdiff} uses a voxel grid and trilinear interpolation to represent the SDF and develops differentiable sphere tracing to find an estimated intersection. 
Our approach deviates from this by using a closed-form solution to solve for \textit{exact} intersections with a more generalized implicit surface field, while also finding more than just the nearest intersections.
% supporting differentiable multi-surface rendering through alpha compositing. 
IDR~\cite{idr} proposes a differentiable sphere-tracing algorithm and optimizes the surface together with a volumetric BRDF. 
% However, this rendering procedure only has gradients defined at first intersections, causing the optimization to be difficult at depth discontinuities. 
VolSDF~\cite{volsdf} maps SDF to volume density via Laplacian CDF and optimizes the SDF via volume rendering.
% within a derived error bound on the approximated transparency function. 
NeuS~\cite{neus} similarly maps an SDF to unbiased weights in the volume rendering equation via a logistic sigmoid function. 
% With a trainable parameter that controls the spread of the weights around the zero-level set, it starts as a coarse surface with "spread-out" effects and converges to a concrete surface in the end. 
% This means their optimization still assumes surface solidity, and hence struggles on semi-transparent or thin surfaces. 
% Although VolSDF and NeuS both incorporate volume rendering in the optimization of SDF, they still assume surface solidity and encourage the rendering weights to become $1$ on the surface to fully occlude the ray. They hence still struggle on semi-transparent or thin surfaces. 
NeuS has motivated several further applications in different areas, such as sparse view surface reconstruction~\cite{sparse_neus}, fast reconstruction~\cite{neus2, voxel_surf, hash_sdf}, and finer details modeling such as HFS~\cite{HFS}, which applies a mapping from SDF to transparency and incorporates an additional displacement field to improve the reconstruction of fine details. 
A crucial and common limitation in existing SDF optimization methods is the assumption of surface solidity. Even the methods that utilize volume rendering in surface reconstruction, such as VolSDF and NeuS, still enforce convergence to solid surfaces in the end. Hence, they cannot properly reconstruct semi-transparent surfaces and suffer from thin structures with strong blending effects. 
% In comparison, our approach does not assume solid surfaces and can model both semi-transparent and thin objects.




