\section{Related Works}
% \FZ{can rw be shortened a bit?}\WW{removed a few sentences, will come back and remove more if needed}

\paragraph{Neural Radiance Fields} 
NeRF~\cite{nerf} is a plenoptic function of volume density and view-dependent appearance. Its differentiable volume rendering allows robust image-based 3D reconstruction and motivated many works in high-quality novel view synthesis~\cite{mipnerf360, refnerf, hdrnerf, nerf++}, 3D asset synthesis and editing ~\cite{gram, graf, dreamfusion, instructnerf2nerf}, few-shot reconstruction \cite{pixelnerf, zero123, SinNeRF, LEAP}, and efficient rendering~\cite{instantNGP, kilonerf, plenoxels, directvoxgo, plenoctrees, gaussian_splatting}. Despite the outstanding novel view synthesis performance, their geometry tends to produce artifacts such as sparse density floaters and inner volume~\cite{mipnerf360, refnerf, nerf++}. 
Direct surface extraction on the density field hence suffers from those artifacts, whereas the depth extraction method does not guarantee complete surfaces and requires additional surface reconstruction \cite{tsdf, alpha_shape, poisson_recon}.
% such as TSDF fusion~\cite{tsdf}, poison surface reconstruction~\cite{poisson_recon} or alpha shapes~\cite{alpha_shape}
% UNISURF~\cite{UNISURF} attempts to mitigate this issue by gradually transitioning from volume rendering to surface rendering, but its surface is tightly coupled as a fixed level set on the opacity field and it still only works on opaque objects. Our approach deviates from this by using a separate implicit surface field with decoupled opacity to model semi-transparent and thin surfaces.
% \ww{Recent Gaussian Splatting methods~\cite{gaussian_splatting, sugar} uses anisotropic 3D Gaussians to represent volumetric field and achieves efficient rendering. However, they do not resolve the transparency ambiguity and progressively remove Gaussians below a certain opacity threshold, and hence cannot be directly applied to reconstruct translucent surfaces.}

\vspace{-5pt}
\paragraph{Signed Distance Field} 
% To reconstruct well-defined surfaces from multi-view images, SDF has been widely utilized with various differentiable rendering techniques, which map 3D representations into 2D images in a differentiable way and therefore allow optimization via photometric loss.
SDF has been extensively employed with differentiable rendering methods to reconstruct surfaces from multi-view images. 
% SDFDiff~\cite{sdfdiff} uses a voxel grid and trilinear interpolation to represent the SDF and develops differentiable sphere tracing to find an estimated intersection. 
% Our approach deviates from this by using a closed-form solution to solve for \textit{exact} intersections with a more generalized implicit surface field, while also finding more than just the nearest intersections.
% supporting differentiable multi-surface rendering through alpha compositing. 
IDR~\cite{idr} proposes a differentiable sphere-tracing algorithm and optimizes the surface together with a volumetric BRDF. 
% However, this rendering procedure only has gradients defined at first intersections, causing the optimization to be difficult at depth discontinuities. 
VolSDF~\cite{volsdf} maps SDF to volume density via Laplacian CDF and optimizes the SDF via volume rendering.
% within a derived error bound on the approximated transparency function. 
NeuS~\cite{neus} similarly maps an SDF to unbiased weights in the volume rendering equation via a logistic sigmoid function. 
% With a trainable parameter that controls the spread of the weights around the zero-level set, it starts as a coarse surface with "spread-out" effects and converges to a concrete surface in the end. 
% This means their optimization still assumes surface solidity, and hence struggles on semi-transparent or thin surfaces. 
% Although VolSDF and NeuS both incorporate volume rendering in the optimization of SDF, they still assume surface solidity and encourage the rendering weights to become $1$ on the surface to fully occlude the ray. They hence still struggle on semi-transparent or thin surfaces. 
NeuS has motivated several further applications in different areas, such as sparse view surface reconstruction~\cite{sparse_neus, volrecon}, fast reconstruction~\cite{neus2, voxel_surf, hash_sdf}, and finer details modeling \cite{HFS, neuda, HFS, neuralangelo, GeoNeus}. 
% HFS~\cite{HFS} is a method that improves the reconstruction of fine details by applying a mapping from SDF to transparency and incorporating an additional displacement field to improve the reconstruction of fine details. 
A crucial and common limitation in existing SDF optimization methods is the assumption of surface opaqueness. Even the methods that utilize volume rendering in surface reconstruction still enforce convergence to opaque surfaces. Hence, they cannot properly reconstruct semi-transparent surfaces and suffer from thin structures with strong blending effects. 
% In comparison, our approach does not assume solid surfaces and can model both semi-transparent and thin objects.

\vspace{-5pt}
\paragraph{Transparent Object Reconstruction} 
% \ww{Many works have tried to address the problem of transparent object reconstruction~\cite{neto, laser_transparent_recon, through_glass}. They focus on thick and fully transparent objects, and aim to reconstruct the shape by solving the complicated light transportation within the objects. Most methods require additional supervision such as environment matting, which can only be obtained with checkerboard-patterned backgrounds. In comparison, we reconstruct thin translucent surfaces from RGB images alone with no other supervision, and we focus on resolving the material ambiguity in existing neural representation instead of solving for light transport. Our approach is hence orthogonal to those methods.}
\ww{Many works have tried to address the problem of transparent object reconstruction~\cite{neto, laser_transparent_recon, through_glass}. They focus on thick and fully transparent objects, and aim to reconstruct the shape by solving the complicated light transportation within the objects. Most methods require additional supervision such as environment matting, which can only be obtained with checkerboard-patterned backgrounds. In comparison, we reconstruct thin translucent surfaces from RGB images alone with no other supervision. NeRRF~\cite{chen2023nerrf} is a method that similarly reconstructs surfaces from RGB images and mask supervisions.}

% \WW{Add reference to methods that specifically reconstructs translucent materials}



