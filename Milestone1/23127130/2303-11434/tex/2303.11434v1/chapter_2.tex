\chapter{Literature Review}\label{chapter_2}

\section{Overview}

In the recent years, there have been a lot of development in computational method to predict the drug-target binding affinity prediction. Most of these developments came from the increasing development in the data science field. The approaches that have been used for this work can be categorized in three sections. These are – 

\begin{itemize}
    \item Machine Learning based approaches
    \item Deep Learning based approaches using string representation
    \item Deep Learning based approaches using Molecular Graph
\end{itemize}

Each of these methods gives a lot of new ideas and ways to increase the evaluation results. But no methods are completely perfect as each one has some merits and demerits. In this section we will briefly know about the merits and demerits of these approaches and give some solutions to those demerits to overcome them.\\

\section{Machine Learning Based Approach}

\textbf{KronRLS~\cite{kronrls}:} It aims to minimize the following function, where $f$ is the prediction function

\begin{equation}
J(f)=\sum_{i=1}^{m}\left(y_{i}-f\left(x_{i}\right)\right)^{2}+\lambda\|f\|_{k}^{2}
\label{kronrls_equ}
\end{equation}

$\|f\|_{k}^{2}$ is the norm of $f$, which is related to the kernel function $k$, and $\lambda > 0 $ is a regularization hyper-parameter defined by the user. A minimizer for the equation can be defined as follows ~\cite{kimeldorf1971some}

\begin{equation}
f(x)=\sum_{i=1}^{m} a_{i} k\left(x, x_{i}\right)
\label{kronrls_equ_2}
\end{equation}

where $k$ is the kernel function. In order to represent compounds, they utilized a similarity matrix computed using Pubchem structure clustering server (Pubchem Sim\footnote{http://pubchem.ncbi.nlm.nih.gov} ), a tool that utilizes single linkage for cluster and uses 2D properties of the compounds to measure their similarity. As for proteins, the Smith–Waterman algorithm was used to construct a protein similarity matrix~\cite{smith1981identification}.\\

\textbf{SimBoost:} SimBoost is a gradient boosting machine based method that depends
on the features constructed from drugs, targets and drug–target pairs~\cite{simboost}. The proposed methodology uses feature engineering to build three types of features: (i) object-based features that utilize occurrence statistics and pairwise similarity information of drugs
and targets, (ii) network-based features such as neighbor statistics, network metrics (betweenness, closeness etc.), PageRank score, which are collected from the respective drug–drug and target–target networks (In a drug–drug network, drugs are represented as nodes and connected to each other if the similarity of these two drugs is above a user-defined threshold. The target–target network is constructed in a similar way.) and (iii) network-based features that are collected from a heterogeneous network (drug–target network) where a node can either be a drug or target and the drug nodes and target nodes are connected to each other via binding affinity value. In addition to the network metrics, neighbor statistics and PageRank scores, as well as latent vectors from matrix factorization
are also included in this type of network.\\

These features are fed into a supervised learning method named gradient boosting regression trees ~\cite{chen2016xgboost,chen2015higgs} derived from gradient boosting machine model~\cite{friedman2001greedy}. With gradient boosting regression trees, for a given drug–target pair $dt_i$, the binding affinity score $\overline{y_i}$ predicted as follows~\cite{simboost}:

\begin{equation}
\bar{y}_{l}=\theta\left(d t_{i}\right)=\sum_{m=1}^{M} f_{m}\left(d t_{i}\right), f_{m} \in F
\label{simboost_equ_1}
\end{equation}

in which $M$ denotes the number of regression trees and F represents the space of all possible trees. A regularized objective function to learn the set of trees $f_m$ is described in the following form~\cite{simboost}:

\begin{equation}
R(\theta)=\sum_{l} l\left(y_{i}, \bar{y}_{l}\right)+\sum_{m} \alpha\left(f_{m}\right)
\label{simboost_equ_2}
\end{equation}

where $l$ is the loss function that measures the difference between the actual binding affinity value $y_i$ and the predicted value $\overline{y_i}$  while $\alpha$ is the tuning parameter that controls the complexity of the model. The details are described in~\cite{chen2016xgboost,chen2015higgs, simboost}. Similar to ~\cite{kronrls}, ~\cite{simboost} also used PubChem clustering server for drug similarity and Smith–Waterman for protein similarity computation.\\

As we can see that both of these methods use hand engineering techniques along with machine learning techniques. Most of these methods score in a low coefficient correlation value which question the reliability of these methods. \newpage

\section{Deep-learning Based Approach Using String Representation}

\textbf{DeepDTA~\cite{deepdta}:} comprises two separate CNN blocks, each of which aims to learn representations from SMILES strings and protein sequences. For each CNN block, DeepDTA used three consecutive 1D-convolutional layers with increasing number of filters. The second layer had double and the third convolutional layer had triple the number of filters in the first one. The convolutional layers were then followed by the max-pooling layer. The final features of the max-pooling layers were concatenated and fed into three FC layers. DeepDTA used 1024 nodes in the first two FC layers, each followed by a dropout layer of rate 0.1. The third layer consisted of 512 nodes and was followed by the output layer.\\

\textbf{MT-DTI~\cite{mtdti}:} Molecule Transformer Drug Target Interaction (MT-DTI), based on a new molecule representation. They use a self-attention mechanism to learn the high-dimensional structure of a molecule from a given raw sequence. Their self-attention mechanism, Molecular Transformer (MT), is pre-trained on publicly available chemical compounds (PubChem database) to learn the complex structure of a molecule. This pre-training is important, because most datasets available for DTI training has only 2000 molecules, while the data for pre-training (PubChem database) contains 97 million of molecules. Although it does not contain interaction data but just molecules, their MT is able to learn a chemical structure from it, which will be effectively utilized when transferred to MT-DTI. Therefore, they transfer this trained molecule representation to their DTI model so that it can be fine-tuned with a DTI dataset.\\

\textbf{Deep-CPI~\cite{deepcpi}:} In their work they demonstrate that predicting compound-protein interaction (CPI) problem can be solved using a neural attention mechanism~\cite{bahdanau2014neural}. This mechanism allows them to consider which subsequences in a protein are important for a drug compound to predict CPIs (i.e. interaction sites) by using weights, which are also learned in the proposed neural networks. Furthermore, by using the obtained weights, the neural attention mechanism provides clear visualizations, which makes models easier to analyze even when modeling is performed using real-valued vector representations rather than discrete features. In their experiments using three CPI datasets ~\cite{liu2015improving, mysinger2012directory}, they demonstrated that the proposed approach based on end-to-end learning of GNN and CNN can achieve competitive or higher performance than existing approaches.\\

\textbf{WideDTA~\cite{widedta}:} They propose a methodology to predict protein-ligand binding affinity through text-only information of both proteins and compounds. Without relying on 3D structure information of the complex or 2D representation of the compound, they learn high dimensional features from sequences of the proteins and ligands. They suggested that, since the full-length sequence was used, the biologically important short subsequences that would be more powerful at representing the protein were lost due the
low signal to noise ratio~\cite{deepdta}. In order to overcome this problem, they propose to integrate different pieces of text-based information in the WideDTA model to provide a better representation of the interaction. They still utilize the protein sequence and ligand SMILES string by representing them as a set of words. A word of a protein sequence corresponds to a three-residue subsequence, whereas a word of a ligand is equal to an 8-character subsequence extracted with a sliding window approach~\cite{vidal2005lingo}. In addition, they use two textual information sources that can provide valuable clues about the specificity of the interaction.

The first piece of information we add to our words is protein motif and/or domain information. They utilize the PROSITE database~\cite{sigrist2010prosite} to extract motifs and profiles that are associated with a biologically significant function and domain. Then, they benefit from a recent study that showed that maximum common substructures (MCS) of ligands constitute the actual words in the chemical space~\cite{wozniak2018linguistic}. Approximately 100K MCS were used to extract a new set of words from the ligands. Together, these four text-based information sources constitute the WideDTA model.\\

\textbf{GANsDTA~\cite{gansdta}:} They propose a GANs~\cite{goodfellow2014generative}-based method to predict binding affinity, called GANsDTA for short. Their method comprises two types of networks, two partial GANs for the feature extraction from the raw protein sequences and SMILES strings separately and a regression network using convolutional neural networks for prediction. The contributions of their paper mainly include: They proposed a semi-supervised framework for DTA prediction; they adopted GAN to extract features of protein sequence and compound SMILES in an unsupervised way. Therefore, the proposed model can accommodate unlabeled data for the training as feature extractor using GANs does not require labeled data. This semi-supervised mechanism enables more datasets even without labels available for our model to learn proteins drugs features, leading to better feature representation and prediction performance accordingly. \\

\textbf{AttentionDTA~\cite{attentiondta}:} They propose a model to predict the binding affinities of drug-protein interactions with attention model using only sequences (1D representations) of proteins and drugs. After CNN extracted the abstract matrix representation of drugs and proteins, they use the attention module to calculate the scores between drugs and proteins representations at different positions, which allows them to consider which subsequences in a protein are more important for subsequences in the drug when predicting its affinity score and vice versa. They combine these representations to feed into a fully connected layer block, so called AttentionDTA. \\

All these methods use 1D convolutional neural network. One of the common problem these models face the loss of information in the initial layers. So, the representation in each stream remains under-represented as it can’t retain information when the input propagates through the model. In ~\cite{widedta} they try to address this problem by using additional data along with the input data.\\

\section{Deep-learning Based Approach Using Graph Representation}

These approaches use molecular graph as the input rather than the 1D string or the SMILES representation of the drug. Currently, these methods are becoming very much popular as they are able to create better representation for this task. \\

\textbf{DeepH-DTA~\cite{deephdta}:} They introduce a novel deep-learning-based DTI framework, called deepH-DTA, which geometrically exploits existing the topological structure of drug molecules as input features, along with the corresponding molecular fingerprints. They investigated twofold prediction of chemical interactions between protein sequences of target and homogeneity of drug candidate compounds. To this end, they propose a novel DTI prediction framework that utilizes a HGAT ~\cite{wang2019heterogeneous} for efficient modeling of interactions of various targeted topological representation of drugs. Simultaneously, they introduce two layers of bidirectional ConvLSTM~\cite{shi2015convolutional} to capture spatio-sequential characteristics of drug sequences encoded in a simplified molecular-input line-entry system (SMILES) format~\cite{weininger1988smiles}. The spatio-sequential sequences capture both positional features of input SMILES and the long-term dependency representation within input sequences.\\

\textbf{GraphDTA~\cite{nguyen2021graphdta}:} GraphDTA is a new neural network architecture capable of directly modelling drugs as molecular graphs. The approach is based on the solution they submitted to the IDG-DREAM Drug-Kinase Binding Prediction Challenge\footnote{https://www.synapse.org/\#!Synapse:syn15667962/wiki/583305}, where they were among the Top Ten Performers from 530 registered participants\footnote{https://www.synapse.org/\#!Synapse:syn15667962/wiki/592145}. Their results suggest that graph neural networks are highly accurate, abstract meaningful concepts, and yet fail in predictable ways. They conclude with a discussion about how these insights can feedback into the research cycle.\\

\textbf{GIN~\cite{wang2020dipeptide}:} They propose a novel feature extraction method which is polypeptide frequency of word frequency based on natural language word frequency characteristics to enhance the ability of protein sequence expression. The network model is constructed by merging the graph convolutional network that calculates the graph structure of drugs and the convolutional neural network that calculates the hidden relationship of protein features. The results of output are combined as the input of two hidden layers for regression training and prediction of DTA.\\

\textbf{DeepGS~\cite{lin2020deepgs}:} Their work is the first to consider both local chemical context and topological structure to learn the interaction between drugs and targets. Their experimental results demonstrate that considering jointly local chemical context and topological structure are effective and the newly designed molecular structure modeling approach works well under their proposed framework.\\

While these works provide much greater results than the rest of the works but to understand and comprehend their work and in some cases to use their work the knowledge in molecular science and chemical domain is required.\\

\section{Summary}

In this chapter, we have looked into all sorts of work that has been done in the drug target binding affinity prediction domain. We have looked into a lot of works that has been done in the last ten years and some of the works achieve great results but they do possess some demerits as well. We have briefly talked about those demerits in this chapter and we will try to address those in the following chapter with our contribution in this research topic. 





\endinput

