% \documentclass{uai2023} % for initial submission
% % \documentclass[accepted]{uai2023} % after acceptance, for a revised
%                                     % version; also before submission to
%                                     % see how the non-anonymous paper
%                                     % would look like

% %% There is a class option to choose the math font
% % \documentclass[mathfont=ptmx]{uai2023} % ptmx math instead of Computer
% % Modern (has noticable issues)
% % \documentclass[mathfont=newtx]{uai2023} % newtx fonts (improves upon
%  % ptmx; less tested, no support)
% % NOTE: Only keep *one* line above as appropriate, as it will be replaced
% %       automatically for papers to be published. Do not make any other
% %       change above this note for an accepted version.

% %% Choose your variant of English; be consistent
% \usepackage[american]{babel}
% % \usepackage[british]{babel}

% %% Some suggested packages, as needed:
% \usepackage{natbib} % has a nice set of citation styles and commands
%     \bibliographystyle{plainnat}
%     \renewcommand{\bibsection}{\subsubsection*{References}}
% \usepackage{mathtools} % amsmath with fixes and additions
% % \usepackage{siunitx} % for proper typesetting of numbers and units
% \usepackage{booktabs} % commands to create good-looking tables
% \usepackage{tikz} % nice language for creating drawings and diagrams

% % for cross referencing the main text
% % PLEASE ONLY USE xr IN THE SUPPLEMENTARY MATERIAL. 
% % In the main paper, hard code any cross-reference to the supplementary material. 
% \usepackage{xr} 
% \externaldocument{uai2023-template}

% %% Provided macros
% % \smaller: Because the class footnote size is essentially LaTeX's \small,
% %           redefining \footnotesize, we provide the original \footnotesize
% %           using this macro.
% %           (Use only sparingly, e.g., in drawings, as it is quite small.)

% %% Self-defined macros
% \newcommand{\swap}[3][-]{#3#1#2} % just an example

% \title{Title in Title Case\\(Supplementary Material)}

% % The standard author block has changed for UAI 2023 to provide
% % more space for long author lists and allow for complex affiliations
% %
% % All author information is authomatically removed by the class for the
% % anonymous submission version of your paper, so you can already add your
% % information below.
% %
% % Add authors
% \author[1]{\href{mailto:<jj@example.edu>?Subject=Your UAI 2023 paper}{Jane~J.~von~O'L\'opez}{}}
% \author[1]{Harry~Q.~Bovik}
% \author[1,2]{Further~Coauthor}
% \author[3]{Further~Coauthor}
% \author[1]{Further~Coauthor}
% \author[3]{Further~Coauthor}
% \author[3,1]{Further~Coauthor}
% % Add affiliations after the authors
% \affil[1]{%
%     Computer Science Dept.\\
%     Cranberry University\\
%     Pittsburgh, Pennsylvania, USA
% }
% \affil[2]{%
%     Second Affiliation\\
%     Address\\
%     …
% }
% \affil[3]{%
%     Another Affiliation\\
%     Address\\
%     …
%   }
  
% \onecolumn %% Turn this off if single column is desired for the supplement
% \maketitle

\appendix
\vspace{-7pt}
\section*{Appendix}
\vspace{-7pt}
In this Appendix, we include the following additional information, which we could not include in the main paper due to space constraints.
\vspace{-5pt}
\begin{itemize}
 \setlength\itemsep{-0.3em}
    \item Causality preliminaries
    \item Proofs of propositions
    \item Experimental setup including
    \begin{itemize}\setlength\itemsep{-0.1em}
         \item Causal DAG of Lung Cancer dataset
        \item LiNGAM output for AUTOMPG dataset
    \end{itemize}
    \item Additional results
    \begin{itemize} \setlength\itemsep{-0.1em}
        \item Comparison of direct, indirect, and total causal effects of our method with baselines
        \item Qualitative results on synthetic flight datasets
    \end{itemize}
    \item Details on efficient implementation strategies
    \item Related work on concept based explainability
\end{itemize}


% Supplementary list
% Approximation time complexity proof
% Approximation clustering techniques 
% Results of direct, indirect and total effect
% code to reproduce results
% causal graph for lung cancer data
% approximated causal graph for autompg data
% synthetic flight data causal graphs and ACE plots


\vspace{-7pt}
\section{Causality Preliminaries}
\vspace{-9pt}

\label{preliminaries}
\noindent \textbf{Structural Causal Models:} A Structural Causal Model (SCM) $\mathcal{S}(X, U, F, P_u)$ represents cause-effect relationships among a set of random variables $\{X\cup U\}$ in the form of a set of structural equations $F$ relating variables and their parents. This set of random variables can be divided into exogenous ($U$) and endogenous ($X$) variables. An exogenous variable is usually a noise variable that we do not have control over. Exogenous variables often denote uncontrolled external factors. Endogenous variables are deterministically fixed via functions over the exogenous and other endogenous variables. An SCM can also be viewed as a directed graphical model $\mathcal{G}=(\mathcal{V},\mathcal{E})$, where the set of vertices $\mathcal{V}$ corresponds to the set of endogenous variables $X$. The set of edges $\mathcal{E}$ corresponds to the set of causal mechanisms $F$ relating each variable with its parents and corresponding noise. Concretely, if $x_i = f_i(Pa(x_i),u_i)$ then $\forall x_j \in Pa(x_i)$, there exists a directed edge from the vertex $v_j$ corresponding to $x_j$ to the vertex $v_i$ corresponding to $x_i$ in $\mathcal{G}$. In $v_j\rightarrow v_i$, the vertex $v_j$ is called the \textit{parent} vertex while the vertex $v_i$ is called the \textit{child} vertex. Such a graph is called a \textit{Causal Bayesian Network} (CBN). The distribution of every vertex in a CBN depends only upon its parent vertices--called the local Markov property~\cite{kiiveri1984recursive}. 

A \textit{path} in a CBN is defined as a sequence of unique vertices $v_0, v_1, v_2, ..., v_n$ with an edge between each consecutive vertices $v_i$ and $v_{i+1}$. The edge between $v_i$ and $v_{i+1}$ can take one of the following two forms: (i) $v_i \rightarrow v_{i+1}$, (ii) $v_{i+1}\rightarrow v_i$. On the other hand, a \textit{directed path} is defined as a sequence of unique vertices $v_0, v_1, v_2, ..., v_n$ with an edge between each consecutive vertex $v_i$ and $v_{i+1}$ so that the the edge between $v_i$ and $v_{i+1}$ takes from $v_i \rightarrow v_{i+1}$. A \textit{collider} is defined w.r.t. a \textit{path} as a vertex  $v_i$ which has a $\rightarrow v_i \leftarrow$ structure (the direction of the arrows imply the direction of the edges along the path). A \textit{path} is said to be \textit{blocked} if either (i) there exists a \textit{collider} that is not in $Anc(Z)$, or, (ii) there exists a \textit{non-collider} $v \in Z$ along the path.  $Anc(Z)$ is the set of all vertices which exhibit a \textit{directed path} to any vertex $v \in Z$.

\theoremstyle{definition}
\begin{definition}({d-separation}).
Two vertices $v_x$ and $v_y$ corresponding to two random variables $x$ and $y$ are said to be \textit{d-separated} in $\mathcal{G}$ if all paths connecting the two vertices are blocked by a set of nodes $v_Z$  corresponding to the set of random variables $Z$. 
\label{def: d-separation}
\end{definition}

\begin{propositions}\cite{pearl2009causality}
Two random variables $X$ and $Y$ are considered conditionally independent given a set of random variables $Z$ if they are \textit{d-separated} in the corresponding graphical model $G$.
\label{prop: conditional_independence}
\end{propositions}
\vspace{-5pt}

Since we view NNs as graphical models, in $\mathcal{N}$, each input feature is $d$-separated from all other input features conditioned on an empty set. However, in $\mathcal{N}^{AH}$, since the input features are connected similarly to the ground truth causal graph $\mathcal{G}$, any $d$-separation condition among input features that is valid in the ground truth causal graph is also valid in $\mathcal{N}^{AH}$.

A CBN $\mathcal{G} = (\mathcal{V},\mathcal{E})$ induces a joint distribution over its vertices $P_{\mathcal{V}} = \prod_{v_i \in \mathcal{V}}P(v_i|Pa(v_i))$. Performing interventions on a random variable $x_i$ is analogous to surgically removing incoming edges to its corresponding vertex $v_i$ in the network $\mathcal{G}$. This is because the value of the random variable $x_i$ now depends on the nature of the intervention caused by the \textit{external doer} and not the inherent causal structure of the system. The interventional joint distribution over the vertices of $\mathcal{G}$ would be $P_{(\mathcal{V} | do(v_i))} = \prod_{v_i \in \mathcal{V} \setminus v_i}P(v_i|Pa(v_i)))$. Notice that in $P_{(\mathcal{V} | do(v_i))}$, the factorization of the interventional joint distribution ignores the intervened random variable $x_i$. In an SCM $\mathcal{S}(X, U, f, P_u)$, performing a $do(x_i = x_i')$ operation results in an intervened SCM $\mathcal{S}^i(X, U, f^i, P_u)$, where the causal mechanism $f_{x_i}$ for variable $x_i$, is replaced by the constant function $x_i'$. $f^i$ is obtained from the set $f$ by replacing all the instances of random variable $x_i$ in the arguments of the causal functions by $x_i'$. Although similar in appearance to the conditional expectation $\E(y|x = 1)$, $\E(y|do(x = 1))$ refers to the expectation of the random variable $y$ taken over its interventional distribution $P(y|do(x = 1))$.
\begin{definition}({Average Causal Effect}).
The Average Causal Effect (ACE) of a random variable $x$ at an intervention $\alpha$ on another random variable $y$ w.r.t. a baseline intervention $b$ is defined as $ACE_x^y := \E[y|do(x = \alpha)] - \E[y|do(x = b)]$.
\end{definition}
In Eqn \ref{eq: ACE}, an ideal baseline would be any point along the decision boundary of the neural network, where predictions are neutral~\cite{causalattributions}.  In this work, following~\cite{causalattributions}, we consider the average ACE of $x_i$ on $y$ as the baseline value for $x_i$, i.e. $\E(y|do(x = b)) = \E_{\alpha}[\E_y[y|do(x_i = \alpha)]]$.


\begin{definition}({Direct and Indirect Causal Effects}).
\label{directindirecteffects}
The causal effect of a random variable $X$ on another random variable $Y$ that is not flowing through other random variables is known as the direct causal effect. The causal effect of a random variable $X$ on another random variable $Y$ flowing through other random variables is known as the indirect causal effect.
\end{definition}
To understand Defn~\ref{directindirecteffects}, Consider Fig~\ref{fig:direct_indirect_effects}. The causal effect of $X$ on $Y$ that flows through the directed path $X\rightarrow Y$ is the direct causal effect, and the causal effect of $X$ on $Y$ that flows through the directed path $X\rightarrow Z \rightarrow Y$ is the indirect causal effect.

\begin{figure}
    \hspace{-15pt}
    \centering
    \includegraphics[width=0.2\textwidth]{images/direct_indirect.png}
    \caption{Direct and Indirect Effects}
    \label{fig:direct_indirect_effects}
\end{figure}

\vspace{-9pt}
\section{Proofs of Propositions}
\label{proofs}
\vspace{-7pt}
\propositionone*
\vspace{-7pt}
\begin{proof}
In a feedforward neural network, each layer neurons can be written as functions of neurons in its previous layer, i.e. $\forall i \in l: \forall l_{i_j} \in l_{i}: l_{i_j} = F_{i_j}(l_{i - 1})$. The input layer $l_1$ can be assumed to be functions of independent noise variables $U$ such that $l_{1_i} = F_{1_i}(u_i) $ $\forall l_{1_i} \in l_1$ and $u_i \in U$. This structure in the random variables, neurons in the network, can be equivalently expressed by a SCM $\mathcal{S}([l_1,  l_2, ...., l_n], U, [F_1, F_2, ... F_n], P_u)$.
\end{proof}
\vspace{-7pt}
\corollaryone*
\vspace{-7pt}
\begin{proof}
All notations are consistent with their definitions in Proposition \ref{prop: NN as SCM}. Starting with each neuron $l_{n_i}$ in the output layer $l_n$, the corresponding causal function $F_{n_i}(l_{n - 1})$ can be substituted as $F_{n_i}(F_{{n - 1}_1}(l_{n - 2}), F_{{n - 1}_2}(l_{n - 2}), ... F_{{n - 1}_{|l_{n-1|}}}(l_{n - 2}))$. This can also be written as $l_{n_i} = F'_{n_i}(l_{n - 2})$. $F_{i_j}$ refers to the causal function of neuron $j$ in layer $i$. Similarly, $l_{i_j}$ refers to neuron $j$ in layer $i$. Proceeding recursively layer by layer, we obtain modified functions such that, $\forall l_{n_i} \in layer$ $l_n: l_{n_i} = F'_{n_i}(l_1)$. The causal mechanisms set $F'$ of the reduced SCM $\mathcal{S}'$ would be $\{F'_{n_i}| l_{n_i} \in l_n\} \cup \{l_{1_i} = F_{1_i}(u_i) | l_{1_i} \in l_1$ and $u_i \in U\}$
\end{proof}
\vspace{-9pt}
\propositionindirectidentifiability*
\vspace{-3pt}
\begin{proof}
Consider an NN $\mathcal{N}$ with input features $x_1,\dots,x_n$ and an output neuron $y$ in the final layer. Using Corollary~\ref{corr: recursive_subs}, we can marginalize the hidden layers of $\mathcal{N}$ and consider $y$ as a function $f$ of only $\mathcal{N}$'s inputs i.e., $y=f(x_1,\dots,x_n)$. In a simple feed forward neural network $\mathcal{N}$, the inputs are not causally connected by design i.e., no neural network edges among input neurons. If we perform an intervention $do(x_i=\alpha)$ in $\mathcal{N}$, it will not affect any other input features but affects $y$ through the function $f$. That is, $x_i$ has only a direct effect on $y$ (Defn~\ref{def:direct_effect}), and indirect effect of $x_i$ on $y$ does not exist. If we introduce neural network edges among inputs, the intervention $do(x_i=\alpha)$ will influence $x_i$'s descendants via the newly introduced edges and $y$ via the function $f$. Hence the indirect causal attributions of $x_i$ on $y$ can be identified. Now, to \textit{quantify} the indirect causal attributions, we need to rely on the effect of $x_i$ on $y$ via the children of $x_i$. For this purpose it is required to learn the weights corresponding to the edges between $x_i$ and its children while optimizing $\mathcal{N}$'s objective such as minimizing regression loss.
\end{proof}

\propositiontwo*
\vspace{-9pt}
\begin{proof}
Here, we show that the graphical criterion to experimentally identify the causal effects are satisfied in $\mathcal{N}^{AH}$, which is enough to claim that causal effects are identifiable in $\mathcal{N}^{AH}$~\cite{pearl2009causality}. Let $\mathcal{I}_v = \{x_i, Z, y, W\}$ be the set of nodes in the marginalized neural network where $Z$ is the set of nodes in the input layer that are in a path from $x_i$ to $y$, and $W$ is the set of remaining nodes in the input layer. We need to show that $\big[y|do(x_i, Z)\big]\perp \!\!\!\perp Z_{x_i^*}|W$ for natural direct effect identifiability and $\big[y|do(x_i^*, Z)\big]\perp \!\!\!\perp Z_{x_i}|W$ for natural indirect effect identifiability~\cite{pearl2001direct,pearl2009causality} in $\mathcal{N}^{AH}$ model. Graphically, proving these two criteria is equivalent to showing $(y\perp \!\!\!\perp Z|W)_{\mathcal{G}_{\underline{x_i Z}}}$~\cite{pearl2001direct,pearl2009causality}. Here $\mathcal{G}_{\underline{x_i Z}}$ is formed by removing from $\mathcal{G}$ the outgoing edges from $x_i$ and from the nodes of $Z$. In $\mathcal{N}^{AH}$ model, after removing the outgoing edges from $x_i$ and from the nodes of $Z$, there will be no directed edges from $x_i, Z$ to $y$ and all the \textit{backdoor} paths to $y$ (if exists) will be blocked by $W$ and hence satisfy the property $(y\perp \!\!\!\perp Z|W)_{\mathcal{G}_{\underline{x_i Z}}}$. On the other hand, since there is no indirect causal paths in the SCM of $\mathcal{N}$, indirect causal attributions do not exist in $\mathcal{N}$ i.e., indirect causal attributions in $\mathcal{N}$ are $0$.
\end{proof}

\vspace{-9pt}
\section{Experimental Setup and Additional Results}
\label{setup}
In this section, we provide additional details on the experimental setup. Tabs~\ref{tab:synthetic_data1}-~\ref{tab:synthetic_data3} shows the synthetic datasets used corresponding to the results in Tabs~\ref{tab:synthetic_results_indirect},~\ref{tab:synthetic_results_total}. While the main paper presents results w.r.t. total causal effects, Tabs~\ref{tab:synthetic_results_appendix} and~\ref{tab:appendixcancerandautompg} presents the results w.r.t. the direct, indirect, and total causal attributions of various methods. Figure~\ref{autompg_lingam} shows the output of LiNGAM~\cite{shimizu2006linear} causal discovery algorithm for AUTOMPG dataset which was performed as we do not have access to underlying causal graph. Figure~\ref{asia_dag} shows the causal DAG corresponding to the Lung Cancer dataset obtained from BNLearn repository~\cite{scutari2014bayesian}. Figure~\ref{fig:binning_results} shows the absolute ACE values of each feature at different time steps for various datasets and baselines. In Fig~\ref{fig:binning_results}, `Newtonian` refers to the Newtonian approximation $\nabla^2f \approx J^TJ$, `Approx` refers to the approximation to the second order term in Eqn~\ref{expected taylor expansion eq} proposed in~\cite{causalattributions}. For each plot in Fig~\ref{fig:binning_results}, x-axis denotes the time step (unrolling length of RNN), and y-axis denotes the features. It can be seen that, in many cases, the proposed approximation's causal attributions (last four columns) are close to the exact computation of causal attributions (first two columns). However, there is a trade-off between the binning parameters (number of bins, distance function used in clustering methods, etc.) and the obtained causal attributions.

\begin{table*}
\footnotesize
\begin{minipage}{0.3\linewidth}
        \centering
        \includegraphics[width=0.5\linewidth]{images/synthetic1.png}
        \vspace{-5pt}
	\end{minipage}
	\begin{minipage}{0.3\linewidth}
        \centering
        \includegraphics[width=0.5\linewidth]{images/synthetic2.png}
        \vspace{-5pt}
	\end{minipage}
	\begin{minipage}{0.3\linewidth}
        \centering
        \includegraphics[width=0.5\linewidth]{images/synthetic3.png}
        \vspace{-5pt}
	\end{minipage}
	\begin{minipage}{0.33\linewidth}
    \begin{align*}
     W &\leftarrow Uniform(0, 1)\\
     Z &\leftarrow 2W + \mathcal{N}(0, 0.1)\\
     X &\leftarrow 2W - Z + \mathcal{N}(0, 0.1)\\
     Y &\leftarrow 3X + e^{3Z} + \mathcal{N}(0, 0.1)
    \end{align*}
     \vspace{-.7cm}
    \captionof{table}{Synthetic Data 1}
    \vspace{-.2cm}
    \label{tab:synthetic_data1}
	\end{minipage}
	\begin{minipage}{0.33\linewidth}
    \begin{align*}
     W &\leftarrow Uniform(0, 1)\\
     Z &\leftarrow W/2 + \mathcal{N}(0, 0.1)\\
     X &\leftarrow -W-Z + \mathcal{N}(0, 0.1)\\
     Y &\leftarrow X^3 + \log(Z^2) + \mathcal{N}(0, 0.1)
    \end{align*}
    \vspace{-.7cm}
    \captionof{table}{Synthetic Data 2}
    \vspace{-.2cm}
    \label{tab:synthetic_data2}
	\end{minipage}
	\begin{minipage}{0.33\linewidth}
    \begin{align*}
     W &\leftarrow Uniform(-1, 1)\\
     Z &\leftarrow W/0.2 + \mathcal{N}(0, 0.1)\\
     X &\leftarrow -W - 0.1Z + \mathcal{N}(0, 0.1)\\
     Y &\leftarrow Z- X+ W^2 + \mathcal{N}(0, 0.1)
    \end{align*}
    \vspace{-.7cm}
    \captionof{table}{Synthetic Data 3}
    \vspace{-.2cm}
    \label{tab:synthetic_data3}
	\end{minipage}
\end{table*}

\begin{table*}
\footnotesize
      \vspace{.3cm}
      \centering
     \scalebox{1.00}{
             \begin{tabular}{l|cccc|cccc|cccc}
                \toprule
                \textbf{Feature}&\multicolumn{12}{c}{\textbf{RMSE ($\downarrow$)}}\\
                \midrule
                &\multicolumn{4}{c|}{\textbf{Direct}}&\multicolumn{4}{c|}{\textbf{Indirect}}&\multicolumn{4}{c}{\textbf{Total}}\\
                \midrule
                 &IG& CA & CREDO & Ours &IG& CA & CREDO & Ours&IG& CA & CREDO & Ours \\
                 \midrule
                 \multicolumn{13}{c}{\textbf{Synthetic Data 1}}\\
                \midrule
                W &0.265& 0.070&0.592&0.513&0.869&0.869&0.835&1.114&0.264&0.447&0.226&0.207\\
                Z &0.653& 0.672&0.262&0.502&0.569&0.569&0.804&0.373&0.146&0.462&0.532&0.357\\
                X &0.420& 0.569&0.134&0.389&0.000&0.000&0.229&0.314&0.759&0.279&0.547&0.277\\
                \midrule
                \rowcolor{Gray}
                Average &0.446&0.437&\textbf{0.329}&0.468&0.479&\textbf{0.326}&0.622&0.618&0.389&0.326&0.435&\textbf{0.280}\\
                \midrule
                \multicolumn{13}{c}{\textbf{Synthetic Data 2}}\\
                \midrule
                W &0.656&0.541 &0.798&0.535 &0.571&0.571&0.856&0.534&0.149&0.618&0.510&0.104\\
                Z &0.453&0.510 &0.452&0.465&0.577&0.577&0.678&0.576&0.159&0.268&0.119&0.214\\
                X &0.246&0.547 &0.455&0.547 &0.000&0.000&0.333&0.000&0.584&0.361&0.353&0.359\\
                \midrule
                \rowcolor{Gray}
                Average &0.451&0.533&0.545&\textbf{0.516}&0.382&0.383&0.622&\textbf{0.370}&0.297&0.431&0.327&\textbf{0.226}\\
                \midrule
                \multicolumn{13}{c}{\textbf{Synthetic Data 3}}\\
                \midrule
                W &0.261&0.449 &0.514&0.449&0.574&0.573&0.847&0.006&0.309&0.450&0.189&0.410\\
                Z &0.384&0.527 &0.467&0.575&0.467&0.467&0.782&0.105&0.225&0.385&0.555&0.222\\
                X &0.421& 0.429&0.252&0.578&0.000&0.000&0.202&0.451&0.273&0.164&0.253&0.102\\
                 \midrule
                 \rowcolor{Gray}
                 Average &0.355&\textbf{0.468}&0.469&0.534&0.347&0.347&0.610&\textbf{0.187}&0.269&0.333&0.332&\textbf{0.244}\\

                \midrule
                \textbf{Feature}&\multicolumn{12}{c}{\textbf{Frechet($\downarrow$)}}\\
                \midrule
                \multicolumn{13}{c}{\textbf{Synthetic Data 1}}\\
                 \midrule
                 W&1.000&1.000&1.000&1.000&1.000&1.000&1.000&1.000&0.350&0.038&0.001&0.001\\
                 Z&0.794&0.794&0.425&0.794&1.000&1.000&1.883&0.883&0.386&0.386&0.431&0.386\\
                 X&0.181&1.000&0.295&0.742&0.000&0.000&0.397&0.352&0.336&1.000&0.158&0.584\\
                 \midrule
                  \rowcolor{Gray}Average&0.658&0.931&\textbf{0.573}&0.845&0.667&\textbf{0.667}&1.109&0.745&0.357&0.474&\textbf{0.196}&0.323\\
                  \midrule
                \multicolumn{13}{c}{\textbf{Synthetic Data 2}}\\
                \midrule
                W&1.000&1.000&1.000&1.000&1.000&1.000&1.000&0.922&0.323&1.000&1.000&0.001\\
                Z&0.765&0.765&0.878&0.765&1.000&1.000&0.999&0.992&0.080&0.001&0.111&0.001\\
                X&0.446&0.971&0.971&0.971&0.000&1.000&0.602&0.000&1.000&0.592&0.566&0.592\\
                \midrule
                \rowcolor{Gray}
                 Average&0.737&\textbf{0.912}&0.949&\textbf{0.912}&0.667&0.667&0.867&\textbf{0.638}&0.467&0.531&0.559&\textbf{0.198}\\
                \midrule
                \multicolumn{13}{c}{\textbf{Synthetic Data 3}}\\
                \midrule
                W&0.069&1.000&1.000&1.000&1.000&1.000&0.870&0.011&0.860&1.000&0.283&0.863\\
                Z&0.067&0.071&1.000&1.000&1.000&1.000&1.991&0.003&0.573&0.576&0.708&0.576\\
                X&0.760&0.009&0.145&1.000&0.000&0.000&0.385&1.000&0.685&0.079&0.073&0.079\\
                \rowcolor{Gray} Average&0.298&\textbf{0.360}&0.715&1.000&0.667&0.667&1.082&\textbf{0.338}&0.706&0.551&\textbf{0.354}&0.504\\
                \bottomrule
             \end{tabular}
             }
             \captionof{table}{Results on synthetic datasets. On average, our method performs better than baselines.}
             \label{tab:synthetic_results_appendix}
     \end{table*}
\vspace{-9pt}

\begin{table*}%[14]{r}{0.27\textwidth}
    \centering
    \vspace{-3pt}
    \scalebox{0.95}{
    \begin{tabular}{l|cccc|cccc|cccc}
         \toprule
        \textbf{Feature}&\textbf{IG}&\textbf{CA}&\textbf{CREDO}&\textbf{Ours}&\textbf{IG}&\textbf{CA}&\textbf{CREDO}&\textbf{Ours}&\textbf{IG}&\textbf{CA}&\textbf{CREDO}&\textbf{Ours}\\
        \midrule
        &\multicolumn{4}{c|}{\textbf{Direct}}&\multicolumn{4}{c|}{\textbf{Indirect}}&\multicolumn{4}{c}{\textbf{Total}}\\
        % \midrule
        % \multicolumn{13}{c}{\textbf{Lung Cancer - RMSE($\downarrow$)}}  \\
        % \midrule
        % Asia &&&&&&&&&& 0.961&0.804&0.003\\
        % Tub. &&&&&&&&&&0.426&0.339&0.982\\
        % Smoking &&&&&&&&&& 1.275&1.679&0.932\\
        % L.Cancer &&&&&&&&&&0.678&0.147&0.440\\
        % Bronch. &&&&&&&&&&2.433&3.249&0.773\\
        % Either &&&&&&&&&& 0.443&0.619&0.492\\
        % X-ray &&&&&&&&&&0.138&0.131&0.031\\
        % \midrule
        % \rowcolor{Gray}
        % Average&&&&&&&&&&0.908&0.995&\textbf{0.522}\\
        \midrule
        \multicolumn{13}{c}{\textbf{AUTOMPG - RMSE($\downarrow$)}}  \\
        \midrule
        Cylinders&0.155&0.580&0.570&0.580&0.570&0.570&0.120&0.120&0.155&0.580&0.120&0.120\\
         Disp.&0.545&0.580&0.580&0.580&0.580&0.580&0.000&0.050&0.545&0.580&0.000&0.060\\
         Horsepow.&0.216&0.580&0.580&0.580&0.580&0.580&0.580&0.060&0.216&0.580&0.580&0.060\\
         Weight&0.344&0.010&0.570&0.010&0.570&0.570&0.000&0.070&0.344&0.010&0.000&0.070\\
         Acceler.&0.175&0.580&0.570&0.580&0.570&0.570&0.620&0.330&0.175&0.580&0.620&0.540\\
         \midrule
     \rowcolor{Gray}Average&\textbf{0.286}&0.466&0.574&0.466&0.574&0.574&0.264&\textbf{0.126}&0.286&0.466&0.264&\textbf{0.172}\\
     \midrule
     \multicolumn{13}{c}{\textbf{AUTOMPG - Frechet($\downarrow$)}}  \\
     \midrule
        Cylinders&0.236&1.000&1.000&1.000&1.000&1.000&0.460&0.200&0.236&1.000&0.460&0.210\\
         Disp.&0.985&1.000&1.000&1.000&1.000&1.000&0.000&0.000&0.985&1.000&0.000&0.000\\
         Horsepow.&0.376&1.000&1.000&1.000&1.000&1.000&1.000&0.000&0.376&1.000&1.000&0.000\\
         Weight&0.506&0.000&1.000&0.000&1.000&1.000&0.000&0.000&0.506&0.000&0.000&0.000\\
         Acceler.&0.269&1.000&1.000&1.000&1.000&1.000&1.000&0.450&0.269&1.000&1.000&1.000\\
         \midrule
     \rowcolor{Gray}Average&\textbf{0.474}&0.800&1.000&0.800&1.000&1.000&0.492&\textbf{0.130}&0.474&0.800&0.492&\textbf{0.242}\\
    \bottomrule
    \end{tabular}
    }
    \caption{Direct, indirect, and total causal effects results on AUTOMPG}
    \label{tab:appendixcancerandautompg}
\end{table*}

     
     \begin{table*}
\begin{minipage}{0.48\linewidth}
        \centering
        \includegraphics[width=0.65\linewidth]{images/autompg_dag.png}
        \captionof{figure}{LiNGAM output for AUTOMPG dataset}
        \label{autompg_lingam}
        \vspace{-8pt}
	\end{minipage}
 \begin{minipage}{0.48\linewidth}
        \centering
        \includegraphics[width=0.8\linewidth]{images/asia.png}
        \captionof{figure}{Causal DAG of Lung Cancer dataset}
        \label{asia_dag}
        \vspace{-8pt}
	\end{minipage}
\end{table*}

% \begin{table*}
%     \centering
%     \begin{tabular}{cllllll}
%     \toprule
%     &\multicolumn{6}{c|}{RMSE}
%     \midrule
%          Model &&&&&&  \\
%          $\mathcal{N}$&&&&&&\\
%          $\mathcal{N}^{AH}$&&&&&&\\
%          \midrule
%          &\multicolumn{6}{c|}{Frechet}
%          \midrule
%          Model &&&&&&  \\
%          $\mathcal{N}$&&&&&&\\
%          $\mathcal{N}^{AH}$&&&&&&\\
% \bottomrule
%     \end{tabular}
%     \caption{SACHS results}
%     \label{tab:sachs}
% \end{table*}

\section{Efficient Implementation Strategies}
\label{implementation}
\vspace{-9pt}
In this section, we expound on the strategies to reduce the storage requirements for binning approach (Sec~\ref{sec:improve_time_and_space_complexity} of main paper). The overall approach of online-offline (binning) method is outlined in Figure~\ref{unifiedframework}. Storing offline interventional statistics for every point on the dataset becomes impractical.
This is owing to the multiple dimensions of data required for every point: unrolling length of an RNN, the number of interventional values, and the number of features. Even if storage bottlenecks are not a concern, managing a data structure that can address, log, and access this on-demand becomes tedious and counter-intuitive. So we seek to reduce the number of points, the number of interventions for each point, and amount of data stored per point while maintaining accuracy of online results of incoming points.

We get data clusters so that the cluster centers can be used as a proxy for cluster points so that the number of points to compare with a test data point during the online phase are significantly less. However, the success of clustering methods differs greatly owing to many factors. One important consideration is the distance function used. Euclidean distances are standard and, owing to current experimental hurdles, are used herein experiments. But ideally, a distance metric that depends on the accuracy of the ACE values (entire pipeline from offline to online) is ideal. We seek to find clustering methods on the dataset with a minimum accuracy trade-off while maximizing the number of points clustered, thus reducing storage by the average size of the cluster. We use the following clustering methods in this work.

\noindent \textbf{KD Tree:}
A K-Dimensional (KD) tree is constructed with flattened points so that cluster centroids can be extracted and used for offline computation. Here a hyperparameter is the maximum distance between two points for them to be considered neighbors. Our experiments suggest a Euclidean distance of 10 is ideal, but a roll-off till 20 is still acceptable.

\noindent \textbf{DBSCAN:}
Since the nature and shape of the clusters are unknown, we can use DBSCAN to get a density-based estimate, where points too sparsely connected to an existing cluster would be considered as outliers. This adds another hyperparameter apart from the maximum distance called minimum points, that quantifies the number of nearby points needed to consider it as a cluster. This allows us to have a handle on the storage requirements but setting this value too high results in many points being outliers without a cluster.

\noindent \textbf{Complexity Analysis in RNNs}
In RNNs, the number of steps to unroll the network, call the \textit{chunk} size, impacts the dataset size when we collect data from a stream. From a data stream, we split the dataset such that chunks are overlapping sub-sequences i.e., if the length of a stream is $l$ and chunk size is $k$, we get approximately $l-k$ chunks in total. Evaluating Eqn~\ref{eq: ACE} takes order of $\mathcal{O}(l\times n^p)$ time (assuming $k<<l$ and features are $p$-valued, $n$ is the of input size). On the other hand, evaluating the approximation in Equation~\ref{expected taylor expansion eq} also scales in the order of $\mathcal{O}(kn)$ as the inputs at a particular time step affect the inputs at the next time step in RNNs~\cite{causalattributions}. In RNNs, interventional statistics caluation take considerable time as these steps have to be done for every feature in the data point, at every time step starting from $t$ to 1, where $t$ is the time step at which we wish to calculate the causal effect, which would take considerable time.

\begin{figure}%[15]{r}{0.5\textwidth}
    \centering
    \vspace{-5pt}
    \includegraphics[width=0.5\textwidth]{images/EAIFramework.png}
    \caption{Binnig (offline - online) framework for quick and accurate explainability}
    \label{unifiedframework}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{images/grid.png}
    \caption{Results on binning approximation to causal attributions for time series data}
    \label{fig:binning_results}
\end{figure}
\section{Related Work on Concept Based Explanations}
Concept-based explanation models attempt to explain an NN behavior in terms of semantically meaningful concepts in the input when the input is not readily expressed as a discrete set of concepts. Concept bottleneck models~\citep{cbmodels}, and concept embedding models~\citep{cemodels} learn the relationship between manually annotated concepts in the input samples and the model predictions.
% so that apart from having an interpretation for the prediction the predicted concept probabilities at test time can be manually intervened upon to improve test accuracy. 
Linguistic concept-based explanation models such as~\citep{flexmodel,ccnngc} try to automatically discover semantically meaningful concepts in the input space by leveraging text annotations corresponding to the inputs and using them to explain model predictions. Other methods like TCAV~\citep{tcav} can be used as a post hoc method to explain model predictions in terms of arbitrary concepts that may exist in the input samples but not known at the time of training. ~\citep{eecv18} is a method to decompose the input samples into semantically interpretable concepts derived from a pre-trained concept corpus. However, as discussed earlier, when the number of concepts is more, evaluating the causal attributions is time-consuming.