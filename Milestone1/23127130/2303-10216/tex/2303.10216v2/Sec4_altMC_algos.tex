\section{Accelerated Monte Carlo sampling with precomputations}\label{sec::altMC_algos}

The algorithms presented in Section \ref{sec::MC_theory} on estimating explainers all contain parts that require real-time sampling (of coalitions $A\subseteq M$ and $S\subseteq N$) and repeated calls to the model $f$. One way of reducing the computation time of these algorithms is to separate out the sampling part and have it be executed as a precomputation step. The result of the precomputation can then be passed as an input to the computation step, which would execute the averaging of the MC iterates preferably in a manner that minimizes the number of model calls.

The idea of incorporating a precomputation step to generate and store samples for the MC iterations, while it is sound, may not always be feasible. To understand why, consider Algorithm \ref{algo_game_marg}. Observe that for each feature $i\in\{1,\dots,n\}$, $K=|\bar{D}_X|$ samples of coalitions must be generated (where each coalition is stored as a vector of zeroes and ones of size $n$), which means that the total memory required to store all $n$ matrices of coalition samples is $O(n^2 \cdot K)$ bytes. This can become exceedingly large if the number of features $n$ and MC samples $K$ are large.

To address this issue, we propose a methodology that allows us to reduce the number of stored matrices from $n$ to $1$, which will decrease the runtime of the precomputation and the memory required for storage. In order to accomplish this, one has to reformulate the linear game value \eqref{lingamevalue} so that the summation does not depend on the index $i$. In other words, we shift the sampling procedure from one based on $P_i^{(h)}$ to a probability distribution independent of $i$, which in turn allows us to generate only one set of coalition samples and use that to generate explanations for every feature $i \in N$.


\medskip
\noindent {\bf Accelerated-MC sampling for Shapley values.}

We showcase  the algorithm for the Shapley value \eqref{shapform} and then explain how these calculations can be extended to any linear game value; see Remark \ref{fastmc_extension}.

\begin{lemma}
    Define $P^{(\varphi)}(\{S\}) = \frac{1}{n}\frac{s!(n-s)!}{n!}$ on the space $\Omega = \{S:S\subsetneq N\}$, $s = |S|$, $n=|N|$. Then $P^{(\varphi)}(\Omega) = 1$ and for any game $(N,v)$
    \begin{equation}\label{altshapform}
        \varphi_i[N,v] = \int \left[\left(\frac{|N|}{|N|-|S|}\right) \left(v(S \cup \{i\}) - v( S )\right) \right]\,P^{(\varphi)}(dS), \quad i\in N.
    \end{equation}
\end{lemma}

\begin{proof}
    $P^{(\varphi)}$ defines a probability measure on $\Omega$. For any $S\in \Omega$, $P^{(\varphi)}(\{S\})$ is nonnegative and

    \begin{equation*}
        \begin{aligned}
        P^{(\varphi)}(\Omega) &= \sum_{S\in \Omega}P^{(\varphi)}(\{S\}) = \sum_{S\subsetneq N} \frac{1}{n}\frac{s!(n-s)!}{n!} = \sum_{S\subsetneq N} \frac{1}{n}\binom{n}{s}^{-1} = \sum_{\gamma=0}^{n-1}\sum_{S\subsetneq N,|S|=\gamma} \frac{1}{n}\binom{n}{\gamma}^{-1}\\
        &= \sum_{\gamma=0}^{n-1} \frac{1}{n}\binom{n}{\gamma}^{-1}\hspace{-10 pt} \sum_{S\subsetneq N,|S|=\gamma} 1 = \sum_{\gamma=0}^{n-1} \frac{1}{n}\binom{n}{\gamma}^{-1}\binom{n}{\gamma} = \sum_{\gamma=0}^{n-1} \frac{1}{n} = 1.
        \end{aligned}
    \end{equation*}
Furthermore, the Shapley value can be rewritten as an integral with respect to $P^{(\varphi)}$ as follows.
    \begin{equation*}
        \begin{aligned}
            \varphi_i[N,v] &= \sum_{S \subseteq N \backslash\{i\}} \frac{s!(n-s-1)!}{n!} [ v(S \cup \{i\}) - v( S ) ] = \sum_{S \subsetneq N} \frac{1}{n}\frac{s!(n-s)!}{n!} \left[\left(\frac{n}{n-s}\right) \left(v(S \cup \{i\}) - v( S )\right) \right]\\
            &= \int \left[\left( \frac{|N|}{|N|-|S|}\right) \left(v(S \cup \{i\}) - v( S )\right) \right]\,P^{(\varphi)}(dS).
        \end{aligned}
    \end{equation*}
\end{proof}


Notice that in \eqref{altshapform} the only dependence on the index $i$ is in the term $v(S\cup i)$. The coalitions $S$ are now independent of $i$ since we are considering proper subsets of $N$ and not subsets of $N\setminus \{i\}$. Practically, this has the implication that one can sample coalitions and reuse them to estimate $\varphi_i[N,v]$ for all $i\in N$. Algorithms \ref{algo_pre_fastmc_shapley} and \ref{algo_comp_fastmc_shapley} describe the precomputation and computation steps, respectively, where the former generates and stores the sampled coalitions and the coefficients $\frac{n}{n-s}$, and the latter simply loads that stored information and produces the MC estimate of $\varphi[N,\vpdp]$.

\begin{algorithm}
    \SetAlgoLined 
    \KwIn{Dataset $\bar{D}_X=\{x^{(k)}\}_{k=1}^K$.}
    \KwOut{Matrix $C$ and vector $w$.}
    \BlankLine
    Initialize a zero matrix $C$ of size $K\times n$;\\
    Initialize a zero vector $w$ of length $K$;\\
    \For{$k$ in $\{1,\dots,K\}$} 
    {
        Pick $r_k$ from the set $\in \{0,1,\dots,n-1\}$ uniformly at random;\\
        Randomly generate a logical array $c_k$ of length $n$ such that $\sum_{\ell=1}^n c_k[\ell] = r_k$;\\
        Set $C[k,\cdot] = c_k$;\\
        Set $w[k] = \frac{n}{n-r_k}$;\\
    }
    \Return{$C$ and $w$;}
\caption{Precomputation step of Accelerated-MC sampling for marginal Shapley values}
\label{algo_pre_fastmc_shapley}
\end{algorithm}

\begin{algorithm}
    \SetAlgoLined 
    \KwIn{Observation $x^*\in \R^n$, model $f$, dataset $\bar{D}_X=\{x^{(k)}\}_{k=1}^K$, matrix $C$ and vector $w$ from Algorithm \ref{algo_pre_fastmc_shapley}.
    }
    \KwOut{MC estimate $\hat{\varphi}=\{\hat{\varphi}\}_{i=1}^n$ of $\varphi[N,\vpdp]$.}
    \BlankLine
    Initialize a zero vector $\hat{\varphi}$ of length $n$;\\
    Set $X_{synth} = x^* \cdot C + \bar{D}_X\cdot (1-C)$;\\
    \Comment*[h]{$/^*$ Both multiplications in line 2 are component-wise. In the former, every row of $C$ is multiplied component-wise with $x^*$, creating a matrix with the same size as $C$ $^*/$}\\
    Set $X_{synth,copy} = copy(X_{synth})$;\\
    Evaluate $f_{synth} = f(X_{synth})$;\\
    \For{$i$ in $\{1,\dots,n\}$}
    {
        Set $X_{synth,copy}[\cdot,i] = x^*[i]$;\\
        Evaluate $f_{synth,i} = f(X_{synth,copy})$;\\
        Reset $X_{synth,copy}[\cdot,i] = X_{synth}[\cdot,i]$;\\
        \For{$k$ in $\{1,\dots,K\}$ such that $C[k,i]=0$}
        {
            Evaluate $\hat{\varphi}_i = \hat{\varphi}_i + w[k](f_{synth,i}[k] - f_{synth}[k])$;\\
        }
        Set $\hat{\varphi}_i = \hat{\varphi}_i/K$;\\
    }
    \Return{$\hat{\varphi} = (\hat{\varphi}_1,\dots,\hat{\varphi}_n)$;}
\caption{Computation step of Accelerated-MC sampling for marginal Shapley values}
\label{algo_comp_fastmc_shapley}
\end{algorithm}

\begin{remark}\rm\label{fastmc_extension}
To extend the Accelerated-MC sampling to any linear game value of the form \eqref{lingamevalue}, suppose that the coefficient $w_i(S,N)$ is renormalized to $w'_i(S,N) = c(S,N)w_i(S,N)$ so that $\sum_{S\subsetneq N}w'_i(S,N) = 1$. Then the term $v(S\cup \{i\}) - v(S)$ is multiplied by $c(S,N)^{-1}$. To generalize Algorithm \ref{algo_pre_fastmc_shapley} to any linear game value, notice that lines $4-5$ define the distribution of 1's in the logical array $c_k$ based on the probability $\frac{1}{n}\frac{r_k!(n-r_k)!}{n!}$ (the coefficient of the reformulated Shapley value \eqref{altshapform}), where $r_k$ specifies the number of 1's in the array. Thus, in the general case, these lines should be changed so that the distribution of 1's in $c_k$ is based on the probability $w'_i(S,N)$. Furthermore, line 7 should change to $w[k] = c(S,N)^{-1}$. No modifications are required in Algorithm \ref{algo_comp_fastmc_shapley}.
\end{remark}

\begin{remark}\rm
Note that $v(S \cup \{i\})-v(S)=0$ if $i \in S$. Thus, the difference of functions in line $10$ of Algorithm \ref{algo_comp_fastmc_shapley} has to be computed only for  those samples of coalitions which do not contain $i$.
\end{remark}

\begin{remark}\rm
    As with the previous algorithms presented in Section \ref{sec::MC_theory}, Algorithms \ref{algo_pre_fastmc_shapley} and \ref{algo_comp_fastmc_shapley} can be adjusted to estimate the Shapley values for the empirical marginal game $\hat{v}^{\ME}$ (based on the dataset $\bar{D}_X$) by sampling with replacement from $\bar{D}_X$, creating a new dataset $\tilde{D}$. Using this set as an input to the algorithms instead of $\bar{D}_X$ yields the estimate.
\end{remark}

\begin{remark}\rm
    The benefit of having precomputed samples is that in Algorithm \ref{algo_comp_fastmc_shapley} the input to the model $f$ can be the entire matrix of samples, which minimizes the call to the function. The mutliple function calls for each sample is the main bottleneck in the algorithms presented in Section \ref{sec::MC_theory}.
\end{remark}

\medskip
\noindent {\bf Accelerated-MC sampling for Owen values.} Next, we adapt the ideas above to the Owen value \eqref{OwenandBzOw} to produce sampling algorithms with a precomputation and computation step, respectively. The calculations again can be extended to any coalitional value of the form \eqref{coalvalform}; see Remark \ref{fastmc_extension_owen}.

\begin{lemma}
    Define $P_j^{(Ow,\cP)}(\{(R,T)\}) = \frac{1}{m}\frac{r!(m-r)!}{m!}\cdot \frac{1}{s_j}\frac{t!(s_j-t)!}{s_j!}$ on $\Omega_j^{\cP} = \{(R,T):R\subsetneq M,\ T\subsetneq S_j\}$, where $S_j \in \cP = \{S_1,\dots,S_m\}$, $s_j = |S_j|$, $r=|R|$ and $t=|T|$. Then $P_j^{(Ow,\cP)}(\Omega_j^{\cP}) = 1$ and for any coalitional game $[N,v,\cP]$ and $i\in S_j$
    \begin{equation}\label{altowenform}
        Ow_i[N,v,\cP] = \int \left[\left(\frac{|M|}{|M|-|R|}\frac{|S_j|}{|S_j|-|T|}\right) \left(v(Q_R \cup T \cup \{i\}) - v( Q_R \cup T )\right) \right]\,P_j^{(Ow,\cP)}(dR,dT),
    \end{equation}
    where $Q_R = \cup_{\alpha \in R}S_{\alpha}$ and $M=\{1,2,\dots,m\}$.
\end{lemma}

\begin{proof}
    Given $j\in M$ and a partition $\cP$, $P_j^{(Ow,\cP)}$ defines a probability measure on $\Omega_j^{\cP}$. For any $(R,T)\in \Omega_j^{\cP}$, $P_j^{(Ow,\cP)}(\{(R,T)\})$ is nonnegative and

    \begin{equation*}
        \begin{aligned}
        P_j^{(Ow,\cP)}(\Omega_j^{\cP}) &= \sum_{(R,T)\in \Omega_j^{\cP}}P_j^{(Ow,\cP)}(\{R,T\}) = \sum_{R\subsetneq M}\sum_{T\subsetneq S_j} \frac{1}{m}\frac{r!(m-r)!}{m!}\cdot \frac{1}{s_j}\frac{t!(s_j-t)!}{s_j!}\\
         &= \sum_{R\subsetneq M}\sum_{T\subsetneq S_j} \frac{1}{m}\binom{m}{r}^{-1} \frac{1}{s_j}\binom{s_j}{t}^{-1} = \frac{1}{m s_j} \left(\sum_{R\subsetneq M} \binom{m}{r}^{-1}\right) \left(\sum_{T\subsetneq S_j}\binom{s_j}{t}^{-1}\right)\\
        &= \frac{1}{m s_j} \left(\sum_{\gamma=0}^{m-1}\sum_{R\subsetneq M,|R|=\gamma} \binom{m}{\gamma}^{-1}\right) \left(\sum_{\zeta=0}^{s_j-1}\sum_{T\subsetneq S_j,|T|=\zeta}\binom{s_j}{\zeta}^{-1}\right)\\
        &= \frac{1}{m s_j} \left(\sum_{\gamma=0}^{m-1}\binom{m}{\gamma}^{-1}\binom{m}{\gamma}\right) \left(\sum_{\zeta=0}^{s_j-1}\binom{s_j}{\zeta}^{-1}\binom{s_j}{\zeta}\right) = 1.
        \end{aligned}
    \end{equation*}
Furthermore, the Owen value $Ow_i[N,v,\cP]$ for $i\in S_j$ can be rewritten as an integral with respect to $P_j^{(Ow,\cP)}$ as follows.
    \begin{equation*}
        \begin{aligned}
            Ow_i[N,v,\cP] &= \sum_{R\subseteq M\setminus \{j\}}\sum_{T\subseteq S_j\setminus \{i\}} \tfrac{|R|!(|M|-|R|-1)!}{|M|!}\tfrac{|T|!(|S_j|-|T|-1)!}{|S_j|!} \left[ v(Q_R \cup T \cup \{i\}) - v(Q_R \cup T) \right]\\
            &= \sum_{R\subsetneq M}\sum_{T\subsetneq S_j} \tfrac{1}{|M|}\tfrac{|R|!(|M|-|R|)!}{|M|!}\tfrac{1}{|S_j|}\tfrac{|T|!(|S_j|-|T|)!}{|S_j|!} \left(\tfrac{|M|}{|M|-|R|}\tfrac{|S_j|}{|S_j|-|T|}\right) \left[v(Q_R \cup T \cup \{i\}) - v(Q_R \cup T)\right]\\
            &= \int \left[\left(\frac{|M|}{|M|-|R|}\frac{|S_j|}{|S_j|-|T|}\right) \left(v(Q_R \cup T \cup \{i\}) - v( Q_R \cup T )\right) \right]\,P_j^{(Ow,\cP)}(dR,dT).
        \end{aligned}
    \end{equation*}
\end{proof}

Notice that in \eqref{altowenform} the sampling of the set $T \subsetneq S_j$ depends on the index $j$. Due to the nature of coalitional values the dependence on $S_j$ cannot be fully removed from the second summation. Practically, this has the implication that one can sample coalitions of unions $Q_R$ and reuse them to estimate $Ow_i[N,v,\cP]$ for all $i\in N$. However, separate samples of coalitions $T$ must be generated for each group $S_j$, $j\in M$. Algorithms \ref{algo_pre_fastmc_owen} and \ref{algo_comp_fastmc_owen} describe the precomputation and computation steps, respectively, where the former generates and stores the sampled coalitions of unions, the sampled coalitions of predictor indices for each group, and the coefficients $\frac{m}{m-r}\cdot \frac{s_j}{s_j-t}$. The latter algorithm simply loads that stored information and produces the MC estimate of $Ow[N,\vpdp,\cP]$.

\begin{algorithm}
    \SetAlgoLined 
    \KwIn{Partition $\cP=\{S_1,\dots,S_m\}$, dataset $\bar{D}_X=\{x^{(k)}\}_{k=1}^K$.
    }
    \KwOut{Matrices $\{C_i\}_{i=1}^m$ and $W$.
    }
    \BlankLine
    Initialize a zero matrix $R$ of size $K\times m$;\\
    Initialize a zero matrix $A$ of size $m\times n$;\\
    Initialize a zero matrix $W$ of size $m\times K$;\\    
    \For{$k$ in $\{1,\dots,K\}$}
    {
        Pick $q_k$ from the set $\in \{0,1,\dots,m-1\}$ uniformly at random;\\
        Randomly generate a logical array $r_k$ of length $m$ such that $\sum_{\ell=1}^m r_k[\ell] = q_k$;\\
        Set $R[k,\cdot] = r_k$;\\
    }
    \For{$j$ in $\{1,\dots,m\}$}
    {
        Set $A[j,S_j] = 1$;\\
        Initialize a zero matrix $T_j$ of size $K\times |S_j|$;\\
        \For{$k$ in $\{1,\dots,K\}$}
        {
            Pick $d_k$ from the set $\in \{0,1,\dots,|S_j|-1\}$ uniformly at random;\\
            Randomly generate a logical array $t_k$ of length $|S_j|$ such that $\sum_{\ell=1}^{|S_j|} t_k[\ell] = d_k$;\\
            Set $T_j[k,\cdot] = t_k$;\\
        }
    }
    Set $Q = RA$ (matrix multiplication);\\
    \For{$j$ in $\{1,\dots,m\}$}
    {
        Set $C_j = Q$;\\
        Set $C_j[\cdot, S_j] = Q[\cdot, S_j] + T_j$;\\
        Set any element of $C_j$ that is greater than $1$ equal to $1$;\\
        \For{$k$ in $\{1,\dots,K\}$}
        {
            Set $W[j,k] = \frac{m}{m-\sum_{\ell=1}^m R[k,\ell]}\cdot \frac{|S_j|}{|S_j| - \sum_{\ell=1}^{|S_j|} T_j[k,\ell]}$;\\
        }
    }
    \Return{$\{C_j\}_{j=1}^m$ and $W$;}
\caption{Precomputation step of Accelerated-MC sampling for marginal Owen values}
\label{algo_pre_fastmc_owen}
\end{algorithm}

\begin{algorithm}
    \SetAlgoLined 
    \KwIn{Observation $x^*\in \R^n$, model $f$, partition $\cP=\{S_1,\dots,S_m\}$, dataset $\bar{D}_X=\{x^{(k)}\}_{k=1}^K$, matrices $\{C_j\}_{j=1}^m$ and $W$ from Algorithm \ref{algo_pre_fastmc_owen}.
    }
    \KwOut{MC estimate $\hat{Ow}=\{\hat{Ow}_i\}_{i=1}^n$ of $Ow[N,\vpdp,\cP]$.
    }
    \BlankLine
    Initialize a zero vector $\hat{Ow}$ of length $n$;\\
    \For{$j$ in $\{1,\dots,m\}$}
    {
        Set $X_{synth} = x^* \cdot C_j + \bar{D}_X\cdot (1-C_j)$;\\
        \Comment*[h]{$/^*$ Both multiplications in line 3 are component-wise. In the former, every row of $C_j$ is multiplied component-wise with $x^*$, creating a matrix with the same size as $C_j$ $^*/$}\\
        Set $X_{synth,copy} = copy(X_{synth})$;\\
        Evaluate $f_{synth} = f(X_{synth})$;\\
        \For{$i$ in $S_j$}
        {
            Set $X_{synth,copy}[\cdot,i] = x^*[i]$;\\
            Evaluate $f_{synth,i} = f(X_{synth,copy})$;\\
            Reset $X_{synth,copy}[\cdot,i] = X_{synth}[\cdot,i]$;\\
            \For{$k$ in $\{1,\dots,K\}$ such that $C_j[k,i]=0$}
            {
                Evaluate $\hat{Ow}_i = \hat{Ow}_i + W[j,k](f_{synth,i}[k] - f_{synth}[k])$;\\
            }
            Set $\hat{Ow}_i = \hat{Ow}_i/K$;\\
        }
    }
    \Return{$\hat{Ow} = (\hat{Ow}_1,\dots,\hat{Ow}_n)$;}
\caption{Computation step of Accelerated-MC sampling for marginal Owen values}
\label{algo_comp_fastmc_owen}
\end{algorithm}

\begin{remark}\rm\label{fastmc_extension_owen}
    To extend the Accelerated-MC sampling to any coalitional value of the form \eqref{coalvalform}, suppose that the coefficient is renormalized to $w'_i(A,M,T,S_j) = c^{(1)}(A,M)w_j^{(1)}(A,M)c^{(2)}(T,S_j)w_i^{(2)}(T,S_j)$ so that $\sum_{A\subsetneq M}c^{(1)}(A,M)w_j^{(1)}(A,M) = \sum_{T\subsetneq S_j}c^{(2)}(T,S_j)w_i^{(2)}(T,S_j) = \sum_{A\subsetneq M}\sum_{T\subsetneq S_j}w'_i(A,M,T,S_j) = 1$. Then the term $v(Q_A\cup T\cup \{i\}) - v(Q_A\cup T)$ is multiplied by $(c^{(1)}(A,M)c^{(2)}(T,S_j))^{-1}$. Similar to Remark \ref{fastmc_extension}, to generalize Algorithm \ref{algo_pre_fastmc_owen} to any coalitional value, lines $5-6$ should be changed so that the distribution of 1's in $r_k$ is based on the probability $c^{(1)}(R,M)w_j^{(1)}(R,M)$, and lines $13-14$ should be changed so that the distribution of 1's in $t_k$ is based on the probability $c^{(2)}(T,S_j)w_i^{(2)}(T,S_j)$. Furthermore, line $24$ should change to $W[j,k] = (c^{(1)}(R,M)c^{(2)}(T,S_j))^{-1}$. No modifications are required in Algorithm \ref{algo_comp_fastmc_owen}.
\end{remark}

\begin{remark}\rm
    As with the previous algorithms, Algorithms \ref{algo_pre_fastmc_owen} and \ref{algo_comp_fastmc_owen} can be adjusted to estimate the Owen value for the empirical marginal game $\hat{v}^{\ME}$ (based on the dataset $\bar{D}_X$) by sampling with replacement from $\bar{D}_X$, creating a new dataset $\tilde{D}$. Using this set as an input to the algorithms instead of $\bar{D}_X$ yields the estimate.
\end{remark}
