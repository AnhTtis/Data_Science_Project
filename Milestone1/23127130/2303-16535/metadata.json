{
    "arxiv_id": "2303.16535",
    "paper_title": "Nonlinear Independent Component Analysis for Principled Disentanglement in Unsupervised Deep Learning",
    "authors": [
        "Aapo Hyvarinen",
        "Ilyes Khemakhem",
        "Hiroshi Morioka"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-03-30"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "stat.ML"
    ],
    "abstract": "A central problem in unsupervised deep learning is how to find useful representations of high-dimensional data, sometimes called \"disentanglement\". Most approaches are heuristic and lack a proper theoretical foundation. In linear representation learning, independent component analysis (ICA) has been successful in many applications areas, and it is principled, i.e. based on a well-defined probabilistic model. However, extension of ICA to the nonlinear case has been problematic due to the lack of identifiability, i.e. uniqueness of the representation. Recently, nonlinear extensions that utilize temporal structure or some auxiliary information have been proposed. Such models are in fact identifiable, and consequently, an increasing number of algorithms have been developed. In particular, some self-supervised algorithms can be shown to estimate nonlinear ICA, even though they have initially been proposed from heuristic perspectives. This paper reviews the state-of-the-art of nonlinear ICA theory and algorithms.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16535v1"
    ],
    "publication_venue": null
}