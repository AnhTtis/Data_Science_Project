\section{Conclusion}

We have designed a protocol that allows for a quantitative study of the impact of explanations on users' choices in item recommendation.
Key elements of this design include preference elicitation that allows for the generation of personalized recommendations, manual identification and extraction of item aspects to include in explanations, a controlled way of introducing bias via the combination of both positive and negative aspects, and the presentation of explanations in two different textual formats.
We have conducted a user study and showed that explanations can indeed have a large effect on the item selections that people make, and that these findings generalize across the two explanation formats.
The results have also yielded some unexpected findings that warrant further investigation in future work.
We also plan to conduct a more detailed statistical analysis of the results and perform qualitative evaluation based on post-survey responses.
Further, the differences in terms of absolute impact between itemized and fluent natural language explanations suggest that the specific wording of the latter might play a role.  Measuring whether slight differences in phrasing have an impact is an interesting topic for future research.
Finally, we focused on movie recommendations, yet our approach is generalizable to other domains where users rely on automatic suggestions due to the size of the item collection (e.g., books, music, recipes). It would be interesting to repeat the experiment in other domains.
