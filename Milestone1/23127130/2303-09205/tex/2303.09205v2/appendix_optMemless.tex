\section{Optimal memory-less algorithm}\label{appendix:optMemless}


\subsection{First properties of memory-less algorithms}\label{appx:memless}
This section presents several properties of memory-less algorithms that will be utilized to derive the optimal algorithm by the mean of dynamic programming.

In the following proposition we demonstrate that if a memory-less algorithm $\A$ does not halt at candidate $x_{t-1}$ and moves to step $t$, then knowing the available budget $B_{t}$ and the number of candidates in each group up to that point, its success probability is independent of all the past observations and actions. In other words, the state of the algorithm at step $t$ is fully determined by the triplet $(B_t, N^1_t, N^2_t)$, independently of the relative ranks of the past candidates and of their groups.
Let us assume for simplicity that the randomness in $\act_{t, 1}, \act_{t, 2}$ knowing $\F_{t-1}$ is due to some random noise $\xi_{t,1}, \xi_{t,2}$ independent of all the rest.

\begin{proposition}\label{prop:success-memless-skip}
Let $\A$ be a memory-less algorithm with stopping time $\tau$. Let $2 \leq t \leq N$ and $\F_t$ be the history of the algorithm up to $t$, then we have
\[
\Prob(\A \text{ succeeds} \mid \tau \geq t, \F_{t-1}) = \Prob(\A \text{ succeeds} \mid \tau \geq t, B_{t}, N^1_{t-1})\enspace,
\]
Where $B_t$ is the budget available at time $t$ and $N^1_{t-1} \eqdef |G^1_{t-1}|$.
\end{proposition}

\begin{proof}
We first show that the following claims hold
\begin{enumerate}[label=(\roman*)]
\item $\Prob(R_t = 1 \mid \F_{t-1}) = \frac{1}{t}$,
\item knowing $(g_t, N^1_{t-1})$, the distribution of $r_t$ is independent of $\F_{t-1}$,
\item if $s \geq t$ then $\act_{s,1}$ is measurable with respect to $(N^1_{t-1},B_t,\{ g_u, r_u, \xi_{u,1} \}_{u=t}^{s})$.
\end{enumerate} 
\textbf{(i)} 
We remind that 
$\F_{t-1} = \{r_s,g_s, \act_{s, 1}, R_s\indic{\act_{s, 1} = \acomp}, \act_{s, 2}\indic{\act_{s, 1} = \acomp}\}_{s=1}^{t-1}$. Since the distributions of $\act_{s, 1}, \act_{s, 2}$ are measurable with respect to $\{r_s,R_s,g_s\}_{s=1}^{t-1}$, we only need to show the independence between $R_t$ and the past observations.\\  
We have that $\{R_t = 1\} = \{x_t > \max\{x_s\}_{s=1}^{t-1}\}$, this event is independent of the groups of the past candidates, and by Proposition \ref{prop:max2sets} it is also independent of their relative ranks, therefore $R_t$ is independent of $\F_{t-1}$ and 
$\Prob(R_t = 1 \mid \F_{t-1}) = \Prob(R_t = 1)
=\frac{1}{t}$.\\
\textbf{(ii)}
We only need to show the independence between $r_t$ and the past observations conditionally to $(g_t, N^1_{t-1})$. 
Knowing $G^1_t$, we have that $r_t$ is independent of the relative ranks of $\{x_1, \ldots, x_{t-1}\}$ by Proposition \ref{prop:max2sets}, thus it is independent of $\{r_s\}_{s<t}, \{R_s\}_{s<t}$. We also have by  Proposition \ref{prop:max2sets} that knowing $(g_t, N^1_{t-1})$, the probability of $\{r_t = 1\}$ is $1/N^{g_t}_t$ independently of $G^1_t$, where 
\[
N^{g_t}_t = \indic{g_t = 1}(N^1_{t-1} +1) + (1- \indic{g_t = 1})(t - N^1_{t-1}),
\]
hence knowing $(g_t, N^1_{t-1})$,$r_t$ is independent of $\{r_s,R_s,g_s\}_{s=1}^t$, thus independent of $\F_{t-1}$. \\
\textbf{(iii)} We will prove the claim by induction. For $s=t$ it is true because $\A$ is memory-less. Assume that it is true up to some $s \geq t$. Thus $A_{s+1,1}$ is $(N^1_{s-1}, B_{s+1}, g_{s+1}, r_{s+1}, \xi_{s+1,1})-$measurable, and we have
\[
N^1_{s} = N^1_{t-1} + \sum_{u=t}^s \indic{g_t = 1}, \qquad
B_{s+1} = B_t - \sum_{u=t}^{s} \indic{\act_{u, 1} = \acomp},
\]
$N^1_{s}$ is, therefore, $(N^1_{s}, \{g_u\}_{u=t}^s)$-measurable and $B_{s+1}$ is $(B_t,\{ \act_{u, 1} \}_{t \leq u\leq s})$-measurable, using the induction hypothesis we deduce that it is measurable with respect to $(N^1_{t-1}, B_t,\{ g_u, r_u, \xi_{u,1} \}_{u=t}^{s})$, and thus the result.

We will now prove the proposition. Let $t^\star$ be the position of the best candidates overall,
\[
\Prob(\A \text{ succeeds} \mid \tau \geq t, \F_{t-1}) 
= \Prob(\tau = {t^\star} \mid \tau \geq t, \F_{t-1}) 
= \E_T \left[ 
        \Prob(\tau = {t^\star} \mid \tau \geq t, \F_{t-1}, {t^\star}) 
    \right],
\]
if ${t^\star} < t$ then $\Prob(\A \text{ succeeds} \mid \tau \geq t, \F_{t-1}, T) = 0$, otherwise this probability only depends on the future actions of $\A$, because conditionally to $\{ \tau \geq t\}$, we have that 
\[
\tau = \min \{s \geq t \mid \act_{s, 1} = \astop \text{ or } \act_{s, 2} = \astop \}.
\]
Conditionally to $(N^1_{t-1}, B_t)$, we have that the distributions of $\{\act_{s, 1}, \act_{s, 2}\}_{s \geq t}$ are measurable with respect to $\{g_u, r_u, R_u\}_{u=t}^s$. The variables $\{g_u\}_{u \geq t}$ are independent of $\F_{t-1}$, and $\{r_u, R_u\}_{u \geq t}$ are also independent of $\F_{t-1}$ knowing $(N^1_{t-1}, B_t)$, hence $\{\act_{s, 1}, \act_{s, 2}\}_{s \geq t}$ are independent of $\F_{t-1}$ and thus the result.
\end{proof}




The following proposition states that when a memory-less stops at some step $t$, then we can express its success probability as a function of $(r_t,g_t,R_t,N^1_t)$.

\begin{proposition}\label{prop:success-memless-stop}
Under the same assumptions of the last proposition, we have
\begin{align*}
\Prob(\A \text{ succeeds} \mid \act_{t, 1} = \astop, r_t, g_t, B_t, N^1_t) 
&= \indic{r_t = 1}\frac{ N^{g_t}_t}{N},
\\
\Prob(\A \text{ succeeds} \mid \act_{t, 2} = \astop, r_t, g_t, B_t, N^1_t, R_t) 
&= \indic{R_t = 1}\frac{t}{N}.
\end{align*}
\end{proposition}

\begin{proof}
Let us denote $t^\star$ the position of the best candidate overall. Conditionally to $\act_{t,1} = \astop$, we have $\{ \A \text{ succeeds} \}= \{ t^\star = t \}$. If $r_t \neq 1$ then with probability 1 we have $t^\star \neq t$, and if $r_t = 1$, then the only information about the rank of $x_t$ contained in $r_t, g_t, B_t, N^1_t$ is that $x_t$ is better than all the past candidates of $G^{g_t}$, i.e that it is the best among a collection of $N^{g_t}_t$ candidates, which happens with probability $1/N^{g_t}_t$. The success probability is therefore
\begin{align*}
\Prob(\A \text{ succeeds} \mid \act_{t, 1} = \astop, r_t=1, g_t, B_t, N^1_t)
&= \Prob(t^\star = t \mid \act_{t, 1} = \astop, r_t=1, g_t, B_t, N^1_t)\\
&= \Prob(t^\star = t \mid  r_t=1, g_t, N^1_t)\\
&= \frac{\Prob(t^\star = t \mid  g_t, N^1_t)}{\Prob(r_t=1 \mid g_t, N^1_t)}
= \frac{N^{g_t}_t}{N},
\end{align*}
which means that it is null when $r_t \neq 1$ and equal to $N^{g_t}_t/N$ otherwise.

If $\act_{t, 2} = \astop$, then necessarily $(\act_{t, 1} = \acomp)$ and $R_t$ is known. If $R_t \neq 1$ then $\Prob(t^\star = t \mid \act_{t, 2} = \astop, R_t \neq 1, \F_t) = 0$, otherwise $R_t = 1$, implying that $r_t = 1$, thus $R_t = 1$ is the maximal information that we get from all the past on the absolute rank of $x_t$, thus 
\[
\Prob(\A \text{ succeeds} \mid \act_{t, 2} = \astop, R_t = 1)
= \Prob(t^\star = t \mid R_t = 1)
= \frac{t}{N}.
\]
\end{proof}





\subsection{Optimal algorithm via dynamic programming: Proofs of Section \ref{sec:opt-dynprog}}\label{appx:opt-dynprog}
Let $\A$ be a memory-less algorithm. To make the presentation lighter, we will denote, unlike in the statement of the proposition, $(\rwd^b_{t,m}(\A))_{t,m,b}$ the table defined by
\[
\rwd^b_{t,m}(\A)
\eqdef \Prob(\A \text{ succeeds} \mid \tau \geq t, B_t = b, N^1_{t-1} = m)\enspace,
\]
and we will prove that it is upper bounded by that defined in Proposition \ref{prop:dynprogb}, which is $\rwd^b_{t,m}(\A^\star)$, where $\A^\star$ is the optimal memory-less algorithm. We will fix the algorithm $\A$ in all this section, thus we will drop the dependency with respect to $\A$ and denote $\rwd^b_{t,m}$. We will treat the cases $b=0$ and $b>0$ separately, we will prove for each of them the formula announced in the proposition, with an upper bound instead of equality, then we will derive the optimal policy, for which it is equality.

\subsubsection{Case of $b=0$}
\begin{proof}[Proof of the case $b=0$ in Proposition \ref{prop:dynprogb}]
Let $\A$ be any memory-less algorithm for the 2-groups secretary problem with no comparisons between the two groups, with a stopping time $\tau$, and let us denote for $t \geq 1$
\[
\rwd^0_{t,m} \eqdef \Prob (\A \text{ succeeds} \mid \tau \geq t, N^1_t).
\]

$\{\tau \geq t\}$ is $\F_{t-1}$-measurable, and the distribution of $r_t$ is independent of $\F_{t-1}$ knowing $(N^1_{t-1}, g_t)$, therefore $r_t$ is independent of $\{ \tau \geq t\}$, thus we have
\begin{align}
\rwd^0_{t,N^1_{t-1}t} \nonumber \label{eq:req-rwd0-0}
=& \E_{g_t}[ \Prob(r_t=1 \mid \tau \geq t, N^1_{t-1}, g_t)
\Prob (\A \text{ succeeds} \mid \tau \geq t, N^1_{t-1}, r_t=1, g_t) \\\nonumber
&\qquad + \Prob(r_t \neq 1 \mid \tau \geq t, N^1_{t-1}, g_t)
\Prob (\A \text{ succeeds} \mid \tau \geq t, N^1_{t-1}, r_t \neq 1, g_t) ]\\ \nonumber
=& \E_{g_t} \left[  \frac{1}{1 + N^{g_t}_{t-1}}
    \Prob (\A \text{ succeeds} \mid \tau \geq t, N^1_{t-1}, r_t=1, g_t)  \right.\\
&\qquad \left.+ \left( 1 - \frac{1}{1 + N^{g_t}_{t-1}}\right) 
    \Prob (\A \text{ succeeds} \mid \tau \geq t, N^1_{t-1}, r_t \neq 1, g_t) \right]\enspace.
\end{align}

If we denote $q$ the probability that $\act_{t, 1} = \askip$ knowing $(N^1_{t-1}, r_t, g_t)$, we have that

\begin{align} \label{eq:opt0-ineq}
\Prob (\A \text{ succeeds} \mid \tau \geq t, &N^1_{t-1}, r_t, g_t)\\ \nonumber
&= q\Prob (\A \text{ succeeds} \mid \tau \geq t, N^1_{t-1}, r_t, g_t, \act_{t, 1} = \askip) \\ \nonumber
& \qquad + (1-q) \Prob (\A \text{ succeeds} \mid \tau \geq t, N^1_{t-1}, r_t, g_t, \act_{t, 1} = \astop)\\ \nonumber
&\leq \max\{
    \Prob (\A \text{ succeeds} \mid \tau \geq t,  N^1_{t-1}, r_t, g_t, \act_{t, 1} = \askip)\\ \nonumber
&\hspace{35pt} + \Prob (\A \text{ succeeds} \mid \tau \geq t, N^1_{t-1}, r_t, g_t, \act_{t, 1} = \astop) 
\}
\end{align}
The first term can be simplified using the implication $(\tau \geq t, A_{t,1} = \askip) \implies (\tau \geq t+1)$ and the memory-less property of $\A$ gives for any value of $r_t$ that
\begin{align*}
\Prob (\A \text{ succeeds} &\mid \tau \geq t, N^1_{t-1}, r_t, g_t, \act_{t, 1} = \askip)\\
&= \Prob (\A \text{ succeeds} \mid \tau \geq t+1, N^1_t = N^1_{t-1} + \indic{g_t=1})\\
&= \rwd^0_{t+1, N^1_{t-1} +\indic{g_t=1}}
\end{align*}
The second term is null for $r_t \neq 1$. For $r_t=1$, we have that $(\act_{t, 1} = \astop) \iff ( \tau = t)$, the event $\{ \A \text{ succeeds}\}$ becomes equivalent to $\{t = t^\star\}$, and knowing $r_t, g_t, N^1_{t-1}$, it is independent of the distribution $Q_{t,1}$ of $\act_{t, 1}$ because $\A$ is memory-less, it yields
\begin{align*}
\Prob (\A \text{ succeeds} \mid \tau \geq t,  N^1_{t-1}, r_t=1, g_t, \act_{t, 1} = \astop)
= \Prob (t = t^\star \mid N^1_{t-1}, r_t=1, g_t)
= \frac{1+N^{g_t}_{t-1}}{N}.
\end{align*}
Substituting into Equation \eqref{eq:req-rwd0-0} gives
\begin{align*}
\rwd^0_{t,m}
&\leq \E_{g_t} \left[ \frac{1}{1+N^{g_t}_{t-1}}\max\left\{  
    \rwd^0_{t+1,m+\indic{g_t=1}}, \frac{1+N^{g_t}_{t-1}}{N} \right\}
    + \left(1 - \frac{1}{1+N^{g_t}_{t-1}} \right) \rwd^0_{t+1,m+\indic{g_t=1}} \right]\\
&=  \E_{g_t} \left[   \max\left\{  
    \rwd^0_{t+1,m+\indic{g_t=1}}, \frac{1}{N} + \left(1 - \frac{1}{1+N^{g_t}_{t-1}} \right) \rwd^0_{t+1,m+\indic{g_t=1}}\right\} \right]\\
&= \lambda \max\left\{  
    \rwd^0_{t+1,m+1}, \frac{1}{N} + \left(1 - \frac{1}{1+m} \right) \rwd^0_{t+1,m+1}\right\}\\
&\qquad + (1 - \lambda) \max\left\{  
    \rwd^0_{t+1,m}, \frac{1}{N} + \left(1 - \frac{1}{t-m} \right) \rwd^0_{t+1,m}\right\}.
\end{align*}
\end{proof}


\paragraph{Optimal action when $b = 0$}
An algorithm is optimal if the dynamic programming inequality from the previous statement is satisfied as an equality. The condition is met if and only if Inequality \eqref{eq:opt0-ineq} in the previous proof is an equality, and this can be achieved by stopping with probability 1 at step $s$ if 
\[
r_s = 1 \text{ and }  N \rwd^0_{s+1, N^1_s} \leq N^{g_s}_s\enspace.
\]



\subsubsection{Case of $b > 0$}

\begin{proof}
Let $1 \leq t \leq N$ and assume that $B_t = b > 1$. The tree of all possible observations $(r_t, R_t)$ and actions $\act_{t, 1}, \act_{t, 2}$ that can happen at step $t$ are presented in Figure \ref{fig:tree-b>1}. Before trying to determine the optimal action at this step, let us start by establishing that some actions are never optimal when we still have a positive budget $b$: 
\begin{itemize}
    \item if $r_t \neq 1$, then stopping is not optimal because the success probability would be $0$,
    \item same thing if $R_t \neq 1$,
    \item if $r_t = 1$, stopping is not optimal because it is equivalent to comparing then stopping with probability 1 since $b>0$, therefore comparing then choosing an optimal action given $R_t$ is better than immediately stopping,
    \item a reasonable algorithm never skips after observing $R_t = 1$. In fact, since we consider memory-less algorithms, by Proposition \ref{prop:success-memless-stop} we deduce that skipping $x_t$ after observing $R_t$ has no impact on the success probability compared to skipping after just observing $r_t$, except having $B_{t+1} = b-1$ instead of $B_{t+1} = b$. A reasonable algorithm must therefore use a comparison only if it is ready to stop if $R_t = 1$. 
\end{itemize}

If we want to determine the optimal algorithm, the only sequences of actions and observations possible at step $t$ are $(r_t=1, \acomp, R_t=1, \astop)$, $(r_t=1, \acomp, R_t \neq 1, \askip)$, $(r_t=1, \askip)$, and $(r_t \neq 1, \askip)$.

\begin{figure}[h!]
\centering
\begin{tikzpicture}
\node {$(r_t,g_t)$}[grow=right][sibling distance = 1cm][level distance=2.5cm]
    child [yshift = -0.8cm]{node {$r_t \neq 1$}
        child {node {$\askip$}}
        child {node {\color{red} $\astop$} edge from parent [red]}
    }
    child [yshift = 0.8cm] {node {$r_t=1$}
        child {node {$\askip$}}
        child {node {\color{red} $\astop$} edge from parent [red]}
        child {node {$\acomp$}
            child [yshift = -.5cm]  {node {$R_t \neq 1$} 
                child {node {$\askip$}}
                child {node {\color{red} $\astop$} edge from parent [red]}
            }
            child [yshift = .5cm]  {node {$R_t=1$}
                child {node {\color{red} $\askip$} edge from parent [red]}
                child {node {$\astop$}}
            }
        }
    };
\end{tikzpicture}
\caption{Tree of possible observations and actions when a new observation $(r_t, g_t)$ arrives and $B_t > 0$.} 
\label{fig:tree-b>1}
\end{figure}

We showed in the proof of Proposition \ref{prop:success-memless-stop} that conditionally to $(g_t, N^1_{t-1})$, the distribution of $r_t$ is independent of $\F_{t-1}$, thus we have 
\[
\Prob(r_t = 1 \mid g_t, N^1_{t-1}) = \frac{1}{N^{g_t}_t},
\]
with $N^{g_t}_t = \indic{g_t = 1}(N^1_{t-1} + 1) + (1 - \indic{g_t = 1} )(t - N^1_{t-1})$. In particular, the event $\{ \tau \geq t\}$ is $\F_{t-1}$-measurable, hence
\begin{align*}
\Prob(\A \text{ succeeds} \mid \tau \geq t, B_t, N^1_{t-1}, g_t)
=& \frac{1}{N^{g_t}_t} \Prob(\A \text{ succeeds} \mid \tau \geq t, B_t, N^1_{t-1}, g_t, r_t=1)\\
&+ \left(1 - \frac{1}{N^{g_t}_t} \right) 
\Prob(\A \text{ succeeds} \mid \tau \geq t, B_t, N^1_{t-1}, g_t, r_t \neq 1)    
\end{align*}
If $r_t \neq 1$, the only possible action is $\act_{t, 1} = \askip$, consequently
\begin{align*}
\Prob(\A \text{ succeeds}& \mid \tau \geq t, B_t, N^1_{t-1}, g_t, r_t \neq 1)\\
&= \Prob(\A \text{ succeeds} \mid \tau \geq t+1, B_t, N^1_{t-1}, g_t, r_t \neq 1, \act_{t, 1}=\askip)\\
&= \Prob(\A \text{ succeeds} \mid \tau \geq t+1, B_{t+1} = B_t, N^1_{t} = N^1_{t-1} + \indic{g_t=1})\\
&=\rwd^{B_t}_{t+1, N^1_{t-1} + \indic{g_t=1}}.
\end{align*}
If $r_t = 1$, then
\begin{align}\label{eq:rwdb-max}
\Prob(\A &\text{ succeeds} \mid \tau \geq t, B_t, N^1_{t-1}, g_t, r_t=1)\\ \nonumber
&\leq \max \{
\Prob(\A \text{ succeeds} \mid \tau \geq t, B_t, N^1_{t-1}, g_t, r_t=1, \act_{t, 1} = \askip),\\ \nonumber
&\qquad \Prob(\A \text{ succeeds} \mid \tau \geq t, B_t, N^1_{t-1}, g_t, r_t=1, \act_{t, 1} = \acomp)\}\\ \nonumber
&= \max\{ 
\rwd^{B_t}_{t+1, N^1_{t-1} + \indic{g_t=1}},
\Prob(\A \text{ succeeds} \mid \tau \geq t, B_t, N^1_{t-1}, g_t, r_t=1, \act_{t, 1} = \acomp)\}
\end{align}
With the same arguments as in the proof of Proposition \ref{prop:success-memless-stop}, we have that 
\[
\Prob(R_t=1 \mid N^1_{t-1}, g_t, r_t=1, \act_{t, 1}, B_t)
= \Prob(R_t=1 \mid N^1_{t-1}, g_t, r_t=1)
= \frac{\Prob(R_t=1 \mid N^1_{t-1}, g_t)}{\Prob(r_t=1 \mid N^1_{t-1}, g_t)}
= \frac{N^{g_t}_t}{t},
\]
therefore
\begin{align*}
\Prob(\A \text{ succeeds} &\mid \tau \geq t, B_t, N^1_{t-1}, g_t, r_t=1, \act_{t, 1} = \acomp)\\
=& \frac{N^{g_t}_t}{t}
  \Prob(\A \text{ succeeds} \mid \tau \geq t, B_t, N^1_{t-1}, g_t, r_t=1, \act_{t, 1} = \acomp, R_t=1)\\
&+ \left(1 - \frac{N^{g_t}_t}{t} \right) \Prob(\A \text{ succeeds} \mid \tau \geq t, B_t, N^1_{t-1}, g_t, r_t=1, \act_{t, 1} = \acomp, R_t \neq 1)\\
=& \frac{N^{g_t}_t}{t}
  \Prob(\A \text{ succeeds} \mid R_t=1, \act_{t, 2} = \astop)\\
&+ \left(1 - \frac{N^{g_t}_t}{t} \right) \Prob(\A \text{ succeeds} \mid \tau \geq t+1, B_{t+1}=B_t - 1, N^1_t = N^1_{t-1} + \indic{g_t = 1})\\
=& \frac{N^{g_t}_t}{N} + \left(1 - \frac{N^{g_t}_t}{t} \right)
    \rwd^{B_t-1}_{t+1, N^1_{t-1} + \indic{g_t=1}}\\
\end{align*}
where we used in the second equality that the only possible action for the optimal algorithm after observing $R_t \neq 1$ is $\act_{t, 2} = \askip$ and the only action after $R_t = 1$ is $\act_{t, 2} = \astop$, and for the last equality we used Propositions \ref{prop:success-memless-stop} and \ref{prop:success-memless-skip}.\\
Substituting into Inequality \eqref{eq:rwdb-max} yields
\begin{align*}
\Prob(\A \text{ succeeds}& \mid \tau \geq t, B_t, N^1_{t-1}, g_t, r_t=1)\\
&\leq \max\left\{
\rwd^{B_t-1}_{t+1, N^1_{t-1} + \indic{g_t=1}},
\frac{N^{g_t}_t}{N} + \left(1 - \frac{N^{g_t}_t}{t} \right)
\rwd^{B_t}_{t+1, N^1_{t-1} + \indic{g_t=1}}
\right\},
\end{align*}
and finally
\begin{align*}
\Prob(\A &\text{ succeeds} \mid \tau \geq t, B_t, N^1_{t-1}, g_t)\\
&\leq \frac{1}{N^{g_t}_t} \max\left\{
\rwd^{B_t}_{t+1, N^1_{t-1} + \indic{g_t=1}},
\frac{N^{g_t}_t}{N} + \left(1 - \frac{N^{g_t}_t}{t} \right)
\rwd^{B_t-1}_{t+1, N^1_{t-1} + \indic{g_t=1}}
\right\}
+ \left(1 - \frac{1}{N^{g_t}_t} \right) 
\rwd^{B_t}_{t+1, N^1_{t-1} + \indic{g_t=1}}\\
&=\max\left\{
\rwd^{B_t}_{t+1, N^1_{t-1} + \indic{g_t=1}},
\frac{1}{N} + \left(\frac{1}{N^{g_t}_t} - \frac{1}{t} \right)
\rwd^{B_t-1}_{t+1, N^1_{t-1} + \indic{g_t=1}}
+ \left(1 - \frac{1}{N^{g_t}_t} \right) 
\rwd^{B_t}_{t+1, N^1_{t-1} + \indic{g_t=1}}
\right\},
\end{align*}
If $B_t = b \geq 1$ and $N_{t-1}^1 = m$, the previous inequality translates, in expectation over $g_t$, as
\begin{align*}
\rwd^b_{t,m}
\leq& \lambda \max\left\{
\rwd^{b}_{t+1, m+1},
\frac{1}{N} + \left(\frac{1}{m+1} - \frac{1}{t} \right)
\rwd^{b-1}_{t+1, m+1}
+ \left(1 - \frac{1}{m+1} \right) 
\rwd^{b}_{t+1, m+1}
\right\}\\
&+ (1 - \lambda) \max\left\{
\rwd^{b}_{t+1, m},
\frac{1}{N} + \left(\frac{1}{t-m} - \frac{1}{t} \right)
\rwd^{b-1}_{t+1, m}
+ \left(1 - \frac{1}{t-m} \right) 
\rwd^{b}_{t+1, m}
\right\}.
\end{align*}

\end{proof}







\subsubsection{Optimal action when $b > 0$}
Similarly to the case $b = 0$, an algorithm is optimal if the inequality in Proposition \ref{prop:dynprogb} is an equality, and this is satisfied if and only if Inequality \eqref{eq:rwdb-max} in the proof of Proposition \ref{prop:dynprogb} is an equality, i.e when choosing to use a comparison with probability 1 if
\[
r_s = 1 \text{ and }
\rwd^{b}_{s+1, N^1_s}
- \left(1 - \frac{N^{g_s}_s}{s} \right) \rwd^{b-1}_{s+1, N^1_s}
<
\frac{ N^{g_s}_s}{N}\enspace.
\]


