\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
\PassOptionsToPackage{numbers}{natbib}

\usepackage[preprint]{neurips_2023}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}

\usepackage{titletoc}
\usepackage[noend, ruled, linesnumbered]{algorithm2e} % For algorithms
\usepackage{amsfonts,amsmath,amsthm}
% \usepackage[ruled]{algorithm2e}
% \usepackage{}
\usepackage{algorithmic}
\usepackage{tikz}
\usepackage{enumitem}   
\usepackage{dsfont}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{stmaryrd}
\usepackage{comment}




\newcommand{\interior}{\overset{\circ}}

\newcommand{\norminf}[1]{\left\|#1 \right\|_\infty}
\newcommand{\normun}[1]{\left\|#1 \right\|_1}
\newcommand{\Sig}{\sum_{i=1}^n}
\newcommand{\Supp}{\text{Supp}}
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\Q}{\mathbb Q}
\newcommand{\R}{\mathbb R}
\newcommand{\N}{\mathbb N}
\newcommand{\Z}{\mathbb Z}
\newcommand{\indic}[1]{\mathds{1}\hspace{-2pt}\left(#1\right)}
\newcommand{\cov}{\text{cov}}
\newcommand{\Prob}{\mathbf P}
\renewcommand{\Pr}{\mathbf P}
\newcommand{\eps}{\varepsilon}
\newcommand{\deriv}[2]{\partial #1/\partial #2}
\newcommand{\Deriv}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\indep}{\perp \!\!\! \perp}
\newcommand{\convP}{\stackrel{\mathbb{P}}{\longrightarrow}}
\newcommand{\convL}{\stackrel{d}{\longrightarrow}}
\DeclareMathOperator{\best}{max}
\newcommand{\E}{\mathbf{E}}
\newcommand{\rwd}{\mathcal{V}}
\newcommand{\rd}{\mathcal{U}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\askip}{\texttt{skip}}
\newcommand{\astop}{\texttt{stop}}
\newcommand{\acomp}{\texttt{compare}}
\newcommand{\anone}{\texttt{none}}
\newcommand{\act}{a}
\newcommand{\w}{\alpha}

\newcommand{\diff}{\mathrm{d}}

\newcommand{\comp}{\rho}

\renewcommand{\phi}{\varphi}

\newcommand{\e}{\mathrm{e}}



\usepackage{mathtools}
\newcommand{\eqdef}{\coloneqq}

%\renewcommand{\citep}[1]{\citeauthor{#1}, \citeyear{#1}}
\newcommand{\sgn}{\text{sgn}}
\newcommand{\st}[1]{\texttt{#1}}
\newcommand{\pl}{\text{pl}}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\providecommand*\lemmaautorefname{Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{definition}{Definition}[section]
\newtheorem{proposition}[theorem]{Proposition}

%\usepackage[createShortEnv]{proof-at-the-end}
\usepackage{proof-at-the-end}


\pgfkeys{/prAtEnd/appendix/.style={
    end,
    text link={\begin{proof}See \hyperref[proof:prAtEnd\pratendcountercurrent]{full proof} in \pratendSectionlikeCref. \end{proof}}
} }



\usepackage[textwidth=1.0cm, textsize=tiny]{todonotes} % for writting
% \usepackage[textwidth=2.0cm, textsize=tiny,disable]{todonotes} % for submission
\newcommand{\evg}[2][noinline]{\todo[color=yellow!20,#1]{{\bf Evg:} #2}}
\newcommand{\nic}[2][noinline]{\todo[color=green!20,#1]{{\bf Nic:} #2}}
\newcommand{\ziy}[2][noinline]{\todo[color=red!20,#1]{{\bf Ziy:} #2}}














\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors


\title{Addressing bias in online selection with a limited budget of comparisons}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
    Ziyad Benomar \\
    CREST, ENSAE, Ecole polytechique\\
    \texttt{ziyad.benomar@ensae.fr} \\
  \And
    Evgenii Chzhen\\
    CNRS, LMO, Université Paris-Saclay\\
    \texttt{evgenii.chzhen@universite-paris-saclay.fr}
  \AND
    Nicolas Schreuder \\
    MaLGa, DiBris, Università di Genova\\
    \texttt{schreuder.nicolas@gmail.com}
   \And
    Vianney Perchet \\
    CREST, ENSAE and Criteo AI LAB\\
    \texttt{vianney.perchet@normalesup.org}
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}


\begin{document}


\maketitle


\begin{abstract}
Consider a hiring process with candidates coming from different universities. It is easy to order candidates who have the same background, yet it can be challenging to compare them otherwise.
The latter case requires additional costly assessments and can result in sub-optimal hiring decisions.
%Given an assigned budget, what is the optimal strategy to select the most  qualified candidate?
Given an assigned budget, what would be an optimal strategy to select the most qualified candidate?
We model the above problem by introducing a new variant of the secretary problem in which sequentially observed candidates are split into two distinct groups.
For each new
% ly observed
candidate, the decision maker observes its rank among
already seen
% observed
candidates from the same group and can access its rank among all observed candidates at some fixed cost.
%At each round, a new candidate is presented to the decision maker who 
%At each round, the decision make can compare the latest candidate to observed candidates from the same group for free and at a given cost to the other observed candidates.
%in which the observed candidates belong to two distinct groups, and the decision maker has access to their partial rank within their own group and can request their total rank by paying some price. 
%Our work contributes to the field of online algorithms with advice by 
%Most of the literature on online algorithms with advice consider scenarios in which advice are free and readily available to the algorithm---. We propose to overcome this limitation 
%However, unlike most research papers where advice is free and readily available for the algorithm to use as input, we consider a scenario where the algorithm operates under a limited budget of hints and must carefully decide when to query them. 
%The problem framework we propose allows for strong performance guarantees when using optimal prediction-requesting strategies.
To tackle this new problem, we introduce and study the family of Dynamic Double Threshold (DDT) algorithms. 
%We show that they achieve asymptotic near-optimal performance with only a constant budget, independent of the number of candidates.
We show that, with well-chosen parameters, their success probability converges rapidly to $1/\e$ as the budget grows, recovering the optimal success probability from the usual secretary problem.
Finally, focusing on the class of memory-less algorithms, we propose an optimal algorithm in the non-asymptotic regime and show that it belongs to the DDT family when the number of candidates is large. 

%Then we provide an optimal memory-less algorithm and show that it belongs to the DDT family when the number of candidates is big.

%Our analysis reveals several alluring properties of the optimal algorithm. 
%Our work provides a step towards a better online selection process in the presence of unidentifiable biases. 
\end{abstract}




\section{Introduction}


Online selection is among the most fundamental problems in decision-making under uncertainty.  It is traditionally framed as a sequential decision making problem with imperfect information about the future. 
For instance, in the classical secretary problem~\cite{chow1971great, dynkin1963optimum, gardner1970mathematical}, the decision-maker has to identify the best candidate among a pool of totally ordered candidates that it observes sequentially and in a random order.
%Unlike in the prophet problem \cite{prophet}, only the ranks of the candidates matter and not their values. 
The optimal strategy is well known and consists in skipping a $1/\e$ fraction of the first candidates and then selecting the first candidate that is better than all previously observed candidates.
A large body of literature is dedicated to the secretary problem and its variants, we refer the interested reader to ~\cite{chow1971great, ferguson, McNamara-1980, lindley-1961} for a historical overview of this theoretical problem.
In practice, however, the ranking of the candidates is established through curriculum evaluation and a variety of interview processes.
%testing, examination, and overall performance in an interview process. 
Yet, as pointed out by several social studies, those processes do not necessarily reflect the actual ability of a candidate and might be biased with respect to some socioeconomic attributes \cite{salem2022don, Raghavan_Barocas_Kleinberg_Levy20}. To tackle this issue, several authors have explored variants of the secretary problem with noisy/biased observations of the ranks \cite{pmlr-v139-correa21a, salem2019closing, freij2010partially}.

In this work, we propose and study a model in which the information that is available to the decision-maker differs from that of the classical setting. In our setting, the candidates are grouped in two groups, the within-group orders are freely observable and can be trusted (\textit{e.g.}, two candidates from the same university can fairly be compared using GPA), but inter-group order must be acquired at some cost. In order to make the proposed setting more realistic, we strictly limit the number of inter-group order comparisons through a given budget.
This budget represents the amount of time/money that the hiring organization is willing to invest to understanding the candidate's ``true'' performance (through extra costly tests for instance).



Roughly speaking, one can change the setup of the secretary problem in two ways---provide additional information or reduce the usually available one.
% we study optimal strategy for when the information that is available to the decision-maker differs from that of the classical setting.
% In this work, we are interested in adapting the optimal strategy for when the information that is available to the decision-maker differs from that of the classical setting.
%Here we only focus on those works that are closest to us in spirit.
%A natural question around the secretary problem is
For example, in the first direction, \citet{Gilbert2006} investigate the case in which the candidates' values are drawn from a known probability distribution, while \citet{advice-2021} assume that some additional signal about the value of each secretary is available. This signal is, for example, a recommendation letter or a prior belief about the

the candidate. 
% In a different direction, one can imagine scenarios where there is a lack of information:
In contrast, considering limited information,
\citet{pmlr-v139-correa21a} introduce a multi-color secretary problem. In this problem, totally ordered candidates belong to different groups and only their in-group partial order, consistent with the total one, can be accessed. They design an asymptotically optimal strategy, in the sense of selecting the best candidate. A closely related prophet problem of the online multi-group selection has been studied in~\cite{arsenis2022individual} and \cite{pmlr-v139-correa21a}.
Similarly to~\citep{pmlr-v139-correa21a},~\citet{salem2019closing} analyze a poset-secretary problem, in which a partially ordered set is revealed sequentially and the goal is to select $k$-candidates with the highest score. Partially ordered secretaries have also been previously considered by~\citet{freij2010partially}, with the goal of selecting \emph{any} maximal element.
Another related problem has been considered in~\cite{monahan1980optimal, monahan1982state}, where the goal is to optimally stop a target process assuming that only a related process is observed.
% In this case, the author introduces a mechanism for acquiring information from the target process. Yet, the budget is not assumed to be fixed, and only a penalized version is considered.
% but again no comparisons were allowed between candidates of different groups.


%\paragraph{Learning-augmented algorithms}
More broadly, our work contributes to the line of research on \textit{learning augmented algorithms}. In this paradigm, algorithms are supported by additional input---hints delivered by an external method or an expert~\cite{lykouris2021competitive, LattanziLMV20, GollapudiP19, AntoniadisGKK20, AntoniadisCE0S20, PurohitSK18, kraska2018case, khalil2017learning, rohatgi2020near}. In particular, our framework is highly practical, and yet not extensively explored---algorithms can request hints on the fly.
A crucial aspect of our work, which distinguishes us from the aforementioned authors, is a strict budget constraint, which puts a hard limit on the total amount of available hints. This setup corresponds to a more realistic scenario, in which hints are costly.
% as they require running heavy methods or an intervention of an expert.
\citet{BhaskaraCKP21} and \citet{im2022parsimonious} studied respectively online optimization and the caching problem, under the assumption that the number of hints is limited, and they show that strong performance can be achieved by adequately choosing when to use them. 
%Thus, our work can be seen as an ``extension'' of the caching problem to the two-group secretary one.
Another related field is the \textit{advice complexity} \cite{dobrev2009measuring, arora2009computational, bockenhauer2009advice, boyar2017online, komm2016introduction}, in which a fixed size advice if given, which brings additional error-free information. The aim is to establish a trade-off between size of the advice and the algorithm's performance.

% Our paper contributes to the line of research on \textit{learning augmented algorithms}, which involves providing algorithms with additional input in the form of predictions, delivered by a machine learning program or by an expert, concerning some unknown parameters of the problem \cite{lykouris2021competitive, LattanziLMV20, GollapudiP19, AntoniadisGKK20, AntoniadisCE0S20, PurohitSK18, kraska2018case, khalil2017learning, rohatgi2020near}More precisely, we study in this paper a highly practical, and yet not extensively explored setting, where predictions are not given as input, but the algorithm can choose when to request them, under a budget constraint. Predictions are in general costly as they require running heavy machine learning algorithms or the intervention of an expert, and it is difficult to provide an arbitrarily large number of predictions at the start of the algorithm. \citet{BhaskaraCKP21} and \citet{im2022parsimonious} studied respectively online optimization and the caching problem, under the assumption that the number of hints is limited, and they show that strong performance can be achieved by adequately choosing when to use the hints. We extend this study to the two-group secretary problem.
% Such settings can also be related to the field of \textit{advice complexity} \cite{dobrev2009measuring, arora2009computational, bockenhauer2009advice, boyar2017online, komm2016introduction} in theoretical computer science, where an advice of size $B$ is given, and brings some additional error-free information about the input. The aim is to establish a tradeoff between $B$ and the algorithm's performance. 


\subsection{Contributions and organization}

In this work we assume that totally ordered candidates from two distinct groups are observed sequentially. The goal of the decision-maker is to design a stopping rule that maximizes the probability of selecting the best candidate. 
We consider a setting in which the decision-access has a free access to the partial within-group order (of already observed candidates). As discussed above, this setting recently emerged in the literature to better model online selection processes.
% and can pay to observe the overall order. 
%We consider a less explored, but still previously considered case (see the discussion above) of accessing only to the partial order within the group and among previously seen candidates.
The main twist of our work is the introduction of an additional mechanism---a fixed budget of comparisons of candidates from different groups. In other words, as long as the budget is not exhausted, any algorithm can request access to the total order of a candidate among those already seen. Thus, our goal is to characterize an optimal budget spending and stopping time algorithmic strategy.
% More colloquially, our model addresses a situation when the order within groups is free and can be trusted without doubt, \textit{e.g.}, two candidates from the same university can be compared by the mean of their transcripts, but when they are coming from two different schools, with different evaluation processes, inter-group order must be acquired. The budget of comparisons is seen then as the number of times the hiring organization is willing to invest in understanding the ``true'' candidate's performance.%

\textbf{Contributions.\,} We study the two-group secretary problem in the new setting of \textit{learning-augmented algorithms} with the ability to freely choose when to query the hints under a budget constraint.
Our paper highlights the substantial performance improvement that can obtained made by requesting hints at the right moment. 
% In our setup, hints are seen as comparisons between candidates of different groups.
We make the following contributions:
\begin{enumerate}[noitemsep,topsep=0ex,leftmargin=.5cm]
    % \item we first introduce our problem and setting
    \item[\textbf{1.}] we first introduce a new twist on classical secretary problem, better reflecting real-world applications;
    \item[\textbf{2.}] we propose a new family of algorithms that generalizes, in a non-trivial way, the optimal algorithm for the secretary problem in the case of two groups;
    \item[\textbf{3.}] we study the asymptotic properties of these algorithms and describe the optimal choice of parameters within this family; we provide, in the appendix, theoretical guarantees on their success probability in the non-asymptotic regime;
    \item[\textbf{4.}] we derive an optimal memory-less non-asymptotic algorithm using a dynamic programming approach;
    % \item[\textbf{1.}] 
\end{enumerate}
Finally, we conduct a numerical study supporting our theoretical claims and providing additional empirical evidence.



%We study the two-group secretary problem in the new setting of \textit{learning-augmented algorithms} with the ability to freely choose when to query the hints under a budget constraint. In our setup, hints are seen as comparisons between candidates of different groups. 
%This model introduces additional challenges in designing algorithms to fully exploit this feature.
%We formally present the problem in Section~\ref{sec:setup} and introduce additional notation that will be used throughout the paper.
%In Section~\ref{sec:DDT}, we introduce a new family of algorithms that generalizes, in a non-trivial way, the optimal algorithm for the classical secretary problem. We study the asymptotic properties of this family and describe asymptotically optimal, within this family, choice of parameters. In Section~\ref{sec:memless}, we turn our attention to non-asymptotic study and derive an explicit algorithm, which is optimal among memory-less algorithms. We also provide evidence that, for a large number of candidates, this algorithm belongs to the previously introduced family. Finally, in Section~\ref{sec:exps} we conduct a numerical study supporting our theoretical claims and providing additional empirical evidence.


\textbf{Organization.\,} The problem is formally presented in Section \ref{sec:setup}, along with definitions and notation that we will use throughout the paper. In Section \ref{sec:DDT}, we introduce the Dynamic Double Threshold (DDT) algorithms. We give a recursive formula for computing their asymptotic success probability, which allows to derive an explicit lower bound depending on the budget and on the sizes of both groups. We turn our attention in Section \ref{sec:memless} to the non-asymptotic setting, where we give an optimal memory-less algorithm. We provide evidence suggesting that it behaves as a DDT algorithm when the number of candidates is large. In the last section, we give numerical results, showing additional properties of the DDT family, and comparing them to the optimal memory-less algorithm.



% We assumed that the hints are error-free, which is a realistic hypothesis in our setting. Indeed, we only require the comparison of already seen candidates and do not ask for any information in the future.
% % since the information we seek is comparing two previously seen candidates, by testing for example, and not estimating some unknown parameters that will be revealed in the future.
% Nevertheless, similarly to the approach employed for the online knapsack problem in \cite{knapsack}, our algorithms can be adapted to handle eventually unreliable comparisons. In particular, running the optimal algorithm presented in \cite{pmlr-v139-correa21a} for two groups, which is also identical to our DDT algorithm in the case of null budget, with a probability $1 - \gamma$, and an algorithm taking advantage of the hints with a probability $\gamma$. By doing so, we achieve a worst-case success probability of at least $(1-\gamma)\lambda^2\exp(1/\lambda - 2)$ -where $\lambda$ is the proportion of the majority group-,  and a higher success probability when the hints are accurate.



%{\color{red}A broad range of problems within the learning augmented algorithm framework can be studied in similar settings, where knowing some time-variant quantity can enhance the algorithm's performance, and the decision-maker may request predictions about this quantity at any time within a limited budget constraint.\evg{Useless phrase and too long, I would erase it}}



\section{Formal Problem}
\label{sec:setup}
We consider a strictly totally ordered set of cardinal $N$, whose elements will be called \textit{candidates}. We assume that they are observed in a uniform random arrival order $(x_1, \ldots x_N)$. Moreover, we assume that they are partitioned into two groups $G^1$ and $G^2$ such that, for any $t = 1, \ldots, N$, 
$x_t \in G^{g_t}$, where $\{g_t\}_{t=1}^N$ are mutually independent random variables with
$
\Prob(g_t = 1) = 1 - \Prob(g_t = 2) = \lambda
$
for some constant $\lambda \in (0,1)$. We consider without loss of generality that $\lambda \geq 1/2$. We assume that we can compare for free candidates of the same group and that comparing two candidates of different groups is costly. To address the latter case, we will consider a budget $B \geq 0$ of possible comparisons between candidates from different groups. We assume that $B$ is a constant independent of the number of candidates, and we show that this suffices to obtain algorithms with strong theoretical guarantees.

We assume that the inter-group comparisons are error-free, which is a realistic hypothesis in our setting. Indeed, we only require the comparison of already seen candidates and do not ask for any information in the future.
Nevertheless, similarly to the approach employed for the online knapsack problem in \cite{knapsack}, our algorithms can be adapted to handle eventually unreliable comparisons. In particular, we can run our algorithm in the case of null budget with a probability $1 - \gamma$ and an algorithm taking advantage of the hints with a probability $\gamma$. This mechanism achieves a worst-case success probability of at least $(1-\gamma)\lambda^2\exp(1/\lambda - 2)$, where $\lambda$ is the proportion of the majority group, but a higher success probability when the hints are accurate.

In what follows, for $g \in \{1,2\}$, we denote $G^g_t$ the set of candidates of group $G^g$ observed up to time $t$, i.e
$
G^g_t \eqdef \{ x_s \mid s \leq t \text{ and } g_s = g\}.
$ 
Let $\A$ be any algorithm for the 2-groups secretary problem, we define its stopping time $\tau(\A)$ as the step $t$ when it decides to return the observed candidate. We will often drop the explicit dependency on $\A$ and write $\tau$ when no ambiguity is involved. We will say that $\A$ succeeded if 
$x_{\tau(\A)} = \max \{x_1, \ldots, x_N\}$.
Let us also define, for any step $t$, the random variables
$
r_t = \sum_{i=1}^t \indic{x_t \leq x_i, g_t=g_{i}}
$ and 
$
R_t = \sum_{i=1}^t \indic{x_t \leq x_{i}}.
$
Given a candidate at time $t$, $r_t$ is its \emph{in-group rank} up to time $t$, while $R_t$ is its \emph{overall rank} up to time $t$.
Note that the actual values of $x_t$ do not play a role in the secretary problem and we can restrict ourselves to the observations $r_t, g_t, R_t$. While the first two random variables are always available at the beginning of round $t$, the third one can be only acquired utilizing the available budget.

At each step $t$, $\A$ observes $(r_t, g_t)$ and can perform one of the following three actions:
\begin{enumerate}
    \item $\askip$: ignore $x_t$ and move to the next candidate;
    \item $\astop$: halt the process and return $x_t$;
    \item $\acomp$: if the comparison budget is not exhausted, observe $R_t$;
\end{enumerate}
Furthermore, if a comparison has been used at time $t$, the algorithm has to perform $\astop$ or $\askip$ afterward. We denote respectively $\act_{t,1}$ and $\act_{t,2}$ the first and second action made by the algorithm at step $t$. The history available to the algorithm after the round $t$ is $\F_{t} = \big(r_s, g_s, \act_{s, 1}, R_s \textbf{1}(\act_{s, 1} = \acomp), \act_{s, 2}\textbf{1}(\act_{s, 1} = \acomp) \big)_{s \leq t}$. We also define $B_t$ as the budget available for $\A$ at step $t$. We have $B_1 = B$ and 
$B_{t+1} = B_{t} - \indic{\act_{t, 1} = \acomp}$ 
for $t \geq 2$.
Finally, for each $b \leq B$, let $\rho_b(\A)$ denote the time when $\A$ uses its $b^\text{th}$ comparison, with the agreement that $\rho_{B+1}(\A)$ denotes the time when $\A$ chooses to stop if it has consumed all of its budget.
As with the stopping time, when there is no confusion about $\A$ we simply write $(\rho_b)_b$. The random variables $(\rho_b)_{b=1}^{B+1}$ take values in $\{1, \ldots, N\} \cup \{\infty\}$, where $\rho_b = \infty$ if $\A$ stops before using $b$ comparisons.




\begin{remark}
Although we formalized the problem using the variables $r_t$ and $R_t$, the only information needed at any step $t$ is $\indic{r_t = 1}$ and $\indic{R_t = 1}$, i.e we only need to know if the candidate is the best seen so far, in its own group and overall. 
In practice, $\indic{r_t = 1}$ can be observed by comparing $x_t$ to the best candidate up to $t-1$ belonging to $G^{g_t}$, and if this is the case then $\indic{R_t = 1}$ can be observed by comparing $x_t$ to the best candidate in the other group.
\end{remark}


\section{Dynamic Double Threshold Algorithms}
\label{sec:DDT}
In this section, we define a general class of algorithms termed Dynamic Double Threshold (DDT) algorithms. 
We call a DDT algorithm with thresholds $(\alpha_b, \beta_b)_{b = 0}^B$ and we denote $\A\big{(}(\alpha_b, \beta_b)_{b = 0}^B \big{)}$ the algorithm such that at any step, if $x_t$ is the best candidate in its group so far, then if $b=0$ the candidate is selected, and if $b > 0$ then it compares $x_t$ to the best candidate in the other group only if $g_t = 1$ and $t \geq \alpha_b N$, or $g_t = 2$ and $t \geq \beta_b N$. If $x_t$ wins this comparison then it is selected.
The formal description can be found in Algorithm~\ref{algo:DDT}, and visual representation in Figure~\ref{fig:DDT}.
The structure of these algorithms resembles that of the optimal algorithm for the multi-choice secretary problem \cite{Gilbert2006, matsui2016lower}, where $k$ candidates can be selected and the algorithm \textit{succeeds} if one of them is the best overall. Nonetheless, since we need to handle group membership, different thresholds are set for each group, and our analysis and proof techniques differ significantly.

\begin{figure}[!tbp]
  \centering
    \includegraphics[width=.8\textwidth]{pics/dynamic_dta.pdf}
    \caption{Schematic description of a DDT algorithm.}\label{fig:DDT}
\end{figure}



Before analyzing the family of DDT algorithms and presenting the main results of this section, let us introduce key quantities that will guide our analysis.
For all $B \geq 0$ and all $(\alpha_b, \beta_b)_{b = 0}^B$ set
\begin{align}
    \label{eq:phi_function}
\varphi_B\big(w; (\alpha_b, \beta_b)_{b = 0}^B\big) \eqdef \lim_{N \to \infty} \Prob\big(\A((\alpha_b, \beta_b)_{b = 0}^B) \text{ succeeds} \mid \comp_1 \geq w N \big)\enspace,
\end{align}
where $\comp_1$ is defined in Section~\ref{sec:setup}. Note that it is not clear at this point that the above limit should or does exist. Yet, if it exists for $w = 0$, then the asymptotic success probability of the DDT algorithm is $\varphi_B\big(0; (\alpha_b, \beta_b)_{b = 0}^B\big)$.
We will analyze the above-defined functions recursively, by introducing the second object of interest for all $\alpha \leq \beta$ and $B \geq 1$ as
\begin{equation}
    \label{eq:g_function}
\begin{aligned}
    &g_0(\alpha, \beta) = \lambda \alpha\log(\beta/\alpha) + \alpha(1 - \beta)\enspace,\\
    &g_B(\alpha, \beta) = g_0(\alpha, \beta)+ (1 {-} \lambda) \alpha  \int_{\alpha}^\beta \frac{\phi_{B-1}\big(u ; (\alpha_b, \beta_b)_{b=0}^{B-1}\big)}{u^2} \diff u {+} \alpha\beta \int_{\beta}^1 \frac{\phi_{B - 1}\big(u ; (\alpha_b, \beta_b)_{b=0}^{B-1}\big)}{u^3} \diff u\enspace.
\end{aligned}
\end{equation}

% which will play a crucial role in expressing the success probability of any DDT algorithm for $B=0$, as well as will appear in the study of a more general case $B \geq 1$. The secon quantity of interest is defined 


% For fixed parameters $\alpha_1 \leq \beta_b$ and $B = 1$, the algorithms $\A(\alpha_1, \beta_1)$ has three stages: i) if $t < \alpha_1 N$, as in the usual secretary problem, the algorithms skips these candidates no matter their group membership; ii) if $t \in [\alpha_1 N, \beta_1 N)$ the algorithm can only select a candidate from group $1$ if $x_t$ is better than all previously seen candidates from group $1$ and then comparing to the best seen from the group $2$ (in this latter case we use the assigned budget and set $B = 0$); iii) if no candidate were selected in the previous stages and $B = 1$, for $t \in [\beta_1 N, N]$ candidates from either groups can be selected again by first making sure that they are the best among already seen candidates of their group and then comparing them to the best candidate of the opposite group.
% We give below the pseudo-code for $\A((\alpha_b, \beta_b)_b)$.
\begin{algorithm}[t]
\DontPrintSemicolon 
\caption{Dynamic Double Threshold $\A((\alpha_b, \beta_b)_b)$}\label{algo:DDT}
\SetKwInput{Input}{Input}
   \SetKwInOut{Output}{Output}
   \SetKwInput{Initialization}{Initialization}
   \Input{Available budget $B$, thresholds $(\alpha_b, \beta_b)_{b = 0}^B$}
   \Initialization{$B_1 = B$, $s_b^1 = \alpha_b N$, $s_b^2 = \beta_b N$}
\For{$t=1,\ldots,N$}{
    Receive new observation: $(r_t, g_t) \in  \{1, \ldots, t\} \times \{1, 2\}$\;
    \If(\tcp*[f]{\small compare in-group}){$t \geq s_{B_t}^{g_t} \And r_t = 1$}{%\label{algoline:better-than-best}

        % \vspace{-0.4cm}
        
        \If(\tcp*[f]{\small check budget}){$B_t > 0$}{
            % \vspace{-0.4cm}
            Update budget: $B_{t+1} \gets B_{t} - 1$\;
            
            \lIf(\tcp*[f]{\small compare inter-group}){$R_t = 1$}{
            Return: $t$
            }
        }
        \lElse
        {
        Return: $t$} 
    }
}
\end{algorithm}


\subsection{Recursive formula for the asymptotic success probability}


We first analyze DDT algorithm in the case of no-comparisons, i.e., $B=0$. This particular setup falls into the multi-colored secretary problem with two colors introduced by~\citet{pmlr-v139-correa21a}. While it is only a particular case we further study, we need to extend the main results of~\citet{pmlr-v139-correa21a}, which were announced but proofs were not provided. We give the proof of the following theorem the proof in Appendix \ref{appx:DDT-0}.
\begin{theorem}\label{thm:prob-win0}
    If $\alpha_0 \leq \beta_0$, then
    $
    \lim\Prob( \A(\alpha_0 , \beta_0 ) \text{ succeeds}) = g_0(\alpha_0, \beta_0).
    $ 
    Furthermore, the optimal thresholds are
    $
    \alpha_0^\star = \lambda \exp\left( \frac{1}{\lambda} - 2\right)
    \text{ and }
    \beta_0^\star  = \lambda\,
    $ 
    and 
    $
    \lim\Prob( \A(\alpha_0^\star , \beta_0^\star ) \text{ succeeds}) = \lambda^2 \exp\left( \frac{1}{\lambda} - 2\right)\enspace.
    $
\end{theorem}

The above result gives the asymptotic success probability of any DDT algorithm with $B=0$, yet, to generalize it to the case $B \geq 1$, we need a stronger statement that will eventually allow us to recursively relate the success probability of $\A((\alpha_b, \beta_b)_{b=1}^B)$ to $\A((\alpha_b, \beta_b)_{b=1}^{B-1})$. In fact, we need to compute $\varphi_B(w; (\alpha_0, \beta_0))$ for any $B\geq 0$ and $w\in (0,1)$. The following theorem introduces the required quantity, the case $B=0$ is a strict generalization of the previous theorem,
and we show that $\phi_B$ can be expressed via $\phi_{B-1}$, hence handling the case of general $B \geq 0$ and providing a recursive formula to compute the asymptotic success probability of any DDT algorithm.


\begin{theorem}\label{thm:asymptoticDDT}
For any $B \geq 0$, $(\alpha_b, \beta_b)_{b=0}^B$, and $w \in (0,1)$, $\varphi_B\big(w  ; (\alpha_b, \beta_b)_{b=0}^B\big)$ defined in Eq.~\eqref{eq:phi_function} exists, is continuous and piece-wise $\mathcal{C}^1$.
Furthermore, if $\alpha_B \leq \beta_B$, then for any $w \in (0,1)$
\[
\varphi_B\big(w  ; (\alpha_b, \beta_b)_{b=0}^B\big)
=\left\{
    \begin{array}{ll}
        g_B(\alpha_B, \beta_B) &\text{if } w < \alpha_B\\
        g_B(w, \beta_B)  & \mbox{if } \alpha_B \leq w < \beta_B\\
        g_B(w, w) & \mbox{otherwise}
    \end{array}\enspace,
\right.
\]
where the functions $g_B$ are defined in Equation \eqref{eq:g_function}.
\end{theorem}

\begin{proof}[Sketch of the proof]
The full proof of Theorem \ref{thm:asymptoticDDT} is given in Appendix \ref{appx:DDT-B}, here we provide the main ideas that are used.
The base case $B=0$ is treated separately, and we explicitly compute the asymptotic success probability. 
If $B \geq 1$, we fix $(\alpha_b, \beta_b)_{b=0}^B$ and for each $b \leq B$ we denote $\A^b$ the algorithm $\A((\alpha_\ell, \beta_\ell)_{\ell=0}^b)$ with the initial budget $b$. For any $1 \leq t \leq N$ and $0 \leq b \leq B$, let
$
\rd^b_{N,t} \eqdef \Prob(\A^b \text{ succeeds} \mid \rho^b_1 \geq t),
$
where $\rho_1^b$ is, as in Section \ref{sec:setup}, the first time when $\A^b$ uses a comparison, with the convention $\rho_1 = \tau$ for $\A^0$.
The key argument of the proof is that by conditioning on the position of $\rho_1^B$, we can express $\rd^B_{N,wN}$ as a function of $N$, $\lambda$, the thresholds, the budget, and sums of the terms $(\rd^{B-1}_{N,t})$ for $w N \leq t \leq \beta_B N$ and $\beta_B N \leq t \leq N$. These sums can be expressed as Riemann sums, eliminating any other dependency with respect to $N$. Finally, by induction over $B$, and using convergence properties of Riemann sums and adequate concentration bounds we find the claimed result. 
\end{proof}



\subsection{Lower bound and optimal thresholds}
If the budget is unlimited, we find the classical secretary problem. 
The success probability of any algorithm is therefore upper bounded by $1/\e$.
In the following proposition, we give a lower bound for the success probability of the DDT algorithm with optimal thresholds, i.e maximizing the asymptotic success probability.

\begin{proposition}\label{prop:lb-optDDT}
If $B \geq 0$ and $(\alpha^\star_b, \beta^\star_b)_{b=0}^B$ are the optimal DDT thresholds then 
\[
\lim_{N \to \infty} \Prob\left( \A\big((\alpha^\star_b, \beta^\star_b)_{b=0}^B \big) \text{ succeeds}\right)
\geq \frac{1}{\e}
- \min\left\{ \frac{1}{\e(B+1)!}\, , \, \frac{\lambda(1-\lambda)}{2} \right\}\enspace.
\]
\end{proposition}
See proof in Appendix \ref{appx:lb-optDDT}

The success probability of the optimal DDT algorithm converges therefore very rapidly to the upper bound $1/\e$ when $B$ grows or $\lambda$ approaches $0$ or $1$.
The remaining question is how to compute the optimal thresholds. We discuss this in detail in Appendix \ref{appx:choose-opt-thresh}.
% the case where all the thresholds are equal to the same value
% Optimal thresholds for $B=1$



\section{Optimal Memory-less Algorithm}\label{sec:memless}
Proposition \ref{prop:lb-optDDT} shows that, with well-chosen thresholds, DDT algorithms have a high success probability. However, we do not have any guarantees on their performance when the number of candidates is finite. Furthermore, we can hope to find other algorithms that are better asymptotically. 
Providing a general study of the overall optimal algorithm is a very challenging task due to the potential ability of an optimal algorithm to take the whole history of comparisons into account. Yet, by eliminating the such intricate dependency on the past, it becomes possible to derive an optimal algorithm. In this section, we consider a family of memory-less algorithms, which includes the DDT family, that prohibits the use of the information from previous comparisons and their results. We demonstrate a dynamic programming approach that yields an optimal algorithm in this class for a  finite $N$.

\begin{definition}
Let us denote $N^g_t = |G^g_t|$ for any $1 \leq t \leq N$ and $g \in \{0,1\}$.
We say that an algorithm $\A$ is memory-less if for any $1 \leq t \leq N$, the distribution $Q_{t,1}$ of $\act_{t, 1}$ is $(N^1_{t-1},B_t, g_t, r_t)$-measurable and the distribution $Q_{t,2}$ of $\act_{t, 2}$ is $(N^1_{t-1},B_t, g_t, r_t, R_t)$-measurable given that $\act_{t,1} = \acomp$.
A memory-less algorithm knows the number of candidates $N$ and is aware of the current step $t$ at any time.
\end{definition}

A memory-less algorithm can therefore make decisions only based on its available budget, the number of previously seen candidates belonging to each group, and the current observations. In the following, we will derive the optimal non-asymptotic memory-less algorithm, and in later sections, we will provide evidence that it behaves asymptotically like a DDT algorithm.



\subsection{Non-asymptotic optimal algorithm via dynamic programming}\label{sec:opt-dynprog}
We prove in Appendix \ref{appx:opt-dynprog} that the state of any memory-less algorithm $\A$ is fully determined by the triplet $(t, B_t, N^1_{t-1})$, which are the current step, the available budget, and the number of candidates previously seen in $G^1$, and implicitly $N^2_t = t - N^1_t$.
Using a dynamic programming approach, similar to the spirit in \cite{ano2010odds}, where we carefully examine the possible actions of the algorithm at each step, and the evolution of the success probability by taking any action, we obtain the following proposition.

\begin{proposition}\label{prop:dynprogb}
Let $(\rwd^b_{t,m})_{b,m<t}$ be defined for any $b \leq B,m \leq N$ by $\rwd^b_{N+1,m} = 0$, and for any $0 \leq m < t \leq N$ by
\begin{align*}
\rwd^0_{t,m}
&= \lambda \max\left\{  
    \rwd^0_{t+1,m+1},\, \frac{1}{N} + \left(1 - \frac{1}{1+m} \right) \rwd^0_{t+1,m+1} \right\}\\
&\quad + (1 - \lambda) \max\left\{  
    \rwd^0_{t+1,m},\, \frac{1}{N} + \left(1 - \frac{1}{t-m} \right) \rwd^0_{t+1,m} \right\}\enspace,
\end{align*}
and for $b \geq 1$
\begin{align*}
\rwd^b_{t,m}
= \, & \lambda \max\left\{
\rwd^{b}_{t+1, m+1},\,
\frac{1}{N} + \left(\frac{1}{m+1} - \frac{1}{t} \right)
\rwd^{b-1}_{t+1, m+1}
+ \left(1 - \frac{1}{m+1} \right) 
\rwd^{b}_{t+1, m+1}
\right\}\\
&+ (1 - \lambda) \max\left\{
\rwd^{b}_{t+1, m},\,
\frac{1}{N} + \left(\frac{1}{t-m} - \frac{1}{t} \right)
\rwd^{b-1}_{t+1, m}
+ \left(1 - \frac{1}{t-m} \right) 
\rwd^{b}_{t+1, m}
\right\}\enspace,
\end{align*}
Then for any memory-less algorithm $\A$ we have
$\Prob(\A \text{ succeeds} \mid \tau \geq t, B_t = b, N^1_{t-1} = m)
\leq \rwd^{b}_{t,m}$, with equality for Algorithm \ref{algo:opt-memless}, thus it is the optimal memory-less algorithm. 
\end{proposition}

The optimal decision-making revealed in Algorithm \ref{algo:opt-memless} is much more complicated than that of other variants of the secretary problem \cite{ano2010odds,freeman1983secretary}, because it must take into account the number of candidates previously seen in each group: the more candidates are seen in a group $G^g$ the more we can trust the in-group rank of candidates belonging to $G^g$ to give information about their true rank.

\begin{algorithm}
\DontPrintSemicolon 
\caption{Optimal memory-less algorithm}\label{algo:opt-memless}
\SetKwInput{Input}{Input}
   \SetKwInOut{Output}{Output}
   \SetKwInput{Initialization}{Initialization}
   \Input{The table $(\rwd^b_{t,m})_{b \leq B, 0 \leq m < t \leq N}$ as defined in Proposition \ref{prop:dynprogb}.}
   \Initialization{budget $B_1 = B$, $N_0^1 = 0$, $N_0^2 = 0$}
\For{$t=1,\ldots,N$}{

    Receive new observation: $(r_t, g_t) \in  \{1, \ldots, t\} \times \{1, 2\}$
    
    Set: $N_t^{g_t} \gets N_{t-1}^{g_t} + 1$ \;
    
    \If(\tcp*[f]{\small compare in-group}){$r_t = 1$}{
        \If{$B_t > 0 \text{ and } \rwd^{B_t}_{t+1, N^1_t} - (1 - N^{g_t}_t/t ) \rwd^{B_t-1}_{t+1, N^1_t}<\frac{N^{g_t}_t}{N}$
        \label{algoline:opt-comp-cdtn}}
        {
                Update budget: $B_{t+1} \gets B_{t} - 1$\;
                \lIf{$R_t = 1$}{
                    Return: $t$
                }
        }
        \lIf{$B_t = 0 \text{ and } \rwd^0_{t+1, N^1_t} \leq \frac{N^{g_t}_t}{N}$}{
            Return: $t$
        } 
        % \EndIf
    }
}
\end{algorithm}




\subsection{Asymptotic behavior}\label{sec:opt-memless-asymptotic}
Although Algorithm \ref{algo:opt-memless} is the optimal memory-less algorithm, it is challenging to implement it when the number of candidates is high. Indeed, using it requires computing the table $(\rwd^b_{t,m})_{0\leq b \leq B,0 \leq m < t \leq N}$, which requires a $\Theta(B N^2)$ time. This is why we will try to understand how the algorithm behaves asymptotically. The rigorous justification of the intuition that we provide in this section is left for future works, however, we validate our intuition numerically in the experimental section. More precisely, in this section, we want to provide simple arguments that demonstrate that Algorithm \ref{algo:opt-memless} behaves as an instance of the DDT family for large values of $N$. 

First, note that the algorithm will not stop or use a comparison before $\Omega(N)$ steps, because if $k_N = o(N)$ then the probability of having the best candidate overall among the $k_N$ first ones is $k_N/N = o(1)$, thus it is futile to spend a comparison before observing at least some fraction $\varepsilon N$ of the candidates.
After $\varepsilon N$ steps, we have with high probability that $N^1_t = \lambda t + O(\sqrt{t}\log t )$ for any $\varepsilon N \leq t \leq N$, therefore we can say that $\rwd^b_{t,N^1_t} \approx \rwd^b_{t, \lambda t}$, and we will denote it simply $\rwd^b_t$ for any $0 \leq b \leq B$. The recursion of Proposition \ref{prop:dynprogb} can be written for $b=0$ as
\[
\frac{\rwd^0_t - \rwd^0_{t+1}}{1/N}
= \left( \lambda - \frac{\rwd^0_{t+1}}{t/N}\right)_{+}
+ \left( (1-\lambda) - \frac{\rwd^0_{t+1}}{t/N}\right)_{+}\enspace,
\]
where we denote $u_+ = \max\{0,u\}$. If we assume, as was the case for DDT algorithms, that $\rwd^0_t$ converges to some function $\Phi_0$ of $t/N$, then considering $w = (t+1)/N$ and $dw = 1/N$ the previous equation becomes
\begin{equation}\label{eq:Phi0}
-\Phi'_0(w) 
= \left( \lambda - \frac{\Phi_0(w)}{w} \right)_+
+ \left( 1-\lambda - \frac{\Phi_0(w)}{w} \right)_+.    
\end{equation}


%\begin{figure}[!tbp]
%  \centering
  % \begin{minipage}[b]{0.32\textwidth}
%    \includegraphics[width=0.32\textwidth]{pics/success_proba_l=60.pdf}
%    \hfill
%    \includegraphics[width=0.32\textwidth]{pics/success_proba_l=75.pdf}
%    \hfill
%    \includegraphics[width=0.32\textwidth]{pics/success_proba_l=90.pdf}

    
    %\includegraphics[width=0.32\textwidth]{pics/success_ratio_l=60.pdf}
    %\hfill
    %\includegraphics[width=0.32\textwidth]{pics/success_ratio_l=75.pdf}
    %\hfill
    %\includegraphics[width=0.32\textwidth]{pics/success_ratio_l=90.pdf}
%    \caption{Success probabilities for varying values of $\lambda$ of the optimal DDT and the benchmark algorithms.}\label{fig:lambda_changes}
%\end{figure}


This differential equation is also satisfied by $\varphi_0(w;(\alpha_0^\star, \beta_0^\star))$ defined in Theorem \ref{thm:asymptoticDDT} and $\alpha^\star_0, \beta^\star_0$ as in Theorem \ref{thm:prob-win0}, a proof is given in Proposition \ref{prop:phi0-DE}.
Furthermore, $\Phi_0(1) = 0$ because it is the asymptotic success probability when selecting the last candidate, hence $\varphi_0(\cdot;(\alpha^\star_0, \beta^\star_0)) = \Phi_0$. When no comparisons are allowed, the optimal DDT algorithm is therefore asymptotically optimal over the class of all memory-less algorithms. 
If we consider now $B \geq 1$, using the same approximations, and assuming that $\rwd^b_{wN}$ converges to some function $\Phi_b(w)$, Proposition \ref{prop:dynprogb} gives
\begin{equation}\label{eq:Phib}
-\Phi_b'(w)
= \left( \lambda - \frac{\Phi_b(w) - (1-\lambda)\Phi_{b-1}(w)}{w} \right)_+
+ \left( 1-\lambda - \frac{\Phi_{b}(w) - \lambda \Phi_{b-1}(w)}{w} \right)_+\enspace.
\end{equation}
This equation along with $\Phi_b(1) = 0$ defines a unique function. $\Phi_b$ is non-increasing because its derivative is non-positive, and solving the differential equation numerically, we observe that $(\Phi_b(w) - \Phi_{b-1}(w))/w$ is a decreasing function, and thus both functions $(\Phi_b(w) - \lambda \Phi_{b-1}(w))/w$ and $(\Phi_b(w) - (1-\lambda)\Phi_{b-1}(w))/w$ are decreasing. Hence, there exists $\tilde{\alpha}_b, \tilde{\beta}_b$ such that 
\[
\left\{
    \begin{array}{ll}
        \lambda - \frac{\Phi_b(w) - (1-\lambda)\Phi_{b-1}(w)}{w} \geq 0  &\iff w \geq \tilde{\alpha}_b,\\
        1-\lambda - \frac{\Phi_b(w) - \lambda\Phi_{b-1}(w)}{w} \geq 0 &\iff w \geq \tilde{\beta}_b\enspace, 
    \end{array}
\right.
\]
considering for example that $g_t = 1$, the condition in line \ref{algoline:opt-comp-cdtn} of Algorithm \ref{algo:opt-memless} for using a comparison asymptotically becomes
$
\frac{\Phi_b(w) - (1-\lambda)\Phi_{b-1}(w)}{w}
\leq \lambda.
$
The optimal action when having a candidate that belongs to $G^1$ is thus to use a comparison if and only if $r_t = 1$ and $w \geq \tilde{\alpha}_b$, and similarly we obtain that the optimal action when having a candidate belonging to $G^2$ is to use a comparison if and only if $r_t = 1$ and $w \geq \tilde{\beta}_b$. With this being true for every $1 \leq b \leq B$ and with the explanations we gave in the case of $B=0$, we deduce that the optimal memory-less algorithm behaves asymptotically like a DDT algorithm and the obtained thresholds $(\tilde{\alpha}_b, \tilde{\beta}_b)_{b = 0}^B$ are necessarily optimal. In the next section, we provide numerical evidence supporting this analysis.


\section{Numerical experiments}
\label{sec:exps}

\begin{figure}
  \centering
  % \begin{minipage}[b]{0.32\textwidth}
    \includegraphics[width=0.48\textwidth]{pics/alphas_all.pdf}
    \hfill
    \includegraphics[width=0.48\textwidth]{pics/betas_all.pdf}

    \caption{Evolution of $(\alpha_b^\star, \beta_b^\star)$ as a function of $\lambda$.}\label{fig:threhsolds_alphas_betas}
\end{figure}

In this section, we provide some empirical illustrations comparing the optimal DDT with the optimal memory-less algorithm. Furthermore, we investigate and highlight some interesting phenomena connected with the optimal thresholds $\big(\alpha_b^\star, \beta_b^\star\big)_{b = 1}^B$. 

\paragraph{Optimal thresholds}
Given the discussion in Section \ref{sec:opt-memless-asymptotic}, if the optimal memory-less algorithm has indeed an asymptotic behavior similar to a DDT algorithm with some thresholds $(\tilde{\alpha}_b, \Tilde{\beta}_b)_{b=0}^B$, then these thresholds are necessarily optimal. Furthermore, they are independent of the initial budget, i.e $\alpha^\star_1, \beta^\star_1$ for example are independent of $B$ and are only functions of $\lambda$. More details supporting this claim are provided in Appendix \ref{appx:choose-opt-thresh}.
Figure~\ref{fig:threhsolds_alphas_betas} displays a continuous evolution of the two optimal thresholds as a function of $\lambda \geq 1/2$ and different values of $b$. One can immediately observe two phenomena: the threshold $\beta^\star_b$ for the minority group remains larger than the standard $1/\e$ threshold and rapidly converges to it as $B$ increases; meanwhile, the threshold $\alpha^\star_b$ for the majority group displays two different behaviors depending on the actual value of $\lambda$---in the regime of moderate values of $\lambda$ (compared to $1/2$), $\alpha^\star_b$ behaves similarly to $\beta^\star_b$, while for high values of $\lambda$, $\alpha_b^\star$ is smaller than $1/\e$ (for $b \geq 1$) and converges to it as $B$ increases. 

Finally, Figure~\ref{fig:success} displays the success probability of the optimal dynamic double-threshold algorithm as a function of $\lambda \in (0, 1)$ and $4$ values of the available budget. These successes are symmetric about $1/2$ and converge rapidly to the theoretical upper bound of $1/\e$. We also emphasize the significant improvement of the optimal algorithm for $\lambda \gg 1/2$ (same for $\lambda \ll 1/2$) over $\lambda = 1/2$. The latter value of $\lambda$ corresponds to the benchmark algorithm which is oblivious to $\lambda$ by construction. 

\paragraph{Choosing the thresholds when $\lambda$ is unknown}
A difficulty in practically using the optimal DDT algorithm is that one must know the parameter $\lambda$ beforehand because the optimal thresholds depend on it. We can overcome this by observing in Figure \ref{fig:threhsolds_alphas_betas} that the optimal thresholds are always lower bounded by $1/3$. Thus, the algorithm can observe the first $N/3$ candidates, then estimate the probability of belonging to group $G^1$ as $\hat{\lambda}_N \eqdef |G^1_{N/3}|/N$ and use this estimator in place of the true $\lambda$. Asymptotically this strategy yields the same success probability as if $\lambda$ was known.

\begin{figure}
  \centering
  % \begin{minipage}[b]{0.32\textwidth}
    \includegraphics[width=.8\textwidth]{pics/success.pdf}

    \caption{Success probability of DDT algorithm with optimal thresholds for different $(B, \lambda)$.}\label{fig:success}
\end{figure}

\paragraph{Non-asymptotic performance}
We also investigate how Algorithm \ref{algo:opt-memless}---the optimal memory-less algorithm---compares to the DDT algorithm. As shown in Figure \ref{fig:N-changes}, the success probability of Algorithm \ref{algo:opt-memless} is higher for small values of $N$ and it decreases to meet the success probability of the optimal DDT algorithm as $N$ grows. This confirms that Algorithm \ref{algo:opt-memless} asymptotically belongs to the DDT family. However, its inconveniences are that it requires knowing $\lambda$, and computing the table $(\rwd^b_{t,m})$.
All in all, we can draw the following conclusions: if the number of candidates is high, say for example $N \geq 1000$, it is better to use the optimal DDT algorithm, as it does not require knowing $\lambda$ beforehand nor important preprocessing computations. On the other hand, if the number of candidates is small, then if $\lambda$ is known we can use Algorithm \ref{algo:opt-memless}, and if it is unknown we can naively use the DDT algorithm with all the thresholds equal to $1/\e$. If the budget is enough then this would give a reasonably good success probability.


 



\begin{figure}[h]
  \centering
    \includegraphics[width=0.325\textwidth]{pics/asympt_proba_optVsDDT_B0.pdf}
    \hfill
    \includegraphics[width=0.325\textwidth]{pics/asympt_proba_optVsDDT_B1.pdf}
    \hfill
    \includegraphics[width=0.325\textwidth]{pics/asympt_proba_optVsDDT_B2.pdf}
    \caption{Empirical Success probabilities for $N \in \{2^k \mid 4 \leq k \leq 10 \}$ of optimal memory-less and optimal DDT algorithms, for $\lambda = 0.6$ and $B \in \{0,1,2\}$. The success probabilities were estimated over $5\cdot 10^6$ runs of both algorithms.}\label{fig:N-changes}
\end{figure}



\section{Conclusion} In our study, we presented and examined a partially-ordered secretary problem that allows for a restricted budget of comparisons, which can be utilized by the algorithm at any step. By carefully deciding when to request hints, we demonstrate that highly effective algorithms can be developed, with a success rate that quickly converges to the theoretical upper bound of $1/\e$. Our work provides numerous avenues for further research, both in the field of the secretary problem and in learning-augmented algorithms. Specifically, future studies could investigate the success probability of the optimal memory-less algorithm and extend our findings to multiple groups with non-zero budgets. Additionally, this limited prediction approach could be applied to other online problems that involve partial observation at each step, offering the potential for significant results.

\textbf{Limitations.\,} As the first step, we only considered candidates belonging to $2$ groups and we plan to work on an extension to multiple groups. The study of a setting with $K$ groups is left for future work. We can also try to exhibit minimax type guarantees,
i.e. design algorithms which maximizes $\min_{1 \leq g \leq K} \Prob(\text{ select } x^\star \mid x^\star \text{ belongs to group } g )$, where $x^\star$ is the best candidate.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




% Bibliography
\bibliographystyle{plainnat}
\bibliography{bibliography}


% Appendix
\newpage
\input{appendix}

\end{document}