\documentclass[format=acmsmall, review=false, authorversion=true]{acmart}
%\usepackage{titletoc}
\usepackage{acm-ec-23}
\usepackage{booktabs} % For formal tables
\usepackage[ruled, linesnumbered]{algorithm2e} % For algorithms
\usepackage{amsfonts,amsmath,amsthm}
% \usepackage[ruled]{algorithm2e}
% \usepackage{}
\usepackage{algorithmic}
\usepackage{tikz}
\usepackage{enumitem}   
\usepackage{dsfont}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{stmaryrd}



%%%%%


\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}
\newtheorem{prop}{Proposition}
\newtheorem{lem}{Lemma}
\newtheorem{hyp}{Assumption}
\newtheorem{mydef}{Regression}
\newcommand{\interior}{\overset{\circ}}

\newcommand{\norminf}[1]{\left\|#1 \right\|_\infty}
\newcommand{\normun}[1]{\left\|#1 \right\|_1}
\newcommand{\Sig}{\sum_{i=1}^n}
\newcommand{\Supp}{\text{Supp}}
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\Q}{\mathbb Q}
\newcommand{\R}{\mathbb R}
\newcommand{\N}{\mathbb N}
\newcommand{\Z}{\mathbb Z}
\newcommand{\indic}[1]{\mathds{1}\hspace{-2pt}\left(#1\right)}
\newcommand{\cov}{\text{cov}}
\newcommand{\Prob}{\mathbf P}
\renewcommand{\Pr}{\mathbf P}
\newcommand{\eps}{\varepsilon}
\newcommand{\deriv}[2]{\partial #1/\partial #2}
\newcommand{\Deriv}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\indep}{\perp \!\!\! \perp}
\newcommand{\convP}{\stackrel{\mathbb{P}}{\longrightarrow}}
\newcommand{\convL}{\stackrel{d}{\longrightarrow}}
\DeclareMathOperator{\best}{max}
\newcommand{\E}{\mathbf{E}}
\newcommand{\rwd}{\mathcal{V}}
\newcommand{\rd}{\mathcal{U}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\askip}{\texttt{skip}}
\newcommand{\astop}{\texttt{stop}}
\newcommand{\acomp}{\texttt{compare}}
\newcommand{\anone}{\texttt{none}}
\newcommand{\act}{a}
\newcommand{\w}{\alpha}

\newcommand{\diff}{\mathrm{d}}

\newcommand{\comp}{\rho}

\renewcommand{\phi}{\varphi}

\newcommand{\e}{\mathrm{e}}

\newcounter{protocol}
\makeatletter
\newenvironment{protocol}[1][htb]{%
  \let\c@algorithm\c@protocol
  \renewcommand{\ALG@name}{Protocol}% Update algorithm name
  \begin{algorithm}[#1]%
  }{\end{algorithm}
}
\makeatother

\usepackage{mathtools}
\newcommand{\eqdef}{\coloneqq}

%\renewcommand{\citep}[1]{\citeauthor{#1}, \citeyear{#1}}
\newcommand{\sgn}{\text{sgn}}
\newcommand{\st}[1]{\texttt{#1}}
\newcommand{\pl}{\text{pl}}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\providecommand*\lemmaautorefname{Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{definition}{Definition}[section]

%\usepackage[createShortEnv]{proof-at-the-end}
\usepackage{proof-at-the-end}


\pgfkeys{/prAtEnd/appendix/.style={
    end,
    text link={\begin{proof}See \hyperref[proof:prAtEnd\pratendcountercurrent]{full proof} in \pratendSectionlikeCref. \end{proof}}
} }


\usepackage[textwidth=1.0cm, textsize=tiny]{todonotes} % for writting
% \usepackage[textwidth=2.0cm, textsize=tiny,disable]{todonotes} % for submission
\newcommand{\evg}[2][noinline]{\todo[color=yellow!20,#1]{{\bf Evg:} #2}}
\newcommand{\nic}[2][noinline]{\todo[color=green!20,#1]{{\bf Nic:} #2}}
\newcommand{\ziy}[2][noinline]{\todo[color=red!20,#1]{{\bf Ziy:} #2}}


%%%%%


\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

% Choose a citation style by commenting/uncommenting the appropriate line:
%\setcitestyle{acmnumeric}
\setcitestyle{authoryear}

% Title. Note the optional short title for running heads. In the interest of anonymization, please do not include any acknowledgements.
\title[Addressing bias in online selection with limited budget of comparisons]{Addressing bias in online selection with limited budget of comparisons}

%Adressing bias and fairness in online selction with limited budget of comparisons


% Anonymized submission.
\author{\linebreak Ziyad Benomar \hfill {\small CREST, ENSAE}\linebreak
% $\phantom{111111111111111111111jjjjjsdfsdfsdfdsfsdfsdfsdsdfsdf}$
Evgenii Chzhen \hfill {\small CNRS, LMO, Université Paris-Saclay}\linebreak
% $\phantom{111111111111111111111jjjjj}$
Nicolas Schreuder \hfill {\small MaLGa, DiBris, Università di Genova}\linebreak
% $\phantom{111111111111111111111jjjjj}$
Vianney Perchet \hfill{\small CREST, ENSAE and Criteo AI LAB}\linebreak}
% \author{Vianney Perchet, sdddddddddddddddddddddddddddddddddddddd}
% \address{aaa}

% Abstract. Note that this must come before \maketitle.
\begin{abstract}

%Consider a hiring process with candidates coming from different universities. It is easy to order candidates if they went to the same school, yet can be challenging to compare candidates otherwise. The latter can be accomplished by the means of testing, leading to a potentially high total cost for the hiring organization. Given an assigned budget, what is the optimal strategy to select the most qualified person?
\begin{center}
    \large\textbf{Abstract}
\end{center}
\noindent Consider a hiring process with candidates coming from different universities. It is easy to order candidates who have the exact same background, yet it can be challenging to compare candidates otherwise.
The latter case requires additional assessments, leading to a potentially high total cost for the hiring organization. Given an assigned budget, what is the optimal strategy to select the most qualified candidate?
In the absence of additional information, we model the above problem by introducing a new variant of the secretary problem. Completely ordered candidates, belonging to distinct groups, are arriving in a sequential manner. The decision maker has access to the partial order of the candidates within their own group and can request access to the total order of observed candidates by paying some price. Given a bounded budget of comparisons, the goal of the decision-maker is to maximize the probability of selecting the best candidate. We consider a special case of two groups with stochastic i.i.d.\ group membership.
We introduce and analyze a particular family of algorithms that we called Dynamic Double Threshold (DDT) family, deriving its asymptotic success probability which, given an optimal choice of parameter converges rapidly to the theoretical upper bound of $1/\e$ as the comparison budget growth.
We provide an optimal non-asymptotic memory-less algorithm for the above problem and give numerical evidence that it belongs to the DDT family when the number of candidates is high.
We compare theoretically and numerically the optimal algorithm with a more naive approach that is directly inspired by the standard single-threshold secretary algorithm. Our analysis reveals several alluring properties of the optimal algorithm. It provides a step towards a fairer online selection process in the presence of unidentifiable biases.
\end{abstract}

\begin{document}

% Title page for title and abstract only.


\maketitle




% Notation:
% \begin{enumerate}
%     \item $r_t$ in-group rank among already seen
%     \item $R_t$ overall rank among already seen
%     \item $s$ the threshold times $N$ (number to skip)
% \end{enumerate}

% %TODO: define stopping time


% \newpage

\section{Introduction}

Online selection is among the most fundamental problems having applications in many areas of daily life. In the classical secretary problem~\cite{chow1971great} the goal is to select the best candidate among a pool of totally ordered individuals in a sequential manner. The solution to this problem is well known and corresponds to ``skip $1/\e$ fraction of first candidates and select the first best among the rest'' rule of thumbs.
% Since its inception and solution, many generalizations have been proposed and analyzed.
The total order of candidates is often acquired through testing, examination, and overall performance in an interview. Meanwhile, many social studies show that~\cite[see e.g.,][and references therein]{salem2022don, Raghavan_Barocas_Kleinberg_Levy20} the aforementioned tests or exams do not necessarily reflect the actual performance and can be biased based on the socio-demographic attributes of the individual. To take this issue into account, several authors consider generalizations of the secretary problem trying to invent a more fair selection rule.

We assume that totally ordered candidates from two district groups are arriving sequentially and the goal is to design a stopping rule that maximizes the probability of selecting the best one. The decision-maker has only access to the partial order induced by the total one within each group.
Unlike previous works, we introduce an additional mechanism---budget of comparisons of candidates from two distinct groups. In other words, as long as the budget is not exhausted, any algorithm can request access to the total order of a candidate among those already seen. Thus, our goal is to understand what is the optimal way to spend the comparison budget and when to stop the algorithm. More colloquially, our model addresses a situation when the order within groups can be trusted without doubt, but inter-group order must be bought, i.e., when candidates are coming from two different universities with different evaluation processes. The budget of comparisons is seen then as the number of times the hiring organization is willing to invest in understanding the ``true'' candidate's performance. 

\paragraph{Previous works}


The history of the secretary problem is rich and we refer the interested reader to such monographs as~\cite[see e.g.,][]{chow1971great, ferguson, McNamara-1980, lindley-1961}, for a historical overview. Here we only focus on those works that are closest to us in spirit. A natural question around the secretary problem is how the optimal strategy can be adapted if the information available at each step differs from that of the classical setting. \citet{Gilbert2006} investigate the case where the values of the secretaries are drawn from a known probability distribution, while \citet{advice-2021} assume that some additional signal about the value of each secretary is available, this signal is for example a recommendation letter or a priory on the candidate given its background. On the opposite, one can imagine a case where there is instead a lack of information: \citet{pmlr-v139-correa21a} introduce a multi-color secretary problem, where totally ordered candidates belong to different groups and only their in-group partial order, consistent with the total one, can be accessed. They design an asymptotically optimal strategy, in the sense of selecting the best candidate, for this case. Similarly to the previous authors,~\citet{salem2019closing} analyze a poset-secretary problem, in which a partially ordered set is revealed sequentially and the goal is to select $k$-candidates with the highest score. Partially ordered secretaries have been previously considered by~\citet{freij2010partially}, where the goal is to select \emph{any} maximal element in the chains induced by the poset.
A somewhat related problem has been considered in~\cite{monahan1980optimal, monahan1982state}, where the goal is to optimally stop a target process assuming that only a related process is observed. In this case, the author introduces a mechanism for acquiring information from the target process. Yet, the budget is not assumed to be fixed, and only a penalized version is considered.
A prophet version of the secretary problem with fairness considerations has been the subject of study of~\cite{arsenis2022individual} and \cite{pmlr-v139-correa21a}.
% \cite{salem2022don} provide

% Optimal stopping with partially observed information with price for full info: \cite{monahan1980optimal, monahan1982state}

% Classic secretaries:~\cite{chow1971great}

% Partially ordered secretaries:~\cite{freij2010partially, salem2019closing}

% Fair secretary/Prophets and versions: \cite{pmlr-v139-correa21a, arsenis2022individual, salem2019closing}

% Looks funky: \cite{salem2022don}

\paragraph{Organization and contributions} In Section~\ref{sec:setup}, we formally present the problem and introduce additional notation that will be used throughout the paper. In Section~\ref{sec:benchmark}, we introduce and analyze a simple, yet powerful, benchmark algorithm that follows the aforementioned rule of thumbs: ``skip $r$ first, then pick best''. In Section~\ref{sec:DDT}, we introduce a new family of algorithms that generalizes the benchmark algorithm. We study the asymptotic properties of this family and describe asymptotically optimal, within this family, choice of parameters. In Section~\ref{sec:memless}, we turn our attention to non-asymptotic study and derive an explicit algorithm, which is optimal among memory-less algorithms. We also provide evidence that for a large number of candidates, this algorithm belongs to the previously introduced family. Finally, in Section~\ref{sec:exps} we conduct a numerical study supporting our theoretical claims and providing additional empirical evidence.

\section{Formal Problem}
\label{sec:setup}

We consider a strictly totally ordered set of cardinal $N$, whose elements will be called \textit{candidates}. We assume that these candidates are observed in a uniform random arrival order $(x_1, \ldots x_N)$. Moreover, we assume that they are partitioned into two groups $G^1$ and $G^2$ such that, for any $t = 1, \ldots, N$, $x_t \in G^{g_t}$, where
\[
\Prob(g_t = 1) = \lambda \quad\text{and}\quad \Prob(g_t = 2) = 1-\lambda\enspace,
\]
for some constant $\lambda \in (0,1)$ and mutually independent random variables $\{g_t\}_{t=1}^N$. We assume that we can compare for free candidates of the same group and that comparing two candidates of different groups is costly. To address the latter case, we will consider a budget $B \geq 0$ of possible comparisons between candidates from different groups.

In the online setting, when a candidate arrives, we can choose to select them, halting the process, or we can choose to skip them, moving on to the next one---hoping to find a better candidate in the future. Skipping a candidate means that once they have been rejected, they cannot be recalled---the decisions are irreversible. Given the total number of candidates $N$, the probability $\lambda$ of belonging to $G^1$, and a budget $B$, the goal is to derive an algorithm that maximizes the probability of selecting the best overall candidate.
It is explicitly assumed that $N,B$ are known. While we will provide a non-asymptotic study, our main focus is on the asymptotic performance when $N$ is large, assuming that $B$ and $\lambda$ are fixed constants.
Finally, since $G^1$ and $G^2$ have symmetric roles, we assume without loss of generality that $\lambda \geq 1/2$, i.e., the first group is the majority and the second one is the minority.





\subsection{Stopping times and additional notation}
In what follows, for $g \in \{1,2\}$, we denote by
\[
G^g_t \eqdef \{ x_s \mid s \leq t \text{ and } g_s = g\} \qquad t = 1, \ldots, N\enspace,
\]
the set of candidates of group $G^g$ observed up to time $t$.
Let $\A$ be any algorithm for the 2-groups secretary problem, we define its stopping time $\tau(\A)$ as the step $t$ when it decides to return the observed candidate. We will often drop the explicit dependency on $\A$ and write $\tau$ when no ambiguity is involved. We will say that $\A$ succeeded if the selected candidate $x_\tau$ is the best among all the candidates $\{x_1, \ldots, x_N\}$.
Let us also define, for any step $t \geq 1$, the random variables

\begin{equation}\label{eq:def-zt}
r_t = \sum_{t'=1}^t \indic{x_t \leq x_i, g_t=g_{t'}}
\quad \text{ and } \quad
R_t = \sum_{t'=1}^t \indic{x_t \leq x_{t'}}\enspace.
\end{equation}
%\begin{equation}\label{eq:def-zt}
%z_t = \textbf{1}(x_t = \best G^{g_t}_t)
%\quad \text{ and } \quad
%Z_t = \textbf{1}(x_t = \best \{ x_1, \ldots, x_{t-1}, %x_t\})\enspace.
%\end{equation}
Both random variables have natural interpretations: given a candidate at time $t$, $r_t$ is its \emph{in-group rank} up to time $t$, while $R_t$ is its \emph{overall rank} up to time $t$.
%$r_t = 1$ indicates that $x_t$ is the best in its own group so far and $R_t = 1$ indicates that $x_t$ is the best candidate over all the past ones. 
Note that the actual values of $x_t$ do not play a role in the secretary problem and we can restrict ourselves to the observations $r_t, g_t, R_t$. While the first two random variables are always available at the beginning of round $t$, the third one can be only acquired utilizing the available budget.

At each time $t = 1, \ldots, N$, an algorithm $\A$ observes $r_t, g_t$ and can perform one of the following three actions:
\begin{enumerate}
    \item $\askip$: ignore $x_t$ and move to the next one;
    \item $\astop$: return $x_t$;
    \item $\acomp$: if the comparison budget is not exhausted, observe $R_t$---compare the candidate $x_t$ to the already seen candidates in the other group;
\end{enumerate}
Furthermore, if the comparison has been used at time $t$, the algorithm has to perform $\astop$ or $\askip$ afterward. We denote respectively $\act_{t,1}$ and $\act_{t,2}$ the first and second action made by the algorithm at step $t$. Protocol~\ref{algo:general} describes possible interactions and defines permitted operations for our problem. Let us formally define the history available to the algorithm after the round $t = 1, \ldots, N$ as $\F_{t} = \big(r_s, g_s, \act_{s, 1}, R_s \textbf{1}(\act_{s, 1} = \acomp), \act_{s, 2}\textbf{1}(\act_{s, 1} = \acomp) \big)_{s \leq t}$. Let us also define $B_t$ as the budget available for $\A$ at step $t$ by 
\begin{align*}
B_t = B_{t-1} - \indic{\act_{t, 1} = \acomp} \quad t = 2, \ldots, N\quad\text{and}\quad B_1 = B\enspace.
\end{align*}

In the presence of a non-zero budget, every algorithm is going to use comparisons to acquire more information about the total order. The times that these comparisons are used will be determinant for analyzing many algorithms.
\begin{definition}\label{def:rho_b}
For every algorithm $\A$, each $b = 0, \ldots, B$, let $\rho_b(\A)$ denote the time when $\A$ uses its $b^\text{th}$ comparison, with the agreement that $\rho_{B+1}(\A)$ denotes the time when $\A$ chooses to stop if it has consumed all of its budget.
\end{definition}
As with the stopping time, when there is no confusion about $\A$ we simply write $(\rho_b)_b$. The random variables $(\rho_b)_{b=1}^{B+1}$ take values in $\{1, \ldots, N\} \cup \{\infty\}$, where for any $b \leq B+1$ we have $\rho_b = \infty$ if $\A$ stops before using $b$ comparisons.


\begin{algorithm}
% \renewcommand{\ALG@name}{Protocol}
\renewcommand{\algorithmcfname}{Interaction protocol}
\DontPrintSemicolon
\caption{}\label{algo:general}
\SetKwInput{Input}{Input}
   \SetKwInOut{Output}{Output}
   \SetKwInput{Initialization}{Initialization}
   \Input{Number of observations $N$, budget of comparisons $B \leq N$}
   \Initialization{budget $B_1 = B$}
\For{$t=1,\ldots,N$}{

    Observe $(r_t, g_t) \in \{1, \ldots, t\} \times \{1, 2\}$

    Pick $Q_{1, t} \in \Delta(\{\askip, \astop, \acomp\})$

    Sample $\act_{t, 1} \sim Q_{1, t}$

    \If(){$\act_{t, 1} = \astop$}{
    
    Return $t$
    
    }

    \If(){$\act_{t, 1} = \acomp \And B_t > 0$}{

    Set $B_{t + 1} = B_t - 1$
    
    Observe $R_t$

    Pick $Q_{2, t} \in \Delta(\{\askip, \astop\})$

    Sample $\act_{t, 2} \sim Q_{2, t}$

    \If(){$\act_{t, 2} = \astop$}{
    
    Return $t$
    
    }
    
    }
}

\end{algorithm}






% It is common in the context of online algorithms to be interested in the competitive ratio, defined in our case for any online algorithm $\A$ by 
% \[
% \frac{\Prob(\operatorname{OPT} \text{ succeeds})}{\Prob(\A \text{ succeeds})}\enspace,
% \]
% where $\operatorname{OPT}$ is the optimal offline algorithm. If $B\geq 1$ then the optimal offline algorithm can determine the maximum in each group and then use one comparison to select the best candidate overall, and if $B=0$ then the optimal offline algorithm selects the group with higher cardinal and returns its maximum. The success probability of this algorithm is therefore $1$ if $B \geq 1$ and $\E[ \max\{ \lvert G^1 \rvert, \lvert G^2 \rvert \} ]/N$ otherwise.\\
% However, we will not focus on the notion of competitive ratio and we will instead compare the success probability of our algorithms to the upper bound $1/\e$. In fact, if the budget of comparisons is unlimited, then a comparison can be used at each step and our problem becomes equivalent to the classical secretary problem, to which the optimal strategy yields an asymptotic success probability of $1/\e$, the success probability of any online algorithm to our problem is thus asymptotically upper bounded by $1/\e$.





% If $\A$ chooses the action $\acomp$, then after observing $Z_t$ it has to choose again a new action. If $\A$ is a reasonable algorithm then it will not choose $\acomp$ a second time. The reasonable actions for $\A$ at step $t$ are therefore $\askip$, $\astop$, $\acomp$ then $\askip$, $\acomp$ then $\astop$. 
% For convenience, let us say that at each step $t$, two consecutive actions $\act_{t, 1}$ then $\act_{t, 2}$ are made such that
% \begin{equation}\label{actionset}
% (\act_{t, 1}, \act_{t, 2}) \in \{ (\askip, \anone), (\astop, \anone), (\acomp, \askip), (\acomp, \astop)\},
% \end{equation}
% where $\act_{t, 2} = \anone$ means that there is no second action.\\



\section{Benchmark Algorithm}
\label{sec:benchmark}

% We observe sequentially $N$ candidates $x_1, \ldots, x_N$, each belonging to one of two groups
% $G^1$ and $G^2$. We assume that the events $\{x_i \in G^1\}$, $i \in \{1,\ldots,N\}$, are independent and
% \[
% \forall i \in \{1, \ldots, N\}: \quad 
% \Pr[x_i \in G^1] = \lambda, \quad \Pr[x_i \in G^2] = 1-\lambda
% \]
% for some unknown $\lambda \in (0,1)$.
% \begin{remark}
% This modeling corresponds to the setting where we have for example $N$ candidates from two different universities $G^1$ and $G^2$ applying for a job, we have a number $N_1$ of candidates from university $G^1$ and $N_2$ from university $G^2$, but we ignore $N_1$ and $N_2$, we only know $N = N_1 + N_2$. If we shuffle the resumes of the candidates before treating them, then we find our mathematical modeling with $\lambda = N_1/N$.
% \end{remark}
In this section, we analyze a rather straightforward approach to addressing the 2-group secretary problem. Despite its simplicity, it serves as a useful benchmark for controlling the success probability of an improved algorithm that we describe in Section~\ref{sec:DDT}.
The approach considered here is presented in Algorithm~\ref{algo:bench-algo}. In words, this approach tries to mimic the classical secretary stopping rule, by first skipping a fraction of candidates and then selecting the first either best overall (if budget permits) or best in-group candidate (if the budget is exhausted). As shown in the end of this section, the success probability of the this algorithm rapidly approaches the full-information value of $1 / \e$ as the available budget $B$ increases.


\begin{algorithm}
\DontPrintSemicolon 
\caption{Benchmark algorithm with $B$ comparisons}\label{algo:bench-algo}
\SetKwInput{Input}{Input}
   \SetKwInOut{Output}{Output}
   \SetKwInput{Initialization}{Initialization}
   \Input{number of explorations $\w N$}
   \Initialization{budget $B$, $N_0^1 = 0$, $N_0^2 = 0$}
\For{$t=1,\ldots,N$}{

    Receive new observation: $(r_t, g_t) \in  \{1, \ldots, t\} \times \{1, 2\}$
    
    Set: $N_t^{g_t} \gets N_{t-1}^{g_t} + 1$ \;
    
    %\If(\tcp*[f]{\small compare in-group}){$t \ge r \And x_t \ge \max\{x_s \,:\, s < t \text{ and } g_s = g_t\}$}{\label{algoline:better-than-best}
    \If(\tcp*[f]{\small compare in-group}){$t \ge \w N \And r_t=1$}{%\label{algoline:better-than-best}

        % \vspace{-0.4cm}
        
        \If(\tcp*[f]{\small check budget}){$B > 0$}{
            % \vspace{-0.4cm}
            Update budget: $B \gets B - 1$\;


            \If(\tcp*[f]{\small compare inter-group}){$R_t=1$}{\label{algoline:compare-inter-group}
            %\If(\tcp*[f]{\small compare inter-group}){$x_t \ge \max\{x_s \,:\, s < t \text{ and } g_s \neq g_t\}$}{\label{algoline:compare-inter-group}

            % \vspace{-0.4cm}
            
            Return: $t$ \;
            }
        }
        \Else
        {
        Return: $t$ \;} 
        % \EndIf
    }
}

\end{algorithm}

% For all $j \in \{1, 2\}$, we denote by $G^j$ all the observations that belong to the group $j$.
% Also, for any $t \geq 1$ and $j \in \{1, 2\}$, we denote by
% \begin{align*}
%     G^j_t &= \{ x_1, \ldots, x_t \} \cap G^j\enspace,
% \end{align*}
% the observations belonging to the group $j$ up to time $t$. 

% Observe first that $M^1$ and $M^2$ are updated during the algorithm for $i = r, \ldots, N$.
% We will denote them therefore $M^1_i$ and $M^2_i$, we have for any $r \leq i \leq \tau$ and $j \in \{1,2\}$
% \[
% M^j_i = \best G^j_i.
% \]

% We say that the algorithm \emph{succeeded} if it returns the best among all the candidates, otherwise it failed. Note that it is possible that the algorithm does not return any candidate. We consider that case a failure, and we say by convention that the stopping time of the algorithm is $\infty$.


\subsection{Analysis of the algorithm}
We estimate in this section the success probability of Algorithm \ref{algo:bench-algo}. The parameters of the algorithm are the total number of candidates $N$, the fraction of skipped candidates in the exploration phase $\w$, and the budget of comparisons $B$. 
% Let $P_B(\w N,N)$ denote the probability of success of Algorithm \ref{algo:bench-algo} for given parameters $\w,N,B$.
The main result of this section is concerned with the behavior of
\begin{align*}
    P_{N}^B(\alpha) \eqdef \Prob(\A(\w) \text{ succeeds})\enspace,
\end{align*}
where $\A(\w)$ is the Algorithm \ref{algo:bench-algo} with budget $B$ and exploration number $\w N$.

\begin{thm}\label{thm:lb-PB(s,N)}
Let $\w \in (0,1)$ and $N \in \mathbb{N}$ be such that $\frac{N}{\log N} \geq \frac{(1 + 1/\sqrt{\w})^2}{2\sqrt{\w}(1 - \lambda)^2}$.
% The success probability $P_B(\w N,N)$ of Algorithm \ref{algo:bench-algo} with budget $B$ satisfies
Then,
\begin{align*}
    P_{N}^B(\alpha) \geq P_{\infty}^B(\alpha) - K_{\lambda,\w,B} \sqrt{\frac{\log N}{N}}\enspace,
\end{align*}
% \[
%  P_B(\w N,N) 
%  \geq 
%  \w^2 \sum_{b=0}^B \left( \frac{1}{\w} - \sum_{\ell=0}^{b} \frac{\log(1/ \w)^\ell}{\ell !}   \right) 
% - K_{\lambda,\w,B} \sqrt{\frac{\log N}{N}}\enspace,
% \]
with
% $K_{\lambda,\w,B}$ being defined as
\begin{align*}
&P_{\infty}^B(\alpha) = \w^2 \sum_{b=0}^B \left( \frac{1}{\w} - \sum_{\ell=0}^{b} \frac{\log(1/ \w)^\ell}{\ell !}   \right) \,\text{ and }\,
K_{\lambda,\w,B} 
= \frac{\sqrt{2}(B+1)\log(1/ \w)}{\lambda(1-\lambda)} 
  {+} \frac{\e}{\sqrt{\w}} \sum_{b=0}^{B-1} \log(1/ \w)^b\enspace.
\end{align*}
\end{thm}
Let us comment on the above derived lower bound on the success probability of Algorithm \ref{algo:bench-algo}. The leading term depends neither on $N$ nor on $\lambda$ and, as it will be shown later, corresponds exactly to the asymptotic success probability of Algorithm \ref{algo:bench-algo} and it only depends on $\w$ and $B$---the maximization of the leading term in $\w$ does not require the knowledge of $\lambda$. The second term decreases in $N$ and essentially corresponds to the speed of concentration of $|G^1_t|$ around its mean. We additionally recall that both $\lambda$ and $B$ are assumed to be fixed constants that do not depend on $N$. 
The full proof of the above result is postponed to Appendix \ref{appx:bench-algo}, here we only give a sketch of the main steps.
\begin{proof}[Sketch of the proof]

% Theorem \ref{thm:lb-PB(s,N)}. It states that, for $N$ large enough, we have the lower bound
% \[
% P_B(\w N,N) 
% \geq \w^2 \sum_{b=0}^B \left( \frac{1}{\w} - \sum_{\ell=0}^{b} \frac{\ln(1/ \w)^\ell}{\ell !}   \right)
% - K_{\lambda,\w,B} \sqrt{\frac{\log N}{N}}\enspace,
% \]
% where $K_{\lambda,w,B}$ is a constant depending on $\lambda$, $\w$ and $B$.
We observe first that the times $\{ \rho_b \}_{b=1}^{B+1}$ from Definition \ref{def:rho_b} are such that for any $1 \leq b \leq B+1$
\begin{align*}
\rho_b = \min\left\{ t > \rho_{b-1} \mid  r_t = 1\right\}\enspace.
\end{align*}
with $\rho_0 \eqdef \w N$. These times are central in the analysis of Algorithm~\ref{algo:bench-algo} as they give a convenient decomposition of the success probability of the algorithm. In particular, we show that if $\tau$ is stopping time of Algorithm~\ref{algo:bench-algo}, then
% Let us now state some useful properties regarding the stopping time of Algorithm~\ref{algo:bench-algo}.
\begin{align}
    \label{eq:benchmark_prob_decomposition}
        P_{N}^B(\w) = \sum_{b=1}^{B+1} p_{N}^b(\w)\enspace,
\end{align}
where 
$p_{N}^b(\w) \eqdef \Prob (\tau = t^\star \text{ and } \tau = \rho_b)$ for any $1 \leq b \leq B+1$.\\
First we show that $p_{N}^1(\w) = \w - \w^2 + O(\sqrt{\log N / N})$ and that for $2 \leq b \leq B+1$
\[
p_{N}^b(\w) = \left(\w^2 N \sum_{i=r}^N \frac{1}{i^2} \sum_{s \leq t_1 < \ldots < t_{b-1} < i} \prod_{\ell=1}^{b-1} \frac{1}{t_\ell}\right)
+ O\left( \sqrt{\frac{\log N}{N}} \right)\enspace.
\]
Finally, a good estimation of the sum above gives the claimed result.
\end{proof}






\begin{remark}
While the previous theorem only establishes a lower bound of the form $P_{N}^B(\w) \geq P_{\infty}^B( \w) - O(\sqrt{\log N /N})$, one analogously obtains $P_{N}^B(\w) \leq P_{\infty}^B(\w) + O(\sqrt{\log N /N})$, implying that 
\[
\lim_{N \to \infty} P_{N}^B(\w) = P_{\infty}^B( \w)\enspace.
\]
In Theorem \ref{thm:asymptoticDDT}, we give a more general result which, in particular, gives an exact asymptotic expression of the success probability of the algorithm considered in this section.
% Note that the algorithm is not required to know $\lambda$ in order to choose a threshold value $\w$ maximizing its asymptotic success probability.
\end{remark}

\subsection{Lower bound for the success probability}


The final result of this section shows that Algorithm \ref{algo:bench-algo} has a success probability very close to the upper bound $1/\e$ with only a few comparisons when $N$ is high enough.

\begin{corollary}
\label{cor:success_proba_bound_budget}

Under the same assumptions of Theorem \ref{thm:lb-PB(s,N)}, the success probability of Algorithm~\ref{algo:bench-algo} with threshold $\w$ and $B$ comparisons satisfies
\begin{align*}
0\leq \frac{1}{\e} - \sup_{\w \in (0,1)}P^B_N(\w)
&\leq \frac{1}{\e(B+1)!} + K_{\lambda,B}\sqrt{\frac{\log N}{N}}\enspace.
% \\
% \frac{1}{\e} - \sup_{\w \in (0,1)} \tilde{P}_B( \w)
% &\leq \frac{1}{\e (B+1)!}\enspace.
\end{align*}
% On the other hand, non asymptotically, we have for $N$ large enough 
% \[
% \frac{1}{\e} - \sup_{\w \in (0,1)}P_B(\w N,N)
% \leq \frac{1}{e(B+1)!} + K_{\lambda,B}\sqrt{\frac{\log N}{N}},
% \]
where
$K_{\lambda,B} = 
\frac{\sqrt{2}(B+1)}{\lambda(1-\lambda)} + \e^{3/2}B$.
\end{corollary}

See full proof in Appendix \ref{appx:lower-bound-benchalgo}.

Although the success probability of Algorithm \ref{algo:bench-algo} with a good threshold choice converges very rapidly to $1/\e$, a weakness of the algorithm is that its asymptotic success probability does not take into account the distribution of the groups $\lambda$. Indeed, when $\lambda$ approaches $1$, one should be able to reach nearly the $1/\e$ success probability, since a naive algorithm that ignores the elements of group $G^2$ and uses the classical reject-accept strategy only on $G^1$ results in a success probability of $\lambda/\e$. Yet, even in the case $\lambda$ goes to $1$, the asymptotic success probability of Algorithm \ref{algo:bench-algo} stays away from $1/\e$. This intuition suggests an adaptation of the strategy presented in this part that is introduced and explored in the next section.





\section{Dynamic Double Threshold Algorithms}
\label{sec:DDT}

In Algorithm \ref{algo:bench-algo}, we fix a threshold $\w$ for both groups, starting from which we stop if a candidate is the best in its group. In this section, we define a more general class of algorithms termed as Dynamic Double Threshold (DDT) algorithms. Instead of one threshold for every group and every remaining budget, a different threshold is fixed for each group depending on the available budget. 
%We analyze the optimal thresholds choice and the asymptotic success probability of such algorithms for $B \in \{0,1\}$. In Section \ref{sec:memless} we will provide a dynamic programming approach to derive the optimal thresholds for $B \geq 2$.

A formal description can be found in Algorithm~\ref{algo:DDT} and the visual representation is provided in Figure~\ref{fig:DDT}.

\begin{figure}[!tbp]
  \centering
  % \begin{minipage}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{pics/dynamic_dta.pdf}
    \caption{Schematic description of DDT algorithm.}\label{fig:DDT}
\end{figure}


\begin{definition}[Dynamic Double Threshold (DDT) algorithm]
    An algorithm $\A$ for the 2-groups secretary problem with a budget of $B$ comparisons is said to be a dynamic double threshold algorithm if there exists $(\alpha_0, \beta_0), \ldots, (\alpha_B, \beta_B)$ such that at any step $t \in \{1,\ldots,N\}$, if $x_t$ is the best candidate in its group so far, and if $\A$ still has a budget of $b > 0$ comparisons left at that step, then it compares $x_t$ to the best candidate in the other group only if $g_t = 1$ and $t \geq \alpha_b N$, or $g_t = 2$ and $t \geq \beta_b N$. If $x_t$ wins this comparisons then $\A$ returns $x_t$.
    The DDT algorithm with thresholds $(\alpha_b, \beta_b)_{b = 0}^B$ is denoted by
    % \[
    $\A\left((\alpha_b, \beta_b)_{b = 0}^B \right)$.
    % \]
\end{definition}


Before analyzing the family of DDT algorithms and presenting the main results of this section, let us introduce key quantities that will guide our analysis.
For all $B \geq 0$ and all $(\alpha_b, \beta_b)_{b = 0}^B$ set
\begin{align}
    \label{eq:phi_function}
\varphi_B\left(w; (\alpha_b, \beta_b)_{b = 0}^B\right) \eqdef \lim_{N \to \infty} \Prob\big(\A((\alpha_b, \beta_b)_{b = 0}^B) \text{ succeeds} \mid \comp_1 \geq w N \big)\enspace,
\end{align}
where we recall that $\comp_1$ is from Definition~\ref{def:rho_b}. Note that at this point it is not clear that the above limit should or does exist. Yet, if the above-defined limit exists for $w = 0$, then
\begin{align*}
    \Prob\big(\A((\alpha_b, \beta_b)_{b = 0}^B)  \text{ succeeds}\big) = \varphi_B\left(0; (\alpha_b, \beta_b)_{b = 0}^B\right)\enspace.
\end{align*}
We will analyze the above-defined functions recursively, by introducing the second object of interest for all $\alpha \leq \beta$ as
% is similar to the one studied in \cite{pmlr-v139-correa21a} in the case of two groups.
\begin{equation}
    \label{eq:g_function}
\begin{aligned}
    &g_0(\alpha, \beta) = \lambda \alpha\log(\beta/\alpha) + \alpha(1 - \beta)\enspace,\\
    &g_B(\alpha, \beta) = g_0(\alpha, \beta)+ (1 {-} \lambda) \alpha  \int_{\alpha}^\beta \frac{\phi_{B-1}\left(u ; (\alpha_b, \beta_b)_{b=0}^{B-1}\right)}{u^2} \diff u {+} \alpha\beta \int_{\beta}^1 \frac{\phi_{B - 1}\left(u ; (\alpha_b, \beta_b)_{b=0}^{B-1}\right)}{u^3} \diff u\enspace,
\end{aligned}
\end{equation}
for $B \geq 1$.

% which will play a crucial role in expressing the success probability of any DDT algorithm for $B=0$, as well as will appear in the study of a more general case $B \geq 1$. The secon quantity of interest is defined 


% For fixed parameters $\alpha_1 \leq \beta_b$ and $B = 1$, the algorithms $\A(\alpha_1, \beta_1)$ has three stages: i) if $t < \alpha_1 N$, as in the usual secretary problem, the algorithms skips these candidates no matter their group membership; ii) if $t \in [\alpha_1 N, \beta_1 N)$ the algorithm can only select a candidate from group $1$ if $x_t$ is better than all previously seen candidates from group $1$ and then comparing to the best seen from the group $2$ (in this latter case we use the assigned budget and set $B = 0$); iii) if no candidate were selected in the previous stages and $B = 1$, for $t \in [\beta_1 N, N]$ candidates from either groups can be selected again by first making sure that they are the best among already seen candidates of their group and then comparing them to the best candidate of the opposite group.
% We give below the pseudo-code for $\A((\alpha_b, \beta_b)_b)$.
\begin{algorithm}[t]
\DontPrintSemicolon 
\caption{Dynamic Double Therehols $\A((\alpha_b, \beta_b)_b)$}\label{algo:DDT}
\SetKwInput{Input}{Input}
   \SetKwInOut{Output}{Output}
   \SetKwInput{Initialization}{Initialization}
   \Input{Available budget $B$, thresholds $(\alpha_b, \beta_b)_{b = 0}^B$}
   \Initialization{$B_0 = B_1 = B$, $N_0^1 = 0$, $N_0^2 = 0$, $s_b^1 = \alpha_b N$, $s_b^2 = \beta_b N$}
\For{$t=1,\ldots,N$}{

    Receive new observation: $(r_t, g_t) \in  \{1, \ldots, t\} \times \{1, 2\}$
    
    % Set: $N_t^{g_t} \gets N_{t-1}^{g_t} + 1$ \;
    
    \If(\tcp*[f]{\small compare in-group}){$t \geq s_{B_t}^{g_t} \And r_t = 1$}{%\label{algoline:better-than-best}

        % \vspace{-0.4cm}
        
        \If(\tcp*[f]{\small check budget}){$B > 0$}{
            % \vspace{-0.4cm}
            Update budget: $B_t \gets B_{t-1} - 1$\;
            
            \If(\tcp*[f]{\small compare inter-group}){$R_t = 1$}{

            % \vspace{-0.4cm}
            
            Return: $t$ \;
            }
        }
        \Else
        {
        Return: $t$ \;} 
        % \EndIf
    }
}
\end{algorithm}


\subsection{No comparisons allowed: two-colored secretary}


In this section, we analyze DDT algorithm in the case of no-comparisons, i.e., $B=0$. This particular setup falls into the multi-colored secretary problem with two colors introduced by~\citet{pmlr-v139-correa21a}. While it is only a particular case we further study, we need to extend the main results of~\citet{pmlr-v139-correa21a}, which were announced but proofs were not provided.

The next theorem has been already announced by~\citet{pmlr-v139-correa21a}. At the time of writing, the proof has not been made public though. We provide the proof in the appendix, along with a useful extension that will be needed later. 
\begin{thm}\label{thm:prob-win0}
    If $\alpha_0 \leq \beta_0$, then
    \[
    \lim_{N \to \infty}\Prob( \A(\alpha_0 , \beta_0 ) \text{ succeeds}) = g_0(\alpha_0, \beta_0)\enspace.
    \]
    Furthermore, if $\lambda = \Prob(g_t = 1) \geq 1/2$, then the optimal thresholds are
    \[
    \alpha_0^\star = \lambda \exp\left( \frac{1}{\lambda} - 2\right)
    \quad \text{ and } \quad
    \beta_0^\star  = \lambda\enspace,
    \]
    and 
    \[
    \lim_{N \to \infty}\Prob( \A(\alpha_0^\star , \beta_0^\star ) \text{ succeeds}) = \lambda^2 \exp\left( \frac{1}{\lambda} - 2\right)\enspace.
    \]
\end{thm}

See proof in Appendix \ref{appx:DDT-0}.\\

% \begin{remark}
% The above statement relies on the claim of
% \citet{pmlr-v139-correa21a} who establish that $\A(\alpha_0^\star, \beta_0^\star)$ is an overall optimal algorithm. The proof of this result was left for the complete version of the paper and, by the time of writing of the present work, was still not published.
% For our purposes, we only need the optimality of $\A(\alpha_0^\star, \beta_0^\star )$ among the DDT algorithms and the proof is provided in appendix.\\
% \end{remark}

Although $\alpha^\star_0, \beta^\star_0$ are functions of $\lambda$, they are lower bounded by $1/\e$, thus it is not necessary to know the value of $\lambda$: it can observe the first $N/\e$ candidates, estimate $\bar{\lambda}_N \eqdef \lvert G^1_{N/\e} \rvert / N$ and then fix the thresholds $\alpha^\star_0(\bar{\lambda}_N), \beta^\star_0(\bar{\lambda}_N)$, which will asymptotically converge to the optimal ones.

The above result gives the asymptotic success probability of any DDT algorithm with $B=0$, yet, in order to generalize it to the case $B \geq 1$, we need a stronger statement that will eventually allow us to recursively relate the success probability of $\A((\alpha_b, \beta_b)_{b=1}^B)$ to $\A((\alpha_b, \beta_b)_{b=1}^{B-1})$. The following proposition introduces the required quantity and is a strict generalization of the result of~\cite{pmlr-v139-correa21a}. 

\begin{proposition}\label{prop:asymptoticDDT0}
For any $\alpha_0, \beta_0 \in (0,1)$, let $\tau$ denote the stopping time of $\A(\alpha_0, \beta_0)$, then for any $w \in (0,1)$, $\varphi_0(w; (\alpha_0, \beta_0))$ defined in Eq~\eqref{eq:phi_function} exists.
% \[
% \varphi_0(w; (\alpha_0, \beta_0)) \eqdef \lim_{N \to \infty} \Prob(\A_2(\alpha_0, \beta_0) \text{ succeeds} \mid \rho_1 \geq w N)
% \]
% exists.
Furthermore, if $\alpha_0 \leq \beta_0$, then for any $w \in (0, 1]$
\[
\varphi_0(w; (\alpha_0, \beta_0))
= \left\{
    \begin{array}{ll}
        g_0(\alpha_0, \beta_0) & \mbox{if } w < \alpha_0\\
        g_0(w, \beta_0) & \mbox{if } \alpha_0 \leq w < \beta_0 \\
        g_0(w, w) & \mbox{otherwise}
    \end{array}\enspace,
\right.
\]
where $g_0$ is defined in Eq.~\eqref{eq:g_function}.
\end{proposition}

See proof in Appendix \ref{appx:DDT-0}.\\

% Note that the previous proposition immedietely implies the result of Theorem~\ref{thm:prob-win0} by simply evaluating and maximizing $\varphi_0(0; (\alpha_0, \beta_0))$.





\subsection{General case: budget of $B \geq 1$ comparisons}
% Previous subsection served as the base case for consequently expressing $\phi_B$ in terms of $\phi_{B-1}$.
In this section, we show that $\phi_B$ can be expressed via $\phi_{B-1}$, hence handling the case of general $B \geq 0$ and providing a recursive formula to compute the asymptotic success probability of any DDT algorithm.

% We will show in this section that, if we denote $\rho_1$ the time when $\A((\alpha_b, \beta_b)_{b=0}^B)$ makes the first comparison, then when $N \to \infty$, the success probability of  $\A_2((\alpha_b, \beta_b)_{b=0}^B)$ conditionally to $\rho_1 \geq wN$ converges to a piece-wise $C^1$ function of $w$, depending on $B$ and the parameters $(\alpha_b, \beta_b)_{b=0}^B$, that we denote $\varphi_B((\alpha_b, \beta_b)_{b=0}^B; w)$. Moreover, we give a recursive formula in $B$ to explicitly compute this function. The asymptotic success probability of a $\A(\{\alpha_b, \beta_b\}_{b=0}^B)$ can thus be deduced as $\varphi_B((\alpha_b, \beta_b)_{b=0}^B;0)$. In particular, the asymptotic success probability of the benchmark algorithm \ref{algo:bench-algo} can be found if we attribute the same value $\w$ to all the thresholds.

\begin{thm}\label{thm:asymptoticDDT}
For any $B \geq 1$, $(\alpha_b, \beta_b)_{b=0}^B$, any $w \in (0,1]$, $\varphi_B\left(w  ; (\alpha_b, \beta_b)_{b=0}^B\right)$ defined in Eq.~\eqref{eq:phi_function} exists, is continuous and piece-wise $\mathcal{C}^1$ on $(0,1]$.
% \[
% \varphi_B\left(w  ; (\alpha_b, \beta_b)_{b=0}^B\right) \eqdef \lim_{N \to \infty} \Prob\left(\A\left((\alpha_b, \beta_b)_{b=0}^B\right) \text{ succeeds} \mid \rho_1 \geq w N \right)
% \]
% exists, is a function of the variable $w$ and the parameters $B$ and $(\alpha_b, \beta_b)_{b=0}^B$, is continuous and piece-wise $\mathcal{C}^1$ on $(0,1]$.
Furthermore, for all $B \geq 1$ if $\alpha_B \leq \beta_B$, then for any $w \in (0,1]$
\[
\varphi_B\left(w  ; (\alpha_b, \beta_b)_{b=0}^B\right)
=\left\{
    \begin{array}{ll}
        g_B(\alpha_B, \beta_B) &\text{if } w < \alpha_B,\\
        g_B(w, \beta_B)  & \mbox{if } \alpha_B \leq w < \beta_B\\
        g_B(w, w) & \mbox{otherwise}
    \end{array}\enspace.
\right.
\]
with $g_B$ being defined in Eq.~\eqref{eq:g_function}.
% where
% \[
% g_B(w) = \lambda \log \beta_B 
% - (1-\lambda) \int_{\beta_B}^{1} \frac{\varphi_{B-1}(u)}{u^2}du
% + \beta_B \int_{\beta_B}^1 \frac{\varphi_{B-1}(u)}{u^3}du,
% \]
% and
% \[
% h_B(w) = \lambda w \log \frac{1}{w} + w + (1-\lambda)w \int_w^{1} \frac{\varphi_{B-1}(u)}{u^2}du.
% \]
% $\varphi_0$ is defined in Proposition \ref{prop:asymptoticDDT0}.
\end{thm}
Note that by setting all the thresholds to the same value $\w \in (0,1)$, we find a recursion to which the solution for any $B$ is the function $\Prob^B_{\infty}(\w)$ defined in Theorem \ref{thm:prob-win0}.
\begin{proof}[Sketch of the proof]
The full proof of Theorem \ref{thm:asymptoticDDT} is given in Appendix \ref{appx:DDT-B}, here we provide the main ideas that are used.
Without loss of generality, we assume in the following that $\alpha_B \leq \beta_B$. Indeed, if $\beta_B \leq \alpha_B$ then we obtain the same results replacing $\lambda$ by $1-\lambda$ by the symmetry of the roles played by $G^1, G^2$.
To lighten the notations we fix $B \geq 1$ and $(\alpha_b, \beta_b)_{b=0}^B$ and for each $b \leq B$ we denote $\A^b$ the algorithm $\A((\alpha_\ell, \beta_\ell)_{\ell=0}^b)$ with the initial budget $b$. We also simply write $\varphi_b(w)$ instead of $\varphi_b(w; (\alpha_\ell, \beta_\ell)_{\ell=0}^b)$. For any $1 \leq t \leq N$ and $0 \leq b \leq B$ let
\[
\rd^b_{N,t} \eqdef \Prob(\A^b \text{ succeeds} \mid \rho^b_1 \geq t)\enspace,
\]
where $\rho_1^b$ is, as in Definition \ref{def:rho_b}, the first time when $\A^b$ uses a comparison, with the convention $\rho_1 = \tau$ for $\A^0$.
The key argument of the proof is that knowing $\{\rho_1^B \geq wN\}$, and conditioning on the position of $\rho_1^B$, we obtain that for any $w \in [\alpha_B,\beta_B)$
\begin{align*}
\rd^B_{N,wN}
=& \lambda w \log\frac{\beta_B}{w} + w(1 - \beta_B)
+ (1-\lambda)w \left(\frac{1}{N} \sum_{t=wN}^{\beta_B N}
        \frac{\rd^{B-1}_{N,t+1}}{(t/N)^2}\right)\\
&\quad + w\beta_B \left(\frac{1}{N} \sum_{t=\beta_B N + 1}^{N} \frac{\rd^{B-1}_{N,t+1}}{(t/N)^3}\right)
+ O\left( \sqrt{\frac{\log N}{N}}\right)\enspace,
\end{align*}
and for any $w \in [\beta_B, 1]$
\[
\rd^B_{N,wN}
= w - w^2 + w^2 \left( \frac{1}{N}\sum_{t=wN}^{N} \frac{\rd^{B-1}_{N,t+1}}{(t/N)^3} \right) + O\left( \sqrt{\frac{\log N}{N}}\right)\enspace.
\]
Then by induction over $B$ and using convergence properties of Riemann sums we find the claimed result. 
\end{proof}



\subsection{Lower bound and optimal thresholds}
In the following Proposition we give a lower bound for the success probability of a DDT algorithm with optimal thresholds, i.e maximizing the asymptotic success probability.

\begin{proposition}\label{prop:lb-optDDT}
If $B \geq 0$ and $\A((\alpha^\star_b, \beta^\star_b)_{b=0}^B)$ is a DDT algorithm with optimal thresholds then 
\[
\lim_{N \to \infty} \Prob\left( \A\left((\alpha^\star_b, \beta^\star_b)_{b=0}^B \right) \text{ succeeds}\right)
\geq \frac{1}{\e}
- \min\left\{ \frac{1}{\e(B+1)!}\, , \, \frac{\lambda(1-\lambda)}{2} \right\}\enspace.
\]
\end{proposition}
See proof in Appendix \ref{appx:lb-optDDT}

Although the lower bound above seems to be strong, it is not tight. Indeed, the above result is obtained by comparing the case where all the thresholds are set to the same value $1/\e$ and the case where the budget is null. While the recursive expression on the success probability gives a way to numerically compute the optimal thresholds, it is still unclear if they are universal and do not depend on the initial budget $B$.


For any $B \geq 0$, let $(\alpha^B_b, \beta^B_b)_{b=0}^B$ be some optimal choice of thresholds, i.e
\[
(\alpha^B_b, \beta^B_b)_{b=0}^B
\in \argmax_{(\alpha_b, \beta_b)_{b=0}^B} \varphi_B\left(w;(\alpha_b, \beta_b)_{b=0}^B\right) \enspace.
\]
For $B = 0$, Proposition \ref{prop:DDT0-optanyw} establishes that the optimal thresholds $\alpha^0_0, \beta^0_0$ maximize the mapping $(\alpha, \beta) \mapsto \varphi_0(w; (\alpha, \beta))$. This implies that if $B=1$, we have
\begin{align*}
\varphi_1(0;(\alpha^1_b, \beta^1_b)_{b=0,1})
&= g_0(\alpha^1_0, \beta^1_0)+ (1 - \lambda) \alpha^1_1 \int_{\alpha^1_1}^{\beta^1_1} \frac{\phi_{0}\left(u ; (\alpha^1_0, \beta^1_0)\right)}{u^2} \diff u {+} \alpha^1_1\beta^1_1 \int_{\beta^1_1}^1 \frac{\phi_{0}\left(u ; (\alpha^1_0, \beta^1_0) \right)}{u^3} \diff u\\
&\leq g_0(\alpha^0_0, \beta^0_0)+ (1 - \lambda) \alpha_1 \int_{\alpha_1}^{\beta_1} \frac{\phi_{0}\left(u ; (\alpha^0_0, \beta^0_0)\right)}{u^2} \diff u {+} \alpha_1\beta_1 \int_{\beta^1_1}^1 \frac{\phi_{0}\left(u ; (\alpha^0_0, \beta^0_0) \right)}{u^3} \diff u\\
&= \varphi_1(0;(\alpha^0_0, \beta^0_0), (\alpha^1_1, \beta^1_1))\enspace.
\end{align*}
Thus, the thresholds $((\alpha^0_0, \beta^0_0), (\alpha^1_1, \beta^1_1))$ are also optimal. We can prove by induction that for any $B \geq 0$, replacing $(\alpha^B_0, \beta^B_0)$ by $(\alpha^0_0, \beta^0_0)$ can only increase the success probability, deducing that optimal values $\alpha_0, \beta_0$ can be chosen independently of the initial budget.


Deriving this property for any $b \geq 1$ is more challenging. The main difficulty lies in the increasing complexity of functions $g_b$ compared to $g_0$. Nevertheless, numerical simulations show that indeed the optimal thresholds are independent of the initial budget, i.e., if $B_1 < B_2$ and if we replace the $B_1$ first optimal thresholds $(\alpha^{B_2}_b, \beta^{B_2}_b)_{b=0}^{B_1}$ for initial budget $B_2$ by $(\alpha^{B_1}_b, \beta^{B_1}_b)_{b=0}^{B_1}$ then the obtained family of thresholds is also optimal.
% Proving a similar property for any $b$ turns out to be difficult because the functions $g_b$ for $b \geq 1$ are way more complex than $g_0$, but numerically computing the optimal thresholds shows that indeed, if $B_1 < B_2$ and if we replace the $B_1$ first optimal thresholds $(\alpha^{B_2}_b, \beta^{B_2}_b)_{b=0}^{B_1}$ for initial budget $B_2$ by $(\alpha^{B_1}_b, \beta^{B_1}_b)_{b=0}^{B_1}$ then the obtained family of thresholds is also optimal.\\
If supported by theoretical analysis, the above would imply optimal thresholds $(\alpha^\star_b, \beta^\star_b)_{b\geq 0}$ can be obtained by setting $(\alpha^\star_0, \beta^\star_0)$ as in Proposition \ref{prop:asymptoticDDT0}, then for any $B \geq 1$ computing
\[
(\alpha^\star_B, \beta^\star_B) \in 
\argmax_{(\alpha_B, \beta_B)} \varphi_B\big{(}w;((\alpha^\star_b, \beta^\star_b)_{b=0}^{B-1}, (\alpha_B, \beta_B))\big{)} \enspace.
\]
Theoretically, and practically, the above characterization of the optimal thresholds is much simpler and more convenient. The rigorous analysis of this phenomenon is left for future work.


\section{Optimal Memory-less Algorithm}\label{sec:memless}
Proposition \ref{prop:lb-optDDT} shows that, with well-chosen thresholds, DDT algorithms can be very efficient and have an asymptotic success probability that converges rapidly to $1/\e$ when the budget $B$ increases or $\lambda$ approaches $1$. However, we do not have any guarantees on the performance of these algorithms when the number of candidates is finite. Furthermore, we can hope to find other algorithms that are better asymptotically. 
Providing a general study of the overall optimal algorithm is a very challenging task due to the potential ability of an optimal algorithm to take the whole history of comparisons into account. Yet, by eliminating such intricate dependency on the past, it becomes possible to derive an optimal algorithm. In this section, we consider a family of memory-less algorithms, which, in particular, include the DDT family, that prohibits the use of the information from previous comparisons and their results. We demonstrate a dynamic programming approach that yields a finite $N$ optimal algorithm in this class.,
% because, for taking an optimal action at some step $t$, the history of all the past observations and the results of past comparisons might be taken into account. we consider in this section the family of what we call memory-less algorithms, which includes DDT algorithms, and we propose a dynamic programming approach to derive an optimal algorithm in this class. 
% An algorithm is said to be memory-less if it makes decisions that do not depend on the history of past comparisons and their results.
More formally, the only information available to a memory-less algorithm at step $t$ is $(N^1_{t-1},B_t,g_t,r_t,R_t)$, where $N^1_{t-1}$ is the number of candidates up to step $t-1$ belonging to $G^1$, $B_t$ is the comparisons budget, $g_t$ is the group of the candidate such that $x_t \in G^{g_t}$, and $r_t, R_t$ defined in \ref{eq:def-zt}. The latter overall rank is available only if the algorithm uses a comparison. The formal definition is provided below.


\begin{definition}[Memory-less algorithm]\label{def:memless}
We say that an algorithm $\A$, that follows Protocol~\ref{algo:general}, with the stopping time $\tau$ is memory-less if for any $t \in \{1, \ldots, N\}$, the distribution $Q_{t,1}$ of $\act_{t, 1}$ is $(N^1_{t-1},B_t, g_t, r_t)$-measurable and the distribution $Q_{t,2}$ of $\act_{t, 2}$ is $(N^1_{t-1},B_t, g_t, r_t, R_t)$-measurable given that $\act_{t,1} = \acomp$.
\end{definition}
We remark that a memory-less algorithm knows the number of candidates $N$ and is aware of the current step $t$ at any time.
In the following proposition we show that if a memory-less algorithm $\A$ does not stop at candidate $x_{t-1}$ and moves to step $t$, then knowing the available budget $B_{t}$ and the number of candidates in each group so far, its success probability is independent of all the past observations and actions. In other words, the state of the algorithm at step $t$ is fully determined by the triplet $(B_t, N^1_t, N^2_t)$, independently of the relative ranks of the past candidates and of their groups.


\begin{proposition}\label{prop:success-memless-skip}
Let $\A$ be a memory-less algorithm with stopping time $\tau$. Let $2 \leq t \leq N$ and $\F_t$ be the history of the algorithm up to $t$, then we have
\[
\Prob(\A \text{ succeeds} \mid \tau \geq t, \F_{t-1}) = \Prob(\A \text{ succeeds} \mid \tau \geq t, B_{t}, N^1_{t-1})\enspace,
\]
Where $B_t$ is the budget available at time $t$ and $N^1_{t-1} \eqdef |G^1_{t-1}|$.
\end{proposition}
See proof in Appendix \ref{appx:memless}.

Finally, we end this part with the proposition that shows that the family of DDT algorithms is included in the family of memory-less algorithms.
\begin{proposition}
DDT algorithms are memory-less.
\end{proposition}
\begin{proof}
From the description of the dynamic-double-threshold algorithms, we have immediately that the decision taken at step $t$ only depends on the thresholds $(\alpha_b, \beta_b)_{b=0}^B$ which are constants, on the current time step $t$, and on the random variables $r_t, R_t, B_t$.
\end{proof}




\subsection{Non-asymptotic optimal algorithm via dynamic programming}\label{sec:opt-dynprog}
We prove in this section a dynamic programming formula to compute the success probability of the optimal memory-less algorithm and allowing to derive the optimal action at each step depending on $B_t, N^1_t$ and on the group and the relative rank of the current candidate.

Let $\A$ be any memory-less algorithm for the 2-groups secretary problem. During the online observation of the candidates, using Proposition \ref{prop:success-memless-skip}, we have that the state of the algorithm is fully determined by the triplet $(t,B_t, N^1_{t-1})$. For any non-negative integer $b$, any $1 \leq t \leq N$ and $m \leq t-1$, define
\[
\rwd^b_{t,m}(\A)
\eqdef \Prob(\A \text{ succeeds} \mid \tau \geq t, B_t = b, N^1_{t-1} = m)\enspace.
\]
The proofs of the following results are to be found in Appendix \ref{appx:opt-dynprog}

\begin{proposition}\label{prop:dynprog0}
If $B=0$, then for any memory-less algorithm $\A$, all $t = 1, \ldots, N$,  $m = 0 ,\ldots, t-1$ 
\begin{align*}
\rwd^0_{t,m}(\A)
&\leq \lambda \max\left\{  
    \rwd^0_{t+1,m+1}(\A),\, \frac{1}{N} + \left(1 - \frac{1}{1+m} \right) \rwd^0_{t+1,m+1}(\A)\right\}\\
&\quad + (1 - \lambda) \max\left\{  
    \rwd^0_{t+1,m}(\A),\, \frac{1}{N} + \left(1 - \frac{1}{t-m} \right) \rwd^0_{t+1,m}(\A)\right\}\enspace,
\end{align*}
with $\rwd^0_{N+1,m}(\A) = 0$ for any $m=0, \ldots,N$.
\end{proposition}





\begin{corollary}\label{cor:optAction0}
If at some step $t$ we have $B_t=0$, the optimal memory-less stopping rule $\tau^\star$ is 
\[
\tau^\star 
= \min \left\{s \geq t \mid r_s = 1 \text{ and }  N \rwd^0_{s+1, N^1_s} \leq N^{g_s}_s \right\}\enspace.
\]
Using this rule, the inequality in the previous proposition becomes an equality.
\end{corollary}

\begin{proposition}\label{prop:dynprogb}
If $B \geq 1$, then for any memory-less algorithm $\A$, any $b=0,\ldots,B$, $t = 1,\ldots,N$, and $m = 1\ldots, t-1$ 
\begin{align*}
\rwd^b_{t,m}(\A)
\leq\, & \lambda \max\left\{
\rwd^{b}_{t+1, m+1}(\A),\,
\frac{1}{N} + \left(\frac{1}{m+1} - \frac{1}{t} \right)
\rwd^{b-1}_{t+1, m+1}(\A)
+ \left(1 - \frac{1}{m+1} \right) 
\rwd^{b}_{t+1, m+1}(\A)
\right\}\\
&+ (1 - \lambda) \max\left\{
\rwd^{b}_{t+1, m}(\A),\,
\frac{1}{N} + \left(\frac{1}{t-m} - \frac{1}{t} \right)
\rwd^{b-1}_{t+1, m}(\A)
+ \left(1 - \frac{1}{t-m} \right) 
\rwd^{b}_{t+1, m}(\A)
\right\}\enspace,
\end{align*}
with $\rwd^b_{N+1,m}(\A) = 0$ for any $m=0, \ldots, N$. 
% \ref{prop:dynprog0}
\end{proposition}

\begin{corollary}\label{cor:optActionB}
if at step $t$ we have $B_t = b > 0$, then the optimal memory-less policy is to skip all candidates until
\[
\rho \eqdef \min \left\{s \geq t \mid 
r_s = 1 \text{ and }
\rwd^{b}_{s+1, N^1_s}
- \left(1 - \frac{N^{g_s}_s}{s} \right) \rwd^{b-1}_{s+1, N^1_s}
<
\frac{ N^{g_s}_s}{N}
\right\}\enspace,
\]
then use comparison to observe $R_\rho$, if is equal to $1$ then stop at $\rho$, otherwise repeat the same process.\\
Again, using this rule, the inequality in the previous proposition becomes an equality.
\end{corollary}

% \begin{remark}
Note in the two Corollaries \ref{cor:optAction0} and \ref{cor:optActionB} that playing the optimal action at each step requires knowing $\lambda$, because it is used to compute the values $(\rwd^b_{t,m})_{b,t,m}$.
The strength of this algorithm is that it makes optimal actions for a finite number of candidates and using Propositions \ref{prop:dynprog0} and \ref{prop:dynprogb} we can compute its exact success probability for any $N$, which is not the case for DDT algorithms since we only have asymptotic results. 
% \end{remark}
Using Corollaries \ref{cor:optAction0} and \ref{cor:optActionB}, the optimal memory-less algorithm is presented in Algorithm~\ref{algo:opt-memless}.

\begin{algorithm}
\DontPrintSemicolon 
\caption{Optimal memory-less algorithm}\label{algo:opt-memless}
\SetKwInput{Input}{Input}
   \SetKwInOut{Output}{Output}
   \SetKwInput{Initialization}{Initialization}
   \Input{The table $(\rwd^b_{t,m})_{b \leq B, 0 \leq m < t \leq N}$ as defined in Propositions \ref{prop:dynprog0} and \ref{prop:dynprogb}.}
   \Initialization{budget $B_0 = B$, $N_0^1 = 0$, $N_0^2 = 0$, $s_b^1 = \alpha_b N$, $s_b^1 = \beta_b N$}
\For{$t=1,\ldots,N$}{

    Receive new observation: $(r_t, g_t) \in  \{1, \ldots, t\} \times \{1, 2\}$
    
    Set: $N_t^{g_t} \gets N_{t-1}^{g_t} + 1$ \;
    
    \If(\tcp*[f]{\small compare in-group}){$r_t = 1$}{%\label{algoline:better-than-best}

        % \vspace{-0.4cm}
        
        \If(\tcp*[f]{\small Corollary \ref{cor:optActionB}}){$B > 0 \text{ and } \rwd^{B_t}_{t+1, N^1_t} - (1 - N^{g_t}_t/t ) \rwd^{B_t-1}_{t+1, N^1_t}<\frac{N^{g_t}_t}{N}$}{
            % \vspace{-0.4cm}
                Update budget: $B_t \gets B_{t-1} - 1$\;
                % \vspace{-0.4cm}
                \If{$R_t = 1$}{
                    Return: $t$ \;
                }
        }
        \If(\tcp*[f]{\small Corollary \ref{cor:optAction0}}){$B = 0 \text{ and } \rwd^0_{t+1, N^1_t} \leq \frac{N^{g_t}_t}{N}$}{
            Return: $t$ \;
        } 
        % \EndIf
    }
}
\end{algorithm}




\subsection{Asymptotic behavior}\label{sec:opt-memless-asymptotic}
Algorithm \ref{algo:opt-memless}, although very efficient, presents a problem when the number of candidates is high. Indeed, the use of this algorithm requires computing of the table $(\rwd^b_{t,m})_{b,t,m}$ for $0 \leq b \leq B$ and $0\leq m \leq t \leq N$, which requires a $O(B N^2)$ time. This is why we will now try to understand how the algorithm behaves asymptotically. The rigorous justification of the intuition that we provide in this section is left for future works, however, we validate our intuition numerically in the experimental section. More precisely, in this section, we want to provide simple arguments that demonstrate that Algorithm \ref{algo:opt-memless}, derived from Corollaries~\ref{cor:optAction0} and~\ref{cor:optActionB}, behaves as an instance of the DDT family for large values of $N$. 

% Although a rigorous mathematical study is difficult, we will give elements to have some intuition on its behavior of the, and we will check later numerically that these intuitions are correct. Our claim is the following,\\

% \noindent
% \textbf{Claim.} When the number of candidates is very high, Algorithm \ref{algo:opt-memless} behaves like a DDT algorithm, 

%[ziy: This is not true] For $N$ being very high, the success probability of any DDT with a budget of $B$ comparisons is $\Phi_B(0)$, where
% For $N$ being very high, the success probability of Algorithm \ref{algo:opt-memless} with a budget of $B$ comparisons is $\Phi_B(0)$, where
% \[
% \Phi_0(1) = 0 
% \quad
% \text{ and } \quad
% \forall w \in (0,1]: \;
% -\Phi'_0(w) 
% = \left( \lambda - \frac{\Phi_0(w)}{w} \right)_+
% + \left( 1-\lambda - \frac{\Phi_0(w)}{w} \right)_+. 
% \]
% and for any $1 \leq b \leq B$, $\Phi_b$ is defined by $\Phi_b(1) = 0$ and $\forall w \in (0,1]: \;$
% \[
% -\Phi_b'(w)
% = \left( \lambda - \frac{\Phi_b(w) - (1-\lambda)\Phi_{b-1}(w)}{w} \right)_+
% + \left( 1-\lambda - \frac{\Phi_{b}(w) - \lambda \Phi_{b-1}(w)}{w} \right)_+.
% \]
% Moreover, the optimal DDT thresholds $\{\alpha_b, \beta_b\}_{b=0}^B$ are such that $\Phi_0(\alpha_0^\star) = \lambda \alpha_0^\star$, $\Phi_0(\beta_0^\star) = (1-\lambda) \beta_0^\star$ and for any $1 \leq b \leq B$
% \[
% \frac{\Phi_b(\alpha^\star_b) - (1-\lambda)\Phi_{b-1}(\alpha^\star_b)}{\alpha^\star_b}
% = \lambda
% \quad\text{and}\quad
% \frac{\Phi_b(\beta^\star_b) - \lambda\Phi_{b-1}(\beta^\star_b)}{\beta^\star_b}
% = 1 - \lambda\enspace.
% \]


First, note that the algorithm will not stop or use a comparison before $\Omega(N)$ steps, because if $k_N = o(N)$ then the probability of having the best candidate overall among the $k_N$ first ones is $k_N/N = o(1)$, thus it is futile to spend a comparison before observing at least some fraction $\varepsilon N$ of the candidates.
After $\varepsilon N$ steps, we have with high probability that $N^1_t = \lambda t + O(\sqrt{t}\log t )$ for any $\varepsilon N \leq t \leq N$, therefore we can say that $\rwd^b_{t,N^1_t} \approx \rwd^b_{t, \lambda t}$ that we will denote simply $\rwd^b_t$ for any $0 \leq b \leq B$. The recursion of Proposition \ref{prop:dynprog0} can be written as
\[
\frac{\rwd^0_t - \rwd^0_{t+1}}{1/N}
= \left( \lambda - \frac{\rwd^0_{t+1}}{t/N}\right)_{+}
+ \left( (1-\lambda) - \frac{\rwd^0_{t+1}}{t/N}\right)_{+}\enspace,
\]
where we denote $u_+ = \max\{0,u\}$. If we assume, as was the case for DDT algorithms, that $\rwd^0_t$ converges to some function $\Phi_0$ of $t/N$, then considering $w = t/N$ and $dw = 1/N$ the previous equation becomes
\begin{equation}\label{eq:Phi0}
-\Phi'_0(w) 
= \left( \lambda - \frac{\Phi_0(w)}{w} \right)_+
+ \left( 1-\lambda - \frac{\Phi_0(w)}{w} \right)_+.    
\end{equation}


\begin{figure}[!tbp]
  \centering
  % \begin{minipage}[b]{0.32\textwidth}
    \includegraphics[width=0.32\textwidth]{pics/success_proba_l=60.pdf}
    \hfill
    \includegraphics[width=0.32\textwidth]{pics/success_proba_l=75.pdf}
    \hfill
    \includegraphics[width=0.32\textwidth]{pics/success_proba_l=90.pdf}

    
    %\includegraphics[width=0.32\textwidth]{pics/success_ratio_l=60.pdf}
    %\hfill
    %\includegraphics[width=0.32\textwidth]{pics/success_ratio_l=75.pdf}
    %\hfill
    %\includegraphics[width=0.32\textwidth]{pics/success_ratio_l=90.pdf}
    \caption{Success probabilities for varying values of $\lambda$ of the optimal DDT and the benchmark algorithms.}\label{fig:lambda_changes}
\end{figure}


We can verify that this differential equation is also satisfied by $\varphi_0((\alpha_0^\star, \beta_0^\star);w)$ defined in Theorem \ref{thm:prob-win0} and $\alpha^\star_0, \beta^\star_0$ as in Proposition \ref{prop:DDT0-optanyw}. 
Furthermore, $\Phi_0(1) = 0$ because it is the asymptotic success probability when selecting the last candidate, hence $\varphi'_0((\alpha^\star_0, \beta^\star_0);w) = \Phi_0(w)$. When no comparisons are allowed, the optimal DDT algorithm is therefore asymptotically optimal over the class of all memory-less algorithms.

If we consider now $B \geq 1$, using the same approximations, Proposition \ref{prop:dynprogb}
\[
\frac{\rwd^b_t - \rwd^b_{t+1}}{t/N}
= \left( \lambda - \frac{\rwd^b_{t+1} - (1-\lambda)\rwd^{b-1}_{t+1}}{t/N} \right)_+
+ \left( 1-\lambda - \frac{\rwd^b_{t+1} - \lambda \rwd^{b-1}_{t+1}}{t/N} \right)_+\enspace.
\]
Assuming that $\rwd^b_{wN}$ converges to some function $\Phi_b(w)$, the previous identity becomes
\begin{equation}\label{eq:Phib}
-\Phi_b'(w)
= \left( \lambda - \frac{\Phi_b(w) - (1-\lambda)\Phi_{b-1}(w)}{w} \right)_+
+ \left( 1-\lambda - \frac{\Phi_{b}(w) - \lambda \Phi_{b-1}(w)}{w} \right)_+\enspace.
\end{equation}
This equation along with $\Phi_b(1) = 0$ defines a unique function. $\Phi_b$ is non-increasing because its derivative is non-positive, and solving the differential equation numerically, we observe that $(\Phi_b(w) - \Phi_{b-1}(w))/w$ is a decreasing function, and thus both functions $(\Phi_b(w) - \lambda \Phi_{b-1}(w))/w$ and $(\Phi_b(w) - (1-\lambda)\Phi_{b-1}(w))/w$ are decreasing. Hence, there exists $\alpha_b, \beta_b$ such that 
\[
\left\{
    \begin{array}{ll}
        \lambda - \frac{\Phi_b(w) - (1-\lambda)\Phi_{b-1}(w)}{w} \geq 0  &\iff w \geq \alpha_b,\\
        1-\lambda - \frac{\Phi_b(w) - \lambda\Phi_{b-1}(w)}{w} \geq 0 &\iff w \geq \beta_b\enspace, 
    \end{array}
\right.
\]

Using Corollary \ref{cor:optActionB}, if we have $r_t = 1$, then the optimal action is to use a comparison if 
\[
\frac{1}{t/N}\left(\rwd^{b}_{t+1, N^1_t}
- \left(1 - \frac{N^{1}_t}{t} \right) \rwd^{b-1}_{t+1, N^{g_t}_t}\right)
<
\frac{N^{g_t}_t}{t}\enspace.
\]
The above, asymptotically, considering that $g_t = 1$, becomes
\[
\frac{\Phi_b(w) - (1-\lambda)\Phi_{b-1}(w)}{w}
\leq \lambda\enspace.
\]
The optimal action when having a candidate that belongs to $G^1$ is thus to use a comparison if and only if $w \geq \alpha_b$ and similarly we obtain that the optimal action when having a candidate belonging to $G^2$ is to use a comparison if and only if $w \geq \beta_b$. With this being true for every $1 \leq b \leq B$ and with the explanations we gave in the case of $B=0$, we deduce that the optimal memory-less algorithm behaves asymptotically like a DDT algorithm and the obtained thresholds $\alpha_b, \beta_b$ are necessarily optimal since this is the optimal memory-less algorithm. In the next section, we provide numerical evidence supporting this analysis.


\section{Numerical experiments}
\label{sec:exps}

\begin{figure}[!tbp]
  \centering
  % \begin{minipage}[b]{0.32\textwidth}
    \includegraphics[width=0.32\textwidth]{pics/alphas_betas_l=6.pdf}
    \hfill
    \includegraphics[width=0.32\textwidth]{pics/alphas_betas_l=7.pdf}
    \hfill
    \includegraphics[width=0.32\textwidth]{pics/alphas_betas_l=8.pdf}
    

    \caption{Optimal thresholds $(\alpha_b^\star, \beta_b^{\star})$.}\label{fig:threhsolds}
\end{figure}




In this section, we provide some empirical illustrations comparing the optimal single threshold algorithm with the optimal dynamic double threshold algorithm. Furthermore, we investigate and highlight some interesting phenomena connected with the optimal thresholds $(\alpha_b^\star, \beta_b^\star)_{b = 1}^B$. 

Figure~\ref{fig:lambda_changes} displays the evolution of the asymptotical success probabilities of the benchmark and the optimal DDT algorithms with the growth of the available budget $B$ compared to the theoretical upper bound $1/\e$. The performances of the two algorithms are similar in the case of balanced groups and start to differ significantly as $\lambda$ increases, which is consistent with the derived theory. We also note that as the comparison budget increases both algorithms approach rapidly the theoretical maximum of $1/\e$ as highlighted in Corollary~\ref{cor:success_proba_bound_budget}. However, recall that the benchmark algorithm is oblivious to the group proportions, while choosing the best thresholds requires knowing $\lambda$.  





Given the above discussion, we move to a more detailed investigation of the optimal thresholds for the DDT algorithm and explain how they can be obtained without prior knowledge of $\lambda$. Figure~\ref{fig:threhsolds} displays the two optimal thresholds as a function of $b$ and different values of $\lambda \geq 1/2$. One can immediately observe two phenomena: the threshold $\beta^\star_b$ for the minority group remains larger than the standard $1/\e$ threshold and rapidly converges to it as $B$ increases; meanwhile, the threshold $\alpha^\star_b$ for the majority group displays two different behaviors depending on the actual value of $\lambda$---in the regime of moderate values of $\lambda$ (compared to $1/2$), $\alpha^\star_b$ behaves similarly to $\beta^\star_b$, while for high values of $\lambda$, $\alpha_b^\star$ is smaller than $1/\e$ (for $b \geq 1$) and converges to it as $B$ increases. In Figure~\ref{fig:threhsolds_alphas_betas}, we display a continuous evolution of $\alpha^\star_b$ (left) and $\beta^\star_b$ (right) as functions of $\lambda \geq 1/2$, again confirming the above discussion on the behavior of the two thresholds. 
Finally, although the optimal thresholds depend on $\lambda$, it is not necessary to know its value beforehand. In fact, we observe in Figure \ref{fig:threhsolds_alphas_betas} that the optimal thresholds are always lower bounded by $1/3$. Thus, the algorithm can observe the first $N/3$ candidates, then estimate the probability of belonging to group $G^1$ as $\hat{\lambda}_N \eqdef |G^1_{N/3}|/N$ and use this estimator in place of the true $\lambda$. Asymptotically this strategy yields the same success probability as if $\lambda$ was known.

Figure~\ref{fig:success} displays the success probability of the optimal dynamic double-threshold algorithm as a function of $\lambda \in (0, 1)$ and $4$ values of the available budget. These successes are symmetric about $1/2$ and converge rapidly to the theoretical upper bound of $1/\e$. We also emphasize the significant improvement of the optimal algorithm for $\lambda \gg 1/2$ (same for $\lambda \ll 1/2$) over $\lambda = 1/2$. The latter value of $\lambda$ corresponds to the benchmark algorithm which is oblivious to $\lambda$ by construction. 

\begin{figure}[h]
  \centering
  % \begin{minipage}[b]{0.32\textwidth}
    \includegraphics[width=0.48\textwidth]{pics/alphas_all.pdf}
    \hfill
    \includegraphics[width=0.48\textwidth]{pics/betas_all.pdf}

    \caption{Evolution of $(\alpha_b^\star, \beta_b^\star)$ as a function of $\lambda$.}\label{fig:threhsolds_alphas_betas}
\end{figure}


We also investigate how Algorithm \ref{algo:opt-memless}---the optimal memory-less algorithm---compares to the other ones.
Figure \ref{fig:acceptance_opt} shows the acceptance region (dark green) of the optimal algorithm, when $\lambda = 0.6$ and $B=0$, for $N = 50,1000$, i.e., the region where it will return a candidate if $r_t = 1$.
On the x- and y-axes we display the time $t$ and possible group cardinal $|G_t^{1 / 2}|$ up to time $t$ respectively. The latter follows binomial random distribution with parameters $(\lambda, t)$ and tightly concentrates around its mean $|G_t^{1}| \approx \lambda t$ (resp. $|G_t^{2}| \approx (1-\lambda) t$) for already moderate values of $t$.
% On the x-axis, we have the time $t$, while on the y-axis, we have the cardinal of the group $G^1_t$, which we recall is a Binomial random variable with parameters $(\lambda, t)$.
We first remark that the acceptance region depends on the group, since the group-membership is stochastic with parameter $\lambda$, the algorithm tries to sufficiently explore either of the groups.
% if at a given step $t$ we have for example $|G^1_t| = 0$ and the candidate who arrives at the next step is in the group $t$, the algorithm will not return it because it did not sufficiently observe the elements of this group yet.
% The same remark is valid for group $G^2$.
Then, let us observe that the shape of the acceptance region is almost identical for $N = 50$ and $N = 1000$, i.e., the curve defining this region converges rapidly to a curve that only depends on $(t/N, |G^1|/N)$.
% which is the consequence of the concentration properties of the binomial random variables.
% With this observation, as explained in Section \ref{sec:opt-memless-asymptotic},
% Then, let us notice that the acceptance region is almost defined by the same curve for $N = 50$ and $N = 1000$, i.e. the curve defining this region converges very quickly to a curve depending only on $t/N$. With this observation, as explained in Section \ref{sec:opt-memless-asymptotic},
As recalled above, when $N$ is very large we have that $|G^1_t| \approx\lambda t$, thus, the acceptance region is defined only by a threshold at the intersection of the acceptance curve and the line $|G^1_t| \approx\lambda t$.
Numerically, this intersection for $N=1000$ occurs for $t/N \approx 0.428$ for $G^1$, and $t/N \approx 0.598$ for $G^2$, while the optimal thresholds of the DDT algorithm, given by Proposition \ref{prop:asymptoticDDT0}, are respectively $\alpha_0^\star = 0.430$ and $\beta_0^\star = 0.6$.
% These two values are practically the same as the optimal thresholds highlighted in Proposition \ref{prop:asymptoticDDT0}: $\alpha_0 = \lambda \exp(1/l - 2) = 0.4299..., \beta_0 = 0.6$. 
A direct consequence of this observation is that the optimal threshold for any $\lambda$, any $b = 0, \ldots, B$, and any $g \in \{1,2\}$ can be estimated as the intersection of the acceptance region for $G^g$ and the line $(t,\lambda t)$, with $N = 500$ for example. 


Finally, Algorithm \ref{algo:opt-memless} remains more efficient than DDT algorithms when the number of candidates is limited. As shown in Figure \ref{fig:N-changes}, the success probability of Algorithm \ref{algo:opt-memless} is higher for small values of $N$ and it decreases to the optimal DDT Algorithm as $N$ growth. Its only inconvenience is that it requires knowing $\lambda$.




All in all, we can draw the following conclusions: If $\lambda$ is unknown, the benchmark algorithm, being simpler, can be applied in case $B$ is big enough, say for example $B \geq 3$; If $B$ is small, as $\lambda$ might depart significantly from the balanced case $\lambda \approx 1/2$, the optimal DDT algorithm should be preferred. In the case of known $\lambda$, if the number of candidates is limited, say for example $N \leq 1000$, the optimal memory-less algorithm is to be used, because its performance is better than that of DDT algorithms and because the table $(\rwd^b_{t,m})_{b,t,m}$ defined in Propositions \ref{prop:dynprog0} and \ref{prop:dynprogb} can be computed rapidly. If the number of candidates is high, then computing the previous table becomes heavy as it takes a $O(B N^2)$ time. In this case, using a DDT algorithm with optimal thresholds is advised, because it does not need any time-consuming pre-computations and it has a success probability almost equal to that of Algorithm \ref{algo:opt-memless}. 
%We also recall that neither of the two algorithms requires the knowledge of $\lambda$, thus, if no prior information on this value is available to the decision maker, the optimal algorithm should be always the default choice.


% \begin{figure}[!tbp]
%   \centering
%   % \begin{minipage}[b]{0.32\textwidth}
%     \includegraphics[width=0.32\textwidth]{pics/alphas_betas_l=70.pdf}
%     \hfill
%     \includegraphics[width=0.32\textwidth]{pics/alphas_betas_l=75.pdf}
%     \hfill
%     \includegraphics[width=0.32\textwidth]{pics/alphas_betas_l=80.pdf}

%     \caption{Non-monotone behavior of $\alpha_b^\star$.}\label{fig:threhsolds_alphas}
% \end{figure}




\begin{figure}[h]
  \centering
  % \begin{minipage}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{pics/success.pdf}

    \caption{Success probability of DDT algorithm with optimal thresholds for different $(B, \lambda)$.}\label{fig:success}
\end{figure}


\begin{figure}[t!]
    \centering
    \includegraphics[width=0.85\textwidth]{pics/acceptance_region_N50.pdf}
    \includegraphics[width=0.85\textwidth]{pics/acceptance_region_N1000.pdf}
    \caption{Acceptance regions of the optimal memory-less algorithm, with $\lambda = 0.6$, $B= 0$ and $N = 50, 1000$.}
    \label{fig:acceptance_opt}
\end{figure}




\section{Conclusion} In this work we have introduced and analyzed a partially-ordered secretary problem with permitting a limited budget of comparisons. Our results are of both asymptotic and non-asymptotic nature---we study the asymptotic behavior of the DDT family and provide an optimal memory-less non-asymptotic algorithm. The success probability of the former converges rapidly to the theoretical limit of $1/\e$, given a good choice of parameters. We have provided theoretical and empirical evidence that asymptotically the optimal algorithm belongs to the DDT family. Our work opens much interesting research directions. We plan to further strengthen our theoretical results, providing a more subtle study of the optimal thresholds of the asymptotically optimal DDT algorithm. Furthermore, we have considered the case of two groups and the generalization of our results to many groups with a non-zero budget can prove to be useful for more realistic setups.

\begin{figure}[h]
  \centering
  % \begin{minipage}[b]{0.32\textwidth}
    \includegraphics[width=0.325\textwidth]{pics/asympt_proba_optVsDDT_B0.pdf}
    \hfill
    \includegraphics[width=0.325\textwidth]{pics/asympt_proba_optVsDDT_B1.pdf}
    \hfill
    \includegraphics[width=0.325\textwidth]{pics/asympt_proba_optVsDDT_B2.pdf}
    \caption{Emprirical Success probabilities for $N \in \{2^k \mid 4 \leq k \leq 10 \}$ of optimal memory-less and optimal DDT algorithms, for $\lambda = 0.6$ and $B \in \{0,1,2\}$. The success probabilities were estimated over $5000000$ runs of both algorithms.}\label{fig:N-changes}
\end{figure}


\newpage
% Bibliography
\bibliographystyle{plainnat}
\bibliography{sample-bibliography}

\input{appendix}


\end{document}
