\section{Dynamic Threshold algorithm for $K$ groups}\label{sec:DT}
In this section, we introduce a general family of Dynamic-threshold ($\DT$) algorithms. 
A $\DT$ algorithm for the $(K,B)$-secretary problem is defined by a finite doubly-indexed sequence $(\w_{k,b})_{k \in [K],b \leq B}$ of non-negative numbers in $[0,1]$, which determines the \textit{acceptance} thresholds based on the group of the observed candidate and the available budget. During a run of the algorithm, the thresholds used for each group dynamically change depending on the evolution of the available budget.
We denote this algorithm by $\A^B\big((\w_{k,b})_{k \in [K],b \leq B}\big)$.

Upon the arrival of a new candidate $x_t$, the algorithm observes its group $g_t = k \in [K]$ and its in-group rank $r_t$, and has an available budget of $B_t = b \geq 0$. If $t/N < \w_{k,b}$ or $r_t = 0$, the candidate is immediately rejected. Otherwise, if $t/N \geq \w_{k,b}$ and $r_t = 1$, then the candidate is selected if $b=0$; and if the budget is not yet exhausted ($b>0$), then the algorithm pays a unit cost to observe the variable $\indic{R_t = 1}$. If this variable is $1$, indicating a favorable comparison, the candidate is selected; otherwise, it is rejected.


A formal description is given in Algorithm \ref{algo:DT}, and a visual representation for the case of two groups is provided in Figure \ref{fig:DTviz}.






\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figs/DTviz.pdf}
    \caption{Schematic description of a DT algorithm in the case of 3 groups}
    \label{fig:DTviz}
\end{figure}


\begin{algorithm}[h!]
\DontPrintSemicolon 
\caption{Dynamic-Threshold algorithm $\A^B\big((\w_{k,b})_{k \in [K],b \leq B}\big)$}\label{algo:DT}
\SetKwInput{Input}{Input}
   \SetKwInOut{Output}{Output}
   \SetKwInput{Initialization}{Initialization}
   \Input{Available budget $B$, thresholds $(\w_{k,b})_{k \in [K],b \leq B}$}
   \Initialization{$b = B$}
\For{$t=1,\ldots,N$}{
    Receive new observation: $(r_t, g_t)$\;
    \If(\tcp*[f]{\small compare in-group}){$t \geq \lfloor \w_{g_t,b} N \rfloor \emph{ and } r_t = 1$}{%\label{algoline:better-than-best}
        \If(\tcp*[f]{\small check budget}){$b > 0$}{
            % \vspace{-0.4cm}
            Update budget: $b \gets b - 1$\;
            \lIf(\tcp*[f]{\small compare inter-group}){$R_t = 1$}{
            Return: $t$
            }
        }
        \lElse{Return: $t$} 
    }
}
\end{algorithm}




In the alternative comparison model introduced in Section \ref{sec:setup}, where a unit cost only permits comparing the current candidate $x_t$ to a previously observed candidate $x_s$, rather than determining if $x_t$ is the best among all groups, a $\DT$ algorithm may bypass a candidate even if they are the best in their group, hence it cannot keep track of the best-observed candidate. Consequently, determining if a new candidate is the best among all groups becomes more costly. 
The algorithm can for example use $K-1$ comparisons at the first step when it decides to observe $\indic{R_t = 1}$, then use a comparison whenever $r_t = 1$, to keep track of the best candidate in each group.




\subsection{Memory-less algorithms}


One distinctive feature of Dynamic Threshold algorithms is their decision-making process, which solely depends on the observations at each step and the available budget, without recourse to past comparison history. We designate algorithms exhibiting this characteristic as memory-less algorithms.


\begin{definition}\label{def:memless}
An algorithm $\A$ for the $(K,B)$-secretary problem is memory-less if its actions at any step $t \in [N]$ depend only on the current observations $r_t, g_t, \indic{R_t = 1}$, the available budget $B_t$, the cardinals $(|G^k_{t-1}|)_{k \in [K]}$.
\end{definition}



Being aware of the group sizes implies knowledge of the current step. Additionally, we assume that a memory-less algorithm knows the total number of candidates and the proportions of each group $(\lambda_k)_{k \in [K]}$. However, in our analysis, the knowledge of group proportions is dispensable since we investigate the asymptotic success probabilities of $\DT$ algorithms. Indeed, for setting thresholds that depend on group proportions, if the smallest threshold is at least $\epsilon > 0$, regardless of group proportions, it suffices to observe the first $\lfloor \epsilon N \rfloor$ candidates, then estimate $\bar{\lambda}_k = \lfloor \epsilon N \rfloor^{-1} \sum_{t = 1}^{\lfloor \epsilon N \rfloor} \indic{g_t = k}$ for all $k \in [K]$. The algorithm can choose the thresholds using $(\bar{\lambda}_k)_{k \in [K]}$ instead of $({\lambda}_k)_{k \in [K]}$. As the number of candidates tends to infinity, $\bar{\lambda}_k$ becomes arbitrarily close to $\lambda_k$ with high probability, and so do the thresholds, assuming they are continuous functions of the group proportions. Though this introduces additional intricacies to the proofs, the fundamental proof arguments and the results remain the same.


In the following lemma, we establish that the success probability of a memory-less algorithm, given the history up to step $t-1$, is contingent upon only a few parameters, which are the available budget $B_t$, the group to which the best-observed candidate belongs $g^*t$, and the sizes of the groups $(|G^k_t|){k \in [K]}$. Collectively, these parameters define the \textit{state} of a memory-less algorithm at step $t$, which entirely determines the success probability of the algorithm starting from that state.

\begin{lemma}\label{lem:memless}
For any memory-less algorithm $\A$ and $t \in [N]$, denoting by $\tau$ the stopping time of $\A$ and by $\F_{t-1}$ is the history of the algorithm up to step $t-1$, i.e. the set of all the observations and actions taken by the algorithm until step $t-1$, then 
\[
\Pr(\A \text{ succeeds} \mid \tau \geq t, g^*_t, \F_{t-1})
= \Pr(\A \text{ succeeds} \mid \tau \geq t, g^*_t, B_t, (|G^k_t|)_{k \in [K]})\;.
\]
\end{lemma}






While Definition \ref{def:memless} and Lemma \ref{lem:memless} only cover deterministic algorithms, they both can be easily extended to randomized by algorithms, by talking about the distributions of the actions instead of the actions themselves.





\subsection{Single-threshold algorithm for $K$ groups}\label{sec:single-thresh}
In this section, we focus on the single-threshold algorithm, a specific case within the family of $\DT$ algorithms, where all thresholds are identical across groups and budgets. Initially, the algorithm rejects all candidates until step $T-1$, where $T \in [N]$ is a fixed threshold. Upon encountering a new candidate that is the best within its group, if no budget remains, the candidate is selected. Alternatively, if there is still a budget available, the algorithm utilizes it to determine if the current candidate is the best among all groups. If that is the case, the candidate is then selected. We denote by $\A^B_T$ the single-threshold algorithm with threshold $T$ and budget $B$.
Although seemingly simplistic, we demonstrate that this algorithm has an asymptotic success probability converging very rapidly to the theoretical upper bound of $1/e$.


In the alternate comparison model where a unit cost only allows for comparing two candidates with each other, the single-threshold algorithm necessitates an additional budget of $K-1$ to maintain the same theoretical guarantees that we prove. By employing these extra $K-1$ comparisons at the threshold step $T$, the algorithm can determine the group $g^*_{T-1}$ to which the best candidate before step $T$ belongs. Subsequently, as the algorithm continues, it holds true that $g^t = g^*_{T-1}$, until the algorithm selects a candidate and concludes. This is because if $x_t$ is the first candidate with $t \geq T$ to surpass the maximum observed within the group $G^{g^*_{T-1}}$ before step $T-1$—which represents the maximum of all values observed until $T-1$—then it follows that $r_t = 1$ and $R_t = 1$. Consequently, the candidate is selected, and the algorithm terminates. Therefore, whenever $r_t = 1$, it suffices to compare the current candidate $x_t$ to the best candidate belonging to group $G^{g^*_{T-1}}$, which only incurs a cost of $1$.



In this first lemma, we prove a recursion formula on the success probability of the single-threshold algorithm, with a threshold $T = \lfloor \w N \rfloor$ for some $\w \in [0,1]$.

\begin{lemma}\label{lem:single-thres-recursion}
The success probability of the single threshold algorithm $\A_T^B$ with threshold $T = \lfloor \w N \rfloor$ and budget $B \geq 0$ satisfies the recursion formula
\[
\Pr(\A^{B}_{T} \text{ succeeds})
= \frac{\w - \w^{K}}{K-1} + \indic{B\geq 0} (K-1) \sum_{t=T}^N \frac{T^K}{t^{K+1}}\Pr(\A^{B-1}_{t+1} \text{ succeeds}) + O\Big( \sqrt{\tfrac{\log N}{N}}\Big)\;.
\]
\end{lemma}


The central arguments of the proof hinge on analyzing the state transition of the algorithm following the first comparison. After that comparison, the algorithm halts if $R_t = 1$, and the success probability can be computed in that case. Otherwise, if $R_t \neq 1$, the candidate is rejected, and the algorithm transitions to a new state at step $t+1$, where the available budget reduces to $B-1$. Leveraging the memory-less property of the single-threshold algorithm, the success probability starting from the new state is precisely that of algorithm $\A^{B-1}_{t+1}$, with budget $B-1$ and threshold $t+1$ instead, starting from the same state.






The recursion outlined in Lemma \ref{lem:single-thres-recursion} can be used to calculate the asymptotic success probability of the single-threshold algorithm $\A_{\lfloor \w N \rfloor}^B$ as the number of candidates $N$ approaches infinity. The resultant expression is presented in the following theorem.


\begin{theorem}\label{thm:single-thresh}
The asymptotic success probability of the single threshold algorithm $\A^B_T$ with threshold $T = \lfloor \w N \rfloor$ and budget $B \geq 0$ is 
\[
\lim_{N \to \infty} \Pr(\A^B_{\lfloor \w N \rfloor} \text{ succeeds}) = \frac{\w^K}{K-1} \sum_{b = 0}^B \left( \frac{1}{\w^{K-1}} - \sum_{\ell = 0}^b \frac{\log(1/\w^{K-1})^\ell}{\ell !} \right)\;.
\]
\end{theorem}


Note that, for $B = \infty$, the asymptotic success probability in the previous theorem becomes
\begin{align*}
\lim_{N \to \infty} \Pr(\A_{\lfloor \w N \rfloor}^B \text{ succeeds})
&= \frac{\w^K}{K-1} \sum_{b = 0}^{\infty} \left( \frac{1}{\w^{K-1}} - \sum_{\ell = 0}^b \frac{\log(1/\w^{K-1})^{\ell}}{\ell!}\right)\\
&= \frac{\w^K}{K-1} \sum_{b = 0}^{\infty}\sum_{\ell = b+1}^\infty \frac{\log(1/\w^{K-1})^{\ell}}{\ell!}\\
&= \frac{\w^K}{K-1} \sum_{\ell = 1}^{\infty}\sum_{b = 0}^{\ell - 1} \frac{\log(1/\w^{K-1})^{\ell}}{\ell!}\\
&= \frac{\w^K}{K-1} \sum_{\ell = 1}^{\infty}\frac{\log(1/\w^{K-1})^{\ell}}{(\ell-1)!}\\
&=  \frac{\w^K \log(1/\w^{K-1})}{K-1} \sum_{\ell = 0}^{\infty}\frac{\log(1/\w^{K-1})^{\ell}}{\ell!}\\
&= \w^K \log(1/\w)\cdot \frac{1}{\w^{K-1}}\\
&= \w \log(1/\w)\;,
\end{align*}
which corresponds to the success probability of the algorithm with a threshold $\lfloor \w N \rfloor$ in the secretary problem. 
This behavior stems from the fact that with an unlimited budget, the decision-maker can make comparisons at each step, which allows them to assess whether the current candidate is better than all the ones observed previously. The problem becomes equivalent to the classical secretary problem.

The next corollary measures how the success probability of the single threshold algorithm, in the setting with $K$ groups, converges to $1/e$ as the budget increases.




\begin{corollary}\label{cor:single-thresh-factorial-conv}
The success probability of the single-threshold algorithm with threshold $T = \lfloor N/e \rfloor$ and budget $B \geq 0$ satisfies
\[
\lim_{N \to \infty} \Pr(\A_{\lfloor N/e \rfloor}^B \text{ succeeds})
\geq \frac{1}{e}\left(1 - \frac{(K-1)^{B+1}}{(B+1)!} \right)\;.
\]
\end{corollary}


The previous corollary proves that the success probability of the single-threshold-algorithm with threshold $\lfloor N/e \rfloor$ converges very rapidly to the upper bound $1/e$ as $B$ increases. However, the convergence becomes slower when the number of distinct groups $K$ is large. Typically, to achieve an asymptotic success probability of at least $\frac{1-\eps}{e}$ for some $\eps > 0$, using the inequality $m! \geq e\big( \frac{m}{e} \big)^m$, it suffices that $K$ and $B$ satisfy
$
\frac{(K-1)^{B+1}}{e(\tfrac{B+1}{e})^{B+1}} \leq \eps,
$
which is equivalent to 
\[
K \leq 1 + \frac{B+1}{e}(e\eps)^{\frac{1}{B+1}}\;.
\]






It might be surprising that the asymptotic success probability of the single-threshold algorithm is not influenced by the proportions $(\lambda_k)_{k \in [K]}$ of the groups but only by the number of distinct groups $K$. For example, let us consider the scenario with only one group, reducing the problem to the classical secretary problem where the budget becomes insignificant. In this case, the asymptotic success probability of the single-threshold algorithm with a threshold $\lfloor \w N\rfloor$ is $\w \log(1/\w)$. However, when there are two groups with respective proportions $\lambda_1 = 1-\delta$ and $\lambda_2 = \delta$, with $\delta > 0$ arbitrarily small, the asymptotic success probability of the single-threshold algorithm becomes $\frac{\w(1-\w)}{2}$, identical to the scenario where $\lambda_1 = \lambda_2 = 1/2$.

This highlights a weakness in the algorithm, since it is possible to have an improved success probability when there is a group $G^k$ with proportion close to $1$, by considering a naive algorithm that rejects all candidates not belonging to group $G^k$ and employs the classical $1/e$-rule, counting only elements from $G^k$, yielding a success probability of $\lambda_k/e$. Overcoming this weakness requires setting a different threshold for each group, as in \cite{correa2021fairness} for the case with zero budget. Having a non-zero budget makes the analysis even more complicated, as we show in the case of two groups in Section \ref{sec:2grps}.

