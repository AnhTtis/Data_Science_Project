\section{Optimal memory-less algorithm for two groups}

\subsection{Proof of Lemma \ref{lem:memless}}

Before studying the optimal memory-less algorithm, we show that the state of a memory-less algorithm at any step $t$, fully characterizing its success probability, can be reduced to a few parameters, instead of the the history of the algorithm from the beginning of its execution.

\begin{proof}
Let $\A$ be a memory-less algorithm, and let us denote by $\tau$ its stopping time. Conditionally to the history of the algorithm until step $t-1$ and to the event $\{\tau \geq t\}$, the success probability of $\A$ depends on the future observations and the future actions of the algorithm.

Given that the algorithm is memory-less, at any step $s \geq t$, its actions $\act_{s,1}, \act_{s,2}$ depend on the observations $r_t, g_t, R_t$, the budget $B_t$ and $(|G^k_{s-1}|)_{k \in [K]}$. 

Conditionally to the cardinals of the groups at step $t-1$, the cardinals $(|G^k_{s-1}|)_{k \in [K]}$ are independent of the history $F_{t-1}$ because
\[
|G^k_{s-1}| = |G^k_{t-1}| + \sum_{u = t}^{s-1} \indic{g_u = k} \quad \forall k \in [K]\;,
\]
Moreover, since the candidates are observed in a uniformly random order, and the group memberships are also i.i.d random variables, then for all $s \geq 2$ distributions of $r_s, R_s$ depend only on the cardinals of each group at step $s-1$, on $g_s$ and $g^*_{s-1}$. Also $g^*_s$ is a function of $g^*_{s-1}, g_s$ and $\indic{R_s = 1}$:
\[
g^*_s = \indic{R_s \neq 1} g^*_{s-1} + \indic{R_s \neq 1} g_s\;,
\]
and the budget $B_s$ satisfies
\[
B_s = B_{s-1} - \indic{a_{s-1,2} = \acomp}\;.
\]

Therefore, Conditionally to the $B_t, (|G^k_{t-1}|)_{k \in [K]}, g^*_{t-1}$, 
the distributions of the observations and of the algorithm's actions at any step $s \geq t$ are independent of the history before step $t$.
\end{proof}







\subsection{Proof of Lemma \ref{lem:dynprog-rt-Rt}}
\begin{proof}
If $\S_t(\A) = (t,m,b,\ell)$, then in particular $g^*_{t-1} = \ell$, i.e. $\max G^\ell_{t-1} > \max G^k_{t-1}$, thus
\begin{align*}
\Pr(r_t = 1 \mid \S_t(\A) = (t,m,b,\ell), g_t = \ell) 
&= \Pr( x_t > \max G^\ell_{t-1} \mid \S_t(\A) = (t,m,b,\ell), g_t = \ell) \\
&= \Pr( x_t > \max x_{1:t-1} \mid \S_t(\A) = (t,m,b,\ell), g_t = \ell) \\
&= \frac{1}{t}\;,
\end{align*}
because the rank of $x_t$ among previous candidates is independent of their relative ranks and groups, thus independent of the state of the algorithm. Moreover, if $r_t = 1$, $g_t = 1$ and $g^*_{t-1} = \ell$, then $x_t$ is the better than the maximum of $G^\ell_{t-1}$, which is the maximum of $x_{1:t-1}$, thus necessarily $R_t = 1$,
\[
\Pr(R_t = 1 \mid \S_t(\A) = (t,m,b,\ell), g_t = \ell, r_t = 1) = 1\;.
\]

On the other hand, if $g_t = k \neq \ell = g^*_{t-1}$, assume that $|G^\ell_{t-1}| > 0$. It holds that
\begin{align*}
\Pr(r_t = 1 \mid \S_t(\A) = (t,m,b,\ell), g_t = k) 
&= \Pr( r_t = 1 \mid g^*_{t-1} = \ell, g_t = k, |G^1_{t-1}| = m) \\
&= \frac{\Pr( r_t = 1, g^*_{t-1} = \ell \mid g_t = k, |G^1_{t-1}| = m)}{\Pr(g^*_{t-1} = \ell \mid |G^1_{t-1}| = m)}\;.
\end{align*}
We have immediately that 
\[
\Pr(g^*_{t-1} = \ell \mid |G^1_{t-1}| = m)
= \Pr(\max G^\ell_{t-1} > \max G^k_{t-1} \mid |G^1_{t-1}| = m)
= \frac{|G^\ell_{t-1}|}{t-1}\;,
\]
and the numerator can be computed as
\begin{align}
\Pr( r_t = 1, g^*_{t-1} = \ell \mid g_t = k, |G^1_{t-1}| = m)
=& \Pr( x_t > \max G^k_{t-1}, g^*_{t-1} = \ell\mid  |G^1_{t-1}| = m) \nonumber\\ 
&= \Pr(x_t > \max G^k_{t-1}, \max G^\ell_{t-1} > \max G^k_{t-1} \mid |G^1_{t-1}| = m)\nonumber \\
&= \Pr(x_t > \max G^\ell_{t-1} > \max G^k_{t-1} \mid |G^1_{t-1}| = m) \nonumber \\
&\quad + \Pr(\max G^\ell_{t-1} > x_t > \max G^k_{t-1} \mid |G^1_{t-1}| = m) \nonumber \\
&= \frac{1}{t}\cdot \frac{|G^\ell_{t-1}|}{t-1} + \frac{|G^\ell_{t-1}|}{t} \cdot \frac{1}{|G^k_{t-1}|+1} \nonumber \\
&= \frac{|G^\ell_{t-1}|}{t} \left( \frac{1}{t-1} + \frac{1}{|G^k_{t-1}| + 1} \right)\;, \label{eq:term(q)}
\end{align}
which yields
\begin{align*}
\Pr(r_t = 1 \mid \S_t(\A) = (t,m,b,\ell), g_t = k) 
&= \frac{t-1}{|G^\ell_{t-1}|} \cdot \frac{|G^\ell_{t-1}|}{t} \left( \frac{1}{t-1} + \frac{1}{|G^k_{t-1}| + 1} \right)\\
&= \frac{1}{t} \left( 1 + \frac{t-1}{|G^k_{t-1}| + 1} \right)\\
&= \frac{|G^k_{t-1}|+t}{t(|G^k_{t-1}|+1)}\;.
\end{align*}

Finally, 

\begin{align*}
\Pr(R_t = 1 \mid \S_t(\A) = (t,m,b,\ell), g_t = k, r_t = 1) 
&= \frac{\Pr(R_t = 1, r_t = 1, g^*_{t-1} = \ell \mid g_t = k, |G^1_{t-1}|) }{\Pr(r_t = 1, g^*_{t-1} = \ell \mid g_t = k, |G^1_{t-1}|)}\;.
\end{align*}
We computed the denominator term in \eqref{eq:term(q)}, and the numerator satisfies
\begin{align*}
\Pr(R_t = 1, r_t = 1, g^*_{t-1} = \ell \mid g_t = k, |G^1_{t-1}|)
&= \Pr(R_t = 1, g^*_{t-1} = \ell \mid g_t = k, |G^1_{t-1}|)\\
&= \Pr(x_t > \max G^\ell G^\ell_{t-1} > \max G^k_{t-1} \mid |G^1_{t-1}|)\\
&= \frac{1}{t} \cdot \frac{|G^\ell_{t-1}|}{t-1}\;,
\end{align*}
hence
\begin{align*}
\Pr(R_t = 1 \mid \S_t(\A) = (t,m,b,\ell), g_t = k, r_t = 1) 
&= \frac{ \frac{|G^\ell_{t-1}|}{t(t-1)} }{\frac{|G^\ell_{t-1}|}{t} \left( \frac{1}{t-1} + \frac{1}{|G^k_{t-1}| + 1} \right)}\\
&= \frac{1}{ 1 + \frac{t-1}{|G^k_{t-1}| + 1} }\\
&= \frac{|G^k_{t-1}| + 1}{|G^k_{t-1}| + t}\;.
\end{align*}
This concludes the proof when $|G^\ell_{t-1}| > 0$. If $|G^\ell_{t-1}| = 0$, then the same identities remain trivially true.
\end{proof}






\subsection{Proof of Theorem \ref{thm:opt-memless}}
\begin{proof}
Using the results from Section \ref{sec:state-transition} and \ref{sec:expected-rwd}, the actions of $\A_*$ and the resulting state transitions are as follows.
If the state of $\A_*$ at step $t$ is $\S_t(\A_*) = (t,B,m,\ell)$ for some $B \geq 1$, $m<t$ and $\ell \in \{1,2\}$:
If $g_t = \ell$, denoting by $M_\ell = m + \indic{\ell = 1}$, we have
\begin{itemize}
    \item with probability $1-1/t$: $r_t = 0$, and the algorithm rejects the candidate, transitioning to the state $(t+1,B,M_\ell,\ell)$.
    \item with probability $1/t$: $r_t = 1$, and necessarily $R_t = 1$, because $g_t = g^*_{t-1} = \ell$. 
    \begin{itemize}
        \item If $\rwd^B_{t,m,k}(\acomp) > \rwd^B_{t,m,k}(\askip)$, then the algorithm uses a comparison and observes $R_t = 1$, hence accepts the candidate. The success probability in that case is $t/N$.
        \item Otherwise, the candidate is rejected and the algorithm goes to state $(t+1,B,M_\ell,\ell)$
    \end{itemize}
\end{itemize}
On the other hand, if $g_t = k \neq g^*_{t-1}$, then denoting by $M_k = m + \indic{k = 1}$, we have
\begin{itemize}
    \item with probability $\frac{|G^k_{t-1}|(t+1)}{t(|G^k_{t-1}|+1)}$: $r_t = 0$, and the algorithm rejects the candidate, transitioning to the state $(t+1,B,M_k,\ell)$.
    \item with probability $\frac{|G^k_{t-1}| + t}{t(|G^k_{t-1}|+1)}$: $r_t = 1$
    \begin{itemize}
        \item If $\rwd^B_{t,m,k}(\acomp) > \rwd^B_{t,m,k}(\askip)$, then the algorithm uses a comparison
        \begin{itemize}
            \item with probability $\frac{|G^k_{t-1}| + 1}{|G^k_{t-1}|+t}$: $R_t = 1$ and the algorithm stops, its success probability is $t/N$
            \item with probability $\frac{t- 1}{|G^k_{t-1}|+t}$: $R_t = 0$, the candidate is rejected, and the algorithm goes to state $(t+1,B-1,M_k,\ell)$
        \end{itemize}
        \item Otherwise, the candidate is rejected and 
        \begin{itemize}
            \item with probability $\frac{|G^k_{t-1}| + 1}{|G^k_{t-1}|+t}$: the algorithm goes to state $(t+1,B, M_k,k)$
            \item with probability $\frac{t- 1}{|G^k_{t-1}|+t}$: the algorithm goes to state $(t+1,B, M_k,\ell)$
        \end{itemize}
    \end{itemize}
\end{itemize}

In the case of a zero budget, the algorithm compares $\rwd^B_{t,m,k}(\askip)$ to $\rwd^B_{t,m,k}(\acomp)$ instead of $\rwd^B_{t,m,k}(\acomp)$. If the algorithm decides to reject the candidate then the same state transition occurs. However, if the candidate is selected and if $g_t = g^*_{t-1} = \ell$ then the success probability is $t/N$. If On the other hand, if it is selected and $g_t = k \neq g^*_{t-1} = \ell$ then the probability that the current candidate is the best overall is $\frac{|G^k_{t-1}| + 1}{|G^k_{t-1}|+t} \times \frac{t}{N}$.

All in all, for $B = 0$, then
\begin{align*}
(\V^0_{t,m,\ell} \mid g_t = \ell)
&= \frac{1}{t}\left( \delta^0_\ell \frac{t}{N} + (1 - \delta^0_\ell) \V^0_{t+1,M_\ell,\ell}  \right) + \left(1 - \frac{1}{t} \right) \V^0_{t+1,M_\ell,\ell}\\
&= \left(1 - \tfrac{\delta^0_\ell}{t}\right)\V^0_{t+1,M_\ell,\ell} + \tfrac{\delta^0_\ell}{N}\\
(\V^0_{t,m,\ell} \mid g_t = k)
&= \tfrac{|G^k_{t-1}| + t}{t(|G^k_{t-1}|+1)}\left( \delta^0_k \tfrac{t(|G^k_{t-1}| + 1)}{N(|G^k_{t-1}|+t)} + (1-\delta^0_k) \left( \tfrac{|G^k_{t-1}| + 1}{|G^k_{t-1}|+t} \V^0_{t+1,M_\ell,l} + \tfrac{t- 1}{|G^k_{t-1}|+t} \V^0_{t+1,M_\ell,\ell} \right) \right)\\
&\quad + \tfrac{|G^k_{t-1}| + t}{t(|G^k_{t-1}|+1)}\V^0_{t+1,M_k,\ell}\\
&=  \tfrac{\delta^0_k}{N} + \tfrac{1-\delta^0_k}{t} \V^0_{t+1,M_k,k} + \left(1 - \tfrac{1}{t}\right)\left(2 - \delta^0_k - \tfrac{1}{|G^k_{t-1}|+1} \right) \V^0_{t+1,M_k,\ell}\;,
\end{align*}
and we deduce that 
\begin{align*}
\V^0_{t,m,\ell}
&= \lambda_\ell \left( \left(1 - \tfrac{\delta^0_\ell}{t}\right)\V^0_{t+1,M_\ell,\ell} + \tfrac{\delta^0_\ell}{N} \right) 
+ \lambda_k \left( \tfrac{\delta^0_k}{N} + \tfrac{1-\delta^0_k}{t} \V^0_{t+1,M_k,k} + \left(1 - \tfrac{1}{t}\right)\left(2 - \delta^0_k - \tfrac{1}{|G^k_{t-1}|+1} \right) \V^0_{t+1,M_k,\ell} \right)\;.
\end{align*}

For $B \geq 1$, we obtain
\begin{align*}
(\V^B_{t,m,\ell} \mid g_t = \ell)
&= \frac{1}{t}\left( \delta^B_\ell \frac{t}{N} + (1 - \delta^B_\ell) \V^B_{t+1,M_\ell,\ell}  \right) + \left(1 - \frac{1}{t} \right) \V^B_{t+1,M_\ell,\ell}\\
&= \left(1 - \tfrac{\delta^B_\ell}{t}\right)\V^B_{t+1,M_\ell,\ell} + \tfrac{\delta^B_\ell}{N}\\
(\V^B_{t,m,\ell} \mid g_t = k)
&= \tfrac{|G^k_{t-1}| + t}{t(|G^k_{t-1}|+1)}\bigg[ \delta^B_k \left( \tfrac{|G^k_{t-1}| + 1}{|G^k_{t-1}|+t} \V^B_{t+1,M_k,k} + \tfrac{t - 1}{|G^k_{t-1}|+t} \V^B_{t+1,M_k,\ell} \right) \\
&\quad + (1-\delta^B_k) \left( \tfrac{|G^k_{t-1}| + 1}{|G^k_{t-1}|+t} \V^0_{t+1,M_k,l} + \tfrac{t- 1}{|G^k_{t-1}|+t} \V^0_{t+1,M_k,\ell} \right) \bigg] + \tfrac{|G^k_{t-1}| + t}{t(|G^k_{t-1}|+1)}\V^B_{t+1,M_k,\ell}\\
&=  \tfrac{\delta^B_k}{N} + \tfrac{\delta^B_k}{|G^k_{t-1}|+1}\big( 1 - \tfrac{1}{t}\big) \V^{B-1}_{t+1,M_k,\ell} + \tfrac{1-\delta^B_k}{t} \V^{B}_{t+1,M_k,k} + \big(1-\tfrac{1}{t}\big)\big( 1 - \tfrac{\delta^B_k}{|G^k_{t-1}|+1}\big)  \V^{B}_{t+1,M_k,\ell}\;,
\end{align*}
hence
\begin{align*}
\V^B_{t,m,\ell}
&= \lambda_\ell \left( \tfrac{\delta^B_\ell}{N} + \big( 1 - \tfrac{\delta^B_\ell}{t} \big) \V^B_{t+1,M_\ell,\ell} \right) \\
&\quad+ \lambda_k \left( \tfrac{\delta^B_k}{N} + \tfrac{\delta^B_k}{|G^k_{t-1}|+1}\big( 1 - \tfrac{1}{t}\big) \V^{B-1}_{t+1,M_k,\ell} + \tfrac{1-\delta^B_k}{t} \V^{B}_{t+1,M_k,k} + \big(1-\tfrac{1}{t}\big)\big( 1 - \tfrac{\delta^B_k}{|G^k_{t-1}|+1}\big)  \V^{B}_{t+1,M_k,\ell}  \right)\;,
\end{align*}
which concludes the proof.
\end{proof}


