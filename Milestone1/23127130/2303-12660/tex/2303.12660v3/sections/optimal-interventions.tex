
\subsection{Techniques for General Production Networks} \label{sec:general_supply_chains}

% \mpcomment{move discussion about circular economies to the discussion section, talk only about cycles in supply chains}

So far, we have focused our attention on simple structures where we can find analytical expressions for $\ev {} {F}$, and, subsequently, by bounding $\ev {} {F}$ we can determine the upper and / or lower bounds for $R_{\cG}(\varepsilon)$. However, in more general cases, $\cG$ may have a more complicated structure for which we want to calculate the resilience, and in general, $\ev {} {F}$ is \#P-hard to compute; cf. \citep{chen2010scalable}.%, and in general, any sampling-based algorithm has complexity at least $\Omega (K + M)$ \citep{borgs2014maximizing}. 
Moreover, it is certainly possible for a production network to have cycles, e.g., when complex products are used in the production of simpler products. It is also possible that production networks have cycles that represent recycling or other forms of circular flows of materials or resources in modern economies; cf. circular economies \citep{geissdoerfer2017circular}. In this section, we offer techniques to address the following questions for general network topologies:  
% such as in the case of circular economies \citep{geissdoerfer2017circular,kirchherr2017conceptualizing}. In some cases, production networks can have cycles, which can represent recycling or other forms of circular flows of materials or resources. 
\begin{compactenum}
\item[\emph{Question 1.}] \emph{How do we efficiently calculate the cascade size $F$?}
\item[\emph{Question 2.}] \emph{How do we identify network vulnerabilities in the failure of their most critical nodes?}
\item[\emph{Question 3.}] \emph{How can we design interventions to minimize the (expected) size of failure cascades?}
\end{compactenum}

As expected, production networks are most vulnerable to failure of their most ``central'' nodes, to which many of their products have (potentially higher order) connections. In fact, we can identify such nodes using their Katz centrality \citep{katz1953new}, which arises naturally under certain assumptions in our model. Moreover, efficient network protection can be achieved to minimize the size of cascading failures (in part) by protecting the most central nodes, which we formulate in \cref{sec:interventions}.

A surprising way to identify such nodes involves extending the percolation process to allow link failures, creating a noisy version of the node percolation process introduced in \cref{sec:node_percolation}. More specifically, for each edge $(i, j) \in \cE(\cG)$ of the production network, we flip a coin of bias $y \in (0, 1]$, independently of the other edges and suppliers, and decide to keep the edge with probability $y$. Model-wise, this corresponds to firms holding inventories and, therefore, if a product $i$ has enough inventory from its input product $j$, then it is likely to discard its network dependencies with probability $1 - y$. 

This creates a subsampled graph $\cG_y \subseteq \cG$, which, under reasonable assumptions for $x$ and $y$, can be used to identify vulnerabilities of the network to products whose failure is likely to cause the largest cascading failures. The above process can also be viewed as a \emph{joint percolation} on both nodes and edges or a node percolation on the noisy subnetwork $\cG_y$, where in order for a product to function, on average it only needs a $y$-fraction of its inputs to operate. We define $R_{\cG}(\varepsilon; y)$ as resilience assuming randomness in the sampling $\cG_y$, such that $R_{\cG}(\varepsilon) = R_{\cG}(\varepsilon; y = 1)$. Moreover, we define $F_y$ as the size of the cascade in $\cG_y$ and $F$ as the size of the cascade when $y = 1$. A simple coupling argument similar to \cref{lemma:upper_bound_resilience} for $0 < y_1 \le y_2 < 1$ shows that survivals in $\cG_{y_1}$ are greater than in $\cG_{y_2}$: 

\begin{proposition} \label{prop:rel_resilience}
    For any $0 < y_1 \le y_2 \le 1$, we have $R_{\cG} (\varepsilon; y_1) \ge R_\cG(\varepsilon; y_2)$. Subsequently, $R_\cG (\varepsilon; y) \ge R_{\cG}(\varepsilon)$ for all $y \in (0, 1]$. 
\end{proposition}

 In the following, we answer the above questions and provide a systematic way to treat general graphs that undergo a joint percolation process. More specifically, we systematically bound the expected number of failures and subsequently derive bounds for the resilience metric. Finally, we show that our analysis has deep connections to financial networks. To put our analysis into a mathematical framework, Markov's inequality states $\Pr [F_y \ge \varepsilon K] \le {\ev {} {F_y}} /{\varepsilon K}$. This together with \Cref{prop:rel_resilience} allows us to have an upper bound on resilience by limiting the failure of at least $\varepsilon K$ products which requires an upper bound on $\ev {} {F_y} = \sum_{i \in \cK} \Pr [Z_i = 0]$ following Markov's inequality; recalling notation of \Cref{eq:dynamics}, $Z_i$ is an indicator variable for the failure of product $i$. 

To connect the approximation of $\ev {} {F_y}$ with linear programming, we define the following optimization problem and its dual, with optimal solutions $\beta_{\cG}^*(u; y)$ and $\gamma_{\cG}^*(u; y)$, which are parametrized by a shock vector $u \in [\zero, \one] := [0,1]^{K}$: 

\begin{align}
	p_\cG^*(u; y) & = \max_{\beta \in [\zero, \one]}  \one^T \beta \quad &
	\text{s.t.} \quad & \beta \le y A^T \beta + u, \label{eq:upper_bound_lp} \\
        d_{\cG}^*(u; y) & = \min_{\gamma, \theta \ge \zero}  u^T \gamma + \one^T \theta \quad & \text{s.t.}  \quad  & (I - yA) \gamma  + \theta \ge \one. \nonumber%\label{eq:upper_bound_lp_dual} 
\end{align}

 When the context is evident, we skip the arguments and simply write $p^*, d^*, \beta^*$ and $\gamma^*$. The following theorem gives a way to characterize an upper bound on $\ev {} {F_y}$ as the solution to a linear program (proof in Appendix \ref{app:proof:theorem:general_ub}).


\begin{theorem} \label{theorem:general_ub}
    Let $\cG$ be a production network that undergoes a joint percolation process with the probability of supplier failure $x$ and the probability of survival of edges $y$. If $p^*$ is the optimal value of the primal problem in \cref{eq:upper_bound_lp} for $u = \one x^n$, then, for $y = \varrho / m$ and $\varrho \in (0, 1)$, we have $\ev {} {F_y} \le p^* \le \left (1 + \varrho + O((\varrho)^2) \right ) \ev {} {F_y}$. The solution to LP can be found as the unique fixed point $\beta^*$ of the contraction $\Phi(\beta) = \one \wedge (y A^T \beta + x^n \one)$.
\end{theorem}

The above theorem provides an algorithm to find $\beta^*$ by solving the fixed point problem, i.e., if $\beta^{(t)}$ corresponds to the failure probabilities in iteration $t$, then $\beta^*$ can be found using the following iteration which corresponds to a contraction map (since $y < 1/m$):
\begin{align}
    \beta^{(t)} = \one \wedge \left (yA^T \beta^{(t - 1)} + x^n \one \right ). \label{eq:contarction_iteration}
\end{align}

% \begin{proofsketch}
%     The proof uses a union bound on $\beta_i = \Pr [Z_i = 0]$ for every $i \in \cK$ and maximizes $\sum_{i \in \cK} \Pr [Z_i = 0]$ under the union bound constraint and the fact that $\{ \Pr [Z_i = 0] \}_{i \in \cK}$ are valid probabilities. Moreover, due to optimality $p^* \ge \ev {} {F_y}$. To get the upper bound, note that if $\beta^*$ is an optimal solution, then the union bound constraint implies that $(1 - my) \sum_{i = 1}^K \beta_i^* \le Kx^n \le \ev {} {F_y}$. Using the fact that $\frac {1} {1 - my} = 1 + my + O((my)^2)$ we get the right hand side. The final part of the proof applies \citep[Lemma 4]{eisenberg2001systemic}. 
% \end{proofsketch}

To obtain a solution with precision $\eta$, we need to iterate \cref{eq:contarction_iteration} $\log(2K/\eta) / \log (1 / \varrho)$ times,  where $\varrho < 1$ is the Lipschitz constant for the contraction map and $2K$ bounds the $L_1$ norm of the initial condition.  This algorithm has a runtime of $O \left ( \frac {(K + M)\log (K / \eta)} {\log (1 / \varrho)} \right ) = \tilde O(K + M)$ to yield a solution that is close to $\beta^*$ by some accuracy $\eta$, and subsequently is a $1 + \eta + \varrho + O(\varrho^2)$ approximation of the cascade size. The runtime matches the lower bound (up to logarithmic factors) $\Omega(K + M)$ of the influence maximization problem as shown in \cite{borgs2014maximizing}. We also show that the following approximation bounds hold for $F_y$ and also that $\ev {} {F_y}$ can never give a better approximation than $3/4 + o(1)$ -- the proof is in Appendix \ref{app:proof:theorem:Fy_approximation}. 

 \begin{theorem} \label{theorem:Fy_approximation}
    For $y < 1 / m$, we have $\ev {} {F_y} \ge \frac {\ev {} {F} - Kq} {1 - q}$ where $q = (1 - (1 - x^n(1 - y))^m$. Moreover, $\ev {} {F_y} \le \left ( \frac {3} {4} + o(1)  \right ) \ev {} {F}$.
 \end{theorem}


% \textcolor{red}{Combining \cref{theorem:general_ub,theorem:Fy_approximation}, we get that the LP yields a $3/4 + o(1)$ approximation to $\ev {} {F}$ for $y < 1/m$.} 
\cref{theorem:general_ub} shows that there is a systematic way of bounding $\ev {} {F}$ and $\ev {} {F_y}$ via the solution of a linear program or a fixed-point equation (if the edge survival probability is less than $1/{m}$). It is surprising to note that an elegant upper bound on the expected number of failures becomes possible by introducing sampling at the edge level which reduces network dependencies. Moreover, if we want to maximize a weighted cascade, namely the objective function is $\pi^T \beta$ for some vector $\pi \ge \zero$ instead of $\one^T \beta$, then the corresponding dual program, corresponds to the systemic risk measure \citep[Example 7]{chen2013axiomatic}: $$\Lambda_{\cG}(\pi; x) = \min_{\gamma, \theta \ge \zero} x^n \one^T \gamma + \one^T \theta \quad \text{s.t.} \quad (I - yA)\gamma + \theta \ge \pi.$$
 
% \begin{algorithm}[t]
%     \scriptsize
%     \captionof{algorithm}{Solution to \cref{eq:upper_bound_lp} for DAGs\label{alg:dag_upper_bound}}
%     \begin{flushleft}
%     \textbf{Input:} DAG $\cG$, node percolation probability $x$, number of suppliers $n$, edge sampling probability $y$. \\
%     \textbf{Output:} The solution ${\beta^*}$ to the linear program in \cref{theorem:general_ub} ---  \cref{eq:upper_bound_lp}. 
%     \medskip
%     \begin{compactenum}
%         \item Use depth-first search to create a topological ordering of DAG $\cG$, $\pi : \cK \to \cK$, and let ${\beta^*}_{\pi(1)} = x^n$
%         \item For $2 \le i \le K$, set ${\beta^*}_{\pi(i)} = \min \left \{ 1, y \sum_{j \in \cN(\pi(i))} \beta^*_j + x^n \right \}$
%     \end{compactenum}
%     \end{flushleft}
% \end{algorithm}




% However, \cref{theorem:general_ub} gives a polynomial time algorithm to compute an \emph{upper bound} on $\ev {\cG, y, x} {F}$ by solving the aforementioned LP. \cref{alg:dag_upper_bound} solves this LP when $\cG$ is a DAG in $O(K + |\cE(\cG)|)$ time. When we allow cycles in $\cG$, the calculation becomes more complicated, and \cref{alg:dag_upper_bound} does not produce a valid solution, and we instead have to rely on solving the LP. 



After defining $p^*_{\cG}$ and its dual $d^*_{\cG}$, the next question is how they are related to resilience. In the following (proved in Appendix \ref{app:proof:theorem:lp_duality_resilience}), we show that we can bound the resilience using the sum of the Katz centralities $\beta_\cG^\katz(y) = (I - yA^T)^{-1} \one$ in $\cG$.

\begin{theorem} \label{theorem:lp_duality_resilience}
    If $y < 1/m$, the resilience $R_{\cG}(\varepsilon; y)$ satisfies $R_{\cG}(\varepsilon; y)  \ge \left (\frac {\varepsilon} {\one^T \beta_{\cG}^\katz (y)} \right )^{1/ n}$.
\end{theorem}

% In the case of DAGs, we can get a special lower bound for $R_{\cG}(\varepsilon; y)$, in the large-shock regime for edges, i.e., when edges fail with high probability $1-y$. 

% \begin{proposition} \label{prop:dag_lb_sparse}
%     Let $\cG$ be a DAG, and consider the joint percolation process with node percolation probability $x \in (0, 1)$, and edge survival probability $y \in (0, 1)$. Then $$R_{\cG}(\varepsilon; y) \ge \left ( \frac {\varepsilon y} {e^{Ky}} \right )^{1/n}.$$ 
    
%     When $y = \frac 1 K$, the lower bound on the resilience is maximized and equals $\left ( \frac {\varepsilon} {e K} \right )^{1/n}$.
% \end{proposition}

% \begin{proofsketch}
%     We consider a topological order of the DAG and prove that the solution $\beta^*$ to the linear program of \cref{theorem:general_ub} --- \cref{eq:upper_bound_lp} --- satisfies $\beta_i^* \le (1 + y)^{i - 1} x^n$ for all $i \in \cK$. Therefore, we can prove that the expected number of failures is at most ${x^n e^{K y}}/ {y}$ which is minimized for $y = 1/K$, yielding the maximized lower bound on  $R_{\cG}(\varepsilon)$. 
% \end{proofsketch}

% An immediate consequence of \cref{{prop:dag_lb_sparse}} is that whenever there is an over-diversification of suppliers, i.e., $n \ge Ky$, then every DAG is resilient --- in agreement with the results of \citet{elliott2022supply}. This idea of maximizing $\ev {} {F}$ has its roots in financial networks, specifically the Eisenberg-Noe model of financial contagion among agents with assets and liabilities \citep{eisenberg2001systemic, glasserman2015likely}. Similar connections between the Eisenberg-Noe clearing problem and network centrality have been made by \citet{siebenbrunner2018clearing,bartesaghi2020risk} and references therein. 

% Moreover, the solution to \cref{eq:upper_bound_lp} gives a measure of \emph{``vulnerability''} of each node, i.e., how likely they are to be affected by cascading failures. In case of DAGs, we can relate this ranking of the node vulnerabilities to their topological ordering as follows:

% \begin{corollary}
%     If $\cG$ is a DAG, $\pi : \cK \to \cK$ is a topological ordering of the nodes in $\cG$, and $\beta^*$ is the solution to the linear program in \cref{eq:upper_bound_lp}, then $\beta^*_{\pi(i)} \le \beta^*_{\pi(j)}$ for all $1 \le i \le j \le K$. 
% \end{corollary}

% The preceding corollary, which is a direct consequence of \cref{theorem:general_ub} and \cref{alg:dag_upper_bound}, states that when $\cG$ is a DAG, the least vulnerable nodes are the raw materials that precede more complex products in their topological ordering. On the other hand, the failure of raw materials in a DAG will cause large cascading failures, affecting all the complex products that succeed the raw materials in their topological ordering. Hence, to prevent large cascading failures, it seems intuitive to intervene to protect nodes that rank highest in the reversed graph. Our results in the next section formalize this intuition, giving an explicit solution for optimal interventions in terms of the Katz centrality of the reversed graph (\cref{prop:intervention}).    

So far, we have focused on the regimes where $y < 1/m$. A reasonable question to ask here is whether the LP bounds are a good approximation of $\ev {} {F_y}$ for $y > 1/m$. Unfortunately, the answer is negative as we show in Appendix \ref{app:innaproximability} as we can find families of graphs such that the gap between the LP and $\ev {} {F_y}$ is at least $K / 8$.



%  .... This gives a clear way to design interventions on a DAG, which would involve intervening on $\pi(1), \dots, \pi(T)$

% \subsection{Relationship to Input-Output Matrices}

% \mpcomment{talk about Leonfieff inverse, input output matrices, etc. see the production networks primer review for ideas}


% \begin{figure}[t]
%     \centering
%     \begin{tikzpicture}[transform shape]
%         \Vertex[x=-1, y=0, label=$1$]{u1}
%         \Vertex[x=1, y=0, label=$2$]{u2}
%         \Vertex[x=0, y=1, label=$3$]{u3}
%         \Edge[Direct, color=black](u2)(u1)
%         \Edge[Direct, color=black](u2)(u3)
%         \Edge[Direct, color=black](u3)(u1)
        
%     \end{tikzpicture}
    
    
%     \caption{Example for \cref{theorem:general_ub}. The optimization of \cref{theorem:general_ub} yields $\beta = ((1 + y)^2 x^n, x^n, (1 + y) x^n)$ and a bound $\ev {} {F} \le \frac {(1 + y)^3 x^n} {y}$.}
%     \label{fig:optimization2}
% \end{figure}

\subsection{Intervention Design} \label{sec:interventions}

% Safeguarding supply chains is an ever-important issue in supply-chain management. Many potential risks can disrupt the supply chain and impact a business's operations and bottom line. These risks can include natural disasters, transportation issues, supplier bankruptcy, cyber-attacks, geopolitical turmoils, etc. It is important for suppliers to have contingency plans to address potential supply chain disruptions and minimize their impact. 


In our model, we build intuition behind designing interventions to protect the supply chain. Our problem involves a global planner that can treat a maximum of $B$ products in the network. Regulators aim to minimize failures, which can be achieved in many ways, such as diversifying the supplier base, building inventory buffers, and implementing robust risk management and monitoring systems. In mathematical terms, since each product can be produced if it has at least one functional supplier, this is equivalent to selecting a maximum of $B$ products in which to intervene. The decision variables are set to $t_i \in \{ 0, 1 \}, i \in \cK$, corresponding to the subset $T \subseteq \cK$ of treated products). The probability of failure of every product is then given by $(x(1 - t_i))^n = x^n (1 - t_i)$. Abusing notation, we define $p_{\cG}^*(T; y)$ (resp. $d_{\cG}^*(T; y)$) as the value of $p_{\cG}^*(u; y)$ (resp. $d_{\cG}^*(u; y)$) where $u_i = 0$ for every $i \in T$ and with $F(T)$ (resp. $F_y(T)$) to be the cascade size (resp. cascade size on the subsampled graph) after treating the products in $T$. A candidate problem for the planner in this case is 

\begin{align} \label{eq:optimal_interventions_opt}
    \min_{T \subseteq \cK : |T| = B} p_{\cG}^*(T; y) = \min_{T \subseteq \cK : |T| = B} d_{\cG}^*(T; y)
\end{align}

The function $p_{\cG}^*(T; y)$ is increasing and submodular as a direct consequence of \cite[Online Appendix, Proposition A.7]{banerjee2022pricing}. Therefore, the intervention problem focuses on minimizing a monotone, increasing sub-modular function. This problem can be solved in polynomial time by relying on the Lov\'asz extension of $p_{\cG}^*(T; y)$. For small shocks, we can solve the intervention problem analytically. Specifically, if $0 < y < \frac 1 {\max \{m, \mu \}}$ and $0 < x < (1 - y \max \{ m, \mu \})^{1/n}$, then the optimal solution of the maximization LP in \cref{eq:optimal_interventions_opt} (since the constraint that corresponds to the network and individual effects holds with equality) is $\hat \beta (T) = x^n (I - yA^T)^{-1} \one_{\cK \setminus T}$ where $\one_{\cK \setminus T}$ is the indicator vector of $\cK \setminus T$. This yields the following proposition (proved in Appendix \ref{app:prop:intervention}).

\begin{proposition} \label{prop:intervention}
    Let $0 < y < \frac 1 {\max \{m, \mu \}}$, $0 < x < (1 - y \max \{m, \mu \})^{1/n}$. Let $\cG^R$ be the graph where the direction of the edges in $\cG$ is reversed, and consider $\gamma_{\cG}^\katz(y) = (I - yA)^{-1} \one$, the Katz centrality of $\cG^R$. Let $\pi : \cK \to \cK$ be a decreasing order on the entries of $\gamma_{\cG}^\katz(y)$. Then, the optimal policy $\hat t$ sets $\hat t_{\pi(i)} = 1$ for $i \in [B]$ and sets it to zero otherwise.
\end{proposition}

So, we can think of the ``riskiest'' products to be the ones with a high Katz centrality in $\cG^R$  --- the reversed graph representing the sourcing relationships between products. This agrees with our intuition about DAGs, which says to intervene starting from the raw materials and progressing in the topological order of the DAG until the budget is exhausted. 

% \mpedit{In the more general case when $y$ is large and $x$ has arbitrary values, it is a direct consequence of the results of \citep{papachristou2024optimal,banerjee2022pricing} that $p_{\cG}^*(u; y)$ is $K$-increasing and submodular in $u$, and that the intervention problem can be equivalently phrased as identifying $K - T$ products to place on the failures. This problem is NP-Hard by a reduction from the 3-Set-Cover problem (see also \cref{theorem:resilience_deterministic_hardness} later in the paper), which yields an $(1 - 1/e)$-approximation algorithm. 

% \begin{proposition} \label{prop:intervention_general}
%     Let $\cG$ be a graph of maximum outdegree $m \ge 1$, let $\cG^R$ be the graph where the direction of edges in $\cG$ are reversed, and let $\mu$ be the maximum outdegree of $\cG^R$. Let $ y \ge \frac 1 {\min \{ m, \mu \}}$. Then, the greedy hill-climbing algorithm yields a policy $t^{\mathsf{sol}}$ such that $p_{\cG}^*((\one - t^{\mathsf{sol}}) x^n; y) \ge \left ( 1 - \frac 1 e \right ) p_\cG^*((\one - t^{\mathsf{opt}})x^n; y)$. 
% \end{proposition}}


\subsection{The Risk Exposure Index} \label{sec:rei}

Our metric has connections to important metrics already present in the supply chain literature \citep{levi2016identifying,simchi2014superstorms,ham2022companies}, such as the Risk Exposure Index (REI). To define REI, suppose that a product in the production network is disrupted by an infinitesimal shock, assuming the same responses from the other nodes. In our case, this corresponds to a change in the probability of shock of the product $i$ from $x$ to $x + \delta$ and its impact on the size of cascading failures, which corresponds to the potential impact $\potentialimpact(i)$. Since it is difficult to quantify an exact formula for the change of $\ev {} {F}$, we will instead focus on the change in $\ev {} {F_y}$ given by \cref{eq:upper_bound_lp}. Specifically, the potential impact for a node is defined as 

{\small
\begin{align} \label{eq:potential_impact}
    \potentialimpact_i (x; y) & = \lim_{\delta \to 0} \frac {p_\cG^*\left ((x^n, \dots, (x + \delta)^n, \dots, x^n)^T; y\right ) - p_\cG^* \left ( (x^n, \dots, x^n, \dots, x^n )^T; y\right )} {\delta} = \left (  n x^{n - 1} \right ) \cdot \frac {\partial \beta_i^*(u; y)} {\partial u_i} \bigg |_{u_i = x^n}.
\end{align}}

Subsequently, the Risk Exposure Index of $\cG$ (REI, \cite{levi2016identifying}) is given as the worst possible magnitude of $\potentialimpact_i(x; y)$, i.e.,

\begin{align} \label{eq:rei}
    \rei_{\cG}(x; y) = \max_{i \in \cK} |\potentialimpact_i(x; y)| = n x^{n - 1} \left \| \frac {\partial \beta^*} {\partial u} \bigg |_{u = \one x^n} \right \|_{\infty}.
\end{align}

We give the following Theorem to characterize the REI:

\begin{theorem} \label{theorem:marginal_rei}
    Consider an optimal solution $\beta^\star$ of \cref{eq:upper_bound_lp}. Let $\cK^+  = \left \{ i \in [K]: \beta_i^* = 1, \beta_i^* \le y \sum_{j \sim i} \beta_j^* + x^n \right \}, \cK^- = \left \{ i \in [K] : \beta_i^* < 1, \beta_i^* =  y \sum_{j \sim i} \beta_j^* + x^n \right \}, \cK^0 = \left \{ i \in [K] : \beta_i^* =1 =  y \sum_{j \sim i} \beta_j^* + x^n \right \}$ be a partition of the products $\cK$. Let $\cB^+ = \cK^- \cup \left \{ K + j : j \in \cV^+ \cup \cV^0 \right \}, \cB^- = \cK^+ \cup \left \{ K + j : j \in \cV^- \cup \cV^0 \right \} $ be the bases of the equivalent LP with variable $s$, that is, $\max_{\beta, s \ge \zero} \; \one^T \beta$ subject to $(I - yA^T) \beta + s = \one x^n$ and $\beta \le \one$. If $B^+$ and $B^-$ are the matrices formed by the columns of $\begin{pmatrix} I - yA^T & I\end{pmatrix}$ corresponding to $\cB^+$ and $\cB^-$, and 

    {\small
    \begin{align*} 
    \potentialimpact^{+}_i (x; y) =  \left (  n x^{n - 1} \right ) \cdot \frac {\partial^+ \beta_i^*(u; y)} {\partial u_i} \bigg |_{u_i = x^n}, \rei^{+}_{\cG}(x) = \max_{i \in [K]} |\potentialimpact^{+}_i(x; y)|, \\ \potentialimpact^{-}_i (x; y) =  \left (  n x^{n - 1} \right ) \cdot \frac {\partial^- \beta_i^*(u; y)} {\partial u_i} \bigg |_{u_i = x^n}, \rei^{-}_{\cG}(x; y) = \max_{i \in [K]} |\potentialimpact^{-}_i(x; y)|,
    \end{align*}}
     
    then $\rei^{+}_\cG(x; y) = n x^{n - 1} \left \| \begin{pmatrix} I & O \end{pmatrix}_{\cdot, \cB^+} \left ( B^+ \right )^{-1} \right \|_{\infty}$ and $\rei^{-}_\cG(x; y) = n x^{n - 1} \left \| \begin{pmatrix} I & O \end{pmatrix}_{\cdot, \cB^-} \left ( B^- \right )^{-1} \right \|_{\infty}$. 

    Moreover, if there are no borderline nodes (i.e., $\cK^0 = \emptyset$), then $\cB^+ = \cB^- = \cB$, $B^+ = B^- = B$, and subsequently $ \rei_\cG(x; y) = n x^{n - 1} \left \| \begin{pmatrix} I & O \end{pmatrix}_{\cdot, \cB} \left ( B \right )^{-1} \right \|_{\infty}$.   
\end{theorem}

\cref{theorem:marginal_rei} is a direct consequence of applying Proposition 1 of \cite{liu2010sensitivity}. We can also show that when firms hold large enough inventory ($y < 1/m$) and the shocks are sufficiently small the REI is proportional to the node with the highest Katz centrality in $\cG^R$. 

\begin{corollary} \label{collorary:rei_katz}
    If $y < 1/ m$, and $x < (1 - my)^{1/n}$,  then $\mathrm {REI}_\cG(x; y) = n x^{n - 1} \| \gamma_\cG^\katz(y) \|_\infty.$
\end{corollary}

