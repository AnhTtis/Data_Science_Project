\section{Graph Neural Networks (GNNs)}\label{sec:gnns}

Graph neural networks are generalizations of convolutional neural networks from grid-structured data to graphs.
The input to a GNN is a graph and a set of feature vectors associated with the graph nodes.
GNNs work by propagating feature information between neighboring nodes, which can be seen as message-passing.
More specifically, at each layer, the GNN computes the messages each node sends based on its feature vector and then updates each node's feature vectors given the messages its neighbors received.
% Following the deep learning paradigm, the GNN performs this message-passing recurrently through its layers, aiming to extract complex features.
We will refer to the feature update as a graph \emph{convolution}, due to its similarities to the operations in convolutional neural networks.

At each layer $l\in\{1,...,L\}$, the graph convolution operation has two major components: message functions $M_l(\cdot)$, which compute the messages propagated by each node, and update functions $U_l(\cdot)$, which update the node-associated features based on the messages.
Let $G = (V, E)$ be a graph and $\bm{h}^{(0)}_v$ be feature vectors for every node $v\in V$.
The messages sent $\bm{m}_{u}^{(l)}$ are computed based on the node features
\begin{equation}\label{eq:message-passing-messages}
    \bm{m}_{u}^{(l)} = M_l(\bm{h}_u^{(l-1)}), \forall u\in V
,\end{equation}
where $M_l(\cdot)$ is the message function of layer $l$.
After computing the messages, the features of node $v$ are updated through
\begin{equation}\label{eq:message-passing-updates}
    \bm{h}_v^{(l)} = U_l\left(\bm{h}_v^{(l-1)}, {\tt Aggregation}\left(\left\{\bm{m}^{(l)}_{u} : u\in \mathcal{N}(v) \right\}\right)\right)
,\end{equation}
where $\mathcal{N}(v)$ are the neighbors of $v$, $U_l(\cdot)$ is the update function of layer $l$, and ${\tt Aggregation}$ is a function that receives multiple message vectors and returns a single vector.

A common choice for graph convolutions is to use feedforward neural networks as message and update functions.
For these to be well-defined, we need ${\tt Aggregation}$ to return, for how many messages received, a vector with a fixed length, thus the naming.
A natural choice is to sum up the messages, but many are the possibilities, such as
\begin{align}
{\tt Aggregation} = \begin{cases}
    \frac{1}{|\mathcal{N}(v)|} \sum\limits_{u \in \mathcal{N}(v)} \bm{m}_{u}^{(l)}, & \textrm{if mean} \\  
        %%%
    \underset{u \in \mathcal{N}(v)}{\max}  \bm{m}_{u}^{(l)}, & \textrm{if max} \\   
        %%%
    \sum\limits_{u \in \mathcal{N}(v)} \bm{m}_{u}^{(l)}, & \textrm{if sum} \\ 
        %%%
    \sum\limits_{u \in \mathcal{N}(v)} \alpha_{u,v} \bm{m}_{u}^{(l)}, & \textrm{if attention} \\
\end{cases},
\end{align}
where $\alpha_{u,v}$ is an attention weight for node $u$ given node $v$, which can be learned along the model parameters.
Furthermore, the message function can easily be extended to consider the edge weight (or even edge features) along with the feature vectors of the neighbors.

A common approach is to define the message functions $M_l, l=1,\ldots,L$, as linear operators over the hidden features of the neighbors, aggregate these messages by summing, and use the ReLU (Rectifier Linear Unit) activation function with a bias as the update functions $U_l, l=1,\ldots,L$.
An example of such is the model proposed by Kipf and Welling~\cite{kipf_semi-supervised_2017}, which uses a linear combination of the features as the message function, aggregates messages by summation, and updates using a single-layer neural network with ReLU activation.
More precisely, we can describe their convolution operation as
\begin{equation}\label{eq:graph-conv}
\begin{aligned}
    % M_l(h_u^{(l-1)}) &= \frac{1}{c_{vu}}W^{(l)}h_u^{(l-1)} \\
    \bm{m}_{u,v}^{(l)} &= \frac{1}{c_{vu}}W^{(l)}\bm{h}_u^{(l-1)},\, u\in \mathcal{N}(v) \\
    \bm{h}_{v}^{(l)} &= \text{ReLU}\left(\bm{b}^{(l)} + \sum_{u \in \mathcal{N}(v)} \bm{m}_{u,v}^{(l)}\right)
\end{aligned}
\end{equation}
where $c_{vu} = \sqrt{|\mathcal{N}(u)|}\sqrt{|\mathcal{N}(v)|}$ with $|\mathcal{N}(v)|$ denoting the number of neighbors, and $W^{(l)}\in \mathbb{R}^{d_l\times d_l},\bm{b}^{(l)}\in\mathbb{R}^{d_l}$ (layer $l$ has size $d_l$) are the weights and biases of the model, i.e., learnable parameters.

Another convolution operator was proposed by \cite{hamilton_inductive_2017} and named SAGE (SAmple and aGgrEgate).
The authors propose to directly aggregate the features of the neighbors, i.e., to use the identity as the message function and to use a single-layer network with ReLU activation as the update function.
Putting it into terms, the proposed graph convolution is
\begin{equation}\label{eq:sage-conv}
\begin{aligned}
    \bm{m}_{u,v}^{(l)} &= \bm{h}_u^{(l-1)},\, u\in \mathcal{N}(v) \\
              %%%%
    \bm{h}_{v}^{(l)} &= \text{ReLU}\left(\bm{b}^{(l)} + W^{(l)}_1 \bm{h}_v^{(l-1)} + W^{(l)}_2 {\tt Aggregation}\left (\bm{m}_{u,v}^{(l)},\, u\in \mathcal{N}(v)\right)\right)
\end{aligned}
\end{equation}
where $W^{(l)}_1,W^{(l)}_2\in \mathbb{R}^{d_l\times d_l},\bm{b}^{(l)}\in\mathbb{R}^{d_l}$ are the parameters.
The authors suggest using more complex aggregation operators, such as an LSTM (Long Short-Term Memory network) and a fully connected single-layer neural network, followed by a pooling operation (element-wise maximum).
Note that the SAGE convolution with summation as the aggregation function is equivalent to the one proposed by Kipf and Welling.

After recurrent graph convolutions through the $L$ layers of a GNN, we can use the resulting node features $H^{(L)} = \left[ \bm{h}_v^{(L)} \right]_{v\in V}$ straight-away, which is suitable for, e.g., node classification tasks, or we can aggregate them further into a single feature vector, suitable for, e.g., graph classification tasks.
The GNN can be trained end-to-end by minimizing a prediction loss based on its outputs, optimizing its parameters (e.g., $W^{(l)}$ and $\bm{b}^{(l)}$ of \eqref{eq:graph-conv}) in the same way as a traditional deep learning model.

% https://arxiv.org/pdf/1710.10903.pdf
% https://arxiv.org/pdf/2105.14491.pdf

\subsection{MILP Problems as Inputs for GNNs}\label{sec:instance-embedding}

We can feed MILP problem instances to GNNs by representing the relationship between problem variables and constraints through a bipartite graph~\cite{gasse_exact_2019,ding_accelerating_2020,khalil_mip-gnn_2022,nair_neural_2020,han_gnn-guided_2023}.
% Given a linear problem, we can build a graph $G=(V,E)$ in which we add one node for each variable of the problem, one node for each constraint, and connect each variable node to constraint nodes whenever the coefficient of the respective variable is not null in the respective constraint.
More precisely, given a problem of the form 
\begin{equation}\label{eq:opt}
\begin{aligned}
\max_{\bm{x}} & \quad \bm{c}^T \bm{x} \\
\text{s.t.:} & \quad A\bm{x} \le\bm{b} 
,\end{aligned}
\end{equation}
where $\bm{x}\in X \subseteq\mathbb{R}^n$ and $\bm{b}\in \mathbb{R}^m$, we can build a graph $G=(V_{\textrm{var}}\cup V_{\textrm{con}}, E)$, in which $|V_{\textrm{var}}| = n$, $|V_{\textrm{con}}|=m$, and $E=\{(v_{{\rm con},i},v_{{\rm var},j}) : A_{i,j} \neq 0\}$.
Intuitively, the graph represents the structure of the problem at hand, with edges capturing the relationship between variables and constraints.
Note that this approach yields a bipartite graph, that is a graph in which the nodes are separated into two disjoint sets, $V_{\textrm{var}}$ and $V_{\textrm{con}}$, with edges connecting only nodes from one set to the other.

To fully represent an MILP instance, however, the graph has to be enhanced with edge and node weights.
Let $w:V\cup E\mapsto \mathbb{R}$ be the weight function\footnote{Note that, in a slight abuse of notation, we use a single function to weigh both nodes and edges.}.
Then, for every node $v_i\in V_{\rm con}$, associated with the $i$-th constraint, the weight will be the constraint's bound, i.e., $i$-th element of $\bm{b}$, i.e., $w(v_i)=b_i$.
Similarly, for $v_j\in V_{\rm var}$, associated with the $j$-th variable, $w(v_j)=c_j$, where $\bm{c}=(c_j)_{j=1,\ldots,n}$.
Edge weights are given by the incidence matrix $A$, that is, given $e=(v_{con,i},v_{var,j}) \in E$, then $w(e)= A_{i,j}$.
This graph representation approach establishes a bijective relationship to the instance space, i.e., every MILP instance is uniquely determined by a weighted graph and vice-versa\footnote{For the weighted graph to identify an MILP instance uniquely, it would need to contain the information about the integrality of the variables. Restricting the bijection statement to MILP problems with the same number of integer variables would be more precise. Alternatively, to assume, without loss of generality, that the first $k\le n$ variables (i.e., $x_1$ to $x_k$) are integer variables and use $k$ as a weight for the whole graph.}.

In practice, the graph fed to a GNN is associated with feature vectors $\bm{h}_v^{(0)}, \forall v\in V$, of arbitrary size.
In other words, the information contained in the features provided to the network is a design choice.
It can contain the weights described above, but many other features might also help the model learn the graph-related task~\cite{gasse_exact_2019,nair_neural_2020}.

For illustration purposes, consider an optimization problem in the form of Eq. \eqref{eq:opt} with three variables $\bm{x} = [x_1, x_2, x_3]^T$, three constraints $C_1,C_2$ and $C_3$, and
\begin{equation}\label{eq:A-matrix-example}
    \bm{c} = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}; ~\\
    A = \begin{bmatrix} 1 & 2 & 0 \\ 0 & 1 & -1 \\ 3 & 0 & 1 \end{bmatrix}; ~\\
\bm{b} = \begin{bmatrix} 2 \\ 1 \\ 4 \end{bmatrix}
.\end{equation}
% \begin{equation}\label{ilustra_bi}
% A = \begin{bmatrix} 1 & 2 & 0 \\ 0 & 1 & -1 \\ 3 & 0 & 1 \end{bmatrix}; ~\\
% \end{equation}
% and $\bm{x} = [x_1, x_2, x_3]^T$.
Then, a bipartite graph representation is illustrated in Figure \ref{fig:ilustra_b}.
For the features, one may define \[
\bm{h}_{x_j}^{(0)} = \begin{bmatrix}
    c_j \\
    \frac{1}{3}\sum_{i=1}^{3} A_{ij} \\
    \max_{i} A_{ij}
\end{bmatrix}\quad{\rm and}\quad\bm{h}_{C_i}^{(0)} = \begin{bmatrix}
    b_i \\
    \frac{1}{3}\sum_{j=1}^{3} A_{ij} \\
    \max_{j} A_{ij}
\end{bmatrix}
,\] such that \[
H^{(0)} = \begin{bmatrix}
    \bm{h}_{x_1}^{(0)T} \\
    \bm{h}_{x_2}^{(0)T} \\
    \bm{h}_{x_3}^{(0)T} \\
    \bm{h}_{C_1}^{(0)T} \\
    \bm{h}_{C_2}^{(0)T} \\
    \bm{h}_{C_3}^{(0)T}
\end{bmatrix} = \begin{bmatrix}
    1 & 2 & 3 \\
    2 & 1.5 & 2 \\
    3 & 0 & 1 \\
    2 & 1.5 & 2 \\
    1 & 0 & 1 \\
    4 & 2 & 3
\end{bmatrix}
.\]

\begin{figure}[!htb]
\centering
\begin{tikzpicture}
\node[circle,draw,fill =green!40] (x1) {$x_1$};
\node[ right = of x1,circle,draw,fill =green!40] (x2)  {$x_2$};
\node[ right = of x2,circle,draw,fill =green!40] (x3) {$x_3$};

\node[ below = of x1,circle,draw,fill =blue!40] (c1) {$C_1$};
\node[ below = of x2,circle,draw,fill =blue!40] (c2) {$C_2$};
\node[ below = of x3,circle,draw,fill =blue!40] (c3) {$C_3$};
\draw (x1) -- (c1);
\draw (x2) -- (c1);
\draw (x3) -- (c2);
\draw (x1) -- (c3);
\draw (x2) -- (c2);
\draw (x3) -- (c3);
\end{tikzpicture}
\caption{Bipartith graph representation of an MILP with three variables ($x_1$, $x_2$, and $x_3$), three constraints ($C_1$, $C_2$, and $C_3$), and $A$ as in Eq. \eqref{eq:A-matrix-example}.}\label{fig:ilustra_b}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%5
