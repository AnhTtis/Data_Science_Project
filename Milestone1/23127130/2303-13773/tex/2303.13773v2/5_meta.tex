\section{Methodology}\label{sec:meth}

In this section, we provide a detailed description of our methodological approach to tackle the two research questions proposed in the introduction.
Namely, we describe our approach to generating ONTS problem data used to train GNNs, our proposed GNN architecture (SatGNN), and how we embed our trained models in heuristics.

\subsection{Data}\label{sec:data}

High-quality data is necessary to learn the tasks of interest and perform reliable evaluations.
To achieve a significant quantity of data, we generate new instances of the ONTS problem with variations of all task parameters and energy availability.
However, randomly sampling parameter values suitable for the problem formulation presented in Sec. \ref{sec:problem} would not reflect the distribution of instances we expect to see in practice.
Therefore, we use a methodological approach to sample the parameter values, following Rigo et al.~\cite{rigo_instance_2023}.
The procedure for generating pseudo-random realistic parameters is described in detail in \ref{appx:random-instance}.

The algorithm for constructing our dataset is described in Algorithm \ref{alg:dataset-generation}.
We optimize every new instance $I\in\mathcal{I}$ using a commercial solver with limited time, during which we collect the best candidate solutions found (represented by $Z^\star$).
Note that we collect only the values for the binary variables $\bm{z}$, as the binary ones can completely determine the continuous variables (see Sec. \ref{sec:problem}).
% Gurobi~\cite{gurobi_optimization_llc_gurobi_2023} for a maximum of 5 minutes, during which we collect the 500 best candidate solutions found by the solver (represented by $\hat{Z}$).
The instance is rejected if no feasible solution is found during the time budget (or if the solver proves infeasibility).

\begin{algorithm}[h]
    \SetAlgoLined
    \KwData{Time horizon $T$, number of jobs $J$, number of instances (final dataset size) $n$.}
    \KwResult{Dataset $\mathcal{D} = \{(I,Z^\star): Z^\star\subset Z\,{\rm given}\,I\}$.}
    
    \While{$|\mathcal{D}| < n$}{
        $\pi \gets {\tt RandomInstance}(T,J)$ \\
        $I \gets {\tt BuildInstance}(\pi)$ \\
        $Z^\star \gets {\tt Solver}(I)$
        
        \If{$|Z^\star| > 0$}{%
            $\mathcal{D}$.add$(I, Z^\star)$
        }
    }
    \caption{Dataset generation. $\pi$ is the parameter vector described in Sec. \ref{sec:problem}, $Z$ is the set of all feasible solutions, and $Z^\star \subset Z$ is the set of candidate solutions the solver finds.
    For a description of ${\tt RandomInstance}$ see \ref{appx:random-instance}.}\label{alg:dataset-generation}
\end{algorithm}

\subsection{SatGNN}\label{sec:sat-gnn}

We name \emph{SatGNN} the base model proposed for all experiments.
An overview of the components of our model can be seen in the diagram of Figure \ref{fig:sat-gnn-overview}.
We follow the approach of embedding the ONTS problem instances as bipartite graphs and feeding them to a GNN (see Sec. \ref{sec:gnns}).
Because of the convolutional nature of the message-passing iterations of the GNNs, the model can deal with arbitrary-sized graphs, which enables the same GNN to handle optimization problems with varying numbers of variables and constraints.
In other words, the GNN can handle ONTS instances with varying numbers of jobs, which is useful, e.g., for iterating over the number of jobs during the mission design to maximize QoS.

The input graph is enhanced with feature vectors for every node.
Let $G=(V, E,w)$ be the graph representation of an instance $I\in\mathcal{I}$ as described in Sec. \ref{sec:instance-embedding}, with $V=V_{\textrm{var}}\cup V_{\textrm{con}}$ the set of nodes and $w: E \longrightarrow \mathbb{R}$ the edge weight function based on the variables coefficients on the constraints.
We name $\bm{f}_v$ the feature vector associated with node $v$.
We add four features to constraint nodes and six to variable nodes, as described in Table \ref{tab:feature-desc}.

\begin{table}[h]
    \centering
    \begin{tabular}{p{7.5cm}|p{7.5cm}}
    \toprule
        Features of constraint nodes ($\bm{f}_{v_{\rm con}}$) & Features of variable nodes ($\bm{f}_{v_{\rm var}}$) \\
    \midrule
         Constraint's upper bound ($\bm{b}$)                     &  Variable's coefficient in the objective ($\bm{c}$)\\
         Constraint's average coefficient (mean of $A_{i*}$)     &  Variable's average coefficient in the constraints (mean of $A_{*j}$) \\
         Number of neighbors/non-null coefficients ($|\mathcal{N}(v_{\rm con})|$)    &  Number of neighbors/non-null coefficients ($|\mathcal{N}(v_{\rm var})|$) \\
         Whether it is an equality or an inequality constraint &  Largest coefficient in the constraints ($\max(A_{*j})$) \\
                                                                    &  Smallest coefficient in the constraints ($\min(A_{*j})$) \\
                                                                    &  Whether it is a continuous or binary variable \\
    \bottomrule
    \end{tabular}
    \caption{Description of input features for SatGNN.}
    \label{tab:feature-desc}
\end{table}

The feature vectors are encoded into the first layer of hidden features by fully-connected neural networks.
More precisely, the hidden feature vectors $H^{(0)}\in \mathbb{R}^{(n+m)\times d}$ (where $n$ is the number of variables, $m$ is the number of constraints, and $d$ is the dimension of the hidden feature vectors) are computed by single-layer neural networks with ReLU activation
\begin{align*}
    {\rm NN}_{\rm var}:\mathbb{R}^6& \longrightarrow\mathbb{R}^{d}_+ \\
    \bm{f}_{v_{\rm var}} &\longmapsto \bm{h}^{(0)}_{v_{\rm var}} = {\rm NN}_{\rm var}(\bm{f}_{v_{\rm var}})
\end{align*}
and
\begin{align*}
    {\rm NN}_{\rm con}:\mathbb{R}^4& \longrightarrow\mathbb{R}^{d}_+ \\
    \bm{f}_{v_{\rm con}} &\longmapsto \bm{h}^{(0)}_{v_{\rm con}} = {\rm NN}_{\rm con}(\bm{f}_{v_{\rm con}})
,\end{align*}
such that the initial hidden features associated to the variable nodes $H^{(0)}_{\rm var} \in \mathbb{R}^{n\times d}$ are computed through ${\rm NN}_{\rm var}$ and the initial hidden features associated to the constraint nodes $H^{(0)}_{\rm con} \in \mathbb{R}^{m\times d}$ are computed through ${\rm NN}_{\rm con}$, in which $H^{(0)} = [H^{(0)}_{\rm var},H^{(0)}_{\rm con}]$.

At each layer of SatGNN, the graph convolutions are performed in two steps, as in Gasse et al.~\cite{gasse_exact_2019}.
First, a graph convolution is applied to update the hidden features of the constraint nodes.
Then, another graph convolution is performed, now considering the updated features of the constraint nodes, to update the hidden features of the variable nodes.
These two operations are illustrated in Figure \ref{fig:sat-gnn-overview} through the $GraphConv$ blocks.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.99\textwidth]{SatGNN.pdf}
    \caption{\emph{SatGNN} architecture overview, where $G$ is the bipartite graph representation of an MILP problem instance, $H$ variables represent the sets of hidden features of the nodes, and $NN_\cdot$ are neural networks. The connection of $G$ and the $GraphConv$ operators represents both the weights of the edges and the neighborhood information.}
    \label{fig:sat-gnn-overview}
\end{figure}

Finally, after $L$ iterations, the last layer's hidden features associated to the variable nodes are fed to a neural network
\begin{align*}
    {\rm NN}_{\rm out}:\mathbb{R}^d_+& \longrightarrow\mathbb{R} \\
    \bm{h}^{(L)}_{v_{\rm var}} &\longmapsto \hat{z}_{v_{\rm var}} = {\rm NN}_{\rm out}(\bm{h}^{(L)}_{v_{\rm var}})
.\end{align*}
This network combines the features extracted by the graph convolution operations into the desired shape of the output.
% Note that the output shape will depend on the learning task (see Sec. \ref{sec:training}).
The network contains two layers of $d$ nodes with ReLU activation.
For node classification tasks (Sec. \ref{sec:meth-sol-pred}), the output of the ${\rm NN}_{\rm out}$ contains a sigmoid activation function, resulting in a probability prediction for each variable node.
For graph classification tasks (Sec. \ref{sec:meth-feas-classification}), in which the output is a single probability value for the entire graph, the output of ${\rm NN}_{\rm out}$ for every variable node is summed into a single value before the sigmoid.

\subsection{Training}\label{sec:training}

Two learning tasks are proposed to investigate the research questions that are the focus of this paper. To investigate whether a GNN can learn the structure of the ONTS problem (\textit{first research question}), we train the SatGNN model on the feasibility classification of candidate solutions. To evaluate the effectiveness of a GNN-based heuristic (\textit{second research question}), we train SatGNN to generate candidate solutions given instances of the problem.

\subsubsection{Feasibility Classification}\label{sec:meth-feas-classification}

Given an instance of the ONTS problem $I\in\mathcal{I}$ and a candidate solution $\bm{\hat{z}}$, we want the model to determine whether $\hat{\bm{z}}$ is a feasible solution or not, that is, $p(\hat{\bm{z}}\in Z | I)$, where $Z\subset \{0,1\}^{2JT}$ is the set of feasible solutions.
The candidate solution is fed to the model as features, adding an extra dimension to $\bm{f}_{v_{\rm var}}$.
As briefly described in Section \ref{sec:sat-gnn}, the feasibility classification is a graph classification task, thus, we aggregate the output of SatGNN before the sigmoid function, i.e., the outputs of ${\rm NN}_{\rm out}$ for each variable node are aggregated to generate the predicted logit, before applying the sigmoid to have the predicted probability $\hat{p}(\hat{\bm{z}}\in Z | I)$.
More precisely, we can write \[
\hat{p}(\hat{\bm{z}}\in Z | I) = \frac{1}{|V_{\rm var}|} \sum_{v_{\rm var}\in V_{\rm var}} {\rm NN}_{\rm out}\left(\bm{h}^{(L)}_{v_{\rm var}}\right)
,\] where $\bm{h}^{(L)}_{v_{\rm var}}$ is computed as described in Sec. \ref{sec:sat-gnn}, and $V_{\rm var}$ is the set of variable nodes, as described in Sec. \ref{sec:instance-embedding}.
The model is trained to minimize the binary cross-entropy (BCE) between the predicted probability and the actual probability \[
    \min_{\theta} \mathcal{L}_{\rm feas}(\theta) = \sum_{(I,\hat{\bm{z}}, y)\in \mathcal{D}_{\rm feas}} {\rm BCE}({\rm SatGNN}(I,\hat{\bm{z}};\theta),y) 
,\] where $y\in\{0,1\}$ indicates whether $\hat{\bm{z}}$ is feasible ($y=1$) or not ($y=0$), and $\theta$ encapsulates all trainable parameters of SatGNN, which includes the parameters of the graph convolutions and the parameters of ${\rm NN}_{\rm con}$, ${\rm NN}_{\rm var}$, and ${\rm NN}_{\rm out}$.

The training data is built with instances from $\mathcal{D}$ (see Sec. \ref{sec:data}).
For each instance $I$ such that $(I,Z^\star)\in\mathcal{D}$, beyond $Z^\star$ as a set of feasible solutions, we also associate with the instance two other sets of candidate solutions $Z_{R},Z_N \subset Z$, such that the dataset can be described as \[
    \mathcal{D}_{\rm feas} = \left\{ (I,\hat{\bm{z}},y)\in \mathcal{I} \times Z\times \{0,1\} : (I,Z^\star) \in \mathcal{D}, \hat{\bm{z}}\in Z^\star\cup Z_R\cup Z_N , y = p(\hat{\bm{z}}\in Z | I) \right\}
.\]
Note that $p(\hat{\bm{z}}\in Z | I) \in \{0,1\}$, as it is computed analytically by evaluating the constraints.

The first set is built with randomly sampled instances \[
    Z_R=\left\{\bm{\hat{z}}\in Z : \bm{\hat{z}}\sim \mathcal{U}\left[\{0,1\}^{JT}\right] \right\}
,\] where $\mathcal{U}\left[\{0,1\}^{JT}\right]$ denotes a uniform distribution over the set of all possible assignments for the binary variables.
The second set is built with candidate solutions from the neighborhood of the solutions in $Z^\star$, \[
    Z_N=\left\{\bm{\hat{z}}\in Z : \|\bm{\hat{z}}-\bm{z}^\star\|_0 \le \eta, \bm{z}^\star \in Z^\star \right\}
,\] where $\eta\in\mathbb{N}$ limits the size of the neighborhood. In practice, we build candidate solutions in $Z_N$ by randomly flipping at most $\eta$ values from a randomly selected candidate solution from $Z^\star$.
Intuitively, $Z^\star$ and $Z_N$ are used to teach the model the limits of the feasible region, while $Z_R$ carries general information about the domain of the problem.

% \subsubsection{Optimality classification}\label{sec:meth-opt-classification}

% For an instance of the 

\subsubsection{Optimal Solution Prediction}\label{sec:meth-sol-pred}

We want to train the SatGNN model to predict the variables' bias in optimal solutions for instances of the ONTS problem $I\in\mathcal{I}$.
More precisely, we want the model to estimate the probability that each binary variable takes a positive value in the optimal solution, which we will denote as \[
\bm{\hat{p}}(\bm{z}^\star = 1 | I) = \begin{bmatrix}
     \hat{p}(z^\star_{1,1} = 1 | I) \\ \vdots \\ \hat{p}(z^\star_{J,T} = 1 | I)]
\end{bmatrix}
.\]
Therefore, we have a node classification task for which we apply the sigmoid function at the output of SatGNN for each variable node such that
\begin{align*}
    {\rm SatGNN} : \mathcal{I} \times \Theta & \longrightarrow [0,1]^{JT} \\
                    I ; \theta & \longmapsto \hat{\bm{p}}(\bm{z}^\star = 1 | I) = {\rm SatGNN}(I;\theta)
,\end{align*}
where $\theta \in \Theta$ is the vector of trainable parameters.
Note that the most probable candidate solution $\bm{\hat{z}}=(\hat{\bm{x}},\hat{\bm{\phi}})\in \{0,1\}^{2JT}$ is easily obtained given the model's prediction as \[
    \hat{x}_{j,t} = \lceil \hat{p}(x^\star_{j,t} = 1 | I)\rfloor, \forall (j,t)\in\mathcal{J}\times\mathcal{T}
\] and similarly for $\hat{\phi}_{j,t}$.

One way to train the model is to minimize the BCE between the predicted probability and the single best solution known for each instance, minimizing the loss \[
    \min_{\theta} \mathcal{L}_{\rm opt\text{-}b}(\theta) = \sum_{(I,\bm{z}^\star)\in \mathcal{D}_{\rm opt\text{-}b}} {\rm BCE}({\rm SatGNN}(I; \theta),\bm{z}^\star) 
,\] where the dataset is built such that $\bm{z}^\star$ is the best solution available for each instance in $\mathcal{D}$, i.e., \[
    \mathcal{D}_{\rm opt\text{-}b} = \left\{ (I,\bm{z}^\star) \in \mathcal{I}\times Z : (I,Z^\star)\in \mathcal{D}, \bm{z}^\star = \arg\max_{\hat{\bm{z}}\in Z^\star} {\rm QoS}(\hat{\bm{z}}; \bm{u}_I) \right\}
,\] in which $\bm{u}_I$ is the vector of priorities from instance $I$ (see Sec. \ref{sec:problem}).

Another way is through the approach proposed by Nair et al.~\cite{nair_neural_2020}, in which multiple solutions are used as targets, being weighted by their objective value.
Note that the best-known solution is also used in this approach, along with sub-optimal solutions.
In this approach, the optimization can be described as \[
    \min_{\theta} \mathcal{L}_{\rm opt\text{-}m}(\theta) = \sum_{(I,Z^\star)\in \mathcal{D}_{\rm opt\text{-}m}} \sum_{\bm{z}^\star \in Z^\star} w(\bm{z}^\star; Z^\star,I) \cdot {\rm BCE}({\rm SatGNN}(I; \theta),\bm{z}^\star) 
,\] where \[
    w(\bm{z}^\star; Z^\star,I) = \frac{\exp({\rm QoS}(\bm{z}^\star; \bm{u}_I))}{\sum_{\bm{z} \in Z^\star}\exp({\rm QoS}(\bm{z}; \bm{u}_I))}
\] is the weight associated with each candidate solution found by the solver, which is built such that the better the objective, the higher the weight, and, for each instance, the weights add up to 1.
Note that we can directly take $\mathcal{D}_{\rm opt\text{-}m}\subseteq \mathcal{D}$.

\subsection{SatGNN-based Heuristic}\label{sec:meth-heuristics}

The output of the SatGNN as trained for the optimal solution prediction, that is, the predicted variables' bias, can be rounded to the closest integer (either 0 or 1) to generate the most probable candidate solution.
However, this is not expected to perform well as we have no feasibility guarantees; thus, any error in the network may generate an infeasible solution.
Given that ONTS problems of moderate size already have thousands of variables\footnote{The smallest instance evaluated by Rigo et al.~\cite{rigo_branch-and-price_2022} has 1746 binary variables, considering both $x$ and $\phi$ variables.}, infeasibility is likely to occur.
Therefore, we propose using the deep learning model to aid the optimization in three approaches: warm-starting, early-fixing, and trust region.

\subsubsection{Warm-starting}\label{sec:meth-heuristics-ws}

Another straightforward approach to using the information learned by the model is to provide (partial) solutions to a solver, warm-starting the optimization.
For example, the SCIP solver~\cite{bestuzheva_scip_2021} accepts complete and partial solutions to the problem, which are used to guide the inner heuristics during the optimization process.
We use the output of the model to determine which variables will compose the partial solution provided to the solver based on the \emph{confidence} of the model's prediction.
In other words, the closer the model's probability output is to the extreme values (0 or 1), the more confident it is of that assignment.

Formally, let $\hat{\bm{p}}(\bm{z}^\star = 1|I)$ be the output of SatGNN given an instance $I\in\mathcal{I}$ as defined in Sec. \ref{sec:meth-sol-pred}.
Then, we will denote $\bm{\kappa}(\bm{z}^\star|I) \in [0,1]^{2JT}$ the confidence the model has in each binary variable.
For variable $x_{j,t}$ of instance $I$, given that the model's output is $\hat{p}(x_{j,t}^\star = 1|I)$, then we can describe the respective confidence $\kappa(x_{j,t}|I)$ as \[
\kappa(x_{j,t}|I) = \begin{cases}
    \hat{p}(x_{j,t}^\star = 1|I), &\text{if}\quad\hat{p}(x_{j,t}^\star = 1|I) \ge 0.5 \\
    \hat{p}(x_{j,t}^\star = 0|I) = 1 - \hat{p}(x_{j,t}^\star = 1|I), &\text{otherwise}
\end{cases}
.\] The confidence associated with the $\phi_{j,t}$ variables can be described similarly.
Note that the confidence is always between 0.5 and 1.

Let us write $\bm{z}=(\bm{x},\bm{\phi}) = (z_1, \ldots, z_k,\ldots, z_{2JT})$.
We define $\mathcal{C}^{N}_{I}\subseteq \{1,\ldots,2JT\}$ as the set of indices of the $N$ variables that the model is most confident of, that is, $|\mathcal{C}^{N}_I| = N$ and \[
    \mathcal{C}^{N}_I = \left\{ k \in \{1,\ldots,2JT\} : \kappa(z^\star_k|I) \ge \kappa(z^\star_{k'}|I), \forall k' \not\in \mathcal{C}^{N}_I \right\}
.\] Then, a partial solution $\bar{\bm{z}}^{(N)}$ of size $N$ can be written \[
    \bar{\bm{z}}^{(N)} = \left[\hat{z}_{k}\right]_{k\in \mathcal{C}^{N}_{I}}
,\] which contains the predicted assignments of the highest confidence and can be provided to the solver.

Note that warm-starting does not configure a heuristic solution to the problem, as it just modifies the behavior of the heuristics already present in the algorithmic solution.
In other words, warm-starting will only modify the order of exploring the B\&B tree.
Therefore, we maintain optimality and feasibility guarantees, even in the worst-case scenario when the model provides the solver with bad, infeasible solutions.

\subsubsection{Early-fixing}

A heuristic solution can be made by fixing the value assignments based on the most confident biases predicted by SatGNN, similar to what is proposed in the Neural Diving approach by Nair et al.~\cite{nair_neural_2020}.
Compared to the warm-starting approach, instead of merely informing the solver, we modify the instance of the problem and fix the values of the variables that the model is most confident of before calling the solver.
More precisely, early-fixing is equivalent (in principle) to adding to the problem constraints of the form \[
    z_{k} = \hat{z}_{k}, \forall k\in \mathcal{C}^{N}_{I}
,\] which limits $N$ variables to the values predicted by the model.
In practice, however, no constraints are added, but the assignment in the existing constraints and the objective replaces the variables.
Thus, the resulting sub-problem will contain fewer binary variables and, thus, is expected to be faster to solve.

Note that every feasible solution to the early-fixed problem and the fixed variables is also feasible in the original instance.
However, an optimal solution to the sub-problem might not be optimal for the original instance.
Even worse, early-fixing the problem might render it infeasible if the model predicts a poor variable assignment.
Therefore, this approach of early-fixing is a matheuristic, as it uses mathematical optimization to find heuristic solutions.

\subsubsection{Trust Region}

Instead of fixing the variables that the model is most confident of, we may allow a slight deviation from the partial candidate solution.
In other words, we can use SatGNN's prediction to define a trust region~\cite{han_gnn-guided_2023}.
A new constraint is added to the problem of the form \[
    \sum_{k\in \mathcal{C}^N_I} \left|z_{k} - \hat{z}_{k} \right| \le \Delta
,\] where $\Delta \in \mathbb{N}$ is the parameter that defines the size of the trust region.
This limits the solution space to vectors in the vicinity of the partial candidate solution.

In the above definition, it is easy to see that the early-fix is a particular case of the trust region method with $\Delta=0$.
In fact, just like the early-fixing approach, allowing a trust region around the (partial) candidate solution also configures a matheuristic, as neither optimality nor feasibility are guaranteed.
