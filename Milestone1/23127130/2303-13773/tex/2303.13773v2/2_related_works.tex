\section{Related Work}\label{sec:rel-work}

The ONTS problem has received significant contributions in recent years, with different approaches and formulations.
At the same time, machine learning applications for optimization problems have become a prolific area of research.
This section briefly overviews our paper's most influential works in both areas.

Mathematical programming is consolidated as a practical approach for satellite scheduling problems~\cite{wang_dynamic_2013,wang_pure_2016,cui_application_2019}.
Targeting small satellites, Rigo et al.~\cite{rigo_task_2021} formulated the problem of maximizing task allocation under power availability constraints as an integer programming (IP) problem.
The formulation considers discrete time steps and information such as the maximum power input at each time step along the planning horizon, power consumption of tasks, execution periods, and task priorities.
This approach was able to provide energy-efficient allocations that improved mission value.

Seman et al.~\cite{seman_energy-aware_2022} extended the approach by \cite{rigo_task_2021} and proposed a Mixed-Integer Linear Programming (MILP) formulation to tackle the task scheduling in constellations of nanosatellites.
Camponogara et al.~\cite{camponogara_continuous-time_2022} applied the Multi-Operation Sequencing with Synchronized Start Times (MOS-SST) representation to the problem, maintaining an MILP formulation but extending the problem to continuous time.
The continuous-time feature allowed for greater flexibility and versatility, fundamental characteristics for decision-making during the design phase.
The evolution of formulations and methodologies highlights the continuous efforts to find the most efficient and effective solutions to the ONTS problem.

More recently, given the difficulty in solving complex instances of the ONTS problem, Rigo et al.~\cite{rigo_branch-and-price_2022} proposed a Dantzig-Wolfe decomposition, coupled with a branch-and-price (B\&P) methodology. This approach was designed to build a unique column-based formulation that produces feasible and optimal schedules. In addition, they leveraged the Dynamic Programming (DP) technique to identify optimal columns and speed up the whole process.
Their computational experiments significantly improved overall solution time compared to a commercial MILP solver, with a 70\% reduction in computation time.
%However, this approach relies heavily on the applicability of the decomposition, which is known to be very problem-dependent, and there is no known way to \emph{a priori} determine whether a given decomposable structure is present in the problem~\cite{kruber_learning_2017}.
%Furthermore, this, alongside the complexity of the optimization algorithm, results in a high development burden, making it prohibitive for some applications.
Despite these promising results, the B\&P method introduces specific challenges and limitations that preclude its universal application. One significant drawback is its heavy reliance on the suitability of the decomposition, which is notoriously problem-specific. Currently, no known method allows practitioners to \emph{a priori} ascertain the presence of a decomposable structure in a given problem~\cite{kruber_learning_2017}. This lack of a deterministic approach to identifying suitable problems adds a layer of complexity to the application of B\&P. Additionally, the complexity inherent in the decomposition and the optimization algorithm can result in a high development undertaking. The intricate nature of these processes requires specialized knowledge and expertise, potentially rendering the B\&P method prohibitive for particular applications or settings. Consequently, while the B\&P methodology offers substantial improvements in computational efficiency for specific problem instances, its applicability may be limited by these challenges, emphasizing the need for caution in considering it as a universal solution for all optimization problems.

Machine learning applications for optimization problems were first proposed in 1985, applying Hopfield neural networks to the Travelling Salesperson Problem (TSP)~\cite{hopfield_neural_1985}.
Due to the hardware limitations of the time~\cite{smith_neural_1999}, neural network applications to optimization problems have stayed out of the spotlight up to recent years, when developments in novel architectures, more powerful hardware, and promising published results have attracted the attention of the research community back to this area~\cite{bengio_machine_2021}.
One of the drivers of this change was the proposition of structured artificial neural networks able to handle the symmetries that optimization problems have~\cite{cappart_combinatorial_2022}, such as the invariance to permutation of constraints.
A significant example of such property for Combinatorial Optimization (CO) is the work of Khalil et al.~\cite{khalil_learning_2017}, which developed a greedy heuristic for CO problems on graphs using a GNN.
Gasse et al.~\cite{gasse_exact_2019} proposed to embed linear programming problems as a bipartite graph, generalizing the use of GNNs to any MILP.
The results presented in these works indicate that GNNs can learn the structures of MILP problems.

Many authors proposed using GNNs to predict solution values, aiming at using the learned model in heuristic solutions.
Ding et al.~\cite{ding_accelerating_2020} proposed using such GNNs to guide the Branch and Bound (B\&B) algorithm towards the variables the model had the most difficulty learning.
Khalil et al.~\cite{khalil_mip-gnn_2022} use the GNNs trained to predict biases of the binary variables to perform node selection and warm starting.
Nair et al.~\cite{nair_neural_2020}, in their approach named \emph{Neural Diving}, proposed to train the model to provide partial solutions, which generate sub-problems through variable fixing.
The multiple sub-problems are then solved using off-the-shelf solvers.
Han et al.~\cite{han_gnn-guided_2023} compare the fixing approach of \cite{nair_neural_2020} to their proposed approach of defining a trust region around the partial solution generated by the GNN, showing significant improvements over off-the-shelf solvers like SCIP and Gurobi.
These works highlight how promising building GNN-based heuristic approaches to MILP can be. 

To the best of our knowledge, our work is the first to apply deep learning models to satellite task scheduling.
Furthermore, machine learning application to MILP has not been extensively tested, as confirmed by the novelty of the works presented above and the lack of learning-based components in open-source solvers such as SCIP and CPLEX.
In other words, although promising, applying GNNs to MILP still needs to be well-understood and is not guaranteed to yield positive results.
In this context, the present work also contributes to the machine learning and combinatorial optimization area of research by validating novel techniques.
