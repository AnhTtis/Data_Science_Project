\section{Discussion}\label{sec:discussion}

In this section, we discuss the results obtained from a series of experiments conducted to address the research questions posed in the introduction.
The experiments aimed to evaluate the effectiveness of GNNs in solving the ONTS problem.
More specifically, we use our proposed model, SatGNN, which is based in the models by Gasse et al.\,\cite{gasse_exact_2019} and Hamilton et al.\,\cite{hamilton_inductive_2017}.
Our experiments evaluate whether SatGNN can learn feasibility and optimality given large instances of the ONTS problem, and whether the trained model can be used in heuristic solutions.

The results of the first set of experiments (Sec. \ref{sec:exp-feas}) indicate that the SatGNN can provide accurate feasibility estimations even in challenging scenarios.
Three scenarios of increasing difficulty were considered, and the results were quite promising, with over 89\% accuracy in all experiments.
In the most challenging scenario, SatGNN is evaluated on large ($J\in\{20, 22, 24\}$) unseen instances, but trained on small instances ($J\in\{9,13,18\}$), and it achieved 94.15\% accuracy in feasibility classification.
The remarkable accuracy indicates that SatGNN is highly effective at learning the constraints of the ONTS problem.
This performance is expected as the feasibility classification task requires the model to learn linear classification boundaries, which are derived from the linear constraints of the problem.
In other words, the model learns the indicator function of a convex set (considering the LP relaxation of the problem), which neural networks are known to be suitable for.

The second set of experiments (Sec. \ref{sec:exp-opt-pred}) aimed to predict optimal solutions to ONTS instances using SatGNN.
More specifically, SatGNN was trained to predict the biases of the binary variables for multiple instances of the ONTS problem.
Two training approaches were explored: one trained with a single target (the quasi-optimal solution) and another trained with multiple solutions (the best feasible solutions found).
Both approaches showed promising results, with no signs of overfitting, as indicated by the small difference between validation and test set performance.
Interestingly, the model trained with multiple solutions tended to be more confident in its predictions, particularly for the binary variables. This increased confidence could be valuable in guiding the optimization process, as it indicates the model's certainty about its predictions.

Although the results from the second set of experiments suggest that SatGNN can effectively predict optimal or near-optimal solutions to ONTS instances, we put the models to the test through a third set of experiments (Sec. \ref{sec:exp-heuristics}) in which we build (mat)heuristic solutions based on the output of the SatGNN trained for optimality prediction.
Namely, as detailed in Sec. \ref{sec:meth-heuristics}, three approaches were evaluated for applying the model's output: warm-start, early fix, and trust region.
Each approach is optimized for finding the best solution, giving the time budget (2 min.) and reducing the time to find a feasible solution (2 separate experiments).
First, we notice that in all direct comparisons, the SatGNN model trained with multiple solutions resulted in better heuristic solutions than the model trained with a single solution, as was suggested by the results of the second set of experiments.

Early-fixing the partial solution provided by the SatGNN models yielded the best results overall, showing a 43\% gain in the evaluation of the expected objective value within the time budget, and a 35\% reduction in the evaluation of the expected time to find a feasible solution.
The trust region approach, which can be seen as a relaxation of the early-fixing, was comparable to early-fixing in terms of the best solution found within the time limit, but overall seems to provide a worse trade-off, as both early-fixing and trust region do not provide optimality guarantees, but trust region takes longer to find good solutions to the ONTS problem.
Using the SatGNN models to warm-start the SCIP solver significantly reduced the time to find a feasible solution (in comparison to the baseline), but was overall worse than the two other approaches.
However, warm-start has the advantage of providing optimality guarantees, which makes it more widely applicable.

Across all experiments, a highlight of the GNNs' performance was the generalization to larger instances.
This characteristic is essential for problems with varying instance size and is not trivially achievable with traditional deep-learning models.
However, it is also key for tasks with higher acquisition costs for certain problem sizes, as in the case of the ONTS problem.
Large instances of optimization problems are the ones that drive the research of heuristic solutions, as they are usually more expensive to solve; however, as we need to solve instances to create a training dataset, it often becomes infeasible to train the deep learning models on large instances.
In this context, the generalization results from our experiments suggest that GNNs can be effectively trained using easy (cheap to acquire) instances of the problem, and be used on the hard instances of interest.

Generating reliable instances to train and evaluate solvers is a key point in such a project, as the confidence of the results depends on how carefully instances are designed to compose the test set~\cite{smith-miles_generating_2015}.
Data generation is particularly critical when historical data is not available~\cite{bengio_machine_2021}, which motivates the research on algorithms for generating reliable instances~\cite{smith-miles_generating_2015,malitsky_structure-preserving_2016}.
We follow the problem definition of the FloripaSat-I mission~\cite{marcelino_critical_2020} to define the parameters' ranges used to sample new instances uniformly.
Although the data generation process is reliable, it still depends on the optimization of every randomly generated instance.
Furthermore, as we restrict ourselves to feasible instances, we only add to the dataset instances for which the solver could find at least one feasible solution within the time budget, effectively restricting our data to an easier sub-problem~\cite{yehuda_its_2020}.
Given the nature of the ONTS problem, a future research direction could be generating large instances by combining the job parameters from easier instances, thus generating instances that extrapolate the time budget restriction.

\section{Conclusion}\label{sec:conclusion}

This work has proposed a novel approach to tackle the ONTS problem using graph neural networks.
More specifically, we investigated whether a GNN can learn the structure of the problem and be used to build effective heuristic solutions.
Our experiments showed that our proposed architecture, SatGNN, successfully classifies the feasibility of candidate solutions and is also able to provide reliable partial solutions to varied instances of the ONTS problem.
Not only was the model able to generalize to unseen instances, but it also showed promising results on out-of-distribution instances, which were larger than the ones seen during training.
This outcome shows how the inherent symmetries of graph neural networks make them suitable for dealing with the structures of the optimization problem.

By leveraging partial solutions provided by the SatGNN model, we built heuristic solutions to the ONTS problem that outperformed the SCIP solver in hard instances.
More specifically, by fixing the variable assignment from the partial solution provided by SatGNN, our heuristics were able to improve up to 43\% in the expected objective value of the best solution found within the time budget, and reduce up to 35\% in the expected time to find a feasible solution.

Overall, the experiments presented in this paper showcase the potential of GNNs for addressing the ONTS problem.
The high accuracy in feasibility classification, the ability to predict optimal solutions, and the effectiveness of SatGNN-based heuristics suggest that this approach has the potential to revolutionize the way complex space mission scheduling problems are tackled, enabling more efficient and reliable scheduling for nanosatellite missions.
Further research could explore the scalability of these methods to larger problem instances, problems with satellite constellations, and real-world applications in space mission planning and scheduling.
