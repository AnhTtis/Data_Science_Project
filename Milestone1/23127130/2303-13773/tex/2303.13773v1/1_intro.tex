\section{Introduction} \label{sec:intro}
Nanosatellites are gaining popularity for various applications, including Earth observation and scientific research. Due to its limited computational and energy resources, this spacecraft standard is associated with difficulties in mission planning despite the format's clear advantages, such as low cost and fast development time. Scheduling tasks is essential to mission planning, as it maximizes resource usage and increases data quality, cost savings, and mission success. The Offline Nanosatellite Task Scheduling (ONTS) problem is crucial in developing, deploying, and operating nanosatellites in orbit. It involves finding the best schedule for tasks execution in orbit, taking into account Quality-of-Service (QoS) factors such as priority, minimum and maximum activation events, execution time-frames, periods, and execution windows, as well as the limitations of the satellite's power resources and complexities of energy harvesting and management systems. 

Traditional mathematical formulations and exact algorithms have been proposed to solve the ONTS problem, starting from Integer Programming (IP) \cite{RIGO2021550} to Mixed Integer Programming (MILP)  \cite{RIGO2021114784, s22103715} and Continuous-Time techniques \cite{CAMPONOGARA2022105945}. More recently, 
given the difficulty in solving complex instances of the ONTS problem, Rigo et al.  \cite{RIGO2022168} proposed a Dantzig-Wolfe decomposition and a branch-and-price (B\&P) methodology to build a unique column-based formulation for producing feasible and optimal schedules. They also explored the Dynamic Programming (DP) technique to find optimal columns. Their computational experiments significantly improved overall solution time compared to a commercial MILP solver, with a 70\% reduction in computation time. The evolution of these formulations and methodologies highlights the continuous efforts to find the most efficient and effective solutions to the problem. 


Meanwhile, several recent investigations have considered machine learning tools to address combinatorial optimization problems \cite{BENGIO2021405, KARIMIMAMAGHAN2022393}, such as the single machine problem \cite{PARMENTIER20231032}, resource-constrained project scheduling \cite{GUO2023579}, and knapsack problems \cite{YANG2022828}. Graph Neural Networks (GNN), in particular, has gained popularity in recent years to solve combinatorial optimization problems when the underlying structure may be represented as a graph \cite{ZHANG2023205}. The problem's graph structure is employed to transfer information between nodes, and several iterations of message passing update the node representations. The final representations of nodes can be utilized to generate predictions or solve optimization problems. GNNs are well-suited for handling combinatorial optimization problems because they can simulate complex problem structures and convey information across nodes. They have been successfully used for many optimization problems, such as traveling salesman problems \cite{joshi2019efficient}, scheduling tasks, and facility location problems. 

A popular approach has been the application of GNNs to learn variable selection for branching, directly \cite{shen2021learning}, with the help of  Markov Decision Process \cite{qu2022improved} or multi-layer perceptrons \cite{gupta2020hybrid}. For instance, the authors of \cite{gasse2019exact} were the first to suggest a novel graph convolutional neural network model that uses the inherent variable-constraint bipartite graph representation of MILPs, which is trained via imitation learning from a strong branching expert method. They show, using complex problems, that the technique can beat expert-designed branching rules applied in cutting-edge solvers, generating policies that outperform state-of-the-art machine-learning approaches for branching. They concluded that their model was a superior design choice before branching in MILP, and subsequent work demonstrated the feasibility of their strategy on a larger range of combinatorial problems tested with graph-based reinforcement learning techniques.

In the MILP framework, \cite{gupta2020hybrid} presents a novel hybrid architecture for efficient branching on GPUs. For branching, they suggested an architecture to combine the capabilities of GNN with computationally cheap multi-layer perceptrons (MLP). The authors tested their technique on four classes of MILP problems and found that it reduced solver running time by up to 26\% when compared to state-of-the-art solutions without a GPU, even when extrapolated to more complex problems than it was trained on. Further works explore GNNs in exact algorithms to select which cutting plane to add \cite{pmlrv162paulus22a} or even learn a parallel Lagrangean decomposition by encoding the duals on a bipartite graph \cite{abbas2022doge}.

Several researchers have also explored GNNs to learn and improve on heuristic approaches for solving combinatorial optimization problems \cite{ding2020accelerating}, such as the large neighborhood search \cite{nair2020neural, sonnerat2021learning}. In \cite{garmendia2022neural}, a Neural Improvement (NI) model for graph-based problems is presented that can efficiently guide various hill-climbing algorithms. The model leverages information stored in both nodes and edges and may be used to replace classic local-search algorithms while requiring less processing effort. The authors examine advanced models in order to avoid becoming locked in local optima, as well as to construct models for population-based metaheuristics. Experiments reveal that the NI model outperforms traditional variants for the preference ranking, traveling salesman, and graph partitioning problems.


 A general framework for augmenting MILP solvers with data-driven insights by predicting variable biases using GNN topologies is proposed by \cite{khalil2022mip}. The predicted biases are used to steer the solver, substituting heuristic components by storing the variable-constraint interactions as bipartite graphs. The framework is demonstrated to significantly enhance the solver's performance on two classes of difficult binary MILPs, and it is extendable to additional important solver components. The work of \cite{liu2022learning} explores learning to fix variables early in iterative approximation approaches applied to IP problems. The authors model the early fixing as a Markov decision process and train it through imitation learning. They undertake comprehensive experiments on three typical IP applications and demonstrate that their technique may dramatically accelerate prior approximation methods by up to ten times in most situations while generating comparable or even better solutions. The authors also analyze the use of their suggested learning-based early fixing approach and potential prospects for increasing its efficacy.

Beyond the pure application of GNN into optimization problems, this subfield of ML has been rapidly evolving as well, where unique new techniques have been proposed recently on how to explore the graph architecture in neural networks better \cite{yang2021graph}, such as gated graphs \cite{li2015gated}, large graphs \cite{hamilton2017inductive}, and directional graphs \cite{beaini2021directional}. In \cite{GINEhu2019strategies}, a new pre-training strategy for graph datasets is introduced, named Graph Isomorphism Network with Edge Features (GINEConv). It involves training a GNN at both node and graph levels to learn good local and global representations simultaneously. The authors systematically studied pre-training on multiple graph classification datasets. Their proposed strategy significantly improves out-of-distribution generalization, achieving state-of-the-art performance. In contrast, \cite{GAT1velivckovic2017graph} introduced the now widely used Graph Attention Network (GAT) technique -- later improved in \cite{GATbrody2021attentive}. GAT uses masked self-attention layers to allow nodes to attend to their neighbor's features and implicitly assign weights to different nodes without costly matrix operations or prior knowledge of the graph structure. 

Taking advantage of all this recent progress in GNN research and its successful application to optimization problems, this study proposes a novel solution methodology to the ONTS problem. By representing the problem as a bipartite graph, we leverage the robust representation learning capabilities of GNNs. The parameters of the MILP problem generate feature vectors fed into the model, allowing us to encode both the structure and parameters of each instance of the problem. GNNs can handle graphs of arbitrary size to handle optimization problems with varying numbers of variables and constraints. Our method employs two fully-connected, single-layer multilayer perceptron (MLP) networks with ReLU activations to encode the features of variables and constraints into hidden features that are updated using a two-step message-passing mechanism. The parameters can then be optimized similarly to conventional deep learning models. The proposed GNN model is then shown here to accelerate task scheduling by efficiently learning the relationships between tasks and resources and optimizing mission planning.

Furthermore, research in Artificial Intelligence (AI) as a whole has recently focused on Explainable Artificial Intelligence (XAI), which analyzes the factors that impact solution quality and their interconnections in AI methodologies \cite{9965435, bacardit2022intersection}, such as those of traffic classification \cite{9311723} of variable selection \cite{singh2022towards}. Similarly, Explainable Graph Neural Networks (XGNN) can offer insights into the underlying mechanisms of these black-box models and assist researchers and users in understanding better how these models are producing predictions \cite{yuan2022explainability, yuan2020xgnn} through parameterized explanations \cite{luo2020parameterized}, probabilistic explanations \cite{vu2020pgm}, or attribution evaluation \cite{sanchez2020evaluating}. A model-neutral method for explaining the predictions of any Graph Neural Network (GNN) on any graph-based machine learning is presented in \cite{ying2019gnnexplainer}. The method uses the recursive neighborhood-aggregation methodology of GNNs to pinpoint significant graph paths and pertinent node characteristic data sent along each edge. The approach uses relational structures, including rich node-featured graphs, and offers an interface for analyzing GNN predictions, troubleshooting GNN models, and spotting systematic error patterns. In the study, GnnExplainer is defined as an optimization job that optimizes the mutual information between the prediction of a GNN and the distribution of potential subgraph structures.

In \cite{pope2019explainability},  the authors create graph analogs of three well-known explainability techniques for GNNs, including gradient-weighted CAM (Grad-CAM) and contrastive EB. These techniques include contrastive gradient-based saliency maps, class activation mapping, and excitation backpropagation (c-EB). Moreover, they examine the important sub-graphs derived from the explanations and note recurring trends. Our work also aims to explore explainability to understand better how a GNN and its attributes can contribute to the final quality of ONTS problem solutions, providing insights into this field of knowledge.


 This paper is organized as follows: Section two describes the problem statement in detail, providing context and background information. The third section describes how the problem was approached and the methods employed for the investigation. The computational experiments are described in detail in the fourth section, along with a succinct summary of the findings. This study finishes with section five, summarizing and discussing the key findings.

 
 
%\cite{wang2019dgl}
