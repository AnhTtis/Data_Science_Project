
\section{Methodology}
%%%%%%%%%%

The most traditional approach to use a deep learning model in a task in which the input is an optimization problem is to vectorize all problem parameters and feed them to a traditional neural network such as a multilayer perceptron (MLP) \cite{Anderson2022}.
However, this might not even be possible, as different instances of a problem might have different constraints and/or variables and, thus, would yield vectors of varying sizes to the deep learning model.

Furthermore, even if the dimensions are fixed, traditional neural networks do not exploit the symmetries that exist in an optimization problem.
There is no inherent ordering in the constraints nor in the variables of an optimization problem, i.e., an instance is not changed if we change the order of the rows (columns) of $A$ along with the elements of $b$ ($c$).
By vectorizing these elements, we impose an order, upon which the output of the neural network will depend.
Therefore, these symmetries are not embedded in the structure of a traditional deep learning model, and would need to be enforced during training, i.e., the model would need to learn these symmetries.
This might slow down significantly the training and will not give any guarantees that the model will generalize with the given knowledge.

%%%%%%%%%%%%%%%%%%%%%%%%%5
\subsection{Graph Neural Networks}\label{sec:gnns}

Graph neural networks, or message-passing neural networks, are generalizations of convolutional neural networks from grid-structured data to graphs.
GNNs work by propagating features between neighboring nodes recurrently.
Let $G = (V, E)$ be a graph and $H^{(0)} \in \mathbb{R}^{n \times d}$ an initial feature matrix associated with the nodes, in which each row $h^{(0)}_v \in \mathbb{R}^d$ is the feature vector of node $v\in V$.
At each layer $l\in\{1,...,L\}$ of the GNN, and for each node $v\in V$, we first compute the messages $m_{u,v}^{(l)}$ propagated by its neighbors $u\in \mathcal{N}(v)$ based on their features $h_u^{(l-1)}$,
\begin{equation}\label{eq:message-passing-messages}
    m_{u,v}^{(l)} = M_l(h_u^{(l-1)}),\, u\in \mathcal{N}(v)
,\end{equation}
where $\mathcal{N}(v)$ represents the set of neighbors of $v$, and $M_l(\cdot)$ is the message function of layer $l$.
Then, the features of node $v$ are updated with the information from these messages
\begin{equation}\label{eq:message-passing-updates}
    h_v^{(l)} = U_l\left(h_v^{(l-1)}, {\tt Aggregation}\left(\{m^{(l)}_{u,v} : u\in \mathcal{N}(v) \}\right)\right)
,\end{equation}
where $U_l(\cdot)$ is the update function of layer $l$, and ${\tt Aggregation}$ is a function that receives multiple message vectors and returns a single vector.
The most usual choice for ${\tt Aggregation}$ is the sum, but many are the possibilities, such as
\begin{align}
{\tt Aggregation} = \begin{cases}
    \frac{1}{|\mathcal{N}(v)|} \sum\limits_{u \in \mathcal{N}(v)} m_{u,v}^{(l)}, & \textrm{if mean} \\  
        %%%
    \underset{u \in \mathcal{N}(v)}{\max}  m_{u,v}^{(l)}, & \textrm{if max} \\   
        %%%
    \sum\limits_{u \in \mathcal{N}(v)} m_{u,v}^{(l)}, & \textrm{if sum} \\ 
        %%%
    \sum\limits_{u \in \mathcal{N}(v)} \alpha_{u,v} m_{u,v}^{(l)}, & \textrm{if attention} \\
\end{cases}
\end{align}
%%
where $\alpha_{u,v}$ is the attention weight for node $u$ given node $v$. The attention weights can be learned using a neural network or other techniques.
Furthermore, the message function can easily be extended to consider the edge weight (or even edge features) along with the feature vectors of the neighbors.

% Applying the message-passing operations described in equations \ref{eq:message-passing-messages} and \ref{eq:message-passing-updates} is akin to performing a convolution on the graph and its node features.
% Therefore, given a graph $G$ with $n$ nodes and a feature matrix $H\in\mathbb{R}^{n\times d}$, we will represent the message-passing operations using the notation \[
% Conv(G, H) = \begin{bmatrix}
%     \vdots \\
%     U\left(h_v, {\tt Aggregation}\left(\{M(h_u) : u\in \mathcal{N}(v) \}\right)\right) \\
%     \vdots
% \end{bmatrix}
% .\]
A common approach is to define the message functions $M_l, l=1,\ldots,L$ as linear operators over the hidden features of the neighbors, aggregate these messages by summing, and use the ReLU activation function with a bias as the update functions $U_l, l=1,\ldots,L$. We use the approach of \cite{kipf_semi-supervised_2017} as a reference point and write
\begin{equation}\label{eq:graph-conv}
\begin{aligned}
    % M_l(h_u^{(l-1)}) &= \frac{1}{c_{vu}}W^{(l)}h_u^{(l-1)} \\
    m_{u,v}^{(l)} &= \frac{1}{c_{vu}}W^{(l)}h_u^{(l-1)},\, u\in \mathcal{N}(v) \\
    h_{v}^{(l)} &= \text{ReLU}\left(b^{(l)} + \sum_{u \in \mathcal{N}(v)} m_{u,v}^{(l)}\right)
\end{aligned}
\end{equation}
where $c_{vu} = \sqrt{|\mathcal{N}(u)|}\sqrt{|\mathcal{N}(v)|}$ with $|\mathcal{N}(v)|$ denoting the number of neighbors, and $W^{(l)}\in \mathbb{R}^{d\times d},b^{(l)}\in\mathbb{R}^d$ are (learnable) parameters.

A more recent method was proposed by \cite{hamilton2017inductive} and named SAGE (SAmple and aGgrEgate). The authors propose to directly aggregate the features of the neighbors, i.e., to use the identity as the message function and apply a linear operator with a nonlinear activation as the update function.
Putting it into terms, 
\begin{equation}\label{eq:sage-conv}
\begin{aligned}
    m_{u,v}^{(l)} &= h_u^{(l-1)},\, u\in \mathcal{N}(v) \\
    h_{v}^{(l)} &= \text{ReLU}\left(b^{(l)} + W^{(l)}_1 h_v^{(l-1)} + W^{(l)}_2 {\tt Aggregation}(m_{u,v}^{(l)},\, u\in \mathcal{N}(v))\right)
\end{aligned}
\end{equation}
where $W^{(l)}_1,W^{(l)}_2\in \mathbb{R}^{d\times d},b^{(l)}\in\mathbb{R}^d$ are the parameters.
The authors suggest using more complex aggregation operators, such as an LSTM and a fully-connected single-layer neural network followed by a pooling operation (element-wise maximum).

After recurrent message passing operations through the $L$ layers of a GNN, $H^{(L)}$ can be further aggregated to generate a single feature vector of the entire graph.
The GNN can be trained end-to-end by minimizing a prediction loss based on its outputs, optimizing its parameters (\textit{e.g.}, $W^{(l)}$ and $b^{(l)}$ of \eqref{eq:graph-conv}) in the same way as a traditional deep learning model.

% https://arxiv.org/pdf/1710.10903.pdf
% https://arxiv.org/pdf/2105.14491.pdf

%%%%%%%%%%%%%%%%%%%%%%%
\subsection{GNNs for Combinatorics}

Given a linear problem, we can build a graph $G=(V,E)$ in which we add one node for each variable of the problem, one node for each constraint, and connect each variable node to constraint nodes whenever the coefficient of the respective variable is not null in the respective constraint.
    More precisely, given the problem of the form 
\begin{equation}\label{eq:opt}
\begin{aligned}
\max & \quad c^T x \\
\text{s.t.:} & \quad Ax \ge b \\
\end{aligned}
\end{equation}
where $x\in \mathbb{R}^n$ and $b\in \mathbb{R}^m$, we can build a graph $G=(V_{\textrm{var}}\cup V_{\textrm{con}}, E)$, in which $|V_{\textrm{var}}| = n$, $|V_{\textrm{con}}|=m$, and $E=\{(v_{var,i},v_{con,j}) : A_{i,j} \neq 0\}$.
Intuitively, the graph represents the structure of the problem at hand, the relationship between variables and constraints.
Note that this approach yields a bipartite graph, that is, a graph in which the nodes are separated into two disjoint sets, $V_{\textrm{var}}$ and $V_{\textrm{con}}$, with edges connecting only nodes from different sets.

% TODO: review this example (maybe redo the figure)
For illustration purposes, consider an optimization problem like Eq. \ref{eq:opt} with
\begin{equation}\label{ilustra_bi}
c = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}; ~\\
A = \begin{bmatrix} 1 & 2 & 0 \\ 0 & 1 & -1 \\ 3 & 0 & 1 \end{bmatrix}; ~\\
b = \begin{bmatrix} 2 \\ 1 \\ 4 \end{bmatrix}
\end{equation}
%
and $x = [x_1, x_2, x_3]^T$. The bipartite graph can be represented as in Figure \ref{fig:ilustra_b}.

\begin{figure}[!htb]
\centering
\begin{tikzpicture}
\node[circle,draw,fill =green!40] (x1) {$x_1$};
\node[ right = of x1,circle,draw,fill =green!40] (x2)  {$x_2$};
\node[ right = of x2,circle,draw,fill =green!40] (x3) {$x_3$};

\node[ below = of x1,circle,draw,fill =blue!40] (c1) {$b_1$};
\node[ below = of x2,circle,draw,fill =blue!40] (c2) {$b_2$};
\node[ below = of x3,circle,draw,fill =blue!40] (c3) {$b_3$};
\draw (x1) -- (c1);
\draw (x2) -- (c1);
\draw (x3) -- (c2);
\draw (x1) -- (c3);
\draw (x2) -- (c2);
\draw (x3) -- (c3);
\end{tikzpicture}
\caption{Bipartith graph representation of Eq. \eqref{ilustra_bi}}\label{fig:ilustra_b}
\end{figure}

By representing an optimization problem as a graph, we can feed it to a GNN.
The parameters of the optimization problem can be used to generate the feature vectors fed to the model, enabling us to codify not only the structure but also the parameters of any given instance of the problem.
Because of the convolutional nature of the message-passing iterations of the GNNs, the model can deal with arbitrary-sized graphs, which enables us to handle optimization problems with varying variables and constraints with the same GNN.
Furthermore, the message function is invariant to the ordering of the neighboring nodes (see Eq. (\ref{eq:message-passing})), which are precisely the symmetries of the optimization problem (order of variables and constraints).
% TODO: maybe add a concluding sentence here, like "therefore, the GNN is suitable for optimization problems"

\subsection{SatGNN}\label{sec:sat-gnn}

We name \emph{SatGNN} the network that serves as a basis for the experiments reported in the next section.
To encode the features associated with the variables and the constraints into the hidden features of the first layer $H^{(0)}\in \mathcal{R}^{(n+m)\times d}$, we use two fully-connected, single-layer MLPs, $\textrm{NN}_{\textrm{var}}$ and $\textrm{NN}_{\textrm{con}}$ with ReLU activations.
We can write \[
h^{(0)}_{v} = \begin{cases}
\textrm{NN}_{\textrm{var}}(f_v), & v \in V_{\textrm{var}} \\
\textrm{NN}_{\textrm{con}}(f_v), & v \in V_{\textrm{con}}
\end{cases}
,\] where $f_v$ is the vector of features associated with each constraint or variable node.
In our experiments, for a node $v_{var,i} \in V_{\textrm{var}}$ associated with variable $x_i$, the feature vector is $f_{v_{var,i}} = (\hat{x}_i, c_i)$, where $\hat{x}$ is a candidate solution and $c_i$ is the weight of variable $x_i$ in the objective function.
   Likewise, for a constraint node $v_{con,i} \in V_{\textrm{con}}$ associated with the $i$-th constraint, $f_{v_{\textrm{con}},i} = (b_i, s_i)$, where $s_i\in \{=,\ge,\le\}$ models the constraint type.

% TODO: review if this change of notation is really necessary; it is quite confusing for the reader.
At the core of the model are $MP$ operators, which perform the update of the hidden features of the nodes through message-passing, as described in Section \ref{sec:gnns},
\begin{equation*}
    H_{\mathcal{N}(v)}^{(l)} = \textrm{MP}_l(h_{v}^{(l-1)}, H_{\mathcal{N}(v)}^{(l-1)}, w_{\mathcal{N}(v)}),
\end{equation*}
where $H_{\mathcal{N}(v)}^{(l-1)} = \{ h^{(l-1)}_u : u \in \mathcal{N}(v) \}$ is the set of hidden features of the neighbors of the target node and $w_{\mathcal{N}(v)} = \{w_{u,v} : u \in \mathcal{N}(v)\}$ is the set of edge weights.
However, we generalize this operator to apply multiple convolutions at each node instead of applying a single convolution, considering the same context.
The application of an MP operator with $K$ convolutions is illustrated in Algorithm \ref{alg:mp-operator}.
This allows for more complex features to be extracted at each model layer.

\begin{algorithm}[!htb]
\SetAlgoLined
\KwData{Target node $v$, node features $h_v$, neighbors' features $H_{\mathcal{N}(v)}$, edge weights $w_{u,v}, \forall u \in \mathcal{N}(v)$.}
\KwResult{Updated node features $h_v^{*}$.}
% Initialize node embeddings: $h_i^{(0)} = x_i$\;
$h^{(0)} \gets h_v$ \\
\For{$k \gets 1$ \KwTo $K$}{
    $h^{(k)} \gets U^{(k)} \left( h^{(k-1)}, {\tt Aggregation}^{(k)}\left(M^{(k)}(h_u,w_{u,v}) : u\in \mathcal{N}(v)\right)\right)$
}
$h_v^{*}\gets h^{(K)}$
% \For{$i \in V_1 \cup V_2$}{
% $h_i \gets h_i^{(K)}$;
% }
\caption{Application of an $MP$ operator with $K$ convolutions to update the features of a node $v$ through message-passing.}\label{alg:mp-operator}
\end{algorithm}

The message-passing is split into two steps, one for each set of nodes, similar to the approach of \cite{gasse2019exact}.
At each layer, the messages are propagated first from the variable nodes to the constraint nodes and then from the constraint nodes to the variable nodes, exploiting the bipartite nature of the graph.
Algorithm \ref{alg:sat-gnn-message-passing} describes this process with further detail.

Finally, the output of model is generated from the last hidden feature vectors of the variable nodes, generating an output in the same shape as the problem's variable vector.
The hidden features are fed to an MLP with two hidden layers and ReLU activations $\textrm{NN}_{\textrm{out}}$, which maps each $d$-dimensional vector into a single output, \textit{i.e.}, 
\begin{equation*}
\hat{y}_{v} = \textrm{NN}_{\textrm{out}}(h_{v}^{(L)}), \forall v \in V_{\textrm{var}}.
\end{equation*}

Figure \ref{fig:sat-gnn-overview} shows an overview of the architecture.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{figures/SatGNN.png}
    \caption{Overview of the components of \emph{SatGNN} and the operations it performs given an optimization problem (embedded as a bipartite graph $G$). $H$ variables represent the sets of hidden features of the nodes. The connection of $G$ and both $MP$ operators represents both the weights of the edges as well as the neighborhood information.}
    \label{fig:sat-gnn-overview}
\end{figure}

\begin{algorithm}[!htb]
\SetAlgoLined
\KwData{Bipartite graph $(V_{\textrm{var}}, V_{\textrm{con}}, E)$, node features $H^{(0)} \in \mathbb{R}^{(n+m)\times d}$, edge weights $w_e \in \mathbb{R}, \forall e \in E$, number of message passing iterations $L$.}
\KwResult{Node embeddings $H^{(L)}$.}
% Initialize node embeddings: $h_i^{(0)} = x_i$\;
\For{$l \gets 1$ \KwTo $L$}{
    \For{$v_{\textrm{con}} \in V_{\textrm{con}}$}{
        % $m_{v_{\textrm{con}}}^{(l)} \gets \sum_{v_{\textrm{var}}\in \mathcal{N}(v)} M_l(h_{v_{\textrm{con}}}^{(l-1)}, h_{v_{\textrm{var}}}^{(l-1)}, w_{v_{\textrm{var}},v_{\textrm{con}}})$ \\
        $h_{v_{\textrm{con}}}^{(l)} \gets \textrm{MP}_{\textrm{con}}(h_{v_{\textrm{con}}}^{(l-1)}, H_{\mathcal{N}(v_{\textrm{con}})}^{(l-1)}, w_{\mathcal{N}(v_{\textrm{con}})})$
    }
    \For{$v_{\textrm{var}} \in V_{\textrm{var}}$}{
% $h_i^{(k)} \gets \sigma \left( \sum_{j \in \mathcal{N}(i) \cap V_1} W^{(k)}h_j^{(k-1)} + b^{(k)} \right)$;
        % $m_{v_{\textrm{var}}}^{(l)} \gets \sum_{v_{\textrm{con}}\in \mathcal{N}(v)} M_l(h_{v_{\textrm{var}}}^{(l-1)}, h_{v_{\textrm{con}}}^{(l)}, w_{v_{\textrm{con}},v_{\textrm{var}}})$ \\
        % $h_{v_{\textrm{var}}}^{(l)} \gets U_l(h_{v_{\textrm{var}}}^{(l-1)}, m_{v_{\textrm{var}}}^{(l)})$
        $h_{v_{\textrm{var}}}^{(l)} \gets \textrm{MP}_{\textrm{var}}(h_{v_{\textrm{var}}}^{(l-1)}, H_{\mathcal{N}(v_{\textrm{var}})}^{(l)}, w_{\mathcal{N}(v_{\textrm{var}})})$
    }
}
% \For{$i \in V_1 \cup V_2$}{
% $h_i \gets h_i^{(K)}$;
% }
\caption{Message passing in a bipartite graph.}\label{alg:sat-gnn-message-passing}
\end{algorithm}

\subsection{XAI for GNN}

Explainable Artificial Intelligence (XAI) refers to the development of AI models that can explain their predictions and human-comprehensible decisions. As AI models are increasingly utilized in high-stakes domains, such as healthcare and finance, where understanding why a model makes a specific prediction is critical, XAI is gaining importance. 

%GNNs, also known as Graph Neural Networks, are a sort of deep learning model that may be applied to a variety of graph-based tasks, such as node classification, link prediction, and graph categorization. GNNs are especially beneficial for graph-based challenges because they can handle relational data in an organized manner and identify the underlying patterns in the graph. 

XAI can be performed in the context of GNNs by employing interpretable models or interpretability approaches that reveal the inner workings of the GNN model. For example, feature importance analysis can be used to determine which graph features are most important for the prediction made by the GNN. The intermediate representations learned by the GNN can also be visualized using the activations visualization technique. These illustrations help show how the GNN analyzes data and generates predictions.

For instance, the authors in \cite{gnnexplainer} introduce GNNExplainer, a new approach for explaining Graph Neural Network (GNN) predictions in graph-based machine learning tasks. GNNs are powerful, but explaining their predictions is challenging due to their complexity. GNNExplainer identifies a compact subgraph, and a subset of node features important for GNN predictions, allowing for consistent and concise explanations across instances. The approach maximizes the mutual information between GNN predictions and subgraph structures. Experiments show that GNNExplainer outperforms other methods and can identify important graph structures and node features, providing interpretability and insights into faulty GNNs.

\subsection{Hyperparameter Optimization}\label{sec:hp-tuning}

Hyperparameter optimization is an essential task in machine learning that involves adjusting the hyperparameters of a model so that its performance is maximized.
Hyperparameters are not learned during the training and must be defined before the training begins, e.g., learning rate, number of layers, number of learnable parameters, and regularization factor.
Adjusting the hyperparameters can be done manually, through trial-and-error iterations, using an expert's intuition, or automatically treating the relationship between the hyperparameters and the model performance as a black-box function.

Optuna is a Python library that provides a flexible and efficient platform for hyperparameter optimization using a variety of algorithms, including TPE (Tree-structured Parzen Estimator).
   %%%
TPE is a Bayesian optimization variant that models the hyperparameter distribution using a tree-structured Parzen estimator. Let $\boldsymbol{x} = (x_1, x_2, ..., x_d)$ denote a set of $d$ hyperparameters, and let $f(\boldsymbol{x})$ be the cost function to be optimized.

The TPE algorithm divides the hyperparameter space into two regions: a region containing the hyperparameters that have been observed to result in a good performance, denoted by $\boldsymbol{u}$, and a region containing the hyperparameters that have not been observed to result in a good performance, denoted by $\boldsymbol{v}$. TPE constructs the acquisition function $a(\boldsymbol{x})$ as follows:
%
\begin{align}
a(\boldsymbol{x}) = \frac{p_{\boldsymbol{u}}(\boldsymbol{x})}{p_{\boldsymbol{v}}(\boldsymbol{x})},
\end{align}
%
where $p_{\boldsymbol{u}}(\boldsymbol{x})$ and $p_{\boldsymbol{v}}(\boldsymbol{x})$ are the density functions estimated by the tree-structured Parzen estimator for the regions $\boldsymbol{u}$ and $\boldsymbol{v}$, respectively. Specifically, $p_{\boldsymbol{u}}(\boldsymbol{x})$ and $p_{\boldsymbol{v}}(\boldsymbol{x})$ are estimated as follows:
%
\begin{align}p_{\boldsymbol{u}}(\boldsymbol{x}) = \frac{1}{|S_{\boldsymbol{u}}|}\sum_{\boldsymbol{y}\in S_{\boldsymbol{u}}} K\left(\frac{\boldsymbol{x} - \boldsymbol{y}}{\sigma_{\boldsymbol{u}}}\right),
\end{align}
%
and
%
\begin{align}
p_{\boldsymbol{v}}(\boldsymbol{x}) = \frac{1}{|S_{\boldsymbol{v}}|}\sum_{\boldsymbol{y}\in S_{\boldsymbol{v}}} K\left(\frac{\boldsymbol{x} - \boldsymbol{y}}{\sigma_{\boldsymbol{v}}}\right),
\end{align}
%%
where $S_{\boldsymbol{u}}$ and $S_{\boldsymbol{v}}$ are the sets of hyperparameters observed in regions $\boldsymbol{u}$ and $\boldsymbol{v}$, respectively, $K(\cdot)$ is a kernel function, and $\sigma_{\boldsymbol{u}}$ and $\sigma_{\boldsymbol{v}}$ are bandwidth parameters. The TPE algorithm selects the next set of hyperparameters to evaluate by maximizing the acquisition function:
%%
\begin{align}
\boldsymbol{x}_{\textrm{next}} = \arg\max_{\boldsymbol{x}} a(\boldsymbol{x}).
\end{align}

This process is repeated until the optimal set of hyperparameters is found, or a stopping criterion is met.

\subsection{Data}

To supply the models with data suitable for learning the tasks of interest, we generate new instances of the ONTS problem on demand, including the energy input and task QoS parameters. These methodologies are briefly presented in the following topics and were previously published in \cite{data8030062}.

\subsubsection{Power Input Vector}

An analytical model has been used to determine the power input vector of each instance of the ONTS problem considered in this study. Once orbits are stable and solar flux constant -- $1360 W/m^2$  -- one can calculate this vector by knowing the spacecraft orbit, attitude -- its kinematics -- and size. We have taken the FloripaSat-I mission as a parameter for orbital data, which has an altitude of 628 kilometers and an orbital period of 97.2 minutes \cite{marcelino2020}. The attitude considered here is the Nadir, in which the satellite turns at the same rate around the Earth, so one side (or axis) always faces the Earth's surface. This analytical model then utilizes a rotation matrix to simulate the satellite's dynamics and can be adapted for larger or different geometries by adjusting the normal vectors representing the body. For this study, we considered a 3U nanosatellite size. The power generated by photovoltaic panels on each of the CubeSat's six sides depends on the efficiency of the cells, the area of the cells, the view factor of the surface to the Sun, and a step function that accounts for the satellite's location concerning Earth's shadow, as:
%%
\begin{equation}
    P_k=\eta A_{pv_{k}} I_{Sun}F_{k \rightarrow Sun} \Psi ,
    \label{sun_rad}
\end{equation}
%%%
where $\eta$ and $A_{pv}$ are the solar cell efficiency and area, respectively; $I_{Sun}$ is the solar flux; $F_{k \rightarrow Sun}$ is the cell projection to the Sun; and $\Psi$ is a step function that, when the spacecraft is in the shade of the Earth, takes a value of zero. More details about the equations used can be found in  \cite{morsch2020ate}. 

\subsubsection{Tasks Parameters}

For any particular mission size and orbital length, the main objective is to generate a realistic ONTS case using random data. The number of tasks or time units can be increased to make the instances distinct. Algorithm \ref{alg:task-scheduling} presents an instance generator technique that has been used here to accomplish this. It requires two inputs: the number of tasks ($J$) and the time units ($T$) to be taken into account. The process produces nine variables for each task, including $u_j$, $q_j$, $y_j^{\min}$, $y_j^{\max}$, $t_j^{\min}$, $t_j^{\max}$, $p_j^{\min}$, $p_j^{\max}$, $w_j^{\min}$, and $w_j^{\max}$.jmax. These parameters completely describe an instance of the ONTS regarding the QoS aspects.
 

\begin{algorithm}[!htb]
\footnotesize
\caption{Instance Generator Algorithm}
\label{alg:task-scheduling}
\SetAlgoLined
\DontPrintSemicolon
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}

\Input{Number of jobs $J$, number of time periods $T$}

\Output{Initial values for $u_j, q_j, y_j^{\min}, y_j^{\max}, t_j^{\min}, t_j^{\max}, p_j^{\min}, p_j^{\max}, w_j^{\min}, w_j^{\max}$}

\BlankLine

\For{$j \gets 1$ \KwTo $J$}{

$u_j \gets \text{U}(1, J)$;

$q_j \gets \text{U}(0.3, 2.5)$;

$y_j^{\min} \gets \text{U}[1, \lceil T/45 \rceil]$;

$y_j^{\max} \gets \text{U}[y_j^{\min}, \lceil T/15 \rceil]$;

$t_j^{\min} \gets \text{U}[1, \lceil T/10 \rceil]$;

$t_j^{\max} \gets \text{U}[t_j^{\min}, \lceil T/4 \rceil]$;

$p_j^{\min} \gets \text{U}[t_j^{\min}, \lceil T/4 \rceil]$;

$p_j^{\max} \gets \text{U}[p_j^{\min}, T]$;

$w_j^{\min} \gets \text{U}[0, \lceil T/5 \rceil]$;

$w_j^{\max} \gets \text{U}[\lfloor T-\lceil T/5 \rceil \rfloor, T]$;
}
\end{algorithm}

