%% 
%% Copyright 2007-2020 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references

\documentclass[preprint,12pt,authoryear]{elsarticle}
%% Use the option review to obtain double line spacing
% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times,authoryear]{elsarticle}
%% \documentclass[final,1p,times,twocolumn,authoryear]{elsarticle}
%% \documentclass[final,3p,times,authoryear]{elsarticle}
%% \documentclass[final,3p,times,twocolumn,authoryear]{elsarticle}
%% \documentclass[final,5p,times,authoryear]{elsarticle}
%% \documentclass[final,5p,times,twocolumn,authoryear]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
% \usepackage{amsthm}
\usepackage{fullpage}

\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{url}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{xfrac}
\usepackage{xcolor}

\usepackage{blindtext}
\usepackage{hyperref}

\usepackage{tikz}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{plotmarks}
\definecolor{lightgray}{rgb}{0.83, 0.83, 0.83}

\newcommand{\bm}[1]{%
    \boldsymbol{#1}
}

% \newcommand{\new}[1]{\textcolor{blue}{#1}}
\newcommand{\new}[1]{#1}


%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

\journal{Applied Soft Computing}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \affiliation for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%            addressline={}, 
%%            city={},
%%            postcode={}, 
%%            state={},
%%            country={}}
%% \fntext[label3]{}

\title{Graph Neural Networks for the Offline Nanosatellite Task Scheduling Problem}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \affiliation[label1]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%%
%% \affiliation[label2]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}

\author[1]{Bruno Machado Pacheco}
\ead{bruno.m.pacheco@posgrad.ufsc.br}

\author[1]{Laio Oriel Seman}
\ead{laio@ieee.org}

\author[2]{Cezar Antônio Rigo}
\ead{cezar.a.rigo@gmail.com}

\author[1]{Eduardo Camponogara}
\ead{eduardo.camponogara@ufsc.br}

\author[2]{Eduardo Augusto Bezerra}
\ead{eduardo.bezerra@ufsc.br}

\author[3]{Leandro dos Santos Coelho}
\ead{leandro.coelho@ufpr.br}

\affiliation[1]{organization={Department of Automation and Systems Engineering, Federal University of Santa Catarina (UFSC)},%Department and Organization
            % addressline={}, 
            city={Florianópolis},
            % postcode={}, 
            state={SC},
            country={Brazil}}

\affiliation[2]{organization={Department of Electrical Engineering, Federal University of Santa Catarina (UFSC)},%Department and Organization
            % addressline={}, 
            city={Florianópolis},
            % postcode={}, 
            state={SC},
            country={Brazil}}

\affiliation[3]{organization={Department of Electrical Engineering, Federal University of Parana (UFPR)},%Department and Organization
            % addressline={}, 
            city={Curitiba},
            % postcode={}, 
            state={PR},
            country={Brazil}}

\begin{abstract}
%% Text of abstract
This study investigates how to schedule nanosatellite tasks more efficiently using Graph Neural Networks (GNNs).
In the Offline Nanosatellite Task Scheduling (ONTS) problem, the goal is to find the optimal schedule for tasks to be carried out in orbit while taking into account Quality-of-Service (QoS) considerations such as priority, minimum and maximum activation events, execution time-frames, periods, and execution windows, as well as constraints on the satellite's power resources and the complexity of energy harvesting and management.
% The ONTS problem has been approached using conventional mathematical formulations and exact methods, but their applicability to challenging cases of the problem is limited.
This study explores the use of Graph Neural Networks (GNNs) as primal heuristics for the ONTS problem, as this class of deep learning model has been effectively applied to optimization problems such as the traveling salesman, scheduling, and facility placement.
We investigate whether GNNs can learn the complex structure of the ONTS problem with respect to feasibility and optimality of candidate solutions.
Furthermore, we evaluate using GNN-based heuristic solutions to provide better solutions (w.r.t. the objective value) to the ONTS problem and reduce the optimization cost.
Our experiments show that GNNs are not only able to learn feasibility and optimality for instances of the ONTS problem, but they can generalize to harder instances than those seen during training, addressing the data acquisition cost of training deep learning models on optimization problems.
On top of that, the GNN-based heuristics improved the expected objective value of the best solution found under the time limit in 45\%, and reduced the expected time to find a feasible solution in 35\%, when compared to the SCIP (Solving Constraint Integer Programs) solver in its off-the-shelf configuration.
\end{abstract}

%%Graphical abstract
% \begin{graphicalabstract}
%\includegraphics{grabs}
% \end{graphicalabstract}

%%Research highlights
% \begin{highlights}
% \item Research highlight 1
% \item Research highlight 2
% \end{highlights}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
Scheduling \sep Graph Neural Network \sep Combinatorial Optimization \sep  Nanosatellite \sep Deep Learning

%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

%% \linenumbers

%% main text
\section{Introduction} \label{sec:intro}


\new{%
Nanosatellites have attracted attention from industry and academia for over a decade, primarily due to their reduced development and launch costs~\citep{shiroma_cubesats_2011,lucia_computational_2021,Nagel2020,saeed_cubesat_2020}. However, these miniaturized spacecraft face significant operational challenges due to their inherent resource constraints, particularly in task scheduling and resource management.
}

\new{%
The Offline Nanosatellite Task Scheduling (ONTS) problem addresses these challenges by optimizing the allocation of satellite resources during the mission planning phase. This optimization is particularly complex due to the diverse operational characteristics of satellite payloads, including varying power consumption profiles, data handling requirements, and specific operational windows. Furthermore, the reliance on solar power as the primary energy source introduces considerable variability in energy supply, affected by factors such as cyclical eclipses in Low Earth Orbit (LEO), varying solar incidence angles, spacecraft attitude, and size.
}

\new{%
As an offline planning tool, ONTS assists engineers in simulating and evaluating performance before launch. The problem must address five fundamental scheduling requirements: \textit{i}) non-preemptive tasks that must be completed without interruption once initiated; \textit{ii}) task periodicity within specific thresholds; \textit{iii}) minimum and maximum task startups within an orbit to meet Quality-of-Service (QoS) requirements; \textit{iv}) task execution windows for precise operations; and \textit{v}) battery state-of-charge management balancing energy consumption with generation.
}

\new{%
Traditional approaches to solving the ONTS problem have employed various mathematical optimization techniques, progressing from Integer Programming (IP)~\citep{rigo_task_2021} to Mixed-Integer Linear Programming (MILP)~\citep{rigo_nanosatellite_2021,seman_energy-aware_2022} and Continuous-Time formulations~\citep{camponogara_continuous-time_2022}. However, due to the (Non-deterministic Polynomial time)-hard nature of the problem, efficiently solving large instances—involving many tasks or extended planning horizons—remains an open research challenge.
}

Meanwhile, several recent investigations~\citep{bengio_machine_2021,karimi-mamaghan_machine_2022,pacheco2023deeplearningbased,han_gnn-guided_2023} have considered machine learning tools to address combinatorial optimization problems, such as the single machine problem~\citep{parmentier_structured_2023}, resource-constrained project scheduling~\citep{guo_prediction_2023}, and knapsack problems~\citep{yang_learning_2022}.
Graph Neural Networks (GNNs), in particular, have gained popularity in recent years to solve combinatorial optimization problems when the underlying structure can be represented as a graph~\citep{zhang_survey_2023}, which is the case for MILP~\citep{khalil_mip-gnn_2022}.

This paper investigates the novel application of GNNs for the ONTS problem.
More specifically, we consider two research questions:
\begin{itemize}
    \item Can a graph neural network learn the structure of the ONTS problem?
    \item Is a GNN-based heuristic effective (fast and accurate) for the ONTS problem?
\end{itemize}
To address these two questions, we propose two sets of experiments.
% In the first, we train GNNs to predict the feasibility and optimality of candidate solutions given an instance of the problem.
% In our results, the deep learning models successfully learned both characteristics and generalized to unseen instances.
% In the second set of experiments, we train GNNs to generate candidate solutions given problem instances and use the resulting models to build matheuristics.
% Our results show the GNN-based matheuristics being particularly successful for quickly providing high-quality solutions, overcoming the MILP solver (SCIP).
First, we train GNNs to predict the feasibility and optimality of candidate solutions given an instance of the problem.
In the second set of experiments, we train GNNs to generate candidate solutions given problem instances and use the resulting models to build matheuristics~\citep{boschetti_matheuristics_2022}.
Our results indicate that the proposed GNN can learn the feasibility and optimality of candidate solutions, even when given instances that are larger (and harder) than those seen during training.
Furthermore, GNN-based matheuristics effectively provide high-quality solutions for large problems, overcoming the MILP solver (SCIP) both in the time to generate feasible solutions and the quality of the solutions found within limited time.

\new{%
Everything considered, this paper takes a fundamentally different approach compared to previous works. Rather than proposing a new standalone algorithm, our work aims to develop a supportive heuristic component that can enhance existing solution methods. This is accomplished through three main aspects: (\textit{i}) the GNN-based heuristic is designed specifically to improve and accelerate the performance of traditional exact methods or sophisticated ones like branch-and-price, not to replace them; (\textit{ii}) it serves as an integrated component that works in conjunction with established algorithms, providing high-quality initial solutions to speed up convergence; and (\textit{iii}) it maintains the mathematical guarantees of the host algorithm while improving its computational efficiency.
} In summary, the main contributions of this paper are as follows:
\begin{itemize}
\item The introduction of SatGNN, a pioneering GNN architecture suitable to the ONTS problem;
\item A showcase of SatGNN's impressive performance in accurately classifying feasibility, predicting optimality, and generating effective heuristic solutions;
\item A demonstration of GNN's robust generalization abilities for optimization problems, particularly when dealing with larger ONTS instances;
\item An implication of the potential for a transformative impact on complex space mission scheduling.
\end{itemize}

% Our experimental results show promising results, with the resulting heuristic overcoming the SCIP solver in the hardest problems.
% This study investigates applications of GNNs for the ONTS problem
% Taking advantage of all this recent progress in GNN research and its successful application to optimization problems, this study proposes a novel solution methodology to the ONTS problem.
% By representing the problem as a bipartite graph, we leverage the robust representation learning capabilities of GNNs.
% The parameters of the MILP problem generate feature vectors fed into the model, allowing us to encode both the structure and parameters of each instance of the problem.
% GNNs can handle graphs of arbitrary size to handle optimization problems with varying numbers of variables and constraints.
% Our method employs two fully-connected, single-layer multilayer perceptron (MLP) networks with ReLU activations to encode the features of variables and constraints into hidden features that are updated using a two-step message-passing mechanism.
% The parameters can then be optimized similarly to conventional deep learning models.
% The proposed GNN model is then shown here to accelerate task scheduling by efficiently learning the relationships between tasks and resources and optimizing mission planning.



The remainder of this paper is organized as follows:
Section \ref{sec:rel-work} provides an overview of the related literature.
Section \ref{sec:onts} describes the problem in detail, providing context and background information and formulating the optimization problem.
Section \ref{sec:gnns} provides the necessary theoretical background on GNNs and their application to linear optimization problems.
The data acquisition, the proposed GNN architecture, and the heuristics for optimization problems are presented in Section \ref{sec:meth}.
The experiments that tackle the two research questions and the results are presented in Section \ref{sec:exps}.
Finally, Sections \ref{sec:discussion} and \ref{sec:conclusion} discuss the key findings and provide concluding remarks and future research directions.

\section{Related Work}\label{sec:rel-work}

The ONTS problem has received significant contributions in recent years, with different approaches and formulations.
At the same time, machine learning applications for optimization problems have become a prolific area of research.
\new{%
This section briefly overviews our paper's most influential works, which are also summarized in Table~\ref{tab:related-work}.
}

\begin{table}[htbp]
    \centering
    \caption{Summary of related work}
    \label{tab:related-work}
    \footnotesize
    % \color{blue}
    \begin{tabular}{p{2.5cm}p{6cm}p{4cm}p{2.5cm}}
        \toprule
        \textbf{Reference} & \textbf{Main Contribution} & \textbf{Methodology} & \textbf{Application} \\
        \midrule
        \multicolumn{4}{l}{\textit{Nanosatellite Task Scheduling}} \\
        \midrule
        \citet{wang_dynamic_2013} & Dynamic scheduling of emergency tasks & Mathematical programming with multiple objectives & Emergency tasks \\
        \citet{wang_pure_2016} & Handling cloud blockage uncertainties & Approximate integer linear programming & Visibility constraints \\
        \citet{NIU2018813} & Multi-satellite scheduling under emergency conditions & Integer programming + genetic algorithm & Emergency response \\
        \citet{rouzot:hal-04430171} & Scheduling under tight nanosatellite constraints & Constraint programming & Nanosatellite missions \\
        \citet{rigo_task_2021} & Power-aware task allocation & Integer programming & Power optimization \\
        \citet{seman_energy-aware_2022} & Constellation task scheduling & Mixed-integer linear programming & Nanosatellite constellations \\
        \citet{rigo_branch-and-price_2022} & Column generation approach & Branch-and-price & Task scheduling \\
        \midrule
        \multicolumn{4}{l}{\textit{Machine Learning for Scheduling}} \\
        \midrule
        \citet{hopfield_neural_1985} & First ML application to optimization & Hopfield neural networks & TSP \\
        \citet{wang_complex_2021} & Heuristic scheduling solutions & Reinforcement learning (MDP) & General scheduling \\
        \citet{FENG2024102362} & Static constraint satisfaction & Deep learning + optimization & Satellite scheduling \\
        \midrule
        \multicolumn{4}{l}{\textit{GNNs for Combinatorial Optimization}} \\
        \midrule
        \citet{khalil_learning_2017} & Graph-based CO solutions & GNN-based greedy heuristic & Graph problems \\
        \citet{gasse_exact_2019} & MILP problem embedding & Bipartite graph representation & General MILP \\
        \citet{ding_accelerating_2020} & Variable selection in B\&B & GNN-guided branching & MILP solving \\
        \citet{nair_neural_2020} & Neural Diving approach & GNN-based partial solutions & MILP solving \\
        \citet{han_gnn-guided_2023} & Trust region optimization & GNN-guided solution space exploration & MILP solving \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection*{Nanosatellite task scheduling}

Mathematical programming is consolidated as a practical approach for satellite scheduling problems.
\citet{wang_dynamic_2013} formulate the problem of dynamic scheduling emergency tasks as a mathematical program with multiple objectives.
\citet{wang_pure_2016} handle the uncertainties from cloud blockage with respect to the satellite visibility and propose an approximate integer linear program to schedule tasks, which is solved by the authors using a branch and cut approach.
Considering multiple satellites, \citet{NIU2018813} propose an integer program model and a genetic algorithm to provide feasible solutions faster under emergency conditions.

Targeting small satellites, \citet{rouzot:hal-04430171} formulated the problem using constraint programming to generate schedules that satisfy the multiple tight requirements that a nanosatellite mission imposes.
\citet{rigo_task_2021} formulated the problem of maximizing task allocation under power availability constraints as an integer programming (IP) problem, enabling the generation of optimal schedules.
% The formulation considers discrete time steps and information such as the maximum power input at each time step along the planning horizon, power consumption of tasks, execution periods, and task priorities.
% This approach was able to provide energy-efficient allocations that improved mission value.
\citet{seman_energy-aware_2022} extended the approach by \citet{rigo_task_2021} and proposed a Mixed-Integer Linear Programming (MILP) formulation to tackle the task scheduling in constellations of nanosatellites.
\citet{camponogara_continuous-time_2022} applied the Multi-Operation Sequencing with Synchronized Start Times (MOS-SST) representation to the problem, maintaining an MILP formulation but extending the problem to continuous time.
% The continuous-time feature allowed for greater flexibility and versatility, fundamental characteristics for decision-making during the design phase.
The evolution of formulations and methodologies highlights the continuous efforts to find the most efficient and effective solutions to the ONTS problem.

More recently, given the difficulty in solving complex instances of the ONTS problem, \citet{rigo_branch-and-price_2022} proposed a Dantzig-Wolfe decomposition, coupled with a branch-and-price (B\&P) methodology, which was further adapted in a heuristic solution through the use of a genetic algorithm~\citep{SEMAN2023110475}.
This approach was designed to build a unique column-based formulation that produces feasible and optimal schedules.
In addition, they leveraged the Dynamic Programming (DP) technique to identify optimal columns and speed up the whole process.
Their computational experiments significantly improved overall solution time compared to a commercial MILP solver, with a 70\% reduction in computation time.
Despite these promising results, the B\&P method introduces specific challenges and limitations that preclude its universal application.
One significant drawback is its heavy reliance on the suitability of the decomposition, which is notoriously problem-specific.
Currently, no known method allows practitioners to \emph{a priori} ascertain the presence of a decomposable structure in a given problem~\citep{kruber_learning_2017}.
This lack of a deterministic approach to identifying suitable problems adds a layer of complexity to the application of B\&P.
Additionally, the complexity inherent in the decomposition and the optimization algorithm can result in a high development undertaking.
The intricate nature of these processes requires specialized knowledge and expertise, potentially rendering the B\&P method prohibitive for particular applications or settings.
Consequently, while the B\&P methodology offers substantial improvements in computational efficiency for specific problem instances, its applicability may be limited by these challenges, emphasizing the need for caution in considering it as a universal solution for all optimization problems.

\new{The literature demonstrates a clear progression in solution methodologies for the ONTS problem, from classical mathematical programming to sophisticated decomposition approaches. While the B\&P methodology has demonstrated substantial computational advantages, its effectiveness remains contingent upon problem-specific characteristics and implementation expertise. These limitations underscore the necessity for developing more generalizable solution approaches that maintain computational efficiency while reducing implementation complexity.}

\subsubsection*{Machine learning for offline task scheduling}

Machine learning applications for optimization problems were first proposed in 1985, applying Hopfield neural networks to the Travelling Salesperson Problem (TSP)~\citep{hopfield_neural_1985}.
Due to the hardware limitations of the time~\citep{smith_neural_1999}, neural network applications to optimization problems have stayed out of the spotlight up to recent years, when developments in novel architectures, more powerful hardware, and promising published results have attracted the attention of the research community back to this area~\citep{bengio_machine_2021}.

For scheduling problems, many authors have proposed reinforcement learning strategies to make the scheduling decisions, even in offline settings.
A series of works have focused on training models to provide completely heuristic solutions, modeling the scheduling problem as a markov decision process~\citep{wang_complex_2021,tassel2021reinforcement,NEURIPS2020_11958dfe}.
Another research direction with significant contributions has been on modeling uncertainty through reinforcement learning and modifying the parameters of the scheduling IP formulation based on the model's output~\citep{Kenworthy_Nayak_Chin_Balakrishnan_2022,gomes_reinforcement_2017}.
To the best of our knowledge, no works in scheduling have proposed learning-based matheuristics, for example, as is done for vertex coloring and set covering in \citet{kruber_learning_2017}.

This is particularly true for satellite task scheduling problems, where many works focused on reinforcement learning policies for generating a heuristic solution for the schedule~\citep{10004750,rs13122377,9998480,9152114}.
To the best of our knowledge, the work by~\citet{FENG2024102362} is the only one to use a deep learning model interacting directly with the solver of a satellite task scheduling problem.
The authors train a deep learning model to solve the problem's static constraints, alleviating the optimizer's job, which aims to satisfy the dynamic constraints of the problem.

\new{The applications of machine learning in scheduling problems have predominantly focused on reinforcement learning strategies, both for direct heuristic solutions and uncertainty modeling. However, the integration of learning-based matheuristics with satellite task scheduling remains largely unexplored, particularly in contrast to other combinatorial optimization domains. This gap in the literature presents opportunities for novel methodological contributions.}


\subsubsection*{GNNs for combinatorial optimization}

One of the drivers of the recent interest in machine learning for Combinatorial Optimization (CO) problems was the proposition of structured artificial neural networks able to handle the symmetries that optimization problems have~\citep{cappart_combinatorial_2022}, such as the invariance to permutation of constraints.
A significant example of such property for CO is the work of \citet{khalil_learning_2017}, which developed a greedy heuristic for CO problems on graphs using a GNN.
\citet{gasse_exact_2019} proposed to embed linear programming problems as a bipartite graph, generalizing the use of GNNs to any MILP.
The results presented in these works indicate that GNNs can learn the structures of MILP problems.

Many authors proposed using GNNs to predict solution values, aiming at using the learned model in heuristic solutions.
\citet{ding_accelerating_2020} proposed using such GNNs to guide the Branch and Bound (B\&B) algorithm towards the variables the model had the most difficulty learning.
\citet{khalil_mip-gnn_2022} use the GNNs trained to predict biases of the binary variables to perform node selection and warm starting.
\citet{nair_neural_2020}, in their approach named \emph{Neural Diving}, proposed to train the model to provide partial solutions, which generate sub-problems through variable fixing.
The multiple sub-problems are then solved using off-the-shelf solvers.
\citet{han_gnn-guided_2023} compare the fixing approach of \citet{nair_neural_2020} to their proposed approach of defining a trust region around the partial solution generated by the GNN, showing significant improvements over off-the-shelf solvers like SCIP and Gurobi.
These works highlight how promising building GNN-based heuristic approaches to MILP can be.

\new{The literature evidences the efficacy of GNN architectures in addressing combinatorial optimization problems, particularly through their integration with traditional exact methods such as B\&B. Recent developments in solution prediction and variable fixing strategies have yielded promising computational results. Nevertheless, the application of these techniques remains an emerging field, with significant potential for theoretical and practical advances.}


\subsubsection*{}


%To the best of our knowledge, our work is the first to apply deep learning models to nanosatellite task scheduling.
%In fact, our work is one of the first to propose learning-based matheuristics for satellite scheduling problems.
%Furthermore, machine learning applications to MILP has only recently attracted intense attention, as confirmed by the novelty of the works presented above and the lack of learning-based components in open-source solvers such as SCIP and CPLEX.
%In other words, although promising, applying GNNs to MILP still needs to be well-understood and is not guaranteed to yield positive results.
%In this context, the present work also contributes to the area of machine learning and combinatorial optimization of research by validating novel techniques.

\new{%
To the best of our knowledge, while metaheuristic approaches like genetic algorithms have been applied to nanosatellite task scheduling~\citep{SEMAN2023110475}, our work is the first to propose a matheuristic specifically designed to enhance exact solution methods. Unlike metaheuristics that operate independently but cannot guarantee global optimality, our approach is engineered to provide high-quality initial solutions that accelerate the convergence of exact methods while maintaining their optimality guarantees. 
}
Furthermore, machine learning applications to MILP has only recently attracted intense attention, as confirmed by the novelty of the works presented above and the lack of learning-based components in open-source solvers such as SCIP and CPLEX. In other words, although promising, applying GNNs to MILP still needs to be well-understood and is not guaranteed to yield positive results. In this context, the present work also contributes to the area of machine learning and combinatorial optimization research by validating novel techniques that complement rather than replace exact methods.

\section{Offline Nanosatellite Task Scheduling (ONTS)}\label{sec:onts}

Nanosatellite scheduling problems concern the decisions on each task's start and finish time.
The tasks usually require periodic execution and during restricted moments along the orbit.
Besides time, energy availability through orbit is a crucial resource to consider.
Figure \ref{fig:example-scheduling} shows an example of optimal scheduling, in which each job is represented by a different color and the activation and deactivations are shown through the steps of the signals.
Proper scheduling must account for energy management, so the tasks do not draw more energy than the system can provide and the battery is not depleted before the end of the mission.
Energy management is a difficult task since the nanosatellite draws power from its solar panels, with the energy availability depending on the attitude of the nanosatellite (which affects the orientation of the solar panels) and the trajectory with respect to Earth's shadow, as illustrated in Figure \ref{fig:onts-orbit}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{schedule_example.pdf}
    \caption{Illustration of an optimum scheduling for 9 tasks on a horizon of 125 time steps. Each color represents the execution of the different tasks.}
    \label{fig:example-scheduling}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{onts_orbit.png}
    \caption{Illustration of a nanosatellite's orbit around Earth. Image from \citet{rigo_branch-and-price_2022}.}
    \label{fig:onts-orbit}
\end{figure}

\subsection{MILP Formulation}\label{sec:problem}

A formulation that considers the realistic constraints and objectives of ONTS was proposed by \citet{rigo_task_2021} and is presented here.
\new{For reference, all symbols (sets, variables, and parameters) used in our formulation are summarized in \ref{appx:tab-symbols}.}
Given a set of jobs $\mathcal{J}=\{0,...,J\}$ that represents the tasks, and a set of time units $\mathcal{T}=\{0,...,T\}$ that represents the scheduling horizon, variables \[
\new{\bm{x} = \left(x_{j,t}\right)_{\substack{j=1,\ldots,J \\ t = 1,\ldots,T}}}
    % \bm{x}=(x_{1,1},\ldots,x_{1,T},\ldots,x_{J,1},\ldots,x_{J,T})
    % \bm{x}=[x_{j,t}]_{\substack{j=1,\ldots,J \\ t=1,\ldots,T}}
\] represent the allocation of jobs $j\in \mathcal{J}$ at times $t\in\mathcal{T}$, i.e., $x_{j,t}=1$ indicates that job $j$ is scheduled to execute at time $t$.
Naturally, $x_{j,t}$ are binary variables, i.e., $\bm{x} \in \{0,1\}^{JT}$.

It is assumed that there exists a priority for every job, which is defined by $\bm{u} = (u_1,\ldots,u_{J})$.
The goal is to maximize the mission's Quality of Service (QoS) \eqref{eq:qos}, which is the sum of the allocations weighted by the priorities,
\begin{align}\label{eq:qos}
{\rm QoS}(\bm{x};\bm{u}) =
	% \underset{x_{j,t}}{\max} ~~
	\sum_{j=1}^{J} \sum_{t=1}^{T} {u}_{j} x_{j,t}
% x_{j,t}\in\{0,1\}, ~~\quad \forall j\in\mathcal{J}, t\in\mathcal{T} 
\end{align}

To formalize the ONTS problem of maximizing QoS, we follow the formulation proposed by \citet{rigo_task_2021}.
The following constraints are added to ensure that the scheduling respects the requirements and specificities of each job:
\begin{subequations}\label{eq:qos-constraints}
    \begin{align}
        &\phi_{j,t} \geq x_{j,t}, &~\forall j\in\mathcal{J},\, t = 1 \label{phiA} \\
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        &\phi_{j,t} \geq x_{j,t} - x_{j,(t-1)}, &~\forall j\in\mathcal{J}, \,\forall t\in\mathcal{T}: t > 1  \label{phiB} \\
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        &\phi_{j,t} \leq x_{j,t}, &~\forall j\in\mathcal{J}, \,\forall t\in\mathcal{T}  \label{phiC} \\
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        &\phi_{j,t} \leq 2 - x_{j,t} - x_{j,(t-1)}, &~\forall j\in\mathcal{J}, \,\forall t\in\mathcal{T}: t > 1 \label{phiE} \\
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        &\sum_{t=1}^{\textcolor{black}{w^{\min}_{j}}} x_{j,t} = 0,  & \forall j\in\mathcal{J} \, \label{window1} \\
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        &\sum_{t=w^{\max}_{j}+1}^{T} x_{j,t} = 0, & \forall j\in\mathcal{J}  \label{window2}\\
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        &\sum_{l=t}^{t+{t}^{\min}_{j}-1} x_{j,l} \geq {t}^{\min}_{j} \phi_{j,t},  &\forall t \in \{1,...,T-{t}^{\min}_{j} + 1\}, \forall j\in\mathcal{J} \label{c} \\
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        &\sum_{l=t}^{t+{t}^{\max}_{j}} x_{j,l} \leq {t}^{\max}_{j},  &\forall t \in \{1,...,T-{t}^{\max}_{j}\}, \forall j\in\mathcal{J} \label{d} \\
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        &\sum_{l=t}^{T} x_{j,l} \geq (T - t + 1) \phi_{j,t},  & \forall t \in \{T-{t}^{\min}_{j} + 2,...,T\}, \forall j\in\mathcal{J}\, \label{e} \\
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        &\sum_{l=t}^{t+{p}^{\min}_{j}-1} \phi_{j,l} \leq 1,   & \forall t \in \{1,...,T-{p}^{\min}_{j}+1\}, \forall j\in\mathcal{J} \label{f} \\
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        & \sum_{l=t}^{t+{p}^{\max}_{j}-1} \phi_{j,l} \geq 1,  & \forall t \in \{1,...,T-{p}^{\max}_{j}+1\},  \forall j\in\mathcal{J} \label{g} \\
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        &\sum_{t=1}^{T} \phi_{j,t} \geq {y}^{\min}_{j}, &\forall j\in\mathcal{J}  \label{a} \\
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        &\sum_{t=1}^{T} \phi_{j,t} \leq {y}^{\max}_{j}, &\forall j\in\mathcal{J}  \label{b} \\
        %%
        & \phi_{j,t}\in\{0,1\}, &~\forall j\in\mathcal{J}, t\in\mathcal{T}  \label{phi_bin} \\
        %%%
        & x_{j,t}\in\{0,1\}, &~\forall j\in\mathcal{J}, t\in\mathcal{T}.  \label{x_bin}  
    \end{align}
\end{subequations}

Note that auxiliary binary variables \[
    % \bm{\phi}=(\phi_{1,1},\ldots,\phi_{1,T},\ldots,\phi_{J,1},\ldots,\phi_{J,T})
    \bm{\phi} = \left(\phi_{j,t}\right)_{\substack{j=1,\ldots,J \\ t = 1,\ldots,T}}
\] are used, which take a positive value if, and only if, job $j$ was not running at time $t-1$, but started running at time $t$.
Constraints \eqref{phiA} to \eqref{phiE} are used to ensure this behavior.
We also consider that jobs may run only during a time window defined by parameters $w^{\min}_{j}$ and $w^{\max}_{j}$, which is ensured by constraints \eqref{window1} and \eqref{window2}.
Such behavior is necessary to ensure that a payload, for instance, runs only when passing above a certain territory.

Jobs may also have limits on continuous execution.
If a job $j$ starts running at time $t$, then it must run for at least $t^{\min}_{j}$ time steps, and at most $t^{\max}_{j}$ time steps.
This is ensured by constraints \eqref{c} and \eqref{d}.
The formulation, through constraint \eqref{e}, also allows a job to start at the last time steps and keep running until the end, assuming it will keep running at the start of the following schedule.

A job may require to be executed periodically, at least every $p^{\min}_{j}$ time step, and at most every $p^{\max}_{j}$ time step.
This is ensured through constraints \eqref{f} and \eqref{g}, over the $\phi_{j,t}$ variables.
A job may also require multiple executions through the planning horizon, starting at least $y^{\min}_{j}$ times, and at most $y^{\max}_{j}$ times, which is ensured through constraints \eqref{a} and \eqref{b}.

Beyond job-specific restrictions in constraints \eqref{eq:qos-constraints}, the formulation also covers energy management,
\begin{subequations} \label{eq:energy-constraints}
\begin{align}
    &\sum_{j=1}^{J} q_{j} x_{j,t} \leq r_t + \gamma~V_{b}, & \forall t\in\mathcal{T} \label{EN_r} \\
    & b_{t} = r_{t} - \sum_{j \in \mathcal{J}} q_{j} x_{j,t}, &  \forall t \in \mathcal{T} \label{EN_b} \\
    & i_{t} = \frac{b_{t}}{V_{b}}, &  \forall t \in \mathcal{T} \label{EN_i}\\
    &\text{SoC}_{t+1} = \text{SoC}_{t} + \frac{i_{t}~e}{60~Q}, & \forall t \in \mathcal{T}  \label{EN_SOC1}\\
    &\text{SoC}_{t} \leq 1, & \forall t\in\mathcal{T} \label{EN_SOC2}   \\
    &\text{SoC}_{t} \geq \rho, & \forall t\in\mathcal{T} \label{EN_SOC3} 
.\end{align}
\end{subequations}
Parameter $r_t$ provides the power available from the solar panels at time $t$ and $q_j$ the power required for executing job $j$.
Thus, constraint \eqref{EN_r} limits the power consumption, with $\gamma \cdot V_b$ being the maximum power the battery can provide.
Constraints \eqref{EN_b} to \eqref{EN_SOC1} update the auxiliary variables $b_t$ and ${\rm SoC}_t$, which represent the exceeding power and State of Charge (SoC) at time $t$, based on the battery capacity $Q$ and the discharge efficiency $e$.
The SoC of the battery must stay within the limits given in constraints \eqref{EN_SOC2} and \eqref{EN_SOC3}, with $\rho$ being a lower limit usually greater than zero as a safety measure.

Thus, the MILP formulation is the maximization of \eqref{eq:qos} while subject to constraints \eqref{eq:qos-constraints} and \eqref{eq:energy-constraints}.
In other words, we can write any instance $I\in\mathcal{I}$, where $\mathcal{I}$ is the set of all possible instances of the ONTS problem, as
\begin{equation}\label{eq:formulation}
\begin{split}
    I : \max_{\bm{x},\bm{\phi},{\rm SoC}} ~& \underbrace{\sum_{j=1}^{J} \sum_{t=1}^{T} {u}_{j} x_{j,t} }_{ \text{QoS}}  \\
    \text{s.t.}  ~& \eqref{eq:qos-constraints},\eqref{eq:energy-constraints}  \\
    & \bm{x},\bm{\phi} \in \{0,1\}^{JT} , {\rm SoC}\in [0,1]^T
.\end{split}
\end{equation}
Note that the continuous variables ${\rm SoC}$ can be completely determined by the binary variables $\bm{x}$ and $\bm{\phi}$, so our problem can be reduced to finding an assignment $\bm{z}=(\bm{x},\bm{\phi}) \in \{0,1\}^{2JT}$.

Any instance $I\in\mathcal{I}$ is parameterized by the number of tasks $J$, the number of time units $T$ and the parameters $\bm{u}$, $\bm{q}$, $\bm{y}^{\min}$, $\bm{y}^{\max}$, $\bm{t}^{\min}$, $\bm{t}^{\max}$, $\bm{p}^{\min}$, $\bm{p}^{\max}$, $\bm{w}^{\min}$, $\bm{w}^{\max}$, $\bm{r}$, $\rho$, $e$, $Q$, $\gamma$, and $V_b$.
We will denote $\Pi_{J,T}$ the parameter space through which any instance $I\in\mathcal{I}$ can be uniquely determined by some parameter vector $\pi\in\Pi_{J,T}$ (given adequate $J$ and $T$).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Graph Neural Networks (GNNs)}\label{sec:gnns}

Graph neural networks are generalizations of convolutional neural networks from grid-structured data to graphs.
The input to a GNN is a graph and a set of feature vectors associated with the graph nodes.
GNNs work by propagating feature information between neighboring nodes, which can be seen as message-passing.
\new{%
More specifically, at each layer, the GNN first computes the messages sent by the nodes based on their feature vectors.
Then, it updates each node's feature vectors based on the messages sent by their neighbors.
}
% Following the deep learning paradigm, the GNN performs this message-passing recurrently through its layers, aiming to extract complex features.
We will refer to the feature update as a graph \emph{convolution}, due to its similarities to the operations in convolutional neural networks.

At each layer $l\in\{1,...,L\}$, the graph convolution operation has two major components: \textit{message functions} $M_l(\cdot)$, which compute the messages propagated by each node, and \textit{update functions} $U_l(\cdot)$, which update the node-associated features based on the messages.
Let $G = (V, E)$ be a graph and $\bm{h}^{(0)}_v$ be feature vectors for every node $v\in V$.
The messages sent $\bm{m}_{u}^{(l)}$ are computed based on the node features
\begin{equation}\label{eq:message-passing-messages}
    \bm{m}_{u}^{(l)} = M_l(\bm{h}_u^{(l-1)}), \forall u\in V
,\end{equation}
where $M_l(\cdot)$ is the message function of layer $l$.
After computing the messages, the features of node $v$ are updated through
\begin{equation}\label{eq:message-passing-updates}
    \bm{h}_v^{(l)} = U_l\left(\bm{h}_v^{(l-1)}, {\tt Aggregation}\left(\left\{\bm{m}^{(l)}_{u} : u\in \mathcal{N}(v) \right\}\right)\right)
,\end{equation}
where $\mathcal{N}(v)$ is the set of neighbors of $v$, $U_l(\cdot)$ is the update function of layer $l$, and ${\tt Aggregation}$ is a function that receives multiple message vectors and returns a single vector.

A common choice for graph convolutions is to use feedforward neural networks as message and update functions.
\new{%
Given that the number of neighbors varies, we need an ${\tt Aggregation}$ function that always returns a fixed-length vector, invariant to input size, hence the naming.
}
A natural choice is to add up the messages, but many are the possibilities, such as
\begin{align}
{\tt Aggregation} = \begin{cases}
    \frac{1}{|\mathcal{N}(v)|} \sum\limits_{u \in \mathcal{N}(v)} \bm{m}_{u}^{(l)}, & \textrm{if mean} \\  
        %%%
    \underset{u \in \mathcal{N}(v)}{\max}  \bm{m}_{u}^{(l)}, & \textrm{if max} \\   
        %%%
    \sum\limits_{u \in \mathcal{N}(v)} \bm{m}_{u}^{(l)}, & \textrm{if sum} \\ 
        %%%
    \sum\limits_{u \in \mathcal{N}(v)} \alpha_{u,v} \bm{m}_{u}^{(l)}, & \textrm{if attention} \\
\end{cases},
\end{align}
where $\alpha_{u,v}$ is an attention weight for node $u$ given node $v$, which can be learned along the model parameters.
Furthermore, the message function can easily be extended to consider the edge weight (or even edge features) along with the feature vectors of the neighbors.

A common approach is to define the message functions $M_l, l=1,\ldots,L$, as linear operators over the hidden features of the neighbors, aggregate these messages by summing, and use the ReLU (Rectifier Linear Unit) activation function with a bias as the update functions $U_l, l=1,\ldots,L$.
An example of such an approach is the model proposed by \citet{kipf_semi-supervised_2017}, which uses a linear combination of the features as the message function, aggregates messages by summation, and updates using a single-layer neural network with ReLU activation.
More precisely, we can describe their convolution operation as
\begin{equation}\label{eq:graph-conv}
\begin{aligned}
    % M_l(h_u^{(l-1)}) &= \frac{1}{c_{vu}}W^{(l)}h_u^{(l-1)} \\
    \bm{m}_{u,v}^{(l)} &= \frac{1}{c_{vu}}W^{(l)}\bm{h}_u^{(l-1)},\, u\in \mathcal{N}(v) \\
    \bm{h}_{v}^{(l)} &= \text{ReLU}\left(\bm{b}^{(l)} + \sum_{u \in \mathcal{N}(v)} \bm{m}_{u,v}^{(l)}\right)
\end{aligned}
\end{equation}
where $c_{vu} = \sqrt{|\mathcal{N}(u)|}\sqrt{|\mathcal{N}(v)|}$ with $|\mathcal{N}(v)|$ denoting the number of neighbors, and $W^{(l)}\in \mathbb{R}^{d_l\times d_l},\bm{b}^{(l)}\in\mathbb{R}^{d_l}$ (layer $l$ has size $d_l$) are the weights and biases of the model, i.e., learnable parameters.

Another convolution operator was proposed by \citet{hamilton_inductive_2017} and named SAGE (SAmple and aGgrEgate).
The authors propose to directly aggregate the features of the neighbors, i.e., to use the identity as the message function and to use a single-layer network with ReLU activation as the update function.
Putting it into terms, the proposed graph convolution is
\begin{equation}\label{eq:sage-conv}
\begin{aligned}
    \bm{m}_{u,v}^{(l)} &= \bm{h}_u^{(l-1)},\, u\in \mathcal{N}(v) \\
              %%%%
    \bm{h}_{v}^{(l)} &= \text{ReLU}\left(\bm{b}^{(l)} + W^{(l)}_1 \bm{h}_v^{(l-1)} + W^{(l)}_2 {\tt Aggregation}\left (\bm{m}_{u,v}^{(l)},\, u\in \mathcal{N}(v)\right)\right)
\end{aligned}
\end{equation}
where $W^{(l)}_1,W^{(l)}_2\in \mathbb{R}^{d_l\times d_l},\bm{b}^{(l)}\in\mathbb{R}^{d_l}$ are the parameters.
The authors suggest using more complex aggregation operators, such as an LSTM (Long Short-Term Memory network) and a fully connected single-layer neural network, followed by a pooling operation (element-wise maximum).
Note that the SAGE convolution with summation as the aggregation function is equivalent to the one proposed by Kipf and Welling.

After recurrent graph convolutions through the $L$ layers of a GNN, we can use the resulting node features $H^{(L)} = \left[ \bm{h}_v^{(L)} \right]_{v\in V}$ straight-away, which is suitable for, e.g., node classification tasks, or we can aggregate them further into a single feature vector, suitable for, e.g., graph classification tasks.
The GNN can be trained end-to-end by minimizing a prediction loss based on its outputs, optimizing its parameters (e.g., $W^{(l)}$ and $\bm{b}^{(l)}$ of \eqref{eq:graph-conv}) in the same way as a traditional deep learning model.

% https://arxiv.org/pdf/1710.10903.pdf
% https://arxiv.org/pdf/2105.14491.pdf

\subsection{MILP Problems as Inputs for GNNs}\label{sec:instance-embedding}

We can feed MILP problem instances to GNNs by representing the relationship between problem variables and constraints through a bipartite graph~\citep{gasse_exact_2019,ding_accelerating_2020,khalil_mip-gnn_2022,nair_neural_2020,han_gnn-guided_2023}.
% Given a linear problem, we can build a graph $G=(V,E)$ in which we add one node for each variable of the problem, one node for each constraint, and connect each variable node to constraint nodes whenever the coefficient of the respective variable is not null in the respective constraint.
More precisely, given a problem of the form 
\begin{equation}\label{eq:opt}
\begin{aligned}
\max_{\bm{x}} & \quad \bm{c}^T \bm{x} \\
\text{s.t.:} & \quad A\bm{x} \le\bm{b} 
,\end{aligned}
\end{equation}
where $\bm{x}\in X \subseteq\mathbb{R}^n$, $A\in\mathbb{R}^{m \times n}$, $\bm{c}\in \mathbb{R}^n$, and $\bm{b}\in \mathbb{R}^m$, we can build a graph $G=(V_{\textrm{var}}\cup V_{\textrm{con}}, E)$, in which $|V_{\textrm{var}}| = n$, $|V_{\textrm{con}}|=m$, and $E=\{(v_{{\rm con},i},v_{{\rm var},j}) : A_{i,j} \neq 0\}$.
Intuitively, the graph represents the structure of the problem at hand, with edges capturing the relationship between variables and constraints.
Note that this approach yields a bipartite graph, that is a graph in which the nodes are separated into two disjoint sets, $V_{\textrm{var}}$ and $V_{\textrm{con}}$, with edges connecting only nodes from one set to the other.

To fully represent an MILP instance, however, the graph has to be enhanced with edge and node weights.
Let $w:V\cup E\mapsto \mathbb{R}$ be the weight function\footnote{Note that, in a slight abuse of notation, we use a single function to weigh both nodes and edges.}.
Then, for every node $v_i\in V_{\rm con}$, associated with the $i$-th constraint, the weight will be the constraint's bound, i.e., $i$-th element of $\bm{b}$, i.e., $w(v_i)=b_i$.
Similarly, for $v_j\in V_{\rm var}$, associated with the $j$-th variable, $w(v_j)=c_j$, where $\bm{c}=(c_j)_{j=1,\ldots,n}$.
Edge weights are given by the incidence matrix $A$, that is, given $e=(v_{con,i},v_{var,j}) \in E$, then $w(e)= A_{i,j}$.
This graph representation approach establishes a bijective relationship to the instance space, i.e., every MILP instance is uniquely determined by a weighted graph and vice-versa\footnote{For the weighted graph to identify an MILP instance uniquely, it would need to contain the information about the integrality of the variables. Restricting the bijection statement to MILP problems with the same number of integer variables would be more precise. Alternatively, to assume, without loss of generality, that the first $k\le n$ variables (i.e., $x_1$ to $x_k$) are integer variables and use $k$ as a weight for the whole graph.}.

In practice, the graph fed to a GNN is associated with feature vectors $\bm{h}_v^{(0)}, \forall v\in V$, of arbitrary size.
In other words, the information contained in the features provided to the network is a design choice.
It can contain the weights described above, but many other features might also help the model learn the graph-related task~\citep{gasse_exact_2019,nair_neural_2020}.

For illustration purposes, consider an optimization problem in the form of Eq. \eqref{eq:opt} with three variables $\bm{x} = [x_1, x_2, x_3]^T$, three constraints $C_1,C_2$ and $C_3$, and
\begin{equation}\label{eq:A-matrix-example}
    \bm{c} = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}; ~\\
    A = \begin{bmatrix} 1 & 2 & 0 \\ 0 & 1 & -1 \\ 5 & 0 & 1 \end{bmatrix}; ~\\
\bm{b} = \begin{bmatrix} 2 \\ 1 \\ 4 \end{bmatrix}
.\end{equation}
% \begin{equation}\label{ilustra_bi}
% A = \begin{bmatrix} 1 & 2 & 0 \\ 0 & 1 & -1 \\ 3 & 0 & 1 \end{bmatrix}; ~\\
% \end{equation}
% and $\bm{x} = [x_1, x_2, x_3]^T$.
Then, a bipartite graph representation is illustrated in Figure \ref{fig:ilustra_b}.
For the features, one may define \[
\bm{h}_{x_j}^{(0)} = \begin{bmatrix}
    c_j \\
    \frac{1}{3}\sum_{i=1}^{3} A_{ij} \\
    \max_{i} A_{ij}
\end{bmatrix}\quad{\rm and}\quad\bm{h}_{C_i}^{(0)} = \begin{bmatrix}
    b_i \\
    \frac{1}{3}\sum_{j=1}^{3} A_{ij} \\
    \max_{j} A_{ij}
\end{bmatrix}
,\] such that \[
H^{(0)} = \begin{bmatrix}
    \bm{h}_{x_1}^{(0)T} \\
    \bm{h}_{x_2}^{(0)T} \\
    \bm{h}_{x_3}^{(0)T} \\
    \bm{h}_{C_1}^{(0)T} \\
    \bm{h}_{C_2}^{(0)T} \\
    \bm{h}_{C_3}^{(0)T}
\end{bmatrix} = \begin{bmatrix}
    1 & 2 & 5 \\
    2 & 1 & 2 \\
    3 & 0 & 1 \\
    2 & 1 & 2 \\
    1 & 0 & 1 \\
    4 & 2 & 5
\end{bmatrix}
.\]

\begin{figure}[!htb]
\centering
\begin{tikzpicture}
\node[circle,draw,fill =green!40] (x1) {$x_1$};
\node[ right = of x1,circle,draw,fill =green!40] (x2)  {$x_2$};
\node[ right = of x2,circle,draw,fill =green!40] (x3) {$x_3$};

\node[ below = of x1,circle,draw,fill =blue!40] (c1) {$C_1$};
\node[ below = of x2,circle,draw,fill =blue!40] (c2) {$C_2$};
\node[ below = of x3,circle,draw,fill =blue!40] (c3) {$C_3$};
\draw (x1) -- (c1);
\draw (x2) -- (c1);
\draw (x3) -- (c2);
\draw (x1) -- (c3);
\draw (x2) -- (c2);
\draw (x3) -- (c3);
\end{tikzpicture}
\caption{Bipartith graph representation of an MILP with three variables ($x_1$, $x_2$, and $x_3$), three constraints ($C_1$, $C_2$, and $C_3$), and $A$ as in Eq. \eqref{eq:A-matrix-example}.}\label{fig:ilustra_b}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%5
\section{Methodology}\label{sec:meth}

This section presents our methodological approach to tackle the two research questions proposed in the introduction.
As both questions concern learning tasks with GNNs on to the ONTS problem, we describe our approach to generating problem data used to train the deep learning models, and our proposed GNN architecture (SatGNN). 
Furthermore, and specifically for the experiments that tackle the second research question, we show our approach to embed trained deep learning models in heuristic solutions for the ONTS problem.

\subsection{Data}\label{sec:data}

High-quality data is necessary to learn the tasks of interest and perform reliable evaluations.
To achieve a significant quantity of data, we generate new instances of the ONTS problem with variations of all task parameters and energy availability.
However, randomly sampling parameter values suitable for the problem formulation presented in Sec. \ref{sec:problem} would not reflect the distribution of instances we expect to see in practice.
Therefore, we use a methodological approach to sample the parameter values, following \citet{rigo_instance_2023}.
The procedure for generating pseudo-random realistic parameters is detailed in \ref{appx:random-instance}.

The algorithm for constructing our dataset is formalized in Algorithm \ref{alg:dataset-generation}.
We optimize every new instance $I\in\mathcal{I}$ using a commercial solver with limited time, during which we collect the best candidate solutions found (represented by $Z^\star$).
Note that we collect only the values for the binary variables $\bm{z}$, as the binary ones can completely determine the continuous variables (see Sec. \ref{sec:problem}).
% Gurobi~\cite{gurobi_optimization_llc_gurobi_2023} for a maximum of 5 minutes, during which we collect the 500 best candidate solutions found by the solver (represented by $\hat{Z}$).
The instance is rejected if no feasible solution is found during the time budget (or if the solver proves infeasibility).

\begin{algorithm}[h]
    \SetAlgoLined
    \KwData{Time horizon $T$, number of jobs $J$, number of instances (final dataset size) $n$.}
    \KwResult{Dataset $\mathcal{D} = \{(I,Z^\star): Z^\star\subset Z\,{\rm given}\,I\}$.}
    
    \While{$|\mathcal{D}| < n$}{
        $\pi \gets {\tt RandomInstance}(T,J)$ \\
        $I \gets {\tt BuildInstance}(\pi)$ \\
        $Z^\star \gets {\tt Solver}(I)$
        
        \If{$|Z^\star| > 0$}{%
            $\mathcal{D}$.add$(I, Z^\star)$
        }
    }
    \caption{Dataset generation. $\pi$ is the parameter vector described in Sec. \ref{sec:problem}, $Z$ is the set of all feasible solutions, and $Z^\star \subset Z$ is the set of candidate solutions the solver finds.
    For a description of ${\tt RandomInstance}$ see \ref{appx:random-instance}.}\label{alg:dataset-generation}
\end{algorithm}

\subsection{SatGNN}\label{sec:sat-gnn}

We name \emph{SatGNN} the base model proposed for all experiments.
An overview of the components of our model can be seen in the diagram of Figure \ref{fig:sat-gnn-overview}.
We follow the approach of embedding the ONTS problem instances as bipartite graphs and feeding them to a GNN (see Sec. \ref{sec:gnns}).
Because of the convolutional nature of the message-passing iterations of the GNNs, the model can deal with arbitrary-sized graphs, which enables the same GNN to handle optimization problems with varying numbers of variables and constraints.
In other words, the GNN can handle ONTS instances with varying numbers of jobs, which is useful, e.g., for iterating over the number of jobs during the mission design to maximize QoS.

The input graph is enhanced with feature vectors for every node.
Let $G=(V, E,w)$ be the graph representation of an instance $I\in\mathcal{I}$ as described in Sec. \ref{sec:instance-embedding}, with $V=V_{\textrm{var}}\cup V_{\textrm{con}}$ the set of nodes and $w: E \longrightarrow \mathbb{R}$ the edge weight function based on the variables coefficients on the constraints.
We name $\bm{f}_v$ the feature vector associated with node $v$.
We add four features to constraint nodes and six to variable nodes, as described in Table \ref{tab:feature-desc}.

\begin{table}[h]
    \centering
        \caption{Description of input features for SatGNN.}
    \label{tab:feature-desc}
    \begin{tabular}{p{6.5cm}|p{6.5cm}}
    \toprule
        Features of constraint nodes ($\bm{f}_{v_{\rm con}}$) & Features of variable nodes ($\bm{f}_{v_{\rm var}}$) \\
    \midrule
         Constraint's upper bound ($\bm{b}$)                     &  Variable's coefficient in the objective ($\bm{c}$)\\
         Constraint's average coefficient (mean of $A_{i*}$)     &  Variable's average coefficient in the constraints (mean of $A_{*j}$) \\
         Number of neighbors/non-null coefficients ($|\mathcal{N}(v_{\rm con})|$)    &  Number of neighbors/non-null coefficients ($|\mathcal{N}(v_{\rm var})|$) \\
         Whether it is an equality or an inequality constraint &  Largest coefficient in the constraints ($\max(A_{*j})$) \\
                                                                    &  Smallest coefficient in the constraints ($\min(A_{*j})$) \\
                                                                    &  Whether it is a continuous or binary variable \\
    \bottomrule
    \end{tabular}
\end{table}

The feature vectors are encoded into the first layer of hidden features by fully-connected neural networks.
More precisely, the hidden feature vectors $H^{(0)}\in \mathbb{R}^{(n+m)\times d}$ (where $n$ is the number of variables, $m$ is the number of constraints, and $d$ is the dimension of the hidden feature vectors) are computed by single-layer neural networks with ReLU activation
\begin{align*}
    {\rm NN}_{\rm var}:\mathbb{R}^6& \longrightarrow\mathbb{R}^{d}_+ \\
    \bm{f}_{v_{\rm var}} &\longmapsto \bm{h}^{(0)}_{v_{\rm var}} = {\rm NN}_{\rm var}(\bm{f}_{v_{\rm var}})
\end{align*}
and
\begin{align*}
    {\rm NN}_{\rm con}:\mathbb{R}^4& \longrightarrow\mathbb{R}^{d}_+ \\
    \bm{f}_{v_{\rm con}} &\longmapsto \bm{h}^{(0)}_{v_{\rm con}} = {\rm NN}_{\rm con}(\bm{f}_{v_{\rm con}})
,\end{align*}
such that the initial hidden features associated to the variable nodes $H^{(0)}_{\rm var} \in \mathbb{R}^{n\times d}$ are computed through ${\rm NN}_{\rm var}$ and the initial hidden features associated to the constraint nodes $H^{(0)}_{\rm con} \in \mathbb{R}^{m\times d}$ are computed through ${\rm NN}_{\rm con}$, in which $H^{(0)} = [H^{(0)}_{\rm var},H^{(0)}_{\rm con}]$.

At each layer of SatGNN, the graph convolutions are performed in two steps, as in \citet{gasse_exact_2019}.
First, a graph convolution is applied to update the hidden features of the constraint nodes.
Then, another graph convolution is performed, this time considering the updated features of the constraint nodes to update the hidden features of the variable nodes.
These two operations are illustrated in Figure \ref{fig:sat-gnn-overview} through the $GraphConv$ blocks.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.99\textwidth]{SatGNN.pdf}
    \caption{\emph{SatGNN} architecture overview, where $G$ is the bipartite graph representation of an MILP problem instance, $H$ variables represent the sets of hidden features of the nodes, and $NN_\cdot$ are neural networks. The connection of $G$ and the $GraphConv$ operators represents both the weights of the edges and the neighborhood information.}
    \label{fig:sat-gnn-overview}
\end{figure}

Finally, after $L$ iterations, the last layer's hidden features associated to the variable nodes are fed to a neural network
\begin{align*}
    {\rm NN}_{\rm out}:\mathbb{R}^d_+& \longrightarrow\mathbb{R} \\
    \bm{h}^{(L)}_{v_{\rm var}} &\longmapsto \hat{z}_{v_{\rm var}} = {\rm NN}_{\rm out}(\bm{h}^{(L)}_{v_{\rm var}})
.\end{align*}
This network combines the features extracted by the graph convolution operations into the desired shape of the output.
% Note that the output shape will depend on the learning task (see Sec. \ref{sec:training}).
The network contains two layers of $d$ nodes with ReLU activation.
For node classification tasks (Sec. \ref{sec:meth-sol-pred}), the output of the ${\rm NN}_{\rm out}$ contains a sigmoid activation function, resulting in a probability prediction for each variable node.
For graph classification tasks (Sec. \ref{sec:meth-feas-classification}), in which the output is a single probability value for the entire graph, the output of ${\rm NN}_{\rm out}$ for every variable node is summed into a single value before the sigmoid.

\subsection{Training}\label{sec:training}

Two learning tasks are proposed to investigate the research questions that are the focus of this paper. To investigate whether a GNN can learn the structure of the ONTS problem (\textit{first research question}), we train the SatGNN model on the feasibility classification of candidate solutions. To evaluate the effectiveness of a GNN-based heuristic (\textit{second research question}), we train SatGNN to generate candidate solutions given instances of the problem.

\subsubsection{Feasibility Classification}\label{sec:meth-feas-classification}

Given an instance of the ONTS problem $I\in\mathcal{I}$ and a candidate solution $\bm{\hat{z}}$, we want the model to determine whether $\hat{\bm{z}}$ is a feasible solution or not, that is, $p(\hat{\bm{z}}\in Z | I)$, where $Z\subset \{0,1\}^{2JT}$ is the set of feasible solutions.
The candidate solution is fed to the model as features, adding an extra dimension to $\bm{f}_{v_{\rm var}}$.
As briefly described in Section \ref{sec:sat-gnn}, the feasibility classification is a graph classification task, thus, we aggregate the output of SatGNN before the sigmoid function, i.e., the outputs of ${\rm NN}_{\rm out}$ for each variable node are aggregated to generate the predicted logit, before applying the sigmoid to have the predicted probability $\hat{p}(\hat{\bm{z}}\in Z | I)$.
More precisely, we can write \[
\hat{p}(\hat{\bm{z}}\in Z | I) = \frac{1}{|V_{\rm var}|} \sum_{v_{\rm var}\in V_{\rm var}} {\rm NN}_{\rm out}\left(\bm{h}^{(L)}_{v_{\rm var}}\right)
,\] where $\bm{h}^{(L)}_{v_{\rm var}}$ is computed as described in Sec. \ref{sec:sat-gnn}, and $V_{\rm var}$ is the set of variable nodes, as described in Sec. \ref{sec:instance-embedding}.
The model is trained to minimize the binary cross-entropy (BCE) between the predicted probability and the actual probability \[
    \min_{\theta} \mathcal{L}_{\rm feas}(\theta) = \sum_{(I,\hat{\bm{z}}, y)\in \mathcal{D}_{\rm feas}} {\rm BCE}({\rm SatGNN}(I,\hat{\bm{z}};\theta),y) 
,\] where $y\in\{0,1\}$ indicates whether $\hat{\bm{z}}$ is feasible ($y=1$) or not ($y=0$), and $\theta$ encapsulates all trainable parameters of SatGNN, which includes the parameters of the graph convolutions and the parameters of ${\rm NN}_{\rm con}$, ${\rm NN}_{\rm var}$, and ${\rm NN}_{\rm out}$.

The training data is built with instances from $\mathcal{D}$ (see Sec. \ref{sec:data}).
For each instance $I$ such that $(I,Z^\star)\in\mathcal{D}$, beyond $Z^\star$ as a set of feasible solutions, we also associate with the instance two other sets of candidate solutions $Z_{R},Z_N \subset Z$, such that the dataset can be described as \[
    \mathcal{D}_{\rm feas} = \left\{ (I,\hat{\bm{z}},y)\in \mathcal{I} \times Z\times \{0,1\} : (I,Z^\star) \in \mathcal{D}, \hat{\bm{z}}\in Z^\star\cup Z_R\cup Z_N , y = p(\hat{\bm{z}}\in Z | I) \right\}
.\]
Note that $p(\hat{\bm{z}}\in Z | I) \in \{0,1\}$, as it is computed analytically by evaluating the constraints.

The first set is built with randomly sampled instances \[
    Z_R=\left\{\bm{\hat{z}}\in Z : \bm{\hat{z}}\sim \mathcal{U}\left[\{0,1\}^{JT}\right] \right\}
,\] where $\mathcal{U}\left[\{0,1\}^{JT}\right]$ denotes a uniform distribution over the set of all possible assignments for the binary variables.
The second set is built with candidate solutions from the neighborhood of the solutions in $Z^\star$, \[
    Z_N=\left\{\bm{\hat{z}}\in Z : \|\bm{\hat{z}}-\bm{z}^\star\|_0 \le \eta, \bm{z}^\star \in Z^\star \right\}
,\] where $\eta\in\mathbb{N}$ limits the size of the neighborhood. In our experiments, we build candidate solutions in $Z_N$ by randomly flipping at most $\eta$ values from a randomly selected candidate solution from $Z^\star$.
Intuitively, $Z^\star$ and $Z_N$ are used to teach the model the limits of the feasible region, while $Z_R$ carries general information about the domain of the problem.

% \subsubsection{Optimality classification}\label{sec:meth-opt-classification}

% For an instance of the 

\subsubsection{Optimal Solution Prediction}\label{sec:meth-sol-pred}

We want to train the SatGNN model to predict the variables' bias in optimal solutions for instances of the ONTS problem $I\in\mathcal{I}$.
More precisely, we want the model to estimate the probability that each binary variable takes a positive value in the optimal solution, which we will denote as \[
\bm{\hat{p}}(\bm{z}^\star = 1 | I) = \begin{bmatrix}
     \hat{p}(z^\star_{1,1} = 1 | I) \\ \vdots \\ \hat{p}(z^\star_{J,T} = 1 | I)]
\end{bmatrix}
.\]
Therefore, we have a node classification task for which we apply the sigmoid function at the output of SatGNN for each variable node such that
\begin{align*}
    {\rm SatGNN} : \mathcal{I} \times \Theta & \longrightarrow [0,1]^{JT} \\
                    I ; \theta & \longmapsto \hat{\bm{p}}(\bm{z}^\star = 1 | I) = {\rm SatGNN}(I;\theta)
,\end{align*}
where $\theta \in \Theta$ is the vector of trainable parameters.
Note that the most probable candidate solution $\bm{\hat{z}}=(\hat{\bm{x}},\hat{\bm{\phi}})\in \{0,1\}^{2JT}$ is easily obtained given the model's prediction as \[
    \hat{x}_{j,t} = \lceil \hat{p}(x^\star_{j,t} = 1 | I)\rfloor, \forall (j,t)\in\mathcal{J}\times\mathcal{T}
\] and similarly for $\hat{\phi}_{j,t}$.

One way to train the model is to minimize the BCE between the predicted probability and the single best solution known for each instance, minimizing the loss \[
    \min_{\theta} \mathcal{L}_{\rm opt\text{-}b}(\theta) = \sum_{(I,\bm{z}^\star)\in \mathcal{D}_{\rm opt\text{-}b}} {\rm BCE}({\rm SatGNN}(I; \theta),\bm{z}^\star) 
,\] where the dataset is built such that $\bm{z}^\star$ is the best solution available for each instance in $\mathcal{D}$, i.e., \[
    \mathcal{D}_{\rm opt\text{-}b} = \left\{ (I,\bm{z}^\star) \in \mathcal{I}\times Z : (I,Z^\star)\in \mathcal{D}, \bm{z}^\star = \arg\max_{\hat{\bm{z}}\in Z^\star} {\rm QoS}(\hat{\bm{z}}; \bm{u}_I) \right\}
,\] in which $\bm{u}_I$ is the vector of priorities from instance $I$ (see Sec. \ref{sec:problem}).

Another way is through the approach proposed by \citet{nair_neural_2020}, in which multiple solutions are used as targets, being weighted by their objective value.
Note that the best-known solution is also used in this approach, along with sub-optimal solutions.
In this approach, the optimization can be described as \[
    \min_{\theta} \mathcal{L}_{\rm opt\text{-}m}(\theta) = \sum_{(I,Z^\star)\in \mathcal{D}_{\rm opt\text{-}m}} \sum_{\bm{z}^\star \in Z^\star} w(\bm{z}^\star; Z^\star,I) \cdot {\rm BCE}({\rm SatGNN}(I; \theta),\bm{z}^\star) 
,\] where \[
    w(\bm{z}^\star; Z^\star,I) = \frac{\exp({\rm QoS}(\bm{z}^\star; \bm{u}_I))}{\sum_{\bm{z} \in Z^\star}\exp({\rm QoS}(\bm{z}; \bm{u}_I))}
\] is the weight associated with each candidate solution found by the solver, which is built such that the better the objective, the higher the weight, and, for each instance, the weights add up to 1.
Note that we can directly take $\mathcal{D}_{\rm opt\text{-}m}\subseteq \mathcal{D}$.

\subsection{SatGNN-based Heuristic}\label{sec:meth-heuristics}

The output of the SatGNN as trained for the optimal solution prediction, that is, the predicted variables' bias, can be rounded to the closest integer (either 0 or 1) to generate the most probable candidate solution.
However, this is not expected to perform well as we have no feasibility guarantees; thus, any error in the network may generate an infeasible solution.
Given that ONTS problems of moderate size already have thousands of variables\footnote{The smallest instance evaluated by \citet{rigo_branch-and-price_2022} has 1746 binary variables, considering both $x$ and $\phi$ variables.}, infeasibility is likely to occur.
Therefore, we propose using the deep learning model to aid the optimization in three approaches: warm-starting, early-fixing, and trust region.

\subsubsection{Warm-starting}\label{sec:meth-heuristics-ws}

Another straightforward approach to using the information learned by the model is to provide (partial) solutions to a solver, warm-starting the optimization.
For example, the SCIP solver~\citep{bestuzheva_scip_2021} accepts complete and partial solutions to the problem, which are used to guide the inner heuristics during the optimization process.
We use the output of the model to determine which variables will compose the partial solution provided to the solver based on the \emph{confidence} of the model's prediction.
In other words, the closer the model's probability output is to the extreme values (0 or 1), the more confident it is of that assignment.

Formally, let $\hat{\bm{p}}(\bm{z}^\star = 1|I)$ be the output of SatGNN given an instance $I\in\mathcal{I}$ as defined in Sec. \ref{sec:meth-sol-pred}.
Then, we will denote $\bm{\kappa}(\bm{z}^\star|I) \in [0,1]^{2JT}$ the confidence the model has in each binary variable.
For variable $x_{j,t}$ of instance $I$, given that the model's output is $\hat{p}(x_{j,t}^\star = 1|I)$, then we can describe the respective confidence $\kappa(x_{j,t}|I)$ as \[
\kappa(x_{j,t}|I) = \begin{cases}
    \hat{p}(x_{j,t}^\star = 1|I), &\text{if}\quad\hat{p}(x_{j,t}^\star = 1|I) \ge 0.5 \\
    \hat{p}(x_{j,t}^\star = 0|I) = 1 - \hat{p}(x_{j,t}^\star = 1|I), &\text{otherwise}
\end{cases}
.\] The confidence associated with the $\phi_{j,t}$ variables can be described similarly.
Note that the confidence is always between 0.5 and 1.

Let us write $\bm{z}=(\bm{x},\bm{\phi}) = (z_1, \ldots, z_k,\ldots, z_{2JT})$.
We define $\mathcal{C}^{N}_{I}\subseteq \{1,\ldots,2JT\}$ as the set of indices of the $N$ variables that the model is most confident of, that is, $|\mathcal{C}^{N}_I| = N$ and \[
    \mathcal{C}^{N}_I = \left\{ k \in \{1,\ldots,2JT\} : \kappa(z^\star_k|I) \ge \kappa(z^\star_{k'}|I), \forall k' \not\in \mathcal{C}^{N}_I \right\}
.\] Then, a partial solution $\bar{\bm{z}}^{(N)}$ of size $N$ can be written \[
    \bar{\bm{z}}^{(N)} = \left[\hat{z}_{k}\right]_{k\in \mathcal{C}^{N}_{I}}
,\] which contains the predicted assignments of the highest confidence and can be provided to the solver.

Note that warm-starting does not configure a heuristic solution to the problem, as it just modifies the behavior of the heuristics already present in the algorithmic solution.
In other words, warm-starting will only modify the order of exploring the B\&B tree.
Therefore, we maintain optimality and feasibility guarantees, even in the worst-case scenario when the model provides the solver with bad, infeasible solutions.

\subsubsection{Early-fixing}

A heuristic solution can be made by fixing the value assignments based on the most confident biases predicted by SatGNN, similar to what is proposed in the Neural Diving approach by \citet{nair_neural_2020}.
Compared to the warm-starting approach, instead of merely informing the solver, we modify the instance of the problem and fix the values of the variables that the model is most confident of before calling the solver.
More precisely, early-fixing is equivalent (in principle) to adding to the problem constraints of the form \[
    z_{k} = \hat{z}_{k}, \forall k\in \mathcal{C}^{N}_{I}
,\] which limits $N$ variables to the values predicted by the model.
In practice, however, no constraints are added, but the assignment in the existing constraints and the objective replaces the variables.
Thus, the resulting sub-problem will contain fewer binary variables and, thus, is expected to be faster to solve.

Note that every feasible solution to the early-fixed problem and the fixed variables is also feasible in the original instance.
However, an optimal solution to the sub-problem might not be optimal for the original instance.
Even worse, early-fixing the problem might render it infeasible if the model predicts a poor variable assignment.
Therefore, this approach of early-fixing is a matheuristic, as it uses mathematical optimization to find heuristic solutions.

\subsubsection{Trust Region}

Instead of fixing the variables that the model is most confident of, we may allow a slight deviation from the partial candidate solution.
In other words, we can use SatGNN's prediction to define a trust region~\citep{han_gnn-guided_2023}.
A new constraint is added to the problem of the form \[
    \sum_{k\in \mathcal{C}^N_I} \left|z_{k} - \hat{z}_{k} \right| \le \Delta
,\] where $\Delta \in \mathbb{N}$ is the parameter that defines the size of the trust region.
This limits the solution space to vectors in the vicinity of the partial candidate solution.

In the above definition, it is easy to see that the early-fix is a particular case of the trust region method with $\Delta=0$.
In fact, just like the early-fixing approach, allowing a trust region around the (partial) candidate solution also configures a matheuristic, as neither optimality nor feasibility are guaranteed.


%%%%%%%%%%%%%%
\section{Experiments and Results}\label{sec:exps}

The experiments for this paper were conducted in Python, using PyTorch, the DGL libraries, and the SCIP solver, on a server with an Intel i7-12700  16-Core (12 cores, 20 threads), an NVIDIA RTX A4000, 16 GB of memory, running Ubuntu 22.04.1 LTS 64 bits.
\new{All the code written for our experiments, as well as detailed instructions on how to reproduce our results, are available in the paper's accompanying repository\footnote{\url{https://github.com/brunompacheco/sat-gnn}}.}

In the following sections, we present three experiments addressing the two research questions raised in the introduction (Sec. \ref{sec:intro}).
In the first experiment, we train the proposed SatGNN model to classify the feasibility of candidate solutions for problem instances.
We consider three scenarios of increasing difficulty with respect to the generalization performance.
In the second experiment we train SatGNN models to predict the bias for the binary variables of problem instances, effectively learning the probability that each binary variable has to assume a positive value in an optimal solution.
We compare two training approaches, considering either the optimal solution as the target or multiple feasible solutions as targets for each instance.
Finally, we use the models trained for optimality prediction to generate candidate solutions, which are used to construct heuristics to the ONTS problem.
More specifically, we use the trained models to construct three approaches (as presented in Sec. \ref{sec:meth-heuristics}) to improve the SCIP solver in its off-the-shelf setting: warm-starting, early-fixing, and trust region.

\subsection{Dataset}\label{sec:exp-datasets}

The data for the following experiments is generated according to the procedure described in Sec. \ref{sec:data}.
The dataset construction requires verifying feasibility solving to (quasi-)optimality instances of the ONTS problem.
In other words, the dataset construction imposes a high computational cost, which scales with the size of the problem.

To circumvent the cost of dataset generation, we build a training set with many smaller instances and validation and test sets with fewer but larger instances.
This way, we can afford a sufficient volume of data for training while evaluating at the most relevant instances, which have a higher solving cost.
At the same time, we test the model's generalization capability by evaluating its performance on instances harder than those seen during training.

We base our data generation in the instances proposed by \citet{rigo_instance_2023}, which take the FloripaSat-I mission as a reference~\citep{marcelino_critical_2020} (see \ref{appx:random-instance}).
More precisely, we focus on instances with scheduling horizon $T=125$.
%which accounts for a little more than a full orbit.

The dataset is generated through Algorithm \ref{alg:dataset-generation}.
We solve each instance and gather 500 of the best solutions possible, limited to a time budget of 5 minutes.
More precisely, every instance $(I, Z^\star)\in \mathcal{D}$ is such that $|Z^\star| = 500$.
An example of the optimal schedule for one of the generated instances with $J=9$ can be seen in Figure \ref{fig:example-scheduling}.
All instances and solutions are made publicly available~\citep{pacheco_bruno_m_2023_8356798}.

We generate 200 instances for each $J\in\{9,13,18\}$ jobs, and 40 instances for each $J\in\{20,22,24\}$ jobs, in a total of 720 instances.
\new{%
A summary of the size (in terms of variables and constraints) of each instance in our dataset is seen in Table~\ref{tab:dataset-description}.
We underscore the difference in difficulty between the instances in the training set and the ones in the validation and test sets, as evidenced by the significant increase in the average primal-dual gap and decrease in the lower bound as measured by the relative objective value, when solving those instances using our baseline method (SCIP) within the time limit.
}

\begin{table}[h]
    \centering
    \caption{\new{%
    Summary of instances in our dataset.
    Columns $m$ and $n$ indicate the number of constraints and variables, resp., in each instance.
    Under \emph{Dataset}, we present the number of instances in each part of our dataset.
    Columns in \emph{Baseline optimization results} have summary statistics after using our baseline optimization method (SCIP) with the time budget ($T$).
    More specifically, \emph{Feasible} and \emph{Optimal} indicate, respectively, the fraction of instances that were solved to feasibility and optimality under the time budget, \emph{Gap} is the primal-dual gap, and \emph{LB} is the average relative objective of the candidate solutions.
    }}
    \label{tab:dataset-description}
    % \color{blue}
    \begin{tabular}{ccc|ccc|cccc}
    \toprule
               &       &      & \multicolumn{3}{c|}{Dataset} & \multicolumn{4}{c}{Baseline optimization results} \\
    \# of jobs & $m$   & $n$  & Train & Val. & Test          & Feasible & Optimal & Gap  & LB \\
    \midrule
    9          & 7518  & 2250 & 200   &      &               & 98\%     & 20\%    & 0.03  & 98\%      \\
    13         & 10618 & 3250 & 200   &      &               & 96\%     & 3\%     & 0.05  & 95\%      \\
    18         & 13434 & 4500 & 200   &      &               & 85\%     & 0\%     & 0.09  & 83\%      \\
    20         & 14633 & 5000 &       & 20   & 20            & 78\%     & 0\%     & 0.13  & 75\%      \\
    22         & 16430 & 5500 &       & 20   & 20            & 60\%     & 0\%     & 0.17  & 56\%      \\
    24         & 18664 & 6000 &       & 20   & 20            & 48\%     & 0\%     & 0.31  & 42\%      \\
    \bottomrule
    \end{tabular}
\end{table}


\subsection{Feasibility Classification}\label{sec:exp-feas}

As described in Sec. \ref{sec:meth-feas-classification}, we build the dataset for feasibility classification $\mathcal{D}_{\rm feas}$ by adding random candidate solutions to $Z^\star$ for every $(I,Z^\star) \in \mathcal{D}$.
More precisely, for every instance of the ONTS problem, we generate $Z_R$ and $Z_N$ such that $|Z_R|=250$ and $|Z_N| = 250$, in a total of 1000 solutions for every instance.

SatGNN is modified for graph classification as described in Sec. \ref{sec:meth-feas-classification}.
We use the graph convolution proposed by \citet{kipf_semi-supervised_2017}, as presented in equation \eqref{eq:graph-conv}, and a single layer ($L=1$).
The hidden features all have a fixed size $d=8$.
Both ${\rm NN}_{\rm con}$ and ${\rm NN}_{\rm var}$ are neural networks with a single layer and ReLU activation, while ${\rm NN}_{\rm out}$ is an artificial neural network with 3 layers and ReLU activation in the hidden layers and sigmoid activation at the last layer.
For all feasibility classification experiments, SatGNN is trained using Adam~\citep{kingma_adam_2015} with a learning rate of $10^{-3}$ to minimize the binary cross-entropy between the prediction and the feasibility of the candidate solution.
The model is trained until the training loss becomes smaller than $10^{-2}$, limited to a maximum of 200 epochs.

First, SatGNN is trained for one particular instance.
Given an instance $I$, we build $\mathcal{D}_{\rm feas}^{I} = \{ (\bm{\hat{z}},y)\in Z\times \{0,1\} : (I,\bm{\hat{z}},y)\in\mathcal{D}_{\rm feas}\}$.
This dataset is randomly divided into a training and a test set in an 80-20 split, so 800 instances are used to train the model.
For each number of jobs $J\in\{9,13,18,20,22,24\}$, we select 5 different instances randomly.
In all experiments (all instances of all sizes), \emph{SatGNN achieves 100\%  accuracy}, that is, the model is able to perfectly distinguish between feasible and infeasible candidate solutions in the test datasets.

Then, SatGNN is trained to generalize across instances with the same number of jobs.
For each number of jobs $J$, we build the dataset by selecting only instances (and the respective candidate solutions) with the same number of jobs, i.e.,
\begin{equation}\label{eq:D-feas-jobs}
    \mathcal{D}_{\rm feas}^{J} = \{(I,\hat{\bm{z}},y)\in \mathcal{D}_{\rm feas} : J_I = J \}
,\end{equation}
where $J_I$ represents the number of jobs of instance $I$.
20 of the generated instances are randomly selected for training, in a total of 20,000 training samples, while 10 different instances are randomly selected for testing.
SatGNN achieves a very high performance, with over 90\% accuracy on all settings.
The complete test set performance for the different number of jobs can be seen in Figure \ref{fig:across-instances-accuracy}.

\begin{figure}
    \centering
    \includegraphics{accuracy_classification_across_instances.pdf}
    \caption{Test set performance of SatGNN trained for feasibility classification of candidate solutions given a fixed number of jobs. All instances used for testing were not seen by the model beforehand.}
    \label{fig:across-instances-accuracy}
\end{figure}

Finally, SatGNN is trained solely on candidate solutions from small instances (i.e., those with $J\in\{9,13,18\}$) and tested on candidate solutions from large instances (i.e., those with $J\in\{20,22,24\}$).
Following the notation of equation \eqref{eq:D-feas-jobs}, we use $\mathcal{D}_{\rm feas}^9\cup \mathcal{D}_{\rm feas}^{13}\cup\mathcal{D}_{\rm feas}^{18}$ for training and $\mathcal{D}_{\rm feas}^{20}\cup \mathcal{D}_{\rm feas}^{22}\cup\mathcal{D}_{\rm feas}^{24}$ for testing.
In total, 60,000 samples are used for training and 30,000 samples are used for testing.
SatGNN achieves 94.15\% accuracy in the test set.
The performance across the different sizes of instances and the groups of candidate solutions is presented in Table \ref{tab:across-sizes-accuracy}.
We see that the model has more difficulty in the candidate solutions from the $Z_N$ sets, the candidate solutions in the edge of the feasible region.
It is also true that the performance decreases with problem size (number of jobs), indicating an increasing difficulty, as expected.

\begin{table}[h]
    \centering
    \caption{Feasibility classification performance of SatGNN on instances larger than those used for training. The test set is discriminated into the three sets of candidate solutions that compose it (see Sec. \ref{sec:meth-feas-classification}). Each row indicates the set of 10 instances with the same size (number of jobs).}
    \label{tab:across-sizes-accuracy}
    \begin{tabular}{c | cccc}
    \toprule
               & \multicolumn{4}{c}{Accuracy}          \\
    \# of jobs & $Z^\star$ & $Z_N$ & $Z_R$   & Total   \\
    \midrule
    20         & 100\%     & 90\%  & 100\%   & 97.5\%  \\
    22         & 100\%     & 80\%  & 100\%   & 95\%    \\
    24         & 90\%      & 90\%  & 89.84\% & 89.96\% \\
    \bottomrule
    \end{tabular}
\end{table}

\new{%
To further assess the architecture of the SatGNN model, we perform an ablation study on the number of layers in the $NN_{\text{out}}$ component.
We repeat the training and evaluation of the SatGNN model in the feasibility classification task across instance sizes for different numbers of layers in the last MLP of our model.
More specifically, we experiment with up to 4 layers in $NN_{\text{out}}$, and for each number of layers, we repeat the experiment 5 times with different random initializations.
The average performance of those models appears in Figure~\ref{fig:nnout-layers-ablation-accuracy}.
No significant difference can be observed between the experiments, indicating that the learning primarily occurs before $NN_\text{out}$, in the graph convolutional layers.
In fact, applying the Wilcoxon signed-rank test~\citep{wilcoxon_1945} shows no statistically significant ($p$-value$>0.05$) difference between the samples; however, this result should be taken with caution in the face of the size of the samples.
}

\begin{figure}
    \centering
    \includegraphics{feasibility_classification_ablation_accuracy.pdf}
    \caption{\new{%
    Test set performance of SatGNN with a varying number of layers in $NN_{\text{out}}$. Accuracy is measured as an average over 5 random repetitions of the experiment. Vertical bars indicate the minimum and maximum values observed.
    }}
    \label{fig:nnout-layers-ablation-accuracy}
\end{figure}


\subsection{Optimal Solution Prediction}\label{sec:exp-opt-pred}

Following the methodology presented in Sec. \ref{sec:meth-sol-pred}, we first generate the datasets $\mathcal{D}_{\rm opt\text{-}b}$ and $\mathcal{D}_{\rm opt\text{-}m}$ from the dataset $\mathcal{D}$ (described in Sec. \ref{sec:exp-datasets}).
Having both datasets allows us to compare the two different training strategies: training with a single target (quasi-optimal solution), and training with the best solutions found (which include the quasi-optimal solutions).
% Note that $\mathcal{D}_{\rm opt}$ is easily generated from the $\mathcal{D}$ by just taking the best candidate solution from each $Z^\star$, while $\mathcal{D}_{\rm mopt}$ is identical to $\mathcal{D}$.
The data is divided into training, validation, and test sets.
The training sets contain the 200 small instances from $\mathcal{D}$, with 9, 13 or 18 jobs, while the validation and test sets contain, each, 20 large instances from $\mathcal{D}$, with 20, 22 or 24 jobs, such that no instance is used in both validation and test (empty intersection).

The models are trained according to the description provided in Sec. \ref{sec:meth-sol-pred}.
Both when training with the best solution for each instance and when training with multiple solutions, the models are trained using Adam to minimize the BCE between the prediction and the targets.

\new{%
We tune the hyperparameters of the models by performing a random search and evaluating the models' performance on the validation set.
More specifically, we optimize the learning rate, number of convolutional layers ($L$), number of hidden features ($d$), graph convolutional operator, and whether or not the convolutions share the parameters.
Table~\ref{tab:hp-tuning} shows the ranges and best values found.
We refer the reader to our code repository\footnote{\url{https://github.com/brunompacheco/sat-gnn}} for further details, as we have made all our hyperparameter tuning implementation and results available.
We underscore that for both models, the SAGE graph convolution is the best choice, as well as sharing the parameters between the two convolutional operators.
}

\begin{table}[h]
    \centering
    \caption{\new{Hyperparameter space and best values for both models trained for optimality prediction. \emph{BS} and \emph{MS} indicate, resp., the models trained with the best solution and multiple solutions as targets. \emph{Weight tying} refers to the parameter sharing process between the two graph convolutional operators in the model (see Section \ref{sec:sat-gnn}).}}
    \label{tab:hp-tuning}
    % \color{blue}
    \begin{tabular}{l|c|c|c}
    \toprule
                             &                                               & \multicolumn{2}{c}{Best value} \\
    Hyperparameter           & Search space                                  & BS             & MS            \\
    \midrule
    Learning rate            & $\{10^{-2},10^{-3},10^{-4}\}$                 & $10^{-2}$      & $10^{-3}$     \\
    Layers ($L$)             & $\{1,2,3\}$                                   & $2$            & $3$           \\
    Hidden features ($d$)    & $\{2^5,2^6,2^7,2^7\}$                         & $2^6$          & $2^8$         \\
    Graph convolution        & $\{\text{GraphConv},\text{SAGE}\}$            & SAGE           & SAGE          \\
    Weight tying             & $\{\text{Yes},\text{No}\}$                    & Yes            & Yes           \\
    \bottomrule
    \end{tabular}
\end{table}

\new{Our training stopping criteria is determined through the validation set, i.e., from all epochs of our training budget (100 epochs), we pick the model that achieves the lowest validation loss.}
The training curve for both training approaches can be seen in Figure \ref{fig:opt-training-curves}.
After training with the best solution, the average BCE on the validation set is 0.2887 and on the test set 0.2873.
After training with multiple solutions, the average BCE on the validation set is 0.2451 and on the test set 0.2482.
Although the BCE values are not comparable across training approaches, the small difference between the validation and the test sets for both approaches indicates no sign of overfitting.

\begin{figure}
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{training_curve_optimal.pdf}
        \caption{Best Solution}\label{fig:training-bs}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{training_curve_multi.pdf}
        \caption{Multiple Solutions}\label{fig:training-ms}
    \end{subfigure}
    \caption{Training curves for SatGNN models trained with (a) the best solution or (b) multiple solutions. The best average BCE on the validation set (highlighted in red) is used for early-stopping the training.}
    \label{fig:opt-training-curves}
\end{figure}

\new{%
To grasp the actual performance of the models in the optimality prediction, we evaluate both on the test set after training.
Because of the high number of variables, neither could predict all variable assignments of any instance perfectly.
However, when considering each variable assignment individually, the model trained with multiple solutions and the model trained with the best solutions achieved 90\% and 88\% average accuracy, respectively.
We point out that the data is naturally biased towards zero assignments, as most jobs pass most of the time inactive (not assigned to run) when there are many jobs to be scheduled.
Given the imbalance of the data, the performance of both models is better visualized in Figure~\ref{fig:confusion-matrices}.
Furthermore, the model trained with multiple solutions achieved an F1 score of 0.72, while the model trained with the best solutions achieved an F1 score of 0.68.
}

\begin{figure}
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics{confusion_matrix_os.pdf}
        \caption{Best Solution}\label{fig:cm-bs}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics{confusion_matrix_ms.pdf}
        \caption{Multiple Solutions}\label{fig:cm-ms}
    \end{subfigure}
    \caption{\new{Accuracy of the models when predicting optimal assignments. Computed with respect to all variables of all instances in the test set.}}
    \label{fig:confusion-matrices}
\end{figure}

\new{%
For building useful primal heuristics, the models should achieve consistent behavior across instances, meaning they should correctly predict a high number of variable assignments.
Under that perspective, we measure the accuracy within each instance, which is calculated as the ratio of correctly classified variable assignments within a given instance.
The performance is detailed in the histogram of Figure~\ref{fig:histogram-accuracy}.
We see that both models achieve high expected accuracy values, and none of them ever correctly predicts less than 75\% of the variables correctly.
}

\begin{figure}[h]
    \centering
    \includegraphics{histogram_accuracy.pdf}
    \caption{\new{Histogram of accuracies for both models over the test set. For each instance, we compute the ratio of correctly predicted variable assignments. Vertical dashed lines indicate the mean value.}}
    \label{fig:histogram-accuracy}
\end{figure}


A deeper analysis is performed on the models' confidence when predicting variable assignments $\bm{\kappa}(\bm{z}=1|I)$, as presented in Sec. \ref{sec:meth-heuristics-ws}.
The average confidence of both models on instances of the test set is depicted in Figure \ref{fig:prediction-confidences} with respect to the binary variables of the optimization problem.
Training with multiple solutions seems to result in a more confident model overall.
Furthermore, both models provide significantly more confident predictions for the $\bm{\phi}$ variables.

% \begin{figure}
%     \centering
%     \begin{subfigure}{\textwidth}
%         \centering
%         \includegraphics{figures/optimals_confidence.pdf}
%         \caption{Model trained with the best solution.}
%     \end{subfigure}
%     \begin{subfigure}{\textwidth}
%         \centering
%         \includegraphics{figures/multiple_confidence.pdf}
%         \caption{Model trained with multiple solutions.}
%     \end{subfigure}
%     \caption{Average confidence (probability of the predicted class) of predicted values for $\bm{x}$ and $\bm{\phi}$ variables. The average is taken over all jobs of all instances in the test set.}
%     \label{fig:prediction-confidences}
% \end{figure}

\begin{figure}[h]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{X_confidences.pdf}
        \caption{$x_{j,t}$}\label{fig:conf-x}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Phi_confidences.pdf}
        \caption{$\phi_{j,t}$}\label{fig:conf-phi}
    \end{subfigure}
    \caption{Average confidence (probability of the predicted class) of predicted values for (a) $\bm{x}$ and (b) $\bm{\phi}$ variables of the model trained only with the best solution and the model trained with multiple solutions. The average is taken over all jobs of all instances in the test set.}
    \label{fig:prediction-confidences}
\end{figure}

\subsection{SatGNN-based Heuristic}\label{sec:exp-heuristics}

The two models presented in Sec. \ref{sec:exp-opt-pred} are used (each) to build three matheuristics, as described in Sec. \ref{sec:meth-sol-pred}.
Namely, the two models are the SatGNN trained with the best solution available and the SatGNN trained with multiple solutions (see Sec. \ref{sec:meth-sol-pred}).
The three matheuristics evaluated are: warm-starting, early-fixing, and trust region.
We use SCIP as our solver both for the baseline results and the optimization within the matheuristics.

Although all model parameters and hyperparameters are already defined (and will not change) by the time the heuristics are assembled, the heuristics have their own hyperparameters, which require adjustment.
More specifically, all three heuristic approaches have the hyperparameter $N\in\mathbb{N}$, representing the size of the partial solution extracted from SatGNN.
Besides, the trust region matheuristic has the size of the trust region $\Delta\in\mathbb{N}$.

We use the validation set to select the best values for the hyperparameters, aiming to optimize two performance metrics.
For once, we select values for the hyperparameters that maximize the expected objective value.
\new{The objective values are normalized, i.e., we divide them by the objective value of the best solution known for each instance\footnote{We remind the reader that those solutions were computed along with the dataset generation, as detailed in Section~\ref{sec:exp-datasets}.}, resulting in a value between $0$ (no QoS) and $1$ (max. QoS known for the instance).}
In parallel, we select the hyperparameters that minimize the time required to find a feasible solution to each problem.
The two tunings are performed for the SatGNN model trained with the best solution available and the SatGNN trained with multiple solutions.
Table \ref{tab:best-N-delta} summarizes the best hyperparameters for each model and each heuristic approach, in both evaluations.

\begin{table}[h]
    \centering
    \caption{Best values for partial solution size ($N$) and trust region size ($\Delta$) for each heuristic approach and each SatGNN model, as evaluated on the validation set. \emph{Objective} corresponds to the values that maximize the objective value of the best solution found. \emph{Feasibility} indicates the values that minimize the amount of time to find a feasible solution.}
    \label{tab:best-N-delta}
    \begin{tabular}{ll|cc|cc}
    \toprule
                                        &              & \multicolumn{2}{c|}{Objective} & \multicolumn{2}{c}{Feasibility} \\
    SatGNN model                        & Heuristic    & $N$         & $\Delta$        & $N$          & $\Delta$         \\
    \midrule
    \multirow{3}{*}{Best Solution}      & Warm-start   & 750         & -               & 1000         & -                \\
                                        & Early-fix    & 500         & -               & 750          & -                \\
                                        & Trust region & 1000        & 5               & 1000         & 1                \\
    \midrule
    \multirow{3}{*}{Multiple Solutions} & Warm-start   & 1750        & -               & 1500         & -                \\
                                        & Early-fix    & 1000        & -               & 1250         & -                \\
                                        & Trust region & 1250        & 1               & 1750         & 1             \\
    \bottomrule
    \end{tabular}
\end{table}

The heuristics are then evaluated on the test set, which is not used for tuning neither the deep learning models' hyperparameters nor the heuristics' hyperparameters.
The final performance is measured through the expected relative objective value given the time budget, and the time it takes the heuristics to find a feasible solution.
Furthermore, we also analyze the progress of the lower bound over time, indicating the expected performance under more restricted budgets.
Figure \ref{fig:heuristics-test-results} illustrates the results.

\begin{figure}
    \centering
    \begin{subfigure}{0.99\textwidth}
        \centering
        \includegraphics[width=\textwidth]{heuristic_test_obj.pdf}
        \caption{Best solution found within the time budget.}
        \label{fig:heuristics-test-results-obj}
    \end{subfigure}
    \begin{subfigure}{0.99\textwidth}
        \centering
        \includegraphics[width=\textwidth]{heuristic_test_feas.pdf}
        \caption{Time to find a feasible solution.}
        \label{fig:heuristics-test-results-feas}
    \end{subfigure}
    \caption{Test set performance of the SatGNN-based matheuristics. On the left, we have the distribution of the evaluation metric of interest over the instances of the test set for the multiple approaches, in which the triangle indicates the mean value and the circles indicate outliers. \emph{MS} indicates that the SatGNN model trained with multiple solutions was used, whereas \emph{BS} indicates that the model trained solely with the optimal solution was used instead. On the right is the average progress of the lower bound on all test set instances. \new{The objective value is considered relative to the objective of the best solution known, thereby always lying in the unit interval.} The heuristics' hyperparameters $N$ and $\Delta$ are defined upon experiments on the validation set, as presented in Table \ref{tab:best-N-delta}.}
    \label{fig:heuristics-test-results}
\end{figure}

\new{%
To assess the significance of the results presented in Figure \ref{fig:heuristics-test-results} through statistical tests.
Given that the matheuristic performance data is generated from a shared set of instances, our samples are paired.
Furthermore, there is no evidence of normality in the results' distribution.
Therefore, we apply the Wilcoxon signed-rank test~\citep{wilcoxon_1945}, which is a non-parametric version of the t-test for matched pairs.
We apply the test pair-wise, comparing each matheuristic approach to every other matheuristic approach, and to the baseline.
}
The results are summarized in the critical difference diagram of Figure \ref{fig:cdds}.
Through early-fixing, both SatGNN models provide statistically significant ($p$-value$>0.05$) improvements over the baseline in both performance metrics.
However, the results show a significant advantage of the model trained with multiple solutions, providing better solutions (objective value) through early-fixing and trust region, and speeding up the feasibility definition (time to find a feasible solution) through all heuristic approaches.

\begin{figure}
    \centering
    \begin{subfigure}{0.99\textwidth}
        \centering
        \includegraphics{cdd_obj.pdf}
        \caption{Best solution found within the time budget.}
        \label{fig:cdd-obj}
    \end{subfigure}
    \begin{subfigure}{0.99\textwidth}
        \centering
        \includegraphics{cdd_feas.pdf}
        \caption{Time to find a feasible solution.}
        \label{fig:cdd-feas}
    \end{subfigure}
    \caption{Critical difference diagram presenting the average test set performance of the SatGNN-based matheuristics (round marker in the axis). A crossbar between two (or more) approaches indicates that their performance (distribution on the test set) was not deemed significantly different ($p$-value$>0.05$) through the paired Wilcoxon signed-rank test~\citep{wilcoxon_1945}.}
    \label{fig:cdds}
\end{figure}

Through the SatGNN model trained with multiple solutions, a 43\% increase in the expected objective value within the time budget is achieved by early-fixing the partial solution, while defining a trust region around that same partial solution resulted in an expected 45\% increase.
Although the results are close, we see from the progress of the lower bound (in Fig. \ref{fig:heuristics-test-results-obj}, the plot on the right) that the early-fix heuristic is able to find better solutions more quickly than the trust region method during the time budget.
In terms of feasibility, the early-fixing strategy using the same SatGNN model reduces in 35\% the expected time to find a feasible solution, having a significant advantage over all other heuristic approaches.
Surprisingly, even when optimized (through hyperparameter tuning) for reducing the time to find a feasible solution, the early-fix heuristic still improves the expected objective value of the best solution found in 41\%, as the lower bound progress illustrates (in Fig. \ref{fig:heuristics-test-results-feas}, the plot on the right).

\subsubsection{Partial Solution Size}\label{sec:exp-N}

To evaluate the impact of the value of $N$, the number of variables in the partial solution being fed to the matheuristics, we further evaluate the SatGNN model on the test.
More specifically, we vary the value of $N$ for all matheuristics and measure the impact on the test set considering both perspectives (objective value and time to find a feasible solution).
For completeness, we also vary $\Delta$, the size of the trust region, to evaluate the full potential of the matheuristic.
For conciseness, we consider only the SatGNN model trained with multiple solutions, as it is overall superior, in our experiments, to the model trained solely with the best solution.
The results are illustrated in Figure \ref{fig:N-impact}.

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.59\textwidth}
        % \centering
        \includegraphics[width=\textwidth]{N_impact_obj.pdf}
    \end{subfigure}
    \begin{subfigure}[t]{0.40\textwidth}
        % \centering
        \includegraphics[width=\textwidth]{N_impact_feas.pdf}
    \end{subfigure}
    \caption{Performance of the matheuristics for varying values of $N$, the number of binary variables in the partial solution. \emph{EF} indicates the early-fixing matheuristic, \emph{TR} the trust region, and \emph{WS} warm-start. The SatGNN model trained with multiple solutions is used. The evaluation is performed on the test set.}
    \label{fig:N-impact}
\end{figure}

As expected, the number of variables that compose the partial solution is impactful for all approaches, with early-fixing being the one most sensitive to it, and warm-start the less sensitive one.
Furthermore, we note a relation between $N$ and $\Delta$ through the peak performance of the trust region method (including early-fixing, which is equivalent to trust region with $\Delta=0$), that is, larger partial solutions seem to require larger trust regions.
Intuitively, this result is expected since the partial solutions are based on confidence, and, thus, the larger the partial solution is, the higher the expected probability of it including wrongly predicted variables.
Therefore, this results suggests that the SatGNN model is properly trained (its confidence correlates to its performance).


%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}\label{sec:discussion}

In this section, we discuss the results obtained from a series of experiments to address the research questions posed in the introduction.
The experiments aimed to evaluate the effectiveness of GNNs in solving the ONTS problem.
More specifically, we use our proposed model, SatGNN, based on the models by \citet{gasse_exact_2019} and \citet{hamilton_inductive_2017}.
Our experiments evaluate whether SatGNN can learn feasibility and optimality given large instances of the ONTS problem and whether the trained model can be used in heuristic solutions.

The results of the first set of experiments (Sec. \ref{sec:exp-feas}) indicate that the SatGNN can provide accurate feasibility estimations even in challenging scenarios.
Three scenarios of increasing difficulty were considered, and the results were quite promising, with over 89\% accuracy in all experiments.
In the most challenging scenario, SatGNN is evaluated on large ($J\in\{20, 22, 24\}$) unseen instances, but trained on small instances ($J\in\{9,13,18\}$), and it achieved 94.15\% accuracy in feasibility classification.
The remarkable accuracy indicates that SatGNN is highly effective at learning the constraints of the ONTS problem.
This performance is expected as the feasibility classification task requires the model to learn linear classification boundaries, which are derived from the problem's linear constraints.
In other words, the model learns the indicator function of a convex set (considering the problem's LP relaxation), for which neural networks are known to be suitable.

The second set of experiments (Sec. \ref{sec:exp-opt-pred}) aimed to predict optimal solutions to ONTS instances using SatGNN.
More specifically, SatGNN was trained to predict the biases of the binary variables for multiple instances of the ONTS problem.
Two training approaches were explored: one trained with a single target (the quasi-optimal solution) and another trained with multiple solutions (the best feasible solutions found).
Both approaches showed promising results, with no signs of overfitting, as indicated by the small difference between validation and test set performance.

\new{%
Both models achieved similar accuracy results on a per-variable basis, with the model trained with multiple solutions having a slight advantage of 2 p.p. on average.
Nevertheless, as illustrated by Figure~\ref{fig:histogram-accuracy}, both models show similar distributions, always correctly predicting more than 75\% of the variables in all instances.
}
Interestingly, the model trained with multiple solutions tended to be more confident in its predictions, particularly for the binary variables.
This increased confidence could be valuable in guiding the optimization process, as it can be understood as an indication of the model's certainty about its predictions.

Although the results from the second set of experiments suggest that SatGNN can effectively predict optimal or near-optimal solutions to ONTS instances, we put the models to the test through a third set of experiments (Sec. \ref{sec:exp-heuristics}) in which we build (mat)heuristic solutions based on the output of the SatGNN trained for optimality prediction.
Namely, as detailed in Sec. \ref{sec:meth-heuristics}, three approaches were evaluated for applying the model's output: warm-start, early fix, and trust region.
Each approach is optimized for finding the best solution, giving the time budget (2 min.) and reducing the time to find a feasible solution (2 separate experiments).
First, we notice that in all direct comparisons, the SatGNN model trained with multiple solutions resulted in better heuristic solutions than the model trained with a single solution, as the results of the second set of experiments suggested.

Early-fixing the partial solution provided by the SatGNN models yielded the best results overall, showing a 43\% gain in the evaluation of the expected objective value within the time budget, and a 35\% reduction in the evaluation of the expected time to find a feasible solution.
The trust region approach, which can be seen as a relaxation of early-fixing, was comparable to early-fixing in terms of the best solution found within the time limit. However, overall, it seems to provide a worse trade-off, as both early-fixing and trust region do not provide optimality guarantees, but trust region takes longer to find good solutions to the ONTS problem.
Using the SatGNN models to warm-start the SCIP solver significantly reduced the time needed to find a feasible solution (in comparison to the baseline), but it was worse overall than the two other approaches.

Across all experiments, a highlight of the GNNs' performance was the generalization to larger instances.
This characteristic is essential for problems with varying instance size and is not trivially achievable with traditional deep-learning models.
However, it is also key for tasks with higher acquisition costs for certain problem sizes, as in the case of the ONTS problem.
Large instances of optimization problems are the ones that drive the research of heuristic solutions, as they are usually more expensive to solve; however, as we need to solve instances to create a training dataset, it often becomes infeasible to train the deep learning models on large instances.
In this context, the generalization results from our experiments suggest that GNNs can be effectively trained using easy (cheap to acquire) instances of the problem, and be used on the hard instances of interest.

Generating reliable instances to train and evaluate solvers is a key point in such a project, as the confidence of the results depends on how carefully instances are designed to compose the test set~\citep{smith-miles_generating_2015}.
Data generation is particularly critical when historical data is not available~\citep{bengio_machine_2021}, which motivates the research on algorithms for generating reliable instances~\citep{smith-miles_generating_2015,malitsky_structure-preserving_2016}.
We follow the problem definition of the FloripaSat-I mission~\citep{marcelino_critical_2020} to define the parameters' ranges used to sample new instances uniformly.
Although the data generation process is reliable, it still depends on the optimization of every randomly generated instance.
Furthermore, as we restrict ourselves to feasible instances, we only add to the dataset instances for which the solver could find at least one feasible solution within the time budget, effectively restricting our data to an easier sub-problem~\citep{yehuda_its_2020}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion and Future Research}\label{sec:conclusion}

This work has proposed a novel approach to tackle the ONTS problem using graph neural networks.
More specifically, we investigated whether a GNN can learn the structure of the problem and be used to build effective heuristic solutions.
Our experiments showed that our proposed architecture, SatGNN, successfully classifies the feasibility of candidate solutions and is also able to provide reliable partial solutions to varied instances of the ONTS problem.
Not only was the model able to generalize to unseen instances, but it also showed promising results on out-of-distribution instances, which were larger than the ones seen during training.
This outcome shows how the inherent symmetries of graph neural networks make them suitable for dealing with the structures of the optimization problem.

By leveraging partial solutions provided by the SatGNN model, we built heuristic solutions to the ONTS problem that outperformed the SCIP solver in hard instances.
More specifically, by fixing the variable assignment from the partial solution provided by SatGNN, our heuristics were able to improve up to 43\% in the expected objective value of the best solution found within the time budget and reduce up to 35\% in the expected time to find a feasible solution.

Overall, the experiments presented in this paper showcase the potential of GNNs for addressing the ONTS problem.
\new{The high accuracy in feasibility classification, the ability to predict optimal solutions, and the effectiveness of SatGNN-based heuristics suggest that our learning-based approach yields a strong primal heuristic that has the potential to significantly improve the performance of exact methods for complex space mission scheduling problems.}

%Further research could explore the scalability of these methods to larger problem instances, problems with satellite constellations, and real-world applications in space mission planning and scheduling.

\subsection{Future Work}

\new{%
Given the nature of the ONTS problem, generating large, difficult instances is a significant challenge.
Although realistic, the instance generation method used in this work is limited regarding instance difficulty by the time budget.
One possible future research direction is to leverage easier instances, combining job parameters to generate large feasible instances that extrapolate the time budget restriction.
This line also leads to a non-trivial application of machine learning models for combinatorial optimization: guiding the search for difficult instances.
More specifically, using the SatGNN for feasibility classification could significantly alleviate the cost of generating larger feasible instances.
}

\new{%
Future works naturally entail the integration of the proposed methodology into exact methods tailored to the ONTS problem.
State-of-the-art branch-and-price algorithms~\citep{rigo_branch-and-price_2022} could significantly benefit from better initial solutions.
The explainability aspects could be further developed to provide deeper insights into solution quality and guide the generation of columns for specific jobs.
Additionally, the approach could be adapted to handle dynamic scheduling scenarios where task requirements evolve over time, requiring online learning to update the parameters of the SatGNN.
Also, the principles developed here could be extended to related space mission optimization problems, including constellation management and multi-satellite resource allocation challenges.
}

\section*{Acknowledgments}

The authors acknowledge support from CNPq (Conselho Nacional de Desenvolvimento Cient{\'\i}fico e Tecnol{\'o}gico) under grant numbers 150281/2022-6 and 404576/2021-4 as well as FAPESC under grant number 2021TR001851. 


\section{Declaration of Generative AI and AI-assisted technologies in the writing process}

During the preparation of this work the author(s) used generative AI tools in order to perform light editing of the text. After using these tools/services, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.

%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
\appendix

\section{Symbols in the ONTS mathematical programming model}\label{appx:tab-symbols}

The table below compiles the sets, variables, and parameters of the ONTS MILP formulation.

\bigskip

% \color{blue}
\begin{tabular}{cl}
\hline
\textbf{Symbol} & \textbf{Description} \\ \hline
\multicolumn{2}{l}{\quad\textit{Sets}} \\ \hline
\(\mathcal{J}\) & Tasks assigned to the nanosatellite \(\{1, \dots, J\}\) \\ 
\(\mathcal{T}\) & Discrete time periods within the planning horizon \(\{1, \dots, T\}\) \\ \hline
\multicolumn{2}{l}{\quad\textit{Decision Variables}} \\ \hline
\(x_{j,t}\) & Binary: 1 if task \(j\) is executed at time \(t\), 0 otherwise \\
\(\phi_{j,t}\) & Binary: 1 if task \(j\) starts at time \(t\), 0 otherwise \\
\hline
\multicolumn{2}{l}{\quad\textit{Parameters}} \\ \hline
\(u_{j,t}\) & Utility or mission value derived from executing task \(j\) at time \(t\) \\ 
\(w^{\min}_{j}\) & Minimum start time window for task \(j\) \\
\(w^{\max}_{j}\) & Maximum start time window for task \(j\) \\ 
\({p}^{\min}_{j}\) & Minimum time between consecutive starts of task \(j\) \\ 
\({p}^{\max}_{j}\) & Maximum time between consecutive starts of task \(j\) \\ 
\({t}^{\min}_{j}\) & Minimum execution time of task \(j\) \\ 
\({t}^{\max}_{j}\) & Maximum execution time of task \(j\) \\ 
\({y}^{\min}_{j}\) & Minimum number of start-ups for task \(j\) \\ 
\({y}^{\max}_{j}\) & Maximum number of start-ups for task \(j\) \\ 
\(b_{t}\) & Energy balance at time \(t\) \\ 
\(i_{t}\) & Total current at time \(t\) \\ 
\(\text{SoC}_{t}\) & State-of-charge of the battery at time \(t\) \\  
\(r_{t}\) & Power input at time \(t\) (from solar panels) \\  
\(q_{j}\) & Power consumption of task \(j\) per time slot \\ 
\(V_{b}\) & Nominal battery voltage \\  
\(e\) & Battery efficiency during charging and discharging \\  
\(Q\) & Nominal capacity of the battery \\ 
\(\rho\) & Minimum energy level allowed for the battery \\  
\(\gamma\) & Maximum allowed current rate for charging or discharging the battery \\ \hline
\end{tabular}
\color{black}




%%%%%%%%%%%%%%%%%%
\section{Random instance generation}\label{appx:random-instance}

For any particular mission size and orbital length, the main objective is to generate a realistic ONTS case using random data.
We have taken the FloripaSat-I mission as a reference for instance generation, which has an altitude of 628 kilometers and an orbital period of 97.2 minutes~\cite{marcelino_critical_2020}.
The battery-related parameters are fixed for all instances as
\begin{align*}
    e &\gets 0.9 \\
    Q &\gets 5 \\
    \gamma &\gets 5 \\
    V_b &\gets 3.6 \\
    \rho &\gets 0.0
\end{align*}
The attitude considered here is the Nadir, in which the satellite turns at the same rate around the Earth, so one side (or axis) always faces the Earth's surface.
This analytical model then utilizes a rotation matrix to simulate the satellite's dynamics and can be adapted for larger or different geometries by adjusting the normal vectors representing the body.

To generate realistic power input vectors $\boldsymbol{r}$, we use 2 years of historical data of solar irradiance in orbit.
More precisely, a window is randomly drawn from the historical data, and an analytical model is used to determine the power input vector.
Once orbits are stable and solar flux constant -- $1360 W/m^2$  -- one can calculate this vector by knowing the spacecraft orbit, attitude -- its kinematics -- and size~\cite{filho_comprehensive_2020}.

The remaining parameters are drawn uniformly, given handcrafted limits to increase the feasibility rate.
Specifically, given the number of tasks $J$ and the number of time units $T$, the parameters are drawn as
\begin{align*}
    u_j &\gets \mathcal{U}(1, J) \\
    q_j &\gets \mathcal{U}(0.3, 2.5) \\
    y_j^{\min} &\gets \mathcal{U}(1, \lceil T/45 \rceil) \\
    y_j^{\max} &\gets \mathcal{U}(y_j^{\min}, \lceil T/15 \rceil) \\
    t_j^{\min} &\gets \mathcal{U}(1, \lceil T/10 \rceil) \\
    t_j^{\max} &\gets \mathcal{U}(t_j^{\min}, \lceil T/4 \rceil) \\
    p_j^{\min} &\gets \mathcal{U}(t_j^{\min}, \lceil T/4 \rceil) \\
    p_j^{\max} &\gets \mathcal{U}(p_j^{\min}, T) \\
    w_j^{\min} &\gets \mathcal{U}(0, \lceil T/5 \rceil) \\
    w_j^{\max} &\gets \mathcal{U}(\lfloor T-\lceil T/5 \rceil \rfloor, T)
.\end{align*}

%% \section{}
%% \label{}

%% If you have bibdatabase file and want bibtex to generate the
%% bibitems, please use
%%
\bibliographystyle{elsarticle-harv} 
\bibliography{compiled_main.bib}

%% else use the following coding to input the bibitems directly in the
%% TeX file.

% \begin{thebibliography}{00}

%% \bibitem[Author(year)]{label}
%% Text of bibliographic item

% \bibitem[ ()]{}

% \end{thebibliography}

\end{document}

\endinput
%%
%% End of file `elsarticle-template-harv.tex'.
