\documentclass[%
 reprint,
superscriptaddress,
nofootinbib,
 amsmath,amssymb,
 amsfonts,
 aps,
]{revtex4-2}

\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{dcolumn}
\usepackage{bm}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=blue,      
    urlcolor=blue,
    citecolor=blue, 
    pdftitle={GFL paper},
    pdfpagemode=FullScreen,
    }
\usepackage{appendix}
\usepackage[mathlines]{lineno}
%\linenumbers\relax

\usepackage[normalem]{ulem}
\usepackage{tabularx}
\newcolumntype{Y}{>{\centering\arraybackslash}X}

\usepackage[usenames,dvipsnames]{color}
\newcommand{\steve}[1]{ {\color{red}{\textbf{\textit{Steve:}} #1}} }
\newcommand{\william}[1]{ {\color{blue}{\textbf{\textit{WGL:}} #1}} }

\begin{document}

\preprint{APS/123-QED}

\title{The Need For Speed: Rapid Refitting Techniques for Bayesian Spectral Characterization of the Gravitational Wave Background Using PTAs}

\author{William G. Lamb}
 \affiliation{Department of Physics \& Astronomy, Vanderbilt University, 2301 Vanderbilt Place, Nashville, TN 37235, USA}
 \email{william.g.lamb@vanderbilt.edu}
\author{Stephen R. Taylor}
 \affiliation{Department of Physics \& Astronomy, Vanderbilt University, 2301 Vanderbilt Place, Nashville, TN 37235, USA}
\author{Rutger van Haasteren}
\affiliation{Max-Planck-Institut f{\"u}r Gravitationsphysik (Albert-Einstein-Institut), Callinstrasse 38, D-30167, Hannover, Germany}

\date{\today}

\begin{abstract}
Current pulsar timing array (PTA) techniques for characterizing the spectrum of a nanohertz-frequency stochastic gravitational-wave background (SGWB) begin at the stage of timing data. This can be slow and memory intensive, with computational scaling that will worsen PTA analysis times as more pulsars and observations are added. Given recent evidence for a common-spectrum process in PTA data sets, and the need to understand present and future PTA capabilities to characterize the SGWB through large-scale simulations, we have developed efficient and rapid approaches that operate on intermediate SGWB analysis products. These techniques refit SGWB spectral models to previously-computed Bayesian posterior estimations of the timing power spectra. We test our new techniques on simulated PTA data sets and the NANOGrav $12.5$-year data set, where in the latter our refit posterior achieves a Hellinger distance---bounded between $0$ for identical distributions and $1$ for zero overlap---from the current full production-level pipeline that is $\lesssim 0.1$. Our techniques are $\sim10^2$--$10^4$ times faster than the production-level likelihood, and scale much more favorably (sub-linearly) as a PTA is expanded with new pulsars or observations. Our techniques also allow us to demonstrate conclusively that SGWB spectral characterization in PTA data sets is driven by the longest-timed pulsars with the best-measured power spectral densities, which is not necessarily the case for SGWB detection that is predicated on correlating many pulsars. Indeed, the common-process spectral properties found in the NANOGrav $12.5$-year data set are given by analyzing only the $\sim10$ longest-timed pulsars out of the full $45$ pulsar array, and we find that the ``shallowing'' of the common-process power-law model occurs when gravitational-wave frequencies higher than $\sim 50$~nanohertz are included. The implementation of our techniques is openly available as a software suite to allow fast and flexible PTA SGWB spectral characterization and model selection.

\end{abstract}

\maketitle

%%%%%%%%%%
\section{\label{sec:intro}Introduction}
%
Pulsar Timing Arrays (PTAs) \citep{1990ApJ...361..300F} may be on the cusp of detecting the nanohertz-frequency stochastic gravitational wave background (SGWB) from a population of supermassive black hole binary (SMBHB) systems \citep{astro4cast}. By measuring deviations between the expected and observed radio-pulse times-of-arrival (TOAs) from a set of pulsars, the SGWB may be inferred by the spatial correlations it induces between pulsars in the PTA; in particular, the Hellings \& Downs correlation signature \citep{hellings1983upper}.

The North American Nanohertz Observatory for Gravitational waves (NANOGrav) \citep{Arzoumanian2020-br}, the European PTA (EPTA) \citep{10.1093/mnras/stab2833}, and the Parkes PTA (PPTA) \citep{Goncharov_2021}---individually, and in collaboration as the International PTA (IPTA) \citep{iptadr2}---have reported evidence for a spatially-uncorrelated common-spectrum process that affects all pulsars in the array. However, no significant evidence has yet been found for Helling \& Downs correlations that would herald the presence of the SGWB. Continued observations and expanded pulsar arrays, perhaps with the inclusion of the Indian PTA \citep{joshi2018precision}, as well as emerging timing projects like CHIME \citep{chime} and MeerTime \citep{bailes2018meertime}, may soon yield convincing evidence for inter-pulsar Hellings \& Downs (HD) correlations \citep{astro4cast}.

Despite the present lack of detection, information about putative source populations may still be gleaned from current data sets and the properties of the measured common uncorrelated process (CUP). Spectral characterization of the SGWB is dominated by the auto-correlation terms of the Bayesian PTA likelihood, hence if the CUP is really a precursor signature of the SGWB, then the properties of the CUP should be an excellent approximation of full SGWB spectral characterization \citep{Taylor2022-nq, Romano2020-mq, astro4cast}. Assuming that the source of the SGWB is a population of circular SMBHBs that are inspiralling purely due to gravitational wave (GW) emission, the SGWB's characteristic strain $h_\mathrm{c}$ as a function of frequency follows a power-law, $h_\mathrm{c}(f) = A_\mathrm{1yr^{-1}}\left(f / f_\mathrm{1yr^{-1}}\right)^{\alpha}$,
where $\alpha=-2/3$, and the amplitude $A$ is determined by the demographics of the binary population, e.g., number density of emitting systems per redshift, primary mass, and mass ratio \citep{Burke-Spolaor2018-io, Phinney_2001}.

Thus, spectral characterisation of the SGWB by fitting an $\alpha=-2/3$ power-law is astrophysically informative for population estimation. However, galaxy mergers are significantly more complicated. Cosmic variance may cause deviations from the power-law spectral index of $\alpha=-2/3$ \citep{sesana_vecchio_colacino, Roebber_2016, kelley_17}, while orbital eccentricity, and interactions of binaries with gas and stars (particularly at wider orbital separations) will attenuate the expected SGWB characteristic strain at lower frequencies \citep{Sesana_2013, Burke-Spolaor2018-io}. This causes a deviation from a power-law \citep{Sampson2015-qj} and as such, the SGWB may have a more feature-rich spectral shape that carries information about the dynamical interactions of the SMBHB population within the final parsec of orbital evolution.

Beyond SMBHBs, searches are underway for cosmic strings \citep{1986coco}, primordial gravitational waves \citep{Lasky_2016}, and cosmological phase transitions \citep{cpt2015}. These signals are likely to be an additional, weaker contribution to the SMBHB signal. \citet{Kaiser2022-su} investigated the separability of a SGWB signal into its component sources -- a circular-SMBHB-population signal and a background from primordial gravitational waves. Using simulated data sets developed by \citet{astro4cast}, they found that they could begin to distinguish two injected power-law spectra from 17 years of data, and after 20 years, they could begin to characterize the sub-dominant power-law GWB signal. However, their sub-dominant injected GWB spectrum had a cosmological energy density that was still rather strong, comparable to current upper limits on primordial gravitational waves \citep[e.g.][]{arzoumanian2018nanograv, Lasky_2016}.

Current PTA GW search techniques involve modeling the SGWB as a term within the PTA time-domain covariance matrix. Uneven observational sampling and issues with spectral leakage from windowing renders fast searches directly in the Fourier domain impractical. The computational bottleneck of modeling with a time-domain Gaussian likelihood is inverting the covariance matrix within which the SGWB signal contributes. Even with the accelerations afforded by modeling low-frequency processes like the SGWB or per-pulsar red noise on lower rank bases, as well as implementing sparse and other linear algebra speed-ups, Bayesian parameter estimation of SGWB models with the PTA likelihood via Markov Chain Monte Carlo (MCMC) sampling can require a few days to weeks of computation. This is the status quo, and can be expected to worsen as more pulsars are added and further observations of existing pulsars are incorporated into datasets. In addition, Bayesian spectral model selection can be challenging given the significant wall-time it would take to carry out. There is great need for robust, efficient, and flexible analysis methods for PTAs as more data from more pulsars PTAs are collected, in particular when high-cadence observations from telescopes such as CHIME in the near future significantly increase the data volume.

Significant acceleration of parameter estimation was achieved by \citet{Taylor2022-nq} through factorizing the PTA likelihood for a CUP into parallelized per-pulsar analyses \citep[see e.g.][]{Arzoumanian2020-br, iptadr2, Johnson_2022, Goncharov_2021}. This Factorized Likelihood (FL) method shows excellent agreement with the full production-level PTA likelihood analysis. Unfortunately, the FL method assumes a power-law CUP with a fixed spectral index---typically $\alpha=-2/3$ as a default model of a SGWB from SMBHBs---thereby limiting spectral characterization to models with a fixed spectral shape. A more general approach would maintain the likelihood computational speed-up, parallelization over pulsars, and the intended modularity of this FL technique, while permitting analyses of SGWB models with arbitrary spectral parametrizations.

In this paper, we introduce a generalization of the FL approach that allows for rapid SGWB spectral characterization under arbitrary parametrized models, rather than just a fixed-slope power-law. This is made possible by condensing the pulsar timing data down to what we call \textit{Bayesian periodograms}: probability density reconstructions of the pulsar timing-residual power spectral density at each frequency. Models are then re-fit to combinations of these Bayesian periodograms. In \autoref{sec:method}, we discuss current analysis methods before introducing our analysis techniques. We present the results of our comparison tests between the current and new methods on simulated and real data in \autoref{sec:results}, before sharing our conclusions in \autoref{sec:discuss}.
%
\section{\label{sec:method}Methods}
In this section, we explain current PTA data-analysis techniques as they pertain to SGWB spectral characterization, and discuss expected future limitations as PTA data sets expand. We then introduce the factorized likelihood (FL) approach, \cite{Taylor2022-nq} and the concept of refitting spectral models to Bayesian periodograms of PTA timing residuals.


    \subsection{\label{sec:current}Current spectral characterization methods}
    
    PTA analyses model pulsar timing residuals $\vec{\delta t}$ as the sum of a deterministic pulsar timing model and stochastic red and white noise components:
    %%%%%%%%%%
    \begin{equation} \label{eq:residuals}
        \vec{\delta t} = \mathbf{M}\vec{\epsilon} + \mathbf{F}\vec{a} + \vec{n}.
    \end{equation}
    %%%%%%%%%%
    The $(N_\mathrm{TOA}\times m)$-shaped \textit{design matrix} $\mathbf{M}$ is a matrix of partial derivatives of the TOAs with respect to $m$ timing-ephemeris parameters evaluated at an initial fitting solution, with a vector of linear offsets from the initial fit $\vec{\epsilon}$. Red-noise processes, such as the common gravitational wave signal and red noise intrinsic to each pulsar, are modeled as a Fourier sum over $N_f$ sampling frequencies such that, for $i$-th timing residual observed at time $t_i$,
    %%%%%%%%%%
\begin{equation} \label{eq:redfourier}
    \left[\mathbf{F}\vec{a}\right]_i = \sum_{k=1}^{N_f} \left\{a_k\sin\left(\frac{2\pi k t_i}{T}\right) + b_k\cos\left(\frac{2\pi k t_i}{T}\right)\right\},
\end{equation}
%%%%%%%%%%
    where $T$ is the timing baseline (typically the total timespan of the data set being analyzed). As such, $\mathbf{F}$ is a $N_\mathrm{TOA}\times2N_f$ matrix of sines and cosines evaluated at observation times, and $\vec{a} = \left(a_1, b_1, a_2, b_2, ..., a_{N_f}, b_{N_f}\right)^\mathrm{T}$ is a vector of Fourier coefficients. We model intrinsic red noise (IRN) as independent between pulsars, and the SGWB as a common signal to all pulsars. For a single pulsar $p$, its total red noise is the sum, $(\mathbf{F}\vec{a})_p=(\mathbf{F}\vec{a})_p^\mathrm{IRN}+(\mathbf{F}\vec{a})^\mathrm{SGWB}$. 

    Finally, $\vec{n}$ is uncorrelated white noise due to radiometer noise, instrumental effects, and pulsar phase jitter. We rearrange equation \eqref{eq:residuals} to model residual, unmodeled noise as $\vec{r}$:
    %%%%%%%%%%
    \begin{equation} \label{eq:WNresiduals}
        \vec{r} = \vec{\delta t} - \mathbf{M}\vec{\epsilon} - \mathbf{F}\vec{a} = \vec{\delta t} - \mathbf{T}\vec{b},
    \end{equation}
    %%%%%%%%%%
    where $\mathbf{T}=[\mathbf{M}\ \mathbf{F}]$ and $\vec{b}=[\vec{\epsilon}\ \vec{a}]^\mathrm{T}$. Other contributions to the timing residuals include correlated white noise between TOAs within the same timing epoch, and radio frequency-dependent red noise due to time-dependent variation in dispersion from the interstellar medium\citep[see e.g.][]{cordes2010measurement, keith2013measurement}.
    
    We place a zero-mean Gaussian prior on $\vec{b}$ such that, for model hyper-parameters $\vec{\eta}$,
    %%%
    \begin{equation}\label{eq:b-prior}
        p(\vec{b}|\vec{\eta}) = \frac{\exp{\left(-\frac{1}{2}\vec{b}^\mathrm{T}\mathbf{B}^{-1}\vec{b}\right)}}{\sqrt{\det{\left(2\pi \mathbf{B}\right)}}},
    \end{equation}
    %%%%%%%%%%
    where $\mathbf{B}\equiv\mathbf{B}(\vec{\eta})=\langle\vec{b}\vec{b}^\mathrm{T}\rangle=\mathrm{diag}(\mathbf{\infty},\mathbf{\phi})$. The matrix $\mathbf{\phi}$ is the Fourier-domain covariance on red-noise processes, while the $\infty$-block effectively converts the Gaussian prior into a improper uniform prior on the timing model. Given that we will eventually only deal with the inverse of $\mathbf{B}$, we need not worry about the practicalities of treating infinities.

    The full hierarchical likelihood of the timing residuals given the model hyoer-parameters and $b$-coefficients is given by $p(\vec{\delta t}|\vec{b},\vec{\eta}) = p(\vec{\delta t}|\vec{b}) \times p(\vec{b}|\vec{\eta})$. %, which for $N_p$ pulsars, which requires $\mathcal{O}(10^3)$ parameters. 
    However, we are only interested in the model hyper-parameters $\vec{\eta}$ that describe the statistical properties of various stochastic processes; thus we marginalize over the Gaussian $b$-coefficients to recover a more concise likelihood:
    %%%%%%%%%%
    \begin{equation} \label{eq:PTA like}
        p(\vec{\delta t}|\vec{\eta}) = \frac{\exp{\left(-\frac{1}{2}\vec{\delta t}^\mathrm{T}\mathbf{C}^{-1}\vec{\delta t}\right)}}{\sqrt{\det{\left(2\pi \mathbf{C}\right)}}}.
    \end{equation}
    %%%%%%%%%%
    Here, $\mathbf{C}=\mathbf{N} + \mathbf{TBT}^\mathrm{T}$ is the full time-domain covariance matrix of the data model, with white-noise covariance $\mathbf{N}$, where
    %
    \begin{align} \label{eq:PTA cov}
        [\mathbf{C}]_{(pi),(qj)} = [\mathbf{N}]_{p,(ij)}\delta_{pq}\delta_{ij} &+ [\mathbf{C}^\mathrm{IRN}]_{p,(ij)}\delta_{pq} \nonumber \\
        &+ \Gamma_{pq}[\mathbf{C}^\mathrm{SGWB}]_{(ij)}.
    \end{align}
    %%%%%%%%%%
    \autoref{eq:PTA cov} indexes over pulsars ($p,q$) and TOAs ($i,j$). $[\mathbf{N}]_{p,(ij)}$ and $[\mathbf{C}^\mathrm{IRN}]_{p,(ij)}$ are the white noise and intrinsic red noise covariance matrix components respectively for pulsar $p$ and $i$-th TOA, while $[\mathbf{C}^\mathrm{SGWB}]_{(ij)}$ is the covariance matrix components for the SGWB between the $i$-th and $j$-th TOAs. The expected GW-induced cross-correlation in timing residuals between pulsars is given by the overlap reduction function (ORF) coefficient $\Gamma_{pq}$. The SGWB is expected to induce a quadrupolar-like correlation pattern among pulsar pairs, known as the Hellings \& Downs (HD) curve \citep{hellings1983upper}.

    All current spectral characterization techniques involve computing the PTA likelihood in \autoref{eq:PTA like} under different models or assumptions. When inter-pulsar correlations are modeled, inverting $\mathbf{C}$ scales as $\mathcal{O}(N_p^3N_b^3)$. As more TOAs and more pulsars are added to the array, evaluation of this likelihood will slow down significantly because of this scaling. The autocorrelation blocks in the PTA data covariance matrix contain white noise, pulsar-intrinsic red noise, and the SGWB, while the cross-correlation blocks only feature the SGWB. Interestingly, it has been found recently that spectral characterization of an SGWB is dominated by PTA autocorrelation information \citep{Romano2020-mq,astro4cast}. For our purposes here we can therefore assume no correlations between pulsars, and we model the CUP with $\Gamma_{pq}=\delta_{pq}$.
    
    Modeling only the diagonal blocks of the PTA data covariance matrix reduces the likelihood evaluation scaling to $\mathcal{O}(N_pN_b^3)$. Physically speaking, this significant acceleration arises because the PTA likelihood is factorized as a product over pulsars:
%%%%%%%%%%
    \begin{align} \label{eq:model2a}
        p(\{\vec{\delta t}\} | \vec\eta) &= \frac{\exp{\left(-\frac{1}{2}\sum_{p=1}^{N_p}\vec{\delta t}_{p}^\mathrm{T}C_{pp}^{-1}\vec{\delta t}_{p}\right)}}{\sqrt{\det{\left(2\pi C\right)}}} \nonumber \\
        &= \prod_{p=1}^{N_p} \frac{\exp{\left(-\frac{1}{2}\vec{\delta t}_{p}^\mathrm{T}C_{pp}^{-1}\vec{\delta t}_{p}\right)}}{\sqrt{2\pi C_{pp}}} =\prod_{p=1}^\mathrm{N_p} p(\vec{\delta t}_p|\vec{\eta}),
    \end{align}
    %%%%%%%%%%
    where $p(\vec{\delta t}_p|\vec{\eta})$ is the likelihood for a single pulsar $p$ with a set of timing residuals $\vec{\delta t}_p$, and $\vec{\eta}$ are model hyperparameters describing variables like spectral-shape parameters, etc. However, this factorization is not exploited to full effect within the production-level \texttt{enterprise} analysis pipeline \citep{enterprise}, which carries this out as a serialized calculation over pulsars. Parallelizing the computation over $N_p$ processors would theoretically remove the computation's dependence on the number of pulsars, while being numerically equivalent to an analysis that uses the production-level PTA likelihood.
    
    \subsection{\label{sec:refit}Factorized likelihood methods}
    The factorized likelihood (FL) corresponds to a class of techniques where \autoref{eq:model2a} is computed in parallel across pulsars, then the re-weighted posterior distributions from each pulsar are combined in post-processing to calculate the likelihood for the array. Evaluation of the likelihood becomes approximately scale invariant with $N_p$. \citet{Taylor2022-nq} modeled a power-law SGWB strain spectrum with a fixed spectral index of $\alpha=-2/3$ to recover posteriors on the SGWB strain amplitude for each pulsar. The posteriors on the strain amplitude were represented by histograms, re-weighted by the single-pulsar parameter priors, then multiplied across pulsars with a suitable prior for the final posterior calculation.
    
    This fixed-index FL technique has been used in SGWB searches of the NANOGrav 12.5-year data set \citep{Arzoumanian2020-br} and IPTA Data Release 2 \citep{iptadr2} to accelerate parameter estimation and cross-validation. However as discussed in \autoref{sec:intro}, cosmic variance and SMBHB environmental interactions may cause the SGWB strain spectrum to deviate from the expected power-law behavior. Additionally, early-Universe GW signals may contribute towards the SGWB with spectral shapes that are different from that of the SMBHB signal. We therefore require a more flexible and generalized FL approach that would allow for inference of more physically-motivated SGWB spectral models.
    
    A General Factorized Likelihood (GFL) approach is possible by fitting spectral models to the \textit{free spectrum}, a minimally-modeled Bayesian spectral characterization of PTA data \citep{lentati, taylor13}. The free spectrum recovers the joint posterior of the red-noise power spectrum at all sampling frequencies, parameterized by the coefficient $\rho$, such that
    %%%%%%%%%%
    \begin{equation} \label{eq:freespec}
        \rho_{k}^2 := \frac{\langle\vec{a_k}^\mathrm{T}\vec{a_k}\rangle}{T} = \frac{S(f_k)}{T},
    \end{equation}
    %%%%%%%%%%
    where $k$ is the Fourier frequency-bin index and $S$ is the power spectral density of the timing residuals induced by red processes. Typically, a free-spectrum analysis is conducted with a uniform prior on $\log_{10}\rho$, with posteriors jointly recovered at all sampling frequencies. In the following we assume that there is independence between sampling frequencies, thus no covariance between them. PTA searches deal with unevenly sampled pulsar timing observations, so we will assess the strength of this assumption in our tests.

    Refitting spectral models to Bayesian free spectra can be done at various levels; one can $(i)$ perform a PTA Bayesian free-spectrum analysis, followed by refitting on the PTA free spectrum, or $(ii)$ perform free-spectral analyses on individual pulsars that are then combined into a likelihood against which spectral models are fit. There are some variations within $(ii)$ that we discuss in the next sub-section.

    The general scheme for $(i)$ is as follows. Translating $h_\mathrm{c}$ into $\rho$-space gives
%%%%%%%%%%
    \begin{equation} \label{eq:rho_pl}
        \rho_k^2 = \frac{h_\mathrm{c}(f_k)^2}{12\pi^2f_k^3 T} = \frac{A}{12\pi^2T}\left(\frac{f_k}{f_\mathrm{1yr^{-1}}}\right)^{-\gamma},
    \end{equation}
    %%%%%%%%%%
    where $\gamma=3-2\alpha=13/3$ for the idealised SMBHB population. We form a likelihood by computing the probability that a given model is supported by the free spectrum at each frequency.
    %%%%%%%%%%
    \begin{align} \label{eq:FL}
        p(\{\vec{\delta t}_p\} | \vec\eta) &\approx \prod_{k=1}^{N_f} \int \mathrm{d}\rho_k\,\, p(\{\vec{\delta t}_p\} | \rho_k) \, p(\rho_k | \vec\eta)  \nonumber \\
        &\propto \prod_{k=1}^{N_f} \int \mathrm{d}\rho_k\,\, \frac{p(\rho_k | \{\vec{\delta t}_p\})}{p(\rho_k)} \times p(\rho_k | \vec\eta)  
    \end{align}
    %%%%%%%%%%
    where $p(\rho_k)$ is the prior probability of $\rho_k$ in the free-spectrum analysis, $p(\rho_k | \{\vec{\delta t}_p\})$ is the marginal posterior probability density of $\rho_k$ that is sampled using MCMC techniques, and $p(\rho_k | \vec\eta)$ is the probability of $\rho_k$ under a parametrized spectral model, such as \autoref{eq:rho_pl}. In all cases considered here, the spectral model maps precisely to a value of $\rho$ at each frequency, in which case the integral in \autoref{eq:rho_pl} is trivial. However, \autoref{eq:FL} is the more general form that allows for models which have intrinsic spread, due to, e.g., cosmic variance \citep{Roebber_2016,Burke-Spolaor2018-io}. We note that the PTA free-spectrum need not necessarily use only autocorrelation information in the PTA; a spatially-correlated free-spectral analysis may be performed, which would still allow factorization over frequencies.

    In \autoref{eq:FL} the approximation is that the frequencies are independent, just like they would be in Fourier analysis of regularly sampled data. This is not true in pulsar timing in general, because the observations are 1) irregularly sampled, 2) observations are heteroscedastic, 3) the timing model is covariant with the $\vec{a_k}$, and 4) not all pulsars are observed for the same number of years. Regardless, empirically we know that the $\rho_k$ are generally not covariant from regular free spectrum analyses, and we assume that  \autoref{eq:FL} is a good approximation.
    
    To compute probabilities of a spectral model with a given set of hyper-parameters $\vec\eta$ under the free-spectral likelihoods $p(\{\vec{\delta t}_p\} | \rho_k)$, we use optimized density estimation. There are already a number of examples in the literature of fitting SGWB spectra to a free spectrum of a PTA (e.g. \citep{Ratzinger_2021, deng}). It is favored over analyzing the full likelihood because it is fast, since the data structures that we are fitting to are no longer the timing residuals themselves, but a compressed representation in terms a red process at each GW frequency. Other timing-residual contributions such as from the timing model, uncorrelated and correlated white noise, and interstellar-medium effects, are preprocessed out. However, it is not always clear what choices have been made to represent the free spectrum likelihoods during the refit stage. Density estimation can introduce biases and errors if the data is under/over-fitted, and care must be taken to represent the data accurately.

    The simplest density estimation technique is by binning our free-spectrum MCMC samples as histograms, just like in the FL method. This recreates the probability densities of the free spectra posteriors within bins of $\log_{10} \rho$. To faithfully reconstruct the original distribution, an appropriate choice of bin width must be made. If the width of the bins are too wide, the histogram will be \textit{oversmoothed}, perhaps removing important fluctuations in the actual distribution. In contrast, if the bin width is too narrow, the histogram will \textit{undersmooth} the data, creating a density reconstruction that captures all of the fluctuations in the data that are a result of statistical sampling randomness and not due to the underlying distribution. There are several standard rules of thumb ways of fining the optimal bin width for a histogram given some data, such as by using Scott's Normal Reference Rule \citep{scott} or the Freedman-Diaconis Rule \citep{freedman1981histogram}, which are tuned for an underlying normal distribution.
    
    Unfortunately, histograms do not result in a continuous distribution from which probability densities can be extracted, causing some loss of data in-between bins, particularly if the bin width is wide. Posteriors at different frequencies will likely have varying numbers of bins, and extracting probabilities from bin arrays of changing lengths for different frequencies requires book-keeping and is computationally inefficient.
    
    An alternative method is to use Kernel Density Estimators (KDEs) \citep{kde1, kde2}. A KDE recreates a distribution by replacing each sample with a normalized, symmetric, strictly positive, real-valued function called a kernel (also known as a window function). If samples $(x_1, x_2, \ldots, x_N)$ are extracted from an unknown distribution $f$, the density estimate $\hat{f}$ of a KDE is given by
    %%%%%%%%%%
    \begin{equation} \label{eq:KDE}
        \hat{f}(x) = \frac{1}{Nh} \sum_{i=1}^{N} K\left(\frac{x-x_i}{h}\right),
    \end{equation}
    %%%%%%%%%%
    where $K$ is the kernel function, and $h$ is the bandwidth of the KDE. As with histograms, an appropriate bandwidth must be chosen to avoid creating an under- or over-smoothed estimator. The kernel function itself is also a choice to be decided. In this paper, we use an \textit{Epanechnikov kernel} \citep{epanechnikov}, and select bandwidths using the \textit{Sheather-Jones Plug-in Selector} \citep{sj}. Further details on these choices, and KDEs in general, are given in Appendix~\ref{appendix:kde}.
    
    Finally, the extension to factorize the likelihood over pulsars simply requires that the right hand side of \autoref{eq:FL} is modified to have an additional product over pulsars; this then explicitly makes the usual FL assumption of conditioning spectral characterization on the PTA autocorrelation information:
    %
    \begin{equation}
    	 p(\{\vec{\delta t}_p\} | \vec\eta) \propto \prod_{p=1}^{N_p}\prod_{k=1}^{N_f} \int \mathrm{d}\rho_k\,\, \frac{p(\rho_k | \vec{\delta t}_p)}{p(\rho_k)} \times p(\rho_k | \vec\eta) .
    \end{equation}
    %
    \subsection{\label{sec:pipe}Refit pipelines}
    
        We refit our free-spectral likelihood representations using Markov Chain Monte Carlo (MCMC) techniques. A typical algorithm is as follows: $(1)$ an iteration of the MCMC proposes a set of parameters for the spectral model, from which we calculate our $\rho$ coefficients at all GW sampling frequencies; $(2)$ we then find the probability of these model $\rho$ values under the free-spectrum likelihoods at each frequency---and, if applicable, for each pulsar----given our KDEs, and take their product to compute the total likelihood. The employed Metropolis-Hastings algorithm will then reject or accept those parameters accordingly. We repeat this until the MCMC has sufficiently sampled the parameter space of the spectral model and converged to the target posterior.
        
        KDE objects are memory intensive, and extracting the probability density function of a point from every KDE object at each MCMC iteration would slow down computation. However, KDEs are continuous, therefore before conducting the MCMC, we extract an array of probabilities along a grid of $\log_{10}\rho$ that is intentionally finer than the KDE bandwidth. This allows us to implement \texttt{numpy} vectorization techniques to accelerate computation of the likelihood. When a set of $\rho$ are calculated, we look up its probability within the pre-calculated KDE density array across frequencies (and pulsars, where relevant).
        
        With this strategy, there are three possible types of refits that can be conducted:

        \begin{enumerate}[label=\textbf{$(\roman*)$},wide=0pt]
        %
        \item \textbf{PTA free spectrum refit:} The one-time PTA free spectrum analysis step models the entire PTA with a timing model, white noise, and power-law intrinsic red noise for each pulsar, and a free-spectrum common process across the entire array. The interpulsar correlation model is adopted at this stage (i.e., uncorrelated, Hellings \& Downs, etc.). The refit process fits a common-process spectral model to the free spectrum posteriors. Note that while we can refit SGWB spectra to different numbers of frequencies with the PTA free spectrum, we cannot refit using different combinations of pulsars without recomputing the free spectrum with our desired array.
        %
        \item[$(ii$--$a)$] \textbf{GFL Lite:} Each pulsar is analyzed independently in parallel, with a model composed of a timing model, white noise, power-law intrinsic red noise, and a free spectrum that acts as a proxy for the common process. We then refit a common spectral model to the free spectra of an ensemble of all (or a subset of) pulsars to recreate the PTA common process. This method allows us to fit a common process to different combinations of pulsars and frequencies quickly. However the per-pulsar intrinsic red noise model cannot be refit.
        %
        \item[$(ii$--$b)$] \textbf{GFL:} The most generalized case considered in this paper. Since the common process and the pulsars' intrinsic red noise are indistinguishable at the individual pulsar level, we may model them both together through a single free spectrum. Therefore, each pulsar is modeled in parallel with a timing model, white noise, and a single free spectrum only. The refit stage then models intrinsic red noise in each individual pulsar and a common process across the ensemble of selected pulsars. We can fit any intrinsic red noise model and common process to any combination of frequencies and pulsars. The benefit of this generalization is to rapidly model more complicated or bespoke intrinsic red noise models for each pulsar (beyond power-laws), and to rapidly alter priors on spectral parameters. The drawback (as we shall see) is that the increased dimensionality of this refit analysis compared to the previous two demands very high fidelity KDE representation of the free-spectral likelihoods.
        
        \end{enumerate}

        \noindent
        
    %%%%%%%
    \subsection{\label{sec:timing}Pipeline profiling}
    
    In addition to being modular and flexible, our motivation for these approaches is to develop a significantly faster analysis method to spectrally characterize PTA data, especially where many repeated studies and simulations are required. The primary bottleneck in current production methods is inverting the covariance matrix of the PTA likelihood. As discussed in \autoref{sec:current}, the spatially-uncorrelated full-likelihood evaluation should scale $\propto N_p$ because of the inversion of a block-diagonal PTA covariance matrix, and should scale as $\propto N_p^3$ for the Hellings \& Downs (HD)-correlated full likelihood because of the additional off-diagonal structure of this PTA covariance matrix.

    We profiled our analyses on a simulated $N$-pulsar PTA dataset with an injected SGWB signal (as detailed later in \autoref{sec:sims}), evaluating the likelihood 50 times for the uncorrelated and HD-correlated power-laws, and $10^4$ times for the PTA free-spectrum refit, GFL Lite, and GFL methods to calculate a mean computation time. The timing profiles are shown in \autoref{fig:profiler}. For a simulated 45-pulsar data set, the mean likelihood evaluation time for the uncorrelated full likelihood was $0.012$~seconds, and $0.24$~seconds for the HD-correlated full likelihood. The uncorrelated full likelihood scales as expected with the number of pulsars, however the HD-correlated full likelihood scales $\propto N_p^2$, rather than the expected $\propto N_p^3$. This suggests that for our simulated PTA, the likelihood evaluation benefits either from sparse linear algebra optimizations and/or operations that are dominated by matrix-vector scalings. The 45-pulsar PTA free-spectrum refit likelihood takes $53$~milliseconds, while GFL Lite and GFL likelihoods for 45 pulsars are $88$~milliseconds and $181$~milliseconds, respectively. These are $226$, $136$, and $66$ times faster than the uncorrelated full likelihood (which is the most fair comparison).

    The GFL Lite likelihood evaluation is constant as the number of pulsars increases, while GFL shows a weak sub-linear scaling. The GFL likelihood evaluation is slightly slower than GFL Lite because it explicitly models and samples intrinsic red noise for each pulsar. The bottleneck in this computation is from \texttt{np.searchsorted} which causes the weak scaling with $N_p$ as the algorithm must search a KDE density grid with $N_p$ columns for probabilities corresponding to proposed intrinsic red noise for each pulsar. In addition, a full GFL analysis will require more MCMC iterations for convergence than the GFL Lite or the PTA free-spectrum refit because of the additional $2N_p$ parameters for intrinsic red-noise modeling, which increases the total analysis time compared to the two other refit techniques. Despite this, GFL is still significantly faster than the uncorrelated and HD-correlated full likelihood analyses.
%%%%%
    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figs/profile.pdf}
        \caption{The likelihood evaluation time as a function of the number of pulsars on a simulated data set, ran on an AMD EPYC 7702 64-core processor. The uncorrelated (red) and HD-correlated (purple) full likelihoods scale $\propto N_p$ and $\propto N_p^2$ respectively, while GFL (green) has a weak sub-linear scaling with number of pulsars. GFL Lite (orange) is scale-independent with the number of pulsars, but the PTA free-spectrum refit (dashed blue) is the most rapid method at $10^2-10^4 \times$ faster than the uncorrelated and HD-correlated full likelihoods.}
        \label{fig:profiler}
    \end{figure}
%%%
\section{\label{sec:results}Results}

    In this section, we present the results of our analyses of 100 SGWB simulations of PTA data, which we outline below, comparing the performance of the full PTA likelihood to our refit techniques. In each analysis, we model intrinsic red noise as a $10$ frequency power-law in each pulsar in addition to a $10$ frequency power-law common process, unless otherwise specified. We assess the ability of the PTA free-spectrum refit, GFL Lite, and GFL techniques to recover SGWB parameter posteriors that are comparable to the full likelihood, and investigate tolerance factors.

    To quantify the difference between the posteriors recovered by our techniques compared to the full likelihood, we use the \textit{Hellinger distance} \citep{hellinger}, a measure of the similarity between two probability distributions. Given probability density functions $f(\vec{x})$ and $g(\vec{x})$ in $n$-dimensional parameter space, the Hellinger distance $H$ is
%%%%%%%%%%
    \begin{align}
        H^2(f, g) &= \frac{1}{2}\int \left(\sqrt{f(\vec{x})}-\sqrt{g(\vec{x})}\right)^2\mathrm{d}^n x \\
        &= 1 - \int\sqrt{f(\vec{x})g(\vec{x})}\mathrm{d}^n x.
    \end{align}
%%%%%%%%%%
    The Hellinger distance is bounded $0 \leq H \leq 1$, where $H=0$ implies that $f$ and $g$ are identical, while $H=1$ implies that $f$ and $g$ do not have any overlap and are completely different distributions. For our refit techniques to be robust and accurate, we seek Hellinger distances to be as low as possible with respect to results from using the full likelihood. We chose the Hellinger distance over other distance measures---such as Jensen-Shannon---as it is bounded and valid for multivariate distributions. We compare Hellinger distances between the 2D posteriors, as well as the 1D marginalised posteriors for each parameter in a power-law spectral model for the common process, $\gamma$ and $\log_{10}A$.
    
    \subsection{\label{sec:sims}Simulations}
    
    Our simulated dataset creation follows \citet{astro4cast}. The pulsar datasets are based on the observational timestamps and TOA uncertainties from the 45 pulsars of the NANOGrav $12.5$~year dataset \citep{Arzoumanian2020-br}. We extended the timespan of the data set by drawing new TOAs and uncertainties from the distributions of the final year of observations from each pulsar to form a $15$~year data set. However, we kept the number of pulsars fixed, rather than adding new ones over time. We injected intrinsic red noise in each pulsar at linearly-spaced frequencies of $1/T$ to $10/T$. The injected spectral characteristics of a pulsar's intrinsic red noise were measured by modeling per-pulsar power-laws alongside a common-process power-law with $\gamma=13/3$ in the NANOGrav 12.5 year data set.
    
    Finally, 100 realizations of a SGWB signal were injected into 100 copies of our simulated PTA dataset. We randomly drew SGWB spectral characteristics from a bank of $234,000$ that had been fit to SMBHB population realizations \citep{rosado} (see also \citep{middleton}). \autoref{fig:middleton} shows the total distribution of SGWB spectral characteristics in blue, and the spectral characteristics injected into our simulations in red. Typical PTA analyses use priors of $\gamma\in[0, 7]$ and $\log_{10}A\in[-18, -12]$. Following this convention, we also ensured that the randomly-drawn SGWB spectral characteristics satisfied these prior constraints.
    
        \begin{figure}
            \centering
            \includegraphics[width=\columnwidth]{figs/rosado_dist.pdf}
            \caption{The blue regions are the 68, 95, and 99\% credible regions of the distribution of SGWB spectral characteristics from the $234,000$ SMBHB population realizations of \citet{rosado}. We randomly selected $100$ SGWB realizations from this distribution (red markers). The dashed black line designates $\gamma=13/3$, the realization-averaged expected SGWB spectral index from a population of SMBHBs.}
            \label{fig:middleton}
        \end{figure}
        
    \subsection{\label{sec:model2a}Parameter Estimation Fidelity}
    
    We choose one of our simulations as a case study. This simulation has similar spectral characteristics comparable to the common process detected in the NANOGrav $12.5$~year data set, and has one of the smallest Hellinger distances between the uncorrelated full-likelihood power-law analysis and PTA free-spectrum refit. Firsly, since each GFL-Lite per-pulsar free spectrum has already been marginalized over intrinsic red noise, the combined product of those likelihood distributions across the array should be consistent with the PTA free spectrum. This is shown in the left panel of \autoref{fig:corner}, where there is broad consistency between the techniques. 
    
    The comparison of power-law--model posterior distributions for our case-study simulation is shown in the right panel of \autoref{fig:corner}, where credible regions correspond to 68\% and 95\% levels for the spatially-uncorrelated full-likelihood, the PTA free-spectrum refit, and the GFL Lite analysis. 
    Both refit methods perform well, recovering posteriors consistent with the production-level full PTA likelihood. We see that the PTA free-spectrum refit more accurately recreates the posterior of the full likelihood than GFL Lite, with 2D Hellinger distances of $0.10$ and $0.20$, respectively. The marginalized posteriors on $\log_{10}A$ and $\gamma$ are also more similar between the PTA free-spectrum refit and full likelihood, with distances of $0.06$ and $0.07$ compared to $0.19$ and $0.17$ for GFL Lite. The \textit{maximum a posteriori} (MAP) values are more offset in both parameters between GFL Lite and the full likelihood than between the PTA free-spectrum refit and the full likelihood. Nevertheless, the posterior from the GFL Lite analysis is still consistent with the full likelihood posterior. Each analysis successfully captures the injected spectral characteristics within their $95\%$ credible regions. We do not show the posterior of the GFL analysis here as it is more offset, more constrained, and less consistent with the full likelihood method than the other refit techniques, with a 2D posterior Hellinger distance $0.40$, and Hellinger distances of $0.29$ and $0.11$ on $\log_{10}A$ and $\gamma$ respectively.
    %%%%%%
    \begin{figure*}
        \centering
        \includegraphics[width=\textwidth]{figs/corner.pdf}
        \caption{\textit{Left panel:} A comparison of the free spectrum of the full PTA likelihood (orange) with a product of the per-pulsar free spectrum from the GFL Lite pipeline (green) on a simulated data set. The two violins are nearly identical and follow the injected SGWB power-law (black line). \textit{Right panel:} Posteriors of a 10 frequency power-law analysis with the full likelihood, PTA free-spectrum refit, and GFL Lite methods, for the simulated dataset shown in the left panel. Credible regions enclose $68\%$ and $95\%$ of the posterior. The injected SGWB spectral characteristics are shown as the dashed black lines, with $\log_{10}A=-14.7$ and $\gamma=4.17$. The PTA free-spectrum refit posterior matches well to the full likelihood. The GFL Lite posterior is less constrained but it is still consistent with the posterior of the other two analyses.}
        \label{fig:corner}
    \end{figure*}
    %%%%%%%%%%

    We see a similar trend when comparing the Hellinger distances of all 100 data set realizations. The distributions of Hellinger distances for the 2D and 1D marginalised posteriors are shown in \autoref{fig:1Dhellinger}, from which we quote the median, $16^\mathrm{th}$ percentile, and $84^\mathrm{th}$ percentile values. As expected, the 2D Hellinger distances between the PTA free-spectrum refit and the full likelihood are the smallest with distance $0.26\substack{0.40 \\ 0.17}$.  GFL Lite performs better than GFL over the 100 realizations, with 2D Hellingers of $0.38\substack{0.54 \\ 0.24}$ and $0.47\substack{0.63 \\ 0.32}$ respectively. Typically, the PTA free-spectrum refit has a Hellinger distance $0.12$ less than GFL Lite, and GFL Lite has a 2D Hellinger distance $0.08$ smaller than for GFL. We conclude that the PTA free-spectrum refit is the most accurate analysis method as its posterior best approximates the full-likelihood analysis given the 2D Hellinger distance between it and the uncorrelated full likelihood. This makes sense because our factorized likelihood approximations enter the analysis at a later stage in the PTA free-spectrum refit case than in GFL/GFL-Lite. However, it lacks the ability to trivially and rapidly refit different combinations of pulsars.

    To better understand the origin of discrepancies between our refit methods and the full likelihood, we investigate the magnitude of inter-frequency correlations in the Bayesian free-spectrum posteriors, using \textit{Pearson's correlation coefficient} \citep{pearson1895vii}. If inter-frequency correlations are weak, the correlation matrix of the posterior samples should be mostly diagonal in structure; Pearson's correlation coefficient quantifies how `diagonal' a correlation matrix is, with a coefficient of $1$ being perfectly diagonal, and $0$ suggesting zero correlations. The median, $16^\mathrm{th}$, and $84^\mathrm{th}$ percentile values of the coefficient across all 100 realizations of the PTA free spectra is $0.92\substack{0.98 \\ 0.86}$, suggesting very weak correlations between frequencies. We also compute the coefficient for all $45$ per-pulsar free spectra from the GFL Lite pipeline across all $100$ simulation realizations, giving $1.0\substack{1.0 \\ 0.99}$; per-pulsar free spectra are strongly independent between frequencies. In fact, out of the $4500$ free spectra, only $42$ had coefficients $<0.92$. This shows that our assumption throughout of independence between frequencies is justified, and suggests that the majority of information being lost from the GFL Lite pipeline (and by extension GFL) is through the compounding of small inaccuracies in our density estimators over many frequencies and pulsars.

    We see from the middle and right panel of \autoref{fig:1Dhellinger} that GFL better recovers the 1D marginalized posteriors of the full likelihood (in particular for $\gamma$) compared to GFL Lite because the distributions of Hellinger distances on $\gamma$ and $\log_{10}A$ are smaller. This appears to be in tension with the results of the Hellinger distance on the 2D posterior. However, the GFL Lite 2D posteriors are broader than the GFL 2D posteriors, resulting in a greater overlap with the full likelihood posterior, and a smaller 2D Hellinger distance. In contrast, while GFL may typically (but not always) recover the marginalized posterior on $\gamma$ better than GFL Lite, the MAP offset on $\log_{10}A$ relative will shift its highest probability region in the 2D posterior away from that of the full likelihood, resulting in a greater Hellinger distance for the 2D posteriors. Thus, the GFL technique requires further optimization to ensure high fidelity relative to the full likelihood, and further study is needed to understand how various noise processes affect the GFL pipeline. We discuss the required developments, as well as present use cases even in the absence of those optimizations, in \autoref{sec:discuss}. For the rest of this paper, we focus on spectral characterization and model selection with the PTA free-spectrum refit and GFL Lite techniques.
    %%%
    \begin{figure*}
        \centering
        \includegraphics[width=\textwidth]{figs/hellinger.pdf}
        \caption{Hellinger distances between the posteriors of the full likelihood and for each refitting technique for all 100 SGWB dataset realizations. Refitting to the PTA free-spectrum tends to have the smallest Hellinger distances, hence it is the most accurate method. Overall, GFL Lite performs better than GFL when comparing 2D posteriors, while GFL's 1D Hellinger distances are slightly smaller overall than for GFL Lite.}
        \label{fig:1Dhellinger}
    \end{figure*}
    
    Finally, test the efficacy of Bayesian recovery between our proposed methods and the full likelihood with $p$--$p$ plots, as shown in \autoref{fig:pp-plot}. If we were to draw our injected spectral characteristics from the same priors as employed in our Bayesian analysis, then we would expect to recover our injections within the $p\%$-credible region for $p\%$ of our simulations. However in our analyses---even with the full likelihood---we see bias, causing deviation from the diagonal $p$--$p$ plot, because we drew our characteristics from the SMBHB populations of \citet{rosado}, and other analysis approximations. Instead, we compare the relative efficacy of our refit methods to the full likelihood analysis by taking the difference in $p$--$p$ recovery between the full likelihood and our refit methods. A perfect comparison would give zero difference for all $p$. The PTA free-spectrum refit has the smallest differences from the full likelihood, showing deviations around zero mostly within a $1\sigma$ confidence interval, where $\sigma=\sqrt{p(1-p)/100}$ is the binomial standard error for a sample of 100 realizations \citep{bilby}. GFL Lite shows more deviations from the full likelihood, which are typically within a $1\sigma$ confidence interval on $\log_{10}A$, and within $3\sigma$ for the spectral index.

    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figs/ppplots.pdf}
        \caption{The difference in $p$--$p$ plots between the full likelihood and the PTA free-spectrum refit or GFL Lite. Equivalent recovery would show zero for all $p\%$ credible regions. The PTA free-spectrum refit is centered close to zero and within the $1\sigma$ confidence region, where grey curves show $1\sigma$, $2\sigma$, $3\sigma$ regions. GFL Lite deviates more for both parameters, and most noticeably for $\gamma$ where there is a tendency to have injected values lie within the tails more often than in the full likelihood recovery.}
        \label{fig:pp-plot}
    \end{figure}

    %%%%%%%%%%
    \begin{figure*}
        \centering
        \includegraphics[width=\textwidth]{figs/per_freq.pdf}
        \caption{The median, 1-$\sigma$, and 2-$\sigma$ posterior credible constraints on $\log_{10}A$, $\gamma$ for a power-law process as a function of the number of modeled frequencies, $N_f$. The blue regions signify the constraints from fitting to the lowest frequency upwards, while the grey signifies fitting from the tenth frequency downwards.  As the number of frequencies increase, the posteriors become more constrained towards the injected parameter values (dashed black lines), with the expected behavior of the blue contours constraining the parameters more quickly than the grey. Qualitatively, GFL Lite (right column) performs similarly to the PTA free-spectrum refit (left column).}
        \label{fig:perfreq}
    \end{figure*}
    %%%%%%%%%%

    \subsection{\label{sec:model_select}Model Selection}
    
    Given the performance improvements of our new refitting methods, we now explore their efficiacy for spectral model selection. The SGWB spectrum is typically modeled as a power-law, but other astrophysical and cosmological phenomena, and potentially even noise contamination, may influence its inferred shape. We would like to test whether these models better fit PTA data than a simple power-law, and make astrophysical and cosmological interpretations from their spectral characteristics.

    Model selection with the current production-level PTA analysis pipeline is very difficult given the relatively slow computation time of the PTA likelihood. We must compare the Bayesian evidence of our data given our hypothesis models, $p(\vec{\delta t}|\mathcal{H})$, to derive a Bayes factor $\mathcal{B}_{12}=p(\vec{\delta t}|\mathcal{H}_1)/p(\vec{\delta t}|\mathcal{H}_2)$, and interpret those values to reject or accept $\mathcal{H}_1$ over $\mathcal{H}_2$. The interpretation is problem-specific, but some rules of thumb are given in \citet{kass1995bayes}. In PTA analysis, model selection is typically conducted via calculating the Savage-Dickey density ratio \citep{dickey1971weighted} for reasonably low-contrast nested models, or by product-space sampling for mildly-disjoint nested models \citep[see, e.g.,][]{carlin1995bayesian,godsill2001relationship,aggarwal2019nanograv}.

    One model selection technique that is currently infeasible for production-level PTA analyses on large arrays ($\gtrsim 30$~pulsars) is nested sampling, for which one analyzes each model separately to compute the Bayesian evidence \citep{skilling2004nested,2021arXiv210109675B}). The algorithm evaluates the likelihood of a set of points within the prior volume. Each iteration selects new points with a likelihood greater than the least likely points in the prior volume to slowly climb up the likelihood surface and integrate the evidence as it goes. Nested sampling is computationally expensive and cannot be realistically computed with the full PTA likelihood given the combination of parameter dimensionality and slow evaluation time. However, our new techniques now make spectral model selection via nested sampling feasible.
    %
    \begin{table}
        \begin{tabular}{c|c|c}
            \hline
            Disfavored model & Favored model & $\mathcal{B}$ \\
            \hline
            \hline
             broken power-law & power-law & $21.1 \pm 6.0$ \\
             turnover & power-law & $1.71 \pm 0.44$ \\
             $t$-process & power-law & $50.7 \pm 11.8$ \\ \hline
        \end{tabular}
        \caption{Bayes factors for different 10-frequency common process models compared to a power-law when refitted to a PTA free-spectrum via the \texttt{Ultranest} nested sampler \citep{ultranest}. As expected, a power-law model is favored over every other tested model.}
        \label{table:table}
    \end{table}

        \autoref{table:table} compares Bayes factors between various spectral models and the injected power-law behavior from the same simulation as \autoref{fig:corner}. We used our PTA free-spectrum refitting technique for these model selection tests. A \textit{broken power-law} has power-law behavior at low frequencies that then transitions into into (in this case) a flat spectrum at higher frequencies in order to account for a white-noise floor in real data. This is used often in production-level analyses as a data-driven way of identifying the optimal number of frequencies with which to model a common red-noise process such that the inference is not biased by white noise \cite{Arzoumanian2020-br}. A \textit{turnover model} is similar in spirit to the broken power-law---in that it is effectively two power-laws connected by a bend---but motivated as a way to model low-frequency SGWB spectral attenuation from a binary population's interactions with their respective galaxy environments \cite{Sampson2015-qj,Arzoumanian_2016}. A \textit{$t$-process} model has an underlying power-law behavior, but with per-frequency deviations that are constrained by an inverse-Gamma prior. This is used to account for spectral fuzziness owing to noise conflation with the common process, or potentially even binary-population finiteness influencing the spectral shape \cite{arzoumanian2020multimessenger}.
        
        Unsurprisingly, the power-law is the most favored model since it is the injected spectrum. However, the power-law is only slightly favored over the turnover model with a Bayes Factor of $1.71$. This is because we allowed the range of turnover frequencies to be in any of the $10$ modeled GW frequency bins. The model favored the lowest frequency bin, which made it behave mostly like a power-law. The broken power-law's bend frequency was also allowed to vary across all frequencies, however it is significantly less favored than the power-law because its spectral index at frequencies greater than the bend frequency is fixed at zero, which the data do not support. Similarly, the injected power-law is so strong that any noise-induced deviations from it are small; hence the $t$-process is also not favored.
    
        Using our spectral refitting techniques, it is now possible to systematically explore the evidence for various realistic SGWB spectra in PTA data. We however emphasize that this is currently only for SGWB or common-process spectral model selection; development to include inter-pulsar correlation information, or to assess evidence for the presence of a common process over only intrinsic per-pulsar noise, will be discussed in \autoref{sec:discuss}.

    \subsection{Evolution of Bayesian spectral constraints with number of GW frequencies and pulsars}

    Given that spectral characterization is now trivial with our refitting techniques, we can use our simulations to efficiently study how the Bayesian inference of spectral characteristics evolves with the number of modeled GW frequencies and pulsars.
    
    \subsubsection{Dependence on number of GW frequencies} \label{subsec:specchar_numfreq}
    
    First, we recover the Bayesian posterior for a power-law common process on simulated data as a function of the number of modeled GW frequencies (\autoref{fig:perfreq}). Typically, we fit a common-process model to the $N_f$ lowest frequencies; this is shown by the blue regions. However, we also may fit a power-law to our highest $N_f$ frequencies, given by the grey contours. This gives us a comparison between the information content of the highest versus lowest frequencies. The SGWB expected from astrophysical or cosmological sources is expected to be red, with more power at lower frequencies. Hence, PTAs are more sensitive to the SGWB at frequencies of $\sim 1/T$ than to higher frequencies, where intrinsic per-pulsar red noise and white noise can dominate \cite{moore2015estimating, hazboun}. Therefore we expect the blue contours to converge toward the injected lines faster than the grey contours; we see this for both the PTA free-spectrum refit and GFL Lite techniques methods, where the posterior spread in recovered parameters decreases significantly after only two frequencies. The grey contours (representing fitting from higher frequencies downwards) are remain wide for a larger number of modeled frequencies. For these, the recovered amplitude only converges on the injection after $4$ frequencies for the free spectrum refit and $6$ frequencies for GFL Lite, while both methods require 8 frequencies to converge on the spectral index $\gamma$. Thus, as expected, PTAs derive most information on SGWB spectral characteristics from the lowest analyzed GW frequencies.

 	\subsubsection{Dependence on number of pulsars}
	
	\begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figs/per_psr.pdf}
        \caption{The median, 1-$\sigma$, and 2-$\sigma$ posterior credible constraints on $\log_{10}A$, $\gamma$ for a power-law process as a function of the number of modeled pulsars, $N_p$. The blue regions signify posterior constraints of a $10$-frequency power-law common process fitted to the $N_p$-pulsars with the longest observing timespan, while the grey regions are the corresponding constraints from the $N_p$ shortest pulsars. The black dashed line denotes the injected SGWB spectral characteristics.}
        \label{fig:perpsr}
    \end{figure}

    Since GFL Lite is a consistent approximation to the PTA free-spectrum refit, we may also analyze the posterior recovery as a function of the number of pulsars $N_p$ in our PTA (\autoref{fig:perpsr}). Given the large number of combinations with with $N_p$ pulsars can be chosen from the array of $45$, we only look at two sets of analyses, where we either add pulsars by decreasing or increasing timespan.

    Similar to \autoref{subsec:specchar_numfreq}, pulsars with longer observational timespans are more informative of lower GW frequencies, where the signal is expected to be strongest. Therefore, we expect and observe that the blue contours converge on the injected parameter values (black dashed lines) faster than the grey contours, requiring $\sim8$ long-timespan pulsars before the median and posterior credible regions of the recovered spectral characteristics become constant. By contrast, $\sim 32$ short-timespan pulsars are required to recover the same precision as the 8 longest pulsars. 
    
    \subsubsection{Characterization through the effective number of pulsars}

    From these analyses, it is clear that not all pulsars and frequencies contribute equally toward spectral characterization. Using the GFL Lite free spectrum of each pulsar, we can calculate the \textit{effective number of pulsars} $N_\mathrm{eff}$ in an $N_p$-pulsar PTA searching for an $N_f$-frequency power-law SGWB spectrum. We used a modified form of Eq.\ (8) in \citet{Cornish2015-ly} where we account for the uncertainty on the free spectrum measurements.
    %%%%%
    \begin{equation} \label{eq:neff}
        N_\mathrm{eff} = \frac{\sum_{p=1}^{N_p}\sum_{k=1}^{N_f} 1/\sigma_\mathrm{G}(\log_{10}\rho_{p,k})^2}{\mathrm{max}_{1\leq p\leq N_p}\sum_{k=1}^{N_f} 1/\sigma_\mathrm{G}(\log_{10}\rho_{p,k})^{2}}
    \end{equation}
    %%%%%%
    where $\sigma_\mathrm{G}$ is a rank-based estimate of the standard deviation to account for distribution non-Gaussianity, $\sigma_\mathrm{G}\approx0.7413\times\mathrm{IQR}$, and $\mathrm{IQR}$ is the interquartile range. The free spectrum posteriors $\log_{10}\rho_{p,k}$ come from the $p$-th pulsar and $k$-th frequency of the GFL Lite free spectrum pipeline. The normalization ensures that $N_\mathrm{eff}\geq1$ for all $N_p$ and $N_f$, therefore $N_\mathrm{eff}$ is the effective number of pulsars relative to the most constrained (and therefore most informative) pulsar for spectral characterization in the array. For a PTA with heterogeneous uncertainties, $N_\mathrm{eff}<N_p$.

    \autoref{fig:sigma} shows the relationship between the power-law parameter uncertainties as a function of $N_\mathrm{eff}$. We fitted a 10-frequency, $N_p$-pulsar powerlaw with the GFL Lite pipeline, adding pulsars in order of the greatest to smallest value of $\sum_k^{N_f} 1/ \sigma_\mathrm{G}(\log_{10}\rho_{p,k})^{2}$. We computed the marginalized posterior uncertainty on both power-law parameters using the rank-based standard deviation estimate $\sigma_\mathrm{G}$. We see here that increasing the number of real pulsars increases the effective number of pulsars in the PTA, and decreases $\sigma_\mathrm{G}$ for both parameters. These studies allow us to posit a general relationship for spectral constraints in Bayesian PTA analyses, where $\sigma_\mathrm{G}\propto 1/\sqrt{N_\mathrm{eff}}$, as one may expect for a standard-deviation-type quantity computed from a data sample.

    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figs/neff.pdf}
        \caption{The relationship between the effective number of pulsars in a PTA, $N_\mathrm{eff}$, and the uncertainty on the spectral parameters (see text for a definition of $\sigma_\mathrm{G}$). We increase $N_p$ and keep the number of GW frequencies as $10$. Fewer than $7$ pulsars gave large values for $\sigma_\mathrm{G}$ since not many pulsars are informing the posterior recovery. The recovered parameter uncertainties scale approximately as the expected $1/\sqrt{N_\mathrm{eff}}$ for both $\log_{10}A$ and $\gamma$ after 10 pulsars ($N_\mathrm{eff}\sim3.5$) are included in the array.  We use the single pulsar free spectra from GFL Lite for calculating $N_\mathrm{eff}$.}
        \label{fig:sigma}
    \end{figure}
    

    \subsection{Recreating the results of the NANOGrav $12.5$-year data set} \label{sec:realdata}
    
    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figs/12p5corner.pdf}
        \caption{Fitting a $5$-frequency power-law to the NANOGrav $12.5$-year data set via the PTA free-spectrum refit technique (blue) and GFL Lite analysis (green). We compare our analyses to the published posterior (red). We find excellent agreement between the published result and both techniques, where the PTA free-spectrum refit attains a Hellinger distance of $H=0.10$, while GFL Lite attains $H=0.33$.}
        \label{fig:12p5}
    \end{figure}

    We now apply our refitting techniques to the NANOGrav $12.5$-year dataset to assess performance against published results. Analysis of the NANOGrav $12.5$-year data set did not find significant evidence for Hellings \& Downs inter-pulsar correlations, however there was strong evidence for a spatially-uncorrelated common process across the array of pulsars. The  posterior probability density for an analysis with a $5$-frequency power-law common process (and $30$-frequency power-law per-pulsar intrinsic red noise) is shown in \autoref{fig:12p5}, along with a PTA free-spectrum refit and GFL Lite analysis on this data set. We use the published posterior chains for the $5$-frequency common process \citep{Arzoumanian2020-br}, however we re-ran the PTA free-spectrum analysis to ensure adequate sampling for accurate KDE reconstruction. As expected, the PTA free-spectrum refit is more accurate than GFL Lite, recovering the posterior on the published uncorrelated power-law parameters with a Hellinger distance of $0.10$, while GFL Lite gave a Hellinger distance of $0.33$.

    \autoref{table:table12p5} shows the results of model selection via nested sampling for various 5-frequency spectral models. We see that a varied-$\gamma$ power-law is barely favoured over a $\gamma=13/3$ power-law, and $\gamma=13/3$ is not ruled out by these data. There is a little more evidence to favour a power-law over broken power-law, turnover, and $t$-process spectra, however none of these are substantial.
%%%%%%%%%%
    \begin{table}
       \begin{tabular}{c|c|c}
            \hline
            Disfavored model & Favored model & $\mathcal{B}$ \\
            \hline
            \hline
             $\gamma\!=\!13/3$ power-law & power-law & $1.17\pm0.40$\\
             broken power-law & power-law & $1.82\pm0.34$\\
             turnover & power-law & $2.23\pm0.57$\\
             $t$-process & power-law & $1.83\pm0.57$\\ \hline
        \end{tabular}
        \caption{Bayes factors $\mathcal{B}$ for different 5-frequency common-process spectral models compared to a power-law, when refitted to a PTA free spectrum for the NANOGrav $12.5$-year data set. The power-law has varied spectral index $\gamma$ unless stated.}
        \label{table:table12p5}
    \end{table}
    
    \begin{figure*}
        \centering
        \includegraphics[width=\textwidth]{figs/per_freq_12p5.pdf}
        \caption{\textit{Left:} The median, 1-$\sigma$, and 2-$\sigma$ posterior credible constraints on $\log_{10}A$, $\gamma$ for an $N_f$-frequency power-law as a function of number of GW frequencies in the NANOGrav $12.5$-year data set. In blue, we show increasing number of frequencies from the lowest bin and increase upwards to $f=30/T$. In grey, we show addition of frequencies from $f=30/T$ downwards. We observe a similar shallowing of the spectrum as \citet{Arzoumanian2020-br} when a larger number of frequencies are modeled because of the contribution of white noise. \textit{Right:} A 5-frequency power-law is fit to an increasing number of pulsars in the NANOGrav $12.5$-year data set, where blue regions show constraints from adding pulsars in long- to short-timespan order. The blue posteriors are well constrained after $\sim10$ pulsars, while the grey posterior require $\sim36$ pulsars out of 45 to be constrained. Hence, the longest 10 pulsars are the most important for spectral characterization in this data set.}
        \label{fig:perfreq_12.5}
    \end{figure*}

    We also characterize the spectral recovery as a function of the number of modeled GW frequencies and pulsars. The PTA free-spectrum refit to increasing numbers of low GW frequencies (blue) in the left panel of \autoref{fig:perfreq_12.5} shows a similar ``shallowing'' of the spectrum as seen in \citet{Arzoumanian2020-br}, where $\gamma$ trends toward $\sim2-3$, potentially due to coupling with unmodeled excess higher frequency noise. Meanwhile, increasing the number of frequencies from $f=30/T$ downwards tends to have a broad, unconstrained posterior for all frequencies consistent with low $\gamma$ i.e. a flatter power spectrum typefied by white noise. GFL Lite (not shown) is consistent with the PTA free-spectrum refit up to $15$ frequencies, but  deviates after that. While the posterior constraints overlap, it appears that GFL Lite did not sufficiently sample the tails of the per-pulsar free spectra to ensure enough support for a shallower common-process power-law at higher numbers of frequencies. We discuss optimizations to ensure sufficient tail sampling in \autoref{sec:discuss}. In the right panel, we use GFL Lite to fit a $5$-frequency power-law to an increasing number of pulsars, expanding by decreasing-timespan (blue) and increasing-timespan (grey) pulsars. As with \autoref{fig:perpsr}, the blue posterior is constrained after relatively few pulsars are added ($\sim 10$),\footnote{The ten pulsars are J1744-1134, J1455-3330, J1012+5307, B1937+21, J2145-0750, J1909-3744, J1918-0642, J1643-1224, J2317+1439, B1855+09, and J1713+0747} while the grey posterior is unconstrained, particularly for $\gamma$, until the final 10 pulsars are added. 

    Finally, we also analyze $\sigma_\mathrm{G}$ for $\{\log_{10}A, \gamma\}$ as a function of the effective number of pulsars $N_\mathrm{eff}$. \autoref{fig:perfreqpsr12.5} shows $\sigma_\mathrm{G}$ of parameters for a $5$-frequency power-law model as a function of $N_\mathrm{eff}$ as we increase the number of pulsars in the array in order of greatest to smallest value of $\sum_k^{N_f} 1/ \sigma_\mathrm{G}(\log_{10}\rho_{p,k})^{2}$. Again, we observe an approximate $1/\sqrt{N_\mathrm{eff}}$ scaling relationship after $\sim10$ pulsars ($N_\mathrm{eff}\sim1.5$). We also notice that the real data set has fewer numbers of effective pulsars than the simulated data set. This is because the simulation contains less excess noise with respect to the real data set, and the SGWB signal is stronger than the excess white noise for fewer frequencies than the simulation.
    %
    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figs/neff_125.pdf}
        \caption{Similar to \autoref{fig:sigma}, using the NANOGrav 12.5 year data set. We fit a 5-frequency power-law to an increasing number of pulsars in the array. At least 10 pulsars ($N_\mathrm{eff}\sim1.6$) are required before the recovered parameter uncertainties scales as $1/\sqrt{N_\mathrm{eff}}$. We use the single pulsar free spectra from GFL Lite for calculating $N_\mathrm{eff}$.}
        \label{fig:perfreqpsr12.5}
    \end{figure}


\section{\label{sec:discuss}Conclusions \& Future Prospects}

    In this paper, we have developed a set of rapid and robust refitting techniques that operate on posterior samples from pulsar and PTA Bayesian periodogram analyses, where the power spectral density is jointly modeled by free parameters at each GW frequency (sometimes referred to in the PTA literature as \textit{free spectrum} analyses). This is a generalization of our previously-developed \textit{Factorized Likelihood} (FL) technique \citep{Taylor2022-nq}, where GW background amplitude posteriors for fixed power-law spectral index models are combined in post-processing, under the assumption that spectral characterization is mostly driven by autocorrelation information in the PTA covariance matrix. The main limitation of FL was its conditioning on a GW-background spectral model with a fixed power-law spectral index. Our new formulations---which we label under the broad term \textit{Generalized Factorized Likelihood} (GFL)--loosen that assumption, allowing for refitting and inference of arbitrary spectral models.
    
    In order of generality, we assessed the performance of: a model that refits on a Bayesian PTA free spectrum (\textit{PTA free-spectrum refit}); one that refits on the combination of per-pulsar free spectra, which act as proxies for the common process in each pulsar, with intrinsic per-pulsar red noise modeled separately (\textit{GFL Lite}); and finally, one that refits on the combination of per-pulsar free spectra, which act as agnostic measures of all low-frequency processes in a given pulsar dataset, and where the common process and intrinsic per-pulsar red noise are modeled jointly in the refitting stage (\textit{GFL}). These techniques are several orders of magnitude faster in evaluating their likelihood functions when compared to the production-level PTA pipeline, and also scale much more favorably when adding new pulsars. These gains in speed and scalability will be important in safeguarding PTA analyses from future bottlenecks, as significantly more data and pulsars are added to arrays through IPTA combinations and high-cadence observations in MeerTime \citep{bailes2018meertime}, CHIME \citep{chime}, and (farther in the future) the SKA \citep{ska}.
    
    We assessed the fidelity of parameter estimation using a set of $100$ realistic PTA datasets based on the NANOGrav $12.5$-year dataset that is extended into the future, and into which realizations of a GW background are injected with power-law spectral characteristics based on supermassive black-hole binary population models. Through Hellinger-distance comparisons---which assess the distance between probability distributions---we found that the \textit{PTA free-spectrum refit} is the most reliable emulator of the full production-level PTA likelihood analysis. If available, this technique is favored, and can even be used to refit on PTA free-spectral posteriors that have an assumed inter-pulsar correlation signature. For example, in the case study presented in \autoref{fig:corner}, the Hellinger distance (closer to zero is better) of the PTA free-spectrum refit was $0.06$ when refitting on the HD-correlated free spectrum, compared to $0.10$ from the uncorrelated free-spectrum. Additionally, we showed that the PTA free-spectrum refit technique allows us to conduct spectral-model selection via nested sampling, a capability previously too cumbersome to apply to the full likelihood model. 

    \textit{GFL Lite} follows next in the accuracy of its spectral characterization when compared to the production-level PTA pipeline. It generally recovers a posterior that is broader but consistent with the uncorrelated power-law model analysis. This method is of particular use in studying how different subsets of frequencies and pulsars---e.g., long-baseline pulsars versus short-baseline pulsars---affect spectral characterization of a common process like the GW background. Finally, \textit{GFL} is the most general technique, and has the advantage of allowing trivial changes to the spectral models and priors of the intrinsic red noise in each pulsar. However, it currently has the lowest accuracy, and must be used with appropriate caution. When refined further, this method will enable quick GW-background analyses in the presence of advanced per-pulsar red-noise models that are customized to each pulsar, which is currently not tractable with the production-level PTA pipeline.

    We plan to continue optimizing the \textit{GFL} technique. We suspect that the main loss of information and fidelity at the moment is through the sampling and representation of the distribution tails of the per-pulsar free-spectral posteriors. A potential solution to this is to use Gibbs techniques and to draw directly from the analytic conditional posteriors of our free-spectral parameters, which has been shown to have better tail sampling \citep{geman1984stochastic}. For improving the representation of the posterior densities, we will explore alternatives to the Epanechnikov KDE kernel function used here that have more gradual drop-offs in support. If information is being lost in our density estimators, then we will assess the performance of multivariate KDEs across frequencies, or other higher-dimensional density estimation techniques based on neural network architectures, such as normalizing flows \citep{rezende2015variational}. Another avenue is based on likelihood reweighting techniques, where an approximate distribution that is easier to sample is used to generate many random draws, then a subsequent reweighting stage updates these samples based on their support under the correct (potentially computationally-expensive) distribution \citep[see, e.g.,][for a recent PTA application]{Hourihane_Meyers_Johnson_Chatziioannou_Vallisneri_2022}. Given the speed with which GFL refit analyses can be conducted, allowing many samples to be collected, we could subsequently reweight these samples to match the full PTA likelihood. While this procedure will add extra computation time, it would still be quite a bit faster than a full pipeline analysis.

    We also envision that future development of PTA refitting techniques will include inter-pulsar correlations, which would be the zenith of stochastic GW-background modeling through compressed sufficient statistics. While our current techniques are based on power-spectrum modeling, we would need to recover the Fourier coefficients  of the timing residuals in order to retain phase information among the pulsars. We would then need to accurately represent the likelihood distribution of these Fourier coefficients, using density estimation techniques, to act as sufficient statistics for inter-pulsar correlation studies. There is ongoing development along these lines to replace the current production-level PTA pipeline, and ensure that future Bayesian PTA analyses with significantly larger datasets will continue to be tractable.

    The new techniques presented in this paper will have several immediate benefits for astrophysical- and cosmological-model testing with PTA data. The demographics and dynamics of supermassive black-hole binary populations is encoded in the amplitude and shape of the GW characteristic strain spectrum in the PTA band. Our techniques offer a path to use intermediate data products (i.e., Bayesian free-spectrum posteriors) for rapid spectral parameter estimation and model selection. Likewise, several potential sources of early-Universe GW-background signals give rise to strain spectra that deviate from the expected form of the supermassive black-hole binary population signal, e.g., a phase transition may produce a more peaked spectrum than the power-law expected from binaries. While cosmological backgrounds are unlikely to be the dominant signal in the PTA band, they could contribute at a lower level. We plan to use our fast and flexible techniques to study milestones for PTA spectral estimation, such as what can be inferred in the near future about supermassive black-hole binary populations, and the conditions under which cosmological background signals could be inferred beneath a dominant astrophysical signal. Answering these questions, and developing the spectral-estimation techniques with which they are addressed, are key to illuminating the path for PTA science in the next decade.

%%%%%%%%%%
    \subsection{\label{sec:software}Software}
        The introduced refit methods are featured in a new analysis suite called \href{https://github.com/astrolamb/ceffyl}{\texttt{ceffyl}} for quick model selection and parameter estimation of spectra given PTA data. This is achieved by creating condensed data products representing the Bayesian spectra of a PTA's timing residuals. The data are represented by highly optimised KDEs from which we can extract probabilities to form Bayesian likelihoods to estimate our PTA likelihoods and to rapidly recover posteriors to our models. The suite employs code from \texttt{enterprise} \citep{enterprise}, which was also used to create our free spectra and the full likelihood posteriors to which our analyses were compared. We conducted parameter estimation via MCMC with \texttt{PTMCMC} \citep{justin_ellis_2017_1037579}, which utilises parallel tempering and empirical proposal distributions for more efficient sampling of the parameter space, while the nested sampler \texttt{UltraNest} \citep{ultranest} is used for model selection. To calculate the relevant KDE bandwidths, we translated the Sheather-Jones algorithm from an R implementation \citep{R} into Python; this code is now contained within the \texttt{ceffyl} suite. The KDEs are created using the \texttt{FFTKDE} method in \texttt{KDEpy} \citep{tommy}, and we use \texttt{ChainConsumer} \citep{Hinton2016} to create our corner plots to compare posteriors. The suite of PTA simulations were created with \texttt{libstempo} \citep{2020ascl.soft02017V}.

\section{Acknowledgements}
We thank our colleagues in NANOGrav and the International Pulsar Timing Array for fruitful discussions and feedback during the development of this technique. We particularly thank Alberto Sesana for providing the distributions of power-law fit parameters to characteristic strain spectra from SMBHB population realizations, based on \citet{rosado}; Kyle Gersbach for conversations on using the Pearson correlation coefficient; Xavier Siemens, Michele Vallisneri, and Joe Romano for stimulating discussions. SRT acknowledges support from NSF AST-2007993, the NANOGrav NSF Physics Frontier Center \#2020265, and an NSF CAREER \#2146016.  WGL is supported by the NANOGrav NSF Physics Frontier Center \#2020265, and acknowledges travel support from the Divison of Gravitational Physics (DGRAV) to present this work at the APS April 2022 meeting, and from Vanderbilt University's Graduate Student Council. This work was conducted in part using the resources of the Advanced Computing Center for Research and Education (ACCRE) at Vanderbilt University, Nashville, TN. This work was performed in part at Aspen Center for Physics, which is supported by National Science Foundation grant PHY-2210452.

\bibliography{apssamp}
%%%%%%%%%%
\appendix
\section{Kernel Density Estimators}\label{appendix:kde}
%%%%%%%%%%
    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figs/gauss_kde_hist_points.pdf}
        \caption{A demonstration on the importance of good sampling to construct an accurate KDE. We randomly drew 100, 1000, and 10000 points from a Rayleigh distribution $f(x)$, and created the KDE $\hat{f}(x)$ with the Epanechnikov kernel \citep{epanechnikov} and a bandwidth selected by the Sheather-Jones method \citep{sj}. The bottom panel shows the absolute difference between the actual distribution and its reconstruction.}
        \label{fig:gauss_toy}
    \end{figure}
    %%%%%%%%%%
Selecting the optimal kernel $K$ and bandwidth $h$ typically focuses on minimizing the asymptotic mean integrable squared error (AMISE) between the underlying distribution $f$ and the reconstructed estimator $\hat{f}$ given $N$ samples.
    %%%%%%%%%%
    \begin{equation} \label{eq:AMISE}
        \mathrm{AMISE}(h) = \frac{R(K)}{Nh} + \frac{1}{4}\sigma_K h^4 R(f'').
    \end{equation}
    %%%%%%%%%%
    Here, $R(g)=\int g(x)^2\mathrm{d}x$ for any function $g$, and $\sigma_K^2=\int x^2 K(x)\mathrm{d}x > 0$ is the second moment of the kernel, at a given point $x$. The second derivitive $f''$ is with respect to $x$. Note that if the kernel is normal with standard deviation $\sigma$, $\sigma_K^2=\sigma^2$.
    
    The optimal bandwidth $h^*$ is found by minimizing \autoref{eq:AMISE} with respect to $h$ such that
    %%%%%%%%%%
    \begin{equation} \label{eq:dAMISEdh}
        h^* = \left(\frac{R(K)}{\sigma_K^4 R(f'')}\right)^\frac{1}{5} N^{-\frac{1}{5}}.
    \end{equation}
    %%%%%%%%%%
    If the kernel is normal with standard deviation $\sigma_K=1$, and the underlying distribution $f$ is known to be normal with standard deviation $\sigma$, bandwidth selection is trivial: $h^*=1.06\,\hat{\sigma}\,N^{-1/5}$, where $\hat{\sigma}$ is the standard deviation of the samples.

    However, $f$ is not always known and a method is required to reduce the AMISE without prior knowledge of $f$. One such method is the Sheather-Jones plug-in selector \citep{sj}. It computes the optimal bandwidth $h^*$ by estimating $R(f'')$ and iteratively solving \autoref{eq:dAMISEdh} with the Newton-Raphson method. This is a fast and effective bandwidth selector which we use in our KDE reconstructions.
    
    After the optimal bandwidth is selected, substituting \autoref{eq:dAMISEdh} into \autoref{eq:AMISE} finds the following relation between the AMISE and the kernel:
    %%%%%%%%%%
    \begin{equation} \label{eq:kAMISE}
        \mathrm{AMISE}(h^*) \propto \left[\sigma_K R(K)\right]^\frac{4}{5}.
    \end{equation}
    %%%%%%%%%%
    The optimal kernel is the kernel which minimizes this relation. This is the Epanechnikov kernel \citep{epanechnikov} which has the form
    %%%%%%%%%%
    \begin{equation} \label{eq:epanechnikov}
        K(x) = \frac{3}{4}(1-x^2), \ x \in [-1, 1].
    \end{equation}
    %%%%%%%%%%
    We expect to collect samples at the lower boundary of the free spectrum prior. To ensure accurate KDE representation of the samples at the boundary, we mirror the data at the boundary point and fit the KDE to the mirrored data. This reduces the bias induced at the boundary. We then compute probability densities along a fine grid of $\log_{10}\rho$ within the prior space. 

    \autoref{fig:gauss_toy} shows a toy model of using KDEs to recreate a distribution. We randomly drew 100, 1000, and 10000 points from a Rayleigh distribution, $f(x)=x\exp{\left(-x^2/2\right)}$, and recreate the distribution from those random samples using a KDE with the aforementioned optimizations. The reconstruction improves as the number of random draws in the training sample increases. Constructing a KDE with 10000 random samples from the distribution more accurately estimates the original distribution than using less number of samples. Therefore, the more data points we draw from the original distribution, the smaller the absolute difference between the distribution and its reconstruction.

\end{document}
%
% ****** End of file apssamp.tex ******
