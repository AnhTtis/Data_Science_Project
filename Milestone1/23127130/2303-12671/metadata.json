{
    "arxiv_id": "2303.12671",
    "paper_title": "Integrating Image Features with Convolutional Sequence-to-sequence Network for Multilingual Visual Question Answering",
    "authors": [
        "Triet Minh Thai",
        "Son T. Luu"
    ],
    "submission_date": "2023-03-22",
    "revised_dates": [
        "2023-03-23"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.CL"
    ],
    "abstract": "Visual Question Answering (VQA) is a task that requires computers to give correct answers for the input questions based on the images. This task can be solved by humans with ease but is a challenge for computers. The VLSP2022-EVJVQA shared task carries the Visual Question Answering task in the multilingual domain on a newly released dataset: UIT-EVJVQA, in which the questions and answers are written in three different languages: English, Vietnamese and Japanese. We approached the challenge as a sequence-to-sequence learning task, in which we integrated hints from pre-trained state-of-the-art VQA models and image features with Convolutional Sequence-to-Sequence network to generate the desired answers. Our results obtained up to 0.3442 by F1 score on the public test set, 0.4210 on the private test set, and placed 3rd in the competition.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12671v1"
    ],
    "publication_venue": "VLSP2022-EVJVQA"
}