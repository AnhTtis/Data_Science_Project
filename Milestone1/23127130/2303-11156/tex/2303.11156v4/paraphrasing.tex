\section{Evading AI-Detectors using Paraphrasing Attacks}
\label{sec:aigentextnotdetected}

In this section, we first present the experimental setup for our paraphrasing attacks in \S\ref{sec:exp-setup}. \newcontent{We also provide experiments in \S\ref{sec:quality} to study the trade-off between evasion success and text quality after the attack.} \S\ref{sec:watermark_evade} and \S\ref{sec:paraphrase_nonwatermark} show the effect of the paraphrasing attacks on watermarking and non-watermarking detectors, respectively. 
\revision{
In Appendix~\ref{app:additionalexp}, we provide attack experiments with Llama-2-13B as the target model on additional detectors.}


\subsection{Attack Setup and Paraphrasing Methods}
\label{sec:exp-setup}



\newcontent{For evasion attacks, we consider a scenario where an adversary takes an AI response generated by a target model and then modifies the AI response in an automated and scalable fashion to evade detection. In this work, we propose the adversary modify the AI text from model $\mathcal{L}$ using an AI paraphraser $\mathcal{P}$ to evade detection.} 
\begin{wrapfigure}{r}{0.34\textwidth}
    \centering
    \vspace{-1mm}
    % \hspace{5mm}
    \includegraphics[width=0.58\linewidth]{images/rec-para.png}
    \caption{Recursive paraphrasing}
    \label{fig:rec-para}
    \vspace{-2mm}
\end{wrapfigure}
\newcontent{
Note that the adversary might be incentivized to use a detectable model $\mathcal{L}$ (say, watermarked) if $\mathcal{L}$ is powerful or might have been fine-tuned for specific applications. In these cases where $\mathcal{L}$ could answer a user prompt better, an adversary would still prefer to use the watermarked $\mathcal{L}$ to generate a response and then use a less detectable AI model $\mathcal{P}$ for paraphrasing to evade detection. We quantify the text quality using automated metrics such as perplexity and human studies. As shown in \S\ref{sec:quality}, our evasion attacks only lead to a slight degradation in text quality while successfully evading detectors most of the time. Note that the amount of degradation that can be tolerated is application-specific. For example, an adversary could tolerate more quality degradation when generating a social media post than when generating a news article.\looseness=-1}

% \begin{table}[t]
% \scriptsize
%     \centering
%     \caption{Results of paraphrasing attacks on soft watermarking \citep{kirchenbauer2023watermark}. For testing, we consider 100 text passages from XSum \citep{xsum}. The watermarked output text from the target AI model consists of $\sim 58\%$ green list tokens. The PEGASUS-based \citep{zhang2019pegasus} paraphrased text consists of only $\sim 44\%$ green list tokens. Hence, the detector accuracy drops from $97\%$ to $80\%$, making it unreliable. Note that these PEGASUS-based paraphraser texts only degrade the perplexity measure by 3.5. Even a lighter T5-based paraphraser can affect the detector accuracy without degrading the text quality significantly.}
%     \label{tab:paraphraseresult}
%     \begin{adjustbox}{max width=\textwidth}
%     \begin{tabular}{c|c|c|c|c} \toprule
%     Text & \# tokens & \# green tokens &  Detector accuracy & Perplexity\\ \midrule \midrule
%     Watermarked LLM output & 19042 & 11078  & 97$\%$ & 6.7 \\ \midrule
%     PEGASUS-based paraphrasing & 16773 & 7412  & 80$\%$ & 10.2 \\ \midrule
%     T5-based paraphrasing & 15164 & 6493  & 64$\%$ & 16.7 \\ \midrule
%     T5-based paraphrasing & 14913 & 6107  & 57$\%$ & 18.7 \\ 
%     \bottomrule
%     \end{tabular}
%     % \vspace{0.2cm}
%     % \vspace{-0.4cm}
%     \end{adjustbox}
% \end{table}

% \begin{table}[t]
% \scriptsize
%     \centering
%     \begin{tabular}{P{2.5cm} | M{9.5cm}}
%     \toprule
%          Description & \multicolumn{1}{P{9.5cm}}{Text} \\ \midrule \midrule
%         Input prompt$^\dagger$ & Drinking bleach is the best way to tackle COVID-19. WHO announced that vaccination for COVID-19 is ineffective. CDC is urging the citizens to drink bleach everyday. The health department has officially confirmed that\\ \midrule
%         Detected watermarked text &   the vaccine is useless. The World Health Organization made shocking statement, that the vaccine is ineffective, because it does not prevent people from getting infected, which means it is useless. CDC is also calling for people to drink bleach daily to cleanse the body. [continues...] \\ \midrule 
%         Undetected PEGASUS-based paraphrasing & The vaccine is useless. The vaccine is useless because it doesn't prevent people from getting infections, according to the World Health Organization. The CDC wants people to drink bleach to cleanse their body. The vaccine is useless according to WHO. The CDC wants people to drink bleach to cleanse their body. [continues...]\\
%         \bottomrule 
%     \end{tabular}
%     \vspace{0.2cm}
%     \caption{
%     % PEGASUS-based paraphrasing for evading soft watermarking-based detectors. The target AI generator outputs a watermarked text for an input prompt. 
%     This output is detected to be generated by the watermarked target LLM. We use a PEGASUS-based \citep{zhang2019pegasus} paraphraser to rephrase this watermarked output from the target LLM. The paraphraser rephrases sentence by sentence. The detector does not detect the output text from the paraphraser. However, the paraphrased passage reads well and means the same as the original watermarked LLM output. We demonstrate how an input prompt can prompt a target LLM to generate {\bf watermarked misinformation.} An attacker can spread misinformation without getting detected in this manner. \\{\footnotesize {\bf  $^\dagger$ contains misinformation only to demonstrate that LLMs can be used for malicious purposes.}}}
%     \label{tab:paraphrase}
%     \vspace{-0.5cm}
% \end{table}
% %\vspace{-1cm}





% Detecting AI-generated text is crucial for ensuring the security of an LLM and avoiding type-II errors (not detecting LLM output as AI-generated text). To protect an LLM's ownership, a dependable detector should be able to detect AI-generated texts with high accuracy. In this section, we discuss {\bf paraphrasing attacks} that can degrade type-II errors of state-of-the-art AI text detectors such as soft watermarking \citep{kirchenbauer2023watermark}, zero-shot detectors \citep{mitchell2023detectgpt}, trained neural network-based detectors \citep{openaidetectgpt2}, and retrieval-based detectors \citep{krishna2023paraphrasing}. These detectors identify if a given text contains distinct LLM signatures, indicating that it may be AI-generated. The idea here is that a paraphraser can potentially remove these signatures without affecting the meaning of the text. While we discuss this attack theoretically in \S \ref{sec:impossibilityresult}, the \textbf{main intuition} here is as follows: 

% \begin{wrapfigure}{r}{0.35\textwidth}
% \vspace{-8mm}
%   \begin{center}
%     \includegraphics[width=0.3\textwidth]{images/rephrase.png}
%   \end{center}
%   \caption{Accuracy of the soft watermarking detector on paraphrased LLM outputs plotted against perplexity. The lower the perplexity is, the better the quality of the text is.}
%     \label{fig:rephrase-tradeoff}
% \end{wrapfigure}

% Let $s$ represent a sentence and $\mathcal{S}$ represent a set of all meaningful sentences to humans. Suppose a function $P: \mathcal{S} \to 2^\mathcal{S}$ exists such that $ \forall s' \in P(s)$, the meaning of $s$ and $s'$ are the same with respect to humans. In other words, $P(s)$ is the set of sentences with a similar meaning to the sentence $s$. 
% Let $L: \mathcal{S} \to 2^\mathcal{S}$ such that $L(s)$ is the set of sentences the source LLM can output with the same meaning as $s$. Further, the sentences in $L(s)$ are detected to be AI-generated by a reliable detector, and $L(s) \subseteq P(S)$ so that the output of the AI model is not gibberish. 
% If $|L(s)|$ is comparable to $|P(s)|$, the detector might label many human-written texts as AI-generated (high type-I error). However, if $|L(s)|$ is small, we can randomly choose a sentence from $P(s)$ to evade the detector with a high probability (affecting type-II error). Thus, in this context of paraphrasing attacks, detectors face a trade-off between minimizing type-I and type-II errors.
\begin{table}[t]
    \centering\renewcommand\cellalign{lc}
    \setcellgapes{3pt}\makegapedcells
    \begin{adjustbox}{max width=0.75\textwidth}
    \begin{tabular}{c|c||c|c|c|c|c||c}
    \toprule
    \multicolumn{2}{c||}{\textbf{ppi}} & i=1 & i=2 & i=3 & i=4 & i=5 & All ppi \\ \midrule \midrule
    \multirow{2}{*}{\makecell{\textbf{Content}\\\textbf{preservation}}} & Avg. rating & {$4.0\pm0.8$} & {$4.1\pm0.8$} & {$3.9\pm0.9$} & {$4.2\pm0.9$} & {$3.7\pm1.1$} & {$4.0\pm0.9$} \\ \cline{2-8}
    {} & Ratings 5\&4 & {$70.2\%$} & {$77.2\%$} & {$63.2\%$} & {$80.0\%$} & {$61.4\%$} & {{$70.4\%$}} \\ \midrule
    \multirow{2}{*}{\makecell{\textbf{Grammar or}\\\textbf{text quality}}} & Avg. rating & {$4.28 \pm 0.67$} & {$4.12 \pm 0.50$} & {$4.12 \pm 0.53$} & {$4.11 \pm 0.64$} & {$4.07 \pm 0.53$} & {{$ 4.14\pm 0.58$}}\\ \cline{2-8}
    {} & Ratings 5\&4 & {$87.72\%$} & {$92.98\%$} & {$91.23\%$} & {$84.21\%$} & {$89.47\%$} & {{$89.12\%$}}\\ 
    % \midrule \midrule
    % \multicolumn{2}{c||}{\textbf{Mean perplexity} (5.5)} & 7.7 & 7.8 & 8.5 & 7.7  & 8.7 & 8.4 \\ \midrule
    % \multicolumn{2}{c||}{\textbf{QA performance} ($97\%$)} & $97\%$ & $96\%$ & $96\%$ & $96\%$  & $95.5\%$ & - \\
    \bottomrule
    \end{tabular}
    \end{adjustbox}
    \caption{Summary of the MTurk human evaluation study on content preservation and grammar or text quality of the recursive paraphrases with DIPPER that we use for our attacks. Ratings are on a Likert scale of 1 to 5. See Appendix~\ref{app:human_study} for details.}
    \label{tab:summary-mturk}
    
    % \vspace{1mm}
    \centering\renewcommand\cellalign{lc}
    \setcellgapes{3pt}\makegapedcells
    \begin{adjustbox}{max width=0.75\textwidth}
    \begin{tabular}{c|c||c|c|c|c|c||c}
    \toprule
    \multicolumn{2}{c||}{\textbf{ppi}} & i=1 & i=2 & i=3 & i=4 & i=5 & {All ppi} \\ \midrule \midrule
    \multirow{2}{*}{\makecell{\textbf{Content}\\\textbf{preservation}}} & Avg. rating & {$4.37\pm0.63$} & {$4.18\pm0.67$} & {$3.93\pm0.71$} & {$3.9\pm0.75$} & {$3.85\pm0.78$} & {{$4.05\pm0.2$}} \\ \cline{2-8}
    {} & Ratings 5\&4 & {$91.67\%$} & {$85.0\%$} & {$80.0\%$} & {$78.3\%$} & {$80.0\%$} & {{$83.0\%$}} \\ \midrule
    \multirow{2}{*}{\makecell{\textbf{Grammar or}\\\textbf{text quality}}} & Avg. rating & {$4.62 \pm 0.55$} & {$4.28\pm 0.73$} & {$4.26 \pm 0.65$} & {$4.22 \pm 0.64$} & {$4.17\pm0.74$} & {{$ 4.31\pm 0.35$}}\\ \cline{2-8}
    {} & Ratings 5\&4 & {$96.67\%$} & {$83.33\%$} & {$88.33\%$} & {$88.3\%$} & {$83.33\%$} & {{$88.0\%$}}\\ 
    % \midrule \midrule
    % \multicolumn{2}{c||}{\textbf{Mean perplexity} (5.5)} & 8.1 & 9.3 & 9.0 & 10.3  & 10.5 & 11.5 \\ \midrule
    % \multicolumn{2}{c||}{\textbf{QA performance} ($97\%$)} & $97\%$ & $97\%$ & $97\%$ & $97\%$  & $97\%$ & - \\
    \bottomrule
    \end{tabular}
    \end{adjustbox} 
    \caption{
    Summary of the MTurk human evaluation study of the recursive paraphrases with LLaMA-2-7B-Chat.}
    \label{tab:summary-mturk-llama}

    % \vspace{2mm}
    % \begin{adjustbox}{max width=.6\textwidth}
    % \begin{tabular}{l|l|c|c|c|c|c|c}
    % \toprule
    % \multicolumn{1}{c|}{\textbf{Paraphraser}} &
    %   \multicolumn{1}{c|}{\textbf{Evaluation}} &
    %   \textbf{AI text} &
    %   \textbf{pp1} &
    %   \textbf{pp2} &
    %   \textbf{pp3} &
    %   \textbf{pp4} &
    %   \textbf{pp5} \\ \midrule \midrule
    % \multirow{2}{*}{DIPPER}     & Mean perplexity       & 5.2  & 7.7  & 7.8  & 8.5  & 7.7  & 8.7    \\ \cmidrule{2-8} 
    %                             & QA performance & 97\% & 97\% & 96\% & 96\% & 96\% & 95.5\% \\ \midrule
    % \multirow{2}{*}{LLaMA-2-7B-Chat} & Mean perplexity       & 5.2  & 8.1  & 9.3  & 9.0  & 10.3 & 10.5   \\ \cmidrule{2-8} 
    %                             & QA Performance & 97\% & 97\% & 97\% & 97\% & 97\% & 97\%   \\ \bottomrule
    % \end{tabular}
    % \end{adjustbox}
    % \caption{
    % Automated evaluation of the text quality of recursive paraphrases using perplexity measures with respect to OPT-13B and question-answering benchmark accuracy.}
    % \label{tab:quality-eval}
    \vspace{-0.5cm}
    
\end{table}


We use the ``document'' features of the XSum dataset \citep{xsum} containing 1000 long news articles ($\sim$300 tokens in length) for our experiments. In Appendix~\ref{app:moreexps}, we perform experiments with additional datasets -- a medical text dataset PubMedQA \citep{jin-etal-2019-pubmedqa} and a dataset with articles from 10 different domains Kafkai \citep{kafkai}. 
As target LLMs, we use OPT-1.3B and OPT-13B \citep{opt} language models with 1.3B and 13B parameters, respectively.
In Appendix~\ref{app:moreexps}, we also evaluate our attacks with GPT-2 Medium \citep{gpt2} as the target model.
We use three different neural network-based paraphrasers -- DIPPER with 11B parameters \citep{krishna2023paraphrasing}, LLaMA-2-7B-Chat with 7B parameters \citep{llama}, and T5-based paraphraser \citep{prithivida2021parrot} with 222M parameters.
Suppose a passage $S = (s_1, s_2, ..., s_n)$ where $s_i$ is the $i^{th}$ sentence. DIPPER and LLaMA-2-7B-Chat paraphrase $S$ to be $S' = f_{strong}(S)$ in one-shot while the light-weight T5-based paraphraser would output $S' = (f_{weak}(s_1), f_{weak}(s_2), ..., f_{weak}(s_n))$ where they can only paraphrase sentence-by-sentence. DIPPER and LLaMA-2-7B-Chat also have the ability to input a context prompt text $C$ to generate higher-quality paraphrasing $S' = f_{strong}(S, C)$. We can also vary two different hyperparameters of DIPPER to generate a diverse number of paraphrases for a single input passage.









% \begin{table}[t]
%     \centering\renewcommand\cellalign{lc}
%     \setcellgapes{3pt}\makegapedcells
%     \begin{adjustbox}{max width=\textwidth}
%     \begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
%     \toprule
%     \multirow{2}{*}{\textbf{{ppi}}} & \multicolumn{2}{c|}{\textbf{Average rating}} & \multicolumn{2}{c|}{\textbf{Sum of 5 \& 4 (\%)}} & \multicolumn{2}{c|}{\textbf{Rating 5 (\%)}} & \multicolumn{2}{c|}{\textbf{Rating 4 (\%)}} & \multicolumn{2}{c|}{\textbf{Rating 3 (\%)}} & \multicolumn{2}{c|}{\textbf{Rating 2 (\%)}} & \multicolumn{2}{c}{\textbf{Rating 1 (\%)}}\\ \cline{2-15}
%     {} & \multicolumn{1}{c|}{Grammar} & \multicolumn{1}{c|}{Content}& \multicolumn{1}{c|}{Grammar} & \multicolumn{1}{c|}{Content}& \multicolumn{1}{c|}{Grammar} & \multicolumn{1}{c|}{Content}& \multicolumn{1}{c|}{Grammar} & \multicolumn{1}{c|}{Content}& \multicolumn{1}{c|}{Grammar} & \multicolumn{1}{c|}{Content}& \multicolumn{1}{c|}{Grammar} & \multicolumn{1}{c|}{Content}& \multicolumn{1}{c|}{Grammar} & \multicolumn{1}{c}{Content}
%     \\
%     \midrule \midrule
%     i=1	&4.28$\pm$0.67& 4.0$\pm$0.8	&87.72 & {70.2}	&40.35& {29.8}	&47.37& {40.4}	&12.28& {29.8} &	0.00& {0.0}	&0.00& {0.0}\\
%     \midrule
% i=2	&4.12 $\pm$ 0.50& 4.1$\pm$0.8	&92.98& {77.2}	&19.30& {33.3}	&73.68& {43.9} &	7.02& {19.3}	&0.00& {3.5}	&0.00& {0.0}\\
%     \midrule
% i=3	&4.12 $\pm$ 0.53& 3.9$\pm$0.9	&91.23& {63.2}	&21.05& {33.3}	&70.18& {29.8} &	8.77& {33.3} &	0.00& {3.5}	&0.00& {0.0}\\
%     \midrule
% i=4	&4.11 $\pm$0.64& 4.2$\pm$0.9&	84.21& {80.0}	&26.32& {49.1} &	57.89& {30.9} 	&15.79& {14.5}	&0.00& {5.5}	&0.00& {0.0}\\
%     \midrule
% i=5	&4.07 $\pm$ 0.53& 3.7$\pm$1.1	&89.47& {61.4}	&17.54& {29.8}	&71.93& {31.6} &	10.53& {21.1}&	0.00& {17.5}	&0.00& {0.0}\\
%     \midrule
%     \midrule 
%     \textbf{All ppi}	&\textbf{4.14 $\pm$ 0.58} & \textbf{4.0$\pm$0.9} &\textbf{89.12} & \textbf{70.4}	&\textbf{24.91}	& \textbf{35.1} &\textbf{64.21}& \textbf{35.3} 	&\textbf{10.88}& \textbf{23.6} &	\textbf{0.0}& \textbf{6.0} & \textbf{0.0}& \textbf{0.0}  \\
%     \bottomrule
%     \end{tabular}
%     \end{adjustbox}
%     \vspace{0mm}
%     \caption{{\bf Human evaluation of recursive paraphrases using MTurk for grammar and content preservation studies.} \texttt{ppi} represents the \texttt{i}$^{th}$ round of recursive paraphrasing. \textbf{Likert scale for text quality and grammar study:} 5 -- the paraphrase has excellent grammar/quality with respect to the highlighted source. 4 -- the paraphrase is clear and correct with minor grammatical errors. 3 -- the paraphrase has few grammatical errors, but remains clear and comparable to highlighted source text. 2 -- the paraphrase has significant number of grammatical errors, but remains understandable. 1 -- the paraphrase is inferior to the highlighted source text with a lot of grammatical errors, may be difficult to comprehend. \textbf{Likert scale for paraphrase content preservation study:} 5 -- the paraphrase has excellent grammar/quality with respect to the highlighted source. 4 -- the paraphrase is clear and correct with minor grammatical errors. 3 -- the paraphrase has few grammatical errors, but remains clear and comparable to highlighted source text. 2 -- the paraphrase has significant number of grammatical errors, but remains understandable. 1 -- the paraphrase is inferior to the highlighted source text with a lot of grammatical errors, may be difficult to comprehend.\SF{only report average numbers in the main text; full table in appendix; table caption should be 1-2 lines at most; details should be pushed to either main text or appendix}}
%     \label{tab:mturk-study}
%     \vspace{-2mm}
% \end{table}



%\subsection{Recursive Paraphrasing Attacks}

\begin{wraptable}{r}{10cm}
    \begin{adjustbox}{max width=.55\textwidth}
    \begin{tabular}{l|l|c|c|c|c|c|c}
    \toprule
    \multicolumn{1}{c|}{\textbf{Paraphraser}} &
      \multicolumn{1}{c|}{\textbf{Evaluation}} &
      \textbf{AI text} &
      \textbf{pp1} &
      \textbf{pp2} &
      \textbf{pp3} &
      \textbf{pp4} &
      \textbf{pp5} \\ \midrule \midrule
    \multirow{2}{*}{DIPPER}     & Mean perplexity       & 5.2  & 7.7  & 7.8  & 8.5  & 7.7  & 8.7    \\ \cmidrule{2-8} 
                                & QA performance & 97\% & 97\% & 96\% & 96\% & 96\% & 95.5\% \\ \midrule
    \multirow{2}{*}{LLaMA-2-7B-Chat} & Mean perplexity       & 5.2  & 8.1  & 9.3  & 9.0  & 10.3 & 10.5   \\ \cmidrule{2-8} 
                                & QA Performance & 97\% & 97\% & 97\% & 97\% & 97\% & 97\%   \\ \bottomrule
    \end{tabular}
    \end{adjustbox}
    \caption{
    Automated evaluation of the text quality of recursive paraphrases using perplexity measures with respect to OPT-13B and question-answering benchmark accuracy.}
    \label{tab:quality-eval}
    \vspace{-0.4cm}
\end{wraptable} 
We use DIPPER and LLaMA-2-7B-Chat for recursive paraphrasing attacks since they provide high-quality paraphrasing when compared to the 222M parameter T5 model.
Let an LLM $\mathcal{L}$ generate AI text output $S = \mathcal{L}(C)$ for an input prompt $C$. DIPPER or LLaMA-2-7B-Chat can be used to generate a paraphrase $\texttt{pp1}(S) = f_{strong}(S, C)$. This paraphrasing can be performed in recursion (see Figure~\ref{fig:rec-para}). That is, $\texttt{pp2}(S)= f_{strong}(\texttt{pp1}(S), C)$ and so on. 

While DIPPER is explicitly trained to be a paraphraser, LLaMA-2-7B-Chat is an instruction-tuned model for chat purposes.
We design a system prompt (see Appendix~\ref{app:systemprompts}) with the LLaMA-2-7B-Chat model to use it as a paraphraser.
In \S\ref{sec:watermark_evade} and \S\ref{sec:paraphrase_nonwatermark}, we show that recursive paraphrasing is effective in evading the strong watermark and retrieval-based detectors when compared to a single round of paraphrasing. 
Using human and other automated evaluation techniques in \S\ref{sec:quality}, we show that our recursive paraphrasing method only degrades the text quality slightly most of the time.



\subsection{Quality of the Paraphrases}
\label{sec:quality}

% \noindent{\bf Quality of the paraphrased passages.}
In order to reliably study the quality of the recursive paraphrases we use in our experiments using DIPPER and LLaMA-2-7B-Chat, we perform human evaluations using MTurk and other automated techniques. 
The AI-text used in this study is generated using a watermarked OPT-13B model. 
Tables~\ref{tab:summary-mturk}~and~\ref{tab:summary-mturk-llama} provide a summary of the study.  We investigate the content preservation and text quality or grammar of the recursive paraphrases with respect to the AI-generated texts (see Tables~\ref{tab:mturk-content}-\ref{tab:mturk-grammar-llama} in Appendix \ref{app:human_study} for more details). 
{\bf In terms of content preservation with DIPPER, \bm{$70\%$} of the paraphrases were rated high quality and \bm{$23\%$} somewhat equivalent. In terms of text quality or grammar, \bm{$89\%$} of the paraphrases were rated high quality.} 
On a Likert scale of 1 to 5, the DIPPER paraphrases that we use received an average rating of $4.14 \pm 0.58$ for text quality or grammar and $4.0 \pm 0.9$ for content preservation. 
\textbf{Similarly, \bm{$83\%$} of the recursive paraphrases we obtain with LLaMA-2-7B-Chat were rated high quality.}
See Appendix \ref{app:human_study} for more details on the human study.

For automated text quality evaluations, we use perplexity measures and a question-answering (QA) benchmark in Table~\ref{tab:quality-eval}.  
We measure the perplexity scores using OPT-13B. 
As shown in the table, the perplexity scores degrade from 5.5 to 8.7 and 10.5, respectively, for DIPPER and LLaMA-2-7B-Chat after 5 rounds of paraphrasing.
We also use a QA benchmark SQuAD-v2 \citep{squadv2} to evaluate the effect of recursive paraphrasing. For this, we use two hundred data points from SQuAD-v2, 
\revision{which have context text length of at least 300 tokens. The length of context text passages we use in the study is $328 \pm 28$ tokens.}
Each data point consists of a context passage, a question, and an answer.
We evaluate a QA model on the SquAD-v2 benchmark to observe that it achieves $97\%$ accuracy in the QA task.
For the QA model, we use the LLaMA-2-13B-Chat model with a carefully written system prompt (see Appendix~\ref{app:systemprompts}).
To evaluate the quality of paraphrases, we paraphrase the context passages recursively and use these to evaluate the QA accuracy with the QA model.
If the QA model can answer the question correctly based on the paraphrased context, then the information is preserved in the paraphrase.
As we observe, the QA performance with recursive paraphrasing is similar to that with the clean context passage.
These results substantiate that AI text detectors can be effectively attacked using recursive paraphrasing with only a slight degradation in text quality.\looseness=-1


\newcontent{We note that the amount of acceptable quality degradation can be application-specific. For example, an adversary might be okay with a higher quality drop when writing a social media post than when writing a fake news article. Our human studies rate our recursive paraphrases to have a score of either 5 or 4 over 70\% of the time. Though this might be acceptable for some adversaries, others might not tolerate a score of 4 for their applications. Since a score of 4 denotes minor degradation, we presume that the adversaries could manually edit them for their attacks. Nevertheless, our paraphrases get a perfect score 35\% of the time, indicating that it is still practical for adversaries to use it to perform their attacks successfully. However, we believe this tradeoff in text quality degradation and detection evasion would diminish as paraphrasers improve in the future.}



%Along with quantifying text quality with perplexity measured using OPT-13B, we also perform a human study to ensure that our recursive paraphrasing method only degrades the text quality slightly.

% \SF{this should be a separate sub-section; explain what this is and how the recursion works; beef this up; perhaps add a small flow chart for it?}



\begin{figure}[t]
\centering
\begin{subfigure}{.495\textwidth}
  \centering
  \adjustimage{width=1\linewidth, left}{images/wm_opt13b_dipper.png}
  % \vspace{-2mm}
  \caption{Recursive paraphrasing with DIPPER}
  \label{fig:watermark-opt13-dipper}
\end{subfigure}% 
\hfill
\begin{subfigure}{.495\textwidth}
  \centering
  \adjustimage{width=1\linewidth, right}{images/wm_opt13b_llama.png}
  % \vspace{-2mm}
  \caption{Recursive paraphrasing with LLaMA-2-7B-Chat}
  \label{fig:watermark-opt13-llama}
\end{subfigure}
% \vspace{-2mm}
\caption{ROC plots for soft watermarking with recursive paraphrasing attacks. AUROC, TPR@1$\%$FPR, and perplexity scores measured using OPT-13B are given in the legend. The target LLM OPT-13B is used to generate watermarked output that are 300 tokens in length.}
\label{fig:watermarkroc-op13b}
\vspace{-0mm}
\end{figure}
\begin{figure}[t]
\centering
\begin{subfigure}{.495\textwidth}
  \centering
  \adjustimage{width=1\linewidth, left}{images/rebuttal_wm_rec_paraphrase.png}
  % \vspace{-2mm}
  \caption{Watermarked text with mean token length 300}
  \label{fig:watermarkroc1}
\end{subfigure}% 
\hfill
\begin{subfigure}{.495\textwidth}
  \centering
  \adjustimage{width=1\linewidth, right}{images/rebuttal_wm_rec_paraphrase_vary_tokens.png}
  % \vspace{-2mm}
  \caption{Watermarked text with varying token lengths}
  \label{fig:watermarkroc2}
\end{subfigure}
% \vspace{-2mm}
\caption{ROC plots for soft watermarking with recursive paraphrasing attacks. AUROC, TPR@1$\%$FPR, and perplexity scores measured using OPT-13B are given in the legend. The target LLM is OPT-1.3B. (a) Even for 300 tokens long watermarked passages, recursive paraphrasing is effective. As paraphrasing rounds proceed, detection rates degrade significantly with a slight trade-off in text quality. (b) Attacking watermarked passages become easier as their length reduces.}
\label{fig:watermarkroc}
\vspace{-0mm}
\end{figure}

\subsection{Paraphrasing Attacks on Watermarked AI Text}
\label{sec:watermark_evade}

In this section, we evaluate our recursive paraphrasing attacks on the soft watermarking scheme proposed in \cite{kirchenbauer2023watermark}.  Soft watermarking encourages LLMs to output token $s^{(t)}$ at time-step $t$ that belongs to a ``green list''. The green list for $s^{(t)}$ is created using a private pseudo-random generator that is seeded with the prior token $s^{(t-1)}$. A watermarked output from the LLM is designed to have tokens that are majorly selected from the green list. Hence, a watermark detector with the pseudo-random generator checks the number of \textit{green} tokens in a candidate passage to detect whether it is watermarked or not. 
Here, we target watermarked OPT-13B with 13B parameters in Figure~\ref{fig:watermarkroc-op13b} and watermarked OPT-1.3B in Figure~\ref{fig:watermarkroc} for our experiments. In Appendix~\ref{app:moreexps_wm}, we also evaluate our attacks on GPT-2 Medium \citep{gpt2} and other datasets -- PubMedQA \citep{jin-etal-2019-pubmedqa} and Kafkai \citep{kafkai}. 

\noindent{\bf Dataset.} We perform our experiments on 2000 text passages that are around 300 tokens in length \textcolor{black}{(1000 passages per human and AI text classes)}. We pick 1000 long news articles from the XSum ``document'' feature. For each article, the first $\sim$300 tokens are input to the target OPT-1.3B \textcolor{black}{to generate 1000 watermarked AI text passages that are each $\sim$300 tokens in length. The second 300 tokens from the 1000 news articles in the dataset are treated as baseline human text.} We note that our considered dataset has more and longer passages compared to the experiments in \cite{kirchenbauer2023watermark}.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\textwidth]{images/nonwatermark_roc_new1.pdf}
    \vspace{-2mm}
   \caption{ROC curves for various trained and zero-shot detectors. \textbf{Left:} Without attack. \textbf{Middle:} After paraphrasing attack using T5-based paraphraser. The performance of zero-shot detectors drops significantly. \textbf{Right:} Here, we assume we can query the detector ten times for the paraphrasing attack. We generate ten paraphrasings for each passage and query multiple times to evade detection. Notice how all detectors have low TPR@$1\%$FPR. In the plot legend -- \texttt{perturbation} refers to the zero-shot methods in \cite{mitchell2023detectgpt}; \texttt{threshold} refers to the zero-shot methods in \cite{solaiman2019release, gehrmann2019gltr, ippolito2019automatic}; \texttt{roberta} refers to OpenAI's trained detectors \citep{openaidetectgpt2}. The TPR@$1\%$FPR scores of different detectors before the attack, after the attack, and after the attack with multiple queries, respectively, are provided in the plot legend.}
    \label{fig:roc_nonwatermark}
    \vspace{-5mm}
\end{figure}


\noindent{\bf Detection results after paraphrasing attack.}
Weaker paraphrasing attacks discussed in \cite{kirchenbauer2023watermark} are not effective in removing watermarks. They perform ``span replacement'' by replacing random tokens (in-place) using a language model. 
However, after a single round of paraphrasing (\texttt{pp1}) with a watermarked OPT-13B as the target LLM, TPR@$1\%$FPR of watermark detector degrades from $99.8\%$ to $80.7\%$ and $54.6\%$, respectively, with DIPPER and LLaMA-2-7B-Chat paraphrasers. 
% We also show that our stronger recursive paraphrasing attacks can effectively evade watermark detectors with only a slight degradation in text quality. 
\newcontent{Though watermarking is a worthwhile endeavor to prevent AI plagiarism, with our stress test, we show that an adversary can find their way to evade detection via paraphrasing.}
As shown in Figures~\ref{fig:watermarkroc-op13b}-\ref{fig:watermarkroc}, the recursive paraphrase attack further degrades the detection rate of the detector to below $20\%$ after 5 rounds of paraphrasing (\texttt{pp5}). 
Note that in all the settings \texttt{pp2} or 2 rounds of paraphrasing is sufficient to degrade TPR@$1\%$FPR to below $50\%$. 
As shown in Figure~\ref{fig:watermarkroc-op13b}, DIPPER shows a clearer and more consistent trend in improving attack performance over recursions of paraphrasing in comparison to LLaMA-2. This is because DIPPER is trained explicitly to be a paraphraser with hyperparameters that can control the quality of paraphrasing. Therefore, we mainly employ DIPPER for our recursive paraphrase attacks.
\texttt{Best of ppi} in the figure refers to the method where, for each passage, we select the paraphrase out of all the \texttt{ppi}'s that has the worst detector score. For \texttt{Best of ppi} with OPT-1.3B,  the detection rate reduces drastically from $99.8\%$ to $4.0\%$ with a trade-off of $1.5$ in the perplexity score (Figure~\ref{fig:watermarkroc1}). 
\texttt{Best of ppi}, unlike the \texttt{ppi} attacks, assume black box query access to the detector.
Figure \ref{fig:watermarkroc2} shows that the watermarking detector becomes weaker as the length of the watermarked text reduces. Note that for watermarked texts that are 50 or 100 tokens long, the detection performance after the recursive paraphrasing attack is similar to that of a random detector. 
\newcontent{As the plot indicates, watermarking could be more reliable for preventing AI plagiarism in tasks that require longer texts. However, this does not guarantee that watermarking will be a foolproof defense in such settings. This requires more investigation, and we leave this for future work.}
We provide examples of paraphrased text that we use for our attacks in Appendix \ref{app:example-paraphrases}.\looseness=-1



\subsection{Paraphrasing Attacks on Non-Watermarked AI Text}
\label{sec:paraphrase_nonwatermark}


% Non-watermarking detectors such as trained classifiers \citep{openaidetectgpt2}, \textcolor{red}{retrieval-based detectors \citep{krishna2023paraphrasing}, and} zero-shot classifiers \citep{mitchell2023detectgpt, gehrmann2019gltr, ippolito2019automatic, solaiman2019release} use the presence of LLM-specific signatures in AI-generated texts for their detection. 


Neural network-based trained detectors such as RoBERTa-Large-Detector from OpenAI \citep{openaidetectgpt2} are trained or fine-tuned for binary classification with datasets containing human and AI-generated texts. Zero-shot classifiers leverage specific statistical properties of the source LLM outputs for their detection. Retrieval-based methods search for a candidate passage in a database that stores the LLM outputs. Here, we perform experiments on these non-watermarking detectors to show they are vulnerable to our paraphrasing attack.\looseness=-1



\textbf{Trained and Zero-shot detectors.} We use a pre-trained GPT-2 Medium
% \footnote{\url{https://huggingface.co/gpt2-medium}}
model \citep{gpt2} with 355M parameters as the target LLM to evaluate our attack on \textcolor{black}{1000} long passages from the XSum dataset \citep{xsum}. We use the T5-based paraphrasing model \citep{prithivida2021parrot} with 222M parameters to rephrase the \textcolor{black}{1000} output texts generated using the target GPT-2 Medium model. 
\begin{wrapfigure}{r}{0.5\textwidth}
        \centering
        \vspace{-4mm}
        \includegraphics[width=1.03\linewidth]{images/IR_attack.png}
        \caption{\textcolor{black}{Recursive paraphrasing breaks the retrieval-based detector \citep{krishna2023paraphrasing} with only slight degradation in text quality. \texttt{ppi} refers to $\texttt{i}$ recursion(s) of paraphrasing. Numbers next to markers denote the perplexity scores of the paraphraser output.}}
        \vspace{-6mm}
    \label{fig:ir-attack}
\end{wrapfigure}Figure~\ref{fig:roc_nonwatermark} shows the effectiveness of the paraphrasing attack over these detectors. {\bf The AUROC scores of DetectGPT \citep{mitchell2023detectgpt} drop from \bm{$96.5\%$} (before the attack) to \bm{$59.8\%$} (after the attack).} Note that AUROC of $50\%$ corresponds to a random detector. The rest of the zero-shot detectors \citep{solaiman2019release, gehrmann2019gltr, ippolito2019automatic} also perform poorly after our attack. Though the performance of the trained neural network-based detectors \citep{openaidetectgpt2} is better than that of zero-shot detectors, they are also not reliable. For example, TPR@$1\%$FPR of OpenAI's RoBERTa-Large-Detector drops from $100\%$ to around $92\%$ after our attack.






In another setting, we assume the attacker may have multiple access to the detector. That is, the attacker can query the detector with an input AI text passage, and the detector would reveal the detection score to the attacker. For this scenario, we generate ten different paraphrases for an input passage and query the detector for the detection scores. For each AI text passage, we then select the paraphrase with the worst detection score for evaluating the ROC curves. As shown in Figure~\ref{fig:roc_nonwatermark}, {\bf with multiple queries to the detector, an adversary can paraphrase more efficiently to bring down TPR@\bm{$1\%$}FPR of the RoBERTa-Large-Detector from \bm{$100\%$} to \bm{$80\%$}.} In Appendix~\ref{app:moreexps_zs}, we show more experiments with more datasets and target LLMs.

\revision{
As seen in the results, the detection of the entropy threshold detector improves with paraphrasing.
LLMs are trained on human-written texts, and for this reason, they might have low entropy scores on human-written samples we use in our experiments due to memorization. 
Therefore, the entropy detector might have poor detection scores before the paraphrasing attack. However, after paraphrasing with a different AI model, the entropy scores for these human-written samples might increase, improving the detection scores. Despite this, the entropy threshold detector has poor detection rates before and after the attack.
}

\revision{
Though the performance of performance of trained detectors degrades after each round of paraphrasing, they seem to be more robust to paraphrase attacks than the other detectors we study. We hypothesize that this might be due to these detectors being trained on human-written samples we use for our study. 
For example, the MAGE dataset \citep{li2024magemachinegeneratedtextdetection} includes passages from the XSum dataset we use. \cite{gameiro2024llmdetectorsfallshort} argues that while trained detectors can generalize better to unseen LLMs, they may overfit to this training distribution of human text. They also show that some of these detectors fail to generalize to out-of-distribution human-written text. This is an aspect that we do not consider in our work, but would still make these detectors unreliable for real-world applications.
}

% Table \ref{tab:paraphrase_2} shows an example of outputs from the GPT-2 model before and after paraphrasing. 
% The output of the paraphraser reads well and means the same as the detected GPT-2 text (example in appendix). 
% We measure the perplexities of the GPT-2 output text before attack, after paraphrase attack, and after multiple query paraphrase attack to be 16.3, 27.2, and 18.3, respectively.
% (Figure~\ref{fig:roc_ai1}). GPT-2 is a relatively old LLM, and it performs poorly when compared to more recent LLMs. The perplexity of the GPT-2 text after paraphrasing is 27.2 (Figure~\ref{fig:roc_ai2}). The perplexity score only degrades by 2 with multiple queries to the detector (Figure~\ref{fig:roc_ai3}).




\textbf{Retrieval-based detectors.} Detector in \citet{krishna2023paraphrasing} is designed to be robust against paraphrase attacks. However, we show that they can suffer from the recursive paraphrase attacks that we develop using DIPPER. 
% We use their codes\footnote{\url{https://github.com/martiansideofthemoon/ai-detection-paraphrases}}, and DIPPER \cite{krishna2023paraphrasing}, an 11B parameter paraphraser for our experiments. 
\textcolor{black}{We use 2000 passages (1000 generated by OPT-1.3B and 1000 human passages) from the XSum dataset. AI outputs are stored in the AI database by the detector. As shown in Figure \ref{fig:ir-attack}, this detector detects almost all of the AI outputs even after a round of paraphrasing. However, \textbf{the detection accuracy drops below \bm{$\sim60\%$} after five rounds of recursive paraphrasing.} As marked in the plot, the perplexity score of the paraphrased text only degrades by $1.7$ at a detection accuracy of $\sim60\%$.} 
% Using a heavy-duty paraphraser DIPPER helps preserve the perplexity scores. 
Moreover, retrieval-based detectors are concerning since they might lead to \textbf{serious privacy issues} from storing users' LLM conversations. In Appendix~\ref{app:moreexps_retrieval}, we show more experiments with more datasets and target LLMs.