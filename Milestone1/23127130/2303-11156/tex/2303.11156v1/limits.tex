\section{Impossibility Results for Reliable Detection of AI-Generated Text}
\label{sec:impossibilityresult}






%While it is theoretically possible to identify text generated by language models that have been modified with specific features, such as watermarks, ensuring that all publicly available models have been appropriately modified may not be feasible.
%%Although it may be possible to detect text generated by language models with specific modifications (e.g., watermarked LLMs), in practice, it is difficult to ensure that every publicly available model is appropriately modified.
Detecting the misuse of language models in the real world, such as plagiarism and mass propaganda, necessitates the identification of text produced by all kinds of language models, including those without watermarks.
However, as these models improve over time, the generated text looks increasingly similar to human text, which complicates the detection process. Specifically, the total variation distance between the distributions of AI-generated and human-generated text sequences diminishes as language models become more sophisticated. This section presents a fundamental constraint on general AI-text detection, demonstrating that even the most effective detector performs only marginally better than a random classifier when dealing with a sufficiently advanced language model. The purpose of this analysis is to caution against relying too heavily on detection systems that claim to identify AI-generated text. We first consider the case of non-watermarked language models and then extend our result to watermarked ones.

%In this section, we show a fundamental limitation for general AI-text detection.
%We show that for a sufficiently good language model, even the best-possible detector performs only marginally better than a random classifier.


In the following theorem, we formalize the above statement by showing an upper bound on the area under the ROC curve of an arbitrary detector in terms of the total variation distance between the distributions for AI and human-generated text.
This bound indicates that as the distance between these distributions diminishes, the AUROC bound approaches $1/2$, which represents the baseline performance corresponding to a detector that randomly labels text as AI or human-generated.
We define $\mathcal{M}$ and $\mathcal{H}$ as the text distributions produced by an AI model and humans, respectively, over the set of all possible text sequences $\Omega$.
We use $\mathsf{TV}(\mathcal{M}, \mathcal{H})$ to denote the total variation distance between these two distributions and a function $D: \Omega \rightarrow \mathbb{R}$ that maps every sequence in $\Omega$ to a real number.
% detection parameter $\gamma$.
Sequences are classified into AI and human-generated by applying a threshold $\gamma$ on this number.
By adjusting the parameter $\gamma$, we can tune the sensitivity of the detector to AI and human-generated texts to obtain an ROC curve.

\begin{theorem}
\label{thm:ROC_bound}
The area under the ROC of any detector $D$ is bounded as
\[\mathsf{AUROC}(D) \leq \frac{1}{2} + \mathsf{TV}(\mathcal{M}, \mathcal{H}) - \frac{\mathsf{TV}(\mathcal{M}, \mathcal{H})^2}{2}.\]
\end{theorem}

\begin{proof}
The ROC is a plot between the true positive rate (TPR) and the false positive rate (FPR) which are defined as follows:
\begin{align*}
    \mathsf{TPR}_\gamma &= \mathbb{P}_{s \sim \mathcal{M}}[D(s) \geq \gamma]\\
    \text{and } \mathsf{FPR}_\gamma &= \mathbb{P}_{s \sim \mathcal{H}}[D(s) \geq \gamma],
\end{align*}
where $\gamma$ is some classifier parameter.
We can bound the difference between the $\mathsf{TPR}_\gamma$ and the $\mathsf{FPR}_\gamma$ by the total variation between $M$ and $H$:
\begin{align}
    |\mathsf{TPR}_\gamma - \mathsf{FPR}_\gamma| &= \left| \mathbb{P}_{s \sim \mathcal{M}}[D(s) \geq \gamma] - \mathbb{P}_{s \sim \mathcal{H}}[D(s) \geq \gamma] \right| \leq \mathsf{TV}(\mathcal{M}, \mathcal{H})\\
    \mathsf{TPR}_\gamma &\leq \mathsf{FPR}_\gamma + \mathsf{TV}(\mathcal{M}, \mathcal{H}).
    \label{eq:TPR_FPR_bound}
\end{align}
Since the $\mathsf{TPR}_\gamma$ is also bounded by 1 we have:
\begin{align}
\label{eq:tpr_bound}
\mathsf{TPR}_\gamma \leq \min(\mathsf{FPR}_\gamma + \mathsf{TV}(\mathcal{M}, \mathcal{H}), 1).
\end{align}
Denoting $\mathsf{FPR}_\gamma$, $\mathsf{TPR}_\gamma$, and $\mathsf{TV}(\mathcal{M}, \mathcal{H})$ with $x$, $y$, and $tv$ for brevity, we bound the AUROC as follows:
\allowdisplaybreaks
\begin{align*}
    \mathsf{AUROC}(D) = \int_0^1 y \; dx &\leq \int_0^1 \min(x + tv, 1) dx\\
    &= \int_0^{1 -tv} (x + tv) dx + \int_{1-tv}^1 dx\\
    &= \left| \frac{x^2}{2} + tvx \right|_0^{1-tv} + \left| x \right|_{1-tv}^1\\
    &= \frac{(1-tv)^2}{2} + tv(1-tv) + tv\\
    &= \frac{1}{2} + \frac{tv^2}{2} - tv + tv - tv^2 + tv\\
    &= \frac{1}{2} + tv - \frac{tv^2}{2}.
\end{align*}
\end{proof}

\begin{wrapfigure}{r}{0.5\textwidth}
    %\centering
    \vspace{-6mm}
    \hspace{-7mm}
    \includegraphics[width=1.2\linewidth]{images/roc_bound.png}
    \vspace{-5mm}
    \caption{Comparing the performance, in terms of area under the ROC curve, of the best-possible detector to that of the baseline performance corresponding to a random classifier.}
    \label{fig:roc_bound}
    \vspace{-4mm}
\end{wrapfigure}

\looseness -1
Figure~\ref{fig:roc_bound} shows how the above bound grows as a function of the total variation.
For a detector to have a good performance (say, AUROC $\geq 0.9$), the distributions of human and AI-generated texts must be very different from each other (total variation $> 0.5$).
As the two distributions become similar (say, total variation $\leq 0.2$), the performance of even the best-possible detector is not good (AUROC $< 0.7$).
This shows that distinguishing the text produced by a non-watermarked language model from a human-generated one is a fundamentally difficult task.
Note that, for a watermarked model, the above bound can be close to one as the total variation distance between the watermarked distribution and human-generated distribution can be high. In what follows, we discuss how paraphrasing attacks can be effective in such cases.

\textbf{Paraphrasing to Evade Detection:} Although our analysis considers the text generated by all humans and general language models, it can also be applied to specific scenarios, such as particular writing styles or sentence paraphrasing, by defining $\mathcal{M}$ and $\mathcal{H}$ appropriately.
For example, it could be used to show that AI-generated text, even with watermarks, can be made difficult to detect by simply passing it through a paraphrasing tool.
Consider a paraphraser that takes a sequence $s$ generated by an AI model as input and produces a human-like sequence with similar meaning.
Set $\mathcal{M} = \mathcal{R_M}(s)$ and $\mathcal{H} = \mathcal{R_H}(s)$ to be the distribution of sequences with similar meanings to $s$ produced by the paraphraser and humans, respectively.
The goal of the paraphraser is to make its distribution $\mathcal{R_M}(s)$ as similar to the human distribution $\mathcal{R_H}(s)$ as possible, essentially reducing the total variation distance between them.
Theorem~\ref{thm:ROC_bound} puts the following bound on the performance of a detector $D$ that seeks to detect the outputs of the paraphraser from the sequences produced by humans.


\begin{corollary}
The area under the ROC of the detector $D$ is bounded as
\[\mathsf{AUROC}(D) \leq \frac{1}{2} + \mathsf{TV}(\mathcal{R_M}(s), \mathcal{R_H}(s)) - \frac{\mathsf{TV}(\mathcal{R_M}(s), \mathcal{R_H}(s))^2}{2}.\]
\end{corollary}


\textbf{General Trade-offs between True Positive and False Positive Rates.} Another way to understand the limitations of AI-generated text detectors is directly through the characterization of the trade-offs between true positive rates and false positive rates. Adapting inequality \ref{eq:TPR_FPR_bound}, we have the following corollaries: 


\begin{corollary}
\label{corollary:rephrasing_wm}
For any watermarking scheme $W$,
\begin{align*}
    \Pr_{s_w\sim \mathcal{R}_{\mathcal{M}}(s)} [\text{$s_w$ is watermarked using $W$}] \leq &
    \mathsf{TV}(\mathcal{R_M}(s), \mathcal{R_H}(s)) + \\
    & \Pr_{s_w\sim \mathcal{R}_{\mathcal{H}}(s)}[\text{$s_w$ is watermarked using $W$}],
\end{align*}
where $\mathcal{R_M}(s)$ and $\mathcal{R_H}(s)$ are respectively the distributions of rephrased sequences for $s$ produced by the paraphrasing model and humans, respectively.
\end{corollary}

\looseness -1
Humans may have different writing styles. Corollary \ref{corollary:rephrasing_wm} indicates that if a rephrasing model resembles certain human text distribution $\mathcal{H}$ (i.e. $\mathsf{TV}(\mathcal{R_M}(s), \mathcal{R_H}(s))$ is small), then either certain people's writing will be detected falsely as watermarked (i.e. $\Pr_{s_w\sim \mathcal{R}_{\mathcal{H}}(s)} [\text{$s_w$ is watermarked using $W$}]$ is high) or the paraphrasing model can remove the watermark (i.e. $\Pr_{s_w\sim \mathcal{R}_{\mathcal{M}}(s)} [\text{$s_w$ is watermarked respect to $W$}]$ is low).


\begin{corollary}
\label{corollary:rephrasing_no_wm}
For any AI-text detector $D$, 
\begin{align*}
    \Pr_{s\sim \mathcal{M}} [\text{$s$ is detected as AI-text by $D$}] \leq \mathsf{TV}(\mathcal{M}, \mathcal{H}) + \Pr_{s\sim \mathcal{H}}[\text{$s$ is detected as AI-text by $D$}],
\end{align*}
where $\mathcal{M}$ and $\mathcal{H}$ denote text distributions by the model and by humans, respectively.
\end{corollary}

Corollary \ref{corollary:rephrasing_no_wm} indicates that if a model resembles certain human text distribution $\mathcal{H}$ (i.e. $\mathsf{TV}(\mathcal{M}, \mathcal{H})$ is small), then either certain people's writing will be detected falsely as AI-generated (i.e. $\Pr_{s\sim \mathcal{H}} [\text{$s$ is detected as AI-text by $D$}]$ is high) or the AI-generated text will not be detected reliably (i.e. $\Pr_{s\sim \mathcal{M}} [\text{$s$ is detected as AI-text by $D$}]$ is low).

\looseness -1
These results demonstrate fundamental limitations for AI-text detectors, with and without watermarking schemes.


\subsection{Tightness Analysis}
In this section, we show that the bound in Theorem~\ref{thm:ROC_bound} is tight.
For a given distribution of human-generated text sequences $\mathcal{H}$, we construct an AI-text distribution $\mathcal{M}$ and a detector $D$ such that the bound holds with equality.
Define sublevel sets of the probability density function of the distribution of human-generated text $\mathsf{pdf}_\mathcal{H}$ over the set of all sequences $\Omega$ as follows:
\[\Omega_\mathcal{H}(c) = \{s \in \Omega \mid \mathsf{pdf}_\mathcal{H}(s) \leq c\}\]
where $c \in \mathbb{R}$.
Assume that, $\Omega_\mathcal{H}(0)$ is not empty.
Now, consider a distribution $\mathcal{M}$, with density function $\mathsf{pdf}_\mathcal{M}$, which has the following properties:
\begin{enumerate}
    \item The probability of a sequence drawn from $\mathcal{M}$ falling in $\Omega_\mathcal{H}(0)$ is $\mathsf{TV}(\mathcal{M}, \mathcal{H})$, i.e., $\mathbb{P}_{s \sim \mathcal{M}}[s \in \Omega_\mathcal{H}(0)] = \mathsf{TV}(\mathcal{M}, \mathcal{H})$.
    \item $\mathsf{pdf}_\mathcal{M}(s) = \mathsf{pdf}_\mathcal{H}(s)$ for all $s \in \Omega(\tau) - \Omega(0)$ where $\tau > 0$ such that $\mathbb{P}_{s \sim \mathcal{H}}[ s \in \Omega(\tau)] = 1 - \mathsf{TV}(\mathcal{M}, \mathcal{H})$.
    \item $\mathsf{pdf}_\mathcal{M}(s) = 0$ for all $s \in \Omega - \Omega(\tau)$.
\end{enumerate}
Define a hypothetical detector $D$ that maps each sequence in $\Omega$ to the negative of the probability density function of $\mathcal{H}$, i.e., $D(s) = - \mathsf{pdf}_\mathcal{H}(s)$.
Using the definitions of $\mathsf{TPR}_\gamma$ and $\mathsf{FPR}_\gamma$, we have:
\begin{align*}
    \mathsf{TPR}_\gamma &= \mathbb{P}_{s \sim \mathcal{M}}[D(s) \geq \gamma]\\
    &= \mathbb{P}_{s \sim \mathcal{M}}[- \mathsf{pdf}_\mathcal{H}(s) \geq \gamma]\\
    &= \mathbb{P}_{s \sim \mathcal{M}}[\mathsf{pdf}_\mathcal{H}(s) \leq -\gamma]\\
    &= \mathbb{P}_{s \sim \mathcal{M}}[ s \in \Omega_\mathcal{H}(-\gamma)]
\end{align*}
Similarly,
\[\mathsf{FPR}_\gamma = \mathbb{P}_{s \sim \mathcal{H}}[ s \in \Omega_\mathcal{H}(-\gamma)].\]
For $\gamma \in [-\tau, 0]$,
\begin{align*}
    \mathsf{TPR}_\gamma &= \mathbb{P}_{s \sim \mathcal{M}}[ s \in \Omega_\mathcal{H}(-\gamma)]\\
    &= \mathbb{P}_{s \sim \mathcal{M}}[ s \in \Omega_\mathcal{H}(0)] + \mathbb{P}_{s \sim \mathcal{M}}[ s \in \Omega_\mathcal{H}(-\gamma) - \Omega_\mathcal{H}(0)]\\
    &= \mathsf{TV}(\mathcal{M}, \mathcal{H}) + \mathbb{P}_{s \sim \mathcal{M}}[ s \in \Omega_\mathcal{H}(-\gamma) - \Omega_\mathcal{H}(0)] \tag{using property 1}\\
    &= \mathsf{TV}(\mathcal{M}, \mathcal{H}) + \mathbb{P}_{s \sim \mathcal{H}}[ s \in \Omega_\mathcal{H}(-\gamma) - \Omega_\mathcal{H}(0)] \tag{using property 2}\\
    &= \mathsf{TV}(\mathcal{M}, \mathcal{H}) + \mathbb{P}_{s \sim \mathcal{H}}[ s \in \Omega_\mathcal{H}(-\gamma)] - \mathbb{P}_{s \sim \mathcal{H}}[s \in \Omega_\mathcal{H}(0)] \tag{$\Omega_\mathcal{H}(0) \subseteq \Omega_\mathcal{H}(-\gamma)$}\\
    &= \mathsf{TV}(\mathcal{M}, \mathcal{H}) + \mathsf{FPR}_\gamma. \tag{$\mathbb{P}_{s \sim \mathcal{H}}[s \in \Omega_\mathcal{H}(0)] = 0$}
\end{align*}
For $\gamma \in [-\infty, -\tau]$, $\mathsf{TPR}_\gamma = 1$, by property 3.
Also, as $\gamma$ goes from $0$ to $-\infty$, $\mathsf{FPR}_\gamma$ goes from $0$ to $1$.
Therefore, $\mathsf{TPR}_\gamma = \min(\mathsf{FPR}_\gamma + \mathsf{TV}(\mathcal{M}, \mathcal{H}), 1)$ which is similar to Equation~\ref{eq:tpr_bound}.
Calculating the AUROC in a similar fashion as in the previous section, we get:
\[\mathsf{AUROC}(D) = \frac{1}{2} + \mathsf{TV}(\mathcal{M}, \mathcal{H}) - \frac{\mathsf{TV}(\mathcal{M}, \mathcal{H})^2}{2}.\]