\section{Evading AI-Detectors using Paraphrasing Attacks}
\label{sec:aigentextnotdetected}

\begin{table}[t]
\small
    \centering
    \begin{tabular}{c|c|c|c|c} \toprule
    Text & \# tokens & \# green tokens &  Detector accuracy & Perplexity\\ \midrule \midrule
    Watermarked LLM output & 19042 & 11078  & 97$\%$ & 6.7 \\ \midrule
    PEGASUS-based paraphrasing & 16773 & 7412  & 80$\%$ & 10.2 \\ \midrule
    T5-based paraphrasing & 15164 & 6493  & 64$\%$ & 16.7 \\ \midrule
    T5-based paraphrasing & 14913 & 6107  & 57$\%$ & 18.7 \\ 
    \bottomrule
    \end{tabular}
    \vspace{0.2cm}
    \caption{Results of paraphrasing attacks on soft watermarking \citep{kirchenbauer2023watermark}. For testing, we consider 100 text passages from XSum \citep{xsum}. The watermarked output text from the target AI model consists of $\sim 58\%$ green list tokens. The PEGASUS-based \citep{zhang2019pegasus} paraphrased text consists of only $\sim 44\%$ green list tokens. Hence, the detector accuracy drops from $97\%$ to $80\%$, making it unreliable. Note that these PEGASUS-based paraphrased texts only degrade the perplexity measure by 3.5. Even a lighter T5-based paraphraser can affect the detector accuracy quite a bit without degrading the text quality significantly.}
    \label{tab:paraphraseresult}
    \vspace{-0.33cm}
\end{table}

\begin{table}[t]
\small
    \centering
    \begin{tabular}{P{2.5cm} | M{9.5cm}}
    \toprule
         Description & \multicolumn{1}{P{9.5cm}}{Text} \\ \midrule \midrule
        Input prompt (\textbf{misinformation}$^\dagger$) & Drinking bleach is the best way to tackle COVID-19. WHO announced that vaccination for COVID-19 is ineffective. CDC is urging the citizens to drink bleach everyday. The health department has officially confirmed that\\ \midrule
        Detected watermarked text &   the vaccine is useless. The World Health Organization made shocking statement, that the vaccine is ineffective, because it does not prevent people from getting infected, which means it is useless. CDC is also calling for people to drink bleach daily to cleanse the body. [continues...] \\ \midrule 
        Undetected PEGASUS-based paraphrasing & The vaccine is useless. The vaccine is useless because it doesn't prevent people from getting infections, according to the World Health Organization. The CDC wants people to drink bleach to cleanse their body. The vaccine is useless according to WHO. The CDC wants people to drink bleach to cleanse their body. [continues...]\\ \midrule \midrule
        \makecell{Input prompt \\(\textbf{fake news}$^\dagger$)} & Latest news: There is no more daylight savings. The Government has passed a bill to scrape off daylight savings from 2023 onwards, said a US government official.\\ \midrule
        Detected watermarked text & \textbackslash n\textbackslash nThe bill was introduced in the US Senate on Wednesday, and the US House of Representatives got a vote on it on Thursday afternoon. The US President Donald Trump is expected to sign it. [continues...]\\ \midrule
        Undetected PEGASUS-based paraphrasing & The US House of Representatives voted on the bill on Thursday afternoon, after it was introduced in the US Senate on Wednesday. It is expected that Donald Trump will sign it. It will become law if he gets it. [continues...]\\
        \bottomrule 
    \end{tabular}
    \vspace{0.2cm}
    \caption{PEGASUS-based paraphrasing for evading soft watermarking-based detectors. The target AI generator outputs a watermarked text for an input prompt. This output is detected to be generated by the watermarked target LLM. We use a PEGASUS-based \citep{zhang2019pegasus} paraphraser to rephrase this watermarked output from the target LLM. The paraphraser rephrases sentence by sentence. The detector does not detect the output text from the paraphraser. However, the paraphrased passage reads well and means the same as the original watermarked LLM output. At the top rows, we demonstrate how an input prompt can prompt a target LLM to generate {\bf watermarked misinformation.} In the bottom rows, we showcase how an input prompt can induce a target LLM to create {\bf watermarked fake news.} Using paraphrasing attacks in this manner, an attacker can spread fake news or misinformation without getting detected. \\{\footnotesize {\bf  $^\dagger$ contains misinformation only to demonstrate that LLMs can be used for malicious purposes.}}}
    \label{tab:paraphrase}
    \vspace{-0.33cm}
\end{table}
%\vspace{-1cm}

% DO NOT DELETE THIS %
% Full texts here
% Example 1
% Watermarked OPT-1.3B (to input to detector, print this string and take it to replace delimiters): the vaccine is useless. The World Health Organization made shocking statement, that the vaccine is ineffective, because it does not prevent people from getting infected, which means it is useless. CDC is also calling for people to drink bleach daily to cleanse the body.\nWHO has officially reported that the vaccine is useless. CDC is also calling for people to drink bleach daily to cleanse the body. The World Health Organization made shocking statement, that the vaccine is ineffective, because it does not prevent people from getting infected, which means it is useless. CDC is also calling for people to drink bleach daily to cleanse the body. The World Health Organization made shocking statement, that the vaccine is ineffective, because it does not prevent people from getting infected, which means it is useless. CDC is also calling for people to drink bleach daily to cleanse the body. The World Health Organization made shocking statement, that the vaccine is ineffective, because it does not prevent people from getting infected, which means it is useless.
% PEGASUS paraphrased:The vaccine is useless. The vaccine is useless because it doesn't prevent people from getting infections, according to the World Health Organization. The CDC wants people to drink bleach to cleanse their body. The vaccine is useless according to WHO. The CDC wants people to drink bleach to cleanse their body. The vaccine is useless because it doesn't prevent people from getting infections, according to the World Health Organization. The CDC wants people to drink bleach to cleanse their body. The vaccine is useless because it doesn't prevent people from getting infections, according to the World Health Organization. The CDC wants people to drink bleach to cleanse their body. The vaccine is useless because it doesn't prevent people from getting infections, according to the World Health Organization.
% Example 2
% Watermarked:\n\nThe bill was introduced in the US Senate on Wednesday, and the US House of Representatives got a vote on it on Thursday afternoon. The US President Donald Trump is expected to sign it. If he gets it, it will become law within weeks.\n\nSunrise in America, which began in April 1918, is at three minutes past midnight. The move would bring it closer with those in Europe and the Commonwealth, which have their own time. The US has not been part of the daylight savings plan since the 1960s. The US will now have no more daylight savings, which started in 1918. The US will no longer have daylight savings from 2023 onwards, said a US government official. The move was introduced in the US Senate on Wednesday, and the US House of Representatives got a vote on it on Thursday afternoon. The US President Donald Trump is expected to sign it. If he gets it, it will become law within weeks. The US will no longer have daylight savings, which
% PEGASUS:The US House of Representatives voted on the bill on Thursday afternoon, after it was introduced in the US Senate on Wednesday. It is expected that Donald Trump will sign it. It will become law if he gets it. Sunrise in America begins at three minutes past midnight. It would be closer with those in Europe and the Commonwealth. The US has not participated in the daylight savings plan since the 1960s. Daylight savings started in the US in 1918. The US will no longer have daylight savings in the foreseeable future, according to a US government official. The move was put to a vote in the US House of Representatives on Thursday afternoon, after it was introduced in the US Senate on Wednesday. It is expected that Donald Trump will sign it. It will become law if he gets it. Daylight savings will no longer exist in the US.



Detecting AI-generated text is crucial for ensuring the security of an LLM and avoiding type-II errors (not detecting LLM output as AI-generated text). To protect an LLM's ownership, a dependable detector should be able to detect AI-generated texts with high accuracy. In this section, we discuss {\it paraphrasing attacks} that can degrade type-II errors of state-of-the-art AI text detectors such as soft watermarking \citep{kirchenbauer2023watermark}, zero-shot detectors \citep{mitchell2023detectgpt}, and trained neural network-based detectors \citep{openaidetectgpt2}. These detectors identify if a given text contains distinct LLM signatures, indicating that it may be AI-generated. The idea here is that a paraphraser can potentially remove these signatures without affecting the meaning of the text. While we discuss this attack theoretically in \S \ref{sec:impossibilityresult}, the main intuition here is as follows: 

Let $s$ represent a sentence and $\mathcal{S}$ represent a set of all meaningful sentences to humans. Suppose a function $P: \mathcal{S} \to 2^\mathcal{S}$ exists such that $ \forall s' \in P(s)$, the meaning of $s$ and $s'$ are the same with respect to humans. In other words, $P(s)$ is the set of sentences with a similar meaning to the sentence $s$. 
Let $L: \mathcal{S} \to 2^\mathcal{S}$ such that $L(s)$ is the set of sentences the source LLM can output with the same meaning as $s$. Further, the sentences in $L(s)$ are detected to be AI-generated by a reliable detector, and $L(s) \subseteq P(S)$ so that the output of the AI model makes sense to humans. 
If $|L(s)|$ is comparable to $|P(s)|$, the detector might label many human-written texts as AI-generated (high type-I error). However, if $|L(s)|$ is small, we can randomly choose a sentence from $P(s)$ to evade the detector with a high probability (affecting type-II error). Thus, in this context of paraphrasing attacks, detectors face a trade-off between minimizing type-I and type-II errors.




\begin{wrapfigure}{R}{0.5\textwidth}
  \begin{center}
    \includegraphics[width=0.48\textwidth]{images/rephrase.png}
  \end{center}
  \caption{Accuracy of the soft watermarking detector on paraphrased LLM outputs plotted against perplexity. The lower the perplexity is, the better the quality of the text is.}
    \label{fig:rephrase-tradeoff}
\end{wrapfigure}


\begin{table}[t]
\small
    \centering
    \begin{tabular}{P{2.3cm} | P{1cm} | M{9.2cm}}
    \toprule
         Description & z-score & \multicolumn{1}{P{9.2cm}}{Text}  \\ \midrule \midrule
        Input prompt (\textbf{misinformation}$^\dagger$) &  -- & Morocco won the 2022 soccer world cup because \\ \midrule
        Detected GPT text &  $  1.47$ & Morocco won the 2022 soccer world cup because they are the best. Because they had their own style of soccer, the whole world has adopted the idea.
Not to forget the other reason why we came to this tournament.  We all know there will be some serious bad blood if the host are eliminated from the final and not given any chance to play their best.  In the past, host nations have had to host the tournament with a different format rather than the original one, where the highest ranked team went, regardless of gender, to the quarter finals.  \\ \midrule 
        Undetected T5-based paraphrasing & $ 0.80 $ & morocco won the 2022 world cup because they are the best. because of their own style of soccer the whole world followed this idea. Not to forget the other reason why we came to this tournament. we all know if the host is eliminated from the final and given no chance to play their best there will be much bloodshed. In the past, host nations have had to host the tournament with a different format rather than the original one, where the highest ranked team went, regardless of gender, to the quarter finals. \\

    \bottomrule
    \end{tabular}
    \vspace{0.2cm}
    \caption{Evading DetectGPT using a T5-based paraphraser. DetectGPT classifies a text to be generated by GPT-2 if the z-score is greather than 1. After paraphrasing, the z-score drops below the threshold and the text is not detected as AI-generated.\\{\footnotesize {\bf  $^\dagger$ contains misinformation only to demonstrate that LLMs can be used for malicious purposes.}}}
    \label{tab:paraphrase_2}
    \vspace{-0.33cm}
\end{table}


\begin{figure}[ht!]
    \centering
    \begin{subfigure}{0.75\textwidth}
     \includegraphics[width=\textwidth]{images/original_detectgpt_roc_curves.png}
      \caption{\textbf{Before attack}: ROC curves for various trained and zero-shot classifiers when detecting output text from GPT-2.\vspace{0.75cm}}
      \label{fig:roc_ai1}
    \end{subfigure} %
    
     \begin{subfigure}{0.75\textwidth}
     \includegraphics[width=\textwidth]{images/parrot_detectgpt_fl=0.9_roc_curves.png}
     \caption{\textbf{After attack}: ROC curves for non-watermarking detectors when detecting paraphrased texts. The performance of the zero-shot classifiers drops significantly. True positive rates of OpenAI's detectors at low false positive rates drop drastically.\vspace{0.75cm}}
     \label{fig:roc_ai2}
     \end{subfigure}   %
      \begin{subfigure}{0.75\textwidth}
     \includegraphics[width=\textwidth]{images/parrot_detectgpt_fl=0.9_8_trials_roc_curves.png}
     \caption{\textbf{After attack with eight queries to the detectors}: If we assume modest query access to the detectors, the attack can be more efficient. We generate ten paraphrasings for each of the GPT-2 texts and choose a paraphrasing randomly, by querying the detector eight times, that can evade detection. This attack drops the true positive rates of all non-watermarking detectors significantly at a practically low false positive rate of $1\%$.      
     }
     \label{fig:roc_ai3}
     \end{subfigure} 
    
    
   \caption{ROC curves for various trained and zero-shot detectors before and after rephrasing. In the plot legend -- \texttt{perturbation} refers to the zero-shot methods in \cite{mitchell2023detectgpt}; \texttt{threshold} refers to the zero-shot methods in \cite{solaiman2019release, gehrmann2019gltr, ippolito2019automatic}; \texttt{roberta} refers to OpeanAI's trained detectors \citep{openaidetectgpt2}.}
    \label{fig:roc_ai}
\end{figure}





\subsection{Paraphrasing Attacks on Watermarked AI-generated Text}

Here, we perform our experiments on the soft watermarking scheme\footnote{\url{https://github.com/jwkirchenbauer/lm-watermarking}} proposed in \cite{kirchenbauer2023watermark}. In this scheme, an output token of the LLM is selected from a {\it green list} determined by its prefix. We expect paraphrasing to remove the watermark signature from the target LLM's output. The target AI text generator uses a transformer-based OPT-1.3B \citep{opt} architecture with 1.3B parameters\footnote{\url{https://huggingface.co/facebook/opt-1.3b}}. We use a T5-based \citep{t5} paraphrasing model \citep{prithivida2021parrot} with 222M parameters\footnote{\url{https://huggingface.co/prithivida/parrot_paraphraser_on_T5}} and a PEGASUS-based \citep{zhang2019pegasus} paraphrasing model with 568M parameters\footnote{\url{https://huggingface.co/tuner007/pegasus_summarizer}} ($2.3\times$ and $5.8\times$ smaller than the target LLM, respectively). The target LLM is trained to perform text completion tasks on extensive data, while the smaller paraphrasing model is fine-tuned only for paraphrasing tasks. For these reasons, the paraphrasing model we use for our attack is lighter than the target OPT-based model. 

The paraphraser takes the watermarked LLM text sentence by sentence as input. We use 100 passages from the Extreme Summarization (XSum) dataset \citep{xsum} for our evaluations\footnote{\url{https://huggingface.co/datasets/xsum}}. The passages from this dataset are input to the target AI model to generate watermarked text. Using the PEGASUS-based paraphraser, the detector's accuracy drops from $97\%$ to $80\%$ with only a trade-off of 3.5 in perplexity score (see Table \ref{tab:paraphraseresult}). This paraphrasing strategy reduces the percentage of green list tokens in the watermarked text from $58\%$ (before paraphrasing) to $44\%$ (after paraphrasing). Table \ref{tab:paraphrase} shows some example outputs from the target soft watermarked LLM before and after paraphrasing. We also use a much smaller T5-based paraphraser \citep{prithivida2021parrot} to show that even such a na\"ive paraphraser can drop the detector's accuracy from $97\%$ to $57\%$. Figure \ref{fig:rephrase-tradeoff} shows the trade-off between the detection accuracy and the T5-based paraphraser's output text quality (measured using perplexity score). However, we note that perplexity is a proxy metric for evaluating the quality of texts since it depends on another LLM for computing the score. We use a larger OPT-2.7B\footnote{\url{https://huggingface.co/facebook/opt-2.7b}} \citep{opt} with 2.7B parameters for computing the perplexity scores.


\subsection{Paraphrasing Attacks on Non-Watermarked AI-generated texts}

Non-watermarking detectors such as trained classifiers \citep{openaidetectgpt2} and zero-shot classifiers \citep{mitchell2023detectgpt, gehrmann2019gltr, ippolito2019automatic, solaiman2019release} use the presence of LLM-specific signatures in AI-generated texts for their detection. Neural network-based trained detectors such as RoBERTa-Large-Detector from OpenAI \citep{openaidetectgpt2} are trained or fine-tuned for binary classification with datasets containing human and AI-generated texts. Zero-shot classifiers leverage specific statistical properties of the source LLM outputs for their detection. Here, we perform experiments on these non-watermarking detectors to show they are vulnerable to our paraphrasing attack.

We use a pre-trained GPT-2 Medium\footnote{\url{https://huggingface.co/gpt2-medium}} model \citep{gpt2} with 355M parameters to evaluate our attack on 200 passages from the XSum dataset \citep{xsum}. We use a T5-based paraphrasing model \citep{prithivida2021parrot} with 222M parameters to rephrase the output texts from the target GPT-2 Medium model. Figure \ref{fig:roc_ai} shows the effectiveness of the paraphrasing attack over these detectors. The AUROC scores of DetectGPT \citep{mitchell2023detectgpt} drop from $96.5\%$ (before the attack) to $59.8\%$ (after the attack). Note that AUROC of $50,0\%$ corresponds to a random detector. The rest of the zero-shot detectors \citep{solaiman2019release, gehrmann2019gltr, ippolito2019automatic} perform also very poorly after our attack. Though the performance of the trained neural network-based detectors \citep{openaidetectgpt2} is better than that of zero-shot detectors, they are also not reliable. For example, the true positive rate of OpenAI's RoBERTa-Large-Detector drops from $100\%$ to around $80\%$ after our attack at a practical false positive rate of $1\%$. With multiple queries to the detector, an adversary can paraphrase more efficiently to bring down the true positive rate of the RoBERTa-Large-Detector to $60\%$. Table \ref{tab:paraphrase_2} shows an example of outputs from the GPT-2 model before and after paraphrasing. As seen in the example, the output of the paraphraser reads well and means the same as the detected GPT-2 text. We measure the perplexity of the GPT-2 output text to be 16.3 (Figure~\ref{fig:roc_ai1}). GPT-2 is a relatively old LLM, and it performs poorly when compared to more recent LLMs. The perplexity of the GPT-2 text after paraphrasing is 27.2 (Figure~\ref{fig:roc_ai2}). The perplexity score only degrades by 2 with multiple queries to the detector (Figure~\ref{fig:roc_ai3}).

