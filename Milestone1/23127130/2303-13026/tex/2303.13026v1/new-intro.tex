\section{Introduction}

The last decade has seen significant academic research on DRAM caches, and today
these ideas are becoming a reality with CPU vendors implementing DRAM cache-based computer systems, e.g., Intel's Cascade Lake and Sapphire Rapids.
Hardware-managed DRAM caches are seen as one way to enable heterogeneous memory systems (e.g., systems with DRAM and non-volatile memory) to be more easily programmable.
DRAM caches are transparent to the programmer and easier to use than manual data movement.

However, recent work has shown that these transparent hardware-based data movement designs are much less efficient than manual data movement~\cite{hildebrand2021case}.
While the work by Hildebrand et al.~\cite{hildebrand2021case} and other recent work investigating Intel's Cascade Lake systems provides some insight into real implementations on DRAM caches~\cite{izraelevitz2019basic,wang2020characterizing}, there is a gap in the community's access to cycle-level simulation models for DRAM caches.
This paper describes a new \gem{}-based model of a unified DRAM cache controller inspired by the Cascade Lake hardware to fill this gap.

Previous work has explored many aspects of DRAM cache design in simulation such as the replacement policy, caching granularity~\cite{qureshi2012fundamental,jevdjic2013stacked}, dram cache tag placement~\cite{huang2014atcache,loh2012supporting,loh2011efficiently}, associativity~\cite{qureshi2012fundamental,kotra2018chameleon,young2018accord}, and other metadata to improve performance~\cite{loh2011efficiently,jevdjic2013stacked,young2018accord}.
These mostly high-level memory system design investigations can appropriately be evaluated with trace-based or non-cycle-level simulation.
However, as shown in recent work, the micro-architecture of the unified DRAM and non-volatile main memory (NVRAM) controller can lead to unexpected performance pathologies not captured in these prior works (e.g., Hildebrand et al. showed that a dirty miss to the DRAM cache requires up to \emph{five accesses} to memory~\cite{hildebrand2021case}).

Thus, to better understand these realistic DRAM cache systems, it is imperative to build a detailed DRAM cache simulation model which can be used to perform a design space exploration around the DRAM cache idea.
The previous research works on DRAM cache design improvements do not provide any (open-source) DRAM cache modeling platform for a detailed micro-architectural and timing analysis.
To the best of our knowledge, most research works do not consider systems where the hardware-managed DRAM cache and NVRAM are sharing the same physical interface and are controlled by a unified memory controller (as is the case in real platforms like Intel Cascade Lake).

In this work, we describe our unified DRAM cache and main memory controller (\textit{UDCC}) cycle-level DRAM cache model for \gem{}~\cite{lowepower2020gem5}.
The protocol takes inspiration from the actual hardware providing DRAM cache, such as Intel's Cascade Lake, in which an NVRAM accompanies a DRAM cache as the off-chip main memory sharing the same bus.
To model such hardware, we leverage the cycle-level DRAM~\cite{hansson2014simulating} and NVRAM~\cite{gem5-workshop-presentation} models in \gem{}.
Our model implements the timing and micro-architectural details enforced by the memory interfaces including the DRAM timing constraints, scheduling policies, buffer sizes, and internal queues.
We propose a DRAM cache model that is direct-mapped, insert-on-miss, and write-back to model Intel's Cascade Lake design.
% FUTURE WORK: though in our model these policy decisions are parameterized \note{IS THIS TRUE???}.

Using this model, we present validation data and investigate five case studies.

\emph{What is the impact of memory scheduling policies in a unified DRAM cache and memory controller?}
We find that using FR-FCFS is highly impactful when the cache hit ratio is high, but less so when the hit ratio is low and the NVRAM's bandwidth limits performance.

\emph{What is the impact of DRAM technology on performance and memory controller architecture?}
We find that higher performing memory technologies require more buffering to achieve peak performance. 
Moreover, we find that the composition of the memory access patterns and their hit/miss ratio on DRAM cache, 
can also affect the amount of buffering to achieve the peak bandwidth.

\emph{What is the impact of backing ``main memory'' performance?}
We find that while slower backing memory hurts performance, the performance of the backing memory does not have a significant affect on the micro-architecture of the cache controller.

\emph{What is the impact of the UDCC model for full-system applications?}
We find that our model shows similar performance characteristics on real applications as previously shown on real hardware providing further evidence for the importance of cycle-level simulation.

\emph{What is the impact of NVRAM wear leveling on memory system performance with a DRAM cache?}
We find that while wear leveling has a very small direct impact, the impact when using NVRAM as backing memory with a DRAM cache can be much higher. Although only 1 in 14,000 requests experience a wear-leveling event, the performance impact is up to an 8\% slowdown.

Our model is open-source and publicly available for the use of research community~\cite{dcacheGem5Code} and will be integrated into \gem{} mainstream. Using this new model which implements the micro-architectural details of realistic DRAM caches on a simulator can help find any potential improvement for the next generation of memory systems.

%The rest of the paper is organized as follows...
