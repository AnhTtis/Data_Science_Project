\begin{table*}[!t]
  \centering
  \resizebox{0.75\textwidth}{!}{
  % \begin{tabular}{@{} >{\raggedright}p{5.2cm} >{\raggedright}p{2.2cm} >{\raggedright}p{2.2cm} >{\raggedright}p{2cm} p{2cm}}
  \begin{tabular}{lccccc}
    \toprule  \\[-1em]
    Dataset & \#Images & \#Classes & Category Type & Shift Type & Metadata \\
    \midrule
    Office-31~\cite{office31} & 4.1k & 31 & Objects & Web/real/dslr & \cross \\
    Office-Home~\cite{venkateswara2017deep} & 15.5k & 65 & Objects & Style & \cross \\
    visDA~\cite{peng2017visda} & 207k & 12 & Objects & sim2real & \cross \\
    DomainNet~\cite{peng2019moment} & 587k & 345 & Objects & style & \cross \\
    Dollar Street~\cite{DBLP:journals/corr/abs-1906-02659, prabhu2022can} & 11.7k & 58 & Objects & Household income & \cross \\
    \midrule
    \textit{Proposed Benchmark} \\
    \GeoI & - & - & Objects & \multirow{2}{*}{Geographies} & \multirow{2}{*}{\tick}  \\
    % \multirow{2}{*}{GPS coordinates, hashtags, textual captions}
    \GeoP & 567k & 205 & Places/Scenes \\
    \bottomrule \\
  \end{tabular}
  }
  \vspace{-1em}
  \captionsetup{width=0.9\textwidth}
  \caption{\label{tab:comparison-table} Comparison of existing benchmarks for unsupervised domain adaptation. In contrast to existing benchmarks, \Ours{} is the first large-scale benchmark to study the problem of geographical domain adaptation across diverse tasks like scene and object classification,  }
  \vspace{-1em}
\end{table*}