% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage[review]{cvpr}      % To produce the REVIEW version
% \usepackage{cvpr}              % To produce the CAMERA-READY version
\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{array}
\usepackage{xcolor}
\usepackage{adjustbox}
\usepackage{wrapfig}
\usepackage[table]{colortbl}
\usepackage{multirow}

\input{cvpr2023-author_kit-v1_1-1/latex/def}


% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{6324} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{MELTR: Meta Loss Transformer for\\ Learning to Fine-tune Video Foundation Models}

\newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}
\author{
Dohwan Ko\textsuperscript{\rm 1}\thanks{Equal contribution.}\hspace{0.4cm}
Joonmyung Choi\textsuperscript{\rm 1}\samethanks\hspace{0.4cm}
Hyeong Kyu Choi\textsuperscript{\rm 1}\hspace{0.4cm} \\
Kyoung-Woon On\textsuperscript{\rm 2}\hspace{0.4cm} 
Byungseok Roh\textsuperscript{\rm 2}\hspace{0.4cm}
Hyunwoo J. Kim\textsuperscript{\rm 1}\thanks{Corresponding author.}\vspace{0.3cm} \\
\textsuperscript{\rm 1}Department of Computer Science and Engineering, Korea University\hspace{0.4cm}\vspace{0cm} \textsuperscript{\rm 2}Kakao Brain \\
\tt\small \{ikodoh, pizard, imhgchoi, hyunwoojkim\}@korea.ac.kr \vspace{0cm}
\\\tt\small \{kloud.ohn, peter.roh\}@kakaobrain.com \vspace{0cm}
}

\maketitle


%%%%%%%%% ABSTRACT
\input{Sections/0_Abstract/abstract}
%%%%%%%%% BODY TEXT
\input{Sections/1_Introduction/introduction}
\input{Sections/2_Related_Work/related}
\input{Sections/3_Preliminaries/0_preliminaries}
\input{Sections/4_Method/0_method}
\input{Sections/5_Experiments/0_experiments}
\input{Sections/6_Conclusion/conclusion}

\noindent \textbf{Acknowledgments.}
This work was partly supported by ICT Creative Consilience program (IITP-2023-2020-0-01819) supervised by the IITP; Electronics and Telecommunications Research Institute (ETRI) grant funded by the Korean government (23ZS1200, Fundamental Technology Research for Human-Centric Autonomous Intelligent Systems); and KaKaoBrain corporation.


\appendix

\section*{\Large Appendix}
\input{Appendix/settings}
\input{Appendix/datasets}
\input{Figures/apdx_grad}
\input{Appendix/gamma}
\input{Appendix/linear}
\input{Figures/box}
\input{Tables/apdx_gamma}
\input{Tables/apdx_arch}
\input{Appendix/input}
\input{Figures/nonlinearity}
\input{Appendix/nonlinearity}
\input{Tables/univl_advanced}
\input{Tables/apdx_quan}
\input{Appendix/univl}
\input{Appendix/quantitative}





%%%%%%%%% REFERENCES
{\small
\bibliographystyle{unsrt}
% \bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
