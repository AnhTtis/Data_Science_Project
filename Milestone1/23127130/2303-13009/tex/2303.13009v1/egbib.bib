@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



% 학회
% Meta Weight Net
@inproceedings{shu2019meta,
  title={Meta-weight-net: Learning an explicit mapping for sample weighting},
  author={Shu, Jun and Xie, Qi and Yi, Lixuan and Zhao, Qian and Zhou, Sanping and Xu, Zongben and Meng, Deyu},
  booktitle={NeurIPS},
  year={2019}
}
% Transformer
@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  booktitle={NeurIPS},
  year={2017}
}
% BERT
@inproceedings{devlin2019bert,
    title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
    booktitle = {NACCL},
    year = {2019}
}
% GPT-3
@inproceedings{brown2020language,
    title = {Language Models are Few-Shot Learners},
    author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
    booktitle = {NeurIPS},
    year = {2020}
}
% CoMMA
@inproceedings{tan2021look,
    author = {Reuben Tan and Bryan A. Plummer and Kate Saenko and Hailin Jin and Bryan Russell},
    title = {Look at What I’m Doing: Self-Supervised Spatial Grounding of Narrations in Instructional Videos},
    booktitle = {NeurIPS},
    year = {2021} 
}
% VCLR
@InProceedings{kuang2021video,
    author    = {Kuang, Haofei and Zhu, Yi and Zhang, Zhi and Li, Xinyu and Tighe, Joseph and Schwertfeger, S\"oren and Stachniss, Cyrill and Li, Mu},
    title     = {Video Contrastive Learning With Global Context},
    booktitle = {ICCVW},
    year      = {2021}
}
% VTN
@inproceedings{neimark2021video,
    title={Video Transformer Network},
    author={Daniel Neimark and Omri Bar and Maya Zohar and Dotan Asselmann},
    booktitle={ICCVW},
    year={2021}
}
% Merlot
@inproceedings{zellers2021merlot,
    title={MERLOT: Multimodal Neural Script Knowledge Models},
    author={Rowan Zellers and Ximing Lu and Jack Hessel and Youngjae Yu and Jae Sung Park and Jize Cao and Ali Farhadi and Yejin Choi},
    booktitle={NeurIPS},
    year={2021}
}
% VATT
@inproceedings{akbari2021vatt,
    title={VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text},
    author={Hassan Akbari and Liangzhe Yuan and Rui Qian and Wei-Hong Chuang and Shih-Fu Chang and Yin Cui and Boqing Gong},
    booktitle={NeurIPS},
    year={2021}
}
% MMCA
@INPROCEEDINGS{wei2020multi,
    author={Wei, Xi and Zhang, Tianzhu and Li, Yan and Zhang, Yongdong and Wu, Feng},
    booktitle={CVPR}, 
    title={Multi-Modality Cross Attention Network for Image and Sentence Matching}, 
    year={2020}
}
% MMT
@inproceedings{gabeur2020multi,
    author = {Gabeur, Valentin and Sun, Chen and Alahari, Karteek and Schmid, Cordelia},
    title = {Multi-Modal Transformer for Video Retrieval},
    year = {2020},
    booktitle = {ECCV}
}
% TACo
@InProceedings{yang2021taco,
    author    = {Yang, Jianwei and Bisk, Yonatan and Gao, Jianfeng},
    title     = {TACo: Token-Aware Cascade Contrastive Learning for Video-Text Alignment},
    booktitle = {ICCV},
    year      = {2021}
}
% XViT
@inproceedings{bulat2021space,
    title={Space-time Mixing Attention for Video Transformer},
    author={Adrian Bulat and Juan-Manuel Perez-Rua and Swathikiran Sudhakaran and Brais Martinez and Georgios Tzimiropoulos},
    booktitle={NeurIPS},
    year={2021}
}
% Timesformer
@inproceedings{bertasius2021space,
  author    = {Gedas Bertasius and Heng Wang and Lorenzo Torresani},
  title     = {Is Space-Time Attention All You Need for Video Understanding?},
  booktitle = {ICML},
  year      = {2021}
}
% COOT
@inproceedings{ging2020coot,
    author = {Ging, Simon and Zolfaghari, Mohammadreza and Pirsiavash, Hamed and Brox, Thomas},
    booktitle = {NeurIPS},
    title = {COOT: Cooperative Hierarchical Transformer for Video-Text Representation Learning},
    year = {2020}
}
% CLIP
@InProceedings{radford2021learning,
  title = 	 {Learning Transferable Visual Models From Natural Language Supervision},
  author =   {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle = 	 {ICML},
  year = 	 {2021}
}
% HOWTO100M
@InProceedings{miech2019howto100m,
  title={HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips},
  author={Antoine Miech and Dimitri Zhukov and Jean-Baptiste Alayrac and Makarand Tapaswi and Ivan Laptev and Josef Sivic},
  booktitle={ICCV},
  year={2019}
}
% hglmm
@inproceedings{klein2015associating,
author = {Klein, Benjamin and Lev, Guy and Sadeh, Gil and Wolf, Lior},
year = {2015},
title = {Associating neural word embeddings with deep image representations using Fisher Vectors},
booktitle = {CVPR}
}
% CLIP for video
@inproceedings{portillo2021straightforward,
  author    = {Jes{\'{u}}s Andr{\'{e}}s Portillo{-}Quintero and Jos{\'{e}} Carlos Ortiz{-}Bayliss and Hugo Terashima{-}Mar{\'{\i}}n},
  title     = {A Straightforward Framework for Video Retrieval Using CLIP},
  booktitle = {MCPR},
  year      = {2021}
}
% MDMMT
@InProceedings{dzabraev2021mdmmt,
    author    = {Dzabraev, Maksim and Kalashnikov, Maksim and Komkov, Stepan and Petiushko, Aleksandr},
    title     = {MDMMT: Multidomain Multimodal Transformer for Video Retrieval},
    booktitle = {CVPRW},
    year      = {2021}
}
% EMT
@INPROCEEDINGS {zhou2018end,
author = {L. Zhou and Y. Zhou and J. J. Corso and R. Socher and C. Xiong},
booktitle = {CVPR},
title = {End-to-End Dense Video Captioning with Masked Transformer},
year = {2018}
}
% E2vidD6-MASSvid-BiD
@inproceedings{huang2020multimodal,
    title = {Multimodal Pretraining for Dense Video Captioning},
    author = {Huang, Gabriel and Pang, Bo and Zhu, Zhenhai and Rivera, Clara  and Soricut, Radu},
    booktitle = {AACL},
    year = {2020}
}
% OA-BTG
@inproceedings{zhang2019object,
      title={Object-aware Aggregation with Bidirectional Temporal Graph for Video Captioning}, 
      author={Junchao Zhang and Yuxin Peng},
      year={2019},
      booktitle={CVPR}
}
% POS-VCT
@InProceedings{hou2019joint,
author = {Hou, Jingyi and Wu, Xinxiao and Zhao, Wentian and Luo, Jiebo and Jia, Yunde},
title = {Joint Syntax Representation Learning and Visual Cue Translation for Video Captioning},
booktitle = {ICCV},
year = {2019}
}
% MIL-NCE
@inproceedings{miech2020end,
   title={{E}nd-to-{E}nd {L}earning of {V}isual {R}epresentations from {U}ncurated {I}nstructional {V}ideos},
   author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
   booktitle={CVPR},
   year={2020},
}
% ActBERT
@inproceedings{zhu2020actbert,
  author    = {Linchao Zhu and Yi Yang},
  title     = {ActBERT: Learning Global-Local Video-Text Representations},
  booktitle = {CVPR},
  year      = {2020}
}
% MAXL
@inproceedings{liu2019self,
 author = {Liu, Shikun and Davison, Andrew and Johns, Edward},
 booktitle = {NeurIPS},
 title = {Self-Supervised Generalisation with Meta Auxiliary Learning},
 year = {2019}
}
% Auxilearn
@inproceedings{navon2020auxiliary,
title={Auxiliary Learning by Implicit Differentiation},
author={Aviv Navon and Idan Achituve and Haggai Maron and Gal Chechik and Ethan Fetaya},
booktitle={ICLR},
year={2021}
}
% Manual Auxiary Learning
@article{liebel2018auxiliary,
  title={Auxiliary tasks in multi-task learning},
  author={Liebel, Lukas and K{\"o}rner, Marco},
  journal={arXiv preprint arXiv:1805.06334},
  year={2018}
}
@inproceedings{Toshniwal2017,
  author={Shubham Toshniwal and Hao Tang and Liang Lu and Karen Livescu},
  title={Multitask Learning with Low-Level Auxiliary Tasks for Encoder-Decoder Based Speech Recognition},
  year={2017},
  booktitle={Interspeech},
}
% SELAR
@inproceedings{hwang2020self,
 author = {Hwang, Dasol and Park, Jinyoung and Kwon, Sunyoung and Kim, KyungMin and Ha, Jung-Woo and Kim, Hyunwoo J},
 booktitle = {NeurIPS},
 title = {Self-supervised Auxiliary Learning with Meta-paths for Heterogeneous Graphs},
 year = {2020}
}
% AuxSegNet
@inproceedings{xu2021leveraging,
  title={Leveraging Auxiliary Tasks with Affinity Learning for Weakly Supervised Semantic Segmentation},
  author={Xu, Lian and Ouyang, Wanli and Bennamoun, Mohammed and Boussaid, Farid and Sohel, Ferdous and Xu, Dan},
  booktitle={ICCV},
  year={2021}
}
% MGSA
@inproceedings{chen2019motion,
  title={Motion guided spatial attention for video captioning},
  author={Chen, Shaoxiang and Jiang, Yu-Gang},
  booktitle={AAAI},
  year={2019}
}
% ORG-TRL
@inproceedings{zhang2020object,
  author    = {Ziqi Zhang and Yaya Shi and Chunfeng Yuan and Bing Li and Peijin Wang and Weiming Hu and Zheng{-}Jun Zha},
  title     = {Object Relational Graph With Teacher-Recommended Learning for Video Captioning},
  booktitle = {CVPR},
  year      = {2020}
}
% VideoCLIP
@inproceedings{xu2021videoclip,
    title = {VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding},
    author = {Xu, Hu  and Ghosh, Gargi  and Huang, Po-Yao  and Okhonko, Dmytro  and Aghajanyan, Armen  and Metze, Florian  and   Zettlemoyer, Luke  and Feichtenhofer, Christoph},
    booktitle = {EMNLP},
    year = {2021}
}
% Picknet
@inproceedings{chen2018less,
  title={Less is more: Picking informative frames for video captioning},
  author={Chen, Yangyu and Wang, Shuhui and Zhang, Weigang and Huang, Qingming},
  booktitle={ECCV},
  year={2018}
}
% MARN
@article{pei2019marn,
  title={Memory-Attended Recurrent Network for Video Captioning},
  author={Wenjie Pei and Jiyuan Zhang and Xiangrong Wang and Lei Ke and Xiaoyong Shen and Yu-Wing Tai},
  journal={CVPR},
  year={2019}
}
% ClipBERT
@InProceedings{lei2021clipbert,
    author    = {Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L. and Bansal, Mohit and Liu, Jingjing},
    title     = {Less Is More: ClipBERT for Video-and-Language Learning via Sparse Sampling},
    booktitle = {CVPR},
    year      = {2021}
}
% JSFusion
@inproceedings{yu2018joint,
  title={A joint sequence fusion model for video question answering and retrieval},
  author={Yu, Youngjae and Kim, Jongseok and Kim, Gunhee},
  booktitle={ECCV},
  year={2018}
}
% T2VLAD
@inproceedings{wang2021t2vlad,
  title={T2vlad: global-local sequence alignment for text-video retrieval},
  author={Wang, Xiaohan and Zhu, Linchao and Yang, Yi},
  booktitle={CVPR},
  year={2021}
}
% YouCook2
@inproceedings{zhou2018towards,
  title={Towards automatic learning of procedures from web instructional videos},
  author={Zhou, Luowei and Xu, Chenliang and Corso, Jason J},
  booktitle={AAAI},
  year={2018}
}
% MSRVTT
@inproceedings{xu2016msr,
  title={Msr-vtt: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={CVPR},
  year={2016}
}
% TGIF
@inproceedings{jang2017tgif,
  title={Tgif-qa: Toward spatio-temporal reasoning in visual question answering},
  author={Jang, Yunseok and Song, Yale and Yu, Youngjae and Kim, Youngjin and Kim, Gunhee},
  booktitle={CVPR},
  year={2017}
}
% MSVD
@inproceedings{xu2017video,
  title={Video question answering via gradually refined attention over appearance and motion},
  author={Xu, Dejing and Zhao, Zhou and Xiao, Jun and Wu, Fei and Zhang, Hanwang and He, Xiangnan and Zhuang, Yueting},
  booktitle={MM},
  year={2017}
}
@inproceedings{chen2011collecting,
  title={Collecting highly parallel data for paraphrase evaluation},
  author={Chen, David and Dolan, William B},
  booktitle={ACL},
  year={2011}
}
% MOSI
@article{zadeh2016mosi,
  title={Mosi: multimodal corpus of sentiment intensity and subjectivity analysis in online opinion videos},
  author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},
  journal={arXiv preprint arXiv:1606.06259},
  year={2016}
}
% CIDEr
@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={CVPR},
  year={2015}
}
% BLEU
@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={ACL},
  year={2002}
}
% METEOR
@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={ACLW},
  year={2005}
}
% DPC
@inproceedings{shi2019dense,
  title={Dense procedure captioning in narrated instructional videos},
  author={Shi, Botian and Ji, Lei and Liang, Yaobo and Duan, Nan and Chen, Peng and Niu, Zhendong and Zhou, Ming},
  booktitle={ACL},
  year={2019}
}
% ADAM
@inproceedings{kingma2015adam,
  author    = {Diederik P. Kingma and Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {ICLR},
  year      = {2015}
}
% Focal Loss
@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={ICCV},
  year={2017}
}
% STOCBIO
@inproceedings{ji2021bilevel,
  title={Bilevel optimization: Convergence analysis and enhanced design},
  author={Ji, Kaiyi and Yang, Junjie and Liang, Yingbin},
  booktitle={ICML},
  year={2021}
}

% 저널
% VideoBERT
@article{sun2019videobert,
    author    = {Chen Sun and Austin Myers and Carl Vondrick and Kevin Murphy and Cordelia Schmid},
    title     = {VideoBERT: A Joint Model for Video and Language Representation Learning},
    journal   = {CoRR},
    year      = {2019}
}
% CLIP2Video
@article{fang2021clip2video,
  author    = {Han Fang and Pengfei Xiong and Luhui Xu and Yu Chen},
  title     = {CLIP2Video: Mastering Video-Text Retrieval via Image CLIP},
  journal   = {CoRR},
  year      = {2021},
}
% SibNet
@article{liu2020sibnet,
  title={Sibnet: Sibling convolutional encoder for video captioning},
  author={Liu, Sheng and Ren, Zhou and Yuan, Junsong},
  journal={TPAMI},
  year={2020}
}
% ROUGE-L
@article{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  journal={Text summarization branches out},
  year={2004}
}

% 아카이브
% codex
@misc{chen2021evaluating,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      journal={arXiv preprint arXiv:2107.03374}
}
% univl
@misc{luo2020univl,
      title={UniVL: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation}, 
      author={Huaishao Luo and Lei Ji and Botian Shi and Haoyang Huang and Nan Duan and Tianrui Li and Jason Li and Taroon Bharti and Ming Zhou},
      year={2020},
      journal={arXiv preprint arXiv:2002.06353}
}
% CBT
@misc{sun2019learning,
      title={Learning Video Representations using Contrastive Bidirectional Transformer}, 
      author={Chen Sun and Fabien Baradel and Kevin Murphy and Cordelia Schmid},
      year={2019},
      journal={arXiv preprint arXiv:1906.05743}
}
% HERO
@misc{li2020hero,
      title={HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training}, 
      author={Linjie Li and Yen-Chun Chen and Yu Cheng and Zhe Gan and Licheng Yu and Jingjing Liu},
      year={2020},
      journal={arXiv preprint arXiv:2005.00200}
}
% CAMoE
@misc{cheng2021improving,
      title={Improving Video-Text Retrieval by Multi-Stream Corpus Alignment and Dual Softmax Loss}, 
      author={Xing Cheng and Hezheng Lin and Xiangyu Wu and Fan Yang and Dong Shen},
      year={2021},
      journal={arXiv preprint arXiv:2109.04290}
}
% CLIP2TV
@misc{gao2021clip2tv,
      title={CLIP2TV: An Empirical Study on Transformer-based Methods for Video-Text Retrieval}, 
      author={Zijian Gao and Jingyu Liu and Sheng Chen and Dedan Chang and Hao Zhang and Jinwei Yuan},
      year={2021},
      journal={arXiv preprint arXiv:2111.05610}
}
% FLORENCE
@misc{yuan2021florence,
      title={Florence: A New Foundation Model for Computer Vision}, 
      author={Lu Yuan and Dongdong Chen and Yi-Ling Chen and Noel Codella and Xiyang Dai and Jianfeng Gao and Houdong Hu and Xuedong Huang and Boxin Li and Chunyuan Li and Ce Liu and Mengchen Liu and Zicheng Liu and Yumao Lu and Yu Shi and Lijuan Wang and Jianfeng Wang and Bin Xiao and Zhen Xiao and Jianwei Yang and Michael Zeng and Luowei Zhou and Pengchuan Zhang},
      year={2021},
      journal={arXiv preprint arXiv:2111.11432},
}
% VideoAsMT
@misc{korbar2020video,
      title={Video Understanding as Machine Translation}, 
      author={Bruno Korbar and Fabio Petroni and Rohit Girdhar and Lorenzo Torresani},
      year={2020},
      journal={arXiv preprint arXiv:2006.07203}
}
% CLIP4CLIP
@misc{luo2021clip4clip,
  author  = {Huaishao Luo and Lei Ji and Ming Zhong and Yang Chen and Wen Lei and Nan Duan and Tianrui Li},
  title   = {{CLIP4Clip}: An Empirical Study of CLIP for End to End Video Clip Retrieval},
  journal = {arXiv preprint arXiv:2104.08860},
  year    = {2021},
}
% objectnav
@misc{ye2021auxiliary,
      title={Auxiliary Tasks and Exploration Enable ObjectNav},
      author={Joel Ye and Dhruv Batra and Abhishek Das and Erik Wijmans},
      year={2021},
      journal={arXiv preprint arXiv:2104.04112}
}

% IFT1
@inproceedings{liao2018reviving,
  title={Reviving and improving recurrent back-propagation},
  author={Liao, Renjie and Xiong, Yuwen and Fetaya, Ethan and Zhang, Lisa and Yoon, KiJung and Pitkow, Xaq and Urtasun, Raquel and Zemel, Richard},
  booktitle={ICML},
  year={2018}
}

% IFT2
@inproceedings{lorraine2020optimizing,
  title={Optimizing millions of hyperparameters by implicit differentiation},
  author={Lorraine, Jonathan and Vicol, Paul and Duvenaud, David},
  booktitle={AISTATS},
  year={2020},
}

% Reptile
@misc{nichol2018first,
  title={On first-order meta-learning algorithms},
  author={Nichol, Alex and Achiam, Joshua and Schulman, John},
  journal={arXiv preprint arXiv:1803.02999},
  year={2018}
}

% MAML
@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={ICML},
  year={2017}
}

% ALIGN
@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={ICML},
  year={2021}
}
% Foundation Model
@misc{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}
% FLAVA
@misc{singh2021flava,
  title={FLAVA: A Foundational Language And Vision Alignment Model},
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  journal={arXiv preprint arXiv:2112.04482},
  year={2021}
}
% support set
@article{patrick2020support,
  title={Support-set bottlenecks for video-text representation learning},
  author={Patrick, Mandela and Huang, Po-Yao and Asano, Yuki and Metze, Florian and Hauptmann, Alexander and Henriques, Joao and Vedaldi, Andrea},
  journal={arXiv preprint arXiv:2010.02824},
  year={2020}
}
% MOEE
@article{miech2018learning,
  title={Learning a text-video embedding from incomplete and heterogeneous data},
  author={Miech, Antoine and Laptev, Ivan and Sivic, Josef},
  journal={arXiv preprint arXiv:1804.02516},
  year={2018}
}
% AT
@article{hessel2019case,
  title={A case study on combining asr and visual features for generating instructional video captions},
  author={Hessel, Jack and Pang, Bo and Zhu, Zhenhai and Soricut, Radu},
  journal={arXiv preprint arXiv:1910.02930},
  year={2019}
}

% IDT1
@inproceedings{maclaurin2015gradient,
  title={Gradient-based hyperparameter optimization through reversible learning},
  author={Maclaurin, Dougal and Duvenaud, David and Adams, Ryan},
  booktitle={ICML},
  year={2015}
}

% IDT2
@inproceedings{franceschi2018bilevel,
  title={Bilevel programming for hyperparameter optimization and meta-learning},
  author={Franceschi, Luca and Frasconi, Paolo and Salzo, Saverio and Grazzi, Riccardo and Pontil, Massimiliano},
  booktitle={ICML},
  year={2018}
}

% IDT3
@inproceedings{franceschi2017forward,
  title={Forward and reverse gradient-based hyperparameter optimization},
  author={Franceschi, Luca and Donini, Michele and Frasconi, Paolo and Pontil, Massimiliano},
  booktitle={ICML},
  year={2017}
}

% AID1
@inproceedings{pedregosa2016hyperparameter,
  title={Hyperparameter optimization with approximate gradient},
  author={Pedregosa, Fabian},
  booktitle={ICML},
  year={2016}
}

% AID2
@article{rajeswaran2019meta,
  title={Meta-learning with implicit gradients},
  author={Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham M and Levine, Sergey},
  journal={NeurIPS},
  year={2019}
}

@inproceedings{grazzi2020iteration,
  title={On the iteration complexity of hypergradient computation},
  author={Grazzi, Riccardo and Franceschi, Luca and Pontil, Massimiliano and Salzo, Saverio},
  booktitle={ICML},
  year={2020}
}

@article{derivatives2000principles,
  title={Principles and Techniques of Algorithmic Differentiation},
  author={Derivatives, Evaluating},
  journal={SIAM},
  year={2000}
}

@inproceedings{baydin2018automatic,
  title={Automatic differentiation in machine learning: a survey},
  author={Baydin, Atilim Gunes and Pearlmutter, Barak A and Radul, Alexey Andreyevich and Siskind, Jeffrey Mark},
  booktitle={JMLR},
  year={2018}
}

@misc{univl_github,
  author = {Huaishao Luo and Lei Ji and Botian Shi and Haoyang Huang and Nan Duan and Tianrui Li and Jason Li and Taroon Bharti and Ming Zhou},
  title = {},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/microsoft/UniVL}}
}

@misc{violet_github,
  author = {Fu, Tsu-Jui and Li, Linjie and Gan, Zhe and Lin, Kevin and Wang, William Yang and Wang, Lijuan and Liu, Zicheng},
  title = {},
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tsujuifu/pytorch_violet}}
}

@misc{all_github,
  author = {Wang, Alex Jinpeng and Ge, Yixiao and Yan, Rui and Ge, Yuying and Lin, Xudong and Cai, Guanyu and Wu, Jianping and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  title = {},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/showlab/all-in-one}}
}

@inproceedings{antoniou2018train,
  title={How to train your MAML},
  author={Antoniou, Antreas and Edwards, Harrison and Storkey, Amos},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{zintgraf2019fast,
  title={Fast context adaptation via meta-learning},
  author={Zintgraf, Luisa and Shiarli, Kyriacos and Kurin, Vitaly and Hofmann, Katja and Whiteson, Shimon},
  booktitle={ICML},
  year={2019},
}

% Violet
@article{fu2021violet,
  title={VIOLET: End-to-end video-language transformers with masked visual-token modeling},
  author={Fu, Tsu-Jui and Li, Linjie and Gan, Zhe and Lin, Kevin and Wang, William Yang and Wang, Lijuan and Liu, Zicheng},
  journal={arXiv preprint arXiv:2111.12681},
  year={2021}
}

% All-in-one
@article{wang2022all,
  title={All in one: Exploring unified video-language pre-training},
  author={Wang, Alex Jinpeng and Ge, Yixiao and Yan, Rui and Ge, Yuying and Lin, Xudong and Cai, Guanyu and Wu, Jianping and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2203.07303},
  year={2022}
}

% HME
@inproceedings{fan2019heterogeneous,
  title={Heterogeneous memory enhanced multimodal attention model for video question answering},
  author={Fan, Chenyou and Zhang, Xiaofan and Zhang, Shu and Wang, Wensheng and Zhang, Chi and Huang, Heng},
  booktitle={CVPR},
  year={2019}
}

% HCRN
@inproceedings{le2020hierarchical,
  title={Hierarchical conditional relation networks for video question answering},
  author={Le, Thao Minh and Le, Vuong and Venkatesh, Svetha and Tran, Truyen},
  booktitle={CVPR},
  year={2020}
}

% QueST
@inproceedings{jiang2020divide,
  title={Divide and conquer: Question-guided spatio-temporal contextual attention for video question answering},
  author={Jiang, Jianwen and Chen, Ziqiang and Lin, Haojie and Zhao, Xibin and Gao, Yue},
  booktitle={AAAI},
  year={2020}
}

% ClipBERT
@inproceedings{lei2021less,
  title={Less is more: Clipbert for video-and-language learning via sparse sampling},
  author={Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L and Bansal, Mohit and Liu, Jingjing},
  booktitle={CVPR},
  year={2021}
}

@article{ruder2017overview,
  title={An overview of multi-task learning in deep neural networks},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1706.05098},
  year={2017}
}

% CC3M
@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={ACL},
  year={2018}
}

% CC12M
@inproceedings{changpinyo2021cc12m,
  title = {{Conceptual 12M}: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts},
  author = {Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle = {CVPR},
  year = {2021},
}

% WebVid
@inproceedings{bain2021frozen,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  booktitle={ICCV},
  year={2021}
}

% SBU
@inproceedings{ordonez2011im2text,
  title={Im2text: Describing images using 1 million captioned photographs},
  author={Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara},
  booktitle={NeurIPS},
  year={2011}
}

% VisualGenome
@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={IJCV},
  year={2017},
}

% COCO
@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  year={2014}
}

% ALPRO
@inproceedings{li2022align,
  title={Align and prompt: Video-and-language pre-training with entity prompts},
  author={Li, Dongxu and Li, Junnan and Li, Hongdong and Niebles, Juan Carlos and Hoi, Steven CH},
  booktitle={CVPR},
  year={2022}
}

% Kinetics
@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={CVPR},
  year={2017}
}

% mixup
@inproceedings{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  booktitle={ICLR},
  year={2018}
}

% rotation
@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={ICML},
  year={2020}
}