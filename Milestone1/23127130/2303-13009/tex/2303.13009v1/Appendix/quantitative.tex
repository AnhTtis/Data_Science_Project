\section{Adaptation to a new baseline and tasks}

\noindent \textbf{Plug-in to a new baseline.}
In Table~\ref{tab:apdx_quan} (Left), we conduct an experiment with another strong model ALPRO~\cite{li2022align} trained with four pretext losses.
In the video question answering task on MSVD-QA, ALPRO shows the original performance of 45.9\%, and MELTR improves it to 46.8\%. 

\noindent \textbf{Video only setting.} 
We also evaluate action recognition performance on Kinetics400~\cite{carreira2017quo} by applying MELTR to Violet in Table~\ref{tab:apdx_quan} (Middle).
Since the action recognition is a unimodal task with \emph{only} `videos', we use the following two losses: classification loss (primary task) and Masked Visual-token Modeling loss (MVM; auxiliary task).
Violet's accuracy is improved from 72.4\% to 73.1\%.

\noindent \textbf{Image only setting.} 
Furthermore, to verify the generalizability of MELTR to other domains, we also conduct our experiment on the  `image' domain (image classification on CIFAR-100) with ResNet32 backbone in Table~\ref{tab:apdx_quan} (Right).
We add two simple auxiliary losses (mixup~\cite{zhang2017mixup} and rotation~\cite{chen2020simple}) with a basic classification loss.
Our MELTR outperforms the baseline by a margin of 2.7\%.
These experimental results demonstrate that MELTR is a general framework to be adapted to a wide range of domains and tasks.