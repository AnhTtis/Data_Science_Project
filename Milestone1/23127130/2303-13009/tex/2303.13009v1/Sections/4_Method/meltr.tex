\subsection{Meta Loss Transformer}
\label{subsec:MELTR}
Our framework generates a unified auxiliary loss function $\Laux$ by combining auxiliary losses $\Ljoint, \Lalign, \dots, \Ldecoder$.
In other words, our framework takes loss values from multiple auxiliary tasks and converts them to a new combined loss value as shown in Figure~\ref{fig:main}.
In order to leverage the relationship between primary and auxiliary tasks, we adopt the Transformer~\cite{vaswani2017attention} architecture.

Let $\mathcal{F}(\cdot ; w)$ denote a backbone foundation model parameterized by $w$. 
For $t$-th task, given input data $x$ and its label $y_t$, the loss value $\ell_t$ is defined as:
\begin{equation}
    \ell_t = \Lct(\mathcal{F}(x; w), y_t),
\end{equation}
where $\mathcal{L}_t$ is a loss function for $t$-th task.
With loss values $\Ell=[\ell_0, \ldots, \ell_T]$ from the primary task $t=0$ and auxiliary tasks $\{t=1, \ldots t=T \}$, our framework MELTR learns a unified auxiliary loss function defined as:
\begin{equation}
    \aux := \text{MELTR}(\Ell;\phi),
    \label{eq:MELTR}
\end{equation}
where $\text{MELTR}(\cdot;\phi)$ is a transformer-based neural network parameterized by $\phi$, which are meta-parameters in our meta-learning formulation.
In order to feed loss values, $\ell_0, \ldots, \ell_T$ to a Multi-head Self-attention layer, 
we transform a scalar loss value into the scale embedding (\textbf{SE}) and the task embedding (\textbf{TE}).
Each auxiliary loss value is first projected to a $d$-dimensional vector via $\textbf{SE}(\cdot)$, which is an MLP layer with a non-linear activation.
Similarly, we adopt a learnable embedding layer for \textbf{TE}, which plays the role of positional encodings.
Then, \textbf{SE} : $\bbR \rightarrow \bbR^{d}$ and \textbf{TE} : $\{0, \ldots, T \} \rightarrow \bbR^d$ are defined as:
\begin{equation}
    \textbf{SE}(\ell) := \text{MLP}(\ell) \text{, and } \textbf{TE}(t) := \text{Embedding}(t).
    \label{eq:sete}
\end{equation}
Then, the scale and task embeddings are summed to construct an input token. The input embeddings are self-attended and finally pooled to a scalar loss value, $\text{MELTR}(\Ell; \phi) \in \bbR$, by considering both the \textit{loss scale} and the \textit{task information}.
The overall architecture with the UniVL backbone is illustrated in Figure~\ref{fig:main}. 

 
% Regularization
However, when {\em meta-data} (or a validation dataset) is small, meta-learning often suffers 
{\em meta-overfitting}~\cite{antoniou2018train,zintgraf2019fast}. 
In other words, meta-parameter $\phi$ may overfit to the primary task performance on small validation data.
To address this problem, we additionally introduce a regularization term $\mathcal{L}^\text{reg}$ given as:
\begin{equation}
    \mathcal{L}^\text{reg} = \left|\text{MELTR}(\Ell; \phi) - \sum_{t=0}^{T} \ell_t\right|.
    \label{eq:reg}
\end{equation}
This encourages the learned loss $\text{MELTR}(\Ell; \phi)$ to stay within a reasonable range.
Then, the primary task loss $\pri$, and the unified auxiliary loss $\aux$ are defined as follows:
\begin{equation}
    \pri = \mathcal{L}_0+\gamma\mathcal{L}^\text{reg}, \:\:\:
    \aux = \text{MELTR}(\Ell;\phi),
    \label{eq:loss}
\end{equation}
where $\gamma$ is a regularization strength and $\mathcal{L}_0$ is the original supervised loss for the target downstream task. For example, if $\Lalign$ is selected as the primary loss for the text-to-video retrieval task, then $\mathcal{L}_0 = \Lalign$ and all other tasks are considered as pretext tasks, \textit{i.e.}, $\Ell = [\Lalign, \Ljoint, \Lcmlm, \Lcmfm, \Ldecoder]$. 
Note that the primary loss itself is also included in the list of input loss functions.