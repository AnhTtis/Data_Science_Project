\vspace{4mm}
\section{Method}
The goal of our framework is {\em learning to fine-tune}. 
We propose MEta Loss TRansformer (MELTR), a novel auxiliary learning framework that adaptively combines auxiliary losses to assist fine-tuning on the target downstream task.
We formulate this as a bi-level optimization problem and 
present an efficient training procedure with Approximated Implicit Differentiation (AID) built on the Implicit Function Theorem (IFT).
Additionally, we introduce a regularization term to alleviate \textit{meta-overfitting} and learn a more effective combination of loss functions.

\input{Figures/main}
\input{Sections/4_Method/meltr}
\input{Sections/4_Method/objective_function}
\input{Algorithms/main}