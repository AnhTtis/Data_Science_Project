\section{Conclusion}

We proposed Meta Loss Transformer (MELTR), an auxiliary learning framework that learns to fine-tune video foundation models.
MELTR learns to integrate various pretext task losses into one loss function to boost the performance of the target downstream task.
Our qualitative analysis demonstrates that MELTR improves the performance of the primary task by considering the type of task and the scale of the loss value.
The proposed training procedure built on AID-FP-Lite with a simple approximation of the inverse Hessian matrix achieved the efficiency without a significant performance loss.
By plugging MELTR into various foundation models, our method outperformed state-of-the-art video foundation models as well as task-specific models on a wide range of downstream tasks.