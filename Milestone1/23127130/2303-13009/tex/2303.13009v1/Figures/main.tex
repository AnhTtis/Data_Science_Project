\begin{figure*}[t] 
    \centering
    \includegraphics[width=0.98\textwidth]{Figures/main.png}
    \caption{\textbf{Overall architecture.} 
    The Meta Loss Transformer (MELTR) is a plug-in module for meta auxiliary learning.
    The auxiliary pretext task losses derived from the video foundation model (\eg, UniVL~\cite{luo2020univl}) are input to MELTR, which is a transformer-based module that non-linearly aggregates the loss values from different tasks. The module is optimized to help learning of the primary task. 
    This figure illustrates the case when video captioning ($\mathcal{L}_\text{Decoder}$) is the primary task.}
    \label{fig:main}
\end{figure*}