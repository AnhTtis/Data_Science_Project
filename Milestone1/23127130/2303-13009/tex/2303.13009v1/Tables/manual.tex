\begin{table*}[t!]
    \centering
    \caption{\textbf{Comparison of various multi-task learning schemes.}
    We compare MELTR with manually designed five multi-task learning schemes:
    (A) adopts only $\Ldecoder$,
    (B) adopts both $\Ldecoder$ and $\Lmdecoder$ which are useful for video captioning based on our observation,
    (C) fixes all the coefficients to 1,
    (D) drops only $\Lcmfm$ which is useless for video captioning from (C) based on our observation,
    and (E) re-weights the loss coefficients based on task importance, contrary to (D).
    }
    \begin{adjustbox}{width=\linewidth}
    \begin{tabular}{c|c c c c c c c c|c c c c c}
        \toprule
        \textbf{Models} & \multicolumn{8}{c|}{\textbf{Coefficient of each task}} & \multicolumn{5}{c}{\textbf{Video captioning on YouCook2}} \\
        & $\Ljoint$ & $\Lmjoint$ & $\Lalign$ & $\Lmalign$ & $\Lcmlm$ & $\Lcmfm$ & $\Ldecoder$ & $\Lmdecoder$ & BLEU-3 & BLEU-4 & METEOR & ROUGE-L & CIDEr  \\
        \midrule
        \midrule
        (A) & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 22.79 & 16.54 & 21.73 & 45.85 & 1.78 \\
        (B) & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 23.42 & 17.14 & 22.27 & 46.65 & 1.85 \\
        (C) & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 21.72 & 15.93 & 20.89 & 45.16 & 1.79 \\
        (D) & 1 & 1 & 1 & 1 & 1 & 0 & 1 & 1 & 21.99 & 16.10 & 21.09 & 45.35 & 1.85 \\
        (E) & 1 & 1 & 1 & 1 & 1 & 0 & 8 & 8 & 23.31 & 17.23 & 21.98 & 46.26 & 1.85 \\
        \midrule
        \textbf{MELTR} & \multicolumn{8}{c|}{ADAPTIVE} & \textbf{24.12} & \textbf{17.92} & \textbf{22.56} & \textbf{47.04} & \textbf{1.90} \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \label{tab:manual}
    \vspace{-2mm}
\end{table*}