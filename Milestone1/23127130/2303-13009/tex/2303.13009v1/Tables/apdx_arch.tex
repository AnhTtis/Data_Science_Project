\begin{table}[t!]
    \centering
    \setlength{\tabcolsep}{3.5pt}
    \caption{\textbf{The effect of MELTR architecture.} 
    Experimental results for different MELTR architectures are provided. 
    The performances are reported for video retrieval on MSRVTT. 
    We do not report performance for task-embedding-only Transformer, as our optimization method is not trained properly in such a setting; $\nabla_w \Laux$ is always zero.}
    \begin{tabular}{c c}
        \toprule
        $\textbf{Architecture}$ & \textbf{R@1} \\
        \midrule
        \midrule
        Linear & 27.6 \\
        \midrule
        Transformer (SE+TE) & \textbf{28.6} \\
        Transformer (SE only) & 27.9 \\
        Transformer (TE only) & - \\
        \bottomrule
    \end{tabular}
    \label{tab:apdx_arch}
\end{table}