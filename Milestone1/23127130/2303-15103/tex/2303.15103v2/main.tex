\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
% \usepackage{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
\usepackage[preprint]{neurips_2023}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% PACKAGES
\input{packages.tex}
\input{math_commands.tex}


\title{Contrastive Learning Is Spectral Clustering On Similarity Graph}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{
Zhiquan Tan$^*$\\
  Department of Math, Tsinghua University\\
  \texttt{tanzq21@mails.tsinghua.edu.cn}
  \And 
  Yifan Zhang\thanks{Equal Contribution.}\\
  IIIS, Tsinghua University\\
  \texttt{zhangyif21@mails.tsinghua.edu.cn}
  \\
  \And
  Jingqin Yang$^*$\\
  IIIS, Tsinghua University\\
\texttt{yangjq21@mails.tsinghua.edu.cn} 
\\
  \And
  Yang Yuan\thanks{Corresponding Author}\\
  IIIS, Tsinghua University \\
  Shanghai Artificial Intelligence Laboratory \\
  Shanghai Qi Zhi Institute \\
  \texttt{yuanyang@tsinghua.edu.cn}\\
}



\begin{document}


\maketitle



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Abstract

\input{contents/abstract.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Introduction
\input{contents/introduction.tex}

\input{contents/related.tex}

\input{contents/prelim.tex}

\input{contents/mrf.tex}

\input{contents/newKernel.tex}

\input{contents/experiments.tex}

\input{contents/conclusion.tex}

\subsubsection*{Acknowledgments}
The authors would like to thank Van Assel for clarifying a derivation step in his paper, and anonymous reviewers and ACs for their helpful suggestions. 
This work is supported by the Ministry of Science and Technology of the People's Republic of China, the 2030 Innovation Megaprojects ``Program on New Generation Artificial Intelligence'' (Grant No. 2021AAA0150000). 



\vspace{10ex}
\bibliography{reference}
\bibliographystyle{icml}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix

%%%
\subsubsection*{Author Contributions}
Zhiquan Tan discovered the MRF framework for dimension reduction~\citep{van2022probabilistic}, and applied this framework to prove Theorem~\ref{thm:main}. He also introduced the viewpoint of the maximum entropy principle for contrastive learning. Yifan Zhang suggested the relationship between MRF and contrastive learning. Yifan and Zhiquan proposed Kernel-InfoNCE loss and refined the paper. Jingqin Yang implemented all the experiments and wrote the experimental section. Yang Yuan extended Theorem~\ref{thm:main} to CLIP, and wrote most part of the paper. 

\input{contents/appendix.tex}

\end{document}
