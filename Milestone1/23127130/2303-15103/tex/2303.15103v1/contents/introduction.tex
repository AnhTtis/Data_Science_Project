\section{Introduction}
Contrastive learning is one of the most popular self-supervised learning methods, particularly for vision tasks~\citep{chen2020simple,he2019momentum}.
It trains a neural network to map a collection of objects into an embedding space, ensuring that similar objects are in close proximity while dissimilar objects remain distant. A widely used loss function utilized to accomplish this objective is the InfoNCE loss, as exemplified by  SimCLR~\citep{chen2020simple}.


In the inspiring work, \citet{haochen2021provable} showed that if one replaces the standard InfoNCE loss with their spectral contrastive loss, contrastive learning is doing spectral clustering on the population augmentation graph. However, the spectral contrastive loss is rarely used empirically, and cannot be used for analyzing the performance of various similarity functions in the embedding space. Moreover, using the spectral contrastive loss, the final embedding is a combination of the standard spectral clustering and an additional  linear transformation.
Thus, the existing results cannot connect the original InfoNCE loss with the standard spectral clustering.



\begin{figure*}
\input{contents/1.tex}
\caption{An illustration of our analysis.}
\label{fig:illustration}
\end{figure*}


In this paper, we prove that SimCLR, the standard contrastive learning method, performs spectral clustering without modifying the InfoNCE loss or applying additional transformations to the embeddings. 
Our analysis with a collection of $n$ objects $\bfX=[\bfX_1, \cdots, \bfX_n]$ in space $\cX$. For these objects, we define a similarity graph with adjacency matrix $\bfpi$, such that $\bfpi_{i,j}$ equals the probability of $\bfX_i$ and $\bfX_j$ being paired together in the data augmentation step of contrastive learning. 



Given this similarity graph, we want to find an embedding function  $f:\cX\rightarrow \cZ$.
Denote $\bfZ \triangleq f(\bfX)$ as the embedding of $\bfX$,
and our objective is to ensure that the gram matrix $\bfK_\bfZ$ with kernel $k$ representing the similarities for $\bfZ$ is as close to $\bfpi$ as possible. See Figure~\ref{fig:illustration} for an illustration. 

However, directly comparing $\bfpi$ with $\bfK_\bfZ$ can be difficult, as there are too many edges in both graphs. Therefore, we define two Markov random fields (MRFs) based on $\bfpi$ and $\bfK_\bfZ$, and compare the MRFs instead. Indeed, 
each MRF introduces a probability distribution of unweighted directed subgraphs on $n$ objects~\citep{van2022probabilistic}, denoted as $\bfW_\bfX$ and $\bfW_\bfZ$ respectively.  As a natural approximation to the ideal loss between $\bfpi$ and $\bfK_\bfZ$, we use the cross entropy loss between $\bfW_\bfX$ and $\bfW_\bfZ$. 
The surprising discovery of our paper is that the InfoNCE loss is equivalent to the cross entropy loss when each subgraph is restricted to have an out-degree of exactly one. Moreover, when $k$ is the Gaussian kernel, optimizing the cross entropy loss is equivalent to running spectral clustering on $\bfpi$. Combining the two observations, we conclude that using the InfoNCE loss is equivalent to running spectral clustering.


Our characterization of contrastive learning depends on two key factors: the augmentation step that defines a similarity graph, and the InfoNCE loss that measures the distance between two MRFs. Therefore, any other models with these two factors can be analyzed similarly. In particular, the CLIP~\citep{radford2021learning} model for multi-modal learning belongs to this paradigm. Using the same framework, we prove a representation theorem for CLIP, showing that it runs spectral clustering on the bipartite graph induced by the paired training data. 

Is it possible to improve the InfoNCE loss by using a different kernel? Based on the maximum entropy principle, we demonstrate that the exponential kernels are the natural choices for capturing the local similarity structure for contrastive learning. Moreover, they are also good candidates in terms of expressive power. Empirically, we observe that 
taking the mixture of Gaussian and Laplacian kernels, which maintain the aforementioned properties, can achieve better performance than the Gaussian kernel on several benchmark vision datasets. 

In summary, our main contributions include:
\begin{itemize} [itemsep=0\baselineskip, topsep=0\baselineskip, leftmargin=0.5cm]
\item We prove the equivalence of SimCLR and spectral clustering on the similarity graph.

\item We extend our analysis to the multi-modal setting and prove the equivalence of CLIP and spectral clustering on the multi-modal similarity graph.

\item Inspired by theory, we propose new kernels that achieve better performance than the standard kernel empirically on the benchmark vision datasets. 
\end{itemize}

