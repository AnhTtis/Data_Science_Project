\section{Experiments}

\begin{table}[thb]
\centering
\caption{Results on CIFAR-10, CIFAR-100, and TinyImageNet datasets.}
\label{tab:results-combined}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}c|cc|cc|cc@{}}
\toprule
\multirow{3}{*}{Method} & \multicolumn{2}{c|}{CIFAR-10} & \multicolumn{2}{c|}{CIFAR-100} & \multicolumn{2}{c}{TinyImageNet} \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
                        & 200 epochs & 400 epochs       & 200 epochs & 400 epochs       & 200 epochs & 400 epochs       \\ \midrule
SimCLR (repro.)         & $88.11 \pm 0.09$    & $90.60 \pm 0.15$          & $62.57 \pm 0.10$    & $66.29 \pm 0.12$          & $34.00 \pm 0.18$    & $37.83 \pm 0.09$          \\
\midrule
Laplacian Kernel        & $89.26 \pm 0.18$    & $91.03 \pm 0.17$          & $63.16 \pm 0.15$    & $66.09 \pm 0.11$          & $35.91 \pm 0.21$    & $38.71 \pm 0.18$          \\
$\gamma=0.5$ Exponential Kernel & $89.00 \pm 0.07$ & $91.23 \pm 0.12$      & $63.48 \pm 0.22$    & $65.81 \pm 0.19$          & $34.17 \pm 0.13$    & $38.75 \pm 0.15$          \\
\textbf{Simple Sum Kernel} & $89.82 \pm 0.09$   & $\mathbf{91.72 \pm 0.10}$ & $\mathbf{66.67 \pm 0.20}$ & $\mathbf{68.62 \pm 0.15}$ & $\mathbf{36.61 \pm 0.13}$ & $\mathbf{39.38 \pm 0.16}$ \\
Concatenation Sum Kernel & $\mathbf{89.89 \pm 0.18}$ & $91.28 \pm 0.07$   & $66.10 \pm 0.21$    & $68.57 \pm 0.11$          & $35.98 \pm 0.17$    & $38.77 \pm 0.22$          \\
\midrule
\end{tabular}
}
\vspace{-5mm}
\end{table}

In our experiments, we reproduce the baseline algorithm SimCLR ~\citep{chen2020simple}, and replace SimCLR's Gaussian kernel with other kernels. We then test against SimCLR using Kernel-InfoNCE loss on various benchmark vision datasets, including CIFAR-10/100 ~\citep{krizhevsky2009learning} and TinyImageNet ~\citep{le2015tiny}.

For each algorithm, we first train an encoder $f$ on the training dataset to minimize the empirical loss function generated by the kernel. Then, following the standard linear evaluation protocol, we freeze the encoder $f$ and train a supervised linear classifier, which takes the output representation of $f$ as input. Additional experimental details, dataset information, and results can be found in Appendix~\ref{section: experiment_details}.

\textbf{Experimental Results. } We summarize our empirical results on various benchmark datasets in Table~\ref{tab:results-combined}. It is evident that we have achieved better performance than SimCLR on all three benchmark datasets, with the Simple Sum Kernel reaching the best average performance.

