\section{Experiments And Results}

 
        % \begin{minipage}{0.4\textwidth}
        %     \centering
        %     \begin{table}[H]
        %         \scriptsize
        %         \setlength\tabcolsep{4pt}
        %         \centering
        %         \begin{tabular}{ |c|c|c|c|c|c|}
        %             \hline
        %             \multicolumn{2}{|c||}{Setting} & \multicolumn{1}{c|}{2 Block} & \multicolumn{1}{c|}{2block} & \multicolumn{1}{c|}{3rd Block} & \multicolumn{1}{c|}{3block}  \\ 
        %             \cline{1-2}
        %             % & \textbf{2 Block Pickup} & \textbf{2block Connection} & \textbf{3rd Block Pickup} & \textbf{3block Connection} \\ \hline
        %             \multicolumn{1}{|c|}{Noise} & \multicolumn{1}{c||}{Action Interp.} & \multicolumn{1}{c|}{Pickup} & \multicolumn{1}{c|}{Connection} & \multicolumn{1}{c|}{Pickup} & \multicolumn{1}{c|}{Connection}\\ \hline
        %             \multicolumn{1}{|c|}{\textbf{YES}} & \multicolumn{1}{c||}{\textbf{YES}} & 95\% & 90\% & 70\% & 50\% \\  \hline 
        %             \multicolumn{1}{|c|}{\textbf{YES}} & \multicolumn{1}{c||}{\textbf{NO}} & 30\% & 30\% & 10\% & 0\% \\  \hline 
        %             \multicolumn{1}{|c|}{\textbf{NO}} & \multicolumn{1}{c||}{\textbf{YES}} & 40\% & 30\% & 10\% & 10\% \\  \hline 
        %             \multicolumn{1}{|c|}{\textbf{NO}} & \multicolumn{1}{c||}{\textbf{NO}} & 10\% & 10\% & 0\% & 0\% \\  \hline 
        %         \end{tabular}
        %         \caption{Effect of noise and action interpolation ("Interp.") on success rate (across 20 trials each).}
        %         % \vspace{2mm}
        %         \label{tab:real_world_results}
        %     \end{table}
        % \end{minipage}
        
        The goal of our experiments is to validate that learning and transfer of bi-arm policy for assembly is feasible, and to evaluate which pieces are critical through ablation studies.
        
        In summary, our learning setup can consistently produce a PPO policy with $\geq$95\% success rate in 3B train steps, 24 hours in simulation,
        % (0\% success with SAC after 16M steps, 24 hours)
        which retains 50\% success rate when zero-shot transferred to the real world. Figure \ref{fig:real_world_demo} shows snapshots of the behaviors in the real world execution, generated by the agent trained on the U-shape block assembly environment. In the snapshots, the two robotic arms accurately grip the blocks and move the blocks to the connecting position, open left gripper to let the blocks connect via the magnets, grip the 3rd block, move the 3rd block to the 2block structure, then open the gripper to let the 3rd block connect. In the following sections, we show ablations in both simulation-based learning and Sim2Real design choices which were crucial for these results.
        
    \subsection{Simulation RL Results}
        \label{sec:sim_results}
        % We evaluate the effectiveness of U-shape block assembly by computing average success rates over 40 episodes, broken down to 4 sub-steps, with ablations on different network sizes and the effect of applied force limit (Section \ref{sec:behavior_constraints}).  Given the large computation cost of large-scale distributed training which uses 4000 CPUs, we use at most 2 seeds for each experiment and choose the better one for evaluation.
        % \sg{is this evaluation for sim or real world? why can't we report average of the two? this is taking max of two seeds?}  It's because the training randomly becomes unstable which results are not good to use.  Ideally it's better to do more expriments but due to the given time constraint, we couldn't do that.
    
        % \yc{Redo of above: 
        We evaluate the performance of a policy on the U-shape block assembly task in simulation by computing the average success rate over 40 episodes, with ablations on different network sizes,  applied force limits and noises (Section \ref{sec:behavior_constraints}). Given the high computation cost of large-scale distributed training (using 4000 CPUs), we run at most 2 seeds for each experiment and choose the better one for evaluation.
        % }
        %  \sg{for this level of change, feel free to diretly edit! you can turn on "track" on overleaf if you want.}

        \textbf{Ablation: Effect of Network Width and Depth}
%        \sg{if space is a constraint, i think we can remove network size ablation study. it's not too significant.}\sk{yeah I agree.  Once space allocation is clear, I'll address that.  For now let's leave it as is, but I'm sure we'll trim this.}
        % Table~\ref{tab:network_success_rate} displays the effect of policy network size on training progress within simulation.
        To check the effect of policy network size on training progress, we trained the policy with different network size configurations (256-2048 as MLP hidden units, and 1-6 as number of MLP layers).
        For each setting of network depth and width, we measure the number of train steps required to reach 90\% success rate in simulation.
        The results indicate that training is optimized when the number of hidden units is between 512 and 1024, and when the number of network layers is between 2 and 4.
        % Note that training wallclock time is non-significantly different between different network sizes (180M/h for 512x1, 150M/h for 1024x6).
        Given these results, to ensure a large network capacity, we configure our policy networks to have 4 layers of 1024 hidden units.
        % \sg{Satok-san, can you say things in terms of compute time as well? arguably we don't care about policy steps, but wall-clock time. E.g. ", which translates to halving the training time of a worse network size.". Time per step doesn't change for different network size?}
        % 1024 as the number of hidden units and 4 as the number of layers which configuration is used by default.
        % In table \ref{tab:network_success_rate}, we compare number of required simulation steps to achieve 90\% success rate of U-shape assembly task in simulation.  The results indicate training performance becomes better if number of hidden units is between 512 and 1024, and if number of network layers is between 2 and 4.  To maximize the network capacity within decent training performance range, we adopt 1024 as the number of hidden unit and 4 as the number of layers which configuration is used by default.
        % \begin{minipage}{0.5\textwidth}
        %     \centering
        %     \begin{table}[H]
        %         \scriptsize
        %         \setlength\tabcolsep{10pt}
        %         \centering
        %         \begin{tabular}{ |c|c|c|c|c|}
        %             \hline
        %             \multicolumn{1}{|c||}{Network} & \multicolumn{4}{c|}{Network Width (hidden units per layer)} \\ 
        %             % \multicolumn{1}{|c||}{Depth} & \multicolumn{1}{c|}{256} & \multicolumn{1}{c|}{512} & \multicolumn{1}{c|}{1024} & \multicolumn{1}{c|}{2048}  \\ 
        %             % \cline{2-5} \hline
        %             \multicolumn{1}{|c||}{Depth} & 256 & 512 & 1024 & 2048 \\ 
        %             \cline{2-5} \hline
        %             \multicolumn{1}{|c||}{1} & N/A & 2700 & 2000 & 1900 \\
        %             \multicolumn{1}{|c||}{2} & 1700 & 950 & 1600 & 2000 \\
        %             \multicolumn{1}{|c||}{3} & 1300 & 960 & 1000 & 1900 \\
        %             \multicolumn{1}{|c||}{4} & N/A & 1100 & 1200 & N/A \\
        %             \multicolumn{1}{|c||}{5} & N/A & 920 & 1800 & N/A \\
        %             \multicolumn{1}{|c||}{6} & N/A & 980 & 2700 & N/A \\ \hline
        %             % \cline{2-3}
        %         \end{tabular}
        %         \caption{Effect of policy network size: training steps (in millions) to reach $90\%$ success rate on U-shape block assembly in simulation. N/A implies $<10\%$ success after 3 billion steps.}
        %         % \vspace{2mm}
        %         \label{tab:network_success_rate}
        %     \end{table}
        % \end{minipage}
    
        \textbf{Ablation: Applied Force Limit}
        \label{sec:applied_force_limt_result}
        % As excessive applied force readily breaks objects and robots in real world, the policy must learn behaviors which do not cause large forces. However, tightening applied force limit increases task difficulty. In Table~\ref{tab:block_to_floor_force_limit}, we compare required actor's environment steps to achieve 90\% success rate with different block-to-floor applied force limit variants.  Tightening the limit increases the task difficulty, and inhibits the policy to learn the task if the limit is 1.0 or less.  Note that the unit of the force limit is defined by mujoco~\cite{mujoco2012}.  In practice, policies learnt with 3.0 or larger limit frequently causes abnormal electric current fault when running in the real world.  So, we use 2.5 as the block to floor force limit.
        % We also compared the effect of the general applied force limit in Table~\ref{tab:block_to_floor_force_limit}. As expected, the training performance becomes significantly worse if we tighten the general applied force limit.  In particular, if we use 3.0 or lower general applied force limit, the policy can't learn the assembly behavior.  Also, the training speed is 3x slower if we use 4.0 as the limit.  Given these results, we use 5.0 as the general applied force limit by default.
        Excessive applied force in the real world poses safety risks, thus the policy must learn behaviors which are not too forceful, and to achieve this, we place a limit on applied force in simulation. However, this increases the task difficulty.
        In Table~\ref{tab:block_to_floor_force_limit}, we show the effect of force limit on training speed. As expected, tightening the limit (lower value) makes training much slower, and limits which are too low can even prevent the policy from learning the task.
      
        In determining the block to floor force limit, we find that when policies learned with a limit of 3.0 or higher are deployed in the real world, they frequency cause abnormal electric current fault. Therefore, we apply 2.5 as the block to floor applied force limit.
        Likewise, we found 5.0 to be an adequate value for the general applied force limit.
        (Note: the unit for force limit is defined by Mujoco~\cite{mujoco2012}.)
        \noindent
        \begin{minipage}{0.50\textwidth}
            \centering
            \begin{table}[H]
                \scriptsize
                \setlength\tabcolsep{10pt}
                \centering
                \begin{tabular}{ |c|c|c|c|c|c|}
                    \hline
                    \multicolumn{1}{|c||}{} & \multicolumn{5}{c|}{Block To Floor Applied Force Limit} \\ 
                    \multicolumn{1}{|c||}{} & 1.0 & 1.5 & 2.5 & 3.75 & 5.0 \\ 
                    \cline{2-5} \hline
                    \multicolumn{1}{|c||}{Steps} & N/A & 1420 & 1220 & 1030 & 840 \\ \hline
                    \multicolumn{1}{|c||}{} & \multicolumn{5}{c|}{General Applied Force Limit} \\
                    \multicolumn{1}{|c||}{} & 1.0 & 2.0 & 3.0 & 4.0 & 5.0 \\ 
                    \cline{2-5} \hline
                    \multicolumn{1}{|c||}{Steps} & N/A & N/A & N/A & 2600 & 840 \\ \hline
                    % \cline{2-3}
                \end{tabular}
                \caption{\scriptsize{Effect of applied force limit: training steps (in millions) to reach $90\%$ success rate on U-shape block assembly in simulation.  N/A implies $<10\%$ success after 3 billion steps.}}
                % \vspace{2mm}
                \label{tab:block_to_floor_force_limit}
                \vspace{-0mm}
            \end{table}
        \end{minipage} 
        
        \textbf{Ablation: Effect of Noise in Simulation}
        Similar to applied force limits, modeling noise in simulation is a necessary component for successful policy transfer in the real world, but it also significantly decreases training speed in simulation. Based on the level of observation noise in the real world, we apply in simulation a zero-mean Gaussian noise distribution with scale $=1$cm. This increases training time required to achieve $90\%$ success rate by $\sim1.8$ times. However, as we will see in the next section, modeling noise in simulation is absolutely critical for real world transfer.
        % Like applied force limit, noise is also one of major factors to decrease the training performance.  In our study, we use 1.0cm as the scale of Gaussian noise distribution based on the noise distribution in the real world.  The training on environments with that noise parameter requires 1.8x wall clock time to achieve 90\% success compared to environments without noise.
        
        % These results show that to develop a functional Sim2Real system for challenging tasks, simulation-based learning difficulty and Sim2Real transfer success need to be carefully traded off. 
        These results highlight a key point in developing a functional Sim2Real system for challenging tasks: there can be a trade-off between learning difficulty in simulation and Sim2Real transfer success in the real world, hence these two must be carefully balanced.

        % \begin{minipage}{0.45\textwidth}
        %     \centering
        %     \begin{table}[H]
        %         \scriptsize
        %         \setlength\tabcolsep{10pt}
        %         \centering
        %         \begin{tabular}{ |c|c|c|c|c|c|}
        %             \hline
        %             \multicolumn{1}{|c||}{} & \multicolumn{5}{c|}{General Applied Force Limit} \\ 
        %             \multicolumn{1}{|c||}{} & 1.0 & 2.0 & 3.0 & 4.0 & 5.0 \\ 
        %             \cline{2-5} \hline
        %             \multicolumn{1}{|c||}{Steps} & N/A & N/A & N/A & 2600 & 840 \\ \hline
        %             % \cline{2-3}
        %         \end{tabular}
        %         \caption{Effect of general applied force limit between all objects: for given applied force limit, the table displays the number of training steps required (units are 1 million steps) to reach $90\%$ success rate on U-Shape Block Assembly in simulation.}
        %         % \vspace{2mm}
        %         \label{tab:block_to_floor_force_limit_gen}
        %     \end{table}
        % \end{minipage}     

    \subsection{Real-World Transfer Results}
        \label{sec:real_results}
        \textbf{Ablation: Effect of Noise and Action Interpolation.}
        We demonstrate the effect of modeling observation noise and interpolating across delayed actions during training on real world performance. 
        In Table~\ref{tab:real_world_results}, we train policies with and without noise and action interpolation applied in simulation, and evaluate its success rate reaching intermediate checkpoints, or sub-tasks, during the U-shape block assembly task. \textit{2 Block Pickup} denotes gripping the first two assembly blocks, \textit{2block Connection} denotes successfully connecting the first two blocks, \textit{3rd Block Pickup} denotes successfully gripping the third block, and \textit{3block Connection} denotes successful U-shape block assembly.
        While applying noise or action interpolation individually improved performance over not applying both, applying both was absolutely beneficial across all sub-tasks.
    % \subsection{Snapshots for Real-World Demonstration}
    % Figure \ref{fig:real_world_demo} shows snapshots of the behaviors in the real world execution, generated by the agent trained on U-Shape Block Assembly environment. In the snapshots, the two robotics arms accurately grip the blocks and move the blocks to the connecting position, open left gripper to let the blocks be connected by magnets, grip the 3rd block, move the 3rd block to the 2block structure, and open the gripper to let the 3rd block be connected. This result shows that our agent can acquire the ability to generate behaviors to assemble three blocks to be U-Shape.
    %\sg{moved to head of experimemt}
    
    
    \noindent
        \begin{minipage}{0.5\textwidth}
            \centering
            \begin{table}[H]
                \scriptsize
                \setlength\tabcolsep{4pt}
                \centering
                \begin{tabular}{ |c|c|c|c|c|c|}
                    \hline
                    \multicolumn{2}{|c||}{Setting} & \multicolumn{1}{c|}{2 Block} & \multicolumn{1}{c|}{2block} & \multicolumn{1}{c|}{3rd Block} & \multicolumn{1}{c|}{3block}  \\ 
                    \cline{1-2}
                    % & \textbf{2 Block Pickup} & \textbf{2block Connection} & \textbf{3rd Block Pickup} & \textbf{3block Connection} \\ \hline
                    \multicolumn{1}{|c|}{Noise} & \multicolumn{1}{c||}{Action Interp.} & \multicolumn{1}{c|}{Pickup} & \multicolumn{1}{c|}{Connection} & \multicolumn{1}{c|}{Pickup} & \multicolumn{1}{c|}{Connection}\\ \hline
                    \multicolumn{1}{|c|}{\textbf{YES}} & \multicolumn{1}{c||}{\textbf{YES}} & 95\% & 90\% & 70\% & 50\% \\  \hline 
                    \multicolumn{1}{|c|}{\textbf{YES}} & \multicolumn{1}{c||}{\textbf{NO}} & 30\% & 30\% & 10\% & 0\% \\  \hline 
                    \multicolumn{1}{|c|}{\textbf{NO}} & \multicolumn{1}{c||}{\textbf{YES}} & 40\% & 30\% & 10\% & 10\% \\  \hline 
                    \multicolumn{1}{|c|}{\textbf{NO}} & \multicolumn{1}{c||}{\textbf{NO}} & 10\% & 10\% & 0\% & 0\% \\  \hline 
                \end{tabular}
                \caption{\scriptsize{Effect of noise and action interpolation ("Interp.") on real-world success rate (across 20 trials each).}}
                \vspace{-3mm}
                \label{tab:real_world_results}
            \end{table}
        \end{minipage}
    \subsection{Emergent Behaviors}
    \label{sec:emergent_behaviors}
     Since the policy is optimized using RL in simulation with initial state randomization and exploration noises, it has acquired unintended but intelligent emergent behaviors. These behaviors are shown in the supplementary videos.
    \begin{itemize}[leftmargin=*]
        \item \textbf{Intentional Ungrasp}: Sometimes due to imperfect grasp, the arms open the gripper and regrasp to enable the success of downstream connection.
        % the arms struggle to make connections. We observe that sometimes the arms appear to intentionally drop blocks and regrasp to enable the success of downstream connection. \sg{so do we have this? :) just in sim is also fine}\sk{It's up to the reward parameters.  As I shared in the chat, out policy can learn to drop and grip with some specific rewards.  So, the policy can learn intentional drops, but that reward parameter is not used in our golden policy.  I changed the title to Intentional Ungrasp to reflect more on the reward shaping.  We have a reward shaping to open a gripper for alignment mismatch and grip position mismatch}
      
        \item \textbf{Retries}: The arm sometimes drops the block due to imperfect grasp or loss of block information from occlusion, but can re-grasp and often succeed.
      
        \item \textbf{Change-of-pace}:  Sometimes while connecting, the arms appear to slow down to carefully align and bring the blocks closer where accuracy is required.
    
        % Sometimes while connecting, the arms appear to slow down to carefully align and bring the blocks closer. This behavior results from added noises: reaching and grasping may be robust against noise, but connecting requires slow and careful alignment for success.
        %This behavior likely results from added noises, where grasping and reaching may be robust against but connecting requires slow downs for success.
        
    \end{itemize}
      
  \subsection{Future Work}
    There are numerous promising future work to be done from our minimal task and system.
      \begin{itemize}[leftmargin=*]
          \item \textbf{More blueprints and blocks}: While we focused on 3-block U-shape assembly to test out the critical components of a system in depth, we can readily scale and extend the pipeline to more blocks and intricate blueprints.
          \item \textbf{From perception}: We used AprilTags for state tracking, but for simpler real-world deployment, we would ideally prefer raw vision as input.
          % Besides the option of end-to-end RL from vision, we could also use our current system to derive an expert policy from low dimension, and do behavioral cloning with vision as observation.
          % as vision\yc{"vision as observation"?}.
      \end{itemize}
  
