\begin{thebibliography}{99}
\bibitem{blockassemble2022} Ghasemipour, Seyed Kamyar Seyed, Satoshi Kataoka, Byron David, Daniel Freeman, Shixiang Shane Gu, and Igor Mordatch. "Blocks assemble! learning to assemble with large-scale structured reinforcement learning." In International Conference on Machine Learning, pp. 7435-7469. PMLR, 2022.
\bibitem{robosuite2020} Zhu, Yuke, Josiah Wong, Ajay Mandlekar, and Roberto Martín-Martín. "robosuite: A modular simulation framework and benchmark for robot learning." arXiv preprint arXiv:2009.12293 (2020).
\bibitem{bidex2022} Chen, Yuanpei, Yaodong Yang, Tianhao Wu, Shengjie Wang, Xidong Feng, Jiechuang Jiang, Stephen Marcus McAleer, Hao Dong, Zongqing Lu, and Song-Chun Zhu. "Towards Human-Level Bimanual Dexterous Manipulation with Reinforcement Learning." arXiv preprint arXiv:2206.08686 (2022).
\bibitem{infant2007} Albers, Craig A., and Adam J. Grieve. "Test review: Bayley, N.(2006). Bayley scales of infant and toddler development–third edition. San Antonio, TX: Harcourt assessment." Journal of Psychoeducational Assessment 25, no. 2 (2007): 180-190.
\bibitem{her2017} Andrychowicz, Marcin, Filip Wolski, Alex Ray, Jonas Schneider, Rachel Fong, Peter Welinder, Bob McGrew, Josh Tobin, OpenAI Pieter Abbeel, and Wojciech Zaremba. "Hindsight experience replay." Advances in neural information processing systems 30 (2017).
\bibitem{asyncnaf2017} Gu, Shixiang, Ethan Holly, Timothy Lillicrap, and Sergey Levine. "Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates." In 2017 IEEE international conference on robotics and automation (ICRA), pp. 3389-3396. IEEE, 2017.
\bibitem{qtopt2018} Kalashnikov, Dmitry, Alex Irpan, Peter Pastor, Julian Ibarz, Alexander Herzog, Eric Jang, Deirdre Quillen et al. "Scalable deep reinforcement learning for vision-based robotic manipulation." In Conference on Robot Learning, pp. 651-673. PMLR, 2018.
\bibitem{metaworld2020} Yu, Tianhe, Deirdre Quillen, Zhanpeng He, Ryan Julian, Karol Hausman, Chelsea Finn, and Sergey Levine. "Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning." In Conference on robot learning, pp. 1094-1100. PMLR, 2020.
\bibitem{rlbench2020} James, Stephen, Zicong Ma, David Rovick Arrojo, and Andrew J. Davison. "Rlbench: The robot learning benchmark and learning environment." IEEE Robotics and Automation Letters 5, no. 2 (2020): 3019-3026.
\bibitem{luck2017} Luck, Kevin Sebastian, and Heni Ben Amor. "Extracting bimanual synergies with reinforcement learning." In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4805-4812. IEEE, 2017.
\bibitem{amadio2019} Amadio, Fabio, Adrià Colomé, and Carme Torras. "Exploiting symmetries in reinforcement learning of bimanual robotic tasks." IEEE Robotics and Automation Letters 4, no. 2 (2019): 1838-1845.
\bibitem{peg2022} Stepputtis, Simon, Maryam Bandari, Stefan Schaal, and Heni Ben Amor. "A System for Imitation Learning of Contact-Rich Bimanual Manipulation Policies." arXiv preprint arXiv:2208.00596 (2022).
\bibitem{sac2018} Haarnoja, Tuomas, Aurick Zhou, Pieter Abbeel, and Sergey Levine. "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor." In International conference on machine learning, pp. 1861-1870. PMLR, 2018.
\bibitem{pinto2016} Pinto, Lerrel, and Abhinav Gupta. "Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours." In 2016 IEEE international conference on robotics and automation (ICRA), pp. 3406-3413. IEEE, 2016.
\bibitem{levine2018} Levine, Sergey, Peter Pastor, Alex Krizhevsky, Julian Ibarz, and Deirdre Quillen. "Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection." The International journal of robotics research 37, no. 4-5 (2018): 421-436.
\bibitem{insertion2020} Schoettler, Gerrit, Ashvin Nair, Jianlan Luo, Shikhar Bahl, Juan Aparicio Ojea, Eugen Solowjow, and Sergey Levine. "Deep reinforcement learning for industrial insertion tasks with visual inputs and natural rewards." In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 5548-5555. IEEE, 2020.
\bibitem{tossingbot2020} Zeng, Andy, Shuran Song, Johnny Lee, Alberto Rodriguez, and Thomas Funkhouser. "Tossingbot: Learning to throw arbitrary objects with residual physics." IEEE Transactions on Robotics 36, no. 4 (2020): 1307-1319.
\bibitem{saycan2022} Ahn, Michael, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn et al. "Do as i can, not as i say: Grounding language in robotic affordances." arXiv preprint arXiv:2204.01691 (2022).
\bibitem{grasping2016} Prattichizzo, Domenico, and Jeffrey C. Trinkle. "Grasping." In Springer handbook of robotics, pp. 955-988. Springer, Cham, 2016.
\bibitem{rubiks2019} Agostinelli, Forest, Stephen McAleer, Alexander Shmakov, and Pierre Baldi. "Solving the Rubik’s cube with deep reinforcement learning and search." Nature Machine Intelligence 1, no. 8 (2019): 356-363.
\bibitem{rubiks2020} Andrychowicz, OpenAI: Marcin, Bowen Baker, Maciek Chociej, Rafal Jozefowicz, Bob McGrew, Jakub Pachocki, Arthur Petron et al. "Learning dexterous in-hand manipulation." The International Journal of Robotics Research 39, no. 1 (2020): 3-20.
\bibitem{baoding2020} Nagabandi, Anusha, Kurt Konolige, Sergey Levine, and Vikash Kumar. "Deep dynamics models for learning dexterous manipulation." In Conference on Robot Learning, pp. 1101-1112. PMLR, 2020.
\bibitem{robel2020} Ahn, Michael, Henry Zhu, Kristian Hartikainen, Hugo Ponte, Abhishek Gupta, Sergey Levine, and Vikash Kumar. "Robel: Robotics benchmarks for learning with low-cost robots." In Conference on robot learning, pp. 1300-1313. PMLR, 2020.
\bibitem{kumar2016} Kumar, Vikash, Emanuel Todorov, and Sergey Levine. "Optimal control with learned local models: Application to dexterous manipulation." In 2016 IEEE International Conference on Robotics and Automation (ICRA), pp. 378-383. IEEE, 2016.
\bibitem{schulman2017proximal} Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg, Proximal policy optimization algorithms, arXiv preprint arXiv:1707.06347, 2017.
\bibitem{schulman2015high} Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter, High-dimensional continuous control using generalized advantage estimation, arXiv preprint arXiv:1506.02438, 2015.
\bibitem{andrychowicz2020matters} Andrychowicz, Marcin and Raichuk, Anton and Sta{\'n}czyk, Piotr and Orsini, Manu and Girgin, Sertan and Marinier, Rapha{\"e}l and Hussenot, Leonard and Geist, Matthieu and Pietquin, Olivier and Michalski, Marcin and others, What matters for on-policy deep actor-critic methods? a large-scale study, International Conference on Learning Representations, 2020.
\bibitem{jax2018github} James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang, {JAX}: composable transformations of {P}ython+{N}um{P}y programs, http://github.com/google/jax, 2018.
\bibitem{jraph2020github} Jonathan Godwin* and Thomas Keck* and Peter Battaglia and Victor Bapst and Thomas Kipf and Yujia Li and Kimberly Stachenfeld and Petar Veli\v{c}kovi\'{c} and Alvaro Sanchez-Gonzalez, {J}raph: {A} library for graph neural networks in jax., http://github.com/deepmind/jraph, 2020.
\bibitem{haiku2020github} Tom Hennigan and Trevor Cai and Tamara Norman and Igor Babuschkin, {H}aiku: {S}onnet for {JAX}, http://github.com/deepmind/dm-haiku, 2020.
\bibitem{hoffman2020acme} Matt Hoffman and Bobak Shahriari and John Aslanides and Gabriel Barth-Maron and Feryal Behbahani and Tamara Norman and Abbas Abdolmaleki and Albin Cassirer and Fan Yang and Kate Baumli and Sarah Henderson and Alex Novikov and Sergio Gómez Colmenarejo and Serkan Cabi and Caglar Gulcehre and Tom Le Paine and Andrew Cowie and Ziyu Wang and Bilal Piot and Nando de Freitas, Acme: A Research Framework for Distributed Reinforcement Learning, arXiv preprint arXiv:2006.00979, https://arxiv.org/abs/2006.00979, 2020.
\bibitem{mujoco2012} Emanuel Todorov and Tom Erez and Yuval Tassa, MuJoCo: A physics engine for model-based control, Mujoco. http://mujoco.org, 2015–2020.
\bibitem{levine2018learning} Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Ibarz, Julian and Quillen, Deirdre, Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection, The International Journal of Robotics Research 37 4-5 4211--436, 2018.
\bibitem{kalashnikov2018qt} Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others, Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation, arXiv preprint arXiv:1806.10293, 2018.
\bibitem{andrychowicz2020learning} Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others, Learning dexterous in-hand manipulation, The International Journal of Robotics Research, The International Journal of Robotics Research 39 1 3--20, 2020.
\bibitem{chen2021system} Chen, Tao and Xu, Jie and Agrawal, Pulkit, A System for General In-Hand Object Re-Orientation, Conference on Robot Learning, 2021.
\bibitem{huang2021generalization} Huang, Wenlong and Mordatch, Igor and Abbeel, Pieter and Pathak, Deepak, Generalization in Dexterous Manipulation via Geometry-Aware Multi-Task Learning, arXiv preprint arXiv:2111.03062, 2021.
\bibitem{yu2020meta} Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey, Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning, Conference on Robot Learning, 1094--1100, 2020.
% \bibitem{li2020towards} Li, Richard and Jabri, Allan and Darrell, Trevor and Agrawal, Pulkit, Towards practical multi-object manipulation using relational reinforcement learning, 2020 IEEE International Conference on Robotics and Automation (ICRA) 4051--4058, 2020.
% \bibitem{batra2020rearrangement} Batra, Dhruv and Chang, Angel X and Chernova, Sonia and Davison, Andrew J and Deng, Jia and Koltun, Vladlen and Levine, Sergey and Malik, Jitendra and Mordatch, Igor and Mottaghi, Roozbeh and others, Rearrangement: A challenge for embodied ai, arXiv preprint arXiv:2011.01975, 2020.
% \bibitem{openai2021asymmetric} OpenAI, OpenAI and Plappert, Matthias and Sampedro, Raul and Xu, Tao and Akkaya, Ilge and Kosaraju, Vineet and Welinder, Peter and D'Sa, Ruben and Petron, Arthur and Pinto, Henrique P d O and others, Asymmetric self-play for automatic goal discovery in robotic manipulation, arXiv preprint arXiv:2101.04882, 2021.
% \bibitem{gupta2019relay} Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol, Relay policy learning: Solving long-horizon tasks via imitation and reinforcement learning, arXiv preprint arXiv:1910.11956, 2019.
\bibitem{apriltag} AprilTag, https://april.eecs.umich.edu/software/apriltag
\bibitem{xarm6} UFACTORY xArm6, https://www.ufactory.cc/products/xarm-6-2020
\bibitem{d455} Intel RealSense D455, https://www.intelrealsense.com/depth-camera-d455
\bibitem{opencv} OpenCV team, https://opencv.org/
\bibitem{bapst2019structured} Bapst, Victor and Sanchez-Gonzalez, Alvaro and Doersch, Carl and Stachenfeld, Kimberly and Kohli, Pushmeet and Battaglia, Peter and Hamrick, Jessic, Structured agents for physical construction, International Conference on Machine Learning, 464--474, 2019.
\bibitem{lee2019ikea} Lee, Youngwoon and Hu, Edward S and Yang, Zhengyu and Yin, Alex and Lim, Joseph J, IKEA furniture assembly environment for long-horizon complex manipulation task, arXiv preprint arXiv:1911.07246, 2019.
\bibitem{lee2021adversarial} Lee, Youngwoon and Lim, Joseph J and Anandkumar, Anima and Zhu, Yuke, Adversarial Skill Chaining for Long-Horizon Robot Manipulation via Terminal State Regularization, arXiv preprint arXiv:2111.07999, 2021.
\bibitem{suarez2018can} Su{\'a}rez-Ruiz, Francisco and Zhou, Xian and Pham, Quang-Cuong, Can robots assemble an IKEA chair?, Science Robotics - 3 - 17, 2018.
\bibitem{levine2016end} Levine S, Finn C, Darrell T, Abbeel P. End-to-end training of deep visuomotor policies. The Journal of Machine Learning Research. 2016.
\bibitem{shepard2010cloth} Maitin-Shepard, Jeremy B., Marco F. Cusumano-Towner, Jinna Lei and P. Abbeel. “Cloth grasp point detection based on multiple-view geometric cues with application to robotic towel folding.” 2010 IEEE International Conference on Robotics and Automation (2010): 2308-2315.
\bibitem{go2016} Silver, David, et al. "Mastering the game of Go with deep neural networks and tree search." nature 529.7587 (2016): 484-489.
\bibitem{dota2019} Berner, Christopher, et al. "Dota 2 with large scale deep reinforcement learning." arXiv preprint arXiv:1912.06680 (2019).
\bibitem{tokomak2022} Degrave, Jonas, et al. "Magnetic control of tokamak plasmas through deep reinforcement learning." Nature 602.7897 (2022): 414-419.
\bibitem{qtopt2018} Kalashnikov, Dmitry, et al. "Scalable deep reinforcement learning for vision-based robotic manipulation." Conference on Robot Learning. PMLR, 2018.
\bibitem{rubik2019} OpenAI, Ilge Akkaya, et al. "Solving Rubik's Cube with a Robot Hand." (2019).
\bibitem{dmcontrol2018} Tassa, Yuval, et al. "Deepmind control suite." arXiv preprint arXiv:1801.00690 (2018).
\bibitem{sim2real2017} Tobin, Josh, et al. "Domain randomization for transferring deep neural networks from simulation to the real world." 2017 IEEE/RSJ international conference on intelligent robots and systems (IROS). IEEE, 2017.
\bibitem{sim2real2018} Peng, Xue Bin, et al. "Sim-to-real transfer of robotic control with dynamics randomization." 2018 IEEE international conference on robotics and automation (ICRA). IEEE, 2018.
\bibitem{eppner2016lessons} Eppner, Clemens et al. "Lessons from the amazon picking challenge: Four aspects of building robotic systems." 2016 Robotics: science and systems
\bibitem{ha2020multiarm} Ha, Huy et al. "Learning a Decentralized Multi-arm Motion Planner" 2020 Conference on Robotic Learning (CoRL)
\bibitem{lavalle1998rapidly} LaValle, Steven M et al. "Rapidly-exploring random trees: A new tool for path planning" 1998 Ames, IA, USA
\bibitem{kavraki1996probabilistic} Kavraki, Lydia E et al. "Probabilistic roadmaps for path planning in high-dimensional configuration spaces" 1996 IEEE transactions on Robotics and Automation
\bibitem{isim2real2022} Abeyruwan, Saminda et al. "i-Sim2Real: Reinforcement Learning of Robotic Policies in Tight Human-Robot Interaction Loops" 2022 Conference on Robotic Learning (CoRL)
\bibitem{lee2022multi} Lee, Kuang-Huei et al. "Multi-Game Decision Transformers" 2022 Conference on Neural Information Processing Systems
\bibitem{reed2022generalist} Reed, Scott et al. "A generalist agent" 2022 arXiv preprint arXiv:2205.06175
\bibitem{chitnis2020efficient} Chitnis, Rohan et al. "Efficient bimanual manipulation using learned task schemas" 2020 IEEE International Conference on Robotics and Automation (ICRA)
% @inproceedings{
% abeyruwan2022isimreal,
% title={i-Sim2Real: Reinforcement Learning of Robotic Policies in Tight Human-Robot Interaction Loops},
% author={Saminda Wishwajith Abeyruwan and Laura Graesser and David B D'Ambrosio and Avi Singh and Anish Shankar and Alex Bewley and Pannag R Sanketi},
% booktitle={6th Annual Conference on Robot Learning},
% year={2022},
% url={https://openreview.net/forum?id=4nt6RUGmILw}
% }
\end{thebibliography}
