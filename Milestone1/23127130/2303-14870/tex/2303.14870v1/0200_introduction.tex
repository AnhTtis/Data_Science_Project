\section{Introduction}

% \sg{todo: in-hand dexterous manipulation is also a popular kind of work in sim and real. we should also write about why biarm is more functional with its larger workspace (grasp wrench space). some nvidia friend sent me they are sending a strong real-world in-hand dexterous manip paper to icra. we should convince readers why biarm real world demo is significant compared to those "seemingly more dexterous" ones}

% \kg{Curious, what is their paper about / doing / accomplishing? What task, what robot?}

Robot arms have the immense potential to perform a wide variety of useful manipulation tasks, and approaches have already made their way into many applications such as manufacturing and warehouse pick-and-place operations~\cite{eppner2016lessons}. However, most successful cases are confined to the single-arm setting~\cite{pinto2016,asyncnaf2017,qtopt2018,levine2018,insertion2020,tossingbot2020}.
Dual and multi-arm platforms enable robots to accomplish a much wider variety of complex tasks, such as cooking and construction, due to additional dexterity and effective workspace (e.g. richer grasp wrench space~\cite{grasping2016}).
Furthermore, the use of multi-arm robots can simplify tasks that can be accomplished by single-arm robots, by alleviating the need for extremely dexterous in-hand manipulation behaviors~\cite{rubik2019,chen2021system}.


\begin{figure}[t]
    \centering
    % 490 x 400
    % \includegraphics[width=196,height=160,natwidth=196,natheight=160]{ICRA_images/3block_task.pdf}
    \includegraphics[scale=0.62,bb=0 0 490 290]{ICRA_images/3block_task.pdf}

    \caption{
        \scriptsize{Visualization of simulated and real-world U-Shape Assembly Tasks.}
    }
    \label{fig:three_block_task}
\vspace{-6mm}
\end{figure}

%\kg{"Multi-Arm manipulation is hard because of... In this work we..." paragraph needs to go here, needs to emphasize real-world and why it's hard. They also need to be properly cited with clear evidence.}
Despite their inherent advantages, introducing multiple arms into robotic systems brings about a host of unique challenges to the control problem. Designing controllers for bi-manual systems in end-effector or task space is often ineffective as one needs to consider complex inter-arm collision avoidance and coordination behaviors, especially for tasks such as assembly which require long-horizon, intricate, and close interactions among arms and objects. Motion planning algorithms~\cite{lavalle1998rapidly,kavraki1996probabilistic} are intractable for closed loop real-time multi-arm manipulation settings due to their unfavorable scaling as the degrees of freedom in systems increase. On the other hand, open loop controllers are also ineffective in multi-arm setups, as they are more likely to experience drift from the intended plan due to noise, asynchronous control delays, and amplification of coordination errors. Thus, in current robotics literature, most examples of multi-arm manipulation systems rely on planning with parameterized motion primitives \cite{amadio2019}, imitation learning \cite{peg2022}, or reinforcement learning with parameterized sub-motions~\cite{luck2017,chitnis2020efficient}.

In contrast to the above approaches, the use of reinforcement learning (RL) for joint-space control of bimanual robots is significantly underexplored. In particular, with the use of deep learning, RL methods have many significant advantages: neural network policies can be seamlessly integrated with perception modules that are themselves often reliant on deep learning techniques~\cite{pinto2016,qtopt2018,levine2018,saycan2022}; neural network policies can be trained in multi-task setups and effectively share acquired knowledge amongst tasks~\cite{metaworld2020,lee2022multi,reed2022generalist}; the output of an RL system is a policy that can be executed with tight real-time real-world constraints~\cite{isim2real2022}. Thus, in this work we investigate the feasibility of training deep RL policies in simulation and transferring them to the real world (Sim2Real), as a generic methodology for obtaining performant controllers for real-world bi-manual robotic manipulation tasks.

% Our goal in this work is to devise methodology for obtaining performant controllers for real-world bi-manual robotic manipulation tasks.
To study the efficacy of simulated deep RL and Sim2Real transfer, we design the \textit{``U-Shape Magnetic Block Assembly Task"} as a testbed for studying key challenges of bi-manual manipulation in the real world. In this task, two robot arms equipped with parallel grippers must connect 3 magnetic blocks in order to form a "U" shape. Despite its minimalism, magnetic block assembly is substantially more challenging than prior bi-manual policy learning tasks on real robots~\cite{luck2017,amadio2019,peg2022}, and preserves many of the core challenges of multi-arm manipulation such as coordination, precision, geometric reasoning and collision avoidance (between robots, blocks, and ground), and real-time execution constraints.
%\kg{I think I wanna move this to the main text where we discuss the task} \sg{i feel it's fine to keep it here. intro should emphasize difficulty/extandability clearly first to grab audience attention. taking extra few lines to descrive the task doesnt hurt.}
Furthermore, solutions are required to be closed-loop as blocks can move, slip, and drop. Block assembly can also be readily extended by increasing the number and diversity of available blocks, and replacing magnets with altenative attachment mechanisms to enable the construction of more complex blueprints.
% \sg{it would be nice to make consistent lists}
% Given the aforementioned challenges with motion planning algorithms, we decided to approach the problem through RL, Sim2Real, joint-space control

In this work, we demonstrate that deep RL and Sim2Real transfer lead to an effective recipe for solving the ``U-shape block assembly task". The key contributions of our work are as follows:

\begin{itemize}[leftmargin=10pt]
    \item We develop the ``U-Shape Magnetic Block Assembly Task" as a testbed for real-world bi-manual manipulation, and detail each component of the system design in simulation and the real world.
    \item To the best of our knowledge, we demonstrate for the first time that joint-based control through deep reinforcement learning is an effective approach for obtaining controllers for a real-world bi-manual manipulation task.
    \item Critically, we demonstrate that by taking the appropriate measures, RL policies trained in simulation can be transferred to the real-world without any fine-tuning. We present detailed ablations identifying key components for effective Sim2Real transfer of RL policies trained in simulation.
\end{itemize}

% \kg{Finalized is above this line~~~~~~~}

% As a benchmark to study the intricacy of learning dexterous bi-arm manipulation, we design U-Shape Block Assembly Task in simulation and real world, where two robot arms with parallel grippers need to connect 3 magnetic blocks in the shape of ``U''. Despite its simplicity and minimalism, it preserves the core difficulties of generic multi-block bi-arm assembly, extends readily by changing blueprints or having more blocks, and is already substantially more challenging than prior bi-manual policy learning tasks on real robots~\cite{luck2017,amadio2019,peg2022}. % \sg{it would be nice to make consistent lists}

% \begin{itemize}
%     \item Let's think "Why RL?"
%     \item Motion planning algorithms won't work
%     \item RL can discover good ways of doing things
%     \item RL let's you more seemlessly integrate perception modules into the system and learn end-to-end fashion
%     \item Neural networks can be trained on diverse tasks and share knowledge between tasks
%     \item Hence, RL will be a more general approach / future-proof / easier to extend to more challenging more dexterous tasks / etc.
% \end{itemize}

% \begin{itemize}
%     % \item We want a generalizable/generic approach to learning manipulation policies
%     % \item Motion planning methods have the aforementioned problems
%     % \item We decide to take the approach of RL + Sim2Real
%     \item We are able to solve the task with RL + Sim2Real
%     \item We identify and resolve the key obstacles inhibiting the transfer of policies to the real world
% \end{itemize}

% \begin{itemize}
%     % \item motion planning intractable
%     % \item the ones who do motion planning do it like this
%     % \item people approach it through motion planning, imitation learning lfd, planning/control
%     % \item problems with each
%     % \item Most of these also require special parameterizations for accomplishing the tasks
%     % \item Our goal is to obtain a generic approach that can be applied to any task
%     % \item 
%     % \item RL is very underexplored
%     % \item significantly under-explored is RL in bimanual
%     % \item we do RL + Sim2Real
%     % \item to study it we need a testbed
%     % \item we make magnetic block assembly benchmark
%     \item we demonstrate how careful considerations for sim2real allow policies trained in sim to be directly transfered to the real-world without any finetuning
%     \item the contributions of our work are
% \end{itemize}

% In designing an approach for solving real-world bi-manual manipulation tasks, our objective is to design a generic approach that could be potentially applicable to.......

% Drafting:
% While we have the u-shape bimanual manipulation task as a testbed, our objective is to solve this task using general approaches that can be approached down the line towards solving any task.
% Given the challenges of scaling motion-planning algorithms (discussed above), we focus on Deep Reinforcement Learning (deep RL) in simulation + Sim2Real transfer. \kg{The rest might even be moved to related works or the methodology section} Deep RL approaches have many favorable properties: they can be seamlessly integrated with perception modules which are typically deep neural network architectures themselves (cite); they can be trained on and share knowledge when trained in multi-task settings (cite blocks assemble paper, ofir et al's multi-task, gato); they produce controllers that can be used in closed-loop systems under real-time constraints(cite?);

% Given the challenges of using motion-planning algorithm in a multi-arm setup

% To solve the ``$\bigsqcup$-Shape Magnetic Block Assembly Task"

% To learn the task, we use large-scale reinforcement learning (RL) in simulation for policy learning without human demonstrations. We then transfer the simulation policy directly to the real robots for execution without additional finetuing. We show that this Sim2Real system can effectively let real bi-arm robots perform U-shape assembly, which requires robust grasping, precision control, bi-arm coordination and collision avoidance, and long-horizon multi-step execution.

% To learn the task, we use large-scale reinforcement learning (RL) in simulation for policy learning without human demonstrations, training with 3 billion environment steps or equivalently of 3000 hours of simulated robot experience, in 8-hour real-world wall-clock time using 1 Nvidia V100 GPU and 4000 CPUs.
% We then transfer the simulation policy directly to the real robots for execution without additional finetuing. We show that this Sim2Real system can effectively let real bi-arm robots perform U-shape assembly, which requires robust grasping, precision control, bi-arm coordination and collision avoidance, and long-horizon multi-step execution.
%We propose RL in simulation as an effective method to develop a general controller for this bi-arm manipulation problem, and show that it can be directly transferred to the real robots without additional finetuning.
% Our approach provides multiple simplifications: 1) We directly use real-time (4Hz) joint space control (rather than end-effector control), which relieves the need for run-time collision libraries or planners, 2) We do not use explicit filtering, state estimation, or observation engineering. Instead we simply use raw robot observations that are fed to a single neural network policy.
%We show that our approach can produce highly effective controllers in the real-world by demonstrating its performance without real-world finetuning. 

 \begin{figure*}[t]
            \begin{minipage}{\textwidth}
                \centering
                \includegraphics[scale=0.5]{ICRA_images/connect_photos.pdf}
                \vspace{-3mm}
                \caption{
                    \small{
                        Snapshots of U-Shape Block Assembly Task Execution in Real World.
                    }
                }
                \label{fig:real_world_demo}
                \vspace{-4mm}
            \end{minipage}
        \end{figure*}

% \sg{todo: reference specific details in Method and Experiment sections.}

Our results present a significant step forward for bi-arm capability on real hardware.
% We detail how each component of the system -- task design in simulation and real world, learning algorithm designs, and additional techniques for filling Sim2Real gaps -- is critical for successful learning and transfer of this dexterous policy, through a series of ablation studies in both simulation and real-world evaluations.
Since our policy is learned through RL with many hours of simulated experience, it also exhibits a series of emergent properties such as intentional ungrasping,
% \kg{I don't believe this can be intentional and learned, do we have evidence that this is actually intentional?}\sk{we have a reward to open the gripper when the rotation diff between block and gripper becomes too large.  We have some policies which always drop and grip for some reward configuration set.}
robust retries, and intentional slow-downs. While most learning-based robotic research focuses on enabling perceptual~\cite{pinto2016,qtopt2018,levine2018} and semantic~\cite{saycan2022} generalization, we hope our work could inspire the community to look more into fundamentally enhancing the dexterity and effective workspace of robots in the real world through machine learning.

% \ps{(@Kamyar: adding contributions below. Please remove redundant lines from the previous paragraph and assimilate. )}

% The contributions of this work are as follows: We define a new task that is a significant step forward for bi-arm manipulation and dexterity. We detail each component of the system design in simulation and real world. We present large-scale distributed RL as a recipe for solving this task. We present detailed ablations to identify the critical parts of the algorithm design for successful learning. We demonstrate that the policy transfers successfully to a real world setup without any finetuning. We detail techniques for reducing Sim2Real gaps to achieve that.

% We hope that this work will spur the community to look at bi-manual setups as a testbed for learning dexterous tasks.
%     \item 
% Fair evaluation of bi-arm manipulation can be difficult, because some tasks can either require no coordination among the arms and be too easy (e.g. combination of pickâ€“and-place tasks can be solved with each arm independently)\yc{(need references)}, and other tasks can rely too heavily on functions that are orthogonal to the core control problem (e.g. towel-folding stresses accurate perception and modeling of cloth dynamics). To this end, we propose Magnetic Block Assembly as a benchmark task for real-world bi-manual manipulation. In the Magnetic Block Assembly task, individual blocks are attached to one-another via magnetic connections to create a desired structure. The use of magnets requires less precision than other mechanisms such as pegs and holes. Using solid blocks, perception and dynamics modeling problems are likewise simplified. The difficulty of the task is instead focused on coordinating two arms and cannot be performed by one arm alone. This task is also a useful end in itself because it can become a foundational operation for more complex assembly tasks in the future.

% The contributions of this work are as follows:
% \begin{itemize}
%     \item We propose an RL approach to bi-arm manipulation, with an emphasis on the critical factors for success.
%     \item We propose a block assembly task which evaluates the core coordination and manipulation aspects of the bi-arm setting.
% \end{itemize}
% \ps{(Contributions Ver2)}
% \begin{itemize}
%     \item We define a U-Shape block assembly task suitable for evaluating the long horizon reasoning, coordination and manipulation aspects of the bi-arm setting.
%     \item We propose a simulation based RL approach to bi-arm manipulation that achieves zero-shot transfer to the robot, without needing scripted controllers or human demonstrations. 
%     \item We describe the critical components of the system for achieving successful Sim2Real transfer.
% \end{itemize}

% The rest of the paper is organized as follows. \yc{(@@@depends on how we structure the rest of the paper@@@)}.


    % Robot arms are currently capable of accomplishing interesting and useful manipulation tasks, and have made their way into many industries. However, most such successes have been limited to single-arm robots, which limit solvable tasks to pick-and-place and object rearrangement problems.
    % In comparison, dual and multi arm robot platforms unlock a richer set of problems that can be tackled, such as insertion \cite{levine2016end} and laundry folding \cite{shepard2010cloth}, and have the potential to solve many more tasks. Using multiple arms can also simplify existing robot tasks, such as relaxing the need for extremely dexterous in-hand manipulation when two hands could be used.
    
    % However, the control problem for multi-arm robots is challenging due to a number of unique difficulties. Methods that execute pre-planned trajectories are more likely to see drift from the intended plan in bi-arm systems over single-arm systems. This is due to noise, asynchronous control delays, and coordination errors being amplified by having two arms. Pre-designing controllers for bi-manual systems in end-effector or task space control is also challenging as one needs to consider complex inter-arm collision avoidance and coordination behaviors. For this reason, we use reinforcement learning (RL) trained in simulation as our method to solve bi-manual tasks. Our RL approach offers the following simplifications: 1) We directly use real-time (4Hz) joint space control (rather than end-effector control), which relieves the need for run-time collision libraries or planners, 2) We do not use explicit filtering, state estimation, or observation engineering. Instead we simply use raw robot observations that are fed to a single neural network policy.
    
    % Aside from designing control algorithms, a significant challenge is to design fair evaluation tasks for bi-manual robots. Some tasks are either too easy, as they consist of independent sub-tasks that do not require coordination and could be done with one arm. And other existing tasks are difficult due to challenges that are orthogonal to bimanual control. As examples, towel-folding stresses perception and modeling cloth dynamics, while insertion stresses high precision. In this work, we offer a task that connects two (and potentially more) blocks together. The blocks are connected via magnets, which require less precision than other mechanisms such as pegs and holes. Using solid blocks, perception and dynamics modeling problems are likewise simplified. The difficulty of the task is instead focused on coordinating two arms and cannot be performed by one arm alone. This task is also a useful end in itself because it can become a foundational operation for more complex assembly tasks in the future.
    
    % To test our ideas, we implement a bi-manual platform with two xArm6 robots and 3D printed blocks with magnets attached. We find that our system has 100\% success rate with the task of picking up blocks and holding them at target locations, and 50-65\% success rate of connecting two blocks together.
