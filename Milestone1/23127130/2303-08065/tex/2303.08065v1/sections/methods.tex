\documentclass[../main.tex]{subfiles}

\begin{document}
\subsection{General Description}

The ultimate goal of our proposed framework is to predict enrollment timeline of a study at planning stage. With given number of sites in each country, a forecast of enrollment duration can be accomplished if we can model the opening time of sites and the corresponding subject recruitment pattern of each site.
In our framework, we assume the number of sites in each country is pre-specified, and the models will be built under given therapeutic area. 
We do not make any assumption on specific recruitment criterion or in-trial observation to be available. Instead, historical data, both internally and externally, plays a role in parameter estimation in each step. 

Our model consists of two parts: subject enrollment in each site and site activation in each country. For the subject enrollment model, a homogeneous Poisson Process is applied, where the rate is assumed to be the same across all sites in all countries and can be estimated from historical studies using quasi-Poisson regression. Monte Carlo sampling of subject accrual rate is also considered.  
For the site activation model, another homogeneous Poisson Process is applied, where the rate is estimated and simulated from historical data that are internally available within the author's organization. A simplified linear (fixed) approach and a perturbed approach are proposed. We will describe the model details in the next and provide a summarized modelling procedure at the end of this section.



\subsection{Poisson Process for Subject Enrollment Model}
Let $N_{ev}(u_1,u_2)$ be the number of subjects enrolled between time points $u_1$ and $u_2$. Suppose there are $n_{cntry}$ countries, where for the $i$-th country there are $n_{cntry,i}$ sites open for recruitment of subjects. Let $N_{ev,i,j}(u_1,u_2)$ be the number of subjects enrolled from the $j$-th site in the $i$-th country. Then, we assume the subject enrollment in each site is an independent Poisson Process
\[
N_{ev}(u_1,u_2) = \sum_{i=1}^{n_{cntry}} \sum_{j=1}^{n_{cntry,i}} N_{ev,i,j}(u_1,u_2),
\] 
\[
N_{ev,i,j}(u_1,u_2) \overset{\mathrm{independent}}{\sim} Poisson \left( \int_{u_1}^{u_2} \lambda_{ij}(\nu)  d \nu \right) ,
\]
where $\lambda_{ij}(=\lambda_i)$ is the subject accrual rate that are the same across all sites in a county.

In our framework, we simply use linear subject accrual rate $\lambda_i(\nu) = \mu$ that are the same across all countries. A common example for the concept of $\mu$ in clinical trials is the Patient per Site per Month ($psm$).  Given the site activation (opening) time point $u_{i,j}, i=1,\dots,n_{cntry}, j=1,\dots,n_{cntry,i}$, the rate parameter in Poisson Process can be simplified as
\[
\int_{u_1}^{u_2} \lambda_{ij}(\nu)  d \nu =  (u_2\vee u_{i,j}- u_1\vee u_{i,j}) \mu,
\]
where $a \vee b$ is the maximum between $a$ and $b$. Therefore, the subject enrollment model becomes
\[
N_{ev}(u_1,u_2) \sim Poisson \left( \sum_{i=1}^{n_{cntry}}  \sum_{j=1}^{n_{cntry,i}} \{u_2\vee u_{i,j}- u_1\vee u_{i,j}\} \mu  \right).
\]
Here, we assume the list of countries and the number of sites in each given country are usually given by the study team. If they are pending estimated, a country-site recommendation algorithm will be discussed in Section~\ref{sec:discussion}. With the number of sites in each countriy determined, we only need to know $\mu$ and $u_{i,j}$ to generate the subject enrollment pattern.


\subsection{Quasi-Poisson Estimation of Subject Accrual Rate $\mu$}
Since we assume the study in plan is for a new drug or a new indication within our organization, a better source for subject accrual rate estimation is the global data from Citeline (ClinicalTrials.gov) rather than the internal Clinical Trial Management System (CTMS). To circumvent the caveat that Citeline does not include site-level information, the subject accrual rate $\mu$ must be modeled directly.
Suppose there are $s=1, \dots, S$ historical studies to be used in this estimation step, where the $S$ studies are filtered from Citeline under certain criteria that are subject to specific requirement for the study to forecast. For example, the criteria can include study phase, therapeutic area, indication and etc.
For each study, denote $T_{i,j}^{(s)}$ as the enrollment duration for Site $j$ in Country $i$, $X_s$ as the number of accrual subjects and $d_s$ as the offset of combined effect from number of sites and enrollment duration. The setup of quasi-Poisson is
\[
X_s \sim quasi-Poisson (\lambda_s),  \quad E(X_s) = \phi \ var(X_s) \quad \text{and} \quad \log \lambda_s = \log d_s + \mu.
\]
Here, we allow an over-dispersion effect through the dispersion parameter $\phi$ such that $E(X_s) = \phi \ var(X_s)$ and 
\[
d_s = \sum_{i=1}^{n_{cntry}^{(s)}} \sum_{j=1}^{n_{cntry,i}^{(s)}} T_{i,j}^{(s)}.
\]

The offset $d_s$ serves as a calibration in modeling the rate $\mu$ using count data. In most cases, the widely-used $psm$ simply reflects the total number of subject divided by the total number of sites and entire study duration. However, due to operational considerations and other reasons, countries can start up in different pace. Hence, the $psm$ before any adjustment can be slower and leads to a forecast departing far from reality. We propose to adjust the $d_s$, which should be in the magnitude of "site*month", by integrating the opening time of each site, approximately or exactly upon data availability. For example, suppose the enrollment of study lasted 10 months, where Country~1 opened 50 sites at Day 1 and Country~2 opened 20 sites at Month 6. Then, $d_s$ for this historical trial becomes 600 site*month as illustrated in Figure~\ref{fig:offset_adjust}. Ideally, when each site opening time is documented and available to public, it is better to calculate the $d_s$ from such granule information. However, country start-up times sometimes are even unknown. Under such circumstances, we suggest applying the idea in Section~\ref{sec:fixed_estimate} to estimate $T_{i,j}^{(s)}$.

\begin{figure}[h]
\centering
\caption{Offset adjustment for subject accrual estimation in quasi-Poisson estimation.}
\label{fig:offset_adjust}
\includegraphics[width=7cm]{./sections/images/offset_adjust}
\end{figure}


In real application, over-dispersion arises naturally when a model does not contain a parameter for modeling the variance directly. Some common cases in generalized linear models include multinomial distribution based models like logistic regression where the variance is a function of the mean, and count data models like Poisson regression where variance equals mean. To better incorporate variability in prediction of parameter distribution, Monte Carlo simulation is applied to draw the subject accrual rate given model estimate $\hat{\mu}$ and the corresponding standard deviation $\sigma_{\mu}$. For example, one can obtain a sample of $\mu_b, b=1,\dots,B$ from normal distribution $N(\hat{\mu},\sigma_{\mu}^2)$ in practice.

\begin{remark}
%\subsubsection{Discussion on random effect}
Alternatively, random effect of $\mu$ may be introduced to the Poisson model to account for over-dispersion effect, where 
\[
X_s \sim Poisson (\lambda_s), \quad \log \lambda_s = \log d_s + \mu + \tau_s, \quad \tau_s \overset{\mathrm{i.i.d.}}{\sim} N(0,\sigma_\tau^2).
\]
Through this model, the average enrollment rate from different studies can be conceptualized as a realization of population level effect for a type of indication or a category of therapeutic area. Different from the fixed quasi-Poisson model where we can only estimate the mean of accrual rate for the $S$ studies that share a common variance, we allocate the variance to broader (but hidden) group level effect such that the inference can be extended to similar collection of trials. However, random effect model usually requires moderate number of observations. 
Due to the limits of real data availability, we do not consider random effect model for now. The random effect of indication or therapeutic area can be left to future exploration. 
\end{remark}

\subsection{Poisson Process for Site Activation $u_{i,j}$ and the linear (fixed) projection} \label{sec:fixed_estimate}
Denote $N_{site,i}$ as the number of sites opened in Country $i$ and $\beta_i$ as the corresponding site opening rate. Recall $u_{i,j}$ as the $j$-th site activation time in Country $i$. We assume the sites are non-distinguishable and their activation time points follow the following Poisson Process
\[
N_{site,i}(u_2) - N_{site,i}(u_1) \sim Poisson \left( (u_2 \vee t_i - u_1\vee t_i) \beta_i \right),
\]
where $t_i = u_{i,1}$ is the first site initiation time across Country $i$, i.e., the start-up time of Country $i$. Denote $w_k$ as the whole enrollment duration for Study $k$.
Consequently, 
\[
u_{i,j} = \inf_u \{N_{site,i}(u)=j\}, \quad T_{i,j}^{(k)} = w_k - u_{i,j}.
\]

In clinical trials, from protocol approval to the first site opening, the preparation period including but not limited to building database, developing Trial Master File (TMF), training Principal Investigators, generating subject randomization schedule and preparing investigational kits can take months to a year or even long. Hence, we must estimate $t_i$ separately from $u_{i,j}$ or $T_{i,j}^{(k)}$ for better accuracy. Here, we rely on internal CTMS data rather than Citeline data to extract anchor dates due to data availability.
Our framework first uses the median of historical site initiation time within each country as 
\[
\hat{t}_i = median_k \{t_i^{(k)} | \textnormal{$t_i^{(k)}$ is the first site initiation time of Country $i$ for all available studies $k=1,\dots$}\}.    
\]
As all site activation times are available for each study in CTMS, the duration between the first site activation and the last site activation can also be found in summary. Then, the median of their ratios (i.e., the total amount of sites divided by the duration of site opening) can serve as the estimate of $\hat{\beta}_i$. 
To further simplify the Poisson Process, linear (fixed) projection can be used to approximate $N_{site,i}(u)$ and $T_{i,j}^{(k)}$ so that the time between any consecutive site openings are equal. Specifically, one can simply estimate $\hat{u}_{i,j} = \hat{t}_i + (j-1)\hat{\beta}_i$. 

Similarly,  this idea can also apply to the $T_{i,j}^{(s)}$ 
in calibrating $d_s$ from the previous section, if deemed necessary. Let $\hat{T}_{i,j}^{(s)} = w_s - \hat{u}_{i,j}$, where $w_s$ is the whole enrollment duration for Study $s$, $s=1,\dots, S$ and $\hat{u}_{i,j}$ is the activation time for the $j$-th site in Country $i$. The subscript runs within $i=1,\dots,n_{cntry}, j=1,\dots,n_{cntry,i}^{(s)}$, where $n_{cntry,i}^{(s)}$ is the total number of sites activated in Country $i$ for historical Study $s$. In application, it is common to have $w_s$ available, but $n_{cntry,i}^{(s)}$ from Citeline may be unreliable sometimes. Hence, one may further approximate $d_s$ by making $\hat{T}_{i,j}^{(s)} = w_s$ so the summation in $d_s$ reduces to the product of trial duration and total number of sites. In our numeric study, we simply plugin the estimations from internal CTMS data.


\subsection{Country-level Perturbation for Site Opening Rate $\beta_i$ and Site Initiation $t_i$} \label{sec:perturbation_estimate}
In model development, when data and model are consistent, it is always believed that a greater amount of data points can depict a more accurate and convincing story. However, when it comes to forecasting models in practice, a narrow prediction window (prediction interval) can be restrictive to guide team on study preparation or budget calculation. Another criticism is that future projection may easily shift from historical record subtly.  Therefore, we recommend introducing some randomness to avoid such spurious precision issue by performing parameter perturbation based on historical country-level data. 

For example, we can bootstrap site activation time (or site opening rate) of Country $i$ as estimates of $t_i$ (or $\beta_i$) instead of using the fixed median. We can also draw the paired samples of $t_i$ and $\beta_i$ for each country to maintain their correlation, which is commonly positive. In fact, site preparation, such as contracting and training, always starts way ahead of protocol approval in clinical trials. Delayed activation of one site (in a country) may not heavily impact other sites to be operationally ready soon, thus a faster opening pattern of $\beta_i$ usually accompany prolonged country start-up $t_i$. Besides, if a trial defers site activation, the study team is likely to urge subsequent sites to open and enroll patients to catch up timeline. As a result, the paired bootstrapping of site initiation time and site opening rate is more desirable.

\subsection{Summary of Modelling Procedure}
The Algorithm~\ref{alg:cap} provides pseudo code for our study-level enrollment prediction model.

\begin{algorithm}
\caption{Algorithm of study-level enrollment model}\label{alg:cap}
\begin{algorithmic}
\Require $u_1 \gets 0$  \Comment{E.g., The time zero can be protocol approval date.}
\Require Therapeutic area, list of countries, and etc. to filter historical data
\Ensure Anticipated amounts of sites $n_{cntry,i}$ for $i=1,\dots,n_{cntry}$ and enrolled subjects $n_{ev}$ are given.

    \For{$b=1, b++, b\leq B$}
    \State \textbf{Site Activation:}
        \State Estimate $\hat{t_i}$ for $i=1,\dots,n_{cntry}$
        \State Estimate $\hat{\beta_i}$ for $i=1,\dots,n_{cntry}$
        \State $\hat{u}_{i,j} \gets \hat{t}_i + (j-1)\hat{\beta}_i$ and $T_{i,j}^{(s)} = w_s - u_{i,j}$ for $j = 1, \dots, n_{cntry,i}$
        \State Obtain offsets for historical studies $\hat{d}_s$ for $s=1,\dots, S$ 
    \State \textbf{Subject Enrollment:}
        \State Perform quasi-Poisson model and estimate $\hat{\lambda}_s$ for $s=1,\dots, S$ 
        \State Sample $N_{ev,i,j}(u_1,u_2)$ independently and sum together
    \EndFor
\end{algorithmic}
\end{algorithm}




\end{document}