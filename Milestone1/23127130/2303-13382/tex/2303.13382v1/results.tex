\section{Results}\label{sec:results}
In this section, we present  numerical results for our proposed approach and compare  them against some baselines.
%We present  numerical results to highlight the problems with different assumptions and approaches for uncertain contact-rich systems and how these could be overcome by the approach presented in the paper. 
% Since stochastic complementarity systems are not so well studied in literature, we start with presenting some basic analysis along with results of the proposed controller. 
In particular, we would like to highlight and understand the following questions:
\begin{enumerate}
    \item Does uncertainty in complementarity constraints lead to uncertainty in state trajectory?
    % \item Can ERM sufficiently model evolution of state and complementarity variables for SDLCS?
    \item How does the proposed controller perform of variance of states for SDLCS?
    % \item How well the proposed controller perform when compared to a stochastic open-loop controller?
\end{enumerate}
% Analysis of the first two questions provides an understanding of the challenges for controlling uncertain contact-rich systems. In the remaining two questions, we propose a solution that can potentially alleviate some of these issues.

% To answer the above four questions, we plan to show the following results:
% \begin{enumerate}
% \item Time history of $\lambda, y$ and time history of $x$: Then, we can show that $x_{k+1}$ has distribution if $\lambda_{k+1}$ has distribution. Answering question No. 1. We can also show the opposite direction as well.  
% \item Show MC results with ERM. Then we can show that controller could not stabilize the system since uncertainty evolution from complementarity constraints to state dynamics is not captured even if optimization can find feasible solutions. 
% \item Show figures for MC results with mean planned trajectory with chance constraint bounds. Show table that summarizes chance constraints satisfaction. Also, to show chance constraints are active, show MC results with different probability. Open-loop controller will be also shown. 
% \end{enumerate}







% \subsection{Experiment Setup}
We implement our method using IPOPT \cite{80fe29bf9dc245ffa5c8bd7b3eee2902} with PYROBOCOP \cite{9812069}. The optimization problem is implemented on a computer with Intel i7-12700K processor. 
We set $\alpha=250, \beta=1000$ for \alg{cutting_plane}. For $\gamma$ and $\eta$ in \alg{cutting_plane}, we use the different values for different applications as shown in \tab{table_cartpole} and \tab{table_acrobot}. When we run \eq{equation_control_bilevel_MPCC} alone without using  \alg{cutting_plane}, we use 1000 samples to calculate the empirical probability of failure to evaluate the satisfaction of chance constraints. 

% To verify the robustness of open-loop trajectories obtained from our proposed optimization, we use MC simulations.
Here we explain how we simulate trajectories (i.e., perform MC simulation for SDLCS, see~\cite{shirai2022chance} for more details).
\textcolor{black}{We propagate the dynamics by finding the roots of the complementarity system with sampled parameters given the control sequence obtained from optimization. We run each case for 1000 trials with different sampled parameters to estimate the probability of failure.}
 Note that, unlike the continuous-domain dynamics, we cannot rollout the dynamics for SDLCS with the given control sequences since we do not have the access to $\lambda_{k+1}$. 
%  We add the noise sampled from the distribution which was used during optimization.

\subsection{Uncertainty Propagation for SDLCS}\label{uncertainty_demo_SDLCS}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.25\textwidth]{figures/sdlcs_dynamics-cropped.pdf} %
    \caption{(a): cartpole with softwalls. (b): acrobot with soft joints.}
    \label{fig:dynamics}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.499\textwidth]{figures/test.png} %
    \caption{Uncertainty propagation for cartpole system. Here only uncertainty arises from stiffness parameters $k_1, k_2$. }
    \label{fig:q1}
\end{figure}


\begin{figure}[t]
    \centering
    \includegraphics[width=0.479\textwidth]{figures/erm_open_cart.png} %
    \caption{Simulated trajectories for cartpole system using ERM-based controller. $\Delta=0.2$ and $\Delta_\text{test} = 0.083$. Red lines show boundaries specified in chance constraints.}
    \label{fig:cartpole_ERM}
\end{figure}

We show uncertainty evolution for SDLCS. We demonstrate this for a cartpole system with softwalls (see \cite{9197568} for more details). Here we consider both $k_1$ and $k_2$ follows uniform distributions where upper bound of uniform distribution for $k_1$ and $k_2$ is 14, 12, respectively, and the lower bound is 5 for both $k_1$ and $k_2$. In this experiment, we do not run any controller: we simply propagate SDLCS given uncertain parameters in order to show how the SDLCS behaves.

\fig{fig:q1} shows the evolution of uncertainty for the aforementioned system. At $t=0$ s,  there is no uncertainty for state $\theta_{t=0}$. However, because we provide uncertainty with $k_1$ and $k_2$, $\lambda_{t=0.1}$ has uncertainty. This is again because given realization of uncertain parameters, complementarity constraints give a realization of $\lambda$ and $y$, resulting in uncertainty in $\lambda$ and $y$. This stochastic $\lambda_{t=0.1}$ brings uncertainty in $\theta_{t=0.1}$ based on \eq{SDLCS_equations}. As shown in \fig{fig:q1}, both state and complementarity variables are stochastic. This can not be captured in approximations like Expected Residual Minimization (ERM)~\cite{drnach2021robust}.
% \djnote{Point out the distribution of different variables as a function of time. This should lead to the discussion as in why the previous approaches can fail.}

\subsection{Cartpole with Softwalls}
% We demonstrate our work for cartpole with softwalls system (see \cite{9197568} for more details). 
% \djnote{Point out the difference between contact-aware and the non-contact-aware controllers.}
% Finally, we discuss the difference between our proposed contact-aware and the non-contact-aware (i.e., $L_k=0, \forall k$ in \eq{feedback}). To observe how controllers behave in a longer horizon, we set $T = 20$ and use the same values for the other parameters. We observed that  
% Therefore, we conclude that introducing feedback to both states and forces is important to design feedback controller over SDLCS. 
We demonstrate our open- and closed-loop controllers for cartpole with softwalls system. 
$x$ is the cart position and $\theta$ is the pole angle. $u_{1}$ is the control and $\lambda_{1}, \lambda_{2}$ are the reaction forces at from the wall 1, 2, respectively.
We have the following deterministic physical parameters. $g=9.81$ is the gravitational acceleration, $m_p=0.1, m_c=1.0$ are the mass of the  pole, cart, respectively. $l=0.5$ is the length of the pole and $d=0.15$ is the distance from the origin of the coordinate to the walls.  
We assume that the uncertainty arises from the ${k_1}, {k_2}$ and use the same distribution in Sec~\ref{uncertainty_demo_SDLCS}. We set $dt=0.1$ for the explicit Euler integration and $T=6$.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.479\textwidth]{figures/feedforward_cartpole_chance_comp.png} %
    \caption{Simulated trajectories for cartpole system using our open-loop controller. $\Delta=0.2$ and $\Delta_\text{test} = 0.190$ where $\Delta$ is input of optimization and $\Delta_\text{test}$ is the empirically obtained success rate from MC simulation. Red lines show boundaries specified in chance constraints.}
    \label{fig:cartpole_open}
\end{figure}


\begin{figure}[t]
    \centering
    \includegraphics[width=0.479\textwidth]{figures/feedback_cartpole_chance_comp.png} %
    \caption{Simulated trajectories for cartpole system using our closed-loop controller. Top: $\Delta=0.6$ and $\Delta_\text{test} = 0.510$, bottom: $\Delta=0.2$ and $\Delta_\text{test} = 0.188$, where $\Delta$ is input of optimization and $\Delta_\text{test}$ is the empirically obtained success rate from MC simulation. Red lines show boundaries specified in chance constraints.}
    \label{fig:diff_chance_cartpole}
    \vspace{-2em}
\end{figure}


The results  using ERM and our controller for the open-loop trajectory are shown in \fig{fig:cartpole_ERM}, \fig{fig:cartpole_open}. We observed that the proposed open-loop controller shows the better satisfaction of chance constraints compared to the ERM-based method. This is because our method explicitly considers propagation of uncertainty for SDLCS while the ERM-based method is unable to consider. Also, we observe that the gap between the commanded $\Delta$ used in our optimization and $\Delta_\text{test}$ obtained from MC simulation over testing dataset is smaller the gap between the commanded $\Delta$ used in ERM method and $\Delta_\text{test}$ obtained from MC simulation over testing dataset. Again this is because our method could capture the evolution of uncertainty for SDLCS.
However, even our open-loop controller does not show the much better performance than the ERM. To show the higher $\Delta_\text{test}$, we need to input the higher $\Delta$ as an input of optimization. It is quite difficult especially for long-horizon planning problems since uncertainty keeps evolving, which can be observed from both \fig{fig:cartpole_ERM} and \fig{fig:cartpole_open}. 

Next, we discuss the difference among our proposed contact-aware closed-loop, the non-contact-aware (i.e., $L_k=0, \forall k$ in \eq{feedback}) closed loop, and the open-loop controllers. 
% To observe how controllers behave in a longer horizon, we set $T = 20$ and use the same values for the other parameters.
We observed that  in \tab{open_closed_vio_comarison}, \eq{equation_control_bilevel_MPCC} for  open-loop controller with high $\Delta$ was unable to find feasible solutions but \eq{equation_control_bilevel_MPCC} for  closed-loop controller could find feasible solutions. Since the closed-loop controller can change feedback gains to satisfy chance constraints, it could find feasible solutions with high $\Delta$. Also, \tab{open_closed_vio_comarison} shows that the contact-aware closed-loop controller could find the feasible solution with high $\Delta = 0.8, 0.7$  but the non-contact-aware controller (i.e., $L_k=0, \forall k$ in \eq{feedback}) could not. For SDLCS, introducing feedback to both states and forces is important to realize the robust motion. 
% Therefore, we conclude that introducing feedback to both states and forces is important to design feedback controller over SDLCS. 
The MC simulation results using our contact-aware closed-loop controller are shown in \fig{fig:diff_chance_cartpole}. In contrast to \fig{fig:cartpole_ERM} and  \fig{fig:cartpole_open}, the closed-loop controller could bound the distribution of the states because it controls covariance. 
% Also, we observed that our closed-loop controller could realize much higher $\Delta$, which can be also verified in \tab{open_closed_vio_comarison}. 
% In \tab{open_closed_vio_comarison}, \eq{equation_control_bilevel_MPCC} for  open-loop controller with high $\Delta$ was unable to find feasible solutions but \eq{equation_control_bilevel_MPCC} for  closed-loop controller could find feasible solutions. Since the closed-loop controller can change feedback gains to satisfy chance constraints, it could find feasible solutions with high $\Delta$.


We discuss computational results. 
Firstly,  we observe that our important-particle method converges and the gap between $\Delta_\text{train}$ and $\Delta_\text{test}$ is small once it finishes its third time iteration. It means that our important-particle method could successfully find feasible trajectories with relative small number of particles. 
Secondly,   in \tab{table_cartpole} the  important-particle method shows the higher $\Delta_\text{train}$ as the number of particles used in optimization increases. The proposed important-particle method shows better convergence (in total 208 s to have $\Delta_\text{train}\geq 0.49$) than the naive  method (620 s with 50 particles to have $\Delta_\text{test}\geq 0.49$) since our important-particle method keeps choosing the worst-case particles which break chance constraints. 

% Based on these observations, we verified that our controller could successfully generate robust trajectories under SDLCS. 
% 
% \tab{open_closed_vio_comarison} summarizes 

\begin{table}[t]
    \caption{{Comparison of feasibility for cartpole system among open-, non-contact-aware closed, and contact-aware-closed controllers with different $\Delta$. $\circ$ and $\times$ show if optimization finds a feasible solution or not, respectively.}}
    \centering
    \begin{tabular}{c|c|c|c|c|c}
    $\Delta$ & $0.8$& $0.7$ & $0.6$ & $0.4$  & $0.2$ \\
         \hline
         Open-loop  & $\times$ & $\times$ & $\times$ & $\circ$ & $\circ$ \\
         \hline
         Non-contact-aware closed-loop & $\times$ & $\times$ & $\circ$ & $\circ$ & $\circ$ \\
                  \hline
         Contact-aware closed-loop & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\circ$
    \end{tabular}
    \label{open_closed_vio_comarison}
\end{table}

\begin{table}[t]
    \caption{{Comparison of safe probability and runtime for cartpole system between important-particle  method (top) with $\gamma = 10, \eta=10$ and naive method (bottom) with $\Delta = 0.6$ for designing the closed-loop controller. $T$ represents runtime for each iteration and $n_p$ is the number of particles.}}
    \centering
    \begin{tabular}{c|c|c|c}
     \text{iter} & $1$& $2$ & $3$ \\
         \hline
         $\Delta_{\text{train}}$  & 0.2708 & 0.09 & 0.592 \\
         \hline
         $\Delta_{\text{test}}$  & N/A & N/A & 0.588 \\
         \hline
         T [s]  & 25 & 35 & 148
         \\
         \hline
         $n_p$  & 10 & 20 & 30
    \end{tabular}
        \begin{tabular}{c|c|c|c|c}
     Case & 1& 2 & 3 & 4\\
         \hline
         $\Delta_{\text{test}}$ & 0.277 & 0.376 & 0.451 & 0.499 \\ 
         \hline
         T [s] & 25 & 26 & 55 & 620
         \\ 
         \hline
         $n_p$ & 10 & 20 & 30 & 50
    \end{tabular}
    \label{table_cartpole}
\end{table}
% want to say:
% open loop is not suited for long-term planning
% ERM is worse than TO


% 


\subsection{Acrobot with Soft Joints}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/image258.png} %
    \caption{Simulated trajectories for acrobot using our open- and closed-loop controllers.  Top: closed-loop controller with $\Delta=0.8$ and $\Delta_\text{test} = 0.771$, bottom: open-loop controller with $\Delta=0.4$ and $\Delta_\text{test} = 0.366$. Red lines show boundaries specified in chance constraints. The reader should note that open-loop controller solution was infeasible for $\Delta=0.8$, and thus we show results for $\Delta=0.4$.}
    \label{fig:acrobot_closed}
\end{figure}





\begin{table}[t]
    \caption{{Comparison of safe probability and runtime for acrobot system between important-particle method (top) with $\gamma = 4, \eta=4$ and naive method (bottom) with $\Delta = 0.8$.} $T$ represents runtime for each iteration and $n_p$ is the number of particles.}
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|c}
     \text{iter} & $1$& $2$ & $3$ & $4$& $5$ & $6$ & $7$ \\
         \hline
         $\Delta_{\text{train}}$  & 0.426 & 0.485 & 0.562 & 0.625 & 0.363 & 0.593  & 0.763 \\
                %   $\Delta_{\text{train}}$  & 0.4268 & 0.4851 & 0.5628 & 0.6256 & 0.3633 & 0.5937  & 0.7639 \\
         \hline
         $\Delta_{\text{test}}$  & N/A & N/A & N/A & N/A & N/A & N/A & 0.771 \\
         \hline
         $T$ [s]  & 31 & 97 & 557 & 887 & 698 & 2450 & 779
         \\
         \hline
        $n_p$  & 4 & 8 & 12 & 16 & 20 & 24 & 28 
    \end{tabular}
        \begin{tabular}{c|c|c|c|c|c|c|c}
     Case & 1& 2 & 3 & 4 & 5 & 6 & 7\\
         \hline
         $\Delta_{\text{test}}$ & 0.009 & 0.103 & 0.159 & 0.541 & 0.670 & 0.553 & 0.539 \\ 
         \hline
         $T$ [s] & 31 & 15 & 229 & 260 & 944 & 3993 & 901 
         \\ 
         \hline
        $n_p$  & 4 & 8 & 12 & 16 & 20 & 24 & 28
    \end{tabular}
    \label{table_acrobot}
\end{table}

We also demonstrate our controller for acrobot with soft joints system (see \cite{9197568} for more details). $\theta_{1}$ is the first joint angle and $\theta_{2}$ is the second joint angle. 
$u_{1}$ is the control at the second joint and $\lambda_{1}, \lambda_{2}$ are the reaction forces at from the wall 1, 2, respectively.
We have the following deterministic physical parameters.$g=9.81$ is the gravitational acceleration, $m_1=0.5, m_2=1.0$ are the mass of the  pole, cart, respectively. $l_1=0.5$ is the length of the rod from the first to the second joint. $d=0.2$ is the angle limit of $\theta_1$.  
We consider the stochastic physical parameters $k$ and $l_2$ where $k$ is the stiffness of the walls and $l_2$ is the length of the second rod. We assume that $k$ follows uniform distribution where the upper bound and the lower bound of the distribution is 1.6 and 0.6, respectively. We assume that $l_2$ follows a truncated Gaussian distribution where we set the mean to 1.0, variance to 0.01, the upper bound of the interval is 1.3, and the lower bound of the interval is 0.7, respectively.
We set $dt=0.04$ for the explicit Euler integration and $T=15$.

The open- and closed-loop trajectories are shown in \fig{fig:acrobot_closed}. We observed that both controller could satisfy chance constraints over the testing dataset and the closed-loop controller shows the better performance. \tab{table_acrobot} shows that the important-particle method shows the higher $\Delta_\text{test} = 0.771$ than the naive method with the same number of particles used in optimization.




% \begin{table}[t]
%     \caption{{Comparison of feasibility for acrobot system between contact-aware and non-contact-aware closed-loop controllers with different $\Delta$.}}
%     \centering
%     \begin{tabular}{c|c|c|c|c}
%     $\Delta$ & $0.8$& $0.7$ & $0.6$  & $0.5$ \\
%          \hline
%          Contact-aware  & feasible & feasible & feasible & feasible \\
%          \hline
%          Non-contact-aware & infeasible & infeasible & feasible & feasible 
%     \end{tabular}
%     \label{contact-aware_vio_comarison}
% \end{table}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.499\textwidth]{figures/acrobot_contact_gain_comparison.png} %
%     \caption{Simulated trajectories for acrobot using our contact-aware and non-contact-aware controllers.  Top: contact-aware controller with $\Delta=0.7$ and $\Delta_\text{test} = 0.630$, bottom: non-contact-aware controller with $\Delta=0.6$ and $\Delta_\text{test} = 0.587$.}
%     \label{fig:acrobot_contact_gain_discussion}
% \end{figure}

% \subsection{Computation Results}