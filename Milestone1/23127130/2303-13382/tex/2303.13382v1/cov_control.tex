\section{Covariance Steering for Contact-Rich Systems}\label{sec:cov_control}

This section presents our proposed framework of stochastic optimal control for contact-rich systems. Our framework approximates the distribution of the state and algebraic variables  using particles. Under the assumption that $\bar{F}$ is P-matrix, our method can capture stochastic evolution of SDLCS such that we can formally guarantee the violation of states and design a closed-loop controller for SDLCS (i.e., covariance steering for SDLCS). 

%evolution of uncertainty through complementarity constraints by assuming  we can 

We first present our open- and closed-loop controller formulation for SDLCS using particles and  then present a computationally beneficial approach based on the active-point method \cite{jorge2006numerical} to accelerate the resulting optimization.

\subsection{Particle-based Control for Contact-Rich Systems}
% To overcome those issues, we propose to use particles to approximately represent the distribution of the state and algebraic variables.
We propose to solve~\eqref{equation_control} approximately using SAA by sampling the uncertainty.  In particular, we obtain $N$ realizations of the uncertainty $\Xi^N=\{\xi^1,\ldots,\xi^N\}$ by sampling the distribution $\Xi$.  In other words, we approximate the distribution $\Xi$ using a finite-dimensional distribution $\Xi^N$ which follows an uniform distribution on the samples. Accordingly, the SAA for~\eqref{equation_control} is given as 
\begin{subequations}\label{saa_equation_control}
    \begin{align}
        \min _{u}  &\;  \sum_{k=1}^{T} \left\|\mathbb{E}_{\xi \thicksim \Xi^N}\left[\mathbf{x}_{k}(\xi,u)\right] - x_d\right\|_Q^2  + \sum\limits_{k=0}^{T-1} \left\|u_k\right\|_R^2
        \label{saa_exp_cost}\\
        \text{s.t.}  &\; u_k \in \mathcal{U} \label{saa_control_bnds} \\
        &\; \text{Pr}_{\xi \thicksim \Xi^N}\left(\mathbf{x}(\xi,u) \in \mathcal{X}\right) \geq \Delta. \label{saa_chance_const}        
    \end{align}
\end{subequations}
Note that the distribution $\Xi$ has been replaced with the finite-dimensional $\Xi^N$ in the above to simplify the computation of the expectation in the objective and chance constraint.  However, there still remains the implicit function $\mathbf{x}(\xi,u)$ which requires us to simulate the SDLCS for every realization of $\xi \in \Xi^N$.  We opt to remove this difficulty by replacing the implicit functions with the corresponding trajectories $x^i, \lambda^i$ for each $\xi^i \in \Xi^N$.  

Our proposed computational formulation using $N$ particles is given by:
\begin{subequations}
\begin{flalign}
\min _{x^i, u, \lambda^i}   &\;  \sum_{k=1}^{T}
\left\| \frac{1}{N} \sum\limits_{i=1}^N x^i_{k} - x_d\right\|_Q^2
% (\bar{x}_{k} - x_g)^{\top} Q (\bar{x}_{k} - x_g)
+\sum_{k=0}^{T-1}\left\|u_k\right\|_R^2 
\label{exp_cost11}\\
\text{s.t.} &\; x_{k+1}^i={A}^i_k x_k^i+B_k u_k+{C}^i_k \lambda_{k+1}^i+{g}^i_k + w_k^i \label{slcp1_p111} \\
&\; 0 \leq \lambda_{k+1}^i \perp {D}^i_k x_k^i+E_k u_k+{F}^i_k \lambda_{k+1}^i \nonumber \\ & +{h}^i_k  +l_k^i \geq 0 \\
&\; x_0^i = x_0(\xi^i) \label{x0_condn} \\
&\; u_{k} \in \mathcal{U} \label{bounds_variables1}\\
&\; \frac{1}{N}\sum_{i=1}^{N} \mathbb{I}\left( x^i \in \mathcal{X}  \right) \geq \Delta \label{chance_const1}
\end{flalign}
\label{equation_control_MILP}
\end{subequations}
where $\mathbb{I}(\cdot)$ is an indicator function returning $1$ when the conditions in the operand are satisfied and $0$ otherwise. 
Note that $x^i, \lambda^i$ represent the state and algebraic variable trajectory, respectively, propagated from a particular set of particles $x_0^i,   \theta_k^i$ where $\theta_k^i = [{A}^i_k, {C}^i_k, {g}^i_k, {D}^i_k, {F}^i_k, {h}^i_k, w_{k}^i,  v_{k}^i]$. 
% Also, $x_{1:T}^i = [{x_{1}^i}^\top, \ldots, {x_{T}^i}^\top]^\top, \lambda_{0:T-1}^i = [{\lambda_{0}^i}^\top, \ldots, {\lambda_{T-1}^i}^\top]^\top$. 
Using $N$ trajectories obtained from $N$ particles, we approximate mean of random variables as 
$\mathbb{E}_{\xi \thicksim \Xi}[\mathbf{x}_k(\xi,u)] \approx \frac{1}{N} \sum_{i=1}^{N}x_k^i, \mathbb{E}_{\xi \in \Xi}[\boldsymbol{{\lambda}}_{k}(\xi,u)] \approx \frac{1}{N} \sum_{i=1}^{N}\lambda_k^i$. In \eq{equation_control_MILP}, we approximate \eq{exp_cost} using the mean variable as shown in \eq{exp_cost11}. 
% 
Chance constraints \eq{chance_const} can be also approximated as \eq{chance_const1} using
$N$ realization trajectories, which can be formulated as integer constraints (see \cite{5477242}).

% In this paper, we 


In this work, we consider the following controllers:
\begin{subequations}
\begin{align}
 &\textbf{feedforward}: u_k = v_k \label{feedforward}\\
&\textbf{feedback}: u_k = v_k + K_k(x_k - \bar{x}_{k}) + L_k (\lambda_k - \bar{\lambda}_{k}) \label{feedback}
\end{align}
\end{subequations}
where $K_k, L_k$ are feedback gains to control covariance.
For brevity, we use $\bar{x}_k = \frac{1}{N} \sum_{i=1}^{N}x_k^i, \bar{\lambda}_k = \frac{1}{N} \sum_{i=1}^{N}\lambda_k^i$.
We emphasize that controlling both states and contact variables is critical for contact-rich systems and thus we also introduce $L_k (\lambda_k - \bar{\lambda}_{k})$ to \eq{feedback} to stabilize the system. 
Here, we focus on discussing feedback controller \eq{feedback} for \eq{equation_control_MILP}. The optimization formulation for covariance steering of SDLCS using particles would be: 
\begin{subequations}
\begin{flalign}
&\min _{x^i, v, K, L, \lambda^i}   \sum_{k=1}^{T}
||\bar{x}_{k} - x_d||_Q^2
% (\bar{x}_{k} - x_g)^{\top} Q (\bar{x}_{k} - x_g)
+\sum_{k=0}^{T-1}\left\|u_k\right\|_R^2   \label{exp_cost11_cov}\\
\text{s. t. } 
&x_{k+1}^i=({A}^i_k + B_k K_k) x_k^i+B_k v_k \nonumber \\ &+({C}^i_k + B_k L_k) \lambda_{k+1}^i + \bar{g}^i_k \nonumber \\
&-B_kK_k \bar{x}_k - B_kL_k \bar{\lambda}_{k+1} + w_k^i \label{slcp1_p111_cov}\ \\
&0 \leq \lambda_{k+1}^i \perp ({D}^i_k + E_k K_k) x_k^i \nonumber \\ &+E_k v_k+({F}^i_k + E_k L_k) \lambda_{k+1}^i \nonumber
\\
&+{h}^i_k -E_kK_k \bar{x}_k - E_kL_k  \bar{\lambda}_{k+1} + l_k^i \geq 0 \label{compl_milp} \\
&\eq{x0_condn}, \eq{bounds_variables1}, \eq{chance_const1} \label{const_milp}
\end{flalign}
\label{equation_control_MILP_cov}
\end{subequations}
% where $A^{cl, i}_k = {A}^i_k + B_k K_k,
% B^{cl}_k = B_k, 
% C^{cl, i}_k = {C}^i_k + B_k L_k, g^{cl, i}_k = \bar{g}^i_k -B_kK_k \mathbb{E}[x_k] - B_kL_k \mathbb{E}[\lambda_{k+1}],
% D^{cl, i}_k = {D}^i_k + E_k K_k, 
% E^{cl}_k = E_k, 
% F^{cl, i}_k = {F}^i_k + E_k L_k, h^{cl, i}_k = {h}^i_k -E_kK_k \mathbb{E}[x_k] - E_kL_k \mathbb{E}[\lambda_{k+1}]$. 
% 
% 
To solve \eq{equation_control_MILP_cov}, we need to take care of, \eq{slcp1_p111_cov}, \eq{compl_milp} and \eq{chance_const1}. One method is mixed-integer programming. It is possible that binary variables can be used to deal with integer constraints \eq{chance_const1} using Big-M formulation. 
Also, bilinear terms in \eq{slcp1_p111_cov} and \eq{compl_milp} can be approximated using McCormick envelopes, leading to additional binary variables. As a result, a number of binary variables are introduced and 
% where you introduce binary variables and use some methods such as Big-M formulation to handle integer constraints. However, 
we observed that it is almost impossible to obtain a single feasible solution.
Instead, in this work, we use NLP which can solve \eq{slcp1_p111_cov} as nonlinear constraints and  \eq{compl_milp} as complementarity constraints. We describe how we solve \eq{chance_const1} using NLP through complementarity constraints in Sec~\ref{bilevel_sec}.

% \textit{Remark 1}: 
% We can employ Mixed-Integer Linear Programming (MILP), similar to \cite{5477242}, to implement \eq{equation_control_MILP_cov} by replacing \eq{exp_cost11_} with linear costs. In order to use MILP for contact-rich systems, we need to make the following modifications. Firstly, we need to convert complementarity constraints  since they are nonlinear constraints. Secondly, we have other nonlinear terms such as $K_k x_k^i$. For the first case, we can use integer constraints such as big-M formulation to deal with complementarity constraints. For the second case, we can use McCormick envelopes to approximate bilinear terms. As a result, the MILP would introduce a number of integer variables and it is almost impossible to obtain a single feasible solution since the computational complexity is quite high. Thus, in this work, we decided to work on NLP based on bilevel optimization where it can only find locally-optimal controllers but at least we hope we can relatively quickly find solutions compared to the MILP method explained here. 

\subsection{Bilevel Optimization for Particle-based Control}\label{bilevel_sec}
To solve \eq{equation_control_MILP_cov} using NLP, we need to solve integer constraints \eq{chance_const1} in NLP fashion. To achieve this, we propose the following bilevel optimization problem. 
\begin{subequations}
\begin{flalign}
\min _{x^i, v, K, L, \lambda^i, t^i, z^*}   \sum_{k=1}^{T}
\left\|\bar{x}_{k} - x_d\right\|_Q^2
% (\bar{x}_{k} - x_g)^{\top} Q (\bar{x}_{k} - x_g)
+\sum_{k=0}^{T-1}\left\|u_k\right\|_R^2  \label{exp_cost11_bilevel}\\
\text{s. t. }  \eq{slcp1_p111_cov}, \eq{compl_milp}, \eq{bounds_variables1}\label{slcp1_p111_bilevel}\\
% \bigwedge_{m=1, \ldots, N_m} f_m(x_{1:T}^i)
\forall j = 1,  \ldots, n_g, \; g_j(x)\leq t^i,  \label{param_safe}\\
\frac{1}{N}\sum_{i=1}^N z^{i, *} \geq \Delta \label{approx_bilevel_chance}\\
\forall i = 1, \ldots, N, \; z^{i, *} = \argmin_{z^i} t^i z^i |0 \leq z^i \leq 1 \label{lower_opt}
\end{flalign}
\label{equation_control_bilevel}
\end{subequations}
We introduce time-invariant parameter $t^i \in \mathbb{R}^{1}$ for each set of trajectory realization $i$.  If  $x^i \in \mathcal{X}$, $t^i \geq -\epsilon$ with $\epsilon \geq 0$. In contrast, if  $x \not \in \mathcal{X}$, $t^i \geq 0$. This condition is encoded in \eq{param_safe}. 
We have in total $N$ lower-level optimization problems \eq{lower_opt}, where each optimization is formulated as linear programming.
% We solve linear programming for each lower-level optimization \eq{lower_opt},  where 
$z^i \in \mathbb{R}^{1}$ is the decision variable used in $i$~-th lower-level optimization problem. 

The purpose of \eq{lower_opt} is to count the number of trajectory realizations that are inside $\mathcal{X}$. The optimal solution of \eq{lower_opt} can be as follows:
\begin{equation}
 z^i=   \begin{cases}1, & t^i < 0 \\ \left[0, 1\right], & t^i = 0 \\0, &  t^i > 0 \end{cases}
\end{equation}
If $t^i < 0$, \eq{param_safe} argues that  $x^i \in \mathcal{X}$ and thus we count this $i$-th trajectory propagated from $i$-th particles as one. If $t^i = 0$, \eq{param_safe} argues $x^i \in \mathcal{X}$ ($x^i$ lies on the boundary of $\mathcal{X}$) and thus  we count this $i$-th trajectory propagated from $i$-th particles as one. If $t^i > 0$, then $x^i$ is not within $\mathcal{X}$, and thus we count it as zero.  Then \eq{approx_bilevel_chance} considers the approximated chance constraints. 
% Here, it is worth noting that our method considers joint chance constraints as showon in \eq{param_safe}. Thus, 

Since the upper-level optimization decision variable $t^i$ can be influenced by other upper-level decision variables, we need to solve these two problems simultaneously, leading to a bilevel optimization problem.
Since the lower-level optimization problems are formulated as $N$ linear programming problems, we can efficiently solve the entire bilevel optimization problem using the Karush-Kuhn-Tucker (KKT) condition as follows:
\begin{subequations}
\begin{flalign}
\min _{x^i, v, K, L, \lambda^i, t^i, z^{i, *}, w^i_+, w^i_-}  \eq{exp_cost11_bilevel} \label{exp_cost11_bilevel_MPCC}\\
\text{s. t. }  \eq{slcp1_p111_bilevel}, \eq{param_safe}, \eq{approx_bilevel_chance}\label{slcp1_p111_bilevel_MPCC}\\
\forall i = 1, \ldots, N, \; 0 \leq z^{i, *} \leq 1,  w^i_+, w^i_- \geq 0\label{lower_opt_MPCC}\\
w^i_+ (z^{i, *}-1) = 0, w^i_- (z^{i, *}) = 0, \\
t^i + w^i_+  - w^i_-  = 0
\end{flalign}
\label{equation_control_bilevel_MPCC}
\end{subequations}
where $w^i_+, w^i_-$ are Lagrange multipliers associated with $z^i - 1 \leq 0$, $-z^i  \leq 0$, respectively. In conclusion, we obtain a single-level nonlinear programming problem with complementarity constraints, which can be efficiently solved using an off-the-shelf solver such as IPOPT \cite{80fe29bf9dc245ffa5c8bd7b3eee2902}.

% \textit{Remark:} $t^i$ can take zero when the trajectory $x_{1:T}^i$ lies on the edge of $\mathcal{X}$. In this case, $z^i$ can take any arbitrary value from $[0, 1]$. Hence, \eq{lower_opt} might not correctly count the number of trajectories which are on $F$. However, if the solver finds a feasible solution, it means that the solver can satisfy all constraints including \eq{approx_bilevel_chance}. Therefore, it means that the solver could find a feasible trajectory with chance constraints.
% Another way of thinking of this problem is as follows. $t^i=0$ means that $x_{1:T}^i$ lies on the edge of $F$, which is feasible. Thus, $z^i$ can take any value given constraints $0 \leq z^i \leq 1$ to satisfy \eq{approx_bilevel_chance}. [Need to be re-written]


\subsection{Important-particle Method for Particle-based Control}
One limitation of our method in Sec~\ref{bilevel_sec} is that the computation can be demanding with many particles to capture the evolution of uncertainty.
% To capture the evolution of uncertainty well, a number of particles might be necessary, which 
In this section, we present an approximate algorithm which samples important particles which might be most informative for constraint violation.
%We are interested in if we really need to have many particles to train the controller. 
To decrease the computational burden, we employ an important-particle method (see \alg{cutting_plane}) which starts from a relatively small number of particles and keeps adding  particles if the chance constraints are not satisfied due to the lack of the accurate approximation of variables. Since we start from a small number of particles, it is possible that our optimization could quickly find a feasible solution which works over testing data set. However, in the case when the problem is infeasible for some particles, we add the particles which experience maximum constraint violation to our set. Thus, we call our proposed method "important-particle" method-- the worst particles specify the boundary of feasible sets.

%If the problem is really complicated and the uncertainty is quite high, it might not happen but we still hope that  the performance of our controller improves monotonically by adding the "bad" particles, which make the controller fail to capture the evolution of uncertainty. That's why we call our method as "active-point" method - the worst particles specify the boundary of feasible sets. 
% We hope our cutting plane method would work better than the naive optimization method \eq{equation_control_bilevel_MPCC} since each iteration 

The pseudocode of our important-particle method for covariance steering is shown in \alg{cutting_plane}. 
% Given $\alpha$ particles for training the controller and $\beta$ particles for testing the controller, our method 
Param is the collection of parameters such as $Q, R$. $\alpha, \beta$ represent the number of particles for training and testing the controller, respectively. $\gamma$ is the number of initial particles our method uses during its first iteration. $\eta$ is the number of particles our methods adds to \eq{equation_control_bilevel_MPCC} for each iteration. 

As shown in \alg{cutting_plane}, our method keeps adding more particles unless either it runs more than MAX-ITER or converges to user-defined $\Delta$ given threshold $\Delta_\text{th}$. For each iteration, we run \eq{equation_control_bilevel_MPCC}. If the obtained solution is feasible, we do Monte Carlo simulation (MC simulation) over the training data set with $\alpha$ particles and calculate the empirical safe probability $\Delta_\alpha$. If this $\Delta_\alpha$ is close to or greater than $\Delta$, we terminate the while loop and run the obtained controller over the testing data set with $\beta$ particles. Otherwise, we choose the $\eta$ worst particles based on how much they violate the chance constraints and add them to $\theta$. If we obtain the infeasible solution or the "restoration phase failed" solution in IPOPT, we randomly choose the $\eta$ particles. 






  \begin{algorithm}[t]
    \small 
  \algsetup{linenosize=\small}
 \caption{$\operatorname{ImportantParticle}(\text{Param}, \alpha, \beta, \gamma, \eta)$}
 \label{cutting_plane}
 \begin{algorithmic}[1]
 \STATE $j = 0$, $\theta = \gamma$, $\Delta_\alpha = 0$
 \WHILE{$j\leq \text{MAX-ITER}$ \AND $(\Delta-\Delta_\alpha)^2 \geq \Delta_\text{th}$ \AND $\Delta > \Delta_\alpha$;} 
 \STATE Run \eq{equation_control_bilevel_MPCC} with $N=\theta$
  \IF{The obtained solution from \eq{equation_control_bilevel_MPCC} is feasible}\label{4400}
 \STATE Run MC simulation with $\alpha$ particles and calculate $\Delta_\alpha$.\label{line23}
 \STATE Choose the $\eta$ worst particles that violate chance constraints.
 \ELSE
 \STATE Choose the random $\eta$ particles.
 \ENDIF
 \STATE $\theta = \theta + \eta$
 \ENDWHILE
 \STATE Run MC simulation with $\beta$ particles and calculate $\Delta_\beta$.
  \RETURN $x^{i, *}, v^*, K^*, L^*, \lambda^{i, *}, t^{i, *}, z^{i, *}, w^i_+, w^i_-, \Delta_\beta$
 \end{algorithmic} 
 \end{algorithm}




% \textit{Remark 2}: In this work, 

% We first present open-loop controller for SDLCS and then present closed-loop controller for SDLCS (i.e., covariance steering). 

% \subsection{Open-Loop Controller for SDLCS}
% Overview is presented in \tab{open_sdlcs}. Here we explain non-trivial details involving integer variables. 


% \subsubsection{Chance Constraints}
% To approximate the chance constraints, we need to count the number of particles that fall outside of region $A$. To realize this, we introduce binary variables $z = [z_1, \ldots, z_N]$, where $z_i \in \{0, 1\} \forall i = 1, \ldots, N$. We define $z_i$ so that $z_i = 0$ means that particle $i$ falls inside $A$ and $z_i$ means that particle $i$ falls outside $A$. We can formulate this constraint using big-M formulation. 

% \subsubsection{Complementarity Constraints} 

% Complementarity constraints are expressed in \eq{slcp2_p} which has $\max$ operator. We can deal with it using binary variables $\alpha_{k, j}^i \in \{0, 1\}, k = 0, \ldots, T-1, j = 1, \ldots, n_c, i = 1, \ldots, N$ as follows:
% % 
% \begin{subequations}
% \begin{align}
% \alpha_{k, j}^i = 0 \Longrightarrow c_{k, j}^i \leq 0, \lambda_{k, j}^i = 0 \label{max_1} \\
% \alpha_{k, j}^i = 1 \Longrightarrow c_{k, j}^i \geq 0, \lambda_{k, j}^i = c_{k, j}^i \label{max_2}
% % 0 \leq \lambda_{k+1}^i \perp D^i x_k^i+E^i u_k+F^i \lambda_{k+1}^i+h_k^i + v_k \geq 0 \label{slcp2_p}
% \end{align}
% \end{subequations}
% where $c_{k, j}^i$ is $j$-th element of $c_{k}^i = -({\bar{F}^i})^{-1}\left(\bar{D}^i x_k^i+E^i u_k+\bar{h}^i + l_k\right)$.

% I formulated the above constraints using big-M formulation as follows:
% \begin{subequations}
% \begin{align}
% -M (1-\alpha_{k, j}^i) \leq c_{k, j}^i \leq M \alpha_{k, j}^i, 0 \leq \lambda_{k, j}^i \leq M \alpha_{k, j}^i \label{max_11} \\
% c_{k, j}^i -M (1-\alpha_{k, j}^i)  \leq \lambda_{k, j}^i \leq c_{k, j}^i +  M (1-\alpha_{k, j}^i)
% \label{max_21}
% \end{align}
% \end{subequations}


% % \subsection{Closed-Loop Controller for SDLCS}
% % First, we clarify our problem statement. This work tries to solve the following problem:
% % \begin{subequations}
% % \begin{flalign}
% % \min _{x, u, \lambda}  J(x, u, \lambda) \\
% % \text{s. t. } \text{SDLCS} \\
% % \text{Bounds on variables}\\
% % \text{Initial and terminal constraints}\\
% % \text{Chance constraints on states}
% % \end{flalign}
% %  \label{cc_ProblemStatement}
% % \end{subequations}
% % Our goal is to design robust closed-loop controller for SDLCS. The key constraints here are chance constraints, which ensures the probability of violating constraints is under the user-defined threshold. Previous works \cite{shirai2022chance} pointed out that very small uncertainty is necessary to find feasible open-loop controllers to satisfy joint chance constraints over the whole time horizon. In this work, we want to overcome this issue by introducing feedback controller and try to control covariance. By realizing this "covariance steering", our framework is able to find controller under much greater uncertainty with satisfaction of joint chance constraints. 

% % Here we define closed-loop controller as follows:
% % \begin{equation}
% %     u_k = v_k + K_k(x_k^i - \mathbb{E}[x_k]) + L_k (\lambda_{k+1}^i - \mathbb{E}[\lambda_{k+1}])
% % \end{equation}
% % Thus, the resulting SDLCS for particle $i$ would be as follows:
% % \begin{subequations}
% % \begin{align}
% % x_{k+1}^i=A x_k^i+B^i v_k+C^i \lambda_{k+1}^i+{g}^i + w_k \label{slcp1_p_cc} \\
% %  \lambda_{k+1}^i = \max{\left(0, -({{F}^i})^{-1}\left({D}^i x_k^i+E^i v_k+{h}^i + l_k\right)\right)} \label{slcp2_p_cc}
% % % 0 \leq \lambda_{k+1}^i \perp D^i x_k^i+E^i u_k+F^i \lambda_{k+1}^i+h_k^i + v_k \geq 0 \label{slcp2_p}
% % \end{align}
% % \end{subequations}
% % where $A^i = \bar{A}^i + B^i K_k, C^i = \bar{C}^i + B^i L_k, g^i = \bar{g}^i -B^iK_k \mathbb{E}[x_k] - B^iL_k \mathbb{E}[\lambda_{k+1}], D^i = \bar{D}^i + E^i K_k, F^i = \bar{F}^i + E^i L_k, h^i = \bar{h}^i -E^iK_k \mathbb{E}[x_k] - E^iL_k \mathbb{E}[\lambda_{k+1}]$. 

% %  In this work we assume $F^i$ is P-matrix and to realize this, we have the following additional constraints:
% % %  \begin{equation}
% % %      F^i \succ 0 \label{psd_const}
% % %  \end{equation}
% % %  \eq{psd_const} means that $F^i$ is positive-definite matrix. In practice, we cannot directly impose  \eq{psd_const} and thus we use the following inequality constraints:
% % %   \begin{equation}
% % %      F^i \succeq \epsilon I \label{psd_const2}
% % %  \end{equation}
% % % where $\epsilon$ is arbitrary small scalar.  Therefore, the controller $L$ tries to regulate the contact states while ensuring $F$ is P-matrix so that we can still have the access to $\lambda$ explicitly. 

% % \subsection{Mixed-Integer Linear Programming with Chance Constraints Using Particles}
% % Our MILP with chance constraints for open-loop controller of contact rich system is as follows:
% % \begin{subequations}
% % \begin{flalign}
% % \min _{x, u, \lambda, z}  \frac{1}{N} \sum_{i=1}^{N}  J\left({u}_{0: T-1}, {x}_{0: T}^{i}, {\lambda}_{0: T-1}^{i}\right) \\
% % \text{s. t. }x_{k+1}^i=A x_k^i+B^i v_k+C^i \lambda_{k+1}^i+{g}^i + w_k \label{slcp1_p_cc2} \\
% %  \lambda_{k+1}^i = \max{\left(0, -({{F}^i})^{-1}\left({D}^i x_k^i+E^i v_k+{h}^i + l_k\right)\right)} \label{slcp2_p_cc2}\\
% % x_{0}^i \sim \mathcal{N}\left(x_{s}, \Sigma_{s}\right), u_{k} \in \mathcal{U},  \lambda_k^i \leq \lambda_{u},\label{eq001}\\
% %  z_i = 0 \Longrightarrow f(x_{1:T}^i) \in A, z_i = 1 \Longrightarrow f(x_{1:T}^i) \notin A, \label{eq002}\\
% %  \alpha_{k, j}^i = 0 \Longrightarrow c_{k, j}^i \leq 0, \lambda_{k, j}^i = 0 \label{max_11} \\
% % \alpha_{k, j}^i = 1 \Longrightarrow c_{k, j}^i \geq 0, \lambda_{k, j}^i = c_{k, j}^i \label{max_21}
% % \end{flalign}
% % \end{subequations}

% \subsection{Mixed Integer Bilinear Programming with Chance Constraints Using Particles}