{
    "arxiv_id": "2303.11812",
    "paper_title": "Chinese Intermediate English Learners outdid ChatGPT in deep cohesion: Evidence from English narrative writing",
    "authors": [
        "Tongquan Zhou",
        "Siyi Cao",
        "Siruo Zhou",
        "Yao Zhang",
        "Aijing He"
    ],
    "submission_date": "2023-03-21",
    "revised_dates": [
        "2023-03-22"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CL"
    ],
    "abstract": "ChatGPT is a publicly available chatbot that can quickly generate texts on given topics, but it is unknown whether the chatbot is really superior to human writers in all aspects of writing and whether its writing quality can be prominently improved on the basis of updating commands. Consequently, this study compared the writing performance on a narrative topic by ChatGPT and Chinese intermediate English (CIE) learners so as to reveal the chatbot's advantage and disadvantage in writing. The data were analyzed in terms of five discourse components using Coh-Metrix (a special instrument for analyzing language discourses), and the results revealed that ChatGPT performed better than human writers in narrativity, word concreteness, and referential cohesion, but worse in syntactic simplicity and deep cohesion in its initial version. After more revision commands were updated, while the resulting version was facilitated in syntactic simplicity, yet it is still lagged far behind CIE learners' writing in deep cohesion. In addition, the correlation analysis of the discourse components suggests that narrativity was correlated with referential cohesion in both ChatGPT and human writers, but the correlations varied within each group.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11812v1"
    ],
    "publication_venue": null
}