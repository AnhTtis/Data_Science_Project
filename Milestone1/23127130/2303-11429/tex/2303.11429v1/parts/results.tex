\subsection{Cardiovascular diseases classification}

The experiment results showed the superior performance of the 1D ResNet model learned over raw data in both datasets. Especially, in CinC~2020, this model surpassed the 1st rank solution by a large margin. The comparison of F1 scores and the efficiency metrics (power consumption, eq. CO2) are given in Table \ref{tab:scores}. To better illustrate the tandem "Perfomance vs. Complexity" for examined models the figure \ref{fig:co2_vs_f1} fives cross-plots on F1 score and CO2 emissions for both datasets. In particular, one can reveal that DenseNet121 and ResNet50 models learned over Poincare diagrams stand out from other models as inefficient while ResNet learned on raw ECG signals outperforms. 

\begin{table}[!ht]
    \caption{Performance on test datasets for CinC~2017 and CinC~2020 competitions} 
    \label{tab:scores}
    \small
    \centering
    \begin{threeparttable}
    \begin{tabular}{p{0.1\linewidth} | p{0.1\linewidth}  p{0.11\linewidth} p{0.1\linewidth} p{0.17\linewidth} p{0.12\linewidth} }
    \toprule\toprule
    \textbf{Dataset} & \textbf{Input data} & \textbf{Model} & \textbf{F1 score} 
    & \textbf{Power consumption, Wh} 
    & \textbf{$CO_2$, g}  \\ 
    \midrule
    
            & Poincaré     & ResNet50       & 0.71          & 127 & 69         \\ %\hline
                     & Poincaré     & DenseNet121    & 0.77          & 148 & 81         \\ %\hline
    CinC~2017       & Raw Signal   & 1D CNN         & 0.84          & 077 & 42   \\ %\hline
            & Raw Signal   & 1D ResNet      & \textbf{0.85} & 44 & 24 \\ %\hline
           & Raw Signal   & Ruhi*           & 0.84          & 92 & 51 \\ %\hline
           & Time Series  & XGBoost        & 0.69          & \textbf{42} & \textbf{23} \\ \hline
    
          & Poincaré     & ResNet50       & 0.45          & 630 & 344 \\ %\hline
            & Poincaré     & DenseNet121    & 0.50          & 740 & 404 \\ %\hline
    CinC~2020          & Raw Signal   & 1D CNN         & 0.69          & 396 & 216 \\ %\hline
           & Raw Signal   & 1D ResNet      & \textbf{0.71} & \textbf{223} & \textbf{122} \\ %\hline
           & Raw Signal   & PRNA*          & 0.63          & 497 & 271 \\ %\hline
           & Time Series  & XGBoost        & 0.65          & 286 & 156 \\
    \bottomrule
    \end{tabular}
    \begin{tablenotes}
     \item *The first rank solution.
    \end{tablenotes}
    \end{threeparttable}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\textwidth]{images/CO2vsF1.png}
    \caption{F1 score vs. $CO_2$ emissions: left side - models learned over CinC 2017 dataset, right side - models learned over CinC 2020 dataset. Dotted red ellipses highlight relatively heavy models}
    \label{fig:co2_vs_f1}
\end{figure}

The Poincaré-based methods have adequate performance in the CinC~2017 challenge. However, they do not perform well in the CinC~2020 challenge. In particular, some classes are not discriminated in the Poincaré diagrams. The models ResNet50 and DenseNet121 only identified the types AF, SB, SNR, STach and other, while the metrics for the remaining types are close to zero. This result is understandable as the information on heart rate variability is not sufficient to identify many types of heart disease. They are also the most power-hungry models: ResNet50 and DenseNet121 consumed 2 to 3 times more energy than the others.

The XGBoost is under-expected because it ranked lowest in CinC~2017 and only third in CinC~2020 despite the gradient-boosting family usually gaining the highest place at many machine learning benchmarks. In terms of power consumption, this model is very efficient when processing the short-term signal in CinC~2017; however, the required energy increases by seven folds when processing the long-term signals in CinC~2020. This phenomenon is the result of the heavy preprocessing step in this pipeline.

The unidimensional convolutional models yielded excellent results in both classification performance and energy usage. The 1D CNN and 1D ResNet shared the top~2 places in both datasets. In CinC 2020, the 1D ResNet is the best model, followed by the 1D CNN with only 1\% lower. The former is also very energy efficient: the 1D ResNet consumed more energy than only XGBoost in CinC 2017 and was the most efficient model in CinC 2020. Despite the 1D CNN having a simpler base block than the 1D ResNet, the CNN required more layers than ResNet (12 CNN blocks versus 4 ResNet blocks). So the former required more power and performed less well than the latter.

% \begin{table}[h]
%     \caption{The F1 score on each sources in CinC~2020 dataset.}
%     \label{tab:cinc2020_f1_by_source}
%     \centering
%     \begin{threeparttable}
%     \begin{tabular}{|l|r|r|r|r|r|r|}
%     \toprule \toprule
%     \textbf{Model} 
%         & \begin{tabular}{@{}c@{}}\textbf{G12EC} \\ $\bar{l}=10$ \end{tabular}
%         & \begin{tabular}{@{}c@{}}\textbf{PTB-XL} \\ $\bar{l}=10$ \end{tabular}
%         & \begin{tabular}{@{}c@{}}\textbf{CPSC} \\ $\bar{l}=16$ \end{tabular} 
%         & \begin{tabular}{@{}c@{}}\textbf{CPSC-Extra} \\ $\bar{l}=16$ \end{tabular}
%         & \begin{tabular}{@{}c@{}}\textbf{PTB} \\ $\bar{l}=109$ \end{tabular} 
%         & \begin{tabular}{@{}c@{}}\textbf{INCART} \\ $\bar{l}=1800$ \end{tabular} \\ \hline
%     ResNet50 & 0.28 & 0.56 & 0.35 & 0.33 & 0.16 & 0.2 \\ \hline
%     DenseNet121 & 0.36 & 0.58 & 0.38 & 0.5 & 0.77 & 0.6 \\ \hline
%     1D CNN & 0.55 & \textbf{0.76} & 0.61 & 0.68 & 0.85 & \textbf{0.74} \\ \hline
%     1D ResNet & \textbf{0.59} & \textbf{0.76} & \textbf{0.7} & 0.66 & 0.85 & 0.7 \\ \hline
%     XGBoost & 0.56 & 0.69 & 0.55 & \textbf{0.77} &\textbf{ 0.87} & \textbf{0.74} \\ \hline
%     \end{tabular}
%     \begin{tablenotes}
%         \item[] $\bar{l}$ is the average length of signal in seconds
%     \end{tablenotes}
%     \end{threeparttable}
% \end{table}

\begin{table}[h]
    \caption{The F1 score on each sources in CinC~2020 dataset.}
    \label{tab:cinc2020_f1_by_source}
    \centering
    \begin{threeparttable}
    \begin{tabular}{l|cccccc}
    \toprule \toprule
    \textbf{Model} 
        & \begin{tabular}{@{}c@{}}\textbf{G12EC} \\ $\bar{l}=10$ \end{tabular}
        & \begin{tabular}{@{}c@{}}\textbf{PTB-XL} \\ $\bar{l}=10$ \end{tabular}
        & \begin{tabular}{@{}c@{}}\textbf{CPSC} \\ $\bar{l}=16$ \end{tabular} 
        & \begin{tabular}{@{}c@{}}\textbf{CPSC-Extra} \\ $\bar{l}=16$ \end{tabular}
        & \begin{tabular}{@{}c@{}}\textbf{PTB} \\ $\bar{l}=109$ \end{tabular} 
        & \begin{tabular}{@{}c@{}}\textbf{INCART} \\ $\bar{l}=1800$ \end{tabular} \\ \midrule
    ResNet50 & 0.28 & 0.56 & 0.35 & 0.33 & 0.16 & 0.20 \\ 
    DenseNet121 & 0.36 & 0.58 & 0.38 & 0.50 & 0.77 & 0.60 \\ 
    1D CNN & 0.55 & \textbf{0.76} & 0.61 & 0.68 & 0.85 & \textbf{0.74} \\ 
    1D ResNet & \textbf{0.59} & \textbf{0.76} & \textbf{0.70} & 0.66 & 0.85 & 0.70 \\
    XGBoost & 0.56 & 0.69 & 0.55 & \textbf{0.77} &\textbf{ 0.87} & \textbf{0.74} \\
    \bottomrule
    \end{tabular}
    \begin{tablenotes}
        \item $\bar{l}$ is the average length of signal in seconds
    \end{tablenotes}
    \end{threeparttable}
\end{table}

We also analyzed the performance of investigated models in each source of the CinC 2020 dataset (Table \ref{tab:cinc2020_f1_by_source}). The ResNet50 was good at the short-term recordings while performing poorly in long-term data. The DenseNet121 was better than ResNet50 in long-term signal classification but did not surpass the 1D Convolutional model. The XGBoost outperformed the others in long-term ECG. However, the number of long-term signals is modest, so their metrics might not stable.

\subsection{Models interpretation}

\subsubsection{DenseNet121 on Poincaré diagram classification}
Figure \ref{fig:explain_densenet} visualized the GradCAM output of DenseNet121 on CinC 2017. We can see how this model processes the Poincaré diagram differently. In the Normal graph, the model focused on the area in the upper-left and lower-right, while the shape of the point cloud was ignored. In the arrhythmia diagram, the model focuses on the point cloud or the diversion of data. 

This behavior of the model is compatible with human knowledge. For ordinary people, we do not expect any data point far away from the diagonal of the diagram. Any data point in the upper left or lower right area is evidence of abnormal changes in heart rate and predicts the problem.
%
While in arrhythmia patients, because of the fluctuation in the heartbeat statistics, the data should be very varied and form a spreading cloud in the Poincaré diagram. The bigger cloud shows more variation in heart rate.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{images/explain_densenet121.pdf}
    \caption{Explaining CinC~2017 predictions on the Poincaré diagrams using GradCam}
    \label{fig:explain_densenet}
\end{figure}


\subsubsection{1D ResNet on ECG signal classification}

Our work also took advantage of GradCAM to explore the mechanism of the 1D ResNet model. In medical literature, the ECG of Atrial fibrillation was detected by the irregular pattern in P- and T-waves around the QRS complex.

Figure \ref{fig:explain_resnet1d} shows the focusing points of the 1D ResNet when predicting the AF signal. The yellow area is the segment that the model attracts. These heatmaps show that the classifier focused on the signal at the neighbor of the QRS complex. These regions are corresponding to the P-wave and T-wave of ECG recordings. In fact, the absence or abnormality of P-wave and T-wave is related to the fluctuation of heart rate and predicts arrhythmia disease \cite{hampton2013ecg}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.65\textwidth]{images/explain_resnet1d.pdf}
    \caption{Explaining 1D ResNet decision by GradCam methods in case of normal regimes and arrhythmia}
    \label{fig:explain_resnet1d}
\end{figure}

\subsubsection{Feature importance of XGBoost}

To explore how model XGBoost predicts classes, the feature importance score was calculated and summarized in Table~\ref{tab:fi_xgboost}. The results show that the features relating to the peak of signal, like \texttt{fft\_coefficient} and \texttt{ratio\_beyond\_r\_sigma}, are the highly important features. We can see that the XGBoost model infers the heart rate information indirectly via the peak-related features, after that the model could give the prediction of arrhythmia from heart rate.

\begin{table}[!ht]
   \caption{Feature importance score of each feature group in the model \texttt{XGBoost}} 
   \label{tab:fi_xgboost}
   \small
   \centering
   \begin{tabular}{p{0.25\linewidth} | p{0.1\linewidth}  p{0.15\linewidth} }
   \toprule\toprule
   \textbf{Group} & \textbf{\# features} & \textbf{Importance score}  \\ 
   \midrule

    \texttt{fft\_coefficient} & 22 & 0.2138 \\ 
    \texttt{ratio\_beyond\_r\_sigma} & 10 & 0.1989 \\
    \texttt{autocorrelation} & 8 & 0.0935 \\ 
    \texttt{energy\_ratio\_by\_chunks} & 5 & 0.0657 \\ 
    \texttt{index\_mass\_quantile} & 5 & 0.0651 \\ 
    \texttt{lempel\_ziv\_complexity} & 5 & 0.0483 \\ 
    \texttt{agg\_autocorrelation} & 3 & 0.0444 \\ 
    \texttt{range\_count} & 3 & 0.0411 \\ 
    \texttt{spkt\_welch\_density} & 3 & 0.0408 \\ 
    \texttt{change\_quantiles} & 3 & 0.0316 \\ 
    \texttt{quantile} & 2 & 0.0279 \\ 
    \texttt{number\_peaks} & 2 & 0.0241 \\ 
    \texttt{count\_below} & 1 & 0.0185 \\ 
    \texttt{cwt\_coefficients} & 2 & 0.0154 \\ 
    \texttt{number\_crossing\_m} & 1 & 0.0137 \\ 
    % \texttt{maximum} & 1 & 0.0122 \\ 
    % \texttt{kurtosis} & 1 & 0.0113 \\ 
    % \texttt{skewness} & 1 & 0.0089 \\ 
    % \texttt{fft\_aggregated} & 1 & 0.0084 \\ 
    % \texttt{benford\_correlation} & 1 & 0.0082 \\ 
    % \texttt{binned\_entropy} & 1 & 0.0082 \\ 
    % \texttt{count\_above} & 1 & 0.0000 \\ 
       
   \bottomrule
  \end{tabular}
  
\end{table}

\subsection{Inference Time}
Table \ref{tab:infer_time} shows the comparison in the inference time among trained methods. Although that  XGBoost had a lightning prediction time, this model dominated the total inference time benchmark, which comes from the heavy processing steps. This problem leads to the fact that XGBoost still inferred 24 times longer than the second place. The Poincaré-based method requires an approximate two-fold longer inference time than the 1D CNN or 1D ResNet. This result complies with the mathematical characteristics of the 1D and 2D convolutional operators.

\begin{table}[!ht]
   \caption{The inference time of trained models.} 
   \label{tab:infer_time}
   \small
   \centering
   \begin{tabular}{p{0.12\linewidth} | p{0.13\linewidth}  p{0.13\linewidth}  p{0.11\linewidth}}
   \toprule\toprule
   \textbf{Model} & \textbf{Processing (ms)} & \textbf{Prediction (ms)} & \textbf{Total (ms)} \\ 
   \midrule
   
   \textbf{ResNet50} & 33.7 & 37.9 & 71.6  \\
   \textbf{DenseNet121} & 33.7 & 38.2 & 71.8 \\
   \textbf{1D CNN} & 13.5 & 27.5 & 41.0 \\
   \textbf{1D ResNet} & 13.5 & 18.8 & 32.2 \\
   \textbf{XGBoost} & 1717.6 & 0.2 & 1717.8 \\
   \bottomrule
  \end{tabular}
  
\end{table}


\subsection{Statement on computational resources and environmental impact}  

The experiment was performed on a workstation with 1 CPU Intel Core i7-9700F and 1 GPU NVIDIA RTX 3600. This work contributed totally 1.8 kg equivalent $CO_{2}$ emissions. The carbon emissions information was generated using the open-source library \textit{eco2AI}\footnote{Source code for \textit{eco2AI} is available at \url{https://github.com/sb-ai-lab/Eco2AI}} \cite{budennyy2023eco2ai}.