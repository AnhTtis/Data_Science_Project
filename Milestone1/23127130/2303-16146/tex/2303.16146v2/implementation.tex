\section{Implementation}
\label{sec:Implementation}

\subsection{IPython Integration}

To work automatically, \system{} currently depends on IPython
\cite{ipython_org}, which is an enhanced Python interpreter. This implies that a
current limitation of our implementation is that \system{} is not automatic in
standard Python. In practice, this is not a problem because the dominant
platform for the notebooks we target is the IPython notebook (usually accessed
through Jupyter \cite{jupyter}), which requires IPython. However, \system{} can
still be used as a library even with a standard Python interpreter. In the rest
of this section, we will assume that \system{} is running on top of IPython.

An IPython notebook consists of a collection of code snippets called
\emph{cells}. Each cell can be executed individually, which is commonly done in
interactive EDA workloads. The goal of our implementation to invoke \system{}
automatically before a cell is executed, and rewrite it automatically, on the
fly. A key feature of IPython that allows us to do that is the input transformer
\cite{ipython_input_transformer}. This allows us to register a function that
runs before a cell gets executed. That function gets the cell content as a
string and returns a new string which becomes the new cell. Our input
transformer just inserts a call to \system{}' main routine, with the original
cell passed as an argument. \system{} then potentially rewrites and finally
executes the cell. This is all automatic; the user just needs to import
\system{}.

\system{}' main routine gets the cell code as a string, which it first parses as
an AST. For that, we use the Python \code{ast} library \cite{python_ast}, which
parses Python code. This implies a limitation because cells can contain invalid
Python syntax (but valid for IPython, e.g., magic functions), which this library
will not handle. This did not cause serious problems in practice but we hope to
fix it in the future.

An important detail is that \system{} runs on the \emph{same} IPython instance
as the notebook, having access to the same namespace as the underlying cells.
This is necessary because \system{} needs to inspect dynamic information
like names, types, function objects, etc.

\subsection{Crossing Library Boundaries}

It might seem that we could achieve the same optimizations simply by modifying
the \code{pandas} library. In fact, for some rules, the implementation is
effectively a replacement of \code{pandas} routines with our own. For example,
\code{RemoveAxis1} is implemented by overriding \code{pandas}'s \code{apply()}.
This way, we get both the \code{@\{func\}} and the \code{@\{called\_on\}}
components easily, without needing to do source-level transformations (like the
ones we described in Section~\ref{sub-sec:rewriter}). The former is accessed
through the \code{self} implicit argument, and the latter through the
\code{func} argument to \code{apply()}.

However, this approach does not suit all cases. First, in some cases, it is
simply easier to operate as an external rewriter. For example, the rule in
Figure~\ref{fig:sort-values-rule} can be applied if \code{sort\_values()} is
followed by \code{head()}. If we overwrite \code{sort\_values()}, we cannot know
what happens with its result. If we overwrite \code{head()}, we cannot know how
the object it is applied to came to be. There are ways to work around these
limitations and one popular one is lazy execution, which has been employed for
similar purposes \cite{best_effort_lazy} (Modin also employs it).

In summary, in lazy execution, we do not execute the code but rather we log which
functions have been called. After a call chain is evaluated, the result is a
computation graph that captures the whole computation. We can evaluate it in
the trivial way (e.g., actually calling the functions in sequence), or in an
optimized way (e.g., by calling \code{nsmallest}).

% For example, in the call chain
% \code{df.sort\_values().head()}, the function \code{sort\_values()}, instead of
% sorting \code{df} and returning the new object, returns a special object which
% logs that \code{sort\_values} was called on \code{df}, let's represent it as a
% computation graph: \code{df} $\rightarrow$ \code{sort\_values}. Then,
% \code{head()} it also does not return the first 5 elements, but rather it
% augments this new computation graph, thus returning \code{df} $\rightarrow$
% \code{sort\_values} $\rightarrow$ \code{head}. 

% The effect is that at the end of
% this call chain, the resulting object captures the whole computation, 

The problem, however, is that this requires a lot of bookkeeping to know when
exactly to evaluate the computation graph, to hide from the user the fact that
the functions do not return the type the user expects them to return, to build
this computation graph, etc. In other words, lazy execution is a hack around the
fact that we do not see all the computation and we are just trying to
reconstruct it from inside a library. With an external rewriter, this is
trivially solved because we just view all the code. So, we just apply well-known
code transformation techniques.

But the most important benefit of an external rewriter is that it can
effortlessly rewrite across representations. For example, it would be nearly
impossible to support the rewrite shown in Figure~\ref{fig:concat-with-lists}
with lazy execution by keeping the API intact because \code{tolist()} is
supposed to actually return a Python list, thereby moving us away from the
library's control. So, the lists will unavoidably get concatenated in pure
Python. But an external rewriter just views the code and it can trivially
perform the rewrite.
% \iffalse
% The first why ust logistics. If we modified the Pandas code,  we would have to
% keep two code bases in-sync, and the user would have to download our version of
% Pandas. With the current approach, the user only has to download and update one
% package.

% ---

% This is not a good argument. If we could support all functionality by changing
% the library, then the user would have to download only one package (our version
% of the library), which they have to do now too. Now, seemingly there can be a
% problem with keeping in sync. Meaning, if our library lacks behind, then the
% user will have to also download Pandas to use the latest features of Pandas. But
% the user anyway has to download Pandas now. Finally, there might be a problem if
% Pandas changes its API and a rewrite that was correct now isn't. This is also.
% In both cases (either as a library or as an external tool), you can solve that
% by checking the version of the library.

% Basically, there is only one reason for not doing it in the form a library and
% that's because it lacks power. That's the reason we give below.
% \fi
