@article{multiple-rewrites,
author = {Li, John M. and Appel, Andrew W.},
title = {Deriving Efficient Program Transformations from Rewrite Rules},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {ICFP},
url = {https://doi.org/10.1145/3473579},
doi = {10.1145/3473579},
abstract = {An efficient optimizing compiler can perform many cascading rewrites in a single pass, using auxiliary data structures such as variable binding maps, delayed substitutions, and occurrence counts. Such optimizers often perform transformations according to relatively simple rewrite rules, but the subtle interactions between the data structures needed for efficiency make them tricky to write and trickier to prove correct. We present a system for semi-automatically deriving both an efficient program transformation and its correctness proof from a list of rewrite rules and specifications of the auxiliary data structures it requires. Dependent types ensure that the holes left behind by our system (for the user to fill in) are filled in correctly, allowing the user low-level control over the implementation without having to worry about getting it wrong. We implemented our system in Coq (though it could be implemented in other logics as well), and used it to write optimization passes that perform uncurrying, inlining, dead code elimination, and static evaluation of case expressions and record projections. The generated implementations are sometimes faster, and at most 40\% slower, than hand-written counterparts on a small set of benchmarks; in some cases, they require significantly less code to write and prove correct.},
journal = {Proc. ACM Program. Lang.},
month = {aug},
articleno = {74},
numpages = {29},
keywords = {shrink reduction, compiler correctness, domain-specific languages, metaprogramming, interactive theorem proving, compiler optimization}
}

@article{halide-rewrites,
author = {Newcomb, Julie L. and Adams, Andrew and Johnson, Steven and Bodik, Rastislav and Kamil, Shoaib},
title = {Verifying and Improving Halide’s Term Rewriting System with Program Synthesis},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {OOPSLA},
url = {https://doi.org/10.1145/3428234},
doi = {10.1145/3428234},
abstract = {Halide is a domain-specific language for high-performance image processing and tensor computations, widely adopted in industry. Internally, the Halide compiler relies on a term rewriting system to prove properties of code required for efficient and correct compilation. This rewrite system is a collection of handwritten transformation rules that incrementally rewrite expressions into simpler forms; the system requires high performance in both time and memory usage to keep compile times low, while operating over the undecidable theory of integers. In this work, we apply formal techniques to prove the correctness of existing rewrite rules and provide a guarantee of termination. Then, we build an automatic program synthesis system in order to craft new, provably correct rules from failure cases where the compiler was unable to prove properties. We identify and fix 4 incorrect rules as well as 8 rules which could give rise to infinite rewriting loops. We demonstrate that the synthesizer can produce better rules than hand-authored ones in five bug fixes, and describe four cases in which it has served as an assistant to a human compiler engineer. We further show that it can proactively improve weaknesses in the compiler by synthesizing a large number of rules without human supervision and showing that the enhanced ruleset lowers peak memory usage of compiled code without appreciably increasing compilation times.},
journal = {Proc. ACM Program. Lang.},
month = {nov},
articleno = {166},
numpages = {28},
keywords = {verification, term rewriting system, synthesis}
}

@inproceedings{halide,
  acmid = {2462176},
  added-at = {2016-01-01T14:11:27.000+0100},
  address = {New York, NY, USA},
  author = {Ragan-Kelley, Jonathan and Barnes, Connelly and Adams, Andrew and Paris, Sylvain and Durand, Fr{\'e}do and Amarasinghe, Saman},
  biburl = {https://www.bibsonomy.org/bibtex/2996cf997a847095b63a3b47a3e3a876d/csl_uth},
  booktitle = {Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2491956.2462176},
  interhash = {9578568d144e3fc11a1349ea08b3e0b0},
  intrahash = {996cf997a847095b63a3b47a3e3a876d},
  isbn = {978-1-4503-2014-6},
  keywords = {FPGA autotuning compiler multicore},
  location = {Seattle, Washington, USA},
  numpages = {12},
  pages = {519--530},
  publisher = {ACM},
  series = {PLDI '13},
  timestamp = {2018-02-19T18:25:17.000+0100},
  title = {Halide: A Language and Compiler for Optimizing Parallelism, Locality, and Recomputation in Image Processing Pipelines},
  url = {http://doi.acm.org/10.1145/2491956.2462176},
  year = 2013
}

@INPROCEEDINGS{llvm,
  author={Lattner, C. and Adve, V.},
  booktitle={International Symposium on Code Generation and Optimization, 2004. CGO 2004.}, 
  title={LLVM: a compilation framework for lifelong program analysis \& transformation}, 
  year={2004},
  volume={},
  number={},
  pages={75-86},
  doi={10.1109/CGO.2004.1281665}}

  @inproceedings{taso,
author = {Jia, Zhihao and Padon, Oded and Thomas, James and Warszawski, Todd and Zaharia, Matei and Aiken, Alex},
title = {TASO: Optimizing Deep Learning Computation with Automatic Generation of Graph Substitutions},
year = {2019},
isbn = {9781450368735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341301.3359630},
doi = {10.1145/3341301.3359630},
abstract = {Existing deep neural network (DNN) frameworks optimize the computation graph of a DNN by applying graph transformations manually designed by human experts. This approach misses possible graph optimizations and is difficult to scale, as new DNN operators are introduced on a regular basis.We propose TASO, the first DNN computation graph optimizer that automatically generates graph substitutions. TASO takes as input a list of operator specifications and generates candidate substitutions using the given operators as basic building blocks. All generated substitutions are formally verified against the operator specifications using an automated theorem prover. To optimize a given DNN computation graph, TASO performs a cost-based backtracking search, applying the substitutions to find an optimized graph, which can be directly used by existing DNN frameworks.Our evaluation on five real-world DNN architectures shows that TASO outperforms existing DNN frameworks by up to 2.8X, while requiring significantly less human effort. For example, TensorFlow currently contains approximately 53,000 lines of manual optimization rules, while the operator specifications needed by TASO are only 1,400 lines of code.},
booktitle = {Proceedings of the 27th ACM Symposium on Operating Systems Principles},
pages = {47–62},
numpages = {16},
keywords = {computation graph substitutions, deep neural network, superoptimization, formal verification},
location = {Huntsville, Ontario, Canada},
series = {SOSP '19}
}

@inproceedings{pet,
  author    = {Haojie Wang and
               Jidong Zhai and
               Mingyu Gao and
               Zixuan Ma and
               Shizhi Tang and
               Liyan Zheng and
               Yuanzhi Li and
               Kaiyuan Rong and
               Yuanyong Chen and
               Zhihao Jia},
  editor    = {Angela Demke Brown and
               Jay R. Lorch},
  title     = {{PET:} Optimizing Tensor Programs with Partially Equivalent Transformations
               and Automated Corrections},
  booktitle = {15th {USENIX} Symposium on Operating Systems Design and Implementation,
               {OSDI} 2021, July 14-16, 2021},
  pages     = {37--54},
  publisher = {{USENIX} Association},
  year      = {2021},
  url       = {https://www.usenix.org/conference/osdi21/presentation/wang},
  timestamp = {Sat, 09 Apr 2022 12:44:31 +0200},
  biburl    = {https://dblp.org/rec/conf/osdi/WangZGMTZLRCJ21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{vegen,
author = {Chen, Yishen and Mendis, Charith and Carbin, Michael and Amarasinghe, Saman},
title = {VeGen: A Vectorizer Generator for SIMD and Beyond},
year = {2021},
isbn = {9781450383172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3445814.3446692},
doi = {10.1145/3445814.3446692},
abstract = {Vector instructions are ubiquitous in modern processors. Traditional compiler auto-vectorization techniques have focused on targeting single instruction multiple data (SIMD) instructions. However, these auto-vectorization techniques are not sufficiently powerful to model non-SIMD vector instructions, which can accelerate applications in domains such as image processing, digital signal processing, and machine learning. To target non-SIMD instruction, compiler developers have resorted to complicated, ad hoc peephole optimizations, expending significant development time while still coming up short. As vector instruction sets continue to rapidly evolve, compilers cannot keep up with these new hardware capabilities. In this paper, we introduce Lane Level Parallelism (LLP), which captures the model of parallelism implemented by both SIMD and non-SIMD vector instructions. We present VeGen, a vectorizer generator that automatically generates a vectorization pass to uncover target-architecture-specific LLP in programs while using only instruction semantics as input. VeGen decouples, yet coordinates automatically generated target-specific vectorization utilities with its target-independent vectorization algorithm. This design enables us to systematically target non-SIMD vector instructions that until now require ad hoc coordination between different compiler stages. We show that VeGen can use non-SIMD vector instructions effectively, for example, getting speedup 3\texttimes{} (compared to LLVM’s vectorizer) on x265’s idct4 kernel.},
booktitle = {Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {902–914},
numpages = {13},
keywords = {optimization, auto-vectorization, non-SIMD},
location = {Virtual, USA},
series = {ASPLOS '21}
}

@inproceedings{alive,
author = {Lopes, Nuno and Menendez, David and Nagarakatte,  Santosh and Regehr, John},
title = {Provably Correct Peephole Optimizations with Alive},
booktitle = {PLDI'15, Portland, OR, USA},
year = {2015},
month = {June},
abstract = {Compilers should not miscompile. Our work addresses problemsÂ in developing peephole optimizations that perform local rewritingÂ to improve the efficiency of LLVM code. These optimizations areÂ individually difficult to get right, particularly in the presence of undefinedÂ behavior; taken together they represent a persistent sourceÂ of bugs. This paper presents Alive, a domain-specific language forÂ writing optimizations and for automatically either proving them correctÂ or else generating counterexamples. Furthermore, Alive canÂ be automatically translated into C++ code that is suitable for inclusionÂ in an LLVM optimization pass. Alive is based on an attemptÂ to balance usability and formal methods; for example, it capturesâbut largely hidesâthe detailed semantics of three different kindsÂ of undefined behavior in LLVM. We have translated more than 300Â LLVM optimizations into Alive and, in the process, found that eightÂ of them were wrong.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/provably-correct-peephole-optimizations-alive/},
}

@inproceedings{alive2,
author = {Lopes, Nuno P. and Lee, Juneyoung and Hur, Chung-Kil and Liu, Zhengyang and Regehr, John},
title = {Alive2: Bounded Translation Validation for LLVM},
year = {2021},
isbn = {9781450383912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3453483.3454030},
doi = {10.1145/3453483.3454030},
abstract = {We designed, implemented, and deployed Alive2: a bounded translation validation tool for the LLVM compiler’s intermediate representation (IR). It limits resource consumption by, for example, unrolling loops up to some bound, which means there are circumstances in which it misses bugs. Alive2 is designed to avoid false alarms, is fully automatic through the use of an SMT solver, and requires no changes to LLVM. By running Alive2 over LLVM’s unit test suite, we discovered and reported 47 new bugs, 28 of which have been fixed already. Moreover, our work has led to eight patches to the LLVM Language Reference—the definitive description of the semantics of its IR—and we have participated in numerous discussions with the goal of clarifying ambiguities and fixing errors in these semantics. Alive2 is open source and we also made it available on the web, where it has active users from the LLVM community.},
booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {65–79},
numpages = {15},
keywords = {Automatic Software Verification, Compilers, IR Semantics, Translation Validation},
location = {Virtual, Canada},
series = {PLDI 2021}
}


@misc{souper,
  doi = {10.48550/ARXIV.1711.04422}, 
  url = {https://arxiv.org/abs/1711.04422},
  author = {Sasnauskas, Raimondas and Chen, Yang and Collingbourne, Peter and Ketema, Jeroen and Lup, Gratian and Taneja, Jubi and Regehr, John},
  keywords = {Programming Languages (cs.PL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Souper: A Synthesizing Superoptimizer},  
  publisher = {arXiv},  
  year = {2017},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{mlir,
title	= {MLIR: Scaling Compiler Infrastructure for Domain Specific Computation},
author	= {Chris Lattner and Mehdi Amini and Uday Bondhugula and Albert Cohen and Andy Davis and Jacques Arnaud Pienaar and River Riddle and Tatiana Shpeisman and Nicolas Vasilache and Oleksandr Zinenko},
year	= {2021},
booktitle	= {CGO 2021}
}

@inproceedings{10.1145/1168857.1168906,
author = {Bansal, Sorav and Aiken, Alex},
title = {Automatic Generation of Peephole Superoptimizers},
year = {2006},
isbn = {1595934510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1168857.1168906},
doi = {10.1145/1168857.1168906},
abstract = {Peephole optimizers are typically constructed using human-written pattern matching rules, an approach that requires expertise and time, as well as being less than systematic at exploiting all opportunities for optimization. We explore fully automatic construction of peephole optimizers using brute force superoptimization. While the optimizations discovered by our automatic system may be less general than human-written counterparts, our approach has the potential to automatically learn a database of thousands to millions of optimizations, in contrast to the hundreds found in current peephole optimizers. We show experimentally that our optimizer is able to exploit performance opportunities not found by existing compilers; in particular, we show speedups from 1.7 to a factor of 10 on some compute intensive kernels over a conventional optimizing compiler.},
booktitle = {Proceedings of the 12th International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {394–403},
numpages = {10},
keywords = {code selection, peephole optimization, superoptimization},
location = {San Jose, California, USA},
series = {ASPLOS XII}
}

@article{10.1145/1168918.1168906,
author = {Bansal, Sorav and Aiken, Alex},
title = {Automatic Generation of Peephole Superoptimizers},
year = {2006},
issue_date = {November 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {11},
issn = {0362-1340},
url = {https://doi.org/10.1145/1168918.1168906},
doi = {10.1145/1168918.1168906},
abstract = {Peephole optimizers are typically constructed using human-written pattern matching rules, an approach that requires expertise and time, as well as being less than systematic at exploiting all opportunities for optimization. We explore fully automatic construction of peephole optimizers using brute force superoptimization. While the optimizations discovered by our automatic system may be less general than human-written counterparts, our approach has the potential to automatically learn a database of thousands to millions of optimizations, in contrast to the hundreds found in current peephole optimizers. We show experimentally that our optimizer is able to exploit performance opportunities not found by existing compilers; in particular, we show speedups from 1.7 to a factor of 10 on some compute intensive kernels over a conventional optimizing compiler.},
journal = {SIGPLAN Not.},
month = {oct},
pages = {394–403},
numpages = {10},
keywords = {code selection, peephole optimization, superoptimization}
}

@article{10.1145/1168919.1168906,
author = {Bansal, Sorav and Aiken, Alex},
title = {Automatic Generation of Peephole Superoptimizers},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {0163-5964},
url = {https://doi.org/10.1145/1168919.1168906},
doi = {10.1145/1168919.1168906},
abstract = {Peephole optimizers are typically constructed using human-written pattern matching rules, an approach that requires expertise and time, as well as being less than systematic at exploiting all opportunities for optimization. We explore fully automatic construction of peephole optimizers using brute force superoptimization. While the optimizations discovered by our automatic system may be less general than human-written counterparts, our approach has the potential to automatically learn a database of thousands to millions of optimizations, in contrast to the hundreds found in current peephole optimizers. We show experimentally that our optimizer is able to exploit performance opportunities not found by existing compilers; in particular, we show speedups from 1.7 to a factor of 10 on some compute intensive kernels over a conventional optimizing compiler.},
journal = {SIGARCH Comput. Archit. News},
month = {oct},
pages = {394–403},
numpages = {10},
keywords = {superoptimization, code selection, peephole optimization}
}

@article{bansal-optimize,
author = {Bansal, Sorav and Aiken, Alex},
title = {Automatic Generation of Peephole Superoptimizers},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {5},
issn = {0163-5980},
url = {https://doi.org/10.1145/1168917.1168906},
doi = {10.1145/1168917.1168906},
abstract = {Peephole optimizers are typically constructed using human-written pattern matching rules, an approach that requires expertise and time, as well as being less than systematic at exploiting all opportunities for optimization. We explore fully automatic construction of peephole optimizers using brute force superoptimization. While the optimizations discovered by our automatic system may be less general than human-written counterparts, our approach has the potential to automatically learn a database of thousands to millions of optimizations, in contrast to the hundreds found in current peephole optimizers. We show experimentally that our optimizer is able to exploit performance opportunities not found by existing compilers; in particular, we show speedups from 1.7 to a factor of 10 on some compute intensive kernels over a conventional optimizing compiler.},
journal = {SIGOPS Oper. Syst. Rev.},
month = {oct},
pages = {394–403},
numpages = {10},
keywords = {code selection, superoptimization, peephole optimization}
}

@misc{llvm_instcombine,
  author = {LLVM},
  title = {InstCombine},
  year = {2022},
  howpublished = {\url{https://llvm.org/doxygen/InstructionCombining_8cpp_source.html}},
  note = {Accessed: 2022-12-09},
}

@misc{llvm_vectorcombine,
  author = {LLVM},
  title = {VectorCombine},
  year = {2022},
  howpublished = {\url{https://llvm.org/doxygen/VectorCombine_8cpp_source.html}},
  note = {Accessed: 2022-12-09},
}
