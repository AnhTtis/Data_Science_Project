\section{Related work}
\label{sec:related}
\subsection{P2P network and Perigee}
%\noindent {\bf P2P network and Perigee.} 
A P2P network is an overlay logical network that has a wide range of applications including distributed file storage\cite{ripeanu2001peer}, distributed lookup table\cite{maymounkov2002kademlia}. Because connections on an overlay network are logical, the physical property like peer-to-peer distance is abstracted away, therefore the network topology has great impact on a node's shortest path to other nodes in the network. %\soubhik{Sudden description of Perigee here. Break from storyline.} \bowen{it is marked in the title}
Perigee\cite{mao2020perigee} is a system specifically built for blockchain, it treats peer selection as a tradeoff of exploration vs. exploitation. It uses local time measurement similar to $\GF$  as the only source of information for making peer selections. However, unlike $\GF$, Perigee only uses current set of connections to decide which peers to keep. Its core (called subset) algorithm  enumerates all possible combination of exploitation subset from the current peers, then associates each combination with a score generated using  time observation in its current connections; it chooses the exploitation peers which achieves the best score. Perigee was shown to have similar, if not superior, performance than Kademlia in many network scenarios.

\subsection{KNN and tensor graph}
%\noindent {\bf KNN and tensor graph.}
The Matrix completion problem in $\GF$ can be categorized as a unsupervised learning problem, whose input data does not contain any label and is often represented in vector form. $\GF$ employs K-nearest neighbor (KNN) to solve this learning problem, which is a method that looks for using $K$ closest vector surrounding the interested vector for interpolation. Since the optimization problem in $\GF$ is non-convex, we use  Pytorch \cite{pytorch} to empirically evaluate variables for finding their local optimal solution. Pytorch is an optimized tensor library for deep neural network, which has shown been effective to train machine learning model with appropriate loss functions. 
%A neural network is a network of tensor which encodes input, hyperparameter and output of a model that represents a learning problem. Training a model with input data is equivalent to adjusting hyperparameter for the tensors based on their gradient with respect to the model loss function. Pytorch contains a built-in differentiation engine called autograd, which automatically generates tensor's gradient if the model is properly set with 3 components: tensor input definition, tensor graph and an optimizer \soubhik{too much description of pytorch here, doesn't look relevant}. 
%$\GF$ uses pytorch to solve the formulated non-convex optimization function. 

%We use notation $[n]$ to denote integer $1,..,n$, and $X_i$ means $i$-th row of a matrix $X$. A standard softmax can be used for normalize a vector, and can be computed as $\sigma(z)_i = \frac{\exp{e^{z_i}}}{\sum_{j=1}^K \exp^{z_j}}$ where $i=1..K$, and $z=(z_1,..z_K) \in \mathbb{R}^K$ \cite{softmax} \soubhik{shouldn't the notations like this be described later in model or protocol description?}.