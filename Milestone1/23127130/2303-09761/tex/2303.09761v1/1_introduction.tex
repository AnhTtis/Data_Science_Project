\section{introduction}
\label{system:introduction}
P2P overlay network is a fundamental layer required by any blockchain consensus protocol for block delivery and reaching consensus. In a proof of work blockchain like Bitcoin, a network with high delivery latency produces a higher chance of forking in the consensus layer, effectively reducing the security parameter for any adversary to overtake the honest chain \cite{dembo2020everything}. 
%Consequently, a P2P layer needs to have a low latency network for consensus layer safety. 
In a proof of stake blockchain like Ethereum, a high latency network can delay the block propogation, and possibly reduce the participating reward because of missing protocol assigned tasks. This loss can discourage home validators(nodes) from running their own hardware, and increase the barrier for decentralization. 
%So, a low latency P2P layer is needed for decentralization. 
Decentralization is a key defense mechanism against censorship attack, which is required for the liveness property of any consensus protocol. Recently there was an outcry within Ethereum community on large staking pools engaging in censoring of certain transactions \cite{flashbot, thedefiant}. Such liveness concern can only be addressed by having a large set of decentralized nodes participating in the consensus protocol, which in turn would require underlying P2P protocol to be scalable. In the end, a node's safety also depends on security of the P2P layer. Inside the P2P network, if a node locally connects to the adversary only, its view on the state of the chain can be manipulated by feeding the wrong  blocks. Such an attack is called eclipse attack \cite{vyzovitis2020gossipsub}. Hence a P2P layer should secure nodes against connection manipulation. To summarize, a P2P protocol needs to address at least three aspects: latency, scalability and robustness to connection manipulation. We ask the question how we can design a broadcast P2P protocol that addresses those issues?
 
 %\soubhik{the main content in next para is how right design of P2P is crucial. The desired properties only came at the end. This question can be moved to that ending, I think.}


%There are different P2P schemes with tradeoff among those properties. \soubhik{This last line seems unnecessary}

Suppose there are $N$ nodes in a P2P network, a fully connected graph is a design that has the most security. Its message delivery time is constant $O(1)$ and each node only receives the broadcast message only once. But such scheme
is not scalable since the total number of connections in the entire network is $O(N^2)$. One can design a structured P2P network like Kademlia\cite{maymounkov2002kademlia}, where each node only connects to $O(log(N))$ number of peers based on  consistent hashing. The network is scalable since each node only connects to a few nodes even within a large graph; it is also efficient since the network structure helps  disseminate messages such that there is no redundant message received by each node \cite{el2003efficient}. 
%Consequently, a network with low traffic has less chance to incur high latency congestion.
Besides Kademlia, another design that reduces latency is to use synthetic coordinates\cite{dabek2004vivaldi} for creating a structured network.
However, the structured design is not secure, since an adversary can always observe the network and pinpoint connections to compromise. Proposals have been made to modify structured P2P design to accommodate the security \cite{augustine2022fully}, but as far as authors' understanding such designs have not been adopted by  scalable blockchains.  %\soubhik{write many citations like this \cite{augustine2022fully, augustine2022fully}}
%\soubhik{In SBC, there was this prof Gopal Pandurangan or something like that who gave lecture on Byzantine designs for DHTs. You might wanna confirm this.} \bowen{ good point, forget about that, I remembered such scheme is not really secure, similarly Handels is too complex noone is using it}.

An unstructured p2p network is a balanced design between the above approaches, where connections are created by randomly choosing a constant number of nodes in the network. 
Such design is scalable because the node only connects to a constant number of peers. The security is also preserved since it is difficult for an adversary to predict and manipulate the node's local network given its connections are purely random out of all possible connections. The unstructured network has drawbacks of being less efficient because it relies on flooding its local network in order to broadcast the message; it is also more difficult to add latency optimization since there is no coordination among random connections from each node. However, in production, blockchains like Ethereum and Bitcoin both use the unstructured p2p design as its overlay network,  for its good scalability and safety properties. The particular unstructured network design used by Ethereum 2.0 is descrribed in\cite{vyzovitis2020gossipsub}. However, we still need to address the latency problem as it is a potential threat to the consensus protocol, and moreover, latency is an important factor in user experience for any protocol that wants to achieve fast time block finality.

Latency optimization in unstructured P2P networks is challenging, because an algorithm needs to be adaptable to variability introduced by network churn, and to the randomness from the publishing sources. Work has been done to treat the peer selection problem as a bandit problem \cite{mao2020perigee}  in which a node makes exploration and exploitation to minimize the latency. 
%\soubhik{if possible, avoid citing at the beginning of sentence}. 
However, such scheme relies on a relatively simple heuristic that only considers the peer performance at the moment, and discard all the information explored in the past.
We noticed that there are still open design space inside peer selection problem, which improves latency while maintaining scalablility and security. Specifically, we can decouple the network modelling and peer selection into two parts, and we can optimize each of them with  higher design freedom. 
%\soubhik{Probably should describe briefly here what other design space are there. This will bring out shortcomings of Perigee.}. 

We propose $\GF$ that treats the peer selection as a learning problem whose data points are continuously collected from the network to create a model, which predicts network latency to any nodes. The model is able to adjust itself across time as the network experiences churn or randomness from the publishing sources.  
%\soubhik{this para break seems unnecessary}
Specifically, a $\GF$ instance optimizes itself through four procedures: \textbf{data observation}, \textbf{matrix constructor}, \textbf{matrix completer} and \textbf{peer selector}. %\soubhik{Seems like you have described the four procedures in following paras but no mention of these names. Just saying "this is that procedure" in appropriate places in following paras would be helpful for readers to relate to.}. 
The \textbf{data observation} procedure takes care of collecting information from the network.
The input data %\soubhik{input for what?} 
requires only the IP address from the TCP header, without extra information from the P2P overlay protocol. 
%itself\soubhik{wdym Internet? Internet is itself made of several layers.}. 
Moreover, in the context of blockchain, $\GF$ can optimize connections to miners even if the block does not include timestamp of creation, which can provide additional privacy defense.
%, hide miner's publickey with zero knowledge \soubhik{why do you need pubkey anyway for P2P optimization?} \bowen{one can use pubkey to associate blocks to miner, then a simple method is to group all relevant blocks to do an optimization}. 

The core algorithm considers every input data point as a (peer, message, delivery time) tuple observed by a $\GF$ instance. Those data points are used by the \textbf{matrix constructor} to fill in a matrix whose dimensions are message and peer. The missing entries represent the unknown delivery time for some messages with some unconnected peers. A naive implementation would be to create a large matrix for every possible message for every peer ever connected. But completing such matrix would be computationally intensive and slow, preventing the system to adapt with the network changes in real-time. In addition, using data from old history could also leads to inaccurate results, because data points collected long time ago are not reflective of the current network state. 
We solve both the issues by using a streaming algorithm to digest information in real time and deprioritize old information. This design removes the constraint to interpolate the entire matrix, and is still able to attain optimal solution by incrementally finding the best peer within a local region. 

The key step for interpolating the missing cells is to solve a non-convex optimization problem derived from the matrix, the procedure is carried out by a \textbf{matrix completer} procedure
which uses an optimizer to find the best value such that the interpolated missing values %\soubhik{Got confused here. So there is one interpolation for each row?} \bowen{yes} 
are consistent to known value in the matrix. We use $K$ nearest neighbor (see Section~\ref{sec:goldfish}) to pick up the consistent peers.
After interpolating the missing values, the \textbf{peer selector} procedure uses an altruistic exploitation strategy by choosing best peers from the existing set of peers that minimizes the broadcast latency. To dynamically adapt to the network as well as to explore new peers, a $\GF$ establishes new connections to random peers every time the exploitation strategy is run. Each node can only have a constant number of outgoing connections, the exploration process requires to drop some existing peers. But since exploration in nature is random, sometimes a good performing peer is replaced by a random peer who turned out to be less performant.
%\soubhik{this line is not clear. Did you mean they might replace them with random ones?}, 
$\GF$ inherently has the memory about which peers had good performance in the recent history, and therefore re-catches the good performing peers if they were dropped during exploration. 

To validate the design of $\GF$, we create a simulation tool that measures latency among any pair of nodes in a network. The network can be generated with arbitrary size with ability to specify constraints on degree of any node. Every node assumes two roles. A node must be either a publishing or forwarding node for the first role; and a node must either be a static node that fixes its peers, or a adaptive node that actively selects its peers  for the second role.
%\soubhik{why is there "or" and "and"? Combination is confusing.}. 
The broadcast latency measures how well a node is choosing its peers, and is computed efficiently using the shortest path algorithm. 
%\soubhik{why is there sudden mention of latency here? Is the simulation measuring latency? If so, it would be better to have this goal mentioned at the beginning of para}. 
We evaluate $\GF$ under both analytical and complex dynamic settings. In the analytical setting, only 1 $\GF$ node is adaptating and the number of publishing source is equal to the degree of the node.  We can quantify the performance by clearly defining success and failure: if $\GF$ can attain the global optimal solution %\soubhik{optimal in what quantity?} via direct connections, 
which is direct connections to all publishing sources. We show that in a network size of 100 nodes with 3 publishers, a $\GF$ node succeeds with $92.7\%$ probability from 200 randomly generated network by only exploring every peer only once. In more complex dynamic settings, many independent nodes are publishing and adapting simultaneously. Because the global optimal solution for all node simultaneously is computationally intractable, we compare $\GF$ with a baseline algorithm Perigee\cite{mao2020perigee} to solve the same problem. We show that $\GF$ has strictly superior performance in all cases, and reduces broadcast latency by  $14.5\%$ than the baseline algorithm. 

Section~\ref{sec:related} summarizes the related works. Section~\ref{sec:system_model} describes data measurement methods and network assumption. Section~\ref{sec:goldfish} dives into details of $\GF$. Section~\ref{sec: sim_and_exp} presents the simulation tool and experiment results. The code is available at \cite{goldfish}. 

% Eth longest chain https://ethereum.stackexchange.com/questions/13378/what-is-the-exact-longest-chain-rule-implemented-in-the-ethereum-homestead-p

% State current P2P network and limitation is a fundamental component to decentralized systems like Bitcoin and Ethereum to ensure data is available to sufficient number of nodes. 
%  
%Although the unstructured Bitcoin Overlay network and DHT based Ethereum overlay has shown to be secure, the space of performance improvement remains an open area. 
%
%Previous researches focus on creating a decentralized mesh back-bond network, like gossipsub, to disseminate the network messages, but it remains a question about how each mesh node connects to each other.
%
%In one approach, \cite{mao2020perigee} collects relative data delivery time from the current peers to decide a subset of current peers to retain in the future. But the approach has limitations that the candidate exploitation pools is constraint by the number of active connections, such that it takes a long time to converge to the local optima. 
%
%We don't require extra information about how publish the messages, when the message is first generated.  

%In a life time of P2P node, it continuously accepts incoming peers, initiate outgoing connections or sometimes rejecting or being rejected about an connection. The constant task of the node is relaying messages or occasionally publishing messages. A wealth of data is accumulated during the process which characterize the performance of each directly connected peers on delivering the message to itself. Some peers are better than others due to its physical resource (faster CPU, network card) or their closeness to the main publishing sources. Thus each peer has its unique responds to the underlying publishing distribution and those character reflects on the message delivery time to the node itself. (for example, in proof-of-work blockchain system, publishing distribution corresponds to the mining power). Hence it is critical for a node to optimize its connections to make it more visible to the network. A node's network connection is either an incoming connection initiated by another peer, or an outgoing connection by the node itself. Because a node has little freedom to react to an incoming connections (accept or drop), we studied a more interesting problem: how could a node adjust its outgoing connections to reduce broadcast latency to the rest of the network, while using peer data accumulated in the past.

%The problem of choosing outgoing peers inherits the spirit of a bandit problem, because choosing outgoing connections can be formulated as balancing exploration vs. exploitation whose reward is determined by their peer delivery time.
%
%After running a while, a node undergoes a series of topological changes, by adding or dropping peers between them. Each configurations is regarded as an epoch of the node, which denotes a period of experience about relaying or publishing several messages of that node. 
%
%Clearly each epoch to a node in a P2P network is characterized by its connections to the network, the network's internal topology and underlying publishing distribution. The entire epoch experience can be captured in a matrix form whose rows are messages, and columns directly connected peer.

%$\GF$ uses a novel method to e
%To merge and one past matrix $T_{i-1}$ and current data $T_{i}$, we create a new matrix whose rows are concatenation of their rows, and whose columns are union of perspective peers, (we could either simply concatenate them or sort them by on their network id.). 
%
%Clearly, every row of the matrix contains many missing entries because that message in the past, $T_{i-1}$, is only received by a subset of peers represented in the matrix column, and vise versa for message appearing in the current connections, $T_{i}$.
%
%The advantage of completing the missing value is multi-fold. First, if a node happens to accidentally(mistakenly) drop a good performing peer for exploring new peer in $T_i$ (replacing the old peer, with the new peer does not yield a good broadcast latency), the node's memory about $T_{i-1}$ can help the node to reconnect to the old peer. Second, it allows a node to select its best set of outgoing peer from a larger set, essentially the missing value represents the virtual connections that allows a node to choose a best subset of outgoing connections.
%
%The data completion is a unsupervised learning problem, where each row is a vector in some high dimensional space, whose entries are missing in some axes. We attempt to interpolate a missing value by locating its K nearest neighbors and taking a weighted sum for the missing dimension based on weights from their common present dimensions. 
%
%We devise a novel metrics using unbiased variance to measure the closeness between vectors, for accommodating an additional constraint that all time measurements are locally compared, i.e. the performance of each peer for a specific message is compared against its best performing peers for that message. 
%
%we devise a novel method to run the K NN algorithm, by formulating the problem into an optimization problem, which is then solved by a gradient graph, which is handled by Pytorch solver.
%
%After data is completed, we devise an altruistic peer exploitation rule using the complete data and neighbor's implicit feedback which simultaneously benefits the peer and the group as a whole. The peer exploration part is based on a greedy heuristics, that each node maintains a pool, and keeps depleting peers it has explored; the pool resets itself until all peers in the pools are depleted. 
 
%To evaluate the effectiveness of the new algorithm, we evaluate $\NAME$ in simulation and actual experiment. The simulations contains both artificial generated graphs to make sure the algorithm is robust a broad range of network scenario, and the network graph under the real world using bitcoin data. Since the major contribution is concerned with peer exploitation, we evaluate the broadcast latency in present of the randomly exploring peer. 
%
%The broadcast latency from a node to the rest of the graph is measured as a weighted sum of the shortest message latency between the node and all other nodes, whose weight depends on the other nodes' publishing ratio. The shortest message latency is computed with Dijkstra shortest path algorithm on a latency-weighted graph.


