\section{Experiment and Evaluation}
\label{sec: sim_and_exp}

We aim to investigate the following questions through evaluations: in a random network (1) Can a single $\GF$ instance use a short memory to find and retain the global optimal connections quickly when the unique global optimal solution is direct connections to all publishers? (2) What is the performance of multiple simultaneous $\GF$ running under varying number of publishers when global optimal for all adapting nodes is computationally intractable? (3) What is the performance of multiple $\GF$ in networks with real world propagation latency under varying number of publishers? %(4) Is $\GF$ feasible to be implemented for real world P2P system. 
We address (1-3) with a simulation tool.
%and (4) with actual AWS experiments.    



\subsection{Simulation Framework}
For answering (1) and (2), we create multiple artificial networks inside a 2D plane, where locations of nodes are uniform randomly generated along both axes. For answering (3), we use measured latency\cite{wonderproxy} among randomly selected cities in the real world to create a 3D network graph. Every node is constraint by $8$ incoming connections and $4$ outgoing connections; any pair of nodes need to respect both constraint before setting up a connection. Every node needs to relay messages as specified in Section~\ref{sec:system_model}. Network operates in round fashion. Only one publisher generates one message in each round, and each node has a fixed publishing probability, together sum to 1. Every message is broadcast until every node has a copy. The delivery latency between 2 directly connected peers has two components: fixed 20ms node (including processing and transmission) delay and propagation delay. The latency of delivering a message between any 2 nodes is the shortest path on the weighted graph, whose edge weight is propagation latency. We use Dijkstra algorithm to find the shortest path using only the exploitation edges. Each experiment is initialized with a random network topology (respecting the edge constraints) using a random seed. Every $\GF$ node uses $3$ outgoing connections for exploitation and $1$ for exploration. Every epoch contains $40$ messages(rounds), and the matrix constructor combines $3$ epochs, where the middle epoch is always the pure exploration epoch, see Section~\ref{sec:goldfish} Scheduler. Matrix completer sets $K=2$ for nearest neighbor problem, and runs at most 2000 optimization steps. The typical amount of time to run a matrix of size $120 \times 7$ requires around $20$ seconds on a 6 cores 2.6G Hz 16 memory laptop.


%.  . Each partially observed matrix contains $3$ epochs $E_1, E_2, E_3$. $E_2$ is the epoch when $\GF$ last time runs; $E_3$ keeps exploitation peers, and connect new peers using depleting pool explorer; $E_1$ is the epoch that contains the best exploitation peers before $E_2$. Hence $\GF$ runs every $2$ epochs, and includes two best exploitation peers.


%a node, $A$, is able to send outgoing connections to another node, $B$, if $A$'s total number active outgoing peers is less than its outgoing constraint, and at the same time, $B$'s total incoming peers of is also respected. 

%Each node is assumed to relay messages, but some of them publish messages like miners in Bitcoin. Every publisher node is associated with a publishing probability, similar to the hash power in the proof of work blockchain. 

%Network operates in round fashion. In each round, one publisher is selected to generate a message based on their publishing probability; the message is broadcast until every node has a copy. The latency of delivering a message between 2 directly connected peers has 2 components: node delay and propagation delay computed by euclidean distance. Both transmission delay and processing delay is assumed to be constant and grouped into node delay. The latency of delivering a message between any 2 nodes is the shortest path on the weighted graph, whose edge weight is propagation latency, and node weight is the propagation transmission combined latency. 

%Initially every node randomly connects to other nodes constraining $4$ outgoing peer, and $8$ incoming peers. $3$ of outgoing connections is reserved for exploitation and $1$ for exploration. To configure $\GF$, we decide every epoch contains $40$ messages, set $K=2$ for nearest neighbor problem. Each partially observed matrix contains $3$ epochs $E_1, E_2, E_3$. $E_2$ is the epoch when $\GF$ last time runs; $E_3$ keeps exploitation peers, and connect new peers using depleting pool explorer; $E_1$ is the epoch that contains the best exploitation peers before $E_2$. Hence $\GF$ runs every $2$ epochs, and includes two best exploitation peers.

\begin{figure*}[!hbt]
    \centering
    \includegraphics[width=0.73\textwidth]{figs/perf-compare-rand.png}
    \caption{Performance comparison between Goldfish and Perigee in a random graph of 100 nodes with exponential publishing probability. Solid line connects  median values, upper bar shows the 75th wasted latency, and bottom bar for 25th of 10 experiments. The dashed line shows captures the network that uses Perigee.}
    \label{fig:goldfish_perf}
\end{figure*}


\begin{table*}[hbt]
\centering
\caption{$\GF$ Perigee Latency on 10 experiments under both random and real model. measured in millisecond}
\scalebox{0.94}{
\begin{tabular}{|c|c|c| c | c | c | c| c| c| c| c| c|c|}
\hline
topo & $\#$ & pub & $\#$ & \multicolumn{4}{c|}{$\GF$}  & \multicolumn{4}{c|}{Perigee} & ratio  \\ \cline{4-12} type & pub & prob & adapt & 25th & 50th & 75th & $mean$ & 25th & 50th & 75th & $mean$ & mean \\ 
\hline
\multirow{10}[0]{*}{ random } &  \multirow{4}[0]{*}{ $100$ } & \multirow{4}[0]{*}{ exp }
   & 10 & 249 & 288 & 342 & 299 & 262 & 319 & 370 & 323 & 0.926\\
 \cline{4-13}
 & & & 32 & 181 & 218 & 259 & 222 & 237 & 296 & 356 & 306 & 0.725\\
 \cline{4-13}
 & & & 64 & 155 & 185 & 217 & 191 & 188 & 227 & 270 & 235 & 0.813\\
 \cline{4-13}
 & & & 100& 134 & 162 & 193 & 169  & 151 & 173 & 201 & 178 & 0.949\\
\cline{2-13}
& \multirow{3}[0]{*}{ $32$ } & \multirow{3}[0]{*}{ unif } 
   & 10 & 261 & 294 & 354 & 308 & 288 & 315 & 381 & 332 & 0.928\\
 \cline{4-13}
 & & & 32 & 197 & 228 & 264 & 234 & 255 & 293 & 330 & 298 & 0.785\\
 \cline{4-13}
 & & & 64 & 164 & 188 & 218 & 194 & 189 & 218 & 260 & 229 & 0.847\\
 \cline{4-13}
\cline{2-13}
 & \multirow{3}[0]{*}{ $64$ } & \multirow{3}[0]{*}{ unif }
   & 10 & 287 & 320 & 358 & 328 & 316 & 348 & 390 & 358 & 0.916\\
 \cline{4-13}
 & & & 32 & 250 & 282 & 312 & 284 & 260 & 301 & 342 & 306 & 0.928\\
 \cline{4-13}
 & & & 64 & 195 & 218 & 247 & 226 & 195 & 221 & 257 & 229 & 0.987\\
\cline{1-13}
 \multirow{4}[0]{*}{ real } & \multirow{4}[0]{*}{ $100$ } & \multirow{4}[0]{*}{ exp }
   & 10 & 130 & 154 & 188 & 162 & 144 & 181 & 218 & 184 & 0.880\\
 \cline{4-13}
 & & & 32 & 114 & 131 & 158 & 140 & 128 & 152 & 193 & 165 & 0.848\\
 \cline{4-13}
 & & & 64 & 100 & 114 & 131 & 120 & 118 & 136 & 163 & 145 & 0.828\\
 \cline{4-13    }
 & & & 100& 86 & 99 & 114 & 104 & 98 & 111 & 130 & 120 & 0.867\\
\hline
\end{tabular}}
\label{table:table:rand_g_perf}
\end{table*}




\subsection{Global Optimal}
We claimed that $\GF$ can use short memory to find and retain the best connections with high probability only by exploring every peer once. To evaluate the idea, we setup experiments where the number of publishers is less than or equal to exploitation limit; in such situation, the global optimal solution is direct connections to all publishers. The experiments contain 200 random graphs on a $500 \times 500$ plane, and each experiment runs on a distinct graph configuration of random node locations and initial network topology for $300$ epochs. In each graph, 3 random nodes out of 100 nodes are assigned with publishing probability $\frac{1}{3}$, and 1 other node is randomly selected to run $\GF$ for changing outgoing peers (3 exploitation and 1 exploration) per epoch; all other nodes remain static. Note that a $\GF$ has to spend at most $96$ epochs to discover every peer once. 

Fig.~\ref{fig:optimal}(a) is a histogram generated from the $200$ random experiments whose x axis is the number of epochs that a $\GF$ node does not attain optimal solution. This condition captures both the convergence rate to find the optimal solution and tendency to diverge from the optimal solution. It shows that in most (around $92.7\%$) cases $\GF$ can find and retain the optimal solution by exploring every peer only once.

Fig.~\ref{fig:optimal}(b) is a similar histogram that depicts how many epochs the $\GF$ node is sufficiently far away from its unique optimal solution. Let $\lambda_i(e)$ be the latency difference at epoch $e$ between the optimal solution and its current Dijkstra distance; we compute and plot the sum of their difference for every epoch every experiment $\lambda(e) = \sum_{i=1,2,3} \lambda_i(e)$; the criteria for an epoch to be sufficiently far is determined as $\lambda(e) / \lambda(0)>0.05$, where $\lambda(0)$ is latency which a $\GF$ node gets from random connections. From the figure, the distribution is shifted downward, around 61.5\% cases $\GF$ finds sufficiently close solution within 48 epochs. 
%See Appendix A for detail analysis to a single experiment.



%is $5\%$ of the latency sum of initial random configuration at epoch 0, which is a relaxed condition on (a). Note that a node needs $96$ epochs to connect to every peer. Figure ~\ref{fig:optimal}(a) shows that $\GF$ can find optimal peers with $92.7\%$ probability in 1 pass of all peers. Figure ~\ref{fig:optimal}(b) shows that in most cases, a $\GF$ node can find a good enough ($5\%$) of its initial latency fairly quickly.


\subsection{Multiple $\GF$ on Many Publishers Network}
When a $\GF$ is optimizing for more publishers greater than its exploitation limit, the node needs to compromise connections to balance latency to all publishers. In such complex system, finding the global optimal solution is intractable, hence we evaluate performance by comparing $\GF$ against a baseline algorithm Perigee\cite{mao2020perigee}, see Section~\ref{sec:related}.
Figure~\ref{fig:goldfish_perf} is a comparison for a 100 nodes random graph which contains 32 adapting nodes, 68 static nodes, and all nodes have publishing probabilities based on an exponential distribution (80\% probability is concentrated on 20 nodes). For evaluating broadcast latency of each node, we use only exploitation edges to compute the weighted shortest distance to all publishing sources. The broadcast latency is identified as the distance to reach $90\%$ of the publishing probability. To visualize how much extra time wasted on the topological relay as opposed to direct connection, we subtract each node's topological latency with their direct connection latency, and plot the sorted broadcast wasted latency. To get a robust comparison, we run 10 experiments with random graph to get the 25th, median, 75th percentile of $i$-th node performance. The last epoch (99) of Perigee is shown as the dashed line in the figure. 
%A similar graph that measures broadcast latency as the distance to reach $50\%$ of the publishing probability is shown in Appendix B. 
Fig.~\ref{fig:goldfish_perf} shows $\GF$ keeps improving performance until it converges at a region around epoch 64 and 99; $\GF$ has better performance than Perigee.




To robustly compare $\GF$ and Perigee, we run both systems under various network scenario, and each scenario is repeated with 10 different network initialization. %(including nodes geolocation, nodes' publishing probability assignment, initial network topology) for 100 epochs. 
Table~\ref{table:table:rand_g_perf} records the performance at their final epochs after summarizing over 10 runs. We use the identical evaluation method as above to show broadcast wasted latency. 
%(The red curve with index 7, 15, 24 in Fig.~\ref{fig:goldfish_perf} corresponds to the row whose ratio mean is 0.725). 
As the number of adapting nodes increase, both systems produce better performance, but $\GF$ is consistently better in all categories. We also observed that when there are many adaptation nodes, $\GF$ is only slightly better than the Perigee; the difference is most significant when around $30\%$ nodes in the network are adapting. 


\subsection{Evaluation based on real world latency}
We use real world geolocation and latency to setup the network. The result is shown in the lower part of Table~\ref{table:table:rand_g_perf}. Compared to Perigee, $\GF$ on average uses $14.5\%$ less time. 

%A similar performance comparison like Fig. 3 is analyzed based on real topology and its result is presented on Fig. 4.

%\subsection{AWS Experiment}
%To further test feasibility to run those algorithm on real network. We create implement everything in Go, and run the experiment on AWS. 

%We measure the CPU computation, time to run the simulation algorithm, time




