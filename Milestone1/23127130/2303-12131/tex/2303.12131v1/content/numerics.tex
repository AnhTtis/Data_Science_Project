
\section{Numerical methods}
\label{sec:numerical}

In this section we describe the numerical methods used in Hermes-3
components. The architecture described in
section~\ref{sec:software-arch} does not enforce the choice of
numerical method, but this section describes the methods which have
been implemented to date and are used in
section~\ref{sec:applications}.  The system of PDEs is solved using
the method of lines, in which the time and spatial dimensions are
treated separately: The time integrator simply integrates a set of
Ordinary Differential Equations (ODEs), and is discussed in
section~\ref{sec:time-integration}; the spatial discretisation is by
finite difference methods
(section~\ref{sec:finite_differencing}). Boundary conditions are
discussed in section~\ref{sec:boundary}.

\subsection{Time integration}
\label{sec:time-integration}

Hermes-3 is built on the BOUT++ framework~\cite{bout:manual}, and so
can make use of a range of explicit (e.g RK4), fully implicit
(e.g. BDF via SUNDIALS~\cite{hindmarsh2005}), and implicit-explicit
(e.g IMEX-BDF2 and ARKODE via SUNDIALS) methods. These were
implemented with the aim of studying time-dependent problems, such as
the study of Edge Localised Mode (ELM) eruptions~\cite{xu2010} or
tokamak edge turbulence~\cite{seto2019}, where accurate time evolution
is required.

Many of the problems of interest for Hermes-3 are steady state:
Axisymmetric tokamak transport solutions, potentially as a starting
point for 3D time-dependent turbulence simulations. To find these
steady-state solutions efficiently it is desirable to take large
timesteps, ideally an infinite timestep, damping transient
oscillations in the system. A dissipative time integration scheme that
is unconditionally stable is therefore desirable. A first order
backward Euler method and preconditioning algorithm similar to that
used in UEDGE~\cite{rognlien-2002} has been implemented here. This
method is stable for any timestep provided that the nonlinear solver,
(typically a variety of Newton's method) iterations converge. In
practice this limits the timestep to a finite, and sometimes quite
small, value.

An important ingredient to robustly and efficiently solving the
nonlinear problem at each time step is a good preconditioner: It
enables the linear inner solve to converge with fewer iterations (and
so computational cost) for larger timesteps than would otherwise be
possible. Custom preconditioners developed using a methodology such as
physics-based preconditioning~\cite{chacon2002, chacon2008} can be
highly effective, but are challenging in multi-fluid contexts: The
tokamak edge is a highly nonlinear system, with a potentially large
number of species (and so equations), coupled through atomic rates
which are typically tabulated rather than analytic, and which vary by
orders of magnitude over relatively small temperature ranges. The
approach used in UEDGE, and adopted for the Backward Euler solver
here, is to use finite differences to calculate the elements of the
system Jacobian, and then use a solver such as ILU (in serial) to
factorise and invert this approximate Jacobian.

The calculation of a dense Jacobian using finite differences would be
prohibitively slow in most cases: A typical simulation might contain
$N \simeq 10^5-10^8$ evolving quantities, while the Jacobian has $N^2$
elements. Fortunately the Jacobian is typically sparse, because the
finite differences and other interaction terms are local. This is
exploited by using the PETSc coloring
facilities~\cite{petsc-user-ref}, which are provided with the matrix
structure (determined by the finite difference stencil), and
efficiently calculate many Jacobian matrix entries
simultaneously. Because each cell only has a fixed number of
neighbours, the cost of evaluating the Jacobian is reduced from
scaling like $N^2$ to approximately linear in $N$ as the grid
resolution is increased.

The effectiveness of this time integrator for steady state problems
will be applied to 1D transport problems in
section~\ref{sec:1d-transport} (fig~\ref{fig:timederivs-rhsevals}).
For 2D transport in an axisymmetric tokamak geometry in
section~\ref{sec:applications-2d}, the CVODE
solver~\cite{hindmarsh2005} remains competitive and is used for now
while extension of the Backward Euler solver to 2D and 3D domains
continues.

\subsection{Finite differencing spatial operators}
\label{sec:finite_differencing}

The models to be shown here make use of conservative finite difference
operators which were implemented in the Hermes code~\cite{Dudson2017}
and have been improved over time and moved into the BOUT++
library. All quantities are cell centred, and advection operators are
written in terms of fluxes between cells calculated at cell faces. The
cross-field operators presently assume that the grid is orthogonal in
the tokamak poloidal plane. This limits the accuracy with which
strongly shaped divertor geometries can be simulated with the present
code. Non-orthogonal grids which align with wall surfaces can be
generated for Hermes using the BOUT++ grid generator~\cite{hypnotoad},
but the required off-diagonal metric terms have not yet been
implemented. Those terms have long been implemented in UEDGE, and were
recently added to SOLPS~\cite{dekeyser2019}, where they were found to
be essential for fluid neutral modelling on distorted grids, but
relatively unimportant when kinetic neutrals were used. Implementing
these terms is a high priority for future improvements to Hermes-3.

Because all quantities are cell centred, in the absence of dissipation
zig-zag modes are likely to develop. In~\cite{Dudson2017} an Added
Dissipation~\cite{murthy-2002} artificial dissipation term was used in
advection operators.  Here this is replaced with an HLL type flux
splitting method~\cite{harten1983}, which was developed for 1D tokamak
divertor simulations and is described in~\cite{dudson2019,
  bout:sd1d}. A further improvement made here is to use the
Monotonised Central (MC) slope limiter~\cite{vanleer1977} rather than
MinMod or Fromm limiters. The MC limiter has reduced dissipation while
still being sufficiently dissipative in the cases studied here to
maintain smooth solutions. This has been found to provide a good
balance between stability and performance when using implicit time
integration schemes.

To verify the implementation of fluid flow along the magnetic field
for smooth solutions, a set of 1D fluid equations along a magnetic
field given in equation~\ref{eq:fluid-equations} is tested using the
Method of Manufactured solutions (MMS). This testing method has become
widely used to verify the correct implementation of complex sets of
equations, in tokamak edge plasma codes~\cite{riva2014} including
BOUT++~\cite{dudson-2015}.
\begin{subequations}
  \label{eq:fluid-equations}
  \begin{align}
    \frac{\partial n}{\partial t} &= -\nabla\cdot\left(n\mathbf{b}v_{||}\right) \\
    \frac{\partial p}{\partial t} &= -\nabla\cdot\left(p\mathbf{b}v_{||}\right) - \frac{2}{3}p\nabla\cdot\left(\mathbf{b}v_{||}\right) \\
    \frac{\partial}{\partial t}\left(mnv_{||}\right) &= -\nabla\cdot\left(nv_{||}\mathbf{b}v_{||}\right) - \partial_{||}p
  \end{align}
\end{subequations}
Error norms as a function of mesh cell spacing are presented in
figure~\ref{fig:fluid-norm}, showing convergence towards the
manufactured solution on a 1D periodic domain. Second order convergence
is found for both $l^2$ and $l^\infty$ error norms, consistent with the
order of accuracy of the numerical methods used.
\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{content/fluid_norm.pdf}
  \caption{Verification of the convergence of a 1D system of fluid
    equations on a periodic domain.  Showing $l^2$ (Root-Mean-Square)
    and $l^\infty$ (Max) errors for the evolving density $N_i$,
    pressure $P_i$ and momentum $NV_i$.}
  \label{fig:fluid-norm}
\end{figure}

The intended application of Hermes-3 is to magnetically confined
fusion plasmas, in which flows are typically subsonic. Nevertheless
the code must be robust to transients, and transitions to supersonic
flow can occur in tokamak plasmas~\cite{ghendrih2011}. Figure~\ref{fig:sod-shock}
shows the results of the standard 1D Sod shock tube test case~\cite{sod1978}.
\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{content/sod_shock.pdf}
  \caption{Standard Sod shock tube problem~\cite{sod1978} at $t=0.2$. A solution with
    reference resolution ($n = 100$ cells) is compared to higher
    resolutions and their $l^2$ (RMS) errors. The inset figure shows the shock front
    in more detail.}
  \label{fig:sod-shock}
\end{figure}
In general good agreement between exact and numerical solution is
found. There are however unphysical overshoot oscillations, and in the
expanded view shown inset in figure~\ref{fig:sod-shock} it can be seen
that the numerical shock location lags the exact solution, so that the
$l^2$ error norm does not converge to zero. The result is insensitive
to time integration method, being observed with both the default CVODE
time integrator and the RK3-SSP method implemented in BOUT++. This is
likely a consequence of Hermes-3 solving the fluid equations in a
non-conservative form: pressure is solved for rather than total
energy, and reconstruction of cell edges is in terms of primitive
variables. We conclude that the methods currently implemented are
suitable and $2^{nd}$-order accurate for smooth solutions
(figure~\ref{fig:fluid-norm}), and remain robust but lose accuracy
around shocks (figure~\ref{fig:sod-shock}).  This is sufficient for
present applications. The modular nature of Hermes-3 allows multiple
fluid formulations to be implemented and inter-operate, if a method
more suited to shock capturing is required.

\subsection{Boundary conditions}
\label{sec:boundary}

The domain typically solved for in 2D and 3D Hermes-3 tokamak
simulations is an annulus consisting of a region of closed and open
magnetic flux surfaces.  An example is discussed in
section~\ref{sec:applications-2d} and shown in
figure~\ref{fig:2d_domain}. The hot ``core'' of the plasma is not
modelled because the fluid equations solved become invalid in that
region. Instead a boundary condition must be imposed at that innermost
surface where no boundary physically exists. At the outer edge of the
domain the grid is typically close to, but not aligned with, the solid
vacuum vessel of the tokamak. Boundary conditions for the
thermodynamic variables on both ``core'' and ``wall'' boundaries are
typically set to either Dirichlet or Neumann.

The boundary condition on the potential $\phi$ is a variation on the
method used in the STORM model~\cite{ukaea:storm, easy2014}: A
time-evolving boundary condition that relaxes towards a Neumann
boundary. This is implemented in the following way: When inverting the
Laplacian-type equation for $\phi$ from vorticity, the potential is
fixed at both core and wall boundaries. If a simple Dirichlet
condition is used then narrow boundary layers typically form close to
the boundaries in which the imposed boundary potential is matched to
the plasma potential. These boundary layers can develop unphysical
instabilities. Instead, at every timestep the value of the boundary
condition is adjusted towards the value inside the domain with a
characteristic timescale that is set by default to $1\mu s$. In this
manner the electrostatic potential $\phi$ evolves smoothly to
solutions that can have different potentials on core and wall
boundaries.

