\section{Software architecture}
\label{sec:software}

Hermes-3~\cite{dudson:hermes3, dudson:hermes3-manual} aims to
support a wide range of different models, with an arbitrary number of
species and equations. This flexibility presents a challenge for the
software design: A poorly chosen architecture will result in the code
complexity growing rapidly with the model size, so that further
progress becomes increasingly difficult as the model is extended.

There are many domains besides tokamak plasma physics where
performance is important, and where many different software components
have to interact in complex ways which need to be extended over time
as the software grows and is applied to new problems. A variety of
approaches have been developed within scientific computing and in
other fields. In section~\ref{sec:software-survey} we briefly describe
some of the approaches that influenced the design of Hermes-3.

\subsection{A brief survey of approaches}
\label{sec:software-survey}

Within physical sciences there are a number of codes which have
adopted designs that enable users and developers to develop components
or plugins, and to combine them in novel ways so that the ecosystem
becomes increasingly useful as new components are added. An example is
LAMMPS~\cite{lammps2022}, which uses a system of ``styles'' that
define interfaces which users can implement to modify the simulation
behaviour.

In the software industry Entity Component Systems (ECS) are a design
pattern which is commonly used in game development. Those are intended
to describe a set of ``Entities'' that have defined sets of behaviour
and can interact with each other. This design pattern offers
flexibility through composition rather than inheritance, and
considerable run-time configurability. A widely used and
high-performance implementation of an ECS is EnTT~\cite{entt}.

Task graphs are another widely applicable and powerful approach to
thinking about computations, which focuses on managing the
dependencies between components, so that at a high level the whole
calculation is a directed acyclic graph (DAG). Examples of task-based
systems include StarPU~\cite{starpu} and TaskFlow\cite{taskflow}.

An important aspect of all of these approaches is splitting complex
models into simpler components, which interact through standardised
interfaces and not global state.  This facilitates testing, in
particular unit testing, provides a powerful way to mitigate the
growth of complexity, and helps to maintain productivity as code
becomes larger.

\subsection{The design of Hermes-3}
\label{sec:software-arch}

The design of Hermes-3 is a combination of the Encapsulate
Context~\cite{kelly2003} and Command patterns~\cite{gof1994}.  The
main elements are a flexible store or database, into which values
(e.g. spatially dependent fields like densities, temperatures) can be
inserted and later retrieved; and a collection of composable model
components that set and use values in the store. The approach has
similarities to data oriented design~\cite{joshi2007}, in which loose
coupling between components is achieved by focusing on defining the
data being operated on. In fusion an example of this is the OMFIT
framework~\cite{Meneghini_2015}, which uses a tree data structure to
loosely couple data sources, codes and analysis scripts.

The data in a simulation is physical quantities, such as density and
temperature fields, and derived quantities representing terms in the
equations being solved. Hermes-3 stores these quantities in a nested
dictionary structure (a tree), using C++ \texttt{variant} to enable
different data types to be stored. A schema defines a convention for
where values are stored, for example
\texttt{state["species"]["h+"]["density"]} is the number density of
hydrogen ions.

Operations on the simulation state are performed by a collection of
composable model components, that set and use values in the state. For
example there is a component that evolves an equation for fluid
number density, another component that evolves pressure. These
components are configured when they are created, so that the same code
is used to evolve every species that needs that component. Every
component can access the whole state, so some perform calculations for
a single species, while others perform calculations involving multiple
species (e.g. collisions, sheath boundary conditions).

An important distinction between this design and one with a shared
global state is that here the state is an object which is passed to
components in a user-defined order. This has two advantages: It
controls when state can be modified, making the flow of the program
easier to understand, and it facilitates unit testing because the
inputs to the components can be precisely specified with no hidden
side-channels or large setup/teardown procedures.

Controlling when and how data can be modified is crucial to preventing
errors, such as components being run out of order so that quantities
are set or modified after use. The values being calculated are
physical quantities at the current simulation time, and so logically
do not change. It is therefore tempting to adopt an immutable
(persistent) data structure, such as the HAMT used in
Clojure~\cite{hickey2020} and available in C++ libraries such as
Immer~\cite{puente2017}. There are however situations in which
components need to modify fields set by earlier components; an
important example is applying boundary conditions. Rather than copy
arrays of data to maintain immutability, the approach used here is to
mark quantities as immutable after they have been used: A quantity can
be modified (e.g. boundary conditions applied) only if that quantity
has not already been used in a previous calculation.

The flow of information carried by the state through a sequence of components
is shown in figure~\ref{fig:state-command}.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{content/state-command.pdf}
    \caption{The State of the simulation system is passed through a
      sequence of Components in two passes. In the first pass
      components can modify the state passed to their
      \texttt{transform} function; in the second pass the state cannot
      be modified, but is used to update component internal states in
      their \texttt{finally} functions.}
    \label{fig:state-command}
\end{figure}
This design restricts when the state can be modified, limiting the
complexity of interactions between components, and making the logic of
the program easier to follow. In Hermes-3 the state is passed to each
component twice: The first time the state is mutable, and the
component can insert values into it. After all components have been
called in this way, the state is ``frozen'', and passed to each
component again but cannot be modified. In this second pass each
component can use the final state to update its own internal state,
such as time derivatives to be passed to the time integrator.  This
means that components can depend on each other's outputs, including
mutual dependencies, but all modifications must be in the first
function (called \texttt{transform()}), and in the second function
(called \texttt{finally()}) all components can assume that the state
will not subsequently change. This structure could be exploited to
enable all component \texttt{finally()} functions to be run in
parallel, but this is not currently done in Hermes-3.

The design of Hermes-3 enables run-time configuration of the
simulation equations: All of the examples shown in
section~\ref{sec:applications} use the same executable, despite
solving different sets of equations in different numbers of spatial
dimensions.  The overhead of this flexibility appears to be small, but
for high performance scientific simulation codes it is debatable
whether run-time configuration is essential: Once the simulation is
set up, it is performing the same set of operations repeatedly,
calculating time derivatives given different system states. Run-time
configuration enables the user (scientist) to modify the equations
without recompiling, but means that some errors are only caught at
runtime, which might have been caught more quickly at compile time.
Compile-time configuration of the equations solved might enable more
optimisations, since conditionals can be known and optimised out by
the compiler. Just-In-Time (JIT) compilation might offer the best of
both worlds; since the operations are the same with different data,
run-time analysis of the performance might enable on-the-fly tuning to
identify bottlenecks and optimise throughput.




