\section{Dataset}
\label{sec:dataset}
To train the contact map prediction model, we need a dataset consisting of point cloud of the rigid object, and contact areas when they undergo interaction with the volumetric deformable object. To date, there exists no such dataset, and thus we opted to curate our own synthetic dataset. To achieve this, we develop a simulation environment, named SPONGESim. The simulation environment and the dataset generation process are explained further below.

\textbf{\textit{SPONGESim} environment:} The developed SPONGESim contains actions and sensor simulation data for interacting between volumetric deformable objects and rigid objects. More precisely, we use a physics-based simulator, specifically the NVIDIA Isaac Gym simulator with Flex engine, which features the GPU-accelerated finite element method (FEM) which represents a volumetric deformable body as a graph of connected tetrahedrons. As shown in \figref{fig:sponge_env}, we build an environment in which the robot uses a deformable tool attached to a hemispherical finger to interact with the surface of target objects. In this environment, we first randomly sample contact points on the surface of the target objects and vary the orientation of the tool around the Z axis. The deformable tool then approaches the contact points from their normal directions and applies 5N of force to the target objects. Once the desired contact force is reached, we store the point cloud, contact points, deformable tool orientation, and ground-truth contact map between the deformable tool and the object as data points for training. This process of getting this information is further discussed in the following. 
\begin{figure}[!t]
    \centering
    \def\svgwidth{\linewidth}
     {\fontsize{10}{10}%\selectfont\sf
    % \input{figures_tex/datagennew.pdf_tex}}
    \input{figures_tex/sponge_env.pdf_tex}} 
    \caption{We introduce SPONGESim, a manipulation environment of realistic volumetric deformable objects interacting with rigid objects. Top: example images from the five parallel environments performing five different interactions at randomized contact locations. Bottom: the process from simulating the interaction between two objects to getting ground-truth contact map for the network.}
    \label{fig:sponge_env}
    \vspace{-0.3 cm}
\end{figure}

\textbf{Inputs to the network:} We captured depth images of target objects with a virtual camera set to view the scene from the top down. The depth images are then transformed into point clouds of the target objects. The point clouds of the target objects along with the sampled contact points and deformable tool orientation are then stored to serve as input of the contact map prediction network.

\textbf{Ground-truth contact map:} During the interaction between rigid and deformable bodies, Isaac Gym only returns the nodal positions, the nodal contact forces of the deformable body. Thus, the contact map between the rigid and deformable objects is not available to be stored directly. Therefore, we need to calculate the desired contact map from the obtained nodal position and nodal contact forces of the deformable tool. To do this, we first set a threshold of 0.5N on the nodal contact forces of the deformable tool so that a point is only considered to be in contact with the target objects if its contact force is greater than the threshold. This gives us a set of points of the deformable tool that are in contact with the target object. Next, for each point of the deformable tool in the contact set, we find its closest points (within a distance $\tau$) on the surface of the target object and label those points as in contact with the deformable tool. The labeled point cloud is then used as the ground-truth contact map for training the contact prediction network. 

\textbf{Training dataset:} As a training dataset, we generate and label the contact maps for 10 objects shown in \figref{fig:sim_objs}. The objects include 2 objects from the YCB dataset \cite{ycb}, and 8 objects from the ShapeNet dataset \cite{shapenet}. The objects chosen are mainly bowls and plates with different curvatures. For each object, labeled data was collected by simulating 1000 contacts between the deformable tool and the object. We further sped up the data generation and labeling process by executing contact interactions in parallel environments. In total, tens of thousands of unique contact interactions were conducted. 70\% of contact interactions were assigned for training, 15\% for validation, and 15\% for testing.
\begin{figure}[!t]
    \centering
    \def\svgwidth{\linewidth}
     {\fontsize{10}{10}%\selectfont\sf
    % \input{figures_tex/datagennew.pdf_tex}}
    \input{figures_tex/sim_objs.pdf_tex}} 
    \caption{The 10 individually numbered rigid objects used in simulation. The objects represent a high variation in size, shape, and curvatures.}
    \label{fig:sim_objs}
    \vspace{-0.7cm}
\end{figure}

% \begin{figure}[!t]
%     \centering
%     \def\svgwidth{0.5\linewidth}
%      {\color{white} \fontsize{8}{8}%\selectfont\sf
%     \input{figures_tex/grasprep.pdf_tex}}   
%     \caption{A grasp is represented as a rectangle in 2D image plane.}
%     \label{fig:grasprep}
%     \vspace{-0.5cm}
% \end{figure}

