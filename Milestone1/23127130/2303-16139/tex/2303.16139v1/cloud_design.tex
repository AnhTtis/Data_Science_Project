% Title needs to change.
\section{Cloud Architecture and Implementation}
\label{s:cloud_arch_impl}

In a typical on-premise deployment, the CES servers and physical network are part of the trusted infrastructure of the exchange: the exchange operators have exclusive access to the physical machines, network elements and cables. On the other, the MPs own the physical servers that connect to the exchange network. Migrating such components to the public cloud is slightly more complicated: while the CES servers and MPs could be accommodated by virtual machines owned by the different parties, but the network infrastructure is still owned by the cloud provider. Compared to on-premise deployments, \sys requires leveraging two extra components for correctness: the Release Buffer (RB) and the Ordering Buffer (OB). 
%\pg{baremetal or VM?}

\subsection{Release Buffer}
\label{ss:release_buffer}


%The Release Buffer (RB) is a critical component for achieving fairness in a cloud-hosted deployment. The RB transparently interposes the communication between the Market Participant (MP) and the Ordering Buffer (OB). It is responsible for releasing the market data to a specific Market Participant in a well-defined manner, and at the same time tagging each new trade with a Delivery Clock-derived timestamp, before sending it to the OB so that appropriate ordering can be achieved later on. 

Figure~\ref{fig:rb_archtiecture} depicts a high-level view of the RB's functionality. The RB transparently interposes the communication between the Market Participant (MP) and the Ordering Buffer (OB). As mentioned previously, the RB maintains the Delivery Clock (DC),  the logical clock tuple consisting of id of the latest data point transmitted to the MP and the time elapsed since the last transmission. Market data is grouped into logical batches %(of configurable size) 
by the CES and sent to each MP. The RB buffers the received market data (packets) that belong to the same batch, until the full batch is received. %\pg{can we say the batch is sent as a jumbo packet or something by the CES}
Upon the reception of the last market data (packet) of the batch, the RB checks whether the time elapsed since the previous market data batch delivery to the MP: if it is equal to or more than $\delta$, the batch is released to the MP at once, and the DC is updated on transmission completion of each packet. Otherwise, the batch is buffered at the RB for the appropriate duration to ensure that inter-batch gap is equal to or more than $\delta$.

 Each MP implements its own strategy on how to respond to each market data received, and generates trades. All the trades from an MP are intercepted by the correspondent RB: upon the reception of a trade, the RB needs to tag the trade accordingly with a DC-derived timestamp so that full ordering can be achieved at the Ordering Buffer. This timestamp is piggybacked on each trade and is calculated simply as the tuple consisting of the current DC id and the real time elapsed between trade reception and latest market delivery.
%\pg{Ilias I think this is repeated a lot of stuff, we can trim quite a bit till here. What do you think? Although I like your description much easier to follow}

\begin{figure}[t]
\centering
    \includegraphics[width=0.85\columnwidth]{images/RB_MP-crop.pdf}
    \caption{\small{\bf High-level architecture of the Release Buffer. The Delivery Clock advances upon new market data reception from the CES. Incoming trades from the MP are tagged with the Delivery Clock id and MP's response time before sent to the OB/CES.}}
    \label{fig:rb_archtiecture}
    \vspace{-5mm}
\end{figure}

Where should the RB placed in a cloud-hosted Financial Exchange deployment? There are two essential requirements for the RB component: a. the latency between MP and RB must be minimal so that it does not affect correctness, and b. for security reasons, the RB must be isolated from the MP, to avoid attacks that aim to tamper with response time measurements or market data delivery. Deploying the RB as a standalone VM is not a solution, as that would introduce non-negligible, variable latency between MP and RB. Even for VMs that are collocated into the same physical node, inter-VM communication is still achieved via network communication so that cloud providers can enforce the appropriate SDN policy. A switch-based implementation would also suffer from similar limitations: a. there is lack of fine-grained control for VM placement in cloud (so we cannot have any guarantees about switch-VM latencies), b. switch resources are scarce and shared by multitenant traffic  in the cloud, and avoiding interference would be a challenging problem to solve. 

%The cloud computing model enforces clean separation for 

Top-tier cloud providers deploy (custom) programmable NICs that leverage a variety of ASIC- or FPGA-based accelerators and powerful SoCs to enforce strict SDN policies required for I/O resource management, network virtualization, billing etc. These platforms serve as a natural boundary between the guest VMs that are controlled by the customers and the datacenter network which is shared resource managed by the cloud operator. We believe that the RB's functionality should be embedded in the cloud providers' smartNICs. RB support in the programmable NIC could be incrementally deployed in the existing infrastructure, and exposed to customers as a virtual NIC feature similar to accelerated networking \cite{firestone2018azure, efa, ena}. NIC performance isolation and background interference challenges are beyond the scope of this paper: MPs already invest large amounts of money for their co-located server hardware -- using high-end instances that provide single-tenancy guarantees per cloud node (cite dedicated instances) would eliminate interference stemming from on-host multi-tenancy. 

Since we do not have access to cloud providers' smartNICs, we used an off-the-shelf programmable (DPU) NIC~\cite{bf2} to demonstrate the feasibility of a NIC-based RB implementation. We implemented the RB functionality on top of DPDK~\cite{www-dpdk}, running it on the System-on-Chip ARM cores. A busy-polling receive engine intercepts all incoming market data traffic and releases them to the host while enforcing the pacing requirements. The RB functionality is completely transparent for the MP: market data  packets appear at the host's RX ring unmodified.

\subsection{Ordering Buffer}
\label{ss:ob}

The Ordering Buffer component's functionality closely resembles that of a `sequencer' which tags incoming trades in a First-Come-First-Served (FCFS) manner in existing on-premise deployments. In our system, it is responsible for ordering all received trades based on their Delivery Clock timestamp, before they are submitted to the Matching Engine (ME). Similarly to the `sequencer', the OB component is part of the trusted CES platform. In our prototype system, we have implemented the Ordering Buffer as a dedicated thread which buffers incoming trades in a priority queue (for ordering). When the OB has received all heartbeats up until a particular DC-derived timestamp it dequeues all the relevant trades to the Matching Engine over  shared-memory channels. 

%It is safe to dequeue buffered trades from the OB's priority queue when we are certain that all trades from all RBs have arrived up until a particular logical timestamp. How can we ensure such property? A naive way to achieve this is by waiting for trades  tagged with a higher market id to arrive from all RBs. That, in combination with in-order packet delivery guarantees from the network (single-path flow) allows to safely dequeue from the OB's priority queue. This would work well if there was no packet loss and all MPs were generating trades for each market data received, but this is not required. To mitigate this issue, we rely on periodic heartbeats from the RB to the CES. Several major financial exchanges already rely on heartbeats~\cite{nyse-client} for liveness when traffic is low. \pg{this repeats  a bit, cut everything except the last line?}

\noindent\textbf{Scaling:} With higher numbers of MPs, a single OB instance would become the bottleneck (in aggregate, number of heartbeats scale linearly with participants). In such cases, scaling the OB is straightforward by leveraging sharding: multiple OB components could be deployed either as different threads on multicore CPUs or even as standalone VMs. Each OB needs to be responsible for a subset of the RBs. The OB instances can dequeue a batch of pending trades when safe and send them to ME-colocated OB for the final merge before they are forwarded to the matching engine. A distributed OB deployment would also allow handling the higher rates of heartbeats in the case of numerous MPs, as each OB can effectively filter out all incoming heartbeats before reaching the CES. Each distributed OB instance needs to maintain the minimum of current Delivery Clocks from its associated RBs, while the master OB needs to maintain the minimum DC from all the distributed OBs to be able to dequeue trades safely to the matching engine. Since contemporary cloud datacenter networks do not support in-network multicast for market data transmission, such distributed approach would also allow scaling the CES' market data distribution engine to higher rates.


%\pg{Scaling put a title here, explain the problem, with larger number of participants the number of heartbeats incease, the heartbeat handler can be sharded. Each sharded handler maintains a minimum of delivery clock from its RBs. The master heartbeat handler takes a minmum over all such handlers to decide and deque. Another thing you might want to say is that unlike RB, OB need not be colocated. Although colocation is latency efficient.}


\begin{figure}[t]
\centering
    \includegraphics[width=0.8\columnwidth]{images/DBO_Cloud_design-crop.pdf}
    \caption{\small{\bf Cloud-hosted exchanges' architectural view.}}
    \label{fig:dbo_full_arch}
    \vspace{-5mm}
\end{figure}
