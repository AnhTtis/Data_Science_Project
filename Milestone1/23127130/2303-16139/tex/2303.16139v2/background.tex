\section{Background}

%\textit{Remark:} This section is based on our discussion with three major financial exchanges (all are among the top 10 exchanges in the world by trading volume). Other sources include recent works in the financial academic community and some industry papers and podcasts \pg{cite XXX)}.

%\radhika{Alternate framing: 

We begin with discussing the challenges in hosting financial exchanges on the cloud, that are derived from our discussions with three major financial exchanges (all are among the top 10 exchanges in the world by trading volume) and our review of papers from financial academic community~\cite{frequent_batch_auctions, libra,burdisch_working, fragile} as well as industry papers~\cite{iex_cost_report, signals_threads}. %\sadjad{I would avoid mentioning podcasts}




\noindent\textbf{Why is moving to the cloud so hard?} \textit{Short Answer: It is hard to achieve fairness in cloud.} A key customer/business for any major financial exchange is High Frequency Traders (HFTs). At a high level, high frequency traders aim to process incoming market data feed from the exchange server and place trade orders as fast as possible. These traders are engaged in what is known as \emph{speed races} where they are competing for the same trading opportunity, trying to get their trade orders ahead of competition. There is an arms race in high frequency traders to respond to market data the fastest~\cite{frequent_batch_auctions}. HFTs are becoming faster with time,
even minor differences in latency (microsecond level) for market data delivery and trade orders can give a trader significant advantage/disadvantage over the others ~\cite{burdisch_working, fragile, signals_threads}.% \pg{better wording?} 
Allowing such traders to trade fairly is critical for any exchange to attract HFTs that bring significant liquidity to the exchange. However, cloud environments exhibit variable network latency. This can be due to several reasons, such as congestion in the network, networks paths with unequal hops, etc. Ensuring such fairness in cloud environments is thus very challenging. Exchanges not only want fairness, to speed up price discovery; they also want low latency. The latency requirements depend on the exchange, from sub-100 microsecond to millisecond ~\cite{iex_cost_report}.

\if 0
\begin{figure}[t]
\centering
    \includegraphics[width=0.8\columnwidth]{hotnets-images/FSI architecture2.pdf}
    \vspace{-2.5mm}
    \caption{\small{\bf Basic components in exchanges today.} \pg{Redraw, remove RBs and OBs, remove other labels.}}% \pg{Eashan see Ranveer's comment}}% \pg{Eashan can you redraw this figure in powerpoint or something.}}}
    \label{fig:current_archtiecture}
    \vspace{-2.5mm}
\end{figure}
\fi

\noindent\textbf{How exchanges enable fair speed racing today?} \textit{Short Answer: Equal bi-directional latency.} Major exchanges operate their own datacenters. HFT traders that want to engage in speed trading colocate\footnote{Exchanges support colocation for a limited number of participants. The exact numbers are confidential, but the number is in 10s to less than couple of hundred depending on the exchange.} to the exchange datacenter.% for a hefty premium fee.% (NASDAQ charges \$600,000 per customer for colocation and market data feed~\cite{iex_cost_report}). 

The central exchange server (CES) produces a real time market data feed and distributes it to all the colocated participants (MPs). The exchange datacenter is optimized to ensure that participants get all the market data points at the same time. Further, exchanges ensure that all the trades placed by the participants experience the same latency to the exchange server. The exchange server simply processes the trades in a first-come-first-serve (FCFS) manner. Optimizing datacenters to provide such equal bi-directional latency is expensive~\cite{iex_cost_report}. 
As a result of high cost, exchanges charge a huge premium for such colocation (NASDAQ charges \$600,000 per customer for colocation and direct data feed~\cite{iex_cost_report}). 
These high premiums create a barrier for entry into the high frequency trading world. Major exchanges are also interested in opening up regional exchanges but the cost of creating a new regional datacenter is prohibitively high. 


\begin{figure}[t]
\centering
    \includegraphics[width=0.6\columnwidth]{figures/our_architecture.pdf}
     \vspace{-1mm}
    \caption{\small{\bf Basic components of \sys.}} %\pg{Redraw, remove other labels.}}% \pg{Eashan see Ranveer's comment}}% \pg{Eashan can you redraw this figure in powerpoint or something.}}}
    \label{fig:new_archtiecture}
    \vspace{-5mm}
\end{figure}

\subsection{Related Work}

The problem of moving financial exchanges to the cloud has received some attention. There are two bodies of work.

\noindent
%\textbf{Clock-synchronization based solutions are not enough:} CloudEx~\cite{cloudex} proposes using clock synchronization to achieve an equal latency abstraction. CloudEx adds two new components to the architecture \radhika{: the release buffer and the ordering buffer}. The broader architecture of our solution is same as CloudEx. Figure \pg{XXX} shows the basic components. In CloudEx, all the components have synchronized clocks. For each participant there is a colocated trusted component called the release buffer. A market data point produced at time $t$ is released by the release buffers simultaneously at a prespecified time $t+C_1$. A trade order generated by the participant at time $t$ is forwarded to the CES by the ordering buffering at time $t+C_2$.  
%
\textbf{Clock-synchronization based solutions are not sufficient:} CloudEx~\cite{cloudex} proposes using clock synchronization to achieve an equal latency abstraction. CloudEx adds two new components to the architecture (as shown in Figure~\ref{fig:new_archtiecture}): (i) For each participant there is a colocated trusted component called the \emph{release buffer}, which buffers market data points, enabling a delayed delivery to the market participant. (ii) Likewise, the \emph{ordering buffer} at the CES buffers the trade order generated by the participants, enabling delayed and re-ordered delivery of the trade orders to the CES. The broader architecture of our solution is same as CloudEx.

In CloudEx, all the components have synchronized clocks. A market data point produced at time $t$ is released by the release buffers simultaneously at a prespecified time $t+C_1$. A trade order generated by the participant at time $t$ is forwarded to the CES by the ordering buffering at time $t+C_2$. The problem with this solution is that even with perfect clock synchronization if network latency spikes beyond the pre-specified thresholds, then such a system incurs unfairness. Cloud networks experience latency spikes that are a couple of orders of magnitude higher than the average. Latency spikes,  although rare,  are still unpredictable, and setting high thresholds can help guard against sudden spikes and help us achieve better fairness.  With such high thresholds though, the system incurs high latency even when the underlying network latency is well behaved. Safeguarding against tail spikes, increases the overall end-to-end latency ($C_1+C_2$) not only at the tail but on average as well.
More importantly, the main issue remains unsolved: %is that %not the latency, no matter the threshold, 
still, there is no guarantee that equal bidirectional latency will always hold. In fact, there is a known impossibility result on this.
%\radhika{if running short on space, can replace above with: ``The main issue however is that there is still no guarantee that equal bidirectional latency will always hold, as we cannot guarantee perfect clock synchronization (there is a known impossibility result on this -- add this cite -- [Lundelius and Lynch 1984 -- an upper and lower bound for clock synchronization])'' You can then chop off the next paragraph.} \pg{Rewrote a little. We are not commenting on the problem bein clock synchronization but enforcing simultaneous delivery.}\radhika{the rewriting helps clarify this}

\noindent
\textit{Impossibility Result for equal bi-directional latency:} In network environments with finite but unbounded latency (common network model is distributed systems~\cite{lamportSeminalPaper}), even with perfectly synchronized clocks, it is impossible for two machines to communicate and co-ordinate to do a task at the same time (two generals problem \cite{two_generals}).
So two release buffers can never co-ordinate to deliver the same data to the respective market participants simultaneously,  no matter how they communicate with the CES or other release buffers. Note that it is still  to co-ordinate at the OB to ensure that latency on the reverse path stays the same (i.e., two trades generated at the same time are forwarded to the CES at the same time). %This can be done through coordination at the CES? i.e. the OB simply orders the trades based on when they are generated.
%\radhika{cut ``Note that'' onwards, unless you are using this later -- hard to follow the reasoning.}


\noindent\textit{Impossibility Result on Clock Synchronization:} Further, in network environments with unbounded network latency, it is also impossible to synchronize clocks to any extent and the error in clock synchronization is unbounded~\cite{imp_cs}. 

Our conversations reveal that exchanges wish to provide guaranteed fairness and as a result such solutions haven't seen much adoption.

\textbf{Modifying how the matching engine behaves:} Frequent Batch Auctions~\cite{frequent_batch_auctions} proposes releasing market data periodically in batches. The batch frequency is kept very low (1 batch per 100 ms) to allow all participants to respond before the next batch is released. All the trades corresponding to a batch are given the same priority for execution at the CES. This solution ensures fairness in the sense that no participant has an advantage over others because of network latency. However, the system latency is high (100 ms!). Further, this solution completely eliminates the speed races and a participant that responds to market data faster no longer has a competitive advantage. To achieve fairness in environments with unpredictable network latency, Libra~\cite{libra} assigns random priorities to the incoming trades. Libra achieves fairness for speed races stochastically (faster participants trades are ordered ahead more than 50\% of the times) when the variability in network latency is bounded.
Beyond the issues stated here, the main problem with both these solutions is that they require intrusive changes to the exchange matching algorithm. 

%\pg{difference from traditional networks}

\section{Problem Statement}

%\pg{Srikanth suggestion, include a table contrasting DBO and CloudEx here.}

\noindent
\textbf{Goals:} In this paper, we aim to solve the problem of enabling fair speed racing among high frequency traders in network environments where latency is finite but unbounded. We also do not wish to modify the matching engine to achieve this goal.
At a high level, our solution leverages the nature of the speed races to propose a new logical time domain -- delivery clocks -- that tracks time relative to when market data was delivered to the participants. By ordering trades using this delivery time domain we can achieve guaranteed fairness for such speed races.%\footnote{There is a caveat here, explained later.} 
Our goal here is not to just propose a solution, but also present theoretical insights that help researchers in understanding this space and enable future work.

%\pg{Global exchange and scalability?}

\noindent
\textbf{Non-Goals:} Achieving bounded latency in cloud networks remains an open problem as of now. In this paper, we do not attempt to optimize the underlying network latency or the transport mechanism for multicasting market data or communicating trade orders. 
We also do not discuss solutions for reliability of the various components. Exchanges today incur unfairness in the event of failures \cite{signals_threads}. In our system, it should be possible to detect failure of various components and migrate the impacted components. During failures, fairness can get affected (\S\ref{ss:understanding_latency}).
%$ (\S\ref{ss:understanding_losses}). %As with existing exchange infrastructure, the main challenge is in ensuring reliability of the CES server and that critical state (state of the order book) is not lost there. \radhika{can cut last line -- does not seem that relevant and calling it out as main challenge makes it sound like you are going to solve it}

%We would like to note that cloud providers today do offer a very high amount of reliability (4 9s). \pg{cite XXX}. \pg{This paragraph is a bit weird}

%In our system, in case there is a release buffer or ordering buffer failure it will likely impact fairness. Existing solution for reliability in exchange datacenters should be applicable to handle failure of the participants and the CES and ensure correctness (fairness will get compromised). \pg{is this paragraph ok?}

We will now introduce some notation, formally define a speed race and fairness for such races. 

\noindent
\textbf{Notation:}
We refer to the $x^{th}$ market data point as $x$. $(i,a)$ refers to the $a^{th}$ trade from MP$_i$. Table\ref{tab:notation} lists the notations used in this paper.


\begin{table}[h!]
\small
    \centering
    \begin{tabular}{p{0.15\columnwidth} | p{0.75\columnwidth}}
    %\hline
        \textbf{Notation} & \textbf{Definition} \\
        \hline
        $G(x)$ & Real Time at which $x$ was generated at the CES.\\
        $D(i,x)$ & Real Time at which $x$ was delivered (by $RB_i$ in case of our system) to MP$_i$. \\%Governed by network latency and RB$_i$\\
        $TP(i,a)$ & Market data point used to generate $(i,a)$.\\
        $RT(i,a)$ & Response time of $(i,a)$.  \\
        $S(i,a)$ & Real Time at which $(i,a)$ was submitted by MP$_i$.\\% to RB$_i$.\\
        $F(i,a)$ & Real Time at which $(i,a)$ is forwarded (by OB in our system) to the CES's matching engine (ME). \\%\pg{include or drop?}\\
        $O(i,a)$ & The order in which trades are forwarded (by OB in our system) to the CES. If $O(i,a) < O(j,b)$ then $F(i,a)$ < $F(j,b)$.

    %\hline
    \end{tabular}
    %\vspace{-2mm}
    \caption{\small{Notation.}}
    \label{tab:notation}
    \vspace{-5.5mm}
\end{table}


\begin{figure}[t]
\centering
    \includegraphics[width=0.8\columnwidth]{figures/speed_race.pdf}
    \caption{\small{\bf Events in a speed race.}}% \pg{Eashan see Ranveer's comment}}% \pg{Eashan can you redraw this figure in powerpoint or something.}}}
    \label{fig:speed_race}
    \vspace{-2.5mm}
\end{figure}

 \noindent
 \textbf{Speed Race:} Informally, a speed race \cite{frequent_batch_auctions, libra, burdisch_working} consists of trades from multiple participants competing for the same trading opportunity. A particular market data point serves as the trigger/stimulus for trades competing in the speed race. Participants aim to identify the trading opportunity and win the speed race by responding as fast as possible after receiving the trigger market data point. 
 %\radhika{the next three lines can be moved to background where you introduce speed races / de-duplicated with the text there}
 The trades belonging to a speed race are the most latency sensitive \cite{frequent_batch_auctions, libra, burdisch_working}. Differences in latency across participants in delivering the trigger point or on the reverse path to the CES can create significant disadvantages for certain participants~\cite{fragile, burdisch_working}. %\pg{cite the Mackenzie paper and the burdisch working paper}. 
 These speed trades  constitute a substantial fraction of the overall trades in major exchanges (atleast 20\% in LSE \cite{burdisch_working}). In this paper, we will try to achieve fair ordering for trades engaged in such speed races.

\noindent
\textit{Compute model for speed trades:} The response time for trade $(i,a)$, $RT(i,a)$, whose trigger point is $x$ ($TP(i,a) = x$), is defined as the time it took to generate the trade after receiving the trigger point $x$. Formally, the time trade $(i,a)$ is submitted/generated by an MP is given by,

\begin{align}
    S(i,a) = D(i, x = TP(i,a)) + RT(i,a) 
    \label{eq:cm}
\end{align}

%\radhika{another version:} 
%We formally define it as: 
%\begin{align}
%     RT(i,a) = S(i,a) - D(i, x = TP(i,a))
%    \label{eq:cm}
%\end{align}
where $S(i,a)$ is the time trade $(i,a)$ is submitted/generated by an MP, and $D(i, x = TP(i,a))$ is the time at which $RB_i$ delivers $x$ to $MP_i$ (see Table 1).  

%This is the compute model we are going to use throughout this paper \radhika{cut this line?}.
Response time captures the speed of the participant. Note that such a trade might be generated using market data points other than the trigger point. However, the trade submission time is completely governed by the delivery time of the trigger point and the response time of the participant for that trade.% \radhika{maybe cut this line -- not sure if this is relevant for the upcoming text}.

 \noindent
 \textbf{Fair ordering of Trades in a Speed Race:} Outcome of a speed race is simply governed by the ordering of the competing trades in the race. Our goal is to achieve the same ordering for these trades had the network provided equal bi-direction latency. We refer to such an ordering of trades as \textit{Response Time Fairness}. 
 
 
 In an equal bi-directional latency network ($C_1$ latency from CES to MP, $C_2$ latency from MP to CES), trade $(i,a)$ will be received by the CES at time,
 \begin{align}
     F(i,a) = G(x=TP(i,a)) + C_1 + RT(i,a) + C_2 
 \end{align}

By definition, Trade $(i,a)$ is ordered ahead of $(j,b)$, i.e., $O(i,a) < O(j,b)$), if $F(i,a) < F(j,b)$. In such a network, two trades $(i,a)$ and $(j,b)$ belonging to the same race (i.e. the same trigger point $x$) will be ordered as follows, 
\begin{align}
    \text{If } G(x) + C_1 + RT(i,a) + C_2 < G(x) + C_1 + RT(j,b) + C_2,\nonumber\\ \text{ then, } O(i,a) < O(j,b)
\end{align}

Using the above equation, we define response time fairness as follows,

\begin{definition}
An ordering system achieves response time fairness if it satisfies the following condition for all competing speed trades $(i,a)$ and $(j,b)$
\begin{align*}
    C1: &\text{ if } TP(i,a)= TP(j,b) = x\\ 
    &\land RT(i,a) < RT(j,b), \\
    &\text{ then, }O(i,a) < O(j,b).
\end{align*}
\label{def:rtf}
\vspace{-5mm}
\end{definition}

The above condition is simply stating that a faster participant's trades should be ordered ahead of slower participant. The above condition is from the perspective of the participants. Response time is not directly visible to the cloud provider or the exchanges. We will rewrite the above conditions using quantities visible to them.
%This form is what we will focus on in this paper \radhika{can cut this line}. Using Equation~\ref{eq:cm}, 
The above condition can be rewritten as,

\vspace{-1mm}
\begin{align*}
    C1': \text{ if } &TP(i,a)= TP(j,b) = x \\
     &\land S(i,a) - D(i,x) < S(j,b) - D(j,x), \\
    \text{ then, } &O(i,a) < O(j,b).
\end{align*}

This condition states that the exchange can achieve response time fairness by measuring time of trades relative to when a market participant received the market data to order trades. 

%There is another way of writing the above condition in terms of one way latency from CES to the participants that might be more intuitive to understand for the readers in the networking community. $D(i,x) - G(x)$  represents the one way latency from CES to participant $i$ for data point $x$.  Adding $G(x)$ to both sides in the equation above we get the following condition,

%\radhika{v2: cut the above para, and simply say: 

Adding $G(x)$, i.e. the generation time of $x$, to both sides of the equation results in the following condition:%}  

\begin{align*}
    C1'': \text{ if } &TP(i,a)= TP(j,b) = x \\
     &\land S(i,a) - (D(i,x)-G(x)) < S(j,b) - (D(j,x)-G(x)), \\
    \text{ then, } &O(i,a) < O(j,b).
\end{align*}

%\radhika{v2: 
Here $D(i,x) - G(x)$  represents the one way latency from CES to participant $i$ for data point $x$.  
So to achieve response time fairness all the exchange needs to do is correct for the differences in latency from the exchange to the participant. 


To deal with variability in network latency, CloudEx tries to equalize latency by holding information at the release buffer and releasing it simultaneously all participants using synchronized clocks. In other words, it strives to ensure that $(D(i,x)-G(x))$ is equal to $(D(j,x)-G(x))$, so that trades can simply be ordered by the time when they were submitted by the participants (i.e. $S(i, a)$). However, as discussed earlier, it is not possible to equalize latency always when the underlying network latency is unbounded. 

%\radhika{can do a slight re-org here. Have a subsection heading ``Our approach'' here. Alternatively, leave the next paragraph in this section, and start a new section on your system design from before assumptions, where the first subsection is assumptions, second is challenges, and then the rest of the design follows.} 


In this work, we take a different approach. Instead of trying to synchronize clocks or equalize latency (either of which can never be done precisely \cite{two_generals, imp_cs}), we show that it is possible to post facto correct for latency difference and achieve response time fairness.




\noindent
\textbf{Causality of trades from a participant:} We add an additional requirement for ordering of trades. This condition simply states that trades from a participant should respect causality, i.e, if trade $(i,a)$ was generated before trade $(i,b)$ then it should be ordered ahead. Formally, 
\begin{align}
\text{If } S(i,a) < S(i,b), \text{ then }, O(i,a) < O(i,b).
\label{eq:causality}
\end{align}


\noindent
\textbf{Fairness beyond Response Time Fairness:} While speed races are the most latency critical, in theory there can be latency-critical trades that don't fall under the speed race model (e.g., trades whose submission time depend on delivery time of multiple data points or some other external data). Guaranteeing perfect fairness for such trades does require simultaneous delivery of both market data and external data. While this is impossible, we will discuss how DBO can be enhanced to provide better fairness for such trades (\S\ref{ss:beyond_fairness}). 

%\pg{QUESTION: should we talk about ordering of two trades from the same participant, i.e., if (S(i,a) < S(i,b) then O(i,a) < O(j,b)}



 \noindent
 \textbf{Assumptions:} We will list out some of the assumptions we make in our solution.

\noindent
 \textit{Trust:} Release and ordering buffers are trusted components that are controlled by the cloud provider and that cannot be tampered with. 

\noindent
\textit{Proximity:} Release buffers are colocated with the participants. The latency between them is negligible. In our system, we implement the release buffer at participant's NIC. For scenarios where release buffer cannot be colocated we analyze the impact of latency between the release buffer and the participant. %\pg{Should we do this or just say nothing}

\noindent
\textit{Clock-drift rate:} We don't make any assumptions on clocks being synchronized across components in the network. Similar to literature in the traditional distributed systems~\cite{imp_cs}, we assume that clock-drift rate is negligible and release buffers can measure time-intervals accurately. Clock drifts rates are small in practice ($< 0.02\%$ under a wide range of scenarios~\cite{sundial}). %We also analyze the impact of clock drift rate.

\noindent
\textit{In-order delivery:} We assume that packets can be lost in the network. Packets that are not dropped are delivered in order. Just like exchanges today, we assume that all loses are handled out of band where the receiver requests retransmission using an alternative slower path~\cite{signals_threads}. Similar to modus operandi, our system incurs unfairness in such cases. 

\noindent
\textit{Participants are located in the cloud:} We assume that all the participants are located in the cloud. In case a certain participant doesn't want to move to the cloud, the exchange can run a proxy machine in the cloud on the behalf of such a participant. External participants can get market data feed and place trades through this proxy. Because of additional latency from proxy to the participant machines, trades from such external participants will be at a disadvantage. Fairness for other participants in the cloud remains unaffected.

\noindent
\textit{Remark:} CloudEx also makes the same assumptions on trust, proximity, and participants being in the cloud. The key difference is that CloudEx further assumes clock synchronization and requires bounded latency for guaranteeing fairness.

\subsection{Challenges}% and how we overcome them}%in achieving Response Time Fairness}

%\radhika{you can cut the first challenge (addressing this point more briefly as in my comments above), and directly start with the second one.}

There are three key challenges.

\noindent
\textbf{Challenge 1: Clock-synchronization:} Ideally, we want a solution that doesn't require any clock synchronization.

%\noindent
%\textbf{Our Solution:} Our system uses delivery clocks to order trades. Maintaining such delivery clocks only requires measuring time intervals locally. With small clock drift rates, time intervals can be measured accurately.

%\pg{Radhika's comment: even in synchronized systems where network latency is bounded (but the min and max network latency may differ), you can synchronize two clocks with minimum bound of (max - min)/2. the cite is in the comment above} 


\noindent
\textbf{Challenge 2: Trigger point is unknown:} We assume that trigger point of a speed trade is not known. 
%\radhika{a footnote or a line on why you make this assumption. you can also consider adding a point under your list of assumptions on what information is available at the RB and the OB and what is not.}.
In such case it is hard to measure the response time and consequently decide how trades should be ordered. Unfortunately, when response times are unbounded it is impossible to achieve Response Time Fairness. 

\begin{theorem}
If trigger points for trades are unknown, then no ordering system can achieve Response Time Fairness.
\label{thm:1}
\end{theorem}

\begin{proof}
When trigger points are unknown, the ordering enforced by the system should achieve response time fairness for trades regardless what might have been their trigger point. This means that the ordering enforced by the system should respect condition $C1'$ regardless of what the trigger point $x$ is. The necessary condition for this to hold true is given below. 


\begin{lemma}
When trigger points are unknown, the \textit{necessary} conditions on the delivery processes for achieving response time fairness with any ordering system is given by,
\begin{align*}
    D(i,y) - D(i,x) &= D(j,y) - D(j,x), & \forall i,j,x,y.
\end{align*}
\label{lemma:inter_delivery_imp}
\vspace{-6mm}
\end{lemma}


Please see Appendix~\ref{app:lem1} for proof. The lemma states that for response time fairness the inter-delivery times should be the same across all  participants. 
%\pg{with same inter-delivery times, for competing trades it does not matter which trigger point we consider to c}
%This way the same ordering regardless of the trigger point provides response time fairness. 
%\radhika{one concern I have here is that it's hard to define the ordering in C1' when TPs are unknown. can you give the condition you would use in such a case? maybe all you need to do is say that you measure response time based on the most recently delivered $x$, and under this inter-delivery condition, response time fairness is still guaranteed even if the TPs are different from $x$}
However, achieving the same inter-delivery time when network latency is unbounded is also impossible. If two processes can co-ordinate to achieve the same inter-delivery time then they can co-ordinate to do a task at the same time, a contradiction of the two generals impossibility result. 

 \end{proof}

%\radhika{yet to read design, but I feel that this can come later. You can just list the  challenges in this section. The LRTF bit seems more like a solution that can be brought up and expanded on in the following section/subsection.}


%\noindent
%\textbf{Our Solution:}  
We cannot achieve Response Time Fairness in settings where trigger points are unknown. We define a new slightly weaker version called \textbf{Limited Horizon Response Time Fairness} (LRTF) that is still useful. Formally, LRTF is defined as,

 \begin{definition}
An ordering system achieves limited-horizon response time fairness if it satisfies the following condition for all competing speed trades $(i,a)$ and $(j,b)$
\vspace{-1mm}
\begin{align*}
    C2: &\text{ if } TP(i,a)= TP(j,b) = x\\ 
    &\land RT(i,a) < RT(j,b), \\
    & \land RT(i,a) < \delta,\\
    &\text{ then, }O(i,a) < O(j,b).
\end{align*}
\label{def:lrtf}
\vspace{-5mm}
\end{definition}

The above condition is similar to condition (C1) with an additional constraint that the system guarantees response time fairness for only fast trades that are generated within a bounded amount of time. 
Notice that the constraint on response time being less than $\delta$ is only on  participant $i$.  Participant $i$'s trades will be ordered fairly regardless of whether the response time of other participant's competing trades is within $\delta$ or not.
\emph{In this paper, we will present a system, DBO, that for any given $\delta$  achieves LRTF in a guaranteed manner.}

%\pg{should we include necessary and sufficient conditions for achieving LRTF?}

\textit{Why is LRTF useful?} LRTF is based on the fact that typically participants response very quickly to market data. From our conversations, the faster participants in major exchanges responds within a few microseconds. \cite{burdisch_working} further shows that majority of the speed races last 5-10 microseconds. An exchange provider can choose to offer its participants guaranteed response time fairness for fast trades. The choice of $\delta$ does present a trade-off, increasing $\delta$ increases system latency.



\noindent
\textbf{Challenge 3: Enforcing the ordering} Suppose we could mark the trades at generation with the sequence in which they should be forwarded to the CES. Because trades can take unbounded amount of time on the reverse path, even in this scenario its hard to enforce such an ordering at the ordering buffer. In particular, before forwarding trade $(i,a)$ we need to be sure that there is no other trade $(j,b)$ in flight that should be ordered ahead.


