\section{Background}
\label{s:background}

\subsection{High-level Architecture}
\label{ss:basic_architecture}

%Our system is composed by three discrete entities: the Central Exchange Server (CES), the Release Buffer Components (RBs), and the Market Participants (MPs). The Central Exchange Server is essential component, responsible for serving trade orders.
\Fig{basic_architecture} shows the main components of our system. This architecture is roughly in line with earlier works~\cite{cloudex, libra}. 
%
%
For now, we will assume that each MP is a single machine (or a virtual machine) in the cloud. We will relax this constraint in \S\ref{ss:multi_machine}. 

%\chaitanya{There are broadly two types of orders:}

%\chaitanya{\noindent 1. Market Order: Here, the amount to be sold or bought is specified in this order type, but not the price.
%The exchange is in charge of filling the order at the lowest price possible. While market orders are frequently used to swiftly unload a "position," traders prefer alternative forms that offer them more control over the execution price.}

%\chaitanya{\noindent 2. Limit Order: A limit order defines a maximum or minimum price for the purchase or sale of a number of shares. Limit orders, unlike market orders, may not be filled if the specified price is not met. Investors can set time restrictions for order execution in some variations, beyond which the order is canceled.}

\noindent
\textit{Outgoing market data:} The CES generates a stream of real-time market data. There are multiple market participants, all located within the cloud. For each MP there is an associated Release Buffer (RB) that is controlled by the cloud-provider. Each RB receives market data directly from the CES; then it decides when the market data should be released to the corresponding MP. 

\noindent
\textit{Incoming trade orders:} Each MP generates trades based on the market data stream %(received through the RB)
and \emph{submits it} to the corresponding RB. The RB tags the incoming trade with any additional information necessary for fair ordering and forwards it to the CES. At the CES, the ordering buffer (OB) orders incoming trades based on the tagged information and forwards it to the matching engine (ME).\footnote{
To account for latency differences from MPs to the CES, the OB might need to buffer trades before forwarding them to the CES (see \S\ref{s:exp}).} 
The ME, matches buy orders against selling orders, and executes matched trade orders.% and updates the book.% \footnote{All updates to the book are published as market data.} 
%\pg{Chaitanya is this correct, are we missing something here?}

\begin{figure}[t]
\centering
    \includegraphics[width=0.8\columnwidth]{hotnets-images/FSI architecture2.pdf}
    \vspace{-2.5mm}
    \caption{\small{\bf Basic components.} RBs and OB are controlled by the cloud provider.}% \pg{Eashan see Ranveer's comment}}% \pg{Eashan can you redraw this figure in powerpoint or something.}}}
    \label{fig:basic_architecture}
    \vspace{-2.5mm}
\end{figure}

\noindent
\textbf{Notation:} 
We refer to the $x^{th}$ market data point as $x$. $(i,k)$ refers to the $k^{th}$ trade from MP$_i$. Table\ref{tab:notation} lists the notations used in this paper.


\begin{table}[h!]
\small
    \centering
    \begin{tabular}{p{0.1\columnwidth} | p{0.8\columnwidth}}
    %\hline
        \textbf{Notation} & \textbf{Definition} \\
        \hline
        $G(x)$ & Real Time at which $x$ was generated at the CES.\\
        $R_i(x)$ & Real Time at which $x$ was received at RB$_i$.\\
        $D_i(x)$ & Real Time at which $x$ was delivered by RB$_i$ to MP$_i$.\\
        $A_i(k)$ & Real Time at which $(i,k)$ was submitted by MP$_i$ to RB$_i$.\\
        $f_i(k)$ & Market data point used to generate $(i,k)$. This function is not known to anyone besides MP$_i$.\\
        $rt_i(k)$ & Response time of $(i,k)$. $rt_i(k) = A_i(k) - D_i(f_i(k))$. \\
        $O(i,k)$ & The order in which OB forwards trades to the ME. If $O(i,k) < O(j,l)$ then $(i,k)$ is ordered before $(j,l)$.
    %\hline
    \end{tabular}
    %\vspace{-2mm}
    \caption{\small{Notation.}}
    \label{tab:notation}
    \vspace{-5.5mm}
\end{table}

\if 0
\noindent
$G(x)$: Real Time at which $x$ was generated at the CES.

\noindent
$R_i(x)$: Real Time at which $x$ was received at RB$_i$.

\noindent
$D_i(x)$: Real Time at which $x$ was delivered by RB$_i$ to MP$_i$.

%\noindent
%$(i,k)$: Trade $k$ from MP$_i$.

\noindent
$A_i(k)$: Real Time at which $(i,k)$ was submitted by MP$_i$ to RB$_i$.

\noindent
$f_i(k)$: Market data point used to generate $(i,k)$. This function is not known to anyone besides MP$_i$.

\noindent
$rt_i(k)$: Response time of $(i,k)$. $rt_i(k) = A_i(k) - D_i(f_i(k))$. 

\noindent
$O(i,k)$: The order in which OB forwards trades to the ME. If $O(i,k) < O(j,l)$ then $(i,k)$ is ordered before $(j,l)$.
\fi

%\smallskip
\noindent
\textbf{Assumptions:} 

\noindent
\textit{Proximity of RB to MP:} Each RB is located sufficiently close to its MP (e.g., colocated in the same VM as the MP, \S\ref{s:disc}) and the latency between a RB and MP pair does not impact fairness.

\noindent
\textit{Communication model:} %Messages between RBs and MPs are never lost. 
%Message between a RB and the CES can get lost but it will eventually be transmitted successfully. 
Messages between a RB and the CES are delivered in-order using a reliable transport (such as TCP).
Connection disruptions can be handled using timeouts (\S\ref{s:exp}).%Latency between RBs and the CES is not bounded.
%We also assume that besides the market data stream and corresponding trades there is no other communication that can impact fairness.
We focus on trades generated directly in response to the real-time market data.
\footnote{MPs can also have access to external streams of data such as financial news streams. Compared to real-time market data, such external streams are not latency-critical and important for fairness.} %While providing fair-access to such streams is indeed possible with our framework, in the interest of space we do not consider it in this paper.}

\noindent
\textit{No failures:} We do not consider scenarios where the MPs or the CES fail. %and need to be restarted with the relevant state.
Existing solutions for replicating state machines can potentially be used to handle such failures~\cite{paxos_made_simple}. In the event of a failure, our approach will likely incur unfairness.

\subsection{Related Work}
\label{ss:related}

%CloudEx\cite{cloudex} is the closest work in this space. 
CloudEx~\cite{cloudex} leverages clock synchronization for fairness.
%to ensure that market data points are released at the same time. 
Market data $x$ is delivered simultaneously to all MPs at a pre-specified threshold ($Th$) from generation time (i.e., $D_i(x) = \max (R_i(x), G(x) + Th$). Incoming trades are simply processed in the order of submission time ($O(i,k) =A_i(k)$). An MP experiences unfairness if the latency between the CES and the MP goes beyond $Th$ and market data is delivered to it later than intended. 
%
%\attn{Increasing $Th$ can potentially help mask small latency spikes and reduce unfairness at the cost of additional latency.}
%
%\footnote{\pg{Data from production datacenters shows that network latency can increase by upto three order of magnitude in certain scenarios~\cite{google_timely}.  necessitating setting a highly of }}
%
Our approach does not require synchronized clocks. This is because, our approach only requires measuring time intervals locally at each RB. For such purposes, each RB can use its own local clock as long as the clock drift rate is small ($< 0.02\%$ in practice under a wide range of scenarios~\cite{sundial}).
%
Further, our approach can be combined with CloudEx for simultaneous delivery of market data (to the extent possible) to also provide fairness for 'one-sided' trades (see \S\ref{ss:approximate_fairness}) while also ensuring better fairness for reactive trades when latency spikes happen (\S\ref{s:exp}) or when clocks go out of sync (e.g., due to link failures ~\cite{sundial}).

\noindent
\textit{Advances in conventional networking:} There is a huge body of work~\cite{dctcp, hpcc, dcqcn, swift, hpcc, conga, bfc} (spanning congestion control, routing, kernel bypass, etc.) on reducing message transfer latencies in datacenter networks. However, none of these solutions (and none of the production datacenters) provide bounded end-to-end latency that could potentially solve the fairness problem.
%. Synchronous communication can potentially solve the fairness problem. 
In this paper, we do not attempt to change the underlying network fabric in any way. 



%\noindent 
%\chaitanya{\textit{Studies in Financial Literature:} The issue of a disconnect between economic theory and the inherent difficulties that arise when supposedly "fair" market arrangements (such as FCFS matching) are put into practice, has been well documented. The sophisticated and distributed architecture of current exchanges makes it difficult for operators to keep track of all potential sources of delays and monitor how they may effect each participant. }

%\chaitanya{Alternative market designs/order-matching strategies have been presented as solutions to account for unequal delays. For example, \cite{frequent_batch_auctions} propose a policy that interprets time as a discrete variable (rather than a continuous one) and replaces continuous auctions with "batches." This permits numerous orders to arrive at the same (separate) time, reducing the relevance of (fair or unfair) sub-millisecond submission time disparities. There is a burgeoning field developing to use mechanism design as a tool to control information transmission, as well as, to handicap participants who have an unfair advantage.}

%\noindent
%\textit{\pg{Chaitanya: related work from the financial world.}}% I am rethinking if this is needed.}}