\section{Introduction}
\label{s:introduction}

Cloud providers are continuously improving their datacenters to provide better computing, networking and storage resources to end customers. These innovations have helped many industries to forego the cumbersome task of building and maintaining their own on-premise data centers and move to the cloud. Despite all the investment and innovation from cloud providers, however, cloud environments today are still not well suited for many industries.

%Most of the major financial exchanges (such as NASDAQ, CME, NYSE) run their Central Exchange Server (CES) in  on-premise data centers. At a high level, the CES generates market data and distributes it to various market participants (MPs) in real time. Fairness with regards to the market data stream, would constitute simultaneous data delivery to all market participants. In modern financial exchanges such fairness is not a commodity but rather comes at a premium: MPs that are interested in earliest possible delivery of the market data, are paying high fees to collocate their servers in the financial exchanges' data centers as close as possible to the exchange's Matching Engine (ME). Such MPs (commonly known as high-frequency traders), rapidly react\footnote{High frequency traders are very aggressive in reducing latency: they often use programmable smartNICs to shave off just ns of latency on their end to gain competitive advantage.} to new market data generating a high volume of transactions: their profit is highly dependent on winning the `race for speed', aiming to submit their trade transactions before other competing MPs. For the rest of the MPs there is no guarantee with regards to market data delivery (data are streamed over variable-latency private or public WAN links). \attn{Fairness with regards to trade orders processing, would constitute processing them sorted based on their response time since the delivery of the actual market data. } A property that would be sufficient to achieve both of the aforementioned types of fairness is ensuring provable equal bi-directional latency between the CES and the colocated MPs. Such property immediately guarantees simultaneous delivery of market data to the colocated MPs, while a simple First Come, First Served (FCFS) for orders processing would be sufficient to ensure fairness with respect to response time. The financial exchanges often go to great lengths in achieving equal bi-directional latency between the CES and the colocated MPs: It is not uncommon, for example, for exchanges such as NASDAQ to use equal-length cables for all colocated MPs to achieve provably equal bidirectional latency.

\iffalse
Most of the major financial exchanges (such as NASDAQ, CME, NYSE) run their Central Exchange Server (CES) in  on-premise data centers. At a high level, the CES generates market data and distributes it to various market participants (MPs) in real time. Fairness with regards to the market data stream, would constitute simultaneous data delivery to all market participants. In modern financial exchanges such fairness is not a commodity but rather comes at a premium: MPs that are interested in earliest possible delivery of the market data, are paying high fees to collocate their servers in the financial exchanges' data centers as close as possible to the exchange's Matching Engine (ME). Such MPs (commonly known as high-frequency traders), rapidly react\footnote{High frequency traders are very aggressive in reducing latency: they often use programmable smartNICs to shave off just ns of latency on their end to gain competitive advantage.} to new market data generating a high volume of transactions: their profit is highly dependent on winning the `race for speed', aiming to submit their trade transactions before other competing MPs. For the rest of the MPs there is no guarantee with regards to market data delivery (data are streamed over variable-latency private or public WAN links). \attn{Fairness with regards to trade orders processing, would constitute processing them sorted based on the time they were generated.} A property that would be sufficient to achieve both of the aforementioned types of fairness is ensuring provable equal bi-directional latency between the CES and the colocated MPs. Such property immediately guarantees simultaneous delivery of market data to the colocated MPs, while a simple First Come, First Served (FCFS) for orders processing would be sufficient to ensure fairness with respect to response time. The financial exchanges often go to great lengths in achieving equal bi-directional latency between the CES and the colocated MPs: It is not uncommon, for example, for exchanges such as NASDAQ to use equal-length cables for all colocated MPs to achieve provably equal bidirectional latency.
\fi

%Most of the 
Major financial exchanges such as NASDAQ, CME, and NYSE run their Central Exchange Server (CES) in on-premise data centers. At a high level, the CES generates market data and distributes it to various market participants (MPs) in real time. Certain MPs (commonly known as high-frequency traders), rapidly \emph{react} to new market data issuing a high volume of transactions: their profit is highly dependent on winning the `race for speed', aiming to submit their trade orders before other competitors.\footnote{High frequency traders are very aggressive in reducing latency: they often use programmable smartNICs to shave off just $\mu\,s$ of latency on their end to gain competitive advantage.}
To accommodate fair competition based on speed of trading, modern financial exchanges offer simultaneous delivery of market data to the interested MPs, as well as ordered processing of the trade transactions based on their submission time \attn{(measured at the MP)}. Such fairness is only  provided to a fraction of the MPs, and comes at a premium cost: financial exchanges offer colocation services for MPs' servers at the same datacenter as the exchange's CES, where they are able to provably guarantee equal bidirectional latency from the CES to all colocated MPs. Exchanges go to a great extent to ensure fairness for their colocated MP customers; it is not uncommon, for example, to use layer-1 fan-out switches for market data stream replication and equal-length cables to all colocated MPs.
%for provably equal bi-directional latency. 
For the rest of the MPs -- who either do not profit from such trading strategies or cannot afford the colocation services -- fairness of such kind is not available. Such MPs typically receive the market data stream and submit orders over variable-latency private or shared WAN links, or through intermediate brokers.

% \eg{Most of the major financial exchanges such as NASDAQ, CME, and NYSE run their Central Exchange Server (CES) in on-premise data centers. At a high level, the CES generates market data and distributes it to various market participants (MPs) in real time. Certain MPs (commonly known as high-frequency traders), rapidly \emph{react} to new market data issuing a high volume of transactions: their profit is highly dependent on winning the `race for speed', aiming to submit their trade orders before other competitors\footnote{High frequency traders are very aggressive in reducing latency: they often use programmable smartNICs to shave off just $\mu\,s$ of latency on their end to gain competitive advantage.}.
% To accommodate fair competition based on speed of trading, modern financial exchanges offer simultaneous delivery of market data to the interested MPs to a fraction of the MPs at a premium cost: financial exchanges offer colocation services for MPs' servers at the same datacenter as the exchange's CES, where they are able to provably guarantee equal bidirectional latency from the CES to all colocated MPs. Exchanges go to a great extent to ensure fairness for their colocated MP customers; it is not uncommon, for example, to use layer-1 fan-out switches for market data stream replication and equal-length cables to all colocated MPs. For the rest of the MPs -- who either do not follow such trading strategies or cannot afford the colocation services -- fairness of such kind is not available. Such MPs typically receive the market data stream and submit orders over variable-latency private or shared WAN links, or through intermediate brokers.}

Moving the CES to the cloud presents a huge business opportunity for major cloud providers such as Amazon, Google, and Microsoft~\cite{nasdaq_cme_an, nasdaq_aws}. Financial exchanges also have a strong incentive to move their business to the cloud: they could rapidly increase market access to more participants, and also benefit from modern cloud's elastic resource scaling. To achieve smooth migration to the cloud, however, all of modern exchanges' services need to be accommodated, including fairness on speed trading which presents unique challenges. In particular, ensuring fairness by providing deterministic equal latency to the MPs similar to the on-premise datacenters, would be quite challenging in the cloud. Cloud datacenters have originally been designed for a heterogeneous, multi-tenant environment, aiming to accommodate diverse workloads. Even if the MPs are located within the same cloud region as the CES, it is hard to guarantee that the latency between CES and various MPs will be the same. Copper and fiber optics cables are not necessarily of equal length, network traffic is not evenly balanced among the different paths, multiple vendors' network elements have different performance characteristics, network oversubscription is still common in datacenters, and network quality of service mechanisms for concurrent workloads are only best effort.


Over the recent years, this problem has received some attention from both the financial and computer science research communities.
%to counter the asynchronous communication constraint. 
CloudEx~\cite{cloudex} proposes using high-precision clock synchronization to ensure that the market data is released %(at vantage points located very close to the MPs)
to MPs simultaneously along with ordering trades based on the submission time. In the event of latency spikes beyond a certain threshold, however, CloudEx incurs unfairness. Unfortunately, production datacenters do not guarantee bounded latency. Latency spikes (up to a few orders of magnitude increase than average) are quite frequent due to a multitude reasons such as congestion~\cite{google_timely}, and link failures~\cite{conga}. \pg{Maybe make the point that no algorithm can ensure simultaneous delivery of data with unbounded latency (two generals problem).}
Libra~\cite{libra} orders incoming trade requests based on their contents %(e.g., the selling price offered by the MP for an instrument). 
while Budish et al.~\cite{frequent_batch_auctions} propose aggregating real-time market data and delivering it in batches to the MPs along with aggregating incoming trades corresponding to a batch. These approaches, however, impose significant restrictions as they require changes to how trades are processed at the CES~\cite{cloudex}.% and can introduce inefficiencies (\S\ref{s:exp}).}


In this paper, we set out to tackle the problem of providing fairness for financial exchange systems that operate in modern cloud datacenters. We observe that provably equal latency between CES and MPs is a useful property that helps ensuring equal opportunity for market participants, but it is both hard to achieve and not strictly essential for the purpose. Instead, for our solution we adopt a radically different approach: we choose to relax any assumptions for tight clock synchronization among cloud nodes or predictable bounded latency in datacenter networks. Further, our approach is general since it does not require any changes to the core central exchange algorithms. 
Our key premise is that, simultaneous delivery of market data is only essential for \emph{reactive} trades that are generated directly and quickly in response to specific real-time market data points~\cite{libra}. For all other trades, minor differences in delivery times are not critical.\footnote{Our approach can leverage clock synchronization to additionally provide fine-grained fairness for such trades (\S\ref{s:background}).}  For such reactive trades, we do not need to ensure simultaneous delivery of market data. We can alternatively achieve fairness by enforcing {\it ordering} on incoming trade requests based on the duration it took for each participant to react, \attn{i.e, time taken to submit a trade since the reception of some particular market data (response time).}
%(i.e, submit a trade) upon the reception of some particular market data (response time).%\pg{is this our insight?}


%\sout{With such an approach, we shift the problem from the datacenter network to the cloud end hosts, where operators have more flexibility and tighter control. \pg{Doesn't CloudEx also do this?}}
% \pg{say ensuring equal or even bounded latency might be hard and even not possible. Maybe we should say that our solution is capable of providing some/better fairness when clocks go out of sync or latency spike happens.}

%\pg{Ilias should we move the next two paragraphs to the related work section? I am not sure, I rewrote them a little.}
%\attn{The challenge in ordering trades this way is that it is hard to measure response times since the cloud-provider does not know how the MP generated a specific trade (i.e., which data triggered the trade). Inspired by the use of logical clocks for ordering events in distributed systems~\cite{lamportSeminalPaper, paxos_made_simple}, we introduce the notion of ``Delivery Clocks'' to overcome this issue. Corresponding to each MP, we maintain a delivery clock that tracks the progress of market data delivery to the MP. We show that \emph{ordering trades from the MP based on its delivery clock (DBO)} coupled with imposing certain \emph{restrictions on how these delivery clocks advance} (i.e., controlling the \emph{pace} of delivery of market data to MPs) can help account for delay variations in delivery of market data to MPs and enable the CES to achieve response time fairness. }

\attn{The challenge in ordering trades this way is that it is hard to measure response times since the cloud-provider does not know how the MP generated a specific trade (i.e., which data triggered the trade). Inspired by the use of logical clocks for ordering events in distributed systems~\cite{lamportSeminalPaper, paxos_made_simple}, we introduce the notion of ``Delivery Clocks'' to overcome this issue. Corresponding to each MP, we maintain a delivery clock that tracks the progress of market data delivery to the MP. We show that \emph{ordering trades from the MP based on its delivery clock (DBO)} coupled with \emph{controlling how these delivery clocks advance}\footnote{\attn{By controlling the \emph{pace} of delivery of market data to MPs}.} can help account for delay variations in delivery of market data to MPs and enable the CES to achieve response time fairness. }


%To this end, in \S\ref{s:core}, we establish the properties (for ordering trades and delivery of market data) required for achieving fairness. These properties can serve as guiding principles for building end-to-end schemes that achieve fairness (with high probability). In \S\ref{s:exp}, we use these properties to propose a few simple schemes and evaluate their performance against state-of-the-art.

\attn{To this end, in \S\ref{s:core}, we first show how DBO on its own can help improve fairness. Next, we establish some fundamental requirements on pacing of market data delivery for achieving perfect fairness. We show that if these requirements are met, DBO can indeed provide perfect fairness. In \S\ref{s:exp}, we use DBO and the constraints on pacing as our guiding principles to propose a few simple schemes and evaluate their performance.}% against state-of-the-art.}


Contrary to the current {\it modus operandi} of financial exchanges, where fairness has limited scalability and comes at a premium, our solution does not rely on equal latency between the CES and MPs and hence scales to arbitrarily sized datacenters or even across datacenters and regions. This property could be the building block for democratizing fairness in financial exchanges, with all MPs getting  equal opportunities when trading. 

%While we focus on fairness for financial exchanges, our approach is general and applicable for providing fairness in many other %distributed system settings. %where there are multiple participants taking actions based on the same real-time data from a central server. 
%Examples include, multi-player games where the game is hosted in a cloud server, advertisement auctions where multiple algorithmic bots bid on a common good, etc. %\attn{We believe that more such uses cases will emerge in future where fairness will be an important desired property.} %Going forward, logical clocks might prove to be critical in building generalized systems where any process can communicate with any other process in a fair manner.
%\pg{talk about the structure of the paper. Will write this when the rest of the paper in flushed out better.}


%We show that ordering trades from the MP based on its delivery clock can help account for delay variations in delivery of market data and enable the CES to order trades based on the response time for fairness. 

%time can be very helpful for measuring response times and ordering trades for fairness.







\if 0

Most of the major financial exchanges (such as NASDAQ, CME, NYSE) run their Central Exchange Server (CES) in  on-premise data centers. At a high level, the CES generates market data and distributes it to various market participants (MPs) in real time. Certain MPs (commonly known as high-frequency traders), rapidly react to new market data issuing a high volume of transactions: their profit is highly dependent on winning the `race for speed', aiming to submit their trade orders before other competing MPs.\footnote{High frequency traders are very aggressive in reducing latency: they often use programmable smartNICs to shave off just ns of latency on their end to gain competitive advantage.}
To accommodate fair competition based on speed of trading, financial exchanges provide 
\pg{Fairness with regards to such `reactive' trade orders constitutes simultaneous delivery of market data to the interested MPs, and processing of the trade orders based on their submission time.} Contemporary financial exchanges provide such fairness to interested MPs at a premium cost: they offer colocation services of the MPs' servers at the same datacenter with the exchange's CES, where they are able to provably guarantee equal bidirectional latency from the CES to all colocated MPs;
%The financial exchanges often go to great lengths in achieving equal bi-directional latency between the CES and the colocated MPs: 
it is not uncommon, for example, for exchanges such as NASDAQ to use equal-length cables for all colocated MPs. For the rest of the MPs -- who either do not profit from such trading strategies or cannot afford the colocation services -- fairness \pg{of such kind} is not available. Such MPs typically receive the market data stream and submit orders over variable-latency private or public WAN links.
\fi