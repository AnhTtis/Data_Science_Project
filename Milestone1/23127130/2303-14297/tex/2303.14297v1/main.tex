% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
%\usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.



\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{bm}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\usepackage{xcolor}
\newcommand{\gx}[1]{{\color{red}{GX:#1}}}
\newcommand{\hy}[1]{{\color{blue}{HY:#1}}}
\newcommand{\tc}[1]{{\color{violet}{TC:#1}}}
\newcommand{\lj}[1]{{\color{purple}{LJ:#1}}}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{8116} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{AgileGAN3D: Few-Shot 3D Portrait Stylization by Augmented Transfer Learning
}

% \author{Guoxian Song$^1$ \quad Hongyi Xu$^1$ \quad Jing Liu$^1$ \quad Tiancheng Zhi$^1$ \quad Yichun Shi$^1$ \\  Jianfeng Zhang$^{1,2}$ \quad Zihang Jiang$^{1,2}$ \quad Jiashi Feng$^1$ \quad Shen Sang$^1$ \quad Linjie Luo$^1$\\
% $^1$ByteDance Inc \quad\quad $^2$National University of Singapore\\
% % Institution1 address\\
% {\tt\small {\{guoxiansong, hongyixu, jing.liu, tiancheng.zhi, yichun.shi, jianfeng.zhang, zihang.jiang,} \\ \tt\small{ jshfeng, shen.sang, linjie.luo\}}@bytedance.com}
% % For a paper whose authors are all at the same institution,
% % omit the following lines up until the closing ``}''.
% % Additional authors and addresses can be added with ``\and'',
% % just like the second author.
% % To save space, use either the email address or home page, not both
% % \and
% % Second Author\\
% % Institution2\\
% % First line of institution2 address\\
% % {\tt\small secondauthor@i2.org}
% }

\author{Guoxian Song$^1$ \quad Hongyi Xu$^1$ \quad Jing Liu$^1$ \quad Tiancheng Zhi$^1$ \quad Yichun Shi$^1$ \\  Jianfeng Zhang$^{1,2}$ \quad Zihang Jiang$^{1,2}$ \quad Jiashi Feng$^1$ \quad Shen Sang$^1$ \quad Linjie Luo$^1$\\
$^1$ByteDance Inc \quad\quad $^2$National University of Singapore\\
% {\tt\small {guoxiansong, hongyixu, jing.liu, tiancheng.zhi, yichun.shi, jianfeng.zhang, zihang.jiang, jshfeng, shen.sang, linjie.luo@bytedance.com}}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
}


\maketitle


\newcommand{\bb}[1]{\boldsymbol{\mathbf{#1}}}
%%%%%%%%% ABSTRACT
\begin{abstract}

% Portraiture as an art form has evolved from realistic depiction into a plethora of creative styles. 
% Portrait stylization has gained 
While substantial progresses have been made in automated 2D portrait stylization, admirable 3D portrait stylization from a single user photo remains to be an unresolved challenge. One primary obstacle here is the lack of high quality stylized 3D training data. In this paper, we propose a novel framework \emph{AgileGAN3D} that can produce 3D artistically appealing and personalized portraits with detailed geometry. New stylization can be obtained with just a few (around 20) unpaired 2D exemplars. We achieve this by first leveraging existing 2D stylization capabilities, \emph{style prior creation}, to produce a large amount of augmented 2D style exemplars. These augmented exemplars are generated with accurate camera pose labels, as well as paired real face images, which prove to be critical for the downstream 3D stylization task. Capitalizing on the recent advancement of 3D-aware GAN models, we perform \emph{guided transfer learning} on a pretrained 3D GAN generator to produce multi-view-consistent stylized renderings. In order to achieve 3D GAN inversion that can preserve subject's identity well, we incorporate \emph{multi-view consistency loss} in the training of our encoder. Our pipeline demonstrates strong capability in turning user photos into a diverse range of 3D artistic portraits. Both qualitative results and quantitative evaluations have been conducted to show the superior performance of our method. Code and pretrained models will be released for reproduction purpose.

% To the best of our knowledge, we are the first paper to propose generative 3D stylized portrait creation using only a limited number of 2D style exemplars ($\sim$20). 

% with comparisons done qualitatively, quantitatively and through a perceptual user study. 

% including 2D art paintings, 3D cartoons, comics and sculpture styles, but enhanced with consistent 3D view manipulation capability. 
 
% and identity-preserving 3D portraits with visually-appealing details, we carefully study the latent space and neural representation of EG3D, the state-of-the-art 3D real-image GAN, and augment its transfer learning to various styles by lifting the prior knowledge of 2D few-shot stylization methods. 

% Specifically, in spite of prior successful few-shot style transfer learning by fine-tuning 2D convolutional network, adapting the 3D neural radiance representation to stylistic domain demands accurate camera estimation and adequate visual supervision on a wide view distribution.

% We then present a novel image encoder tailored for 3D GAN with multi-view cycle consistency loss, largely alleviating out-of-domain artifacts. We therefore propose to distill the knowledge of 2D few-shot style prior by guiding the 3D-aware generator tuning with large corpus of paired 2D stylized portraits and camera labels from widely accessible real image collections. 

%We collected several style datasets for evaluation including 3D cartoons, comics, oil paintings and celebrities. 

%We show that we can achieve superior portrait stylization quality to previous state-of-the-art 2D methods, with comparisons done qualitatively, quantitatively and through a perceptual user study. 

%We also demonstrate two applications of our method, image editing and motion retargeting.
\end{abstract}

%%%%%%%%% BODY TEXT

\input{sections/introduction}
\input{sections/method}
\input{sections/results}



\section{Conclusion}
We presented \emph{AgileGAN3D}, the first few-shot pipeline generating high quality 3D stylistic portraits with detailed in-style geometry from a single user image, which sheds light on many potential applications. Our method only uses a limited number (around 20) of unpaired 2D style exemplars for a new target style. This is achieved via a novel framework incorporating \emph{style prior creation} into \emph{guided transfer learning}, which addresses the inadequate supervision issue of 3D GAN transfer learning with accurate camera labels. We also introduce a 3D GAN inversion module with \emph{multi-view consistency loss} to improve identity preservation while achieving appealing stylization quality.
Experimental results show that the algorithm produces high-quality multi-view consistent stylized 3D portraits.
% The result 3D portrait is multi-view consistent with detailed geometry, enabling many exciting future applications.
%Experimental results show that the algorithm produces high-quality stylized 3D portrait. The result is multi-view consistent while preserving the identity.

\begin{figure}
	\centering
	\includegraphics[width=1.0\linewidth]{figures/Big/Asset_46.png}
	\centering
	\caption[Caption for LOF]{Failure examples. (a) inconsistent gaze directions, (b) unmodeled hat. }
	\label{fig:limitation}
\end{figure}

\paragraph{Limitations} We presented a variety of compelling 3D portrait stylization results, but there is still space for further improvement in our framework.  Fig.~\ref{fig:limitation} shows two example failure cases. (a) In some situations, we found that the generated eye gaze direction is biased towards frontal gaze, which may not be consistent with the input. (b) Occasionally, our approach fail to preserve accessories such as hat and glasses after stylization, as such cases are under-represented in the input datasets. These problems could potentially be mitigated by including more diverse input exemplars.

\paragraph{Societal Impact} Our work focuses on improving stylization quality of 3D GANs in technical aspects and is not designed for any malicious uses. However, inappropriate usage of the proposed method might generate undesired fake images, which is a well-known issue of portrait stylization algorithms.

%\lj{might need to polish the words in limitation societal impact sections}

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
