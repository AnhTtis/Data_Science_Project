% !TEX root = ../main.tex
\section{Experiments}
\label{sec:experiment}

\begin{figure*}[t!]
	\centering
	\includegraphics[width=\linewidth]{figs/comparison.pdf}
	\vspace{-20pt}
	\caption{\small Qualitative comparison between baselines and ours. 
	On large urban scenes, MLP-based methods (NeRF) and (Mega-NeRF) suffer from severe blurry artifacts. 
	Grid-based method (TensoRF) shows better results, but tend to produce noisy appearance with inaccurate shapes. 
	The pre-trained multi-resolution grid feature (Ours, Grid Pretrain) improves over the single high-resolution methods, yet the results is still suboptimal.
	Our final model achieves photo-realistic quality compared with ground-truth images on novel views. While grid branch (Ours, Grid branch) and NeRF branch (Ours, NeRF branch) receive similar metric scores, it is preferred to render from the NeRF branch which has sharper details and smoother spatial continuity, especially when rendering long videos in practice.
}
    \vspace{-15pt}
	\label{fig:comparison}
\end{figure*}


\subsection{Experimental Setup}

\noindent \textbf{Dataset.} Our main experiments are conducted on the real-world urban scenes. The three scenes cover different urban environments including rural rubble site~~\cite{turki2021mega} (\emph{Rubble}), university campus (\emph{Campus}), and residential complexes (\emph{Residential}). 
The camera poses are obtained from the photogrammetry software \href{https://www.bentley.com/en/terms-of-use-and-select-online-agreement}{ContextCapture}.  
Additional experiements and results on general scene datasets, alterative camera poses, and techniques for further improvements can be found in the supplementary and our webpage.

\smallskip
\noindent \textbf{Baselines and Implementations.}
We compare the performance of our approach with 1) NeRF~\cite{mildenhall2020nerf} applied on the whole scene; 2) Mega-NeRF~\cite{turki2021mega} with $4$ partitions; 3) TensoRF~\cite{chen2022tensorf}, which reduces the memory footprint of feature grid via low-rank tensor factorization and considered suitable for large-scene scenarios. 
%
For NeRF and Mega-NeRF, we accordingly adopted larger model with $12$ layers and $256$ hidden units. 
The highest frequency of position encoding is set to $2^{15}$, inserted to NeRF model via skip connection at the $4,6,8,10$ layers. 
We use hierarchical sampling during training with $64$ coarse and $128$ fine samples per ray. 
All NeRF models are optimized using Adam optimizer~\cite{kingma2014adam} with a learning rate that decayed exponentially from $5e^{-4}$ and a batch size of $2048$ rays, trained for $150k$ iterations. 
%
For TensoRF, in accordance with our observation on large urban scenes discussed previously in Sec.~\ref{subsec:multires_grid_pretrain}, we evaluated the simplified version that factorizes a feature grid into an xy-plane matrix and z-axis vector components. $16/48$ components are used for density and appearance feature grid respectively.
Starting from an initial low-resolution grid with $128^3$ voxels, the grid gets upsampled to $1024^3$ linearly in logarithmic space during training. 
The grid resolution along each dimension is scaled by the $x,y,z$ dimensions. 
A small MLP with $2$ fully connected layers of $128$ hidden layers and ReLU activation is used as the color output head.
Adam optimizer is adopted with initial leaning rate of $0.02$ for tensor factors and $0.01$ for the MLP decoder. The batch size is $4096$. The model is trained for $100k$ iterations.

Our method takes the matching grid resolution as the highest resolution feature plane and $8/16$ components for density/appearance grid respectively, with another two at the downsampled $\times 4$ and $\times 16$ resolution. The MLP head for the grid branch is same as TensoRF. The NeRF branch use a 4 MLP layer without skip layer. The highest frequency of position encoding is also set to $2^{15}$. Adam optimizer is adopted with initial learning rate of $0.02$ for tensor factors and $0.01$ for the MLP layers with batch size $4096$.
We pre-train the grid branch for the first $10k$ iterations and joint optimization for another $100k$ iterations, and the time fraction between two stages is roughly 1:4.
We use weighted loss 1:1 for two branches in joint training. 

\subsection{Results Analysis}
We report the performance of baselines and our method in Fig.~\ref{fig:comparison} and Tab.~\ref{tab:compare} both qualitatively and quantitatively. A significant improvement can be observed in visual quality and across all metrics.
Our method reveals sharper geometry and more delicate details than purely MLP-based approaches (NeRF and Mega-NeRF).
Especially, due to the limited capacity and spectral bias of NeRF, it always fails to model rapid changes in geometry and color, such as vegetation and stripes on the playground. 
Even though geographically partitioning scenes into small regions slightly helps as shown in the Mega-NeRF baseline, the rendered results still appear to be overly smoothed.
On the contrary, with the guidance from the learned feature grid, NeRF's sampling space is effectively and drastically compressed to near scene surface.
The density and appearance features sampled from the ground feature planes explicitly indicate the scene contents, as depicted in Fig.~\ref{fig:comparison}. Despite being less accurate, it already offers informative local geometry and texture, and encourages NeRF's PE to pick up the missing scene details.

\begin{table}[t!]
	\caption{\small Quantitative comparison on three large urban scene datasets. We report PSNR($\uparrow$), LPIPS($\uparrow$)~\cite{zhang2018unreasonable}, SSIM($\downarrow$) metric on the test views. The \tb{best} and \underline{second best} results are highlighted.}
	\vspace{-4mm}
	\label{tab:compare}
	\begin{center}
		\resizebox{\linewidth}{!}{
			\begin{tabular}{l|rrr|rrr|rrr}
				\toprule
				Scene   &   \multicolumn{3}{c|}{\emph{Rubble}}  &   \multicolumn{3}{c|}{\emph{Campus}} &   \multicolumn{3}{c}{\emph{Residential}} \\
				\midrule
				Metric &  PSNR & LPIPS & SSIM   &
				PSNR & LPIPS & SSIM   &
				PSNR & LPIPS & SSIM     \\
				\midrule
				NeRF   & 21.659 & 0.541 & 0.547 & 22.283 & 0.560 & 0.509 & 18.548 & 0.622 & 0.401 \\
				Mega-NeRF & 23.505 & 0.516 & 0.565 & 22.365 & 0.496 & 0.544 & 19.350 & 0.561 & 0.452 \\
				TensoRF   & 23.800 & 0.478 & 0.670 & 20.915 & 0.471 & 0.571 & 18.332 & 0.575 & 0.428 \\
				Ours (pretrain)   & 22.617 & 0.451 & 0.622 & 24.542 & 0.385 & 0.698 & 21.032 & 0.428 & 0.620\\
				\midrule
				\tb{Ours} (grid branch) & \tb{25.467} & \underline{0.213} & \tb{0.780} & \tb{25.505} & \underline{0.174} & \tb{0.767} & \tb{24.372} & \underline{0.142} & \tb{0.807}\\
				\tb{Ours} (nerf branch) & \underline{24.130} & \tb{0.207} & \underline{0.767} & \underline{24.903} &  \tb{0.162}  & \underline{0.757} & \underline{23.765} & \tb{0.137} & \underline{0.802}\\
				\bottomrule
			\end{tabular}		
		}
	\vspace{-3mm}
	\end{center}
	\centering
\end{table}

\begin{figure}[t!]
	\centering
	\includegraphics[width=\linewidth]{figs/refine.pdf}
	\vspace{-6mm}
	\caption{\small Visualization of one feature component in (a) density and (b) appearance feature plane (\emph{Residential} scene). Compared to the pre-trained feature planes, the refined ones are less noisy; sharper edges and regular shapes of grouped objects can also be clearly identified. Since density and appearance features are independently learned, they encode different information that describes the scene. The appearance feature can capture environmental effects like shadows, as shown in (b).}
	\vspace{-5mm}
\label{fig:rectified}
\end{figure}

\smallskip
\noindent \textbf{Refined Ground Feature Planes.}
Grid-based methods often require explicitly imposed regularization, such as the total variation loss or L1 loss~\cite{chen2022tensorf}, to avoid noises in regions with fewer observations, otherwise the independently optimized grid features can easily result in fuzzy and wavy appearances, as illustrated in Fig.~\ref{fig:comparison}.
By jointly optimizing with the NeRF branch, the $xy$-plane and $z$-axis encoding are constantly improved to encode more local details while becoming less noisy. A drastic improvement in fidelity can be observed in Fig.~\ref{fig:grid-rectified}. 
Similar refinement can also be observed in feature space. Take one dimensional density plane on the \emph{Residential} scene (Fig.~\ref{fig:rectified}) as an example,
%
while a coarse floor layout of the targeting urban area can already be identified on the pre-trained $xy$-plane feature (Fig.~\ref{fig:rectified}(a)), it still missed details like sharp edges and varied shapes and colors widespread in the scene, which are hard to be represented with grids unless finer grid resolution is adopted. 
NeRF, on the other hand, searches for scene surfaces with points, which provides a more accurate  and meaningful signal for grid feature optimization, and boosts it out of local minima. 
%
Another noticeable artifact on the pre-trained feature plane is the noise on continuous regions (\eg, land, facade) due to grid variation, which is largely eased after jointly optimized with NeRF.
This can be ascribed to NeRF's continuous representation of the scene, which imposes an implicit regularization on the feature grid by constructing a stronger correlation among coordinates.
The resulting refined feature planes (Fig.~\ref{fig:rectified}(b)) exhibit smooth grid features with a cleaner silhouette where content-similar grids can be clustered together (\eg, buildings, duplexes, and roads). 

\begin{figure}[t!]
	\centering
	\includegraphics[width=0.9\linewidth]{figs/xy-plane.pdf}
	\vspace{-3mm}
	\caption{\small Visualization of a slice of $xy$ feature plane from (a) TensoRF's factorization; and (b) our ground plane representation. 
		Our joint learning results in more accurate plane features with sharp region boundaries that is better
		aligned with the sceneâ€™s physical ground plan, which is naturally more suitable for large urban scene modeling and downstream analysis. A cleaner feature grid also reveals that the learned latent space is more \emph{compact}, which is critical for large-scale modeling even with limited model capacity.}
	\vspace{-10pt}
	\label{fig:xy-plane}
\end{figure}

\begin{figure}[t!]
	\centering
	\includegraphics[width=\linewidth]{figs/grid_refined.pdf}
	\caption{\small Qualitative comparison showing the rendering results using features learned (a) at a moderate grid resolution ($2048^2$), (b) at a high grid resolution ($4096^2$) and (c) from the re grid branch at resolution ($4096^2$). Despite higher grid resolution leads to better visual quality, adding NeRF supervision pushes the quality toward photorealistic one step further.}
	\vspace{-3mm}
	\label{fig:grid-rectified}
\end{figure}

\smallskip
\noindent \textbf{Compact Representations. } 
While it is instinctive to design a heavy framework for modeling large scenes, our principle is to keep it compact and efficient without significantly reduced quality. 
Bearing that in mind, we modeled the full 3D feature grid with a succinct plane-vector representation. We demonstrate in Fig.~\ref{fig:xy-plane} that,
with similar performance on reconstructing large urban scenes (PSNR: (TensoRF) 21.075 vs. (Ours) 20.915),
the 2D ground plane learned from TensoRF's VM decomposition~\cite{chen2022tensorf} appears to be fuzzier and less informative than ours; 
and our representation uses less parameters ($3e8$) compared to TensoRF ($4e8$).  
%
Moreover, recall that grid resolution is critical for purely voxel-based representation to obtain high quality renderings, our method realizes photorealistic rendering of large scenes without further upsampling. Although supplying finer-grained feature planes to our framework is beneficial, the integration with NeRF largely alleviates the dependence on grid resolution to capture scene details.
%
From NeRF's perspective, we show that a relative small MLP is sufficient to handle large scenes by taking the learned grid features with PE, and achieves superior result than the scaled-up NeRF and Mega-NeRF~\cite{turki2021mega}, as shown in Fig.~\ref{fig:comparison}. 

\subsection{Ablations}
Ablations are conducted to verify the impact of 1) different model configurations: for the grid branch, we switch to single resolution feature grid at different resolutions; for NeRF branch, we inspect model capacity and the frequency bandwidth of PE in helping NeRF recover the scene details; 
Apart from the model architecture, we also look into 2) the efficacy of enriching NeRF's pure coordinated input with grid features; and 3) the efficacy of NeRF as a supervision signal to enhance feature grid.

\smallskip
\noindent\textbf{Model configuration.}
For the grid branch, we show in Fig.~\ref{fig:abl_gridres} that adopting a single resolution feature grid leads to inferior performance. Concretely, results from a low resolution ($512^2$) grid branch already suffers from blurry artifacts during pre-training. Adding NeRF branch at the latter stage can help produce more details to the facade and rooftop but still lack sharp detail in general. On the other hand, results from a high resolution ($2048^2$) grid branch is fuzzy and noisy at the pre-training stage, which is eased by NeRF to a large extent, but still unstable at continuous regions, such as roads and walls. 
Existing works~\cite{sun2021direct,mueller2022instant,chen2022tensorf} usually adopt a small MLP as a renderer to translate grid features. In Fig.~\ref{fig:abl_nerfsize} We show that for our scenario, NeRF with a small model capacity ($D$=3, $W$=32) is insufficient to translate grid features of such complex scenes, giving inaccurate geometry and missing a large amount of scene details. Naively increasing frequency bandwidth in PE does little help under this circumstance.
By enlarging the MLP ($D$=3, $W$=256), significant improvements can be observed, from which imposing higher frequency inputs via PE can help recover more scene details.

\begin{figure}[t!]
	\centering
	\includegraphics[width=0.84\linewidth]{figs/abl_gridres.pdf}
	\caption{\small Using a single resolution grid feature results in inferior results. Low-resolution feature grid suffers from blurry artifacts and high-resolution grid gives noisy results. NeRF branch greatly helps remedy these issues with its point-wise supervision signal to pick up more details and global prior to regularize grid features. }
	\vspace{-3mm}
	\label{fig:abl_gridres}
\end{figure}

\begin{figure}[t!]
	\centering
	\includegraphics[width=0.85\linewidth]{figs/abl_nerfsize.pdf}
	\caption{\small A small renderer is insufficient to translate the grid features, producing inaccurate geometry and scene contents. However, given enough modeling capacity, NeRF picks up more details with the help of increasingly higher PE frequency channels.}
	\vspace{-3mm}
	\label{fig:abl_nerfsize}
\end{figure}

\smallskip
\noindent \textbf{Efficacy of grid features to NeRF. }
We start by simply supplying NeRF with grid features without tuning grid features and supervision from the grid branch. NeRF can already benefit from the local features encoded in the grid features, with $\sim1db$ improvement in PSNR. Tuning the feature grid can further achieve $\sim2.5db$ gain in PSNR.

\smallskip
\noindent \textbf{Efficacy of NeRF supervision to feature grid.}
As depicted in Fig.~\ref{fig:abl_gridres}, NeRF helps feature grids in recovering more details when grid resolution is inadequate, and smooth unregularized features with global prior to produce more consistent rendering results. On high-resolution grid, combining NeRF can raise PSNR by $\sim2db$ on the \emph{Campus} scene. 