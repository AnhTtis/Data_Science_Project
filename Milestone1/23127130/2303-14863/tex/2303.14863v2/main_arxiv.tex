\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

\usepackage{algorithm}
\usepackage{bm}
\usepackage{algorithmic}
\usepackage{listings}
\usepackage{makecell}  % \Xhline
\usepackage{diagbox} % diagonal table cell
\usepackage{mathtools} % \coloneqq :=
% \usepackage{graphicx} % rotated text
\usepackage{multirow}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usepackage[table]{xcolor}
\usepackage[pagebackref, breaklinks=true, colorlinks, citecolor=citecolor, linkcolor=linkcolor, bookmarks=false]{hyperref}
\definecolor{citecolor}{HTML}{0071BC}
\definecolor{linkcolor}{HTML}{ED1C24}

\def\ours{DiffusionDet\xspace}
\def\TBD{\textcolor{red}{TBD}\xspace}

\definecolor{detcolor}{gray}{.9}
\newcommand{\diffcell}[1]{\cellcolor{detcolor}{#1}}

% \definecolor{bestcolor}{RGB}{238, 255, 238}
\definecolor{bestcolor}{gray}{.9}
\newcommand{\bestcell}[1]{\cellcolor{bestcolor}{#1}}

%%%%%%%%%%%%%% ConvNext %%%%%%%%
\newcommand{\tablestyle}[2]{\setlength{\tabcolsep};{#1}\renewcommand{\arraystretch}{#2}\centering\footnotesize}
\newlength\savewidth\newcommand\shline{\noalign{\global\savewidth\arrayrulewidth
  \global\arrayrulewidth 1pt}\hline\noalign{\global\arrayrulewidth\savewidth}}
  
%%%%%%%%%%%%%%%%%%% MAE %%%%%%%%%%
\newcolumntype{x}[1]{>{\centering\arraybackslash}p{#1pt}}
\newcolumntype{y}[1]{>{\raggedright\arraybackslash}p{#1pt}}
\newcolumntype{z}[1]{>{\raggedleft\arraybackslash}p{#1pt}}
\renewcommand{\paragraph}[1]{\vspace{1.25mm}\noindent\textbf{#1}}
\definecolor{deemph}{gray}{0.6}
\newcommand{\gc}[1]{\textcolor{deemph}{#1}}

\usepackage{etoolbox}
\makeatletter
\AfterEndEnvironment{algorithm}{\let\@algcomment\relax}
\AtEndEnvironment{algorithm}{\kern2pt\hrule\relax\vskip3pt\@algcomment}
\let\@algcomment\relax
\newcommand\algcomment[1]{\def\@algcomment{\footnotesize#1}}
\renewcommand\fs@ruled{\def\@fs@cfont{\bfseries}\let\@fs@capt\floatc@ruled
  \def\@fs@pre{\hrule height.8pt depth0pt \kern2pt}%
  \def\@fs@post{}%
  \def\@fs@mid{\kern2pt\hrule\kern2pt}%
  \let\@fs@iftopcapt\iftrue}
\makeatother

\def\fullmodelname{Conditioned Location Diffusion}
\def\modelname{DiffTAD}


% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
% \usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

% \def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
% \ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
% \title{DiffTAD: Diffusion via Latent Action Query \\ for Temporal Action Detection}
% \title{DiffTAD: Temporal Action Detection with Conditioned Location Diffusion}
\title{DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion}

\author{Sauradip Nag$^{1,2}$ $\thanks{This work was done during internship with Jiankang Deng.}$
\and
Xiatian Zhu$^{1,3}$
\and
Jiankang Deng$^{4}$
\and
Yi-Zhe Song$^{1,2}$
\and 
Tao Xiang$^{1,2}$ 
\and \newline
{\small $^1$ CVSSP, University of Surrey, UK} ~ 
{\small $^2$ iFlyTek-Surrey Joint Research Center on Artificial Intelligence, UK} \\
{\small $^3$ Surrey Institute for People-Centred Artificial Intelligence, UK} ~
{\small $^4$ Imperial College London, UK} ~
}
\maketitle

\begin{abstract}
We propose a new formulation of temporal action detection (TAD) with denoising diffusion, \textbf{\em \modelname{}} in short.
%
Taking as input random temporal proposals,
it can yield action proposals accurately given an untrimmed long video.
%
This presents a generative modeling perspective,
against previous discriminative learning manners.
%
This capability is achieved by first diffusing the ground-truth proposals
to random ones (\ie, the forward/noising process) 
and then learning to reverse the noising process 
(\ie, the backward/denoising process).
%
Concretely, we establish the denoising process in the Transformer decoder (\eg, DETR) by introducing a temporal location query design
with faster convergence in training. 
%
We further propose a cross-step selective conditioning algorithm
for inference acceleration.
%
Extensive evaluations on ActivityNet and THUMOS show that our \modelname{} achieves top performance compared to previous art alternatives. The code will be made available at \href{https://github.com/sauradip/DiffusionTAD}{https://github.com/sauradip/DiffusionTAD}.
%


% We propose DiffusionTAD, a new framework that formulates temporal action detection (TAD) as a DDIM based denoising diffusion process from noisy proposals to action proposals. During  training stage, action proposals diffuse from ground-truth proposals to random distribution, and the model learns to reverse this noising process. In inference, the model refines a set of randomly generated proposals to the output results in a progressive way. The extensive evaluations on the standard benchmarks, including ActivityNet and THUMOS, show that DiffusionTAD achieves favorable performance compared to previous well-established action detection models. Our work brings two important findings in action detection.
% First, using transformer decoder as a denoiser and denoising action proposals as learned queries helps in faster convergence than regular 
% DETR based TAD models.  Second, action proposal generation, one of the subtasks of action detection, can be solved by a generative way.
% Extensive experiments on ActivityNetv1.3 and THUMOS14 demonstrate that our DiffTAD outperforms state-of-the-art non-generative TAD methods and generative baselines often by a large margin.
% random proposals, although drastically different from pre-defined anchors or learned queries, are also effective object candidates. Second, object detection, one of the representative perception tasks, can be solved by a generative way. 
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
Temporal action detection (TAD) aims to predict the temporal duration (\ie, start and end time) and the class label of each action instance in an untrimmed video \cite{idrees2017thumos,caba2015activitynet}. 
Existing methods 
rely on {\em proposal prediction} by regressing anchor proposals \cite{xu2017r,chao2018rethinking,gao2017turn,long2019gaussian}
%(Fig.~\ref{fig:fig1}(a)) 
or predicting the start/end times of proposals \cite{lin2019bmn,buch2017sst,lin2018bsn,xu2020g,nag2021few,xu2021boundary,xu2021low}.
These models are all discriminative learning based.


% Motivated by the big success of
In the generative learning perspective, diffusion model \cite{song2021denoising} has been recently exploited in image based object detection \cite{chen2022diffusiondet}.
This represents a new direction for designing detection models in general.
%
Although conceptually similar to object detection,
the TAD problem presents more complexity due to 
the presence of temporal dynamics.
%
Besides, there are several limitations 
with the detection diffusion formulation in \cite{chen2022diffusiondet}.
First, a two-stage pipeline (\eg, RCNN \cite{chao2018rethinking}) is adopted, suffering localization-error propagation from proposal generation to proposal classification \cite{nag2022gsm}.
Second, as each proposal is processed individually, their relationship modeling is overlooked, potentially hurting the learning efficacy.
%
To avoid these issues, we adopt the one-stage detection pipelines \cite{tian2019fcos,wang2020solo}
that have already shown excellent performance with a relatively simpler design, in particular, DETR \cite{carion2020end}.

% (Fig.~\ref{fig:fig1}(b))
% Inspired by the advance of one-stage object detectors \cite{tian2019fcos,lin2021detr}, many recent works focus on one-stage action detectors \cite{tan2021relaxed}, which show excellent performance while having a relatively simple structure. 


% a) the sampled proposals have no correlation among each one of themselves while prediction b) RCNN-based approaches are sensitive to the quality of region-proposals which can affect the accuracy of the final predictions. Additionaly, one region can only correspond to one object c) Two-stage approaches typically suffer from notorious localization-error propagation from proposal generation to proposal classification. 




\begin{figure}
    \centering
    \includegraphics[scale=0.51]{img/DiffTAD_fig1_v4.pdf} 
    \caption{\textbf{Diffusion for temporal action detection (TAD).} (a)
    A diffusion model for text-to-image generation where text embeddings are passed as the condition in the denoising (reverse) process. 
    We draw an analogy by exploiting 
    (b) a diffusion model for TAD: 
    {\em To generate action temporal boundaries from noisy proposals
    with the condition of video embedding.}
    % where we formulate it as a noisy proposals to action proposal denoising task and video embedding is passed as a condition in $f_{\theta}$ the denoising (reverse) process. 
    }
    \vspace{-4mm}
    \label{fig:fig1}
\end{figure}



Nonetheless, it is non-trivial to integrate denoising diffusion with existing detection models, due to several reasons.
(1) 
Whilst efficient at handling high-dimension data simultaneously, diffusion models \cite{dhariwal2021diffusion,li2022diffusion} typically work with continuous input data.
But temporal locations in TAD are discrete.
%
(2) 
Denoising diffusion and action detection
both suffer low efficiency, and their combination would make it even worse.
%
Both of the problems have not been investigated systematically thus far.



To address the aforementioned challenges,
a novel {\bf\em \fullmodelname} method is proposed 
for efficiently tackling the TAD task in a diffusion formulation,
abbreviated as {\bf \modelname}.
%
It takes a set of random temporal proposals (\ie, the start and end time pairs) following Gaussian distribution,
and outputs the action proposals of a given untrimmed video.
%
At training time, Gaussian noises are first added to the ground truth proposals to make \emph{noisy} proposals. 
%
These discrete noisy proposals are then projected into a continuous vector space using sinusoidal projection \cite{liu2022dab} to form noisy queries in which the decoder (\eg, DETR) will conduct the denoising diffusion process. 
%
Our denoising space choice facilitates the adoption of existing diffusion models, as discussed above.
%
As a byproduct, the denoising queries strategy itself can accelerate the training convergence of DETR type models \cite{li2022dn}.
%
At inference time, conditioned on a test video, \modelname{} can generate action temporal boundaries by reversing the learned diffusion process
from Gaussian random proposals.
%
For improving inference efficiency,
we further introduce a cross-timestep selective conditioning mechanism 
with two key functions:
(1) minimizing the redundancy of intermediate predictions at each sampling step by filtering out the proposals far away from the distribution of corrupted proposals generated in training, and (2) conditioning the next sampling step by selected proposals 
to regulate the diffusion direction for more accurate inference.
%

% which adjusts a noisy prior distribution to the learned distribution over bounding proposals.

% Our pipeline of DiffTAD has the appealing advantage of Once-for-All: we can train the video encoder once and use the same network parameters under diverse settings in inference.
% (1)~\emph{Dynamic proposals}: Leveraging random action proposals as object candidates, DiffTAD decouples the training and evaluation. DiffTAD can be trained with $N_{train}$ random queries while being evaluated with $N_{eval}$ random queries, where the $N_{eval}$ is arbitrary and does not need to be equal to $N_{train}$. 
% (2)~\emph{Progressive refinement}: The diffusion model benefits DiffTAD by iterative refinement. We can adjust the number of denoising sampling steps to improve the detection accuracy or accelerate the inference speed. This flexibility enables DiffTAD to suit different detection scenarios where accuracy and speed are required differently.




% Motivated by this, we project the discrete bounding proposals as continuous object queries using sinosoidal projections similar to \cite{wang2021anchor,liu2022dab} and then we can use  diffusion on continuous diffusion models. 



% DETR based approaches however enjoys several advantages over RCNN. Firstly, the object queries (instead of object proposals) have self-attention on top that influences the prediction based on other query prediction. Secondly, DETR based models can handle instances of varying sizes and number of objects in an image with a fixed number of output predictions. Thirdly, DETR is a NMS-Free single-stage approach which does not suffer from localization-error propagation. Since, the task of object detection has close association with temporal action detection, DETR has been used frequently in TAD domain \cite{shi2022react,tan2021relaxed} which is far superior than RCNN based counter part \cite{chao2018rethinking}. 


% Generative modeling for object detection is challenging as the bounding proposals are discrete/categorical and can be very large in number. There are two prominent ways in which a object detection problem can be posed as a generative task namely RCNN based two-staged approaches where a naive way to formulate this is to replace the RPN with a bounding box generator and another approach is to use single-stage DETR based approach where the decoder can be made auto-regressive. 
% Recently, the former one has been first explored by DiffusionDet \cite{chen2022diffusiondet} where the authors have used DDIM based diffusion to model it as a \textit{noise-to-proposals} task. 

% However, there are some drawbacks for such approach a) the sampled proposals have no correlation among each one of themselves while prediction b) RCNN-based approaches are sensitive to the quality of region-proposals which can affect the accuracy of the final predictions. Additionaly, one region can only correspond to one object c) Two-stage approaches typically suffer from notorious localization-error propagation from proposal generation to proposal classification. DETR based approaches however enjoys several advantages over RCNN. Firstly, the object queries (instead of object proposals) have self-attention on top that influences the prediction based on other query prediction. Secondly, DETR based models can handle instances of varying sizes and number of objects in an image with a fixed number of output predictions. Thirdly, DETR is a NMS-Free single-stage approach which does not suffer from localization-error propagation. Since, the task of object detection has close association with temporal action detection, DETR has been used frequently in TAD domain \cite{shi2022react,tan2021relaxed} which is far superior than RCNN based counter part \cite{chao2018rethinking}. 

% It is not straightforward to implement Diffusion models for DETR based designs, mainly because DETR based approaches normally suffers from slow-convergence issue mainly due to bipartite set matching, which coupled with dense DDIM sampling worsens. Also, diffusion models \cite{dhariwal2021diffusion,li2022diffusion} are better at handling high dimension data but they are most commonly applied to continuous rather than discrete domains. To model diffusion for discrete data, Bit Diffusion \cite{chen2022analog} first converts integers representing discrete tokens into bit strings to which continuous diffusion models can be applied. Motivated by this, we project the discrete bounding proposals as continuous object queries using sinosoidal projections similar to \cite{wang2021anchor,liu2022dab} and then we can use  diffusion on continuous diffusion models. Apart from slow convergence, DETR based models have some drawbacks when applied directly to TAD. First, the inter-query relations are not fully explored by the self-attention in the decoder, which is performed densely over all the queries. Second, DETR-like methods may suffer from the inadequate training of action classification since the number of positive training samples for the classifier is relatively small compared to anchor-based/free methods. Moreover, when multiple queries fire for the same action instance at inference, queries with higher classification scores may not necessarily have better temporal localization. 

% To address these problems jointly we propose DiffTAD, which tackles the action detection task with a diffusion model by casting detection as a generative task over the space of the locations~(action start/end points) of anchor proposals in the video. At training stage, Gaussian noise controlled by a variance schedule~\cite{ho2020denoising} is added to ground truth proposals to obtain \emph{noisy} proposals. Then these discrete noisy proposals are projected into continuous spaces using a sinusoidal projection \cite{?} module to obtain noisy queries. These noisy queries are then passed into the DETR decoder, which is trained to predict the ground-truth proposals without noise. With this training objective, DiffTAD is able to predict the ground truth proposals from random proposals using the Transformer Decoder as a denoiser. At inference stage, DiffTAD generates bounding proposals by reversing the learned diffusion process, which adjusts a noisy prior distribution to the learned distribution over bounding proposals.

% Our pipeline of DiffTAD has the appealing advantage of Once-for-All: we can train the video encoder once and use the same network parameters under diverse settings in inference.
% (1)~\emph{Dynamic proposals}: Leveraging random action proposals as object candidates, DiffTAD decouples the training and evaluation. DiffTAD can be trained with $N_{train}$ random queries while being evaluated with $N_{eval}$ random queries, where the $N_{eval}$ is arbitrary and does not need to be equal to $N_{train}$. 
% (2)~\emph{Progressive refinement}: The diffusion model benefits DiffTAD by iterative refinement. We can adjust the number of denoising sampling steps to improve the detection accuracy or accelerate the inference speed. This flexibility enables DiffTAD to suit different detection scenarios where accuracy and speed are required differently.

Our \textbf{contributions} are summarized as follows. 
\noindent (1) For the first time we formulate the temporal action detection problem through denoising diffusion in the elegant transformer decoder framework. Additionally, integrating denoising diffusion with this decoder design
 solves the typical slow-convergence limitation.
%
\noindent (2) We further enhance the diffusion sampling efficiency and accuracy by introducing a novel selective conditioning mechanism during inference.
%
\noindent (3) Extensive experiments on ActivityNet and THUMOS benchmarks show that our \modelname{} achieves favorable performance against prior art alternatives.
% We formulate temporal action detection as a Diffusion based generative denoising process, which is the first study to apply the diffusion
% model to single stage action detection to the best of our knowledge. We use transformer decoder as a denoising module which additionally solves slow-convergence issue common in DETR based approaches

% \noindent (ii) Repurposing transformer decoder as a denoising module has several appealing properties, such as decoupling training, solving slow convergence issue and evaluation stage for dynamic proposals and progressive refinement.
% %
% \noindent (ii) We also improved the diffusion sampling efficiency through our novel iterative self-conditioning module.

% \noindent (iii) We conducted extensive experiments on ActivityNet and THUMOS benchmarks. DiffusionDet achieves favorable performance against previous well-established detectors.


% Then these noisy proposals are used to crop~\cite{ren2015faster,he2017mask} features of Region of Interest (RoI) from the output feature map of the backbone encoder, \eg, ResNet~\cite{he2016deep}, Swin Transformer~\cite{liu2021swin}. Finally, these RoI features are sent to the detection decoder, which is trained to predict the ground-truth proposals without noise. With this training objective, \ours is able to predict the ground truth proposals from random proposals.  
% % 
% At inference stage, \ours generates bounding proposals by reversing the learned diffusion process, which adjusts a noisy prior distribution to the learned distribution over bounding proposals.

 



% RCNN-based approaches can be computationally expensive and require a lot of memory, especially during inference time, due to their multi-stage design. RCNN-based approaches require anchor proposals, which can be difficult to design and choose the right size and aspect ratios for different object types and scales. RCNN-based approaches are sensitive to the quality of the region proposals, which can affect the accuracy of the final predictions.


% Generative modeling for panoptic segmentation is very challenging as the panoptic masks are discrete/categorical and can be very large

% On the other hand, DETR[4], which tackles object detection in a Transformer encoder-decoder framework, attracted considerable attention. 

% In an early attempt, generative model (e.g, VAE) based approaches have been first explored in weakly supervised TAD by \cite{shi2020weakly}. 




% In this work, we propose a novel one-stage action detector ReAct that is based on such a learning paradigm. Inspired by DETR, ReAct models action instances as a set of learnable action queries. In contrast to previous detectors, DETR uses learnable queries to probe image features from the output of Transformer encoders and bipartite graph matching to perform set-based box prediction. Such a design effectively eliminates hand-designed anchors and non-maximum suppression (NMS) and makes object detection end-to-end optimizable. However, DETR suffers from prohibitively slow training convergence compared with previous detectors. 

% Despite all the progress, few works pay attention to the bipartite graph matching part for more efficient training. In this study, we find that the slow convergence issue also results from the discrete bipartite graph matching component, which is unstable especially in the early stages of training due to the nature of stochastic optimization. As a consequence, for the same image, a query is often matched with different objects in different epochs, which makes optimization ambiguous and inconstant.

% To address this problem, we propose a novel training
% method by introducing a query denoising task to help
% stabilize bipartite graph matching in the training process.
% Since previous works have shown effectiveness in interpreting queries as reference points. Our solution is to feed noised GT bounding proposals as noised queries together with learnable anchor queries into Transformer
% decoders. Both kinds of queries have the same input format of (x, y, w, h) and can be fed into Transformer decoders simultaneously. For noised queries, we perform a denoising task to reconstruct their corresponding GT proposals. For other learnable anchor queries, we use the same training loss and bipartite matching as in the vanilla DETR. 

%  As the noised bounding proposals do not need to go through the bipartite
% graph matching component, the denoising task can be regarded as an easier auxiliary task, helping DETR alleviate the unstable discrete bipartite matching and learn bounding box prediction more quickly. Meanwhile, the denoising task also helps lower the optimization difficulty because the
% added random noise is usually small. To maximize the potential of this auxiliary task, we also regard each decoder query as a bounding box + a class label embedding so that we are able to conduct both box denoising and label denoising.

% In summary, our method is a denoising training approach. Our loss function consists of two components. One is a reconstruction loss and the other is a Hungarian loss which is the same as in other DETR-like methods. Our
% method can be easily plugged into any existing DETR like method. For those that do not support anchors like the vanilla DETR[1], we can do linear transformation to map 4D anchor proposals to the same latent space as for other learnable queries. 


% We design a novel training method to speed up DETR training. Experimental results show that our method not only accelerates training convergence
% but also leads to a remarkably better training result

% In this work, we propose \ours, which tackles the object detection task with a diffusion model by casting detection as a generative task over the space of the positions~(center coordinates) and sizes~(widths and heights) of bounding proposals in the image. At training stage, Gaussian noise controlled by a variance schedule~\cite{ho2020denoising} is added to ground truth proposals to obtain \emph{noisy} proposals.
% Then these noisy proposals are used to crop~\cite{ren2015faster,he2017mask} features of Region of Interest (RoI) from the output feature map of the backbone encoder, \eg, ResNet~\cite{he2016deep}, Swin Transformer~\cite{liu2021swin}. Finally, these RoI features are sent to the detection decoder, which is trained to predict the ground-truth proposals without noise. With this training objective, \ours is able to predict the ground truth proposals from random proposals.  
% % 
% At inference stage, \ours generates bounding proposals by reversing the learned diffusion process, which adjusts a noisy prior distribution to the learned distribution over bounding proposals.

% The noise-to-box pipeline of \ours has the appealing advantage of Once-for-All: we can train the network once and use the same network parameters under diverse settings in inference.
% (1)~\emph{Dynamic proposals}: Leveraging random proposals as object candidates, \ours decouples the training and evaluation. \ours can be trained with $N_{train}$ random proposals while being evaluated with $N_{eval}$ random proposals, where the $N_{eval}$ is arbitrary and does not need to be equal to $N_{train}$. 
% (2)~\emph{Progressive refinement}: The diffusion model benefits \ours by iterative refinement. We can adjust the number of denoising sampling steps to improve the detection accuracy or accelerate the inference speed. This flexibility enables \ours to suit different detection scenarios where accuracy and speed are required differently.



% We analyze the slow convergence of DETR from a novel viewpoint and give a deeper understanding of DETR training. We design a metric to evaluate
% the instability of bipartite matching and verify that our method can effectively lower the instability.


\section{Related Works}

\noindent \textbf{Temporal action detection.} Inspired by object detection in static images \cite{ren2016faster},
R-C3D \cite{xu2017r} uses anchor proposals by following the design of proposal generation and classification.
With a similar model design, TURN \cite{gao2017turn} aggregates local features to represent snippet-level features for temporal boundary regression and classification. SSN \cite{zhao2017temporal} decomposes an action instance into three stages (starting, course, and ending)
and employs structured temporal pyramid pooling
to generate proposals.
BSN \cite{lin2018bsn} predicts the start, end, and actionness at each temporal location and generates proposals with high start and end probabilities. The actionness was further improved in BMN \cite{lin2019bmn} via
additionally generating a boundary-matching confidence map for improved proposal generation. 
GTAN \cite{long2019gaussian}
improves the proposal feature pooling procedure with a learnable Gaussian kernel for weighted averaging. G-TAD \cite{xu2020g}
learns semantic and temporal context via graph convolutional networks for more accurate proposal generation. BSN++ \cite{su2020bsn++} further extends BMN with a complementary boundary generator to capture rich context.
CSA \cite{sridhar2021class} enriches the proposal temporal context via attention transfer. VSGN \cite{zhao2021video} improves short-action localization using a cross-scale multi-level pyramidal architecture. \textcolor{black}{Recently, Actionformer \cite{zhang2022actionformer} and React \cite{shi2022react} proposed a purely DETR based design for temporal action localization at multiple scales.} 
Our DiffTAD is the very first TAD model which proposes action detection as a generative task.
% Mostly, existing TAD models suffer from temporal quantization error as the actions are detected in the reduced temporal space. 
% We present a model-agnostic post-processing strategy
% for generally tackling this problem
% Our GAP is designed to address this limitation by building a refinement module on top of existing models 
% without model redesign and retraining at a negligible cost.

\noindent \textbf{Diffusion models.} As a class of deep generative models, diffusion models~\cite{ho2020denoising, song2019generative, song2021scorebased} start from the sample in random distribution and recover the data sample via a gradual denoising process. 
Diffusion models have recently demonstrated remarkable results in fields including 
% 
computer vision~\cite{avrahami2022blended, Ramesh2022HierarchicalTI, saharia2022photorealistic, pmlr-v162-nichol22a, gu2022vector, Fan2022FridoFP, Ruiz2022DreamBoothFT, singer2022make, harvey2022flexible, zhang2022motiondiffuse, ho2022video, yang2022diffusion},
% 
nature language processing~\cite{austin2021structured, li2022diffusion, gong2022diffuseq},
% 
audio processing~\cite{Popov2021GradTTSAD, yang2022diffsound, wu2021itotts, levkovitch2022zero, tae2021editts, huang2022prodiff, kim2022guided}, 
% 
interdisciplinary applications\cite{jing2022torsional, hoogeboom2022equivariant, anand2022protein, xu2021geodiff, trippe2022diffusion, wu2022diffusion, arne2022structure}, \etc. More applications of diffusion models can be found in recent surveys~\cite{yang2022diffusion, cao2022survey}.

\begin{figure*}
    \centering
    \includegraphics[width=1.0\linewidth]
    % \includegraphics[scale=0.29]
    {img/fig2_v4.pdf}
    \caption{\textbf{Overview of our proposed DiffTAD.} In the forward diffusion process, Gaussian noises are added to the ground-truth boundaries iteratively to obtain noisy versions $X_{T}$. In the reverse denoising process, a video is passed as the condition along with random proposals sampled from Gaussian distribution. The discrete proposals are then projected to a continuous embedding space where proposal denoising takes place in an iterative fashion to obtain action proposals. In particular, a cross-timestep selective conditioning strategy is introduced for proposal refinement and filtering for more accurate and efficient inference.
     }
     \vspace{-4mm}
    \label{fig:my_label}
\end{figure*}

\noindent \textbf{Diffusion model for perception tasks.} While Diffusion models have achieved great success in image generation~\cite{ho2020denoising, song2021scorebased, dhariwal2021diffusion}, their potential for other perception tasks has yet to be fully explored. Some pioneer works tried to adopt the diffusion model for image segmentation tasks~\cite{wolleb2021diffusion, baranchuk2022labelefficient, graikos2022diffusion, kim2022diffusion, brempong2022denoising, amit2021segdiff, chen2022generalist}. For example, Chen~\etal~\cite{chen2022generalist} adopted Bit Diffusion model~\cite{chen2022analog} for panoptic segmentation~\cite{kirillov2019panoptic} of images and videos. However, despite significant interest in this idea,  
there is no previous solution that successfully adapts generative diffusion models for object detection, the progress of which remarkably lags behind that of segmentation. This might be because the segmentation task can be processed in an image-to-image style, which is more similar to image generation in formulation \cite{chen2023gss}. 
While object detection is a set prediction problem~\cite{carion2020end} with a need for assigning object candidates~\cite{ren2015faster,lin2017feature,carion2020end} to ground truth objects. However, Chen \etal~\cite{chen2022diffusiondet} managed to apply a diffusion model to object detection for the first time. 
Similarly, we make the first attempt at formulating TAD
in the diffusion framework by integrating the denoising process with 
the single-stage DETR architecture.
% To the best of our knowledge, this is the first work that adopts a diffusion model for action detection in a single stage framework.

\section{Methodology}
\subsection{Preliminaries}

\noindent \textbf{Temporal action detection.} Our \modelname{} model takes as input an untrimmed video $V$ with a variable number of frames. Video frames are first pre-processed by a feature encoder (\eg, a Kinetics pre-trained I3D network \cite{carreira2017quo}) into a sequence of localized snippets following the standard practice \cite{lin2019bmn}. To train the model, we collect a set of labeled video training set $\mathcal{D}^{train} = \{V_i, \Psi_i\}$. Each video $V_i$ is labeled with temporal annotation $\Psi_i = \{(\psi_j, \xi_j, y_j)\}_{j=1}^{M_i}$ where $\psi_{j}$/$\xi_{j}$ denote the start/end time, $y_j$ is the action category, and $M_i$ is the number of action instances. 

\noindent \textbf{Diffusion models}~\cite{sohl2015deep, ho2020denoising, song2019generative, song2021denoising} are a class of likelihood-based models inspired by nonequilibrium thermodynamics~\cite{song2019generative, song2020improved}. These models define a Markovian chain of diffusion forward process by gradually adding noises to the sample data. The forward noising process is defined as
\begin{equation}
\label{eq:noise_process}
    q(\bm{z}_t | \bm{z}_0) = \mathcal{N}(\bm{z}_t | \sqrt{\bar{\alpha}_t} \bm{z}_0, (1 - \bar{\alpha}_t) \bm{I}),
\end{equation}
which transforms a sample $\bm{z}_0$ to a latent noisy sample $\bm{z}_t$ ($t\in\{0, 1, ...,T\}$) by adding noises to $\bm{z}_0$.
% 
$\bar{\alpha}_t \coloneqq \prod_{s=0}^{t} \alpha_s = \prod_{s=0}^{t} (1 - \beta_s)$ and $\beta_s$ represents the noise variance schedule~\cite{ho2020denoising}.
During training, a neural network $f_\theta(\bm{z}_t, t)$ is trained to predict $\bm{z}_0$ from $\bm{z}_t$ by minimizing the training objective with $\ell_2$ loss~\cite{ho2020denoising}:
\begin{equation}
    \mathcal{L}_\text{train} =  \frac{1}{2}|| f_\theta(\bm{z}_t, t) - \bm{z}_0 ||^2.
\end{equation}
At inference, a sample $\bm{z}_0$ is reconstructed from noise $\bm{z}_T$ with the model $f_\theta$ and an updating rule~\cite{ho2020denoising, song2021denoising} in an iterative way, \ie,  $\bm{z}_T \rightarrow \bm{z}_{T-\Delta} \rightarrow ... \rightarrow \bm{z}_0$. More details of diffusion models can be found in Supplementary.

% \paragraph{Self-conditioning} \cite{chen2022analog} was first introduced to enable the denoising function to refine the previous estimation rather than making a new estimation from scratch for more efficient sampling. 
% % Motivated by this, we propose to use the strategy of selective conditioning on the predicted proposals to make inference faster and better align with training. 
% More specifically, at each time step $t$ the denoising decoder generates an estimate $\Bar{x}^{t}_{0} = f_{\theta}(x_{t},t)$ of $x_{0}$ given only $x_{t}$ as input.  Self-conditioning progressively refines $x_{0}$ estimates by passing the estimate $\Tilde{x}^{t+1}_{0}$ obtained at the previous sampling step as input to the denoising network; The self-conditioned estimate is defined as $\Tilde{x}^{t}_{0} = f_{\theta}(x_{t}, \Tilde{x}^{t+1}_{0},t)$ and sets the diffusion direction.

\subsection{\modelname}
\label{sec:difftad}
\paragraph{Diffusion-based TAD formulation.}
In this work, we formulate the temporal action detection task in 
a conditional denoising diffusion framework. In our setting, data samples are a set of action temporal boundaries $\bm{z}_0 = \bm{b}$, where $\bm{b}\in \mathbb{R}^{N \times 2}$ denotes $N$ temporal proposals. 
A neural network $f_\theta(\bm{z}_t, t, \bm{x})$ is trained to predict $\bm{z}_0$ from noisy proposals $\bm{z}_t$, conditioned on the corresponding video $\bm{V}$. The corresponding category label $\bm{\hat{y}}$ is produced accordingly. 

Since the diffusion model generates a data sample iteratively, it needs to run the model $f_\theta$ multiple times in inference. However, it would be computationally intractable to directly apply $f_\theta$ on the raw video at every iterative step.
For efficiency, we propose to separate the whole model into two parts, \textit{video encoder} and \textit{detection decoder}, where the former runs only once to extract a feature representation of the input video $\bm{V_{i}}$, and the latter takes this feature as a condition
% instead of the raw image, 
to progressively refine the %the proposal predictions from 
noisy proposals $\bm{z}_t$.

\noindent \textbf{Video encoder.} 
The video encoder takes as input the 
pre-extracted video features and extracts high-level features for the following detection decoder. In general, any video encoder can be used. 
We use a video encoder same as \cite{zhang2022actionformer}.
%
% We use a CNN based projection followed by Multi-scale Transformer as our encoder backbone, following  \cite{zhang2022actionformer}. 
More specifically, the raw video $V$ is first 
encoded by a convolution encoder to obtain multiscale feature $H_{i} \in \mathbb{R}^{T \times D}$ for RGB and optical flow separately. This is followed by a multi-scale temporal transformer \cite{vaswani2017attention} $\mathcal{T}$ that performs global attention across the time dimension to obtain the global feature as:
\begin{align}
    F^{i}_{g} = \mathcal{T}(H_{i}) , i \in [1,\cdots,L] 
\end{align}
where query/key/value of the transformer is set to $H_{i}$ and $L$ is the number of scales. We estimate the shared global representations $F^{i}_{g} \in \mathbb{R}^{T \times D}$ across all the scales and concatenate them as $F_{g} = \{ F^{0}_{g}, F^{1}_{g}, ..., F^{L}_{g}\}$. 

Previous TAD works \cite{lin2019bmn,xu2020g} typically 
use fused RGB and flow features (\ie, early fusion)
for modeling.
% focus on both RGB and flow fusion as early fusion features, 
%
Considering the feature specificity (RGB for appearance, and optical flow for motion), 
we instead exploit a late fusion strategy (Fig.~\ref{fig:decoup}).
% In \modelname{}, we find the late fusion a better alternative (refer Table~\ref{tab:fusion}). 
Specifically, we extract the video features $F^{rgb}_{g}$ and $F^{flow}_{g}$ for RGB and optical flow separately.
The proposal denoising is then conducted in each space individually.
%
The forward/noising process is random (\ie, feature agnostic) and thus
% it is 
shared by both features.
%
We will compare the two fusion strategies empirically
(see Table~\ref{tab:fusion}).
% Hence we extract the global features separately for RGB backbone which is represented by $F^{rgb}_{g}$ and for flow $F^{flow}_{g}$ respectively as shown in Fig {\color{red}xyz}. 
% The RGB features carry meaningful spatial information for action frames since we use dense feature representation. It however does not capture the motion information of the action happening which is compensated by the $F^{flow}_{g}$ features. 


% Convolutional Neural Networks such as ResNet~\cite{he2016deep} and Transformer-based models like Swin~\cite{liu2021swin}. Feature Pyramid Network~\cite{lin2017feature} is used to generate multi-scale feature maps for both ResNet and Swin backbones following~\cite{lin2017feature, sun2021sparse, liu2021swin}.

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{img/fig3_v2.pdf} 
    \caption{\textbf{Spacetime decoupled denoising.} We perform spacetime decoupled denoising via feature late-fusion. The RGB and optical flow features are extracted separately and passed as a condition to the denoiser, separately.
    % thus making the denoiser spatial aware and temporal motion aware. 
    }
    \label{fig:decoup}
\end{figure}

\noindent \textbf{Detection decoder.} Similar to DETR \cite{lin2021detr}, we use a transformer decoder \cite{vaswani2017attention} (denoted by $f_{\theta}$) for detection.
Functionally it serves as a denoiser. % of \modelname{}.
% In \modelname{}, it is formulated as a denoiser. 
In traditional DETR, the queries are learnable continuous embeddings with random initialization. 
%
% However, previous findings \cite{liu2022dabdetr} has shown that \textit{anchor proposals are better queries for DETR style designs}. 
%
In \modelname{}, however, we exploit the queries as the {\em denoising targets}.
%
% Motivated by that, 

Specifically, we first project discrete proposals $\psi \in \mathbb{R}^{N \times 2}$ to continuous query embeddings \cite{wang2021anchor}:
% To facilitate this, we learn a projection module \cite{wang2021anchor} as:
\begin{align}
    Q = g(\psi) \in \mathbb{R}^{N \times D}
\end{align}
where $g$ is MLP-based learnable projection.
% can be fixed embeddings (\eg sinusoidal) or learnable (\eg MLP). We use MLP based learnable projection. 
% The projection module $g(\cdot)$ projects the discrete action proposals $\psi$ as continuous query embeddings $Q \in \mathbb{R}^{N \times D}$. 
% More specifically, 
Taking $Q$ as input, 
% $N$ action proposals as continuous embeddings and 
the decoder then predicts $N$ outputs:
\begin{align}
    F_{d} = f_{\theta}(Q;F_{g}) \in \mathbb{R}^{N \times D}
\end{align}
where $F_{g}$ is the global encoder feature and 
the $F_{d}$ is the final embedding.
%
$F_{d}$ is finally decoded using three parallel heads namely (1) \textit{action classification head}, (2) \textit{action localization head}, and (3) \textit{completeness head}, respectively. The first estimates the probability of a particular action within the action proposal. The second estimates the start, end and IOU overlap between the proposals. The third estimates the quality of predicted action proposals. 


% by the decoder head for action detection. It is defined formally as:
% which is used as a cross-attention with the action query embeddings to obtain the final embedding $F_{d}$. 
% Following \cite{tan2021relaxed}, our transformer decoder is composed of a 6-layer design. 



% The decoder takes as input a set of discrete action proposals $\psi \in \mathbb{R}^{N \times 2}$ projected as continuous query embeddings $Q \in \mathbb{R}^{N \times D}$ which is conditioned on the video encoder features $F_{g}$ via cross-attention and then finally sends these features to FFN based detection heads to obtain box regression and classification.


% The difference between our transformer decoder and the decoder used in React \cite{shi2022react} are that (i) DiffTAD begins from random proposals as queries while React start from random queries.
% (iii) DiffTAD re-uses the detector head in iterative sampling steps and the parameters are shared across different steps, each of which is specified to the diffusion process by timestep embedding \cite{}, while React uses the detection decoder only once in the forward pass. (iii) DiffTAD reuses past time-step output as a condition to the input queries to refine and optimize the denoising process, while React never uses intermediate results as a condition.



\paragraph{Cross-timestep selective conditioning.}
% In diffusion based paradigm, we sample noise from a random gaussian distribution and then iteratively denoise it to get the cleaner data. 
In \modelname{}, the denoising decoder $f_{\theta}$ takes $N$ action queries and then denoises each of them iteratively.
% through time-steps. 
Processing a large number of queries is thus inefficient.
%
An intuitive way for better efficiency is to use static thresholds to suppress unimportant candidates \cite{chen2022diffusiondet}, which however is ad-hoc and ineffective.
%

Here, we propose a more principled {\em cross-timestep selective conditioning} mechanism (Fig. \ref{fig:sel}). 
More specifically, 
%
we calculate a similarity matrix $A \in \mathbb{R}^{N \times N}$ between the $N$ queries $x_{t}$ of current timestep and $N$ queries $x_{t+1}$ of conditioned/previous timestep $x_{t+1}$.
%
Each element of $A$ represents the similarity of the same queries across two successive timesteps.
%
We select a set of queries according to: 
\begin{align}
    \hat{P} _{sim} = \{(i,j)|A[i,j] - \gamma > 0 \}
\end{align}
where $\gamma \in [-1,1]$ is a preset similarity threshold. 
%
%
%
We consider higher IoU with the desired (approximated by the estimate of the last step) proposals,
more effective for the queries to be denoised.
%
% To compute which proposal most likely to denoise closer to the next time-step, the temporal IOU overlap of desired proposals will be high.
Thus, we construct an IoU based matrix $B \in \mathbb{R}^{N \times N}$ between two successive timesteps:
\begin{align}
    \hat{P}_{iou} = \{(i,j)|B[i,j] - \gamma > 0 \}
\end{align}
where $i$/$j$ indexes the queries.
This allows for the most useful queries to be selected (see Fig. 1 in Supplementary).

We obtain the 
final query set as $Q_{c} = (\hat{P}_{iou} / \hat{P}_{sim}) \bigcup Q$ with $/$ denotes the set divide operation. 
For a selected query $q_{i}$, its key and value features can be obtained by fusion as $K_{i}/V_{i} = cat(\{k_{j}/v_{j}|(i,j) \in Q_{c}\})$. Each query feature is then updated as 
\begin{align}
    \hat{q}_{i} = softmax(q_{i}K^{\top}_{i}).V^{\top}_{i}
\end{align}
These selected queries $\{\hat{q}_{i}\}$
will be passed through the cross-attention with video embeddings for denoising.
%
This selective conditioning is applied on
a random proportion (\eg, 70\%) of proposals per mini-batch during training, and on all the proposals during inference.

% This $\hat{q}_{i}$ is the conditioned query features with attention weights on selected queries satisfying the condition.

Our selective conditioning strategy shares the spirit of self-conditioning \cite{chen2022analog} in the sense that the output of the last step is used for accelerating the subsequent denoising.
%
However, our design and problem setup both are different.
For example, self-conditioning can be simply realized
by per-sample feature concatenation, whilst our objective
is to select a subset of queries
based on the pairwise similarity and IoU measurement in an attention manner.
We validate the conditioning design in the experiments 
(Table \ref{tab:selcond}).


% As shown in Fig xyz, this strategy refines the most probable action queries. 
% Finally, we obtain the 
% most similar denoised query set $Q_{c} = (\varepsilon _{iou} / \varepsilon _{sim}) \bigcup Q$. For a query $q_{i}$ , the key and value features can be obtained as $K_{i}/V_{i} = cat(\{k_{j}/v_{j}|(i,j) \in Q_{c}\})$. The query features are then updated respectively by 
% \begin{align}
%     \hat{q}_{i} = softmax(q_{i}K^{T}_{i}).V^{T}_{i}
% \end{align}
% This $\hat{q}_{i}$ is the conditioned query features with attention weights on selected queries satisfying the condition.


% given the estimate $\Tilde{x}^{t+1}_{0}$ from the previous sampling step, we aim to find out a subset of 
% queries $\Tilde{x}^{t}_{0}$ for the current time step
%

% to gather the context of the queries in two time-steps, 
% we calculate a similarity matrix $A \in \mathbb{R}^{N \times N}$ ($N$ is the number of queries) between the $N$ queries of current time-step $x_{t}$ and $N$ queries of conditioned/previous time-step $x_{t+1}$. 
% Each element of $A$ represents the cosine-similarity of the same queries but at different time-step. 
% We construct a set of queries as: 
% \begin{align}
%     \varepsilon _{sim} = \{(i,j)|A[i,j] - \gamma > 0 \}
% \end{align}
% where $\gamma \in [-1,1]$ is a preset similarity threshold. To compute which proposal most likely to denoise closer to the next time-step, the temporal IOU overlap of desired proposals will be high.
% To estimate that, we compute a matrix $B \in \mathbb{R}^{N \times N}$ between the current and reference time-step to obtain:
% \begin{align}
%     \varepsilon _{iou} = \{(i,j)|B[i,j] - \gamma > 0 \}
% \end{align}
% where $i$/$j$ index the queries. 
% As shown in Fig xyz, this strategy refines the most probable action queries. Finally, we obtain the 
% most similar denoised query set $Q_{c} = (\varepsilon _{iou} / \varepsilon _{sim}) \bigcup Q$. For a query $q_{i}$ , the key and value features can be obtained as $K_{i}/V_{i} = cat(\{k_{j}/v_{j}|(i,j) \in Q_{c}\})$. The query features are then updated respectively by 
% \begin{align}
%     \hat{q}_{i} = softmax(q_{i}K^{T}_{i}).V^{T}_{i}
% \end{align}
% This $\hat{q}_{i}$ is the conditioned query features with attention weights on selected queries satisfying the condition.


% Meanwhile, self-conditioning is shown to 
% be an effective acceleration strategy in image generation \cite{?}.
%
% It is realized by concatenating $x_{t}$ and $\Tilde{x}^{t+1}_{0}$ in the feature dimension.
%
% However, we find that stacking noisy proposals is even detrimental due to different data nature (refer to Table xyz). 
% Instead, we consider the self-conditioning idea \cite{?}
% for automatic candidate filtering.
% In image generation, conditioning can be performed by concatenating $x_{t}$ and $\Tilde{x}^{t+1}_{0}$ in the feature dimension \cite{?}. However, $x_{t}/\Tilde{x}^{t+1}_{0}$ are discrete bounding proposals in our case. 
% Stacking noisy proposals is detrimental (refer to Table xyz). 

% \paragraph{Self-conditioning} \cite{chen2022analog} was first introduced to enable the denoising function to refine the previous estimation rather than making a new estimation from scratch for more efficient sampling. 
% % Motivated by this, we propose to use the strategy of selective conditioning on the predicted proposals to make inference faster and better align with training. 
% More specifically, at each time step $t$ the denoising decoder generates an estimate $\Bar{x}^{t}_{0} = f_{\theta}(x_{t},t)$ of $x_{0}$ given only $x_{t}$ as input.  Self-conditioning progressively refines $x_{0}$ estimates by passing the estimate $\Tilde{x}^{t+1}_{0}$ obtained at the previous sampling step as input to the denoising network; The self-conditioned estimate is defined as $\Tilde{x}^{t}_{0} = f_{\theta}(x_{t}, \Tilde{x}^{t+1}_{0},t)$ and sets the diffusion direction.



% Hence, we propose to use 
% selective conditioning to denoise the action queries based on the objective to reach the denoised version faster. 
% To realise this, we replace the self-attention in the decoder $f_{\theta}$ with a similarity based soft-attention which successfully preserves the communication between
% the current time-step noisy proposals and previous time-step query while blocking that between uninformative ones. 

% This approach may be finite but slow to obtain the denoised version. 
% DiffusionDet \cite{chen2022diffusiondet} solves this problem by box-renewal strategy using static thresholds to suppress the unimportant boxes. 
% Instead of manually suppressing undesired predictions, we formulate the model to decide by itself using self-conditioning. In practise, conditioning is performed by concatenating $x_{t}$ and $\Tilde{x}^{t+1}_{0}$ on the feature axis. However, our $x_{t}/\Tilde{x}^{t+1}_{0}$ are discrete bounding proposals in our case. Stacking noisy proposals alone proves to be detrimental in performance (refer to Table xyz). Hence, we propose to use 
% selective conditioning to denoise the action queries based on the objective to reach the denoised version faster. To realise this, we replace the self-attention in the decoder $f_{\theta}$ with a similarity based soft-attention which successfully preserves the communication between
% the current time-step noisy proposals and previous time-step query while blocking that between uninformative ones. 
% Thus the current time-step query gets guided towards the previous time-step desired prediction thus making it faster inference. 
% More specifically, to gather the context of the queries in these two timesteps, we calculate similarity matrix $S \in \mathbb{R^{N \times N}}$ ($N$ is the number of queries) based on the $N$ queries in current time-step $x_{t}$ and $N$ queries of conditioned time-step $x_{t+1}$. Each element of this matrix $A$ represent the cosine-similarity of the same object queries but at different time-step. We construct a set of queries as follows : 
% \begin{align}
%     \varepsilon _{sim} = \{(i,j)|A[i,j] - \gamma > 0 \}
% \end{align}
% where $\gamma \in [-1,1]$ is a preset similarity threshold. To compute which proposal most likely to denoise closer to the next time-step, the temporal IOU overlap of desired proposals will be high. To estimate that, we compute a matrix $B \in \mathbb{R}^{N \times N}$ between the current and reference time-step to obtain :
% \begin{align}
%     \varepsilon _{iou} = \{(i,j)|B[i,j] - \gamma > 0 \}
% \end{align}
% where $i$/$j$ index the queries. As shown in Fig xyz, this simple strategy refines the most probable action query. We can finally, obtain the 
% most similar denoised query set $Q_{c} = (\varepsilon _{iou} / \varepsilon _{sim}) \bigcup Q$. For a query $q_{i}$ , the key and value features can be obtained as $K_{i}/V_{i} = cat(\{k_{j}/v_{j}|(i,j) \in Q_{c}\})$. The query features are then updated by 
% \begin{align}
%     \hat{q}_{i} = softmax(q_{i}K^{T}_{i}).V^{T}_{i}
% \end{align}
%  respectively. This $\hat{q}_{i}$ is the self-conditioned query features with attention weights on selected queries satisfying the condition. 


\begin{figure}[t]
    \centering
    \includegraphics[scale=0.25]{img/DiffTAD_fig3_v2.pdf} 
    \caption{\textbf{Cross-timestep selective conditioning.} At the current time step, noisy query only attends to other queries selectively based on the overlap and similarity with the previously denoised reference proposals/segments. For clarity, LayerNorm, FFN, and residual connection are omitted.}
    \label{fig:sel}
\end{figure}
% After each sampling step, the predicted proposals are categorized into two groups: \emph{desired} and \emph{undesired}. The desired group contains the proposals located close to a corresponding action instance, while the undesired group takes the left. Intuitively, sending the undesired proposals to the next sampling iteration would bring little/no benefit since they are far away from the distribution of corrupted proposals during training. 


% their distribution is not constructed by box corruption in training. 

% To make inference better align with training, we propose to use the strategy of iterative refinement on the predicted proposals. Motivated by self-conditioning \cite{chen2022analog}, iterative refinement can enable the denoising function refine the previous estimation rather than make a new estimation from scratch. In standard diffusion sampling, at each time step $t$ the denoising decoder generates a estimate $\Bar{x}^{t}_{0} = \hat{x}_{0}(x_{t},t,\theta)$ of $x_{0}$ given only $x_{t}$ as input. Self-conditioning progressively refines $x_{0}$ estimates by passing the estimate $\Tilde{x}^{t+1}_{0}$ obtained at the previous sampling step as input to the denoising network; the self conditioned estimate is defined as $\Tilde{x}^{t}_{0} = \hat{x}_{0}(x_{t}, \Tilde{x}^{t+1}_{0},t,\theta)$ and sets the diffusion direction. In practise, conditioning is performed by concatenating $x_{t}$ and $\Tilde{x}^{t+1}_{0}$ on the feature axis. However, our $x_{t}/\Tilde{x}^{t+1}_{0}$ are discrete bounding proposals. Stacking noisy proposals alone proves to be detrimental in performance (refer to Table xyz). This is because , we project the noisy proposals to continuous embeddings and pass as noisy query to denoising decoder. The decoder has a self-attention on top of these queries. However, distinct similar queries are the queries that try to detect different action instances but of similar (or same) action class to current query. Attending to distinct-similar queries can benefit the query $q$ by gathering some background information and cues around $q_{i}$. For example, some actions may occur multiple times in a clip, and attending to each other can increase the confidence of the detection. Similar to React\cite{shi2022react} we consider high context similarity and low temporal overlap as the two important characteristics to filter out desired predictions and drive the denoising process towards the desired predictions. Thus we replace the standard self-attention in Decoder with the Relational Attention  which successfully preserves the communication between
% the current time-step noisy proposals and previous time-step query while blocking that between uninformative ones. Thus the current time-step query gets guided towards the previous time-step desired prediction thus making it faster inference. 
% \noindent \textbf{Relational self-conditioning} 

% To approximate the inference behavior at train time while remaining computationally efficient, we compute a first estimate $\Bar{x}^{t}_{0} = \hat{x}_{0}(x_{t},0,t,\theta)$ with self-conditioning set to zero, then perform a second forward pass using a stop gradient on $\Bar{x}^{t}_{0}$ to obtain $\Tilde{x}^{t}_{0} = \hat{x}_{0}(x_{t},\Bar{x}^{t}_{0},t,\theta)$. The denoising network is then optimized using the output from two forward passes in order to estimate $x_{0}$ accurately with and without self-conditioning.

% Borrowed from Sparse R-CNN [81],
% the detection decoder takes as input a set of proposal proposals
% to crop RoI-feature [33, 66] from feature map generated by
% image encoder, and sends these RoI-features to detection
% head to obtain box regression and classification results. Following [10,81,102], our detection decoder is composed of 6
% cascading stages. The differences between our decoder and
% the one in Sparse R-CNN are that (1) DiffusionDet begins
% from random proposals while Sparse R-CNN uses a fixed set
% of learned proposals in inference; (2) Sparse R-CNN takes as
% input pairs of the proposal proposals and its corresponding proposal feature, while DiffusionDet needs the proposal proposals
% only; (3) DiffusionDet re-uses the detector head in iterative
% sampling steps and the parameters are shared across different steps, each of which is specified to the diffusion process
% by timestep embedding [35, 86], while Sparse R-CNN uses
% the detection decoder only once in the forward pass.

% \paragraph{TAD head}
% The resultant action queries $F_{d}$ are then decoded using three parallel heads namely (1) \textit{action classification head}, (2) \textit{action localization head} and (3) \textit{completeness head} respectively. The first estimates the probability of a particular action within the action proposal. The second estimates the start, end and IOU overlap between the proposals. The third estimates the quality of predicted action proposals. 

\subsection{Training}
During training, we first construct the diffusion process that corrupts the ground-truth proposals to noisy proposals.
We then train the model to reverse this noising process. Please refer to Algorithm~\ref{alg:train} for more details.

\begin{algorithm}[h]
\small
\caption{\small DiffTAD Training 
}
\label{alg:train}
\algcomment{\fontsize{7.2pt}{0em}\selectfont \texttt{alpha\_cumprod(t)}: cumulative product of $\alpha_i$, \ie, $\prod_{i=1}^t \alpha_i$
}
\definecolor{codeblue}{rgb}{0.25,0.5,0.5}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codebluenew}{RGB}{52, 70, 235}
\definecolor{codekw}{RGB}{207,33,46}
\lstset{
  backgroundcolor=\color{white},
  basicstyle=\fontsize{7.5pt}{7.5pt}\ttfamily\selectfont,
  columns=fullflexible,
  breaklines=true,
  captionpos=b,
  commentstyle=\fontsize{7.5pt}{7.5pt}\color{codebluenew},
  keywordstyle=\fontsize{7.5pt}{7.5pt}\color{codekw},
  escapechar={|}, 
}
\begin{lstlisting}[language=python]
def train(video_feat, gt_proposals):

  # Encode image features
  feats = video_encoder(video_feat)

  # Signal scaling
  pb = (pb * 2 - 1) * scale  

  # Corrupt gt_proposals
  t = randint(0, T)|~~~~~~~~~~~|# time step
  eps = normal(mean=0, std=1)  # noise: [B, N, 2]
  
  pb_crpt = sqrt(|~~~~|alpha_cumprod(t)) * pb + 
              |~|sqrt(1 - alpha_cumprod(t)) * eps

  # Project to continuous embedding
  pb_crpt = project(pb_crpt) # query : [B, N, D]
              
  # Calculate Self-condition estimate
  pb_pred = zeros_like(pb_crpt)
  if self_cond and uniform(0,1) > 0.7:
    pb_pred = decoder(pb_crpt, pb_pred, feats, t)
    pb_pred = stop_gradient(pb_pred)
  
  # Predict
  pb_pred = decoder(pb_crpt, pb_pred, feats, t)

  # Set prediction loss
  loss = set_prediction_loss(pb_pred, gt_proposals)
  
  return loss
\end{lstlisting}
\end{algorithm}

\paragraph{Proposal corruption.}
We add Gaussian noises to the ground truth action proposals. The noise scale is controlled by $\alpha_{t}$~(in Eq.~\eqref{eq:noise_process}), which adopts the monotonically decreasing cosine schedule in different timestep $t$, following~\cite{nichol2021improved}. Notably, the ground truth proposal coordinates need to be scaled as well since the signal-to-noise ratio has a significant effect on the performance of diffusion model~\cite{chen2022generalist}. We observe that TAD favors a relatively lower signal scaling value than object detection \cite{chen2022diffusiondet} (see Table \ref{tab:snr}).
%and image generation task~\cite{ho2020denoising, dhariwal2021diffusion, chen2022analog}. 
More discussions are given in Supplementary. 


\paragraph{Training losses.}
The detection detector takes as input $N_{train}$ corrupted proposals and predicts $N_{train}$ predictions each including the category classification, proposal coordinates, and IOU regression. We apply the set prediction loss~\cite{carion2020end, sun2021sparse, zhu2021deformable} on the set of $N_{train}$ predictions. We assign multiple predictions to each ground truth by selecting the top $k$ predictions with the least cost by an optimal transport assignment method~\cite{ge2021ota, ge2021yolox, wu2022defense, du20211st}. 

\subsection{Inference}\label{sec:inference}

% The inference procedure of \modelname{} is a denoising sampling process from noises to action proposals. 
In inference, starting from noisy proposals sampled in Gaussian distribution, the model progressively refines the predictions as illustrated in Algorithm~\ref{alg:sample}.

\begin{algorithm}[t]
    \small
\caption{\small DiffTAD Sampling 
}
\label{alg:sample}
\algcomment{\fontsize{7.2pt}{0em}\selectfont \texttt{linespace}: generate evenly spaced values
}
\definecolor{codeblue}{rgb}{0.25,0.5,0.5}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codebluenew}{RGB}{52, 70, 235}
\definecolor{codekw}{rgb}{0.85, 0.18, 0.50}
\lstset{
  backgroundcolor=\color{white},
  basicstyle=\fontsize{7.5pt}{7.5pt}\ttfamily\selectfont,
  columns=fullflexible,
  breaklines=true,
  captionpos=b,
  commentstyle=\fontsize{7.5pt}{7.5pt}\color{codebluenew},
  keywordstyle=\fontsize{7.5pt}{7.5pt}\color{codekw},
  escapechar={|}, 
}
\begin{lstlisting}[language=python]
def infer(video_feat, steps, T):
  
  # Encode video features
  feats = video_encoder(video_feat)

  # noisy proposals: [B, N, 2]
  pb_t = normal(mean=0, std=1)

  # noisy embeddings: [B, N, D]
  pb_t = project(pb_t) 
  
  pb_pred = zeros_like(pb_t)

  # uniform sample step size
  times = reversed(linespace(-1, T, steps))
  
  # [(T-1, T-2), (T-2, T-3), ..., (1, 0), (0, -1)]
  time_pairs = list(zip(times[:-1], times[1:])

  for t_now, t_next in zip(time_pairs):
    # Predict pb_0 from pb_t
    if not self_cond:
        pb_pred = zeros_like(pb_t)
    pb_pred = decoder(pb_t, pb_pred, feats, t_now)
    
    # Estimate pb_t at t_next
    pb_t = ddim_step(pb_t, pb_pred, t_now, t_next)
 
  return pb_pred
\end{lstlisting}

\end{algorithm}

% The inference procedure of DiffTAD is a denoising sampling process from noises to action proposals. Starting from noisy proposals sampled in Gaussian distribution, the model progressively refines the predictions (see Algorithm \ref{alg:sample}).


% \subsection{Inference}








\paragraph{Sampling step.}
At each sampling step, the random or estimated proposals from the last sampling step are first projected into the continuous query embeddings and sent into the detection decoder to predict the category, proposal IOU and proposal coordinates. After obtaining the proposals of the current step, DDIM~\cite{song2021denoising} is adopted to estimate the proposals for the next step. 

\paragraph{Proposal prediction.}  
DiffTAD has a simple proposal generation pipeline without post-processing (\eg, non-maximum suppression).
% as DETR \cite{lin2021detr,liu2022dabdetr}. 
To make a reliable confidence estimation for each proposal, we fuse the action classification
score $p_{bc}$ and completeness score $p_{c}$ for each proposal with
a simple average to obtain the final proposal score $p_{sc}$. 
%
%
% The resulted final proposal set is directly evaluated without any post-processing.




\subsection{Remarks}

\paragraph{One model multiple trade-offs.}
Once trained,
\modelname{} works under multiple settings with a varying number of proposals and sampling steps during inference (Fig.~\ref{fig:properties}(b)). 
In general, better accuracy can be obtained using more proposals and more steps.
Thus, a single \modelname{} can realize a number of trade-off needs between speed and accuracy.


% The main properties of DiffTAD lie on \emph{once training for all inference cases}. Once the model is trained, it can be used with changing the number of proposals and number of sample steps in inference, as shown in Figure~\ref{fig:once_for_all}. DiffTAD can achieve better accuracy by using more proposals or/and more refining steps at the cost of higher latency.
% Therefore, we can deploy a single DiffTAD to multiple scenarios and obtain a desired speed-accuracy trade-off without re-training the network.

\paragraph{Faster convergence.}
% 
DETR variants suffer generally slow convergence \cite{liu2022dabdetr} due to two reasons.
First, inconsistent updates of the anchors, the objective for the object queries to learn, would make the optimization of target boundaries difficult.
Second, the ground truth assignment using a dynamic process (\eg, Hungarian matching) is unstable due to both the nature of discrete bipartite matching and the stochastic training process. For instance, a small perturbation with the cost matrix might cause enormous matching and inconsistent optimization.
%
Our \modelname{} takes a denoising strategy 
that makes learning easier.
% without bipartite matching, making the boundary learning easier.
% As this bypasses bipartite matching. 
More specifically, each query is designed as a proposal proxy, a noised query, that can be regarded as a good anchor due to being close to a ground truth. 
%
% Our query denoising task thus has a definite optimization objective which is 
%
With the ground truth proposal as a definite optimization objective,
the ambiguity brought by Hungarian matching can be well suppressed. 
%
We validate that our query denoising based \modelname{} converges more stably than DiffusionDet \cite{chen2022diffusiondet} based Baseline-I (Fig.~\ref{fig:properties}(a)), whilst achieving superior performance (Table \ref{tab:sota}).




% We view the training process of DETR-like models as two stages, learning good anchors and learning relative offsets. Decoder queries are responsible for learning anchors as shown in previous works \cite{liu2022dabdetr}. The inconsistent update of anchors can make it difficult to learn start/end points. DETR turns ground truth assignment to a dynamic process, which brings in an instability problem due to its discrete bipartite matching and the stochastic training process. There are works \cite{?} showing that Hungarian matching does not result in a stable matching since blocking pairs exist. A small change of the cost matrix may cause an enormous change in the matching result, which will further lead to inconsistent optimization goals for decoder queries. 

% Therefore, in our method,  we leverage a denoising task as a shortcut to make relative action start/end point  learning easier, as the denoising task bypasses bipartite matching. Since we interpret each decoder query as a 2-D anchor proposals, a noised query can be regarded as a good anchor which has a corresponding ground truth proposal nearby. The query denoising thus has a clear optimization goal - to predict the original  proposal, which essentially avoids the ambiguity brought by Hungarian matching. This is more visible when we observe the plots in Fig xyz where our model using the query denoising converges faster than the Baseline-II and also in terms of performance it brings clear improvement as shown in Table 1.

\begin{figure}[t]
    \centering
    \includegraphics[scale=0.26]{img/remarks_v3.png} 
    \caption{\textbf{Properties of \modelname.}
    (a) Our proposed model converges more stably during training. 
    (b) Its performance increases with the number of queries (20/50/100) and also with the sampling steps, with a clear margin over the Baseline (B-20/50/100).
    Dataset: THUMOS.}
    \label{fig:properties}
\end{figure}

\paragraph{Better sampling.}
We evaluate \modelname{} under a varying number of (10/50/100) random proposals by increasing the sampling steps from 1 to 30.
As shown in Table~\ref{tab:sota}, under all three settings, \modelname{} yields steady performance gains from more steps consumed. In particular, in the case of fewer random proposals, often \modelname{} can achieve larger gains than DiffusionDet \cite{chen2022diffusiondet}.
For example, in the case of 50 proposals,
the mAP of \modelname{} boosts the avg mAP from 64.9\%~(1 step) to 68.5\%~(5 steps), \ie, an absolute gain of 3.6\% avg mAP. 
Unlike object detection, we find TAD benefits little from increasing the number of proposals.
One intuitive reason is that positive samples are less in TAD than in object detection. 
Compared to the previous two-stage refinement of discriminative learning based TAD models \cite{tan2021relaxed}, our gain is also more decent ({{0.8\% {\em vs.} 4.2\% (10 steps)}}).
This is because it lacks a principled iterative inference ability as in diffusion models.






% Due to the direct proposal generation scheme in our DiffTAD like DETR \cite{lin2021detr,liu2022dabdetr}, we follow a simple proposal generation pipeline without post-processing methods as non-maximum suppression, that are widely used in previous methods \cite{lin2019bmn,xu2020g}. More specifically, to make a reliable confidence estimation for each proposal, we fuse the action classification
% score $p_{bc}$ and completeness score $p_{c}$ for each proposal with
% a simple average to obtain the final proposal score $p_{sc}$. The resulted final proposal set is directly evaluated without any post-processing method.
% We note that sending the predicted proposals without DDIM to the next step is also an optional progressive refinement strategy. However, it brings significant deterioration, as discussed in Section 4.3.


% we propose the strategy of \emph{proposal renewal} to revive these undesired proposals by replacing them with random proposals.
% Specifically, we first filter out undesired proposals with scores lower than a particular threshold. Then, we concatenate the remaining proposals with new random proposals sampled from a Gaussian distribution.  


% \paragraph{Once-for-all.}
% Thanks to the random proposals design, we can evaluate DiffTAD with an arbitrary number of random proposals and the number of sampling steps, which do not need to be equal to the training stage. As a comparison, previous approaches~\cite{carion2020end, zhu2021deformable, sun2021sparse} rely on the same number of processed proposals during training and evaluation, and their detection decoders are used only once in the forward pass.

\begin{table*}[t]
\caption{Performance comparison with the state-of-the-art methods.
Metrics: mAP at different IoU thresholds, and average mAP in {[}0.3 : 0.1 : 0.7{]} on THUMOS14 and {[}0.5 : 0.05 : 0.95{]} on ActivityNet-v1.3.}
% \label{tab:sota}
\label{tab:sota}
\centering
\begin{tabular}{clccccccccccc}
\hline
\multicolumn{1}{c|}{}                                        & \multicolumn{1}{l|}{}                                  & \multicolumn{1}{c|}{}                                   & \multicolumn{6}{c|}{\textbf{THUMOS}}                                                                                                                                                                                  & \multicolumn{4}{c}{\textbf{ActivityNet}}                                                                                               \\ \cline{4-13} 
\multicolumn{1}{c|}{\multirow{-2}{*}{\textbf{Models}}}       & \multicolumn{1}{l|}{\multirow{-2}{*}{\textbf{Design}}} & \multicolumn{1}{c|}{\multirow{-2}{*}{\textbf{Feature}}} & \textbf{0.3}               & \textbf{0.4}               & \textbf{0.5}               & \textbf{0.6}               & \multicolumn{1}{c|}{\textbf{0.7}}               & \multicolumn{1}{c|}{\textbf{Avg}}               & \textbf{0.5}               & \textbf{0.75}              & \multicolumn{1}{c|}{\textbf{0.95}}              & \textbf{Avg}               \\ \hline
\multicolumn{13}{c}{\bf \em Discriminative learning based models}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \\ \hline
\multicolumn{1}{c|}{TAL-Net \cite{chao2018rethinking}}                                     & \multicolumn{1}{l|}{2-stage}                           & \multicolumn{1}{c|}{I3D}                                &  53.2                       & 48.5                       & 42.8                        & 33.8                       & \multicolumn{1}{c|}{20.8}                       & \multicolumn{1}{c|}{-}                       &  38.2                       & 18.3 & \multicolumn{1}{c|}{ 1.3}                        & 20.2                       \\
\multicolumn{1}{c|}{BMN \cite{lin2019bmn}}                                     & \multicolumn{1}{l|}{2-stage}                           & \multicolumn{1}{c|}{TSN}                                & 56.0                       & 47.4                       & 38.8                       & 29.7                       & \multicolumn{1}{c|}{20.5}                       & \multicolumn{1}{c|}{38.5}                       & 50.1                       & 34.8                       & \multicolumn{1}{c|}{8.3}                        & 33.9                       \\
\multicolumn{1}{c|}{GTAD \cite{xu2020g}}                                    & \multicolumn{1}{l|}{2-stage}                           & \multicolumn{1}{c|}{TSN}                                & 54.5                       & 47.6                       & 40.3                       & 30.8                       & \multicolumn{1}{c|}{23.4}                       & \multicolumn{1}{c|}{39.3}                       & 50.4                       & 34.6                       & \multicolumn{1}{c|}{9.0}                        & 34.1                       \\
\multicolumn{1}{c|}{RTD-Net \cite{tan2021relaxed}}                                 & \multicolumn{1}{l|}{2-stage}                           & \multicolumn{1}{c|}{I3D}                                & 68.3                       & 62.3                       & 51.9                       & 38.8                       & \multicolumn{1}{c|}{23.7}                       & \multicolumn{1}{c|}{-}                          & 47.2                       & 30.7                       & \multicolumn{1}{c|}{8.6}                        & 30.8                       \\
\multicolumn{1}{c|}{TCANet \cite{qing2021temporal}}                                  & \multicolumn{1}{l|}{2-stage}                           & \multicolumn{1}{c|}{I3D}                                & 60.6                       & 53.2                       & 44.6                       & 36.8                       & \multicolumn{1}{c|}{26.7}                       & \multicolumn{1}{c|}{44.3}                       & 52.3                       & 36.7                       & \multicolumn{1}{c|}{6.9}                        & 35.5                       \\
\multicolumn{1}{c|}{MUSES \cite{liu2021multi}}                                   & \multicolumn{1}{l|}{2-stage}                           & \multicolumn{1}{c|}{I3D}                                & 68.9                       & 64.0                       & 56.9                       & 46.3                       & \multicolumn{1}{c|}{31.0}                       & \multicolumn{1}{c|}{}                          & 50.0                       & 35.0                       & \multicolumn{1}{c|}{6.6}                        & 34.0                       \\
\multicolumn{1}{c|}{ContextLoc \cite{zhu2021enriching}}                              & \multicolumn{1}{l|}{2-stage}                           & \multicolumn{1}{c|}{I3D}                                & 68.3                       & 63.8                       & 54.3                       & 41.8                       & \multicolumn{1}{c|}{26.2}                       & \multicolumn{1}{c|}{50.9}                       & 56.0                       & 35.2                       & \multicolumn{1}{c|}{3.6}                        & 34.2                       \\
\multicolumn{1}{c|}{RCL \cite{wang2022rcl}}                                    & \multicolumn{1}{l|}{2-stage}                           & \multicolumn{1}{c|}{I3D}                                & 70.1                        & 62.3                        & 52.9                        & 42.7                        & \multicolumn{1}{c|}{30.7}                       & \multicolumn{1}{c|}{57.1}                       & 51.7                         & 35.2                       & \multicolumn{1}{c|}{8.0}                        & 34.4                       \\
\multicolumn{1}{c|}{React \cite{shi2022react}}                                   & \multicolumn{1}{l|}{1-stage}                           & \multicolumn{1}{c|}{I3D}                                & 69.2                       & 65.0                       & 57.1                       & 47.8                       & \multicolumn{1}{c|}{35.6}                       & \multicolumn{1}{c|}{55.0}                       & 49.6                       & 33.0                       & \multicolumn{1}{c|}{8.6}                        & 32.6                       \\
\multicolumn{1}{c|}{TAGS \cite{nag2022gsm}}                                   & \multicolumn{1}{l|}{1-stage}                           & \multicolumn{1}{c|}{I3D}                                & 68.6                        & 63.8                        & 57.0                        & 46.3                        & \multicolumn{1}{c|}{31.8 }                       & \multicolumn{1}{c|}{52.8 }                       & \bf{56.3}                        & 36.8                        & \multicolumn{1}{c|}{\bf{9.6} }                        & \bf{36.5}                       \\ 
\multicolumn{1}{c|}{ActionFormer \cite{zhang2022actionformer}}                            & \multicolumn{1}{l|}{1-stage}                           & \multicolumn{1}{c|}{I3D}                                & 82.1                       & 77.8                       & 71.0                       & 59.4                       & \multicolumn{1}{c|}{43.9}                       & \multicolumn{1}{c|}{66.8}                       & 53.5                       & 36.2                       & \multicolumn{1}{c|}{8.2}                        & 35.6                       \\ \hline
\multicolumn{13}{c}{\bf\em Generative learning based models}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \\ \hline
\multicolumn{1}{c|}{Baseline(1-step)}                                & \multicolumn{1}{l|}{2-stage}                           & \multicolumn{1}{c|}{I3D}                                & 65.2                          & 61.3                          & 55.4                          & 44.6                         & \multicolumn{1}{c|}{35.5}                         & \multicolumn{1}{c|}{52.4}                         & 48.5                         & 31.4                         & \multicolumn{1}{c|}{8.6}                         & 31.5                         \\

\multicolumn{1}{c|}{Baseline(5-step)}                                & \multicolumn{1}{l|}{2-stage}                           & \multicolumn{1}{c|}{I3D}                                & 69.1                         & 65.7                         & 60.2                         & 47.1                         & \multicolumn{1}{c|}{36.4}                         & \multicolumn{1}{c|}{55.7}                         & 50.2                         & 32.3                         & \multicolumn{1}{c|}{8.9}                         & 32.2                         \\
\multicolumn{1}{c|}{Baseline(10-step)}                                & \multicolumn{1}{l|}{2-stage}                           & \multicolumn{1}{c|}{I3D}                                & 70.0                         & 66.5                         & 60.6                         & 47.5                         & \multicolumn{1}{c|}{36.9}                         & \multicolumn{1}{c|}{56.3}                         & 51.0                         & 32.9                         & \multicolumn{1}{c|}{9.0}                         & 32.4                         \\
\hline
\multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB} {\bf DiffTAD}(1-step)} & \multicolumn{1}{l|}{\cellcolor[HTML]{CBCEFB} 1-stage}                           & \multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}I3D}        & \cellcolor[HTML]{CBCEFB}68.7 & \cellcolor[HTML]{CBCEFB}66.8 & \cellcolor[HTML]{CBCEFB}64.7 & \cellcolor[HTML]{CBCEFB}\bf{61.2} & \multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}\bf{57.3}} & \multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}63.8} & \cellcolor[HTML]{CBCEFB}52.4 & \cellcolor[HTML]{CBCEFB}35.6 & \multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}8.8} & \cellcolor[HTML]{CBCEFB}34.8 \\ 
\multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}{\bf DiffTAD}(5-step)} & \multicolumn{1}{l|}{\cellcolor[HTML]{CBCEFB} 1-stage}                           & \multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}I3D}        & \cellcolor[HTML]{CBCEFB}73.4 & \cellcolor[HTML]{CBCEFB}71.5 & \cellcolor[HTML]{CBCEFB}69.9 & \cellcolor[HTML]{CBCEFB}\bf{62.8} & \multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}\bf{58.4}} & \multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}\bf{67.2}} & \cellcolor[HTML]{CBCEFB}55.2 & \cellcolor[HTML]{CBCEFB}\bf{36.8} & \multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}8.9} & \cellcolor[HTML]{CBCEFB}36.0 \\
\multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}{\bf DiffTAD}(10-step)} & \multicolumn{1}{l|}{\cellcolor[HTML]{CBCEFB} 1-stage}                           & \multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}I3D}        & \cellcolor[HTML]{CBCEFB}74.9 & \cellcolor[HTML]{CBCEFB}72.8 & \cellcolor[HTML]{CBCEFB}\bf{71.2} & \cellcolor[HTML]{CBCEFB}\bf{62.9} & \multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}\bf{58.5}} & \multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}\bf{68.0}} & \cellcolor[HTML]{CBCEFB}56.1 & \cellcolor[HTML]{CBCEFB}\bf{36.9} & \multicolumn{1}{c|}{\cellcolor[HTML]{CBCEFB}9.0} & \cellcolor[HTML]{CBCEFB}36.1 \\\hline
\end{tabular}
\end{table*}


\section{Experiments}
\noindent{\bf Datasets.}
We conduct extensive experiments on two popular TAD benchmarks.
(1) \textit{ActivityNet-v1.3}~\cite{caba2015activitynet} has 19,994 videos from 200 action classes. We follow the standard setting %~\cite{lin2018bsn} 
to split all videos into training, validation and testing subsets 
in ratio of 2:1:1.
% THUMOS14~\cite{jiang2014thumos} and ActivityNet1.3~\cite{caba2015activitynet}.
(2) \textit{THUMOS14}~\cite{idrees2017thumos} has 200 validation videos and 213 testing videos from 20 categories with labeled temporal boundary and action class. 


\subsection{Implementation details}

\noindent \textbf{Training schedule.}
% We use two pre-trained video encoders for feature extraction to make fair comparisons with previous methods. 
% One is a fine-tuned two-stream model \cite{lin2019bmn}, with downsampling ratio 16 and stride 2. Each video's feature sequence $F$ is rescaled to $T = 400/800$ snippets for AcitivtyNet/THUMOS using linear interpolation. %For THUMOS14, 
% The other is %are extracted using 
%
For video feature extraction, we use
Kinetics pre-trained I3D model \cite{carreira2017quo,zhang2022actionformer} with a downsampling ratio of 4 and R(2+1)D model \cite{alwassel2020tsp,zhang2022actionformer} with a downsampling ratio of 2. Our model is trained for 50 epochs using Adam optimizer with a learning rate of {$10^{-4}/10^{-5}$ for AcitivityNet/THUMOS respectively. The batch size is set to 40 for ActivityNet and 32 for THUMOS}.
For selective conditioning, we apply the rate of 70\%
during training. %for our best results reported. 
All models are trained with 4 NVIDIA-V100 GPUs. 
% \textcolor{black}{For classification-mask consistency, the threshold $\theta_{m}/\theta_{p}$ is set to $0.5/0.3$ and in top$-k$ to 40}. In testing, 
% we set the threshold set for mask $\Theta=\{0.1\sim 0.9\}$ with step $0.05$. We use the same set of threshold $\Theta$ for mask predictive redundancy during training.

% The ResNet and Swin backbone are initialized with pre-trained weights on ImageNet-1K and ImageNet-21K~\cite{deng2009imagenet}, respectively. The newly added detection decoder is initialized with Xavier init~\cite{glorot2010understanding}. We train \ours using AdamW~\cite{loshchilov2018decoupled} optimizer with the initial learning rate as $2.5\times 10^{-5}$ and the weight decay as $10^{-4}$. All models are trained with a mini-batch size 16 on 8 GPUs. For MS-COCO, the default training schedule is 450K iterations, with the learning rate divided by 10 at 350K and 420K iterations. For LVIS, the training schedule is 210K, 250K, 270K.

% We use two pre-extracted encoders for feature extraction, for fair comparisons with previous methods. 
% % For ActivityNet-v1.3, % One we adopt the
% One is a fine-tuned two-stream model \cite{lin2019bmn}, with downsampling ratio 16 and stride 2. Each video's feature sequence $F$ is rescaled to $T = 800/1024$ snippets for AcitivtyNet/THUMOS using linear interpolation. %For THUMOS14, 
% The other is %are extracted using 
% Kinetics pre-trained I3D model \cite{carreira2017quo} with a downsampling ratio of 5. 
% Our model is trained for 15 epochs using Adam with learning rate of {$10^{-4}/10^{-5}$ for AcitivityNet/THUMOS respectively. The batch size is set to 50 for ActivityNet and 25 for THUMOS}. 
% \textcolor{black}{For classification-mask consistency, the threshold $\theta_{m}/\theta_{p}$ is set to $0.5/0.3$ and in top$-k$ to 40}. In testing, 
% we set the threshold set for mask $\Theta=\{0.1\sim 0.9\}$ with step $0.05$. We use the same set of threshold $\Theta$ for mask predictive redundancy during training.


\noindent \textbf{Testing schedule.}
At the inference stage, the detection decoder iteratively refines the predictions from Gaussian random proposals. By default, we set the total sampling time steps as 10. 
% The predictions at each sampling step are ensembled together by soft-NMS to produce the output. 



% The performance of DiffTAD can be improved not only by solving the hungarian matching bottleneck but also by efficient sampling during inference. We evaluate our approach with 100,200 and 300 random action proposals by increasing the iterative steps from 1 to 15. The results are presented in Table xyz.  We see that \modelname with these three settings all have steady performance gains with more refining steps. Besides, \modelname with fewer random proposals tends to have a larger gain with refinement than DiffDet \cite{chen2022diffusiondet}.
% For example, the mAP of \modelname{} instance with 100 random proposals increases from 42.4~(1 step) to 45.9~(9 steps), an absolute 3.5 AP improvement. However, unlike object detection, action detection does not tend to benefit by increasing the number of proposals as the number of positive samples is less in TAD than object detection thus there is misclassification. In comparison, we find that previous approaches~\cite{tan2021relaxed} uses a two-stage refinement module and the gain obtained by refinement is far less than ours. This is possible as they can only use the decoder once. Using two or more iteration steps will drop the performance. 
% do not have this refinement property. They can use the detection decoder only once. Using two or more iteration steps will drop the performance. 


% number of random proposals but by iterating more steps. We evaluate \ours with 100, 300, and 500 random proposals by increasing their iterative steps from 1 to 9. The results are presented in . We see that \ours with these three settings all have steady performance gains with more refining steps. Besides, \ours with fewer random proposals tends to have a larger gain with refinement. For example, the AP of \ours instance with 100 random proposals increases from 42.4~(1 step) to 45.9~(9 steps), an absolute 3.5 AP improvement. This accuracy performance is comparable with 45.0~(1 step) of 300 random proposals and 45.5~(1 step) of 500, showing that high accuracy in \ours could be achieved by either increasing the number of proposal proposals or the iterative steps.

% In comparison, we find that previous approaches~\cite{carion2020end, zhu2021deformable, sun2021sparse}  do not have this refinement property. They can use the detection decoder only once. Using two or more iteration steps will drop the performance. 
% More detailed comparison can be found in~\Cref{sec:app_refine}.

 
% \begin{figure}
%     \centering
%     \includegraphics[scale=0.27]{iccv2023AuthorKit/img/diffusion_AR.png} 
%     \caption{\textbf{Proposal Generation performance} Proposals generated by our (b) DiffTAD performs superior to (a) Baseline and converges in less number of epochs.}
%     \label{fig:proposal}
% \end{figure}






\subsection{Main results}
\paragraph{Competitors.} 
We compare our \modelname{} with the state-of-the-art non-generative approaches including BMN \cite{lin2019bmn}, GTAD \cite{xu2020g}, React \cite{shi2022react} and ActionFormer \cite{zhang2022actionformer}. 
% Since tackling TAD as a generative task is new, we created a new baseline to compare with our method. 
Further, we adapt the object detection counterpart DiffusionDet \cite{chen2022diffusiondet} 
to a two-stage generative TAD method, termed as \texttt{Baseline}. 

\paragraph{Results on THUMOS.}
We make several observations from Table \ref{tab:sota}:
% Similar conclusions can be drawn in general on THUMOS from Table \ref{tab:sota}. 
(1) Our {\modelname} achieves the best result,
% When using I3D features, 
% {\modelname} achieves the best results, 
surpassing strong discriminative learning based competitors like TCANet \cite{wang2021temporal} and ActionFormer \cite{zhang2022actionformer} by a clear margin. 
This suggests the overall performance advantage of our model design and generative formulation idea.
(2) Importantly, \modelname{} excels on the alternative generative learning design (\ie, \texttt{Baseline}),
validating the superiority of our diffusion-based detection formulation.
%
For both generative models, more sampling steps lead to higher performance.
%
This concurs with the general property of diffusion models.
% of xx\%.
% There are some noticeable differences:
% We find that I3D is now much more effective in THUMOS, compared with ActivityNet. This is mostly likely caused by the distinctive characteristics of the two datasets in terms of action instance duration and video length.
% (2) Our method achieves the state-of-the-art beating the strongest competitor Actionformer in 5 steps.
% in only 0.6 and 0.7 mAP. 
(3) In particular, our model achieves significantly stronger results in stricter IOU metrics (\eg, IOU@0.5/0.6/0.7), as compared to all the other alternatives. This demonstrates the potential of generative learning in tackling the action boundary often with high ambiguity, and the significance of proper diffusion design.
% as seen in the comparison to 2-stage baseline.
% verifying the effectiveness of our diffusion based pipeline.

\paragraph{Results on ActivityNet.}
Similar observations can be drawn in general on ActivityNet from Table \ref{tab:sota}.
We further highlight several differences:
(1) Indeed, overall our \modelname{} is not the best performer, with a slight edge underneath TAGS \cite{nag2022gsm}.
However, we note that all other DETR style methods (\eg, RTD-Net) are significantly inferior. 
%
This means that our method has already successfully filled up the most performance disadvantage of the DETR family.
% to the others (\eg, ActionFormer),
% our {\modelname} still achieves the best result \textcolor{blue}{in stricter metric of mAP@0.75 and 2nd best to best single stage model (\eg TAGS) by 0.5\% in avg mAP}.
% This indicates that 
We attribute this result to our design choice of denoising in the query space and cross-timestep selective conditioning.
% turns out to be particularly effective in dealing with long action instances, which has never been achieved by this family of detectors before.
%
That being said, our formulation in exploiting the DETR architecture for TAD
is superior than all prior attempts.
% in average mAP, although being simpler in architecture design than most existing alternatives. 
% This validates the over design advantage of our formulation.
% This validates our assumption that with proper global context modeling, explicit proposal generation is not only redundant but also less effective. 
(2) %Being a single-stage generative model, {\modelname} can efficiently surpass both the existing 1-stage and 2-stage alternatives often by a large margin. 
Compared to the generative competitor (\ie, \texttt{Baseline}),
our model is not only more stable to converge (Fig. \ref{fig:properties}(a)),
but also yields a margin of 3.7\%
(smaller than that on THUMOS as this is a more challenging test for the DETR family in general).
% Even for generative baselines, it converges faster(in 3 steps) and is better than Baseline-I by 3.7\%. 
%
% \textcolor{black}{(3) Compared to RTD-Net
% also employing a DETR style architecture,
% % which employs an architecture similar to object detection Transformers, 
% our {\modelname} is significantly superior. This validates the advantage of our formulation in exploiting the Transformer for TAD.}




\subsection{Ablation study}
We conduct ablation experiments on THUMOS to study \modelname{} in detail. 
In all experiments, %use I3D features and 
we use 30 proposals for training and inference,
unless specified otherwise.
% without further specification.
% \paragraph{2-stage vs 1-stage}



\paragraph{Cross-timestep selective conditioning.} 
We examine the effect of the proposed selective conditioning
for proposal refinement (Section \ref{sec:difftad}).
%
To that end, we vary the rate/portion of proposals per batch at which selective conditioning is applied during training.
%
The case of 0\% training rate means {\em no conditioning}.
%
Note, during inference selective conditioning is always applied to all the proposals (\ie, 100\% test rate).
%
As demonstrated in Fig.~\ref{fig:selfc}(b), we observe a clear correlation between conditioning rate and sampling quality (\ie, mAP), validating the importance of our selective conditioning in refining proposals for enhanced denoising.

Additionally, we compare with two different refinement designs:
(1) {\em Feature concatenation} as in self-conditioning \cite{chen2022analog},
and
(2) {\em Proposal renewal} as in DiffusionDet \cite{chen2022diffusiondet}.
% of selective conditioning at training time. A rate of 0 denotes the special case where no conditioning is
% used (for training nor inference), while a rate $>$ 0 (\eg, 0.7) means that conditioning is used for 70\% of each batch of training tasks (and always used at inference). 
% As demonstrated in Fig.~\ref{fig:selfc}(b), there is a clear correlation between conditioning rate and sample quality (\ie, mAP), validating the importance using latent conditioning to provide context for enhanced routing.
% Additionally, we can also
We observe from Table~\ref{tab:selcond} that our selective conditioning is superior to both alternatives,
verifying our design idea.

% choice than plain concat or box renewal strategies as followed by standard approaches.

% We study the effect of the rate of selective conditioning at training time. A rate of 0 denotes the special case where no conditioning is
% used (for training nor inference), while a rate $>$ 0 (\eg, 0.7) means that conditioning is used for 70\% of each batch of training tasks (and always used at inference). As demonstrated in Fig~\ref{fig:selfc}(b), there is a clear correlation between conditioning rate and sample quality (\ie, mAP), validating the importance using latent conditioning to provide context for enhanced routing. We use a rate of 0.7 for our best results reported. Additionally, we can also observe from Table~\ref{tab:selcond} that selective conditioning is a better choice than plain concat or box renewal strategies as followed by standard approaches.

% We study the effect of the rate of self-conditioning at training time. A rate of 0 denotes the special case where no self-conditioning is
% used (for training nor inference), while a rate $>$ 0 e.g. 0.7 means that self-conditioning is used for 70\% of each batch of training tasks (and always used at inference). 

% As demonstrated in Figure 7a, there is a clear correlation between self-conditioning rate and sample quality (i.e., mAP), validating the importance using latent self-conditioning to provide context for enhanced routing. We use a rate of 0.7 for our best results reported. Additionaly, we can also observe from Tab xyz that attentive conditioning is a better choice than plain concat as followed by standard approaches.


\begin{table}[t]
\centering
\caption{\textbf{Proposal refinement design.} 
Dataset: THUMOS.
% Selective conditioning works best for proposal refinement than other alternatives.
}
\label{tab:selcond}
\begin{tabular}{c|cccc}
\hline
                                             & \multicolumn{4}{c}{\textbf{mAP}}                                                                      \\ \cline{2-5} 
\multirow{-2}{*}{\textbf{Design}} & \textbf{0.3} & \textbf{0.5} & \multicolumn{1}{c|}{\textbf{0.7}}                        & \textbf{Avg} \\ \hline
Feature Concatenation \cite{chen2022analog}                                & 71.1           & 66.3           & \multicolumn{1}{c|}{56.5}                                  & 65.9           \\
Proposal Renewal \cite{chen2022diffusiondet}                                & 71.2           & 65.4           & \multicolumn{1}{c|}{54.2}                                  & 65.1
\\ 
\rowcolor[HTML]{EFEFEF} 
\textbf{Selective Condition} (Ours)                          & \textbf{74.9}  & \textbf{71.2}  & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\textbf{58.5}} & \textbf{68.0}  \\ \hline
\end{tabular}
\end{table}




\paragraph{Sampling decomposition.}
We decompose the sampling strategy with \modelname{}
by testing four variants:
(1) {\em No denoising}: No DDIM \cite{song2021denoising} is applied, which means 
the output prediction of the current step is used directly as the input of the next step (\ie, a naive baseline).
(2) {\em Vanilla denoising}: DDIM is applied in the original form.
%
(3) {\em Selective conditioning}:
Only selective conditioning is used but no vanilla denoising.
%
(4) {\em Both vanilla denoising and selective conditioning}:
Our full model.
%
We observe from Table~\ref{tab:samp} that
(1) Without proper denoising, applying more steps 
will cause more degradation, as expected,
because there is no optimized Markovian chain. 
%
(2) Applying vanilla denoising can address the above problem
and improve the performance from multiple sampling accordingly.
However, the performance increase saturates quickly.
%
(3) Interestingly, our proposed selective conditioning 
even turns out to be more effective than vanilla denoising.
%
(4) When both vanilla denoising and selective conditioning are applied (\ie, our full model), the best performances can be achieved, with a clear gain over the either and even improved saturation phenomenon. This suggests that the two ingredients are largely complementary, which is not surprising given their distinctive design nature.  

% or selective conditioning would bring slight benefit at 10 steps and does not bring further improvement from using more steps.
%
% We compare different sampling strategies in Table~\ref{tab:samp}. When evaluating \modelname{} that does not use DDIM, we directly take the output prediction of the current step as input of the next step. 
%
% We found that the mAP of \modelname{} degrades with more evaluation steps when neither DDIM nor selective conditioning is adopted. 
%
% Besides, only using DDIM or selective conditioning would bring slight benefit at 10 steps and does not bring further improvement from using more steps. Moreover, our \modelname{} attains remarkable gains when equipped with both DDIM and selective conditioning. 
% These experiments together verify the importance of both DDIM and proposal selection in sampling.

\begin{table}[t]
\centering
\caption{\textbf{Sampling decomposition} in terms of iterative denoising ({\bf ID}) and selective conditioning ({\bf SC}). Dataset: THUMOS.
% Using both diffusion and selective conditioning works best.
}
\label{tab:samp}
\begin{tabular}{c|c|c|c|c}
\hline
\textbf{ID} & \textbf{SC} & \textbf{step 1} & \textbf{step 5} & \textbf{step 10} \\ \hline
\xmark            & \xmark                    & 62.7              & 62.9              & 61.3              \\
\cmark           & \xmark                    & 62.7              & 65.0              & 64.9              \\
\xmark            & \cmark                   & 62.7              & 65.7              & 65.6              \\ \hline
\rowcolor[HTML]{EFEFEF} 
\cmark           & \cmark                   & 62.7              &\bf 67.2              &\bf 68.0              \\ \hline
\end{tabular}
\end{table}












\paragraph{Signal scaling.}
The signal scaling factor (Eq.~\eqref{eq:noise_process}) controls the signal-to-noise ratio~(SNR) of the denoising process. 
We study the influence of this facet in \modelname{}.
As shown in Table~\ref{tab:snr}, the scaling factor of 0.5 achieves the optimal performance.
This means this setting is task-specific at large (\eg, %outperforming the factor of 0.1 optimal for 
the best choice is 2.0 for object detection 
\cite{chen2022diffusiondet}).
% panoptic segmentation is 0.1 instead~\cite{chen2022generalist}. 
%
% The proposal representation is more fragile than image (\eg, panoptic segmentation~\cite{chen2022analog}). 
% Additionally, the action proposals are fewer than bounding boxes in object detection \cite{chen2022diffusiondet}. 
% Therefore, \modelname{} prefers an easier training objective with a slightly low signal-to-noise ratio, compared to image generation and panoptic segmentation. 
% The proposal representation is more fragile than the dense representation, \eg, $512\times 512$ mask presentation in panoptic segmentation~\cite{chen2022analog}.
% Therefore, \ours prefers an easier training objective with an increased signal-to-noise ratio compared to image generation and panoptic segmentation.

\begin{table}[t]
\centering
\caption{\textbf{Signal-noise ratio} under a variety of different 
scaling factors. Dataset: THUMOS.
% A small scaling factor can enhance the performance.
}
\label{tab:snr}
\begin{tabular}{c|cccc}
\hline
                                 & \multicolumn{4}{c}{\textbf{mAP}}                                                                      \\ \cline{2-5} 
\multirow{-2}{*}{\textbf{Scale}} & \textbf{0.3} & \textbf{0.5} & \multicolumn{1}{c|}{\textbf{0.7}}                        & \textbf{Avg} \\ \hline
0.1                              & 70.5           & 67.5           & \multicolumn{1}{c|}{57.2}                                  & 66.6           \\
\rowcolor[HTML]{EFEFEF} 
\textbf{0.5}                     & \textbf{74.9}  & \textbf{71.2}  & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\textbf{58.5}} & \textbf{68.0}  \\
1.0                              & 73.2           & 70.6           & \multicolumn{1}{c|}{58.0}                                  & 67.3           \\
2.0                              & 69.9           & 67.3           & \multicolumn{1}{c|}{56.8}                                  & 64.2           \\ \hline
\end{tabular}
\end{table}

\paragraph{Accuracy vs. speed.}
We evaluate the trade-off between the accuracy and memory cost with  \modelname{}. 
In this test, we experiment with three choices $\{10, 50,100\}$ in the number of proposals.
For each choice, the same is applied to both model training and evaluation consistently.
% keep the number of proposals during evaluation consistent with the training. 
We observe in Table~\ref{tab:speed} that:
(1) Increasing the number of proposals/queries from 30 to 
50 brings about 0.5\% in mAP with %$\sim 3.5x$ 
extra 0.46 % increasing the number of 
GFLOPs, thanks to the proposed selective conditioning.
%
(2) However, further increasing the proposals is detrimental to the model performance. This is because the number of action instances per video is much fewer than that of objects per image on average.
%
(3) With 50 proposals, increasing the sampling steps from 1 to 5 provides an mAP gain of $3.6\%$ with 
an additional cost of 1.9 GFLOPs.
% $\sim$2.5$\times$ extra cost.
A similar observation is with the case of 100 proposals.
% in speed of the model.

% However, we observed that , unlike object detection, increasing the number of proposals further is detrimental to the model performance. 
% This is because the number of action proposals per video is much fewer than in object detection. Increasing the refining step from 1 to 5 provides $3.6\%$ mAP gain with negligible impact in speed of the model.

\begin{table}[]
\centering
\small
\caption{\textbf{Accuracy vs. speed} under a variety of different proposal numbers and sampling steps.
Dataset: THUMOS.}
\label{tab:speed}
\begin{tabular}{c|c|cccc|c}
\hline
                                   &                                 & \multicolumn{4}{c|}{\textbf{mAP}}                                                                     &                                  \\ \cline{3-6}
\multirow{-2}{*}{\textbf{Proposals}} & \multirow{-2}{*}{\textbf{Step}} & \textbf{0.3} & \textbf{0.5} & \multicolumn{1}{c|}{\textbf{0.7}}                        & \textbf{Avg} & \multirow{-2}{*}{\textbf{GFLOPs}} \\ \hline
\cellcolor[HTML]{EFEFEF}30                                 & \cellcolor[HTML]{EFEFEF}5                               & \cellcolor[HTML]{EFEFEF}74.9           & \cellcolor[HTML]{EFEFEF}71.2           & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}58.5}                                  & \cellcolor[HTML]{EFEFEF}68.0           & \cellcolor[HTML]{EFEFEF}0.81                              \\

50                                & 1                               & 69.2           & 65.2           & \multicolumn{1}{c|}{53.0}                                  & 64.9           & 1.27                               \\


\textbf{50}                       & \textbf{5}                      & \textbf{77.2}  & \textbf{73.5}  & \multicolumn{1}{c|}{\textbf{59.1}} & \textbf{68.5}  & \textbf{3.17}                      \\
100                                & 1                               & 70.4           & 66.1           & \multicolumn{1}{c|}{53.8}                                  & 65.1           & 2.18                               \\
100                                & 5                               & 77.1           & 73.8           & \multicolumn{1}{c|}{58.7}                                  & 68.4           & 6.32                               \\
\hline
\end{tabular}
\end{table}

\begin{figure}
    \centering
    \includegraphics[scale=0.238]{img/self_sampling.png} 
    \caption{\textbf{Impact of sampling and selective-conditioning.} (a) The effect of varying sampling steps with Baseline and \modelname{}.
    % are compared over increasing sampling steps. 
    (b) The effect of selective conditioning rate during training \modelname{}.
    Dataset: THUMOS.
    % Performance of \modelname{} is improved if the rate of selective conditioning is kept high.
    }
    \label{fig:selfc}
\end{figure}



% Self-conditioning
% dramatically improves sample quality; the diffusion model gets the low-level structure right and
% generates syntactically correct sentences, even though the global text is not intelligible. Combining
% self-conditioning and pretrained embeddings leads to globally coherent paragraphs that stay on topic
% with proper sentence structure

\paragraph{Decoupled diffusion strategy.} 
We evaluate the impact of feature decoupling (video encoder in Sec. \ref{sec:difftad}). 
Typically, existing TAD methods \cite{xu2020g,lin2019bmn}
use fused RGB and optical flow video features (\ie, early fusion).
However, we take a late fusion strategy where the RGB and flow features are processed separately before their proposals are fused 
(Fig. \ref{fig:decoup}).
%
We contrast the two fusion strategies.
%
It is evident in Table~\ref{tab:fusion}
that with the typical early fusion (\ie, passing early fused features as a condition to our detection decoder),
a drop of $2\%$ in average mAP is resulted.
%
This indicates that due to modal specificity 
there is a need for specific conditional inference,
validating our design consideration.
%
% . Most of the existing TAD  approaches \cite{xu2020g,lin2019bmn} rely on early fusion of video features, however, when we pass early fused features as a condition to our detection decoder, it observes a drop of $2\%$ in avg mAP. However, decoupling the RGB and optical flow features for conditioning the decoder in space-time separately has the best performance as seen in Table~\ref{tab:fusion}. 
For visual understanding, an example is given in Fig.~\ref{fig:fusion} to show how the two features can contribute to TAD in a cooperative manner.
% it can be observed that RGB and Flow denoising can complement each other to improve the overall performance of the detection detector.  

\begin{table}[t]
\centering
\caption{\textbf{Decoupling the denoising.}
RGB and optical flow video features are decoupled for individual denoising (\ie, late fusion),
in contrast to typical early fusion strategy where
the two features are first fused in prior to being processed.
Dataset: THUMOS.
% Decoupling diffusion into RGB and optical flow based conditioning improves performance.
}
\label{tab:fusion}
\begin{tabular}{c|ccc|c}
\hline
\textbf{Decoupling} & \textbf{0.5} & \textbf{0.75} & \textbf{0.95} & \textbf{Avg} \\ \hline
\xmark{}                 & 71.8           & 67.4            & 57.1            & 66.0           \\ \hline
\rowcolor[HTML]{C0C0C0} 
\textbf{\cmark{}}            & \textbf{74.9}  & \textbf{71.2}   & \textbf{58.5}   & \textbf{68.0}  \\ \hline
\end{tabular}
\end{table}
% \end{table}
\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{img/decoupling.pdf} 
     \caption{\textbf{Late fusion example} on a test video from THUMOS. 
     It is observed that RGB and optical flow features are complementarily useful in capturing the ground truth (GT) action instance.}
    % \caption{\textbf{Detection result of Space-Time denoising} The RGB conditioned denoiser is much noiser than Flow conditioned prediction. However, late-fusing them compensates for one another.}
    \label{fig:fusion}
\end{figure}
% \paragraph{Choice of encoder and decoder}

\paragraph{NMS-free design.} 
As shown in Table~\ref{tab:snms}, when comparing DiffTAD with and without non-maximum suppression (NMS), we observe similar results. NMS is not necessary in DiffTAD because the predictions are relatively
sparse and minor overlapped with our cross-step conditional strategy (Sec.~\ref{sec:difftad}). In contrast, existing non-generative TAD works like BMN \cite{lin2019bmn} and GTAD \cite{xu2020g} generate highly overlapped proposals with similar confidence. Thus, NMS becomes necessary
% for these non generative dense proposal generators 
to suppress redundant proposals. 
\begin{table}[t]
\centering
\caption{Ablation study on non-maximum suppression (NMS) on THUMOS14, measured by AR@AN.}
\label{tab:snms}
\begin{tabular}{c|c|c|c}
\hline
\textbf{Model} & \textbf{AR@50} & \textbf{AR@100} & \textbf{AR@500} \\ \hline 
BMN \cite{lin2019bmn}       &  29.04           & 37.72           & 56.07   \\ 
BMN \cite{lin2019bmn}  + NMS       &  32.73           & 40.68           & 56.42   \\ \hline
DiffTAD & 63.6  & 69.6   & \textbf{73.1} \\ 
DiffTAD + NMS & \textbf{64.3}  & \textbf{69.9}   & 72.8            \\ \hline
\end{tabular}
\end{table}

\paragraph{Ablation of denoising strategy.} Due to the inherent query based design with the detection decoder, (1) we can corrupt discrete action proposals and project them as queries,
and (2) we can also corrupt the action label and project it as label queries.
Both can be taken as the input to the decoder. 
For corrupting the label queries, we use random shuffle as the noise in the forward diffusion step.
To validate this design choice experimentally, we test three variants: (1) only labels are corrupted,
(2) only proposals are corrupted, and
(3) both proposals and labels are corrupted. 
For the non-corrupted quantity,
% For all the cases without corruption, 
we add noise to the randomly initialized embedding. 
For the last variant, we stack all the corrupted proposals and labels and pass them into the decoder. %From the results in Table~\ref{tab:denoise}, i
It can be observed in Table~\ref{tab:denoise} that corrupting  labels alone observes the most drop in performance, and corrupting both labels and proposals is inferior to only corrupting the proposals.

\begin{table}[t]
\centering
\caption{Denoising strategy with DiffTAD on THUMOS14.}
\label{tab:denoise}
\begin{tabular}{cc|cccc}
\hline
\multicolumn{2}{c|}{Denoising Strategy}                            & \multicolumn{4}{c}{mAP}                                           \\ \hline
\multicolumn{1}{c|}{Proposal}               & Label & 0.3 & 0.5 & \multicolumn{1}{c|}{0.7}                        & Avg \\ \hline
\multicolumn{1}{c|}{\xmark}                          & \cmark             & 70.1  & 65.9  & \multicolumn{1}{c|}{52.7}                         & 62.4  \\
\rowcolor[HTML]{EFEFEF} 
\multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\cmark} & \xmark              & 74.9  & 71.2  & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}58.5} & 68.0  \\
\multicolumn{1}{c|}{\cmark}                         & \cmark             & 73.8  & 70.4  & \multicolumn{1}{c|}{58.0}                         & 67.3  \\ \hline
\end{tabular}
\end{table}

\begin{figure*}[t]
    \centering
    \includegraphics[scale=0.185]{img/DiffTAD_visual_v2.pdf}
    \caption{\textbf{Visualization of DiffTAD} proposal denoising step during inference}
    \label{fig:visual}
\end{figure*}

\section{Visualization of proposal denoising}

We visualize our sampling step of DiffTAD in Fig~\ref{fig:visual}. The model is initialized with 30 proposals for better visualization. This experiment is performed on a random testing video from ActivityNet dataset. 

\textit{(a)} Initial action proposals are randomly sampled from the Gaussian distribution ($Z_{T}$) and then projected as queries into the detection decoder $f_{\theta}$. 

\textit{(b)} The detection decoder predicts the action proposals (start/end point) along with the action class. The noise is calculated and then the action proposals are denoised using DDIM based denoising diffusion strategy. 

\textit{(c)} Our proposed cross-step selection strategy estimates the best candidate proposals based on the denoised reference proposal from the last step. The proposals with low temporal overlap with the reference proposals are dropped from the denoising step thus accelerating the inference. 

\textit{(d)} After multiple steps of refinement, final denoised action proposal predictions are obtained.

\section{Conclusion}

In this work, we propose a novel temporal action detection (TAD) paradigm, \modelname{}, by considering it as a denoising diffusion process from noisy proposals to action proposals. 
This proposed generative model is conceptually distinctive from all previous TAD methods based on discriminative learning.
%
Our model is designed by properly tailoring the diffusion and denoising process in a single-stage DETR framework,
with appealing properties such as more stable convergence, flexible proposal sizes, and superior proposal refinement.
%
% Our noise-to-proposal pipeline has several appealing properties, including dynamic proposal and iterative refinement, enabling us to use the same network parameters to obtain the desired speed-accuracy trade-off without re-training. 
Experiments on standard benchmarks show that \modelname{} achieves favorable performance compared to both generative and non-generative alternatives. 

% To further explore the potential of diffusion model to solve video-level action recognition tasks, several future works are beneficial. Another is to extend DiffTAD from close-world to open-world or open-vocabulary temporal action detection.


% \noindent{\bf Implementation details } 




{\small
\bibliographystyle{ieee_fullname}
\bibliography{main_arxiv}
}



% \clearpage

% \title{\textit{Supplementary}: Temporal Action Detection with Conditioned Location Diffusion}

% \author{First Author\\
% Institution1\\
% Institution1 address\\
% {\tt\small firstauthor@i1.org}
% % For a paper whose authors are all at the same institution,
% % omit the following lines up until the closing ``}''.
% % Additional authors and addresses can be added with ``\and'',
% % just like the second author.
% % To save space, use either the email address or home page, not both
% \and
% Second Author\\
% Institution2\\
% First line of institution2 address\\
% {\tt\small secondauthor@i2.org}
% }

% \maketitle

% \section{More Implementation Details}

% \subsection{Formulation of Diffusion Model}\label{appendix:diffusion_formula}

% We provide a detailed review of the formulation of diffusion models, following the notion of~\cite{ho2020denoising, dhariwal2021diffusion, nichol2021improved}. Starting from a data distribution $\bm{x}_0 \sim q(\bm{x}_0)$, we define a forward Markovian noising process $q$ which produces data samples $\bm{x}_1$, $\bm{x}_2$, ..., $\bm{x}_T$ by gradually adding Gaussian noise at each timestep $t$. In particular, the added noise is scheduled by the variance $\beta_t \in (0, 1)$:
% \begin{alignat}{2}
%     q(\bm{x}_{1:T}|\bm{x}_0) &\coloneqq \prod^T_{t=1}q(\bm{x}_t | \bm{x}_{t-1}) \\
%     q(\bm{x}_t | \bm{x}_{t-1}) &\coloneqq \mathcal{N}(\bm{x}_t; \sqrt{1-\beta_t}\bm{x}_{t-1}, \beta_t \bm{I})
% \end{alignat}

% \noindent As noted by Ho~\etal~\cite{ho2020denoising}, we can directly sample data $\bm{x}_t$ at an arbitrary timestep $t$ without the need of applying $q$ repeatedly:

% \begin{alignat}{2}
%     q(\bm{x}_t|\bm{x}_0) &\coloneqq \mathcal{N}(\bm{x}_t; \sqrt{\bar{\alpha}_t}\bm{x}_0, (1 - \bar{\alpha}_t)\bm{I}) \\
%     &\coloneqq \sqrt{\bar{\alpha}_t} \bm{x}_0  + \epsilon \sqrt{1 - \bar{\alpha}_t}, \epsilon \in \mathcal{N}(0, \bm{I})\label{eq:diffuse}
% \end{alignat}
% \noindent where $\bar{\alpha}_t \coloneqq \prod_{s=0}^{t} \alpha_s$ and $\alpha_t \coloneqq 1 - \beta_t$. Then, we could use $\bar{\alpha}_t$ instead of $\beta_t$ to define the noise schedule.

% Based on Bayes' theorem, it is found that the posterior $q(\bm{x}_{t-1}|\bm{x}_t, \bm{x}_0)$ is a Gaussian distribution as well:

% \begin{alignat}{2}
%      q(\bm{x}_{t-1}|\bm{x}_t, \bm{x}_0) &= \mathcal{N}(\bm{x}_{t-1}; \tilde{\mu}(\bm{x}_t, \bm{z}_0), \tilde{\beta}_t \mathbf{I})\label{eq:posterior}
% \end{alignat}

% \noindent where
% \begin{alignat}{2}
%     \tilde{\mu}_t(\bm{x}_t, \bm{x}_0) &\coloneqq
%     \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\bm{x}_0 + \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t} \bm{x}_t \label{eq:mutilde}
% \end{alignat}
% \noindent and
% \begin{alignat}{2}
%     \tilde{\beta}_t &\coloneqq \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \beta_t \label{eq:betatilde}
% \end{alignat}
 
% \noindent are mean and variance of this Gaussian distribution.

% We could get a sample from $q(\bm{x}_0)$ by first sampling from $q(\bm{x}_T)$ and running the reversing steps $q(\bm{x}_{t-1} | \bm{x}_t)$ until $\bm{x}_0$. Besides, the distribution of $q(\bm{x}_T)$ is nearly an isotropic Gaussian distribution with a sufficiently large $T$ and reasonable schedule of $\beta_t$~($\beta_t \rightarrow 0$), making it trivial to sample $\bm{x}_T \sim \mathcal{N}(0, \bm{I})$. Moreover, since calculating $q(\bm{x}_{t-1} | \bm{x}_t)$ exactly should depend on the entire data distribution, we could approximate $q(\bm{x}_{t-1} | \bm{x}_t)$ using a neural network,
% % 
% which is optimized to predict a mean $\mu_\theta$ and a diagonal covariance matrix $\Sigma_\theta$:
% \begin{alignat}{2}
% p_{\theta}(\bm{x}_{t-1}|\bm{x}_t) &\coloneqq \mathcal{N}(\bm{x}_{t-1};\mu_{\theta}(\bm{x}_t, t), \Sigma_{\theta}(\bm{x}_t, t)) \label{eq:ptheta}
% \end{alignat}
% Instead of directly parameterizing $\mu_\theta(\bm{x}_t, t)$, Ho~\etal~\cite{ho2020denoising} found that learning a network $f_\theta(\bm{x}_t, t)$ to predict the $\epsilon$ or $\bm{x}_0$ from \ref{eq:diffuse} works the best. We hence choose predicting $\bm{x}_0$ in this work.

% \subsection{Detection Decoder}

% To help understand our detection decoder better, we provide more details below.
% % describe it in details.
% There are two attention modules in the decoder: 
% (1) The proposed selective attention module and 
% (2) a cross-attention module. As shown in Fig.~\ref{fig:decoder}, first we project the noisy queries as noisy action segments both from current time step $x_{t}$ and previous denoised step $x_{t+1}$ (denoted as reference segment). We calculate the most promising noisy query to be denoised using Eq. (6) and Eq. (7) (in main paper). Additionally, the noisy query at $x_{t}$ also predicts soft attention weights by a fully-connected layer. With the soft-attention, the decoder samples the most confident query features $\hat{q}_{i}$ at each decoder layer for cross-attention. Another input of the cross-attention in the decoder is the video encoder features (\ie\ the condition). Finally the cross-attended noisy query features are passed onto the FFN layers for estimating the noise for denoising. 


% \begin{figure}
%     \centering
%     \includegraphics[scale=0.15]{iccv2023AuthorKit/img/supple_decoder.pdf}
%     \caption{Illustration of detection decoder module in DiffTAD.}
%     \label{fig:decoder}
% \end{figure}

% \subsection{Label Assignment in DiffTAD} 
% Similar to RTD-Net \cite{tan2021relaxed} the ground-truth instance set
% $\hat{\psi} = \{ \hat{\psi}_{n} = (\hat{t}^{n}_{s}, \hat{t}^{n}_{e},\hat{y}^{n})\}^{N_{g}}_{n=1}$ is composed of $N_{g}$ targets, where $\hat{t}^{n}_{s}$ and $\hat{t}^{n}_{e}$ are the starting and ending temporal locations of $\hat{\psi}_{n}$ and $\hat{y}_{n}$ is the action label of the corresponding proposal. Likewise, the prediction set of $N_{p}$ samples is denoted as  $\Psi = \{ \hat{\psi}_{n} = (t^{n}_{s}, t^{n}_{e},y^{n}) \}^{N_{p}}_{n=1}$. We assume $N_{p}$ is larger than $N_{g}$ and augment $\hat{\psi}$ to the size of $N_{p}$ by padding $\phi$. 


% \subsection{Details on the TAD Loss}
% Similar to DETR based TAD designs \cite{tan2021relaxed,shi2022react}, we have three heads for each noisy query and the set-prediction \cite{lin2021detr} loss terms for each of them. The set-prediction loss requires pairwise matching cost between the predictions and ground truth instances, taking into account both the category and proposal predictions. The matching cost is formulated as:
% \begin{align}
%     \texttt{C} = \lambda_{cls}C_{cls} + \lambda_{l1}C_{l1} + \lambda_{tiou}C_{tiou} + \lambda_{comp}C_{comp} 
% \end{align}
% where $C_{cls}$ is the focal loss~\cite{lin2017focal} between the prediction and
% ground truth class labels. Besides, our action proposal loss contains
% %$C_{l1}$ and $C_{tiou}$ , which are most commonly used
% the common l1-loss $C_{l1}$ and
% temporal IoU (tIoU) loss $C_{tiou}$ \cite{tan2021relaxed}. We additionally have an action completeness loss $C_{comp}$ -- a variant of tIOU loss \cite{tan2021relaxed} that refines the low confidence proposals. $\lambda_{cls}, \lambda_{l1}$, $\lambda_{tiou}$ and $\lambda_{comp} \in \mathbb{R}$ are the weights of each component for balancing the multiple losses. Following \cite{tan2021relaxed}, we adopt $\lambda_{cls} = 1.0$, $\lambda_{l1} = 1.0$, $\lambda_{iou} = 1.0$ and $\lambda_{comp} = 1.0$. 
% We assign multiple predictions to each ground truth with the optimal transport approach \cite{ge2021ota,ge2021yolox}.  Specifically, for each ground-truth, we select the top-$k$ predictions with the least matching cost as its positive samples, and the others as negatives. Overall, DiffTAD is optimized with a multi-task loss function:
%  \begin{align}
%      \texttt{L} = \lambda_{cls}L_{cls} + \lambda_{l1}L_{l1} + \lambda_{iou}L_{iou} + \lambda_{comp}L_{comp}
%  \end{align}
% The component of training loss is the same as the matching cost, except that the loss is only performed on the matched pairs.

% % \paragraph{Classification head:}  For the
% % prediction with index $\sigma{i}$ we define probability of class $c_{i}$ as $p_{\sigma_{i}}(c_{i})$ 

% % We define the binary classification loss function as:
% % \begin{align}
% % L_{cls} = 
% % \end{align}

% % \paragraph{Proposal head:} 

% % \paragraph{Completeness head:} 



% \subsection{Model Training and Inference}
% During training, we first construct the diffusion process that corrupts the ground-truth proposals to noisy proposals, and then trains the model to reverse this noising process. Please refer to 
% Algorithm \ref{alg:train} % \texttt{Algorithm 1} 
% for more details. 

% During inference, starting from noisy proposals sampled in Gaussian distribution, the model progressively refines the predictions, as illustrated in Algorithm \ref{alg:sample}.
% % \texttt{Algorithm 2}.

% \begin{algorithm}[h]
% \small
% \caption{\small DiffTAD Training 
% }
% \label{alg:train}
% \algcomment{\fontsize{7.2pt}{0em}\selectfont \texttt{alpha\_cumprod(t)}: cumulative product of $\alpha_i$, \ie, $\prod_{i=1}^t \alpha_i$
% }
% \definecolor{codeblue}{rgb}{0.25,0.5,0.5}
% \definecolor{codegreen}{rgb}{0,0.6,0}
% \definecolor{codekw}{RGB}{207,33,46}
% \lstset{
%   backgroundcolor=\color{white},
%   basicstyle=\fontsize{7.5pt}{7.5pt}\ttfamily\selectfont,
%   columns=fullflexible,
%   breaklines=true,
%   captionpos=b,
%   commentstyle=\fontsize{7.5pt}{7.5pt}\color{codegreen},
%   keywordstyle=\fontsize{7.5pt}{7.5pt}\color{codekw},
%   escapechar={|}, 
% }
% \begin{lstlisting}[language=python]
% def train(video_feat, gt_proposals):

%   # Encode image features
%   feats = video_encoder(video_feat)

%   # Signal scaling
%   pb = (pb * 2 - 1) * scale  

%   # Corrupt gt_proposals
%   t = randint(0, T)|~~~~~~~~~~~|# time step
%   eps = normal(mean=0, std=1)  # noise: [B, N, 2]
  
%   pb_crpt = sqrt(|~~~~|alpha_cumprod(t)) * pb + 
%               |~|sqrt(1 - alpha_cumprod(t)) * eps

%   # Project to continuous embedding
%   pb_crpt = project(pb_crpt) # query : [B, N, D]
              
%   # Calculate Self-condition estimate
%   pb_pred = zeros_like(pb_crpt)
%   if self_cond and uniform(0,1) > 0.7:
%     pb_pred = decoder(pb_crpt, pb_pred, feats, t)
%     pb_pred = stop_gradient(pb_pred)
  
%   # Predict
%   pb_pred = decoder(pb_crpt, pb_pred, feats, t)

%   # Set prediction loss
%   loss = set_prediction_loss(pb_pred, gt_proposals)
  
%   return loss
% \end{lstlisting}
% \end{algorithm}


% \begin{algorithm}[h]
%     \small
% \caption{\small DiffTAD Sampling 
% }
% \label{alg:sample}
% \algcomment{\fontsize{7.2pt}{0em}\selectfont \texttt{linespace}: generate evenly spaced values
% }
% \definecolor{codeblue}{rgb}{0.25,0.5,0.5}
% \definecolor{codegreen}{rgb}{0,0.6,0}
% \definecolor{codekw}{rgb}{0.85, 0.18, 0.50}
% \lstset{
%   backgroundcolor=\color{white},
%   basicstyle=\fontsize{7.5pt}{7.5pt}\ttfamily\selectfont,
%   columns=fullflexible,
%   breaklines=true,
%   captionpos=b,
%   commentstyle=\fontsize{7.5pt}{7.5pt}\color{codegreen},
%   keywordstyle=\fontsize{7.5pt}{7.5pt}\color{codekw},
%   escapechar={|}, 
% }
% \begin{lstlisting}[language=python]
% def infer(video_feat, steps, T):
  
%   # Encode video features
%   feats = video_encoder(video_feat)

%   # noisy proposals: [B, N, 2]
%   pb_t = normal(mean=0, std=1)

%   # noisy embeddings: [B, N, D]
%   pb_t = project(pb_t) 
  
%   pb_pred = zeros_like(pb_t)

%   # uniform sample step size
%   times = reversed(linespace(-1, T, steps))
  
%   # [(T-1, T-2), (T-2, T-3), ..., (1, 0), (0, -1)]
%   time_pairs = list(zip(times[:-1], times[1:])

%   for t_now, t_next in zip(time_pairs):
%     # Predict pb_0 from pb_t
%     if not self_cond:
%         pb_pred = zeros_like(pb_t)
%     pb_pred = decoder(pb_t, pb_pred, feats, t_now)
    
%     # Estimate pb_t at t_next
%     pb_t = ddim_step(pb_t, pb_pred, t_now, t_next)
 
%   return pb_pred
% \end{lstlisting}

% \end{algorithm}



% \section{More Model Ablation}

% \paragraph{Importance of positional encoding} 
% In this section, we show the importance of temporal positional embedding in the video encoder module. We experiment with removing positional embedding at MLP encoder or directly adding it into the encoder. We contend that the commonly used positional encoding, however, does not bring performance gain. We postulate that the projection using convolutions as well as the depthwise convolutions in the Transformer encoder blocks already leak the location information, as reported in \cite{zhang2022actionformer}. The results in Table~\ref{tab:pe} show that the model performance even decreases by 1.3\% on avg mAP from using temporal positional embedding in the encoder.

% \begin{table}[h]
% \centering
% \caption{Positional encoding (PE) with DiffTAD on THUMOS14.}
% \label{tab:pe}
% \begin{tabular}{c|ccc|c}
% \hline
% \textbf{Model}      & \textbf{0.3}                        & \textbf{0.5}                        & \textbf{0.7}                        & \textbf{Avg}                        \\ \hline
% Ours w/ PE         & 72.7                                  & 70.1                                  & 56.2                                  & 66.7                                  \\ \hline
% \textbf{Ours w/o PE} & \cellcolor[HTML]{EFEFEF}\textbf{74.9} & \cellcolor[HTML]{EFEFEF}\textbf{71.2} & \cellcolor[HTML]{EFEFEF}\textbf{58.5} & \cellcolor[HTML]{EFEFEF}\textbf{68.0} \\ \hline
% \end{tabular}
% \end{table}


% \paragraph{NMS-free design} 
% As shown in Table~\ref{tab:snms}, when comparing DiffTAD with and without non-maximum suppression (NMS), we observe similar results. NMS is not necessary in DiffTAD because the predictions are relatively
% sparse and minor-overlapped with our cross-step conditional strategy (Section 3.3). In contrast, existing non-generative TAD works like BMN \cite{lin2019bmn} and GTAD \cite{xu2020g} generate highly overlapped proposals with similar confidence. Thus, NMS becomes necessary
% % for these non generative dense proposal generators 
% to suppress redundant proposals. 
% \begin{table}[h]
% \centering
% \caption{Ablation study on non-maximum suppression (NMS) on THUMOS14, measured by AR@AN}
% \label{tab:snms}
% \begin{tabular}{c|c|c|c}
% \hline
% \textbf{Model} & \textbf{AR@50} & \textbf{AR@100} & \textbf{AR@500} \\ \hline 
% BMN \cite{lin2019bmn}       &  29.04           & 37.72           & 56.07   \\ 
% BMN \cite{lin2019bmn}  + NMS       &  32.73           & 40.68           & 56.42   \\ \hline
% DiffTAD & 63.6  & 69.6   & \textbf{73.1} \\ 
% DiffTAD + NMS & \textbf{64.3}  & \textbf{69.9}   & 72.8            \\ \hline
% \end{tabular}
% \end{table}

% % \paragraph{Ablation on number of decoders} 

% \paragraph{Query padding strategy} As introduced in Section 3.3, we need to pad additional proposals to the original ground truth proposals so that each video has the same number of proposal queries during training $N_{train}$ and evaluation $N_{eval}$. We study different padding strategies, including (1) repeating original ground truth proposals projected as queries evenly until the total number reaches pre-defined value $N_{train}$; (2) Padding random queries in Gaussian distribution; (3) Padding random queries following uniform distribution. 
% As shown in Table~\ref{tab:query}, concatenating uniform random query works the best for DiffTAD, which is different to object detection \cite{chen2022diffusiondet} with Gaussian distributed padding the best. We use the uniform padding strategy as default. 

% \begin{table}[h]
% \centering
% \caption{Strategies of padding queries on THUMOS14.}
% \label{tab:query}
% \begin{tabular}{c|ccc|c}
% \hline
% \textbf{Type} & \textbf{0.3}               & \textbf{0.5}               & \textbf{0.7}               & \textbf{Avg}               \\ \hline
% Repeat        & 70.2                         & 67.8                         & 54.1                         & 63.7                         \\
% Uniform      & \cellcolor[HTML]{EFEFEF}74.9 & \cellcolor[HTML]{EFEFEF}71.2 & \cellcolor[HTML]{EFEFEF}58.5 & \cellcolor[HTML]{EFEFEF}68.0 \\
% Gaussian       & 74.0                         & 70.5                         & 57.6                         & 67.1                         \\ \hline
% \end{tabular}
% \end{table}

% % boxes to the original ground truth boxes such that each image has the same number of boxes. We study different padding strategies in Table 3b, including (1.) repeating original ground truth boxes evenly until the total number reaches pre-defined value Ntrain; (2.) padding random boxes that follow Gaussian distribution; (3.) padding random boxes that follow uniform distribution; (4.) padding boxes that have the same size as the whole image, which is the default initialization of learnable boxes in [81]. Concatenating Gaussian random boxes works best
% % for DiffusionDet. We use this padding strategy as default.

% \paragraph{Random seed} DiffTAD is given random action proposals
% as input at the start of inference. One may ask whether there is a large performance variance across different random seeds. We evaluate the stability of DiffTAD by training five models independently with strictly the same configurations except for random seed on THUMOS14 dataset. Then, we evaluate each model instance with ten different random seeds to measure the distribution of performance, inspired by \cite{chen2022diffusiondet}. As shown in Figure~\ref{fig:rand_seed}, most evaluation results are distributed closely to 68.11 avg mAP. Besides, the mean values are all above 67.7 avg mAP, with marginal performance differences across different model instances.
% This demonstrates that DiffTAD is robust to the random proposals, able to produce reliable performance.

% \begin{figure}
%     \centering
%     \includegraphics[scale=0.45]{iccv2023AuthorKit/img/random_seed.png}
%     \caption{\textbf{Statistical results} over 5 independent training instances, with each evaluated 10 times with different random seeds on THUMOS14 dataset. The numbers inside the figure are the mean values.}
%     \label{fig:rand_seed}
% \end{figure}

% \paragraph{Effect of video feature} 
% We evaluate the effect of video features in DiffTAD.
% %The robustness of the feature space is verified in Table~\ref{tab:feat}. 
% For this experiment, we considered two video feature backbones namely R(2+1)D \cite{tran2018closer} and I3D \cite{carreira2017quo}. It is observed from Table~\ref{tab:feat} that in both cases DiffTAD outperforms existing approaches consistently on THUMOS dataset. 
% This indicates that the advantage of our model is video feature generic.
% % 
% % This shows the feature agnostic nature of DiffTAD over other model designs. 

% \begin{table}[h]
% \centering
% \caption{Effect of video features with DiffTAD on THUMOS14.}
% \label{tab:feat}
% \begin{tabular}{c|cccc}
% \hline
% \multirow{2}{*}{\textbf{Features}} & \multicolumn{4}{c}{\textbf{mAP}}                                                 \\ \cline{2-5} 
%                                    & \textbf{0.3} & \textbf{0.5} & \multicolumn{1}{c|}{\textbf{0.7}} & \textbf{Avg} \\ \hline
% I3D  \cite{carreira2017quo}                              & 74.9           & 71.2            & \multicolumn{1}{c|}{58.5}            & 68.0           \\ \hline
% % TSN                                & 21           & 22            & \multicolumn{1}{c|}{23}            & 24           \\ 
% R(2+1)D  \cite{tran2018closer}   & 67.4           & 62.8            & \multicolumn{1}{c|}{48.5}            & 55.9           \\ \hline
% \end{tabular}
% \end{table}

% \paragraph{Ablation of denoising strategy} Due to the inherent query based design with the detection decoder, (1) we can corrupt both discrete action proposals and project it as queries,
% and (2) we can also corrupt the action label and project it as label queries.
% Both are the input to the decoder. 
% For corrupting the label queries, we use random shuffle as the noise in the forward diffusion step.
% To validate this experimentally, we test three variants: (1) Only labels are corrupted;
% (2) Only proposals are corrupted;
% (3) Both proposals and labels are corrupted. 
% For the non-corrupted quantity,
% % For all the cases without corruption, 
% we add noise to the random initialized embedding. 
% For the last variant, we stack all the corrupted proposals and labels and pass it into the decoder. %From the results in Table~\ref{tab:denoise}, i
% It can be observed in Table~\ref{tab:denoise} that corrupting  labels alone observes the most drop in performance, and corrupting both labels and proposals is inferior to only corrupting the proposals.

% \begin{table}[h]
% \centering
% \caption{Denoising strategy with DiffTAD on THUMOS14.}
% \label{tab:denoise}
% \begin{tabular}{cc|cccc}
% \hline
% \multicolumn{2}{c|}{Denoising Strategy}                            & \multicolumn{4}{c}{mAP}                                           \\ \hline
% \multicolumn{1}{c|}{Proposal}               & Label & 0.3 & 0.5 & \multicolumn{1}{c|}{0.7}                        & Avg \\ \hline
% \multicolumn{1}{c|}{\xmark}                          & \cmark             & 70.1  & 65.9  & \multicolumn{1}{c|}{52.7}                         & 62.4  \\
% \rowcolor[HTML]{EFEFEF} 
% \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\cmark} & \xmark              & 74.9  & 71.2  & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}58.5} & 68.0  \\
% \multicolumn{1}{c|}{\cmark}                         & \cmark             & 73.8  & 70.4  & \multicolumn{1}{c|}{58.0}                         & 67.3  \\ \hline
% \end{tabular}
% \end{table}

% % \section{Visualization}
% % We visualize our sampling step of DiffTAD in Figure xyz. The model runs with $N$ proposals. For better visualization, we only draw xx proposals in the video. 
% % \\
% % (a) Initial random proposals sampled from the Gaussian distribution are input into the detection detector. 
% % % The random proposals are sampled from the Gaussian distribution. 
% % \\
% % (b) The detection decoder predicts the category scores and proposal coordinates of the current step. In sub-figure (b), the color brightness is proportional to the score value, where the deep red is high score, and white is low score. 
% % \\
% % (c)  DDIM estimates the proposals for the next step. \\
% % (d)  Those proposals with lower scores than the threshold are
% % dropped. 
% % \\
% % (e) New random proposals sampled from the Gaussian distribution are concatenated to the remaining proposals. This new set of proposals are input to the detection detector. 
% % \\
% % (f) After refining for a desired number of steps, the final predictions
% % can be obtained.  




\end{document}