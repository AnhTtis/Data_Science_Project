\section{Conclusion}
In this work, we study the DR problem where the participating consumers' baselines have to be estimated online. The online nature of our baseline learning problem results in an exploration-exploitation trade-off between learning the baseline and optimizing the overall operating cost simultaneously, with an added complexity that the consumers can have incentives to inflate the baseline estimate. We propose a novel, online learning DR scheme for this problem and show that our approach achieves a low regret of $\mathcal{O}((\log{T})^2)$ over $T$ days of the DR program with respect to the best DR outcome with full information of the baselines and ensures that participating is individually rational for each consumer. The utility of our approach lies in the fact all prior approaches either require large quantity data or the consumers to report their baselines, both of which could be infeasible. Our contribution is a low regret online learning DR scheme.