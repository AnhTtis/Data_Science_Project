\section{Data Processing}\label{appsec:dataprocess}
To construct the hedged counterstatments, if the main verb is `is' or `are' we convert it to `can also be'. For example `men are vain' becomes `men can also be vain'. If the main verb is `should' we convert it to `should also'. Otherwise, we insert `may also' before the quality. For example, `men think they know everything' becomes `men may also think they know everything'.

We also note that the group names in Table~\ref{tab:groupstats} have been normalized. We will include both the normalized and unnormalized names in the released data.


\subsection{GPT-3 Generation}\label{appsec:gpt3}
We access GPT-3 using the API from OpenAI\footnote{\url{https://beta.openai.com/docs/introduction}}. To obtain subtypes from GPT-3 we use the \textit{`davinci'}
model and top-$p$ sampling with $p = 0.9$, temperature 0.8 and maximum length $100$ tokens. The presence and frequency penalties are both $0$. We kept the top 5 generations from GPT-3. 
We filter out generations that are the same as the queried group. The prompts are shown in Table~\ref{tab:gpt3prompts}. We randomized the order of the 5 examples in each prompt for every group. 

\input{tables/gpt3_prompts}


\section{Human Studies}\label{appsec:annotation}
For our user studies, we recruit annotators from Amazon Mechanical Turk who were qualified for a toxicity explanation task from our previous work \cite{anon}.\footnote{Anonymized to preserve double-blindness of reviewing, will be de-anonymized upon public release.}
Racial and gender breakdowns of our annotator pool are in Figure~\ref{fig:annotatordemos}.
Annotators were paid \$0.27 per task. 
For each instance in each of the three settings we have 3 annotators.
This study was approved by our institution's ethics board (IRB).

We show the detailed task instructions in Figure~\ref{fig:annotationinstructions}. 
An example of the task setup is shown in Figure~\ref{fig:mturk}.
Before choosing the most convincing counter statements, annotators have the option to mark each statement as incorrect or ungrammatical (Figure~\ref{fig:taskexample}).
Note that before asking annotators to select their second choice, we include an attention check (in Figure~\ref{fig:taskquestions}). The attention check was randomly set in each HIT. Annotations where the attention check incorrect were discarded. As a result, we removed 3 annotations from the \textit{post} setting, 5 from the \textit{stereo} setting, and 4 from \textit{post+stereo}. 
\input{graphics/mturk/mturk-instruct}
\input{graphics/mturk/mturk-setup}

For each annotation, we also collected demographic information (Figure~\ref{fig:demoquestions}). The demographic information is associated only with an annonymized annotator ID. Additionally, before annotators select counter-statements, we ask annotators to indicate their own belief in or agreement with the provided statement and stereotype (Figure~\ref{fig:agreequestions}).
\input{graphics/mturk/mturk-demos}
\input{graphics/mturk/mturk-endorse}









