
\section{Online Study}\label{sec:experiments}
As a preliminary investigation into the task of generating counterstatements to combat essentialism, we use posts with gold-annotated implications (\S\ref{ssec:sbf-data}) to conduct an online experiment with crowdworkers (\S\ref{ssec:mturk-study-setup}).

\subsection{Essentialism Data}\label{ssec:sbf-data}
We use annotations provided in the SBIC~\citep{sap2020socialbiasframes} to obtain pairs $(t, s)$ where $t$ is a text and $s$ is a stereotype implied by $t$ (i.e., an essentialist implication that can be drawn from $t$). The $s$ in SBF are human written and so to ensure the statements we consider are clear implications of the text $t$,
we use only instances where at least two out of the three human annotators wrote the same stereotype verbatim. This results in a set of $227$ pairs, covering $25$ unique groups, where each $s_i$ can be clearly inferred from $t_i$. 

\subsection{Study Setup}\label{ssec:mturk-study-setup}
In order to investigate the effectiveness of different counter statements (\S\ref{sec:method}), we conduct three different human studies. In each study, we ask annotators on Amazon Mechanical Turk to play the role of an online content moderator or fact-checker whose job is to provide counterstatements to expressed stereotypes. Each annotator is provided with a statement and a set of machine-generated counterstatements and asked to select their first and second choices. We also include an attention check to monitor annotation quality, and collect information on how much annotators agree with the provided statement and annotator demographic information. See full instructions in Appendix~\ref{appsec:annotation}.


Our three human studies vary the statements provided to annotators: \textbf{(1) post} -- an original text $t$ from SBF, \textbf{(2) stereo} -- the stereotype $s$ implied by a text $t$, or \textbf{(3) post + stereo} -- both $t$ and $s$. Note that for each pair $(t, s)$ the counterstatements are always derived from $s$, regardless of whether annotators are provided $s$ directly.  



\section{Empirical Results}\label{ssec:results}
Our results show clear differences in how often certain types of counterstatements are preferred over others to combat essentialism (Figure~\ref{fig:choicecharts}).
We see that overall, the \textsc{Lots} counterstatements are the most popular for both first and second choice. 
In addition, when considering broadening statements grouped together (\textsc{Lots} and \textsc{Alt}), there is a clear preference for such statements, compared to both the \textsc{Tol} and the direct exceptions. 
Despite the lack of content in the \textsc{Tol} statements, these are the second most popular as the first choice. 
Note, we choose not to conduct statistical tests because our goal is not to find the single most effective countering strategy but rather to study a range of strategies.

Of the generics-exceptions-based counterstatements, the direct exceptions \textsc{Dir} are consistently the least preferred. We hypothesize that this is impacted by the high portion of incorrect statements among the \textsc{Dir} type (Figure~\ref{fig:percentincorrect}), as well as the subjective nature of many stereotypes (e.g., in Table~\ref{tab:statementexs}, being a `sex object' is subjective). 
When considering only the statements \textit{not} marked as incorrect by annotators, we do not observe a change in relative popularity. Therefore, future investigation is needed to understand the role of correct individuals in counterstatements.

\input{graphs/incorrect}


In contrast, the broadening exceptions \textsc{Alt} rank second as the second-choice and only 7\% are marked as incorrect. 
We also note that in settings where the stereotype is provided explicitly (stereo and stereo+post) the proportion of \textsc{Lots} was higher (and \textsc{Tol} lower) for the first choice, and for the second choice the proportion of \textsc{Alt} increased markedly. 
From this we observe that the effectiveness of a countering strategy may depend on the explicitness of the demonstrated bias. 
For example, generalizing the stereotype (\textsc{Lots}) may be less effective when the stereotype is not explicitly identified (post setting).

Finally, we observe that when annotators agree with a statement, their preference for \textsc{Lots} statements increases while the preference for \textsc{Dir} counterstatements decreases (Fig.~\ref{subfig:agreestatements}). Annotator preference for \textsc{Tol} also decreases. 
We also note that annotators more often endorse a belief when it is stated explicitly, rather than implied by a text (Fig.~\ref{subfig:annotatoragree})
These results underscore the importance both of directly identifying an essentialist belief from an implication and of reasoning about the implications of the stereotype when countering real-world essentialist beliefs (i.e., from individuals who endorse the belief).

\input{graphs/agree-statements}