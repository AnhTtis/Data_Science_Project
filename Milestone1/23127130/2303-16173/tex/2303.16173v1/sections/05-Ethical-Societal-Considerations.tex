\section{Societal and Ethical Considerations}\label{sec:ethical-considerations}
\paragraph{Annotation Considerations}
Prior work has highlighted the potential harms to workers who are subjected to offensive statements~\cite{Roberts2017-rp,Steiger2021-ka}. To mitigate these, we encourage annotators to reach out to the authors with concerns and questions or to the Crisis Text Line.\footnote{\url{https://www.crisistextline.org/}} Additionally, our study design was approved by our ethics review board (IRB) and 
workers earned a median wage of \$10/h.

\paragraph{Risks of Generation}
Since our system automatically generates counterstatements, there is potential for misuse in several ways. First, our system can automatically and quickly produce millions of counterstatements could therefore be used in a distributed-denial-of-service attack. Second, by generating counterstatements to stereotypes in text the original text remains available and so it may still cause harm~\cite{Ullmann2019quarantining} and perpetuate essentialist beliefs. Additionally, the automatic construction of counterstatements has the potential to produce false statements and further harmful generalizations (e.g., generalize a harmful stereotype to another marginalized group). Considering these factors, it is important to jointly develop regulation alongside AI technology to limit harms and misuse in deployment~\cite{Crawford2021-kz,Reich2021-xw}.
