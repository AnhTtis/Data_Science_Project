
\subsection{Objectives}
Programming by example, or inductive synthesis, is the following problem: given a few examples, construct a program satisfying these examples. This particular setting in program synthesis, where the user gives a very partial specification, has been extremely useful and successful for automating tasks for end users, the prime example being FlashFill for performing string transformations in Excel~\cite{Gulwani2011}.

When considering knowledge-powered programming by example, we do not change the problem, only the solution: instead of classical programs performing syntactic manipulations, we include knowledge-powered programs. To illustrate the difference, let us consider the following two tasks.
\begin{minted}{python}
f("Paris") = "I love P"
f("Berlin") = "I love B"

g("Donald Knuth") = "DK is American"
g("Ada Lovelace") = "AL is English"
\end{minted} 
The first is a classical program synthesis task in the sense that it is purely syntactical, it can be solved with a two-line program concatenating ``I love '' with the first letter of the input.
On the other hand, the second requires some knowledge about the input individuals, here their nationality: one needs a knowledge-powered program to solve this task.
Since almost all program synthesis tools perform only syntactical manipulations of the examples (we refer to the related work section for an in-depth discussion), they cannot solve the second task.

Knowledge-powered programming by example goes much beyond query answering: the goal is not to answer a particular query, but to produce a program able to answer that query for any input. This is computationally and conceptually a much more difficult problem.

For concreteness we introduce some terminology about knowledge graphs, and refer to Figure~\ref{fig:knowledge_graph} for an illustration.
Nodes are called entities, and edges are labelled by a relation. Entities are arranged into classes: ``E. Macron'' belongs to the class of people, and ``France'' to the class of countries. The classes and relations are constrained by ontologies, which define which relations can hold between entities.
The de facto standard for querying knowledge graphs is through \texttt{SPARQL} queries, which is a very powerful and versatile query language.

\begin{figure}[ht]
   \centering
   \includegraphics[width=0.8\textwidth]{knowledge_graph}
   \caption{Illustration of part of a knowledge graph.}
   \label{fig:knowledge_graph}
\end{figure}

\subsection{Milestones}\label{sec:milestones}
We identify three independent ways in which semantical information can be used.
They correspond to different stages for solving a task:
\begin{itemize}
	\item \textit{preprocessing:} the first step is to extract entities from the examples;
	\item \textit{relating:} the second step is to relate entities in the knowledge graph;
	\item \textit{postprocessing:} the third step is to process the information found in the knowledge graph.
\end{itemize}

\paragraph*{How much preprocessing to extract entities?}
Let us consider two tasks.
\begin{minted}{python}
f("Aix, Paris, Bordeaux") = "Paris"
f("Hamburg, Berlin, Munich") = "Berlin"

g("President Obama") = "Obama"
g("Prime Minister de Pfeffel Johnson") = "de Pfeffel Johnson"
\end{minted}
In the function \texttt{f} the goal is to extract the second word as separated by commas: this is a purely syntactic operation.
In the function \texttt{g} we need to remove the job title from the input: this requires semantical knowledge, for instance it is not enough to use neither the second nor the last word.

\paragraph*{How complicated is the relationship between entities?}
We examine two more tasks.
\begin{minted}{python}
f("Paris") = "France is beautiful"
f("Berlin") = "Germany is beautiful"

g("Paris") = "Phone country code: 33"
g("Berlin") = "Phone country code: 49"
\end{minted}
The function \texttt{f} relates two entities: a city and a country. One can expect that the knowledge graph includes the relation \texttt{CapitalOf}, which induces a labelled edge between ``Paris'' and  ``France'' as well as ``Berlin'' and ``Germany'' (as in Figure~\ref{fig:knowledge_graph}). Note that it could also be the relation \texttt{CityOf}.
More complex, the function \texttt{g} requires crossing information: indeed to connect a city to its country code, it is probably required 
to compose two relations: \texttt{CapitalOf} and \texttt{PhoneCode}. In other words, the entities are related by a path of length $2$ in the knowledge graph, that we write \texttt{CapitalOf-PhoneCode}.
More generally, the length of the path relating the entities is a measure of complexity of a task.

\paragraph*{How much postprocessing on external knowledge?}
Let us look again at two tasks.
\begin{minted}{python}
f("Paris") = "Country's first letter: F"
f("Berlin") = "Country's first letter: G"

g("President Obama") = "B@r@ck"
g("Prime Minister Johnson") = "B0r1s"
\end{minted}
For the function \texttt{f}, the difficulty lies in finding out that the external knowledge to be search for relates ``Paris'' to ``France'' and ``Berlin'' to ``Germany'', and then to return only the first letter of the result. 
Similarly, for \texttt{g}, before applying a leet translation we need to retrieve as external knowledge the first name.
In both cases the difficulty is that the intermediate knowledge is not present in the examples.

\vskip1em
The three steps can be necessary, the most complex tasks involve at the same time subtle preprocessing to extract entities, complicated relationships between entities, and significant postprocessing on external knowledge.

\subsection{Motivating Examples}\label{sec:applications}
We illustrate the disruptive power of knowledge-powered program synthesis in three application domains.

\paragraph*{General knowledge}
The first example, which we use throughout the paper for illustrations, in the dataset and in the experiments, is to use the knowledge graph to obtain general facts about the world, such as geography, movies, people. Wikidata and Yago are natural knowledge graphs candidates for this setting. 
This domain is heavily used for query answering: combining it with program synthesis brings it to another level, since programs generalize to any input.

\paragraph*{Grammar exercises}
The second example, inspired from~\cite{VerbruggenLG21}, is about language learning: tasks are grammar exercises, where the goal is to write a grammatically correct sentence. Here the knowledge graph includes grammatical forms and their connections, such as verbs and their different conjugated forms, pronouns, adjectives, and so on.
Generating programs for solving exercises opens several perspectives, including generating new exercises as well as solving them automatically.

\paragraph*{Advanced database queries}
In the third example knowledge-powered program synthesis becomes a powerful querying engine. This scenario has been heavily investigated for SQL queries~\cite{WangCB17,ZhouBCW22}, but only at a syntactic level.
Being able to rely on the semantic properties of the data opens a number of possibilities, let us illustrate them on an example scenario.
The knowledge graph is owned and built by a company, it contains immutable data about products.
The database contains customer data.
Crossing semantical information between the database being queried and the knowledge graph allows the user to generate complex queries to extract more information from the database including for instance complex statistics.
