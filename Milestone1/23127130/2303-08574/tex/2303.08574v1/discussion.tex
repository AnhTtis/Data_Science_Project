\subsection{Related work}
The closest related work is~\cite{VerbruggenLG21}: 
the tool FlashGPT3 solves knowledge-powered program synthesis with a completely different approach: 
instead of querying a knowledge graph, FlashGPT3 uses a large language model (GPT3~\cite{BrownMRSKDNSSAA20}) to get external knowledge.
FlashGPT3 is shown superior to both program synthesis tools and GPT3 taken in isolation, and achieves impressive results in different domains.
There are three advantages of using a knowledge graph over a large language model:
\begin{itemize}
	\item \textbf{Reliability}: the synthesized program is only as reliable as the knowledge source that it uses.
To illustrate this point, let us consider the task
\begin{minted}{python}
f("Paris") = "France"
f("Berlin") = "Germany"
\end{minted}
GPT3 needs very few examples to predict that \mint{python}|f("Washington") = "United States"| \noindent but it might fail on more exotic inputs.
On the other hand, querying a knowledge graph results in setting \texttt{f = CountryOf} implying that the program will correctly reproduce the knowledge from the graph. 
Although GPT3 has achieved extraordinary results in query answering, it is still more satisfactory to rely on an established and potentially certified source of knowledge such as Wikipedia.
	\item \textbf{Explainability}: the constructed program has good explainability properties: the exact knowledge source it uses can be traced back to the knowledge graph and therefore effectively verified.
	\item \textbf{Adaptability}: knowledge-powered program synthesis can be deployed with any knowledge graph, possibly collecting specialised or private information which a largue language model would not know about.
\end{itemize}

\paragraph*{Other knowledge-powered program synthesis tools}
Most program synthesis tools work at a purely syntactical level. However, some included limited level of semantic capabilities for domain-specific tasks: for instance Transform-data-by-example (TDE) uses functions from code bases and web forms to allow semantic operations in inductive synthesis~\cite{HeCGZNC18},
and APIs were used for data transformations~\cite{BhupatirajuSMK17}.

\paragraph*{Knowledge graphs}
A growing research community focuses on creating, maintaining, and querying knowledge graphs.
The most related problems to our setting are query by example, where the goal is either to construct a query from a set of examples~\cite{JayaramKLYE16,MetzgerSS17}, and entity set expansion, aiming at expanding a small set of examples into a more complete set of entities having common traits~\cite{ZhengSCLW22}.

\subsection{Contributions and Outlook}

We have introduced knowledge-powered program synthesis, extending program synthesis by allowing programs to rely on knowledge graphs.
We described a number of milestones for this exciting and widely unexplored research objective, and proposed a dataset to evaluate the progress in this direction.
We constructed an algorithm and implemented a general-purpose knowledge-powered program synthesis tool WikiCoder that solves tasks previously unsolvable. Our tool can only address about one third of the dataset; we believe that solving the whole dataset would be an important step forward towards deploying program synthesis in the real world.

The most natural continuation of this work is to use very large language models for knowledge-powered program synthesis.
As discussed above, how can we retain the properties of our framework with knowledge graphs: reliability, explainability, and adaptability, while leveraging the power of very large language models?
