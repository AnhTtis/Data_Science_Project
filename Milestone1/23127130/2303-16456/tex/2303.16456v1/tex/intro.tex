\section{Introduction}
\label{sec:intro}

\begin{figure}
    \centering
    \includegraphics[width=.99\linewidth]{figures/cover.pdf}
    \caption{\textit{PoseDA} addresses 3d human pose domain adaptation problem through global adaptation and local generalization. The 2D poses from target dataset are used to guide the translation of 3D poses from source dataset. And the local root-relative poses also be augmented to achieve better generalization ability.}
    \label{fig:intro}
\end{figure}

% paragraph 1: task introduction
3D human pose estimation is an essential computer vision task which aims to estimate the coordinates of 3D joints from single-frame images or videos. This task can be further used for several downstream tasks in multiple object tracking~\cite{andriluka2018posetrack}, person re-identification~\cite{su2017pose}, action recognition~\cite{song2021human}, robot~\cite{svenstrup2009pose}, \textit{etc}. However, large-scale 3D-annotated datasets are hard to obtain. Existing methods are usually built on an off-the-shelf 2D pose estimator~\cite{chen2018cascaded, sun2019deep} following two-stage schemes.

% paragraph 2: challenge
Deep learning based methods~\cite{martinez2017simple, pavllo20193d} have achieved great success in learning the mapping from 2D to 3D in the past decade. Despite their success in in-distribution data, these fully-supervised methods show poor performance in cross-dataset inference~\cite{gong2021poseaug}. We argue that the real bottleneck lies in the domain gap of 3D pose data rather than the 2D-3D lifting network architecture or training strategy. Existing datasets either lack enough diversity in laboratorial environments~\cite{ionescu2013human3
} or lack adequate quantity and accuracy in the wild~\cite{mehta2017monocular}.
We model the pose domain gap in terms of global position and local pose separately shown in Figure~\ref{fig:intro}. As for the global position, the camera intrinsic and extrinsic parameters are completely different in different datasets, resulting in performance degradation in cross-dataset evaluation. And for the local pose, the lack of action diversity also limits the generalization ability of the model.
Addressing the domain adaptation or generalization problem is a crucial step for 3D human pose estimation to move from toy experiments to real-world applications. Recent works focus more on enhancing the generalization ability of the 2D-3D lifting networks or set camera view prediction as an auxiliary task~\cite{wandt2019repnet, wang2020predicting} to address adaptation problems. Some methods apply data augmentation in training images through image transformations~\cite{rogez2016mocap, mehta2018single, mehta2017vnect} or human synthetics~\cite{chen2016synthesizing, hoffmann2019learning, varol2017learning}. However, our proposed method does not rely on RGB or temporal information. Specifically, our method first generates transformed pose pairs from source dataset and then use them to train the 2D-3D lifting network, thus can fit any off-the-shelf model.

% paragraph 4: our work
In this paper, we propose \textit{PoseDA}, an unsupervised domain adaptation framework for 3D human pose estimation. Our method only requires non-sequence 2D poses (not images) and camera intrinsic parameters in target dataset as well as a large-scale 3D-annotated human pose dataset (\textit{e.g.,}~Human3.6M~\cite{ionescu2013human3}). 
The basic idea behind the proposed method is to combine global adaptation and local generalization to address the issue of unsupervised domain adaptation for 3D human pose estimation. Global adaptation aims to align global positions of poses from source domain to target domain, and local generalization aims to enhance the diversity of local structures of poses.
Therefore, our proposed method applies global position alignment strictly but only enhances the diversity of local poses. To be specific, we take a sample from the source dataset and apply transformations in terms of bone angle, bone length, and rotation. We use an augmentation generator to generate the parameters for these transformations and an anchor discriminator to ensure the realisticity and quality of these transformed pose pairs. As for the global position, we apply 2D global position alignment to ensure the alignment in both scales and 2D root positions between the projected 3D poses from the source domain with sampled 2D poses from the target domain. This process is solvable through geometry constraints with no additional learnable parameters. Finally, we use the transformed pose pairs to fine-tune the pre-trained 2D-3D lifting network and thus boost model performance on the target dataset without any use of 3D annotations.
% paragraph 6: contribution
Our contributions are summarized as follows:
\begin{itemize}
    \item We reduce the domain gap by separately applying global position alignment and local pose augmentation, where two major domain gaps are effectively decoupled.
    % \item We combine the global adaptation and local generalization in a unified framework to address the problem of unsupervised domain adaptation for 3D human pose estimation.
    % \item Global adaptation is implemented with a global position alignment (GPA) module to align global positions of poses from source domain to target domain. And local generalization is proposed with a local pose augmentation (LPA) module to enhance the diversity of local structures of 3D poses.
    \item We align the global position through geometry constraint with no additional learnable parameters, which can boost model performance significantly. And we apply local pose augmentation to enhance the diversity of local structures of 3D poses.
    \item Our approach is applicable to almost all 2D-3D lifting models. We achieve the state-of-the-art performance in Human3.6M-3DHP cross-dataset evaluation with 61.3 mm of MPJPE.
\end{itemize}