% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

% \documentclass[10pt,twocolumn,letterpaper]{article}
\documentclass[10pt,onecolumn,letterpaper]{article}
%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage[review]{iccv}      % To produce the REVIEW version
%\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{colortbl}
\usepackage{subcaption}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}
\renewcommand{\thefigure}{S\arabic{figure}}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\iccvPaperID{8973} % *** Enter the CVPR Paper ID here
\def\confName{ICCV}
\def\confYear{2023}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Global Adaptation meets Local Generalization: Unsupervised Domain Adaptation for 3D Human Pose Estimation \\ (Supplementary Material)}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}
\maketitle

\section*{A. More discussion on Global Position Alignment (GPA)}

% GPA前后分布，目标分布 done.

We show that global position alignment module actually align the 2D pose distribution in terms of scale and root position on 2D images in \cref{fig:position}. While other works did camera view estimation~\cite{wandt2019repnet, wang2020predicting} or generation~\cite{gholami2022adaptpose, gong2021poseaug} as an auxiliary task to address the global position adaptation problems, our method achieves alignment explicitly and directly.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/scale.pdf}
    \includegraphics[width=0.95\linewidth]{figures/x.pdf}
    \includegraphics[width=0.95\linewidth]{figures/y.pdf}
    \caption{Comparison of 2D scale (first row), root position of x-axis (second row), y-axis (third row) in source domain (left), source domain after GPA (middle), target domain (right). Source: H3.6M. Target: 3DHP.}
    \label{fig:position}
\end{figure*}


\section*{B. More discussion on Local Pose Augmentation (LPA)}

The most counter-intuitive conclusion in this paper is why adaptation methods perform worse than augmentation methods. In the discussion section, we include more detailed ablation studies on LPA. 

% \subsection*{B.1. Why is local pose augmentation better than local pose adaptation?}

% 在augmented domain和target domain间
% 找到一个2d一样但是3D差很多的样本对 done.
% 找到一个统计量表明在2D相似度提升的同时，3D相似度并没有一致的提升 hard

As shown in \cref{fig:2d3dcomparison}, we sampled two poses from generated poses trained with a 2D discriminator and the target dataset. They have similar 2D poses but different 3D poses, which shows the reason why simply applying local pose adaptation based on a 2D pose discriminator may not have the final adaptation performance.

\begin{table}[h]
    \small
    \centering
    \setlength{\tabcolsep}{1mm}
    
    \begin{tabular}{ccc|ccc}
        \specialrule{1pt}{1pt}{2pt}
        $\mathcal{G}_{pose}$ & $\mathcal{D}_{3D}$ & $\mathcal{D}_{2D}$ & MPJPE~($\downarrow$) & PCK~($\uparrow$) & AUC~($\uparrow$)\\
        \hline
        - & - & - & 66.07 & 90.87 & 60.07\\
        $\mathcal{S}$ & $\mathcal{S}$ & $\mathcal{S}$ & 73.55 & 88.96 & 56.41\\
        $\mathcal{S}$ & $\mathcal{S}$ & $\mathcal{T}$ & 65.46 & 91.27 & 60.03\\
        $\mathcal{S}$ & $\mathcal{S}$ & - & \textbf{61.36}& \textbf{92.05} & \textbf{62.52}\\
        \specialrule{1pt}{1pt}{2pt}
    \end{tabular}
    \caption{The input of the pose generator $\mathcal{G}_{pose}$, the 3D pose discriminator $\mathcal{D}_{3D}$, and the 2D pose discriminator $\mathcal{D}_{2D}$ in Local Pose Augmentation (LPA) module. $S, T$ denote poses from the source or target domain. Source: H3.6M. Target: 3DHP.}
    \label{tab:dis}
\end{table}

As \cref{tab:dis}, compared with our final method, the 2D discriminator trained with 2D poses from the target dataset improves the performance from $66.07$ mm to $65.46$ mm in MPJPE since the discriminator makes scale and location adaptation better. However, once the 2D discriminator is removed, we can achieve a better result, $61.36$ mm. The reason is that the 2D pose discriminator suppresses the diversity of generated 3D poses and makes the generator generates poses with similar 2D poses, but different 3D poses, as \cref{fig:2d3dcomparison} shows.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/sup1.pdf}
    \caption{These 2 sampled poses are from generated poses and the target dataset. They have similar 2D poses but different 3D poses, indicating that adaptation based on 2D poses may not lead to adaptation on 3D poses.}
    \label{fig:2d3dcomparison}
\end{figure*}

% \subsection*{B.2. Why pseudo 3D pose from target dataset can not guide augmentation process?}

% 可视化一个epoch序列，展示在训练不同阶段pseudo 3D和augmented 3D并没有共同优化 meaningless



%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{ref}
}

\end{document}