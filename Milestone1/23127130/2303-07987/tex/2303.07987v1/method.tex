\section{Methods}\label{sec:method}

In this section, we will introduce our methods under the three different settings introduced in~\Cref{sec:intro}.
This section is organized as follows.~\Cref{sec:method_unlimited} introduces our methods when the data distribution coincides with the population distribution and the time complexity is a major concern. In other words, we assume an unrestricted number of fresh LPN samples are given and our goal is to learn the secret as fast as possible.
We will show that under this setting, direct application of the gradient-based optimization (cf.~\Cref{alg:optim_example}) works well both empirically and theoretically.
~\Cref{sec:method_restricted} introduces our methods when the sample complexity is greatly limited. Under this setting, reduction to decision version LPN and proper regularization is essential.
~\Cref{sec:method_abundant} introduces our methods when the sample complexity and the time complexity need a subtle balance such that our method can be utilized as 
a building block in the classical \emph{reduction-decoding} scheme of the LPN problem. Under this setting, we will use the samples to approximate the population distribution with a bootstrapping technique.

Due to~\Cref{lem:s_sparse}, we will always assume secret $\ary{s}$ has Hamming weight $\lfloor n\tau \rfloor$. 
\footnote{This is the expected hamming weight of a secret. We fix the sparsity here mainly for the convenience of comparing and adjusting other parameters.} We will first highlight the common hyperparameters for all three settings in~\Cref{tab:shared_hyperparameter}. The first row is applied in all our implemented algorithms and the second row is used in our theoretical analysis in~\Cref{sec:theory}.

We further outline other hyperparameters specified for each algorithm in~\Cref{tab:hyperparameter}. Readers should note that the hyperparameters are tuned specifically towards the typical problem specification we list out in~\Cref{tab:problem} on which our hyperparameters selection is conducted on. The power of our method is not limited to the typical specification listed and we provide generic meta~\cref{alg:abundant_meta,alg:restricted_meta} for hyperparameter selection in other cases.




\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline 
    & Model $\model$ & Initialization & Regularization & Loss & Optimizer\\
    \hline
        Practical  &  $\basemodel_{1000}$ (\Cref{def:basemodel})& Kaiming & None & Logistic & Adam\\
    \hline
       Theory  &  $\basemodel_{d}$ with smooth activation $\sigma$ & Any & None & MAE & SGD
    \\
    \hline
    \end{tabular}
    \caption{Shared Hyperparameters}
    \label{tab:shared_hyperparameter}
\end{table}


\begin{table}[]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|} 
    \hline & Sampler & Learning Rate & Weight Decay &  Batch Size & Stop Criterion \\
    \hline
      \Cref{alg:abundant}   & Oracle & $2e-4$ to $6e-3$ & 0 & 131072 to 1048576& $\timestopcriterion(\rtime)$ \\
    \hline
      \Cref{alg:abundant_theory} & Oracle & Any
    & Any & Any &$\stepstopcriterion(\step)$\\
    \hline
    \Cref{alg:restricted} & Fix Batch & $2e-5$ to $1e-4$ & $2e-3$  & Training Set Size&$\stepstopcriterion(\step)$ \\
    \hline
    \Cref{alg:moderate} & Fix Batch & $2e-3$ & 0 & 1048576 & $\timestopcriterion(\rtime)$ \\
    \hline
    \end{tabular}
    \caption{Hyperparameters for Different Algorithms}
    \label{tab:hyperparameter}
\end{table}
\

\begin{table}[]
    \centering
    \begin{tabular}{|c|c|c|c|} 
    \hline & Dimension $n$ & Noise Rate $\tau$ & Sample Size\\
    \hline
      \Cref{alg:abundant}   & 20 to 40 & 0.4 to 0.498 & Abundant \\
    \hline
    \Cref{alg:restricted} & 20 to 50 & 0.2 to 0.3  & Less than $1e6$ \\
    \hline
    \Cref{alg:moderate} & 20  & 0.498 & 8e7\\
    \hline
    \end{tabular}
    \caption{Typical Problem Specification for Different Algorithms }
    \label{tab:problem}
\end{table}

\subsection{Abundant Sample}\label{sec:method_unlimited}

In~\Cref{setting:abundant}, we assume the learner has access to the Oracle Sampler (\Cref{alg:inf_sample}) with underlying distribution following LPN instances with a fixed secret, a fixed noise rate $\tau$, and any batch size $B$. Under this setting, the memory of the devices is the key constraint and the goal of this algorithm is to 
reduce the time complexity. We propose to use a direct variant of the gradient-based optimization algorithm~\Cref{alg:optim_example}, which is shown in~\Cref{alg:abundant}.

\begin{algorithm}
    \caption{Abundant Sample Algorithm: Practical Version}\label{alg:abundant}
    \begin{algorithmic}
    \Require $n$, the dimension, $\tau$ the error rate.
    \State Run~\Cref{alg:optim_example} with hyperparameters specified in~\Cref{tab:hyperparameter,tab:shared_hyperparameter} to get a learned model $\model[\weight_T]$.
    \State Set $\hat s$ as all zero vector in $\R^n$.
    \For{$i \in \{1,2,...n\}$}
    \State Set $\hat s[i] = \one{\model[\weight_T][e_i] > 0.5}$ with $e_i \in \R^n$ as the unit vector with the $i-$th coordinate being $1$.
    \EndFor
    \State \Return $\hat s$.
    \end{algorithmic}
\end{algorithm}

One may notice that there are some unspecified hyperparameters, including the time threshold $\rtime$ in~\Cref{alg:abundant}. Also for settings outside the scope of~\Cref{tab:problem}, some currently fixed parameters such as the learning rate $\eta$ and the batch size $B$ may also require tuning based on the problem setting, i.e, $n$ and $\tau$. Under such case, we propose to use~\Cref{alg:abundant_meta}, a meta algorithm for hyperparameter selection. In~\Cref{sec:abundant_hyper}, we show that~\Cref{alg:abundant_meta} 
effectively finds hyperparameters that leads to low time complexity of~\Cref{alg:abundant}, for example,~\Cref{alg:abundant} with $\eta =6e-3$ and $B = 1048576$, can solve $n = 20, \tau = 0.495$ in $6$ minutes with a single GPU.
An example running results of~\Cref{alg:abundant_meta} is shown in~\Cref{tab:ablation_1_lr_bz}.


\begin{algorithm}
    \caption{Abundant Sample Algorithm: Theoretical Version}\label{alg:abundant_theory}
    \begin{algorithmic}
    \Require $n$, the dimension, $\tau$ the error rate.
    \State Run~\Cref{alg:optim_example} with hyperparameters specified in~\Cref{tab:hyperparameter,tab:shared_hyperparameter} to get a learned model $\model[\weight_T]$ and return the model.
    \end{algorithmic}
\end{algorithm}
\begin{algorithm}
    \caption{Abundant Sample Meta Algorithm For Hyperparameters Selection}\label{alg:abundant_meta}
    \begin{algorithmic}
    \Require $n$, the dimension, $\tau$ the error rate.
    \Require $\gamma$, the accuracy threshold, fixed as $80\%$ in our experiments,.
    \Require $Repeat$,  the number of different datasets to estimate $\rtime$, fixed as $3$ in our experiments
    \Require A set of hyperparameters profiles $\mathcal{P}$.
    \State Initialize an empty hashmap $\mathrm{Map}_t$ to record running time.
    \For{Profile $P \in \mathcal{P}$}
    \State Set $\mathrm{Map}_{\rtime}[P] = \infty$.
    \For{$\mathrm{r} \le Repeat$}
    \State Randomly generate secret $s$ with Hamming weight $\lfloor n\tau \rfloor$.
    \State Create an oracle sampler $\sampler$ with batch size $B$ and error rate $\tau$ corresponding to $s$.
    \State Sample a test dataset $\testset$ using $\sampler$, with size $O(n)$. 
    \State \Comment{Fixed as 131072 in our experiments.}
    \State Set stop criterion $\stopcriterion'$ as $\accstopcriterion(\testset, \gamma)$.
    \State Run a variant of~\Cref{alg:abundant} with stop criterion $\stopcriterion'$ and  profile $P$ and record running time $\rtime$.
    \State Set $\mathrm{Map}_{\rtime}[(B, \eta)] = \min\{\rtime, \mathrm{Map}_{\rtime}[(B, \eta)] \}$.
    \State \Comment{Only require solving by constant probability.}
    \EndFor
    \EndFor
    \State \Return $(P,\mathrm{Map}_{\rtime}[P])$ with the smallest $\mathrm{Map}_{\rtime}[P]$ for $P \in \mathcal{P}$. 
    \end{algorithmic}
\end{algorithm}

We also perform some theoretical analysis on the time complexity of our method, showing that the dependency on $\tau$ is merely $(\frac{1}{2} - \tau)^{-2}$. 
However, due to the complexity of our choice of the optimizer and the loss function in~\Cref{alg:abundant}, our analysis is conducted on a simpler version (\Cref{alg:abundant_theory}) with more clear theoretical structure.
The analysis is deferred to~\Cref{sec:theory_optimization}.



\subsection{Restricted Sample}\label{sec:method_restricted}

In~\Cref{setting:restricted}, the sample complexity is assumed to be highly limited. 
Due to the restriction on sample complexity, we could no longer expect the learned model to fully recover the secret directly as in~\Cref{sec:method_unlimited}.
Hence we design our algorithm to solve the decisional version of LPN and use neural network as a reduction method instead. We present our algorithm in~\Cref{alg:restricted}.
The returning value of~\Cref{alg:restricted} is with high probability the value of secret $s$ at index $n-1$.
In practice, the inner for loop of~\Cref{alg:restricted} is parallelized across multiple GPUs.

\begin{algorithm}
    \caption{Restricted Sample Algorithm}\label{alg:restricted}
    \begin{algorithmic}
    \Require $\dataset$ with $m$ samples drawn from LPN with dimension $n$ and error rate $\tau$.
    \Require $repeat$ the number of random initializations to try, typically set as $8$.
    \Require $\gamma$, the accuracy threshold.
    \State Split $\dataset$ into $\trainset$ and $\testset$, each with $\lfloor m/2 \rfloor$ sample.
    \For{Guess $g \in \{0,1\}$}
    \State Generate $\trainset^g = \{ (x[1:d-1], y + x[d] \times g \mod 2) \mid (x,y) \in \trainset \}$.
    \State Generate $\testset^g = \{ (x[1:d-1], y + x[d] \times g \mod 2) \mid (x,y) \in \testset \}$.
    \State Set sampler $\sampler$ as batch sampler with batch size $\lfloor m/2 \rfloor$ on $\trainset^g$.
    \For{$r \le repeat $}
    \State Run~\Cref{alg:optim_example} with the hyperparameters specified in~\Cref{tab:hyperparameter,tab:shared_hyperparameter} to get a learned model $\model[\weight_T]$.
    \If{the accuracy of $\model[\weight_T]$ on $\testset^g$ exceeds $\gamma$} {\Return $g$.}
    \EndIf
    \EndFor
    \EndFor
    \end{algorithmic}
\end{algorithm}

Again, there are some unspecified hyperparameters in~\Cref{alg:restricted} that need to be pivoted down by experiments.
In our experiments, we mainly consider $n \le 50$, $\tau \le 0.3$ and $m \in [2^{10}, 2^{20}]$. In this regime, we propose to set $\step = 300k$ and $\gamma$ as $1/2 + \sqrt{\log(20)/{m}}$. 
The dependency on $\tau$ is dropped here because the noise we considered here is relatively small. We observe in practice that the accuracy of test set on successful runs almost always exceeds this threshold by a large margin. For other hyperparameters including the exact value of sample size $m$, we apply meta algorithm~\Cref{alg:restricted_meta}.

We would like to stress a few major differences in hyperparameters selection between~\Cref{setting:abundant} and~\Cref{setting:restricted}.
\begin{enumerate}
    \item L2 regularization, or weight decay, is not helpful in~\Cref{setting:abundant}, but can reduce the sample complexity significantly in~\Cref{setting:restricted}.
    \item Under~\Cref{setting:restricted}, it is generally better to use the whole dataset as a batch instead of using a smaller batch size. 
    \item The learning rate required by~\Cref{alg:restricted} is typically smaller than the learning rate required by~\Cref{alg:abundant} by a factor of $10$ to $100$.
\end{enumerate}


\begin{algorithm}[t]
    \caption{Restricted Sample Meta Algorithm For Hyperparameters Selection}\label{alg:restricted_meta}
    \begin{algorithmic}
    \Require $n$, the dimension, $\tau$ the error rate.
    \Require A set of sample numbers $m_0 < m_1 < m_2 < ... < m_L$.
    \Require $Repeat$, the number of different datasets we tested on, fixed as $3$ in our experiments
    \Require A set of hyperparameters profiles $\mathcal{P}$.
    \For{Profile  $P \in \mathcal{P}$}
    \State Set $\mathrm{Map}_m[P] = 0$ to record the sample needed to perform reduction.
    \State Set low and high index to perform a binary search, $Left = 0$ and $Right = L$.
    \While{$Left \neq Right$}
    \State Middle index $Mid = \lfloor (Left + Right)/2 \rfloor$.
    \State Set sample number $m = m_{Mid}$.
    \State Set success Count $c = 0$.
    \For{$\mathrm{r} \le Repeat$}
    \State Randomly generate secret $s$ with Hamming weight $\lfloor n\tau \rfloor$ 
    \State Sample a dataset $\dataset$ generated with secret $s$ and error rate $\tau$, with size $m$. 
    \State Run a variant of~\Cref{alg:restricted} with hyperparameter profile $P$ 
    \State Increment success count $c$ by $1$ if the return value equals $s[d-1]$.
    \EndFor
    \If{$c \ge \lfloor 2Repeat / 3 \rfloor$} {Right = Mid}
    \EndIf
    \If{$c < \lfloor 2Repeat / 3 \rfloor$} {Left = Mid + 1}
    \EndIf
    \EndWhile
    \State Set $\mathrm{Map}_m[P] = m_{Left}$.
    \EndFor
    \State \Return $(P, \mathrm{Map}_m[P])$ with the smallest $\mathrm{Map}_m[P]$.
    \end{algorithmic}
\end{algorithm}


\subsection{Moderate Sample}\label{sec:method_abundant}
\begin{algorithm}[h]
    \caption{Moderate Sample Algorithm}\label{alg:moderate}
    \begin{algorithmic}
    \Require $\dataset$ with $m$ samples drawn from LPN with dimension $n$ and error rate $\tau$.
    \Require Repeat number $repeat$ for starting with different initializations, set to $1$ in our experiments.
    \Require Repeat number $repeat_{post}$ for post processing run, set to $20$ in our experiments.
    \Require The size of boosting set $m'$ for post processing run.
    \Require The hypothesis test error rate threshold $\tau'$.
    \State Set $m_1 = \frac{2n}{(1/2 - \tau)^2}$. \Comment{See Lemma 3 in \cite{DBLP:conf/crypto/EsserKM17}}
    \State Split the dataset with a training set $\trainingset$ of size $m - m_1$ and a test set $\testset$ of size $m_1$.
    \For{$r \le repeat$}
    \State Run~\Cref{alg:optim_example} with the parameters specified in~\Cref{tab:hyperparameter,tab:shared_hyperparameter} to get a learned model $\model[\weight_T]$.
    \State Randomly generate $m'$ boolean vector $x_i \in \{0,1\}^{n + 1}$ and use $\model[\weight_T]$ to predict the pseudo label $\one{\model[\weight_T](x_i[1:n]) > 0.5} + x_i[n+1] \mod 2$ to form $\boostingset$. 
    \State \Comment{Rebalance Step}
    \State Run Pooled Gaussian algorithm \cite{DBLP:conf/crypto/EsserKM17} on $\boostingset$ for $repeat_{post}$ number of times to get a set of possible secret (discard the last bit) using hypothesis test error rate threshold $\tau'$. 
    \State \Comment{Post Processing Step}
    \State Return the secret if one of them reaches accuracy $1 - \tau - \sqrt{\frac{3(\frac{1}{2} - \tau) n}{m_1}}$  on $\testset$.
    \EndFor
    \end{algorithmic}
\end{algorithm}



\Cref{setting:restricted} and~\Cref{setting:abundant} can be viewed as two extreme settings where in the first one only time complexity is considered and in the second one only sample complexity is considered. Although they both show interesting properties and strong performances, difficulties are faced 
when trying to fit them in the classical \emph{reduction-decoding} paradigm of LPN algorithms, in which the sample complexity after reduction is mediocre. This calls for investigating whether and how we can apply machine learning methods as a part of the \emph{reduction-decoding} paradigm, especially as the decoding algorithm.

Our work gives an affirmative answer to the first question and proposes the following~\Cref{alg:moderate} as a candidate. 
We would like to point out that the algorithm design process of~\Cref{alg:moderate} centered around LPN problems with medium dimension $n \approx 20$ and heavy error rate $\tau > 0.495$, as this is the 
setting after the reduction phase where classical algorithms like Pooled Gaussian and MMT require huge time complexity.
Similar to the previous section, a meta algorithm is required to determine the running time $\rtime$ and predicted accuracy $\tau'$. The algorithm is analogous to~\Cref{alg:abundant_meta} and is omitted here.


One can see the major differences between~\Cref{alg:abundant} and~\Cref{alg:moderate} is that
\begin{enumerate}
    \item The sampler is replaced by the fixed batch sampler. We use this bootstrapping technique to simulate sampling from $\distribution$ with the sample we possess.
    \item The direct inference is replaced by a pooled Gaussian step. This is because the training part of~\Cref{alg:moderate} typically returns a model with low accuracy, for example around $52\%$ on clean data when $n = 20, \tau = 0.498$ and $m - m_1  = 1e8$. We empirically observe that the rebalance and post-processing step usually takes less than 2 minutes to recover the correct secret under the typical setting. The experiment details are deferred to~\Cref{sec:experiment}.
\end{enumerate}

To simulate the training dynamics of~\Cref{alg:moderate} with~\Cref{alg:abundant}, we propose to use the same hyperparameter setting except for the sampler. The initial sample $m$ under this setting is mostly determined by the reduction phase. For example, in our case study in~\Cref{sec:experiment}, it is set to $1e8$ as the BKW algorithm reduces LPN problem with $n = 125, \tau = 0.2, m = 1.2e10$ to LPN problem with 
$n = 26, p = 0.498, m = 1.1e8$ in about $0.5$ hours with 128 cores server.

