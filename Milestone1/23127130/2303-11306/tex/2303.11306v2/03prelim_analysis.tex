\input{figures/overview.tex}


\section{Preliminaries}


\paragraph{Latent Diffusion Models}
We demonstrate our method applied over the publicly available Stable Diffusion model which is built over the Latent Diffusion Models (LDM) architecture~\cite{Rombach2021HighResolutionIS}. 
In LDM, a diffusion model operates in the latent space of a pretrained autoencoder. 

The denoising network is implemented as a UNET and consists of self-attention layers followed by cross-attention layers.
At each timestep $t$, the noised spatial code $z_t$ is passed as input to the denoising network. The intermediate features of the network, denoted by $\phi(z_t)$, receive information from the self and cross-attention layers. The attention mechanism consists of three main components: Keys ($K$), Queries ($Q$), and Values ($V$). The Keys and the Queries together form an attention map, which is multiplied by the Values. In this work, we utilize the attention maps of both the self and cross-attention layers.
\vspace{-16pt}

\paragraph{Cross-Attention Layers in LDM}
Text guidance in LDM is performed using the cross-attention mechanism. 
Specifically, denoting the text encoding by $c$, $Q=f_Q(\phi(z_t))$, $K=f_K(c)$, and $V=f_V(c)$ are obtained using learned linear layers $f_Q, f_K, f_V$. 
Each token in the text prompt corresponds to an attention map formed by the Queries and the Keys, which is multiplied by each token's Values. Therefore, intuitively, the Keys and the Queries control the placement of each token, while the Values control its shape and appearance, as we later show in the supplementary materials. It is important to note, however, that these components are not fully disentangled.

By the definition of the cross-attention mechanism, it can be observed that the encoding of the text prompt is fed only to $f_K$ and $f_V$, and therefore the Keys and the Values are the only components affected directly by the text prompt.
\vspace{-16pt}


\paragraph{Self-Attention Layers in LDM}
Self-attention layers model the relation between each pixel to all the other pixels. In LDM, each such pixel corresponds to a patch in the final generated image. Previous works~\cite{hertz2022prompt, pnpDiffusion2022} have shown that self-attention strictly controls the image layout and objects' shapes in it, and is therefore useful to preserve the input image structure in image editing. In our work, we aim to modify the object of interest and preserve the remainder of the image. Thus, injecting the entire self-attention map does not allow for shape variations on the object of interest as was demonstrated in the above works.

