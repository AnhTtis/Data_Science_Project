@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}


@article{Bailis2017InfrastructureFU,
  title={Infrastructure for Usable Machine Learning: The Stanford DAWN Project},
  author={Peter D. Bailis and Kunle Olukotun and Christopher R{\'e} and Matei A. Zaharia},
  journal={ArXiv},
  year={2017},
  volume={abs/1705.07538}
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@Book{VilleBook,
  author =       "Tuulo, Ville",
  title =        "Effective Data Science Infrastructure: How to make data scientists productive",
  publisher =    "Manning",
  edition =      "1st",
  year =         "2022"
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@article{Tsagkias2020ChallengesAR,
  title={Challenges and research opportunities in ecommerce search and recommendations},
  author={Tsagkias, Manos and King, Tracy Holloway and Kallumadi, Surya and Murdock, Vanessa and de Rijke, Maarten},
journal   = {{SIGIR} Forum},  volume={54},
  number={1},
  pages={1--23},
  year={2021},
  organization={ACM New York, NY, USA}
}

@misc{https://doi.org/10.48550/arxiv.2204.03972,
  doi = {10.48550/ARXIV.2204.03972},
  
  url = {https://arxiv.org/abs/2204.03972},
  
  author = {Chia, Patrick John and Attanasio, Giuseppe and Bianchi, Federico and Terragni, Silvia and Magalhães, Ana Rita and Goncalves, Diogo and Greco, Ciro and Tagliabue, Jacopo},
  
  keywords = {Information Retrieval (cs.IR), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {FashionCLIP: Connecting Language and Images for Product Representations},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

@inproceedings{bianchi-etal-2021-query2prod2vec,
    title = "{Q}uery2{P}rod2{V}ec: Grounded Word Embeddings for e{C}ommerce",
    author = "Bianchi, Federico  and
      Tagliabue, Jacopo  and
      Yu, Bingqing",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Papers",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-industry.20",
    doi = "10.18653/v1/2021.naacl-industry.20",
    pages = "154--162",
    abstract = "We present Query2Prod2Vec, a model that grounds lexical representations for product search in product embeddings: in our model, meaning is a mapping between words and a latent space of products in a digital shop. We leverage shopping sessions to learn the underlying space and use merchandising annotations to build lexical analogies for evaluation: our experiments show that our model is more accurate than known techniques from the NLP and IR literature. Finally, we stress the importance of data efficiency for product search outside of retail giants, and highlight how Query2Prod2Vec fits with practical constraints faced by most practitioners.",
}

@inproceedings{45530,
title	= {Deep Neural Networks for YouTube Recommendations},
author	= {Paul Covington and Jay Adams and Emre Sargin},
year	= {2016},
booktitle	= {Proceedings of the 10th ACM Conference on Recommender Systems},
address	= {New York, NY, USA}
}

@article{bianchi2020bert,
  title={BERT Goes Shopping: Comparing Distributional Models for Product Representations},
  author={Bianchi, Federico and Yu, Bingqing and Tagliabue, Jacopo},
  journal={arXiv preprint arXiv:2012.09807},
  year={2020}
}



@article{Chia2021AreYS,
  title={"Are you sure?": Preliminary Insights from Scaling Product Comparisons to Multiple Shops},
  author={Patrick John Chia and Bingqing Yu and Jacopo Tagliabue},
  journal={ArXiv},
  year={2021},
  volume={abs/2107.03256}
}

@misc{towardDataScienceJT,
  title= {MLOps without Much Ops},
  author= {Tagliabue, Jacopo},
  url = {https://towardsdatascience.com/mlops-without-much-ops-d17f502f76e8},
  year= {2022}
}

@misc{ericMLOPSMess,
  title= {MLOps Is a Mess But That's to be Expected},
  author= {Eric, Mihail},
  url = {https://www.mihaileric.com/posts/mlops-is-a-mess/},
  year= {2022}
}

@misc{https://doi.org/10.48550/arxiv.2209.05310,
  doi = {10.48550/ARXIV.2209.05310},
  
  url = {https://arxiv.org/abs/2209.05310},
  
  author = {Anil, Rohan and Gadanho, Sandra and Huang, Da and Jacob, Nijith and Li, Zhuoshu and Lin, Dong and Phillips, Todd and Pop, Cristina and Regan, Kevin and Shamir, Gil I. and Shivanna, Rakesh and Yan, Qiqi},
  
  keywords = {Information Retrieval (cs.IR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {On the Factory Floor: ML Engineering for Industrial-Scale Ads Recommendation Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{datasurvery,
  title= {What Data Scientists Tell Us About AI Model Training Today},
  author= {{Dimensional Research}},
  url = {https://content.alegion.com/dimensional-researchs-survey},
  year= {2022}
}

@misc{stonebraker12,
title= {What Does 'Big Data' Mean?},
  author= {Stonebraker,Michael },
  url = {https://cacm.acm.org/blogs/blog-cacm/155468-what-does-big-data-mean/fulltext},
  year= {2012}

}

@misc{hbr2022,
  title= {Why Your Company Needs Data-Product Managers},
  author= {Davenport, Thomas H. and Bean, Randy and Jain,  Shail},
  url = {https://hbr.org/2022/10/why-your-company-needs-data-product-managers},
  year= {2022}
}


@misc{https://doi.org/10.48550/arxiv.2207.05772,
  doi = {10.48550/ARXIV.2207.05772},
  url = {https://arxiv.org/abs/2207.05772},
  author = {Tagliabue, Jacopo and Bianchi, Federico and Schnabel, Tobias and Attanasio, Giuseppe and Greco, Ciro and Moreira, Gabriel de Souza P. and Chia, Patrick John},
  title = {EvalRS: a Rounded Evaluation of Recommender Systems},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{CoveoSIGIR2021,
author = {Tagliabue, Jacopo and Greco, Ciro and Roy, Jean-Francis and Bianchi, Federico and Cassani, Giovanni and Yu, Bingqing and Chia, Patrick John},
title = {SIGIR 2021 E-Commerce Workshop Data Challenge},
year = {2021},
booktitle = {SIGIR eCom 2021}
}

@inproceedings{10.1145/3299869.3320212,
author = {Raasveldt, Mark and M\"{u}hleisen, Hannes},
title = {DuckDB: An Embeddable Analytical Database},
year = {2019},
isbn = {9781450356435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299869.3320212},
doi = {10.1145/3299869.3320212},
abstract = {The immense popularity of SQLite shows that there is a need for unobtrusive in-process data management solutions. However, there is no such system yet geared towards analytical workloads. We demonstrate DuckDB, a novel data management system designed to execute analytical SQL queries while embedded in another process. In our demonstration, we pit DuckDB against other data management solutions to showcase its performance in the embedded analytics scenario. DuckDB is available as Open Source software under a permissive license.},
booktitle = {Proceedings of the 2019 International Conference on Management of Data},
pages = {1981–1984},
numpages = {4},
location = {Amsterdam, Netherlands},
series = {SIGMOD '19}
}







@article{doi:10.1089/big.2013.0037,
author = {Junqu\'{e} de Fortuny, Enric and Martens, David and Provost, Foster},
title = {Predictive Modeling With Big Data: Is Bigger Really Better?},
journal = {Big Data},
volume = {1},
number = {4},
pages = {215-226},
year = {2013},
doi = {10.1089/big.2013.0037},
    note ={PMID: 27447254},

URL = { 
        https://doi.org/10.1089/big.2013.0037
    
},
eprint = { 
        https://doi.org/10.1089/big.2013.0037
    
}
}




@misc{luigi,
title= {Luigi},
author={{Spotify Data Team}},
url={https://github.com/spotify/luigi},
year= {2019}
}

@misc{airflow,
title= {Apache Airflow},
author={{Apache Foundation}},
url={https://airflow.apache.org/},
year= {2022}
}

@misc{prefect,
title= {Prefect},
author={{Prefect}},
url={https://github.com/PrefectHQ/prefect},
year= {2022}
}

@misc{gartnerenterprise,
title= {Artificial Intelligence and the Enterprise},
  author= { Pettey,Christy},
  url = {https://www.gartner.com/smarterwithgartner/artificial-intelligence-and-the-enterprise},
  year= {2017}
}


@misc{https://doi.org/10.48550/arxiv.2209.09125,
  doi = {10.48550/ARXIV.2209.09125},
  
  url = {https://arxiv.org/abs/2209.09125},
  
  author = {Shankar, Shreya and Garcia, Rolando and Hellerstein, Joseph M. and Parameswaran, Aditya G.},
  
  keywords = {Software Engineering (cs.SE), Human-Computer Interaction (cs.HC), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Operationalizing Machine Learning: An Interview Study},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{Mitchell2019ModelCF,
  title={Model Cards for Model Reporting},
  author={Margaret Mitchell and Simone Wu and Andrew Zaldivar and Parker Barnes and Lucy Vasserman and Ben Hutchinson and Elena Spitzer and Inioluwa Deborah Raji and Timnit Gebru},
  journal={Proceedings of the Conference on Fairness, Accountability, and Transparency},
  year={2019}
}

@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{sklearn_api,
  author    = {Lars Buitinck and Gilles Louppe and Mathieu Blondel and
               Fabian Pedregosa and Andreas Mueller and Olivier Grisel and
               Vlad Niculae and Peter Prettenhofer and Alexandre Gramfort
               and Jaques Grobler and Robert Layton and Jake VanderPlas and
               Arnaud Joly and Brian Holt and Ga{\"{e}}l Varoquaux},
  title     = {{API} design for machine learning software: experiences from the scikit-learn
               project},
  booktitle = {ECML PKDD Workshop: Languages for Data Mining and Machine Learning},
  year      = {2013},
  pages = {108--122},
}


@inproceedings{NIPS2012_6aca9700,
 author = {Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Ranzato, Marc\textquotesingle aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and Le, Quoc and Ng, Andrew},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Large Scale Distributed Deep Networks},
 url = {https://proceedings.neurips.cc/paper/2012/file/6aca97005c68f1206823815f66102863-Paper.pdf},
 volume = {25},
 year = {2012}
}


@inproceedings{Bennett2007TheNP,
  title={The Netflix Prize},
  author={James Bennett and Stan Lanning},
  year={2007}
}




@misc{gartnerproduction,
title= {85\% of big data projects fail, but your developers can help yours succeed},
  author= {Asay, Matt},
  url = {https://www.techrepublic.com/article/85-of-big-data-projects-fail-but-your-developers-can-help-yours-succeed/},
  year= {2017}
}

@misc{villeyoutube,
    title = {Metaflow: The ML Infrastructure at Netflix},
    author = {Ville Tuulos},
    url={https://www.youtube.com/watch?v=JCbOI_1ZA5E},
    year = {2021}
}

@inproceedings{43146,
title	= {Machine Learning: The High Interest Credit Card of Technical Debt},
author	= {D. Sculley and Gary Holt and Daniel Golovin and Eugene Davydov and Todd Phillips and Dietmar Ebner and Vinay Chaudhary and Michael Young},
year	= {2014},
booktitle	= {SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop)}
}



@inproceedings{10.1145/3411764.3445518,
author = {Sambasivan, Nithya and Kapania, Shivani and Highfill, Hannah and Akrong, Diana and Paritosh, Praveen and Aroyo, Lora M},
title = {“Everyone Wants to Do the Model Work, Not the Data Work”: Data Cascades in High-Stakes AI},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445518},
doi = {10.1145/3411764.3445518},
abstract = {AI models are increasingly applied in high-stakes domains like health and conservation. Data quality carries an elevated significance in high-stakes AI due to its heightened downstream impact, impacting predictions like cancer detection, wildlife poaching, and loan allocations. Paradoxically, data is the most under-valued and de-glamorised aspect of AI. In this paper, we report on data practices in high-stakes AI, from interviews with 53 AI practitioners in India, East and West African countries, and USA. We define, identify, and present empirical evidence on Data Cascades—compounding events causing negative, downstream effects from data issues—triggered by conventional AI/ML practices that undervalue data quality. Data cascades are pervasive (92\% prevalence), invisible, delayed, but often avoidable. We discuss HCI opportunities in designing and incentivizing data excellence as a first-class citizen of AI, resulting in safer and more robust systems for all.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {39},
numpages = {15},
keywords = {data collectors, India, application-domain experts, Uganda, high-stakes AI, AI, Ghana, ML, Data, data politics, data cascades, USA, Kenya, developers, Nigeria, raters, data quality},
location = {Yokohama, Japan},
series = {CHI '21}
}

@article{DBLP:journals/corr/abs-1909-07930,
  author    = {Piero Molino and
               Yaroslav Dudin and
               Sai Sumanth Miryala},
  title     = {Ludwig: a type-based declarative deep learning toolbox},
  journal   = {CoRR},
  volume    = {abs/1909.07930},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.07930},
  eprinttype = {arXiv},
  eprint    = {1909.07930},
  timestamp = {Tue, 24 Sep 2019 11:33:51 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-07930.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{McSherry2015ScalabilityBA,
  title={Scalability! But at what COST?},
  author={Frank McSherry and Michael Isard and Derek Gordon Murray},
  booktitle={HotOS},
  year={2015}
}

@book{skelton2019team,
  title={Team Topologies: Organizing Business and Technology Teams for Fast Flow},
  author={Skelton, M. and Malan, R. and Pais, M.},
  isbn={9781942788812},
  lccn={2019016691},
  series={G - Reference,Information and Interdisciplinary Subjects Series},
  url={https://books.google.com/books?id=oFdRuAEACAAJ},
  year={2019},
  publisher={IT Revolution}
}




@software{gong_abe_2022_7094191,
  author       = {Gong, Abe and
                  Campbell, James and
                  Superconductive and
                  Great Expectations},
  title        = {Great Expectations},
  month        = sep,
  year         = 2022,
  note         = {{If you use this software, please cite it using 
                   these metadata.}},
  publisher    = {Zenodo},
  version      = {0.15.24},
  doi          = {10.5281/zenodo.7094191},
  url          = {https://doi.org/10.5281/zenodo.7094191}
}

@inproceedings{10.1145/3487553.3524215,
    author = {Chia, Patrick John and Tagliabue, Jacopo and Bianchi, Federico and He, Chloe and Ko, Brian},
    title = {Beyond NDCG: Behavioral Testing of Recommender Systems with RecList},
    year = {2022},
    isbn = {9781450391306},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3487553.3524215},
    doi = {10.1145/3487553.3524215},
    pages = {99–104},
    numpages = {6},
    keywords = {recommender systems, open source, behavioral testing},
    location = {Virtual Event, Lyon, France},
    series = {WWW '22 Companion}
}

@INPROCEEDINGS{5496972,  author={Shvachko, Konstantin and Kuang, Hairong and Radia, Sanjay and Chansler, Robert},  booktitle={2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST)},   title={The Hadoop Distributed File System},   year={2010},  volume={},  number={},  pages={1-10},  doi={10.1109/MSST.2010.5496972}}

@inproceedings{10.5555/2228298.2228301,
author = {Zaharia, Matei and Chowdhury, Mosharaf and Das, Tathagata and Dave, Ankur and Ma, Justin and McCauley, Murphy and Franklin, Michael J. and Shenker, Scott and Stoica, Ion},
title = {Resilient Distributed Datasets: A Fault-Tolerant Abstraction for in-Memory Cluster Computing},
year = {2012},
publisher = {USENIX Association},
address = {USA},
abstract = {We present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDDs are motivated by two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools. In both cases, keeping data in memory can improve performance by an order of magnitude. To achieve fault tolerance efficiently, RDDs provide a restricted form of shared memory, based on coarse-grained transformations rather than fine-grained updates to shared state. However, we show that RDDs are expressive enough to capture a wide class of computations, including recent specialized programming models for iterative jobs, such as Pregel, and new applications that these models do not capture. We have implemented RDDs in a system called Spark, which we evaluate through a variety of user applications and benchmarks.},
booktitle = {Proceedings of the 9th USENIX Conference on Networked Systems Design and Implementation},
pages = {2},
numpages = {1},
location = {San Jose, CA},
series = {NSDI'12}
}
@misc{ReGithub,
  author = {Goel,Karan and Orr, Laurel},
  title = {Data-Centric AI},
  year = {2012},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/HazyResearch/data-centric-ai}}
}

@online{NG,
  title = {AI Doesn’t Have to Be Too Complicated or Expensive for Your Business},
  author = {Andrew Ng},
  year = 2021,
  url = {https://hbr.org/2021/07/ai-doesnt-have-to-be-too-complicated-or-expensive-for-your-business},
  urldate = {2021-09-21}
}

@misc{algoritmia2021,
title= {2021 enterprise trends in machine learning},
  author= {{Algorithmia Research}},
  url = {https://info.algorithmia.com/hubfs/2020/Reports/2021-Trends-in-ML/Algorithmia_2021_enterprise_ML_trends.pdf},
  year= {2021}
}

@misc{algo2019,
    title= {Add It Up: How Long Does a Machine Learning Deployment Take?},
    author= {Hecht,Lawrence E. },
    url = {https://thenewstack.io/add-it-up-how-long-does-a-machine-learning-deployment-take/},
    year= {2021}
}


@misc{hbr2012,
    title= {Data Scientist: The Sexiest Job of the 21st Century},
    author= {Davenport,Thomas H.  and Patil, DJ},
    url = {https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century},
    year= {2012}
}

@article{DBLP:journals/corr/abs-2110-13601,
  author    = {Jacopo Tagliabue and
               Ville Tuulos and
               Ciro Greco and
               Valay Dave},
  title     = {{DAG} Card is the new Model Card},
  journal   = {CoRR},
  volume    = {abs/2110.13601},
  year      = {2021},
  url       = {https://arxiv.org/abs/2110.13601},
  eprinttype = {arXiv},
  eprint    = {2110.13601},
  timestamp = {Thu, 28 Oct 2021 15:25:31 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2110-13601.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{43826,
title	= {Kubernetes - Scheduling the Future at Cloud Scale},
author	= {David K. Rensin},
year	= {2015},
URL	= {http://www.oreilly.com/webops-perf/free/kubernetes.csp},
booktitle	= {OSCON 2015},
pages	= {All},
address	= {1005 Gravenstein Highway North Sebastopol, CA 95472}
}



@techreport{49050,
title	= {Learning-to-Rank with BERT in TF-Ranking},
author	= {Shuguang Han and Xuanhui Wang and Mike Bendersky and Marc Najork},
year	= {2020},
institution	= {arXiv}
}

@article{10.1145/3475965.3479315,
author = {Molino, Piero and R\'{e}, Christopher},
title = {Declarative Machine Learning Systems: The Future of Machine Learning Will Depend on It Being in the Hands of the Rest of Us.},
year = {2021},
issue_date = {May-June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1542-7730},
url = {https://doi.org/10.1145/3475965.3479315},
doi = {10.1145/3475965.3479315},
abstract = {The people training and using ML models now are typically experienced developers with years of study working within large organizations, but the next wave of ML systems should allow a substantially larger number of people, potentially without any coding skills, to perform the same tasks. These new ML systems will not require users to fully understand all the details of how models are trained and used for obtaining predictions, but will provide them a more abstract interface that is less demanding and more familiar. Declarative interfaces are well-suited for this goal, by hiding complexity and favoring separation of interest, and ultimately leading to increased productivity.},
journal = {Queue},
month = {jun},
pages = {46–76},
numpages = {31}
}

@inproceedings{10.1145/3292500.3330723,
author = {Chen, Mia Xu and Lee, Benjamin N. and Bansal, Gagan and Cao, Yuan and Zhang, Shuyuan and Lu, Justin and Tsay, Jackie and Wang, Yinan and Dai, Andrew M. and Chen, Zhifeng and Sohn, Timothy and Wu, Yonghui},
title = {Gmail Smart Compose: Real-Time Assisted Writing},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330723},
doi = {10.1145/3292500.3330723},
abstract = {In this paper, we present Smart Compose, a novel system for generating interactive, real-time suggestions in Gmail that assists users in writing mails by reducing repetitive typing. In the design and deployment of such a large-scale and complicated system, we faced several challenges including model selection, performance evaluation, serving and other practical issues. At the core of Smart Compose is a large-scale neural language model. We leveraged state-of-the-art machine learning techniques for language model training which enabled high-quality suggestion prediction, and constructed novel serving infrastructure for high-throughput and real-time inference. Experimental results show the effectiveness of our proposed system design and deployment approach. This system is currently being served in Gmail.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining},
pages = {2287–2295},
numpages = {9},
keywords = {large-scale serving, smart compose, assisted writing, language model},
location = {Anchorage, AK, USA},
series = {KDD '19}
}



@Inproceedings{Mohan2019,
 author = {Vijai Mohan and Yiwei Song and Priyanka Nigam and Choon Hui Teo and Weitian Ding and Vihan Lakshman and Ankit Shingavi and Hao Gu and Bing Yin},
 title = {Semantic product search},
 year = {2019},
 url = {https://www.amazon.science/publications/semantic-product-search},
 booktitle = {KDD 2019},
}

@misc{cnn,
  author = {Kelly Davis},
  title = {{Accelerating ML within CNN}},
  howpublished = "\url{https://medium.com/cnn-digital/accelerating-ml-within-cnn-983f6b7bd2eb/}",
  year = {2021}, 
  note = "[Online; accessed 19-Feb-2023]"
}

@inproceedings{chia-etal-2022-come,
    title = "{``}Does it come in black?{''} {CLIP}-like models are zero-shot recommenders",
    author = "Chia, Patrick John  and
      Tagliabue, Jacopo  and
      Bianchi, Federico  and
      Greco, Ciro  and
      Goncalves, Diogo",
    booktitle = "Proceedings of the Fifth Workshop on e-Commerce and NLP (ECNLP 5)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.ecnlp-1.22",
    doi = "10.18653/v1/2022.ecnlp-1.22",
    pages = "191--198",
    abstract = "Product discovery is a crucial component for online shopping. However, item-to-item recommendations today do not allow users to explore changes along selected dimensions: given a query item, can a model suggest something similar but in a different color? We consider item recommendations of the comparative nature (e.g. {``}something darker{''}) and show how CLIP-based models can support this use case in a zero-shot manner. Leveraging a large model built for fashion, we introduce GradREC and its industry potential, and offer a first rounded assessment of its strength and weaknesses.",
}

@misc{jacopo_medium,
  author = {Jacopo Tagliabue},
  title = {{Applied Research at Reasonable Scale}},
  howpublished = "\url{https://medium.com/the-techlife/applied-research-at-reasonable-scale-8a74d2beed89}",
  year = {2022}, 
  note = "[Online; accessed 19-Feb-2023]"
}



@misc{realtor,
  author = {Nicole Murphy},
  title = {{Improving Data Science Processes to Speed Innovation at Realtor.com}},
  howpublished = "\url{https://medium.com/realtor-com-innovation-blog/improving-data-science-processes-to-speed-innovation-at-realtor-com-b6b90fa530dc/}",
  year = {2021}, 
  note = "[Online; accessed 19-Feb-2023]"
}

@article{Naturearticle,
author = {Chia, Patrick and Attanasio, Giuseppe and Bianchi, Federico and Terragni, Silvia and Magalhães, Ana and Goncalves, Diogo and Greco, Ciro and Tagliabue, Jacopo},
year = {2022},
month = {11},
pages = {},
title = {Contrastive language and vision learning of general fashion concepts},
volume = {12},
journal = {Scientific Reports},
doi = {10.1038/s41598-022-23052-9}
}

@misc{23andme,
  author = {Manoj Ganesan},
  title = {{Developing safe and reliable ML products at 23andMe}},
  howpublished = "\url{https://medium.com/23andme-engineering/machine-learning-eeee69d40736}",
  year = {2021}, 
  note = "[Online; accessed 19-Feb-2023]"
}

@misc{dataOpsblog,
title= {DataOps and MLOps for Reasonable Organizations},
  author= {Jacopo Tagliabue, Hugo Bowne-Anderson},
  url = {https://outerbounds.com/blog/dataops-mlops-reasonable-organizations/},
  year= {2022},
  note = "[Online; accessed 19-Feb-2023]"
}




@inproceedings{tagliabue-etal-2021-bert,
    title = "{BERT} Goes Shopping: Comparing Distributional Models for Product Representations",
    author = "Bianchi, Federico  and
      Yu, Bingqing  and
      Tagliabue, Jacopo",
    booktitle = "Proceedings of the 4th Workshop on e-Commerce and NLP",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.ecnlp-1.1",
    doi = "10.18653/v1/2021.ecnlp-1.1",
    pages = "1--12",
    abstract = "Word embeddings (e.g., word2vec) have been applied successfully to eCommerce products through prod2vec. Inspired by the recent performance improvements on several NLP tasks brought by contextualized embeddings, we propose to transfer BERT-like architectures to eCommerce: our model - Prod2BERT - is trained to generate representations of products through masked session modeling. Through extensive experiments over multiple shops, different tasks, and a range of design choices, we systematically compare the accuracy of Prod2BERT and prod2vec embeddings: while Prod2BERT is found to be superior in several scenarios, we highlight the importance of resources and hyperparameters in the best performing models. Finally, we provide guidelines to practitioners for training embeddings under a variety of computational and data constraints.",
}

@article{Tagliabue2021DAGCI,
  title={DAG Card is the new Model Card},
  author={Jacopo Tagliabue and Ville H. Tuulos and Ciro Greco and Valay Dave},
  journal={ArXiv},
  year={2021},
  volume={abs/2110.13601}
}


@inproceedings{10.1145/3460231.3474604,
author = {Tagliabue, Jacopo},
title = {You Do Not Need a Bigger Boat: Recommendations at Reasonable Scale in a (Mostly) Serverless and Open Stack},
year = {2021},
isbn = {9781450384582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460231.3474604},
doi = {10.1145/3460231.3474604},
abstract = {We argue that immature data pipelines are preventing a large portion of industry practitioners from leveraging the latest research on recommender systems. We propose our template data stack for machine learning at “reasonable scale”, and show how many challenges are solved by embracing a serverless paradigm. Leveraging our experience, we detail how modern open source tools can provide a pipeline processing terabytes of data with minimal infrastructure work.},
booktitle = {Fifteenth ACM Conference on Recommender Systems},
pages = {598–600},
numpages = {3},
keywords = {MLOps, serverless computing, recommender systems},
location = {Amsterdam, Netherlands},
series = {RecSys '21}
}