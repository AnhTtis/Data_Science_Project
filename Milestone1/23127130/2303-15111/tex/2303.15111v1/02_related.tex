\section{Related work}
\label{sec:related}
\emph{Visual attribute} has been widely studied to understand how visual properties can be learned from objects.  The pioneering work by Ferrari and Zisserman~\cite{ferrari2007learning} learned visual attributes using a probabilistic generative model. The successive work by Lampert \etal~\cite{lampert2009learning} used visual attributes to detect unseen objects with an attribute-based multi-label classification. Similarly, Patterson \etal~\cite{patterson2016coco} proposed Economic Labeling Algorithm (ELA) to discover multi-label attributes for objects. Different from multi-label classification, other works~\cite{chen2014inferring,hwang2011sharing,farhadi2009describing,mahajan2011joint} learned attribute-object relationship to generalize attribute feature across all object categories based on probabilistic models. Visual attributes also benefit downstream tasks, \eg, object recognition~\cite{nan2019recognizing,isola2015discovering,farhadi2010attribute}, action recognition~\cite{alayrac2017joint,fathi2013modeling,mccandless2013object}, image captioning~\cite{ordonez2011im2text,kulkarni2013babytalk}, and semi-supervised learning~\cite{shrivastava2012constrained}.

\emph{Compositional zero-shot learning (CZSL)} is a special case of zero-shot learning (ZSL)~\cite{palatucci2009zero,xian2017zero,xian2018feature,socher2013zero,romera2015embarrassingly}, aims at recognizing unseen attribute-object compositions learning from seen compositions. Misra \etal~\cite{misra2017red} first termed and studied CZSL by projecting composed primitives and visual features to a joint embedding space. Nagarajan \etal~\cite{nagarajan2018attributes} formulated attributes as matrix operators applied on object vectors. Purushwalkam \etal~\cite{purushwalkam2019task} introduced a task-driven modular architecture to learn unseen compositions by re-weighting a set of sub-tasks. Wei \etal~\cite{wei2019adversarial} generated attribute-object compositions with GAN~\cite{goodfellow2014generative} to match visual features. Li \etal~\cite{li2020symmetry} proposed symmetry principle of attribute-object transformation under the supervision of group axioms. Naeem \etal~\cite{naeem2021learning} and Mancini \etal~\cite{mancini2022learning} used graph convolutional networks to extract attribute-object representations. Recently, some works shift their interest from word composing to visual disentanglement. Atzmon \etal~\cite{atzmon2020causal} solved CZSL from a causal perspective to learn disentangled representations. Ruis \etal~\cite{ruis2021independent} proposed to learn prototypical representations of objects and attributes. Li \etal~\cite{li2022siamese} disentangled visual features into a Siamese contrastive space and entangled them with a generative model. Saini \etal~\cite{Saini_2022_CVPR} extracted visual similarity from spatial features to disentangle attributes and objects. Zhang \etal~\cite{zhang2022learning} treated CZSL as a domain generalization task, learning attribute- and object-invariant domains. A more realistic open-world CZSL setting was studied in \cite{mancini2021open,mancini2022learning,karthik2022kg}, which considered all possible compositions in testing. Very recently, an inspiring work by Nayak \etal~\cite{nayak2022learning} introduced compositional soft prompts to CLIP~\cite{radford2021learning} to tackle CZSL problem.

\emph{Attention mechanism} has been well studied by non-local neural networks~\cite{wang2018non} in computer vision and transformers~\cite{vaswani2017attention} in machine translation. Dosovitskiy \etal~\cite{dosovitskiy2020vit} adapted transformer architecture to computer vision field, proving its comparable efficiency over traditional CNNs. Inspired by the multi-head self-attention implemented by transformers, our work exploits efficient attention as disentangler for CZSL.

