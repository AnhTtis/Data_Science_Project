\section{Related Work}
\label{related}
The two broad categories of dialog systems are open-ended and task-oriented dialog systems. In the following, we summarize the personalization aspect of related work for both categories.


\stitle{Personalized Open-ended Dialogue Systems.}
Among the earlier attempts to personalize open-ended dialog systems, \cite{li2016persona} proposes learning interlocutor persona embeddings and adapting the conversation style accordingly. 
Researchers have since proposed a variety of methods, including persona information fusion~\cite{mazare2018training,zhang2018personalizing}, multi-task learning~\cite{luan2017multi},
transfer learning~\cite{yang2017personalized,zhang2019neural},
meta learning~\cite{madotto2019personalizing},
persona incorporation into the sequence-to-sequence framework~\cite{gulcehre2016pointing,li2016persona},
persona-conditioned RNN-based model~\cite{ficler2017controlling},
persona memory-conditioned variational autoencoders~\cite{song2019exploiting},
response selection using  memory networks~\cite{zhang2018personalizing},
topical information usage~\cite{xu2020neural},
persona pre-training~\cite{herzig2017neural,zheng2020pre}, and
extra training procedures for personalization~\cite{qian2017assigning,herzig2017neural}.
While many of these works have proven useful for assigning personalities or language styles to open-ended dialog systems, they are ineffective for task-oriented dialog systems.
We propose that, rather than assigning personalities to agents (i.e., dialog systems), make them more adaptive to their different kinds of interlocutors in task-oriented dialog settings.


\stitle{Personalized Task-oriented Dialogue
Systems.}
Comparatively to open-domain dialog systems, personalized task-oriented dialog systems are under-explored. In fact, to the best of our knowledge, \myspecial{personalized bAbI dialogue}~\cite{joshi2017personalization} is the only publicly available benchmark for the evaluation of task-oriented dialog systems.
Most of the existing work~\cite{joshi2017personalization,luo2019learning,madotto2018mem2seq,wu2019global,pei2021cooperative} use memory networks by concatenating profile information and dialog memory~\cite{joshi2017personalization}, combining style information~\cite{luo2019learning}, query generation via RNN-based decoder~\cite{madotto2018mem2seq}, local and global encoders~\cite{wu2019global}. 
Similarly, cooperative memory network have been proposed~\cite{pei2021cooperative} to handle the case, where only partial profile information is available. 
All of these works follow supervised learning approaches and require a large amount of labeled training data for each user profile. 
In contrast to previous work, we employ deep reinforcement learning to personalize task-oriented dialog systems in the unsupervised setting without requiring any labeled training data. 
This work leverages pre-trained language models and zero-shot learning for natural language understanding and generation, and adapts its responses to a wide range of user profiles in unsupervised way.
Nonetheless, it is noteworthy to mention that several key ideas leveraged in this work have been used for task-oriented dialog systems such as deep reinforcement learning for dialog policy generation~\cite{le2021predictable,le2021generating} and paraphrasing~\cite{siddique2020unsupervised}, zero-shot learning for
intent detection~\cite{siddique2021generalized} and slot filling~\cite{siddique2021linguistically}, and language models for anaphora resolution~\cite{maqbool2022zero} and response generation~\cite{farooq2020app}. However, none of these works have proposed to personalizing dialog systems in the unsupervised setting.



