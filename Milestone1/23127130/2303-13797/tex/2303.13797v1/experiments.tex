\section{Experimental Setup}
\label{experiments}

In this section, we describe the task-specific and personalization datasets, methodology of evaluation, competing methods, and the implementation details of our framework {\ourmodel}.

\subsection{Datasets}
\label{datasets}
We used one task-specific task dataset \myspecial{bAbI dialogue}~\cite{bordes2016learning} that trains our model in phase one. The personalized counterpart, called \myspecial{personalized bAbI dialogue}~\cite{joshi2017personalization}, is used to train all the supervised competing models. Our proposed framework adapts to diverse user profiles in the unsupervised setting.
To the best of our knowledge, \myspecial{personalized bAbI dialogue} is the \emph{only} publicly available personalization benchmark for task-oriented dialog systems. Table~\ref{tab:dataset} presents important statistics for both datasets. Both datasets are in the restaurant domain and consist of five tasks.

\stitle{Task 1: Issue API calls.}
This task involves extracting values of all the required slots (a.k.a. values for query parameters, e.g., \myspecial{cuisine} = \myspecial{spanish}) from natural language utterances and successfully making an API call. In this task, the personalization involves understanding and adapting the linguistic variations for a given user profile (e.g., male vs female).

\stitle{Task 2: Update API calls.}
This task includes updating the values for certain slots, if the user wishes to do so. For example, a user's request in natural language, ``Instead could it be in a cheap price range in Madrid?'', should update the current API call: \myspecial{api\_call(cuisine=french, city=paris, party\_size=four, price\_range=expensive)} to the call: \myspecial{api\_call(cuisine=french, city=madrid, party\_size=four, price\_range=cheap)}. Similarly to task one, personalization task two mainly deals with the style adaptations.

\stitle{Task 3:  Display Options.}
This task requires displaying relevant options from the knowledge base using the search results from API call. The personalization task involves adapting certain linguistic style as well as understanding user's taste and restaurant's specialities, among others, and making appropriate suggestions based on the active user's profile. Unsupervised personalization for this task is the most challenging part of this work. 

\stitle{Task 4: Provide extra information.}
The user's acceptance of an option entails asking for extra information (e.g., \myspecial{phone\_number}) from the system. The personalization for task four calls for resolving ambiguities efficiently along with the style adaptation. For example, asking for contact information could refer to \myspecial{phone\_number} or \myspecial{social\_media} depending on the active user (e.g., elederly vs young).

\stitle{Task 5: Conduct  Full dialogs.}
This task is about conducting the full dialogue that covers tasks 1-4 successfully. Similarly, personalization task includes, but not limited to: \myNum{i} adjusting the conversation flow to the active userâ€™s personality, \myNum{ii} adapting the linguistic style, and \myNum{iii} dealing with nuances effectively. 

The \myspecial{personalized bAbI dialogue} dataset contains two test sets: a standard test set and a test set - \myspecial{OOV} (Out Of Vocabulary). We conduct extensive experiments on both test sets for all the five tasks for up to 180 diverse user profiles.


\begin{table*}[t!]
\caption{F1 scores for task completion.}
\label{tab:f1}
\centering
\begin{tabular}{llccccc}
\toprule
\textbf{Approach}                           & \textbf{Models} & \multicolumn{1}{l}{\textbf{Task 1}} & \multicolumn{1}{l}{\textbf{Task 2}} & \multicolumn{1}{l}{\textbf{Task 3}} & \multicolumn{1}{l}{\textbf{Task 4}} & \multicolumn{1}{l}{\textbf{Task 5}} \\ \hline
\multirow{9}{*}{Supervised} & MemNN-org       & 99.63                               & 99.81                               & 98.87                               & 98.87                               & 85.10                               \\
                                            & MemNN-split     & 85.66                               & 85.83                               & 84.89                               & 84.89                               & 87.28                               \\
                                            & PMemN2N         & 99.70                               & 99.93                               & 98.91                               & 98.97                               & 95.33                               \\
                                            & Mem2Seq-org     & 99.68                               & 99.68                               & 98.28                               & 99.68                               & 80.41                               \\
                                            & Mem2Seq-split   & 99.62                               & 99.62                               & 98.52                               & 99.62                               & 82.19                               \\
                                            & Mem2Seq-att     & 99.66                               & 99.66                               & 98.46                               & 99.66                               & 82.38                               \\
                                            & GLMP            & 99.45                               & 99.45                               & 98.48                               & 99.45                               & 86.20                               \\
                                            & CoMemNN         & 99.65                               & 99.65                               & 98.61                               & 99.65                               & 98.13                               \\
                                            & Supervised-GPT  & \underline{99.72}                      & \textbf{99.96}                      & \underline{99.02}                      & \textbf{99.96}                      & \textbf{98.21}                      \\
                                            \hline
Unsupervised Personalization                & PToD-0   (This work)       & 99.69                               & 99.86                               & 98.92                               & 99.88                               & 98.14                 \\ \hline
\multirow{2}{*}{Few-shot Personalization} & Few-shot GPT       & 98.12                               & 99.08                               & 97.71                               & 97.32                               & 91.23                               \\
                    & {\ourmodel}  (This work)          & \textbf{99.74}                               & \underline{99.94}                               & \textbf{99.03}                               & \underline{99.94}                               & \underline{98.17}   \\
\bottomrule
\end{tabular}
\vspace{-8pt}
\end{table*}


\subsection{Evaluation Methodology}
\label{testing}

To demonstrate the effectiveness of {\ourmodel}, we evaluate our framework and all the competing methods for \myNum{i}~task completion and \myNum{ii}~personalization of the dialog for the given user profile.

\stitle{Task Completion.}
To quantify the performance for the task completion, we compute the F1 scores and present evaluation results for all the models for all five tasks.

\stitle{Personalization.}
The main task for the proposed framework is to personalize the task-oriented dialog systems in the unsupervised way. To evaluate the efficacy of the framework and how it compares to the other supervised approaches, we use BLEU-4 and ROUGE-2 scores. The BLEU~\cite{papineni2002bleu} and ROUGE~\cite{hovy2006automated} metrics have been extensively used for natural language generation tasks.
Human judgment and BLEU scores show a very strong correlation. 
The BLEU-n (n $\in \{1,2,3,4\}$) score $\in [0,100]$ measures the proportion of n-grams in the generation that also occurs in the reference.
ROUGE, on the other hand, is a recall-based measure that quantifies n-gram overlap between the generation and the reference.
Moreover, we also conduct a user study on a randomly selected 300 responses generated by the top performing supervised models and our proposed unsupervised personalization framework.

\subsection{Competing Methods}
\label{baselines}
We compare against the following state-of-the-art (SOTA) personalization models and GPT-2-based strong baselines:
\begin{description}[leftmargin=1.2\parindent,labelindent=-3.5pt, itemsep=-1pt]
\item \textbf{MemNN~\cite{joshi2017personalization}:}
The response selection-based approach proposes to use the memory network to encode dialog content and user profile information using a concatenation of the profile information and dialog memory (i.e., MemNN-org) and using split memory for the profile information and concatenating hidden states (i.e., MemNN-split).


\item \textbf{PMemN2N~\cite{luo2019learning}:}
The memory network-based method facilitates the model's personalization by combining the style information of the user attributes in the encoder.


\item \textbf{Mem2Seq~\cite{madotto2018mem2seq}:}
An end-to-end approach that proposes to use memory network in the encoder and employs RNN-based decoder for query generation and memory network for personalized response generation. This work proposes three variants of the models, called Mem2Seq-org, Mem2Seq-split, and Mem2Seqatt.

\item \textbf{GLMP~\cite{wu2019global}:}
Based on Mem2Seq, this model includes local and global encoders to share external knowledge efficiently.

\item \textbf{CoMemNN~\cite{pei2021cooperative}:}
This work proposes cooperative memory network and assumes that only partial user profile information is available. This approach does not generate response, instead relies on the response selection. In our experiments, we provided the model with 100\% user profile information for a fair comparison.

\item \textbf{Supervised GPT:}
Since none of the SOTA personalized models follow SOTA transformers architecture, we also trained a supervised GPT-2 model. This model was trained in the same fashion as our phase three except it was trained on all the training examples of the dataset, thus serves as a strong supervised baseline.
\item \textbf{Few-shot GPT:}
Due to the unavailability of any unsupervised approach for comparison and coming up with a reward function is non-trivial, we also trained a few-shot GPT-2 model. This model follows same training process, except phase two (i.e., unsupervised personalization) is skipped to demonstrate the effectiveness of the phase two of the proposed framework.

\end{description}


\subsection{Implementation Details}
\label{implementation}
We use the pre-trained GPT-2 model as a backbone model that is trained in all the three phases of the framework. 
The phase one trains the task-specific model for 3 epochs using cross-entropy loss and Adam optimizer, with a batch size of 8, and a learning rate of $5 \times 10^{-5}$. Other parameters are as follows:
\myspecial{warmup\_steps=100}, \myspecial{weight\_decay=0.01},
\myspecial{max\_length=1024}. 
The zero-shot generalizable reward function uses a pre-trained MPNet for input encoding.
It is trained for 3 epochs using contrastive loss on 50\% of the user profiles on every task and the remaining 50\% profiles are considered unseen. 
The phase two uses the same parameters as phase one, except batch size of 4 was used because of the GPU memory limitations (and a learning rate of $1.41 \times 10^{-5}$). Similarly, phase three uses same parameters, except a smaller learning rate of  $5 \times 10^{-7}$ was used and up to 20 training examples were made available for training.
We present two variants of our model: \myNum{i} PToD-0 does not use phase three (i.e., personalized model is only trained in the unsupervised setting) and \myNum{ii} {\ourmodel} that uses 20 training examples in the phase three. 

