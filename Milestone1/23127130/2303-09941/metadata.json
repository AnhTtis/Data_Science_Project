{
    "arxiv_id": "2303.09941",
    "paper_title": "Leaping Into Memories: Space-Time Deep Feature Synthesis",
    "authors": [
        "Alexandros Stergiou",
        "Nikos Deligiannis"
    ],
    "submission_date": "2023-03-17",
    "revised_dates": [
        "2023-03-30"
    ],
    "latest_version": 3,
    "categories": [
        "cs.CV"
    ],
    "abstract": "The success of deep learning models has led to their adaptation and adoption by prominent video understanding methods. The majority of these approaches encode features in a joint space-time modality for which the inner workings and learned representations are difficult to visually interpret. We propose LEArned Preconscious Synthesis (LEAPS), an architecture-agnostic method for synthesizing videos from the internal spatiotemporal representations of models. Using a stimulus video and a target class, we prime a fixed space-time model and iteratively optimize a video initialized with random noise. We incorporate additional regularizers to improve the feature diversity of the synthesized videos as well as the cross-frame temporal coherence of motions. We quantitatively and qualitatively evaluate the applicability of LEAPS by inverting a range of spatiotemporal convolutional and attention-based architectures trained on Kinetics-400, which to the best of our knowledge has not been previously accomplished.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09941v1",
        "http://arxiv.org/pdf/2303.09941v2",
        "http://arxiv.org/pdf/2303.09941v3"
    ],
    "publication_venue": null
}