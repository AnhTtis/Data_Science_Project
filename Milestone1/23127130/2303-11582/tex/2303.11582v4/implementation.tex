\section{Implementation Details}
\label{section:implementation}

We first discuss the implementation details for solving the $\algofull$ planning problem \eqref{eqn:rho}.
Recall that the problem involves maximizing the expectation of future posterior means
over constant sampling allocations in the simplex $\Delta_{\numarm}$:
\[
\maximize_{\bar{\rho} \in \Delta_\numarm}
\left\{ V^{\bar{\rho}}_{t}(\mu_{t},\sigma_{t})
  =  \E_{t} \left[ \max_{a} \left\{ \mu_{t,a}
      + \sqrt{\frac{\sigma_{t, a}^4 \bar{\rho}_{a} \bar{b}_{t}}
        {s_a^2 + \sigma_{t, a}^2 \bar{\rho}_{a} \bar{b}_{t}}} Z_{t, a}
    \right\} \right] \right\}.
\]
We approximate the expectation in the objective function by a sample average approximation
with $N$ standard normal random vectors.
\[
    \maximize_{\bar{\rho} \in \Delta_\numarm}
    \left\{
    \frac{1}{N}\sum_{j=1}^{N}
   \max_{a} \left\{ \mu_{t,a}
      + \sqrt{\frac{\sigma_{t, a}^4 \bar{\rho}_{a} \bar{b}_{t}}
        {s_a^2 + \sigma_{t, a}^2 \bar{\rho}_{a} \bar{b}_{t}}} Z_{t, a, j}
    \right\}
    \right\}.
\]
where $Z_{t,a,1},...,Z_{t,a,N}$ are iid draws of $N(0,1)$ random variables. 
We use quasi-Monte Carlo methods for variance reduction and draw
the normal random variables from a Sobol sequence,
which is widely used in practice in Bayesian Optimizaton \cite{BalandatEtAl20}.

There are many methods for solving this constrained optimization problem (e.g. projected gradient descent).
We use a softmax parameterization of the 
simplex $\bar{\rho}_{a} \propto e^{v_{a}}$,
and use unconstrained stochastic gradient methods to optimize over $v$.
We observe that vanilla stochastic gradient descent gets stuck at sub-optimal allocations
that allocate all sampling effort to one treatment arm. We obtain much better performance
from approximate second-order methods such as Adam \cite{KingmaBa15} or L-BFGS \cite{LiuNo89},
and use Adam for the experimental evaluation.

For the policy gradient method, we parameterize the policy as a feed-forward neural network with 
2 hidden layers with 512 units in each layer. The network uses the rectified non-linearity \cite{GlorotBoBe11} for all hidden layers.
We pass the posterior means $\mu \in \R^{\numarm}$, the posterior variances $\sigma^{2} \in \R^{\numarm}$, the current epoch $t \in \N$,
and the measurement variance $s^{2} \in \R^{\numarm}$ as inputs. The output of the network is passed through a softmax layer
and so the final output is a sampling allocation $\bar{\rho}\in \Delta^{\numarm}$. We train the network with the 
Adam optimizer with learning rate $5.0 \times 10^{-6}$ and $(\beta_{1},\beta_{2}) = (0.9, 0.999)$ in minibatches of size $50$.
Minibatches are drawn by randomly generating priors $(\mu_{0}, \sigma_{0})$.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
