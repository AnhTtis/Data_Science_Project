{
    "arxiv_id": "2303.11582",
    "paper_title": "Adaptive Experimentation at Scale: A Computational Framework for Flexible Batches",
    "authors": [
        "Ethan Che",
        "Hongseok Namkoong"
    ],
    "submission_date": "2023-03-21",
    "revised_dates": [
        "2023-07-11"
    ],
    "latest_version": 3,
    "categories": [
        "cs.LG",
        "stat.ML"
    ],
    "abstract": "Standard bandit algorithms that assume continual reallocation of measurement effort are challenging to implement due to delayed feedback and infrastructural/organizational difficulties. Motivated by practical instances involving a handful of reallocation epochs in which outcomes are measured in batches, we develop a computation-driven adaptive experimentation framework that can flexibly handle batching. Our main observation is that normal approximations, which are universal in statistical inference, can also guide the design of adaptive algorithms. By deriving a Gaussian sequential experiment, we formulate a dynamic program that can leverage prior information on average rewards. Instead of the typical theory-driven paradigm, we leverage computational tools and empirical benchmarking for algorithm development. In particular, our empirical analysis highlights a simple yet effective algorithm, Residual Horizon Optimization, which iteratively solves a planning problem using stochastic gradient descent. Our approach significantly improves statistical power over standard methods, even when compared to Bayesian bandit algorithms (e.g., Thompson sampling) that require full distributional knowledge of individual rewards. Overall, we expand the scope of adaptive experimentation to settings that are difficult for standard methods, involving a small number of reallocation epochs, low signal-to-noise ratio, and unknown reward distributions.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11582v1",
        "http://arxiv.org/pdf/2303.11582v2",
        "http://arxiv.org/pdf/2303.11582v3"
    ],
    "publication_venue": null
}