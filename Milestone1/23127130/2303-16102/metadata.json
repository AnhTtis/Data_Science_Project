{
    "arxiv_id": "2303.16102",
    "paper_title": "KeyMatchNet: Zero-Shot Pose Estimation in 3D Point Clouds by Generalized Keypoint Matching",
    "authors": [
        "Frederik Hagelskj√¶r",
        "Rasmus Laurvig Haugaard"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2023-09-27"
    ],
    "latest_version": 2,
    "categories": [
        "cs.CV"
    ],
    "abstract": "In this paper, we present KeyMatchNet, a novel network for zero-shot pose estimation in 3D point clouds. The network is trained to match object keypoints with scene-points, and these matches are then used for pose estimation. The method generalizes to new objects by using not only the scene point cloud as input but also the object point cloud. This is in contrast with conventional methods where object features are stored in network weights. By having a generalized network we avoid the need for training new models for novel objects, thus significantly decreasing the computational requirements of the method.\n  However, as a result of the complexity, zero-shot pose estimation methods generally have lower performance than networks trained for a single object. To address this, we reduce the complexity of the task by including the scenario information during training. This is generally not feasible as collecting real data for new tasks increases the cost drastically. But, in the zero-shot pose estimation task, no retraining is needed for new objects. The expensive data collection can thus be performed once, and the scenario information is retained in the network weights.\n  The network is trained on 1,500 objects and is tested on unseen objects. We demonstrate that the trained network can accurately estimate poses for novel objects and demonstrate the ability of the network to perform outside of the trained class. We believe that the presented method is valuable for many real-world scenarios. Code, trained network, and dataset will be made available at publication.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16102v1",
        "http://arxiv.org/pdf/2303.16102v2"
    ],
    "publication_venue": "7 pages, 5 figures, 4 tables"
}