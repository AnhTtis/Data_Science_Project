@inproceedings{irie2010autotrailer,
  author = {Irie, Go and Satou, Takashi and Kojima, Akira and Yamasaki, Toshihiko and Aizawa, Kiyoharu},
  title = {Automatic Trailer Generation},
  year = {2010},
  booktitle = {Proc. ACM Int. Conf. Multimedia},
  pages = {839â€“-842},
}

@inproceedings{grabska2021application,
  title={Application of Graphs for Story Generation in Video Games},
  author={Grabska-Gradzi{\'n}ska, Iwona and Nowak, Leszek and Palacz, Wojciech and Grabska, Ewa},
  booktitle={Proc. Australas. Comput. Sci. Week Multiconf.},
  pages={1--6},
  year={2021}
}

@inproceedings{song2015tvsum,
  title={Tvsum: Summarizing Web Videos using Titles},
  author={Song, Yale and Vallmitjana, Jordi and Stent, Amanda and Jaimes, Alejandro},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  pages={5179--5187},
  year={2015}
}

@inproceedings{gygli2014creating,
  title={Creating Summaries from User Videos},
  author={Gygli, Michael and Grabner, Helmut and Riemenschneider, Hayko and Van Gool, Luc},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={505--520},
  year={2014},
}

@article{de2011vsumm,
  title={VSUMM: A Mechanism Designed to Produce Static Video Summaries and A Novel Evaluation Method},
  author={De Avila, Sandra Eliza Fontes and Lopes, Ana Paula Brandao and da Luz Jr, Antonio and de Albuquerque Ara{\'u}jo, Arnaldo},
  journal={Pattern Recognit. Lett.},
  pages={56--68},
  year={2011},
}

@inproceedings{zhou2018towards,
  title={Towards Automatic Learning of Procedures from Web Instructional Videos},
  author={Zhou, Luowei and Xu, Chenliang and Corso, Jason},
  booktitle={Proc. AAAI Conf. Artif. Intell.},
  year={2018}
}

@inproceedings{xu2016msr,
  title={MSR-VTT: A Large Video Description Dataset for Bridging Video and Language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  pages={5288--5296},
  year={2016}
}

@inproceedings{krishna2017dense,
  title={Dense-captioning Events in Videos},
  author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Carlos Niebles, Juan},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  pages={706--715},
  year={2017}
}

@inproceedings{chen2017video,
  title={Video to Text Summary: Joint Video Summarization and Captioning with Recurrent Neural Networks},
  author={Chen, Bor-Chun and Chen, Yan-Ying and Chen, Francine},
  booktitle={Brit. Mach. Vis. Conf.},
  year={2017}
}


@inproceedings{li2022blip,
  title={Blip: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  pages={12888--12900},
  year={2022},
}

@inproceedings{zoph2020rethinking,
  title={Rethinking Pre-training and Self-training},
  author={Zoph, Barret and Ghiasi, Golnaz and Lin, Tsung-Yi and Cui, Yin and Liu, Hanxiao and Cubuk, Ekin Dogus and Le, Quoc},
  booktitle={Adv. Neural Inf. Process. Syst.},
  pages={3833--3845},
  year={2020}
}

@inproceedings{li2020hero,
    title={{HERO}: Hierarchical Encoder for {V}ideo+{L}anguage Omni-representation Pre-training},
    author={Li, Linjie  and Chen, Yen-Chun  and Cheng, Yu  and Gan, Zhe  and Yu, Licheng  and Liu, Jingjing},
    booktitle={Proc. Conf. Empir. Methods Nat. Lang. Process.},
    year = {2020},
    pages = {2046--2065},
}

@article{Beltagy2020Longformer,
  title={Longformer: The Long-Document Transformer},
  author={Iz Beltagy and Matthew E. Peters and Arman Cohan},
  journal={arXiv:2004.05150},
  year={2020},
}

@inproceedings{ju2022prompting,
  title={Prompting Visual-Language Models for Efficient Video Understanding},
  author={Ju, Chen and Han, Tengda and Zheng, Kunhao and Zhang, Ya and Xie, Weidi},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={105--124},
  year={2022},
}

@inproceedings{ni2022expanding,
  title={Expanding Language-Image Pretrained Models for General Video Recognition},
  author={Ni, Bolin and Peng, Houwen and Chen, Minghao and Zhang, Songyang and Meng, Gaofeng and Fu, Jianlong and Xiang, Shiming and Ling, Haibin},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={1--18},
  year={2022},
}

@inproceedings{narasimhan2021clip,
  title={CLIP-It! Language-Guided Video Summarization},
  author={Narasimhan, Medhini and Rohrbach, Anna and Darrell, Trevor},
  booktitle={Adv. Neural Inf. Process. Syst.},
  pages={13988--14000},
  year={2021}
}

@inproceedings{hessel2021clipscore,
    title = {CLIPScore: A Reference-free Evaluation Metric for Image Captioning},
    author = {Hessel, Jack  and Holtzman, Ari  and Forbes, Maxwell  and Le Bras, Ronan  and Choi, Yejin},
    booktitle={Proc. Conf. Empir. Methods Nat. Lang. Process.},
    year = {2021},
    pages = {7514--7528},
}

@article{wu2021godiva,
  title={GODIVA: Generating Open-DomaIn Videos from nAtural Descriptions},
  author={Wu, Chenfei and Huang, Lun and Zhang, Qianxi and Li, Binyang and Ji, Lei and Yang, Fan and Sapiro, Guillermo and Duan, Nan},
  journal={arXiv:2104.14806},
  year={2021}
}

@inproceedings{zhang2016video,
  title={Video Summarization with Long Short-term Memory},
  author={Zhang, Ke and Chao, Wei-Lun and Sha, Fei and Grauman, Kristen},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={766--782},
  year={2016},
}

@inproceedings{zhou2018deep,
  title={Deep Reinforcement Learning for Unsupervised Video Summarization with Diversity-Representativeness Reward},
  author={Zhou, Kaiyang and Qiao, Yu and Xiang, Tao},
  booktitle={Proc. AAAI Conf. Artif. Intell.},
  year={2018}
}

@inproceedings{park2020sumgraph,
  title={SumGraph: Video Summarization via Recursive Graph Modeling},
  author={Park, Jungin and Lee, Jiyoung and Kim, Ig-Jae and Sohn, Kwanghoon},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={647--663},
  year={2020},
}

@inproceedings{saquil2021multiple,
  title={Multiple Pairwise Ranking Networks for Personalized Video Summarization},
  author={Saquil, Yassir and Chen, Da and He, Yuan and Li, Chuan and Yang, Yong-Liang},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  pages={1718--1727},
  year={2021}
}

@article{graves2012long,
  title={Long Short-Term Memory},
  author={Graves, Alex and Graves, Alex},
  journal={Superv. Seq. Labell. with Recur. Neural Netw.},
  pages={37--45},
  year={2012},
}

@inproceedings{zhao2017hierarchical,
  title={Hierarchical Recurrent Neural Network for Video Summarization},
  author={Zhao, Bin and Li, Xuelong and Lu, Xiaoqiang},
  booktitle = {Proc. ACM Int. Conf. Multimedia},
  pages={863--871},
  year={2017}
}

@inproceedings{zhao2018hsa,
  title={HSA-RNN: Hierarchical Structure-Adaptive RNN for Video Summarization},
  author={Zhao, Bin and Li, Xuelong and Lu, Xiaoqiang},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  pages={7405--7414},
  year={2018}
}

@article{ji2020deep,
  title={Deep Attentive and Semantic Preserving Video Summarization},
  author={Ji, Zhong and Jiao, Fang and Pang, Yanwei and Shao, Ling},
  journal={Neurocomputing},
  pages={200--207},
  year={2020},
}

@inproceedings{lal2019online,
  title={Online Video Summarization: Predicting Future to Better Summarize Present},
  author={Lal, Shamit and Duggal, Shivam and Sreedevi, Indu},
  booktitle={Proc. IEEE Winter Conf. Appl. Comput. Vis.},
  pages={471--480},
  year={2019},
}

@article{yuan2019spatiotemporal,
  title={Spatiotemporal Modeling for Video Summarization Using Convolutional Recurrent Neural Network},
  author={Yuan, Yuan and Li, Haopeng and Wang, Qi},
  journal={IEEE Access},
  pages={64676--64685},
  year={2019},
}

@inproceedings{fu2019attentive,
  title={Attentive and Adversarial Learning for Video Summarization},
  author={Fu, Tsu-Jui and Tai, Shao-Heng and Chen, Hwann-Tzong},
  booktitle={Proc. IEEE Winter Conf. Appl. Comput. Vis.},
  pages={1579--1587},
  year={2019},
}

@inproceedings{zhang2019dtr,
  title={DTR-GAN: Dilated Temporal Relational Adversarial Network for Generic Video Summarization},
  author={Zhang, Yujia and Kampffmeyer, Michael and Zhao, Xiaoguang and Tan, Min},
  booktitle={Proc. ACM Turing Celebr. Conf. - China},
  pages={1--6},
  year={2019}
}

@inproceedings{chen2011collecting,
  title={Collecting Highly Parallel Data for Paraphrase Evaluation},
  author={Chen, David and Dolan, William B},
  booktitle={Proc. 49th Annu. Meet. Assoc. Comput. Linguist.},
  pages={190--200},
  year={2011}
}

@inproceedings{yao2015describing,
  title={Describing Videos by Exploiting Temporal Structure},
  author={Yao, Li and Torabi, Atousa and Cho, Kyunghyun and Ballas, Nicolas and Pal, Christopher and Larochelle, Hugo and Courville, Aaron},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  pages={4507--4515},
  year={2015}
}

@article{yan2019stat,
  title={STAT: Spatial-Temporal Attention Mechanism for Video Captioning},
  author={Yan, Chenggang and Tu, Yunbin and Wang, Xingzheng and Zhang, Yongbing and Hao, Xinhong and Zhang, Yongdong and Dai, Qionghai},
  journal={IEEE Trans. Multimedia},
  pages={229--241},
  year={2019},
}

@inproceedings{wang2018bidirectional,
  title={Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning},
  author={Wang, Jingwen and Jiang, Wenhao and Ma, Lin and Liu, Wei and Xu, Yong},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  pages={7190--7198},
  year={2018}
}

@inproceedings{zhou2018end,
  title={End-to-End Dense Video Captioning with Masked Transformer},
  author={Zhou, Luowei and Zhou, Yingbo and Corso, Jason J and Socher, Richard and Xiong, Caiming},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  pages={8739--8748},
  year={2018}
}

@inproceedings{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={Adv. Neural Inf. Process. Syst.},
  pages={1877--1901},
  year={2020}
}

@inproceedings{devlin2018bert,
    title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
    booktitle = "Proc. Conf. North Am. Chap. Assoc. Comput. Linguist.",
    year = {2019},
    pages = {4171--4186},
}

@inproceedings{lewis2019bart,
    title = {BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
    author = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
    booktitle = {Proc. 58th Annu. Meet. Assoc. Comput. Linguist.},
    year = {2020},
    pages = {7871--7880},
}

@article{raffel2020exploring,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={J. Mach. Learn. Res.},
  pages={5485--5551},
  year={2020},
}

@inproceedings{kim2021vilt,
  title={ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  pages={5583--5594},
  year={2021},
}

@inproceedings{wang2020minilm,
  title={MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers},
  author={Wang, Wenhui and Wei, Furu and Dong, Li and Bao, Hangbo and Yang, Nan and Zhou, Ming},
  booktitle={Adv. Neural Inf. Process. Syst.},
  pages={5776--5788},
  year={2020}
}

@inproceedings{xue2021probing,
  title={Probing Inter-modality: Visual Parsing with Self-Attention for Vision-Language Pre-training},
  author={Xue, Hongwei and Huang, Yupan and Liu, Bei and Peng, Houwen and Fu, Jianlong and Li, Houqiang and Luo, Jiebo},
  booktitle={Adv. Neural Inf. Process. Syst.},
  pages={4514--4528},
  year={2021}
}

@inproceedings{zhang2021vinvl,
  title={VinVL: Revisiting Visual Representations in Vision-Language Models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  pages={5579--5588},
  year={2021}
}

@inproceedings{biten2019scene,
  title={Scene Text Visual Question Answering},
  author={Biten, Ali Furkan and Tito, Ruben and Mafla, Andres and Gomez, Lluis and Rusinol, Mar{\c{c}}al and Valveny, Ernest and Jawahar, CV and Karatzas, Dimosthenis},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  pages={4291--4301},
  year={2019}
}

@inproceedings{lin2014microsoft,
  title={Microsoft COCO: Common Objects in Context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={740--755},
  year={2014},
}

@article{regneri2013grounding,
  title={Grounding Action Descriptions in Videos},
  author={Regneri, Michaela and Rohrbach, Marcus and Wetzel, Dominikus and Thater, Stefan and Schiele, Bernt and Pinkal, Manfred},
  journal={Trans. Assoc. Comput. Linguist.},
  pages={25--36},
  year={2013},
}

@inproceedings{singh2019towards,
  title={Towards VQA Models That Can Read},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  pages={8317--8326},
  year={2019}
}

@inproceedings{alayrac2022flamingo,
  title={Flamingo: A Visual Language Model for Few-Shot Learning},
  author={Jean-Baptiste Alayrac and Jeff Donahue and Pauline Luc and Antoine Miech and Iain Barr and Yana Hasson and Karel Lenc and Arthur Mensch and Katherine Millican and Malcolm Reynolds and others},
  booktitle={Adv. Neural Inf. Process. Syst.},
  year={2022},
}

@article{wang2022git,
  title={GIT: A Generative Image-to-text Transformer for Vision and Language},
  author={Jianfeng Wang and Zhengyuan Yang and Xiaowei Hu and Linjie Li and Kevin Lin and Zhe Gan and Zicheng Liu and Ce Liu and Lijuan Wang},
  journal={Trans. Mach. Learn. Res.},
  year={2022},
}

@article{yu2022coca,
  title={CoCa: Contrastive Captioners are Image-Text Foundation Models},
  author={Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
  journal={Trans. Mach. Learn. Res.},
  year={2022},
}

@article{yuan2021florence,
  title={Florence: A New Foundation Model for Computer Vision},
  author={Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  journal={arXiv:2111.11432},
  year={2021}
}

@article{li2019visualbert,
  title={VisualBERT: A Simple and Performant Baseline for Vision and Language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv:1908.03557},
  year={2019}
}

@inproceedings{lu2019vilbert,
  title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle={Adv. Neural Inf. Process. Syst.},
  pages={13--23},
  year={2019}
}

@inproceedings{su2019vl,
  title={VL-BERT: Pre-training of Generic Visual-Linguistic Representations},
  author={Weijie Su and Xizhou Zhu and Yue Cao and Bin Li and Lewei Lu and Furu Wei and Jifeng Dai},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2020},
}

@inproceedings{tan2019lxmert,
  author       = {Hao Tan and Mohit Bansal},
  title        = {LXMERT: Learning Cross-Modality Encoder Representations from Transformers},
  booktitle    = {Proc. Conf. Empir. Methods Nat. Lang. Process.},
  pages        = {5099--5110},
  year         = {2019},
}

@inproceedings{radford2021learning,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  pages={8748--8763},
  year={2021},
}

@article{bao2021vlmo,
  title={{VLM}o: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts},
  author={Hangbo Bao and Wenhui Wang and Li Dong and Qiang Liu and Owais Khan Mohammed and Kriti Aggarwal and Subhojit Som and Songhao Piao and Furu Wei},
  booktitle={Adv. Neural Inf. Process. Syst.},
  year={2022},
}

@inproceedings{du2022survey,
  author       = {Yifan Du and Zikang Liu and Junyi Li and Wayne Xin Zhao},
  title        = {A Survey of Vision-Language Pre-Trained Models},
  booktitle    = {Proc. Int. Joint Conf. Artif. Intell.},
  pages        = {5436--5443},
  year         = {2022},
}


@inproceedings{singh2022flava,
  title={FLAVA: A Foundational Language And Vision Alignment Model},
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2022}
}

@inproceedings{sun2019videobert,
  title={VideoBERT: A Joint Model for Video and Language Representation Learning},
  author={Sun, Chen and Myers, Austin and Vondrick, Carl and Murphy, Kevin and Schmid, Cordelia},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  pages={7464--7473},
  year={2019}
}

@article{luo2020univl,
  title={UniVL: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation},
  author={Luo, Huaishao and Ji, Lei and Shi, Botian and Huang, Haoyang and Duan, Nan and Li, Tianrui and Li, Jason and Bharti, Taroon and Zhou, Ming},
  journal={arXiv:2002.06353},
  year={2020}
}

@inproceedings{lei2021detecting,
  title={Detecting Moments and Highlights in Videos via Natural Language Queries},
  author={Lei, Jie and Berg, Tamara L and Bansal, Mohit},
  booktitle={Adv. Neural Inf. Process. Syst.},
  pages={11846--11858},
  year={2021}
}

@inproceedings{sun2014ranking,
  title={Ranking Domain-specific Highlights by Analyzing Edited Videos},
  author={Sun, Min and Farhadi, Ali and Seitz, Steve},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={787--802},
  year={2014},
}

@inproceedings{otani2019rethinking,
  title={Rethinking the Evaluation of Video Summaries},
  author={Otani, Mayu and Nakashima, Yuta and Rahtu, Esa and Heikkila, Janne},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2019}
}

@inproceedings{ruan2022histruct+,
  title={HiStruct+: Improving Extractive Text Summarization with Hierarchical Structure Information},
  author={Ruan, Qian and Ostendorff, Malte and Rehm, Georg},
  booktitle={Find. Assoc. Comput. Linguist.},
  pages={1292--1308},
  year={2022}
}

@inproceedings{chen2020uniter,
  title={UNITER: UNiversal Image-TExt Representation Learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={104--120},
  year={2020},
}

@inproceedings{gabeur2020multi,
  title={Multi-modal Transformer for Video Retrieval},
  author={Gabeur, Valentin and Sun, Chen and Alahari, Karteek and Schmid, Cordelia},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={214--229},
  year={2020},
}

@inproceedings{patrick2021supportset,
  title={Support-set Bottlenecks for Video-Text Representation Learning},
  author={Mandela Patrick and Po-Yao Huang and Yuki Asano and Florian Metze and Alexander G Hauptmann and Joao F. Henriques and Andrea Vedaldi},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2021},
}

@inproceedings{zhang2018cross,
  title={Cross-Modal and Hierarchical Modeling of Video and Text},
  author={Zhang, Bowen and Hu, Hexiang and Sha, Fei},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={385--401},
  year={2018}
}

@inproceedings{loshchilov2018decoupled,
  title={Decoupled Weight Decay Regularization},
  author={Ilya Loshchilov and Frank Hutter},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2019},
}

@inproceedings{loshchilov2016sgdr,
  title={{SGDR}: Stochastic Gradient Descent with Warm Restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2017}
}

@book{zwillinger1999crc,
  title={CRC standard probability and statistics tables and formulae},
  author={Zwillinger, Daniel and Kokoska, Stephen},
  year={1999},
  publisher={Crc Press}
}

@article{xu2023mplug,
  title={mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image and Video},
  author={Xu, Haiyang and Ye, Qinghao and Yan, Ming and Shi, Yaya and Ye, Jiabo and Xu, Yuanhong and Li, Chenliang and Bi, Bin and Qian, Qi and Wang, Wei and others},
  journal={arXiv:2302.00402},
  year={2023}
}

@inproceedings{papineni2002bleu,
  title={BLEU: a Method for Automatic Evaluation of Machine Translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proc. 40th Annu. Meet. Assoc. Comput. Linguist.},
  pages={311--318},
  year={2002}
}

@inproceedings{banerjee2005meteor,
  title={METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proc. Assoc. Comput. Linguist. Workshop},
  pages={65--72},
  year={2005}
}

@inproceedings{lin2004rouge,
  title={ROUGE: A Package for Automatic Evaluation of Summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@inproceedings{vedantam2015cider,
  title={CIDEr: Consensus-based Image Description Evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  pages={4566--4575},
  year={2015}
}

@inproceedings{singer2022make,
  title={Make-A-Video: Text-to-Video Generation without Text-Video Data},
  author={Uriel Singer and Adam Polyak and Thomas Hayes and Xi Yin and Jie An and Songyang Zhang and Qiyuan Hu and Harry Yang and Oron Ashual and Oran Gafni and Devi Parikh and Sonal Gupta and Yaniv Taigman},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2023}
}

@inproceedings{Zhang2020BERTScore,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Zhang, Tianyi and Kishore, Varsha  and Wu, Felix  and Weinberger, Kilian Q.  and Artzi, Yoav},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2020},
}

@inproceedings{reimers2019sentence,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, Nils and Gurevych, Iryna},
  booktitle={Proc. Conf. Empir. Methods Nat. Lang. Process.},
  pages={3982--3992},
  year={2019}
}

@inproceedings{li2018jointly,
  title={Jointly Localizing and Describing Events for Dense Video Captioning},
  author={Li, Yehao and Yao, Ting and Pan, Yingwei and Chao, Hongyang and Mei, Tao},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  pages={7492--7500},
  year={2018}
}

@inproceedings{arora2018stronger,
  title={Stronger Generalization Bounds for Deep Nets via A Compression Approach},
  author={Arora, Sanjeev and Ge, Rong and Neyshabur, Behnam and Zhang, Yi},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  pages={254--263},
  year={2018},
}

@inproceedings{hua2021noise,
  author       = {Hang Hua and Xingjian Li and Dejing Dou and Cheng{-}Zhong Xu and Jiebo Luo},
  title        = {Noise Stability Regularization for Improving {BERT} Fine-tuning},
  booktitle    = {Proc. Conf. North Am. Chap. Assoc. Comput. Linguist.},
  pages        = {3229--3241},
  year         = {2021},
}

@article{hua2022fine,
  title={Fine-tuning Pre-trained Language Models with Noise Stability Regularization},
  author={Hua, Hang and Li, Xingjian and Dou, Dejing and Xu, Cheng-Zhong and Luo, Jiebo},
  journal={arXiv:2206.05658},
  year={2022}
}

@inproceedings{wang2019controllable,
  title={Controllable unsupervised text attribute transfer via editing entangled latent representation},
  author={Wang, Ke and Hua, Hang and Wan, Xiaojun},
  booktitle={Adv. Neural Inf. Process. Syst.},
  pages={11034--11044},
  year={2019}
}

@article{kendall1945treatment,
  title={The treatment of ties in ranking problems},
  author={Kendall, Maurice G},
  journal={Biometrika},
  pages={239--251},
  year={1945},
}

@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2021},
}

@article{openai2023gpt4,
  author       = {OpenAI},
  title        = {{GPT-4} Technical Report},
  journal      = {arXiv:2303.08774},
  year         = {2023},
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv:2307.09288},
  year={2023}
}

@inproceedings{hu2022promptcap,
  title={Promptcap: Prompt-guided task-aware image captioning},
  author={Hu, Yushi and Hua, Hang and Yang, Zhengyuan and Shi, Weijia and Smith, Noah A and Luo, Jiebo},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  year={2023}
}