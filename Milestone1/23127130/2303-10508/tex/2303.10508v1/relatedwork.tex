\section{FPGA Design Flow through Machine Learning: from HDL Elaboration to Bitstream Generation}\label{sec:related}
In this section, we will review recent advances in DL-based FPGA CAD techniques and discuss their potential impact on FPGA design flow.

\subsection{HDL Generation}
There are research that explore the use of DL for the analysis and optimization of HDLs. . 
One approach is to use Convolutional Neural Networks (CNNs) for HDL code classification and identification of code errors, as demonstrated in \cite{Yang2018}\cite{Tan2019}. 
A hybrid approach that combines both RNNs and CNNs has been proposed by Xia et al. \cite{Xia2021}
 for automatic HDL code generation. These approaches have shown promising results in improving the efficiency and accuracy of HDL design and have the potential to enhance the overall FPGA design process.

\subsection{Synthesis}
FPGA design flow involves High-Level Synthesis (HLS) and logic synthesis stages, where HLS synthesis generates an RTL (Register Transfer Level) description from a high-level language, while logic synthesis converts an RTL design into a gate-level netlist.  Recently, researchers have explored the use of DL techniques to improve both HLS and logic synthesis, resulting in promising outcomes.

\subsubsection{RTL Synthesis}
In FPGA synthesis, the slow timing of runs can pose a significant challenge, with modern designs requiring days of runtime. To address this challenge, Yanghua combines the predictions of multiple classification algorithms, resulting in improved predictive accuracy of InTime, an automated timing plugin for Xilinx and Altera CAD tools \cite{Yanghua2016}.

\subsubsection{HL Synthesis}
In recent years, deep learning (DL) algorithms have been widely utilized in high-level synthesis (HLS) to optimize performance in terms of resource and time usage. One approach is to leverage graph neural networks (GNN) to incorporate structural information among operations in a data-flow graph, improving the accuracy of operation delay estimation \cite{ustun2020accurate}. Congestion estimation is another important aspect of HLS optimization, and Zhao et al. \cite{8714724} have used gradient boosted regression tree (GBRT) to predict routing congestion during HLS. In addition, Makrani \cite{makrani2019pyramid} has modeled time optimization as a regression problem and used DL to evaluate the clock frequency of the HLS tool's output code.
In \cite{9789084}, the authors proposed a methodology to address the challenge of  the availability of open-source HLS designs for training and prediction of DL models. They present a methodology for generating diverse designs with various variations from a single design, resulting in a dataset of synthesizable FPGA HLS designs. 



% One of the main objectives of DL algorithms in HLS is to optimize performance in terms of resource and time usage. Graph neural networks (GNN) have been leveraged to incorporate structural information among operations in a data-flow graph, improving the accuracy of operation delay estimation in HLS \cite{ustun2020accurate}.
% In addition to improving the accuracy of resource usage and timing estimation, early and accurate routing congestion estimation is also crucial to guide optimization in HLS and enhance implementation efficiency. Zhao et al. \cite{8714724} have employed the gradient boosted regression tree (GBRT) to predict routing congestion during the HLS stage, as a representative study.
% Makrani \cite{makrani2019pyramid} has modeled time optimization as a regression problem and utilized the deep learning to evaluate the clock frequency of the HLS tool's output code.



\subsection{Placement}

To achieve accurate congestion and routability evaluations, several ML techniques have been used.
\cite{al2021deep} used CNN model for predicting the routability of a circuit based on its placement. 
Al-Hyari \cite{al2019novel} introduces a congestion estimation framework that includes two machine-learning models for placement prediction. The model is used to determine whether it is possible to route a placement solution without the overhead of a conventional router. The first model, MLCong, identifies key features to accurately estimate congestion during placement. The second model, MLRoute, utilizes these features to predict the routability of a placed circuit based on congestion maps generated by MLCong. 
Martin \cite{martin2021effective}  proposes a set of simple DL models and ensembles to accurately predict the routability of placement solutions. Three ensemble methods based on Bagging, Boosting, and Stack of classifiers are introduced to improve the accuracy and robustness of the models.  Esmaeili et. al.
\cite{esmaeili2022guiding} presented a method for reducing runtime in the Detailed Placement (DP) optimization step of FPGA design flow using Reinforcement Learning (RL) while maintaining Quality-of-Result (QoR). The goal of DP is to refine the global placement to improve the routing step success. Three RL models, based on Tabular Q-Learning, Deep Q-Learning, and Actor-Critic, are proposed and evaluated for their effectiveness in reducing DP runtimes. Results demonstrate the potential for significant reduction in runtime without sacrificing QoR. 
Murray et al. \cite{elgammal2021rlplace} presented RLPlace, a new simulated annealing (SA)-based FPGA placer that combines reinforcement learning (RL) with targeted perturbations to optimize wirelength and timing. By using directed moves, the proposed method explores the solution space more effectively than traditional random moves while preventing oscillation in the Quality of Results (QoR). RL is utilized to dynamically select the most effective move types during optimization.
Rajarathnam et. al. \cite{rajarathnam2022dreamplacefpga} presented DREAMPlaceFPGA, an open-source FPGA placement framework that is accelerated and built using the PyTorch deep-learning toolkit. It handles FPGA resource heterogeneity and architecture-specific legality constraints using optimized operators and provides a high-level programming interface in Python.
\subsection{Routing}
Farooq \cite{baig2022efficient} proposed a reinforcement learning (RL)-based approach to the routing problem by transforming the classical routing iterative process into the training process of RL. The proposed method utilizes a greedy approach and customized reward functions to speed up the routing step while maintaining similar or better quality of results (QoR) compared to conventional congestion-driven routing solutions based on negotiation. Ghavami et al. \cite{9556338} proposed MAPLE, a tool that enables aging-aware static timing analysis of FPGA design after routing using DL models. MAPLE efficiently models the aging-induced delay degradation at the basic block level using DNNs. The framework accurately predicts the relation between delay degradation and comprehensive aging factors by training one DNN model for each FPGA block type. 







% Due to the fixed interconnect resources available on the FPGA fabric and the increased complexity of designs targeting FPGAs, predicting routability has become a major concern in modern FPGA CAD flows. Therefore, the ability to quickly and accurately estimate the routability of a placement has become an essential goal in the FPGA design flow. Various routability estimation and prediction techniques have been introduced by researchers in this area.

% Early work by researchers used a wirelength calculation based on the circuit's Rent exponent to predict routability. However, this technique is not as accurate as more recent approaches presented in the literature. Another approach presents a stochastic model that gives an analytic expression for the routability of the circuit in the FPGA. However, the predictions produced by the stochastic model are overly pessimistic.

% More recently, a multivariate adaptive regression model was proposed to predict the routability of a placement after detailed routing, achieving an accuracy of 79.8\%. To date, the best-published results for routability prediction are for the CNN model - DLRoute. However, this model has a high computational cost, unlike the simple ML and ensemble models proposed in this paper.