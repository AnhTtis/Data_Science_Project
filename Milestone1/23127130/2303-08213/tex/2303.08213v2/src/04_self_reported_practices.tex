\section{Data Practices in Privacy Labels}
% In this section, we study how the app developers report their apps' privacy practices in the privacy labels. Specifically, we use the APL and DSS datasets curated in \Cref{sec:measurement} to answer the question: \textit{How do applications collect and use data?}. Further, we analyze the privacy labels for apps along three dimension: age rating, price and popularity. Finally, we identify sensitive data flows and perform a case study to show how apps can misuse the data.
\subsection{Google Data Safety Section}
\label{google-data-safety-sec4}
In this section, we analyze the DSS dataset (\cref{sec:google_dsc}) comprising \nnumber{573K} apps. We first discuss the practices present in DSS and then examine how these practices vary with an age rating, price, and popularity.
% In this section, we begin by discussing the high level practices. We then discuss the practices at \textit{Data Category} and \textit{Purpose} level. In our  we find that \nnumber{50}\% of the apps on the play store have Data Safety Sections.\smallskip

\noindent
\textbf{Data Collection and Sharing:} 
Among the apps having DSS, we saw \nnumber{42.3}\% collecting at least one type of data, and \nnumber{35.8}\% sharing at least one data type (purple bars in the top plot for \cref{fig:free_paid}). This suggests that the majority of the apps on the play store report do not collect or share data. This is in contrast with the findings from prior work~\cite{wang2015wukong} that found that the majority of the apps use at least one third-party application, which has been shown to collect sensitive information~\cite{book2013longitudinal, lin2013understanding}. One possible explanation for this is that developers find it hard to understand the collection and sharing practices of third-party libraries. This is also supported by prior research~\cite{balebako2014privacy, li2022understanding}. As such, when inquired about change in DSS, one developer also alluded to lack of transparency by third parties:\newline
\textit{``We don't collect or share any user data. But we use Meta (former Facebook) audience network for monetizing non-paying users with ads. Unfortunately, the details provided by Meta are very vague..''}

We also note that among the apps not collecting any data around \nnumber{23}\% are sharing data. This is because \textit{Data Collection} is defined as the instance when the developers retrieve the data from the device using the app~\cite{googledocumentation}, whereas \textit{Data Sharing} is defined as when the data is transferred from the device to a third party. This way, the developers can share data without collecting it if the application uses third-party libraries which directly send data to their servers.\smallskip

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{figures/good_pdfs/google_apple_high_level_privacy_labels_distribution_cropped.pdf}
  \caption{Distribution of privacy types in Google Data Safety Sections and Apple Privacy Labels. The normalization is done by the total number of apps with privacy labels.}
  \label{fig:free_paid}
\end{figure}

\noindent\textbf{Security Practices:}
We find that \nnumber{23}\% of the apps do not provide any details of their security practices. \nnumber{65}\% of the apps encrypt data that they collect or share while it's in transit, and \nnumber{42}\% allow the users to request that their data be deleted or automatically anonymize data within 90 days. Notably, we find that \nnumber{17.4\%} of the apps state that they do not collect or share data, but encrypt the data in transit. We explore this behavior further in \cref{sec:developer}. As apps need network permissions to transmit data, we cross-verified encryption practices with apps' network permission requests and find that \nnumber{10.5\%} apps do request network permission but do not encrypt data, potentially exposing user data in plain text. Additionally, \nnumber{2.2\%} of apps do not request network permissions, yet state that they encrypt data in transit, suggesting that some developers might be over-reporting their practices, consistent with prior research~\cite{li2022understanding}.\smallskip


\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{figures/good_pdfs/google_apple_highlevel_category_cropped.pdf}
  \caption{Distribution of Top-5 data categories for high-level practices for apps in Play Store (top) and App store (bottom). The normalization is done by the total number of apps with privacy labels. For plots with data categories, see \cref{fig:inconsistency_app_no_thresh} in the Appendix.}
  \label{fig:google_collected_sharing}
\end{figure}

%and among the apps not sharing any data, 30\% are collecting data. 

\noindent\textbf{Category and Purpose Level Practices:}
In \cref{fig:google_collected_sharing}, we present the top-5 data categories for \textit{Data Collection} and \textit{Data Sharing} by apps in play store. A full plot including all data categories can be found in \cref{fig:inconsistency_app_no_thresh} (Appendix).
Our findings indicate that the data categories \textit{Personal Information} and \textit{App activity} are among the most frequently collected, and are primarily used for \textit{App functionality} and \textit{Analytics}. However, \textit{Location} and \textit{Device Ids} are more commonly shared for the purpose of \textit{Advertising or Marketing}. We emphasize that this flow poses serious privacy risks and allows for tracking by third parties.
We also observe that sensitive data types such as \textit{Audio}, \textit{Files and Docs}, and \textit{Health and Fitness} are collected less frequently, with the most common purpose being \textit{App functionality}. Furthermore, we note that out of the 7 possible purposes for collecting data there are over \nnumber{4K} apps that list 6 or more purposes for the data they collect, which may indicate that app developers list all purposes out of convenience. For example, \textit{Workplace from Meta} with over 15M+ downloads, lists the same 6 purposes for all the data they collect like access to \textit{Installed Apps}, \textit{SMS or MMS}, \textit{Music Files}. This is consistent with the findings of Li et al.~\cite{li2022understanding}, who suggest that developers may over-report in cases of ambiguity.\smallskip

\noindent\textbf{Variation of Practices with Popularity:}  We first investigate the relationship between privacy practices and app popularity. We classify apps into three categories based on their number of downloads: extremely popular (greater than 1M download, n=56K), semi-popular (more than 10K downloads, n=524K), and low-popular (less than 10K downloads, n=621K).
Our findings reveal that 1) the fraction of apps displaying Data Safety Sections (DSS) increases with the popularity of the apps (42\% for low-popular, 51\% for semi-popular and 76\% for extremely popular) and 2) the fraction of apps collecting and sharing data is less for popular apps (41\% for low-popular, 46\% for semi-popular and 12\% for extremely popular). These results suggest that developers from popular apps tend to report more privacy-friendly practices.\smallskip

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{figures/good_pdfs/google_apple_high_level_age_rating_distribution_cropped.pdf}
  \caption{Distribution of privacy types based on age rating for DSS and APLs. The normalization is done by the total number of apps with privacy labels.}
  \label{fig:age_rating}
\end{figure}

\noindent\textbf{Variation of Practices with Age Rating:}
Next, we examine how the practices of apps differ based on their age rating as determined by the Google Play Store. The Play Store assigns five different age ratings: Everyone, Teen, Mature 17+, and Everyone 10+\footnote{Google also has Adults 18+ rating, but we found less than 200 apps in this category and decided to filter it out for this analysis}. We acknowledge the importance of this distinction, as apps that are accessible to children and teens (falling in the Everyone and Teen categories) are expected to have higher transparency and collect less data. However, our analysis of the dataset reveals that 59\% of apps with the \textit{Mature 17+} rating have a Data Safety Section (DSS), while the fraction of apps with a DSS in the other age ratings ranges from 47\% (Everyone) to 55\% (Everyone 10+). The data practices for different age ratings are shown in \cref{fig:age_rating}.  We find that the fraction of apps having \textit{Data Collection} and \textit{Data Sharing} is lowest for apps rated for \textit{Everyone}, whereas apps targeting \textit{Mature 17+} have the highest encryption rate.\smallskip

\noindent\textbf{Variation of Practices with Price:}
Finally, we study the difference in practices based on whether the app is available for free, free with in-app purchases, or paid. We find that 68\% of the paid apps have DSS whereas, for free apps, only 46\% have DSS. \cref{fig:free_paid} shows the distribution of high-level practices with free and paid apps. We note that for paid apps, a fraction of apps collecting and sharing data is lower. Furthermore, apps with \textit{Data Encryption} and \textit{Data Deletion} are lower because the apps are collecting and sharing fewer data. This suggests that paid apps tend to have better data practices. 

% \rishabh{@Asmit: Add the detailed analysis for encryption here}.

%=======================================================================================================================

\subsection{Apple Privacy Labels}
Next, we examine the Apple Privacy Label (APL) dataset (\cref{sec:apple_label_methodology}) consisting of privacy labels from \nnumber{955K} apps. We first discuss the practices present in APL and then dive into variations of practices with an age rating and price. Finally, we conclude by comparing the low-level practices mentioned in APL and DSS \smallskip

\noindent
\textbf{High-Level Practices:} In our dataset, 42\% of apps collected data from users that were not linked back to the user (Data Not Linked to You), whereas 37\% of apps did collect data that is linked to the user (\cref{fig:free_paid}. Note that apps could collect multiple types of data some of which may be linked to the users while others may not. Furthermore, around 18\% of the apps reported collecting data that was used to track the users. Note that this reflects the status of the APLs after the \textit{Apple Tracking Transparency} policy was implemented, which requires developers to obtain consent from users before tracking. We also find that 42\% of apps report that they do not collect any data from users. Recent works~\cite{kollnig2021iphones, kollnig2022goodbye} analyzing iOS apps have found that at least 80\% of the apps still use tracking libraries in the apps. Further, these libraries have been shown to collect user data~\cite{book2013longitudinal, lin2013understanding}. Similar to the case of android developers, this discrepancy can be explained by the lack of transparency of privacy practices by the third-party libraries, resulting in confusion for the developers. \smallskip
% \rishabh{Should we go one level deeper and talk about data types as well? }

For \textit{Data Used to Track You}, we find that \textit{Usage Data} and \textit{Identifiers} are most commonly used. We note here that Apple defines \textit{Tracking} as when data collected is linked with third-party data for targeted advertising, as well as when the data is shared with a data broker. Additionally, we observe that 25\% of the apps collecting \textit{Location} information also use it for tracking. This poses severe privacy risks to the users as entities can track the physical location of the users which can reveal sensitive details about users' habits and routines. \smallskip

\noindent\textbf{Data Category and Purpose Level Practices:} In \cref{fig:google_collected_sharing} (bottom), we show the top-6 data categories mentioned in the high-level practices in the APL dataset. We find that for \textit{Data Linked to You}, \textit{Contact Information} and \textit{Identifiers} are collected most frequently, whereas for \textit{Data Not Linked to You}, \textit{Diagnostics} and \textit{Usage Data} are collected most frequently. Apple defines \textit{Contact Information} as name, email, phone number, and physical address, whereas \textit{Usage Data} refers to product interactions and advertising data such as information about the ads that the user has viewed. Analyzing purposes for these data categories, we find that nearly 60\% of the apps use these data categories for \textit{App functionality} and \textit{Analytics}. It is also worthwhile to note that \textit{Contact Information} is used for \textit{Advertisements} in only 8\% of the apps that collect this information, indicating that apps generally do not use personal information for advertisements. We also note that \textit{Identifiers}, commonly used for tracking users for targeted advertising is used for \textit{Advertisement or Marketing} in more than 20\% of the apps that collect \textit{Identifiers}. Interestingly, \textit{Location}, under \textit{Data Linked to You} is also used for \textit{Advertisement or Marketing} by 20\% of the apps that collect \textit{Location}.\smallskip

\noindent
\textbf{Variation of Practices with Age Rating} Next, we investigate the correlation between the privacy practices described in the Android Permission List (APL) and the age rating and price of apps. The App Store assigns four different age ratings: 4+, 9+, 12+, and 17+ (which roughly align with the rating system used by the Google Play Store). Our analysis reveals that the fraction of apps with an age rating of 17+ is highest at 76\%. However, we note that the high-level data practices, shown in Figure 1, are consistently more privacy-friendly for apps with lower age ratings. For instance, only 13\% of the apps with an age rating of 4+ track users. Similarly, data collection for these apps is also consistently lower than that of other categories.\smallskip

\noindent
\textbf{Variation of Practices with Price:} Finally, we categorize the dataset into free and paid apps and examine the differences in privacy labels. Recall that for the play store, we observed that paid apps contained more DSS than free apps. For APL, we find the reverse trend with 70\% of the free apps having APL as compared to 52\% paid apps. On the other hand, the high-level practices are decidedly better for the paid apps, as shown in \cref{fig:free_paid} (bottom chart). For instance, 82\% of the paid apps reported not collecting any data, while only 3\% of paid apps mentioned using data to track the user. This indicates that the paid apps on iOS platforms are more friendly than the free apps.\smallskip

\noindent
\textbf{Comparison Between DSS and APL:} As discussed in \cref{sec:background}, DSS and APL provide different information to the users, and cannot be directly compared based on high-level practices. However, since the underlying data collected is the same, we can compare the practices shown in \cref{fig:google_collected_sharing}. We observe that the fraction of apps requesting similar datatypes is much smaller for apps on the play store than that of the app store (with a notable exception of Location). This can be attributed to the fact that developers have had a longer to work with the APL framework, while the DSS framework is still relatively new. In our communication with app developers, one app developer mentioned that they try different answers on the data safety form. We also received communication indicating that some developers updated their DSS based on the questions that we had asked. This indicates that the developers are unclear on the process involved in the data safety forms, which might result in some inaccuracies in the DSSs. This is also supported by the study conducted by Li. et al ~\cite{lin2013understanding} where they find that app developers find it difficult and challenging to fill out the privacy labels, especially, because the frameworks for Apple and Google are starkly different and can create confusion.

\input{src/05_developer_study.tex}

% \rishabh{We might want to remove the case studies?}
% \subsection{Case Studies}
% For the case studies, we looked into how apps use sensitive data like sexual orientation, race and ethnicity, and political ideations. From the dataset of google apps, we find about \nnumber{7.6K} apps that collect sensitive data types, and \nnumber{4K} apps that share these sensitive data.

% Of the apps that share sensitive data, there are \nnumber{398} apps with more than 500K downloads. Of these \nnumber{398} apps, there are \nnumber{51} apps that share sensitive data for \textit{Developer Communications}, \nnumber{132} apps sharing data for \textit{Advertising or Marketing} purposes, and \nnumber{74} apps sharing data for \textit{Fraud Prevention, Security, and Compliance}. We further found that \nnumber{31} apps under the Parenting genre collecting and/or sharing sensitive data, with \nnumber{11} apps having more than 100K downloads and \nnumber{3} apps having more than 1M downloads. These apps are targeted toward children and it's interesting to observe that they are collecting and/or sharing sensitive data. For example, the app ~\textit{Find My Kids Family tracker} \footnote{~\url{https://play.google.com/store/apps/details?id=org.findmykids.app}} collects the Sexual Orientation of the users for App functionality and personalization, which in this case are clearly kids. Another app, ~\textit{Preggers | Pregnancy \& Baby} \footnote{~\url{https://play.google.com/store/apps/details?id=life.stroller.preggers}} collects Sexual Orientation data for developer communication, and Race and Ethnicity data for App Functionality and Analytics. This app is aimed at expectant parents and collects significant sensitive data from their users as stated in their app descriptions.

% Similarly, we analyzed the apps in the App Store to observe the trends in apps handling sensitive data. We found that there are 14K apps that handled sensitive data. 11K apps collected data that was linked to the user, 2.4K apps collected data that was not linked to the user, and 500 apps that use sensitive data to track users. Furthermore, there were 600 Education apps, and 1200 Financial apps collecting sensitive data. Moreover, among the 14K apps, 2.3K apps are rated 12+, 128 apps are rated 9+ and 7.6K apps are rated 4+. Upon further analyzing the apps rated 4+ and how they handle sensitive data we find that 239 apps use it to track users, 365 apps use it for advertising. For example, \textit{Nike Training Club: Fitness}\footnote{\url{https://apps.apple.com/us/app/nike-training-club-fitness/id301521403}}, rated 4+, in the app store collects sensitive data for tracking. Same app on Google Play Store\footnote{\url{https://play.google.com/store/apps/details?id=com.nike.ntc}} has over 23M downloads.
\subsection{Takeaways}
The analysis presented here results in three main takeaways: 1) Privacy practices reported in the privacy nutrition labels differ from the privacy practices derived using app analysis by prior works~\cite{wang2015wukong}. Specifically, prior works have shown that third-party libraries are used in the majority of the apps and that these libraries collect sensitive information from the users. This is inconsistent with what we find in the privacy labels. This inconsistency can be explained by the fact that privacy practices of third-party libraries are often vague and create confusion among the developers (consistent with findings from literature~\cite{li2022understanding}). 2) We also show that paid apps, and apps that are open to all age groups, including children, are more privacy-friendly. As shown in \cref{fig:free_paid} and \cref{fig:age_rating}, these apps are less likely to engage in tracking, data collection, and data sharing. 3) \cref{fig:google_collected_sharing} also shows that location data is often used for advertising, marketing, and tracking. This poses severe privacy risks, as location data can reveal sensitive information about an individual's habits and routines. Our research suggests that further attention should be paid to the use of location data in mobile apps, and the potential risks it poses to user privacy.












%We first perform longitudinal study was conducted to analyze the periodic snapshots of data safety cards across all apps on the Google Play Store. The study also analyzed the practices reported by app developers in the Data Safety Card.

%Google imposed a hard deadline for app developers to add the data safety cards on July 20, 2022, which falls within the data collection window. This allowed for the study of the adoption rate as well as the evolution of data safety cards.

%During the period of June 20, 2022 to November 23, 2022, it was found that the fraction of apps with data safety cards increased from 27.9% to 43.3%. The largest change was observed between July 13, 2022 and August 1, 2022, which coincides with the deadline provided by Google.

% We first perform a longitudinal study of the data safety cards by analyzing periodic snapshots of data safety cards across all apps on the play store. We then analyze the practices as reported by the app developers in the Data Safety Card.
% \vspace{-1.5mm}
% \noindent
% For example, ~\textit{Shake-it Alarm - Alarm Clock
% }\footnote{\url{https://play.google.com/store/apps/details?id=com.ingyomate.shakeit}} with over 7M downloads state that they share `Health and Fitness' data with third parties but earlier in July\footnote{\url{https://web.archive.org/web/20220715114242/https://play.google.com/store/apps/details?id=com.ingyomate.shakeit}} their DSS didn't have that information. In fact, Google's own apps ~\textit{Clock}\footnote{\url{https://play.google.com/store/apps/details?id=com.google.android.deskclock}} added the collection of `Personal Info' after June.

% \rishabh{Add one/two examples here, possibly showing a sensitive datatype being added/removed}.

% \red{In order to understand the nature of change in privacy labels, we contacted developers of these apps via email asking them to provide information about the change in the privacy labels. In particular, we sent emails to developers of top 10K apps where the data safety card changed. Based on the responses of \nnumber{n} developers, we find that filling the data safety card is confusing for the developers, which can results in errors, requiring updates.}\smallskip

%\Cref{fig:trend_with_time} shows %the rate of adoption trend of high level data practices with time. 
%how the data safety cards were added during our collection window. 

% In particular, we find that the fraction of apps with data safety card increases over time from \nnumber{27.9\%} to \nnumber{43.3\%}. 
% % However, it is worth noting that we found \nnumber{7\%} of the apps removing their data safety card after adding it at an earlier date. 
% This change over time can be attributed to 4 cases:
% \begin{enumerate}
%   \item \nnumber{x} new apps with DSS are added. This number is affected by 2 conditions:
%   \begin{enumerate}
%     \item New apps are added to Google Play Store which are also listed in the androzoo list
%     \item Earlier apps are now added to the androzoo list
%   \end{enumerate}
%   \item \nnumber{x} old apps without DSS update and add DSS 
%   \item \nnumber{x} apps removed their DSS
%   \item \nnumber{x} apps are removed from Play Store
% \end{enumerate}
 
% \todo[inline]{We can say that such a significant turnout suggests that apps developers sometimes just put down random data to meet deadline then remove it}
% \rishabh{This feels very incomplete. We are not providing any insights here, just a plot and how to read the plot.}

%From the plot, it shows that the number of new apps being added is more than the number of net apps that have DSS. Although the number of apps whose DSS is removed without the app itself being deleted from the play store is low but not insignificant. 

% <TALK ABOUT FINDINGS FROM THE PLOT, INTERSTING EXAMPLE WHERE DATA SAFETY CARD CHANGED FOR THE BETTER AND ONE FOR THE WORSE>
% \begin{figure}
%   \centering
%   \includegraphics[width=\columnwidth]{figures/good_pdfs/collected_shared_vs_purpose.pdf}
%   \caption{Purpose distribution for apps for data sharing and data collected. The denominator here is the number of apps mentioning collection or sharing in the Data safety card.}
%   \label{fig:methodology}
% \end{figure}
% \subsubsection{Data Practices in Data Safety Cards}
% Next, we analyze the data practices as reported by the app developers on the android platform. We study the self-reported practices of the developers along three dimensions: age rating, number of downloads and price.\smallskip


% \rishabh{Look into transition from landscape to consistency - we can leverage the fact that the practices reported here are not in line with prior works, so in the remaining paper, we investigate the consistency}


% We have the following key takeaways: \rishabh{TODO: Form a coherent paragraph from these}
% \begin{itemize}
%     \item Privacy practices described in the PLs differ from what research has found - main reason being third party libraries, supported by previous research
%     \item Paid apps, and apps that are open to all age groups, including children are more privacy friendly - less tracking, collection and sharing.
%     \item Location is being used for ads, marketing and tracking - poses severe privacy risks. 
% \end{itemize}
% One of the points:

% 60\% of the apps do not disclose their data collection practices, even when they have a DSS. Of these apps, over \red{95\%} of the apps mention collecting data in their privacy policy. This indicates that developers might be uploading inaccurate data safety cards, just to comply with the regulations. Without a consistency check, the data safety cards are not usable as the users do not know whether the practices mentioned in the DSS are accurate.