\section{Data Practices Across Platforms}
\label{sec:consistency_cross}
Next, we compare the self-reported privacy practices in Privacy Labels of cross-listed apps across the Google play store and Apple app store using the cross-listed dataset described in \cref{sec:cross_apps}. 
% As DSS and APL use different terminology for privacy practices, we first create a common mapping for privacy practices. We then compare the practices reported in privacy labels.
%In particular, we first identify the apps that are present in both the platforms, extract their privacy nutrition labels and investigate whether the same app (and developers) report different privacy practices across different platforms. We first begin by detailing the methodology for identifying cross-listed apps and then perform the comparison between self reported privacy practices at scale. 

\begin{figure*}
\hspace*{-2.2cm} 
  \centering
  \includegraphics[width=1.3\columnwidth]{figures/good_pdfs/heatmap_normalized4.pdf}
  \caption{Normalized Heatmap showing the inconsistencies in the datatype-purpose pair. Normalization is done for each cell block in the heatmap, \textit{i.e.}, for each datatype-purpose pair, we normalize with the total number of apps which have that datatype-purpose pair.}
  \label{fig:heatmap}
\end{figure*}



% \subsection{Identifying Cross Listed Apps}
% In the app market, the two major platforms are Apple store and Google play store. Developers can increase their reach by building and serving their app across both the platforms. However, identifying two versions of the same app across platforms is a challenging problem due to lack of unique identifiers. There are several pseudo identifies such as app name, developer name, privacy policy and developer website, but none of them can be used as unique identifiers. For example, a same developer can build multiple apps across both platforms, each of the app having their own privacy nutrition label. However, these apps might have the same privacy policy, developer name and developer website. Further, a developer might also use different URLs to show privacy policies for different platforms, such as \url{APP NAME}. 

% \begin{figure}[t]
%   \centering
%   \includegraphics[width=\columnwidth]{figures/cross_listing.pdf}
%   \caption{Pipeline for identifying cross listed apps}
%   \label{fig:cross_listed}
% \end{figure}


% To address this problem and uniquely map apps across platforms, we use combination of pseudo identifies and relied on a set of heuristic pipeline, shown in Fig.~\ref{fig:cross_listed}. Specifically, we start with the apps which have the same name across both the platforms (n=500k). Next, if the privacy policy of the apps match, then we treat them as a unique match (n=190K). In some cases, <ENTER EXAMPLE HERE>, the app developers can include platform specific identifiers in the URLs for privacy policies. To capture these instances, we match the first level domain of the privacy policy URLs, and identify them as unique matches (n=104K). Finally, while providing privacy policy links is highly encouraged in both platforms, some apps do not contain the link to privacy policy. To further increase the coverage, we also match the first level domain of the developer website, which is present in both the platforms. Using this criteria, we are further able to get 45K matches. This way, we obtain a total of 400K apps which have instances in both Apple play store and Google play store. 

% Another potential scenario is that apps can have different names but the same privacy policy and the same developer name. In such cases, we can do a fuzzy string matching and find apps with similar names. While capturing these instances will increase our coverage, it might also result in higher number of false positives as different apps developed by the same developer might get flagged with this approach. For example, \texttt{app1} and \texttt{app2} have the same developer and the same privacy policy but have different functionality. Our objective with the analysis of privacy labels for cross-listed apps is to understand whether developers disclose their privacy practices similarly on the two platforms. For our purposes, having an accurately mapped set for is more important than captures all instances cross-listed apps. Therefore, we rely on the strong set of heuristics to curate this set.

% \subsubsection*{\textbf{Manual Verification}} We note that the set of cross-listed apps identified above are based on a set of heuristic rules, with the objective to minimize false positives. To further ensure that we do not compare practices of different apps, two of the authors manually verified 150 app pairs identified using each of the three steps shown in Fig.~\ref{fig:cross_listed} and found that no app from Google Play Store was matched to an incorrect app from App Store. 

% \subsubsection*{\textbf{Cross-listed Apps Dataset}} Using the methodology described above, we find a total of 400K cross listed apps. Among these apps, we find that 15\% have privacy nutrition label only on the Google Play Store, 31\% of the apps have the label only on the Apple App store, 43\% of the apps have labels on both the platforms while 11\% of the apps do not have privacy nutrition label on either of the platform. The higher rate of privacy labels for App store can be understood as Apple enforced nutrition label on their platform earlier than Google, giving more time for developers to add the details in the privacy label. For the 13\% of the apps which have privacy label for play store but not for app store - majority of the apps have not been updated in the last 1.5 years, suggesting that a driving factor for adding the nutrition labels is when the developers are forced to add it. Examining the apps which have privacy label for app store but not for play store also reveals a similar pattern. 
%  <add some examples>


\subsection{Mapping DSS categories to APL categories}
%Privacy Nutrition labels are designed to provide information about the data collection, sharing and usage by a given app. 
As previously discussed in Sec.~\ref{sec:background}, the privacy labels for android and iOS platforms cover different aspects of data practices. APL emphasizes on tracking and linkability of the collected data without distinguishing between collected and shared data, while DSS focuses on security practices and whether the data is collected or shared with a third party. 
%For example, in Apple privacy label, data used for tracking is highlighted separately whereas in data safety sections, security practices such as data encryption in transit and option to delete data are mentioned. 
However, despite covering disjoint high-level practices, the lower-level attributes in the privacy labels - namely the \texttt{datatype} and \texttt{purpose} - have a large overlap. Thus, to compare the disclosure practices of app developers across platforms, we first find the common datatypes and purposes in the two labels, and then compare 1) the datatypes, and 2) datatype-purpose pairs. 
% For the latter, we take a union of  all the common datatype-purpose pairs present in the APL and compare them with the common datatype-purpose pairs present in DSS. 

% \begin{table}[t]
% \footnotesize
% \centering
% \begin{tabular}{>{\arraybackslash}l>{\arraybackslash}l>{\arraybackslash}l}
% \toprule
% \multicolumn{1}{c}{\textbf{Google Purposes}} & $\rightarrow$      & \multicolumn{1}{c}{\textbf{Apple Purposes}} \\ \midrule
% Approximate Location  &$\rightarrow$  & Coarse Location  \\ \midrule
% Race and Ethnicity   & $\rightarrow$ & Sensitive Info\\ \midrule
% Sexual Orientation  & $\rightarrow$ & Sensitive Info \\ \midrule
% d &  &d \\ \midrule
% Personalization  & $\rightarrow$ & Personalization \\ \midrule
% Account Management       & $\rightarrow$ & N/A  \\  \midrule
% Developer Communication  &  & \\
% \bottomrule
% \end{tabular}}
% \caption{Table showing the common mapping from Data Safety Card and Apple Privacy Label}
% \end{table}


It is worth noting that the datatype and purpose tags used in the two labels can be used to denote different concepts. For example, in APL, \texttt{App functionality} also includes fraud prevention and implementing security measures, whereas the data safety section has separate tags for app functionality and fraud prevention and security measures. For the purposes of this analysis, we combine these two purposes into \textit{App functionality} to create a common map. Since APL does not have any tags for \textit{Account Management} and \textit{Dev. Communicaitons}, we removed them from DSS for this comparison. After taking the intersection of the available datatypes and purposes, we end up with 4 purpose categories and 26 datatypes. A complete mapping for classes from DSS to APL is shown in \cref{appendix:mapping}.
%There are also data types which are not common in the labels such as Files and Docs, Calendar etc. For our comparison, we remove these data types, along with the ambiguous data types such as \textit{Other info} in personal information and \textit{Other actions} (in App interactions). ~\cref{table:common_map1} and ~\cref{table:common_map2} provides a complete mapping that we have used to compare.

\subsection{Findings}
We compare the self-reported privacy practices of the 100K apps that are cross-listed on both the platforms and have privacy labels. Specifically, we ask the following questions: a) How does the high-level practice of data collection compare between the two labels? and b) Is the purpose for using datatypes consistent between the two labels?

% \begin{itemize}[leftmargin=*, align=parleft, labelsep=4mm]
%     \item[\textbf{Q1}] How does the high level practice of data collection compare between the two labels?
%     \item[\textbf{Q2}] When the apps uses datatypes, is the purpose for using datatypes consistent between the two labels?
% \end{itemize}

\subsubsection{Comparison of Data Collection}
 To compare how many apps do not collect data, we rely on the \textit{Data Not Collected} tag for the iOS platform and \textit{Data Shared} and \textit{Data Collected} tags for the android platform. 
 % Note that here we use both data shared and data collected tags for android platform because iOS platform denotes both the practices with 
 % does not make a distinction between the two, and the \textit{Data Not Collected} refers to both collection and sharing. 
 % We  emphasize here that due to the reason mentioned above, it is not possible to compare the data sharing practices between the two labels. 
We find that a total of \nnumber{22K(~22\%)} apps report different data collection practices on the two platforms. Of these apps, \nnumber{42\%} of the apps report collecting data on android while \nnumber{58\%} of the apps report collecting data on the iOS platform. Examining these apps further, we find that \nnumber{18\%} of these apps have more than 100k downloads, and \nnumber{5\%} has over 1M downloads indicating that even popular apps have this inconsistency. For example, ~\textit{KineMaster - Video Editor} a video editing app with over 400M+ downloads on Google Play Store states that they do not collect any data in the Play store but states in App Store that they do collect sensitive data such as \textit{Location} and \textit{Identifiers}.

The inconsistency in self-reported data collection practices as indicated by the inaccuracies in privacy labels undermines the credibility of the Privacy Label framework. This poses a significant concern for users, as they may base their decisions on inaccurate information, thereby increasing their privacy and security risks.

% The inconsistency suggests that at least one of the privacy labels is inaccurate which is concerning as this indicates that developers are not consistent in self reporting their data collection practices, which in turn erodes on the credibility of the Privacy Label framework. If the privacy labels are inaccurate, then privacy-concious users might be at higher privacy and security risk as they may make decisions about which app to use based on false information.

\subsubsection{Comparison of Fine-grained Practice}
% Next, we investigate whether the apps mention the same purpose for using datatypes in the privacy labels across the platforms. To perform this analysis, we only consider the apps where both the labels report collecting data, resulting in a set of \nnumber{yy} apps.
%removed the 50K apps identified above from this analysis as our objective is to analyze fine-grained inconsistencies across the two privacy labels when both the apps are collecting data. 

%Our assumption here is that same app will have the same features across the platforms and therefore will request same datatypes on both the platforms for same purpose. We note that neither of the platforms disallow developers from collecting or using a particular data type. The underlying operating systems might provide more controls to the user, but the developers are not prohibited from accessing any resources. Further, we note that we removed the 50K apps identified above from this analysis as our objective is to understand 

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/good_pdfs/datatype_inconsistency2_cropped.pdf}
  \caption{Distribution of inconsistent apps with datatypes. Each datatype is normalized with the number of apps using that particular datatype on either platform. Note that we have omitted some datatypes here for brevity. The full distribution can be found in the ~\cref{fig:inconsistency_app_no_thresh} in the Appendix}.
  \label{fig:inconsistency}
\end{figure}

We compare fine-grained practices along two dimensions: 1) DataType where we check whether the privacy labels report collecting/sharing the same datatypes; and 2) DataType-Purpose pairs where we compare the common datatype-purpose pair in the two labels. If there is at least one datatype-purpose pair that is not present in both sets, we treat the app as inconsistent for that datatype-purpose pair. We also tag instances as inconsistent where the datatype-purpose pair is present in one of the labels and is missing from the other. For example, if the DSS of an app has \textit{(Location - Personalization)}, while the APL has \textit{(Location - App Functionality)}, then we treat the app as inconsistent. Similarly, if the DSS of an app has \textit{(Location - Personalization)}, while the APL has \textit{(Location - App Functionality)} and \textit{(Location - Personalization)}, we still treat the app as inconsistent as the tags \textit{(Location - App Functionality)} is not common in both. 

Across the cross-listed apps that have privacy labels, we find that at least \nnumber{60\%} of the apps have at least one inconsistency. For example, in \textit{Tiktok}, DSS states that they collect the contact list of the users for `Advertising and Marketing' purposes, but APL states that the app does not collect a contact list. 
\cref{fig:inconsistency} shows the inconsistency in datatypes across the two platforms. We find that \textit{Sensitive Information}, \textit{Browsing History}, and \textit{Emails or Text Messages} have the highest inconsistencies across the two platforms.  From Fig.~\ref{fig:inconsistency}, we observe that DeviceID and Product Interactions are the data counts with the highest inconsistencies. We also observe that \textit{Precise Location} and \textit{Coarse Location} is inconsistent with \textit{Advertising} implying that at least in one of the labels, location is used for advertising, raising privacy concerns for the users.

% Analyzing inconsistencies in purpose \rishabh{Add this when the plot is ready}. 

% We find that at least \red{70\%} of the apps have at least one inconsistency between the two privacy labels. Fig.~\ref{fig:inconsistency} shows the distribution of inconsistent apps with data types and with purpose. We find that \textit{App functionality} is the most common purpose for which inconsistencies arise. For Datatypes \textit{DeviceID} is the most common data type for which there are inconsistencies. For example, <AAP A>, a popular app with XX downloads has ...
% Only looking at the popular apps, we see a similar pattern with App Functionality and DeviceID being the most common purpose and datatype respectively, with inconsistencies. 

To analyze datatype-purpose inconsistencies, we show the normalized heatmap of inconsistent apps in \cref{fig:heatmap}. Normalization is done for each cell block in the heatmap, \textit{i.e.}, for each datatype-purpose pair, we normalize with the total number of apps that have that datatype-purpose pair. 
%Thus, each cell block in \cref{fig:heatmap} denotes the fraction of apps in which the corresponding datatype-purpose pair is consistent. 
We find that \textit{Fitness} and \textit{Sensitive Information} when used for \textit{Advertising or Marketing} are frequently inconsistent. The plot shows that even though \textit{Sensitive Information} and \textit{Fitness} data are not collected very often (Fig.~\ref{fig:inconsistency}), when they are collected, they are often inconsistent in privacy labels across two platforms. On the other hand, \textit{Credit Information} and \textit{Financial Information} have the least number of inconsistencies, which is encouraging considering the sensitive nature of this information.

% Fig.~\ref{fig:heatmap} shows the distribution of apps that are inconsistent across datatype and purposes, without distinguishing between where the mismatch occurs. To understand how purposes are being matched incorrectly, we show the confusion matrix for a following datatypes - \textit{Device ID}, \textit{Location} (Coarse and Precise combined), \textit{Performance Data}, \textit{Product Interaction}, \textit{Sensitive Information} and \textit{Purchase History}. 

% \todo[inline]{Add the figures, describe them and give some examples}

% \paragraph*{\textbf{Case Studies}} Here, we perform a qualitative case study with two genres that normally are associated with sensitive information. Our objective is to understand the impact and reach of these inconsistencies. Specifically, we focus on the following two genres: Medical, and Finance. We observed that for both these genres the most confusing data type was Location. Moreover, we 

% In fact, when taking a large scale view across genres, we observe that apps systematically collect more data in google than in apple as shown in the confusion matrices in Appendix. ~\todo[inline]{add cnf mats to the appendix and refer here}


% \paragraph*{\textbf{Discussion}} Earlier, we made an assumption that same apps with same features will access same datatypes on both the platforms.  We note that in the event that our assumption were wrong, there would be a systematic skew in the data in favor of one platform. For example, if it was difficult for developers to access location for the users in iOS, then we would observe that for apps that are accessing location on the android platform, the corresponding labels for iOS platform would have them as missing. However, as shown in Fig.~\ref{fig:location_confusion}, apps accessing location on the android platform consistently get the purpose confused when reporting on the iOS platform. We observed similar behavior across all common data types



% \begin{figure}
%   \centering
%   \includegraphics[width=\columnwidth]{figures/good_pdfs/credit_info.png}
%   \caption{Confusion metric for Credit Information. Each row shows what the purpose in apple for credit information was mislabeled in Google whereas each column shows what the purpose in Google was mislabeled in Apple. Takeaway: When the developers mentioned app functionality in google, a lot of times, it was confused with advertising or analytics or personalization, indicating that the frameworks are not working as they are supposed to, i.e. the users might not be getting accurate information about privacy practices of the apps.}
%   \label{fig:methodology}
% \end{figure}

% \begin{figure}
%   \centering
%   \includegraphics[width=\columnwidth]{figures/good_pdfs/payment_info.png}
%   \caption{Confusion metric for Payment Information. Each row shows what the purpose in apple for payment information was mislabeled in Google whereas each column shows what the purpose in Google was mislabeled in Apple.}
%   \label{fig:methodology}
% \end{figure}

% \begin{figure}
%   \centering
%   \includegraphics[width=\columnwidth]{figures/good_pdfs/precise_location.png}
%   \caption{Confusion metric for precise location}
%   \label{fig:methodology}
% \end{figure}

% \begin{figure}
%   \centering
%   \includegraphics[width=\columnwidth]{figures/good_pdfs/purchase_history.png}
%   \caption{confusion metric for purchase history}
%   \label{fig:methodology}
% \end{figure}



\subsection{Takeaway}
In this section, we analyzed the consistency of privacy labels for the same apps across the two platforms. We find that 60\% of the cross-listed apps had at least one inconsistency between APL and DSS. We further find that inconsistencies are highest for \textit{Sensitive Information}, \textit{Browsing History}, and  \textit{Emails or Text Messages} datatypes. Through a detailed analysis of datatype-purpose inconsistencies, we find that \textit{Emails and Text Messages} when used for Advertising results in inconsistencies 96\% of the time, indicating a concerning problem with disclosure of practices in privacy labels.
