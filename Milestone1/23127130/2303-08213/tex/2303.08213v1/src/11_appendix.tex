\section{Privacy Policy Analysis}
\subsection{Privacy Policy Taxonomy}
\label{appendix:taxonomy}

\textbf{Limitations of the OPP-115 Taxonomy} Figure.~\ref{fig:opp_taxonomy} shows the privacy taxonomy proposed by Wilson et al.~\cite{wilson2016creation}. The top-level defined high-level privacy categories whereas the lower level defined a set of privacy attributes that can take a particular set of values. Additionally, some examples of attribute-value pairs are shown such as Information Type and Purpose. Note that several lower-level attributes are shared across the high-level categories. 
\begin{figure*}
\hspace*{-2.2cm} 
  \centering
  \includegraphics[width=1.25\columnwidth]{figures/good_pdfs/opp_dataset-crop.pdf}
  \caption{The privacy policy taxonomy by Wilson et al. ~\cite{wilson2016creation}}
  \label{fig:opp_taxonomy}
\end{figure*}

Prior works~\cite{harkous2018polisis, srinath2020privacy} have used the OPP-115 taxonomy and the associated dataset to build machine-learning classifiers that tag segments of the policy with the labels from the taxonomy. However, there are two limitations to directly using the taxonomy (and existing frameworks such as Polisis~\cite{harkous2018polisis}) to compare privacy practices between privacy labels and privacy policies. First, the OPP-115 taxonomy was developed for privacy policies of websites, which is vastly different than the ecosystem of applications (both Android and iOS). In particular, the applications have access to sensitive data types, which are present in the privacy labels. This taxonomy, while having some overlap with the APL and DSS privacy labels, does not cover such app-specific data types. For example, \texttt{app activity}, a data category covering users' interactions within the application, is not covered in the taxonomy. Second, the OPP-115 dataset has limited annotations for the lower-level attributes that overlap with the private labels. For example, \textit{Encryption in Transit}, which is a separate practice covered in Data Safety Sections, only has less than 100 labeled instances in the OPP-115 dataset. 

\begin{figure}
  \centering
  \includegraphics[scale=0.6]{figures/good_pdfs/privacy_label_taxonomy.pdf}
  \caption{Privacy Label Taxonomy}
  \label{fig:privacy_taxonomy}
\end{figure}

We address these limitations by incorporating the missing labels to the existing OPP-115 taxonomy. We derive a \textit{Privacy Label Taxonomy} (\cref{fig:privacy_taxonomy}) as a union of a subset of the original OPP-115 taxonomy with the new labels from APL and DSS. To build the taxonomy, we first identify the categories from the taxonomy that are relevant to privacy labels, thus creating a subset of the original taxonomy. We then add the missing categories to get the new taxonomy. 

\medskip
\noindent \textbf{Identifying relevant categories from OPP-115} 
As discussed in Sec.~\ref{sec:background}, privacy labels consist of high-level privacy practices, data categories, and purposes for the use of data. The high-level categories \textit{First-party-data-collection} and \textit{Third-party-sharing-collection} from the OPP-115 taxonomy are relevant as they map directly to Data Safety Sections' \textit{Data Collection} and \textit{Data Sharing} privacy types. Further, APL covers the first-party collection and sharing practices implicitly through \textit{Data Linked to You} and \textit{Data Not Linked to You}. Similarly, the attribute level categories \textit{Purpose}, \textit{Data Type}, and \textit{Identifiable} are relevant. 


For example, in Apple Privacy Label (APL), the \textit{Data Used to Track You} privacy type includes the data that is linked with third-party data for targeted advertising. It also includes cases when the data is shared with a data broker. Note here that linking can be done by both the app developers (by using data obtained from a third party) or by sharing the data with a third party. Thus, this privacy practice can be represented with \textit{Advertising or Marketing} purpose of \textit{First-party-collection-use} and \textit{Third-party-sharing}. At this stage, we drop the categories absent in the privacy labels. For example, \textit{Policy Change} is a high-level category in OPP-115 which is not present in the \textit{Privacy Label Taxonomy}. 

\medskip
\noindent \textbf{Adding New Categories} As indicated earlier, the OPP-115 taxonomy misses some of the lower-level data categories and purposes. We add these missing elements and adapt the OPP-115 taxonomy to \textit{Privacy Label Taxonomy}. 

Apart from the high level categories from the taxonomy, we also add two high level categories: \textit{Data Deletion Option} and \textit{Encryption in Transit}. Both the categories are part of \textit{Security Practices} privacy type from DSS. \textit{Data Deletion} corresponds to when the app ``Provides a way for you to request that your data be deleted, or automatically deletes or anonymizes your data within 90 days''. As there is no specific way to get this information from the taxonomy, we create a separate high level practice for Data Deletion. For \textit{Secure Data Transfer}, there is low level element in the taxonomy that covers the practice, however, since the other categories from the taxonomy in the hierarchy are not related, we add \textit{Secure Data Transfer} as a high level category. Also note that since there were less than 100 annotations for this category, we also perform additional annotations and increase the dataset size.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{figures/good_pdfs/datatype_inconsistency2_no_thresh_cropped.pdf}
  \caption{}
  \label{fig:inconsistency_app_no_thresh}
\end{figure}

% \begin{figure*}[h]
%   \centering
%   \includegraphics[width=2\columnwidth]{figures/good_pdfs/heatmap2_cropped.pdf}
%   \caption{}
%   \label{fig:inconsistency_app}
% \end{figure*}

\subsection{Annotation Setup}
\label{appendix:annotation_setup}

\noindent \textbf{Creating Annotation Set} For our \textit{Privacy Label Taxonomy}, we were able to have the data missing from OPP-115 for \red{13} elements. Curating the candidate set for missing categories is a major challenge due to label imbalance. To address this issue, we follow the approach used by Harkous et al.,~\cite{harkous2022hark} and use the task of \textit{Natural Language Inference} (NLI) to curate the candidate set. The NLI tasks consist of a hypothesis and a premise, and the objective is to determine if the hypothesis is true (\texttt{entailment}), false (\texttt{contradiction}) or undetermined (\texttt{neutral}) given the premise~\cite{maccartney2009natural}. For example, if the premise is: \textit{``Your data is safely and completely removed from our servers or retained only in anonymized form.''} and the hypothesis is \textit{``Data deletion is being discussed''}, then this instance will receive an entailment. On the other hand, if the hypothesis were \textit{``Policy change is being discussed''}, then the label would be neutral. This method of using NLI-based sampling to reduce the annotation effort has been shown to be effective by Harkous et al.~\cite{harkous2022hark}.

We start by creating a hypothesis for each of the missing categories that we have. For example, for \textit{Data Deletion Option}, we created two hypotheses: ``Data deletion is being discussed'' and ``Data Anonymization is being discussed''. For the NLI task, we used the T5-Large model checkpoint from \texttt{Huggingface}. This model is already trained on MultiNLI task~\cite{2020t5} which consists of a multi-genre dataset covering a large variety of domains.  Next, we run the NLI model and get weak labels for all the missing categories. Note that these are weak labels that are later manually annotated to create the training set.

\medskip
\noindent \textbf{Annotation Details} Using the NLI sampling approach, we curated a candidate set with 2000 segments for each of the missing categories. These segments are roughly balanced based on the weak labels assigned by the NLI model. For each class, we then randomly sample 500 segments to annotate. Two of the authors annotated the segments and created the training set.

The annotation was performed using the label studio framework~\cite{labstud}. The framework supports not only simple natural language processing tasks but also sophisticated labels such as taxonomies and sentence highlightings. The framework also supports active learning with the capability of integrating a backend machine learning classifier of one's taste in order to facilitate annotation.

The label studio server was deployed in an internal network, where the two authors simultaneously worked on annotating and creating the training set. Figure \ref{fig:anno_setup} shows the annotation setup used by the authors.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{figures/good_pdfs/anno_setup.png}
  \caption{Label Studio Annotation Setup}
  \label{fig:anno_setup}
\end{figure}

After the annotation step, the dataset was converted into a data frame consisting of the text column and a binary indicator column for each of the categories, to prepare for the training.


\subsection{Training Setup}
\label{appendix:training_setup}
Large language models like BERT~\cite{devlin-etal-2019-bert}, T5~\cite{2020t5} etc have shown remarkable performance using small training sets. Thus, for our purposes, we use the \texttt{distilbert-base-uncased}~\cite{sanh2019distilbert} model consisting of 67 million parameters. This model is the distilled version of BERT~\cite{sanh2019distilbert}. It has 40\% fewer parameters, can run 60\% faster and performs only slightly worse (\textasciitilde 5\%) than the original \texttt{bert-base-uncased} model on several natural language tasks. Additionally, we also perform domain adaptation by pre-training the DistilBert model on privacy policy text with the Masked Language Model (MLM) task. In particular, we pre-trained the model with the default hyperparameters, with a batch size of 256 for 24800 steps on a single NVIDIA A100 GPU.

We then use the new pre-trained model to train the category classifiers for the Privacy Label Taxonomy. We use a classification head on the model after adding a linear classification. For classification, the data annotated by the authors is split into two parts: testing (20\%) and training sets (80\%).


\section{Data Practices in Privacy Labels}
\label{appendix:landscape_details}
In this section, we look into the distribution of all the data types as shown in \cref{fig:inconsistency_app_no_thresh}. From this figure, we observe that the six categories--App Activity, App Info \& Performance, Device IDs, Financial Info, Location, Personal Info--are reported to be the most collected in Google, while the six categories--Contact Info, Diagnostics, Identifiers, Location, Purchases, Usage Data and User Content--are reported to be the most collected in Apple.

\begin{figure*}
\hspace*{-2.2cm} 
  \centering
  \includegraphics[width=1.25\columnwidth]{figures/good_pdfs/google_apple_highlevel_category_all_cropped.pdf}
  \caption{Distribution of data categories for high level
practices for apps in Play Store (top) and App store (bottom).}
  \label{fig:high_level_data_dist}
\end{figure*}



 
\section{Developer Study}
\label{app:dev-study}
For the Developer Study (\cref{sec:developer}) we sent emails to developers in 3 different categories: (A) apps stating that they encrypt data without collecting or sharing data, (B) apps changing their practice from not collecting/sharing data to collecting/sharing data, and (C) apps changing their practices from collecting/sharing data to not collecting/sharing data.

For category (A) we used the following template:
\begin{enumerate}
\item[] \textit{We hope this email finds you well. We are researchers at <LAB\_NAME> and have been using your app, <APP\_NAME>, in our recent studies. We have noticed that in the data safety section of your app, it states that you encrypt data. However, we have also noticed that your app does not collect or share data.}

\textit{We are reaching out to ask if you could clarify this for us. We are trying to better understand the data safety section implemented in your app. We appreciate any information you can provide.}

\textit{Thank you for your time and we look forward to your response.}
\end{enumerate}
\section{Comparing Privacy Policies with Privacy Labels}
In this section, we provide details about how to obtain privacy practices present in the policies. We first note that \textit{Data Category} and \textit{Purpose} are the lowest levels in the taxonomy such that there are classifiers for each data category and purpose. So, extracting lower-level practices from policies is straightforward. Furthermore, we note that we have added classifiers for \textit{Encryption in Transit} and \textit{Data Deletion Option} separately. Additionally, we have two high-level classifiers, namely \textit{First-Party-Collection} and \textit{Third-party-collection} that capture segments that refer to data collection by first parties and data sharing to third parties, respectively.

To extract the remaining high-level practices, we follow the mapping shown in  \cref{tab:policy_to_label}. Specifically, as shown in \cref{tab:policy_to_label} we use multiple data category classifiers in conjunction with high-level classifier (First-party-collection-share/Third-party-collection-share) to indicate if the policy mentions data collection or data sharing. This result can be directly compared with the categories present in Google's Data Safety Section.

To match the policy to the Apple Privacy Label, we use an additional classifier: \textit{Identifiability}. This represents if the data being collected is anonymous or not. If the data is anonymous then we equate it to the \textit{Data Not Linked to You} label else the \textit{Data Linked to You} label. For example, To obtain whether a policy is collecting \textit{Location} under \textit{Data Linked To You}, we check whether there are any segments where the lower level \textit{Data Category} classifier tags the segments to contain \textit{Location} information. Then we check  whether these segments also have either \textit{First-party-collection} or \textit{Third-party-collection-share} tags in combination with \textit{Identifiability-identifiable} tag. 
\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.17]{figures/good_pdfs/purpose_label_policy_cropped.pdf}
    \caption{Inconsistencies between privacy policies and DSS, purpose based}
    \label{fig:purpose_inconst_google}
\end{figure}


\section{Mapping from DSS to APL}
\label{appendix:mapping}

In \cref{table:common_map1} and \cref{table:common_map2} we show how we convert the datatypes of DSS to those of APL. We do these conversions based on the definitions provided by Google and Apple respectively. 

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.17]{figures/good_pdfs/apple_datatypes_inconsistency_cropped.pdf}
    \caption{Inconsistencies between privacy policies and APL, datatypes based}
    \label{fig:datatype_inconst_apple}
\end{figure}
% \clearpage
\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.17]{figures/good_pdfs/datatypes_label_policy_cropped.pdf}
    \caption{Inconsistencies between privacy policies and DSS, datatypes based}
    \label{fig:datatype_inconst_google}
\end{figure}
% \begin{figure}[htbp]
%   \centering
%   \includegraphics[width=\columnwidth]{figures/good_pdfs/data_safety_card_trends2_cropped.pdf}
%   \caption{Data Safety Trends}
%   \label{fig:trend_with_time}
% \end{figure}

\begin{figure}[p]
  \centering
  \includegraphics[scale=0.17]{figures/good_pdfs/collected_shared_vs_category2_cropped.pdf}
  \caption{Plot showing what data category is collected or shared in Google Data Safety cards}
  \label{fig:google_datatype_distribution}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.8]{figures/good_pdfs/privacyTypes_vs_category_cropped.pdf}
  \caption{Plot showing the data categories used for high-level privacy practices in APL. }
  \label{fig:methodology}
\end{figure}



\begin{figure}[ht]
  \centering
  \includegraphics[width=\columnwidth]{figures/good_pdfs/purposes_google_apple_cropped.pdf}
  \caption{Plot showing the distribution of purpose for high-level privacy practices in APL}
  \label{fig:purpose_methodology}
\end{figure}


% \begin{figure*}
%   \centering
%   \includegraphics[width=2\columnwidth]{figures/good_pdfs/purpose_datatype_paircount_google_cropped.pdf}
%   \caption{Plot showing what data category is collected or shared in Google Data Safety cards}
%   \label{fig:google_datatype_purpose_distribution}
% \end{figure*}


\begin{table}[htbp]
\footnotesize
    \centering
\begin{tabularx}{\columnwidth}{|p{3.3cm}|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|}
\hline
\textbf{Data Category Classifiers}  & \textbf{High Level Classifier}  & \textbf{Google Data Safety Section} & \textbf{Classifier} & \textbf{Apple Privacy Labels} \\ \hline
\multirow{2}{3.3cm}{App Activity, App Info and Performance, Sensitive Info, Location, Health and Fitness, ...} & \multirow{2}{3cm}{First-party-collection-share} & \multirow{2}{3cm}{Data Collection}  & Identifiability (Identifiable) & Data Linked to You \\ \cline{4-5} 
 & & & Identifiability (Anonymous) & Data Not Linked to You \\ \hline
\multirow{2}{3.3cm}{App Activity, App Info and Performance, Sensitive Info, Location, Health and Fitness, ...} & \multirow{2}{3cm}{Third-party-collection-share} & \multirow{2}{3cm}{Data Sharing} & Identifiability (Identifiable) & Data Linked to You \\ \cline{4-5} 
& & & Identifiability (Anonymous) & Data Not Linked to You        \\ \hline
\end{tabularx}
\caption{This table shows the bottoms-up approach to get the high-level classification for Google's Data Safety Section and Apple Privacy Labels}
\label{tab:policy_to_label}
\end{table}

\begin{table}[htbp]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Category} & \textbf{CNN ~\cite{o2015introduction}} & \textbf{BERT ~\cite{devlin-etal-2019-bert}} & \textbf{Here}\\
\midrule
\rowcolor{aliceblue}First-party-collection-share  & 82 & 91 & 98 \\
Third-party-sharing-collection & 82 & 90 & 96 \\
\rowcolor{aliceblue}Identifiability & 77 & 91 & 97\\
Does-does-not & 86 & 93 & 96 \\
\rowcolor{aliceblue}Encryption-in-transit  & N/A & N/A & 99 \\
Data Deletion Option  & N/A & N/A & 91 \\
\rowcolor{aliceblue} (DC) App Activity & N/A & N/A & 93 \\
(DC) App Info and Performance & N/A & N/A & 93 \\
\rowcolor{aliceblue} (DC) Sensitive Info  & N/A & N/A & 97 \\
(DC) Location  & N/A & N/A & 99 \\
\rowcolor{aliceblue} (DC) Health and Fitness  & N/A & N/A & 97 \\
(DC) Device or Other ID  & N/A & N/A & 94 \\
\rowcolor{aliceblue} (DC) Photos and Videos  & N/A & N/A & 96 \\
(DC) Web Browsing  & N/A & N/A & 96 \\
\rowcolor{aliceblue} (DC) Contacts  & N/A & N/A & 87 \\
(DC) Calendar  & N/A & N/A & 94 \\
\rowcolor{aliceblue} (Purp) Account Management  & N/A & N/A & 92 \\
(Purp) Developer Communication  & N/A & N/A & 93 \\
\rowcolor{aliceblue} (Purp) Personalization & N/A & N/A & 98 \\
\bottomrule
\end{tabular}
\caption{Classifiers's performance on the test set. Training was done on one GPU with early stopping.}
\label{tab:privacy_label_classifier_stats}
\end{table}

\begin{table}[htbp]
\footnotesize
\centering
\begin{tabular}{>{\arraybackslash}l>{\arraybackslash}l>{\arraybackslash}l}
\toprule
\multicolumn{1}{c}{\textbf{Google Purposes}} & $\rightarrow$      & \multicolumn{1}{c}{\textbf{Apple Purposes}} \\ \midrule
Advertising or Marketing  &$\rightarrow$  & Advertising or Marketing  \\ \midrule
\rowcolor{aliceblue}Analytics   & $\rightarrow$ & Analytics\\ \midrule
App Functionality   & $\rightarrow$ &App Functionality \\ \midrule
\rowcolor{aliceblue}\begin{tabular}[l]{@{}l@{}}Fraud prevention, Security, \\ and Compliance\end{tabular} & $\rightarrow$ & App Functionality\\ \midrule
Personalization  & $\rightarrow$ & Personalization \\ \midrule
\rowcolor{aliceblue}Account Management       & $\rightarrow$ & N/A  \\  \midrule
Developer Communication  & $\rightarrow$ & N/A  \\
\bottomrule
\end{tabular}
\caption{Table showing the common mapping from Data Safety Card to Apple Privacy Label}
\label{table:common_map1}
\end{table}

\begin{table}[p]
    \footnotesize
    \centering
    \begin{tabular}{>{\arraybackslash}l>{\arraybackslash}l>{\arraybackslash}l}
    \toprule
    \multicolumn{1}{c}{\textbf{Google DataType}} & $\rightarrow$ & \multicolumn{1}{c}{\textbf{Apple DataType}} \\ \midrule
    Approximate Location & $\rightarrow$ & Coarse Location\\ \midrule
\rowcolor{aliceblue}Precise Location & $\rightarrow$ & Precise Location\\ \midrule
Name & $\rightarrow$ & Name\\ \midrule
\rowcolor{aliceblue}Email Address & $\rightarrow$ & Email Address\\ \midrule
Address & $\rightarrow$ & Physical Address\\ \midrule
\rowcolor{aliceblue}Phone Number & $\rightarrow$ & Phone Number\\ \midrule
Race And Ethnicity & $\rightarrow$ & Sensitive Info\\ \midrule
\rowcolor{aliceblue}Political Or Religious Belief & $\rightarrow$ & Sensitive Info\\ \midrule
Sexual Orientation & $\rightarrow$ & Sensitive Info\\ \midrule
\rowcolor{aliceblue}User Ids & $\rightarrow$ & User Id\\ \midrule
User Payment Info & $\rightarrow$ & Payment Info\\ \midrule
\rowcolor{aliceblue}Credit Score & $\rightarrow$ & Credit Info\\ \midrule
Other Financial Info & $\rightarrow$ & Other Financial Info\\ \midrule
\rowcolor{aliceblue}Purchase History & $\rightarrow$ & Purchase History\\ \midrule
Health Info & $\rightarrow$ & Health\\ \midrule
\rowcolor{aliceblue}Fitness Info & $\rightarrow$ & Fitness\\ \midrule
Emails & $\rightarrow$ & Emails Or Text Messages\\ \midrule
\rowcolor{aliceblue}Sms Or Mms & $\rightarrow$ & Emails Or Text Messages\\ \midrule
Other In-App Messages & $\rightarrow$ & N/A\\ \midrule
\rowcolor{aliceblue}Photos & $\rightarrow$ & Photos Or Videos\\ \midrule
Videos & $\rightarrow$ & Photos Or Videos\\ \midrule
\rowcolor{aliceblue}Voice Or Sound Recordings & $\rightarrow$ & Audio Data\\ \midrule
Music Files & $\rightarrow$ & N/A\\ \midrule
\rowcolor{aliceblue}Other Audio Files & $\rightarrow$ & N/A\\ \midrule
Files And Docs & $\rightarrow$ & N/A\\ \midrule
\rowcolor{aliceblue}Calendar & $\rightarrow$ & N/A\\ \midrule
Contacts & $\rightarrow$ & Contacts\\ \midrule
\rowcolor{aliceblue}App Interactions & $\rightarrow$ & Product Interaction\\ \midrule
Other User-Generated Content & $\rightarrow$ & Other User Content\\ \midrule
\rowcolor{aliceblue}In-App Search History & $\rightarrow$ & Search History\\ \midrule
Other Actions & $\rightarrow$ & N/A\\ \midrule
\rowcolor{aliceblue}Web Browsing History & $\rightarrow$ & Browsing History\\ \midrule
Crash Logs & $\rightarrow$ & Crash Data\\ \midrule
\rowcolor{aliceblue}Diagnostics & $\rightarrow$ & Performance Data\\ \midrule
Other App Performance Data & $\rightarrow$ & Other Diagnostic Data\\ \midrule
\rowcolor{aliceblue}Device Or Other Ids & $\rightarrow$ & Device Id\\ \midrule
Other Info & $\rightarrow$ & N/A\\ \midrule
    \bottomrule
    \end{tabular}
    % \caption{Caption}
    % \label{tab:my_label}    
    \caption{Table showing the common mapping from Data Safety Card to Apple Privacy Label}
    \label{table:common_map2}
\end{table}
