\section{Discussion}
In this paper, we investigated the consistency of privacy labels with privacy policies and labels on other platforms. Our findings suggest that there is a significant degree of inconsistency in privacy labels. Overall, there is a need for greater consistency in the way that privacy practices are disclosed to users, both within and between platforms. In this section, we discuss the implications of our findings and suggest potential solutions for improving the transparency and consistency of privacy practices. We also discuss the limitations of our study.\smallskip

\noindent\textbf{Comparison between the two labels.} We analyzed both the Data Safety Sections and the Apple Privacy Labels and find that the two labels cover different aspects of data practices. While both labels provide information about the types of data that apps collect, Apple's privacy label does not distinguish between data collection and data sharing. Apple's privacy label is more explicit about certain aspects of data practices, such as linkability, third-party advertising, and tracking, whereas data safety sections lack these details, but does inform the users about the safety of their data (\textit{Data Encryption}) and the choices that they have with developers (\textit{Data Deletion Option}). These practices may be of particular interest to the users in light of the GDPR~\cite{linden2018privacy}, which requires companies to provide a clear and explicit purpose for the collection and use of personal data. The regulations like the GDPR and the CCPA also provide the right to delete the data to the users, which is covered in Data safety forms but not in the Apple privacy labels.

The comparison between the two labels highlights the importance of considering multiple sources of information when evaluating the data practices of apps. By combining the information provided by both labels, users can make more informed decisions about their privacy and the apps they choose to use.\smallskip

\noindent\textbf{Usability of Privacy Policies For Apps.} Privacy policies have been used as a default framework for notice and choice to users. Our analysis reveals that many developers have several products, including websites, Internet of Things (IoT) devices, and applications. However, it is common for these products from the same developer to have the same privacy policy, even if they collect data in different ways. This provides inaccurate information, as the privacy policy itself may not accurately convey the privacy practices of a specific product. This can be addressed by having separate privacy policies for each product or by clearly identifying the specific practices that apply to each product within a single privacy policy. Failing to do so may lead to misunderstandings and mistrust among users, and may also violate privacy regulations.\smallskip

\noindent\textbf{Inconsistencies in disclosed practices across platforms.} Our findings indicate that there are inconsistencies between the privacy labels in the Apple Privacy Labels and the Google Data Safety Sections for the same apps. One possible reason for these inconsistencies is the confusing framework for privacy labels. While previous research~\cite{li2022understanding} has shown that privacy labels are useful for both developers and users, it also highlighted that filling privacy labels is perceived as challenging extra work. On top of that, developers are also unclear about definitions which can result in confusion and ultimately, inaccurate privacy labels. This confusion can be compounded by the fact that different platforms may use different terminology to describe similar practices. For example, in Apple's privacy label, the term \textit{tracking} is used when data collected is linked with third-party data for advertising purposes or when data is shared with a third party, which can be confusing to the developers, even when they are asked to pay close attention~\cite{li2022understanding}.

Another possible reason for the inconsistencies we observed is the casual attitude of some developers toward disclosing their data practices. Some developers may not fully understand the data practices of their own apps, or may not prioritize accurately disclosing this information to users. Finally, the platforms lack consistency checks to ensure that the information provided in the privacy labels is accurate. Without these checks, it is possible for developers to provide misleading or incomplete information about their data practices, just to meet the requirements.

We note that these inconsistencies can have serious consequences for users, as they may be confused about the privacy practices of the apps they use. If the practices disclosed in the privacy labels are inaccurate, it can reduce the efficacy of these labels as a tool for helping users make informed decisions about their privacy. Even worse, it could induce a false sense of security in users, who may assume that their data is being handled in a certain way when it is not.\smallskip

\noindent\textbf{Usability of Privacy Labels.} Even though our analysis finds inconsistencies between privacy labels and privacy practices, evidence suggests that privacy labels generally carry more specific information about the practices. They include information about the types of data that an app collects, how the data is used, and whether it is shared with third parties. This information can be very useful for users who are concerned about their privacy and want to ensure that they are only using apps that respect their personal data.

However, the accuracy of privacy labels is not guaranteed. While developers are required to disclose their data practices in order to obtain a privacy label, there is no guarantee that the information they provide is accurate or complete. As such, it is important for platforms to recognize that developers may not always be honest about their data practices. Therefore, it is necessary to have systems in place to verify the accuracy of privacy labels and to hold developers accountable for any discrepancies. This is particularly important because the false labels can create a false sense of security among the users. 

One potential model for regulating privacy labels is a system similar to the one used for food nutrition labels, which are regulated by the Food and Drug Administration (FDA). A regulatory body could be established to oversee privacy labels and ensure that they are accurate and consistent. This could help to build trust among users and encourage developers to be more transparent about their data practices.\smallskip

\noindent\textbf{Limitations.} Extracting privacy practices using automated analysis comes with several limitations. First, the framework used here treats privacy policies as segmented text, missing out of relations between different segments. This can potentially result in internal contradictions, as shown in ~\cite{andow2019policylint}. Second, the classifiers used to extract privacy practices can introduce errors, which can then propagate through the pipeline and induce uncertainty in the inconsistency rates. We do however note that the error rate of our classifiers is significantly less than the inconsistency rate obtained, indicating that the results presented in the paper are valid. 

% \begin{itemize}
%     \item Inconsistency via data flow analysis
%     \item Limitations of Automated Policy analysis, specially for practices which can long range relations
% \end{itemize}

% \begin{itemize}
%     \item Comparison between the two labels: Talk about how the two labels combined can more information.\\
%     Subpoint: The two labels are covering very different aspects data practices. Apple does not distinguish between colelction and sharing, whereas google is not explicit about linkability, third party advertising, tracking etc. Connect these to the GDPR
%     \item possible reasons for the discrepancy, both for privacy policies and for labels
%     \item Talk about privacy policies not being adequate for conveying information about the practices and they cover vastly different informations. This is sort of a motivation for using privacy labels, but the information provided there is not reliable as well. 
%     \item Limitations: talk about automated privacy policy analysis.
%     \item Future direction: Use privacy labels to automatically edit privacy policies and generate a more comprehensive/readable privacy policies
% \end{itemize}