\section{Conclusion}
\label{sec:conc}
In this work we have presented a novel, one-shot point cloud simplification algorithm capable of preserving both the salient features and the overall structure of the original point cloud. We reduce the cloud size by up to three orders of magnitude without the need for computationally intensive training on huge datasets. This is achieved via a greedy algorithm which iteratively selects points based on a selection criterion determined by modeling the surface variation over the original point cloud using Gaussian processes with kernels which operate on Riemannian manifolds. We show that our technique achieves competitive results and runtimes when compared to a number of relevant methods, outperforming all baselines tested in terms of mean Hausdorff distance on \textit{Lucy}, the largest and most complex point cloud we consider, consisting of 14 million points. Our method can also be used to improve the computational efficiency of downstream tasks such as point cloud registration with no negative effects on the empirical performance.

\paragraph{Future work:} 
Whilst Hausdorff distance is a useful metric, it is not the ideal candidate for assessing the feature sensitivity of a simplification algorithm, as it tends to return lower errors for more evenly distributed clouds. Whilst out of the scope of this work, there is a clear need for a well-defined and widely adopted error metric for curvature-sensitive simplification. Currently, the best way to evaluate this is a qualitative visual inspection of the resulting point cloud (or reconstructed mesh). This view is supported by the fact that some recent works employ user studies to evaluate their feature-preserving approaches \cite{potamias2022revisiting}.

In this work we study the setting where we enforce the restriction that the simplified cloud be a subset of the original; as discussed in Section \ref{sec:sod}, a greedy inference scheme is appropriate in this setting. However, this assumption could be relaxed and sparse GPs can be used to perform continuous optimization of the inducing points across the point cloud \cite{hutchinson2021vector}. This would also allow occluded as well as extremely noisy point clouds, where the original observations do not necessarily lie on the true surface of the manifold, to be denoised and/or simplified.






