\section{Empirical evaluation}
\label{sec:experiments}
% \begin{figure}
%      \centering
%         \includegraphics[scale=0.58, trim=2.5cm 8cm 1cm 2cm, clip]{images/originals.pdf}
%          \caption{The original Stanford meshes corresponding to the three point cloud datasets evaluated.}
%          \vspace{-0.4cm}
%          \label{fig:original}
% \end{figure}
%
%
\begin{figure*}[t]
     \centering
        \includegraphics[trim=0cm 2.75cm 0cm 3.4cm, clip, width=0.95\linewidth]{images/dragon.pdf}
         \caption{Simplified representations of the Dragon point cloud for simplification ratio $\alpha=0.03$ (top row) and associated reconstructed meshes (bottom row) for all evaluated simplification techniques.}
         \label{fig:dragon_all}
\end{figure*}
%
\begin{figure*}
     \centering
        \includegraphics[trim=0cm 9.35cm 0cm 0.1cm, clip, width=0.95\linewidth]{images/noisy.pdf}
         \caption{Simplification results of a noisy Armadillo with Gaussian noise added to every point position (of standard deviation $\sigma = 2.5\times 10^{-3} \times d$, where $d$ is the bounding box diagonal length) for simplification ratio $\alpha=0.05$ for all evaluated simplification techniques.}
         \vspace{-0.3cm}
         \label{fig:noisy}
\end{figure*}
%
In this section, we extensively evaluate the proposed simplification method using various point cloud datasets and processing techniques. First, we compare our simplification technique both quantitively and qualitatively using benchmark object level point clouds as given in subsection \ref{sec:opc}. Second, subsection \ref{sec:spc} demonstrates the application of our method on a scene level point cloud as well as some self-acquired noisy objects and human point clouds. Finally, in subsection \ref{sec:reg} we extend the use-case of our algorithm as a time and memory efficient pre-processing step for the downstream task of point cloud registration. 
%
\subsection{Benchmark object level point clouds}
\label{sec:opc}
\paragraph{Evaluation criteria:}
\label{sec:eval_criteria}
In order to evaluate the performance of our method in comparison to other simplification techniques, we firstly use each simplified point cloud obtained from three object level point clouds to form simplified meshes, using \textit{screened Poisson surface reconstruction} \cite{kazhdan2013screened}. We can then compute the reconstruction errors between the original meshes, and the reconstructed meshes formed from our simplified clouds. Specifically, we choose to evaluate the mean and maximum \textit{Hausdorff distance} \cite{cignoni1998metro}. Evaluating the error associated with mesh reconstruction is effective at quantifying the ability of each method to preserve features from the original cloud, as accurate reconstruction of a mesh from a simplified point cloud requires that a high density of points be placed in the vicinity of finer details within the cloud. The \textit{MeshLab} software \cite{meshlab} was used to reconstruct all surfaces and compute the Hausdorff distances. Also, given that one of our primary aims is to preserve sharp features within each point cloud, we also report the \textit{average surface variation} over each simplified point cloud. The surface variation at each point is computed using the approach described in Section \ref{sec:surface}.
%
\paragraph{Baselines:}
We use the aforementioned evaluation procedure to compare our method (denoted \textit{GP}) empirically to a number of competing simplification techniques discussed in Section \ref{sec:rw}. We compare our approach to \textit{PC-Simp}, \textit{AIVS}, \textit{HC} and \textit{WLOP}, with the latter two approaches implemented using the CGAL library \cite{cgal:eb-23a}. For the HC method, the size and variation parameters discussed in Section \ref{sec:rw} were manually tuned to obtain approximate desired simplified sizes. Also, as noted in Section \ref{sec:rw}, we use the non-curvature aware version of the AIVS algorithm, as there is no available open-source implementation of the curvature-aware variant. 
% A naive \textit{top curvature points (TCP)} approach was also attempted, involving simply selecting the points from the original cloud which correspond to the largest values of surface variation, as defined in Section \ref{sec:surface}. However, due to the challenging nature of the low simplification ratio setting which we study in this work, it was not possible to reconstruct a mesh from the TCP simplified cloud which bore any resemblance to the original. This is because unlike our algorithm, TCP does not explore \textit{any} low curvature regions within the original point cloud.
%
\paragraph{Experimental details:}
We evaluate our proposed method and the aforementioned baselines on three complex object-level point clouds from the Stanford 3D Scanning Repository \cite{levoy2005stanford}, namely \textit{Armadillo} ($N = 1,72,974$), \textit{Dragon} ($N = 4,37,645$) and \textit{Lucy} ($N = 1,40,27,872$). Let the \textit{simplification ratio} be defined as $\alpha = M/N$. In this work we focus on the challenging regime where we wish to significantly reduce the size of the cloud, such that $\alpha << 1$. It is in this regime that feature-preserving techniques such as ours become particularly important, as we do not have a large number of points to select, thus we must efficiently select points which allow us to capture the salient features of the original cloud. We chose $\alpha$ for each cloud by finding the minimum $\alpha$ at which all evaluated techniques were capable of forming simplified clouds from which meshes visually comparable to the original meshes could be generated \cite{levoy2005stanford}. This value varies depending on the surface complexity of each cloud, thus for \textit{Armadillo}, \textit{Dragon} and \textit{Lucy} we chose $\alpha = 0.05$, $0.03$ and $0.002$ respectively. Additionally, we also visually evaluate the point cloud simplification results of all aforementioned techniques on a noisy Armadillo from the PCPNet dataset \cite{guerrero2018pcpnet}, with $\alpha=0.05$. This corresponds to the original Armadillo model surface sampled $10^5$ times ($N = 1,00,000$), with Gaussian noise (of standard deviation $\sigma = 2.5\times 10^{-3} \times d$, where $d$ is bounding box diagonal length) added to every point position. Our code is included in the supplementary material, which will be open sourced upon publication, alongside further experimental details.
%
\begin{table*}
    \centering
    \begin{tabular}{cccccccccc}
    \toprule
    {} & \multicolumn{3}{c}{Mean Hausdorff Distance ($\downarrow$)} & \multicolumn{3}{c}{Max. Hausdorff Distance ($\downarrow$)} & \multicolumn{3}{c}{Mean Surface Variation ($\uparrow$)}  \\
    \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10}
    {} & Armadillo & Dragon & Lucy & Armadillo & Dragon & Lucy & Armadillo & Dragon & Lucy \\
    \midrule
     GP (ours) & 0.246 & \underline{0.000246} & \textbf{1.11} & \textbf{3.26} & \underline{0.00457} & 195.78 & \underline{0.0728} & \underline{0.0546} & \underline{0.0724} \\
     HC & 0.374 & 0.000758 & \underline{1.14} & \textbf{3.26} & 0.0141 & \textbf{195.41} & \textbf{0.0803} & \textbf{0.0686} & \textbf{0.0762} \\
     WLOP & \textbf{0.197} & \textbf{0.000188} & 1.29 & 4.14 & \textbf{0.00417} & \underline{195.52} & 0.0557 & 0.0413 & 0.0631 \\
     PC-Simp & \underline{0.241} & 0.000487 & - & 5.48 & 0.00802 & - & 0.0364 & 0.0433 & - \\
     AIVS & 0.715 & 0.000638 & 8.75 & 4.11 & 0.00539 & 196.45 & 0.0513 & 0.0441 & 0.0666 \\
    \bottomrule
    \\
    \end{tabular}
    \vspace{-0.3cm}
    \caption{Empirical results for all tested simplification methods and point clouds. We report the maximum and mean Hausdorff distances between the original meshes, and the meshes reconstructed from the simplified point clouds. Also reported is the average surface variation over each simplified point cloud. Best results are boldfaced, whilst second-best are underlined.}
    \label{tab:results}
    \vspace{-0.2cm}
\end{table*}
%
% \begin{table}
%     \centering
%     \begin{tabular}{cccc}
%     \toprule
%     {} & \multicolumn{3}{c}{Time (s) ($\downarrow$)}  \\
%     \cmidrule(lr){2-4}
%     {} & Armadillo & Dragon & Lucy \\
%     \midrule
%      GP (ours) & \underline{0.809} & \underline{1.362} & \underline{12.86} \\
%      HC & \textbf{0.144} & \textbf{1.078} & \textbf{9.992} \\
%      WLOP & 3.536 & 6.501 & 84.158 \\
%      PC-Simp & 132.586 & 245.498 & -\\
%      AIVS & 17.236 & 44.570 & 1983.485 \\
%     \bottomrule
%     \\
%     \end{tabular}
%     \vspace{-0.3cm}
%     \caption{Total runtimes for all simplification methods and datasets. Best times are boldfaced, second-best are underlined.}
%     \label{tab:timings}
% \end{table}

\begin{table}
    \centering
    \begin{tabular}{cccc}
    \toprule
    {} & \multicolumn{3}{c}{Time (s) ($\downarrow$)}  \\
    \cmidrule(lr){2-4}
    {} & Armadillo & Dragon & Lucy \\
    \midrule
     GP (ours) & \underline{0.8} & \underline{1.4} & \underline{12.9} \\
     HC & \textbf{0.1} & \textbf{1.1} & \textbf{10.0} \\
     WLOP & 3.5 & 6.5 & 84.2 \\
     PC-Simp & 132.6 & 245.5 & -\\
     AIVS & 17.2 & 44.6 & 1983.5 \\
    \bottomrule
    \\
    \end{tabular}
    \vspace{-0.3cm}
    \caption{Total runtimes for all simplification methods and point clouds. Best times are boldfaced, second-best are underlined.}
    \label{tab:timings}
\end{table}
%
\paragraph{Discussion:}
From the results presented in Table \ref{tab:results}, it is clear that our proposed method is capable of comparable empirical performance to many of the existing methods for simplifying point clouds. The GP-based approach outperforms the AIVS baseline across all experiments and metrics, and outperforms the PC-Simp baseline on all but the mean Hausdorff distance for the Armadillo experiment. As shown in Table \ref{tab:timings}, our algorithm also runs considerably faster than both of these approaches. Note that due to the scale of \textit{Lucy}, we were unable to evaluate PC-Simp on this cloud as it was taking more than two hours to run. 

HC is the only baseline with a shorter runtime than our method, and obtains maximum Hausdorff distances comparable to those obtained by our approach. However, as discussed in Section \ref{sec:rw}, tuning the user-specified HC parameters can make striking a balance between feature preservation and retaining a sufficient density of points across the cloud relatively challenging. Moreover, there is no control over the size of the simplified cloud, as discussed by the authors \cite{pauly2002efficient} and in subsequent work \cite{lv2021approximate}. We tuned this baseline to attempt to balance this trade-off, and whilst the HC-simplified clouds shown in Figures \ref{fig:dragon_all}, \ref{fig:noisy} and 7 (supplementary material) do have clearly preserved features (an observation supported by the high mean surface variation across all clouds), the density of points away from these areas is very low. This leads to inferior mesh reconstructions compared to our approach, as evidenced by the fact that we obtain superior mean Hausdorff distance compared to HC across all three clouds.

The WLOP baseline does not efficiently preserve the features and favours uniformly covering the domain of the original cloud. Therefore, the mean surface variation of the WLOP simplified clouds is lower, but overall the Hausdorff distances obtained from the reconstructed meshes are superior to those obtained by our method. However, it is noteworthy that on the largest and unarguably the most challenging point cloud, \textit{Lucy}, our method achieves a superior mean Hausdorff distance as compared to all of the other techniques evaluated, including WLOP. Additionally, WLOP is significantly slower than our approach, as shown in Table \ref{tab:timings}. Our surface variation computation is currently performed on a CPU, therefore further improvements to the runtimes of our method shown in Table \ref{tab:timings} could be achieved by re-implementing this in a GPU-compatible framework.

Overall, these results show that our approach provides a computationally efficient option for performing point cloud simplification in settings where the user wishes to strike a balance between preserving high fidelity around sharp features in the cloud, and ensuring that the simplified cloud covers the manifold defined by the original cloud with a sufficient density of points. This is important for generating reconstructions which resemble the original meshes, as is evident from visual inspection of the reconstruction results in Figures \ref{fig:dragon_all} and 7 (supplementary material). In terms of surface reconstruction, our method clearly outperforms all of the other techniques for the \textit{Dragon} (compare the tail, teeth, horns and the face detailing for all methods and additionally the curved body for HC) and the \textit{Armadillo} (compare the ears, hands and feet across all the methods) and gives competitive results for \textit{Lucy}, shown in Figure 6 of the supplementary material. Again, visual inspection of the simplification results for the noisy armadillo in Figure \ref{fig:noisy} demonstrates the balanced feature-sensitivity of our method in comparison to others.

\begin{figure}[H]
     \centering
        \includegraphics[scale=0.33, trim=2cm 5.7cm 4cm 4cm, clip, width=\linewidth]{images/nyu.pdf}
         \caption{GP-based simplification applied on a point cloud derived from real-life NYU Depth V2 Dataset's desk scene \cite{Silberman:ECCV12} with simplification ratio $\alpha=0.03$.}
         \vspace{-0.4cm}
         \label{fig:nyu}
\end{figure}
%
\begin{figure}[H]
     \centering
        \includegraphics[scale=0.9, trim=13cm 6.8cm 14cm 0.2cm, clip, width=0.85\linewidth]{images/new.pdf}
         \caption{Simplification of three self-acquired point clouds.}
         \vspace{-0.4cm}
         \label{fig:new}
\end{figure}

% Overall, we can safely conclude that although HC performs well quantiatively it results in a ill-balanced point distribution which leads to downstream difficulties. and again it is extremely difficult to run it.

The $\mathcal{O}(M^3)$ and $\mathcal{O}(M^2 N)$ complexities associated with training and prediction respectively in the greedy inference scheme described in Section \ref{sec:sod} allow for increased scalability compared to typical GP regression, in which inference has $\mathcal{O}(N^3)$ complexity. The scalability of our approach is limited by the fact that, as in a conventional exact GP, we have a storage demand associated with $\mathbf{K}$ matrix which scales according to $\mathcal{O}(N^2)$. However, we can circumvent this issue when $N$ is very large by simply using Algorithm \ref{alg:simpli} with a randomly selected subset of $P$. For \textit{Armadillo} and \textit{Dragon} we obtain the above results with just 25,000 randomly selected points. For a large point cloud such as \textit{Lucy}, we obtain competitive results using a subset of just 40,000 points to run our simplification algorithm.

%

\subsection{Scene level and self-acquired point clouds}
\label{sec:spc}
Furthermore, we validate our technique's feature-sensitive approach on real-world scanning datasets captured using different acquisition devices. Firstly, we use a desk scene point cloud from the NYU Depth V2 dataset \cite{Silberman:ECCV12}, derived from RGBD data acquired using RGB and Depth cameras from Microsoft Kinect. This cloud and the resulting simplification are shown in Figure \ref{fig:nyu}. Secondly, we acquired point clouds from three real-life objects: an angel, a human and a bike frame. They were captured using FARO's scan-in-a-box system, photogrammetry and AliceVision's Meshroom \cite{alicevision2021} and Artec 3D's portable 3D scanner respectively. All three of them were simplified using our method with $\alpha= 0.04$, $0.05$ and $0.6$ respectively as shown in Figure \ref{fig:new}.

\subsection{Point cloud registration}
\label{sec:reg}
As discussed earlier, PC simplification has benefits for many downstream tasks, not solely surface reconstruction. In Table \ref{tab:register} we present registration results on some simplified clouds. We firstly translate and rotate the original, HC and GP-simplified clouds in the same fashion, before performing global and ICP point-to-point registration \cite{besl1992method} with the Open3D package \cite{Zhou2018}; visualisations are available in the supplementary material (Figure 8). Our GP-simplified cloud allows for quicker registration and leads to superior inlier RMSE.
%
\begin{table}[H]
    \centering
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{cccccc}
    \toprule
    {} & \multicolumn{2}{c}{Inlier RMSE ($\downarrow$)} & \multicolumn{3}{c}{Time (s) ($\downarrow$)}  \\
    \cmidrule(lr){2-3} \cmidrule(lr){4-6} 
    {} & Global ($10^{-3}$) & ICP ($10^{-7}$) & Global & ICP & Total \\
    \midrule
     Original & \underline{4.76} & \textbf{4.08} & \textbf{0.017} & 1.448 & 1.465\\
     HC & 5.41 & \textbf{4.08} & \underline{0.018} & \underline{0.046} & \underline{0.064}\\
     GP (ours) & \textbf{3.91} & \textbf{4.08} & \textbf{0.017} & \textbf{0.040} & \textbf{0.057} \\
    \bottomrule
    \\
    \end{tabular}
    }
    \vspace{-0.5cm}
    \caption{Inlier RMSE and time taken for global and ICP registration. Best results are boldfaced, whilst second-best are underlined.}
    \label{tab:register}
\end{table}
%
\setlength{\tabcolsep}{4pt}



