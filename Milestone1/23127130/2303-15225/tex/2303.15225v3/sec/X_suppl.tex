\clearpage
\setcounter{page}{1}
\section*{Supplementary Material}


\section{Additional experimental details}
\label{sec:exp_det}
Our approach practically has no user-specified parameters, as it generates a simplified cloud based on the desired simplification ratio ($\alpha$). However, we supply to our algorithm (Algorithm 1 in main text) some fixed default values which work well for most point clouds. We set $k_{\text{opt}} = 200$ for all experiments as even with a small subset of the original point cloud, the GP typically converges on an optimal set of hyperparameters within 100 iterations. $k_{\text{init}}$ was chosen to be $1/3$ of the target number of points in the simplified cloud, a ratio which empirically works well across all point clouds tested. Finally, $k_{\text{add}}$ is determined adaptively based on $k_{\text{init}}$, $N$ and $M$. Our algorithm is implemented in the \textit{PyTorch} framework, 
%\cite{paszke2019pytorch}
and whilst the runtimes reported in Table 1 of main manuscript were achieved with GPU acceleration using an NVIDIA A100 with 80GB of RAM, our algorithm can also be run purely on a CPU. All baselines were run on an Intel i7-11800H CPU with 32GB RAM. Our code is available \href{https://drive.google.com/drive/folders/1xtYdHCtUrJOOQbZLlMhMzDFk42QDwqCT?usp=sharing}{here}.
\section{Additional visualisations}
\label{sec:add_vis}
On the following pages we present additional visualisations to accompany the results presented in the main text. Figure \ref{fig:original} shows the original meshes provided here for a better visual comparison. Figure \ref{fig:lucy_all} shows the surface reconstruction results on \textit{Lucy}. Figure \ref{fig:armadillo_all} shows the simplified clouds and reconstructed meshes for all techniques on the \textit{Armadillo} cloud. Figure \ref{fig:regis} is a qualitative comparison of the HC and GP-based approaches to performing point cloud registration on the \textit{Dragon} cloud.

Furthermore, we validate our technique's feature-sensitive approach on real-world scanning datasets captured using different acquisition devices. Firstly, we use a desk scene point cloud from the NYU Depth V2 dataset, derived from RGBD data acquired using RGB and Depth cameras from Microsoft Kinect. This cloud and the resulting simplification are shown in Figure \ref{fig:nyu}. Secondly, we acquired point clouds from three real-life objects: an angel figure, a human and a bike frame. They were captured using FARO's scan-in-a-box system, photogrammetry and AliceVision's Meshroom %\cite{alicevision2021} 
and Artec 3D's portable 3D scanner respectively. The three of them when simplified using our method with $\alpha= 0.04$, $0.05$ and $0.6$ respectively give results which are shown in Figure \ref{fig:new}.

Finally, in Figure \ref{fig:angel} we show an extensive comparison of our method with all the mentioned simplification techniques for a range of simplification ratios for the angel point cloud. Again, our method works best for striking a trade-off between enhancing salient features and keeping the low curvature region well-sampled, and hence leads to the best reconstruction results ($\alpha=0.05$) when compared to the original angel mesh (Figure \ref{fig:original}). The reconstructions obtained from WLOP, PC-Simp and AIVS simplified clouds are less detailed around salient features (compare the hair, fingers, face, wings and feet) while the one from HC-simplified cloud is quite poor around the torso region of the angel because of less density of points around low curvature regions in the simplified cloud.
\vspace{-5cm}
\begin{figure}
     \centering
        \includegraphics[trim=0cm 8cm 5cm 0cm, clip, scale=0.3]{originals.pdf}\vspace{-0.3cm}
         \caption{The original Stanford meshes and the angel mesh.}
         \label{fig:original}
%
\end{figure}

\begin{figure}
     \centering 
        \vspace{-0.3cm}\includegraphics[trim=0cm 3.5cm 0cm 4cm, clip, scale=0.3]{lucy.pdf}\vspace{-0.3cm}
         \caption{Surface reconstruction results of the simplified version of the Lucy point cloud for simplification ratio $\alpha=0.002$ for all evaluated simplification techniques except PC-Simp.}
         \label{fig:lucy_all}
%
\end{figure}
\begin{figure}
     \centering
        \vspace{-5cm}\includegraphics[trim=0cm 1.5cm 0cm 0cm, clip, scale=0.3]{armadillo.pdf}\vspace{-0.3cm}
         \caption{Simplified representations of the Armadillo point cloud for simplification ratio $\alpha=0.05$ (top row) and associated reconstructed meshes (bottom row) for all evaluated simplification techniques.}
    \label{fig:armadillo_all}
\end{figure}
%
% trim= l d r u
%
\begin{figure}
     \centering
        \vspace{-2cm}\includegraphics[scale=0.3, trim=0.2cm 0cm 10cm 0cm, clip]{regis.pdf}
         \caption{Global and ICP registration results shown for the original, HC and GP-simplified versions (simplification ratio $\alpha=0.03$) of the Stanford dragon.}
         \label{fig:regis}
\end{figure}


% \begin{figure}
%      \centering 
%         \includegraphics[trim=0cm 13cm 18cm 2cm, clip, scale=0.75]{nyu.pdf}\vspace{-1.2cm}
%          \caption{GP-based simplification applied on a point cloud derived from real-life NYU Depth V2 Dataset's desk scene \cite{Silberman:ECCV12} with simplification ratio $\alpha=0.03$.}
%          \label{fig:nyu}
% \end{figure}

% \begin{figure}
%      \centering 
%         \includegraphics[trim=0cm 12cm 14cm 2.4cm, clip, scale=0.75]{new.pdf}\vspace{-1.3cm}
%          \caption{Simplification of three self-acquired point clouds.}
%          \label{fig:new}
% \end{figure}


\begin{figure}
     \centering
        \includegraphics[trim=0cm 14cm 18cm 1.7cm, clip, scale=0.75]{nyu.pdf}\vspace{-0.5cm}
           \caption{GP-based simplification applied on a point cloud derived from real-life NYU Depth V2 Dataset's desk scene with simplification ratio $\alpha=0.03$.}
  \label{fig:nyu}
\end{figure}
\begin{figure}
     \centering
        \includegraphics[trim=0cm 14cm 12cm 2.4cm, clip, scale=0.75]{new.pdf} \vspace{-0.5cm}
           \caption{Simplification of three self-acquired point clouds.}
  \label{fig:new}
\end{figure}






















% \begin{figure*}
% \vspace{-1cm}

% \begin{minipage}{0.75\columnwidth}
% \vspace{0.3cm}
%   \hspace{-1cm}\includegraphics[trim=0cm 14cm 18cm 1.7cm, clip, scale=0.75]{nyu.pdf}\vspace{-0.5cm}
%            \caption{GP-based simplification applied on a point cloud derived from real-life NYU Depth V2 Dataset's desk scene with simplification ratio $\alpha=0.03$.}
%   \label{fig:nyu}
% \end{minipage}%
%  \hfill
% \begin{minipage}{1.25\columnwidth}
% \vspace{0.3cm}
% \begin{flushright}
%   \hspace{1cm}\includegraphics[trim=0cm 14cm 12cm 2.4cm, clip, scale=0.75]{new.pdf} \vspace{-0.5cm}
%            \caption{Simplification of three self-acquired point clouds.}
%   \label{fig:new}
%   \end{flushright}
% \end{minipage}
% \end{figure*}











\begin{figure*}
     \centering \vspace{0.1cm}
        \includegraphics[trim=0.5cm 4.5cm 0cm 4.4cm, clip, scale=0.89]{angel.pdf}
         \caption{Simplified representations of the angel point cloud for a variety of simplification ratios (leftmost column) and the meshes reconstructed from clouds obtained using simplification ratio $\alpha=0.05$ for all evaluated simplification techniques (last row).}
         \label{fig:angel}
\end{figure*}
