\nsection{Introduction} \label{sec:intro}

LiDAR (Light Detection And Ranging)
is one of the most innovative sensors in the past decade. By shooting a laser pulse and measuring its reflection,
LiDAR can provide a detailed 3D understanding of the surrounding environment.
Autonomous Driving (AD) is one of the most benefited applications of the high-speed and high-precision sensing of LiDARs. After LiDAR showed its effectiveness in the 2007 DARPA Urban Challenge\cite{urmson2007tartan}, it has been widely recognized as an essential sensor for Level-4 AD and has been adopted in almost all recent robotaxi services (Waymo One~\cite{waymoone}, Cruise~\cite{Cruise}) and AD vehicles operating in the US~\cite{Motional, Nuro}.
While highly beneficial to our everyday life and society, AD is also highly security-critical as even a small operational error can cause fatal consequences~\cite{ubersafety}. To address this, numerous researchers have been conducting security analyses on LiDARs~\cite{petit2015remote, shin2017illusion, cao2019adversarial, jiachen2020towards, cao2021invisible, hallyburton2022security, cao2023you} due to their critical role in AD perception. The major security concern of LiDARs is the fundamental vulnerability against malicious laser shooting, or \textit{LiDAR spoofing attacks}.
The recent research along this line~\cite{jiachen2020towards, zhongyuan2021object, hallyburton2022security} found that such attacks can cause both false positives (injecting a non-existing fake object) and false negatives (removing an existing object). However, we find that there are 3 critical research gaps in these prior efforts: 



\begin{figure}[t!]
\centering
\includegraphics[width=\linewidth]{imgs/intro/ndss_sp_poc_prior_works_3d.pdf}
\caption{Demonstration of the Chosen Pattern Injection (CPI) attack capability with $>$6,000 spoofed points with our improved LiDAR spoofer. This significantly improves the spoofing attack capability from prior works:~\cite{shin2017illusion} ($\sim$10 points),~\cite{cao2019adversarial} ($\sim$20 points)~\cite{jiachen2020towards} ($\sim$200 points), and~\cite{hallyburton2022security} ($\sim$200 points).
}
\label{fig:arbitrary_point}
\end{figure}

\textbf{Considering only one specific LiDAR:}
Velodyne VLP-16~\cite{VLP16} has been dominantly used in the prior works since it is viewed as a \textit{de facto} choice for LiDAR spoofing evaluation after the first practical spoofing attack was proposed in 2017~\cite{shin2017illusion}. The following works thus all evaluate their attacks only on VLP-16~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security, cao2023you} or use the attack capability on VLP-16 to justify the validity of their threat model~\cite{zhongyuan2021object, hau2021shadow}. 
Although these results are valid on VLP-16, there is no guarantee that these results are still valid in more recent LiDARs, known as next-generation or new-generation (or \textit{new-gen}) LiDARs~\cite{yoshioka2022tutorial}, as opposed to the first-generation (or \textit{first-gen}) ones such as VLP-16. The new-gen LiDARs have more advanced security-related features, such as laser timing randomization and pulse fingerprinting. 
Prior works~\cite{cao2019adversarial, cao2023you, shin2017illusion} partially discussed some of them as potential defenses, but none of them experimentally studied their impact and effectiveness against LiDAR spoofing. 


\textbf{Assuming unvalidated attack capabilities:}
So far, all prior works on fake object injection~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security} assume a \textit{Chosen Pattern Injection (CPI)} attack capability, i.e., an attacker can spoof a specifically chosen point cloud pattern that was carefully optimized/identified offline beforehand.
For example, the Adv-LiDAR attack~\cite{cao2019adversarial} is a white-box adversarial attack that needs a specific pattern to trigger a vulnerability in deep neural networks (DNNs). The black-box attacks in~\cite{jiachen2020towards, hallyburton2022security} also require a specific pattern in the shape of a vehicle surface.
However, none of them have systematically
studied how achievable this is in practice.
The top area of Fig.~\ref{fig:arbitrary_point} shows the demonstrated spoofing capabilities so far from prior works~\cite{shin2017illusion, cao2019adversarial, jiachen2020towards, hallyburton2022security}. As shown, none of them were able to show strong pattern control capabilities, not to mention to provide a systematic quantification of such a capability to ensure valid security analysis on the object detector side.


\textbf{Evaluating object detectors with limited spoofing capability modeling and setup diversity:} To study the spoofing attack impacts on the object detector side, prior works typically leverage a mathematical modeling of the spoofing capability to achieve high analysis scalability and flexibility~\cite{cao2019adversarial,jiachen2020towards, hallyburton2022security}. However, the modelings used so far not only fail to correctly capture real-world attack characteristics such as spoofing inaccuracies (detailed in~\S\ref{sec:cpi_capability}, which can significantly bias the analysis results as shown in~\S\ref{sec:od_injection_eval}), but also lack the coverage of more recent LiDAR features that can significantly change the spoofing capabilities (\S\ref{sec:sec_enchance_feats}). Moreover, the object detector model setup is also limited, e.g., no prior works have evaluated the same model design trained on different training datasets, which we found can significantly change the model robustness analysis results (\S\ref{sec:od_injection_eval} and~\S\ref{sec:od_removal}).









To fill these critical research gaps, we conduct the first large-scale measurement study on LiDAR spoofing attack capabilities against object detection. Specifically, our study is driven by 3 key novel research questions (RQ): \\
\textbf{RQ1}: \textit{Are the common design-level assumptions made in prior LiDAR spoofing attacks actually realizable? If so, can they also hold for the more recent new-gen LiDARs?} \\
\textbf{RQ2}: \textit{Do different types of LiDARs, especially the new-gen ones with security-related features, have different vulnerability characteristics to LiDAR spoofing attacks?} \\
\textbf{RQ3}: \textit{Does the vulnerability status of popular object detectors to spoofing attacks significantly change due to the new-gen LiDAR features and different model setups?}


To comprehensively address these RQs, we devote significant engineering efforts to reproduce and/or improve the current state-of-the-art attacks: For RQ1, to properly explore the potential to achieve the CPI attack capability, we improve the spoofing device on their optical and electronics parts (\S\ref{sec:optical_setup}), which enables us to be the first to demonstrate and quantify the CPI attack capability, which is commonly assumed but never clearly demonstrated in prior works~\cite{cao2019adversarial, jiachen2020towards, cao2023you, hallyburton2022security, zhongyuan2021object} and shown in Fig.~\ref{fig:arbitrary_point}. 
For RQ2, to adequately measure the vulnerability status of new-gen LiDARs, we explore \textit{asynchronized} (\S\ref{sec:lidar_spoofing_attack}) spoofing attacks since synchronized ones are directly foiled by their common security-related features such as timing randomization and pulse fingerprinting (\S\ref{sec:inj_other_lidars}). However, since all existing works only consider first-gen LiDARs, their designs predominately focus on synchronized attacks~\cite{shin2017illusion, cao2019adversarial, jiachen2020towards, hallyburton2022security, cao2023you}, leaving the asynchronized attack design space under-explored. 
For RQ3, to enable large-scale evaluation of LiDAR spoofing attack capabilities against different object detectors, we perform novel mathematical modeling of the spoofing attack capabilities on different types of LiDARs based on our measurements for RQ1 and RQ2, which is not only the first to perform such modelling for first- and new-gen LiDARs, but also the first to model for object removal attacks.


In the measurement study, we cover major types of LiDAR spoofing attacks against (1) 9 popular LiDAR models in total, covering both the classic first-gen ones (e.g., VLP-16) and the new-gen ones with new security-related features; and (2) 3 major types of object detectors trained on 5 different datasets. To the best of our knowledge, this is the first large-scale measurement study on this topic in terms of \textit{LiDAR numbers} (none of the prior works studied over 1 LiDAR model, while we study 9), \textit{LiDAR types} (all prior works concentrate on first-gen ones, and we are the first to study the new-gen ones), and also \textit{training datasets} (no prior works studied the same model design with over 1 dataset, while we study 5).

Through this study, we are able to identify a total of \textit{15 novel findings}, which include not only completely new ones due to the measurement angle novelty (e.g., measurements on new-gen LiDARs), but also many that directly challenge the latest understandings in this problem space. For example:


\begin{itemize}[leftmargin=0.2in]

\item We find that with more careful spoofer optics and electronics implementations, an attacker actually does not really need to exploit object detector-level vulnerabilities to achieve a near-front road object injection, which is a common assumption made in prior works~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security};

\item We find that VLP-16 is actually the \textit{only} LiDAR model for which the CPI attack capability assumption is feasible, which is another key design assumption made in latest prior works~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security};

\item We find that the new-gen LiDAR features previously expected to be capable of largely mitigating or even preventing spoofing (e.g., timing randomization~\cite{cao2019adversarial, cao2023you}, pulse fingerprinting~\cite{shin2017illusion}) may not be effective as expected 
(\S\ref{sec:sec_enchance_feats}, \S\ref{sec:od_injection_eval});

\item We find that the latest synchronized object removal attack can no longer be applied to the new-gen LiDARs, but there exist asynchronized object removal attacks that can overcome such a limitation and can lead to a similar level of practical attack capabilities (\S\ref{sec:removal_attack}).



\end{itemize}


In summary, our study has the following contributions:
\begin{itemize}[leftmargin=0.2in]
    \item We conduct the first large-scale measurement study on LiDAR spoofing attack capabilities on object detectors with 9 LiDARs, covering both first- and new-generation ones, and 3 major types of object detectors. We are also the first to investigate the impacts of new security-related features in more recent LiDARs from the security perspective. 
    \item To facilitate the measurements, we not only identify spoofer improvements that significantly improve the latest spoofing capability, but also identify  a new asynchronized object removal attack that overcomes the applicability limitation of the latest method to new-gen LiDARs while having a similar level of practical attack capability.
   
    \item To facilitate the object detector-level measurements, we perform novel mathematical modeling of the spoofing capabilities for both object injection and removal attacks based on our measurement results, which is the first to model for both first- and new-gen LiDARs and also to model for object removal attacks.
    \item Our study is able to uncover a total of 15 novel findings, including not only completely new ones due to the measurement angle novelty, but also many that can directly challenge the latest understandings in this problem space.
\end{itemize}


\textbf{Data/code release.} All data, code, and hardware designs (e.g., for the new spoofer) are released at \DemoWeb.



