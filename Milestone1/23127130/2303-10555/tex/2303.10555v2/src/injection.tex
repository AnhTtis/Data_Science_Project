\nsection{Object Injection Attack Measurements} \label{sec:injection_attack}

With the measurement setup above, in this paper we perform the first large-scale measurement study for both classes of state-of-the-art LiDAR spoofing attacks: object injection attack and object removal attack, which will be the focus of this and the next section respectively. For each attack class, we first perform the attack capability measurements at the LiDAR point cloud level, and then model such attack capabilities for the subsequent measurements at the object detector level. 



\nsubsection{LiDAR-Level Measurements (RQ1, RQ2)}
\label{sec:lidar_injection}

In this section, we measure the object injection attack capabilities at the LiDAR point cloud level, which is measured by the spoofing attack's capability in injecting spoofed points. We perform this measurement using an attack laser with sufficiently high intensity so that the attack-induced spoofed points can be easily differentiated from the benign ones. To answer RQ1, we first re-visit the existing state-of-the-art spoofing attacks for point injection on the VLP-16 LiDAR~\cite{VLP16}, which is predominantly used as the \textit{only} evaluation target in prior works~\cite{shin2017illusion, cao2019adversarial, jiachen2020towards, cao2023you, hallyburton2022security}. After that, we then conduct the measurement study on new-gen LiDARs to answer RQ2. 




\nsubsubsection{Re-Visiting Design Assumptions Made in Prior Works with VLP-16 (RQ1)} \label{sec:inj_vlp16}

Prior works have shown that the number of spoofed points in VLP-16 increases as the quality of the spoofer device improves, ranging from 60~\cite{cao2019adversarial} to $\sim$4k~\cite{cao2023you}. 
As shown in Table~\ref{tbl:distance}, with our spoofer improvements (\S\ref{sec:spoofer_design}), such attack capabilities are further improved significantly,
which can now inject $>$6,131 points indoors and $>$6,514 points outdoors. This is at least 50\% more than those in the latest prior work~\cite{cao2023you}, which capped at $\sim$4,000. We noticed a concurrent work that may have also made contributions in improving the spoofing capability~\cite{jin2022pla}. The full paper is not available at the time of our writing, but from the abstract it seems that (1) the spoofing capability is still capped at 4200 points, which is still at least 50\% fewer than ours; and (2) the study scale is much smaller than ours in terms of LiDAR number (only 2, versus 9 for us) and likely also LiDAR types and generation coverage.


Meanwhile, we also observe that the number of spoofed points and angles in the outdoor setup is generally larger than those in the indoor setup. We consider this reasonable since the legitimate laser reflections are fewer in the outdoor environment (e.g., no wall reflections), leaving more room for spoofing.  However, this actually contradicts those reported results in the latest prior work~\cite{cao2023you}: as shown in Table~\ref{tbl:distance}, the spoofed points outdoors are significantly fewer than those indoors (1.8k versus 4k) and they attribute this to the lighting condition differences (e.g., they also report that the number of spoofed points decreases from $\sim$2,500 at night to $\sim$1,600 at day.)
We consider that our results are achieved by our more careful optical setup as described in~\S\ref{sec:optical_setup} since the spoofing laser intensity is much stronger than the sunlight and should not be decayed in a short 10 m flight. 
We suspect that the optical setup of the previous work is not well calibrated and the laser beam diverges. 


\begin{observation}{RQ1}
With electronic and optical setups, the LiDAR spoofing attack can inject $>$6,000 points ranging $>$80$^{\circ}$, which is a significantly higher number of points and wider range than in previous studies.
Furthermore, previous observations that spoofing distance and lighting conditions can greatly affect the LiDAR spoofing capability~\cite{cao2023you} no longer hold if implemented using more careful optics.
\end{observation}



\nsubsubsection{CPI Attack Capability Measurements} \label{sec:cpi_capability}
As shown in Fig.~\ref{fig:arbitrary_point}, with our spoofing improvements we are able to demonstrate strong spoofed point pattern control capability for the first time. Considering that the CPI attack capability is a common design-level assumption made in prior works (\S\ref{sec:cpi}), we thus perform the first systematic quantification of it to allow more rigorous attack capability analysis on the object detector side.
Note that some prior works tried to include a modeling of such CPI attack capability in their object detector-side analysis~\cite{hallyburton2022security}, but their modeling is based on their intuitions (e.g., simply add vertical and horizontal noises~\cite{hallyburton2022security}) instead of the LiDAR sensing mechanisms and the spoofer designs. As shown later in~\S\ref{sec:od_injection_eval}, such erroneous spoofing accuracy modeling can cause significant differences in the object detector-side attack results. 


Based on our attack reproduction and spoofing inaccuracy cause investigations, we find that there are two types of errors in controlling the position control of each spoofed point $x_{ij}$ at $i$-th altitude and $j$-th azimuth (illustrated in Fig~\ref{fig:inter_inner}): (1) \textit{inner-frame error} $\delta^{\rm inner}_{ij}$: the inaccuracy in spoofing a point at a chosen 3D position within an individual frame; and (2) \textit{inter-frame error} $\delta^{\rm inter}$: the inaccuracy in maintaining the spoofed position of the same point in the chosen pattern across consecutive frames. Rooted in the spoofing design (Fig.~\ref{fig:spoofer1}), the inner-frame error is due to the inaccurate signal bursting of FG to the gate driver, while the inter-frame one is due to inaccurate timing of triggering the FG from TIA. With our experimental setup, we measure both and find that $\delta^{\rm inner}_{ij}$ and $\delta^{\rm inter}$ are $\sim$10 cm as in Fig~\ref{fig:inner_frame_error} and $\sim$35 cm respectively.





\begin{figure}[t!]
\centering
\vspace{-0.1in}
\includegraphics[width=\linewidth]{imgs/spoofing/inner_frame_noise.pdf}
\vspace{-0.3in}
\caption{Standard deviations of inner-frame error on VLP-16.}
\label{fig:inner_frame_error}
\end{figure}

\begin{observation}{RQ1}
The CPI attack capability, which is commonly assumed but never demonstrated in prior works~\cite{cao2019adversarial, jiachen2020towards, cao2023you, hallyburton2022security, zhongyuan2021object}, can be achievable in practice with a well-calibrated spoofer, while by design such pattern control capability is subject to inner- and inter-frame errors.
\end{observation}


\textbf{Assumption that object detector-level vulnerability exploitation is needed:} Combining these spoofing capability advances above (significantly improved spoofable points, angle, and CPI attack capability), this actually means that \textit{an attacker does not always need to exploit object detector-level vulnerabilities to achieve a near-front road object injection}, which is actually the major design assumption for all attack works so far on the object injection attack side~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security}.
Specifically, as clearly stated in prior works~\cite{cao2019adversarial, jiachen2020towards}, a valid point cloud for a front-near vehicle needs $\sim$2,000 points and 15$^{\circ}$ azimuth ($\theta$) coverage, but their spoofers can only achieve $<$200 points and $<$8$^{\circ}$, which is why object detector-level vulnerability exploitation (and thus those novel spoofing pattern optimization/identification) are needed. \newpart{These results indicate that the exploitation of the object detector-level vulnerability is not the necessary condition although it may help to design more sophisticated attacks.}



\begin{observation}{RQ1}
\newpart{
Now with the CPI attack capability demonstrated with sufficiently larger spoofable point number and angle, an attacker actually has sufficient capabilities to directly inject a near-front vehicle pattern. This finding has significant implications for the current line of research, since this  (1) may not need to exploit object detector-level vulnerabilities on the attack sides~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security}; and 
(2) may suggest that model-level defenses that try to leverage the inability of spoofers in directly injecting indistinguishable patterns as benign cases (e.g., \cite{jiachen2020towards}) can be ineffective.
}
\end{observation}

\begin{table}[t!]
\centering
\footnotesize
\caption{Evaluation results of the synchronized injection attack on VLP-16. 
$\mathcal{N}$: Number of injected points by spoofing. $\theta$: Azimuthal range of the point injection. $\mathcal{R}$: Point injection success rate within $\theta$.
The distance $d$ is between the spoofer and the LiDAR. Number in parenthesis: $\mathcal{N}$ from latest prior work~\cite{cao2023you}. ``-'': Data not available.
}
\label{tbl:distance}
\footnotesize
\setlength{\tabcolsep}{4.5pt}
\renewcommand{\arraystretch}{0.75}
\begin{tabular}{cccccccc}
\toprule
     & \multicolumn{3}{c}{Indoor} &  & \multicolumn{3}{c}{Outdoor (Daytime: 70 lux)} \\ \cline{2-4} \cline{6-8} 
$d$     & $\mathcal{N}$     &  $\mathcal{R}$     & $\theta$         &  & $\mathcal{N}$     &  $\mathcal{R}$     & $\theta$      \\ \cline{1-4} \cline{6-8} 
2 m  & 6,523 (-)  & 98.5\% & 82.7$^{\circ}$  &  & 7,705 (-)  &  94.9\%     & 100.5$^{\circ}$        \\
(2.5 m)  & ($<$4k)  &  &   &  & (-)  &      &        \\
4 m  & 6,386 (-)  & 96.9\% & 82.5$^{\circ}$ &  &  7,950 ({$<$1.8k})  &   96.9\%     & 101.5$^{\circ}$        \\
6 m  & 6,575 (-)  & 98.6\% & 83.4$^{\circ}$  &  & 7,357 ({$<$1.5k}) &   87.2\%    & 99.6$^{\circ}$        \\
8 m  & 6,213 (-)  & 93.8\% & 82.8$^{\circ}$  &  & 6,702 ({$<$1k}) &   97.7\%     & 83.4$^{\circ}$         \\
10 m & 6,131 (-) & 93.2\% & 82.1$^{\circ}$  &  & 6,514 ({$<$1k}) &    93.3\%     &  84.2$^{\circ}$     \\ \toprule
\end{tabular}
\vspace{-0in}
\end{table}


\nsubsubsection{Measurements on New-Gen LiDARs}  \label{sec:inj_other_lidars}

Table~\ref{tbl:inject_attack} shows the measurement results of the point injection capabilities on not only first-gen LiDARs such as VLP-16 but also new-gen ones. The first thing we find is that the latest spoofing attack for object injection, synchronized spoofing  (\S\ref{sec:attack_taxonomy}), can only be applied to the first-gen ones; for the new-gen ones, 
since they all have either timing randomization or pulse fingerprinting, synchronization (and thus CPI) becomes virtually impossible since timing randomization by design prevents the prediction of the future laser firing timing from the victim LiDAR, while pulse fingerprinting by design prevents the prediction of the future laser pulse pattern of each measurement. To still measure their vulnerabilities to spoofing attacks, we try to inject as many spoofed points as possible with a random attack with high-frequency pulses. 
The random attack is similar to the newly-identified HFR attack (\S\ref{sec:high_freq_attack}), but the frequency is tuned to achieve the largest number of injected points.

As shown, compared to the first-gen LiDARs, the security-related features in the new-gen LiDARs result in huge differences in the point injection capabilities: $>$19k injected points for Horizon, $\sim$3.2k for Helios, 100-350 on Realsense L515 and XT32, and only 28 on OS1-32. We will closely investigate such differences in the next section. Despite these variances, one observation is in common: VLP-16 is actually the \textit{only} LiDAR among all these 7 ones that can achieve the CPI attack capability --- it is not possible by design for the 6 new-gen ones due to timing randomization and pulse fingerprinting, while it is also not achievable to the other first-gen LiDAR (VLP-32c) due to simultaneous firing (\S\ref{sec:sec_enchance_feats}).





\begin{observation}{RQ1}
VLP-16 is actually the only LiDAR for which the CPI attack capability is feasible, which is the key design assumption made in all prior works on object injection attack side~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security}. This directly challenges the validity of all these existing designs against the more general and recent set of LiDARs.
\end{observation}



\nsubsubsection{Impacts from Security-Related Features}  \label{sec:sec_enchance_feats}
~

\begin{table}[t!]
\centering
\footnotesize
\caption{Measurements of the point injection capabilities on different LiDARs. For the first-gen LiDARs, the attack is synchronized spoofing (\S\ref{sec:attack_taxonomy}). For the new-gen ones, we inject as many points as possible with random firing (1 MHz). Symbols are the same as in Table~\ref{tbl:distance}. %
}
\label{tbl:inject_attack}
\setlength{\tabcolsep}{3.1pt}
\setlength{\aboverulesep}{0pt}
\setlength{\belowrulesep}{0pt}
\renewcommand{\arraystretch}{0.9}
\begin{tabular}{c|cc|cccc|c}
\toprule
       & \multicolumn{2}{c|}{\multirow{2}{*}{First-Gen}} & \multicolumn{5}{c}{New-Gen}  \\  \cline{4-8}
       &  & & \multicolumn{4}{c|}{w/ Timing Randomization}    & w/ Fingerprint  \\  \cline{2-8}
 &       VLP-16  & VLP-32c & OS1-32 & Helios    & Horizon  & L515    & XT32  \\  
 \hline  \hline$\mathcal{N}$     & 6,523    & 9,711    & 28     & 3,203   & 19,182    & 321   & 113    \\
$\mathcal{R}$     & 98.50\% & 82.90\% & 43.80\%   & 19.4\%& 79.90\%  & 0.1\%  & 2.10\%  \\
$\mathcal{\theta}$ & 82.7$^{\circ}$ & 73.2$^{\circ}$ & 0.72$^{\circ}$  & 34.2$^{\circ}$ & 103.4$^{\circ}$ & 81.7$^{\circ}$ & 70$^{\circ}$\\ \toprule
\end{tabular}
\raggedright
\vspace{0.05in}
\end{table}

\noindent\textbf{Simultaneous Laser Firing.} \label{sec:sim_fireing}
As listed in Table~\ref{tbl:target_lidars}, many LiDARs fire multiple laser pulses simultaneously. Velodyne LiDAR is likely adopting a modular approach that doubles units when increasing altitudes. Hence, the number of simultaneous laser firings is also doubled: VLP-16~\cite{VLP16} fires 1 laser during each measurement, and VLS-32~\cite{VLP32c} fires 2 lasers simultaneously. This design makes the CPI attack infeasible because we cannot selectively return the laser to each simultaneous laser due to the large diameter of the spoofing laser. For example, on VLP-32c we can always inject spoofed points pair by pair, and the injected pair will always have the same distance to LiDAR. Although simultaneous laser firing may help attackers since it can affect more points by a single attack laser pulse, the CPI becomes no longer feasible. 




\noindent\textbf{Timing Randomization.}
New-gen LiDARs typically have a feature that randomizes their laser shooting timing at each firing to mitigate interference from other LiDARs as listed in Table~\ref{tbl:target_lidars}. The timing randomization makes the CPI attack capability virtually impossible because the attacker can no longer synchronize with the laser firing pattern. However, interestingly, we find that the attacker may still be able to inject some points if the randomization is not strong enough. To quantify the impacts of the timing randomization, we measure the laser firing interval (not available from data sheets) with a PD and an oscilloscope. Table~\ref{tbl:randomization} illustrates the histogram, standard deviation, and maximum value of laser firing intervals of each LiDAR with timing randomization. 
We also categorize and fit the observed firing intervals into the uniform or Gaussian distribution based on the shape of its histogram.
We convert time difference to distance with the following formula: $\frac{\Delta t \times c}{2}$, where $\Delta t$ is the timing difference and $c$ is the speed of light. Fig.~\ref{fig:livox_spoofing} in Appendix shows the point clouds of Horizon~\cite{livox_horizon}, which can illustrate the impacts of timing randomization on spoofing capability. As shown, when under attack, the whole point cloud becomes highly randomized, and the object shapes (e.g., our lab room as shown in the benign case) completely disappeared. We further evaluate the significance of the errors on object detectors in~\S\ref{sec:impact_noise}. 
 




\begin{table}[t!]
\centering
\footnotesize
\setlength{\tabcolsep}{2pt}
\renewcommand{\arraystretch}{0.75}
\caption{Distribution of laser firing intervals for LiDAR with timing randomization. Std. $\sigma$: Standard deviation of the error caused by the timing randomization in meters. Max. $\Delta$: Maximum error caused by the timing randomization in meters. 
}
\label{tbl:randomization}
\begin{tabular}{lccccc}
\toprule
                        & OS1-32~\cite{OS1-32}        & Horizon~\cite{livox_horizon}       &  L515~\cite{L515} & Pixell~\cite{pixell}  &  Helios~\cite{Helios}    \\ \cline{2-6} 
                        & \includegraphics[width=0.5in]{imgs/spoofing/randomization/os1-random-hist.pdf}              
                        & \includegraphics[width=0.5in]{imgs/spoofing/randomization/horizon-random-hist.pdf}               
                        & \includegraphics[width=0.5in]{imgs/spoofing/randomization/L515-random-hist.pdf}               
                        & \includegraphics[width=0.5in]{imgs/spoofing/randomization/pixell-random-hist.pdf}
                        &
                        \includegraphics[width=0.5in]{imgs/spoofing/randomization/helios-random-hist.pdf}
                        \\ \hline
Dist. {[}$\mu$s{]} & $\mathcal{U}_{1.4, 1.8}$ & $\mathcal{U}_{4.0, 4.3}$ & $\mathcal{N}_{51, 0.025}$   & $\mathcal{U}_{4.5, 5.8}$ & $\mathcal{N}_{1.6, 0.005}$\\
Std. $\sigma$      & 33.3 m          & 26.0 m            & 7.5 m           & 110.4 m     &    1.5 m   \\
Max. $\Delta$      & 57.7 m          & 45.0 m            & 20.1 m           & 191.3 m     &   5.3 m      \\ \toprule
\end{tabular}
$\mathcal{U}_{{\rm min, max}}$ - Uniform distribution, $\mathcal{N}_{{\rm mean, std}}$ - Gaussian distribution
\vspace{0.1in}
\end{table}

\noindent\textbf{Pulse Fingerprinting.} We identify that Hesai XT32~\cite{XT32} can foil synchronization (and CPI attack capability) even without timing randomization due to its pulse fingerprinting. While we cannot be entirely sure due to the lack of official documentation, XT32 likely encodes its fingerprinting in the interval of the pair: As shown in Fig.~\ref{fig:hesai_fingerprint}, the XT32 pulse always forms a pair of pulses (two closely-connected spikes) corresponding to a single distance measurement.
However, we also find that the fingerprinting itself cannot perfectly defend against spoofing attacks because random spoofing can sometimes coincide with the fingerprinting interval, which can lead to up to 113 spoofed points as in Table~\ref{tbl:inject_attack}.
This could be because such pulse fingerprinting is originally developed for anti-interference purposes (e.g., to allow multiple LiDARs to operate at close range) instead of security and thus does not have enough randomness/entropy. Furthermore, it is not trivial to design more complex fingerprinting while ensuring eye safety as we will discuss in~\S\ref{sec:discussion}.
This means that if in each attack laser-firing event the attacker also fires a pair of pulses with the interval that can most likely coincide the fingerprinting interval (e.g., the one we found that can spoof 113 points), there can still be a random subset (e.g., 113) of the points in the attacker-chosen point cloud pattern that can be spoofed with the CPI attack capability. 
Thus, later in~\S\ref{sec:od_injection}, we model this effect on the spoofing capability as a random downsampling from a chosen pattern.


\begin{observation}{RQ2}
The current pulse fingerprinting is not complex enough to perfectly prevent spoofing attacks, likely because it is currently designed only for anti-interference purposes instead of security. However, it is not trivial to design a complex fingerprinting while ensuring eye safety.
\end{observation}


\begin{figure}[t!]
    \begin{minipage}{.63\linewidth}
\centering
\includegraphics[width=\linewidth]{imgs/spoofing/inter_inner_errors.pdf}
\vspace{-0.1in}
\caption{Illustration of inner- and inter-frame errors. Inner-frame error causes spoofing inaccuracy along with the ray direction within a frame. Inter-frame error causes the entire pattern to vibrate across consecutive frames.
}
\label{fig:inter_inner}
    \end{minipage}
    \hspace{0.01in}
    \begin{minipage}{.33\linewidth}
        \vspace{-0.1in}
        \centering
        \includegraphics[width=\linewidth]{imgs/spoofing/xt32_pulse.pdf}
        \caption{Examples of the receiving pulse shape of XT32~\cite{XT32}.
        }
        \label{fig:hesai_fingerprint}
   \end{minipage}
\end{figure}



\nsubsubsection{Case Study on Specific LiDARs}
\label{sec:specific-lidars}
Using our measurement setup, we also found 5 uniquely-interesting characteristics of specific LiDARs: the use of rare wavelength in OS1-32, relay attack on Leddar Pixell, zero-distance sensing of XT32, extra-wide vertical FOV of Helios 5515, and simultaneous laser firing on OS1-32 and VLS-128, which led to 2 new findings that are different from existing understandings in the community. Details are in Appendix~\ref{appendix:specific-lidars}.



\nsubsection{Object Detector-Level Measurements (RQ3)} 
\label{sec:od_injection}

\nsubsubsection{Modeling of the Spoofing Attack Capability in Point Injection} \label{sec:od_injection_modeling}
Similar to prior works in this problem space~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security}, to enable large-scale measurements of the attack capabilities on the object detector side, we need to mathematically model the point injection capabilities. Prior efforts in such modeling did not systematically consider (1) the modeling of the CPI attack capability (\S\ref{sec:cpi}), and (2) common new-gen LiDAR features that can fundamentally affect the object injection attack capabilities such as timing randomization and pulse fingerprinting. Leveraging this measurement study, we can thus develop a new modeling that addresses both fronts: 

\vspace{-0.2in}
\footnotesize
\begin{align}
    \mathcal{P}_I (x_{ij}) = 
     x_{ij} + (\delta_{ij}^{\rm rand} + \delta^{\rm inner}_{ij} + \delta^{\rm inter}) \cdot g(x_{ij}), \ x_{ij} \in \mathcal{C}_n \subset \mathcal{C} 
     \label{eq:attack_cap}
\end{align}
\normalsize
, where $\mathcal{C}$ is a point cloud (i.e., chosen pattern) that the attacker originally wants to inject (e.g., the point cloud of a vehicle); 
$\mathcal{C}_n$ is a point cloud randomly downsampled to $n$ points from $\mathcal{C}$ to model the impact from pulse fingerprinting (\S\ref{sec:sec_enchance_feats});
$x_{ij} \in \mathbb{R}^{3}$ is a point injected by the attack at $i$-th altitude and $j$-th azimuth; $g: \mathbb{R}^{3} \rightarrow \mathbb{R}^{3}$ is a function to obtain a movable unit direction of point $x$. Due to the physics of LiDAR, each point can only move along with the laser direction. As the LiDAR typically locates at the origin of the point cloud, $g(x_{ij})$ can be written as $\frac{x}{||x||_{2}}$ in this case.
To model the spoofing inaccuracy and the effect of the timing randomization, we add 3 types of errors: $\delta_{ij}^{\rm rand}$, $\delta^{\rm inner}_{ij}$, and $\delta^{\rm inter}$. Randomization error $\delta_{ij}^{\rm rand}$ is the error introduced by the timing randomization. It follows a certain distribution based on the target LiDAR as measured in Table~\ref{tbl:randomization}. 
We use $\delta_{ij}^{\rm rand} \sim \mathcal{N}(0, \sigma$) for the Gaussian distribution and $\delta_{ij}^{\rm rand} \sim \mathcal{U}(-\frac{\max - \min}{2}, \frac{\max - \min}{2})$ for the uniform distribution. $\delta_{ij}^{\rm inner}$ and $\delta^{\rm inter}$ are the inner-frame and inter-frame errors, respectively. Based on the measurements in~\S\ref{sec:cpi_capability}, we sample $\delta_{ij}^{\rm inner}$ from $\mathcal{N}(0, 10 \ {\rm cm})$ and sample $\delta^{\rm inter}$ from $\mathcal{N}(0, 35 \ {\rm cm})$. Note that $\delta^{\rm inter} \in \mathbb{R}$ does not depend on each point $x_{ij}$, i.e., one scalar value is sampled per case and applied to all points in the case. To the best of our knowledge, this is the first modeling
of the point injection capability that can cover both first- and new-gen LiDAR features.

\newpart{Note that this modeling does not cover the impacts from the simultaneous laser firing feature (\S\ref{sec:sim_fireing}). This is because although such a feature can make the CPI attack capability infeasible, (1) it cannot prevent the point injection itself; (2) details of the simultaneous firing pattern are not well documented; and (3) the more recent LiDARs (e.g., the ones after 2019 in Table~\ref{tbl:target_lidars}) do not have such a feature. We thus leave its modeling to future work.}











\nsubsubsection{Experimental Setups} \label{sec:model_level_scenario}
We perform the experiments based on a scenario in the KITTI dataset.
Fig.~\ref{fig:synth_scenario} in Appendix %
depicts the generated scenario: we place a 3D vehicle object in front of the victim and move the corresponding points to the object's surface, following the same methodology used in~\cite{jiachen2020towards, cao2021invisible}. 
We generate 15 scenarios varying the distance between the victim to the vehicle object from 0 m to 14 m (0 m means the victim's nose touches the vehicle object's tail). 
Fig.~\ref{fig:n_points} in Appendix shows the number of points on the injected vehicle object.
In addition to the original point clouds, we evaluate point clouds downsampled from the original one to 10, 50, 100, and 200 points (i.e., $n = 10, 50, 100,$ and $200$ in Eq.~\ref{eq:attack_cap}) as a modeling of the fingerprinting effect  (\S\ref{sec:sec_enchance_feats}).
We judge the object injection as successful if there exists a detected object overlapping with the ground truth area of the injected object, i.e., the IoU between the ground truth and detected object is more than zero. 



\vspace{0.05in}
\nsubsubsection{Results} \label{sec:od_injection_eval}  \label{sec:impact_model} \label{sec:impact_data} \label{sec:impact_noise}
~

\textbf{Impact of Error Modeling on Spoofing Accuracy:}
We measure the impacts of 3 types of different modeling: without errors, our modeling with inner- and inter-frame errors (\S\ref{sec:cpi_capability}), and the error modeling used in the Frustum attack~\cite{hallyburton2022security}, which is the latest modeling effort in prior works and simply adds Gaussian errors along with the vehicle's Cartesian coordinates (forward, left, and up) following ($\mathcal{N}(1, 0.1)$, $\mathcal{N}(0, 0.5)$, $\mathcal{N}(1, 0.2)$) in meters, respectively.
Fig.~\ref{fig:obj_impact_errors} shows the attack success rates against our targeted models with different architectures and different training datasets (\S\ref{sec:target_lidar_od}).
As shown, the different error modeling can generally cause significant differences in the attack success rates, e.g., the results without errors and with the naive modeling in~\cite{hallyburton2022security} can differ 96\% and 70\% respectively on average to those using our modeling. Specifically, the latest modeling effort in~\cite{hallyburton2022security} significantly over-estimates the errors along their forward and up coordinates, which causes the model-level success rates to be generally lower than those with our more systematic modeling based on actual experiments (\S\ref{sec:cpi_capability}).




\begin{observation}{RQ1} 
Error modeling on the spoofing accuracy can significantly affect the object detector-level attack results. The latest prior efforts~\cite{hallyburton2022security} largely overestimate the errors as compared to our systematically modeled and quantified ones via experiments. 
\end{observation}
\vspace{-0.1in}

\begin{figure}[t!]
\centering
\includegraphics[width=\linewidth]{imgs/obj_detector/obj_comp_noises.pdf}
\vspace{-0.2in}
\caption{
Object injection attack success rates under 3 different types of noises on (a) multiple models trained on the KITTI dataset and (b) PointPillars trained on different datasets.
}
\label{fig:obj_impact_errors}
\end{figure}

\textbf{Impact of Pulse Fingerprinting:}
Fig.~\ref{fig:obj_fingerprinting} shows the attack success rates under different down-sampling levels $n$ as a modelling of different pulse fingerprinting levels (\S\ref{sec:sec_enchance_feats}). 
To perform control experiments of the fingerprinting impact factor, we do not apply inter- and inner-frame errors in this experiment. 
Generally, fingerprinting with higher complexity (i.e., lower $n$) shows higher defense capability. However, when $n=100$, which can represent the fingerprinting complexity level today (XT32 as measured in~\S\ref{sec:sec_enchance_feats}), the defense effectiveness is actually still very minimal (reduce the attack success rate only by 3\% on average). The defense effectiveness only becomes significant when $n$ reaches as low as 10, while such higher effectiveness is still model architecture and training dataset dependent.

\begin{observation}{RQ3}
If with enough complexity, pulse fingerprinting can indeed show high defense capability to object injection attacks (although can be object detector model architecture and training dataset dependent). Unfortunately, the complexity of pulse fingerprinting today may not be enough to achieve such high defense capability. 
\label{finding:pulsefp}
\end{observation}
\vspace{-0.1in}


\begin{figure}[t!]
\centering
\includegraphics[width=\linewidth]{imgs/obj_detector/obj_fingerprinting.pdf}
\vspace{-0.2in}
\caption{
Object injection attack success rates under different down-sampling levels $n$ on (a) multiple models trained on the KITTI dataset and (b) PointPillars trained on different datasets.
}
\label{fig:obj_fingerprinting}
\end{figure}

\textbf{Impact of Timing Randomization:}
Table~\ref{tbl:inj_rand_arch} and~\ref{tbl:inj_rand_data} show the attack success rates under different timing randomization levels based on our measurements in~\S\ref{sec:sec_enchance_feats}. As shown, timing randomization can in general significantly reduce the attack success rates, e.g., the average attack success rates with randomization are dramatically reduced to at most 34\% for most models, while those without randomization are at least 88\%. We also measured the attack success rates with both timing randomization and pulse fingerprinting, with the fingerprinting level set at the observed level today ($n=100$, based on XT32 measurements in~\S\ref{sec:sec_enchance_feats}). However, consistent with Finding~\ref{finding:pulsefp}, we are not able to observe significant changes in the attack success rate reduction.

\begin{observation}{RQ3}
Timing randomization, even with those with low randomization entropy that is realized for anti-interference purposes instead of security today, can have significant defense capabilities against object injection attacks. Today's fingerprinting complexity level again may not be able to significantly help boost the defense capabilities when used together with timing randomization.
\end{observation}


Meanwhile, we further notice that the defense effectiveness with timing randomization can differ significantly when applied to models trained on different datasets. For example, as shown in Table~\ref{tbl:inj_rand_data}, the attack success rates are reduced by only 10\% and even 0\% on average across all randomization levels for the models trained on Lyft and nuScenes respectively, while the success rates can be reduced by as high as 84\% and 88.6\% for the same model design trained on Waymo dataset and the private dataset from Apollo. In particular, the models trained on Lyft and nuScenes are particularly vulnerable to object injection attacks since as shown in Fig.~\ref{fig:obj_fingerprinting}, these models can detect the vehicle even when the vehicle point cloud is randomly downsampled to as few as only 10 points. This suggests that the training dataset choice can play a significant role in determining the model vulnerability to spoofing attacks. Later in~\S\ref{sec:od_removal}, we will continue investigating this aspect together with the object removal attack measurement results.





\begin{table}[t!]
\centering
\footnotesize
\setlength{\tabcolsep}{1.3pt}
\setlength{\aboverulesep}{0pt}
\setlength{\belowrulesep}{0pt}
\renewcommand{\arraystretch}{0.75}
\caption{Object injection attack success rates under different randomization levels based on our measurements in~\S\ref{sec:sec_enchance_feats} on \textit{different model architectures}. $\emptyset$: No randomization. Avg.: The average results across all these randomization levels.
}
\label{tbl:inj_rand_arch}
\begin{tabular}{ccccccc}
\toprule
LiDAR   & Rand. model {[}m{]}         & PointPillars & SECOND & PartA$^{2}$ & 3DSSD & PV-RCNN \\\hline\hline
VLP-16  & $\emptyset$                 & \underline{100\%}        & \underline{100\%}  & 80\%   & 93\%  & 97\%    \\\hline\hline 
Helios  & $\mathcal{N}(0, 1.5)$       & 2\%          & 54\%   & 41\%   & 7\%   & 24\%    \\
L515    & $\mathcal{N}(0, 7.5)$       & \textbf{0\%}          & 24\%   & 14\%   & 7\%   & \textbf{0\%}     \\
Horizon & $\mathcal{U}(-45, 45)$      & 39\%         & 35\%   & 21\%   & 30\%  & 17\%    \\
OS1-32  & $\mathcal{U}(-58, 58)$ & 47\%         & 38\%   & 21\%   & 28\%  & 23\%    \\
Pixell  & $\mathcal{U}(-191, 191)$   & 60\%         & 21\%   & 20\%   & 8\%   & 43\%    \\ \hline
        & Avg.                         &   30\%         & 34\%   & 23\%   & 16\%  & 21\%  \\\hline\hline
  \multicolumn{3}{l}{With fingerprinting effect $n=100$:}        &     &     &    &     \\
                    & Avg.     & 38\%         & 20\%   & 16\%   & 18\%  & 41\%   \\\toprule
\end{tabular}
\end{table}


\begin{table}[t!]
\centering
\footnotesize
\setlength{\tabcolsep}{3.5pt}
\setlength{\aboverulesep}{0pt}
\setlength{\belowrulesep}{0pt}
\renewcommand{\arraystretch}{0.75}
\caption{Object injection attack success rates under different randomization levels based on our measurements in~\S\ref{sec:sec_enchance_feats} on \textit{models trained on different datasets}. $\emptyset$: No randomization.  Avg.: The average results across all these randomization levels.
}
\label{tbl:inj_rand_data}
\begin{tabular}{ccccccc}
\toprule
LiDAR   & Rand. model {[}m{]}         & KITTI & Lyft  & nuScenes & Waymo & Apollo \\ \hline\hline
VLP-16  & $\emptyset$                 & \underline{100\%} & \underline{100\%} & \underline{100\%}    & \underline{100\%} & 88\%   \\\hline\hline 
Helios  & $\mathcal{N}(0, 1.5)$       & 2\%   & \underline{100\%} & \underline{100\%}    & 26\%  & 48\%   \\
L515    & $\mathcal{N}(0, 7.5)$       & \textbf{0\%}   & 60\%  & \underline{100\%}    & \textbf{0\%}   & \textbf{0\%}    \\
Horizon & $\mathcal{U}(-45, 45)$      & 39\%  & 96\%  & \underline{100\%}    & 7\%   & \textbf{0\%}    \\
OS1-32  & $\mathcal{U}(- 58, 58)$ & 47\%  & 99\%  & \underline{100\%}    & 12\%  & \textbf{0\%}    \\
Pixell  & $\mathcal{U}(- 191, 191)$   & 60\%  & 96\%  & \underline{100\%}    & 36\%  & 1\%    \\ \hline
        & Avg.                         & 30\%  & 90\%  & \underline{100\%}    & 16\%  & 10\%   \\ \hline\hline
  \multicolumn{3}{l}{With fingerprinting effect $n=100$:}        &     &     &    &     \\
        & Avg.                         & 38\%  & 85\%  & 92\%    & 33\%  & 5\%   \\ \toprule
\end{tabular}
\end{table}



