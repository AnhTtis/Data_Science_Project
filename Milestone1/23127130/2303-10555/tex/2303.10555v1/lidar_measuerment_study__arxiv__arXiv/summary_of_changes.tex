\documentclass[conference,compsoc]{IEEEtran}

\IEEEoverridecommandlockouts

\pagestyle{plain}

\pagenumbering{arabic}


\let\proof\relax
\let\endproof\relax
\let\amalg\relax


\usepackage{epsfig,amsmath,amsfonts,multirow,graphicx,makecell,caption,soul,csquotes,color,wrapfig,subcaption,mathtools,bm,spverbatim,booktabs,xcolor,color,amsthm,tcolorbox,wrapfig,enumitem}
\usepackage[e]{esvect}
\usepackage{graphics}
\usepackage{marvosym,listings,etoolbox}
\usepackage{adjustbox}
\usepackage[space]{cite}
\usepackage{subcaption}
\DeclareCaptionSubType * [alph]{table}
\captionsetup[subtable]{labelformat=simple, labelsep=space}
\usepackage{multicol}
\usepackage{lipsum}

\let\Cross\relax
\usepackage{bbding}

\usepackage{array}
\usepackage{longtable}
\usepackage{colortab}
\usepackage{colortbl}
\usepackage{arydshln}


\renewcommand\thesubtable{(\alph{subtable})}

\captionsetup[sub]{labelformat=simple}
\makeatletter
\renewcommand\p@subfigure{\thefigure\,}
\renewcommand\thesubfigure{(\alph{subfigure})}
\makeatother

\usepackage{fancyhdr}
\renewcommand{\headrulewidth}{0pt}
\fancypagestyle{empty}{\fancyfoot[C]{\vspace*{-1.8\baselineskip}\thepage}}
\fancypagestyle{plain}{\fancyfoot[C]{\vspace*{-1.8\baselineskip}\thepage}}


\newcommand{\alfred}[1]{\textcolor{red}{[Alfred: #1]}}

\usepackage[first=0,last=9]{lcg}
\usepackage{colortbl}
\definecolor{Gray}{gray}{0.8}

\usepackage{url}
\def\UrlBreaks{\do\/\do-}
\renewcommand{\UrlBreaks}{\do\/\do-\do:\do\a\do\b\do\c\do\d\do\e\do\f\do\g\do\h\do\i\do\j\do\k\do\l\do\m\do\n\do\o\do\p\do\q\do\r\do\s\do\t\do\u\do\v\do\w\do\x\do\y\do\z\do\A\do\B\do\C\do\D\do\E\do\F\do\G\do\H\do\I\do\J\do\K\do\L\do\M\do\N\do\O\do\P\do\Q\do\R\do\S\do\T\do\U\do\V\do\W\do\X\do\Y\do\Z}
\usepackage{hyperref}
\usepackage{xurl}


\setlength\extrarowheight{2pt}


\captionsetup[table]{format=plain,labelformat=simple,labelsep=period}
\def\tablename{Table}
\def\figurename{Figure}





\makeatletter
\newif\if@restonecol
\makeatother
\let\algorithm\relax
\let\endalgorithm\relax
\usepackage[boxed, ruled, vlined, linesnumbered]{algorithm2e}
\SetKwRepeat{Do}{do}{while}





\setlength{\textfloatsep}{0.25\baselineskip}
\setlength{\floatsep}{0.25\floatsep}
\setlength{\dblfloatsep}{0.25\dblfloatsep}
\setlength{\dbltextfloatsep}{0.25\dbltextfloatsep}
\setlength{\intextsep}{0.25\intextsep}


\setlength{\belowcaptionskip}{3pt}
\setlength{\abovecaptionskip}{3pt}


\newenvironment{changemargin}[2]{\begin{list}{}{
	\setlength{\topsep}{0pt}\setlength{\leftmargin}{0pt}
	\setlength{\rightmargin}{0pt}
	\setlength{\listparindent}{\parindent}
	\setlength{\itemindent}{\parindent}
	\setlength{\parsep}{0pt plus 1pt}
	\addtolength{\leftmargin}{#1}\addtolength{\rightmargin}{#2}
	}\item}
	{\end{list}}

\newenvironment{myitemize}{
	\begin{changemargin}{-3pt}{-0cm}
	\vspace{-10pt}
	\hspace{-5pt}
	\begin{itemize}
	\setlength{\itemsep}{3pt}}
	{\end{itemize}
	\vspace{2pt}
	\end{changemargin}}

\newenvironment{mydescription}{
	\begin{changemargin}{-8pt}{-0cm}
	\vspace{-13pt}
	\hspace{5pt}
	\begin{description}
	\setlength{\itemsep}{-1pt}}
	{\end{description}
	\end{changemargin}}

\newenvironment{myenumerate}{
	\begin{changemargin}{-8pt}{-0cm}
	\vspace{-13pt}
	\hspace{5pt}
	\begin{enumerate}
	\setlength{\itemsep}{1pt}}
	{\end{enumerate}
	\end{changemargin}}

\newcommand{\mypara}[1]{\vspace{-6pt}\paragraph*{#1}}





\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{prop}{Proposition}






\renewcommand{\sectionautorefname}{\S}
\newcommand{\msec}[1]{\S\ref{#1}}
\newcommand{\meq}[1]{Eq.\,(\ref{#1})}
\newcommand{\mcite}[1]{~\cite{#1}}
\newcommand{\mref}[1]{\,\ref{#1}}

\newcommand\matt{{\scaleobj{0.8}{\top}}}
\newcommand\mati{{\scaleobj{0.8}{-1}}}
\newcommand\szero{{\scaleobj{0.8}{0}}}




\usepackage{xr}

\makeatletter
\newcommand*{\addFileDependency}[1]{%
  \typeout{(#1)}
  \@addtofilelist{#1}
  \IfFileExists{#1}{}{\typeout{No file #1.}}
}
\makeatother

\newcommand*{\myexternaldocument}[1]{%
    \externaldocument{#1}%
    \addFileDependency{#1.tex}%
    \addFileDependency{#1.aux}%
}


\DeclareRobustCommand{\stirling}{\genfrac\{\}{0pt}{}}
\newcommand{\com}[2]{C_{#1}^{#2}}


\usepackage{scalerel}[2016/12/29]

\usepackage{diagbox}

\usepackage{array}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}


\makeatletter
\providecommand{\leadsfrom}{%
  \mathrel{\mathpalette\reflect@squig\relax}%
}
\newcommand{\reflect@squig}[2]{%
  \reflectbox{$\m@th#1\leadsto$}%
}
\makeatother

\makeatletter                 
\g@addto@macro\maketitle{\thispagestyle{plain}}
\makeatother

\usepackage{footnote}
\makesavenoteenv{tabular}
\usepackage{tabularx}

\newcommand{\bx}{{x_\circ}}
\newcommand{\by}{{c_\szero}}
\newcommand{\bbm}{{m_\circ}}

\newcommand{\ax}{{x_*}}
\newcommand{\ay}{c_t}
\newcommand{\tm}{m_t}
\newcommand{\am}{{m_*}}

\newcommand{\perc}{\mathrm{perceptual}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\DeclareMathAlphabet\mathbfcal{OMS}{cmsy}{b}{n}

\newcommand{\etal}{\textit{et al.}}
\newcommand{\system}{{MSF-ADV}\xspace}
\newcommand{\DemoWeb}{\textbf{\url{https://sites.google.com/view/cav-sec/msf-adv}}}






\usepackage{mdframed}
\mdfdefinestyle{rebuttalstyle}{innerleftmargin=3pt, innerrightmargin=3pt, innertopmargin=3pt, innerbottommargin=3pt}

\newcounter{response}%
\newenvironment{response}{\refstepcounter{response}
\vspace{-1mm}
\begin{mdframed}[style=rebuttalstyle]
\noindent \textbf{Response~\theresponse:}\normalfont
}
{
\end{mdframed}
\vspace{-1mm}
}

\newcounter{revision}%
\newenvironment{revision}{\refstepcounter{revision}
\vspace{-1mm}
\begin{mdframed}[style=rebuttalstyle]
\noindent \textbf{Revision~\therevision:}\normalfont
}
{
\end{mdframed}
\vspace{-1mm}
}

\newcounter{link}%
\newenvironment{link}{
\vspace{-1mm}
\begin{mdframed}[style=rebuttalstyle]
\noindent \normalfont
}
{
\end{mdframed}
\vspace{-2mm}
}


\newcounter{comments}[section]
\newenvironment{comments}{\refstepcounter{comments}
\vspace{-1mm}
\begin{mdframed}[style=rebuttalstyle]
\noindent 
}
{
\end{mdframed}
\vspace{-1mm}
}

\newcounter{observation} %
\newenvironment{observation}{\refstepcounter{observation}
\vspace{-1mm}
\begin{mdframed}[style=rebuttalstyle]
\noindent \textbf{Observation~\theobservation:} \itshape
}
{
\end{mdframed}
\vspace{-0.5mm}
}

\definecolor{gray}{rgb}{0.7,0.7,0.7}

\newcommand{\cut}[1]{}
\newcommand{\takami}[1]{\textcolor{purple}{[Takami: #1]}}
\newcommand{\newpart}[1]{{\color{blue} #1}}

\newcommand{\deleted}[1]{}
\newcommand{\ken}[1]{\textcolor{magenta}{[Ken: #1]}}
\newcommand{\ryo}[1]{\textcolor{magenta}{[Ryo: #1]}}
\newcommand{\circled}[1]{\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {{\small #1}}}}}
\makeatletter
\newcommand\notsotiny{\@setfontsize\notsotiny{7}{8}}
\makeatother

\newcommand\appendixxx{\par
  \setcounter{section}{0}%
  \setcounter{subsection}{0}%
  }



\begin{document}

\title{
{\Large \bf Summary of Changes} \\

\textit{Revisiting LiDAR Spoofing Attack Capabilities against Object Detection: \\Improvements, Measurement, and New Attack
}
}

\author{Paper \#: 139 (\#70 in the 2nd cycle)}

\maketitle

The first version of the paper was submitted to the previous cycle (Cycle 2) of IEEE S\&P and received a Major Revision decision. We are very grateful for the constructive comments and thoughtful suggestions for the requested changes. As shown in the summary of changes below and also in the revised version, these benefited us a lot in improving this work from both technical and writing aspects. 




\section{Responses to List of Revision Requirements}
\label{sec:required-revisions}

In this section, we provide point-by-point responses and revisions to the main major revision criteria.

{\itshape

1.	The main contribution of this paper lies in the evaluation of popular LiDARs, but the evaluation itself is an extension to the prior art in LiDAR spoofing attack. Please clarify the novelty of this paper. 
}

\begin{response}\label{response:criteria1}


As we explained in the author's response, this paper has 2 categories of novelty and research contributions over prior works: methodology-level contributions and finding-level contributions.

\textbf{Methodology-Level Contributions}: To systematically enable the first large-scale measurement study on LiDAR spoofing attack capabilities against object detection, our work has 3 methodology-level contributions:

(1) We identify and overcome multiple spoofer design challenges, especially the optical and electronics parts, which enables us to be the first to demonstrate and quantify the CPI attack capability, which is commonly assumed but never clearly demonstrated in prior works~\cite{cao2019adversarial, jiachen2020towards, cao2023you, hallyburton2022security, zhongyuan2021object}.


(2) We identify a new asynchronized attack design called \textit{High-Frequency Removal (HFR)} attack, which is much more powerful and practical than prior ones (e.g., can remove points in a 10$\times$10 m$^2$ area, while the latest prior one can only remove points in a 41$\times$42 cm$^2$ area~\cite{shin2017illusion}). To measure the vulnerability status of next-generation LiDARs, we need a powerful and practical asynchronized spoofing attack since synchronized one is directly foiled by common security-related features in next-generation LiDARs. However, since all existing works only consider first-gen LiDARs, their designs predominately focus on synchronized attacks~\cite{shin2017illusion, cao2019adversarial, jiachen2020towards, hallyburton2022security, cao2023you}, leaving the asynchronized attack design space under-explored. 

(3) To overcome the challenge in performing large-scale evaluation of LiDAR spoofing attack capabilities against different object detectors, we perform novel mathematical modeling of the spoofing attack capabilities on different types of LiDARs based on our measurements.

\textbf{Finding-Level Contributions}:
With the novel methods above, we identify \textit{12 novel findings in total}, which include not only completely new ones due to the measurement angle novelty (e.g., the measurements on next-gen LiDARs), but also many that directly challenge latest knowledge/understandings in this problem space.

\end{response}
 
\begin{revision}\label{revision:criteria1}
We significantly restructured our introduction to improve the clarity of our main novel research angle (i.e., the measurement study angle) and different categories of novel research contributions, and also changed all the following sections accordingly to ensure such level of clarity throughout the paper. Specifically:

\begin{itemize}
    \item In the introduction we emphasized that the main novel research angle is being the ``First Large-Scale Measurement Study'' of LiDAR spoofing attack capabilities against object detection, and accordingly, explicitly listed the \textbf{research questions (RQs)} for the measurement effort as the driver of the whole paper. After that, we explicitly highlighted different novel aspects of the measurement effort itself, e.g., in terms of the \textbf{measurement scale} (none of the prior works studied over 1 LiDAR model, while we study 9), the \textbf{LiDAR types} (all prior works concentrate on first-gen ones, and we are the first to study the next-gen ones), and the \textbf{training datasets} (no prior works studied the same model design with over 1 dataset, while we study 5).

    \item In the introduction we now describe our methodology-level contributions and finding-level contributions \textbf{separately} to make the different types of novel contributions clear. 

    \item We consistently apply such changes to the rest of the paper. For example, in Section 3 we emphasized that the attack experiment setup and methodology improvements are for the measurement studies in later sections. Further, for each Observation box, we labeled them with ``(RQ1)'', ``(RQ2)'', or ``(RQ3)'' to make it clear which research question it answers.
    
\end{itemize}

\end{revision}

{\itshape
2.	Specify technique merits and the research challenges of the paper.
}
\begin{response}\label{response:criteria2}
The technique merits and research challenges of this paper are mainly from the various attack methodology-level contributions we made in order to systematically answer the 3 RQs. For example, for RQ1, to properly explore the potential to achieve the CPI attack capability, we identify and overcome multiple spoofer design challenges, especially the optical and electronics parts (\S3.1), which enables us to be the first to demonstrate and quantify the CPI attack capability (detailed later in Response~\ref{response:criteria3}), which is commonly assumed but never clearly demonstrated in prior works~\cite{cao2019adversarial, jiachen2020towards, cao2023you, hallyburton2022security, zhongyuan2021object} and shown in Fig.~1.

For RQ2, to measure the vulnerability status of next-gen LiDARs, we need powerful and practical \textit{asynchronized} (\S2.3) spoofing attacks since synchronized ones are directly foiled by their common security-related features (\S4.2.2). However, since all existing works only consider first-gen LiDARs, their designs predominately focus on synchronized attacks~\cite{shin2017illusion, cao2019adversarial, jiachen2020towards, hallyburton2022security, cao2023you}, leaving the asynchronized attack design space under-explored. To address this, we identify a new asynchronized attack design called \textit{High-Frequency Removal (HFR)} attack, which is much more powerful and practical than prior ones (e.g., can remove points in a 10$\times$10 m$^2$ area, while the latest prior one can only remove points in a 41$\times$42 cm$^2$ area~\cite{shin2017illusion}). For RQ3, to overcome the challenge in performing large-scale evaluation of LiDAR spoofing attack capabilities against different object detectors, we perform novel mathematical modeling of the spoofing attack capabilities on different types of LiDARs based on our measurements for RQ1 and RQ2.
\end{response}
\begin{revision}\label{revision:criteria2}
To make this clear, we explicitly added a dedicated description of the technique merits and research challenges of our work described above in the introduction (\S1), under bullet ``Methodology-Level Contributions''. 
\end{revision}

{\itshape
3.	Clarify chosen pattern injection attack to introduce the attack goal and how the attacker spoofs a LiDAR. 
}

\begin{response}\label{response:criteria3}
The chosen pattern injection (CPI) is not a specific type of LiDAR spoofing attack, but a type of attack capability for a given LiDAR spoofing attack. Specifically, this attack capability means that at the actual attack time the attacker is able to effectively inject a specific spoofed point cloud pattern carefully chosen by the attacker beforehand, e.g., via a certain kind of off-line optimization/identification processes~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security}. So far, all prior works on the synchronized injection attack side explicitly or implicitly assume this in their attack designs~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security}.

Such an attack capability is theoretically achievable since the synchronized (more detailed explanation on such ``synchronization'' is in Response~\ref{response:criteria7}) LiDAR spoofing methodology should by design be capable of precisely controlling the position of each injected spoofed point. However, so far no prior works have clearly demonstrated it experimentally as shown in Fig.~1, not to mention to provide a systematic quantification of the pattern control precision, which is necessary for achieving valid downstream task security analysis (e.g., for object detectors). This inevitably raises the doubt that whether such an attack capability is indeed feasible or not in practice; if not, the basic attack design assumption made by all these prior works actually becomes invalid, which can directly challenge the validity and meaningfulness of their current research findings. To fill this critical research gap, in this work we thus re-visit the validity of this assumption with multiple spoofer design improvements (detailed in \S3.1).
\end{response}
\begin{revision}\label{revision:criteria3}
We created a dedicated section (\S2.3.2) to clearly define the CPI attack capability, which is separated from \S2.3.1 on the taxonomy of different LiDAR spoofing attack types to make it clear that CPI is not a specific type of LiDAR spoofing attack, but a type of attack capability. In this section, we also explain why we are highly motivated to re-visit its feasibility as described above.
\end{revision}

{\itshape
4.	In the background section, provide detailed information about how these attacks (asynchronized injection and removal attack, the saturating attack, synchronized injection attack, and synchronized Removal attack) are launched and why they can spoof a LiDAR
}

\begin{revision}\label{revision:criteria4}
We follow the suggestion to significantly improve the background section with:

\begin{itemize}
    \item Illustration figures for \textbf{each of the 4 attack types} (in Fig.~2) to best improve the clarity on how each of them are launched;
    \item Adding more detailed descriptions not only at the beginning of \S2.3 (LiDAR Spoofing Attacks) to explain how LiDAR spoofing works, but also at the beginning of \S2.1 (Basics of LiDAR Sensing) to also make the descriptions on how LiDAR works more clearly to facilitate the understanding of LiDAR spoofing;
    \item Add even more illustrations on \textbf{synchronized attacks} (Appendix A and Fig. 20) to help better understand the key step in synchronized attacks, synchronization with victim LiDAR scanning pattern.
\end{itemize}

\end{revision}

{\itshape
5.	Clarify the novelty of the high-frequency removal attack. What makes this attack fundamentally different from other attacks? 
}


\begin{response}\label{response:criteria5}
Since the HFR attack belongs to the asynchronous removal attack type, the most closely-related state-of-the-art prior attack design is the saturating attack~\cite{shin2017illusion}. In comparison, their attack strategies are fundamentally different: HFR attack uses \textbf{pulsed} lasers to \textit{directly} manipulate the laser-receiving event timing, while the saturating attack works by using a \textbf{continuous} laser to increase the ambient noise level to \textit{indirectly} cause random detection errors of laser-receiving events, which can thus cause random point injection and removal effects as illustrated in Fig.~12 in Appendix. Due to the requirement of maintaining continuous high-power laser of the latter, it is physically difficult to (1) achieve a large attack laser beam coverage at the victim LiDAR side with sufficiently high intensity, and (2) maintain the attack effect. These thus cause fundamental limitations in the attack capability and practicality, especially when compared to HFR. For example, the demonstrated removal attack effect is only about removing points in a 41$\times$42 cm$^2$ area, lasting $\sim$1 second. On the other hand, our HFR attack leveraging pulsed lasers can remove points in a 10$\times$10 m$^2$ area, without any limit on such attack effect duration, which is thus much more powerful and practical, especially for AD settings.

Meanwhile, we can also compare HFR to other attacks in the removal attack category, not necessarily asynchronized. Among all spoofing attacks with object removal effect, the latest is PRA, a \textit{synchronized} attack (\S2.3.1). Although it can remove $\sim$4,000 points, it requires synchronization and thus compared to HFR, it is by design (1) \textbf{less deployable} due to the white-box attack assumption (\S2.3.1): for HFR, the attack can work without knowing which LiDAR model the victim uses, and can omit the PD part in the spoofer (Fig.~2); and (2) \textbf{not generalizable to next-gen LiDARs} since the common security-related features (e.g., timing randomization, pulse fingerprinting) can directly foil synchronization (\S4.2.2).

\end{response}
\begin{revision}\label{revision:criteria5}
We not only added a dedicated bullet ``Comparison with prior removal attacks'' in~\S3.2 to clarify the novelty of the HFR attack with explicit comparisons with other attacks as above, but also included new illustration figures (Fig. 2 and Fig. 12) to facilitate the understanding of their fundamental differences.
\end{revision}

{\itshape
6.	Describe the high-frequency removal attack in detail. including a discussion on pulse strength and its effects on the success rate of the attack. 
}

\begin{revision}\label{revision:criteria6}
We (1) significantly expanded our descriptions of the HRF attack in~\S3.2, along with a formally derived relationship between the attack frequency and attack success rate in Appendix E; and (2) included a dedicated bullet ``Impact of Pulse Frequency and Laser Drive Voltage'' to study the pulse strength and its effects on the success rate of the attack. Specifically, we performed extensive experiments from both pulse frequency and laser drive voltage angles, and also updated Fig. 7 with the results at different laser drive voltages.
\end{revision}

{\itshape
7.	Answer the following questions.
\begin{description}
\item[a.] How to launch the HFR attack?
\item[b.] What does the synchronization mean? why synchronization is important?
\item[c.] Why is synchronization not needed for this attack? How to mimic the legitimate laser pulse?
\item[d.] How to make the original pulses indistinguishable from what?
\end{description}
}

\begin{response}\label{response:criteria7}
\begin{description}
\item[a.] See Revision~\ref{revision:criteria6}, and the newly-added Fig. 2 and 12.

\item[b.] Synchronization means to synchronize the malicious laser firing timing with the \textbf{victim LiDAR scanning (i.e., laser firing) timing}, which can enable precise control of the attack laser-receiving timing and thus the corresponding positions of the spoofed points. To achieve this, the attacker needs to use an \textbf{extra device} (PD in Fig. 2) to first learn the current state of the victim LiDAR scanning in the real time, and then use the victim LiDAR’s scanning pattern to derive future victim laser-firing timings for synchronized attack laser-firing. More detailed explanations are in Appendix A. This process requires precise knowledge of the victim LiDAR’s scanning pattern beforehand, which is thus referred to as \textit{white-box} attacks in this paper. Those that do not assume synchronization (i.e., asynchronized attacks) can be applied without knowing anything about the LiDAR internal scanning logic, which is thus referred to as \textit{black-box} attacks.

\item[c.] Since the synchronization process above is not applicable to next-gen LiDARs due to their common security-related features such timing randomization and pulse fingerprinting  (\S4.2.2), we \textbf{have to} look for spoofing attack designs that do not need synchronization, or \textit{asynchronized} attacks, if we want to measurement vulnerability status of next-gen LiDARs (RQ2). HFR attack is one such attack that we newly identified, which by design do not assume to know the victim LiDAR scanning pattern beforehand (i.e., the black-box LiDAR attack model). 

\item[d.] Without pulse fingerprinting, LiDAR cannot distinguish between legitimate and malicious lasers (they are both just a signal ``pulse'' from the signal process point of view). Thus, the attacker only needs to fire a laser stronger than the legitimate laser.
\end{description}
\end{response}
\begin{revision}\label{revision:criteria7}
We added an explicit description of ``synchronization'' at the beginning of~\S2.3.1, and further added an even more detailed explanation along with an illustration figure (Fig.~20) in Appendix A. We also added illustration figures for both synchronized and asynchronized attacks and put them side-by-side in Fig.~2 to make it easier to understand (1) how to launch HFR attack without synchronization, and (2) why HFR attack can work without the need of synchronization.
\end{revision}

{\itshape
8.	Clarify the term “points”.
}

\begin{response}\label{response:criteria8}
LiDAR fires laser pulses to the environment and receives their reflections from surrounding objects. Using the time difference between the laser-firing and laser-receiving events and the speed of light, it can calculate the 3D position of a \textbf{``point''} on the surface of such an object in the environment. With such active measurement (or ``scanning'') by firing lasers to different horizontal angles (\textit{azimuth}) and vertical angles (\textit{altitude}), each object is thus perceived as a group of such object surface points, called \textbf{``point cloud''} (Fig.~1).

With the LiDAR spoofing mechanism above, LiDAR spoofing attack works by using an external attack device (\textbf{``spoofer''}) to fire laser pulses back to the victim LiDAR in order to manipulate the time measurements of the laser-receiving events and thus the corresponding 3D position measurements. In the resulting point cloud, the points induced by the receiving of the laser pulses fired by the attacker are thus called \textbf{``spoofed points''}.


\end{response}
\begin{revision}\label{revision:criteria8}
We have significantly expanded the descriptions in LiDAR sensing basics in~\S2.1, with an explicit definition of ``point''. We also explicitly defined ``spoofed points'' accordingly at the beginning of~\S2.3.1.

\end{revision}

{\itshape
9.	Explain why “our spoofer” can achieve significant improvement over traditional spoofers.
}

\begin{response}\label{response:criteria9}

Our spoofer can achieve significant improvement over traditional spoofers due to our new improvements in the \textbf{optical design and electronics setups} of the attack methodology. We found that the optical design in prior spoofers is inadequate in that they cause undesired diffusion and convergence of the laser beam. This degrades the laser power per unit area before reaching the target LiDAR, which thus causes the limitation on the number and angle coverage of spoofable points. 
For example, if the laser beam is expanding (e.g., no lens), the laser intensity rapidly decays with distance. On the other hand, if the laser beam is converging by the lens, it makes the attack unstable because the diameter of the beam decreases along with the distance, making the attacker difficult to aim at the target LiDAR. Ideally, the laser beam should be collimated without diffusion and convergence to achieve the target LiDAR with a minimum loss.
To form a collimated beam, we use a 25.4 mm focal length plano-convex lens with 1 inch (25.4 mm) diameter to cover the laser emitted by SPL90\_3~\cite{SPLPL90_3}, which has a maximum beam divergence angle of 25$^{\circ}$. 
Since the diameter of the laser at the focal point is $\tan{25^\circ}\times 25.4 \times 2 = 23.7$ mm, we can cover it with the 1 inch (25.4 mm) lens. 
To precisely calibrate the lens setup, we develop a device that can adjust the distance between the LD and the lens as designed. As shown in Fig.~3, the lens is connected to the frame with a hollow screw so that we can adjust it precisely. Technically, this allows our spoofer to maintain a larger number and angle coverage of spoofable points from hundreds of meters away since the intensity of decay by air is not so substantial. Detailed results are shown in~\S4.2.1.

Besides optical design, we also found that the electronic setup in prior spoofers is inadequate in that they introduce inaccurate laser detection timing and also long and unstable delays in the signal processing of the spoofer devices, which thus makes it difficult to precisely control the timing of the attack laser firing. To address this, we improve the amplifier for the PD to increase the laser detection accuracy, and also improve FG setup to allow more precise nanosecond-level configuration and calibration.
Due to these improvements, we find that our spoofer is the first to clearly demonstrate the CPI attack capability and can launch robust attacks at a long range and against high ambient light, which are shown in Fig.~1 and detailed later in~\S4.2.1.



\end{response}
\begin{revision}\label{revision:criteria9}
We significantly restructured~\S3.1 with more extensive details to make our new improvements on the spoofer designs more clear as described above.
\end{revision}

{\itshape
10.	Explain how and why the spoofer hardware design can enable the HFR attack.
}

\begin{response}\label{response:criteria10}
To clarify, we do not claim that the HFR attack is \textit{enabled} by our spoofer hardware design improvements (i.e., those explained in Response~\ref{response:criteria9}). Those spoofer hardware design improvements are for exploring the feasibility of the CPI attack capability (i.e., for the results in~\S4.2.1). The HFR attack-side research contribution is about a new asynchronized removal attack design that is fundamentally different from other ones (detailed in Response~\ref{response:criteria5}). Although we use the same spoofer setup to perform the experiments for HFR, it is not necessarily tied to our spoofer hardware design improvements by design.

\end{response}
\begin{revision}\label{revision:criteria10}
We separated the descriptions of our spoofer hardware design improvements and the HFR attack designs in two different parallel sections (i.e.,~\S3.1 and~\S3.2), and also added clarifications into each of them to make it clear that the later does not depend on the former. In the introduction (\S1), we also made it clear that the former is for RQ1 and the latter is for RQ2, and thus are orthogonal methodology-level contributions.
\end{revision}

{\itshape
11.	Explain why the proposed spoofer can achieve the better number of spoofed points and angle coverage than the traditional spoofers. 
}

\begin{response}\label{response:criteria11}
We find the limitations on the number and angle coverage of spoofable points of prior spoofers are mainly caused by the \textbf{inadequate optical design} that causes undesired diffusion and convergence of the laser beam. This degrades the laser power per unit area before reaching the target LiDAR, which thus causes the limitation on the number and angle coverage of spoofable points. Detailed explanations on this are in Response~\ref{response:criteria9}.
\end{response}
\begin{revision}\label{revision:criteria11}
We have revised~\S3.2 to clarify that the number and angle coverage of spoofable points of prior spoofers are mainly caused by the inadequate optical design. We further included extensive descriptions on how we improved it to achieve the better number of spoofed points and angle coverage than the traditional spoofers. 
\end{revision}

{\itshape
12.	Discuss the generic defense (regardless of any specific LiDARs) against the new proposed attack
}
\begin{revision}\label{revision:criteria12}
Following the suggestion, we significantly revised our defense discussions in~\S6 to include: (1) generic defense discussions from both injection and removal attack perspective that is not specific to any specific LiDARs; and (2) included a dedicated defense discussion on the newly-proposed HFR attack in both the sections for sensor-level and software-level defense, under the bullet ``HFR attack-specific defense discussion''. 
\end{revision}


\section{Responses to Other Review Comments}
\label{sec:others}
In this section, we describe our responses and revisions to several other issues raised in the individual reviews but not included in the main major revision criteria above.

\cut{
\subsection*{Reviewer A}

{\itshape

\noindent\textbf{Paper summary}

The authors evaluated the security performance of popular LiDARs against spoofing attacks. For the evaluation, the authors considered both traditional and next generation LiDARs and they improved the capability of the existing LiDAR spoofing attacks with some optics and functional electronics. The evaluation results show that the improved attack achieve better spoofing performance than the existing ones. New generation LiDARs with time randomization capability can still be vulnerable to the spoofing attacks under some special conditions.

\noindent\textbf{Strengths}

1. Autonomous driving is an emerging area, and it is important to investigate the security issues related to autonomous driving.

2. LiDARs are critical to autonomous cars. Evaluating popular LiDARS in terms of the resilience against spoofing attacks is essential to ensure the trustworthy of autonomous cars.

\noindent\textbf{Weaknesses}

1. It is hard to follow and understand the content of this paper. 

2. This paper is a simple extension to the prior art in LiDAR spoofing attack. The novelty of this paper seems to be weak.

\noindent\textbf{Comments for author}

It is hard to follow and understand the content of this paper. In the introduction, the authors mention that they aim to evaluate the chosen pattern injection attack, but there is no description about this attack. I wonder what the attack goal is and how the attacker spoofs a LiDAR. 

\begin{response}\label{response_A_1}
The CPI is not a specific attack, but the attack capability that is widely assumed but not clearly demonstrated by existing attacks as we discussed in the introduction. The CPI attack capability is that the attacker can spoof a specifically-chosen point cloud pattern that was carefully crafted/identified offline before the actual attack time. 
\end{response}
\begin{revision}\label{revision_A_1}
We have created a dedicated section (\S2.3.2) to explain thedetails of the CPI attack capability. 
\end{revision}

In the background section, the authors mention some new attack names, i.e., asynchronized injection and removal attack, the saturating attack, synchronized injection attack, and synchronized Removal attack. The description of these attacks is too general, e.g., “The relay attack [8] is an asynchronized injection attack, which can inject spoofed points by relaying the laser received from the target LiDAR….” but it does not provide constructive information about how these attacks are launched and why they can spoof a LiDAR. 

\begin{response}\label{response_A_2}
In our previous version, we did not include a detailed discussion of the related works because we generally follow the same design of LiDAR spoofer as previous works~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security, cao2023you} and were not able to include the details of each attack due to the page limit.
\end{response}
\begin{revision}\label{revision_A_2}
We have drawn the overview of each existing attack in Fig. 2 and discussed its details in~\S2.3. We have explained the details of the synchronization in Appendix A.
\end{revision}

The author mention in the introduction that they discover a new attack that is named the high-frequency removal attack, but I cannot find any useful information about this attack from the paper. Section 3.4 says that “The attack vector of this attack is similar to the saturating attack [9], but our attack shoots a laser pulse in a high frequency instead of shooting a continuous laser”.  There is no prior description about the saturating attack. 

\begin{response}\label{response_A_3}
The key difference between the saturating attack and HFR attack is whether the shooting laser is continuous or high-frequency pulse laser. As the other parts are similar, we did not introduce the technical details of the saturating attack in the previous version.
\end{response}
\begin{revision}\label{revision_A_3}
We have illustrated the difference between the saturating attack and the HFR attack in Fig. 2 and discussed its details in~\S2.3.
\end{revision}


The entire section does not convey the idea of the high-frequency removal (HFR) attack. Many questions can be raised, e.g., how to launch the HFR attack? what does the synchronization mean? why synchronization is important? Why is synchronization not needed for this attack? How to mimic the legitimate laser pulse? How to make the original pulses indistinguishable from what? The term “points” seem to be an important key word that is used throughout the paper, but again there is no description about the meaning of “points” Observation 1 says that “our spoofer significantly improved the number of spoofed points and angle coverage…”.  What does “our spoofer” mean? What is the difference between “our spoofer” and the new HFR attack identified in this paper? Does “our spoofer” refer to the implementation of the new HFR attack? Why can this spoofer achieve the significant improvement?  Sections 3.2 and 3.1 talks about the spoofer hardware design and spoofer optics respectively, but there is no explanation regarding how and why such a design can enable the HFR attack, or a spoofer to achieve the better number of spoofed points and angle coverage than the traditional spoofers. 

\begin{response}\label{response_A_4}
For our spoofer, we followed the basic design of prior spoofer, but used electronics and optics better than those of previous works. We thus note that ``at the methodology level, we do not think we have a substantial improvement from the prior work''. However, we list them as our contributions because the demonstration of the CPI attack capability has a high research impact considering the circumstance that many recent studies assume the CPI attack capability even though it is not clearly validated.
\end{response}
\begin{revision}\label{revision_A_4}
We have illustrated the differences of the spoofer for each attack in in Fig. 2 and discussed why it brings such a significant difference in~\S2.3.
\end{revision}

The main contribution of this paper lies in the evaluation of popular LiDARs, but the evaluation itself is a straightforward extension to the prior art in LiDAR spoofing attack. The novelty of this paper seems to be weak.

\begin{response}\label{response_A_5}
As discussed in Response~\ref{response:criteria1}, this paper has 2 categories of novelty and research contributions over prior works: methodology-level contributions and finding-level contributions.
\end{response}
\begin{revision}\label{revision_A_5}
To clarify our contributions, we have revised the introduction. Details of the revision are illustrated in Revision~\ref{revision:criteria1}.
\end{revision}



\noindent\textbf{Requested changes}


1. The paper extends and improves an existing attack. Please clarify the novelty issue.
\begin{link}
Addressed in Revision~\ref{revision_A_1},~\ref{revision_A_2} and~\ref{revision_A_5}.
\end{link}

2. Writing should be improved. For example, how to launch the HFR attack? Why does the proposed attack achieve better performance than pervious attacks? Please see the details in the "Comments for author" section

\begin{link}
Addressed in Revision~\ref{revision_A_3} and~\ref{revision_A_4}.
\end{link}
}
}
\subsection*{Reviewer B}

{\itshape
\cut{
\noindent\textbf{Paper summary}

This paper covers the effects of LiDAR spoofing attacks against both first and next-generation LiDAR sensors, the latter of which contains many security upgrades that defeat spoofing methods proposed by prior works.  They also examine the effects of these attacks against three different types of object detectors and the resulting impact on autonomous driving.  In the meantime, the authors identify the HFR attack, which works against next-generation LiDAR sensors and can cause end-to-end impacts.  Finally, the authors evaluate the effect that the training dataset has on object detector performance, discovering that training on specific datasets like nuScenes can significantly weaken an object detector's performance against spoofing.

\noindent\textbf{Strengths}

+ Comprehensive evaluation of spoofing against different LiDAR sensors that identify a critical gap in previous work

 + Demonstration of a new, novel attack (HFR) that addresses that gap and affects next-generation LiDAR sensors

 + Identifies potential weaknesses that can be introduced by using certain popular datasets to train object detectors

+ Defenses are discussed, and the pathway to a solution is made clear.

\noindent\textbf{Weaknesses}

-  The HFR attack is not well-detailed; although it is sufficiently contrasted with the previous saturating attack, important details such as the optimum frequency are not discussed.

-  The paper builds many important aspects of the proposed approaches on prior works but whether the contributions of those aspects are significant is not fully clear

- An overly broad definition of robustness evaluation and (often) unclear justification of the findings

- Language issues throughout

- Minor grammatical and spelling mistakes are scattered throughout the paper.

\noindent\textbf{Comments for author}

This paper was an enjoyable read, with many strengths.   However, there are a few points that need clarification and opportunities for improvement.
}

The authors motivate the paper by giving three limitations (or more broadly research gaps as stated) of the prior works.  While the first two of them are sound, I find the last gap of limited datasets a bit vague. While evaluating attacks on more datasets is deserved, I don't quite understand the problem with evaluating the attacks on the models trained on the KITTI dataset, and the pre-trained model of the Apollo. Unfortunately, "model design", and "scientifically tell" is in  "scientifically tell whether a model is being vulnerable because its model design is not robust or simply the training dataset is insufficient" is not fully clear to understand this.


\begin{response}\label{response_B_1}
We meant that existing model evaluation setups cannot tell whether the observed model vulnerabilities can mainly be caused by model design flaws, or caused by training dataset limitations (e.g., biases). Specifically, the evaluated models in prior works~\cite{jiachen2020towards, hallyburton2022security, cao2023you} are (1) different academia model designs trained on the KITTI dataset~\cite{Geiger2012CVPR}, and/or (2) a model designed and pre-trained by Baidu Apollo~\cite{apollo}. However, this means that they never evaluate the same model design trained on different datasets, which makes it unclear whether the observed model vulnerabilities can in fact be caused by training dataset limitations (e.g., biases) instead of model design flaws. Now that more and more 3D object detection datasets are publicly available (e.g., Waymo~\cite{Sun_2020_CVPR}, nuScenes~\cite{nuscenes}, Lyft~\cite{lyft}), we have the opportunity to more scientifically understand the impacts of training datasets on the security of object detectors under LiDAR spoofing, which thus motivated one of the measurement angles of this study (RQ3).
\end{response}
\begin{revision}\label{revision_B_1}
We revised the descriptions about the limitation on the limited training dataset in the Introduction to make our point about this measurement angle more clear.
\end{revision}

\cut{
In many places, I tried to see a major contribution over prior works. However, I see that many of the proposed approaches and setups are borrowed from prior work. This is clearly stated by authors in many places. For instance, to understand the CPI attack feasibility in the physical world, it is stated that "we do not think substantial improvement from the prior work [14]". As another example, the spoofer hardware design similarly follows the common setup of prior works. 

One of the strongest contributions of the paper is the HFR attack. However,  the HFR attack should be fleshed out in more detail.  The most important detail that was left undiscussed was how "high" the frequency should be in the HFR attack.  I would like to see a discrete mathematical evaluation of the strength of the HFR pulses and their effect on the attack, or at least a ballpark estimate of how strong they should be.

\begin{response}\label{response_B_2}
As discussed in Response~\ref{response:criteria1}, this paper has 2 categories of novelty and research contributions over prior works: methodology-level contributions and finding-level contributions.

For further evaluation of the HFR attack, we have investigated the trade-off between laser power/frequency and attack effectiveness. For laser power, the HFR is still successful even at 40V; for the laser frequency, the lower frequency results in lower attack success rates, as the name of the HFR attack implies.
\end{response}
\begin{revision}\label{revision_B_2}
To clarify our contributions, we have revised the introduction. Details of the revision is illustrated in Revision~\ref{revision:criteria1}.
\end{revision}
}

The next thrust of improvement the paper should receive concerns the description of the robustness evaluation of object detectors. This is one of the sections that I was excited to read and learn about. However, many details are given in the Appendix that makes this section difficult to understand. Second, the paper's language in this section is sometimes imprecise or confusing. Some examples include unclear use of security properties, lacking metrics or systematic evaluation and definition of robustness.   Third, there exists quantitative evaluation that is described at a high level without precise metrics and numbers, and with again unclear use of terms. For instance, I had a hard time understanding what model design robustness refers to.  Here the paper may benefit from the recent efforts in the adversarial machine learning community that aims to provide methodological foundations to correctly evaluate defenses against adversarial examples [a].

[a] Carlini, Nicholas, et al. "On evaluating adversarial robustness." arXiv preprint arXiv:1902.06705 (2019).


\begin{revision}\label{revision_B_3}
We have significantly re-organized the previous~\S5 and Appendix B to improve the clarify. In the paper [a], it suggests clearly stating the adversarial capabilities when evaluating model robustness. To address this, we thus added a formal definition of our spoofing attack modelling at the beginning of~\S5.1, which not only can make it clear what adversarial capabilities we use in our model robustness evalautions in~\S5, but also is a standalone methodology-level contribution itself since future researchers can directly use them for LiDAR spoofing attack evaluation on object detectors. We have also resolved the writing issues pointed out by the reviewers. 
\end{revision}

\cut{
\noindent\textbf{Requested changes}

* An expansion of Section 3.4 with additional details of the HFR attack, including a discussion on pulse strength and its effects on the success rate of the attack.

\begin{link}
Addressed in Revision~\ref{revision_B_2}.
\end{link}

* In Section 5, clarify the vaguely used terms, justify many design decisions adequately, and include the crucial aspects to understand the section entirely.

\begin{link}
Addressed in Revision~\ref{revision_B_1} and~\ref{revision_B_3}.
\end{link}
}
}

\subsection*{Reviewer C}

{\itshape
\cut{
\noindent\textbf{Paper summary}

The paper evaluates the spoofing attack capabilities on a set of first and next-generation LiDARs and presents a new spoofing attack that is capable of evading security features in recent LiDARs.

\noindent\textbf{Strengths}

+ presents a spoofing attack that evades new security features of LiDARs
+ evaluates the attack capabilities on 9 LiDARs, covering first and new-generation LiDARs

\noindent\textbf{Weaknesses}

- The technical contributions are incremental 
- It's not clear what are the new research challenges that the paper intends to address

\noindent\textbf{Comments for author}
}

\cut{
- The paper demonstrates the previously proposed spoofing attacks in a physical setup, that's great, but what research questions are answered towards that demonstration?

\begin{response}\label{response_C_1}
As discussed in Response~\ref{revision:criteria1}, this paper has 2 categories of novelty and research contributions over prior works. 
\end{response}
\begin{revision}\label{revision_C_1}
To clarify our contributions, we have revised the introduction. Details of the revision is illustrated in Revision~\ref{revision:criteria1}.
\end{revision}
}

- The authors find that the CPI attack only works with VLP-16, but not with the new LiDARs that implement new security features. It seems obvious that new attacks would enforce to have new defense mechanisms. Therefore, if an old attack does not work with the new security features in place, I do not think we should tag this as a limitation or a question of 'validity' of the previous attack. Although, I appreciate that the authors conduct comprehensive experiments to identify this.

\begin{response}\label{response_C_2}
The reviewer's point makes sense if the prior work explicitly mention that their attack is only valid on VLP-16. However, prior works~\cite{cao2019adversarial, jiachen2020towards, zhongyuan2021object, hallyburton2022security, cao2023you} proposed their attacks as a generic attack against LiDARs. For example, the most recent work~\cite{cao2023you} says ``our attack approach can be generalized to other LiDAR-based AV perception systems.'' The early work~\cite{zhongyuan2021object} has also explicitly admitted the potential impact from new LiDAR features such as timing randomization, but has never concretely evaluated it. We thus think that our measurement study has a high research impact since we clearly shown the limitation of existing attack, quantitatively evaluated the new defense mechanisms, and identified a new attack which can bypass the defense.
\end{response}


- The authors mention that the prior works evaluate their attacks on a limited number of datasets, while new and more datasets are currently available. Again, I failed to understand how you "fill research gaps" by considering the newly available training datasets for a particular model. Can you be more concrete about the "research gap" when compared with the prior works?

\begin{response}\label{response_C_3}
We meant that existing model evaluation setups cannot tell whether the observed model vulnerabilities can mainly be caused by model design flaws, or caused by training dataset limitations (e.g., biases). Specifically, the evaluated models in prior works~\cite{jiachen2020towards, hallyburton2022security, cao2023you} are (1) different academia model designs trained on the KITTI dataset~\cite{Geiger2012CVPR}, and/or (2) a model designed and pre-trained by Baidu Apollo~\cite{apollo}. However, this means that they never evaluate the same model design trained on different datasets, which makes it unclear whether the observed model vulnerabilities can in fact be caused by training dataset limitations instead of model design flaws. 

To address this, we need to perform evaluations with the same model designs trained on different datasets. Here, by considering the newly-available training dataset for a particular model, we are able to fill the research gap in terms of more scientifically understanding the impacts of training datasets on the security of object detectors under LiDAR spoofing, which has not been done before by prior works since they never evaluate the same model design trained on different datasets. 


\end{response}
\begin{revision}\label{revision_C_3}
We revised the descriptions about the research gap about the limited training dataset in the Introduction (\S1) to make our point more clear, and also explicitly listed this in the form of research questions (i.e., RQ3) to make it more clear what is exactly the gap (research question) that hasn't been filled before.


\end{revision}


- The paper discusses several defense mechanisms, some of which are already implemented in most new-generation LiDARs. However, since the paper presents a new HFR attack, I think the defense against this attack should also be discussed in a more detailed and generic fashion. 

\begin{revision}\label{revision_C_4}
Thanks a lot for the suggestion! We revised our defense discussions in~\S6 to include a dedicated defense discussion on the new HFR attack in both the sensor-level defense context and the software-level defense context, as can be found in both the sections for sensor-level and software-level defenses, under the bullet ``HFR attack-specific defense discussion''. 
\end{revision}

\cut{
- Lastly, I think the paper emphasizes too much "being first" in demonstrating the CPI attacks in a physical setup (mentioned more than ten times). I would suggest focusing more on the novel contributions towards a particular set of research challenges, which would also help to reproduce the attacks (and come up with new defenses) for the new generation of LiDARs.

\begin{response}\label{response_C_5}
We appriciate your comments. As detailed in Response~\ref{response:criteria1}, we have emphasized our research questions more clearly.
\end{response}
\begin{revision}\label{revision_C_5}
To clarify our contributions, we have revised the introduction.
\end{revision}

\noindent\textbf{Requested changes}

- clearly specify the research challenges and goal of the paper

\begin{link}
Addressed in Revision~\ref{revision_C_1}.
\end{link}

- emphasize more on the research questions (and how they are answered) than just "being first" in doing something

\begin{link}
Addressed in Revision~\ref{revision_C_5}.
\end{link}

- identify the generic defense (regardless of any specific LiDARs) against the new proposed attack

\begin{link}
Addressed in Revision~\ref{revision_C_4}.
\end{link}

- please also feel free to address the questions and comments mentioned above

\begin{link}
Addressed in Revision~\ref{revision_C_3}.
\end{link}
}
}



\subsection*{Reviewer D}

{\itshape
\cut{
\noindent\textbf{Paper summary}

This paper presents the first in depth study of LiDAR spoofing attacks across a wide range of LiDAR systems, spoofing goals, significantly extending prior experimental evaluations. It further  presents new attack vectors against LiDAR systems.

\noindent\textbf{Strengths}

- extensive evaluation 
- simulation and experimental work 
- wide range of lidar systems 
- novel attacks

\noindent\textbf{Comments for author}

I truly enjoyed reading this paper. The extent of the evaluation is impressive, and the authors try to draw clear messages and conclusions. I love the supplementary material that the paper links to and the visualisation of the attacks. 

The observations related to pulse fingerprinting are particularly interesting. This is where I find the only criticism. The authors conclude that fingerprinting is not complex enough to perfectly prevent spoofing attacks because it is likely designed to address interference and not adversarial settings. This is likely correct. But then the authors say that it might not be easy to design  complex fingerprints while ensuring eye safety and leave this without further elaboration.  Such conclusions which almost imply the impossibility of building a valid defense would need to be further substantiated or weakened. 
}
Ideally, one should have a broader discussion on possible countermeasures and limitations, in terms of processing, latency (which should be small given the required reaction time in the case of cars), and also safety for the people and animals in the environment.

}

\begin{revision}\label{revision_D_1}
Thank you so much for the constructive comments! We have added a dedicated Table for this purpose (Table 8) in~\S6.1 to explicitly show the trade-off of the countermeasures between defense effectiveness and the different possible limitation aspects such as safety, latency, and range degradation. We also added a dedicated discussion about the dilemma between more complex fingerprinting and longer distance measurement in~\S6.1.
\end{revision}

\bibliographystyle{IEEEtran}
\bibliography{main.bib}



\end{document}
