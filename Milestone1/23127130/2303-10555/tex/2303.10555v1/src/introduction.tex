\nsection{Introduction} \label{sec:intro}

LiDAR (Light Detection And Ranging)
is one of the most innovative sensors in the past decade. By shooting a laser pulse and measuring its reflection,
LiDAR can provide a detailed 3D understanding of the surrounding environment.
Autonomous Driving (AD) is one of the most benefited applications of the high-speed and high-precision sensing of LiDARs. After LiDAR showed its effectiveness in the 2007 DARPA Urban Challenge\cite{urmson2007tartan}, it has been widely recognized as an essential sensor for Level-4 AD and has been adopted in almost all recent robotaxi services (Waymo One~\cite{waymoone}, Cruise~\cite{Cruise}) and AD vehicles operating in the US~\cite{Motional, Nuro, ponyai}.
While highly beneficial to our everyday life and society, AD is also highly security-critical as even a small operational error can cause fatal consequences~\cite{ubersafety}. To address this, numerous researchers have been conducting security analyses on LiDARs~\cite{petit2015remote, shin2017illusion, cao2019adversarial, jiachen2020towards, cao2021invisible, hallyburton2022security, cao2023you} due to their critical role in AD perception. The major security concern of LiDARs is the fundamental vulnerability against malicious laser shooting, or \textit{LiDAR spoofing attacks}.
The recent research along this line~\cite{jiachen2020towards, zhongyuan2021object, hallyburton2022security} found that such attacks can cause both false positives (injecting a non-existing fake object) and false negatives (removing an existing object). However, we find that there are 3 critical research gaps in these prior efforts: 


\begin{figure}[t!]
\centering
\includegraphics[width=\linewidth]{imgs/intro/arxiv_sp_poc_prior_works_3d.pdf}
\caption{Demonstrations of the Chosen Pattern Injection (CPI) attack capability with $>$6,000 spoofed points using our improved LiDAR spoofer. This significantly improves the LiDAR spoofing attack capability from prior works:~\cite{shin2017illusion} ($\sim$10 points),~\cite{cao2019adversarial} ($\sim$20 points)~\cite{jiachen2020towards} ($\sim$200 points), and~\cite{hallyburton2022security} ($\sim$200 points).
Details are in~\S\ref{sec:arbitrary_point_injection}.
}
\label{fig:arbitrary_point}
\end{figure}

\textbf{Evaluating only on a specific LiDAR:}
Velodyne VLP-16~\cite{VLP16} has been dominantly used in the prior works since it is viewed as a \textit{de facto} choice for LiDAR spoofing evaluation after the first practical spoofing attack was proposed in 2017~\cite{shin2017illusion}. The following works thus all evaluate their attacks only on VLP-16~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security, cao2023you} or use the attack capability on VLP-16 to justify the validity of their threat model~\cite{zhongyuan2021object, hau2021shadow}. 
Although these results are valid on VLP-16, there is no guarantee that these results are still valid in more recent LiDARs, known as next-generation (or \textit{next-gen}) LiDARs~\cite{yoshioka2022tutorial}, as opposed to the first-generation (or \textit{first-gen}) ones such as VLP-16. The next-gen LiDARs have more advanced security-related features, such as laser timing randomization and pulse fingerprinting. 
Prior works~\cite{cao2019adversarial, cao2023you, shin2017illusion} actually discussed some of them as potential defenses, but none of them actually evaluates the impact and effectiveness of them against LiDAR spoofing attacks. 

\textbf{Assuming unvalidated attack capabilities:}
So far, all prior works on fake object injection~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security} assume a \textit{Chosen Pattern Injection (CPI)} attack capability, i.e., an attacker can spoof a specifically-chosen point cloud pattern that was carefully optimized/identified offline before the actual attack time.
For example, the Adv-LiDAR attack~\cite{cao2019adversarial} is a white-box adversarial attack that needs a specific pattern to trigger a vulnerability in deep neural networks (DNNs). The black-box attacks in~\cite{jiachen2020towards, hallyburton2022security} also require a specific pattern in the shape of a vehicle surface.
However, none of them have clearly demonstrated such an attack capability in the physical world.
The bottom area of Fig.~\ref{fig:arbitrary_point} shows the physically-demonstrated spoofing capabilities so far from prior works~\cite{shin2017illusion, cao2019adversarial, jiachen2020towards, hallyburton2022security}. As shown, these were not able to clearly show strong pattern control capabilities.

\textbf{Evaluating with models trained on limited datasets:}
Prior works~\cite{jiachen2020towards, hallyburton2022security, cao2023you} have evaluated their attacks on different DNN models, typically different academia model designs trained on the KITTI dataset~\cite{Geiger2012CVPR} and a model designed and pre-trained by Baidu Apollo~\cite{apollo}. \newpart{However, this means that they never evaluate the same model design trained on different datasets, which makes it unclear whether the observed model vulnerabilities can in fact be caused by training dataset limitations (e.g., biases) instead of model design flaws. Now that more and more 3D object detection datasets are publicly available (e.g., Waymo~\cite{Sun_2020_CVPR}, nuScenes~\cite{nuscenes}, Lyft~\cite{lyft}), we have the opportunity to more scientifically understand the impacts of training datasets on the security of object detectors under LiDAR spoofing.}


\newpart{\textbf{Our work: First Large-Scale Measurement Study.} To fill these critical research gaps, we conduct the first large-scale measurement study on LiDAR spoofing attack capabilities against object detection. Specifically, our study is driven by 3 key novel research questions (RQ): \\
\textbf{RQ1}: \textit{Are the common assumptions made in prior LiDAR spoofing attacks actually realizable? If so, can they also hold for the most recent next-gen LiDARs?} \\
\textbf{RQ2}: \textit{Do different types of LiDARs, especially the next-gen ones with security-related features, have different vulnerability characteristics to LiDAR spoofing attacks?} \\
\textbf{RQ3}: \textit{Will the vulnerability status of popular object detectors to spoofing attacks significantly change with regard to different training datasets and different LiDAR types?}

To comprehensively address these RQs, we empirically evaluate major types of LiDAR spoofing attacks against (1) 9 popular LiDAR models in total, covering both the classic first-gen ones (e.g., VLP-16) and the next-gen ones with new security-related features; and (2) 3 major types of object detectors trained on 5 different datasets. To the best of our knowledge, such a measurement effort is novel in terms of not only the \textit{measurement scale} (none of the prior works studied over 1 LiDAR model, while we study 9), but also the \textit{LiDAR types} (all prior works concentrate on first-gen ones, and we are the first to study the next-gen ones), and \textit{training datasets} (no prior works studied the same model design with over 1 dataset, while we study 5).


\textbf{Methodology-Level Contributions}. To systematically enable these novel measurement efforts above, our work also makes various attack methodology-level contributions. For RQ1, to properly explore the potential to achieve the CPI attack capability, we identify and overcome multiple spoofer design challenges, especially the optical and electronics parts (\S\ref{sec:optical_setup}), which enables us to be the first to demonstrate and quantify the CPI attack capability, which is commonly assumed but never clearly demonstrated in prior works~\cite{cao2019adversarial, jiachen2020towards, cao2023you, hallyburton2022security, zhongyuan2021object} and shown in Fig.~\ref{fig:arbitrary_point}.

For RQ2, to measure the vulnerability status of next-gen LiDARs, we need powerful and practical \textit{asynchronized} (\S\ref{sec:lidar_spoofing_attack}) spoofing attacks since synchronized ones are directly foiled by their common security-related features (\S\ref{sec:inj_other_lidars}). However, since all existing works only consider first-gen LiDARs, their designs predominately focus on synchronized attacks~\cite{shin2017illusion, cao2019adversarial, jiachen2020towards, hallyburton2022security, cao2023you}, leaving the asynchronized attack design space under-explored. To address this, we identify a new asynchronized attack design called \textit{High-Frequency Removal (HFR)} attack, which is much more powerful and practical than prior ones (e.g., can remove points in a 10$\times$10 m$^2$ area, while the latest prior one can only remove points in a 41$\times$42 cm$^2$ area~\cite{shin2017illusion}). For RQ3, to overcome the challenge in performing large-scale evaluation of LiDAR spoofing attack capabilities against different object detectors, we perform novel mathematical modeling of the spoofing attack capabilities on different types of LiDARs based on our measurements for RQ1 and RQ2.


\textbf{Finding-Level Contributions}. With the novel methods above, we are able to extensively explore the 3 RQs and identify \textit{12 novel findings in total}, which include not only completely new ones due to the measurement angle novelty (e.g., the measurements on next-gen LiDARs), but also many that directly challenge latest knowledge/understandings in this problem space, for example:

\begin{itemize}[leftmargin=0.2in]

\item We find that VLP-16 is actually the \textit{only} LiDAR model for which the CPI attack capability is feasible, which is the key design assumption made in all prior works on fake object injection side~\cite{cao2019adversarial, jiachen2020towards, hallyburton2022security}. This directly challenges the validity of all these prior designs against the more general and recent set of LiDARs. (\S\ref{sec:inj_other_lidars})

\item We find that the next-gen LiDAR features previously expected to be capable of largely mitigating or even preventing spoofing (e.g., timing randomization~\cite{cao2019adversarial, cao2023you}, pulse fingerprinting~\cite{shin2017illusion}) may not be effective as expected (e.g., can still have $>$35\% success rate on industry-grade detector even with timing randomization). (\S\ref{sec:sec_enchance_feats}, \S\ref{sec:vul_to_injection})

\item We find that while the latest synchronized removal attack can no longer be applied to the next-gen LiDARs, our newly-identified asynchronized HFR attack can effectively overcome such a limitation and can cause end-to-end safety hazards in simulated AD scenarios and remove real vehicles in the physical world. (\S\ref{sec:vul_to_removal})

\end{itemize}

More details and demos are in~\S\ref{sec:spoofing} to~\S\ref{sec:object_detection} and our website at \textcolor{blue}{\textbf{\url{https://sites.google.com/view/lidar-study/}}}.

\textbf{Data and code release.} All the involved data and code (including the new spoofer circuit diagram) will be released.

}

\cut{
To comprehensively address the RQs, we evaluate major LiDAR spoofing attacks on 9 popular LiDARs, covering both the classic first-generation ones such as VLP-16. As a side product of the study, we identify a new attack named HFR attack, which has almost a similar attack vector to an existing attack but can achieve high attack effectiveness even though it does not require synchronization with LiDAR scanning.
Based on the newly-obtained LiDAR spoofing attack capabilities, we evaluate their impacts on 3 major types of object detectors trained on 4 different datasets.
In summary, our study has 2 aspects of contributions: novel findings obtained through our empirical study and methodology-level contributions to conduct our study.

\noindent\textbf{Findings-Level Contributions:}
\begin{itemize}[leftmargin=0.2in]
    \item We conduct the first large-scale measurement study on LiDAR spoofing attack capabilities on object detectors with 9 LiDARs, covering both the next-gen LiDARs with new security-related features.
    \item We find that the CPI attack capability is only feasible on VLP-16, which directly challenges the validity of all the existing injection attack designs against more recent LiDARs.
    \item We formulate the LiDAR spoofing attack capability on each LiDARs and evaluate their impacts on 3 major types of object detectors trained on 4 different datasets.
    \item We discuss effective and possible defenses against LiDAR spoofing attacks based on the 12 observations of this study. 
\end{itemize}

\noindent\textbf{Methodology-Level Contributions:}
\begin{itemize}[leftmargin=0.2in]
    \item We significantly improved the LiDAR spoofing capability with more careful optics and functional electronics. With that, we are the first to clearly demonstrate and quantify the commonly-assumed CPI attack capability.
    \item We identify the HFR attack, which is the first practical black-box removal attack that does not require synchronization with LiDAR scanning. 
    We find that its attack capability is enough to cause end-to-end safety hazards in simulated AD scenarios, and also can remove real vehicles in the physical world.
\end{itemize}
}



