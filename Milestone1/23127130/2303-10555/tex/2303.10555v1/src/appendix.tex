




\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{imgs/methodology/high-frequency_removal_attack.pdf}
\caption{Attack mechanism difference between the saturating attack and our HFR attack.
}
\label{fig:highfreq_vs_saturating}
\vspace{-0.1in}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{imgs/spoofing/spoofing_nextg4.pdf}
\caption{Point cloud of NextG\circled{4} in benign and attack scenarios. The point cloud is totally randomized by the attack and the pattern of the rectangle area (our lab room) in the left figure completely disappears in the right figure.}
\label{fig:livox_spoofing}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{imgs/obj_detector/synthesized_scenarios.pdf}
\caption{Evaluation scenario synthesized on a scenario in the KITTI~\cite{Geiger2012CVPR}.}
\label{fig:synth_scenario}
\vspace{-0.1in}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{imgs/obj_detector/n_points.pdf}
\vspace{-0.1in}
\caption{The number of points for the target vehicle at each distance.}
\label{fig:n_points}
\end{figure}



\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{imgs/obj_detector/obj_in_kitti_caronly.pdf}
\vspace{-0.2in}
\caption{Detection rates of the injected object with multiple models trained on KITTI dataset~\cite{Geiger2012CVPR}. The points of the injected object is down-sampled  to 10, 50, 100, and 200 points. The last graph shows the average detection rates of all above 5 models.}
\label{fig:obj_kitti}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{imgs/obj_detector/obj_in_multi_dataset.pdf}
\vspace{-0.2in}
\caption{
Detection rates of the injected object with PointPillars trained on multiple datasets. The points of the injected object is downsampled  to 10, 50, 100, and 200 points.
}
\label{fig:obj_dataset}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{imgs/obj_detector/obj_100pts_under_noise_arch.pdf}
\vspace{-0.2in}
\caption{Detection rates of different models trained on the KITTI dataset~\cite{Geiger2012CVPR} under different noise levels}
\label{fig:obj_noise_arch}
\end{figure}


\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{imgs/simulator/sim_setup.pdf}
\caption{Overview of the evaluation scenario. AD starts driving from 200 m away and it can successfully stop before the target sedan  without attack.}
\label{fig:overview_sim}
\end{figure}

\newpage

\appendices
\renewcommand{\thesection}{\Alph{section}}


\vspace{-0.2in}
\nsection{Detailed Explanations on Synchronized LiDAR Spoofing Attacks}
\label{appndix:sync_attack}

Fig.~\ref{fig:overview_sync} illustrates the synchronized attacks on VLP-16. The attack mechanism is common on both the injection attacks~\cite{shin2017illusion, cao2019adversarial, jiachen2020towards, hallyburton2022security} and the removal attacks~\cite{zhongyuan2021object, cao2023you} since their difference is whether they move points at target locations or move points into undetectable area. The attack procedure consists of 3 steps:~\circled{1} PD first receive the legitimate laser from the target LiDAR to know when the LiDAR will scan the point that the attacker want to change; ~\circled{2} FG plans when to fire lasers based on the information from PD and the pre-defined scan pattern of the target LiDAR;~\circled{3} the laser is fired based on the plan from FG through the gate driver and LD. Therefore, to achieve the CPI attack capabilities, the attacker must know exactly where LiDAR is scanning and the scan schedule must be predefined or predictable. The timing randomization breaks the assumption by randomizing the scan schedule.


\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{imgs/methodology/sync_attack_detail.pdf}
\caption{\newpart{Illustration of synchronized attacks on VLP-16. VLP-16 scans each azimuth (every 0.1$^{\circ}$) one by one. At an azimuth, it fires 16 lasers vertically based on the pre-defined scan pattern. Once attackers can identify its state by PD, they can know \textit{when} to fire a malicious laser based on the scan pattern.}}
\label{fig:overview_sync}
\end{figure}

\vspace{-0.05in}
\nsection{Defense Effect of Rare Wavelengths}
\label{appendix:wavelength}

For NextG\circled{1}, we find that we are not able to inject many points since we only have a 905 nm wavelength (SPL PL90\_3), which is also the setup for all prior works~\cite{shin2017illusion, cao2019adversarial, jiachen2020towards, hallyburton2022security, cao2023you}. %
The spoofing with 905 nm wavelength is not effective on NextG\circled{1} that uses an 865 nm wavelength laser. 
We tried our best to purchase 865 nm laser diodes, but we find that high-power 865 nm laser diodes are actually not generally publicly available for personal use. We also tried low-power 860 nm laser diodes such as OPV380 and RLD85PZJ4, but they cannot work more than 4 W, which is too low to inject any points (our 905 nm diodes work at 90W to achieve successful injections).
This suggests that developing/using a LiDAR with a relatively rare wavelength may have a mitigation effect on LiDAR spoofing attacks in practice since it may make it harder for attackers to acquire the corresponding attack laser diodes.
At this point, only a very small portion of LiDARs has this property; a recent survey~\cite{lidar_survey2021} reports that 905 nm wavelength laser is the most commonly used in LiDARs and 865 nm wavelength laser does not even appear in their graph due to its rarity.

Nevertheless, such a potential mitigation effect would lose effectiveness if more LiDARs adopt 865 nm wavelength as this may boost the availability of 865 nm laser diodes on market. Also we find that not all LiDARs using a rare wavelength can directly have such a mitigation effect. For example, although NextG\circled{5} is using 860 nm instead of 905 nm, we find that it is still directly attackable with the 905 nm attack laser since it does not have a band-pass filter to exclude light other than its wavelength. 


\nsection{Case Study Results on Specific LiDARs}
\label{appendix:specific-lidars}
\vspace{0.05in}
\nsubsection{Relay attack on NextG\circled{6}}

Flash LiDAR fires a wide diverging laser beam and needs to receive them at the same time. This mechanism is exploitable by the relay attack (\S\ref{sec:async_attack}), which is not effective on the scanning LiDARs because PD can only receive a very limited azimuthal range, and the spoofed points will always be located far from the spoofer as discussed in~\cite{shin2017illusion}. 
However, we find that the relay %
attack can be effective on the flash LiDAR as a removal attack. As its laser covers a wide range, the attacker can also disturb a wider range. If the attacker's laser is strong enough, they can remove the original points by moving them to farther points than the spoofer.
Fig.~\ref{fig:relay_attack} shows the results of the relay attack on NextG\circled{6}. The entire row of detection is moved to very far position.
Note that NextG\circled{6} has a special design that consists of multiple rows of scanning. If it is a typical flash LiDAR, the relay attack can cause an effect \newpart{on more rows.} %


\begin{observation}{RQ2}
Compared to traditional scanning LiDARs, relay attack can be more effective on flash LiDARs as a removal attack.
\end{observation}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{imgs/spoofing/relay_attack_nextg6.png}
\caption{Relay Attack on NextG\circled{6}. The attack moves the detected area to a much farther location. %
}
\label{fig:relay_attack}
\vspace{-0.1in}
\end{figure}

\nsubsection{Zero-distance sensing of NextG\circled{2}}

As listed in Table~\ref{tbl:target_lidars}, NextG\circled{2} is capable to measure the distance to LiDAR down to 0 m. The zero-distance sensing is not available in most LiDARs due to its technical challenges: detecting a very short time of laser flight is difficult to distinguish from noise due to unideal hardware calibration as discussed in~\cite{cao2023you}. However, it is technically realizable, which thus directly breaks the design assumption of the latest PRA attack~\cite{cao2023you} (i.e., needs enough MOT, \S\ref{sec:sync_removal_attack}).


\begin{observation}{RQ1}
LiDARs with zero-distance sensing exist, which directly breaks the design assumption of the latest PRA attack~\cite{cao2023you}.
\end{observation}

\nsubsection{Wide Vertical FOV of NextG\circled{3}} \label{sec:case_nextg3}


As listed in Table~\ref{tbl:target_lidars}, NextG\circled{3} has the widest vertical field-of-view (FOV), 70$^{\circ}$.
It results in the lower attack success rate $\mathcal{R}=19.4\%$ even though the number of points is large, 3,203 points.
This is because our spoofer cannot cover all altitudes of NextG\circled{3}. However, it does not mean that NextG\circled{3} is more robust against attacks because the attacker does not need to attack the entire vertical FOV. Fig.~\ref{fig:nextg3_hfa} shows an example of our HFR attack effect on NextG\circled{3}. As shown, our HFR attack is successful in the middle of the vertical FOV, which can allow attackers to hide objects there. In~\S\ref{sec:vul_to_removal}, we will evaluate the impact of our HFR attack on NextG\circled{3} in simulated AD scenarios.

\begin{figure}[t!]
    \begin{minipage}{.6\linewidth}
        \centering
        \includegraphics[width=\linewidth]{imgs/spoofing/nextg3_hfa.pdf}
        \caption{HFR attack on NextG\circled{3}. Our spoofer cannot cover the entire FOV, but can still be effective in the middle area.}
        \label{fig:nextg3_hfa}
   \end{minipage}\hspace{0.03in}
    \begin{minipage}{.37\linewidth}
        \centering
        \vspace{-0.1in}
        \includegraphics[width=\linewidth]{imgs/spoofing/nextg2_100pt_injection.png}
        \caption{Spoofed points on NextG\circled{2}.}
        \label{fig:nextg2_100pt_injection}
    \end{minipage}
\end{figure}





\nsubsection{Simultaneous Firing on NextG\circled{1} and VLS-128}

Fig.~\ref{fig:sim_firing} shows the spoofed points on NextG\circled{1} and VLS-128~\cite{VLS128}.%
As shown, NextG\circled{1} fires and scans 32 lasers vertically, and thus we can only move the depth of each vertical line with 32 points simultaneously.
VLS-128 shoots 8 lasers based on a predefined pattern, and thus we can only simultaneously change the depth of each group consisting of 8 points.
As we do not have the capability to selectively return a laser to each simultaneous laser, we are not able to achieve the CPI attack capability as discussed in~\S\ref{sec:sec_enchance_feats}.

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{imgs/spoofing/sim_firing_nextg1_vls128.pdf}
\caption{Spoofing results for NextG\circled{1} and VLS-128.}
\label{fig:sim_firing}
\vspace{-0.1in}
\end{figure}

\nsection{Taxonomy of 3D Object Detectors}
\label{appndix:obj_detector}


\textbf{Voxel-based Methods.}
Voxel-based method is a very early, but still dominant approach~\cite{lang2019pointpillars, zhou2018voxelnet, shi2020points, yan2018second}. To deal with the irregular structure of point clouds, this approach aggregates points into 3D voxels to make the CNN work effectively. 
PointPillars~\cite{lang2019pointpillars} is the most widely used in autonomous driving systems such as Baidu Apollo~\cite{apollo} and Autoware~\cite{autoware} because it can achieve higher throughput by constructing voxels as pillars perpendicular to the grounds although the z-axis resolution becomes coarse. In~\S\ref{sec:vul_to_injection}, we find that the voxel-based method is slightly less robust than the other methods to the injection attacks as it cannot recognize the detailed geometry of points.




\textbf{Point-based Methods.}
\newpart{Point-based methods directly handle point cloud without voxelization. To efficiently handle point clouds, this approach utilizes permutation-invariant operators. PointRCNN~\cite{shi2019pointrcnn} is a two-stage method inspired by FastRCNN~\cite{girshick2015fast} in 2D object detection. PointRCNN generate 3D proposals and point features with PointNet backborns~\cite{qi2017pointnet++}.  3DSSD~\cite{yang20203dssd} is a single stage method inspired by SSD~\cite{liu2016ssd} in 2D object detection. By leaving only representative points in the downsampling, 3DSSD removes the feature propagation layer and achieves higher throughput than the two-stage method.}





\textbf{Point voxel-based Methods.}
Point voxel-based method~\cite{shi2020pv, chen2019fast} is a hybrid approach of the voxel-based and point-based  methods. PV-RCNN~\cite{shi2020pv} is a two-stage method that uses the voxel-based method in the first stage (3D proposal generation) and the point-based method in the second stage (regional refinement). In~\S\ref{sec:vul_to_injection}, PV-RCNN~\cite{shi2020pv} shows the highest robustness to the injection attacks. The second stage with PointNet backbone, which is not in 3DSSD, enables to obtain more detailed point geometry.



\newpart{
\nsection{Theoretical HFR Attack Success Rate}
\label{appndix:attack_formula}
\cut{
The primal requirement for LiDAR spoofing attacks, including this HFR attack, is to fire a malicious laser that is stronger than the legitimate laser from LiDAR. This requirement can be represent as follows:
\begin{align}
    \frac{L_s}{d^2_s} > \frac{L \times R}{(2d)^2}
\end{align}
, where $L$ is the power of the legitimate laser, $R$ is the reflectivity of the legitimate object, $L_s$ is the power of the malicious laser, $d$ is the distance between LiDAR and the legitimate object, and $d_s$ is  the distance between LiDAR and the LiDAR spoofer.
}
HFR attack can theoretically achieve 100\% attack success rate if the pulse frequency of the attack laser is higher than the one of the LiDAR scanning. In this case, the attacker can always hit the victim LiDAR immediately after every legitimate laser fire and can move all points to 0 m from LiDAR similar to the PRA~\cite{cao2023you}. Thus, we can formulate the attack success rate (ASR) of the HFR attack based on the laser frequency as follows:
\begin{align}
    \min \left ( 1, \frac{F_{\rm HFR}}{F_L} \right )
\end{align}
, where $F_{\rm HFR}$ is the pulse frequency of HFR attack and $F_L$ is the frequency of LiDAR scanning.
}


\cut{
\nsection{Preliminary Experiment on Major Object Detectors}
\label{appndix:obj_in_kitti_caronly}

We conduct a preliminary experiment to investigate the robustness against the injection attacks under precise CPI assumption.

\nsubsection{Impact of Model Architecture} \label{sec:impact_model}
Fig.~\ref{fig:obj_kitti} shows the detection rates of the injected object with multiple models trained on the KITTI~\cite{Geiger2012CVPR} dataset, which is commonly used for the evaluation of LiDAR spoofing attacks in the prior works~\cite{jiachen2020towards, hallyburton2022security}. The last row shows the averaged detection rates for the five models above.
The results show that PointPillars~\cite{lang2019pointpillars} is the most vulnerable to a small number of point injection (e.g., 10 points) as the detection rates reach more than 86\% at 5 m distance. PointPillars is the most widely used in autonomous driving systems such as Baidu Apollo~\cite{apollo} and Autoware~\cite{autoware} due to its low computational overhead. However, its voxel-based approach can be vulnerable to the attack with dozens of injected points since it cannot capture the the shape of points precisely.
On the other hand, PV-RCNN~\cite{shi2020pv} shows the highest robustness as the detection rates are not consistent with the number of spoofed points even in the 50-point case. It should be due to the PointNet~\cite{qi2017pointnet++} backbone in the second stage. It enables to obtain more detailed shape of points and may contribute to the robustness. 3DSSD~\cite{yang20203dssd} also adopt a point-based approach, but the robustness is not so high as the PointNet~\cite{qi2017pointnet++} since it does not have the PointNet backbone.
Meanwhile, the attacks generally can achieve high detection rate with 100 points. This observation is consistent with ~\cite{jiachen2020towards}. However, our results indicates that the attacker may not require a complex black-box attack used in~\cite{jiachen2020towards}, but the attacker can inject ghost objects simply by spoofing random points along a surface of vehicle.

\begin{table}[t!]
\centering
\caption{Overview of datasets for 3D object detection.}
\label{tbl:datasets}
\begin{tabular}{cccc}
\toprule
         & Size    & Vertical Channel & Object types \\ \hline
KITTI~\cite{Geiger2012CVPR}    & 14,999  & 64               & 8            \\
nuScenes~\cite{nuscenes} & 34,149  & 32               & 23           \\
Lyft~\cite{lyft}     & 18,634  & 40 or 64         & 9            \\
Waymo~\cite{Sun_2020_CVPR}    & 192,484 & 64 (top)         & 4            \\ \toprule
\end{tabular}
\end{table}


\begin{figure}[t!]
\centering
\includegraphics[width=\linewidth]{imgs/obj_detector/obj_in_kitti_caronly.pdf}
\caption{Detection rates of the injected object with multiple models trained on KITTI dataset~\cite{Geiger2012CVPR}. The points of the injected object is down-sampled  to 10, 50, 100, and 200 points. The last graph shows the average detection rates of all above 5 models.}
\label{fig:obj_kitti}
\end{figure}

\nsubsection{Impact of Training Data} \label{sec:impact_data}
Fig.~\ref{fig:obj_dataset} shows the detection rates of the injected object with PointPillars~\cite{lang2019pointpillars} trained on different datasets including the PointPillars model in Baidu Apollo 6.0~\cite{apollo}, an industry-grade autonomous driving system. We select PointPillars~\cite{lang2019pointpillars} due to their widely used in autonomous driving systems~\cite{apollo, autoware}.
As shown, the Apollo model shows different security properties from the other models. It does not detect the object in most cases when its number of points is 10 and the distance is further than 2 m. On the other hand, other models typically detect the injected object even with 10 points. Particularly, the models trained on the nuScenes~\cite{nuscenes} and Lyft~\cite{lyft} are vulnerable even to the 10-point attack. It could be due to the domain shift as these datasets have smaller vertical channels than the evaluating scenario with 64 channels. However, the 10-point attack is also effective on the model trained on the KITTI~\cite{Geiger2012CVPR} dataset further than the 5 m distance. We consider that there is a considerable gap between the industry-grade object detector, which should be trained on large-scale private datasets, and the models trained with public datasets. This suggests that when we conduct the security analysis on object detectors in AD, we should target such an industry-grade models designed to be usable in AD systems.

\begin{figure}[t!]
\centering
\includegraphics[width=\linewidth]{imgs/obj_detector/obj_in_multi_dataset.pdf}
\caption{
Detection rates of the injected object with PointPillars trained on multiple datasets. The points of the injected object is downsampled  to 10, 50, 100, and 200 points.
}
\label{fig:obj_dataset}
\end{figure}

\begin{figure}[htb]
\centering
\includegraphics[width=\linewidth]{imgs/obj_detector/obj_100pts_under_noise_arch.pdf}
\caption{Detection rates of different models trained on the KITTI dataset~\cite{Geiger2012CVPR} under different noise levels}
\label{fig:obj_noise_arch}
\end{figure}
}

\nsection{Criteria to Count the Number of Removed and Injected Points} \label{appndix:count_method}

To quantitatively evaluate the attack performance, we design a systematic method to count the number of removed and injected points by attacks.
For injection attacks, we judge whether a point is spoofed or not based on 2 aspects: location and intensity. First, we limit the interest area by physical conditions. For example, we can limit the area in our experiment room as the legitimate points cannot be out of our room. Second, We count only points with high intensity because the spoofed laser has much higher intensity than a reflection of the legitimate laser. 
For removal attacks, we remove a wall in our room. We judge a point is removed if the points is not detected or moved more than 20 cm from the location in the benign measurement.






\cut{
\nsection{Reproduction Tips for Agilent 81160A}

For the efficient reproduction, we note that the byte sequence needs to have the maximum length that the FG can store. Otherwise, it will strangely introduce a few nanoseconds error and disrupt the arbitrary point injection. This problem should be a specific on Agilent 81160A.
}

\nsection{Limitations of Our Study} \label{appendix:limitation}

\textbf{Aiming Problem.}
In this study, we do not discuss the deployability of LiDAR spoofing attacks against driving AD vehicles. We focus more on investigating the security property of different types of LiDARs, rather than the system-level security analysis of autonomous driving in the real world. In a future study, we plan to demonstrate attacks against driving vehicles. %
A recent study~\cite{cao2023you} has demonstrated a system capable of victim LiDAR tracking and spoofer aiming to address this problem.
Therefore, we expect that targeting a driving vehicle is feasible. %


\textbf{LiDAR Model Coverage.}
While we cover popular LiDARs as many as possible with our best efforts, it is infeasible to cover all public LiDARs due to our budget and their supply capacity. For example, we cannot cover 1550 nm LiDARs such as AEye~\cite{Aeye} and Luminar~\cite{Luminar} which utilize unique technology, e.g. adaptive scanning and FMCW ToF, and thus potentially have different spoofing capabilities.
We also cannot cover private LiDARs such as those in Waymo's robotaxi~\cite{waymoone} since they are not publicly available on market.


\nsection{Considerations for Safe Experiments} \label{appendix:safety}
All experiments were conducted in a controlled environment and we wore safety goggles for extra eye safety. Note that the unit-area peak power of our laser is actually weaker than that used by the prior work~\cite{cao2023you} as we use a 50\% larger aperture lens. %
