% !TEX root = main.tex
\subsection{Cross-Modality Association Performance}\label{system_performance}
% To thoroughly evaluate the system performance in real-world scenarios, 
% In this section, we present the system performance on both association accuracy in each window (W-ACC) and the end-to-end association accuracy. 

%In the following, we first introduce the baseline and metric, and present the overall performance in Section \ref{main_acc_result}. Then, we conduct experiments with two practical settings, when there are passengers or the number of people changes continuously over time. Their results are presented in Section \ref{eval_passenger} and Section \ref{eval_change_people}, respectively. 

% We also evaluate the system under two challenging scenarios, where there are passengers or the number of people changes continuously over time.  
% Different real-world settings are involved in this Section:
% \begin{enumerate}
%   \item  All users enable their IMU while nobody leaves or enters the area.
%   \item  All users enable their IMU while someone leaves or enters the area.
%   \item  Part of the users enable his/her IMU  while some passengers who do not enable IMU pass by. 
% \end{enumerate}

\begin{figure}
\centering
\begin{subfigure}[t]{.3\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/scene1}
  % \caption{Case 1: users walks in trajectories with different shapes in the same speed }
  \caption{Sports hall setup}
\end{subfigure}%
\hfill
\begin{subfigure}[t]{.3\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/scene3}
  \caption{Subject detection}
  \label{fig:subject-detection}
\end{subfigure}
\hfill
\begin{subfigure}[t]{.3\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/scene2}
  \caption{Outdoor setup}
\end{subfigure}
\vspace{-1em}
\caption{The sports hall and outdoor experiment setups.}
\label{fig:different scene}
\vspace{-1em}
\end{figure}

\begin{figure}
  \begin{subfigure}[t]{\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/finalMatch-fix}
   \caption{Overall W-ACC and E2E-ACC}
    \label{fig:Finalfix}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[t]{\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/fix-2scene}
    \caption{Sports hall and outdoor W-ACC and E2E-ACC}
    \label{fig:Finalfix2scene}
  \end{subfigure}%
  \vspace{-1em}
  \caption{Cross-modality association accuracy.}
  \label{fig:accFinal}
  \vspace{-1em}
\end{figure}

\subsubsection{Baselines and evaluation metrics}

We employ the following \yimin{three} baseline systems.

% We introduce two baselines for comparison: UniverSense \cite{pan2018universense} and iCTrack.
%\textcolor{red}{[make sure names are consistent in figure and text]}



$\blacksquare$ {\em ICTrack} is the variant of ImmTrack with mmWave radar replaced by camera.
%, where ``I'' and ``C'' represent IMU and camera, respectively.
Camera provides much higher resolution than mmWave radar, but causes privacy concerns. 
% The comparison between ImmTrack and ICTrack helps understand whether mmWave radar is sufficient for interpersonal distance tracking. 
ICTrack employs YOLO \cite{yolo} to detect objects and Deep SORT \cite{deepsort} to associate the bounding boxes of the same object in adjacent image frames.
%We implement a visual multi-object tracking system using camera, with YOLOv4 \cite{yolov4}
%as the object detector to generate bounding boxes for every frame and Deep SORT \cite{deepsort} to associate candidate boxes in adjacent frames.
% Deep SORT utilizes the high-dimensional representation extracted by a deep feature extractor for bipartite matching. 
In our implementation, the feature dimension used in Deep SORT for each bounding box is 416. However, Deep SORT does not exploit the prior information of the total number of users (i.e., $N$). As a result, it often mistakenly creates a new tracking identity for a previously seen user. For fair comparison, we explicitly correct a wrongly created tracking identity by the nearest bounding box in the previous frame.
%\yimin{Moreover, YOLO model has shown its capability in person detection, but for person identification, it may make mistake by assigning a new id to a previously seen person. To achieve an equal comparison, we explicitly correct the wrongly assigned id by matching it to a previous id based on nearest location.}
% After that, we apply the Deep SORT, an extension to SORT (Simple Real-time Tracker) for cluster association and tracking.
ICTrack generates the 2D trajectory of each detected user from the video stream and executes the cross-modality trajectory association module presented in \sect\ref{subsec:association}.
%The tracking system can provide 2D location of each detected person in the image coordinate. We then transfer the 2D location into the world coordinate for trajectory generation. Finally, we match those trajectories with the per-IMU ones using our proposed trajectory-based matching algorithm. For clarity, we name this baseline as \textbf{iCTrack} where “i” stands for IMU and “C” for camera.

\yimin{
  $\blacksquare$ {\em ImmTrack-ICP} is the variant of ImmTrack with the Siamese network replaced by {\em colored-ICP} \cite{park2017colored}, a colored point cloud registration algorithm. ImmTrack-ICP applies colored-ICP to find the optimal transformation matrix from each trace map of the radar cluster to each trace map of IMU. 
ImmTrack-ICP adopts the optimization objective function value of the transformation as the similarity between the trace maps of the radar cluster and IMU.
}

$\blacksquare$ {\em mmUniverSense} is a variant of UniverSense \cite{pan2018universense} that associates the user's limb movement detected by camera with IMU data based on movement acceleration.
We compare UniverSense's single metric-based association with ImmTrack's high-dimensional comparative feature-based association. For fair comparison, we adapt UniverSense to mmWave radar by replacing the acceleration metric with velocity metric, as mmWave radar directly provides velocity data.
%The association is based on movement acceleration.
%a pairing method between IoT devices with an IMU and another edge device equipped with a camera. When users in front of the camera are waving the IoT device, the IMU and camera can both estimate the acceleration of the IoT device, and establish the pairing by comparing the acceleration signals. 
% However, the acceleration-based matching solution does not work for mmWave 
% due to the sparisty of the point cloud and we can not tell which part of the point cloud 
% which does not hold in our system because the IMU caputures the acceleration of the arms and the mmWave focuses on the whole body part. In consideration of this point, 4
%To adapt UniverSense to mmWave radar, we make the following customization.
%In this paper, we follow most of the designs of UniverSense but with two adaptations. 
%First, we use the mmWave radar instead of the camera as the ambient sensor. Second,
%We leverage the velocity tracked by the radar and the velocity estimated from the IMU tracking module for pairing, rather than acceleration, considering that mmWave radars directly provide accurate velocity estimation.
This adapted version is called mmUniverSense.
% Similar with UniverSense, we transform the acquired velocity sequence data into fingerprints using binarization with a threshold $\alpha$. Then a similarity score of every pair of fingerprints will be calculated, which will be used for association.



\begin{comment}
The IDIoT system \cite{ruiz2020idiot} associates the user activities detected by camera and multiple body-worn IMUs based on the orientation metric. It requires multiple IMUs for each user and focuses on the scenario where the users perform {\em in situ} activities (e.g., gym exercises). Thus, it cannot be applied for the scenario considered by ImmTrack, where each user only has one IMU and moves around in the monitored space.
\textcolor{red}{may move to related works and cut to one or two sentences.}
%Therefore, we skip it as a baseline.
\end{comment}

{\em Evaluation metrics:} We adopt the ratio of correctly associated pairs to all users to characterize the association accuracy. This accuracy in each association time window is denoted by W-ACC, while the accuracy of the association achieved by the average similarity matrix over $W$ windows is called end-to-end accuracy (E2E-ACC).
%$$
%\text{W-ACC} = \frac{\# \text{correct pairs }}{\# \text{users}}
%$$
%It characterizes the performance of association only using the information within one time window. 
%Moreover, as mentioned in Section \ref{oneshot_id_ass}, we augment the trajectory-based matching by aggregating the similarity matrix in multiple time windows with a soft voting algorithm. 
%We call the matching accuracy obtained with the soft voting end-to-end accuracy, or \textbf{E2E-ACC} for short. 
%{\bf However, as we will discuss in Section \ref{main_acc_result}, a higher W-ACC does not necessarily mean a higher E2E-ACC, as there are other factors that influence.}



\subsubsection{Association performance in sports hall and outdoor spaces} \label{main_acc_result}

\yimin{
Fig.~\ref{fig:Finalfix} presents W-ACC and E2E-ACC of ImmTrack, ImmTrack-ICP, ICTrack, and mmUniverSense on the data collected in the sports hall and outdoor spaces. For each setting of $N$, the experiment lasts for half an hour. Overall, ImmTrack achieves comparable performance with ICTrack on cross-modality association, while remaining less privacy-intrusive.
Specifically, ImmTrack achieves E2E-ACC from 81.4\% to 93.6\%, while ICTrack achieves 85.4\% to 95.1\%.
%The E2E-ACC of ImmTrack reaches $93.56\%$ in the best case and $81.2$\% in the worst case. 
On W-ACC and E2E-ACC, ICTrack outperforms ImmTrack by around 7\% and 3\%, respectively.
% When the number of users is greater than three, ImmTrack outperforms ICTrack in terms of E2E-ACC, although its W-ACC is slightly lower than that of ICTrack. {\red \bf (the examples in Fig 10 explain why camera underperform. they don't explain why lower W-ACC lead to higher E2E-ACC)} 
The accuracy of mmUniverSense is inferior, because when users walk at similar speeds, the association merely based on velocity is prone to be erroneous. ImmTrack-ICP gives the lowest accuracy, which is close to random guessing. For each pair of trace maps from mmWave radar cluster and IMU, the colored-ICP algorithm  finds a transformation with small error even if the cluster and IMU are from different users. As a result, all values in the similarity matrix are high and the association process is close to random guessing.
% This shows that the trace map feature incorporating both trajectory and velocity information is better.
}
%more advantageous. 

\begin{figure}[t]
  \includegraphics[width=.85\linewidth]{figures/path_demo}
  \vspace{-1em}
  \caption{ImmTrack can track the trajectory of a partially occluded user (marked in blue) correctly with help of IMU. } 
  %Though the user marked in blue is partially occluded by the orange one, the system can still track his hovering trajectory correctly. , which in result shows lots of overlapping and occulsions with the orange one.}
  %The mmWave radar can only capture a partial view of the occulded user. ImmTrack relies on IMU PID feature for  inter-frame cluster tracking.
  \label{fig:occulsion-demo}
  \vspace{-1.5em}
\end{figure}

% Fig.~\ref{fig:Finalfix2scene} shows the results in the indoor and outdoor environments separately. 
As shown in Fig.~\ref{fig:Finalfix2scene}, camera-based ICTrack yields higher accuracy indoors than outdoors. 
% due to the more stable illumination indoors. 
% As camera is susceptible to illumination condition, in general, ICTrack yields higher accuracy indoors than outdoors due to the more stable illumination indoors. 
Essentially, the performance of ICTrack may degrade in certain environments with dimmed illumination, e.g., in museums with low illumination for protecting ancient artifacts. Differently, ImmTrack yields consistent accuracy, as mmWave radar is robust to different illumination condition.

By analyzing the results of ICTrack, 
%In our observation,
YOLO in ICTrack performs well in detecting humans (as shown in Fig.~\ref{fig:subject-detection}), while Deep SORT has difficulties in associating bounding box across frames due to the non-coherent visual features of the same user in different frames. Differently, ImmTrack employs extensive features including shape, motion and IMU PID to achieve robust inter-frame cluster tracking. 
% uses more coherent shape, motion, and IMU PID features extracted by mmClusterNet to achieve more robust inter-frame cluster tracking. 
%\yimin{The experiment aims to evaluate the ImmTrack's performance in the presence of  inter-person occlusions.}
Note that the experiments include cases of inter-person occlusions.
In Fig.~\ref{fig:occulsion-demo}, we show that the mmWave radar can still yield some points on the visually occluded user, though with a lower density. This, together with our IMU-assisted design, makes ImmTrack work well in the transient occlusion cases.

% the cases where a user occludes another user in the camera's or radar's FOV. Computer vision in general faces challenges in dealing with occlusions. 
% The mmWave radar can still yield some points on the visually occluded user, though with a lower density. In general, ImmTrack remains robust against such occlusions.
%\yimin{Specifically, refer to Fig~\ref{fig:occulsion-demo}, when inter-users occlusion occurs, though the mmWave radar can only perceive partial part of the occulded user, the occlusion has little influence on  the mmWave-Imu pre-matching module because the module relies on the motion features. As a result, the ImmTrack can still track the users when there are occulsions.}


%Without exposing user privacy, ImmTrack achieves competitive performance as ICTrack. Specifically, the RGB camera is good at person detection, which outperforms the clustering algorithms on sparse point cloud. However, the camera may make mistakes during the  Inter-Frame detection association process due to the non-coherent features of the same person. In ImmTrack, we specifically design the IMU assisted Inter-Frame cluster tracking algorithm by deep fusing the cross modalities information to achieve a robust tracking process.

% We analyze that there might be two reasons. 
% First, iCTrack heavily relies on the visual features for discriminating people. However, when occlusion occurs, which is very common, the camera can only perceive part of the person. As a result, the feature for the occluded person could be different from that with a full view of the body, and thus the iCTrack may wrongly assign the person a new ID. Figure \ref{fig:camViewBef} and \ref{fig:camViewAft} illustrate an example that the camera regards the partial occluded person 5 as a new person 6 after the occlusion disappears. 
% % This is an inherent drawback of visual-feature-based tracking system, where the association heavily relies on the  
% On the contrary, in ImmTrack, we embed the features in multiple dimensions, including motion, shape information of the cluster to acquire coherent and robust features of the same person. 
% % Another critical drawback of the pure shape based feature 
% % is that the visual features heavily depend on the previous one. However, 
% The second reason is that the camera can only provide 2D view, while mmWave radar can provide 3D perception view, which largely broadens the perception capability and decreases the chances for occlusion. In Figure \ref{fig:pcView1}, we exhibit the corresponding radar point cloud of the scene shown in Figure \ref{fig:camViewBef}. The point cloud from five people is not separable from X-axis. However, five clusters are easy to be divided from Y-axis, as shown in Figure \ref{fig:pcView2}.


\subsubsection{Dealing with passengers entering the monitored space} \label{eval_passenger}


% \begin{figure*}[t]
%   \centering
%   \begin{subfigure}[t]{.22\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{figures/PointCloud_cluster_phase1}
%     \caption{Three people in the view with two participants. ImmTrack initializes the clustering with the two centriod positions.}
%     \label{fig:clusterP1}
%   \end{subfigure}%
%   \hfill
%   \begin{subfigure}[t]{.22\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{figures/PointCloud_cluster_phase2}
%     \caption{Removing the outliers after the clustering. }
%     \label{fig:clusterP2}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}[t]{0.5\textwidth}  
%       \centering 
%       \includegraphics[width=\textwidth]{figures/passenger}
%       \caption[]%
%       {{ System performance under differnt number of passengers and participants }}    
%       \label{fig:accEachWin5Pass}
%   \end{subfigure}
  
%   \caption[ ]
%   { W-ACC of competing approaches when there are passengers. The performance for ImmTrack slightly drops in the case. } 
%   \label{fig:accEachWinAllpass}
% \end{figure*}


\begin{figure}
    \centering
    \begin{subfigure}[t]{.46\linewidth}
    \centering
  \includegraphics[width=.8\linewidth]{figures/PointCloud_cluster_phase1}
  \caption{ImmTrack's clustering with passenger causing outliers}
  \label{fig:clusterP1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\linewidth}
       \includegraphics[width=\textwidth]{figures/passenger}
    \caption{W-ACC vs. the ratio of passengers to users}   
    \label{fig:accEachWin5Pass}
  \end{subfigure}       
  
  %\hfill
  %\begin{subfigure}[t]{.31\linewidth}
  %  \includegraphics[width=\linewidth]{figures/PointCloud_cluster_phase2}
  %  \caption{Outliers are removed after the clustering.}
  %  \label{fig:clusterP2}
  %\end{subfigure}
  \vspace{-1em}
\caption[ ]
{Impact of passengers on cross-modality association.}
% (a) ImmTrack is not sensitive to passengers. (b) ImmTrack tackles this problem by being initialized with only two centroids.
\label{fig:accEachWinAllpass}
\vspace{-1em}
  \end{figure}



A passenger refers to a person who is within the monitored space but does not participate in the monitoring. 
% The passengers do not inform ImmTrack their presence and also do not upload the IMU data. 
For instance, a person whose smartphone is not installed with the ImmTrack app is a passenger. 
% To keep ImmTrack's service for the users undisrupted in the presence of passengers, we employ the following additional mechanism to enhance the RKF-assisted $k$-means algorithm for clustering the mmWave point cloud. 
%to a person who enters the field of view of mmWave radar but does not enable the ImmTrack System.  Under the presence of passengers, we use the following algorithm to separate the passengers from the participants during the point clustering phase. 
%Denote by $\widetilde{\vec{c}}_{i,j}$ the centroid of the $i^\text{th}$ user in the $j^\text{th}$ frame predicted by the RKF based on the data before the $j^\text{th}$ frame. ImmTrack applies the $k$-means algorithm to the point cloud in the $j^\text{th}$ frame with $\widetilde{\vec{c}}_{i,j}$, $\forall i \in [1, N]$, as the initial centroids.
In the presence of passengers, there are outlier points corresponding to the passengers away from the new centroids after the RKF-assisted $k$-means clustering. 
To address this problem, ImmTrack views all the points out of the new centroids' bounding boxes as outliers and removes them, where the bounding box size is set to be commensurate to human body dimension. 
This design is motivated by the fact that the enhanced RKF-assisted $k$-means algorithm can keep tracking the users even if passengers enter the space, as long as ImmTrack is bootstrapped from a situation with no passenger. 
Fig.~\ref{fig:clusterP1} shows ImmTrack's clustering when one out of three people is a passenger. The outlier points away from the centroids represented by crosses are excluded from the clustering result.
For fair comparison, we also augment ICTrack to deal with passenger. In specific, we use an asymmetric auction algorithm to perform the $M$-to-$N$ bipartite cross-modality matching, where $M$ is the total number of people detected by YOLO, and $N$ is the number of users. 
% For ICTrack, all people in the FoV can be detected and tracked by YOLO. The cross-modality association is an $M$-to-$N$ weighted bipartite matching problem, where $M$ is the total number of people detected by YOLO, $N$ is the number of users, and the weight is the cosine similarity between the comparative feature vectors extracted from a person's trace map and an IMU's trace map. We use the asymmetric auction algorithm to solve the problem. 
% \yimin{As for ICTrack, the YOLO's ability in detecting person does not fluctuate with the presence of passengers. Therefore, we do not modify the YOLO model and it  detects both the users and passengers. We let the 
% ICTrack track the trajectories of the users and passengers. In the association period, we abstract the problem as a $M-N$ matching, where M stands for the total
% number of people in the FOV of camera and N is the number of users. The system finds the most similar trace map for each IMU from the $M$ maps generated from camera.}
%Note that as this passenger issue is out of this paper's problem description (cf.~Section~\ref{sec:problem}), tracking the passenger's distances to other people in the monitored space is out of scope.
%We use the precision score as the evaluation metric, where the true postive reprenets the number of pairs that are matching correctly.
% The matching accuracy is an indicator of the overall performance of the mmWave tracking moduel, IMU tracking module and the trajectory based matching algorithm.
% We conduct experiments to evaluate the robustness of various systems when a certain number (0 to 8) of passengers enter the monitored space, while fixing the number of participants as 5. 
We measure W-ACC when a certain number (0 to 8) of passengers enter the monitored space, while fixing the number of users at 5. 
From Fig.~\ref{fig:accEachWin5Pass},
ImmTrack achieves similar or even better W-ACC than ICTrack when there are passengers; the W-ACC of ImmTrack is not sensitive to the passenger-user ratio.

% On the other hand, the performance of ImmTrack is not strictly worse than ICTrack in this case, which is different from the observation obtained in the absence of passengers. The inter-person occlusion may be a more detrimental in iCTrack.
% In particular, ratio between passengers and  participants appears to be a irrelevant variable in  terms of ImmTrack's W-ACC. This shows that ImmTrack effectively excludes the passengers from the point cloud clustering. 


%In most cases, the performance of ImmTrack is only slightly lower than that of iCTrack, which indicates that in general, our mmWave tracking module can correctly identify and localize the participants in presence of passengers. Specifically, the W-ACC of ImmTrack is above 72.5$\%$ for 7 people, and we do not see a significant performance fluctuation when the ratio of passengers changes.



% \begin{figure}

%     \centering
%     % \includegraphics[width=\linewidth]{figures/twommWave-demo}
%     \includegraphics[width=.325\linewidth]{figures/demo_radar_one}
%     \includegraphics[width=.325\linewidth]{figures/demo_radar_two}
%     \includegraphics[width=.325\linewidth]{figures/demo_radar_combine}
%     \captionsetup{width=\linewidth}
%     \vspace{-2em}
%     \caption{Combining point clouds from two radars with FOVs' axes of symmetry perpendicular. Color represents user.}
%     \label{fig:twommwave}
 
%   % \hfill
%   % \begin{minipage}{0.49\textwidth}
%   %   % \centering
%   %   % \includegraphics[width=\linewidth]{figures/finalMatch-mutiple}
%   %   % \vspace{-2em}
%   %   % \caption{Cross-modality association accuracy with one or two radars.}
%   %   % \label{fig:multi-acc}  
 
%   % \end{minipage}
% \end{figure}
\begin{table}[]
\caption{Performance improvement by one more radar.}
  \label{tab:2radar-improve}
  \vspace{-1em}
  \begin{tabular}{ccccccc}
  \hline
  Number of users & 2     & 3     & 4     & 5     & 6     & 7     \\ \hline
  $\!\!$W-ACC improvement   & 2.3\% & 2.1\% & 4.0\% & 2.5\% & 4.2\% & 3.8\% \\
  $\!\!$E2E-ACC improvement$\!\!$ & 1.1\% & 1.2\% & 1.1\% & 1.0\% & 1.7\% & 1.3\% \\ \hline
  \end{tabular}
\end{table}


\subsubsection{Combining point clouds from multiple radars}\label{subsec:multi-radar}

%{\red work on multiple radars as shown in section\ref{subsec:multi-radar} by combing their points clouds as in \cite{bansal2020pointillism} to output a single point cloud.}

% Note that the existing camera placement algorithms (e.g., \cite{gonzalez2009optimal}) can be used to determine the locations and orientations of radars for full or maximized spatial coverage. 
Properly combining the point clouds from multiple radars may increase the spatial coverage of a space as well as the point density of a human target seen by multiple radars. 
In this set of experiments, we deploy two radars with their FOVs' axes of symmetry perpendicular. 
% In the system, it leverages the planar world assumption to  register the position information from different mmWave radar views. Specifically, the ImmTrack system constrains the problem space by assuming that objects mostly move on the ground plane\cite{yildiz2010fast}.
% The system accumulates information in all views into the rectified plane as a point cloud registration process.
To accurately combine the two point clouds, we first apply a linear transform including a 90\textdegree{} rotation and origin shift to one point cloud, such that the two point clouds are roughly aligned. Then, we apply the iterative closest point (ICP) algorithm to perform a fine registration of the two point clouds. 
% Fig.~\ref{fig:twommwave} shows the two radars' point clouds and the combined one, when there are two users in the monitored space. 
Table~\ref{tab:2radar-improve} presents the W-ACC and E2E-ACC improvement over varying number of users when two radars are used. With one more radar, there are about 4\% and 1\% absolute improvements in W-ACC and E2E-ACC, respectively, due to higher point cloud density.




\begin{figure}
 
  \begin{subfigure}[t]{0.5\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/floor_plan}
   \caption{Floor plan; angular coverages of two radars; a snapshot of distribution of human subjects.}
    \label{Fig:floorPlan}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[t]{.48\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/end2end-cncl}
   \caption{W-ACC vs. number of people. Horizontal line indicates mean E2E-ACC over four days. }
    \label{Fig:end2endcncl}
  \end{subfigure}%
  \vspace{-1em}
  \caption{Cross-modality association in a live lab space.}
  \label{fig:accTinyFinal}
\end{figure}






\subsubsection{Evaluation in a live lab space}
\label{eval_tiny_space}

%We evaluate ImmTrack in a live lab space with 31 workspaces.
Fig.~\ref{Fig:floorPlan} shows the floor plan. The total area of the space is about $300\,\text{m}^2$. We deploy two mmWave radars to fully cover the corridors and occupied workspaces, while accounting for the blockages caused by internal concrete structures. A total of 17 lab residents voluntarily participate in our evaluation by installing the IMU data collection program on their smartphones. Other lab residents are passengers to our system. \yimin{During the timespan, the numbers of users and passengers in the lab change.}
Fig.~\ref{Fig:floorPlan} also shows a snapshot distribution of the users and passengers. We collect data for four consecutive days. In this setup, we observe the users may walk side by side in the corridor. Thus, we particularly evaluate the effectiveness of the mechanism presented in \sect\ref{boundary_case_macth} for handling identical trace maps. The ImmTrack variant that does not apply the mechanism to separately process the nearly identical trace maps is called {\em non-hierarchical ImmTrack}. 
Note that stationary users, who can be detected in both the radar and IMU modalities, are excluded from the processing pipeline, because the workspaces in this lab conform to safe distancing requirement.
\yimin{However, the stationary users' locations and PIDs are maintained in the system.}
% Fig.~\ref{Fig:floorPlan} to see the floor plan of the office.
%With two mmWave radars, the ImmTrack is able to cover the 300 $m^2$ office by overcoming the occlusions and multipath effect.  
%As shown in Fig.~\ref{Fig:floorPlan}, we deploy two mmWave radar orthogonally to cover the whole area. The data collection lasted for four consecutive days, including both weekdays and weekends. Moreover, we explicitly arrange 17 volunteers as the system users, while the remaining people act as the passengers. 
Fig.~\ref{Fig:end2endcncl} shows the W-ACC of ImmTrack and the non-hierarchical ImmTrack, versus the total number of people in the monitored area. \yimin{The $x$-axis is the number of people in the lab during different
testing periods.}
ImmTrack achieves up to 5.6\% higher W-ACC compared with the non-hierarchical ImmTrack. The horizontal line in Fig.~\ref{Fig:end2endcncl} shows the mean E2E-ACC of ImmTrack over the entire evaluation period, which is 94.1\%.
%With \todo{\textit{Hierarchical Association}}, and the W-ACC increases by up to 5.6\%. 
% Note that On W-ACC, ImmTrack reaches from 87.1\% to 94.1\% and the average Mean-ACC each day achieves 94.1\%.
%\yimin{In ImmTrack, we implement a table to track if a user stays stationary based on the mmWave radar data. The stationary user does not involve in the association phase, which also improves the association accuracy.}
%\yimin{We do not evaluate mmUniverSense because the IMU data of a user may not be zero while he/she stays stationary due to activities such as using mobile phone. As a result, the user's trace map does not reflect his/her movement, making the velocity-based mmUniverSense inapplicable.} 
%Due to prohibition of camera surveillance in this space for the sake of privacy, ICTrack cannot be deployed and evaluated.

%In addition, the office is a privacy-sensitive area that may be improper to deploy the camera to track the users, discouraging approaches like ICTrack. 

%Overall, the ImmTrack system can achieve satisfactory performance in continuously tracking in a real-world privacy-sensitive scenario over a large time span. 




















%=======================================================
% \subsubsection{Association performance for variable $N$} \label{eval_change_people}
  
% We conduct an experiment with five users, in which the users enter and exit the monitored space.
% % In this experiment, we evaluate the system performance when there are people walking in and out.
% Specifically, the users A and B enter the monitored space 30 seconds after the start of the experiment. User C enters the space at the $90^\text{th}$ second. Users D and E enter the space at the $150^\text{th}$ second. After entering, all users continuously walk for three minutes and exit the monitored space one by one with an interval of one minute and in the reverse order of entering. 
% At the time instants when each user enters the monitored space, ImmTrack assigns a PID and completes the cross-modality association.
% %there are 5 participants (denoted by A to E) and two of them enter the test area first, followed by another one after 1 minute. The remaining two people then enter after 2 minutes (i.e., at timestamp 150). 
% %After all of them continuously walk for 3 minutes, we let them leave the area one by one with the interval of one minute and in reverse order as the entering.
% Fig.~\ref{fig:Finalchange} shows the E2E-ACC when $N$ is fixed at 5 (i.e., no entering and exiting events). ImmTrack achieves over 90\% E2E-ACC when $N$ varies. In addition, both ImmTrack and ICTrack exhibit better performance compared with the case of fixed $N$. This is primarily because both ImmTrack and ICTrack achieve higher association accuracy for smaller $N$ settings (as shown in Fig.~\ref{fig:accFinal}) and the average $N$ throughout the experiment time is smaller than five. The experiment results show that ImmTrack can deal with the users' entering and exiting events.

% %There are two reasons. First, under the experiment script illustrated in Fig.~\ref{fig:assocTimeline}, the average number of users throughout the experiment time is smaller than five. From Fig.~\ref{fig:accFinal}, both ImmTrack and ICTrack achieve higher association accuracy when $N$ is smaller. Second, the users' progressive entering makes the inter-frame 

%with different people entering the area in succession, wrong matching is less likely to occur. For example, when person C is entering, people A and B are already associated with two IMU IDs. Therefore, there is only one unmatched IMU for person C, which makes the association less challenging.

% Then the third person is also associated before the remaining two people enter since there is only one IMU.
% We show a deep analysis on the timeline of a specific workflow when the accuracy is 100$\%$ in figure\ref{fig:assocTimeline}.





% \begin{wrapfigure}{L}{0.25\textwidth}
% \begin{figure}
%   \begin{minipage}[t]{.38\textwidth}
%     \includegraphics[width=\linewidth]{figures/finalMatch-changing}
%     % \caption{{E2E-ACC when number of people is changing. }}
%     % \caption{{E2E-ACC when number of people is changing. }}
%     \vspace{-1.5em}
%     \caption{E2E-ACC when $N$ is fixed at 5 (i.e., no entering and exiting) and varies over time.}
%     \label{fig:Finalchange}
%   \end{minipage}
%   \hfill
%   \begin{minipage}{0.58\textwidth}
%     \vspace{-4.5em}
%     \includegraphics[width=\linewidth]{figures/end-to-end-accuracy-with-pass}
%     \vspace{-2em}
%     \caption{W-ACC of various systems when a certain number (0 to 4) of passengers enter the monitored space.}
%     \label{fig:accEachWinAllpass}    
%   \end{minipage}
% \end{figure}
% % \end{wrapfigure}



% \subsection{Hyper-Parameter Analysis} \label{hyperparam}
% In this next, we present the sensitivity analysis of {\em ImmTrack} with various settings of different hyper-parameters.  
% % the system performance does not fluctuate a lot. 
% %For the bin size used for the generation of the trajectory heatmap, we empirically find the optimal value that is most beneficial to the robustness of the system. 

% \subsubsection{Influence of the Proportional Filter Gain}
% The proportional filter gain $k_p$ is defined in Mahony Filter, which estimates user's orientation in the world coordination. A larger $K_p$ makes the algorithm more aggressive at responding to cumulative errors in previous frames. 

% \noindent \textbf{Experiment Design.} 
% A single user follows three pre-defined trajectories with different shapes and repeats the process ten times. We first use dynamic time warping (DTW) to construct the discrete matching between the trajectory from the IMU tracking module and the ground truth. 
% Then we calculate the error using the sum of distance over all matching points.

% \noindent \textbf{Observation.} As shown in Figure \ref{fig:propotional}, our system is not sensitive to the choice of proportional filter gain $k_p$.
% The tracking error is high  when  $k_{p} = 0$, which means the module purely estimates orientation based on the Integral error.
% On the other hand, as long as $K_p \ge 0$, the tracking error does not show much difference. 






% \begin{table}[!h]
% \begin{tabular}{|l|l|}
% \hline
% Trajectory    & Description                                                                                           \\ \hline
% Straight Line & An 8m line                                                                                            \\ \hline
% L Turn        & \begin{tabular}[c]{@{}l@{}}Follow a 4m line\\ and then turn left then\\ follow a 4m line\end{tabular} \\ \hline
% Square        & A 2m * 2m square                                                                                      \\ \hline
% \end{tabular}
% \label{tab:des_trace}
% \caption{Trajectories in the experiment}
% \end{table}

 


   


% {\blue
% \subsubsection{Handling roamers and passengers}    




% For the first heuristic, the number of IMU sensors should be equal to or smaller than the number of clusters because we can not assume every user in the field of view participates in the system.
% The logic here is that the system is only interested in the people who enable their IMU sensors, so the clustering result  of the people that do not participate is out of interest. 
% Here we divide the algorithm into the following two steps to leverage the first and third heuristics.
% \todo{what is the first and the third heuristics? May need to list here or somewhere to remind readers.}

% As the number of people is larger than or equal to $N$, there must be extra points away from the centroid of the cluster, as shown in Figure \ref{fig:clusterP1}. 
% For each cluster $c$, we select the outliers based on their distance from the centroid position.
% % For each cluster $c$, we select the outlier points in $c$ based on the third heuristic and remove them from $c$. 

% % The outliers are those who are not in the bounding box. 
% In this way, we eliminate the interference of the point cloud from passengers, as shown in Figure \ref{fig:clusterP2}.
% % Refer to Figure \ref{fig:clusterDemo} to see a demo on the process when there are 3 people totally and 2 of them are the users.
% }


 


% On the other hand, we observe that the performance of UniverSense drops significantly when the number of people increases. When the number of people is seven, the prediction of UniverSense is almost close to random guessing. This is because UniverSense is a velocity-based association approach. However, the velocity of different people may not vary a lot in many time windows thus not provide enough discriminative information for association. 
% In a short time window, the velocity of different people can be quite noisy and change frequently, while in the long term, the velocity of different people may not vary a lot thus does not provide discriminative information for association. 
% The reason behind is that   in an short period 
% velocity of differnt person's does not 
% have a large difference. On the other hand, the large discrepancy between the IMU velocity pofile and the mmWave velocity profile due to the different sensing part makes the two profile
% different even for the same person.
% We also observe that the W-ACC of ImmTrack drops to zero in some extreme cases. It is mainly because of the occlusions among different people and there will be fewer or near to zero points for the occulded person. 
% \subsubsection{Influence On The Passengers}

% We also evaluate the influence of the number of passengers on the W-ACC.
% We use the same experiment process while let different number of participants shut their IMU to act as passengers. 
% We also observe that the number of passengers does not influence the performance of iCTrack or ImmTrack a lot, which is expected.

% the main influence of the passengers are the clustering result.
% Refer to Figure \ref{fig:accEachWin5Pass},\ref{fig:accEachWin6Pass},\ref{fig:accEachWin7Pass},  the passengers do not influence on the iCTrack's performance much, which is expected.
% On the other hand the performance drops slightly  for about ImmTrack. However, we also don't see a clear relationship between 
% the ratio of passengers with the  accuracy loss. Thus, we assume that the performance loss is due to some extreme case where the 
% passengers are very close to the participants.


% \begin{tabular}[c]{@{}c@{}}ClusterTrack\\ Net\end{tabular}



\begin{comment}
%\yimin{Here we also implement our ImmTrack system to support working with multiple radars. Multiple radars can largely improve the system field of view and point cloud density.}
\yimin{As illustrated in Fig~\ref{fig:twommwave}, When two mmWave radars are placed orthoganoally, neither of the mmWave radar perceives the full view of the two users because  both users locate at the boundary of the field of view of one mmWave radar. However, combining the two point cloud results in a denser cluster for each user as shown in Fig~\ref{fig:twommwave}.}
\yimin{ We modify the iterative closest point algorithm\cite{chen1992objectICP}, initialized with a 90-degree rotation transformation for associating the points in the overlapping part of the two point clouds.  Note that the objective function only considers the points in the overlapping  area of the field of view of different mmWave radars. 
The goal is to find transformation matrix $\mathbf{T}$ from target point cloud $\mathbf{P}$ to 
source point cloud $\mathbf{Q}$.  Let $\mathbf{Q'}$ be  the source point cloud after transformation. Then we use $\mathcal{K}=\{(\mathbf{p}, \mathbf{q})\}$ to denote the nearest-point set, where $\mathbf{p}$  is the nearest point for $\mathbf{q}$ in $\mathbf{Q'}$ Similarly we use $\mathcal{C}=\{(\mathbf{c_p}, \mathbf{c_q})\}$ to denote the nearest-cluster set.
The object function considers the internal distance by summing the distance between each nearest-point set. However, due to the sparsity of the point cloud, the nearest-point set may have little correlation in reality. Therefore, we also consider the 
overall distance between nearest-cluster set by calculating the volume of the non-overlapping area of their bounding box.
Then the final object function to be miniized is  }

$$E(\mathbf{T}) = \sum_{(\mathbf{c_p},\mathbf{c_q}) \in \mathcal{C}} V_{\mathbf{c_p} \cup \mathbf{c_q} }-2 \cdot V_{\mathbf{c_p} \cap \mathbf{c_q} }  +  \sum_{(\mathbf{p},\mathbf{q})\in\mathcal{K}}\|\mathbf{p} - \mathbf{T}\mathbf{q}\|^{2}$$

\yimin{where the first part denotes the non-overlapping volume and the second part is the point-to-point distance.}
\end{comment}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End: