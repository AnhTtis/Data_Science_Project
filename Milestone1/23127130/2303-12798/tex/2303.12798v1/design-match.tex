% !TEX root = main.tex
% \section{Trajectory-Based Association}
\section{Learning-Based Cross-Modality Trajectory Association}
\label{subsec:association}

\subsection{Design Principle}

This module identifies the correspondence among the trajectories reconstructed by the radar in \sect\ref{sec:global-tracking-design} and IMUs via dead reckoning, to re-identify radar's sensing results. Essentially, it is a weighted bipartite matching problem with trajectory similarity as the weight.
%Note that the radar-sensed trajectories are given by the module presented in Section~\ref{sec:global-tracking-design}. The IMU trajectories are obtained by dead reckoning.
%The module's primary goal is to assign  a virtual id of  imu  to a cluster in the mmWave.
%Essentially, it solves an $N$-to-$N$ assignment problem.
% it is a $N-M$ matching problem, where $N$ is the number of participants  and $M$ is the number of occupants within the field of view of the mmWave sensor.
For association, we use the 2D trajectory (without including the altitude dimension), as it is a common feature that can be derived from both the radar's and IMUs' results and is agnostic to modality-dependent details. 
% The trajectory-based matching is considered to be a robust criterion because of the uniqueness of the trajectory for different users. Moreover, since trajectory represents the feature over time, short-term noise should have a relatively lower influence. 
% After generating the trajectories for each imu sensor and cluster in the mmWave, we need to define a similarity score.
For either a radar cluster or an IMU, a trajectory over an {\em association time window} $[t_0, t_1]$ is denoted by $\mathcal{T}(t) = \{x(t), y(t) | t \in [t_0, t_1]\}$. To compute the similarity between a radar cluster's trajectory $\mathcal{T}_{r}(t)$ and an IMU's trajectory $\mathcal{T}_{i}(t)$, the radar's and IMU's 2D coordinate systems need to be registered. A potential method to register the two coordinate systems, both originating at the start points of $\mathcal{T}_r(t)$ and $\mathcal{T}_i(t)$, is to exhaustively search a relative angle between them such that the similarity between $\mathcal{T}_r(t)$ and $\mathcal{T}_i(t)$ under the candidate registration is maximized. However, this registration incurs high compute overhead.
%, depending on the granularity that also affects registration quality.

We design a learning-based, registration-free association approach. 
The main idea is that, instead of considering the distance between two registered trajectories in the same Euclidean space, we take advantage of the feature extraction capability of neural networks to transform trajectories into high-dimensional features, and perform the association based on the distance in the high-dimensional space.
Specifically, we first encode the trajectory into an imagery representation, called {\em trace map}. This is a preparation step that restructures data to a uniform and compact form.
% we use a single image, called {\em trace map}, to compactly present a trajectory. 
Then, we feed {\em trace maps} from the two modalities into a Siamese neural network for feature extraction, based on whose outputs, the distance matrix can be calculated. 
Finally, in association, we introduce a soft voting mechanism which aggregates the information of multiple association time windows and thus mitigates the short-time interference. 
To train the Siamese network, we do not require the ground-truth trajectories. Instead, we extensively construct positive pairs and negative pairs of trajectories, and use a triplet loss to push negative pairs away while bringing together positive pairs, where the only labels required are the matching relationships of the trajectories from the two modalities.

\begin{comment}
As IMU dead reckoning has been extensively studied, we only mention the points noteworthy. ImmTrack adopts the double integration approach.
%applying the double integration on the tri-axis linear acceleration.
%We apply double integration on the accelerometer to generate the trajectory.
%In order to avoid extensively data collection and design a general system, our IMU tracking module adopts the double integration approach. The high level-idea is to apply double integration on the acceleration data to obtain the distance. 
%When integrating acceleration to obtain velocity, the acceleration should be aligned with the heading direction of the IMU to achieve higher tracking accuracy.
When integrating acceleration to obtain velocity, we apply the Mahony Filter \cite{mahony} to estimate the IMU's attitude (i.e., the rotation of the IMU from the gravitational direction) and then project the acceleration to align with the heading direction. In addition, we rectify the \textit{integral drift} by excluding static moments identified in terms of acceleration magnitude.
%One typical reason of integral drift is that the noises shift the actual zero acceleration to non-zero values. We identify the static moments by comparing the acceleration magnitude with a predefined threshold and remove the corresponding acceleration data.
%setting a threshold on the acceleration magnitude. Any magnitude value lower than the threshold is regarded as static. Then we correct the drift by removing the corresponding acceleration data of the static moment.
\end{comment}

\begin{comment}
ImmTrack uses a single image, called {\em trace map}, to compactly represent a trajectory, which facilitates (i) coping with the deviations between the radar's and IMU's trajectories corresponding to the same user and (ii) utilizing the state-of-the-art deep learning models to ...

{\blue
Though the idea is straightforward, we still need to overcome the following problems to successfully utilize the trajectory-based matching.
 
  \begin{enumerate}
     \item \textit{Handel the difference of the trajectory from imu  and the global tracking module}. 
     Due to the different sampling rates and noise,  the trajectories for the same person at the same time from the mmWave and imu are not identical. 
     \item \textit{Embed direction information in the trajectory}. Specifically, we need to distinguish between two users, who walk with the same
     shape of trajectories but from different direction.
 \end{enumerate}
}
\end{comment}
 

% \subsection{Trace map}
\subsection{Trace Map Generation}

Let $\mathcal{M}=\{M(x,y) | \forall (x,y)\}$ denote a trace map converted from a trajectory $\mathcal{T}(t)$, where the pixel value $\mathcal{M}(x,y)$ encodes all the times elapsed from when the trajectory crosses the location $(x,y)$. Let $f_s$ denote the sampling rate in frames per second (fps) of the sensor. Let $T(x,y)$ denote the set of the time instants at which the trajectory crosses $(x,y)$. If $T(x,y) \neq \emptyset$, the map pixel value is given by $\mathcal{M}(x,y) = \sum_{t \in T(x,y)} f_s \cdot (t - t_0)$, where $t_0$ denotes the time instant that the trajectory starts; otherwise, $\mathcal{M}(x,y) = 0$. 
Intuitively, $\mathcal{M}(x,y)$ encodes the number of frames passed when the user's trajectory crossed $(x, y)$ since the trajectory begins. Then, ImmTrack converts the obtained trace map into an image with three 8-bit channels of RGB data.
% ImmTrack further converts the map to a color image by filling the R, G, and B channels up to 255 sequentially using the $\mathcal{M}(x,y)$ as the budget. Once the $B$ channel is full, ImmTrack goes back to refill the $R$ channel. 
We use $\mathcal{M}_r$ and $\mathcal{M}_i$ to denote the color trace maps converted from $\mathcal{T}_r(t)$ and $\mathcal{T}_i(t)$, respectively.
%\todo{Ensure the notations are consistent with those in Algo. 1; OR delete this sentence here as they are not used very frequently later}
%Although it's been a long time since the question was asked but the solution @gehbiszumeis offered didn't work for me and I still got the normal figure caption for each subfigure. So in case anyone has still the same problem as mine here is what I did (according to this):

%=======
%Although it's been a long time since the question was asked but the solution @gehbiszumeis offered didn't work for me and I still got the normal figure caption for each subfigure. So in case anyone has still the same problem as mine here is what I did (according to this):
%>>>>>>> 02afdc82c070b0db667c738610dc9d5287fbc5d5

\begin{figure}
\centering
\begin{subfigure}{.15\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/gt-05}  
    \caption{truth ($\rho$=0.5)}
    \label{figure:gt5}
\end{subfigure}
\begin{subfigure}{.15\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/mmwave-05}  
    \caption{radar ($\rho$=0.5)}
    \label{figure:mmwave5}
\end{subfigure}
\begin{subfigure}{.15\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/imu-05}  
    \caption{IMU ($\rho$=0.5)}
    \label{figure:imu5}
  \end{subfigure}
  \hfill
\begin{subfigure}{.15\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/gt-02}  
    \caption{truth ($\rho$=0.2)}
    \label{figure:gt2}
\end{subfigure}
\begin{subfigure}{.15\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/mmwave-02}   
  \caption{radar ($\rho$=0.2)}
  \label{figure:mmwave2}
\end{subfigure}
\begin{subfigure}{.15\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/imu-02}  
  \caption{IMU ($\rho$=0.2)}
  \label{figure:imu2}
\end{subfigure}
\vspace{-1em}
  \caption{Trace maps of ground truth, radar, IMU trajectories.}
  \label{fig:demoOnS}
\end{figure}





\begin{comment}
 To handle the differences between the trajctories in imu tracking module and the global tracking module, 
 the trajectories are reduced into 2D heat maps to facilitate the matching process. Specifically, instead of denoting each position as a point on the image, we divide the field of view into squares with length $s$.  
 The heat map can preserve the shape information in the original trajectory and weaken the influence of errors and noises in the trajectories in the two different sensing modalities.
 

 If we describe the motion of an object by the function $f(x,y,t)$, where $x,y$ is the location and $t$ is the time,
  the shape of the trajectory contains the location information. Therefore, to solve the 
 second challenge, we need to add another variable to  embed the information related to the time in the trajectory. 
 Here we use the variable intensity of the heatmap $p$ and we design a mapping between
 $$
 f(x,y,t) \rightarrow G(x^{'},y^{'},p(x^{'},y^{'},t))
 $$
 Here $x^{'},y^{'}$ is the location
 on the image. We use ${h}_x,{h}_y$ to represent the size of the heat map, $x_0,y_0$ to represent the starting position of the trajectory, $s$ to represent the 
 grid size of the heat map, $f_{sample}$ to represent the sampling frequency of the sensor. Then specifically:

 $$
x^{'} =  \lceil \frac{x-x_0}{s \cdot {b}_x} \cdot h_x \rfloor  \hspace{1cm} y^{'} =  \lfloor \frac{y-y_0}{s \cdot {b}_y} \cdot h_y \rceil 
 $$
 
 $$
 p(x^{'},y^{'},t) = \left( p(x^{'},y^{'},t) + f_{sample} \cdot t \right) \mod{p_{max}}
 $$

The value $b_x,b_y$ is the length of the targeted sensing area.
Here $p_{max}$ is the maximum intensity of the heat map. Then since $ p = \frac{R+G+B}{3} $,  we change the $R$ equal to $p$ first, once the $R$ value is staurated, we modify the value of $G,B$ .

To weaken the impact of the sensing errors, we adopt low-resolution trace map.
\end{comment}

Furthermore, in order to mitigate the impact of noises, we adopt specific spatial grid size $\rho$ for the trace maps.
% lower resolutions by letting each pixel in $\mathcal{M}(x,y)$ correspond to a $\rho \times \rho\,\text{m}^2$ square in the coordinate system of the trajectory. Moreover, the time instants at which the trajectory crosses the square are included into $T(x,y)$. 
% Furthermore, to weaken the impact of the noises in reconstructing the trajectories from the radar and IMU data, we construct the trace maps with lower resolutions by letting each pixel in $\mathcal{M}(x,y)$ correspond to a $\rho \times \rho\,\text{m}^2$ square in the coordinate system of the trajectory. 
Fig.~\ref{fig:demoOnS} shows the trace maps of the ground truth, radar, and IMU trajectories under two $\rho$ settings, where a user follows a square zig-zag path to move. A darker red pixel indicates that the trajectory crosses the position more recently. We can see that, due to the inherent uncertainty of sensing, the radar's and IMU's trace maps have deviations from the ground truth. Moreover, under a certain $\rho$ setting, the IMU's trace map has more colored pixels on the trace than the radar's because of IMU's higher sampling rate. As a result, for IMU, setting a smaller $\rho$ can better reduce the crosstalks among different segments of the trajectory, while a larger $\rho$ can make the trace for the radar more continuous. % maintain the trace connected for radar. 
In the rest of this paper, we adopt $\rho=0.2\,\text{m}$ and $\rho=0.5\,\text{m}$ for IMU and radar, respectively.
Finally, we crop the trace map in an area of 20m $\times$ 20m and resize it to 193 $\times$ 193, which will be fed into the Siamese neural network presented in \sect\ref{subsec:siamese}.
% Finally, we find the optimal trajectory generation time to balance the accuracy and delay of the system.

% \begin{figure}
%   \hfill
%   \begin{minipage}[t]{.22\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{figures/window}
%     \caption{\footnotesize{The sampling time should not set to a larger value duo to the cumulative error on the mmWave and IMU tracking module.}}
%     \label{fig:generation time}
%   \end{minipage}%
% \end{figure}
%We observe  a proper value of $\rho$ for mmWave tracking  is not suitable for imu tracking. Refer to Figure \ref{fig:demoOnS}, when $\rho=0.5m$ for both mmWave and imu, while the track map from the mmWave tracking module is close to the ground truth,  the one from the imu is misaligned.  The observation leads us to set a different value for $\rho$ in mmwave tracking module and IMU tracking module.  Expressly, we set $\rho = 0.5m$ and  $\rho = 0.2m$ in mmwave tracking module and IMU tracking module respectively. 
 
%Then We rely on the siamese network to miltigate the difference in  two trajectories to the same size in order to  match the two trajectories. 

% \todo{move this section to front}
% \subsubsection{Influence of the Trajectory Generation Time}
% We investigate the relationship between the trajectory generation time $t_{gen}$ and the performance of W-ACC. %comparing \textbf{W-ACC}. on 3 and 4 people under different. 
% To eliminate the occasion of occlusion and focus on the impact of $t_{gen}$, we conduct this evaluation using the data with 3 and 4 participants. 
% %so that the only factor is $t_{gen}$. Note that we do not experiment on a higher number of people here in order to exclude the 
% As depicted in \ref{fig:generation time}, the accuracy is low when $t_{gen}$ is too small, which is reasonable, as less temporal information could be utilized for association.
% % is as expected since if the trajectory generation time ($t_{gen}$) is too short, nearly all the trajectories are the same. 
% We also observe a degradation of W-ACC when $t_{gen}$ is too large. This is because the cumulative errors over a long period time, which results in very discrepant trajectories obtained by the same user from two sensors. Moreover, for the sake of the user experience, we expect the system to generate the association as soon as possible, which prevents us from using a very large window size.
% % A larger trajectory generation time  results in more unique trajectories and hence leads to a matching with a higher confidence level.  Nevertheless, there
% % are mainly two considerations that restrict us to set a higher value on it. 
% % \subsection{Siamese network for comparing trajectories}
\subsection{Comparative Features Extraction}
\label{subsec:siamese}

% that can generate a similarity score of two input trace maps.
%After we transfer the trajectory to the heat map, 
% we design a siamese network for comparing the similarity between the trajectory.

We design a Siamese neural network to extract comparative features from $\mathcal{M}_r$ and $\mathcal{M}_i$, whose cosine similarity characterizes how close the $\mathcal{T}_r(t)$ and $\mathcal{T}_i(t)$ are.
%the similarity between $\mathcal{M}_r$ and $\mathcal{M}_i$.
Typically, a Siamese network contains two or more identical sub-networks that extract features from their respective input. During training, any parameter updates are mirrored across all sub-networks.
%The specific architecture is specifically designed for tasks related to image similarity comparison, such as face recognition.
%In addition, the siamese network is designed for one shot learning , whose task is  learning representations from a single sample. In our scenarios, each trajectory is unique and there isn't a lot of samples with the same shape. 
As illustrated in Fig.~\ref{fig:siamese}, the Siamese network used by ImmTrack employs a convolutional neural network (CNN) as the feature extractor. The CNN consists of three convolutional layers with rectified linear unit (ReLU) activation followed by max-pooling and a final fully-connected layer producing a $1 \times 1024$ feature vector.
% This layer produces the feature vectors that the weighed distance layer will fuse for comparing the similarity.
During training, three such identical CNNs are used to process three inputs, i.e., anchor, positive, and negative inputs.
% Our model uses three identical CNN sub-networks with shared weights for three different inputs: anchor, positive, and negative input.
The anchor and positive inputs are two trace maps generated from the radar and IMU for the same user at the same time, while the negative input is an unrelated trace map from either the radar or IMU.
% Specifically, the inputs are three heatmaps, where two of them will be the trajectories from the same person at the same time, one from mmWave and one from imu and the third one a negative example either from mmWave or imu, which is not similar to the previous one.
Denoting by $\vec{f}_a$, $\vec{f}_p$, and $\vec{f}_n$ the feature vectors produced by the CNN for the anchor, positive, and negative inputs, we use the triplet loss function for training: $\mathcal{L}=\max ( \| \vec{f}_a - \vec{f}_p\|_{\ell_2}- \| \vec{f}_a - \vec{f}_n \|_{\ell_2} + \mathrm{margin}, 0)$.
%After the distance layer, we adopt the triplet loss\cite{facenet} shown in equation\ref{eq:triplet} and the loss will maximize the distance beteen anchor and negative pair while minimizing the distance beteen anchor and positive pair.
% We collect a training dataset by randomly walking in a monitored space. In addition, 
We also generate simulated trajectories to augment \yimin{the training data collected in a real environment}. 
% {\red {Specifically, we use a random walk stochastic process to simulate the anchor input. Then we scale up or down the anchor input and hence  shift $10\%$ positions of the anchor input to neighbor positions.
Specifically, we use a random walk stochastic process to generate the anchor, and obtain the positive input by scaling up or down the anchor and shifting $10\%$ of the anchor positions to their neighbors. \yimin{Note that the training data needed by the Siamese neural network is unnecessary to be {\em in situ} data, because the network only learns extracting environment-agnostic comparative features.}
% During inference, the Cosine distance between the feature vectors of a radar cluster's and an IMU's trace maps is yielded as the similarity score.
At ImmTrack's run time, the trained CNN is used to extract the comparative feature from any given trace map $\mathcal{M}$.

%As for the inference phase, the input will be a pair of trajectories and the output will be the distance beteen them.

 % \begin{equation*}
%   \mathcal{L}=\max (d(ahr, pos)-d(ahr, neg)+\operatorname{margin}, 0)
%    \label{eq:triplet}
%  \end{equation*}

 
% \subsection{One-shot Id Association}\label{oneshot_id_ass}  
\subsection{Cross-Modality Association}\label{oneshot_id_ass}  

\begin{figure}
  \centering
  \begin{subfigure}[]{0.28\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/siamese}
    \label{fig:siamese_general}
  \end{subfigure}
  \hspace{0.45em}
  \begin{subfigure}[]{0.68\linewidth}
    %\centering
    \includegraphics[width=\linewidth]{figures/siamese_cnn}    
    \label{fig:siamese_cnn}    
  \end{subfigure}
  \vspace{-3em}
  \caption{Left: Siamese network using three identical CNNs with shared weights during training. Right: Architecture of CNN that extracts comparative feature from trace map.}
  \label{fig:siamese}
\end{figure}
 


% It is clear that if a  bipartite graph $G = (L, R, E)$ has a perfect matching, then it must have $\|L\| = \|R\|$. Furthermore, for a set of vertices $S \subseteq V$, we define its set of neighbors $\Gamma(S)$ by:

% $$
% \Gamma(S)=\{v \in V \mid \exists u \in S \text { s.t. }\{u, v\} \in E\} .
% $$

%Suppose that for every $ S \subseteq L$,  we have $|\Gamma(S)| \geq |S|$ ,then  $G$ has a perfect matching\cite{perfectMatching}. In the \textit{Heuristic Clustering}, the number of cluster $N_{clu}$ will be equal to the number of IMU $N_{IMU}$, which ensures that $\|L\| = \|R\|$. 
% After feeding each trajectory pair from mmWave cluster and IMU sensor to the Siamese network,

%This section presents the design to associate each radar cluster and each IMU exclusively.
For the $w^\text{th}$ time step in an association time window, 
% For the $w^\text{th}$ association time window, After acquiring the feature vector of trace map from different trajectories,
ImmTrack constructs a similarity matrix $\mat{S}_w \in \mathbb{R}^{N \times N}$, where its $(i,j)^\text{th}$ element is the cosine similarity between the comparative feature vectors extracted by the Siamese network from the trace maps of the $i^\text{th}$ radar cluster and $j^\text{th}$ IMU, respectively.
%of trajectories from the $i^{th}$  cluster of  mmWave and  the $j^{th}$ IMU.
% The range of $S_{(i,j)}$ is $[0,2]$, where the similar pair should result in a value between 0 to 1.
% We then solve the association problem in each window with matrix $S$ using Hungarian Algorithm, which works in polynomial time. 
% Then the remaining issue is choosing the most confident association result or  generate a final association result based on the result in each window.
%Rather than solving the association problem using only $\mat{S}$, we introduce a simple yet effective multi-window ensemble scheme.
% , which performs soft voting among $p$ consecutive windows to generate a final associating proposal.
ImmTrack generates an average similarity matrix, denoted by $\mat{S}$, over a total of $W$ consecutive association time windows, i.e., $\mat{S}=\frac{1}{W} \sum_{w=1}^{W}\mat{S}_w$. Hungarian algorithm is applied to propose an association between the radar clusters and IMUs. If the proposal is accepted, the IMUs' PIDs are transferred to the radar clusters for re-identification.
%We construct matrix $\hat{\mat{S}}$ by aggregating the matrices in $p$ consecutive windows: $\mat{\hat{S}} = \frac{1}{p} \cdot \sum_{1}^{p}  \mat{S_{w}}$, on which the Hungarian algorithm is applied for generating the final association proposal. 
\sect\ref{main_acc_result} will show via evaluation that the multi-window similarity averaging improves the robustness of the association, compared with using a single window only.
%, especially when the number of users increases.
%we will show that this ensemble scheme boosts the system performance, especially when the number of people is relatively large.
% Then we apply the Hungarian Algorithm on the $S_{final}$ to 
% generate the final association proposal.

In addition, ImmTrack applies two criteria to accept an association proposal. If either criterion is not met, ImmTrack excludes the oldest window from the $W$ windows, waits for a new window becoming available, and checks the two criteria again.
%we define two criteria for $\hat{\mat{S}}$ to ensure the final proposal is with a high confidence level. Only when both two criteria are satisfied will we adopt this proposal and associate the radar's cluster with the IMU ID. Otherwise, we remove the earliest window in $p$ windows that form $\hat{\mat{S}}$ and wait for the outcome of a new window.
The two criteria are as follows. {\bf Criterion~1:} For each pair of associated radar cluster and IMU, the similarity between their comparative features needs to be higher than a pre-defined threshold $\alpha$. This criterion sets a lower bound for the association quality.
The $\alpha$ can be set according to the data used to train the Siamese network by $\alpha = \max \{\min_{\forall (\vec{a}, \vec{p}) \in \mathcal{P} } S_c(\vec{a},\vec{p}), \max_{\forall (\vec{a}, \vec{n}) \in \mathcal{N}} S_c(\vec{a},\vec{n}) \}$, where $\mathcal{P}$ and $\mathcal{N}$ are the positive and negative pair sets, $S_c(\cdot, \cdot)$ denotes cosine similarity. Our training data gives $\alpha=0.23$.
%  If the Hungarian algorithm proposes that the $i^{th}$ cluster should pair with the $j^{th}$ IMU, then $\hat{\mat{S}}_{[i,j]} \geq \alpha$
{\bf Criterion~2:} Any IMU cannot produce the highest cosine similarity with two or more radar clusters among all IMUs. Formally, $\forall i \in [1, N]$, if the $(i,j)^\text{th}$ element of $\mat{S}$ (denoted by $\mat{S}_{i,j}$) is the maximum value within the $i^\text{th}$ row of $\mat{S}$, then $\nexists k \in [1,N]$ such that $\mat{S}_{k,j}$ is the maximum value within the $k^\text{th}$ row of $\mat{S}$. This criterion makes sure that the IMU most similar with every radar cluster is unique.

%Intuitively, the first criterion sets a lower confidence bound for the associated IMU and the radar's cluster. The second criterion makes sure the IMU with the highest similarity for every radar is distinct. 
% each IMU will be associated with the radar's cluster with the highest similarity rather than others.
%A pseudo-code of the whole procedure of ImmTrack is presented in Algorithm \ref{algo1}, where the multi-window based association is shown in line 10 to line 22.  

\begin{comment}
\begin{algorithm} 
	% \caption{One-Shot Matching \todo{May need to change the name; M to N} 
  \caption{Cross-Modality Matching \todo{double check the notations; discuss the name here}} 
	\begin{algorithmic}[1]
	    \State $N \leftarrow \text{number of imus, number of clusters }$
	    % \State $M \leftarrow \text{number of the radar's clusters}$
	    \State $IMUList,ClusterList \leftarrow [1,2,\ldots,N]$
	    % \State $ClusterList \leftarrow [1,2,\ldots,M]$
	    \State $\mat{\hat{S}} \leftarrow \mathcal{O} \in \mathbb{R}^{N \times N}$
        \State $ b \leftarrow 1$
		\For {$window:w=1,2,\ldots $} 
		    
    		\State $\mathcal{M}_{w}^{imu},\mathcal{M}_{w}^{mmWave}\leftarrow GenerateTraceMap(w)$
            %\Comment{T stands for trajectory}
    		\State $\mat{S_{w}}  \leftarrow Similarity(\mathcal{M}_{w}^{imu},\mathcal{M}_{w}^{mmWave})$ 
    		
    		\If{$b \le p $}
    		    \State $\mat{\hat{S}}\leftarrow \mat{\hat{S}} +  \mat{S_{w}}$
    		    \State $b \leftarrow b+1$
    		\EndIf
    		
    		\If{$b == p$}
    		\State $\mat{\hat{S}} \leftarrow Hungarian(\mat{\hat{S}})$
    		
    		
    		\If {\text{both two criteria satisfied}}
    		\State lock the id
            \Else
            \State $\mat{\hat{S}} \leftarrow \mat{\hat{S}} -  \hat{S_{w-p+1}}$
            \State $b \leftarrow b-1$
            
    		% \State $IMUList \leftarrow IMUList \setminus \text{matched IMU id } $
    		% \State $clusterList \leftarrow clusterList \setminus \text{Matched cluster id}$
    		\EndIf
    		
    		\EndIf
    		% \State Detect new IMU
		    
			
		\EndFor
	\end{algorithmic} 
  \label{algo1}
\end{algorithm}
\end{comment}


\subsection{Handling Users with Identical Trace Maps}
\label{boundary_case_macth}

Multiple users may generate nearly identical trace maps in certain cases, e.g., when they walk side by side or follow simple straight paths.
%This section describes the algorithm for associating the radar cluster and IMU 
% when the trajectory association is not suitable 
%when some of the users' trajectories are nearly identical in certain scenarios. 
% For instance, when two friends go out together, their trajectories may appear identical after conveied to trace maps.
Within a certain modality, such nearly identical trace maps can be detected by checking their pair-wise similarities.
%\yimin{We collect data from 6 users over 20 minutes, in which two of them walk side by side 10 times, 30 seconds at a time. ImmTrack sets the similarity threshold to 0.92. The detection rates of identifying the users walking together are  92.5\% and 77.5\% by using  mmWave radar and IMU respectively.}
\yimin{Based on a dataset collected from six human subjects in controlled experiments with pairs of human subjects walking side by side, the detection rates of identifying the side-by-side walk are 92.5\% and 77.5\% using mmWave radar data and IMU data, respectively, by adopting a threshold of 0.92 on the normalized similarity for the detection. After removing the entries of the $\mat{S}_w$ corresponding to the detected identical trace maps, the remaining entries are processed by the cross-modality association presented in \sect\ref{oneshot_id_ass}.} This section presents a separate cross-modality association approach for the nearly identical trace maps based on gait analysis. \yimin{ImmTrack initializes the gait analysis if it detects users with nearly identical trace maps from the mmWave radar.} The gait analysis for an mmWave cluster is as follows. First, we compute the measured spectrogram $\mat{X}_m(v_k, t_l)$ from the Doppler Fourier transform corresponding to the points belonging to the cluster, where $v_k$ and $t_l$ represent the velocity and time bins, respectively. Second, we use the Boulic model \cite{boulic1990global} to generate the simulated spectrogram $\mat{X}_s(v_k, t_k | f_c, l_c, \varphi_c)$, where the parameters $f_c$, $l_c$, and $\varphi_c$ are the specified step frequency, step length, and start phase, respectively. \yimin{By solving $
\mathop{\arg\min}_{f_c, l_c, \varphi_c}
\sum_{\forall v_k, t_l} \left\| \mat{X}_{\mathrm{m}}^{\log }\left(v_k, t_l\right) 
- \mat{X}_{\mathrm{s}}^{\log }\left(v_k, t_l | f_c, l_c, \varphi_c \right) \right\|_{\ell_2}^2
$, where the superscript ``log'' means element-wise log normalization, the gait feature $(f_c, l_c)$  is estimated from mmWave radar data.}
For IMU data, we employ the IMU-based gait analysis \cite{madgwick2011Imutrack} to estimate the gait feature $(f_c, l_c)$. Lastly, Hungarian algorithm is applied to associate the mmWave clusters and IMU traces that respectively produce nearly identical trace maps, in terms of the cosine similarity between the mmWave-based and IMU-based gait features. The effectiveness of the mechanism presented in this section will be evaluated in \sect\ref{eval_tiny_space}.

%Different body parts of a walking person induce varied Doppler signatures in mmWave radar sensing: the torso induces a Doppler signature with constant velocity, while other parts induce sideband Doppler signatures on both sides of the torso \cite{chen2006micro}.
%We utilize the micro-doppler effect to conduct the human gait analysis based on the mmWave radar. Specifically, different body parts induce varied Doppler signatures.
%The torso of a walking human induces a Doppler signature with constant velocity and Radar Cross Section (RCS) while the other human components induce sideband Doppler signatures on both sides of the torso \cite{chen2006micro}. 

\begin{comment}
The overview of the mmWave radar based gait analysis is that we first construct the measured spectrogram $\mat{X_{m}}$ from the Dopple FFT result, in which the x-axis is the time bins and the y-axis represents the velocity bins.
Here we use $\mat{X_{m}}(v_{k}, t_{l})$ to represent amplitude at time bins index $t_{l}$  and velocity bins index $v_{k}$. 
At the same time, we use the Boulic model \cite{boulic1990global} to simulate the walking motion of a certain user as a function of time.  As a result, we derive a simulated spectrogram $\mat{X_{s}}$
The Boulic model utilizes three parameters namely step frequency $f^c$, step length $l^c$, and start phase $ \varphi^c$ to simulate the walking motion. 
A fit function is chosen to calculate the difference between $\mat{X_{m}}$ and $\mat{X_{s}}$
as  a function of the parameters of the walking model. By minimizing the difference as a function of the parameters of the walking
model, the values of $f^c$,  $l^c$, $ \varphi^c$  for the best fit is found.

Formally, $\mat{X_{s}}$ is calcuated in function $\mat{X_{s}}(v_k, t_l, f^c, l^c, \varphi^c, a_{\log }, n_{\log })$, where $a_{Log}$ and $n_{log}$ are two constants in the model, and their estimations are mentioned in \cite{chen2006micro}, which is out of the scope of our system. 
We choose the scaled version of spectral distortion function (SD) \todo{cite} as the fit function and derive gait parameter $(f^c, l^c, \varphi^c)$ from the optimization problem below using Powell's method\todo{cite} with starting value discribed in \todo{cite}. 


$$
\begin{aligned}
% \chi^2\left(f^c, l^c, \varphi^c \right)=
\mathop{\arg\min}_{(f^c, l^c, \varphi^c)}
\sum_{\text {all } v_k, t_l} \mid  \mat{X}_{\mathrm{m}}^{\log }\left(v_k, t_l\right) 
- \left.\mat{X}_{\mathrm{s}}^{\log }\left(v_k, t_l, f^c, l^c, \varphi^c, a_{\log }, n_{\log }\right)|^2\right.
\end{aligned}
$$

% Given the measured spectrogram $X_{m}(v_{k}, t_{l})$, the goal is to minimize the difference between the measured data and the estimated data. We first normalize $X_{m}(v_k, t_l)$ to
% $ \mathbf{X}_{\mathbf{m}}^{\log }\left(v_k, t_l\right)$:
% $$
%  \mathbf{X}_{\mathbf{m}}^{\log }\left(v_k, t_l\right)= \frac{\log \left(\mathbf{X}_{\mathbf{m}}\left(v_k, t_l\right)\right)}{\sqrt{\sum_{a l l} v_k, t_l} \log \left(\mathbf{X}_{\mathbf{m}}\left(v_k, t_l\right)^2\right)}
% $$

\end{comment}


%The estimation of step information from the IMU is well-studied \textcolor{red}{[citation]}. The cosine similarity between the gait information vextor  $\vec{(f^c, l^c)}$ extracted from the mmWave radar and IMU is calculated, which is further used for cross-modality association in the case. 

%In summary, the association module works in a hierarchical manner. The gait analysis pipeline will be only invoked after ImmTrack detects certain users' trace map are nearly identical.


