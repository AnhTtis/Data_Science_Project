% !TEX root = main.tex
\subsection{Training and Efficacy of mmClusterNet}\label{compare_down_task}

%%%%%%%%%%%%%%%%%%%%%%%%%%
% double column format
%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{table}
%   \caption{Summary of downstream tasks and loss functions.}
%   \label{tab:summary_ds_task}
%   \vspace{-1em}
%   %\resizebox{\linewidth}{!}{
%     \begin{tabular}{|c|c|c|c|c|}
%       \hline
%       \textbf{Model} & \textbf{Input} & \textbf{Training} & \textbf{Downstream} & \textbf{Loss} \\
%                  &    & \textbf{dataset} & \textbf{task} & \textbf{function} \\ \hline
%       \multirow{3}{*}{\rotatebox{90}{mmClusterNet}} & \multirow{3}{*}{\rotatebox{90}{\begin{tabular}[c]{@{}c@{}}Point cloud\\with velocity\end{tabular}}} & \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Self-\\collected\end{tabular}} & \begin{tabular}[c]{@{}c@{}}Point cloud\\ completion\end{tabular}                & \begin{tabular}[c]{@{}c@{}}Chamber\\distance \cite{fan2017point}\end{tabular}                                                                 \\ \cline{4-5} 
%                      &  &                                                                          & \begin{tabular}[c]{@{}c@{}}Bounding box \\ regression\end{tabular}               & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Intersection\\ over union \\ (IoU) \end{tabular}} \\ \cline{4-4}
%                      &  &                                                                          & \begin{tabular}[c]{@{}c@{}}Next-frame \\ bounding box\\ regression\end{tabular} &                                                                                    \\ \hline
%       \multirow{2}{*}{\rotatebox{90}{PointNet}}                                              &  \multirow{2}{*}{\rotatebox{90}{\begin{tabular}[c]{@{}c@{}}Point cloud\\w/o velocity\end{tabular}}} & \multirow{2}{*}{ShapeNet}                                                  & \begin{tabular}[c]{@{}c@{}}Object\\ classification\end{tabular}                 & \begin{tabular}[c]{@{}c@{}}Negative log\\ likelihood \end{tabular}                  \\ \cline{4-5} 
%                      &    &                                                                        & \begin{tabular}[c]{@{}c@{}}Point cloud\\ completion\end{tabular}                & \begin{tabular}[c]{@{}c@{}}Chamber\\distance \\ \cite{fan2017point}\end{tabular}                                                            \\ \hline      
%     \end{tabular}
%   %}
%   \end{table}

  \begin{table}
  \caption{Summary of training datasets \& downstream tasks.}
  \label{tab:summary_ds_task}
  \vspace{-1em}
  %\resizebox{\linewidth}{!}{
    \begin{tabular}{|c|c|c|c|}
      \hline
      \textbf{Model} & \textbf{Input} & \textbf{Training} & \textbf{Downstream} \\
                 &    & \textbf{dataset} & \textbf{task} \\ \hline
      \multirow{3}{*}{mmClusterNet} & \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Point cloud\\with velocity\end{tabular}} & \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Self-\\collected\end{tabular}} & PC                                                                               \\ \cline{4-4} 
                     &  &                                                                          & BBR                \\ \cline{4-4}
                     &  &                                                                          & NBBR                                                                                   \\ \hline
      \multirow{2}{*}{PointNet}                                              &  \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Point cloud\\w/o velocity\end{tabular}} & \multirow{2}{*}{ShapeNet}                                                  & OC                                    \\ \cline{4-4} 
                     &    &                                                                        & PC                                                                           \\ \hline      
    \end{tabular}
  %}
\end{table}

The MLPs used by mmClusterNet to extract the shape-motion feature of a point cloud cluster needs to be trained before use. The training requires a downstream task that utilizes the shape-motion feature. This set of experiments evaluates the impact of various downstream tasks on the training of mmClusterNet. We also compare the cluster tracking feature extracted by mmClusterNet and the feature extracted by PointNet \cite{pointnet}, a widely adopted point cloud feature extractor. PointNet takes a point cloud without velocity as input and also needs a downstream task to drive training.

% We consider three well-known downstream tasks: {\em Object classification (OC)}, {\em Point cloud completion (PCC)}, {\em Bounding box regression (BBR)}.
%Here, we investigate the influence of different downstream tasks on the performance of the mmClusterNet.





% %A summary of the used models, downstream tasks and loss functions are presented in Table \ref{tab:summary_ds_task}.
% We consider four downstream tasks:

% \noindent $\blacksquare$ {\em Object classification (OC)} classifies the point cloud based on the given feature into an object type.
% %(e.g., chair, ball, etc).

% \noindent $\blacksquare$ {\em Point cloud completion (PCC)} reconstructs the point cloud based on the feature extracted from an incomplete point cloud. It enforces learning spatial relation among the points.

% \noindent $\blacksquare$ {\em Bounding box regression (BBR)} produces a 2D bounding box containing the 3D point cloud's projection onto the floor plane. As it is a task customized for human tracking, the 2D bounding box also has a property of orientation in the 2D space, which should be consistent with the human orientation.

% \noindent $\blacksquare$ {\em Next-frame bounding box regression (NBBR)} predicts the 2D bounding box with orientation in the next frame based on the feature extracted from the current frame.

%which requires the model to estimate the location of the 2D bounding box at time $t$ given the data at time $t-1$.
%The object classification require's the overall shape feature, while point cloud completion focuses learning the inter-point relationship.
%The bounding box regression requires both the shape and motion characteristics.
% For the first two tasks, we use PointNet \cite{fan2017point} trained under a subset of ShapeNet dataset \cite{chang2015shapenet} as the baseline, where PointNet is a state-of-the-art point cloud processing neural network, and ShapeNet is a public 3D model repository that includes a large amount of 3D point cloud data for different classified objects.

%To train mmClusterNet, we use our own data collected by the AWR1843 mmWave radar. We skip the OC task for mmClusterNet because our dataset only contains one object type (i.e., human).

% Notably, we do not evaluate the task of object classification on our collected dataset, as it only includes one category (i.e., human). 
% To handle the sparsity of radar point cloud in our dataset, we perform point augmentation by sampling 1024 points uniformly on the original one and jitter the position of each point using a Gaussian noise with zero mean and 0.05 standard deviation.

%To train PointNet, we use ShapeNet \cite{chang2015shapenet}, a public large-scale 3D point cloud database of many classified objects. Note that as ShapeNet does not contain velocity information, it cannot be used to train mmClusterNet. For PointNet, we skip the BBR and NBBR tasks, because the bounding box orientation requires velocity information. Our small-scale self-collected dataset is ill-suited for training PointNet, because PointNet's scale requires larger datasets.

%We use NLL loss for object classification and IoU loss for bounding box regression, which are both standard choices for the corresponding task. For point cloud completion, we use the Chamfer Distance (CD) \cite{fan2017point} as the loss function. For each point in each cloud, CD finds the nearest point in the other point cloud, and sums the square of distance up:

% \begin{equation*}
%     C D\left(S_{1}, S_{2}\right)= \frac{1}{\left|S_{1}\right|} \sum_{x \in S_{1}} \min _{y \in S_{2}}\|x-y\|_{2} 
% +\frac{1}{\left|S_{2}\right|} \sum_{y \in S_{2}} \min _{x \in S_{1}}\|y-x\|_{2}
% \end{equation*}

% \noindent where $S_1$ and $S_2$ are the completed point cloud and the ground truth point cloud, respectively.
% % In the evaluation part, we let  users walk on the pre-defined trajectories and we let them swap the trajectories  each round for 3 rounds. 

%After mmClusterNet and PointNet are trained, we use them to extract features and the Hungarian algorithm to track clusters, as presented in Section~\ref{subsubsec:cluster-tracking}. 
Table~\ref{tab:summary_ds_task} summarizes the input data, training datasets, and downstream tasks used to train mmClusterNet and PointNet. Beside the widely adopted point cloud completion (PC), bounding box regression (BBR), and object classification (OC) tasks, we devise a new task called {\em next-frame bounding box regression} (NBBR), which predicts the 2D bounding box with orientation in the next frame based on the feature extracted from the current frame. The loss functions used by the downstream tasks are as follows: PC uses chamber distance \cite{fan2017point}; BBR and NBBR use intersection over union (IoU); OC uses negative log likelihood.
We employ the multiple object tracking error (MOTE) and ratio of mismatches (RoM)
%over a total of $J$ consecutive frames
to jointly measure the inter-frame cluster tracking performance.
A mismatch refers to the case that a cluster is associated with another cluster in the previous frame that corresponds to a different user. 
%  Formally, $\mathrm{MOTE} = \frac{\sum_{j=1}^J\sum_{i=1}^N e_{i,j}}{J \cdot N}$ and $\mathrm{RoM} = \frac{\sum_{j=1}^J \mathrm{NoM}_j}{J \cdot N}$, where $e_{i,j}$ is the distance between the estimated position and the true position of the $i^\text{th}$ user in the $j^\text{th}$ frame, $\mathrm{NoM}_j$ is the number of mismatches in the $j^\text{th}$ frame.


%Since there is no proper metric to directly evaluate the quality of generated feature vectors, we use the performance of the  tracking instead. Specifically, we introduce two metrics. 
%The first one is multiple object tracking precision (MOTP), which is the total error between estimated positions and real positions over all frames, averaged by the total number of objects over all frames. It mainly focuses on the precision of object tracking. %and is independent of the capability of sensors at recognizing object. 
%The second metric is ratio of mismatches (mme) over all frames. 
%The mismatch refers to the case that a cluster is associated with a previous cluster belongs to a different person.
% The definition of these two metrics are:
%$$
%\mathrm{MOTP}=\frac{\sum_{i, t} d_{t}^{i}}{\sum_{t} N_{t}},\hspace{1cm} \overline{m m e}=\frac{\sum_{t} \#\text{mme}_{t}}{\sum_{t} N_{t}}
%$$
%Here, $N_{t}$ is the number of objects at time $t$. $d_{t}^{i}$ is the distance between the estimated position and the real position for object $i$ at time $t$.

  

%The mean errors are eror stays under 40cm while the interpersonal distance increases, which guarantees the system's performance in a large range.
\begin{figure}
  \begin{minipage}{0.21\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/down_stream_task}
  \vspace{-2em}
  \caption{Multi-object tracking error of inter-frame cluster tracking.}
  \label{fig:motp}
\end{minipage}%
\hfill
\begin{minipage}{0.23\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/mismatch}
  \vspace{-2em}
  \caption{Ratio of mismatches during inter-frame cluster tracking.}
  \label{fig:mismatch}
\end{minipage}%
\vspace{-1em}
\end{figure}


% \noindent \textbf{Result.}

The results in Figs.~\ref{fig:motp} and \ref{fig:mismatch} show that: (1) mmClusterNet outperforms the off-the-shelf PointNet in achieving inter-cluster tracking; (2) BBR is an appropriate downstream task for training mmClusterNet.
%Fig.~\ref{fig:motp} and \ref{fig:mismatch} shows the MOTE and RoM of mmClusterNet and PointNet trained with various downstream tasks. The mmClusterNet achieves the best performance and also then in terms of the two metrics when it is trained with BBR, which is chosen as the downstream task in ImmTrack. 
BBR enforces the model to simultaneously capture cluster contour and enforces utilization of the velocity information of the shape-motion feature. Thus, BBR helps mmClusterNet better learn the shape-motion feature. On the contrary, NBBR leads to poor tracking performance. A possible reason is that NBBR overstretches the utilization of velocity information. ImmTrack evaluated in other sections adopts the mmClusterNet trained with BBR.

%Different from OC that focuses on cluster shape and PCC that focuses on the spatial relations among the points of a cluster, BBR simultaneously captures cluster contour and enforces utilization of the velocity information of the shape-motion feature. Thus, BBR helps mmClusterNet better learn the shape-motion feature.
%oint cloud completion and object classification, the bounding box regression finds a good balance between the precise position of each point and shape of the whole point cloud. 
%We also observe that NBBR leads to poor tracking performance. A possible reason is that NBBR overstretches the utilization of velocity information.
%that forcing the neural network to automatically learn the bounding box position in the next frame can result in poor tracking performance.
%More complex model structure such as deep affinity network (DAN) can be deployed to directly learn the inter-frame cluster association in the future.
%Compared with the mmClusterNet trained with BBR, the PointNet trained with either OC or PCC achieves inferior tracking performance. This is because the shape-motion feature extracted by mmClusterNet provides more information than the shape feature extracted by PointNet.



% Moreover, directly applying the PointNet trained under ShapeNet does not work well, although PointNet is much larger than our proposed PointTrack Net and ShapeNet is also much larger than our collected dataset. This is because radar point cloud is noisy and sparse, which is significantly different from fine-grained one in ShapeNet.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End: