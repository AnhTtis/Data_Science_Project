% !TEX root = main.tex
\section{Overview of ImmTrack}%And System Overview}
\label{sec:problem}

\subsection{Problem Description and Challenges}
\label{subsec:challenges}

We consider an enclosed space that requires extra attention to interpersonal distances, due to say the risk of airborne transmissions of pathogens via respiratory droplets. One or more mmWave radars are deployed to fully cover the space such that any human subject therein can be sensed by the radar(s). The objective of ImmTrack is to track the interpersonal distances among the users in the space. The tracking results can be sent back to the users and/or fed into downstream applications (e.g., contact tracing). When a user is about to enter the space, the user needs to enrol in ImmTrack, e.g., by quick response (QR) code scanning.
%In practice, an enrolment QR code can be placed at the entrance of the monitored space.
Certain user PID generation scheme can be used for ImmTrack, depending on the detailed privacy policy. For instance, the ImmTrack mobile app may generate a universally unique identifier (UUID) that takes effect throughout the lifetime of the app and is used as the PID across all ImmTrack-instrumented spaces; or the app may communicate with the ImmTrack server to generate a temporary PID that is unique in the enrolled space. The design of ImmTrack is agnostic to the PID generation scheme. When the user is in the ImmTrack-instrumented space, the ImmTrack mobile app runs in the background and collects IMU data. When the user exits the monitored space, the user needs to sign out. Thus, ImmTrack works in a nearly unobtrusive manner, except the little overhead of signing in and out incurred to the user. Such little overhead is acceptable for specific spaces that require close interpersonal distance monitoring.

%The participation model is as follows. When a user is about to enter the monitored space, if the user wishes to receive the tracking results and agrees to render IMU data, the user can enrol in ImmTrack. In practice, an enrolment QR code can be placed at the entrance of the monitored space. Upon enrollment, ImmTrack assigns the user an integer PID. The PID is piggybacked to the user's IMU data submissions. We define three types of persons: (1) a {\bf \em participant} is an enrolee who is in the monitored space; (2) a {\bf \em passenger} is a non-enrolee who is in the monitored space; (3) a {\bf \em roamer} is an enrolee who is out of the monitored space. Note that when an enrolee does not explicitly sign out when exiting the monitored space, the enrolee becomes a roamer. The presentation of this paper focuses on a time period, during which there are $N_p$ participants and $N_q$ passengers in the monitored space.
%, where $N_p \ge 1$ and $N_q \ge 0$.
The presentation of this paper focuses on a given time period, during which there are $N$ users in the monitored space. Due to the mandatory enrolment, the value of $N$, although may vary with time, is known by the system at all times.
To simplify exposition, the design presentation of ImmTrack focuses on the case that a single mmWave radar is deployed.
When a single radar is insufficient to cover the entire space, multiple radars can be deployed. The existing planning algorithms to minimize the number of cameras while achieving visual coverage \cite{he2015full,huang2013connected} can be applied to plan the radars' deployment.
\sect\ref{subsec:multi-radar} and \sect\ref{eval_tiny_space} will present the details of merging the point clouds from multiple radars and the evaluation of multi-radar ImmTrack, respectively. Although the deployment of radar(s) involves a cost, it enables the demanded close interpersonal distance monitoring. Moreover, it is a one-time cost that brings sustained benefits to the users' health and safety.
% When  multiple radars can be deployed to fully cover the space and their output point clouds can be combined as in \cite{bansal2020pointillism} to form a single point cloud. Note that the existing camera placement algorithms (e.g., \cite{gonzalez2009optimal}) can be used to determine the locations and orientations of radars for full or maximized spatial coverage. In a set of experiments presented in Section~\ref{sec:eval}, we will combine the point clouds from two radars.

The design of ImmTrack faces the following two main challenges.

First, robust tracking of multiple users with mmWave radar is challenging. Reflections from unrelated objects may cause excessive noise points in the radar's output point cloud. Moreover, as mmWave reflections are mostly specular, the radar's point clouds are generally sparse. As such, the state-of-the-art object detection and tracking algorithms developed for processing dense point clouds yielded by high-profile lidars are ill-suited for mmWave radars.
%Unlike Lidar, whose output point cloud is dense and informative, the point cloud from the mmWave radar is quiet noisy. Thus, state-of-the-art detection or tracking algorithms using Lidar point cloud are not applicable to the mmWave radar.
% Although tracking with Lidar is well-studied, lidar is known for its high resolution, which means each data frame from the lidar consists of a large number of points and can form a dense point cloud. Thus the tracking systems which utilize lidar focus on segmenting and extracting region of interest. Compared to lidar, the point cloud generating from mmWave is sparse, which makes it difficult to directly transfer the state-of-art tracking system to mmWave radar.
The mmWave-based multi-user tracking also needs to deal with the users' close encounters and crossings in FoV. The DBSCAN algorithm that is widely adopted for point cloud clustering often mistakenly merges multiple users in proximity into a single cluster. As such, the clustering accuracy decreases drastically with the number of people (45\% \cite{livshitz2017tracking} and 65\% \cite{huang2021indoor} for five people). To address this issue, the clustering algorithm should maintain and incorporate the understanding of all users' movements.
%Recent works have applied beam forming techniques \cite{wu2020mmtrack} and Kalman filter \cite{huang2021indoor} to improve mmWave-based human tracking.
%focus on either designing new beam-forming techniques \cite{wu2020mmtrack} or robust variations on Kalman filter \cite{huang2021indoor}. 
% Although these works demonstrate improvement on the tracking accuracy,
%However, their performance is unsatisfactory when the number of people is greater than three.
% equal or more than 3 people even for people's counting problem. 
% We will demonstrate that by adopting the sensor fusion approach, the problem can be simplified and a robust tracking algorithm can be designed.

Second, robust cross-modality association of the mmWave and IMU tracking results is non-trivial. The two modalities differ in the following two aspects. First, their sensing results are in different coordinate systems. Second, they capture different aspects of the user's movement. The mmWave radar captures the user torso location and velocity with lower frame rates, while the IMU captures the acceleration and angular speed of the user limb with higher frame rates. To achieve robust association, a common feature of the user's movement needs to be derived from both the mmWave data and IMU data. Moreover, the association algorithm needs to accommodate each modality's error in deriving the common feature.


%To design a robust Radar-IMU association system, we first need to overcome the challenges in mmWave radar tracking and then the challenges in associating
%the cross modalities sensors.


%\noindent \textbf{Mapping the global view with the individual view} The mmWave captures the movement of all the people in the field of view, which gives us limited information about each individual. However, the imu caputures the movement of a single body part, which is independent from others'  movement. Assume we can rely on the robust radar tracking module to seperate the individual information from the global view, we still need to overcome the challenges introduced by different coordinate systems and sources of noise.

%The mmWave captures the movement of all the people in the field of views, which gives us limited information about each individual. However, the imu caputures the movement of a single body part, which is unrelated to others'  movement.

%Scattering effect of radar electromagnetic wave is negligible, resulting in an sparse point cloud from mmWave. On the contrary, the imu works in high sampling rate, which generates dense data in a short time.


% In order to associate the Specifically, three challenges 
 


% 1. radar全局视角，imu局部视角；
% radar躯干，imu可以放在四肢，口袋，胸前，数据有domain gap；
% radar 是 point cloud主要indicate occupancy, imu是时序数据，主要展示运动
 
% 2. 基于以上挑战，我们运用轨迹，但radar点云 sparse noisy，不能区分离得很近的两个人，导致不能有效tracking；IMU的tracking也会存在积分误差，导致两个modality生成的轨迹差很远，

% and magnetometer.
% Our system utilizes a 3D mmWave to capture the global information, including the location and radial velocity of each person. 
% every line-of-sight person's location, velocity. 
% And each person wear an Imu to capture the each individual's limb movements, including the data comes directly from gyroscope, accelerometer and magnetometer.  
% To address the above problem, we first design a \textit{joint tracking} pipeline to track the trajectories of all the users in the field of view of mmWave radar. In the same time, the system also tracks each individual's trajectory solely based on the Imu sensor. And then design an \textit{trajectory based matching} pipeline to fuse the data provided by the two sensors based on the generated trajectories.

% The proposed modules further divide the challenges into the following smaller challenges.




% \noindent
% \textbf{How to take advantage of the information from two highly heterogeneous modalities?} 
% % \textbf{Aggregate the cross-modalities information provided by mmWave and Imu } 
% \todo{Change the name} 
% Radars and IMUs are two modalities that differ greatly, in which radars provide occupancy and velocity information of a group of people in a global view, while IMUs mainly capture the movement of the individual's limb that wears it using measurements from the gyroscope and the accelerometer. 
% As a result, these two sensors show huge differences in terms of the output data format, magnitude, field of view, coordinate and even the feature of the object depicted by the data, making it extremely difficult to fuse or associate the sensing results from them. 

% \noindent
% \textbf{How to perform the cross-modality matching when the domain gap between two modalities is large?}
% % \textbf{Handle the differences in the outcome from tracking system in Imu and mmWave}
% \todo{add a graph to compare the difference of the outcome of the IMU tracking and mmwave tracking}
% Although the tracking using merely IMUs or radars has been widely studied, due to either integral drift or noise, two modalities are not likely to generate the absolutely precise and identical trajectories for the same person. 
% This puts forwards a stringent requirement on the robustness and reliability to the cross-modality association module. 
% % The difference between the tracking results from the two sensors brings more uncertainties to the \textit{trajectory based matching}. In the matching process, it should find the correct matching even if the two trajectories are not identical. 



\begin{comment}
\subsection{Main Challenges} \label{challenges}

In order to design a robust Radar-IMU association system, we need to overcome the challenges in both mmWave radar tracking and cross-modality association module. 

\noindent \textbf{Robust Tracking with mmWave Radars.} 
% The wavelength of the radar signal determines that most of the reflections are specular, which results in a sparse point cloud. 
% We design a tracking system that leveraging the IMU information and motion model to enrich the available information. Hence, we design a 
% deep model to fully extract the embedded information from the point cloud. 
Due to the low angular resolution and the specular reflection of RF signals, the point cloud from mmWave radars is usually noisy and sparse. As a result, state-of-the-art point cloud detection or tracking algorithms \todo{cite} using high-end Lidars are not applicable.  
Recent works on designing new beam-forming techniques \cite{wu2020mmtrack} or exploring new variations on Kalman filter \cite{huang2021indoor} are also unsatisfactory when the number of people is greater than three. 
To address this challenge, we propose an IMU-assist mmWave tracking, where the IMU information is utilized in both the point cloud clustering and the cluster association step.  
First, in point cloud clustering, we take the total number of IMUs as a prior knowledge, and use a Kalman Filter to maintain the initial centroids of the cluster to realize motion-aware clustering. 
Second, in inter-frame association, we design a specific neural network called \textit{mmClusterNet} to extract the shape features of point cloud and then fuse them with the motion features from IMUs to provide for robust association.

\noindent \textbf{Mapping between Two Highly Heterogeneous Modalities.} 
% The mmWave captures the movement of all the people in the field of view, 
% which gives us limited information about each individual. However, the imu caputures the movement of a single body part, which is independent from others'  movement. 
% Assume we can rely on the robust radar tracking 
% module to seperate the individual information from the global view, we still need to overcome the challenges introduced by different coordinate systems and sources of noise. 
% We design a trace map generation algorithm to overcome the influence of noise and then we utilize the Siamese Network to refrain the problem of searching the coordinate transfrom matrix in a large searching space.
Radars and IMUs are two modalities that differ greatly, in which radars indicate the occupancy and movement of a group of people in a global view, while IMUs mainly capture the movement of a certain body part wearing the IMU. 
These two sensors also show huge differences in terms of the output data format, magnitude, and coordinate. As a result, the radar and IMU are not likely to generate the absolutely precise and identical trajectories for the same person. This puts forwards a high requirement on the robustness of the cross-modality association module. To address this challenge, we first embed the information of two sensors into a uniform representation, called trace map. Then we devise a Siamese network to extract comparative features of a pair of trace maps, whose cosine distance will be used as similarity metric for association.









=======
%\noindent
%\textbf{How to take advantage of the information from two highly heterogeneous modalities?} 
% \textbf{Aggregate the cross-modalities information provided by mmWave and Imu } 
%Radars and IMUs are two modalities that differ greatly, in which radars provide occupancy and velocity information of a group of people in a global view, while IMUs mainly capture the movement of the individual's limb that wears it using measurements from the gyroscope and the accelerometer. As a result, these two sensors show huge differences in terms of the output data format, magnitude, field of view, coordinate and even the feature of the object depicted by the data, making it extremely difficult to fuse or associate the sensing results from them. 

%\noindent
%\textbf{How to perform the cross-modality matching when the domain gap between two modalities is large?}
% \textbf{Handle the differences in the outcome from tracking system in Imu and mmWave}
%\todo{add a graph to compare the difference of the outcome of the IMU tracking and mmwave tracking}
%Although the tracking using merely IMUs or radars has been widely studied, due to either integral drift or noise, two modalities are not likely to generate the absolutely precise and identical trajectories for the same person. This puts forwards a stringent requirement on the robustness and reliability to the cross-modality association module. 
% The difference between the tracking results from the two sensors brings more uncertainties to the \textit{trajectory based matching}. In the matching process, it should find the correct matching even if the two trajectories are not identical. 

\end{comment}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End: