% !TEX root = main.tex
\subsection{System Overview}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/overall}
    \vspace{-2em}
  \caption{Overview of ImmTrack. It processes data from one or more mmWave radars and users' IMUs with two components: {\em IMU-assisted mmWave tracking} and {\em learning-based cross-modality trajectory association}. The association results are fed to downstream applications.}
    \label{fig:structure}
    \vspace{-1em}
\end{figure}

Fig.~\ref{fig:structure} overviews the design of ImmTrack. It consists of two components to address the above two challenges.

{\bf IMU-assisted mmWave tracking:} This component consists of three steps. First, it clusters the points in each frame's point cloud into human bodies and associates the clusters corresponding to the same user across frames. ImmTrack maintains a recurive Kalman filter \cite{feng2014kalman} to track each user's movement and uses its predicted user location as the initial centroid of the user's cluster for the clustering algorithm. This motion-aware clustering remains robust when the users encounter each other. \yimin{Compared with the simplistic mmWave-based target tracking techniques such as that included in the radar vendor's application note \cite{livshitz2017tracking}, our algorithm avoids using heuristic object detectors such as constant false alarm rate (CFAR) detector, which easily result in detection errors.} Second, to perform the cross-frame cluster association for user tracking, a deep neural network called mmClusterNet extracts the feature of each cluster produced by the clustering algorithm. The feature incorporates the shape and motion information of the point cluster, as well as the PID of a pre-matched IMU in terms of movement velocity. \yimin{Such multidimensional information improves the robustness of the cross-frame cluster association.}
%While the pre-matching may be erroneous, our evaluation shows that its benefit in assisting managing radar's inherently noisy sensing outweighs the impact of pre-matching errors.
Third, the Hungarian algorithm associates the clusters across frames in terms of their features extracted by the mmClusterNet to achieve multi-user tracking. The details are presented in \sect\ref{sec:global-tracking-design}.

{\bf Learning-based cross-modality trajectory association:} ImmTrack adopts the trajectory incorporated with velocity information as the common feature of the user's movement sensed by mmWave radar and IMU. Reasons are two-fold. First, velocity-incorporated trajectory is high-level information that summarizes the user movement and generally remains consistent between the two modalities. Second, trajectory includes both temporal and spatial information. With the temporal continuity embedded in adjacent frames, the noise flickering in single frame can be largely suppressed. After the users' trajectories are reconstructed from the mmWave and IMU tracking, ImmTrack computes an imagery representation of each trajectory, which is called {\em trace map}. Then, ImmTrack applies a Siamese neural network \cite{facenet} with convolutional layers to extract comparative features from the trace maps, which are insensitive to the relative relationship between the radar's global coordinate system and the IMU's local coordinate system.
%To address the second challenge, we design a trace map generation algorithm to overcome the influence of noise and then we utilize the Siamese Network to refrain the problem of searching the coordinate transfrom matrix in a large searching space.
Finally, a bipartite graph matching algorithm associates the mmWave and IMU tracking results in terms of the cosine similarity among the comparative features. For users with nearly identical trace maps due to say side-by-side walks or simple straight walks, gait analysis will be performed on the involved mmWave clusters and IMU traces to generate gait features for mmWave-IMU association. The details are presented in \sect\ref{subsec:association}.

Note that except the IMU trace map generation running on each user's smartphone, all other processing tasks of ImmTrack run on an edge server or a cloud server. The smartphone transmits the periodically generated trace maps to the ImmTrack server.

%combined with soft-voting scheme, the trajectory-based matching module performs associations between the Track ID and People ID (i.e., IMU ID), based on which the distance tracking and social tracking records of participants are revealed.

%It mainly consists of three modules: imu-assisted mmWave radar tracking, imu tracking and learning based cross-modality trajectory association 
%The imu-assisted tracking module is carefully designed to generate trajectories of multiple participants in a global view using the sparse mmWave radar point cloud. We embed the motion model and leverage the cross-modality information from the imu to assist the radar tracking process


%To address the first challenge, we design a tracking system that leveraging the IMU information and motion model to enrich the available information. Hence, we design a deep model to fully extract the embedded information from the point cloud.

%In ImmTrack, we take advantage of the IMU information within the radar-based tracking, greatly improves the robustness of the system while keeping the algorithm very lightwight.



%We overcome the above challenges by designing a mmWave tracking system with the help of data fusion, which can works on multiple people in long distance druing long period. Note that previous work on RF signal tracking mainly focuses  either on individual body motion tracking\cite{wu2020fingerdraw} or multiple people mootion capture in a short period\cite{wu2020mmtrack}. Then we utilize the contrastive learning approach\cite{khosla2020supervised-contra} to build a robust association scheme.

%As introduced in Section \ref{challenges}, we aim to associate two modality sensors that differs in the sensing scope (global vs individual). In our ImmTrack system, we first design an motion-aware intra-frame clustering algorithm to seperate each individual from the global view. In particular, the output of mmWave radars are 3D points which mainly show the occupancy and the radial movement of people's torso in the global coordinate, while IMU measurements present angular speed and acceleration of a certain human body part where the IMU is worn, and are in a local coordinate. 



%We validate that this additional information is very critical for robust and high-performance global tracking, as the mmWave radar point cloud is usually noisy and sparse, thus may not informative enough to keep tracking on the same person over long period The IMU tracking module estimates the trajectory of every participant that hold an IMU via double integration on the acceleration.

% {\em ImmTrack} system deploys mmWave radar to capture the global view of multiple users and the goal is to identify the ID of the clusters appeared in the mmWave point cloud by associating the clusters with the IMU sensors each user holds. 
% Therefore, we associate the cluster and IMU based on the trajectory of the cluster and the trajectory the IMU generates.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End: