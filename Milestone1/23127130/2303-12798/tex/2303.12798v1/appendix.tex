
More specifically, a JSON file is needed in Brick to initiate points and their tag, with the 2-tuple format \{ Brick Point, (Corresponding) RDF Tag \}, e.g., \{ brick: High\_AirSpeed\_Sensor, rdf: type owl: Class \} and \{ brick: High\_AirSpeed\_Sensor, rdfs: subClassOf brick: AirSpeed\_Sensor \} for the air-speed sensor. We leverage another JSON file to store the initial mapping from the point in the dataset to the point in Brick with another 2-tuple format \{ Dataset Point, Brick Point \}, e.g., \{ vel\_h,  High\_AirSpeed\_Sensor \}. Then we connect the two JSON files using the following code to manually update the graph of entities: ``graph.add( Dataset Point, RDF Tag, Brick Point)'', where the three parameters refer to the triple \{ subject, predicate, object \} in the graph of entries of Brick.

\begin{figure}[t]
\centering
%\vspace{-1cm}
\includegraphics[angle=0, width=0.4\textwidth]{figures/ValueVsError.pdf}
\vspace{-0.5cm}
\caption{Error rate as a function of the number of distinct values of the task attribute, where the number of maximum layers is set as two to avoid point explosion in the figure.}
\label{fig:ValueVsError}
\end{figure}

\textbf{Metadata Vs. Data.} A key different between metadata and data lies in the number of distinct values. As the descriptor of data, metadata has much less number of distinct values than data. To evaluate the impact of metadata, we evaluate task definition with different attributes which have varying numbers of distinct values. We set the maximum number of layers in the forest as two in order to avoid task explosion mentioned above and keep a lower running time. We show the error rate of using these task attributes in Fig.~\ref{fig:ValueVsError}. We also compute a trend line over the scatter graph. A linear line fits well with $R^2 = 0.795$, which is quite close to 1. That indicates a strong linear relationship between the error rate and the number of distinct value. In general, the error rate increases as the number of distinct values raises, which indicates that metadata (with less number of values) plays a more important role in task definition for multi-task thermal-comfort prediction. 

\begin{table}[t]
\caption{Different numbers of maximum layers in the forest: improvement over the previous layer and training time.}
\label{tab:maxLayer}
\begin{tabular}{|c|c|c|}
\hline
 Max. \# Layers & IMP over Previous Layer (\%) & Training Time (h) \\ \hline
1              & -                         & 0.27              \\ \hline
2              & 31\%                      & 3.86              \\ \hline
3              & 11\%                      & 8.37              \\ \hline
4              & -36\%*                    & 14.27*            \\ \hline
\end{tabular}
\begin{flushleft} \small
*Memory error occurs in this layer and the program stopped in the middle. We provide the best result found before error occurs.
\end{flushleft}
\end{table}
%0.67 0.47 0.42 0.57

\textbf{Impact of Maximum Number of Layers.} An important factor of DUET is the maximum number of layers allowed in the forest. In Table~\ref{tab:maxLayer}, we show the minimum error rate and training time as the function of the maximum number of layers in the forest. First, we see that the training time increases significantly as the maximum number of layers increases and it can even lead to memory error when the number reaches four. That is because when the maximum number of layer increases, the number of separated datasets increases exponentially, which leads to much more tries of combining and training. Second, we see that when the maximum number of layers is larger than two, the improvement of error rate drops significantly and may even lead to a higher error rate due to a memory error. The top layers of attributes have a much greater impact than those in the bottom layers. It is wiser to leverage a 2/3-layer forest to achieve a lower error rate and at the same time less computing resources.



\begin{figure}[t]
\centering
%\vspace{-1cm}
\includegraphics[angle=0, width=0.4\textwidth]{figures/metadegreeVsError.pdf}
\vspace{-1cm}
\caption{Error rate as a function of meta degree of the task attribute, where the maximum number of layers is two.}
\label{fig:metadegreeVsError}
\end{figure}

\textbf{Impact of Minimum Meta Degree.} Another important factor of DUET is the number of minimum meta degree $\Lambda$ which is used to define metadata. According to our definition, merely those data item with meta degree higher than $\Lambda$ is recognized as metadata and used to extract the meta attribute and the final task attribute. In Fig.~\ref{fig:metadegreeVsError}, we plot the error rate as a function of meta degree. We see that basically, the error rate is inversely proportional to the meta degree. In RP884, with the maximum number of layers set as two, the best error rate can be achieved with the data item of VELAV, which has a meta degree as high as 0.9996.