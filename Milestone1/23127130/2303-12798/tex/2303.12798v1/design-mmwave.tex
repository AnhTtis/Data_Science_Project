% !TEX root = main.tex

% \section{Detailed System Design}

\section{IMU-Assisted mmWave Tracking}
\label{sec:global-tracking-design}

%This section presents the design of global tracking by mmWave radar with certain information from the IMUs.

%and briefly presents the local tracking of a certain user using IMU.


%The processing pipeline consists of two steps. First, for each frame's point cloud, ImmTrack applies {\em motion-aware intra-frame clustering} on the point cloud to form clusters, where each cluster corresponds to a user. The clustering process is initialized with centroids predicted by Kalman filters that capture the users' motions. Section~\ref{subsec:mmWave-track-cluster} presents the first step. Then, ImmTrack applies the {\em IMU-assisted inter-frame cluster tracking} to associate the clusters in different frames that correspond to the same user, which is presented in Section~\ref{subsubsec:cluster-tracking}.Lastly, Section~\ref{subsec:imu-tracking} briefly presents the local tracking of a certain user using IMU.

% This section presents the detailed designs to implement the global tracking by the mmWave radar (Section~\ref{subsec:mmWave-track}), 
% local tracking by IMU (Section~\ref{subsec:imu-tracking}),
%  and trajectory-based association of radar's and IMUs' sensing results (Section~\ref{subsec:association}).
% Motivated by visual multi-object tracking \cite{deepsort}, where detection results are first generated frame-by-frame and then associated temporally between adjacent frames for object tracking, ImmTrack follows a similar tracking-by-detection paradigm for trajectory generation.
% Specifically, we first remove the static points that normally correspond to the background for each frame. 
% Then, we perform intra-frame point clustering algorithm on the remaining points to form clusters, in which each cluster corresponds to a user. Finally, ImmTrack associates the detected clusters among frames to generate a trajectory for each user.  
% Notably, different from existing works \cite{shuai2021millieye, wu2020mmtrack} that merely use point cloud from the radar for tracking, we fully take advantage of the information from IMUs in both of the intra-frame clustering and inter-frame association module. We validate in Section \ref{sec: preliminary-tracking} that this cross-modality information from IMU greatly benefits the tracking performance. 


%In what follows, we present the details of these two algorithms when there are no roamers and no passengers. At the end of this section, we will discuss how to handle roamers and passengers.

%The \textit{global tracking module} starts with removing static points. The static removal  is to exclude the static background and preserve the moving objects. The static points can be detected by applying doppler fourier transform on the received data, whose results are the velocity of the detected subjects. Then we will feed the processed point cloud to the \textit{Heuristic Clustering} module.

\subsection{Motion-Aware Intra-Frame Clustering}
\label{subsec:mmWave-track-cluster}

\subsubsection{Design}
The radar yields a point cloud per frame. For each frame, ImmTrack removes the static points that normally correspond to the background. 
Specifically, ImmTrack compares each point's velocity with an adaptive velocity threshold updated by the triangle histogram algorithm \cite{li1998iterative} to decide whether the point is static.
%The static points can be identified by applying Doppler Fourier transform on the received signal, whose results are the velocities of the detected objects. \yimin{By apply the  triangle histogram algorithm \cite{li1998iterative}, an adaptive threshold $v_{static}$ is calculated. The components smaller than the threshold are removed.}
%ImmTrack can count the enrolments to know the number of users, i.e., $N$.
ImmTrack adopts the $k$-means algorithm to divide the point cloud into $N$ clusters by setting $k=N$. 
Notably, the initial centroids often affect the performance of $k$-means.
ImmTrack uses the recursive Kalman filters (RKFs) \cite{feng2014kalman} to predict the initial centroids.
%RKF performs recursive estimation of the covariance matrix characterizing observation noise.
%Therefore, RKF is suitable for ImmTrack as the observation noise's prior distribution is in general uncertain and may vary with time. 
% The initial centroids often affect the performance of $k$-means. To improve the quality of the initial centroids, we use the recursive Kalman filter (RKF) \cite{feng2014kalman}, which applies recursive covariance estimation. RKF is designed to deal with the situation where the covariance matrix of the observation noise is unknown. RKF is suitable for ImmTrack because the observation noise's prior distribution is in general unknown and may vary with time, which will be detailed shortly.

%Two important variables in the clustering algorithms are the number of clusters and the  initialization of the centroids.  Therefore, specifying the two parameters can significantly increase the performance of the clustering algorithm. 

\begin{comment}
We call the module \textit{Heuristic Clustering} because we use three heuristics to boost the performance of the clustering algorithm.
\begin{enumerate}
\item The number of IMU sensors.
\item The points in the cluster should be within a limted distance from the centriod due to the limit of human body part size.    
\item For each cluster centroid's  position $C_{i,t}$ at time $t$, we use the Kalman Filter to predict the position $(C_{i,t+1})$ and use  it as the initialization of the centroids position at time $t+1$.    
\end{enumerate}
\end{comment}


ImmTrack maintains an RKF for each user's volumetric centroid. The human body's kinetic model used by RKF is as follows. Let $\vec{x}_{i,j}$ denote the state of the $i^\text{th}$ user's centroid in the $j^\text{th}$ frame, where $i \in [1, N]$ is the internal PID in the domain of RKF. Note that this PID is different from the PID of the IMU.
%We describe the state in the spherical coordinate system to avoid approximating nonlinear systems by linear models using Taylor expansion, which may bring extra errors.
We define $\vec{x}_{i,j}=[r_{i,j}, \dot{r}_{i,j}, \theta_{i,j}, \dot{\theta}_{i,j}, \phi_{i,j}, \dot{\phi}_{i,j}]^\top$, where $r_{i,j}$, $\theta_{i,j}$, and $\phi_{i,j}$ are the radial range, azimuthal and polar angles, and the overhead dot denotes the velocity. Denote by $\vec{c}_{i,j} = [\hat{r}_{i,j}, \hat{\theta}_{i,j}, \hat{\phi}_{i,j}]^\top$ the $i^\text{th}$ user's observed centroid, where the $k$-means algorithm fed with the point cloud is viewed as the observation process. By assuming that the user's velocity is constant in a frame duration (denoted by $\Delta t$), the state transition and observation models are
\begin{equation}
  \vec{x}_{i,j} = \mat{F} \vec{x}_{i,j-1} + \vec{w}_{i,j}, \quad \vec{c}_{i,j} = \mat{H} \vec{x}_{i,j} + \vec{z}_{i,j},
  \label{eq:rkf}
\end{equation}
where $\mat{F}$ is the state-transition matrix capturing the movement kinetics, $\vec{w}_{i,j}$ is the stationary process noise capturing the uncertainty of the movement, $\mat{H}$ is the observation matrix, and $\vec{z}_{i,j}$ is the non-stationary observation noise capturing the uncertainties caused by the radar's sensing noises and inaccuracy of the $k$-means algorithm. Specifically, $\mat{F} = \mathrm{diag}(\mat{A}, \mat{A}, \mat{A}) \in \mathbb{R}^{6\times 6}$, where $\mat{A} = [1, \Delta t; 0, 1]$ and $\mat{H}$ is a binary matrix that selects $r_{i,j}$, $\theta_{i,j}$, and $\phi_{i,j}$ from $\vec{x}_{i,j}$.

\begin{comment}
\begin{equation*}
  \mat{A} = \left[
  \begin{array}{ll}
    1 & \Delta t \\
    0 & 1  \\
  \end{array}\right] \quad \text{and} \quad
  \mat{H} = \left[
    \begin{array}{llllll}
      1 & 0 & 0 & 0 & 0 & 0 \\
      0 & 0 & 1 & 0 & 0 & 0 \\
      0 & 0 & 0 & 0 & 1 & 0
    \end{array}\right].
\end{equation*}
\end{comment}

Before processing the $j^\text{th}$ frame, ImmTrack uses the RKF to predict the $i^\text{th}$ user's centroid $\widetilde{\vec{c}}_{i,j}$ by $\widetilde{\vec{c}}_{i,j} = \mat{H} \mat{F} \vec{x}_{i,j-1}$, where $\vec{x}_{i,j-1}$ was obtained in the previous frame. When RKF is bootstrapped (i.e., $j=0$), ImmTrack uses the DBSCAN algorithm to obtain $\widetilde{\vec{c}}_{i,0}$. Then, ImmTrack uses $\{\widetilde{\vec{c}}_{i,j} | i \in [1, N]\}$ as the initial centroids for the $k$-means algorithm with $k=N$ to process the point cloud in the $j^\text{th}$ frame. We sequentially assign the PID of each initial centroid to the closest centroid of a cluster exclusively, forming the pseudo-identified clustering result $\{\vec{c}_{i,j} | i \in [1, N]\}$. Finally, ImmTrack uses a policy derived in \cite{feng2014kalman} to update $\vec{x}_{i,j}$ and the covariance matrix of $\vec{z}_{i,j}$, i.e.,  $\vec{x}_{i,j} = \vec{x}_{i,j-1} + \vec{K}_{i,j}\left(\vec{c}_{i,j}-\mat{H} \vec{x}_{i,j-1}\right)$ and $\mathrm{cov}(\vec{z}_{i,j}) = \mathrm{cov}(\mat{M} \vec{c}_{i,j} - \mat{F} \mat{M} \vec{c}_{i,j-1}) - \mathrm{cov}(\vec{w}_{i,j})$, where $\vec{K}_{i,j}$ is the constant Kalman gain and $\mat{M} = \left( \mat{H}^\top \mat{H} \right)^{-1} \mat{H}^\top$. We follow the approach described in \cite{basso2017kalman} to estimate $\mathrm{cov}(\vec{w}_{i,j})$ used in the above update. The update of $\mathrm{cov}(\vec{w}_{i,j})$ enables ImmTrack to adapt to dynamic sensing performance of the radar due to the position variations of users.

Note that the distance-based heuristic rule of transferring the PID of the initial centroids to the resulting centroids of the $k$-means clustering may have errors when the trajectories of two users cross in the radar's FoV. However, since the RKF is mainly used to assist better choosing the initial centroids rather than track the users, the swap of PIDs does not have long-lasting negative effect after the crossing because the models in Eq.~(\ref{eq:rkf}) are Markovian. Note that tracking the users is the subject of \sect\ref{subsubsec:cluster-tracking}.

% \begin{wrapfigure}{R}{0.2\textwidth}
%   \includegraphics[width=\linewidth]{figures/PointCloud_DB_vs_rkf}
%     \caption{Clustering results ($N=3$)}
%     \label{fig:compareRKF}
% \end{wrapfigure}
\subsubsection{Evaluation}


% \begin{figure}[htp]% [H] is so declass\'e!
%   \centering
%   \begin{minipage}{0.45\linewidth}
%   \includegraphics[width=\linewidth]{figures/demo_rkf}
%   \caption{figure caption}
%   \end{minipage}\hfill
%   \begin{minipage}{0.45\linewidth}
%   \includegraphics[width=\linewidth]{figures/demo_dbscan}
%   \caption{figure caption}
%   \end{minipage}\par
%   \vskip\floatsep% normal separation between figures
%   \includegraphics[width=0.45\linewidth]{figures/cluster_experiment}
%   \caption{figure caption}
%   \end{figure}


% \begin{figure}[!htp]
%   \begin{subfigure}{.15\textwidth}
%     {
%       \includegraphics[width=\textwidth]{figures/cluster_experiment}
%       \caption{Performance of intra-frame clustering algorithms}
%       \label{fig:cluster algorithm}
%     }
%   \end{subfigure}
%   \begin{subfigure}{.15\textwidth}
%     \includegraphics[width=\textwidth]{figures/demo_rkf}
%     \caption{Results of RKF-assisted $k$-means when $N=3$}
%     \label{fig:RKFClu}
%   \end{subfigure}
%   \begin{subfigure}{.15\textwidth}
%     \includegraphics[width=\textwidth]{figures/demo_dbscan}
%     \caption{Results of DBSCAN when $N=3$}
%     \label{fig:DBSCANClu}
%   \end{subfigure}
%   \caption{Intra-frame clustering. The proposed RKF-assisted $k$-means clustering algorithm outperforms $k$-means, DBSCAN, and GMM. It also outperforms mmTrack \cite{wu2020mmtrack} when $N \ge 4$. In (b), color represents cluster ID, cross represents centroid, and the DBSCAN yields 2 clusters for 3 users.}    
% \end{figure}

\begin{figure}
  \begin{minipage}[t]{.6\linewidth}
    \begin{subfigure}[t]{\linewidth}
      \includegraphics[width=\linewidth]{figures/cluster_experiment}
      \caption{Performance of intra-frame clustering algorithms. Baselines: $k$-means, DBSCAN, GMM, mmTrack and its variant.}
      \label{fig:cluster algorithm}
    \end{subfigure}
  \end{minipage}
  \hfill
  \begin{minipage}[t]{0.35\linewidth}
    \begin{subfigure}[t]{\linewidth}
      \includegraphics[width=\linewidth]{figures/demo_cluster}
      \caption{Results of RKF-assisted $k$-means and DBSCAN when $N=3$.}
      \label{fig:ClusterDemo}
    \end{subfigure}
  \end{minipage}
  \caption{Intra-frame clustering. The proposed RKF-assisted $k$-means clustering algorithm outperforms $k$-means, DBSCAN, and GMM. It also outperforms mmTrack \cite{wu2020mmtrack} when $N \ge 4$. In (b), color represents cluster ID, cross represents centroid, and DBSCAN yields 2 clusters for 3 users.}
  \vspace{-1em}
\end{figure}
  
% \begin{wrapfigure}{R}{0.5\textwidth}
% \begin{figure}
%   \begin{subfigure}[h]{.6\linewidth}
%     \centering
%     \includegraphics[width=\linewidth]{figures/cluster_experiment}
%     \caption{Performance of intra-frame clustering algorithms}
%      \label{fig:cluster algorithm}
%   \end{subfigure}%
%   \hfill
%   %\begin{subfigure}[t]{.15\textwidth}
%   %  \centering
%   %  \includegraphics[width=\linewidth]{figures/PointCloud_DB_vs_rkf}
%   %  \caption{Clustering results ($N=3$)}
%   %  \label{fig:compareRKF}
%   %\end{subfigure}
%   \begin{subfigure}[t]{.35\linewidth}
%     \includegraphics[width=\linewidth]{figures/demo_rkf}
%     \includegraphics[width=\linewidth]{figures/demo_dbscan}
%     \caption{Results of RKF-assisted $k$-means and DBSCAN when $N=3$}
%     \label{fig:compareRKF}
%   \end{subfigure}
%   \vspace{-0.5em}
%   \caption{Intra-frame clustering. The proposed RKF-assisted $k$-means clustering algorithm outperforms $k$-means, DBSCAN, and GMM. It also outperforms mmTrack \cite{wu2020mmtrack} when $N \ge 4$. In (b), color represents cluster ID, cross represents centroid, and the DBSCAN yields 2 clusters for 3 users.}
% \end{figure}
% %  \hfill
%\end{wrapfigure}


We compare our RKF-assisted $k$-means algorithm with a variant without RKF and several other clustering approaches including DBSCAN and Gaussian mixture model (GMM) built with the expectation-maximization (EM) algorithm. We also implement the clustering algorithm proposed in mmTrack \cite{wu2020mmtrack}. The mmTrack applies the $k$-means algorithm with random initial centroids to cluster the point cloud. During the $k$-means iterations, mmTrack uses the medoids of the clusters obtained in the previous iteration as the initial centroids of the next iteration. The mmTrack determines the value of $k$ using the silhouette analysis. In addition, we implement a variant of mmTrack's clustering algorithm by removing the silhouette analysis and directly setting $k=N$. All the above baseline approaches do not consider motion.

%\yimin{Moreover, we also implement the clustering algorithms proposed in mmTrack\cite{wu2020mmtrack}. In addition, we also implement a variation of it by replacing its number of clusters estimation module with a known number of users.  }
%The $k$-means and GMM require the prior knowledge of $N$.
% our  prior knowledge assisted intra-frame point clustering algorithms with several classical clustering algorithms, including \textit{K}-means, DBSCAN, and clustering with Gaussian Mixture Model (GMM).
%The goal is to study on the influence of the prior knowledge on the clustering process. The prior knowledge in the \textit{K}-means  and GMM clustering is the number of clusters, which we also embed in our algorithm. The GMM clustering furthur assumes each cluster follows a gaussian distribution. As for DBSCAN, it use the cluster density as the prior knowledge.
%\noindent \textbf{Metric.}


% \begin{wrapfigure}{L}{0.4\textwidth}
%   \centering
%   \includegraphics[width=\linewidth]{figures/cluster_experiment}
%   \caption{Performance of various intra-frame clustering algorithms}
%    \label{fig:cluster algorithm}
% \end{wrapfigure}


We use the Adjusted Rand Index (ARI) to measure the quality of clustering. Zero ARI indicates random guessing-like clustering, whereas ARI of one suggests perfect clustering.
We compute per-frame ARIs and report the average ARI.
During the experiment, the users follow pre-defined trajectories, so that we can obtain the ground truth. More details of the experiment setup are presented in \sect\ref{sec:eval}. From Fig.~\ref{fig:cluster algorithm},
our RKF-assisted $k$-means outperforms $k$-means, DBSCAN, and GMM. When $N \le 3$, the mmTrack and its variant with known $k$ slightly outperform our RKF-assisted $k$-means in terms of ARI. However, the advantage of our RFK-assisted $k$-means over mmTrack and its variant increases with $N$ when $N \ge 4$. \yimin{The explanations for the above results are as follows. When the occlusion cases increase due to the increase of users, our RKF-assisted $k$-means algorithm outperforms mmTrack. When there are no or limited occlusions, mmTrack's clustering algorithm performs well. However, with our RKF-assisted $k$-means algorithm, some of the points corresponding to users in the point cloud are excluded in the phase of static points removal, leading to lower ARI.}
%When $N=6$, the mmTrack and its variants are worse than GMM.
Fig.~\ref{fig:ClusterDemo} shows the clustering results of the DBSCAN and RKF-assisted $k$-means algorithms when $N=3$, respectively. DBSCAN mistakenly combines two users into a single cluster. The above results suggest that the consideration of motion improves clustering performance.
%Other than our algorithm, we find that the GMM clustering outperforms the remainings, while DBSCAN shows the worst performance. As shown in the experiment, the  accuracy of clustering  is positive related to the quality and quantity of the prior knowledge.





% \begin{figure}
%   \centering
%   \includegraphics[width=0.8\linewidth]{figures/cluster_experiment}
%   \caption{Performance of various intra-frame clustering algorithms.}
%   \label{fig:cluster algorithm}
%   % Our proposed heuristic clustering performance is slightly betterthan GMM when there is no passenger. Moreover, it shows similar performance when there are some passengers.}  
% \end{figure}



% Our clustering algorithm outperforms others under all cases regardless of the number of people and whether there is a passenger. When there is no passenger, the performance of all algorithms degrades when there are more people. 
% % Specifically, compared to the most comparable algorithm GMM, the ARI are 0.71 and 0.69 for heuristic clustering and GMM respectively when the number of people is six. 
% When there are passengers, the number of clusters is no longer equal to the number of IMU sensors. In this case, those algorithms that require the number of clusters (i.e., K-means, GMM) perform worse as the number of passengers is getting larger. However, our heuristic clustering shows an upward trend and reaches an ARI over 0.9 when there are 2 passengers out of 5 people. \textcolor{red}{[why increase? ours is also based on Kmeans]}

\begin{comment}
$\Delta t$, so the motion model (A) and the observation model (C) are defined as followings:
$$
\begin{aligned}
x_{k} &=\left[\begin{array}{cccccc}
1 & \Delta t & 0 & 0  & 0 & 0\\
0 & 1 & 0 & 0 & 0 & 0\\
0 & 0 & 1 & \Delta t & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 0 & 1 & \Delta t\\
0 & 0 & 0 & 0 & 0 & 1\\

\end{array}\right] x_{k-1}+Q, \\
y_{k} &=\left[\begin{array}{llllll}
1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 
\end{array}\right] x_{k}+R_{k-1},
\end{aligned}
$$

For each cluster centroid's  position $C_{i,t}$ at time $t$, we use the Kalman Filter to predict the position $(C_{i,t+1})$ and use  it as the initialization of the centroids position at time $t+1$.

In each iteration, the RKF estimate the covariance of $R$ using the formula\cite{feng2014kalman}
$$
\operatorname{Cov}{(R_k)}=\operatorname{Cov}{(\xi_k)}-\operatorname{Cov}(Q)
$$
where
 $\xi_{k}=M \cdot y_{k}-A\cdot M \cdot y_{k-1}$ and $M=\left[C^{T} C\right]^{-1} C^{T}$
\end{comment}

%After the Kalman filter predicts the next position $(C_{i,t+1})$, we transform  $(C_{i,t+1})$ from  polar system to Cartesian coordinates and use it as the initialization of the centrodds for the cluster in the next frame. First of all, we apply \textit{K}-Means on the frame at time $t$ with centroids initialized position as $C_{t+1}$ and we set the number of clusters equal to the number of imu sensors $N$.


\subsection{IMU-Assisted Inter-Frame Cluster Tracking}
\label{subsubsec:cluster-tracking}

%After removing the clutters (e.g.,non-human object) and separating the  clusters, the remaining problem is the cluster association: an inherent mechanism needs to be designed to connect clusters across consecutive frames.

\subsubsection{Design}
The association of the clusters in the consecutive frames that correspond to the same user is based on {\em space coherence} and {\em motion coherence}. The former means that the shape of a moving object at close locations are similar from the radar's perspective; the latter means that the object's motions in consecutive frames are similar. We design a new deep learning-based feature extractor called {\em mmClusterNet} that fuses {\em shape}, {\em motion}, and {\em IMU PID} features of a cluster into a single {\em cluster tracking feature} for each frame.

% For tracking with the camera, rich 
% features related to the shape and coloring can be extracted from the region of interest by using deep learning. Then the tracking systems using the camera compare the similarity between the 
% features across consecutive frames to solve the cluster association.  

% On the contrary,  the existing solutions for the sparse point cloud is to rely on the location (e.g. nearest neighbor) and velocity data  which are directly obtained from measurements. 
% However, the naive solution suffers from high false-positive rate in indoor applications since people tend to gather together and the velocity is limited to a 
% small range, which makes it indistinguishable among different people.  On the other hand,  due to the sparsity of the point cloud in mmWave radar,  the shape and color features embedded in the point cloud is not reliable enough for 
% cluster association.  

% In our cluster association module, we propose two innoviations to solve the above challenges, which utilize multiple features of the point cloud including shape, location, and velocity.
% \begin{enumerate}
%     \item We leverage the velocity information in imu to assist the cluster association process and overcome the sparsity problem.
%     \item  We design the PointTrack Net (PTrack Net) to jointly embed the shape, velocity and location information in each cluster to a feature vector. 
% \end{enumerate}




%\textit{\textbf{PointTrack Net Structure}}

%\todo{add downstream task, change position encoding to imu id encoding}



\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{figures/mmcluster}
  \vspace{-2em}
  \caption{mmClusterNet for fusing shape, motion, IMU PID features. The distance matrix of fused feature of clusters is used as the metric for inter-frame association and tracking. }
  \label{fig:feature_extractor}
  \vspace{-1em}
\end{figure}


% In most of the tracking systems, they focus on Kalemn Filter design or data pre-processing pipeline. For the cluster association similarity calculation, most of work use simple heuristics  such as nearest point using the euclidean distance \cite{wu2020mmtrack}. This simple approach is not robust and accurate enough because 
% \begin{enumerate}
%     \item The approach does not make full use of the existing information such as the velocity, radical velocity, number of points in the cluster, shape of the cluster.
%     \item A single heuristic can not cover all the situations. For example the nearest point solution works when the object are separated far away but will fail when the object are relatively near to each other.
% \end{enumerate} 

% Our network is designed to handle the sparsity in radar point clouds and output the feature vector for clustering association. 

Fig.~\ref{fig:feature_extractor} shows mmClusterNet's architecture. For each frame, it takes each of the clusters produced by \sect\ref{subsec:mmWave-track-cluster} as input. The mmClusterNet is designed to process a cluster with $n$ 3D points, where $n$ is fixed at the design phase. When processing a smaller cluster, ImmTrack firstly applies interpolation to generate an $n$-point cluster. For the AWR1843 mmWave radar, $n=24$ is a good setting because it is an empirical upper bound of human cluster size. 
As shown in the upper branch in Fig.~\ref{fig:feature_extractor}, each of the $n$ points is processed by a shared multilayer perceptron (MLP) with two 32-neuron hidden layers. The results of the $n$ shared MLPs are max-pooled to generate a $1\times 32$ shape feature, which is copied vertically $n$ times, concatenated with the shared MLPs' outputs and the cluster's radial velocity vector (as the motion feature) to form an $n \times 65$ tensor. Then, each row of the tensor is processed by an MLP with two 64-neuron hidden layers and max-pooling to produce a $1 \times 64$ shape-motion feature. Finally, the shape-motion feature is fused with the IMU PID feature, which is detailed shortly, by element-wise addition to produce the cluster tracking feature. To train mmClusterNet, we append a regression MLP as the downstream task that produces a bounding box of the cluster from the shape-motion feature. Then, we use manually labeled bounding boxes as ground truth to train the mmClusterNet core. In \sect\ref{compare_down_task}, we will evaluate the impact of different choices of the downstream task on mmClusterNet's performance. \yimin{Note that the training data for the mmClusterNet core is unnecessary to be {\em in situ} data. The training can be based on a public dataset such as ShapeNet.}

%\todo{As for training the network, we feed the shape-motion feature into  a MLP layer to regress the bounding box  $\left(x_{1}, y_{1}, x_{2}, y_{2}\right) \in \mathcal{R}^{4}$ of each cluster on the data we collect. }

%Instead of directly using the whole point cloud as the input, we feed each cluster to the model one by one to learn the features of each cluster. For each cluster, we first feed the location vector to a shared MLP layer, then followed by a max-pooling layer to aggregate the information from all the points and output the global feature $G$. The shared-MLP is designed for making the model invariant to input permutation\cite{pointnet} and learning the individual features. Then we concatenate $G$ with the individual features before and add the velocity vector in the end. Then we feed concatenated vector to another shared-MLP layer with a larger size, followed by a max-pooling layer. The output features $F$ will be added with the imu id  encoding with the same length. Then final output feature will be used in the cluster association process. 


%Then we will explain the \textit{imu id  encoding} in details. Besides the model structure, the downstream task plays an important role. The downstream task will control the features the model  learns. In our system, we choose bounding box prediction because the task requires the feature from  both the shape and location information.

%\textit{\textbf{Imu Id Encoding}}


%  Instead of using the entire captured point cloud, the model handles each cluster  separately. The model can be divided into two phases.
% \begin{enumerate}
%     \item  \textbf{Embed shape information: } The model first embed the information about the shape and outline of the object by using the shared mlp originally proposed in pointnet\cite{pointnet}.
%     \item \textbf{Bounding Box refinement:}  Due to the sparsity of the radar point cloud, the feature directly extracted from the point cloud is not robust enough. With the help of heuristic clustering, the cluster result is promising so we further concatenate the centriod information , including the $(x,y)$ position and the velocity to the feature out from phase 1. Then we apply the similar shared mpl with more neurons and one more layers. After that, the features pass through a max pooling layer and then become  a single representative feature for 2D-bounding box generation.

%     \end{enumerate}

%$\lVert \vec{c}_i - \vec{p}_{i,s}\rVert$

%Using the rank as weight instead of the actual distance avoid  the problem of attenuation of the data. Specifically,  if we divide the velocity by the actual distance,  all velocities will be near to zero since the distance is much larger than velocity.

The shape-motion feature is directly affected by the radar's sensing noises. Thus, we supplement user-specific static information (i.e., the IMU PID feature) to assist the cluster tracking. Specifically, we perform a {\em pre-matching} between the clusters generated by the radar and the IMUs, and then use the matched IMU's PID as the user-specific static information. The pre-matching is as follows. First, we compute $\overline{\vec{v}}_i$, which is the weighted average 3D velocity of all points in the $i^\text{th}$ cluster, by $\overline{\vec{v}}_i= \sum_{s=1}^{n_i} \frac{\textit{projection}_{\vec{v}_{\vec{c}_i}}\vec{v}_{i,s}}{\ln n_i \cdot \textit{rank}(d_s, \{d_1, \ldots, d_{n_i}\})}$, where
% We assign the id to the cluster  based  on  similarity between $M_{v_t}^{(j)}$  and $I_{v_t}^{i}$   There main difficulty here is that 
% \begin{enumerate}
%     \item  $M_{v_t}^{(j)}$  contains the estimated velocity of all the points in the point cloud, which is corrsponding to different body part. However, the profile $I_{v_t}^{i}$ only 
%     contains one estimated data. 
%     %\item  $M_{v_t}^{(k,j)}$   stores the velocity respect to mmWave  as a scalar while $I_{v_t}^{i}$  is the velocity of the user in world frame. 
% \end{enumerate}
% For $I_{v_t}^{i}$, we choose 2 dimensions with larger variance from x,y,z ,  The key observation is that it is enough to dinstinguish the velocity profile only based on 2 dimensions data. Moreover, reduced the problem from 
% 3D to 2D will ease  it.
% for $M_{v_t}^{(k,j)}$, we assign it to the direction $\theta^{j,k,t}$ in 2D plane. Here 
% the $\theta^{j,k,t}$ is the arrival of angle(AOA) of the point. Then the average velocity $\overline{V_{mmWave}^{j,t}}$  is calculated as 
$n_{i}$ is the number of points in the cluster, $\vec{c}_i$ is the cluster centroid, $\vec{v}_{\vec{c}_i}$ is $\vec{c}_i$'s 3D velocity, $\vec{v}_{i,s}$ is the 3D velocity of the $s^\text{th}$ point of the cluster, $d_s$ is the Euclidean distance between the $s^\text{th}$ point and the centroid, the operator $\textit{projection}_\vec{a} \vec{b}$ returns the projection of $\vec{b}$ in the direction of $\vec{a}$, and the operator $\textit{rank}(a, A) \in \{1, \ldots, |A|\}$ returns the rank of $a$ in the set $A$ with elements in ascending order. With the reciprocal of rank as the weight, a point closer to the centroid receives a larger weight in the averaging. Using the rank instead of distance as weight for velocity avoids the issue of physical unit conciliation.
%Using the rank as weight instead of the actual distance avoid  the problem of attenuation of the data. Specifically,  if we divide the velocity by the actual distance,  all velocities will be near to zero since the distance is much larger than velocity.
We apply the coefficient $\frac{1}{\ln n_i}$ to make the sum of the weights to be approximately one, i.e., $\sum_{s=1}^{n_i} \frac{1}{\ln n_i \cdot \textit{rank}(d_s, \{d_1, \ldots, d_{n_i}\})} \approx 1$. Second, with all clusters' average velocity magnitudes $\{|\overline{\vec{v}}_1|, \ldots, |\overline{\vec{v}}_{N}|\}$ and all IMUs' velocity magnitudes denoted by $\{|\vec{u}_1|, \ldots, |\vec{u}_{N}|\}$, we apply the Hungarian algorithm to find the one-to-one pre-match between the clusters and IMUs based on Euclidean distance. Let $\mathrm{PID}_i \in \{1, \ldots, N\}$ denote the PID of the IMU pre-matched with the $i^\text{th}$ cluster. We apply the position encoding \cite{vaswani2017attention} to generate the $i^\text{th}$ cluster's $1 \times 64$ IMU PID feature as $[g_1, h_1, g_2, h_2, \ldots, g_{32}, h_{32}]$, where $g_m =\sin \left( \left( \frac{\mathrm{PID}_i}{1000}\right)^{\frac{m}{32}} \right)$ and $h_m=\cos \left( \left( \frac{\mathrm{PID}_i}{1000}\right)^{\frac{m}{32}} \right)$. As presented earlier, the IMU PID feature is added to the shape-motion feature to form the cluster tracking feature.

Given the cluster tracking features obtained in two consecutive frames, the Hungarian algorithm is used to associate one feature in the former frame and one feature in the latter, exclusively, based on cosine similarity. The associated clusters are considered from the same user. In addition, their centroids over time form the trajectory of the user. All trajectories will be input to the trajectory-based association module presented in \sect\ref{subsec:association}.



%$p_{(s,j)}$  is the $s^{th}$ point.
%The function \textit{RANK} return the order of the distance among all the points in the $j^{th}$ cluster, starting from 1. The ranking severs as the weight of each point, and since $\sum_{i=0}{m} \frac{1}{i}  \approx \frac{1}{m}$, we divide the sum by $\frac{1}{m}$

%Here we use  $\vec{I_{v_t}^{i}}$,$\vec{M_{v_t}^{(j)}}$  to denote the velocity vector   of the $i^{th}$ imu and $j^{th}$ cluster at time $t$. Note that for each cluster, it contains multiple points, so we use  $\vec{M_{v_t}^{(s,j)}}$ to denote the velocity of $s^{th}$  point of the $j^{th}$  cluster. We apply the following process to define the similarity score between $\vec{I_{v_t}^{i}}$ and $\vec{M_{v_t}^{(j)}}$.

%The features learned from the PointTrack Net embeds the shape and motion information of the cluster. However, due to the uncertainty during the measurements, the motion coherent and space coherent of the cluster are not  invariant proprties. However, there is an invariant  property: \textit{there is  an one to one mathching between each cluster and each user}.  Therefore, we first find a matching between the clusters $C$ and the set of imu $I$. 


% If we model the matched pair $\left(C_{i},I_{j}\right)$
% We leverage the  property to assign the id of the most similar imu sensor. 

\begin{comment}
Given the number of users $N$, we first assign a pseudo id  $i$ from $1 \dots N$ to each IMU. 
Then we adopt the position encoding function, which is proposed in \cite{vaswani2017attention} with dimension D to encode the id, namely \textit{imu id encoding}

$$
PE(i) = 
\left[
  \begin{array}{c}
    \sin(i/1000^{\dfrac{1}{D}}),
    \cos(i/1000^{\dfrac{1}{D}})\\
    \vdots \\
    \sin(i /1000^{\dfrac{D}{D}}),
    \cos(i/1000^{\dfrac{D}{D}})
  \end{array}
\right]
$$
\end{comment}
  
%Up to this stage, we can  calculate the  similarity score   by using the cosine similarity. After finding the  most similar imu $i$ for cluster $j$, we add the $PE(i)$ to the feature vector of $j^th$ cluster.


% \todo{proof here, try to proof the gain of using the encoding, just draft right now}
% \textbf{Gain Information}
% Let $F = \{\xi_{0}, \xi_{1},\dots, \xi_{D-1}\}$ denote the feature vector from PointTrack Net for cluster i at frame t and
% $\hat{F} = \{\hat{\xi}_{0}, \hat{\xi}_{1},\dots, \hat{\xi}_{D-1}\}$ denote the feature vector for cluster i at frame t+1 .
% \begin{proof}
%   If $\cos\left(F,\hat{F}\right) \geq 0$, 
  
%   then $\cos\left(F,\hat{F}\right) \leq \cos\left(F+PE(i),\hat{F+PE(i)}\right)$


% $\cos\left(F+PE(i),\hat{F+PE(i)}\right)$
  


% $= \frac{\sum_{j=0}^{D} (\xi \cdot \hat{\xi} +  \gamma_{j}\cdot(\xi + \hat{\xi}))  + \frac{D}{2}}
%  {  \sqrt{ \sum_{j=0}^{D} (\xi_{j}^2 +2\gamma_{j} \cdot \xi_{j} + \gamma_{j}^2) } \cdot  \sqrt{ \sum_{j=0}^{D} (\hat{\xi}_{j}^2 +2\gamma_{j} \cdot \hat{\xi}_{j} + \gamma_{j}^2) }  }$ 


% $\geq \frac{\sum_{j=0}^{D} (\xi \cdot \hat{\xi} +  \gamma_{j}\cdot(\xi + \hat{\xi}))  + \frac{D}{2}}
% {\sqrt{\sum_{j=0}^{D} \xi_{j}}\cdot \sqrt{\sum_{j=0}^{D} \hat{\xi}_{j}} + 2 \sqrt{\sum_{j=0}^{D} \sum_{h=0}^{D} \xi_{j}\cdot \gamma_{j} \cdot \hat{\xi}_{h}  \cdot \gamma_{h}}  +\frac{D}{2}}$





% \end{proof}


%Furthermore, we design a new mechanism to handle the case when the assumptions of space and motion coherence fail due to unknown noise or occlusion.

\begin{figure}
  \centering
  \begin{subfigure}[b]{.23\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/2case_demo}
    % \caption{Case 1: users walks in trajectories with different shapes in the same speed }
    \caption{Setup.}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[b]{.37\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/case1_association}
    \caption{Case 1 result.}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{.37\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/case2_association}
    \caption{Case 2 result.}
  \end{subfigure}
  \vspace{-1em}
  \caption{Cosine similarity between features of clusters of same user in two consecutive frames.}
  % provides cross-modality information to make a more robust cluster matching process. }
  \label{fig:imuencoding}
  \vspace{-1em}
  \end{figure}

\subsubsection{Evaluation}
We evaluate the advantage of the cluster tracking feature, compared with solely using either shape-motion feature or IMU PID feature.
% We also introduce a baseline based on global nearest neighbor (GNN for short) between the prediction positions from Kalman Filter and the and the observation points. 
%The Kalman Filter predicts the position ${pos}_{c_i}^{t+1}$ of cluster $c_i$ at time $t+1$, and the GNN finds the matched cluster $c_j$ nearest to ${pos}_{c_i}^{t+1}$ among all observed clusters at time $t+1$. 
% where the \textit{IMU Id Encoding} provides cross-modalities information.
We consider two cases as illustrated in Fig.~\ref{fig:imuencoding}: (1) all users walk at the same speed but follow different paths of different shapes; (2) all users walk at different speeds and follow different paths of the same shape. We measure the cosine similarity between the features of the clusters corresponding to the same user in two consecutive frames.
%Finally, we plot the cumulative distribution of cosine similarity between the features from the same clusters in two consecutive frames under the two scenarios for comparsion. 
Fig.~\ref{fig:imuencoding} shows the cumulative distribution functions (CDFs) of the measured cosine similarities in the two cases. 
% When cluster tracking feature is used, the cosine similarities are statistically higher.
% , under both two cases, using  \textit{cluster tracking feature}  achieves the best performance.
In case (1), the performance of shape-motion feature is similar to cluster tracking feature. In case (2), the performance of IMU PID feature is similar to cluster tracking feature, because the velocity-based mmWave-IMU pre-matching is accurate when users' speeds are different and the matched IMU PID contributes more information than the shape-motion feature. The above results show that the cluster tracking feature takes both the advantages of shape-motion feature and IMU PID feature.

%is representative enough to  discriminate different people in Case 1.  On the other hand, \textit{IMU PID} is reliable in case2  as the pre-matching process is accurate enough. Moreover, we can find that the \textit{shape-motion feature} plus the \textit{IMU PID}  achieves the result of $1 + 1 \geq 2$.
% This is because the assignment of the \textit{IMU PID} encoding heavily relies on the velocity information from two sensors. Therefore, when participants walk at a similar speed, the \textit{IMU PID} is not a discriminative indicator for different people.
%  On the contrary, when people walk in different speeds, the pre-matching process is accurate enough and \textit{IMU PID} can provide strong supplementary information for \textit{shape-motion feature}.
% In addition, we notice that the performance of GNN is poor. The reason is that GNN depends on the accurate position of clusters for association. However, this premise may not hold, especially when there are multiple people, considering that the radar point cloud is sparse and noisy. 
% In summary, this experiments shows that combining both F and P can make the cluster matching process more robust and accurate. 

% On the other hand, performance of using F drops in scenario two while using P results in W-ACC around 80$\%$. Overall, the experiment shows the two feature vectors
% embed different information related to the point cloud. 
% Moreover, it also shows combining the two features will lead to a better result.

% \begin{figure}[]
%   \centering
%   \includegraphics[width=.45\textwidth]{figures/demo2case}
%   \caption{Demo on the two experiment scenarios}
%   \label{fig:demo_association}
% \end{figure}%

% \begin{figure}
   
%   \begin{subfigure}[t]{.23\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{figures/association_case1}
%     \caption{Case 1}
%     \label{fig:association1}
%   \end{subfigure}%
%   \hfill
%   \begin{subfigure}[t]{.23\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{figures/association_case2.eps}
%     \caption{Case 2}
%     \label{fig:association2}
%   \end{subfigure}
%   \vspace{-0.5em}
%   \caption{Demo on the two experiment scenarios}
%   \label{fig:demo_association}
% \end{figure}

% \begin{figure}   
%     \begin{subfigure}[t]{.47\textwidth}
%       \centering
%       \begin{tabular}{p{0.4\textwidth}p{0.54\textwidth}}
%         \vspace{0pt} \includegraphics[width=\linewidth]{figures/association_case1} &
%                                                                                        \vspace{0pt} \includegraphics[width=\linewidth]{figures/case1_association}
%       \end{tabular}
%       \caption{Case 1: Same speeds, different paths}
%       \label{fig:association1}
%     \end{subfigure}%
%     \hfill
%     \begin{subfigure}[t]{.47\textwidth}
%       \centering
%       \begin{tabular}{p{0.4\textwidth}p{0.54\textwidth}}
%        \vspace{0pt} \includegraphics[width=\linewidth]{figures/association_case2} &
%                                                                                     \vspace{0pt} \includegraphics[width=\linewidth]{figures/case2_association}
%       \end{tabular}
%       \caption{Case 2: Different speeds, different paths of same shape}
%       \label{fig:association2}
%     \end{subfigure}
%     \vspace{-0.5em}
%     \caption{Cosine similarity between features of clusters of same user in two consecutive frames.}
%     % provides cross-modality information to make a more robust cluster matching process. }
%     \label{fig:imuencoding}
% \end{figure}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End: