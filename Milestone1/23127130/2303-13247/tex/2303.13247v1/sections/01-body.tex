\section{Introduction}

While clone detection is a well-established field of research, its practical application still faces open questions, in particular, the minimal size of clones that need to be detected to filter out trivial, universal code, with researchers often selecting different thresholds for the same techniques~\cite{wang2013searching, ragkhitwetsagul2018comparison}. Several works even researched the idea of using many different thresholds at once~\cite{keivanloo2015threshold, golubev2021multi}. This problem manifests itself in IntelliJ-based IDEs~\cite{kurbatova2021intellij}, such as PyCharm~\cite{pycharm}, where exact clones~\cite{roy2007survey} are underlined in the editor. 
To do  this, the current threshold was established empirically back when the system was developed. At the same time, different languages vary in their verboseness and thus may require different thresholds. Therefore, for the younger IDEs, we decided to establish new, more fitting, thresholds. However, firstly, it is very time-consuming to carry out a separate user-studies and A/B tests for each IDE and language. Secondly, existing users already got used to the current default thresholds, and changing the IDE's behavior drastically might interfere with their workflow. Thus, rather than implement a brand new threshold, the IDE development team wanted to \textit{update} and \textit{optimize} the threshold for a new language so that the amount of detected clones is roughly the same. In this paper, we describe how we did this for two new JetBrains IDEs --- Datalore~\cite{datalore} and DataSpell~\cite{dataspell} --- via comparing regular Python code and Jupyter notebooks.

\section{Approach, Evaluation, and Future Work}

\textbf{Approach.} Our core idea is to use distributions of all the detected clones within two languages or ecosystems to find such a threshold that would detect the same percentage of clones. In this work, we consider only exact clones within a single file, since they are the ones highlighted in the IDE.

To find all clones within one file, we employed the popular suffix tree based approach that is used in the platform~\cite{liu2006detecting}.  While the suffix tree is usually applied to strings, it is possible to build it for any arbitrary sequence, therefore, we use it directly on the elements of the platform's concrete syntax tree (CST)~\cite{kurbatova2021intellij}. Having obtained these elements from parsing, we iteratively go through all possible sizes for duplicates, from 3 tokens up to the half of the file's length. As a result, we get a list of all duplicates for each given size for the analyzed file.

\begin{figure}[t]
\includegraphics[width=0.9\columnwidth]{figures/quantiles_distribution.pdf}
\centering
\vspace{-0.4cm}
    \caption{(a) Probability density function of duplicate count in notebooks and scripts. (b) Quantile-Quantile plot of notebook and script clone distributions. Red square indicates the intersection of quantiles, corresponding to the same quantile's marker of different distributions.}
    \label{fig:quantiles}
    \vspace{-0.6cm}
\end{figure}

Firstly, we take the language, for which we know the optimal threshold, collect a dataset for it, and search it for clones as described above. This results in the distribution of a mean number of duplicates in a file with each tested minimal threshold. On this distribution, we can find the bin corresponding to our optimal value and calculate its quantile rank. In order to find the optimal threshold for another language, we need to repeat the same process and find the threshold that corresponds to the same quantile rank in its distribution.

\textbf{Evaluation.} We applied this approach to find the optimal value for Jupyter Notebooks for two new IDEs --- Datalore~\cite{datalore} and DataSpell~\cite{dataspell}. Research shows that code clones are frequent in notebooks~\cite{koenzen2020code} and that the code in regular Python and notebooks is different~\cite{grotov2022large}. 
We sampled 10,000 Python scripts and 10,000 Jupyter notebooks with permissive licences and 10+ stars on GitHub from our previous work~\cite{grotov2022large}. Next, we applied our algorithm, and calculated that the default PyCharm's threshold of 45 CST elements corresponds to the 95th percentile of the distribution, meaning that 5\% of all potential Python clones are underlined. The area under curve of the probability density functions (Figure~\ref{fig:quantiles}a) shows that to highlight the same percentage in notebooks, the threshold needs to be higher, at 54 elements, since Jupyter notebooks have a ``heavier tail'' of larger clones. The same can be visualized as a QQ-plot (Figure~\ref{fig:quantiles}b). You can find additional technical details and figures in our online appendix~\cite{appendix}.

\textbf{Future work.} Currently, the obtained threshold is being evaluated by the development teams of Datalore and DataSpell, we plan to carry out UX studies with users to compare the threshold's comfortability.
We believe that our pipeline, while simple, can be useful for various practical applications of clone detection. It can be used for any other family of languages, for example, for JVM-based languages. 