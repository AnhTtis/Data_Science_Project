\section{Related Works}
This section reviews related methods for facial expression recognition and self-paced learning.
\vspace{0.2cm}
\par
\textbf{Facial Expression Recognition.} Over the past decades, classical facial expression classification techniques such as neural networks \cite{1998Zhang, 2004Tian}, support vector machine \cite{2005Bartlett}, bayesian network \cite{2002Cohen} and rule-based classifiers \cite{2000Pantic, 2004Pantic, 2006Dynamics} have been well proposed. Especially as the rise of the CNN architectures \cite{krizhevsky2012imagenet, szegedy2015going}, excellent performance has been shown on facial related recognition tasks \cite{yim2015rotating, zhu2013deep}. With the development of deep learning, researchers are devoted to obtaining effective expression information. Ruan \emph{et al}. \cite{2021Feature} view the expression information as the combination of the shared information across different expressions as well as unique information. Ding \emph{et al}. \cite{2016FaceNet2ExpNet} propose a novel FaceNet2ExpNet for the training of expression recognition network based on static image, where a two-stage training algorithm is designed by first using face net for convolution layers recognition in expression net and then refining it with fully connected layers. In dynamic expression recognition, Liu \emph{et al}. \cite{2014Liu} solve the temporal alignment and semantics-aware dynamic representation issues by manifold modeling of videos based on a novel mid-level representation. Zhao \emph{et al}. \cite{2016Peak} enable the natural evolution of expressions from non-peak to peak during the learning process using a novel peak-piloted deep network architecture. Yang \emph{et al}. \cite{2018Yang} generate subject's neutral face using generative adversarial networks, and then extract expressive features embedded in the encoder and decoder. 

In terms of disturbance disentangling, it is widely used to eliminate disturbing factors such as identity and pose in order to get the holistic expression features of images. Meng \emph{et al}. \cite{2017Identity} ameliorate the facial variety variations and propose identity-aware convolutional neural network by using an identity-sensitive contrastive loss amid the identity-related information learning process. %, ending up reaching a better accuracy rate. 
Zhang \emph{et al}. \cite{2018Joint} use generative adversarial network to alleviate pose-invariance along with simultaneous facial image synthesis and FER. Wang \emph{et al}. \cite{2019Identity} use adversarial feature learning method to reduce the disturbance caused by both facial identity and pose variations, yet those methods can only handle one or two disturbing factors. Ruan \emph{et al}. \cite{2020Ruan} propose disturbance-disentangled learning method to simultaneously disentangle multiple disturbing factors by taking advantage of multi-task learning and adversarial transfer learning.
\vspace{0.2cm}
\par
\textbf{Self-Paced Learning.} Self-paced learning (SPL) is a recently proposed methodology designed by mimicking the learning rules of humans. It processes training data from easy to hard step by step. As a consequence, during the learning process the model can be built from general to specific, thus can better fit the data and not be misguided easily \cite{Kumar2010Self}. Various degrees of success have been achieved using variants of SPL methods. Ma \emph{et al}. propose self-paced co-training in which SPL is applied to multi-view or multi-modality problems \cite{2017Fan}. In \cite{2017SelfMixture}, Han \emph{et al}. propose a novel self-paced regularizer for mixture of regressions.
%poorly conditioned linear sub-regressors was ameliorated by the effort of Han et al on the field of regression mixture with SPL. 
Zhao \emph{et al}. \cite{2015curriculum} realize a more effective real valued (soft) weighting manner from the original conventional binary (hard) weighting scheme for SPL. In \cite{2020ren} and \cite{2017ren}, Ren \emph{et al}. introduce soft weighting schemes of SPL to reduce the negative influence of outliers and noisy samples. In \cite{Huang0P021}, Huang \emph{et al.} propose a non-linear fusion SPL method for multi-view clustering to reduce the negative impact caused by variation of characteristics and qualities of different views. In \cite{ijms23073900}, Zhao \emph{et al.} introduce a single cell self-paced clustering for single cell RNA sequencing. In computer vision, deep learning methods usually achieve remarkable performance but also suffer from the non-convexity of the solution space and data noisy issues. Thus, SPL has also been widely used in deep neural networks. For instance, Li \emph{et al.} \cite{2017Li} seek to enhance the learning robustness of CNNs with SPL and propose SP-CNNs, in which the imbalance of training data in the discriminative model can be omitted. 
However, to our knowledge, the usage of SPL in FER tasks has not been well explored except \cite{ShaoWLHP022}.

