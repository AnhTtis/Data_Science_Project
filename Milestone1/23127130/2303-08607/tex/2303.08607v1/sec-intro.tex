\section{Introduction}
\label{sec:intro}

SVS aims to generate a singing voice from a music score that contains pitch and duration information organized by notes with corresponding lyrics~\cite{cook1996singing}. Different from the similar task of text-to-speech (TTS), it is difficult to obtain large public singing datasets for SVS \cite{baseline1, guo2022singaug, ren2020deepsinger}, due to the copyright restrictions and the strict recording environment requirements. Moreover, singing has higher variability than spoken language, as singers have the flexibility to make changes to scores, making singing more natural and pleasing. For example, the pronunciation of the same word can vary significantly due to pitch and tempo changes in singing. 
Therefore, it is challenging to learn the pronunciation of lyrics and make the singing match the melodic changes in the music score, especially on small-scale SVS corpora. Recently, a work \cite{Karaoker} trains a singing-data-free SVS model on speech datasets to imitate the voice of a singing template. Nevertheless, a common practice in current score-based SVS systems is to adopt acoustic feature processing (AFP) strategies in the acoustic model to enhance the learning of singing pronunciation based on limited SVS data.
%The common solution of these issues is to adopt feature processing strategies for the acoustic model of SVS to alleviate the variability and scarcity of the SVS data.
%\qin{we need a logic link from here to connect why we care about feature processing strategy in this work}

\begin{figure}[t]
	\centering
	\includegraphics[width=1.0\columnwidth]{input.pdf}
	\caption{\small (a) Music score input. Black bold vertical lines denote note splits. (b) Manually labeled phoneme time sequence. White bold lines indicate syllable splits and red dotted lines indicate phoneme splits in each syllable.}
	\label{fig:input}
\end{figure}

\begin{figure*}[t]
	\centering
	\includegraphics[width=1.0\linewidth]{3.pdf}
  \vspace{-15pt}
	\caption{\small Different AFP strategy. Details of \textit{\textbf{Type 1}} and \textit{\textbf{Type 2}} are introduced in Sec.~\ref{sec:intro} and \textit{\textbf{PHONEix}} are in ~\ref{ssec: Acoustic Feature Processing Strategy}. Blocks of different colors represent phoneme duration. The green blocks are from the music score and the yellow blocks are from annotation. The gray block is obtained by HMM-based forced alignment. The orange block is predicted by the phoneme distribution predictor. In column \textit{\textbf{Type 2}} strategy and the red lines are division of vowels and consonants. The red phonemes in phone-level feature input are redundant phonemes and missing phonemes caused by misalignments between notes and annotation.}
	\label{fig:AFP}

 \end{figure*}
 
\begin{figure}[t]
	\centering
	\includegraphics[width=1.0\columnwidth]{model.pdf}
	\caption{\small The SVS system architecture with \textit{\textbf{PHONEix}} AFP strategy. Details are introduced in Sec.~\ref{ssec: overall framework}. The green blocks can be adjusted to accommodate different acoustic models.}
	\label{fig:model}
\end{figure}

%The actual singing is more flexible and there shows subtle differences from the \textit{\textbf{\textit{\textbf{Type 1}}}} music score to make the singing sound more natural and tuneful. The pronunciation of the same syllable changes with pitch and tempo changes in singing greatly. Therefore, it is challenging to learn the pronunciation of the lyrics on a small-scale SVS dataset and make singing conform to the melody changes in the music score.

%\qin{we need a logic link to connect above mentioned lacking large-scale SVS data to our work on feature processing}

%Before deep learning, previous SVS systems use concatenation \cite{kenmochi2007vocaloid,bonada2016expressive} or statistical parameters \cite{oura2010recent,saino2006hmm}. These traditional methods usually have strong dependencies on corresponding training corpora and the generated singing voices are usually lacking flexibility. Since the recent progress of deep learning, the concept of sequence-to-sequence models has been adopted to build end-to-end SVS systems~\cite{VISinger}. The acoustic model passes the acoustic feature to the vocoder to generate singing audio. Currently, the state-of-the-art SVS systems \cite{VISinger,lu2020xiaoicesing} apply an encoder-decoder-based acoustic model and include a duration predictor proposed in TTS~\cite{FastSpeech} to expand phoneme-level features to frame-level sequences.

Current AFP strategies for SVS acoustic models can be roughly categorized into two types. 1) \textbf{\textit{Type~1}} AFP strategy is to use the original note pitch and whole note duration from the music score (i.e., Fig.~\ref{fig:input}~(a)) as the 
pitch and duration input, with no distinction between vowels and consonants. 
%Then, the phoneme duration is calculated through statistical rule-based, force-alignment \cite{mcauliffe2017montreal} or heuristic method \cite{} to serve as a supervision signal of the duration predictor. 
To further distinguish vowels and consonants, a duration predictor is built to produce fine-grained phoneme-level duration, which is trained based on supervision calculated by force-alignment \cite{oura2010recent, chen2020hifisinger, liu2022diffsinger, hono2021sinsy, yi2019singing, wang2022mr}, heuristics \cite{tae2021mlp, choi2022melody, lu2020xiaoicesing, baseline2} etc. % mcauliffe2017montreal 
%The advantage of the standardized music score is that the input phoneme and pitch sequence are strictly aligned by note level. 
The advantage of this type of feature processing strategy is that the input phoneme and pitch sequence are strictly aligned at the note level based on the music score.
However, as illustrated in Fig.~\ref{fig:input}, there is a gap between the \textit{\textbf{Type~1}} music score and the actual singing voice in phoneme duration distribution. Acoustic models are not able to adapt the distribution with only music scores. 
%\qin{need a better summary of the following other type of strategy}
2) \textbf{\textit{Type~2}} AFP strategy is to use a labeled phoneme duration sequence (i.e. Fig.~\ref{fig:input}~(b)) and the note sequence from the music score (i.e. Fig.~\ref{fig:input}~(a)) as input \cite{zhang2022susing, lee2021n, zhuang2021litesing, liu2021vibrato, zhang2022wesinger, wang2022singing, gu2021bytesing, VISinger, kim2018korean,nakamura2019singing,hono2018recent}. The labeled phoneme duration sequence provides a supervision signal for duration predictor to predict the actual duration of phonemes and notes given \textit{\textbf{Type~1}} phoneme and note duration from the music score. 
The disadvantage is that the labeled phoneme duration sequence is annotated based on the singing voice and it is not exactly aligned with the music score. 
This misalignment will lead to redundant phonemes and missing phonemes, which will hurt the generation from the actual singing voice. Moreover, different from the training phase, the actual phoneme duration is unavailable during inference, such discrepancy between training and inference adversely leads to a great restriction of application scenarios for SVS. Overall, the divergence between music score and actual singing cannot be well solved in the acoustic model by these two types of strategies. %\qin{this final touch of our motivation a bit confusing}

% Considering the gap between the music score and actual singing in the acoustic model and the difficulty of obtaining accurate feature input at the phoneme level,
To mitigate the gap between the music score and actual singing, 
we propose a new AFP strategy, named \textit{\textbf{PHONEix}}, for the SVS acoustic model. Specifically, the acoustic model accepts the music score as input, and then the proposed \textbf{phoneme distribution predictor} learns the phoneme durations, adapting to the actual pronunciation. Finally, the aligned \textit{\textbf{Type 1}} score features (phoneme, pitch, phoneme duration) are encoded and then length regulated under the guidance of the actual phoneme duration to address the gap (illustrated in Fig.~\ref{fig:AFP}). In summary, the contributions of this work include:
\begin{itemize}
    \item We propose a new AFP strategy \textit{\textbf{PHONEix}} for SVS, which narrows the gap between the music score and the singing voice by feeding \textit{\textbf{Type 1}} duration and actual duration successively into the acoustic model. \textit{\textbf{PHONEix}} can be easily migrated to different SVS systems.
    \item We evaluate the proposed strategy on different SVS models. Extensive objective and subjective experiments demonstrate the effectiveness of \textit{\textbf{PHONEix}}, which brings significant improvement.
\end{itemize}

% 1) We apply an acoustic feature processing strategy for SVS system. It narrows the gap between the musical score and the singing voice by feeding \textit{\textbf{\textit{\textbf{Type 1}}}} duration and actual duration successively into the acoustic model. 

% 2) A phoneme distribution predictor is integrated to split note duration into phoneme-level duration before we feed them into the encoder-decoder-based acoustic model. This module can be easily migrated to different SVS systems. 

 % Mel-cepstral distortion (MCD) rises 0.67 on average (See Table1). Objective scores also show improvement in singing.

The rest of this article is organized as follows. Section 2 presents the proposed AFP strategy and phoneme distribution predictor. Section 3 presents our experimental setup, results, and discussion. Finally, Section 4 concludes the paper.

