\section{Conclusion, Limitations, and Future Work}
\label{sec:future}
We presented \ours, a NeRF editing method conditioned on text and sketch. Using novel loss functions, our framework allows for local editing of neural fields.
\begin{wrapfigure}{r}{0.2\textwidth} 
\vspace{-10pt}
  \begin{center}
    \includegraphics[width=0.2\textwidth]{figs/failures_Ali.jpg}
  \end{center}
    \vspace{-15pt}
 \vspace{1pt}
\end{wrapfigure} 
Similar to previous works \cite{poole2022dreamfusion, lin2022magic3d, metzer2022latent}, our approach utilizes the SDS Loss and may be vulnerable to the well-known "multiface issue" (inset figure) depending on the choice of diffusion model and prompt. Our method supports a single set of prompt and sketch views at a time. A simple workaround is to apply our method multiple times progressively (Fig.~\ref{fig:progressive}). 
Our results rely on the publicly available Stable-Diffusion model \cite{rombach2021highresolution}, which is less amenable to directional text prompts and produces lower quality 3D generated outputs compared to commercial diffusion models used by previous works~\cite{poole2022dreamfusion, lin2022magic3d}. In Fig~\ref{fig:diff_diff} we show that it is possible to get better results by using the Deepfloyd-IF model \cite{deepfloyd}.


Future directions may expand our method to better support for non-opaque materials, or condition on other modalities, possibly through the diffusion model. More research may further extend the usage of sketch scribbles for animation, similar to \cite{dvoro2020monstermash}. 



% \orrc{In addition, the interface of our method may further close the gap with non data-driven methods, through allowing inflated single sketch views or other primitive based sketch interfaces. Mention also we didn't explore half-transparent objects enough

% \orr{
% Limitations: 1. Janus effect / multiface problem (cat with santa hat), 2. sketching multiple disjoint regions at once. 3. mention that quality presented in this work depend on the diffusion model used? (we can't compete with the larger IMAGINE / e-diffi).

% Notes: remember thanking people: Andrey for SGMT code and mention mesh sources. (the cat, the plate, the horse)
% }
