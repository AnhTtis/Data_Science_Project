% !TEX encoding = UTF-8 Unicode 
% !TEX TS-program = pdflatex
 
\documentclass[a4paper,onecolumn,11pt]{IEEEtran}

\usepackage{enumitem}
\usepackage{multirow}
\usepackage{balance}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{latexsym}
\usepackage{cite}
\usepackage{cancel}
\usepackage{url}
\usepackage{mathrsfs}
\usepackage{empheq}
\usepackage[normalem]{ulem}
%\sout{文字} %删除线
%\uwave{文字} %波浪线
%\xout{文字} %斜删除线
%\uuline{文字}  %双下划线

\allowdisplaybreaks
\setlength\abovedisplayskip{4pt}
\setlength\belowdisplayskip{1.1pt}

\newtheorem{algorithm}{Algorithm}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}

\newcommand\tie {{\mathscr{T}}}
\newcommand\notie{{\mathscr{N}}}
\newcommand\ML {{\mathscr{M}}}
\renewcommand\Re {{\mathbb{R}}}
\newcommand\bydef{\triangleq}

\newcommand\Ac   {{\cal A}}
\newcommand\Bc   {{\cal B}}
\newcommand\code {{\cal C}}
\newcommand\codeb {\mathbf{C}}
\newcommand\Dc  {{\cal D}}
\newcommand\Ic  {{\cal I}}
\newcommand\Jc {{\cal J}}
\newcommand\Gc {{\cal G}}
\newcommand\Hc {{\cal H}}
\newcommand\Oc  {{\cal O}}
\newcommand\Pc  {{\cal P}}
\newcommand\Qc  {{\cal Q}}
\newcommand\Rc  {{\cal R}}
\newcommand\Sc  {{\cal S}}
\newcommand\Sac {{\mathscr{S}}}
\newcommand\Eac {{\mathscr{E}}}
\newcommand\Tc  {{\cal T}}
\newcommand\Tsc {{\mathscr{T}}}
\newcommand\Nc  {{\cal N}}
\newcommand\Uc  {{\cal U}}
\newcommand\Xc   {{\cal X}}
\newcommand\Yc  {{\cal Y}}
\newcommand\Zc  {{\cal Z}}
\newcommand\calC  {{\cal C}}
\newcommand\xhat {{\hat x}}
\newcommand\Xhat {{\hat X}}
\newcommand\What {{\hat W}}
\newcommand\xu   {{\underline x}}
\newcommand\zu   {{\underline z}}
\newcommand\Fu   {{\underline F}}
\newcommand\Wu   {{\underline W}}
\newcommand\Xu   {{\underline X}}
\newcommand\Zu   {{\underline Z}}
\newcommand\cb   {{\boldsymbol c}}
\newcommand\Xb   {{\boldsymbol X}}
\newcommand\E    {{\mathbb E}}
\newcommand{\lis}[1]{\limsup_{#1\biggarrow\infty}}
\newcommand{\lif}[1]{\liminf_{#1\biggarrow\infty}}
\newcommand*{\qedsymbol}{\hfill\ensuremath{\blacksquare}}
\newcommand\Supp {{\cal S}}

\definecolor{darkgreen}{rgb}{0, 0.5, 0}
\definecolor{poning}{rgb}{0.2,0.2,0.6}
\definecolor{poning2}{rgb}{0.6,0.2,0.2}
\definecolor{poning2d}{rgb}{0.3,0.1,0.1}

\newcommand\red[1]{\textcolor{red}{#1}}
\newcommand\blue[1]{\textcolor{blue}{#1}}
\newcommand\magenta[1]{\textcolor{magenta}{#1}}
\newcommand\lblue[1]{\textcolor{teal}{#1}}

\providecommand{\carol}[1]{\begin{quotation}\lblue{#1}\end{quotation}}

\flushbottom

\newcounter{step}

\begin{document}

\begin{spacing}{1.5}

\title{\Huge{On Decoder Ties for the Binary Symmetric Channel with Arbitrarily Distributed Input}}

\author{
\vspace{0.1in}

\IEEEauthorblockN{
     Ling-Hua Chang\IEEEauthorrefmark{1},
     Po-Ning~Chen\IEEEauthorrefmark{2},
     and
     Fady Alajaji\IEEEauthorrefmark{3}
%\thanks{In preparation for submission to Entropy.}    
\thanks{\IEEEauthorrefmark{1}Department of Electrical Engineering, Yuan Ze University, Taiwan, R.O.C. (iamjaung@gmail.com).}
\thanks{\IEEEauthorrefmark{2}Institute of Communications Engineering, National Yang-Ming Chiao-Tung University, Taiwan, R.O.C. (poningchen@nycu.edu.tw).}
\thanks{\IEEEauthorrefmark{3}Department of Mathematics and Statistics,  Queen's University,  Kingston, ON,  Canada (fa@queensu.ca).}
\thanks{
The work of Ling-Hua Chang is supported by the Ministry of Science and Technology, Taiwan, R.O.C.~(Grant\,No.\,MOST\,109-2221-E-155-035-MY3). 
The work of Po-Ning Chen is supported by the Ministry of Science and Technology, Taiwan, R.O.C.~(Grant\,No.\,MOST\,110-2221-E-A49-024-MY3). 
The work of Fady Alajaji is supported by the Natural Sciences and Engineering Research Council of Canada.
}}} 

\end{spacing}
\maketitle

\begin{spacing}{1.65}

\begin{abstract}
The error probability of block codes sent under a non-uniform input distribution over the memoryless binary symmetric channel (BSC) and decoded via the maximum a posteriori (MAP) decoding rule is investigated. It is proved that the ratio of the probability of MAP decoder ties to the probability of error when no MAP decoding ties occur grows at most linearly in blocklength, thus showing that decoder ties do not affect the code's error exponent. This result generalizes a similar recent result shown for the case of block codes transmitted over the BSC under a uniform input distribution.
\end{abstract}


\bigskip\noindent
{\bf Keywords:} Binary symmetric channel, block codes, non-uniformly distributed channel inputs, joint source-channel coding, maximum a posteriori (MAP) decoding, decoder ties, error probability, error exponent.

%\newpage 
\section{Introduction}

Consider the classical channel coding context, where we send a block code through the memoryless binary symmetric channel (BSC) with crossover probability $0<p<1/2$. Given a sequence of binary codes $\{\code_n\}_{n\geq 1}$ with $n$ being the blocklength, we denote the sequence of corresponding minimal probabilities of decoding error under \emph{maximum a posteriori} (MAP) decoding by $\{a_n\}_{n\geq 1}$. It was recently shown in \cite{us} that if the channel input is uniformly distributed over $\code_n$, decoder ties (which occur when two or more codewords in $\code_n$ are identified by the decoder as the estimated transmitted codeword) do not affect the error exponent of $a_n$. The error exponent or reliability function of a block coding communication system represents the largest rate of exponential decay of the system's probability of decoding error as the coding blocklength grows to infinity (e.g., see \cite{SGB67-I,SGB67-II,mceliece77,gallager,viterbi,csiszar,blahut,barg05,harout07,dalai13,burnashev15,csiszar80,ZAC06}).

It is known that uniformly distributed data achieves the largest entropy rate and leaves no room for data compression. Thus, ideally compressed data should exhibit uniform distribution for all blocklength $n$. However, this setting is often impractical due to the sub-optimality of the implemented data compression schemes. Instead, we generally have non-uniformly distributed data after compression in the form of residual redundancy such as in speech or image coding (e.g., \cite{APF96,XHH96}). Furthermore, one may have a compressed source that can be divided into several groups, within each of which the symbols are equally probable. Decoder ties can thus occur with respect to two (or more) codewords corresponding to symbols within the same group. 

In this paper, we consider a non-uniform prior distribution over $\code_n$ and prove that 
decoder ties, under optimal MAP decoding, still have linear and hence sub-exponential impact on the error probability $a_n$, thus extending the result established in \cite{us} for the case of a uniform prior distribution over $\code_n$. Since our problem falls within the general framework of joint source-channel coding for point-to-point communication systems, we refer the reader to \cite{APF96,H95,XHH96,ZAC06,G07,DK09,FPPV10}, \cite[Section~4.6]{AC18} and the references therein for theoretical studies on this subject as well as practical designs that outperform separate source and channel coding under complexity or delay constraints.

The proof technique used in \cite{us} is based on the observation that there are two types of decoding errors. One is that the received tuple at the channel output induces no decoder ties but the corresponding decoder decision is wrong. The other is that the received tuple at the channel output causes a decoder tie, but the decoder picks the wrong codeword.
%One is that the channel output induces no decoder tie but the corresponding decoder decision is wrong. The other is that the tie breaker picks the wrong codeword when the channel output induces a tie. 
As a result, the MAP error probability $a_n$ can be upper bounded by the sum of two terms, $b_n$ and $\delta_n$, where $b_n$ is the probability of the first type of decoding errors, and $\delta_n$ is the probability of decoder ties regardless of whether the tie breaker misses the correct codeword or not. Under the assumption that the channel input is uniformly distributed over block code $\code_n$ for each blocklength $n$ and an arbitrary sequence of codes $\{\code_n\}_{n\geq 1}$, it was shown in \cite{us} that flipping a properly selected bit component of the channel output that causes a decoder tie can produce a unique channel output that leads to the first type of decoding errors. An analysis of this bit-flipping manipulation leads to the main result in \cite{us} that the ratio $\delta_n/b_n$ grows at most linearly in $n$.
However, this flipping technique no longer works when non-uniform channel inputs are considered. To tackle this problem, we judiciously separate the channel output tuples that induce decoder ties into two groups, one group consisting of output tuples that do not fulfill the above flipping manipulation property and the other group composed of the remaining output tuples (i.e., the complement group). We then show that the probability of the former group is upper bounded by that of the latter group, and therefore $\delta_n/b_n$ remains growing at most linearly in blocklength $n$ under arbitrary channel input statistics. Note that the group that fails the flipping property is an empty set when channel input is uniformly distributed over $\code_n$, thereby making the result in \cite{us} a special case of the extended result in this paper. 
The rest of the paper is organized as follows. Section \ref{MainR} presents the main result and highlights the key steps of the proof. The proof is then provided in full in Section~\ref{Proof}. Finally, conclusions are drawn in Section~\ref{Con}.

Throughout the paper, we denote $[M]\triangleq \{1,2,\ldots,M\}$ for positive integer $M$, and set $d(x^n, y^n|\Sc)$ to be the Hamming distance between $n$-tuples $x^n=(x_1,x_2,\ldots,x_n)$ and $y^n=(y_1,y_2,\ldots,y_n)$ with the indices of the tuples restricted to $\Sc\subseteq[n]$. By convention, we set $d(x^n,y^n|\Sc)=0$ when $\Sc=\emptyset$, and use $d(x^n,y^n)$ to represent  $d(x^n,y^n|[n])$.

\section{Main Result}
\label{MainR}

Consider a binary code $\code_n\subseteq\{0,1\}^n$ with fixed blocklength $n$ and size $M$ to be used over the memoryless BSC with crossover probability $0<p<\frac 12$. Denote the prior probability on $\code_n$ by $P_{X^n}$ and hence $P_{X^n}(\code_n)=1$. Without loss of generality, we assume that all codewords in $\code_n$ occur with positive probability, i.e., $P_{X^n}(x^n)>0$ for all $x^n\in\code_n$; hence, $\code_n$ is the support of $P_{X^n}$.

It is known the minimal probability of decoding error is achieved by the MAP decoder, which upon the reception of the channel output $y^n\in\{0,1\}^n$ estimates the codeword $x^n\in\code_n$ according to
\begin{IEEEeqnarray}{rCl}\label{MAP}
e(y^n)=\arg\max_{u^n\in\code_n}P_{X^n|Y^n}(u^n|y^n),
\end{IEEEeqnarray}
where $P_{X^n|Y^n}$ is the posterior conditional distribution of $X^n$ given $Y^n$. We can see from \eqref{MAP} that if more than one $u^n\in\code_n$ achieves the maximum value of $P_{X^n|Y^n}(u^n|y^n)$ for a given $y^n$, a decoder tie occurs, in which case the set of these $u^n$, denoted conveniently as $\{e(y^n)\}$, contains more than one element. As a result, an erroneous MAP decision is made if one of the two situations occurs: $i)$ the transmitted codeword does not belong to $\{e(y^n)\}$; $ii)$ the transmitted codeword belong to $\{e(y^n)\}$ and $|\{e(y^n)\}|>1$, but the tie breaker picks the wrong one from $\{e(y^n)\}$. By conveniently denoting $\code_n=\{\cb_1,\cb_2,\cdots, \cb_M\}$, the probability of the first situation acts as a lower bound $b_n$ for $a_n$ (i.e., $b_n\le a_n$),  where \cite{us}
\begin{IEEEeqnarray}{rCl}
b_n&\triangleq&\sum_{i=1}^M P_{X^n}(\cb_i)\,
P_{Y^n|X^n}\Big(\Big\{y^n\in\{0,1\}^n:P_{X^n|Y^n}(\cb_i|y^n)<\max_{r\in[M]\setminus\{i\}}P_{X^n|Y^n}(\cb_r|y^n)\Big\}\Big).
\label{b_p}
\end{IEEEeqnarray}
It is shown in \cite{conf} that $b_n$ exactly equals the generalized Poor-Verd\'u (lower) bound \cite{gpv,pv} as its tilting parameter approaches infinity. The probability of the second situation is bounded above by the probability that the transmitted codeword belong to $\{e(y^n)\}$ and $|\{e(y^n)\}|>1$, disregarding whether the tie breaker picks the wrong codeword or not, and this upper bound can be expressed as:
\begin{IEEEeqnarray}{rCl}
\delta_n&\triangleq&\sum_{i=1}^M P_{X^n}(\cb_i)\,
P_{Y^n|X^n}\Big(\Big\{y^n\in\{0,1\}^n:P_{X^n|Y^n}(\cb_i|y^n)=\max_{r\in[M]\setminus\{i\}}P_{X^n|Y^n}(\cb_r|y^n)\Big\}\Big).
\label{delta_p}
\end{IEEEeqnarray}
We thus have 
\begin{equation}\label{eq:anbndn}
b_n\leq a_n\leq b_n+\delta_n.
\end{equation}
By proving the inequality 
\begin{equation}
\delta_n\leq 2qnb_n, 
\end{equation}
where $q\triangleq\frac{1-p}p>1$, we have our main result as follows.

\begin{theorem}\label{theorem}
For any sequence of binary codes  $\{\code_n\}_{n\geq 1}$ and prior probabilities
$\{P_{X^n}\}_{n\geq 1}$ used over the BSC, we have
\begin{equation}\label{eq:bnan}
b_n\leq a_n\leq \left(1+2qn\right)b_n.
\end{equation}
\end{theorem}

\begin{remark}\label{remark1}
Theorem~\ref{theorem} implies that the relative deviation of $a_n$ from $b_n$ is at most linear in the blocklength $n$ and the impact of decoder ties in \eqref{delta_p} to $a_n$ is only sub-exponential. Consequently, $a_n$ and $b_n$ must have the same error exponent. Note also that the upper bound in \eqref{eq:bnan} differs from the  result in \cite[Eq.~(5)]{us} by an additional multiplicative factor of $2$ in the $qn$ term. As explained in the introduction section, this is a consequence of the fact that the probability of the group of channel output tuples that cause decoder ties but fail the flipping manipulation property is upper bounded by that of the remaining tie-inducing channel outputs. The full technical details are provided in Section~\ref{Sec_28}.
\end{remark}

To facilitate understanding of the proof of Theorem~\ref{theorem}, we highlight its main steps here before presenting in full detail in the next section. The main symbols used in the paper are summarized in Table~\ref{tab:1}, where $\Tc_{j|i}$, $\Nc_{j|i}$ and $\Sc_{1,j}^{(m)}$ are defined differently from the terms in \cite{us} that use the same notation.

\begin{table*}[t]
\begin{center}
\caption{Summary of the main symbols used in this paper}\label{tab:1}
{\small
\begin{tabular}{|c|l|c|}
\hline\hline
{\bf Symbol}&{\bf Description}&{\bf Defined in}\\\hline\hline
$[M]$&\multicolumn{2}{|l|}{A shorthand for $\{1,2,\ldots,M\}$}\\\hline
$\code_n$&\multicolumn{2}{|l|}{The code $\big\{\cb_1,\cb_2,\ldots,\cb_n\big\}$ with $\cb_1$ being the all-zero codeword}\\\hline
$d(u^n,v^n|\Sc)$&\multicolumn{2}{|l|}{The Hamming distance between the portions of $u^n$ and $v^n$ with indices in $\Sc$}\\\hline\hline
\multicolumn{3}{|l|}{\emph{All terms below are functions of $\code_n$ (this dependence is not explicitly shown to simplify notation)}}\\\hline\hline
$\Tc_i$&The set of channel outputs $y^n$ inducing a decoder tie when $\cb_i$ is sent &\eqref{p1-tn_a}\\ \hline
$\Nc_i$&The set of channel outputs $y^n$ leading to a tie-free decoder decision error when $\cb_{i}$ is sent &\eqref{eq:no-ties} \\\hline
$\Ic_i(y^n)$& The set $\{m\in[M]\setminus\{i\}: y^n\in\Tc_m\}$ for $y^n\in \Tc_i$&\eqref{equal}\\\hline
$\Sc_{i,j}$&The set of indices for which the components of $\cb_i$ and $\cb_j$ differ&\\\hline
$\ell_{i,j}$&The size of $\Sc_{i,j}$, i.e., $|\Sc_{i,j}|$&\\\hline
$\Tc_{j|i}$&The subset of $\Tc_i$ consisting of channel outputs $y^n$ such that $j$ is the minimal  &\eqref{p2_a}\\
&number $r$ in $\Ic_i(y^n)$ satisfying $d(\cb_i,y^n|\Sc_{i,r})<\ell_{i,r}$ &\\\hline
$\Nc_{j|i}$&The subset of $\Nc_i$ consisting of channel outputs $y^n$ that satisfy $P_{X^n,Y^n}(\cb_i,y^n)\cdot q=$&\eqref{p2_b}\\
&$P_{X^n,Y^n}(\cb_j,y^n)\cdot\frac 1q$ and that are not included in $\Nc_{r|i}$ for $r\in[j-1]\subset\{i\}$&\\
\hline
$\Tsc_{j|i}$&The subset of $\Tc_i\setminus\left(\bigcup_{h\in[M]\setminus\{i\}}\Tc_{h|i}\right)$ consisting of channel outputs $y^n$  &\eqref{p2_c}\\
&such that $j$ is the minimal number in $\Ic_i(y^n)$ &\\
\hline
$\Sc_{1,j}^{(m)}$&The subset of $\Sc_{1,j}$ defined according to whether each index in $\Sc_{1,j}$ is in each&\eqref{scjm}\\
&of $\Sc_{1,2}$, $\ldots$, $\Sc_{1,j-1}$, $\Sc_{1, j+1}$, $\ldots$, $\Sc_{1,M}$&\\\hline
$\Sac_{1,j}^{(m)}$&The union of $\Sc_{1,j}^{(1)}$, $\Sc_{1,j}^{(2)}$, $\ldots$, $\Sc_{1,j}^{(m)}$&\eqref{def1sac}\\\hline
$\ell_{1,j}^{(m)}$&The size of $\Sac_{1,j}^{(m)}$, i.e., $|\Sac_{1,j}^{(m)}|$&\\\hline
$\eta_k$&The mapping from $k\in \{0,1,\ldots,\ell_j-1\}$ to $[2^{M-2}]$ used for partitioning $\Tc_{j|1}$ into $\ell_{1,j}$&\eqref{mappingkm}\\
&subsets $\{\Tc_{j|1}(k)\}_{0\leq k<\ell_{1,j}}$&\\\hline
$\Tc_{j|1}(k)$&The $k$th partition of $\Tc_{j|1}$ for $k=0$, $1$, $\ldots$, $\ell_{1,j}-1$&\eqref{p3_a}\\\hline
$\Nc_{j|1}(k)$&The $k$th subset of $\Nc_{j|1}$ for $k=0$, $1$, $\ldots$, $\ell_{1,j}-1$&\eqref{p3_b}\\\hline
$\Uc_{j|1}(k)$&The set of representative elements in $\Tc_{j|1}(k)$ for partitioning $\Tc_{j|1}(k)$&\\\hline
$\Tc_{j|1}(u^n;k)$&The subset of $\Tc_{j|1}(k)$ associated with $u^n\in\Uc_{j|1}(k)$&\eqref{p4_a}\\\hline
$\Nc_{j|1}(u^n;k)$&The subset of $\Nc_{j|1}(k)$ associated with $u^n\in\Uc_{j|1}(k)$&\eqref{p4_b}\\\hline\hline
\end{tabular}
}
\end{center}
\end{table*}

\textit{Overview of the Proof}: 
Given that codeword $\cb_i$ is sent over the channel, $i \in [M]$, let $\Tc_i$ denote the set of output tuples $y^n$ that result in MAP decoding ties:
\begin{IEEEeqnarray}{rCl}
 \Tc_i&\triangleq&\bigg\{y^n\in\{0,1\}^n: P_{X^n|Y^n}(\cb_i|y^n)=\max_{r\in[M]\setminus \{i\}} P_{X^n|Y^n}(\cb_r|y^n)\bigg\}\\
 &=&\bigg\{y^n\in\{0,1\}^n:  P_{X^n,Y^n}(\cb_i,y^n)=\max_{{ r\in[M]\setminus \{i\}}} P_{X^n,Y^n}(\cb_r,y^n)\bigg\},\label{p1-tn_a}
\end{IEEEeqnarray}
where \eqref{p1-tn_a} holds because $P_{X^n|Y^n}(x^n|y^n)=\frac{P_{X^n,Y^n}(x^n,y^n)}{P_{Y^n}(y^n)}$. Then, $\delta_n$ in \eqref{delta_p} can be re-written as:
\begin{equation}\label{delta_n}
\delta_n=\sum_{i\in [M]}P_{X^n}(\cb_i)\,P_{Y^n|X^n}\big(\Tc_i|\cb_i\big)=\sum_{i\in [M]}P_{X^n,Y^n}(\cb_i,\Tc_i).
\end{equation} 
Similarly, let $\Nc_i$ denote the set of output tuples $y^n$ which guarantee a tie-free MAP decoding error when $\cb_i$ is transmitted over the channel:
\begin{IEEEeqnarray}{rCl}
 \Nc_i&\triangleq&\bigg\{y^n\in\{0,1\}^n: P_{X^n|Y^n}(\cb_i|y^n)<\max_{r\in[M]\setminus \{i\}} P_{X^n|Y^n}(\cb_r|y^n)\bigg\}\\
 &=&\bigg\{y^n\in\{0,1\}^n: P_{X^n,Y^n}(\cb_i,y^n)<\max_{{ r\in[M]\setminus \{i\}}} P_{X^n,Y^n}(\cb_r,y^n)\bigg\}\label{eq:no-ties}.
\end{IEEEeqnarray}
Hence $b_n$ in \eqref{b_p} can be re-written as:
\begin{equation}\label{eq:bn-form}
b_n=\sum_{i\in [M]} P_{X^n}(\cb_i)\,P_{Y^n|X^n}(\Nc_i|\cb_i)=\sum_{i\in [M]}P_{X^n,Y^n}(\cb_i,\Nc_i).
\end{equation}
Note if $\delta_n=0$, then~\eqref{eq:anbndn} is tight and \eqref{eq:bnan} holds trivially; so without loss of generality, we assume in the proof that $\delta_n>0$, which implies that there exists at least one non-empty $\Tc_i$ for $i\in[M]$. Then, according to \eqref{delta_n} and \eqref{eq:bn-form}, 
we have that 
\begin{IEEEeqnarray}{rCl}
\frac{\delta_n}{b_n}&=&\frac{\sum_{i\in [M]}P_{X^n,Y^n}(\cb_i,\Tc_i)}{\sum_{i\in [M]}P_{X^n,Y^n}(\cb_i,\Nc_i)}\leq\frac{\sum_{i\in [M]:\Tc_i\neq\emptyset}P_{X^n,Y^n}(\cb_i,\Tc_i)}{\sum_{i\in [M]:\Tc_i\neq\emptyset}P_{X^n,Y^n}(\cb_i,\Nc_i)}.\label{tec2}
\end{IEEEeqnarray} 
We can upper-bound \eqref{tec2} by
\begin{equation}\label{rate-sum}
\frac{\sum_{i\in[M]:\Tc_i\neq\emptyset}P_{X^n,Y^n}(\cb_i,\Tc_i)}{\sum_{i\in[M]:\Tc_i\neq\emptyset} P_{X^n,Y^n}(\cb_i,\Nc_i)}\leq\max_{1\in[M]:\Tc_i\neq\emptyset}\frac{P_{X^n,Y^n}(\cb_i,\Tc_i)}{P_{X^n,Y^n}(\cb_i,\Nc_i)},
\end{equation}
where for convenience we will refer to an inequality of the form given in \eqref{rate-sum} as the \emph{ratio-sum} inequality. As a result, Theorem~\ref{theorem} holds if we can substantiate that $2qn$ is an upper bound for \eqref{rate-sum}. To this end, we will find a {\em proper partition} of $\Tc_i$ and {\em an equal number} of disjoint subsets of $\Nc_i$, of which the individual probabilities can be evaluated. For ease of notation, we denote the individual probabilities corresponding to the $K$-partition of $\Tc_i$ and $K$ disjoint subsets of $\Nc_i$ by $\{\alpha_k\}_{k=1}^K$ and $\{\beta_k\}_{k=1}^K$, respectively. Then,
we obtain that
\begin{eqnarray}
\frac{P_{X^n,Y^n}(\cb_i,\Tc_i)}{P_{X^n,Y^n}(\cb_i,\Nc_i)}\leq \frac{\sum_{k=1}^K\alpha_k}{\sum_{k=1}^K\beta_k}.
\end{eqnarray}
By showing that each individual ratio $\alpha_k/\beta_k$, $k\in [K]$, is bounded above by $2qn$, the ratio-sum inequality can again be applied to  complete the proof. 

\section{Proof of Theorem~\ref{theorem}}\label{Proof}

In \cite{us}, where a uniformly distributed prior probability $P_{X^n}$ over $\code_n$ is assumed, one can flip a properly selected bit in the output $y^n\in\Tc_i$ to convert it to a corresponding element in $\Nc_i$. In light of this connection, one can evaluate the ratio $\frac{P_{Y^n|X^n}(\Tc_i|\cb_i)}{P_{Y^n|X^n}(\Nc_i|\cb_i)}$. This approach, however, no longer works when a non-uniformly distributed prior probability is considered. Therefore, we have to devise a more judicious approach to extend the result in \cite{us} for a general prior probability.


 
\subsection{A Partition of Non-empty $\Tc_i$ and Corresponding Disjoint Subsets of $\Nc_i$}\label{part1}

In this section, instead of finding a disjoint covering of the set of decoder ties $\Tc_i$ as in \cite{us}, we establish a proper partition of $\Tc_i$ from Definitions \ref{D1} and \ref{D2}. This is one of the key differences from the techniques used in \cite{us}. Example \ref{example1} is given after Proposition~\ref{proposition} to illustrate Definitions \ref{D1} and \ref{D2}.

Given $y^n\in \Tc_{i}$ defined in \eqref{p1-tn_a}, there exists at least one $m\in[M]\setminus\{i\}$ such that
\begin{IEEEeqnarray}{rCl}
P_{X^n,Y^n}(\cb_i,y^n)=P_{X^n,Y^n}(\cb_m,y^n)=\max_{{ r\in[M]\setminus \{i\}}} P_{X^n,Y^n}(\cb_r,y^n)
.\label{AtleastOne}
\end{IEEEeqnarray}
 We collect the indices $m$ that satisfy \eqref{AtleastOne} in $\Ic_i(y^n)$ as follows:
%\begin{definition}\label{def1}
\begin{equation}\label{equal}
  \Ic_i(y^n)\triangleq \Big\{h\in[M]\setminus\{i\}:P_{X^n,Y^n}(\cb_i,y^n)=P_{X^n,Y^n}(\cb_h,y^n)=\max_{r\in[M]\setminus\{i\}}P_{X^n,Y^n}(\cb_r,y^n)\Big\}.
  \end{equation}
%\end{definition}
\begin{remark}\label{sub}
First, we note that $\Ic_i(y^n)$ is not empty as long as $y^n\in\Tc_i$. Also, for any $y^n\in\Tc_i$, we can infer from \eqref{equal} that $h\in \Ic_{i}(y^n)$ if and only if $y^n\in \Tc_{h}$.
\end{remark} 

In Definitions \ref{D1} and \ref{D2} that follow, we will assign each $y^n\in \Tc_{i}$ to a subset indexed by $j\in\Ic_i(y^n)$. These subsets will form a partition of $\Tc_i$ as stated in Proposition~\ref{proposition}.

\begin{definition}\label{D1}
For $j\in[M]\setminus\{i\}$, denoting by $\Sc_{i,j}$ the set of indices where the bit components of $\cb_i$ and $\cb_j$ differ, we define
\begin{subequations}
\begin{empheq}[left=\empheqlbrace]
{align}
&\Tc_{j|i}\triangleq\bigg\{y^n\in\Tc_i: j=\min_{r\in\Ic_i(y^n):d(\cb_i,y^n|\Sc_{i,r})<|\Sc_{i,r}|} r\bigg\};\label{p2_a}\\
& \Nc_{j|i }\triangleq\bigg\{y^n\in\Nc_i: P_{X^n,Y^n}(\cb_i,y^n)\cdot q=P_{X^n,Y^n}(\cb_j,y^n)\cdot\frac 1q \nonumber\\
&\quad\quad\quad\quad\quad\quad\quad\quad\quad  
\text{and }P_{X^n,Y^n}(\cb_j,y^n)\neq
P_{X^n,Y^n}(\cb_r,y^n)\text{ for }~r\in[j-1]\setminus\{i\}\bigg\}.\label{p2_b}
\end{empheq}
\end{subequations}
\end{definition}

Since there may exist $y^n\in\Tc_i$ satisfying $d(\cb_i,y^n|\Sc_{i,r})=|\Sc_{i,r}|$ for all $r\in\Ic_i(y^n)$, the collection of all elements in $\bigcup_{j\in[M]\setminus\{i\}}\Tc_{j|i}$ may not exhaust the elements in $\Tc_{i}$ (see~Example~\ref{example1}). 
We thus go on to collect the remaining elements in $\Tc_i\setminus\bigcup_{j\in[M]\setminus\{i\}}\Tc_{j|i}$ as follows.

\begin{definition}\label{D2}
Define for $j\in[M]\setminus\{i\}$,
\begin{IEEEeqnarray}{rCl}
\Tsc_{j|i}&\triangleq&\bigg\{y^n\in\Tc_i\,\Big\backslash\,\Big(\bigcup_{h\in[M]\setminus\{i\}}\Tc_{h|i}\Big): j=\min_{r\in\Ic_i(y^n)}r\bigg\}.\label{p2_c}
\end{IEEEeqnarray}
\end{definition} 

With the sets defined in Definitions \ref{D1} and \ref{D2}, a partition of $\Tc_i$ and disjoint subsets of $\Nc_i$ are constructed as proven in the following proposition.

\begin{proposition}\label{proposition}
For non-empty $\Tc_{i}$, the following two properties hold.
\begin{list}{\roman{step})}
    {\usecounter{step}
    \setlength{\labelwidth}{0.5cm}
    \setlength{\leftmargin}{1.1cm}\slshape}
\item The collection $\{\Tc_{j|i}\bigcup\Tsc_{j|i} \}_{j\in[M]\setminus\{i\}}$ forms a (disjoint) partition of $\Tc_{i}$.
\item $\{\Nc_{j|i}\}_{j\in[M]\setminus\{i\}}$ is a collection of disjoint subsets of $\Nc_{i}$.
\end{list}
\end{proposition} 

Before proving Proposition~\ref{proposition}, we provide the following example to illustrate the above sets.

\begin{example}\label{example1}
This example illustrates the necessity of introducing $\Tsc_{j|i}$ as a companion to $\Tc_{j|i}$. Suppose $\code_4=\{\cb_1, \cb_2, \cb_3,\cb_4\}=\{0000,0101,0110,0111\}$. Let $P_{X^4}(\cb_1)=\frac{q^2}{2+q^2+q^{-2}}$, $P_{X^4}(\cb_2)=P_{X^4}(\cb_3)=\frac{1}{2+q^2+q^{-2}}$ and $P_{X^4}(\cb_4)=\frac{q^{-2}}{2+q^2+q^{-2}}$. Then, $y^4=0111$ satisfies
\begin{equation}\label{19}
\underbrace{P_{X^4,Y^4}(\cb_1,y^4)}_{\frac{q^2}{(2+q^2+q^{-2})}p^4q^1}=\max_{r\in [4]\setminus\{1\}}P_{X^4,Y^4}(\cb_r,y^4)=\underbrace{P_{X^4,Y^4}(\cb_2,y^n)}_{\frac{1}{(2+q^2+q^{-2})}p^4q^3}=\underbrace{P_{X^4,Y^4}(\cb_3,y^4)}_{\frac{1}{(2+q^2+q^{-2})}p^4q^3}>\underbrace{P_{X^4,Y^4}(\cb_4,y^4)}_{\frac{q^{-2}}{(2+q^2+q^{-2})}p^4q^4},
\end{equation}
where the probabilities $P_{X^n,Y^n}(x^n,y^n)$ are written in the form
\begin{equation}
P_{X^n, Y^n}(x^n,y^n)=P_{X^n}(x^n)P_{Y^n|X^n}(y^n|x^n)=P_{X^n}(x^n)p^nq^{n-d(x^n,y^n)}. \label{prob}
\end{equation}
Note that the first equality in \eqref{19} indicates
 $0111\in\Tc_1$ and the last two equalities and the right-most inequality jointly imply that $\Ic_1(0111)=\{2,3\}$. In light of Proposition~\ref{proposition}, this $0111$ must lie in one and only one of $\{\Tc_{j|1}\bigcup\Tsc_{j|1}\}_{j\in[4]\setminus\{1\}}$ as shown in Tables~\ref{table2}-\ref{table3} of Appendix~\ref{AA}. Since there exist no integers $h$ in $\Ic_1(0111)$ fulfilling $d(\cb_1,0111|\Sc_{1,h})<|\Sc_{1,h}|$, this $0111$ belongs to $\Tsc_{j|1}$ with $j=\min_{r\in\Ic_1(0111)}=2$. Recall that in \cite{us}, an element in $\Nc_{j|1}$ can be obtained if flipping a zero of $y^n\in\Tc_{j|1}$ can make it further away from $\cb_1$ but closer to $\cb_j$. However, for $y^4=0111$ in this example if we flip the only zero to one, it gets further away from both $\cb_1$ and $\cb_h$ for any $h=2,3,4$. Therefore, the bit-flipping manipulation fails.
 
With $y^4=0111$, we also have
\begin{equation}\label{example1-1}
\underbrace{P_{X^4,Y^4}(\cb_2,y^4)}_{\frac{1}{(2+q^2+q^{-2})}p^4q^3}=\max_{r\in [4]\setminus\{2\}}P_{X^4,Y^4}(\cb_r,y^4)=\underbrace{P_{X^4,Y^4}(\cb_1,y^4)}_{\frac{q^2}{(2+q^2+q^{-2})}p^4q}=\underbrace{P_{X^4,Y^4}(\cb_3,y^n)}_{\frac{1}{(2+q^2+q^{-2})}p^4q^3}>\underbrace{P_{X^4,Y^4}(\cb_4,y^4)}_{\frac{1}{(2+q^2+q^{-2})}p^4q^4},
\end{equation}
where the first equality indicates
 $0111\in\Tc_2$ and the remaining parts in \eqref{example1-1} jointly imply $\Ic_2(0111)=\{1,3\}$. Proposition~\ref{proposition} then states that this $0111$ lies in one and only one of $\{\Tc_{j|2}\bigcup\Tsc_{j|2}\}_{j\in[4]\setminus\{2\}}$. Since $1\in \Ic_2(0111)=\{1,3\}$ and $d(\cb_2,0111|\Sc_{2,1})=0<|\Sc_{2,1}|=2$, we have $0111\in \Tc_{1|2}$ according to \eqref{p2_a}. Thus, we can flip a bit in $0111$ to get further away from $\cb_2$ and closer to $\cb_j$ simultaneously. More specifically, the bit-flipping manipulation produces either $0110$ or $0011$, which lies in $\Nc_{1|2}$ as $y^4=0111$ is in $\Tc_{1|2}$. Therefore, we can associate the element in $\Tc_{1|2}$ with an element in $\Nc_{1|2}$ via a single flipping operation. For completeness, a full list of the sets $\Tc_i$, $\Nc_i$, $\Tc_{j|i}$, $\Tsc_{j|i}$ and $\Nc_{j|i}$ for $i\in[4]$ and $j\in[4]\setminus\{i\}$, is given in Appendix~\ref{AA}. \hfill$\Box$
 \end{example}

\begin{IEEEproof}[Proof of Proposition~\ref{proposition}]
First, we note that by the definitions in \eqref{p2_a} and \eqref{p2_c}, $\{\Tc_{j|i}\}_{j\in[M]\setminus\{i\}}$ are disjoint, and so is $\{\Tsc_{j|i}\}_{j\in[M]\setminus\{i\}}$. Also, \eqref{p2_c} implies $\Tc_{j|i}\bigcap\Tsc_{h|i}=\emptyset$ for arbitrary $j, h\in[M]\setminus\{i\}$. Furthermore, according to Definitions \ref{D1} and \ref{D2}, for any $y^n\in\Tc_{i}$, we have either $y^n\in\Tc_{h|i}$ or $y^n\in\Tsc_{h|i}$ for some $h\in[M]\setminus \{i\}$. Consequently, $\{\Tc_{j|i}\bigcup\Tsc_{j|i}\}_{j\in[M]\setminus\{i\}}$ forms a partition of $\Tc_{i}$. 

On the other hand, the inequality in \eqref{p2_b} prevents multiple inclusions of an element from the previous collections. Therefore, $\{\Nc_{j|i}\}_{j\in[M]\setminus\{i\}}$ are a collection of disjoint subsets of $\Nc_i$.
\end{IEEEproof}

\begin{remark}
When channel inputs are uniformly distributed as considered in  \cite{us}, it follows that 
\begin{equation}\label{Ii}
  \Ic_i(y^n)=\Big\{h\in[M]\setminus\{i\}:d(\cb_i,y^n)=d(\cb_h,y^n)=\max_{r\in[M]\setminus\{i\}}d(\cb_r,y^n)\Big\},
\end{equation}
and 
$d(\cb_i,y^n|\Sc_{i,j})=\frac{|\Sc_{i,j}|}{2}< |\Sc_{i,j}|$ for every $j\in \Ic_{i}(y^n)$. Therefore, \eqref{p2_a} is reduced to 
\begin{IEEEeqnarray}{rCl}
\Tc_{j|i}&=&\bigg\{y^n\in\Tc_i: j=\min_{r\in\Ic_i(y^n)} r\bigg\},\label{reduce_p2_1}
\end{IEEEeqnarray} 
and 
\begin{IEEEeqnarray}{rcl}
\Tsc_{j|i}=\emptyset.\label{empty}
\end{IEEEeqnarray}
We then have the following two remarks. 
First, we note that the $\Tc_{j|i}$ newly defined via \eqref{p2_a} and reduced to \eqref{reduce_p2_1} in the regime considered in \cite{us} is more restrictive than the $\Tc_{j|i}$ introduced in \cite[Eq.~(16a)]{us}. As a consequence,  $\{\Tc_{j|i}\}_{j\in[M]\setminus\{i\}}$ forms a partition of $\Tc_i$ in this paper while those introduced in \cite[Eq.~(16a)]{us} are a disjoint covering of $\Tc_i$ under uniform channel inputs. Second, \eqref{empty} shows that \cite{us} does not need to consider a companion $\Tsc_{j|i}$ to $\Tc_{j|i}$ but this paper does. \hfill $\Box$
\end{remark}

Based on Proposition~\ref{proposition}, we continue the derivation from \eqref{tec2} and obtain:
\begin{IEEEeqnarray}{rCl}
\frac{\delta_n}{b_n}
&\leq&\frac{\sum_{i\in [M]}  P_{X^n,Y^n}\Big(\cb_i, \bigcup_{j\in [M]\setminus\{i\}}(\Tc_{j|i} \bigcup\Tsc_{j|i})\Big) }{\sum_{i\in [M]} P_{X^n,Y^n}\Big (\cb_i, \bigcup_{j\in [M]\setminus\{i\}}\Nc_{j|i}\Big)}\\
&=&\frac{\sum_{i\in [M]} \sum_{j\in [M]\setminus\{i\}}P_{X^n,Y^n}\big(\cb_i, \Tc_{j|i}\big)+\sum_{i\in [M]}\sum_{j\in [M]\setminus\{i\}}P_{X^n,Y^n}\big(\cb_i, \Tsc_{j|i}\big)}{\sum_{i\in [M]}\sum_{j\in [M]\setminus\{i\}}P_{X^n,Y^n}\big(\cb_i, \Nc_{j|i}\big)},\label{27}
\end{IEEEeqnarray} 
where \eqref{27} holds because $\{\Tc_{j|i}\}_{j\in[M]\setminus\{i\}}$ and $\{\Tsc_{j|i}\}_{j\in[M]\setminus\{i\}}$ are disjoint, and the same applies to $\{\Nc_{j|i}\}_{j\in[M]\setminus\{i\}}$. An additional upper bound for \eqref{27} requires the verification of the inequality:
\begin{equation}\label{28}
\sum_{i\in [M]}\sum_{j\in [M]\setminus\{i\}}P_{X^n,Y^n}\big(\cb_i, \Tsc_{j|i}\big)\leq\sum_{j\in [M]}\sum_{i\in [M]\setminus\{j\}} P_{X^n,Y^n}\big(\cb_j, \Tc_{i|j}\big),
\end{equation}
which is an immediate consequence of the proposition to be proven in the next section (Proposition~\ref{proposition2}), stating that:
\begin{equation}\label{29}
y^n\in\Tsc_{j|i}\text{ and }h\in\Ic_i(y^n)\Rightarrow y^n\in\Tc_{\ell|h}\text{ for some }\ell\in\Ic_h(y^n)\text{ and }
P_{X^n,Y^n}(\cb_i,y^n)=P_{X^n,Y^n}(\cb_h,y^n).
\end{equation}

\subsection{Verification of \eqref{28}} 
\label{Sec_28}
Recall that the main technique used in \cite{us} is to associate every element in $\Tc_i$ with a corresponding element in $\Nc_i$ via the bit-flipping manipulation. By this bit-flipping association, the probability ratio of the elements and corresponding elements respectively in $\Tc_i$ and $\Nc_i$ can be evaluated. However, as Example \ref{example1} indicates, for an element in $\Tsc_{j|i}$, the bit-flipping association no longer works. This reveals the challenge of generalizing the results in \cite{us} from uniform channel inputs to arbitrarily distributed channel inputs. A solution is to subdivide the elements in $\Tc_i$ into two groups $\{\Tc_{j|i}\}_{j\in[M]\setminus\{i\}}$ and $\{\Tsc_{j|i}\}_{j\in[M]\setminus\{i\}}$, where the bit-flipping association to $\{\Nc_{j|i}\}_{j\in[M]\setminus\{i\}}$ works for the former group but not for the latter. The inequality in \eqref{28} can then be used to exclude the latter group with an upper bound:
\begin{IEEEeqnarray}{rCl}
\frac{\delta_n}{b_n}&\leq&
\frac{\sum_{i\in [M]} \sum_{j\in [M]\setminus\{i\}}P_{X^n,Y^n}\big(\cb_i, \Tc_{j|i}\big)+\sum_{i\in [M]}\sum_{j\in [M]\setminus\{i\}}P_{X^n,Y^n}\big(\cb_i, \Tsc_{j|i}\big)}{\sum_{i\in [M]}\sum_{j\in [M]\setminus\{i\}}P_{X^n,Y^n}\big(\cb_i, \Nc_{j|i}\big)}\\
&\leq&2\frac{\sum_{i\in [M]} \sum_{j\in [M]\setminus\{i\}}P_{X^n,Y^n}\big(\cb_i, \Tc_{j|i}\big)}{\sum_{i\in [M]}\sum_{j\in [M]\setminus\{i\}}P_{X^n,Y^n}\big(\cb_i, \Nc_{j|i}\big)}. \label{tec3}
\end{IEEEeqnarray} 

Since uniform channel inputs as considered in \cite{us} guarantee \eqref{empty}, it can be seen from \eqref{tec3} that the multiplicative factor of $2$ can be reduced to $1$ as observed in Remark \ref{remark1}. For general arbitrary channel inputs, we have the factor of $2$ since the set $\Tsc_{j|i}$ may not be empty. 
The validity of \eqref{28} can be confirmed by the next proposition.

\begin{proposition}\label{proposition2}
Suppose $y^n\in\Tsc_{j|i}$. Then, for every $h\in\Ic_i(y^n)$, we have
\begin{equation}
y^n\in\Tc_{\ell|h}\text{ for some }\ell\in\Ic_h(y^n)\text{ and }P_{X^n,Y^n}(\cb_i,y^n)=P_{X^n,Y^n}(\cb_h,y^n).
\end{equation}
\end{proposition}
\begin{IEEEproof} 
Suppose $y^n\in \Tsc_{j|i}$. Then, $d(\cb_i,y^n|\Sc_{i,h})=|\Sc_{i,h}|$ for every $h\in\Ic_i(y^n)$. We therefore have:
\begin{equation}\label{31}
P_{X^n,Y^n}(\cb_i,y^n)=P_{X^n,Y^n}(\cb_h,y^n)=\max_{r\in[M]\setminus\{i\}}P_{X^n,Y^n}(\cb_r,y^n).
\end{equation}
We can rewrite \eqref{31} as
\begin{equation}\label{32}
P_{X^n,Y^n}(\cb_h,y^n)=P_{X^n,Y^n}(\cb_i,y^n)=\max_{r\in[M]\setminus\{h\}}P_{X^n,Y^n}(\cb_r,y^n),
\end{equation}
implying $y^n\in\Tc_h$ and $i\in\Ic_h(y^n)$. Noting that $d(\cb_h,y^n|S_{h,i})=0<|\Sc_{h,i}|$ because $d(\cb_i,y^n|S_{i,h})=|\Sc_{i,h}|$ and $S_{h,i}=S_{i,h}$, we conclude that the smallest integer $\ell\in\Ic_h(y^n)$ satisfying $d(\cb_h,y^n|S_{h,\ell})<|\Sc_{h,\ell}|$ exists, and therefore $y^n\in\Tc_{\ell|h}$.
\end{IEEEproof}

\begin{remark}\label{R4}
Two observations can be made based on Proposition~\ref{proposition2}. First, Proposition~\ref{proposition2} indicates that every $y^n\in\Tsc_{j|i}$ must appear {\it at least} once  in the sum $\sum_{h\in [M]}$ $\sum_{\ell\in [M]\setminus\{h\}}$ $P_{X^n,Y^n}\big(\cb_h,\Tc_{\ell|h}\big)$, contributing the same probability mass $P_{X^n,Y^n}(\cb_h,y^n)$ as $P_{X^n,Y^n}(\cb_i,y^n)$. Second, Proposition~\ref{proposition2} also implies that every $y^n\in\Tsc_{j|i}$ cannot be contained in $\big(\bigcup_{h\in [M]}\bigcup_{r\in [M]\setminus\{h\}}\Tsc_{r|h}\big)\setminus\Tsc_{j|i}$. This observation can be substantiated as follows. For every $h\in\Ic_i(y^n)$, Proposition~\ref{proposition2} implies $y^n\in\Tc_{\ell|h}$ for some $\ell\in\Ic_h(y^n)$ and hence Definition~\ref{D2} immediately gives  $y^n\not\in\Tsc_{r|h}$ for all $r\in[M]\setminus\{h\}$. For $h\not\in\Ic_i(y^n)$, we have $y^n\not\in\Tc_h$ and therefore $y^n\not\in\Tc_{r|h}\subseteq\Tc_h$ for all $r\in[M]\setminus\{h\}$ as pointed out in Remark~\ref{sub}. As a result, every $y^n\in\Tsc_{j|i}$ appears \emph{exactly} once in the sum $\sum_{h\in [M]}$ $\sum_{r\in [M]\setminus\{h\}}P_{X^n,Y^n}\big(\cb_h, \Tsc_{r|h}\big)$. Combining the two observations leads to:
\begin{IEEEeqnarray}{rCl}
\sum_{i\in [M]}\sum_{j\in [M]\setminus\{i\}}\sum_{y^n\in\Tsc_{j|i}}P_{X^n,Y^n}\big(\cb_i, y^n\big)&\leq&\sum_{j\in [M]}\sum_{\ell\in [M]\setminus\{j\}}\sum_{y^n\in\Tc_{\ell|j}} P_{X^n,Y^n}\big(\cb_j, y^n\big).
\end{IEEEeqnarray}
\hfill$\Box$
\end{remark}
To flesh out the above inequality, we give the next example.

\begin{example}\label{example3}
Proceeding from Example~\ref{example1}, we observe from Tables~\ref{table2} and \ref{table3} in Appendix \ref{AA} that $0111$ is contained in $\Tsc_{2|1}$, $\Tc_{1|2}$ and $\Tc_{1|3}$. Hence, \blue{it} appears once in the sum $\sum_{j\in [4]}\sum_{i\in [4]\setminus\{j\}} P_{X^n,Y^n}\big(\cb_j,\Tsc_{i|j}\big)$ while it contributes twice in the sum $\sum_{j\in [4]}\sum_{i\in [4]\setminus\{j\}} P_{X^n,Y^n}\big(\cb_j,\Tc_{i|j}\big)$. We then confirm from \eqref{92} that: 
\begin{IEEEeqnarray}{rCl}
\sum_{i\in [4]} \sum_{j\in [4]\setminus\{i\}}P_{X^4,Y^4}\big(\cb_i, \Tc_{j|i}\big)
&\geq&\sum_{i\in [4]}\sum_{j\in [4]\setminus\{i\}}P_{X^4,Y^4}\big(\cb_i, \Tsc_{j|i}\big)
.\label{92*}
\end{IEEEeqnarray}
\hfill$\Box$
\end{example}

We continue the derivation from \eqref{tec3} and obtain:
\begin{IEEEeqnarray}{rCl}
\frac{\delta_n}{b_n}
&\leq&2\frac{\sum_{i\in [M]} \sum_{j\in [M]\setminus\{i\}:\Tc_{j|i}\neq\emptyset}P_{X^n,Y^n}\big(\cb_i, \Tc_{j|i}\big)}{\sum_{i\in [M]}\sum_{j\in [M]\setminus\{i\}:\Tc_{j|i}\neq\emptyset}P_{X^n,Y^n}\big(\cb_i, \Nc_{j|i}\big)}\label{37}\\
&\leq&2\max_{i\in [M]\text{ and }j\in [M]\setminus\{i\}: \Tc_{j|i}\neq\emptyset}\frac{P_{X^n,Y^n}\big(\cb_i, \Tc_{j|i}\big)}{P_{X^n,Y^n}\big(\cb_i, \Nc_{j|i}\big)},\label{upperTN}
\end{IEEEeqnarray} 
where we add the restriction $\Tc_{j|i}\neq\emptyset$ in \eqref{37} to exclude the cases of zero dividing by zero in \eqref{upperTN}, and \eqref{upperTN} follows the ratio-sum inequality in \eqref{rate-sum}.

In the next section, we introduce a number of delicate decompositions of non-empty $\Tc_{j|i}$ and an equal number of disjoint subsets of $\Nc_{j|i}$ to facilitate the bit-flipping association of the pairs.

\subsection{Atomic Decomposition of 
Non-empty $\Tc_{j|i}$ and the Corresponding Disjoint Subsets of $\Nc_{j|i}$}

To simplify the exposition, we assume without loss of generality that $\cb_1$ is the all-zero codeword.\footnote{It is known that we can simultaneously flip the same position of all codewords to yield a new code of equal performance over the BSC. Thus, via a number of flipping manipulations, we can transform any code to a code of equal performance with the first codeword being all-zero.} Below we present  the proof for $i=1$.  The proof for general $i>1$ follows annalagously.

Since $\cb_1$ is the all-zero codeword, $\Sc_{1,j}$ is the set containing the indices of the non-zero components of $\cb_j$. To facilitate the investigation of the structure of $\cb_j$ relative to the remaining codewords $\{\cb_r\}_{r\in[M]\setminus\{1,j\}}$, we first partition $\Sc_{1,j}$ into $2^{M-2}$ subsets according to whether each index in $\Sc_{1,j}$ is in $\Sc_{1,2}$, $\ldots$, $\Sc_{1,j-1}$, $\Sc_{1,j+1}$, $\ldots$, $\Sc_{1,M}$ or not as follows: 
\begin{equation}\label{scjm}
\Sc_{1,j}^{(m)}\triangleq \Big(\bigcap_{r=2}^{j-1}\Sc_{r;\lambda_r}\Big)
\bigcap\Big(\bigcap_{r=j+1}^{M}\Sc_{r;\lambda_r}\Big)\bigcap\Sc_{1,j} \quad\text{for }m\triangleq 1+\sum_{r=2}^{j-1}\lambda_r\cdot 2^{r-2}+\sum_{r=j+1}^M\lambda_r\cdot 2^{r-3},
\end{equation}
where $\Sc_{r;1}\triangleq\Sc_{1,r}$ and $\Sc_{r;0}\triangleq[n]\setminus\Sc_{1,r}=\Sc_{1,r}^{\text{c}}$, and each $\lambda_r\in\{0,1\}$. An example of the partition is given below.

\begin{example} Suppose $\code_4=\{00000,11001, 01111,01101\}$. For $j=3$ and $\Sc_{1,j}=\{2,3,4,5\}$, we obtain $2^{4-2}=4$ subsets as:
\begin{IEEEeqnarray}{rCl}
\Sc_{1,3}^{(m)}=\begin{cases}
\Sc_{1,3}^{(1)}=S_{1,2}^\text{c}\bigcap\Sc_{1,4}^\text{c}\bigcap\Sc_{1,3}=\{4\},& \text{if }(\lambda_4,\lambda_2)=(0,0);\\
\Sc_{1,3}^{(2)}=S_{1,2}\bigcap\Sc_{1,4}^\text{c}\bigcap\Sc_{1,3}=\emptyset,& \text{if }(\lambda_4,\lambda_2)=(0,1);\\
\Sc_{1,3}^{(3)}=S_{1,2}^\text{c}\bigcap\Sc_{1,4}\bigcap\Sc_{1,3}=\{3\},& \text{if }(\lambda_4,\lambda_2)=(1,0);\\
\Sc_{1,3}^{(4)}=S_{1,2}\bigcap\Sc_{1,4}\bigcap\Sc_{1,3}=\{2,5\},& \text{if }(\lambda_4,\lambda_2)=(1,1).\\
\end{cases}
\end{IEEEeqnarray}\hfill$\Box$
\label{ex_ex}
\end{example}

As $\cb_1$ is the all-zero codeword, the components of $\cb_r$ with indices in $\Sc_{1,j}^{(m)}$ can now be unambiguously identified and must all equal $\lambda_r$. As a result,  
\begin{equation}\label{remark5}
d\Big(\cb_1,\cb_r\Big|\Sc_{1,j}^{(m)}\Big)=\begin{cases}
\big|\Sc_{1,j}^{(m)}\big|,&\lambda_r=1;\\
0,&\lambda_r=0.
\end{cases}
\end{equation}

\begin{example}
Proceeding from Example~\ref{ex_ex}, we have:
\begin{IEEEeqnarray}{rCl}
\begin{cases}
d\Big(\cb_1,\cb_2\Big|\Sc_{1,3}^{(1)}\Big)=0&\text{because }\lambda_2=0;\\
d\Big(\cb_1,\cb_2\Big|\Sc_{1,3}^{(2)}\Big)=|\Sc_{1,3}^{(2)}|=0&\text{because }\lambda_2=1;\\
d\Big(\cb_1,\cb_2\Big|\Sc_{1,3}^{(3)}\Big)=0&\text{because }\lambda_2=0;\\
d\Big(\cb_1,\cb_2\Big|\Sc_{1,3}^{(4)}\Big)=|\Sc_{1,3}^{(4)}|=2&\text{because }\lambda_2=1,
\end{cases}
\end{IEEEeqnarray}
and
\begin{IEEEeqnarray}{rCl}
\begin{cases}
d\Big(\cb_1,\cb_4\Big|\Sc_{1,3}^{(1)}\Big)=0&\text{because }\lambda_4=0;\\
d\Big(\cb_1,\cb_4\Big|\Sc_{1,3}^{(2)}\Big)=0&\text{because }\lambda_4=0;\\
d\Big(\cb_1,\cb_4\Big|\Sc_{1,3}^{(3)}\Big)=|\Sc_{1,3}^{(3)}|=1&\text{because }\lambda_4=1;\\
d\Big(\cb_1,\cb_4\Big|\Sc_{1,3}^{(4)}\Big)=|\Sc_{1,3}^{(4)}|=2&\text{because }\lambda_4=1.
\end{cases}
\end{IEEEeqnarray}
\hfill$\Box$
\end{example}

It should be emphasized that $\Sc_{1,j}^{(m)}$ in this paper is defined differently from that in \cite{us}. While the one defined in \cite{us} partitions $\Sc_{1,j}$ only according to codewords with indices less than $j$, the one defined in this paper considers all other $M-2$ codewords in the partition manipulation and hence the order of codewords become irrelevant. 

Next, to decompose $\Tc_{j|1}$, we further define a sequence of incremental sets:
\begin{equation}\label{def1sac}
\Sac_{1,j}^{(m)}\triangleq\bigcup_{h=1}^m\Sc_{1,j}^{(h)}, \quad m\in[2^{M-2}],
\end{equation}
and set $\Sac_{1,j}^{(0)}\triangleq\emptyset$. Let $\ell_{1,j}\triangleq|\Sc_{1,j}|$ and $\ell_{1,j}^{(m)}\triangleq|\Sac_{1,j}^{(m)}|$ respectively denote the sizes of $\Sc_{1,j}$ and $\Sac_{1,j}^{(m)}$, and note that $0=\ell_{1,j}^{(0)}\leq\ell_{1,j}^{(1)}\leq \ell_{1,j}^{(2)}\leq\cdots\leq \ell_{1,j}^{(2^{M-2})}=\ell_{1,j}$.

The idea behind the partition of $\Tc_{j|1}$ into $\ell_{1,j}$ subsets, indexed by $k\in[\ell_{1,j}-1]\bigcup\{0\}$, is as follows. Pick one $y^n\in\Tc_{j|1}$. We start by examining whether $d(\cb_1,y^n|\Sac_{1,j}^{(1)})$ is strickly less than $\ell_{1,j}^{(1)}-1$. If the answer is negative, we continue examining whether $d(\cb_1,y^n|\Sac_{1,j}^{(2)})$ is strictly less than $\ell_{1,j}^{(2)}-1$. Proceed until we reach the smallest $m$ such that $d(\cb_1,y^n|\Sac_{1,j}^{(m)})<\ell_{1,j}^{(m)}-1$ holds. Setting $k$ to be equal to $k=d(\cb_1,y^n|\Sac_{1,j}^{(m)})$, we assign this $y^n$ to the subset $\Tc_{j|1}(k)$. Notably, there exists no such number $m\in[2^{M-2}]$ that satisfies $d(\cb_1,y^n|\Sac_{1,j}^{(m)})<\ell_{1,j}^{(m)}-1$ if and only if $d(\cb_1,y^n|\Sc_{1,j})=\ell_{1,j}-1$; in this case, we find the smallest $m$ satisfying $\Sac_{1,j}^{(m)}=\Sc_{1,j}$ and assign this element to $\Tc_{j|1}(\ell_{1,j}-1)$ as $d(\cb_1,y^n|\Sac_{1,j}^{(m)})=\ell_{1,j}-1$. For ease of describing the above algorithmic partition process, we introduce a mapping from $k\in[\ell_{1,j}-1]\bigcup\{0\}$ to $m\in[2^{M-2}]$ as follows:
\begin{equation}\label{mappingkm}
\eta_k\triangleq
\begin{cases}
\min\Big\{m\in[2^{M-2}]:k<\ell_{1,j}^{(m)}-1\Big\},&0\leq k<\ell_{1,j}-1;\\
\min\Big\{m\in[2^{M-2}]:k=\ell_{1,j}^{(m)}-1\Big\},&k=\ell_{1,j}-1.
\end{cases}
\end{equation}
We can see that for $0\leq k<\ell_{1,j}-1$, 
we have $\ell_{1,j}^{(\eta_k-1)}-1\leq k<\ell_{1,j}^{(\eta_k)}-1$. Therefore, if $y^n\in\Tc_{j|1}$ is assigned to $\Tc_{j|1}(k)$ for some $k<\ell_{1,j}-1$, we must have
\begin{equation}\label{mappingkm1}
\ell_{1,j}^{(\eta_k-1)}-1\leq d\big(\cb_1,y^n\big|\Sac_{1,j}^{(\eta_k-1)}\big)\leq d\big(\cb_1,y^n\big|\Sac_{1,j}^{(\eta_k)}\big)=k<\ell_{1,j}^{(\eta_k)}-1.
\end{equation} 
On the other hand, if $y^n\in\Tc_{j|1}$ is collected in $\Tc_{j|1}(\ell_{1,j}-1)$, then $\Sac_{1,j}^{(\eta_k)}=\Sc_{1,j}$ and
\begin{equation}\label{mappingkm2}
\ell_{1,j}^{(\eta_k-1)}-1\leq d\big(\cb_1,y^n\big|\Sac_{1,j}^{(\eta_k-1)}\big)\leq d\big(\cb_1,y^n\big|\Sac_{1,j}^{(\eta_k)}\big)=\ell_{1,j}-1.
\end{equation}
A formal definition of $\Tc_{j|1}(k)$ is given next, where the corresponding subsets $\Nc_{j|1}(k)$ of $\Nc_{j|1}$ are also introduced.

\begin{definition}\label{definition3}
Define for $k=0$, $1$, $\ldots$, $\ell_{1,j}-1$,
\begin{subequations}
\begin{empheq}[left=\empheqlbrace]{align}
&\Tc_{j|1}(k)\triangleq
\left\{y^n\in\Tc_{j|1}: \ell_{1,j}^{(\eta_k-1)}-1\leq d\big(\cb_1,y^n\big|\Sac_{1,j}^{(\eta_k-1)}\big)\text{ and }d\big(\cb_1,y^n\big|\Sac_{1,j}^{(\eta_k)}\big)=k\right\};\label{p3_a}\\
&\Nc_{j|1}(k)\triangleq
\left\{y^n\in\Nc_{j|1}: \ell_{1,j}^{(\eta_k-1)}=d\big(\cb_1,y^n\big|\Sac_{1,j}^{(\eta_k-1)}\big)\text{ and }d\big(\cb_1,y^n\big|\Sac_{1,j}^{(\eta_k)}\big)=k+1\right\},\label{p3_b}
\end{empheq}
\end{subequations}
where $\eta_k$ is defined in \eqref{mappingkm}.
\end{definition}

With Definition~\ref{definition3}, we have the following proposition.

\begin{proposition}\label{proposition3}
For non-empty $\Tc_{j|1}$, the following two properties hold.
\begin{list}{\roman{step})}
    {\usecounter{step}
    \setlength{\labelwidth}{0.5cm}
    \setlength{\leftmargin}{1.1cm}\slshape}
\item $\{\Tc_{j|1}(k)\}_{k\in[\ell_{1,j}-1]\bigcup\{0\}}$
 forms a partition of $\Tc_{j|1}$;
\item $\{\Nc_{j|1}(k)\}_{k\in[\ell_{1,j}-1]\bigcup\{0\}}$ is a collection of disjoint subsets of $\Nc_{j|1}$.
\end{list}
\end{proposition}
\begin{IEEEproof}
It can be seen from the definitions of $\{\Tc_{j|1}(k)\}_{k\in[\ell_{1,j}-1]\bigcup\{0\}}$ and $\{\Nc_{j|1}(k)\}_{k\in[\ell_{1,j}-1]\bigcup\{0\}}$ that they are collections of mutually disjoint subsets of $\Tc_{j|1}$ and $\Nc_{j|1}$, respectively. It remains to argue that every element in $\Tc_{j|1}$ belongs to $\Tc_{j|1}(k)$ for some $k\in[\ell_{1,j}-1]\bigcup\{0\}$. Noting that the element $y^n$ in $\Tc_{j|1}$ satisfies $d(\cb_1,y^n|\Sc_{1,j})\leq \ell_{1,j}-1$, we  differentiate two cases: $d(\cb_1,y^n|\Sc_{1,j})\leq \ell_{1,j}-2$ and $d(\cb_1,y^n|\Sc_{1,j})=\ell_{1,j}-1$. For the former case, $d(\cb_1,y^n|\Sac_{1,j}^{(m)})<\ell_{1,j}^{(m)}-1$ must hold for $m=\eta_k$; hence, this $y^n$ will be contained in $\Tc_{j|1}(k)$. For the latter case, $y^n$ will be included in $\Tc_{j|1}(\ell_{1,j}-1)$. The proof is thus completed.
\end{IEEEproof}

In light of Proposition~\ref{proposition3}, we can apply the ratio-sum inequality to obtain:
 \begin{IEEEeqnarray}{rCl}
 \frac{P_{X^n,Y^n}(\cb_1, \Tc_{j|1})}{P_{X^n,Y^n}(\cb_1, \Nc_{j|1})}\leq \frac{\sum_{k=0:\Tc_{j|1}(k)\neq\emptyset}^{\ell_{1,j-1}}P_{X^n,Y^n}\big(\cb_1, \Tc_{j|1}(k)\big)}{\sum_{k=0:\Tc_{j|1}(k)\neq\emptyset}^{\ell_{1,j-1}}P_{X^n,Y^n}\big(\cb_1, \Nc_{j|1}(k)\big)}
 \leq \max_{k\in[\ell_{1,j}-1]\bigcup\{0\}:\Tc_{j|1}(k)\neq\emptyset}
 \frac{P_{X^n,Y^n}\big(\cb_1, \Tc_{j|1}(k)\big)}{P_{X^n,Y^n}\big(\cb_1, \Nc_{j|1}(k)\big )}.\label{Tk}
 \end{IEEEeqnarray}
 
We continue to construct a fine partition of $\Tc_{j|1}(k)$ and the corresponding disjoint subsets of $\Nc_{j|1}(k)$ in Proposition~\ref{proposition4} after giving the next definition.

\begin{definition}\label{defi3} Define for $u^n\in\Tc_{j|1}(k)$,
\begin{subequations}
\begin{empheq}[left=\empheqlbrace]{align}
&\Tc_{j|1}(u^n;k)\triangleq
\big\{y^n\in\Tc_{j|1}(k): d\big(u^n,y^n\Big|\big(\Sac_{1,j}^{(\eta_k)}\big)^{\text{c}}\big)=0\big\};\label{p4_a}\\
&\Nc_{j|1}(u^n;k)\triangleq
\big\{y^n\in\Nc_{j|1}(k): d\big(u^n,y^n\Big|(\Sac_{1,j}^{(\eta_k)})^{\text{c}}\big)=0\big\},\label{p4_b}
\end{empheq}
\end{subequations}
where $\eta_k$ is given in \eqref{mappingkm}.
\end{definition}

Note from Definition~\ref{defi3} that for one element $u^n$ in non-empty $\Tc_{j|1}(k)$, we can find a group of elements that have identical bit components to $u^n$ with indices in $(\Sac_{1,j}^{(\eta_k)})^{\text{c}}$. We denote this group as $\Tc_{j|1}(u^n;k)$. We continue this grouping manipulation until all elements in $\Tc_{j|1}(k)$ are exhausted as summarized below. 

\begin{proposition}\label{proposition4} 
For non-empty $\Tc_{j|1}(k)$, there exists a representative subset $\Uc_{j|1}(k)\subseteq\Tc_{j|1}(k)$ such that the following two properties hold.
\begin{list}{\roman{step})}
    {\usecounter{step}
    \setlength{\labelwidth}{0.5cm}
    \setlength{\leftmargin}{1.1cm}\slshape}
\item $\big\{\Tc_{j|1}(u^n;k)\big\}_{u^n\in\Uc_{j|1}(k)}$  forms a (non-empty) partition of  $\Tc_{j|1}(k)$;
\item $\big\{\Nc_{j|1}(u^n;k)\big\}_{u^n\in\Uc_{j|1}(k)}$  is a collection of (non-empty) disjoint subsets of $\Nc_{j|1}(k)$.
\end{list}
\end{proposition}

Since the above proposition can be self-validated via its sequential selection manipulation of each $u^n$ from $\Tc_{j|1}(k)$, we omit the proof. Interested readers can find the details in \cite[Sec.~III-C]{us}.

From Proposition~\ref{proposition4}, using again the ratio-sum inequality, we obtain that for non-empty $\Tc_{j|1}(k)$, 
 \begin{IEEEeqnarray}{rCl}
 \frac{P_{X^n,Y^n}\big(\cb_1, \Tc_{j|1}(k)\big)}{P_{X^n,Y^n}\big(\cb_1, \Nc_{j|1}(k)\big )}\leq \frac{\sum_{u^n\in\Uc_{j|1}(k)}P_{X^n,Y^n}\big(\cb_1, \Tc_{j|1}(u^n;k)\big)}{\sum_{u^n\in\Uc_{j|1}(k)}P_{X^n,Y^n}\big(\cb_1, \Nc_{j|1}(u^n;k)\big)}
 \leq \max_{u^n\in\Uc_{j|1}(k)}
 \frac{P_{X^n,Y^n}\big(\cb_1, \Tc_{j|1}(u^n;k)\big)}{P_{X^n,Y^n}\big(\cb_1, \Nc_{j|1}(u^n;k)\big )}.\label{u}
 \end{IEEEeqnarray}
 
 Noting that the above result can be similarly conducted for general $i>1$, 
 we combine \eqref{upperTN}, \eqref{Tk} and \eqref{u} to conclude that
 \begin{IEEEeqnarray}{rCl}
 \frac{\delta_n}{b_n}\leq 2\max_{i\in [M]\text{ and }j\in [M]\setminus\{i\}: \Tc_{j|i}\neq\emptyset}\max_{k\in[\ell_{i,j}-1]\bigcup\{0\}:\Tc_{j|i}(k)\neq\emptyset}
  \max_{u^n\in\Uc_{j|i}(k)}
 \frac{P_{X^n,Y^n}\big(\cb_i, \Tc_{j|i}(u^n;k)\big)}{P_{X^n,Y^n}\big(\cb_i, \Nc_{j|i}(u^n;k)\big )}.\label{Last}
 \end{IEEEeqnarray}
 The final task is to evaluate $P_{X^n,Y^n}\big(\cb_i, \Tc_{j|i}(u^n;k)\big)/P_{X^n,Y^n}\big(\cb_i, \Nc_{j|i}(u^n;k)\big )$ in order to characterize a linear upper bound for $\delta_n/b_n$.

\subsection{Characterization of a Linear Upper Bound for $\delta_n/b_n$}\label{part2}

We again focus on $i=1$ with $\cb_1$ being the all-zero codeword for simplicity.
The definitions of $\Tc_{j|1}(u^n;k)$ in \eqref{p4_a} and $\Nc_{j|1}(u^n;k)$ in \eqref{p4_b} indicate that when dealing with the ratio $P_{X^n,Y^n}(\cb_1, \Tc_{j|1}(u^n;k))/P_{X^n,Y^n}(\cb_1, \Nc_{j|1}(u^n;k))$, we only need to consider those bits with indices in $\Sac_{1,j}^{(\eta_k)}$ because the remaining bits of all tuples in $\Tc_{j|1}(u^n;k)$ and $\Nc_{j|1}(u^n;k)$ have identical values as $u^n$. Note that all $|\Tc_{j|1}(u^n;k)|$ elements in $\Tc_{j|1}(u^n;k)$ have exactly $k$ ones with indices in $\Sac_{1,j}^{(\eta_k)}$, and all $|\Nc_{j|1}(u^n;k)|$ elements in $\Nc_{j|1}(u^n;k)$ have exactly $k+1$ ones with indices in $\Sac_{1,j}^{(\eta_k)}$, we can immediately infer that:
\begin{equation}\label{eq:exact}
\frac{P_{X^n,Y^n}(\cb_1,\Tc_{j|1}(u^n;k))}{P_{X^n,Y^n}(\cb_1,\Nc_{j|1}(u^n;k))}=\frac{P_{X^n}(\cb_1)\cdot P_{Y^n|\cb_1}(\Tc_{j|1}(u^n;k)|{\cb_1})}{P_{X^n}(\cb_1)\cdot P_{Y^n|\cb_1}(\Nc_{j|1}(u^n;k)|{\cb_1})}=\frac{(1-p)}p\cdot\frac{|\Tc_{j|1}(u^n;k)|}{|\Nc_{j|1}(u^n;k)|}.
\end{equation}
The cardinalities of $\Tc_{j|1}(u^n;k)$ and $\Nc_{j|1}(u^n;k)$ then decide the ratio in \eqref{eq:exact} as verified in the next proposition, based on which the proof of Theorem~\ref{theorem} can be completed from \eqref{Last}.

\begin{proposition} \label{proposition9}
For $u^n\in\Tc_{j|1}(k)$, we have
\begin{equation}
\frac{P_{X^n,Y^n}(\cb_1,\Tc_{j|1}(u^n;k))}{P_{X^n,Y^n}(\cb_1,\Nc_{j|1}(u^n;k))}\leq\frac{(1-p)}pn.
\end{equation}
\end{proposition}
\begin{IEEEproof} 
Recall from  \eqref{p2_a}, \eqref{p3_a} and \eqref{p4_a} that $y^n\in\Tc_{j|1}(u^n;k)\subseteq\Tc_{j|1}(k)\subseteq\Tc_{j|1}$ if and only if
\begin{subequations}
\begin{empheq}[left=\empheqlbrace]{align}
&P_{X^n,Y^n}(\cb_1,y^n)=P_{X^n,Y^n}(\cb_j,y^n)=\max_{h\in[M]\setminus\{1\}}P_{X^n, Y^n}(x^n_{(h)},y^n)\text{ and }d(\cb_1,y^n|\Sc_{1,j})<|\Sc_{i,j}|;
\label{p9-con1a_c2}\\
&\ell_{1,j}^{(\eta_k-1)}-1\leq d\big(\cb_1,y^n\big|\Sac_{1,j}^{(\eta_k-1)}\big)\text{ and }d\big(\cb_1,y^n\big|\Sac_{1,j}^{(\eta_k)}\big)=k;\label{p9-con1b_c2}\\
&d\big(u^n,y^n\big|(\Sac_{1,j}^{(\eta_k)})^{\text{c}}\big)=0.\label{p9-con1c_c2}
\end{empheq}
\end{subequations}
Thus, the number of elements in $\Tc_{j|1}(u^n;k)$ is exactly the number of channel outputs $y^n$ fulfilling the above three conditions.
We then examine the number of $y^n$ satisfying \eqref{p9-con1b_c2} and \eqref{p9-con1c_c2}. Noting that these $y^n$ have either $\ell_{1,j}^{(\eta_k-1)}-1$ ones or $\ell_{1,j}^{(\eta_k-1)}$ ones with indices in $\Sac_{1,j}^{(\eta_k-1)}$, we know that there are at most
\begin{IEEEeqnarray}{rCl}
{\ell_{1,j}^{(\eta_k-1)}\choose \ell_{1,j}^{(\eta_k-1)}-1} {\ell_{j}^{(\eta_k)}-\ell_{1,j}^{(\eta_k-1)}\choose k-(\ell_{1,j}^{(\eta_k-1)}-1)}
+{\ell_{1,j}^{(\eta_k-1)}\choose \ell_{1,j}^{(\eta_k-1)}} {\ell_{j}^{(\eta_k)}-\ell_{1,j}^{(\eta_k-1)}\choose k-\ell_{1,j}^{(\eta_k-1)}}\label{86}
\end{IEEEeqnarray} 
of $y^n$ tuples satisfying \eqref{p9-con1b_c2} and \eqref{p9-con1c_c2}. Disregarding \eqref{p9-con1a_c2}, we get that the number of elements in $\Tc_{j|1}(u^n;k)$ is upper-bounded by
\eqref{86}.

On the other hand, from \eqref{p2_b}, \eqref{p3_b} and \eqref{p4_b}, we obtain that 
$w^n\in\Nc_{j|1}(u^n;k)\subseteq\Nc_{j|1}(k)\subseteq\Nc_{j|1}$ if and only if
\begin{subequations}
\begin{empheq}[left=\empheqlbrace]{align}
&P_{X^n,Y^n}(\cb_1,w^n)\cdot q^2=P_{X^n,Y^n}(\cb_j,w^n);\label{p9-con2a_c2}\\
&P_{X^n,Y^n}(\cb_1,w^n)\cdot q^2\not=P_{X^n,Y^n}(\cb_r,w^n)\text{ for }r\in[j-1]\setminus\{1\};\label{p9-con2a-1_c2}\\
&\ell_{1,j}^{(\eta_k-1)}=d\big(\cb_1,w^n\big|\Sac_{1,j}^{(\eta_k-1)}\big)\text{ and } d\big(\cb_1,w^n\big|\Sac_{1,j}^{(\eta_k)}\big)=k+1;\label{p9-con2b_c2}\\
&d\big(u^n,w^n\big|(\Sac_{1,j}^{(\eta_k)})^{\text{c}}\big)=0.\label{p9-con2c_c2}
\end{empheq}
\end{subequations}
We then claim that any $w^n$ satisfying \eqref{p9-con2b_c2} and \eqref{p9-con2c_c2} directly validate \eqref{p9-con2a_c2} and \eqref{p9-con2a-1_c2}.
Note that the validity of the claim, which we prove  in Appendix \ref{detail}, immediately implies that the number of elements in $\Nc_{j|1}(u^n;k)$ can be determined by \eqref{p9-con2b_c2} and \eqref{p9-con2c_c2},
and hence 
\begin{equation}\label{36}
|\Nc_{j|1}(u^n;k)|=\binom{\ell_{j}^{(\eta_k)}-\ell_{1,j}^{(\eta_k-1)}}{k+1-\ell_{1,j}^{(\eta_k-1)}}.
\end{equation}
Under this claim, \eqref{86} and \eqref{36} result in:
\begin{IEEEeqnarray}{rCl}
\frac{|\Tc_{j|1}(u^n;k)|}{|\Nc_{j|1}(u^n;k)|}
&\leq&\frac{{\ell_{1,j}^{(\eta_k-1)}\choose \ell_{1,j}^{(\eta_k-1)}-1} {\ell_{j}^{(\eta_k)}-\ell_{1,j}^{(\eta_k-1)}\choose k-(\ell_{1,j}^{(\eta_k-1)}-1)}
+{\ell_{1,j}^{(\eta_k-1)}\choose \ell_{1,j}^{(\eta_k-1)}} {\ell_{j}^{(\eta_k)}-\ell_{1,j}^{(\eta_k-1)}\choose k-\ell_{1,j}^{(\eta_k-1)}}}{\binom{\ell_{j}^{(\eta_k)}-\ell_{1,j}^{(\eta_k-1)}}{k+1-\ell_{1,j}^{(\eta_k-1)}}}\label{morezero}\\
&=&\ell_{1,j}^{(\eta_k-1)}+\frac{k+1-\ell_{1,j}^{(\eta_k-1)}}{\ell_{j}^{(\eta_k)}-k}\\
&\leq& \ell_{1,j}^{(\eta_k-1)}+{\frac{\ell_{j}^{(\eta_k)}-\ell_{1,j}^{(\eta_k-1)}}1}\label{so_1}\\
&\leq&\,n\label{so_2},
\end{IEEEeqnarray}
where \eqref{so_1} holds because $ k\leq\ell_{j}^{(\eta_k)}-1$ by \eqref{mappingkm}, and \eqref{so_2} follows from $\ell_{1,j}^{(\eta_k)}\leq \ell_{1,j}\leq n$. The proof of the proposition is thus completed by \eqref{eq:exact} and \eqref{so_2}.
\end{IEEEproof}

\section{Conclusion}
\label{Con}
In this paper, we analyzed the error probability of block codes sent over the memoryless BSC under an arbitrary (not necessarily uniform) input distribution and used in conjunction with (optimal) MAP decoding. We showed that decoder ties do not affect the error exponent of the probability of error, thus extending a similar result recently established in~\cite{us} for uniformly distributed channel inputs. This result was obtained by proving that the relative deviation of the error probability from the probability of error when no MAP decoding ties occur grows no more than linearly in blocklength, directly implying that decoder ties have only a sub-exponential effect on the error probability as blocklength grows without bound. Future work includes further extending this result for more general channels used under arbitrary input statistics, such as non-binary symmetric channels and binary non-symmetric channels. Studying how to sharpen the upper bound derived in~\eqref{eq:bnan} for small blocklengths is another worthwhile future direction.


\begin{appendices}
\section{Supplement to Example \ref{example1}}\label{AA}
\noindent
Under distribution 
\begin{align}
P_{X^4}(\cb_1)&=\frac{q^2}{2+q^2+q^{-2}} \\ 
P_{X^4}(\cb_2)&=P_{X^4}(\cb_3)=\frac{1}{2+q^2+q^{-2}}\\
P_{X^4}(\cb_4)&=\frac{q^{-2}}{2+q^2+q^{-2}}
\end{align}  
%\begin{equation}
%P_{X^4}(\cb_1)=\frac{q^2}{2+q^2+q^{-2}},\quad P_{X^4}(\cb_2)=P_{X^4}(\cb_3)=\frac{1}{2+q^2+q^{-2}}\quad\text{and}\quad P_{X^4}(\cb_4)=\frac{q^{-2}}{2+q^2+q^{-2}}
%\end{equation}
over the code $\code_4=\{\cb_1,\cb_2,\cb_3,\cb_4\}=\{0000, 0101, 0110, 0111\}$, we obtain:
\begin{IEEEeqnarray}{rCl}
 \Tc_1 &=&\bigg\{y^4\in\{0,1\}^4:  P_{X^4,Y^4}(\cb_1,y^4)=\max_{{ r\in[4]\setminus \{1\}}} P_{X^4,Y^4}(\cb_r,y^4)\bigg\}\\
 &=&\bigg\{y^4\in\{0,1\}^4:  \frac{P_{X^4}(\cb_1)}{q^{d(\cb_1,y^4)}}
 =\max\bigg( \frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)}},\frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)}},\frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)}}\bigg)\bigg\}\label{65}\\
 &=&\bigg\{y^4\in\{0,1\}^4:  d(\cb_1,y^4)-2
 =\min\Big( d(\cb_2,y^4),d(\cb_3,y^4),d(\cb_4,y^4)+2\Big)\bigg\}\\
&=&\big\{0101,0110,0111,1101,1110,1111\big\},
\end{IEEEeqnarray} 
where \eqref{65} follows from \eqref{prob}, and 
\begin{IEEEeqnarray}{rCl}
\Tc_{j|1}&\triangleq&\bigg\{y^4\in\Tc_1: j=\min_{r\in\Ic_1(y^4):d(\cb_1,y^4|\Sc_{1,r})<|\Sc_{1,r}|} r\bigg\}=\emptyset\quad\text{for }j=2,3,4,
\end{IEEEeqnarray}
and
\begin{IEEEeqnarray}{rCl}
\Tsc_{j|1}&\triangleq&\bigg\{y^4\in\Tc_1\,\Big\backslash\,\Big(\bigcup_{h\in[4]\setminus\{1\}}\Tc_{h|1}\Big): j=\min_{r\in\Ic_1(y^n)}r\bigg\}
=\begin{cases}
\{0101,0111,1101,1111\},&j=2;\\
\{0110,1110\},&j=3;\\
\emptyset,&j=4.
\end{cases}
\end{IEEEeqnarray}
The above derivations are verified via Table~\ref{table2}. 
Continuing with the same setting, we obtain:
\begin{IEEEeqnarray}{rCl}
 \Tc_2 &=&\bigg\{y^4\in\{0,1\}^4:  P_{X^4,Y^4}(\cb_2,y^4)=\max_{{ r\in[4]\setminus \{2\}}} P_{X^4,Y^4}(\cb_r,y^4)\bigg\}\\
 &=&\bigg\{y^4\in\{0,1\}^4:  \frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)}}
 =\max\bigg( \frac{P_{X^4}(\cb_1)}{q^{d(\cb_1,y^4)}},\frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)}},\frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)}}\bigg)\bigg\}\\
 &=&\bigg\{y^4\in\{0,1\}^4:  d(\cb_2,y^4)
 =\min\Big( d(\cb_1,y^4)-2,d(\cb_3,y^4),d(\cb_4,y^4)+2\Big)\bigg\}\\
&=&\big\{0101,0111,1101,1111\big\},
\end{IEEEeqnarray} 
\begin{IEEEeqnarray}{rCl}
\Tc_{j|2}&\triangleq&\bigg\{y^4\in\Tc_2: j=\min_{r\in\Ic_2(y^4):d(\cb_2,y^4|\Sc_{2,r})<|\Sc_{2,r}|} r\bigg\}=
\begin{cases}
\Tc_2,&j=1;\\
\emptyset,&j=3,4\\
\end{cases}
\end{IEEEeqnarray}
and
\begin{IEEEeqnarray}{rCl}
\Tsc_{j|2}&\triangleq&\bigg\{y^4\in\Tc_2\,\Big\backslash\,\Big(\bigcup_{h\in[4]\setminus\{1\}}\Tc_{h|2}\Big): j=\min_{r\in\Ic_2(y^n)}r\bigg\}
=\emptyset\quad\text{for }j=1,3,4,
\end{IEEEeqnarray}
where the above derivations are also confirmed via Table~\ref{table2}. 
Based on Table~\ref{table2}, we further have: 
\begin{IEEEeqnarray}{rCl}
 \Tc_3 &=&\bigg\{y^4\in\{0,1\}^4:  P_{X^4,Y^4}(\cb_3,y^4)=\max_{{ r\in[4]\setminus \{3\}}} P_{X^4,Y^4}(\cb_r,y^4)\bigg\}\\
 &=&\bigg\{y^4\in\{0,1\}^4:  \frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)}}
 =\max\bigg( \frac{P_{X^4}(\cb_1)}{q^{d(\cb_1,y^4)}},\frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)}},\frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)}}\bigg)\bigg\}\\
 &=&\bigg\{y^4\in\{0,1\}^4:  d(\cb_3,y^4)
 =\min\Big( d(\cb_1,y^4)-2,d(\cb_2,y^4),d(\cb_4,y^4)+2\Big)\bigg\}\\
&=&\big\{0110,0111,1110,1111\big\},
\end{IEEEeqnarray} 
\begin{IEEEeqnarray}{rCl}
\Tc_{j|3}&\triangleq&\bigg\{y^4\in\Tc_3: j=\min_{r\in\Ic_3(y^4):d(\cb_3,y^4|\Sc_{3,r})<|\Sc_{3,r}|} r\bigg\}=
\begin{cases}
\Tc_3,&j=1;\\
\emptyset,&j=2,4,
\end{cases}
\end{IEEEeqnarray}
and
\begin{IEEEeqnarray}{rCl}
\Tsc_{j|3}&\triangleq&\bigg\{y^4\in\Tc_3\,\Big\backslash\,\Big(\bigcup_{h\in[4]\setminus\{3\}}\Tc_{h|3}\Big): j=\min_{r\in\Ic_3(y^n)}r\bigg\}
=\emptyset\quad\text{for }j=1,2,4.
\end{IEEEeqnarray}
Furthermore, we establish from Table~\ref{table2} that:
\begin{IEEEeqnarray}{rCl}
 \Tc_4 &=&\bigg\{y^4\in\{0,1\}^4:  P_{X^4,Y^4}(\cb_4,y^4)=\max_{{ r\in[4]\setminus \{4\}}} P_{X^4,Y^4}(\cb_r,y^4)\bigg\}\\
 &=&\bigg\{y^4\in\{0,1\}^4:  \frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)}}
 =\max\bigg( \frac{P_{X^4}(\cb_1)}{q^{d(\cb_1,y^4)}},\frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)}},\frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)}}\bigg)\bigg\}\\
 &=&\bigg\{y^4\in\{0,1\}^4:  d(\cb_4,y^4)+2
 =\min\Big( d(\cb_1,y^4)-2,d(\cb_2,y^4),d(\cb_3,y^4)\Big)\bigg\}\\
&=&\emptyset,
\end{IEEEeqnarray} 
\begin{IEEEeqnarray}{rCl}
\Tc_{j|4}&\triangleq&\bigg\{y^4\in\Tc_4: j=\min_{r\in\Ic_4(y^4):d(\cb_4,y^4|\Sc_{4,r})<|\Sc_{4,r}|} r\bigg\}=\emptyset\quad\text{for }j=1,2,3,
\end{IEEEeqnarray}
and
\begin{IEEEeqnarray}{rCl}
\Tsc_{j|4}&\triangleq&\bigg\{y^4\in\Tc_4\,\Big\backslash\,\Big(\bigcup_{h\in[4]\setminus\{4\}}\Tc_{h|4}\Big): j=\min_{r\in\Ic_4(y^n)}r\bigg\}
=\emptyset\quad\text{for }j=1,2,3.
\end{IEEEeqnarray}
After summarizing all sets derived above in Table~\ref{table3}, we remark that  
\begin{equation}
\begin{cases}
\Tsc_{2|1}\subseteq\Tc_{1|2}\quad\text{and}\quad 
P_{X^4,Y^4}(\cb_1,y^4)=P_{X^4,Y^4}(\cb_2,y^4)\quad\text{for every }y^4\in\Tsc_{2|1};\\
\Tsc_{3|1}\subseteq\Tc_{1|3}\quad\text{and}\quad 
P_{X^4,Y^4}(\cb_1,y^4)=P_{X^4,Y^4}(\cb_2,y^4)\quad\text{for every }y^4\in\Tsc_{3|1}.
\end{cases}
\end{equation}
Note that $\{\Tsc_{j|i}\}_{i\in[M], j\in[M]\setminus\{i\}}$ are disjoint as confirmed in Remark~\ref{R4} such that every element $y^n\in \Tsc_{j|i}$ appears only once in the following summation:
\begin{IEEEeqnarray}{rCl}
\sum_{i\in [4]}\sum_{j\in [4]\setminus\{i\}}P_{X^4,Y^4}\big(\cb_i, \Tsc_{j|i}\big)
&=&P_{X^4,Y^4}\big(\cb_1, 0101\big)
+P_{X^4,Y^4}\big(\cb_1, 0110\big)
+P_{X^4,Y^4}\big(\cb_1, 0111\big)\nonumber\\
&&+P_{X^4,Y^4}\big(\cb_1, 1101\big)
+P_{X^4,Y^4}\big(\cb_1, 1110\big)
+P_{X^4,Y^4}\big(\cb_1, 1111\big)\\
&=&\frac{p^4q^2}{2+q^2+q^{-2}}\big( q^{2}+q^2+q+q+q+1\big)\\
&=&\frac{p^4q^2}{2+q^2+q^{-2}}\big(2q^{2}+3q+1\big).
\end{IEEEeqnarray}
Also,
\begin{IEEEeqnarray}{rCl}
\sum_{i\in [4]} \sum_{j\in [4]\setminus\{i\}}P_{X^4,Y^4}\big(\cb_i, \Tc_{j|i}\big)
&=&P_{X^4,Y^4}\big(\cb_2, 0101\big)+P_{X^4,Y^4}\big(\cb_2, {0111}\big)+P_{X^4,Y^4}\big(\cb_2, 1101\big)\nonumber\\
&&+P_{X^4,Y^4}\big(\cb_2, {1111}\big)+P_{X^4,Y^4}\big(\cb_3, 0110\big)
+P_{X^4,Y^4}\big(\cb_3, {0111}\big)\nonumber\\
&&+P_{X^4,Y^4}\big(\cb_3, 1110\big)+P_{X^4,Y^4}\big(\cb_3, {1111}\big)\\
&=&\frac{p^4}{2+q^2+q^{-2}}\big(q^4+{q^3}+q^3+{q^2}+q^4+{q^3}+q^3+{q^2}\big)\\
&=&\sum_{i\in [4]}\sum_{j\in [4]\setminus\{i\}}P_{X^4,Y^4}\big(\cb_i, \Tsc_{j|i}\big)
+\frac{p^4q^2}{2+q^2+q^{-2}}\big({q}+{1}\big).\label{92}
\end{IEEEeqnarray}
Finally, we have:
\begin{IEEEeqnarray}{rCl}
 \Nc_1
 &=&\bigg\{y^4\in\{0,1\}^4:  \frac{P_{X^4}(\cb_1)}{q^{d(\cb_1,y^4)}}
 <\max\bigg( \frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)}},\frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)}},\frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)}}\bigg)\bigg\}\\
 &=&\bigg\{y^4\in\{0,1\}^4:  d(\cb_1,y^4)-2
 >\min\Big( d(\cb_2,y^4),d(\cb_3,y^4),d(\cb_4,y^4)+2\Big)\bigg\}\\
&=&\emptyset,
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
 \Nc_2
 &=&\bigg\{y^4\in\{0,1\}^4:  d(\cb_2,y^4) 
 >\min\Big( d(\cb_1,y^4)-2,d(\cb_3,y^4),d(\cb_4,y^4)+2\Big)\bigg\}=\{0,1\}^4\setminus\Tc_2,
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
 \Nc_3
  &=&\bigg\{y^4\in\{0,1\}^4:  d(\cb_3,y^4) 
 >\min\Big( d(\cb_2,y^4),d(\cb_1,y^4)-2,d(\cb_4,y^4)+2\Big)\bigg\}
=\{0,1\}^4\setminus\Tc_3,
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
 \Nc_4
 &=&\bigg\{y^4\in\{0,1\}^4:  d(\cb_4,y^4)+2 
 >\min\Big( d(\cb_2,y^4),d(\cb_3,y^4),d(\cb_1,y^4)-2\Big)\bigg\}=\{0,1\}^4,
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
\Nc_{j|1}&=&\emptyset\quad\text{for }j=2,3,4,
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
\Nc_{j|2}&=&
\bigg\{y^4\in\Nc_2: P_{X^4,Y^4}(\cb_2,y^4)\cdot q=P_{X^4,Y^4}(\cb_j,y^4)\cdot\frac 1q \nonumber\\
&&\quad\quad\quad\quad\quad\quad\quad\quad\quad  
\text{and }P_{X^4,Y^4}(\cb_j,y^4)\neq
P_{X^4,Y^4}(\cb_r,y^4)\text{ for }~r\in[j-1]\setminus\{2\}\bigg\}\\
&=&
\bigg\{y^4\in\Nc_2: \frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)-1}}=\frac{P_{X^4}(\cb_j)}{q^{d(\cb_j,y^4)+1}} \text{ and }\frac{P_{X^4}(\cb_j)}{q^{d(\cb_j,y^4)}}\neq
\frac{P_{X^4}(\cb_r)}{q^{d(\cb_r,y^4)}}\text{ for }~r\in[j-1]\setminus\{2\}\bigg\}\\
&=&\begin{cases}
\bigg\{y^4\in\Nc_2: \frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)-1}}=\frac{P_{X^4}(\cb_1)}{q^{d(\cb_1,y^4)+1}} \bigg\},&j=1;\\
\bigg\{y^4\in\Nc_2: \frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)-1}}=\frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)+1}} \text{ and }\frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)}}\neq
\frac{P_{X^4}(\cb_1)}{q^{d(\cb_1,y^4)}}\bigg\},&j=3;\\
\bigg\{y^4\in\Nc_2: \frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)-1}}=\frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)+1}} \text{ and }\frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)}}\neq
\frac{P_{X^4}(\cb_r)}{q^{d(\cb_r,y^4)}}\text{ for }~r\in[3]\setminus\{2\}\bigg\},&j=4\\
\end{cases}\\
&=&\begin{cases}
\bigg\{y^4\in\Nc_2: d(\cb_2,y^4)=d(\cb_1,y^4) \bigg\},&j=1;\\
\bigg\{y^4\in\Nc_2: d(\cb_2,y^4)=d(\cb_3,y^4)+2 \text{ and }d(\cb_2,y^4)\neq
d(\cb_1,y^4)\bigg\},&j=3;\\
\bigg\{y^4\in\Nc_2: d(\cb_2,y^4)=d(\cb_4,y^4)+4, d(\cb_2,y^4)\neq
d(\cb_1,y^4)\text{ and }d(\cb_2,y^4)\neq
d(\cb_3,y^4)+2\bigg\},&j=4\\
\end{cases}\nonumber\\
&&\\
&=&\begin{cases}
\big\{0001,0100,0011,0110,1001,1100,1011,1110\big\},&j=1;\\
\big\{0010,1010\big\},&j=3;\\
\emptyset,&j=4,\\
\end{cases}
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
\Nc_{j|3}&=&
\bigg\{y^4\in\Nc_3: P_{X^4,Y^4}(\cb_3,y^4)\cdot q=P_{X^4,Y^4}(\cb_j,y^4)\cdot\frac 1q \nonumber\\
&&\quad\quad\quad\quad\quad\quad\quad\quad\quad  
\text{and }P_{X^4,Y^4}(\cb_j,y^4)\neq
P_{X^4,Y^4}(\cb_r,y^4)\text{ for }~r\in[j-1]\setminus\{3\}\bigg\}\\
&=&
\bigg\{y^4\in\Nc_3: \frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)-1}}=\frac{P_{X^4}(\cb_j)}{q^{d(\cb_j,y^4)+1}} \text{ and }\frac{P_{X^4}(\cb_j)}{q^{d(\cb_j,y^4)}}\neq
\frac{P_{X^4}(\cb_r)}{q^{d(\cb_r,y^4)}}\text{ for }~r\in[j-1]\setminus\{3\}\bigg\}\\
&=&\begin{cases}
\bigg\{y^4\in\Nc_3: \frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)-1}}=\frac{P_{X^4}(\cb_1)}{q^{d(\cb_1,y^4)+1}} \bigg\},&j=1;\\
\bigg\{y^4\in\Nc_3: \frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)-1}}=\frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)+1}} \text{ and }\frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)}}\neq
\frac{P_{X^4}(\cb_1)}{q^{d(\cb_1,y^4)}}\bigg\},&j=2;\\
\bigg\{y^4\in\Nc_3: \frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)-1}}=\frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)+1}} \text{ and }\frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)}}\neq
\frac{P_{X^4}(\cb_r)}{q^{d(\cb_r,y^4)}}\text{ for }~r\in[3]\setminus\{3\}\bigg\},&j=4\\
\end{cases}\\
&=&\begin{cases}
\bigg\{y^4\in\Nc_3: d(\cb_3,y^4)=d(\cb_1,y^4) \bigg\},&j=1;\\
\bigg\{y^4\in\Nc_3: d(\cb_3,y^4)=d(\cb_2,y^4)+2 \text{ and }d(\cb_3,y^4)\neq
d(\cb_1,y^4)\bigg\},&j=3;\\
\bigg\{y^4\in\Nc_3: d(\cb_3,y^4)=d(\cb_4,y^4)+4, d(\cb_3,y^4)\neq
d(\cb_1,y^4)\text{ and }d(\cb_3,y^4)\neq
d(\cb_2,y^4)+2\bigg\},&j=4\\
\end{cases}\nonumber\\
&&\\
&=&\begin{cases}
\big\{0010,0100,0011,0101,1010,1100,1011,1101\big\},&j=1;\\
\big\{0001,1001\big\},&j=3;\\
\emptyset,&j=4,\\
\end{cases}
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
\Nc_{j|4}&=&
\bigg\{y^4\in\Nc_4: P_{X^4,Y^4}(\cb_4,y^4)\cdot q=P_{X^4,Y^4}(\cb_j,y^4)\cdot\frac 1q \nonumber\\
&&\quad\quad\quad\quad\quad\quad\quad\quad\quad  
\text{and }P_{X^4,Y^4}(\cb_j,y^4)\neq
P_{X^4,Y^4}(\cb_r,y^4)\text{ for }~r\in[j-1]\setminus\{4\}\bigg\}\\
&=&
\bigg\{y^4\in\Nc_4: \frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)-1}}=\frac{P_{X^4}(\cb_j)}{q^{d(\cb_j,y^4)+1}} \text{ and }\frac{P_{X^4}(\cb_j)}{q^{d(\cb_j,y^4)}}\neq
\frac{P_{X^4}(\cb_r)}{q^{d(\cb_r,y^4)}}\text{ for }~r\in[j-1]\bigg\}\\
&=&\begin{cases}
\bigg\{y^4\in\Nc_4: \frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)-1}}=\frac{P_{X^4}(\cb_1)}{q^{d(\cb_1,y^4)+1}} \bigg\},&j=1;\\
\bigg\{y^4\in\Nc_4: \frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)-1}}=\frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)+1}} \text{ and }\frac{P_{X^4}(\cb_2)}{q^{d(\cb_2,y^4)}}\neq
\frac{P_{X^4}(\cb_1)}{q^{d(\cb_1,y^4)}}\bigg\},&j=2;\\
\bigg\{y^4\in\Nc_4: \frac{P_{X^4}(\cb_4)}{q^{d(\cb_4,y^4)-1}}=\frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)+1}} \text{ and }\frac{P_{X^4}(\cb_3)}{q^{d(\cb_3,y^4)}}\neq
\frac{P_{X^4}(\cb_r)}{q^{d(\cb_r,y^4)}}\text{ for }~r\in[2]\bigg\},&j=3
\end{cases}\\
&=&\begin{cases}
\bigg\{y^4\in\Nc_4: d(\cb_4,y^4)=d(\cb_1,y^4)-2 \bigg\},&j=1;\\
\bigg\{y^4\in\Nc_4: d(\cb_4,y^4)=d(\cb_2,y^4) \text{ and }d(\cb_4,y^4)\neq
d(\cb_1,y^4)-2\bigg\},&j=2;\\
\bigg\{y^4\in\Nc_4: d(\cb_4,y^4)=d(\cb_3,y^4), d(\cb_4,y^4)\neq
d(\cb_1,y^4)-2\text{ and }d(\cb_4,y^4)\neq
d(\cb_2,y^4)\bigg\},&j=3\\
\end{cases}\nonumber\\
&&\\
&=&\emptyset\quad\text{for }j=1,2,3.
\end{IEEEeqnarray}

\begin{table}[h]
\begin{center}
\caption{Measures used in Example~\ref{example1}}\label{table2}
\begin{tabular}{c|c|c|c|c||c|c|c|c}
&$d(0000,y^4)-2$&$d(0101,y^4)$&$d(0110,y^4)$&$d(0111,y^4)+2$&$\Ic_1(y^4)$&$\Ic_2(y^4)$&$\Ic_3(y^4)$&$\Ic_4(y^4)$\\\hline
$y^4=0000$&$-2$&$2$&$2$&$5$&$\emptyset$&$\emptyset$&$\emptyset$&$\emptyset$\\\hline
$y^4=0001$&$-1$&$1$&$3$&$4$&$\emptyset$&$\emptyset$&$\emptyset$&$\emptyset$\\
$y^4=0010$&$-1$&$3$&$1$&$4$&$\emptyset$&$\emptyset$&$\emptyset$&$\emptyset$\\
$y^4=0100$&$-1$&$1$&$1$&$4$&$\emptyset$&$\emptyset$&$\emptyset$&$\emptyset$\\
$y^4=1000$&$-1$&$3$&$3$&$6$&$\emptyset$&$\emptyset$&$\emptyset$&$\emptyset$\\\hline
$y^4=0011$&$0$&$2$&$2$&$3$&$\emptyset$&$\emptyset$&$\emptyset$&$\emptyset$\\
$y^4=0101$&$0$&$0$&$2$&$3$&$\{2\}$&$\{1\}$&$\emptyset$&$\emptyset$\\
$y^4=0110$&$0$&$2$&$0$&$3$&$\{3\}$&$\emptyset$&$\{1\}$&$\emptyset$\\
$y^4=1001$&$0$&$2$&$4$&$5$&$\emptyset$&$\emptyset$&$\emptyset$&$\emptyset$\\
$y^4=1010$&$0$&$4$&$2$&$5$&$\emptyset$&$\emptyset$&$\emptyset$&$\emptyset$\\
$y^4=1100$&$0$&$2$&$2$&$5$&$\emptyset$&$\emptyset$&$\emptyset$&$\emptyset$\\\hline
$y^4=0111$&$1$&$1$&$1$&$2$&$\{2,3\}$&$\{1,3\}$&$\{1,2\}$&$\emptyset$\\
$y^4=1011$&$1$&$3$&$3$&$4$&$\emptyset$&$\emptyset$&$\emptyset$&$\emptyset$\\
$y^4=1101$&$1$&$1$&$3$&$4$&$\{2\}$&$\{1\}$&$\emptyset$&$\emptyset$\\
$y^4=1110$&$1$&$3$&$1$&$4$&$\{3\}$&$\emptyset$&$\{1\}$&$\emptyset$\\\hline
$y^4=1111$&$2$&$2$&$2$&$3$&$\{2,3\}$&$\{1,3\}$&$\{1,2\}$&$\emptyset$
\end{tabular}
\end{center}
\end{table}

\begin{table}[h]
\caption{List of $\Tc_i$, $\Nc_i$, $\Tc_{j|i}$, $\Tsc_{j|i}$ and $\Nc_{j|i}$ for $i\in[4]$ and $j\in[4]\setminus\{i\}$ in Example~\ref{example1}}\label{table3}
\begin{center}
\begin{tabular}{c|l||c|l||c|l}
$\Tc_1$&\multicolumn{3}{l||}{$\big\{0101,0110,0111,1101,1110,1111\big\}$}&$\Nc_1$&$\emptyset$\\
$\Tc_2$&\multicolumn{3}{l||}{$\big\{0101,0111,1101,1111\big\}$}&$\Nc_2$&$\{0,1\}^4\setminus\Tc_2$\\
$\Tc_3$&\multicolumn{3}{l||}{$\big\{0110,0111,1110,1111\big\}$}&$\Nc_3$&$\{0,1\}^4\setminus\Tc_3$\\
$\Tc_4$&\multicolumn{3}{l||}{$\emptyset$}&$\Nc_4$&$\{0,1\}^4$\\\hline\hline
$\Tc_{2|1}$&$\emptyset$&$\Tsc_{2|1}$&$\{0101,0111,1101,1111\}$&$\Nc_{2|1}$&$\emptyset$\\
$\Tc_{3|1}$&$\emptyset$&$\Tsc_{3|1}$&$\{0110,1110\}$&$\Nc_{3|1}$&$\emptyset$\\
$\Tc_{4|1}$&$\emptyset$&$\Tsc_{3|1}$&$\emptyset$&$\Nc_{4|1}$&$\emptyset$\\\hline
$\Tc_{1|2}$&$\{0101,{0111},1101,{1111}\}$&$\Tsc_{1|2}$&$\emptyset$&$\Nc_{1|2}$&$\Nc_2\setminus\{0000,0010,1000,1010\}$\\
$\Tc_{3|2}$&$\emptyset$&$\Tsc_{3|2}$&$\emptyset$&$\Nc_{3|2}$&$\{0010,1010\}$\\
$\Tc_{4|2}$&$\emptyset$&$\Tsc_{4|2}$&$\emptyset$&$\Nc_{1|2}$&$\emptyset$\\\hline
$\Tc_{1|3}$&$\{0110,{0111},1110,{1111}\}$&$\Tsc_{1|3}$&$\emptyset$&$\Nc_{1|3}$&$\Nc_3\setminus\{0000,0001,1000,1001\}$\\
$\Tc_{2|3}$&$\emptyset$&$\Tsc_{2|3}$&$\emptyset$&$\Nc_{2|3}$&$\{0001,1001\}$\\
$\Tc_{4|3}$&$\emptyset$&$\Tsc_{4|3}$&$\emptyset$&$\Nc_{4|3}$&$\emptyset$\\\hline
$\Tc_{1|4}$&$\emptyset$&$\Tsc_{1|4}$&$\emptyset$&$\Nc_{1|4}$&$\emptyset$\\
$\Tc_{2|4}$&$\emptyset$&$\Tsc_{2|4}$&$\emptyset$&$\Nc_{2|4}$&$\emptyset$\\
$\Tc_{3|4}$&$\emptyset$&$\Tsc_{3|4}$&$\emptyset$&$\Nc_{3|4}$&$\emptyset$\\
\end{tabular}
\end{center}
\end{table}

\section{The Proof of the Claim Supporting Proposition~\ref{proposition9}}\label{detail}

We validate the claim that \eqref{p9-con2b_c2} and \eqref{p9-con2c_c2} imply  \eqref{p9-con2a_c2} and  \eqref{p9-con2a-1_c2} via the construction of an auxiliary $v^n\in \Nc_{j|1}(u^n;k)$ from $u^n\in \Tc_{j|1}(u^n;k)$. This auxiliary $v^n$ will be defined differently according to whether $d\big(\cb_1,u^n\big|\Sac_{1,j}^{(\eta_k-1)}\big)$ equals $\ell_{1,j}^{(\eta_k-1)}$ or $\ell_{1,j}^{(\eta_k-1)}-1$ as follows.
\begin{enumerate}
\item[$i)$] $d(\cb_1,u^n|\Sac_{1,j}^{(\eta_k-1)})=\ell_{1,j}^{(\eta_k-1)}$: In this case, $u^n$ has no zero components with indices in $\Sac_{1,j}^{(\eta_k-1)}$. Moreover,  $d(\cb_1,u^n|\Sac_{1,j}^{(\eta_k)})=k\leq\ell_{j}^{(\eta_k)}-1$ indicates that: 
\begin{IEEEeqnarray}{rCl}
u^n \text{ has at least one zero component with its index in } \Sac_{1,j}^{(\eta_k)}\setminus \Sac_{1,j}^{(\eta_k-1)}=\Sc_{1,j}^{(\eta_k)}.\label{cont}
\end{IEEEeqnarray} 
Therefore, we flip arbitrarily a zero component of $u^n$ with its index in $\Sc_{1,j}^{(\eta_k)}$ to construct a $v^n$ such that  
\begin{equation}\label{key-extension}
d(\cb_1,v^n)=d(\cb_1,u^n)+1\quad\text{and}\quad
d(\cb_j,v^n)=d(\cb_j,u^n)-1,
\end{equation}
which implies
\begin{IEEEeqnarray}{rCl}
P_{X^n,Y^n}(\cb_1,v^n)=P_{X^n,Y^n}(\cb_1,u^n)\cdot \frac 1q \quad\text{and}\quad P_{X^n,Y^n}(\cb_j,v^n)=P_{X^n,Y^n}(\cb_j,u^n)\cdot q.
\end{IEEEeqnarray}
Then, $v^n$ must fulfill \eqref{p9-con2a_c2}, \eqref{p9-con2b_c2} and \eqref{p9-con2c_c2} (with $w^n$ replaced by $v^n$) as $u^n$ satisfies \eqref{p9-con1a_c2}, \eqref{p9-con1b_c2} and \eqref{p9-con1c_c2}. We next declare that $v^n$ also fulfills \eqref{p9-con2a-1_c2} and will prove this declaration by contradiction. 

{\it Proof of the declaration:} Suppose there exists a $r\in[j-1]\setminus\{1\}$ satisfying 
\begin{equation}\label{contradiction}
P_{X^n,Y^n}(\cb_1,v^n)\cdot q^2=P_{X^n,Y^n}(\cb_r,v^n).
\end{equation}
We then recall from \eqref{remark5} that $d(\cb_1,\cb_r|\Sc_{1,j}^{(\eta_k)})$ is either $0$ or $|\Sc_{1,j}^{(\eta_k)}|$. Thus, \eqref{contradiction} can be disproved by differentiating two subcases: $1)$ $d(\cb_1,\cb_r|\Sc_{1,j}^{(\eta_k)})=0$, and $2)$ $d(\cb_1,\cb_r|\Sc_{1,j}^{(\eta_k)})=|\Sc_{1,j}^{(\eta_k)}|$.\footnote{Since 
$\ell_{1,j}^{(\eta_k-1)}<\ell_{1,j}^{(\eta_k)}$ as can be seen from \eqref{mappingkm1} and~\eqref{mappingkm2}, we have $|\Sc_{1,j}^{(\eta_k)}|=\ell_{1,j}^{(\eta_k)}-\ell_{1,j}^{(\eta_k-1)}>0$, i.e., $\Sc_{1,j}^{(\eta_k)}$ non-empty.} 

\hspace*{6mm}
In Subcase $1)$,  $v^n$ that is obtained by flipping a zero component of $u^n$ with index in $\Sc_{1,j}^{(\eta_k)}$ must satisfy $d(\cb_1,v^n)=d(\cb_1,u^n)+1$ and $d(\cb_r,v^n)=d(\cb_r,u^n)+1$, which is equivalent to
\begin{equation}
P_{X^n,Y^n}(\cb_1,v^n)\cdot q=P_{X^n,Y^n}(\cb_1,u^n)
\text{ and }P_{X^n|Y^n}(\cb_r|v^n)\cdot q=P_{X^n|Y^n}(\cb_r|u^n).
\end{equation}
Then, \eqref{contradiction} implies 
\begin{equation}
P_{X^n,Y^n}(\cb_1,u^n)\cdot q^2=P_{X^n,Y^n}(\cb_r,u^n).
\end{equation}
Hence, 
\begin{equation}
P_{X^n,Y^n}(\cb_1,u^n)<P_{X^n,Y^n}(\cb_r,u^n)\leq\max_{h\in[M]\setminus\{1\}}P_{X^n,Y^n}(x^n_{(h)},u^n).
\end{equation}
A contradiction to the fact that $u^n\in \Tc_{j|1}(u^n;k)$ satisfies \eqref{p9-con1a_c2} (with $y^n$ replaced by $u^n$) is obtained. 

\hspace*{6mm}
In Subcase $2)$, we note that $d(\cb_1,\cb_r|\Sc_{1,j}^{(\eta_k)})=|\Sc_{1,j}^{(\eta_k)}|$ implies $\Sc_{1,j}^{(\eta_k)}\subseteq \Sc_{1,r}$. Therefore,  \eqref{cont} leads to
\begin{IEEEeqnarray}{rCl}
d(\cb_1,u^n|\Sc_{1,r})<|\Sc_{1,r}|.\label{cont2}
\end{IEEEeqnarray}
 The flipping manipulation on $u^n$ results in $d(\cb_1,v^n)=d(\cb_1,u^n)+1$ and $d(\cb_r,v^n)=d(\cb_r,u^n)-1$, which is equivalent to
\begin{equation}
P_{X^n,Y^n}(\cb_1,v^n)\cdot q=P_{X^n,Y^n}(\cb_1,u^n)\text{ and }P_{X^n,Y^n}(\cb_r,v^n)=P_{X^n,Y^n}(\cb_r,u^n)\cdot q.
\end{equation}
Therefore, \eqref{contradiction} implies 
\begin{equation}
P_{X^n,Y^n}(\cb_1,u^n)=P_{X^n,Y^n}(\cb_r,u^n),\label{cont_end}
\end{equation}
which together with $\max_{h\in[M]\setminus\{1\}}P_{X^n,Y^n}(\cb_h,u^n)=P_{X^n,Y^n}(\cb_1,u^n)$ and \eqref{cont2} result in $u^n\in \Tc_{r|1}$ because $r<j$. This contradict to that $u^n\in \Tc_{j|1}$. Accordingly, $v^n$ must also fulfill \eqref{p9-con2a-1_c2}; hence, $v^n\in\Nc_{j|1}(u^n;k)$. This completes the proof of the declaration. \hfill$\Box$

\hspace*{6mm}
With this auxiliary $v^n$, we are ready to prove that every $w^n$ satisfying \eqref{p9-con2b_c2} and \eqref{p9-con2c_c2} also validates \eqref{p9-con2a_c2} and \eqref{p9-con2a-1_c2}. Toward this end, we need to prove 
\begin{IEEEeqnarray}{rCl}\label{later}
P_{X^n,Y^n}(\cb_r,w^n)=P_{X^n,Y^n}(\cb_r,v^n)\text{ for all }r\in[M].
\end{IEEEeqnarray}
Note that
\begin{subequations}
\begin{empheq}[left=\empheqlbrace]{align}
&d\big(w^n,v^n\big|\Sac_{1,j}^{(\eta_k-1)}\big)=0;\label{aaa}\\
&d\big(\cb_r,w^n\big|\Sc_{1,j}^{(\eta_k)}\big)=d\big(\cb_r,v^n\big|\Sc_{1,j}^{(\eta_k)}\big)\text{ for all }r\in[M];\label{bbb}\\
&d\big(w^n,v^n\big|(\Sac_{1,j}^{(\eta_k-1)})^{\text{c}}=0,\label{ccc}
\end{empheq}
\end{subequations}
where \eqref{aaa} holds because both $v^n$ and $w^n$ satisfy \eqref{p9-con2b_c2}, implying that all components of $v^n$ and $w^n$ with indices in $\Sac_{1,j}^{(\eta_k-1)}$ are equal  to one; \eqref{bbb} holds because when considering only those portions with indices in (non-empty) $\Sc_{1,j}^{(\eta_k)}$, $\cb_r$ gives either all ones or all zeros according to \eqref{remark5}, and both $w^n$ and $v^n$ have exactly $k+1-\ell_{1,j}^{(\eta_k-1)}$ ones according to \eqref{p9-con2b_c2}; and \eqref{ccc} is valid since both $v^n$ and $w^n$ satisfy \eqref{p9-con2c_c2}. Based on \eqref{aaa}-\eqref{ccc}, we remark that $d(\cb_r, w^n)=d(\cb_r, v^n)$ for all $r\in[M]$, which implies $P_{Y^n|X^n}(w^n|\cb_r)=P_{Y^n|X^n}(v^n|\cb_r)$ (equivalently, $P_{X^n,Y^n}(\cb_r,w^n)=P_{X^n,Y^n}(\cb_r,v^n)$) for all $r\in[M]$).

\item[$ii)$] $d(\cb_1,u^n|\Sac_{1,j}^{(\eta_k-1)})=\ell_{1,j}^{(\eta_k-1)}-1$: In this case, there is only one zero component of $u^n$ with its index in $\Sac_{1,j}^{(\eta_k-1)}$. Suppose the index of such zero component lie in $\Sc_{1,j}^{(h)}\subseteq \Sac_{1,j}^{(\eta_k-1)}$, where $h\leq \eta_k-1$.
The flipping manipulation to $u^n$ leads to $v^n$, which has all one components with respect to $\Sac_{1,j}^{(\eta_k-1)}$. Then, $v^n$ must fulfill \eqref{p9-con2a_c2}, \eqref{p9-con2b_c2} and \eqref{p9-con2c_c2} as $u^n$ satisfies \eqref{p9-con1a_c2}, \eqref{p9-con1b_c2} and \eqref{p9-con1c_c2}. With the components of $\cb_r$ with respect to (non-empty) $\Sc_{1,j}^{(h)}$ being either all zeros or all ones, the same contradiction argument between \eqref{contradiction} and \eqref{cont_end}, with $\eta_k$ replaced by $h$, can disprove the validity of \eqref{contradiction} for this $v^n$ and for any $r\in [j-1]\setminus\{1\}$. Therefore, $v^n$ also fulfills \eqref{p9-con2a-1_c2}, implying $v^n\in\Nc_{j|1}(u^n;k)$. With this auxiliary $v^n$, we can again verify \eqref{aaa}-\eqref{ccc} via the same argument. The claim that 
$w^n$ satisfying \eqref{p9-con2b_c2} and \eqref{p9-con2c_c2} validates \eqref{p9-con2a_c2} and \eqref{p9-con2a-1_c2} is thus confirmed.~\hfill$\Box$
\end{enumerate}
\end{appendices}

\bibliographystyle{IEEEtran}
\bibliography{biblio_dis_pn}
\end{spacing}
\end{document}