\section{Performance}
\label{sec:performance}

\subsection{Training and Architecture Details}

\begin{figure*}[t]
\centering
\includegraphics[width=0.99\textwidth]{figures/architecture-cropped.pdf}
\caption{\textbf{\textit{Network architecture overview.}} The network accepts as input a 4D point cloud of photon OM hits, as shown by the colored points in the figure. The color indicates the timing (red is earlier, blue is later). Residual connections, denoted with $\oplus$, are used in between convolutions. Downsampling (dashed red lines) is performed after a series of convolutions. The final layer of the network is a fully connected layer, which outputs the logarithmic $\nu_\mu$ energy, and the three components of the normalized $\nu_\mu$ direction vector.}
\label{fig:arch}
\end{figure*}

We utilize a ResNet-based architecture, taking advantage of residual connections between layers to promote robust learning for deeper networks.
More details on the network architecture can be found in~\cref{fig:arch}.
A typical block of the network consists of a sparse submanifold convolution, followed by batch normalization and the parametric rectified linear unit (PReLU) activation function.
Downsampling is performed using a stride 2 sparse submanifold convolution.
We use the \texttt{PyTorch} deep learning framework and the \texttt{MinkowskiEngine}~\cite{minkowski} library to implement the network.
The network was trained on each dataset (trigger and quality) for 25 epochs using a batch size of 128 and the \texttt{AdamW} optimizer.
The initial learning rate was set at $0.001$ and was dropped periodically during training.

For the purpose of this article, we train the network to infer the primary neutrino energy $E_\nu$, and the three components of its directional pointing vector, ($X_\nu$, $Y_\nu$, $Z_\nu$).
The directional vector is learned rather than the zenith and azimuth angles because of complications with azimuthal periodicity and undesirable boundary condition behavior at large or small angles.
The network is trained to predict the logarithmic energy, $\log_{10}(E_\nu)$, and the normalized directional vectors, as they can vary over a wide range of magnitudes. 

To train the energy reconstruction task, the \texttt{LogCosh} loss function is used, since it is more robust to outliers than the standard \texttt{MSE} loss.
The loss function is defined as follows,
%
\begin{equation}
    \mathcal{L}_E = \frac{1}{N} \sum^N_i{\log{(\cosh{(x_i - y_i)})}},
\end{equation}
%
where $N$ is the number of events in the batch, $x_i$ are the predictions, and $y_i$ are the labels.
For the angular reconstruction, an angular distance loss function is used, namely,
%
\begin{equation}
    \mathcal{L}_A = \frac{1}{N} \sum^N_i{\arccos{\left(\frac{\vec{X_i} \cdot \vec{Y_i}}{||X_i|| \: ||Y_i||}\right)}},
\end{equation}
%
where $\vec{X_i}$ and $\vec{Y_i}$ are the predicted and true directional vectors, respectively.
Then, the total loss is given by
%
\begin{equation}
    \mathcal{L}_{tot} = \alpha_E\mathcal{L}_E + \alpha_A\mathcal{L}_A,
\end{equation}
where a weighting factor $\alpha$ is applied to each of the separate loss terms to ensure balanced learning between the two different tasks. 

% In addition to the SSCNN, we also train a separate CNN on the same datasets that allows for feature spreading. This network would produce the same results as a traditional CNN and serves as a comparison point. However, due to memory constraints, we modified the architecture of this model by slightly reducing its depth and complexity. Additionally, the traditional CNN model can only fit a batch size of 2 during training, which hinders its learning and makes it significantly slower to train. These compromises can allow the SSCNN to outperform the traditional CNN in certain tasks. 

\subsection{Run-time Performance}

\renewcommand{\arraystretch}{1.25}
\begin{table}[bht]
    \centering
    \begin{tabular}{|p{4.25cm}|p{3cm}|}
        \hline 
        \textbf{SSCNN (GPU)} & \textbf{0.090 $\pm$ 0.007 ms} \\
        \hline
        % \textbf{SSCNN $|$ CPU (Low-energy)} & \textbf{12.1 $\pm$ 7.67 ms} \\
        % \hline
        % \textbf{SSCNN $|$ CPU} & \textbf{45.1 $\pm$ 84.9 ms} \\
        % \hline
        \textbf{SSCNN (CPU)} & \textbf{65.22 $\pm$ 117.04 ms} \\
        \hline
        % CNN (GPU) & 14.7 $\pm$ 7.81 ms \\
        % \hline
        % CNN (CPU) & 5.08 $\pm$ 8.57 s \\
        % \hline
        Max Likelihood (CPU) & 42.6 $\pm$ 175 ms \\
        \hline
    \end{tabular}
    \caption{\textbf{\textit{Per-event average run-time performance.}} The forward pass run-times (mean $\pm$ STD) for SSCNN was evaluated on trigger-level events. A likelihood-based method for energy and angular reconstruction was included for reference~\cite{Mirco:2017, Bradascio:2019eub}.}
    \label{tab:runtime}
\end{table}

We evaluate the run-time performance of the SSCNN in terms of the forward pass duration on both CPU and GPU hardware. The CPU benchmark is performed on a single core of an Intel Xeon Platinum 8358 CPU, while the GPU benchmark uses a 40~GB NVIDIA A100. As is generally the case for neural networks, running on GPU is preferred due to its superior parallel computation capabilities. Additionally, the use of sparse submanifold convolutions has greatly enhanced our GPU memory efficiency, enabling us to run larger batch sizes during inference. The SSCNN can process events at a rate of 11,098 Hz on a 40~GB NVIDIA A100 GPU, while handling a batch size of 12,288 events simultaneously.
This is fast enough to handle the expected $\sim$kHz current and planned large neutrino telescopes.
% This rate is over four times that of the current IceCube trigger rate.

The run-time on a single-core CPU is slower and largely dependent on the number of photons hits in the event due to the limited parallel computation capabilities. However, the SSCNN run-time on a CPU core is comparable to that of the likelihood-based method and is more consistent, as indicated by the lower standard deviation on the run-time distribution. The run-time results on both GPU and CPU are summarized in Table~\ref{tab:runtime}.

% One of the most significant benefits of switching to sparse submanifold convolutions is their improved GPU memory efficiency.
% This enables larger batch sizes during inference, taking advantage of parallel computation.
% On a 40~GB NVIDIA A100~GPU, the SSCNN can process a batch size of 12,288 events at a time.
% We also evaluate the network runtime performance on a single core of an Intel Xeon Platinum 8358 CPU.
% The runtime on a single-core CPU is slower and largely dependent on the number of photons hits in the event due to the limited parallel computation capabilities.
% Because of this, running on GPU is preferred, as is generally the case for neural networks.


\subsection{Reconstruction Performance}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/angular_results.png}
    \caption{\textbf{\textit{Angular reconstruction performance as a function of the true neutrino energy.}} The angular resolution results are binned by the true neutrino energy, with the median taken from each bin to form the lines shown.
    }
    \label{fig:angular_results}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/energy_results.png}
    \caption{\textbf{\textit{Energy reconstruction performance at the trigger-level.}} The solid lines show the median of the predicted $\log_{10}(E_{\nu})$, while the shaded regions are the $5\%$ to $95\%$ confidence level bands. The events in the test dataset are separated into starting and through-going events. The solid black line serves as a reference for a perfect reconstruction.
    }
    \label{fig:energy_results}
\end{figure}

We first test the network on reconstructing the direction of the primary neutrino.
We measure performance using the angular resolution metric, which is calculated by taking the angular difference between the predicted and true directional vectors.
Fig.~\ref{fig:angular_results} shows the angular resolutions as a function of the true neutrino energy.
Lower-energy events generally produce less photon hits, leading to a shorter lever-arm and, consequently, worse resolution.
As expected, the trigger-level events are generally harder to reconstruct due to the lower light yield and the presence of corner-clipper events.
This is especially true for angular reconstruction, where the SSCNN is able to reach under 4\textdegree{} median angular resolution on the highest-energy events.
% However, poorly-defined events, such as the corner-clippers previously mentioned, can easily pass the SMT-8 threshold.
% These events have little directional information to provide for the network due to their morphology.
Enforcing the previously described quality cuts improves the results of the SSCNN by roughly 2\textdegree{} across the entire energy range.
This performance is comparable to or better than current trigger-level reconstruction methods used in neutrino telescopes.
For example, the current trigger-level direction reconstruction at IceCube is done using the traditional \texttt{Linefit} algorithm~\cite{linefit}, which has a median angular resolution of approximately $10$\textdegree{} on raw data. 

We also test the networks by reconstructing the energy of the primary neutrino.
Fig.~\ref{fig:energy_results} summarizes the energy reconstruction results.
Events where the interaction point of the neutrino occurs outside the detector, known as through-going events, make up the majority of our dataset.
As a result, predicting the neutrino energy has an inherent, irreducible uncertainty produced by the unknown interaction vertex and the muon losses outside of the detector.
This missing-information problem leads to an intrinsic uncertainty in the logarithmic neutrino energy of approximately $0.4$ for a through-going event.
Additionally, the network performs noticeably worse at the lowest and highest energies, with a tendency to overpredict at low energies and underpredict at high energies.
This behavior can be attributed to the artificial energy bounds on the simulated training dataset. 
