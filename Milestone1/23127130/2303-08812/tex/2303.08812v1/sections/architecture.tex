\section{Methods}
\label{sec:architecture}

\subsection{Sparse Submanifold Convolutions}

Convolutional neural networks (CNNs) have become the staple architecture for image-like data, and have achieved great success in a wide range of applications, including neutrino physics~\cite{Radovic:2018dip, Aurisano:2016jvx, microboone_cnn, icecube_dnn_reco}. However, data from neutrino telescopes presents inherent challenges to CNNs.
In particular: 
%
\begin{itemize}
    \item \textit{Non-regular geometry}: CNNs are designed to operate on images, which are arranged on Cartesian grids.  Neutrino telescope sensors are typically spaced irregularly~\cite{KM3NeT:2009xxi, ictdr, baikaltdr, P-ONE:2020ljt}, with varying distances and arrangements in between each sensor.
    % For example, the DOMs in IceCube are roughly arranged in a hexagonal grid, with varying horizontal distances between each of the strings.
    % Additionally, the DeepCore array within IceCube has a different arrangement of DOMs than the rest of the detector.
    \item \textit{Sparsity}: Traditional CNNs use convolutions which operate on all points in the given input data.
    This leads to computational inefficiencies when the data is sparse. 
    \item \textit{High dimensionality}: Events occur in large spatial and temporal scales.
    This makes using traditional CNNs computationally unfeasible on raw 4D data (three spatial and one time) without information loss or significant pre-processing.
\end{itemize}

In this article, we propose a solution to these challenges using sparse submanifold convolutions~\cite{sscnn}.
This strategy has already shown success in liquid argon time projection chamber neutrino experiments~\cite{Abratenko_2021, domine}.
The usage of sparse submanifold convolutions in our network naturally solves the challenges laid out above.
Sparsity and high dimensionality are no longer a concern, as the number of computations performed will depend only on the number of OM hits.
With this improved computational efficiency, we can also handle non-regular geometries more smoothly by using the spatial coordinates of each OM hit (in meters from the center of the detector).
This allows us to consider data of any shape or arrangement, without restricting ourselves to a Cartesian grid; thus our alogrithm can be easily adapted from our IceCube-like test case to, \textit{e.g.} IceCube, KM3NeT, P-ONE, \textit{etc}.

Our SSCNN replaces traditional convolutions with sparse submanifold convolutions.
While a traditional convolution extracts features by mapping a learned kernel over all input data, a sparse submanifold convolution operates only on the non-zero elements.
This circumvents the inefficiency of using CNNs on sparse data, wherein the vast majority of operations are wasted multiplying zeros together.
Furthermore, to preserve the sparsity of the data after applying multiple layers in succession, sparse submanifold convolutions enforces that the coordinates and number of output activations matches those of the input.
In other words, the features do not spread layer after layer, as shown in Fig.~\ref{fig:compression}.
This is a compromise that is necessary for the efficiency of SSCNNs that are very deep, because this effect will cause the data to become less and less sparse throughout the network. 
The lack of feature spreading will have a minimal impact on performance as long as the network can rely on local information.
It should be noted that SSCNNs still compute over a grid-like structure, but this structure can be arbitrarily large because the network only operates on a submanifold of it.

\begin{figure}[t]
\centering
\includegraphics[width=0.45\textwidth]{figures/ssnet.png}
\caption{\textbf{\textit{Comparison of conventional and submanifold convolution with a Gaussian kernel.}}
The submanifold convolution maintains the sparsity of the input, while the traditional convolution blurs the input, making it less sparse.
In this example, a traditional convolution would require 18 or 25 matrix multiplications for sparse and non-sparse convolution respectively, whereas the bottom image only requires three matrix multiplications.
% It should also be noted the advantage that the sparse conventional gives will diminish with each layer as the number of non-zero-valued pixels``bleed into" zero-valued pixels.
% This same loss will not be seen in sparse submanifold convolution as the number of non-zero-valued pixels is constant from layer-to-layer.
}
\label{fig:compression}
\end{figure}

\subsection{Input Format}
As input, the SSCNN takes in two tensors: a coordinate tensor $C$, and a feature tensor $F$. In symbols:
\begin{equation}
    C = \begin{bmatrix}
    x_1 & y_1 & z_1 & t_1 \\
    \vdots & \vdots & \vdots & \vdots \\
    x_n & y_n & z_n & t_n
    \end{bmatrix}, 
    F = \begin{bmatrix}
    h_1 \\
    \vdots \\
    h_n
    \end{bmatrix},
\end{equation}
where the coordinate tensor is a $n \times 4$ tensor representing the space-time coordinates of the OMs in which there were a nonzero number of photon hits.
The symbol $n$ represents the total number of photon hits in the event, which is variable and can typically range from one to hundreds of thousands.
The feature tensor contains the number of photon hits which occurred within a 1~ns time window on that OM, starting from the time indicated in the coordinate tensor.
Nanosecond units were chosen for very fine timing resolution, as we aim to deploy the network on both low- and high-energy events.
However, depending on the application, the 1~ns time window can be expanded to trade off timing resolution for even better run-time and memory efficiency.