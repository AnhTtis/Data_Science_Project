\section{Methodology}
\input{figures/overview.tex}
We first revisit the preliminary of VOS in Section~\ref{preliminary}. Then we formulate the problem of two-shot VOS and show an overview of our method in Section~\ref{sec:formulation}. Next, the details of training a two-shot VOS model are presented in Section~\ref{sec:phase_one} and \ref{phase2}. At last, we show our methodology can be generalized to a majority of VOS models in Section~\ref{sec:gene}.


\subsection{Preliminary}
\label{preliminary}
Previous works train VOS models on densely annotated videos. Given the annotation of the first frame, the training objective is to maximize the mask prediction of the target object from the second frame to the last frame. For instance, STM~\cite{oh2019video} and STCN~\cite{cheng2021rethinking} take a triplet of frames as input; RDE-VOS~\cite{li2022recurrent} and XMem~\cite{cheng2022xmem} propose to model longer video sequences containing 5 and 8 frames, respectively. Random frame skipping, which randomly skips frames during the sampling, is a widely-used data augmentation to improve the generalization. In general, the maximum number of frames to skip gradually increases from 0 to $K$ as training progresses.

In our setting, we could only access two labeled frames per video. To reduce error propagation caused by unreliable pseudo labels, we adopt STCN~\cite{cheng2021rethinking} as our base model in phase-1 training since it merely needs a triplet of frames as input. Nevertheless, we can train any VOS models in phase-2, which will be described in Section~\ref{sec:gene}. Now we briefly revisit STCN. Given a training video, STCN first samples a triplet of frames as input. Then it predicts the mask of the second frame according to the ground-truth of the first frame, and the mask of the third frame based on the prediction of the previous frame in addition to the ground-truth of the first frame. The objective function of STCN is a standard segmentation loss, which is applied to each of the two predictions.



\subsection{Problem formulation and overview}
\label{sec:formulation}
\noindent\textbf{Problem formulation.} Given a VOS dataset $\mathcal{D}$, for each training video $\mathcal{V} = [\boldsymbol{V}_1, ...,\boldsymbol{V}_T] \in \mathcal{D}$ containing $T~(T\gg2)$ frames with the associated ground-truth $\mathcal{Y} = [\boldsymbol{Y}_1,...,\boldsymbol{Y}_T]$, we randomly sample two frames as the labeled data, while the remaining ones are served as the unlabeled data. The objective is to train a VOS model by using both labeled and unlabeled data.

\noindent\textbf{Overview.} \cref{fig:overview} shows an overview of our two-shot video object segmentation (VOS). First, we train a VOS model in a semi-supervised manner, with the reference frame always being a labeled one, which is referred to as \textit{phase-1} training. Then, we perform an \textit{intermediate inference} to generate pseudo labels for unlabeled frames by the VOS model trained in phase-1. The generated pseudo labels are stored in a pseudo-label bank for the convenience of accessing. 
At last, we re-train a VOS model on both labeled frames and pseudo-labeled frames without any restrictions on the reference frame. We term this stage as \textit{phase-2} training. It is worth noting that the pseudo-label bank is dynamically updated once more reliable pseudo labels are yielded in phase-2 training.



\subsection{Phase-1 training}
\label{sec:phase_one}
We adopt STCN~\cite{cheng2021rethinking} as our base model, which takes a triplet of frames as input. Nevertheless, in our setting, each training video only contains two labeled frames, which is insufficient to be served as the input of STCN in a fully supervised manner. To tackle this problem, we adopt semi-supervised learning, which generates pseudo-labeled frames together with the labeled ones to enable triplet construction. Since STCN requires the annotation of the reference (or first) frame to segment the object of interest that appeared in subsequent frames, we always use a labeled frame as the reference frame to alleviate the error propagation in the phase-1 training. The last two frames, however, can be either labeled or unlabeled. In our implementation, the last two frames have a $0.5$ probability of being both unlabeled, and a $0.5$ probability of having one frame be labeled. The training of two-shot VOS is identical to that of full-set VOS, except that our training triplet is composed of labeled frames with ground-truth and unlabeled frames with pseudo labels. Concretely, given a randomly sampled triplet where the last two frames are composed of $N_1$ labeled frames and $N_2$ unlabeled frames ($N_1=1$, $N_2=1$ or $N_1=0$, $N_2=2$), the overall loss $\mathcal{L}$ is the sum of the supervised loss $\mathcal{L}_S$ and the unsupervised loss $\mathcal{L}_U$ effected on labeled and unlabeled frames, respectively. $\mathcal{L}_S$ is a standard segmentation loss, which can be formulated as: 
\begin{equation}
    \mathcal{L}_S = \frac{1}{HWN_1}\sum_{n=1}^{N_1}\sum_{i=1}^{H}\sum_{j=1}^{W}\mathcal{H}(\boldsymbol{Y}_n^{(i,j)}, \boldsymbol{P}_n^{(i,j)}),
\label{eq:loss_l}
\end{equation}
where $H$ and $W$ represent the height and the width of the input, $\mathcal{H}(\cdot,\cdot)$ denotes the cross-entropy function, $\boldsymbol{P}_n^{(i,j)}$ is the prediction at pixel $(i,j)$ in the $n$-th labeled frame, and $\boldsymbol{Y}_n^{(i,j)}$ denotes the corresponding ground-truth. 

The unsupervised loss $\mathcal{L}_U$ is a variant of $\mathcal{L}_S$, which is defined as follows:
\begin{equation}
    \mathcal{L}_U =     \frac{1}{HWN_2}\sum_{n=1}^{N_2}\sum_{i=1}^{H}\sum_{j=1}^{W}  \mathbbm{1}_{[\max(\boldsymbol{P}_n^{(i,j)}) \geq \tau_{1}]}\mathcal{H}(\hat{\boldsymbol{Y}}_n^{(i,j)}, \boldsymbol{P}_n^{(i,j)}),
\end{equation}
where $\mathbbm{1}_{[\cdot]}$ is the indicator function to filter out the predictions whose maximal confidences are lower than the pre-defined threshold $\tau_{1}$, $\boldsymbol{P}_n^{(i,j)}$ is the prediction at pixel $(i,j)$ in the $n$-th unlabeled frame, and $\hat{\boldsymbol{Y}}_n^{(i,j)} = \mathrm{argmax}(\boldsymbol{P}_n^{(i,j)})$ represents the corresponding one-hot pseudo label. By default, we set $\tau_{1} = 0.9$ to guarantee the reliability of the yielded pseudo labels. 

As training progresses, an increasing number of high-quality pseudo-labeled samples are generated, injecting implicit knowledge included in unlabeled data into the model. In addition, we also randomly skip frames during sampling as described in Section~\ref{preliminary}.






\subsection{Phase-2 training}
\label{phase2}
\noindent\textbf{Discussion.} In phase-1 training, we constrain the reference (or first) frame to be a labeled frame since the predictions of the subsequent frames significantly rely on the mask of the reference frame. Adopting an unlabeled frame with pseudo-labeled mask as the reference frame aggravates error propagation in the early training. To make full use of the unlabeled data, we present phase-2 training, which lifts the restriction placed on the reference frame, allowing it to be either a labeled or pseudo-labeled frame. The underlying idea behind phase-2 training is to generate pseudo labels for all unlabeled frames using the decent VOS model trained in phase-1. After then, the pseudo-labeled data is stored in a pseudo-label bank, providing efficient access when constructing a training triplet where the reference frame is selected as a pseudo-labeled one.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.7\columnwidth]{./imgs/Inference.pdf}
  \caption{Illustration of bidirectional inference. Two reference frames are denoted by blue rectangles. A pre-trained VOS model infers unlabeled frames from the inference frame to the end frame and, in a reverse manner, from the inference frame to the beginning frame. We pick the prediction inferred by the labeled frame that is closest to the unlabeled frame. } \label{fig:bd}
\end{figure}

\noindent\textbf{Intermediate inference and pseudo-label bank.} We perform an intermediate inference before initiating phase-2 training. The inference of a VOS model requires the annotation of the reference (or first) frame. Nevertheless, only two labeled frames per video are available in our scenario. To generate the pseudo label per frame, inspired by bidirectional prediction and labelling~\cite{lee2022iteratively,miao2021vspw}, we introduce a bidirectional inference strategy as shown in Figure~\ref{fig:bd}. Specifically, for each of the two labeled frames, the VOS model trained in phase-1 takes it as the reference frame to infer the predictions for the unlabeled frames from the inference frame to the end frame and, in a reverse manner, from the inference frame to the beginning frame. After that, each unlabeled frame has two predictions associated with it, and we pick the prediction inferred by the labeled frame that is closest to this unlabeled frame. We maintain a pseudo-label bank to store pseudo labels associated with unlabeled frames.

\noindent\textbf{Training.} The training process of phase-2 is identical to that of phase-1, except that the reference (or first) frame can be either a labeled frame or an unlabeled frame with a pseudo label from the pseudo label bank attached to it.


\noindent\textbf{Update pseudo-label bank.}
As training progresses, predictions become more accurate, resulting in more reliable pseudo labels. Therefore, to further facilitate phase-2 training, we propose to dynamically update the pseudo-label bank as needed. Concretely, at each iteration, given the prediction $\boldsymbol{P}$ of an unlabeled frame, we use $\boldsymbol{P}^{(i,j)}$ to denote the prediction at pixel $(i,j)$. Once the prediction $\boldsymbol{P}^{(i,j)}$ meets the condition that $\mathrm{max}(\boldsymbol{P}^{(i,j)}) \geq \tau_{2}$, where $\tau_{2}$ denotes a pre-defined threshold, the corresponding pseudo label in pseudo label bank is updated by $\hat{\boldsymbol{Y}}^{(i,j)} = \mathrm{argmax}(\boldsymbol{P}^{(i,j)})$. We set $\tau_2 = 0.99$ by default.

\subsection{Generalization capability}
\label{sec:gene}
Thanks to the proposed pseudo-label bank and phase-2 training, our two-shot training paradigm can be applied to a majority of VOS models regardless of their architectures and requirements on the input. To generalize to other models, we adopt a STCN model trained in phase-1 to construct a pseudo-label bank. After that, various VOS models can utilize the universal training paradigm presented in phase-2 to enable two-shot VOS learning. Experimentally, we also apply our methodology to RDE-VOS~\cite{li2022recurrent} and XMem~\cite{cheng2022xmem} besides STCN~\cite{cheng2021rethinking} to show the generalization capability.


