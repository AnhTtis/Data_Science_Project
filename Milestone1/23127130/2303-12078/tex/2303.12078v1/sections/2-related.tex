\section{Related work}
%\paragraph{Video Object Segmentation.}
\noindent\textbf{Video object segmentation.}
Existing VOS methods can be categorized into two groups: online-learning methods and offline-learning methods. Online-learning methods~\cite{caelles2017one,luiten2018premvos,perazzi2017learning,voigtlaender2017online,xiao2018monet,maninis2018video,cheng2017segflow} need to fine-tune the networks at test time based on the query mask of the first frame. However, test-time fine-tuning is computationally expensive. 
In contrast, offline-learning methods~\cite{mao2021joint,yang2021associating,hu2021learning,zhang2020transductive,ge2021video,lu2020video} aim at training a model that segments videos without any adaptations during inference. It is usually achieved via propagation and matching. Propagation-based methods~\cite{chen2020state,li2018video,oh2018fast,johnander2019generative} segment the target object sequentially by propagating the reference mask of the first frame. Matching-based methods~\cite{cheng2021rethinking,yang2020collaborative,oh2019video,wang2021swiftnet} typically employ a memory bank to store the features of a collection of frames, then a feature matching is adopted to segment the query frame.

STM~\cite{oh2019video} received widespread attention among the matching-based methods. STM proposes to construct a memory network to store the masks of the previous frames. Then the query frame is segmented using the information stored in the memory. A majority of follow-up works improved STM in several aspects~\cite{seong2020kernelized,seong2021hierarchical,cheng2022xmem,li2022recurrent,xie2021efficient}. 
%
For example, STCN~\cite{cheng2021rethinking} establishes correspondences between frames to avoid re-encoding the mask feature of each object; RDE-VOS~\cite{li2022recurrent} builds a constant-size memory bank by recurrent dynamic embedding while retaining the performance; XMem~\cite{cheng2022xmem} incorporates multiple feature memory stores and achieves the best performance. 
Despite their promising results, these methods need densely annotated videos for training. Instead, our method only needs two labeled frames per video and is compatible with most VOS models. It is worth noting that the meaning of ``one-shot'' claimed by \cite{caelles2017one} significantly differs from that of our ``two-shot''. In \cite{caelles2017one}, ``one-shot'' refers to that given a reference frame during inference, the optimized model is able to segment the remaining frames. In contrast, we use the term ``$N$-shot'' to denote the number of labeled frames per video. Therefore, in our setting, ``one-shot'' denotes that only a single labeled frame per video is available during training. 


\noindent\textbf{Semi-supervised learning.}
Semi-supervised learning is an efficient way to improve model performance by using a few labeled data and a large amount of unlabeled data. It has achieved promising results across various computer vision tasks, such as image classification~\cite{sohn2020fixmatch,tarvainen2017mean}, image segmentation~\cite{hu2021semi,ke2020guided}, object detection~\cite{sohn2020simple,xu2021end} and action recognition~\cite{xu2022cross}. 
The dominated works can be roughly categorized into consistency based methods~\cite{laine2016temporal,tarvainen2017mean,berthelot2019mixmatch,sajjadi2016regularization,french2019semi,chen2021semi} and pseudo-labeling based methods~\cite{lee2013pseudo,sohn2020simple,zoph2020rethinking,xie2020self,grandvalet2004semi,zou2020pseudoseg}. Consistency based methods enforce consistency between predictions of different perturbations, such as model perturbing~\cite{bachman2014learning}, data augmentations~\cite{xie2020unsupervised,berthelot2019remixmatch} and adversarial perturbations~\cite{miyato2018virtual}. Pseudo-labeling based methods generate one-hot pseudo labels for unlabeled data. Then the model is optimized on the combination of labeled data and pseudo-labeled data. Our approach also adopts pseudo-labeling to improve two-shot VOS.


