\section{Conclusion}
For the first time, we demonstrate the feasibility that only two labeled frames per video are almost sufficient for training a decent VOS model. On top of this, we present a simple training paradigm to resolve two-shot VOS. The underlying idea behind our approach is to exploit the wealth of information present in unlabeled data in a semi-supervised learning manner. Our approach can be applied to a majority of fully supervised VOS models, such as STCN, RDE-VOS, and XMem. By using 7.3\% and 2.9\% labeled data of YouTube-VOS and DAVIS benchmarks, our approach achieves comparable results in contrast to the counterparts trained on fully labeled set. With its simplicity and strong performance, we hope our approach can serve as a solid baseline for future research.

