Before we demonstrate our evaluation results, we review the state-of-the-art works that characterize interference in task consolidation environments, and minimize interference via scheduling or compilation techniques.
\subsection{Interference Characterization}
To solve the interference issues (e.g., resource contention), a comprehensive analysis is always necessary. Mars et al.~\cite{marshipeac11} leveraged  a synthesis engine to characterize interference sensitivity of SPEC CPU2006 benchmarks and identify contentious application code. Moreover, Tang et al.~\cite{lingjiaisca11} studied the impacts of sharing memory resources on five Google applications (protocol buffer, web search, etc.) and leverage the analysis results to guide thread-to-core mappings for better performance. Cook et al.~\cite{isca2013cook} evaluate the potential hardware cache partitioning schemes for multi-tenant executions formed by PARSEC~\cite{parsec} and SPEC CPU2006~\cite{spec2006} applications. Bubble-up~\cite{bubbleup} presents a characterization methodology that can predict latency-sensitive tasks' (e.g. web search) performance degradation caused by shared memory subsystems. To better understand the resource sharing in servers, Dong et al.~\cite{dong2016venice} designed Venice, a hardware prototype, to transparently monitor the consolidation interference at runtime. Other than the interference analysis work, Delimitrou et al.~\cite{ibench} released the iBench benchmark suite, which consists of manual-crafted benchmarks that can stress different hardware components, such as CPU, cache hierarchy, memory, etc.


\subsection{Scheduling}
Leveraging the comprehensive characterization of application's performance in multi-tenant environments, many researchers have proposed to minimize the interference effects via scheduling techniques. 
Zhao et al.~\cite{raojia2016} proposed delayed preemption and differential scheduling to interleave foreground/background tasks and avoid the co-location case of interfering workloads. Bubble-flux~\cite{bubbleflex} monitored the QoS bounded applications and schedule the background tasks to guarantee the QoS quality of foreground tasks. By training a simple program classifier, Wang et al.~\cite{Wang2013} created an interference-aware schedule to avoid contentious application pairings. To achieve fair sharing in cloud computing, Chen et al.~\cite{chenatc2017} designed two preemption policies (\textit{preemptive} and \textit{graceful}) for the container-based frameworks. Cooper~\cite{cooper} leveraged the stable matching algorithm to guide task consolidation. 
Wang et al.~\cite{wangipdps2015} presented CC, a scheduling algorithm that leveraged the benefits of contention while supporting limited reservations to reduce interference with fairness guaranteed. 

\subsection{Compilation}
Besides the scheduling techniques, Tang et al.~\cite{lingjiacgo2012} proposed the first compilation approach to statically pinpoint and throttle the memory access rate of an application's contentious region, which resulted in less interference in the co-running environment. Similarly, ReQos et al.~\cite{reqos} leveraged a profile-guided compilation technique to insert marks in contentious code regions. Marked code would reactively reduce pressure on memory subsystems when contention was detected. To solve the inclusion victim problem in co-running environments, Bao et al.~\cite{dingchencgo2013} used defensive tiling to estimate cache sharing effect and then select optimal tile size that can minimize interference in cache.
