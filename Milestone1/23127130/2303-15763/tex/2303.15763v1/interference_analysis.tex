To identify the impact of co-running on shared hardware resource and contentious code region of the consolidating task, we deploy mini-benchmarks to study interference of each application, and present collected performance statistics in this section. 
Moreover, here we also discuss the insights obtained from comparing the profiling results of co-running with mini-benchmarks to the ones of consolidating with real applications.

\begin{figure}[t]
    \centering
    %\quad
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=3.5in]{./figure/corun-bandit.pdf}
        \caption{Co-run with Bandit}
        \label{fig:corun_stream}
    \end{subfigure}  

    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=3.5in]{./figure/corun-stream.pdf}
        \caption{Co-run with Stream}
        \label{fig:corun_bandit}
    \end{subfigure}
    \caption{Speedup for applications co-running with mini-benchmarks.}
    \label{fig:corun_minibenchmarks}
    \vspace{-5mm}
\end{figure}

\begin{figure*}[t]
    \centering
    %\quad  
    \begin{subfigure}[b]{0.23\textwidth}
        \includegraphics[width=\textwidth]{./figure/bd_gemini_cpi_stream.pdf}
        \caption{CPI}
        \label{fig:cpi_stream}
    \end{subfigure}  
    \begin{subfigure}[b]{0.23\textwidth}
        \includegraphics[width=\textwidth]{./figure/bd_gemini_l2_stream.pdf}
        \caption{L2\_PCP}
        \label{fig:l2_stream}
    \end{subfigure}
    \begin{subfigure}[b]{0.23\textwidth}
        \includegraphics[width=\textwidth]{./figure/bd_gemini_llc_stream.pdf}
        \caption{LLC MPKI}
        \label{fig:llcm_stream}
    \end{subfigure}
    \begin{subfigure}[b]{0.23\textwidth}
        \includegraphics[width=\textwidth]{./figure/bd_gemini_ll_stream.pdf}
        \caption{LL}
        \label{fig:ll_stream}
    \end{subfigure}
    \caption{Performance metrics for Gemini Graph applications co-running with Stream.}
    \label{fig:metric_stream}
    \vspace{-5mm}
\end{figure*}

\subsection{Performance Metrics for Analyzing Problematic Co-running Pairs}
To analyze the root-cause of performance degradation in the multi-tenant environment, we use the Intel Vtune profile to collect memory related hardware event statistics and map such results to the contentious code region in the application. The metrics of profiled hardware events are summarized as follows: 
\begin{itemize}
\item \texttt{CPI}: cycles per instruction.
\item \texttt{L2 misses}: the number of L2 cache misses. 
\item \texttt{L2\_PCP}: L2 Pending Cycle Percent, which is the ratio of all CPU cycles pending on L2 cache miss. 
\item \texttt{LLC MPKI}: misses of LLC per 1000 instructions.
\item \texttt{LL}: average latency of load from LLC or memory, roughly equal to average latency per L2 misses. 
\end{itemize}
Here, L2 pending cycles can be split into two parts: cycles spent on LLC and cycles spent on memory access. Both LLC and memory subsystem are the shared resources in our co-running configuration. Therefore, we use \texttt{LL} to quantify the average latency happened at shared resource, which is defined as:
$$\texttt{LL}= \frac{\texttt{CPI} * \texttt{L2\_PCP}}{\texttt{L2 misses count per instruction}}$$




In our co-running setup, two applications do not share physical cores, and each physical core owns private L1/L2 cache. Hence, \texttt{L2 misses count per instruction} is considered to be a fixed value for each application with a unvarying core count, regardless of the interference caused by task co-execution. Consequently, \texttt{LL} is driven by $\texttt{CPI}$ and $\texttt{L2\_PCP}$. 



\subsection{Co-running with Mini-benchmarks}

We choose two mini-benchmarks consuming high bandwidth: Stream and Bandit, introduced in section \ref{sec:exp}. To evaluate each benchmark's sensitivity to different memory access patterns, we co-run all of the 25 applications with these mini-benchmarks. Here, mini-benchmark is deployed as a background application, which takes 4 physical cores.

Figure~\ref{fig:corun_stream} and~\ref{fig:corun_bandit} show the normalized execution time for each application when co-running with Bandit and Stream, respectively. Compared to co-running with Stream, applications co-running with Bandit have a relatively smaller slowdown ranging between $0.77\times$ to $1.0\times$. Among all applications, GeminiGraph applications' execution time gets affected the most, as the average slowdown is $0.82\times$. Even though PowerGraph applications analyze the same graph input, the interference only slows them down by an average of $0.93\times$. 
Other than the graph applications, the execution time of streamcluster and fotonik3d increase by 21\% and 27\%, respectively. Based on the Intel PCM's measurement, Bandit consumes memory bandwidth at a rate of 18GB/s, when it is running alone with 4 thread slots provided. Since Bandit doesn't benefit from cache and hardware prefetchers, it only stresses the bandwidth resource in the co-executing environments. Our experiment shows that the bandwidth contention at such level can not impact emerging applications' performance too much.



\begin{figure*}[t]
    \centering
    %\quad     
    \begin{subfigure}[b]{0.23\textwidth}
        \includegraphics[width=\textwidth]{./figure/bd_gemini_cpi_others.pdf}
        \caption{CPI}
        \label{fig:cpi_other}
    \end{subfigure}  
    \begin{subfigure}[b]{0.23\textwidth}
        \includegraphics[width=\textwidth]{./figure/bd_gemini_l2_others.pdf}
        \caption{L2\_PCP}
        \label{fig:l2_other}
    \end{subfigure}
    \begin{subfigure}[b]{0.23\textwidth}
        \includegraphics[width=\textwidth]{./figure/bd_gemini_llc_others.pdf}
        \caption{LLC MPKI}
        \label{fig:llcm_other}
    \end{subfigure}
    \begin{subfigure}[b]{0.23\textwidth}
        \includegraphics[width=\textwidth]{./figure/bd_gemini_ll_others.pdf}
        \caption{LLC MPKI}
        \label{fig:ll_other}
    \end{subfigure}
    \caption{Performance metrics for Gemini Graph applications co-running with offender applications.}
    \label{fig:metric_gemini_otherapps}
    \vspace{-5mm}
\end{figure*}

When applications co-locate with Stream, they suffer more in terms of performance, as the average slowdown of 25 application drops to $0.61\times$.
The average runtime of GeminiGraph applications' and PowerGraph applications' execution time is increased to $208\%$. Only few applications avoid such tremendous performance degradation: blackscholes, freqmine, swaptions, deepsjeng and nab. These benchmarks consume very little bandwidth resource, as we previously showed in Figure \ref{fig:bandwidth_eachapp}. 
The highest practical memory bandwidth of our system is approximately 28 GB/s. Running a 4-thread Steam benchmark alone can produce 24.5 GB/s bandwidth consumption. Such high bandwidth consumption is due to the regular memory access pattern that can be benefited by hardware prefetchers a lot. Other than the memory bandwidth, co-executing applications also share the LLC, which can be severely impacted by the memory intensive applications like Stream as well. Compared to other applications, We find that data analytical applications on GeminiGraph have the worst performance degradation co-running with Stream. 

Due to the space limit, Figure \ref{fig:metric_stream} only demonstrates 5 GeminiGraph applications' comparisons of co-running with Stream and running alone without interference in terms of \texttt{LLC MPKI}, \texttt{CPI}, \texttt{L2\_PCP}, and \texttt{LL}.
As shown in Figure~\ref{fig:llcm_stream}, the \texttt{LLC MPKI} of each application also increases by $2.6\times$ due to the LLC contention. Both Stream and graph applications benefit from the LLC. However, 
two applications compete for the limited space of last level cache, causing the increment of LLC misses for graph applications. The combination of the interference effect from the LLC and memory bandwidth results in high \texttt{LC\_PCP}, which means most of the execution cycles are spent on waiting for the data loaded from LLC or memory. Especially for G-PR, \texttt{LC\_PCP} reaches $93\%$ of total cycles. Such memory bottleneck worsens the overall \texttt{CPI} of each graph application. Figure~\ref{fig:cpi_stream} shows that every application's \texttt{CPI} increases more than $2\times$, which is highly correlated to the overall runtime elongation. Consequently, \texttt{LL} driven by \texttt{CPI} and \texttt{L2\_PCP} also gets a more than $2\times$ increase for each application (shown in Figure~\ref{fig:l2_stream}). Compared to other graph applications in GeminiGraph, G-BFS and G-BC are less memory-intensive, as these applications only iterate and update each vertex once. Such lightweight memory access can be well serviced by the LLC cache. However, when they are sharing the LLC with Stream, \texttt{LLC MPKI} of both application dramatically increases, as shown in Figure~\ref{fig:llcm_stream}. 




The co-running experiments with two mini-benchmarks help to verify the conclusion in the previous section: applications with the following two properties :
\begin{itemize}
\item Large amount of memory accesses with regular pattern 
\item Consuming large portion of bandwidth
\end{itemize}
will easily degrade performance of memory intensive applications. Applications with the such properties can also impact graph benchmarks a lot, we will analysis it in the next subsection.


\begin{table}[]
\centering
\scriptsize
\tabcolsep=0.11cm
\caption{Profiling results of P-PR and fotonik3d.}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Metric & \begin{tabular}[c]{@{}c@{}}Foreground\\ Application\end{tabular} & \begin{tabular}[c]{@{}c@{}}No \\ Interference\end{tabular} & \begin{tabular}[c]{@{}c@{}}With \\ IRSmk\end{tabular} & \begin{tabular}[c]{@{}c@{}}With \\ CIFAR\end{tabular} & \begin{tabular}[c]{@{}c@{}}With \\ fotonik3d\end{tabular} & \begin{tabular}[c]{@{}c@{}}With \\ G-SSSP\end{tabular} \\ \hline
\multirow{2}{*}{CPI} & \begin{tabular}[c]{@{}c@{}}P-PR\\ (gather)\end{tabular} & 2.3 & 3.7 & 3.5 & 4.3 & - \\ \cline{2-7} 
 & \begin{tabular}[c]{@{}c@{}}fotonik3d\\ (UUS)\end{tabular} & 2.0 & 3.6 & 3.2 & - & 1.8 \\ \hline
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}LLC \\ MPKI\end{tabular}} & \begin{tabular}[c]{@{}c@{}}P-PR\\ (gather)\end{tabular} & 3.9 & 5.2 & 4.8 & 4.8 & - \\ \cline{2-7} 
 & \begin{tabular}[c]{@{}c@{}}fotonik3d\\ (UUS)\end{tabular} & 20.9 & 22.1 & 21.1 & - & 21.3 \\ \hline
\multirow{2}{*}{L2\_PCP} & \begin{tabular}[c]{@{}c@{}}P-PR\\ (gather)\end{tabular} & 71\% & 80\% & 79\% & 83\% & - \\ \cline{2-7} 
 & \begin{tabular}[c]{@{}c@{}}fotonik3d\\ (UUS)\end{tabular} & 65\% & 80\% & 81\% & - & 63\% \\ \hline
\multirow{2}{*}{LL} & \begin{tabular}[c]{@{}c@{}}P-PR\\ (gather)\end{tabular} & 1.7 & 2.9 & 2.8 & 3.6 & - \\ \cline{2-7} 
 & \begin{tabular}[c]{@{}c@{}}fotonik3d\\ (UUS)\end{tabular} & 1.3 & 2.9 & 2.6 & - & 1.2 \\ \hline
\end{tabular}
\label{table:presults_pr_fotonik3d}
\vspace{-5mm}
\end{table}

\iffalse
\begin{table}[t]
\renewcommand{\arraystretch}{1}
\caption{Profiling results of P-PR and fotonik3d.}
\label{table:presults_pr_fotonik3d}
\centering
\scriptsize
\begin{tabular}{|c|c|c|}
\hline
& P-PR(gather) & fotonik3d(UUS) \\
\hline
\multicolumn{3}{|c|}{\textbf{CPI}} \\
\hline
No interference & 2.33  & 1.97 \\
\hline
With IRSmk & 3.66& 3.57 \\
\hline
With CIFAR & 3.5  & 3.2 \\
\hline
With fotonik3d & 4.33  & - \\
\hline
With G-SSSP & -  & 1.81 \\
\hline
\multicolumn{3}{|c|}{\textbf{LLC MPKI}} \\
\hline
No interference & 3.86 & 20.92  \\
\hline
With IRSmk & 5.16 & 22.14 \\
\hline
With CIFAR & 4.81 & 21.14 \\
\hline
With fotonik3d & 4.76 & - \\
\hline
With G-SSSP & -  & 21.33 \\
\hline
\multicolumn{3}{|c|}{\textbf{L2\_PCP}} \\
\hline
No interference & 71\%  & 65\% \\
\hline
With IRSmk & 80\%  & 80\% \\
\hline
With CIFAR & 79\%  & 81\%\\
\hline
With fotonik3d & 83\%  & -\\
\hline
With G-SSSP & -  & 63\%\\
\hline
\multicolumn{3}{|c|}{\textbf{LL}} \\
\hline
No interference & 1.65  & 1.28 \\
\hline
With IRSmk & 2.92  & 2.85 \\
\hline
With CIFAR & 2.77  & 2.59\\
\hline
With fotonik3d & 3.58  & -\\
\hline
With G-SSSP & -  & 1.14\\
\hline
\end{tabular}
\end{table}
\fi



\subsection{GeminiGraph Applications}
\label{sec:cs_gemini}
In section \ref{sec:interference}, we demonstrate graph applications suffer from co-running with fotonik3d, IRSmk and CIFAR applications. Figure \ref{fig:metric_gemini_otherapps} shows \texttt{CPI}, \texttt{L2\_PCP} and \texttt{MPKI} comparison of co-running with three \textbf{Offender} applications and running alone without interference.  The \texttt{LLC MPKI} of each application increases up to $18\%$. All applications benefit from LLC. The interference on LLC caused by these three \textbf{Offender} applications is not as severe as Stream. However, high \texttt{L2\_PCP} of all co-running pairs means LLC and memory subsystem are the bottleneck. 
Correspondingly, \texttt{LL} also increases more than $100\%$. 

Similar to Stream, Fotonik3d and IRSmk have a very regular memory access pattern. However, they are not as harmful as Stream, as purely regular memory access pattern is impossible to achieve in the real world applications. Since CIFAR's memory access pattern is less regular than fotonik3d and IRSmk, CIFAR's impact on graph applications are much less than IRSmk and fotonik3d. As shown in Figure \ref{fig:corun_heatmap}, only GeminiGraph applications co-running with CIFAR have a normalized execution time below 1.5, except for G-CC.    

\lstset { %
    language=C++,
    backgroundcolor=\color{white}, % set backgroundcolor
    breaklines=true,
    basicstyle=\scriptsize\ttfamily,% basic font setting
    numbers=left,
    stepnumber=1,
    firstnumber=63,
    xleftmargin=2em,
}
\begin{figure}[h]
\centering
\scriptsize
\begin{lstlisting}
[&](VertexId dst, VertexAdjList<Empty> incoming_adj) {
  double sum = 0;
  for (AdjUnit<Empty> * ptr=incoming_adj.begin; ptr!=incoming_adj.end; ptr++) {
    VertexId src = ptr->neighbour;
    sum += curr[src];
  }
  graph->emit(dst, sum);
}
\end{lstlisting}
\caption{Code for Pagerank Gemini (G-PR), line number from $63$ to $70$ for pagerank.c}
\label{fig:code_pagerank_gemini}
\vspace{-7mm}
\end{figure}

\begin{figure}[h]
\centering
\scriptsize
\begin{lstlisting}
double gather(icontext_type & context, const vertex_type& vertex, edge_type& edge) const{
	// printf("%ld", edge.source().num_out.edges());
	return (edge.source().data()/edge.source().num_out_edges());
}
\end{lstlisting}
\caption{Code for Pagerank Powergraph (P-PR), line number from $63$ to $66$ for pagerank.c}
\label{fig:code_pagerank_powergraph}
\vspace{-5mm}
\end{figure}


\subsection{PowerGraph Applications}
\label{sec:cs_power}
P-PR is the only graph application in PowerGraph that suffers from co-running with fotonik3d, CIFAR and IRSmk. For P-PR, function \texttt{gather} takes most of the CPU execution cycles. The code of \texttt{gather} is demonstrated in Figure \ref{fig:code_pagerank_powergraph}. The \texttt{gather} function is responsible for loading all the value of connected edges. Such massive data loading phase in graph applications (implemented in gather-apply-scatter execution model) can be heavily impacted, when co-running with fotonik3d, CIFAR and IRSmk. Identifying the contentious code region in the graph application can benefit system designers to carry out more robust graph computation model. Meanwhile, it can help compiler designer to relief the interference impact at the source code level.

Similar to GeminiGraph applications, P-PR also benefits from the LLC. As shown in Table \ref{table:presults_pr_fotonik3d}, \texttt{LLC MPKI} increases nearly $30\%$. Three \textbf{Offender} applications cause intensive \texttt{LLC} contention. Due to the high \texttt{L2\_PCP} (up to $83\%$) and high \texttt{LL}, P-PR is bounded by LLC and memory bandwidth. The memory burden of PowerGraph is less than GeminiGraph, and the performance of PowerGraph is worse than GeminiGraph. As a result, the interference impact brought by three \textbf{Offender} applications (fotonik3d, IRSmk, CIFAR) on PowerGraph is much less than that on GeminiGraph.

\subsection{Fotonik3d}
Even though fotonik3d offends other co-running applications severely (e.g. graph applications), it is impacted by other \textbf{Offender} applications like CIFAR and IRSmk. 
In Table \ref{table:presults_pr_fotonik3d}, Fotonik3d's profiling results are compared between co-runs and sole-run.
Fotonik3d's \texttt{LLC MPKI} is more than $20$ when running alone without interference. It doesn't change too much after co-running with the other two \textbf{Offender} applications. Therefore, \texttt{LLC} contention is not the root-cause for the performance loss. However, \texttt{L2\_PCP} increases from $65\%$ to nearly $80\%$, which shows that memory bandwidth becomes the bottleneck. Memory bandwidth bottleneck causes \texttt{LL} increase more than $1\times$. Both fotonik3d and IRSmk have a very regular memory access pattern and consume large portion of available bandwidth. When they are formed as a co-execution pair, fotonik3d suffers more than IRSmk. 
Compared to consolidating with CIFAR, fotonik3d losses more performance, when it shares the hardware resource with IRSmk. Such performance degradation is not observed in the co-execution with G-SSSP.























