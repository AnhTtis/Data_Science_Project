% Why we need corun
Modern computer systems have evolved to employ powerful parallel architectures, including multi-core processors, multi-socket chips, large memory subsystems, and fast network communication. Given such powerful hardware, it is difficult for a single application to achieve the theoretical peak performance. For example, many high-performance computing (HPC) software applications achieve only 5-15\% of the peak performance on modern supercomputers~\cite{lowutilization1}. %cite this paper: https://link.springer.com/article/10.1007/s11227-017-1993-y
To maximize the hardware usage, researchers consolidate multiple programs onto a single machine, which is known as throughput-oriented computing.

%{\color{red} corun is important for Cloud computing as well}

%The throughput-oriented computing has also become popular in the cloud environment.

Beyond the HPC systems, the rapid development of cloud environment keeps accepting increasing amount of tasks. Consequently, such quick ramp up leads to a critical energy consumption concern~\cite{dce1,dce2,islamhpca2016} in modern data centers. Cloud service providers have widely adopted the throughput-oriented computing as one of the most effective manners to safe energy consumption, as it can consolidate/stack multiple tasks on the shared computing resources and leave unused machines power off.
Prior studies~\cite{isca2013cook,cooper,bubbleup,bubbleflex} have shown that such task consolidation can significantly improve hardware utilization and result in high energy efficiency.

%{\color{red}Condense this paragraph and the next one to show why corun appears in cloud? Cloud provider platform cares more about throughput, which saves energy bill.}

%With the rapid development of processing, communication and storage technologies, hardware resources have become cheaper while more powerful than ever before. The recent technological trend has been the formation of a centralized computing model (e.g. cloud and warehouse-scale computing), which can help reduce a user's total cost of ownership (TCO) of computing facilities and simplify the difficulty of task management for small businesses. In centralized computing, energy consumption is always a primary concern~\cite{xxx}. For instance, the electricity consumption by modern data centers reached 91 billion kilo-watt hours (kWh) in 2013 and is projected to grow in the future~\cite{dce1}~\cite{dce2}~\cite{islamhpca2016}. Hence, reducing energy consumption is considered as one of the critical tasks for centralized computing.


%{\color{red}The importance of corun}

%With the amount of tasks in data center continuously increasing, improving energy efficiency becomes the most effective manner to minimize the total energy consumption, as energy efficiency can directly impact the capital costs of infrastructure needed to distribute power and cool the servers~\cite{isca2013cook}. To maintain a task's performance and responsiveness at a certain level, computing resource providers often dedicate large clusters to single applications. However, such task placement leads to low hardware resource utilization and energy efficiency. 
%To enhance energy efficiency, modern data centers consolidate multiple small tasks on the shared computing resource, and power off unused machines. Studies~\cite{xxx} have shown that such task consolidation can significantly increase the utilization of hardware resources, which results in better energy efficiency.  

%{\color{red}Challenges of corun}

Clearly, the goals of task consolidation are to: (1) increasing the system throughput and (2) improving hardware utilization and energy efficiency. However, efficiently application co-running in modern data centers is challenging. From the hardware perspective, there are many shared resources, such as last-level cache (LLC) and memory bandwidth, which can be affected by these co-running applications, leading to significant contention~\cite{dingchencgo2013,isca2013cook,lingjiaisca11}. From the software perspective, there are applications in various domains, such as data mining, machine learning, standard benchmarks, HPC, and real-world parallel applications, among others. Applications from different domains can have different requirements (e.g. Quality of Service (QoS)) and different characteristics that can lead to unpredictable co-running behaviors~\cite{bubbleup,bubbleflex,chenatc2017}. Given a large variety of individual application's characteristics, a high throughput-oriented system faces the challenges of understanding and improving task consolidation.

%{\color{red}The goal of the corun}

%(1) increase the system throughput and (2) application QoS. Need detailed application charaterization and system measurement to obtain this information. Then you can introduce the existing work (high level with references). And then motivate our approach that distinguishes existing ones.
To overcome such challenges, prior work proposed solutions that fall into two categories: task scheduling and code compilation. Task scheduling techniques~\cite{raojia2016,bubbleflex,Wang2013,chenatc2017,wangipdps2015} preempt the applications with non-critical performance requirement and prioritize the QoS-sensitive ones in the contentious period. Code optimization techniques~\cite{lingjiacgo2012,reqos,dingchencgo2013} throttle an application's memory access intensity (e.g., reduce memory instruction issue rate or cache requirement), which results in less interference in shared resources. Both methods heavily rely on the characterization of interference. However, existing approaches~\cite{marshipeac11,isca2013cook,lingjiaisca11} provided interference characterizations of either traditional benchmarks (e.g. SPEC CPU2006~\cite{spec2006}) or a single domain (e.g. query-based web service), which provides limited insights into co-running interference of modern applications across various domains. 
In this paper, we conduct an empirical study to address this issue in prior work.

We summarize our contribution as follows:

%{\color{red}May not need this paragraph}
%Efficient task co-running is not straightforward to be achieved in modern data centers, as applications running on the warehouse-scale computing platform are more heterogeneous than ever before, such as the proliferation of machine learning, data mining, data analytics and etc.. Different application can have very distinguished resource demands on the shared hardware resources (e.g. last level cache (LLC) and memory subsystems). Moreover, due to the various performance bottlenecks in different workloads, application can have unexpected reactions to different co-runners. For example, if consolidating two applications with same memory bandwidth bottleneck can significantly longer their runtime and result in lower throughput. Such case contradicts the co-running purpose of cloud service providers. Besides these, applications usually have different performance requirements. For instance, the model training workloads in machine learning domain usually have long execution time with loose quality of service (QoS) requirement compared to the short jobs that are sensitive to delays.  

%{\color{red}What prior work did and what we do in this project}

%{\color{red}Summarized our contributions}
%The contributions of this paper can be summarized as follows:
\begin{itemize}
\item To conduct a comprehensive evaluation of co-running environments, we select 25 emerging applications/benchmarks, including graph analytics, deep learning applications, standard CPU/memory benchmarks, parallel benchmarks, and HPC applications. Most of them are up-to-date ones, such as GeminiGraph~\cite{geminigraph}, SPEC CPU2017~\cite{spec2017}, and Microsoft CNTK~\cite{cntk}.
%\item To comprehensively reflect the co-running situation in the cloud/warehouse-scale computing, we select 26 emerging applications from 6 different application suites/platforms to represent data mining, machine learning, CPU/memory-intensive, high performance computing, and parallel real-world applications.
\item We leverage the selected applications to form 625 consolidated task  pairs. The evaluation of each pair is performed three times to obtain the accurate runtime and interference measurement. 
%We evaluate each application's scalability, prefetch sensitivity, and memory bandwidth consumption without interference. Moreover, we conduct 325 experiments to fully reflect the consolidation interference on application's performance.
\item To understand each application's characteristics, we analyze its scalability, prefetching sensitivity, and memory bandwidth consumption in the sole-run. We then measure each co-running pair's runtime and bandwidth usage to truly quantify the interference effect caused by task consolidation. For heavily affected applications, we leverage mini-benchmarks and real applications to deep dive into the provenance of performance degradation from both hardware and software aspects.
%Based on the results of co-running experiments, we categorize task consolidation into three different type: \textbf{Harmony}, \textbf{Victim-Offender}, and \textbf{Both-Victim}. Furthermore, we deep-dive in the provenance of performance interference from both software and hardware sides. 
\end{itemize}

We have observed many insightful findings via our experiments. For instance, we find that graph analytic applications are vulnerable to cache and memory contention; they does not degrade their co-runners but can be harmed seriously by memory intensive applications. Moreover, we identify contentious code regions under severe contention, which can benefit software design for minimizing co-running interference. We believe our thorough analysis can benefit future researches from multiple domains.

The rest of the paper is organized as follows. Section~\ref{sec:related} reviews the related prior work. Section~\ref{sec:exp} illustrates our platform configuration, describes selected workloads, and introduces the tools used in experiments. Application's scalability, prefetching sensitivity, and bottlenecks are discussed in Section~\ref{sec:nointerference}. Then, the results of comprehensive consolidation experiments are presented in Section~\ref{sec:interference}. Based on these result, we deep-dive to analyze the provenance of interference in Section~\ref{sec:analysis}. Finally, we conclude this paper in Section~\ref{sec:conclusion}.
