\section{Problem Definition}

Suppose $K$ clients and a server collaboratively train a model. There is an overlapped dataset\footnote{We assume the alignment between overlapping samples is known as a priori. In some applications private set intersection could be used before running VFL to find the sample alignment.} across all clients with size $N_o$:  $\{x_{o,i}, y_{o,i}\}_{i=1}^{N_o}$. The feature vector $x_{o,i}\in \mathbb{R}^{d}$ is distributed among $K$ clients $\{x_{o,i}^{k}\in \mathbb{R}^{d_k}\}_{k=1}^K$, where $d_k$ is the feature dimension of client $k$. For simplicity, the aligned dataset $\{x_{o,i}^{k}\in \mathbb{R}^{d_k}\}_{i=1}^{N_o}$ on client $k$ is denoted as $X_o^k$, and the set $\{X_o^k\}_{k\in[K]}$ is denoted as $X_o$. Besides $X_o^k$, each client $k$ also possesses $N_k$ local samples $\{x_{u,i}^{k}\in \mathbb{R}^{d_k}\}_{i=1}^{N_k}$ which is denoted as $X_u^k$ that is ``unaligned'' with other clients. The server has the true label of the overlapping samples $\{y_{o,i}\}_{i=1}^{N_o}$ which is denoted as $Y_o$. An example of data splitting in the two-client setting is shown in \cref{fig:data_split}. 

Each client (says the $k$-th) learns a representation extractor $f_k(.;\theta_k)$ to extract representations and the server learns a classifier $f_c(.;\theta_c)$ to classify the representations uploaded by clients. The collaborative training problem can be formulated as
%
%Let us denote the aligned data as $D_o\triangleq\{D_{o,i}\}_{i=1}^{N_o}$ where $D_{o,i}\triangleq\{x_{o,i}^1,...,x_{o,i}^K,y_{o,i}\}$. Then the collaborative training problem can be formulated as
%
{\small
\begin{equation}
    \min\limits_{\Theta} \mathcal{L}(\Theta;X_o, Y_o) \triangleq \frac{1}{N_o} \sum_{i=1}^{N_o} g(\theta_1,...,\theta_K,\theta_c;x_{o,i},y_{o,i}),
    \label{eq:problem_def}
\end{equation}
}
%
where $\Theta = \left[ \theta_1;...;\theta_K;\theta_c \right]$. $g(.)$ denotes the loss function formulated as:
%
\begin{equation}
    %g(\theta_1,...,\theta_K,\theta_c;D_{o,i}) = g\left(f_c\left(h_{o,i}^1\circ ... h_{o,i}^K\right),y_{o,i}\right),
    g(\theta_1,...,\theta_K,\theta_c;x_{o,i},y_{o,i}) = g\left(f_c\left(h_{o,i}^1\circ ... \circ h_{o,i}^K\right),y_{o,i}\right),
\end{equation}
%
where $\circ$ stands for the concatenation operation, and $h_{o,i}^k$ is the representation extracted by the local model on client $k$:
%
\begin{equation}
    h_{o,i}^k = f_k(x_{o,i}^k;\theta_k).
\end{equation}
%
For simplicity, the set of representations of the aligned data extracted by client $k$ $\{h_{o,i}^k\}_{i=1}^{N_o}$ is denoted as $H_o^k$. The objective of each party $k$ is to find the optimal $\theta_k$ without sharing local data $\{x_{o,i}^k\}_{i=1}^{N_o}$ and parameter $\theta_k$. The objective of the server is to optimize $\theta_c$ without sharing $\theta_c$ and true labels $Y_o$.
