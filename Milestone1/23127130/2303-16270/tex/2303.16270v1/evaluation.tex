\section{Evaluation}

\subsection{Experimental setup}
We evaluate our proposed one-shot VFL and few-shot VFL on both image and tabular data. As stated before, we focus and evaluate on two-client scenarios in this paper, which is a common experimental setup in most VFL literature\cite{liu2019communication,liu2020federated}. We compare our methods with two SOTA VFL methods aiming at reducing communication cost and solving the problem of limited overlapping samples, respectively.
\vspace{-3mm}
\paragraph{Baselines.} We compare our proposed algorithm with vanilla VFL and two SOTA VFL methods. (1) \textbf{FedBCD~\cite{liu2019communication}} aims at reducing the communication cost. In vanilla VFL, clients conduct one iteration of training after one time of inter-party communication. FedBCD allows clients to conduct multiple iterations of local training using the stale partial gradients of representations received in the last communication. (2) \textbf{FedCVT~\cite{kang2022fedcvt}} is a semi-supervised learning approach that improves the performance of VFL using limited overlapping samples. FedCVT leverages representation estimation and pseudo-labels prediction to expand the training set to improve the modelâ€™s representation learning. However, it still suffers from high communication cost.

% \begin{figure}[ht]
% \centering
%      \includegraphics[scale=0.4]{img/CIFAR-10.png}
% \caption{Split an image into halves and distribute them to two parties.}
% \label{fig:CIFAR-10}
% \end{figure}

%
\vspace{-3mm}
\paragraph{Datasets.} To evaluate our VFL methods under different VFL settings, we use both image data and tabular data for experiments. We use CIFAR-10 for image classification and UCI\_credit\_card dataset~\cite{yeh2009comparisons} for prediction of default of credit card clients. For CIFAR-10, we follow~\cite{liu2019communication,kang2022fedcvt} to split an image into two halves. For UCI\_credit\_card dataset, we follow FATE~\cite{liu2021fate} to assign ten attributes to one client and the rest to the other client. To mimic the settings that limited samples are overlapping, we randomly sample $N_o$ samples from the dataset as the aligned dataset. For the rest of samples we evenly and randomly separate them into two sets, and one client has access to the assigned attributes/halves of images of one set.
\vspace{-3mm}
\paragraph{Hyperparameter Configurations.}
%
To evaluate our methods under settings with different sizes of overlapping samples, we set $N_o=\{256, 512, 1024, 2048\}$ for CIFAR-10 and $N_o=\{1000, 2000\}$ for UCI\_default\_credit. We set $B$ as 32 for both datasets. Learning rates $\eta_s$ and $\eta_c$ are set to be 0.01. For FedBCD, we set $Q$ as 5. We set $\sigma$ as 0.1 and $r_m$ as 0.2 for tabular data augmentation. For CIFAR-10, we allow the baselines to continue training even after convergence to try to achieve a decent accuracy. For UCI\_default\_credit, we stop the training of baselines where there is no improvement on accuracy in the last 20 rounds. We use WideResNet20 as the backbone model for CIFAR-10 and a two-layer MLP for UCI\_default\_credit.

\vspace{-3mm}
\paragraph{Evaluation metrics.} (1) \textbf{Utility metric (Accuracy \& AUC):} We use the test data accuracy of the classifier on the server to measure the performance of VFL on CIFAR-10. For UCI\_default\_credit, we apply Area under the ROC Curve (AUC) as the utility metric. A smaller accuracy or AUC means a less practical utility. (2) \textbf{Communication metric (Communication cost/times):} We use the times of communication between the clients and the server and the total data volume of communication cost to evaluate the communication efficiency of VFL.
%
%
\subsection{Experimental results}
%
\begin{table*}[th]
\small
    \centering
    \caption{Results of accuracy and communication on CIFAR-10. Best accuracy is shown in \textbf{bold} and best communication cost in \textbf{\textit{bold italic}}.}
        \begin{tabular}{l || c  c c| c  c c| c  c c| c  c c}
            \toprule
            \textbf{Overlap size} & \multicolumn{3}{c|}{256} & \multicolumn{3}{c|}{512} &\multicolumn{3}{c|}{1024} &\multicolumn{3}{c}{2048}\\
            \hline
            & \tabincell{c}{Acc\\(\%)} & \tabincell{c}{Comm \\times} & \tabincell{c}{Comm \\cost\\(MB)} & \tabincell{c}{Acc\\(\%)} & \tabincell{c}{Comm \\times} & \tabincell{c}{Comm \\cost\\(MB)} & \tabincell{c}{Acc\\(\%)} & \tabincell{c}{Comm \\times} & \tabincell{c}{Comm \\cost\\(MB)} & \tabincell{c}{Acc\\(\%)} & \tabincell{c}{Comm \\times} & \tabincell{c}{Comm \\cost\\(MB)} \\
            \hline
            Vanilla VFL & 31.47 & 8000 & 262 & 35.33 & 16000 & 524 & 42.71 & 32000 & 1047 & 50.75 & 64000 & 2094\\
            \hline
            FedCVT~\cite{kang2022fedcvt} & 31.83 & 8000 & 262 & 35.12 & 16000 & 524 & 42.38 & 32000 & 1047 & 48.2 & 64000 & 2094\\
            \hline
            FedBCD~\cite{liu2019communication} & 31.45 & 1600 & 53 & 35.43 & 3200 & 105 & 41.93 & 6400 & 209 & 49.75 & 12800 & 419 \\
            \hline
            One-shot VFL & 78.23 & \textbf{\textit{3}} & \textbf{\textit{0.79}} & 81.12 & \textbf{\textit{3}} & \textbf{\textit{1.6}} & 85.25 & \textbf{\textit{3}} & \textbf{\textit{3.1}} & 86.13 & \textbf{\textit{3}} & \textbf{\textit{6.3}} \\
            \hline
            Few-shot VFL & 78.93 & 5 & 26.4 & 83.03 & 5 & 27.2 & 85.68 & 5 & 28.7 & 87.23 & 5 & 31.9 \\
            \hline
            \tabincell{l}{Few-shot VFL \\+finetune} & \textbf{80.37} & 805 & 52.6 & \textbf{84.05} & 965 & 58.6 & \textbf{86.35} & 1805 & 87.7 & \textbf{87.49} & 2005 & 97.4\\
            \bottomrule
        \end{tabular}
    \label{tb:results_cifar}
\end{table*}


% \begin{table*}[th]
% \small
%     \centering
%     \caption{Results of accuracy and communication on Credit Default Detection. Best accuracy is shown in \textbf{bold} and best communication cost in \textbf{\textit{bold italic}}.}
%         \begin{tabular}{l || c  c c| c  c c| c  c c}
%             \toprule
%             \textbf{Overlap size} & \multicolumn{3}{c|}{500} & \multicolumn{3}{c|}{1000} &\multicolumn{3}{c}{2000} \\
%             \hline
%             & \tabincell{c}{AUC} & \tabincell{c}{Comm \\times} & \tabincell{c}{Comm \\cost\\(KB)} & \tabincell{c}{AUC} & \tabincell{c}{Comm \\times} & \tabincell{c}{Comm \\cost\\(KB)} & \tabincell{c}{AUC} & \tabincell{c}{Comm \\times} & \tabincell{c}{Comm \\cost\\(KB)}\\
%             \hline
%             Vanilla VFL & \textbf{0.733} & 882 & 2596.48 & 0.738 & 1026 & 3032.48 & 0.758 & 4094 & 12052.82\\
%             \hline
%             FedCVT & 0.715 & 1858 & 5470.08 & 0.724 & 2908 & 8561.28 & 0.733 & 4318 & 12712.32\\
%             \hline
%             FedBCD & 0.732 & 440 & 1295.36 & 0.733 & 624 & 1837.12 & 0.760 & 1686 & 4963.52\\
%             \hline
%             One-shot VFL & 0.715 & \textit{\textbf{3}} & \textit{\textbf{94.00}} & 0.748 & \textit{\textbf{3}} & \textit{\textbf{188.00}} & 0.764 & \textit{\textbf{3}} & \textit{\textbf{376.00}} \\
%             \hline
%             Few-shot VFL & 0.726 & 5 & 1462.76 & \textbf{0.753} & 5 & 1725.00 & \textbf{0.769} & 5 & 1832.00 \\
%             \bottomrule
%         \end{tabular}
%     \label{tb:results_credit}
% \end{table*}





\paragraph{Accuracy v.s. Communication Cost.}
The results of CIFAR-10 are shown in \cref{tb:results_cifar}. It is shown that compared with vanilla VFL, one-shot VFL improves the accuracy by more than 45\% while reducing communication cost by more than 330$\times$. FedBCD reduces communication cost compared with Vanilla VFL. However, it does not improve the accuracy of the model, and the communication reduction is not comparable with one-shot VFL. It is notable that FedCVT cannot achieve significant accuracy improvement compared with vanilla VFL, because the true label is extremely limited in our realistic setting. With extremely limited true labels, it is hard for the server of FedCVT to conduct SSL using only the estimated representations and pseudo labels. 

Few-shot VFL improves the accuracy further with higher communication cost compared with one-shot VFL. However, the communication reduction is still significant compared with baselines. In both one-shot VFL and few-shot VFL, clients train representation extractors first, then the server trains the classifier. To improve the accuracy further, we conduct end-to-end vanilla VFL after completing few-shot VFL to finetune the global model on CIFAR-10. It is shown that the end-to-end finetuning can improve the accuracy further. Even though the finetuning requires more communication rounds, it is still much more efficient compared with the baselines and offers the clients an option to further improve the performance.

\begin{figure}[ht]
\centering
     \includegraphics[scale=0.34]{img/tab-cost.pdf}
\caption{Compared results of AUC v.s. communication cost on UCI\_default\_credit.}
\label{fig:tab-cost}
\end{figure}


The results of UCI\_default\_credit dataset are shown in \cref{fig:tab-cost}. Even though the task of credit card default detection is much simpler than image classification, which does not require a large amount of data to learn, our one-shot VFL can still achieve AUC higher than all the baselines in both settings. One-shot VFL can reduce the communication cost by more than 32$\times$, 33$\times$ and 10$\times$ compared with Vanilla VFL, FedCVT and FedBCD, respectively, under the setting with 2000 overlapping samples. Few-shot VFL increases the communication cost slightly compared with one-shot VFL, but it can improve the AUC further.

%The results of UCI\_default\_credit dataset are shown in \cref{fig:tab-cost}. It is shown that one-shot and few-shot VFL do not improve the accuracy of the system as much as CIFAR-10. The reason is that the task of credit card default detection is much simpler than image classification. The global model has only two layers, and only the first layer is semi-supervised trained locally with both overlapping and unaligned data points. The other layer (i.e., classifier on the server) is trained with only limited overlapping data. Thus, it is hard to locally improve the performance of the simple extractor as compared to a deep CNN-based extractor in image classification. However, our methods can still reduce communication cost significantly compared with the baselines with descent AUC improvement.
%
\vspace{-3.5mm}
\paragraph{Accuracy v.s. Times of Communication.}
%
Besides the communication cost, the times of communication needed between the clients are also an important metric to evaluate the communication efficiency. If the clients are required to communicate with the server continually (e.g., vanilla VFL), a stable and reliable communication channel between the server and a client will be necessary. In addition, if a client cannot upload its update to the server in one round of training due to network outage, all the other clients have to wait for it, which is extremely detrimental to the robustness and efficiency of the system. As shown in \cref{tb:results_cifar} and \cref{fig:tab-time}, only three times of communications are needed for one-shot VFL, and the clients conduct SSL locally without waiting for the response from the server, which improves the efficiency significantly. FedBCD reduces the times of communication, but it is still not comparable to one-shot and few-shot VFL. In addition, continual communication between clients are still required for FedBCD, which cannot solve the bottleneck of communication efficiently. Few-shot VFL improves the accuracy further with only two additional times of communication between the clients and the server. During finetuning, the clients need to continually communicate with the server for multiple rounds. However, the clients do not need to communicate during as many rounds as for the other baselines. In practice, our one-shot and few-shot VFL can be used as pre-training techniques to achieve higher performance while significantly reducing the communication cost.

\begin{figure}[ht]
\centering
     \includegraphics[scale=0.34]{img/tab-times.pdf}
\caption{Compared results of AUC v.s. number of communication times on UCI\_default\_credit.}
\label{fig:tab-time}
\end{figure}

