@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@article{kollias2022abaw, title={ABAW: Learning from Synthetic Data \& Multi-Task Learning Challenges}, author={Kollias, Dimitrios}, journal={arXiv preprint arXiv:2207.01138}, year={2022} }

@inproceedings{kollias2022abaw1, title={Abaw: Valence-arousal estimation, expression recognition, action unit detection \& multi-task learning challenges}, author={Kollias, Dimitrios}, booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages={2328--2336}, year={2022} } 

@article{kollias2021distribution, title={Distribution Matching for Heterogeneous Multi-Task Learning: a Large-scale Face Study}, author={Kollias, Dimitrios and Sharmanska, Viktoriia and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2105.03790}, year={2021} }

@article{meng2022multi,
  title={Multi-modal emotion estimation for in-the-wild videos},
  author={Meng, Liyu and Liu, Yuchen and Liu, Xiaolong and Huang, Zhaopei and Jiang, Wenqiang and Zhang, Tenggan and Deng, Yuanyuan and Li, Ruichen and Wu, Yannan and Zhao, Jinming and others},
  journal={arXiv preprint arXiv:2203.13032},
  year={2022}
}

@inproceedings{kollias2021analysing, title={Analysing affective behavior in the second abaw2 competition}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages={3652--3660}, year={2021}}

@inproceedings{kollias2020analysing, title={Analysing Affective Behavior in the First ABAW 2020 Competition}, author={Kollias, D and Schulc, A and Hajiyev, E and Zafeiriou, S}, booktitle={2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)(FG)}, pages={794--800}}

@inproceedings{zhang2022transformer,
  title={Transformer-based multimodal information fusion for facial expression analysis},
  author={Zhang, Wei and Qiu, Feng and Wang, Suzhen and Zeng, Hao and Zhang, Zhimeng and An, Rudong and Ma, Bowen and Ding, Yu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2428--2437},
  year={2022}
}

@article{kollias2019expression, title={Expression, Affect, Action Unit Recognition: Aff-Wild2, Multi-Task Learning and ArcFace}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:1910.04855}, year={2019}}

@article{ekman1978facial,
  title={Facial action coding system},
  author={Ekman, Paul and Friesen, Wallace V},
  journal={Environmental Psychology \& Nonverbal Behavior},
  year={1978}
}

@article{kowalczuk2021cognitive,
  title={Cognitive, affective, and behavioral consumer responses to augmented reality in e-commerce: A comparative study},
  author={Kowalczuk, Pascal and Siepmann, Carolin and Adler, Jost},
  journal={Journal of Business Research},
  volume={124},
  pages={357--373},
  year={2021},
  publisher={Elsevier}
}
@article{kollias2023abaw,
  title={ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit Detection \& Emotional Reaction Intensity Estimation Challenges},
  author={Kollias, Dimitrios and Tzirakis, Panagiotis and Baird, Alice and Cowen, Alan and Zafeiriou, Stefanos},
  journal={arXiv preprint arXiv:2303.01498},
  year={2023}
}

@inproceedings{cao2018vggface2,
  title={Vggface2: A dataset for recognising faces across pose and age},
  author={Cao, Qiong and Shen, Li and Xie, Weidi and Parkhi, Omkar M and Zisserman, Andrew},
  booktitle={2018 13th IEEE international conference on automatic face \& gesture recognition (FG 2018)},
  pages={67--74},
  year={2018},
  organization={IEEE}
}

@article{mollahosseini2017affectnet,
  title={Affectnet: A database for facial expression, valence, and arousal computing in the wild},
  author={Mollahosseini, Ali and Hasani, Behzad and Mahoor, Mohammad H},
  journal={IEEE Transactions on Affective Computing},
  volume={10},
  number={1},
  pages={18--31},
  year={2017},
  publisher={IEEE}
}

@article{kollias2021affect, title={Affect Analysis in-the-wild: Valence-Arousal, Expressions, Action Units and a Unified Framework}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2103.15792}, year={2021}}

@inproceedings{nguyen2023affective,
  title={Affective Behavior Analysis Using Action Unit Relation Graph and Multi-task Cross Attention},
  author={Nguyen, Dang-Khanh and Pant, Sudarshan and Ho, Ngoc-Huynh and Lee, Guee-Sang and Kim, Soo-Hyung and Yang, Hyung-Jeong},
  booktitle={European Conference on Computer Vision},
  pages={132--142},
  year={2023},
  organization={Springer}
}

@inproceedings{lucey2010extended,
  title={The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression},
  author={Lucey, Patrick and Cohn, Jeffrey F and Kanade, Takeo and Saragih, Jason and Ambadar, Zara and Matthews, Iain},
  booktitle={2010 ieee computer society conference on computer vision and pattern recognition-workshops},
  pages={94--101},
  year={2010},
  organization={IEEE}
}

@article{ferrer2020role,
  title={The role of incidental affective states in appetitive risk behavior: A meta-analysis.},
  author={Ferrer, Rebecca A and Taber, Jennifer M and Sheeran, Paschal and Bryan, Angela D and Cameron, Linda D and Peters, Ellen and Lerner, Jennifer S and Grenen, Emily and Klein, William MP},
  journal={Health Psychology},
  volume={39},
  number={12},
  pages={1109},
  year={2020},
  publisher={American Psychological Association}
}
@inproceedings{zafeiriou2017aff, title={Aff-wild: Valence and arousal ‘in-the-wild’challenge}, author={Zafeiriou, Stefanos and Kollias, Dimitrios and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Kotsia, Irene}, booktitle={Computer Vision and Pattern Recognition Workshops (CVPRW), 2017 IEEE Conference on}, pages={1980--1987}, year={2017}, organization={IEEE} } 

@article{kollias2019face,title={Face Behavior a la carte: Expressions, Affect and Action Units in a Single Network}, author={Kollias, Dimitrios and Sharmanska, Viktoriia and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:1910.11111}, year={2019}}

@article{kollias2019deep, title={Deep affect prediction in-the-wild: Aff-wild database and challenge, deep architectures, and beyond}, author={Kollias, Dimitrios and Tzirakis, Panagiotis and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Schuller, Bj{\"o}rn and Kotsia, Irene and Zafeiriou, Stefanos}, journal={International Journal of Computer Vision}, pages={1--23}, year={2019}, publisher={Springer} }

@article{baden2019impact,
  title={The impact of constructive news on affective and behavioural responses},
  author={Baden, Denise and McIntyre, Karen and Homberg, Fabian},
  journal={Journalism Studies},
  volume={20},
  number={13},
  pages={1940--1959},
  year={2019},
  publisher={Taylor \& Francis}
}

@inproceedings{zhang2016multimodal,
  title={Multimodal spontaneous emotion corpus for human behavior analysis},
  author={Zhang, Zheng and Girard, Jeff M and Wu, Yue and Zhang, Xing and Liu, Peng and Ciftci, Umur and Canavan, Shaun and Reale, Michael and Horowitz, Andy and Yang, Huiyuan and others},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3438--3446},
  year={2016}
}

@article{chen2020transformer,
  title={Transformer encoder with multi-modal multi-head attention for continuous affect recognition},
  author={Chen, Haifeng and Jiang, Dongmei and Sahli, Hichem},
  journal={IEEE Transactions on Multimedia},
  volume={23},
  pages={4171--4183},
  year={2020},
  publisher={IEEE}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{jiang2022facial,
  title={Facial action unit recognition with multi-models ensembling},
  author={Jiang, Wenqiang and Wu, Yannan and Qiao, Fengsheng and Meng, Liyu and Deng, Yuanyuan and Liu, Chuanhe},
  journal={arXiv preprint arXiv:2203.13046},
  year={2022}
}

@article{nguyen2022ensemble,
  title={An ensemble approach for facial expression analysis in video},
  author={Nguyen, Hong-Hai and Huynh, Van-Thong and Kim, Soo-Hyung},
  journal={arXiv preprint arXiv:2203.12891},
  year={2022}
}
@article{jeong2022facial,
  title={Facial expression recognition based on multi-head cross attention network},
  author={Jeong, Jae-Yeop and Hong, Yeong-Gi and Kim, Daun and Jung, Yuchul and Jeong, Jin-Woo},
  journal={arXiv preprint arXiv:2203.13235},
  year={2022}
}

@article{wang2022multi,
  title={Multi-modal multi-label facial action unit detection with transformer},
  author={Wang, Lingfeng and Wang, Shisen and Qi, Jin},
  journal={arXiv preprint arXiv:2203.13301},
  year={2022}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{zhang2022continuous,
  title={Continuous emotion recognition using visual-audio-linguistic information: A technical report for abaw3},
  author={Zhang, Su and An, Ruyi and Ding, Yi and Guan, Cuntai},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2376--2381},
  year={2022}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
