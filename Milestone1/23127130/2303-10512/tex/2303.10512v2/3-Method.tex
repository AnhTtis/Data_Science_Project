\section{\ouralg~ Method}\label{sec:method}
Our method contains two important components: (i) SVD-based adaptation, which formulates the incremental matrices in the form of singular value decomposition; (ii) Importance-aware rank allocation, which prunes redundant singular values based on our newly-designed importance metric.  

\vspace{-1mm}
\subsection{SVD-Based Adaptation}\label{sec:svd_adaptation}
\vspace{-1mm}
As mentioned in Section~\ref{sec:introduction}, we propose to parameterize the incremental updates of the pre-trained weight matrices in the form of singular value decomposition:
\begin{align}\label{eq:svd_adaptation}
	\W = \Wpre + \DeltaW = \Wpre + \PP \Lam \QQ, 
\end{align}
where $ \PP\in\R^{d_1 \times r} $ and $ \QQ\in\R^{r \times d_2} $ represent the left/right singular vectors of $ \DeltaW $ and the diagonal matrix $ \Lam \in \R^{r\times r} $ contains the singular values $ \{ \lambda_{i} \}_{1\leq i \leq r} $ with $ r\ll \min(d_1, d_2) $.  
We further denote $ \Gcali = \{\PP_{*i}, \lambda_{i}, \QQ_{i*} \} $ as the triplet containing the $i$-th singular value and vectors. 
In practice, since $\Lam$ is diagonal, we only need to save it as a vector in $\R^r$. $ \Lam $ is initialized with zero while $ \PP $ and $ \QQ $ adopt a random Gaussian initialization to ensure $ \DeltaW = 0 $ at the beginning of training. To enforce the orthogonality of $ \PP $ and $ \QQ $, i.e.,~$ \PP^{\top}\PP = \QQ\QQ^{\top} = I $, we utilize the following regularizer\footnote{We present the experiments in Appendix~\ref{app:regularization} to verify the effectiveness of the regularization.}: 
\begin{align}\label{eq:regularization}
\Reg(P, Q) = \norm{ P^{\top}P-I }_{\sf F}^2 + \norm{QQ^{\top}-I}_{\sf F}^2.  
\end{align}
In our method, $ \Lam $ is iteratively pruned to adjust the rank after each gradient decent step.  As mentioned in Section~\ref{sec:introduction}, one can directly compute SVD for every $ \DeltaW $ to manipulate singular values. The computational complexity, however, is $ O(\min(d_1,d_2) d_1 d_2) $. It becomes extremely expensive to iteratively apply SVD for a large number of high-dimensional incremental matrices. In contrast, our parameterization avoids intensive SVD computation, greatly releasing the computational overhead.  


We remark that one can also apply structured pruning to LoRA to control the rank (i.e., prune $ \B\A $ doublet-wise in (\ref{eq:lora})), whereas it has the following disadvantages.  First, when a doublet is measured as unimportant, we have to prune all of its elements. It makes scarcely possible to reactivate the pruned doublets as their entries are all zeroed out and not trained. In contrast, {\ouralg} only masks out the singular values based on (\ref{eq:svd_adaptation}) while the singular vectors are always maintained. It preserves the potential of future recovery for the triplets dropped by mistake.  Second, $ \A $ and $ \B $ of LoRA are not orthogonal, meaning the doublets can be dependent with each other.  Discarding the doublets can incur larger variation from the original matrix than truncating the smallest singular values. Therefore, the incremental matrices are often altered dramatically after each step of rank allocation, which causes training instability and even hurts generalization. To demonstrate this point, we present an ablation study in Section~\ref{sec:exp_analysis}, which compares {\ouralg} with structured pruning for LoRA. 



\subsection{Importance-aware Rank Allocation}\label{sec:rank_allocation}
We apply the SVD-based adaptation (\ref{eq:svd_adaptation}) to every weight matrix including $\Wq$,  $\Wk$, $\Wv$, $\Wfp$ and $\Wfq$ of each transformer layer. In order to control the budget, we iteratively prune singular values in correspondence to their importance score during the training.  
For clear reference, we use $ \kk $ to index the incremental matrix, i.e., $ \DeltaWk = \PPk \Lamk \QQk$ for $\kk=1,\dots, n $, where $ n $ is the number of adapted weight matrices.  We denote the $ i $-th triplet of $ \DeltaWk $ as $ \Gcalki = \{\PPki, \lambdaki, \QQki \} $ and its importance score as $ \Scki $.   We further denote the parameter sets $ \PPcal = \{\PPk \}_{\kk=1}^{n}  $, $ \Lamcal  = \{\Lamk \}_{\kk=1}^{n} $, $ \QQcal = \{ \QQk \}_{k=1}^{n} $ and training cost as $ \CC(\PPcal, \Lamcal, \QQcal) $. With the regularization (\ref{eq:regularization}), the training objective is given by   $ \LL(\PPcal, \Lamcal, \QQcal) = \CC(\PPcal, \Lamcal, \QQcal) + \gamma \sum_{k=1}^{n} \Reg(\PPk, \QQk) $, where $\gamma>0$ is the regularization coefficient. At the $ t $-th step, we first take a stochastic gradient step to update $ \PPtk, \Lamtk \text{ and } \QQtk$ for $ k=1,\dots,n $. Specifically, for $ \Lamtk $  
\begin{align}
	\tLamtk = \Lamtk - \eta \nabla_{\Lamk} \LL(\PPcalt, \Lamcalt, \QQcalt),
\end{align}
where $ \eta > 0 $ is learning rate. Then, given importance score $ \Sctk $, the singular values are pruned following 
\begin{align}
	\Lamtpk = \Proj(\tLamtk, \Sctk), \text{ with } 
	\Proj(\tLamtk, \Sctk)_{ii} = 
	\left\{ \begin{array}{lc}
		\tLamt_{\kk,ii} & \Sctki \text{ is in the top-}\But \text{ of } \Sct,\\ 
		0 & \text{ otherwise,}
	\end{array}
	\right. 
\end{align}
where $ \Sct = \{ \Sctki \}_{1\leq \kk \leq n, 1\leq i \leq r} $ contains the importance score of all triplets. Here $ \But $ is the budget of remaining singular values at the $ t $-th step, which we explain more in Section~\ref{sec:global_budget_control}.  In this way, we leave more budget to the incremental matrices of higher priority by pruning the singular values of less important ones. In the sequel, we introduce several options to design the importance score. 


{\bf Magnitude of singular values} is the most straightforward way to quantify the importance of every triplet, i.e.,~$ \Scki = \lvert \lambdaki \rvert $. 
In this way, only the least significant singular values are discarded. It minimizes the deviation from the original matrix and further stabilizes the training.  Many existing methods use this criterion to control the rank of matrix  \citep{cai2010singular,koltchinskii2011nuclear,toh2010accelerated}.   However, we remark that such a simple metric cannot properly quantify the contribution of parameters to model performance. 


{\bf Sensitivity-based importance} is another option for importance scoring, which quantifies the sensitivity of parameters to the training loss 
\citep{molchanov2019importance,sanh2020movement,liang2021super,zhang2022platon}.  The prior work, however, leverages the sensitivity to quantify the importance of single entries and applies it for unstructured pruning that prunes weights element-wise.  When it turns to our case, we have to design a new metric as the triplets are discarded group-wise. Every entry's sensitivity ought to be considered and properly combined to quantify the overall contribution of the triplet to model performance. Therefore, we propose a newly-designed importance metric in account of both the singular value and vectors in triplet $ \Gcalki $: 
\begin{align}\label{eq:all_importance}
	\Scki = \scf(\lambdaki) + \frac{1}{d_1} \sum_{j=1}^{d_1} \scf(\PP_{\kk,ji}) + \frac{1}{d_2} \sum_{j=1}^{d_2} \scf(\QQ_{\kk,ij}), 
\end{align}
where we calculate the mean importance of $ \PPki $ and $ \QQki $ such that $ \Scki $ does not scale with the number of parameters in $ \Gcalki $.  Here $ \scf(\cdot) $ is a specific importance function for single entries.  We can adopt the sensitivity for $ \scf(\cdot) $, which is defined as the magnitude of the gradient-weight product: 
\begin{align}\label{eq:sensitivity}
	\I(w_{ij}) = | w_{ij} \nabla_{w_{ij}}\LL |,
\end{align}
where $ w_{ij} $ is any trainable parameter. (\ref{eq:sensitivity}) essentially approximates the change in loss when a parameter is zeroed out. If the removal of a parameter has a large influence, then the model is sensitive to it and we should retain it \citep{molchanov2019importance,liang2021super,zhang2022platon}. 


However, \citet{zhang2022platon} point out that the sensitivity in (\ref{eq:sensitivity}) is not yet a reliable importance indicator. Such a score is estimated on the sampled mini batch. The stochastic sampling and complicated training dynamics incur high variability and large uncertainty for estimating the sensitivity with (\ref{eq:sensitivity}). Therefore, \citet{zhang2022platon} propose to resolve this issue by sensitivity smoothing and uncertainty quantification:
\begin{align}
\Ibar^{(t)}(w_{ij}) = & \beta_1 \Ibar^{(t-1)}(w_{ij}) + (1-\beta_1) \I^{(t)}(w_{ij}) \label{eq:smoothed_sensitivity} \\
\Ubar^{(t)}(w_{ij}) = & \beta_2 \Ubar^{(t-1)} (w_{ij}) + (1-\beta_2) \Big\lvert \I^{(t)}(w_{ij}) - \Ibar^{(t)}(w_{ij}) \Big\rvert \label{eq:uncertainty},
\end{align}
where $ 0<\beta_1, \beta_2 <1 $. $ \Ibart $ is the smoothed sensitivity by exponential moving average and $ \Ubart $ is the uncertainty term quantified by the local variation between $ \I^{(t)} $ and $ \Ibart $. Then they define the importance as the product between $ \Ibart $ and $ \Ubart $, which can be another option for $ \scf(\cdot) $: 
\begin{align}\label{eq:platon_score}
	\scft(w_{ij}) = \Ibart(w_{ij}) \cdot \Ubart(w_{ij}).
\end{align}
We present a detailed ablation study in Section~\ref{sec:exp_analysis} to compare the performance of different importance metrics. We find the proposed metric (\ref{eq:all_importance}) based on the sensitivity variant (\ref{eq:platon_score}) generally performs best. 
We summarize the detailed algorithm in Algorithm~\ref{alg:our_algorithm}. 


\begin{algorithm}[t!]
 	\caption{{\ouralg}} 
 	\label{alg:our_algorithm}
 	\begin{algorithmic}[1]
 		\STATE {{\bfseries Input:} Dataset $ \mathcal{D} $; total iterations $ T $; budget schedule $ \{ \But \}_{t=0}^{T} $; hyperparameters $ \eta, \gamma, \beta_1, \beta_2 $. }  
 		%		\STATE {{\bf Initialize} $ \PPk, \Lamk, \QQk $ for $ k=1,...,n $. }
 		\FOR{$ t = 1, \dots, T $}  
 		\STATE Sample a mini-batch from $\mathcal{D}$ and compute the gradient $ \nabla\LL(\PPcal, \Lamcal, \QQcal) $;
 		\STATE Compute the sensitivity $ \I^{(t)} $ in (\ref{eq:sensitivity}) for every parameter in $ \{ \PPcal, \Lamcal, \QQcal \} $;
 		\STATE Update $ \Ibart $ as (\ref{eq:smoothed_sensitivity}) and $ \Ubart $ as (\ref{eq:uncertainty}) for every parameter in $ \{ \PPcal, \Lamcal, \QQcal \} $;
 		\STATE Compute $ \Sctki $ by (\ref{eq:all_importance}), for $ k=1,\dots,n $ and $ i=1,\dots,r $ ;
 		\STATE Update $ \PPk^{(t+1)} = \PPtk - \eta \nabla_{\PPk}\LL(\PPcal, \Lamcal, \QQcal)  $ and $ \QQk^{(t+1)} = \QQk^{(t)} - \eta \nabla_{\QQk}\LL(\PPcal, \Lamcal, \QQcal) $;
 		\STATE Update $ \Lamtpk = \Proj(\Lamtk -\eta \nabla_{\Lamk}\LL(\PPcal, \Lamcal, \QQcal), \Sctk) $ given the budget $ \But $.  
 		\ENDFOR
 		\STATE \textbf{Output:}  { The fine-tuned parameters $ \{ \PPcal^{(T)}, \Lamcal^{(T)}, \QQcal^{(T)} \} $.} 
	\end{algorithmic}
\end{algorithm}


\vspace{3mm}
\subsection{Global Budget Scheduler}\label{sec:global_budget_control}
%\vspace{-1mm}
As mentioned in Section~\ref{sec:introduction}, adjusting the rank is naturally to control the parameter budget in the context of low-rank adaptation. Hence we define the budget $ \But $ as the total rank of all incremental matrices, i.e., the number of total singular values. Recall that the budget allocation is iteratively conducted during the fine-tuning. To facilitate the training, we propose a global budget scheduler. Specifically, we start from an initial budget $ \Buinit $ that is slightly higher than the target budget $ \BuT $ (e.g., 1.5 times of $ \BuT $).  We set the initial rank of each incremental matrix as $r = \Buinit / n$.  We warm up the training for $t_i$ steps, and then follow a cubic schedule to decrease the budget $\But$ until it reaches $\BuT$.  Finally, we fix the resulting budget distribution and fine-tune the model for $ t_f $ steps.  The exact equation for the budget schedule is presented in Appendix~\ref{app:budget_schedule}.  This allows {\ouralg} to explore the parameter space first and then focus on the most important weights later.

