\newpage 
\appendix 

%\section{The Detailed Algorithm}\label{app:algorithm_box}
%
%\begin{algorithm}[htb!]
%	\caption{{\ouralg}} 
%	\label{alg:our_algorithm}
%	\begin{algorithmic}[1]
%		\STATE {{\bfseries Input:} Dataset $ \mathcal{D} $; total iterations $ T $; budget schedule $ \{ \But \}_{t=0}^{T} $; hyperparameters $ \eta, \gamma, \beta_1, \beta_2 $. }  
%		%		\STATE {{\bf Initialize} $ \PPk, \Lamk, \QQk $ for $ k=1,...,n $. }
%		\FOR{$ t = 1, \dots, T $}  
%		\STATE Sample a mini-batch from $\mathcal{D}$ and compute the gradient $ \nabla\LL(\PPcal, \Lamcal, \QQcal) $;
%		\STATE Compute the sensitivity $ \I^{(t)} $ in (\ref{eq:sensitivity}) for every parameter in $ \{ \PPcal, \Lamcal, \QQcal \} $;
%		\STATE Update $ \Ibart $ as (\ref{eq:smoothed_sensitivity}) and $ \Ubart $ as (\ref{eq:uncertainty}) for every parameter in $ \{ \PPcal, \Lamcal, \QQcal \} $;
%		\STATE Compute $ \Sctki $ by (\ref{eq:all_importance}), for $ k=1,\dots,n $ and $ i=1,\dots,r $ ;
%		\STATE Update $ \PPk^{(t+1)} = \PPtk - \eta \nabla_{\PPk}\LL(\PPcal, \Lamcal, \QQcal)  $ and $ \QQk^{(t+1)} = \QQk^{(t)} - \eta \nabla_{\QQk}\LL(\PPcal, \Lamcal, \QQcal) $;
%		\STATE Update $ \Lamtpk = \Proj(\Lamtk -\eta \nabla_{\Lamk}\LL(\PPcal, \Lamcal, \QQcal), \Sctk) $ given the budget $ \But $.  
%		\ENDFOR
%		\STATE \textbf{Output:} 
%	\end{algorithmic}
%\end{algorithm}

\section{Global Budget Schedule}\label{app:budget_schedule}
As mentioned in Section~\ref{sec:global_budget_control}, we propose a global budget scheduler to gradually decrease the budget $\But$ following a cubic schedule. The detailed equation is given as follows: 
\begin{equation}\label{eq:cubic_schedule}
\But = \begin{cases}
\Buinit & 0 \leq t<t_{i} \\ 
\BuT+ \left(\Buinit-\BuT\right)\left(1-\frac{t-t_{i}-t_{f}}{T-t_i - t_f}\right)^{3} & t_{i} \leq t<T-t_{f} \\ 
\BuT &\text { o.w. }
\end{cases}.
\end{equation}


%\section{The Budget Distribution}\label{app:budget_distribution}
%\begin{figure}[htb!]
%    %\vspace{-1mm}
%    \centering
%    \includegraphics[width=0.95\linewidth]{img/rank_pattern_mnli_init12.pdf}
%    \vspace{-2mm}
%    \caption{The resulting rank of each incremental matrix when fine-tuning DeBERTaV3-base on MNLI with {\ouralg}. Here the $x$-axis is the layer index and the $y$-axis represents different types of adapted weight matrices.} 
%    \label{fig:rank_pattern_app}
%    % \vspace{-2mm}
%\end{figure}
%Figure~\ref{fig:rank_pattern} shows the resulting rank of each incremenal matrix when fine-tuning DeBERTaV3-base on MNLI with {\ouralg}. We can see that {\ouralg} allocates more parameter budget to weight matrices of 8, 9, 10, and 11 layers, especially for $\Wfp$ and $\Wv$. Such behavior aligns with our conclusions presented in Figure~\ref{fig:budget_distribution}. 


\section{GLUE Dataset Statistics}\label{app:glue_datesets} 

We present the dataset statistics of GLUE \citep{wang2018glue} in the following table. 

\begin{table*}[htb!]
	\begin{center}
	\caption{Summary of the GLUE benchmark.}
	\label{tab:glue}
		\begin{tabular}{l|l|c|c|c|c|c}
			\toprule 
			\bf Corpus &Task& \#Train & \#Dev & \#Test   & \#Label &Metrics\\ \midrule
			\multicolumn{6}{@{\hskip1pt}r@{\hskip1pt}}{Single-Sentence Classification (GLUE)} \\ \hline
			CoLA & Acceptability&8.5k & 1k & 1k & 2 & Matthews corr\\ \hline
			SST & Sentiment&67k & 872 & 1.8k & 2 & Accuracy\\ \midrule
			\multicolumn{6}{@{\hskip1pt}r@{\hskip1pt}}{Pairwise Text Classification (GLUE)} \\ \hline
			MNLI & NLI& 393k& 20k & 20k& 3 & Accuracy\\ \hline
			RTE & NLI &2.5k & 276 & 3k & 2 & Accuracy \\ \hline
			% WNLI & NLI &634& 71& 146& 2 & Accuracy \\ \hline
			QQP & Paraphrase&364k & 40k & 391k& 2 & Accuracy/F1\\ \hline
			MRPC & Paraphrase &3.7k & 408 & 1.7k& 2&Accuracy/F1\\ \hline
			QNLI & QA/NLI& 108k &5.7k&5.7k&2& Accuracy\\ \midrule
			\multicolumn{5}{@{\hskip1pt}r@{\hskip1pt}}{Text Similarity (GLUE)} \\ \hline
			STS-B & Similarity &7k &1.5k& 1.4k &1 & Pearson/Spearman corr\\ \bottomrule
			%			\multicolumn{6}{@{\hskip1pt}r@{\hskip1pt}}{Pairwise Text Classification} \bottomrule %\\ \hline
			% 			SNLI & NLI& 549k &9.8k&9.8k&3& Accuracy\\ \hline
			% 			SciTail & NLI& 23.5k &1.3k&2.1k&2& Accuracy\\ \hline
			% 			ANLI & NLI& 163k &3.2k&3.2k&3& Accuracy\\ \hline
		\end{tabular}
	\end{center}
	\vspace{-2mm}
\end{table*}


\section{Natural Language Understanding}\label{app:NLU}
\subsection{Budget Configuration}
For each budget level, we tune the final budget $\BuT$ for {\ouralg}, the rank $r$ for LoRA, the hidden dimension $d$ for two adapters to match the budget requirements.

\begin{table*}[h!]
 \vspace{2mm}
\caption{Detailed budget setup for GLUE benchmark.}
\vspace{-1mm}
\label{tab:app_glue_budget}
\begin{center}
\begin{small}
\begin{tabular}{l|cccc}
\toprule
{\# Params} & {Houlsby Adapter ($d$)} & {Pfeiffer Adapter ($d$)} & {LoRA ($r$)} & {{\ouralg} ($\BuT$)}
\\
\midrule
{1.2M} & {32} & 64 & 8 & 576 
\\
{0.6M} & 16 & 32 & 4 & 288 
\\
{0.3M} & 8 & 16 & 2 & 144 
\\
\bottomrule
\end{tabular}
\end{small}
\end{center}
%\vspace{-1mm}
\end{table*}

Alternatively, we can also set the final average rank $ \rbarT = \BuT / n $ for {\ouralg} to control the budget,  which is set as 2, 4, and 8 given the final budget as 144, 288, and 576 respectively. Then we select the initial rank $r$ from $\{4,6,12\}$ for the final average rank $\{ 2, 4, 8\}$ respectively.   

\subsection{Training Details}
We tune the learning rate from $ \{ 8\times10^{-5}, 5\times10^{-5}, 3\times10^{-5}, 1\times10^{-4}, 3\times10^{-4}, 5\times10^{-4}, 8\times10^{-4}, 1\times10^{-3} \} $ and pick the best learning rate for every method. For each dataset, the batch size is set as identical for every method.  

\begin{table*}[h!]
 \vspace{1mm}
\caption{Hyper-parameter setup of {\ouralg} for GLUE benchmark.}
\vspace{-1mm}
\label{tab:app_glue_setup}
\begin{center}
\begin{small}
\begin{tabular}{l|ccccccc}
\toprule
{Dataset} & {learning rate} & {batch size} & {\# epochs} & {$\gamma$}  & {$t_i$} & {$\DeltaT$}  & {$t_f$}
\\
\midrule 
{\bf MNLI} & {$5\times 10^{-4}$} & 32 & 7 & 0.1 & 8000 & 100 & 50000 
\\
{\bf RTE} & $ 1.2\times 10^{-3} $ & 32 & 50 & 0.3 & 600 & 1 & 1800 
\\
{\bf QNLI}  & $ 1.2\times 10^{-3} $ & 32 & 5 & 0.1 & 2000 & 100 & 8000 
\\
{\bf MRPC} & $ 1\times 10^{-3} $ & 32 & 30 & 0.1 & 600 & 1 & 1800 
\\
{\bf QQP } & $5\times 10^{-4}$ & 32 & 5 & 0.1 & 8000 & 100 & 25000
\\
{\bf SST-2} & $ 8\times 10^{-4} $ & 32 & 24 & 0.1 & 6000 & 100 & 22000 
\\
{\bf CoLA} & $ 5\times 10^{-4} $ & 32 & 25 & 0.5 & 800 & 10 & 3500  
\\
{\bf STS-B} & $ 2.2\times 10^{-3} $ & 32 & 25 & 0.1 & 800 & 10 & 2000 
\\
\bottomrule
\end{tabular}
\end{small}
\end{center}
%\vspace{-1mm}
\end{table*}




% \subsection{Detailed Results}

% {\setlength{\tabcolsep}{0.35em}
% \renewcommand{\arraystretch}{1.1}
% \begin{table}[t!]
% \vspace{-8mm}
% \caption{Results with DeBERTaV3-base on GLUE development set. The best results on each dataset are shown in \textbf{bold}. We report mean of $5$ runs using different random seeds.}
% \vspace{-3mm}
% \label{tab:glue_datasets}
% \begin{center}
% \begin{small}
% \begin{tabular}{l|c|cccccccc}
% \toprule
% \multirow{2}*{\bf Method} & \multirow{2}*{\bf \small \# Params} & {\bf MNLI} & {\bf SST-2} & {\bf CoLA} & {\bf QQP } & {\bf QNLI} & {\bf RTE}  & {\bf MRPC}  & {\bf STS-B} \\  
% ~ & ~ & {m/mm} & {Acc} & {Mcc} & {Acc/F1} & {Acc} & {Acc} & {Acc} & { Corr } \\
% \midrule 
% {Fine-tuning} & {184M} & {89.90/90.12} & {95.63} & {69.19} & {\bf92.40/89.80} & {94.03} & {83.75} & {89.46} & {91.60}
% \\
% \midrule
% {BitFit} & {0.1M} & {89.37/89.91} & {94.84} & {66.96} & {88.41/84.95} & {92.24} & {78.70} & {87.75} & {91.35} 
% \\
% \midrule 
% {\small Houlsby adapter} & {1.22M} & {90.13/90.17} & {95.53} & {68.64} & {91.91/89.27} &  {94.11} & {84.48} & {89.95} & {91.48}  
% \\%size 32
% {\small Pfeiffer adapter} & {1.18M} & {90.33/90.39} & {95.61} & {68.77} & {92.04/89.40} & {94.29} & {85.20} & {89.46} & {91.54}
% \\%size 64 sst2-96.18
% {LoRA ($ r=8 $)} & {1.33M} & {90.65/90.69} & {94.95} & {69.82} & {91.99/89.38} & {93.87} & {85.20} & {89.95} & {91.60}
% \\
% {\ouralg} & {1.27M} & {\bf 90.76/90.79} & {\bf96.10} & {\bf71.45} & {\bf92.23/89.74} & {\bf94.55} & {\bf88.09} & {\bf90.69} & {\bf91.84}
% \\
% \midrule 
% {\small Houlsby adapter} & {0.61M} & {90.12/90.23} & {95.30} & {67.87} & {91.65/88.95} &  {93.76} & {85.56} & {89.22} & {91.30}
% \\%size 16
% {\small Pfeiffer adapter} & {0.60M} & {90.15/90.28} & {95.53} & {69.48} & {91.62/88.86} &  {93.98} & {84.12} & {89.22} & {91.52}
% \\%size 32 
% {\small Houlsby adapter} & {0.31M} & {90.10/90.02} & {95.41} & {67.65} & {91.54/88.81} &  {93.52} & {83.39} & {89.25} & {91.31}
% \\%size 8
% {\small Pfeiffer adapter} & {0.30M} & {89.89/90.06} & {94.72} & {69.06} & {91.40/88.62} &  {93.87} & {84.48} & {89.71} & {91.38} 
% \\%size 16
% {LoRA ($ r=2 $)} & {0.33M} & {90.30/90.38} & {94.95} & {68.71} & {91.61/88.91} & {94.03} & {85.56} & {89.71} & {\bf91.68}
% \\
% {\ouralg} & {0.32M} & {\bf 90.66/90.70} & {\bf95.80} & {\bf70.04} & {\bf91.78/89.16} & {\bf94.49} & {\bf87.36} & {\bf90.44} & {91.63}
% \\

% \bottomrule
% \end{tabular}
% \end{small}
% \end{center}
% % \vspace{-1mm}
% \end{table}
% }





\section{Question Answering}\label{app:question_answering}


\subsection{Budget Configuration}

Given the budget, we control the trainable parameters for each method as the following table. 


\begin{table*}[h!]
\vspace{2mm}
\caption{Detailed budget setup for question answering.}
\vspace{-1mm}
\label{tab:app_squad_budget}
\begin{center}
\begin{small}
\begin{tabular}{l|cccc}
\toprule
{\# Params} & {Houlsby Adapter} & {Pfeiffer Adapter} & {LoRA} & {{\ouralg}}
\\
~ & $ d $ & $ d $ & $ r $ & $ \BuT / \rbarT / r $
\\
\midrule
{0.65\%} & {32} & 64 & 8 & 576 / 8 / 12 
\\
{0.32\%} & {16} & 32 & 4 & 288 / 4 / 6
\\
{0.16\%} & 8 & 16 & 2 & 144 / 2 / 4
\\
{0.08\%} & 4 & 8 & 1 & 72 / 1 / 2
\\
\bottomrule
\end{tabular}
\end{small}
\end{center}
%\vspace{-1mm}
\end{table*}


\subsection{Training Details} 
We set the batch size as 16. We select the learning rate from $ \{ 8\times10^{-5}, 5\times10^{-5}, 3\times10^{-5}, 1\times10^{-4}, 3\times10^{-4}, 5\times10^{-4}, 8\times10^{-4}, 1\times10^{-3} \} $ and pick the best-performing learning rate for every method. The configuration of {\ouralg} is listed in the following table. 


\begin{table*}[h!]
\vspace{1mm}
\caption{Hyper-parameter setup of {\ouralg} for question answering tasks.}
\vspace{-1mm}
\label{tab:app_squad_setup}
\begin{center}
\begin{small}
\begin{tabular}{l|ccccccc}
\toprule
{Dataset} & {learning rate} & {batch size} & {\# epochs} & {$\gamma$}  & {$t_i$} & {$\DeltaT$}  & {$t_f$}
\\
\midrule 
{\bf SQuADv1.1} & {$1\times 10^{-3}$} & 16 & 10 & 0.1 & 5000 & 100 & 25000 
\\
{\bf SQuADv2.0} & $ 1\times 10^{-3} $ & 16 & 12 & 0.1 & 5000 & 100 & 50000 
\\
\bottomrule
\end{tabular}
\end{small}
\end{center}
\vspace{2mm}
\end{table*}


\subsection{Dataset}

The statistics of question answering datasets are summarized in Table~\ref{tab:app_squad}. 

\begin{table}[h!]
    \centering
    \vspace{2mm}
    \caption{Statistics of the SQuAD dataset.}\label{tab:app_squad}
    \begin{tabular}{l|cc}
    \toprule
    & \# Train & \# Validation \\
    \midrule
    SQuAD v1.1 & 87,599 & 10,570 \\
    SQuAD v2.0 & 130,319 & 11,873 \\
    \bottomrule
    \end{tabular}
\end{table}





\section{Natural Language Generation}\label{app:NLG}  

\subsection{Budget Configuration}

Given the budget, we control the trainable parameters for each method as the following table. 


\begin{table*}[h!]
\vspace{2mm}
\caption{Detailed budget setup for summarization tasks.}
\vspace{-1mm}
\label{tab:app_sum_budget}
\begin{center}
\begin{small}
\begin{tabular}{l|cccc}
\toprule
{\# Params} & {Houlsby Adapter} & {Pfeiffer Adapter} & {LoRA} & {{\ouralg}}
\\
~ & $ d $ & $ d $ & $ r $ & $ \BuT / \rbarT / r $
\\
\midrule
{0.65\%} & {32} & 64 & 8 & 576 / 8 / 12 
\\
{0.32\%} & {16} & 32 & 4 & 288 / 4 / 6
\\
{0.16\%} & 8 & 16 & 2 & 144 / 2 / 4
\\
{0.08\%} & 4 & 8 & 1 & 72 / 1 / 2
\\
\bottomrule
\end{tabular}
\end{small}
\end{center}
%\vspace{-1mm}
\end{table*}


\subsection{Training Details} 
We set the batch size as 16. We select the learning rate from $ \{ 8\times10^{-5}, 5\times10^{-5}, 3\times10^{-5}, 1\times10^{-4}, 3\times10^{-4}, 5\times10^{-4}, 8\times10^{-4}, 1\times10^{-3} \} $ and pick the best-performing learning rate for every method. The configuration of {\ouralg} is listed in the following table. 


\begin{table*}[h!]
\vspace{2mm}
\caption{Hyper-parameter setup of {\ouralg} for summarization tasks.}
\vspace{-1mm}
\label{tab:app_sum_setup}
\begin{center}
\begin{small}
\begin{tabular}{l|ccccccc}
\toprule
{Dataset} & {learning rate} & {batch size} & {\# epochs} & {$\gamma$}  & {$t_i$} & {$\DeltaT$}  & {$t_f$}
\\
\midrule 
{\bf XSum} & {$5\times 10^{-4}$} & 64 & 25 & 0.1 & 6000 & 100 & 50000 
\\
{\bf CNN/DailyMail} & $ 5\times 10^{-4} $ & 32 & 15 & 0.1 & 5000 & 100 & 85000 
\\
\bottomrule
\end{tabular}
\end{small}
\end{center}
%\vspace{-1mm}
\end{table*}






\section{Ablation Study for LoRA}\label{app:lora_ablation}
As mentioned in Section~\ref{sec:experiments}, we find that the performance of LoRA can be further improved when applying it to every weight matrix, compared to fine-tuning $ \Wq $ and $ \Wv $ only \citep{hu2022lora}. This observation aligns with the empirical results of \citet{he2022towards}. In Table~\ref{tab:app_lora_ablation}, we follow the same training configuration as Section~\ref{sec:NLU_expriments} and present an ablation study to illustrate this point. 

\begin{table*}[h!]
\vspace{2mm}
\caption{We compare the fine-tuning performance when apply LoRA to every weight matrix or $ \Wq, \Wv $ only. The parameter budget is fixed as 0.3M. We report accuracy for QQP and MRPC, accuracy(m) for MNLI, and average correlation for STS-B.} 
\vspace{-1mm}
\label{tab:app_lora_ablation}
\begin{center}
\begin{small}
\begin{tabular}{l|cccccccc}
\toprule
~ & MNLI & QQP & CoLA & RTE & QNLI & SST-2 & MRPC & STS-B 
\\
\midrule 
{LoRA ($ \Wq, \Wk $)} & 89.80 & 90.48 & 67.04 & 83.75 & 93.69 & 94.84 & 90.20 & 91.05 
\\
{LoRA (all)} & 90.30 & 91.61 & 68.71 & 85.56 & 94.31 & 94.95 & 90.44 & 91.68 
\\
\bottomrule
\end{tabular}
\end{small}
\end{center}
%\vspace{-1mm}
\end{table*}





\section{Orthogonal Regularization}\label{app:regularization}

\begin{figure}[h!]
\vspace{1mm}
\centering
\begin{subfigure}{0.38\textwidth}
    \centering
    \includegraphics[width=1.0\textwidth]{attout_loraB.pdf}
    \vspace{-5mm}
    \caption{$\PP$ of $\Wo$ at the first layer.}
\end{subfigure}
\begin{subfigure}{0.38\textwidth}
    \centering
    \includegraphics[width=1.0\textwidth]{attout_loraA.pdf}
    \vspace{-5mm}
    \caption{$\QQ$ of $\Wo$ at the first layer.}
\end{subfigure}
\begin{subfigure}{0.38\textwidth}
    \centering
    \includegraphics[width=1.0\textwidth]{out_loraB.pdf}
    \vspace{-5mm}
    \caption{$\PP$ of $\Wfq$ at the first layer.}
\end{subfigure}
\begin{subfigure}{0.38\textwidth}
    \centering
    \includegraphics[width=1.0\textwidth]{out_loraA.pdf}
    \vspace{-5mm}
    \caption{$\QQ$ of $\Wfq$ at the first layer}
\end{subfigure}
% \vspace{-3mm}
\caption{We plot the $\norm{\PP^{\top}\PP-I }_{\sf F}^2$ and $\norm{\QQ\QQ^{\top}-I }_{\sf F}^2$ when fine-tuning DeBERTaV3-base on SST-2. 
}
\label{fig:app_regularization}
\vspace{2mm}
\end{figure}

To verify the effectiveness of (\ref{eq:regularization}), we plot $\norm{\PP^{\top}\PP-I }_{\sf F}^2$ and $\norm{\QQ\QQ^{\top}-I }_{\sf F}^2$ to show whether $\PP$ and $\QQ$ are regularized to be orthogonal. 
We fine-tune a DeBERTaV3-base model on SST-2 with {\ouralg} and follow the same training configuration as Section~\ref{sec:NLU_expriments}. We set $\gamma$ as 0.1 and plot the two terms along the training horizon. From Figure~\ref{fig:app_regularization}, we can see that two regularization terms can be optimized to a very small value (e.g., 0.001) at the beginning of training. Therefore, both $\PP$ and $\QQ$ can be enforced to be orthogonal quickly during the initial warm-up of {\ouralg}. It ensures that the triplets are not dependent with each other. 



%\section{The role of two components} 
%We remark that both two components of our method - SVD adaptation and adaptive budget allocation, play vital roles for the performance gain. To demonstrate it,  we compare {\ouralg} with the following variants:  (i) SVD-LoRA: fine-tuning only with the proposed SVD-based adaptation in (\ref{eq:svd_adaptation}) and (\ref{eq:regularization}); (ii) LoRA\textsubscript{regu}: LoRA with orthogonal regularization (\ref{eq:regularization}) on $\A$ and $\B$; (iii) {\ouralg}\textsubscript{$\gamma=0$}: {\ouralg} without orthogonal regularization (\ref{eq:regularization}). Table~\ref{tab:svd_ablation} present the results when fine-tuning DeBERTaVe-base on SST-2 and MNLI. We can see that fine-tuning only with SVD adaptation shows an improvement over LoRA but cannot match the performance of {\ouralg}. Meanwhile, without SVD orthogonal regularization, the performance of {\ouralg} can degenerate. These results validate that both components contribute to the model performance.
%\begin{table}[htb!]
%\vspace{1mm} 
%\caption{We present ablation studies about SVD-based adaptation, orthogonal regularization, and budget allocation in this table. For MNLI, we report the average score of m/mm acc.} 
%\vspace{-1mm}
%\label{tab:svd_ablation}
%\begin{center}
%\begin{tabular}{c|cccc|cccc}
%\toprule
%& \multicolumn{4}{|c}{\bf SST-2} & \multicolumn{4}{|c}{\bf MNLI} 
%\\
%\midrule 
%{\# Params}  
%& {0.08\%}  & {0.16\%} & {0.32\%} & {0.65\%} 
%& {0.08\%}  & {0.16\%} & {0.32\%} & {0.65\%} 
%\\ 
%\midrule
%{LoRA} 
%& 94.38 & 94.95 & - & 94.95 
%% & 90.20/90.17 & 90.30/90.38 & - / - & 90.65/90.69
%& 90.19 & 90.34 & - & 90.57 
%\\
%{LoRA\textsubscript{regu}} 
%& - & 94.61 & 94.72 & 94.61
%% - / -  90.24/90.35  90.35/90.44  90.63/90.70
%& - & 90.30 & 90.40 & 90.66 
%\\
%{SVD-LoRA}
%& 95.33 & 95.18 & 95.07 & 95.53
%% 90.18/90.38 90.14/90.37 90.44/90.60 90.60/90.64
%& 90.28 & 90.25 & 90.52 & 90.62 
%\\
%\midrule
%{{\ouralg}\textsubscript{$\gamma=0$}} 
%& 95.41 & 95.10 & 95.30 & 95.10
%% 90.33/90.40 90.30/90.39 90.52/90.60 90.35/90.52
%& 90.37 & 90.34 & 90.56 & 90.43 
%\\
%{{\ouralg}} 
%&95.64 & 95.80 & 96.10 & 96.10 
%% 90.64/90.65 90.66/90.70 90.66/90.65 90.76/90.79
%&90.65 & 90.68 & 90.66 & 90.77
%\\
%\bottomrule
%\end{tabular}
%\end{center}
%\end{table}

\section{Comparison of Training Cost}
We compare the training cost between {\ouralg} and LoRA in the following table. We use two methods to fine-tune DeBERTaV3-base on a single NVIDIA V100 GPU. We do training only and set hyperparameters, e.g., batch size and training epochs, the same as in Section~\ref{sec:experiments}. 

\begin{table}[htb!]
\vspace{2mm} 
\caption{Comparison of practical training cost between {\ouralg} and LoRA.} 
\vspace{-2mm}
\label{tab:training_cost}
\begin{center}
\begin{tabular}{c|c|ccc}
\toprule
{\bf Dataset} & {\bf \# Param} & {\bf Method} & {\bf GPU Mem} & {\bf Time/epoch}
\\
\midrule 
\multirow{6}*{\bf MNLI} 
& \multirow{2}*{\bf 0.08\%} & {LoRA} & 11.094 GB & 105 min 
\\
~ & ~ & {\ouralg} & 11.104 GB & 116 min 
\\
% \midrule
~ & \multirow{2}*{\bf 0.16\%} & {LoRA} & 11.098 GB & 105 min
\\
~ & ~ & {\ouralg} & 11.110 GB & 117 min  
\\
~ & \multirow{2}*{\bf 0.65\%} & {LoRA} & 11.128 GB & 105 min
\\
~ & ~ & {\ouralg} & 11.188 GB & 117 min  
\\
\midrule 
\multirow{6}*{\bf SST-2} 
& \multirow{2}*{\bf 0.08\%} & {LoRA} & 13.138 GB & 60 min 
\\
~ & ~ & {\ouralg} & 13.148 GB & 71 min 
\\
% \midrule
~ & \multirow{2}*{\bf 0.16\%} & {LoRA} & 13.142 GB & 61 min
\\
~ & ~ & {\ouralg} & 13.164 GB & 71 min 
\\
~ & \multirow{2}*{\bf 0.65\%} & {LoRA} & 13.170 GB & 61 min
\\
~ & ~ & {\ouralg} & 13.226 GB & 71 min  
\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

Table~\ref{tab:training_cost} shows that {\ouralg} incurs 11\% additional training time on MNLI and 16\% on SQuADv2 under different budgets. The memory footprint of two methods are quite close. Such results demonstrate that {\ouralg} does not incur significant training overheads. The reason behind is that we only evaluate the importance score for small incremental matrices $\PP\Lam\QQ$. Their total number of parameters is usually less than 1\% of pre-trained weights. Therefore, it does not lead to significant computational cost to update the importance scores of these well-structured small matrices, compared to forward-backward pass of full model.
