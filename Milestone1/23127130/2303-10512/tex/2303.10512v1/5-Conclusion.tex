\vspace{-1mm}
\section{Conclusion}
\vspace{-2mm}
We propose a parameter-efficient fine-tuning method -- {\ouralg} that adaptively allocates the parameter budget according to importance scoring. In {\ouralg}, we parameterize the incremental updates of weight matrices in the form of singular value decomposition. Then, we dynamically allocate the parameter budget among incremental matrices by manipulating the singular values based on a new importance metric.  
Such an a   pproach effectively improves the model performance and parameter efficiency. We conduct extensive experiments on natural language processing, question answering and natural language generation tasks. Results show that {\ouralg} outperforms existing approaches. 




