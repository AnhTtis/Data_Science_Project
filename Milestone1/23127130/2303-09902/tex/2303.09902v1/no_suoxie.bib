
@inproceedings{aberdamSequencetoSequenceContrastiveLearning2021,
  title = {Sequence-to-{{Sequence Contrastive Learning}} for {{Text Recognition}}},
  booktitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Aberdam, Aviad and Litman, Ron and Tsiper, Shahar and Anschel, Oron and Slossberg, Ron and Mazor, Shai and Manmatha, R. and Perona, Pietro},
  year = {2021},
  month = jun,
  pages = {15297--15307},
  publisher = {{IEEE}},
  address = {{Nashville, TN, USA}},
  doi = {10.1109/CVPR46437.2021.01505},
  file = {D\:\\Filez\\Zetero\\storage\\ITESGCGM\\Aberdam et al_2021_Sequence-to-Sequence Contrastive Learning for Text Recognition.pdf},
  isbn = {978-1-66544-509-2},
  language = {en}
}

@article{abuduweiliAdaptiveConsistencyRegularization2021,
  title = {Adaptive {{Consistency Regularization}} for {{Semi}}-{{Supervised Transfer Learning}}},
  author = {Abuduweili, Abulikemu and Li, Xingjian and Shi, Humphrey and Xu, Cheng-Zhong and Dou, Dejing},
  year = {2021},
  month = aug,
  abstract = {While recent studies on semi-supervised learning have shown remarkable progress in leveraging both labeled and unlabeled data, most of them presume a basic setting of the model is randomly initialized. In this work, we consider semi-supervised learning and transfer learning jointly, leading to a more practical and competitive paradigm that can utilize both powerful pre-trained models from source domain as well as labeled/unlabeled data in the target domain. To better exploit the value of both pre-trained weights and unlabeled target examples, we introduce adaptive consistency regularization that consists of two complementary components: Adaptive Knowledge Consistency (AKC) on the examples between the source and target model, and Adaptive Representation Consistency (ARC) on the target model between labeled and unlabeled examples. Examples involved in the consistency regularization are adaptively selected according to their potential contributions to the target task. We conduct extensive experiments on popular benchmarks including CIFAR-10, CUB200, and MURA, by fine-tuning the ImageNet pre-trained ResNet-50 model. Results show that our proposed adaptive consistency regularization outperforms state-of-the-art semi-supervised learning techniques such as Pseudo Label, Mean Teacher, and FixMatch. Moreover, our algorithm is orthogonal to existing methods and thus able to gain additional improvements on top of MixMatch and FixMatch. Our code is available at https://github.com/SHI-Labs/SemiSupervised-Transfer-Learning.},
  archivePrefix = {arXiv},
  eprint = {2103.02193},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\Y9XSCKR9\\Abuduweili et al_2021_Adaptive Consistency Regularization for Semi-Supervised Transfer Learning.pdf},
  journal = {arXiv:2103.02193 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{anConditionalSelfSupervisedLearning2021,
  title = {Conditional {{Self}}-{{Supervised Learning}} for {{Few}}-{{Shot Classification}}},
  booktitle = {Proceedings of the {{Thirtieth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {An, Yuexuan and Xue, Hui and Zhao, Xingyu and Zhang, Lu},
  year = {2021},
  month = aug,
  pages = {2140--2146},
  publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
  address = {{Montreal, Canada}},
  doi = {10.24963/ijcai.2021/295},
  abstract = {How to learn a transferable feature representation from limited examples is a key challenge for fewshot classification. Self-supervision as an auxiliary task to the main supervised few-shot task is considered to be a conceivable way to solve the problem since self-supervision can provide additional structural information easily ignored by the main task. However, learning a good representation by traditional self-supervised methods is usually dependent on large training samples. In few-shot scenarios, due to the lack of sufficient samples, these self-supervised methods might learn a biased representation, which more likely leads to the wrong guidance for the main tasks and finally causes the performance degradation. In this paper, we propose conditional self-supervised learning (CSS) to use prior knowledge to guide the representation learning of self-supervised tasks. Specifically, CSS leverages inherent supervised information in labeled data to shape and improve the learning feature manifold of self-supervision without auxiliary unlabeled data, so as to reduce representation bias and mine more effective semantic information. Moreover, CSS exploits more meaningful information through supervised learning and the improved self-supervised learning respectively and integrates the information into a unified distribution, which can further enrich and broaden the original representation. Extensive experiments demonstrate that our proposed method without any fine-tuning can achieve a significant accuracy improvement on the few-shot classification scenarios compared to the state-of-the-art few-shot learning methods.},
  file = {D\:\\Filez\\Zetero\\storage\\5353V8YH\\An et al_2021_Conditional Self-Supervised Learning for Few-Shot Classification.pdf},
  isbn = {978-0-9992411-9-6},
  language = {en}
}

@article{aroraTheoreticalAnalysisContrastive2019,
  title = {A {{Theoretical Analysis}} of {{Contrastive Unsupervised Representation Learning}}},
  author = {Arora, Sanjeev and Khandeparkar, Hrishikesh and Khodak, Mikhail and Plevrakis, Orestis and Saunshi, Nikunj},
  year = {2019},
  month = feb,
  abstract = {Recent empirical works have successfully used unlabeled data to learn feature representations that are broadly useful in downstream classification tasks. Several of these methods are reminiscent of the well-known word2vec embedding algorithm: leveraging availability of pairs of semantically ``similar'' data points and ``negative samples,'' the learner forces the inner product of representations of similar pairs with each other to be higher on average than with negative samples. The current paper uses the term contrastive learning for such algorithms and presents a theoretical framework for analyzing them by introducing latent classes and hypothesizing that semantically similar points are sampled from the same latent class. This framework allows us to show provable guarantees on the performance of the learned representations on the average classification task that is comprised of a subset of the same set of latent classes. Our generalization bound also shows that learned representations can reduce (labeled) sample complexity on downstream tasks. We conduct controlled experiments in both the text and image domains to support the theory.},
  archivePrefix = {arXiv},
  eprint = {1902.09229},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\CMG2BIXN\\Arora et al_2019_A Theoretical Analysis of Contrastive Unsupervised Representation Learning.pdf},
  journal = {arXiv:1902.09229 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{baiUnsupervisedMultiSourceDomain2021,
  title = {Unsupervised {{Multi}}-{{Source Domain Adaptation}} for {{Person Re}}-{{Identification}}},
  author = {Bai, Zechen and Wang, Zhigang and Wang, Jian and Hu, Di and Ding, Errui},
  year = {2021},
  month = apr,
  abstract = {Unsupervised domain adaptation (UDA) methods for person re-identification (re-ID) aim at transferring re-ID knowledge from labeled source data to unlabeled target data. Although achieving great success, most of them only use limited data from a single-source domain for model pre-training, making the rich labeled data insufficiently exploited. To make full use of the valuable labeled data, we introduce the multi-source concept into UDA person re-ID field, where multiple source datasets are used during training. However, because of domain gaps, simply combining different datasets only brings limited improvement. In this paper, we try to address this problem from two perspectives, i.e. domain-specific view and domain-fusion view. Two constructive modules are proposed, and they are compatible with each other. First, a rectification domain-specific batch normalization (RDSBN) module is explored to simultaneously reduce domain-specific characteristics and increase the distinctiveness of person features. Second, a graph convolutional network (GCN) based multi-domain information fusion (MDIF) module is developed, which minimizes domain distances by fusing features of different domains. The proposed method outperforms state-of-the-art UDA person re-ID methods by a large margin, and even achieves comparable performance to the supervised approaches without any post-processing techniques.},
  archivePrefix = {arXiv},
  eprint = {2104.12961},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\WIYFKQHZ\\Bai et al_2021_Unsupervised Multi-Source Domain Adaptation for Person Re-Identification.pdf},
  journal = {arXiv:2104.12961 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  language = {en},
  primaryClass = {cs}
}

@article{bansalSelfSupervisedMetaLearningFewShot2020,
  title = {Self-{{Supervised Meta}}-{{Learning}} for {{Few}}-{{Shot Natural Language Classification Tasks}}},
  author = {Bansal, Trapit and Jha, Rishikesh and Munkhdalai, Tsendsuren and McCallum, Andrew},
  year = {2020},
  month = nov,
  abstract = {Self-supervised pre-training of transformer models has revolutionized NLP applications. Such pre-training with language modeling objectives provides a useful initial point for parameters that generalize well to new tasks with fine-tuning. However, fine-tuning is still data inefficient \textemdash{} when there are few labeled examples, accuracy can be low. Data efficiency can be improved by optimizing pre-training directly for future fine-tuning with few examples; this can be treated as a meta-learning problem. However, standard meta-learning techniques require many training tasks in order to generalize; unfortunately, finding a diverse set of such supervised tasks is usually difficult. This paper proposes a self-supervised approach to generate a large, rich, metalearning task distribution from unlabeled text. This is achieved using a cloze-style objective, but creating separate multi-class classification tasks by gathering tokens-to-be blanked from among only a handful of vocabulary terms. This yields as many unique meta-training tasks as the number of subsets of vocabulary terms. We meta-train a transformer model on this distribution of tasks using a recent meta-learning framework. On 17 NLP tasks, we show that this meta-training leads to better few-shot generalization than language-model pre-training followed by finetuning. Furthermore, we show how the self-supervised tasks can be combined with supervised tasks for meta-learning, providing substantial accuracy gains over previous supervised meta-learning.},
  archivePrefix = {arXiv},
  eprint = {2009.08445},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\MZ8HVHPC\\Bansal et al_2020_Self-Supervised Meta-Learning for Few-Shot Natural Language Classification Tasks.pdf},
  journal = {arXiv:2009.08445 [cs]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{bharadhwajMetaLearningUserColdStart2019,
  title = {Meta-{{Learning}} for {{User Cold}}-{{Start Recommendation}}},
  booktitle = {2019 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Bharadhwaj, Homanga},
  year = {2019},
  month = jul,
  pages = {1--8},
  issn = {2161-4407},
  doi = {10.1109/IJCNN.2019.8852100},
  abstract = {Recent studies in recommender systems emphasize the importance of dealing with the cold-start problem i.e. the modeling of new users or items in the recommendation system. Meta-learning approaches have gained popularity recently in the Machine Learning (ML) community for learning representations useful for a wide-range of tasks. Inspired by the generalizable modeling prowess of Model-Agnostic Meta Learning, we design a recommendation framework that is trained to be reasonably good enough for a wide range of users. During testing, to adapt to a specific user, the model parameters are updated by a few gradient steps. We evaluate our approach on three different benchmark datasets, from Movielens, Netflix, and MyFitnessPal. Through detailed simulation studies, we show that this framework handles the user cold-start model much better than state-of-the art benchmark recommender systems. We also show that the proposed approach performs well on the task of general recommendations to non cold-start users and effectively takes care of routine and eclectic preference trends of users.},
  file = {D\:\\Filez\\Zetero\\storage\\3K7UYSDI\\Bharadhwaj_2019_Meta-Learning for User Cold-Start Recommendation.pdf;D\:\\Filez\\Zetero\\storage\\QGA5FRPX\\8852100.html},
  keywords = {Adaptation models,cold-start problem,Computational modeling,deep neural network,Machine learning,meta-learning,Neural networks,recommender systems,Recommender systems,Task analysis,Training}
}

@inproceedings{bianContrastiveCurriculumLearning2021,
  title = {Contrastive {{Curriculum Learning}} for {{Sequential User Behavior Modeling}} via {{Data Augmentation}}},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Bian, Shuqing and Zhao, Wayne Xin and Zhou, Kun and Cai, Jing and He, Yancheng and Yin, Cunxiang and Wen, Ji-Rong},
  year = {2021},
  month = oct,
  pages = {3737--3746},
  publisher = {{ACM}},
  address = {{Virtual Event Queensland Australia}},
  doi = {10.1145/3459637.3481905},
  abstract = {Within online platforms, it is critical to capture the semantics of sequential user behaviors for accurately modeling user interests. However, dynamic characteristics and sparse behaviors make it difficult to learn effective user representations for sequential user behavior modeling.},
  file = {D\:\\Filez\\Zetero\\storage\\2BVBZY42\\Bian et al_2021_Contrastive Curriculum Learning for Sequential User Behavior Modeling via Data.pdf;D\:\\Filez\\Zetero\\storage\\89DB9IPR\\Contrastive Curriculum Learning for Sequential User Behavior Modeling via Data Augmentatio.md},
  isbn = {978-1-4503-8446-9},
  language = {en}
}

@article{bond-taylorDeepGenerativeModelling2021,
  title = {Deep {{Generative Modelling}}: {{A Comparative Review}} of {{VAEs}}, {{GANs}}, {{Normalizing Flows}}, {{Energy}}-{{Based}} and {{Autoregressive Models}}},
  shorttitle = {Deep {{Generative Modelling}}},
  author = {{Bond-Taylor}, Sam and Leach, Adam and Long, Yang and Willcocks, Chris G.},
  year = {2021},
  month = apr,
  abstract = {Deep generative modelling is a class of techniques that train deep neural networks to model the distribution of training samples. Research has fragmented into various interconnected approaches, each of which making trade-offs including run-time, diversity, and architectural restrictions. In particular, this compendium covers energy-based models, variational autoencoders, generative adversarial networks, autoregressive models, normalizing flows, in addition to numerous hybrid approaches. These techniques are drawn under a single cohesive framework, comparing and contrasting to explain the premises behind each, while reviewing current state-of-the-art advances and implementations.},
  archivePrefix = {arXiv},
  eprint = {2103.04922},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\BSPJW7TC\\Bond-Taylor 等。 - 2021 - Deep Generative Modelling A Comparative Review of.pdf},
  journal = {arXiv:2103.04922 [cs, stat]},
  keywords = {68T01 (Primary); 68T07 (Secondary),Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,G.3,I.4.0,I.5.0,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{buMusicRecommendationUnified,
  title = {Music Recommendation by Unified Hypergraph: Combining Social Media Information and Music Content},
  author = {Bu, Jiajun and Tan, Shulong and Chen, Chun and Wang, Can and Wu, Hao and Zhang, Lijun and He, Xiaofei},
  pages = {10},
  abstract = {Acoustic-based music recommender systems have received increasing interest in recent years. Due to the semantic gap between low level acoustic features and high level music concepts, many researchers have explored collaborative filtering techniques in music recommender systems. Traditional collaborative filtering music recommendation methods only focus on user rating information. However, there are various kinds of social media information, including different types of objects and relations among these objects, in music social communities such as Last.fm and Pandora. This information is valuable for music recommendation. However, there are two challenges to exploit this rich social media information: (a) There are many different types of objects and relations in music social communities, which makes it difficult to develop a unified framework taking into account all objects and relations. (b) In these communities, some relations are much more sophisticated than pairwise relation, and thus cannot be simply modeled by a graph. In this paper, we propose a novel music recommendation algorithm by using both multiple kinds of social media information and music acoustic-based content. Instead of graph, we use hypergraph to model the various objects and relations, and consider music recommendation as a ranking problem on this hypergraph. While an edge of an ordinary graph connects only two objects, a hyperedge represents a set of objects. In this way, hypergraph can be naturally used to model highorder relations. Experiments on a data set collected from the music social community Last.fm have demonstrated the effectiveness of our proposed algorithm.},
  file = {D\:\\Filez\\Zetero\\storage\\CL7SZQLF\\Bu et al_Music recommendation by unified hypergraph.pdf},
  keywords = {Hypergraph},
  language = {en}
}

@inproceedings{carlucciDomainGeneralizationSolving2019,
  title = {Domain {{Generalization}} by {{Solving Jigsaw Puzzles}}},
  booktitle = {2019 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Carlucci, Fabio M. and D'Innocente, Antonio and Bucci, Silvia and Caputo, Barbara and Tommasi, Tatiana},
  year = {2019},
  month = jun,
  pages = {2224--2233},
  issn = {2575-7075},
  doi = {10.1109/CVPR.2019.00233},
  abstract = {Human adaptability relies crucially on the ability to learn and merge knowledge both from supervised and unsupervised learning: the parents point out few important concepts, but then the children fill in the gaps on their own. This is particularly effective, because supervised learning can never be exhaustive and thus learning autonomously allows to discover invariances and regularities that help to generalize. In this paper we propose to apply a similar approach to the task of object recognition across domains: our model learns the semantic labels in a supervised fashion, and broadens its understanding of the data by learning from self-supervised signals how to solve a jigsaw puzzle on the same images. This secondary task helps the network to learn the concepts of spatial correlation while acting as a regularizer for the classification task. Multiple experiments on the PACS, VLCS, Office-Home and digits datasets confirm our intuition and show that this simple method outperforms previous domain generalization and adaptation solutions. An ablation study further illustrates the inner workings of our approach.},
  file = {D\:\\Filez\\Zetero\\storage\\R7AH3TCH\\Carlucci et al_2019_Domain Generalization by Solving Jigsaw Puzzles.pdf;D\:\\Filez\\Zetero\\storage\\RAP6TRJX\\8953760.html},
  keywords = {Categorization,Deep Learning,Recognition: Detection,Retrieval}
}

@article{caronUnsupervisedLearningVisual,
  title = {Unsupervised {{Learning}} of {{Visual Features}} by {{Contrasting Cluster Assignments}}},
  author = {Caron, Mathilde and Goyal, Priya and Misra, Ishan and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  pages = {13},
  abstract = {Unsupervised image representations have significantly reduced the gap with supervised pretraining, notably with the recent achievements of contrastive learning methods. These contrastive methods typically work online and rely on a large number of explicit pairwise feature comparisons, which is computationally challenging. In this paper, we propose an online algorithm, SwAV, that takes advantage of contrastive methods without requiring to compute pairwise comparisons. Specifically, our method simultaneously clusters the data while enforcing consistency between cluster assignments produced for different augmentations (or ``views'') of the same image, instead of comparing features directly as in contrastive learning. Simply put, we use a ``swapped'' prediction mechanism where we predict the code of a view from the representation of another view. Our method can be trained with large and small batches and can scale to unlimited amounts of data. Compared to previous contrastive methods, our method is more memory efficient since it does not require a large memory bank or a special momentum network. In addition, we also propose a new data augmentation strategy, multi-crop, that uses a mix of views with different resolutions in place of two full-resolution views, without increasing the memory or compute requirements. We validate our findings by achieving 75.3\% top-1 accuracy on ImageNet with ResNet-50, as well as surpassing supervised pretraining on all the considered transfer tasks.},
  file = {D\:\\Filez\\Zetero\\storage\\RALBGKM5\\Caron et al_Unsupervised Learning of Visual Features by Contrasting Cluster Assignments.pdf},
  language = {en}
}

@article{caronUnsupervisedLearningVisuala,
  title = {Unsupervised {{Learning}} of {{Visual Features}} by {{Contrasting Cluster Assignments}}},
  author = {Caron, Mathilde and Goyal, Priya and Misra, Ishan and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  pages = {13},
  abstract = {Unsupervised image representations have significantly reduced the gap with supervised pretraining, notably with the recent achievements of contrastive learning methods. These contrastive methods typically work online and rely on a large number of explicit pairwise feature comparisons, which is computationally challenging. In this paper, we propose an online algorithm, SwAV, that takes advantage of contrastive methods without requiring to compute pairwise comparisons. Specifically, our method simultaneously clusters the data while enforcing consistency between cluster assignments produced for different augmentations (or ``views'') of the same image, instead of comparing features directly as in contrastive learning. Simply put, we use a ``swapped'' prediction mechanism where we predict the code of a view from the representation of another view. Our method can be trained with large and small batches and can scale to unlimited amounts of data. Compared to previous contrastive methods, our method is more memory efficient since it does not require a large memory bank or a special momentum network. In addition, we also propose a new data augmentation strategy, multi-crop, that uses a mix of views with different resolutions in place of two full-resolution views, without increasing the memory or compute requirements. We validate our findings by achieving 75.3\% top-1 accuracy on ImageNet with ResNet-50, as well as surpassing supervised pretraining on all the considered transfer tasks.},
  file = {D\:\\Filez\\Zetero\\storage\\LUYD6GV6\\Caron et al_Unsupervised Learning of Visual Features by Contrasting Cluster Assignments.pdf},
  language = {en}
}

@article{chenBiasDebiasRecommender2021,
  title = {Bias and {{Debias}} in {{Recommender System}}: {{A Survey}} and {{Future Directions}}},
  shorttitle = {Bias and {{Debias}} in {{Recommender System}}},
  author = {Chen, Jiawei and Dong, Hande and Wang, Xiang and Feng, Fuli and Wang, Meng and He, Xiangnan},
  year = {2021},
  month = dec,
  abstract = {While recent years have witnessed a rapid growth of research papers on recommender system (RS), most of the papers focus on inventing machine learning models to better fit user behavior data. However, user behavior data is observational rather than experimental. This makes various biases widely exist in the data, including but not limited to selection bias, position bias, exposure bias, and popularity bias. Blindly fitting the data without considering the inherent biases will result in many serious issues, e.g., the discrepancy between offline evaluation and online metrics, hurting user satisfaction and trust on the recommendation service, etc. To transform the large volume of research models into practical improvements, it is highly urgent to explore the impacts of the biases and perform debiasing when necessary. When reviewing the papers that consider biases in RS, we find that, to our surprise, the studies are rather fragmented and lack a systematic organization. The terminology ``bias'' is widely used in the literature, but its definition is usually vague and even inconsistent across papers. This motivates us to provide a systematic survey of existing work on RS biases. In this paper, we first summarize seven types of biases in recommendation, along with their definitions and characteristics. We then provide a taxonomy to position and organize the existing work on recommendation debiasing. Finally, we identify some open challenges and envision some future directions, with the hope of inspiring more research work on this important yet less investigated topic.},
  archivePrefix = {arXiv},
  eprint = {2010.03240},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\Y4HQWVBU\\Chen 等。 - 2021 - Bias and Debias in Recommender System A Survey an.pdf},
  journal = {arXiv:2010.03240 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{chenCLOSERLOOKFEWSHOT2019,
  title = {A {{CLOSER LOOK AT FEW}}-{{SHOT CLASSIFICATION}}},
  author = {Chen, Wei-Yu and Wang, Yu-Chiang Frank and Liu, Yen-Cheng and Kira, Zsolt and Huang, Jia-Bin},
  year = {2019},
  pages = {16},
  abstract = {Few-shot classification aims to learn a classifier to recognize unseen classes during training with limited labeled examples. While significant progress has been made, the growing complexity of network designs, meta-learning algorithms, and differences in implementation details make a fair comparison difficult. In this paper, we present 1) a consistent comparative analysis of several representative few-shot classification algorithms, with results showing that deeper backbones significantly reduce the performance differences among methods on datasets with limited domain differences, 2) a modified baseline method that surprisingly achieves competitive performance when compared with the state-of-the-art on both the miniImageNet and the CUB datasets, and 3) a new experimental setting for evaluating the cross-domain generalization ability for few-shot classification algorithms. Our results reveal that reducing intra-class variation is an important factor when the feature backbone is shallow, but not as critical when using deeper backbones. In a realistic cross-domain evaluation setting, we show that a baseline method with a standard fine-tuning practice compares favorably against other state-of-the-art few-shot learning algorithms.},
  file = {D\:\\Filez\\Zetero\\storage\\E8RMBDRQ\\Chen et al_2019_A CLOSER LOOK AT FEW-SHOT CLASSIFICATION.pdf},
  language = {en}
}

@article{chenDistancewiseGraphContrastive2020,
  title = {Distance-Wise {{Graph Contrastive Learning}}},
  author = {Chen, Deli and Lin, Yanyai and Li, Lei and Li, Xuancheng Ren Peng and Zhou, Jie and Sun, Xu},
  year = {2020},
  month = dec,
  abstract = {Contrastive learning (CL) has proven highly effective in graph-based semi-supervised learning (SSL), since it can efficiently supplement the limited task information from the annotated nodes in graph. However, existing graph CL (GCL) studies ignore the uneven distribution of task information across graph caused by the graph topology and the selection of annotated nodes. They apply CL to the whole graph evenly, which results in an incongruous combination of CL and graph learning. To address this issue, we propose to apply CL in the graph learning adaptively by taking the received task information of each node into consideration. Firstly, we introduce Group PageRank to measure the node information gain from graph and find that CL mainly works for nodes that are topologically far away from the labeled nodes. We then propose our Distance-wise Graph Contrastive Learning (DwGCL) method from two views: (1) From the global view of the task information distribution across the graph, we enhance the CL effect on nodes that are topologically far away from labeled nodes; (2) From the personal view of each node's received information, we measure the relative distance between nodes and then we adapt the sampling strategy of GCL accordingly. Extensive experiments on five benchmark graph datasets show that DwGCL can bring a clear improvement over previous GCL methods. Our analysis on eight graph neural network with various types of architecture and three different annotation settings further demonstrates the generalizability of DwGCL.},
  archivePrefix = {arXiv},
  eprint = {2012.07437},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\4MBZ6KH8\\Chen 等。 - 2020 - Distance-wise Graph Contrastive Learning.pdf},
  journal = {arXiv:2012.07437 [cs]},
  keywords = {Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{chenExploringSimpleSiamese,
  title = {Exploring {{Simple Siamese Representation Learning}}},
  author = {Chen, Xinlei and He, Kaiming},
  pages = {9},
  file = {D\:\\Filez\\Zetero\\storage\\P925FG35\\Chen_He_Exploring Simple Siamese Representation Learning.pdf},
  language = {en}
}

@article{chengLearningTransferableUser,
  title = {Learning {{Transferable User Representations}} with {{Sequential Behaviors}} via {{Contrastive Pre}}-Training},
  author = {Cheng, Mingyue and Yuan, Fajie and Liu, Qi and Xin, Xin and Chen, Enhong},
  pages = {10},
  abstract = {Learning effective user representations from sequential user-item interactions is a fundamental problem for recommender systems (RS). Recently, several unsupervised methods focusing on user representations pre-training have been explored. In general, these methods apply similar learning paradigms by first corrupting the behavior sequence, and then restoring the original input with some item-level prediction loss functions. Despite its effectiveness, we argue that there exist important gaps between such item-level optimization objective and user-level representations, and as a result, the learned user representations may only lead to sub-optimal generalization performance. In this paper, we propose a novel self-supervised pre-training framework, called CLUE, which stands for employing Contrastive Learning for modeling sequence-level User rEpresentation. The core idea of CLUE is to regard each user behavior sequence as a whole and then construct the self-supervision signals by transforming the original user behaviors by data augmentations (DA). Specifically, we employ two Siamese (weight-sharing) networks to learn the user-oriented representations, where the optimization goal is to maximize the similarity of learned representations of the same user by these two encoders. More importantly, we perform careful investigation of the impacts of view generating strategies for user behavior inputs from a more comprehensive perspective, including processing sequential behaviors by explicit DA strategies and employing dropout as implicit DA. To verify the effectiveness of CLUE, we perform extensive experiments on several user-related tasks with different scales and characteristics. Our experimental results show that the user representations learned by CLUE surpass existing item-level baselines under several evaluation protocols.},
  file = {D\:\\Filez\\Zetero\\storage\\5W2KWV7Y\\notes.md;D\:\\Filez\\Zetero\\storage\\9W28PFR8\\Cheng et al_Learning Transferable User Representations with Sequential Behaviors via.pdf},
  language = {en}
}

@article{chenModelingDynamicAttributes2021,
  title = {Modeling {{Dynamic Attributes}} for {{Next Basket Recommendation}}},
  author = {Chen, Yongjun and Li, Jia and Liu, Chenghao and Li, Chenxi and Anderle, Markus and McAuley, Julian and Xiong, Caiming},
  year = {2021},
  month = sep,
  abstract = {Traditional approaches to next item and next basket recommendation typically extract users' interests based on their past interactions and associated static contextual information (e.g. a user id or item category). However, extracted interests can be inaccurate and become obsolete. Dynamic attributes, such as user income changes, item price changes (etc.), change over time. Such dynamics can intrinsically reflect the evolution of users' interests. We argue that modeling such dynamic attributes can boost recommendation performance. However, properly integrating them into user interest models is challenging since attribute dynamics can be diverse such as time-interval aware, periodic patterns (etc.), and they represent users' behaviors from different perspectives, which can happen asynchronously with interactions. Besides dynamic attributes, items in each basket contain complex interdependencies which might be beneficial but nontrivial to effectively capture. To address these challenges, we propose a novel Attentive network to model Dynamic attributes (named AnDa). AnDa separately encodes dynamic attributes and basket item sequences. We design a periodic aware encoder to allow the model to capture various temporal patterns from dynamic attributes. To effectively learn useful item relationships, intra-basket attention module is proposed. Experimental results on three real-world datasets demonstrate that our method consistently outperforms the state-of-the-art.},
  archivePrefix = {arXiv},
  eprint = {2109.11654},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\GHUTH3XI\\Chen 等。 - 2021 - Modeling Dynamic Attributes for Next Basket Recomm.pdf},
  journal = {arXiv:2109.11654 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{chenParetoSelfSupervisedTraining,
  title = {Pareto {{Self}}-{{Supervised Training}} for {{Few}}-{{Shot Learning}}},
  author = {Chen, Zhengyu and Ge, Jixie and Zhan, Heshen and Huang, Siteng and Wang, Donglin},
  pages = {10},
  abstract = {While few-shot learning (FSL) aims for rapid generalization to new concepts with little supervision, self-supervised learning (SSL) constructs supervisory signals directly computed from unlabeled data. Exploiting the complementarity of these two manners, few-shot auxiliary learning has recently drawn much attention to deal with few labeled data. Previous works benefit from sharing inductive bias between the main task (FSL) and auxiliary tasks (SSL), where the shared parameters of tasks are optimized by minimizing a linear combination of task losses. However, it is challenging to select a proper weight to balance tasks and reduce task conflict. To handle the problem as a whole, we propose a novel approach named as Pareto self-supervised training (PSST) for FSL. PSST explicitly decomposes the few-shot auxiliary problem into multiple constrained multi-objective subproblems with different trade-off preferences, and here a preference region in which the main task achieves the best performance is identified. Then, an effective preferred Pareto exploration is proposed to find a set of optimal solutions in such a preference region. Extensive experiments on several public benchmark datasets validate the effectiveness of our approach by achieving state-of-the-art performance.},
  file = {D\:\\Filez\\Zetero\\storage\\RKMDUMWT\\Chen et al_Pareto Self-Supervised Training for Few-Shot Learning.pdf},
  keywords = {few-shot},
  language = {en}
}

@article{chenRevisitingGraphBased2020,
  title = {Revisiting {{Graph Based Collaborative Filtering}}: {{A Linear Residual Graph Convolutional Network Approach}}},
  shorttitle = {Revisiting {{Graph Based Collaborative Filtering}}},
  author = {Chen, Lei and Wu, Le and Hong, Richang and Zhang, Kun and Wang, Meng},
  year = {2020},
  month = apr,
  volume = {34},
  pages = {27--34},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v34i01.5330},
  abstract = {Graph Convolutional Networks (GCNs) are state-of-the-art graph based representation learning models by iteratively stacking multiple layers of convolution aggregation operations and non-linear activation operations. Recently, in Collaborative Filtering (CF) based Recommender Systems (RS), by treating the user-item interaction behavior as a bipartite graph, some researchers model higher-layer collaborative signals with GCNs. These GCN based recommender models show superior performance compared to traditional works. However, these models suffer from training difficulty with non-linear activations for large user-item graphs. Besides, most GCN based models could not model deeper layers due to the over smoothing effect with the graph convolution operation. In this paper, we revisit GCN based CF models from two aspects. First, we empirically show that removing non-linearities would enhance recommendation performance, which is consistent with the theories in simple graph convolutional networks. Second, we propose a residual network structure that is specifically designed for CF with useritem interaction modeling, which alleviates the over smoothing problem in graph convolution aggregation operation with sparse user-item interaction data. The proposed model is a linear model and it is easy to train, scale to large datasets, and yield better efficiency and effectiveness on two real datasets. We publish the source code at https://github.com/newlei/LRGCCF.},
  file = {D\:\\Filez\\Zetero\\storage\\IFRZXHRB\\Chen et al_2020_Revisiting Graph Based Collaborative FilteringProceedings of the AAAI Conference on Artificial Intelligence.pdf},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  language = {en},
  number = {01}
}

@article{chuangDebiasedContrastiveLearning2020,
  title = {Debiased {{Contrastive Learning}}},
  author = {Chuang, Ching-Yao and Robinson, Joshua and {Yen-Chen}, Lin and Torralba, Antonio and Jegelka, Stefanie},
  year = {2020},
  month = oct,
  abstract = {A prominent technique for self-supervised representation learning has been to contrast semantically similar and dissimilar pairs of samples. Without access to labels, dissimilar (negative) points are typically taken to be randomly sampled datapoints, implicitly accepting that these points may, in reality, actually have the same label. Perhaps unsurprisingly, we observe that sampling negative examples from truly different labels improves performance, in a synthetic setting where labels are available. Motivated by this observation, we develop a debiased contrastive objective that corrects for the sampling of same-label datapoints, even without knowledge of the true labels. Empirically, the proposed objective consistently outperforms the state-of-the-art for representation learning in vision, language, and reinforcement learning benchmarks. Theoretically, we establish generalization bounds for the downstream classification task.},
  archivePrefix = {arXiv},
  eprint = {2007.00224},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\AY7FLZVN\\Chuang et al_2020_Debiased Contrastive Learning.pdf},
  journal = {arXiv:2007.00224 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{chuangDebiasedContrastiveLearning2020a,
  title = {Debiased {{Contrastive Learning}}},
  author = {Chuang, Ching-Yao and Robinson, Joshua and {Yen-Chen}, Lin and Torralba, Antonio and Jegelka, Stefanie},
  year = {2020},
  month = oct,
  abstract = {A prominent technique for self-supervised representation learning has been to contrast semantically similar and dissimilar pairs of samples. Without access to labels, dissimilar (negative) points are typically taken to be randomly sampled datapoints, implicitly accepting that these points may, in reality, actually have the same label. Perhaps unsurprisingly, we observe that sampling negative examples from truly different labels improves performance, in a synthetic setting where labels are available. Motivated by this observation, we develop a debiased contrastive objective that corrects for the sampling of same-label datapoints, even without knowledge of the true labels. Empirically, the proposed objective consistently outperforms the state-of-the-art for representation learning in vision, language, and reinforcement learning benchmarks. Theoretically, we establish generalization bounds for the downstream classification task.},
  archivePrefix = {arXiv},
  eprint = {2007.00224},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\MHFMFSJM\\Chuang et al_2020_Debiased Contrastive Learning.pdf},
  journal = {arXiv:2007.00224 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{chuangDebiasedContrastiveLearning2020b,
  title = {Debiased {{Contrastive Learning}}},
  author = {Chuang, Ching-Yao and Robinson, Joshua and {Yen-Chen}, Lin and Torralba, Antonio and Jegelka, Stefanie},
  year = {2020},
  month = oct,
  abstract = {A prominent technique for self-supervised representation learning has been to contrast semantically similar and dissimilar pairs of samples. Without access to labels, dissimilar (negative) points are typically taken to be randomly sampled datapoints, implicitly accepting that these points may, in reality, actually have the same label. Perhaps unsurprisingly, we observe that sampling negative examples from truly different labels improves performance, in a synthetic setting where labels are available. Motivated by this observation, we develop a debiased contrastive objective that corrects for the sampling of same-label datapoints, even without knowledge of the true labels. Empirically, the proposed objective consistently outperforms the state-of-the-art for representation learning in vision, language, and reinforcement learning benchmarks. Theoretically, we establish generalization bounds for the downstream classification task.},
  archivePrefix = {arXiv},
  eprint = {2007.00224},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\S7NQIWJ8\\Chuang 等。 - 2020 - Debiased Contrastive Learning.pdf},
  journal = {arXiv:2007.00224 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{ContrastiveLearningRecommender2017,
  title = {Contrastive {{Learning}} for {{Recommender System}}},
  year = {2017},
  pages = {10},
  abstract = {Recommender systems, which analyze users' preference patterns to suggest potential targets, are indispensable in today's society. Collaborative Filtering (CF) is the most popular recommendation model. Specifically, Graph Neural Network (GNN) has become a new state-of-the-art for CF. In the GNN-based recommender system, message dropout is usually used to alleviate the selection bias in the user-item bipartite graph. However, message dropout might deteriorate the recommender system's performance due to the randomness of dropping out the outgoing messages based on the user-item bipartite graph. To solve this problem, we propose a graph contrastive learning module for a general recommender system that learns the embeddings in a self-supervised manner and reduces the randomness of message dropout. Besides, many recommender systems optimize models with pairwise ranking objectives, such as the Bayesian Pairwise Ranking (BPR) based on a negative sampling strategy. However, BPR has the following problems: suboptimal sampling and sample bias. We introduce a new debiased contrastive loss to solve these problems, which provides sufficient negative samples and applies a bias correction probability to alleviate the sample bias. We integrate the proposed framework, including graph contrastive module and debiased contrastive module with several Matrix Factorization(MF) and GNN-based recommendation models. Experimental results on three public benchmarks demonstrate the effectiveness of our framework.},
  file = {D\:\\Filez\\Zetero\\storage\\77HWRBBD\\2017_Contrastive Learning for Recommender System.pdf;D\:\\Filez\\Zetero\\storage\\RF4TJ5AJ\\notes.md},
  language = {en}
}

@article{ContrastiveLearningRepresentation,
  title = {Contrastive {{Learning}} for {{Representation Degeneration Problem}} in {{Sequential Recommendation}}},
  pages = {11},
  abstract = {Recent advancements of sequential deep learning models such as Transformer and BERT have significantly facilitated the sequential recommendation. However, according to our study, the distribution of item embeddings generated by these models tends to degenerate into an anisotropic shape, which may result in high semantic similarities among embeddings. In this paper, both empirical and theoretical investigations of this representation degeneration problem are first provided, based on which a novel recommender model DuoRec is proposed to improve the item embeddings distribution. Specifically, in light of the uniformity property of contrastive learning, a contrastive regularization is designed for DuoRec to reshape the distribution of sequence representations. Given the convention that the recommendation task is performed by measuring the similarity between sequence representations and item embeddings in the same space via dot product, the regularization can be implicitly applied to the item embedding distribution. Existing contrastive learning methods mainly rely on data level augmentation for useritem interaction sequences through item cropping, masking, or reordering and can hardly provide semantically consistent augmentation samples. In DuoRec, a model-level augmentation is proposed based on Dropout to enable better semantic preserving. Furthermore, a novel sampling strategy is developed, where sequences having the same target item are chosen hard positive samples. Extensive experiments conducted on five datasets demonstrate the superior performance of the proposed DuoRec model compared with baseline methods. Visualization results of the learned representations validate that DuoRec can largely alleviate the representation degeneration problem.},
  file = {D\:\\Filez\\Zetero\\storage\\WTQRLEZF\\Contrastive Learning for Representation Degeneration Problem in Sequential.pdf},
  language = {en}
}

@misc{ContrastiveRepresentationLearning,
  title = {Contrastive {{Representation Learning}}},
  file = {D\:\\Filez\\Zetero\\storage\\VAPRWUGZ\\contrastive-representation-learning.html},
  howpublished = {https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html}
}

@article{cuiParametricContrastiveLearning,
  title = {Parametric {{Contrastive Learning}}},
  author = {Cui, Jiequan and Zhong, Zhisheng and Liu, Shu and Yu, Bei and Jia, Jiaya},
  pages = {10},
  abstract = {In this paper, we propose Parametric Contrastive Learning (PaCo) to tackle long-tailed recognition. Based on theoretical analysis, we observe supervised contrastive loss tends to bias on high-frequency classes and thus increases the difficulty of imbalanced learning. We introduce a set of parametric class-wise learnable centers to rebalance from an optimization perspective. Further, we analyze our PaCo loss under a balanced setting. Our analysis demonstrates that PaCo can adaptively enhance the intensity of pushing samples of the same class close as more samples are pulled together with their corresponding centers and benefit hard example learning. Experiments on long-tailed CIFAR, ImageNet, Places, and iNaturalist 2018 manifest the new state-of-the-art for longtailed recognition. On full ImageNet, models trained with PaCo loss surpass supervised contrastive learning across various ResNet backbones, e.g., our ResNet-200 achieves 81.8\% top-1 accuracy. Our code is available at https://github.com/dvlab-research/ Parametric-Contrastive-Learning.},
  file = {D\:\\Filez\\Zetero\\storage\\KAYNMSLC\\Cui et al_Parametric Contrastive Learning.pdf},
  language = {en}
}

@article{dauphinLanguageModelingGated2017,
  title = {Language {{Modeling}} with {{Gated Convolutional Networks}}},
  author = {Dauphin, Yann N. and Fan, Angela and Auli, Michael and Grangier, David},
  year = {2017},
  month = sep,
  abstract = {The pre-dominant approach to language modeling to date is based on recurrent neural networks. Their success on this task is often linked to their ability to capture unbounded context. In this paper we develop a finite context approach through stacked convolutions, which can be more efficient since they allow parallelization over sequential tokens. We propose a novel simplified gating mechanism that outperforms Oord et al (2016) and investigate the impact of key architectural decisions. The proposed approach achieves state-of-the-art on the WikiText-103 benchmark, even though it features long-term dependencies, as well as competitive results on the Google Billion Words benchmark. Our model reduces the latency to score a sentence by an order of magnitude compared to a recurrent baseline. To our knowledge, this is the first time a non-recurrent approach is competitive with strong recurrent models on these large scale language tasks.},
  archivePrefix = {arXiv},
  eprint = {1612.08083},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\JVV8BBKJ\\Dauphin et al_2017_Language Modeling with Gated Convolutional Networks.pdf;D\:\\Filez\\Zetero\\storage\\5TC5V5AD\\1612.html},
  journal = {arXiv:1612.08083 [cs]},
  keywords = {Computer Science - Computation and Language},
  primaryClass = {cs}
}

@article{devlinBERTPretrainingDeep2019,
  title = {{{BERT}}: {{Pre}}-Training of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  month = may,
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  archivePrefix = {arXiv},
  eprint = {1810.04805},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\8H4YKT7K\\Devlin et al_2019_BERT.pdf;D\:\\Filez\\Zetero\\storage\\WVVRY3UH\\1810.html},
  journal = {arXiv:1810.04805 [cs]},
  keywords = {Computer Science - Computation and Language},
  primaryClass = {cs}
}

@inproceedings{dingSemideterministicContrastiveVariational2021,
  title = {Semi-Deterministic and {{Contrastive Variational Graph Autoencoder}} for {{Recommendation}}},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Ding, Yue and Shi, Yuxiang and Chen, Bo and Lin, Chenghua and Lu, Hongtao and Li, Jie and Tang, Ruiming and Wang, Dong},
  year = {2021},
  month = oct,
  pages = {382--391},
  publisher = {{ACM}},
  address = {{Virtual Event Queensland Australia}},
  doi = {10.1145/3459637.3482390},
  abstract = {Variational AutoEncoder (VAE) is a popular deep generative framework with a solid theoretical basis. There are many research efforts on improving VAE. Among the existing works, a recently proposed deterministic Regularized AutoEncoder (RAE) provides a new scheme for generative modeling. RAE fixes the variance of the inferred Gaussian approximate posterior distribution as a hyperparameter, and substitutes the stochastic encoder by injecting noise into the input of a deterministic decoder. However, the deterministic RAE has three limitations: 1) RAE needs to fit the variance; 2) RAE requires ex-post density estimation to ensure sample quality; 3) RAE employs an additional gradient regularization to ensure training smoothness. Thus, it raises an interesting research question: Can we maintain the flexibility of variational inference while simplifying VAE, and at the same time ensuring a smooth training process to obtain good generative performance? Based on the above motivation, in this paper, we propose a novel Semi-deterministic and Contrastive Variational Graph autoencoder (SCVG) for item recommendation. The core design of SCVG is to learn the variance of the approximate Gaussian posterior distribution in a semi-deterministic manner by aggregating inferred mean vectors from other connected nodes via graph convolution operation. We analyze the expressive power of SCVG for the Weisfeiler-Lehman graph isomorphism test, and we deduce the simplified form of the evidence lower bound of SCVG. Besides, we introduce an efficient contrastive regularization instead of gradient regularization. We empirically show that the contrastive regularization makes learned user/item latent representation more personalized and helps to smooth the training process. We conduct extensive experiments on three real-world datasets to show the superiority of our model over state-of-the-art methods for the item recommendation task. Codes are available at https://github.com/syxkason/SCVG.},
  file = {D\:\\Filez\\Zetero\\storage\\4S8LJQY8\\Ding et al_2021_Semi-deterministic and Contrastive Variational Graph Autoencoder for.pdf},
  isbn = {978-1-4503-8446-9},
  language = {en}
}

@misc{DuiCPCDuiBiYuCeBianMa,
  title = {对 {{CPC}} (对比预测编码) 的理解 - 知乎},
  howpublished = {https://zhuanlan.zhihu.com/p/317711322}
}

@article{FalseNegativeDistillation,
  title = {False {{Negative Distillation}} and {{Contrastive Learning}} for {{Personalized Outfit Recommendation}}},
  pages = {9},
  abstract = {Personalized outfit recommendation has recently been in the spotlight with the rapid growth of the online fashion industry. However, recommending outfits has two significant challenges that should be addressed. The first challenge is that outfit recommendation often requires a complex and large model that utilizes visual information, incurring huge memory and time costs. One natural way to mitigate this problem is to compress such a cumbersome model with knowledge distillation (KD) techniques that leverage knowledge from a pretrained teacher model. However, it is hard to apply existing KD approaches in recommender systems (RS) to the outfit recommendation because they require the ranking of all possible outfits while the number of outfits grows exponentially to the number of consisting clothing items. Therefore, we propose a new KD framework for outfit recommendation, called False Negative Distillation (FND), which exploits false-negative information from the teacher model while not requiring the ranking of all candidates. The second challenge is that the explosive number of outfit candidates amplifying the data sparsity problem, often leading to poor outfit representation. To tackle this issue, inspired by the recent success of contrastive learning (CL), we introduce a CL framework for outfit representation learning with two proposed data augmentation methods. Quantitative and qualitative experiments on outfit recommendation datasets demonstrate the effectiveness and soundness of our proposed methods.},
  file = {D\:\\Filez\\Zetero\\storage\\Q7UGGW4K\\False Negative Distillation and Contrastive Learning for Personalized Outfit.pdf},
  language = {en}
}

@article{gaoAdvancesChallengesConversational2021,
  title = {Advances and {{Challenges}} in {{Conversational Recommender Systems}}: {{A Survey}}},
  shorttitle = {Advances and {{Challenges}} in {{Conversational Recommender Systems}}},
  author = {Gao, Chongming and Lei, Wenqiang and He, Xiangnan and {de Rijke}, Maarten and Chua, Tat-Seng},
  year = {2021},
  volume = {2},
  pages = {100--126},
  issn = {26666510},
  doi = {10.1016/j.aiopen.2021.06.002},
  abstract = {Recommender systems exploit interaction history to estimate user preference, having been heavily used in a wide range of industry applications. However, static recommendation models are difficult to answer two important questions well due to inherent shortcomings: (a) What exactly does a user like? (b) Why does a user like an item? The shortcomings are due to the way that static models learn user preference, i.e., without explicit instructions and active feedback from users. The recent rise of conversational recommender systems (CRSs) changes this situation fundamentally. In a CRS, users and the system can dynamically communicate through natural language interactions, which provide unprecedented opportunities to explicitly obtain the exact preference of users.},
  archivePrefix = {arXiv},
  eprint = {2101.09459},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\CEH2K27P\\Gao 等。 - 2021 - Advances and Challenges in Conversational Recommen.pdf},
  journal = {AI Open},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
  language = {en}
}

@article{gaoGraphNeuralNetworks2021,
  title = {Graph {{Neural Networks}} for {{Recommender Systems}}: {{Challenges}}, {{Methods}}, and {{Directions}}},
  shorttitle = {Graph {{Neural Networks}} for {{Recommender Systems}}},
  author = {Gao, Chen and Zheng, Yu and Li, Nian and Li, Yinfeng and Qin, Yingrong and Piao, Jinghua and Quan, Yuhan and Chang, Jianxin and Jin, Depeng and He, Xiangnan and Li, Yong},
  year = {2021},
  month = sep,
  abstract = {CHEN GAO*1, YU ZHENG*1, NIAN LI1, YINFENG LI1, YINGRONG QIN1, JINGHUA PIAO1, YUHAN QUAN1, JIANXIN CHANG1, DEPENG JIN1, XIANGNAN HE2, YONG LI*1, 1Beijing National Research Center for Information Science and Technology (BNRist), Department of Electronic Engineering, Tsinghua University and 2School of Information Science and Technology, University of Science and Technology of China Recommender system is one of the most important information services on today's Internet. Recently, graph neural networks have become the new state-of-the-art approach of recommender systems. In this survey, we conduct a comprehensive review of the literature in graph neural network-based recommender systems. We first introduce the background and the history of the development of both recommender systems and graph neural networks. For recommender systems, in general, there are four aspects for categorizing existing works: stage, scenario, objective, and application. For graph neural networks, the existing methods consist of two categories, spectral models and spatial ones. We then discuss the motivation of applying graph neural networks into recommender systems, mainly consisting of the high-order connectivity, the structural property of data, and the enhanced supervision signal. We then systematically analyze the challenges in graph construction, embedding propagation/aggregation, model optimization, and computation efficiency. Afterward and primarily, we provide a comprehensive overview of a multitude of existing works of graph neural network-based recommender systems, following the taxonomy above. Finally, we raise discussions on the open problems and promising future directions of this area. We summarize the representative papers along with their codes repositories in https://github.com/tsinghua-fib-lab/GNN-Recommender-Systems.},
  archivePrefix = {arXiv},
  eprint = {2109.12843},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\75PXN87K\\Gao 等。 - 2021 - Graph Neural Networks for Recommender Systems Cha.pdf},
  journal = {arXiv:2109.12843 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{gaoRecommenderSystemsBased2020,
  title = {Recommender {{Systems Based}} on {{Generative Adversarial Networks}}: {{A Problem}}-{{Driven Perspective}}},
  shorttitle = {Recommender {{Systems Based}} on {{Generative Adversarial Networks}}},
  author = {Gao, Min and Zhang, Junwei and Yu, Junliang and Li, Jundong and Wen, Junhao and Xiong, Qingyu},
  year = {2020},
  month = sep,
  abstract = {Recommender systems (RSs) now play a very important role in the online lives of people as they serve as personalized filters for users to find relevant items from an array of options. Owing to their effectiveness, RSs have been widely employed in consumer-oriented e-commerce platforms. However, despite their empirical successes, these systems still suffer from two limitations: data noise and data sparsity. In recent years, generative adversarial networks (GANs) have garnered increased interest in many fields, owing to their strong capacity to learn complex real data distributions; their abilities to enhance RSs by tackling the challenges these systems exhibit have also been demonstrated in numerous studies. In general, two lines of research have been conducted, and their common ideas can be summarized as follows: (1) for the data noise issue, adversarial perturbations and adversarial sampling-based training often serve as a solution; (2) for the data sparsity issue, data augmentation\textendash implemented by capturing the distribution of real data under the minimax framework\textendash is the primary coping strategy. To gain a comprehensive understanding of these research efforts, we review the corresponding studies and models, organizing them from a problem-driven perspective. More specifically, we propose a taxonomy of these models, along with their detailed descriptions and advantages. Finally, we elaborate on several open issues and current trends in GAN-based RSs.},
  archivePrefix = {arXiv},
  eprint = {2003.02474},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\WGFICAZE\\Gao 等。 - 2020 - Recommender Systems Based on Generative Adversaria.pdf},
  journal = {arXiv:2003.02474 [cs]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{gaoSelfsupervisedRepresentationLearning2021,
  title = {Self-Supervised {{Representation Learning}} for {{Trip Recommendation}}},
  author = {Gao, Qiang and Wang, Wei and Zhang, Kunpeng and Yang, Xin and Miao, Congcong},
  year = {2021},
  month = sep,
  abstract = {Trip recommendation is a significant and engaging locationbased service that can help new tourists make more customized travel plans. It often attempts to suggest a sequence of points of interest (POIs) for a user who requests a personalized travel demand. Conventional methods either leverage the heuristic algorithms (e.g., dynamic programming) or statistical analysis (e.g., Markov models) to search or rank a POI sequence. These procedures may fail to capture the diversity of human needs and transitional regularities. They even provide recommendations that deviate from tourists' real travel intention when the trip data is sparse. Although recent deep recursive models (e.g., RNN) are capable of alleviating these concerns, existing solutions hardly recognize the practical reality, such as the diversity of tourist demands, uncertainties in the trip generation, and the complex visiting preference. Inspired by the advance in deep learning, we introduce a novel self-supervised representation learning framework for trip recommendation \textendash{} SelfTrip, aiming at tackling the aforementioned challenges. Specifically, we propose a two-step contrastive learning mechanism concerning the POI representation, as well as trip representation. Furthermore, we present four trip augmentation methods to capture the visiting uncertainties in trip planning. We evaluate our SelfTrip on four real-world datasets, and extensive results demonstrate the promising gain compared with several cutting-edge benchmarks, e.g., up to 4\% and 10\% improvements on Osaka regarding F1 and pair-F1.},
  archivePrefix = {arXiv},
  eprint = {2109.00968},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\DPZ5PED8\\Gao et al_2021_Self-supervised Representation Learning for Trip Recommendation.pdf},
  journal = {arXiv:2109.00968 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{gaoSimCSESimpleContrastive2021,
  title = {{{SimCSE}}: {{Simple Contrastive Learning}} of {{Sentence Embeddings}}},
  shorttitle = {{{SimCSE}}},
  author = {Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
  year = {2021},
  month = sep,
  abstract = {This paper presents SimCSE, a simple contrastive learning framework that greatly advances the state-of-the-art sentence embeddings. We first describe an unsupervised approach, which takes an input sentence and predicts itself in a contrastive objective, with only standard dropout used as noise. This simple method works surprisingly well, performing on par with previous supervised counterparts. We find that dropout acts as minimal data augmentation and removing it leads to a representation collapse. Then, we propose a supervised approach, which incorporates annotated pairs from natural language inference datasets into our contrastive learning framework, by using "entailment" pairs as positives and "contradiction" pairs as hard negatives. We evaluate SimCSE on standard semantic textual similarity (STS) tasks, and our unsupervised and supervised models using BERT base achieve an average of 76.3\% and 81.6\% Spearman's correlation respectively, a 4.2\% and 2.2\% improvement compared to previous best results. We also show -- both theoretically and empirically -- that contrastive learning objective regularizes pre-trained embeddings' anisotropic space to be more uniform, and it better aligns positive pairs when supervised signals are available.},
  archivePrefix = {arXiv},
  eprint = {2104.08821},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\TWVP85BB\\Gao et al_2021_SimCSE.pdf},
  journal = {arXiv:2104.08821 [cs]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{ghoshVariationalDeterministicAutoencoders2020,
  title = {From {{Variational}} to {{Deterministic Autoencoders}}},
  author = {Ghosh, Partha and Sajjadi, Mehdi S. M. and Vergari, Antonio and Black, Michael and Sch{\"o}lkopf, Bernhard},
  year = {2020},
  month = may,
  abstract = {Variational Autoencoders (VAEs) provide a theoretically-backed and popular framework for deep generative models. However, learning a VAE from data poses still unanswered theoretical questions and considerable practical challenges. In this work, we propose an alternative framework for generative modeling that is simpler, easier to train, and deterministic, yet has many of the advantages of VAEs. We observe that sampling a stochastic encoder in a Gaussian VAE can be interpreted as simply injecting noise into the input of a deterministic decoder. We investigate how substituting this kind of stochasticity, with other explicit and implicit regularization schemes, can lead to an equally smooth and meaningful latent space without forcing it to conform to an arbitrarily chosen prior. To retrieve a generative mechanism to sample new data, we introduce an ex-post density estimation step that can be readily applied also to existing VAEs, improving their sample quality. We show, in a rigorous empirical study, that the proposed regularized deterministic autoencoders are able to generate samples that are comparable to, or better than, those of VAEs and more powerful alternatives when applied to images as well as to structured data such as molecules. \textbackslash footnote\{An implementation is available at: \textbackslash url\{https://github.com/ParthaEth/Regularized\_autoencoders-RAE-\}\}},
  archivePrefix = {arXiv},
  eprint = {1903.12436},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\59GH2HJW\\Ghosh et al_2020_From Variational to Deterministic Autoencoders.pdf},
  journal = {arXiv:1903.12436 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@inproceedings{gidarisBoostingFewShotVisual2019,
  title = {Boosting {{Few}}-{{Shot Visual Learning With Self}}-{{Supervision}}},
  booktitle = {2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Gidaris, Spyros and Bursuc, Andrei and Komodakis, Nikos and Perez, Patrick Perez and Cord, Matthieu},
  year = {2019},
  month = oct,
  pages = {8058--8067},
  publisher = {{IEEE}},
  address = {{Seoul, Korea (South)}},
  doi = {10.1109/ICCV.2019.00815},
  abstract = {Few-shot learning and self-supervised learning address different facets of the same problem: how to train a model with little or no labeled data. Few-shot learning aims for optimization methods and models that can learn efficiently to recognize patterns in the low data regime. Self-supervised learning focuses instead on unlabeled data and looks into it for the supervisory signal to feed high capacity deep neural networks. In this work we exploit the complementarity of these two domains and propose an approach for improving few-shot learning through self-supervision. We use self-supervision as an auxiliary task in a few-shot learning pipeline, enabling feature extractors to learn richer and more transferable visual representations while still using few annotated samples. Through self-supervision, our approach can be naturally extended towards using diverse unlabeled data from other datasets in the few-shot setting. We report consistent improvements across an array of architectures, datasets and self-supervision techniques. We provide the implementation code at https://github.com/valeoai/BF3S.},
  file = {D\:\\Filez\\Zetero\\storage\\KRCSWA3V\\Gidaris et al_2019_Boosting Few-Shot Visual Learning With Self-Supervision.pdf},
  isbn = {978-1-72814-803-8},
  language = {en}
}

@misc{GitHubAmusiCVPR2021PaperswithCode,
  title = {{{GitHub}} - Amusi/{{CVPR2021}}-{{Papers}}-with-{{Code}}: {{CVPR}} 2021 论文和开源项目合集},
  file = {D\:\\Filez\\Zetero\\storage\\FLAD5KY5\\CVPR2021-Papers-with-Code.html},
  howpublished = {https://github.com/amusi/CVPR2021-Papers-with-Code\#Un/Self-Supervised}
}

@misc{GitHubDevsungmanAwesomeSelfSupervisedPapers,
  title = {{{GitHub}} - Dev-Sungman/{{Awesome}}-{{Self}}-{{Supervised}}-{{Papers}}: {{Paper}} Bank for {{Self}}-{{Supervised Learning}}},
  howpublished = {https://github.com/dev-sungman/Awesome-Self-Supervised-Papers}
}

@misc{GitHubJason718Awesomeselfsupervisedlearning,
  title = {{{GitHub}} - Jason718/Awesome-Self-Supervised-Learning: {{A}} Curated List of Awesome Self-Supervised Methods},
  file = {D\:\\Filez\\Zetero\\storage\\IH7TVPKC\\awesome-self-supervised-learning.html},
  howpublished = {https://github.com/jason718/awesome-self-supervised-learning}
}

@misc{GitHubWvangansbekeSelfSupervisedLearningOverview,
  title = {{{GitHub}} - Wvangansbeke/{{Self}}-{{Supervised}}-{{Learning}}-{{Overview}}: 📜 {{Self}}-{{Supervised Learning}} from {{Images}}: {{Up}}-to-Date Reading List.},
  howpublished = {https://github.com/wvangansbeke/Self-Supervised-Learning-Overview}
}

@misc{GitHubWvangansbekeSelfSupervisedLearningOverviewa,
  title = {{{GitHub}} - Wvangansbeke/{{Self}}-{{Supervised}}-{{Learning}}-{{Overview}}: 📜 {{Self}}-{{Supervised Learning}} from {{Images}}: {{Up}}-to-Date Reading List.},
  howpublished = {https://github.com/wvangansbeke/Self-Supervised-Learning-Overview}
}

@article{guoSurveyKnowledgeGraphBased2020,
  title = {A {{Survey}} on {{Knowledge Graph}}-{{Based Recommender Systems}}},
  author = {Guo, Qingyu and Zhuang, Fuzhen and Qin, Chuan and Zhu, Hengshu and Xie, Xing and Xiong, Hui and He, Qing},
  year = {2020},
  month = feb,
  abstract = {To solve the information explosion problem and enhance user experience in various online applications, recommender systems have been developed to model users preferences. Although numerous efforts have been made toward more personalized recommendations, recommender systems still suffer from several challenges, such as data sparsity and cold start. In recent years, generating recommendations with the knowledge graph as side information has attracted considerable interest. Such an approach can not only alleviate the abovementioned issues for a more accurate recommendation, but also provide explanations for recommended items. In this paper, we conduct a systematical survey of knowledge graph-based recommender systems. We collect recently published papers in this field and summarize them from two perspectives. On the one hand, we investigate the proposed algorithms by focusing on how the papers utilize the knowledge graph for accurate and explainable recommendation. On the other hand, we introduce datasets used in these works. Finally, we propose several potential research directions in this field.},
  archivePrefix = {arXiv},
  eprint = {2003.00911},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\KRMKXKMD\\Guo 等。 - 2020 - A Survey on Knowledge Graph-Based Recommender Syst.pdf},
  journal = {arXiv:2003.00911 [cs, stat]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@inproceedings{guSelfSupervisedLearningUsers2021,
  title = {Self-{{Supervised Learning}} on {{Users}}' {{Spontaneous Behaviors}} for {{Multi}}-{{Scenario Ranking}} in {{E}}-Commerce},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Gu, Yulong and Bao, Wentian and Ou, Dan and Li, Xiang and Cui, Baoliang and Ma, Biyu and Huang, Haikuan and Liu, Qingwen and Zeng, Xiaoyi},
  year = {2021},
  month = oct,
  pages = {3828--3837},
  publisher = {{ACM}},
  address = {{Virtual Event Queensland Australia}},
  doi = {10.1145/3459637.3481953},
  abstract = {Multi-scenario Learning to Rank is essential for Recommender Systems, Search Engines and Online Advertising in e-commerce portals where the ranking models are usually applied in many scenarios. However, existing works mainly focus on learning the ranking model for a single scenario, and pay less attention to learning ranking models for multiple scenarios. We identify two practical challenges in industrial multi-scenario ranking systems: (1) The Feedback Loop problem that the model is always trained on the items chosen by the ranker itself. (2) Insufficient training data for small and new scenarios. To address the above issues, we present ZEUS, a novel framework that learns a Zoo of ranking modEls for mUltiple Scenarios based on pre-training on users' spontaneous behaviors (e.g., queries which are directly searched in the search box and not recommended by the ranking system). ZEUS decomposes the training process into two stages: self-supervised learning based pre-training and fine-tuning. Firstly, ZEUS performs selfsupervised learning on users' spontaneous behaviors and generates a pre-trained model. Secondly, ZEUS fine-tunes the pre-trained model on users' implicit feedback in multiple scenarios. Extensive experiments on Alibaba's production dataset demonstrate the effectiveness of ZEUS, which significantly outperforms state-of-theart methods. ZEUS averagely achieves 6.0\%, 9.7\%, 11.7\% improvement in CTR, CVR and GMV respectively than state-of-the-art method.},
  file = {D\:\\Filez\\Zetero\\storage\\4XSG43M3\\notes.md;D\:\\Filez\\Zetero\\storage\\DYP95IHW\\Gu et al_2021_Self-Supervised Learning on Users' Spontaneous Behaviors for Multi-Scenario.pdf},
  isbn = {978-1-4503-8446-9},
  language = {en}
}

@article{gutmannNoisecontrastiveEstimationNew,
  title = {Noise-Contrastive Estimation: {{A}} New Estimation Principle for Unnormalized Statistical Models},
  author = {Gutmann, Michael and Hyvarinen, Aapo},
  pages = {8},
  abstract = {We present a new estimation principle for parameterized statistical models. The idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially generated noise, using the model log-density function in the regression nonlinearity. We show that this leads to a consistent (convergent) estimator of the parameters, and analyze the asymptotic variance. In particular, the method is shown to directly work for unnormalized models, i.e. models where the density function does not integrate to one. The normalization constant can be estimated just like any other parameter. For a tractable ICA model, we compare the method with other estimation methods that can be used to learn unnormalized models, including score matching, contrastive divergence, and maximum-likelihood where the normalization constant is estimated with importance sampling. Simulations show that noise-contrastive estimation offers the best trade-off between computational and statistical efficiency. The method is then applied to the modeling of natural images: We show that the method can successfully estimate a large-scale two-layer model and a Markov random field.},
  file = {D\:\\Filez\\Zetero\\storage\\S3D4UBW9\\Gutmann_Hyvarinen_Noise-contrastive estimation.pdf},
  language = {en}
}

@inproceedings{haoPreTrainingGraphNeural2021,
  title = {Pre-{{Training Graph Neural Networks}} for {{Cold}}-{{Start Users}} and {{Items Representation}}},
  booktitle = {Proceedings of the 14th {{ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Hao, Bowen and Zhang, Jing and Yin, Hongzhi and Li, Cuiping and Chen, Hong},
  year = {2021},
  month = mar,
  pages = {265--273},
  publisher = {{ACM}},
  address = {{Virtual Event Israel}},
  doi = {10.1145/3437963.3441738},
  abstract = {Cold-start problem is a fundamental challenge for recommendation tasks. Despite the recent advances on Graph Neural Networks (GNNs) incorporate the high-order collaborative signal to alleviate the problem, the embeddings of the cold-start users and items aren't explicitly optimized, and the cold-start neighbors are not dealt with during the graph convolution in GNNs. This paper proposes to pretrain a GNN model before applying it for recommendation. Unlike the goal of recommendation, the pre-training GNN simulates the cold-start scenarios from the users/items with sufficient interactions and takes the embedding reconstruction as the pretext task, such that it can directly improve the embedding quality and can be easily adapted to the new cold-start users/items. To further reduce the impact from the cold-start neighbors, we incorporate a selfattention-based meta aggregator to enhance the aggregation ability of each graph convolution step, and an adaptive neighbor sampler to select the effective neighbors according to the feedbacks from the pre-training GNN model. Experiments on three public recommendation datasets show the superiority of our pre-training GNN model against the original GNN models on user/item embedding inference and the recommendation task.},
  file = {D\:\\Filez\\Zetero\\storage\\UTA9J9FK\\3437963.pdf},
  isbn = {978-1-4503-8297-7},
  language = {en}
}

@article{hassaniContrastiveMultiViewRepresentation,
  title = {Contrastive {{Multi}}-{{View Representation Learning}} on {{Graphs}}},
  author = {Hassani, Kaveh and Khasahmadi, Amir Hosein},
  pages = {11},
  abstract = {We introduce a self-supervised approach for learning node and graph level representations by contrasting structural views of graphs. We show that unlike visual representation learning, increasing the number of views to more than two or contrasting multi-scale encodings do not improve performance, and the best performance is achieved by contrasting encodings from first-order neighbors and a graph diffusion. We achieve new state-ofthe-art results in self-supervised learning on 8 out of 8 node and graph classification benchmarks under the linear evaluation protocol. For example, on Cora (node) and Reddit-Binary (graph) classification benchmarks, we achieve 86.8\% and 84.5\% accuracy, which are 5.5\% and 2.4\% relative improvements over previous state-of-the-art. When compared to supervised baselines, our approach outperforms them in 4 out of 8 benchmarks.},
  file = {D\:\\Filez\\Zetero\\storage\\NCGRTH92\\Hassani 和 Khasahmadi - Contrastive Multi-View Representation Learning on .pdf},
  language = {en}
}

@article{huynhBoostingContrastiveSelfSupervised2020,
  title = {Boosting {{Contrastive Self}}-{{Supervised Learning}} with {{False Negative Cancellation}}},
  author = {Huynh, Tri and Kornblith, Simon and Walter, Matthew R. and Maire, Michael and Khademi, Maryam},
  year = {2020},
  month = nov,
  abstract = {Self-supervised representation learning has witnessed significant leaps fueled by recent progress in Contrastive learning, which seeks to learn transformations that embed positive input pairs nearby, while pushing negative pairs far apart. While positive pairs can be generated reliably (e.g., as different views of the same image), it is difficult to accurately establish negative pairs, defined as samples from different images regardless of their semantic content or visual features. A fundamental problem in contrastive learning is mitigating the effects of false negatives. Contrasting false negatives induces two critical issues in representation learning: discarding semantic information and slow convergence. In this paper, we study this problem in detail and propose novel approaches to mitigate the effects of false negatives. The proposed methods exhibit consistent and significant improvements over existing contrastive learning-based models. We achieve new state-of-the-art performance on ImageNet evaluations, achieving 5.8\% absolute improvement in top-1 accuracy over the previous state-of-the-art when finetuning with 1\% labels, as well as transferring to downstream tasks.},
  archivePrefix = {arXiv},
  eprint = {2011.11765},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\Z6WDUIL2\\Huynh et al_2020_Boosting Contrastive Self-Supervised Learning with False Negative Cancellation.pdf},
  journal = {arXiv:2011.11765 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{huynhBoostingContrastiveSelfSupervised2022,
  title = {Boosting {{Contrastive Self}}-{{Supervised Learning}} with {{False Negative Cancellation}}},
  author = {Huynh, Tri and Kornblith, Simon and Walter, Matthew R. and Maire, Michael and Khademi, Maryam},
  year = {2022},
  month = jan,
  abstract = {Self-supervised representation learning has made significant leaps fueled by progress in contrastive learning, which seeks to learn transformations that embed positive input pairs nearby, while pushing negative pairs far apart. While positive pairs can be generated reliably (e.g., as different views of the same image), it is difficult to accurately establish negative pairs, defined as samples from different images regardless of their semantic content or visual features. A fundamental problem in contrastive learning is mitigating the effects of false negatives. Contrasting false negatives induces two critical issues in representation learning: discarding semantic information and slow convergence. In this paper, we propose novel approaches to identify false negatives, as well as two strategies to mitigate their effect, i.e. false negative elimination and attraction, while systematically performing rigorous evaluations to study this problem in detail. Our method exhibits consistent improvements over existing contrastive learning-based methods. Without labels, we identify false negatives with 40\% accuracy among 1000 semantic classes on ImageNet, and achieve 5.8\% absolute improvement in top-1 accuracy over the previous state-of-the-art when finetuning with 1\% labels. Our code is available at https://github.com/google-research/fnc.},
  archivePrefix = {arXiv},
  eprint = {2011.11765},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\ACF2SUK5\\Huynh 等。 - 2022 - Boosting Contrastive Self-Supervised Learning with.pdf},
  journal = {arXiv:2011.11765 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{hwangSelfsupervisedAuxiliaryLearning2021,
  title = {Self-Supervised {{Auxiliary Learning}} for {{Graph Neural Networks}} via {{Meta}}-{{Learning}}},
  author = {Hwang, Dasol and Park, Jinyoung and Kwon, Sunyoung and Kim, Kyung-Min and Ha, Jung-Woo and Kim, Hyunwoo J.},
  year = {2021},
  month = apr,
  abstract = {In recent years, graph neural networks (GNNs) have been widely adopted in the representation learning of graph-structured data and provided state-of-the-art performance in various applications such as link prediction, node classification, and recommendation. Motivated by recent advances of self-supervision for representation learning in natural language processing and computer vision, self-supervised learning has been recently studied to leverage unlabeled graph-structured data. However, employing self-supervision tasks as auxiliary tasks to assist a primary task has been less explored in the literature on graphs. In this paper, we propose a novel self-supervised auxiliary learning framework to effectively learn graph neural networks. Moreover, this work is the first study showing that a meta-path prediction is beneficial as a self-supervised auxiliary task for heterogeneous graphs. Our method is learning to learn a primary task with various auxiliary tasks to improve generalization performance. The proposed method identifies an effective combination of auxiliary tasks and automatically balances them to improve the primary task. Our methods can be applied to any graph neural network in a plug-in manner without manual labeling or additional data. Also, it can be extended to any other auxiliary tasks. Our experiments demonstrate that the proposed method consistently improves the performance of node classification and link prediction.},
  archivePrefix = {arXiv},
  eprint = {2103.00771},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\A4TKIJU2\\Hwang et al_2021_Self-supervised Auxiliary Learning for Graph Neural Networks via Meta-Learning.pdf},
  journal = {arXiv:2103.00771 [cs]},
  keywords = {Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{hwangSelfsupervisedAuxiliaryLearning2021a,
  title = {Self-Supervised {{Auxiliary Learning}} for {{Graph Neural Networks}} via {{Meta}}-{{Learning}}},
  author = {Hwang, Dasol and Park, Jinyoung and Kwon, Sunyoung and Kim, Kyung-Min and Ha, Jung-Woo and Kim, Hyunwoo J.},
  year = {2021},
  month = apr,
  abstract = {In recent years, graph neural networks (GNNs) have been widely adopted in the representation learning of graph-structured data and provided state-of-the-art performance in various applications such as link prediction, node classification, and recommendation. Motivated by recent advances of self-supervision for representation learning in natural language processing and computer vision, self-supervised learning has been recently studied to leverage unlabeled graph-structured data. However, employing self-supervision tasks as auxiliary tasks to assist a primary task has been less explored in the literature on graphs. In this paper, we propose a novel self-supervised auxiliary learning framework to effectively learn graph neural networks. Moreover, this work is the first study showing that a meta-path prediction is beneficial as a self-supervised auxiliary task for heterogeneous graphs. Our method is learning to learn a primary task with various auxiliary tasks to improve generalization performance. The proposed method identifies an effective combination of auxiliary tasks and automatically balances them to improve the primary task. Our methods can be applied to any graph neural network in a plug-in manner without manual labeling or additional data. Also, it can be extended to any other auxiliary tasks. Our experiments demonstrate that the proposed method consistently improves the performance of node classification and link prediction.},
  archivePrefix = {arXiv},
  eprint = {2103.00771},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\WC8NX4AJ\\Hwang 等。 - 2021 - Self-supervised Auxiliary Learning for Graph Neura.pdf},
  journal = {arXiv:2103.00771 [cs]},
  keywords = {Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@misc{ICCV2021JieGuoChuLu,
  title = {{{ICCV}} 2021 结果出炉！{{最新200篇ICCV2021论文分方向汇总}}（更新中） - 知乎},
  file = {D\:\\Filez\\Zetero\\storage\\QBBUF8HB\\392575669.html},
  howpublished = {https://zhuanlan.zhihu.com/p/392575669}
}

@misc{IEEEXploreFullText,
  title = {{{IEEE Xplore Full}}-{{Text PDF}}:},
  howpublished = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=\&arnumber=9010654}
}

@misc{IeslMetanlpMetalearning,
  title = {Iesl/Metanlp: {{Meta}}-Learning for {{NLP}}},
  howpublished = {https://github.com/iesl/metanlp}
}

@article{jaiswalSurveyContrastiveSelfsupervised2021,
  title = {A {{Survey}} on {{Contrastive Self}}-Supervised {{Learning}}},
  author = {Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
  year = {2021},
  month = feb,
  abstract = {Self-supervised learning has gained popularity because of its ability to avoid the cost of annotating large-scale datasets. It is capable of adopting self-defined pseudo labels as supervision and use the learned representations for several downstream tasks. Specifically, contrastive learning has recently become a dominant component in self-supervised learning methods for computer vision, natural language processing (NLP), and other domains. It aims at embedding augmented versions of the same sample close to each other while trying to push away embeddings from different samples. This paper provides an extensive review of self-supervised methods that follow the contrastive approach. The work explains commonly used pretext tasks in a contrastive learning setup, followed by different architectures that have been proposed so far. Next, we have a performance comparison of different methods for multiple downstream tasks such as image classification, object detection, and action recognition. Finally, we conclude with the limitations of the current methods and the need for further techniques and future directions to make substantial progress.},
  archivePrefix = {arXiv},
  eprint = {2011.00362},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\K5374EHC\\Jaiswal et al_2021_A Survey on Contrastive Self-supervised Learning.pdf},
  journal = {arXiv:2011.00362 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  language = {en},
  primaryClass = {cs}
}

@article{jaiswalSurveyContrastiveSelfsupervised2021a,
  title = {A {{Survey}} on {{Contrastive Self}}-Supervised {{Learning}}},
  author = {Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
  year = {2021},
  month = feb,
  abstract = {Self-supervised learning has gained popularity because of its ability to avoid the cost of annotating large-scale datasets. It is capable of adopting self-defined pseudo labels as supervision and use the learned representations for several downstream tasks. Specifically, contrastive learning has recently become a dominant component in self-supervised learning methods for computer vision, natural language processing (NLP), and other domains. It aims at embedding augmented versions of the same sample close to each other while trying to push away embeddings from different samples. This paper provides an extensive review of self-supervised methods that follow the contrastive approach. The work explains commonly used pretext tasks in a contrastive learning setup, followed by different architectures that have been proposed so far. Next, we have a performance comparison of different methods for multiple downstream tasks such as image classification, object detection, and action recognition. Finally, we conclude with the limitations of the current methods and the need for further techniques and future directions to make substantial progress.},
  archivePrefix = {arXiv},
  eprint = {2011.00362},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\IKH5HKM3\\Jaiswal 等。 - 2021 - A Survey on Contrastive Self-supervised Learning.pdf},
  journal = {arXiv:2011.00362 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  language = {en},
  primaryClass = {cs}
}

@article{jiangDeepLearningAlgorithm2018,
  title = {A {{Deep Learning Algorithm}} of {{Neural Network}} for the {{Parameterization}} of {{Typhoon}}-{{Ocean Feedback}} in {{Typhoon Forecast Models}}},
  author = {Jiang, Guo-Qing and Xu, Jing and Wei, Jun},
  year = {2018},
  month = apr,
  volume = {45},
  pages = {3706--3716},
  issn = {0094-8276, 1944-8007},
  doi = {10.1002/2018GL077004},
  abstract = {Two algorithms based on machine learning neural networks are proposed\textemdash the shallow learning (S-L) and deep learning (D-L) algorithms\textemdash that can potentially be used in atmosphere-only typhoon forecast models to provide flow-dependent typhoon-induced sea surface temperature cooling (SSTC) for improving typhoon predictions. The major challenge of existing SSTC algorithms in forecast models is how to accurately predict SSTC induced by an upcoming typhoon, which requires information not only from historical data but more importantly also from the target typhoon itself. The S-L algorithm composes of a single layer of neurons with mixed atmospheric and oceanic factors. Such a structure is found to be unable to represent correctly the physical typhoon-ocean interaction. It tends to produce an unstable SSTC distribution, for which any perturbations may lead to changes in both SSTC pattern and strength. The D-L algorithm extends the neural network to a 4 \texttimes{} 5 neuron matrix with atmospheric and oceanic factors being separated in different layers of neurons, so that the machine learning can determine the roles of atmospheric and oceanic factors in shaping the SSTC. Therefore, it produces a stable crescent-shaped SSTC distribution, with its large-scale pattern determined mainly by atmospheric factors (e.g., winds) and small-scale features by oceanic factors (e.g., eddies). Sensitivity experiments reveal that the D-L algorithms improve maximum wind intensity errors by 60\textendash 70\% for four case study simulations, compared to their atmosphere-only model runs. Plain Language Summary Forecasting accuracy with respect to storm track and intensity are two important factors for evaluating typhoon models. While 24-h forecast errors of typhoon track have steadily improved to an order of 50 km, the prediction of typhoon intensity has remained one of the major challenges during the last decade. In this study, two algorithms based on machine-learning neural networks are proposed-the shallow learning (S-L) and deep learning (D-L) algorithms-that can potentially be used in atmosphere-only typhoon forecast models to provide flow-dependent typhoon-induced sea surface temperature cooling (SSTC) for improving typhoon predictions.},
  file = {D\:\\Filez\\Zetero\\storage\\2SUP2ZRH\\Jiang et al_2018_A Deep Learning Algorithm of Neural Network for the Parameterization of.pdf},
  journal = {Geophysical Research Letters},
  language = {en},
  number = {8}
}

@article{jiangSequentialRecommendationBidirectional2021,
  title = {Sequential {{Recommendation}} with {{Bidirectional Chronological Augmentation}} of {{Transformer}}},
  author = {Jiang, Juyong and Luo, Yingtao and Kim, Jae Boum and Zhang, Kai and Kim, Sunghun},
  year = {2021},
  month = dec,
  abstract = {Sequential recommendation can capture user chronological preferences from their historical behaviors, yet the learning of short sequences is still an open challenge. Recently, data augmentation with pseudo-prior items generated by transformers has drawn considerable attention in improving recommendation in short sequences and addressing the cold-start problem. These methods typically generate pseudo-prior items sequentially in reverse chronological order (i.e., from the future to the past) to obtain longer sequences for subsequent learning. However, the performance can still degrade for very short sequences than for longer ones. In fact, reverse sequential augmentation does not explicitly take into account the forward direction, and so the underlying temporal correlations may not be fully preserved in terms of conditional probabilities. In this paper, we propose a Bidirectional Chronological Augmentation of Transformer (BiCAT) that uses a forward learning constraint in the reverse generative process to capture contextual information more effectively. The forward constraint serves as a bridge between reverse data augmentation and forward recommendation. It can also be used as pretraining to facilitate subsequent learning. Extensive experiments on two public datasets with detailed comparisons to multiple baseline models demonstrate the effectiveness of our method, especially for very short sequences (3 or fewer items). Source code is available at https://github.com/juyongjiang/BiCAT.},
  archivePrefix = {arXiv},
  eprint = {2112.06460},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\Z2XJW3JG\\Jiang 等。 - 2021 - Sequential Recommendation with Bidirectional Chron.pdf},
  journal = {arXiv:2112.06460 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{jiaSelfSupervisedLearningFramework2021,
  title = {A {{Self}}-{{Supervised Learning Framework}} for {{Sequential Recommendation}}},
  booktitle = {2021 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Jia, Renqi and Bai, Xu and Zhou, Xiaofei and Pan, Shirui},
  year = {2021},
  month = jul,
  pages = {1--8},
  issn = {2161-4407},
  doi = {10.1109/IJCNN52387.2021.9534405},
  abstract = {Sequential recommendation that aims to predict user preference with historical user interactions becomes one of the most popular tasks in the recommendation area. The existing methods concentrated on user's sequential features among exposed items have achieved good performance. However, they only rely on single item prediction optimization to learn data representation, which ignores the association between context data and sequence data. In this paper, we propose a novel self-supervised learning based sequential recommendation network (SSLRN), which contrastively learns data correlation to promote data representation of users and items. We design two auxiliary contrastive learning tasks to regularize user and item representation based on mutual information maximization (MIM). In particular, the item contrastive learning captures sequential contrast feature with sequence-item MIM, and the user contrastive learning regularizes user latent representation with user-item MIM. We evaluate our model on five real-world datasets and the experimental results show that the proposed framework significantly and consistently outperforms state-of-the-art sequential recommendation techniques.},
  file = {D\:\\Filez\\Zetero\\storage\\A4E79RMW\\Jia et al_2021_A Self-Supervised Learning Framework for Sequential Recommendation.pdf;D\:\\Filez\\Zetero\\storage\\G5Z5HZPP\\notes.md;D\:\\Filez\\Zetero\\storage\\RDVP95XN\\9534405.html},
  keywords = {contrastive learning,Correlation,Data mining,Mutual information,Neural networks,Optimization,self-supervised learning,sequential recommendation,Task analysis}
}

@article{jingSelfsupervisedVisualFeature2019,
  title = {Self-Supervised {{Visual Feature Learning}} with {{Deep Neural Networks}}: {{A Survey}}},
  shorttitle = {Self-Supervised {{Visual Feature Learning}} with {{Deep Neural Networks}}},
  author = {Jing, Longlong and Tian, Yingli},
  year = {2019},
  month = feb,
  abstract = {Large-scale labeled data are generally required to train deep neural networks in order to obtain better performance in visual feature learning from images or videos for computer vision applications. To avoid extensive cost of collecting and annotating large-scale datasets, as a subset of unsupervised learning methods, self-supervised learning methods are proposed to learn general image and video features from large-scale unlabeled data without using any human-annotated labels. This paper provides an extensive review of deep learning-based self-supervised general visual feature learning methods from images or videos. First, the motivation, general pipeline, and terminologies of this field are described. Then the common deep neural network architectures that used for self-supervised learning are summarized. Next, the schema and evaluation metrics of self-supervised learning methods are reviewed followed by the commonly used image and video datasets and the existing self-supervised visual feature learning methods. Finally, quantitative performance comparisons of the reviewed methods on benchmark datasets are summarized and discussed for both image and video feature learning. At last, this paper is concluded and lists a set of promising future directions for self-supervised visual feature learning.},
  archivePrefix = {arXiv},
  eprint = {1902.06162},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\B9I3WQ6U\\Jing 和 Tian - 2019 - Self-supervised Visual Feature Learning with Deep .pdf},
  journal = {arXiv:1902.06162 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  language = {en},
  primaryClass = {cs}
}

@article{jovanovicRobustGraphContrastive2021,
  title = {Towards {{Robust Graph Contrastive Learning}}},
  author = {Jovanovi{\'c}, Nikola and Meng, Zhao and Faber, Lukas and Wattenhofer, Roger},
  year = {2021},
  month = feb,
  abstract = {We study the problem of adversarially robust self-supervised learning on graphs. In the contrastive learning framework, we introduce a new method that increases the adversarial robustness of the learned representations through i) adversarial transformations and ii) transformations that not only remove but also insert edges. We evaluate the learned representations in a preliminary set of experiments, obtaining promising results. We believe this work takes an important step towards incorporating robustness as a viable auxiliary task in graph contrastive learning.},
  archivePrefix = {arXiv},
  eprint = {2102.13085},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\JCVEKHYK\\Jovanović 等。 - 2021 - Towards Robust Graph Contrastive Learning.pdf},
  journal = {arXiv:2102.13085 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{kalantidisHardNegativeMixing2020,
  title = {Hard {{Negative Mixing}} for {{Contrastive Learning}}},
  author = {Kalantidis, Yannis and Sariyildiz, Mert Bulent and Pion, Noe and Weinzaepfel, Philippe and Larlus, Diane},
  year = {2020},
  month = dec,
  abstract = {Contrastive learning has become a key component of self-supervised learning approaches for computer vision. By learning to embed two augmented versions of the same image close to each other and to push the embeddings of different images apart, one can train highly transferable visual representations. As revealed by recent studies, heavy data augmentation and large sets of negatives are both crucial in learning such representations. At the same time, data mixing strategies either at the image or the feature level improve both supervised and semi-supervised learning by synthesizing novel examples, forcing networks to learn more robust features. In this paper, we argue that an important aspect of contrastive learning, i.e., the effect of hard negatives, has so far been neglected. To get more meaningful negative samples, current top contrastive self-supervised learning approaches either substantially increase the batch sizes, or keep very large memory banks; increasing the memory size, however, leads to diminishing returns in terms of performance. We therefore start by delving deeper into a top-performing framework and show evidence that harder negatives are needed to facilitate better and faster learning. Based on these observations, and motivated by the success of data mixing, we propose hard negative mixing strategies at the feature level, that can be computed on-the-fly with a minimal computational overhead. We exhaustively ablate our approach on linear classification, object detection and instance segmentation and show that employing our hard negative mixing procedure improves the quality of visual representations learned by a state-of-the-art self-supervised learning method.},
  archivePrefix = {arXiv},
  eprint = {2010.01028},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\FJUKPSTU\\Kalantidis et al_2020_Hard Negative Mixing for Contrastive Learning.pdf},
  journal = {arXiv:2010.01028 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{kangRecommendationCommunicationGame2019,
  title = {Recommendation as a {{Communication Game}}: {{Self}}-{{Supervised Bot}}-{{Play}} for {{Goal}}-Oriented {{Dialogue}}},
  shorttitle = {Recommendation as a {{Communication Game}}},
  booktitle = {Proceedings of the 2019 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} and the 9th {{International Joint Conference}} on {{Natural Language Processing}} ({{EMNLP}}-{{IJCNLP}})},
  author = {Kang, Dongyeop and Balakrishnan, Anusha and Shah, Pararth and Crook, Paul and Boureau, Y-Lan and Weston, Jason},
  year = {2019},
  pages = {1951--1961},
  publisher = {{Association for Computational Linguistics}},
  address = {{Hong Kong, China}},
  doi = {10.18653/v1/D19-1203},
  abstract = {Traditional recommendation systems produce static rather than interactive recommendations invariant to a user's specific requests, clarifications, or current mood, and can suffer from the cold-start problem if their tastes are unknown. These issues can be alleviated by treating recommendation as an interactive dialogue task instead, where an expert recommender can sequentially ask about someone's preferences, react to their requests, and recommend more appropriate items. In this work, we collect a goal-driven recommendation dialogue dataset (GoRecDial), which consists of 9,125 dialogue games and 81,260 conversation turns between pairs of human workers recommending movies to each other. The task is specifically designed as a cooperative game between two players working towards a quantifiable common goal. We leverage the dataset to develop an end-to-end dialogue system that can simultaneously converse and recommend. Models are first trained to imitate the behavior of human players without considering the task goal itself (supervised training). We then finetune our models on simulated bot-bot conversations between two paired pre-trained models (bot-play), in order to achieve the dialogue goal. Our experiments show that models finetuned with bot-play learn improved dialogue strategies, reach the dialogue goal more often when paired with a human, and are rated as more consistent by humans compared to models trained without bot-play. The dataset and code are publicly available through the ParlAI framework1.},
  file = {D\:\\Filez\\Zetero\\storage\\8AU5KCWK\\Kang et al_2019_Recommendation as a Communication Game.pdf},
  language = {en}
}

@inproceedings{kangRecommendationCommunicationGame2019a,
  title = {Recommendation as a {{Communication Game}}: {{Self}}-{{Supervised Bot}}-{{Play}} for {{Goal}}-Oriented {{Dialogue}}},
  shorttitle = {Recommendation as a {{Communication Game}}},
  booktitle = {Proceedings of the 2019 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} and the 9th {{International Joint Conference}} on {{Natural Language Processing}} ({{EMNLP}}-{{IJCNLP}})},
  author = {Kang, Dongyeop and Balakrishnan, Anusha and Shah, Pararth and Crook, Paul and Boureau, Y-Lan and Weston, Jason},
  year = {2019},
  pages = {1951--1961},
  publisher = {{Association for Computational Linguistics}},
  address = {{Hong Kong, China}},
  doi = {10.18653/v1/D19-1203},
  abstract = {Traditional recommendation systems produce static rather than interactive recommendations invariant to a user's specific requests, clarifications, or current mood, and can suffer from the cold-start problem if their tastes are unknown. These issues can be alleviated by treating recommendation as an interactive dialogue task instead, where an expert recommender can sequentially ask about someone's preferences, react to their requests, and recommend more appropriate items. In this work, we collect a goal-driven recommendation dialogue dataset (GoRecDial), which consists of 9,125 dialogue games and 81,260 conversation turns between pairs of human workers recommending movies to each other. The task is specifically designed as a cooperative game between two players working towards a quantifiable common goal. We leverage the dataset to develop an end-to-end dialogue system that can simultaneously converse and recommend. Models are first trained to imitate the behavior of human players without considering the task goal itself (supervised training). We then finetune our models on simulated bot-bot conversations between two paired pre-trained models (bot-play), in order to achieve the dialogue goal. Our experiments show that models finetuned with bot-play learn improved dialogue strategies, reach the dialogue goal more often when paired with a human, and are rated as more consistent by humans compared to models trained without bot-play. The dataset and code are publicly available through the ParlAI framework1.},
  file = {D\:\\Filez\\Zetero\\storage\\M3MIXLST\\Kang et al_2019_Recommendation as a Communication Game.pdf},
  language = {en}
}

@article{kefatoJointlyLearnableData2021,
  title = {Jointly {{Learnable Data Augmentations}} for {{Self}}-{{Supervised GNNs}}},
  author = {Kefato, Zekarias T. and Girdzijauskas, Sarunas and St{\"a}rk, Hannes},
  year = {2021},
  month = aug,
  abstract = {Self-supervised Learning (SSL) aims at learning representations of objects without relying on manual labeling. Recently, a number of SSL methods for graph representation learning have achieved performance comparable to SOTA semi-supervised GNNs. A Siamese network, which relies on data augmentation, is the popular architecture used in these methods. However, these methods rely on heuristically crafted data augmentation techniques. Furthermore, they use either contrastive terms or other tricks (e.g., asymmetry) to avoid trivial solutions that can occur in Siamese networks.},
  archivePrefix = {arXiv},
  eprint = {2108.10420},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\LKDKL7EL\\Kefato 等。 - 2021 - Jointly Learnable Data Augmentations for Self-Supe.pdf},
  journal = {arXiv:2108.10420 [cs]},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  language = {en},
  primaryClass = {cs}
}

@article{khoslaSupervisedContrastiveLearning2021,
  title = {Supervised {{Contrastive Learning}}},
  author = {Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
  year = {2021},
  month = mar,
  abstract = {Contrastive learning applied to self-supervised representation learning has seen a resurgence in recent years, leading to state of the art performance in the unsupervised training of deep image models. Modern batch contrastive approaches subsume or significantly outperform traditional contrastive losses such as triplet, max-margin and the N-pairs loss. In this work, we extend the self-supervised batch contrastive approach to the fully-supervised setting, allowing us to effectively leverage label information. Clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes. We analyze two possible versions of the supervised contrastive (SupCon) loss, identifying the best-performing formulation of the loss. On ResNet-200, we achieve top-1 accuracy of 81.4\% on the ImageNet dataset, which is 0.8\% above the best number reported for this architecture. We show consistent outperformance over cross-entropy on other datasets and two ResNet variants. The loss shows benefits for robustness to natural corruptions, and is more stable to hyperparameter settings such as optimizers and data augmentations. Our loss function is simple to implement and reference TensorFlow code is released at https://t.ly/supcon 1.},
  archivePrefix = {arXiv},
  eprint = {2004.11362},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\QPBU6JM6\\Khosla et al_2021_Supervised Contrastive Learning.pdf},
  journal = {arXiv:2004.11362 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{khoslaSupervisedContrastiveLearning2021a,
  title = {Supervised {{Contrastive Learning}}},
  author = {Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
  year = {2021},
  month = mar,
  abstract = {Contrastive learning applied to self-supervised representation learning has seen a resurgence in recent years, leading to state of the art performance in the unsupervised training of deep image models. Modern batch contrastive approaches subsume or significantly outperform traditional contrastive losses such as triplet, max-margin and the N-pairs loss. In this work, we extend the self-supervised batch contrastive approach to the fully-supervised setting, allowing us to effectively leverage label information. Clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes. We analyze two possible versions of the supervised contrastive (SupCon) loss, identifying the best-performing formulation of the loss. On ResNet-200, we achieve top-1 accuracy of 81.4\% on the ImageNet dataset, which is 0.8\% above the best number reported for this architecture. We show consistent outperformance over cross-entropy on other datasets and two ResNet variants. The loss shows benefits for robustness to natural corruptions, and is more stable to hyperparameter settings such as optimizers and data augmentations. Our loss function is simple to implement and reference TensorFlow code is released at https://t.ly/supcon 1.},
  archivePrefix = {arXiv},
  eprint = {2004.11362},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\XGZQTDWA\\Khosla 等。 - 2021 - Supervised Contrastive Learning.pdf},
  journal = {arXiv:2004.11362 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@inproceedings{kimEnhancingVAEsCollaborative2019,
  title = {Enhancing {{VAEs}} for Collaborative Filtering: Flexible Priors \& Gating Mechanisms},
  shorttitle = {Enhancing {{VAEs}} for Collaborative Filtering},
  booktitle = {Proceedings of the 13th {{ACM Conference}} on {{Recommender Systems}}},
  author = {Kim, Daeryong and Suh, Bongwon},
  year = {2019},
  month = sep,
  pages = {403--407},
  publisher = {{ACM}},
  address = {{Copenhagen Denmark}},
  doi = {10.1145/3298689.3347015},
  abstract = {Neural network based models for collaborative filtering have started to gain attention recently. One branch of research is based on using deep generative models to model user preferences where variational autoencoders were shown to produce state-of-the-art results. However, there are some potentially problematic characteristics of the current variational autoencoder for CF. The first is the too simplistic prior that VAEs incorporate for learning the latent representations of user preference. The other is the model's inability to learn deeper representations with more than one hidden layer for each network.},
  file = {D\:\\Filez\\Zetero\\storage\\3IIBNN48\\Kim 和 Suh - 2019 - Enhancing VAEs for collaborative filtering flexib.pdf},
  isbn = {978-1-4503-6243-6},
  language = {en}
}

@article{kimMetaLearningOnlineUpdate,
  title = {Meta-{{Learning}} for {{Online Update}} of {{Recommender Systems}}},
  author = {Kim, Minseok and Song, Hwanjun and Shin, Yooju and Park, Dongmin and Shin, Kijung and Lee, Jae-Gil},
  pages = {11},
  abstract = {Online recommender systems should be always aligned with users' current interest to accurately suggest items that each user would like. Since user interest usually evolves over time, the update strategy should be flexible to quickly catch users' current interest from continuously generated new user-item interactions. Existing update strategies focus either on the importance of each user-item interaction or the learning rate for each recommender parameter, but such one-directional flexibility is insufficient to adapt to varying relationships between interactions and parameters. In this paper, we propose MeLON, a meta-learning based novel online recommender update strategy that supports two-directional flexibility. It is featured with an adaptive learning rate for each parameterinteraction pair for inducing a recommender to quickly learn users' up-to-date interest. The procedure of MeLON is optimized following a meta-learning approach: it learns how a recommender learns to generate the optimal learning rates for future updates. Specifically, MeLON first enriches the meaning of each interaction based on previous interactions and identifies the role of each parameter for the interaction; and then combines these two pieces of information to generate an adaptive learning rate. Theoretical analysis and extensive evaluation on three real-world online recommender datasets validate the effectiveness of MeLON.},
  file = {D\:\\Filez\\Zetero\\storage\\M36ZAX99\\2022melon_aaai.pdf},
  language = {en}
}

@article{kongMutualInformationMaximization2019,
  title = {A {{Mutual Information Maximization Perspective}} of {{Language Representation Learning}}},
  author = {Kong, Lingpeng and {d'Autume}, Cyprien de Masson and Ling, Wang and Yu, Lei and Dai, Zihang and Yogatama, Dani},
  year = {2019},
  month = nov,
  abstract = {We show state-of-the-art word representation learning methods maximize an objective function that is a lower bound on the mutual information between different parts of a word sequence (i.e., a sentence). Our formulation provides an alternative perspective that unifies classical word embedding models (e.g., Skip-gram) and modern contextual embeddings (e.g., BERT, XLNet). In addition to enhancing our theoretical understanding of these methods, our derivation leads to a principled framework that can be used to construct new self-supervised tasks. We provide an example by drawing inspirations from related methods based on mutual information maximization that have been successful in computer vision, and introduce a simple self-supervised objective that maximizes the mutual information between a global sentence representation and n-grams in the sentence. Our analysis offers a holistic view of representation learning methods to transfer knowledge and translate progress across multiple domains (e.g., natural language processing, computer vision, audio processing).},
  archivePrefix = {arXiv},
  eprint = {1910.08350},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\QNMTR9DI\\Kong et al_2019_A Mutual Information Maximization Perspective of Language Representation.pdf},
  journal = {arXiv:1910.08350 [cs]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{koseFairnessAwareNodeRepresentation2021,
  title = {Fairness-{{Aware Node Representation Learning}}},
  author = {K{\"o}se, {\"O}yk{\"u} Deniz and Shen, Yanning},
  year = {2021},
  month = jun,
  abstract = {Node representation learning has demonstrated its effectiveness for various applications on graphs. Particularly, recent developments in contrastive learning have led to promising results in unsupervised node representation learning for a number of tasks. Despite the success of graph contrastive learning and consequent growing interest, fairness is largely under-explored in the field. To this end, this study addresses fairness issues in graph contrastive learning with fairness-aware graph augmentation designs, through adaptive feature masking and edge deletion. In the study, different fairness notions on graphs are introduced, which serve as guidelines for the proposed graph augmentations. Furthermore, theoretical analysis is provided to quantitatively prove that the proposed feature masking approach can reduce intrinsic bias. Experimental results on real social networks are presented to demonstrate that the proposed augmentations can enhance fairness in terms of statistical parity and equal opportunity, while providing comparable classification accuracy to state-of-the-art contrastive methods for node classification.},
  archivePrefix = {arXiv},
  eprint = {2106.05391},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\7LVCYG5N\\Köse 和 Shen - 2021 - Fairness-Aware Node Representation Learning.pdf},
  journal = {arXiv:2106.05391 [cs]},
  keywords = {Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{leeAugmentedVariationalAutoencoders2017,
  title = {Augmented {{Variational Autoencoders}} for {{Collaborative Filtering}} with {{Auxiliary Information}}},
  booktitle = {Proceedings of the 2017 {{ACM}} on {{Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Lee, Wonsung and Song, Kyungwoo and Moon, Il-Chul},
  year = {2017},
  month = nov,
  pages = {1139--1148},
  publisher = {{ACM}},
  address = {{Singapore Singapore}},
  doi = {10.1145/3132847.3132972},
  abstract = {Recommender systems o er critical services in the age of mass information. A good recommender system selects a certain item for a speci c user by recognizing why the user might like the item. is awareness implies that the system should model the background of the items and the users. is background modeling for recommendation is tackled through the various models of collaborative ltering with auxiliary information. is paper presents variational approaches for collaborative ltering to deal with auxiliary information. e proposed methods encompass variational autoencoders through augmenting structures to model the auxiliary information and to model the implicit user feedback. is augmentation includes the ladder network and the generative adversarial network to extract the low-dimensional representations in uenced by the auxiliary information. ese two augmentations are the rst trial in the venue of the variational autoencoders, and we demonstrate their signi cant improvement on the performances in the applications of the collaborative ltering.},
  file = {D\:\\Filez\\Zetero\\storage\\GIWLC3PL\\Lee 等。 - 2017 - Augmented Variational Autoencoders for Collaborati.pdf},
  isbn = {978-1-4503-4918-5},
  language = {en}
}

@inproceedings{leeAugmentedVariationalAutoencoders2017a,
  title = {Augmented {{Variational Autoencoders}} for {{Collaborative Filtering}} with {{Auxiliary Information}}},
  booktitle = {Proceedings of the 2017 {{ACM}} on {{Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Lee, Wonsung and Song, Kyungwoo and Moon, Il-Chul},
  year = {2017},
  month = nov,
  pages = {1139--1148},
  publisher = {{ACM}},
  address = {{Singapore Singapore}},
  doi = {10.1145/3132847.3132972},
  abstract = {Recommender systems o er critical services in the age of mass information. A good recommender system selects a certain item for a speci c user by recognizing why the user might like the item. is awareness implies that the system should model the background of the items and the users. is background modeling for recommendation is tackled through the various models of collaborative ltering with auxiliary information. is paper presents variational approaches for collaborative ltering to deal with auxiliary information. e proposed methods encompass variational autoencoders through augmenting structures to model the auxiliary information and to model the implicit user feedback. is augmentation includes the ladder network and the generative adversarial network to extract the low-dimensional representations in uenced by the auxiliary information. ese two augmentations are the rst trial in the venue of the variational autoencoders, and we demonstrate their signi cant improvement on the performances in the applications of the collaborative ltering.},
  file = {D\:\\Filez\\Zetero\\storage\\JQ2ENJGJ\\Lee 等。 - 2017 - Augmented Variational Autoencoders for Collaborati.pdf},
  isbn = {978-1-4503-4918-5},
  language = {en}
}

@article{leeSelfsupervisedLabelAugmentation,
  title = {Self-Supervised {{Label Augmentation}} via {{Input Transformations}}},
  author = {Lee, Hankook and Hwang, Sung Ju and Shin, Jinwoo},
  pages = {11},
  abstract = {Self-supervised learning, which learns by constructing artificial labels given only the input signals, has recently gained considerable attention for learning representations with unlabeled datasets, i.e., learning without any humanannotated supervision. In this paper, we show that such a technique can be used to significantly improve the model accuracy even under fullylabeled datasets. Our scheme trains the model to learn both original and self-supervised tasks, but is different from conventional multi-task learning frameworks that optimize the summation of their corresponding losses. Our main idea is to learn a single unified task with respect to the joint distribution of the original and self-supervised labels, i.e., we augment original labels via selfsupervision of input transformation. This simple, yet effective approach allows to train models easier by relaxing a certain invariant constraint during learning the original and self-supervised tasks simultaneously. It also enables an aggregated inference which combines the predictions from different augmentations to improve the prediction accuracy. Furthermore, we propose a novel knowledge transfer technique, which we refer to as self-distillation, that has the effect of the aggregated inference in a single (faster) inference. We demonstrate the large accuracy improvement and wide applicability of our framework on various fully-supervised settings, e.g., the few-shot and imbalanced classification scenarios.},
  file = {D\:\\Filez\\Zetero\\storage\\4WKIDWQI\\Lee et al_Self-supervised Label Augmentation via Input Transformations.pdf},
  language = {en}
}

@inproceedings{liangVariationalAutoencodersCollaborative2018,
  title = {Variational {{Autoencoders}} for {{Collaborative Filtering}}},
  booktitle = {Proceedings of the 2018 {{World Wide Web Conference}} on {{World Wide Web}} - {{WWW}} '18},
  author = {Liang, Dawen and Krishnan, Rahul G. and Hoffman, Matthew D. and Jebara, Tony},
  year = {2018},
  pages = {689--698},
  publisher = {{ACM Press}},
  address = {{Lyon, France}},
  doi = {10.1145/3178876.3186150},
  abstract = {We extend variational autoencoders (vaes) to collaborative filtering for implicit feedback. This non-linear probabilistic model enables us to go beyond the limited modeling capacity of linear factor models which still largely dominate collaborative filtering research. We introduce a generative model with multinomial likelihood and use Bayesian inference for parameter estimation. Despite widespread use in language modeling and economics, the multinomial likelihood receives less attention in the recommender systems literature. We introduce a different regularization parameter for the learning objective, which proves to be crucial for achieving competitive performance. Remarkably, there is an efficient way to tune the parameter using annealing. The resulting model and learning algorithm has information-theoretic connections to maximum entropy discrimination and the information bottleneck principle. Empirically, we show that the proposed approach significantly outperforms several state-of-the-art baselines, including two recently-proposed neural network approaches, on several real-world datasets. We also provide extended experiments comparing the multinomial likelihood with other commonly used likelihood functions in the latent factor collaborative filtering literature and show favorable results. Finally, we identify the pros and cons of employing a principled Bayesian inference approach and characterize settings where it provides the most significant improvements.},
  file = {D\:\\Filez\\Zetero\\storage\\GURUY25P\\Liang et al_2018_Variational Autoencoders for Collaborative Filtering.pdf},
  isbn = {978-1-4503-5639-8},
  language = {en}
}

@inproceedings{liaoEfficientCollaborativeFiltering2021,
  title = {Efficient {{Collaborative Filtering}} via {{Data Augmentation}} and {{Step}}-Size {{Optimization}}},
  booktitle = {Proceedings of the 27th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Liao, Xuejun and Koch, Patrick and Huang, Shunping and Xu, Yan},
  year = {2021},
  month = aug,
  pages = {1006--1016},
  publisher = {{ACM}},
  address = {{Virtual Event Singapore}},
  doi = {10.1145/3447548.3467380},
  abstract = {As a popular approach to collaborative filtering, matrix factorization (MF) models the underlying rating matrix as a product of two factor matrices, one for users and one for items. The MF model can be learned by Alternating Least Squares (ALS), which updates the two factor matrices alternately, keeping one fixed while updating the other. Although ALS improves the learning objective aggressively in each iteration, it suffers from high computational cost due to the necessity of inverting a separate matrix for every user and item. The softImpute-ALS reduces the per-iteration computation significantly using a strategy that requires only two matrix inversions; however, the computation saving leads to shrinkage of objective improvement. In this paper, we introduce a new algorithm, termed Data Augmentation with Optimal Step-size (DAOS), which alleviates the drawback of softImpute-ALS while still maintaining its low cost of computation per iteration. The DAOS is presented in the context that factor matrices may include fixed columns or rows, with this allowing bias terms and/or linear models to be incorporated into the ML model. Experimental results on synthetic and MovieLens 1M Dataset demonstrate the benefits of DAOS over ALS and softImpute-ALS in terms of generalization performance and computational time.},
  file = {D\:\\Filez\\Zetero\\storage\\ZLCHRB2S\\Liao 等。 - 2021 - Efficient Collaborative Filtering via Data Augment.pdf},
  isbn = {978-1-4503-8332-5},
  language = {en}
}

@inproceedings{liCollaborativeVariationalAutoencoder2017,
  title = {Collaborative {{Variational Autoencoder}} for {{Recommender Systems}}},
  booktitle = {Proceedings of the 23rd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Li, Xiaopeng and She, James},
  year = {2017},
  month = aug,
  pages = {305--314},
  publisher = {{ACM}},
  address = {{Halifax NS Canada}},
  doi = {10.1145/3097983.3098077},
  abstract = {Modern recommender systems usually employ collaborative ltering with rating information to recommend items to users due to its successful performance. However, because of the drawbacks of collaborative-based methods such as sparsity, cold start, etc., more a ention has been drawn to hybrid methods that consider both the rating and content information. Most of the previous works in this area cannot learn a good representation from content for recommendation task or consider only text modality of the content, thus their methods are very limited in current multimedia scenario. is paper proposes a Bayesian generative model called collaborative variational autoencoder (CVAE) that considers both rating and content for recommendation in multimedia scenario. e model learns deep latent representations from content data in an unsupervised manner and also learns implicit relationships between items and users from both content and rating. Unlike previous works with denoising criteria, the proposed CVAE learns a latent distribution for content in latent space instead of observation space through an inference network and can be easily extended to other multimedia modalities other than text. Experiments show that CVAE is able to signi cantly outperform the state-of-the-art recommendation methods with more robust performance.},
  file = {D\:\\Filez\\Zetero\\storage\\XDJKLJ6G\\Li_She_2017_Collaborative Variational Autoencoder for Recommender Systems.pdf},
  isbn = {978-1-4503-4887-4},
  language = {en}
}

@inproceedings{liDeepCollaborativeFiltering2015,
  title = {Deep {{Collaborative Filtering}} via {{Marginalized Denoising Auto}}-Encoder},
  booktitle = {Proceedings of the 24th {{ACM International}} on {{Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Li, Sheng and Kawale, Jaya and Fu, Yun},
  year = {2015},
  month = oct,
  pages = {811--820},
  publisher = {{ACM}},
  address = {{Melbourne Australia}},
  doi = {10.1145/2806416.2806527},
  abstract = {Collaborative filtering (CF) has been widely employed within recommender systems to solve many real-world problems. Learning effective latent factors plays the most important role in collaborative filtering. Traditional CF methods based upon matrix factorization techniques learn the latent factors from the user-item ratings and suffer from the cold start problem as well as the sparsity problem. Some improved CF methods enrich the priors on the latent factors by incorporating side information as regularization. However, the learned latent factors may not be very effective due to the sparse nature of the ratings and the side information. To tackle this problem, we learn effective latent representations via deep learning. Deep learning models have emerged as very appealing in learning effective representations in many applications. In particular, we propose a general deep architecture for CF by integrating matrix factorization with deep feature learning. We provide a natural instantiations of our architecture by combining probabilistic matrix factorization with marginalized denoising stacked auto-encoders. The combined framework leads to a parsimonious fit over the latent features as indicated by its improved performance in comparison to prior state-of-art models over four large datasets for the tasks of movie/book recommendation and response prediction.},
  file = {D\:\\Filez\\Zetero\\storage\\6AKLQMGS\\Li 等。 - 2015 - Deep Collaborative Filtering via Marginalized Deno.pdf},
  isbn = {978-1-4503-3794-6},
  language = {en}
}

@inproceedings{liDeepConversationalRecommendations2018,
  title = {Towards {{Deep Conversational Recommendations}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Li, Raymond and Ebrahimi Kahou, Samira and Schulz, Hannes and Michalski, Vincent and Charlin, Laurent and Pal, Chris},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  file = {D\:\\Filez\\Zetero\\storage\\CRVDE38S\\Li et al_2018_Towards Deep Conversational Recommendations.pdf}
}

@inproceedings{liDeepConversationalRecommendations2018a,
  title = {Towards {{Deep Conversational Recommendations}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Li, Raymond and Ebrahimi Kahou, Samira and Schulz, Hannes and Michalski, Vincent and Charlin, Laurent and Pal, Chris},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  file = {D\:\\Filez\\Zetero\\storage\\9V3LCWPT\\Li et al_2018_Towards Deep Conversational Recommendations.pdf}
}

@inproceedings{liLightweightSelfAttentiveSequential2021,
  title = {Lightweight {{Self}}-{{Attentive Sequential Recommendation}}},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Li, Yang and Chen, Tong and Zhang, Peng-Fei and Yin, Hongzhi},
  year = {2021},
  month = oct,
  pages = {967--977},
  publisher = {{ACM}},
  address = {{Virtual Event Queensland Australia}},
  doi = {10.1145/3459637.3482448},
  abstract = {Modern deep neural networks (DNNs) have greatly facilitated the development of sequential recommender systems by achieving state-of-the-art recommendation performance on various sequential recommendation tasks. Given a sequence of interacted items, existing DNN-based sequential recommenders commonly embed each item into a unique vector to support subsequent computations of the user interest. However, due to the potentially large number of items, the over-parameterised item embedding matrix of a sequential recommender has become a memory bottleneck for efficient deployment in resource-constrained environments, e.g., smartphones and other edge devices. Furthermore, we observe that the widely-used multi-head self-attention, though being effective in modelling sequential dependencies among items, heavily relies on redundant attention units to fully capture both global and local item-item transition patterns within a sequence.},
  file = {D\:\\Filez\\Zetero\\storage\\GEVB7PHZ\\Li et al_2021_Lightweight Self-Attentive Sequential Recommendation.pdf},
  isbn = {978-1-4503-8446-9},
  language = {en}
}

@article{liNeuralCollaborativeAutoencoder2018,
  title = {Neural {{Collaborative Autoencoder}}},
  author = {Li, Qibing and Zheng, Xiaolin and Wu, Xinyue},
  year = {2018},
  month = dec,
  abstract = {In recent years, deep neural networks have yielded state-of-the-art performance on several tasks. Although some recent works have focused on combining deep learning with recommendation, we highlight three issues of existing models. First, these models cannot work on both explicit and implicit feedback, since the network structures are specially designed for one particular case. Second, due to the difficulty on training deep neural networks, existing explicit models do not fully exploit the expressive potential of deep learning. Third, neural network models are easier to overfit on the implicit setting than shallow models. To tackle these issues, we present a generic recommender framework called Neural Collaborative Autoencoder (NCAE) to perform collaborative filtering, which works well for both explicit feedback and implicit feedback. NCAE can effectively capture the subtle hidden relationships between interactions via a non-linear matrix factorization process. To optimize the deep architecture of NCAE, we develop a three-stage pre-training mechanism that combines supervised and unsupervised feature learning. Moreover, to prevent overfitting on the implicit setting, we propose an error reweighting module and a sparsity-aware data-augmentation strategy. Extensive experiments on three real-world datasets demonstrate that NCAE can significantly advance the state-of-the-art.},
  archivePrefix = {arXiv},
  eprint = {1712.09043},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\P7HFLSKK\\Li 等。 - 2018 - Neural Collaborative Autoencoder.pdf},
  journal = {arXiv:1712.09043 [cs, stat]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{liuAugmentingSequentialRecommendation2021,
  title = {Augmenting {{Sequential Recommendation}} with {{Pseudo}}-{{Prior Items}} via {{Reversely Pre}}-Training {{Transformer}}},
  author = {Liu, Zhiwei and Fan, Ziwei and Wang, Yu and Yu, Philip S.},
  year = {2021},
  month = jul,
  pages = {1608--1612},
  doi = {10.1145/3404835.3463036},
  abstract = {Sequential Recommendation characterizes the evolving patterns by modeling item sequences chronologically. The essential target of it is to capture the item transition correlations. The recent developments of transformer inspire the community to design effective sequence encoders, e.g., SASRec and BERT4Rec. However, we observe that these transformer-based models suffer from the cold-start issue, i.e., performing poorly for short sequences. Therefore, we propose to augment short sequences while still preserving original sequential correlations. We introduce a new framework for Augmenting Sequential Recommendation with Pseudo-prior items (ASReP). We firstly pre-train a transformer with sequences in a reverse direction to predict prior items. Then, we use this transformer to generate fabricated historical items at the beginning of short sequences. Finally, we fine-tune the transformer using these augmented sequences from the time order to predict the next item. Experiments on two real-world datasets verify the effectiveness of ASReP. The code is available on https://github.com/DyGRec/ASReP.},
  archivePrefix = {arXiv},
  eprint = {2105.00522},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\D55IX9F7\\Liu et al_2021_Augmenting Sequential Recommendation with Pseudo-Prior Items via Reversely.pdf},
  journal = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
  language = {en}
}

@article{liuContrastiveSelfsupervisedSequential2021,
  title = {Contrastive {{Self}}-Supervised {{Sequential Recommendation}} with {{Robust Augmentation}}},
  author = {Liu, Zhiwei and Chen, Yongjun and Li, Jia and Yu, Philip S. and McAuley, Julian and Xiong, Caiming},
  year = {2021},
  month = aug,
  abstract = {Sequential Recommendationdescribes a set of techniques to model dynamic user behavior in order to predict future interactions in sequential user data. At their core, such approaches model transition probabilities between items in a sequence, whether through Markov chains, recurrent networks, or more recently, Transformers. However both old and new issues remain, including data-sparsity and noisy data; such issues can impair the performance, especially in complex, parameter-hungry models. In this paper, we investigate the application of contrastive Self-Supervised Learning (SSL) to the sequential recommendation, as a way to alleviate some of these issues. Contrastive SSL constructs augmentations from unlabelled instances, where agreements among positive pairs are maximized. It is challenging to devise a contrastive SSL framework for a sequential recommendation, due to its discrete nature, correlations among items, and skewness of length distributions. To this end, we propose a novel framework, Contrastive Self-supervised Learning for sequential Recommendation (CoSeRec). We introduce two informative augmentation operators leveraging item correlations to create high-quality views for contrastive learning. Experimental results on three real-world datasets demonstrate the effectiveness of the proposed method on improving model performance and the robustness against sparse and noisy data. Our implementation is available online at \textbackslash url\{https://github.com/YChen1993/CoSeRec\}},
  archivePrefix = {arXiv},
  eprint = {2108.06479},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\GWGDTHQA\\notes.md;D\:\\Filez\\Zetero\\storage\\U589LZ9N\\Liu et al_2021_Contrastive Self-supervised Sequential Recommendation with Robust Augmentation.pdf},
  journal = {arXiv:2108.06479 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{liuDeepGlobalLocal2020,
  title = {Deep {{Global}} and {{Local Generative Model}} for {{Recommendation}}},
  booktitle = {Proceedings of {{The Web Conference}} 2020},
  author = {Liu, Huafeng and Jing, Liping and Wen, Jingxuan and Wu, Zhicheng and Sun, Xiaoyi and Wang, Jiaqi and Xiao, Lin and Yu, Jian},
  year = {2020},
  month = apr,
  pages = {551--561},
  publisher = {{ACM}},
  address = {{Taipei Taiwan}},
  doi = {10.1145/3366423.3380138},
  abstract = {Deep generative model, especially variational auto-encoder (VAE), has been successfully employed by more and more recommendation systems. The reason is that it combines the flexibility of probabilistic generative model with the powerful non-linear feature representation ability of deep neural networks. The existing VAEbased recommendation models are usually proposed under global assumption by incorporating simple priors, e.g., a single Gaussian, to regularize the latent variables. This strategy, however, is ineffective when the user is simultaneously interested in different kinds of items, i.e., the user's preference may be highly diverse. In this paper, thus, we propose a Deep Global and Local Generative Model for recommendation to consider both local and global structure among users (DGLGM) under the Wasserstein auto-encoder framework. Besides keeping the global structure like the existing model, DGLGM adopts a non-parametric Mixture Gaussian distribution with several components to capture the diversity of the users' preferences. Each component is corresponding to one local structure and its optimal size can be determined via the automatic relevance determination technique. These two parts can be seamlessly integrated and enhance each other. The proposed DGLGM can be efficiently inferred by minimizing its penalized upper bound with the aid of local variational optimization technique. Meanwhile, we theoretically analyze its generalization error bounds to guarantee its performance in sparse feedback data with diversity. By comparing with the state-of-the-art methods, the experimental results demonstrate that DGLGM consistently benefits the recommendation system in top-N recommendation task.},
  file = {D\:\\Filez\\Zetero\\storage\\ZQC4NEVM\\Liu 等。 - 2020 - Deep Global and Local Generative Model for Recomme.pdf},
  isbn = {978-1-4503-7023-3},
  language = {en}
}

@incollection{liuDiscoveringProperNeighbors2021,
  title = {Discovering {{Proper Neighbors}} to {{Improve Session}}-{{Based Recommendation}}},
  booktitle = {Machine {{Learning}} and {{Knowledge Discovery}} in {{Databases}}. {{Research Track}}},
  author = {Liu, Lin and Wang, Li and Lian, Tao},
  editor = {Oliver, Nuria and {P{\'e}rez-Cruz}, Fernando and Kramer, Stefan and Read, Jesse and Lozano, Jose A.},
  year = {2021},
  volume = {12975},
  pages = {353--369},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-86486-6_22},
  abstract = {Session-based recommendation shows increasing importance in E-commerce, news and multimedia applications. Its main challenge is to predict next item just using a short anonymous behavior sequence. Some works introduce other close similar sessions as complementary to help recommendation. But users' online behaviors are diverse and very similar sessions are always rare, so the information provided by such similar sessions is limited. In fact, if we observe the data at the high level of coarse granularity, we will find that they may present certain regularity of content and patterns. The selection of close neighborhood sessions at tag level can solve the problem of data sparsity and improve the quality of recommendation. Therefore, we propose a novel model CoKnow that is a collaborative knowledge-aware session-based recommendation model. In this model, we establish a tag-based neighbor selection mechanism. Specifically, CoKnow contains two modules: Current session modeling with item tag(Cu-tag) and Neighbor session modeling with item tag (Netag). In Cu-tag, we construct an item graph and a tag graph based on current session, and use graph neural networks to learn the representations of items and tags. In Ne-tag, a memory matrix is used to store the representations of neighborhood sessions with tag information, and then we integrate these representations according to their similarity with current session to get the output. Finally, the outputs of these two modules are combined to obtain the final representation of session for recommendation. Extensive experiments on real-world datasets show that our proposed model outperforms other state-of-the-art methods consistently.},
  file = {D\:\\Filez\\Zetero\\storage\\H9PCXM8K\\Liu 等。 - 2021 - Discovering Proper Neighbors to Improve Session-Ba.pdf},
  isbn = {978-3-030-86485-9 978-3-030-86486-6},
  language = {en}
}

@article{liuGraphSelfSupervisedLearning2021,
  title = {Graph {{Self}}-{{Supervised Learning}}: {{A Survey}}},
  shorttitle = {Graph {{Self}}-{{Supervised Learning}}},
  author = {Liu, Yixin and Pan, Shirui and Jin, Ming and Zhou, Chuan and Xia, Feng and Yu, Philip S.},
  year = {2021},
  month = aug,
  abstract = {Deep learning on graphs has attracted significant interests recently. However, most of the works have focused on (semi-) supervised learning, resulting in shortcomings including heavy label reliance, poor generalization, and weak robustness. To address these issues, self-supervised learning (SSL), which extracts informative knowledge through well-designed pretext tasks without relying on manual labels, has become a promising and trending learning paradigm for graph data. Different from SSL on other domains like computer vision and natural language processing, SSL on graphs has an exclusive background, design ideas, and taxonomies. Under the umbrella of graph self-supervised learning, we present a timely and comprehensive review of the existing approaches which employ SSL techniques for graph data. We construct a unified framework that mathematically formalizes the paradigm of graph SSL. According to the objectives of pretext tasks, we divide these approaches into four categories: generation-based, auxiliary property-based, contrast-based, and hybrid approaches. We further conclude the applications of graph SSL across various research fields and summarize the commonly used datasets, evaluation benchmark, performance comparison and open-source codes of graph SSL. Finally, we discuss the remaining challenges and potential future directions in this research field.},
  archivePrefix = {arXiv},
  eprint = {2103.00111},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\JTLJRF6E\\Liu et al_2021_Graph Self-Supervised Learning.pdf},
  journal = {arXiv:2103.00111 [cs]},
  keywords = {Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{liuSelfSupervisedGeneralisationMeta,
  title = {Self-{{Supervised Generalisation}} with {{Meta Auxiliary Learning}}},
  author = {Liu, Shikun and Davison, Andrew and Johns, Edward},
  pages = {11},
  abstract = {Learning with auxiliary tasks can improve the ability of a primary task to generalise. However, this comes at the cost of manually labelling auxiliary data. We propose a new method which automatically learns appropriate labels for an auxiliary task, such that any supervised learning task can be improved without requiring access to any further data. The approach is to train two neural networks: a label-generation network to predict the auxiliary labels, and a multi-task network to train the primary task alongside the auxiliary task. The loss for the label-generation network incorporates the loss of the multi-task network, and so this interaction between the two networks can be seen as a form of meta learning with a double gradient. We show that our proposed method, Meta AuXiliary Learning (MAXL), outperforms single-task learning on 7 image datasets, without requiring any additional data. We also show that MAXL outperforms several other baselines for generating auxiliary labels, and is even competitive when compared with human-defined auxiliary labels. The self-supervised nature of our method leads to a promising new direction towards automated generalisation. Source code can be found at https://github.com/lorenmt/maxl.},
  file = {D\:\\Filez\\Zetero\\storage\\JC45I44Z\\Liu et al_Self-Supervised Generalisation with Meta Auxiliary Learning.pdf},
  language = {en}
}

@article{liuSelfsupervisedLearningAlleviating2021,
  title = {Self-Supervised {{Learning}} for {{Alleviating Selection Bias}} in {{Recommendation Systems}}},
  author = {Liu, Haochen and Tang, Da and Yang, Ji},
  year = {2021},
  pages = {7},
  abstract = {Recommendation systems are trained on historical rating data explicitly provided by users. Since users have the freedom to select what items to rate by themselves, the collected recommendation datasets typically suffer from selection bias. As a result, recommendation models trained on such biased data perform not well on unobserved data. Traditional solutions to selection bias such as data imputation and inverse propensity score are sensitive to the quality of the additionally introduced imputation model or the propensity estimation model. In this work, we propose a novel self-supervised learning (SSL) framework Rating Distribution Calibration (RDC) to alleviate the negative impacts of selection bias on recommendation models. In addition to the original training objective, we introduce a rating distribution calibration loss which aims to correct the predicted rating distribution of a biased user by forcing them to be close to that of similar unbiased users. Extensive experiments are conducted on a real-world recommendation dataset and results show that our proposed framework outperforms the original model as well as state-of-the-art debiasing approaches by a significant margin. A detailed parameter sensitivity analysis is also included to help us understand the influence of the choices of the hyperparameters on the debiasing performance.},
  file = {D\:\\Filez\\Zetero\\storage\\8QKDLDF8\\notes.md;D\:\\Filez\\Zetero\\storage\\PRUEFBXP\\Liu et al_2021_Self-supervised Learning for Alleviating Selection Bias in Recommendation.pdf},
  language = {en}
}

@article{liuSelfsupervisedLearningAlleviating2021a,
  title = {Self-Supervised {{Learning}} for {{Alleviating Selection Bias}} in {{Recommendation Systems}}},
  author = {Liu, Haochen and Tang, Da and Yang, Ji},
  year = {2021},
  pages = {7},
  abstract = {Recommendation systems are trained on historical rating data explicitly provided by users. Since users have the freedom to select what items to rate by themselves, the collected recommendation datasets typically suffer from selection bias. As a result, recommendation models trained on such biased data perform not well on unobserved data. Traditional solutions to selection bias such as data imputation and inverse propensity score are sensitive to the quality of the additionally introduced imputation model or the propensity estimation model. In this work, we propose a novel self-supervised learning (SSL) framework Rating Distribution Calibration (RDC) to alleviate the negative impacts of selection bias on recommendation models. In addition to the original training objective, we introduce a rating distribution calibration loss which aims to correct the predicted rating distribution of a biased user by forcing them to be close to that of similar unbiased users. Extensive experiments are conducted on a real-world recommendation dataset and results show that our proposed framework outperforms the original model as well as state-of-the-art debiasing approaches by a significant margin. A detailed parameter sensitivity analysis is also included to help us understand the influence of the choices of the hyperparameters on the debiasing performance.},
  file = {D\:\\Filez\\Zetero\\storage\\URKGC88N\\Liu et al_2021_Self-supervised Learning for Alleviating Selection Bias in Recommendation.pdf},
  language = {en}
}

@article{liuSelfsupervisedLearningGenerative2021,
  title = {Self-Supervised {{Learning}}: {{Generative}} or {{Contrastive}}},
  shorttitle = {Self-Supervised {{Learning}}},
  author = {Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Wang, Zhaoyu and Mian, Li and Zhang, Jing and Tang, Jie},
  year = {2021},
  pages = {1--1},
  issn = {1041-4347, 1558-2191, 2326-3865},
  doi = {10.1109/TKDE.2021.3090866},
  abstract = {Deep supervised learning has achieved great success in the last decade. However, its defects of heavy dependence on manual labels and vulnerability to attacks have driven people to find other paradigms. As an alternative, self-supervised learning (SSL) attracts many researchers for its soaring performance on representation learning in the last several years. Self-supervised representation learning leverages input data itself as supervision and benefits almost all types of downstream tasks. In this survey, we take a look into new self-supervised learning methods for representation in computer vision, natural language processing, and graph learning. We comprehensively review the existing empirical methods and summarize them into three main categories according to their objectives: generative, contrastive, and generative-contrastive (adversarial). We further collect related theoretical analysis on self-supervised learning to provide deeper thoughts on why self-supervised learning works. Finally, we briefly discuss open problems and future directions for self-supervised learning. An outline slide for the survey is provided1.},
  archivePrefix = {arXiv},
  eprint = {2006.08218},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\HBYGNA8X\\Liu et al_2021_Self-supervised Learning.pdf;D\:\\Filez\\Zetero\\storage\\QAQECY2Q\\Liu et al_2021_Self-supervised Learning.pdf},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en}
}

@article{liuSelfsupervisedLearningGenerative2021a,
  title = {Self-Supervised {{Learning}}: {{Generative}} or {{Contrastive}}},
  shorttitle = {Self-Supervised {{Learning}}},
  author = {Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Mian, Li and Wang, Zhaoyu and Zhang, Jing and Tang, Jie},
  year = {2021},
  pages = {1--1},
  issn = {1041-4347, 1558-2191, 2326-3865},
  doi = {10.1109/TKDE.2021.3090866},
  abstract = {Deep supervised learning has achieved great success in the last decade. However, its defects of heavy dependence on manual labels and vulnerability to attacks have driven people to find other paradigms. As an alternative, self-supervised learning (SSL) attracts many researchers for its soaring performance on representation learning in the last several years. Self-supervised representation learning leverages input data itself as supervision and benefits almost all types of downstream tasks. In this survey, we take a look into new self-supervised learning methods for representation in computer vision, natural language processing, and graph learning. We comprehensively review the existing empirical methods and summarize them into three main categories according to their objectives: generative, contrastive, and generative-contrastive (adversarial). We further collect related theoretical analysis on self-supervised learning to provide deeper thoughts on why self-supervised learning works. Finally, we briefly discuss open problems and future directions for self-supervised learning. An outline slide for the survey is provided1.},
  file = {D\:\\Filez\\Zetero\\storage\\IHYNTNMS\\Liu 等。 - 2021 - Self-supervised Learning Generative or Contrastiv.pdf},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  language = {en}
}

@article{lobelAmortizedRankingCriticalTraining2020,
  title = {Towards {{Amortized Ranking}}-{{Critical Training}} for {{Collaborative Filtering}}},
  author = {Lobel, Sam and Li, Chunyuan and Gao, Jianfeng and Carin, Lawrence},
  year = {2020},
  month = feb,
  abstract = {We investigate new methods for training collaborative filtering models based on actor-critic reinforcement learning, to more directly maximize ranking-based objective functions. Specifically, we train a critic network to approximate ranking-based metrics, and then update the actor network to directly optimize against the learned metrics. In contrast to traditional learning-to-rank methods that require re-running the optimization procedure for new lists, our critic-based method amortizes the scoring process with a neural network, and can directly provide the (approximate) ranking scores for new lists. We demonstrate the actor-critic's ability to significantly improve the performance of a variety of prediction models, and achieve better or comparable performance to a variety of strong baselines on three large-scale datasets.},
  archivePrefix = {arXiv},
  eprint = {1906.04281},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\FTL3R4RG\\1906.04281.pdf},
  journal = {arXiv:1906.04281 [cs, stat]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{logeswaranEFFICIENTFRAMEWORKLEARNING,
  title = {{{AN EFFICIENT FRAMEWORK FOR LEARNING SENTENCE REPRESENTATIONS}}},
  author = {Logeswaran, Lajanugen and Lee, Honglak},
  pages = {16},
  abstract = {In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. Given a sentence and the context in which it appears, a classifier distinguishes context sentences from other contrastive sentences based on their vector representations. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. We demonstrate that our sentence representations outperform stateof-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time.},
  file = {D\:\\Filez\\Zetero\\storage\\MKZVNGEU\\Logeswaran_Lee_AN EFFICIENT FRAMEWORK FOR LEARNING SENTENCE REPRESENTATIONS.pdf},
  language = {en}
}

@inproceedings{longSocialRecommendationSelfSupervised2021,
  title = {Social {{Recommendation}} with {{Self}}-{{Supervised Metagraph Informax Network}}},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Long, Xiaoling and Huang, Chao and Xu, Yong and Xu, Huance and Dai, Peng and Xia, Lianghao and Bo, Liefeng},
  year = {2021},
  month = oct,
  pages = {1160--1169},
  publisher = {{ACM}},
  address = {{Virtual Event Queensland Australia}},
  doi = {10.1145/3459637.3482480},
  abstract = {In recent years, researchers attempt to utilize online social information to alleviate data sparsity for collaborative filtering, based on the rationale that social networks offers the insights to understand the behavioral patterns. However, due to the overlook of inter-dependent knowledge across items (e.g., categories of products), existing social recommender systems are insufficient to distill the heterogeneous collaborative signals from both user and item side. In this work, we propose Self-Supervised Metagraph Informax Network (SMIN) which investigates the potential of jointly incorporating social- and knowledge-aware relational structures into the user preference representation for recommendation. To model relation heterogeneity, we design a metapath-guided heterogeneous graph neural network to aggregate feature embeddings from different types of meta-relations across users and items, empowering SMIN to maintain dedicated representations for multifaceted user- and item-wise dependencies. Additionally, to inject high-order collaborative signals, we generalize the mutual information learning paradigm under the self-supervised graph-based collaborative filtering. This endows the expressive modeling of useritem interactive patterns, by exploring global-level collaborative relations and underlying isomorphic transformation property of graph topology. Experimental results on several real-world datasets demonstrate the effectiveness of our SMIN model over various stateof-the-art recommendation methods. We release our source code at https://github.com/SocialRecsys/SMIN.},
  file = {D\:\\Filez\\Zetero\\storage\\PJQ2CKZ9\\Long et al_2021_Social Recommendation with Self-Supervised Metagraph Informax Network.pdf},
  isbn = {978-1-4503-8446-9},
  language = {en}
}

@inproceedings{longSocialRecommendationSelfSupervised2021a,
  title = {Social {{Recommendation}} with {{Self}}-{{Supervised Metagraph Informax Network}}},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Long, Xiaoling and Huang, Chao and Xu, Yong and Xu, Huance and Dai, Peng and Xia, Lianghao and Bo, Liefeng},
  year = {2021},
  month = oct,
  pages = {1160--1169},
  publisher = {{ACM}},
  address = {{Virtual Event Queensland Australia}},
  doi = {10.1145/3459637.3482480},
  abstract = {In recent years, researchers attempt to utilize online social information to alleviate data sparsity for collaborative filtering, based on the rationale that social networks offers the insights to understand the behavioral patterns. However, due to the overlook of inter-dependent knowledge across items (e.g., categories of products), existing social recommender systems are insufficient to distill the heterogeneous collaborative signals from both user and item side. In this work, we propose Self-Supervised Metagraph Informax Network (SMIN) which investigates the potential of jointly incorporating social- and knowledge-aware relational structures into the user preference representation for recommendation. To model relation heterogeneity, we design a metapath-guided heterogeneous graph neural network to aggregate feature embeddings from different types of meta-relations across users and items, empowering SMIN to maintain dedicated representations for multifaceted user- and item-wise dependencies. Additionally, to inject high-order collaborative signals, we generalize the mutual information learning paradigm under the self-supervised graph-based collaborative filtering. This endows the expressive modeling of useritem interactive patterns, by exploring global-level collaborative relations and underlying isomorphic transformation property of graph topology. Experimental results on several real-world datasets demonstrate the effectiveness of our SMIN model over various stateof-the-art recommendation methods. We release our source code at https://github.com/SocialRecsys/SMIN.},
  file = {D\:\\Filez\\Zetero\\storage\\AFCNE78E\\Long et al_2021_Social Recommendation with Self-Supervised Metagraph Informax Network.pdf;D\:\\Filez\\Zetero\\storage\\HNVUKTV3\\notes.md},
  isbn = {978-1-4503-8446-9},
  language = {en}
}

@article{maDisentangledGraphConvolutional,
  title = {Disentangled {{Graph Convolutional Networks}}},
  author = {Ma, Jianxin and Cui, Peng and Kuang, Kun and Wang, Xin and Zhu, Wenwu},
  pages = {10},
  abstract = {The formation of a real-world graph typically arises from the highly complex interaction of many latent factors. The existing deep learning methods for graph-structured data neglect the entanglement of the latent factors, rendering the learned representations non-robust and hardly explainable. However, learning representations that disentangle the latent factors poses great challenges and remains largely unexplored in the literature of graph neural networks. In this paper, we introduce the disentangled graph convolutional network (DisenGCN) to learn disentangled node representations. In particular, we propose a novel neighborhood routing mechanism, which is capable of dynamically identifying the latent factor that may have caused the edge between a node and one of its neighbors, and accordingly assigning the neighbor to a channel that extracts and convolutes features specific to that factor. We theoretically prove the convergence properties of the routing mechanism. Empirical results show that our proposed model can achieve significant performance gains, especially when the data demonstrate the existence of many entangled factors.},
  file = {D\:\\Filez\\Zetero\\storage\\C56IYF32\\Ma et al_Disentangled Graph Convolutional Networks.pdf},
  language = {en}
}

@inproceedings{maDisentangledSelfSupervisionSequential2020,
  title = {Disentangled {{Self}}-{{Supervision}} in {{Sequential Recommenders}}},
  booktitle = {Proceedings of the 26th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Ma, Jianxin and Zhou, Chang and Yang, Hongxia and Cui, Peng and Wang, Xin and Zhu, Wenwu},
  year = {2020},
  month = aug,
  pages = {483--491},
  publisher = {{ACM}},
  address = {{Virtual Event CA USA}},
  doi = {10.1145/3394486.3403091},
  abstract = {To learn a sequential recommender, the existing methods typically adopt the sequence-to-item (seq2item) training strategy, which supervises a sequence model with a user's next behavior as the label and the user's past behaviors as the input. The seq2item strategy, however, is myopic and usually produces non-diverse recommendation lists. In this paper, we study the problem of mining extra signals for supervision by looking at the longer-term future. There exist two challenges: i) reconstructing a future sequence containing many behaviors is exponentially harder than reconstructing a single next behavior, which can lead to difficulty in convergence, and ii) the sequence of all future behaviors can involve many intentions, not all of which may be predictable from the sequence of earlier behaviors. To address these challenges, we propose a sequence-to-sequence (seq2seq) training strategy based on latent self-supervision and disentanglement. Specifically, we perform self-supervision in the latent space, i.e., reconstructing the representation of the future sequence as a whole, instead of reconstructing the items in the future sequence individually. We also disentangle the intentions behind any given sequence of behaviors and construct seq2seq training samples using only pairs of sub-sequences that involve a shared intention. Results on real-world benchmarks and synthetic data demonstrate the improvement brought by seq2seq training.},
  file = {D\:\\Filez\\Zetero\\storage\\9LG5QH57\\Ma et al_2020_Disentangled Self-Supervision in Sequential Recommenders.pdf;D\:\\Filez\\Zetero\\storage\\YLM44HSZ\\notes.md},
  isbn = {978-1-4503-7998-4},
  language = {en}
}

@article{majumderSupervisedMomentumContrastive2021,
  title = {Supervised {{Momentum Contrastive Learning}} for {{Few}}-{{Shot Classification}}},
  author = {Majumder, Orchid and Ravichandran, Avinash and Maji, Subhransu and Achille, Alessandro and Polito, Marzia and Soatto, Stefano},
  year = {2021},
  month = jun,
  abstract = {Few-shot learning aims to transfer information from one task to enable generalization on novel tasks given a few examples. This information is present both in the domain and the class labels. In this work we investigate the complementary roles of these two sources of information by combining instance-discriminative contrastive learning and supervised learning in a single framework called Supervised Momentum Contrastive learning (SUPMOCO). Our approach avoids a problem observed in supervised learning where information in images not relevant to the task is discarded, which hampers their generalization to novel tasks. We show that (self-supervised) contrastive learning and supervised learning are mutually beneficial, leading to a new state-of-the-art on the META-DATASET [47] \textemdash{} a recently introduced benchmark for few-shot learning. Our method is based on a simple modification of MOCO [19] and scales better than prior work on combining supervised and selfsupervised learning. This allows us to easily combine data from multiple domains leading to further improvements.},
  archivePrefix = {arXiv},
  eprint = {2101.11058},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\SM9K6LUM\\Majumder et al_2021_Supervised Momentum Contrastive Learning for Few-Shot Classification.pdf},
  journal = {arXiv:2101.11058 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{maLearningDisentangledRepresentations,
  title = {Learning {{Disentangled Representations}} for {{Recommendation}}},
  author = {Ma, Jianxin and Zhou, Chang and Cui, Peng and Yang, Hongxia and Zhu, Wenwu},
  pages = {12},
  abstract = {User behavior data in recommender systems are driven by the complex interactions of many latent factors behind the users' decision making processes. The factors are highly entangled, and may range from high-level ones that govern user intentions, to low-level ones that characterize a user's preference when executing an intention. Learning representations that uncover and disentangle these latent factors can bring enhanced robustness, interpretability, and controllability. However, learning such disentangled representations from user behavior is challenging, and remains largely neglected by the existing literature. In this paper, we present the MACRo-mIcro Disentangled Variational Auto-Encoder (MacridVAE) for learning disentangled representations from user behavior. Our approach achieves macro disentanglement by inferring the high-level concepts associated with user intentions (e.g., to buy a shirt or a cellphone), while capturing the preference of a user regarding the different concepts separately. A micro-disentanglement regularizer, stemming from an information-theoretic interpretation of VAEs, then forces each dimension of the representations to independently reflect an isolated low-level factor (e.g., the size or the color of a shirt). Empirical results show that our approach can achieve substantial improvement over the state-of-the-art baselines. We further demonstrate that the learned representations are interpretable and controllable, which can potentially lead to a new paradigm for recommendation where users are given fine-grained control over targeted aspects of the recommendation lists.},
  file = {D\:\\Filez\\Zetero\\storage\\J5F8A7PP\\Ma et al_Learning Disentangled Representations for Recommendation.pdf},
  language = {en}
}

@inproceedings{mattosSemiSupervisedGraphAttention2021,
  title = {Semi-{{Supervised Graph Attention Networks}} for {{Event Representation Learning}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  author = {Mattos, Joao Pedro Rodrigues and Marcacini, Ricardo M.},
  year = {2021},
  month = dec,
  pages = {1234--1239},
  publisher = {{IEEE}},
  address = {{Auckland, New Zealand}},
  doi = {10.1109/ICDM51629.2021.00150},
  abstract = {Event analysis from news and social networks is very useful for a wide range of social studies and real-world applications. Recently, event graphs have been explored to model event datasets and their complex relationships, where events are vertices connected to other vertices representing locations, people's names, dates, and various other event metadata. Graph representation learning methods are promising for extracting latent features from event graphs to enable the use of different classification algorithms. However, existing methods fail to meet essential requirements for event graphs, such as (i) dealing with semi-supervised graph embedding to take advantage of some labeled events, (ii) automatically determining the importance of the relationships between event vertices and their metadata vertices, as well as (iii) dealing with the graph heterogeneity. This paper presents GNEE (GAT Neural Event Embeddings), a method that combines Graph Attention Networks and Graph Regularization. First, an event graph regularization is proposed to ensure that all graph vertices receive event features, thereby mitigating the graph heterogeneity drawback. Second, semisupervised graph embedding with self-attention mechanism considers existing labeled events, as well as learns the importance of relationships in the event graph during the representation learning process. A statistical analysis of experimental results with five real-world event graphs and six graph embedding methods shows that our GNEE outperforms state-of-the-art semisupervised graph embedding methods.},
  file = {D\:\\Filez\\Zetero\\storage\\2RNGNT35\\Mattos 和 Marcacini - 2021 - Semi-Supervised Graph Attention Networks for Event.pdf},
  isbn = {978-1-66542-398-4},
  language = {en}
}

@inproceedings{mengInitiativeAwareSelfSupervisedLearning2021,
  title = {Initiative-{{Aware Self}}-{{Supervised Learning}} for {{Knowledge}}-{{Grounded Conversations}}},
  booktitle = {Proceedings of the 44th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Meng, Chuan and Ren, Pengjie and Chen, Zhumin and Ren, Zhaochun and Xi, Tengxiao and de Rijke, Maarten},
  year = {2021},
  month = jul,
  pages = {522--532},
  publisher = {{ACM}},
  address = {{Virtual Event Canada}},
  doi = {10.1145/3404835.3462824},
  abstract = {In the knowledge-grounded conversation (KGC) task systems aim to produce more informative responses by leveraging external knowledge. KGC includes a vital part, knowledge selection, where conversational agents select the appropriate knowledge to be incorporated in the next response. Mixed initiative is an intrinsic feature of conversations where the user and the system can both take the initiative in suggesting new conversational directions. Knowledge selection can be driven by the user's initiative or by the system's initiative. For the former, the system usually selects knowledge according to the current user utterance that contains new topics or questions posed by the user; for the latter, the system usually selects knowledge according to the previously selected knowledge. No previous study has considered the mixed-initiative characteristics of knowledge selection to improve its performance.},
  file = {D\:\\Filez\\Zetero\\storage\\AI795PGP\\Meng et al_2021_Initiative-Aware Self-Supervised Learning for Knowledge-Grounded Conversations.pdf},
  isbn = {978-1-4503-8037-9},
  language = {en}
}

@article{milenkoskiRecommendingBurgersBased2021,
  title = {Recommending {{Burgers}} Based on {{Pizza Preferences}}: {{Addressing Data Sparsity}} in {{Recommendation}} with a {{Product}} of {{Experts}}},
  author = {Milenkoski, Martin and Antognini, Diego and Musat, Claudiu},
  year = {2021},
  pages = {10},
  file = {D\:\\Filez\\Zetero\\storage\\9C2WB8CZ\\Milenkoski et al_2021_Recommending Burgers based on Pizza Preferences.pdf},
  language = {en}
}

@article{mnihFastSimpleAlgorithm,
  title = {A Fast and Simple Algorithm for Training Neural Probabilistic Language Models},
  author = {Mnih, Andriy and Teh, Yee Whye},
  pages = {8},
  abstract = {In spite of their superior performance, neural probabilistic language models (NPLMs) remain far less widely used than n-gram models due to their notoriously long training times, which are measured in weeks even for moderately-sized datasets. Training NPLMs is computationally expensive because they are explicitly normalized, which leads to having to consider all words in the vocabulary when computing the log-likelihood gradients.},
  file = {D\:\\Filez\\Zetero\\storage\\XVUTZIBX\\Mnih_Teh_A fast and simple algorithm for training neural probabilistic language models.pdf},
  language = {en}
}

@article{niPerceiveYourUsers2018,
  title = {Perceive {{Your Users}} in {{Depth}}: {{Learning Universal User Representations}} from {{Multiple E}}-Commerce {{Tasks}}},
  shorttitle = {Perceive {{Your Users}} in {{Depth}}},
  author = {Ni, Yabo and Ou, Dan and Liu, Shichen and Li, Xiang and Ou, Wenwu and Zeng, Anxiang and Si, Luo},
  year = {2018},
  month = may,
  abstract = {Tasks such as search and recommendation have become increasingly important for E-commerce to deal with the information overload problem. To meet the diverse needs of different users, personalization plays an important role. In many large portals such as Taobao and Amazon, there are a bunch of different types of search and recommendation tasks operating simultaneously for personalization. However, most of current techniques address each task separately. This is suboptimal as no information about users shared across different tasks.},
  archivePrefix = {arXiv},
  eprint = {1805.10727},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\JSJANC6X\\Ni et al_2018_Perceive Your Users in Depth.pdf},
  journal = {arXiv:1805.10727 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@book{oliverMachineLearningKnowledge2021,
  title = {Machine {{Learning}} and {{Knowledge Discovery}} in {{Databases}}. {{Research Track}}: {{European Conference}}, {{ECML PKDD}} 2021, {{Bilbao}}, {{Spain}}, {{September}} 13\textendash 17, 2021, {{Proceedings}}, {{Part I}}},
  shorttitle = {Machine {{Learning}} and {{Knowledge Discovery}} in {{Databases}}. {{Research Track}}},
  editor = {Oliver, Nuria and {P{\'e}rez-Cruz}, Fernando and Kramer, Stefan and Read, Jesse and Lozano, Jose A.},
  year = {2021},
  volume = {12975},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-86486-6},
  file = {D\:\\Filez\\Zetero\\storage\\8EDMLRG2\\Oliver 等。 - 2021 - Machine Learning and Knowledge Discovery in Databa.pdf},
  isbn = {978-3-030-86485-9 978-3-030-86486-6},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{oordRepresentationLearningContrastive2019,
  title = {Representation {{Learning}} with {{Contrastive Predictive Coding}}},
  author = {van den Oord, Aaron and Li, Yazhe and Vinyals, Oriol},
  year = {2019},
  month = jan,
  abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
  archivePrefix = {arXiv},
  eprint = {1807.03748},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\KVZKG8JI\\Oord et al_2019_Representation Learning with Contrastive Predictive Coding.pdf;D\:\\Filez\\Zetero\\storage\\9HPNXMHN\\317711322.html},
  journal = {arXiv:1807.03748 [cs, stat]},
  keywords = {Computer Science - Machine Learning,InfoNCE,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{oualiSpatialContrastiveLearning2021,
  title = {Spatial {{Contrastive Learning}} for {{Few}}-{{Shot Classification}}},
  author = {Ouali, Yassine and Hudelot, C{\'e}line and Tami, Myriam},
  year = {2021},
  month = jun,
  abstract = {In this paper, we explore contrastive learning for few-shot classification, in which we propose to use it as an additional auxiliary training objective acting as a data-dependent regularizer to promote more general and transferable features. In particular, we present a novel attention-based spatial contrastive objective to learn locally discriminative and class-agnostic features. As a result, our approach overcomes some of the limitations of the cross-entropy loss, such as its excessive discrimination towards seen classes, which reduces the transferability of features to unseen classes. With extensive experiments, we show that the proposed method outperforms state-of-the-art approaches, confirming the importance of learning good and transferable embeddings for few-shot learning Code: https://github.com/yassouali/SCL.},
  archivePrefix = {arXiv},
  eprint = {2012.13831},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\3B6Q5K7B\\Ouali et al_2021_Spatial Contrastive Learning for Few-Shot Classification.pdf},
  journal = {arXiv:2012.13831 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@incollection{oualiSpatialContrastiveLearning2021a,
  title = {Spatial {{Contrastive Learning}} for {{Few}}-{{Shot Classification}}},
  booktitle = {Machine {{Learning}} and {{Knowledge Discovery}} in {{Databases}}. {{Research Track}}},
  author = {Ouali, Yassine and Hudelot, C{\'e}line and Tami, Myriam},
  editor = {Oliver, Nuria and {P{\'e}rez-Cruz}, Fernando and Kramer, Stefan and Read, Jesse and Lozano, Jose A.},
  year = {2021},
  volume = {12975},
  pages = {671--686},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-86486-6_41},
  abstract = {In this paper we explore contrastive learning for few-shot classification, in which we propose to use it as an additional auxiliary training objective acting as a data-dependent regularizer to promote more general and transferable features. In particular, we present a novel attention-based spatial contrastive objective to learn locally discriminative and class-agnostic features. As a result, our approach overcomes some of the limitations of the cross-entropy loss, such as its excessive discrimination towards seen classes, which reduces the transferability of features to unseen classes. With extensive experiments, we show that the proposed method outperforms state-of-the-art approaches, confirming the importance of learning good and transferable embeddings for few-shot learning. Code: https://github.com/yassouali/SCL.},
  file = {D\:\\Filez\\Zetero\\storage\\2BI4Q564\\Ouali 等。 - 2021 - Spatial Contrastive Learning for Few-Shot Classifi.pdf},
  isbn = {978-3-030-86485-9 978-3-030-86486-6},
  language = {en}
}

@article{panClickthroughRatePrediction2021,
  title = {Click-through {{Rate Prediction}} with {{Auto}}-{{Quantized Contrastive Learning}}},
  author = {Pan, Yujie and Yao, Jiangchao and Han, Bo and Jia, Kunyang and Zhang, Ya and Yang, Hongxia},
  year = {2021},
  month = sep,
  abstract = {Click-through rate (CTR) prediction becomes indispensable in ubiquitous web recommendation applications. Nevertheless, the current methods are struggling under the cold-start scenarios where the user interactions are extremely sparse. We consider this problem as an automatic identification about whether the user behaviors are rich enough to capture the interests for prediction, and propose an Auto-Quantized Contrastive Learning (AQCL) loss to regularize the model. Different from previous methods, AQCL explores both the instance-instance and the instance-cluster similarity to robustify the latent representation, and automatically reduces the information loss to the active users due to the quantization. The proposed framework is agnostic to different model architectures and can be trained in an end-to-end fashion. Extensive results show that it consistently improves the current state-of-the-art CTR models.},
  archivePrefix = {arXiv},
  eprint = {2109.13921},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\4VFD97D3\\notes.md;D\:\\Filez\\Zetero\\storage\\EX7RI4P5\\Pan et al_2021_Click-through Rate Prediction with Auto-Quantized Contrastive Learning.pdf},
  journal = {arXiv:2109.13921 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{panCollaborativeKnowledgeEnhancedRecommendation2021,
  title = {Collaborative {{Knowledge}}-{{Enhanced Recommendation}} with {{Self}}-{{Supervisions}}},
  author = {Pan, Zhiqiang and Chen, Honghui},
  year = {2021},
  month = sep,
  volume = {9},
  pages = {2129},
  issn = {2227-7390},
  doi = {10.3390/math9172129},
  abstract = {Knowledge-enhanced recommendation (KER) aims to integrate the knowledge graph (KG) into collaborative filtering (CF) for alleviating the sparsity and cold start problems. The state-ofthe-art graph neural network (GNN)\textendash based methods mainly focus on exploiting the connectivity between entities in the knowledge graph, while neglecting the interaction relation between items reflected in the user-item interactions. Moreover, the widely adopted BPR loss for model optimization fails to provide sufficient supervisions for learning discriminative representation of users and items. To address these issues, we propose the collaborative knowledge-enhanced recommendation (CKER) method. Specifically, CKER proposes a collaborative graph convolution network (CGCN) to learn the user and item representations from the connection between items in the constructed interaction graph and the connectivity between entities in the knowledge graph. Moreover, we introduce the selfsupervised learning to maximize the mutual information between the interaction- and knowledgeaware user preferences by deriving additional supervision signals. We conduct comprehensive experiments on two benchmark datasets, namely Amazon-Book and Last-FM, and the experimental results show that CKER can outperform the state-of-the-art baselines in terms of recall and NDCG on knowledge-enhanced recommendation.},
  file = {D\:\\Filez\\Zetero\\storage\\2GFEH3RS\\Pan_Chen_2021_Collaborative Knowledge-Enhanced Recommendation with Self-Supervisions.pdf},
  journal = {Mathematics},
  language = {en},
  number = {17}
}

@article{panEfficientGraphCollaborative2021,
  title = {Efficient {{Graph Collaborative Filtering}} via {{Contrastive Learning}}},
  author = {Pan, Zhiqiang and Chen, Honghui},
  year = {2021},
  month = jul,
  volume = {21},
  pages = {4666},
  issn = {1424-8220},
  doi = {10.3390/s21144666},
  abstract = {Collaborative filtering (CF) aims to make recommendations for users by detecting user's preference from the historical user\textendash item interactions. Existing graph neural networks (GNN) based methods achieve satisfactory performance by exploiting the high-order connectivity between users and items, however they suffer from the poor training efficiency problem and easily introduce bias for information propagation. Moreover, the widely applied Bayesian personalized ranking (BPR) loss is insufficient to provide supervision signals for training due to the extremely sparse observed interactions. To deal with the above issues, we propose the Efficient Graph Collaborative Filtering (EGCF) method. Specifically, EGCF adopts merely one-layer graph convolution to model the collaborative signal for users and items from the first-order neighbors in the user\textendash item interactions. Moreover, we introduce contrastive learning to enhance the representation learning of users and items by deriving the self-supervisions, which is jointly trained with the supervised learning. Extensive experiments are conducted on two benchmark datasets, i.e., Yelp2018 and Amazon-book, and the experimental results demonstrate that EGCF can achieve the state-of-the-art performance in terms of Recall and normalized discounted cumulative gain (NDCG), especially on ranking the target items at right positions. In addition, EGCF shows obvious advantages in the training efficiency compared with the competitive baselines, making it practicable for potential applications.},
  file = {D\:\\Filez\\Zetero\\storage\\SIV8EGIW\\Pan_Chen_2021_Efficient Graph Collaborative Filtering via Contrastive Learning.pdf},
  journal = {Sensors},
  language = {en},
  number = {14}
}

@article{pantazisFocusPositivesSelfSupervised,
  title = {Focus on the {{Positives}}: {{Self}}-{{Supervised Learning}} for {{Biodiversity Monitoring}}},
  author = {Pantazis, Omiros and Brostow, Gabriel J and Jones, Kate E and Aodha, Oisin Mac},
  pages = {17},
  abstract = {We address the problem of learning self-supervised representations from unlabeled image collections. Unlike existing approaches that attempt to learn useful features by maximizing similarity between augmented versions of each input image or by speculatively picking negative samples, we instead also make use of the natural variation that occurs in image collections that are captured using static monitoring cameras. To achieve this, we exploit readily available context data that encodes information such as the spatial and temporal relationships between the input images. We are able to learn representations that are surprisingly effective for downstream supervised classification, by first identifying high probability positive pairs at training time, i.e. those images that are likely to depict the same visual concept. For the critical task of global biodiversity monitoring, this results in image features that can be adapted to challenging visual species classification tasks with limited human supervision. We present results on four different camera trap image collections, across three different families of self-supervised learning methods, and show that careful image selection at training time results in superior performance compared to existing baselines such as conventional self-supervised training and transfer learning.},
  file = {D\:\\Filez\\Zetero\\storage\\VH3QGQFV\\Pantazis et al_Focus on the Positives.pdf},
  language = {en}
}

@inproceedings{parkUnsupervisedDifferentiableMultiaspect2020,
  title = {Unsupervised {{Differentiable Multi}}-Aspect {{Network Embedding}}},
  booktitle = {Proceedings of the 26th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Park, Chanyoung and Yang, Carl and Zhu, Qi and Kim, Donghyun and Yu, Hwanjo and Han, Jiawei},
  year = {2020},
  month = aug,
  pages = {1435--1445},
  publisher = {{ACM}},
  address = {{Virtual Event CA USA}},
  doi = {10.1145/3394486.3403196},
  abstract = {Network embedding is an in uential graph mining technique for representing nodes in a graph as distributed vectors. However, the majority of network embedding methods focus on learning a single vector representation for each node, which has been recently criticized for not being capable of modeling multiple aspects of a node. To capture the multiple aspects of each node, existing studies mainly rely on o ine graph clustering performed prior to the actual embedding, which results in the cluster membership of each node (i.e., node aspect distribution) xed throughout training of the embedding model. We argue that this not only makes each node always have the same aspect distribution regardless of its dynamic context, but also hinders the end-to-end training of the model that eventually leads to the nal embedding quality largely dependent on the clustering. In this paper, we propose a novel end-to-end framework for multi-aspect network embedding, called asp2vec, in which the aspects of each node are dynamically assigned based on its local context. More precisely, among multiple aspects, we dynamically assign a single aspect to each node based on its current context, and our aspect selection module is end-to-end di erentiable via the Gumbel-Softmax trick. We also introduce the aspect regularization framework to capture the interactions among the multiple aspects in terms of relatedness and diversity. We further demonstrate that our proposed framework can be readily extended to heterogeneous networks. Extensive experiments towards various downstream tasks on various types of homogeneous networks and a heterogeneous network demonstrate the superiority of asp2vec.},
  file = {D\:\\Filez\\Zetero\\storage\\UZZATXFN\\Park 等。 - 2020 - Unsupervised Differentiable Multi-aspect Network E.pdf},
  isbn = {978-1-4503-7998-4},
  language = {en}
}

@article{qianIntentDisentanglementFeature2021,
  title = {Intent {{Disentanglement}} and {{Feature Self}}-Supervision for {{Novel Recommendation}}},
  author = {Qian, Tieyun and Liang, Yile and Li, Qing and Ma, Xuan and Sun, Ke and Peng, Zhiyong},
  year = {2021},
  month = jun,
  abstract = {One key property in recommender systems is the long-tail distribution in user-item interactions where most items only have few user feedback. Improving the recommendation of tail items can promote novelty and bring positive effects to both users and providers, and thus is a desirable property of recommender systems. Current novel recommendation studies over-emphasize the importance of tail items without differentiating the degree of users' intent on popularity and often incur a sharp decline of accuracy. Moreover, none of existing methods has ever taken the extreme case of tail items, i.e., cold-start items without any interaction, into consideration.},
  archivePrefix = {arXiv},
  eprint = {2106.14388},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\IA5Y9JI5\\notes.md;D\:\\Filez\\Zetero\\storage\\UCQH39MI\\Qian et al_2021_Intent Disentanglement and Feature Self-supervision for Novel Recommendation.pdf},
  journal = {arXiv:2106.14388 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{qiLowShotLearningImprinted2018,
  title = {Low-{{Shot Learning}} with {{Imprinted Weights}}},
  booktitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Qi, Hang and Brown, Matthew and Lowe, David G.},
  year = {2018},
  month = jun,
  pages = {5822--5830},
  publisher = {{IEEE}},
  address = {{Salt Lake City, UT}},
  doi = {10.1109/CVPR.2018.00610},
  abstract = {Human vision is able to immediately recognize novel visual categories after seeing just one or a few training examples. We describe how to add a similar capability to ConvNet classifiers by directly setting the final layer weights from novel training examples during low-shot learning. We call this process weight imprinting as it directly sets weights for a new category based on an appropriately scaled copy of the embedding layer activations for that training example. The imprinting process provides a valuable complement to training with stochastic gradient descent, as it provides immediate good classification performance and an initialization for any further fine-tuning in the future. We show how this imprinting process is related to proxy-based embeddings. However, it differs in that only a single imprinted weight vector is learned for each novel category, rather than relying on a nearest-neighbor distance to training instances as typically used with embedding methods. Our experiments show that using averaging of imprinted weights provides better generalization than using nearest-neighbor instance embeddings.},
  file = {D\:\\Filez\\Zetero\\storage\\IASPSMG9\\Qi et al_2018_Low-Shot Learning with Imprinted Weights.pdf},
  isbn = {978-1-5386-6420-9},
  language = {en}
}

@inproceedings{qinWorldBinaryContrastive2021,
  title = {The {{World}} Is {{Binary}}: {{Contrastive Learning}} for {{Denoising Next Basket Recommendation}}},
  shorttitle = {The {{World}} Is {{Binary}}},
  booktitle = {Proceedings of the 44th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Qin, Yuqi and Wang, Pengfei and Li, Chenliang},
  year = {2021},
  month = jul,
  pages = {859--868},
  publisher = {{ACM}},
  address = {{Virtual Event Canada}},
  doi = {10.1145/3404835.3462836},
  abstract = {Next basket recommendation aims to infer a set of items that a user will purchase at the next visit by considering a sequence of baskets he/she has purchased previously. This task has drawn increasing attention from both the academic and industrial communities. The existing solutions mainly focus on sequential modeling over their historical interactions. However, due to the diversity and randomness of users' behaviors, not all these baskets are relevant to help identify the user's next move. It is necessary to denoise the baskets and extract credibly relevant items to enhance recommendation performance. Unfortunately, this dimension is usually overlooked in the current literature.},
  file = {D\:\\Filez\\Zetero\\storage\\F26K4RMW\\Qin et al_2021_The World is Binary.pdf;D\:\\Filez\\Zetero\\storage\\G3R8YN8I\\notes.md},
  isbn = {978-1-4503-8037-9},
  language = {en}
}

@article{qiPPRecNewsRecommendation2021,
  title = {{{PP}}-{{Rec}}: {{News Recommendation}} with {{Personalized User Interest}} and {{Time}}-Aware {{News Popularity}}},
  shorttitle = {{{PP}}-{{Rec}}},
  author = {Qi, Tao and Wu, Fangzhao and Wu, Chuhan and Huang, Yongfeng},
  year = {2021},
  month = jun,
  abstract = {Personalized news recommendation methods are widely used in online news services. These methods usually recommend news based on the matching between news content and user interest inferred from historical behaviors. However, these methods usually have difficulties in making accurate recommendations to cold-start users, and tend to recommend similar news with those users have read. In general, popular news usually contain important information and can attract users with different interests. Besides, they are usually diverse in content and topic. Thus, in this paper we propose to incorporate news popularity information to alleviate the cold-start and diversity problems for personalized news recommendation. In our method, the ranking score for recommending a candidate news to a target user is the combination of a personalized matching score and a news popularity score. The former is used to capture the personalized user interest in news. The latter is used to measure timeaware popularity of candidate news, which is predicted based on news content, recency, and real-time CTR using a unified framework. Besides, we propose a popularity-aware user encoder to eliminate the popularity bias in user behaviors for accurate interest modeling. Experiments on two real-world datasets show our method can effectively improve the accuracy and diversity for news recommendation.},
  archivePrefix = {arXiv},
  eprint = {2106.01300},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\QB4THMSK\\Qi et al_2021_PP-Rec.pdf},
  journal = {arXiv:2106.01300 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{qiuMemoryAugmentedMultiInstance,
  title = {Memory {{Augmented Multi}}-{{Instance Contrastive Predictive Coding}} for {{Sequential Recommendation}}},
  author = {Qiu, Ruihong and Huang, Zi and Yin, Hongzhi},
  pages = {10},
  file = {D\:\\Filez\\Zetero\\storage\\UCW454TJ\\Qiu et al_Memory Augmented Multi-Instance Contrastive Predictive Coding for Sequential.pdf},
  language = {en}
}

@inproceedings{qiuMemoryAugmentedMultiInstance2021,
  title = {Memory {{Augmented Multi}}-{{Instance Contrastive Predictive Coding}} for {{Sequential Recommendation}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  author = {Qiu, Ruihong and Huang, Zi and Yin, Hongzhi},
  year = {2021},
  month = dec,
  pages = {519--528},
  publisher = {{IEEE}},
  address = {{Auckland, New Zealand}},
  doi = {10.1109/ICDM51629.2021.00063},
  abstract = {The sequential recommendation aims to recommend items, such as products, songs and places, to users based on the sequential patterns of their historical records. Most existing sequential recommender models consider the next item prediction task as the training signal. Unfortunately, there are two essential challenges for these methods: (1) the long-term preference is difficult to capture, and (2) the supervision signal is too sparse to effectively train a model. In this paper, we propose a novel sequential recommendation framework to overcome these challenges based on a memory augmented multi-instance contrastive predictive coding scheme, denoted as MMInfoRec. The basic contrastive predictive coding (CPC) serves as encoders of sequences and items. The memory module is designed to augment the autoregressive prediction in CPC to enable a flexible and general representation of the encoded preference, which can improve the ability to capture the long-term preference. For effective training of the MMInfoRec model, a novel multi-instance noise contrastive estimation (MINCE) loss is proposed, using multiple positive samples, which offers effective exploitation of samples inside a mini-batch. The proposed MMInfoRec framework falls into the contrastive learning style, within which, however, a further finetuning step is not required given that its contrastive training task is well aligned with the target recommendation task. With extensive experiments on four benchmark datasets, MMInfoRec can outperform the state-of-the-art baselines.},
  file = {D\:\\Filez\\Zetero\\storage\\88TI5HFY\\Qiu 等。 - 2021 - Memory Augmented Multi-Instance Contrastive Predic.pdf},
  isbn = {978-1-66542-398-4},
  language = {en}
}

@article{renCollaborativeGraphContrastive2021,
  title = {Collaborative {{Graph Contrastive Learning}}: {{Data Augmentation Composition May Not}} Be {{Necessary}} for {{Graph Representation Learning}}},
  shorttitle = {Collaborative {{Graph Contrastive Learning}}},
  author = {Ren, Yuxiang and Zhang, Jiawei},
  year = {2021},
  month = nov,
  abstract = {Unsupervised graph representation learning is a non-trivial topic for graph data. The success of contrastive learning in the unsupervised representation learning of structured data inspires similar attempts on the graph. The current unsupervised graph representation learning and pre-training using the contrastive loss are mainly based on the contrast between handcrafted augmented graph data. However, the graph data augmentation is still not well-explored due to the uncontrollable invariance. In this paper, we propose a novel collaborative graph neural networks contrastive learning framework (CGCL), which uses multiple graph encoders to observe the graph. Features observed from different views act as the graph augmentation for contrastive learning between graph encoders, which avoid inducing any perturbation to guarantee the invariance. CGCL can handle both graph-level and node-level representation learning. Extensive experiments demonstrate the advantages of CGCL in unsupervised graph representation learning and the nonnecessity of handcrafted data augmentation composition for graph representation learning. Our code are available at: Clickable link1.},
  archivePrefix = {arXiv},
  eprint = {2111.03262},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\ELE2YYMX\\2111.03262.pdf},
  journal = {arXiv:2111.03262 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{robinsonContrastiveLearningHard2021,
  title = {Contrastive {{Learning}} with {{Hard Negative Samples}}},
  author = {Robinson, Joshua and Chuang, Ching-Yao and Sra, Suvrit and Jegelka, Stefanie},
  year = {2021},
  month = jan,
  abstract = {How can you sample good negative examples for contrastive learning? We argue that, as with metric learning, contrastive learning of representations benefits from hard negative samples (i.e., points that are difficult to distinguish from an anchor point). The key challenge toward using hard negatives is that contrastive methods must remain unsupervised, making it infeasible to adopt existing negative sampling strategies that use true similarity information. In response, we develop a new family of unsupervised sampling methods for selecting hard negative samples where the user can control the hardness. A limiting case of this sampling results in a representation that tightly clusters each class, and pushes different classes as far apart as possible. The proposed method improves downstream performance across multiple modalities, requires only few additional lines of code to implement, and introduces no computational overhead.},
  archivePrefix = {arXiv},
  eprint = {2010.04592},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\ETTVYE62\\Robinson et al_2021_Contrastive Learning with Hard Negative Samples.pdf},
  journal = {arXiv:2010.04592 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@inproceedings{sachdevaSequentialVariationalAutoencoders2019,
  title = {Sequential {{Variational Autoencoders}} for {{Collaborative Filtering}}},
  booktitle = {Proceedings of the {{Twelfth ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Sachdeva, Noveen and Manco, Giuseppe and Ritacco, Ettore and Pudi, Vikram},
  year = {2019},
  month = jan,
  pages = {600--608},
  publisher = {{ACM}},
  address = {{Melbourne VIC Australia}},
  doi = {10.1145/3289600.3291007},
  abstract = {Variational autoencoders were proven successful in domains such as computer vision and speech processing. Their adoption for modeling user preferences is still unexplored, although recently it is starting to gain attention in the current literature. In this work, we propose a model which extends variational autoencoders by exploiting the rich information present in the past preference history. We introduce a recurrent version of the VAE, where instead of passing a subset of the whole history regardless of temporal dependencies, we rather pass the consumption sequence subset through a recurrent neural network. At each time-step of the RNN, the sequence is fed through a series of fully-connected layers, the output of which models the probability distribution of the most likely future preferences. We show that handling temporal information is crucial for improving the accuracy of the VAE: In fact, our model beats the current state-of-the-art by valuable margins because of its ability to capture temporal dependencies among the user-consumption sequence using the recurrent encoder still keeping the fundamentals of variational autoencoders intact.},
  file = {D\:\\Filez\\Zetero\\storage\\CAGYJLUB\\Sachdeva 等。 - 2019 - Sequential Variational Autoencoders for Collaborat.pdf},
  isbn = {978-1-4503-5940-5},
  language = {en}
}

@article{schmarjeSurveySemiSelf2021,
  title = {A Survey on {{Semi}}-, {{Self}}- and {{Unsupervised Learning}} for {{Image Classification}}},
  author = {Schmarje, Lars and Santarossa, Monty and Schr{\"o}der, Simon-Martin and Koch, Reinhard},
  year = {2021},
  volume = {9},
  pages = {82146--82168},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2021.3084358},
  abstract = {While deep learning strategies achieve outstanding results in computer vision tasks, one issue remains: The current strategies rely heavily on a huge amount of labeled data. In many real-world problems, it is not feasible to create such an amount of labeled training data. Therefore, it is common to incorporate unlabeled data into the training process to reach equal results with fewer labels. Due to a lot of concurrent research, it is difficult to keep track of recent developments. In this survey, we provide an overview of often used ideas and methods in image classification with fewer labels. We compare 34 methods in detail based on their performance and their commonly used ideas rather than a fine-grained taxonomy. In our analysis, we identify three major trends that lead to future research opportunities. 1. State-of-the-art methods are scaleable to real-world applications in theory but issues like class imbalance, robustness, or fuzzy labels are not considered. 2. The degree of supervision which is needed to achieve comparable results to the usage of all labels is decreasing and therefore methods need to be extended to settings with a variable number of classes. 3. All methods share some common ideas but we identify clusters of methods that do not share many ideas. We show that combining ideas from different clusters can lead to better performance.},
  archivePrefix = {arXiv},
  eprint = {2002.08721},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\A6ZCBDYI\\Schmarje 等。 - 2021 - A survey on Semi-, Self- and Unsupervised Learning.pdf},
  journal = {IEEE Access},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  language = {en}
}

@inproceedings{sedhainAutoRecAutoencodersMeet2015,
  title = {{{AutoRec}}: {{Autoencoders Meet Collaborative Filtering}}},
  shorttitle = {{{AutoRec}}},
  booktitle = {Proceedings of the 24th {{International Conference}} on {{World Wide Web}}},
  author = {Sedhain, Suvash and Menon, Aditya Krishna and Sanner, Scott and Xie, Lexing},
  year = {2015},
  month = may,
  pages = {111--112},
  publisher = {{ACM}},
  address = {{Florence Italy}},
  doi = {10.1145/2740908.2742726},
  abstract = {This paper proposes AutoRec, a novel autoencoder framework for collaborative filtering (CF). Empirically, AutoRec's compact and efficiently trainable model outperforms stateof-the-art CF techniques (biased matrix factorization, RBMCF and LLORMA) on the Movielens and Netflix datasets.},
  file = {D\:\\Filez\\Zetero\\storage\\GFV75LZ3\\Sedhain 等。 - 2015 - AutoRec Autoencoders Meet Collaborative Filtering.pdf},
  isbn = {978-1-4503-3473-0},
  language = {en}
}

@inproceedings{shenbinRecVAENewVariational2020,
  title = {{{RecVAE}}: {{A New Variational Autoencoder}} for {{Top}}-{{N Recommendations}} with {{Implicit Feedback}}},
  shorttitle = {{{RecVAE}}},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Shenbin, Ilya and Alekseev, Anton and Tutubalina, Elena and Malykh, Valentin and Nikolenko, Sergey I.},
  year = {2020},
  month = jan,
  pages = {528--536},
  publisher = {{ACM}},
  address = {{Houston TX USA}},
  doi = {10.1145/3336191.3371831},
  abstract = {Recent research has shown the advantages of using autoencoders based on deep neural networks for collaborative filtering. In particular, the recently proposed Mult-VAE model, which used the multinomial likelihood variational autoencoders, has shown excellent results for top-N recommendations. In this work, we propose the Recommender VAE (RecVAE) model that originates from our research on regularization techniques for variational autoencoders. RecVAE introduces several novel ideas to improve MultVAE, including a novel composite prior distribution for the latent codes, a new approach to setting the {$\beta$} hyperparameter for the {$\beta$}-VAE framework, and a new approach to training based on alternating updates. In experimental evaluation, we show that RecVAE significantly outperforms previously proposed autoencoderbased models, including Mult-VAE and RaCT, across classical collaborative filtering datasets, and present a detailed ablation study to assess our new developments. Code and models are available at https://github.com/ilya-shenbin/RecVAE.},
  file = {D\:\\Filez\\Zetero\\storage\\98WLGV87\\Shenbin et al_2020_RecVAE.pdf},
  isbn = {978-1-4503-6822-3},
  language = {en}
}

@article{shiAdaptiveMultilayerContrastive2021,
  title = {Adaptive {{Multi}}-Layer {{Contrastive Graph Neural Networks}}},
  author = {Shi, Shuhao and Xie, Pengfei and Luo, Xu and Qiao, Kai and Wang, Linyuan and Chen, Jian and Yan, Bin},
  year = {2021},
  month = sep,
  abstract = {We present Adaptive Multi-layer Contrastive Graph Neural Networks (AMC-GNN), a self-supervised learning framework for Graph Neural Network, which learns feature representations of sample data without data labels. AMC-GNN generates two graph views by data augmentation and compares different layers' output embeddings of Graph Neural Network encoders to obtain feature representations, which could be used for downstream tasks. AMC-GNN could learn the importance weights of embeddings in different layers adaptively through the attention mechanism, and an auxiliary encoder is introduced to train graph contrastive encoders better. The accuracy is improved by maximizing the representation's consistency of positive pairs in the early layers and the final embedding space. Our experiments show that the results can be consistently improved by using the AMC-GNN framework, across four established graph benchmarks: Cora, Citeseer, Pubmed, DBLP citation network datasets, as well as four newly proposed datasets: Co-author-CS, Co-author-Physics, Amazon-Computers, Amazon-Photo.},
  archivePrefix = {arXiv},
  eprint = {2109.14159},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\BMMWMVF2\\Shi 等。 - 2021 - Adaptive Multi-layer Contrastive Graph Neural Netw.pdf},
  journal = {arXiv:2109.14159 [cs]},
  keywords = {Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{songCoupledVariationalRecurrent2019,
  title = {Coupled {{Variational Recurrent Collaborative Filtering}}},
  booktitle = {Proceedings of the 25th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Song, Qingquan and Chang, Shiyu and Hu, Xia},
  year = {2019},
  month = jul,
  pages = {335--343},
  publisher = {{ACM}},
  address = {{Anchorage AK USA}},
  doi = {10.1145/3292500.3330940},
  abstract = {We focus on the problem of streaming recommender system and explore novel collaborative filtering algorithms to handle the data dynamicity and complexity in a streaming manner. Although deep neural networks have demonstrated the effectiveness of recommendation tasks, it is lack of explorations on integrating probabilistic models and deep architectures under streaming recommendation settings. Conjoining the complementary advantages of probabilistic models and deep neural networks could enhance both model effectiveness and the understanding of inference uncertainties. To bridge the gap, in this paper, we propose a Coupled Variational Recurrent Collaborative Filtering (CVRCF) framework based on the idea of Deep Bayesian Learning to handle the streaming recommendation problem. The framework jointly combines stochastic processes and deep factorization models under a Bayesian paradigm to model the generation and evolution of users' preferences and items' popularities. To ensure efficient optimization and streaming update, we further propose a sequential variational inference algorithm based on a cross variational recurrent neural network structure. Experimental results on three benchmark datasets demonstrate that the proposed framework performs favorably against the state-ofthe-art methods in terms of both temporal dependency modeling and predictive accuracy. The learned latent variables also provide visualized interpretations for the evolution of temporal dynamics.},
  file = {D\:\\Filez\\Zetero\\storage\\YHD95NQ2\\Song 等。 - 2019 - Coupled Variational Recurrent Collaborative Filter.pdf},
  isbn = {978-1-4503-6201-6},
  language = {en}
}

@article{SpecialIssueAdvances,
  title = {Special {{Issue}}: {{Advances}} in {{Climate Prediction Using Artificial Intelligence}}},
  issn = {10260471},
  file = {D\:\\Filez\\Zetero\\storage\\7NIDZUJP\\Special Issue.pdf},
  journal = {CLIVAR Exchanges},
  language = {en},
  number = {81}
}

@inproceedings{steckEmbarrassinglyShallowAutoencoders2019,
  title = {Embarrassingly {{Shallow Autoencoders}} for {{Sparse Data}}},
  booktitle = {The {{World Wide Web Conference}} on   - {{WWW}} '19},
  author = {Steck, Harald},
  year = {2019},
  pages = {3251--3257},
  publisher = {{ACM Press}},
  address = {{San Francisco, CA, USA}},
  doi = {10.1145/3308558.3313710},
  file = {D\:\\Filez\\Zetero\\storage\\DGM7ETMJ\\Steck - 2019 - Embarrassingly Shallow Autoencoders for Sparse Dat.pdf},
  isbn = {978-1-4503-6674-8},
  language = {en}
}

@article{sunBERT4RecSequentialRecommendation2019,
  title = {{{BERT4Rec}}: {{Sequential Recommendation}} with {{Bidirectional Encoder Representations}} from {{Transformer}}},
  shorttitle = {{{BERT4Rec}}},
  author = {Sun, Fei and Liu, Jun and Wu, Jian and Pei, Changhua and Lin, Xiao and Ou, Wenwu and Jiang, Peng},
  year = {2019},
  month = aug,
  abstract = {Modeling users' dynamic preferences from their historical behaviors is challenging and crucial for recommendation systems. Previous methods employ sequential neural networks to encode users' historical interactions from left to right into hidden representations for making recommendations. Despite their effectiveness, we argue that such left-to-right unidirectional models are sub-optimal due to the limitations including: a) unidirectional architectures restrict the power of hidden representation in users' behavior sequences; b) they often assume a rigidly ordered sequence which is not always practical. To address these limitations, we proposed a sequential recommendation model called BERT4Rec, which employs the deep bidirectional self-attention to model user behavior sequences. To avoid the information leakage and efficiently train the bidirectional model, we adopt the Cloze objective to sequential recommendation, predicting the random masked items in the sequence by jointly conditioning on their left and right context. In this way, we learn a bidirectional representation model to make recommendations by allowing each item in user historical behaviors to fuse information from both left and right sides. Extensive experiments on four benchmark datasets show that our model outperforms various state-of-the-art sequential models consistently.},
  archivePrefix = {arXiv},
  eprint = {1904.06690},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\G34TZAUW\\Sun et al_2019_BERT4Rec.pdf},
  journal = {arXiv:1904.06690 [cs]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{sunINFOGRAPHUNSUPERVISEDSEMISUPERVISED2020,
  title = {{{INFOGRAPH}}: {{UNSUPERVISED AND SEMI}}-{{SUPERVISED GRAPH}}-{{LEVEL REPRESENTATION LEARNING VIA MU}}- {{TUAL INFORMATION MAXIMIZATION}}},
  author = {Sun, Fan-Yun and Hoffmann, Jordan and Verma, Vikas and Tang, Jian},
  year = {2020},
  pages = {16},
  abstract = {This paper studies learning the representations of whole graphs in both unsupervised and semi-supervised scenarios. Graph-level representations are critical in a variety of real-world applications such as predicting the properties of molecules and community analysis in social networks. Traditional graph kernel based methods are simple, yet effective for obtaining fixed-length representations for graphs but they suffer from poor generalization due to hand-crafted designs. There are also some recent methods based on language models (e.g. graph2vec) but they tend to only consider certain substructures (e.g. subtrees) as graph representatives. Inspired by recent progress of unsupervised representation learning, in this paper we proposed a novel method called InfoGraph for learning graph-level representations. We maximize the mutual information between the graph-level representation and the representations of substructures of different scales (e.g., nodes, edges, triangles). By doing so, the graph-level representations encode aspects of the data that are shared across different scales of substructures. Furthermore, we further propose InfoGraph*, an extension of InfoGraph for semi-supervised scenarios. InfoGraph* maximizes the mutual information between unsupervised graph representations learned by InfoGraph and the representations learned by existing supervised methods. As a result, the supervised encoder learns from unlabeled data while preserving the latent semantic space favored by the current supervised task. Experimental results on the tasks of graph classification and molecular property prediction show that InfoGraph is superior to state-of-the-art baselines and InfoGraph* can achieve performance competitive with state-of-the-art semi-supervised models.},
  file = {D\:\\Filez\\Zetero\\storage\\824LHMIJ\\Sun 等。 - 2020 - INFOGRAPH UNSUPERVISED AND SEMI-SUPERVISED GRAPH-.pdf},
  language = {en}
}

@article{sureshAdversarialGraphAugmentation2021,
  title = {Adversarial {{Graph Augmentation}} to {{Improve Graph Contrastive Learning}}},
  author = {Suresh, Susheel and Li, Pan and Hao, Cong and Neville, Jennifer},
  year = {2021},
  month = nov,
  abstract = {Self-supervised learning of graph neural networks (GNN) is in great need because of the widespread label scarcity issue in real-world graph/network data. Graph contrastive learning (GCL), by training GNNs to maximize the correspondence between the representations of the same graph in its different augmented forms, may yield robust and transferable GNNs even without using labels. However, GNNs trained by traditional GCL often risk capturing redundant graph features and thus may be brittle and provide sub-par performance in downstream tasks. Here, we propose a novel principle, termed adversarial-GCL (AD-GCL), which enables GNNs to avoid capturing redundant information during the training by optimizing adversarial graph augmentation strategies used in GCL. We pair AD-GCL with theoretical explanations and design a practical instantiation based on trainable edge-dropping graph augmentation. We experimentally validate AD-GCL2 by comparing with the state-of-the-art GCL methods and achieve performance gains of up-to 14\% in unsupervised, 6\% in transfer, and 3\% in semi-supervised learning settings overall with 18 different benchmark datasets for the tasks of molecule property regression and classification, and social network classification.},
  archivePrefix = {arXiv},
  eprint = {2106.05819},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\YHXTESLQ\\Suresh 等。 - 2021 - Adversarial Graph Augmentation to Improve Graph Co.pdf},
  journal = {arXiv:2106.05819 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@incollection{suWhenDoesSelfsupervision2020,
  title = {When {{Does Self}}-Supervision {{Improve Few}}-{{Shot Learning}}?},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2020},
  author = {Su, Jong-Chyi and Maji, Subhransu and Hariharan, Bharath},
  editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
  year = {2020},
  volume = {12352},
  pages = {645--666},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-58571-6_38},
  abstract = {We investigate the role of self-supervised learning (SSL) in the context of few-shot learning. Although recent research has shown the benefits of SSL on large unlabeled datasets, its utility on small datasets is relatively unexplored. We find that SSL reduces the relative error rate of few-shot meta-learners by 4\%-27\%, even when the datasets are small and only utilizing images within the datasets. The improvements are greater when the training set is smaller or the task is more challenging. Although the benefits of SSL may increase with larger training sets, we observe that SSL can hurt the performance when the distributions of images used for meta-learning and SSL are different. We conduct a systematic study by varying the degree of domain shift and analyzing the performance of several meta-learners on a multitude of domains. Based on this analysis we present a technique that automatically selects images for SSL from a large, generic pool of unlabeled images for a given dataset that provides further improvements.},
  file = {D\:\\Filez\\Zetero\\storage\\WMP9Q2GM\\Su et al_2020_When Does Self-supervision Improve Few-Shot Learning.pdf},
  isbn = {978-3-030-58570-9 978-3-030-58571-6},
  language = {en}
}

@article{tangMultiSampleBasedContrastive2021,
  title = {Multi-{{Sample}} Based {{Contrastive Loss}} for {{Top}}-k {{Recommendation}}},
  author = {Tang, Hao and Zhao, Guoshuai and Wu, Yuxia and Qian, Xueming},
  year = {2021},
  month = sep,
  abstract = {The top-k recommendation is a fundamental task in recommendation systems which is generally learned by comparing positive and negative pairs. The Contrastive Loss (CL) is the key in contrastive learning that has received more attention recently and we find it is well suited for top-k recommendations. However, it is a problem that CL treats the importance of the positive and negative samples as the same. On the one hand, CL faces the imbalance problem of one positive sample and many negative samples. On the other hand, positive items are so few in sparser datasets that their importance should be emphasized. Moreover, the other important issue is that the sparse positive items are still not sufficiently utilized in recommendations. So we propose a new data augmentation method by using multiple positive items (or samples) simultaneously with the CL loss function. Therefore, we propose a Multi-Sample based Contrastive Loss (MSCL) function which solves the two problems by balancing the importance of positive and negative samples and data augmentation. And based on the graph convolution network (GCN) method, experimental results demonstrate the state-of-the-art performance of MSCL. The proposed MSCL is simple and can be applied in many methods. We will release our code on GitHub upon the acceptance.},
  archivePrefix = {arXiv},
  eprint = {2109.00217},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\8N9H2ZUU\\Tang 等。 - 2021 - Multi-Sample based Contrastive Loss for Top-k Reco.pdf},
  journal = {arXiv:2109.00217 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{tangMultisamplebasedContrastiveLoss2021,
  title = {Multisample-Based {{Contrastive Loss}} for {{Top}}-k {{Recommendation}}},
  author = {Tang, Hao and Zhao, Guoshuai and Wu, Yuxia and Qian, Xueming},
  year = {2021},
  pages = {1--1},
  issn = {1520-9210, 1941-0077},
  doi = {10.1109/TMM.2021.3126146},
  abstract = {The top-k recommendation is a fundamental task in recommendation systems which is generally learned by comparing positive and negative pairs. The Contrastive Loss (CL) is the key in contrastive learning that has received more attention recently and we find it is well suited for top-k recommendations. However, it is a problem that CL treats the importance of the positive and negative samples as the same. On the one hand, CL faces the imbalance problem of one positive sample and many negative samples. On the other hand, positive items are so few in sparser datasets that their importance should be emphasized. Moreover, the other important issue is that the sparse positive items are still not sufficiently utilized in recommendations. So we propose a new data augmentation method by using multiple positive items (or samples) simultaneously with the CL loss function. Therefore, we propose a Multi-Sample based Contrastive Loss (MSCL) function which solves the two problems by balancing the importance of positive and negative samples and data augmentation. And based on the graph convolution network (GCN) method, experimental results demonstrate the state-of-the-art performance of MSCL. The proposed MSCL is simple and can be applied in many methods. We will release our code on GitHub upon the acceptance.},
  file = {D\:\\Filez\\Zetero\\storage\\25YXMVC6\\Tang et al_2021_Multisample-based Contrastive Loss for Top-k Recommendation.pdf},
  journal = {IEEE Transactions on Multimedia},
  language = {en}
}

@inproceedings{tianSelfsupervisedRepresentationLearning2021,
  title = {Self-Supervised {{Representation Learning}} on {{Dynamic Graphs}}},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Tian, Sheng and Wu, Ruofan and Shi, Leilei and Zhu, Liang and Xiong, Tao},
  year = {2021},
  month = oct,
  pages = {1814--1823},
  publisher = {{ACM}},
  address = {{Virtual Event Queensland Australia}},
  doi = {10.1145/3459637.3482389},
  abstract = {Graph representation learning has now become the de facto standard when dealing with graph-structured data. Using powerful tools from deep learning and graph neural networks, recent works have applied graph representation learning to time-evolving dynamic graphs and showed promising results. However, all the previous dynamic graph models require labeled samples to train, which might be costly to acquire in practice. Self-supervision offers a principled way of utilizing unlabeled data and has achieved great success in the computer vision community. In this paper, we propose debiased dynamic graph contrastive learning (DDGCL ), the first self-supervised representation learning framework on dynamic graphs. The proposed model extends the contrastive learning idea to dynamic graphs via contrasting two nearby temporal views of the same node identity, with a time-dependent similarity critic. Inspired by recent theoretical developments in contrastive learning, we propose a novel debiased GAN-type contrastive loss as the learning objective to correct the sampling bias that occurred in the negative sample construction process. We conduct extensive experiments on benchmark datasets via testing the DDGCL framework under two different self-supervision schemes: pretraining and finetuning and multi-task learning. The results show that using a simple time-aware GNN encoder, the performance of the downstream tasks is significantly improved under either scheme to closely match, or even outperform state-of-the-art dynamic graph models with more elegant encoder architectures. Further empirical evaluations suggest that the proposed approach offers more performance improvement than previously established self-supervision mechanisms over static graphs.},
  file = {D\:\\Filez\\Zetero\\storage\\9W2LHH2N\\Tian 等。 - 2021 - Self-supervised Representation Learning on Dynamic.pdf},
  isbn = {978-1-4503-8446-9},
  language = {en}
}

@article{tianWhatMakesGood,
  title = {What {{Makes}} for {{Good Views}} for {{Contrastive Learning}}?},
  author = {Tian, Yonglong and Krishnan, Dilip and Sun, Chen and Schmid, Cordelia and Poole, Ben and Isola, Phillip},
  pages = {13},
  abstract = {Contrastive learning between multiple views of the data has recently achieved state of the art performance in the field of self-supervised representation learning. Despite its success, the influence of different view choices has been less studied. In this paper, we use theoretical and empirical analysis to better understand the importance of view selection, and argue that we should reduce the mutual information (MI) between views while keeping task-relevant information intact. To verify this hypothesis, we devise unsupervised and semi-supervised frameworks that learn effective views by aiming to reduce their MI. We also consider data augmentation as a way to reduce MI, and show that increasing data augmentation indeed leads to decreasing MI and improves downstream classification accuracy. As a byproduct, we achieve a new state-of-the-art accuracy on unsupervised pre-training for ImageNet classification (73\% top-1 linear readout with a ResNet-50)1.},
  file = {D\:\\Filez\\Zetero\\storage\\LD8YFIGT\\Tian 等。 - What Makes for Good Views for Contrastive Learning.pdf},
  language = {en}
}

@inproceedings{tongPatternenhancedContrastivePolicy2021,
  title = {Pattern-Enhanced {{Contrastive Policy Learning Network}} for {{Sequential Recommendation}}},
  booktitle = {Proceedings of the {{Thirtieth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Tong, Xiaohai and Wang, Pengfei and Li, Chenliang and Xia, Long and Niu, Shaozhang},
  year = {2021},
  month = aug,
  pages = {1593--1599},
  publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
  address = {{Montreal, Canada}},
  doi = {10.24963/ijcai.2021/220},
  abstract = {Sequential recommendation aims to predict users' future behaviors given their historical interactions. However, due to the randomness and diversity of a user's behaviors, not all historical items are informative to tell his/her next choice. It is obvious that identifying relevant items and extracting meaningful sequential patterns are necessary for a better recommendation. Unfortunately, few works have focused on this sequence denoising process.},
  file = {D\:\\Filez\\Zetero\\storage\\52QRGGCV\\notes.md;D\:\\Filez\\Zetero\\storage\\9AW3DRYG\\Tong et al_2021_Pattern-enhanced Contrastive Policy Learning Network for Sequential.pdf},
  isbn = {978-0-9992411-9-6},
  language = {en}
}

@article{trivediAugmentationsGraphContrastive2021,
  title = {Augmentations in {{Graph Contrastive Learning}}: {{Current Methodological Flaws}} \& {{Towards Better Practices}}},
  shorttitle = {Augmentations in {{Graph Contrastive Learning}}},
  author = {Trivedi, Puja and Lubana, Ekdeep Singh and Yan, Yujun and Yang, Yaoqing and Koutra, Danai},
  year = {2021},
  month = nov,
  abstract = {Graph classification has a wide range of applications in bioinformatics, social sciences, automated fake news detection, web document classification, and more. In many practical scenarios, including web-scale applications, where labels are scarce or hard to obtain, unsupervised learning is a natural paradigm but it trades off performance. Recently, contrastive learning (CL) has enabled unsupervised computer vision models to compete well against supervised ones. Theoretical and empirical works analyzing visual CL frameworks find that leveraging large datasets and domain relevant augmentations is essential for framework success. Interestingly, graph CL frameworks report high performance while using orders of magnitude smaller data, and employing domain-agnostic augmentations (e.g., node or edge dropping, feature perturbations) that can corrupt the graphs' underlying properties. Motivated by these discrepancies, we seek to determine: (i) why existing graph CL frameworks perform well despite weak augmentations and limited data; and (ii) whether adhering to visual CL principles can improve performance on graph classification tasks. Through extensive analysis, we identify flawed practices in graph data augmentation and evaluation protocols that are commonly used in the graph CL literature, and propose improved practices and sanity checks for future research and applications. We show that on small benchmark datasets, the inductive bias of graph neural networks can significantly compensate for the limitations of existing frameworks. In case studies with relatively larger graph classification tasks, we find that commonly used domain-agnostic augmentations perform poorly, while adhering to principles in visual CL can significantly improve performance. For example, in graph-based document classification, which can be used for better web search, we show task-relevant augmentations improve accuracy by 20\%.},
  archivePrefix = {arXiv},
  eprint = {2111.03220},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\T7ECIKCY\\Trivedi 等。 - 2021 - Augmentations in Graph Contrastive Learning Curre.pdf},
  journal = {arXiv:2111.03220 [cs]},
  keywords = {Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{truongBilateralVariationalAutoencoder2021,
  title = {Bilateral {{Variational Autoencoder}} for {{Collaborative Filtering}}},
  booktitle = {Proceedings of the 14th {{ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Truong, Quoc-Tuan and Salah, Aghiles and Lauw, Hady W.},
  year = {2021},
  month = mar,
  pages = {292--300},
  publisher = {{ACM}},
  address = {{Virtual Event Israel}},
  doi = {10.1145/3437963.3441759},
  abstract = {Preference data is a form of dyadic data, with measurements associated with pairs of elements arising from two discrete sets of objects. These are users and items, as well as their interactions, e.g., ratings. We are interested in learning representations for both sets of objects, i.e., users and items, to predict unknown pairwise interactions. Motivated by the recent successes of deep latent variable models, we propose Bilateral Variational Autoencoder (BiVAE), which arises from a combination of a generative model of dyadic data with two inference models, user- and item-based, parameterized by neural networks. Interestingly, our model can take the form of a Bayesian variational autoencoder either on the user or item side. As opposed to the vanilla VAE model, BiVAE is ``bilateral'', in that users and items are treated similarly, making it more apt for two-way or dyadic data. While theoretically sound, we formally show that, similarly to VAE, our model might suffer from an over-regularized latent space. This issue, known as posterior collapse in the VAE literature, may appear due to assuming an over-simplified prior (isotropic Gaussian) over the latent space. Hence, we further propose a mitigation of this issue by introducing constrained adaptive prior (CAP) for learning userand item-dependent prior distributions. Empirical results on several real-world datasets show that the proposed model outperforms conventional VAE and other comparative collaborative filtering models in terms of item recommendation. Moreover, the proposed CAP further boosts the performance of BiVAE. An implementation of BiVAE is available on Cornac recommender library.},
  file = {D\:\\Filez\\Zetero\\storage\\R2Q4JR67\\3437963.pdf},
  isbn = {978-1-4503-8297-7},
  language = {en}
}

@inproceedings{wangAutomatedMachineLearning2021,
  title = {Automated {{Machine Learning}} on {{Graph}}},
  booktitle = {Proceedings of the 27th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Wang, Xin and Zhu, Wenwu},
  year = {2021},
  month = aug,
  pages = {4082--4083},
  publisher = {{ACM}},
  address = {{Virtual Event Singapore}},
  doi = {10.1145/3447548.3470804},
  abstract = {Machine learning on graphs has been extensively studied in both academic and industry. However, as the literature on graph learning booms with a vast number of emerging methods and techniques, it becomes increasingly difficult to manually design the optimal machine learning algorithm for different graph-related tasks. To solve this critical challenge, automated machine learning (AutoML) on graphs which combines the strength of graph machine learning and AutoML together, is gaining attentions from the research community. In this tutorial, we discuss AutoML on graphs, primarily focusing on hyper-parameter optimization (HPO) and neural architecture search (NAS) for graph machine learning. We further overview libraries related to automated graph machine learning and in depth discuss AutoGL, the first dedicated open-source library for AutoML on graphs. In the end, we share our insights on future research directions for automated graph machine learning. To the best of our knowledge, this tutorial is the first to systematically and comprehensively review automated machine learning on graphs, possessing a great potential to draw a large amount of interests in the community.},
  file = {D\:\\Filez\\Zetero\\storage\\GYMFDJN7\\Wang 和 Zhu - 2021 - Automated Machine Learning on Graph.pdf},
  isbn = {978-1-4503-8332-5},
  language = {en}
}

@inproceedings{wangAutomatedMachineLearning2021a,
  title = {Automated {{Machine Learning}} on {{Graph}}},
  booktitle = {Proceedings of the 27th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Wang, Xin and Zhu, Wenwu},
  year = {2021},
  month = aug,
  pages = {4082--4083},
  publisher = {{ACM}},
  address = {{Virtual Event Singapore}},
  doi = {10.1145/3447548.3470804},
  abstract = {Machine learning on graphs has been extensively studied in both academic and industry. However, as the literature on graph learning booms with a vast number of emerging methods and techniques, it becomes increasingly difficult to manually design the optimal machine learning algorithm for different graph-related tasks. To solve this critical challenge, automated machine learning (AutoML) on graphs which combines the strength of graph machine learning and AutoML together, is gaining attentions from the research community. In this tutorial, we discuss AutoML on graphs, primarily focusing on hyper-parameter optimization (HPO) and neural architecture search (NAS) for graph machine learning. We further overview libraries related to automated graph machine learning and in depth discuss AutoGL, the first dedicated open-source library for AutoML on graphs. In the end, we share our insights on future research directions for automated graph machine learning. To the best of our knowledge, this tutorial is the first to systematically and comprehensively review automated machine learning on graphs, possessing a great potential to draw a large amount of interests in the community.},
  file = {D\:\\Filez\\Zetero\\storage\\7XJ5TRRD\\Wang 和 Zhu - 2021 - Automated Machine Learning on Graph.pdf},
  isbn = {978-1-4503-8332-5},
  language = {en}
}

@article{wangCollaborativeRecurrentAutoencoder,
  title = {Collaborative {{Recurrent Autoencoder}}: {{Recommend}} While {{Learning}} to {{Fill}} in the {{Blanks}}},
  author = {Wang, Hao and Shi, Xingjian and Yeung, Dit-Yan},
  pages = {9},
  abstract = {Hybrid methods that utilize both content and rating information are commonly used in many recommender systems. However, most of them use either handcrafted features or the bag-of-words representation as a surrogate for the content information but they are neither effective nor natural enough. To address this problem, we develop a collaborative recurrent autoencoder (CRAE) which is a denoising recurrent autoencoder (DRAE) that models the generation of content sequences in the collaborative filtering (CF) setting. The model generalizes recent advances in recurrent deep learning from i.i.d. input to non-i.i.d. (CF-based) input and provides a new denoising scheme along with a novel learnable pooling scheme for the recurrent autoencoder. To do this, we first develop a hierarchical Bayesian model for the DRAE and then generalize it to the CF setting. The synergy between denoising and CF enables CRAE to make accurate recommendations while learning to fill in the blanks in sequences. Experiments on real-world datasets from different domains (CiteULike and Netflix) show that, by jointly modeling the order-aware generation of sequences for the content information and performing CF for the ratings, CRAE is able to significantly outperform the state of the art on both the recommendation task based on ratings and the sequence generation task based on content information.},
  file = {D\:\\Filez\\Zetero\\storage\\8MQWSNNQ\\Wang 等。 - Collaborative Recurrent Autoencoder Recommend whi.pdf},
  language = {en}
}

@article{wangContrastiveLearningStronger2021,
  title = {Contrastive {{Learning}} with {{Stronger Augmentations}}},
  author = {Wang, Xiao and Qi, Guo-Jun},
  year = {2021},
  month = apr,
  abstract = {Representation learning has significantly been developed with the advance of contrastive learning methods. Most of those methods have benefited from various data augmentations that are carefully designated to maintain their identities so that the images transformed from the same instance can still be retrieved. However, those carefully designed transformations limited us to further explore the novel patterns exposed by other transformations. Meanwhile, as found in our experiments, the strong augmentations distorted the images' structures, resulting in difficult retrieval. Thus, we propose a general framework called Contrastive Learning with Stronger Augmentations (CLSA) to complement current contrastive learning approaches. Here, the distribution divergence between the weakly and strongly augmented images over the representation bank is adopted to supervise the retrieval of strongly augmented queries from a pool of instances. Experiments on the ImageNet dataset and downstream datasets showed the information from the strongly augmented images can significantly boost the performance. For example, CLSA achieves top-1 accuracy of 76.2\% on ImageNet with a standard ResNet-50 architecture with a single-layer classifier fine-tuned, which is almost the same level as 76.5\% of supervised results. The code and pre-trained models are available in https://github.com/maple-research-lab/CLSA.},
  archivePrefix = {arXiv},
  eprint = {2104.07713},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\WUPA3KJY\\Wang_Qi_2021_Contrastive Learning with Stronger Augmentations.pdf},
  journal = {arXiv:2104.07713 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{wangDemiNetDependencyAwareMultiInterest2021,
  title = {{{DemiNet}}: {{Dependency}}-{{Aware Multi}}-{{Interest Network}} with {{Self}}-{{Supervised Graph Learning}} for {{Click}}-{{Through Rate Prediction}}},
  shorttitle = {{{DemiNet}}},
  author = {Wang, Yule and Luo, Qiang and Ding, Yue and Wang, Dong and Deng, Hongbo},
  year = {2021},
  month = sep,
  abstract = {Click-through rate (CTR) prediction is one of the the most important tasks in modern search engine, recommendation and advertising systems. Recently, some existing models leverage user's historical behaviors for multiple interest modeling. However, there remain two main challenges in the prior works: (1) Raw user behavior sequence is noisy and intertwined, making it difficult to extract multiple core interests. (2) The latent correlations between extracted multiple interest vectors are neglected, leading to information loss.},
  archivePrefix = {arXiv},
  eprint = {2109.12512},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\BL3DIKJB\\Wang et al_2021_DemiNet.pdf},
  journal = {arXiv:2109.12512 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{wangDomainSpecificSuppressionAdaptive2021,
  title = {Domain-{{Specific Suppression}} for {{Adaptive Object Detection}}},
  author = {Wang, Yu and Zhang, Rui and Zhang, Shuo and Li, Miao and Xia, YangYang and Zhang, XiShan and Liu, ShaoLi},
  year = {2021},
  month = may,
  abstract = {Domain adaptation methods face performance degradation in object detection, as the complexity of tasks require more about the transferability of the model. We propose a new perspective on how CNN models gain the transferability, viewing the weights of a model as a series of motion patterns. The directions of weights, and the gradients, can be divided into domain-specific and domain-invariant parts, and the goal of domain adaptation is to concentrate on the domain-invariant direction while eliminating the disturbance from domain-specific one. Current UDA object detection methods view the two directions as a whole while optimizing, which will cause domain-invariant direction mismatch even if the output features are perfectly aligned. In this paper, we propose the domain-specific suppression, an exemplary and generalizable constraint to the original convolution gradients in backpropagation to detach the two parts of directions and suppress the domain-specific one. We further validate our theoretical analysis and methods on several domain adaptive object detection tasks, including weather, camera configuration, and synthetic to realworld adaptation. Our experiment results show significant advance over the state-of-the-art methods in the UDA object detection field, performing a promotion of 10.2 {$\sim$} 12.2\% mAP on all these domain adaptation scenarios.},
  archivePrefix = {arXiv},
  eprint = {2105.03570},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\FAZ8W53S\\Wang et al_2021_Domain-Specific Suppression for Adaptive Object Detection.pdf},
  journal = {arXiv:2105.03570 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  language = {en},
  primaryClass = {cs}
}

@article{wangGraphLearningBased2021,
  title = {Graph {{Learning}} Based {{Recommender Systems}}: {{A Review}}},
  shorttitle = {Graph {{Learning}} Based {{Recommender Systems}}},
  author = {Wang, Shoujin and Hu, Liang and Wang, Yan and He, Xiangnan and Sheng, Quan Z. and Orgun, Mehmet A. and Cao, Longbing and Ricci, Francesco and Yu, Philip S.},
  year = {2021},
  month = may,
  abstract = {Recent years have witnessed the fast development of the emerging topic of Graph Learning based Recommender Systems (GLRS). GLRS employ advanced graph learning approaches to model users' preferences and intentions as well as items' characteristics for recommendations. Differently from other RS approaches, including content-based filtering and collaborative filtering, GLRS are built on graphs where the important objects, e.g., users, items, and attributes, are either explicitly or implicitly connected. With the rapid development of graph learning techniques, exploring and exploiting homogeneous or heterogeneous relations in graphs are a promising direction for building more effective RS. In this paper, we provide a systematic review of GLRS, by discussing how they extract important knowledge from graph-based representations to improve the accuracy, reliability and explainability of the recommendations. First, we characterize and formalize GLRS, and then summarize and categorize the key challenges and main progress in this novel research area. Finally, we share some new research directions in this vibrant area.},
  archivePrefix = {arXiv},
  eprint = {2105.06339},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\6HK2YBY3\\Wang 等。 - 2021 - Graph Learning based Recommender Systems A Review.pdf},
  journal = {arXiv:2105.06339 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{wangInstancewiseHardNegative2021,
  title = {Instance-Wise {{Hard Negative Example Generation}} for {{Contrastive Learning}} in {{Unpaired Image}}-to-{{Image Translation}}},
  author = {Wang, Weilun and Zhou, Wengang and Bao, Jianmin and Chen, Dong and Li, Houqiang},
  year = {2021},
  month = aug,
  abstract = {Contrastive learning shows great potential in unpaired image-to-image translation, but sometimes the translated results are in poor quality and the contents are not preserved consistently. In this paper, we uncover that the negative examples play a critical role in the performance of contrastive learning for image translation. The negative examples in previous methods are randomly sampled from the patches of different positions in the source image, which are not effective to push the positive examples close to the query examples. To address this issue, we present instance-wise hard Negative Example Generation for Contrastive learning in Unpaired image-to-image Translation (NEGCUT). Specifically, we train a generator to produce negative examples online. The generator is novel from two perspectives: 1) it is instance-wise which means that the generated examples are based on the input image, and 2) it can generate hard negative examples since it is trained with an adversarial loss. With the generator, the performance of unpaired image-to-image translation is significantly improved. Experiments on three benchmark datasets demonstrate that the proposed NEGCUT framework achieves state-of-the-art performance compared to previous methods.},
  archivePrefix = {arXiv},
  eprint = {2108.04547},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\4GAVFBLR\\Wang et al_2021_Instance-wise Hard Negative Example Generation for Contrastive Learning in.pdf},
  journal = {arXiv:2108.04547 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  language = {en},
  primaryClass = {cs}
}

@article{wangPretrainingGraphNeural2021,
  title = {Pre-Training {{Graph Neural Network}} for {{Cross Domain Recommendation}}},
  author = {Wang, Chen and Liang, Yueqing and Liu, Zhiwei and Zhang, Tao and Yu, Philip S.},
  year = {2021},
  month = nov,
  abstract = {A recommender system predicts users' potential interests in items, where the core is to learn user/item embeddings. Nevertheless, it suffers from the data-sparsity issue, which the cross-domain recommendation can alleviate. However, most prior works either jointly learn the source domain and target domain models, or require side-features. However, jointly training and side features would affect the prediction on the target domain as the learned embedding is dominated by the source domain containing bias information. Inspired by the contemporary arts in pre-training from graph representation learning, we propose a pre-training and fine-tuning diagram for cross-domain recommendation. We devise a novel Pre-training Graph Neural Network for Cross-Domain Recommendation (PCRec), which adopts the contrastive self-supervised pre-training of a graph encoder. Then, we transfer the pre-trained graph encoder to initialize the node embeddings on the target domain, which benefits the fine-tuning of the single domain recommender system on the target domain. The experimental results demonstrate the superiority of PCRec. Detailed analyses verify the superiority of PCRec in transferring information while avoiding biases from source domains.},
  archivePrefix = {arXiv},
  eprint = {2111.08268},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\NPMDBG34\\Wang et al_2021_Pre-training Graph Neural Network for Cross Domain Recommendation.pdf},
  journal = {arXiv:2111.08268 [cs]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{wangSelfsupervisedHeterogeneousGraph2021,
  title = {Self-Supervised {{Heterogeneous Graph Neural Network}} with {{Co}}-Contrastive {{Learning}}},
  booktitle = {Proceedings of the 27th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Wang, Xiao and Liu, Nian and Han, Hui and Shi, Chuan},
  year = {2021},
  month = aug,
  pages = {1726--1736},
  publisher = {{ACM}},
  address = {{Virtual Event Singapore}},
  doi = {10.1145/3447548.3467415},
  abstract = {Heterogeneous graph neural networks (HGNNs) as an emerging technique have shown superior capacity of dealing with heterogeneous information network (HIN). However, most HGNNs follow a semi-supervised learning manner, which notably limits their wide use in reality since labels are usually scarce in real applications. Recently, contrastive learning, a self-supervised method, becomes one of the most exciting learning paradigms and shows great potential when there are no labels. In this paper, we study the problem of self-supervised HGNNs and propose a novel co-contrastive learning mechanism for HGNNs, named HeCo. Different from traditional contrastive learning which only focuses on contrasting positive and negative samples, HeCo employs cross-view contrastive mechanism. Specifically, two views of a HIN (network schema and meta-path views) are proposed to learn node embeddings, so as to capture both of local and high-order structures simultaneously. Then the cross-view contrastive learning, as well as a view mask mechanism, is proposed, which is able to extract the positive and negative embeddings from two views. This enables the two views to collaboratively supervise each other and finally learn high-level node embeddings. Moreover, two extensions of HeCo are designed to generate harder negative samples with high quality, which further boosts the performance of HeCo. Extensive experiments conducted on a variety of real-world networks show the superior performance of the proposed methods over the state-of-the-arts.},
  file = {D\:\\Filez\\Zetero\\storage\\7XMYI7X6\\Wang et al_2021_Self-supervised Heterogeneous Graph Neural Network with Co-contrastive Learning.pdf},
  isbn = {978-1-4503-8332-5},
  language = {en}
}

@inproceedings{wangSelfsupervisedHeterogeneousGraph2021a,
  title = {Self-Supervised {{Heterogeneous Graph Neural Network}} with {{Co}}-Contrastive {{Learning}}},
  booktitle = {Proceedings of the 27th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Wang, Xiao and Liu, Nian and Han, Hui and Shi, Chuan},
  year = {2021},
  month = aug,
  pages = {1726--1736},
  publisher = {{ACM}},
  address = {{Virtual Event Singapore}},
  doi = {10.1145/3447548.3467415},
  abstract = {Heterogeneous graph neural networks (HGNNs) as an emerging technique have shown superior capacity of dealing with heterogeneous information network (HIN). However, most HGNNs follow a semi-supervised learning manner, which notably limits their wide use in reality since labels are usually scarce in real applications. Recently, contrastive learning, a self-supervised method, becomes one of the most exciting learning paradigms and shows great potential when there are no labels. In this paper, we study the problem of self-supervised HGNNs and propose a novel co-contrastive learning mechanism for HGNNs, named HeCo. Different from traditional contrastive learning which only focuses on contrasting positive and negative samples, HeCo employs cross-view contrastive mechanism. Specifically, two views of a HIN (network schema and meta-path views) are proposed to learn node embeddings, so as to capture both of local and high-order structures simultaneously. Then the cross-view contrastive learning, as well as a view mask mechanism, is proposed, which is able to extract the positive and negative embeddings from two views. This enables the two views to collaboratively supervise each other and finally learn high-level node embeddings. Moreover, two extensions of HeCo are designed to generate harder negative samples with high quality, which further boosts the performance of HeCo. Extensive experiments conducted on a variety of real-world networks show the superior performance of the proposed methods over the state-of-the-arts.},
  file = {D\:\\Filez\\Zetero\\storage\\7M4WPYNZ\\3447548.pdf},
  isbn = {978-1-4503-8332-5},
  language = {en}
}

@article{wangSurveySessionbasedRecommender2022,
  title = {A {{Survey}} on {{Session}}-Based {{Recommender Systems}}},
  author = {Wang, Shoujin and Cao, Longbing and Wang, Yan and Sheng, Quan Z. and Orgun, Mehmet A. and Lian, Defu},
  year = {2022},
  month = sep,
  volume = {54},
  pages = {1--38},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3465401},
  abstract = {Recommender systems (RSs) have been playing an increasingly important role for informed consumption, services, and decision-making in the overloaded information era and digitized economy. In recent years, session-based recommender systems (SBRSs) have emerged as a new paradigm of RSs. Different from other RSs such as content-based RSs and collaborative filtering-based RSs that usually model long-term yet static user preferences, SBRSs aim to capture short-term but dynamic user preferences to provide more timely and accurate recommendations sensitive to the evolution of their session contexts. Although SBRSs have been intensively studied, neither unified problem statements for SBRSs nor in-depth elaboration of SBRS characteristics and challenges are available. It is also unclear to what extent SBRS challenges have been addressed and what the overall research landscape of SBRSs is. This comprehensive review of SBRSs addresses the above aspects by exploring in depth the SBRS entities (e.g., sessions), behaviours (e.g., users' clicks on items), and their properties (e.g., session length). We propose a general problem statement of SBRSs, summarize the diversified data characteristics and challenges of SBRSs, and define a taxonomy to categorize the representative SBRS research. Finally, we discuss new research opportunities in this exciting and vibrant area.},
  file = {D\:\\Filez\\Zetero\\storage\\6SL8MJPY\\Wang 等。 - 2022 - A Survey on Session-based Recommender Systems.pdf},
  journal = {ACM Computing Surveys},
  language = {en},
  number = {7}
}

@inproceedings{weiContrastiveLearningColdStart2021,
  title = {Contrastive {{Learning}} for {{Cold}}-{{Start Recommendation}}},
  booktitle = {Proceedings of the 29th {{ACM International Conference}} on {{Multimedia}}},
  author = {Wei, Yinwei and Wang, Xiang and Li, Qi and Nie, Liqiang and Li, Yan and Li, Xuanping and Chua, Tat-Seng},
  year = {2021},
  month = oct,
  pages = {5382--5390},
  publisher = {{ACM}},
  address = {{Virtual Event China}},
  doi = {10.1145/3474085.3475665},
  abstract = {Recommending purely cold-start items is a long-standing and fundamental challenge in the recommender systems. Without any historical interaction on cold-start items, the collaborative filtering (CF) scheme fails to leverage collaborative signals to infer user preference on these items. To solve this problem, extensive studies have been conducted to incorporate side information of items (e.g., content features) into the CF scheme. Specifically, they employ modern neural network techniques (e.g., dropout, consistency constraint) to discover and exploit the coalition effect of content features and collaborative representations. However, we argue that these works less explore the mutual dependencies between content features and collaborative representations and lack sufficient theoretical supports, thus resulting in unsatisfactory performance on cold-start recommendation.},
  file = {D\:\\Filez\\Zetero\\storage\\QPTQ8M59\\Wei et al_2021_Contrastive Learning for Cold-Start Recommendation.pdf},
  isbn = {978-1-4503-8651-7},
  language = {en}
}

@article{weiParameterizationTyphooninducedOcean2017,
  title = {Parameterization of Typhoon-Induced Ocean Cooling Using Temperature Equation and Machine Learning Algorithms: An Example of Typhoon {{Soulik}} (2013)},
  shorttitle = {Parameterization of Typhoon-Induced Ocean Cooling Using Temperature Equation and Machine Learning Algorithms},
  author = {Wei, Jun and Jiang, Guo-Qing and Liu, Xin},
  year = {2017},
  month = sep,
  volume = {67},
  pages = {1179--1193},
  issn = {1616-7341, 1616-7228},
  doi = {10.1007/s10236-017-1082-z},
  file = {D\:\\Filez\\Zetero\\storage\\9LWV52PX\\Wei et al_2017_Parameterization of typhoon-induced ocean cooling using temperature equation.pdf},
  journal = {Ocean Dynamics},
  language = {en},
  number = {9}
}

@inproceedings{wortsmanLearningLearnHow2019,
  title = {Learning to {{Learn How}} to {{Learn}}: {{Self}}-{{Adaptive Visual Navigation Using Meta}}-{{Learning}}},
  shorttitle = {Learning to {{Learn How}} to {{Learn}}},
  booktitle = {2019 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Wortsman, Mitchell and Ehsani, Kiana and Rastegari, Mohammad and Farhadi, Ali and Mottaghi, Roozbeh},
  year = {2019},
  month = jun,
  pages = {6743--6752},
  publisher = {{IEEE}},
  address = {{Long Beach, CA, USA}},
  doi = {10.1109/CVPR.2019.00691},
  abstract = {Learning is an inherently continuous phenomenon. When humans learn a new task there is no explicit distinction between training and inference. As we learn a task, we keep learning about it while performing the task. What we learn and how we learn it varies during different stages of learning. Learning how to learn and adapt is a key property that enables us to generalize effortlessly to new settings. This is in contrast with conventional settings in machine learning where a trained model is frozen during inference. In this paper we study the problem of learning to learn at both training and test time in the context of visual navigation. A fundamental challenge in navigation is generalization to unseen scenes. In this paper we propose a self-adaptive visual navigation method (SAVN) which learns to adapt to new environments without any explicit supervision. Our solution is a meta-reinforcement learning approach where an agent learns a self-supervised interaction loss that encourages effective navigation. Our experiments, performed in the AI2-THOR framework, show major improvements in both success rate and SPL for visual navigation in novel scenes. Our code and data are available at: https://github.com/allenai/savn.},
  file = {D\:\\Filez\\Zetero\\storage\\JUX9B4IV\\Wortsman et al_2019_Learning to Learn How to Learn.pdf},
  isbn = {978-1-72813-293-8},
  language = {en}
}

@inproceedings{wuCollaborativeDenoisingAutoEncoders2016,
  title = {Collaborative {{Denoising Auto}}-{{Encoders}} for {{Top}}-{{N Recommender Systems}}},
  booktitle = {Proceedings of the {{Ninth ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Wu, Yao and DuBois, Christopher and Zheng, Alice X. and Ester, Martin},
  year = {2016},
  month = feb,
  pages = {153--162},
  publisher = {{ACM}},
  address = {{San Francisco California USA}},
  doi = {10.1145/2835776.2835837},
  abstract = {Most real-world recommender services measure their performance based on the top-N results shown to the end users. Thus, advances in top-N recommendation have far-ranging consequences in practical applications. In this paper, we present a novel method, called Collaborative Denoising Auto-Encoder (CDAE), for top-N recommendation that utilizes the idea of Denoising Auto-Encoders. We demonstrate that the proposed model is a generalization of several well-known collaborative filtering models but with more flexible components. Thorough experiments are conducted to understand the performance of CDAE under various component settings. Furthermore, experimental results on several public datasets demonstrate that CDAE consistently outperforms state-of-the-art top-N recommendation methods on a variety of common evaluation metrics.},
  file = {D\:\\Filez\\Zetero\\storage\\TTVALC9Y\\Wu 等。 - 2016 - Collaborative Denoising Auto-Encoders for Top-N Re.pdf},
  isbn = {978-1-4503-3716-8},
  language = {en}
}

@article{wuComprehensiveSurveyGraph2021,
  title = {A {{Comprehensive Survey}} on {{Graph Neural Networks}}},
  author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
  year = {2021},
  month = jan,
  volume = {32},
  pages = {4--24},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2020.2978386},
  abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.},
  archivePrefix = {arXiv},
  eprint = {1901.00596},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\MJMPF25Q\\notes.pptx;D\:\\Filez\\Zetero\\storage\\TURBEYWH\\Wu et al_2021_A Comprehensive Survey on Graph Neural Networks.pdf},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  number = {1}
}

@article{wuComprehensiveSurveyGraph2021a,
  title = {A {{Comprehensive Survey}} on {{Graph Neural Networks}}},
  author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
  year = {2021},
  month = jan,
  volume = {32},
  pages = {4--24},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2020.2978386},
  abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.},
  archivePrefix = {arXiv},
  eprint = {1901.00596},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\U7GYQGZV\\Wu et al_2021_A Comprehensive Survey on Graph Neural Networks.pdf},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  number = {1}
}

@article{wuComprehensiveSurveyGraph2021b,
  title = {A {{Comprehensive Survey}} on {{Graph Neural Networks}}},
  author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
  year = {2021},
  month = jan,
  volume = {32},
  pages = {4--24},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2020.2978386},
  abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.},
  archivePrefix = {arXiv},
  eprint = {1901.00596},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\PE58Q6DA\\Wu 等。 - 2021 - A Comprehensive Survey on Graph Neural Networks.pdf},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  number = {1}
}

@article{wuConditionalNegativeSampling2020,
  title = {Conditional {{Negative Sampling}} for {{Contrastive Learning}} of {{Visual Representations}}},
  author = {Wu, Mike and Mosse, Milan and Zhuang, Chengxu and Yamins, Daniel and Goodman, Noah},
  year = {2020},
  month = oct,
  abstract = {Recent methods for learning unsupervised visual representations, dubbed contrastive learning, optimize the noise-contrastive estimation (NCE) bound on mutual information between two views of an image. NCE uses randomly sampled negative examples to normalize the objective. In this paper, we show that choosing difficult negatives, or those more similar to the current instance, can yield stronger representations. To do this, we introduce a family of mutual information estimators that sample negatives conditionally \textendash{} in a ``ring'' around each positive. We prove that these estimators lower-bound mutual information, with higher bias but lower variance than NCE. Experimentally, we find our approach, applied on top of existing models (IR, CMC, and MoCo) improves accuracy by 2-5\% points in each case, measured by linear evaluation on four standard image datasets. Moreover, we find continued benefits when transferring features to a variety of new image distributions from the Meta-Dataset collection and to a variety of downstream tasks such as object detection, instance segmentation, and keypoint detection.},
  archivePrefix = {arXiv},
  eprint = {2010.02037},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\REPRP9HA\\Wu et al_2020_Conditional Negative Sampling for Contrastive Learning of Visual Representations.pdf},
  journal = {arXiv:2010.02037 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{wuGraphNeuralNetworks2021,
  title = {Graph {{Neural Networks}} in {{Recommender Systems}}: {{A Survey}}},
  shorttitle = {Graph {{Neural Networks}} in {{Recommender Systems}}},
  author = {Wu, Shiwen and Sun, Fei and Zhang, Wentao and Cui, Bin},
  year = {2021},
  month = apr,
  abstract = {Owing to the superiority of GNN in learning on graph data and its efficacy in capturing collaborative signals and sequential patterns, utilizing GNN techniques in recommender systems has gain increasing interests in academia and industry. In this survey, we provide a comprehensive review of the most recent works on GNN-based recommender systems. We proposed a classification scheme for organizing existing works. For each category, we briefly clarify the main issues, and detail the corresponding strategies adopted by the representative models. We also discuss the advantages and limitations of the existing strategies. Furthermore, we suggest several promising directions for future researches. We hope this survey can provide readers with a general understanding of the recent progress in this field, and shed some light on future developments.},
  archivePrefix = {arXiv},
  eprint = {2011.02260},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\NPGURP7R\\Wu 等。 - 2021 - Graph Neural Networks in Recommender Systems A Su.pdf},
  journal = {arXiv:2011.02260 [cs]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{wuSelfsupervisedGraphLearning2021,
  title = {Self-Supervised {{Graph Learning}} for {{Recommendation}}},
  booktitle = {Proceedings of the 44th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Wu, Jiancan and Wang, Xiang and Feng, Fuli and He, Xiangnan and Chen, Liang and Lian, Jianxun and Xie, Xing},
  year = {2021},
  month = jul,
  pages = {726--735},
  publisher = {{ACM}},
  address = {{Virtual Event Canada}},
  doi = {10.1145/3404835.3462862},
  abstract = {Representation learning on user-item graph for recommendation has evolved from using single ID or interaction history to exploiting higher-order neighbors. This leads to the success of graph convolution networks (GCNs) for recommendation such as PinSage and LightGCN. Despite effectiveness, we argue that they suffer from two limitations: (1) high-degree nodes exert larger impact on the representation learning, deteriorating the recommendations of low-degree (long-tail) items; and (2) representations are vulnerable to noisy interactions, as the neighborhood aggregation scheme further enlarges the impact of observed edges.},
  file = {D\:\\Filez\\Zetero\\storage\\744GBWPY\\Wu et al_2021_Self-supervised Graph Learning for Recommendation.pdf;D\:\\Filez\\Zetero\\storage\\FLNT46FI\\notes.md;D\:\\Filez\\Zetero\\storage\\WMB9K6PU\\SGL-main.zip},
  isbn = {978-1-4503-8037-9},
  language = {en}
}

@article{wuSelfsupervisedLearningGraphs2021,
  title = {Self-Supervised {{Learning}} on {{Graphs}}: {{Contrastive}}, {{Generative}},or {{Predictive}}},
  shorttitle = {Self-Supervised {{Learning}} on {{Graphs}}},
  author = {Wu, Lirong and Lin, Haitao and Tan, Cheng and Gao, Zhangyang and Li, Stan Z.},
  year = {2021},
  pages = {1--1},
  issn = {1041-4347, 1558-2191, 2326-3865},
  doi = {10.1109/TKDE.2021.3131584},
  abstract = {Deep learning on graphs has recently achieved remarkable success on a variety of tasks, while such success relies heavily on the massive and carefully labeled data. However, precise annotations are generally very expensive and time-consuming. To address this problem, self-supervised learning (SSL) is emerging as a new paradigm for extracting informative knowledge through well-designed pretext tasks without relying on manual labels. In this survey, we extend the concept of SSL, which first emerged in the fields of computer vision and natural language processing, to present a timely and comprehensive review of existing SSL techniques for graph data. Specifically, we divide existing graph SSL methods into three categories: contrastive, generative, and predictive. More importantly, unlike other surveys that only provide a high-level description of published research, we present an additional mathematical summary of existing works in a unified framework. Furthermore, to facilitate methodological development and empirical comparisons, we also summarize the commonly used datasets, evaluation metrics, downstream tasks, open-source implementations, and experimental study of various algorithms. Finally, we discuss the technical challenges and potential future directions for improving graph self-supervised learning. Latest advances in graph SSL are summarized in a GitHub repository https://github.com/LirongWu/awesome-graph-self-supervised-learning.},
  file = {D\:\\Filez\\Zetero\\storage\\5E55TVYL\\Wu 等。 - 2021 - Self-supervised Learning on Graphs Contrastive, G.pdf},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  language = {en}
}

@article{wuSelfsupervisedLearningGraphs2021a,
  title = {Self-Supervised {{Learning}} on {{Graphs}}: {{Contrastive}}, {{Generative}},or {{Predictive}}},
  shorttitle = {Self-Supervised {{Learning}} on {{Graphs}}},
  author = {Wu, Lirong and Lin, Haitao and Gao, Zhangyang and Tan, Cheng and Li, Stan Z.},
  year = {2021},
  month = sep,
  abstract = {Deep learning on graphs has recently achieved remarkable success on a variety of tasks while such success relies heavily on the massive and carefully labeled data. However, precise annotations are generally very expensive and time-consuming. To address this problem, self-supervised learning (SSL) is emerging as a new paradigm for extracting informative knowledge through well-designed pretext tasks without relying on manual labels. In this survey, we extend the concept of SSL, which first emerged in the fields of computer vision and natural language processing, to present a timely and comprehensive review of the existing SSL techniques for graph data. Specifically, we divide existing graph SSL methods into three categories: contrastive, generative, and predictive. More importantly, unlike many other surveys that only provide a high-level description of published research, we present an additional mathematical summary of the existing works in a unified framework. Furthermore, to facilitate methodological development and empirical comparisons, we also summarize the commonly used datasets, evaluation metrics, downstream tasks, and open-source implementations of various algorithms. Finally, we discuss the technical challenges and potential future directions for improving graph self-supervised learning. Latest advances in graph SSL are summarized in a GitHub repository https://github.com/LirongWu/awesome-graph-self-supervised-learning.},
  archivePrefix = {arXiv},
  eprint = {2105.07342},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\I4YIQKBA\\Wu et al_2021_Self-supervised Learning on GraphsarXiv2105.07342 [cs].pdf},
  journal = {arXiv:2105.07342 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{wuSurveyAccuracyorientedNeural2021,
  title = {A {{Survey}} on {{Accuracy}}-Oriented {{Neural Recommendation}}: {{From Collaborative Filtering}} to {{Information}}-Rich {{Recommendation}}},
  shorttitle = {A {{Survey}} on {{Accuracy}}-Oriented {{Neural Recommendation}}},
  author = {Wu, Le and He, Xiangnan and Wang, Xiang and Zhang, Kun and Wang, Meng},
  year = {2021},
  month = dec,
  abstract = {Influenced by the great success of deep learning in computer vision and language understanding, research in recommendation has shifted to inventing new recommender models based on neural networks. In recent years, we have witnessed significant progress in developing neural recommender models, which generalize and surpass traditional recommender models owing to the strong representation power of neural networks. In this survey paper, we conduct a systematic review on neural recommender models from the perspective of recommendation modeling with the accuracy goal, aiming to summarize this field to facilitate researchers and practitioners working on recommender systems. Specifically, based on the data usage during recommendation modeling, we divide the work into collaborative filtering and information-rich recommendation: 1) collaborative filtering, which leverages the key source of user-item interaction data; 2) content enriched recommendation, which additionally utilizes the side information associated with users and items, like user profile and item knowledge graph; and 3) temporal/sequential recommendation, which accounts for the contextual information associated with an interaction, such as time, location, and the past interactions. After reviewing representative work for each type, we finally discuss some promising directions in this field.},
  archivePrefix = {arXiv},
  eprint = {2104.13030},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\6QBKTA6M\\Wu 等。 - 2021 - A Survey on Accuracy-oriented Neural Recommendatio.pdf},
  journal = {arXiv:2104.13030 [cs]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{wuSurveyAccuracyorientedNeural2021a,
  title = {A {{Survey}} on {{Accuracy}}-Oriented {{Neural Recommendation}}: {{From Collaborative Filtering}} to {{Information}}-Rich {{Recommendation}}},
  shorttitle = {A {{Survey}} on {{Accuracy}}-Oriented {{Neural Recommendation}}},
  author = {Wu, Le and He, Xiangnan and Wang, Xiang and Zhang, Kun and Wang, Meng},
  year = {2021},
  month = dec,
  abstract = {Influenced by the great success of deep learning in computer vision and language understanding, research in recommendation has shifted to inventing new recommender models based on neural networks. In recent years, we have witnessed significant progress in developing neural recommender models, which generalize and surpass traditional recommender models owing to the strong representation power of neural networks. In this survey paper, we conduct a systematic review on neural recommender models from the perspective of recommendation modeling with the accuracy goal, aiming to summarize this field to facilitate researchers and practitioners working on recommender systems. Specifically, based on the data usage during recommendation modeling, we divide the work into collaborative filtering and information-rich recommendation: 1) collaborative filtering, which leverages the key source of user-item interaction data; 2) content enriched recommendation, which additionally utilizes the side information associated with users and items, like user profile and item knowledge graph; and 3) temporal/sequential recommendation, which accounts for the contextual information associated with an interaction, such as time, location, and the past interactions. After reviewing representative work for each type, we finally discuss some promising directions in this field.},
  archivePrefix = {arXiv},
  eprint = {2104.13030},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\YZ7KMFPF\\2104.13030.pdf},
  journal = {arXiv:2104.13030 [cs]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{xiaoUPRecUserAwarePretraining2021,
  title = {{{UPRec}}: {{User}}-{{Aware Pre}}-Training for {{Recommender Systems}}},
  shorttitle = {{{UPRec}}},
  author = {Xiao, Chaojun and Xie, Ruobing and Yao, Yuan and Liu, Zhiyuan and Sun, Maosong and Zhang, Xu and Lin, Leyu},
  year = {2021},
  month = feb,
  abstract = {Existing sequential recommendation methods rely on large amounts of training data and usually suffer from the data sparsity problem. To tackle this, the pre-training mechanism has been widely adopted, which attempts to leverage large-scale data to perform self-supervised learning and transfer the pre-trained parameters to downstream tasks. However, previous pre-trained models for recommendation focus on leverage universal sequence patterns from user behaviour sequences and item information, whereas ignore capturing personalized interests with the heterogeneous user information, which has been shown effective in contributing to personalized recommendation. In this paper, we propose a method to enhance pre-trained models with heterogeneous user information, called User-aware Pre-training for Recommendation (UPRec). Specifically, UPRec leverages the user attributes and structured social graphs to construct self-supervised objectives in the pre-training stage and proposes two user-aware pre-training tasks. Comprehensive experimental results on several real-world large-scale recommendation datasets demonstrate that UPRec can effectively integrate user information into pre-trained models and thus provide more appropriate recommendations for users.},
  archivePrefix = {arXiv},
  eprint = {2102.10989},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\MQJK375E\\Xiao et al_2021_UPRec.pdf},
  journal = {arXiv:2102.10989 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{xiaSelfSupervisedGraphCoTraining2021,
  title = {Self-{{Supervised Graph Co}}-{{Training}} for {{Session}}-Based {{Recommendation}}},
  author = {Xia, Xin and Yin, Hongzhi and Yu, Junliang and Shao, Yingxia and Cui, Lizhen},
  year = {2021},
  month = aug,
  abstract = {Session-based recommendation targets next-item prediction by exploiting user behaviors within a short time period. Compared with other recommendation paradigms, session-based recommendation suffers more from the problem of data sparsity due to the very limited short-term interactions. Self-supervised learning, which can discover ground-truth samples from the raw data, holds vast potentials to tackle this problem. However, existing self-supervised recommendation models mainly rely on item/segment dropout to augment data, which are not fit for session-based recommendation because the dropout leads to sparser data, creating unserviceable self-supervision signals. In this paper, for informative sessionbased data augmentation, we combine self-supervised learning with co-training, and then develop a framework to enhance sessionbased recommendation. Technically, we first exploit the sessionbased graph to augment two views that exhibit the internal and external connectivities of sessions, and then we build two distinct graph encoders over the two views, which recursively leverage the different connectivity information to generate ground-truth samples to supervise each other by contrastive learning. In contrast to the dropout strategy, the proposed self-supervised graph co-training preserves the complete session information and fulfills genuine data augmentation. Extensive experiments on multiple benchmark datasets show that, session-based recommendation can be remarkably enhanced under the regime of self-supervised graph co-training, achieving the state-of-the-art performance.},
  archivePrefix = {arXiv},
  eprint = {2108.10560},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\Q7222YA9\\Xia et al_2021_Self-Supervised Graph Co-Training for Session-based Recommendation.pdf},
  journal = {arXiv:2108.10560 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{xiaSelfSupervisedHypergraphConvolutional,
  title = {Self-{{Supervised Hypergraph Convolutional Networks}} for {{Session}}-Based {{Recommendation}}},
  author = {Xia, Xin},
  pages = {9},
  abstract = {Session-based recommendation (SBR) focuses on next-item prediction at a certain time point. As user profiles are generally not available in this scenario, capturing the user intent lying in the item transitions plays a pivotal role. Recent graph neural networks (GNNs) based SBR methods regard the item transitions as pairwise relations, which neglect the complex high-order information among items. Hypergraph provides a natural way to capture beyond-pairwise relations, while its potential for SBR has remained unexplored. In this paper, we fill this gap by modeling sessionbased data as a hypergraph and then propose a hypergraph convolutional network to improve SBR. Moreover, to enhance hypergraph modeling, we devise another graph convolutional network which is based on the line graph of the hypergraph and then integrate self-supervised learning into the training of the networks by maximizing mutual information between the session representations learned via the two networks, serving as an auxiliary task to improve the recommendation task. Since the two types of networks both are based on hypergraph, which can be seen as two channels for hypergraph modeling, we name our model DHCN (Dual Channel Hypergraph Convolutional Networks). Extensive experiments on three benchmark datasets demonstrate the superiority of our model over the SOTA methods, and the results validate the effectiveness of hypergraph modeling and selfsupervised task. The implementation of our model is available via https://github.com/xiaxin1998/DHCN.},
  file = {D\:\\Filez\\Zetero\\storage\\A834IDUL\\Xia_Self-Supervised Hypergraph Convolutional Networks for Session-based.pdf;D\:\\Filez\\Zetero\\storage\\CBRWZ42W\\notes.md},
  keywords = {Hypergraph,session-based recommendation},
  language = {en}
}

@inproceedings{xieAdversarialContrastiveVariational2021,
  title = {Adversarial and {{Contrastive Variational Autoencoder}} for {{Sequential Recommendation}}},
  booktitle = {Proceedings of the {{Web Conference}} 2021},
  author = {Xie, Zhe and Liu, Chengxuan and Zhang, Yichi and Lu, Hongtao and Wang, Dong and Ding, Yue},
  year = {2021},
  month = apr,
  pages = {449--459},
  publisher = {{ACM}},
  address = {{Ljubljana Slovenia}},
  doi = {10.1145/3442381.3449873},
  abstract = {Sequential recommendation as an emerging topic has attracted increasing attention due to its important practical significance. Models based on deep learning and attention mechanism have achieved good performance in sequential recommendation. Recently, the generative models based on Variational Autoencoder (VAE) have shown the unique advantage in collaborative filtering. In particular, the sequential VAE model as a recurrent version of VAE can effectively capture temporal dependencies among items in user sequence and perform sequential recommendation. However, VAE-based models suffer from a common limitation that the representational ability of the obtained approximate posterior distribution is limited, resulting in lower quality of generated samples. This is especially true for generating sequences. To solve the above problem, in this work, we propose a novel method called Adversarial and Contrastive Variational Autoencoder (ACVAE) for sequential recommendation. Specifically, we first introduce the adversarial training for sequence generation under the Adversarial Variational Bayes (AVB) framework, which enables our model to generate high-quality latent variables. Then, we employ the contrastive loss. The latent variables will be able to learn more personalized and salient characteristics by minimizing the contrastive loss. Besides, when encoding the sequence, we apply a recurrent and convolutional structure to capture global and local relationships in the sequence. Finally, we conduct extensive experiments on four real-world datasets. The experimental results show that our proposed ACVAE model outperforms other state-of-the-art methods.},
  file = {D\:\\Filez\\Zetero\\storage\\CHK8GC5I\\notes.md;D\:\\Filez\\Zetero\\storage\\J5KHDXX5\\Xie et al_2021_Adversarial and Contrastive Variational Autoencoder for Sequential.pdf},
  isbn = {978-1-4503-8312-7},
  language = {en}
}

@article{xieContrastiveLearningSequential2021,
  title = {Contrastive {{Learning}} for {{Sequential Recommendation}}},
  author = {Xie, Xu and Sun, Fei and Liu, Zhaoyang and Wu, Shiwen and Gao, Jinyang and Ding, Bolin and Cui, Bin},
  year = {2021},
  month = feb,
  abstract = {Sequential recommendation methods play a crucial role in modern recommender systems because of their ability to capture a user's dynamic interest from her/his historical interactions. Despite their success, we argue that these approaches usually rely on the sequential prediction task to optimize the huge amounts of parameters. They usually suffer from the data sparsity problem, which makes it difficult for them to learn high-quality user representations. To tackle that, inspired by recent advances of contrastive learning techniques in the computer version, we propose a novel multi-task model called Contrastive Learning for Sequential Recommendation (CL4SRec). CL4SRec not only takes advantage of the traditional next item prediction task but also utilizes the contrastive learning framework to derive self-supervision signals from the original user behavior sequences. Therefore, it can extract more meaningful user patterns and further encode the user representation effectively. In addition, we propose three data augmentation approaches to construct self-supervision signals. Extensive experiments on four public datasets demonstrate that CL4SRec achieves state-of-the-art performance over existing baselines by inferring better user representations.},
  archivePrefix = {arXiv},
  eprint = {2010.14395},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\DBYCX6QX\\notes.md;D\:\\Filez\\Zetero\\storage\\P633A5S7\\Xie et al_2021_Contrastive Learning for Sequential Recommendation.pdf},
  journal = {arXiv:2010.14395 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{xieSelfSupervisedLearningGraph2021,
  title = {Self-{{Supervised Learning}} of {{Graph Neural Networks}}: {{A Unified Review}}},
  shorttitle = {Self-{{Supervised Learning}} of {{Graph Neural Networks}}},
  author = {Xie, Yaochen and Xu, Zhao and Zhang, Jingtun and Wang, Zhengyang and Ji, Shuiwang},
  year = {2021},
  month = mar,
  abstract = {Deep models trained in supervised mode have achieved remarkable success on a variety of tasks. When labeled samples are limited, self-supervised learning (SSL) is emerging as a new paradigm for making use of large amounts of unlabeled samples. SSL has achieved promising performance on natural language and image learning tasks. Recently, there is a trend to extend such success to graph data using graph neural networks (GNNs). In this survey, we provide a unified review of different ways of training GNNs using SSL. Specifically, we categorize SSL methods into contrastive and predictive models. In either category, we provide a unified framework for methods as well as how these methods differ in each component under the framework. Our unified treatment of SSL methods for GNNs sheds light on the similarities and differences of various methods, setting the stage for developing new methods and algorithms. We also summarize different SSL settings and the corresponding datasets used in each setting. To facilitate methodological development and empirical comparison, we develop a standardized testbed for SSL in GNNs, including implementations of common baseline methods, datasets, and evaluation metrics.},
  archivePrefix = {arXiv},
  eprint = {2102.10757},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\ZDSA89VL\\Xie et al_2021_Self-Supervised Learning of Graph Neural Networks.pdf},
  journal = {arXiv:2102.10757 [cs]},
  keywords = {Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{xinSelfSupervisedReinforcementLearning2020,
  title = {Self-{{Supervised Reinforcement Learning}} for {{Recommender Systems}}},
  booktitle = {Proceedings of the 43rd {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Xin, Xin and Karatzoglou, Alexandros and Arapakis, Ioannis and Jose, Joemon M.},
  year = {2020},
  month = jul,
  pages = {931--940},
  publisher = {{ACM}},
  address = {{Virtual Event China}},
  doi = {10.1145/3397271.3401147},
  abstract = {In session-based or sequential recommendation, it is important to consider a number of factors like long-term user engagement, multiple types of user-item interactions such as clicks, purchases etc. The current state-of-the-art supervised approaches fail to model them appropriately. Casting sequential recommendation task as a reinforcement learning (RL) problem is a promising direction. A major component of RL approaches is to train the agent through interactions with the environment. However, it is often problematic to train a recommender in an on-line fashion due to the requirement to expose users to irrelevant recommendations. As a result, learning the policy from logged implicit feedback is of vital importance, which is challenging due to the pure off-policy setting and lack of negative rewards (feedback).},
  file = {D\:\\Filez\\Zetero\\storage\\CN3KKFML\\Xin et al_2020_Self-Supervised Reinforcement Learning for Recommender Systems.pdf},
  isbn = {978-1-4503-8016-4},
  language = {en}
}

@inproceedings{xuLearningSharedVertex2019,
  title = {Learning {{Shared Vertex Representation}} in {{Heterogeneous Graphs}} with {{Convolutional Networks}} for {{Recommendation}}},
  booktitle = {Proceedings of the {{Twenty}}-{{Eighth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Xu, Yanan and Zhu, Yanmin and Shen, Yanyan and Yu, Jiadi},
  year = {2019},
  month = aug,
  pages = {4620--4626},
  publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
  address = {{Macao, China}},
  doi = {10.24963/ijcai.2019/642},
  abstract = {Collaborative Filtering (CF) is among the most successful techniques in recommendation tasks. Recent works have shown a boost of performance of CF when introducing the pairwise relationships between users and items or among items (users) using interaction data. However, these works usually only utilize one kind of information, i.e., user preference in a user-item interaction matrix or item dependency in interaction sequences which can limit the recommendation performance. In this paper, we propose to mine three kinds of information (user preference, item dependency, and user similarity on behaviors) by converting interaction sequence data into multiple graphs (i.e., a user-item graph, an item-item graph, and a user-subseq graph). We design a novel graph convolutional network (PGCN) to learn shared representations of users and items with the three heterogeneous graphs. In our approach, a neighbor pooling and a convolution operation are designed to aggregate features of neighbors. Extensive experiments on two real-world datasets demonstrate that our graph convolution approaches outperform various competitive methods in terms of two metrics, and the heterogeneous graphs are proved effective for improving recommendation performance.},
  file = {D\:\\Filez\\Zetero\\storage\\XMRDX5TE\\Xu 等。 - 2019 - Learning Shared Vertex Representation in Heterogen.pdf},
  isbn = {978-0-9992411-4-1},
  language = {en}
}

@article{yadatiHyperGCNNewMethod2019,
  title = {{{HyperGCN}}: {{A New Method}} of {{Training Graph Convolutional Networks}} on {{Hypergraphs}}},
  shorttitle = {{{HyperGCN}}},
  author = {Yadati, Naganand and Nimishakavi, Madhav and Yadav, Prateek and Nitin, Vikram and Louis, Anand and Talukdar, Partha},
  year = {2019},
  month = may,
  abstract = {In many real-world network datasets such as co-authorship, co-citation, email communication, etc., relationships are complex and go beyond pairwise associations. Hypergraphs provide a flexible and natural modeling tool to model such complex relationships. The obvious existence of such complex relationships in many realworld networks naturally motivates the problem of learning with hypergraphs. A popular learning paradigm is hypergraph-based semi-supervised learning (SSL) where the goal is to assign labels to initially unlabelled vertices in a hypergraph. Motivated by the fact that a graph convolutional network (GCN) has been effective for graph-based SSL, we propose HyperGCN, a novel way of training a GCN for SSL on hypergraphs. We demonstrate HyperGCN's effectiveness through detailed experimentation on real-world hypergraphs and analyse when it is going to be more effective than state-of-the art baselines.},
  archivePrefix = {arXiv},
  eprint = {1809.02589},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\HSJU5VV4\\Yadati et al_2019_HyperGCN.pdf},
  journal = {arXiv:1809.02589 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Hypergraph,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{yangHeterogeneousNetworkRepresentation2020,
  title = {Heterogeneous {{Network Representation Learning}}: {{A Unified Framework}} with {{Survey}} and {{Benchmark}}},
  shorttitle = {Heterogeneous {{Network Representation Learning}}},
  author = {Yang, Carl and Xiao, Yuxin and Zhang, Yu and Sun, Yizhou and Han, Jiawei},
  year = {2020},
  month = dec,
  abstract = {Since real-world objects and their interactions are often multi-modal and multi-typed, heterogeneous networks have been widely used as a more powerful, realistic, and generic superclass of traditional homogeneous networks (graphs). Meanwhile, representation learning (a.k.a. embedding) has recently been intensively studied and shown effective for various network mining and analytical tasks. In this work, we aim to provide a unified framework to deeply summarize and evaluate existing research on heterogeneous network embedding (HNE), which includes but goes beyond a normal survey. Since there has already been a broad body of HNE algorithms, as the first contribution of this work, we provide a generic paradigm for the systematic categorization and analysis over the merits of various existing HNE algorithms. Moreover, existing HNE algorithms, though mostly claimed generic, are often evaluated on different datasets. Understandable due to the application favor of HNE, such indirect comparisons largely hinder the proper attribution of improved task performance towards effective data preprocessing and novel technical design, especially considering the various ways possible to construct a heterogeneous network from real-world application data. Therefore, as the second contribution, we create four benchmark datasets with various properties regarding scale, structure, attribute/label availability, and etc. from different sources, towards handy and fair evaluations of HNE algorithms. As the third contribution, we carefully refactor and amend the implementations and create friendly interfaces for 13 popular HNE algorithms, and provide all-around comparisons among them over multiple tasks and experimental settings. By putting all existing HNE algorithms under a unified framework, we aim to provide a universal reference and guideline for the understanding and development of HNE algorithms. Meanwhile, by open-sourcing all data and code, we envision to serve the community with an ready-to-use benchmark platform to test and compare the performance of existing and future HNE algorithms (https://github.com/yangji9181/HNE).},
  archivePrefix = {arXiv},
  eprint = {2004.00216},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\9HJN7DV6\\2004.00216.pdf},
  journal = {arXiv:2004.00216 [cs]},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  language = {en},
  primaryClass = {cs}
}

@article{yangHyperMetaPathContrastive2021,
  title = {Hyper {{Meta}}-{{Path Contrastive Learning}} for {{Multi}}-{{Behavior Recommendation}}},
  author = {Yang, Haoran and Chen, Hongxu and Li, Lin and Yu, Philip S. and Xu, Guandong},
  year = {2021},
  month = sep,
  abstract = {User purchasing prediction with multi-behavior information remains a challenging problem for current recommendation systems. Various methods have been proposed to address it via leveraging the advantages of graph neural networks (GNNs) or multi-task learning. However, most existing works do not take the complex dependencies among different behaviors of users into consideration. They utilize simple and fixed schemes, like neighborhood information aggregation or mathematical calculation of vectors, to fuse the embeddings of different user behaviors to obtain a unified embedding to represent a user's behavioral patterns which will be used in downstream recommendation tasks. To tackle the challenge, in this paper, we first propose the concept of hyper metapath to construct hyper meta-paths or hyper meta-graphs to explicitly illustrate the dependencies among different behaviors of a user. How to obtain a unified embedding for a user from hyper meta-paths and avoid the previously mentioned limitations simultaneously is critical. Thanks to the recent success of graph contrastive learning, we leverage it to learn embeddings of user behavior patterns adaptively instead of assigning a fixed scheme to understand the dependencies among different behaviors. A new graph contrastive learning based framework is proposed by coupling with hyper metapaths, namely HMG-CR, which consistently and significantly outperforms all baselines in extensive comparison experiments.},
  archivePrefix = {arXiv},
  eprint = {2109.02859},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\HFZTX2AL\\Yang et al_2021_Hyper Meta-Path Contrastive Learning for Multi-Behavior Recommendation.pdf;D\:\\Filez\\Zetero\\storage\\P27UMRJN\\notes.md},
  journal = {arXiv:2109.02859 [cs]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{yangHyperMetaPathContrastive2021a,
  title = {Hyper {{Meta}}-{{Path Contrastive Learning}} for {{Multi}}-{{Behavior Recommendation}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  author = {Yang, Haoran and Chen, Hongxu and Li, Lin and Yu, Philip S. and Xu, Guandong},
  year = {2021},
  month = dec,
  pages = {787--796},
  publisher = {{IEEE}},
  address = {{Auckland, New Zealand}},
  doi = {10.1109/ICDM51629.2021.00090},
  abstract = {User purchasing prediction with multi-behavior information remains a challenging problem for current recommendation systems. Various methods have been proposed to address it via leveraging the advantages of graph neural networks (GNNs) or multi-task learning. However, most existing works do not take the complex dependencies among different behaviors of users into consideration. They utilize simple and fixed schemes, like neighborhood information aggregation or mathematical calculation of vectors, to fuse the embeddings of different user behaviors to obtain a unified embedding to represent a user's behavioral patterns which will be used in downstream recommendation tasks. To tackle the challenge, in this paper, we first propose the concept of hyper metapath to construct hyper meta-paths or hyper meta-graphs to explicitly illustrate the dependencies among different behaviors of a user. How to obtain a unified embedding for a user from hyper meta-paths and avoid the previously mentioned limitations simultaneously is critical. Thanks to the recent success of graph contrastive learning, we leverage it to learn embeddings of user behavior patterns adaptively instead of assigning a fixed scheme to understand the dependencies among different behaviors. A new graph contrastive learning based framework is proposed by coupling with hyper metapaths, namely HMG-CR, which consistently and significantly outperforms all baselines in extensive comparison experiments.},
  file = {D\:\\Filez\\Zetero\\storage\\J3GEB5P9\\Yang 等。 - 2021 - Hyper Meta-Path Contrastive Learning for Multi-Beh.pdf},
  isbn = {978-1-66542-398-4},
  language = {en}
}

@inproceedings{yangRevisitingUserMobility2019,
  title = {Revisiting {{User Mobility}} and {{Social Relationships}} in {{LBSNs}}: {{A Hypergraph Embedding Approach}}},
  shorttitle = {Revisiting {{User Mobility}} and {{Social Relationships}} in {{LBSNs}}},
  booktitle = {The {{World Wide Web Conference}} on   - {{WWW}} '19},
  author = {Yang, Dingqi and Qu, Bingqing and Yang, Jie and {Cudre-Mauroux}, Philippe},
  year = {2019},
  pages = {2147--2157},
  publisher = {{ACM Press}},
  address = {{San Francisco, CA, USA}},
  doi = {10.1145/3308558.3313635},
  abstract = {Location Based Social Networks (LBSNs) have been widely used as a primary data source to study the impact of mobility and social relationships on each other. Traditional approaches manually define features to characterize users' mobility homophily and social proximity, and show that mobility and social features can help friendship and location prediction tasks, respectively. However, these handcrafted features not only require tedious human efforts, but also are difficult to generalize. In this paper, by revisiting user mobility and social relationships based on a large-scale LBSN dataset collected over a long-term period, we propose LBSN2Vec, a hypergraph embedding approach designed specifically for LBSN data for automatic feature learning. Specifically, LBSN data intrinsically forms a hypergraph including both user-user edges (friendships) and user-time-POI-semantic hyperedges (check-ins). Based on this hypergraph, we first propose a random-walk-with-stay scheme to jointly sample user check-ins and social relationships, and then learn node embeddings from the sampled (hyper)edges by preserving n-wise node proximity (n = 2 or 4). Our evaluation results show that LBSN2Vec both consistently and significantly outperforms the state-of-the-art graph embedding methods on both friendship and location prediction tasks, with an average improvement of 32.95\% and 25.32\%, respectively. Moreover, using LBSN2Vec, we discover the asymmetric impact of mobility and social relationships on predicting each other, which can serve as guidelines for future research on friendship and location prediction in LBSNs.},
  file = {D\:\\Filez\\Zetero\\storage\\KFS2TLZD\\Yang et al_2019_Revisiting User Mobility and Social Relationships in LBSNs.pdf},
  isbn = {978-1-4503-6674-8},
  keywords = {hypergraph},
  language = {en}
}

@article{yangSupervisedContrastiveLearning2022,
  title = {Supervised {{Contrastive Learning}} for {{Recommendation}}},
  author = {Yang, Chun},
  year = {2022},
  month = jan,
  abstract = {Compared with the traditional collaborative filtering methods, the graph convolution network can explicitly model the interaction between the nodes of the user-item bipartite graph and effectively use higher-order neighbors, which enables the graph neural network to obtain more effective embeddings for recommendation, such as NGCF And LightGCN. However, its representations is very susceptible to the noise of interaction. In response to this problem, SGL explored the self-supervised learning on the user-item graph to improve the robustness of GCN. Although effective, we found that SGL directly applies SimCLR's comparative learning framework. This framework may not be directly applicable to the scenario of the recommendation system, and does not fully consider the uncertainty of user-item interaction.},
  archivePrefix = {arXiv},
  eprint = {2201.03144},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\MVICAAF9\\Yang - 2022 - Supervised Contrastive Learning for Recommendation.pdf},
  journal = {arXiv:2201.03144 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{yaoSelfsupervisedLearningLargescale2021,
  title = {Self-Supervised {{Learning}} for {{Large}}-Scale {{Item Recommendations}}},
  author = {Yao, Tiansheng and Yi, Xinyang and Cheng, Derek Zhiyuan and Yu, Felix and Chen, Ting and Menon, Aditya and Hong, Lichan and Chi, Ed H. and Tjoa, Steve and Kang, Jieqi and Ettinger, Evan},
  year = {2021},
  month = feb,
  abstract = {Large scale recommender models find most relevant items from huge catalogs, and they play a critical role in modern search and recommendation systems. To model the input space with large-vocab categorical features, a typical recommender model learns a joint embedding space through neural networks for both queries and items from user feedback data. However, with millions to billions of items in the corpus, users tend to provide feedback for a very small set of them, causing a power-law distribution. This makes the feedback data for long-tail items extremely sparse.},
  archivePrefix = {arXiv},
  eprint = {2007.12865},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\SPL3IDEV\\notes.md;D\:\\Filez\\Zetero\\storage\\V6L9C4KQ\\Yao et al_2021_Self-supervised Learning for Large-scale Item Recommendations.pdf},
  journal = {arXiv:2007.12865 [cs, stat]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{yeEfficientContrastiveLearning2021,
  title = {Efficient {{Contrastive Learning}} via {{Novel Data Augmentation}} and {{Curriculum Learning}}},
  author = {Ye, Seonghyeon and Kim, Jiseon and Oh, Alice},
  year = {2021},
  month = oct,
  abstract = {We introduce EfficientCL, a memory-efficient continual pretraining method that applies contrastive learning with novel data augmentation and curriculum learning. For data augmentation, we stack two types of operation sequentially: cutoff and PCA jittering. While pretraining steps proceed, we apply curriculum learning by incrementing the augmentation degree for each difficulty step. After data augmentation is finished, contrastive learning is applied on projected embeddings of original and augmented examples. When finetuned on GLUE benchmark, our model outperforms baseline models, especially for sentence-level tasks. Additionally, this improvement is capable with only 70\% of computational memory compared to the baseline model.},
  archivePrefix = {arXiv},
  eprint = {2109.05941},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\MKMHHUS5\\Ye et al_2021_Efficient Contrastive Learning via Novel Data Augmentation and Curriculum.pdf},
  journal = {arXiv:2109.05941 [cs]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@misc{YiWenGaoDongShangEntropyJiaoChaShang,
  title = {一文搞懂熵({{Entropy}}),交叉熵({{Cross}}-{{Entropy}}) - 知乎},
  file = {D\:\\Filez\\Zetero\\storage\\MDNMW9K2\\149186719.html},
  howpublished = {https://zhuanlan.zhihu.com/p/149186719}
}

@article{yuanFutureDataHelps2020,
  title = {Future {{Data Helps Training}}: {{Modeling Future Contexts}} for {{Session}}-Based {{Recommendation}}},
  shorttitle = {Future {{Data Helps Training}}},
  author = {Yuan, Fajie and He, Xiangnan and Jiang, Haochuan and Guo, Guibing and Xiong, Jian and Xu, Zhezhao and Xiong, Yilin},
  year = {2020},
  month = jan,
  abstract = {Session-based recommender systems have attracted much attention recently. To capture the sequential dependencies, existing methods resort either to data augmentation techniques or left-to-right style autoregressive training. Since these methods are aimed to model the sequential nature of user behaviors, they ignore the future data of a target interaction when constructing the prediction model for it. However, we argue that the future interactions after a target interaction, which are also available during training, provide valuable signal on user preference and can be used to enhance the recommendation quality.},
  archivePrefix = {arXiv},
  eprint = {1906.04473},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\FVB9IBQK\\Yuan et al_2020_Future Data Helps Training.pdf},
  journal = {arXiv:1906.04473 [cs]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{yuanImprovingSequentialRecommendation2021,
  title = {Improving {{Sequential Recommendation Consistency}} with {{Self}}-{{Supervised Imitation}}},
  booktitle = {Proceedings of the {{Thirtieth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Yuan, Xu and Chen, Hongshen and Song, Yonghao and Zhao, Xiaofang and Ding, Zhuoye},
  year = {2021},
  month = aug,
  pages = {3321--3327},
  publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
  address = {{Montreal, Canada}},
  doi = {10.24963/ijcai.2021/457},
  abstract = {Most sequential recommendation models capture the features of consecutive items in a user-item interaction history. Though effective, their representation expressiveness is still hindered by the sparse learning signals. As a result, the sequential recommender is prone to make inconsistent predictions. In this paper, we propose a model, SSI, to improve sequential recommendation consistency with Self-Supervised Imitation. Precisely, we extract the consistency knowledge by utilizing three self-supervised pre-training tasks, where temporal consistency and persona consistency capture user-interaction dynamics in terms of the chronological order and persona sensitivities, respectively. Furthermore, to provide the model with a global perspective, global session consistency is introduced by maximizing the mutual information among global and local interaction sequences. Finally, to comprehensively take advantage of all three independent aspects of consistency-enhanced knowledge, we establish an integrated imitation learning framework. The consistency knowledge is effectively internalized and transferred to the student model by imitating the conventional prediction logit as well as the consistency-enhanced item representations. In addition, the flexible selfsupervised imitation framework can also benefit other student recommenders. Experiments on four real-world datasets show that SSI effectively outperforms the state-of-the-art sequential recommendation methods.},
  file = {D\:\\Filez\\Zetero\\storage\\HKTQ7SZA\\notes.md;D\:\\Filez\\Zetero\\storage\\W99UP5GN\\Yuan et al_2021_Improving Sequential Recommendation Consistency with Self-Supervised Imitation.pdf},
  isbn = {978-0-9992411-9-6},
  language = {en}
}

@article{yuanOnePersonOne2021,
  title = {One {{Person}}, {{One Model}}, {{One World}}: {{Learning Continual User Representation}} without {{Forgetting}}},
  shorttitle = {One {{Person}}, {{One Model}}, {{One World}}},
  author = {Yuan, Fajie and Zhang, Guoxiao and Karatzoglou, Alexandros and Jose, Joemon and Kong, Beibei and Li, Yudong},
  year = {2021},
  month = may,
  abstract = {Learning generic user representations which can then be applied to other user-related tasks (e.g., profile prediction and recommendation) has recently attracted the attention from both academy and industry. Existing approaches often derive an individual set of model parameters for each task by training their own data. However, the representation of a user usually has some potential commonalities, such as preference and personality, even in different tasks or real-world scenes. As such, these separately trained representations could be suboptimal in performance as well as inefficient in terms of parameter sharing.},
  archivePrefix = {arXiv},
  eprint = {2009.13724},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\6BZTR55N\\Yuan et al_2021_One Person, One Model, One World.pdf},
  journal = {arXiv:2009.13724 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{yuanParameterEfficientTransferSequential2020,
  title = {Parameter-{{Efficient Transfer}} from {{Sequential Behaviors}} for {{User Modeling}} and {{Recommendation}}},
  booktitle = {Proceedings of the 43rd {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Yuan, Fajie and He, Xiangnan and Karatzoglou, Alexandros and Zhang, Liguang},
  year = {2020},
  month = jul,
  pages = {1469--1478},
  publisher = {{ACM}},
  address = {{Virtual Event China}},
  doi = {10.1145/3397271.3401156},
  isbn = {978-1-4503-8016-4},
  language = {en}
}

@inproceedings{yuanParameterEfficientTransferSequential2020a,
  title = {Parameter-{{Efficient Transfer}} from {{Sequential Behaviors}} for {{User Modeling}} and {{Recommendation}}},
  booktitle = {Proceedings of the 43rd {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Yuan, Fajie and He, Xiangnan and Karatzoglou, Alexandros and Zhang, Liguang},
  year = {2020},
  month = jul,
  pages = {1469--1478},
  publisher = {{ACM}},
  address = {{Virtual Event China}},
  doi = {10.1145/3397271.3401156},
  abstract = {Inductive transfer learning has had a big impact on computer vision and NLP domains but has not been used in the area of recommender systems. Even though there has been a large body of research on generating recommendations based on modeling user-item interaction sequences, few of them attempt to represent and transfer these models for serving downstream tasks where only limited data exists.},
  file = {D\:\\Filez\\Zetero\\storage\\9FEMFDPH\\Yuan et al_2020_Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and.pdf;D\:\\Filez\\Zetero\\storage\\HGUCQ7ZX\\Yuan et al_2020_Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and.pdf;D\:\\Filez\\Zetero\\storage\\R8YMIHDU\\notes.md},
  isbn = {978-1-4503-8016-4},
  language = {en}
}

@article{yuanSimpleConvolutionalGenerative2018,
  title = {A {{Simple Convolutional Generative Network}} for {{Next Item Recommendation}}},
  author = {Yuan, Fajie and Karatzoglou, Alexandros and Arapakis, Ioannis and Jose, Joemon M. and He, Xiangnan},
  year = {2018},
  month = nov,
  abstract = {Convolutional Neural Networks (CNNs) have been recently introduced in the domain of session-based next item recommendation. An ordered collection of past items the user has interacted with in a session (or sequence) are embedded into a 2-dimensional latent matrix, and treated as an image. The convolution and pooling operations are then applied to the mapped item embeddings. In this paper, we first examine the typical session-based CNN recommender and show that both the generative model and network architecture are suboptimal when modeling long-range dependencies in the item sequence. To address the issues, we introduce a simple, but very effective generative model that is capable of learning high-level representation from both short- and long-range item dependencies. The network architecture of the proposed model is formed of a stack of holed convolutional layers, which can efficiently increase the receptive fields without relying on the pooling operation. Another contribution is the effective use of residual block structure in recommender systems, which can ease the optimization for much deeper networks. The proposed generative model attains state-of-the-art accuracy with less training time in the next item recommendation task. It accordingly can be used as a powerful recommendation baseline to beat in future, especially when there are long sequences of user feedback.},
  archivePrefix = {arXiv},
  eprint = {1808.05163},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\6WQDXSN2\\Yuan et al_2018_A Simple Convolutional Generative Network for Next Item Recommendation.pdf},
  journal = {arXiv:1808.05163 [cs, stat]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{yuEnhancingSocialRecommendation2020,
  title = {Enhancing {{Social Recommendation}} with {{Adversarial Graph Convolutional Networks}}},
  author = {Yu, Junliang and Yin, Hongzhi and Li, Jundong and Gao, Min and Huang, Zi and Cui, Lizhen},
  year = {2020},
  month = oct,
  abstract = {Social recommender systems are expected to improve recommendation quality by incorporating social information when there is little user-item interaction data. However, recent reports from industry show that social recommender systems consistently fail in practice. According to the negative findings, the failure is attributed to: (1) A majority of users only have a very limited number of neighbors in social networks and can hardly benefit from social relations; (2) Social relations are noisy but they are indiscriminately used; (3) Social relations are assumed to be universally applicable to multiple scenarios while they are actually multi-faceted and show heterogeneous strengths in different scenarios. Most existing social recommendation models only consider the homophily in social networks and neglect these drawbacks. In this paper we propose a deep adversarial framework based on graph convolutional networks (GCN) to address these problems. Concretely, for (1) and (2), a GCN-based autoencoder is developed to augment the relation data by encoding high-order and complex connectivity patterns, and meanwhile is optimized subject to the constraint of reconstructing the social profile to guarantee the validity of the identified neighborhood. After obtaining enough purified social relations for each user, a GCN-based attentive social recommendation module is designed to address (3) by capturing the heterogeneous strengths of social relations. Finally, we adopt adversarial training to unify all the components by playing a Minimax game and ensure a coordinated effort to enhance recommendation performance. Extensive experiments on multiple open datasets demonstrate the superiority of our framework and the ablation study confirms the importance and effectiveness of each component.},
  archivePrefix = {arXiv},
  eprint = {2004.02340},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\VUWHJAJI\\Yu 等。 - 2020 - Enhancing Social Recommendation with Adversarial G.pdf},
  journal = {arXiv:2004.02340 [cs]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Social and Information Networks},
  language = {en},
  primaryClass = {cs}
}

@article{yuGraphAugmentationFreeContrastive2021,
  title = {Graph {{Augmentation}}-{{Free Contrastive Learning}} for {{Recommendation}}},
  author = {Yu, Junliang and Yin, Hongzhi and Xia, Xin and Cui, Lizhen and Nguyen, Quoc Viet Hung},
  year = {2021},
  month = dec,
  abstract = {Contrastive learning (CL) recently has received considerable attention in the field of recommendation, since it can greatly alleviate the data sparsity issue and improve recommendation performance in a self-supervised manner. A typical way to apply CL to recommendation is conducting edge/node dropout on the user-item bipartite graph to augment the graph data and then maximizing the correspondence between representations of the same user/item augmentations under a joint optimization setting. Despite the encouraging results brought by CL, however, what underlies the performance gains still remains unclear. In this paper, we first experimentally demystify that the uniformity of the learned user/item representation distributions on the unit hypersphere is closely related to the recommendation performance. Based on the experimental findings, we propose a graph augmentation-free CL method to simply adjust the uniformity by adding uniform noises to the original representations for data augmentations, and enhance recommendation from a geometric view. Specifically, the constant graph perturbation during training is not required in our method and hence the positive and negative samples for CL can be generated on-the-fly. The experimental results on three benchmark datasets demonstrate that the proposed method has distinct advantages over its graph augmentation-based counterparts in terms of both the ability to improve recommendation performance and the running/convergence speed. The code is released at https://github.com/Coder-Yu/QRec.},
  archivePrefix = {arXiv},
  eprint = {2112.08679},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\GXWJJZHU\\Yu 等。 - 2021 - Graph Augmentation-Free Contrastive Learning for R.pdf},
  journal = {arXiv:2112.08679 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{yuGraphConvolutionalNetwork2020,
  title = {Graph {{Convolutional Network}} for {{Recommendation}}  with {{Low}}-Pass {{Collaborative Filters}}},
  author = {Yu, Wenhui and Qin, Zheng},
  year = {2020},
  pages = {11},
  abstract = {Graph Convolutional Network (GCN) is widely used in graph data learning tasks such as recommendation. However, when facing a large graph, the graph convolution is very computationally expensive thus is simplified in all existing GCNs, yet is seriously impaired due to the oversimplification. To address this gap, we leverage the original graph convolution in GCN and propose a Low-pass Collaborative Filter (LCF) to make it applicable to the large graph. LCF is designed to remove the noise caused by exposure and quantization in the observed data, and it also reduces the complexity of graph convolution in an unscathed way. Experiments show that LCF improves the effectiveness and efficiency of graph convolution and our GCN outperforms existing GCNs significantly. Codes are available on https: //github.com/Wenhui-Yu/LCFN.},
  file = {D\:\\Filez\\Zetero\\storage\\QUKXCCVT\\Yu 和 Qin - 2020 - Graph Convolutional Network for Recommendation  wi.pdf},
  keywords = {GCN},
  language = {en}
}

@article{yuPersonalizedAdaptiveMeta,
  title = {Personalized {{Adaptive Meta Learning}} for {{Cold}}-Start {{User Preference Prediction}}},
  author = {Yu, Runsheng and Gong, Yu and He, Xu and An, Bo and Zhu, Yu and Liu, Qingwen and Ou, Wenwu},
  pages = {20},
  abstract = {A common challenge in personalized user preference prediction is the cold-start problem. Due to the lack of user-item interactions, directly learning from the new users' log data causes serious over-fitting problem. Recently, many existing studies regard the cold-start personalized preference prediction as a few-shot learning problem, where each user is the task and recommended items are the classes, and the gradient-based meta learning method (MAML) is leveraged to address this challenge. However, in real-world application, the users are not uniformly distributed (i.e., different users may have different browsing history, recommended items, and user profiles. We define the major users as the users in the groups with large numbers of users sharing similar user information, and other users are the minor users), existing MAML approaches tend to fit the major users and ignore the minor users. To address this cold-start task-overfitting problem, we propose a novel personalized adaptive meta learning approach to consider both the major and the minor users with three key contributions: 1) We are the first to present a personalized adaptive learning rate meta-learning approach to improve the performance of MAML by focusing on both the major and minor users. 2) To provide better personalized learning rates for each user, we introduce a similarity-based method to find similar users as a reference and a tree-based method to store users' features for fast search. 3) To reduce the memory usage, we design a memory agnostic regularizer to further reduce the space complexity to constant while maintain the performance. Experiments on MovieLens, BookCrossing, and real-world production datasets reveal that our method outperforms the state-of-the-art methods dramatically for both the minor and major users.},
  file = {D\:\\Filez\\Zetero\\storage\\ZEFZ86JQ\\Yu et al_Personalized Adaptive Meta Learning for Cold-start User Preference Prediction.pdf},
  language = {en}
}

@inproceedings{yuSelfSupervisedMultiChannelHypergraph2021,
  title = {Self-{{Supervised Multi}}-{{Channel Hypergraph Convolutional Network}} for {{Social Recommendation}}},
  booktitle = {Proceedings of the {{Web Conference}} 2021},
  author = {Yu, Junliang and Yin, Hongzhi and Li, Jundong and Wang, Qinyong and Hung, Nguyen Quoc Viet and Zhang, Xiangliang},
  year = {2021},
  month = apr,
  pages = {413--424},
  publisher = {{ACM}},
  address = {{Ljubljana Slovenia}},
  doi = {10.1145/3442381.3449844},
  abstract = {Social relations are often used to improve recommendation quality when user-item interaction data is sparse in recommender systems. Most existing social recommendation models exploit pairwise relations to mine potential user preferences. However, real-life interactions among users are very complex and user relations can be high-order. Hypergraph provides a natural way to model high-order relations, while its potentials for improving social recommendation are under-explored. In this paper, we fill this gap and propose a multi-channel hypergraph convolutional network to enhance social recommendation by leveraging high-order user relations. Technically, each channel in the network encodes a hypergraph that depicts a common high-order user relation pattern via hypergraph convolution. By aggregating the embeddings learned through multiple channels, we obtain comprehensive user representations to generate recommendation results. However, the aggregation operation might also obscure the inherent characteristics of different types of high-order connectivity information. To compensate for the aggregating loss, we innovatively integrate self-supervised learning into the training of the hypergraph convolutional network to regain the connectivity information with hierarchical mutual information maximization. Extensive experiments on multiple realworld datasets demonstrate the superiority of the proposed model over the current SOTA methods, and the ablation study verifies the effectiveness and rationale of the multi-channel setting and the self-supervised task. The implementation of our model is available via https://github.com/Coder-Yu/RecQ.},
  file = {D\:\\Filez\\Zetero\\storage\\IY9Q2PU5\\notes.md;D\:\\Filez\\Zetero\\storage\\NFCIY7ML\\Yu et al_2021_Self-Supervised Multi-Channel Hypergraph Convolutional Network for Social.pdf},
  isbn = {978-1-4503-8312-7},
  keywords = {Hypergraph},
  language = {en}
}

@inproceedings{yuSociallyAwareSelfSupervisedTriTraining2021,
  title = {Socially-{{Aware Self}}-{{Supervised Tri}}-{{Training}} for {{Recommendation}}},
  booktitle = {Proceedings of the 27th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Yu, Junliang and Yin, Hongzhi and Gao, Min and Xia, Xin and Zhang, Xiangliang and Viet Hung, Nguyen Quoc},
  year = {2021},
  month = aug,
  pages = {2084--2092},
  publisher = {{ACM}},
  address = {{Virtual Event Singapore}},
  doi = {10.1145/3447548.3467340},
  abstract = {Self-supervised learning (SSL), which can automatically generate ground-truth samples from raw data, holds vast potential to improve recommender systems. Most existing SSL-based methods perturb the raw data graph with uniform node/edge dropout to generate new data views and then conduct the self-discrimination based contrastive learning over different views to learn generalizable representations. Under this scheme, only a bijective mapping is built between nodes in two different views, which means that the self-supervision signals from other nodes are being neglected. Due to the widely observed homophily in recommender systems, we argue that the supervisory signals from other nodes are also highly likely to benefit the representation learning for recommendation. To capture these signals, a general socially-aware SSL framework that integrates tri-training is proposed in this paper. Technically, our framework first augments the user data views with the user social information. And then under the regime of tri-training for multi-view encoding, the framework builds three graph encoders (one for recommendation) upon the augmented views and iteratively improves each encoder with self-supervision signals from other users, generated by the other two encoders. Since the tri-training operates on the augmented views of the same data sources for self-supervision signals, we name it self-supervised tri-training. Extensive experiments on multiple real-world datasets consistently validate the effectiveness of the self-supervised tritraining framework for improving recommendation. The code is released at https://github.com/Coder-Yu/QRec.},
  file = {D\:\\Filez\\Zetero\\storage\\5I24I23T\\notes.md;D\:\\Filez\\Zetero\\storage\\EXVUVNZK\\Yu et al_2021_Socially-Aware Self-Supervised Tri-Training for Recommendation.pdf},
  isbn = {978-1-4503-8332-5},
  language = {en}
}

@article{zangSurveyCrossdomainRecommendation2021,
  title = {A {{Survey}} on {{Cross}}-Domain {{Recommendation}}: {{Taxonomies}}, {{Methods}}, and {{Future Directions}}},
  shorttitle = {A {{Survey}} on {{Cross}}-Domain {{Recommendation}}},
  author = {Zang, Tianzi and Zhu, Yanmin and Liu, Haobing and Zhang, Ruohan and Yu, Jiadi},
  year = {2021},
  month = aug,
  abstract = {Traditional recommendation systems are faced with two long-standing obstacles, namely, data sparsity and cold-start problems, which promote the emergence and development of Cross-Domain Recommendation (CDR). The core idea of CDR is to leverage information collected from other domains to alleviate the two problems in one domain. Over the last decade, many efforts have been engaged for cross-domain recommendation. Recently, with the development of deep learning and neural networks, a large number of methods have emerged. However, there is a limited number of systematic surveys on CDR, especially regarding the latest proposed methods as well as the recommendation scenarios and recommendation tasks they address. In this survey paper, we first proposed a two-level taxonomy of cross-domain recommendation which classifies different recommendation scenarios and recommendation tasks. We then introduce and summarize existing cross-domain recommendation approaches under different recommendation scenarios in a structured manner. We also organize datasets commonly used. We conclude this survey by providing several potential research directions about this field.},
  archivePrefix = {arXiv},
  eprint = {2108.03357},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\48TCJUGA\\Zang 等。 - 2021 - A Survey on Cross-domain Recommendation Taxonomie.pdf},
  journal = {arXiv:2108.03357 [cs]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{zhangDeepContrastiveGraph2021,
  title = {Deep {{Contrastive Graph Representation}} via {{Adaptive Homotopy Learning}}},
  author = {Zhang, Rui and Lu, Chengjun and Jiao, Ziheng and Li, Xuelong},
  year = {2021},
  month = jun,
  abstract = {Homotopy model is an excellent tool exploited by diverse research works in the field of machine learning. However, its flexibility is limited due to lack of adaptiveness, i.e., manual fixing or tuning the appropriate homotopy coefficients. To address the problem above, we propose a novel adaptive homotopy framework (AH) in which the Maclaurin duality is employed, such that the homotopy parameters can be adaptively obtained. Accordingly, the proposed AH can be widely utilized to enhance the homotopy-based algorithm. In particular, in this paper, we apply AH to contrastive learning (AHCL) such that it can be effectively transferred from weaksupervised learning (given label priori) to unsupervised learning, where soft labels of contrastive learning are directly and adaptively learned. Accordingly, AHCL has the adaptive ability to extract deep features without any sort of prior information. Consequently, the affinity matrix formulated by the related adaptive labels can be constructed as the deep Laplacian graph that incorporates the topology of deep representations for the inputs. Eventually, extensive experiments on benchmark datasets validate the superiority of our method.},
  archivePrefix = {arXiv},
  eprint = {2106.09244},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\G96NDG7J\\Zhang 等。 - 2021 - Deep Contrastive Graph Representation via Adaptive.pdf},
  journal = {arXiv:2106.09244 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  language = {en},
  primaryClass = {cs}
}

@article{zhangDoubleScaleSelfSupervisedHypergraph2021,
  title = {Double-{{Scale Self}}-{{Supervised Hypergraph Learning}} for {{Group Recommendation}}},
  author = {Zhang, Junwei and Gao, Min and Yu, Junliang and Guo, Lei and Li, Jundong and Yin, Hongzhi},
  year = {2021},
  month = sep,
  doi = {10.1145/3459637.3482426},
  abstract = {With the prevalence of social media, there has recently been a proliferation of recommenders that shift their focus from individual modeling to group recommendation. Since the group preference is a mixture of various predilections from group members, the fundamental challenge of group recommendation is to model the correlations among members. Existing methods mostly adopt heuristic or attention-based preference aggregation strategies to synthesize group preferences. However, these models mainly focus on the pairwise connections of users and ignore the complex high-order interactions within and beyond groups. Besides, group recommendation suffers seriously from the problem of data sparsity due to severely sparse group-item interactions. In this paper, we propose a self-supervised hypergraph learning framework for group recommendation to achieve two goals: (1) capturing the intraand inter-group interactions among users; (2) alleviating the data sparsity issue with the raw data itself. Technically, for (1), a hierarchical hypergraph convolutional network based on the userand group-level hypergraphs is developed to model the complex tuplewise correlations among users within and beyond groups. For (2), we design a double-scale node dropout strategy to create selfsupervision signals that can regularize user representations with different granularities against the sparsity issue. The experimental analysis on multiple benchmark datasets demonstrates the superiority of the proposed model and also elucidates the rationality of the hypergraph modeling and the double-scale self-supervision.},
  archivePrefix = {arXiv},
  eprint = {2109.04200},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\3KK3NB3J\\notes.md;D\:\\Filez\\Zetero\\storage\\HC9TVF82\\Zhang et al_2021_Double-Scale Self-Supervised Hypergraph Learning for Group Recommendation.pdf},
  journal = {arXiv:2109.04200 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{zhangFewShotIntentDetection2021,
  title = {Few-{{Shot Intent Detection}} via {{Contrastive Pre}}-{{Training}} and {{Fine}}-{{Tuning}}},
  author = {Zhang, Jianguo and Bui, Trung and Yoon, Seunghyun and Chen, Xiang and Liu, Zhiwei and Xia, Congying and Tran, Quan Hung and Chang, Walter and Yu, Philip},
  year = {2021},
  month = sep,
  abstract = {In this work, we focus on a more challenging few-shot intent detection scenario where many intents are fine-grained and semantically similar. We present a simple yet effective fewshot intent detection schema via contrastive pre-training and fine-tuning. Specifically, we first conduct self-supervised contrastive pretraining on collected intent datasets, which implicitly learns to discriminate semantically similar utterances without using any labels. We then perform few-shot intent detection together with supervised contrastive learning, which explicitly pulls utterances from the same intent closer and pushes utterances across different intents farther. Experimental results show that our proposed method achieves state-of-the-art performance on three challenging intent detection datasets under 5shot and 10-shot settings.},
  archivePrefix = {arXiv},
  eprint = {2109.06349},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\X2DKDR89\\Zhang 等。 - 2021 - Few-Shot Intent Detection via Contrastive Pre-Trai.pdf},
  journal = {arXiv:2109.06349 [cs]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{zhangLatentStructuresMining,
  title = {Latent {{Structures Mining}} with {{Contrastive Modality Fusion}} for {{Multimedia Recommendation}}},
  author = {Zhang, Jinghao and Zhu, Yanqiao and Zhang, Mengqi and Wu, Shu and Wang, Liang},
  pages = {13},
  abstract = {Multimedia content is of predominance in the modern Web era. Recent years have witnessed growing research interests in multimedia recommendation, which aims to predict whether a user will interact with an item with multimodal contents. Most previous studies focus on modeling user-item interactions with multimodal features included as side information. However, this scheme is not well-designed for multimedia recommendation. Firstly, only collaborative item-item relationships are implicitly modeled through high-order item-user-item co-occurrences. Considering that items are associated with rich contents in multiple modalities, we argue that the latent semantic item-item structures underlying these multimodal contents could be beneficial for learning better item representations and assist the recommender models to comprehensively discover candidate items. Secondly, previous studies disregard the fine-grained multimodal fusion. Although having access to multiple modalities might allow us to capture rich information, we argue that the simple coarse-grained fusion by linear combination or concatenation in previous work is insufficient to fully understand content information of items and item relationships.To this end, we propose a latent structure MIning with ContRastive mOdality fusion method, which we term MICRO for brevity. To be specific, in the proposed MICRO model, we devise a novel modality-aware structure learning module, which learns item-item relationships for each modality. Based on the learned modality-aware latent item relationships, we perform graph convolutions which explicitly inject item affinities to modality-aware item representations. Additionally, we design a novel multi-modal contrastive framework to facilitate fine-grained multimodal fusion by forcing the modality-aware representation and multimodal fused representation to be close. Finally, these enriched item representations can be plugged into existing collaborative filtering methods to make more accurate recommendations. Extensive experiments on three real-world datasets demonstrate the superiority of our method over state-of-the-art multimedia recommendation methods and ablation studies validate the efficacy of mining latent item-item relationships and the contrastive multimodal fusion framework.},
  file = {D\:\\Filez\\Zetero\\storage\\AGCE3GNI\\Zhang et al_Latent Structures Mining with Contrastive Modality Fusion for Multimedia.pdf},
  language = {en}
}

@inproceedings{zhangTripletDeepSubspace2021,
  title = {Triplet {{Deep Subspace Clustering}} via {{Self}}-{{Supervised Data Augmentation}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  author = {Zhang, Zhao and Li, Xianzhen and Zhang, Haijun and Yang, Yi and Yan, Shuicheng and Wang, Meng},
  year = {2021},
  month = dec,
  pages = {946--955},
  publisher = {{IEEE}},
  address = {{Auckland, New Zealand}},
  doi = {10.1109/ICDM51629.2021.00106},
  abstract = {Deep subspace clustering (DSC) with the auto-encoder and self-expression layer is of great concern due to encouraging performance. However, existing methods usually adopt a ``single-task'' strategy based on a single dataset, without considering other related tasks or data. As such, they cannot discover other useful information to improve the clustering task. Besides, the local structure preservation of the latent codes in mapping is usually ignored. In this paper, we therefore present an effective ``multi-task'' strategy via the self-supervised data augmentation, and propose a new end-to-end trainable Triplet Deep Subspace Clustering Network (TDSC-net). Specifically, TDSC-net firstly generates triplet data (i.e., anchor, positive and negative data) from input data by a spectral clustering module and a self-supervised data augmentation module. This can enable it to inherit the merits of self-supervised learning and multitask learning implicitly. After that, TDSC-net builds a triplet deep autoencoder network with a self-expression layer, which takes the triplet data as input, where they share the common network layers (i.e., autoencoder and self-expression layers) over the triple tasks for complementary learning and mutual supervision. A triplet loss is also included to retain the local information of deep latent codes, which will also benefit the self-expression. Furthermore, TDSC-net separates the self-expression layer from decoding process to improve the efficiency of reconstruction. Extensive results on several public datasets demonstrate the effectiveness of our triplet-task DSC strategy.},
  file = {D\:\\Filez\\Zetero\\storage\\JVXVJLTU\\Zhang 等。 - 2021 - Triplet Deep Subspace Clustering via Self-Supervis.pdf},
  isbn = {978-1-66542-398-4},
  language = {en}
}

@article{zhangUnsupervisedSentenceEmbedding2021,
  title = {An {{Unsupervised Sentence Embedding Method}} by {{Mutual Information Maximization}}},
  author = {Zhang, Yan and He, Ruidan and Liu, Zuozhu and Lim, Kwan Hui and Bing, Lidong},
  year = {2021},
  month = feb,
  abstract = {BERT is inefficient for sentence-pair tasks such as clustering or semantic search as it needs to evaluate combinatorially many sentence pairs which is very time-consuming. Sentence BERT (SBERT) attempted to solve this challenge by learning semantically meaningful representations of single sentences, such that similarity comparison can be easily accessed. However, SBERT is trained on corpus with high-quality labeled sentence pairs, which limits its application to tasks where labeled data is extremely scarce. In this paper, we propose a lightweight extension on top of BERT and a novel self-supervised learning objective based on mutual information maximization strategies to derive meaningful sentence embeddings in an unsupervised manner. Unlike SBERT, our method is not restricted by the availability of labeled data, such that it can be applied on different domainspecific corpus. Experimental results show that the proposed method significantly outperforms other unsupervised sentence embedding baselines on common semantic textual similarity (STS) tasks and downstream supervised tasks. It also outperforms SBERT in a setting where in-domain labeled data is not available, and achieves performance competitive with supervised methods on various tasks. Our code is available at https://github.com/ yanzhangnlp/IS-BERT.},
  archivePrefix = {arXiv},
  eprint = {2009.12061},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\BWF5SQA8\\Zhang et al_2021_An Unsupervised Sentence Embedding Method by Mutual Information Maximization.pdf},
  journal = {arXiv:2009.12061 [cs]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{zhaoMultimodalGraphMeta2021,
  title = {Multimodal {{Graph Meta Contrastive Learning}}},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Zhao, Feng and Wang, Donglin},
  year = {2021},
  month = oct,
  pages = {3657--3661},
  publisher = {{ACM}},
  address = {{Virtual Event Queensland Australia}},
  doi = {10.1145/3459637.3482151},
  abstract = {In recent years, graph contrastive learning has achieved promising node classification accuracy using graph neural networks (GNNs), which can learn representations in an unsupervised manner. However, such representations cannot be generalized to unseen novel classes with only few-shot labeled samples in spite of exhibiting good performance on seen classes. In order to assign generalization capability to graph contrastive learning, we propose multimodal graph meta contrastive learning (MGMC) in this paper, which integrates multimodal meta learning into graph contrastive learning. On one hand, MGMC accomplishes effectively fast adapation on unseen novel classes by the aid of bilevel meta optimization to solve few-shot problems. On the other hand, MGMC can generalize quickly to a generic dataset with multimodal distribution by inducing the FiLM-based modulation module. In addition, MGMC incorporates the lastest graph contrastive learning method that does not rely on the construction of augmentations and negative examples. To our best knowledge, this is the first work to investigate graph contrastive learning for few-shot problems. Extensieve experimental results on three graph-structure datasets demonstrate the effectiveness of our proposed MGMC in few-shot node classification tasks.},
  file = {D\:\\Filez\\Zetero\\storage\\IYDPXYTW\\Zhao_Wang_2021_Multimodal Graph Meta Contrastive Learning.pdf},
  isbn = {978-1-4503-8446-9},
  language = {en}
}

@article{zhaoRankingUsersSocial,
  title = {Ranking {{Users}} in {{Social Networks}} with {{Higher}}-{{Order Structures}}},
  author = {Zhao, Huan and Xu, Xiaogang and Song, Yangqiu and Lee, Dik Lun and Chen, Zhao and Gao, Han},
  pages = {8},
  file = {D\:\\Filez\\Zetero\\storage\\DE4KDL9I\\Zhao et al_Ranking Users in Social Networks with Higher-Order Structures.pdf},
  language = {en}
}

@article{zhaoSelfDistillationEmbeddedSupervised2021,
  title = {A {{Self}}-{{Distillation Embedded Supervised Affinity Attention Model}} for {{Few}}-{{Shot Segmentation}}},
  author = {Zhao, Qi and Liu, Binghao and Lyu, Shuchang and Wang, Xu and Yang, Yifan},
  year = {2021},
  month = aug,
  abstract = {Few-shot semantic segmentation is a challenging task of predicting object categories in pixel-wise with only few annotated samples. However, existing approaches still face two main challenges. First, huge feature distinction between support and query images causes knowledge transferring barrier, which harms the segmentation performance. Second, few support samples cause unrepresentative of support features, hardly to guide high-quality query segmentation. To deal with the above two issues, we propose self-distillation embedded supervised affinity attention model (SD-AANet) to improve the performance of fewshot segmentation task. Specifically, the self-distillation guided prototype module (SDPM) extracts intrinsic prototype by selfdistillation between support and query to capture representative features. The supervised affinity attention module (SAAM) adopts support ground truth to guide the production of high quality query attention map, which can learn affinity information to focus on whole area of query target. Extensive experiments prove that our SD-AANet significantly improves the performance comparing with existing methods. Comprehensive ablation experiments and visualization studies also show the significant effect of SDPM and SAAM for few-shot segmentation task. On benchmark datasets, PASCAL-5i and COCO-20i, our proposed SD-AANet both achieve state-of-the-art results. Our code will be publicly available soon.},
  archivePrefix = {arXiv},
  eprint = {2108.06600},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\HXYU5M47\\Zhao et al_2021_A Self-Distillation Embedded Supervised Affinity Attention Model for Few-Shot.pdf},
  journal = {arXiv:2108.06600 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  language = {en},
  primaryClass = {cs}
}

@article{zhengContrastiveAttractionContrastive2021,
  title = {Contrastive {{Attraction}} and {{Contrastive Repulsion}} for {{Representation Learning}}},
  author = {Zheng, Huangjie and Chen, Xu and Yao, Jiangchao and Yang, Hongxia and Li, Chunyuan and Zhang, Ya and Zhang, Hao and Tsang, Ivor and Zhou, Jingren and Zhou, Mingyuan},
  year = {2021},
  month = jun,
  abstract = {Contrastive learning (CL) is effective in learning data representations without label supervision, where the encoder needs to contrast each positive sample over multiple negative samples via a one-vs-many softmax cross-entropy loss. However, conventional CL is sensitive to how many negative samples are included and how they are selected. Proposed in this paper is a doubly CL strategy that contrasts positive samples and negative ones within themselves separately. We realize this strategy with contrastive attraction and contrastive repulsion (CACR) makes the query not only exert a greater force to attract more distant positive samples but also do so to repel closer negative samples. Theoretical analysis reveals the connection between CACR and CL from the perspectives of both positive attraction and negative repulsion and shows the benefits in both efficiency and robustness brought by separately contrasting within the sampled positive and negative pairs. Extensive large-scale experiments on standard vision tasks show that CACR not only consistently outperforms existing CL methods on benchmark datasets in representation learning, but also provides interpretable contrastive weights, demonstrating the efficacy of the proposed doubly contrastive strategy.},
  archivePrefix = {arXiv},
  eprint = {2105.03746},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\BRLUZH38\\Zheng et al_2021_Contrastive Attraction and Contrastive Repulsion for Representation Learning.pdf},
  journal = {arXiv:2105.03746 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{zhengContrastiveAttractionContrastive2021a,
  title = {Contrastive {{Attraction}} and {{Contrastive Repulsion}} for {{Representation Learning}}},
  author = {Zheng, Huangjie and Chen, Xu and Yao, Jiangchao and Yang, Hongxia and Li, Chunyuan and Zhang, Ya and Zhang, Hao and Tsang, Ivor and Zhou, Jingren and Zhou, Mingyuan},
  year = {2021},
  month = jun,
  abstract = {Contrastive learning (CL) is effective in learning data representations without label supervision, where the encoder needs to contrast each positive sample over multiple negative samples via a one-vs-many softmax cross-entropy loss. However, conventional CL is sensitive to how many negative samples are included and how they are selected. Proposed in this paper is a doubly CL strategy that contrasts positive samples and negative ones within themselves separately. We realize this strategy with contrastive attraction and contrastive repulsion (CACR) makes the query not only exert a greater force to attract more distant positive samples but also do so to repel closer negative samples. Theoretical analysis reveals the connection between CACR and CL from the perspectives of both positive attraction and negative repulsion and shows the benefits in both efficiency and robustness brought by separately contrasting within the sampled positive and negative pairs. Extensive large-scale experiments on standard vision tasks show that CACR not only consistently outperforms existing CL methods on benchmark datasets in representation learning, but also provides interpretable contrastive weights, demonstrating the efficacy of the proposed doubly contrastive strategy.},
  archivePrefix = {arXiv},
  eprint = {2105.03746},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\TVPXYMSG\\Zheng 等。 - 2021 - Contrastive Attraction and Contrastive Repulsion f.pdf},
  journal = {arXiv:2105.03746 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@inproceedings{zhengMultiviewDenoisingGraph2021,
  title = {Multi-View {{Denoising Graph Auto}}-{{Encoders}} on {{Heterogeneous Information Networks}} for {{Cold}}-Start {{Recommendation}}},
  booktitle = {Proceedings of the 27th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Zheng, Jiawei and Ma, Qianli and Gu, Hao and Zheng, Zhenjing},
  year = {2021},
  month = aug,
  pages = {2338--2348},
  publisher = {{ACM}},
  address = {{Virtual Event Singapore}},
  doi = {10.1145/3447548.3467427},
  abstract = {Cold-start recommendation is a challenging problem due to the lack of user-item interactions. Recently, heterogeneous information network (HIN)-based recommendation methods use rich auxiliary information to enhance users and items' connections, helping alleviate the cold-start problem. Despite progress, most existing methods model HINs under traditional supervised learning settings, ignoring the gaps between training and inference procedures in cold-start scenarios. In this paper, we regard cold-start recommendation as a missing data problem where some user-item interaction data are missing. Inspired by denoising auto-encoders that train a model to reconstruct the input from its corrupted version, we propose a novel model called Multi-view Denoising Graph AutoEncoders (MvDGAE) on HINS. Specifically, we first extract multifaceted meaningful semantics on HINs as multi-views for both users and items, effectively enhancing user/item relationships on different aspects. Then we conduct the training procedure by randomly dropping out some user-item interactions in the encoder while forcing the decoder to use these limited views to recover the full views, including the missing ones. In this way, the complementary representations for both users and items are more informative and robust to adjust to cold-start scenarios. Moreover, the decoder's reconstruction goals are multi-view user-user and item-item relationship graphs rather than the original input graphs, which make the features of similar users (or items) in the meta-paths closer together. Finally, we adopt a Bayesian task weight learner to balance multi-view graph reconstruction objectives automatically. Extensive experiments on both public benchmark datasets and a large-scale industry dataset WeChat Channel demonstrate that MvDGAE significantly outperforms the state-of-the-art recommendation models in various cold-start scenarios. The case studies also illustrate that MvDGAE has potentially good interpretability.},
  file = {D\:\\Filez\\Zetero\\storage\\TS26A36X\\Zheng 等。 - 2021 - Multi-view Denoising Graph Auto-Encoders on Hetero.pdf},
  isbn = {978-1-4503-8332-5},
  language = {en}
}

@article{zhongSessionbasedRecommendationFlowbased2020,
  title = {Session-Based Recommendation via Flow-Based Deep Generative Networks and {{Bayesian}} Inference},
  author = {Zhong, Ting and Wen, Zijing and Zhou, Fan and Trajcevski, Goce and Zhang, Kunpeng},
  year = {2020},
  month = may,
  volume = {391},
  pages = {129--141},
  issn = {09252312},
  doi = {10.1016/j.neucom.2020.01.096},
  abstract = {We present a novel generative Session-Based Recommendation (SBR) framework, called VAriational SEssion-based Recommendation (VASER) \textendash{} a non-linear probabilistic methodology allowing Bayesian inference for flexible parameter estimation of sequential recommendations. Instead of directly applying extended Variational AutoEncoders (VAE) to SBR, the proposed method introduces normalizing flows to estimate the probabilistic posterior, which is more effective than the agnostic presumed prior approximation used in existing deep generative recommendation approaches. We also combine the effectiveness of both stochastic and amortized variational inference to reduce the inference gaps and to alleviate the underfitting problem of variational recommendation. We propose two specific implementations of VASER, both of which explore soft attention mechanism to upweight the important clicks in a session and show that one of them, treating the attention vector as an auxiliary latent factor, can make the variational distribution more expressive, and thus improves the recommendation accuracy over the widely used deterministic attention approaches. Empirically, we show that the proposed models significantly outperform several state-of-the-art baselines, including the recently-proposed RNN/VAE-based approaches, on several real-world datasets.},
  file = {D\:\\Filez\\Zetero\\storage\\JRKU6YBB\\am.pdf},
  journal = {Neurocomputing},
  language = {en}
}

@article{zhouContrastiveTrajectoryLearning2022,
  title = {Contrastive {{Trajectory Learning}} for {{Tour Recommendation}}},
  author = {Zhou, Fan and Wang, Pengyu and Xu, Xovee and Tai, Wenxin and Trajcevski, Goce},
  year = {2022},
  month = feb,
  volume = {13},
  pages = {1--25},
  issn = {2157-6904, 2157-6912},
  doi = {10.1145/3462331},
  abstract = {The main objective of Personalized Tour Recommendation (PTR) is to generate a sequence of point-of-interest (POIs) for a particular tourist, according to the user-specific constraints such as duration time, start and end points, the number of attractions planned to visit, and so on. Previous PTR solutions are based on either heuristics for solving the orienteering problem to maximize a global reward with a specified budget or approaches attempting to learn user visiting preferences and transition patterns with the stochastic process or recurrent neural networks. However, existing learning methodologies rely on historical trips to train the model and use the next visited POI as the supervised signal, which may not fully capture the coherence of preferences and thus recommend similar trips to different users, primarily due to the data sparsity problem and long-tailed distribution of POI popularity. This work presents a novel tour recommendation model by distilling knowledge and supervision signals from the trips in a self-supervised manner. We propose Contrastive Trajectory Learning for Tour Recommendation (CTLTR), which utilizes the intrinsic POI dependencies and traveling intent to discover extra knowledge and augments the sparse data via pre-training auxiliary self-supervised objectives. CTLTR provides a principled way to characterize the inherent data correlations while tackling the implicit feedback and weak supervision problems by learning robust representations applicable for tour planning. We introduce a hierarchical recurrent encoder-decoder to identify tourists' intentions and use the contrastive loss to discover subsequence semantics and their sequential patterns through maximizing the mutual information. Additionally, we observe that a data augmentation step as the preliminary of contrastive learning can solve the overfitting issue resulting from data sparsity. We conduct extensive experiments on a range of real-world datasets and demonstrate that our model can significantly improve the recommendation performance over the state-of-the-art baselines in terms of both recommendation accuracy and visiting orders.},
  file = {D\:\\Filez\\Zetero\\storage\\B6ZGEDUW\\Zhou et al_2022_Contrastive Trajectory Learning for Tour Recommendation.pdf},
  journal = {ACM Transactions on Intelligent Systems and Technology},
  language = {en},
  number = {1}
}

@article{zhouRecommendationCollaborativeAutoregressive2020,
  title = {Recommendation via {{Collaborative Autoregressive Flows}}},
  author = {Zhou, Fan and Mo, Yuhua and Trajcevski, Goce and Zhang, Kunpeng and Wu, Jin and Zhong, Ting},
  year = {2020},
  month = jun,
  volume = {126},
  pages = {52--64},
  issn = {08936080},
  doi = {10.1016/j.neunet.2020.03.010},
  abstract = {Although it is one of the most widely used methods in recommender systems, Collaborative Filtering (CF) still has difficulties in modeling non-linear user\textendash item interactions. Complementary to this, recently developed deep generative model variants (e.g., Variational Autoencoder (VAE)) allowing Bayesian inference and approximation of the variational posterior distributions in these models, have achieved promising performance improvement in many areas. However, the choices of variation distribution \textendash{} e.g., the popular diagonal-covariance Gaussians \textendash{} are insufficient to recover the true distributions, often resulting in biased maximum likelihood estimates of the model parameters.},
  file = {D\:\\Filez\\Zetero\\storage\\27SMP2ZR\\Zhou 等。 - 2020 - Recommendation via Collaborative Autoregressive Fl.pdf},
  journal = {Neural Networks},
  language = {en}
}

@inproceedings{zhouS3RecSelfSupervisedLearning2020,
  title = {S3-{{Rec}}: {{Self}}-{{Supervised Learning}} for {{Sequential Recommendation}} with {{Mutual Information Maximization}}},
  shorttitle = {S3-{{Rec}}},
  booktitle = {Proceedings of the 29th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Zhou, Kun and Wang, Hui and Zhao, Wayne Xin and Zhu, Yutao and Wang, Sirui and Zhang, Fuzheng and Wang, Zhongyuan and Wen, Ji-Rong},
  year = {2020},
  month = oct,
  pages = {1893--1902},
  publisher = {{ACM}},
  address = {{Virtual Event Ireland}},
  doi = {10.1145/3340531.3411954},
  abstract = {Recently, significant progress has been made in sequential recommendation with deep learning. Existing neural sequential recommendation models usually rely on the item prediction loss to learn model parameters or data representations. However, the model trained with this loss is prone to suffer from data sparsity problem. Since it overemphasizes the final performance, the association or fusion between context data and sequence data has not been well captured and utilized for sequential recommendation.},
  file = {D\:\\Filez\\Zetero\\storage\\2TWFNZNX\\notes.md;D\:\\Filez\\Zetero\\storage\\BDXAWHY7\\Zhou et al_2020_S3-Rec.pdf},
  isbn = {978-1-4503-6859-9},
  language = {en}
}

@article{zhouSELFCFSimpleFramework2015,
  title = {{{SELFCF}}: {{A Simple Framework}} for {{Self}}-Supervised {{Collaborative Filtering}}},
  author = {Zhou, Xin and Sun, Aixin and Liu, Yong and Zhang, Jie and Miao, Chunyan},
  year = {2015},
  volume = {14},
  pages = {11},
  abstract = {Collaborative filtering (CF) is widely used to learn an informative latent representation of a user or item from observed interactions. Existing CF-based methods commonly adopt negative sampling to discriminate different items. That is, observed user-item pairs are treated as positive instances; unobserved pairs are considered as negative instances and are sampled under a defined distribution for training. Training with negative sampling on large datasets is computationally expensive. Further, negative items should be carefully sampled under the defined distribution, in order to avoid selecting an observed positive item in the training dataset. Unavoidably, some negative items sampled from the training dataset could be positive in the test set. Recently, self-supervised learning (SSL) has emerged as a powerful tool to learn a model without negative samples. In this paper, we propose a self-supervised collaborative filtering framework (SELFCF), that is specially designed for recommender scenario with implicit feedback. The proposed SELFCF framework simplifies the Siamese networks and can be easily applied to existing deep-learning based CF models, which we refer to as backbone networks. The main idea of SELFCF is to augment the output embeddings generated by backbone networks, because it is infeasible to augment raw input of user/item ids. We propose and study three output perturbation techniques that can be applied to different types of backbone networks including both traditional CF models and graph-based models. The framework enables learning informative representations of users and items without negative samples, and is agnostic to the encapsulated backbones. By encapsulating two popular recommendation models into the framework, our experiments on three datasets show that the best performance of our framework is comparable or better than the supervised counterpart. We also show that SELFCF can boost up the performance by up to 8.93\% on average, compared with another self-supervised framework as the baseline. Source codes are available at: https://github.com/enoche/SelfCF.},
  file = {D\:\\Filez\\Zetero\\storage\\NZDDEX63\\Zhou et al_2015_SELFCF.pdf},
  language = {en},
  number = {8}
}

@article{zhouSelfCFSimpleFramework2021,
  title = {{{SelfCF}}: {{A Simple Framework}} for {{Self}}-Supervised {{Collaborative Filtering}}},
  shorttitle = {{{SelfCF}}},
  author = {Zhou, Xin and Sun, Aixin and Liu, Yong and Zhang, Jie and Miao, Chunyan},
  year = {2021},
  month = jul,
  abstract = {Collaborative filtering (CF) is widely used to learn an informative latent representation of a user or item from observed interactions. Existing CF-based methods commonly adopt negative sampling to discriminate different items. That is, observed user-item pairs are treated as positive instances; unobserved pairs are considered as negative instances and are sampled under a defined distribution for training. Training with negative sampling on large datasets is computationally expensive. Further, negative items should be carefully sampled under the defined distribution, in order to avoid selecting an observed positive item in the training dataset. Unavoidably, some negative items sampled from the training dataset could be positive in the test set. Recently, self-supervised learning (SSL) has emerged as a powerful tool to learn a model without negative samples. In this paper, we propose a self-supervised collaborative filtering framework (SELFCF), that is specially designed for recommender scenario with implicit feedback. The proposed SELFCF framework simplifies the Siamese networks and can be easily applied to existing deep-learning based CF models, which we refer to as backbone networks. The main idea of SELFCF is to augment the output embeddings generated by backbone networks, because it is infeasible to augment raw input of user/item ids. We propose and study three output perturbation techniques that can be applied to different types of backbone networks including both traditional CF models and graph-based models. The framework enables learning informative representations of users and items without negative samples, and is agnostic to the encapsulated backbones. By encapsulating two popular recommendation models into the framework, our experiments on three datasets show that the best performance of our framework is comparable or better than the supervised counterpart. We also show that SELFCF can boost up the performance by up to 8.93\% on average, compared with another self-supervised framework as the baseline. Source codes are available at: https://github.com/enoche/SelfCF.},
  archivePrefix = {arXiv},
  eprint = {2107.03019},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\ABG63HI2\\Zhou 等。 - 2021 - SelfCF A Simple Framework for Self-supervised Col.pdf},
  journal = {arXiv:2107.03019 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{zhuangCollaborativeUnsupervisedVisual2021,
  title = {Collaborative {{Unsupervised Visual Representation Learning}} from {{Decentralized Data}}},
  author = {Zhuang, Weiming and Gan, Xin and Wen, Yonggang and Zhang, Shuai and Yi, Shuai},
  year = {2021},
  month = aug,
  abstract = {Unsupervised representation learning has achieved outstanding performances using centralized data available on the Internet. However, the increasing awareness of privacy protection limits sharing of decentralized unlabeled image data that grows explosively in multiple parties (e.g., mobile phones and cameras). As such, a natural problem is how to leverage these data to learn visual representations for downstream tasks while preserving data privacy. To address this problem, we propose a novel federated unsupervised learning framework, FedU. In this framework, each party trains models from unlabeled data independently using contrastive learning with an online network and a target network. Then, a central server aggregates trained models and updates clients' models with the aggregated model. It preserves data privacy as each party only has access to its raw data. Decentralized data among multiple parties are normally non-independent and identically distributed (nonIID), leading to performance degradation. To tackle this challenge, we propose two simple but effective methods: 1) We design the communication protocol to upload only the encoders of online networks for server aggregation and update them with the aggregated encoder; 2) We introduce a new module to dynamically decide how to update predictors based on the divergence caused by non-IID. The predictor is the other component of the online network. Extensive experiments and ablations demonstrate the effectiveness and significance of FedU. It outperforms training with only one party by over 5\% and other methods by over 14\% in linear and semi-supervised evaluation on non-IID data.},
  archivePrefix = {arXiv},
  eprint = {2108.06492},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\93F3Q9KH\\Zhuang et al_2021_Collaborative Unsupervised Visual Representation Learning from Decentralized.pdf},
  journal = {arXiv:2108.06492 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{zhuangComprehensiveSurveyTransfer2020,
  title = {A {{Comprehensive Survey}} on {{Transfer Learning}}},
  author = {Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
  year = {2020},
  month = jun,
  abstract = {Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge contained in different but related source domains. In this way, the dependence on a large number of target domain data can be reduced for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances in transfer learning. Due to the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect and systematize the existing transfer learning researches, as well as to summarize and interpret the mechanisms and the strategies of transfer learning in a comprehensive way, which may help readers have a better understanding of the current research status and ideas. Unlike previous surveys, this survey paper reviews more than forty representative transfer learning approaches, especially homogeneous transfer learning approaches, from the perspectives of data and model. The applications of transfer learning are also briefly introduced. In order to show the performance of different transfer learning models, over twenty representative transfer learning models are used for experiments. The models are performed on three different datasets, i.e., Amazon Reviews, Reuters-21578, and Office-31. And the experimental results demonstrate the importance of selecting appropriate transfer learning models for different applications in practice.},
  archivePrefix = {arXiv},
  eprint = {1911.02685},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\5YTGZ3EC\\Zhuang 等。 - 2020 - A Comprehensive Survey on Transfer Learning.pdf},
  journal = {arXiv:1911.02685 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{zhuGraphContrastiveLearning2021,
  title = {Graph {{Contrastive Learning}} with {{Adaptive Augmentation}}},
  author = {Zhu, Yanqiao and Xu, Yichen and Yu, Feng and Liu, Qiang and Wu, Shu and Wang, Liang},
  year = {2021},
  month = apr,
  pages = {2069--2080},
  doi = {10.1145/3442381.3449802},
  abstract = {Recently, contrastive learning (CL) has emerged as a successful method for unsupervised graph representation learning. Most graph CL methods first perform stochastic augmentation on the input graph to obtain two graph views and maximize the agreement of representations in the two views. Despite the prosperous development of graph CL methods, the design of graph augmentation schemes\textemdash a crucial component in CL\textemdash remains rarely explored. We argue that the data augmentation schemes should preserve intrinsic structures and attributes of graphs, which will force the model to learn representations that are insensitive to perturbation on unimportant nodes and edges. However, most existing methods adopt uniform data augmentation schemes, like uniformly dropping edges and uniformly shuffling features, leading to suboptimal performance. In this paper, we propose a novel graph contrastive representation learning method with adaptive augmentation that incorporates various priors for topological and semantic aspects of the graph. Specifically, on the topology level, we design augmentation schemes based on node centrality measures to highlight important connective structures. On the node attribute level, we corrupt node features by adding more noise to unimportant node features, to enforce the model to recognize underlying semantic information. We perform extensive experiments of node classification on a variety of real-world datasets. Experimental results demonstrate that our proposed method consistently outperforms existing state-of-the-art baselines and even surpasses some supervised counterparts, which validates the effectiveness of the proposed contrastive framework with adaptive augmentation.},
  archivePrefix = {arXiv},
  eprint = {2010.14945},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\M4NGNPDP\\Zhu et al_2021_Graph Contrastive Learning with Adaptive Augmentation.pdf;D\:\\Filez\\Zetero\\storage\\WMP7KGS9\\GCA-main.zip},
  journal = {Proceedings of the Web Conference 2021},
  keywords = {Computer Science - Machine Learning},
  language = {en}
}

@inproceedings{zhuImprovingTopKRecommendation2019,
  title = {Improving {{Top}}-{{K Recommendation}} via {{JointCollaborative Autoencoders}}},
  booktitle = {The {{World Wide Web Conference}}},
  author = {Zhu, Ziwei and Wang, Jianling and Caverlee, James},
  year = {2019},
  month = may,
  pages = {3483--3482},
  publisher = {{ACM}},
  address = {{San Francisco CA USA}},
  doi = {10.1145/3308558.3313678},
  abstract = {In this paper, we propose a Joint Collaborative Autoencoder framework that learns both user-user and item-item correlations simultaneously, leading to a more robust model and improved top-K recommendation performance. More specifically, we show how to model these user-item correlations and demonstrate the importance of careful normalization to alleviate the influence of feedback heterogeneity. Further, we adopt a pairwise hinge-based objective function to maximize the top-K precision and recall directly for top-K recommenders. Finally, a mini-batch optimization algorithm is proposed to train the proposed model. Extensive experiments on three public datasets show the effectiveness of the proposed framework over state-of-the-art non-neural and neural alternatives.},
  file = {D\:\\Filez\\Zetero\\storage\\NU83N6AM\\Zhu 等。 - 2019 - Improving Top-K Recommendation via JointCollaborat.pdf},
  isbn = {978-1-4503-6674-8},
  language = {en}
}

@article{zhuSelfsupervisedRecommendationCrosschannel2021,
  title = {Self-Supervised {{Recommendation}} with {{Cross}}-Channel {{Matching Representation}} and {{Hierarchical Contrastive Learning}}},
  author = {Zhu, Dongjie and Sun, Yundong and Du, Haiwen and Tian, Zhaoshuo},
  year = {2021},
  month = sep,
  abstract = {Recently, using different channels to model social semantic information, and using self-supervised learning tasks to maintain the characteristics of each channel when fusing the information, which has been proven to be a very promising work. However, how to deeply dig out the relationship between different channels and make full use of it while maintaining the uniqueness of each channel is a problem that has not been well studied and resolved in this field. Under such circumstances, this paper explores and verifies the deficiency of directly constructing contrastive learning tasks on different channels with practical experiments and proposes the scheme of interactive modeling and matching representation across different channels. This is the first attempt in the field of recommender systems, we believe the insight of this paper is inspirational to future self-supervised learning research based on multi-channel information. To solve this problem, we propose a cross-channel matching representation model based on attentive interaction, which realizes efficient modeling of the relationship between cross-channel information. Based on this, we also proposed a hierarchical self-supervised learning model, which realized two levels of self-supervised learning within and between channels and improved the ability of self-supervised tasks to autonomously mine different levels of potential information. We have conducted abundant experiments, and many experimental metrics on multiple public data sets show that the method proposed in this paper has a significant improvement compared with the state-of-the-art methods, no matter in the general or cold-start scenario. And in the experiment of model variant analysis, the benefits of the cross-channel matching representation model and the hierarchical self-supervised model proposed in this paper are also fully verified.},
  archivePrefix = {arXiv},
  eprint = {2109.00676},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\FHDNL4BJ\\Zhu et al_2021_Self-supervised Recommendation with Cross-channel Matching Representation and.pdf},
  journal = {arXiv:2109.00676 [cs]},
  keywords = {Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}

@article{zhuStructureAwareHardNegative2021,
  title = {Structure-{{Aware Hard Negative Mining}} for {{Heterogeneous Graph Contrastive Learning}}},
  author = {Zhu, Yanqiao and Xu, Yichen and Cui, Hejie and Yang, Carl and Liu, Qiang and Wu, Shu},
  year = {2021},
  month = aug,
  abstract = {Recently, heterogeneous Graph Neural Networks (GNNs) have become a de facto model for analyzing HGs, while most of them rely on a relative large number of labeled data. In this work, we investigate Contrastive Learning (CL), a key component in self-supervised approaches, on HGs to alleviate the label scarcity problem. We first generate multiple semantic views according to metapaths and network schemas. Then, by pushing node embeddings corresponding to different semantic views close to each other (positives) and pulling other embeddings apart (negatives), one can obtain informative representations without human annotations. However, this CL approach ignores the relative hardness of negative samples, which may lead to suboptimal performance. Considering the complex graph structure and the smoothing nature of GNNs, we propose a structure-aware hard negative mining scheme that measures hardness by structural characteristics for HGs. By synthesizing more negative nodes, we give larger weights to harder negatives with limited computational overhead to further boost the performance. Empirical studies on three real-world datasets show the effectiveness of our proposed method. The proposed method consistently outperforms existing state-of-the-art methods and notably, even surpasses several supervised counterparts.},
  archivePrefix = {arXiv},
  eprint = {2108.13886},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\LTDEBCLL\\2108.13886.pdf},
  journal = {arXiv:2108.13886 [cs]},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  language = {en},
  primaryClass = {cs}
}

@article{zhuVariationalBandwidthAutoencoder2021,
  title = {Variational {{Bandwidth Auto}}-Encoder for {{Hybrid Recommender Systems}}},
  author = {Zhu, Yaochen and Chen, Zhenzhong},
  year = {2021},
  month = aug,
  abstract = {Hybrid recommendations have recently attracted a lot of attention where user features are utilized as auxiliary information to address the sparsity problem caused by insufficient user-item interactions. However, extracted user features generally contain rich multimodal information, and most of them are irrelevant to the recommendation purpose. Therefore, excessive reliance on these features will make the model overfit on noise and difficult to generalize. In this article, we propose a variational bandwidth auto-encoder (VBAE) for recommendations, aiming to address the sparsity and noise problems simultaneously. VBAE first encodes user collaborative and feature information into Gaussian latent variables via deep neural networks to capture non-linear user similarities. Moreover, by considering the fusion of collaborative and feature variables as a virtual communication channel from an information-theoretic perspective, we introduce a user-dependent channel to dynamically control the information allowed to be accessed from the feature embeddings. A quantum-inspired uncertainty measurement of the hidden rating embeddings is proposed accordingly to infer the channel bandwidth by disentangling the uncertainty information in the ratings from the semantic information. Through this mechanism, VBAE incorporates adequate auxiliary information from user features if collaborative information is insufficient, while avoiding excessive reliance on noisy user features to improve its generalization ability to new users. Extensive experiments conducted on three real-world datasets demonstrate the effectiveness of the proposed method. Codes and datasets are released at https://github.com/yaochenzhu/vbae.},
  archivePrefix = {arXiv},
  eprint = {2105.07597},
  eprinttype = {arxiv},
  file = {D\:\\Filez\\Zetero\\storage\\AVL2NV3F\\Zhu 和 Chen - 2021 - Variational Bandwidth Auto-encoder for Hybrid Reco.pdf},
  journal = {arXiv:2105.07597 [cs]},
  keywords = {Computer Science - Databases,Computer Science - Information Retrieval},
  language = {en},
  primaryClass = {cs}
}


