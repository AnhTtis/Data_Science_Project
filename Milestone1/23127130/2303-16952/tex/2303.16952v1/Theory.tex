\section{Theory} \label{sec: theory}

We illustrate the potential of the DCO framework by analyzing the meta-learner process for a class of linear least-squares problems. Specifically, we let the tasks $\task$ be the least-squares problems
\begin{align} \label{eq:shiftls}
    \min_{\theta \in \R^p} \|X\theta - (y + X \Delta_i) \|_2^2,
\end{align}
where $X$ is a \emph{fixed} feature matrix with $X^{\top} X$ invertible and the regression targets vary using task-specific $\Delta_i$. We restrict our task-dependent regression target shifts to lie in the range space of $X$ for theoretical tractability and concreteness: note that each task assumes a shifted version of the same loss landscape, with the optimal weights also shifted by $\Delta_i$.

Namely, let $\theta' = (X^{\top} X)^{-1} X^{\top} y$ be the typical least-squares solution to \eqref{eq:shiftls} in the case where $\Delta_i=0$. It is then clear by inspection that $\theta^*_i = \theta' + \Delta_i$, and that the minimizing loss $\losst(\theta_i^*)$ is invariant to $i$; we thus denote the solution to \eqref{eq:shiftls} by $\lossopt$. Note that here we consider the case where training and validation data are identical for a particular task; i.e. $\losst = \lossv$. With some abuse of notation, our $k^{\textrm{th}}$ meta-optimization step target task loss
\begin{align} \label{eq:shiftlstarget}
   \lossttargetit \defeq \lossttarget(\Alg_1(\thetait{}{1}; \phit{k})) 
\end{align}
consists of an identically constructed task \eqref{eq:shiftls} with a distinct $\Delta$ and $\thetait{}{1}$. Concretely, we consider the performance on the target loss after one inner loop optimizer step using the meta-parameters $\phit{k}$ obtained from $k$ meta-optimization steps. Naturally, we expect that increasing both the number of meta-optimization steps $k$ and the number of training tasks $N$ should help reduce the target loss, ideally such that $\lossttargetit$ approaches the optimum $\lossopt$. This is formalized in Theorem~\ref{thm:main}.

\begin{theorem} \label{thm:main}
Consider executing Algorithm~\ref{alg:method} with the DCOGD optimizer \eqref{eq:DCO_general_descent} and $T=1$ on the set of shifted least-squares problems $\tasks$ introduced in \eqref{eq:shiftls}, each with an arbitrary but fixed initial parameter $\thetait{i}{1} \in \R^p$. Instantiate $\MetaAlg$ as standard GD with step size $\eta > 0$. Finally, define the set of vectors $\{Z_i\}_{i=1}^N$ by
\begin{align*}
    Z_i &\defeq \thetait{i}{1} - \Delta_i - \theta'.
\end{align*}
Then if $\{Z_i\}_{i=1}^N$ span $\R^p$, there exists a sufficiently small $\eta$ such that the one-step target task loss \eqref{eq:shiftlstarget}  approaches the optimum as the number of meta-steps $k \rightarrow \infty$; specifically,
\[
    \lossttargetit - \lossopt \leq O((1 - \epsilon)^k),
\]
for some $0 < \epsilon < 1$.
\end{theorem}
\begin{proof}
We can solve the gradient update from \eqref{eq:DCO_general_descent} in closed form. Doing this yields the following weight vector the $i$th task after one step on the inner problem:
% Should divide the l2 proximity term by 1/2
% Also should probably normalize total loss by 1/N
\begin{align}
    \thetait{i}{2} \defeq \thetait{i}{1} - B \grad{i}{1}.
\end{align}

The total loss $\losstotal$ with $T=1$ can therefore be written as:
\begin{align}
    \losstotal &= \frac{1}{N} \sum_{i=1}^N \| X (\thetait{i}{1} - B \grad{i}{1}) - (y + X \Delta_i) \|_2^2 \nonumber \\
   &= \frac{1}{N} \sum_{i=1}^N \| X B \grad{i}{1} - X \thetait{i}{1} + y + X \Delta_i \|_2^2.  \label{eq:shiftlsloss}
\end{align}

The meta-learning problem aims to minimize this loss over the meta-parameter $\phi = B$. We will proceed with two steps: (1) show that there exists a meta-parameter $B^*$ for which $\losstotal$ equals the optimal minimizer $l^*$, and (2) show that $B^*$ is attained by our meta-learning procedure.

The existence of such a minimizing $B^*$ can be shown directly by letting $B^* = (1/2) (X^{\top} X)^{-1}$. Noting that
\[
    \grad{i}{1} = 2X^{\top} X (\thetait{i}{1} - \Delta_i) - 2X^{\top} y
\]
from differentiation of \eqref{eq:shiftls}, we can substitute $B^*$ and $\grad{i}{1}$ into \eqref{eq:shiftlsloss} to yield:
\begin{align}
    \losstotal = \frac{1}{N} \sum_{i=1}^N \| (X^{\top} X)^{-1} X^{\top} y - y \|_2^2 = \lossopt.
\end{align}

We now show that $B^*$ is attained by the meta-learning procedure. Namely, we consider our total loss for each outer meta-learning step in Algorithm~\ref{alg:method} to be a function $\losstotal(B)$ of our meta-parameter $\phi=B$. We let $\lossttarget(B)$ be defined similarly. It is easy to verify that the gradient $\nabla_{B} \losstotal$ is Lipschitz in $B$; therefore, we aim to show strong convexity of $\losstotal$ in $B$ to complete the proof using standard convex optimization results.

For convenience, define $y_i' \defeq -X \thetait{i}{1} + y + X \Delta_i$. Substituting into \eqref{eq:shiftlsloss}, we want to show that the following is strictly convex:
\[
    \losstotal(B) = \frac{1}{N} \sum_{i=1}^N \| X B \grad{i}{1} + y_i' \|_2^2.
\]

Expanding the square, scaling, and dropping terms which are linear in $B$ and thus do not affect convexity, we have that $\losstotal(B)$ is strictly convex iff $f(B)$ is strictly convex, where
\[
    f(B) = \sum_{i=1}^N (\grad{i}{1})^{\top} B^{\top} X^{\top} X B \grad{i}{1}.
\]

With some abuse of notation, we aim to compute the Hessian of $f(B^v)$ with respect to the vectorized $B^v = \matvec(B)$. Using standard matrix calculus identities \cite{Petersen2008} gives
\begin{align*}
    \frac{\partial f}{\partial B} &= 2 \sum_{i=1}^N X^{\top} X B \grad{i}{1} (\grad{i}{1})^{\top} \\
   &= 2 X^{\top} X B \sum_{i=1}^N \grad{i}{1} (\grad{i}{1})^{\top}.
\end{align*}

In order to compute the Hessian, we need to express $\matvec(\frac{\partial f}{\partial B}) = \frac{\partial f}{\partial B^v}$. Using the standard identity $\matvec(ABC) = (C^{\top} \otimes A) \ \matvec(B)$ yields
\begin{align*}
    \frac{\partial f}{\partial B^v} &= \left(\sum_{i=1}^N \grad{i}{1} (\grad{i}{1})^{\top} \otimes 2 X^{\top} X \right) B^v.
\end{align*}

Note that the gradient of $f$ with respect to $B^v$ is now linear in $B^v$. It is therefore immediate that that our desired Hessian is a constant matrix
\begin{align*}
    \nabla^2_{B^v} f &= \sum_{i=1}^N \grad{i}{1} (\grad{i}{1})^{\top} \otimes 2 X^{\top} X.
\end{align*}

Note that the Kronecker product of positive definite matrices is positive definite. Since $X^{\top} X \succ 0$ by assumption, $\nabla^2_{B^v} f \succ 0$ (and therefore $\losstotal(B)$ is strictly convex) if $\sum_{i=1}^N \grad{i}{1} (\grad{i}{1})^{\top} \succ 0$. This occurs iff the set of vectors $\{\grad{i}{1}\}_{i=1}^N$ spans $\R^p$. Invertibility of $X^{\top} X$ implies that this is equivalent to the collection of vectors $\{Z_i\}_{i=1}^N$ spanning $\R^p$, where $Z_i$ is as defined in the theorem statement.

Therefore $\nabla^2_{B^v} f \succ 0$, and $\losstotal(B)$ is strongly convex. Letting $B^{(k)}$ denote the values of the meta-parameters after $k$ iterations of GD, by standard convex optimization results \cite[Theorem~3.6]{garrigos2023handbook} we have that for a sufficiently small step size $\eta$,
\begin{align*}
    \| B^{(k)} - B^* \|_2^2 \leq O\left((1 - \epsilon)^k \right),
\end{align*}
where $0 < \epsilon < 1$. As $\lossttarget(B)$ is Lipschitz on any bounded set around $B^*$, the linear convergence in parameter space implies linear convergence in value, and we have shown the desired statement.
\end{proof}

Note that the condition that $\{Z_i\}_{i=1}^{\infty}$ span $\R^p$ is satisfied almost surely for typical random initializations of $\thetait{i}{1}$. Theorem~\ref{thm:main} can thus be interpreted as follows: provided at least $N=p$ sensibly initialized meta-training tasks, the meta learner will eventually learn to solve any target task to arbitrary precision with \emph{exactly one} inner-loop gradient descent step. This is an interesting formal guarantee that suggests the expressive power of our DCO meta-learning framework. While this section focuses on a particularly simple and tractable family of shifted least-squares problems as a proof-of-concept, we expect that the DCO meta-learning framework provides a tractable avenue for more sophisticated convergence results.