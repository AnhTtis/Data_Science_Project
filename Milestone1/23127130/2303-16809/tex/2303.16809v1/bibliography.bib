@misc{bitcoin,
  author = {{Bitcoin developers}},
  title = {{Bitcoin referential implementation}},
  year = 2022,
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/bitcoin/bitcoin}},
  note={{(Accessed 2022-12-02)}}
}

@misc{xthin,
  author = {{Peter Tschipper}},
  title = {{BUIP010 Xtreme Thinblocks}},
  year = 2016,
  journal = {Bitcoin Forum},
  howpublished = {\url{https://bitco.in/forum/threads/buip010-passed-xtreme-thinblocks.774/}},
  note={{(Accessed 2022-12-02)}}
}

@misc{bitcoin_ancestor_score,
  author = {{Bitcoin developers}},
  title = {{Ancestor Score Sorting}},
  year = 2022,
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/bitcoin/bitcoin/blob/master/src/txmempool.h}},
  note={{(Accessed 2022-12-02)}}
}

@misc{compact_block,
  author = {{Matt Corallo}},
  title = {Compact Block Relay Protocol},
  year = 2016,
  publisher = {GitHub},
  journal = {Bitcoin Improvement Standard},
  howpublished = {\url{https://github.com/bitcoin/bips/blob/master/bip-0152.mediawiki}},
  note={{(Accessed 2022-12-02)}}
}

@INPROCEEDINGS{mes_ether_topo,
  author={Gao, Yue and Shi, Jinqiao and Wang, Xuebin and Tan, Qingfeng and Zhao, Can and Yin, Zelin},
  booktitle={2019 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={{Topology Measurement and Analysis on Ethereum P2P Network}}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/ISCC47284.2019.8969695}}

@ARTICLE{theory_model,
  author={Shahsavari, Yahya and Zhang, Kaiwen and Talhi, Chamseddine},
  journal={IEEE Transactions on Engineering Management}, 
  title={{A Theoretical Model for Block Propagation Analysis in Bitcoin Network}}, 
  year={2022},
  volume={69},
  number={4},
  pages={1459-1476},
  doi={10.1109/TEM.2020.2989170}}

@ARTICLE{ethna,
  author={Wang, Taotao and Zhao, Chonghe and Yang, Qing and Zhang, Shengli and Liew, Soung Chang},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={{Ethna: Analyzing the Underlying Peer-to-Peer Network of Ethereum Blockchain}}, 
  year={2021},
  volume={8},
  number={3},
  pages={2131-2146},
  doi={10.1109/TNSE.2021.3078181}}

@inproceedings{under_the_hood,
author = {Kiffer, Lucianna and Salman, Asad and Levin, Dave and Mislove, Alan and Nita-Rotaru, Cristina},
title = {{Under the Hood of the Ethereum Gossip Protocol}},
year = {2021},
isbn = {978-3-662-64330-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-64331-0\_23},
doi = {10.1007/978-3-662-64331-0\_23},
abstract = {Blockchain protocols’ primary security goal is consensus: one version of the global ledger that everyone in the network agrees on. Their proofs of security depend on assumptions on how well their peer-to-peer (P2P) overlay networks operate. Yet, surprisingly, little is understood about what factors influence the P2P network properties. In this work, we extensively study the Ethereum P2P network’s connectivity and its block propagation mechanism. We gather data on the Ethereum network by running the official Ethereum client, geth, modified to run as a “super peer” with many neighbors. We run this client in North America for over seven months, as well as shorter runs with multiple vantages around the world. Our results expose an incredible amount of churn, and a surprisingly small number of peers who are actually useful (that is, who propagate new blocks). We also find that a node’s location has a significant impact on when it hears about blocks, and that the precise behavior of this has changed over time (e.g., nodes in the US have become less likely to hear about new blocks first). Finally, we find prune blocks propagate faster than uncles.},
booktitle = {Financial Cryptography and Data Security: 25th International Conference, FC 2021, Virtual Event, March 1–5, 2021, Revised Selected Papers, Part II},
pages = {437–456},
numpages = {20}
}

@INPROCEEDINGS{cblocksim,
  author={Ma, Xuyang and Wu, Han and Xu, Du and Wolter, Katinka},
  booktitle={2022 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)}, 
  title={{CBlockSim: A Modular High-Performance Blockchain Simulator}}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICBC54727.2022.9805504}}

@article{chung2001diameter,
  title={{The diameter of sparse random graphs}},
  author={Chung, Fan and Lu, Linyuan},
  journal={Advances in Applied Mathematics},
  volume={26},
  number={4},
  pages={257--279},
  year={2001},
  publisher={Elsevier}
}

@InProceedings{txprobe,
author="Delgado-Segura, Sergi
and Bakshi, Surya
and P{\'e}rez-Sol{\`a}, Cristina
and Litton, James
and Pachulski, Andrew
and Miller, Andrew
and Bhattacharjee, Bobby",
editor="Goldberg, Ian
and Moore, Tyler",
title={{TxProbe: Discovering Bitcoin's Network Topology Using Orphan Transactions}},
booktitle="Financial Cryptography and Data Security",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="550--566",
abstract="Bitcoin relies on a peer-to-peer overlay network to broadcast transactions and blocks. From the viewpoint of network measurement, we would like to observe this topology so we can characterize its performance, fairness and robustness. However, this is difficult because Bitcoin is deliberately designed to hide its topology from onlookers. Knowledge of the topology is not in itself a vulnerability, although it could conceivably help an attacker performing targeted eclipse attacks or to deanonymize transaction senders.",
isbn="978-3-030-32101-7"
}

@misc{bitcoin_core_defcount,
  author = {{Bitcoin developers}},
  title = {Bitcoin Core implementation},
  year = 2022,
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/bitcoin/bitcoin/blob/v22.0/src/net.h\#L72}}
}

@INPROCEEDINGS{degwithunreachable,
  author={Grundmann, Matthias and Baumstark, Max and Hartenstein, Hannes},
  booktitle={2022 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)}, 
  title={{On the Peer Degree Distribution of the Bitcoin P2P Network}}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICBC54727.2022.9805511}}

﻿@article{ding2022,
author={Ding, Xiaoqiang and Zhao, Liushun and Luo, Lailong and Xie, Junjie and Guo, Deke and Li, Jinxi},
title={{Gauze: Enabling Communication-Friendly Block Synchronization with Cuckoo Filter}},
journal={Frontiers of Computer Science},
year={2022},
month={Sep},
day={17},
volume={17},
number={3},
pages={173403},
abstract={Block synchronization is an essential component of blockchain systems. Traditionally, blockchain systems tend to send all the transactions from one node to another for synchronization. However, such a method may lead to an extremely high network bandwidth overhead and significant transmission latency. It is crucial to speed up such a block synchronization process and save bandwidth consumption. A feasible solution is to reduce the amount of data transmission in the block synchronization process between any pair of peers. However, existing methods based on the Bloom filter or its variants still suffer from multiple roundtrips of communications and significant synchronization delay. In this paper, we propose a novel protocol named Gauze for fast block synchronization. It utilizes the Cuckoo filter (CF) to discern the transactions in the receiver's mempool and the block to verify, providing an efficient solution to the problem of set reconciliation in the P2P (Peer-to-Peer Network) network. By up to two rounds of exchanging and querying the CFs, the sending node can acknowledge whether the transactions in a block are contained by the receiver's mempool or not. Based on this message, the sender only needs to transfer the missed transactions to the receiver, which speeds up the block synchronization and saves precious bandwidth resources. The evaluation results show that Gauze outperforms existing methods in terms of the average processing latency (about 10{\texttimes} lower than Graphene) and the total synchronization space cost (about 10{\texttimes} lower than Compact Blocks) in different scenarios.},
issn={2095-2236},
doi={10.1007/s11704-022-1685-5},
url={https://doi.org/10.1007/s11704-022-1685-5}}

@ARTICLE{anas_empir,
  author={Imtiaz, Muhammad Anas and Starobinski, David and Trachtenberg, Ari},
  journal={IEEE Transactions on Network and Service Management}, 
  title={{Empirical Comparison of Block Relay Protocols}}, 
  year={2022},
  volume={},
  number={},
  pages={1-1},
  doi={10.1109/TNSM.2022.3195976}}

@INPROCEEDINGS{anas_churn_icbc,
  author={Imtiaz, Muhammad Anas and Starobinski, David and Trachtenberg, Ari and Younis, Nabeel},
  booktitle={2019 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)}, 
  title={{Churn in the Bitcoin Network: Characterization and Impact}}, 
  year={2019},
  volume={},
  number={},
  pages={431-439},
  doi={10.1109/BLOC.2019.8751297}}

@ARTICLE{anas_churn_tnsm,
  author={Imtiaz, Muhammad Anas and Starobinski, David and Trachtenberg, Ari and Younis, Nabeel},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Churn in the Bitcoin Network}, 
  year={2021},
  volume={18},
  number={2},
  pages={1598-1615},
  doi={10.1109/TNSM.2021.3050428}}

@ARTICLE{churn_misic,
  author={Motlagh, Saeideh G. and Mišić, Jelena and Mišić, Vojislav B.},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={{Impact of Node Churn in the Bitcoin Network}}, 
  year={2020},
  volume={7},
  number={3},
  pages={2104-2113},
  doi={10.1109/TNSE.2020.2974739}}

@INPROCEEDINGS{anas_orphan_icbc,
  author={Imtiaz, Muhammad Anas and Starobinski, David and Trachtenberg, Ari},
  booktitle={2020 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)}, 
  title={{Characterizing Orphan Transactions in the Bitcoin Network}}, 
  year={2020},
  volume={},
  number={},
  pages={1-9},
  doi={10.1109/ICBC48266.2020.9169449}}

@ARTICLE{anas_orphan_tnsm,
  author={Imtiaz, Muhammad Anas and Starobinski, David and Trachtenberg, Ari},
  journal={IEEE Transactions on Network and Service Management}, 
  title={{Investigating Orphan Transactions in the Bitcoin Network}}, 
  year={2021},
  volume={18},
  number={2},
  pages={1718-1731},
  doi={10.1109/TNSM.2021.3056949}}

@incollection{ozisik2019graphene,
  title={{Graphene: Efficient Interactive Set Reconciliation Applied to Blockchain Propagation}},
  author={Ozisik, A Pinar and Andresen, Gavin and Levine, Brian N and Tapp, Darren and Bissias, George and Katkuri, Sunny},
  booktitle={Proceedings of the ACM Special Interest Group on Data Communication},
  pages={303--317},
  year={2019}
}

@INPROCEEDINGS{blocksim_faria,
  author={Faria, Carlos and Correia, Miguel},
  booktitle={2019 IEEE International Conference on Blockchain (Blockchain)}, 
  title={{BlockSim: Blockchain Simulator}}, 
  year={2019},
  volume={},
  number={},
  pages={439-446},
  doi={10.1109/Blockchain.2019.00067}}

@ARTICLE{blocksim_alharby,  
AUTHOR={Alharby, Maher and van Moorsel, Aad},   
TITLE={BlockSim: An Extensible Simulation Tool for Blockchain Systems},      
JOURNAL={Frontiers in Blockchain},      
VOLUME={3},           
YEAR={2020},      
URL={https://www.frontiersin.org/articles/10.3389/fbloc.2020.00028},
DOI={10.3389/fbloc.2020.00028},
ISSN={2624-7852},
ABSTRACT={Both in the design and deployment of blockchain solutions many performance-impacting configuration choices need to be made. We introduce BlockSim, a framework and software tool to build and simulate discrete-event dynamic systems models for blockchain systems. BlockSim is designed to support the analysis of a large variety of blockchains and blockchain deployments as well as a wide set of analysis questions. At the core of BlockSim is a Base Model, which contains the main model constructs common across various blockchain systems organized in three abstraction layers (network, consensus, and incentives layer). The Base Model is usable for a wide variety of blockchain systems and can be extended easily to include system or deployment particulars. The BlockSim software tool provides a simulator that implements the Base Model in Python. The paper describes the Base Model, the simulator implementation, and the application of BlockSim to Bitcoin, Ethereum and other consensus algorithms. We validate BlockSim simulation results by comparison with performance results from actual systems and from other studies in the literature. We close the paper by a BlockSim simulation study of the impact of uncle blocks rewards on mining decentralization, for a variety of blockchain configurations.}
}

@INPROCEEDINGS{simblock,
  author={Banno, Ryohei and Shudo, Kazuyuki},
  booktitle={2019 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)}, 
  title={{Simulating a Blockchain Network with SimBlock}}, 
  year={2019},
  volume={},
  number={},
  pages={3-4},
  doi={10.1109/BLOC.2019.8751431}}

@InProceedings{utxo,
author="Delgado-Segura, Sergi and P{\'e}rez-Sol{\`a}, Cristina and Navarro-Arribas, Guillermo and Herrera-Joancomart{\'i}, Jordi",
editor="Zohar, Aviv and Eyal, Ittay and Teague, Vanessa and Clark, Jeremy and Bracciali, Andrea and Pintore, Federico and Sala, Massimiliano",
title={{Analysis of the Bitcoin UTXO Set}},
booktitle="Financial Cryptography and Data Security",
year="2019",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="78--91",
abstract="Bitcoin relies on the Unspent Transaction Outputs (UTXO) set to efficiently verify new generated transactions. Every unspent output, no matter its type, age, value or length is stored in every full node. In this paper we introduce a tool to study and analyze the UTXO set, along with a detailed description of the set format and functionality. Our analysis includes a general view of the set and quantifies the difference between the two existing formats up to the date. We also provide an accurate analysis of the volume of dust and unprofitable outputs included in the set, the distribution of the block height in which the outputs where included, and the use of non-standard outputs.",
isbn="978-3-662-58820-8"
}

@inproceedings{eppstein2011s,
author = {Eppstein, David and Goodrich, Michael T. and Uyeda, Frank and Varghese, George},
title = {{What's the Difference? Efficient Set Reconciliation without Prior Context}},
year = {2011},
isbn = {9781450307970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
note={doi: https://doi.org/10.1145/2018436.2018462},
doi = {10.1145/2018436.2018462},
abstract = {We describe a synopsis structure, the Difference Digest, that allows two nodes to compute the elements belonging to the set difference in a single round with communication overhead proportional to the size of the difference times the logarithm of the keyspace. While set reconciliation can be done efficiently using logs, logs require overhead for every update and scale poorly when multiple users are to be reconciled. By contrast, our abstraction assumes no prior context and is useful in networking and distributed systems applications such as trading blocks in a peer-to-peer network, and synchronizing link-state databases after a partition.Our basic set-reconciliation method has a similarity with the peeling algorithm used in Tornado codes [6], which is not surprising, as there is an intimate connection between set difference and coding. Beyond set reconciliation, an essential component in our Difference Digest is a new estimator for the size of the set difference that outperforms min-wise sketches [3] for small set differences.Our experiments show that the Difference Digest is more efficient than prior approaches such as Approximate Reconciliation Trees [5] and Characteristic Polynomial Interpolation [17]. We use Difference Digests to implement a generic KeyDiff service in Linux that runs over TCP and returns the sets of keys that differ between machines.},
booktitle = {Proceedings of the ACM SIGCOMM 2011 Conference},
pages = {218–229},
numpages = {12},
keywords = {difference digest, set difference, invertible bloom filter},
location = {Toronto, Ontario, Canada},
series = {SIGCOMM '11}
}

@InProceedings{dodis2004fuzzy,
author="Dodis, Yevgeniy
and Reyzin, Leonid
and Smith, Adam",
editor="Cachin, Christian
and Camenisch, Jan L.",
title={{Fuzzy Extractors: How to Generate Strong Keys from Biometrics and Other Noisy Data}},
booktitle="Advances in Cryptology - EUROCRYPT 2004",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="523--540",
abstract="We provide formal definitions and efficient secure techniques for turning biometric information into keys usable for any cryptographic application, andreliably and securely authenticating biometric data.",
note = {{ISBN: 978-3-540-24676-3}},
isbn="978-3-540-24676-3"
}

@INPROCEEDINGS{minsky2003set,
  author={Minsky, Y. and Trachtenberg, A. and Zippel, R.},
  booktitle={Proceedings. 2001 IEEE International Symposium on Information Theory (IEEE Cat. No.01CH37252)}, 
  title={Set reconciliation with nearly optimal communication complexity}, 
  year={2001},
  volume={},
  number={},
  pages={232-},
  note={doi: https://doi.org/10.1109/ISIT.2001.936095},
  doi={10.1109/ISIT.2001.936095}
}

@inproceedings{minsky2002practical,
  title={{Practical set reconciliation}},
  author={Minsky, Yaron and Trachtenberg, Ari},
  booktitle={40th Annual Allerton Conference on Communication, Control, and Computing},
  volume={248},
  year={2002},
  url={https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.456.7200}
}

﻿@ARTICLE{Watts1998,
author={Watts, Duncan J. and Strogatz, Steven H.},
title={{Collective dynamics of `small-world' networks}},
journal={Nature},
year={1998},
month={Jun},
day={01},
volume={393},
number={6684},
pages={440-442},
abstract={Networks of coupled dynamical systems have been used to model biological oscillators1,2,3,4, Josephson junction arrays5,6, excitable media7, neural networks8,9,10, spatial games11, genetic control networks12 and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks `rewired' to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them `small-world' networks, by analogy with the small-world phenomenon13,14 (popularly known as six degrees of separation15). The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices.},
issn={1476-4687},
doi={10.1038/30918},
url={https://doi.org/10.1038/30918}
}

@InProceedings{kademlia,
author="Maymounkov, Petar and Mazi{\`e}res, David", editor="Druschel, Peter and Kaashoek, Frans and Rowstron, Antony",
title={{Kademlia: A Peer-to-Peer Information System Based on the XOR Metric}},
booktitle="Peer-to-Peer Systems",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="53--65",
abstract="We describe a peer-to-peer distributed hash table with provable consistency and performance in a fault-prone environment. Our system routes queries and locates nodes using a novel XOR-based metric topology that simplifies the algorithm and facilitates our proof. The topology has the property that every message exchanged conveys or reinforces useful contact information. The system exploits this information to send parallel, asynchronous query messages that tolerate node failures without imposing timeout delays on users.",
isbn="978-3-540-45748-0"
}

@inproceedings{fan2014cuckoo,
author = {Fan, Bin and Andersen, Dave G. and Kaminsky, Michael and Mitzenmacher, Michael D.},
title = {Cuckoo Filter: Practically Better Than Bloom},
year = {2014},
isbn = {9781450332798},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
note={doi: https://doi.org/10.1145/2674005.2674994},
doi = {10.1145/2674005.2674994},
abstract = {In many networking systems, Bloom filters are used for high-speed set membership tests. They permit a small fraction of false positive answers with very good space efficiency. However, they do not permit deletion of items from the set, and previous attempts to extend "standard" Bloom filters to support deletion all degrade either space or performance.We propose a new data structure called the cuckoo filter that can replace Bloom filters for approximate set membership tests. Cuckoo filters support adding and removing items dynamically while achieving even higher performance than Bloom filters. For applications that store many items and target moderately low false positive rates, cuckoo filters have lower space overhead than space-optimized Bloom filters. Our experimental results also show that cuckoo filters outperform previous data structures that extend Bloom filters to support deletions substantially in both time and space.},
booktitle = {Proceedings of the 10th ACM International on Conference on Emerging Networking Experiments and Technologies},
pages = {75–88},
numpages = {14},
keywords = {compression, cuckoo hashing, bloom filters},
location = {Sydney, Australia},
series = {CoNEXT '14}
}

@article{bloomfilter,
author = {Bloom, Burton H.},
title = {Space/Time Trade-Offs in Hash Coding with Allowable Errors},
year = {1970},
issue_date = {July 1970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/362686.362692},
doi = {10.1145/362686.362692},
abstract = {In this paper trade-offs among certain computational factors in hash coding are analyzed. The paradigm problem considered is that of testing a series of messages one-by-one for membership in a given set of messages. Two new hash-coding methods are examined and compared with a particular conventional hash-coding method. The computational factors considered are the size of the hash area (space), the time required to identify a message as a nonmember of the given set (reject time), and an allowable error frequency.The new methods are intended to reduce the amount of space required to contain the hash-coded information from that associated with conventional methods. The reduction in space is accomplished by exploiting the possibility that a small fraction of errors of commission may be tolerable in some applications, in particular, applications in which a large amount of data is involved and a core resident hash area is consequently not feasible using conventional methods.In such applications, it is envisaged that overall performance could be improved by using a smaller core resident hash area in conjunction with the new methods and, when necessary, by using some secondary and perhaps time-consuming test to “catch” the small fraction of errors associated with the new methods. An example is discussed which illustrates possible areas of application for the new methods.Analysis of the paradigm problem demonstrates that allowing a small number of test messages to be falsely identified as members of the given set will permit a much smaller hash area to be used without increasing reject time.},
journal = {Commun. ACM},
month = {jul},
pages = {422–426},
numpages = {5},
keywords = {scatter storage, storage efficiency, searching, hash coding, retrieval trade-offs, storage layout, hash addressing, retrieval efficiency}
}

@article{orlitsky1993interactive,
  title={Interactive communication of balanced distributions and of correlated files},
  author={Orlitsky, Alon},
  journal={SIAM Journal on Discrete Mathematics},
  volume={6},
  number={4},
  pages={548--564},
  year={1993},
  publisher={SIAM}
}

@ARTICLE{karpovsky2003data,
  author={Karpovsky, M.G. and Levitin, L.B. and Trachtenberg, A.},
  journal={IEEE Transactions on Information Theory}, 
  title={Data verification and reconciliation with generalized error-control codes}, 
  year={2003},
  volume={49},
  number={7},
  pages={1788-1793},
  note={doi: https://doi.org/10.1109/TIT.2003.813498},
  doi={10.1109/TIT.2003.813498}
}

@ARTICLE{luo2021capacity,
  author={Luo, Lailong and Guo, Deke and Rottenstreich, Ori and Ma, Richard T. B. and Luo, Xueshan and Ren, Bangbang},
  journal={IEEE Transactions on Network and Service Management}, 
  title={A Capacity-Elastic Cuckoo Filter Design for Dynamic Set Representation}, 
  year={2021},
  volume={18},
  number={4},
  pages={4860-4874},
  note={doi: https://doi.org/TNSM.2021.3099433},
  doi={10.1109/TNSM.2021.3099433}
}

@ARTICLE{gensync,
  author={Boškov, Novak and Trachtenberg, Ari and Starobinski, David},
  journal={IEEE Transactions on Network and Service Management}, 
  title={GenSync: A New Framework for Benchmarking and Optimizing Reconciliation of Data}, 
  year={2022},
  volume={},
  number={},
  pages={1-1},
  doi={10.1109/TNSM.2022.3164369}}

@ARTICLE{reconsimilar,
  author={Gabrys, Ryan and Farnoud, Farzad},
  journal={IEEE Transactions on Communications}, 
  title={Reconciling Similar Sets of Data}, 
  year={2019},
  volume={67},
  number={8},
  pages={5217-5229},
  doi={10.1109/TCOMM.2019.2910578}}

﻿@Article{multiparty,
author={Mitzenmacher, Michael and Pagh, Rasmus},
title={{Simple multi-party set reconciliation}},
journal={Distributed Computing},
year={2018},
month={Nov},
day={01},
volume={31},
number={6},
pages={441-453},
abstract={Many distributed cloud-based services use multiple loosely consistent replicas of user information to avoid the high overhead of more tightly coupled synchronization. Periodically, the information must be synchronized, or reconciled. One can place this problem in the theoretical framework of set reconciliation: two parties {\$}{\$}A{\_}1{\$}{\$}and {\$}{\$}A{\_}2{\$}{\$}each hold a set of keys, named {\$}{\$}S{\_}1{\$}{\$}and {\$}{\$}S{\_}2{\$}{\$}respectively, and the goal is for both parties to obtain {\$}{\$}S{\_}1 {\backslash}cup S{\_}2{\$}{\$}. Typically, set reconciliation is interesting algorithmically when sets are large but the set difference {\$}{\$}|S{\_}1-S{\_}2|+|S{\_}2-S{\_}1|{\$}{\$}is small. In this setting the focus is on accomplishing reconciliation efficiently in terms of communication; ideally, the communication should depend on the size of the set difference, and not on the size of the sets. In this paper, we extend recent approaches using Invertible Bloom Lookup Tables (IBLTs) for set reconciliation to the multi-party setting. There are three or more parties {\$}{\$}A{\_}1,A{\_}2,{\backslash}ldots ,A{\_}n{\$}{\$}holding sets of keys {\$}{\$}S{\_}1,S{\_}2,{\backslash}ldots ,S{\_}n{\$}{\$}respectively, and the goal is for all parties to obtain {\$}{\$}{\backslash}cup {\_}i S{\_}i{\$}{\$}. While this could be done by pairwise reconciliations, we seek more effective methods. Our general approach can function even if the number of parties is not exactly known in advance, and with some additional cost can be used to determine which other parties hold missing keys. Our methodology uses network coding techniques in conjunction with IBLTs, allowing efficiency in network utilization along with efficiency obtained by passing messages of size {\$}{\$}O(|{\backslash}cup {\_}i S{\_}i - {\backslash}cap {\_}i S{\_}i|){\$}{\$}. By connecting reconciliation with network coding, we can provide efficient reconciliation methods for a number of natural distributed settings.},
issn={1432-0452},
doi={10.1007/s00446-017-0316-0},
url={https://doi.org/10.1007/s00446-017-0316-0}
}

@misc{iblt_new,
  doi = {10.48550/ARXIV.2211.05472},
  url = {https://arxiv.org/abs/2211.05472},
  author = {Lázaro, Francisco and Matuz, Balázs},
  keywords = {Information Theory (cs.IT), Databases (cs.DB), Data Structures and Algorithms (cs.DS), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {{A Rate-Compatible Solution to the Set Reconciliation Problem}},
  publisher = {arXiv},
  year = {2022},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@INPROCEEDINGS{goodrich2011invertible,
  author={Goodrich, Michael T. and Mitzenmacher, Michael},
  booktitle={2011 49th Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, 
  title={{Invertible bloom lookup tables}}, 
  year={2011},
  volume={},
  number={},
  pages={792-799},
  note={doi: https://doi.org/10.1109/Allerton.2011.6120248},
  doi={10.1109/Allerton.2011.6120248}
}

@INPROCEEDINGS{multiparty_cpi,
  author={Boral, Anudhyan and Mitzenmacher, Michael},
  booktitle={2014 52nd Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, 
  title={Multi-party set reconciliation using characteristic polynomials}, 
  year={2014},
  volume={},
  number={},
  pages={1182-1187},
  doi={10.1109/ALLERTON.2014.7028589}}

@ARTICLE{blockchain_consensus_survey,
  author={Xiao, Yang and Zhang, Ning and Lou, Wenjing and Hou, Y. Thomas},
  journal={IEEE Communications Surveys \& Tutorials}, 
  title={{A Survey of Distributed Consensus Protocols for Blockchain Networks}}, 
  year={2020},
  volume={22},
  number={2},
  pages={1432-1465},
  doi={10.1109/COMST.2020.2969706}}

@misc{srepsim_code, 
  author  = {Boškov, Novak}, 
  title   = {{SREPSim}}, 
  howpublished     = {\url{http://www.github.com/nislab/SREPSim}},
  note={{(Accessed 2023-02-02)}}
}
