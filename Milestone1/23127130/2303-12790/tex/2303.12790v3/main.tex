\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

\usepackage{multirow}
\usepackage{amsmath}
\usepackage{xfrac}
\usepackage[accsupp]{axessibility} % Improves PDF readability for those with visual impairments.
\usepackage{colortbl}

%%%%%%%%%

% Import additional packages in the preamble file, before hyperref
\input{preamble}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, 
% e.g. with the file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete *.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you should be clear).
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=cvprblue]{hyperref}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{makecell}
\usepackage{adjustbox}
\usepackage{hhline}

\usepackage{algorithm}
\usepackage{bm}
\usepackage{algorithmic}
\usepackage{listings}

\lstset{
  backgroundcolor=\color{white},
  basicstyle=\linespread{0.8}\fontsize{7.5pt}{7.5pt}\ttfamily\selectfont,
  columns=fullflexible,
  breaklines=true,
  captionpos=b,
  commentstyle=\fontsize{7.5pt}{7.5pt}\color{Green},
  keywordstyle=\fontsize{7.5pt}{7.5pt}\color{Blue},
  escapechar={|}, 
}


\usepackage{pifont} 
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\method}{{CrowdDiff}}

\usepackage[hyphens]{url} % DO NOT CHANGE THIS
\usetikzlibrary{positioning}

\usepackage{mathtools}
\usepackage{siunitx}
%#####################
\newcommand{\sota}{state-of-the-art}
\newcommand{\snr}{SNR}
\newcommand{\mapfont}[1]{\fontsize{#1}{#1}\selectfont}
\newcommand{\sect}[1]{Section {#1}}

\newcommand{\qnrf}{UCF-QNRF}
\newcommand{\shha}{ShanghaiTech A}
\newcommand{\ucf}{UCF-CC-50}
\newcommand{\shhb}{ShanghaiTech B}
\newcommand{\jhu}{JHU-Crowd++}
\newcommand{\nwpu}{NWPU-Crowd}

\newcommand{\fig}[1]{Fig. {#1}}
\newcommand{\tab}[1]{Table {#1}}

\newcommand{\first}[1]{\textbf{\textcolor{red}{#1}}}
\newcommand{\second}[1]{\textbf{\textcolor{blue}{#1}}}

\def\tablegap{-3 mm}
%%%%%%%%% TITLE
\title{\textit{CrowdDiff}: Multi-hypothesis Crowd Density Estimation using Diffusion Models}

%%%%%%%%% AUTHORS
\author{Yasiru Ranasinghe, Nithin Gopalakrishnan Nair, Wele Gedara Chaminda Bandara, and Vishal M. Patel\\
Johns Hopkins University, Baltimore, USA\\
{\tt\small \{dranasi1, ngopala2, wbandar1, vpatel36\}@jhu.edu}
}

\begin{document}
\maketitle

\setlength{\belowdisplayskip}{0pt} \setlength{\belowdisplayshortskip}{0pt}
\setlength{\abovedisplayskip}{0pt} \setlength{\abovedisplayshortskip}{0pt}

%%%%%%%%%%%%%% ABSTRACT %%%%%%%%%%%%%%
\begin{abstract}
Crowd counting is a fundamental problem in crowd analysis which is typically accomplished by estimating a crowd density map and summing over the density values. However, this approach suffers from background noise accumulation and loss of density due to the use of broad Gaussian kernels to create the ground truth density maps. This issue can be overcome by narrowing the Gaussian kernel. However, existing approaches perform poorly when trained with ground truth density maps with broad kernels. To deal with this limitation, we propose using conditional diffusion models to predict density maps, as diffusion models show high fidelity to training data during generation. With that, we present \method\ that generates the crowd density map as a reverse diffusion process. Furthermore, as the intermediate time steps of the diffusion process are noisy, we incorporate a regression branch for direct crowd estimation only during training to improve the feature learning. In addition, owing to the stochastic nature of the diffusion model, we introduce producing multiple density maps to improve the counting performance contrary to the existing crowd counting pipelines. We conduct extensive experiments on publicly available datasets to validate the effectiveness of our method. \method\ outperforms existing \sota\ crowd counting methods on several public crowd analysis benchmarks with significant improvements. \method\ project is available at: \href{https://dylran.github.io/crowddiff.github.io}{https://dylran.github.io/crowddiff.github.io}.
\end{abstract}

%%%%%%%%%%%%%% FIGURE 1 %%%%%%%%%%%%%%
% Density reproduction comparison
\input{plots/1_first_graph}
%%%%%%%%%%%%%% FIGURE 1 %%%%%%%%%%%%%%

%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%
\section{Introduction}
\label{sec: introduction}
Crowd counting has been a fundamental problem in surveillance, public safety, and crowd control. Various methods have been proposed in the literature, including methods that directly predict the count \cite{liang2022transcrowd, zhang2019attentional, wang2019learning} or use a surrogate task such as density estimation \cite{hu2020count, jiang2020attention, wang2020distribution, song2021choose, wan2020kernel, tian2021cctrans}, object detection \cite{liu2019point, sam2020locate}, or point localization \cite{song2021rethinking, liang2022end, xu2022autoscale, gao2023application}. 

While density-based methods sum the estimated pixel density values for counting \cite{hu2020count}, localization-based methods count proposals with confidence scores higher than a threshold \cite{song2021rethinking}. As a result, density-based methods are more susceptible to introducing background noise into the final count compared to localization-based methods \cite{wan2019adaptive}. Furthermore, density estimation methods are affected by variations in crowd density distributions that arise due to different congestion levels of the crowd \cite{bai2020adaptive}. This could result in a loss of accuracy in the density estimation. In contrast, recent localization-based methods with point queries do not have the issue of background noise accumulation \cite{liang2022end}, like in density-based methods \cite{shu2022crowd}, as there is no interference between neighboring point proposals. However, localization-based methods require crowd density heuristics for proposal setting \cite{song2021rethinking}, which is not required by density-based methods. Thus, if the premise of point supervision is translated into density-based methods, it is possible to circumvent the requirement for crowd density heuristics, and the flaws of conventional density-based methods, and a narrow density kernel can be used to achieve this. However, Xu et al. \cite{xu2022autoscale} demonstrated that using a narrow kernel with density regression methods is ineffective.

Alternatively, it is feasible to use a generative model to predict the density map of a given crowd image that would learn the distribution of the values in the density map. Though Generative Adversarial Network (GAN) based architectures have been used for density map prediction \cite{yao2020mask, duan2021mask, shen2018crowd}, these methods still rely upon broad kernel sizes and overlook the benefits of point supervision. Since the model learns the distribution of the density pixel values, it is advantageous to maintain the sample space of the density pixel values, and employing a broad kernel will only discourage it. Furthermore, the use of both point supervision and crowd density prediction with generative models has not been thoroughly investigated before. Also, the aforementioned GAN-based approaches restrict to a single crowd density map realization similar to the regression-based methods and jettison the stochastic nature of generative models to produce multiple density map realizations, which could improve the counting performance.

We propose using denoising diffusion probabilistic models (diffusion models), \cite{ho2020denoising, nichol2021improved} to generate crowd density maps for a given image. Though diffusion models have been applied to segmentation \cite{amit2021segdiff, gu2022diffusioninst}, super-resolution \cite{li2022srdiff}, object detection \cite{chen2022diffusiondet}, etc., to the best of our knowledge, neither crowd counting nor density map generation has been studied with diffusion models. Furthermore, with the narrow kernel, we minimize the interference between adjacent densities, which helps to maintain the bounds and the distribution of density pixel values. This, in turn, simplifies the distribution learning for the diffusion model and improves density prediction as illustrated in \cref{figure: density comparison}, where the proposed method has reproduced the narrow kernel even in a dense region, while the other two recent methods failed.

Additionally, to eschew the probable loss of density with the density-based crowd counting methods, we count the number of blobs observed in the predicted density map by thresholding pixel density values. Consequently, we eliminate the effect of background noise as there is no requirement to sum over the density pixel values. Then, we introduce the crowd map fusion mechanism, combining multiple dot maps constructed after thresholding to improve the counting performance. This is only possible with generative models due to their stochastic nature. In addition, inspired by \cite{deja2023learning} on joint learning with diffusion models, we introduce an auxiliary regression branch only during training, which estimates the count based on encoder-decoder features  from the denoising network to improve feature learning. 

In summary, our contributions are:
\begin{itemize}[noitemsep]
    \item {\bf We formulate crowd density map generation as a denoising diffusion process.} \method\ is the first study to perform crowd counting with diffusion models.
    \item {\bf We promote using a narrow Gaussian kernel} to ease the learning process and facilitate the high-quality density map generation with more fidelity to the ground truth. 
    \item {\bf We propose a mechanism to consolidate multiple crowd density realizations}  to improve  performance utilizing the stochastic nature of diffusion models.
    \item {\bf We show that the proposed method surpasses the \sota\ performance} on public datasets.
\end{itemize}

%%%%%%%%%%%%%% RELATED WORK %%%%%%%%%%%%%%
\section{Background and Related Work}
\label{sec: related work}

\subsection{Crowd counting}
\label{subsec: crowd counting}
\textbf{Localization-based methods} perform counting by predicting the locations of heads, and generally, they involve predicting a bounding box \cite{lian2019density, liu2019point, sam2020locate, zhong2022mask} for each head. The literature has also proposed localization by points \cite{lian2019density} or blobs \cite{liu2019context}.  Recently, to remove the necessity of post-processing, such as non-maximum suppression, point localization \cite{song2021rethinking, liang2022end} was introduced to crowd counting.\\
\textbf{Density-based methods} \cite{liu2019counting, liu2020weighing, xiong2019open, li2018csrnet, miao2020shallow, liu2020adaptive, bai2020adaptive} attempt to produce a density map for a given crowd image. However, density-based methods suffer from background noise and loss of density \cite{ma2021learning, oh2020crowd, luo2020hybrid} in congested regions due to broad kernels. But, using a narrow Gaussian kernel to generate ground truths is ineffective according to \cite{xu2022autoscale} with regression networks. Hence, we treat the prediction of the density map as a generative task.

\subsection{Diffusion models for crowd density generation}
\label{subsec: diffusion model}
Diffusion models \cite{sohl2015deep} are defined based on a Markov chain with a forward and a reverse process. In the forward process, noise is gradually added to data; and is denoised in the reverse process. The forward process is formulated as,
    \[q(\mathbf{x_t}|\mathbf{x_{t-1}}) = \mathcal{N}(\mathbf{x_t}|\sqrt{1-\beta_t}\mathbf{x_{t-1}},\beta_t\mathbf{I}),\]
where the sample datum $\mathbf{x_0}$ is gradually transformed to a noisy sample $\mathbf{x_t}$ for $t \in \{1,\dots,T\}$ by adding Gaussian noise according to a noise variance schedule $\beta_1,\dots,\beta_T$. Here, $\mathbf{I}$ is the identity matrix. Nonetheless, $\mathbf{x_t}$ can be computed using $\mathbf{x_0}$ and a noise vector $\epsilon \sim \mathcal{N}(\mathbf{0},\mathbf{I})$ and with the forward transformation,
    \[\mathbf{x_t} = \sqrt{\bar{\alpha_t}}\mathbf{x_0} + \sqrt{\left(1-\bar{\alpha_t} \right)}\epsilon,\]
where $\bar{\alpha_t} \coloneqq \prod_{\tau=1}^t \alpha_\tau = \prod_{\tau=1}^t (1-\beta_\tau)$ and $\beta_\tau$.

In this work, we aim to perform crowd density map generation via the diffusion model. Hence, our data samples will be crowd density maps $\mathbf{x_0} \in \mathbb{R}^{H\times W}$, where $H \text{ and } W$ are the height and width dimensions. However, in lieu of training a neural network to predict $\mathbf{x_0}$ from $\mathbf{x_t}$ for various time steps, we predict the amount of noise ($\hat{\epsilon}$) in $\mathbf{x_t}$ at each time step conditioned on the crowd image ($\mathbf{y}$) and apply the reverse diffusion process to obtain $\mathbf{x_0}$ ultimately. 

To that end, to train the denoising diffusion network, we use the hybrid loss ($\mathcal{L}_{hybrid}$) function proposed in \cite{nichol2021improved}. To promote learning coarse features at lower \snr\ stages, we adopt the weighting scheme \cite{choi2022perception} defined as,
\begin{equation}
\label{equation: lambda}
    \lambda_t = \frac{\sfrac{(1-\beta_t)(1-\bar{\alpha_t})}{\beta_t}}{{\left(k + \text{\snr}{\scriptstyle(t)}\right)}^\gamma}, \text{where}\;\; \text{\snr}{\scriptstyle(t)} = \frac{\bar{\alpha_t}}{1-\bar{\alpha_t}}
\end{equation}
with $k$ and $\gamma$ as hyperparameters. Hence, the final loss over which the denoising network is optimized is  as follows,
    \[\mathcal{L}_{hybrid} = \mathbf{E}_{\mathbf{x_0},\mathbf{y},\epsilon} \left[ \lambda_t{\lVert\hat{\epsilon}_{(\mathbf{x_0},\mathbf{y},t)} - \epsilon\rVert}_2^2\right] + \lambda_{vlb}~\mathcal{L}_{vlb},\]
where $\mathcal{L}_{vlb}$ is the original variational lower bound defined in \cite{nichol2021improved} and $\lambda_{vlb}$ is its weighting factor.

%%%%%%%%%%%%%% FIGURE 2 %%%%%%%%%%%%%%
% CrowdDiff pipeline
\input{plots/2_crowddiff_pipeline}
%%%%%%%%%%%%%% FIGURE 2 %%%%%%%%%%%%%%

%%%%%%%%%%%%%% METHOD %%%%%%%%%%%%%%
\section{\method}
\label{sec: methods}
In this section, we first review the motivation for selecting an appropriate kernel size. We present the joint learning of counting as an auxiliary task to improve the density map generation performance. Finally, we introduce a method to combine different realizations for density maps to improve crowd counting performance. The overall crowd counting pipeline is illustrated in \cref{figure: diffusion crowd count pipeline}.

\subsection{Narrow kernel}
\label{subsec: narrow kernel}
The diffusion process requires a density map to learn the conditional distribution of crowd density. The crowd density map can be acquired by convolving point information with a pre-defined Gaussian kernel. For that, selecting a proper kernel size and variance is important as it governs the distribution of the pixel values of the crowd density maps.

As demonstrated in \cref{figure: pixel value distribution}, the divergence between the distribution of the Gaussian kernel (values) and the resulting density map increases as the kernel size and variance increase, especially for the congested scene. This might not be the case for sparse crowd scenes, as there is minimal or no interference between density kernels. However, this implies that the density pixel value distribution is highly image-dependent, hindering the crowd densities' learning. This can be eschewed by narrowing the distribution of the Gaussian kernel as illustrated in \cref{figure: pixel value distribution}. This also helps the denoising  network to maintain the pixel values within a pre-defined range. The difference between the probability mass of a broad Gaussian kernel and the resulting density map is significant. This can lead to the clipping of many pixel values, resulting in a loss of information in congested scenes.

The aforementioned issue can be solved by a narrow kernel. A narrow kernel provides an alternative path to crowd counting without summing over the density map values. As shown in \cref{figure: density comparison}, the crowd count can be obtained by simply counting the observable kernels. For that, we perform thresholding on the density maps and obtain the location of each kernel. Then, the crowd count is computed as the total number of locations. This provides the means to avoid background noise in the generated density maps and to obtain the crowd count by detecting these narrow kernels in the crowd density maps. Unlike the local maxima detection strategy proposed in \cite{liang2022focal} to detect head locations from a crowd density map, our method is not dependent on any hyperparameter tuning for detection.

%%%%%%%%%%%%%% FIGURE 3 %%%%%%%%%%%%%%
% Pixel value distribution difference
\input{plots/3_pixel_distribution}
%%%%%%%%%%%%%% FIGURE 3 %%%%%%%%%%%%%%

\subsection{Joint learning of counting}
\label{subsec: joint learning}
Directly regressing the crowd count from image features is a difficult task \cite{liang2022transcrowd} compared to counting with a surrogate task. To perform the direct computation of the crowd count, we consider the intermediate features of the encoder-decoder of the denoising U-Net. Let's denote the set of intermediate features from the denoising network for a particular timestep $t$ as $\mathcal{Z}_t = \{\mathbf{z}^1_t,\mathbf{z}^2_t,\dots,\mathbf{z}^d_t\}$, where $\mathbf{z}^{*}_t$ is the representation vector at the corresponding feature level of the decoder. Since the spatial dimensions of the intermediate representations at different depth levels are incompatible, global average pooling is performed on each $\mathbf{z}^*_t$, which are then concatenated to construct a single feature vector $\mathbf{z}_t$. This is then passed through the regression network to estimate the crowd count at various noise levels.

However, for a sampled pair ($\mathbf{x_0}, \mathbf{y}$), only the density map $\mathbf{x_0}$ is diffused with noise according to a noise schedule. Hence, the noise level in the set of intermediate features $\mathcal{Z}_t$ will vary with the timestep, and \snr\ will be lower in the later stages of the diffusion process than in the earlier stages. Hence, we utilize the weighting scheme discussed in \cref{subsec: diffusion model} during the training of the count regression network. We utilize $\mathcal{L}_1$ loss as follows, 
    \[\mathcal{L}_1^t = \lambda_t{\lVert\bar{c_t} - c\rVert}_1\]
to measure the difference between the prediction ($\bar{c_t}$) and the ground truth ($c$) for a given time step $t$ and a given sampled pair, where $\lambda_t$ is the same weighting factor used in \cref{equation: lambda}. As the training loss for the denoising model is the Monte-Carlo approximation of the sum over all timesteps, the training loss can be written as
    \[\mathcal{L}_{count} = \mathbb{E}_{\mathbf{x_0}, \mathbf{y}, t}\left[ \lambda_t{\lVert\bar{c_t} - c\rVert}_1 \right].\]
The overall training includes optimization over the parameters of the denoising network and the regression branch. Hence, the overall training objective is as follows,
    \[\mathcal{L}_{overall} = \mathcal{L}_{hybrid} + \lambda_{count}\mathcal{L}_{count},\]
where $\lambda_{count}$ is a weightage on the counting task.

%%%%%%%%%%%%%% FIGURE 4 %%%%%%%%%%%%%%
% Density fusion criterion
\input{plots/4_density_fusion}
%%%%%%%%%%%%%% FIGURE 4 %%%%%%%%%%%%%%

\subsection{Stochastic crowd map fusion}
\label{ssec: crowd density fusion}
The stochastic nature of the diffusion models could generate different realizations of the crowd density map for the same crowd image. Therefore, the counting performance with diffusion models can be improved with multiple realizations contrary to the traditional crowd counting methods as evidenced by other tasks based on diffusion models such as segmentation \cite{gu2022diffusioninst} and detection \cite{chen2022diffusiondet}. However, rather than averaging individual counts from different realizations, they could be combined to compute a more improved count because individual realizations could infer crowd densities that were not present in other realizations.

To combine different realizations for the  density maps, only the new information should be transferred to the compound  density map. For that, we first compute the locations of the density kernels by density thresholding. Once these locations are found, a dot map is constructed for each density map, referred to as the `crowd map.' Then, we consider the dissimilarity between the crowd maps from different realizations, and to measure that, we consider the structural similarity index measure (SSIM) \cite{wang2004image}. We assign a similarity score measured as the cumulative SSIM with the remaining crowd map realizations for each crowd map. Then, the maps will be arranged in the ascending order of the SSIM before combining. Further, we don't require the ground truth locations to combine different realizations; they are combined depending on the similarity of the crowd maps. 

Let’s consider four crowd maps. For a given crowd map (source map), we’ll measure the SSIM with each of the remaining three crowd maps, and the sum of those three SSIMs will be assigned as the similarity score of the source map. If the similarity score is the highest of a map, then it is the most similar to the remaining maps and likely to contain most of the point locations available in the remaining maps. Hence, the new points that can be added to and from the most similar map are minimal. Conversely, the crowd map with the least similarity score differs the most from the remaining maps; therefore, the new points that can be added to\,/\,from this map are maximal. Consequently, the best map to start the fusion process is the crowd map with the lowest similarity score. Likewise, we order the crowd maps in the ascending order of the similarity score to combine.

When fusing two crowd maps, it is necessary to reject repeating point locations. This is performed based on the locations of the new points compared to the points in the combined list. We take the crowd map first and the head locations from that realization as the reference. 
Next, we define a rejection radius for each head location as:
    \[r_n = \beta \frac{\sum_{i=1}^{\Tilde{k}}r_{ni}}{2\Tilde{k}}\]
by considering the {\it k}-nearest neighbors within a fixed range. Here $\beta$ is a scaling factor and $\Tilde{k}$ is the total nearest neighbors within the range. Next, we remove the head locations of the next crowd map locations that fall within the rejection radii in the reference map as illustrated in \cref{figure: density fusion method}, and the remaining locations are added to the reference map. This procedure is performed until all realizations are exhausted.

%%%%%%%%%%%%%% EXPERIMENTAL DETAILS %%%%%%%%%%%%%%
\section{Experimental Details}
\label{sec: experimental details}
\textbf{\method\ pipelines.} \underline{During training}, we create the ground truth density map with narrow kernels as described in \cref{subsec: narrow kernel}. Next, we randomly sample a timestep $t$. Then, we sample a Gaussian noise according to the variance at $t$ and add it to the ground truth map, resulting in the noisy map ($\mathbf{x_t}$). Then, we input the image and $\mathbf{x_t}$ to the denoising U-Net (network) and predict the noise added to the ground truth. Hence, based on the crowd image, the network is trained to predict the noise in $\mathbf{x_t}$. \underline{During inference}, we sample a Gaussian noise from $\mathcal{N}\left(\mathbf{0,I}\right)$ at time $T$, which is used as the initial noisy density map $\mathbf{x_T}$. Then, the network will estimate the noise present in $\mathbf{x_T}$, and by removing that noise, we produce the noisy density map ($\mathbf{x_{T-1}}$) at time $T-1$. Likewise, we’ll repeat the process where the noisy density map $\mathbf{x_{t-1}}$ at $t-1$ is estimated from the noisy density map $\mathbf{x_t}$ at time $t$ until we produce the density map ($\mathbf{x_0}$) for the image. Besides that, the counting branch output is discarded during inference.\\
\textbf{Diffusion process} uses 1,000 timesteps and DDIM sampling \cite{song2020denoising} during inference. We use a linear noise schedule with noise variance ranging from \num{1e-3} to 0.02.\\
\textbf{Hyperparameter values} $\lambda_{count}$ is set as \num{5e-3} to match the range of the value for $L_{hybrid}$. The $\gamma$ and $k$ values are set as 0.5 and 1, respectively, to compute the \snr-based weighting factors. We adopt the original scaling factor of \num{1e-3} for $\lambda_{vlb}$ following \cite{nichol2021improved}. For crowd map fusion, we set $\beta$ equal to 0.85 and the maximum nearest neighbors to four. The radius for the neighbor search was restricted to 0.05 of the minimum of the image dimensions.\\
\textbf{Training} of the denoising network is initialized with the ImageNet pre-trained weights for the super-resolution \cite{rombach2022high} task except for the input and output layers. The network is trained for \num{2e5} iterations with a batch size of 8 for $256\times256$ images. We use an AdamW optimizer with a fixed learning rate \num{1e-4} and a linear warm-up schedule over \num{5e3} training steps following \cite{wu2023boosting}.\\
\textbf{Evaluations} are performed on six public datasets:  \jhu \cite{sindagi2019pushing}, \shha \cite{zhang2016single}, \shhb \cite{zhang2016single}, \ucf \cite{idrees2013multi}, \qnrf \cite{idrees2018composition}, and \nwpu\cite{wang2020nwpu}. We use MAE and MSE as the performance metrics.

%%%%%%%%%%%%%% TABLE 1 %%%%%%%%%%%%%%
% Main quantitative result comparison
\input{tables/main_table}
%%%%%%%%%%%%%% TABLE 1 %%%%%%%%%%%%%%

%%%%%%%%%%%%%% TABLE 2 %%%%%%%%%%%%%%
% NWPU result comparison
\input{tables/nwpu}
%%%%%%%%%%%%%% TABLE 2 %%%%%%%%%%%%%%

%%%%%%%%%%%%%% RESULTS & ABLATION %%%%%%%%%%%%%%
\section{Results}
\label{sec: results and ablation}

\subsection{Crowd counting performance}
\label{subsec: main results}
\textbf{Quantitative results} for crowd counting are presented in \cref{table: crowd counting performance} for the proposed method with other existing methods. The proposed method achieves \sota\ crowd counting results on public crowd counting datasets, and two factors can explain the improvement. First, the proposed use of a narrow kernel has improved the counting results in dense regions by mitigating the loss of density values in contrast to conventional density-based methods. Second, we eliminate the effect of background noise on the crowd count, which scales with the image dimensions, by replacing density summation with thresholding followed by summation. The performance on \jhu, \qnrf, and \nwpu\ datasets explains the above effect of \method\ as these datasets contain dense crowd scenes and large image dimensions.
This was possible due to the capability to produce accurate density maps with better resemblance to ground truth maps with diffusion models. In \cref{tab: nwpu_counting}, we provide the performance on the \emph{test} set of the \nwpu\ dataset. In addition to the overall MAE, \method\ has the best performance in negative samples or sparse crowds similar to detection or localization-based methods. This is due to density thresholding because of the ability to produce narrow kernels without intersections.\\
\textbf{Qualitative results} are presented in \cref{figure: density comparison} and \cref{figure: crowd maps} for density map generation with diffusion models and crowd map generation with the proposed pipeline. As depicted in \cref{figure: density comparison}, the proposed method and the narrow kernel can accurately perform counting even in a dense region. In contrast, the other two methods have suffered from loss of density. Furthermore, our proposed pipeline has identified head locations accurately, which is impossible with existing density-based methods and without data heuristics, unlike localization-based methods.

%%%%%%%%%%%%%% FIGURE 5 %%%%%%%%%%%%%%
% CrowdDiff qualitative results
\input{plots/5_qualitative_results}
%%%%%%%%%%%%%% FIGURE 5 %%%%%%%%%%%%%%

%%%%%%%%%%%%%% FIGURE 6 %%%%%%%%%%%%%%
% Generative quality comparison
\input{plots/6_ablation_diffusion}
%%%%%%%%%%%%%% FIGURE 6 %%%%%%%%%%%%%%

\subsection{Ablation study}
\label{subsec: ablations}

\noindent\textbf{Diffusion models} are considered to have more fidelity to training data than GAN-based methods. From \cref{figure: gan ablation}, one can see that diffusion models have produced high-quality density maps with more accurate crowd counts while ASCSP \cite{shen2018crowd}, a GAN-based method, has failed. Furthermore, without the ability to produce narrow kernels in the predicted density maps, GAN-based methods have to use density summation as the counting operation, bringing back noise accumulation and loss of density. This highlights the importance of using diffusion models for crowd density map generation with detection as the counting operation.

\noindent\textbf{Stochastic crowd map} generation is a key benefit of diffusion-based generative models. In \cref{figure: stochastic image generation}, we provide qualitative results of two realizations for each crowd image. From  \cref{figure: stochastic image generation}, we can see that different realizations have information that is not present in other realizations. Furthermore, it is noteworthy that using a narrow kernel facilitates the ability to produce new knowledge that can be included in the final prediction. Otherwise, novel information captured by different realizations will be diluted by averaging the density maps had a larger kernel been used. Though this is a generative model, the proposed method has reassigned densities perfectly in certain instances, and for some cases, there is a slight shift in the location between realizations. This necessitates the need for the proposed crowd map fusion method since simply combing these shifted dots results in double counts and worsens the  performance otherwise.\\
\textbf{The counting branch} is added to improve the counting performance with the crowd density maps. We present the counting results for individual realizations with and without the regression network in \cref{table: counting branch ablation}. We consider the average error performance from different realizations to identify characteristic effects of the counting branch before combining them into a single crowd map. Adding the counting branch has improved the average counting results, and the variation in the counting results has been reduced. The counting branch also promotes feature learning for intermediate time steps with noisy features.

Furthermore, we considered the performance of the counting branch even though it is not used to predict the final count of \method. The error metrics for the counting branch are provided in \cref{table: counting performance ablation} along with \sota\ weakly-supervised crowd counting methods \cite{lei2021towards, liang2022transcrowd}. The counting branch can be considered as a subnetwork that was weakly supervised with features from the denoising network and in this regard, the counting branch of \method\ outperforms existing SOTA weakly-supervised methods.

\noindent\textbf{Crowd map fusion} leverages the stochastic nature of the crowd density maps produced by the diffusion process, and we adopt a systematic way to fuse the maps. In \cref{table: fusion method ablation}, we present the error metrics for three different methods: Random, Descend-SSIM, and Ascend-SSIM. In the {\it Random} method, we combine the maps in the order in which they are produced. In the {\it Descend-SSIM} method, we combine the maps in the order of decreasing similarity. In the {\it Ascend-SSIM} method, we combine the maps in the order of increasing similarity as described above. The iterative improvement with stochastic generation and the proposed fusion method is shown in \cref{figure: density fusion ablation}. From  \cref{table: fusion method ablation}, the counting performance has improved with the Ascend method, where more locally dissimilar realizations are combined initially. This observation is validated by the performance degradation with the Descend-SSIM method compared to both Ascend-SSIM and Random methods.

Additionally, the fusion of multiple realizations is prone to introduce false positives. Hence, we considered the localization and counting performance after fusing different realizations for \qnrf. We generated four additional realizations for this ablation study, and the corresponding results are provided in \cref{table: localization ablation} along with the respective inference time. From \cref{table: localization ablation}, we see that the localization and counting performance improves with multiple realizations, demonstrating the advantage of using a generative model and fusing the information from multiple realizations. However, a higher number of realizations increases the inference time, and the performance gain from four realizations to eight realizations is insignificant while the inference time has doubled. Consequently, we chose to produce four realizations as the optimal setting considering the performance and inference time trade-off.\\
\textbf{Density thresholding} is used as an alternative to density summation for the counting operation. The performance comparison between the two methods is tabulated in \cref{table: counting method ablation} for the best-performing realization of each dataset. From  \cref{table: counting method ablation}, we see that the density summation produces  inferior counting results than thresholding despite both methods using the same density map. This is because background noise accumulation with the summation operation and the thresholding method display better noise immunity.

%%%%%%%%%%%%%% FIGURE 7 %%%%%%%%%%%%%%
% Stochastic crowd map generation
\input{plots/7_ablation_stochastic}
%%%%%%%%%%%%%% FIGURE 7 %%%%%%%%%%%%%%


%%%%%%%%%%%%%% FIGURE 8 %%%%%%%%%%%%%%
% Crowd map fusion ablation
\input{plots/8_ablation_map_fusion}
%%%%%%%%%%%%%% FIGURE 8 %%%%%%%%%%%%%%

\noindent\textbf{Kernel size} of the density kernels used to generate the ground truth density map $\mathbf{x_0}$ affects the generation ability and performance of \method. We tabulate the performance with different kernel sizes in \cref{table: kernel ablation}.
We observed similar performance at $1 \times 1$ and $3 \times 3$ kernels, and the performance significantly dropped for the latter kernel sizes. This is because the kernel size affects the pixel value distribution of the density map, and the interference between adjacent kernels introduces true positives at local maxima.\\
\textbf{Rejection radius ($\beta$) and nearest neighbors ($k$)} influence the performance of the fusion of multiple realizations. The results for different $\beta$ and $k$ values are tabulated in \cref{table: beta ablation}. The rejection criterion is stable around the $\beta$ values from $0.80$ to $0.85$. Because a low $\beta$ value is susceptible to including false positives or duplicates, and a high $\beta$ value could also reject true positives. However, the performance difference for different $k$ values was insignificant and the best performing setting was selected.\\
\textbf{The inference process} of the diffusion-based models is iterative and, therefore, exacts higher inference times. However, since we threshold the density map to count the number of kernels rather than summing over the pixel density values, the proposed method is robust to residual noise in the background. With the above exception, we used DDIM sampling to improve the inference procedure by a factor of 20 rather than using the original number of diffusion steps without a significant performance drop. \\
More results and details can be found in the supplementary.

%%%%%%%%%%%%%% CONCLUSION %%%%%%%%%%%%%%
\section{Conclusions}
We proposed a novel crowd counting framework where density map generation was treated as a denoising diffusion process. The new framework allows using extremely narrow density kernels with which noise can be suppressed more robustly in crowd density maps. Consequently, we performed density kernel detection on crowd density maps which offered more immunity to noise than density summation. Also, the proposed method could iteratively improve the counting performance via multiple realizations, unlike other crowd counting frameworks, due to the stochastic nature of the generative models. Further, unlike existing density-based methods, our proposed method assigns density kernels at head positions without the need for data heuristics, as required in the localization-based methods.

%%%%%%%%%%%%%% TABLE 3 %%%%%%%%%%%%%%
% Counting branch addition ablation
\input{tables/ablation_counting_branch}
%%%%%%%%%%%%%% TABLE 3 %%%%%%%%%%%%%%

%%%%%%%%%%%%%% TABLE 4 %%%%%%%%%%%%%%
% Direct counting ablation
\input{tables/ablation_counting_performance}
%%%%%%%%%%%%%% TABLE 4 %%%%%%%%%%%%%%

%%%%%%%%%%%%%% TABLE 5 %%%%%%%%%%%%%%
% Crowd map fusion ablation
\input{tables/ablation_fusion_counting}
%%%%%%%%%%%%%% TABLE 5 %%%%%%%%%%%%%%

{\small
\section*{Acknowledgements}
This research is based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via [2022-21102100005]. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The US Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.
}

%%%%%%%%%%%%%% TABLE 6 %%%%%%%%%%%%%%
% Realization affect ablation
\input{tables/ablation_fusion_localization}
%%%%%%%%%%%%%% TABLE 6 %%%%%%%%%%%%%%

%%%%%%%%%%%%%% TABLE 7 %%%%%%%%%%%%%%
% Kernel size ablation
\input{tables/ablation_kernel_size}
%%%%%%%%%%%%%% TABLE 7 %%%%%%%%%%%%%%

%%%%%%%%%%%%%% TABLE 8 %%%%%%%%%%%%%%
% Counting operation ablation
\input{tables/ablation_density_threshold}
%%%%%%%%%%%%%% TABLE 8 %%%%%%%%%%%%%%

%%%%%%%%%%%%%% TABLE 9 %%%%%%%%%%%%%%
% Rejection parameter ablation
\input{tables/ablation_beta}
%%%%%%%%%%%%%% TABLE 9 %%%%%%%%%%%%%%

\input{main_supp}

{
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{main}
}

\end{document}