@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@article{dehghani2021efficiency,
  title={The efficiency misnomer},
  author={Dehghani, Mostafa and Arnab, Anurag and Beyer, Lucas and Vaswani, Ashish and Tay, Yi},
  journal={arXiv preprint arXiv:2110.12894},
  year={2021}
}

@InProceedings{Yuan_2021_ICCV,
    title     = {Tokens-to-Token ViT: Training Vision Transformers From Scratch on ImageNet},
    author    = {Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis E.H. and Feng, Jiashi and Yan, Shuicheng},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2021}
}

@inproceedings{mobileformer_cvpr2022,
  author    = {Yinpeng Chen and
               Xiyang Dai and
               Dongdong Chen and
               Mengchen Liu and
               Xiaoyi Dong and
               Lu Yuan and
               Zicheng Liu},
  title     = {Mobile-Former: Bridging MobileNet and Transformer},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2022}
}

@InProceedings{MobileViT,
  author    = {Sachin Mehta and
               Mohammad Rastegari},
  title     = {MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer},
  booktitle = {ICLR},
  year      = {2022}
}

@inproceedings{botnet_cvpr2021,
  author    = {Aravind Srinivas and
               Tsung{-}Yi Lin and
               Niki Parmar and
               Jonathon Shlens and
               Pieter Abbeel and
               Ashish Vaswani},
  title     = {Bottleneck Transformers for Visual Recognition},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2021}
}

@inproceedings{d2021convit,
  title={ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases},
  author={d'Ascoli, St{\'e}phane and Touvron, Hugo and Leavitt, Matthew and Morcos, Ari and Biroli, Giulio and Sagun, Levent},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning (ICML)},
  year={2021}
}

@article{li2021localvit,
  title={LocalViT: Bringing Locality to Vision Transformers},
  author={Li, Yawei and Zhang, Kai and Cao, Jiezhang and Timofte, Radu and Van Gool, Luc},
  journal={arXiv preprint arXiv:2104.05707},
  year={2021}
}

@InProceedings{cait,
    author    = {Touvron, Hugo and Cord, Matthieu and Sablayrolles, Alexandre and Synnaeve, Gabriel and J\'egou, Herv\'e},
    title     = {Going Deeper With Image Transformers},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2021}
}

@InProceedings{chen2021crossvit,
      title={CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification}, 
      author={Chun-Fu Chen and Quanfu Fan and Rameswar Panda},
      booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
      year={2021}
}

@InProceedings{Zhang_2021_ICCV,
    author    = {Zhang, Pengchuan and Dai, Xiyang and Yang, Jianwei and Xiao, Bin and Yuan, Lu and Zhang, Lei and Gao, Jianfeng},
    title     = {Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2021}
}

@InProceedings{mobilenext_eccv2020,
  author    = {Daquan Zhou and
               Qibin Hou and
               Yunpeng Chen and
               Jiashi Feng and
               Shuicheng Yan},
  title     = {Rethinking Bottleneck Structure for Efficient Mobile Network Design},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  year      = {2020},
}

@InProceedings{Ma_2018_shufflenetv2,
author = {Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
title = {ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
year = {2018}
}

@article{Howard2017MobileNets,
  title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
  journal={ArXiv},
  year={2017},
  volume={abs/1704.04861}
}



@InProceedings{Ding_2021_repvgg,
    author    = {Ding, Xiaohan and Zhang, Xiangyu and Ma, Ningning and Han, Jungong and Ding, Guiguang and Sun, Jian},
    title     = {RepVGG: Making VGG-Style ConvNets Great Again},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2021}
}

@article{chen2014deeplabv1,
  title={Semantic image segmentation with deep convolutional nets and fully connected crfs},
  author={Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L},
  journal={arXiv preprint arXiv:1412.7062},
  year={2014}
}

@inproceedings{ding2021diverse,
title={Diverse Branch Block: Building a Convolution as an Inception-like Unit},
author={Ding, Xiaohan and Zhang, Xiangyu and Han, Jungong and Ding, Guiguang},
booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
year={2021}
}

@InProceedings{Ding_2019_ICCV,
author = {Ding, Xiaohan and Guo, Yuchen and Ding, Guiguang and Han, Jungong},
title = {ACNet: Strengthening the Kernel Skeletons for Powerful CNN via Asymmetric Convolution Blocks},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
}

@inproceedings{NEURIPS2020_expandnets,
               author = {Guo, Shuxuan and Alvarez, Jose M. and Salzmann, Mathieu},
               booktitle = {Advances in Neural Information Processing Systems},
               title = {ExpandNets: Linear Over-parameterization to Train Compact Convolutional Networks},
               year = {2020}
}

@inproceedings{efficientnet_v2_quoc,
  author = {Tan, Mingxing and Le, Quoc V.},
  title = {EfficientNetV2: Smaller Models and Faster Training},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning (ICML)},
  year = {2021}
}

@inproceedings{Liu_ssd_2016,
	author = {Wei Liu and Dragomir Anguelov and Dumitru Erhan and Christian Szegedy and Scott Reed and Cheng-Yang Fu and Alexander C. Berg},
	title = {{SSD}: Single Shot {MultiBox} Detector},
	booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
	year = {2016}
}

@inproceedings{mscoco_lin_2014,
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
  title = {Microsoft COCO: Common Objects in Context},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  year = {2014}
}

@article{mmdetection,
  title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},
  author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and
             Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and
             Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and
             Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and
             Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong
             and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},
  journal= {arXiv preprint arXiv:1906.07155},
  year={2019}
}

@inproceedings{deng2009imagenet,
author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
title={Imagenet: A large-scale hierarchical image database},
booktitle={CVPR},
year={2009}
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
year = {2019}
}

@InProceedings{sgdsutskever13,
  title = 	 {On the importance of initialization and momentum in deep learning},
  author = 	 {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  year = 	 {2013}
}

@inproceedings{Szegedy2016cv,
author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
title = {Rethinking the Inception Architecture for Computer Vision},
booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2016}
}

@inproceedings{cosinelr_iclr2017,
  author = {Loshchilov, Ilya and Hutter, Frank},
  title = {SGDR: Stochastic Gradient Descent with Warm Restarts},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year = {2017}
}

@inproceedings{autoaugment_cvpr2019,
  author = {Cubuk, Ekin D. and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V.},
  title = {AutoAugment: Learning Augmentation Policies from Data},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2019}}
}

@InProceedings{Li_2021_ICCV_micronet,
    author    = {Li, Yunsheng and Chen, Yinpeng and Dai, Xiyang and Chen, Dongdong and Liu, Mengchen and Yuan, Lu and Liu, Zicheng and Zhang, Lei and Vasconcelos, Nuno},
    title     = {MicroNet: Improving Image Recognition With Extremely Low FLOPs},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2021}
}

@inproceedings{chen2020dynamic,
author = {Chen, Yinpeng and Dai, Xiyang and Liu, Mengchen and Chen, Dongdong and Yuan, Lu and Liu, Zicheng},
title = {Dynamic ReLU},
booktitle = {16th European Conference Computer Vision (ECCV 2020)},
year = {2020}
}

@article{hendrycks2016gelu,
  title={Gaussian Error Linear Units (GELUs)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{silu_2017_elfwing,
  title={Sigmoid-weighted linear units for neural network function approximation in reinforcement learning},
  author={Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  journal={Neural Networks},
  volume={107},
  pages={3--11},
  year={2018},
  publisher={Elsevier}
}


@article{agarap2018deep_relu,
  title={Deep learning using rectified linear units (relu)},
  author={Agarap, Abien Fred},
  journal={Neural and Evolutionary Computing},
  year={2018}
}

@inproceedings{hu2018senet,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}

@article{He2015,
	author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	title = {Deep Residual Learning for Image Recognition},
	journal = {arXiv preprint arXiv:1512.03385},
	year = {2015}
}

@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4510--4520},
  year={2018}
}
@article{marin2021token,
  title={Token pooling in vision transformers},
  author={Marin, Dmitrii and Chang, Jen-Hao Rick and Ranjan, Anurag and Prabhu, Anish and Rastegari, Mohammad and Tuzel, Oncel},
  journal={arXiv preprint arXiv:2110.03860},
  year={2021}
}

@inproceedings{ma2020weightnet, 
            title={WeightNet: Revisiting the Design Space of Weight Networks},  
            author={Ma, Ningning and Zhang, Xiangyu and Huang, Jiawei and Sun, Jian},  
            booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},  
            year={2020} 
}



@article{pascal-voc-2012,
   author = "Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.",
   title = "The Pascal Visual Object Classes (VOC) Challenge",
   journal = "International Journal of Computer Vision",
   volume = "88",
   year = "2010",
   number = "2",
   month = jun,
   pages = "303--338",
}

@article{deeplabv3,
  title={Rethinking atrous convolution for semantic image segmentation},
  author={Chen, Liang-Chieh and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  journal={arXiv preprint arXiv:1706.05587},
  year={2017}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{zagoruyko2017diracnets,
  title={Diracnets: Training very deep neural networks without skip-connections},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1706.00388},
  year={2017}
}

@inproceedings{time_matters_weightdecay,
 author = {Golatkar, Aditya Sharad and Achille, Alessandro and Soatto, Stefano},
 title = {Time Matters in Regularizing Deep Networks: Weight Decay and Data Augmentation Affect Early Learning Dynamics, Matter Little Near Convergence},
 booktitle = {Advances in Neural Information Processing Systems},
 year = {2019}
}



@article{zar2005spearman,
  title={Spearman rank correlation},
  author={Zar, Jerrold H},
  journal={Encyclopedia of biostatistics},
  volume={7},
  year={2005},
  publisher={Wiley Online Library}
}
@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}

@article{squeezenet_2016,
  author = {Iandola, Forrest N. and Moskewicz, Matthew W. and Ashraf, Khalid and Han, Song and Dally, William J. and Keutzer, Kurt},
  title = {SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size.},
  journal = {CoRR},
  year = {2016}
}

@inproceedings{zhang2018shufflenet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  year={2018}
}

@inproceedings{Han_ghostnet_2020_CVPR,
author = {Han, Kai and Wang, Yunhe and Tian, Qi and Guo, Jianyuan and Xu, Chunjing and Xu, Chang},
title = {GhostNet: More Features From Cheap Operations},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2020}
}

@inproceedings{mnasnet_cvpr,
  author = {Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Sandler, Mark and Howard, Andrew and Le, Quoc V.},
  title = {MnasNet: Platform-Aware Neural Architecture Search for Mobile},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2019}
}

@inproceedings{mixconv_bmvc_2019,
  author    = {Mingxing Tan and
               Quoc V. Le},
  title     = {MixConv: Mixed Depthwise Convolutional Kernels},
  booktitle = {30th British Machine Vision Conference 2019, {BMVC} 2019, Cardiff,
               UK, September 9-12, 2019},
  year      = {2019}
}

@inproceedings{tinynets_neurips,
  author={Kai Han and Yunhe Wang and Qiulin Zhang and Wei Zhang and Chunjing Xu and Tong Zhang},
  title={Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets},
  booktitle={NeurIPS},
  year={2020}
}

@article{vitc_arxiv,
  author    = {Tete Xiao and
               Mannat Singh and
               Eric Mintun and
               Trevor Darrell and
               Piotr Doll{\'{a}}r and
               Ross B. Girshick},
  title     = {Early Convolutions Help Transformers See Better},
  journal   = {CoRR},
  volume    = {abs/2106.14881},
  year      = {2021}
}

@inproceedings{shen2020mealv2,
  title={MEAL V2: Boosting Vanilla ResNet-50 to 80\%+ Top-1 Accuracy on ImageNet without Tricks},
  author={Shen, Zhiqiang and Savvides, Marios},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}


@inproceedings{huang2017densenet,
  title={Densely Connected Convolutional Networks},
  author={Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q },
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}

@inproceedings{SunXLW19_hrnet,
  title={Deep High-Resolution Representation Learning for Human Pose Estimation},
  author={Ke Sun and Bin Xiao and Dong Liu and Jingdong Wang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@inproceedings{tinynet_neurips,
  title={Model Rubik’s Cube: Twisting Resolution, Depth and Width for TinyNets},
  author={Han, Kai and Wang, Yunhe and Zhang, Qiulin and Zhang, Wei and Xu, Chunjing and Zhang, Tong},
  booktitle={NeurIPS},
  year={2020}
}

@misc{nvidia_inference,
  title={AWS to Offer Nvidia’s T4 GPUs for AI Inferencing},
  author={Leopold, George},
  howpublished={www.hpcwire.com/2019/03/19/aws-upgrades-its-gpu-backed-ai-inference-platform/},
  year={2019},
}

@misc{amazon_inference,
  title={Amazon EC2 Update},
  author={Barr, Jefff},
  howpublished={https://aws.amazon.com/blogs/aws/amazon-ec2-update-inf1-instances-with-aws-inferentia-chips-for-high-performance-cost-effective-inferencing/},
  year={2019},
}

@misc{coremltools,
  author = {Core ML Tools},
  title = {Use {Core ML Tools} to convert models from third-party libraries to {Core ML}},
  howpublished = {\url{https://coremltools.readme.io/docs}},
  year={2017},
}

@misc{bai2019onnx,
    author = {Bai, Junjie and Lu, Fang and Zhang, Ke and others},
    title = {{ONNX}: Open Neural Network Exchange},
    year = {2019},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/onnx/onnx}},
    commit = {94d238d96e3fb3a7ba34f03c284b9ad3516163be}
}

@misc{fvcore,
  author = {fvcore},
  title = {Light-weight core library that provides the most common and essential functionality shared in various computer vision frameworks developed in FAIR},
  howpublished = {\url{https://github.com/facebookresearch/fvcore}},
  year= {2019},
}

@misc{swift_language,
author = {Apple inc},
title={Swift Programming Language},
howpublished = {\url{https://www.swift.org}},
year={2016},
}

@misc{xcode,
author = {Apple inc},
title={XCode Integrated Development Environment},
howpublished = {\url{https://developer.apple.com/xcode/}},
year={2003}
}

@inproceedings{yu2022metaformer,
  title={Metaformer is actually what you need for vision},
  author={Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10819--10829},
  year={2022}
}

@article{li2022nextvit,
  title={Next-ViT: Next Generation Vision Transformer for Efficient Deployment in Realistic Industrial Scenarios},
  author={Li, Jiashi and Xia, Xin and Li, Wei and Li, Huixia and Wang, Xing and Xiao, Xuefeng and Wang, Rui and Zheng, Min and Pan, Xin},
  journal={arXiv preprint arXiv:2207.05501},
  year={2022}
}

@article{zhai2021aft,
  title={An attention free transformer},
  author={Zhai, Shuangfei and Talbott, Walter and Srivastava, Nitish and Huang, Chen and Goh, Hanlin and Zhang, Ruixiang and Susskind, Josh},
  journal={arXiv preprint arXiv:2105.14103},
  year={2021}
}


@inproceedings{ResNet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={770--778},
  year={2016}
}

@article{ConvNext,
  title={A ConvNet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  journal={arXiv preprint arXiv:2201.03545},
  year={2022}
}

@article{xia2022trt,
  title={TRT-ViT: TensorRT-oriented Vision Transformer},
  author={Xia, Xin and Li, Jiashi and Wu, Jie and Wang, Xing and Wang, Mingkai and Xiao, Xuefeng and Zheng, Min and Wang, Rui},
  journal={arXiv preprint arXiv:2205.09579},
  year={2022}
}

@inproceedings{metaformer,
  title={Metaformer is actually what you need for vision},
  author={Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10819--10829},
  year={2022}
}

@inproceedings{ResNeXt,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1492--1500},
  year={2017}
}

@inproceedings{zhang2022resnest,
  title={Resnest: Split-attention networks},
  author={Zhang, Hang and Wu, Chongruo and Zhang, Zhongyue and Zhu, Yi and Lin, Haibin and Zhang, Zhi and Sun, Yue and He, Tong and Mueller, Jonas and Manmatha, R and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2736--2746},
  year={2022}
}
@inproceedings{RegNet,
  title={Designing network design spaces},
  author={Radosavovic, Ilija and Kosaraju, Raj Prateek and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10428--10436},
  year={2020}
}

@article{MobileNet_v1,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{MobileNet_v2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4510--4520},
  year={2018}
}

@inproceedings{Mobilenet_v3,
  title={Searching for mobilenetv3},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1314--1324},
  year={2019}
}

@article{AlexNet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in Neural Information Processing Systems},
  volume={25},
  year={2012}
}

@inproceedings{GhostNet,
  title={Ghostnet: More features from cheap operations},
  author={Han, Kai and Wang, Yunhe and Tian, Qi and Guo, Jianyuan and Xu, Chunjing and Xu, Chang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1580--1589},
  year={2020}
}

@inproceedings{EfficientNet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International Conference on Machine Learning},
  pages={6105--6114},
  year={2019},
}

@inproceedings{ShuffleNet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6848--6856},
  year={2018}
}

@inproceedings{ShuffleNet_v2,
  title={Shufflenet v2: Practical guidelines for efficient cnn architecture design},
  author={Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
  booktitle={Proceedings of the European Conference on Computer Vision},
  pages={116--131},
  year={2018}
}

@article{ImageNet-1K,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International Journal of Computer Vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
}

@inproceedings{ADE20K,
  title={Scene parsing through ade20k dataset},
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={633--641},
  year={2017}
}

@inproceedings{COCO,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European Conference on Computer Vision},
  pages={740--755},
  year={2014},
}

@article{ViT,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{Deit,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={10347--10357},
  year={2021},
}

@article{PVT_v1,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  journal={arXiv preprint arXiv:2102.12122},
  year={2021}
}

@article{PVT_v2,
  title={Pvtv2: Improved baselines with pyramid vision transformer},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  journal={arXiv preprint arXiv:2106.13797},
  year={2021}
}


@article{Swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  journal={arXiv preprint arXiv:2103.14030},
  year={2021}
}
@article{mobilevit_v2,
  title={Separable Self-attention for Mobile Vision Transformers},
  author={Mehta, Sachin and Rastegari, Mohammad},
  journal={arXiv preprint arXiv:2206.02680},
  year={2022}
}
@article{li2022efficientformer,
  title={EfficientFormer: Vision Transformers at MobileNet Speed},
  author={Li, Yanyu and Yuan, Geng and Wen, Yang and Hu, Eric and Evangelidis, Georgios and Tulyakov, Sergey and Wang, Yanzhi and Ren, Jian},
  journal={arXiv preprint arXiv:2206.01191},
  year={2022}
}
@article{CPVT,
  title={Conditional positional encodings for vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Zhang, Bo and Wang, Xinlong and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={arXiv preprint arXiv:2102.10882},
  year={2021}
}

@article{Twins,
  title={Twins: Revisiting the design of spatial attention in vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Wang, Yuqing and Zhang, Bo and Ren, Haibing and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={arXiv preprint arXiv:2104.13840},
  year={2021}
}

@article{CSWin,
  title={Cswin transformer: A general vision transformer backbone with cross-shaped windows},
  author={Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining},
  journal={arXiv preprint arXiv:2107.00652},
  year={2021}
}

@inproceedings{CoaT,
  title={Co-scale conv-attentional image transformers},
  author={Xu, Weijian and Xu, Yifan and Chang, Tyler and Tu, Zhuowen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9981--9990},
  year={2021}
}

@article{CoAtNet,
  title={Coatnet: Marrying convolution and attention for all data sizes},
  author={Dai, Zihang and Liu, Hanxiao and Le, Quoc V and Tan, Mingxing},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3965--3977},
  year={2021}
}

@inproceedings{LeViT,
  title={LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference},
  author={Graham, Benjamin and El-Nouby, Alaaeldin and Touvron, Hugo and Stock, Pierre and Joulin, Armand and J{\'e}gou, Herv{\'e} and Douze, Matthijs},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12259--12269},
  year={2021}
}

@inproceedings{T2T,
  title={Tokens-to-token vit: Training vision transformers from scratch on imagenet},
  author={Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={558--567},
  year={2021}
}

@article{TNT,
  title={Transformer in transformer},
  author={Han, Kai and Xiao, An and Wu, Enhua and Guo, Jianyuan and Xu, Chunjing and Wang, Yunhe},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{Mobile-Former,
  title={Mobile-former: Bridging mobilenet and transformer},
  author={Chen, Yinpeng and Dai, Xiyang and Chen, Dongdong and Liu, Mengchen and Dong, Xiaoyi and Yuan, Lu and Liu, Zicheng},
  journal={arXiv preprint arXiv:2108.05895},
  year={2021}
}

@article{uniformer,
  title={Uniformer: Unifying convolution and self-attention for visual recognition},
  author={Li, Kunchang and Wang, Yali and Zhang, Junhao and Gao, Peng and Song, Guanglu and Liu, Yu and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2201.09450},
  year={2022}
}

@article{Segformer,
  title={SegFormer: Simple and efficient design for semantic segmentation with transformers},
  author={Xie, Enze and Wang, Wenhai and Yu, Zhiding and Anandkumar, Anima and Alvarez, Jose M and Luo, Ping},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{zheng2021rethinking,
  title={Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
  author={Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6881--6890},
  year={2021}
}

@inproceedings{wang2021max,
  title={Max-deeplab: End-to-end panoptic segmentation with mask transformers},
  author={Wang, Huiyu and Zhu, Yukun and Adam, Hartwig and Yuille, Alan and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5463--5474},
  year={2021}
}

@inproceedings{DETR,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European Conference on Computer Vision},
  pages={213--229},
  year={2020}
}

@article{zhu2020deformable,
  title={Deformable detr: Deformable transformers for end-to-end object detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  journal={arXiv preprint arXiv:2010.04159},
  year={2020}
}

@inproceedings{dai2021up,
  title={Up-detr: Unsupervised pre-training for object detection with transformers},
  author={Dai, Zhigang and Cai, Bolun and Lin, Yugeng and Chen, Junying},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1601--1610},
  year={2021}
}

@inproceedings{so2019evolved,
  title={The evolved transformer},
  author={So, David and Le, Quoc and Liang, Chen},
  booktitle={International Conference on Machine Learning},
  pages={5877--5886},
  year={2019}
}

@inproceedings{Autoformer,
  title={Autoformer: Searching transformers for visual recognition},
  author={Chen, Minghao and Peng, Houwen and Fu, Jianlong and Ling, Haibin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12270--12280},
  year={2021}
}

@inproceedings{Glit,
  title={Glit: Neural architecture search for global and local image transformer},
  author={Chen, Boyu and Li, Peixia and Li, Chuming and Li, Baopu and Bai, Lei and Lin, Chen and Sun, Ming and Yan, Junjie and Ouyang, Wanli},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12--21},
  year={2021}
}

@inproceedings{Bossnas,
  title={Bossnas: Exploring hybrid cnn-transformers with block-wisely self-supervised neural architecture search},
  author={Li, Changlin and Tang, Tao and Wang, Guangrun and Peng, Jiefeng and Wang, Bing and Liang, Xiaodan and Chang, Xiaojun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12281--12291},
  year={2021}
}

@article{zoph2016neural,
  title={Neural architecture search with reinforcement learning},
  author={Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1611.01578},
  year={2016}
}

@inproceedings{Bignas,
  title={Bignas: Scaling up neural architecture search with big single-stage models},
  author={Yu, Jiahui and Jin, Pengchong and Liu, Hanxiao and Bender, Gabriel and Kindermans, Pieter-Jan and Tan, Mingxing and Huang, Thomas and Song, Xiaodan and Pang, Ruoming and Le, Quoc},
  booktitle={European Conference on Computer Vision},
  pages={702--717},
  year={2020}
}

@article{AdamW,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@inproceedings{Stochasticdepth,
  title={Deep networks with stochastic depth},
  author={Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q},
  booktitle={European Conference on Computer Vision},
  pages={646--661},
  year={2016}
}

@inproceedings{Semantic_FPN,
  title={Panoptic feature pyramid networks},
  author={Kirillov, Alexander and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6399--6408},
  year={2019}
}

@inproceedings{UperNet,
  title={Unified perceptual parsing for scene understanding},
  author={Xiao, Tete and Liu, Yingcheng and Zhou, Bolei and Jiang, Yuning and Sun, Jian},
  booktitle={European Conference on Computer Vision},
  pages={418--434},
  year={2018}
}

@inproceedings{RetinaNet,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2980--2988},
  year={2017}
}

@inproceedings{Mask_RCNN,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2961--2969},
  year={2017}
}

@inproceedings{Batch_Norm,
	title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
	author={Ioffe, Sergey and Szegedy, Christian},
	booktitle={International conference on machine learning},
	pages={448--456},
	year={2015},
	organization={PMLR}
}

@inproceedings{DenseNet,
	title={Densely connected convolutional networks},
	author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4700--4708},
	year={2017}
}

@article{Mobilenets,
	title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
	author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
	journal={arXiv preprint arXiv:1704.04861},
	year={2017}
}

@article{Cmt,
	title={Cmt: Convolutional neural networks meet vision transformers},
	author={Guo, Jianyuan and Han, Kai and Wu, Han and Xu, Chang and Tang, Yehui and Xu, Chunjing and Wang, Yunhe},
	journal={arXiv preprint arXiv:2107.06263},
	year={2021}
}

@inproceedings{PiT,
	title={Rethinking spatial dimensions of vision transformers},
	author={Heo, Byeongho and Yun, Sangdoo and Han, Dongyoon and Chun, Sanghyuk and Choe, Junsuk and Oh, Seong Joon},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={11936--11945},
	year={2021}
}

@inproceedings{BoTNet,
	title={Bottleneck transformers for visual recognition},
	author={Srinivas, Aravind and Lin, Tsung-Yi and Parmar, Niki and Shlens, Jonathon and Abbeel, Pieter and Vaswani, Ashish},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={16519--16529},
	year={2021}
}

@article{park2022vision,
  title={How Do Vision Transformers Work?},
  author={Park, Namuk and Kim, Songkuk},
  journal={arXiv preprint arXiv:2202.06709},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{bullier2001integrated,
  title={Integrated model of visual processing},
  author={Bullier, Jean},
  journal={Brain research reviews},
  volume={36},
  number={2-3},
  pages={96--107},
  year={2001},
  publisher={Elsevier}
}
@article{kauffmann2014neural,
  title={The neural bases of spatial frequency processing during scene perception},
  author={Kauffmann, Louise and Ramano{\"e}l, Stephen and Peyrin, Carole},
  journal={Frontiers in integrative neuroscience},
  volume={8},
  pages={37},
  year={2014},
  publisher={Frontiers Media SA}
}

@inproceedings{FAN,
  title={Understanding the robustness in vision transformers},
  author={Zhou, Daquan and Yu, Zhiding and Xie, Enze and Xiao, Chaowei and Anandkumar, Animashree and Feng, Jiashi and Alvarez, Jose M},
  booktitle={International Conference on Machine Learning},
  pages={27378--27394},
  year={2022},
  organization={PMLR}
}

@article{sepvit,
  title={Sepvit: Separable vision transformer},
  author={Li, Wei and Wang, Xing and Xia, Xin and Wu, Jie and Xiao, Xuefeng and Zheng, Min and Wen, Shiping},
  journal={arXiv preprint arXiv:2203.15380},
  year={2022}
}

@inproceedings{qin2022activation,
  title={Activation Modulation and Recalibration Scheme for Weakly Supervised Semantic Segmentation},
  author={Qin, Jie and Wu, Jie and Xiao, Xuefeng and Li, Lujun and Wang, Xingang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={2},
  pages={2117--2125},
  year={2022}
}

 @inproceedings{wu2020tree,
  title={Tree-structured policy based progressive reinforcement learning for temporally language grounding in video},
  author={Wu, Jie and Li, Guanbin and Liu, Si and Lin, Liang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={12386--12393},
  year={2020}
}

@inproceedings{li2019oicsr,
  title={OICSR: Out-in-channel sparsity regularization for compact deep neural networks},
  author={Li, Jiashi and Qi, Qi and Wang, Jingyu and Ge, Ce and Li, Yujian and Yue, Zhangzhang and Sun, Haifeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7046--7055},
  year={2019}
}

@InProceedings{PADNAS,
    author    = {Xia, Xin and Xiao, Xuefeng and Wang, Xing and Zheng, Min},
    title     = {Progressive Automatic Design of Search Space for One-Shot Neural Architecture Search},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {January},
    year      = {2022},
    pages     = {2455-2464}
}

@inproceedings{xiao2017design,
  title={Design of a very compact cnn classifier for online handwritten chinese character recognition using dropweight and global pooling},
  author={Xuefeng  Xiao, Yafeng Yang, Tasweer Ahmad and Lianwen Jin, Tianhai Chang},
  booktitle={2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)},
  volume={1},
  pages={891--895},
  year={2017},
  organization={IEEE}
}

@article{xiao2017building,
  author = {Xuefeng Xiao, Lianwen Jin, Yafeng Yang, Weixin Yang, Jun Sun, Tianhai Chang},
  title = {Building Fast and Compact Convolutional Neural Networks for Offline Handwritten Chinese Character Recognition},
  journal={Pattern Recognition},
  volume={72},
  pages={72--81},
  year = {2017},
}

@article{Deep_compression,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={arXiv preprint arXiv:1510.00149},
  year={2015}
}

@inproceedings{Channel_pruning,
  title={Channel pruning for accelerating very deep neural networks},
  author={He, Yihui and Zhang, Xiangyu and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1389--1397},
  year={2017}
}

@inproceedings{SPOS,
  title={Single path one-shot neural architecture search with uniform sampling},
  author={Guo, Zichao and Zhang, Xiangyu and Mu, Haoyuan and Heng, Wen and Liu, Zechun and Wei, Yichen and Sun, Jian},
  booktitle={European conference on computer vision},
  pages={544--560},
  year={2020},
  organization={Springer}
}

@article{Proxylessnas,
  title={Proxylessnas: Direct neural architecture search on target task and hardware},
  author={Cai, Han and Zhu, Ligeng and Han, Song},
  journal={arXiv preprint arXiv:1812.00332},
  year={2018}
}

@article{Scalablevit,
  title={Scalablevit: Rethinking the context-oriented generalization of vision transformer},
  author={Yang, Rui and Ma, Hailong and Wu, Jie and Tang, Yansong and Xiao, Xuefeng and Zheng, Min and Li, Xiu},
  journal={arXiv preprint arXiv:2203.10790},
  year={2022}
}

@article{li2021revisiting,
  title={Revisiting discriminator in GAN compression: A generator-discriminator cooperative compression scheme},
  author={Li, Shaojie and Wu, Jie and Xiao, Xuefeng and Chao, Fei and Mao, Xudong and Ji, Rongrong},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={28560--28572},
  year={2021}
}

@inproceedings{liu2019circulant,
  title={Circulant binary convolutional networks: Enhancing the performance of 1-bit dcnns with circulant back propagation},
  author={Liu, Chunlei and Ding, Wenrui and Xia, Xin and Zhang, Baochang and Gu, Jiaxin and Liu, Jianzhuang and Ji, Rongrong and Doermann, David},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2691--2699},
  year={2019}
}

@article{mobileone,
  title = {An Improved One millisecond Mobile Backbone},
  author = {Vasu, Pavan Kumar Anasosalu and Gabriel, James and Zhu, Jeff and Tuzel, Oncel and Ranjan, Anurag},
  journal={arXiv preprint arXiv:2206.04040},
  year = {2022}
}

@article{CPE,
  author = {Chu, Xiangxiang and Tian, Zhi and Zhang, Bo and Wang, Xinlong and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  title = {Conditional Positional Encodings for Vision Transformers},
  publisher = {arXiv preprint arXiv:2102.10882},
  year = {2021}
}

@inproceedings{freihand,
  title={Freihand: A dataset for markerless capture of hand pose and shape from single rgb images},
  author={Zimmermann, Christian and Ceylan, Duygu and Yang, Jimei and Russell, Bryan and Argus, Max and Brox, Thomas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={813--822},
  year={2019}
}

@inproceedings{obman,
  title     = {Learning joint reconstruction of hands and manipulated objects},
  author    = {Hasson, Yana and Varol, G{\"u}l and Tzionas, Dimitris and Kalevatykh, Igor and Black, Michael J. and Laptev, Ivan and Schmid, Cordelia},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year      = {2019}
}

@inproceedings{boukhayma20193d,
  title={3d hand shape and pose from images in the wild},
  author={Boukhayma, Adnane and Bem, Rodrigo de and Torr, Philip HS},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={10843--10852},
  year={2019}
}

@inproceedings{expose_hand,
  title = {Monocular Expressive Body Regression through Body-Driven Attention},
  author = {Choutas, Vasileios and Pavlakos, Georgios and Bolkart, Timo and Tzionas, Dimitrios and Black, Michael J.},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year = {2020}
}

@inproceedings{youtube_hand,  
   author = {Kulon, Dominik and 
             Guler, Riza Alp and
             Kokkinos, Iasonas and
             Bronstein, Michael M. and
             Zafeiriou, Stefanos},  
   title = {Weakly-Supervised Mesh-Convolutional Hand Reconstruction in the Wild},  
   booktitle = {The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
   year = {2020}  
}

@inproceedings{i2l_meshnet,  
author = {Moon, Gyeongsik and Lee, Kyoung Mu},  
title = {I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image},  
booktitle = {European Conference on Computer Vision (ECCV)},  
year = {2020}  
}  

@inproceedings{pose2mesh,  
author = {Choi, Hongsuk and Moon, Gyeongsik and Lee, Kyoung Mu},  
title = {Pose2Mesh: Graph Convolutional Network for 3D Human Pose and Mesh Recovery from a 2D Human Pose},  
booktitle = {European Conference on Computer Vision (ECCV)},  
year = {2020}  
}  

@inproceedings{cmr_hand,
  title={Camera-Space Hand Mesh Recovery via Semantic Aggregationand Adaptive 2D-1D Registration},
  author={Chen, Xingyu and Liu, Yufeng and Ma, Chongyang and Chang, Jianlong and Wang, Huayan and Chen, Tian and Guo, Xiaoyan and Wan, Pengfei and Zheng, Wen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@inproceedings{mobrecon,
  title={MobRecon: Mobile-Friendly Hand Mesh Reconstruction from Monocular Image},
  author={Chen, Xingyu and Liu, Yufeng and Dong Yajiao and Zhang, Xiong and Ma, Chongyang and Xiong, Yanmin and Zhang, Yuan and Guo, Xiaoyan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@inproceedings{metro_hand,
author = {Lin, Kevin and Wang, Lijuan and Liu, Zicheng},
title = {End-to-End Human Pose and Mesh Reconstruction with Transformers},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2021},
}

@inproceedings{handar,
  title={Towards Accurate Alignment in Real-time 3D Hand-Mesh Reconstruction},
  author={Tang, Xiao and Wang, Tianyu and Fu, Chi-Wing},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2021}
}

@inproceedings{meshgraphormer,
author = {Lin, Kevin and Wang, Lijuan and Liu, Zicheng},
title = {Mesh Graphormer},
booktitle = {International Conference on Computer Vision (ICCV)},
year = {2021},
}

@inproceedings{i2uv_handnet,
  author = {Chen, Ping and Chen, Yujin and Yang, Dong and Wu, Fangyin and Li, Qin and Xia, Qingpei and Tan, Yong},
  title = {I2UV-HandNet: Image-to-UV Prediction Network for Accurate and High-fidelity 3D Hand Mesh Modeling},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year = {2021}
}

@inproceedings{hiu_dtml,
  author={Zhang, Xiong and Huang, Hongsheng and Tan, Jianchao and Xu, Hongmin and Yang, Cheng and Peng, Guozhu and Wang, Lei and Liu, Ji},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Hand Image Understanding via Deep Multi-Task Learning}, 
  year={2021}
 }
 
@inproceedings{mobilehand,
      title     = {MobileHand: Real-time 3D Hand Shape and Pose Estimation from Color Image},
      author    = {Guan Ming, Lim and Prayook, Jatesiktat and Wei Tech, Ang},
      booktitle = {27th International Conference on Neural Information Processing (ICONIP)},
      year      = {2020}
    }

@article{trockman2022convmixer,
  title={Patches are all you need?},
  author={Trockman, Asher and Kolter, J Zico},
  journal={arXiv preprint arXiv:2201.09792},
  year={2022}
}

@inproceedings{convstem,
  author = {He, Tong and Zhang, Zhi and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},
  title = {Bag of Tricks for Image Classification with Convolutional Neural Networks},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2019}
}

@article{manomodel,
    title = {Embodied Hands: Modeling and Capturing Hands and Bodies Together},
    author = {Romero, Javier and Tzionas, Dimitrios and Black, Michael J.},
    journal = {ACM Transactions on Graphics, (Proc. SIGGRAPH Asia)},
    year = {2017}
  }

@inproceedings{hrnets,
  author={Sun, Ke and Xiao, Bin and Liu, Dong and Wang, Jingdong},
  title={Deep High-Resolution Representation Learning for Human Pose Estimation}, 
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
 }

@misc{mmseg2020,
    title={{MMSegmentation}: OpenMMLab Semantic Segmentation Toolbox and Benchmark},
    author={MMSegmentation Contributors},
    howpublished = {\url{https://github.com/open-mmlab/mmsegmentation}},
    year={2020}
}

@inproceedings{relposembed,
  author = {Wu, Kan and Peng, Houwen and Chen, Minghao and Fu, Jianlong and Chao, Hongyang},
  title = {Rethinking and Improving Relative Position Encoding for Vision Transformer},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  year = {2021}
}

@inproceedings{maxvit,
  author = {Tu, Zhengzhong and Talebi, Hossein and Zhang, Han and Yang, Feng and Milanfar, Peyman and Bovik, Alan and Li, Yinxiao},
  title = {MaxViT: Multi-Axis Vision Transformer},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  year = {2022}
}

@article{cvt,
  title={Cvt: Introducing convolutions to vision transformers},
  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  year={2021}
}

@article{replknet,
title={Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs},
author={Ding, Xiaohan and Zhang, Xiangyu and Zhou, Yizhuang and Han, Jungong and Ding, Guiguang and Sun, Jian},
v={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2022}
    }

@inproceedings{imagenetsketch,
        title={Learning Robust Global Representations by Penalizing Local Predictive Power},
        author={Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
        booktitle={Advances in Neural Information Processing Systems},
        year={2019}
}

@article{imageneta,
  title={Natural Adversarial Examples},
  author={Dan Hendrycks and Kevin Zhao and Steven Basart and Jacob Steinhardt and Dawn Song},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@article{imagenetr,
  title={The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization},
  author={Dan Hendrycks and Steven Basart and Norman Mu and Saurav Kadavath and Frank Wang and Evan Dorundo and Rahul Desai and Tyler Zhu and Samyak Parajuli and Mike Guo and Dawn Song and Jacob Steinhardt and Justin Gilmer},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021}
}

@article{wang2022robustcnn,
  title   = {Can CNNs Be More Robust Than Transformers?}, 
  author  = {Zeyu Wang and Yutong Bai and Yuyin Zhou and Cihang Xie},
  journal = {arXiv preprint arXiv:2206.03452},
  year    = {2022},
}

@inproceedings{mao2022robust,
      title={Towards Robust Vision Transformer}, 
      author={Xiaofeng Mao and Gege Qi and Yuefeng Chen and Xiaodan Li and Ranjie Duan and Shaokai Ye and Yuan He and Hui Xue},
      booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      year={2022}
}

@article{imagenetc,
  title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author={Dan Hendrycks and Thomas Dietterich},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2019}
}

@inproceedings{ceit,
      title={Incorporating Convolution Designs into Visual Transformers}, 
      author={Kun Yuan and Shaopeng Guo and Ziwei Liu and Aojun Zhou and Fengwei Yu and Wei Wu},
      booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)},
      year={2021}
}

@article{nfnets,
  author={Andrew Brock and Soham De and Samuel L. Smith and Karen Simonyan},
  title={High-Performance Large-Scale Image Recognition Without Normalization},
  booktitle={International Conference on Machine Learning, (ICML)},
  year={2021}
}

@misc{timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@misc{rsbresnets,
  author = {Wightman, Ross and Touvron, Hugo and Jégou, Hervé},
  title = {ResNet strikes back: An improved training procedure in timm},
  publisher = {arXiv preprint arXiv:2110.00476},
  year = {2021}
}

@inproceedings{litv2,
  title={Fast Vision Transformers with HiLo Attention},
  author={Pan, Zizheng and Cai, Jianfei and Zhuang, Bohan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}

@inproceedings{litv1,
  title={Less is More: Pay Less Attention in Vision Transformers},
  author={Pan, Zizheng and Zhuang, Bohan and He, Haoyu and Liu, Jing and Cai, Jianfei},
  booktitle = {AAAI},
  year={2022}
}

@misc{layer_norm,
  author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
  title = {Layer Normalization},
  booktitle = {arXiv preprint arXiv:1607.06450},
  year = {2016},
}

@misc{linformer,
    title={Linformer: Self-Attention with Linear Complexity},
    author={Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},
    year={2020},
    eprint={2006.04768},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{reformer,
    title       = {Reformer: The Efficient Transformer},
    author      = {Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},
    booktitle   = {International Conference on Learning Representations},
    year        = {2020},
    url         = {https://openreview.net/forum?id=rkgNKkHtvB}
}

@inproceedings{6drot,
title={On the Continuity of Rotation Representations in Neural Networks},
author={Zhou, Yi and Barnes, Connelly and Jingwan, Lu and Jimei, Yang and Hao, Li},
booktitle={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month={June},
year={2019}
}

@inproceedings{edgevit,
  title={EdgeViTs: Competing Light-weight CNNs on Mobile Devices with Vision Transformers},
  author={Pan, Junting and Bulat, Adrian and Tan, Fuwen and Zhu, Xiatian and Dudziak, Lukasz and Li, Hongsheng and Tzimiropoulos, Georgios and Martinez, Brais},
  booktitle={European Conference on Computer Vision},
  year={2022}
}
