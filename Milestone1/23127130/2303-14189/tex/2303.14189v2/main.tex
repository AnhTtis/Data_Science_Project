\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage[inline]{enumitem}

\usepackage{booktabs}
\usepackage{multicol}
\usepackage{color}
\usepackage{caption}
\usepackage{hhline}
\usepackage{pifont}
\usepackage{threeparttable}
\usepackage{makecell}
\usepackage{algorithm} 
\usepackage{listings}
\usepackage{amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{lipsum}
\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}


\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{9078} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi
\pagenumbering{gobble} % To remove page numbers

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\newcommand{\tablestyle}[2]{\setlength{\tabcolsep}{#1}\renewcommand{\arraystretch}{#2}\centering\footnotesize}
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\usepackage[accsupp]{axessibility}  % Improves PDF readability for those with disabilities.

\begin{document}

%%%%%%%%% TITLE
\title{FastViT: A Fast Hybrid Vision Transformer \\using Structural Reparameterization}

\author{
Pavan Kumar Anasosalu Vasu$^\dagger$ \quad James Gabriel \quad Jeff Zhu \quad Oncel Tuzel \quad Anurag Ranjan$^\dagger$ \\ \\ Apple
}

\maketitle
% Remove page # from the first page of camera-ready.


\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}


%%%%%%%%% ABSTRACT
\begin{abstract}

The recent amalgamation of transformer and convolutional designs has led to steady improvements in accuracy and efficiency of the models. 
In this work, we introduce {FastViT}, a hybrid vision transformer architecture that obtains the state-of-the-art latency-accuracy trade-off. To this end, we introduce a novel token mixing operator, RepMixer, a building block of FastViT, that uses structural reparameterization to lower the memory access cost by removing  skip-connections in the network. We further apply train-time overparametrization and large kernel convolutions to boost accuracy and empirically show that these choices have minimal effect on latency. We show that -- our model is 3.5$\times$ faster than CMT, a recent state-of-the-art hybrid transformer architecture, 4.9$\times$ faster than EfficientNet, and 1.9$\times$ faster than ConvNeXt on a mobile device for the same accuracy on the ImageNet dataset. At similar latency, our model obtains 4.2\% better Top-1 accuracy on ImageNet than MobileOne. Our model consistently outperforms competing architectures across several tasks -- image classification, detection, segmentation and 3D mesh regression with significant improvement in latency on both a mobile device and a desktop GPU. Furthermore, our model is highly robust to out-of-distribution samples and corruptions, improving over competing robust models. Code and models are available at \url{https://github.com/apple/ml-fastvit} \blfootnote{corresponding authors: {\{panasosaluvasu, anuragr\}@apple.com}}



\end{abstract}

%%%%%%%%% BODY TEXT
\input{introduction}
\input{related_work}
\input{method}
\input{experiments}
\input{conclusion}

\paragraph{Acknowledgements}
We thank Jen-Hao Rick Chang, Skyker Seto and Hadi Pouransari for helpful discussions and reviewing the manuscript.

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\input{appendix}

\end{document}
