\documentclass{amsart}
%\let\temp\rmdefault
% \usepackage{mathpazo}
%\let\rmdefault\temp
\usepackage[marginratio=1:1]{geometry}


\usepackage[hidelinks]{hyperref}
\usepackage{calc}
\newsavebox\CBoxx
\newcommand\hcancel[2][0.5pt]{%
  \ifmmode\sbox\CBox{$#2$}\else\sbox\CBox{#2}\fi%
  \makebox[0pt][l]{\usebox\CBox}%  
  \rule[0.5\ht\CBox-#1/2]{\wd\CBox}{#1}}
\usepackage{blindtext}
\usepackage{color}
\usepackage{hyperref,url}
\usepackage{float}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{enumitem}   
\usepackage{bbm}
\usepackage{cancel}
\usepackage{mathrsfs}
\usepackage{colonequals}
\usepackage{pdfpages}
\newcommand\smallO{
  \mathchoice
    {{\scriptstyle\mathcal{O}}}% \displaystyle
    {{\scriptstyle\mathcal{O}}}% \textstyle
    {{\scriptscriptstyle\mathcal{O}}}% \scriptstyle
    {\scalebox{.7}{$\scriptscriptstyle\mathcal{O}$}}%\scriptscriptstyle
  }

\overfullrule=0pt
\sloppy

\usepackage{amsmath,amsfonts,amsthm,bm}
\usepackage{mathrsfs}  
\usepackage{xcolor}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{mathrsfs}  

\usepackage[normalem]{ulem}
%\usepackage{refcheck}
% \newcommand*{\defeq }{\mathrel{\vcenter{\baselineskip0.5ex \lineskiplimit0pt
%                      \hbox{\scriptsize.}\hbox{\scriptsize.}}}%
%                      =}
               


\numberwithin{equation}{section}
\usepackage[toc,page]{appendix}
\usepackage{tikz-cd}
\theoremstyle{definition}


\newtheorem{definicao}{Definition}[section]
\newtheorem{remark}[definicao]{Remark}
\newtheorem{notacao}[definicao]{Notation}
\newtheorem{examplo}[definicao]{Example}

\theoremstyle{plain}

\newtheorem{teorema}[definicao]{Theorem}
\newtheorem{suposicao}{Hypothesis}
\newtheorem{hypothesis}{Hypothesis}


\newtheorem{lema}[definicao]{Lemma}
\newtheorem{proposicao}[definicao]{Proposition}
\newtheorem{corolario}[definicao]{Corollary}



\newtheorem {mtheorem} {\bf Theorem} 
\renewcommand*{\themtheorem}{\Alph{mtheorem}}

\newtheorem{manualtheoreminnera}{\bf Assumption}
\newenvironment{hipotese}[1]{%
  \renewcommand\themanualtheoreminnera{#1}%
  \manualtheoreminnera
}{\endmanualtheoreminner} 

\newtheorem{manualtheoreminner}{\bf Claim}
\newenvironment{claim}[1]{%
  \renewcommand\themanualtheoreminner{#1}%
  \manualtheoreminner
}{\endmanualtheoreminner}

\newtheorem{manualtheoreminnerb}{\bf Step}
\newenvironment{step}[1]{%
  \renewcommand\themanualtheoreminnerb{#1}%
  \manualtheoreminnerb
}{\endmanualtheoreminner} 

\newtheorem{manualtheoreminnerc}{\bf Case}
\newenvironment{case}[1]{%
  \renewcommand\themanualtheoreminnerb{#1}%
  \manualtheoreminnerb
}{\endmanualtheoreminner} 

\newenvironment{claimstep}[1]{\par\noindent{\emph{Proof of the step.}}\space#1}{\leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill\quad\hbox{$\blacksquare$}}

\newenvironment{claimproof}[1]{\par\noindent{\emph{Proof of the claim.}}\space#1}{\leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill\quad\hbox{$\blacksquare$}}

\newenvironment{theoremproofA}[1]{\par\noindent{\emph{Proof of Theorem A.}} \space#1}{\leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill\quad\hbox{$\qed$}}
\newenvironment{theoremproofB}[1]{\par\noindent{\emph{Proof of Theorem B.}}  }{\leavevmode\unskip\penalty9999 \newline\hbox{}\nobreak\hfill \quad\hbox{$\qed$}}
\newenvironment{theoremproofC}[1]{\par\noindent{\textit{Proof of Theorem C.}} \space#1}{\leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill\quad\hbox{$\qed$}}
\usepackage{scalerel}

\definecolor{roxo}{rgb}{0.44, 0.16, 0.39}
\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}
\definecolor{dmagenta}{RGB}{139, 0, 139}
\definecolor{dgreen}{RGB}{0,90,0}
\definecolor{navy}{RGB}{0,0,128}


\DeclareSymbolFont{bbold}{U}{bbold}{m}{n}
\DeclareSymbolFontAlphabet{\mathbbold}{bbold}

% \makeatletter
% \def\@maketitle{%
%   \newpage
%   \null
%   \vskip 2em%
%   \begin{center}%
%   \let \footnote \thanks
%     {\Large\bfseries \@title \par}%
%     \vskip 1.5em%
%     {\normalsize
%       \lineskip .5em%
%       \begin{tabular}[t]{c}%
%         \@author
%       \end{tabular}\par}%
%     \vskip 1em%
%     {\normalsize \@date}%
%   \end{center}%
%   \par
%   \vskip 1.5em}
% \makeatother
\usepackage{stackengine}
\def\cross{%
  \stackon[1ex]{\rule{0.4pt}{1.5ex}}{\rule{.75ex}{0.4pt}}}

\def\ee{\varepsilon}
\def\R{\mathbb R}
\def\d{\mathrm d}
\def \d {\mathrm{d}}
\def \supp {\mathrm{supp}}
\def \x {\mathbf{x}}
\def \y {\mathbf{y}}
\def \arctanh {\mathrm{arctanh}}
\def \s {\mathrm{span}}
\def \w { \underline{\omega} }
\def \cP {\mathcal{P}}
\def \cL {\mathcal{L}}
\def \tri {\mathbbold{\Delta}}
\def\fa{\text{for all}}
\def \dist{\mathrm{dist}}

\DeclareMathOperator*{\esssup}{ess\,sup}
\DeclareMathOperator*{\essinf}{ess\,inf}

\definecolor{iblue}{RGB}{0, 35, 194}
% \title[??? with application to a random logistic map with escape]
\title[Random Young towers for predominantly expanding multimodal circle maps]{Random Young towers and quenched decay of correlations for predominantly expanding multimodal circle maps}
\author[M.M. Castro, G. Tenaglia.]
{Matheus M. Castro$^{*}$, Giuseppe Tenaglia$^{*}$.
}
% A novel approach to finding QEM QSM


\address{Department of Mathematics, Imperial College London, London, SW7 2AZ, United Kingdom.}
\email{ m.de-castro20@imperial.ac.uk,
giuseppe.tenaglia20@imperial.ac.uk.}


\textwidth=14.5truecm
\allowdisplaybreaks
\begin{document}

\subjclass[2020]{37H12, 37H15, 37A25 }

\keywords{ Exponential mixing, Lyapunov exponents, Quenched decay of correlations}

\maketitle
\vspace{-1.3cm}
\begin{align*}
   \small {}^* \textit{Imperial College London} 
\end{align*}

\begin{abstract}

In this paper, we study the random dynamical system $f_\omega^n$  generated by a family of maps $\{f_{\omega_0}: \mathbb S^1 \to \mathbb S^1\}_{\omega \in [-\varepsilon,\varepsilon]},$ $f_{\omega_0}(x) = \alpha \xi (x+\omega_0) +a\ (\mathrm{mod }\ 1),$ where $\xi: \mathbb S^1 \to \mathbb R$ is a non-degenerated map, $a\in [0,1)$, $\alpha,\varepsilon>0$. Fixing a constant $c\in (0,1)$, we show that for $\alpha$ sufficiently large and $\varepsilon > \alpha^{-1+c},$ the random dynamical system $f_\omega^n$ presents a random Young tower structure and quenched decay of correlations.

\end{abstract}



\section{Introduction}

The study of chaotic systems is often focused on comprehending the statistical properties that result from their intricate dynamics. Within the class of chaotic dynamical systems, mixing dynamical systems hold particular importance. Specifically, a map $f:M\to M$, acting on a compact manifold $M$ with an invariant probability measure $\mu$ on $M$ (i.e., $\mu(\cdot) = \mu(f^{-1}(\cdot))$), is referred to as mixing if, for every bounded measurable observable  $\psi, \varphi: M \to \mathbb{R},$ \begin{align}
   \left|\int_M \varphi \circ f^n \ \psi \, \d \mu - \int_M \phi \,\d \mu \int_M \psi \, \d \mu\right| \xrightarrow[]{n\to\infty} 0. \label{correlation}
\end{align}
The equation above suggests that if $f$ is mixing, the random variables $\varphi \circ f^n$ and $\psi$ tend towards asymptotic independence.

When studying mixing systems, a natural question is how fast the convergence of \eqref{correlation} occurs. Two commonly employed techniques to address this question are the spectral gap method and the construction of Young towers for the system $f$. The first technique involves identifying a suitable Banach space $F\subset L^1(M,\mu)$ such that the Perron-Frobenius operator induced by $f$ exhibits a spectral gap in its spectrum (see \cite{CarTransf, BTransf,Btranf2,CarlangeloTransf}). The second  requires finding a subset $\Delta\subset M$ and a return function $R: \Delta \to \mathbb N$ such that $f^R(x) = f^{R(x)}(x)\in \Delta$ for $\mu$-almost every $x\in \Delta$, and $f^R :\Delta \to \Delta$ is a Gibbs-Markov map (for more details, see \cite[Chapters 3 and 6]{Alves}).


The question of how fast the convergence of \eqref{correlation} occurs can be extended to a random dynamical systems context. Given a random dynamical system $f_\omega^n: M\to M$ over an $\mathbb P$-invariant ergodic dynamical system $\theta:\Omega \to \Omega$ one may consider how fast
\begin{align}
   \left|\int_M \varphi \circ f_\omega^n \ \psi \, \d \mu_\omega - \int_M \phi \,\d \mu_{\theta^n\omega} \int_M \psi \, \d \mu_{\omega}\right| \xrightarrow[]{n\to\infty} 0, \label{correlation1}
\end{align}
occurs, where $\mu(\d x, \d \mu) = \mu_\omega(\d x) \mathbb P(\d \omega)$ is an invariant measure for the skew-product $\Theta:\Omega\times M\to \Omega\times M$, $\Theta(\omega,x) = (\theta\omega,f_\omega(x)).$ In the literature \eqref{correlation1} is generally called \emph{quenched decay of correlation}.


The two aforementioned techniques  have their random dynamical system counterparts. The first approach is a functional analytical method that depends either on the analysis of non-autonomous Perron-Frobenius operators (see \cite{Atnip, Buzzi,Froyland, VarTher}) or on the description of the stationary measures of the two-point process $f^{(2)}_\omega(x,y) =(f_\omega(x), f_\omega(y))$ 
 on $M\times M$ (see \cite{LToral, BS,Dolg, BMixing}). The second technique derives from the theory of random Young towers, which has been actively studied in recent years (see \cite{Alves1,Alves2,Baladi, Du, Su} and the references therein). However, constructing random Young towers has proven challenging in several contexts. 

In the literature, the emphasis on constructing random Young towers is primarily based on small perturbations of deterministic chaotic maps. While this has resulted in a variety of interesting and important results, it is worth noting that there has been comparatively little work done on constructing Young towers under moderate or large noise perturbations. This represents an important gap in the field's current state, as such constructions could have significant implications for understanding the statistical properties of random dynamical systems.
 

In this paper, we construct random Young towers and show their quenched decay of correlations for predominantly expanding multimodal circle maps  under moderate to large noise perturbations. Our techniques rely on a non-trivial adaptation of the construction presented in \cite[Chapters 5 and 6]{Alves}. To this end, we define the concept of Young times, which in broad terms, are hyperbolic times that return to a reference set. The construction exhibited in this paper exhibits several fundamental characteristics of non-uniformly expanding maps and may prove to be a powerful tool for future constructions.

This paper is divided into $5$ chapters and two appendixes. Chapter 2 presents the definitions of predominantly expanding multimodal circle maps and states the main results  (Theorems \ref{decay} and \ref{TheoremB}). Chapter 3 focuses on defining Young times and proving their positive density.  In Chapter $4$, we provide the random of the Young time, we prove that the return function $R$ is measurable and show Theorem \ref{TheoremB}. In Chapter $5$, we prove Theorem \ref{decay}. Finally, in the final two appendixes, we show Propositions \ref{LHiperbolicTijmens} and \ref{Thetainvmes}.

 
\section{Main results \label{main}}

\subsection{The model} \label{Model}


To ensure consistency with the predominant literature on expanding multimodal circle maps, we adopt the definitions and model presented in \cite{Blumenthal} throughout this paper. Specifically, we denote the unitary circle as $\mathbb S^1 = \mathbb R/\mathbb Z$, parametrized by the interval $[0,1)$. Also, we always assume that $\xi: \mathbb S^1\to \mathbb \mathbb \mathbb S^1$ is a \emph{non-degenerated $\mathcal C^2$ function}, i.e.
\begin{enumerate}
    \item[$(a)$] the critical set $\mathscr{C}:=\{x\in \mathbb S^1; \xi'(x) = 0\}$  has finite cardinality, and
    \item[$(b)$] $\{\xi''=0\}\cap \mathscr{C} = \emptyset.$
\end{enumerate}

Given $\alpha >0$ and $a\in [0,1)$ we define the family of maps
\begin{align}
    f = f_{\alpha,a} &:= \alpha \xi + a \ (\mathrm{mod }\ 1), \label{functionf}
\end{align}
where $(\mathrm{mod}\ 1)$ denotes the natural projection from $\R$ onto $\mathbb S^1.$ 

In the following, we induce a random dynamical system using the above map. Let $\varepsilon>0$ and define $\Omega = \Omega^{\varepsilon} := [-\varepsilon,\varepsilon]^{\mathbb Z}$, where $\omega\in \Omega$ is written as $\omega= (\ldots, \omega_{-1},\omega_0,\omega_1, \ldots )$.  We set $\nu^\varepsilon$ as the uniform distribution $[-\varepsilon,\varepsilon],$ and  define $\mathbb P = \mathbb P^\varepsilon :=(\nu^\varepsilon)^{\otimes \mathbb Z}$ on $\Omega$. Define $\mathcal F = \mathcal B([-\varepsilon,\varepsilon])^{\otimes Z},$ where $ \mathcal B([-\varepsilon,\varepsilon])$ is the Borel $\sigma$-algebra of the interval $[-\varepsilon,\varepsilon].$

Given $\omega_0 \in [-\varepsilon,\varepsilon],$ we define $f_{\omega_0}(x) := f(x+\omega_0),$ where $x+\omega_0$ should be understood as $x + \omega_0\ (\mathrm{mod}\ 1).$ Now, we define the random dynamical system we aim to study. Setting $\alpha>0,$ $a\in \mathbb [0,1)$ and $\varepsilon >0$, for every $n\in \mathbb N$ we define
\begin{align*}
   f_{\omega}^n := f_{\omega_{ n-1}} \circ \ldots \circ f_{\omega_0}:\mathbb S^1 \to \mathbb S^1.
\end{align*}
Considering the map $\theta: \Omega \to \Omega,$ $\theta  ((\omega_i)_{i\in\mathbb Z} ) = (\omega_{i+1})_{i\in\mathbb Z},$ we obtain that for every $n,m \in\mathbb N$ 
$$f^{m+n}_{\omega}(x) = f^{n}_{\theta^m \omega} \circ f^m_{\omega}.$$
For every $\omega \in \Omega,$ we define  $\mathscr{C}_{\omega} := \left\{x\in\mathbb S^1;\ \d f_\omega(x) = 0\right\}$ as the critical points of $f_\omega.$

Finally, we define the skew-product of $\theta$ and $f_{\omega}$ as the map
\begin{align}
    \Theta: \Omega\times \mathbb S^1 &\to \Omega \times \mathbb S^1\label{skewproduct}\\
    (\omega, x)&\mapsto (\theta \omega, f_{\omega} (x) ).\nonumber
\end{align}
Observe that for every $n\in\mathbb N,$ $\Theta^{n}(\omega, x)= (\theta^n \omega, f^n_{\omega}(x)). $


\subsection{Decay of correlations}

In this subsection, we state the main result of this paper. Before the theorem, we set some notations used throughout the paper.

\begin{notacao}
We denote by $m$  the Lebesgue measure on $\mathbb S^1$. When we are integrating a function $\varphi:\mathbb S^1 \to \mathbb R$ over the measure $m,$ we simply denote
$$\int_{\mathbb{S}^1} \varphi(x) \d x := \int_{\mathbb{S}^1} \varphi(x) m(\d x). $$

Given a function in $\varphi \in L^\infty(\mathbb{S}^1,m)$ we define 
$$\| \varphi \|_\infty = \inf\left\{ \sup_{M \subset \mathbb S^1} |f(x)|; \ m(M) = 1\right\}.$$
On the other hand, given a Lipschitz function $\psi :\mathbb S^1\to \mathbb R$ we denote 
$$\|\psi\|_{\mathrm{Lip}} = \|\psi\|_{\infty} + \sup_{x\neq y}\frac{|\psi(x)- \psi(y)|}{d(x,y)},$$
where $d$ is the distance of $2$ points in the circle.

Given a topological space $X$, we denote $\mathcal B(X)$ as the Borel $\sigma$-algebra of $X$. Consider another topological space $Y$, and a family of probability $\{\mu_y(\d x) \}_{y \in Y}$ on $X,$ and a probability $\mathbb P(\d y)$ on $Y$. If the map $y \to \mu_y(A)$ is measurable for every $A\in \mathcal B(X)$, then   ${\mu(\d x , \d y) := \mu_y(\d x) \mathbb P(\d y)}$ is  the unique probability measure on $X\times Y$ such that
$$\mu(A\times B) = \int_B \mu_y (A) \mathbb P(\d y)\ \text{for every}\ A\times B \in \mathcal B(X)\otimes \mathcal B(Y). $$


\end{notacao}

We now present the main theorem of the paper.
\begin{mtheorem}\label{decay} Let $a \in [0,1)$ and $\alpha,\varepsilon>0$. Consider the random dynamical system generated by ${f_{\omega}(x) = \alpha \xi (x+ \omega_0) + a \ (\mathrm{mod}\ 1)}$ on $\mathbb S^1,$ where $\omega_0 \in [-\varepsilon,\varepsilon],$ as defined in Section \ref{Model}. 

Let $c\in (0,1)$. Then for $\alpha$ sufficiently large and $\varepsilon > \alpha^{c -1}$,  there exists an invariant measure $\mu (\d \omega, \d x) = \mu_{\omega}(\d x) \mathbb P(\d \omega)$ for the skew product $\Theta,$ where $\mu_{\omega}$ is absolute continuous with respect to the Lebesgue measure on $\mathbb S^1$ for $\mathbb P$-almost every $\omega\in \Omega.$ Moreover, there exists $C(\omega)\in L^2(\Omega)$ and $\gamma>0$ such that for every bounded measurable function $\varphi:\mathbb S^1\to \mathbb R$ and Lipschitz function $\psi:\mathbb S^1\to \mathbb R,$ 
$$ \left|\int_{\mathbb S^1} \varphi \circ f_{\omega}^n(x) \,  \psi(x) \d x - \int_{\mathbb S^1} \varphi(x)  \mu_{\theta^n \omega}(\d x) \int_{\mathbb S^1} \psi(x) \d x\right| \leq C(\omega) e^{-\gamma n}\|\varphi\|_{\infty} \|\psi\|_{\mathrm{Lip}},$$
and
$$ \left|\int_{\mathbb S^1} \varphi \circ f_{\theta^{-n}\omega}^n(x) \, \psi(x) \d x - \int_{\mathbb S^1} \varphi(x)  \mu_{\omega}(\d x) \int_{\mathbb S^1} \psi (x)\d x\right| \leq C(\omega) e^{-\gamma n} \|\varphi\|_{\infty} \|\psi\|_{\mathrm{Lip}}.$$


\end{mtheorem}
Theorem \ref{decay} is proven in Section \ref{proofA}.


We mention that the above theorem is sharp if the sense that if noise strength $0<\varepsilon \leq  1/\alpha$, then the above result is not necessarily true anymore since the system $f_\omega^n$ may present sinks with a basin of attraction of positive Lebesgue measure. Furthermore, it is noteworthy that the aforementioned result is not dependent on any particular characteristics of $\xi$ aside from its non-degeneracy, thus showing a significant difference between the conventional dynamical systems theory and its stochastic counterpart.


\subsection{Random Young towers}\label{randomtowers}
The groundwork technique for the proof of Theorem \ref{decay} is the theory of random Young towers. In this subsection, we define the concept of random Young towers used in this paper. We follow the definitions provided in \cite{H, Baladi, Du} for this exposition.

For the simplicity of the exposition, consider $(\Omega,\mathcal F,\mathbb P)$ and $\theta: \Omega \to \Omega$ as in Section \ref{Model}. Let $M$ be a compact metric space endowed with a probability measure $\rho$, and $\{g_\omega: M \to M\}_{\omega \in \Omega}$ a family of maps depending only on the $0^{\mathrm{th} }$ coordinate of $\omega.$ We say that $g_\omega$ \emph{admits a random  tower on $\Delta \subset M$} if there exists a measurable return function $R:\Omega\times \Delta\to \mathbb N$, and for $\mathbb P$-almost every $\omega \in \Omega$ there exists an $\rho$-mod $0$ countable partition partition $\mathcal P(\omega) =\{P_j(\omega)\}_{j\in \mathbb N}$ of $\Delta,$ such that $R_\omega= R(\omega,\cdot)$ is constant on each $P_j(\omega)$ and
$$g^{R}_\omega(x) = g_{\theta^{R_\omega(x) -1}\omega} \circ \ldots \circ g_{\theta \omega} \circ  g_\omega (x) \in \Delta\ \text{for }\mathbb P\otimes \rho \text{-almost every }(\omega,x)\in \Omega\times \Delta. $$

We define the $i$-\emph{th return time} as the following recursive equation:
$$
    R^i_\omega (x) = R^i (\omega,x) := \begin{cases}
    R(\omega,x)&, \ \text{if}\ i=1,\\
    R^{i-1}(\omega,x) + R\left(\theta^{R^{i-1}(\omega,x)} (\omega), g^{R^{i-1} (\omega,x)}_{\omega}(x)\right)&,\ \text{if }i>1.
    \end{cases}
$$


Assuming that $g_\omega$ admits a random tower map on $\Delta$, we can define the random tower of $\mathbb P$-almost every $\omega \in \Omega$ as
\begin{align}
    \Delta_\omega = \left\{(x,\ell) \in \Delta\times \mathbb Z_{\geq 0}; \ x\in \bigcup_{j\in \mathbb N} P_j(\theta^{-\ell} \omega), \ \ell \in \mathbb Z_{\geq 0}, 0 \leq \ell \leq R_{\theta^{-\ell} \omega} -1\right\},\label{Dw}
\end{align}
and the random tower map
\begin{align*}
    F_\omega : \Delta_\omega &\to \Delta_{\theta \omega}\\
    (x,\ell) &\mapsto
    \begin{cases}
    (x,\ell +1), \ \text{if}\ \ell +1 < R_{\theta^{-\ell} \omega} (x)\\
    (g^R_{\theta^{-\ell} \omega}(x),0), \ \text{if}\ \ell +1 = R_{\theta^{-\ell} \omega}(x).
    \end{cases}
\end{align*}

We define $\Delta_{\omega,\ell} := \{(x,\ell) \in \Delta_\omega\} := \{(x,\ell); R_{\theta^{-\ell} \omega}(x) > \ell\}$ as the \emph{$\ell$-th level of the tower.} Considering $$\mathbbold{\Delta} = \{(\omega , (x,\ell)); \omega\in \Omega \ \text{and}\ (x,\ell)\in \Delta_\omega\},$$
we denote $F: \tri \to \tri$ by $F(\omega,(x,\ell)) = (\theta \omega, F_\omega (x,\ell)).$ Using the set $\mathcal P(\omega),$ we induce a partition on $\Delta_\omega$, by defining
$$\widehat{\mathcal P}(\omega) :=\left\{   P\times \{\ell\};  P \in \mathcal P(\theta^{-\ell} \omega),\ \left. R\right|_{P} \geq \ell +1 , \ell \in \mathbb Z_{\geq 0}\right\}.$$

Moreover, for a given $(x,\ell) \in \Delta_\omega,$ we denote $\widehat{R}^i_\omega$ as the $i$-th return time to the base level of $\tri$ i.e.
$$\widehat{R}^i_\omega (x,\ell) = R^i_{\theta^{-\ell} \omega}(x) - \ell.$$
Furthermore, the reference measure $\rho$ on $\Delta$ can naturally be lifted on the set $\Delta_\omega$. We call the lifted measure $\rho_{\omega}$. 



Now, we define the \emph{separation time} $s: \tri \times \tri \to \mathbb Z_{\geq 0} \cup \{\infty\}$ as 
$$s( (\omega_1,z_1) , (\omega_2,z_2)) := \begin{cases}
    0, \ \text{ if }\omega_1\neq \omega_2,\\
    \min\left\{n \geq 0; F_\omega^{\widehat R^n} (z_1)\ \text{and } F_\omega^{\widehat R^n} (z_2)\ \text{lie in a distinct element of }\widehat{\mathcal P}(\theta^{ \widehat R^n_\omega(x)}\omega) \right\},
\end{cases}$$
when $\omega_1 = \omega_2 = \omega,$ we simply denote $s_\omega (z_1,z_2) := s((\omega,z_1), (\omega,z_2)).$


We say that $g_\omega$ \emph{admits a random Young tower on} $\Delta$  if $g_\omega$ admits a tower map on $\Delta,$ such the following properties hold:
\begin{enumerate}
    \item[(P1)] {\bf{Markov}}: For each $P\in \widehat{\mathcal P}(\omega)$ the map $F_\omega^{\widehat{ R}} : P \to \Delta_{\omega, 0}$ is $\rho_\omega$-mod $0$ bijection;
     \item[(P2)]{\bf{Bounded distortion}:} There exist $C_0>0$ and $0<\beta<1,$ such that for $\mathbb P$-almost every $\omega \in\Omega$ and $x,y \in P \in \widehat{\mathcal P} (\omega)$
     $$\log \frac{|\d F_\omega^{R} (x) |}{|\d F_\omega^{R} (y) |} \leq C_0 \beta^{ s(F^R(\omega,x), F^R(\omega,y)) }. $$
     \item[(P3)]{\bf{Weak expansion}:} $\widehat{\mathcal P}(\omega)$ is a generating partition for $F_\omega$, i.e. the diameter of $\bigvee_{j=0}^{n} F_\omega^{-j}\mathcal P^{j}(\theta^j\omega)$ goes to $0$ as $n\to\infty.$
     \item[(P4)]{\bf{Aperiodicity}:} There are $N\in \mathbb N$ and $\{t_i \in \mathbb Z_{\geq 0}; i =1,2,\ldots, N\},$ such that g.c.d.$\{t_i\}=1$ and $\varepsilon_i>0$ so that for $\mathbb P$-almost every $\omega\in \Omega$ and $i=1,2,\ldots, N$ we have that $\rho\{x\in \Delta; R_\omega(x) = t_i\} >\varepsilon_i$.
     \item[(P5)] {\bf{Non-degeneracy of the return time function}:} $R$ is a stopping time, i.e. if $R_{\omega}(x) = n,$ and $\upsilon \in \Omega$ and such that $\omega _i = \upsilon_i,$ for every $0\leq i < n,$ then $R_{\upsilon}(x) =n$, and
     $$ \int_{\Omega \times \Delta} R(\omega,x) \mathbb P \otimes \rho (\d \omega, \d x)<\infty.$$
\end{enumerate}

In the following, we present a central result for this paper.

\begin{mtheorem}\label{TheoremB}
 Consider $f_{\omega}^n$ as the random dynamical system defined in Section \ref{Model}. Let $c\in (0,1)$ and $a\in\mathbb S^1$. Then, for every $\alpha$ sufficiently large and $\varepsilon>\alpha^{c-1}$, there exists an interval $\Delta\subset \mathbb S^1$, such that $f_\omega$ admits a random Young tower structure on $\Delta.$ Moreover, there exists a function $C \in L^2(\Omega, \mathbb P)$ and $\gamma > 0,$ such the return function $R$, satisfies $ m [R_\omega > n] \leq  C(\omega) e^{-\gamma n},$ where $m$ is the Lebesgue measure on $\mathbb S^1.$
\end{mtheorem}
Theorem \ref{TheoremB} is proven in Section \ref{proofB}.  

\section{Young times}

In \cite[Chapter 6]{Alves} using hyperbolic times, the author introduces a technique for constructing a Young tower applicable to non-uniformly expanding maps. However, this method does not readily extend to random systems. To address this issue, we propose a solution by defining the concept of Young times. In broad terms, Young times can be described as hyperbolic times that exhibit a bounded return to a reference set. 

This section formally introduces the notion of Young times (see Definition \ref{YoungTijmen}). To this end, we first establish two essential lemmas that are crucial to the definition of Young times and the construction of the random Young tower. Recall that we denote by $m$  the Lebesgue measure on $\mathbb S^1$.

\subsection{Technical lemmas}

We proceed to prove two technical lemmas.

\begin{lema}
Let $\alpha, a  \in [0,1)$ and consider $f$ as in \eqref{functionf}. 
 Then, given $K_0>0$ and $\gamma \in [0,1)$, there exists $\alpha_1>0,$ such that for every $\alpha >\alpha_1,$
 $$m\left\{x \in \mathbb S^1; \ |\d f(x)| < K_0\alpha^{\gamma}\right\} < \frac{2 K_0 \# \mathscr{C}}{\min_{c\in\mathscr{C}}|\xi''(c)|} \frac{1}{\alpha^{1-\gamma}}. $$\label{LGiu}
\end{lema}

\begin{proof}

  Recall that $f = \alpha \xi + a\ (\mathrm{mod}\ 1)$. Let $\tilde \xi: \mathbb R\to \mathbb R$ be a lift of $\xi.$ Define ${\widetilde{\mathscr C}'_\xi = \{x\in [0,1); x \ (\mathrm{mod}\ 1) \in \mathscr{C}\}.}$ Observe that for every $x\in \mathbb R$ and $y\in \widetilde{\mathscr C}'_\xi$, 
 \begin{align}
   \tilde \xi(x) = \tilde \xi(y) + \frac{\tilde \xi''(y)}{2}(x-y)^2 + \smallO(|x-y|^2). \label{LGiu2}   
 \end{align}
Therefore,  $|\tilde \xi'(x)| > |\tilde \xi''(y)| |x-y| -  |\smallO(|x-y|)|.$ Considering $c_0 = \min\left\{\left|\tilde \xi''(x)\right|; x\in \widetilde{\mathscr C}'_\xi\right \} >0,$ we obtain that there exists $\delta>0$ such that for every $x\in \mathbb S^1$, such that $\dist(x, \mathscr{C}) < \delta,$  implies $ |\xi'(x)| \geq c_0 \mathrm{dist}(x,\mathscr{C})/2.$

Let $c_1 = \min\{|\tilde \xi'(x)| ; \ \dist(x,\mathscr{C})\geq \delta\} >0.$ Therefore, for every $\alpha > \alpha_1:= (K_0/c_1)^{1/(1-\gamma)},$ we obtain that
 $$m\left\{x\in \mathbb S^1; \ |\d f(x)| <K_0\alpha^{\gamma}\right\} \leq \frac{2 K_0  \# \mathscr{C}}{ \min_{c\in\mathscr{C}}{|\xi''(c)|} } \frac{1}{\alpha^{1-\gamma}}.$$
 

    
\end{proof}



\begin{lema}\label{CentralLema}
Fix $c\in (0,1)$. Let $\alpha, \varepsilon >0$ and $a\in [0,1)$. Consider $f_\omega^n$ as the random dynamical system defined in Section \ref{Model}. Then, for $\alpha$ sufficiently large and $\varepsilon>\alpha^{c-1},$ there exists  $\widetilde \varepsilon >0$ and $\delta_0 >0$, such that for every $\delta_1<\widetilde{\varepsilon}$, and for every interval $I\subset \mathbb S^1$, $ \delta_1 \leq |I|,$ there exists $L = L(\delta_1),$ 
$\varepsilon_0 = \varepsilon_0(\delta_1)$ and $\iota = \iota(\delta_1) >0$, such that such that
    $$\mathbb{P}\left\{ \begin{array}{l}
    \mbox{$\exists$ $\ell \in \mathbb N,$ $0<\ell\leq L$ and an interval $J \subset I$ s.t., $f^\ell _\omega(J) =B_{2 \delta_0}(x_0)$} \\
    \mbox{and $\mathrm{dist}(f^i_\omega (J), \mathscr{C}_{\theta^i\omega} )> \varepsilon_0$ for every $0<i<\ell$.}
  \end{array}\right\} > \iota. $$\label{expansion}
\end{lema}

\begin{proof}


Chose $x_0$ as any point in $\mathbb S^1$ such that $\d f(x_0) \neq 0.$  Take $\alpha_2 > 0,$ such that for every $\alpha > \alpha_2,$
\begin{align}
  \delta_0 :=\left((\# \mathscr{C} +1) + \frac{\# \mathscr{C}}{ \min_{c\in\mathscr{C}}{|\xi''(c)|} } \right)\frac{1}{\alpha^{1/2}} <\frac{1}{4}.\label{defd0}  
\end{align}
We divide the remaining proof into three steps.

%\begin{step}{1} We show that there exists $\alpha_2 > \alpha_1,$ such that for every every $\alpha>\alpha_2,$ and every $\omega_0 \in [-\varepsilon,\varepsilon],$ there exists an interval $J_{\omega_0}\subset \mathbb S^1,$ such that:
%\begin{enumerate}
    %\item[(a)] $J_{\omega_0} \subset B_{\delta_0}(x_0 +\omega);$
    %\item[(b)] $f(J_{\omega_0}) = \mathbb S^1; $ and
    %\item[(c)] $\left. f'\right|_{J_{\omega_0}} > \alpha^{1/2}.$
%\end{enumerate}
%\end{step}

%From Lemma \ref{LGiu}, taking $\gamma = 1/2$, there exists $\alpha_2>\alpha_1$, such that for every $\alpha > \alpha_2$
%$$ m\left( |f'| < \alpha^{1/2}\right) \leq \frac{\# \mathscr{C}}{ \min_{c\in\mathscr{C}}{|\xi''(c)|} }\frac{1}{\alpha^{1/2}}.$$
%this implies that the set 
 %$B_{\delta_0}\left( x_0+\omega_0\right) \cap \left\{|f'|>\alpha^{1/2} \right\}$ has Lebesgue measure upper bounded by ${(\# \mathscr C_\xi ' +1)/\alpha^{1/2}}$ and at most $\# \mathscr C_\xi ' +1$ connected components. Therefore, there exists an interval $J_{\omega_0} \subset B_{\delta_0}\left( x_0+\omega_0\right) \cap \left\{|f'|>\alpha^{1/2} \right\}$ of length $\alpha^{-1/2}.$ Using the definition of $J_{\omega}$ and the mean value theorem, we prove Step 1.
                  

 


\begin{step}{1}
We show that there exists $\alpha_3 > \alpha_2$ such that for every $\alpha > \alpha_3,$ given an interval $I_0\subset \mathbb S^1$, such that $$m(I_0) = \frac{ 2k}{\alpha^{1-c}}, \ \text{for some }k\in\mathbb N.$$
 Then, 
\begin{itemize}
    \item[$(a)$] if $m(I_0) < 1/2,$ then there exists $J\subset I_0 \text{ and } m(f(J)) = 2 m(I_0),$
and
$$ \left.f'\right|_{J} > \alpha^{c/2}.$$
    \item[$(b)$] if $1/2\leq m(I_0) \leq 1,$ then there exists $J\subset I_0,$ such that $f(J)$ covers $\mathbb S^1$ twice, i.e. for every $x\in\mathbb S^1,$ there exists $x_1,x_2 \in J$ with $x_1 \neq x_2$ such that $f(x_1) = f(x_2) = x.$ Moreover,
    $$ \left.f'\right|_{J} > \alpha^{c/2}.$$
\end{itemize}
\end{step}

Applying Lemma \ref{LGiu} with $\gamma = 1-c/2,$ we can find $\alpha_3 > \alpha_2$ such that for every $\alpha > \alpha_3,$
$$ m\left( |f'| < \alpha^{c/2}\right) \leq \frac{2 \# \mathscr{C}}{ \min_{c\in\mathscr{C}}{|\xi''(c)|} } 
  \frac{1}{\alpha^{1-c/2}},$$
  and
$$\frac{1}{\#\mathscr{C}+1} \left( \alpha^{c/2} - \frac{ \# \mathscr{C}}{ k \min_{c\in\mathscr{C}}{|\xi''(c)|} } \right)> 4.$$

Let us prove $(a)$. Observe that there exists a connected subset $J_0\subset I_0\cap \{|f'|> \alpha^{c/2}\}$ such that
$$m(J_0) = \frac{1}{\#\mathscr{C} +1} \left(\frac{2 k }{\alpha^{1-c}} - \frac{2 \# \mathscr{C}}{ \min_{c\in\mathscr{C}}{|\xi''(c)|}} \frac{1}{\alpha^{1-c/2}} \right). $$

Then, from the mean value theorem
\begin{align}
    m(f (J_0) ) &= \frac{\alpha^{c /2}}{\#\mathscr{C} +1}\left(\frac{2 k }{\alpha^{1-c}} - \frac{2 \# \mathscr{C}}{ \min_{c\in\mathscr{C}}{|\xi''(c)|} } 
  \frac{1}{\alpha^{1-c/2}} \right)\nonumber \\
  &=\frac{2k}{\alpha^{1-c}} \frac{1}{\#\mathscr{C}+1} \left( \alpha^{c/2} - \frac{ \# \mathscr{C}}{ k \min_{c\in\mathscr{C}}{|\xi''(c)|} } \right)\nonumber  \\
  &\geq 4 m(I),  \label{xt}
\end{align}
therefore one can find an interval $J \subset J_0 \subset  I_0\cap \{|f'|>\alpha^{c/2}\},$ that satisfies the desired properties. This proves $(a)$.

Now we prove $(b).$ Consider $\tilde f: \mathbb R \to \mathbb R,$ as a lift of the function $f :\mathbb S^1\to \mathbb S^1$. Moreover, let $\widetilde I_0$ be a lift of $I_0.$ From the same computations provided in \eqref{xt}, we obtain that there exists $\widetilde{J}_0\subset \widetilde I_0,$  $$\widetilde{J}_0\subset \widetilde I_0 \cap \{f'\geq \alpha^{c/2}\},$$
such that
$$m (\widetilde{J}_0) \geq 4 m(I_0) > 2. $$
We conclude the proof of the clam by defining $J$ as the projection of $\widetilde{J}_0$ on $\mathbb S^1$. This concludes Step 1.


\begin{step}{2} Let $\alpha > \alpha_3,$ $I_0 = [i_0-\alpha^{-1+c}, i_0+ \alpha^{-1+c}]$ for some $i_0\in \mathbb S^1,$ and $n_0 = \min\{n; \ 2^n m(I_0) \geq 1\}.$ Then for every $n > n_0,$ there exists $J'(\omega_1,\ldots, \omega_n)\subset I_0,$ such that
\begin{enumerate}
    \item  $f_{\omega_{n}} \circ \ldots \circ f_{\omega_1}\circ f(J'(\omega_1,\ldots,\omega_{n})) = \mathbb S^1;$
    \item $\d( f_{\omega_{n}} \circ \ldots \circ f_{\omega_1}\circ f)(x) > \alpha^{c/2},$ for every $x\in J'(\omega_1,\ldots, \omega_n);$
    \item $\displaystyle\left( \frac{m(I_0) }{\alpha \|f'\|_{\infty}}\right)^{n+1} \leq m(J'(\omega_1,\ldots,\omega_n )) \leq \left(\frac{m(I_0) }{\alpha^{c/2}}\right)^{n+1};$ and
    \item $\displaystyle f_{\omega_n} \circ \ldots f_{\omega_1} \circ f (J'(\omega_1,\ldots ,\omega)) $ covers $\mathbb S^1$ twice.
\end{enumerate}

Moreover, the intervals $J'(\omega_1,\ldots,\omega_n)$ can be chosen in a way that 
$$J'(\omega_1,\dots,\omega_n) \subset J'(\omega_1,\dots,\omega_k)\ \text{for every }1\leq k \leq n.  $$

\end{step}



We prove the result by induction on $n$ stating at $n_0$. If  $n = n_0$, since $f_{\omega_i} = f(x-\omega_i),$ the result is easily verified using Step 1. 


Now, assume that the result is valid for $n \geq n_{0}$, and we prove for $n+1$. Fix a path $(\omega_1,\ldots, \omega_{n},\omega_{n+1})$. From the induction hypothesis, we obtain that for every interval $I,$ such that $m(I_0) = 2/\alpha^{1-c}$, given $\omega_1,\ldots, \omega_{n},$ we obtain that there exists $J'(\omega_1,\ldots,\omega_n) \subset I_0$ such that
$$f_{\omega_{n}} \circ \ldots \circ f_{\omega_1} \circ f (J'(\omega_1,\ldots,\omega_n))\ \text{covers }\mathbb{S}^1\ \text{twice} $$
and
$$\d \left(f_{\omega_{n}} \circ \ldots \circ f_{\omega_1} \circ f\right)(x) > \alpha^{\frac{n c }{2}} \ \text{for every }x\in J'(\omega_1,\ldots,\omega_n).$$

Therefore,
$$ \left(\frac{m(I_0)}{\alpha\|f'\|_{\infty}}\right)^{n +1}<m \left( J'(\omega_1,\ldots,\omega_{n})\right) < \left(\frac{m(I_0)}{\alpha^{ c/2}  }\right)^{n + 1}. $$

Using Step 1 $(b)$, we obtain that there exists $$J'(\omega_1,\ldots, \omega_{n+1}) \subset J'(\omega_1,\ldots, \omega_n),$$
with the desired properties, which proves Step 2.


\begin{step}{3}
We conclude the proof of the lemma.
\end{step}

Define $D_0 := B_{2\delta_0}(x_0)$. Given $n\geq n_0,$ we obtain from the above claim that  $$f_{\omega_n} \circ f_{\omega_{n-1}}\circ \ldots \circ f_{\omega_1} \circ f (J'(\omega_1,\dots,\omega_n)) $$
covers $\mathbb S^1$ twice. Thus, we can find an interval $J(\omega_1,\ldots, \omega_n) \subset J'(\omega_1,\ldots,\omega_n)$ such that
\begin{itemize}
    \item $\displaystyle f_{\omega_{n}} \circ \ldots \circ f_{\omega_1} \circ f(J(\omega_1,\ldots, \omega_n)) = D_0;$
    
    \item $ f_{\omega_\ell}\circ \ldots f_{\omega_1}\circ f(J(\omega_1,\ldots, \omega_n)) \subset \left\{x \in \mathbb{S}^1; \ \d \left(f^l_{\omega}\right)(x-\omega_0) > \alpha^{\ell c/2}\right\},$ for every $1\leq  \ell \leq n;$ and

    \item $ \displaystyle \left(\frac{4 \delta_0}{\alpha\|\xi'\|_{\infty}}\right)^{n +1}<m \left( J(\omega_1,\ldots,\omega_{n})\right) < \left(\frac{4 \delta_0}{\alpha^{ c/2}  }\right)^{n + 1}. $
\end{itemize}

The above observation implies that there exists $\varepsilon_0 = \varepsilon_0(\delta_0),$ such that
$$\dist(f_{\omega_{\ell}}\circ \ldots \circ f_{\omega_1} \circ f(J'(\omega_1,\ldots,\omega_n)), \mathscr C_{\theta^{\ell}\omega} ) > \varepsilon_0.$$


Let us fix  $L=L(\delta_1)$ big enough such that
$$\left(\frac{4 \delta_0}{\alpha^{ c/2}  }\right)^{L+1} \leq \frac{\delta_1}{2}\ \text{and }L\geq n_0. $$

For simplicity, let us denote
$$P:=  \mathbb{P}\left\{ \begin{array}{l}
    \mbox{$\exists$ $\ell \in \mathbb N,$ $0<\ell<L$ and an interval $J \subset I$ such that}, f^\ell _\omega(J) =B_{2 \delta_0}(x_0)\\
    \mbox{and $\mathrm{dist}(f^i_\omega (J), \mathscr{C}_{\theta^i\omega} )> \varepsilon_0$ for every $0<i<\ell$.}
  \end{array}\right\}.$$
From the construction of $P$, we obtain that
\begin{align*}
     P&\geq \mathbb P[\omega \in \Omega;\ I + \omega_0 \supset J(\omega_1,\ldots, \omega_L) ].
\end{align*}
Therefore, for any interval $I\subset \mathbb S^1,$ such that $m(I) \ge  \delta_1$ with middle point $i_0$  we obtain that if $i_0 +\omega_0\in J(\omega_1,\ldots, \omega_n),$ then ${I+\omega_0 \supset J(\omega_1,\ldots, \omega_n)}.$  Therefore
$$ P \geq  \frac{4\delta_0}{ (\alpha\|\xi'\|_\infty)^{L+1}}.$$ 

This concludes the proof of the lemma.
\end{proof}

\subsection{Young times} \label{RT}
% For every $\alpha, \varepsilon>0$ satisfying the conditions of Lemma \ref{expansion}, let us associate positive numbers $\delta_0,$ $\delta_1$, $\iota,$ and $L$ such that the conclusion of Lemma \ref{expansion} holds.

In this subsection, we finally define Young times. For a given interval $I$, to reduce notation and improve readability, we denote
\begin{align}
    \mathcal E(I) := \left\{ \omega\in\Omega\ \middle\vert \begin{array}{l}
    \mbox{$\exists$ $\ell \in \mathbb N,$ $0<\ell\leq L$ and an interval $J \subset I$ s.t., $f^\ell _\omega(J) =B_{2 \delta_0}(x_0)$} \\
    \mbox{and $\mathrm{dist}(f^i_\omega (J), \mathscr{C}_{\theta^i\omega} )> \varepsilon_0$ for every $0<i<\ell$.}
  \end{array}\right\}.\label{Ei}
  \end{align}

Below we recall the definition of hyperbolic times. The following definition is adapted from  \cite[Section 6.1.1]{Alves}. We start fixing a real number $0 <b < 1/2.$
\begin{definicao}\label{hyperbolic times}
 Given $\sigma \in (0,1)$ and $r>0$, we say that $n$ is a $(\sigma^{2},r)$-hyperbolic time for $(\omega,x) \in \Omega \times \mathbb{S}^1$ if for every $0 \le k < n$, 
\begin{align*}
\prod_{j=k}^{n-1}\left|f'_{\theta^i\omega} (f_{\omega}^i(x))\right|^{-1} \leq \sigma^{2(n-k)},\ \text{and } \mathrm{dist}_{r}(f^{n-k}_\omega(x), {C}_{\theta^{n-k}(\omega)}) \ge \sigma^{b (n-k)}, 
\end{align*}
where, given a measurable set $A$, \ $$\ \dist_r(x,A) := \begin{cases}
\mathrm{dist}(x,A)&,\ \text{if} \ \dist(x,A)\leq r;\\
1&,\ \text{otherwise}.
\end{cases}$$

\end{definicao}

The result below states a consequence of $n$ being a $(\sigma^2,r)$-hyperbolic time for $(\omega,x)$.  The following result is an adaptation of \cite[Proposition 6.7]{Alves}, where the same proof can be naturally adapted to a random dynamical system context.

\begin{proposicao}\label{defVn}
Given $\sigma ,r>0$, there exist $\tilde{\delta}=\tilde{\delta}(\sigma,r)$ and  $C= C(\sigma,r)>0,$ such that for every $(\omega,x)\in \Omega\times \mathbb S^1$ for which $n\in\mathbb N$ is a $(\sigma^2,r)$-hyperbolic time and for every $0<\delta<\tilde\delta$ the following items hold:
\begin{enumerate}\label{HipBalls}
    \item[(i)] There exists an open neighbourhood $V_n^\delta(\omega,x)$ of $x$, such that $f^n_\omega$ maps $V_n(\omega,x)$ diffeomorphically to $B_{\delta} (f_\omega^n(x)).$
    \item[(ii)] for every $z,y\in V_n^\delta(x)$
    \begin{enumerate}
        \item[$a.$] $|f_{\omega}^{n-k}(z) -f_{\omega}^{n-k}(y)| \leq \sigma^{k} |f^n_\omega(z) - f^n_\omega(y)|,$ for every $1\leq k \leq n$;
        \item[$b.$] $\displaystyle \log \frac{|\d f^n_\omega (z)|}{|\d f^n_\omega (y)|} \leq C  |f^n_\omega(z) - f^n_\omega(y)|$.
    \end{enumerate}
\end{enumerate}
\end{proposicao}



The proposition below gives us the existence of the $L$-\emph{sparse hyperbolic times}. To not break the text flow, this proposition is proved in Appendix \ref{AppendixA}. The proof of this proposition closely follows the technique outlined in \cite{Giuseppe}.

\begin{proposicao}\label{LHiperbolicTijmens}
Let $L$ be the natural number defined at the beginning of Section \ref{RYT}. Consider the family of random variables $\{\tau_i: \Omega\times \mathbb S^1 \to\mathbb N\cup \{\infty\}\}_{i\in\mathbb N},$ where $$ \tau_i(\omega,x) :=\begin{cases}
\inf\{n; \ n\ \text{is an }(\sigma^2,r)\ \text{hyperbolic time for }(\omega,x)\}&, \ if\ i=1, \\
\inf\{n; \ n > L+\tau_{i-1}(\omega,x)\ \text{is an }(\sigma^2,r)\ \text{hyperbolic time for }(\omega,x)\}&,\ \text{if }i>1.
\end{cases} $$


Let $c\in (0,1)$. For $\alpha>0$  sufficient large, and $\varepsilon>\alpha^{c-1},$ there exists $0<\sigma < 1$ and $r>0$, independent of $L$,  such that 
$$\mathbb P \otimes m  \left[\bigcap_{i\in\mathbb N}\{\tau_i < \infty\} \right] = 1, $$
and there exists $\gamma >0,$ such that
$$\liminf_{n\to\infty} \frac{1}{n}\#\left(\{1,2,\ldots,n\} \cap \{\tau_i(\omega,x)\}_{i=1}^{\infty}\right) \geq \frac{\gamma}{L+1}.$$
Moreover, the convergence of
$$\sup_{x\in\mathbb S^1}\mathbb P \left[\#\left(\{1,\ldots,n\} \cap \{\tau_i(\omega,x)\}_{i=1}^{\infty}\right) \leq   \frac{\gamma}{2 (L+1)}  n\right] \to 0,$$
holds exponentially fast.

\end{proposicao}

Now, we are ready to define Young times. For every $\alpha, \varepsilon>0$ satisfying the conditions of Lemma \ref{expansion} and Proposition \ref{LHiperbolicTijmens}, let us associate  \begin{align}
    \delta_0, \delta_1, \iota, L >0 \ \text{and }x_0\in \mathbb S^1\label{constants}
\end{align} such that:
\begin{itemize}
    \item $\delta_0>0$ is fixed for every suitable  $\alpha,\varepsilon >0$, this is possible due to \eqref{defd0};  
    \item $\delta_1$ small enough such for $\delta = 9\delta_1$ the conclusions of Proposition \ref{HipBalls} hold;
    \item $\xi'(x_0) \neq 0;$ and
    \item the conclusion of Lemma \ref{CentralLema} holds.
\end{itemize}



\begin{definicao}
Let $\{\tau_i\}_{i=1}^{\infty}$ be the family of $L$-sparse $(\sigma^2,r)$-hyperbolic times defined on Proposition \ref{LHiperbolicTijmens}, and recall the definition of $\mathcal E(I)$ in \eqref{Ei}. Consider the set
\begin{align}
    Y_n(\omega, x) = \left\{i\in \{1,\ldots,n\}\cap \{\tau(\omega,x)\}_{i=1}^{\infty}; \ \theta^{i}\omega \in \mathcal E(B_{\delta_1}(f^i_\omega(x))\right\}.
\end{align} 
We say that $i$ is a $(\sigma^2,r)$-Young time for $(\omega,x)$ if there exists $n\in\mathbb N,$ such that $i\in Y_n$.
\label{YoungTijmen}
\end{definicao}

The following theorem shows that the Young times have positive density.

\begin{teorema}\label{youngprop}
Let $Y_n(\omega)$ be as in \eqref{YoungTijmen} and $c\in(0,1)$. Then for $\alpha>0$ sufficiently large and $\varepsilon>\alpha^{c-1},$  there exists $\theta_1 >0$ such that for every every $x\in\mathbb S^1,$  
$$\mathbb P\left[ \liminf_{n\to \infty} \frac{\#Y_{n}(\omega,x)}{n } > \theta_1 \right] =1. $$
\end{teorema}

\begin{proof}
In order to simplify the notation let us denote $S_n(\omega,x) = \{1,\ldots, n\} \cap \{\tau_i(\omega,x)\}_{i=1}^{\infty}$. From the Borel-Cantelli lemma, it is enough to show that there exists $\lambda>0$ such that 
$$ a_n := \mathbb P [\#Y_n(\omega,x) \leq \lambda  n]$$
decays exponentially fast as $n\to\infty$.


Using Proposition \ref{LHiperbolicTijmens} and setting $\upsilon := \gamma/(2L +2),$ we obtain that
$$ \mathbb P[\#Y_n(\omega,x) \leq   \lambda n, \#S_n(\omega,x) \leq \upsilon n] \leq  \mathbb P[ \# S_n(\omega,x) \leq \upsilon n]  \xrightarrow{n\to\infty} 0,$$
exponentially fast. Since
\begin{align*}
a_n := \mathbb P[\# Y_n(\omega,x) \leq \lambda  n, \# S_n(\omega,x) \leq \upsilon n] +  \mathbb P[\# Y_n(\omega,x) \leq \lambda  n , \# S_n(\omega,x) \geq \upsilon n].
\end{align*}
to finish the proof of the theorem, it is enough to show that, for $\lambda >0$ small enough, the quantity 
$$ \mathbb P[\# Y_n(\omega,x) \leq \lambda  n, \# S_n(\omega,x) \geq \upsilon n]  \xrightarrow{n\to\infty} 0,$$
exponentially fast. We divide the remaining proof into three steps.

\begin{step}{1}
We show that 
\begin{align}
  &\mathbb P \left\{ \begin{array}{l}
   \# Y_n(\omega,x) \leq \lambda  n,\\
    \# S_n(\omega,x) \geq \upsilon n
  \end{array}\right\} =& \sum_{ s = \lceil \upsilon n \rceil}^{n} \sum_{j = s - \lfloor\lambda  n\rfloor}^{s} \sum_{0\leq i_1 \leq \ldots \leq i_j \leq s }\mathbb P \left\{ \begin{array}{l}
   \tau_{i_1}(\cdot,x) ,\ldots, \tau_{i_j}(\cdot,x) \not \in  Y_n(\cdot,x),\\
    \tau_{s}(\cdot ,x) \leq n < \tau_{s+1}(\cdot,x)
  \end{array}\right\}\label{giuseppe2}
    \end{align} 

\end{step}

Observe that
\begin{align*}
   \mathbb P[\# Y_n(\omega,x) \leq \lambda  n, \# S_n(\omega,x) \geq \upsilon n] &= \sum_{ s = \lceil \upsilon n \rceil}^{n} \mathbb P[\# Y_n(\omega,x) \leq \lambda  n, \# S_n(\omega,x) = s].
\end{align*}

Note that $\omega \in \{ \# Y_n(\cdot ,x) \leq \lambda  n , \# S_n(\cdot ,x) = s\}, $ if and only if 
there exists $ j  > s -\lambda  n$, such that there exists $j$ distinct $L$-sparse hyperbolic times $i_1,\ldots,i_j \in S_n(\omega,x) \setminus Y_n(\omega,x)$. Therefore
\begin{align}
   \mathbb P[\# Y_n(\omega,x) \leq \lambda  n, \# S_n(\omega,x) \geq \upsilon n] &= \sum_{ s = \lceil \upsilon n \rceil}^{n} \mathbb P[\exists\ j > s-\lambda  n; \exists\ i_1,\ldots \leq i_j \in S_n \setminus Y_n].\label{giuseppe1}
\end{align}

Observe that a hyperbolic time $i \in S_n \setminus  Y_n,$ if and only if  $i\in S_n(\omega,x)$ and $$\theta^{i}(\omega) \not \in \mathcal E(B_{\delta_1} (f_\omega^{i} (\omega,x) ) \ \text{if and only if } \omega \not \in  \theta^{-i} \left(\mathcal E(B_{\delta_1} (f_\omega^{i}(x))\right).$$
Moreover, $\# S_n(\omega,x) = s,$ if and only if $\tau_s\leq n < \tau_{s+1}.$

Combining the above observation with \eqref{giuseppe1} we obtain \eqref{giuseppe2}. This completes the proof of Step 1.

\begin{step}{2} \it{ We show that for every $j > s-\lambda  n$ and $0\leq i_1\leq  \ldots \leq i_j \leq s$, we have that
$$\mathbb P \left\{ \begin{array}{l}
   \tau_{i_1}(\cdot,x) ,\ldots, \tau_{i_j}(\cdot,x) \not \in  Y_n(\cdot,x),\\
    \tau_{s}(\cdot ,x) \leq n < \tau_{s+1}(\cdot,x)
  \end{array}\right\} \leq (1-\iota)^{ j }. $$}\label{claimgiu1}
\end{step}

 
Observe that 
\begin{align}
   & \mathbb P \left\{\omega \in \Omega\, \bigg \vert\,  \begin{array}{l}
   \tau_{i_1}(\omega,x) ,\ldots, \tau_{i_j}(\omega,x) \not \in  Y_n(\omega,x),\nonumber\\
    \tau_{s}(\cdot ,x) \leq n < \tau_{s+1}(\cdot,x)
  \end{array}\right\} \\=& \mathbb P \left\{\omega \in \Omega\,\left\vert \, \begin{array}{l}
   \omega \in \bigcap_{k=1}^j \theta^{-\tau_{i_k}(\omega,x) }  \left(\mathcal E(B_{\delta_1} (f^{\tau_{i_k}(\omega,x)} (\omega,x)))\right)^{^\mathsf{c}} ,\\
    \tau_{s}(\omega ,x) \leq n < \tau_{s+1}(\omega ,x)
  \end{array}\right. \right\}\nonumber\\
  \leq& \mathbb P \left\{\omega \in \Omega\, \bigg \vert
   \, \bigcap_{k=1}^j \theta^{-\tau_{i_k}(\omega ,x) }  \left(\mathcal E(B_{\delta_1} (f^{\tau_{i_k}(\omega ,x)} (\omega ,x)))\right)^{^\mathsf{c}}  \right\}\label{giuseppe3}.
\end{align}

Moreover
\begin{align}
P &:=\mathbb P \left[\omega\in \Omega\, \bigg\vert\,
   \bigcap_{k=1}^j \theta^{-\tau_{i_k}(\omega,x) }  \left(\mathcal E(B_{\delta_1} (f^{\tau_{i_k}(\omega,x)} (\omega,x)))\right)^{^\mathsf{c}}  \right]\nonumber \\ &= \mathbb E \left[\prod_{k=0}^{j-1} \mathbbm 1_{\theta^{-\tau_{i_k}(\cdot,x) }  \left(\mathcal E(B_{\delta_1} (f^{\tau_{i_k}(\cdot,x)} (\cdot,x)))\right)^{^\mathsf{c}} } \cdot\mathbbm 1_{\theta^{-\tau_{i_j}(\cdot,x) }  \left(\mathcal E(B_{\delta_1} (f^{\tau_{i_j}(\cdot,x)} (\cdot,x)))\right)^{^\mathsf{c}} }\right]\nonumber\\
   &=\mathbb E\left[ \mathbb E \left[\left.\prod_{k=0}^{j-1} \mathbbm 1_{\theta^{-\tau_{i_k}(\cdot,x) }  \left(\mathcal E(B_{\delta_1} (f^{\tau_{i_k}(\cdot,x)} (\cdot,x)))\right)^{^\mathsf{c}} } \cdot\mathbbm 1_{\theta^{-\tau_{i_j}(\cdot,x) }  \left(\mathcal E(B_{\delta_1} (f^{\tau_{i_j}(\cdot,x)} (\cdot,x)))\right)^{^\mathsf{c}} }\right\vert \mathcal F_{\tau_{i_j}(\cdot,x) } \right]\right]\label{giuseppe4},
\end{align}
where   $\mathcal F_{\tau_j(\cdot,x)}$ is the $\sigma$-algebra of $\tau_j(\cdot,x)$-past.

Observe that since $\{\tau_i\}_{i=0}^{\infty}$ are $L$-sparse hyperbolic times, from the definition of $\mathcal E(I)$ we obtain that
$$\prod_{k=0}^{j-1} \mathbbm 1_{\theta^{-\tau_{i_k}(\cdot,x) }  \left(\mathcal E(B_{\delta_1} (f^{\tau_{i_k}(\cdot,x)} (\cdot,x)))\right)^{^\mathsf{c}} }  \text{ is }\mathcal F_{\tau_j(\cdot,x)}\text{-measurable},$$
and, from the strong Markov property, for every $\tilde \omega \in \Omega$
\begin{align*}
    \mathbb E\left[\mathbbm 1_{\theta^{-\tau_{i_j}(\cdot,x) }  \left(\mathcal E(B_{\delta_1} (f^{\tau_{i_j}(\cdot,x)} (\cdot,x)))\right)^{^\mathsf{c}} }\mid \mathcal F_{\tau_{i_j}(\cdot,x)}\right](\tilde \omega) &= \mathbb E\left[ \mathbbm 1_{ \left(\mathcal E(B_{\delta_1} (f^{\tau_{i_j}(\tilde \omega,x)} (\tilde \omega,x)))\right)^{^\mathsf{c}} }\right]\leq 1-\iota.
\end{align*}
The last inequality follows applying Lemma \ref{CentralLema} with $I =  m(B_{\delta_1} (f^{\tau_{i_j}(\tilde \omega,x)} (\tilde \omega,x)))$.


Combining, the above inequality with $\eqref{giuseppe4}$ we obtain that
$$ P \leq (1-\iota) \mathbb P \left[\omega\in \Omega\, \bigg\vert\,
   \bigcap_{k=1}^{j-1} \theta^{-\tau_{i_k}(\omega,x) }  \left(\mathcal E(B_{\delta_1} (f^{\tau_{i_k}(\omega,x)} (\omega,x)))\right)^{^\mathsf{c}}  \right], $$
repeating the same procedure $j-1$ times, we have that
$$ \mathbb P \left\{ \begin{array}{l}
   \tau_{i_1}(\cdot,x) ,\ldots, \tau_{i_j}(\cdot,x) \not \in  Y_n(\cdot,x),\\
    \tau_{s}(\cdot ,x) \leq n < \tau_{s+1}(\cdot,x)
  \end{array}\right\}\leq P \leq (1-\iota)^{ j }.$$

This proves Step 2. 

\begin{step}{3}
We show that for $\lambda$ sufficiently, $\mathbb P[\# Y_n(\omega,x) \leq \lambda  n, \# S_n(\omega,x) \geq \upsilon n]  \xrightarrow{n\to\infty} 0$ exponentially fast.
\end{step}
From Step \ref{claimgiu1}, \eqref{giuseppe2} and assuming that $\lambda < \upsilon/2$ we obtain that

\begin{align}
  \mathbb P \left\{ \begin{array}{l}
   \# Y_n(\omega,x) \leq \lambda  n,\\
    \# S_n(\omega,x) \geq \upsilon n
  \end{array}\right\} \leq& \sum_{ s = \lceil \upsilon n \rceil}^{n} \sum_{j = s - \lfloor\lambda  n\rfloor}^{s} \sum_{0\leq i_1 \leq \ldots \leq i_j \leq s }(1-\iota)^j\nonumber\leq  \sum_{ s = \lceil \upsilon n \rceil}^{n} \sum_{j = s - \lfloor\lambda  n\rfloor}^{s} \binom{s}{j}(1-\iota)^j\nonumber\\
  &\leq  \sum_{ s = \lceil \upsilon n \rceil}^{n} \lambda  n \binom{s}{ s - \lfloor\lambda  n\rfloor}(1-\iota)^{( \upsilon   - \lambda) n}\nonumber\leq  \sum_{ s = \lceil \upsilon n \rceil}^{n} \lambda n \binom{s}{  \lfloor\lambda n\rfloor}(1-\iota)^{( \upsilon   - \lambda ) n}\nonumber\\
    &\leq  \lambda n^2 \binom{n}{  \lfloor\lambda n\rfloor}(1-\iota)^{( \upsilon   - \lambda ) n}\nonumber\leq  \lambda n^2 \left(\frac{e n}{\lfloor\lambda n\rfloor}\right)^{\lfloor\lambda n\rfloor}(1-\iota)^{( \upsilon   - \lambda ) n}\nonumber\\
    &\leq  \lambda n^2 \left(\frac{2e }{\lambda}\right)^{\lambda n}(1-\iota)^{( \upsilon   - \lambda ) n} \nonumber \leq  \lambda n^2 \left(\left(\frac{2e }{\lambda}\right)^{\lambda}(1-\iota)^{( \upsilon   - \lambda ) } \right)^{n}.\nonumber 
    \end{align} 

Since
$$\lim_{\lambda \to 0}  \left(\frac{2e }{\lambda}\right)^{\lambda}(1-\iota)^{( \upsilon   - \lambda )} = (1-\iota)^\upsilon < 1,$$
we can choose, $\lambda$ small enough such that $\lambda< 2\upsilon$ and 
$\frac{1 + (1-\iota)^\upsilon }{2}<1.$  Therefore,
$$\mathbb P \left\{ \begin{array}{l}
   \# Y_n(\omega,x) \leq \lambda n,\\
    \# S_n(\omega,x) \geq \upsilon n
  \end{array}\right\} \leq \lambda n^2\left(\frac{1 + (1-\iota)^\upsilon }{2}\right)^n  \xrightarrow{n\to\infty} 0,  $$
exponentially fast. This proves Step 3. Therefore,  setting $\theta_1 = \lambda$, we complete the proof of the theorem.
% $$ I := 
\end{proof}

\begin{corolario}\label{giucor}
Let $c\in (0,1)$. For $\alpha>0$ sufficiently large and $\varepsilon>\alpha^{c-1},$ 
$$ m\left\{x\in \mathbb S^1: \liminf_{n\to\infty} \frac{\#Y_n(\cdot,x)}{n} > \theta_1\right\}  =1 \ \mathbb P\text{-almost surely}. $$
\label{Gcor}
\end{corolario}
\begin{proof}
From Theorem \ref{youngprop} we obtain that for every $x\in \mathbb S^1$
$$\mathbb P \left[\liminf_{n\to\infty} \frac{\#Y_n(\omega,x)}{n} > \theta_1\right] = 1,$$
integrating both sides with respect to $m(\d x)$ 
$$\int_{\mathbb S^1}\mathbb P \left[\liminf_{n\to\infty} \frac{\#Y_n(\omega,x)}{n} > \theta_1\right] \mathrm {d} x = 1.$$

From Fubini's theorem
\begin{align*}
    1&=\int_{\mathbb S^1}\mathbb P \left[\liminf_{n\to\infty} \frac{\#Y_n(\omega,x)}{n} > \theta_1\right] \mathrm {d} x =\int_{\Omega} m\left[ \liminf_{n\to\infty} \frac{\#Y_n(\omega,x)}{n} > \theta_1 \right] \mathbb P [\mathrm {d}\omega] .
\end{align*}
Since,
$$ m\left[ \liminf_{n\to\infty} \frac{\#Y_n(\omega,x)}{n} > \theta_1 \right] \leq 1\ \text{for every }\omega\in \Omega,$$
we obtain that 
$$m\left[ \liminf_{n\to\infty} \frac{\#Y_n(\omega,x)}{n} > \theta_1 \right]  =1\ \text{for }\mathbb P\text{-almost every }\omega\in\Omega.$$

\end{proof}


Motivated by the above theorem, we define
\begin{align}
    Y(\omega,x) := \bigcup_{n\in \mathbb N} Y_n(\omega,x), \label{defY}
\end{align}
and for every fixed $n\in\mathbb N$ we denote
\begin{align}
    \widetilde{H}_n(\omega) := \{x\in \mathbb S^1 ; n\in Y(\omega,x)\}. \label{defHn}
\end{align}
From Corollary \ref{Gcor} we have that $\mathbb P$-almost every $\omega\in\Omega,$ we have that $m$-almost every $x\in \mathbb S^1$ lies in infinitely meany $H_n(\omega).$

\section{Random Young towers}\label{RYT}

In this section, we construct a random Young tower for $f_\omega^n$. The construction is based on the definition of the positive density of the Young times and the techniques presented \cite[Chapter 5]{Alves}. Recall the definitions of the positive numbers $\delta_0,\delta_1, L$ and $x_0\in\mathbb S^1$ in \eqref{constants}.

 Using Proposition \ref{defVn} and the definition of $\delta_1$, if $n$ is a $(\sigma^2,r)$-Young time for $(\omega,x)$ we define $V_n(\omega,x) := V^{9\delta_1}(\omega,x)=  f^{-n}_\omega \left( B_{9\delta_1}( f^n_\omega(x)\right).$ In a similar fashion, we define the sets $W_n(\omega,x)\subset \widetilde{W}_n(\omega,x)\subset V_n(\omega,x)$ as, 
$$ W_n(\omega,x) := f^{-n}_\omega \left( B_{\delta_1}\left( f^n_\omega(x)\right)\right)\ \text{and}\  \widetilde{W}_n(\omega,x) := f^{-n}_\omega \left( B_{3 \delta_1}( f^n_\omega(x)\right).$$

Supposing that $n$ is a $(\sigma^2,r)$-Young time then $\theta^{n} \omega \in \mathcal E(B_{\delta_1}(f_\omega^i(x)))$. Therefore there exists $0\leq \ell \leq L$, and a set $U \subset f^n_\omega(W_n(\omega,x))$ such that $f^\ell_{\theta^n \omega}$ maps $U$ diffemorphically to $B_{2 \delta_0}(x_0)$. We denote $U'\subset U$ such that $f^{\ell}_{\theta^n \omega}$ maps $U'$ diffeomorphically to $B_{\delta_0}(x_0).$ Finally, we denote 
$\widetilde{w}_{n,\ell}(\omega,x)$ the subset of  $\widetilde{W}_n(\omega,x)$ that $f^n_\omega$ maps diffemorphically to $U$ and $w_{n,\ell}(\omega,x)$ the subset of $\widetilde{w}_{n,\ell}(\omega)$ that $f^n_\omega$ maps diffeomorphically to $U'$. When the context is clear we denote $\widetilde{w}_{n,\ell} (\omega,x)$ and ${w}_{n,\ell}(\omega,x)$, simply by $\widetilde{w}_{n,\ell}$ and ${w}_{n,\ell}$.

Defining $\Delta := B_{\delta_0}(x_0)$ we construct a partition of $\Delta$ using the above notation. In the following, we prove a lemma that allows us to naturally 
 adapt the construction presented {\cite[Chapter 5]{Alves}} to the random  context.



\begin{lema}\label{i1i2i3}
Let $c\in (0,1)$. For sufficiently large $\alpha >0$ and $\varepsilon >\alpha^{c -1}$, we obtain that:
\begin{enumerate}
    \item[$(I_1)$] For $\mathbb P$-almost every $\omega\in \Omega$, $\{H_n(\omega)\}_{n\in\mathbb N}$  are compact sets (see \eqref{defHn}). Moreover, $m$-almost every point in $\Delta$ belongs to infinitely many $H_n(\omega)$'s.
    \item[$(I_2)$] There exists a constant $C>0,$ such that for every $x\in H_n(\omega)$, $V_n(\omega,x)$ is diffeomorphically mapped in a disk of radius $9\delta_1$ around $f^n_\omega(x)$, and for every $y,z \in V_n(\omega,x)$
    \begin{itemize}
        \item  $|f_{ \omega}^{n-k}(z) -f_{ \omega}^{n-k}(y)| \leq \sigma^{k} |f^n_\omega(z) - f^n_\omega(y)|,$ for every $1\leq k \leq n$;
        \item  $\displaystyle \log \frac{|\d f^n_\omega (z)|}{|\d f^n_\omega (y)|} \leq C  |f^n_\omega(z) - f^n_\omega(y)|$.
    \end{itemize}
    \item[$(I_3)$] There exists $C_1 >0$, such that for every $\widetilde{w}_{n,\ell}(\omega,x)$ and $y,z\in f^n_{ \omega}(\widetilde{w}_{n,\ell}(\omega,x) ),$
    \begin{itemize}
        \item $\displaystyle \frac{1}{C_1} |f_{\theta^n \omega}^j(x) - f_{\theta^n \omega}^j(z)| \leq |f^\ell_{\theta^n \omega} (y) - f^\ell_{\theta^n \omega} (z)| \leq C_1 |y-z|,$ for all $0\leq j \leq \ell$;
        \item $\displaystyle\log \frac{|\d f^\ell_{\theta^n \omega} (z)|}{|\d f^\ell_{\theta^n \omega}(y)|} \leq C_1 |f^\ell_{\theta^n \omega} (y) - f^\ell_{\theta^n\omega } (z)|$.
    \end{itemize}
    
\end{enumerate}
\end{lema}
\begin{proof}
Observe that $(I_1)$ follows directly from Corollary \ref{giucor}, and $(I_2)$ from Proposition \ref{defVn}.

We proceed to prove $(I_3)$. Since,  $f_\omega(x) = \alpha \xi_\omega(x+ \omega_0)+ a$, given $\varepsilon_0>0$ as in \eqref{Ei}, we can find a constant $K_0>0,$
$$\inf_{x\in S^1 \setminus B_{\varepsilon_0}(\mathscr{C}_{\omega} )}|d f_\omega(x)| > K_0,$$
where $B_{\varepsilon_0}(\mathscr C_\omega) = \{x\in \mathbb S^1; \mathrm{dist}(x,\mathscr{C}_{\omega}) <\varepsilon_0\}.$

Since $n$ is an $(\sigma^2,r)$-Young time, then $\theta^n\omega\in \mathcal E(B_{\delta_1}(f_\omega^i(x))).$ Using the above observation and the chain rule we obtain that there exists $\widetilde{K}_0$ such that
$$\frac{1}{\widetilde{K}_0} |f_{\theta^n \omega}^j(x) - f_{\theta^n \omega}^j(z)| \leq |f^\ell_{\theta^n \omega} (y) - f^\ell_{\theta^n \omega} (z)| \leq \widetilde{K}_0 |y-z|,$$ for all $0\leq j \leq \ell.$

To prove the second bullet point of $(I_3)$, observe that
$$\displaystyle\log \frac{|\d f^\ell_{\theta^n \omega} (z)|}{|\d f^\ell_{\theta^n \omega}(y)|} = \sum_{i=0}^{\ell-1} |\log|\d f_{\theta^{\ell+i} \omega} (f^{i}_{\theta^n\omega}) (z) - \log|\d f_{\theta^{\ell+i} \omega} (f^{i}_{\theta^n\omega}) (y)| $$
using mean value theorem, the fact that the function is $\mathcal C^2$, and the first item of $I_3$, we find a constant $\widetilde K_1$ such that
$$ \log \frac{|\d f^\ell_{\theta^n \omega} (z)|}{|\d f^\ell_{\theta^n \omega}(y)|} \le \widetilde K_1  |f^\ell_{\theta^n \omega} (y) - f^\ell_{\theta^n\omega } (z)|,$$
the proof is finished defining $C_1 = \max\{\widetilde K_0, \widetilde K_1\}.$
\end{proof}


\subsection{Pathwise classical construction}\label{pathwiseconstr}

This subsection presents a pathwise tower construction for the random dynamical system $f_\omega^n$ on $\Delta$. It should be noted that the construction presented in this subsection does not result in a measurable function return function $R$. However, in subsection \ref{measurabletower}, we slightly modify the construction presented in this section in order to obtain a measurable return function.

The construction below is based on Lemma \ref{i1i2i3} and the method provided in {\cite[Chapter 5]{Alves}}. We closely follow the construction and notation from {\cite[Chapter 5.2]{Alves}} to clarify and emphasise the connection between our work and the classical Young towers theory. 

\label{partition}
Fix a constant $c\in (0,1)$. Consider $\alpha_4 = \alpha_4(c) >0$ large enough,  and $\varepsilon>\alpha^{c-1},$ such that the conclusions of Lemma \ref{i1i2i3} holds and
\begin{align}
    \frac{1}{\# \mathscr{C} +1}\left(2\delta_0 - \frac{2\# \mathscr{C}}{\min_{c\in \mathscr{C} }|\xi''(c)|}\frac{1}{\alpha^{1/2}} \right) \geq \frac{1}{\alpha^{1/2}} \ \text{for every }\alpha>\alpha_4.\label{defa4}
\end{align}


For every $\omega = (\omega_i)_{i\in\mathbb Z}$ we aim to construct a partition $\mathcal P(\omega)$ of $\Delta$ having ${H_n(\omega):= \widetilde{H}_n(\omega) \cap \mathbb S^1}$ (see \ref{defHn}). To this end, we inductively define the families of sets $\{\mathcal P_n(\omega)\}_{n\in\mathbb N},$ $\{\Delta_n(\omega)\}_{n\in \mathbb N}$ and $\{S_n(\omega)\}_{n\in\mathbb N}$ depending only on $(\omega_0,\ldots, \omega_{n-1}),$ in a way that 
\begin{itemize}
    \item $\mathcal P_n(\omega)$ is the family of elements of the partition of $\Delta$ constructed at step $n$;
    \item $\Delta_n(\omega)$ is the set of points which do not belong to  any element of the partition defined up to time $n$;
    \item $S_n(\omega)$ contains points in $H_n(\omega):= \widetilde{H}_n(\omega) \cap  \Delta$ (see \ref{defHn}) not taken by elements of $\mathcal P_k(\omega)$'s constructed until time $n$.
\end{itemize}



In the following, we describe the construction of the above families of sets. Recall the constants $C_0, C_1$ and $\sigma$ defined in Lemma \ref{i1i2i3}. We start by defining the following auxiliary constants:
\begin{itemize}
    \item[(i)] $\delta_2 = \delta_0 + 9\delta_1 C_1/2$; 
    \item[(ii)] $1 < N_0\in\mathbb N$ large enough so that $C\sigma^{N_0} <1;$ and
    \item[(iii)] $N_1\in \mathbb N$ large enough so that
$$\delta_2 \sigma^{N_1} \leq \delta_0 \ \text{and }2\delta_1 \sigma^{N_1} \leq \frac{\delta_0(1-\sigma^{N_1})}{C_1}. $$
\end{itemize}
Also, given $w_{k,\ell}(\omega,x)$ we define for every $n>k,$
$$A_n(\omega, w_{k,\ell}) = \left\{y\in \widetilde{w}_{k,\ell};\ \mathrm{dist}(f^{k+\ell}_\omega(y), f_\omega^{k+\ell}(\omega, w_{k,\ell}) \leq \delta_0 \sigma^{n-k}\right\}. $$

From Lemma \ref{i1i2i3} it is readily verified $A_n(\omega, w_{k,\ell})$ that $f^{k+\ell}_\omega (\widetilde{w}_{n,\ell})$ contains a neighbourhood of the boundary of $f^{k+\ell}_\omega(A_n(\omega))$ of size at least  $$2\delta_0 - \delta_0(1+\sigma^{n-k}) = \delta_0 (1-\sigma^{n-k}).$$

We divide the construction into two steps:

   \begin{step}{1} If $n \in \mathbb N$ and $n <N_0.$ \label{step1}
\end{step}
For $n=1$ we define
$$\mathcal P_1(\omega) = \{w_{1,0}(\omega,x(\omega))\}, $$
where $w_{1,0}(\omega,x(\omega))$ is an open sub-interval of $\Delta$ such that $\left.\d f_\omega\right|_{w_{1,0}(\omega,x(\omega))}\geq \alpha^{1/2}$ and ${m(\mathbb S^1 \setminus f_\omega(w_{1,0}(\omega,\omega(x)))) = 0}$. Combining Lemma \ref{LGiu} with  \eqref{defa4} we obtain that $\mathcal P_1(\omega)$ is non-empty. Also, set
$$S_1(\omega) = \Delta,$$
and 
$$\Delta_1 (\omega) = \Delta \setminus   w_{1,0}(\omega,x(\omega)).$$

For every $1<n< N_0,$ we set 
$$\mathcal P_n(\omega) = \emptyset,\ S_n(\omega) = \Delta,\ \text{and }\Delta_n(\omega) = \Delta_1(\omega). $$

\begin{step}{2}
If $n \geq N_0.$
\end{step}
We proceed with the construction by induction. Give $n\geq N_0$, we assume that the families $\mathcal P_k(\omega)$, $S_k(\omega)$ and $\Delta_k(\omega)$ were constructed for every $1\leq k \leq n-1$. Then, we construct $\mathcal P_n(\omega),$ $S_n(\omega)$ and $\Delta_n.$ 

Let $F_n(\omega)$ be a finite subset of the compact $H_n(\omega)$ such that
$$H_n(\omega)\subset \bigcup_{x\in F_n(\omega)} W_n(\omega,x),$$

Consider $x_1, \ldots, x_{j_n} \in F_n(\omega)$ and, for every $1\leq i \leq j_n,$ a domain $w_{n,\ell}(\omega,x_i)\subset W_n(\omega, x_i)$ as in Lemma \ref{i1i2i3} $(I_3)$ for which $\mathcal P_n(\omega) = \{w_{n,\ell_1} , \ldots, w_{n, \ell_{j_{n}}}\}$ is a maximal family of pairwise disjoint sets contained in $\Delta_{n-1}(\omega),$ such that for every $1\leq i \leq j_n$
\begin{align}
\omega_{n,\ell_i} \cap \left(\bigcup_{k=N_0}^{n-1} \bigcup_{w \in\mathcal P_k(\omega)} A_n(\omega, w)\right) = \emptyset.\label{partA}    
\end{align}

The sets in $\mathcal P_n(\omega)$ are the elements of the partition $\mathcal P(\omega)$ obtained in the $n$-th step of the construction. Set
$$\Delta_n(\omega)= \Delta \setminus \left(\bigcup_{k=N_0}^{n-1} \bigcup_{w \in\mathcal P_k(\omega)} w\right). $$

Given $w_{k,\ell}(\omega,x) \in \mathcal P_k(\omega),$ for some $N_0 \leq k\leq n$ set,
$$S_n(\omega, w_{k,\ell}(\omega,x) ) = \widetilde W_{k}(\omega,x)\ \text{ if }n-k<N_1  $$
and for $n-k\geq N_1$
\begin{align}
  S_n(\omega,  w_{k,\ell}) =\{y\in \widetilde{w}_{k,\ell} ; 0< \mathrm{dist}(f_\omega^{k+\ell}(y), f_{\omega}^{k+\ell}( w_{k,\ell}) \leq \delta_2 \sigma^{n-k}\}, \label{Sn}  
\end{align} 
and 
$$S_n(\omega,\Delta^\mathsf{c}) =\left\{x\in \Delta; \mathrm{dist}(x,\partial \Delta^\mathsf{c}_0) < 2\delta_1 \sigma^n\right\}.$$

Define
$$S_n(\omega)= S_n(\omega,\Delta^\mathsf{c})  \cup \left(\bigcup_{k=1}^{n} \bigcup_{w \in \mathcal P^k(\omega)} S_n(\omega,w)\right). $$

Finally, set 
\begin{align}
  \mathcal P(\omega) = \bigcup_{n\geq 1} \mathcal P_n(\omega). \label{defP}  
\end{align}

\begin{teorema}
Given $c\in (0,1)$. For every $\alpha > \alpha_4$ (see \ref{defa4}) and $\varepsilon > \alpha^{c-1}$, the partition $\mathcal P(\omega)$ constructed above is a $m$-$\mathrm{mod}\ 0$ partition.
\end{teorema}

\begin{proof}
The follows directly from \cite[Corollary 5.9]{Alves}. Observing that the construction of the sets $\mathcal P_n(\omega),$ $S_n(\omega)$ and $\Delta_n(\omega)$ is essentially same as in \cite[Chapter 5.2.1]{Alves} and the assumptions $(I_1),$ $(I_2)$ and $(I_3)$ in \cite[Chapter 5.1]{Alves} correspond to Lemma \ref{i1i2i3}.
\end{proof}


\subsection{Measurability of the return time $R$\label{measurabletower}}

At this moment for $\mathbb P$-almost every $\omega\in \Omega,$ there exists a  $m$-mod $0$ partition $\mathcal P(\omega)$ (see \ref{defP}) of $\Delta = B_{\delta_0} (x_0).$ 
% Let us define $\Omega_0\subset \Omega$ a set such that $\Omega_0$ is $\theta$-invariant, $\mathbb P[\Omega_0]=1$ and for every $\omega\in\Omega_0$ the partition $\mathcal P(\omega)$ exists.
Following the construction presented in \cite[Chapter 5]{Alves}, we aim to define
\begin{align*}
    R:\Omega_0 \times \Delta &\to \mathbb N\\
    (\omega,x)&\to n+\ell\ \text{if }x\in\omega_{n,\ell}\in\mathcal P(\omega).
\end{align*}
However, it is unclear if $R$ is a measurable function.  To guarantee the measurability of the return function $R$, we slightly change the construction of $\mathcal P(\omega)$. 

We start by recalling the definition of a measurable family of sets.
\begin{definicao}
Given a measurable spaces $(\Omega, \mathcal F )$ and $(X,\mathcal B(X))$ a family of sets ${\{A(\omega)\}_{\omega\in\Omega}\subset \mathcal B(X)}$ is called a \emph{measurable family of sets} if for every open set $U$, the set
    $$\{\omega\in \Omega; A(\omega)\cap U \neq \emptyset\}\text{ is measurable}. $$

When the context is clear, we denote $\{A(\omega)\}_{\omega\in\Omega}$ simply by $A(\omega).$    
\end{definicao}

During this section, we make use of the following theorem.
\begin{teorema}[{\cite[Proposition 4.6]{vianaLya}}] \label{meas}Let $(\Omega,\mathcal F)$ and $(X,\mathcal B(X))$ measurable spaces. Given a family of compact sets $\{A(\omega)\}_{\omega\in \Omega}\subset \mathcal B(X),$ the following statements are equivalent:
\begin{enumerate}
    \item $A(\omega)$ is a measurable family of sets; and
    \item the set $\mathrm{Graph}(A) =\{(\omega,x)\in \Omega\times X;\ x\in A(\omega)\}$ is $\mathcal F\otimes \mathcal B(X)$-measurable .
\end{enumerate}\label{eqv}
\end{teorema}


The two results below show that the sets used in constructing the tower presented in Section \ref{measurablepart} are a family of measurable sets. 

\begin{proposicao}
For every $n\in\mathbb N$, the set $A_n := \{(\omega,x)\in \Omega\times \mathbb S^1; V_n(\omega,x)\ \text{exists}\}$ is measurable. Moreover the families of sets $\{H_n(\omega)\}_{\omega \in \Omega}$, $\left\{\overline{V_n(\omega,x)}\right\}_{(\omega,x)\in \Omega}$ and $\{\mathbb S^1 \setminus V_n(\omega,x)\}_{(\omega,x)\in\Omega\times M}$ are measurable. 
\end{proposicao}
\begin{proof}
Denote $\upsilon_i (\omega,x)$ as the $i$-th $(\sigma^2,r)$-Young time. Therefore
$$A_n = \bigcup_{i=0}^{\infty} \{\upsilon_i = n\} = \bigcup_{i=0}^{n} \{\upsilon_i = n\}, $$
which is measurable. Moreover, since $$H_n(\omega) =\Delta \cap  \bigcup_{i=0}^{n} \{\upsilon_i(\omega,\cdot) = n\},$$
we obtain that $H_n(\omega)$ is a measurable family of sets.

We prove that $\left\{\overline{V_n(\omega,x)}\right\}_{(\omega,x)\in \Omega\times \mathbb S^1}$ is a measurable family of sets.  Observe that
$$\overline{V_n(\omega,x)} = \overline{f^{-n}_\omega \left(B_{9\delta_1}(f_\omega(x))\right)} \cap \overline{B_{9\delta_1 \sigma^n}(x)},$$
the above statement is not true in general. However, the above equality holds since $\left.f_\omega\right|_{V_n(\omega,x)}$ is a diffeomorphism. Let $U\subset \mathbb S^1$ be an open set, and consider
$$I(U) := \left\{(\omega,x)\in A_n ; U \cap  \overline{f^{-n}_\omega \left(B_{9\delta_1}(f_\omega(x))\right)} \cap \overline{B_{9\delta_1 \sigma^n}(x)}\neq \emptyset\right\}.$$

Observe that $  U \cap  \overline{f^{-n}_\omega \left(B_{9\delta_1}(f_\omega(x))\right)} \cap \overline{B_{9\delta_1 \sigma^n}(x)} \neq \emptyset $, if and only if, there exists $u\in U$ such that $|f_\omega (u) - f_\omega (x)|\leq 9\delta_1$ and $|u- x| \leq 9\delta_1 \sigma^n$.

Let $\{u_j\}_{j\mathbb N}$ be a dense sequence in $U$, this implies that
\begin{align*}
 A_n\setminus  I(U) &=  \left\{(\omega,x)\in A_n ; U \cap  \overline{f^{-n}_\omega \left(B_{9\delta_1}(f_\omega(x))\right)} \cap \overline{B_{9\delta_1 \sigma^n}(x)}= \emptyset\right\}\\
  &=A_n \cap \bigcup_{u \in U}\{(\omega,x); |f_\omega (u) - f_\omega(x)|> 9\delta_1 \text{ or } |u-x| > 9\delta_1\sigma^n\}\\
  &= A_n \cap \bigcup_{j \in \mathbb N}\left\{(\omega,x); |f_\omega (u_j) - f_\omega(x)|> 9\delta_1 \ \text{or } |u_j-x|> 9\delta_1\sigma^n\right\}\in \mathcal F\otimes \mathcal B(\mathbb S^1).
\end{align*}
Hence $I(U)$ is measurable and therefore $\{\overline{V_n(\omega,x)}\}_{(\omega,x)\in A_n}$ is measurable.

Finally, we prove that $\{\mathbb S^1 \setminus V_n(\omega,x)\}_{(\omega,x)\in \Omega \times \mathbb S^1}$ is a measurable family of sets. Note that $$\mathbb S^1 \setminus V_n(\omega,x) = \mathbb S^1 \setminus \left(f^{-n}_\omega \left(B_{9\delta_1}(f_\omega(x))\right) \cap B_{9\delta_1 \sigma^n}(x)\right).$$
Let $U\subset \mathbb S^1$ be an open set, and define
$$J(U) := \left\{(\omega,x)\in A_n ; U \setminus \left(f^{-n}_\omega \left(B_{9\delta_1}(f_\omega(x))\right) \cap B_{9\delta_1 \sigma^n}(x)\right)\neq \emptyset\right\}.$$

Observe that $ U \setminus \left(f^{-n}_\omega \left(B_{9\delta_1}(f_\omega(x))\right) \cap B_{9\delta_1 \sigma^n}(x)\right) \neq \emptyset $, if and only if, there exists $u\in U$ such that $|f_\omega (u) - f_\omega (x)|\geq 9\delta_1$ or $|u- x| \geq 9\delta_1 \sigma^n$.

Let $\{u_j\}_{j\mathbb N}$ be a dense sequence in $U$, this implies that
\begin{align*}
 A_n \setminus J(U) &=  \left\{(\omega,x)\in A_n ;  U \setminus \left(f^{-n}_\omega \left(B_{9\delta_1}(f_\omega(x))\right) \cap B_{9\delta_1 \sigma^n}(x)\right)= \emptyset\right\}\\
  &= \bigcup_{u \in U}\{(\omega,x)\in A_n; |f_\omega (u) - f_\omega(x)|< 9\delta_1 \text{ and } |u-x| <  9\delta_1\sigma^n\}\\
  &=  \bigcup_{j \in \mathbb N}\left\{(\omega,x)\in A_n; |f_\omega (u_j) - f_\omega(x)|<  9\delta_1 \ \text{and } |u_j-x|< 9\delta_1\sigma^n\right\}\in \mathcal F\otimes \mathcal B(\mathbb S^1).
\end{align*}
Hence $J(U)$ is measurable and therefore $\{\overline{\mathbb S^1 \setminus V_n(\omega,x)}\}_{(\omega,x)\in A_n}$ is a measurable family of sets.

\end{proof}

\begin{corolario}\label{measurablesets}
For every $n\in \mathbb N$, the families of sets:
\begin{itemize}
    \item $\left\{\overline{W_n(\omega,x)}\right\}_{(\omega,x)\in \Omega\times \mathbb S^1}$ and $\{\mathbb S^1 \setminus W_n(\omega,x)\}_{(\omega,x)\in \Omega\times \mathbb S^1}$;
    \item $\left\{\overline{\widetilde W_n(\omega,x)}\right\}_{(\omega,x)\in \Omega\times \mathbb S^1}$ and $\{\mathbb S^1\setminus \widetilde{W}_n(\omega,x)\}_{\omega,x) \in \Omega\times \mathbb S^1};$
    \item $\left\{\overline{ w_{n,\ell} (\omega,x)}\right\}_{(\omega,x)\in \Omega\times \mathbb S^1}\ \text{and }\left\{\mathbb S^1 \setminus w_{n,\ell} (\omega,x)\right\}_{(\omega,x)\in \Omega\times \mathbb S^1}\text{for every }0\leq k\leq L;$ and
    \item $\left\{\overline{\widetilde w_{n,\ell} (\omega,x)}\right\}_{(\omega,x)\in \Omega\times \mathbb S^1}\ \text{and }\left\{\mathbb S^1 \setminus \widetilde w_{n,\ell} (\omega,x)\right\}_{(\omega,x)\in \Omega\times \mathbb S^1}\text{for every }0\leq k\leq L.$
\end{itemize}
are measurable. 
\end{corolario}
\begin{proof}
This follows from the definition of the above sets and the fact that $\left\{ \overline{V_n(\omega,x)}\right\}_{(\omega,x)\in \Omega\times \mathbb S^1}$  and $\left\{ \mathbb S^1 \setminus V_n(\omega,x)\right\}_{(\omega,x)\in \Omega\times \mathbb S^1}$  are measurable.
\end{proof}

The following three propositions show that the elements of $\mathcal P_n(\omega)$ can be chosen in a measurable way.

\begin{proposicao}
The partition $\mathcal P_{1}(\omega)$ can be taken measurably, i.e. there exists a random variables $\delta,x:\Omega \to \Delta,$ such that
$$\mathcal P(\omega) = \{(x(\omega) -\delta(\omega), x(\omega) + \delta(\omega))\}_{\omega \in \Omega}. $$
\label{Giupar}
\end{proposicao}

\begin{proof}
Let us identify $\mathbb S^1$ with $[0,1)$, so that $\Delta$ is a connected interval when projected into $[0,1).$ By abuse of notation we denote $\Delta = [d_1,d_2]. $

Consider the random variable,
$$y(\omega) = \inf\left\{ y\in \Delta\cap [0,1) ; \ \inf_{q\in \mathbb Q \cap [0,1/\alpha^{1/2}] } |\d f_\omega(y+q)| \geq \alpha^{1/2}\right\}. $$
Combining Lemma \ref{LGiu} with  \eqref{defa4} we obtain $y(\omega) \leq d_2 - 1/\alpha^{1/2}.$

Let us define the function $x:\Omega\to [0,1)$,\  $x(\omega) = y(\omega) + 1/(2 \alpha^{1/2}) \in D$. Moreover, consider the function $\delta:\Omega \to [0,1),$ such that
$$\delta(\omega) = \inf\{0<r\leq 1/(2\alpha^1/2); \ m(\mathbb S^1 \setminus (f_\omega (-r+ x(\omega), x(\omega) +r ))) = 0\}. $$

Since $x,\delta:\Omega\to [0,1)$ are random variables, the theorem is proved.



\end{proof}


\begin{proposicao}
Let $n\geq N_0$. In the construction of the partition $\mathcal P_{n}(\omega),$ the compact sets $\{F_n(\omega)\}_{\omega \in \Omega}$ can be taken measurably, i.e. the following properties hold:
\begin{enumerate}
    \item For every $n\in\mathbb N$ and $r\in\mathbb N_0$ the set
    $$M_{n,r} = \{\omega \in \Omega; \# F_n(\omega) =r\} $$
    is measurable, moreover
    \item   $\{F_n(\omega)\}_{\omega \in M_{n,r}}$ is a measurable family of compact sets.
\end{enumerate}
 
\label{GiuFn}

\end{proposicao}

\begin{proof}

Once again, identifying $\mathbb S^1$ with the interval $[0,1)$. Consider the dyadic sets 
$$D_{i,j} := \left[\frac{i}{2^j}, \frac{i+1}{2^j}\right] \subset \mathbb S^1, j\in \mathbb N,\ 0\leq i \leq 2^{j} -1.$$

Since the family $\mathcal D = \{D_{i,j}\}_{j=0,0\leq i\leq 2^j - 1}^{\infty}$ is countable, we can reorder it in a way that $\mathcal D = \{D_\ell\}_{\ell \in \mathbb N}.$ Define the stopping times $i_{1,n} (\omega) :=  \min\{s\in \mathbb N;  H_n(\omega) \cap D_s \neq \emptyset\}.$ Observe that $i_{1,n}(\omega)$ is measurable, since $H_n(\omega)$ is a measurable family of compact sets. Consider the random variable $X_{1,n}(\omega) := \inf\{ [0,1)\cap H_n(\omega) \cap D_{i_{1,n}(\omega) }(\omega)\}.$

For every $k+1 \geq 1$, we recursively define stopping times
$$i_{k+1,n}(\omega) := \min\left\{s \in \mathbb N\,\left|\, \begin{array}{l} s \geq i_{k,n}(\omega),\   H_n(\omega) \cap D_i \neq \emptyset,\ \text{and}\\
\inf\{ [0,1)\cap H_n(\omega) \cap D_{s}\}\neq X_j(\omega),\ \forall \ 1\leq j\leq s.
\end{array}\right.\right\},  $$
and the measurable random variable
$$X_{k+1,n}(\omega)  = \inf\{ [0,1)\cap H_n(\omega) \cap D_{i_{k+1,n}(\omega)}\}.$$


We claim that the function
$$k_n(\omega) = \inf\left\{r\in \mathbb N, H_n(\omega) \subset \bigcup_{i=1}^{r}  W_{n}(\omega,X_{i,n}(\omega) )\right\},$$
is  measurable. In fact, recall that $H_n(\omega)$ is compact $\mathbb P$-almost surely. Observe that for every $j \in \mathbb N$
$$H_n(\omega)\setminus \bigcup_{i=0}^{j-1} W_n(\omega,X_i(\omega)) =H_n(\omega)\cap \left(\bigcap_{i=0}^{j-1} \mathbb S^1\setminus W_n(\omega,X_i(\omega)) \right),$$
is a measurable family of compact sets. Finally, we obtain that
\begin{align*}
  \{k_n >j\} &= \left\{\omega;  H_n(\omega)\setminus \bigcup_{i=0}^{j-1} W_n(\omega,X_{i,n}(\omega)) \neq \emptyset \right\}\\
  &= \left\{\omega;  \left(H_n(\omega)\setminus \bigcup_{i=0}^{j-1} W_n(\omega,X_{i,n}(\omega)) \right) \cap  \mathbb S^1 \neq \emptyset \right\}.
\end{align*}
 is measurable.

% Since for every $x,z\in \mathbb S^1$ the function 
% $$\omega \mapsto \mathrm{dist}(z, \overline{W_n(\omega,x )})$$
% is measurable. From Lemma \ref{infme}
% $$\omega \mapsto \essinf_{z \in }\mathrm{dist}(z, \overline{W_n(\omega,x )}) $$
% is measurable. Applying the lemma again
% $$\omega \mapsto  \essinf_{x_1,\ldots,x_{m-1}\in H_n(\omega)} \esssup_{z\in \overline{ B_{1/r}(H_n(\omega))}} \min_{1\leq i \leq m-1}\mathrm{dist}\left(z,\overline{W_n(\omega, x_i)}\right),$$
% is measurable. Therefore, $\{k>m\}$ is a measurable set.
 


From the above observation, we obtain that
$$F_n(\omega) := \{X_{1,n}(\omega)),\ldots, X_{k_n(\omega),n} (\omega) )\},$$
is a measurable family of compact sets.
% In the following we prove that the above set is a random compact set. We claim that
% $$\omega \mapsto \# F_n(\omega)$$
% is measurable. In fact,

% $$\{\#F_n(\omega) \geq r\} =  \bigcup_{j=r}^{\infty}\left( \{k_n = j\} \cap \bigcup_{1\leq i_1 < \ldots < i_r\leq j} \left\{ X_{i_s} \neq X_{i_\ell} \ \text{for every }1\leq i< j\leq r\  \right\}\right),$$
%  which is measurable.

% Let us restrict ourselves to the measurable set $M_{n+1,r}\{\omega; \#F_n(\omega) = m\}.$


%  Recall that $F_n(\omega) \subset H_n(\omega)$ such that
% $$H_n(\omega) \subset \bigcup_{x\in F_{N_0}(\omega)} W_n(\omega, x). $$

% Let us start taking any point $x\in H_{N_0}(\omega).$ Let us define 
% $$k_n(\omega) =\min\left\{m\in\mathbb N;\ \exists\ x_1,\ldots,x_m\ \text{such that }H_n(\omega) \subset \bigcup_{i=1}^{m} \overline{W_n(\omega, x_i)}\right\}.$$

% \begin{claim}{1}
% The function $k$ is measurable
% \end{claim}
% \begin{claimproof}
% Recall that $H_n(\omega)$ is compact $\mathbb P$-almost surely. Observe that
% \begin{align*}
%   \{k >m\} &= \left\{\omega; \mbox{for every $x_1,\ldots,x_{n-1}$ $H_n(\omega) \setminus \bigcup_{i=0}^{m-1} W_n(\omega,x_i) \neq \emptyset$} \right\}\\
%   &= \bigcup_{r=1}^{\infty} 
%   \left\{ \omega\ \middle\vert \begin{array}{l}
%     \mbox{for every $x_1,\ldots,x_{n-1} \in H_n(\omega),$ } \\
%     \overline{B_{1/r}(H_n)(\omega)} \setminus \bigcup_{i=0}^{m-1} \overline{W_n(\omega,x_i)} \neq \emptyset
%   \end{array}\right\}\\
% %   &=\left\{\omega; \mbox{for every $x_1,\ldots,x_{n-1}$ $\overline{B_{1/r}(H_n)(\omega)} \setminus \bigcup_{i=0}^{m-1} \overline{W_n(\omega,x_i)} \neq \emptyset$} \right\}\\ 
%     &=\bigcup_{r =1}^{\infty} \left\{\omega; \bigcup_{x_1,\ldots,x_{m-1}\in H_n(\omega)}\left\{ \begin{array}{l} \exists z \in \overline{B_{1/r}(H_n(\omega))} \text{ such that}  \\
%     \min_{1\leq i \leq m-1} \mathrm{dist}(z, \overline{W_n(\omega,x_i))}
%   \end{array}\right\} \right\}\\
%     % &=\left\{\omega; \bigcup_{x_1,\ldots,x_{m-1}\in H_n(\omega)}\left\{ \exists z \in H_n(\omega) \text{such that} \min_{1\leq i \leq m-1}\mathrm{dist}\left(z,W_n(\omega, x_i)\right)>0 \right\} \neq \emptyset\right\}\\
%     &=\bigcup_{r=1}^{\infty}\left\{\omega;\essinf_{x_1,\ldots,x_{m-1}\in H_n(\omega)} \esssup_{z\in \overline{ B_{1/r}(H_n(\omega))}}\min_{1\leq i \leq m-1}\mathrm{dist}\left(z,\overline{W_n(\omega, x_i)}\right)>0 \right\} 
% \end{align*}

% Since for every $x,z\in \mathbb S^1$ the function 
% $$\omega \mapsto \mathrm{dist}(z, \overline{W_n(\omega,x )})$$
% is measurable. From Lemma \ref{infme}
% $$\omega \mapsto \essinf_{z \in }\mathrm{dist}(z, \overline{W_n(\omega,x )}) $$
% is measurable. Applying the lemma again
% $$\omega \mapsto  \essinf_{x_1,\ldots,x_{m-1}\in H_n(\omega)} \esssup_{z\in \overline{ B_{1/r}(H_n(\omega))}} \min_{1\leq i \leq m-1}\mathrm{dist}\left(z,\overline{W_n(\omega, x_i)}\right),$$
% is measurable. Therefore, $\{k>m\}$ is a measurable set.



% \end{claimproof}

% Let us consider the sets 
% $$M_{n+1,r} (\omega) = \{\omega ; k_n(\omega) = m\}, $$
% it is clear that
% $$\bigcup_{m=1}^{\infty} M_{n+1,r} = \{\text{domain of }k_n\}. $$

% Consider the functions
% \begin{align*}
%     G: M_{n+1,r} \times (\mathbb S^1)^m \to \mathbb R\\
%     (\omega, (x_1,\ldots, x_{m})&\to m\left(H_n(\omega)\setminus \bigcup_{i=0}^{m-1} W_n(\omega,x_i) \right) + \min\left\{1, \#\left( H_n(\omega)\setminus \bigcup_{i=0}^{m-1} W_n(\omega,x_i)\right)\right\}
% \end{align*}

% From \cite[Theorem 2.27 (i)]{molchanov2005theory} the random set
% $$\widetilde{F}_{n+1,r}(\omega):=\{(x_1,\ldots,x_{m}) \in (S^{1})^m; \omega\in M_{n+1,r},\ x_i\in H_n(\omega), \forall\ 1\leq i\leq m, \text{ and }G(\omega, (x_1,\ldots,x_{m-1}) = 0\} $$
% is a random set closed (and therefore compact).

% From \cite[Proposition 4.6]{vianaLya} there exists a measurable function map $\sigma_{n+1,r}: M_{n+1,r} \to (S^1)^m$ such that $\sigma_{n+1,r}(\omega) \in \widetilde M_{n+1,r}.$

% Defining 
% $$F_n(\omega) = \{\sigma_{n+1,r}(\omega)\}\ \text{if }\omega \in M_{n+1,r} $$

\end{proof}




\begin{proposicao} \label{measurablepart}
For every $n\in \mathbb N$. The partition $\mathcal P_{n}(\omega)$ can be taken measurably, i.e. the following properties are fulfilled
\begin{enumerate}
    \item The set $\widetilde{M}_{n,r}(\omega) = \{\omega ; \#\mathcal P_{n}(\omega) = r \} $ is measurable
    \item Given $\omega \in \widetilde{M}_{n,r}$. There exists measurable function $\omega \mapsto (x_i(\omega), \ell_i(\omega))$ such that  $$\mathcal P_{n}(\omega) = \{ w_{n,\ell_1(\omega)}(\omega,x_1(\omega)) ,\ldots, w_{n,\ell_{m}(\omega)}(\omega,x_m(\omega))\},$$ and
    $$\left\{\overline{w_{n,\ell_i(\omega)}(\omega,x_i(\omega))} \right\}_{\omega \in \widetilde{M}_{n+1,r}} \text{ is measurable } \text{for every }1\leq i \leq r.$$
\end{enumerate}
\end{proposicao}
\begin{proof}
 We prove the result by induction on $n$. By Proposition \ref{Giupar}, the claim is true for every $n =1,\ldots, N_0-1.$ Now, suppose $n \geq N_0-1$, $(1)$ and $(2)$ . We show that the result also holds for $n+1.$


Observe that
$$ \omega \mapsto \widehat{A}(\omega) = \overline{ \bigcup_{k=1}^n \bigcup_{w\in \mathcal P_k(\omega)} A(\omega, w)},$$
is a measurable family of compact sets. 

Let us restrict ourselves to $ \omega \in M_{n+1,r} = \{\omega, \# F_{n+1}(\omega) = r\}$. Consider the set  $$G_{n+1,r} = \{(\omega,y_1,\ldots,y_r); \omega\in M_{n+1,j},\ y_i\in F_{n+1}(\omega)\}, $$
since $\{F_n(\omega)\}_{\omega\in \Omega}$ is a measurable family of compact sets then, from Theorem \ref{eqv}, $G_{n+1,r}$ is a measurable set.


Note that
\begin{align*}
    \widetilde{G}: G_{n+1,r}\times \{1,\ldots,L\}^r &\to \{1,2,\ldots, r\}\\
    (\omega,(y_1,\ldots,y_r),(\ell_1,\ldots,\ell_r))&\mapsto \sum_{j=1}^{r} \left\lfloor \frac{ m\left(\widehat{A}(\omega) \cup \bigcup_{i=1}^{j} \overline{w_{N_0,\ell_i}(\omega, y_i)}\right) }{  \displaystyle m(\widehat{A}(\omega))+ \sum_{i=1}^{j} m\left(\overline{w_{N_0, \ell_i }(\omega,y_r) }\right)  }\right\rfloor
\end{align*}
is a measurable function. It is readily verified that $\widetilde{G}(\omega,(y_1,\ldots,y_n), (\ell_1,\ldots,\ell_r)) = s$ if and only if:
\begin{itemize}
    \item[$(i)$] $w_{n+1,\ell_i}(\omega, y_i) \cap w_{n+1,\ell_j}(\omega, y_j) = \emptyset, \ \text{for every}\ 1\leq i<j\leq s;$
    \item[$(ii)$] $ A(\omega)\cap w_{n+1,\ell_j}(\omega, y_j) = \emptyset, \ \text{for every}\ 1\leq i<j\leq s;$ and
\item[$(iii)$] $s$ is the largest natural number between $1$ and $m,$ such that $(i)$ and $(ii)$ holds. 

\end{itemize}

% $$w_{n+1,\ell_i}(\omega, y_i) \cap w_{n+1,\ell_j}(\omega, y_j) = \emptyset, \ \forall\ 1\leq i<j\leq
% s.$$
% and 
% $$ A(\omega)\cap w_{n+1,\ell_j}(\omega, y_j) = \emptyset, \ \forall\ 1\leq i<j\leq
% s.$$

Define $G_{n+1,r}^r := \widetilde{G}^{-1}(\{r\}) \subset M_{n+1,r} \times \{1,\ldots, L\}^{r} \subset \Omega \times (\mathbb S^1)^r\times \{1,\ldots, L\}^{r}.$ Observe that $G_{n+1,r}^r$ is measurable. This implies that
$$K_{n+1,r,r}({\omega}):= \{(y, \ell ) \in F_{n+1}(\omega)^r\times \{1,\ldots, L\}^r; (\omega,y, \ell)) \in G_{n+1,r}^r\}\subset F(\omega)^r\times\{1,\ldots,L\}^{r}, $$
is a measurable family of compact sets. Therefore $ L_{n+1, r, r} = \{\omega \in M_{n+1,r};\ K_{n+1,r,r}(\omega) = \emptyset\}$ is a measurable set.

From the above construction, given $\omega \in M_{n+1,r} \setminus L_{n+1, r, r}$, the function
$$(x,\ell)\in F_{n+1}(\omega)^r\times \{1,\ldots, L\}^{r} \mapsto \widetilde G(\omega, x,\ell), $$
attains its maximum if and only if $(x,\ell) \in K_{n+1,r,r}(\omega).$

Now we repeat the above process considering the set
$$G_{n+1,r}^{r-1} := \{(\omega,y); \omega\in L_{n+1,r,r}\ \text{and }y\in F_{n+1}(\omega)^r\}. $$
Observe that $ 0\leq \left.\widetilde G\right|_{G_{n+1,r}^{r-1}\times \{1,\ldots, L\}^{r-1}} \leq r-1.$ Therefore we can define the measurable set
$$G_{n+1,r,r-1} := \left(\left.\widetilde G\right|_{G_{n+1,r}^{r-1}\times \{1,\ldots, L\}^{r}}\right)^{-1}(\{r-1\}). $$
This implies that 
$$K_{n+1,r,r-1}(\omega) := \{(y,\ell) \in F_{n+1}(\omega)^r\times \{1,\ldots, L\}^{r}; (\omega,y,\ell) \in G_{n+1,r}^{r-1}\},$$
is a measurable family of compact sets. As before, we obtain that $L_{n+1, r, r-1} = \{\omega \in L_{n+1, r, r}; K_{n+1,r,r-1}(\omega) = \emptyset\}, $
is a measurable set.

From the above construction, given $\omega \in L_{n+1, r, r} \setminus L_{n+1, r, r-1}$, the function
$$(x,\ell)\in F(\omega)^r\times \{1,\ldots, L\}^{r} \mapsto \widetilde G(\omega, x,\ell), $$
attains its maximum if and only if $(x,\ell) \in K_{n+1,r,r-1}(\omega).$

Finally, we define $G_{n+1,r}^{r-2} = \{(\omega,y); \omega \in L_{n+1, r, r-1}\ \text{and } y\in F_{N_0}(\omega)^m\},$ and repeat the process $r-3$ times.

At the end of this procedure we obtain a $\mathbb P$-$\mathrm{mod}\ 0$ measurable decomposition

$$M_{n+1,r} = \bigsqcup_{i=1}^{r} \left(L_{i+1}\setminus L_{i}\right),$$
where $L_{r+1} = M_{n+1,r}$.

Consider the measurable family of compact sets
$$\widehat{G}_{n+1,r} (\omega) := \pi_{(\mathbb S^1)^i} \times \pi_{ \{1,\ldots, L\}^i}\left( K_{n+1, r , i}(\omega)\right) \ \text{if }\omega\in L_{n+1, r , i+1} \setminus L_{n+1,r,i}.$$
where $\pi_{(\mathbb S^1)^i} \times \pi_{ \{1,\ldots, L\}^i} ((y_1,\ldots,y_m),(\ell_1,\ldots,\ell_m)) = ((y_1,\ldots,y_i), (\ell_1,\ldots,\ell_i)).$ From \cite[Proposition 4.6]{vianaLya} there exists a measurable function map $$\sigma_{n+1,r,i}: L_{n+1,r,i+1}\setminus L_{n+1,r,i} \to (\mathbb S^1)^i\times \{1,\ldots, L\}^{i}$$ such that $\sigma_{n+1,r,i}(\omega) \in  \widehat{G}_{n+1,r} (\omega).$

Now, we show that $\mathcal P_n(\omega)$ satisfies $(1)$ and $(2)$. In order to see $(1)$, observe that 
$$\#\{\omega\in \Omega;\mathcal P_{n+1}(\omega) =r \} = \bigcup_{j=0}^{\infty} \left(L_{n+1, j ,r+1}\setminus L_{n+1, j ,r} \right),$$
which is measurable. Furthermore, item $(2)$ follows directly from the construction of the function $\sigma_{n,r, i}$ and Corollary \ref{measurablesets}.


\end{proof}

As a corollary of the above three propositions, we obtain that the partition $\mathcal P(\omega)$ of $\Delta$ can be modified such that the function $R$ defined at the beginning of this subsection is measurable.

\begin{corolario}\label{defR}
Let $\mathcal P(\omega)$ be a partition of the set $\Delta$ as constructed in subsection \ref{pathwiseconstr}, such that the conclusions presented in Proposition \ref{measurablepart} hold. Then, the return time function  \begin{align*}
    R:\Omega \times \Delta &\to \mathbb N\\
    (\omega,x)&\to n+\ell\ \text{if }x\in\omega_{n,\ell}\in\mathcal P(\omega),
\end{align*} is measurable. 
\end{corolario}
\begin{proof}
Recall from Proposition \ref{measurablepart} that
\begin{enumerate}
    \item the set $\widetilde{M}_{n+1,r}(\omega) = \{\omega ; \#\mathcal P_{n}(\omega) = r \} $ is measurable; and
    \item Given $\omega \in \widetilde{M}_{n,r}$. There exists measurable function $\omega \mapsto (x_i(\omega), \ell_i(\omega))$ such that  $$\mathcal P_{n}(\omega) = \{ w_{n,\ell_1(\omega)}(\omega,x_1(\omega)) ,\ldots, w_{n,\ell_{r}(\omega)}(\omega,x_r(\omega))\},$$ and
    $$\left\{\overline{w_{n,\ell_i(\omega)}(\omega,x_i(\omega))} \right\}_{\omega \in \widetilde{M}_{n,r}} \text{ is measurable } \text{for every }1\leq i \leq m.$$
\end{enumerate}

Observe that $\#\{\overline{w_{n,\ell_i(\omega)}(\omega,x_i(\omega))} \setminus {w_{n,\ell_i(\omega)}(\omega,x_i(\omega))} \} \leq 2.$ Therefore for every $k \in \mathbb N$
$$\{R=k\}= \bigcup_{n=1}^{k}\bigcup_{r=1}^\infty \bigcup_{i=1}^{r}\left\{(\omega,x); \omega \in \widetilde{M}_{n,r}, \ell_i(\omega) = k - n, x\in \overline{w_{n,\ell_i(\omega)}(\omega, x_{i}(\omega) )}  \right\}\ \left( \mathrm{mod }\ \mathbb P\otimes m\right).$$

Since $(\Omega\times \mathbb S^1,\mathbb P \otimes m)$ 
 is a complete probability space, we obtain that $R$ is a measurable function.
\end{proof}

\subsection{Random Young tower}
\label{proofB}
In this subsection, we prove Theorem \ref{TheoremB}. Namely, we show that for given $c\in(0,1)$, $\alpha>\alpha_4$ (see \ref{defa4}) and $\varepsilon$, the random dynamical system $f_\omega$ admits a random Young tower.

From now on, we fix the $m$-mod $0$ partition $\mathcal P(\omega)$ of $\Delta$ satisfying Proposition \ref{measurablepart} and define the return function $R$ as is Corollary \ref{defR}.  We start proving the following lemma.
\begin{lema} \label{fr}
There are $C>0$ and $0<\beta <1$ arbitrarily small such that, for all $n\geq 1$ and $x,y \in w_{n,\ell} \in \mathcal P_n(\omega)$
\begin{enumerate}
    \item $|x-y|\leq \beta |f^{R}_\omega( x) - f^{R}_\omega(y) |$;
    \item $|f^j_\omega(x) - f^j_\omega(y)| \leq C|f^R_\omega(x) - f^R_\omega(y)|,\ \forall 0\leq j \leq R(\omega,x) = R(\omega,y);$ and
    \item $\displaystyle \log\frac{|\d f_\omega^R (x)|}{|\d f_\omega^R (y)|} \leq C |f^R_\omega (x) - f_\omega^R(y)|.$
\end{enumerate}
\label{panpilona}
\end{lema}

\begin{proof}
 First, observe that if $n=1$, then $R(\omega,x) = R(\omega,y) = 1$, and the result follows directly from Step \ref{step1} on  Section \ref{pathwiseconstr} and Proposition \ref{giucor}. Recall that $\mathcal P_n(\omega) = \emptyset,$ for every $1<n< N_0.$

Now, suppose that $n\geq N_0,$ $w_{n,\ell} \in \mathcal P_n(\omega),$ we have that $w_{n,\ell} \subset V_n(\omega,z)$ for some $z \in H_n(\omega)$. Moreover $f^{n+\ell}_\omega$ maps $w_{n,\ell}$ diffeomorphically to $(x_0-\delta_0,x_1-\delta_0).$ From Lemma \ref{i1i2i3} ($I_2$ and $I_3$) we obtain that
$$|x-y| \leq \sigma^n |f^n_\omega(x) - f^n_\omega(y)| \leq C_1 \sigma^n | f^{n+\ell}_\omega(x) - f^{n+\ell}_\omega(y)|.$$
Setting $\beta = C_1\sigma^{N_0} <1$, item $1$ is verified.

To prove item $(2)$, we separate it into two cases:
\begin{enumerate}
    \item[$(a)$] $n\leq j \leq n+\ell$; and
    \item[$(b)$] $0\leq j < n$.
\end{enumerate}
In case $(a),$ we obtain from Lemma \ref{i1i2i3}  ($I_3$) that
$$|f^j_\omega(x) - f_\omega^{j}(y)| \leq C_1 |f^{n+\ell}_\omega (x) - f^{n+\ell}_\omega (y)|.$$

On the other hand, if $(b)$ holds, from Lemma \ref{i1i2i3}  ($I_2$ and $I_3$) we obtain that for every $x,y\in w_{n,\ell},$
$$|f^j_\omega(x) - f^j_\omega(y)| \leq \sigma^{n-j} |f_\omega^n(x) - f^n_\omega(y)| \leq C_1 \sigma^{n-j} |f^{n+\ell}_\omega (x) - f^{n+\ell}_\omega(y)|,$$
in both cases, we obtain the conclusion setting $C= C_1.$

The last one follows from Lemma \ref{CentralLema} $(I2)$ and $(I3)$ with
$$\displaystyle \log\frac{|\d f_\omega^R (x)|}{|\d f_\omega^R (y)|}\leq  \log\frac{|\d f_{\theta^n \omega}^\ell (f^n_\omega (x) )|}{|\d f_{\theta^n \omega}^\ell (f^n_\omega (y) )|} +\log\frac{|\d f^n_{\omega} (x )|}{|\d f^n_{\omega}(y)|} .$$

% The proof is exactly the same as the classical case. The idea is to use the definition of the partition and the bounds of $I_2$ and $I_3$.
\end{proof}


Now, we prove Theorem \ref{TheoremB}.\\

\begin{theoremproofB}
    
    Fix $c\in (0,1)$. From the definitions provided in Section \ref{randomtowers}, we obtain that for every $\alpha > 
\alpha_4$ and $\varepsilon>\alpha^{c-1},$ $f_\omega$ admits a random tower with partition $\mathcal P(\omega)$ and return time $R$. We apply the construction presented in Section \ref{randomtowers} setting $g_\omega$ and $\rho$ as, respectively, $f_\omega$ and $m$.

We divide the proof into three steps.

\begin{step}{1} We show that $(P1)$, $(P2),$ $(P3)$ and $(P4)$ in Section \ref{randomtowers} hold.
    
\end{step}

(P1): Observe that (P1) follows directly from the definition of the sets $w_{n,\ell}(\omega,x)$ provided at the beginning of section \ref{pathwiseconstr}. 

(P2):  Let $z_1,z_2 \in \tri$. Assume that $s(\omega,z_1,z_2) >0,$ otherwise, there is nothing to prove. From Lemma \ref{panpilona} ($1$). 
\begin{align*}
    \left|F_\omega^{\widehat{ R}_1} (z_1) - F_\omega^{\widehat{ R}_1} (z_2) \right| &\leq \beta \left|F^{\widehat{ R}_2}_\omega(z_1) - F_\omega^{\widehat{ R}_2}(z_2)\right|\leq \ldots \leq \mathrm{diam}(\Delta) \beta^{s_\omega(z_1,z_2) -1}\\ 
    &=\mathrm{diam}(\Delta_0) \beta^{s \left( \theta^{\widehat{ R}_1}\omega, F_\omega^{\widehat{ R}_1} (z_1), F_\omega^{\widehat{ R}_1} (z_2) \right)} = \mathrm{diam}(\Delta) \beta^{s\left(F^{\widehat{R}}(\omega,x) , F^{\widehat{R}}(\omega,y)\right)}.
\end{align*}
Using, Lemma \ref{panpilona} ($3$)
$$\log \frac{|\d F^{\widehat R}_\omega(z_1)|}{|\d F^{\widehat R}_\omega(z_2)|}\leq C |F^{\widehat R}_\omega(z_1) - F^{\widehat R}_\omega(z_2)| \leq \mathrm{diam}(\Delta_0)C  \beta^{s\left(F^{\widehat{R}}(\omega,x) , F^{\widehat{R}}(\omega,y)\right)}.$$

(P3): It is a standard consequence of  Lemma \ref{panpilona} (1) (for more details see \cite[Lemma 3.2]{Alves}).

(P4): Observe that from the construction of  $\mathcal P_1(\omega) \subset \mathcal P(\omega)$, in Step \ref{step1} of Section \ref{pathwiseconstr} and Proposition \ref{Giupar} that for $\mathbb P$-almost every $\omega\in\Omega,$
$$m(x \in \Delta; R(\omega,x) =1\} \geq \frac{\mathrm{diam}(\Delta)}{\alpha \|\xi'\|_\infty}>0.   $$

\begin{step}{2} We show that there exists $C(\omega)\in L^2(\Omega,\mathbb P)$ and $\gamma >0$ such that for $\mathbb P$-almost every $\omega\in\Omega$
$$m( \{R_\omega > n\}) \leq C(\omega) e^{-\gamma n},$$
where $R_\omega(\cdot) := R(\omega,\cdot).$
\end{step}

Let $\theta_1$ be as in \ref{CentralLema}, and define 
$$h_{\theta_1}(\omega, x ) := \min\left\{n\in\mathbb N; \frac{\#Y_i(\omega,x)}{i} \geq \theta_1,\ \text{for every }i\geq n\right\}.$$

From the same computation provided in \cite[Chapter 5.3.2]{Alves} we are able to obtain that for $\mathbb P$-almost every $\omega\in \Omega$ and $n\geq \mathbb N,$ there exists a set $E_n(\omega)\subset \Delta,$ such that
\begin{align}
    \{R_\omega > n+ L \}\subset \{h_{\theta_1} > n\} \cup  E_n(\omega), \label{Rtail}
\end{align} 
and $m(E_n(\omega)) \leq K_0 e^{-\kappa n},$ for some constants $K_0,\kappa >0$ that do not depend on $(\omega,n)\in \Omega\times \mathbb N$. We mention that $K_0$ and $\kappa$ only depend on the constants of Theorem \ref{i1i2i3} and Lemma \ref{fr}. 

    From \eqref{Rtail}, it is enough to estimate
$$m(\{h_{\theta_1}(\omega,\cdot) > n\}).$$
Recall $Y_n(\omega,x)$ (Definition \ref{YoungTijmen}),
$$h_{\theta_1}(\omega, x ) = \min\left\{n; \frac{\#Y_i(\omega,x)}{i} \geq \theta,\ \text{for every }i\geq n\right\}.$$


Observe that
\begin{align*}
    \left\{(\omega,x) \in \Omega\times \mathbb S^1; h_{\theta_1}(\omega,x)> n\right\} &=\left\{(\omega,x); \frac{1}{i}\#\{1\leq j\leq i: x\in H_i(\omega)\} <\theta_1 \ \text{for some }i >n\right\} \\
    &=\left\{(\omega,x); \frac{\#Y_i(\omega,x)}{i} <\theta_1 \ \text{for some }i >n\right\}\\
    &\subset \bigcup_{i=n+1}^{\infty} \left\{(\omega,x); \frac{\#Y_i(\omega,x)}{i}<\theta_1\right\}.
  %   &\subset \left\{(\omega,x)\in \Omega\times \mathbb S^1;  \begin{array}{l}
  %   \sum_{i=0}^{j-1} \\
  %   e, F, g
  % \end{array}\right\}
\end{align*}

From the proof of Proposition \ref{youngprop}, we obtain that there exists $K_1,\kappa_1>0$ such that
$$\sup_{x\in\mathbb S^1}\mathbb P[\#Y_i(\cdot,x) < \theta_1 i]  < K_1 e^{-\kappa_1 i}.$$

Therefore, for every $x\in\mathbb S^1,$
$$ \mathbb P\left[ h_{\theta_1}(\cdot ,x)> n\right] \leq \sum_{i=n+1}^{\infty }K_{1}e^{-\kappa_1 i} \leq  \widetilde{K}_1 e^{-\kappa_1 n}.$$

% Observe that
% $$\mathbb P\otimes m \left\{h_{\theta_1} >n\right\} \leq  \widetilde{K}_1 e^{-\kappa n}.$$

Observe that for every $\gamma \in (0,\kappa_1)$,
\begin{align}
\mathbb P\left[ m\{h_{\theta_1}(\omega,\cdot)>j\}> \widetilde{K}_1 e^{-\gamma j} \right] &\leq  \frac{1}{\widetilde K_1} e^{\gamma j } \mathbb E \left[m\{h_{\theta_1}(\omega,\cdot)>j\} \right]\nonumber\\
&\leq e^{ -(\kappa_1 -\gamma) j}.\label{gl}
\end{align}

% From the

% \begin{align*}
%     \mathbb P[n(\omega) > n_0] &\leq \frac{1}{n_0} \mathbb E [n(\cdot)]\\
%     &\leq 
% \end{align*}

From the Borel-Cantelli lemma, we obtain that the random variable,
$$n(\omega):=\max\left\{ j\in\mathbb N;\  m\{h_{\theta_1}(\omega,\cdot)>j\}> \widetilde{K}_1 e^{-\gamma j}\right\},$$
is $\mathbb P$-a.s. finite. Moreover, \eqref{gl} implies that
$$ \mathbb P[n(\omega) > k] \leq \sum_{i=k+1}^{\infty} \mathbb P\left[ m\{h_{\theta_1}(\omega,\cdot)>i\}> \widetilde{K}_1 e^{\gamma i } \right] \leq \frac{1}{1-e^{-(\kappa_1 - \gamma)}}e^{- (\kappa_1 - \gamma)n}.$$

Observe that for $\mathbb P$-almost every $\omega\in\Omega,$
\begin{align*}
    m\{h_{\theta_1}(\omega,\cdot) > n\} &\leq \widetilde K_1 e^{\gamma n(\omega) }e^{-\gamma n },
\end{align*}

Setting $0< \gamma < \kappa_1/3$ and defining $C(\omega) := e^{\gamma n(\omega) }$,  we have that $C(\omega)\in L^2(\Omega)$ since
$$\int_{\Omega} C(\omega)^2\mathbb P[\d \omega] \leq  \sum_{i=0}^\infty \frac{e^{-(\kappa_1 - \gamma)i}}{1-e^{-(\kappa_1 - \gamma)}}e^{- (\kappa_1 - 3\gamma)i} <  \infty.$$

Finally, from \eqref{Rtail}  we obtain that
$$m\{R_\omega > n +L\} \leq C(\omega)e^{-\gamma n} + K_0 e^{-\kappa_0 n}, \ $$
which completes the proof of Step 2.
\begin{step}{3} We show (P5) in Section \ref{TheoremB} holds, and therefore, we finish the proof of the theorem.
\end{step}
Observe that from the construction of the partition $\mathcal P(\omega)$ in Sections \ref{pathwiseconstr} and \ref{measurabletower}, and the definition of the return function $R$ it is evident that $R$ is a stopping time. Finally, from Step 2, we obtain that
     $$ \int_{\Omega \times \Delta} R(\omega,x) \mathbb P \otimes m (\d \omega, \d x)\leq \mathbb E \left[\sum_{i=0}^{\infty} n\, m(R_\omega \geq n)\right] \leq \mathbb E[C] \frac{1}{1- e^{\gamma}}<\infty.$$

This completes the proof of Step 3 and consequently proves Theorem \ref{TheoremB}.
\end{theoremproofB}


\section{Quenched decay of correlations}
\label{proofA}
This section aims to prove Theorem \ref{decay}. For a fixed constant $c\in (0,1)$, we have established that for $\alpha >0$ sufficiently large and $\varepsilon>\alpha^{-1+c}$, the random dynamical system $f_\omega^n$ defined in Section \ref{Model}  admits a random Young tower with partition $\mathcal P(\omega)$ and return function $R$. Furthermore, we have shown that the probability of $\mathbb P\otimes m (R> n)$  converges exponentially fast to zero as $n$ approaches infinity. It is worth mentioning that the main technical aspects have been established. The forthcoming task involves linking the random Young tower properties with the original system.

We start by proving that the tower map $F:\tri \to \tri$ admits an invariant measure absolutely continuous to $m_\omega(\d x) \mathbb P(\d \omega)$ with marginal $\mathbb P$. We prove this result in Appendix \ref{AppendixB} to not break the text flow.

\begin{proposicao}\label{invmes}
Let $\alpha,\varepsilon >0$ such that Theorem \ref{TheoremB} holds. Then the map $F:\tri \to \tri$ defined in Section \ref{randomtowers}  admits a unique invariant measure $\widetilde{\mu} = \widetilde{\mu}_\omega(\d x) \mathbb P(\d \omega)$ such that $\widetilde{\mu}_\omega \ll m_\omega$ and $\widetilde\mu_\omega ( \d x) /m_\omega(\d x) \in \mathcal F_\beta$ for $\mathbb P$-almost every $\omega\in \Omega$,  where $\beta$ is defined as in Proposition \ref{fr} and $$\mathcal F_\beta := \{\varphi:\mathbbold{\Delta} \to \mathbb R;\ \exists\ C \in L^{\infty}(\Omega,\mathbb P) \text{ s.t. } |\varphi_\omega(x) - \varphi_\omega(y)|\leq C(\omega) \beta^{s_\omega(x,y)}, \ \text{for all }x,y\in \Delta\}.$$

\end{proposicao}

Recall the skew-product map $\Theta$ in \eqref{skewproduct}. Observe that the map 
\begin{align*}
   \pi: \tri &\to \Omega\times\mathbb S^1\\
   (\omega,(x,\ell))&\mapsto (\omega,f_{\theta^{-\ell}\omega }^\ell (x)),
\end{align*}
satisfies $\pi \circ F = \Theta \circ \pi$. Since $\pi$ is a semi-conjugacy between the maps $F:\tri \to \tri$ and ${\Theta: \Omega \times \mathbb S^1\to \Omega \times \mathbb S^1}$, when we consider the $F$-invariant measure $\widetilde{\mu}$ described in Proposition \ref{invmes}, we obtain that there exists a family of measures $\{\mu_\omega(\d x) \}_{\omega \in\Omega}$ on $\mathbb S^1$ such that
\begin{align}
    \mu(\d \omega,\d x) := (\pi_* \widetilde{\mu})(\d \omega,\d x)  = \mu_\omega(\d x) \mathbb P(\d \omega) \label{Thetainvmes}
\end{align}
is a $\Theta$-invariant measure. Observe that from the construction of $\pi$ we obtain that
$$\mu_\omega(\d x ) = \sum_{\ell =0}^{\infty} \widetilde \mu_{\theta^{-\ell}\omega}\left( ( f^{-\ell}_{\theta^{-\ell} \omega} (\d x) \cap \{R_{\theta^{-\ell} \omega }> \ell\}) \times\{0\}\right)\ \text{for }\mathbb P\text{-almost every }\omega\in\Omega.  $$
From the partition $\mathcal P(\omega)$ defined in Section \ref{pathwiseconstr} and Proposition \ref{Giupar}, and the regularity of the distribution of $\widetilde{\mu}$ over $m_\omega(\d x) \mathbb P(\d \omega),$ given in Proposition \ref{invariantdreams}, it is readily verified that $\mu_\omega(\d x) \ll m(\d x)$ for $\mathbb P$-almost every $\omega\in\Omega.$ 

In the interest of conciseness, we provide a condensed version of \cite[Theorems 1.2.5 and 1.2.6.]{Du} despite being less general than the original theorems presented in \ref{Du}. The version below is enough to show Theorem \ref{decay}.

\begin{teorema}[{\cite[Theorem 1.2.5 and Theorem 1.2.6.]{Du}}]
Let $m$ be the Lebesgue measure on $\mathbb S^1,$ $\Omega$ be defined as in Section \ref{Model} and  $\{g_\omega: \mathbb S^1\to \mathbb S^1\}_{\omega\in \Omega}$ be a family of maps depending only on the $0^{\mathrm{th}}$ coordinate of $\omega$. Suppose that $g_\omega$ admits a random Young tower on $\Delta \subset \mathbb S^1$. Then there exists a unique exact absolutely continuous invariant probability measure $\nu(\d x, \d \omega) =\nu_\omega(\d x)\mathbb P(\d \omega)$ on $(\Omega\times M, \mathcal F\otimes \mathcal B(M) ),$ such that $\nu_\omega \ll  m$ for $\mathbb P$-almost every $\omega\in\Omega$.

Moreover, let $R:\Omega \times \Delta \to \mathbb N\cup \{0\}$ be the return time coming from the random Young tower structure of $g_\omega$ on $\Delta$, if there exists $K_0,\gamma_0>0$ such that $$\mathbb P\otimes m(R>n) \leq K_0 e^{-\gamma_0 n},$$
then there exists $C(\omega)\in L^2(\Omega)$ and $\gamma>0$ such that for every bounded measurable function $\phi:\mathbb S^1\to \mathbb R$ and Lipschitz function $\psi:\mathbb S^1\to \mathbb R$ 
$$ \left|\int_{\mathbb S^1}\varphi \circ f_\omega^n \cdot \psi\, \d m - \int_{\mathbb S^1}\varphi \, \d \nu_{\theta^n \omega} \int_{\mathbb S^1} \psi\, \d m\right| \leq C(\omega) e^{-\gamma n}\|\varphi\|_{\infty} \|\psi\|_{\mathrm{Lip}},$$
and
$$ \left|\int_{\mathbb S^1}\varphi \circ f_{\theta^{-n}\omega}^n \cdot \psi\, \d m - \int_{\mathbb S^1}\varphi\, \d \nu_{\omega} \int_{\mathbb S^1} \psi\, \d m\right| \leq C(\omega) e^{-\gamma n} \|\varphi\|_{\infty} \|\psi\|_{\mathrm{Lip}}.$$


\label{Du}
\end{teorema}

Now we prove Theorem \ref{decay}.\\
\begin{theoremproofA}
    The result follows directly when combining Theorems \ref{TheoremB} and Theorem \ref{Du}. We mention that when applying Theorem \ref{Du} to the random dynamical system $f_\omega^n $, it is clear that $g_\omega = f_\omega$ and $\nu= \mu$ (see \eqref{Thetainvmes}).
\end{theoremproofA}

\section*{Acknowledgments}

The authors wish to thank Alex Blumenthal for proposing the problem, and Jeroen S. W. Lamb,  Martin Rasmussen and Dmitry Turaev for the useful suggestions. MCs research has been supported by an Imperial College Presidents PhD scholarship. MC and GT are also supported by the EPSRC Centre for Doctoral Training in Mathematics of Random Systems: Analysis, Modelling and Simulation (EP/S023925/1).
\appendix

\section{Proof of Proposition \ref{LHiperbolicTijmens}}
\label{AppendixA}

% In this appendix, we prove Proposition \ref{LHiperbolicTijmens}.

% \begin{proof}[Proof of Proposition \ref{LHiperbolicTijmens}]
% Let $c>0$ be fixed, so that $\varepsilon \ge \alpha^{c-1}$. Choose $\alpha_0>1$ sufficiently large such that for every $\alpha > \alpha_0,$ such that the set $G(\alpha):=\{x\in\mathbb S^1;\ \|d f(x)\|> \alpha^{c/2}\},$ satisfies the existence of an interval $I\subset G$ such that $f(I) = \mathbb S^1$.

% Define $s = s(\alpha):= m(G(\alpha)).$ Consider $C = \{x\in\mathbb S^1;\ |\d f(x)|\leq 1\}.$ From Lemma \ref{LGiu} and \eqref{LGiu2}, we can choose $\alpha_1 > \alpha_0$, such that for every $\alpha>\alpha_1$
% $$  h = \frac{1}{2}  < 1 + \frac{2\alpha^{1-c }}{\log(\alpha^{c/2})} \int_C \log |\d f(x)| \d x\ \text{and}\  \frac{1-s(\alpha)}{h} < \frac{1}{\alpha^{1-c}}.$$

% For every $\sigma^2, r>0$, $x\in \mathbb N$ and $n\in \mathbb N$ define
% \begin{align*}
% A(n,x,r)&:= \left\{\omega \in \Omega;\sum_{i=0}^{n-1}\log(\mathrm{dist}_{r}(f^i_{\omega}(x),\mathscr{C}_{\theta^j \omega}))<r n\right\},\\
% B(n,x,\sigma^2)&:= \left\{\omega \in \Omega;\sum_{i=0}^{n-1}\log|\d f_{\theta^i \omega}(f^i_{\omega}(x))|\le \sigma^2 n \right\}.
% \end{align*}


% From the above estimation in the first and second paragraphs, we can apply Theorem $7.1$ and Proposition $7.2$ combined with Remark $7.6$ in {\color{red} Giuseppe's paper} to obtain that there exists $r$ and $\sigma^2$ small enough such that, for every $\alpha > \alpha_1,$
% \begin{align}
% \sup_{x \in \mathbb{S}^1}\mathcal{P}(x,A(n,x,r) \cup B(n,x,\sigma^2))\xrightarrow[]{n \to \infty} 0\label{Giugiuexp1}
% \end{align}
%  exponentially fast. 

%  where for any $x\in \mathbb S^1$ and $n\in\mathbb N$ we define
% \begin{align*}
% A(n,x)&:= \left\{\omega \in \Omega;\sum_{i=0}^{n-1}\log(\mathrm{dist}_{r}(g^i_{\omega}(x),\mathscr{C}_{\theta^j \omega}))<\sqrt{r}(\log(r)+1)\right\},\\
% B(n,x)&:= \left\{\omega \in \Omega;\sum_{i=0}^{n-1}\log|\d f_{\theta^i \omega}(f^i_{\omega}(x))|\le \log(\alpha)\frac{\zeta c}{2}\right\}.
% \end{align*}


% Furthermore, for every $x \in \mathbb{S}^1$, $r>0$ and $n \in \mathbb{N}$, let us consider the following sets:
% \begin{align*}
% A(n,x)&:= \left\{\omega \in \Omega;\sum_{i=0}^{n-1}\log(\mathrm{dist}_{r}(g^i_{\omega}(x),\mathscr{C}_{\theta^j \omega}))<\sqrt{r}(\log(r)+1)\right\},\\
% B(n,x)&:= \left\{\omega \in \Omega;\sum_{i=0}^{n-1}\log|\d f_{\theta^i \omega}(f^i_{\omega}(x))|\le \log(\alpha)\frac{\zeta c}{2}\right\},
% \end{align*}


% Set $\sigma^2:=\alpha^{-\frac{1}{8}} e^{-\frac{c\zeta}{8}}$.
% From Proposition $3.4$ of {\color{red}Giuseppe Paper} and the definition of $L$-sparse hyperbolic times, provided  $r$ is small enough, there exists $\gamma \in (0,1)$ such that for every $x\in\mathbb S^1,$
% \begin{equation}\label{eq1}
% \left\{\omega\in\Omega;\#\left(\{1,\ldots,n\} \cap \{\tau_i(\omega,x)\}_{i=1}^{\infty}\right) \leq   \frac{\gamma}{2 (L+1)}  n\right\} \subset  A(n,x) \cup B(n,x).
% \end{equation}



% From Proposition $7.1$,  Proposition $7.2$ and remark  in {\color{red} Giuseppe's paper}, we obtain that
% \begin{align}
% \sup_{x \in \mathbb{S}^1}\mathcal{P}(x,A(n,x) \cup B(n,x))\xrightarrow[]{n \to \infty} 0\label{Giugiuexp}
% \end{align}
 % exponentially fast.  Combining \eqref{Giugiuexp}, \eqref{eq1} and the Borel-Cantelli lemma concludes the proof of Proposition
% \ref{LHiperbolicTijmens}. 

% Set $\sigma^2:=\alpha^{-\frac{1}{8}} e^{-\frac{c\zeta}{8}}$.
% From Proposition $3.4$ of {\color{red}Giuseppe Paper} and the definition of $L$-sparse hyperbolic times, provided  $r$ and $\sigma^2$ are small enough, there exists $\gamma \in (0,1)$ such that for every $x\in\mathbb S^1,$
% \begin{equation}\label{eq12}
% \left\{\omega\in\Omega;\#\left(\{1,\ldots,n\} \cap \{\tau_i(\omega,x)\}_{i=1}^{\infty}\right) \leq   \frac{\gamma}{2 (L+1)}  n\right\} \subset  A(n,x) \cup B(n,x).
% \end{equation}



% \end{proof}


% \subsection{\color{red} Working in Progress Full proof of  Prop 3.5}

In this appendix, we prove Proposition \ref{LHiperbolicTijmens}. 

Given $a\in \mathbb S^1$, and  $\alpha,\varepsilon >0$ consider the random dynamical system $f_\omega^n$ defined in Section \ref{Model}. Recall that a measure $\mu$ on $\mathbb S^1$ is called a \emph{stationary measure} for $f_\omega^n$ if 
$$\int_{\mathbb S^1} \mathbb P[\omega\in \Omega; f_\omega(x) \in A] \mu(\d x) = \mu(A) \ \text{for every }A\in\mathcal B(\mathbb S^1).$$

We start by proving two technical lemmas.

\begin{lema}\label{largedeviazioni}
Let $a \in [0,1),$ and $\alpha,\varepsilon>0$. Consider the random dynamical system generated by ${f_{\omega}(x) = \alpha \xi (x+ \omega_0) + a \ (\mathrm{mod}\ 1)}$ on $\mathbb S^1,$ where $\omega_0 \in [-\varepsilon,\varepsilon],$ as defined in Section \ref{Model}. 
Then, for every $r$ small enough, there exists $\beta_0, r_0>0$ such that for every $x\in \mathbb S^1,$
\begin{align*}
  \mathbb{P}\left[ \sum_{i=0}^{n-1} -\log(\dist_r(f_\omega^i (x), \mathscr{C}_{\theta^i\omega})> n r_0 \right] \leq e^{-\beta_0 n} \ \text{for every }n\in\mathbb N.
\end{align*}
\end{lema}
\begin{proof}
 For every $n\in \mathbb Z_{\ge 0}$, consider $\mathcal F_n = \sigma(\pi_i; \in \{0,1,\ldots, n-1\} ),$ where for every $i\in\mathbb Z$, we define $\pi_i: \Omega \to [-\varepsilon,\varepsilon]$ as $\pi_i( (\omega_n)_{n\in\mathbb Z}) = \omega_i.$

By the Markov Inequality, given $1<\zeta< e$
\begin{align*}
  \mathbb{P}\left[ \sum_{i=0}^{n-1} -\log(\dist_r(f_\omega^i (x), \mathscr{C}_{\theta^i\omega})> n r_0 \right] \le \frac{\mathbb{E}\left[\prod\limits_{i=0}^{n-1} \zeta^{-\log\left(\mathrm{dist}_{r}\left(f^i_{\omega}(x),\mathscr{C}_{\theta^i\omega}\right)\right)}\right]}{\zeta^{r_0 n}}
\end{align*}
To simplify the notation, we define  write $b_i(\omega,x,r) := -\log\left(\mathrm{dist}_{r}\left(f^i_{\omega}(x),\mathscr{C}_{\theta^i\omega}\right)\right).$ Observe that 
\begin{equation}\label{induction}
\mathbb{E}\left[ \prod_{i\le n} \zeta^{b_i(\omega,x,\delta)}  \right] = \mathbb{E}\left[\prod_{i\le n-1}\zeta^{b_i(\omega,x,\delta)}\mathbb{E}\left[\zeta^{b_n(\omega,x,r)}|\mathcal{F}_{n-1}\right](\omega)\right]
\end{equation}
Since $\mathscr{C}_{\omega}=\mathscr{C}-\omega_0$ and the fact that $\mathscr{C}_{\theta^n\omega}$ depends explicitly on $\omega_n$, whilst $f^n_{\omega}(x)$ depends on $\omega_0,\dots,\omega_{n-1}$ we obtain  
\begin{align*}
\mathbb{E}\left[\zeta^{b_n(\omega,x,r)}|\mathcal{F}_{n-1}\right](\omega) &= \int_{[-\varepsilon,\varepsilon]} \zeta^{-\log\left(\mathrm{dist}_{r}(f^n_{\omega}(x)+\omega_n,\mathscr{C})\right)} \mathbb{P}(\d \omega_n)\\
&= \frac{1}{2\varepsilon} \int_{\mathbb{S}^1} \zeta^{-\log\left(\mathrm{dist}_{r}(y,\mathscr{C})\right)} 1_{B (f^{n}_{\omega}(x),\sigma )}(y)\d y \\
&=     \frac{1}{2\varepsilon}  \int_{\mathbb{S}^1} \mathbbm 1_{B_\varepsilon(f^n_{\omega}(x))}(y) \left(\frac{1}{\mathrm{dist}_{r}(y,\mathscr{C})}\right)^{\log(\zeta)} \d y  \\
&= \frac{1}{2\varepsilon}\int_{\mathbb{S}^1 \setminus B_r(\mathscr{C})}\mathbbm 1_{B_\varepsilon (f^n_{\omega}(x))}(y)\d y  + \frac{1}{2\varepsilon}\int_{B_r(\mathscr{C})}\mathbbm 1_{B_\varepsilon(f^{n}_{\omega}(x))}(y)\left(\frac{1}{\mathrm{dist}_{r}(y,\mathscr{C})}\right)^{\log(\zeta)}\d y 
\\
&\le  1 + \frac{2\# \mathscr{C}}{\varepsilon } \int_{(0,r)}\left(\frac{1}{x}\right)^{\log(\zeta)} \d x \\
&=   1 + \frac{2\# \mathscr{C}}{\varepsilon }\frac{r^{1-\log(\zeta)}}{1-\log(\zeta)},
\end{align*}
Substituting this estimate into \eqref{induction}, we achieve by induction in $n$ that
\begin{equation}\label{bondo3}
\mathbb{E}\left[ \prod_{i\le n} \zeta^{b_i(\omega,x,\delta)}  \right] \le \left(\frac{1}{\zeta^{r_0}}\left(1 + \frac{2\#\mathscr{C}}{\varepsilon }\frac{r^{1-\log(\zeta)}}{1-\log(\zeta)} \right)\right)^n.
\end{equation}
% Observe that:
% \begin{align*}
% \frac{d \zeta^{r}}{d\delta} &= \log(\zeta) \zeta^{r}\left(\frac{1}{2\sqrt{\delta}} + \frac{\log(\frac{1}{\delta})}{2\sqrt{\delta}}- \frac{1}{\sqrt{\delta}}  \right)\\&= \frac{1}{2\sqrt{\delta}}\log(\zeta) \zeta^{r} \left(\log\left(\frac{1}{\delta}\right)-1\right)\\ &> \frac{1}{2\sqrt{\delta}}\log(\zeta) \,\, \text{as} \, \delta \to 0.
% \end{align*}
Thus, for $r$ small enough such that we obtain
$$\beta_0 := -\log\left( \frac{1}{\zeta^{r_0}}\left(1 + \frac{2\#\mathscr{C}}{\varepsilon }\frac{r^{1-\log(\zeta)}}{1-\log(\zeta)} \right) \right) > 0,$$
 which, by  \eqref{bondo3},  concludes the proof.
\end{proof}


\begin{lema}\label{ledev}
Let $a \in [0,1)$ and $\alpha,\varepsilon>0$. Consider the random dynamical system generated by ${f_{\omega}(x) = \alpha \xi (x+ \omega_0) + a \ (\mathrm{mod}\ 1)}$ on $\mathbb S^1,$ where $\omega_0 \in [-\varepsilon,\varepsilon],$ as defined in Section \ref{Model}. 

Let $C = \{x\in\mathbb S^1; |\d f(x)|<1\}.$ Given $R>0$, define $G = G(R) = \{x\in \mathbb S^1; |\d f(x)|> R\}.$  Assume that $f_\omega^n$ admits a unique stationary measure $\mu$, and there exist constants $R>1$, $h\in(0,1)$ and $\varepsilon > (1-m(G))/h$ such
\begin{equation}\label{new}
Z(h):=  \log(R)(1-h)+\frac{1}{2\varepsilon}\int_{C} \log|\d f(z)|\d z>0,
\end{equation}

Then, there exists a constant $D ,\beta_1 ,\sigma^2>0$ such that
\begin{equation}\label{crazy2}
\sup_{x \in \mathbb{S}^1} \mathbb{P}\left( \sum_{i=0}^{n-1}\log\left|\d f_{\theta^i\omega}(x)\right|<\sigma^2 n\right) \le De^{-\beta_1 n}.
\end{equation}

\end{lema}
\begin{proof}
We divide the proof into four steps. The proof is long and technical. In Step 1, we provide useful definitions for the proof. Steps 2 through 4 involve estimating the measure of certain events, which subsequently leads to the desired result.
\begin{step}{1}
Initial preparation for the proof.
\end{step}
Since $\d f(x)$ is a continuous function, it is clear that $\log\left|\d f(x+\omega_0)\right| \in L^1(\mathbb{P}\otimes \mu)$. Thus,
\begin{equation}\label{loteria}
\lambda = \int_{\mathbb{S}^1}\int_{\Omega}\log\left|\d f(x+\omega_0)\right|\mu(\d x)\mathbb{P}(\d \omega) \ge \inf_{x \in \mathbb{S}^1}\int_{\Omega}\log\left|\d f(x+\omega_0)\right|\mathbb{P}(\d \omega).
\end{equation}
For any $x \in \mathbb{S}^1$, observe that
\begin{align*}
\int_{\Omega}\log|\d f(x+\omega_0)|\mathbb{P}(\d \omega)&= \frac{1}{2\varepsilon}\int_{B_\varepsilon (x)\cap G}\log|\d f(z)| \d z + \frac{1}{2\varepsilon}\int_{B_\varepsilon (x)\setminus G} \log|\d f(z)|\d z \\
&\ge \log(R)(1-h) + \frac{1}{2\varepsilon}\int_{B_\varepsilon (x)\setminus G}\log|\d f(z)| \d z>Z(h)>0. 
\end{align*}
%We claim that
%\begin{equation}\label{cita}
%\int_{\Omega}\log\left|\d f(x+\omega_0)\right|\mathbb P(\d \omega) \ge Z(h)\log(R).
%\end{equation}
%Indeed, let $f$ be the generating function of $f^n_{\omega}$ and let $G$ be its super-expanding set. Let $P(k)$ be the partition of $\mathbb{S}^1 \setminus G$ introduced in section $2$, see \eqref{partition}. Using Proposition \ref{basic proposition}, we see that, for all $x \in \mathbb{S}^1$
%\begin{align*}
%\int_{\Omega}\log\left|\d f(x+\omega_0)\right|\mathbb P(\d \omega) &\ge \log(R)\mathbb{P}\left(x +\omega_0 \in G\right) - \sum_{k =0}^{\tilde{k}(f)}(k+1)\log(R)\mathrm{Leb}(P(k))\\
%&\ge \log(R)\left[(1-h)- h\left(\sum_{k=0}^{k_0(f)}k+ C\sum_{k=k_0(f)+1}^{\tilde{k}(f)} (k+1)R^{-k} \right)\right]\\
%&= Z(h)\log(R),
%\end{align*}
%where $k_0(f)$ and $k_{\text{max}}(f)$ were introduced in Proposition \ref{basic proposition} in Definition \ref{admissibleRDS}.
%Combining \eqref{cita} with the inequality in \eqref{loteria}, we obtain \eqref{crazy1}, i.e the Lyapunov exponent is positive and satisfies $\lambda \ge Z(h)\log(R)$. \\


It remains to prove the large deviations estimate in \eqref{crazy2}.  To simplify the notation, we denote $V:=-\int_C\log(|\d f(x)|)\d x>0$.
Let $\beta_2>0$ such that
\begin{equation}\label{zetauno}
Z_1(h) := \log(R)(1-h)-\frac{\beta_2+1}{2\varepsilon}V.
\end{equation}
Take sufficiently large $\ell \in \mathbb{N}$ and consider the sets
\begin{equation}\label{defPk}
P(k):= \left\{x \in \mathbb{S}^1 \mid R^{-\frac{k}{\ell}}>|\d f(x)|>R^{-\frac{(k+1)}{\ell}} \right\}.
\end{equation}
Observe that $\{ P(k)\}_{k \ge -\ell}$ is a partition of $\mathbb{S}^1 \setminus G$ whose diameter is small if $\ell$ is large enough and the sets $\{P(k)\}_{k \ge 0}$ are a partition of $C$  with the same properties. Then, for any sequence $\{x_k\}_{k \ge 0}$ such that $x_k \in P(k)$ we have that
\begin{align*}
 \left|\sum_{k \ge 0} \log|\d f(x_k)|m(P(k)) +V\right| \xrightarrow{\ell \to\infty} 0.
\end{align*}
Furthermore, as a consequence of the definition of $P(k)$ in \eqref{defPk}, we have that  
\begin{align*}
\left|\sum_{k \ge 0} \log|\d f(x_k)|m(P(k))- \sum_{k \ge 0} \log\left(R^{-\frac{(k+1)}{\ell}}\right)m(P(k)) \right| \le \log\left(R^{-\frac{1}{\ell}}\right)m(C).
\end{align*}
Choose  $\ell$ sufficiently large such that
\begin{equation}\label{mirival}
\frac{1}{2\varepsilon}\sum_{k\ge 0} \frac{(k+1)}{\ell}m(P(k))< \left(\frac{1}{2\varepsilon\log(R)}+ \frac{\beta_2}{4\varepsilon\log(R)}\right)V.
\end{equation}

Fix $n \in \mathbb{N}$ and $x \in \mathbb{S}^1$. Given $k \ge -\ell$, let us define 
% let $\widetilde{P}_{n,k}(\omega,x)$ be the number of points among $x+\omega_0, \dots, f^{n-1}_{\omega}(x)+\omega_{n-1}$ that belong to $P(k)$:
\begin{equation}\label{100h}
\widetilde{P}_{n,k}(\omega,x):= \#\{i \in \{0,\dots, n-1 \} ; f^i_{\omega}(x) +\omega_i \in P(k)  \},
\end{equation}
%$where $\{P(k)\}_k$ is the partition defined in %eqref{partition}.
analogously, consider
\begin{align*}
\widetilde{G}_n(\omega,x) &:= \#\{i \in \{0,\dots, n-1 \}; f^i_{\omega}(x)+\omega_i \in G  \}.
\end{align*}
Recall that $G= \{x\in\mathbb S^1; \|d f(x)\|> R\}$ and $\bigcup_{k \ge -\ell }P(k) = \mathbb{S}^1 \setminus G$. Therefore,
\begin{equation}\label{lowerb}
S_n(\omega,x):=\sum_{i=0}^{n-1}\log|\d f_{\theta^i \omega}(f^i_{\omega}(x))| \ge \tilde{G}_{n}(\omega,x)\log(R) - \sum_{k =0}^{\infty}\widetilde{P}_{n,k}(\omega,x) \frac{(k+1)}{\ell}\log(R).
\end{equation}
Given $x \in \mathbb{S}^1$, consider the set of noise realisations 
\begin{align*}
A_n(x) := \left\{\omega\in\Omega; \  \widetilde{G}_n(\omega,x) - \sum_{k \ge 0} \widetilde{P}_{n,k}(\omega,x) (k+1) < \left(1-h-\left(\frac{1+\beta_2}{2\varepsilon \log(R)}\right)V\right)n \right\}.
\end{align*}
Note that by \eqref{zetauno} and  \eqref{lowerb} we have 
\begin{equation}\label{inclusion}
\left\{ S_n(\omega,x)< Z_1(h)n \right\} \subset A_n(x).
\end{equation}
To estimate the measure of $A_n(x)$, we introduce the set $A^1_n(x)$ of all noise realisations for which the orbit of $x$  enters one of the sets  $P(k)$ for  $k \ge n$ at least once,
\begin{align*}
A^1_n(x) &:= \left\{\omega\in \Omega;\ \text{there exists}\ k \ge n\ \text{such that}\  \widetilde{P}_{n,k}(\omega,x) >0  \right\}.
\end{align*}
 We further consider the set of noise realisations that the orbit of $x$ visits $G$ with a frequency smaller than  $1-h- \beta_2V/(8\varepsilon\log(R))$:
\begin{align*}
A^2_n(x) := \left\{\omega\in \Omega;\ \tilde{G}_{n}(\omega,x)\le \left(1-h-\frac{\beta_2 }{8\varepsilon \log(R)}V\right)n \right\}.
\end{align*}
The set $A_n(x)$ can be decomposed as 
\begin{equation}\label{decomposition}
A_n(x) := A^3_n(x) \sqcup \left( A_n(x) \cap \left(A^1_n(x) \cup A^2_n(x)\right)\right),
\end{equation}
where
\begin{align}
A^3_n(x) &=  A_n(x) \setminus \left(A^1_n(x)\cup A^2_n(x)\right)\nonumber\\
&= \left\{\omega \in \Omega;\  \sum_{k = 0}^{n-1} \widetilde{P}_{n,k}(\omega,x) \left(k+1\right)  > \widetilde{Z}n \right\}, \label{name}
\end{align}
where 
\begin{equation}\label{name2}
\widetilde{Z} := \left(\frac{3\alpha}{8\varepsilon \log(R)}+\frac{1}{2\varepsilon \log(R)}\right)V.
\end{equation}
Observe that 
\begin{align*}
\mathbb{P}(A_n(x)) \le \mathbb{P}\left(A^1_n(x)\right) + \mathbb{P}(A^2_n(x)) + \mathbb{P}(A^3_n(x)),
\end{align*}
therefore to prove Lemma \ref{ledev}  it is enough to estimates on  the measure of $A^1_n(x)$, $A^2_n(x)$ and $A^3_n(x)$ this is done in Steps 2-4 below.
\begin{step}{2}\label{motivation}
We show that there exists a $D_0 \ge 1$, such that, for all $n \ge 0$,
 $\mathbb{P}\left(A^1_n(x)\right) \le D_0 R^{-\frac{n}{2\ell}}.$
\end{step} Let 
$\widetilde{P}(n):= \bigcup_{k \ge n}P(k)$, then
\begin{align*}
\mathbb{P}\left(A^1_n(x)\right) \le \sum_{i=0}^{n-1} \mathbb{P}\left( f^i_{\omega}(x)+x_i \in \widetilde{P}(n)  \right) \le \sum_{i=0}^{n-1} \sup_{y \in \mathbb{S}^1}\mathbb{P}\left( y+\omega_i \in \widetilde{P}(n)\right).
\end{align*}
Since the critical set of $f$ is non-degenerate, there exists a constant $D \ge 1$ such that ${m\left(\widetilde P(n)\right)\le D R^{-\frac{n}{\ell}}}$, for all $n \ge 0$. As a consequence, we obtain that
\begin{align*}
\mathbb{P}\left( y+\omega_i \in \widetilde{P}(n)  \right) \le \frac{1}{2\varepsilon}m(\widetilde{P}(n))
&\le D R^{-\frac{n}{\ell}},
\end{align*}
which yields $\mathbb{P}\left(A^1_n(x)\right) \le  DnR^{-\frac{n}{\ell}} \le D_0R^{-\frac{n}{2\ell}},$ for some $D_0 \ge 1$.
 This concludes Step 2. 
\begin{step}{3}\label{coollemma}
 There exists $q_1 \in (0,1)$ such that, for all $n \ge 0$, $\mathbb{P}\left(A^2_n(x)\right) \le q_1^n.$
\end{step}

Given $j\in \mathbb N,$ let us define
\begin{align}
\widehat{\pi}_j(A) = \mathbb{P}(\omega\in \Omega; (\omega_0,\dots,\omega_{j-1}) \in A) \qquad \ \text{for every} A \subset \mathcal{B}([-\varepsilon,\varepsilon]^j). \label{pihat}
\end{align}

 
Observe that $A^2_n(x)$ can be rewritten as
\begin{align*}
A^2_{n}(x)= \left\{ \sum_{i=0}^{n-1}\mathbbm 1_{\mathbb{S}^1 \setminus G}(f^i_{\omega}(x)+\omega_i)>\left(h+ \frac{\beta_2}{4}V\right)n \right\}.
\end{align*}
 By  the Markov inequality, for any $\zeta>1$, we obtain that
\begin{align*}
 \mathbb{P}\left(A^2_{n}(x)\right) \le \frac{\mathbb{E}\left[\zeta^{\sum_{i=0}^{n-1}\mathbbm 1_{\mathbb{S}^1\setminus G}\left(f^i_{\omega}(x)+\omega_i\right)}\right]}{\zeta^{\left(h+ \frac{\beta_2}{4}V\right)n}}.
\end{align*}
Therefore,
\begin{align*}
&\mathbb{E}\left[\zeta^{\sum\limits_{i=0}^{n-1}\mathbbm 1_{\mathbb{S}^1\setminus G}(f^i_{\omega}(x)+\omega_i)}\right]  = \int_{\Omega} \prod_{i=0}^{n-1} \zeta^{\mathbbm 1_{\mathbb{S}^1\setminus G}(f^i_{\omega}(x)+\omega_i)} \widehat{\pi} (\d \omega_0,\dots, \d \omega_{n-1}) \\
=& \int_{\Omega}\prod_{i=0}^{n-2} \zeta^{\mathbbm 1_{\mathbb{S}^1\setminus G}(f^i_{\omega}(x)+\omega_i)}\left[ \int_{[-\varepsilon,\varepsilon]} \zeta^{\mathbbm 1_{\mathbb{S}^1\setminus G}(f^{n-1}_{\omega}(x)+\omega_{n-1})}\mathbb P(\d \omega_{n-1})\right] \widehat{\pi}(\d \omega_0,\dots,\d \omega_{n-2}), 
\end{align*}



Note that, given $\omega_0,\dots,\omega_{n-2}$ fixed, we have that
$$
\int_{[-\varepsilon,\varepsilon]} \zeta^{\mathbbm 1_{\mathbb{S}^1\setminus G}(f^{n-1}_{\omega}(x)+\omega_{n-1})}\mathbb{P}(\d \omega_{n-1}) = (\zeta-1)\frac{\mathrm{Leb}(\omega_n ; f^{n-1}_{\omega}(x)+\omega_{n-1} \notin G)}{2\varepsilon}+ 1.
$$
Since  $\varepsilon > (1-m(G)/(2h)$, we obtain that  
\begin{align*}
\int_{[-\varepsilon,\varepsilon]} \zeta^{\mathbbm 1_{\mathbb{S}^1\setminus G}(f^{n-1}_{\omega}(x)+\omega_{n-1})}\mathbb P(\d \omega_{n-1}) \le \zeta h + 1-h.
\end{align*}
Repeating the argument recursively, we have that $\mathbb{E}\left[\zeta^{\sum_{i=0}^{n-1}1_{\mathbb{S}^1\setminus G}(f^i_{\omega}(x)+\omega_i)}\right]  \le (\zeta h + 1-h)^n.$ Hence, for any $\zeta>1$ 
\begin{align*}
 \mathbb{P}\left(A^2_n(x)\right)\le \left(\frac{h\zeta+ 1-h}{\zeta^{h+\frac{\beta_2}{4}V}}\right)^n.
\end{align*}
Taking $q_1:= (\zeta h+ 1-h)/(\zeta^{h+\frac{\beta_2}{4}V})$  for $\zeta$ close enough to $1$ we conclude the proof of Step 3. 
 
\begin{step}{4}\label{importandev}
We show that there exists  $q_2 \in (0,1)$ such that, for all $n \ge 0$, 
 $\mathbb{P}\left(A^3_n(x)\right) \le q_2^n,$ and conclude the proof of Lemma \ref{ledev}. 
\end{step}
 
%Let 
%\begin{equation}\label{lastZ}
%\widetilde{Z}:= \left(\frac{3\alpha}{8\varepsilon \log(R)}+\frac{1}%{2\varepsilon \log(R)}\right)V
%\end{equation}
%Note that, by \eqref{reF} 
%\begin{align*}
%\widetilde{Z}(h) = h\left[\sum_{k=0}^{k_0(f)}(k+1)+\sum_{k_0(f)+1}^{k_{\text{max}}(f)}(k+1)R^{-\frac{99k}{100}}\right]+ \frac{h}{50}.
%\end{align*}
By the Markov inequality and \eqref{name}, for all $1<\zeta$.
\begin{equation}\label{Chebishev}
\mathbb{P}(A^3_n(x)) \le \frac{\mathbb{E}\left[\zeta^{ \sum_{k = 0}^{n-1} \widetilde{P}_{n,k}(\omega,x)(k+1)}\right]}{\zeta^{n\widetilde{Z}}}
\end{equation}
Given $k \in \{0,\dots, n-1\}$ define $M_j(\omega,x) := \prod_{k=0}^{n-1}\zeta^{(k+1)1_{P(k)}(f^j_{\omega}(x)+\omega_j)}$ and recall the definition of $\widehat{\pi}_k$ in \eqref{pihat}.

From \eqref{100h}
\begin{align*}
\mathbb{E}\left[\zeta^{ \sum\limits_{k = 0}^{n-1} \widetilde{P}_{n,k}(\omega,x)(k+1)}\right] &= \mathbb{E}\left[\prod_{k=0}^{n-1}\zeta^{\widetilde{P}_{n,k}(\omega,x)(k+1)}   \right]
= \mathbb{E}\left[\prod_{k=0}^{n-1}\prod_{j=0}^{n-1}\zeta^{(k+1)\mathbbm 1_{P(k)}(f^j_{\omega}(x)+\omega_j)} \right] \\
&=\mathbb{E}\left[\prod_{j=0}^{n-1}\left[\prod_{k=0}^{n-1} \zeta^{(k+1)\mathbbm 1_{P(k)}(f^j_{\omega}(x)+\omega_j)} \right]\right] 
= \int_{\Omega}  \prod_{j=0}^{n-1} M_j(\omega,x)\widehat{\pi}_n(\d \omega).
\end{align*}
By Fubini's theorem
\begin{equation}\label{fubini}
\int_{\Omega} \prod_{j=0}^{n-1}M_j(\omega,x)\widehat{\pi}_{n-1}(\d \omega)= \int_{\Omega}\prod_{j=0}^{n-2}{M_j(\omega,x)}\left[\int_{[-\varepsilon,\varepsilon]}M_{n-1}(\omega,x)\mathbb P(\d \omega_n)\right]\widehat{\pi}_{n-1}(\d \omega).
\end{equation}
Observe that, given $(\omega_0,\dots,\omega_{n-2}) \in [-\varepsilon,\varepsilon]^{n-1}$, we can rewrite
\begin{align*}
\int_{[-\varepsilon,\varepsilon]}M_{n-1}(\omega,x)\mathbb{P}(\d \omega_{n-1}) &= \int_{[-\varepsilon,\varepsilon]} \prod_{k=0}^{n-1} \zeta^{\frac{k}{\ell}\mathbbm 1_{P(k)}(f^{n-1}_{\omega}(x)+\omega_{n-1})}\mathbb{P}(\d \omega_{n-1})\\
&\le \max_{y \in \mathbb{S}^1}\int_{[-\varepsilon,\varepsilon]} \prod_{k=0}^{n-1} \zeta^{\frac{k}{\ell}\mathbbm 1_{P(k)}(y+\omega_{n-1})}\mathbb{P}(\d \omega_{n-1})
\\
&\le 1- \frac{1}{2\varepsilon} m\left(\bigcup_{k=0}^{n-1 }P(k)\right)+ \sum_{k=0}^{n-1} \zeta^{\frac{(k+1)}{\ell}}\frac{m\left(P(k)\right)}{2\varepsilon}.
\end{align*} 
As a consequence 
\begin{equation}\label{nickchata}
\int_{\Omega} \prod_{j=0}^{n-1}M_j(\omega,x)\widehat{\pi}_{n-1}(\d \omega)\le  W(\zeta) \int_{\Omega} \prod_{j=0}^{n-1}M_j(\omega,x)\pi_{n-2}(\d\omega),
\end{equation}
where  $W(\zeta):= 1+ \sum_{k=0}^{n-1} (\zeta^{\frac{(k+1)}{\ell}}-1)m\left(P(k)\right)/(2\varepsilon).$
Repeating the the same procedure $n-1$ times, we obtain
\begin{equation}\label{exponential}
\mathbb{P}(A^3_n(x)) \le \left(\frac{W(\zeta)}{\zeta^{\widetilde{Z}}}\right)^n. 
\end{equation}
Since $W(1)=1$ and, by \eqref{mirival} and \eqref{name2}
\begin{align*}
W'(1)&= \sum_{k=0}^{n-1}
\frac{(k+1)}{\ell}\frac{m\left(P(k)\right)}{2\varepsilon} < \left(\frac{1}{2\varepsilon \log(R)}+\frac{\beta_2}{4\varepsilon \log(R)}\right)V< \widetilde{Z}.
%&\le h\left[\sum_{k=0}^{k_0(f)}(k+1)+ C\sum_{k=k_0(f)+1}^{k_{\text{max}}(f)} (k+1)R^{-k}\right] = 1-h- Z(h) < \widetilde{Z}(h).
\end{align*}
Therefore $W(\zeta) < \zeta^{\widetilde{Z}}$, for $\zeta>1$ sufficiently close to $\zeta$. Therefore, $q_2:= W(\zeta)/\zeta^{\widetilde{Z}}<1,$ for $\zeta$ sufficiently close to $1$,  which concludes the proof. Finally, combining \eqref{expansion} with the end of Step 1 and Steps 2 and 3 concludes the proof of Lemma \ref{ledev}.
\end{proof}
 
Finally, we prove Proposition \ref{LHiperbolicTijmens}.

\begin{proof}[Proof of Proposition \ref{LHiperbolicTijmens}]
Let $c>0$ be fixed, so that $\varepsilon \ge \alpha^{c-1}$. From \cite[Theorem 1]{Zeng} (also see \cite[Theorem A and Section 3.2]{Blumenthal})  there exists $\alpha_0>1$ sufficiently large such that $f_\omega^n$ has a unique stationary measure $\mu$ on $\mathbb S^1.$

Define $s = s(\alpha):= m(G(\alpha)).$ Consider $C = \{x\in\mathbb S^1;\ |\d f(x)|\leq 1\}.$ From Lemma \ref{LGiu} and \eqref{LGiu2}, we can choose $\alpha_1 > \alpha_0$, such that for every $\alpha>\alpha_1$
$$  h = \frac{1}{2}  < 1 + \frac{2\alpha^{1-c }}{\log(\alpha^{c/2})} \int_C \log |\d f(x)| \d x\ \text{and}\  \frac{1-s(\alpha)}{h} < \frac{1}{\alpha^{1-c}}.$$

For every $\sigma^2, r>0$, $x\in \mathbb N$ and $n\in \mathbb N$ define
\begin{align*}
A(n,x,r)&:= \left\{\omega \in \Omega;\sum_{i=0}^{n-1}\log(\mathrm{dist}_{r}(f^i_{\omega}(x),\mathscr{C}_{\theta^j \omega}))<r n\right\},\\
B(n,x,\sigma^2)&:= \left\{\omega \in \Omega;\sum_{i=0}^{n-1}\log|\d f_{\theta^i \omega}(f^i_{\omega}(x))|\le \sigma^2 n \right\}.
\end{align*}


From Lemmas \ref{largedeviazioni} and  \ref{ledev}, we obtain that there exists $r$ and$\sigma^2$ small enough such that, for every $\alpha > \alpha_1,$
\begin{align}
\sup_{x \in \mathbb{S}^1}\mathbb P [ A(n,x,r) \cup B(n,x,\sigma^2)]\xrightarrow[]{n \to \infty} 0,\label{Giugiuexp}
\end{align}


%  where for any $x\in \mathbb S^1$ and $n\in\mathbb N$ we define
% \begin{align*}
% A(n,x)&:= \left\{\omega \in \Omega;\sum_{i=0}^{n-1}\log(\mathrm{dist}_{r}(g^i_{\omega}(x),\mathscr{C}_{\theta^j \omega}))<\sqrt{r}(\log(r)+1)\right\},\\
% B(n,x)&:= \left\{\omega \in \Omega;\sum_{i=0}^{n-1}\log|\d f_{\theta^i \omega}(f^i_{\omega}(x))|\le \log(\alpha)\frac{\zeta c}{2}\right\}.
% \end{align*}


% Furthermore, for every $x \in \mathbb{S}^1$, $r>0$ and $n \in \mathbb{N}$, let us consider the following sets:
% \begin{align*}
% A(n,x)&:= \left\{\omega \in \Omega;\sum_{i=0}^{n-1}\log(\mathrm{dist}_{r}(g^i_{\omega}(x),\mathscr{C}_{\theta^j \omega}))<\sqrt{r}(\log(r)+1)\right\},\\
% B(n,x)&:= \left\{\omega \in \Omega;\sum_{i=0}^{n-1}\log|\d f_{\theta^i \omega}(f^i_{\omega}(x))|\le \log(\alpha)\frac{\zeta c}{2}\right\},
% \end{align*}


% Set $\sigma^2:=\alpha^{-\frac{1}{8}} e^{-\frac{c\zeta}{8}}$.
% From Proposition $3.4$ of {\color{red}Giuseppe Paper} and the definition of $L$-sparse hyperbolic times, provided  $r$ is small enough, there exists $\gamma \in (0,1)$ such that for every $x\in\mathbb S^1,$
% \begin{equation}\label{eq1}
% \left\{\omega\in\Omega;\#\left(\{1,\ldots,n\} \cap \{\tau_i(\omega,x)\}_{i=1}^{\infty}\right) \leq   \frac{\gamma}{2 (L+1)}  n\right\} \subset  A(n,x) \cup B(n,x).
% \end{equation}



% From Proposition $7.1$,  Proposition $7.2$ and remark  in {\color{red} Giuseppe's paper}, we obtain that
% \begin{align}
% \sup_{x \in \mathbb{S}^1}\mathcal{P}(x,A(n,x) \cup B(n,x))\xrightarrow[]{n \to \infty} 0\label{Giugiuexp}
% \end{align}
 % exponentially fast.  Combining \eqref{Giugiuexp}, \eqref{eq1} and the Borel-Cantelli lemma concludes the proof of Proposition
% \ref{LHiperbolicTijmens}. 

% Set $\sigma^2:=\alpha^{-\frac{1}{8}} e^{-\frac{c\zeta}{8}}$.
From the Pliss Lemma (see \cite[Lemma 6.2]{Alves}) and the definition of $L$-sparse hyperbolic times, provided  $r$ and $\sigma^2$ are small enough, there exists $\gamma \in (0,1)$ such that for every $x\in\mathbb S^1,$
\begin{equation}\label{eq1}
\left\{\omega\in\Omega;\#\left(\{1,\ldots,n\} \cap \{\tau_i(\omega,x)\}_{i=1}^{\infty}\right) \leq   \frac{\gamma}{2 (L+1)}  n\right\} \subset  A(n,x,\sigma^2) \cup B(n,x,r).
\end{equation}
For more details on the construction of $\gamma$, see \cite[Proposition 6.3]{Alves}. Combining equations \eqref{Giugiuexp} and \eqref{eq1}, the proposition follows.


\end{proof}


\section{Proof of Proposition \ref{invmes}}
\label{AppendixB}


This appendix is devoted to proving Proposition \ref{invmes}. While  similar results have been established in the literature (e.g. \cite{Alves, Baladi, Du}), we provide an alternative proof of the existence of an invariant measure based on the aforementioned papers. We note that our approach details the arguments presented in the references mentioned before, and we believe our proof contributes to the existing literature on the topic.

Let us assume that $\alpha,\varepsilon >0$ satisfies the conditions of Theorem \ref{TheoremB}, consider $\beta>0$ as in Lemma \ref{panpilona}, and then define the set
$$\mathcal F_\beta := \{\varphi:\mathbbold{\Delta} \to \mathbb R;\ \exists\ C \in L^{\infty}(\Omega,\mathbb P) \text{ s.t. } |\varphi_\omega(x) - \varphi_\omega(y)|\leq C(\omega) \beta^{s_\omega(x,y)}, \ \text{for all }x,y\in \Delta\}.$$
In $\mathcal F_\beta$ we consider the norm,
$$\|\varphi \|_\beta = \|\varphi\|_{L^\infty(\tri, m_\omega(\d x) \mathbb P(\d \omega) )} +  |\varphi|_\beta,$$
where
$$|\varphi|_\beta = \esssup_{\omega} \sup_{x ,y \in w \in \widehat{P}(\omega) } \frac{|\varphi(\omega,x)- \varphi(\omega,y)|}{\beta^{s(\omega,x,y)}}. $$

We start by proving the following lemma.
\begin{lema} Let $\beta$ be as in Lemma \ref{panpilona}. Then, there exists $C_0 >0$ such that
$$ \log \frac{|\d F^n_\omega(z_1)|}{|\d F^n_\omega(z_2)|}\leq C_0\beta^{s_{\theta^n \omega} (F_\omega^n (z_1), F_\omega^n (z_2) )}, \text{for every }n\in\mathbb N. $$
% in particular if $R^i(\omega,z_1) \leq n < R^{i+1}(\omega,z_1)$, with $0\leq i < s(\omega,z_1,z_2)$ we obtain
% $$ \log \frac{|\d F^n_\omega(z_1)|}{|\d F^n_\omega(z_2)|}\leq C_0\beta^{s_{\theta^n \omega} (F_\omega^n (z_1), F_\omega^n (z_2) )} = C_0 \beta^{s(\omega,z_1,z_2) - i}. $$
\label{5l}
\end{lema}

\begin{proof}
Assume that $s(\omega,z_1,z_2) >0,$ otherwise, there is nothing to prove. From Lemma \ref{fr}, we obtain that the result is valid for $n= R(\omega,z_1) = R(\omega,z_2).$ 

Suppose that $n= R_i(\omega,z_1)$
$$ s(\theta^{R_i}\omega, F^{R_i}_\omega(z_1),F^{R_i}_\omega (z_2)) = s_\omega(z_1,z_2) - i,$$
we obtain that
\begin{align*}
    \log \frac{|\d F^{R_i}_\omega(z_1)|}{|\d F^{R_i}_\omega(z_2)|}&= \sum_{j=0}^{i-1} \log \frac{| \d F_{\theta^{R_j}\omega} (F^{R_j}_\omega (z_1) )| }{| \d F_{\theta^{R_j}\omega} (F^{R_j}_\omega (z_2) )| }\\ &
    \leq \mathrm{diam}(\Delta_0)C \sum_{j=0}^{i-1}\beta^{s(\theta^{R_j} \omega, F_\omega^{R_j} (x), F_\omega^{R_j}(y) )}\\
    &\leq \mathrm{diam}(\Delta_0)C \sum_{j=0}^{i-1} \beta^{n-i}\beta^{s(\theta^{R_i} \omega, F_\omega^{R_i} (x), F_\omega^{R_i}(y) )}\\
    &\leq \frac{\mathrm{diam}(\Delta_0)}{1-\beta} \beta^{s(\theta^{R_i} \omega, F^{R_i}_\omega z_1, F^{R_i}_\omega z_1) } 
    % =\frac{\mathrm{diam}(\Delta_0)}{1-\beta} \beta^{s(\omega, z_1,z_2) - i }
 \end{align*}

Now, observe that since for every $R_{i-1}(\omega,x) < n < R_{i}(\omega,x)$ with $0<i \leq s_\omega (x,y),$ we obtain that
$s(\theta^n \omega , F^n_\omega x, F^n_\omega y) = s(\theta^{R_i}\omega, F^{R_i}_\omega (x) ,  F^{R_i}_\omega (y) ),$
and $|\d F^n_\omega (x)| = |\d F^{R_i}_\omega(x),|$ we obtain the desired inequality.
\end{proof}

In the following, we define sets that are useful during the proof of Proposition\ref{invmes}. We start defining $$\Delta_0 := \Delta_{\omega,0} = \{(x,0); x\in \Delta, R(\omega,x) >0\} = \Delta\times\{0\},$$
as the common level zero of all towers $\Delta_\omega.$ (see \eqref{Dw}). Now, we define a partition of $\Delta \subset \mathbb S^1$. Consider $T_i^1(\omega) := \{x \in \Delta ; R_\omega(x) = i\},$ and define  $\{A^1_{i,j}(\omega)\}_{j \in \mathbb N}$ a collection of sets such that $ \{A^1_{i,j}(\omega)\}_{j\in \mathbb N} = \left\{T_i^1(\omega)\cap w;\ w\in \mathcal P(\omega)\right\}.$

Observe that from the above construction $$\Delta = \bigsqcup_{i,j} A^i_{i,j}(\omega)\ \text{mod-}m\ \text{for }\mathbb P\text{-almost every }\omega\in \Omega,$$ and for every $i,j \in \mathbb N,$  $ F_\omega(A_{i,j}^1(\omega) \times\{i\} )=\Delta_0= \Delta_{\theta \omega}.$

 Moreover, we recursively define a family of subsets $\mathcal Q^n(\omega)$ of $\Delta_\omega$. If $n=1$ we define ${\mathcal Q^1(\omega) := \{A_{i,j}^1\times\{i\}\}_{i,j\in\mathbb N}}$. In the case that $n>1$,
$$ \mathcal Q^n(\omega) := \bigvee_{i=0}^{n-1} (F_\omega^i)^{-1} \mathcal Q^1(\theta^{i}\omega) =: \{A^n_{i,j}(\omega)\times\{i\} \}_{i,j\in\mathbb N},$$
observe that $\Delta = \bigsqcup_{i,j} A^n_{i,j}(\omega)\ \text{mod-}m.$

Now we proceed to the proof.
\begin{teorema}
    There exists a $F$-invariant probability measure $\mu(\d \omega, \d x) = \mu_\omega (\d x) \mathbb P(\d\omega)$ such that $$\frac{1}{C_1} \left.m_{\omega}\right|_{\Delta_0} \leq \left.\mu_\omega\right|_{\Delta_0},$$
where $m_{\omega}$ is the Lebesgue measure on $\Delta_\omega.$ \label{invariantdreams}
\end{teorema}

\begin{proof}

Consider $P = m_\omega(\d x) \mathbb P(\d \omega).$ Define $\mu_0 = \left. P\right|_{\mathbbold{\Delta}_0}/P(\mathbbold{\Delta}_0),$ where $\mathbbold{\Delta}_0 = \{(\omega,(x,0)); x\in \Delta \}.$ Denote $\mu_n =  F^n_*\mu_0. $

Given $\varphi:\mathbbold{\Delta} \to \mathbb R,$ we obtain 
\begin{align*}
    \int_{\tri} \varphi \, \d \mu_n &= \int_{\mathbbold{\Delta}} \mathbbm 1_{\Delta_0}(F^n_\omega(x,\ell)) \varphi(\theta^n \omega, F^n_\omega (x,\ell)) P(\d \omega, \d (x,\ell) )\\
&= \int_{\Omega }\sum_{\ell,j=0}^{\infty}\int_{A^n_{\ell,j}(\omega)}\mathbbm 1_{\Delta\times \{0\}}(F^n_\omega(x,\ell))  \varphi(\theta^n\omega, F_\omega^n(x,\ell))  m_{\omega}(\d (x,\ell) ) \mathbb P( \d \omega)\\
&=  \int_{\Omega }\sum_{\ell,j=0}^{\infty}\int_{A^n_{\ell,j}(\omega)} \varphi(\theta^n\omega, F_\omega^n(x,\ell))  m_{\omega}(\d (x,\ell)) \mathbb P( \d \omega)
\end{align*}




Observe that the family of measures $$\left\{\nu_n := \frac{1}{n}\sum_{i=0}^{n-1}\mu_n\right\},$$ admits an accumulation point in $\mathcal M_1( \widehat{\mathbbold{\Delta}})$ (where $\widehat{\tri}$ is the one point compactification of $\mathbbold{\Delta}$). Let $\nu$ be such an accumulation point. We show that $\nu(\tri) >0.$


Define
$$\phi_{\ell,j}^n (\theta^n\omega, x) = \frac{(\d F_\omega^n)_*m_{\omega, A_{\ell,j}^n }(\d x) }{m_{\theta^n \omega} (\d x \cap \Delta_0)},\ \text{where } m_{\omega,A_{i,j}^n}(B) = m_{\omega} (B\cap A_{\ell,j}^n(\omega )\times\{\ell\} ) ). $$

Observe that $F_\omega^n:A_{\ell,j}(\omega)\times\{\ell\} \to \Delta_0$ is a bijection. Taking $x,y\in \Delta_0,$ there exists $x',y'$ such that $F_\omega^n(x') = x$ and $F_\omega^n (y') = y.$ From Lemma \ref{5l} we obtain that
\begin{align}
    \left| \log \frac{\phi_{\ell,j}^n (\theta^n \omega,y )}{\phi_{\ell,j}^n (\theta^n \omega,x)} \right| &= \left|\log\frac{\d F_\omega^n (x')}{\d F_\omega^n (y')}\right|= C_0 \beta^{s(\theta^n\omega, F_\omega^n (x'), F_\omega^n (y') )} = C_0 \beta^{s(\theta^n \omega,x,y)}\label{DA}
\end{align}
therefore
\begin{align}
\phi_{\ell,j}^n (\theta^j \omega,x )\leq C_1  \phi_{\ell,j}^n (\theta^j \omega,y), \label{arriba}
\end{align}
this implies that
\begin{align*}
    \phi_{\ell,j}^n(\theta^n \omega ,y)  &= \frac{\int_{\Delta_0}\phi_{\ell,j}^n (\theta^n \omega ,y) m_{\theta^n \omega} (\d x)} {m_{\theta^n \omega}(\Delta_0)}\\
    &\geq \frac{1}{C_1}\frac{\int_{\Delta_0}\phi_{\ell,j}^n(\theta^n \omega ,x)  m_{\theta^n \omega} (\d x) }{m_{\theta^n \omega}(\Delta_0)} =\frac{m_{\omega}(A_{i,j}^n(\omega)\times\{i\})}{C_1}
\end{align*}

% In the case $(b)$, we have that $F_\omega^j A_\omega \subset \Delta_{\theta^n\omega,\ell}$. Observe that 
% $$F_\omega^j A_\omega \times \{\} $$

% Observe that for every $$B\times \{\ell\} \subset F_\omega^j (A_\omega\times\{0\}),$$ 
% $$(F^j_\omega)_* \mu^0(B\times\{\ell\}) = (F_\omega^{j-\ell})_*(\mu^0)( B \times \{0\}),$$
% therefore
% $$\phi_{j,A} (\theta^j\omega, (y,\ell) ) = \phi_{j -\ell} ( \theta^{j-\ell} \omega, (y,0)).$$

% % Therefore we obtain from the computations in part $(a)$,
% % $$ \phi_{j,A}(\theta^{j} \omega,y) \leq D \lambda_{\theta^{j}\omega} (A_{\theta^k \omega}).$$

% This implies that $$\frac{\mu(\d \omega,\d x)}{P(\d \omega,\d x)} < D.$$

% Integrating \eqref{arriba} with respect to $y$ in $\Delta_0$ with respect $m_{\theta^n \omega}$ we obtain,
% $$ \phi_{j,A}(\theta^j \omega, x) \geq \frac{1}{D'} \lambda_{\theta^j \omega}(A_{\theta^j \omega}  ).$$

From the above computation, we obtain that,
\begin{align*}
 \int_{\tri} \varphi(x) \mu_n(\d x)&= \int_{\Omega }\sum_{\ell,j=0}^{\infty}\int_{A^n_{\ell,j}(\omega)} \varphi(\theta^n\omega, F_\omega^n(x,\ell))  m_{\omega}(\d(x,\ell) ) \mathbb P( \d \omega)\\
&\geq \frac{1}{C_1} \int_{\Omega }\sum_{\ell,j=0}^{\infty}m_{\omega} (A_{i,j}(\omega)\times\{\ell \} ) \int_{\Delta_0} f(\theta^n\omega,(x,0))  m_{\omega}\otimes \mathbb P( \d x \times \d \omega)\\
&\geq \frac{1}{C_1} \int_{\mathbbold{\Delta}_0} \varphi (\omega , x) P(\d \omega, \d x).
\end{align*}


Therefore, for any continuous function $\varphi: \mathbbold{\Delta}_0 \to \R_+,$  we obtain,
\begin{align*}
    \int_{\mathbbold{\Delta}_0 } \varphi\, \d \nu &= \lim_{n\to\infty} \sum_{i=0}^{n-1}\frac{1}{n}  \int_{\mathbbold{\Delta}_0 } \varphi\, \d \mu_i \geq  \frac{1}{C_1}\int_{\mathbbold{\Delta}_0 } \varphi \, \d P. 
\end{align*}

Therefore, $\mu :=\nu(\d x \times \d\omega \cap \mathbbold{\Delta})/\nu(\mathbbold{\Delta}) $ is an invariant measure for $F.$ Since $\nu = \nu_\omega (\d x) \mathbb P(\d \omega)$ the proof is finished.


\end{proof}

Now, we prove Proposition \ref{invmes}.

% For $k \ge 0$, let us denote by $s_k(\omega,x)$ the $k$-th $()$
\begin{proof}[Proof of Proposition \ref{invmes}]
% For $(\omega,x) \in \Omega \times \mathbb{S}^1$ and $k \ge 0$, let $f_k(\omega,x)$ denote the $k$-th $(\sigma^2,\omega)$-hyperbolic time
% \label{AppendixB}
Let $\mu$ be the invariant $F$-invariant measure obtained in Theorem \ref{invariantdreams}.  We show that 
 $$h_{\omega} (x) := \frac{\mu( \d \omega, \d x)}{m_{\omega}(\d x) \mathbb P (\d \omega)} \in \mathcal F_\beta. $$


\begin{step}{1}
We show that for every $n\in\mathbb N,$ the measure $\mu_n$ (defined in the proof of Theorem \ref{invariantdreams}), satisfies
$$\frac{\mu_n(\d\omega, \d x)}{m_\omega (\d x) \mathbb P(\d \omega)} \in \mathcal F_\beta.$$
\end{step}
Let $n\in \mathbb N$. By integrating \eqref{arriba} over $\Delta$ over $y$ we obtain that
$$\phi_{\ell,j}^n(\theta^j \omega,x) \leq C_1 \frac{\mu_{\omega} (A_{i,j}^n (\omega))}{m_{\omega} (\Delta_0)}\leq C_1. $$

From \eqref{DA}, it follows that for every $x,y \in A_{\ell,j}^n(\omega)\times \{\ell\}$ (assume without loss of generality suppose that $ \phi_{\ell,j}^n(\theta^n \omega,y) \leq \phi_{\ell,j}^n(\theta^n \omega,x))$  that
\begin{align*}
    |\phi_{i,j}^n(\theta^n \omega, x) - \phi_{i,j}^n(\theta^n \omega,y)| &=  \phi_{i,j}^n(\theta^n \omega,x)\left(1 - \frac{\phi_{i,j}^n(\theta^n \omega,y)}{\phi_{i,j}^n(\theta^n \omega,x)}\right)\\
    &\leq\phi_{i,j}^n(\theta^n \omega,x) \left| \log \frac{\phi_{\ell,j}^n (\theta^n \omega,y )}{\phi_{\ell,j}^n (\theta^n \omega,x)} \right|\\
    &\leq  C_1 C_0 e^{\beta(\theta^n \omega, x,y)}.
\end{align*}

Observe that for every $(x,\ell) \in \Delta_\omega,$ we have that $F^{\ell}_{\theta^{-\ell}\omega}(x,0) = (x,\ell),$ and 
$\d F^{\ell}_{\theta^{-\ell \omega}} (x,0) =1,$
therefore
$$\frac{ \d \mu_n  }{\d m_{\omega}} (x,\ell) = \frac{\d (F_{\theta^{-\ell} \omega}^\ell)_* \mu_{\theta^{-\ell} \omega} }{\d m_{\omega}} (x,\ell) =\frac{\d \mu_{\theta^{-\ell}\omega }}{\d m_{\theta^{-\ell} \omega}}(x,0).  $$
Since $\bigcup_{i,j} A_{i,j}^n(\omega)\times\{0\} = \Delta_0,$ we obtain that $\mu_n(\d \omega , \d x)/m_{\omega} (\d x) \mathbb P (\d \omega) \in \mathcal F_\beta. $ This proves Step 1.
 % This implies that
 % $$\left|\frac{\mu(\d x,\d\omega)}{P\otimes m_{\omega} (\\mu_n(\d \omega , \d x)}{m_{\omega} (\d x) \mathbb P (\d \omega)}\right|\leq C_0. $$
 \begin{step}{2}
We show that $h_\omega \in \mathcal F_\beta$.
 \end{step}

Let $\{\nu_{n_k} = \frac{1}{n_k} \sum\limits_{i=0}^{n-1} \mu_{i}\}_{k\in\mathbb N},$ be a sequence of measure such that
$$\nu_{n_k} \xrightarrow[]{n\to \infty} \mu, \ \text{in the weak}^*\ \text{topology}.$$
Hence we obtain that,
$$\frac{ \nu_{n_k}(\d \omega, \d x)}{m_\omega(\d x) \mathbb P(\d \omega)} \xrightarrow[]{n\to \infty} \frac{\mu(\d \omega,\d x)}{ m_\omega(\d x) \mathbb P(\d \omega) }\ \text{in }L^1(\tri, m_\omega(\d x) \mathbb P(\d \omega)).$$
Passing through a subsequence, we can assume that
$$\frac{ \nu_{n_k}(\d \omega, \d x)}{m_\omega(\d x) \mathbb P(\d \omega)} \xrightarrow[]{n\to \infty} \frac{\mu(\d \omega,\d x)}{ m_\omega(\d x) \mathbb P(\d \omega) }\  \mathbb P(\d \omega)\text{-a.s.},$$

From the pointwise convergence and Step 1, we obtain that 
$$ \frac{\mu(\d \omega,\d x)}{ m_\omega(\d x) \mathbb P(\d \omega) } \in \mathcal F_\beta.$$

\begin{step}{3} We show that $\mu$ is the unique $F$-invariant measure such that 
$$ h_\omega(x) := \frac{\mu(\d \omega,\d x)}{ m_\omega(\d x) \mathbb P(\d \omega) } \in \mathcal F_\beta.$$
\end{step}
From Theorem \ref{invariantdreams} we obtain that there exists $C>0,$ such that $C < h_\omega(x)$ for every $x\in \Delta_0$. Moreover, from the construction of the $\mathcal P_1(\omega)\subset \mathcal P(\omega)$ in Section \ref{pathwiseconstr} and Proposition \ref{Giupar}, we obtain that  for every $n\in\mathbb N$
$$F_\omega^n (\Delta_0) \supset \bigcup_{\ell =0}^{n}\Delta_{\theta^{n} \omega ,\ell},\ \text{for } \mathbb P\text{-almost every }\omega\in \Omega,$$
where $\Delta_{\omega,\ell}= \{(x,\ell); x \in R(\theta^{-\ell} \omega,x) > \ell\}.$ Since, $h_\omega$ is uniformly lower bounded and $|\d F^\omega (x,\ell )| \geq 1 $ for $m_\omega (\d(x,\ell)),\mathbb P(\d\omega)$-almost every $(\omega,(x,\ell))\in\tri,$ we obtain that $h_\omega(x,\ell) >0 $ for $m_\omega (\d(x,\ell)),\mathbb P(\d\omega)$-almost every $(\omega,(x,\ell))\in\tri.$

Repeating the same arguments provided in \cite[Theorem 4.3]{Baladi} (see \cite[Theorem 2.3.3]{Du} for a detailed discussion), we obtain that $\mu$ is an exact $F$ invariant measure, and  therefore ergodic. 

Now, let $\nu$ be another different $F$-invariant probability measure such that $\nu \ll \mu_\omega( \d \omega ) \mathbb P(\d \omega).$ Since, $h_\omega >0$ $\mu_\omega( \d \omega ) \mathbb P(\d \omega)$-almost surely, then $\nu \ll \mu$. Since $\mu$ is ergodic, we obtain that $\nu =\mu$ from the Birkhoff ergodic theorem (see \cite[Lemma 3.12]{Alves}).

\end{proof}


\bibliographystyle{plain} 
\bibliography{main}
\end{document}

 


