{
    "arxiv_id": "2303.14133",
    "paper_title": "Adversarial Attack and Defense for Medical Image Analysis: Methods and Applications",
    "authors": [
        "Junhao Dong",
        "Junxi Chen",
        "Xiaohua Xie",
        "Jianhuang Lai",
        "Hao Chen"
    ],
    "submission_date": "2023-03-24",
    "revised_dates": [
        "2023-03-27"
    ],
    "latest_version": 1,
    "categories": [
        "eess.IV",
        "cs.CR",
        "cs.CV"
    ],
    "abstract": "Deep learning techniques have achieved superior performance in computer-aided medical image analysis, yet they are still vulnerable to imperceptible adversarial attacks, resulting in potential misdiagnosis in clinical practice. Oppositely, recent years have also witnessed remarkable progress in defense against these tailored adversarial examples in deep medical diagnosis systems. In this exposition, we present a comprehensive survey on recent advances in adversarial attack and defense for medical image analysis with a novel taxonomy in terms of the application scenario. We also provide a unified theoretical framework for different types of adversarial attack and defense methods for medical image analysis. For a fair comparison, we establish a new benchmark for adversarially robust medical diagnosis models obtained by adversarial training under various scenarios. To the best of our knowledge, this is the first survey paper that provides a thorough evaluation of adversarially robust medical diagnosis models. By analyzing qualitative and quantitative results, we conclude this survey with a detailed discussion of current challenges for adversarial attack and defense in medical image analysis systems to shed light on future research directions.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.14133v1"
    ],
    "publication_venue": null
}