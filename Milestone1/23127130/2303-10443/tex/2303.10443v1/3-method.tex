\section{GazeReader}
\label{sec:method}

\projectname{} automatically detects unknown words by embedding the gaze data and text information using LSTM and a transformer-based model. We also introduced knowledge-based features including term frequency, part of speech, and named entity recognition to improve the performance. In data pre-processing, we apply a moving average filter and re-sampling to de-noise gaze data and map the gaze data to the text data. 




\subsection{Data Preparation}

\begin{figure*}
  \centering
  \includegraphics[scale = 0.45]{fig/data_processing_1.png}
  %\setlength{\abovecaptionskip}{0.1cm}
  \caption{Data pre-processing for \projectname{} model.}
  \label{fig:data_processing} 
\end{figure*}

\subsubsection{Data Collection}
We recruited 12 graduate students ranging in age from 23 to 28 years (\textit{M} = 23.64, \textit{SD} = 1.57), including two males and ten females. They were all second-language learners of English and were able to use English in academic settings, and their years of formal English study ranged from 7 to 24 years (\textit{M} = 16, \textit{SD} = 4.84). Nine of them wore glasses, and the other three did not.
 
We chose 36 articles from TOEFL reading materials with an average length of 386 words per article and 13902 words in total. Participants read 12 articles per day for three days and spent four hours reading in total. The experiment was conducted in a quiet meeting room without disturbing using a Thinkpad X1 carbon laptop (CPU: i7-10710U, 6 cores, 1.1 GHz, RAM: 16GB, Storage: 512GB). There was a break every 30 minutes.

We built a web PDF reader to display the article and used WebGazer.js~\cite{papoutsaki2016webgazer} to track users' gaze. Before each section started, the participants calibrated the WebGazer according to its instruction~\cite{papoutsaki2016webgazer} to map gaze points to screen coordinates. Participants first read the article, recorded the gaze data, and then clicked to mark the unknown words. Our system saved the gaze data, the unknown words, and the text coordinate for each article. We collected a total of 4274 clicks for unknown words and 1232 unknown words after eliminating duplication.




\subsubsection{Data Pre-processing}
Since the gaze data is acquired with only a webcam without highly accurate devices, the original data is extremely noisy and could not be directly fed to the machine learning models. Meanwhile, to avoid potential distractions to users' reading, we do not ask the users to label their unknown words during their reading in real-time, which makes it a necessary step to align the gaze data with its corresponding context and unknown words.

As shown in Fig.~\ref{fig:data_processing}, we first de-noise the gaze data by applying a moving average technique with a sliding window size of 50. Since each time step of the output data from WebGazer is uneven, we re-sample the gaze data with the sample rate of 20Hz and conduct linear interpolation between the raw data on both the x and y-axis. Afterward, to align each unknown word with its corresponding gaze data, we anticipate each word's time based on its relative position of the whole document assuming that people's reading speeds are likely to be uniform. We also chunk the gaze data into segments based on each piece of text's length for matching gaze and text data. We select the text read within 1 second by the user when they see the unknown word as its context. Finally, since we only want to prompt users with the unknown words they are reading, we add negative samples for each gaze data by combining it with the contents containing unknown words that the user was not reading.



% \subsubsection{Data Augmentation}

\subsection{Unknown Words Detection Model}
Our model is designed to predict users' unknown words during reading based on gaze data and reading text information. To capture the positional information of texts and gaze data, we use LSTM layers to encode them into vector space. To improve the model's performance, we use RoBERTa~\cite{liu2019roberta} as the backbone language model for infusing text information. Meanwhile, we further enhance the text information by leveraging word-level knowledge. The overall architecture of our model is illustrated in Fig.~\ref{fig:overview}.

\begin{figure*}
  \centering
  \includegraphics[scale = 0.43]{fig/overview.png}
  %\setlength{\abovecaptionskip}{0.1cm}
  \caption{Overview of \projectname{} model.}
  \label{fig:overview} 
% \vspace{-5mm}
\end{figure*}

\subsubsection{Positional Data Encoding}
At first, we illustrate our neural network that encodes the sequential 2-D data, including the word position in the reading document and the user's eye gaze data. Since both word position and eye gaze data are sequential, we use LSTM network to encode them since it can capture the long and short-term dependencies in sequential data. Overall, the two LSTM layers transform the 2-D gaze sequence $g \in \mathbb{R}^{2 \times n_{gaze}}$ and word position sequence $d \in \mathbb{R}^{2 \times n_{txt}}$ into $H_g \in \mathbb{R}^{n_p \times n_{gaze}}$ and $H_d \in \mathbb{R}^{n_p \times n_{txt}}$ (where $n_p$ is the output dimension of LSTM layer, while $n_{gaze}$ and $n_{txt}$ are the length of the gaze data and texts), respectively. Afterward, we conduct a matrix multiplication between the encoded text positional data and the gaze data as the attention between the gaze and texts:

\begin{align*}
    g = [g_x;g_y]&, H_g = \textrm{LSTM}(g) \\
    d = [d_x; d_y]&, H_d = \textrm{LSTM}(d) \\
    A_p &= \delta(H_d^T \cdot H_g)
\end{align*}

where $\delta$ is the activation function and $g_x, g_y, d_x, d_y$ are the gaze data and word position on X and Y axis, respectively.

\subsubsection{Context Information Capturing}
In order to leverage the rich information from the reading materials, we use a pre-trained RoBERTa model to encode these texts in the vector space. RoBERTa is a pre-trained language model with 12 transformer layers, where each layer contains a self-attention module that captures the attention between word tokens and a feed-forward layer that maps the attention into a higher vector space. It transforms the input texts $s \in \mathbb{R}^{n_{txt}}$ into $Z \in \mathbb{R}^{n_{txt} \times dim}$, where $dim$ is the hidden dimension of RoBERTa. Since the model has been trained on huge amounts of text data, it can accurately embed documents into vector space for downstream tasks. In general, RoBERTa calculates

\begin{equation}
Z = \textrm{RoBERTa}(s)
\end{equation}

\subsubsection{Knowledge Enhancement}
During the processing of language models, the original documents are tokenized into sub-word tokens instead of words. Therefore, there exists word-level knowledge lost during tokenization which causes the degradation of model performance. Hence, for each token, we add its original word-level knowledge, including term frequency, part of speech~\cite{bird2009natural}, named entity recognition~\cite{honnibal2020spacy} to promote the model's performance. In general, we use learnable embeddings and layers to encode these features into a ``knowledge matrix'' $K \in \mathbb{R}^{n_{txt} \times n_k}$. 

\subsubsection{Training}
We combine these features above and feed them to a linear classifier for unknown word prediction:
\begin{align*}
    O &= [A_p; Z; K] \\
    a &= \sigma(W_o \cdot O+ b_o)
\end{align*}
where $W_o, b_o$ are learnable parameters, $\sigma$ is the sigmoid function, and $a \in \mathbb{R}^{n_{txt}}$ is the output activation of the classifier. The model is trained with a binary entropy loss on all tokens
\begin{equation}
    \mathcal{L} = -\sum_{i=1}^{n_{txt}} (1-\tilde{y}_i) \cdot \log(1-a_i) + \tilde{y}_i \cdot \log(a_i)
\end{equation}
where $\tilde{y}_i$ is the label whether the i-th token is part of the unknown word of the user.

\subsection{User Study}

To demonstrate the variability of our approach, we used the Vocabulary Levels Test (VLT) to test users' vocabulary levels. The test was developed by Nation in 1987 and produced questions at different word frequency levels in 2000, 3000, 5000, 10,000, and academic groups~\cite{nation1990teaching}. 
The VLT is one of the most widely used tests to measure the vocabulary level of English learners ~\cite{read1988measuring,read2000assessing}. We chose an optimized version of the test~\cite{schmitt2001developing}.
Considering that the required vocabulary level for TOEFL reading as experimental material is about 4500~\cite{chujo2009many}, we used a 5000-word frequency level group to test users' vocabulary levels.

We also explored future directions for the tool design. In order to understand users' needs, we designed a group of questions to test their subjective feelings and attitudes. The questions include perceived factors that influence English text reading, behaviors when checking unknown words in reading, concerns toward eye-tracking tools, and attitudes toward our proposed new features (eye-tracking reading assistance and vocabulary management). All the above questions and potential answers were grouped and conducted using 5-point Likert items. 

Besides subjective ratings, we collected descriptive information from randomly selected users about their needs during reading. Users were asked to write down their potential needs as much as possible.
