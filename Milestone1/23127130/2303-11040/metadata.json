{
    "arxiv_id": "2303.11040",
    "paper_title": "Benchmarking Robustness of 3D Object Detection to Common Corruptions in Autonomous Driving",
    "authors": [
        "Yinpeng Dong",
        "Caixin Kang",
        "Jinlai Zhang",
        "Zijian Zhu",
        "Yikai Wang",
        "Xiao Yang",
        "Hang Su",
        "Xingxing Wei",
        "Jun Zhu"
    ],
    "submission_date": "2023-03-20",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
    ],
    "abstract": "3D object detection is an important task in autonomous driving to perceive the surroundings. Despite the excellent performance, the existing 3D detectors lack the robustness to real-world corruptions caused by adverse weathers, sensor noises, etc., provoking concerns about the safety and reliability of autonomous driving systems. To comprehensively and rigorously benchmark the corruption robustness of 3D detectors, in this paper we design 27 types of common corruptions for both LiDAR and camera inputs considering real-world driving scenarios. By synthesizing these corruptions on public datasets, we establish three corruption robustness benchmarks -- KITTI-C, nuScenes-C, and Waymo-C. Then, we conduct large-scale experiments on 24 diverse 3D object detection models to evaluate their corruption robustness. Based on the evaluation results, we draw several important findings, including: 1) motion-level corruptions are the most threatening ones that lead to significant performance drop of all models; 2) LiDAR-camera fusion models demonstrate better robustness; 3) camera-only models are extremely vulnerable to image corruptions, showing the indispensability of LiDAR point clouds. We release the benchmarks and codes at https://github.com/kkkcx/3D_Corruptions_AD. We hope that our benchmarks and findings can provide insights for future research on developing robust 3D object detection models.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11040v1"
    ],
    "publication_venue": "CVPR 2023"
}