% Related
% from rebuttal 
@article{tino2004markovian,
  title={Markovian architectural bias of recurrent neural networks},
  author={Tino, Peter and Cernansky, Michal and Benuskova, Lubica},
  journal={IEEE Transactions on Neural Networks},
  volume={15},
  number={1},
  pages={6--15},
  year={2004},
  publisher={IEEE}
}

@inproceedings{kolen1994recurrent,
  title={Recurrent networks: State machines or iterated function systems},
  author={Kolen, John F},
  booktitle={Proceedings of the 1993 Connectionist Models Summer School},
  pages={203--210},
  year={1994},
  organization={Erlbaum Associates Hillsdale}
}

@article{stark1991iterated,
  title={Iterated function systems as neural networks},
  author={Stark, Jaroslav},
  journal={Neural Networks},
  volume={4},
  number={5},
  pages={679--690},
  year={1991},
  publisher={Elsevier}
}
@article{tino1998recurrent,
  title={Recurrent neural networks with iterated function systems dynamics},
  author={Tino, Peter and Dorffner, Georg},
  year={1998},
  publisher={SFB Adaptive Information Systems and Modelling in Economics and Management~…}
}
@article{dym2020expression,
  title={Expression of fractals through neural network functions},
  author={Dym, Nadav and Sober, Barak and Daubechies, Ingrid},
  journal={IEEE Journal on Selected Areas in Information Theory},
  volume={1},
  number={1},
  pages={57--66},
  year={2020},
  publisher={IEEE}
}

%% Fractal inversion
@book{lankhorst1995iterated,
  title={Iterated function systems optimization with genetic algorithms},
  author={Lankhorst, Marc M},
  year={1995},
  publisher={University of Groningen, Department of Mathematics and Computing Science}
}
@incollection{vrscay1989iterated,
  title={Iterated function systems and the inverse problem of fractal construction using moments},
  author={Vrscay, Edward R and Roehrig, Christopher J},
  booktitle={Computers and Mathematics},
  pages={250--259},
  year={1989},
  publisher={Springer}
}
@article{iacus2005approximating,
  title={Approximating distribution functions by iterated function systems},
  author={Iacus, Stefano Maria and La Torre, Davide},
  journal={Journal of Applied Mathematics and Decision Sciences},
  volume={2005},
  number={1},
  pages={33--46},
  year={2005},
  publisher={Hindawi}
}
@incollection{vrscay1991iterated,
  title={Iterated function systems: theory, applications and the inverse problem},
  author={Vrscay, Edward R},
  booktitle={Fractal geometry and analysis},
  pages={405--468},
  year={1991},
  publisher={Springer}
}
@article{forte1995solving,
  title={Solving the inverse problem for measures using iterated function systems: A new approach},
  author={Forte, B and Vrscay, ER},
  journal={Advances in applied probability},
  volume={27},
  number={3},
  pages={800--820},
  year={1995},
  publisher={Cambridge University Press}
}
@incollection{gutierrez2000hybrid,
  title={An hybrid evolutive-genetic strategy for the inverse fractal problem of IFS models},
  author={Guti{\'e}rrez, Jos{\'e} M and Cofi{\~n}o, Antonio S and Ivanissevich, Mar{\'\i}a L},
  booktitle={Advances in Artificial Intelligence},
  pages={467--476},
  year={2000},
  publisher={Springer}
}
@article{kya2001optimization,
  title={Optimization of fractal iterated function system (IFS) with probability and fractal image generation},
  author={Kya, Berthe and Yang, Yang},
  journal={International Journal of Minerals, Metallurgy and Materials},
  volume={8},
  number={2},
  pages={152--156},
  year={2001},
  publisher={International Journal of Minerals, Metallurgy and Materials}
}
%other related
@article{van2016conditional,
  title={Conditional image generation with pixelcnn decoders},
  author={Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
@inproceedings{van2016pixel,
  title={Pixel recurrent neural networks},
  author={Van Oord, Aaron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1747--1756},
  year={2016},
  organization={PMLR}
}
@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}
@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

% optimization
@article{camuto2021fractal,
  title={Fractal structure and generalization properties of stochastic optimization algorithms},
  author={Camuto, Alexander and Deligiannidis, George and Erdogdu, Murat A and Gurbuzbalaban, Mert and Simsekli, Umut and Zhu, Lingjiong},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}
@article{xia2021gan,
  title={GAN inversion: A survey},
  author={Xia, Weihao and Zhang, Yulun and Yang, Yujiu and Xue, Jing-Hao and Zhou, Bolei and Yang, Ming-Hsuan},
  journal={arXiv preprint arXiv:2101.05278},
  year={2021}
}

@inproceedings{welling2011bayesian,
  title={Bayesian learning via stochastic gradient Langevin dynamics},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={681--688},
  year={2011},
  organization={Citeseer}
}

@inproceedings{zhu2016generative,
  title={Generative visual manipulation on the natural image manifold},
  author={Zhu, Jun-Yan and Kr{\"a}henb{\"u}hl, Philipp and Shechtman, Eli and Efros, Alexei A},
  booktitle={European conference on computer vision},
  pages={597--613},
  year={2016},
  organization={Springer}
}

@inproceedings{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  booktitle={ICLR},
  year={2019}
}
@inproceedings{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019},
  organization={PMLR}
}
@article{allen2019learning,
  title={Learning and generalization in overparameterized neural networks, going beyond two layers},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013},
  organization={PMLR}
}

% Pretraining with Fractals

@article{poli2022self,
  title={Self-Similarity Priors: Neural Collages as Differentiable Fractal Representations},
  author={Poli, Michael and Xu, Winnie and Massaroli, Stefano and Meng, Chenlin and Kim, Kuno and Ermon, Stefano},
  journal={arXiv preprint arXiv:2204.07673},
  year={2022}
}

@article{hendrycks2021pixmix,
  title={PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures},
  author={Hendrycks, Dan and Zou, Andy and Mazeika, Mantas and Tang, Leonard and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2112.05135},
  year={2021}
}

@article{baradad2021learning,
  title={Learning to see by looking at noise},
  author={Baradad Jurjo, Manel and Wulff, Jonas and Wang, Tongzhou and Isola, Phillip and Torralba, Antonio},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={2556--2569},
  year={2021}
}

@InProceedings{Ma_2021_ICCV,
    author    = {Ma, Yuxin and Hua, Yang and Deng, Hanming and Song, Tao and Wang, Hao and Xue, Zhengui and Cao, Heng and Ma, Ruhui and Guan, Haibing},
    title     = {Self-Supervised Vessel Segmentation via Adversarial Learning},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {7536-7545}
}

@InProceedings{Anderson_2022_WACV,
    author    = {Anderson, Connor and Farrell, Ryan},
    title     = {Improving Fractal Pre-Training},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {January},
    year      = {2022},
    pages     = {1300-1309}
}

@article{gupta2021beyond,
  title={Beyond Flatland: Pre-training with a Strong 3D Inductive Bias},
  author={Gupta, Shubhaankar and O'Connell, Thomas P and Egger, Bernhard},
  journal={arXiv preprint arXiv:2112.00113},
  year={2021}
}

@article{deng2021fractal,
  title={Fractal Pyramid Networks},
  author={Deng, Zhiqiang and Yu, Huimin and Long, Yangqi},
  journal={arXiv preprint arXiv:2106.14694},
  year={2021}
}

@article{nakashima2021can,
  title={Can vision transformers learn without natural images?},
  author={Nakashima, Kodai and Kataoka, Hirokatsu and Matsumoto, Asato and Iwata, Kenji and Inoue, Nakamasa},
  journal={arXiv preprint arXiv:2103.13023},
  year={2021}
}

% Fractal inverse problem
@incollection{guerin2005fractal,
  title={Fractal inverse problem: approximation formulation and differential methods},
  author={Gu{\'e}rin, Eric and Tosan, Eric},
  booktitle={Fractals in Engineering},
  pages={271--285},
  year={2005},
  publisher={Springer}
}

% Fractal inverse examples
@inproceedings{graham2019applying,
  title={Applying Neural Networks to a Fractal Inverse Problem},
  author={Graham, Liam and Demers, Matthew},
  booktitle={International Conference on Applied Mathematics, Modeling and Computational Science},
  pages={157--165},
  year={2019},
  organization={Springer}
}
@article{menassel2018improved,
  title={An improved fractal image compression using wolf pack algorithm},
  author={Menassel, R and Nini, B and Mekhaznia, T},
  journal={Journal of Experimental \& Theoretical Artificial Intelligence},
  volume={30},
  number={3},
  pages={429--439},
  year={2018},
  publisher={Taylor \& Francis}
}

@article{al2017improved,
  title={An Improved Harmony Search Algorithm for Reducing Computational Time of Fractal Image Coding.},
  author={Al-Saidi, Nadia MG and Al-Bundi, Shaimaa S and Al-Jawari, Naseif J},
  journal={Journal of Theoretical \& Applied Information Technology},
  volume={95},
  number={8},
  year={2017}
}

@article{venkatasekhar2013fast,
  title={Fast search strategies using optimization for fractal image compression},
  author={Venkatasekhar, D and Aruna, P and Parthiban, B},
  journal={International Journal of Computer and Information Technology},
  volume={2},
  number={3},
  pages={437--441},
  year={2013},
  publisher={Citeseer}
}
@article{enright2005mass,
  title={Mass fractal dimension and the compactness of proteins},
  author={Enright, Matthew B and Leitner, David M},
  journal={Physical Review E},
  volume={71},
  number={1},
  pages={011912},
  year={2005},
  publisher={APS}
}
@article{sweet1999topology,
  title={Topology in chaotic scattering},
  author={Sweet, David and Ott, Edward and Yorke, James A},
  journal={Nature},
  volume={399},
  number={6734},
  pages={315--316},
  year={1999},
  publisher={Nature Publishing Group}
}
@article{fisher1994fractal,
  title={Fractal image compression},
  author={Fisher, Yuval},
  journal={Fractals},
  volume={2},
  number={03},
  pages={347--361},
  year={1994},
  publisher={World Scientific}
}
@article{al2016crowding,
  title={Crowding optimization method to improve fractal image compressions based iterated function systems},
  author={Al-Bundi, Shaimaa S and Al-Saidi, Nadia MG and Al-Jawari, Neseif J},
  journal={International Journal of Advanced Computer Science and Applications},
  volume={7},
  number={7},
  pages={392--401},
  year={2016}
}

@article{jacquin1992image,
  title={Image coding based on a fractal theory of iterated contractive image transformations},
  author={Jacquin, Arnaud E and others},
  journal={IEEE Transactions on image processing},
  volume={1},
  number={1},
  pages={18--30},
  year={1992},
  publisher={Citeseer}
}

@article{al2020review,
  title={A Review on Fractal Image Compression Using Optimization Techniques},
  author={AL-Bundi, Shaimaa S and Abd, Mustafa S},
  journal={Journal of Al-Qadisiyah for computer science and mathematics},
  volume={12},
  number={1},
  pages={Page--38},
  year={2020}
}

@article{nettleton1994evolutionary,
  title={Evolutionary algorithms and a fractal inverse problem},
  author={Nettleton, David John and Garigliano, Roberto},
  journal={Biosystems},
  volume={33},
  number={3},
  pages={221--231},
  year={1994},
  publisher={Elsevier}
}

% Fractals in image compression
@article{pandey2015fractal,
  title={Fractal Image Compression using Genetic Algorithm with Variants of Crossover},
  author={Pandey, Anamika and Singh, Anshul},
  journal={International Journal of Electrical, Electronics and Computer Engineering},
  volume={4},
  number={1},
  pages={73--81},
  year={2015},
  publisher={Research Trend}
}

% Fractals in diagonistic images example
@article{karperien2008automated,
  title={Automated detection of proliferative retinopathy in clinical practice},
  author={Karperien, Audrey and Jelinek, Herbert F and Leandro, Jorge JG and Soares, Jo{\~a}o VB and Cesar Jr, Roberto M and Luckie, Alan},
  journal={Clinical ophthalmology (Auckland, NZ)},
  volume={2},
  number={1},
  pages={109},
  year={2008},
  publisher={Dove Press}
}

% Fractals in nature
@book{mandelbrot1982fractal,
  title={The fractal geometry of nature},
  author={Mandelbrot, Benoit B and Mandelbrot, Benoit B},
  volume={1},
  year={1982},
  publisher={WH freeman New York}
}

% Fractals in creating DNN architectures
@article{larsson2016fractalnet,
  title={Fractalnet: Ultra-deep neural networks without residuals},
  author={Larsson, Gustav and Maire, Michael and Shakhnarovich, Gregory},
  journal={arXiv preprint arXiv:1605.07648},
  year={2016}
}

% Fractals in 3D printing
@article{ullah2021utilizing,
  title={Utilizing Fractals for Modeling and 3D Printing of Porous Structures},
  author={Ullah, AMM and D’Addona, Doriana Marilena and Seto, Yusuke and Yonehara, Shota and Kubo, Akihiko},
  journal={Fractal and Fractional},
  volume={5},
  number={2},
  pages={40},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute}
}

% Fractals in butterflies
@article{otaki2021fractal,
  title={The Fractal Geometry of the Nymphalid Groundplan: Self-Similar Configuration of Color Pattern Symmetry Systems in Butterfly Wings},
  author={Otaki, Joji M},
  journal={Insects},
  volume={12},
  number={1},
  pages={39},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute}
}

% FractalDB
@inproceedings{kataoka2020pre,
  title={Pre-training without natural images},
  author={Kataoka, Hirokatsu and Okayasu, Kazushige and Matsumoto, Asato and Yamagata, Eisuke and Yamada, Ryosuke and Inoue, Nakamasa and Nakamura, Akio and Satoh, Yutaka},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  year={2020}
}



@inproceedings{qian2020end,
  title={End-to-end pseudo-lidar for image-based 3d object detection},
  author={Qian, Rui and Garg, Divyansh and Wang, Yan and You, Yurong and Belongie, Serge and Hariharan, Bharath and Campbell, Mark and Weinberger, Kilian Q and Chao, Wei-Lun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5881--5890},
  year={2020}
}



@article{zhao2018federated,
  title={Federated learning with non-iid data},
  author={Zhao, Yue and Li, Meng and Lai, Liangzhen and Suda, Naveen and Civin, Damon and Chandra, Vikas},
  journal={arXiv preprint arXiv:1806.00582},
  year={2018}
}

@inproceedings{anderson2022improving,
  title={Improving Fractal Pre-training},
  author={Anderson, Connor and Farrell, Ryan},
  booktitle={WACV},
  pages={1300--1309},
  year={2022}
}

% SimSiam 
@inproceedings{chen2021exploring,
  title={Exploring simple siamese representation learning},
  author={Chen, Xinlei and He, Kaiming},
  booktitle={CVPR},
  pages={15750--15758},
  year={2021}
}

% InsDis 
@inproceedings{wu2018unsupervised,
  title={Unsupervised feature learning via non-parametric instance discrimination},
  author={Wu, Zhirong and Xiong, Yuanjun and Yu, Stella X and Lin, Dahua},
  booktitle={CVPR},
  pages={3733--3742},
  year={2018}
}

% MoCo-v1 
@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={CVPR},
  pages={9729--9738},
  year={2020}
}

% MoCo-v2 
@article{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}

% PIRL 
@inproceedings{misra2020self,
  title={Self-supervised learning of pretext-invariant representations},
  author={Misra, Ishan and Maaten, Laurens van der},
  booktitle={CVPR},
  pages={6707--6717},
  year={2020}
}

% SimCLR-v1 
@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={ICML},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

% SimCLR-v2 
 @inproceedings{chen2020big,
  title={Big self-supervised models are strong semi-supervised learners},
  author={Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={NeurIPS},
  year={2020}
}

% InfoMin 
@inproceedings{tian2020makes,
  title={What makes for good views for contrastive learning?},
  author={Tian, Yonglong and Sun, Chen and Poole, Ben and Krishnan, Dilip and Schmid, Cordelia and Isola, Phillip},
  booktitle={NeurIPS},
  year={2020}
}

% BYOL 
@inproceedings{grill2020bootstrap,
  title={Bootstrap your own latent: A new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre H and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and others},
  booktitle={NeurIPS},
  year={2020}
}

% PCL 
@inproceedings{li2020prototypical,
  title={Prototypical contrastive learning of unsupervised representations},
  author={Li, Junnan and Zhou, Pan and Xiong, Caiming and Hoi, Steven CH},
  booktitle={ICLR},
  year={2020}
}

% SeLa 
@inproceedings{asano2019self,
  title={Self-labelling via simultaneous clustering and representation learning},
  author={Asano, Yuki Markus and Rupprecht, Christian and Vedaldi, Andrea},
  booktitle={ICLR},
  year={2020}
}

% DeepCluster 
@inproceedings{caron2018deep,
  title={Deep clustering for unsupervised learning of visual features},
  author={Caron, Mathilde and Bojanowski, Piotr and Joulin, Armand and Douze, Matthijs},
  booktitle={ECCV},
  pages={132--149},
  year={2018}
}

% SwAV
@inproceedings{caron2020unsupervised,
  title={Unsupervised learning of visual features by contrasting cluster assignments},
  author={Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{ericsson2021well,
  title={How Well Do Self-Supervised Models Transfer?},
  author={Ericsson, Linus and Gouk, Henry and Hospedales, Timothy M},
  booktitle={CVPR},
  pages={5414--5423},
  year={2021}
}




%%%%%%%%%%%%% Survey (v)
@article{li2020federated-survey,
  title={Federated learning: Challenges, methods, and future directions},
  author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  journal={IEEE Signal Processing Magazine},
  volume={37},
  number={3},
  pages={50--60},
  year={2020}
}

@article{konevcny2016federated,
  title={Federated learning: Strategies for improving communication efficiency},
  author={Kone{\v{c}}n{\`y}, Jakub and McMahan, H Brendan and Yu, Felix X and Richt{\'a}rik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
  journal={arXiv preprint arXiv:1610.05492},
  year={2016}
}

@article{kairouz2019advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Keith and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={arXiv preprint arXiv:1912.04977},
  year={2019}
}

@article{yang2019federated,
  title={Federated machine learning: Concept and applications},
  author={Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={10},
  number={2},
  pages={1--19},
  year={2019}
}

@article{bonawitz2019towards,
  title={Towards federated learning at scale: System design},
  author={Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chloe and Kone{\v{c}}n{\`y}, Jakub and Mazzocchi, Stefano and McMahan, H Brendan and others},
  journal={arXiv preprint arXiv:1902.01046},
  year={2019}
}

%%%%%%%%%%%%%% Theory (v)
%% IID
@article{zhou2017convergence,
  title={On the convergence properties of a $ K $-step averaging stochastic gradient descent algorithm for nonconvex optimization},
  author={Zhou, Fan and Cong, Guojing},
  journal={arXiv preprint arXiv:1708.01012},
  year={2017}
}

@article{haddadpour2019convergence,
  title={On the Convergence of Local Descent Methods in Federated Learning},
  author={Haddadpour, Farzin and Mahdavi, Mehrdad},
  journal={arXiv preprint arXiv:1910.14425},
  year={2019}
}

@inproceedings{stich2019local,
  title={Local SGD converges fast and communicates little},
  author={Stich, Sebastian U},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{zinkevich2010parallelized,
  title={Parallelized stochastic gradient descent},
  author={Zinkevich, Martin and Weimer, Markus and Li, Lihong and Smola, Alex J},
  booktitle={NeurIPS},
  year={2010}
}

%% Non-IID (V)

@inproceedings{li2020convergence,
  title={On the convergence of fedavg on non-iid data},
  author={Li, Xiang and Huang, Kaixuan and Yang, Wenhao and Wang, Shusen and Zhang, Zhihua},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{khaled2020tighter,
  title={Tighter theory for local SGD on identical and heterogeneous data},
  author={Khaled, A and Mishchenko, K and Richt{\'a}rik, P},
  booktitle={AISTATS},
  year={2020}
}


%%%% general method (V)

@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, H Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and others},
  booktitle={AISTATS},
  year={2017}
}

%%%%%%%%%%% Optimization (v)

@inproceedings{yang2021achieving,
  title={Achieving Linear Speedup with Partial Worker Participation in Non-IID Federated Learning},
  author={Yang, Haibo and Fang, Minghong and Liu, Jia},
  booktitle={ICLR},
  year={2021}
}

%% global (v)
@article{hsu2019measuring,
  title={Measuring the effects of non-identical data distribution for federated visual classification},
  author={Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew},
  journal={arXiv preprint arXiv:1909.06335},
  year={2019}
}

@inproceedings{reddi2021adaptive,
  title={Adaptive Federated Optimization},
  author={Reddi, Sashank and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Kone{\v{c}}n{\`y}, Jakub and Kumar, Sanjiv and McMahan, H Brendan},
  booktitle={ICLR},
  year={2021}
}

%% local (v)
@inproceedings{malinovskiy2020local,
  title={From Local SGD to Local Fixed-Point Methods for Federated Learning},
  author={Malinovskiy, Grigory and Kovalev, Dmitry and Gasanov, Elnur and Condat, Laurent and Richtarik, Peter},
  booktitle={ICML},
  year={2020}
}

@inproceedings{yuan2020federated,
  title={Federated accelerated stochastic gradient descent},
  author={Yuan, Honglin and Ma, Tengyu},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{pathak2020fedsplit,
  title={FedSplit: An algorithmic framework for fast federated optimization},
  author={Pathak, Reese and Wainwright, Martin J},
  booktitle={NeurIPS},
  year={2020}
}

%%%%%%%%%%% Robust (v)

@article{liang2019variance,
  title={Variance Reduced Local SGD with Lower Communication Complexity},
  author={Liang, Xianfeng and Shen, Shuheng and Liu, Jingchang and Pan, Zhen and Chen, Enhong and Cheng, Yifei},
  journal={arXiv preprint arXiv:1912.12844},
  year={2019}
}

@inproceedings{li2019feddane,
  title={Feddane: A federated newton-type method},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smithy, Virginia},
  booktitle={2019 53rd Asilomar Conference on Signals, Systems, and Computers},
  year={2019}
}

@inproceedings{li2020federated,
  title={Federated optimization in heterogeneous networks},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  booktitle={MLSys},
  year={2020}
}

@article{sahu2018convergence,
  title={On the convergence of federated optimization in heterogeneous networks},
  author={Sahu, Anit Kumar and Li, Tian and Sanjabi, Maziar and Zaheer, Manzil and Talwalkar, Ameet and Smith, Virginia},
  journal={arXiv preprint arXiv:1812.06127},
  year={2018}
}

@inproceedings{
feddyn,
title={Federated Learning Based on Dynamic Regularization},
author={Durmus Alp Emre Acar and Yue Zhao and Ramon Matas and Matthew Mattina and Paul Whatmough and Venkatesh Saligrama},
booktitle={ICLR},
year={2021}
}

@inproceedings{karimireddy2020scaffold,
  title={SCAFFOLD: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={ICML},
  year={2020}
}

@article{karimireddy2020mime,
  title={Mime: Mimicking centralized stochastic algorithms in federated learning},
  author={Karimireddy, Sai Praneeth and Jaggi, Martin and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank J and Stich, Sebastian U and Suresh, Ananda Theertha},
  journal={arXiv preprint arXiv:2008.03606},
  year={2020}
}

@inproceedings{wang2020tackling,
  title={Tackling the objective inconsistency problem in heterogeneous federated optimization},
  author={Wang, Jianyu and Liu, Qinghua and Liang, Hao and Joshi, Gauri and Poor, H Vincent},
  booktitle={NeurIPS},
  year={2020}
}

@article{yao2019federated,
  title={Federated Learning with Unbiased Gradient Aggregation and Controllable Meta Updating},
  author={Yao, Xin and Huang, Tianchi and Zhang, Rui-Xiao and Li, Ruiyu and Sun, Lifeng},
  journal={arXiv preprint arXiv:1910.08234},
  year={2019}
}

%% agnostic (v)

@inproceedings{mohri2019agnostic,
  title={Agnostic federated learning},
  author={Mohri, Mehryar and Sivek, Gary and Suresh, Ananda Theertha},
  booktitle={ICML},
  year={2019}
}

@article{deng2020distributionally,
  title={Distributionally Robust Federated Averaging},
  author={Deng, Yuyang and Kamani, Mohammad Mahdi and Mahdavi, Mehrdad},
  journal={NeurIPS},
  volume={33},
  year={2020}
}

%% IRM
@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1907.02893},
  year={2019}
}

@inproceedings{ahuja2020invariant,
  title={Invariant risk minimization games},
  author={Ahuja, Kartik and Shanmugam, Karthikeyan and Varshney, Kush and Dhurandhar, Amit},
  booktitle={ICML},
  year={2020}
}

%%%%%%%%%%%%% personalized method (v)
%pFedHN
@inproceedings{shamsian2021personalized,
  title={Personalized Federated Learning using Hypernetworks},
  author={Shamsian, Aviv and Navon, Aviv and Fetaya, Ethan and Chechik, Gal},
  booktitle={ICML},
  year={2021}
}

@article{Kulkarni2020SurveyOP,
  title={Survey of Personalization Techniques for Federated Learning},
  author={V. Kulkarni and Milind Kulkarni and A. Pant},
  journal={2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)},
  year={2020},
  pages={794-797}
}

%FedFomo
@inproceedings{
fedfomo,
title={Personalized Federated Learning with First Order Model Optimization},
author={Michael Zhang and Karan Sapra and Sanja Fidler and Serena Yeung and Jose M. Alvarez},
booktitle={ICLR},
year={2021},
url={https://openreview.net/forum?id=ehJqJQk9cw}
}

%MOCHA
@inproceedings{smith2017federated,
  title={Federated multi-task learning},
  author={Smith, Virginia and Chiang, Chao-Kai and Sanjabi, Maziar and Talwalkar, Ameet S},
  booktitle={NeurIPS},
  year={2017}
}

@article{li2020federated-FMTL,
  title={Ditto: Fair and Robust Federated Learning Through},
  author={Li, Tian and Hu, Shengyuan and Beirami, Ahmad and Smith, Virginia},
  journal={arXiv preprint arXiv:2012.04221},
  year={2020}
}

%Per-FedAvg
@inproceedings{fallah2020personalized,
  title={Personalized federated learning: A meta-learning approach},
  author={Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},
  booktitle={NeurIPS},
  year={2020}
}

@article{Jiang2019ImprovingFL,
  title={Improving Federated Learning Personalization via Model Agnostic Meta Learning},
  author={Yihan Jiang and Jakub Konecn{\'y} and Keith Rush and S. Kannan},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.12488}
}

@article{Chen2018FederatedMW,
  title={Federated Meta-Learning with Fast Convergence and Efficient Communication},
  author={Fei Chen and Mi Luo and Zhenhua Dong and Zhenguo Li and X. He},
  journal={arXiv: Learning},
  year={2018}
}

@inproceedings{Khodak2019AdaptiveGM,
  title={Adaptive Gradient-Based Meta-Learning Methods},
  author={M. Khodak and Maria-Florina Balcan and Ameet Talwalkar},
  booktitle={NeurIPS},
  year={2019}
}

%pFedMe
@inproceedings{dinh2020personalized,
  title={Personalized federated learning with Moreau envelopes},
  author={Dinh, Canh T and Tran, Nguyen H and Nguyen, Tuan Dung},
  booktitle={NeurIPS},
  year={2020}
}

%LG-FedAvg
@article{liang2020think,
  title={Think locally, act globally: Federated learning with local and global representations},
  author={Liang, Paul Pu and Liu, Terrance and Ziyin, Liu and Salakhutdinov, Ruslan and Morency, Louis-Philippe},
  journal={arXiv preprint arXiv:2001.01523},
  year={2020}
}

@article{agarwal2020federated,
  title={Federated residual learning},
  author={Agarwal, Alekh and Langford, John and Wei, Chen-Yu},
  journal={arXiv preprint arXiv:2003.12880},
  year={2020}
}

@article{corinzia2019variational,
  title={Variational federated multi-task learning},
  author={Corinzia, Luca and Buhmann, Joachim M},
  journal={arXiv preprint arXiv:1906.06268},
  year={2019}
}

@inproceedings{hanzely2020lower,
  title={Lower bounds and optimal algorithms for personalized federated learning},
  author={Hanzely, Filip and Hanzely, Slavom{\'\i}r and Horv{\'a}th, Samuel and Richt{\'a}rik, Peter},
  booktitle={NeurIPS},
  year={2020}
}

@article{hanzely2020federated,
  title={Federated learning of a mixture of global and local models},
  author={Hanzely, Filip and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2002.05516},
  year={2020}
}

@inproceedings{Huang2021PersonalizedCF,
  title={Personalized Cross-Silo Federated Learning on Non-IID Data},
  author={Yutao Huang and Lingyang Chu and Z. Zhou and Lanjun Wang and J. Liu and Jian Pei and Yanxin Zhang},
 booktitle={AAAI},
  year={2021}
}


@article{zec2020federated,
  title={Federated learning using a mixture of experts},
  author={Zec, Edvin Listo and Mogren, Olof and Martinsson, John and S{\"u}tfeld, Leon Ren{\'e} and Gillblad, Daniel},
  journal={arXiv preprint arXiv:2010.02056},
  year={2020}
}

@misc{
reisser2021federated,
title={Federated Mixture of Experts},
author={Matthias Reisser and Christos Louizos and Efstratios Gavves and Max Welling},
year={2021},
url={https://openreview.net/forum?id=YgrdmztE4OY}
}

@inproceedings{
li2021fedbn,
title={Fed{\{}BN{\}}: Federated Learning on Non-{\{}IID{\}} Features via Local Batch Normalization},
author={Xiaoxiao Li and Meirui JIANG and Xiaofei Zhang and Michael Kamp and Qi Dou},
booktitle={ICLR},
year={2021}
}

@article{bui2019federated,
  title={Federated user representation learning},
  author={Bui, Duc and Malik, Kshitiz and Goetz, Jack and Liu, Honglei and Moon, Seungwhan and Kumar, Anuj and Shin, Kang G},
  journal={arXiv preprint arXiv:1909.12535},
  year={2019}
}

@article{arivazhagan2019federated,
  title={Federated learning with personalization layers},
  author={Arivazhagan, Manoj Ghuhan and Aggarwal, Vinay and Singh, Aaditya Kumar and Choudhary, Sunav},
  journal={arXiv preprint arXiv:1912.00818},
  year={2019}
}

@article{peterson2019private,
  title={Private federated learning with domain adaptation},
  author={Peterson, Daniel and Kanani, Pallika and Marathe, Virendra J},
  journal={arXiv preprint arXiv:1912.06733},
  year={2019}
}

@article{deng2020adaptive,
  title={Adaptive personalized federated learning},
  author={Deng, Yuyang and Kamani, Mohammad Mahdi and Mahdavi, Mehrdad},
  journal={arXiv preprint arXiv:2003.13461},
  year={2020}
}

@article{mansour2020three,
  title={Three approaches for personalization with applications to federated learning},
  author={Mansour, Yishay and Mohri, Mehryar and Ro, Jae and Suresh, Ananda Theertha},
  journal={arXiv preprint arXiv:2002.10619},
  year={2020}
}

@article{yu2020salvaging,
  title={Salvaging federated learning by local adaptation},
  author={Yu, Tao and Bagdasaryan, Eugene and Shmatikov, Vitaly},
  journal={arXiv preprint arXiv:2002.04758},
  year={2020}
}

@article{Wang2019FederatedEO,
  title={Federated Evaluation of On-device Personalization},
  author={Kangkang Wang and Rajiv Mathews and Chlo{\'e} Kiddon and Hubert Eichner and Franccoise Beaufays and D. Ramage},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.10252}
}

%%%% MTL (V)
@article{zhang2017survey,
  title={A survey on multi-task learning},
  author={Zhang, Yu and Yang, Qiang},
  journal={arXiv preprint arXiv:1707.08114},
  year={2017}
}

@inproceedings{evgeniou2004regularized,
  title={Regularized multi--task learning},
  author={Evgeniou, Theodoros and Pontil, Massimiliano},
  booktitle={KDD},
  year={2004}
}

@article{ruder2017overview,
  title={An overview of multi-task learning in deep neural networks},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1706.05098},
  year={2017}
}

@inproceedings{evgeniou2007multi,
  title={Multi-task feature learning},
  author={Evgeniou, An and Pontil, Massimiliano},
  booktitle={NeurIPS},
  year={2007}
}

@inproceedings{jacob2009clustered,
  title={Clustered multi-task learning: A convex formulation},
  author={Jacob, Laurent and Bach, Francis and Vert, Jean-Philippe},
  booktitle={NeurIPS},
  year={2009}
}

@inproceedings{zhang2010convex,
  title={A convex formulation for learning task relationships in multi-task learning},
  author={Zhang, Yu and Yeung, Dit-Yan},
  journal={UAI},
  year={2010}
}

%%%%% Domain generalization
@inproceedings{li2017deeper,
  title={Deeper, broader and artier domain generalization},
  author={Li, Da and Yang, Yongxin and Song, Yi-Zhe and Hospedales, Timothy M},
  booktitle={ICCV},
  year={2017}
}

@inproceedings{Gong2013ConnectingTD,
  title={Connecting the Dots with Landmarks: Discriminatively Learning Domain-Invariant Features for Unsupervised Domain Adaptation},
  author={Boqing Gong and K. Grauman and F. Sha},
  booktitle={ICML},
  year={2013}
}

@inproceedings{long2018conditional,
  title={Conditional adversarial domain adaptation},
  author={Long, Mingsheng and Cao, Zhangjie and Wang, Jianmin and Jordan, Michael I},
  booktitle={Conference on Neural Information Processing Systems},
  year={2018}
}

@article{ben2010theory,
  title={A theory of learning from different domains},
  author={Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman},
  journal={Machine learning},
  volume={79},
  number={1},
  pages={151--175},
  year={2010},
  publisher={Springer}
}

@inproceedings{zhang2013domain,
  title={Domain adaptation under target and conditional shift},
  author={Zhang, Kun and Sch{\"o}lkopf, Bernhard and Muandet, Krikamol and Wang, Zhikun},
  booktitle={International Conference on Machine Learning},
  pages={819--827},
  year={2013},
  organization={PMLR}
}

@inproceedings{gong2012geodesic,
  title={Geodesic flow kernel for unsupervised domain adaptation},
  author={Gong, Boqing and Shi, Yuan and Sha, Fei and Grauman, Kristen},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  pages={2066--2073},
  year={2012},
  organization={IEEE}
}

@article{ganin2016domain,
  title={Domain-adversarial training of neural networks},
  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario and Lempitsky, Victor},
  journal={The journal of machine learning research},
  volume={17},
  number={1},
  pages={2096--2030},
  year={2016}
}

@inproceedings{ghifary2015domain,
  title={Domain generalization for object recognition with multi-task autoencoders},
  author={Ghifary, Muhammad and Kleijn, W Bastiaan and Zhang, Mengjie and Balduzzi, David},
  booktitle={ICCV},
  year={2015}
}

@inproceedings{li2018domain,
  title={Domain generalization with adversarial feature learning},
  author={Li, Haoliang and Pan, Sinno Jialin and Wang, Shiqi and Kot, Alex C},
  booktitle={CVPR},
  year={2018}
}
@inproceedings{muandet2013domain,
  title={Domain generalization via invariant feature representation},
  author={Muandet, Krikamol and Balduzzi, David and Sch{\"o}lkopf, Bernhard},
  booktitle={ICML},
  year={2013}
}


%%%% imbalance algorithm (V)
%%% basic study

@article{krawczyk2016learning,
  title={Learning from imbalanced data: open challenges and future directions},
  author={Krawczyk, Bartosz},
  journal={Progress in Artificial Intelligence},
  volume={5},
  number={4},
  pages={221--232},
  year={2016},
  publisher={Springer}
}

% BasicUnder
@inproceedings{japkowicz2000class,
  title={The class imbalance problem: Significance and strategies},
  author={Japkowicz, Nathalie},
  booktitle={Proc. of the Int’l Conf. on Artificial Intelligence},
  year={2000}
}

@article{japkowicz2002the,
  title={The class imbalance problem: A systematic study},
  author={Japkowicz, Nathalie and Stephen, Shaju},
  journal={Intelligent data analysis},
  volume={6},
  number={5},
  pages={429--449},
  year={2002},
  publisher={IOS Press}
}

% BasicSurvey2019
@article{johnson2019survey,
  title={Survey on deep learning with class imbalance},
  author={Johnson, Justin M and Khoshgoftaar, Taghi M},
  journal={Journal of Big Data},
  volume={6},
  number={1},
  pages={27},
  year={2019}
}

% BasicSystematic
@article{buda2018systematic,
  title={A systematic study of the class imbalance problem in convolutional neural networks},
  author={Buda, Mateusz and Maki, Atsuto and Mazurowski, Maciej A},
  journal={Neural Networks},
  volume={106},
  pages={249--259},
  year={2018}
}

% BasicLearnfromImb
@article{he2009learning,
  title={Learning from imbalanced data},
  author={He, Haibo and Garcia, Edwardo A},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={21},
  number={9},
  pages={1263--1284},
  year={2009}
}

% Datasets
@inproceedings{Cordts2015Cvprw,
title={The Cityscapes Dataset},
author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Scharw{\"a}chter, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
booktitle={CVPR Workshop on The Future of Datasets in Vision},
year={2015}
}

@article{zhou2017places,
title={Places: A 10 million Image Database for Scene Recognition},
author={Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
year={2017},
publisher={IEEE}
}


@inproceedings{gupta2019lvis,
  title={LVIS: A dataset for large vocabulary instance segmentation},
  author={Gupta, Agrim and Dollar, Piotr and Girshick, Ross},
  booktitle={CVPR},
  year={2019}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={IJCV},
  volume={115},
  number={3},
  pages={211--252},
  year={2015}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  year={2009}
}

@inproceedings{van2018inaturalist,
  title={The inaturalist species classification and detection dataset},
  author={Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
  booktitle={CVPR},
  year={2018}
}

@article{van2017devil,
  title={The devil is in the tails: Fine-grained classification in the wild},
  author={Van Horn, Grant and Perona, Pietro},
  journal={arXiv preprint arXiv:1709.01450},
  year={2017}
}

@article{khan2017cost,
  title={Cost-sensitive learning of deep feature representations from imbalanced data},
  author={Khan, Salman H and Hayat, Munawar and Bennamoun, Mohammed and Sohel, Ferdous A and Togneri, Roberto},
  journal={IEEE transactions on neural networks and learning systems},
  volume={29},
  number={8},
  pages={3573--3587},
  year={2017}
}

@article{cao2019learning,
  title={Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss},
  author={Cao, Kaidi and Wei, Colin and Gaidon, Adrien and Arechiga, Nikos and Ma, Tengyu},
  journal={Conference on Neural Information Processing Systems},
  year={2019}
}

@inproceedings{cui2019class,
  title={Class-balanced loss based on effective number of samples},
  author={Cui, Yin and Jia, Menglin and Lin, Tsung-Yi and Song, Yang and Belongie, Serge},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{kang2019decoupling,
  title={Decoupling Representation and Classifier for Long-Tailed Recognition},
  author={Kang, Bingyi and Xie, Saining and Rohrbach, Marcus and Yan, Zhicheng and Gordo, Albert and Feng, Jiashi and Kalantidis, Yannis},
  booktitle={ICLR},
  year={2020}
}

% weightingLearn2Reweight
@inproceedings{ren2018learning,
  title={Learning to reweight examples for robust deep learning},
  author={Ren, Mengye and Zeng, Wenyuan and Yang, Bin and Urtasun, Raquel},
  booktitle={ICML},
  year={2018}
}

@inproceedings{Shu2019Meta,
  author    = {Jun Shu and
               Qi Xie and
               Lixuan Yi and
               Qian Zhao and
               Sanping Zhou and
               Zongben Xu and
               Deyu Meng},
  title     = {Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting},
  booktitle = {NeurIPS},
  year      = {2019}
}

@article{ye2020identifying,
  title={Identifying and compensating for feature deviation in imbalanced deep learning},
  author={Ye, Han-Jia and Chen, Hong-You and Zhan, De-Chuan and Chao, Wei-Lun},
  journal={arXiv preprint arXiv:2001.01385},
  year={2020}
}

@inproceedings{ren2020balanced,
  title={Balanced Meta-Softmax for Long-Tailed Visual Recognition},
  author={Ren, Jiawei and Yu, Cunjun and Sheng, Shunan and Ma, Xiao and Zhao, Haiyu and Yi, Shuai and Li, Hongsheng},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{li2020overcoming,
  title={Overcoming Classifier Imbalance for Long-Tail Object Detection With Balanced Group Softmax},
  author={Li, Yu and Wang, Tao and Kang, Bingyi and Tang, Sheng and Wang, Chunfeng and Li, Jintao and Feng, Jiashi},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{tan2020equalization,
  title={Equalization Loss for Long-Tailed Object Recognition},
  author={Tan, Jingru and Wang, Changbao and Li, Buyu and Li, Quanquan and Ouyang, Wanli and Yin, Changqing and Yan, Junjie},
  booktitle={CVPR},
  year={2020}
}

%%%% imbalance federated method (v)
@article{yang2020federated,
  title={Federated learning with class imbalance reduction},
  author={Yang, Miao and Wong, Akitanoshou and Zhu, Hongbin and Wang, Haifeng and Qian, Hua},
  journal={arXiv preprint arXiv:2011.11266},
  year={2020}
}

@article{duan2020self,
  title={Self-balancing federated learning with global imbalanced data in mobile systems},
  author={Duan, Moming and Liu, Duo and Chen, Xianzhang and Liu, Renping and Tan, Yujuan and Liang, Liang},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={32},
  number={1},
  pages={59--71},
  year={2020}
}

@inproceedings{duan2019astraea,
  title={Astraea: Self-balancing federated learning for improving classification accuracy of mobile deep learning applications},
  author={Duan, Moming and Liu, Duo and Chen, Xianzhang and Tan, Yujuan and Ren, Jinting and Qiao, Lei and Liang, Liang},
  booktitle={2019 IEEE 37th International Conference on Computer Design (ICCD)},
  year={2019}
}

@article{sarkar2020fed,
  title={Fed-Focal Loss for imbalanced data classification in Federated Learning},
  author={Sarkar, Dipankar and Narang, Ankur and Rai, Sumit},
  journal={arXiv preprint arXiv:2011.06283},
  year={2020}
}

@inproceedings{wang2020towards,
  title={Addressing Class Imbalance in Federated Learning},
  author={Wang, Lixu and Xu, Shichao and Wang, Xiao and Zhu, Qi},
  booktitle={AAAI},
  year={2020}
}

@inproceedings{hsu2020federated,
  title={Federated visual classification with real-world data distribution},
  author={Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew},
  booktitle={ECCV},
  year={2020},
}

%%%%%%%%% Models (V)
@inproceedings{ha2016hypernetworks,
  title={Hypernetworks},
  author={Ha, David and Dai, Andrew and Le, Quoc V},
  booktitle={ICLR},
  year={2017}
}

@inproceedings{changpinyo2016synthesized,
  title={Synthesized classifiers for zero-shot learning},
  author={Changpinyo, Soravit and Chao, Wei-Lun and Gong, Boqing and Sha, Fei},
  booktitle={CVPR},
  year={2016}
}

@article{changpinyo2020classifier,
  title={Classifier and exemplar synthesis for zero-shot learning},
  author={Changpinyo, Soravit and Chao, Wei-Lun and Gong, Boqing and Sha, Fei},
  journal={IJCV},
  volume={128},
  number={1},
  pages={166--201},
  year={2020}
}

@article{xian2018zero,
  title={Zero-shot learning—a comprehensive evaluation of the good, the bad and the ugly},
  author={Xian, Yongqin and Lampert, Christoph H and Schiele, Bernt and Akata, Zeynep},
  journal={TPAMI},
  volume={41},
  number={9},
  pages={2251--2265},
  year={2018}
}

@inproceedings{zhang2017learning,
  title={Learning a deep embedding model for zero-shot learning},
  author={Zhang, Li and Xiang, Tao and Gong, Shaogang},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{lei2015predicting,
  title={Predicting deep zero-shot convolutional neural networks using textual descriptions},
  author={Lei Ba, Jimmy and Swersky, Kevin and Fidler, Sanja and others},
  booktitle={ICCV},
  year={2015}
}

@inproceedings{changpinyo2017predicting,
  title={Predicting visual exemplars of unseen classes for zero-shot learning},
  author={Changpinyo, Soravit and Chao, Wei-Lun and Sha, Fei},
  booktitle={ICCV},
  year={2017}
}

@article{lampert2013attribute,
  title={Attribute-based classification for zero-shot visual object categorization},
  author={Lampert, Christoph H and Nickisch, Hannes and Harmeling, Stefan},
  journal={TPAMI},
  volume={36},
  number={3},
  pages={453--465},
  year={2013}
  }

%% Ensemble (v)

@inproceedings{chen2021fedbe,
  title={FEDBE: Making Bayesian Model Ensemble Applicable to Federated Learning},
  author={Chen, Hong-You and Chao, Wei-Lun},
booktitle={ICLR},
  year={2021}
}

@inproceedings{lin2020ensemble,
  title={Ensemble Distillation for Robust Model Fusion in Federated Learning},
  author={Lin, Tao and Kong, Lingjing and Stich, Sebastian U and Jaggi, Martin},
  booktitle={NeurIPS},
  year={2020}
}

@article{sun2020federated,
  title={Federated model distillation with noise-free differential privacy},
  author={Sun, Lichao and Lyu, Lingjuan},
  journal={arXiv preprint arXiv:2009.05537},
  year={2020}
}

@inproceedings{he2020group,
  title={Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge},
  author={He, Chaoyang and Annavaram, Murali and Avestimehr, Salman},
  booktitle={NeurIPS},
  year={2020}
}

@article{zhou2020distilled,
  title={Distilled One-Shot Federated Learning},
  author={Zhou, Yanlin and Pu, George and Ma, Xiyao and Li, Xiaolin and Wu, Dapeng},
  journal={arXiv preprint arXiv:2009.07999},
  year={2020}
}

@inproceedings{papernot2017semi,
  title={Semi-supervised knowledge transfer for deep learning from private training data},
  author={Papernot, Nicolas and Abadi, Mart{\'\i}n and Erlingsson, Ulfar and Goodfellow, Ian and Talwar, Kunal},
  booktitle={ICLR},
  year={2017}
}

@article{li2019fedmd,
  title={FedMD: Heterogenous Federated Learning via Model Distillation},
  author={Li, Daliang and Wang, Junpu},
  journal={arXiv preprint arXiv:1910.03581},
  year={2019}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@article{guha2019one,
  title={One-shot federated learning},
  author={Guha, Neel and Talwlkar, Ameet and Smith, Virginia},
  journal={arXiv preprint arXiv:1902.11175},
  year={2019}
}

@article{jeong2018communication,
  title={Communication-efficient on-device machine learning: Federated distillation and augmentation under non-iid private data},
  author={Jeong, Eunjeong and Oh, Seungeun and Kim, Hyesung and Park, Jihong and Bennis, Mehdi and Kim, Seong-Lyun},
  journal={arXiv preprint arXiv:1811.11479},
  year={2018}
}

%% Aggregation (v)
@inproceedings{wang2020federated,
  title={Federated learning with matched averaging},
  author={Wang, Hongyi and Yurochkin, Mikhail and Sun, Yuekai and Papailiopoulos, Dimitris and Khazaeni, Yasaman},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{yurochkin2019bayesian,
  title={Bayesian nonparametric federated learning of neural networks},
  author={Yurochkin, Mikhail and Agarwal, Mayank and Ghosh, Soumya and Greenewald, Kristjan and Hoang, Trong Nghia and Khazaeni, Yasaman},
  booktitle={ICML},
  year={2019}
}

%%%% Fed ??
@article{shoham2019overcoming,
  title={Overcoming Forgetting in Federated Learning on Non-IID Data},
  author={Shoham, Neta and Avidor, Tomer and Keren, Aviv and Israel, Nadav and Benditkis, Daniel and Mor-Yosef, Liron and Zeitak, Itai},
  journal={arXiv preprint arXiv:1910.07796},
  year={2019}
}
@article{yao2020continual,
  title={Continual Local Training for Better Initialization of Federated Models},
  author={Yao, Xin and Sun, Lifeng},
  journal={2020 IEEE International Conference on Image Processing},
  year={2020}
}

@article{reisizadeh2019fedpaq,
  title={Fedpaq: A communication-efficient federated learning method with periodic averaging and quantization},
  author={Reisizadeh, Amirhossein and Mokhtari, Aryan and Hassani, Hamed and Jadbabaie, Ali and Pedarsani, Ramtin},
  journal={arXiv preprint arXiv:1909.13014},
  year={2019}
}

@article{caldas2018leaf,
  title={Leaf: A benchmark for federated settings},
  author={Caldas, Sebastian and Wu, Peter and Li, Tian and Kone{\v{c}}n{\`y}, Jakub and McMahan, H Brendan and Smith, Virginia and Talwalkar, Ameet},
  journal={arXiv preprint arXiv:1812.01097},
  year={2018}
}

@inproceedings{peng2020federated,
  title={Federated Adversarial Domain Adaptation},
  author={Peng, Xingchao and Huang, Zijun and Zhu, Yizhe and Saenko, Kate},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{sagawa2020distributionally,
  title={Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle={ICLR},
  year={2020}
}

%%%%%%%%%%%%%%%%%%%% Others general ML

%% Data
@inproceedings{cohen2017emnist,
  title={EMNIST: Extending MNIST to handwritten letters},
  author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and Van Schaik, Andre},
  booktitle={IJCNN},
  year={2017}
}

@article{le2015tiny,
  title={Tiny imagenet visual recognition challenge},
  author={Le, Ya and Yang, Xuan},
  journal={CS 231N},
  year={2015}
}

@inproceedings{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Wierstra, Daan and others},
  booktitle={NeurIPS},
  year={2016}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009}
}


%% Model
@inproceedings{muller2019does,
  title={When does label smoothing help?},
  author={M{\"u}ller, Rafael and Kornblith, Simon and Hinton, Geoffrey E},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4694--4703},
  year={2019}
}

@inproceedings{guo2017calibration,
  title={On calibration of modern neural networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  journal={ICML},
  year={2017}
}

@article{howard2017mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  booktitle={arXiv preprint arXiv:1704.04861},
  year={2017}
}
@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4510--4520},
  year={2018}
}

@inproceedings{Simonyan15,
  author       = "Karen Simonyan and Andrew Zisserman",
  title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
  booktitle    = "International Conference on Learning Representations",
  year         = "2015",
}

@article{chang2011libsvm,
  title={LIBSVM: A library for support vector machines},
  author={Chang, Chih-Chung and Lin, Chih-Jen},
  journal={ACM transactions on intelligent systems and technology (TIST)},
  volume={2},
  number={3},
  pages={1--27},
  year={2011}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}
@misc{Idelbayev18a,
  author       = "Yerlan Idelbayev",
  title        = "Proper {ResNet} Implementation for {CIFAR10/CIFAR100} in {PyTorch}",
  howpublished = "\url{https://github.com/akamaster/pytorch_resnet_cifar10}",
  note         = "Accessed: 2020-June-03"
}

@misc{tfconvnet16,
  author       = "{TensorFlow team}",
  title        = "Tensorflow convolutional neural networks tutorial",
  howpublished = "\url{http://www.tensorflow.org/tutorials/deep_cnn}",
  year={2016}
}

@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}

@article{maaten2008visualizing,
  title={Visualizing data using t-SNE},
  author={Maaten, Laurens van der and Hinton, Geoffrey},
  journal={JMLR},
  volume={9},
  number={Nov},
  pages={2579--2605},
  year={2008}
}

@article{Xiao2017FashionMNISTAN,
  title={Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
  author={H. Xiao and K. Rasul and Roland Vollgraf},
  journal={ArXiv},
  year={2017},
  volume={abs/1708.07747}
}

@article{clanuwat2018deep,
  title={Deep learning for classical japanese literature},
  author={Clanuwat, Tarin and Bober-Irizar, Mikel and Kitamoto, Asanobu and Lamb, Alex and Yamamoto, Kazuaki and Ha, David},
  journal={arXiv preprint arXiv:1812.01718},
  year={2018}
}

%%%%%%%%%%%%%%%%

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{he2019rethinking,
  title={Rethinking imagenet pre-training},
  author={He, Kaiming and Girshick, Ross and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4918--4927},
  year={2019}
}



@article{mishra2021task2sim,
  title={Task2Sim: Towards Effective Pre-training and Transfer from Synthetic Data},
  author={Mishra, Samarth and Panda, Rameswar and Phoo, Cheng Perng and Chen, Chun-Fu and Karlinsky, Leonid and Saenko, Kate and Saligrama, Venkatesh and Feris, Rogerio S},
  journal={arXiv preprint arXiv:2112.00054},
  year={2021}
}

@article{bowles2018gan,
  title={Gan augmentation: Augmenting training data using generative adversarial networks},
  author={Bowles, Christopher and Chen, Liang and Guerrero, Ricardo and Bentley, Paul and Gunn, Roger and Hammers, Alexander and Dickie, David Alexander and Hern{\'a}ndez, Maria Vald{\'e}s and Wardlaw, Joanna and Rueckert, Daniel},
  journal={arXiv preprint arXiv:1810.10863},
  year={2018}
}

@inproceedings{prakash2019structured,
  title={Structured domain randomization: Bridging the reality gap by context-aware synthetic data},
  author={Prakash, Aayush and Boochoon, Shaad and Brophy, Mark and Acuna, David and Cameracci, Eric and State, Gavriel and Shapira, Omer and Birchfield, Stan},
  booktitle={ICRA},
  pages={7249--7255},
  year={2019},
  organization={IEEE}
}

@article{mikami2021scaling,
  title={A Scaling Law for Synthetic-to-Real Transfer: How Much Is Your Pre-training Effective?},
  author={Mikami, Hiroaki and Fukumizu, Kenji and Murai, Shogo and Suzuki, Shuji and Kikuchi, Yuta and Suzuki, Taiji and Maeda, Shin-ichi and Hayashi, Kohei},
  journal={arXiv preprint arXiv:2108.11018},
  year={2021}
}

@article{gan2020threedworld,
  title={Threedworld: A platform for interactive multi-modal physical simulation},
  author={Gan, Chuang and Schwartz, Jeremy and Alter, Seth and Schrimpf, Martin and Traer, James and De Freitas, Julian and Kubilius, Jonas and Bhandwaldar, Abhishek and Haber, Nick and Sano, Megumi and others},
  journal={arXiv preprint arXiv:2007.04954},
  year={2020}
}

@inproceedings{peng2015learning,
  title={Learning deep object detectors from 3d models},
  author={Peng, Xingchao and Sun, Baochen and Ali, Karim and Saenko, Kate},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1278--1286},
  year={2015}
}

@article{eilertsen2021ensembles,
  title={Ensembles of GANs for synthetic training data generation},
  author={Eilertsen, Gabriel and Tsirikoglou, Apostolia and Lundstr{\"o}m, Claes and Unger, Jonas},
  journal={arXiv preprint arXiv:2104.11797},
  year={2021}
}

@article{mayer2018makes,
  title={What makes good synthetic training data for learning disparity and optical flow estimation?},
  author={Mayer, Nikolaus and Ilg, Eddy and Fischer, Philipp and Hazirbas, Caner and Cremers, Daniel and Dosovitskiy, Alexey and Brox, Thomas},
  journal={IJCV},
  volume={126},
  number={9},
  pages={942--960},
  year={2018},
  publisher={Springer}
}

@book{barnsley2014fractals,
  title={Fractals everywhere},
  author={Barnsley, Michael F},
  year={2014},
  publisher={Academic press}
}

@article{liu2021self,
  title={Self-supervised learning: Generative or contrastive},
  author={Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Mian, Li and Wang, Zhaoyu and Zhang, Jing and Tang, Jie},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2021},
  publisher={IEEE}
}

@inproceedings{cordts2016cityscapes,
  title={The cityscapes dataset for semantic urban scene understanding},
  author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
  booktitle={CVPR},
  pages={3213--3223},
  year={2016}
}

@article{cheng2021fine,
  title={Fine-tuning is fine in federated learning},
  author={Cheng, Gary and Chadha, Karan and Duchi, John},
  journal={arXiv preprint arXiv:2108.07313},
  year={2021}
}

@article{qu2021rethinking,
  title={Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning},
  author={Qu, Liangqiong and Zhou, Yuyin and Liang, Paul Pu and Xia, Yingda and Wang, Feifei and Fei-Fei, Li and Adeli, Ehsan and Rubin, Daniel},
  journal={arXiv preprint arXiv:2106.06047},
  year={2021}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@article{french1999catastrophic,
  title={Catastrophic forgetting in connectionist networks},
  author={French, Robert M},
  journal={Trends in cognitive sciences},
  volume={3},
  number={4},
  pages={128--135},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{kolesnikov2020big,
  title={Big transfer (bit): General visual representation learning},
  author={Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
  booktitle={ECCV},
  pages={491--507},
  year={2020},
  organization={Springer}
}

@inproceedings{Radford2021LearningTV,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  booktitle={ICML},
  year={2021}
}

@article{goyal2021self,
  title={Self-supervised pretraining of visual features in the wild},
  author={Goyal, Priya and Caron, Mathilde and Lefaudeux, Benjamin and Xu, Min and Wang, Pengchao and Pai, Vivek and Singh, Mannat and Liptchinsky, Vitaliy and Misra, Ishan and Joulin, Armand and others},
  journal={arXiv preprint arXiv:2103.01988},
  year={2021}
}

@inproceedings{sun2017revisiting,
  title={Revisiting unreasonable effectiveness of data in deep learning era},
  author={Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  booktitle={ICCV},
  pages={843--852},
  year={2017}
}


@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={NeurIPS},
  volume={28},
  pages={91--99},
  year={2015}
}

@article{bochkovskiy2020yolov4,
  title={Yolov4: Optimal speed and accuracy of object detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2004.10934},
  year={2020}
}

@inproceedings{wei2021metaalign,
  title={MetaAlign: Coordinating Domain Alignment and Classification for Unsupervised Domain Adaptation},
  author={Wei, Guoqiang and Lan, Cuiling and Zeng, Wenjun and Chen, Zhibo},
  booktitle={CVPR},
  pages={16643--16653},
  year={2021}
}

@inproceedings{saito2018maximum,
  title={Maximum classifier discrepancy for unsupervised domain adaptation},
  author={Saito, Kuniaki and Watanabe, Kohei and Ushiku, Yoshitaka and Harada, Tatsuya},
  booktitle={CVPR},
  pages={3723--3732},
  year={2018}
}

@inproceedings{wang2019multi,
  title={Multi-similarity loss with general pair weighting for deep metric learning},
  author={Wang, Xun and Han, Xintong and Huang, Weilin and Dong, Dengke and Scott, Matthew R},
  booktitle={CVPR},
  pages={5022--5030},
  year={2019}
}

@inproceedings{wang2020cross,
  title={Cross-batch memory for embedding learning},
  author={Wang, Xun and Zhang, Haozhi and Huang, Weilin and Scott, Matthew R},
  booktitle={CVPR},
  pages={6388--6397},
  year={2020}
}

@inproceedings{brown2020language,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {NeurIPS},
 pages = {1877--1901},
 title = {Language Models are Few-Shot Learners},
 volume = {33},
 year = {2020}
}

@article{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={NeurIPS},
  volume={32},
  year={2019}
}

@inproceedings{chen2020adversarial,
  title={Adversarial robustness: From self-supervised pre-training to fine-tuning},
  author={Chen, Tianlong and Liu, Sijia and Chang, Shiyu and Cheng, Yu and Amini, Lisa and Wang, Zhangyang},
  booktitle={CVPR},
  pages={699--708},
  year={2020}
}

@inproceedings{hendrycks2019using,
  title={Using pre-training can improve model robustness and uncertainty},
  author={Hendrycks, Dan and Lee, Kimin and Mazeika, Mantas},
  booktitle={ICML},
  pages={2712--2721},
  year={2019},
  organization={PMLR}
}

@article{hendrycks2020pretrained,
  title={Pretrained transformers improve out-of-distribution robustness},
  author={Hendrycks, Dan and Liu, Xiaoyuan and Wallace, Eric and Dziedzic, Adam and Krishnan, Rishabh and Song, Dawn},
  journal={arXiv preprint arXiv:2004.06100},
  year={2020}
}

@inproceedings{neyshabur2020being,
  title={What is being transferred in transfer learning?},
  author={Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{djolonga2021robustness,
  title={On robustness and transferability of convolutional neural networks},
  author={Djolonga, Josip and Yung, Jessica and Tschannen, Michael and Romijnders, Rob and Beyer, Lucas and Kolesnikov, Alexander and Puigcerver, Joan and Minderer, Matthias and D'Amour, Alexander and Moldovan, Dan and others},
  booktitle={CVPR},
  pages={16458--16468},
  year={2021}
}

@article{tamkin2020investigating,
  title={Investigating transferability in pretrained language models},
  author={Tamkin, Alex and Singh, Trisha and Giovanardi, Davide and Goodman, Noah},
  journal={arXiv preprint arXiv:2004.14975},
  year={2020}
}

@inproceedings{kornblith2019better,
  title={Do better imagenet models transfer better?},
  author={Kornblith, Simon and Shlens, Jonathon and Le, Quoc V},
  booktitle={CVPR},
  pages={2661--2671},
  year={2019}
}

@article{mehta2021empirical,
  title={An empirical investigation of the role of pre-training in lifelong learning},
  author={Mehta, Sanket Vaibhav and Patil, Darshan and Chandar, Sarath and Strubell, Emma},
  journal={arXiv preprint arXiv:2112.09153},
  year={2021}
}
@inproceedings{erhan2010does,
  title={Why does unsupervised pre-training help deep learning?},
  author={Erhan, Dumitru and Courville, Aaron and Bengio, Yoshua and Vincent, Pascal},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={201--208},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{zoph2020rethinking,
  title={Rethinking pre-training and self-training},
  author={Zoph, Barret and Ghiasi, Golnaz and Lin, Tsung-Yi and Cui, Yin and Liu, Hanxiao and Cubuk, Ekin D and Le, Quoc V},
  journal={arXiv preprint arXiv:2006.06882},
  year={2020}
}

@article{zhang2019fixup,
  title={Fixup initialization: Residual learning without normalization},
  author={Zhang, Hongyi and Dauphin, Yann N and Ma, Tengyu},
  journal={arXiv preprint arXiv:1901.09321},
  year={2019}
}
%adam
@inproceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={ICLR},
  year={2015}
}
%deeplabplus
@inproceedings{chen2018encoder,
  title={Encoder-decoder with atrous separable convolution for semantic image segmentation},
  author={Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={801--818},
  year={2018}
}


@article{cubuk2018autoaugment,
  title={Autoaugment: Learning augmentation policies from data},
  author={Cubuk, Ekin D and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V},
  journal={arXiv preprint arXiv:1805.09501},
  year={2018}
}

@inproceedings{cubuk2020randaugment,
  title={Randaugment: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={CVPR},
  pages={702--703},
  year={2020}
}

@misc{pytorchimagent,
  title = {ImageNet training in PyTorch},
  howpublished = {\url{https://github.com/pytorch/examples/tree/master/imagenet}},
  note = {Accessed: 2022-01-27}
}

@inproceedings{reed2021selfaugment,
  title={Selfaugment: Automatic augmentation policies for self-supervised learning},
  author={Reed, Colorado J and Metzger, Sean and Srinivas, Aravind and Darrell, Trevor and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2674--2683},
  year={2021}
}
@inproceedings{li2021model,
  title={Model-Contrastive Federated Learning},
  author={Li, Qinbin and He, Bingsheng and Song, Dawn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10713--10722},
  year={2021}
}

@inproceedings{loshchilov2017sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={ICLR},
  year={2017}
}

@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}
@inproceedings{hsieh2020non,
  title={The non-iid data quagmire of decentralized machine learning},
  author={Hsieh, Kevin and Phanishayee, Amar and Mutlu, Onur and Gibbons, Phillip},
  booktitle={International Conference on Machine Learning},
  pages={4387--4398},
  year={2020},
  organization={PMLR}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{abadi2016tensorflow,
  title={$\{$TensorFlow$\}$: a system for $\{$Large-Scale$\}$ machine learning},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={12th USENIX symposium on operating systems design and implementation (OSDI 16)},
  pages={265--283},
  year={2016}
}