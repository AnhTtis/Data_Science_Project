\section{Introduction}
\label{intro}

A fractal is an infinitely complex shape that is self-similar across different scales. It displays a pattern that repeats forever, and every part of a fractal looks very similar to the whole fractal. Fractals have been shown to capture geometric properties of elements found in nature~\cite{mandelbrot1982fractal}. In essence, our nature is full of fractals, \eg, trees, rivers, coastlines, mountains, clouds, seashells, hurricanes, etc. 
 
Despite its complex shape, a fractal can be generated via well-defined mathematical systems like iterated function systems (IFS)~\cite{barnsley2014fractals}. 
An IFS generates a fractal image by ``drawing'' points iteratively on a canvas, in which the point transition is governed by a small set of $2\times 2$ affine transformations (each with a probability). Concretely, given the current point $\vv^{(t)}\in\R^2$, the IFS randomly samples one affine transformation with replacement from the set, and uses it to transform $\vv^{(t)}$ into the next point $\vv^{(t+1)}$. This stochastic step is repeated until a pre-defined number of iterations $T$ is reached. The collection of $\{\vv^{(0)}, \cdots, \vv^{(T)}\}$ can then be used to draw the fractal image (see \autoref{fig:render} for an illustration). \emph{The set of affine transformations thus can be seen as the parameters (or ID) of a fractal.} 


Motivated by these nice properties, several recent works in visual recognition have investigated generating a large number of fractal images to facilitate model (pre-)training, in which the parameters of each fractal are randomly sampled~\cite{kataoka2020pre,Anderson_2022_WACV}. For instance, \citet{kataoka2020pre} sampled {multiple sets} of parameters and treated each set as a fractal class. Within each class, they leveraged the stochastic nature of the IFS to generate fractal images with intra-class variations. They then used these images to pre-train a neural network in a supervised way without natural images and achieved promising results.

In this paper, we study a complementary and inverse problem --- \emph{given a target image that is not necessarily a fractal, can we find the parameters such that the generated IFS fractal image looks like it?} We consider this problem important from at least two aspects. First, it has the potential to find fractal parameters suitable for downstream visual tasks, \eg, for different kinds of image domains. Second, it can help us understand the limitations of IFS fractals, \eg, what kinds of image patterns the IFS cannot generate.

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{figures/overview.jpg}
\vskip -2pt
\caption{\small \textbf{Overview of our approach}, which aims to learn the fractal parameters $\sS$ so that the generated point sequence by IFS (\ie, $\{\vv^{(0)},\cdots,\vv^{(300)}\}$), after being rendered onto an image, is close to the target image. We learn $\sS$ by gradient descent (GD). As shown, after $1000$ GD steps, we can learn high-quality $\sS$ to generate images that are visually close to the target one.
}
\vskip -10pt
\label{fig:render}

\end{figure*}

We propose a novel gradient-descent-based approach for this problem (see \autoref{difffractal}). Given a target image and the (initial) fractal parameters, our approach compares the image generated by the IFS to the target image, back-propagates the gradients w.r.t.~the generated image \emph{through the IFS}, and uses the resulting gradients w.r.t.~the parameters to update the fractal parameters. The key insights are three-folded. First, we view an IFS as a special recurrent neural network (RNN) with identity activation functions and stochastic weights. The weights in each recurrent step (\ie, one affine transformation) are not the same, but are sampled with replacement from shared parameters. This analogy allows us to implement the forward (\ie, image generation) and backward (\ie, back-propagation) passes of IFS using deep learning frameworks like PyTorch~\cite{paszke2019pytorch} and TensorFlow~\cite{abadi2016tensorflow}. Second, the IFS generates a sequence of points, not an image directly. To compare this sequence to the target image and, in turn, calculate the gradients w.r.t.~the generated points, we introduce a differentiable rendering module inspired by~\cite{qian2020end}. Third, we identify several challenges in optimization and propose corresponding solutions to make the overall learning process stable, effective, and efficient. The learned parameters can thus lead to high-quality fractal images that are visually similar to the target image. We note that besides reconstructing a target image, our approach can easily be repurposed by plugging in other loss functions that return gradients w.r.t.~the generated image.
 
We conduct two experiments to validate our approach. First, given a target image (that is not necessarily a fractal), we find the fractal parameters to reconstruct it and evaluate our approach using the pixel-wise mean square error (MSE). Our approach notably outperforms the baselines. Second, we extend our approach to finding a set of parameters to approximate a set of target images. This can be achieved by replacing the image-to-image MSE loss with set-to-set losses like the GAN loss~\cite{goodfellow2014generative}. In this experiment, we demonstrate the potential of finding more suitable fractal images for the downstream tasks than the randomly sampled ones~\cite{kataoka2020pre,Anderson_2022_WACV}.


\paragraph{Contributions.} We propose a gradient-descent-based approach to find the fractal parameters for a given image. Our approach is stable, effective, and efficient. It can be easily implemented using popular deep learning frameworks. Moreover, it can be easily extended from finding fractal parameters for image reconstruction to other purposes, by plugging the corresponding loss functions. While we mainly demonstrate the effectiveness of our approach using image reconstruction, we respect think it is a critical and meaningful step towards unlocking other potential usages and applicability of fractal images in visual recognition and deep learning. The codes are provided at \url{https://github.com/andytu28/LearningFractals}.
