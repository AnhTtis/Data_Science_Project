@String(AAAI = {AAAI})
@String(ACCV  = {ACCV})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(CGF  = {Comput. Graph. Forum})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(CVM = {Computational Visual Media})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(ICASSP=	{ICASSP})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(IJCAI = {IJCAI})
@String(IJCV = {Int. J. Comput. Vis.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(JOV	 = {J. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(PR   = {Pattern Recognition})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(TCSVT = {IEEE TCSVT})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(TOG= {ACM Trans. Graph.})
@String(TVC  = {The Vis. Comput.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(VR   = {Vis. Res.})

@inproceedings{liang2023implications,
  title={Implications of Solution Patterns on Adversarial Robustness},
  author={Liang, Hengyue and Liang, Buyun and Cui, Ying and Mitchell, Tim and Sun, Ju},
  booktitle={The 3rd Workshop of Adversarial Machine Learning on Computer Vision: Art of Robustness (in conjunction with CVPR 2023)},
  year={2023}
}

@article{wright1999numerical,
  title={Numerical optimization},
  author={Wright, Stephen and Nocedal, Jorge and others},
  journal={Springer Science},
  volume={35},
  number={67-68},
  pages={7},
  year={1999}
}

@book{pillo2006large,
  title={Large-scale nonlinear optimization},
  author={Pillo, Gianni and Roma, Massimo},
  volume={83},
  year={2006},
  publisher={Springer Science \& Business Media}
}

@article{mosbach2018logit,
  title={Logit pairing methods can fool gradient-based attacks},
  author={Mosbach, Marius and Andriushchenko, Maksym and Trost, Thomas and Hein, Matthias and Klakow, Dietrich},
  journal={arXiv preprint arXiv:1810.12042},
  year={2018}
}

@article{wachter2006implementation,
  title={On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming},
  author={W{\"a}chter, Andreas and Biegler, Lorenz T},
  journal={Mathematical programming},
  volume={106},
  number={1},
  pages={25--57},
  year={2006},
  publisher={Springer}
}

@article{laue2019geno,
  title={GENO--GENeric Optimization for Classical Machine Learning},
  author={Laue, S{\"o}ren and Mitterreiter, Matthias and Giesen, Joachim},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{rony2019decoupling,
  title={Decoupling direction and norm for efficient gradient-based l2 adversarial attacks and defenses},
  author={Rony, J{\'e}r{\^o}me and Hafemann, Luiz G and Oliveira, Luiz S and Ayed, Ismail Ben and Sabourin, Robert and Granger, Eric},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4322--4330},
  year={2019}
}

@Article{LaueEtAl2022Optimization,
  author        = {Sören Laue and Mark Blacher and Joachim Giesen},
  journal       = {arXiv:2203.16340},
  title         = {Optimization for Classical Machine Learning Problems on the GPU},
  year          = {2022},
  month         = mar,
  archiveprefix = {arXiv},
  eprint        = {2203.16340},
  file          = {:http\://arxiv.org/pdf/2203.16340v1:PDF},
  keywords      = {cs.LG, math.OC, stat.ML},
  primaryclass  = {cs.LG},
}

@inproceedings{andriushchenko2020square,
  title={Square attack: a query-efficient black-box adversarial attack via random search},
  author={Andriushchenko, Maksym and Croce, Francesco and Flammarion, Nicolas and Hein, Matthias},
  booktitle={European Conference on Computer Vision},
  pages={484--501},
  year={2020},
  organization={Springer}
}

@article{yang2020closer,
  title={A closer look at accuracy vs. robustness},
  author={Yang, Yao-Yuan and Rashtchian, Cyrus and Zhang, Hongyang and Salakhutdinov, Russ R and Chaudhuri, Kamalika},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={8588--8601},
  year={2020}
}

@article{yang2020deep,
  title={A deep learning approach to grasping the invisible},
  author={Yang, Yang and Liang, Hengyue and Choi, Changhyun},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={2},
  pages={2232--2239},
  year={2020},
  publisher={IEEE}
}

@Book{Clarke1990Optimization,
  author    = {Clarke, Frank H},
  publisher = {SIAM},
  title     = {Optimization and nonsmooth analysis},
  year      = {1990},
}

@inproceedings{laidlaw2021perceptual,
  title={Perceptual Adversarial Robustness: Defense Against Unseen Threat Models},
  author={Laidlaw, Cassidy and Singla, Sahil and Feizi, Soheil},
  booktitle={ICLR},
  year={2021}
}

@InProceedings{Zhang_2018_CVPR,
author = {Zhang, Richard and Isola, Phillip and Efros, Alexei A. and Shechtman, Eli and Wang, Oliver},
title = {The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@Book{CuiPang2021Modern,
  author    = {Ying Cui and Jong Shi Pang},
  publisher = {Society for Industrial and Applied Mathematics},
  title     = {Modern Nonconvex Nondifferentiable Optimization},
  year      = {2021},
  month     = {Jan},
  doi       = {10.1137/1.9781611976748},
}

@article{bai2021recent,
  title={Recent advances in adversarial training for adversarial robustness},
  author={Bai, Tao and Luo, Jinqi and Zhao, Jun and Wen, Bihan and Wang, Qian},
  journal={arXiv preprint arXiv:2102.01356},
  year={2021}
}

@article{curtis2017bfgs,
  title={A BFGS-SQP method for nonsmooth, nonconvex, constrained optimization and its evaluation using relative minimization profiles},
  author={Curtis, Frank E and Mitchell, Tim and Overton, Michael L},
  journal={Optimization Methods and Software},
  volume={32},
  number={1},
  pages={148--181},
  year={2017},
  publisher={Taylor \& Francis}
}

@article{osqp,
  author  = {Stellato, B. and Banjac, G. and Goulart, P. and Bemporad, A. and Boyd, S.},
  title   = {{OSQP}: an operator splitting solver for quadratic programs},
  journal = {Mathematical Programming Computation},
  volume  = {12},
  number  = {4},
  pages   = {637--672},
  year    = {2020},
  doi     = {10.1007/s12532-020-00179-2},
  url     = {https://doi.org/10.1007/s12532-020-00179-2},
}

@article{hendrycks2019robustness,
  title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author={Dan Hendrycks and Thomas Dietterich},
  journal={Proceedings of the International Conference on Learning Representations},
  year={2019}
}

@article{burke2020gradient,
  title={Gradient sampling methods for nonsmooth optimization},
  author={Burke, James V and Curtis, Frank E and Lewis, Adrian S and Overton, Michael L and Sim{\~o}es, Lucas EA},
  journal={Numerical Nonsmooth Optimization},
  pages={201--225},
  year={2020},
  publisher={Springer}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@inproceedings{croce2021robustbench,
  title={RobustBench: a standardized adversarial robustness benchmark},
  author={Croce, Francesco and Andriushchenko, Maksym and Sehwag, Vikash and Debenedetti, Edoardo and Flammarion, Nicolas and Chiang, Mung and Mittal, Prateek and Hein, Matthias},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@inproceedings{martins2005structural,
  title={On structural optimization using constraint aggregation},
  author={Martins, JRRA and Poon, Nicholas MK},
  booktitle={VI World Congress on Structural and Multidisciplinary Optimization WCSMO6, Rio de Janeiro, Brasil},
  year={2005},
  organization={Citeseer}
}

@inproceedings{nguyen2015deep,
  title={Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
  author={Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={427--436},
  year={2015}
}

@article{rauber2017foolbox,
  title={Foolbox: A python toolbox to benchmark the robustness of machine learning models},
  author={Rauber, Jonas and Brendel, Wieland and Bethge, Matthias},
  journal={arXiv preprint arXiv:1707.04131},
  year={2017}
}

@article{papernot2016technical,
  title={Technical report on the cleverhans v2. 1.0 adversarial examples library},
  author={Papernot, Nicolas and Faghri, Fartash and Carlini, Nicholas and Goodfellow, Ian and Feinman, Reuben and Kurakin, Alexey and Xie, Cihang and Sharma, Yash and Brown, Tom and Roy, Aurko and others},
  journal={arXiv preprint arXiv:1610.00768},
  year={2016}
}

@Article{ZhangEtAl2018Constraint,
  author    = {Keshi Zhang and Zhonghua Han and Zhongjian Gao and Yuan Wang},
  journal   = {Structural and Multidisciplinary Optimization},
  title     = {Constraint aggregation for large number of constraints in wing surrogate-based optimization},
  year      = {2018},
  month     = {sep},
  number    = {2},
  pages     = {421--438},
  volume    = {59},
  doi       = {10.1007/s00158-018-2074-4},
  publisher = {Springer Science and Business Media {LLC}},
}

@inproceedings{croce2019sparse,
  title={Sparse and imperceivable adversarial attacks},
  author={Croce, Francesco and Hein, Matthias},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4724--4732},
  year={2019}
}

@Article{DomesNeumaier2014Constraint,
  author    = {Ferenc Domes and Arnold Neumaier},
  journal   = {Mathematical Programming},
  title     = {Constraint aggregation for rigorous global optimization},
  year      = {2014},
  month     = {dec},
  number    = {1-2},
  pages     = {375--401},
  volume    = {155},
  doi       = {10.1007/s10107-014-0851-4},
  publisher = {Springer Science and Business Media {LLC}},
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@Article{ErmolievEtAl1997Constraint,
  author    = {Yuri M. Ermoliev and Arkadii V. Kryazhimskii and Andrzej Ruszczy{\'{n}}ski},
  journal   = {Mathematical Programming},
  title     = {Constraint aggregation principle in convex optimization},
  year      = {1997},
  month     = {mar},
  number    = {3},
  pages     = {353--372},
  volume    = {76},
  doi       = {10.1007/bf02614388},
  publisher = {Springer Science and Business Media {LLC}},
}

@inproceedings{xiao2018spatially,
  title={Spatially Transformed Adversarial Examples},
  author={Xiao, Chaowei and Zhu, Junyan and Li, Bo and He, Warren and Liu, Mingyan and Song, Dawn},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{volpi2018generalizing,
  title={Generalizing to unseen domains via adversarial data augmentation},
  author={Volpi, Riccardo and Namkoong, Hongseok and Sener, Ozan and Duchi, John C and Murino, Vittorio and Savarese, Silvio},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{tsipras2018robustness,
  title={Robustness May Be at Odds with Accuracy},
  author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{gilmer2018adversarial,
  title={Adversarial spheres},
  author={Gilmer, Justin and Metz, Luke and Faghri, Fartash and Schoenholz, Samuel S and Raghu, Maithra and Wattenberg, Martin and Goodfellow, Ian},
  journal={arXiv preprint arXiv:1801.02774},
  year={2018}
}

@inproceedings{wei2019improved,
  title={Improved sample complexities for deep neural networks and robust classification via an all-layer margin},
  author={Wei, Colin and Ma, Tengyu},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{calian2021defending,
  title={Defending Against Image Corruptions Through Adversarial Augmentations},
  author={Calian, Dan Andrei and Stimberg, Florian and Wiles, Olivia and Rebuffi, Sylvestre-Alvise and Gy{\"o}rgy, Andr{\'a}s and Mann, Timothy A and Gowal, Sven},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@Article{TrappProkopyev2015note,
  author    = {Andrew C. Trapp and Oleg A. Prokopyev},
  journal   = {Discrete Optimization},
  title     = {A note on constraint aggregation and value functions for two-stage stochastic integer programs},
  year      = {2015},
  month     = {feb},
  pages     = {37--45},
  volume    = {15},
  doi       = {10.1016/j.disopt.2014.11.003},
  publisher = {Elsevier {BV}},
}

@inproceedings{hendrycks2018benchmarking,
  title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author={Hendrycks, Dan and Dietterich, Thomas},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{mintun2021interaction,
  title={On interaction between augmentations and corruptions in natural corruption robustness},
  author={Mintun, Eric and Kirillov, Alexander and Xie, Saining},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{hendrycks2021many,
  title={The many faces of robustness: A critical analysis of out-of-distribution generalization},
  author={Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8340--8349},
  year={2021}
}

@inproceedings{recht2019imagenet,
  title={Do imagenet classifiers generalize to imagenet?},
  author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle={International Conference on Machine Learning},
  pages={5389--5400},
  year={2019},
  organization={PMLR}
}

@article{hendrycks2019augmix,
  title={Augmix: A simple data processing method to improve robustness and uncertainty},
  author={Hendrycks, Dan and Mu, Norman and Cubuk, Ekin D and Zoph, Barret and Gilmer, Justin and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1912.02781},
  year={2019}
}

@article{lopes2019improving,
  title={Improving robustness without sacrificing accuracy with patch gaussian augmentation},
  author={Lopes, Raphael Gontijo and Yin, Dong and Poole, Ben and Gilmer, Justin and Cubuk, Ekin D},
  journal={arXiv preprint arXiv:1906.02611},
  year={2019}
}

@inproceedings{rusak2020simple,
  title={A Simple Way to Make Neural Networks Robust Against Diverse Image Corruptions},
  author={Rusak, Evgenia and Schott, Lukas and Zimmermann, Roland S and Bitterwolf, Julian and Bringmann, Oliver and Bethge, Matthias and Brendel, Wieland},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part III},
  pages={53--69},
  year={2020}
}

@inproceedings{cubuk2019autoaugment,
  title={AutoAugment: Learning Augmentation Strategies From Data},
  author={Cubuk, Ekin D and Zoph, Barret and Man{\'e}, Dandelion and Vasudevan, Vijay and Le, Quoc V},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={113--123},
  year={2019},
  organization={IEEE}
}

@article{lorenz2021robustbench,
  title={Is robustbench/autoattack a suitable benchmark for adversarial robustness?},
  author={Lorenz, Peter and Strassel, Dominik and Keuper, Margret and Keuper, Janis},
  journal={arXiv preprint arXiv:2112.01601},
  year={2021}
}

@inproceedings{cubuk2020randaugment,
  title={Randaugment: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={702--703},
  year={2020}
}

@inproceedings{yin2019fourier,
  title={A Fourier Perspective on Model Robustness in Computer Vision},
  author={Yin, Dong and Lopes, Raphael Gontijo and Shlens, Jon and Cubuk, Ekin Dogus and Gilmer, Justin},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{xie2020self,
  title={Self-Training With Noisy Student Improves ImageNet Classification},
  author={Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={10684--10695},
  year={2020},
  organization={IEEE}
}

@InProceedings{GoodfellowEtAl2015Explaining,
  author    = {Ian Goodfellow and Jonathon Shlens and Christian Szegedy},
  booktitle = {International Conference on Learning Representations},
  title     = {Explaining and Harnessing Adversarial Examples},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6572},
}

@InProceedings{EngstromEtAl2019Exploring,
  author    = {Engstrom, Logan and Tran, Brandon and Tsipras, Dimitris and Schmidt, Ludwig and Madry, Aleksander},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  title     = {Exploring the Landscape of Spatial Robustness},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  month     = {09--15 Jun},
  pages     = {1802--1811},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {97},
  abstract  = {The study of adversarial robustness has so far largely focused on perturbations bound in $\ell_p$-norms. However, state-of-the-art models turn out to be also vulnerable to other, more natural classes of perturbations such as translations and rotations. In this work, we thoroughly investigate the vulnerability of neural network–based classifiers to rotations and translations. While data augmentation offers relatively small robustness, we use ideas from robust optimization and test-time input aggregation to significantly improve robustness. Finally we find that, in contrast to the $\ell_p$-norm case, first-order methods cannot reliably find worst-case perturbations. This highlights spatial robustness as a fundamentally different setting requiring additional study.},
  pdf       = {http://proceedings.mlr.press/v97/engstrom19a/engstrom19a.pdf},
  url       = {https://proceedings.mlr.press/v97/engstrom19a.html},
}

@Article{WongEtAl2019Wasserstein,
  author        = {Eric Wong and Frank R. Schmidt and J. Zico Kolter},
  journal       = {arXiv:1902.07906},
  title         = {Wasserstein Adversarial Examples via Projected Sinkhorn Iterations},
  year          = {2019},
  month         = feb,
  abstract      = {A rapidly growing area of work has studied the existence of adversarial examples, datapoints which have been perturbed to fool a classifier, but the vast majority of these works have focused primarily on threat models defined by $\ell_p$ norm-bounded perturbations. In this paper, we propose a new threat model for adversarial attacks based on the Wasserstein distance. In the image classification setting, such distances measure the cost of moving pixel mass, which naturally cover "standard" image manipulations such as scaling, rotation, translation, and distortion (and can potentially be applied to other settings as well). To generate Wasserstein adversarial examples, we develop a procedure for projecting onto the Wasserstein ball, based upon a modified version of the Sinkhorn iteration. The resulting algorithm can successfully attack image classification models, bringing traditional CIFAR10 models down to 3% accuracy within a Wasserstein ball with radius 0.1 (i.e., moving 10% of the image mass 1 pixel), and we demonstrate that PGD-based adversarial training can improve this adversarial accuracy to 76%. In total, this work opens up a new direction of study in adversarial robustness, more formally considering convex metrics that accurately capture the invariances that we typically believe should exist in classifiers. Code for all experiments in the paper is available at https://github.com/locuslab/projected_sinkhorn.},
  archiveprefix = {arXiv},
  eprint        = {1902.07906},
  file          = {:http\://arxiv.org/pdf/1902.07906v2:PDF},
  keywords      = {cs.LG, stat.ML},
  primaryclass  = {cs.LG},
}

@Article{LaidlawFeizi2019Functional,
  author  = {Laidlaw, Cassidy and Feizi, Soheil},
  journal = {Advances in neural information processing systems},
  title   = {Functional adversarial attacks},
  year    = {2019},
  volume  = {32},
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@InProceedings{HosseiniPoovendran2018Semantic,
  author    = {Hosseini, Hossein and Poovendran, Radha},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  title     = {Semantic adversarial examples},
  year      = {2018},
  pages     = {1614--1619},
}

@Article{BhattadEtAl2019Big,
  author  = {Bhattad, Anand and Chong, Min Jin and Liang, Kaizhao and Li, Bo and Forsyth, David A},
  journal = {arXiv preprint arXiv:1904.06347},
  title   = {Big but imperceptible adversarial perturbations via semantic manipulation},
  year    = {2019},
  number  = {3},
  volume  = {1},
}

@inproceedings{maini2020adversarial,
  title={Adversarial robustness against the union of multiple perturbation models},
  author={Maini, Pratyush and Wong, Eric and Kolter, Zico},
  booktitle={International Conference on Machine Learning},
  pages={6640--6650},
  year={2020},
  organization={PMLR}
}

@Article{HuangEtAl2015Learning,
  author        = {Ruitong Huang and Bing Xu and Dale Schuurmans and Csaba Szepesvari},
  journal       = {arXiv:1511.03034},
  title         = {Learning with a Strong Adversary},
  year          = {2015},
  month         = nov,
  archiveprefix = {arXiv},
  eprint        = {1511.03034},
  file          = {:http\://arxiv.org/pdf/1511.03034v6:PDF},
  keywords      = {cs.LG},
  primaryclass  = {cs.LG},
}

@Article{TjengEtAl2017Evaluating,
  author        = {Vincent Tjeng and Kai Xiao and Russ Tedrake},
  journal       = {arXiv:1711.07356},
  title         = {Evaluating Robustness of Neural Networks with Mixed Integer Programming},
  year          = {2017},
  month         = nov,
  archiveprefix = {arXiv},
  eprint        = {1711.07356},
  file          = {:http\://arxiv.org/pdf/1711.07356v3:PDF},
  keywords      = {cs.LG, cs.CR, cs.CV},
  primaryclass  = {cs.LG},
}

@Article{KatzEtAl2017Reluplex,
  author        = {Guy Katz and Clark Barrett and David Dill and Kyle Julian and Mykel Kochenderfer},
  journal       = {arXiv:1702.01135},
  title         = {Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks},
  year          = {2017},
  month         = feb,
  archiveprefix = {arXiv},
  eprint        = {1702.01135},
  file          = {:http\://arxiv.org/pdf/1702.01135v2:PDF},
  keywords      = {cs.AI, cs.LO},
  primaryclass  = {cs.AI},
}

@Article{BunelEtAl2020Branch,
  author    = {Bunel, Rudy and Mudigonda, P and Turkaslan, Ilker and Torr, P and Lu, Jingyue and Kohli, Pushmeet},
  journal   = {Journal of Machine Learning Research},
  title     = {Branch and bound for piecewise linear neural network verification},
  year      = {2020},
  number    = {2020},
  volume    = {21},
  publisher = {Journal of Machine Learning Research},
}

@Article{PintorEtAl2021Fast,
  author  = {Pintor, Maura and Roli, Fabio and Brendel, Wieland and Biggio, Battista},
  journal = {Advances in Neural Information Processing Systems},
  title   = {Fast minimum-norm adversarial attacks through adaptive norm constraints},
  year    = {2021},
  volume  = {34},
}

@InProceedings{CroceHein2020Minimally,
  author       = {Croce, Francesco and Hein, Matthias},
  booktitle    = {International Conference on Machine Learning},
  title        = {Minimally distorted adversarial examples with a fast adaptive boundary attack},
  year         = {2020},
  organization = {PMLR},
  pages        = {2196--2205},
}

@inproceedings{croce2020reliable,
  title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
  author={Croce, Francesco and Hein, Matthias},
  booktitle={International conference on machine learning},
  pages={2206--2216},
  year={2020},
  organization={PMLR}
}

@Article{Hein2017,
  author        = {Matthias Hein and Maksym Andriushchenko},
  journal       = {arXiv:1705.08475},
  title         = {Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation},
  year          = {2017},
  month         = may,
  archiveprefix = {arXiv},
  eprint        = {1705.08475},
  file          = {:http\://arxiv.org/pdf/1705.08475v2:PDF},
  keywords      = {cs.LG, cs.AI, cs.CV, stat.ML},
  primaryclass  = {cs.LG},
}

@Article{CarliniWagner2016Towards,
  author        = {Nicholas Carlini and David Wagner},
  journal       = {arXiv:1608.04644},
  title         = {Towards Evaluating the Robustness of Neural Networks},
  year          = {2016},
  month         = aug,
  archiveprefix = {arXiv},
  eprint        = {1608.04644},
  file          = {:http\://arxiv.org/pdf/1608.04644v2:PDF},
  keywords      = {cs.CR, cs.CV},
  primaryclass  = {cs.CR},
}

@Article{MoosaviDezfooliEtAl2015DeepFool,
  author        = {Seyed Mohsen Moosavi-Dezfooli and Alhussein Fawzi and Pascal Frossard},
  journal       = {arXiv:1511.04599.},
  title         = {DeepFool: a simple and accurate method to fool deep neural networks},
  year          = {2015},
  month         = nov,
  archiveprefix = {arXiv},
  eprint        = {1511.04599},
  file          = {:http\://arxiv.org/pdf/1511.04599v3:PDF},
  keywords      = {cs.LG, cs.CV},
  primaryclass  = {cs.LG},
}

@Article{CarliniEtAl2019Evaluating,
  author        = {Nicholas Carlini and Anish Athalye and Nicolas Papernot and Wieland Brendel and Jonas Rauber and Dimitris Tsipras and Ian Goodfellow and Aleksander Madry and Alexey Kurakin},
  journal       = {arXiv:1902.06705},
  title         = {On Evaluating Adversarial Robustness},
  year          = {2019},
  month         = feb,
  archiveprefix = {arXiv},
  eprint        = {1902.06705},
  file          = {:http\://arxiv.org/pdf/1902.06705v2:PDF},
  keywords      = {cs.LG, cs.CR, stat.ML},
  primaryclass  = {cs.LG},
}


@article{BuyunLiangSun2021NCVX,
    title={{NCVX}: {A} General-Purpose Optimization Solver for Constrained Machine and Deep Learning},
    author={Buyun Liang and Tim Mitchell and Ju Sun},
    year={2022},
    eprint={2210.00973},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{kang2019testing,
  title={Testing robustness against unforeseen adversaries},
  author={Kang, Daniel and Sun, Yi and Hendrycks, Dan and Brown, Tom and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:1908.08016},
  year={2019}
}

@article{yu2013decomposing,
  title={On decomposing the proximal map},
  author={Yu, Yao-Liang},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@Article{RazaviyaynEtAl2020Non,
  author        = {Meisam Razaviyayn and Tianjian Huang and Songtao Lu and Maher Nouiehed and Maziar Sanjabi and Mingyi Hong},
  journal       = {IEEE Signal Processing Magazine (Volume: 37, Issue: 5, Sept. 2020)},
  title         = {Non-convex Min-Max Optimization: Applications, Challenges, and Recent Theoretical Advances},
  year          = {2020},
  month         = jun,
  abstract      = {The min-max optimization problem, also known as the saddle point problem, is a classical optimization problem which is also studied in the context of zero-sum games. Given a class of objective functions, the goal is to find a value for the argument which leads to a small objective value even for the worst case function in the given class. Min-max optimization problems have recently become very popular in a wide range of signal and data processing applications such as fair beamforming, training generative adversarial networks (GANs), and robust machine learning, to just name a few. The overarching goal of this article is to provide a survey of recent advances for an important subclass of min-max problem, where the minimization and maximization problems can be non-convex and/or non-concave. In particular, we will first present a number of applications to showcase the importance of such min-max problems; then we discuss key theoretical challenges, and provide a selective review of some exciting recent theoretical and algorithmic advances in tackling non-convex min-max problems. Finally, we will point out open questions and future research directions.},
  archiveprefix = {arXiv},
  doi           = {10.1109/MSP.2020.3003851},
  eprint        = {2006.08141},
  file          = {:http\://arxiv.org/pdf/2006.08141v2:PDF},
  keywords      = {math.OC, cs.LG, stat.ML},
  primaryclass  = {math.OC},
}

@Book{Bertsekas2016Nonlinear,
  author    = {Bertsekas, Dimitri},
  publisher = {Athena Scientific},
  title     = {Nonlinear Programming 3rd Edition},
  year      = {2016},
  isbn      = {9781886529052},
  pages     = {880},
  subtitle  = {3rd Edition},
}

@article{gowal2020uncovering,
  title={Uncovering the limits of adversarial training against norm-bounded adversarial examples},
  author={Gowal, Sven and Qin, Chongli and Uesato, Jonathan and Mann, Timothy and Kohli, Pushmeet},
  journal={arXiv preprint arXiv:2010.03593},
  year={2020}
}

@article{paszke2017automatic,
  title={Automatic differentiation in pytorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@inproceedings{croce2021mind,
  title={Mind the box: $\ell_1 $-APGD for sparse adversarial attacks on image classifiers},
  author={Francesco Croce and Matthias Hein},
  booktitle={International Conference on Machine Learning},
  pages={2201--2211},
  year={2021},
  organization={PMLR}
}

@Article{BernhardRapaport1995theorem,
  author    = {Pierre Bernhard and Alain Rapaport},
  journal   = {Nonlinear Analysis: Theory, Methods $\&$ Applications},
  title     = {On a theorem of Danskin with an application to a theorem of Von Neumann-Sion},
  year      = {1995},
  month     = {apr},
  number    = {8},
  pages     = {1163--1181},
  volume    = {24},
  doi       = {10.1016/0362-546x(94)00186-l},
  publisher = {Elsevier {BV}},
}

@Book{Danskin1967Theory,
  author    = {John M. Danskin},
  publisher = {Springer Berlin Heidelberg},
  title     = {The Theory of Max-Min and its Application to Weapons Allocation Problems},
  year      = {1967},
  doi       = {10.1007/978-3-642-46092-0},
}

@article{clarke1975generalized,
  title={Generalized gradients and applications},
  author={Clarke, Frank H},
  journal={Transactions of the American Mathematical Society},
  volume={205},
  pages={247--262},
  year={1975}
}

@Article{ZhangEtAl2021Revisiting,
  author        = {Yihua Zhang and Guanhua Zhang and Prashant Khanduri and Mingyi Hong and Shiyu Chang and Sijia Liu},
  journal       = {arXiv:2112.12376},
  title         = {Revisiting and Advancing Fast Adversarial Training Through The Lens of Bi-Level Optimization},
  year          = {2021},
  month         = dec,
  abstract      = {Adversarial training (AT) is a widely recognized defense mechanism to gain the robustness of deep neural networks against adversarial attacks. It is built on min-max optimization (MMO), where the minimizer (i.e., defender) seeks a robust model to minimize the worst-case training loss in the presence of adversarial examples crafted by the maximizer (i.e., attacker). However, the conventional MMO method makes AT hard to scale. Thus, Fast-AT and other recent algorithms attempt to simplify MMO by replacing its maximization step with the single gradient sign-based attack generation step. Although easy to implement, FAST-AT lacks theoretical guarantees, and its empirical performance is unsatisfactory due to the issue of robust catastrophic overfitting when training with strong adversaries. In this paper, we advance Fast-AT from the fresh perspective of bi-level optimization (BLO). We first show that the commonly-used Fast-AT is equivalent to using a stochastic gradient algorithm to solve a linearized BLO problem involving a sign operation. However, the discrete nature of the sign operation makes it difficult to understand the algorithm performance. Inspired by BLO, we design and analyze a new set of robust training algorithms termed Fast Bi-level AT (Fast-BAT), which effectively defends sign-based projected gradient descent (PGD) attacks without using any gradient sign method or explicit robust regularization. In practice, we show that our method yields substantial robustness improvements over multiple baselines across multiple models and datasets. All code for reproducing the experiments in this paper is at https://github.com/NormalUhr/Fast_BAT.},
  archiveprefix = {arXiv},
  eprint        = {2112.12376},
  file          = {:http\://arxiv.org/pdf/2112.12376v4:PDF},
  keywords      = {cs.LG},
  primaryclass  = {cs.LG},
}

@Article{WongKolter2017Provable,
  author        = {Eric Wong and J. Zico Kolter},
  journal       = {arXiv:1711.00851},
  title         = {Provable defenses against adversarial examples via the convex outer adversarial polytope},
  year          = {2017},
  month         = nov,
  archiveprefix = {arXiv},
  eprint        = {1711.00851},
  file          = {:http\://arxiv.org/pdf/1711.00851v3:PDF},
  keywords      = {cs.LG, cs.AI, math.OC},
  primaryclass  = {cs.LG},
}

@Article{RaghunathanEtAl2018Certified,
  author        = {Aditi Raghunathan and Jacob Steinhardt and Percy Liang},
  journal       = {arXiv:1801.09344},
  title         = {Certified Defenses against Adversarial Examples},
  year          = {2018},
  month         = jan,
  archiveprefix = {arXiv},
  eprint        = {1801.09344},
  file          = {:http\://arxiv.org/pdf/1801.09344v2:PDF},
  keywords      = {cs.LG},
  primaryclass  = {cs.LG},
}

@Article{MuellerEtAl2022PRIMA,
  author    = {Mark Niklas Müller and Gleb Makarchuk and Gagandeep Singh and Markus Püschel and Martin Vechev},
  journal   = {Proceedings of the {ACM} on Programming Languages},
  title     = {{PRIMA}: general and precise neural network certification via scalable convex hull approximations},
  year      = {2022},
  month     = {jan},
  number    = {{POPL}},
  pages     = {1--33},
  volume    = {6},
  doi       = {10.1145/3498704},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{SinghEtAl2018Fast,
  author  = {Singh, Gagandeep and Gehr, Timon and Mirman, Matthew and P{\"u}schel, Markus and Vechev, Martin},
  journal = {Advances in neural information processing systems},
  title   = {Fast and effective robustness certification},
  year    = {2018},
  volume  = {31},
}

@article{gilmer2018motivating,
  title={Motivating the rules of the game for adversarial example research},
  author={Gilmer, Justin and Adams, Ryan P and Goodfellow, Ian and Andersen, David and Dahl, George E},
  journal={arXiv preprint arXiv:1807.06732},
  year={2018}
}

@inproceedings{liang2022optimization,
  title={Optimization for robustness evaluation beyond $\ell_p$ metrics},
  author={Liang, Hengyue and Liang, Buyun and Cui, Ying and Mitchell, Tim and Sun, Ju},
  booktitle={OPT 2022: Optimization for Machine Learning (NeurIPS 2022 Workshop)},
  year={2022}
}

@Article{LeeEtAl2021Towards,
  author  = {Lee, Sungyoon and Lee, Woojin and Park, Jinseong and Lee, Jaewook},
  journal = {Advances in Neural Information Processing Systems},
  title   = {Towards Better Understanding of Training Certifiably Robust Models against Adversarial Examples},
  year    = {2021},
  volume  = {34},
}

@Article{WongEtAl2018Scaling,
  author  = {Wong, Eric and Schmidt, Frank and Metzen, Jan Hendrik and Kolter, J Zico},
  journal = {Advances in Neural Information Processing Systems},
  title   = {Scaling provable adversarial defenses},
  year    = {2018},
  volume  = {31},
}

@article{lewis2013nonsmooth,
  title={Nonsmooth optimization via quasi-Newton methods},
  author={Lewis, Adrian S and Overton, Michael L},
  journal={Mathematical Programming},
  volume={141},
  number={1},
  pages={135--163},
  year={2013},
  publisher={Springer}
}

@article{sridhar2022towards,
  title={Towards Alternative Techniques for Improving Adversarial Robustness: Analysis of Adversarial Training at a Spectrum of Perturbations},
  author={Sridhar, Kaustubh and Dutta, Souradeep and Kaur, Ramneet and Weimer, James and Sokolsky, Oleg and Lee, Insup},
  journal={arXiv preprint arXiv:2206.06496},
  year={2022}
}

@Article{DvijothamEtAl2018Training,
  author        = {Krishnamurthy Dvijotham and Sven Gowal and Robert Stanforth and Relja Arandjelovic and Brendan O'Donoghue and Jonathan Uesato and Pushmeet Kohli},
  journal       = {arXiv:1805.10265},
  title         = {Training verified learners with learned verifiers},
  year          = {2018},
  month         = may,
  archiveprefix = {arXiv},
  eprint        = {1805.10265},
  file          = {:http\://arxiv.org/pdf/1805.10265v2:PDF},
  keywords      = {cs.LG, stat.ML},
  primaryclass  = {cs.LG},
}

@InProceedings{SinghEtAl2018Boosting,
  author    = {Singh, Gagandeep and Gehr, Timon and P{\"u}schel, Markus and Vechev, Martin},
  booktitle = {International conference on learning representations},
  title     = {Boosting robustness certification of neural networks},
  year      = {2018},
}

@Article{SinghEtAl2019abstract,
  author    = {Singh, Gagandeep and Gehr, Timon and P{\"u}schel, Markus and Vechev, Martin},
  journal   = {Proceedings of the ACM on Programming Languages},
  title     = {An abstract domain for certifying neural networks},
  year      = {2019},
  number    = {POPL},
  pages     = {1--30},
  volume    = {3},
  publisher = {ACM New York, NY, USA},
}

@Article{SalmanEtAl2019Convex,
  author        = {Hadi Salman and Greg Yang and Huan Zhang and Cho-Jui Hsieh and Pengchuan Zhang},
  journal       = {arXiv:1902.08722},
  title         = {A Convex Relaxation Barrier to Tight Robustness Verification of Neural Networks},
  year          = {2019},
  month         = feb,
  archiveprefix = {arXiv},
  eprint        = {1902.08722},
  file          = {:http\://arxiv.org/pdf/1902.08722v5:PDF},
  keywords      = {cs.LG, cs.AI, cs.CR, cs.CV, stat.ML},
  primaryclass  = {cs.LG},
}

@Article{DathathriEtAl2020Enabling,
  author  = {Dathathri, Sumanth and Dvijotham, Krishnamurthy and Kurakin, Alexey and Raghunathan, Aditi and Uesato, Jonathan and Bunel, Rudy R and Shankar, Shreya and Steinhardt, Jacob and Goodfellow, Ian and Liang, Percy S and others},
  journal = {Advances in Neural Information Processing Systems},
  title   = {Enabling certification of verification-agnostic networks via memory-efficient semidefinite programming},
  year    = {2020},
  pages   = {5318--5331},
  volume  = {33},
}

@InProceedings{WengEtAl2018Towards,
  author       = {Weng, Lily and Zhang, Huan and Chen, Hongge and Song, Zhao and Hsieh, Cho-Jui and Daniel, Luca and Boning, Duane and Dhillon, Inderjit},
  booktitle    = {International Conference on Machine Learning},
  title        = {Towards fast computation of certified robustness for relu networks},
  year         = {2018},
  organization = {PMLR},
  pages        = {5276--5285},
}

@Article{ZhangEtAl2018Efficient,
  author  = {Zhang, Huan and Weng, Tsui-Wei and Chen, Pin-Yu and Hsieh, Cho-Jui and Daniel, Luca},
  journal = {Advances in neural information processing systems},
  title   = {Efficient neural network robustness certification with general activation functions},
  year    = {2018},
  volume  = {31},
}

@Article{WengEtAl2018Evaluating,
  author  = {Weng, Tsuiwei and Zhang, Huan and Chen, Pinyu and Yi, Jinfeng and Su, Dong and Gao, Yupeng and Hsieh, Chojui and Daniel, Luca},
  journal = {arXiv preprint arXiv:1801.10578},
  title   = {Evaluating the robustness of neural networks: An extreme value theory approach},
  year    = {2018},
}

@InProceedings{LyuEtAl2020Fastened,
  author    = {Lyu, Zhaoyang and Ko, Chingyun and Kong, Zhifeng and Wong, Ngai and Lin, Dahua and Daniel, Luca},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  title     = {Fastened crown: Tightened neural network robustness certificates},
  year      = {2020},
  number    = {04},
  pages     = {5037--5044},
  volume    = {34},
}

@Book{HastieEtAl2015Statistical,
  author    = {Trevor Hastie and Robert Tibshirani and Martin Wainwright},
  publisher = {Chapman and Hall/{CRC}},
  title     = {Statistical Learning with Sparsity},
  year      = {2015},
  month     = {may},
  doi       = {10.1201/b18401},
}

@Book{WrightMa2021High,
  author    = {Wright, John and Ma, Yi},
  publisher = {University of Cambridge ESOL Examinations},
  title     = {High-Dimensional Data Analysis with Low-Dimensional Models Principles, Computation, and Applications},
  year      = {2021},
  isbn      = {9781108489737},
  subtitle  = {Principles, Computation, and Applications},
}

@inproceedings{raghunathan2019adversarial,
title       = {Adversarial Training Can Hurt Generalization},
author      = {Aditi Raghunathan* and Sang Michael Xie* and Fanny Yang and John Duchi and Percy Liang},
booktitle   = {ICML 2019 Workshop on Identifying and Understanding Deep Learning Phenomena},
year        = {2019},
url         = {https://openreview.net/forum?id=SyxM3J256E}
}


@InProceedings{StuderEtAl2012Signal,
  author    = {Christoph Studer and Wotao Yin and Richard G. Baraniuk},
  booktitle = {2012 50th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  title     = {Signal representations with minimum $\ell_\infty$},
  year      = {2012},
  month     = {oct},
  publisher = {{IEEE}},
  doi       = {10.1109/allerton.2012.6483364},
}

@Article{CroceHein2019Provable,
  author  = {Croce, Francesco and Hein, Matthias},
  journal = {arXiv preprint arXiv:1905.11213},
  title   = {Provable robustness against all adversarial $\ell_p$-perturbations for $p \ge 1$},
  year    = {2019},
}

@Book{BagirovEtAl2014Introduction,
  author    = {Adil Bagirov and Napsu Karmitsa and Marko M. Mäkelä},
  publisher = {Springer International Publishing},
  title     = {Introduction to Nonsmooth Optimization},
  year      = {2014},
  doi       = {10.1007/978-3-319-08114-4},
}

@Comment{jabref-meta: databaseType:bibtex;}
