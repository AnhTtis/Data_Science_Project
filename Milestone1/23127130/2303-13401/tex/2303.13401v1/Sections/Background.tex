\section{Technical background}
\label{sec:background}
% \textcolor{red}{Editing Notes: Comment the min-max paragraph here for now. May change it into the discussion sections}
\subsection{Numerical optimization for max-loss form}
\label{
subsec: numeric method for robust loss}
Max-loss form (\ref{eq:robust_loss}) is popularly solved by PGD method. The basic update reads:
\begin{align}
    \mb x'_{new} = \mc P_{\Delta(\mb x)} \paren{\mb x'_{old} + \gamma \nabla \ell(\mb x'_{old})}
\end{align} 
where $\mc P_{\Delta(\mb x)}$ is the projection operator to the feasible set $\Delta(\mb x)$ and $\gamma$ is the step size. When $\Delta(\mb x) = \{\mb x' \in [0, 1]^n: \norm{\mb x' - \mb x}_p \le \eps\}$ with $p = 1, \infty$, $\mc P_{\Delta(\mb x)}$ takes simple forms. For $p=2$, sequential projection---first onto the box and then the norm ball, at least finds a feasible solution (see our clarification of these projections in Appendix \ref{Sec:app_projection}). Therefore, PGD is viable for these cases. For other general $\ell_p$ metrics and non-$\ell_p$ metrics, analytical projectors mostly cannot be derived and existing PGD methods do not apply. Previous work has shown that the solution quality of PGD is sensitive to hyperparameter tuning, e.g., step-size schedule and iteration budget~\cite{mosbach2018logit,CarliniEtAl2019Evaluating,croce2020reliable}. PGD variants, such as AGPD methods where `A' stands for Auto(matic)~\cite{croce2020reliable}, try to make the tuning process automatic by combining a heuristic adaptive step-size schedule and momentum acceleration under a fixed iteration budget and are built into the popular \texttt{AutoAttack} package\footnote{Package website: \url{https://github.com/fra31/auto-attack}.}. 
\texttt{AutoAttack} also includes non-PGD methods, e.g., Square Attack~\cite{andriushchenko2020square}, which is based on gradient-free random search. Square Attack does not have as effective attack performance as APGDs (see \cref{tab: granso_l1_acc} in later sections) but is included as \cite{croce2020reliable} states that the diversity in the evaluation algorithms is important to achieve reliable numerical RE.

\subsection{Numerical optimization of min-loss-form}
\label{subsec: numeric method for min_distort}
The difficulty in solving min-loss-form (\ref{eq:min_distort}) lies in dealing with the highly nonlinear constraint $\max_{i \ne y} f_{\mb \theta}^i (\mb x') \ge f_{\mb \theta}^y (\mb x')$. There are two lines of ideas to circumvent it: \textbf{1) penalty methods} turn the constraint into a penalty term and add it to the objective~\cite{szegedy2013intriguing,CarliniWagner2016Towards}. The remaining box-constrained problems can then be handled by optimization methods such as L-BFGS~\cite{wright1999numerical} or PGD. One caveat of penalty methods is that they do not guarantee to return feasible solutions to the original problem; \textbf{2) iterative linearization} linearizes the constraint at each step, leading to simple solutions to the projection (onto the intersection of the linearized decision boundary and the $[0, 1]^n$ box) for particular choices of $d$ (i.e., $\ell_1$, $\ell_2$ and $\ell_\infty$ distances); see, e.g. \cite{MoosaviDezfooliEtAl2015DeepFool,CroceHein2020Minimally}. Again, for general metrics $d$, this projection does not have a closed-form solution. In \cite{rony2019decoupling,PintorEtAl2021Fast}, the problem is reformulated as follows:
\begin{align}
\label{eq: min reform}
\begin{split}
    & \min_{\mb x', t} \, t \\
     \st \;  \max_{i \ne y} & f_{\mb \theta}^i (\mb x') \ge f_{\mb \theta}^y (\mb x')\\
     d(\mb x, & ~ \mb x')  \le t\,  ,\; \mb x' \in [0, 1]^n
    \end{split}
\end{align} 
so that the perturbation (determined by $\mb x'$) and the radius (determined by $t$) are decoupled. Then penalty methods and iterative linearization are combined to solve (\ref{eq: min reform}). The popular fast adaptive boundary (FAB) attack~\cite{CroceHein2020Minimally} included in \texttt{AutoAttack} belongs to iterative linearization family. % 

\subsection{\texttt{PyGRANSO} for constrained optimization}
\label{subsec: pygranso for NO}
General \textbf{n}on\textbf{l}inear \textbf{opt}imization (NLOPT) problems take the following form~\cite{wright1999numerical,Bertsekas2016Nonlinear}: 
\begin{align}  
\label{eq:NO_form}
\begin{split}
        & \min_{\mb x}\; g(\mb x) \\
    \st \; c_i&(\mb x) \le 0, \; \forall\;  i \in\mc I\ \\
    h_j&(\mb x) = 0, \; \forall\; j \in \mc E
\end{split}
\end{align}
where $g(\cdot)$ is the continuous objective function; $c_i$'s and $h_j$'s are continuous inequality and equality constraints, respectively.
As instances of NLOPT, both max-loss form and min-radius form in principle can be solved by general-purpose NLOPT solvers such as \texttt{Knitro}~\cite{pillo2006large}, \texttt{IPOPT}~\cite{wachter2006implementation}, and \texttt{GENO}~\cite{laue2019geno,LaueEtAl2022Optimization}. However, there are two caveats: \textbf{1)} these solvers only handle continuously differentiable $g$, $c_i$'s and $h_j$'s, while non-differentiable ones are common in max-loss form and min-radius form, e.g., when $d$ is the $\ell_\infty$ distance, or $f_{\mb \theta}$ uses non-differentiable activations; \textbf{2)} most of them require gradients to be provided by the user, while they are impractical to derive when DNNs are involved. Although gradient derivation can be addressed by combining these solvers with existing auto-differentiation (AD) packages, requiring all components to be continuously differentiable is the major bottleneck that limits these solvers from solving max-loss form and min-radius form reliably.

\pygranso~\cite{BuyunLiangSun2021NCVX}\footnote{Package webpage: \url{https://ncvx.org/}} is a recent \texttt{PyTorch}-port of the powerful MATLAB package \texttt{GRANSO}~\cite{curtis2017bfgs} that can handle general NLOPT problems of form (\ref{eq:NO_form}) with non-differentiable $g$, $c_i$'s, and $h_j$'s. \pygranso~only requires them to be \emph{almost everywhere differentiable}~\cite{Clarke1990Optimization,BagirovEtAl2014Introduction,CuiPang2021Modern}, which covers a much wider range than almost all forms of (\ref{eq:robust_loss}) and (\ref{eq:min_distort}) proposed so far in the literature. \texttt{GRANSO} employs a quasi-Newton sequential quadratic programming (BFGS-SQP) method to solve (\ref{eq:NO_form}), and features a rigorous adaptive step-size rule through a line search and a principled stopping criterion inspired by gradient sampling~\cite{burke2020gradient}; see a sketch of the algorithm in Appendix \ref{Sec:granso_summary} and \cite{curtis2017bfgs} for details. \pygranso\,equips \texttt{GRANSO} with, among other new capabilities, AD and GPU acceleration powered by \texttt{PyTorch}---both are crucial for deep learning problems. \change{The stopping criterion is controlled by the tolerances for total constraint violation and stationarity assessment---the former determines how strict the constraints are enforced, while the latter estimates how close the solution is to a stationary point.} Thus, the solution quality can be transparently controlled.

\subsection{Min-max optimization for adversarial training}
\label{subsec: tecnnical background for min-max}
For a finite training set, AT (\ref{eq:minmax_obj}) becomes:
\begin{align}  
\label{eq:eq:minmax_obj_finite} 
& \min_{\mb \theta} \frac{1}{N} \sum_{i=1}^N  \max_{\mb x'_i \in \Delta(\mb x_i)} \ell\paren{\mb y_i, f_{\mb \theta}(\mb x'_i)} \\
\Longleftrightarrow & \min_{\mb \theta} \max_{\mb x'_i \in \Delta(\mb x_i)\; \forall i}  \frac{1}{N} \sum_{i=1}^N \ell\paren{\mb y_i, f_{\mb \theta}(\mb x'_i)} ~ \text{,}
\label{eq:eq:minmax_obj_finite_eq_form} 
\end{align} 
i.e., in the form of 
\begin{align}
    \min_{\mb \theta} \max_{\mb x'_i \in \Delta(\mb x_i)\; , \forall i} \phi(\mb \theta, \{\mb x_i\}) ~ \text{.}
\label{eq: min_max_practice_form}
\end{align}
(\ref{eq: min_max_practice_form}) is often solved by iterating between the (separable) inner maximization and a subgradient update for the outer minimization. The latter takes a subgradient of $h(\mb \theta) = \max_{\mb x'_i \in \Delta(\mb x_i)\; \forall i} \phi(\mb \theta, \{\mb x_i\})$ from the subdifferential $\partial_{\mb \theta}\phi(\mb \theta, \{\mb x_i^*\})$ ($\mb x_i^*$ are maximizers for the inner maximization), justified by the celebrated Danskin's theorem~\cite{Danskin1967Theory,BernhardRapaport1995theorem,RazaviyaynEtAl2020Non}. However, if the numerical solutions to the inner maximization are substantially suboptimal\footnote{On the other hand, \cite{madry2017towards} argues using numerical evidence that maximization landscapes are typically benign in practice and gradient-based methods often find solutions with function values close to the global optimal. }, the subgradient to update the outer minimization can be misleading; see our discussion in \cref{sec:danskin_minmax}. In practice, people generally do not strive to find the optimal solutions to the inner maximization but prematurely terminate the optimization process, e.g., \change{by a small MaxIter.}
