\section{Related Work}
\label{sec:cheesyfoot:rw}

Chapter \ref{ch:relatedwork} discusses the related works on interaction techniques with \acp{HMD}. The following section presents a set of requirements for foot-based interactions with \acp{HMD} and, in the following, categorizes relevant research with regards to the requirements. Further, this work was strongly inspired by proprioceptive and imaginary user interfaces, to be discussed at the end of the section.

\subsection{Requirements}

The following section presents a set of requirements for foot-based interactions with \acp{HMD} derived from the related works. The requirements are then used to compare the most relevant related work (see table \ref{tab:req:mindthetap}).

\begin{description}
	\item[R5.1: Independent Usage] In many mobile situations, the user's hands are encumbered (e.g., by carrying something). To support such situations, it is necessary that the interaction with the system is possible without the additional use of hands.
	\item[R5.2: Visual Output] To close the feedback loop between user and system, means for output are required in addition to the foot-based input.
	\item[R5.3: Interaction Without Full Visual Attention] The lack of visual attention can quickly lead to dangerous situations in mobile scenarios. Therefore, the user's visual attention should not be completely absorbed by the interface, allowing the user to keep a connection to the real world.
	\item[R5.4: Direct Interaction] A direct spatial connection of input and output (i.e., input and output happen at the same physical location) allows for more \enquote{natural} and \emph{compelling} interactions~\ncite{Forlines2007}. Therefore, systems should provide such a direct spatial connection.
\end{description}

\subsection{Foot-based Interaction}

Foot-based input has a long history in operating industry machines~\ncite{barnes1942pedal,Corlett1975,Keoemer1971,Pearson1986, Barnett2009} and also appeared early as a possible solution in the field of \ac{HCI}: In 1986 Douglas Engelbart gave a famous presentation on the basic concepts of \acp{GUI} and the mouse as an input modality, which would later go down in history as \emph{The Mother of All Demos}~\ncite{Engelbart1968}. One year before, Engelbart's team also worked on other input modalities: \typcite{english1967display} presented a system using knee and foot control for text selection. Since then, foot input frequently emerges as a potential input modality for novel computing systems and has been explored for seated~\ncite{Velloso2015a}, standing~\ncite{Saunders2016}, and walking~\ncite{Yamamoto2008} users in different scenarios.


For example, foot controls have been used to increase the input space for desktop~\ncite{Silva2009} or mobile~\ncite{Lv2014a} games or to operate a smartphone in the pocket of the user~\ncite{Barnett2009, Fan2017, Han2011}. Besides the sole use as an input modality, foot interaction has been used in conjunction with hand-gestures~\ncite{Lv2013, Lv2014, Lv2015} or gaze-input~\ncite{Rajanna2016, Gobel2013}. \typcite{Pakkanen2004} investigated foot-based interaction as a second input channel for non-accurate spatial tasks and found that foot interaction is appropriate, \enquote{maintaining adequate accuracy and execution time}. Highly related, \typcite{Saunders2016} explored indirect interaction with ring-shaped foot interfaces. However, the exploration by Saunders et al. was limited to 1) indirect interfaces and 2) two different layouts.

Further, research proposed multiple use cases for such foot-based input modalities. \typcite{Yin2003} presented an interactive animation system, controlled using foot gestures. \typcite{Simeone2014} used foot-based input for 3D~interaction tasks, \typcite{Schoning2009} presented support for navigating spatial data. Further examples include support for the interaction with large displays~\ncite{Jota2014, Felberbaum2016}, interactive floors~\ncite{Augsten2010a} and other public interfaces~\ncite{Fischer2014}. More general, \typcite{Alexander2012} and \typcite{Felberbaum2018} proposed user-defined foot-gestures for typical GUI tasks in different domains.

In recent years, research also focused on the applicability of foot-based interfaces for \acp{HMD}. \typcite{Matthies2013} presented a technical prototype to provide hands-free interaction for VR applications. \typcite{Fukahori2015} used the shifting of the user's weight on their foot for subtle gestures to control \acp{HMD} interfaces. Furthermore, \typcite{Fan2016} focused on foot-based interaction techniques for exploring a VR representation of a planet. Highly related, \typcite{Lv2015} used foot-based interaction techniques for controlling an \ac{AR} game. However, to the best of our knowledge, there is no systematic investigation of the human ability to interact with HMDs through foot-taps.

\input{tables/requirements_foot}

\subsection{Imaginary and Proprioceptive User Interfaces}

Gustafson et al.~\ncite{Gustafson2010, Gustafson2011a} introduced imaginary interfaces as a novel approach to interaction without any visual feedback, leveraging the human's ability to map the spatial memory to (physical) surfaces. \typcite{Dezfuli2012} extended this idea using proprioception~\ncite{Schmicking2010, Lopes2015}, the subconscious knowledge about the relative position and orientation of our body parts, showing that users were able to create a mental mapping between on-screen user interfaces and eyes-free touch on the hand. This work extends these ideas for foot-based interactions.