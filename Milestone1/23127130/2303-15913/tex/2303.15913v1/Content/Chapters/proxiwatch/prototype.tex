\subsubsection{Proxiwatch: Concept}
\label{sec:proxiwatch:concept}

When interacting with smartwatches, proximity-based interaction can support the user in overcoming the problems of the small touch area and speech interaction discussed above. This section presents two interaction styles, that can serve as an additional input modality for smartwatches.

\textfigH{proxiwatch/apps}{Example application for discrete interaction: An application launcher that allows users to launch applications by raising their arm.}

\paragraph{Discrete Interaction}

Discrete interaction is based on the directly accessible layers, as presented in section \ref{sec:proximity:exp2}. Within this set of layers, each layer can be mapped to a functionality in terms of a shortcut. Such a system can be used to directly select various items in a fixed set of objects (e.g., launcher, media player controls) by raising the arm within the boundaries of one of the target zones in front of the body. The analysis of the experiment presented above found that 4 layers are easily distinguishable for users. As an example for this style of interaction, this section focuses on an application launcher for a smartwatch. This launcher allows users to open up a favorite application by raising the arm (\reffig{fig:proxiwatch/apps}). Based on guidelines 2 and 4 (see section \ref{sec:proximity:discussion:guideline2} and \ref{sec:proximity:discussion:guideline4}), the most frequently used applications are presented as larger layers and close to the center of the interaction space. Further, based on guideline 3 (see section \ref{sec:proximity:discussion:guideline3}), the position of the shortcut positions is tailored to the user in order to adapt to their personal interaction area.


\textfigH{proxiwatch/brightness}{Example application for continuous interaction: A brightness control that lets the user modify the value by moving the arm alongside the line of sight.}

\paragraph{Continuous Interaction}

Continuous interaction allows the user to adjust a continuous value by moving the hand within the bounds of the personal interaction space, as presented in section \ref{sec:proximity:exp1}. Through visual feedback on the smartwatch, the user is able to quickly and efficiently adjust a value (e.g.,\ slider) just by moving the arm. For smartwatches, this style of interaction  can be used as an extension to discrete interaction for lists with more elements. ProxiWatch illustrates this technique with a brightness control for the smartwatch that allows users to adjust the value by moving the hand. The user can select a value by lowering the hand. Based on guideline 3 (see section \ref{sec:proximity:discussion:guideline3}), the part of the interaction area used for adjusting values is adopted to the user's personal interaction space. 

Both interaction techniques presented can be combined (e.g., discrete interaction to launch an application, continuous interaction to adjust a value in this application). In addition, traditional touch-based input is possible on each layer.

\paragraph{Implementation and Prototype}
\label{sec:proxiwatch:implementation}

This subsection illustrates the building process of a stand-alone, wireless prototype to enable proximity-based interaction concepts on a consumer smartwatch (Motorola Moto 360) in an iterative design process (\reffig{fig:proxiwatch/prototypes}).

The implementation of the prototype was based on a battery powered Arduino Nano with two infrared distance sensors (Sharp GP2Y0A21YK0F). Pre-tests indicated that a single distance sensor cannot cover the needed field of view to use the complete degree of freedom provided by the elbow joint. Therefore, the final design contained two distance sensors, slightly tilted relative to each other (\reffig{fig:proxiwatch/prototypes} f). When holding the hand in a rotation that allows to read the display of the watch, both sensors were directed towards the body of the user. The system reported the value of the first sensor as long as this sensor has the body of the user within its field of view. Otherwise, the value of sensor two was reported (\reffig{fig:proxiwatch/distance}). Depending on the body structure of the user, the handover point was found to be around \SI{20}{cm} distance. Because of the limited processing capabilities of the Arduino, the system transmitted the raw sensor data to a processing application on a mobile phone (Samsung Galaxy S4) via Bluetooth. The phone handled the incoming raw data and selected the appropriate sensor. In addition, the system used a Kalman filter to reduce the statistical noise of the returned sensor values. After processing, the phone sent the estimated distance to the smartwatch. To detect if a user raised the arm, the system used the acceleration sensor of the smartwatch. This allowed the system to support the discrete interaction technique presented above. Furthermore, the acceleration sensor was used to register a shake-wrist gesture, which can be used for secondary actions (i.e., select item).

\textfig{proxiwatch/prototypes}{Iterative design of the prototype: a) First version using a generic ultrasonic and infrared sensor b) second version using two infrared sensors c) third version with tilted infrared sensor alignment d) current version with boxed design.}

To confirm the viability of the prototype, the estimated distance values of the prototype were compared to the real distance (measured using an optical tracking system). The recorded data showed that the prototype robustly recognizes the distance to the user for the complete interaction space (average deviation \valSi{1.9}{1.19}{cm}, \reffig{fig:proxiwatch/distance}). Future work is needed to improve the quality of the measurements and to further miniaturize the prototype.

\textfigH{proxiwatch/distance}{The estimated distance values reported by the two sensors compared to the real distance. The handover between both sensors is at $\sim$21cm.}




