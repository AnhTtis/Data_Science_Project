\section{Interacting with Head-Mounted Displays}
\label{sec:relatedwork:hmds}

\acresetall

In the following, this thesis presents the related work in interacting with \acp{HMD}. First, the section gives an overview of the definitions of \acp{HMD}, \ac{AR} and \ac{VR} (section \ref{sec:relatedwork:hmds:def}) and presents a brief historical outline of the technical realization of such devices (section \ref{sec:relatedwork:hmds:implementation}). Second, the section introduces a set of requirements for the interaction with \acp{HMD} with respect to the vision of ubiquitous interaction in a digitally augmented physical world (section \ref{sec:relatedwork:hmds:requirements}). Finally, the section discusses four different streams of research that enable interaction with \acp{HMD} using 1) \nameref{sec:rw:hmd:accessory}, 2) \nameref{sec:rw:hmd:device}, 3) \nameref{sec:rw:hmd:voice} and 4) \nameref{sec:rw:hmd:body} and assesses these research streams with regard to the established requirements.

\subsection{Definitions and Background}
\label{sec:relatedwork:hmds:def}

\citebox{The ultimate display would, of course, be a room within which the computer can control the existence of matter. [...] With appropriate programming such a display could literally be the Wonderland into which Alice walked}{Sutherland1965}

With these words, \typcite{Sutherland1965} described his vision of the \enquote{Ultimate Display}. In his famous article, Sutherland made two fundamental demands to such a display: First, such a display should exert forces that can be perceived and utilized by the user so that \enquote{A chair displayed in such a room would be good enough to sit in}. Second, the display should be a \enquote{kinesthetic display} that can \enquote{make the display presentation depend on where we look}.

Three years later, as a very early step towards such an ultimate display, Sutherland presented what later became known as the \emph{Sword of Damocles}, the first ever \acl{HMD}. \typcite{Sutherland1968} described his \enquote{three-dimensional display} as a device \enquote{to present the user with a perspective image which changes as he moves. [...] The image presented [...] must change in exactly the way that the image of a real object would change for similar motions of the user’s head.}

Much has changed in the fifty years since Sutherland’s \emph{Sword of Damocles}: \acp{HMD} have become smaller and lighter~\ncite{Billinghurst2015}, we have seen the first wave of \ac{VR} applications come and go~\ncite{Cruz-Neira2015}, and with Google Glass and Microsoft Hololens, the first see-through \acp{HMD} have set out to bring mobile \ac{AR} to the end user market. 

Still, many of the concepts present in Sutherland’s glasses can be found in today’s \acp{HMD}: Such devices are \enquote{image display units that are mounted on the head. A unit consists of a helmet and small CRTs or liquid-crystal displays (LCDs) in a pair of goggles.}~\ncite{Shibata2002}. 

\acp{HMD} can be used to add virtual information to the experience of the real world perceived by the user in different levels: Various gradations on the continuum between true reality and complete virtuality are conceivable~\ncite{Milgram1995}. This range between reality and virtuality is referred to as \emph{Mixed Reality}. Yet, no clear definition of mixed reality exists until today~\ncite{Speicher2019}. 

\subsubsection{Virtual and Augmented Reality}

For the scope of this work, we now consider the two extremes of this continuum, \acf{VR}, and \acf{AR}. \typcite{Sherman2002} defined \emph{\ac{VR}} as \enquote{a medium composed of interactive computer simulations that sense the participant’s position and actions and replace or augment the feedback to one or more senses, giving the feeling of being mentally immersed or present in the simulation (a virtual world)}. \typcite{Azuma1997a} defined \ac{AR} as a variation of \ac{VR} that, while \ac{VR} \enquote{completely immerse a user inside a synthetic environment [...] allows the user to see the real world, with virtual objects superimposed upon or composited with the real world. Therefore, AR supplements reality, rather than completely replacing it}. This allows users to see, access, and modify digital information right in front of their eyes anytime, anywhere without losing the connection to the real world. Therefore, \ac{AR} allows the seamless connection of bits and atoms~\ncite{Ishii1997}, representing the digital and physical world.

On the technical side, \ac{VR} glasses use fully opaque displays. Thereby, the user is entirely surrounded by the virtual world; the (visual) reality is suppressed. \ac{AR} systems, in contrast, use partially transparent see-through displays, allowing the user to keep engaging with the surrounding reality. Additional sensing capabilities enable these devices to understand and interpret the environment and merge digital content with the physical world~\ncite{Kress2017}.

Just as \ac{VR} and \ac{AR} share many characteristics, so do the \acp{HMD} built for such applications. Therefore, the requirements for interaction with such devices often show overlaps. Nevertheless, both types have strengths and weaknesses: Due to the increased detachment from reality, \ac{VR} systems show a higher level of immersion~\ncite{Speicher2019}. While the accompanying loss of the (visual) connection to the surroundings is acceptable or even desired in a familiar and static environment like the living room (e.g., for games~\ncite{Pausch1997}), it becomes a problem in unfamiliar or rapidly changing environments like in mobile situations. 

Due to the advantages of \ac{AR} in mobile scenarios and the associated increased practicability, the focus of this work is on \ac{AR} \acp{HMD}. For easier readability, the remainder of this thesis will refer to \ac{AR} \acp{HMD} as \acp{HMD}.

\subsubsection{Output Stabilization, Tracking and Devices}
\label{sec:relatedwork:hmds:implementation}

The visual output of \acp{HMD} can be presented in different ways, depending on which parts of the world they are anchored to. \typcite{Billinghurst1998} defined the possible display methods through stabilization points: 

\begin{description}
	\item[Head-stabilized] interfaces are fixed to the user’s viewpoint, i.e., they provide an interface that moves together with the user and are always displayed at the same position (e.g., the \ac{HUD} interface of Google Glass was intrinsically restricted to this stabilization category).
	\item[Body-stabilized] interfaces are fixed relative to the user’s body position, i.e., they provide an interface that moves together with the user and allows the user to see different parts of the interface through rotating the head.
	\item[World-stabilized] interfaces are fixed to real-world locations, i.e., they provide an interface that stays always at the same physical location with the same orientation.
\end{description}

The possible display methods, namely different stabilization points for information, have increasing technical requirements for the underlying tracking system of the \ac{HMD}: While \emph{head-stabilized} systems do not require any head tracking, \emph{body-stabilized} systems require head-orientation tracking and \emph{world-stabilized} systems require full orientation and position tracking of the user’s head~\ncite{Billinghurst1998}.

Various approaches exist to provide this tracking information of the user's head position and orientation with different advantages and disadvantages depending on the use case. These approaches can be roughly grouped by the hardware used~\ncite{Zhou2008}:

\begin{description}
	\item[Sensor-based approaches] using e.g., gyroscopes, magnetic or mechanical sensors.
	\item[Vision-based approaches] using computer vision techniques on (depth) images.
	\item[Hybrid approaches] using a combination of sensor-based and vision-based approaches.
\end{description}

The tracking technologies can be further grouped by the location of the tracking hardware:

\begin{description}
	\item[Outside-In] systems use tracking integrated into the environment. The system recognizes the headset in the room and calculates estimations for the position and orientation of the device, which is then used to render appropriate visual output~\ncite{Dorfmuller1998}.
	\item[Inside-Out] systems, in contrast, have the necessary sensing hardware integrated into the headset and recognize features in the environment that are, in turn, used to estimate the position and orientation of the device~\ncite{Dorfmuller1999}. Research proposed multiple approaches for inside-out tracking based on (infrared) markers~\ncite{Rekimoto1998} or (color, grayscale or depth) image features~\ncite{Wuest2005}. 
\end{description}

Newer approaches further combine the process of inside-out tracking with the simultaneous creation of a map of the environment, a process known as \ac{SLAM}~\ncite{Izadi2011, Kerl2013, Henry2014}. 

In spite of the great progress achieved in recent years in the field of tracking and registering information in the real world, today's devices still face many problems. While tracking in closed spaces works reasonably well, there is still no conclusion on tracking in large outside and urban areas~\ncite{Pascoal2018}. By design, outside-in tracking systems are unsuitable for such large areas and inside-out systems are (at least today) still overloaded with the size of the area to be tracked. However, this tracking information is essential for a proper registration of information in the real world as discussed above. Furthermore, today's devices still suffer from a low resolution and field of view, as well as large and bulky form factors. However, the development of such devices indicates that these limitations may eventually vanish over time.

\subsection{Requirements}
\label{sec:relatedwork:hmds:requirements}

\def\reqHmdNoDevice{Minimize the Dependence on the Physical Appearance}
\def\reqHmdDirect{Maximize Directness of Interaction}
\def\reqHmdAcceptability{Maximize Social Acceptability}
\def\reqHmdSecondary{Minimize the Dependence on Secondary Control Devices}

In the following, this thesis establishes requirements for the interaction with \acp{HMD} that are later used to classify existing research streams and the interaction concepts used in today’s commercially available \acp{HMD}.

\subsubsection{The Disappearing Tangibility}
\label{sec:relatedwork:hmds:requirements:physicality}

A central difference between \acp{HMD} and other device classes is the increasing disappearance of tangibility. The course of development teaches us that \acp{HMD} are getting smaller and smaller, potentially to the point where they will have largely disappeared as physical devices, existing, for example, as smart contact lenses~\ncite{Conrad2014, TaehoKim2015}. Yet, the physical appearance of devices already gives us an indication of how we can communicate with them. With the disappearance of \acp{HMD} as physical and tangible devices, these communication cues (known as affordances~\ncite{Norman1999}) of \acp{HMD} as physical things are also disappearing and, thus, can no longer be used to encourage interaction (e.g., sliding with a finger alongside the frame of the device for Google Glass). Further, as these devices become smaller and smaller, on-device input might no longer be possible at all.

Therefore, interaction techniques should not rely on the physical appearance of \acp{HMD}. 

\reqbox{hmd:nodevice}{\reqHmdNoDevice}{With \acp{HMD} disappearing as physical devices, on-device input becomes infeasible. Interaction techniques should, therefore, not depend on the physical appearance and tangibility of such devices.}

Not only is the tangibility of the \ac{HMD} as a physical device disappearing, but the displayed information also has no tangibility: Information is represented as images, created in the head of the user, manifested as pixels on displays in front of the eyes. This problem of disembodiment of information is, of course, also present in other device classes: For example, in recent years, touch-based interaction has prevailed in many areas, especially for mobile use, as a central interaction concept. Such devices also display non-physical information. However, there are differences in the types of interaction called for by the visualization: The user interfaces of touch-devices are flat and exist behind a layer of glass, so that touching the display can be perceived as touching the visualization. Using \acp{HMD}, on the other hand, information \emph{breaks the glass} and can be spatially distributed in the space, merged with the real world and appearing as equal members of reality. 

Therefore, information leaves the limited space offered by today’s widespread device classes such as desktop PCs or smartphones, spreading into the physical world. Despite \emph{looking} like an equal member of reality, however, augmented information itself has no physical properties. This prevents the application of the types of interaction we learned from the real world: We mainly touch things to manipulate them. However, since virtual things have no tangibility, these interaction techniques fail with \acp{HMD}. 

As a result, the possibilities of direct interaction with information vanish. This becomes a challenge for interaction with \acp{HMD}, as more direct types of interaction are seen as more \enquote{natural} and \enquote{compelling}~\ncite{Forlines2007}: One of the reasons for the rapid and breakthrough success of smartphones was the radical focus on direct interaction: Such devices omitted physical keyboards and trackballs and relied purely on direct interaction via the touchscreen~\ncite{west2010browsing}.

As a possible solution, interfaces can register virtual information to physical objects in the real world, giving them a (proxy-) body to allow users to directly interact with the information. By design, this solution to the missing tangibility of digital information is only available for \emph{world-stabilized} interfaces and requires additional tracking of the (proxy-) objects. In addition, this solution restricts the mobility of users, since a suitable object must be available at the place of interaction.

As this solution is only feasible for a limited number of interaction situations and, further, only with \emph{world-stabilized} interfaces, other approaches are needed. Therefore, this thesis focuses on other approaches to compensate for the disappearing tangibility of the presented information and the resulting decrease of direct interaction possibilities.

\reqbox{hmd:direct}{\reqHmdDirect}{Interaction techniques for \acp{HMD} should maximize the directness of the interaction (e.g., by providing means for direct interaction) to compensate for the missing tangibility of the displayed information.}

\subsubsection{Head-mounted Displays in a mobile context}

Since Sutherland’s \emph{Sword of Damocles} in 1968, \acp{HMD} have become smaller~\ncite{Billinghurst2015}, untethered~\ncite{Feiner1997} and, thus, more mobile. This increased mobility poses further challenges for the interaction with HMDs to support mobile situations.

Throughout the day, we find ourselves in different spatial and social contexts: We are standing in crowded subways or wandering alone across a wide field, participating in large meetings or intimate conversations. These changes in context lead to requirements for interaction techniques to be suitable for such situations:

First, depending on the context, interaction techniques can be perceived as socially inappropriate from the outside or as embarrassing by the user himself because it might affect the social image, especially for new and unknown classes of devices~\ncite{Koelle2017}. For example, speaking to technology in public environments~\ncite{Efthymiou2016} or touching the groin area~\ncite{Harrison2014} of the body are perceived as inappropriate.

Therefore, interaction techniques should focus on socially acceptable ways of interaction.

\reqbox{hmd:appropriate}{\reqHmdAcceptability}{Interaction techniques for \acp{HMD} should be socially accepted in a variety of contexts.}

Second, mobility leads to frequent changes in location. Each of these changes of location entails the chance to forget things, leave things behind, or lose them. Alongside the general problems that arise as a result, this is particularly critical for interaction with \acp{HMD} when the interaction is bound to a secondary device. 

Therefore, interaction techniques should work autonomously and not depend on secondary devices.

\reqbox{hmd:nosecondary}{\reqHmdSecondary}{Interaction techniques for \acp{HMD} should not depend on secondary devices as these might be misplaced or lost.}

\subsection{Related Work}

In the following, this section discusses the four major streams of research in the field of interacting with \acp{HMD} with regard the the established requirements. This includes work in the fields of 1) \nameref{sec:rw:hmd:accessory}, 2) \nameref{sec:rw:hmd:device}, 3) \nameref{sec:rw:hmd:voice}, and 4) \nameref{sec:rw:hmd:body}.

\subsubsection{Accessory-Based Interaction}
\label{sec:rw:hmd:accessory}

As discussed in the context of \refreq{req:hmd:direct}, the design of head-mounted displays renders traditional touch-based interaction techniques unusable as touch on the display itself is not feasible. Research, as well as manufacturers of \acp{HMD}, tried to transfer touch-based interaction to this new class of devices in different ways. Interaction techniques for Sony’s and Epson’s \acp{HMD}, SmartEyeglasses and Moverio, are built around a wired handset for indirect pointer-based interaction, imitating the mouse interaction known from desktop computers. Research has also provided further possibilities to interact with such devices using physical accessories: As prominent examples, \typcite{Ashbrook2011} presented an interactive ring and \typcite{Dobbelstein2015} proposed an interactive belt for unobtrusive touch input. Other proposed accessories include augmentations to the user’s pocket~\ncite{Dobbelstein2017} or sleeves~\ncite{Schneegass2016}. 

Such accessory interfaces are not bound to the physical appearance of one specific device and are considered socially acceptable~\ncite{Tung2015}. However, such interfaces do not provide means for direct interaction~\ncite{Hsieh2016} and, further, can be misplaced and lost.

\subsubsection{On-Device Interaction}
\label{sec:rw:hmd:device}

As another approach, Google used \emph{on-device} input on a one-dimensional touch-pad for interacting with its \ac{HMD}, Google Glass. Research added use cases for this style of interaction. For example, \typcite{Islam2018} proposed tapping gestures for authentication on the frame of the device. Other examples for on-device tapping and sliding techniques include games~\ncite{Hsu2014} or text entry~\ncite{Grossman2015}.

Such on-device interaction techniques show a high social acceptability~\ncite{Alallah2018} and do not require secondary devices. However, on-device input is based on specific physical properties of the devices and does not provide means for direct interaction. Further, user tests showed little enthusiasm for this type of input for \acp{HMD}~\ncite{Tung2015}.

\subsubsection{Voice-based Interaction}
\label{sec:rw:hmd:voice}

Speech is a central component of human-to-human interaction~\ncite{Kohler2017}: It is always available and provides a natural way of transporting information. Recent advances in speech recognition~\ncite{Hinton2012} and natural language processing~\ncite{manning2014stanford} have led to systems that are suitable for everyday use and can be deployed to mobile devices with limited resources, even for offline use~\ncite{He2018}. Taking together the naturalness of input and the technical feasibility of such interfaces, speech-based input appears to be a compelling way to interact with \acp{HMD}. The industry seems to agree: From Google Glass and Microsoft Hololens to Magic Leap: Voice input is one of the fundamental interaction concepts of these devices. This widespread use of voice-based interaction techniques is based on a number of strong advantages of such interfaces: Naturally, language has no inherent connection to a physical device and representation.

However, voice-based interfaces show problems in many areas: Users might have problems to build a mental model of the system, resulting in systems failing to \enquote{bridge the gap between user expectation and system operation}~\ncite{Luger2016}. Further, language can only describe, not directly manipulate and, thus, excludes the possibility of direct interaction with content~\ncite{Frohlich1993}. \typcite{Shneiderman2000} depicts further problems of voice-based interfaces: \enquote{Speech is slow for presenting information, is transient and therefore difficult to review or edit, and interferes significantly with other cognitive tasks.}

In particular, voice-based interfaces impose problems for mobile use with \acp{HMD}: In the mobile context, other people may be nearby while interacting with the device, raising the question of social acceptance and privacy concerns~\ncite{EaswaraMoorthy2015}. Referring to these situations, \typcite{Alallah2018} compared different input modalities for \acp{HMD} regarding their social acceptability and found the lowest approval rates for voice input compared to other input modalities. In addition, the recognition quality of speech input depends on background noise, rendering such techniques difficult to use in urban environments~\ncite{Starner2002}.

\subsubsection{Body-based Interaction}
\label{sec:rw:hmd:body}

With the increasing proliferation of (low-cost) sensor hardware and advances in computer vision, research began to incorporate the human body as an input modality for interacting with \acp{HMD}. Such \emph{body-based} interaction techniques leverage movements of (parts of) our body as an input modality. The possibilities of such body-based interactions are manifold, reaching from touch input on the surface of our body~\ncite{Harrison2010} to gesture-based interfaces~\ncite{Colaco2013} and eye-based gaze interaction~\ncite{Piumsomboon2017}.

While there are great differences depending on the interaction technique, these techniques nevertheless share vast similarities: The interaction does not rely on the physical properties of the \acp{HMD} nor a secondary device. Further, research showed the social acceptability of such interfaces~\ncite{Hsieh2016} and provided examples for direct interaction~\ncite{Harrison2011a}.

\subsection{Conclusion}

\input{tables/requirements_hmd}

Comparing the basic interaction concepts, body-based techniques show the strongest suitability with respect to the previously established requirements (see table \ref{tab:req:hmd}). In the following, this thesis will, therefore, focus on body-based interaction techniques for \acp{HMD}.
