\section{Around-Body Interaction}
\label{sec:rw:aroundbody}

This section presents definitions and background (section \ref{sec:rw:aroundbody:definitions}) relevant to the topic of \aroundbodyinteraction{} and proposes a classification of such interfaces based on the limb used for input and the stabilization of the output (section \ref{sec:rw:aroundbody:classification}).

\subsection{Definitions and Background}
\label{sec:rw:aroundbody:definitions}

The use of the degrees of freedom offered by our upper and lower limbs for interacting with computer systems and \acp{HMD} is not new; there exists already a variety of interaction techniques for \acp{HMD} that leverage the space \emph{around} the user for interaction. However, despite a multitude of examples of such \aroundbodyinteraction{} techniques, these interaction techniques were only considered separately and not as a common concept. Therefore, this work proposes to conceptualize these interactions in the common framework of \aroundbodyinteraction{} to build a comprehensive concept for interaction with \acp{HMD}.

The following section as well as the remainder of this thesis uses the extended definition of \aroundbodyinteraction{} introduced in section \ref{sec:introduction:aroundbodyinteraction}, which goes beyond the initial definition proposed by~\typcite{Chen2014}. However, it is not possible to separate \aroundbodyinteraction{} sharply from other body-based interaction techniques presented in section \ref{sec:rw:body:onbody}, there are overlaps in these areas. For example, a touch of a body part, depending on the point of view, can be considered as on-body interaction as well as \aroundbodyinteraction{}. The difference lies in the focus of the view: While in on-body interaction the touch itself is the focus of the interpretation, in \aroundbodyinteraction{} it is the movement itself. 

\subsubsection{Limb Movement}

\textfigH{introduction/skeleton}{The skeleton joint model used by Microsoft Kinect.}

The possible movements of the human body result from the degrees of freedom of the connecting points of the bones, called joints~\ncite{Whiting2018}. Not all of these joints are movable, and some are only movable to a very limited extent~\ncite{Archer2003}. Therefore, to assess the possible movements of the human body, a simplified model of the human skeleton is typically used in the body of related works, considering the 15-25 joints most important to human motion.~\ncite{Lee1985, Rocha2015}. 

Looking at these models, the human limbs stand out in particular. For example, the skeleton tracking by the Microsoft Kinect uses a total of 20 body joints (see figure \ref{fig:introduction/skeleton}) with 16 of these joints belonging to the users' limbs. This is also reflected in our daily experience: The interactions with the world in everyday life are mainly driven by changes in the degrees of freedom of the joints of the limbs.

\subsubsection{Gesture-based Interaction}

\Aroundbodyinteraction{} relies on leveraging limb movements to communicate information to the \acp{HMD}. The information is, thus, encoded in the movement of the limbs, a principle known \emph{gestures}. More precisely, \typcite{Kurtenbach1990} defined gestures as \enquote{motion of the body that conveys information. Waving goodbye is a gesture. Pressing a key on a keyboard is not a gesture because the motion of a finger on its way to hitting a key is neither observed nor significant. All that matters is which key was pressed.} \typcite{Billinghurst2018} added that \enquote{this is true regardless of the gesture that was used to push the key. It could have been pushed lovingly or in anger. Either could be easily sensed by an observer. But both are irrelevant to the computer, which only cares about what key was pushed when.}

There is a wide range of different classifications of gestures depending on the context of usage. Therefore, this section cannot be a conclusive discussion of gestures, but merely presents the definitions relevant to this thesis.

\typcite{cadoz2000gesture} proposed a classification of such gestures based on their relationship with the environment as \emph{ergotic} (modify the environment), \emph{epistemic} (receive knowledge from the environment) and \emph{semiotic} (transmit information to the environment). For this thesis, the classification of gestures as a means of transmitting information to the environment (semiotic) is most relevant: If in this classification, the \ac{HMD} is defined as the relevant environment, then this classification quite precisely describes the core idea of \aroundbodyinteraction{}: Using movements of the limbs to transmit information to the \ac{HMD}. 

The temporal aspect can also be included as a further level of classification. However, the distinction is not concerned with the total duration of the interaction, but whether information a) is transmitted by the execution and completion (discrete gesture) or b) is transmitted continuously during the execution (continuous gesture)~\ncite{buxton2007multi}.

\subsection{Classification of Around-Body Interfaces}
\label{sec:rw:aroundbody:classification}

\textfigH{introduction/designspace_reduced}{A classification of \aroundbodyinteraction{} techniques based on the 1) \emph{limbs used for input} and the 2) \emph{stabilization method of the output}. As discussed in section \ref{sec:rw:aroundbody:classification}, this thesis focuses on \emph{upper} and \emph{lower} limbs and \emph{body-stabilized} and \emph{world-stabilized} interfaces.}

In this section we propose a classification of \aroundbodyinteraction{} techniques based on the 1) limbs used for input and the 2) stabilization method of the output.  

It is difficult to distinguish the body parts involved in movements since individual interaction steps typically comprise the seamless interaction of the movement of several joints of the body at the same time~\ncite{Lu2012}. When we use our hand to open a door, we first use the degrees of freedom of the shoulder and arm to position the hand before the degrees of freedom of the hand are used to perform the interaction. In this work, the affected degrees of freedom of the individual joints are, therefore, not studied independently of each other, but as a collective movement of the entire limb.

\subsubsection{Input - Upper and Lower Limbs}
\label{sec:rw:around:upper}

As discussed before, the limbs allow us to perform interactions in the space around our body. The input can be classified by the group of limbs involved: upper, lower, or both.

\paragraph{Input using Upper Limbs}

The \emph{upper limbs} can support interactions in front of the upper part of the body. This can be achieved by using the degrees of freedom of our shoulders, elbows, and wrists, as well as the many further degrees of freedom offered by our hands and fingers.

Figure \ref{fig:introduction/designspace_reduced} shows examples of interaction techniques using the upper limbs together with the different output stabilization methods. These examples are discussed in more detail in chapters \ref{ch:proximity:merged} and \ref{ch:cloudbits}.

\paragraph{Input using Lower Limbs}
\label{sec:rw:around:lower}

The \emph{lower limbs} can support interactions in front of the lower part of the body by leveraging the degrees of freedom offered by the hip, knee, and ankle joints. Such interactions are particularly suitable for situations where the user's hands are not available.

Figure \ref{fig:introduction/designspace_reduced} shows examples of interaction techniques using the upper limbs together with the different output stabilization methods. These examples are discussed in more detail in chapters \ref{ch:cheesyfoot} and \ref{ch:walktheline}.

\paragraph{Input using Both Groups of Limbs}

As a result of requirement \refreq{req:body:blocking} (\reqBlocking) introduced in section \ref{sec:relatedwork:body:requirements}, this thesis focuses on interaction techniques that use as few body parts as possible at the same time. Interaction techniques using upper and lower limbs at the same time complicate the usage in the real world, as they might collide with the regular interaction of the user with the real world.

Therefore, this thesis will not cover \aroundbodyinteraction{} using a combination of upper and lower limbs. However, the increased expressiveness by using multiple limbs simultaneously can also be beneficial in certain interaction situations. Therefore, chapter \ref{sec:conclusion:futurework} presents directions for future work on such interfaces.

\subsubsection{Output - Head, Body and World Stabilization}

As discussed in section \ref{sec:relatedwork:hmds:def}, \acp{HMD} support visual output on a scale from head-stabilization to world-stabilization. These different types of output influence the techniques suitable for interaction.

\paragraph{Head-Stabilized Output}

By design, \emph{head-stabilized} interfaces do not merge information with the real world, but only offer a static overlay. In recent years, such \ac{HUD} interfaces have diminished in importance because of the wide availability of low-cost and robust methods for tracking the orientation of \acp{HMD}.

Based on this decline in interest, this thesis will not cover \aroundbodyinteraction{} with such interfaces in the main contributions. However, chapter \ref{sec:conclusion:futurework} gives an outlook on possible interaction techniques for this kind of visual output.

\paragraph{Body-Stabilized Output}

\emph{Body-stabilized} output can display interfaces that move as the user moves. Together with hand and foot tracking, this allows for interfaces that are registered to parts of the body, regardless of where the user is and whether he is currently moving.

Figure \ref{fig:introduction/designspace_reduced} shows examples for such interaction techniques using the upper and lower limbs. These examples are discussed in more detail in chapters \ref{ch:proximity:merged} and \ref{ch:cheesyfoot}.

\paragraph{World-Stabilized Output}

\emph{World-stabilized} output can display interfaces that are not registered to the user (or parts of the user), but the real world. Such interfaces do not move along with the user. As a consequence, the user can move around or along such interfaces and thus change the relative position and orientation to the interface. This relative position and orientation can further be used as an additional input dimension.

Figure \ref{fig:introduction/designspace_reduced} shows examples for such interaction techniques using the upper and lower limbs. These examples are discussed in more detail in chapters \ref{ch:cloudbits} and \ref{ch:walktheline}.

\subsubsection{Interaction Situations}

In addition to the two-dimensional classification according to the \emph{limbs used for input} and the \emph{stabilization of the output}, this thesis proposes to classify \aroundbodyinteraction{} techniques based on their support for common interaction situations as introduced in section \ref{chp:introduction:challenges}: \inplaceUpper{}, \mobilityUpper{}, \singleuserUpper{}, \multiuserUpper{}, \continuousUpper{} and \discreteUpper{}.

\subsection{Conclusion}

The two-dimensional classification of \aroundbodyinteraction{}s by the limbs used for input and the stabilization of output shows four areas for such interaction techniques. This work will focus more closely on these four areas and offer a corresponding interaction technique for each of these combinations. More precisely, 

\begin{description}
	\item[Chapter \ref{ch:proximity:merged}] presents \projProximity{} and focuses on interaction with the upper limbs for body-stabilized interfaces, contributing solutions for \singleuserLower{} \mobilityLower{} situations, providing support for \continuousLower{} and \discreteLower{}.
	\item[Chapter \ref{ch:cloudbits}] presents \projCloudbits{} and focuses on interaction using the upper limbs and world-stabilized interfaces, contributing solutions for \continuousLower{} in \multiuserLower{} \inplaceLower{} situations.
	\item[Chapter \ref{ch:cheesyfoot}] presents \projCheesyfoot{} and focuses on interaction using the lower limbs and body-stabilized interfaces, contributing solutions for \discreteLower{} for \singleuserLower{} and \mobilityLower{} situations.
	\item[Chapter \ref{ch:walktheline}] presents \projCheesyfootToGo{} and focuses on interaction using the lower limbs and world-stabilized interfaces, contributing solutions for \discreteLower{} for \mobilityLower{} and \singleuserLower{} situations.
\end{description}

As each combination of these input and output possibilities entails specific requirements for interaction, each chapter will present the requirements and a review of the related works for the respective areas.












