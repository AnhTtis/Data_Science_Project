\section{Integration and Future Work}
\label{sec:conclusion:futurework}

As outlined in the introduction of this thesis (chapter \ref{ch:introduction}), a single body-based interaction technique cannot support all situations a user might encounter during the day. Instead, an integrated set of interaction techniques is necessary that allows interaction while particular body-parts are encumbered. 

As illustrated throughout the thesis, the interaction techniques presented already support a variety of situations which users may encounter during a day. However, to allow for ubiquitous interaction with such devices in all everyday situations, it must be possible to perform all types of interaction using all limbs. Therefore, it will be necessary to first identify a set of interaction patterns which are necessary for interaction with this device class. In a second step, this must be translated into interaction techniques to support the respective situations in each of the presented quadrants of the design space. This is a major challenge that is outside of the scope of this thesis. Therefore, further work in this area is necessary to conclude on these challenges.

Approaches for the continuation of the work in the individual areas are given at the end of the respective chapters. This section, in addition, focuses on open questions and challenges for future research that arise from the vision of an integrated set of \aroundbodyinteraction{} techniques for interacting with \acp{HMD}.

\textfigH{conclusion/designspace}{The contributions of this thesis and possible directions for future work in the design space of \aroundbodyinteraction{}.}

\subsection{Head-Stabilized Interfaces}

Even though the rapid development in \ac{HMD} hardware and software led to a decreased usage of \emph{head-stabilized} interfaces, they are still useful in specific situations and, thus, interaction techniques should support such interfaces.

Despite the focus on \emph{body-stabilized} interfaces, we want to argue that the presented interaction techniques in the contributions \projProximityS (for the \emph{lower limbs}) and \projCheesyfootS (for the \emph{upper limbs}) can be used as a foundation to inspire future \emph{head-stabilized} interfaces. 

\paragraph{Upper Limbs} Instead of anchoring the visual output to the user's palm, the visual output can also be displayed as a \ac{HUD} visualization. Through the sense of proprioception, users can continuously scroll through or discretely select layers without looking at their hand. 

\paragraph{Lower Limbs} The second experiment focusing on indirect interfaces used a floating visualization in front of the user. While the interface was still anchored to the body of the user as it stayed in position when the user rotated the head, we still consider the results to be transferable to \emph{head-stabilized} interfaces.

\subsection{Interfaces for Simultaneous Use of Upper and Lower Limbs}

The simultaneous use of multiple limbs limits the possibility of use in many situations, as limbs used to interact with the system are no longer available to interact with the real world. Therefore, this work focused on interaction using individual limbs.

However, inspired by the field of whole-body interaction, interacting using multiple limbs simultaneously can increase the expressiveness of interactions and is, therefore, an important field for future work. In the following, this section presents ideas for the integration of upper and lower limb interaction, grouped by the stabilization of the output. Figure \ref{fig:conclusion/designspace} depicts these examples of the integration of interaction techniques..

\paragraph{Head-Stabilized Interfaces}

For head-stabilized interfaces, the contributions \projProximityS and \projCheesyfootS could be combined to a system that allows the selection of content (displayed as a \acp{HUD} interface) using movements of the user's arm. Foot-taps of the user can further provide input to the selected layer. As shown in chapter \ref{ch:cheesyfoot}, the sense of proprioception allows users to split the area in front of their feet into multiple interactive zones that can be tapped with the feet without visual guidance. 

\paragraph{Body-Stabilized Interfaces}

Similar to the head-stabilized interface, body-stabilized interfaces can combine the input using the upper and lower limbs. Again, foot-tapping can act as a second input modality to provide input for individual layers selected using the hand of the user.

\paragraph{World-Stabilized Interfaces}

For world-stabilized interfaces, the interaction techniques in \projCheesyfootToGoS could be used for the selection of applications which, once selected, pop out of the floor. As a result, the interaction techniques from \projCloudbitsS and \projProximityS could be used for further interaction and spatial classification of these applications and information.

\subsection{Selection of a Suitable Interaction Technique Depending on the Context}

As discussed before, interaction techniques can be rendered unsuitable by the context of use. When we carry things in our hands, we cannot use our hands for interaction. When we walk, we cannot use foot-tapping for interacting and, vice versa, when we stand, we cannot use a locomotion-based interaction technique. This raises the problem of how the user can select a suitable interaction technique. 

Simultaneous availability of all interaction techniques as the most straightforward solution leads to many problems similar to the \emph{Midas Touch Problem} in gaze-based interaction: How can natural movement be distinguished from the interaction? The constant availability of all interaction techniques would, thus, lead to a large number of false actions by the system.

Another simple solution could be the explicit selection of an interaction type by the user. However, this selection must also be carried out somehow - possibly by operating a switch, which again requires the use of the hands and is therefore not possible in all situations.

In this field, therefore, further work is still necessary to reach a truly integrated system, which - based on the context and the situation of the user - can decide which interaction techniques are appropriate for the situation.

\section{Concluding Remarks}

The recent history of technological progress teaches us that we are on the way to ever smaller and more powerful \acp{HMD}, that could one day take on the role that smartphones play in our lives today. Thus, the interaction with such devices could - 50 years after Sutherland's initial steps - finally move out of the laboratory and into the real world; to private homes, remote rural areas and lively urban spaces. 

Certainly, this work cannot provide a conclusive picture of how we will interact with these devices in the future. However, it has made a substantial contribution towards a vision for future interaction with such devices by harnessing the degrees of freedom offered by our bodies for more natural, pleasant and fun interactions.