\section{Related Work}
\label{sec:proximity:rw}

Chapter \ref{ch:relatedwork} discusses the related works on interaction techniques for \acp{HMD}. The following section presents a set of requirements for interacting with \acp{HMD} using the upper limbs and, in the following, categorizes relevant research with regards to the requirements. 

\subsection{Requirements}

The following section presents a set of requirements for one-handed interactions with \acp{HMD} derived from the related works. The requirements are then used to compare the most relevant related work (see tables \ref{tab:req:proximity_twohanded}, \ref{tab:req:proximity_discrete} and \ref{tab:req:proximity_continuous}).

\begin{description}
	\item[R3.1: Independent Usage] Particularly in a mobile context, it is necessary to burden as few body parts as possible with the interaction so that they are available for the normal interaction with the world. Therefore, interaction techniques should focus on one-handed interaction and not require any additional body parts for interaction.
	\item[R3.2: Direct Interaction with Content] A direct spatial connection of input and output (i.e., input and output happen at the same physical location) allows for more \enquote{natural} and \emph{compelling} interactions~\ncite{Forlines2007}. Therefore, systems should provide such a direct spatial connection.
	\item[R3.3: Support for Peripheral or Proxemic Interactions] In many situations, it can be a hindrance to completely draw the user’s (visual) attention to the interface. Therefore, systems should allow interactions without complete visual focus.
	\item[R3.4: Discrete Interaction] Discrete interaction allows fast and short interactions through shortcuts. Therefore, systems should provide means for discrete interaction with content.
	\item[R3.5: Continuous Interaction] Continuous interaction allows fine granular interaction with information. Therefore, systems should provide means for continuous interaction with information.
\end{description}

\subsection{Interaction with the Upper Limbs}

There is a large body of related works on interaction with the upper limbs, most of which relate to the field of gesture-based interaction.

The first approaches to support such interactions started appearing towards the end of the 1980s. \typcite{Zimmerman1987} presented the \emph{DataGlove}, a device supporting real-time position, orientation, and posture tracking of the user’s hand. \typcite{Quam1990} demonstrated how such a device could be used for gesture recognition. These devices typically consisted of a glove, worn by the user, and augmented with a set of sensors or a mechanical construction to track the position and orientation~\ncite{Sturman1994a}.

To overcome the limitations associated with the need to wear a glove, research proposed optical systems that use computer vision to track the user’s hands without any hardware attached to the body ~ \ncite{Maqueda2015}. While the first systems were only able to recognize static postures of the user’s hand~\ncite{Pavlovic1997}, research brought forth various approaches to also understand the temporal dimension of gestures~\ncite{Wu1999}.

Research proposed multiple techniques for interacting with the hands in front of the upper body of the user without a secondary device. These techniques fall into the group of mid-air gestures~\ncite{aigner2012understanding}, also referred to as \emph{Free-Hand}~\ncite{Ren2013} or \emph{Bare-Hand}~\ncite{VonHardenberg2001}. 

\subsubsection{Two-Handed Gestures}

As a prominent example, \typcite{Mistry2009} presented a wearable interface supporting natural gesture interaction. Building on this, \typcite{Datcu2013} proposed two-handed mid-air interaction with \acp{HMD} through hand and finger gestures. Further, \typcite{Benko2012} proposed a combination with tangibles and a system to manipulate virtual objects the \enquote{same way [as] users manipulate real world objects}. 

Such two-handed mid-air gestures have also been proposed for interacting with various types of computing systems, from stationary systems such as tabletops~\ncite{Hilliges2009}, public displays~\ncite{Muller2014} or television sets~\ncite{Sang-HeonLee2013} to highly mobile systems such as smartphones~\ncite{Aslan2014} and smartwatches~\ncite{ArefinShimon2016}.

\input{tables/requirements_proximity_twohanded}

While useful and practical, two-handed interaction limits the suitability of interaction techniques during daily use as both hands need to be free for interaction. Table \ref{tab:req:proximity_twohanded} compares the related work in two-handed gestures to the requirements presented above.

\subsubsection{One-Handed Gestures}

To overcome the problems of two-handed interfaces, research proposed one-handed interaction techniques. In the following, this thesis presents these approaches, grouped as discrete and continuous interaction techniques.

\paragraph{Discrete Gestures}

Research presented a variety of discrete one-handed interaction techniques. As two prominent examples of this group of interfaces prominent example, \typcite{Colaco2013} showed how to capture and interpret fine-grained single-handed gestures, and \typcite{Akkil2016} compared the accuracy of different pointing gestures to communicate locations. Beyond sole interacting with the \ac{HMD} itself, \typcite{Kollee2014} proposed a set of interaction techniques for interacting with surrounding devices in a smart space.

Further examples include interaction techniques in the industrial context~\ncite{Witt2006} and the combination of hand gestures with finger gestures~\ncite{Hsieh2016}, head-pointing~\ncite{Kyto2018} or other body parts~\ncite{Heo2017}.

Highly related, \typcite{Xu2018} proposed a body-stabilized mid-air interface that is bound to the user’s wrist. Users can select items in this interface by pointing to items using the index finger. However, this approach requires an outstretched arm and is, therefore, prone to fatigue. In addition, the approach only displays a selection menu - actual content appears outside the interface. Therefore there are no possibilities for direct interaction with content. Further, all of the presented approaches are missing means for continuous interaction with information. Table \ref{tab:req:proximity_discrete} compares the related work in discrete one-handed gestures to the requirements presented above.

\input{tables/requirements_proximity_discrete}

\paragraph{Continuous Gestures}

Beyond discrete gestures, research also presented approaches for continuous one-handed interaction with information. For example, \typcite{Whitmire2017} presented one-handed finger gestures and \typcite{Buchmann2004} presented a system for direct manipulation of virtual objects in \ac{AR}. Further, \typcite{Khademi2014} presented continuous one-handed mid-air gestures for stroke rehabilitation. Highly related, \typcite{Chen2014} proposed a mid-air \aroundbodyinteraction{} technique leveraging the degrees of freedom of the elbow joint. 

These gesture-based approaches do not relay on the physical appearance of devices, nor on secondary devices and can, further, help to provide more direct interaction while preserving social acceptability of devices. 

However, all the presented approaches only consider continuous interaction and, thus, cannot support shortcuts as a fast technique for interacting with information. Table \ref{tab:req:proximity_continuous} compares the related work in discrete one-handed gestures to the requirements presented above.

\input{tables/requirements_proximity_continuous}

