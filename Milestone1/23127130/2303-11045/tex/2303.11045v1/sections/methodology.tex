\section{Methodology}
\label{sect:methodology}

We create this survey by systematically reviewing a large body of relevant research work.
To find research work and determine its relevance, we conducted a systematic search, which we briefly explain in this section.
% To start with, we employed a core of highly-influential research papers that were initially known to us, as they were published at top-level conferences (e.g., \todo{[here provide list of conferences]}) and which mainly focused on improving the scalability of BFT consensus over state-of-the-art approaches, e.g., by proposing a novel protocol or ideas for advancing existing protocols. This set of research papers includes \todo{[here name and cite papers like Avalanche, Algorand, HotStuff and more]}. 
We performed a systematic search focusing on the scalability of BFT consensus.
Since we aim to increase transparency and reproducibility, we briefly present our search methodology to gather and select these research papers, which mainly originated from the field of distributed systems, and especially the BFT and blockchain communities.
 Our main ambitions are the following:
\begin{itemize}[leftmargin=1em, itemsep=.1em, parsep=.1em, topsep=.1em,partopsep=.1em]
 \item Find distinct approaches in the literature for improving the \emph{scalability of BFT consensus}.
 \item Identify and classify scalability-enhancing techniques to create a taxonomy for scalable BFT.
\end{itemize}
%\todo{Papers are from XYZ conferences, ...}

\subsection{Search Strategy} 
For literature research, we used Semantic Scholar~\cite{semantic_scholar}, whose API allows the automated download of a large number of references. 
We manually crosschecked with Google Scholar to ensure relevant papers were included.
We employed the following search queries without filters on the publication date: 

% 954 papers selected by query
\begin{quote}
\underline{Search~1:} \\
\textit{Query} = Byzantine consensus scalability blockchain \\
\textit{Publication Type} = Journal or Conference \\
\textit{Sorted by Relevance (Citation Count)} = 250 most cited publications 
\end{quote}
 \begin{quote}
\underline{Search~2:} \\
\textit{Query} = Byzantine consensus scalability blockchain \\
\textit{Publication Type} = Journal or Conference \\
\textit{Sorted by Date} = 250 newest publications 
 \end{quote}
% https://www.semanticscholar.org/search?year[0]=2008&year[1]=2021&publicationType[0]=JournalArticle&publicationType[1]=Conference&q=bft%20consensus%20scalability%20blockchain&sort=relevance&page=1&pdf=true
 
For each search query, on December 17, 2021, we downloaded all results (954 papers) and sorted them locally by relevance (Search~1) and by date (Search~2). 
The first search favors relevance (citation count) to ensure that we can cover the most influential works for the topic, while the second search favors publication date to ensure that we can also regard the most recent publications, which might not have been cited often enough due to their recency. 
With these searches, we cover all publications with at least 11 citations and further capture all publications that have been published since January 2021. 
By using two different sortings, we aim to include both the most relevant and most recent works. 
We found that the search engine could handle synonyms well, \eg papers would not evade our systematic search when using \enquote{agreement} instead of \enquote{consensus}.
After that, we combined the results of these queries and sanitized them for duplicates.
 % \hr{``up to 11'': IMHO heisst nur die mit 11 oder weniger zitationen werden abgedeckt. Ist da nicht evtl 11 oder mehr gemeint?}
 
 %\https://www.semanticscholar.org/search?year%5B0%5D=2006&year%5B1%5D=2021&publicationType%5B0%5D=JournalArticle&publicationType%5B1%5D=Conference&q=byzantine%20consensus%20scalability%20blockchain&sort=relevance&pdf=true
 
% \note{cb. Also state additionally used sources. To be completed}
%Apart from the results obtained by these queries, we also used the well established dependability survey of Avi{\v{z}}ienis et al.~\cite{avizienis04basic} to raise a general understanding of resilience in distributed systems. Additionally, we included some classical non-IoT-specific literature works to establish a broader understanding towards the term resilience, in particular the works of~\ref{cite here our additional papers that do not appear in the search but we used them anyways because we had some bias?}.
%\note{pe: The two questionmarks should be taken care of in the final version}
 
 
\subsection{Selection Criteria} 
Further, we employ a set of selection criteria that can be applied to determine if a paper found by the search queries is original research and \textit{potentially relevant}. This means it is selected for inclusion in the survey as long as no exclusion criteria apply. These criteria also encompass conditions used to assess the quality of a found paper. 
 
 \emph{Inclusion criteria} -- A paper is included if its contributions satisfy one of the following criteria:
 
 %\sketch{Todo: Discuss inclusion criteria}
 \begin{itemize}[leftmargin=1em, itemsep=.1em, parsep=.1em, topsep=.1em,partopsep=.1em]
\item The paper presents a novel technique for \textit{improving the scalability} of communication-based Byzantine consensus
\item The paper \textit{combines existing scalability-enhancing techniques}, or ideas, in a novel way, achieving better results than state-of-the-art protocols
 \end{itemize}



 \emph{Exclusion criteria} -- The exclusion process is applied \textit{after inclusion}.
 A paper is excluded if only one of the following criteria applies:
 
  \begin{itemize}[leftmargin=1em, itemsep=.1em, parsep=.1em, topsep=.1em,partopsep=.1em]
 	%\item The paper is not peer-reviewed; [do we want that?]
 	\item The paper is not a research paper (no practical reports, workshop invitations, posters, or other surveys).
 	\item The paper does not cover the scalability aspect sufficiently from a technical point of view or does not originate from the field of computer science (\ie not originating from the right `field', \eg we do not want papers from business informatics or social science).
 	\item The presented paper proposes a scalability mechanism but does not present a careful experimental evaluation showing how it can actually improve scalability (not enough validation).
 	\item The paper lacks relevance: while the paper presents some scalability mechanism(s), the presented mechanism is an incremental refinement of an earlier proposed mechanism.
 	\item The paper does not focus on communication-based Byzantine consensus but presents a `Proof-of-X' consensus variant.
 \end{itemize}

\subsection{Selection Procedure and Results} 
We selected papers as \textit{relevant} in the following way: In the first phase, we conducted a fast scan, in which a single assessor examined each paper only to check if the paper could be of potential interest. Moreover, in this step, only papers that obviously do not qualify are sorted out. For instance, if the field is not computer science, the paper's topic is not related to scalability, or the paper is not a research paper but a short abstract or workshop invitation.
In a second review round, all remaining papers are examined by two different reviewers to validate their relevance: A paper is \textit{relevant} iff at least one inclusion criterion applies, and none of the exclusion criteria applies. All papers are then tagged either \emph{relevant} or \emph{not relevant}.
In the final phase, assessor conflicts are resolved by involving a third assessor and discussing the disagreement.

In the end, $52$ papers have been selected as relevant for inclusion in our SoK paper.
Out of these, 13 papers are published in 11 different journals, 7 papers are published in online archives (\eg arXiv), and 32 are published in proceedings of 25 different conferences. 
The papers are spread over many conferences and journals, many not specific to the topic of blockchain. The most frequent publication channel, besides arXiv, is VLDB, with 3 papers. 


