\section{The semantic latent space of DDMs}
Diffusion models are defined in terms of a forward diffusion process that adds increasing amounts of white Gaussian noise to a clean image $\mathbf{x}_0$ in $T$ steps, and a learned reverse process that gradually removes the noise.
%
During the forward process each noisy image $\mathbf{x}_t$ is generated as
\begin{equation}    
\mathbf{x}_t = \sqrt{\alpha_t}\mathbf{x}_0 + \sqrt{1-\alpha_t}\mathbf{n},
\end{equation}
where $\mathbf{n} \sim \mathcal{N}(\mathbf{0},\mathbf{I})$ and  the noise schedule is defined by~$\{\alpha_t \}$ .
% 
In \cite{song2020ddim}, generating an image from the model is done by first sampling Gaussian noise $\mathbf{x}_T\sim \mathcal{N}(\mathbf{0},\mathbf{I})$, which is then denoised following the approximate reverse diffusion process 
\begin{equation}
\mathbf{x}_{t-1} = 
\sqrt{\alpha_{t-1}} \mathbf{P}_t(\bm{\epsilon}^\theta_t(\mathbf{x}_t)) 
+ \mathbf{D}_t (\bm{\epsilon}^\theta_t(  \mathbf{x}_t))
+ \sigma_t \mathbf{z}_t, 
\label{eq:ddim-reverse}
\end{equation}
where $\mathbf{z}_t\sim\mathcal{N}(\mathbf{0},\mathbf{I})$. Here $\bm{\epsilon}^\theta_t$ is a neural network (usually a U-Net~\cite{ronneberger2015unet}), which is trained to predict $\mathbf{n}$ from $\mathbf{x}_t$, and  
\begin{align}
&\mathbf{P}_t(\bm{\epsilon}^\theta_t( \mathbf{x}_t )) = 
\frac{\mathbf{x}_t - \sqrt{1-\alpha_t} \bm{\epsilon}^\theta_t(\mathbf{x}_t) }{\sqrt{\alpha_t}}, \\ 
&\mathbf{D}_t(\bm{\epsilon}^\theta_t(  \mathbf{x}_t ))  = \sqrt{1-\alpha_{t-1} - \sigma_t^2}
\bm{\epsilon}^\theta_t(  \mathbf{x}_t )
\label{eq:P_D_declaration}
\end{align}
are the predicted $\mathbf{x}_0$ and the direction pointing to $\mathbf{x}_t$ at timestep $t$, respectively.
The variance $\sigma_t$ is taken to be
\begin{equation}
\sigma_t = \eta_t  \sqrt{(1-\alpha_{t-1})/(1-\alpha_t)}\sqrt{1- \alpha_t/\alpha_{t-1}}. 
\end{equation}
The special case where $\eta_t = 0$ for all $t$ is called DDIM~\cite{song2020ddim}. In this setting the noise variance is $\sigma_t = 0$, so that the sampling process is deterministic and fully reversible \cite{ho2020denoising, Dhariwal2021dpmsbeatgans} (\emph{i.e.,}~$\mathbf{x}_T$ can be uniquely obtained from $\mathbf{x}_0$).
The case where $\eta_t = 1$ corresponds to the stochastic DDPM scheme~\cite{ho2020denoising}. 


\begin{figure}[t]
\centering
% \the\linewidth
\includegraphics[width=\linewidth]{figs/hspace-diagram-new.pdf}
\caption{\textbf{Illustration of $h$-space.}
% Graphical Illustration of $h$-space. 
In this paper we define the semantic latent space of DDMs as the activation after the deepest bottleneck layer of the U-Net.}
\label{fig:hspace}
\end{figure}

%\section{The semantic latent space of DDMs}
Following Kwon \etal~\cite{Kwon2022ddmhavesemantic}, we study the semantic latent space of DDMs corresponding to the activation of the bottleneck feature maps of the U-Net (see Fig.~\ref{fig:hspace}). We denote the concatenation of the bottleneck activation across all timesteps by $\mathbf{h}_{T:1}$. 
%% Definition of the semantic latent space
% Kwon \etal~\cite{Kwon2022ddmhavesemantic} proposed to inject edit directions $\Delta\mathbf{h}_t$ 
In \cite{Kwon2022ddmhavesemantic} image editing was performed 
% proposed to inject edit directions $\Delta\mathbf{h}_t$ 
via an asymetric reverse process (Asyrp), where~$\Delta\mathbf{h}_t$ is only injected into $\mathbf{P}_t$ of \eqref{eq:ddim-reverse} and not to $\mathbf{D}_t$.
Empirically, we find that Asyrp amplifies the effect of the edits but semantic editing is also possible without using Asyrp.
In this paper, we inject $\Delta \mathbf{h}_t$ into both terms of~\eqref{eq:ddim-reverse}. 
This has the benefit of only requiring a single forward pass of the U-Net at each step of the sampling process, as opposed to the two forward passes needed in Asyrp (one for $\mathbf{P}_t$ with injection and one for $\mathbf{D}_t$ without the injection).
In the supplementary material (SM) Sec.~\ref{SM:asyrp} we provide a comparison of the effect of editing with and without Asyrp.

\begin{figure}[t] 
\centering
\begin{subfigure}[b]{0.24\linewidth}
\centering
% {\footnotesize $(\mathbf{x}_T^1,\mathbf{h}_{T:1}^1)$}
{\footnotesize Sample 1}
\includegraphics[width=\textwidth]{figs/base/q1h1.png}
% \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.24\linewidth}
\centering
% {\footnotesize $(\mathbf{x}_T^2 ,\mathbf{h}_{T:1}^2)$}
{\footnotesize Sample 2}
\includegraphics[width=\textwidth]{figs/base/q2h2.png}
\end{subfigure}
\begin{subfigure}[b]{0.24\linewidth}
\centering
% {\footnotesize $(\mathbf{x}_T^2 ,\mathbf{h}_{T:1}^2)$}
{\footnotesize 1 with $\mathbf{h}_t$ from 2}
\includegraphics[width=\textwidth]{figs/base/q1h2.png}
\end{subfigure}
\begin{subfigure}[b]{0.24\linewidth}
\centering
{\footnotesize 2 with $\mathbf{h}_t$ from 1}
% {\footnotesize $(\mathbf{x}_T^2 ,\mathbf{h}_{T:1}^2)$}
\includegraphics[width=\textwidth]{figs/base/q2h1.png}
\end{subfigure}
\caption{
\textbf{Effect of swapping the bottleneck activation.}
Swapping $\mathbf{h}_t$ between two samples swaps the semantic content without affecting background and illumination.}
\label{fig:swap_hs}
\end{figure} % single attr

%% The h-space is not a complete latent representation.
The bottleneck activation $\mathbf{h}_t$ is determined directly from~$\mathbf{x}_t$ in each step of the generative process. 
It is worth noting that although most of the high-level semantic content of the generated image is determined by~$\mathbf{h}_{T:1}$, it is not a complete latent representation in the sense that it does not completely specify the generated image. We illustrate this point in Fig.~\ref{fig:swap_hs} where we swap~$\mathbf{h}_{T:1}$ between two samples while keeping~$\{\mathbf{x}_T, \mathbf{z}_{T:1}\}$ fixed. We observe that swapping~$\mathbf{h}_{T:1}$ results in a swap of the high-level semantics, like the gender, but not the background. 

%% Vector arithmetic proporty semantic latent space
A key property of $h$-space is that it obeys vector arithmetic properties which have previously been demonstrated for GANs by Radford \etal~\cite{radford2016dcgan}. Specifically, image editing can be done in $h$-space as follows. Suppose we have found a direction $\mathbf{v}_{T:1}$ associated with some semantic content that we wish to apply to a sample with latent code $\mathbf{h}_{T:1}$. Then $\mathbf{h}_{T:1}^{(\text{edit})} = \mathbf{h}_{T:1} + \gamma \mathbf{v}_{T:1}$ is the latent code of the edited image, where $\gamma$ controls the strength of the edit. In Fig.~\ref{fig:single_example_edit} we illustrate the vector arithmetic property of $h$-space.

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth,trim={0 3cm 0 4cm},clip]{figs/base/single_example/single_example_edit.png}
\caption{
\textbf{Vector arithmetic in the semantic latent space.}
% The semantic $h$-space have a vector arithmetic property.
Adding the difference between a smiling and non-smiling person results in a smile in a new sample. Here the scale of the edit is $\gamma=1/5$.}
\label{fig:single_example_edit}
\end{figure}



% $h$-space facilitates semantic editing in DDMs the representation 
% is not complete latent representation in the sense that it . 
% Although the high level semantic content in determined by $\mathbf{h}_{T:1}$ is is not a complete latent representation. 
% howfter the majority of the semantic content is present in $\mathbf{h}_t$
% is determined in a deterministic way from $\mathbf{x}_t$. 
% For example one cannot interpolate between two samples in $h$-space. 

% For example subtracting the bottleneck activations $\mathbf{h}_{T:1}$ for a smiling person from a non-smiling person and adding the result to a non-smiling woman across results in the appearance of a smile with only minor changes to other attributes. 

