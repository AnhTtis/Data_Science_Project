% \section*{Supplemental Materials}

\begin{center}
{\Large \textbf{Supplemental Materials}}
\end{center}
\vspace{1cm}
\section{The effect of Asyrp}
\label{SM:asyrp}
In the main text we stated that using Asyrp \cite{Kwon2022ddmhavesemantic} acts to amplify the effect edits in $h$-space. 
However, Asyrp is computationally costly since it requires two forward passes of the U-Net at each denoising step. 
Hence, Asyrp is not used for any of the results shown in the main paper.
% as similar edits can be achieved by simply increasing the scale.
In Figs.~\ref{SM:asyrp-plot1} and \ref{SM:asyrp-plot2} we qualitatively compare edits with and without using Asyrp. We observe that simply adjusting the scale of the applied direction results in very similar edits.

\begin{figure}[ht]
\centering
\begin{subfigure}[b]{0.45\linewidth}
\includegraphics[width=\linewidth]{figs/sm/eyes1.png}
\caption{Eyes}
\end{subfigure}
\begin{subfigure}[b]{0.45\linewidth}
\includegraphics[width=\linewidth]{figs/sm/mouth1.png}
\caption{Mouth}
\end{subfigure}

\caption{
\textbf{The Effect of Asyrp.} Results are shown for directions found with Alg.~\ref{alg:cap}.}
\label{SM:asyrp-plot1}
\end{figure}
% and classifier annotation respectively.
\begin{figure}[ht]
\centering
% \begin{subfigure}[b]{0.45\linewidth}
% \includegraphics[width=\linewidth]{figs/sm/eyes1.png}
% \caption{Eyes}
% \end{subfigure}
% \begin{subfigure}[b]{0.45\linewidth}
% \includegraphics[width=\linewidth]{figs/sm/mouth1.png}
% \caption{Mouth}
% \end{subfigure}

\begin{subfigure}[b]{0.45\linewidth}
\includegraphics[width=\linewidth]{figs/sm/age1.png}
\caption{Age}
\end{subfigure}
\begin{subfigure}[b]{0.45\linewidth}
\includegraphics[width=\linewidth]{figs/sm/rot1.png}
\caption{Rotation}
\end{subfigure}

\begin{subfigure}[b]{0.45\linewidth}
\includegraphics[width=\linewidth]{figs/sm/gender1.png}
\caption{Gender}
\end{subfigure}
\begin{subfigure}[b]{0.45\linewidth}
\includegraphics[width=\linewidth]{figs/sm/glasses1.png}
\caption{Glasses}
\end{subfigure}

\caption{
\textbf{The effect of Asyrp.} Results are shown for directions found using classifier annotation.
% Using Asyrp amplifies the scale of the edit, but requires two forward passes of the U-net in each diffusion step. 
% In the paper we do not use Asyrp as similar edits can be achieved by simply increasing the scale.
}
\label{SM:asyrp-plot2}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\section{Image-specific directions at different timesteps} \label{SM:jacobiantimesteps}

Our proposed image-specific unsupervised method in Alg.~\ref{alg:cap} finds different directions for each timestep. 
In Figures \ref{SM:poweriter-seed199805}, \ref{SM:poweriter-seed445314}, \ref{SM:poweriter-seed655092} and \ref{SM:poweriter-seed825356} we show the effect of the three dominant directions (the three top singular vectors of the Jacobian) at different timesteps along the reverse diffusion process. 

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{figs/sm/poweriter-supplemental-seed199805_annotated.jpg}
\caption{\textbf{Directions found by Alg.~\ref{alg:cap}.}}
\label{SM:poweriter-seed199805}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{figs/sm/poweriter-supplemental-seed445314_annotated.jpg}
\caption{\textbf{Directions found by Alg.~\ref{alg:cap}.}}
\label{SM:poweriter-seed445314}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{figs/sm/poweriter-supplemental-seed655092_annotated.jpg}
\caption{\textbf{Directions found by Alg.~\ref{alg:cap}.}}
\label{SM:poweriter-seed655092}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{figs/sm/poweriter-supplemental-seed825356_annotated.jpg}
\caption{\textbf{Directions found by Alg.~\ref{alg:cap}.}}
\label{SM:poweriter-seed825356}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Sequential algorithm for Jacobian subspace iteration}\label{SM:jacobian}~%

As mentioned in the main text, %our proposed algorithm 
% in Alg.~\ref{alg:cap}
Alg.~\ref{alg:cap}
can be memory intensive when calculating a large number of singular vectors in parallel. 
In cases where limited memory is available, we provide an alternative sequential version of our method in Alg.~\ref{alg:jacsubspace_sequential}. 
Here we calculate the singular values and vectors in mini-batches of size $ b $.  The value of $ b $ should be set according to the parallel computation capacity. For example, in the special case of $ b = 1 $, the algorithm computes the vectors one by one and will use small memory. Note that lowering the mini-batch size $b$ comes at the expense of longer running time.

% This is efficiently done by utilizing forward mode automatic differentiation.
% Further \eqref{eq:JacobianVectorProd} can be calculated in parallel for multiple vectors using the batched Jacobian-vector product \eg in Pytorch. 

\begin{algorithm}[ht]
\caption{ Sequential Jacobian subspace iteration}\label{alg:jacsubspace_sequential}
\begin{algorithmic}
\Require function to differentiate $ \mathbf{f} : \mathbb{R}^{d_{\text{in}}} \to \mathbb{R}^{d_{\text{out}}}$, point at which to differentiate
$\mathbf{h} \in  \mathbb{R}^{d_{\text{in}}}$, initial guess $\mathbf{\Theta} \in  \mathbb{R}^{d_{\text{in}} \times k} $ [optional],
mini-batch size $ b<k $ 
\Ensure $ (\mathbf{U}, \mathbf{\Sigma}, \mathbf{V}^\mathrm{T}) $ -- $k$ top singular values and vectors of the Jacobian $ {\partial \mathbf{f} }/{ \partial \mathbf{h}}$
\State  \textbf{Initialization: } $
\mathbf{y} \gets \mathbf{f}(\mathbf{h}), \
i_{\text{start}} \gets 1, \
i_{\text{end}} \gets b, \
\mathbf{V} \gets [ \ ] , \
\mathbf{\Sigma} \gets [ \ ] , \
\mathbf{U} \gets [ \ ]  $
\While{$i_{\text{start}} \leq k$}
\If{$\mathbf{\Theta}$ is empty}
    \State $\mathbf{\Phi} \gets $ i.i.d.\@ standard Gaussian samples in $ \mathbb{R}^{d_{\text{in}}\times (i_{\text{end}}-i_{\text{start}}+1) } $
\Else
    \State $\mathbf{\Phi} \gets $ columns $i_{\text{start}}$ to $i_{\text{end}}$ of $\mathbf{\Theta}$
\EndIf
\State $  \mathbf{Q},\mathbf{R} \gets \mathrm{QR}(\mathbf{\Phi}) $
\Comment{Reduced QR decomposition}
\State $\mathbf{\Phi} \gets \mathbf{Q}$
\Comment{Ensures $ \mathbf{\Phi}^\mathrm{T} \mathbf{\Phi} = \mathbf{I} $}
\While{stopping criterion}
\If{$\mathbf{V}$ is not empty}
\State $\mathbf{\Phi} \gets \left[\mathbf{I} -  \mathbf{V}\left(\mathbf{V}^\mathrm{T}\mathbf{V}\right)^{-1} \mathbf{V}^\mathrm{T} \right] \mathbf{\Phi} $
\State $  \mathbf{\Phi},\mathbf{R} \gets \mathrm{QR}(\mathbf{\Phi}) $
\Comment{Reduced QR decomposition}
\EndIf
\State $\mathbf{\Psi} \gets \partial \mathbf{f} ( \mathbf{h}+a \mathbf{\Phi} ) / \partial a $ at $ a = 0$
\Comment{Batch forward}
\State $\hat{\mathbf{\Phi}} \gets \partial (\mathbf{\Psi}^\mathrm{T}\mathbf{ y })/\partial \mathbf{h}$
\State $\mathbf{\Phi},\mathbf{S}, \mathbf{R} \gets \mathrm{SVD}(\hat{\mathbf{\Phi}})$
\Comment{Reduced SVD}
\EndWhile
\State $\mathbf{V} \gets [\mathbf{V} ; \mathbf{\Phi}]$
\State\vspace*{-\baselineskip}
    \begin{fleqn}[\dimexpr(\leftmargini-\labelsep)]
        \setlength\belowdisplayskip{3pt}
        \setlength\abovedisplayskip{3pt}
        \begin{equation*}
            \mathbf{\Sigma} \gets
            \begin{bmatrix}
                \mathbf{\Sigma} & \mathbf{0} \\
                \mathbf{0}   &   \mathbf{S}^{1/2} 
            \end{bmatrix}
        \end{equation*}
    \end{fleqn}%
\State $\mathbf{U} \gets [\mathbf{U} ; \mathbf{\Psi}]$
\State  $i_{\text{start}} \gets i_{\text{start}}+b $
\State  $i_{\text{end}} \gets \min\{ i_{\text{end}}+b,k\} $

\EndWhile
\State Orthonormalize $\mathbf{U}$
%\State $\mathbf{\Sigma} \gets (\mathbf{\Sigma}^2)^{1/2} $


% \State $\mathbf{y} \gets \mathbf{f}(\mathbf{h})$ % , \;  a \gets 1  $
% \If{$\mathbf{V}$ is empty}
%     \State $\mathbf{V} \gets $ i.i.d.\@ standard Gaussian samples
% \EndIf
% \State $  \mathbf{Q},\mathbf{R} \gets \mathrm{QR}(\mathbf{V}) $
% \Comment{Reduced QR decomposition}
% \State $\mathbf{V} \gets \mathbf{Q}$
% \Comment{Ensures $ \mathbf{V}^\mathrm{T} \mathbf{V} = \mathbf{I} $}
% \While{stopping criteria}
% % \State $\mathbf{B} \gets \mathbf{h}-\mathbf{U} $ 
% % \Comment{$\mathbf{h}$ broadcasted}
% \State $\mathbf{U} \gets \partial \mathbf{f} ( \mathbf{h}+a \mathbf{V} ) / \partial a $ at $ a = 0$
% \Comment{Batch forward}
% \State $\hat{\mathbf{V}} \gets \partial (\mathbf{U}^\mathrm{T}\mathbf{ y })/\partial \mathbf{h}$
% \State $\mathbf{V},\mathbf{\Sigma^2}, \mathbf{R} \gets \mathrm{SVD}(\hat{\mathbf{V}})$
% \Comment{Reduced SVD}
\end{algorithmic}
\end{algorithm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Unsupervised methods on other domains}
\label{SM:pca-lsun}

In addition to the model\footnote{\url{https://huggingface.co/google/ddpm-ema-celebahq-256}} trained on CelebA, which is used throughout the main paper, we also conducted experiments with models trained on 
churches\footnote{\url{https://huggingface.co/google/ddpm-ema-church-256}} 
and bedrooms\footnote{\url{https://huggingface.co/google/ddpm-ema-bedroom-256}}.
%
Although the unsupervised directions found with both PCA and 
Alg.~\ref{alg:cap}
on these models lead to various changes to the images, these directions are less interpretable than those obtained for faces in the main paper. 
We showcase the first $5$ PCA directions on the models trained on churches and bedrooms in Figures~\ref{SM:pca-church} and \ref{SM:pca-bedrooms} and directions found using 
Alg.~\ref{alg:cap}
in Figures~\ref{SM:poweriter-churches} and \ref{SM:poweriter-bedrooms}.



\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{figs/sm/pca-church.png}
\caption{
\textbf{PCA directions.}
For a DDM trained on churches.}
\label{SM:pca-church}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{figs/sm/pca-bedrooms.png}
\caption{
\textbf{PCA directions.}
For a DDM trained on bedrooms.}
\label{SM:pca-bedrooms}
\end{figure}


\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{figs/sm/poweriter-supplemental-seed102952-bedrooms_annotated.jpg}
\caption{
\textbf{Directions found with Alg.~\ref{alg:cap}}.
For a DDM trained on bedrooms.}
\label{SM:poweriter-bedrooms}
\end{figure}


\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{figs/sm/poweriter-supplemental-seed217821-church_annotated.jpg}
\caption{
\textbf{Directions found with Alg.~\ref{alg:cap}}.
For a DDM trained on churches.}
\label{SM:poweriter-churches}
\end{figure}


\clearpage
\section{A Note on image-specific directions}\label{SM:noteonnoiseprediction}

In the main paper, we state that the right singular vectors of the Jacobian of $\bm{\epsilon}_t^\theta$ with respect to $h$-space, denoted as $\mathbf{J}_t$, are the set of orthogonal vectors in $h$-space which perturb the noise prediction $\bm{\epsilon}_t^\theta$ the most.
%
An equivalent statement is that those right singular vectors perturb the predicted image $\mathbf{P}_t(\mathbf{x}_t ,\mathbf{h}_t)$ at timestep $t$ the most. 
%
Specifically, since
\begin{equation}
\mathbf{P}_t(\mathbf{x}_t ,\mathbf{h}_t) =
\frac{\mathbf{x}_t - \sqrt{1-\alpha_t}}{\sqrt{\alpha_t} }
\bm{\epsilon}^\theta_t(\mathbf{x}_t,\mathbf{h}_t)
\end{equation}
 we have that 
\begin{align}
\frac{\partial}{\partial \mathbf{h}_t} \mathbf{P}_t(\mathbf{x}_t ,\mathbf{h}_t) 
= -\frac{\sqrt{1-\alpha_t}}{\sqrt{\alpha_t}} \frac{\partial}{\partial \mathbf{h}_t} \bm{\epsilon}^\theta_t(\mathbf{x}_t,\mathbf{h}_t)  = -\frac{\sqrt{1-\alpha_t}}{\sqrt{\alpha_t}} \mathbf{J}_t.
% \frac{\mathbf{x}_t - \sqrt{1-\alpha_t}  }{\sqrt{\alpha_t}}
\end{align}
Thus, the eigenvectors  of $(\partial \mathbf{P}_t/\partial \mathbf{h}_t)^\mathrm{T}(\partial \mathbf{P}_t/\partial \mathbf{h}_t)$ and  $\mathbf{J}_t^\mathrm{T}\mathbf{J}_t$ are the same with the same ordering. 



% \begin{figure}[tb]
% \centering
% \includegraphics[width=\textwidth]{figs/pca/pixel-pca_test_all50steps250samples-eta1.jpg}
% \caption{Pixel CelebA PCA 50 inference steps 250 samples}
% \end{figure}




