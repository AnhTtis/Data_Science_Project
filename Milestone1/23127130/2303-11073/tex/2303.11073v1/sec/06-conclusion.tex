\section{Discussion and conclusion}
%% Punchline
We presented several supervised and unsupervised methods for finding interpretable directions in the recently proposed semantic latent space of Denoising Diffusion Models.
%% Unsupervised
We showed that the principal components in latent space correspond to global and semantically meaningful editing directions like pose, gender, smile, and age.
Additionally, we proposed a novel method for discovering image-specific directions that correspond to highly localized changes in generated images, such as raising the eyebrows or opening/closing of the mouth and eyes. We further showed that although these directions were found with respect to a specific image they can be transferred to different samples.

Although our unsupervised approaches are effective in discovering meaningful semantics when the DDM was trained on aligned data like human faces, we found that models trained on 
less structured data have less interpretable principal directions. We refer the reader to SM Sec.~\ref{SM:pca-lsun} for experiments on LSUN church and bedrooms. 

%% Supervised
Further, we proposed a conceptually simple supervised method utilizing the linear properties of the semantic latent space. We applied our method by finding directions corresponding to facial expressions using a data set of real images and showed that a diverse set of face semantics can be revealed using classifier annotation. 
Finally, we demonstrated that simple linear projection is an effective strategy for disentangling otherwise correlated semantic directions. 

%% Strengths in terms of not requiring retraining or adaptations  
All of our proposed methods apply to pretrained DDMs without requiring any adaptation to the model architecture, fine-tuning, optimization, or text-based guidance.



% Our findings contribute to a better understanding of the semantic latent space in DDMs.
% \blue{However, direction found with PCA are not consistently disentangled and may affect multiple semantics. It is not possible to use \eqref{eq:condition_multiple_semantics} to remove the entanglement since the principal directions are already orthogonal by construction. We leave disentanglement of direction found via PCA as future work.}
  
%% PCA and Jacobian method requires manual inspection and selection.
% We might not always get directions shere is it possible to assign a clear label is the dataset is unaligned. For exapmles see the supplementary where we conduct experiments on LSUN CHURCh and Bedrooms
% \paragraph{Societal impact}
% In this paper we have introduced several techniques for semantic editing of images of human faces in DDM, demonstrating the potential for creating high-quality edited images that are difficult to distinguish from real images. 
% While this capability has significant positive applications, there is also the potential for malicious or misleading use, such as in the creation of deep fakes. 
% Although some research has focused on detecting and mitigating the risk of AI-edited images, these have mostly focused on GANs \cite{Wang2022GANgeneratedFD} and, so far, there has been little research into detecting images that have been edited using DDMs. Given the differences in the generative process between DDMs and GANs, methods which are effective in detecting images edited by GANs might not be as effective for images edited by DDMs \cite{meng2022sdedit}.
% Further research is needed to develop effective methods for forensic analysis of DDM-edited images. Such research could help address the risk of malicious use of image-editing technologies.









% \begin{tcolorbox}
%     \paragraph{Localized Principal components.}
%     \blue{We could still show experiments with this and/or ICA}
% Given a sample $\mathbf{x}_T$ we can make variations by adding a small amount of Gaussian noise by 
% \begin{align}
%     \tilde{\mathbf{x}_T} = \sqrt{(1-\delta)} \mathbf{x}_T + \sqrt{\delta} \mathbf{x}_\text{noise} \qquad \mathbf{x}_\text{noise} \sim \mathcal{N}(\mathbf{0},\mathbf{I}) 
% \end{align}
% Now er can find local principal components by sampling a collection of $\tilde{\mathbf{x}_T}$ Note in the limit $\delta \to 1$, this method approached the standard global PCA.
% \end{tcolorbox}