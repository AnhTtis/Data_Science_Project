\section{Discussion and conclusion}
%% Punchline
We presented several supervised and unsupervised methods for finding interpretable directions in the recently proposed semantic latent space of Denoising Diffusion Models.
%% Unsupervised
We showed that the principal components in latent space correspond to global and semantically meaningful editing directions like pose, gender, and age. Additionally, we proposed a novel method for discovering directions based on a single input image. These directions correspond to highly localized changes in generated images, such as raising the eyebrows or opening/closing the mouth and eyes. 
% We further showed that 
Although these directions were found with respect to a specific image they can be transferred to different samples.

As our proposed methods enable high-quality editing of face images, we provide a broader impact statement in SM Sec.~\ref{sec:impact}.
Although our unsupervised approaches are effective in discovering meaningful semantics when the DDM was trained on aligned data like human faces, we found that models trained on less structured data have less interpretable principal directions. We refer the reader to SM Sec.~\ref{SM:pca-lsun} for experiments on models trained on churches and bedrooms. 
 
%% Supervised
Further, we proposed a conceptually simple supervised method utilizing the linear properties of the semantic latent space. 
We showed that a diverse set of face semantics can be revealed using an attribute classifier to annotate samples. 
Finally, we demonstrated that simple linear projection is an effective strategy for disentangling otherwise correlated semantic directions. 
%% Strengths in terms of not requiring retraining or adaptations  
All of our proposed methods apply to pretrained DDMs without requiring any adaptation to the model architecture, fine-tuning, optimization, or text-based guidance. 
Possible future avenues of our work include applications of the proposed approaches on different data domains. 
%Additionally, an active area of research is the objective quality assessment of generated images. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% applied our method by finding directions corresponding to facial expressions using a data set of real images and 


% Our findings contribute to a better understanding of the semantic latent space in DDMs.
% \blue{However, direction found with PCA are not consistently disentangled and may affect multiple semantics. It is not possible to use \eqref{eq:condition_multiple_semantics} to remove the entanglement since the principal directions are already orthogonal by construction. We leave disentanglement of direction found via PCA as future work.}
  
%% PCA and Jacobian method requires manual inspection and selection.
% We might not always get directions shere is it possible to assign a clear label is the dataset is unaligned. For exapmles see the supplementary where we conduct experiments on LSUN CHURCh and Bedrooms











% \begin{tcolorbox}
%     \paragraph{Localized Principal components.}
%     \blue{We could still show experiments with this and/or ICA}
% Given a sample $\mathbf{x}_T$ we can make variations by adding a small amount of Gaussian noise by 
% \begin{align}
%     \tilde{\mathbf{x}_T} = \sqrt{(1-\delta)} \mathbf{x}_T + \sqrt{\delta} \mathbf{x}_\text{noise} \qquad \mathbf{x}_\text{noise} \sim \mathcal{N}(\mathbf{0},\mathbf{I}) 
% \end{align}
% Now er can find local principal components by sampling a collection of $\tilde{\mathbf{x}_T}$ Note in the limit $\delta \to 1$, this method approached the standard global PCA.
% \end{tcolorbox}