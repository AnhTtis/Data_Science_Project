\section{The semantic latent space of DDMs}
Diffusion models are defined in terms of a forward diffusion process that adds increasing amounts of white Gaussian noise to a clean image $\mathbf{x}_0$ in $T$ steps, and a learned reverse process that gradually removes the noise.
%
During the forward process each noisy image $\mathbf{x}_t$ is generated as
\begin{equation}    
\mathbf{x}_t = \sqrt{\alpha_t}\mathbf{x}_0 + \sqrt{1-\alpha_t}\mathbf{n},
\end{equation}
where $\mathbf{n} \sim \mathcal{N}(\mathbf{0},\mathbf{I})$ and  the noise schedule is defined by~$\{\alpha_t \}$ .
% 
In \cite{song2020ddim}, generating an image from the model is done by first sampling Gaussian noise $\mathbf{x}_T\sim \mathcal{N}(\mathbf{0},\mathbf{I})$, which is then denoised following the approximate reverse diffusion process 
\begin{equation}
\mathbf{x}_{t-1} = 
\sqrt{\alpha_{t-1}} \mathbf{P}_t(\bm{\epsilon}^\theta_t(\mathbf{x}_t)) 
+ \mathbf{D}_t (\bm{\epsilon}^\theta_t(  \mathbf{x}_t))
+ \sigma_t \mathbf{z}_t, 
\label{eq:ddim-reverse}
\end{equation}
where $\mathbf{z}_t\sim\mathcal{N}(\mathbf{0},\mathbf{I})$. Here $\bm{\epsilon}^\theta_t$ is a neural network (usually a U-Net~\cite{ronneberger2015unet}), which is trained to predict $\mathbf{n}$ from $\mathbf{x}_t$, and the terms 
\begin{align}
\mathbf{P}_t(\bm{\epsilon}^\theta_t( \mathbf{x}_t )) &= 
\frac{\mathbf{x}_t - \sqrt{1-\alpha_t} \bm{\epsilon}^\theta_t(\mathbf{x}_t) }{\sqrt{\alpha_t}} \label{eq:P_declaration}\\
%\qquad 
\intertext{and}
%\qquad 
\mathbf{D}_t(\bm{\epsilon}^\theta_t(  \mathbf{x}_t ))  &= \sqrt{1-\alpha_{t-1} - \sigma_t^2}
\bm{\epsilon}^\theta_t(  \mathbf{x}_t )
\label{eq:P_D_declaration}
\end{align}
are the predicted $\mathbf{x}_0$ and the direction pointing to $\mathbf{x}_t$ at timestep $t$, respectively.
The variance $\sigma_t$ is taken to be
\begin{equation}
\sigma_t = \eta_t  \sqrt{(1-\alpha_{t-1})/(1-\alpha_t)}\sqrt{1- \alpha_t/\alpha_{t-1}}. 
\end{equation}
The special case where $\eta_t = 0$ for all $t$ is called DDIM~\cite{song2020ddim}. In this setting the noise variance is $\sigma_t = 0$, so that the sampling process is deterministic and fully reversible \cite{ho2020denoising, Dhariwal2021dpmsbeatgans} (\emph{i.e.,}~$\mathbf{x}_T$ can be uniquely obtained from $\mathbf{x}_0$).
The case where $\eta_t = 1$ corresponds to the stochastic DDPM scheme~\cite{ho2020denoising}. 

\def\imga{0.22\textwidth}
\begin{figure}[tb]
%\centering
\hspace{0.25cm}
\begin{subfigure}[b]{0.95\linewidth}
\hspace{20pt}
{\scriptsize S1}
\hspace{40pt}
{\scriptsize S2}
\hspace{20pt}
$\substack{\text{S1} \\ (\mathbf{h}_t \text{from S2}) } $ 
\hspace{12pt}
$\substack{\text{S2} \\ (\mathbf{h}_t \text{from S1}) } $ \\
    \includegraphics[width=\imga]{figs/base_q1h1.png}
    \includegraphics[width=\imga]{figs/base_q2h2.png}
    \includegraphics[width=\imga]{figs/base_q1h2.png}
    \includegraphics[width=\imga]{figs/base_q2h1.png}
\caption{Effect of swapping the bottleneck activation.}
\label{fig:swap_hs}    
\end{subfigure}
\\
%%%%%%%%%%%%
\begin{subfigure}[b]{0.95\linewidth} 
\mbox{}
\vspace{-2mm}
\includegraphics[width=\linewidth,trim={0 3cm 0 4cm},clip]{figs/base_single_example_edit.png}
\caption{Vector arithmetic in the semantic latent space.}
\label{fig:single_example_edit}
\end{subfigure}
\caption{
    \textbf{Illustration of properties of the $h$-space.}
    \subref{fig:swap_hs}  Swapping $\mathbf{h}_{T:1}$ between two samples, S1 and S2, swaps the semantic content without affecting background. 
    \subref{fig:single_example_edit} Adding the difference in bottleneck activation $\mathbf{h}_{T:1}$ between a smiling and non-smiling person results in a smile in a new sample. The result are shown with strength parameter $\gamma=1/5$.
}
\end{figure}

Following Kwon \etal~\cite{Kwon2022ddmhavesemantic}, we study the semantic latent space of DDMs corresponding to the activation of the bottleneck feature maps of the U-Net. We denote the concatenation of the bottleneck activation across all timesteps as $\mathbf{h}_{T:1}$ see supplementary material (SM) Sec.~\ref{sm:hspace-diagram} for illustration and additional details.
%% Definition of the semantic latent space
In \cite{Kwon2022ddmhavesemantic} image editing was performed 
via an asymetric reverse process (Asyrp), where~$\Delta\mathbf{h}_t$ is only injected into $\mathbf{P}_t$ of \eqref{eq:ddim-reverse} and not to $\mathbf{D}_t$.
Empirically, we find that Asyrp amplifies the effect of the edits but semantic editing is also possible without using Asyrp.
In this paper, we inject $\Delta \mathbf{h}_t$ into both terms of~\eqref{eq:ddim-reverse}. 
This has the benefit of only requiring a single forward pass of the U-Net at each step of the sampling process, as opposed to the two forward passes needed in Asyrp (one for $\mathbf{P}_t$ with injection and one for $\mathbf{D}_t$ without the injection).
In SM Sec.~\ref{SM:asyrp} we provide a comparison of the effect of editing with and without using Asyrp.

%% The h-space is not a complete latent representation.
The bottleneck activation $\mathbf{h}_t$ is determined directly from~$\mathbf{x}_t$ in each step of the generative process. 
It is worth noting that although most of the high-level semantic content of the generated image is determined by~$\mathbf{h}_{T:1}$, it is not a complete latent representation in the sense that it does not completely specify the generated image. We illustrate this point in Fig.~\ref{fig:swap_hs} where we swap~$\mathbf{h}_{T:1}$ between two samples while keeping~$\{\mathbf{x}_T, \mathbf{z}_{T:1}\}$ fixed. We observe that swapping~$\mathbf{h}_{T:1}$ results in a swap of the high-level semantics, like the gender, but not the background. 

%% Vector arithmetic proporty semantic latent space
A key property of $h$-space is that it obeys vector arithmetic properties which have previously been demonstrated for GANs by Radford \etal~\cite{radford2016dcgan}. Specifically, image editing can be done in $h$-space as follows. Suppose we have found a direction $\mathbf{v}_{T:1}$ associated with some semantic content that we wish to apply to a sample with latent code $\mathbf{h}_{T:1}$. Then $\mathbf{h}_{T:1}^{(\text{edit})} = \mathbf{h}_{T:1} + \gamma \mathbf{v}_{T:1}$ is the latent code of the edited image, where $\gamma$ controls the strength of the edit. In Fig.~\ref{fig:single_example_edit} we illustrate the vector arithmetic property of $h$-space by adding a difference vector which has the semantic effect of adding a smile.












% $h$-space facilitates semantic editing in DDMs the representation 
% is not complete latent representation in the sense that it . 
% Although the high level semantic content in determined by $\mathbf{h}_\mathrm{all}$ is is not a complete latent representation. 
% howfter the majority of the semantic content is present in $\mathbf{h}_t$
% is determined in a deterministic way from $\mathbf{x}_t$. 
% For example one cannot interpolate between two samples in $h$-space. 

% For example subtracting the bottleneck activations $\mathbf{h}_\mathrm{all}$ for a smiling person from a non-smiling person and adding the result to a non-smiling woman across results in the appearance of a smile with only minor changes to other attributes. 

