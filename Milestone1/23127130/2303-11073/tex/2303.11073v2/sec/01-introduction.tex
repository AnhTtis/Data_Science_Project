%% Moved to first page in main file. 
% \begin{figure*}[bt]
%     \includegraphics[width=\linewidth]{figs/base/introfig/first_figure.pdf}
%   \caption{
%   \textbf{Our semantic image editing.} 
%   We present new methods for finding interpretable disentangled semantic directions in the latent space of DDMs. 
%   Specifically, we propose a supervised (left) and two unsupervised (right) methods, where the latter finds either global directions based on a collection of images or local directions based on the analysis of a single sample.
%   }
%   \label{fig:teaser figure}
% \end{figure*}





\section{Introduction}

% DPMs outperform GANs but their latent space is not well understood
Denoising Diffusion Models (DDMs) \cite{sohl2015ddpm-noneqthermo} have emerged as a strong alternative to Generative Adversarial Networks (GANs) \cite{Goodfellow2014GAN}. Today, they outperform GANs in unconditional image synthesis \cite{Dhariwal2021dpmsbeatgans}, a task in which GANs have been dominating in recent years. Besides synthesizing high-quality and diverse images, DDMs can also be used for conditional synthesis tasks by guiding them on various user inputs \cite{ho2021classifierfree}, such as a user-provided reference image~\cite{Gihyun22, meng2022sdedit} or a text-prompt by utilizing Contrastive Language-Image Pretraining (CLIP) \cite{Radford2021CLIP}. 
Conditional DDMs have seen great success, particularly in the context of text-based synthesis. 
Specifically, recent large-scale text-conditional systems like DALL-E \cite{ramesh2021dalle,ramesh2022dalle2}, Stable Diffusion \cite{rombach2021latentdiffusion} and Imagen \cite{Saharia2022Imagen} have sparked a surge of research related to text-driven image editing using DDMs \cite{nichol2021glide, mokady2022null, gal2022textual, ruiz2022dreambooth, kawar2023imagic, kim2022DiffusionCLIP, Hertz22,Narek22,couairon2022diffedit}. 
While there has been extensive research on finding disentangled editing directions in the latent space of unconditional GANs \cite{alaluf2023third, Shen2020Interfacegan,harkonen2020ganspace,Haas2022tensorGAN2,shen2021closedform, spingarn2021gansteerability,  Abdal2020Image2StyleGANpp}, comparatively little work has been done on this topic for unconditional DDMs. Despite their popularity, it is still not well understood how to leverage the latent space of DDMs for semantic image editing in the unconditional setting, \ie, in the absence of CLIP-guidance and without conditioning on a reference image.


%% Our paper  
In this paper, we propose novel editing techniques by utilizing the \emph{semantic latent space} of DDMs which was recently proposed by Kwon \etal~\cite{Kwon2022ddmhavesemantic}. The semantic latent space, coined `$h$-space', is the space of the deepest feature maps of the denoiser. Our research explores supervised and unsupervised methods for finding semantically interpretable editing directions in unconditional DDMs.

%% Paper Organization
We start by proposing two unsupervised methods. In Sec.~\ref{sec:Unsupervised methods}, we demonstrate that interpretable editing directions, like pose, gender, and age emerge as the principal components in the semantic latent space. Additionally, we propose a novel unsupervised method for discovering image-specific semantic directions resulting in highly localized edits like opening/closing of the mouth and eyes that can also be applied to other samples. 
We illustrate a selection of these unsupervised editing directions in Fig.~\ref{fig:teaser figure} (right pane). 
% Supervised directions. 
Next, in Sec.~\ref{sec:Supervised methods}, we utilize the linear properties of the semantic latent space and propose a simple supervised method for finding interpretable editing directions, like age and gender or the appearance of glasses or a smile. We illustrate examples of these edits in Fig.~\ref{fig:teaser figure} (left pane). 
We demonstrate our approach by annotating samples generated by an unconditional DDM using a pretrained attribute classifier. 
We further propose a simple method for disentangling directions that affect multiple attributes. 
 % Why our approach is attractive, main punchlines.
Our approaches allow for intuitive and semantically disentangled image editing and can be applied to the latent space of DDMs without requiring any CLIP guidance, fine-tuning, optimization or any adaptations to the architecture of existing DDMs. 

To summarize the contributions of this paper are the following: 
\begin{itemize}%[noitemsep]
    %\item finding semantically interpretable editing directions in unconditional DDMs,
    \item We propose an unsupervised method to uncover semantically meaningful directions in the $h$-space by PCA.
    \item Our method successfully identifies image-specific semantically meaningful directions corresponding to highly localized changes.
    \item We demonstrate a supervised approach to obtain latent directions corresponding to well-defined labels.
    \item We propose a conditional manipulation in $h$-space to disentangle semantic directions.
    \item The code for this project is available at \url{https://github.com/renhaa/semantic-diffusion}. 
\end{itemize}
