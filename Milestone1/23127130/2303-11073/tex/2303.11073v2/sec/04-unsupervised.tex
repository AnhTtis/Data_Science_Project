\section{Unsupervised semantic directions}\label{sec:Unsupervised methods}

\subsection{Principal component analysis}
Our first goal is to uncover interesting semantic directions in an unsupervised fashion.
To this end, we first explore the use of principal component analysis (PCA) in $h$-space.
In the context of GANs \cite{harkonen2020ganspace}, it was shown that the principal components of a collection of randomly sampled latent codes result in semantically interpretable editing directions. 
Here we demonstrate that the same is true for DDMs if the PCA is performed in the semantic $h$-space.
Specifically, we consider PCA where we generate $n$ random samples and save the bottleneck activation $\mathbf{h}^{(i)}_t$ for each sample $i$ at all timesteps. 
Then, for each timestep $t$ we vectorize $\{\mathbf{h}^{(i)}_t\}_{i=1}^n$ and calculate the principal components. 
We use Incremental PCA \cite{ross2008incremental} in order to calculate PCA on more samples than would otherwise fit in memory. 
We define the editing direction $\mathbf{v}_{j}$ as a concatenation of the $j$'th principal component from all timesteps.
To demonstrate our method, we use Diffusers~\cite{von-platen-etal-2022-diffusers} and a DDPM\footnote{\url{https://huggingface.co/google/ddpm-ema-celebahq-256}} trained on the CelebA \cite{liu2015celeba} data set. 
Unless stated otherwise, all results use $\eta_t = 1$ during the synthesis process. 

%The results are displayed in Fig.~\ref{fig:pca_whole}.
It can be seen that many principal directions have clear semantic interpretations, Fig.~\ref{fig:pca} demonstrates the effect of several of these directions, including directions corresponding to gender, pose, age, and smile. 
Fig.~\ref{subfig:pca-top2} and \ref{subfig:pca-random} compares the effect of applying the two dominant principal components to random directions. For a fair comparison, we set the norm of~$\Delta \mathbf{h}_t$ for the random directions to match that of the principal components. While interpolating along principal directions leads to semantically interpretable edits, shifting along random directions only induces minor changes to the image at small scales and rapid degradation of the image at larger scales. 

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{figs/pca_PCA-Plot-new.png}
    \caption{
    \textbf{PCA in the semantic latent space.}
    PCA in $h$-space provides a way for discovering disentangled and semantically meaningful directions. Here we show a selection of semantic edits corresponding to pose, smile, gender and age. 
    }
    \label{fig:pca}
\end{figure}
\begin{figure}[tb]
\centering
    \begin{subfigure}[b]{0.9\linewidth}
    \includegraphics[width=\linewidth]{figs/pca_top2pca_annotated.png}
    \caption{Two dominant PCA directions}
    \label{subfig:pca-top2}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.9\linewidth}
    \includegraphics[width=\linewidth]{figs/pca_random_direction.png}
    \caption{Random directions}
    \label{subfig:pca-random}
    \end{subfigure}

    \caption{\textbf{PCA v. random directions}
    While directions found with PCA have a clear semantic meaning, like pose and gender, interpolating along random directions results in only minor changes to the image when using the same scale. Increasing the scale results in a degradation of the image.}
\end{figure}

% \begin{figure}[tb]
% \centering
% \begin{subfigure}[b]{0.44\linewidth}
%     \begin{subfigure}[b]{\linewidth}
%     \includegraphics[width=\linewidth]{figs/pca/top2pca_annotated.png}
%     \caption{Two dominant PCA directions}
%     \label{subfig:pca-top2}
%     \end{subfigure}
    
%     \begin{subfigure}[b]{\linewidth}
%     \includegraphics[width=\linewidth]{figs/pca/random_direction.png}
%     \caption{Random directions}
%     \label{subfig:pca-random}
%     \end{subfigure}
% \end{subfigure}
% \begin{subfigure}[b]{0.5\linewidth}
%     \includegraphics[width=\linewidth]{figs/pca/PCA-Plot-new.png}
%     \caption{Selection of semantic directions unveiled by PCA.}
%     \label{fig:pca}
% \end{subfigure}
% \caption{%
% \textbf{PCA in the semantic latent space.}
% \subref{subfig:pca-top2}-\subref{subfig:pca-random} While directions found with PCA have a clear semantic meaning, like pose and gender, interpolating along random directions results in only minor changes to the image when using the same scale. Increasing the scale results in a degradation of the image.
% \subref{fig:pca} PCA in $h$-space provides a way for discovering disentangled and semantically meaningful directions. Here we show edits corresponding to pose, smile, gender and age. 
% }
% \label{fig:pca_whole}
% \end{figure}


\subsection{Discovering image-specific semantic edits}
\begin{figure*}[t]
\centering
\includegraphics[width=0.98\linewidth]{figs/poweriter_poweriterfig3_annotated.png}
\caption{
\textbf{Unsupervised image-specific edits.}
Spectral analysis of the Jacobian of $\bm{\epsilon}_t^\theta$ yields directions corresponding to localized changes in the generated image, \eg eyes opening/closing and raising of the eyebrows.
Although this method is image-specific, directions found for one sample can be transferred to others, where they result in semantically similar edits. }
\label{fig:poweriter}
\end{figure*}

%Motivation. 
% Global directions have the advantage that they are computed based on many samples and are thus applicable to any image. However, many desirable semantic edits are not applicable to all images. 
% For example, a direction that opens or closes eyes is clearly irrelevant for a person wearing dark sunglasses. Therefore, we now focus on finding image-specific semantic directions.

The directions found with PCA are computed based on many samples and tend to find global changes such as pose and gender, while more local changes like the closing of the eyes are absent. The smile direction is the only direction we observed where the semantic changes are localized to a specific region like the mouth. In the following, we present a method to find directions that are specific to a single image and region of interest. 

% What we do - approach.  
To find directions specific to a single image we wish to find a set of orthogonal directions in $h$-space that induce the largest change in the prediction of the clean image $\mathbf{P}_t(\bm{\epsilon}^\theta_t( \mathbf{x}_t ))$ at every timestep. 
This is equivalent to finding the directions that change $\bm{\epsilon}^\theta_t( \mathbf{x}_t )$ the most (see SM Sec.~\ref{SM:noteonnoiseprediction}).
For small perturbations, these directions are the top right-hand singular vectors of the Jacobian of $\bm{\epsilon}^\theta_t$ with respect to $\mathbf{h}_{t}$. 
Due to the skip-connections in the U-Net, the output of the network depends on both $\mathbf{x}_{t}$ and $\mathbf{h}_{t}$. Yet, here we only consider the dependency on the latent variable $\mathbf{h}_{t}$.
In the following, we  denote the Jacobian of $\bm{\epsilon}^\theta_t$ by $\mathbf{J}_t$ and  its singular value decomposition (SVD) as
\begin{equation}
\mathbf{J}_t \triangleq \frac{\partial \bm{\epsilon}^\theta_t(\mathbf{x}_t, \mathbf{h}_t)}{\partial\mathbf{h}_t} 
= \mathbf{U}_t\bm{\Sigma}_t \mathbf{V}^\mathrm{T}_t. 
\end{equation}


The right singular vectors corresponding to the largest singular values, (the columns of $\mathbf{V}_t$) are the set of orthogonal vectors in $h$-space which perturb the predicted image the most. 
Note that for each timestep $t$, we have a different set of directions.  
In practice, we find that semantically interesting effects are obtained by applying directions found at timestep $t$ across all timesteps. Thus, computing~$k$ directions per timestep provide us $kT$ potential edits in each of the~$T$ timesteps. 
In SM Sec.~\ref{SM:jacobiantimesteps}, we illustrate the qualitative difference between directions computed at different timesteps.  

% The computation trick
In practice, calculating $\mathbf{J}_t$ directly is computationally expensive. Instead, we find the dominant singular vectors by power-iteration over the matrix $\mathbf{J}_t^\mathrm{T} \mathbf{J}_t$, whose eigenvectors are precisely the right singular vectors of $\mathbf{J}_t$. 
Each iteration requires multiplication by $\mathbf{J}_t^\mathrm{T} \mathbf{J}_t$, which can be computed without ever storing the Jacobian matrix in memory. 
Specifically, for any vector $\mathbf{v}$, the  product $\mathbf{J}_t^\mathrm{T}\mathbf{J}_t\mathbf{v}$ can be computed as 
\begin{align}
\label{eq:poweriter_trick}
    \mathbf{J}_t^\mathrm{T}\mathbf{J}_t\mathbf{v} &= \frac{\partial}{\partial\mathbf{h}_t}
    \left\langle \bm{\epsilon}^\theta_t(\mathbf{x}_t,\mathbf{h}_t) ,\mathbf{J}_t\mathbf{v} \right \rangle\\
%\qquad
\intertext{with}
%\qquad
    \mathbf{J}_t\mathbf{v} &= \left.\frac{\partial}{\partial a} \bm{\epsilon}^\theta_t(\mathbf{x}_t,\mathbf{h}_t  + a \mathbf{v})\right|_{a=0}.
\end{align}

\begin{algorithm}[t]
\caption{Jacobian subspace iteration}\label{alg:cap}
\begin{algorithmic}
\Require $ \mathbf{f} : \mathbb{R}^{d_{\text{in}}} \to \mathbb{R}^{d_{\text{out}}} $, $ \mathbf{h} \in  \mathbb{R}^{d_{\text{in}}} $ and $ \mathbf{V} \in  \mathbb{R}^{d_{\text{in}} \times k} $ 
\Ensure $ (\mathbf{U}, \mathbf{\Sigma}, \mathbf{V}^\mathrm{T}) $ -- $k$ largest singular values and singular vectors of the Jacobian $ {\partial \mathbf{f} }/{ \partial \mathbf{h}}$
\State $\mathbf{y} \gets \mathbf{f}(\mathbf{h})$ % , \;  a \gets 1  $
\If{$\mathbf{V}$ is empty}
    \State $\mathbf{V} \gets $ i.i.d.\@ standard Gaussian samples
\EndIf
\State $  \mathbf{Q},\mathbf{R} \gets \mathrm{QR}(\mathbf{V}) $
\Comment{Reduced QR decomposition}
\State $\mathbf{V} \gets \mathbf{Q}$
\Comment{Ensures $ \mathbf{V}^\mathrm{T} \mathbf{V} = \mathbf{I} $}
\While{stopping criteria}
% \State $\mathbf{B} \gets \mathbf{h}-\mathbf{U} $ 
% \Comment{$\mathbf{h}$ broadcasted}
\State $\mathbf{U} \gets \partial \mathbf{f} ( \mathbf{h} \mathbf{1}_k^\mathrm{T} +a \mathbf{V} ) / \partial a $ at $ a = 0$
\Comment{Batch forward}
\State $\hat{\mathbf{V}} \gets \partial (\mathbf{U}^\mathrm{T}\mathbf{ y })/\partial \mathbf{h}$
\State $\mathbf{V},\mathbf{\Sigma^2}, \mathbf{R} \gets \mathrm{SVD}(\hat{\mathbf{V}})$
\Comment{Reduced SVD}
\EndWhile
\State Orthonormalize $\mathbf{U}$
\end{algorithmic}
\end{algorithm}

Our algorithm is summarized in Alg.~\ref{alg:cap} and uses \eqref{eq:poweriter_trick} to calculate the singular vectors of the Jacobian of an arbitrary vector-valued function $\mathbf{f}$. 
The algorithm starts by randomly initializing a set of vectors $\{\mathbf{v}_i \}_{i=1}^k$ and iterative computes~\eqref{eq:poweriter_trick} using automatic differentiation while enforcing orthogonality among the singular vectors. 
Importantly, it was shown that batched power iteration with an orthogonalization step, such as presented here, is guaranteed to converge to the SVD of positive semi-definite matrices \cite[Ch.~5]{saad2011numerical}. 

% Few words are in place regarding implementation.
Regarding implementation, in \eqref{eq:poweriter_trick} we compute a derivative of high dimensional output w.r.t.\@ a scalar. 
This is efficiently done by utilizing forward mode automatic differentiation.
Further, \eqref{eq:poweriter_trick} can be calculated in parallel for multiple vectors using the batched Jacobian-vector product, \eg in Pytorch. 
Since, parallel calculation of a large number of vectors can be memory intensive, we give a sequential variant of Alg.\ref{alg:cap} in SM, Sec.~\ref{SM:jacobian}.

%Our proposed method successfully identifies semantically meaningful directions that correspond to highly localized semantic changes in the image, e.g. closing or opening of the eyes and mouth, or raising of the eyebrows. We show a selection of such localized edits at the top of Fig.~\ref{fig:poweriter}.
Our method identifies semantically meaningful directions for localized semantic image changes (e.g., eye and mouth movements), as shown in Fig.~\ref{fig:poweriter}. Although these directions are image-specific, they consistently produce similar changes across different images, demonstrating the effectiveness and generalizability of our approach.
%
%While the semantic directions found by this method are image-specific and may vary depending on the sample analyzed, we find that they result in the same localized changes when applied across different images. 
This is illustrated in the lower part of Fig.~\ref{fig:poweriter} where each of the found editing directions is applied with the same magnitude $\gamma$ across a selection of samples. These results suggest that our approach is effective in identifying meaningful semantic directions that generalize across different images.


\begin{figure*}[h!]%[htb]
    \centering
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\linewidth]{figs/poweriter_mouth69779.png}
        \includegraphics[width=\linewidth]{figs/poweriter_eye251131.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\linewidth]{figs/poweriter_hair248460.png}
        \includegraphics[width=\linewidth]{figs/poweriter_brow979683.png}
    \end{subfigure}
    \caption{
    \textbf{Region-specific edits.}
        Given a mask specifying a region of interest, our method can be guided to focus on finding directions which change only the target area. The first column shows the input with the mask shown in green. 
    }
    \label{fig:regionspecific}
\end{figure*}
%\FloatBarrier

If additional information is available in the form of a mask specifying a region of interest, our method can be naturally extended by applying the mask to the noise prediction $\widetilde{\bm{\epsilon}}^\theta_t$ in order to find directions in $h$-space that change a specific region the most rather than the whole image. We seek the singular vectors of the Jacobian of the masked output of the U-net. We define the a masked Jacobian $\mathbf{J}_t^\text{masked}$ as 
\begin{align}
\mathbf{J}_t^\text{masked} &= \partial  \widetilde{\bm{\epsilon}}^\theta_t(\mathbf{x}_t,\mathbf{h}_t) / \partial \mathbf{h}_t, \\
%\quad \quad 
\widetilde{\bm{\epsilon}}^\theta_t(\mathbf{x}_t,\mathbf{h}_t) &= \bm{\epsilon}^\theta_t(\mathbf{x}_t,\mathbf{h}_t)\odot \mathbf{M},    
\end{align}
where $\odot$ denoted the Hadamard product and $\mathbf{M}$ is a binary mask corresponding to a region of interest. We show examples of such region-specific edits in Fig.~\ref{fig:regionspecific}.




%\paragraph{Implementation details.}
%Our implementation relies on Diffusers \cite{von-platen-etal-2022-diffusers} and we use a pretrained DDPM trained by Google\footnote{\url{https://huggingface.co/google/ddpm-ema-celebahq-256}}  on the CelebA \cite{liu2015celeba} data set. Note that the weights of model checkpoint are kept frozen and not modified in any way. 
%We implement $h$-space by simply adding $\Delta\mathbf{h}$ to the feature map at the smallest scale, that is directly after the activation of the middle {\tt UNetMidBlock2D} layer.
% \red{
% and LSUN \cite{fisher2015lsun} 
% church\footnote{\url{https://huggingface.co/google/ddpm-ema-church-256}} 
% and bedrooms\footnote{\url{https://huggingface.co/google/ddpm-ema-bedroom-256}} 
% data sets.}
% \blue{
% % which is further mean-centered before.
% Due to the high dimensionality  of $\mathbf{H}$ we calculate the PCA via the eigenvalue decomposition of the kernel matrix $\mathbf{H}_t \mathbf{H}^\mathrm{T}_t =  \mathbf{V}_t \bm{\Lambda} \mathbf{V}^\mathrm{T}_t \in \mathbb{R}^{N\times N}$ and proceed to calculate the principal components as $\mathbf{V}_t^\mathrm{T}
% \mathbf{H}_t/\sqrt{N-1} = \bm{\Lambda}^{1/2} \mathbf{U}_t^\mathrm{T} /\sqrt{N-1}$.
% }

% We show that image-specific directions emerge as the singular vectors of the Jacobian of the noise predictions.
% Our method successfully finds directions corresponding to highly localized semantic changes in the image. For example closing or opening of the eyes, raising of the eyebrows 

% Although the found directions  differs depending on the particular sample our method is run on. The found semantic directions are consistent across samples. We demonstrate this in \ref{fig:poweriter} where we apply highly localised edits, such as closing of the eyes or pulling the right part of the mouth on a selection of samples. 


% We do this by finding the eigenvectors of $\mathbf{J}^\mathrm{T}\mathbf{J}\mathbf{v}$ by the power iteration method.
% We can find the dominant singular vectors of any matrix \red{symmetric matrix} $\mathbf{A}\in \mathbb{R}^{n\times m}$ 
% The under iteration of $\tilde{\mathbf{v}}_{k+1} =\mathbf{A}\mathbf{v}_k$ and $\mathbf{v}_k = \tilde{\mathbf{v}}_k/||\tilde{\mathbf{v}}_k|| $  then 
% $\mathbf{v}_k$ converges to the dominant singular vector of $\mathbf{A}$.  

%Let $\mathbf{u}_{it}$ be the $i$th column of $\mathbf{V}_t$, \ie the $i$th right hand singular vector of $\mathbf{J}_t$. We note that the singular vectors are orthogonal at every timestep $t$ $\langle \mathbf{u}_{it} , \mathbf{u}_{i^\prime t^\prime} \rangle = \delta_{i i \prime}$ if $t =  t^\prime$ but not necessarily otherwise.
%%
%We propose to add the direction globally by repeating $\mathbf{u}_{it}$ corresponding to the singular vectors at a particular timestep $t = t^\prime$ across each perturbation of the noise prediction $\bm{\epsilon}^\theta_t(\mathbf{x}_t| \gamma \mathbf{n}_{it^{\prime}}) $ where  $\gamma$ is a scalar parameter controlling the strength of the edit and $\mathbf{n}_{it^{\prime}}$ is the $i$th right hand singular vector of $\mathbf{V}_t$ at timestep $t=t^\prime$.
% repeated across timesteps
% $\mathbf{n}_{it^{\prime}} = \otimes_T^1 \mathbf{u}_{it^{\prime}}$ and .