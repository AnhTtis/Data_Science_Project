%!TEX root = main.tex 

Parameterized analysis of algorithms~\cite{downey2012parameterized} provides a way of understanding the working behaviour of algorithms via their dependence on important structural parameters for NP-hard problems. This technique of fine-grained analysis allows for insights into which parameters make a problem hard. When analyzing heuristic search methods such as evolutionary algorithms, a parameterized runtime analysis allows for runtime bounds not just dependent on the given input size but also in terms of parameters that measure the difficulty of the problem. This is particularly helpfule for understanding heuristic search methods which are usually hard to analyze in a rigorous way.

Parameterized analysis of evolutionary algorithms has been carried out for several important combinatorial optimization problems (see \cite{DBLP:series/ncs/0001S20} for an overview). 
The first analysis was for the classical vertex cover problem~\cite{DBLP:journals/algorithmica/KratschN13} which is the prime problem in the area of parameterized complexity.
Following that, problems such as the maximum leaf spanning problem~\cite{DBLP:conf/ppsn/KratschLNO10}, the Euclidean traveling salesperson problem~\cite{DBLP:journals/ec/SuttonNN14} and parameterized settings of 
makespan scheduling~\cite{DBLP:conf/ppsn/SuttonN12} were considered. More recently, both the closest string problem~\cite{DBLP:journals/algorithmica/Sutton21} and
jump and repair operators have been analyzed in the parameterized setting~\cite{DBLP:conf/foga/BransonS21}.
%
A crucial aspect of the parameterized analysis of evolutionary algorithms (and algorithms in general) is the ability of the considered approaches to obtain a kernelization for the considered problems. A kernel here refers to a smaller sub-problem whose size is polynomially bounded in the size of the given parameter(s). As the size is bounded, brute-force methods or random sampling can then be applied to obtain an optimal solution.


 
A small subset of vertices that disconnect a graph is usually called a vertex separator.
In terms of successful divide-and-conquer or parallel processing strategies, such separators are one of the most powerful tools for developing efficient graph algorithms.
This generality and its broad applicability have made the study of separators a rich and
active field of research, see for example the book by Rosenberg and Heath~\cite{DBLP:books/daglib/0007445}, or the line of research
initiated by the seminal work of Lipton and Tarjan \cite{doi:10.1137/0136016} on separators in planar graphs.
Numerous different types of separator structures have emerged over the past couple of decades.
In this paper, we address the problem of decomposing a graph into small pieces - with respect to a parameter $W$ - by removing the smallest possible set of vertices. 
More formally, given a graph $G=(V,E)$ and a parameter $W \in \N$, the goal is to remove the minimum number of vertices such that each connected component in the resulting graph has at most $W$ vertices.
The problem is called the \emph{$W$-separator problem} - also known in the literature as the \emph{component order connectivity problem} or \emph{$\alpha$-balanced separator problem}, where $\alpha  \in (0,1)$ and $W=\alpha|V|$.
An equivalent view of this problem is to cover or hit every connected subgraph of size $W+1$ with the minimum number of vertices.
In particular, $W=1$ corresponds to covering all edges, showing that the $W$-separator problem is a natural generalization of the vertex cover problem.

In this paper, we generalize the results obtained in \cite{DBLP:journals/algorithmica/KratschN13} for the vertex cover problem to the more general $W$-separator problem.
Precisely, we investigate the $W$-separator problem on multi-objective evolutionary algorithms and show that in expectation they admit fixed parameter runtimes with respect to the value of an optimal solution $\opt$ and $W$.
It is unlikely that such runtimes can be achieved by considering $\opt$ or $W$ alone.
Indeed, $W=1$ corresponds to a hard problem, which shows that $W$ (alone) is not a suitable parameter.
For the parameter $\opt$, the problem is $W[1]$-hard even when restricted to split graphs~\cite{DBLP:journals/algorithmica/DrangeDH16}.
These lower bounds lead to the study of parameterization by $W+\opt$.
The best known algorithm with respect to these parameters finds an optimal solution in time $n^{O(1)} \cdot 2^{\O(\log(W) \cdot \opt)}$~\cite{DBLP:journals/algorithmica/DrangeDH16}.
Unless the exponential time hypothesis fails, the authors prove that this running time is tight up to constant factors, i.e., there is no algorithm that solves the problem in time $n^{\O(1)} \cdot 2^{o(\opt \cdot \log(W))}$.
For kernelizations with respect to the parameters $\opt$ and $W$, the best known polynomial algorithm achieves a kernel of size $3 W \cdot \opt$~\cite{DBLP:conf/esa/Casel0INZ21}.
A kernel of size $2 W \cdot \opt$ is provided in~\cite{DBLP:conf/iwpec/KumarL16} in a runtime of $n^{\O(1)} \cdot 2^{\O(W)}$ by using linear programming methods.
That is, for the cover problem, ie.~$W=1$, they obtain a $2 \cdot \opt$ size-kernel, showing that under the assumption the unique games conjecture is true, $2W \cdot \opt$ is the best kernel we can hope for.
Finally, the best known approximation algorithm also uses linear programming methods and has a gap guarantee of $\O(\log(W))$ with a running time of $2^{\O(W)} \cdot n^{\O(1)}$~\cite{DBLP:journals/corr/Lee16c}. 
They also showed that the superpolynomial dependence on $W$ may be needed to achieve a polylogarithmic approximation.


\paragraph{\textbf{Our Contribution:}}
Of particular interest in our work are kernelizations and the reducible structures used for them.
We show that in expectation the algorithms make incremental progress in finding such structures and beyond.
Compared to the vertex cover problem, kernelization algorithms that are linear in $\opt$ for the $W$-separator are more complicated (cf.~\cite{DBLP:journals/corr/Xiao16b,DBLP:conf/esa/Casel0INZ21,DBLP:conf/iwpec/KumarL16}).
The current best known kernelization of the $W$-separator uses linear programming methods and requires a non-trivial post-process to extract the reducible structures~\cite{DBLP:conf/iwpec/KumarL16}.
The challenge in this paper is to show that natural objectives and simple as well as problem-independent mutations are also capable of extracting them.
To this end, we add additional structural features to the reducible structures used in~\cite{DBLP:conf/iwpec/KumarL16}.
Essentially, our results show that evolutionary algorithms with different objectives guide the search and admit fixed parameterized runtimes to solve or approximate (even arbitrarily close) the $W$-separator problem.
 
The different runtimes are given in this paper in terms of the number of iterations, but the tractability with respect to the considered parameters also applies when we include search point evaluations.
In the following, we roughly describe the runtimes achieved with respect to the search point evaluations for exact and approximate solutions, where all results are given in expectation.
We consider simple and problem-independent evolutionary algorithms in combination with three different multi-objective fitness functions.
The first consists of relatively simple calculations to evaluate the search points and allows us to achieve a running time of $n^{\O(1)} \cdot 2^{\O(\opt^2 \cdot W^2)}$ to find an optimal solution. 
For the second and third fitness functions, stronger objectives are used in the sense of applying linear programming methods.
We prove that with such evaluations the optimal solution can be found in time $n^{\O(1)} \cdot 2^{\O(\opt \cdot W)}$.  
Moreover, depending on the choice of an $\varepsilon \in [0,1)$ we obtain solutions arbitrary close to an optimal one, where the according algorithm is tractable with respect to the parameters $\opt$ and $W$.
As usual, the larger $\varepsilon$, the worse the gap guarantee, but with better running time, where $\varepsilon=0$ corresponds to the above running time in finding an optimal solution.
This result shows that we can hope for a gradual progress until an optimal solution is reached.

Finally, our results show that in expectation evolutionary algorithms are not far away from the problem-specific ones, with the literature review showing that up to constant factors the evolved algorithms are close to the lower bounds for the $W$-separator problem.	