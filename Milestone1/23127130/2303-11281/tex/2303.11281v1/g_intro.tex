%!TEX root = main.tex 

Parameterized analysis of algorithms~\cite{downey2012parameterized} provides a way of understanding the working behaviour of algorithms via their dependence on important structural parameters for NP-hard problems. This technique of fine-grained analysis allows for insights into which parameters make a problem hard. When analyzing heuristic search methods such as evolutionary algorithms, a parameterized runtime analysis allows for runtime bounds not just dependent on the given input size but also in terms of parameters that measure the difficulty of the problem. This is particularly helpful for understanding heuristic search methods which are usually hard to analyze in a rigorous way.

%
The area of runtime analysis has been contributed to the theoretical understanding of evolutionary algorithms and other bio-inspired algorithms from various perspectives~\cite{DBLP:series/ncs/Jansen13,DBLP:books/daglib/0025643,DBLP:series/ncs/2020DN}.
Parameterized analysis of evolutionary algorithms has been carried out for several important combinatorial optimization problems (see \cite{DBLP:series/ncs/0001S20} for an overview). 
The first analysis was for the classical vertex cover problem~\cite{DBLP:journals/algorithmica/KratschN13} which is the prime problem in the area of parameterized complexity.
Following that, problems such as the maximum leaf spanning problem~\cite{DBLP:conf/ppsn/KratschLNO10}, the Euclidean traveling salesperson problem~\cite{DBLP:journals/ec/SuttonNN14} and parameterized settings of 
makespan scheduling~\cite{DBLP:conf/ppsn/SuttonN12} were considered. More recently, both the closest string problem~\cite{DBLP:journals/algorithmica/Sutton21} and
jump and repair operators have been analyzed in the parameterized setting~\cite{DBLP:conf/foga/BransonS21}.
%
A crucial aspect of the parameterized analysis of evolutionary algorithms (and algorithms in general) is the ability of the considered approaches to obtain a kernelization 
%(roughly a polynomial algorithm that provides a kernel)
for the respective problems. A kernel here refers to a smaller sub-problem whose size is polynomially bounded in the size of the given parameter(s). As the size is bounded, brute-force methods or random sampling can then be applied to obtain an optimal solution.

%\zienain{More Gecco literature would be nice.} %\frank{Sorry there is not much more at GECCO although the con version of closest string has been at GECCO}

 
A small subset of vertices that disconnect a graph is usually called a vertex separator.
In terms of successful divide-and-conquer or parallel processing strategies, such separators are one of the most powerful tools for developing efficient graph algorithms.
This generality and its broad applicability have made the study of separators a rich and
active field of research, see for example the book by Rosenberg and Heath~\cite{DBLP:books/daglib/0007445}, or the line of research
initiated by the seminal work of Lipton and Tarjan \cite{doi:10.1137/0136016} on separators in planar graphs.
Numerous different types of separator structures have emerged over the past couple of decades.
In this paper, we address the problem of decomposing a graph into small pieces - with respect to a parameter $W$ - by removing the smallest possible set of vertices. 
More formally, given a graph $G=(V,E)$ and a parameter $W \in \N$, the goal is to remove the minimum number of vertices such that each connected component in the resulting graph has at most $W$ vertices.
The problem is called the \emph{$W$-separator problem} --- also known in the literature as the \emph{component order connectivity problem} or \emph{$\alpha$-balanced separator problem}, where $\alpha  \in (0,1)$ and $W=\alpha|V|$.
An equivalent view of this problem is to ask for the minimum number of vertices required to cover or hit every connected subgraph of size $W+1$.
In particular, $W=1$ corresponds to covering all edges, showing that the $W$-separator problem is a natural generalization of the vertex cover problem.

In this paper, we generalize the results obtained in \cite{DBLP:journals/algorithmica/KratschN13} for the vertex cover problem to the more general $W$-separator problem.
Precisely, we study multi-objective evolutionary algorithms for the $W$-separator problem and show that in expectation they admit fixed parameter runtimes with respect to the value of an optimal solution $\opt$ and $W$.
It is unlikely that such runtimes can be achieved by considering $\opt$ or $W$ alone.
Indeed, $W=1$ corresponds to a hard problem, which shows that $W$ (alone) is not a suitable parameter.
For the parameter $\opt$, the problem is $W[1]$-hard even when restricted to split graphs~\cite{DBLP:journals/algorithmica/DrangeDH16}.
These lower bounds lead to the study of parameterization by $W+\opt$.
The best known algorithm with respect to these parameters finds an optimal solution in time $n^{O(1)} \cdot 2^{\O(\log(W) \cdot \opt)}$~\cite{DBLP:journals/algorithmica/DrangeDH16}.
Unless the exponential time hypothesis fails, the authors prove that this running time is tight up to constant factors, i.e., there is no algorithm that solves the problem in time $n^{\O(1)} \cdot 2^{o(\opt \cdot \log(W))}$.
For kernelizations with respect to the parameters $\opt$ and $W$, the best known polynomial algorithm achieves a kernel of size $3 W \cdot \opt$~\cite{DBLP:conf/esa/Casel0INZ21}.
A kernel of size $2 W \cdot \opt$ is provided in~\cite{DBLP:conf/iwpec/KumarL16} in a runtime of $n^{\O(1)} \cdot 2^{\O(W)}$ by using linear programming methods (the runtime is not specified in the paper, but can be realized as already mentioned in \cite{fomin2019kernelization} Section 6.4.2).
In particular, for the vertex cover problem (, i.e.,~$W=1$), they obtain a $2 \cdot \opt$ size-kernel implying that they also obtain 2-approximation.
That is, under the assumption that the unique games conjecture is true, $2W \cdot \opt$ is the best kernel we can hope for~\cite{KHOT2008335}.
%We remark that under the unique games conjecture a $2$-approximation is a lower bound for the vertex cover problem.
Finally, the best known approximation algorithm also uses linear programming methods and has a gap guarantee of $\O(\log(W))$ with a running time of $n^{\O(1)} \cdot 2^{\O(W)}$~\cite{DBLP:journals/corr/Lee16c}.
%, which makes also use of linear programming methods. 
They also showed that the superpolynomial dependence on $W$ may be needed to achieve a polylogarithmic approximation.


\paragraph{\textbf{Our Contribution:}}
Of particular interest in our work are kernelizations and the reducible structures used for them.
 %in \cite{DBLP:journals/algorithmica/KratschN13} and in our work
We show that in expectation the algorithms make incremental progress in finding such structures and beyond.
Compared to the vertex cover problem, kernelization algorithms that are linear in $\opt$ for the $W$-separator problem are more complicated (cf.~\cite{DBLP:journals/corr/Xiao16b,DBLP:conf/esa/Casel0INZ21,DBLP:conf/iwpec/KumarL16}).
The current best known kernelization of the $W$-separator uses linear programming methods and requires a non-trivial post-process to extract the reducible structures~\cite{DBLP:conf/iwpec/KumarL16}.
The challenge in this paper is to show that natural objectives, combined with simple and problem-independent mutations, are also capable of extracting them.
To this end, we add additional structural features to the reducible structures used in~\cite{DBLP:conf/iwpec/KumarL16}.
%In particular, for this purpose we provide additional structural features to the reducible structures used in~\cite{DBLP:conf/iwpec/KumarL16}.
Essentially, our results show that evolutionary algorithms with different objectives guide the search and admit fixed parameterized runtimes to solve or approximate (even arbitrarily close) the $W$-separator problem.
 
The different runtimes are given in this paper in terms of the number of iterations, but the tractability with respect to the considered parameters also applies when we include search point evaluations.
In the following, we roughly describe the runtimes achieved with respect to the search point evaluations for exact and approximate solutions, where all results are given in expectation.
We consider simple and problem-independent evolutionary algorithms in combination with three different multi-objective fitness functions.
The first consists of relatively simple calculations to evaluate the search points and allows us to achieve a running time of $n^{\O(1)} \cdot 2^{\O(\opt^2 \cdot W^2)}$ to find an optimal solution. 
%Heavier evaluations in the sense of using linear programming methods are used for the second and third fitness function, where the third is a sub-evaluation of the second one and serves rather for approximations.
For the second and third fitness functions, stronger objectives are used in the sense of applying linear programming methods.
%, with the third being an of the second and more of an approximation.
%At this point we emphasize that a search point evaluation is tractable with the parameter $W$.
We prove that with such evaluations the optimal solution can be found in time $n^{\O(1)} \cdot 2^{\O(\opt \cdot W)}$.
%Unless the exponential time hypothesis fails, it is unlikely that there is an algorithm that runs in time $n^{\O(1)} \cdot 2^{o(\opt \cdot \log(W))}$ to find an optimal solution~\cite{DBLP:journals/algorithmica/DrangeDH16}.  
Moreover, depending on the choice of an $\varepsilon \in [0,1)$ we obtain solutions arbitrary close to an optimal one, where the according algorithm is tractable with respect to the parameters $\opt$ and $W$.
As usual, the larger $\varepsilon$, the worse the gap guarantee, but with better running time, where $\varepsilon=0$ corresponds to the above running time in finding an optimal solution.
This result shows that we can hope for a gradual progress until an optimal solution is reached.

Our results show that in expectation evolutionary algorithms are asymptotically not far away from the problem-specific ones, where the evolved algorithms are close to the lower bounds for the $W$-separator problem. 

\paragraph{\textbf{Overview of the paper}}
The paper is organized as follows: Section~\ref{sec::prelim} are the preliminaries and includes the notation, the multiobjective functions and the algorithms we work with.
A runtime analysis of the considered algorithms for finding exact solutions for degree-based and LP-based fitness functions are presented in the sections~\ref{sec::f1}~ and~\ref{sec::f2}, respectively.
Finally, Section~\ref{sec::apx} is dedicated to the analysis of running times for approximations.
Moreover, due to space constraints all omitted proofs of the Sections \ref{sec::prelim},\ref{sec::f1},\ref{sec::f2} and \ref{sec::apx} can be found in the appendix in the Sections \ref{appendix::prelim}, \ref{appendix::f1},  \ref{appendix::f2} and \ref{appendix::apx}, respectively.


%\zienain{Marcus: If we mention here that 'All proofs that are omitted due to space constrains can be found in the supplemental material', we can remove it everywhere else, right?}


%\vspace{1cm}
%
%In this paper, we generalize the results obtained in \cite{DBLP:journals/algorithmica/KratschN13} for the vertex cover problem to the more general $W$-separator problem.
%It has been shown in \cite{DBLP:journals/algorithmica/KratschN13}
%that multi-objective formulations in connection with mutation operators flipping bit adjacent to edges that are not covered by the current solution lead to fixed parameter evolutionary algorithms. 
%The approaches considered in \cite{DBLP:journals/algorithmica/KratschN13} obtain a kernelization for the vertex cover problem enabled through the multi-objective formulations of the problem. Afterwards, the mutation operator choosing nodes adjacent to uncovered edges uniformly at random carries out the brute-force component of the algorithm which leads to the parameterized results.
%
%We extend these approaches to the $W$-separator problem by providing $2$- and $3$-objective formulations that allow evolutionary multi-objective algorithms to obtain optimal solutions and good approximations in the parameterized setting. The $W$-separator problem consists of finding a minimum set of vertices such that after their removal the graph consists of components of size at most $W$. Note that removing the nodes of a vertex cover of a given undirected graph results in an independent set and therefore is equivalent to solving the $W$-separator problem for $W=1$.	