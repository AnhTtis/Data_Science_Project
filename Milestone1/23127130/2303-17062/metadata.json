{
    "arxiv_id": "2303.17062",
    "paper_title": "Ideal Abstractions for Decision-Focused Learning",
    "authors": [
        "Michael Poli",
        "Stefano Massaroli",
        "Stefano Ermon",
        "Bryan Wilder",
        "Eric Horvitz"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-03-31"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "cs.AI"
    ],
    "abstract": "We present a methodology for formulating simplifying abstractions in machine learning systems by identifying and harnessing the utility structure of decisions. Machine learning tasks commonly involve high-dimensional output spaces (e.g., predictions for every pixel in an image or node in a graph), even though a coarser output would often suffice for downstream decision-making (e.g., regions of an image instead of pixels). Developers often hand-engineer abstractions of the output space, but numerous abstractions are possible and it is unclear how the choice of output space for a model impacts its usefulness in downstream decision-making. We propose a method that configures the output space automatically in order to minimize the loss of decision-relevant information. Taking a geometric perspective, we formulate a step of the algorithm as a projection of the probability simplex, termed fold, that minimizes the total loss of decision-related information in the H-entropy sense. Crucially, learning in the abstracted outcome space requires less data, leading to a net improvement in decision quality. We demonstrate the method in two domains: data acquisition for deep neural network training and a closed-loop wildfire management task.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17062v1"
    ],
    "publication_venue": "AISTATS 2023"
}