@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@inproceedings{NIPS2017_f22e4747,
 author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Russ R and Smola, Alexander J},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Deep Sets},
 url = {https://proceedings.neurips.cc/paper/2017/file/f22e4747da1aa27e363d86d40ff442fe-Paper.pdf},
 volume = {30},
 year = {2017}
}



@inproceedings{10.5555/3524938.3525892,
author = {Wistuba, Martin and Pedapati, Tejaswini},
title = {Learning to Rank Learning Curves},
year = {2020},
publisher = {JMLR.org},
abstract = {Many automated machine learning methods, such as those for hyperparameter and neural architecture optimization, are computationally expensive because they involve training many different model configurations. In this work, we present a new method that saves computational budget by terminating poor configurations early on in the training. In contrast to existing methods, we consider this task as a ranking and transfer learning problem. We qualitatively show that by optimizing a pairwise ranking loss and leveraging learning curves from other datasets, our model is able to effectively rank learning curves without having to observe many or very long learning curves. We further demonstrate that our method can be used to accelerate a neural architecture search by a factor of up to 100 without a significant performance degradation of the discovered architecture. In further experiments we analyze the quality of ranking, the influence of different model components as well as the predictive behavior of the model.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {954},
numpages = {10},
series = {ICML'20}
}



@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{Ober2021_Thepromises,
  author    = {Sebastian W. Ober and
               Carl E. Rasmussen and
               Mark van der Wilk},
  editor    = {Cassio P. de Campos and
               Marloes H. Maathuis and
               Erik Quaeghebeur},
  title     = {The promises and pitfalls of deep kernel learning},
  booktitle = {Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
               Intelligence, {UAI} 2021, Virtual Event, 27-30 July 2021},
  series    = {Proceedings of Machine Learning Research},
  volume    = {161},
  pages     = {1206--1216},
  publisher = {{AUAI} Press},
  year      = {2021}
}

@inproceedings{Lakshminarayanan2017_DeepEnsembles,
  author    = {Balaji Lakshminarayanan and
               Alexander Pritzel and
               Charles Blundell},
  editor    = {Isabelle Guyon and
               Ulrike von Luxburg and
               Samy Bengio and
               Hanna M. Wallach and
               Rob Fergus and
               S. V. N. Vishwanathan and
               Roman Garnett},
  title     = {Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
               on Neural Information Processing Systems 2017, December 4-9, 2017,
               Long Beach, CA, {USA}},
  pages     = {6402--6413},
  year      = {2017},

}

@inproceedings{Wilson20_Bayesian,
  author    = {Andrew Gordon Wilson and
               Pavel Izmailov},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Bayesian Deep Learning and a Probabilistic Perspective of Generalization},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020}
}

@inproceedings{Snoek2019_Can,
  author    = {Jasper Snoek and
               Yaniv Ovadia and
               Emily Fertig and
               Balaji Lakshminarayanan and
               Sebastian Nowozin and
               D. Sculley and
               Joshua V. Dillon and
               Jie Ren and
               Zachary Nado},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Can you trust your model's uncertainty? Evaluating predictive uncertainty
               under dataset shift},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {13969--13980},
  year      = {2019}
}

@article{jomaa2021dataset2vec,
  title={Dataset2vec: Learning dataset meta-features},
  author={Jomaa, Hadi S and Schmidt-Thieme, Lars and Grabocka, Josif},
  journal={Data Mining and Knowledge Discovery},
  pages={1--22},
  year={2021},
  publisher={Springer}
}

@inproceedings{
rakotoarison2022learning,
title={Learning meta-features for Auto{ML}},
author={Herilalaina Rakotoarison and Louisot Milijaona and Andry RASOANAIVO and Michele Sebag and Marc Schoenauer},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=DTkEfj0Ygb8}
}

@inproceedings{Ashukha2020_Pitfalls,
  author    = {Arsenii Ashukha and
               Alexander Lyzhov and
               Dmitry Molchanov and
               Dmitry P. Vetrov},
  title     = {Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep
               Learning},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020}
}


@inproceedings{Wen20_BatchEnsemble,
  author    = {Yeming Wen and
               Dustin Tran and
               Jimmy Ba},
  title     = {BatchEnsemble: an Alternative Approach to Efficient Ensemble and Lifelong
               Learning},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020}
}


@inproceedings{Bardenet2013_Collaborative,
  author    = {R{\'{e}}mi Bardenet and
               M{\'{a}}ty{\'{a}}s Brendel and
               Bal{\'{a}}zs K{\'{e}}gl and
               Mich{\`{e}}le Sebag},
  title     = {Collaborative hyperparameter tuning},
  booktitle = {Proceedings of the 30th International Conference on Machine Learning,
               {ICML} 2013, Atlanta, GA, USA, 16-21 June 2013},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {28},
  pages     = {199--207},
  publisher = {JMLR.org},
  year      = {2013}
}

@article{Akiba2019_Optuna,
  author    = {Takuya Akiba and
               Shotaro Sano and
               Toshihiko Yanase and
               Takeru Ohta and
               Masanori Koyama},
  title     = {Optuna: {A} Next-generation Hyperparameter Optimization Framework},
  journal   = {CoRR},
  volume    = {abs/1907.10902},
  year      = {2019},
    archivePrefix = {arXiv},
  eprint    = {1907.10902}
}

@inproceedings{Alaa2018_AutoPrognosis,
  author    = {Ahmed M. Alaa and
               Mihaela van der Schaar},
  title     = {AutoPrognosis: Automated Clinical Prognostic Modeling via Bayesian
               Optimization with Structured Kernel Learning},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning,
               {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July
               10-15, 2018},
  pages     = {139--148},
  year      = {2018},
}

@inbook{Almeida1999_Parameter,
    author = {Almeida, Lu\'{\i}s B. and
              Langlois, Thibault and
              Amaral, Jos\'{e} D. and
              Plakhov, Alexander},
    title = {Parameter Adaptation in Stochastic Optimization},
    year = {1999},
    isbn = {0521652634},
    publisher = {Cambridge University Press},
    address = {USA},
    booktitle = {On-Line Learning in Neural Networks},
    pages = {111–134},
    numpages = {24}
}

@inproceedings{Ansel2018_Opentuner,
  author    = {Jason Ansel and
               Shoaib Kamil and
               Kalyan Veeramachaneni and
               Jonathan Ragan{-}Kelley and
               Jeffrey Bosboom and
               Una{-}May O'Reilly and
               Saman P. Amarasinghe},
  title     = {OpenTuner: an extensible framework for program autotuning},
  booktitle = {International Conference on Parallel Architectures and Compilation,
               {PACT} '14, Edmonton, AB, Canada, August 24-27, 2014},
  pages     = {303--316},
  year      = {2014},
}

@article{Awad2021_DEHB,
  author    = {Noor H. Awad and
               Neeratyoy Mallik and
               Frank Hutter},
  title     = {{DEHB:} Evolutionary Hyberband for Scalable, Robust and Efficient
               Hyperparameter Optimization},
  journal   = {CoRR},
  volume    = {abs/2105.09821},
  year      = {2021},
  archivePrefix = {arXiv},
  eprint    = {2105.09821},
}  

@inproceedings{Baker2018_Accelerating,
  author    = {Bowen Baker and
               Otkrist Gupta and
               Ramesh Raskar and
               Nikhil Naik},
  title     = {Accelerating Neural Architecture Search using Performance Prediction},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Workshop Track Proceedings},
  year      = {2018},
}

@inproceedings{Balandat2020_BoTorch,
  author    = {Maximilian Balandat and
               Brian Karrer and
               Daniel R. Jiang and
               Samuel Daulton and
               Benjamin Letham and
               Andrew Gordon Wilson and
               Eytan Bakshy},
  title     = {BoTorch: {A} Framework for Efficient Monte-Carlo Bayesian Optimization},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020},

}




@inproceedings{Bardenet2013_Scot,
  author    = {R{\'{e}}mi Bardenet and
               M{\'{a}}ty{\'{a}}s Brendel and
               Bal{\'{a}}zs K{\'{e}}gl and
               Mich{\`{e}}le Sebag},
  title     = {Collaborative hyperparameter tuning},
  booktitle = {Proceedings of the 30th International Conference on Machine Learning,
               {ICML} 2013, Atlanta, GA, USA, 16-21 June 2013},
  pages     = {199--207},
  year      = {2013},
}

@article{Baydin2017_Automatic,
  author    = {Atilim Gunes Baydin and
               Barak A. Pearlmutter and
               Alexey Andreyevich Radul and
               Jeffrey Mark Siskind},
  title     = {Automatic Differentiation in Machine Learning: a Survey},
  journal   = {J. Mach. Learn. Res.},
  volume    = {18},
  pages     = {153:1--153:43},
  year      = {2017},
}

@inproceedings{Baydin2018_Online,
  author    = {Atilim Gunes Baydin and
               Robert Cornish and
               David Mart{\'{\i}}nez{-}Rubio and
               Mark Schmidt and
               Frank Wood},
  title     = {Online Learning Rate Adaptation with Hypergradient Descent},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  year      = {2018},
}


@inproceedings{Bergstra2011_Algorithms,
  author    = {James Bergstra and
               R{\'{e}}mi Bardenet and
               Yoshua Bengio and
               Bal{\'{a}}zs K{\'{e}}gl},
  title     = {Algorithms for Hyper-Parameter Optimization},
  booktitle = {Advances in Neural Information Processing Systems 24: 25th Annual
               Conference on Neural Information Processing Systems 2011. Proceedings
               of a meeting held 12-14 December 2011, Granada, Spain},
  pages     = {2546--2554},
  year      = {2011},
}

@article{Bergstra2012_Random,
  author    = {James Bergstra and
               Yoshua Bengio},
  title     = {Random Search for Hyper-Parameter Optimization},
  journal   = {J. Mach. Learn. Res.},
  volume    = {13},
  pages     = {281--305},
  year      = {2012},
}



@inproceedings{Bergstra2013_Making,
  author    = {James Bergstra and
               Daniel Yamins and
               David D. Cox},
  title     = {Making a Science of Model Search: Hyperparameter Optimization in Hundreds
               of Dimensions for Vision Architectures},
  booktitle = {Proceedings of the 30th International Conference on Machine Learning,
               {ICML} 2013, Atlanta, GA, USA, 16-21 June 2013},
  pages     = {115--123},
  year      = {2013},
}


@article{Berkenkamp2020_Probabilistic,
  title={Probabilistic Meta-Learning for Bayesian Optimization},
  author={Berkenkamp, Felix and Eivazi, Anna and Grossberger, Lukas and Skubch, Kathrin and Spitz, Jonathan and Daniel, Christian and Falkner, Stefan},
  year={2020}
}

@article{Bing2021_Reinforced,
  author    = {Bing{-}Jing Hsieh and
               Ping{-}Chun Hsieh and
               Xi Liu},
  title     = {Reinforced Few-Shot Acquisition Function Learning for Bayesian Optimization},
  journal   = {CoRR},
  volume    = {abs/2106.04335},
  year      = {2021},
  archivePrefix = {arXiv},
  eprint    = {2106.04335},
}



@article{Bischl2021_Hyperparameter,
  author    = {Bernd Bischl and
               Martin Binder and
               Michel Lang and
               Tobias Pielok and
               Jakob Richter and
               Stefan Coors and
               Janek Thomas and
               Theresa Ullmann and
               Marc Becker and
               Anne{-}Laure Boulesteix and
               Difan Deng and
               Marius Lindauer},
  title     = {Hyperparameter Optimization: Foundations, Algorithms, Best Practices
               and Open Challenges},
  journal   = {CoRR},
  volume    = {abs/2107.05847},
  year      = {2021},
  archivePrefix = {arXiv},
  eprint    = {2107.05847},
}



@inproceedings{Chandrashekaran2017_Speeding,
  author = {Akshay Chandrashekaran and Ian R. Lane},
  title = {Speeding up Hyper-parameter Optimization by Extrapolation of Learning Curves Using Previous Builds},
  booktitle = {Machine Learning and Knowledge Discovery in Databases - European Conference, {ECML} {PKDD} 2017, Skopje, Macedonia, September 18-22, 2017, Proceedings, Part {I}},
  year = {2017},
  volume = {10534},
  series = {Lecture Notes in Computer Science},
  pages = {477--492},
  publisher = {Springer}
}

@inproceedings{Chen2018_Autostacker,
  author    = {Boyuan Chen and
               Harvey Wu and
               Warren Mo and
               Ishanu Chattopadhyay and
               Hod Lipson},
  editor    = {Hern{\'{a}}n E. Aguirre and
               Keiki Takadama},
  title     = {Autostacker: a compositional evolutionary learning system},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference,
               {GECCO} 2018, Kyoto, Japan, July 15-19, 2018},
  pages     = {402--409},
  publisher = {{ACM}},
  year      = {2018},
  url       = {https://doi.org/10.1145/3205455.3205586},
  doi       = {10.1145/3205455.3205586},

}


@inproceedings{Domhan2015_Speeding,
  author = {Tobias Domhan and Jost Tobias Springenberg and Frank Hutter},
  title = {Speeding Up Automatic Hyperparameter Optimization of Deep Neural Networks by Extrapolation of Learning Curves},
  booktitle = {Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence, {IJCAI} 2015, Buenos Aires, Argentina, July 25-31, 2015},
  year = {2015},
  pages = {3460--3468},
  publisher = {{AAAI} Press}
}


@article{Drori2021_AlphaD3M,
  author    = {Iddo Drori and
               Yamuna Krishnamurthy and
               R{\'{e}}mi Rampin and
               Raoni de Paula Louren{\c{c}}o and
               Jorge Piazentin Ono and
               Kyunghyun Cho and
               Cl{\'{a}}udio T. Silva and
               Juliana Freire},
  title     = {AlphaD3M: Machine Learning Pipeline Synthesis},
  journal   = {CoRR},
  volume    = {abs/2111.02508},
  year      = {2021},
  url       = {https://arxiv.org/abs/2111.02508},
  eprinttype = {arXiv},
  eprint    = {2111.02508},

}

@article{Drori2019_AutoML,
  author    = {Iddo Drori and
               Lu Liu and
               Yi Nian and
               Sharath C. Koorathota and
               Jie S. Li and
               Antonio Khalil Moretti and
               Juliana Freire and
               Madeleine Udell},
  title     = {AutoML using Metadata Language Embeddings},
  journal   = {CoRR},
  volume    = {abs/1910.03698},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.03698},
}


@misc{Eggensperger2020_HPOBench,
    author = {K. Eggensperger and P. Müller},
    title = {{HPOBench}},
    year = {2020},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/automl/HPOBench}},
}

@misc{Eggensperger2016_HPOLib,
    author = {K. Eggensperger and M. Feurer},
    title = {{HPOLib}},
    year = {2016},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/automl/HPOlib}},
}

@inproceedings{Eggensperger2013_Towards,
  title={Towards an empirical foundation for assessing bayesian optimization of hyperparameters},
  author={Eggensperger, Katharina and Feurer, Matthias and Hutter, Frank and Bergstra, James and Snoek, Jasper and Hoos, Holger and Leyton-Brown, Kevin},
  booktitle={NIPS workshop on Bayesian Optimization in Theory and Practice},
  volume={10},
  pages={3},
  year={2013}
}

@article{OpenML2013,
author = {Vanschoren, Joaquin and van Rijn, Jan N. and Bischl, Bernd and Torgo, Luis},
title = {OpenML: Networked Science in Machine Learning},
journal = {SIGKDD Explorations},
volume = {15},
number = {2},
year = {2013},
pages = {49--60},
url = {http://doi.acm.org/10.1145/2641190.2641198},
doi = {10.1145/2641190.2641198},
publisher = {ACM},
address = {New York, NY, USA},
} 


@article{Elsken2019_Neural,
  author    = {Thomas Elsken and
               Jan Hendrik Metzen and
               Frank Hutter},
  title     = {Neural Architecture Search: {A} Survey},
  journal   = {J. Mach. Learn. Res.},
  volume    = {20},
  pages     = {55:1--55:21},
  year      = {2019},
}

@article{Eriksson2019_Pysot,
  author    = {David Eriksson and
               David Bindel and
               Christine A. Shoemaker},
  title     = {pySOT and {POAP:} An event-driven asynchronous framework for surrogate
               optimization},
  journal   = {CoRR},
  volume    = {abs/1908.00420},
  year      = {2019},
  archivePrefix = {arXiv},
  eprint    = {1908.00420},

}

@inproceedings{Eriksson2019_Turbo,
  author    = {David Eriksson and
               Michael Pearce and
               Jacob R. Gardner and
               Ryan Turner and
               Matthias Poloczek},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Scalable Global Optimization via Local Bayesian Optimization},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {5497--5508},
  year      = {2019},
}


@inproceedings{Falkner2018_BOHB,
  author    = {Stefan Falkner and
               Aaron Klein and
               Frank Hutter},
  title     = {{BOHB:} Robust and Efficient Hyperparameter Optimization at Scale},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning,
               {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July
               10-15, 2018},
  pages     = {1436--1445},
  year      = {2018},
}

@inproceedings{Feurer2015_Initializing,
  author    = {Matthias Feurer and
               Jost Tobias Springenberg and
               Frank Hutter},
  editor    = {Blai Bonet and
               Sven Koenig},
  title     = {Initializing Bayesian Hyperparameter Optimization via Meta-Learning},
  booktitle = {Proceedings of the Twenty-Ninth {AAAI} Conference on Artificial Intelligence,
               January 25-30, 2015, Austin, Texas, {USA}},
  pages     = {1128--1135},
  publisher = {{AAAI} Press},
  year      = {2015},

}

@inproceedings{Feurer2018_RGPE,
  title={Scalable meta-learning for bayesian optimization using ranking-weighted gaussian process ensembles},
  author={Feurer, Matthias and Letham, Benjamin and Bakshy, Eytan},
  booktitle={AutoML Workshop at ICML},
  volume={7},
  year={2018}
}

@inproceedings{Franceschi2017_Forward,
  author    = {Luca Franceschi and
               Michele Donini and
               Paolo Frasconi and
               Massimiliano Pontil},
  title     = {Forward and Reverse Gradient-Based Hyperparameter Optimization},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning,
               {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
  pages     = {1165--1173},
  year      = {2017},
}

@inproceedings{Fusi2018_Probabilistic,
  author    = {Nicol{\'{o}} Fusi and
               Rishit Sheth and
               Melih Elibol},
  editor    = {Samy Bengio and
               Hanna M. Wallach and
               Hugo Larochelle and
               Kristen Grauman and
               Nicol{\`{o}} Cesa{-}Bianchi and
               Roman Garnett},
  title     = {Probabilistic Matrix Factorization for Automated Machine Learning},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, December
               3-8, 2018, Montr{\'{e}}al, Canada},
  pages     = {3352--3361},
  year      = {2018},
 }


@inproceedings{Golovin2017_Vizier,
  author    = {Daniel Golovin and
               Benjamin Solnik and
               Subhodeep Moitra and
               Greg Kochanski and
               John Karro and
               D. Sculley},
  title     = {Google Vizier: {A} Service for Black-Box Optimization},
  booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} International Conference on
               Knowledge Discovery and Data Mining, Halifax, NS, Canada, August 13
               - 17, 2017},
  pages     = {1487--1495},
  year      = {2017},
  doi       = {10.1145/3097983.3098043},
}

@Misc{Gpyopt2016,
author = {The GPyOpt authors},
title = {{GPyOpt}: A Bayesian Optimization framework in python},
howpublished = {\url{http://github.com/SheffieldML/GPyOpt}},
year = {2016}
}

@inproceedings{Guimaraes2017_RECIPE,
  author    = {Alex Guimar{\~{a}}es Cardoso de S{\'{a}} and
               Walter Jos{\'{e}} G. S. Pinto and
               Luiz Ot{\'{a}}vio Vilas Boas Oliveira and
               Gisele L. Pappa},
  editor    = {James McDermott and
               Mauro Castelli and
               Luk{\'{a}}s Sekanina and
               Evert Haasdijk and
               Pablo Garc{\'{\i}}a{-}S{\'{a}}nchez},
  title     = {{RECIPE:} {A} Grammar-Based Framework for Automatically Evolving Classification
               Pipelines},
  booktitle = {Genetic Programming - 20th European Conference, EuroGP 2017, Amsterdam,
               The Netherlands, April 19-21, 2017, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {10196},
  pages     = {246--261},
  year      = {2017},
  url       = {https://doi.org/10.1007/978-3-319-55696-3\_16},
  doi       = {10.1007/978-3-319-55696-3\_16},

}

@article{Hakhamaneshi2021_Jumbo,
  author    = {Kourosh Hakhamaneshi and
               Pieter Abbeel and
               Vladimir Stojanovic and
               Aditya Grover},
  title     = {{JUMBO:} Scalable Multi-task Bayesian Optimization using Offline Data},
  journal   = {CoRR},
  volume    = {abs/2106.00942},
  year      = {2021},
  archivePrefix = {arXiv},
  eprint    = {2106.00942},
}




@article{He2021_AutoML,
  author    = {Xin He and
               Kaiyong Zhao and
               Xiaowen Chu},
  title     = {AutoML: {A} survey of the state-of-the-art},
  journal   = {Knowl. Based Syst.},
  volume    = {212},
  pages     = {106622},
  year      = {2021},
  doi       = {10.1016/j.knosys.2020.106622},
}

@article{Hertel2020_Sherpa,
title = {Sherpa: Robust hyperparameter optimization for machine learning},
journal = {SoftwareX},
volume = {12},
pages = {100591},
year = {2020},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2020.100591},
url = {https://www.sciencedirect.com/science/article/pii/S2352711020303046},
author = {Lars Hertel and Julian Collado and Peter Sadowski and Jordan Ott and Pierre Baldi},
}

@inproceedings{Horvath2021_Hyperparameter,
  author    = {Samuel Horv{\'{a}}th and
               Aaron Klein and
               Peter Richt{\'{a}}rik and
               C{\'{e}}dric Archambeau},
  editor    = {Arindam Banerjee and
               Kenji Fukumizu},
  title     = {Hyperparameter Transfer Learning with Adaptive Complexity},
  booktitle = {The 24th International Conference on Artificial Intelligence and Statistics,
               {AISTATS} 2021, April 13-15, 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {130},
  pages     = {1378--1386},
  publisher = {{PMLR}},
  year      = {2021},
}

@article{Hsieh2021_Reinforced,
  author    = {Bing{-}Jing Hsieh and
               Ping{-}Chun Hsieh and
               Xi Liu},
  title     = {Reinforced Few-Shot Acquisition Function Learning for Bayesian Optimization},
  journal   = {CoRR},
  volume    = {abs/2106.04335},
  year      = {2021},
  archivePrefix = {arXiv},
  eprint    = {2106.04335},
}

@inproceedings{Hutter2011_Sequential,
  author    = {Frank Hutter and
               Holger H. Hoos and
               Kevin Leyton{-}Brown},
  title     = {Sequential Model-Based Optimization for General Algorithm Configuration},
  booktitle = {Learning and Intelligent Optimization - 5th International Conference,
               {LION} 5, Rome, Italy, January 17-21, 2011. Selected Papers},
  pages     = {507--523},
  year      = {2011},
  doi       = {10.1007/978-3-642-25566-3\_40},
}

@book{Hutter2019_Automated,
  editor    = {Frank Hutter and
               Lars Kotthoff and
               Joaquin Vanschoren},
  title     = {Automated Machine Learning - Methods, Systems, Challenges},
  series    = {The Springer Series on Challenges in Machine Learning},
  publisher = {Springer},
  year      = {2019},
  doi       = {10.1007/978-3-030-05318-5},
  isbn      = {978-3-030-05317-8},
}

@article{Imani2020_HEBO,
  author    = {Alexander Imani Cowen{-}Rivers and
               Wenlong Lyu and
               Zhi Wang and
               Rasul Tutunov and
               Jianye Hao and
               Jun Wang and
               Haitham Bou{-}Ammar},
  title     = {{HEBO:} Heteroscedastic Evolutionary Bayesian Optimisation},
  journal   = {CoRR},
  volume    = {abs/2012.03826},
  year      = {2020},
  archivePrefix = {arXiv},
  eprint    = {2012.03826}
}

@article{Jaderberg2017_Population,
  author    = {Max Jaderberg and
               Valentin Dalibard and
               Simon Osindero and
               Wojciech M. Czarnecki and
               Jeff Donahue and
               Ali Razavi and
               Oriol Vinyals and
               Tim Green and
               Iain Dunning and
               Karen Simonyan and
               Chrisantha Fernando and
               Koray Kavukcuoglu},
  title     = {Population Based Training of Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1711.09846},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.09846},
  eprinttype = {arXiv},
  eprint    = {1711.09846},
}

@inproceedings{Jamieson2016_Non,
  author    = {Kevin G. Jamieson and
               Ameet Talwalkar},
  title     = {Non-stochastic Best Arm Identification and Hyperparameter Optimization},
  booktitle = {Proceedings of the 19th International Conference on Artificial Intelligence
               and Statistics, {AISTATS} 2016, Cadiz, Spain, May 9-11, 2016},
  pages     = {240--248},
  year      = {2016},
}

@article{Jimenez2017_pyGPGO,
  author    = {Jos{\'{e}} Jim{\'{e}}nez and
               Josep Ginebra},
  title     = {pyGPGO: Bayesian Optimization for Python},
  journal   = {J. Open Source Softw.},
  volume    = {2},
  number    = {19},
  pages     = {431},
  year      = {2017},
}

@inproceedings{Jin2019_Autokeras,
  title={Auto-Keras: An Efficient Neural Architecture Search System},
  author={Jin, Haifeng and Song, Qingquan and Hu, Xia},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1946--1956},
  year={2019},
  organization={ACM}
}

@inproceedings{Kandasamy2018_Neural,
  author    = {Kirthevasan Kandasamy and
               Willie Neiswanger and
               Jeff Schneider and
               Barnab{\'{a}}s P{\'{o}}czos and
               Eric P. Xing},
  title     = {Neural Architecture Search with Bayesian Optimisation and Optimal
               Transport},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, December
               3-8, 2018, Montr{\'{e}}al, Canada},
  pages     = {2020--2029},
  year      = {2018},
}

@article{Kandasamy2020_Tuning,
  author    = {Kirthevasan Kandasamy and
               Karun Raju Vysyaraju and
               Willie Neiswanger and
               Biswajit Paria and
               Christopher R. Collins and
               Jeff Schneider and
               Barnab{\'{a}}s P{\'{o}}czos and
               Eric P. Xing},
  title     = {Tuning Hyperparameters without Grad Students: Scalable and Robust
               Bayesian Optimisation with Dragonfly},
  journal   = {J. Mach. Learn. Res.},
  volume    = {21},
  pages     = {81:1--81:27},
  year      = {2020},
}

@misc{Kill2019_Bayesmark,
    author = {J. Hill and M. Shibata and D. Eriksson},
    title = {{Bayesmark}},
    year = {2019},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/uber/bayesmark}},
}


@inproceedings{Klein2017_Robo,
  title={Robo: A flexible and robust bayesian optimization framework in python.},
  author={Klein, Aaron and Falkner, Stefan and Mansur, Numair and Hutter, Frank},
  booktitle = {NIPS 2017 Bayesian Optimization Workshop},
  year = {2017}
}

@inproceedings{Klein2017_Fast,
  author    = {Aaron Klein and
               Stefan Falkner and
               Simon Bartels and
               Philipp Hennig and
               Frank Hutter},
  title     = {Fast Bayesian Optimization of Machine Learning Hyperparameters on
               Large Datasets},
  booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence
               and Statistics, {AISTATS} 2017, 20-22 April 2017, Fort Lauderdale,
               FL, {USA}},
  pages     = {528--536},
  year      = {2017},
}

@inproceedings{Klein2017_Learning,
  author    = {Aaron Klein and
               Stefan Falkner and
               Jost Tobias Springenberg and
               Frank Hutter},
  title     = {Learning Curve Prediction with Bayesian Neural Networks},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  year      = {2017},
}

@incollection{Komer2019_Hyperopt,
  author    = {Brent Komer and
               James Bergstra and
               Chris Eliasmith},
  title     = {Hyperopt-Sklearn},
  booktitle = {Automated Machine Learning - Methods, Systems, Challenges},
  pages     = {97--111},
  publisher = {Springer},
  year      = {2019},
}


@misc{Kotila2020_Talos,
    author = { Mikko Kotila },
    title = {{Talos}},
    year = {2020},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/autonomio/talos}},
}

@incollection{Larsen1996_Neural,
  author    = {Jan Larsen and
               Claus Svarer and
               Lars Nonboe Andersen and
               Lars Kai Hansen},
  editor    = {Genevieve B. Orr and
               Klaus{-}Robert M{\"{u}}ller},
  title     = {Adaptive Regularization in Neural Network Modeling},
  booktitle = {Neural Networks: Tricks of the Trade},
  series    = {Lecture Notes in Computer Science},
  volume    = {1524},
  pages     = {113--132},
  publisher = {Springer},
  year      = {1996},
  url       = {https://doi.org/10.1007/3-540-49430-8\_6},
  doi       = {10.1007/3-540-49430-8\_6},
}

@inproceedings{Larsen1996_Design,
  author    = {Larsen, J. and
               Hansen, L.K. and
               Svarer, C. and
               Ohlsson, M.},
  booktitle = {Neural Networks for Signal Processing VI. Proceedings of the 1996 IEEE Signal Processing Society Workshop},
  title     = {Design and regularization of neural networks: the optimal use of a validation set},
  year      = {1996},
  volume={},
  number={},
  pages={62-71},
  doi={10.1109/NNSP.1996.548336}
}

@article{Le2020scaling,
  title={Scaling tree-based automated machine learning to biomedical big data with a feature set selector},
  author={Le, Trang T and Fu, Weixuan and Moore, Jason H},
  journal={Bioinformatics},
  volume={36},
  number={1},
  pages={250--256},
  year={2020},
  publisher={Oxford University Press}
}


@article{Li2017_Hyperband,
  author    = {Lisha Li and
               Kevin G. Jamieson and
               Giulia DeSalvo and
               Afshin Rostamizadeh and
               Ameet Talwalkar},
  title     = {Hyperband: {A} Novel Bandit-Based Approach to Hyperparameter Optimization},
  journal   = {J. Mach. Learn. Res.},
  volume    = {18},
  pages     = {185:1--185:52},
  year      = {2017},
}

@article{Liaw2018_Tune,
    title={Tune: A Research Platform for Distributed Model Selection and Training},
    author={Liaw, Richard and Liang, Eric and Nishihara, Robert
            and Moritz, Philipp and Gonzalez, Joseph E and Stoica, Ion},
    journal={arXiv preprint arXiv:1807.05118},
    year={2018}
}

@inproceedings{Li2020_A,
  author    = {Liam Li and
               Kevin G. Jamieson and
               Afshin Rostamizadeh and
               Ekaterina Gonina and
               Jonathan Ben{-}tzur and
               Moritz Hardt and
               Benjamin Recht and
               Ameet Talwalkar},
  title     = {A System for Massively Parallel Hyperparameter Tuning},
  booktitle = {Proceedings of Machine Learning and Systems 2020, MLSys 2020, Austin,
               TX, USA, March 2-4, 2020},
  year      = {2020},
}

@inproceedings{Lin2019_Online,
  author    = {Chen Lin and
               Minghao Guo and
               Chuming Li and
               Xin Yuan and
               Wei Wu and
               Junjie Yan and
               Dahua Lin and
               Wanli Ouyang},
  title     = {Online Hyper-Parameter Learning for Auto-Augmentation Strategy},
  booktitle = {2019 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
               2019, Seoul, Korea (South), October 27 - November 2, 2019},
  pages     = {6578--6587},
  year      = {2019},
  doi       = {10.1109/ICCV.2019.00668},
}

@article{Lindauer2019_Boah,
  author    = {Marius Lindauer and
               Katharina Eggensperger and
               Matthias Feurer and
               Andr{\'{e}} Biedenkapp and
               Joshua Marben and
               Philipp M{\"{u}}ller and
               Frank Hutter},
  title     = {{BOAH:} {A} Tool Suite for Multi-Fidelity Bayesian Optimization {\&}
               Analysis of Hyperparameters},
  journal   = {CoRR},
  volume    = {abs/1908.06756},
  year      = {2019},
  archivePrefix = {arXiv},
  eprint    = {1908.06756},
}

@inproceedings{Liu2019_Auptimizer,
  author    = {Jiayi Liu and
               Samarth Tripathi and
               Unmesh Kurup and
               Mohak Shah},
  title     = {Auptimizer - an Extensible, Open-Source Framework for Hyperparameter
               Tuning},
  booktitle = {2019 {IEEE} International Conference on Big Data (Big Data), Los Angeles,
               CA, USA, December 9-12, 2019},
  pages     = {339--348},
  publisher = {{IEEE}},
  year      = {2019},
  doi       = {10.1109/BigData47090.2019.9006330},
}

@inproceedings{Liu2020_AnADMM,
  author    = {Sijia Liu and
               Parikshit Ram and
               Deepak Vijaykeerthy and
               Djallel Bouneffouf and
               Gregory Bramble and
               Horst Samulowitz and
               Dakuo Wang and
               Andrew Conn and
               Alexander G. Gray},
  title     = {An {ADMM} Based Framework for AutoML Pipeline Configuration},
  booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
               2020, The Thirty-Second Innovative Applications of Artificial Intelligence
               Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
               Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
               February 7-12, 2020},
  pages     = {4892--4899},
  publisher = {{AAAI} Press},
  year      = {2020},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/5926},
}


@article{Liu2021_Investigating,
  author    = {Risheng Liu and
               Jiaxin Gao and
               Jin Zhang and
               Deyu Meng and
               Zhouchen Lin},
  title     = {Investigating Bi-Level Optimization for Learning and Vision from a
               Unified Perspective: {A} Survey and Beyond},
  journal   = {CoRR},
  volume    = {abs/2101.11517},
  year      = {2021},
  archivePrefix = {arXiv},
  eprint    = {2101.11517},
}

@article{Liu2019_Automated,
  author    = {Sijia Liu and
               Parikshit Ram and
               Djallel Bouneffouf and
               Gregory Bramble and
               Andrew R. Conn and
               Horst Samulowitz and
               Alexander G. Gray},
  title     = {Automated Machine Learning via {ADMM}},
  journal   = {CoRR},
  volume    = {abs/1905.00424},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.00424},
  eprinttype = {arXiv},
  eprint    = {1905.00424},

}

@inproceedings{Lorraine2020_Optimizing,
  author    = {Jonathan Lorraine and
               Paul Vicol and
               David Duvenaud},
  title     = {Optimizing Millions of Hyperparameters by Implicit Differentiation},
  booktitle = {The 23rd International Conference on Artificial Intelligence and Statistics,
               {AISTATS} 2020, 26-28 August 2020, Online [Palermo, Sicily, Italy]},
  pages     = {1540--1552},
  year      = {2020},
}

@inproceedings{Luketina2016_Scalable,
  author    = {Jelena Luketina and
               Tapani Raiko and
               Mathias Berglund and
               Klaus Greff},
  title     = {Scalable Gradient-Based Tuning of Continuous Regularization Hyperparameters},
  booktitle = {Proceedings of the 33nd International Conference on Machine Learning,
               {ICML} 2016, New York City, NY, USA, June 19-24, 2016},
  pages     = {2952--2960},
  year      = {2016},
}

@inproceedings{Maclaurin2015_Gradient,
  author    = {Dougal Maclaurin and
               David Duvenaud and
               Ryan P. Adams},
  title     = {Gradient-based Hyperparameter Optimization through Reversible Learning},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning,
               {ICML} 2015, Lille, France, 6-11 July 2015},
  pages     = {2113--2122},
  year      = {2015},
}

@article{Martinez2014_BayesOpt,
  author    = {Ruben Martinez{-}Cantin},
  title     = {BayesOpt: a Bayesian optimization library for nonlinear optimization,
               experimental design and bandits},
  journal   = {J. Mach. Learn. Res.},
  volume    = {15},
  number    = {1},
  pages     = {3735--3739},
  year      = {2014},
}

@article{Metz2020_Thousand,
  author    = {Luke Metz and
               Niru Maheswaranathan and
               Ruoxi Sun and
               C. Daniel Freeman and
               Ben Poole and
               Jascha Sohl{-}Dickstein},
  title     = {Using a thousand optimization tasks to learn hyperparameter search
               strategies},
  journal   = {CoRR},
  volume    = {abs/2002.11887},
  year      = {2020},
  archivePrefix = {arXiv},
  eprint    = {2002.11887},
}

@article{Mohr2018_MLPlan,
  author    = {Felix Mohr and
               Marcel Wever and
               Eyke H{\"{u}}llermeier},
  title     = {ML-Plan: Automated machine learning via hierarchical planning},
  journal   = {Mach. Learn.},
  volume    = {107},
  number    = {8-10},
  pages     = {1495--1515},
  year      = {2018},
  url       = {https://doi.org/10.1007/s10994-018-5735-z},
  doi       = {10.1007/s10994-018-5735-z},
  timestamp = {Mon, 02 Mar 2020 16:29:52 +0100},
  biburl    = {https://dblp.org/rec/journals/ml/MohrWH18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Mohr2021_Naive,
  author    = {Felix Mohr and
               Marcel Wever},
  title     = {Naive Automated Machine Learning - {A} Late Baseline for AutoML},
  journal   = {CoRR},
  volume    = {abs/2103.10496},
  year      = {2021}
}


@inproceedings{Mutny2018_Efficient,
  author    = {Mojmir Mutny and
               Andreas Krause},
  title     = {Efficient High Dimensional Bayesian Optimization with Additivity and
               Quadrature Fourier Features},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, December
               3-8, 2018, Montr{\'{e}}al, Canada},
  pages     = {9019--9030},
  year      = {2018},
}

@misc{Nahstaedt2020_skopt,
    author = {Holger Nahstaedt and Tim Head},
    title = {{Scikit-optimize}},
    year = {2020},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/scikit-optimize/scikit-optimize}},
}

@article{Neiswanger2019_ProBo,
  author    = {Willie Neiswanger and
               Kirthevasan Kandasamy and
               Barnab{\'{a}}s P{\'{o}}czos and
               Jeff Schneider and
               Eric P. Xing},
  title     = {ProBO: a Framework for Using Probabilistic Programming in Bayesian
               Optimization},
  journal   = {CoRR},
  volume    = {abs/1901.11515},
  year      = {2019},

}
@inproceedings{Nomura2021_Warm,
  author    = {Masahiro Nomura and
               Shuhei Watanabe and
               Youhei Akimoto and
               Yoshihiko Ozaki and
               Masaki Onishi},
  title     = {Warm Starting {CMA-ES} for Hyperparameter Optimization},
  booktitle = {Thirty-Fifth {AAAI} Conference on Artificial Intelligence, {AAAI}
               2021, Thirty-Third Conference on Innovative Applications of Artificial
               Intelligence, {IAAI} 2021, The Eleventh Symposium on Educational Advances
               in Artificial Intelligence, {EAAI} 2021, Virtual Event, February 2-9,
               2021},
  pages     = {9188--9196},
  publisher = {{AAAI} Press},
  year      = {2021},

}

@article{Nogueira2014_BayesianOpt,
  title={Bayesian Optimization: Open source constrained global optimization tool for Python},
  author={Nogueira, Fernando},
  journal={URL https://github. com/fmfn/BayesianOptimization},
  year={2014},
}

@article{Nguyen2014_Using,
  title={Using meta-mining to support data mining workflow planning and optimization},
  author={Nguyen, Phong and Hilario, Melanie and Kalousis, Alexandros},
  journal={Journal of Artificial Intelligence Research},
  volume={51},
  pages={605--644},
  year={2014}
}

@inproceedings{Olson2019_TPOT,
  author    = {Randal S. Olson and
               Jason H. Moore},
  editor    = {Frank Hutter and
               Lars Kotthoff and
               Joaquin Vanschoren},
  title     = {{TPOT:} {A} Tree-based Pipeline Optimization Tool for Automating Machine
               Learning},
  booktitle = {Proceedings of the 2016 Workshop on Automatic Machine Learning, AutoML
               2016, co-located with 33rd International Conference on Machine Learning
               {(ICML} 2016), New York City, NY, USA, June 24, 2016},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {64},
  pages     = {66--74},
  publisher = {JMLR.org},
  year      = {2016},
  url       = {http://proceedings.mlr.press/v64/olson\_tpot\_2016.html},
}

@inproceedings{Paleyes2019_Emukit,
  author = {Paleyes, Andrei and Pullin, Mark and Mahsereci, Maren and Lawrence, Neil and González, Javier},
  title = {Emulation of physical processes with Emukit},
  booktitle = {Second Workshop on Machine Learning and the Physical Sciences, NeurIPS},
  year = {2019}
}

@inproceedings{Parker-Holder2020_Provable,
  author    = {Jack Parker{-}Holder and
               Vu Nguyen and
               Stephen J. Roberts},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Provably Efficient Online Hyperparameter Optimization with Population-Based
               Bandits},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020},
  url       = {https://proceedings.neurips.cc/paper/2020/hash/c7af0926b294e47e52e46cfebe173f20-Abstract.html},
}

@inproceedings{Payrosangari2020_Meta,
  author    = {Samin Payrosangari and
               Afshin Sadeghi and
               Damien Graux and
               Jens Lehmann},
  title     = {Meta-hyperband: Hyperparameter Optimization with Meta-learning and
               Coarse-to-Fine},
  booktitle = {Intelligent Data Engineering and Automated Learning - {IDEAL} 2020
               - 21st International Conference, Guimaraes, Portugal, November 4-6,
               2020, Proceedings, Part {II}},
  pages     = {335--347},
  year      = {2020},
  doi       = {10.1007/978-3-030-62365-4\_32},
}

@inproceedings{Pedregosa2016_Hyperparameter,
  author    = {Fabian Pedregosa},
  title     = {Hyperparameter optimization with approximate gradient},
  booktitle = {Proceedings of the 33nd International Conference on Machine Learning,
               {ICML} 2016, New York City, NY, USA, June 19-24, 2016},
  pages     = {737--746},
  year      = {2016},
}

@inproceedings{Perrone2018_Scalable,
  author    = {Valerio Perrone and
               Rodolphe Jenatton and
               Matthias W. Seeger and
               C{\'{e}}dric Archambeau},
  title     = {Scalable Hyperparameter Transfer Learning},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, December
               3-8, 2018, Montr{\'{e}}al, Canada},
  pages     = {6846--6856},
  year      = {2018},
}

@inproceedings{Perrone2019_Learning,
  author    = {Valerio Perrone and
               Huibin Shen},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Learning search spaces for Bayesian optimization: Another view of
               hyperparameter transfer learning},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {12751--12761},
  year      = {2019},
}

@inproceedings{Petrak2000_Fast,
  author    = {Johann Petrak},
  title     = {Fast Subsampling Performance Estimates for Classification Algorithm Selection},
  booktitle = {Proceedings of the {ECML} 2000 Workshop on Meta-Learning, Barcelona, Catalonia, Spain, May 31 - June 2, 2000},
  pages     = {3--14},
  year      = {2000},
}

@misc{Pineda2021_HPOB,
      title={HPO-B: A Large-Scale Reproducible Benchmark for Black-Box HPO based on OpenML}, 
      author={Sebastian Pineda Arango and Hadi S. Jomaa and Martin Wistuba and Josif Grabocka},
      year={2021},
      eprint={2106.06257},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@inproceedings{Rakotoarison2019_Automated,
  author    = {Herilalaina Rakotoarison and
               Marc Schoenauer and
               Mich{\`{e}}le Sebag},
  editor    = {Sarit Kraus},
  title     = {Automated Machine Learning with Monte-Carlo Tree Search},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, {IJCAI} 2019, Macao, China, August 10-16,
               2019},
  pages     = {3296--3303},
  publisher = {ijcai.org},
  year      = {2019},
  url       = {https://doi.org/10.24963/ijcai.2019/457}
}

@misc{Rapin2018_Nevergrad,
    author = {J. Rapin and O. Teytaud},
    title = {{Nevergrad - A gradient-free optimization platform}},
    year = {2018},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://GitHub.com/FacebookResearch/Nevergrad}},
}



@article{Shawi2019_Automated,
  author    = {Radwa El Shawi and
               Mohamed Maher and
               Sherif Sakr},
  title     = {Automated Machine Learning: State-of-The-Art and Open Challenges},
  journal   = {CoRR},
  volume    = {abs/1906.02287},
  year      = {2019},
  archivePrefix = {arXiv},
  eprint    = {1906.02287},
}
@inproceedings{Salinas2020_Quantile,
  author    = {David Salinas and
               Huibin Shen and
               Valerio Perrone},
  title     = {A Quantile-based Approach for Hyperparameter Transfer Learning},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning,
               {ICML} 2020, 13-18 July 2020, Virtual Event},
  pages     = {8438--8448},
  year      = {2020},
}

@inproceedings{SchillingJoint15,
  author    = {Nicolas Schilling and
               Martin Wistuba and
               Lucas Drumond and
               Lars Schmidt{-}Thieme},
  title     = {Joint Model Choice and Hyperparameter Optimization with Factorized
               Multilayer Perceptrons},
  booktitle = {27th {IEEE} International Conference on Tools with Artificial Intelligence,
               {ICTAI} 2015, Vietri sul Mare, Italy, November 9-11, 2015},
  pages     = {72--79},
  publisher = {{IEEE} Computer Society},
  year      = {2015},
  url       = {https://doi.org/10.1109/ICTAI.2015.24},
}


@article{Shi2019_Multi,
  author    = {Han Shi and
               Renjie Pi and
               Hang Xu and
               Zhenguo Li and
               James T. Kwok and
               Tong Zhang},
  title     = {Multi-objective Neural Architecture Search via Predictive Network
               Performance Optimization},
  journal   = {CoRR},
  volume    = {abs/1911.09336},
  year      = {2019},
  archivePrefix = {arXiv},
  eprint    = {1911.09336},
}

@inproceedings{NIPS2016_a96d3afe,
 author = {Springenberg, Jost Tobias and Klein, Aaron and Falkner, Stefan and Hutter, Frank},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Bayesian Optimization with Robust Bayesian Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2016/file/a96d3afec184766bfeca7a9f989fc7e7-Paper.pdf},
 volume = {29},
 year = {2016}
}

@inproceedings{10.1145/3397271.3401333,
author = {Zhuang, Honglei and Wang, Xuanhui and Bendersky, Michael and Najork, Marc},
title = {Feature Transformation for Neural Ranking Models},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401333},
doi = {10.1145/3397271.3401333},
abstract = {Although neural network models enjoy tremendous advantages in handling image and text data, tree-based models still remain competitive for learning-to-rank tasks with numerical data. A major strength of tree-based ranking models is the insensitivity to different feature scales, while neural ranking models may suffer from features with varying scales or skewed distributions. Feature transformation or normalization is a simple technique which preprocesses input features to mitigate their potential adverse impact on neural models. However, due to lack of studies, it is unclear to what extent feature transformation can benefit neural ranking models. In this paper, we aim to answer this question by providing empirical evidence for learning-to-rank tasks. First, we present a list of commonly used feature transformation techniques and perform a comparative study on multiple learning-to-rank data sets. Then we propose a mixture feature transformation mechanism which can automatically derive a mixture of basic feature transformation functions to achieve the optimal performance. Our experiments show that applying feature transformation can substantially improve the performance of neural ranking models compared to directly using the raw features. In addition, the proposed mixture transformation method can further improve the performance of the ranking model without any additional human effort.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1649–1652},
numpages = {4},
keywords = {feature transformation, learning-to-rank, neural ranking model},
location = {Virtual Event, China},
series = {SIGIR '20}
}

@inproceedings{10.1145/3209978.3209985,
author = {Ai, Qingyao and Bi, Keping and Guo, Jiafeng and Croft, W. Bruce},
title = {Learning a Deep Listwise Context Model for Ranking Refinement},
year = {2018},
isbn = {9781450356572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209978.3209985},
doi = {10.1145/3209978.3209985},
abstract = {Learning to rank has been intensively studied and widely applied in information retrieval. Typically, a global ranking function is learned from a set of labeled data, which can achieve good performance on average but may be suboptimal for individual queries by ignoring the fact that relevant documents for different queries may have different distributions in the feature space. Inspired by the idea of pseudo relevance feedback where top ranked documents, which we refer as the local ranking context, can provide important information about the query's characteristics, we propose to use the inherent feature distributions of the top results to learn a Deep Listwise Context Model that helps us fine tune the initial ranked list. Specifically, we employ a recurrent neural network to sequentially encode the top results using their feature vectors, learn a local context model and use it to re-rank the top results. There are three merits with our model: (1) Our model can capture the local ranking context based on the complex interactions between top results using a deep neural network; (2) Our model can be built upon existing learning-to-rank methods by directly using their extracted feature vectors; (3) Our model is trained with an attention-based loss function, which is more effective and efficient than many existing listwise methods. Experimental results show that the proposed model can significantly improve the state-of-the-art learning to rank methods on benchmark retrieval corpora.},
booktitle = {The 41st International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {135–144},
numpages = {10},
keywords = {learning to rank, local ranking context, deep neural network},
location = {Ann Arbor, MI, USA},
series = {SIGIR '18}
}

@inproceedings{wu2018turning,
  title={Turning clicks into purchases: Revenue optimization for product search in e-commerce},
  author={Wu, Liang and Hu, Diane and Hong, Liangjie and Liu, Huan},
  booktitle={The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval},
  pages={365--374},
  year={2018}
}
@inproceedings{10.1145/3219819.3220021,
author = {Tang, Jiaxi and Wang, Ke},
title = {Ranking Distillation: Learning Compact Ranking Models With High Performance for Recommender System},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3220021},
doi = {10.1145/3219819.3220021},
abstract = {We propose a novel way to train ranking models, such as recommender systems, that are both effective and efficient. Knowledge distillation (KD) was shown to be successful in image recognition to achieve both effectiveness and efficiency. We propose a KD technique for learning to rank problems, called ranking distillation (RD). Specifically, we train a smaller student model to learn to rank documents/items from both the training data and the supervision of a larger teacher model. The student model achieves a similar ranking performance to that of the large teacher model, but its smaller model size makes the online inference more efficient. RD is flexible because it is orthogonal to the choices of ranking models for the teacher and student. We address the challenges of RD for ranking problems. The experiments on public data sets and state-of-the-art recommendation models showed that RD achieves its design purposes: the student model learnt with RD has less than an half size of the teacher model while achieving a ranking performance similar tothe teacher model and much better than the student model learnt without RD.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {2289–2298},
numpages = {10},
keywords = {recommender system, learning to rank, knowledge transfer, model compression},
location = {London, United Kingdom},
series = {KDD '18}
}

@article{10.5555/1248547.1248548,
author = {Dem\v{s}ar, Janez},
title = {Statistical Comparisons of Classifiers over Multiple Data Sets},
year = {2006},
issue_date = {12/1/2006},
publisher = {JMLR.org},
volume = {7},
issn = {1532-4435},
abstract = {While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams.},
journal = {J. Mach. Learn. Res.},
month = {dec},
pages = {1–30},
numpages = {30}
}

@article{wang2021pre,
  title={Pre-trained Gaussian processes for Bayesian optimization},
  author={Wang, Zi and Dahl, George E and Swersky, Kevin and Lee, Chansoo and Mariet, Zelda and Nado, Zachary and Gilmer, Justin and Snoek, Jasper and Ghahramani, Zoubin},
  journal={arXiv preprint arXiv:2109.08215},
  year={2021}
}


@inproceedings{10.1145/3404835.3462969,
author = {Feng, Fuli and Li, Moxin and Luo, Cheng and Ng, Ritchie and Chua, Tat-Seng},
title = {Hybrid Learning to Rank for Financial Event Ranking},
year = {2021},
isbn = {9781450380379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404835.3462969},
doi = {10.1145/3404835.3462969},
abstract = {The financial markets are moved by events such as the issuance of administrative orders. The participants in financial markets (e.g., traders) thus pay constant attention to financial news relevant to the financial asset (e.g., oil) of interest. Due to the large scale of news stream, it is time and labor intensive to manually identify influential events that can move the price of the financial asset, pushing the financial participants to embrace automatic financial event ranking, which has received relatively little scrutiny to date. In this work, we formulate the financial event ranking task, which aims to score financial news (document) according to its influence to the given asset (query). To solve this task, we propose a Hybrid News Ranking framework that, from the asset perspective, evaluates the influence of news articles by comparing their contents; and from the event perspective, accesses the influence over all query assets. Moreover, we resolve the dilemma between the essential requirement of sufficient labels for training the framework and the unaffordable cost of hiring domain experts for labeling the news. In particular, we design a cost-friendly system for news labeling that leverages the knowledge within published financial analyst reports. In this way, we construct three financial event ranking datasets. Extensive experiments on the datasets validate the effectiveness of the proposed framework and the rationality of solving financial event ranking through learning to rank.},
booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {233–243},
numpages = {11},
keywords = {finance, learning to rank, document retrieval},
location = {Virtual Event, Canada},
series = {SIGIR '21}
}

@InProceedings{Cakir_2019_CVPR,
author = {Cakir, Fatih and He, Kun and Xia, Xide and Kulis, Brian and Sclaroff, Stan},
title = {Deep Metric Learning to Rank},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}


@inproceedings{Snoek2012_Practical,
  author    = {Jasper Snoek and
               Hugo Larochelle and
               Ryan P. Adams},
  title     = {Practical Bayesian Optimization of Machine Learning Algorithms},
  booktitle = {Advances in Neural Information Processing Systems 25: 26th Annual
               Conference on Neural Information Processing Systems 2012. Proceedings
               of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States},
  pages     = {2960--2968},
  year      = {2012},
}
@inproceedings{Snoek2015_DNGO,
  author    = {Jasper Snoek and
               Oren Rippel and
               Kevin Swersky and
               Ryan Kiros and
               Nadathur Satish and
               Narayanan Sundaram and
               Md. Mostofa Ali Patwary and
               Prabhat and
               Ryan P. Adams},
  title     = {Scalable Bayesian Optimization Using Deep Neural Networks},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning,
               {ICML} 2015, Lille, France, 6-11 July 2015},
  pages     = {2171--2180},
  year      = {2015},
}



@InProceedings{pmlr-v51-wilson16,
  title = 	 {Deep Kernel Learning},
  author = 	 {Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P.},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {370--378},
  year = 	 {2016},
  editor = 	 {Gretton, Arthur and Robert, Christian C.},
  volume = 	 {51},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Cadiz, Spain},
  month = 	 {09--11 May},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v51/wilson16.pdf},
  url = 	 {https://proceedings.mlr.press/v51/wilson16.html}
}


@inproceedings{awad-ijcai21,
  author    = {N. Awad and N. Mallik and F. Hutter},
  title     = {{DEHB}: Evolutionary Hyberband for Scalable, Robust and Efficient Hyperparameter Optimization},
  pages     = {2147--2153},
  booktitle = {Proceedings of the Thirtieth International Joint Conference on
               Artificial Intelligence, {IJCAI-21}},
  publisher = {ijcai.org},
  editor    = {Z. Zhou},
  year      = {2021}
}

@inbook{10.5555/3454287.3455167,
author = {Wu, Jian and Frazier, Peter I.},
title = {Practical Two-Step Look-Ahead Bayesian Optimization},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {880},
numpages = {11}
}

@misc{Snoek2015_Spearmint,
    author = {Jasper Snoek and Jakob Stevenson and Kyunghyun Cho},
    title = {{Spearmint}},
    year = {2016},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/HIPS/Spearmint}},
}

@inproceedings{Springenberg2016_BOHAMIANN,
  author    = {Jost Tobias Springenberg and
               Aaron Klein and
               Stefan Falkner and
               Frank Hutter},
  title     = {Bayesian Optimization with Robust Bayesian Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems 29: Annual Conference
               on Neural Information Processing Systems 2016, December 5-10, 2016,
               Barcelona, Spain},
  pages     = {4134--4142},
  year      = {2016},
}


@inproceedings{Swearingen2017_ATM,
  author    = {Thomas Swearingen and
               Will Drevo and
               Bennett Cyphers and
               Alfredo Cuesta{-}Infante and
               Arun Ross and
               Kalyan Veeramachaneni},
  title     = {{ATM:} {A} distributed, collaborative, scalable system for automated
               machine learning},
  booktitle = {2017 {IEEE} International Conference on Big Data {(IEEE} BigData 2017),
               Boston, MA, USA, December 11-14, 2017},
  pages     = {151--162},
  publisher = {{IEEE} Computer Society},
  year      = {2017},
  url       = {https://doi.org/10.1109/BigData.2017.8257923},
  doi       = {10.1109/BigData.2017.8257923},
}



@inproceedings{Swersky2013_Multi,
  author    = {Kevin Swersky and
               Jasper Snoek and
               Ryan Prescott Adams},
  title     = {Multi-Task Bayesian Optimization},
  booktitle = {Advances in Neural Information Processing Systems 26: 27th Annual
               Conference on Neural Information Processing Systems 2013. Proceedings
               of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States},
  pages     = {2004--2012},
  year      = {2013},
}



@article{Swersky2014_Freeze,
  author    = {Kevin Swersky and
               Jasper Snoek and
               Ryan Prescott Adams},
  title     = {Freeze-Thaw Bayesian Optimization},
  journal   = {CoRR},
  volume    = {abs/1406.3896},
  year      = {2014},
  archivePrefix = {arXiv},
  eprint    = {1406.3896},
}

@inproceedings{sun2019_reinbo,
  author    = {Xudong Sun and
               Jiali Lin and
               Bernd Bischl},
  editor    = {Peggy Cellier and
               Kurt Driessens},
  title     = {ReinBo: Machine Learning Pipeline Conditional Hierarchy Search and
               Configuration with Bayesian Optimization Embedded Reinforcement Learning},
  booktitle = {Machine Learning and Knowledge Discovery in Databases - International
               Workshops of {ECML} {PKDD} 2019, W{\"{u}}rzburg, Germany, September
               16-20, 2019, Proceedings, Part {I}},
  series    = {Communications in Computer and Information Science},
  volume    = {1167},
  pages     = {68--84},
  publisher = {Springer},
  year      = {2019},
  url       = {https://doi.org/10.1007/978-3-030-43823-4\_7}}


@article{Thornton2012_AutoWeka,
  author    = {Chris Thornton and
               Frank Hutter and
               Holger H. Hoos and
               Kevin Leyton{-}Brown},
  title     = {Auto-WEKA: Automated Selection and Hyper-Parameter Optimization of
               Classification Algorithms},
  journal   = {CoRR},
  volume    = {abs/1208.3719},
  year      = {2012},
  archivePrefix = {arXiv},
  eprint    = {1208.3719},
}


@misc{Valkov2018_A,
  author       = {Lazar Valkov and
                  Rodolphe Jenatton,
                  Fela Winkelmolen,
                  C{\'{e}}dric Archambeau},
  title        = {A simple transfer-learning extension of Hyperband},
  howpublished = {\url{http://metalearning.ml/2018/}},
  month        = {},
  year         = {2018},
}

@inproceedings{Volpp2020_Metabo,
  author    = {Michael Volpp and
               Lukas P. Fr{\"{o}}hlich and
               Kirsten Fischer and
               Andreas Doerr and
               Stefan Falkner and
               Frank Hutter and
               Christian Daniel},
  title     = {Meta-Learning Acquisition Functions for Transfer Learning in Bayesian
               Optimization},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  year      = {2020},
}

@inproceedings{Wilson2018_Maximizing,
  author    = {James T. Wilson and
               Frank Hutter and
               Marc Peter Deisenroth},
  title     = {Maximizing acquisition functions for Bayesian optimization},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, December
               3-8, 2018, Montr{\'{e}}al, Canada},
  pages     = {9906--9917},
  year      = {2018},
}

@inproceedings{White2021_BANANAS,
  author    = {Colin White and
               Willie Neiswanger and
               Yash Savani},
  title     = {{BANANAS:} Bayesian Optimization with Neural Architectures for Neural
               Architecture Search},
  booktitle = {Thirty-Fifth {AAAI} Conference on Artificial Intelligence, {AAAI}
               2021, Thirty-Third Conference on Innovative Applications of Artificial
               Intelligence, {IAAI} 2021, The Eleventh Symposium on Educational Advances
               in Artificial Intelligence, {EAAI} 2021, Virtual Event, February 2-9,
               2021},
  pages     = {10293--10301},
  year      = {2021},
}

@inproceedings{Wistuba2015_Learning,
  author    = {Martin Wistuba and
               Nicolas Schilling and
               Lars Schmidt{-}Thieme},
  title     = {Learning hyperparameter optimization initializations},
  booktitle = {2015 {IEEE} International Conference on Data Science and Advanced
               Analytics, {DSAA} 2015, Campus des Cordeliers, Paris, France, October
               19-21, 2015},
  pages     = {1--10},
  year      = {2015},
  doi       = {10.1109/DSAA.2015.7344817},
}

@inproceedings{Wistuba2016_Twostage,
  author    = {Martin Wistuba and
               Nicolas Schilling and
               Lars Schmidt{-}Thieme},
  editor    = {Paolo Frasconi and
               Niels Landwehr and
               Giuseppe Manco and
               Jilles Vreeken},
  title     = {Two-Stage Transfer Surrogate Model for Automatic Hyperparameter Optimization},
  booktitle = {Machine Learning and Knowledge Discovery in Databases - European Conference,
               {ECML} {PKDD} 2016, Riva del Garda, Italy, September 19-23, 2016,
               Proceedings, Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {9851},
  pages     = {199--214},
  publisher = {Springer},
  year      = {2016},

}

@article{Wistuba2018_Scalable,
  author    = {Martin Wistuba and
               Nicolas Schilling and
               Lars Schmidt{-}Thieme},
  title     = {Scalable Gaussian process-based transfer surrogates for hyperparameter
               optimization},
  journal   = {Mach. Learn.},
  volume    = {107},
  number    = {1},
  pages     = {43--78},
  year      = {2018},
}

@article{Wistuba2019_A,
  author    = {Martin Wistuba and
               Ambrish Rawat and
               Tejaswini Pedapati},
  title     = {A Survey on Neural Architecture Search},
  journal   = {CoRR},
  volume    = {abs/1905.01392},
  year      = {2019},
  archivePrefix = {arXiv},
  eprint    = {1905.01392},
}

@inproceedings{burges2005learning,
  title={Learning to rank using gradient descent},
  author={Burges, Chris and Shaked, Tal and Renshaw, Erin and Lazier, Ari and Deeds, Matt and Hamilton, Nicole and Hullender, Greg},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={89--96},
  year={2005}
}

@inproceedings{Wistuba2020_Learning,
  author    = {Martin Wistuba and
               Tejaswini Pedapati},
  title     = {Learning to Rank Learning Curves},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning,
               {ICML} 2020, 13-18 July 2020, Virtual Event},
  pages     = {10303--10312},
  year      = {2020},
}

@inproceedings{Wistuba2021_FSBO,
  author    = {Martin Wistuba and
               Josif Grabocka},
  title     = {Few-Shot Bayesian Optimization with Deep Kernel Surrogates},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  year      = {2021},
}

@inproceedings{Wu2017_CornellMOE,
  author    = {Jian Wu and
               Matthias Poloczek and
               Andrew Gordon Wilson and
               Peter I. Frazier},
 
  title     = {Bayesian Optimization with Gradients},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
               on Neural Information Processing Systems 2017, December 4-9, 2017,
               Long Beach, CA, {USA}},
  pages     = {5267--5278},
  year      = {2017},

}

@inproceedings{Wu2021_Frugal,
  author    = {Qingyun Wu and
               Chi Wang and
               Silu Huang},
  title     = {Frugal Optimization for Cost-related Hyperparameters},
  booktitle = {Thirty-Fifth {AAAI} Conference on Artificial Intelligence, {AAAI}
               2021, Thirty-Third Conference on Innovative Applications of Artificial
               Intelligence, {IAAI} 2021, The Eleventh Symposium on Educational Advances
               in Artificial Intelligence, {EAAI} 2021, Virtual Event, February 2-9,
               2021},
  pages     = {10347--10354},
  year      = {2021},
}
@inproceedings{
Wang2021_Economic,
title={{ECONOMIC} {HYPERPARAMETER} {OPTIMIZATION} {WITH} {BLENDED} {SEARCH} {STRATEGY}},
author={Chi Wang and Qingyun Wu and Silu Huang and Amin Saied},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=VbLH04pRA3}
}
@article{Yang2020_On,
  author    = {Li Yang and
               Abdallah Shami},
  title     = {On hyperparameter optimization of machine learning algorithms: Theory
               and practice},
  journal   = {Neurocomputing},
  volume    = {415},
  pages     = {295--316},
  year      = {2020},
  doi       = {10.1016/j.neucom.2020.07.061},
}

@inproceedings{Wei2021_Meta,
  title={Meta-learning Hyperparameter Performance Prediction with Neural Processes},
  author={Wei, Ying and Zhao, Peilin and Huang, Junzhou},
  booktitle={International Conference on Machine Learning},
  pages={11058--11067},
  year={2021},
  organization={PMLR}
}

@inproceedings{Yang2019_Oboe,
  author    = {Chengrun Yang and
               Yuji Akimoto and
               Dae Won Kim and
               Madeleine Udell},
  editor    = {Ankur Teredesai and
               Vipin Kumar and
               Ying Li and
               R{\'{o}}mer Rosales and
               Evimaria Terzi and
               George Karypis},
  title     = {{OBOE:} Collaborative Filtering for AutoML Model Selection},
  booktitle = {Proceedings of the 25th {ACM} {SIGKDD} International Conference on
               Knowledge Discovery {\&} Data Mining, {KDD} 2019, Anchorage, AK,
               USA, August 4-8, 2019},
  pages     = {1173--1183},
  publisher = {{ACM}},
  year      = {2019},
  url       = {https://doi.org/10.1145/3292500.3330909}
}

@inproceedings{Yang2020_AutoML,
  author    = {Chengrun Yang and
               Jicong Fan and
               Ziyang Wu and
               Madeleine Udell},
  editor    = {Rajesh Gupta and
               Yan Liu and
               Jiliang Tang and
               B. Aditya Prakash},
  title     = {AutoML Pipeline Selection: Efficiently Navigating the Combinatorial
               Space},
  booktitle = {{KDD} '20: The 26th {ACM} {SIGKDD} Conference on Knowledge Discovery
               and Data Mining, Virtual Event, CA, USA, August 23-27, 2020},
  pages     = {1446--1456},
  publisher = {{ACM}},
  year      = {2020},
  url       = {https://doi.org/10.1145/3394486.3403197},
}



@article{Yao2018_Taking,
  author    = {Quanming Yao and
               Mengshuo Wang and
               Hugo Jair Escalante and
               Isabelle Guyon and
               Yi{-}Qi Hu and
               Yu{-}Feng Li and
               Wei{-}Wei Tu and
               Qiang Yang and
               Yang Yu},
  title     = {Taking Human out of Learning Applications: {A} Survey on Automated
               Machine Learning},
  journal   = {CoRR},
  volume    = {abs/1810.13306},
  year      = {2018},
  archivePrefix = {arXiv},
  eprint    = {1810.13306},
}

@inproceedings{Yogatama2014_Efficient,
  author    = {Dani Yogatama and
               Gideon Mann},
  title     = {Efficient Transfer Learning Method for Automatic Hyperparameter Tuning},
  booktitle = {Proceedings of the Seventeenth International Conference on Artificial
               Intelligence and Statistics, {AISTATS} 2014, Reykjavik, Iceland, April
               22-25, 2014},
  pages     = {1077--1085},
  year      = {2014},
}

@article{Zimmer2020_Autopytorch,
  author    = {Lucas Zimmer and
               Marius Lindauer and
               Frank Hutter},
  title     = {Auto-PyTorch Tabular: Multi-Fidelity MetaLearning for Efficient and
               Robust AutoDL},
  journal   = {CoRR},
  volume    = {abs/2006.13799},
  year      = {2020},
  archivePrefix = {arXiv},
  eprint    = {2006.13799},
}

@article{Zoller2021_Benchmark,
  author    = {Marc{-}Andr{\'{e}} Z{\"{o}}ller and
               Marco F. Huber},
  title     = {Benchmark and Survey of Automated Machine Learning Frameworks},
  journal   = {J. Artif. Intell. Res.},
  volume    = {70},
  pages     = {409--472},
  year      = {2021},
  doi       = {10.1613/jair.1.11854},
}

@article{Zoller2021_Incremental,
  author    = {Marc{-}Andr{\'{e}} Z{\"{o}}ller and
               Tien{-}Dung Nguyen and
               Marco F. Huber},
  title     = {Incremental Search Space Construction for Machine Learning Pipeline
               Synthesis},
  journal   = {CoRR},
  volume    = {abs/2101.10951},
  year      = {2021},
  url       = {https://arxiv.org/abs/2101.10951},
  eprinttype = {arXiv},
  eprint    = {2101.10951},
}

@article{Im2021_Online,
  author    = {Daniel Jiwoong Im and
               Cristina Savin and
               Kyunghyun Cho},
  title     = {Online hyperparameter optimization by real-time recurrent learning},
  journal   = {CoRR},
  volume    = {abs/2102.07813},
  year      = {2021},
  eprinttype = {arXiv},
  eprint    = {2102.07813},
}


@inproceedings{Havasi2021_Training,
  author    = {Marton Havasi and
               Rodolphe Jenatton and
               Stanislav Fort and
               Jeremiah Zhe Liu and
               Jasper Snoek and
               Balaji Lakshminarayanan and
               Andrew Mingbo Dai and
               Dustin Tran},
  title     = {Training independent subnetworks for robust prediction},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=OGg9XnKxFAH},
  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/HavasiJFLSLDT21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{jomaa2021transfer,
  title={Transfer Learning for Bayesian HPO with End-to-End Landmark Meta-Features},
  author={Jomaa, Hadi Samer and Arango, Sebastian Pineda and Schmidt-Thieme, Lars and Grabocka, Josif},
  booktitle={Fifth Workshop on Meta-Learning at the Conference on Neural Information Processing Systems},
  year={2021}
}

@article{Wang2021_Automatic,
  author    = {Zi Wang and
               George E. Dahl and
               Kevin Swersky and
               Chansoo Lee and
               Zelda Mariet and
               Zachary Nado and
               Justin Gilmer and
               Jasper Snoek and
               Zoubin Ghahramani},
  title     = {Automatic prior selection for meta Bayesian optimization with a case
               study on tuning deep neural network optimizers},
  journal   = {CoRR},
  volume    = {abs/2109.08215},
  year      = {2021},
  url       = {https://arxiv.org/abs/2109.08215},
  eprinttype = {arXiv},
  eprint    = {2109.08215}
}

@article{Wei2019_Transferable,
  author    = {Ying Wei and
               Peilin Zhao and
               Huaxiu Yao and
               Junzhou Huang},
  title     = {Transferable Neural Processes for Hyperparameter Optimization},
  journal   = {CoRR},
  volume    = {abs/1909.03209},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.03209},
  eprinttype = {arXiv},
  eprint    = {1909.03209}
}


@inproceedings{Cao07_Learning,
  author    = {Zhe Cao and
               Tao Qin and
               Tie{-}Yan Liu and
               Ming{-}Feng Tsai and
               Hang Li},
  editor    = {Zoubin Ghahramani},
  title     = {Learning to rank: from pairwise approach to listwise approach},
  booktitle = {Machine Learning, Proceedings of the Twenty-Fourth International Conference
               {(ICML} 2007), Corvallis, Oregon, USA, June 20-24, 2007},
  series    = {{ACM} International Conference Proceeding Series},
  volume    = {227},
  pages     = {129--136},
  publisher = {{ACM}},
  year      = {2007},
  url       = {https://doi.org/10.1145/1273496.1273513}
}


@inproceedings{Xia2008_Listwise,
  author    = {Fen Xia and
               Tie{-}Yan Liu and
               Jue Wang and
               Wensheng Zhang and
               Hang Li},
  editor    = {William W. Cohen and
               Andrew McCallum and
               Sam T. Roweis},
  title     = {Listwise approach to learning to rank: theory and algorithm},
  booktitle = {Machine Learning, Proceedings of the Twenty-Fifth International Conference
               {(ICML} 2008), Helsinki, Finland, June 5-9, 2008},
  series    = {{ACM} International Conference Proceeding Series},
  volume    = {307},
  pages     = {1192--1199},
  publisher = {{ACM}},
  year      = {2008},
  url       = {https://doi.org/10.1145/1390156.1390306},
  doi       = {10.1145/1390156.1390306},
  timestamp = {Tue, 06 Nov 2018 16:58:28 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/XiaLWZL08.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{chen2017top,
  title={Top-Rank Enhanced Listwise Optimization for Statistical Machine Translation},
  author={Chen, Huadong and Huang, Shujian and Chiang, David and Dai, Xinyu and Chen, Jiajun},
  journal={arXiv preprint arXiv:1707.05438},
  year={2017}
}

@InProceedings{wilson-icai16a,
  title = 	 {Deep Kernel Learning},
  author = 	 {Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P.},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {370--378},
  year = 	 {2016},
  editor = 	 {Gretton, Arthur and Robert, Christian C.},
  volume = 	 {51},
  series = 	 {Proceedings of Machine Learning Research},
 
}

@inproceedings{ozturk-zero2022,
  author    = {Ekrem {\"{O}}zt{\"{u}}rk and
               Fabio Ferreira and
               Hadi S. Jomaa and
               Lars Schmidt{-}Thieme and
               Josif Grabocka and
               Frank Hutter},
  editor    = {Kamalika Chaudhuri and
               Stefanie Jegelka and
               Le Song and
               Csaba Szepesv{\'{a}}ri and
               Gang Niu and
               Sivan Sabato},
  title     = {Zero-shot AutoML with Pretrained Models},
  booktitle = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
               2022, Baltimore, Maryland, {USA}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {162},
  pages     = {17138--17155},
  publisher = {{PMLR}},
  year      = {2022},
  url       = {https://proceedings.mlr.press/v162/ozturk22a.html},
  timestamp = {Tue, 12 Jul 2022 17:36:52 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/OzturkFJSGH22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{jomaa-hyperrl2019,
  author    = {Hadi S. Jomaa and
               Josif Grabocka and
               Lars Schmidt{-}Thieme},
  title     = {Hyp-RL : Hyperparameter Optimization by Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1906.11527},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.11527},
  eprinttype = {arXiv},
  eprint    = {1906.11527},
  timestamp = {Mon, 01 Jul 2019 13:00:07 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-11527.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{pineda-hpob2021,
 author = {Pineda Arango, Sebastian and Jomaa, Hadi and Wistuba, Martin and Grabocka, Josif},
 booktitle = {Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks},
 editor = {J. Vanschoren and S. Yeung},
 pages = {},
 title = {HPO-B: A Large-Scale Reproducible Benchmark for Black-Box HPO based on OpenML },
 url = {https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/ec8956637a99787bd197eacd77acce5e-Paper-round2.pdf},
 volume = {1},
 year = {2021}
}


@inproceedings{wei_ranking2009,
 author = {Chen, Wei and Liu, Tie-yan and Lan, Yanyan and Ma, Zhi-ming and Li, Hang},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. Williams and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Ranking Measures and Loss Functions in Learning to Rank},
 url = {https://proceedings.neurips.cc/paper/2009/file/2f55707d4193dc27118a0f19a1985716-Paper.pdf},
 volume = {22},
 year = {2009}
}

