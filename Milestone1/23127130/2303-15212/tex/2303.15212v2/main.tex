
\documentclass{article} % For LaTeX2e
\usepackage{iclr2023_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage{url}
\usepackage[titlenumbered,ruled,linesnumbered, vlined]{algorithm2e}
\usepackage{bbm}

\usepackage{booktabs}
%\title{Deep Ranker Ensembles\\ for Hyperparameter Optimization}
\title{Deep Ranking Ensembles \\ for Hyperparameter Optimization}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Abdus Salam Khazi\thanks{Equal contribution}\ , Sebastian Pineda Arango\footnotemark[1]\ , Josif Grabocka  \\
University of Freiburg\\
Correspondence to Sebastian Pineda Arango: \texttt{pineda@cs.uni-freiburg.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\usepackage{selectp}
%\outputonly{14-17}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Automatically optimizing the hyperparameters of Machine Learning algorithms is one of the primary open questions in AI. Existing work in Hyperparameter Optimization (HPO) trains surrogate models for approximating the response surface of hyperparameters as a regression task. In contrast, we hypothesize that the optimal strategy for training surrogates is to preserve the ranks of the performances of hyperparameter configurations as a Learning to Rank problem. As a result, we present a novel method that meta-learns neural network surrogates optimized for ranking the configurations' performances while modeling their uncertainty via ensembling. In a large-scale experimental protocol comprising 12 baselines, 16 HPO search spaces and 86 datasets/tasks, we demonstrate that our method achieves new state-of-the-art results in HPO.
%Machine Learning Algorithms are omnipresent in todays applications. Thus, optimizing their hyperparameters automatically is very relevant. Recent work has shown that bayesian optimization is a powerful tool to perform this task. On the other hand, Deep Ensembles are becoming an efficient method for computing uncertainties and improving predictive performance in diverse Machine Learning tasks. However, few methods have explored how to effectively use Deep Ensembles for hyperparameter optimization. In this work, we introduce Deep Ranker Ensembles, a powerful ensemble of Neural Networks for HPO that applies transfer learning and learning-to-rank. We show through large experiments and extensive ablations that Deep Ensembles can be effective methods for tuning ML algorithms and achieve state-the-art performance.
\end{abstract}

\input{sections/introduction}
\input{sections/related_work}
\input{sections/method}
\input{sections/experiments}
%\input{sections/results}
\input{sections/conclusion}


\bibliography{iclr2023_conference}
\bibliographystyle{iclr2023_conference}

\appendix
\input{sections/appendix}
\end{document}
