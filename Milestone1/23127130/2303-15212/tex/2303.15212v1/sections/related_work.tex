\section{Related Work}

\textbf{Hyperparameter Optimization (HPO)} is a problem that has been well elaborated on during the last decade. The mainstream HPO strategies are Reinforcement Learning (RL)~\citep{10.5555/3454287.3455167}, evolutionary search~\citep{Awad2021_DEHB}, and Bayesian optimization (BO)~\citep{Hutter2019_Automated}. The latter comprises two main components: a surrogate function that approximates the response function given some observations, and an acquisition function that leverages the probabilistic output of the surrogate to explore the search space, ultimately deciding which point to observe next. Previous work covers various choices for the surrogate model family, including Gaussian Processes~\citep{Snoek2012_Practical}, and Bayesian Neural Networks~\citep{NIPS2016_a96d3afe}. Other authors report the advantages of using ensembles as a surrogate, such as Random Forests~\cite{Hutter2011_Sequential}, or ensembles of neural networks~\cite{White2021_BANANAS}. In contrast, we train BO surrogates using a learning-to-rank problem definition~\citep{Cao07_Learning}.  

\textbf{Transfer HPO} refers to the problem definition of speeding up HPO by transferring knowledge from evaluations of hyperparameter configurations on other auxiliary datasets~\citep{Wistuba2021_FSBO,Feurer2015_Initializing, Feurer2018_RGPE}. For example, the hyper-parameters of a Gaussian Process can be meta-learned on previous datasets and then transferred to new tasks~\citep{wang2021pre}. Similarly, a deep GP's kernel parameters can also be meta-learned across auxiliary tasks~\citep{Wistuba2021_FSBO}. Another method trains ensembles of GPs weighted proportionally to the similarity between the new task and the auxiliary ones~\citep{Wistuba2016_Twostage}. When performing transfer HPO, it is useful to embed additional information about the dataset. Some approaches use dataset meta-features to warm-initialize the HPO~\citep{Feurer2015_Initializing, Wistuba2015_Learning}, or to condition the surrogate during pre-training~\citep{Bardenet2013_Scot}. Recent works propose an attention mechanism to train dataset-aware surrogates~\citep{Wei2019_Transferable}, or utilize deep sets to extract meta-features~\citep{jomaa2021transfer}. In complement to the prior work, we meta-learn ranking surrogates with meta-features.

\textbf{Learning to Rank (L2R)} is a problem definition that demands estimating the rank (a.k.a. relevance, or importance) of an instance in a set~\citep{burges2005learning}. The primary application domain for L2R is information retrieval (ranking websites in a search engine)~\citep{10.1145/3209978.3209985}, or e-commerce systems (ranking recommended products or advertisements)~\citep{10.1145/3219819.3220021,wu2018turning}. However, L2R is applicable in diverse applications, from learning distance functions among images in computer vision~\citep{Cakir_2019_CVPR}, up to ranking financial events~\citep{10.1145/3404835.3462969}. In this paper, we emphasize the link between HPO and L2R and train neural surrogates for BO with L2R.

\textbf{Learning to Rank for HPO} is a strategy for conducting HPO with an L2R optimization approach. There exist some literature on transfer-learning HPO methods that employ ranking objective within their transfer mechanisms. SCoT uses a surrogate-based ranking mechanism for transferring hyperparameter configurations across datasets~\citep{Bardenet2013_Scot}. On the other hand, \citet{Feurer2018_RGPE} use a weighted ensemble of Gaussian Processes with one GP per auxiliary dataset, while the ensemble weights are learned with a pairwise ranking-based loss. Modeling the ranks of the learning curves also helps estimate the performance of configurations in a multi-fidelity transfer setup~\citep{10.5555/3524938.3525892}.  Recent work has demonstrated that pair-wise ranking losses can be used for transfer-learning surrogates in a zero-shot HPO protocol~\citep{ozturk-zero2022}. However, none of these approaches extensively study the core HPO problem with L2R, nor do they analyze which ranking loss types enable us to learn accurate BO surrogates. 



\begin{figure}[t!]
\centerline{\includegraphics[width=0.99\linewidth]{figures/DREArchitecture.pdf}}
\caption{The neural architecture of our Deep Ranking Ensembles (DRE) with inputs $x$ (query points) and $z$ (meta-features).} 
\label{figure:DREArchitecture}
\end{figure}



%http://proceedings.mlr.press/v119/wistuba20a/wistuba20a.pdf
%\paragraph{Bayesian Optimization for Hyperparameter Optimization } Although there is a broad realm of approaches to deal with Hyperparameter Optimization (e.g. Evolutionary Algorithms \cite{}, Reinforcement Learning \cite{}, etc), Bayesian Optimization remains a popular method. BO comprises two main components: a surrogate function to model problematically the response function given some observations, and an acquisition function that leverages the probabilistic output from the surrogate to explore the search space and decide which point to observe next. Previous work research different possibilities as surrogate including Gaussian Processes \cite{}, Deep Kernel Gaussian Processes \cite{} or Bayesian Neural Networks \cite{}. Different authors report the advantages of using ensemble of models as surrogate. It is possible to find methods that use ensemble of trees (Random Forests) \cite{Hutter2011_Sequential} or ensemble of neural networks \cite{White2021_BANANAS}. However this previous work do not leverage transfer learning nor perform the search on the ranking space.

%\paragraph{Scale Invariance in Transfer HPO} Recent work has provided evidence for the improved performance of HPO on a new dataset, when leveraging information from auxiliary datasets. Since the validation performance of the Machine Learning algorithm varies across datasets, the transfer HPO methods rely in some mechanism to add scale invariance. SCoT \cite{Bardenet2013_Scot}, one of the first approaches that proposed sharing information across task, proposed to map the validation performance to ranks, where the range of values and the scale are fixed. An ensemble of pretrained Neural Networks was proposed by \cite{SchillingJoint15}. However, they do not perform optimization on the ranking space, but they normalize the accuracies, so that the model performances are comparable between different datasets. \cite{Feurer2018_RGPE} use an ensemble of Gaussian Processes, where a GP is trained for every auxiliary dataset, and their output is combined using the observations of the new dataset. They use a pairwise ranking-based loss to provide scale invariance during the optimization on the new dataset. A different approach introduced by \cite{Salinas2020_Quantile} shows that transfer HPO can be performed through Gaussian Copulas which add scale invariance across tasks. 

%\paragraph{Task Contextualization in Transfer HPO} When performing transfer HPO it is useful to embedd information about the task. Some methods use dataset meta-features to warm-initialize \cite{Feurer2015_Initializing, Wistuba2015_Learning} or as additional features to condition the surrogate on during pre-training and during test \cite{Bardenet2013_Scot}. Recent work proposes to use attention mechanism to build a dataset-aware surrogate \cite{Wei2019_Transferable}. \cite{jomaa2021transfer} propose to use Deep sets to achieve the task contextualization. They further found out that this improves the performance of transfer HPO algorihtms. 


%\paragraph{Deep Ensembles} Deep Ensembles \cite{Lakshminarayanan2017_DeepEnsembles} use independently train neural networks that model the mean and uncertainty of a given input. Subsequently, it combines these outputs to create the predictive distribution $y \sim \mathcal{N}(\mu, \sigma)$. They provide a well calibrated predictive distributions \cite{Wilson20_Bayesian, White2021_BANANAS}. Moreover, they can outperform some Bayesian neural networks for uncertainty representation  \cite{Snoek2019_Can, Ashukha2020_Pitfalls}. Follow-up work has found improved ways to improve the accuracy of the ensembles. BatchEnsemble achieve this by factorizing the weights of the netwrok in a component that is shared among ensembles and another component that depends on the activations \cite{Wen20_BatchEnsemble}. MIMO \cite{Havasi2021_Training} proposes to achieve efficiency by training a multi-input, multi-output network configuration that makes possible to train different subnetworks to build ensembles. However, most of the previous work related to Deep Ensembles focus in improving uncertainty estimations for computer vision, and they do not provide deep insights on how to adapt sucessfully Deep Ensembles to hyperparameter optimization.

