%% Created for Prasanta Ghosh on -01-20
@article{zeng2018end,
  title={On the end-to-end solution to mandarin-english code-switching speech recognition},
  author={Zeng, Zhiping and Khassanov, Yerbolat and Pham, Van Tung and Xu, Haihua and Chng, Eng Siong and Li, Haizhou},
  journal={arXiv preprint arXiv:1811.00241},
  year={2018}
}

@article{tseng2021mandarin,
  title={Mandarin-english code-switching speech recognition with self-supervised speech representation models},
  author={Tseng, Liang-Hsuan and Fu, Yu-Kuan and Chang, Heng-Jui and Lee, Hung-yi},
  journal={arXiv preprint arXiv:2110.03504},
  year={2021}
}
@article{joshi2020transfer,
  title={Transfer learning approaches for streaming end-to-end speech recognition system},
  author={Joshi, Vikas and Zhao, Rui and Mehta, Rupesh R and Kumar, Kshitiz and Li, Jinyu},
  journal={arXiv preprint arXiv:2008.05086},
  year={2020}
}

@article{zhang2020pushing,
  title={Pushing the limits of semi-supervised learning for automatic speech recognition},
  author={Zhang, Yu and Qin, James and Park, Daniel S and Han, Wei and Chiu, Chung-Cheng and Pang, Ruoming and Le, Quoc V and Wu, Yonghui},
  journal={arXiv preprint arXiv:2010.10504},
  year={2020}
}

@article{Kumatani2021,
author = {Kenichi Kumatani and
Robert Gmyr and
Felipe Cruz Salinas and
Linquan Liu and
Wei Zuo and
Devang Patel and
Eric Sun and
Yu Shi},
title = {Building a great multi-lingual teacher with sparsely-gated mixture
of experts for speech recognition},
journal = {CoRR},
volume = {abs/2112.05820},
year = {2021},
url = {https://arxiv.org/abs/2112.05820},
eprinttype = {arXiv},
eprint = {2112.05820},
timestamp = {Mon, 03 Jan 2022 15:45:35 +0100},
biburl = {https://dblp.org/rec/journals/corr/abs-2112-05820.bib},
bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{luo2018towards,
  title={Towards end-to-end code-switching speech recognition},
  author={Luo, Ne and Jiang, Dongwei and Zhao, Shuaijiang and Gong, Caixia and Zou, Wei and Li, Xiangang},
  journal={arXiv preprint arXiv:1810.13091},
  year={2018}
}
@inproceedings{zeng19_interspeech,
  author={Zhiping Zeng and Yerbolat Khassanov and Van Tung Pham and Haihua Xu and Eng Siong Chng and Haizhou Li},
  title={{On the End-to-End Solution to Mandarin-English Code-Switching Speech Recognition}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={2165--2169},
  doi={10.21437/Interspeech.2019-1429}
}
@INPROCEEDINGS{2022mwe,
  author={Peng, Yizhou and Zhang, Jicheng and Xu, Haihua and Huang, Hao and Chng, Eng Siong},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Minimum Word Error Training For Non-Autoregressive Transformer-Based Code-Switching ASR}, 
  year={2022},
  volume={},
  number={},
  pages={7807-7811},
  doi={10.1109/ICASSP43922.2022.9746830}}
@INPROCEEDINGS{shan19investigate,
  author={Shan, Changhao and Weng, Chao and Wang, Guangsen and Su, Dan and Luo, Min and Yu, Dong and Xie, Lei},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Investigating End-to-end Speech Recognition for Mandarin-english Code-switching}, 
  year={2019},
  volume={},
  number={},
  pages={6056-6060},
  doi={10.1109/ICASSP.2019.8682850}}
 @inproceedings{lu20f_interspeech,
  author={Yizhou Lu and Mingkun Huang and Hao Li and Jiaqi Guo and Yanmin Qian},
  title={{Bi-Encoder Transformer Network for Mandarin-English Code-Switching Speech Recognition Using Mixture of Experts}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={4766--4770},
  doi={10.21437/Interspeech.2020-2485}
}
@inproceedings{zhou20b_interspeech,
  author={Xinyuan Zhou and Emre YÄ±lmaz and Yanhua Long and Yijie Li and Haizhou Li},
  title={{Multi-Encoder-Decoder Transformer for Code-Switching Speech Recognition}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={1042--1046},
  doi={10.21437/Interspeech.2020-2488}
}
@INPROCEEDINGS{9362075,
  author={Zhang, Shuai and Yi, Jiangyan and Tian, Zhengkun and Tao, Jianhua and Bai, Ye},
  booktitle={2021 12th International Symposium on Chinese Spoken Language Processing (ISCSLP)}, 
  title={Rnn-transducer With Language Bias For End-to-end Mandarin-English Code-switching Speech Recognition}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ISCSLP49672.2021.9362075}}
  
@inproceedings{lyu2010seame,
  author={Dau-Cheng Lyu and Tien-Ping Tan and Eng Siong Chng and Haizhou Li},
  title={{SEAME: a Mandarin-English code-switching speech corpus in south-east asia}},
  year=2010,
  booktitle={Proc. Interspeech 2010},
  pages={1986--1989},
  doi={10.21437/Interspeech.2010-563}
}
@article{zeng2018end,
  title={On the end-to-end solution to mandarin-english code-switching speech recognition},
  author={Zeng, Zhiping and Khassanov, Yerbolat and Pham, Van Tung and Xu, Haihua and Chng, Eng Siong and Li, Haizhou},
  journal={arXiv preprint arXiv:1811.00241},
  year={2018}
}
@inproceedings{shan2019investigating,
  title={Investigating end-to-end speech recognition for mandarin-english code-switching},
  author={Shan, Changhao and Weng, Chao and Wang, Guangsen and Su, Dan and Luo, Min and Yu, Dong and Xie, Lei},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6056--6060},
  year={2019},
  organization={IEEE}
}
@inproceedings{lu2020bi,
  title={Bi-Encoder Transformer Network for Mandarin-English Code-Switching Speech Recognition Using Mixture of Experts.},
  author={Lu, Yizhou and Huang, Mingkun and Li, Hao and Guo, Jiaqi and Qian, Yanmin},
  booktitle={INTERSPEECH},
  pages={4766--4770},
  year={2020}
}
@inproceedings{zhang2021rnn,
  title={Rnn-transducer with language bias for end-to-end Mandarin-English code-switching speech recognition},
  author={Zhang, Shuai and Yi, Jiangyan and Tian, Zhengkun and Tao, Jianhua and Bai, Ye},
  booktitle={2021 12th International Symposium on Chinese Spoken Language Processing (ISCSLP)},
  pages={1--5},
  year={2021},
  organization={IEEE}
}
@INPROCEEDINGS{8683223,
  author={Li, Ke and Li, Jinyu and Ye, Guoli and Zhao, Rui and Gong, Yifan},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Towards Code-switching ASR for End-to-end CTC Models}, 
  year={2019},
  volume={},
  number={},
  pages={6076-6080},
  doi={10.1109/ICASSP.2019.8683223}}
@inproceedings{vu2012first,
  title={A first speech recognition system for Mandarin-English code-switch conversational speech},
  author={Vu, Ngoc Thang and Lyu, Dau-Cheng and Weiner, Jochen and Telaar, Dominic and Schlippe, Tim and Blaicher, Fabian and Chng, Eng-Siong and Schultz, Tanja and Li, Haizhou},
  booktitle={2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4889--4892},
  year={2012},
  organization={IEEE}
}
@inproceedings{graves2006connectionist,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}
@inproceedings{dalmia2021transformer,
  title={Transformer-transducers for code-switched speech recognition},
  author={Dalmia, Siddharth and Liu, Yuzong and Ronanki, Srikanth and Kirchhoff, Katrin},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5859--5863},
  year={2021},
  organization={IEEE}
}
@article{sreeram2020exploration,
  title={Exploration of end-to-end framework for code-switching speech recognition task: Challenges and enhancements},
  author={Sreeram, Ganji and Sinha, Rohit},
  journal={IEEE Access},
  volume={8},
  pages={68146--68157},
  year={2020},
  publisher={IEEE}
}
@article{long2020acoustic,
  title={Acoustic data augmentation for Mandarin-English code-switching speech recognition},
  author={Long, Yanhua and Li, Yijie and Zhang, Qiaozheng and Wei, Shuang and Ye, Hong and Yang, Jichen},
  journal={Applied Acoustics},
  volume={161},
  pages={107175},
  year={2020},
  publisher={Elsevier}
}
@article{lyu2010analysis,
  title={An analysis of a Mandarin-English code-switching speech corpus: SEAME},
  author={Lyu, Dau-Cheng and Tan, Tien-Ping and Chng, Eng-Siong and Li, Haizhou},
  journal={Age},
  volume={21},
  pages={25--8},
  year={2010}
}
@article{zhou2020multi,
  title={Multi-encoder-decoder transformer for code-switching speech recognition},
  author={Zhou, Xinyuan and Y{\i}lmaz, Emre and Long, Yanhua and Li, Yijie and Li, Haizhou},
  journal={arXiv preprint arXiv:2006.10414},
  year={2020}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}
@article{higuchi2020mask,
  title={Mask CTC: Non-autoregressive end-to-end ASR with CTC and mask predict},
  author={Higuchi, Yosuke and Watanabe, Shinji and Chen, Nanxin and Ogawa, Tetsuji and Kobayashi, Tetsunori},
  journal={arXiv preprint arXiv:2005.08700},
  year={2020}
}
@book{yu2016automatic,
  title={Automatic speech recognition},
  author={Yu, Dong and Deng, Li},
  volume={1},
  year={2016},
  publisher={Springer}
}

@article{joshi2020transfer,
  title={Transfer learning approaches for streaming end-to-end speech recognition system},
  author={Joshi, Vikas and Zhao, Rui and Mehta, Rupesh R and Kumar, Kshitiz and Li, Jinyu},
  journal={arXiv preprint arXiv:2008.05086},
  year={2020}
}

@article{zhang2020pushing,
  title={Pushing the limits of semi-supervised learning for automatic speech recognition},
  author={Zhang, Yu and Qin, James and Park, Daniel S and Han, Wei and Chiu, Chung-Cheng and Pang, Ruoming and Le, Quoc V and Wu, Yonghui},
  journal={arXiv preprint arXiv:2010.10504},
  year={2020}
}

@article{Kumatani2021,
author = {Kenichi Kumatani and
Robert Gmyr and
Felipe Cruz Salinas and
Linquan Liu and
Wei Zuo and
Devang Patel and
Eric Sun and
Yu Shi},
title = {Building a great multi-lingual teacher with sparsely-gated mixture
of experts for speech recognition},
journal = {CoRR},
volume = {abs/2112.05820},
year = {2021},
url = {https://arxiv.org/abs/2112.05820},
eprinttype = {arXiv},
eprint = {2112.05820},
timestamp = {Mon, 03 Jan 2022 15:45:35 +0100},
biburl = {https://dblp.org/rec/journals/corr/abs-2112-05820.bib},
bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}
@article{sak2014long,
  title={Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition},
  author={Sak, Ha{\c{s}}im and Senior, Andrew and Beaufays, Fran{\c{c}}oise},
  journal={arXiv preprint arXiv:1402.1128},
  year={2014}
}
@inproceedings{chan2016listen,
  title={Listen, attend and spell: A neural network for large vocabulary conversational speech recognition},
  author={Chan, William and Jaitly, Navdeep and Le, Quoc and Vinyals, Oriol},
  booktitle={2016 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4960--4964},
  year={2016},
  organization={IEEE}
}
@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}
@inproceedings{graves2013speech,
  title={Speech recognition with deep recurrent neural networks},
  author={Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
  booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
  pages={6645--6649},
  year={2013},
  organization={Ieee}
}
@inproceedings{rao2017exploring,
  title={Exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer},
  author={Rao, Kanishka and Sak, Ha{\c{s}}im and Prabhavalkar, Rohit},
  booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={193--199},
  year={2017},
  organization={IEEE}
}
@inproceedings{he2017streaming,
  title={Streaming small-footprint keyword spotting using sequence-to-sequence models},
  author={He, Yanzhang and Prabhavalkar, Rohit and Rao, Kanishka and Li, Wei and Bakhtin, Anton and McGraw, Ian},
  booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={474--481},
  year={2017},
  organization={IEEE}
}
@article{jaitly2015neural,
  title={A neural transducer},
  author={Jaitly, Navdeep and Sussillo, David and Le, Quoc V and Vinyals, Oriol and Sutskever, Ilya and Bengio, Samy},
  journal={arXiv preprint arXiv:1511.04868},
  year={2015}
}
@inproceedings{zhang2020transformer,
  title={Transformer transducer: A streamable speech recognition model with transformer encoders and rnn-t loss},
  author={Zhang, Qian and Lu, Han and Sak, Hasim and Tripathi, Anshuman and McDermott, Erik and Koo, Stephen and Kumar, Shankar},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7829--7833},
  year={2020},
  organization={IEEE}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{chen2022large,
  title={Large-scale self-supervised speech representation learning for automatic speaker verification},
  author={Chen, Zhengyang and Chen, Sanyuan and Wu, Yu and Qian, Yao and Wang, Chengyi and Liu, Shujie and Qian, Yanmin and Zeng, Michael},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6147--6151},
  year={2022},
  organization={IEEE}
}
@article{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1508.07909},
  year={2015}
}
@article{shibata1999byte,
  title={Byte Pair encoding: A text compression scheme that accelerates pattern matching},
  author={Shibata, Yusuxke and Kida, Takuya and Fukamachi, Shuichi and Takeda, Masayuki and Shinohara, Ayumi and Shinohara, Takeshi and Arikawa, Setsuo},
  year={1999},
  publisher={Citeseer}
}
@article{park2019specaugment,
  title={Specaugment: A simple data augmentation method for automatic speech recognition},
  author={Park, Daniel S and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D and Le, Quoc V},
  journal={arXiv preprint arXiv:1904.08779},
  year={2019}
}
@inproceedings{kim2017joint,
  title={Joint CTC-attention based end-to-end speech recognition using multi-task learning},
  author={Kim, Suyoun and Hori, Takaaki and Watanabe, Shinji},
  booktitle={2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4835--4839},
  year={2017},
  organization={IEEE}
}
@INPROCEEDINGS{9746908,  author={Chen, Xie and Meng, Zhong and Parthasarathy, Sarangarajan and Li, Jinyu},  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={Factorized Neural Transducer for Efficient Language Model Adaptation},   year={2022},  volume={},  number={},  pages={8132-8136},  doi={10.1109/ICASSP43922.2022.9746908}}

@article{graves2012sequence,
  title={Sequence transduction with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1211.3711},
  year={2012}
}
@inproceedings{yu21b_interspeech,
  author={Haibin Yu and Jing Zhao and Song Yang and Zhongqin Wu and Yuting Nie and Wei-Qiang Zhang},
  title={{Language Recognition Based on Unsupervised Pretrained Models}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={3271--3275},
  doi={10.21437/Interspeech.2021-807}
}

@inproceedings{chen22r_maestro,
  author={Zhehuai Chen and Yu Zhang and Andrew Rosenberg and Bhuvana Ramabhadran and Pedro J. Moreno and Ankur Bapna and Heiga Zen},
  title={{MAESTRO: Matched Speech Text Representations through Modality Matching}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={4093--4097},
  doi={10.21437/Interspeech.2022-10937}
}
@INPROCEEDINGS{wangwei,
  author={Wang, Wei and Ren, Shuo and Qian, Yao and Liu, Shujie and Shi, Yu and Qian, Yanmin and Zeng, Michael},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Optimizing Alignment of Speech and Language Latent Spaces for End-To-End Speech Recognition and Understanding}, 
  year={2022},
  volume={},
  number={},
  pages={7802-7806},
  doi={10.1109/ICASSP43922.2022.9747760}}

@INPROCEEDINGS{chuang2021non,
  author={Chuang, Shun-Po and Chang, Heng-Jui and Huang, Sung-Feng and Lee, Hung-yi},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={Non-Autoregressive Mandarin-English Code-Switching Speech Recognition}, 
  year={2021},
  volume={},
  number={},
  pages={465-472},
  doi={10.1109/ASRU51503.2021.9688174}}
  
 @article{bapna2021slam,
  title={SLAM: A unified encoder for speech and language modeling via speech-text joint pre-training},
  author={Bapna, Ankur and Chung, Yu-an and Wu, Nan and Gulati, Anmol and Jia, Ye and Clark, Jonathan H and Johnson, Melvin and Riesa, Jason and Conneau, Alexis and Zhang, Yu},
  journal={arXiv preprint arXiv:2110.10329},
  year={2021}
}
@inproceedings{tang-etal-2022-unified,
    title = "Unified Speech-Text Pre-training for Speech Translation and Recognition",
    author = "Tang, Yun  and
      Gong, Hongyu  and
      Dong, Ning  and
      Wang, Changhan  and
      Hsu, Wei-Ning  and
      Gu, Jiatao  and
      Baevski, Alexei  and
      Li, Xian  and
      Mohamed, Abdelrahman  and
      Auli, Michael  and
      Pino, Juan",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.105",
    doi = "10.18653/v1/2022.acl-long.105",
    pages = "1488--1499",
    abstract = "In this work, we describe a method to jointly pre-train speech and text in an encoder-decoder modeling framework for speech translation and recognition. The proposed method utilizes multi-task learning to integrate four self-supervised and supervised subtasks for cross modality learning. A self-supervised speech subtask, which leverages unlabelled speech data, and a (self-)supervised text to text subtask, which makes use of abundant text training data, take up the majority of the pre-training time. Two auxiliary supervised speech tasks are included to unify speech and text modeling space. Detailed analysis reveals learning interference among subtasks. In order to alleviate the subtask interference, two pre-training configurations are proposed for speech translation and speech recognition respectively. Our experiments show the proposed method can effectively fuse speech and text information into one model. It achieves between 1.7 and 2.3 BLEU improvement above the state of the art on the MuST-C speech translation dataset and comparable WERs to wav2vec 2.0 on the Librispeech speech recognition task.",
}
@inproceedings{ye-etal-2022-cross,
    title = "Cross-modal Contrastive Learning for Speech Translation",
    author = "Ye, Rong  and
      Wang, Mingxuan  and
      Li, Lei",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.376",
    doi = "10.18653/v1/2022.naacl-main.376",
    pages = "5099--5113",
    abstract = "How can we learn unified representations for spoken utterances and their written text? Learning similar representations for semantically similar speech and text is important for speech translation. To this end, we propose ConST, a cross-modal contrastive learning method for end-to-end speech-to-text translation. We evaluate ConST and a variety of previous baselines on a popular benchmark MuST-C. Experiments show that the proposed ConST consistently outperforms the previous methods, and achieves an average BLEU of 29.4. The analysis further verifies that ConST indeed closes the representation gap of different modalities {---} its learned representation improves the accuracy of cross-modal speech-text retrieval from 4{\%} to 88{\%}. Code and models are available at https://github.com/ReneeYe/ConST.",
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@inproceedings{chen2021injecting,
  title={Injecting text in self-supervised speech pretraining},
  author={Chen, Zhehuai and Zhang, Yu and Rosenberg, Andrew and Ramabhadran, Bhuvana and Wang, Gary and Moreno, Pedro},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={251--258},
  year={2021},
  organization={IEEE}
}

@inproceedings{zhao2021addressing,
  title={On addressing practical challenges for RNN-Transducer},
  author={Zhao, Rui and Xue, Jian and Li, Jinyu and Wei, Wenning and He, Lei and Gong, Yifan},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={526--533},
  year={2021},
  organization={IEEE}
}

@article{sainath2022joist,
  title={JOIST: A Joint Speech and Text Streaming Model For ASR},
  author={Sainath, Tara N and Prabhavalkar, Rohit and Bapna, Ankur and Zhang, Yu and Huo, Zhouyuan and Chen, Zhehuai and Li, Bo and Wang, Weiran and Strohman, Trevor},
  journal={arXiv preprint arXiv:2210.07353},
  year={2022}
}

@article{ao2021speecht5,
  title={Speecht5: Unified-modal encoder-decoder pre-training for spoken language processing},
  author={Ao, Junyi and Wang, Rui and Zhou, Long and Liu, Shujie and Ren, Shuo and Wu, Yu and Ko, Tom and Li, Qing and Zhang, Yu and Wei, Zhihua and others},
  journal={arXiv preprint arXiv:2110.07205},
  year={2021}
}

@inproceedings{renduchintala18_interspeech,
  author={Adithya Renduchintala and Shuoyang Ding and Matthew Wiesner and Shinji Watanabe},
  title={{Multi-Modal Data Augmentation for End-to-end ASR}},
  year=2018,
  booktitle={Proc. Interspeech 2018},
  pages={2394--2398},
  doi={10.21437/Interspeech.2018-2456}
}