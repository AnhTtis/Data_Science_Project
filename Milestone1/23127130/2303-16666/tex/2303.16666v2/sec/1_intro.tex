\section{Introduction}
\label{sec:intro}

A major challenge towards applying artificial intelligence to the enormous amounts of unlabeled image data gathered worldwide is the ability to learn effective visual representations of data without supervision. Various unsupervised representation learning techniques based on variational autoencoders (VAEs) \cite{kingma2013auto} have been proposed to address this challenge.
%by researchers based on the idea of variational autoencoders (VAEs) \cite{kingma2013auto}. 
The primary objective of VAEs is to learn a mapping between high-dimensional observations and a lower dimensional representation space, such that the original observations can be approximately reconstructed from the lower-dimensional representation. These lower-dimensional visual representations allow for effectively training downstream tasks, such as image generation \cite{higgins2017beta, van2017neural}, image segmentation \cite{ouyang2019data} and clustering \cite{xu2021multi, graving2020vae}. 

\begin{figure}[t!]
\centering
\includegraphics[width=7cm]{./Figures/vae-intro4-1.png}
\caption{An illustration of using sparse coding to model the latent representations of VAEs.
%The majority of VAEs assumes that the latent representations are either continuous, adhering to a static prior, or discrete via vector quantization (VQ) with a codebook.
The majority of VAEs can be categorized into two classes based on whether the latent representations are continuous, using a static prior, or discrete, utilizing vector quantization  (VQ) with a codebook.
Combining the VAE framework with sparse coding can be conceptualized as representing the middle ground between continuous and discrete VAEs.}
\label{figure:1}
\vspace{-2pt}
\end{figure}

Depending on the downstream task, different VAE variants have been proposed. These are distinguished by the assumptions they make about the world, which are encoded as meta-priors \cite{bengio2013representation}. Based on this, two main classes of methods can be identified.
%One line of research have been focusing on learning representations with continuous features from VAEs \cite{kingma2013auto, higgins2017beta, kim2018disentangling, chen2018isolating, zhao2019infovae, kumarvariational}. These models assume a prior of a gaussian distribution and a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Although these models show good disentanglement results. They suffered from sueveral disadvantages: 1) Fixed prior $\rightarrow$ The mismatch between aggregated posterior and prior. 2)Low reconstruction performance. 3) Poor quality of generated samples. 4) Posterior collapse. 5) Does not continue to yield good disentanglement results for very complex (realistic) datasets.
%Since the first VAE model was proposed, most studies focus on latent representations with continuous features. These models utilized a fixed prior (mostly a gaussian distribution) to regularize the latent space so that they can produce disentangled representations and diverse data can be generated by decoding points sampled from the latent space. Although demonstrating good disentanglement and generation behaviors for simple dataset, they typically suffer from several shortcomings when applied to complex datasets: 1) the fixed prior makes the optimization process troublesome in practice because real world datasets cannot be simply modeled by a single distribution. 2) If the autoregressive decoder is expressive enough to model the data density, then the model can learn to ignore the latent variables, resulting in a trivial posterior that collapses to the prior. posterior collapse 3) These latent variable models typically have simple decoders, where the mapping from the latent variable to the input space is uni-modal, for example using a conditional Gaussian decoder. This typically results in representations that are good at capturing the global structure in the input, but fail at capturing more complex local structure.
The first class of methods \cite{kingma2013auto, higgins2017beta, kim2018disentangling, chen2018isolating, zhao2019infovae, kumarvariational} learns representations with continuous latent variables (hereinafter referred to as continuous VAEs). These models utilized a static prior (usually a Gaussian distribution) to regularize the latent space so that disentangled representations and diverse new data can be generated. These approaches have demonstrated good disentanglement and generation performance for simple datasets \cite{zhao2019infovae, kim2018disentangling}. However, they typically suffer from several shortcomings when applied to complex datasets. First, the static prior makes the optimization process troublesome in practice because real world datasets cannot be simply modeled by a single distribution. Second, these methods tend to ignore the latent variables if the decoder is expressive enough to model the data distribution, resulting in posterior collapse \cite{razavipreventing}. Third, while the global structure of the input is well captured by latent representations, the more intricate local structure is not, leading to bad reconstructions.

%Since the first VAEs \cite{kingma2013auto} model was proposed, most studies \cite{kingma2013auto, higgins2017beta, kim2018disentangling, chen2018isolating, zhao2019infovae, kumarvariational} focused on learning latent representations with continuous features (continuous VAEs for short). These models utilized a static prior (mostly a gaussian distribution) to regularize the latent space so that disentangled representations and diverse new data can be generated. Although demonstrating good disentanglement and generation behaviors for simple dataset, they typically suffer from several shortcomings when applied to complex datasets: 1) the static prior makes the optimization process troublesome in practice because real world datasets cannot be simply modeled by a single distribution, 2) these methods tend to ignore the latent variables if the decoder is expressive enough to model the data density, leading to posterior collapse problem \cite{razavipreventing}, 3) the global structure of the input is well captured by latent representations, but the more intricate local structure is not, causing bad reconstructions in the image space.

The second class of methods \cite{van2017neural, esser2021taming, yu2021vector, lee2022autoregressive, zheng2022movq} learns representations with discrete latent variables (hereinafter referred to as discrete VAEs).
 These methods typically utilize vector quantization (VQ) along with a codebook to learn a prior in the latent space. This approach not only circumvents issues of posterior collapse but has also been shown to achieve good image reconstruction and generation performance. Importantly, the perceptual quality of the reconstructed and generated samples  may be further improved through the use of an adversarial or perceptual loss \cite{johnson2016perceptual, larsen2016autoencoding}. However, discrete VAEs often require a large codebook to conserve the information of the encoded observations, which leads to the increase of model parameters and the codebook collapse problem \cite{dhariwal2020jukebox}. Another shortcoming of discrete VAEs \cite{van2017neural, esser2021taming, yu2021vector, lee2022autoregressive} is that they tend to generate repeated artifactual patterns in the reconstructed image because the VQ operator uses the same quantization index to embed similar image patches. Moreover, the VQ operator does not allow the gradient to pass through the codebook. This makes the optimization process more challenging, as it requires the use of techniques such as the Gumbel-Softmax trick \cite{jang2016categorical} or the straight-through estimator \cite{bengio2013estimating} to approximate the gradients.



To address aforementioned shortcomings, we introduce a new VAE variant SC-VAE, which stands for sparse coding-based VAE with learned ISTA \cite{gregor2010learning}.
Instead of using a fixed prior to learn
continuous characteristics or utilizing VQ to learn discrete variables in the latent space, we propose to model latent representations as sparse linear combinations of atoms using sparse coding (SC) \cite{rubinstein2010dictionaries}.
In the case of continuous VAEs, most of the latent factors are active at each time. In contrast, discrete VAEs require only one quantization index to be active at each time. SC-VAE adopts a middle ground, as is depicted in Figure \ref{figure:1}.
SC is anchored in the crucial realization that, despite the need for numerous variables to describe large collections of natural signals, individual instances can be effectively represented using only a small subset of these variables. 
This is in line with evidence \cite{olshausen1996emergence} that biological vision systems, such as the visual cortex in mammals, process information as sparse signals.

In the field of computer vision, SC is a widely adopted technique for efficiently reconstructing features or images \cite{bao2019convolutional, ravishankar2019image} and it has consistently demonstrated superior performance over VQ on benchmark recognition tasks \cite{coates2011importance, yang2009linear}. 
Therefore, we hypothesize that combining the VAE framework with sparse coding for latent representations reconstruction will lead to better reconstruction for the input. 
Moreover, prior works \cite{rolinek2019variational, kumar2020implicit} have indicated that incorporating orthogonality as a regularization method in VAEs is advantageous for promoting disentangled representations. 
SC-VAE offers a natural approach to acquire disentanglement by utilizing a predetermined orthogonal dictionary.
Traditional algorithms for solving the sparse coding problem, such as Iterative Shrinkage-Thresholding Algorithm (ISTA) \cite{daubechies2004iterative} and Fast Iterative Shrinkage-Thresholding Algorithm (FISTA) \cite{beck2009fast}, can be easily integrated with VAE models. However, these algorithms do not allow to back-propagate gradients, which makes it impossible to train the model in an end-to-end manner. To mitigate this issue, a learnable version of ISTA \cite{gregor2010learning} was used in this work.

Our contributions can be summarized as follows:
(1) We introduce a new VAE variant, termed SC-VAE, which seamlessly integrates the VAE framework with sparse coding. The proposed SC-VAE is trainable in an end-to-end manner and does not suffer from posterior or codebook collapse.
(2) We demonstrate that our method surpasses the performance of previous state-of-the-art approaches in image reconstruction tasks. Qualitative experiments reveal that our model exhibits superior generalization performance.
(3) By training SC-VAE with a predetermined orthogonal dictionary, we illustrate the capacity to achieve effective disentanglement and smooth interpolation in generated images through the acquired sparse code vectors.
(4) The learned sparse code vectors from SC-VAE demonstrate a capability for clustering of image patches. We highlight that this property enables us to achieve better unsupervised image segmentation performance than most state-of-the-art methods, coupled with robustness to noise.