%\section{APPROACH}
\section{Approach}
\label{sec:approach}

The proposed SC-VAE model aims to encode an image into a series of
latent vector representations and then to utilize sparse coding to generate sparse code vectors for these representations. These sparse code vectors can be subsequently decoded back to the reconstructed image with a fixed dictionary and a decoder network. The diagram of the proposed model is shown in Figure \ref{figure:3}. We discuss the model formulation in Section \ref{Model Formulation} and the loss functions in Section \ref{Loss Functions}.

\subsection{Model Formulation} \label{Model Formulation}
 
Formally, the input of SC-VAE is an image $x \in \mathbb{R}^{H \times W \times C}$, where $H$, $W$ and $C$ denote the height, width and the number of image channels, respectively. The image
$x$ goes first through an encoder $E$ to obtain 
 latent representations $E(x) \in \mathbb{R}^{h \times w \times n}$.
Here, the values of $h$ and $w$ depend on the number of downsampling blocks $d$ in the encoder. Accordingly, these are defined as follows $h=\frac{H}{2^d}$ and $w = \frac{W}{2^d}$. $n$ denotes the number of dimensions of each latent representation $E_{ij}(x)$, where $i \in [1, h]$ and $j\in [1, w]$. $E_{ij}^{\top}(x) \in \mathbb{R}^{n \times 1}$ is then given as an input to a Learnable ISTA network. The Learnable ISTA produces the sparse code vector $Z_{ij}\in \mathbb{R}^{1\times K}$ for each $E_{ij}(x)$ by using the learnable parameters $W_e$, $S$ and $\theta$. 
Here, $K$ denotes the number of atoms in the  predetermined orthogonal dictionary $\mathbf{D}$. Each reconstructed latent representation $\tilde{E}_{ij}(x)$ can be calculated by the multiplication of $Z_{ij}$ and $\mathbf{D}^{\top}$, which is then used to reconstruct the original image by going through a decoder neural network $G$.
We denote the output of SC-VAE as $G(\tilde{E}(x))$.
%The design of our convolutional encoder $E$ and decoder $G$ follows the architecture in \cite{esser2021taming}. 

\subsection{Loss Functions} \label{Loss Functions}
We need
to define loss functions at two levels: the image level and the latent representation level. The loss in the image level should encourage our model to provide a good reconstruction for the input image. The loss in the latent space should  allow us not only to obtain good latent representation reconstruction, but also to learn sparse codes. 
%which can reconstruct the latent representations well.


\noindent\textbf{Image reconstruction.} The most common image reconstruction term utilized in VAE models is the $L2$ loss. The $L2$ loss is defined as
\begin{align} \label{eq:4}
    \mathcal{L}_{rec}  &= ||G(\tilde{E}(x))-x||_2^2.
\end{align}


\noindent
\textbf{Latent representation reconstruction.} 
We aim to learn how to reconstruct each latent representation $E_{ij}(x)$ based on a linear combination of atoms in the fixed orthogonal dictionary $\mathbf{D}$.
Accordingly, the loss function for the latent representation reconstruction is given by:
\begin{align} \label{eq:4}
    \mathcal{L}_{latent}  =\sum_{ij}(||E_{ij}^{\top}(x) -\mathbf{D}Z_{ij}^{\top}||_2^2  + \alpha||Z_{ij}^{\top}||_1).
\end{align}
Similar to Eq. (\ref{eq:1}), this loss consists of two terms. The first term is a $L2$ norm to penalize differences between the latent representations of input images and their latent representation reconstructions. The second term imposes sparsity to each latent sparse code vector $Z_{ij}$. $\alpha$ controls the sparseness of the learned sparse code vectors $Z$.

\noindent\textbf{Total loss.} An intuitive way to build the total loss function would be to simply add $\mathcal{L}_{rec}$ and $\mathcal{L}_{latent}$.
However, this loss function will not allow us to learn a good image reconstruction due to the summation term in $\mathcal{L}_{latent}$.
This is because each input image corresponds to $h\times w$ latent representations. As a consequence, the model will focus on learning good sparse code vectors for these latent representations and pay less attention on  adequately optimizing $\mathcal{L}_{rec}$. 
To account for this factor, we introduce coefficients $\frac{1}{hw}$ to each of the latent representation $E_{ij}(x)$, which allows for appropriately balancing the two terms.
Thus, the total loss for our model is the following:
\begin{align} \label{eq:6}
    \mathcal{L}_{SC-VAE}(E,G,W_e, S, \theta)  =\mathcal{L}_{rec} +  \frac{1}{hw}\mathcal{L}_{latent}.
\end{align}