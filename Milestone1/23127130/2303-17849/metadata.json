{
    "arxiv_id": "2303.17849",
    "paper_title": "On Rényi Differential Privacy in Statistics-Based Synthetic Data Generation",
    "authors": [
        "Takayuki Miura",
        "Toshiki Shibahara",
        "Masanobu Kii",
        "Atsunori Ichikawa",
        "Juko Yamamoto",
        "Koji Chida"
    ],
    "submission_date": "2023-03-31",
    "revised_dates": [
        "2023-04-03"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CR",
        "cs.IT"
    ],
    "abstract": "Privacy protection with synthetic data generation often uses differentially private statistics and model parameters to quantitatively express theoretical security. However, these methods do not take into account privacy protection due to the randomness of data generation. In this paper, we theoretically evaluate Rényi differential privacy of the randomness in data generation of a synthetic data generation method that uses the mean vector and the covariance matrix of an original dataset. Specifically, for a fixed $α> 1$, we show the condition of $\\varepsilon$ such that the synthetic data generation satisfies $(α, \\varepsilon)$-Rényi differential privacy under a bounded neighboring condition and an unbounded neighboring condition, respectively. In particular, under the unbounded condition, when the size of the original dataset and synthetic datase is 10 million, the mechanism satisfies $(4, 0.576)$-Rényi differential privacy. We also show that when we translate it into the traditional $(\\varepsilon, δ)$-differential privacy, the mechanism satisfies $(4.00, 10^{-10})$-differential privacy.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17849v1"
    ],
    "publication_venue": "18 pages, 3 figures"
}