
\section{Cosmology in the big data era}
The last decade witnessed an extremely rapid increase of observational data in astronomy. 
Sky survey is a commonly adopted mode of observation 
that runs a telescope to scan over a wide area of the sky, instead of pointing to specific celestial objects.
Modern imaging devices such as Charge Coupled Devices (CCDs) and Complementary Metal Oxide Semiconductor (CMOS)
sensors can generate a large amount of data in a short time.
For instance, Subaru Hyper-Suprime Cam (HSC) has 104 CCDs on its focal plane, and a single snapshot generates
a billion-pixel image \cite{Miyazaki18}. 
Typically, one-night observation by HSC 
generates a few hundred gigabytes of data.
The Vera C. Rubin observatory LSST Camera
has a greater capability of generating a 3.2 billion-pixel image per one snapshot. As a designated survey telescope, it operates continuously for many years, and is expected to deliver over $500$ petabyte 
of imaging data per year \cite{Ivezic19}.
There are a variety of exciting scientific returns from such 
wide-field, multi-epoch surveys. Discovering
distant supernovae and new types of transient objects, mapping the universe with nearby 
and distant 
galaxies, and probing the nature of mysterious dark matter and dark energy, are noted key scientific cases among many others. All these science goals can be achieved through a sequence of fairly complex data analysis processes.
Efficient data processing is a central issue, but remains technically challenging.

Similar situations can also be found in other research domains,
from life science to engineering, where new experiments and 
sensor technologies boost production and acquisition of
data of impressive quality and quantity. 
Naturally, machine learning (ML) applications have become
increasingly popular in virtually all these research
domains. In astronomy, massive amount of data have already been obtained by ongoing surveys 
such as Dark Energy Survey (DES) \cite{Abbott21}, 
Kilo-Degree Survey (KiDS) \cite{Kuijken19}, 
and Subaru HSC Survey \cite{Aihara22}. 
It is taking over years to produce
major science results after the completion
or occasional data release of each of these observations.
The situation may get even harder with upcoming surveys. Just as an example, the estimated data production rate by Square Kilometre Array (SKA) \cite{Carilli15}
reaches nearly 1 terabyte {\it per second} and a typical 6-hour observation
will produce multi petabytes of data \cite{Scaife20}. Currently no practical 
technology is available to keep storing the
whole data physically, and thus there is urgent need for real-time analysis so that only necessary data
are to be stored. The question is, {\it how do we know and select the necessary data to be stored ?} 
The answer involves the following two aspects; scientific one regarding what are interesting objects and phenomena, and technical one regarding how much data can be processed on-the-fly on available computers. For both the objectives, there is huge demand for efficient and reliable ML or AI-based methods.

In this review, we summarize the rapidly developing research in machine learning applications in observational cosmology.
The topics to be covered are time domain astronomy, cosmology with galaxy surveys, 
and emulation technologies. We introduce
successful applications to real observational 
data, but the limited space does not allow us to provide detailed description of individual ML methods.  To the interested readers, we suggest more technical text books and literature (e.g., \cite{Hastie09,Goodfellow16,Geron17}). There are also a variety of self-learning tools and materials available on the internet.

Throughout this review, we do not distinguish clearly machine learning, deep learning, and artificial intelligence.
We shall refer to the broad range of techniques as ML applications.