
\section{Detection and classification of transients}
Transient detection is a classical application of ML. 
Supernovae (SNe) are among the most popular transient objects, which are
known historically since thousands years ago
\cite{Clark82}. A star can end its life by causing a violent and luminous explosion called supernova,
which appears as sudden brightening of a point
(a star) in a galaxy \cite{Branch17}. Its brightness
can even exceed that of the host galaxy, 
and thus it should be straightforward
to spot a supernova if one knows the SN host galaxy 
and compare two images of it taken at different nights.
In Figure 1, we can spot a bright SN at a quick glance.
Doing the same thing for numerous galaxies is a real challenge,
however. A modern large telescope can capture images of
millions of galaxies per night, and
obviously human visual check 
like we do with 
Figure 1 is impractical. 
It is necessary to develop and apply some kind of automated machine 
detection and selection methods.


\begin{figure}
    \centering
    \includegraphics[width=10cm]{Figures/M51-SN-2011dh.jpeg}
    \caption{Supernova 2011dh appeared in galaxy M51. The image on the left was taken in 2009, and on the right July 8th, 2011. 
    The supernova is marked by the orange ticks in the upper right
    portion of the right panel. Image credit: Conrad Jung (Chabot Space and Science Center).}
    \label{fig:SN2011dh}
\end{figure}


\subsection{Machine performance}
Before giving an overview of recent development of astronomical transient detection and classification, it would be useful to introduce a few basic diagnostic tools to quantify the performance of ML models.

Let us consider a simple binary classification with positive (real) and negative (bogus) labels. 
Any classification of a sample with a mixture of the two classes yields the following four cases: True Positive (TP), True Negative (TN), False Positive (FP), and False Nagative (FN). 
The number of true positive cases (TP) out of all the positive
cases (TP + FN) yields the true positive rate 
defined as
\begin{align}
\text{TPR} = \frac{{\rm TP}}{{\rm TP+FN}},
\end{align}
whereas the false positive rate is given by
\begin{align}
\text{FPR} = \frac{{\rm FP}}{{\rm FP+TN}}.
\end{align}
The former is also referred to as "recall".
With the same set of quantities, the other often-used metric is
\begin{align}
\text{precision} = \frac{{\rm TP}}{{\rm TP+FP}},
\end{align}
which is also referred to as "purity" for obvious reasons.
The overall accuracy of a classifier can be evaluated by
\begin{align}
\text{accuracy} = \frac{{\rm TP}+{\rm TN}}
{{\rm TP+FP+TN+FN}},
\end{align}
which is the fraction of correct predictions.

Receiver Operation Characteristics (ROC) curves are commonly used to quantify and compare the performance of different methods \cite{Powers11}. There are various manners to represent ROC using different metrics. Often used in astronomy is the one that shows TPR against FPR as in Figure 2.
A classifier can be made flexible to predict the probabilities for each class instead of returning directly a class label. In this case one needs to set a threshold value, say $C_{\rm p}$, so that a probability above $C_{\rm p}$ is considered to be a positive outcome, and otherwise negative. 
Provided with a test sample, the classifier yields an FPR and a TPR for a given $C_{\rm p}$.
By varying $C_{\rm p}$ continuously, one can draw an ROC curve by connecting the resulting set of points of (FPR, TPR).

\begin{figure}
    \centering
    \includegraphics[width=13cm]{Figures/ROC.png}
    \caption{(Left) ROC curves show the overall accuracy of classification methods. Method $a$ yields a larger true positive rate $t_a$, defined in Equation 1, than
    $t_b$ of Method $b$ for a given false positive rate $f_c$ (Equation 2) that is often set as a requirement 
    of an experiment or an observation. 
    (Right) Confusion matrix for a binary classification. Each matrix element is the number of the corresponding case such as True Positive.}
    \label{fig:ROC}
\end{figure}

A good machine classifies accurately and achieves a high TPR while keeping FPR low. 
A perfect classifier would work such that TPR = 1 with FPR = 0,
and then its ROC curve would appear as a
rectangle in the upper left portion. 
Area Under Curve (AUC) measures the integrated area under the TPR curve plotted against FPR. Generally, a large AUC
indicates that the method achieves a 
high TPR with a low FPR. 

Another useful metric is the so-called confusion matrix that summarizes
the classification result for multiple labels (see the right portion of 
Figure 2). Each element in the matrix represents the relative accuracy of the
predicted class compared to the counterparts in the same row or column. Confusion
matrices are especially useful to identify a few particular classes for
which a classifier performs relatively poorly. One can then train the machine 
so that its performance improves for the identified "weak" classes.

The tools introduced here are fairly popular but may not necessarily provide 
clear suggestions when developing a machine for a specific problem.
One may naively think that a machine can be trained so that it achieves a highest score
with a single metric or trained to achieve
as high scores as possible in terms of many different metrics.
In practice, one needs to set practical and empirical requirements, which depend critically on the designated scientific goal. Suppose an astronomical transient survey
is operated so that it can deliver best candidates for Type Ia SNe for follow-up observations. Type Ia SNe can be used
to measure the distance to the galaxies where they occur,
and thus provide a powerful of probe of the cosmic expansion history \cite{Goobar11}.
To search for Type Ia SNe, very accurate identification of the other types,
say Type II SNe, is perhaps unimportant. Instead it is crucial to identify Type Ia 
SNe with high confidence, and without missing scientifically important ones such as
distant Type Ia SNe before their peak brightness.
Clearly, a machine's performance should be judged by using appropriate (combination of) metrics, that are often very specific to the scientific purpose.

\subsection{Transient detection}
In time domain astronomy, detection of transient objects is the first and perhaps the most important step.
Image subtraction yields a number of spots where the local brightness
differs between the two or more images. 
A particular feature
of transient detection and indeed of many other astronomical 
applications is that the fraction of real astronomical phenomena, 
including supernovae and moving objects,
is extremely small compared to other ``bogus" objects
that show up when image subtraction is performed.
The huge disparity of the numbers of
real and bogus objects, which typically amounts to
one out of thousand, demands 
very peculiar tasks to ML applications.
A simple translation of popular ML algorithms would not 
work satisfactorily to the demand, unfortunately.

Bogus pixels are generated in a processed image for a variety 
of reasons. Cosmic rays hit a CCD chip and read-out errors
can occur. Image subtraction should work perfectly if the 
whole image is completely the same except the transient pixels, 
but in practice, two images of the same object taken at
different nights are {\it different} owing to 
many causes
such as sky seeing conditions and miscalibration of telescope pointing (see Ref.~\cite{Starck06} for astronomical image processing).
Fortunately, these typical "errors" can be learnt by a machine
if they are all labeled appropriately. 

Transient detection we discuss in this section
can also be considered as classification of real/bogus objects. 
Applications of an early generation of ML to real/bogus classification
are found in Refs.~\cite{Bailey07,Brink13}.
Automated detection and classification were performed to images collected by Palomar Transient Factory \cite{Bloom12}.
The candidate detection is done by a two-epoch image difference,
and Oarical classifier based on random forest (RF) \cite{Breiman01} is used to distinguish transients from variable stars, active galactic nuclei, and meteorites.
ML algorithms utilize a vector representation of each sample (transient candidate).
The often used vector elements 
are either measured physical quantities such as visual magnitudes or 
may also be some features constructed from
image pixels. The latter is employed
in, for instance, handwritten character recognition \cite{Lecun98} to generate a list of unsupervised features that allow a machine to learn and perform complex tasks. 
Ref.~\cite{Wright15} directly uses image pixel values to construct a feature vector from the data of Pan-STARSS1 Medium Deep Survey,
instead of using transient features that
are defined and derived before the machine selection.
The derived feature data vectors are given to three classifiers (artificial neural network, support vector machine, and RF) to perform real/bogus selection. A combination of the three achieved an
impressively small false negative (missed detection) rate of less than 1 percent.
It is a common practice to adopt
a combination of multiple methods. For example, three methods including a deep NN were adopted to detect
transients in Subaru HSC Survey \cite{Morii16}. The successful application resulted in detection of
65,000 transient objects and 1800 supernovae \cite{Yasuda19}.

Convolutional neural networks (CNNs) have been extensively used
for selecting optical transient candidates
\cite{Gieseke17,Turpin20,Killestein21}.
A CNN-based classifier BRAAI is developed to
separate real astrophysical events from bogus in data from Zwickey Transient Facility \cite{Duev19}. 
BRAAI adopts a custom VGG model \cite{Simonyan14} which consists of sequential layers with activation functions that allow fast learning
with a large imaging data set. 

Most of the popular applications are based on supervised learning.
There are cases where a well trained machine performs poorly
to objects of a particular type. 
A serious problem arises from mislabeling in training data \cite{Ayyar22,Hosenie21}
and also in test data \cite{Northcutt21}, with the latter relatively
less explored even in the general context of image classification.
A practical two-step method has been proposed by Ref.~\cite{Takahashi22}
for the currently operating Tomo-e Gozen Survey 
that detects as many as one million transient candidates per night, which are mostly bogus.

In real observations, classification results by a machine 
or its output "scores" are used as useful metrics, but not as the unique, decisive information. Often many 
other factors are considered in order to select the target objects, and human checks are performed to identify objects for further follow-up observations.
We close this section by discussing a particular need for {\it prompt} detection
of transients. Rapid localization of electromagnetic counterparts of gravitational wave (GW) sources is an important task in time domain astronomy \cite{Levan20}. The angular resolution of LIGO/VIRGO/KAGRA observations,
namely their event localization capability, is $\sim$ 1 square degree as the current best.
This might seem sufficient to point telescopes to the source, but a modern 8-10 meter class telescope is capable of detecting 
thousands of galaxies
within a square-degree field-of-view. One cannot know which galaxy is the host of the GW source. 
Hence prompt identification of the possibly associated optical transient will be of enormous help for rapid follow-up observations,
as has been the case for a binary neutron star merger event GW170817 \cite{Santos17}. 
An urgent task is to detect and identify astronomical transient(s) that is likely
an elecromagnetic counterpart of
the GW event, and quick differentiation from known types will greatly help to generate
a list of targets \cite{Muthukrishna19b,Stachie20}.  
Accumulating a number of such cases will eventually lead to understanding of the physics of the GW events and then to more accurate classification to be performed in the next observational
campaign.


\subsection{Classification of supernovae}
Classification of supernovae 
(SNe) or of more general transient objects is the next critical
step toward important scientific 
goals such as Type Ia SN cosmology.
Most accurate classification can be done by
spectroscopic observations, which are costly, however, 
and thus can be done only for a limited number of objects. 
Clearly, there is strong demand for {\it photometric} classification of transients, which can be performed with data
of the observed brightness and its time variation of an object
(Figure \ref{fig:class_scheme}).
Rapid photometric 
classification should allow selection of appropriate
targets for prompt follow-up observations.

A straightforward way of classification would be type matching 
using templates of
various types of supernovae \cite{Sako08}.
For an observed brightness variation  (lightcurve) 
as a function of time,
a set of templates are tested to find if any of them describes the observed variation accurately, 
and the best-fit pattern is judged as correct class.
Such templates can be constructed from past observations of well known types of supernovae, 
and/or can be generated from theoretical calculations based on physical modelling of supernovae.


\begin{figure}
    \centering
    \includegraphics[width=15cm]{Figures/class_scheme.png}
    \caption{A schematic diagram of photometric supernova classification. The observed lightcurve data are
    directly used or reconstructed by using interpolation techniques such as Gaussian Process. The data vector or matrix are input to the machine classifier, which extracts features of the input data
    and performs classification. In the figure, the classifier
    part is displayed as convolutional neutral networks as an example. The output may be the most likely label for the input, or often the probabilities for multiple labels.
    \label{fig:class_scheme}}
\end{figure}

The Supernova Photometric Classification Challenge (SNPCC) is 
aimed at promoting community-wide effort for the development of efficient and accurate
SN classification methods \cite{Kessler10}. The catalogue contains
lightcurves of 5086 Type Ia SNe and 16231 Type II SNe. 
Realistic occurrence rates of the two types are used based upon the observational
estimates of Refs.~\cite{Dilday08,Bazin09}. 
More than 10 groups participated in SNPCC and tested different kinds of algorithms from a nonlinear dimensional reduction technique
\cite{Richards09} to random forest. It would be ideal to compare the classification methods by 
measuring one or a few quantities that characterize
the classification accuracy and the overall efficiency. Unfortunately, SN classification is
a complicated task, and there does not seem to be a convenient single metric. Thus Ref~\cite{Kessler10} 
adopts a practical measure of classification accuracy of Type Ia SNe. Interestingly, even for a single method, the accuracy varies significantly depending on the sample SN redshift, details of the data set, the level of flux errors etc.
It is also shown that each classification method
has its own pros and cons, and there is no clear indication of one particular method performing better than the others. 
The same holds true between conventional
statistical methods and machine-learning based ones.

Since then the SNPCC data set offered a playground for data science in order to test and develop new classification methods.
Statistical analysis methods such as wavelet transformation
and principal component analysis (PCA) have also been applied to extract features from the data,
and several conventional algorithms including Support Vector Machine (SVM) are tested \cite{Lochner16}.
To the SNPCC data, Ref.~\cite{Charnock17} applied deep recurrent neural networks (RNNs), which are suited for analysis of sequential time-series data, and achieved an AUC of 0.986 for a binary 
classification of Type Ia and non-Type Ia.
The RNN-based method is also able to
provide classification probabilities as a function of time. 

The Photometric LSST Astronomical Time-series Classification Challenge (PLAsTiCC) was held in 2018 to promote further development in automated classification of a broad range of transients
\cite{Plasticc18,Hlozek20}. It was hosted in the Kaggle competition platform, and over 1000 teams and individuals participated. 
PLAsTiCC standardized the competition by adopting a 
science-motivated metric. 
For objects $n = 1, ..., N$ that belong
to class $m=1,...,M$, the participants submit
a table of the posterior probability $p(m|d_n)$ 
given the lightcurve data vector $d_n$.
Then the classifier performance is evaluated by 
a weighted log-loss
\begin{equation}
L = - \sum_{m=1}^{M} w_m \sum_{n=1}^{N_m} \tau_{n,m} \, \ln \big[ p(m|d_n)\big],    
\end{equation}
where $\tau_{n,m} = 1$ if the predicted class 
$m_n$ is $m$ (true class) and 0 otherwise.
Larger weights $w_m$ are assigned to rare objects
such as superluminous supernovae so that 
the participants are encouraged to classify accurately the rare classes that otherwise would be overlooked
\cite{Malz19}. This is perhaps close in spirit to 
real science objectives of transient surveys.
Avocado classifier of Ref.~\cite{Boone19} 
marked the highest score with an AUC of 0.957 for classification of Type Ia supernovae. 
It is based on LightGBM, an implementation of gradient boosted decision trees of Ref.~\cite{Ke17}, which is trained with a number of features extracted from a large set of photometric data.
Gaussian Process is adopted to model arbitrary lightcurves in all photometric bands simultaneously \cite{Revsbech18}. 
Clearly, it is the combination of these modern techniques that realized the highest score, rather than a single specific algorithm.

An array of novel methods have been developed and 
have already been applied to real imaging data from HSC \cite{Takahashi20}, 
Pan-STARRS \cite{Villar19}, and DES \cite{Smith20}.
 A high-way architecture which allows fast gradient-based training of deep NNs is used to perform binary and multi-label classification of SNe \cite{Takahashi20}. 
Recurrent autoencoder neural networks (RAENN) is used to achieve a high accuracy of photometric lightcurve classification of the Pan-STARRS Medium Deep Survey Supernovae \cite{Villar20}.
Automatic Learning for the Rapid Classification of Events (ALeRCE) has a two-level structure to allow
hierarchical classification \cite{Sanchez21}. It has been applied to data from Zwicky Transient Facility \cite{Carrasco21} in preparation for LSST. 
Multi-band photometric data are used for a CNN-based classifier of Type Ia SNe with 
only single-epoch observations \cite{Kimura17}. For future transient surveys,
transfer learning is a promising approach to 
enable classification by exploiting information from
learning with data from different telescopes
\cite{Vilalta18}.
 
A new class of image analysis methods have been proposed based on generative models, and extremely large programs for natural language processing are being applied to astronomical data.
A time-series Transformer has been applied to the PLAsTiCC data and has achieved an AUC score of 0.98 \cite{Allam21}.
In Ref. \cite{Qu22}, Gaussian Process (see Section 5 for details) is applied in a two-dimensional domain of time and wavelength, for a CNN to perform photometric classification using early time SN lightcurves.
 
There have also been several efforts in automating spectroscopic classification.
A CNN-based classifier DASH was developed by \cite{Muthukrishna19}.
A total of 17 (sub)types of supernovae
such as Type Ia-91T, Type-Iax, and IIP, IIL are considered.
Existence and identification of subclasses within Type Ia 
is an important topic in supernova cosmology \cite{Sasdelli16}.
Automated spectroscopic classification will be extremely useful
for forthcoming surveys using multi-object spectrograph such as
DESI \cite{DESI16} and Subaru PFS \cite{PFS14}.


 It would be useful to discuss here an important future development for
 optimal observation scheduling, becauese it is closely related to efficient identification of particular types of transients.
 Suppose several transients are detected in their early phase,
when the brightness is rapidly increasing. 
To determine the
type of each transient, its brightness at the next observation 
at some later epoch might be critical. 
The question then is {\it when} one should observe the object
next time and with which wavelength filters, 
in order to determine the
transient type most accurately. 
A Feature-based scheduler is tested for expected cases with LSST \cite{Naghib19}.
In a more general context of telescope operation, a proposal-based scheduler is already implemented for the operation
of LSST \cite{Delgado16}.
Integer programming models have been applied to Zwicky Transient Fascility \cite{Bellm19} to minimize slew times between observations with different sets of filters. It is motivated by the success of
a scheme adopted for the Las Cumbres Observatory Global Telescope Network 
that operate observations over a global network of telescopes \cite{Lampoudi15}.



\subsection{Anomaly detection}
\label{sec:SN-anomaly}
Previous sections consider detection and classification
of transient objects or phenomena that are already known and have been well characterized.
Another extremely important task of an astronomical survey is to make truly new {\it discoveries}.
Ongoing and planned observations will detect numerous objects that are poorly understood or phenomena that are completely unknown so far. 
Detecting and characterizing such {\it outliers} and {\it anomalies}  
will remain an important but non-trivial task.
Anomaly detection is a key technique in many
ML applications, from manufacturing to credit card fraud \cite{Chalapathy19}. 


Most of the classification methods introduced in the previous sections utilize 
supervised learning. Given a large set of data, a machine
learns characteristic features of certain types of data or of objects,
and then it is trained to classify a different sample or newly collected data.
This is how supervised learning works usually.
Contrastingly, unsupervised learning is suited for finding
outliers and anomalies, or even
"unknown unknowns" in the data. 
A machine can learn some certain patterns of complex, high-dimensional data
by means of grouping, clustering,
and/or dimensionality reduction
without using prior information on the data sample. 
Without any explicit instruction nor expert labelling, 
it becomes able to identify, in one way or another, outliers that are 
clearly different from known types or are well separated from other major groups of data.
Unsupervised ML has been applied to astronomical transients \cite{Baron19}, and sophisticated
methods have already been developed.
Ref.~\cite{Muthukrishna21} combines a probabilistic deep NN model and
a Bayesian approach to identify rare
transients such as kilonovae and tidal disruption events, whose lightcurves are distinct from those of supernovae.
Models based on unsupervised learning are also able to predict future fluxes from time-series data together with the associated uncertainties.
Ref.~\cite{Villar21} develop 
and test an unsupervised method based on a variational recurrent autoencoder NN (VRAENN)
to deal with unlabeled lightcurve data. A portion of the PLAsTiCC data were used for the training. The VRAENN architecture does not require physical models of transients, and can work with unevenly sampled lightcurve data which 
are converted to encode vectors.
Then an isolation forest with a number of decision trees is used to evaluate an anomaly score for each lightcurve.
Several peculiar SNe including super-luminous and pair-instability SNe were successfully detected by the method.

Anomaly detection algorithms have been applied to various astronomical data sets such as stellar spectra, galaxy images, and photometric lightcurves.
For a specific purpose, Ref.~\cite{Chan22} uses a convolutional variational autoencoder to learn a low-dimensional latent representation of periodic variables. The machine successfully identify anomalous objects in the ZTF data,
which are likely asymptotic giant branch stars or young stellar objects. 


