{
    "arxiv_id": "2303.10888",
    "paper_title": "Self-Improving-Leaderboard(SIL): A Call for Real-World Centric Natural Language Processing Leaderboards",
    "authors": [
        "Chanjun Park",
        "Hyeonseok Moon",
        "Seolhwa Lee",
        "Jaehyung Seo",
        "Sugyeong Eo",
        "Heuiseok Lim"
    ],
    "submission_date": "2023-03-20",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CL",
        "cs.AI"
    ],
    "abstract": "Leaderboard systems allow researchers to objectively evaluate Natural Language Processing (NLP) models and are typically used to identify models that exhibit superior performance on a given task in a predetermined setting. However, we argue that evaluation on a given test dataset is just one of many performance indications of the model. In this paper, we claim leaderboard competitions should also aim to identify models that exhibit the best performance in a real-world setting. We highlight three issues with current leaderboard systems: (1) the use of a single, static test set, (2) discrepancy between testing and real-world application (3) the tendency for leaderboard-centric competition to be biased towards the test set. As a solution, we propose a new paradigm of leaderboard systems that addresses these issues of current leaderboard system. Through this study, we hope to induce a paradigm shift towards more real -world-centric leaderboard competitions.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10888v1"
    ],
    "publication_venue": null
}