\documentclass[reqno, 11pt]{amsart}
\usepackage{amsaddr}
\usepackage{amssymb}
\usepackage[nesting]{hyperref}
\usepackage[pdftex]{graphicx}
\usepackage{listings}
\usepackage{multirow}
\usepackage{placeins}
\usepackage{color}
\usepackage{subfigure}
\usepackage{lscape}
\usepackage{dsfont}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage{verbatim}
\usepackage{accents}
\usepackage{natbib}  


\textheight=24cm \textwidth = 16cm \topmargin= -1cm \oddsidemargin
0mm \evensidemargin 0mm
\newcommand{\BlackBoxes}{\global\overfullrule5pt}
\newcommand{\NoBlackBoxes}{\global\overfullrule0pt}
\BlackBoxes
\renewcommand{\subjclassname}
{\textup{2000} Mathematics Subject Classification}
%\providecommand{\U}[1]{\protect\rule{.1in}{.1in}}



\newcommand{\C}{\mathbb{C}} % komplexe
\newcommand{\K}{\mathbb{K}} % komplexe
\newcommand{\R}{\mathbb{R}} % reelle
\newcommand{\Q}{\mathbb{Q}} % rationale
\newcommand{\Z}{\mathbb{Z}} % ganze
\newcommand{\N}{\mathbb{N}} % natuerliche
\newcommand{\dx}{\mathrm{d}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\CX}{\mathcal{X}}
\newcommand{\CD}{\mathcal{D}}
\newcommand{\st}{\text{s.t. }}
\newcommand{\Fmb}{\mathcal{F}_T-\text{measurable}}
\newcommand{\AMF}{\mathcal{A}_{\text{MF}}}
\newcommand{\EMM}{\mathcal{Q}^{\text{EMM}}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\Xbi}{X_\beta^{-i}}
\newcommand{\Xbn}{X_\beta^{-n}}
\newcommand{\Xbin}{X_\beta^{-i,n}}
\newcommand{\chii}{\chi_{\alpha_i}}
\newcommand{\chin}{\chi_{\alpha_n}}
\newcommand{\Pas}{\PP-\text{a.s.}}

\definecolor{darkgreen}{rgb}{0.01, 0.74, 0.25}
\newcommand{\amcomment}{\color{darkgreen} AM:~}
\newcommand{\nbcomment}{\color{red} NB:~}
%\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}







\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumptions}[theorem]{Assumption}

\numberwithin{equation}{section} \numberwithin{theorem}{section}
\def\0{\kern0pt\-\nobreak\hskip0pt\relax}
\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{\theenumi)}
\newcommand{\itemref}[1]{(\ref{#1})}
\makeatletter
\AtBeginDocument{ \def\@serieslogo{ \vbox to\headheight{ \parindent\z@ \fontsize{6}{7\p@}\selectfont
\vss}}}
\def\overbar#1{\skewbar{#1}{-1}{-1}{.25}}
\def\skewbar#1#2#3#4{{\overbarpalette\makeoverbar{#1}{#2}{#3}{#4}}#1}
\def\overbarpalette#1#2#3#4#5{\mathchoice
{#1\textfont\displaystyle{#2}1{#3}{#4}{#5}}
{#1\textfont\textstyle{#2}1{#3}{#4}{#5}}
{#1\scriptfont\scriptstyle{#2}{.7}{#3}{#4}{#5}}
{#1\scriptscriptfont\scriptscriptstyle{#2}{.5}{#3}{#4}{#5}}}
\def\makeoverbar#1#2#3#4#5#6#7{ \setbox0=\hbox{$\m@th#2\mkern#5mu{{}#3{}}\mkern#6mu$} \setbox1=\null \dimen@=#4\fontdimen8#13 \dimen@=3.5\dimen@
\advance\dimen@ by \ht0 \dimen@=-#7\dimen@ \advance\dimen@ by \wd0
\ht1=\ht0 \dp1=\dp0 \wd1=\dimen@
\dimen@=\fontdimen8#13 \fontdimen8#13=#4\fontdimen8#13
\rlap{\hbox to \wd0{$\m@th\hss#2{\overline{\box1}}\mkern#5mu$}}
\fontdimen8#13=\dimen@}
\def\mylabel#1#2{{\def\@currentlabel{#2}\label{#1}}}
\makeatother
\overfullrule=0pt



\begin{document}
\title[  ]{Optimal investment in ambiguous financial markets with learning}


\author[N. \smash{B\"auerle}]{Nicole B\"auerle$^*$}
\address[N. B\"auerle]{Institute of Stochastics,
Karlsruhe Institute of Technology (KIT), D-76128 Karlsruhe, Germany}

\email{\href{mailto:nicole.baeuerle@kit.edu}{nicole.baeuerle@kit.edu}}

\author[A. \smash{Mahayni}]{Antje Mahayni}
\address[A. Mahayni]{ Mercator School of Management, University of Duisburg–Essen, Lotharstr. 65, 47057, Duisburg, Germany}


\email{\href{amahayni@uni-due.de} {amahayni@uni-due.de}}

\thanks{${}^*$ Corresponding author}%Department of Mathematics,
%Karlsruhe Institute of Technology (KIT), D-76128 Karlsruhe, Germany, nicole.baeuerle@kit.edu}
%\thanks{${}^\dagger$  Mercator School of Management, University of Duisburg–Essen, Lotharstr. 65, 47057, Duisburg, Germany, amahayni@uni-due.de}

\begin{abstract}
We consider the classical multi-asset Merton investment problem under drift uncertainty, i.e. the asset price dynamics are given by geometric Brownian motions with constant but unknown drift coefficients. The investor assumes a prior drift distribution  and is able to learn by observing the asset prize realizations during the investment horizon.
While the solution of an expected utility maximizing investor with constant relative risk aversion (CRRA) is well known, we consider the optimization problem under risk and ambiguity preferences by means of the KMM (\cite{klibanoff2005smooth}) approach. Here, the investor maximizes a double certainty equivalent. The inner certainty equivalent is  for given drift coefficient, the outer  is based on a drift
distribution.
Assuming also a CRRA type ambiguity function, it turns out that the optimal strategy can be stated in terms of the solution without ambiguity preferences but an adjusted drift distribution. To the best of our knowledge an explicit solution method in this setting is new. We rely on some duality theorems to prove our statements.\\
Based on our theoretical results, we are able to shed light on the impact of the prior drift distribution as well as the consequences of ambiguity preferences via the transfer to an adjusted  drift distribution, i.e. we are able to explain the interaction of risk and ambiguity preferences.
We compare our results with the ones in a pre-commitment setup where the investor is restricted to deterministic strategies. It turns out that (under risk and ambiguity aversion)
an infinite investment
horizon implies in both cases a maximin decision rule, i.e. the investor follows the  worst (best) Merton fraction (over all realizations of it) if she is more (less)  risk averse than a log-investor. We illustrate our findings with an extensive numerical study.   %Intuitively, this is explained by the observation that the outer risk (implied by the drift uncertainty) itself depends on the (remaining) investment horizon. In particular, it turns out that time inconsistency is also immanent   under the possibility of learning gradually over time.
%discuss the impact of some time inconsistency which is due to the observation that when plugging in the same a priori drift distribution, the optimal strategy is different for varying investment horizons. In addition, we  analyze the value of learning and the information about the drift coefficient. It turns out that $\dots$
\end{abstract}
\maketitle


%\listoftodos


\makeatletter \providecommand\@dotsep{5} \makeatother
%\listoftodos[Changes in Orange/Red To Do List in Green / Blue]\relax


%\address[N. B\"auerle]{Department of Mathematics,
%Karlsruhe Institute of Technology, D-76128 Karlsruhe, Germany}


%\email{\href{mailto:nicole.baeuerle@kit.edu}{nicole.baeuerle@kit.edu}}

\vspace{0.5cm}
\begin{minipage}{14cm}
{\small
\begin{description}
\item[\rm \textsc{ Key words}]
{\small optimal investment, learning, smooth ambiguity, duality theory, Bayesian investment problem}
\item[\rm \textsc{JEL classifications}] {\small C61, G11, D81}

\end{description}
}
\end{minipage}

\section{Introduction}
We investigate the effects of model ambiguity preferences on optimal investment decisions in a multi asset Black Scholes market. Since the seminal paper by  \cite{ellsberg1961risk}, we know that decision makers may have a non-neutral attitude towards model ambiguity. As a result, preferences are decomposed into risk preferences (based on known probabilities) and preferences concerning the degree of uncertainty about the (unknown) model parameters and are evaluated separately. This is in particular relevant for portfolio optimization problems. A recent literature suggests that model ambiguity is at least as prominent as risk in making investment decisions, see \cite{chen2002ambiguity}.

There are different ways to incorporate model ambiguity in decision making, like for example summarized in \cite{guidolin2013ambiguity}. In our setting, model ambiguity refers to the drift uncertainty in the dynamics of asset prices \footnote{It is well-known that the drift of stock prices is notoriously difficult to estimate, \cite{gennotte1986optimal}} and we apply the smooth ambiguity approach of \cite{klibanoff2005smooth} to deal with it. The risk in asset prices itself is evaluated by a utility function applied to the terminal wealth. Thus, the expected utility is itself a random variable (determined by the prior distribution of the drift parameters) which is evaluated by a second utility function (ambiguity function) capturing the model ambiguity. This approach allows for a separation of risk and ambiguity.  As a result we end up with a stochastic optimization problem over a nested expectation which leads to non-linear expectations and the fact that we cannot solve the problem with a standard HJB approach. As in \cite{balter2021time}  we assume that both the risk aversion and ambiguity aversion of the investor are described by (CRRA) power functions. While \cite{balter2021time} consider pre-commitment strategies, we take into account for the possibility that the investor is able to gradually learn about the drift by observing the asset price movements.

First of all, we contribute to the literature by analytically solving the portfolio optimization problem under drift uncertainty and learning while taking into account for both,  risk and ambiguity preferences. To the best of our knowledge this has not yet been achieved before in our setting. We exploit the fact that the norm-like functions which appear in the concatenations of the certainty equivalents for risk and ambiguity allow for a specific dual representation. On the one hand, such a result should have been expected from previous research about the representation of smooth ambiguity, see \cite{iwaki2014dual}, on the other hand it shows that smooth ambiguity is nothing else than a special kind of robust control. Indeed, we can think of the optimization problem as a classical Bayesian problem with adjusted prior probability distribution for the drift where the adjustment is computed in a second optimization problem. The attitude towards ambiguity depends on the relation of the levels of risk and ambiguity aversion (\cite{balter2021time}, \cite{iwaki2014dual}). Our quasi closed form solutions allow an in depth analysis of the interaction of risk and ambiguity preferences. Among others it turns out that with relatively increasing ambiguity aversion, the prior distribution is smoothly shifted from 'good' to 'bad' drift scenarios, i.e. an ambiguity averse decision maker is more pessimistic.


Second, we are able to determine the long-time behavior of an ambiguity neutral/averse Bayes investor in the multi asset case. This is much more challenging than in the single-asset case. There it has been shown in  \cite{bauerle2017extremal} that the worst/best drift is crucial. In the vector-valued case it is not clear which drift scenarios are worst and which best cases. It turns out that these extreme scenarios are determined by the Euclidean norm of the possible drift vectors. An investor who is more (less) risk averse than a log-investor \footnote{investor with logarithmic ultility}   then tends to a maximin (maximax) decision rule (which does not depend on the probability distribution of the drift). More precisely, an infinite investment horizon implies that the  more (less) risk averse investor initially acts as someone who knows that the drift belongs to the worst (best) case scenario.
Relying on this result we are able to compare the optimal strategy under learning with pre-commitment strategies, i.e. strategies where the investor is restricted to strategies which are deterministic functions of time.  We are able to explain why (compared to a pre-commitment strategy) the value of learning is rather low, even in the case of high investment horizons. For short investment horizons (or remaining investment horizons), the investor is not able to learn {\it{much}} about the drift. For long investment horizons, both investors are initially guided by the worst (best) scenario. Finally this observation also carries over to the investor with model ambiguity since she essentially behaves like a Bayesian investor with adjusted prior which does not play a role when a large time horizon is present. This is maybe expected since a large time horizon allows for perfectly learning the model.
\\

Related literature:\\
{\em Bayes optimization problems and their sensitivity:} We treat the fact that the asset drifts or market prices of risk are unknown as a Bayesian problem where we have a prior distribution (knowledge) about the values of the parameters which are here the drift or equivalently the market price of risk. The observations of the asset prices can then be used to update the belief which is also known as learning. This is done with the help of a filter. This filter then becomes part of the state process of the optimization problem. Techniques like these are well-known in finance, see e.g.
\cite{lakner1995utility} \cite{brennan1998role}, \cite{karatzas2001bayesian}, \cite{honda2003optimal}, \cite{rieder2005portfolio}, \cite{bjork2010optimal} for investment problems in Black Scholes markets.
The sensitivity of the optimal investment strategy in a single-asset Bayesian Black Scholes model w.r.t.\ model parameters is an interesting topic and investigated among others in  \cite{rieder2005portfolio}, \cite{longo2016learning}, \cite{bauerle2017extremal}.


{\em Duality and ambiguity:} One early approach to deal with ambiguity is to consider robust approaches, e.g.\ \cite{gilboa2004maxmin,hansen2001robust} and in continuous time control problems with semimartingale markets \cite{schied2007optimal}, \cite{schied2009robust}. The latter survey paper discusses different robust formulations and their connection to risk measures.   Robust approaches care about worst-case scenarios and have sometimes been criticised for being too pessimistic. Thus, \cite{klibanoff2005smooth} introduced smooth ambiguity (KMM) which weights possible scenarios in a smooth way. Using Yaari's duality theory (\cite{yaari1987dual}), \cite{iwaki2014dual} already showed that there is a dual approach to smooth ambiguity which connects the 'smoothing function' to some distorted probabilities. The dual representation of entropic risk measures is used  in %\cite{fujii2017economic} to , 
 \cite{bauerle2019markov} to tackle discrete-time decision problems with exponential utility for the KMM ambiguity applied to an unknown parameter. In  \cite{skiadas2003robust,skiadas2013smooth} the author relates a robust control to a recursive utility approach.



{\em Solving smooth ambiguity:} Smooth ambiguity models are by definition more complex than standard decision models under uncertainty. There are not many explicitly solved cases and approaches to tackle the problem. A static two-asset problem is considered and solved directly in \cite{gollier2011portfolio}.  In \cite{balter2021time}, the authors treat a Black-Scholes market with one risky asset and restrict to deterministic strategies which excludes learning. In  \cite{guan2022equilibrium} the authors look for equilibrium strategies in a smooth ambiguity problem with investment in a single-asset Black Scholes market and reinsurance and the mean-variance criterion. The recent paper \cite{glx} also considers equilibrium portfolio strategies for smooth ambiguity preferences.




{\em Learning and ambiguity:} The effect of learning under ambiguity has e.g.\ been investigated in \cite{epstein2007learning} among others with the help of dynamic variants of the Ellsberg problem. In  \cite{ju2012ambiguity} a generalized recursive smooth ambiguity and the effects on learning are considered. Both references deal with problems in discrete time.
\cite{suzuki2018continuous} generalizes the results in \cite{ju2012ambiguity} by taking a limit to continuous time. Whereas in \cite{baillon2018effect}  the effect of learning information on people’s attitudes toward ambiguity is investigated. 

The outline of the paper is as follows.
First, Section \ref{sec_theory} states the optimization problem and its solution. We start with a multi-asset Black Scholes model where we set the interest rate to zero for simplicity. Then we review the classical Bayesian case and  explain how the problem with ambiguity can be solved analytically. A main tool is Sion's minimax theorem. Proofs are deferred to the appendix.  
Sec. \ref{sec:sensitivity} first analyzes the optimal strategy in the Bayesian model, since the optimal strategy in the ambiguous case boils down to this setting with adjusted prior. We discuss the behavior of the optimal investment strategy for short and long time horizon. The latter one being quite difficult to analyse. A particular focus is on the special case with two-point prior where we can represent the optimal investment strategy as a convex combination of Merton fractions which are optimal in the setting with complete information given by the two drift settings. We also consider the case with pre-commitment i.e. when the investment strategy has to be chosen at time $0$ and compare the two cases. Finally we simplify in the two-prior scenario the problem with model ambiguity. In Section \ref{sec_numerics} we present an extensive numerical study which sheds further light on our theoretical statements and gives some intuitive explanations. We restrict here to the single-asset case and two-point prior. The appendix contains proofs and further parameter constellations not discussed in the main sections.

%\newpage

%{\amcomment{From a technical point of view, we provide the results for risk (ambiguity) averse as well as risk (ambiguity) loving investors. We also account for different relations between risk and ambiguity aversion and  obtain eight different cases. It turns out that the distinction between risk (ambiguity) aversion and loving investors  is intuitively explained by  maximin and maximax decision rules.}}  \\
%In addition, it turns out that the solution can be traced back to the solution without ambiguity preferences but with a distorted prior probability distribution for the drift. The distortion depends on the relation of the levels of risk and ambiguity aversion. (cite related literature with this result).
 



%Intuitively, this is explained by the observation that the outer risk (implied by the drift uncertainty) itself depends of the (remaining) investment horizon. Thus, it turns out that time inconsistency is also immanent   under the possibility of learning.\footnote{Time inconsistency is commonly used to refer to the change of a decision maker's preference for a particular future outcome over another with the passage of time.} Hereby, we also add an explanation why time
%inconsistency implies that a risk averse (and ambiguity averse) investor acts like an even more risk (and ambiguity) averse
%investor the longer the investment horizon is. Intuitively, it is also clear that the
%higher the risk and ambiguity aversion  is the faster the optimal decision converges to the result
%of the maximin decision rule.

%{\amcomment{It is well understood that the problem of time inconsistency naturally arises if one aggregates utilities or certainty equivalents (cf. e.g. 
%\cite{jackson2015collective}
%Jackson and Yariv (2015), and Desmettre and Steffensen (2021).
%\cite{desmettre2021optimal}). 
%In our case, the aggregation is due to the drift uncertainty ($\mu$, or $\frac{\mu}{\sigma}$ respectively).
%Such an aggregation also results when considering uncertainty about preferences (via $\frac{\mu}{\text{relative risk aversion coefficient }\sigma}$)  or the welfare of a collective of heterogeneous investors, where heterogeneity can prevail with respect to beliefs, time preferences, and risk preference. Thus, our results can be applied straightforwardly to capture other sources for utility aggregation.}}\\
%A myopic investor and an investor with a planning horizon that goes to zero are
%both myopic and choose the average of the optimal strategies. An infinite investment
%horizon implies a maximin decision rule, i.e. the investor maximizes the worst case
%savings rate. A longer the investment horizon implies an increasingly risk-averse
%behavior of the investor. In this way,

%are able to shed light on problems arising from time inconsistency and the value of learning. In particular, we are able to explain why (compared to a pre-commitment strategy) the value of learning is rather low, even in the case of high investment horizons.
%Surprisingly, the value of learning is only first increasing in the investment horizon but decreasing after obtaining its maximal value.

%Related literature:\\
%{\it{Learning}} {\amcomment{Our limiting result concerning a long term investor resembles the findings  of B\"auerle and Grether (2017) %\cite{bauerle2017extremal} 
%who consider an ambiguity neutral investor in a Bayesian financial market.}}\\
%{\it{Pre-commitment}}\\
%Balter et al (2021) study portfolio choice in a Black-Scholes world under drift uncertainty. Preferences
%towards risk and ambiguity are modeled using the smooth ambiguity approach under a
%double power utility assumption and a normal distribution assumption on the unknown drift.
%{\it{Time inconsistency}}\\
%\\
%The outline is as follows.
%First, Sec. \ref{sec_theory} states the optimization  results in a general setup with risk and ambiguity preferences, i.e. we give the solution of in a multi asset case with a discrete (a piori) drift distribution.
%Sec. \ref{sec_long_term} analyzes the long term behavior {\amcomment{Question: the current version is without ambiguity.
%Depending on the sign of $\alpha$, Theorem \ref{theo:sensitivity} states that for $\alpha\in (0,1)$ (the level of relative risk aversion is below 1), the investor only considers the best case (maximax decision rule), for $\alpha <0$ (the level of relative risk aversion is above one), the investor only considers the worst case (maximin decision rule). The conjecture is that the decision rule depends on the relation of the levels of risk and ambiguity aversion. Does this straightforwardly follow from Nicole's summary of different cases? (It is not possible to reason with the probability distortion, i.e. in the limit, the probabilities do not matter (maximin versus maximax))
%Question: Shell we add
%short time behavior? While in the long run, the prior distribution does not matter, in the short run (this is myopic!), the risk/ambiguity aversion does not matter, i.e. the investor uses the weighted average of the Merton strategies}}.
%Sec. \ref{sec_numerics} illustrates the results and discusses xxx. Suggestions for xxx:
%{\amcomment{
%(i)
%Form an economic point of view it is interesting to observe that learning has no impact on the optimal decision (and savings rates), neither for long nor short term investment horizons.
%Thus, the value of learning (compared to pre-commitment) is maximal for some investment horizon $T^*$.
%(ii) Illustration of the impact of ambiguity preferences (probability distortion) xxx
%(iii) emphasize on the impact of the relation of ambiguity and risk aversion levels on long term behavior
%(iv) we could also add (based on the reasonings that in the long run ... ) some discussion about how diversification possibilities matter for the worst/best case drift scenario
%}}

\section{Optimization problem and solution}\label{sec_theory}
%Insert results of Nicole
Let $(\Omega, \mathcal{F}, (\mathcal{F}_t), \mathbb{P})$ be a filtered probability space and $T>0$ be a finite time horizon. The underlying financial market consists of $d$ stocks and one riskless bond, each defined on the previously mentioned probability space. The price process $S=(S_1(t),\ldots,S_d(t))_{t\in [0,T]}$ of the $d$ stocks will for $i=1,\ldots ,d$ be given by
\begin{equation}
d S_i(t) = S_i(t) \left[ \mu_i dt + \sum_{j=1}^d \sigma_{ij} dW_j(t)\right] = S_i(t) \left[  \sum_{j=1}^d \sigma_{ij} dY_j(t)\right],
\end{equation}
where $W=(W_1(t),\ldots,W_d(t))^\top_{t\in [0,T]}$ is a d-dimensional Brownian motion, $\mu_i, \sigma_{ij} \in \R, i,j=1,\ldots,d$ and $\sigma=(\sigma_{ij})$ is regular. We further set $$ Y(t):= W(t)+\Theta t,\quad \Theta^\top := \sigma^{-1} \mu, \quad \mu:=(\mu_1,\ldots,\mu_d),  $$
where $\Theta$ denotes the market price per unit of risk.
The price process  of the riskless bond is for simplicity assumed to be identical to $1$.

We further assume that $\mu$   is not known and thus a random variable. This implies that the market price of risk $\Theta$ is not known to the investor. The random variable $\Theta$  may take one of the values $\vartheta_1,\ldots ,\vartheta_m$. We assume a prior knowledge about the values given by $\PP(\Theta=\vartheta_i)=p_i$.

In a next step we introduce a suitable set of trading strategies. Since the riskless bond is equal to 1 and we only consider self-financing strategies we can express the wealth process with the help of the investment in risky assets only. By $\pi = (\pi_1,\ldots,\pi_d)$ we denote a $d$-dimensional stochastic process representing the trading strategy of some investor, where $\pi_k(t)$ describes the amount   invested  in the $k$-th stock  at time $t\in [0,T]$.  We denote by
$$ \mathcal{F}^Y(t) := \sigma(Y(s), 0\le s\le t), \quad \mathcal{F}^Y:= (\mathcal{F}^Y(t))$$
the filtration generated by $Y$ which is equivalent to the filtration generated by $S$. Strategies $\pi$ should be  $\mathcal{F}^Y$-progressively measurable. This means that the agent is able to observe the stock prices and updates the belief about the market price of risk from this observation. In other words, the agent is able to {\em learn} the right market price of risk.
The associated wealth process denoted by $(X^\pi_t)_{t\in [0,T]}$ is given by
\begin{equation}
X^\pi_t = x_0+ (\pi \cdot S)_t, \mbox{ where } (\pi \cdot S)_t=\sum_{k=1}^d \int_0^t\pi_k(u) \mathrm{d}S_k(u) \label{eq sde price process}
\end{equation}
with initial  capital $x_0 \in \R$. In what follows let
$$ u(x) = \frac1\alpha x^\alpha, \quad \alpha<1, \alpha\neq 0$$
be a CRRA utility function. The absolute and relative risk aversion is here given by
\begin{align*}
R_A(x):=-\frac{u''(x)}{u'(x)}= \frac{1-\alpha}{x} \text{ and } R_R(x):= x R_A(x)=1-\alpha.
\end{align*}
It is well-known that the limiting case $\alpha\to 0$ corresponds to the logarithmic utility. 

\subsection{The classical Bayesian case}\label{sec:classicBayes}
The investor aims to maximize her expected utility of terminal wealth. First we assume that the investor is risk-neutral w.r.t.\ the unknown parameter and consider
\begin{equation}\label{eq:Bayesproblem}
V(x_0)= \sup_\pi \int \EE_\vartheta [u(X_T^\pi)] \PP(d\vartheta)
\end{equation}
where the supremum is taken over all $\mathcal{F}^Y$-adapted strategies $\pi$ for which the stochastic integral and the expectations are defined. We denote this set by $\mathcal{A}.$
This problem is the well-known Bayesian adaptive portfolio problem. We summarize its solution in the following theorem (\cite{karatzas2001bayesian,rieder2005portfolio}) (where $\|\cdot\|$ is the usual Euclidean norm):


\begin{theorem}\label{theo:Bayes}
The maximal expected utility attained in \eqref{eq:Bayesproblem} is given by
\begin{equation}
V(x_0) = \frac{x_0^\alpha}{\alpha} \left( \int_{\R^d} F(T,z)^\gamma \varphi_T(z) dz\right)^{1/\gamma}, \quad x_0>0
\end{equation}\label{eq:FL}
where $\gamma = 1/(1-\alpha)$, $\varphi_T$ is the density of the $d$-dimensional normal distribution $\mathcal{N}(0,TI)$ ($I$ being the identity matrix) and for $t\ge 0, z\in\R^d, i=1,\ldots,m$ we define
\begin{equation}
F(t,z):= \sum_{i=1}^d L_t(\vartheta_i,z) p_i, \quad  L_t(\vartheta_i,z) := \left\{ \begin{array}{ll}
       \exp{\big(z\cdot \vartheta_i-\frac12 \|\vartheta_i\|^2 t\big)}  &  t>0\\
     1    & t=0.
   \end{array}\right.\;  
\end{equation}
%\exp(\vartheta\cdot  z -\frac12 \|\vartheta\|^2 t)
The optimal fractions invested in the stocks are for $t\ge 0$ given by
\begin{equation}
\frac{\pi^*(t)}{X^*(t)}
=\gamma (\sigma^\top)^{-1}  \frac{ \int_{\R^d} \nabla F(T,z+Y(t))(F(T,z+Y(t))^{\gamma-1}\varphi_{T-t}(z) dz}{\int_{\R^d} (F(T,z+Y(t))^{\gamma}\varphi_{T-t}(z) dz}
\end{equation}
where $X^*$ is the wealth process under the optimal strategy $\pi^*.$
\end{theorem}

\begin{remark}
Recall in particular that in case the market price of risk is known and is equal to $\vartheta,$ the optimal fractions which have to be invested do not depend on time and wealth and are given by
$$ \kappa^{\text{Mer}}(\gamma,\vartheta):=  \gamma (\sigma^\top)^{-1} \vartheta.$$
This is a special case of our model when the prior distribution is concentrated on $\vartheta.$ It is often named  {\em Merton fractions} of a CRRA investor with a level of relative risk aversion $\frac{1}{\gamma}=1-\alpha$.
\end{remark}

\subsection{The case with model ambiguity concerns}
Now we are interested in an investor who takes model ambiguity into account, i.e. instead of problem \eqref{eq:Bayesproblem} we consider for a second utility function $v(x)=1/\lambda\; x^\lambda, \lambda <1,\lambda \neq 0$ the problem (see e.g.\ \cite{balter2021time})
\begin{eqnarray}\nonumber
 && \sup_{\pi\in\mathcal{A}}  v^{-1} \int v \circ u^{-1} \EE_\vartheta [u(X_T^\pi)] \PP(d\vartheta)\\ \label{eq:Aproblem}
 &=& \sup_{\pi\in\mathcal{A}}  \left(  \int \left( \EE_\vartheta [(X_T^\pi)^\alpha]\right)^{\lambda/\alpha} \PP(d\vartheta)\right)^{1/\lambda}
\end{eqnarray}
This means that model ambiguity, represented by an uncertain market price of risk, is evaluated with a second utility function $v$ which is here of the same form but with possibly different parameter.
In  case $\alpha >0$ problem \eqref{eq:Aproblem} is equivalent to
\begin{equation}\label{eq:Aproblem1}
 \sup_{\pi\in\mathcal{A}}  \left(  \EE \left[\big( \EE_\Theta [(X_T^\pi)^\alpha]\big)^{\lambda/\alpha} \right]\right)^{\alpha/\lambda},
\end{equation}
in case $\alpha<0$ it is equivalent to 
\begin{equation}\label{eq:Aproblem2}
 \inf_{\pi\in\mathcal{A}}  \left(  \EE \left[\big( \EE_\Theta [(X_T^\pi)^\alpha]\big)^{\lambda/\alpha} \right]\right)^{\alpha/\lambda},
\end{equation}
In case $\alpha=\lambda$ the problem reduces to the Bayesian problem discussed previously. Thus, if model risk and the market risk is evaluated with the same parameter we are back in the setting of Section \ref{sec:classicBayes}. 

\subsubsection{The ambiguity loving case}
Let us now assume that $\lambda> \alpha>0$ and define $\mathbf{p} := \lambda/\alpha>1$. The economic interpretation is that the agent is less concerned about model ambiguity than about the risk in the stock market itself. In this case by using the $L^\mathbf{p}$ norm $\|\cdot\|_\mathbf{p}$ we can write  problem \eqref{eq:Aproblem1} as
\begin{equation}\label{eq:Aproblem3}
 \sup_{\pi\in\mathcal{A}}  \left\| \EE_\Theta [(X_T^\pi)^\alpha]\right\|_\mathbf{p}
\end{equation}
where the norm is w.r.t. $\Theta$. It is well-known that the $L^\mathbf{p}$ norm has the following dual representation for a r.v. $X\ge 0$, where $1/\mathbf{p}+1/\mathbf{q}=1$ (see e.g.\ \cite{rudin1991functional}):
\begin{equation}\label{eq:dual_case1}
\| X\|_\mathbf{p} = \sup\left\{ \int X d \Q : \left\| \frac{d\Q}{d\PP}\right\|_\mathbf{q} \le 1 \right\}.
\end{equation}
On the right-hand side of \eqref{eq:dual_case1} the supremum is taken over all measures $\Q$ (not necessarily probability measures) which are absolutely continuous w.r.t.\ $\PP$.  
For a r.v. $X$ with values $\{x_1,\ldots,x_m\}$ and corresponding probabilities $ p_1,\ldots, p_d$ we can write
\begin{equation}\label{eq:dual:discrete}
\left( \sum_{i=1}^m x_i^\mathbf{p} p_i\right)^{1/\mathbf{p}} = \sup\left\{ \sum_{i=1}^m x_i q_i  : \sum_{i=1}^m \left(\frac{q_i}{p_i}\right)^\mathbf{q} p_i \le 1, q_i\ge 0 \right\}.
\end{equation}
Define the set
\begin{equation}\label{eq:Qdef1}
    \mathfrak{Q}:= \left\{ ( q_i)  : \sum_{i=1}^m \left(\frac{q_i}{p_i}\right)^\mathbf{q} p_i \le 1, q_i\ge 0 \right\}
\end{equation} 
as the set of measures which satisfy the constraints in \eqref{eq:dual:discrete}.
%Note that the set consists of measures, not necessarily probability measures.
This gives rise to the following formulation of our problem:
\begin{equation}\label{eq:Aproblem4}
 \sup_{\pi\in\mathcal{A}} \left\| \EE_\Theta [(X_T^\pi)^\alpha]\right\|_\mathbf{p} =
 \sup_{\pi\in\mathcal{A}} \sup_{\Q \in \mathfrak{Q}} \int \EE_\vartheta [(X_T^\pi)^\alpha] \Q(d\vartheta) =  \sup_{\Q \in \mathfrak{Q}} \sup_{\pi\in\mathcal{A}}   \int \EE_\vartheta [(X_T^\pi)^\alpha]\Q(d\vartheta).
\end{equation}
After normalizing $\Q$, the inner optimization problem is however, exactly the Bayesian portfolio problem of the previous section with distribution $\tilde\Q:= \Q/ \Q(\R)$ for the unknown parameter.  So solving \eqref{eq:Aproblem1} boils down to solving the classical Bayesian portfolio problem first and then in a second step  finding the optimal prior distribution implied by $\Q^*$ which is obtained from the outer optimization problem.

\subsubsection{The ambiguity averse case}
Let us now assume that $\alpha >\lambda> 0$, i.e. the agent is more concerned about model ambiguity than about the risk in the financial market. This case is slightly more complicated.  Define again $\mathbf{p} := \lambda/\alpha<1$ and $\mathbf{q}$ by $1/\mathbf{p}+1/\mathbf{q}=1$.   Note that $\mathbf{q}<0$. We obtain (see Appendix \ref{app:duality}):
\begin{equation}
\left( \sum_{i=1}^m x_i^\mathbf{p} p_i\right)^{1/\mathbf{p}} = \inf\left\{ \sum_{i=1}^m x_i q_i  : \sum_{i=1}^m \left(\frac{q_i}{p_i}\right)^\mathbf{q}  p_i \le 1, q_i\ge 0 \right\}.
\end{equation}
Again, the infimum on the right hand side is taken over all measures $\Q=(q_i)$ which satisfy the constraints. Hence we get
\begin{equation}\label{eq:Aproblem5}
 \sup_{\pi\in\mathcal{A}}  \left(  \EE \left( \EE_\Theta [(X_T^\pi)^\alpha]\right)^{\mathbf{p}} \right)^{\frac{1}{\mathbf{p}}} =  \sup_{\pi\in\mathcal{A}} \inf_{\Q \in \mathfrak{Q}} \int \EE_\vartheta [(X_T^\pi)^\alpha] \Q(d\vartheta).
\end{equation}
We have to show next that we can interchange the infimum and supremum in order to solve the problem as in the previous case. We proceed as in \cite{bauerle2019markov} and use the following minimax theorem (see \cite{sion1958general}):

\begin{theorem}\label{theo:minimax}
Let $M$  be  any space and $O$ be a compact space,  $h$ a function on $M\times O$ that is concave-convexlike. If  $h(x,y)$ is lower semi-continuous in $y$ for all $x\in M$ then $$\sup_x\inf_y h(x,y)= \inf_y \sup_x h(x,y).$$
\end{theorem}

\begin{theorem}\label{theo:main}
In our setting we obtain
\begin{equation}
    \sup_{\pi\in\mathcal{A}} \inf_{\Q \in \mathfrak{Q}} \int \EE_\vartheta [(X_T^\pi)^\alpha] \Q(d\vartheta) =  \inf_{\Q \in \mathfrak{Q}}  \sup_{\pi\in\mathcal{A}} \int \EE_\vartheta [(X_T^\pi)^\alpha] \Q(d\vartheta).
\end{equation}
\end{theorem}

\begin{proof}
We apply Theorem \ref{theo:minimax} to the function $L :  \mathcal{A}\times \mathfrak{Q} \to \R$ defined by
$$L(\pi,\Q)=  \int \EE_\vartheta [(X_T^\pi)^\alpha]\Q(d\vartheta).$$
where $\mathcal{A}$ is the set of admissible strategies. The set $\mathfrak{Q}$ is not compact, however since we want to minimize over this set we can replace it by a set $\mathfrak{\tilde Q}$ where the components of $\Q$ are bounded by a constant $K>0$. Next the mapping $\Q\mapsto L(\Q,\pi)$ is linear and continuous w.r.t.\ weak convergence. Finally, since $X_T^\pi$ is linear in $\pi$ and $x^\alpha$ is concave, the mapping $\pi\mapsto L(\Q,\pi)$ is concave. Hence the assumptions are satisfied and  Theorem \ref{theo:minimax} implies that we are able to interchange  the infimum and supremum.
\end{proof}

As a result we can solve problem \eqref{eq:Aproblem5} as in the previous section.
The other cases with $\alpha,\lambda<0$ are discussed in  Appendix \ref{app:duality}.
%\section{Extensions to other criteria}
%The approach we use can be applied for other risk-sensitive criteria as long as they have a dual representation, see \cite{bauerle2019markov}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%          END APPENDIX                                      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Sensitivity and comparison results}\label{sec:sensitivity}
In the previous section we have seen that solving the optimization problem with smooth ambiguity boils down to solving the classical Bayesian investment problem with the 'right' prior distribution for the unknown market price of risk. In particular, as far as sensitivity results are concerned, the model behaves as the classical Bayesian problem. Thus, we first prove some sensitivity results for the classical case, i.e. for the optimal fractions in Theorem \ref{theo:Bayes} which we denote by 
%problem with one risky asset, i.e. $d=1.$ More precisely, the stock price process is given by
%\begin{equation*}
%    d S(t) = S(t) [\mu dt +\sigma dW(t)]
%\end{equation*}
%and $\Theta := \mu/\sigma. $ We denote the optimal fraction which has to be invested into the stock at time $t$ with a time horizon of $T$, given in Theorem \eqref{theo:Bayes} by
\begin{equation*}
    \kappa(t,T,Y(t)) := \frac{\pi^*(t)}{X^*(t)}.
\end{equation*}
%Part a) and b) of the next lemma are special cases of Theorem 9 in \cite{rieder2005portfolio}, part c) and d) are Theorem 3.1/3.3 in \cite{bauerle2017extremal}.
%In what follows it is convenient to define $(\sigma^\top)^{-1}=: \tilde\sigma.$
\subsection{Limiting results for optimal investment fraction - General prior}
In what follows, the $i$-the row of $(\sigma^\top)^{-1}$ will be denoted by $(\sigma^\top)^{-1}_i$ and $ \|\cdot\|$ is the usual Euclidean norm. When we assume that $p_k>0$ for all $k$, we obtain the following results:

\begin{theorem}\label{theo:sensitivity}
In the Bayesian model  it holds for the optimal investment fractions:
\begin{itemize}
    \item[a)] for all $y\in \R:$
    $$\lim_{T\to 0} \kappa(0,T,y) =\gamma  (\sigma^\top)^{-1} \sum_{k=1}^m  \vartheta_k p_k.$$
     \item[b)] when $\|\vartheta_1\| <\ldots < \|\vartheta_m\|$ and $\alpha>0$  then for all $t\ge 0$, $y\in \R:$
    $$ \lim_{T\to\infty}  \kappa(t,T,y)=\gamma  (\sigma^\top)^{-1} \cdot \vartheta_m = \kappa^{\text{Mer}}(\gamma,\vartheta_m).   $$
     \item[c)] when $\|\vartheta_1\| <\ldots < \|\vartheta_m\|$ and $\alpha<0$  then for all $t\ge 0$, $y\in \R:$
      $$ \lim_{T\to\infty}  \kappa(t,T,y)= \gamma (\sigma^\top)^{-1} \cdot \vartheta_1 =\kappa^{\text{Mer}}(\gamma,\vartheta_1).   $$
   \item[d)]  for all $t\ge 0$, $y\in \R$ and $i=1,\ldots,d:$
       $$\gamma \min_k\{ (\sigma^\top)^{-1}_i \cdot \vartheta_k\} \le   \kappa_i(t,T,y) \le  \gamma \max_k \{(\sigma^\top)^{-1}_i \cdot \vartheta_k\}.$$
    \item[e)]  for all $T>0$:
       $$ \lim_{\alpha \downarrow 0} \kappa(0,T,0) =(\sigma^\top)^{-1} \sum_{k=1}^m  \vartheta_k p_k.$$
     
\end{itemize}
\end{theorem}

A proof of this theorem can be found in  Appendix \ref{app:sensi}. Recall again that the limiting case $\alpha\to 0$ corresponds to the logarithmic utility. Indeed with a logarithmic utility the so-called {\em certainty equivalent principle holds}, i.e.\ the unknown market price of risk $\vartheta$  is simply replaced by its expectation in the  Merton fraction $\kappa^{\text{Mer}}(1,\vartheta)$ given by the right-hand side of the equation in e). The same is true, when the time horizon is short, see a). For a large time horizon (b), c)) investors tend to extreme Merton fractions. In general the optimal investment fractions can be bounded by the entries in the Merton fractions (see d)). 

\begin{remark}
  The statements are substantially easier to formulate and prove in the case when we have only one stock. In this case part a), d) and e)  are special cases of Theorem 9 in \cite{rieder2005portfolio}, part b) and c) are Theorem 3.1/3.3 in \cite{bauerle2017extremal}. 
  Further sensitivity results in the one risky asset case can be found in \cite{longo2016learning}.
\end{remark}

\subsection{Representation for optimal investment fraction - Two-point prior}

Assume now further that $\mu=(\mu_1,\ldots,\mu_d)$ can take only two  possible (arbitrary) values $\bar\mu=(\bar\mu_1,\ldots ,\bar\mu_d)$ and $\underline{\mu}=(\underline{\mu}_1,\ldots,\underline{\mu}_d)$.  We assume that
\begin{equation}\label{eq:apriori_distributionmulti}
     \PP(\mu=\bar\mu)=p \text{ and } \PP(\mu=\underline\mu)=1-p, \quad p\in(0,1).
\end{equation}The optimization problem \eqref{eq:Bayesproblem} boils down to
\begin{equation}\label{eq:Bayesproblem_examplem}
V(x_0)= \sup_{\pi\in\mathcal{A}} \; p \EE_{\bar\mu} [u(X_T^\pi)] + (1-p) \EE_{\underline\mu} [u(X_T^\pi)].
\end{equation}
where $u(x)=\frac1\alpha x^{\alpha}.$ In this case the function $F$ appearing in \eqref{eq:FL} is given by  $ F(t,z)  = p L_t(\bar\vartheta,z)+(1-p) L_t(\underline\vartheta,z)$. Let us further denote
\begin{equation*}
    \hat F(t,T,Y(t)) :=\frac{ \int_{\R}
L_T(\underline\vartheta,z+Y(t))
 (F(T,z+Y(t)))^{\gamma-1}\varphi_{T-t}(z) dz}
 {\int_{\R} (F(T,z+Y(t))^{\gamma}\varphi_{T-t}(z) dz}.
\end{equation*}
Then we can express the solution of \eqref{eq:Bayesproblem_examplem} more explicitly.

\begin{lemma}\label{lem_opt_invmulti}
In the case of  a priori distribution of $\mu$  given by \eqref{eq:apriori_distributionmulti}, the optimal investment fractions  $ \kappa(t,T,Y(t)):=\frac{\pi^*(t)}{X^*(t)}$  of the Bayesian problem \eqref{eq:Bayesproblem_examplem} can be written as follows.
%The maximal expect utility $V(x_0)$ attained in \eqref{eq:Bayesproblem_example}  is given by
%\begin{align*}
%V(x_0) = \frac1\alpha x_0^\alpha \left( \int_{\R} F(T,z)^\gamma \varphi_T(z) dz\right)^{\frac1\gamma}
%\end{align*}
%and the optimal fraction of wealth $ \frac{\pi^*(t)}{X(t)}$ is
    \begin{align*}
\kappa(t,T,Y(t))
%& =  \gamma (\sigma^\top)^{-1} \bar\vartheta-
%(1-p)\gamma (\sigma^\top)^{-1}  (\bar\vartheta-\underline\vartheta)\; \hat F(t,T,Y(t))\\
&=   \gamma (\sigma^\top)^{-1} \bar\vartheta\; \alpha(t,T,Y(t)) +   \gamma (\sigma^\top)^{-1} \underline\vartheta\; (1- \alpha(t,T,Y(t)))\\
&= \kappa^{\text{Mer}}(\gamma,\bar \vartheta)\; \alpha(t,T,Y(t)) +  \kappa^{\text{Mer}}(\gamma,\underline\vartheta)\; (1- \alpha(t,T,Y(t)))
\end{align*}
with $\alpha(t,T,Y(t))=1-(1-p) \hat F(t,T,Y(t))\in[0,1].$
\end{lemma}

\begin{proof}
From Theorem \ref{theo:Bayes} we know that the optimal fraction is given by:
\begin{equation}
\kappa(t,T,Y(t))
=\gamma (\sigma^\top)^{-1}  \frac{ \int_{\R^d} \nabla F(T,z+Y(t))(F(T,z+Y(t))^{\gamma-1}\varphi_{T-t}(z) dz}{\int_{\R^d} (F(T,z+Y(t))^{\gamma}\varphi_{T-t}(z) dz}
\end{equation}
We obtain that
\begin{align*}
  \nabla F(t,z) & =  p \nabla L_t(\bar\vartheta,z)+(1-p) \nabla L_t(\underline\vartheta,z)\\
  & = p L_t(\bar\vartheta,z) \bar\vartheta+(1-p) L_t(\underline\vartheta,z) \underline\vartheta\\
    & = \bar\vartheta F(t,z) -(1-p) L_t(\underline\vartheta,z)(\bar\vartheta- \underline\vartheta)  
\end{align*}
which implies
    \begin{align*}
\kappa(t,T,Y(t))
& =  \gamma (\sigma^\top)^{-1} \bar\vartheta-
(1-p)\gamma (\sigma^\top)^{-1}  (\bar\vartheta-\underline\vartheta)\; \hat F(t,T,Y(t)).
\end{align*}
The stated representation is obtained from
    \begin{align*}
\kappa(t,T,Y(t))
& =  \gamma (\sigma^\top)^{-1} \bar\vartheta-
(1-p)\gamma (\sigma^\top)^{-1}  (\bar\vartheta-\underline\vartheta)\; \hat F(t,T,Y(t))\\
&=   \gamma (\sigma^\top)^{-1} \bar\vartheta \Big(1-(1-p) \hat F(t,T,Y(t))  \Big)+
\gamma (\sigma^\top)^{-1} \underline\vartheta (1-p) \hat F(t,T,Y(t)).
\end{align*}
What is left to prove is that $1-\alpha(t,T,Y(t)) = (1-p) \hat F(t,T,Y(t))\in[0,1].$ Non-negativity is clear. For the upper bound note that
$(1-p) L_T(\underline\vartheta,z+Y(t))\le F(T,z+Y(t)).$ 
\end{proof}

Thus, we can see  that the optimal fraction is always a convex combination between the two possible Merton fractions $ \gamma (\sigma^\top)^{-1} \bar\vartheta$ and $\gamma (\sigma^\top)^{-1} \underline\vartheta.$

\subsection{Pre-commitment}
We will also compare the optimal investment fraction $\kappa(t,T,Y(t))$ under learning with the optimal pre-commitment strategy.
The optimal pre-commitment strategy is a constant, $\mathcal{F}_0^Y-$ measurable investment fraction $\kappa^{\text{pre}}_T$ which is defined  by the optimal constant investment fraction $\kappa$ which solves the optimization problem (\cite{bmbo2022})
\begin{equation}\label{eq:pre_example}
V^{\text{pre}}(x_0)= \sup_\pi \; p\; \EE_{\bar\mu} [u(X_T^\pi)] + (1-p) \EE_{\underline\mu} [u(X_T^\pi)] \text{ s.t. } \pi(t)=\kappa X(t).
\end{equation}
The expectation appearing in \eqref{eq:pre_example} can be computed explicitly and the first-order condition for the optimal $\kappa^{\text{pre}}_T$ can implicitly be written as
\begin{align*}
    \kappa^{\text{pre}}_T &= \gamma (\sigma^\top)^{-1} \bar\vartheta \Big( 
\frac{p e^{ \alpha \kappa^{\text{pre}}_T \cdot \bar\mu T} }{p e^{ \alpha \kappa^{\text{pre}}_T \cdot  \bar\mu T}+ (1-p)  e^{ \alpha \kappa^{\text{pre}}_T\cdot  \underline\mu T}} \Big) + \gamma (\sigma^\top)^{-1} \underline\vartheta \Big( 
\frac{(1-p) e^{ \alpha \kappa^{\text{pre}}_T \cdot \underline\mu T} }{p e^{ \alpha \kappa^{\text{pre}}_T \cdot  \bar\mu T}+ (1-p)  e^{ \alpha \kappa^{\text{pre}}_T\cdot  \underline\mu T}} \Big)\\
&=\kappa^{\text{Mer}}(\gamma,\bar \vartheta)\;  \Big( 
\frac{p e^{ \alpha \kappa^{\text{pre}}_T \cdot \bar\mu T} }{p e^{ \alpha \kappa^{\text{pre}}_T \cdot  \bar\mu T}+ (1-p)  e^{ \alpha \kappa^{\text{pre}}_T\cdot  \underline\mu T}} \Big) + \kappa^{\text{Mer}}(\gamma,\underline \vartheta)\;  \Big( 
\frac{(1-p) e^{ \alpha \kappa^{\text{pre}}_T \cdot \underline\mu T} }{p e^{ \alpha \kappa^{\text{pre}}_T \cdot  \bar\mu T}+ (1-p)  e^{ \alpha \kappa^{\text{pre}}_T\cdot  \underline\mu T}} \Big).
\end{align*} 
Thus, we can again write the optimal pre-commitment fraction as a convex combination of the two Merton fractions $ \kappa^{\text{Mer}}(\gamma,\bar \vartheta)$ and $\kappa^{\text{Mer}}(\gamma,\underline \vartheta).$
For the special case $d=1$ see  \cite{bmbo2022}, Prop. 2 and 3.
%, the optimal pre-commitment strategy $\tilde\pi_T^{*,\text{pre}}$ can be implicitly represented by
%\begin{align*} 
%\tilde\pi_T^{*,\text{pre}}
%& =  \frac{\bar\mu}{\tilde\gamma\sigma^2}-
%(1-p)\frac{\bar\mu-\underline\mu}{\tilde\gamma\sigma^2}\; \frac{e^{\underline\mu\tilde\pi_T^{*,\text{pre}}(1-\tilde\gamma)T}}{p e^{\bar\mu\tilde\pi_T^{*,\text{pre}}(1-\tilde\gamma)T}
%+(1-p)e^{\underline\mu\tilde\pi_T^{*,\text{pre}}(1-\tilde\gamma)T}}
% \end{align*}
Obviously it holds $$\lim_{T\rightarrow 0}\kappa^{\text{pre}}_T= p \kappa^{\text{Mer}}(\gamma,\bar \vartheta) +(1-p) \kappa^{\text{Mer}}(\gamma,\underline \vartheta). $$
In case $d=1$ when $\bar\mu> \underline\mu$ and $\alpha >0$ we further obtain 
$$\lim_{T\rightarrow \infty}\tilde\pi_T^{*,\text{pre}}=  \kappa^{\text{Mer}}(\gamma,\bar \vartheta).$$ 
These limiting results coincide with the limits in Theorem \ref{theo:sensitivity} where we allow for learning. 

\subsection{Impact of model ambiguity preferences}
Now we consider an investor who is concerned about model ambiguity, i.e. instead of problem \eqref{eq:Bayesproblem} we consider for a second utility function $v(x)=x^\lambda, 0<\lambda <1$ problem \eqref{eq:Aproblem}.
We treat the multi-asset case but with only two possible values $\bar\mu=(\bar\mu_1,\ldots ,\bar\mu_d)$ and $\underline{\mu}=(\underline{\mu}_1,\ldots,\underline{\mu}_d)$ for $\mu=(\mu_1,\ldots,\mu_d)$. The optimization problem is then
\begin{align}\label{prob:441}
&  \sup_{\pi\in\mathcal{A}} \left(\; p
\left(\EE_{\bar\mu} [(X_T^\pi)^{\alpha}]\right)^{\frac{\lambda}{\alpha}} + (1-p)
\left(\EE_{\underline\mu} [(X_T^\pi)^{\alpha}]\right)^{\frac{\lambda}{\alpha}}
\right)^{\frac{1}{\lambda}}.
\end{align}

\subsubsection{Probability adjustment  in the case of less ambiguity concerns}
Let us first consider the case of $0<\alpha<\lambda$ where $\mathbf{p} := \lambda/\alpha>1$. The optimization problem \eqref{prob:441} is then according to \eqref{eq:Aproblem4} and Theorem \ref{theo:Bayes} equivalent to

\begin{eqnarray}\nonumber
&&\sup_{\Q\in\mathfrak{Q}}\left\{ (q_1+q_2) x_0^\alpha \left( \int_{\R} \big(\frac{q_1}{q_1+q_2} L_T(\bar\vartheta,z)+\frac{q_2}{q_1+q_2} L_T(\underline{\vartheta},z)  \big) ^\gamma \varphi_T(z) dz\right)^{1/\gamma}\right\}\\
&=&  x_0^\alpha \sup_{\Q\in\mathfrak{Q}}\left\{ \left( \int_{\R^d} \big(q_1 L_T(\bar\vartheta,z)+q_2 L_T(\underline{\vartheta},z)  \big) ^\gamma \varphi_T(z) dz\right)^{1/\gamma}\right\}.
\end{eqnarray}
Since $\gamma >0$ it is enough to solve
\begin{equation}\label{prob:Qonly1}
  \sup_{\Q\in\mathfrak{Q}}\int_{\R^d} \big(q_1 L_T(\bar\vartheta,z)+q_2 L_T(\underline{\vartheta},z)  \big) ^\gamma \varphi_T(z) dz.  
\end{equation}
The solution of this problem can be summarized  as follows (the same solution is obtained for $\lambda<\alpha<0$):

\begin{lemma}\label{lem:optimaldistorsion1}
Let  $0<\alpha<\lambda$ or $\lambda<\alpha<0$,  thus $\mathbf{p} := \lambda/\alpha>1$. An optimal solution $(q_1^*,h(q_1^*))$ of \eqref{prob:Qonly1} is obtained by 
\begin{eqnarray*}
   &&  \sup_{0\leq q_1\leq q_1^{\text{b}}}
     \left\{\int_{\R^d} \big(q_1 L_T(\bar\vartheta,z)+h(q_1) L_T(\underline{\vartheta},z)  \big) ^\gamma \varphi_T(z) dz  \right\}\\
     && h(x):=  \left(
\frac{1- x^\mathbf{q} \; p^{1-\mathbf{q}}}{(1-p)^{1-\mathbf{q}}}
\right)^{\frac{1}{\mathbf{q}}}
\end{eqnarray*}
with $q_1^{\text{b}}= p^{1/\mathbf{p}}.$
\end{lemma}

\begin{proof}
Note first that the set $\mathfrak{Q}$ is bounded. Indeed, when we set $q_2=0$, the maximal value of $q_1$ is given by
$p^{1/\mathbf{q}}.$ Moreover, since both $L_T(\bar\vartheta,z)$ and $L_T(\underline\vartheta,z)$ are positive, the optimal pair $(q_1,q_2)$ will satisfy the constraint with equality, i.e.
\begin{align*}
  \left(\frac{q_1}{p}\right)^\mathbf{q} p+ \left(\frac{q_2}{1-p}\right)^\mathbf{q} (1-p) & = 1.
\end{align*}
Solving this equation for $q_2$ yields the function $h$.
\end{proof}

The optimal solution $(q_1^*,q_2^*)$ in Lemma \ref{lem:optimaldistorsion1} then determines the prior distribution $(q_1^*/(q_1^*+q_2^*),q_2^*/(q_1^*+q_2^*))$ which has to be used for the Bayesian problem in order to solve problem \eqref{prob:441}.

\begin{example}
To make things more explicit consider the case that the initial prior distribution is uniform on the two outcomes, i.e.\ $p=\frac12$ and that $0<\alpha<\lambda$ with $\alpha=0.5.$ This implies that $\gamma =1/(1-\alpha)=2.$
In this special case we obtain:
\begin{eqnarray*}
  &&\sup_{\Q\in\mathfrak{Q}}\int_{\R^d} \big(q_1 L_T(\bar\vartheta,z)+q_2 L_T(\underline{\vartheta},z)  \big) ^\gamma \varphi_T(z) dz\\
  &=& 2^{1/\mathbf{q}-1} \sup_{0\le \tilde y\le 1}\int_{\R^d} \big(\tilde{y}^{1/\mathbf{q}} L_T(\bar\vartheta,z)+ (1-\tilde{y})^{1/\mathbf{q}} L_T(\underline{\vartheta},z)  \big)^2 \varphi_T(z) dz\\
  &=& 2^{1/\mathbf{q}-1} \sup_{0\le \tilde y\le 1}   \big(\tilde{y}^{2/\mathbf{q}} \exp{(T\|\bar\vartheta\|^2)}+ (1-\tilde{y})^{2/\mathbf{q}} \exp{(T\|\underline{\vartheta}\|^2)} + 2\tilde{y}^{1/\mathbf{q}}(1-\tilde{y})^{1/\mathbf{q}} \exp{(T\underline{\vartheta}^\top\bar\vartheta)}    \big).
\end{eqnarray*}
The corresponding optimal prior distribution will depend on $T,\bar\vartheta, \underline{\vartheta}. $ It is easy to see that for small time horizon $T$, the optimal prior distribution is again close to the uniform distribution.  For very large $T$, the optimal prior distribution will have large mass on the larger of the two outcomes $\|\bar\vartheta\|^2, \|\underline\vartheta\|^2.$ However, the optimal prior distribution will always be in $(0,1).$ This can easily be seen by inspecting the derivatives of the function to maximize at $\tilde y=0$ and $\tilde y=1.$ 
\end{example}


\subsubsection{Probability adjustment in the case of more ambiguity concerns}
Let us next consider the case of $0<\lambda<\alpha$ where $\mathbf{p} := \lambda/\alpha<1$. Recall that in this case $\mathbf{q}<0.$ The optimization problem \eqref{prob:441} is then according to \eqref{eq:Aproblem4} and Theorem \ref{theo:Bayes} equivalent to

\begin{eqnarray}\nonumber
&&  x_0^\alpha \inf_{\Q\in\mathfrak{Q}}\left\{ \left( \int_{\R^d} \big(q_1 L_T(\bar\vartheta,z)+q_2 L_T(\underline{\vartheta},z)  \big) ^\gamma \varphi_T(z) dz\right)^{1/\gamma}\right\}.
\end{eqnarray}
Since $\gamma >0$ it is enough to solve
\begin{equation}\label{prob:Qonly2}
  \inf_{\Q\in\mathfrak{Q}}\int_{\R^d} \big(q_1 L_T(\bar\vartheta,z)+q_2 L_T(\underline{\vartheta},z)  \big) ^\gamma \varphi_T(z) dz.  
\end{equation}
The solution of this problem can be summarized  as follows. The proof is similar to the proof of Lemma \ref{lem:optimaldistorsion1} and we skip it here (the same solution is obtained for $\alpha<\lambda<0$).

\begin{lemma}\label{lem:optimaldistorsion2}
Let  $0<\lambda<\alpha$ or $\alpha<\lambda<0$, thus $\mathbf{p} := \lambda/\alpha<1$. An optimal solution $(q_1^*,h(q_1^*))$ of \eqref{prob:Qonly2} is obtained by 
\begin{eqnarray*}
   &&  \inf_{ q_1\geq q_1^{\text{b}}}
     \left\{\int_{\R^d} \big(q_1 L_T(\bar\vartheta,z)+h(q_1) L_T(\underline{\vartheta},z)  \big) ^\gamma \varphi_T(z) dz  \right\}
\end{eqnarray*}
with $q_1^{\text{b}}$ and $h$ as in Lemma \ref{lem:optimaldistorsion1}.
\end{lemma}

\begin{example}
We can again consider the case that the initial prior distribution is uniform on the two outcomes, i.e.\ $p=\frac12$ and that $0<\lambda<\alpha$ with $\alpha=0.5.$ This implies that $\gamma =1/(1-\alpha)=2.$
In this special case we obtain:
\begin{eqnarray*}
  && \inf_{ q_1\geq q_1^{\text{b}}} \int_{\R^d} \big(q_1 L_T(\bar\vartheta,z)+q_2 L_T(\underline{\vartheta},z)  \big) ^\gamma \varphi_T(z) dz\\
  &=& 2^{1/\mathbf{q}-1} \inf_{0\le \tilde y\le 1}   \big(\tilde{y}^{2/\mathbf{q}} \exp{(T\|\bar\vartheta\|^2)}+ (1-\tilde{y})^{2/\mathbf{q}} \exp{(T\|\underline{\vartheta}\|^2)} + 2\tilde{y}^{1/\mathbf{q}}(1-\tilde{y})^{1/\mathbf{q}} \exp{(T\underline{\vartheta}^\top\bar\vartheta)}    \big).
\end{eqnarray*}
Again the optimal prior distribution will always be in $(0,1)$ since the function tends to $+\infty$ at the boundary. According to Theorem \ref{theo:sensitivity} b) this implies that for a very large time horizon the optimal investment fraction is hardly influenced by model ambiguity.
\end{example}

\subsubsection{Probability adjustment in the case of much less ambiguity concerns}
Let us finally consider the case of $0<\lambda$ and $\alpha<0$ where $\mathbf{p} := \lambda/\alpha<0$. Recall that in this case $0<\mathbf{q}<1.$ The optimization problem \eqref{prob:441} is then according to \eqref{eq:Aproblem4} and Theorem \ref{theo:Bayes} equivalent to

\begin{eqnarray}\nonumber
&&  x_0^\alpha \inf_{\Q\in\mathfrak{Q}'}\left\{ \left( \int_{\R^d} \big(q_1 L_T(\bar\vartheta,z)+q_2 L_T(\underline{\vartheta},z)  \big) ^\gamma \varphi_T(z) dz\right)^{1/\gamma}\right\}.
\end{eqnarray}
Since $\gamma >0$ it is enough to solve
\begin{equation}\label{prob:Qonly3}
  \inf_{\Q\in\mathfrak{Q}'}\int_{\R^d} \big(q_1 L_T(\bar\vartheta,z)+q_2 L_T(\underline{\vartheta},z)  \big) ^\gamma \varphi_T(z) dz.  
\end{equation}
The solution of this problem can be summarized  as follows. The proof is similar to the proof of Lemma \ref{lem:optimaldistorsion1} and we skip it here (the same solution is obtained for $\alpha>0,\lambda<0$).

\begin{lemma}\label{lem:optimaldistorsion3}
Let  $\alpha<0<\lambda$ or $\lambda<0<\alpha$, thus $\mathbf{p} := \lambda/\alpha<0$. An optimal solution $(q_1^*,h(q_1^*))$ of \eqref{prob:Qonly3} is obtained by 
\begin{eqnarray*}
   &&  \inf_{ 0\le q_1\leq q_1^{\text{b}}}
     \left\{\int_{\R^d} \big(q_1 L_T(\bar\vartheta,z)+h(q_1) L_T(\underline{\vartheta},z)  \big) ^\gamma \varphi_T(z) dz  \right\}
\end{eqnarray*}
with $q_1^{\text{b}}$ and $h$ as in Lemma \ref{lem:optimaldistorsion1}.
\end{lemma}



\section{Numerical illustration and economic discussion}\label{sec_numerics}
The following discussions and numerical illustrations refer to the case of one risky asset with a   two point prior distribution where only two drift scenarios $\underline\mu$ and $\overline\mu$ ($0<\underline\mu\leq\overline\mu$) are possible. The market price of risk is thus positive in both scenarios ($0<\underline\vartheta<\overline\vartheta$).\footnote{From a technical point of view, 
 the results are reversed in the case of a negative market
price of risk (cf. \cite{longo2016learning}).}
Along the lines of Eqn. (\ref{eq:apriori_distributionmulti}), $p$ denotes the prior probability for the higher drift $\overline\mu$ (good or upper drift scenario) such that the prior probability for the lower drift scenario $\underline\mu$ is given by $1-p$. In addition, we refer to the initial date  $t=0$ where $Y(t)=0$.\footnote{The discussion can also be extended to future dates $t>0$ where $Y(t)\neq 0$. Using the log-investor as a benchmark then implies   that the  prior distribution is replaced by the ´updated´ distribution.}

We consider intuitive explanations of the previous results and shed further light on    the impact of the two sources of risk on the optimal investment strategy. Along the lines of Eqn. (\ref{eq:Aproblem}), the strategy is obtained by maximizing the expected utility over a double risk situation
 where the two sources of risk are evaluated with different utility functions $u$ and $v$.
Our economic  reasoning is first based on the classical Bayesian problem which coincides with the special  case that the two utility functions  $v$ and $u$, are identical ($\lambda=\alpha$, respectively). 
Since the general case can be captured by modifying the probability $p$ towards  $q_1^*/(q_1^*+q_2^*)$ (cf. Lemma \ref{lem:optimaldistorsion1}, \ref{lem:optimaldistorsion2} and \ref{lem:optimaldistorsion3}), 
all sensitivities can be explained by the probability adjustment and the sensitivities of the classical setup in $p$.
Thus, 
we first discuss and illustrate the Bayesian case ($\lambda=\alpha$) and consider the impact of $\lambda\neq\alpha$ on the prior probability adjustment subsequently.  
In addition, we comment on the implications of pre-commitment instead of learning.
 
In what follows the classical Merton problem with a constant  market price of risk $\vartheta$ (known drift, respectively) is referred to as the {\em inner risk situation}. Here, the optimal investment fraction $\kappa^{\text{Mer}}(\gamma,\vartheta)= \gamma \frac{\vartheta}{\sigma}$ is constant (it does not depend on the investment horizon $T$). It is increasing in the market price of risk $\vartheta$ and decreasing in the level of relative risk aversion $\frac{1}{\gamma} =1-\alpha$. %{\amcomment{We need to assume that $\alpha<1$. Intuitively, (without short sale constraints) a risk loving investor prefers the risky asset (over the risk free asset) such that the optimal solution is an infinite amount into the risky asset...XXX Kommentar können wir streichen}}
In contrast to the inner risk, we refer to the  probability distribution over the market price of risk as the {\em outer risk situation}. The impact of this outer risk on the optimal investment strategy is more demanding since, in general, it depends on the investment horizon $T$. An exception is the log-investor (an investor with a log utility function) who can be used as an intuitive benchmark for other investors (more or less risk averse investors).  
%{\amcomment{streichen oder später xxx In the classical Bayesian case, the investor can gradually learn over time. However, 
%we discuss that the directional impact of the prior probability $p$, the level of risk (and ambiguity aversion) $\frac{1}{\gamma}=1-\alpha$, and the (remaining) investment horizon $T$ are also immanent in a  pre-commitment setup where the investor is not able to learn or must commit herself to a constant investment fraction (cf. Eqn. \ref{eq:pre_example}). }}



If not mentioned otherwise, we refer to the three benchmark parameter constellation summarized in Table \ref{tab_bench_NA}.


\begin{table}[]
    \centering
    \begin{tabular}{|c|c|c|c|}\hline
    \multicolumn{4}{|c|}{model parameter}\\\hline
 $\underline\mu$     & $\overline\mu$ & $\sigma$ & p \\
0.03 & 0.09 & 0.15 & 0.5\\ \hline
\end{tabular}
 \begin{tabular}{|c|c|c|}\hline
    \multicolumn{3}{|c|}{level of relative risk aversion $\frac{1}{\gamma}=1-\alpha$}\\\hline
 less than log-investor    & log-investor & more than log-investor \\
$1/\gamma=0.5$ & $1/\gamma=1$ & $1/\gamma=2$\\ \hline
\end{tabular}
    \caption{Benchmark parameter setup (classical Bayesian case). If not otherwise mentioned, the investment horizon is $T=10$ years.}
    \label{tab_bench_NA}
\end{table}


\subsection{Sensitivities in the classical Bayesian case}\label{subsec_disc_a}
\begin{figure}[tb]
	\begin{center}
			{\bf{Weight $g(\alpha,p, T,\underline\vartheta,\overline\vartheta)$ on lower Merton investment fraction}}
		\end{center}
	\begin{center}
			\includegraphics[width=0.45\textwidth]{plot_new_lw_T.pdf}	\includegraphics[width=0.45\textwidth]{plot_new_lw_p.pdf}
			\includegraphics[width=0.45\textwidth]{plot_new_lw_RRA.pdf}
			\includegraphics[width=0.45\textwidth]{plot_new_lw_uppermu.pdf}
\end{center}		
	\caption{The figure is based on the benchmark parameter setup of Table \ref{tab_bench_NA} but considers the dependence on the investment horizon (upper left plot), the probability for the good drift scenario $p$ (upper right plot), the level of relative risk aversion $1-\alpha$ (lower left plot), and the parameter for the good drift scenario $\overline\mu$ (lower right plot). 
	The plots depict the weight on the lower Merton fraction in the optimal investment strategy. In addition, each figure contains the  log-investor (dashed line) and the more (black line) and less (gray line) risk averse investor than the log-investor.}\vspace*{0.15cm}
	\label{Fig_new_a}
\end{figure}


If $u$ and $v$ coincide, Lemma \ref{lem_opt_invmulti} immediately separates the impact of the inner and outer risk on the optimal investment fraction.
The optimal myopic investment fraction  of all investors (all levels of relative risk aversion $1-\alpha$), is given by the convex combination of the Merton fractions of the inner risk situations (good and bad scenario). Thus, the impact of the inner risk is simply as in the classical Merton problem while the impact of the outer risk can be stated by the weight on the good (or bad scenario).
Along the lines of Lemma \ref{lem_opt_invmulti}, the weight on the lower Merton solution (the bad scenario)
is given by 
\begin{align*}
1-\alpha(t,T,Y(t))=(1-p) \hat F(t,T,Y(t)).
\end{align*}
%which denotes the weight on the lower Merton solution (the bad scenario is the inner risk), i.e. the remaining weight is on the upper Merton solution (good scenario).  
such that it is  convenient to discuss ($t=0$ and $Y(t)=0$) 
\begin{align*}
g(\alpha,p, T,\underline\vartheta,\overline\vartheta) :=   
1-\alpha(0,T,0)=(1-p) \hat F(0,T,0).
\end{align*}
%i.e. the optimal weight on the lower Merton fraction. 
%If not otherwise mentioned, the illustrations refer to the benchmark setup summarized in Table \ref{tab_bench_NA}.
\subsubsection{Benchmark log-investor}
Formally, the justification that the log-investor $\alpha\rightarrow 0$ (with a level of relative risk aversion $1-\alpha$ equal to 1) defines a convenient benchmark is given by 
Theorem \ref{theo:sensitivity} e), i.e.
\begin{align*}
\lim_{\alpha\rightarrow 0}  g(\alpha,p, T,\underline\vartheta,\overline\vartheta)=\lim_{T\rightarrow 0}  g(\alpha,p, T,\underline\vartheta,\overline\vartheta)
=1-p.
\end{align*}
Observe that the log-investor  behaves in a myopic way.  
In the short run ($T\rightarrow 0$), the impact of the outer risk (weight on the bad scenario/lower Merton solution)   
%In particular, the optimal myopic investment fraction  of all investors (all levels for RRA $1-\alpha$), is given by the convex combination of the Merton fractions of the inner risk situations (good and bad scenario) where the weights are 
is given by the prior probability $1-p$.
While the within regime Merton fractions depend on the individual levels of risk aversion, the myopic solution of the outer risk is {\it{risk neutral}} in the sense that it is given by the expected value (under the prior distribution) of the within regime Merton fractions. 
Obviously, for $T\rightarrow 0$ there is no hedging demand.
For the log-investor, this is also true for investment horizons $T>0$ (cf. Figure \ref{Fig_new_a} upper left plot).
%The  log investor thus defines an important  benchmark. 
In addition, the log-investor gives an important distinction: 
an investor who is less (more) risk averse uses a lower (higher) weight on the lower Merton fraction (bad regime), cf. Figure \ref{Fig_new_a} (lower left plot).\footnote{  \cite{rieder2005portfolio} Theorem 9 d).}
Economically, this is explained by the trade-off between speculating on the better regime (and following the optimal strategy for the good regime) and hedging against the worse regime (and following the optimal strategy for the bad regime). While the log-investor acts neutral, the hedging (speculation) motive dominates for the  more (less) risk averse investor. 


Intuitively, the larger the difference between the two regimes, the stronger is the hedging (speculating) motive, and the more the optimal strategy moves towards the worst(best)-case strategy. An illustration is given in Figure \ref{Fig_new_a} (lower right plot) which depicts the weight on the lower Merton solution for varying $\overline\mu$. The higher $\overline\mu$ (the higher the difference between the regimes), the larger is the impact of the hedging (speculation) motive for the more (less) risk averse investor. 
\subsubsection{Long run investor}
Similar reasoning applies to the investment horizon $T$. The outer risk is 'higher' for longer investment horizons. %(cf. \ref{Fig_new_a}, upper left plot).
In the long run, the investor who is more risk averse than the log-investor only considers the Merton solution of the bad regime, i.e. for $\alpha<0$ 
\begin{align*}
 %& \lim_{\alpha\rightarrow -\infty}  g(\alpha,p, T,\underline\vartheta,\overline\vartheta)\\
 %& 
 \lim_{T\rightarrow \infty}  g(\alpha,p, T,\underline\vartheta,\overline\vartheta)
=1.
\end{align*}
Thus, w.r.t.\ the outer risk, the long term investor who is more risk averse than the log-investor acts extremely risk averse. 
%$\lim_{\alpha\rightarrow -\infty}  g(\alpha,p, T,\underline\vartheta,\overline\vartheta)=1$). 
In contrast, a long term investor who is less risk averse than the log-investor only considers the good regime.\footnote{  \cite{bauerle2017extremal} Theorem 3.1, Theorem 3.3}
In consequence,   for long term investment horizons ($T\rightarrow\infty$), the prior distribution has no impact on the weight $\alpha(0,T,y)$, i.e. 
 $\alpha(0,T,y)=0$ ($\alpha(0,T,y)=1$)
for $\alpha<0$ (for $\alpha>0$).
The long term investor only considers the worst (best) case drift, i.e. $\underline\mu$ ($\overline\mu$) and behaves along the lines of  a maximin (maximax) decision rule. 
This is further emphasized by means of the sensitivities of the optimal weight on the lower Merton investment fraction.   An illustration is given by Figure \ref{Fig_new_a} (upper left plot) which depicts  the weight on the lower Merton  fraction for varying investment horizons $T$. 

%, the a priori probability $p$, the level of relative risk aversion $1-\alpha$, and the upper drift scenario $\overline\mu$. Each figure concerns the cases of a log investor (dashed), an investor who is (compared to the log investor) less risk averse (gray), and an investor who is more risk averse (black). First recall that, in the long run, the less risk averse investor only considers the good scenario while the more risk averse investor the bad scenario (cf upper left plot). 
\subsubsection{Impact of prior distribution}\label{subsubsec_prior}
\begin{figure}[tb]
	\begin{center}
			{\bf{Difference to log-investor ($g(\alpha,p, T,\underline\vartheta,\overline\vartheta)-(1-p)$)}}
		\end{center}
	\begin{center}
		%	\includegraphics[width=0.45\textwidth]{plot_dif_log_T.pdf}	\includegraphics[width=0.45\textwidth]{plot_dif_log_mu.pdf}
		%	\includegraphics[width=0.45\textwidth]{plot_dif_log_T_b.pdf}
		%		\includegraphics[width=0.45\textwidth]{plot_dif_log_mu_b.pdf}
			\includegraphics[width=0.45\textwidth]{plot_dif_log_A.pdf}
				\includegraphics[width=0.45\textwidth]{plot_dif_log_B.pdf}
					\includegraphics[width=0.45\textwidth]{plot_dif_log_C.pdf}
					\includegraphics[width=0.45\textwidth]{plot_dif_log_D.pdf}	
\end{center}		
	\caption{If not otherwise mentioned below, the figure refers to the benchmark parameter scenario of Table \ref{tab_bench_NA}.
	The figure compares, for varying priors $p$, the weight on the lower Merton fraction to the one of  the log-investor, i.e. it depicts the difference $g(\alpha,p, T,\underline\vartheta,\overline\vartheta)-(1-p)$. The black (gray) lines refer to the investor who is more (less) risk averse than the log-investor. The investment horizon is $T=10$ (thick lines) and $T=20$ (dashed lines). The upper right figure is then based on  $\overline\mu= 0.12$ (instead of the benchmark parameter $\overline\mu= 0.09$). The lower left plot then considers the benchmark scenario with the exception that  $\underline\mu= 0.01$ (instead of $\underline\mu= 0.03$). The last figure (lower right plot) considers a  higher risk aversion ($\alpha=-2$ instead of $\alpha=-1$) for the black lines and a lower risk aversion ($\alpha=0.6$ instead of $\alpha=0.5$) for the gray lines.
%	Second line plots: same but more extreme levels of $\alpha$ ( $\alpha=-2$ and  $\alpha=0.2$).\\
%	Below the same procedure but now third line: (bench case RRA) left: $T=15$ versus $T=45$. Right: $T=15$, $\overbar\mu=0.09$ versus $T=15$, $\overbar\mu=0.135$ (such that $0.12-0.09=0.03$ and $\frac{0.03 T}{\sigma}=3$
}
	\vspace*{0.15cm}
	\label{Fig_new_log}
\end{figure}
Intuitively, the weight on the lower Merton investment fraction is decreasing (increasing) in the prior probability $p$ ($1-p$) (upper right plot of Figure \ref{Fig_new_a}). This is obvious for the log-investor who simply relies on the prior probability. However, notice again the important distinction based on the benchmark log-investor. While the more risk averse investor (black line) uses a higher weight on the lower Merton solution, the opposite is true for the less risk averse investor (gray line). Intuitively, the discrepancy is the highest for some intermediate $p$. While there is no outer risk implied in the extreme cases that $p\rightarrow 0$ or   $p\rightarrow 1$, the outer risk is 'maximal' for some intermediate $p$ (which depends on the investment horizon $T$, the level of relative risk aversion $1-\alpha$, and   the relation between good and bad scenario).  The outer risk situation also increases in the distance between the good and bad regime ($\overline\mu$ and $\underline\mu$). Thus, the deviation of a more (less) risk averse investor from the log-investor is the higher, the higher the distance is, e.g. it is increasing in $\overline\mu$ (cf lower right figure of Figure \ref{Fig_new_a}). An additional illustration is given by Figure  \ref{Fig_new_log} which depicts the difference to the log-investor by means of 
$$g(\alpha,p, T,\underline\vartheta,\overline\vartheta)-(1-p),$$
i.e. the difference of the weight on the lower Merton solution and $1-p$ which is the weight of the log-investor. All figures include two investment horizons ($T=10$ and $T=20$).
Observe that the deviation from the log-investor is the higher, the higher the investment horizon is. For the investor who is more (less) risk averse than the log-investor, the highest  deviation is obtained for $p>0.5$ ($p<0.5$). Recall that the more (less) risk averse investor tends to hedge (speculate) the bad (good) drift scenario. In consequence, the prior probability $p$ with the highest deviation increases (decreases) in the investment horizon.   
Analogous reasoning is true w.r.t. the sensitivity to $\overline \mu$ ($\underline \mu$) and the level of risk aversion $1-\alpha$ (cf. Figure  \ref{Fig_new_log}).

\subsubsection{Learning vs.\ pre-commitment}
\begin{figure}[tb]
	\begin{center}
			{\bf{Comparison of optimal initial learning and pre-commitment strategy}}
		\end{center}
	\begin{center}
			\includegraphics[width=0.45\textwidth]{plot_comp_pre_b.pdf}	\includegraphics[width=0.45\textwidth]{plot_comp_pre_a.pdf}	
			\includegraphics[width=0.45\textwidth]{plot_comp_pre_d.pdf}	\includegraphics[width=0.45\textwidth]{plot_comp_pre_c.pdf}
\end{center}		
	\caption{If not otherwise mentioned below, the figure refers to the benchmark parameter scenario of Table \ref{tab_bench_NA}. The upper plots  are based on $p=0.75$ (i.e. $1-p=0.25$) while the lower plots refer to 
	 $p=0.25$ (i.e. $1-p=0.75$).
	The left hand figures compare  the optimal weight on the lower Merton solution of the learning (black) and pre-commitment setup (dashed) for varying investment horizons $T$. The upper (lower) figure concerns the investor who is more (less) risk averse than the log-investor.  The right hand figures depict, for $T=10$ (black) and  $T=20$ (gray), the weight on the lower Merton solution for varying levels of relative risk aversion. Again, the black lines refer to strategies under learning while the dashed ones are pre-commitment strategies.}\vspace*{0.15cm}
	\label{Fig_comp}
\end{figure}
It is worth to mention that similar reasoning as above is valid in a pre-commitment setup (cf. optimization problem \eqref{eq:pre_example}). 
First notice that, in the classical Bayesian setup,  the optimal investment fraction   of the log-investor does not depend on $T$.
Thus, the optimal pre-commitment and learning strategies coincide (at $t=0$).
In addition, this is true for the limiting cases of a myopic investor ($T\rightarrow 0$) and the long term investor ($T\rightarrow \infty$).
For an investor who is more risk averse than the log-investor, recall now the hedging motive. 
W.r.t. 
the trade-off between speculating on the better regime (and following the optimal strategy for the good regime) and hedging against the worse regime (and following the optimal strategy for the bad regime), the hedging motive dominates. In addition, observe that the hedging motive is increasing in the investment horizon $T$. Compared to the setup under learning, pre-commitment implies that the investor must pre-commit to a constant investment fraction at $t=0$. In the optimum, she anticipates that gradually over time, the remaining investment horizon decreases.
Therefore, at $t=0$, the hedging demand is, for rather high investment horizons $T$, lower in the pre-commitment setup than under learning. 
The above reasoning is illustrated in Figure \ref{Fig_comp}. The left figure compares (for an investor who is more risk averse than the log-investor) the optimal weight on the lower Merton solution of the learning (black) and pre-commitment setup (dashed) for varying investment horizons $T$. 
Observe that the strategies coincide in the limiting cases. In addition, for intermediate investment horizons $T$, the pre-commitment strategy has a lower weight on the bad scenario (lower Merton solution). This implies that (at $t=0$) the pre-commitment strategy is more aggressive than the learning strategy. As mentioned above, this is due to the fact that the investor who must pre-commit already has to anticipate that, in the future,  the remaining investment horizon is lower which is associated with a lower hedging demand (against the bad scenario).   
The right plot of Figure \ref{Fig_comp} depicts the weight on the lower Merton solution for varying levels of relative risk aversion. Again, the black line refers to learning while the dashed one is pre-commitment. Observe that the strategies (the weights on the lower Merton solution) coincide in the case of a log-investor  ($\alpha\rightarrow 0$) with level of relative risk aversion equal to one. 
Overall, however, our numerical results do not show a very big difference between the pre-commitment and the learning strategy.

%\begin{figure}[tb]
%	\begin{center}
%			{\bf{Percentage difference}}
%		\end{center}
%	\begin{center}
%			\includegraphics[width=0.45\textwidth]{plot_pre_error_a.pdf}	\includegraphics[width=0.45\textwidth]{plot_pre_error_b.pdf}	
%\end{center}		
%	\caption{xxx.}\vspace*{0.15cm}
%	\label{Fig_comp2}
%\end{figure}



\subsection{Impact of ambiguity}
 Throughout the following, we assume that the investor is more risk averse than the log-investor, i.e. $\alpha<0$.
 Notice that the investor is risk averse if and only if $u$ is concave, while she is ambiguity averse if and only if $v$ is a  concave  transformation  of $u$.
 Assuming that $u$ and $v$ are CRRA functions with relative risk (ambiguity) aversion $1-\alpha$ ($1-\lambda$)  implies that an ambiguity neutral investor is characterized by $\lambda=\alpha$ while she is ambiguity averse (loving)   for $\lambda<\alpha<0$ ( $0>\lambda>\alpha$). 
 
%Intuitively, the directional effects of ambiguity aversion thus depends on the relation between the level of ambiguity aversion and the level of risk aversion. 

Again, we consider the impact of the outer risk (evaluated by the ambiguity function $v$) by means of the weight on the lower (upper) Merton solution (implied by the utility function $u$), i.e. we are interested in $g(\alpha, p^{\text{mod}} ,\dots)$ where 
%we refer to p^{\text{mod}} with
$$p^{\text{mod}}:=q_1^*/(q_1^*+q_2^*)$$
(cf. Lemma \ref{lem:optimaldistorsion1}, \ref{lem:optimaldistorsion2} and \ref{lem:optimaldistorsion3}). 
We call $p^{\text{mod}}$ the adjusted or modified probability.
The ambiguity neutral investor serves as a benchmark since  $p^{\text{mod}}=p$, i.e. the modified probability coincides with the prior probability.

Recall (cf. Subsection \ref{subsubsec_prior})  that the weight on the lower Merton solution is decreasing in the prior probability $p$.
Thus, introducing ambiguity aversion (loving) is equivalent to decreasing (increasing) the prior probability $p$ for the good drift scenario. 
Assume now that both, the level of risk aversion and ambiguity aversion are above the one of the benchmark log-investor, i.e. $\alpha<0$ and $\lambda<0$. Recall that we already discussed the special case $\lambda=\alpha$ in Subsection \ref{subsec_disc_a}. Intuitively, the investor chooses less risk  (a higher weight on the lower Merton solution) under ambiguity aversion, i.e. if the relative ambiguity aversion is higher than the level of risk aversion, i.e. if $\lambda<\alpha$ ($1-\lambda>1-\alpha$). In terms of the probability adjustment this implies that 
the modified  probability  $p^{\text{mod}}$ is smaller than $p$, i.e. the investor is characterized by a lower weight on the upper Merton solution than the ambiguity neutral investor. In contrast,  if $\lambda>\alpha$ ($1-\lambda<1-\alpha$) implies that $p^{\text{mod}}$ is higher than $p$.  
A numerical illustration of the modified probability is given in Figure \ref{Fig_ill_23_a} (left plot).
%The benchmark model setup is given as in xxx. 
The level of relative risk aversion is $1-\alpha=4$. Notice that the modified prior probability $p^{\text{mod}}$  is decreasing in the level of relative ambiguity aversion $1-\lambda$. In particular, it is above (below) the prior $p$ in the case that   $1-\lambda<1-\alpha$ ($1-\lambda>1-\alpha$).
Notice that the effect is more pronounced for higher times to maturity $T$, i.e. the impact on the modified prior probability is increasing in $T$. However, recall that the impact of the prior probability is decreasing in $T$, i.e. for $T\rightarrow \infty$ the (more than log) risk averse investor only relies on the worst drift scenario. Hence the effect of ambiguity aversion is fading for large time horizons. This is natural, since a large time horizon allows for perfectly learning the model. The overall effect on the investment fraction (represented by the weight on the lower Merton solution) is {\it{smooth}} (cf. Figure \ref{Fig_ill_23_a} (right plot)). 



\begin{figure}[tb]
	\begin{center}
			{\bf{Impact of ambiguity aversion on modified probability $p^{\text{mod}}$ and weight on lower Merton solution}}
		\end{center}
	\begin{center}
			\includegraphics[width=0.45\textwidth]{plot_2023_amb_a.pdf}	
			\includegraphics[width=0.45\textwidth]{plot_2023_amb_b.pdf}	
\end{center}
\caption{Model parameters are given as before (cf. Table \ref{tab_bench_NA}).  The prior probability for the good drift scenario is $p=0.5$, the level of relative risk aversion is equal to 4 ($1-\alpha=4$). The figure on the left hand side depicts the modified prior probability for varying levels of relative ambiguity aversion $1-\lambda$.
The figure on the right hand side gives the corresponding weights on the lower Merton solution.
The black lines refers to an investment horizon of  $T=10$ years, the dashed one to $T=20$, and the gray one to $T=50$.}\vspace*{0.15cm}
	\label{Fig_ill_23_a}	
\end{figure}




\section{Conclusion} We consider a classical multi-asset investment problem within a Black Scholes market with terminal utility of CRRA type. In contrast to established literature we include ambiguity aversion by means of the KMM (\cite{klibanoff2005smooth}) approach  where we assume that the drift of the stocks is not known (model ambiguity), but only a prior distribution is given and the investor is able to learn about the drifts by observing the stock prices. Thus, a second utility function of CRRA type for ambiguity aversion is included. We show analytically how problems of this type can be reduced to the solution of a classical Bayesian investment problem with adapted prior. Based on this result we are able to carry out an extensive numerical study where we discuss the impact of ambiguity preferences. It turns out that investors choose less risk (in terms of a higher weight on the lower Merton ratio) under ambiguity aversion. We consider in particular the short-term and the long-term investment behavior. For the long-term investment it turns out that only the risk aversion of the investor matters  and the investor behaves like one who knows the drift and this is either the most optimistic one (if she is less risk averse than the log-investor) or the most pessimistic one (if she is more risk averse than the log-investor) independent from model ambiguity. Whereas it is clear what this means in the single-asset case, in the multi-asset scenario we first have to figure out what the worst and best drift parameters indeed are. We have shown that the Euclidean norm of the drift vector is here the relevant quantity. For the short-term horizon investment,  only the prior distribution is important and the solution is given by the average of within regime Merton solutions. This is again independent from model ambiguity. 



%Recall that the impact of ambiguity aversion implies a modification of the a priori distribution of $\mu$. Thus, we first discuss the impact of the  a priori distribution on the optimal investment fraction $\tilde \pi$ and the optimal savings rate in the standard learning setup.

%One risky asset, $B=1$ ($r=0$)\\
%{\it{Notation: use tilde to refer to our notation, e.g. $\tilde\gamma$ for the level of relative risk aversion, $\tilde\lambda$ for market price per unit of risk...}}

%In the first instance, assume that $\mu$ is a random variable with two values only ($\vartheta_1=\frac{\bar\mu}{\sigma}$ and $\vartheta_2=\frac{\underline\mu}{\sigma}$)\\
%{\it{Alternatively, use $\mu^{\text{up}}$ and $\mu^{\text{down}}$}}
%\begin{align*}
% \PP(\mu=\bar\mu)=p \text{ and } \PP(\mu=\underline\mu)=1-p
%\end{align*}
 %Here, the optimization problem boils down to
%\begin{equation}\label{eq:Bayesproblem_example}
%V(x_0)= \sup_\pi \; p \EE_{\bar\mu} [u(X_T^\pi)] + (1-p) \EE_{\underline\mu} [u(X_T^\pi)].
%\end{equation}
%where $u(x)=x^{\alpha}$, $u'(x)=\alpha x^{\alpha-1}$, $u''(x)=\alpha(\alpha-1)x^{\alpha-2}$ such that
%\begin{align*}
%R_A(x):=-\frac{u''(x)}{u'(x)}= \frac{1-\alpha}{x} \text{ and } R_R(x):= x R_A(x)=1-\alpha=:\tilde\gamma
%\end{align*}

%The maximal expected utility attained in \eqref{eq:Bayesproblem_example} is given by
%\begin{align*}
%V(x_0) = x_0^\alpha \left( \int_{\R} F(T,z)^\gamma \varphi_T(z) dz\right)^{1/\gamma}
%\end{align*}
%where $\gamma = 1/(1-\alpha)$, $\varphi_T$ is the density of the normal distribution $\mathcal{N}(0,T)$ and
%\begin{align*}
%F(t,z) & = %\int \exp(\vartheta z -\frac12 \|\vartheta\|^2 t) \PP(d \vartheta)\\
%p \exp\left(\frac{\bar\mu}{\sigma} z -\frac12 \left(\frac{\bar\mu}{\sigma}\right)^2 t\right)+(1-p)
%\exp\left(\frac{\underline\mu}{\sigma} z -\frac12 \left(\frac{\underline\mu}{\sigma}\right)^2 t\right)\\
%& = p \exp\left(\tilde\lambda^{\text{up}} z -\frac12 \left(\tilde\lambda^{\text{up}} \right)^2 t\right)+(1-p)
%\exp\left(\tilde\lambda^{\text{down}} z -\frac12 \left(\tilde\lambda^{\text{down}}\right)^2 t\right)
%\end{align*}
%i.e.
%\begin{align*}
%V(x_0) = x_0^\alpha \left( \int_{\R} F(T,z)^\gamma \varphi_T(z) dz\right)^{\tilde\gamma}
%\end{align*}

%\begin{lemma}[Maximal expected utility and optimal investment fraction]
%\label{lem_opt_inv}
%In the case of one risky asset and the a priori distribution of $\mu$ is given by {\it{$\overline\mu$ with probability $p$ and $\underline\mu$ with probability $1-p$}}.\\
%Let $\gamma = 1/(1-\alpha)$, $\varphi_T$ is the density of the normal distribution $\mathcal{N}(0,T)$ and
%\begin{align*}
% \hat F(t,T,Y(t))& :=\frac{ \int_{\R}
%F(T,z+Y(t),\underline\mu)
 %(F(T,z+Y(t)))^{\gamma-1}\varphi_{T-t}(z) dz}
% {\int_{\R} F(T,z+Y(t))^{\gamma}\varphi_{T-t}(z) dz}\\
%\text{and }
%  F(t,z,\mu) & := \exp\left(\frac{\mu}{\sigma} z -\frac12 %\left(\frac{\mu}{\sigma}\right)^2 t\right) \\
%  \text{ and }
%  F(t,z) & := p F(t,z,\bar\mu)+(1-p) F(t,z,\overline\mu)
%\text{ i.e. the expectation of $F(t,z,\dot)$}\end{align*}
%The maximal expect utility $V(x_0)$ attained in \eqref{eq:Bayesproblem_example}  is %given by
%\begin{align*}
%V(x_0) = x_0^\alpha \left( \int_{\R} F(T,z)^\gamma \varphi_T(z) %dz\right)^{\tilde\gamma}
%\end{align*}
%and the optimal fraction of wealth $\tilde\pi^*(t):= \frac{\pi^*(t)}{X(t)}$ is
%\begin{align*}
%\tilde\pi^*(t)
%& =  \frac{\bar\mu}{\tilde\gamma\sigma^2}-
%(1-p)\frac{\bar\mu-\underline\mu}{\tilde\gamma\sigma^2}\; \hat F(t,T,Y(t)).
%\end{align*}
%\end{lemma}

%\begin{proof}
%$V(x_0)$  follows immediately with Eqn. xxx. Along the lines of Eqn. xxx, the optimal fraction $\tilde\pi^*(t):=\frac{\pi^*(t)}{X^*(t)}$ invested in the stock $S$ is given by

%\begin{equation}
%\tilde\pi^*(t)%:=\frac{\pi^*(t)}{X^*(t)}
%= \frac{\gamma}{\sigma} \frac{ \int_{\R} %\nabla
% F_z(T,z+Y(t))(F(T,z+Y(t))^{\gamma-1}\varphi_{T-t}(z) dz}{\int_{\R} (F(T,z+Y(t))^{\gamma}\varphi_{T-t}(z) dz}
%\end{equation}
%Notice that $\tilde\gamma=\frac{1}{\gamma}$ and
%\begin{align*}
 % F_z(t,z) & =  p F_z(t,z,\bar\mu)+(1-p) F_z(t,z,\overline\mu)\\
%  & = p F(t,z,\bar\mu)\frac{\bar\mu}{\sigma}+(1-p) F(t,z,\underline\mu)\frac{\underline\mu}{\sigma}\\
%  %& = \frac{1}{\sigma}\left(p \bar\mu F(t,z,\bar\mu)+(1-p) \underline\mu F(t,z,\underline\mu)\right)\\
%%  & = \frac{\bar\mu}{\sigma}\left(p  F(t,z,\bar\mu)+(1-p) \frac{\underline\mu}{\bar\mu} F(t,z,\underline\mu)\right)\\
%%   & = \frac{\bar\mu}{\sigma}\left(p  F(t,z,\bar\mu)+(1-p)F(t,z,\underline\mu) -(1-p) \left(1-\frac{\underline\mu}{\bar\mu} \right)F(t,z,\underline\mu)\right)\\
%    & = \frac{\bar\mu}{\sigma}\left(F(t,z) -(1-p) \left(1-\frac{\underline\mu}{\bar\mu} \right)F(t,z,\underline\mu)\right)
%\end{align*}
%such that
%\begin{align*}
%\tilde\pi^*(t)%& :=\frac{\pi^*(t)}{X^*(t)}\\
%& =  \frac{\bar\mu}{\tilde\gamma\sigma^2}-(1-p)\frac{\bar\mu-\underline\mu}{\tilde\gamma\sigma^2} \frac{ \int_{\R}
%F(T,z+Y(t),\underline\mu)
% (F(T,z+Y(t)))^{\gamma-1}\varphi_{T-t}(z) dz}
% {\int_{\R} F(T,z+Y(t))^{\gamma}\varphi_{T-t}(z) dz}
% \end{align*}
%\end{proof}




%\section{Conclusion}\label{sec_conclusion}
%xxx

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%           APPENDIX                                      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Appendix}
\subsection{Duality results}\label{app:duality}
Throughout we assume here that $x_i\ge 0$ for all $i$.
\subsubsection{Dual representation of $L^\mathbf{p}$ norm}
Let $\mathbf{p},\mathbf{q} >1$ such that $1/\mathbf{p}+1/\mathbf{q}=1$ and $\mathfrak{Q}$ as defined in \eqref{eq:Qdef1}. We prove:
\begin{equation}
\left( \sum_{i=1}^m x_i^\mathbf{p} p_i\right)^{1/\mathbf{p}} = \sup_{(q_i)\in \mathfrak{Q}} \sum_{i=1}^m x_i q_i.
\end{equation}
First note that the constraint is a convex function in $(q_i)$ and the target function $$ \sup_{(q_i)\in \mathfrak{Q}} \sum_{i=1}^m x_i q_i =  -\inf_{(q_i)\in \mathfrak{Q}} \sum_{i=1}^m (-x_i) q_i$$ is linear, i.e. we have a convex optimization problem. The Lagrangian is given by
$$L((q_i),\eta) :=  \sum_{i=1}^m (-x_i) q_i  + \eta \left(  \sum_{i=1}^m \left(\frac{q_i}{p_i}\right)^\mathbf{q} p_i - 1 \right).$$
The Slater condition is satisfied and a KKT point will yield the optimal solution.
$$\frac{\partial}{\partial q_i} L((q_i),\eta)  = -x_i + \eta \mathbf{q} q_i^{\mathbf{q}-1} p_i^{1-\mathbf{q}} = 0 $$
if and only if $$q_i = \left( \frac{x_i}{\eta \mathbf{q}}\right)^{\frac{1}{\mathbf{q}-1}} p_i $$
In order to determine the Lagrange multiplier $\eta$ we set
$$ \sum_{i=1}^m \left( \frac{x_i}{\eta \mathbf{q}}\right)^{\mathbf{q}} p_i  =1.$$
The solution is given by
$$ \eta = \frac{1}{\mathbf{q}} \left( \sum_{i=1}^m x_i^\mathbf{p}  p_i \right)^{\frac{1}{\mathbf{p}}}>0. $$
Plugging this into the equation for $(q_i)$ gives
 $$q_i^* = x_i^\frac{1}{\mathbf{q}-1}\left( \sum_{j=1}^m x_j^\mathbf{p} p_j \right)^{-\frac{1}{\mathbf{q}}} p_i. $$
In order to check for the correct value we compute
$$  \sum_{i=1}^m x_i q_i^* = \left( \sum_{i=1}^m x_i^\mathbf{p} p_i\right)^{1/\mathbf{p}}   $$
which implies the statement.

\subsubsection{Dual representation for $0<\mathbf{p}<1$}
Again let $\mathbf{q}$ be  such that $1/\mathbf{p}+1/\mathbf{q}=1$ which implies $\mathbf{q}<0$ and let $\mathfrak{Q}$ be as defined in \eqref{eq:Qdef1}. 
 We prove:
\begin{equation}
\left( \sum_{i=1}^m x_i^\mathbf{p} p_i\right)^{1/\mathbf{p}} = \inf_{(q_i)\in \mathfrak{Q}} \sum_{i=1}^m x_i q_i.
\end{equation}
The constraint is convex and the target function linear.
The Lagrangian is given by
$$L((q_i),\eta) :=  \sum_{i=1}^m x_i q_i  + \eta \left(  \sum_{i=1}^m \left(\frac{q_i}{p_i}\right)^\mathbf{q} p_i - 1 \right).$$
The Slater condition is satisfied and a KKT point will yield the optimal solution.
$$\frac{\partial}{\partial q_i} L((q_i),\eta)  = x_i + \eta \mathbf{q} q_i^{\mathbf{q}-1} p_i^{1-\mathbf{q}} = 0 $$
if and only if $$q_i = \left( \frac{-x_i}{\eta \mathbf{q}}\right)^{\frac{1}{\mathbf{q}-1}} p_i $$
In order to determine the Lagrange multiplier $\eta$ we set
$$ \sum_{i=1}^m \left( \frac{-x_i}{\eta \mathbf{q}}\right)^\mathbf{p} p_i  =1.$$
The solution is given by
$$ \eta =  \frac{1}{\mathbf{q}}\left( \sum_{j=1}^m ( -x_j)^{\mathbf{p}}  p_j \right)^{\frac{1}{\mathbf{p}}}>0. $$
Plugging this into the equation for $(q_i)$ gives
 $$q_i^* = p_i (x_i)^{\frac{1}{\mathbf{q}-1}}  \left(   \sum_{j=1}^m   x_j^\mathbf{p}  p_j \right)^{-\frac{1}{\mathbf{q}}}. $$
In order to check for the correct value we compute
$$  \sum_{i=1}^m x_i q_i^* =  \left( \sum_{i=1}^m x_i^\mathbf{p} p_i\right)^{1/\mathbf{p}} $$
which implies the statement.

\subsubsection{Dual representation for $\mathbf{p}<0$}
Let $0<\mathbf{q}<1$ be  such that $1/\mathbf{p}+1/\mathbf{q}=1$ and
$$ \mathfrak{Q}' := \left\{ ( q_i)  : \sum_{i=1}^m \left(\frac{q_i}{p_i}\right)^\mathbf{q} p_i \ge 1, q_i\ge 0 \right\}.$$
 We prove:
\begin{equation}
\left( \sum_{i=1}^m x_i^\mathbf{p} p_i\right)^{1/\mathbf{p}} = \inf_{(q_i)\in \mathfrak{Q}'} \sum_{i=1}^m x_i q_i.
\end{equation}
The constraint is convex and the target function linear.
The Lagrangian is given by
$$L((q_i),\eta) :=  \sum_{i=1}^m x_i q_i  + \eta \left(1-  \sum_{i=1}^m \left(\frac{q_i}{p_i}\right)^\mathbf{q} p_i  \right).$$
The Slater condition is satisfied and a KKT point will yield the optimal solution.
$$\frac{\partial}{\partial q_i} L((q_i),\eta)  = x_i - \eta \mathbf{q} q_i^{\mathbf{q}-1} p_i^{1-\mathbf{q}} = 0 $$
if and only if $$q_i = \left( \frac{x_i}{\eta \mathbf{q}}\right)^{\frac{1}{\mathbf{q}-1}} p_i $$
In order to determine the Lagrange multiplier $\eta$ we set
$$ \sum_{i=1}^m \left( \frac{x_i}{\eta \mathbf{q}}\right)^\mathbf{p} p_i  =1.$$
The solution is given by
$$ \eta =  \frac{1}{\mathbf{q}}\left( \sum_{j=1}^m x_j^\mathbf{p}  p_j \right)^{\frac{1}{\mathbf{p}}}>0. $$
Plugging this into the equation for $(q_i)$ gives
 $$q_i^* = x_i^{\frac{1}{\mathbf{q}-1}} p_i  \left(   \sum_{j=1}^m x_j^\mathbf{p}  p_j \right)^{-\frac{1}{\mathbf{q}}}. $$
In order to check for the correct value we compute
$$  \sum_{i=1}^m x_i q_j^* =  \left( \sum_{i=1}^m x_i^\mathbf{p} p_i\right)^{1/\mathbf{p}}  $$
which implies the result.

\subsubsection{Summary of different cases}
For the following table let $$F(\pi):=  \left(  \EE \left[\left( \EE_\Theta [(X_T^\pi)^\alpha]\right)^{\lambda/\alpha} \right]\right)^{\alpha/\lambda}, \quad G(\pi,(q_i)) :=\sum_i \EE_{\vartheta_i} [(X_T^\pi)^\alpha] q_i . $$
Problem \eqref{eq:Aproblem} is equivalent to

$$\begin{array}{cc|c|c}
 & & \lambda >0 & \lambda < 0\\ \hline
  & \lambda/\alpha > 1 &  \sup_\pi F(\pi)  & \\
  & & = \sup_\pi \sup_{(q_i) \in \mathfrak{Q} }G(\pi,(q_i)) & \sup_\pi  F(\pi) \\
  \alpha >0 &&& \\
  & \lambda/\alpha < 1  & \sup_\pi F(\pi) & = \sup_\pi \inf_{(q_i) \in \mathfrak{Q}' } G(\pi,(q_i))\\
  & & = \sup_\pi \inf_{(q_i) \in \mathfrak{Q} } G(\pi,(q_i)) &\\ \hline
  & \lambda/\alpha > 1 &  & \inf_\pi  F(\pi)  \\
  &&  \inf_\pi F(\pi) & = \inf_\pi \sup_{(q_i) \in \mathfrak{Q} } G(\pi,(q_i)) \\
  \alpha < 0 && &\\
  && = \inf_\pi \inf_{(q_i) \in \mathfrak{Q}' } G(\pi,(q_i))  &  \inf_\pi  F(\pi) \\
  &\lambda/\alpha < 1 && = \inf_\pi \inf_{(q_i) \in \mathfrak{Q} } G(\pi,(q_i))\\ \hline

  \end{array}$$
  
  \vspace*{0.4cm}
  
  In all cases sup and inf can be interchanged.
  
\vspace*{1cm}


\subsection{Proof of Theorem \ref{theo:sensitivity}}\label{app:sensi}
Part a) follows directly by inspecting the expression in Theorem \ref{theo:Bayes}.

Next we prove b).
The optimal fraction invested in stock $i$ at time $t$ given observation $y\in\R$ can more explicitly be written as (we denote $(\sigma^\top)^{-1}=: \tilde{\sigma}$):
\begin{align}\label{eq:optimalpi} \kappa_i(t,T,y) = \gamma  \frac{\int_{\R^d} \sum_{k=1}^m (\tilde{\sigma})_i \cdot \vartheta_k p_k L_T(\vartheta_k,y+z) F(T,y+z)^{\gamma-1}\varphi_{T-t}(z)dz}{\int_{\R^d} F(T,y+z)^\gamma\varphi_{T-t}(z)dz}\end{align}
where $(\tilde{\sigma})_i \cdot \vartheta_k = \sum_{j=1}^d (\tilde{\sigma})_{ij}  \vartheta_{kj}$ and
$\varphi_T(z) = (2\pi T)^{-d/2} e^{- \|z\|^2/2T}$ is the density of $N(0,TI)$.

We will show the statement for $t=0$ and $y=0$. The proof of the general case is similar.
First suppose that $\alpha\in (0,1)$. Define for $k=1,\ldots, m$:
$$ f_k(T) := \frac{\int_{\R^d} p_k L_T(\vartheta_k,z) F(T,z)^{\gamma-1}\varphi_{T}(z)dz}{\int_{\R^d} F(T,z)^{\gamma}\varphi_{T}(z)dz}.$$
Obviously we have by definition of $L_T$ and $F$ that $0\le f_k(T)$ and $\sum_{k=1}^m f_k(T)=1$.  Thus, it is enough to show that $\lim_{T\to\infty} f_m(T)=1$. Let us now consider the following inequality where the integral in the last equation can be computed with the formula of the moment generating function of a multivariate normal distribution.
\begin{eqnarray*}
f_m(T) &\ge& \frac{\int_{\R^d} p_m L_T(\vartheta_m,z) (p_m L_T(\vartheta_m,z))^{\gamma-1}\varphi_{T}(z)dz}{\int_{\R^d} F(T,z)^\gamma\varphi_{T}(z)dz}\\
&=& \frac{\int_{\R^d}  (p_m L_T(\vartheta_m,z))^\gamma\varphi_{T}(z)dz}{\int_{\R^d} F(T,z)^\gamma\varphi_{T}(z)dz}= \frac{p_m^\gamma \exp\big(\frac12 \|\vartheta_m\|^2 T\gamma(\gamma-1)\big)}{\int_{\R^d} F(T,z)^\gamma\varphi_{T}(z)dz}.\end{eqnarray*}
We will show that the lower bound tends to $1$ for $T\to\infty$. In what follows we consider the denominator. We can write it as $\mathbb{E}[F(T,Z)^\gamma]$ with $Z\sim \mathcal{N}(0,TI)$. Let $A$ be an $(m,d)$-matrix with rows consisting of $\vartheta_1,\ldots,\vartheta_m$. Then $X:=AZ\sim \mathcal{N}(0,T AA^\top)$. In particular the marginal distribution is given by $X_j \sim \mathcal{N}(0,T \|\vartheta_j\|^2)$ and we can write
$$ \mathbb{E}[F(T,Z)^\gamma] = \mathbb{E}\Big[\Big( \sum_{k=1}^m p_k \exp(X_k -\frac12 \|\vartheta_k\|^2 T)\Big)^\gamma\Big].$$
Now let $\gamma\in \mathbb{Q},$ i.e.\  we can write $\gamma=\frac{n}{l}$. Recall that $\gamma = 1/(1-\alpha)>1$ in this case. Then we obtain with $\beta=(\beta_1,\ldots,\beta_m)\in\N_0^m$ and with the notation $|\beta|=\beta_1+\ldots +\beta_m$ and
$$ { n \choose \beta_1,\ldots, \beta_m} = \frac{n!}{\beta_1!\ldots \beta_m!} $$
using the multinomial formula that
\begin{eqnarray*}
&&\Big[\Big( \sum_{k=1}^m p_k \exp(X_k -\frac12 \|\vartheta_k\|^2 T)\Big)^n\Big]^\frac{1}{l} =\\
&&  \Big[ \sum_{|\beta|=n} { n \choose \beta_1,\ldots, \beta_m} p_1^{\beta_1}\exp\big(\beta_1 (X_1 -\frac12 \|\vartheta_1\|^2 T)\big)\ldots p_m^{\beta_m}\exp\big(\beta_m (X_m -\frac12 \|\vartheta_m\|^2 T)\big) \Big]^\frac{1}{l}.
\end{eqnarray*}
Now since $(x_1+\ldots +x_K)^\frac{1}{l} \le x_1^\frac{1}{l}+\ldots +x_K^\frac{1}{l}$ for $x_i\ge 0$ we further obtain
\begin{eqnarray*}
&&  \Big[ \sum_{|\beta|=n} { n \choose \beta_1,\ldots, \beta_m} p_1^{\beta_1}\exp\big(\beta_1 (X_1 -\frac12 \|\vartheta_1\|^2 T)\big)\ldots p_m^{\beta_m}\exp\big(\beta_m (X_m -\frac12 \|\vartheta_m\|^2 T)\big) \Big]^\frac{1}{l}\\
&\le &  \sum_{|\beta|=n} { n \choose \beta_1,\ldots, \beta_m}^\frac{1}{l} p_1^{\frac{\beta_1}{l}}\exp\big(\frac{\beta_1}{l} (X_1 -\frac12 \|\vartheta_1\|^2 T)\big)\ldots p_m^{\frac{\beta_m}{l}}\exp\big(\frac{\beta_m}{l} (X_m -\frac12 \|\vartheta_m\|^2 T)\big)\\
&=& p_1^\gamma \exp\big(\gamma (X_1 -\frac12 \|\vartheta_1\|^2 T)\big)+\ldots + p_m^\gamma \exp\big(\gamma (X_m -\frac12 \|\vartheta_m\|^2 T)\big)\\
&& +  \sum_{|\beta|=n \atop \beta_i\neq n} C_\beta\exp\big(\frac{\beta_1}{l} (X_1 -\frac12 \|\vartheta_1\|^2 T)+\ldots +\frac{\beta_m}{l} (X_m -\frac12 \|\vartheta_m\|^2 T)\big),
\end{eqnarray*}
for some constants $C_\beta$ which do not depended on $T$. The last summands can be written as
$$ \exp\big(\frac{\beta_1}{l} (\sqrt{T} \|\vartheta_1\| \tilde{X}_1 -\frac12 \|\vartheta_1\|^2 T)+\ldots +\frac{\beta_m}{l} (\sqrt{T} \|\vartheta_m\|  \tilde{X}_m -\frac12 \|\vartheta_m\|^2 T)\big) $$
with marginal distribution $\tilde{X}_i\sim \mathcal{N}(0,1)$. Since the function $$(x_1,\ldots,x_m) \mapsto \exp\big(\frac{\beta_1}{l} (\sqrt{T} \|\vartheta_1\| x_1 -\frac12 \|\vartheta_1\|^2 T)+\ldots +\frac{\beta_m}{l} (\sqrt{T} \|\vartheta_m\|  x_m -\frac12 \|\vartheta_m\|^2 T)\big) $$ is supermodular  (follows e.g.\ with Lemma 2.1 in \cite{bauerle1997inequalities}) we obtain with the Lorentz-inequality (see e.g. Lemma 2.4 a) in \cite{bauerle1997inequalities})
\begin{eqnarray*}
&&\mathbb{E}\Big[  \exp\big(\frac{\beta_1}{l} (\sqrt{T} \|\vartheta_1\| \tilde{X}_1 -\frac12 \|\vartheta_1\|^2 T)+\ldots +\frac{\beta_m}{l} (\sqrt{T} \|\vartheta_m\|  \tilde{X}_m -\frac12 \|\vartheta_m\|^2 T)\big)  \Big] \\
&\le & \mathbb{E}\Big[  \exp\big(\frac{\beta_1}{l} (\sqrt{T} \|\vartheta_1\| {X} -\frac12 \|\vartheta_1\|^2 T)+\ldots +\frac{\beta_m}{l} (\sqrt{T} \|\vartheta_m\|  {X} -\frac12 \|\vartheta_m\|^2 T)\big)  \Big]
\end{eqnarray*}
with the same random variable $X \sim \mathcal{N}(0,1)$.
Now taking the expectation and using the formula of the moment generating function of a normal distribution yields
\begin{eqnarray}
\nonumber&& \mathbb{E}[F(T,Z)^\gamma]   \le  p_1^\gamma \exp\big(\frac12 \|\vartheta_1\|^2 \gamma(\gamma-1) T)\big)+\ldots + p_m^\gamma \exp\big(\frac12 \|\vartheta_m\|^2\gamma(\gamma-1) T)\big)\\
\label{eq:ineqproof}&& +  \sum_{|\beta|=n \atop \beta_i\neq n} C_\beta\exp\Big(\frac12 T \Big[ (\|\vartheta_1\| \beta_1+\ldots + \|\vartheta_m\|\beta_m)^2 \frac{1}{l^2}-(\beta_1\|\vartheta_1\|^2+\ldots \beta_m \|\vartheta_m\|^2)\frac{1}{l}\Big]\Big).
\end{eqnarray}
Let us now consider the exponent in the last line for an arbitrary admissible $\beta$ without the factor $\frac12 T$ in front. Obviously we can choose numbers $\|\vartheta^*\| $ and $\|\bar{\vartheta}\| $ such that
\begin{eqnarray*}
\|\vartheta_1\| \beta_1+\ldots + \|\vartheta_m\|\beta_m &=& \|\bar{\vartheta}\|  |\beta|\\
\beta_1\|\vartheta_1\|^2+\ldots \beta_m \|\vartheta_m\|^2 &=& \|\vartheta^*\|^2  |\beta|.
\end{eqnarray*}
This implies
\begin{eqnarray*}
\|\vartheta^*\| &=& \sqrt{\frac{\beta_1}{ |\beta|}\|\vartheta_1\|^2+\ldots \frac{\beta_m}{ |\beta|} \|\vartheta_m\|^2}\\
&\ge & \frac{\beta_1}{ |\beta|}\|\vartheta_1\|+\ldots \frac{\beta_m}{ |\beta|} \|\vartheta_m\| = \|\bar{\vartheta}\|.
\end{eqnarray*}
Moreover we have that $\|\vartheta^*\| < \|\vartheta_m\|$ since at least two $\beta_i$ are non-zero. This implies
\begin{eqnarray*}
&&  (\|\vartheta_1\| \beta_1+\ldots + \|\vartheta_m\|\beta_m)^2 \frac{1}{l^2}-(\beta_1\|\vartheta_1\|^2+\ldots \beta_m \|\vartheta_m\|^2)\frac{1}{l}\\
&\le & \|\vartheta^*\|^2 \frac{ |\beta|^2}{l^2}-\|\vartheta^*\|^2 \frac{ |\beta|}{l}= \|\vartheta^*\|^2 \gamma(\gamma-1)<   \|\vartheta_m\|^2 \gamma(\gamma-1).
\end{eqnarray*}

This shows us that all summands of the upper bound are of the form $\exp(\frac12 Tc)$ with the largest $c= \|\vartheta_m\|^2  \gamma(\gamma-1)$. Thus we obtain
\begin{eqnarray*}
 1&\ge& \lim_{T\to\infty} f_m(T) \\
&\ge& \lim_{T\to\infty}  \frac{p_m^\gamma \exp\big(\frac12 T \|\vartheta_m\|^2 \gamma(\gamma-1)\big)}{\sum_k p_k^\gamma \exp\big(\frac12 T \|\vartheta_k\|^2 \gamma(\gamma-1) )\big)+\exp\big(\frac12T \|\vartheta^*\|^2 \gamma(\gamma-1)\big) \sum_{|\beta|=n \atop \beta_i\neq n} C_\beta}=1
 \end{eqnarray*}
which implies the statement for $\gamma\in \mathbb{Q}$. Since the expression is continuous in $\gamma$ we obtain the statement for all $\alpha\in (0,1)$.


Part c) The proof for the case $\alpha<0$ can be done similar. In this case we have to show that $\lim_{T\to\infty} f_1(T)=1$. Note that here $\gamma := \frac{1}{1-\alpha}\in (0,1).$ We start with the similar inequality
\begin{eqnarray*}
f_1(T) &\ge& \frac{\int_{\R^d} p_1 L_T(\vartheta_1,z) (p_1 L_T(\vartheta_1,z))^{\gamma-1}\varphi_{T}(z)dz}{\int_{\R^d} F(T,z)^\gamma\varphi_{T}(z)dz}\\
&=&  \frac{p_1^\gamma \exp\big(\frac12 \|\vartheta_1\|^2 T\gamma (\gamma-1)\big)}{\int_{\R^d} F(T,z)^\gamma\varphi_{T}(z)dz}\end{eqnarray*}
For the denominator we can use the same lines of inequality until \eqref{eq:ineqproof}.
Defining  $\|\vartheta^*\|$ in the same way we obtain $\|\vartheta^*\| > \|\vartheta_1\|$ and since $\gamma\in (0,1)$ that
$$ \|\vartheta^*\|^2 \gamma(\gamma-1)<   \|\vartheta_1\|^2 \gamma(\gamma-1).$$ Looking again for the highest exponents in the denominator we obtain the statement as in part b).

Part d) follows from the representation 
$$ \kappa_i(t,T,y) = \gamma \sum_{k=1}^m \tilde\sigma_i \cdot \vartheta_k f_k(T)$$
in the beginning of part b).

Part e) can be obtained by direct calculation.

\bibliographystyle{plainnat}
%\bibliographystyle{amsplain}
%\bibliographystyle{kluwerplus}
\bibliography{literature_BSA}
\end{document}


In the scenario dependent optimum, the  first order conditions are
\begin{align*}
  \tilde\pi_1 & = \frac{\mu_1-r}{\gamma\sigma_1^2}-\rho \tilde\pi_2\frac{\sigma_2}{\sigma_1}\\
  \tilde\pi_2 & =  \frac{\mu_2-r}{\gamma\sigma_2^2}-\rho \tilde\pi_1\frac{\sigma_1}{\sigma_2}
\end{align*}
such that
\begin{itemize}
  \item For $\rho=0$, the optimal weights are given by the one-dimensional Merton solution
  \item For $\rho<0$ ($\rho>0$), the optimal weight $\tilde\pi_1$ is increasing (decreasing) in $\tilde\pi_2$
\end{itemize}



%\begin{figure}[tb]
%	\begin{center}
%			{\bf{xxx}}
%		\end{center}
%	\begin{center}
%\includegraphics[width=0.45\textwidth]{plot_rho_m05.pdf}	
%\includegraphics[width=0.45\textwidth]{plot_rho_0.pdf}	
%\includegraphics[width=0.45\textwidth]{plot_rho_p05.pdf}	
%\end{center}		
%	\caption{For given inner scenario $ (\underline\mu_1,\bar\mu_2) = (0.05;0.04)$, the figures show the region for the outer scenario $(\bar\mu_1,\underline\mu_2)$ which imply that the worst case is given by the inner scenario.}\vspace*{0.15cm}
%	\label{Fig_comp_regions}
%\end{figure}
\bibliographystyle{apalike}
%\bibliographystyle{kluwerplus}
\bibliography{literature_BSA}
\end{document} 

%%%%%
%%%%%
%%%%%



\subsection{The classical Bayesian problem with one risky asset}
We first treat the classical Bayesian optimization problem \eqref{eq:Bayesproblem} with only one risky asset, i.e. $d=1.$ In this case 
\begin{eqnarray*}
d S(t) & =& S(t) \left[ \mu dt + \sigma dW(t)\right]
  = S(t)  \sigma \,dY(t),\\
 \text{ where } \, d Y(t) & =& \frac{\mu}{\sigma}\, dt +\,d W(t).
\end{eqnarray*}
In the first instance, assume that $\mu$ is a random variable with two values $\underline{\mu}<\bar\mu$ only. The corresponding market price of risk are denoted by  $\bar\vartheta=\bar\mu/{\sigma}$ and $\underline{\vartheta}=\underline\mu/{\sigma}$.
We assume that
\begin{equation}\label{eq:apriori_distribution}
     \PP(\mu=\bar\mu)=p \text{ and } \PP(\mu=\underline\mu)=1-p, \quad p\in(0,1).
\end{equation}
 Here, the optimization problem boils down to
\begin{equation}\label{eq:Bayesproblem_example}
V(x_0)= \sup_\pi \; p \EE_{\bar\mu} [u(X_T^\pi)] + (1-p) \EE_{\underline\mu} [u(X_T^\pi)].
\end{equation}
where $u(x)=\frac1\alpha x^{\alpha}.$
%For ease of notation we define for $z\in\R$ and $\vartheta\in\{\underline{\vartheta},\bar{\vartheta}\}$
%\begin{equation*}
%    L_t(\vartheta,z) := \left\{ \begin{array}{ll}
%       \exp{\big(z \vartheta-\frac12 
%       \vartheta^2 t\big)}  &  t>0\\
 %    1    & t=0.
%   \end{array}\right.
%\end{equation*}
In this case the function $F$ appearing in \eqref{eq:FL} is given by  $ F(t,z)  = p L_t(\bar\vartheta,z)+(1-p) L_t(\underline\vartheta,z)$. Let us further denote
\begin{equation*}
    \hat F(t,T,Y(t)) :=\frac{ \int_{\R}
L_T(\underline\vartheta,z+Y(t))
 (F(T,z+Y(t)))^{\gamma-1}\varphi_{T-t}(z) dz}
 {\int_{\R} (F(T,z+Y(t))^{\gamma}\varphi_{T-t}(z) dz}.
\end{equation*}
Then we can express the solution of \eqref{eq:Bayesproblem_example} more explicitly.

\begin{lemma}\label{lem_opt_inv}
In the case of one risky asset and  prior distribution of $\mu$  given by \eqref{eq:apriori_distribution}, the optimal investment fraction  $ \kappa(t,T,Y(t)):=\frac{\pi^*(t)}{X^*(t)}$  of the Bayesian problem \eqref{eq:Bayesproblem_example} can be written as follows.
%The maximal expect utility $V(x_0)$ attained in \eqref{eq:Bayesproblem_example}  is given by
%\begin{align*}
%V(x_0) = \frac1\alpha x_0^\alpha \left( \int_{\R} F(T,z)^\gamma \varphi_T(z) dz\right)^{\frac1\gamma}
%\end{align*}
%and the optimal fraction of wealth $ \frac{\pi^*(t)}{X(t)}$ is
    \begin{align*}
\kappa(t,T,Y(t))
& =  \gamma \frac{\bar\vartheta}{\sigma}-
(1-p)\gamma \frac{\bar\vartheta-\underline\vartheta}{\sigma}\; \hat F(t,T,Y(t)).
\end{align*}
\end{lemma}

\begin{proof}
From Theorem \ref{theo:Bayes} we know that the optimal fraction is given by:
\begin{equation}
\kappa(t,T,Y(t))
= \frac{\gamma}{\sigma} \frac{ \int_{\R} 
 F_z(T,z+Y(t))(F(T,z+Y(t))^{\gamma-1}\varphi_{T-t}(z) dz}{\int_{\R} (F(T,z+Y(t))^{\gamma}\varphi_{T-t}(z) dz}
\end{equation}
We obtain that
\begin{align*}
  F_z(t,z) & =  p \frac{\partial}{\partial z}L_t(\bar\vartheta,z)+(1-p) \frac{\partial}{\partial z} L_t(\underline\vartheta,z)\\
  & = p L_t(\bar\vartheta,z) \bar\vartheta+(1-p) L_t(\underline\vartheta,z) \underline\vartheta\\
    & = \bar\vartheta \left(F(t,z) -(1-p) \left(1-\frac{\underline\vartheta}{\bar\vartheta} \right)  L_t(\underline\vartheta,z)\right)
\end{align*}
which implies the result.
\end{proof}

\begin{remark}
From Lemma \ref{lem_opt_inv} it follows directly that we obtain
\begin{eqnarray}\nonumber
\kappa(t,T,Y(t)) &=& \gamma \frac{\bar\vartheta}{\sigma} \Big( 1-
(1-p)\hat F(t,T,Y(t))\Big) + \gamma \frac{\underline\vartheta}{\sigma}\; (1-p) \hat F(t,T,Y(t))\\ \label{eq:alphashare}
&=:& \gamma \frac{\bar\vartheta}{\sigma} \alpha(t,T,Y(t)) +\gamma \frac{\underline\vartheta}{\sigma} (1-\alpha(t,T,Y(t))
\end{eqnarray}
where $\alpha(t,T,Y(t))$ is defined in an obvious way. Moreover, it holds that $\alpha(t,T,Y(t))\in (0,1).$ This can be seen as follows:
Obviously $1-\alpha(t,T,Y(t))=(1-p) \hat F(t,T,Y(t)) \ge 0.$ To show that it is less or equal 1, recall the definition of $\hat F$ and note that
$(1-p) L_T(\underline\vartheta,z+Y(t))\le F(T,z+Y(t)).$ Thus, we can see from \eqref{eq:alphashare} that the optimal fraction is always a convex combination between the two 'extreme' Merton fractions $ \gamma \frac{\bar\vartheta}{\sigma} $ and $\gamma \frac{\underline\vartheta}{\sigma}.$
\end{remark}

Notice that the there are some special (benchmark cases) cases
\begin{itemize}
  \item $\hat F=0$ implies $\tilde\pi^*(t)=\frac{\bar\mu}{\tilde\gamma\sigma^2}$ (upper Merton solution, i.e. optimal strategy for $\mu=\bar\mu$)
  \item $\hat F=1$ implies $\tilde\pi^*(t)=p\;\frac{\bar\mu}{\tilde\gamma\sigma^2}
      +(1-p)\frac{\underline\mu}{\tilde\gamma\sigma^2} $ (average of the two Merton solutions)
    \item $\hat F=\frac{1}{1-p}$ implies $\tilde\pi^*(t)=\frac{\underline\mu}{\tilde\gamma\sigma^2}$ (lower Merton solution, i.e. optimal strategy for $\mu=\underline\mu$)
\end{itemize}
{\amcomment{
\begin{remark} Along the lines of BMBO (2022) (cf. Prop. 2 and 3 herein), the optimal pre-commitment strategy $\tilde\pi_T^{*,\text{pre}}$ (i.e. the optimal strategy when maximizing the expected utility w.r.t. an investment horizon $T$  over constant investment fractions) can be implicitly represented by
\begin{align*}
\tilde\pi_T^{*,\text{pre}}
& =  \frac{\bar\mu}{\tilde\gamma\sigma^2}-
(1-p)\frac{\bar\mu-\underline\mu}{\tilde\gamma\sigma^2}\; \frac{e^{\underline\mu\tilde\pi_T^{*,\text{pre}}(1-\tilde\gamma)T}}{p e^{\bar\mu\tilde\pi_T^{*,\text{pre}}(1-\tilde\gamma)T}
+(1-p)e^{\underline\mu\tilde\pi_T^{*,\text{pre}}(1-\tilde\gamma)T}}
 \end{align*}
 Notice that it holds $\lim_{T\rightarrow 0}\tilde\pi_T^{*,\text{pre}}=\frac{p\bar\mu+(1-p)\underline\mu}{\tilde\gamma\sigma^2}$ and $\lim_{T\rightarrow \infty}\tilde\pi_T^{*,\text{pre}}=\frac{\underline\mu}{\tilde\gamma\sigma^2}$ for $\tilde\gamma>1$.
\end{remark}}}

\begin{remark}[Standardization of $\hat F$]
  Notice that the upper bound of $\hat F$ depends on $p$. It is more convenient to consider the function $\alpha(T,z+Y(t))$ which solves
 \begin{align*}
  \tilde\pi^*(t)
& =  \alpha(T,z+Y(t))\frac{\bar\mu}{\tilde\gamma\sigma^2}+
(1-\alpha(T,z+Y(t)))\frac{\underline\mu}{\tilde\gamma\sigma^2}
\end{align*}
i.e. \begin{align*}
       1- \alpha(T,z+Y(t))& = (1-p)\hat F(t,T,Y(t)) \\
       \alpha(T,z+Y(t)) & = 1-(1-p)\hat F(t,T,Y(t))
     \end{align*}
     such that $1-\alpha\in [0,1]$ ($\alpha\in [0,1]$ respectively)
     \end{remark}

First, consider the special case that $t=0$ (where $Y(0)=0$), i.e. the initial investment fraction:
\begin{align*}
\tilde\pi^*(0)
& =  \frac{\bar\mu}{\tilde\gamma\sigma^2}-
(1-p)\frac{\bar\mu-\underline\mu}{\tilde\gamma\sigma^2}\; \hat F(0,T,0)
\end{align*}
where
\begin{align*}
 \hat F(0,T,0)& =\frac{ \int_{\R}
F(T,z,\underline\mu)
 (F(T,z))^{\gamma-1}\varphi_{T}(z) dz}
 {\int_{\R} F(T,z)^{\gamma}\varphi_{T}(z) dz}\\
 & = \frac{E\left[F(T,Z_T,\underline\mu)
 (F(T,Z_T))^{\gamma-1}\right]}{E[F(T,Z_T)^{\gamma}]}
 \end{align*}
 and $Z_T\sim N(0,T)$\\
 
 \subsection{Probabilty distortion in the ambiguity loving case}

\begin{lemma}[probability distortion in the ambiguity loving case]

In the ambiguity loving case, the investor replaces $p$ by $\tilde q$ where
\begin{align*}
  \tilde q & = \frac{q_1^*}{q_1^*+q_2(q_1^*)}\\
 \text{where } q_2(q_1) & := \left(
\frac{1- q_1^q\; p^{1-q}}{(1-p)^{1-q}}
\right)^{\frac{1}{q}}\\
  \text{and }q_1^*  & = \sup_{q_1:0\leq q_1\leq q_1^{\text{ub}}}\left\{  q_1
\EE_{\bar\mu} [(X_T^\pi)^{\alpha}] + q_2
\EE_{\underline\mu} [(X_T^\pi)^{\alpha}]
: \left(\frac{q_1}{p}\right)^q p+ \left(\frac{q_2}{1-p}\right)^q (1-p)= 1 \right\}\\
\text{where } q_1^{\text{ub}} & = \left(\frac{1}{p^{1-q}}\right)^{\frac{1}{q}},\;
  q  =\frac{1}{1-1/\nu}\; \nu  =\lambda/\alpha>1\;
\end{align*}
i.e. $\tilde q:=\frac{q^*_1}{q^*_1+q_2(q_1^*)}$ and $1-\tilde q$ defines a new probability measure on the outcomes $\bar\mu$, $\underline\mu$.
Now, we can simply replace $p$ (the success probability for $\bar\mu$) by $\tilde q$ and solve the problem without ambiguity.
\end{lemma}

\begin{proof}
 In the stylized setup, Eqn. xxx implies
\begin{align*}
&  \left(p
\left(\EE_{\bar\mu} [(X_T^\pi)^{\alpha}]\right)^{\nu} + (1-p)
\left(\EE_{\underline\mu} [(X_T^\pi)^{\alpha}]\right)^{\nu}
\right)^{\frac{1}{\nu}}\\
= &
\sup\left\{  q_1
\EE_{\bar\mu} [(X_T^\pi)^{\alpha}] + q_2
\EE_{\underline\mu} [(X_T^\pi)^{\alpha}]
: \left(\frac{q_1}{p}\right)^q p+ \left(\frac{q_2}{1-p}\right)^q (1-p)\le 1, q_i\ge 0 \right\}
\end{align*}
where
\begin{align*}
  \nu & =\lambda/\alpha>1\\
  q & =\frac{1}{1-1/\nu}
\end{align*}
Notice  we have to consider the set of tuples $(q_1,q_2)$ ($q_1\ge 0$ and $q_1\ge 0$) satisfying the condition
\begin{align*}
 \left(\frac{q_1}{p}\right)^q p+ \left(\frac{q_2}{1-p}\right)^q (1-p) & \le 1\\
 q_1^q\; p^{1-q}+q_2^q \;(1-p)^{1-q} & \le 1
\end{align*}
However,
$q_1\ge 0$ and $q_2\ge 0$ implies that the supremum is obtained for
\begin{align*}
  \left(\frac{q_1}{p}\right)^q p+ \left(\frac{q_2}{1-p}\right)^q (1-p) & = 1\\
 q_1^q\; p^{1-q}+q_2^q \;(1-p)^{1-q} & = 1
\end{align*}
Thus, we can set
\begin{align*}
% q_1=\left(\frac{1-q_2^q \;(1-p)^{1-q}}{p^{1-q}}\right)^{1/q}
q_2(q_1) := \left(
\frac{1- q_1^q\; p^{1-q}}{(1-p)^{1-q}}
\right)^{\frac{1}{q}}
\end{align*}
Recall that we need $q_2\geq 0$, i.e. ($q>0$)
\begin{align*}
  \left(
\frac{1- q_1^q\; p^{1-q}}{(1-p)^{1-q}}
\right)^{\frac{1}{q}} & \geq 0 \\
\leftrightarrow \frac{1- q_1^q\; p^{1-q}}{(1-p)^{1-q}}& \geq 0 \\
\leftrightarrow q_1^q\; p^{1-q} & \leq 1\\
\leftrightarrow q_1 & \leq \left(\frac{1}{p^{1-q}}\right)^{\frac{1}{q}}
\end{align*}
\end{proof}

\begin{figure}[tb]
	\begin{center}
			{\bf{xxx}}
		\end{center}
	\begin{center}
%			\includegraphics[width=0.6\textwidth]{plot_g2.pdf}	\includegraphics[width=0.6\textwidth]{plot_opt.pdf}	
\end{center}		
	\caption{XXX}\vspace*{0.15cm}
	\label{Fig_g2}
\end{figure}
\begin{corollary}
In te ambiguity loving case, it holds $\tilde q>p$.
\end{corollary}
\begin{proof}
Notice that for $g_1=p$ it holds
\begin{align*}
  g_1+g_2(g_1) & = g_1+ \left(
\frac{1- q_1^q\; p^{1-q}}{(1-p)^{1-q}}
\right)^{\frac{1}{q}}\\
 & = p+ \left(
\frac{1- p^q\; p^{1-q}}{(1-p)^{1-q}}
\right)^{\frac{1}{q}}=1
\end{align*}
i.e. $q_1=p$ implies $g_2=1-p$. In addition,
\end{proof}
%%%%%%%%%%%%%%%%%%%%%

\section{OLD: Sensitivities optimal strategy}


\subsection{Illustration and sensitivities savings rate}
To get some further intuition, compare the expected utility of the optimal strategy under learning (i.e. $V(x_0)$) with the expected utility implied by the Merton solutions corresponding to $\bar\mu$, $\underline\mu$ and the optimal strategy (mixture of the Merton solutions) without learning (cf. Branger/Becker/Mahayni/Offermann) and {\it{visionary}} (who knows the realization of $\mu$, i.e. upper bound $EU= p EU_{\bar\mu} [V_T^{\pi^{\text{Mer,$\bar\mu$}}}]+(1-p) EU_{\underline\mu} [V_T^{\pi^{\text{Mer,$\underline\mu$}}}]$)

For illustration, use certainty equivalent (savings rate, respectively)
where
\begin{align*}
  CE & =\left(V(x_0)\right)^{1/\alpha} \\
  \text{and } y & =\frac{1}{T}\ln CE
\end{align*}

Notice that the savings rate of the visionary is
\begin{align*}
 y^{\text{visio}}=\frac{1}{T}\ln\left(\frac{1}{2(1-\alpha)\sigma^2}(p \bar\mu^2 +(1-p)\underline\mu^2)\right)
\end{align*}

\begin{figure}[tb]
	\begin{center}
			{\bf{Impact of investment horizon on savings rate ($y$)}}
		\end{center}
	\begin{center}
			\includegraphics[width=0.45\textwidth]{plot_SR_a.pdf}
\includegraphics[width=0.45\textwidth]{plot_SR_b.pdf}			
\end{center}		
	\caption{For varying investment horizons $p$, the figures depict the optimal savings rates (thick line is learning, dashed line is pre-commitment, green is the visionary, red dashed upper Merton, gray dashed constant is lower Merton). The level of relative risk aversion is $\tilde\gamma=2$. The left plot is $p=0.5$, the right is $p=0.75$ }\vspace*{0.15cm}
	\label{Fig_comp_SR}
\end{figure}


Now, further discussions to do w.r.t. the impact of ambiguity aversion, i.e. replacing $p$ by $\dots$ (cf. )

%\subsection{Impact of ambiguity preferences}
%Now we are interested in an ambiguous averse/loving investor, i.e. instead of problem \eqref{eq:Bayesproblem} we consider for a second utility function $v(x)=x^\lambda, 0<\lambda <1$ the problem (see \cite{balter2021time})
%\begin{equation}\label{eq:Aproblem}
% \sup_\pi  v^{-1} \int v \circ u^{-1} \EE_\vartheta [u(X_T^\pi)] \PP(d\vartheta).
%\end{equation}
%In the above stylized setup, the optimization problem boils down to
%\begin{align*}
%& \sup_\pi v^{-1}\left(\; p v\left(u^{-1}\left(\EE_{\bar\mu} [u(X_T^\pi)]\right) \right)+ (1-p) v\left(u^{-1}\left(\EE_{\underline\mu} [u(X_T^\pi)]\right)\right)\right)\\
%&  \sup_\pi \left(\; p
%\left(\EE_{\bar\mu} [(X_T^\pi)^{\alpha}]\right)^{\frac{\lambda}{\alpha}} + (1-p)
%\left(\EE_{\underline\mu} [(X_T^\pi)^{\alpha}]\right)^{\frac{\lambda}{\alpha}}
%\right)^{\frac{1}{\lambda}}.
%\end{align*}
%More precisely in our case ($\alpha>0$) this is equivalent to
%\begin{equation}\label{eq:Aproblem2}
% \sup_\pi  \left(  \EE \left[\left( \EE_\Theta [(X_T^\pi)^\alpha]\right)^{\lambda/\alpha} \right]\right)^{\alpha/\lambda}
%\end{equation}
%i.e.
%\begin{align*}
%\sup_\pi \left(\; p
%\left(\EE_{\bar\mu} [(X_T^\pi)^{\alpha}]\right)^{\frac{\lambda}{\alpha}} + (1-p)
%\left(\EE_{\underline\mu} [(X_T^\pi)^{\alpha}]\right)^{\frac{\lambda}{\alpha}}
%\right)^{\frac{\alpha}{\lambda}}.
%\end{align*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%{\bf{Now}} notation $\nu=\lambda/\alpha>1$, then
%\begin{align*}
%\sup_\pi \left(\; p
%\left(\EE_{\bar\mu} [(X_T^\pi)^{\alpha}]\right)^{\nu} + (1-p)
%\left(\EE_{\underline\mu} [(X_T^\pi)^{\alpha}]\right)^{\nu}
%\right)^{\frac{1}{\nu}}.
%\end{align*}
%notice now that the $L^\nu$ norm has the following dual representation for a r.v. $X\ge 0$, where $1/\nu+1/q=1$ ($1/q=1-(1/\nu)$, $q=\frac{1}{1-1/\nu}$)
%\begin{equation}
%\| X\|_{\nu} = \sup\left\{ \int X d \Q : \left\| \frac{d\Q}{d\PP}\right\|_q \le 1 \right\}.
%\end{equation}
%For a r.v. $X$ with values $\{x_1,\ldots,x_m\}$ we can write
%\begin{equation}
%\left( \sum_{i=1}^m x_i^{\nu} p_i\right)^{1/\nu} = \sup\left\{ \sum_{i=1}^m x_i q_i  : \sum_{i=1}^m \left(\frac{q_i}{p_i}\right)^q p_i \le 1, q_i\ge 0 \right\}.
%\end{equation}
%i.e. for the problem above this reads $m=2$
%\begin{align*}
%&  \left(p
%\left(\EE_{\bar\mu} [(X_T^\pi)^{\alpha}]\right)^{\nu} + (1-p)
%\left(\EE_{\underline\mu} [(X_T^\pi)^{\alpha}]\right)^{\nu}
%\right)^{\frac{1}{\nu}}\\
%= &
%\sup\left\{  q_1
%\EE_{\bar\mu} [(X_T^\pi)^{\alpha}] + q_2
%\EE_{\underline\mu} [(X_T^\pi)^{\alpha}]
%: \left(\frac{q_1}{p}\right)^q p+ \left(\frac{q_2}{1-p}\right)^q (1-p)\le 1, q_i\ge 0 \right\}
%\end{align*}
%Note that the set consists of measures, not necessarily probability measures.
%This gives rise to the following formulation of our problem:
%\begin{equation}\label{eq:Aproblem4}
% \sup_\pi  \left\| \EE_\Theta [(X_T^\pi)^\alpha]\right\|_{\nu} =
% \sup_\pi  \sup_{\Q \in \mathfrak{Q}} \EE_Q \EE_\Theta [(X_T^\pi)^\alpha]=  \sup_{\Q \in \mathfrak{Q}} \sup_\pi   \EE_Q \EE_\Theta [(X_T^\pi)^\alpha].
%\end{equation}
%After normalizing $\Q$, the inner optimization problem is however, exactly the Bayesian portfolio problem of the previous section with distribution $\tilde\Q:= \Q/ \Q(\R)$ for the unknown parameter. Finding the optimal $\Q^*$ in a second step solves the problem.\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Comments on multi asset case}
\subsection{Worst case drift}
Recall that the worst case drift scenario is the one where the investor obtains (in the optimum) the lowest CE (savings rate, respectively). ({\it{check assumptions which are to be posed}})\\
\\
Thus, we can compare the savings rates for different drift scenarios. For simplicity, assume two risky assets.
Recall Merton solution for two risky assets (given the drift scenario $(\mu_1,\mu_2)$ where $\mu_i$ denotes the drift of asset $i$ ($i=1,2$)):\\
The optimal investment fractions (of a CRRA investor) are
\begin{align*}
\tilde\pi_1^{*} & = \frac{1}{1-\rho^2}\left(\frac{\mu_1}{\gamma\sigma_1^2}-\rho\frac{\mu_2}{\gamma\sigma_1\sigma_2}\right),\quad
\tilde\pi_2^{*}  =\frac{1}{1-\rho^2}\left(\frac{\mu_2}{\gamma\sigma_2^2}-\rho\frac{\mu_1}{\gamma\sigma_1\sigma_2}\right).
\end{align*}
The expected utility is
\begin{align*}
E[  u(V_T) ] & =  \frac{x_0^{1-\tilde\gamma}}{1-\tilde\gamma} e^{(1-\tilde\gamma)\left[\mu^{\text{PF}}-\frac{1}{2}\tilde\gamma Var^{\text{PF}}\right]T}\\
\text{where }
\mu^{\text{PF}} & = \tilde\pi_1 \mu_1+\tilde\pi_2 \mu_2\\%+(1-\pi_1-\pi_2)r\\
 Var^{\text{PF}} & = \tilde\pi_1^2\sigma_1^2+\tilde\pi_2^2\sigma_2^2+2 \tilde\pi_1 \tilde\pi_2\rho\sigma_1\sigma_2.
\end{align*}
The
certainty equivalent $CE$ ($x_0=1$) is thus given by
 \begin{align*}%\label{eqn_CE_CM_MA}
CE:=u^{-1}\left( E[V_T]\right)%& =e^{(m \bar\mu -\frac{1}{2}\gamma m^2 \sigma^2)T+\frac{1}{2}(1-\eta)\sigma_{\mu}^2 m^2 T^2}\nonumber\\
& =
 e^{\left[\mu^{\text{PF}}-\frac{1}{2}\gamma Var^{\text{PF}}\right]T}
\end{align*}
and savings rate $y$
\begin{align*}
 y & = \mu^{\text{PF}}-\frac{1}{2}\gamma Var^{\text{PF}}
\end{align*}
In the optimum (given $\mu_1$ and $\mu_2$)
\begin{align*}
  y^* & = y(\tilde\pi_1^*,\tilde\pi_1^*) =\frac{1}{\gamma}\left[(c_1-\frac{1}{2}c_1^2)\tilde\lambda_1^2
  +(c_2-\frac{1}{2}c_2^2)\tilde\lambda_2^2-\rho c_1 c_2 \tilde\lambda_1\tilde\lambda_2
  \right]\\
  \text{where } c_1 & := \frac{1-\rho \frac{\tilde\lambda_2}{\tilde\lambda_1}}{1-\rho^2},\; c_2=\dots\\
  and \tilde\lambda_i & = \frac{\mu_i}{\sigma_i}
\end{align*}
For $\mu_1>\mu_2$ we have to assume
\begin{align*}
 \sigma_1>\sigma_2
\end{align*}
Now consider the following realizations of $(\mu_1,\mu_2)$ where $\mu_1>\mu_2$ (i.e. $\underline\mu_2<\bar\mu_2<\underline\mu_1<\bar\mu_1$):
\begin{align*}
  & (\bar\mu_1,\bar\mu_2)   \\
  & (\bar\mu_1,\underline\mu_2)\\
  & (\underline\mu_1,\bar\mu_2)\\
  & (\underline\mu_1,\underline\mu_2)
\end{align*}
This is not interesting since it is obvious that the worst case drift is $(\underline\mu_1,\underline\mu_2)$. Thus,
the interesting case is to reduce the set of realizations to
\begin{align*}
  & (\bar\mu_1,\underline\mu_2)   \\
  & (\underline\mu_1,\bar\mu_2)
\end{align*}
such as e.g.
\begin{align*}
   (\bar\mu_1,\underline\mu_2) & =(0.06;0.02) \\
  (\underline\mu_1,\bar\mu_2)& = (0.05;0.04).
\end{align*}
First, consider the special case that $\rho=0$. Here, for given $(\mu_1,\mu_2)$ it holds
\begin{align*}
 y^*(\mu_1,\mu_2)= \frac{1}{2\gamma}\left[\left(\frac{\mu_1}{\sigma_1}\right)^2+
 \left(\frac{\mu_2}{\sigma_2}\right)^2
 \right]
\end{align*}

\begin{lemma}[Worst case drift scenario ($\rho=0$)]
For $\rho=0$ and two possible drift scenarios $(\bar\mu_1,\underline\mu_2)$ and
$(\underline\mu_1,\bar\mu_2)$ ($\underline\mu_2<\bar\mu_2<\underline\mu_1<\bar\mu_1$) the worst case drift scenario is implied by
\begin{align*}
  \min\left\{ y^*(\overline\mu_1,\underline\mu_2), y^*(\underline\mu_1,\overline\mu_2)\right\}= \min\left\{ \left(\frac{\overline\mu_1}{\sigma_1}\right)^2+
 \left(\frac{\underline\mu_2}{\sigma_2}\right)^2, \left(\frac{\underline\mu_1}{\sigma_1}\right)^2+
 \left(\frac{\overline\mu_2}{\sigma_2}\right)^2\right\}
\end{align*}
\end{lemma}
Thus, for $\rho=0$,
the worst case drift scenario is given by the combination with the lowest sum of squared market price per unit of risk ($\tilde\lambda=\frac{\mu}{\sigma}$) of the assets. However, the answer is more demanding for $\rho\neq 0$, (cf. Figure \ref{Fig_rho_1}).\\
\\
\begin{figure}[tb]
	\begin{center}
			{\bf{Savings rates for varying $\rho$}}
		\end{center}
	\begin{center}
%			\includegraphics[width=0.45\textwidth]{plot_rho.pdf}	
%\includegraphics[width=0.45\textwidth]{plot_rho_norm.pdf}	
\end{center}		
	\caption{The left figure depicts, for varying $\rho$, the  (optimal) savings rate where the outer scenario is $(\bar\mu_1,\underline\mu_2) =(0.06;0.02)$ (black) and the inner scenario  is $ (\underline\mu_1,\bar\mu_2) = (0.05;0.04)$ (dashed). The right plot refers to the same inner scenario, but the outer scenario is determined such that the savings rates are equal for $\rho=0$. For $\rho<0$, the worst case is implied by the highest value of $\bar\mu_1$ while for $\rho>0$, the worst case is implied by the lowest value of $\bar\mu$.}\vspace*{0.15cm}
	\label{Fig_rho_1}
\end{figure}
Throughout the following, we refer to the drift scenario given by
$(\bar\mu_1,\underline\mu_2)$ as the outer scenario while we call  $ (\underline\mu_1,\bar\mu_2)$ the inner scenario. Intuitively, the relevant question is which scenario benefits (suffers) more from a high (low) correlation coefficient $\rho$.
\begin{lemma}[Worst case drift scenario ($\rho\neq 0$)]
Let $(\bar\mu_1,\underline\mu_2)$ and  $ (\underline\mu_1,\bar\mu_2)$ implicitly defined by
\begin{align*}
\left(\frac{\overline\mu_1}{\sigma_1}\right)^2+
 \left(\frac{\underline\mu_2}{\sigma_2}\right)^2= \left(\frac{\underline\mu_1}{\sigma_1}\right)^2+
 \left(\frac{\overline\mu_2}{\sigma_2}\right)^2
 \end{align*}
 Then, the worst case is implied by the highest value of $\bar\mu_1$ while for $\rho>0$, the worst case is implied by the lowest value of $\bar\mu_1$.
\end{lemma}