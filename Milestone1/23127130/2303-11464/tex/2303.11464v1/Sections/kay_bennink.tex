\section{An Application of Probabilistic Combinatorics to Quantum Circuit Expressiveness}\label{sec:kay}
\begin{flushright}
{\it Bill Kay, Ryan Bennink}
\end{flushright}

\mySub{Introduction}
%\paragraph*{\it{\textbf{Introduction}}}
\label{sec:intro}
Quantum computing is a computing system in which certain physical properties are leveraged for computational advantages for some classes of problems. Recently, access to some quantum computing devices has grown. Many of the accessible devices are small and noisy, and the {\em variational approach} in which a traditional computer modifies parameters of some quantum circuit towards maximizing a function of its output has found success~\cite{mcclean2016theory,magann2021pulses,yuan2019theory}. %(\textbf{CITATIONS from bennink)}.
The purpose of this document is to introduce a purely combinatorial problem, and to explain how it is related to a problem in quantum computing. We note that we are casting the analysis in~\cite{bennink} to a probabilistic setting regarding random binary vectors. Hence, progress in the combinatorial problem has an interpretation which impacts quantum computing.  We then present a sequence of examples, preliminary results, and open questions. 

Commutative quantum circuits, originally introduced as ``Instantaneous Quantum Polytime'' circuits \cite{Shepherd2009}, are a special class of quantum circuits that are relatively simple yet exhibit non-trivial quantum behavior.  For our purposes a commutative quantum circuit may be described as a circuit that first creates a uniform superposition of all $2^n$ computational states of $n$ qubits, then applies parity-dependent phases to selected subsets of qubits. Each subset is specified by a binary vector $a \in \{0,1\}^n$ and its associated phase is specified by a real angle $\theta$. 

\begin{definition}[Commutative Quantum Circuit]
\label{cqc}
A commutative quantum circuit specified by the binary vectors $a_1, \ldots,a_m \in \{0,1\}^n$ and associated parameters $\theta_1, \ldots, \theta_m \in \mathbb{R}$ creates a quantum state of the form
 \[
 \frac{1}{2^{n/2}} \left( \mathrm{e}^{\mathrm{i} \phi_{0 \ldots 0}}, \ldots, \mathrm{e}^{\mathrm{i} \phi_{1 \ldots 1}} \right) \in \mathbb{C}^{2^n}
 \]
\noindent where
\[
\phi_x = \sum_{i=1}^{m} \theta_i (-1)^{\langle a_i, x \rangle}
\]
and $\langle \cdot, \cdot \rangle$ denotes the inner product in GF(2)$^n$.
\end{definition}

In the context of variational quantum computing, the vectors $a_1,\ldots,a_m$ specify a fixed circuit structure and the angles $\theta_1, \ldots, \theta_m$ are the variational parameters.
A fundamental question concerns the \emph{expressiveness} of such: given the vectors $a_1, \ldots, a_m$, how much can the output state be varied by varying the angles  $\theta_1, \ldots, \theta_m$?  Intuitively, the expressiveness can be quantified by the expected (dis)similarity of two output states with randomly chosen parameter values: the more expressive the circuit, the more likely two random output states will be dissimilar.  As discussed in \cite{bennink}, for commutative quantum circuits this expectation value can be reduced to a combinatoric problem involving binary matrices described below. 
There it is shown that in the special case that the circuit is maximal, i.e.\ there is an independent phase for each nonempty subset of qubits, the expressiveness reduces to the problem of counting {\em abelian squares}.  Here we consider the more general problem of computing the expressiveness of commutative quantum circuits involving arbitrary collections of qubit subsets. In the next section we cast this problem in purely combinatorial language. We conclude with some examples, special cases, and open problems. 



%conventional computers vary parameters of a  

 %In the companion article (Bennink- ounting Abelian Squares Efficiently for a Problem
%in Quantum Computing), it is shown that expressiveness of a maximal commutative circuit is equivalent to counting of abelian squares. 

\mySub{A Combinatorial Problem}
\label{sec:acp}
In this section we will have several definitions where prescribed notations will aid in clarity. Here we fix several such notations for the section for ease of exposition. Fix $ n, t \in \mathbb{Z}^+$ and let $1 \leq m \leq 2^n - 1$. 

\begin{itemize}
    \item Let $\mathbf{x} = (x_1^T, \ldots, x_t^T)$ where $x_i \in \{0,1\}^n$ for $1 \leq i \leq t$.
    \item  Let $\mathbf{y} = (y_1^T, \ldots, y_t^T)$ where $y_i \in \{0,1\}^n$ for $1 \leq i \leq t$. 
    \item $\mathbf{A} = (a_1^T, \ldots, a_m^T)$ where $a_i \in \{0,1\}^n$ for $1 \leq i \leq m$. Moreover, the $\{a_i\}_{i=1}^m$ are non-zero and pairwise distinct.
\end{itemize}

For clarity,  $\mathbf{x}$ and $\mathbf{y}$ are $n \times t$ binary matrices with specified column labels, and $\mathbf{A}$ is an $n \times m$ binary matrix with {\em distinct, non-zero} columns with specified labels. For our specific application, we take the columns of $\mathbf{A}$ to be given in lexicographic order. We remark that each $a_i$ is a length $n$ binary vector and has a natural correspondence with subsets of indices of length $n$ vectors. 

We now need the following definition:
\begin{definition}[Expressiveness Indicator]
Given $\mathbf{A}, \mathbf{x}$ as above and $1 \leq i \leq m$, we define the $i$th {\em expressiveness indicator} $m_i^\mathbf{A} (\cdot)$ as:
\[
m_i^\mathbf{A} (\mathbf{x}) := \sum_{j = 1}^t \langle a_i, x_j\rangle_2
\]
where the inner product $\langle \cdot, \cdot\rangle_2$ is {\em mod } $2$ but the outer sum is integral. 
\end{definition}
When $\mathbf{A}$ is clear from context we simply write $m_i(\cdot)$. As these are not standard definitions, and there is a mix of modular and integral arithmetic,  we include a clarifying example:

\begin{example}
Let
\[
\mathbf{A} = 
\begin{pmatrix}
1 & 0 & 0 & 0&1&1&1\\
0 & 1 & 0 & 0&1&0&0\\
0 & 0 & 1 & 0&0&1&0\\
0 & 0 & 0 & 1&0&0&1

\end{pmatrix};
\mathbf{x} = 
\begin{pmatrix}
1 & 0 & 1 & 0\\
1 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1\\

\end{pmatrix}
\]
 Then we have:
\begin{align*}
    m_5(\mathbf{x}) &= \langle a_5, x_1\rangle_2 + \langle a_5, x_2\rangle_2 +\langle a_5, x_3\rangle_2 +\langle a_5, x_4\rangle_2\\
    & = 0 + 1 + 1 + 0\\
    & = 2
\end{align*}
\end{example}

We are now ready to pose a general combinatorial question and relate it back to computing expressiveness of commutative  quantum circuits.

\begin{comp_problem}
Given $\mathbf{A}$,  let $\mathbf{x}$ and $\mathbf{y}$ be sampled uniformly at random. Compute:
\[
\mathbb{P}\left( (m_i(\mathbf{x}) = m_i(\mathbf{y})) \ \forall i \right) 
\]
\end{comp_problem}

While the Computational Problem is interesting in its own right, we would like to clarify how it is related to computing expressiveness of commutative quantum circuits. Recall from Definition~\ref{cqc} that the expressiveness of a commutative quantum circuit takes as input a collection of subsets of indices of a state vector. Further, we have remarked that for a length $n$ state vector, there is a natural correspondence between a subset of indices and binary length $n$ vectors (namely, the indicator vector of which indices are selected). Indeed, one can see in the analysis in~\cite{bennink} that if we encode the subsets of indices in the state vector we are interested in as $\mathbf{A}$, then the computation given in Computational Problem is the critical computation for finding the desired expressiveness. In particular, it is shown that expressiveness of {\em maximal} commutative quantum circuits is equivalent to taking $\mathbf{A}$ to be all $2^n -1$ non-zero length $n$ binary vectors, and that the probability in Computational Problem is precisely resolved by counting abelian squares. 





\mySub{Examples, Preliminary Results, and Open Problems}

Notice that for each choice of $\mathbf{A}$, there is a different instance of Computational Problem. For some fixed choices of $\mathbf{A}$, there is a natural interpretation of Computational Problem. 

\begin{example}
Let $\mathbf{A}$ be the collection of all weight 1 length $n$ vectors (i.e., the $n \times n$ identity matrix). Let $\mathbf{x}$ and $\mathbf{y}$ be $n \times t$ binary matrices. Then 
\[
 (m_i(\mathbf{x}) = m_i(\mathbf{y})) \ \forall i 
\]
if and only if $\mathbf{x}$ and $\mathbf{y}$ have the same row sums. 
\end{example}

This is clear, as $\langle a_j, x_i\rangle_2 = 1$ if and only if $x_i$ is $1$ in coordinate $j$. Using this combinatorial interpretation, we can resolve Computational Problem when $\mathbf{A}$ is the $n \times n$ identity matrix  by the following (equivalent) lemma:

\begin{lemma}
\label{l1}
Let $\mathbf{x}$ and $\mathbf{y}$ be $n \times t$ binary matrices sampled uniformly at random. Then the probability that $\mathbf{x}$ and $\mathbf{y}$ have all the same row sums is 
\[
\binom{2t}{t}^n\frac{1}{2^{2tn}}.
\]
\end{lemma}

\begin{proof}
We will argue for a single pair of uniform random binary vectors of length $t$. Since we are computing row sums for $\mathbf{x}$ and $\mathbf{y}$, we argue first  for a fixed row and conclude by taking a product of independent probabilities. Summing over possible row sums, the probability that a pair of length $t$ binary vectors have the same row sum is given by:
\begin{align*}
\sum_{k=0}^t \binom{t}{k}^2 (1/2)^{2k}(1/2)^{2(t-k)} &=\frac{1}{2^{2t}}\sum_{k=0}^t \binom{t}{k}^2 \\
& = \frac{1}{2^{2t}}\sum_{k=0}^t\binom{t}{k}\binom{t}{t-k}\\
& = \frac{1}{2^{2t}} \binom{2t}{t}
\end{align*}
 where the last equality can be seen by counting the number of length $2t$ binary vectors with precisely $t$ ones. The right hand side counts this quantity directly, while the left hand side counts the number of ways for $k$ ones in the first half with $t-k$ ones in the second half. Taking the product over all $n$ (independent)  rows of $\mathbf{x}$ and $\mathbf{y}$ gives the desired probability. 
\end{proof}

Each column of $\mathbf{A}$ provides an additional constraint on possible choices of $\mathbf{x}$ and $\mathbf{y}$ in Computational Problem. In fact, the collections of $(\mathbf{x},\mathbf{y})$ pairs which satisfy the computation in Computational Problem are {\em monotone} in the columns of $\mathbf{A}$, in that if the set of columns $\mathbf{A}_2$ contains the set of columns of  $\mathbf{A}_1$, then 
\[
 (m_i^{\mathbf{A}_2}(\mathbf{x}) = m_i^{\mathbf{A}_2}(\mathbf{y})) \ \forall i \Rightarrow (m_i^{\mathbf{A}_1}(\mathbf{x}) = m_i^{\mathbf{A}_1}(\mathbf{y})) \ \forall i.
\]

For example, if  $\mathbf{A}$ has among its  columns all weight $1$ length $n$ vectors, if $\mathbf{x}$ and $\mathbf{y}$ satisfy the condition in Computational Problem then $\mathbf{x}$ and $\mathbf{y}$ necessarily have the same row sums. We provide combinatorial interpretation of Computational Problem for another choice of $\mathbf{A}$, and then exploit the monotonicity property to state and prove Computational Problem for another choice of $\mathbf{A}$. 

\begin{example}
\label{e2}
Let $a_{i,j}$ be the length $n$ binary vector with a $1$ in positions $i$ and $j$, $0$ otherwise. Let $x$ be any length $n$ binary vector. $\langle a_{i,j}, x \rangle_2$ is $1$ if the $i$th and $j$th entries of $x$ disagree, $0$ otherwise. We call this an {\em $i,j$-mismatch} in $x$. Hence, if $\mathbf{A}$ consists of all length $n$ binary vectors of weight at most $2$, and  $\mathbf{x}$ and $\mathbf{y}$ are $n \times t$ binary matrices, then 
\[
 (m_i(\mathbf{x}) = m_i(\mathbf{y})) \ \forall i 
\]
if and only if $\mathbf{x}$ and $\mathbf{y}$ have the same row sums, and for each pair of rows $i$ and $j$  the number of columns in which $\mathbf{x}$ and $\mathbf{y}$ have an $i,j$-mismatch are the same.
\end{example}

Computational Problem for the family presented in Example~\ref{e2} remains open. However, we present the following:

\begin{lemma}
\label{l2}
Let $\mathbf{A}$ be the collection of binary vectors weight $1$ and weight $2$ with a $1$ in the first coordinate. Let $\mathbf{x}$ and $\mathbf{y}$ be $n \times t$ binary matrices sampled uniformly at random. Then:
\[
\mathbb{P}\left( (m_i(\mathbf{x}) = m_i(\mathbf{y})) \ \forall i \right) 
\]

is given by:

\[
\frac{1}{2^{2tn}} \sum_{k = 0}^t \left(\binom{2k}{k} \binom{2(t-k)}{t-k}\right)^{n-1}\binom{t}{k}^2
\]
\end{lemma}

\begin{proof}
 For $\mathbf{x}$ and $\mathbf{y}$ sampled uniformly at random, we want to compute the probability  that $\mathbf{x}$ and $\mathbf{y}$ have the same row sums, and for each $ 1 < j \leq n$,  the number columns which have a $1,j$-mismatch is the same. We claim that 
 \[
\sum_{k=0}^t \binom{t}{k}^2\left(\sum_{j = 0}^k \sum_{\ell = 0}^{t-k} \binom{k}{j}^2 \binom{t-k}{\ell}^2\right )^{n-1} 
 \]
counts the number of $(\mathbf{x}, \mathbf{y})$ pairs for which 
\[
 (m_i(\mathbf{x}) = m_i(\mathbf{y})) \ \forall i  
\]
 holds. We now count such pairs. First, fix a first row for each of $\mathbf{x}$ and $\mathbf{y}$. Since the row sums must be the same, these first rows have some number of $1$s, say $k$. For each row $1< r\leq n$, there are some number of $1$s in $\mathbf{x}$ and $\mathbf{y}$. Since the row sums are the same for $\mathbf{x}$ and $\mathbf{y}$, this number is the same. We note that $\mathbf{x}$ and $\mathbf{y}$ need to have the same number of $1,r$ matches as well as mismatches, and this can be counted by enumerating the number of ways to place $1$s in columns with a $1$ in the first entry, and then columns with $0$ in the first entry. There are $j + \ell$ 1s in row $r$, with $j$ in columns with $1$ in the first entry and $\ell$ in columns with $0$ in the first entry. Hence, for each fixed choice of $j$ and $\ell$ there are
\[
 \binom{k}{j}^2 \binom{t-k}{\ell}^2
\]
ways to place these $1$s. Summing over choices of $j$ and $\ell$ we see that for each fixed pair of first rows for $\mathbf{x}$ and $\mathbf{y}$ there are
\[
\sum_{j=0}^k \sum_{\ell = 0}^{t-k} \binom{k}{j}^2 \binom{t-k}{\ell}^2
\]
choices to place the $1$s in row $r$. These choices are independent for rows $1 < r \leq n$, and so there are 
\[
\left(\sum_{j=0}^k \sum_{\ell = 0}^{t-k} \binom{k}{j}^2 \binom{t-k}{\ell}^2\right)^{n-1}
\]
choices for $\mathbf{x}$ and $\mathbf{y}$ for a fixed first row. For each $k$, there are $\binom{t}{k}$ ways to place $1$s in the first row of $\mathbf{x}$ and $\mathbf{y}$. Summing over each $k$, the total number of desired $(\mathbf{x},\mathbf{y})$ pairs is
\[
\sum_{k=0}^t \binom{t}{k}^2\left(\sum_{j=0}^k \sum_{\ell = 0}^{t-k} \binom{k}{j}^2 \binom{t-k}{\ell}^2\right)^{n-1}
\]

Applying analysis similar to that in the proof of Lemma~\ref{l1} shows that this is 
\[
\sum_{k = 0}^t \left(\binom{2k}{k} \binom{2(t-k)}{t-k}\right)^{n-1}\binom{t}{k}^2
\]
There are $2^{2tn}$ total possible pairs $(\mathbf{x},\mathbf{y})$, and dividing through yields the claim in the statement of Lemma~\ref{l2}. 

%For such a pair, since the row sums are the same, the first row has some number of $1$s in the first row, say $k$. For each placement of $1$s in the first row of both $\mathbf{x}$ and $\mathbf{y}$, for each other row there are some number of $1$s ($j+ \ell$).  

\end{proof}

The methods in the proofs of Lemmas~\ref{l1} and~\ref{l2} depend on row-wise independence. However, these methods do not directly extend to $\mathbf{A}$ for, say, all  binary vectors of weight at most $2$, as for $1 \leq i < j< k \leq m$, the configurations of $i,j$-mismatches and the configurations of $j,k$-mismatches affect the possible configurations of $i,k$- mismatches. More broadly, once the family $\mathbf{A}$ becomes rich enough, the step where we appeal to independence is not applicable and more sophisticated analysis is required. Hence, we have the following (open) questions:

\begin{problem}
\label{q1}

Fix $m$ and $k \leq m$. Can we answer Computational Problem when $\mathbf{A}$ consists of all vectors of weight at most $k$? 

\end{problem}

Lemma~\ref{l1} answers Open Problem~\ref{q1} when $k =1$, and the maximal case in~\cite{bennink} answers Open Problem~\ref{q1} when $k=m$. These boundary cases are the only values of $k$ for which Open Problem~\ref{q1} has been answered.    

\begin{problem}
\label{q2}
For which choices of $\mathbf{A}$ can we answer Computational Problem exactly? For which choices of $\mathbf{A}$ can we answer Computational Problem efficiently?
\end{problem}

To rephrase the second part of Open Problem~\ref{q2}, we ask:

\begin{problem}
\label{q3}
Is Computational Problem NP-Complete for arbitrary $\mathbf{A}$?
\end{problem}

Finally, we remark that exact answers to Computational Problem provide answers to expressiveness of commutative quantum circuits, approximate answers to Computational Problem provide approximations to expressiveness of commutative quantum circuits. Hence we ask:

\begin{problem}
\label{q4}
For which choices of $\mathbf{A}$ can we approximate answers to Computational Problem?
\end{problem}
\mySub{\bf Acknowledgements}
This work was performed at Oak Ridge National Laboratory, operated by
UT-Battelle, LLC for the US Department
of Energy (DOE) under contract DE-AC05-00OR22725. Support for the work came from the DOE Advanced
Scientific Computing Research (ASCR) Accelerated Research in Quantum
Computing Program under field work proposal ERKJ354.
