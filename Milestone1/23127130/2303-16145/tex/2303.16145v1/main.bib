@article{jeronymo2022mrobust04,
  title={mRobust04: A Multilingual Version of the TREC Robust 2004 Benchmark},
  author={Jeronymo, Vitor and Nascimento, Mauricio and Lotufo, Roberto and Nogueira, Rodrigo},
  journal={arXiv preprint arXiv:2209.13738},
  year={2022}
}

@article{jeronymo2022boring,
  title={A Boring-yet-effective Approach for the Product Ranking Task of the Amazon KDD Cup 2022},
  author={Jeronymo, Vitor and Rosa, Guilherme and Kallumadi, Surya and Lotufo, Roberto and Nogueira, Rodrigo},
  journal={arXiv preprint arXiv:2208.06264},
  year={2022}
}

@article{lin2021pyserini,
  title={Pyserini: An Easy-to-Use Python Toolkit to Support Replicable IR Research with Sparse and Dense Representations},
  author={Lin, Jimmy and Ma, Xueguang and Lin, Sheng-Chieh and Yang, Jheng-Hong and Pradeep, Ronak and Nogueira, Rodrigo},
  journal={arXiv preprint arXiv:2102.10073},
  year={2021}
}

@article{bonifacio2021mmarco,
  title={mmarco: A multilingual version of the ms marco passage ranking dataset},
  author = {Bonifacio, Luiz and Jeronymo, Vitor and Abonizio, Hugo Queiroz and Campiotti, Israel and Fadaee, Marzieh and Lotufo, Roberto and Nogueira, Rodrigo},
  journal={arXiv preprint arXiv:2108.13897},
  year={2021}
}

@article{li2021learning,
  title={Learning Cross-Lingual IR from an English Retriever},
  author={Li, Yulong and Franz, Martin and Sultan, Md Arafat and Iyer, Bhavani and Lee, Young-Suk and Sil, Avirup},
  journal={arXiv preprint arXiv:2112.08185},
  year={2021}
}

@article{rosa2022no,
  title={No Parameter Left Behind: How Distillation and Model Size Affect Zero-Shot Retrieval},
  author={Rosa, Guilherme Moraes and Bonifacio, Luiz and Jeronymo, Vitor and Abonizio, Hugo and Fadaee, Marzieh and Lotufo, Roberto and Nogueira, Rodrigo},
  journal={arXiv preprint arXiv:2206.02873},
  year={2022}
}

@inproceedings{Robertson1994OkapiAT,
  title={Okapi at TREC-3},
  author={Stephen E. Robertson and Steve Walker and Susan Jones and Micheline Hancock-Beaulieu and Mike Gatford},
  booktitle={TREC},
  year={1994}
}

@inproceedings{tiedemann2020opus,
  title={OPUS-MT--Building open translation services for the World},
  author={Tiedemann, J{\"o}rg and Thottingal, Santhosh},
  booktitle={Proceedings of the 22nd Annual Conference of the European Association for Machine Translation},
  year={2020},
  organization={European Association for Machine Translation}
}

@article{ng2019facebook,
  title={Facebook FAIR's WMT19 news translation task submission},
  author={Ng, Nathan and Yee, Kyra and Baevski, Alexei and Ott, Myle and Auli, Michael and Edunov, Sergey},
  journal={arXiv preprint arXiv:1907.06616},
  year={2019}
}

@article{formal2021splade,
  title={SPLADE v2: Sparse lexical and expansion model for information retrieval},
  author={Formal, Thibault and Lassance, Carlos and Piwowarski, Benjamin and Clinchant, St{\'e}phane},
  journal={arXiv preprint arXiv:2109.10086},
  year={2021}
}


@inproceedings{qiao2020pash,
  title={PASH at TREC 2020 Deep Learning Track: Dense Matching for Nested Ranking.},
  author={Qiao, Yixuan and Chen, Hao and Cao, Liyu and Chen, Liping and Li, Pengyong and Wang, Jun and Gao, Peng and Ni, Yuan and Xie, Guotong},
  booktitle={TREC},
  year={2020}
}

@article{Qiao2022PASHAT,
  title={PASH at TREC 2021 Deep Learning Track: Generative Enhanced Model for Multi-stage Ranking},
  author={Yixuan Qiao and Hao Chen and Yongquan Lai and Jun Wang and Tuozhen Liu and Xianbin Ye and Rui Fang and Peng Gao and Wenfeng Xie and Guo Tong Xie},
  journal={ArXiv},
  year={2022},
  volume={abs/2205.11245}
}

@inproceedings{Huang2022YorkUA,
  title={York University at TREC 2021: Deep Learning Track},
  author={Yizheng Huang and Jimmy Huang},
  year={2022}
}


@inproceedings{gao2022unsupervised,
  title={Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval},
  author={Gao, Luyu and Callan, Jamie},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2843--2853},
  year={2022}
}

@article{zhang2022hlatr,
  title={HLATR: Enhance Multi-stage Text Retrieval with Hybrid List Aware Transformer Reranking},
  author={Zhang, Yanzhao and Long, Dingkun and Xu, Guangwei and Xie, Pengjun},
  journal={arXiv preprint arXiv:2205.10569},
  year={2022}
}

@inproceedings{lawrie2022hc4,
  title={HC4: a new suite of test collections for ad hoc CLIR},
  author={Lawrie, Dawn and Mayfield, James and Oard, Douglas W and Yang, Eugene},
  booktitle={European Conference on Information Retrieval},
  pages={351--366},
  year={2022},
  organization={Springer}
}

@inproceedings{rrf,
author = {Cormack, Gordon V. and Clarke, Charles L A and Buettcher, Stefan},
title = {Reciprocal Rank Fusion Outperforms Condorcet and Individual Rank Learning Methods},
year = {2009},
isbn = {9781605584836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1571941.1572114},
doi = {10.1145/1571941.1572114},
abstract = {Reciprocal Rank Fusion (RRF), a simple method for combining the document rankings from multiple IR systems, consistently yields better results than any individual system, and better results than the standard method Condorcet Fuse. This result is demonstrated by using RRF to combine the results of several TREC experiments, and to build a meta-learner that ranks the LETOR 3 dataset better than any previously reported method},
booktitle = {Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {758–759},
numpages = {2},
keywords = {aggregation, fusion, ranking},
location = {Boston, MA, USA},
series = {SIGIR '09}
}

@article{MS_MARCO_v3,
	title        = {{MS} {MARCO}: {A Human Generated MAchine Reading COmprehension Dataset}},
	author       = {Payal Bajaj and Daniel Campos and Nick Craswell and Li Deng and Jianfeng Gao and Xiaodong Liu and Rangan Majumder and Andrew McNamara and Bhaskar Mitra and Tri Nguyen and Mir Rosenberg and Xia Song and Alina Stoica and Saurabh Tiwary and Tong Wang},
	year         = 2018,
	journal      = {arXiv:1611.09268v3}
}

@inproceedings{zhang2020rapidly,
	title        = {Rapidly Deploying a Neural Search Engine for the COVID-19 Open Research Dataset},
	author       = {Zhang, Edwin and Gupta, Nikhil and Nogueira, Rodrigo and Cho, Kyunghyun and Lin, Jimmy},
	year         = 2020,
	booktitle    = {Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020}
}

@article{craswell2020overview,
	title        = {Overview of the TREC 2019 deep learning track},
	author       = {Craswell, Nick and Mitra, Bhaskar and Yilmaz, Emine and Campos, Daniel and Voorhees, Ellen M},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2003.07820}
}

@inproceedings{Voorhees_TREC2004_robust,
	title        = {Overview of the {TREC} 2004 Robust Track},
	author       = {Ellen M. Voorhees},
	year         = 2004,
	booktitle    = {Proceedings of the Thirteenth Text REtrieval Conference (TREC 2004)},
	address      = {Gaithersburg, Maryland},
	pages        = {52--69}
}

@misc{ccrawl,
	title        = {A Warm Start and a Clean Crawled Corpus -- {A} Recipe for Good Language Models},
	author       = {Vésteinn Snæbjarnarson and Haukur Barri Símonarson and Pétur Orri Ragnarsson and Svanhvít Lilja Ingólfsdóttir and Haukur Páll Jónsson and Vilhjálmur Þorsteinsson and Hafsteinn Einarsson},
	year         = 2022,
	url          = {https://arxiv.org/abs/2201.05601},
	pdf          = {https://arxiv.org/pdf/2201.05601.pdf},
	abstract     = {We train several language models for Icelandic, including IceBERT, that achieve state-of-the-art performance in a variety of downstream tasks, including part-of-speech tagging, named entity recognition, grammatical error detection and constituency parsing. To train the models we introduce a new corpus of Icelandic text, the Icelandic Common Crawl Corpus (IC3), a collection of high quality texts found online by targeting the Icelandic top-level-domain (TLD). Several other public data sources are also collected for a total of 16GB of Icelandic text. To enhance the evaluation of model performance and to raise the bar in baselines for Icelandic, we translate and adapt the WinoGrande dataset for co-reference resolution. Through these efforts we demonstrate that a properly cleaned crawled corpus is sufficient to achieve state-of-the-art results in NLP applications for low to medium resource languages, by comparison with models trained on a curated corpus. We further show that initializing models using existing multilingual models can lead to state-of-the-art results for some downstream tasks.},
	cc-author-affiliation = {Miðeind ehf., Iceland; University of Iceland, Iceland},
	cc-class     = {nlp/corpus-construction, nlp/language-model},
	cc-dataset-used = {CDX, WARC, ARC 2008 – March 2020},
	cc-snippet   = {3.1. The Icelandic Common Crawl Corpus¶ The Common Crawl Foundation is a non-profit organization that scrapes large semi-random subsets of the internet regularly and hosts timestamped and compressed dumps of the web online¹⁰ [¹⁰https://commoncrawl.org/the-data/get-started/]. Each dump contains billions of web pages occupying hundreds of terabytes. Parsing these files directly requires storage and computing power not directly available to most and can come at a significant financial cost. The foundation also hosts indices of URIs and their locations within the large zipped dump files. While these indices are also large, their processing is feasible with a few terabytes of storage.¶ 3.1.1. Extracting Icelandic Common Crawl data¶ The Common Crawl indices, which contain URI and byte offsets within the compressed dumps, are used to reduce the search space when looking for Icelandic texts. The Common Crawl Index Server has a public API¹¹ [¹¹https://index.commoncrawl.org/] where URIs can be queried based on attributes such as date, MIME-type and substring. Using the API eliminates the need to fetch the massive index files. To extract Icelandic, the .is pattern is targeted to match the Icelandic top level domain (TLD), resulting in 63.5 million retrieved pages with URIs and byte locations within the compressed Common Crawl dumps. The computational efficiency of our method can be attributed to these steps. Given the predominant use of the .is TLD for Icelandic web content, we assume that other TLDs have a much lower proportion of Icelandic content. That said, a nontrivial amount of text in Icelandic is still likely to be found outside the .is domain and could be extracted by, e.g., parsing the whole Common Crawl, albeit at a much higher computational cost.¶ By targeting only the byte-offsets corresponding to the Icelandic TLD we extract candidate websites that have a high proportion of Icelandic content. In total, the compressed content is 687GiB on disk. All dumps since the start of the Common Crawl in 2008 until March 2020 were included.¶ Plain text was extracted from the collected WARC (Web Archive format) files using jusText (Pomikálek, 2011)12 to remove boilerplate content and HTML tags.}
}

@inproceedings{overwijk2022clueweb22,
	title        = {ClueWeb22: 10 Billion Web Documents with Rich Information},
	author       = {Overwijk, Arnold and Xiong, Chenyan and Callan, Jamie},
	year         = 2022,
	booktitle    = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages        = {3360--3362}
}

@article{liu2019roberta,
	title        = {Roberta: A robustly optimized bert pretraining approach},
	author       = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1907.11692}
}

@article{devlin2018bert,
	title        = {Bert: Pre-training of deep bidirectional transformers for language understanding},
	author       = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1810.04805}
}

@article{raffel2020exploring,
	title        = {Exploring the limits of transfer learning with a unified text-to-text transformer.},
	author       = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J and others},
	year         = 2020,
	journal      = {J. Mach. Learn. Res.},
	volume       = 21,
	number       = 140,
	pages        = {1--67}
}

@inproceedings{zhang2021mr,
	title        = {Mr. TyDi: A Multi-lingual Benchmark for Dense Retrieval},
	author       = {Zhang, Xinyu and Ma, Xueguang and Shi, Peng and Lin, Jimmy},
	year         = 2021,
	booktitle    = {Proceedings of the 1st Workshop on Multilingual Representation Learning},
	pages        = {127--137}
}


@article{lewis2019mlqa,
	title        = {MLQA: Evaluating cross-lingual extractive question answering},
	author       = {Lewis, Patrick and O{\u{g}}uz, Barlas and Rinott, Ruty and Riedel, Sebastian and Schwenk, Holger},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1910.07475}
}

@inproceedings{mitra2008overview,
	title        = {Overview of FIRE 2008},
	author       = {Mitra, Mandar},
	year         = 2008,
	booktitle    = {Working Notes of Forum for Information Retrieval Evaluation}
}

@incollection{majumder2013overview,
	title        = {Overview of FIRE 2010},
	author       = {Majumder, Prasenjit and Pal, Dipasree and Bandyopadhyay, Ayan and Mitra, Mandar},
	year         = 2013,
	booktitle    = {Multilingual Information Access in South Asian Languages},
	publisher    = {Springer},
	pages        = {252--257}
}

@book{sakai2021evaluating,
	title        = {Evaluating Information Retrieval and Access Tasks: NTCIR's Legacy of Research Impact},
	author       = {Sakai, Tetsuya and Oard, Douglas W and Kando, Noriko},
	year         = 2021,
	publisher    = {Springer Nature}
}

@article{conneau2019unsupervised,
  title={Unsupervised cross-lingual representation learning at scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1911.02116},
  year={2019}
}

@article{xue2020mt5,
  title={mT5: A massively multilingual pre-trained text-to-text transformer},
  author={Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  journal={arXiv preprint arXiv:2010.11934},
  year={2020}
}

@article{tezgider2022text,
  title={Text classification using improved bidirectional transformer},
  author={Tezgider, Murat and Yildiz, Beytullah and Aydin, Galip},
  journal={Concurrency and Computation: Practice and Experience},
  volume={34},
  number={9},
  pages={e6486},
  year={2022},
  publisher={Wiley Online Library}
}

@article{zhang2021fast,
  title={Fast multi-resolution transformer fine-tuning for extreme multi-label text classification},
  author={Zhang, Jiong and Chang, Wei-Cheng and Yu, Hsiang-Fu and Dhillon, Inderjit},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={7267--7280},
  year={2021}
}

@inproceedings{li2021act,
  title={Act: an attentive convolutional transformer for efficient text classification},
  author={Li, Pengfei and Zhong, Peixiang and Mao, Kezhi and Wang, Dongzhe and Yang, Xuefeng and Liu, Yunfeng and Yin, Jianxiong and See, Simon},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={15},
  pages={13261--13269},
  year={2021}
}

@article{yan2019tener,
  title={TENER: adapting transformer encoder for named entity recognition},
  author={Yan, Hang and Deng, Bocao and Li, Xiaonan and Qiu, Xipeng},
  journal={arXiv preprint arXiv:1911.04474},
  year={2019}
}

@inproceedings{arkhipov2019tuning,
  title={Tuning multilingual transformers for language-specific named entity recognition},
  author={Arkhipov, Mikhail and Trofimova, Maria and Kuratov, Yurii and Sorokin, Alexey},
  booktitle={Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing},
  pages={89--93},
  year={2019}
}

@inproceedings{lothritz2020evaluating,
  title={Evaluating pretrained transformer-based models on the task of fine-grained named entity recognition},
  author={Lothritz, Cedric and Allix, Kevin and Veiber, Lisa and Klein, Jacques and Bissyande, Tegawend{\'e} Fran{\c{c}}ois D Assise},
  booktitle={Proceedings of the 28th International Conference on Computational Linguistics},
  pages={3750--3760},
  year={2020}
}

@article{lin2021pretrained,
	title        = {Pretrained transformers for text ranking: Bert and beyond},
	author       = {Lin, Jimmy and Nogueira, Rodrigo and Yates, Andrew},
	year         = 2021,
	journal      = {Synthesis Lectures on Human Language Technologies},
	publisher    = {Morgan \& Claypool Publishers},
	volume       = 14,
	number       = 4,
	pages        = {1--325}
}

@article{vsm,
author = {Salton, G. and Wong, A. and Yang, C. S.},
title = {A Vector Space Model for Automatic Indexing},
year = {1975},
issue_date = {Nov. 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/361219.361220},
doi = {10.1145/361219.361220},
abstract = {In a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing system may be expressible as a function of the density of the object space; in particular, retrieval performance may correlate inversely with space density. An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents. Typical evaluation results are shown, demonstating the usefulness of the model.},
journal = {Commun. ACM},
month = {nov},
pages = {613–620},
numpages = {8},
keywords = {automatic indexing, document space, automatic information retrieval, content analysis}
}

@article{deerwester1990indexing,
  title={Indexing by latent semantic analysis},
  author={Deerwester, Scott and Dumais, Susan T and Furnas, George W and Landauer, Thomas K and Harshman, Richard},
  journal={Journal of the American society for information science},
  volume={41},
  number={6},
  pages={391--407},
  year={1990},
  publisher={Wiley Online Library}
}

@inproceedings{HC4,
	title        = {HC4: A New Suite of Test Collections for Ad Hoc CLIR},
	author       = {Lawrie, Dawn and Mayfield, James and Oard, Douglas W. and Yang, Eugene},
	year         = 2022,
	booktitle    = {Advances in Information Retrieval},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	pages        = {351--366},
	isbn         = {978-3-030-99736-6},
	editor       = {Hagen, Matthias and Verberne, Suzan and Macdonald, Craig and Seifert, Christin and Balog, Krisztian and N{\o}rv{\aa}g, Kjetil and Setty, Vinay},
	abstract     = {HC4 is a new suite of test collections for ad hoc Cross-Language Information Retrieval (CLIR), with Common Crawl News documents in Chinese, Persian, and Russian, topics in English and in the document languages, and graded relevance judgments. New test collections are needed because existing CLIR test collections built using pooling of traditional CLIR runs have systematic gaps in their relevance judgments when used to evaluate neural CLIR methods. The HC4 collections contain 60 topics and about half a million documents for each of Chinese and Persian, and 54 topics and five million documents for Russian. Active learning was used to determine which documents to annotate after being seeded using interactive search and judgment. Documents were judged on a three-grade relevance scale. This paper describes the design and construction of the new test collections and provides baseline results for demonstrating their utility for evaluating systems.}
}