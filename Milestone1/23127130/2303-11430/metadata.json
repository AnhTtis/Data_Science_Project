{
    "arxiv_id": "2303.11430",
    "paper_title": "Deep learning for the detection of machining vibration chatter",
    "authors": [
        "Cheick Abdoul Kadir A. Kounta",
        "Lionel Arnaud",
        "Bernard Kamsu-Foguem",
        "Fana Tangara"
    ],
    "submission_date": "2023-03-17",
    "revised_dates": [
        "2023-03-22"
    ],
    "latest_version": 1,
    "categories": [
        "eess.SP"
    ],
    "abstract": "Most of the work on chatter detection is based on laboratory machining tests, thus without the constraints of noise, the variety of situations to be managed in the industry, and the uncertainties on the parameters (sensor position, tool engagement, and sometimes even spindle rotation frequency). This work presents an approach first based on mechanical skills first to identify the optimal signal processing, then based on deep learning to automatically detect the phenomenon of chatter in machining. To do so, we use input images from the Fast Fourier Transform analysis of a vibration signal from the machining of an Alstom industrial railway system. The FFT images are first cropped in height to perform a renormalization of the signal scale. This renormalization step eliminates a bias regularly observed in the literature, which did not eliminate a simple correlation with signal amplitude because chatter is often, but not always, associated with stronger vibrations. Deep learning extracted features from the image data by exploiting pre-trained deep neural networks such as VGG16 and ResNet50. The data is derived from an industrial vibration signal (with noise, a not ideally placed sensors, and uncertainties on process parameters), which was very poorly represented in the literature. It is shown that by depleting the signal (renormalized amplitude and absence of information on the rotation speed), the model obtains a good result (an accuracy of 99% in the training and validation phases), which had never been done in the literature. In addition, since a part of the test dataset is similar to the training dataset, the proposed model obtains an accuracy of 98.82%. The robustness is proved by adding another test dataset containing noisy and more or less ambiguous images to be classified. The model still manages to detect these cases from its training of unambiguous cases, showing that the obtained generalization is efficient with an accuracy of 73.71%.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11430v1"
    ],
    "publication_venue": null,
    "doi": "10.1016/j.advengsoft.2023.103445"
}