% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage[review]{cvpr}      % To produce the REVIEW version
% \usepackage{cvpr}              % To produce the CAMERA-READY version
\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{bbm}

\usepackage{multirow}
\usepackage{adjustbox}
\usepackage{textcomp}
\usepackage{gensymb}
\usepackage{wrapfig}
\usepackage{setspace}
\usepackage[dvipsnames]{xcolor}
\usepackage[ruled,linesnumbered, noend]{algorithm2e}
\def \HiLi{\leavevmode\rlap{\hbox to \hsize{\color{yellow!50}\leaders\hrule height .8\baselineskip depth .5ex\hfill}}}
\usepackage{hyperref}
\usepackage[capitalize,noabbrev]{cleveref}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\usepackage[ruled,linesnumbered,noend]{algorithm2e}
\usepackage{xspace}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
% \usepackage[pagebackref,breaklinks,colorlinks]{hyperref}
\newcommand{\sys}{DRAM\xspace}
\newcommand{\nattacks}{25\xspace}

\newcommand{\yun}[1]{{\textcolor{BrickRed}{\bf [Yun: #1]}}}


\newcommand{\jc}[2]{{\textcolor{blue}{\bf [JC: #2]}}}

\newcommand{\zy}[3]{{\textcolor{green}{\bf [ZY: #3]}}}

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
% \def\cvprPaperID{22} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Test-time Defense against Adversarial Attacks: Detection and Reconstruction of Adversarial Examples via Masked Autoencoder}

\author{Yun-Yun Tsai$^1$~~~Ju-Chin Chao$^1$~~~Albert Wen$^2$~~~Zhaoyuan Yang$^3$ \\~~~Chengzhi Mao$^1$~~~Tapan Shah$^3$~~~Junfeng Yang$^1$ \\
$^1$Columbia University~~~$^2$University of California, Berkeley~~~$^3$GE Research\\
{\tt\small \{yt2781,jc5859,cm3797\}@columbia.edu,}
{\tt\small albertwen@berkeley.edu,}\\
{\tt\small\{zhaoyuan.yang,tapan.shah\}@ge.com,}
{\tt\small junfeng@cs.columbia.edu}
}


% \author{
% Yun-Yun Tsai \\
% Columbia University\\
% {\tt\small yt2781@columbia.edu}
% % For a paper whose authors are all at the same institution,
% % omit the following lines up until the closing ``}''.
% % Additional authors and addresses can be added with ``\and'',
% % just like the second author.
% % To save space, use either the email address or home page, not both
% \and
% Ju-Chin Chao\\
% Columbia University\\
% {\tt\small jc5859@columbia.edu}

% }

\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}
% Existing defense methods for adversarial attacks often focus on training-time defense, known as adversarial training. However, it requires long-time training and is only robust on the attacks they have been trained on. Since it is hard to anticipate multiple adversarial attacks at the inference stage, training-based defenses might be easily circumvented in real-world scenarios. We propose \sys, a novel transformer-based defense method to Detect and Reconstruct the multiple types of Adversarial attacks via Masked autoencoder (MAE). The rationale lies in the adversarial examples having a significantly higher MAE loss than clean samples. As a result, a statistic-based method such as KS-test combined with MAE loss can effectively detect the attacks with a high detection rate. Moreover, minimizing the MAE loss helps reconstruct the samples from adversarial to clean and improves the robust accuracy of the classifier. Evaluating \sys on the large-scale ImageNet data, we achieve the best detection rate by 80\% on eight types of adversarial attacks compared with three detection baselines. For reconstruction, \sys improves the robust accuracy by 8\% $\sim$ 40\% for Standard ResNet50 and Robust ResNet50 compared with other self-supervision tasks, such as rotation prediction and contrastive learning. 
% TRAM also achieves up to 90\% adversarial detection on self-supervised learning methods and achieves 72\% attack classification score, which on average outperforms transformer-based baselines by 16.12\% and DNN-based baselines by 22.31\%.
Existing defense methods against adversarial attacks can be categorized into training time and test time defenses. 
Training time defense, i.e., adversarial training, requires a significant amount of extra time for training and is often not able to be generalized to unseen attacks. 
On the other hand, test time defense by test time weight adaptation requires access to perform gradient descent on (part of) the model weights, which could be infeasible for models with frozen weights. 
To address these challenges, we propose \sys, a novel defense method to Detect and Reconstruct the multiple types of Adversarial attacks via Masked autoencoder (MAE).
We demonstrate how to use MAE losses to build a KS-test to detect adversarial attacks. Moreover, the MAE losses can be used to repair adversarial samples from unseen attack types.
In this sense, \sys neither requires model weight updates in test time nor augments the training set with more adversarial samples. Evaluating \sys on the large-scale ImageNet data, we achieve the best detection rate of 82\% on average on eight types of adversarial attacks compared with other detection baselines. For reconstruction, \sys improves the robust accuracy by 6\%$\sim$41\% for Standard ResNet50 and 3\%$\sim$8\% for Robust ResNet50 compared with other self-supervision tasks, such as rotation prediction and contrastive learning. 



% \sys is able to detect the existence of adversarial attacks by comparing the MAE loss in Masked autoencoder (MAE) and repair t.
% If a corruption in a sample is detected, our method is able to reconstruct the corrupted samples by....



\end{abstract}

%%%%%%%%% BODY TEXT

\input{docs/introduction}

\input{docs/relatedwork}

\input{docs/methodology}

\input{docs/experiment}

% \input{docs/analysis}

\input{docs/conclusion}


%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{PaperForReview}
}

\end{document}
