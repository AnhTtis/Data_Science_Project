%!TEX root = response.tex

\section*{Reviewer 4}

\textbf{[c1] For runtime adaptation, there are several approximation techniques available. There appear to be better choices for model approximation, such as the slimmable neural network mentioned in Section 2. Could the authors please elaborate on why they made this choice?}

\paragraph{}

[r1] Please see [r1] to Reviewer 1's comments.

\paragraph{}

\textbf{[c2] I appreciate the effort that went into making the complication pipeline available for mobile platforms, such as integrating the Android LLVM and ApproxHPVM compilers and extending OpenCL BLAS. It would be great if the author could compare their implementation to existing mobile deep learning libraries or code generation tools. Otherwise, determining the true speedup in comparison to other existing frameworks is difficult.}

\paragraph{}

[r2] Please see [r2] to Reviewer 1's comments.

\paragraph{}

\textbf{[c3] It's not clear to me why adaptation strategies can help with tasks like image classification on the CIFAR10 dataset. Because I believe there is no time consistent behavior on these tasks, we cannot estimate the complexity of classifying a new image based on previous images.}

\paragraph{}

[r3] Please see [r3] to Reviewer 1's comments. 

\paragraph{}

\textbf{[c4] I'm having trouble understanding the figure in the evaluation section for two reasons. First, what is the relationship between QoS loss and accuracy performance? I was unable to locate a formal definition of QoS loss. Second, I believe that runtime adaptation can provide consistent choice over time, so it would be better to show the average/standard deviation of performance or perhaps their performance distributions. I find it difficult to grasp the main ideas from figures full of dots.}

\paragraph{}

[r4] Please see [r4] to Reviewer 1's comments. 

\paragraph{}
