\section{Preliminaries}
\label{sec:preliminaries}

Mobiprox builds upon a larger body of work on heterogeneous and approximate computing compilers elaborated in the rest of this section.

\textbf{HPVM} (\textit{Heterogeneous Parallel Virtual Machine})~\cite{kotsifakou2018hpvm} is a compiler infrastructure targeting heterogeneous hardware. The project introduces HPVM-C, a programming language for defining \textit{data flow graphs} (DFGs), directed graphs in which nodes represent a computation task and edges represent inputs and outputs of a computation task. Computation workloads are defined using HPVM's intrinsic functions used to specify the {target device} the node will be executed on, node {inputs}, node {outputs}, and any compute {operations} (e.g. addition). HPVM compiler achieves parallel execution of produced binaries by identifying dependencies among the nodes in a DFG and generating compute code for specified target devices (CPU, GPU) for each node. %To orchestrate DFG execution, HPVM inserts appropriate calls to the {HPVM Runtime} library. %which is explained in section~\ref{sec:android-rt}.

\textbf{ApproxHPVM}~\cite{sharif2019approxhpvm} expands HPVM by introducing the support for tensor operations commonly used in NNs: multiplication, convolution, addition, pooling, and activation functions.  Additionally, ApproxHPVM enables transforming high level descriptions of convolutional neural networks (in frameworks such as Keras, PyTorch) into DFGs in the form of generated HPVM-C source files. However, while HPVM generates code for computation nodes in a DFG, ApproxHPVM's tensor operations are mapped to functions defined in the \textbf{HPVM Tensor Runtime} library. In ApproxHPVM individual tensor operations can be marked with the maximum allowed level of approximation, and the compiler then ensures that these are mapped to the appropriate underlying approximate computing techniques (either software or hardware-based). \blue{Yet}, ApproxHPVM's tensor operations are supported for Nvidia CUDA-enabled devices only. %and the PROMISE hardware simulator~\cite{srivastava2018promise}. 
In Mobiprox we introduce an OpenCL tensor runtime that runs on Android devices, as explained in Section~\ref{sec:android-rt}.

\textbf{ApproxTuner}~\cite{sharif2021approxtuner} adds support for heuristic-based search of the space of possible approximations of each individual network layer, so that a comprehensive \textit{speedup-inference accuracy} trade-off curve is charted and the list of the most promising sets of approximations is identified.

\subsection{Approximation techniques}
\label{sec:preliminaries-acts}

\newcommand{\ttit}[1]{\textit{\texttt{#1}}}

%\sasa{This section should more clearly state the distinction between the previous work (ApproxTuner) and the new work in Mobiprox. I suggest we move the description of approximation techniques in the background (while also shortenting them if space becomes tight) and discuss new things here (e.g. half precision quantization)} 

%The last two decades witnessed a range of approximate computing techniques being developed -- from approximate adders and multipliers, to loop perforation and task skipping~\cite{Mittal2015}. However, due to their small form factor mobile devices seldom can host both approximate and accurate versions of hardware circuits. Software techniques, on the other hand, often require a strong involvement from the developer, for example, to label loops that are candidates for perforation. Therefore, in Mobiprox we focus on implementing basic software-based approximations (described below) at the lowest possible level -- the individual DL operation level -- and do not even require that the developer knows about these approximations. 
%\sasa{the key message from this paragraph should be moved to the intro. here is too buried. }

% presented in~\cite{sharif2021approxtuner}

We implement the following techniques, originally present in ApproxTuner, in Mobiprox. These techniques were selected as they do not require specialized hardware and can be applied at a level of a single NN operation. 

%\hashim{"additional hardware" should be "specialized hardware"}
%\hashim{I think here you want to emphasize more strongly that you implemented these approximations and optimized them based on the ARM compute library. I know you spent significant effort doing this and should come through as such. For instance you can mention these routines were optimized with "vectorization", "tiling", etc etc.}

\textbf{Convolution perforation}~\cite{figurnov2016perforatedcnns} is an approximation approach where during the convolution calculation certain input matrix coordinates are skipped, as shown in Figure~\ref{fig:convperf}. %\hashim{can make it more clear that this is "output" perforation - in that some output tensor elements are not computed and later interpolated with neighbour averaging.} 
Due to the nature of convolutions, this does not necessarily mean that the inputs at skipped coordinates are never used -- indeed, the inputs figure in neighboring convolutions. This, in turn, makes it feasible to interpolate convolution results at skipped coordinates by computing the average of computed neighboring cells. We support two types of convolution perforation -- \textbf{row perforation} and \textbf{column perforation}. The parameter \ttit{offset} defines the index of the first omitted row or column, while parameter \ttit{stride} defines the interval between the skipped rows/columns.  In Figure~\ref{fig:convperf}, parameters \ttit{stride}=2 and \ttit{offset}=1 were used.

%The difference between the two stems from the axis along which perforation takes place. Row perforation with \ttit{stride} $k$ skips calculation of convolutions in every $k$-th row of the input image, while column perforation with  \ttit{stride} $k$ skips convolutions at every $k$-th column of the input. Parameter \ttit{offset} defines the index of the first omitted row or column. In Figure~\ref{fig:convperf}, parameters \ttit{stride}=2 and \ttit{offset}=1 were used.


\begin{figure}[h]
    \newcommand{\w}{\linewidth}
    \newcommand{\sw}{0.3\linewidth}
    \centering
    
    \begin{subfigure}{\sw}
        \centering
        \includegraphics[width=\w]{figures/convperf-row.pdf}
        \caption{Row perforation}
        \label{fig:convperf-row}
        
    \end{subfigure}
    \hspace{1cm}
    \begin{subfigure}{\sw}
        \centering
        \includegraphics[width=\w]{figures/convperf-col.pdf}
        \caption{Column perforation}
        \label{fig:convperf-col}
        
    \end{subfigure}
    \caption{Perforated convolution. Coloured sections indicate convolution coordinates. Dashed squares indicate the area of the first and the final convolution.}
    \label{fig:convperf}
\end{figure}


\newcommand{\nelm}{n_\mathrm{elm}}
\newcommand{\nelmPerf}{n_\mathrm{elm-samp}}

\textbf{Filter sampling} focuses on approximating the filters that the convolutions are performed with.
%\hashim{Perforation is actually perforating the "output". Filter sampling is perforating the "filter". In both cases, a subset of inputs are used, so both do input sampling in some sense.}
In CNNs filters are 4-dimensional tensors with dimensions $[N, C, H, W]$. $N$ represents the number of filters in the convolution, $C$ is the number of feature channels in the input and the filter (e.g. 3 channels in RGB images), and finally $H$ and $W$ represent the height and width of the filter, respectively. Each filter is therefore composed of $\nelm{} = C \cdot H \cdot W$ components. Filter sampling with \ttit{stride} $k$ removes every $k$-th component of the filter's $\nelm{}$ components, starting at element specified by \ttit{offset}. The technique, thus, reduces the amount of computation by keeping only $\nelmPerf{} = \nelm{} - \frac{\nelm{} - \ttit{offset}}{\ttit{stride}}$ filter components at the cost of the overall convolution accuracy. To interpolate missing values, each retained filter component is multiplied by a factor of $\nelm{}/\nelmPerf{}$.


%\begin{equation}\label{eq:n_elm}
%    \nelm{} = C \cdot H \cdot W
%\end{equation}

%\begin{equation}\label{eq:n_elm_perf}
%    \nelmPerf{} = \nelm{} - \frac{\nelm{} - %\ttit{offset}}{\ttit{stride}}
%\end{equation}


Finally, Mobiprox provides an optional \textbf{half-precision quantization}. Unlike the convolution perforation and filter sampling, the quantization is not limited to convolutional layer, but can be used to approximate any floating point tensor operation. While such quantization is meaningful only if the underlying hardware supports it, we opted for enabling it as modern mobile GPUs, such as those of Arm Mali series, natively support the IEEE FP16 16-bit format.

%Additionally, each operation can be run at reduced precision with 16-bit floating point data (indicated by \texttt{\_fp16} extension).


% \begin{figure}[h]
%     \newcommand{\w}{\linewidth}
%     \newcommand{\sw}{0.3\linewidth}
%     \centering
    
%     \begin{subfigure}{\sw}
%         \centering
%         \includegraphics[width=\w]{figures/convperf-filter.pdf}
%         \caption{First step}
%         \label{fig:convperf-filter-0}
%     \end{subfigure}
%     % \begin{subfigure}{\sw}
%     %     \centering
%     %     \includegraphics[width=\w]{figures/convperf-filter-1.pdf}
%     %     \caption{}
%     %     \label{fig:convperf-filter-1}
%     % \end{subfigure}
%     \begin{subfigure}{\sw}
%         \centering
%         \includegraphics[width=\w]{figures/convperf-filter-2.pdf}
%         \caption{Intermediate step}
%         \label{fig:convperf-filter-2}
%     \end{subfigure}
%     \begin{subfigure}{\sw}
%         \centering
%         \includegraphics[width=\w]{figures/convperf-filter-3.pdf}
%         \caption{Final step}
%         \label{fig:convperf-filter-3}
%     \end{subfigure}

%     \caption{First, intermediate and final steps of convolution with filter sampling. The filter traverses all input coordinates. Coloured filter components were retained in filter sampling. A non-perforated filter would have all nine squares shaded. All figures depict convolution of a single channel $6\times6$ image and a $3\times3$ filter. Filter sampling was done with \ttit{stride} 2 and \ttit{offset} 1.}
%     \label{fig:convperf-filter}
% \end{figure}
