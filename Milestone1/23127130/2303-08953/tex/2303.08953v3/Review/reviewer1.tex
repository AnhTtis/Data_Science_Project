\newpage
\section*{Response to reviewer \#1}
\rpy{(Responses are highlighted in red. Corresponding code changes are highlighted in red as well in the manuscript.)}

\subsection*{Major comments}
\paragraph{Comment 1} 
In Section 5.1 (weak scaling) and 5.2 (strong scaling), the parallel performance of the stable s-step GMRES is compared to the performance of MGS GMRES. It is pretty clear that in this case s-step GMRES is going to win over MGS-GMRES by a wide margin, because MGS-GMRES is probably the most communication-intensive variant of GMRES. Thus, the comparison is unfair. It would be valuable to include either a CGS2-GMRES or one of the low synch variants to make the comparison more meaningful, as CGS2-GMRES requires less communication and in general, is much more favorable in parallel. Also the block orthogonalization in the s-step GMRES is based on CGS2, so comparing the s-step GMRES with CGS2-GMRES would had been justified.

\rpy{See "Response to both reviewers on benchmarking against other algorithms".}

\paragraph{Comment 2}
Also, what polynomial basis was used in parallel experiments? If it was scaled polynomial basis, what was the cost of computing Ritz values?

\rpy{Thank you for your feedback. Yes, scaled Newton polynomial basis is used in all parallel experiments. We have added clarifications in different places of the text to remind readers about this. For instance, see line 731.

The Ritz values are obtained from a standard Arnoldi/GMRES algorithm, so the cost of obtaining the Ritz value would be equivalent to the cost of a standard Arnoldi/GMRES algorithm. As commented at line 341, this is a common strategy in s-step GMRES algorithms. We did not report the cost of this because (a) this can be inferred from the MGS-GMRES results; (b) the cost of obtaining Ritz values can vary depending on the application. For instance, some Ritz values can be known prior to solving the linear system, or when multiple right hand sides are to be solved, the cost of obtaining Ritz value can be amortized. If a standard GMRES algorithm is used to obtain Ritz values, the solution from the GMRES algorithm can also be used as a better initial guess for the s-step GMRES algorithms. In short, the cost of obtaining Ritz values varies depending on the use case and is therefore not included in this manuscript.

In addition to the cost of obtaining Ritz values, there is also some computational cost associated with the incremental condition estimator as well. But as indicated in Equation (3.15), all operations are element-wise operations on a $s\times s$ matrix, which have $O(s^2)$ complxity and typically have negligible computational cost comparing to the GMRES algorithms. In practice, after we obtain the Ritz values, the preprocessing steps for scaled Newton basis with $s = 100$ take about $O(10^{-3})$ seconds in our parallel experiemnts.
}

\paragraph{Comment 3}
All the parallel tests are performed on relatively "easy" problems. It would be valuable to see the performance on a problem that has high condition number, is run to completion (not just for 100 iterations) and (possibly) requires a preconditioner in order to converge. Also it seems like all parallel tests were performed with s=100 and were run for 100 iterations, hence there was no added operations/communication coming from orthogonalization between blocks and restarting GMRES. It would be valuable to see how do these not included operations influence the overall performance, as ideal scenario is unlikely in practice.

\rpy{Thank you for your suggestion. We think this is a great idea. As requested, we have included a set of results in Section 5.2 where a local ILU(0) preconditioner is applied to the Laplace problem and multiple inter-orthogonalization steps are used. See Fig. 14 for the summary of results. 

We acknowledge the importance of using numerically challenging linear systems. However, we chose to use the same Laplace problem due to several reasons. First of all, we want to use a problem with varying dimensions for weak scaling. Weak scaling allows us to demonstrate scalability up to a larger scale, as compared to strong scaling tests which have stringent memory requirements. Weak scaling also allows us to show the timing breakdown clearly. Therefore, we use a PDE problem with varying number of mesh points for weak scaling analysis.

With increasing matrix dimensions, the condition number of the linear system often increases. It becomes increasingly difficult to find an effective preconditioner that accelerates convergence to the same degree and scale well at the same time. Running to completion would mean different (and likely increasing) number of iterations for increasing matrix dimensions. We can definitely fine-tune the preconditioner to reach the same convergence at different matrix sizes, but as our paper focuses on numerical stability instead of accelerating convergence, we feel this is outside the scope of our paper. We also mentioned in Section 2 (line 80) that our work do not aim to optimize the SpMV and preconditioning operations as their communication-avoiding counterparts depend heavily on the sparsity patterns of the matrix and the preconditioner. Hence, in Figure 14, we present a standard local ILU(0) preconditioner for the same 3D Laplace equation without any fine-tuning of the preconditioner. This also allows for reproducibility of the results.

We want to highlight that the initial step size with local ILU(0) preconditioner can be as large as $s=100$ for scaled Newton polynomials in all our tests. But to mimic a numerically challenging problem, we reduced the step size to $s=25$ instead of $s=100$ for the same 100 iterations, so that multiple inter-orthogonalization steps are necessary. In practice, the tests are not fully converged (e.g., $10^{-8}$), but the runtime behavior of the algorithm with additional iterations can be inferred from the current set of results. The results (as presented in Figure 14) can also be compared with the single-block results in Figure 13. 

Overall, we want to provide a set of standard benchmarks with preconditioning steps and inter-orthogonalization steps, and also allow for reproducibility of our results. We hope the arguments above justify the scope of the added tests in Section 5.2.
}

\subsection*{Minor comments}

\paragraph{Comment 1} Line 31-32: "The performance of many operations in Krylov subspace methods, such as dot products and sparse matrix-vector multiplies (SpMVs), is bounded by communication on distributed systems" Consider reformulating - SpMV requires only local communication between (usually neighboring) ranks but dot product requires reduction which leads to global communication - I.e., all ranks communicate partial result and then the full result is distributed. Global communication is what (typically) limits performance in parallel setting.

\rpy{Thank you for your feedback. We agree that global reduction is often what limits performance on large-scale problems. We have updated the text to place emphasize on dot product operations. Please see line 31. }

\paragraph{Comment 2} Line 36: "redesign Krylov subspace methods that communicate less." Either "design Krylov methods that communicate less" or "redesign Krylov methods to communicate less".

\rpy{We have updated the text. Please see line 36.}

\paragraph{Comment 3} Line 40-41:
"BLAS-3 operations that are better optimized for fast memory [19]"
Not clear what "fast memory" means here.

\rpy{By "fast memory", we meant cache memory that allow quick access to data. It has lower latency compared to DRAM. We have updated the text to explicitly mention cache memory. Please see line 41.}

\paragraph{Comment 4} Line 47-48:
"Formulations of s-step Krylov subspace methods are mathematically equivalent to their classical counterparts"
Should probably be: "s-step methods are mathematically equivalent to their classical counterpart" or "s-step method can be formulated/written in such a way that they are mathematically equivalent to their classical counterpart".

\rpy{We have updated the text. Please see line 47.}

\paragraph{Comment 5} Paragraph starting at Line 53: Change "section 2" to "Section 2", "section 3" to "Section 3" etc (section and subsection should be capitalized). "algorithm 2.1" should be "Algorithm 2.1" (please check the entire paper for referencing algorithms and figures - they should be all capitalized).

\rpy{We have updated all references with capitalization. Thank you for your feedback on the format.}

\paragraph{Comment 6} Line 93: "But in finite precision, the Krylov basis vectors converge to the largest eigenvector of matrix A" Should be "eigenvector associated with the largest eigenvalue"

\rpy{We have updated the text for clarification, please see line 94.}

\paragraph{Comment 7} Line 127: "Each block $V^{(i)}$ first needs to be inter-orthogonalized with respect to orthogonal bases generated from previous iterations
[...]"
This statement is unclear; i.e., this is a first time the notion of "iteration" appears in this section. Should probably be $Q^{(1)}$ to $Q^{(I-1)}$ orthogonalized before or similar. Rewrite.

\rpy{We apologize for the ambiguity. We agree it would be best to delay the discussion of "iteration" to later sections. Here, we think it could be more appropriate to use "previous blocks" instead of "previous iterations". Please see line 129 for the updated text.}

\paragraph{Comment 8} Line 128:
"per s vector."
Should be "per s vectors"

\rpy{Thank you for pointing out the typo. We have corrected it in line 141.}

\paragraph{Comment 9} Line 154:
"Here, we note that the input block does not refer to the block $V^{(i)}$"
This statement is unclear I.e., what is $i$?

\rpy{We meant the $i$th block in the original matrix as defined in Equation (2.2). We have updated the text at line 157 to add the reference about Equation (2.2).}

\paragraph{Comment 10} Line 201:
"As mentioned previously, an ill-conditioned input matrix to CholQR may produce a numerically non-SPD Gram matrix"
But from what I understand, the Gram matrix ($V^TV$) IS the input to CholQR. If not, can you specify which Gram matrix are referring to?

\rpy{We apologize for the ambiguity. Here, we treat CholQR as a QR algorithm, so the input is the matrix to be factorized, which is $V$. $V^TV$ is the first computation within the CholQR algorithm. We have added $V$ in the text to further clarify this. Please see line 205. An additional clarification is also included at line 167 where there might be ambiguity.}

\paragraph{Comment 11} Line 209:
$X_{s-p}$ should be of a dimension $[N \times (s-p)]$ not $[n \times (s-p)]$

\rpy{Correct. Thank you for pointing out the typo. We have updated the text at line 212.}.

\paragraph{Comment 12} Line 236:
"that are relatively cheaper"
That are cheaper.

\rpy{We have updated the text. Please see line 239.}

\paragraph{Comment 13} Line 392
"approximate true eigenvalues, we can compute the product term approximately before the actual adaptive s-step GMRES algorithm without any communication cost."
First, in order to use the method, you need Ritz values. And computing them through Arnoldi Gram-Schmidt is not communication free.
Second, what is meant by "the product term"?

\rpy{Thank you for your feedback. We completely agree that computing Ritz values through Arnoldi/GMRES is not communication free and this statement is ambiguous. Here, our intention is to highlight that the initial step size estimator does not add extra communication cost to the original algorithm, which is using scaled Newton polynomials as a basis for adaptive s-step GMRES. 

To further clarify this, we first acknowledge that the construction of scaled Newton polynomial basis, like that of the standard Newton polynomial basis, requires Ritz value computation and is often not communication-free. But the derivations, such as equation (3.14), show that the initial step size estimator only takes in the Rtiz values as input and generates an estimation based on those Ritz values. Since Ritz values are available on all MPI ranks, all the operations in the estimator are done locally to each rank. Hence, the estimator does not incur additional communication cost, which aligns with the objective of communication-avoiding algorithms.

As for the second comment, "the product term" refers to the $\prod_{k=1}^{j-1}{\frac{\lambda_i-\theta_k}{|\bar{\theta}-\theta_k|}}$ in equation (3.14) as indicated by the product operator $\prod$. 

Nonetheless, we added some clarification to the text at line 397-398.
}

\paragraph{Comment 14} Line 415:
"inevitably increases the condition number of the Krylov basis matrix V exponentially."
Rewrite, i.e., "exponential increase in the condition number is inevitable" or similar.

\rpy{We clarified the text. Please refer to line 420.}

\paragraph{Comment 15} Line 434:
"As the Ritz values are available on all processes"
Processors or ranks, not processes.

\rpy{Thank you for your feedback. We updated the text. Please see line 441.}

\paragraph{Comment 16} Line 435:
"the estimator requires no communication cost"
"The estimator requires no communication" or "the estimator incurs no additional communication cost".

\rpy{Thank you. We updated the text. Please see line 441.}

\paragraph{Comment 17} Line 444:
"to verify the implementation sequentially since parallel implementations only introduce additional data movements that do not affect the stability of the overall algorithm."
This is not necessarily true.

\rpy{Yes, we agree this is not technically correct. Roundoff errors can have variations across software/hardwares, and parallelizing a sequential algorithm can potentially introduce these variations in roundoff errors that could modify the stability of the algorithm. However, such consideration is outside the scope of this work and we treat this as an assumption. Please see 450 for clarification.}

\paragraph{Comment 18} Line 461:
"We first start"
We start.

\rpy{Thank you for your feedback. We updated the text. Please see line 467.}

\paragraph{Comment 19} Line 500:
"The periodic pattern of LOO is because"
"The periodic pattern of LOO results from/is a consequence of"

\rpy{Thank you. We have updated the text at line 509.}

\paragraph{Figure 2, Figure 3, Figure 4}
- Use different ticks (i.e. squares, diamonds, circles, triangles, etc) for each quantity so the graphs are easy to understand even if printed in black and white or read by someone with impaired color vision.
- The LOO and convergence curve should be on separate plots.

\rpy{Thank you for your feedback. We have standardized all graphs to include ticks for all curves in the graphs, with appropriate legends. 

As for the second comment, We would like to request to keep it this way for two reasons. The first is that each figure currently consists of multiple sub-figures and is already taking up almost an entire page. Separating LOO and convergence plots will tend to make each figure go out of the scope of a single page. Although we can definitely break them up into two pages, but we feel having one figure per test case on one single page makes each figure more self-contained and helps readers to see the full picture. The second reason is that this arrangement of having LOO and convergence curve in one single plot is consistent with representations in previous literature. E.g., see Figure 2 and 3 in \cite{swirydowicz2020low}, Figure 5 and 6 in \cite{yamazaki2020low}. Nonetheless, we are open to adjusting them if there are strong opinions. To help, we also added a comment at line 479, where we first discuss results using figures, to clarify the content of figures.}

\paragraph{Line 546}
"In practice, especially on large distributed machines, one could use a smaller restart length and more restarts to trade convergence for communication savings."
Smaller restart means more iterations, and more iterations means more communication. Also at the end of each restart, you have an extra norm (which requires a dot product).

\rpy{Thank you for your feedback. We agree with the statement that smaller restart generally means more iterations which in turn implies more communication. However, it is possible to achieve less communication with smaller restarts in certain cases. The statement right after this line (now at line 557) explains such a scenario and we would like to expand on that.

As shown in Fig. 6, for a total of 600 iterations with 4 restarts (restart length = 150), four block iterations are required within each restart (100 + 23 + 23 + 4). Since each block iteration requires 4 global reductions and each restart requires one reduction to compute the norm of residual vectors, a total of $4\times 4 + 1 =17$ global reductions are needed per restart. This leads to a total of $17 \times 4$ = 68 global reductions. If one were to start with a smaller restart length of 100 instead of 150, a total of 6 restarts are required for the same 600 iterations in total. However, each restart of length 100 would only require one block iteration. Hence, the total number of global reductions would be $5\times 6$ = 30, which is fewer than 4 restarts.

We would like to highlight that the algorithm has the flexibility to adjust this restart length on the fly. As mentioned by the statement at line 557, one can start with a restart length of 150. With the adapted step size at $s\approx 100$, the restart length can be adjusted to $s$ for the next restart to reduce the communication costs. The initial step size estimator can also be used as a form of heuristics to inform the restart length. We acknowledge that adjusting restart length will ultimately alter the convergence behavior. Hence, it is a tradeoff between convergence and communication savings and the choice would depend on the actual use case. 

We hope this clarifies that statement. We have also added some clarification in text. See line 560.
}

\paragraph{Line 569}
"rapid growth/decay of Krylov basis vectors."
It should be either condition number or norms, but not vectors.

\rpy{Yes, we meant the condition numbers of Krylov basis vectors. We have clarified at line 582.}

\paragraph{Line 679} "growth starts depends"
Starts depending

\rpy{Grammatically we think the original text is correct. We meant the exact column (...) depends on the eigenvalue spectrum. Please see the statement currently at line 692.}

\paragraph{Line 717}
"done on Intel Xeon Platinum 8280 processors with 56 cores"
It is clear from the results that not one processor, but entire cluster of them was used. More details of hardware are needed. Also the details of software (version of compiler and libraries used) should be given for reproducibility.

\rpy{Thank you for pointing out this. We apologize for the ambiguity. We have added two short paragraphs at line 762-779 about both the software and hardware used in the parallel experiments.}

\paragraph{Line 754}
"MPK that can explore efficient fast memory usage."
This is a vague statement - please expand.

\rpy{We observed that the MPK kernel in adaptive s-step GMRES, which consists of consecutive SpMVs, is slightly faster than the standard SpMVs that are called at each iteration of MGS-GMRES. Both the MPK kernel in s-step GMRES and SpMVs in MGS-GMRES have approximately the same amount of floating point operators and communication costs. The main difference is that in MPK kernels, SpMVs are called repetitively before any orthogonalization. We want to highlight that we do not make any modification to SpMV kernels. We use the built-in SpMV available in PETSc. We simply call them multiple times in a MPK kernel (with some \texttt{axpy} vector operations for basis computation). Hence, they are essentially the same function calls, but in a different order. Hence, we conjectured that the small difference in performance of MPK/SpMV kernels is because compiler was able to optimize MPK better than standard SpMVs by exploring cache memory. For instance, in MPK, consecutive SpMVs allows the matrix (or part of it) to stay in cache longer for efficient computation. 

Due to the rewrite of results section, we have paraphrased the text with additional details. Please see the paragraph at line 825.}
