%%%%%%%% ICML 2023 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass[10pt,a4paper]{article}
\usepackage[margin = 1in]{geometry}
\usepackage[T1]{fontenc}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{natbib}
% \usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2023}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2023}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
% WRF: Custom package
\usepackage{booktabs}
\usepackage{authblk}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{float}
% \usepackage[bookmarksnumbered,
% hidelinks,
% colorlinks = true,
% linkcolor = blue,
% urlcolor  = blue,
% citecolor = blue,
% anchorcolor = blue]{hyperref}
\usepackage{tikz}
\usepackage{tikz-network}
\usepackage{pgfplots}
\usepackage{colortbl}
\usepackage{enumitem}
\usepackage{caption}
\setlist[description]{leftmargin=\parindent,labelindent=\parindent}
\newcommand{\tf}{\textsf{TensorFlow\texttrademark}}
\newcommand{\nan}{\textsf{nan}}
\newcommand{\ff}{$ \text{\sc flat}_{\text{\sc flow}} $}
\newcommand{\wf}{$ \text{\sc wrap}_{\text{\sc flow}} $}
\newcommand{\bkrw}{{\sc BKRW}}
\newcommand{\qcr}[1]{{\fontfamily{qcr}\selectfont #1}}
\newcommand{\tsf}[1]{{\text{\textsf{#1}}}}
\newcommand{\edge}[2]{\ensuremath{#1 \rightarrow #2}}
% Tikz related
\usetikzlibrary{decorations.pathreplacing,calc,shapes,positioning,arrows,arrows}
%\usepackage[left=2.00cm, right=2.00cm]{geometry}
\usepackage{pgfplots}
\usepackage{subcaption}
% \usepackage{subfigure}
\pgfplotsset{%
	,compat=1.12
	,every axis x label/.style={at={(current axis.right of origin)},anchor=north west}
	,every axis y label/.style={at={(current axis.above origin)},anchor=north east}
}
\usetikzlibrary{datavisualization,shapes.geometric,arrows.meta,decorations.markings, fit}
\usetikzlibrary{datavisualization.formats.functions}
\definecolor{scarlet}{rgb}{1.0, 0.13, 0.0}
\definecolor{brightmaroon}{rgb}{0.76, 0.13, 0.28}
\definecolor{mediumturquoise}{rgb}{0.28, 0.82, 0.8}
\definecolor{fandango}{rgb}{0.71, 0.2, 0.54}
\definecolor{antiquewhite}{rgb}{0.98, 0.92, 0.84}
\definecolor{babyblue}{rgb}{0.54, 0.81, 0.94}
\definecolor{brilliantlavender}{rgb}{0.96, 0.73, 1.0}
\definecolor{bronze}{rgb}{0.8, 0.5, 0.2}
\definecolor{cornsilk}{rgb}{1.0, 0.97, 0.86}
\definecolor{lavenderpink}{rgb}{0.98, 0.68, 0.82}
\definecolor{sandybrown}{rgb}{0.96, 0.64, 0.38}
\definecolor{celadon}{rgb}{0.67, 0.88, 0.69}
\newcommand{\blue}[1]{{\color{blue} #1}}
\newcommand{\todo}[1]{{\color{scarlet} TODO: #1}}
\newcommand{\tbd}{{\color{scarlet} \bf tbd}}
\newcommand{\ph}{CoxPH }
\newcommand{\skeptical}[1]{{\color{teal} SKEPTICAL: #1}}
\newcommand{\modification}[1]{{\color{fandango} #1}}
\newcommand{\ind}{\perp\!\!\!\!\perp} 
\newcommand{\esssup}{\text{esssup}}
\newcommand{\holderspace}[3]{\mathcal{W}^{#1}_{#2}(#3)}
% For editing with trace
\newcommand{\wrf}[1]{{\color{blue} WRF: #1}}
\newcommand{\wmz}[1]{{\color{blue} WMZ: #1}}
\newcommand{\yw}[1]{{\color{red} YW: #1}}
\newcommand{\qjw}[1]{{\color{blue} QJW: #1}}

\newcommand{\result}[2]{${#1}_{\pm#2}$}
\newcommand{\resultf}[2]{$\mathbf{#1}_{\pm#2}$}
\newcommand{\results}[2]{$\underline{#1}_{\pm#2}$}

\newcommand{\cn}[3]{N\left(#1, #2, #3\right)}
\newcommand{\tcn}[3]{\widetilde{N}\left(#1, #2, #3\right)}
\newcommand{\bn}[3]{N_{[]}\left(#1, #2, #3\right)}
\newcommand{\tbn}[3]{\widetilde{N}_{[]}\left(#1, #2, #3\right)}
\newcommand{\var}{\text{Var}}
\newcommand{\vcdim}[1]{\text{VC}\left(#1\right)}
\newcommand{\fdivergence}[3]{\text{D}_{\text{#1}}\left(#2 \parallel #3\right)}
% WRF: Custom package

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\theoremstyle{plain}
\newtheorem{condition}[theorem]{Condition}


\title{Neural Frailty Machine: Beyond proportional hazard assumption in neural survival regressions}

\author[$\dagger$]{Ruofan Wu$^*$}
\author[$\ddagger$]{Jiawei Qiao\thanks{Equal contribution}}
\author[$\S$]{Mingzhe Wu}
\author[$\ddagger$]{\authorcr Wen Yu}
\author[$\ddagger$]{Ming Zheng}
\author[$\dagger$]{Tengfei Liu}
\author[$\dagger$]{Tianyi Zhang}
\author[$\dagger$]{Weiqiang Wang}
\affil[$\dagger$]{Ant Group}
\affil[$\ddagger$]{Fudan University}
\affil[$\S$]{Coupang}


\begin{document}
    \maketitle
    
    \begin{abstract}
        We present neural frailty machine (NFM), a powerful and flexible neural modeling framework for survival regressions. The NFM framework utilizes the classical idea of multiplicative frailty in survival analysis to capture unobserved heterogeneity among individuals, at the same time being able to leverage the strong approximation power of neural architectures for handling nonlinear covariate dependence. Two concrete models are derived under the framework that extends neural proportional hazard models and nonparametric hazard regression models. Both models allow efficient training under the likelihood objective. Theoretically, for both proposed models, we establish statistical guarantees of neural function approximation with respect to nonparametric components via characterizing their rate of convergence. Empirically, we provide synthetic experiments that verify our theoretical statements. We also conduct experimental evaluations over $6$ benchmark datasets of different scales, showing that the proposed NFM models outperform state-of-the-art survival models in terms of predictive performance. Our code is publicly availabel at \href{https://github.com/Rorschach1989/nfm}{https://github.com/Rorschach1989/nfm}
        % \todo{Justify the usage of Hellinger distance, Argue why SODEN is not estimated in MIMIC-III, place the derivation of PF likelihood in the right place. Preditive performance is not guaranteed by theory, state it as only empirical evidence. }
    \end{abstract}
    
    \section{Introduction}
    Regression analysis of time-to-event data \cite{kalbfleisch2002statistical} has been among the most important modeling tools for clinical studies and has witnessed a growing interest in areas like corporate finance \cite{duffie2009frailty}, recommendation systems \cite{jing2017neural}, and computational advertising \cite{wu2015predicting}. The key feature that differentiates time-to-event data from other types of data is that they are often \emph{incompletely observed}, with the most prevailing form of incompleteness being the \emph{right censoring} mechanism \cite{kalbfleisch2002statistical}. In the right censoring mechanism, the duration time of a sampled subject is (sometimes) only known to be larger than the observation time instead of being recorded precisely. It is well known in the community of survival analysis that even in the case of linear regression, naively discarding the censored observations produces estimation results that are statistically biased \cite{buckley1979linear}, at the same time losses sample efficiency if the censoring proportion is high.\par 
    Cox's proportional hazard (\ph) model \cite{cox1972regression} using the convex objective of negative partial likelihood \cite{cox1975partial} is the \emph{de facto} choice in modeling right censored time-to-event data (hereafter abbreviated as censored data without misunderstandings). The model is \emph{semiparametric} \cite{bickel1993efficient} in the sense that the baseline hazard function needs no parametric assumptions. 
    % The rigorous theoretical properties of the maximum partial likelihood estimators were derived by \cite{andersen1982cox}. 
    The original formulation of \ph model assumes a linear form and therefore has limited flexibility since the truth is not necessarily linear. Subsequent studies extended \ph model to nonlinear variants using ideas from nonparametric regression \cite{huang1999efficient, cai2007partially, cai2008partially}, ensemble learning \cite{ishwaran2008random}, and neural networks \cite{faraggi1995neural, katzman2018deepsurv}. While such extensions allowed a more flexible nonlinear dependence structure with the covariates, the learning objectives were still derived under the proportional hazards (PH) assumption, which was shown to be inadequate in many real-world scenarios \cite{gray2000estimation}. The most notable case was the failure of modeling the phenomenon of crossing hazards \cite{stablein1985two}. It is thus of significant interest to explore extensions of \ph that both allow nonlinear dependence over covariates and relaxations of the PH assumption. \par 
    Frailty models \cite{wienke2010frailty, duchateau2007frailty} are among the most important research topics in modern survival analysis, in that they provide a principled way of extending \ph model via incorporating a multiplicative random effect to capture unobserved heterogeneity. The resulting parameterization contains many useful variants of \ph like the proportional odds model \cite{bennett1983analysis}, under specific choices of frailty families. While the theory of frailty models has been well-established \cite{murphy1994consistency, murphy1995asymptotic, parner1998asymptotic, kosorok2004robust}, most of them focused on the linear case. Recent developments on applying neural approaches to survival analysis \cite{katzman2018deepsurv, kvamme2019time, tang2022soden, rindt2022a} have shown promising results in terms of empirical predictive performance, with most of them lacking theoretical discussions. Therefore, it is of significant interest to build more powerful frailty models via adopting techniques in modern deep learning \cite{goodfellow2016deep} with provable statistical guarantees. \par
    In this paper, we present a general framework for neural extensions of frailty models called the \textbf{neural frailty machine (NFM)}. Two concrete neural architectures are derived under the framework: The first one adopts the proportional frailty assumption, allowing an intuitive interpretation of the neural \ph model with a multiplicative random effect.
    The second one further relaxes the proportional frailty assumption and could be viewed as an extension of nonparametric hazard regression (NHR) \cite{cox1990asymptotic, kooperberg1995hazard}, sometimes referred to as "fully neural" models under the context of neural survival analysis \cite{omi2019fully}. We summarize our contributions as follows.\par
    \begin{itemize}[leftmargin=*]
        % \setlength\itemsep{-0.5em}
        \item We propose the neural frailty machine (NFM) framework as a principled way of incorporating unobserved heterogeneity into neural survival regression models. The framework includes many commonly used survival regression models as special cases.
        \item We derive two model architectures based on the NFM framework that extend neural \ph models and neural NHR models. Both models allow stochastic training and scale to large datasets.
        \item We show theoretical guarantees for the two proposed models via characterizing the rates of convergence of the proposed nonparametric function estimators. The proof technique is different from previous theoretical studies on neural survival analysis and is applicable to many other types of neural survival models.
        \item We conduct extensive studies on various benchmark datasets at different scales. Under standard performance metrics, both models are empirically shown to perform competitively, matching or outperforming state-of-the-art neural survival models.
    \end{itemize}
    
    \section{Related works}
    \subsection{Nonlinear extensions of \ph}
    Most nonlinear extensions of \ph model stem from the equivalence of partial likelihood and semiparametric profile likelihood \cite{murphy2000profile} of \ph model, resulting in nonlinear variants that essentially replaces the linear term in partial likelihood with nonlinear variants: \cite{huang1999efficient} used smoothing splines, \cite{cai2007partially, cai2008partially} used local polynomial regression \cite{fan1996local}. The empirical success of tree-based models inspired subsequent developments like \cite{ishwaran2008random} that equip tree-based models such as gradient boosting trees and random forests with losses in the form of negative log partial likelihood. Early developments of neural survival analysis \cite{faraggi1995neural} adopted similar extension strategies and obtained neural versions of partial likelihood. Later attempts \cite{katzman2018deepsurv} suggest using the successful practice of stochastic training which is believed to be at the heart of the empirical success of modern neural methods \cite{hardt2016train}. However, stochastic training under the partial likelihood objective is highly non-trivial, as mini-batch versions of log partial likelihood \cite{katzman2018deepsurv} are no longer valid stochastic gradients of the full-sample log partial likelihood \cite{tang2022soden}. 
    
    \subsection{Beyond \ph in survival analysis}
    In linear survival modeling, there are standard alternatives to \ph such as the accelerated failure time (AFT) model \cite{buckley1979linear, ying1993large}, the extended hazard regression model \cite{etezadi1987extended}, and the family of linear transformation models \cite{zeng2006efficient}. While these models allow certain types of nonlinear extensions, the resulting form of (conditional) hazard function is still restricted to be of a specific form. The idea of nonparametric hazard regression (NHR) \cite{cox1990asymptotic, kooperberg1995hazard, strawderman1996asymptotic} further improves the flexibility of nonparametric survival analysis via directly modeling the conditional hazard function by nonparametric regression techniques such as spline approximation. Neural versions of NHR have been developed lately such as the CoxTime model \cite{kvamme2019time}. \cite{rindt2022a} used a neural network to approximate the conditional survival function and could be thus viewed as another trivial extension of NHR.\par
    Aside from developments in NHR, \cite{lee2018deephit} proposed a discrete-time model with its objective being a mix of the discrete likelihood and a rank-based score; \cite{zhong2021deep} proposed a neural version of the extended hazard model, unifying both neural \ph and neural AFT model; \cite{tang2022soden} used an ODE approach to model the hazard and cumulative hazard functions. 
    
    \subsection{Theoretical justification of neural survival models}
    Despite the abundance of neural survival models, assessment of their theoretical properties remains nascent. In \cite{zhong2021partially}, the authors developed minimax theories of partially linear cox model using neural networks as the functional approximator. \cite{zhong2021deep} provided convergence guarantees of neural estimates under the extended hazard model. The theoretical developments therein rely on specific forms of objective function (partial likelihood and kernel pseudo-likelihood) and are not directly applicable to the standard likelihood-based objective which is frequently used in survival analysis.
    
    \section{Methodology}
    \subsection{The neural frailty machine framework}
    % \subsection{From \ph to frailty models}
    Let $\tilde{T} \ge 0$ be the interested event time with survival function denoted by $S(t)=\mathbb{P}(\tilde{T}>t)$ associated with a feature(covariate) vector $Z \in \mathbb{R}^d $. Suppose that $\tilde{T}$ is a continuous random variable and let $f(t)$ be its density function. Then $\lambda(t)=f(t)/S(t)$ is the hazard function and $\Lambda(t)=\int_0^t\lambda(s)ds$ is the cumulative hazard function. Aside from the covariate $Z$, we use a positive scalar random variable $\omega \in \mathbb{R}^+$ to express the unobserved heterogeneity corresponding to individuals, or \emph{frailty}.
    \footnote{For example in medical biology, it was observed that genetically identical animals kept in as similar an environment as possible will typically not behave the same upon exposure to environmental carcinogens \cite{brennan2002gene}}. 
    In this paper we will assume the following generating scheme of $\tilde{T}$ via specifying its conditional hazard function:
    \begin{align}\label{eqn: frailty_general}
        \lambda(t| Z, \omega) = \omega \widetilde{\nu}(t, Z).
    \end{align}
    Here $\widetilde{\nu}$ is an unspecified non-negative function, and we let the distribution of $\omega$ be parameterized by a one-dimensional parameter $\theta \in \mathbb{R}$. 
    \footnote{The choice of one-dimensional frailty family is mostly for simplicity and clearness of theoretical derivations. Note that there exist multi-dimensional frailty families like the PVF family \cite{wienke2010frailty}. Generalizing our theoretical results to such kinds of families would require additional sets of regularity conditions, and will be left to future explorations.}
    The formulation \eqref{eqn: frailty_general} is quite general and contains several important models in both traditional and neural survival analysis:
    \begin{enumerate}[leftmargin=*]
        \item When $\omega$ follows parametric distributional assumptions, and $\widetilde{\nu}(t, Z) = \lambda(t) e^{\beta^\top Z}$, \eqref{eqn: frailty_general} reduces to the standard proportional frailty model \cite{kosorok2004robust}. A special case is when $\omega$ is degenerate, i.e., it has no randomness, then the model corresponds to the classic \ph model.
        \item When $\omega$ is degenerate and $\widetilde{\nu}$ is arbitrary, the model becomes equivalent to nonparametric hazard regression (NHR) \cite{cox1990asymptotic, kooperberg1995hazard}. In NHR, the function parameter of interest is usually the logarithm of the (conditional) hazard function.
        % the model is essentially the same as the setup in several recent works on "fully-neural" approaches to survival analysis and point process modeling \cite{omi2019fully, rindt2022a}
    \end{enumerate}
    In this paper we construct neural approximations to the logarithm of $\widetilde{\nu}$, i.e., $\nu(t, Z) = \log \widetilde{\nu}(t, Z)$. The resulting models are called \textbf{Neural Frailty Machines (NFM)}. Depending on the prior knowledge of the function $\nu$, we propose two function approximation schemes:\par
    \textbf{The proportional frailty (PF) scheme} assumes the dependence of $\nu$ on event time and covariates to be completely \emph{decoupled}, i.e., 
    \begin{align}\label{eqn: proportional_frailty}
        \nu(t, Z) = h(t) + m(Z).
    \end{align}
    Proportional-style assumption over hazard functions has been shown to be a useful inductive bias in survival analysis. We will treat both $h$ and $m$ in \eqref{eqn: proportional_frailty} as function parameters, and device two multi-layer perceptrons (MLP) to approximate them separately. \par
    \textbf{The fully neural (FN) scheme} imposes no a priori assumptions over $\nu$ and is the most general version of NFM. It is straightforward to see that the most commonly used survival models, such as \ph, AFT\cite{ying1993large}, EH\cite{zhong2021deep}, or PF models are included in the proposed model space as special cases. We treat $\nu = \nu(t, Z)$ as the function parameter with input dimension $d + 1$ and use a multi-layer perceptron (MLP) as the function approximator to $\nu$. Similar approximation schemes with respect to the hazard function have been proposed in some recent works \cite{omi2019fully, rindt2022a}, referred to as "fully neural approaches" without theoretical characterizations. \par
    % The resulting frailty model is also closely related to the nonparametric frailty model proposed in \cite{du2010frailty}, where the authors use regression splines as the function approximator. 
    \textbf{The choice of frailty family} There are many commonly used families of frailty distributions \cite{kosorok2004robust, duchateau2007frailty, wienke2010frailty}, among which the most popular one is the \emph{gamma frailty}, where $\omega$ follows a gamma distribution with mean $1$ and variance $\theta$. We briefly introduce some other types of frailty families in appendix \ref{sec: frailty_spec}.
    
    \subsection{Parameter learning under censored observations}
    In time-to-event modeling scenarios, the event times are typically observed under right censoring. Let $C$ be the right censoring time which is assumed to be conditionally independent of the event time $\tilde{T}$ given $Z$, i.e., $\tilde{T} \ind C | Z$. In data collection, one can observe the minimum of the survival time and the censoring time, that is, observe $T=\tilde{T}\wedge C$ as well as the censoring indicator $\delta=I(\tilde{T}\leqslant C)$, where $a\wedge b=\min(a,b)$ for constants $a$ and $b$ and $I(\cdot)$ stands for the indicator function. We assume $n$ independent and identically distributed (i.i.d.) copies of $(T, \delta, Z)$ are used as the training sample $(T_i, \delta_i, Z_i), i \in [n]$, where we use $[n]$ to denote the set $\{1, 2, \ldots, n\}$. Additionally, we assume the unobserved frailties are independent and identically distributed, i.e., $\omega_i \overset{\text{i.i.d.}}{\sim} f_\theta(\omega), i \in [n]$. 
    % Next we use the FN scheme of NFM as an example to derive the learning procedure based on the \textbf{observed log-likelihood (OLL)} objective. 
    Next, we derive the learning procedure based on the \textbf{observed log-likelihood (OLL)} objective under both PF and FN scheme.
    To obtain the observed likelihood, we first integrate the conditional survival function given the frailty:
    \begin{align}
        \begin{aligned}
            S(t|Z) &= \mathbb{E}_{\omega \sim f_\theta}\left[e^{-\omega \int_0^t e^{\nu(s, Z)}ds}\right] \\
            &=: e^{- G_\theta\left(\int_0^t e^{\nu(s, Z)}ds\right)}.
        \end{aligned}
    \end{align}
    Here the \emph{frailty transform} $G_\theta (x) = - \log \left(\mathbb{E}_{\omega \sim f_\theta}\left[e^{-\omega x}\right]\right)$ is defined as the negative of the logarithm of the Laplace transform of the frailty distribution. The conditional cumulative hazard function is thus $\Lambda(t|Z) = G_\theta(\int_0^t e^{\nu(s, Z)}ds)$. For the PF scheme of NFM, we use two MLPs $\widehat{h} = \widehat{h}(t; \mathbf{W}^h, \mathbf{b}^h)$ and $\widehat{m} = \widehat{m}(Z; \mathbf{W}^m, \mathbf{b}^m)$ as function approximators to $\nu$ and $m$, parameterized by $(\mathbf{W}^h, \mathbf{b}^h)$ and $(\mathbf{W}^m, \mathbf{b}^m)$, respectively. 
    \footnote{Here we adopt the conventional notation that $\mathbf{W}$ is the collection of the weight matrices of the MLP in all layers, and $\mathbf{b}$ corresponds to the collection of the bias vectors in all layers.}
    According to standard results on censored data likelihood \cite{kalbfleisch2002statistical}, we write the learning objective under the PF scheme as:
    \begin{align}\label{eqn: pf_obj}
        \begin{aligned}
            &\mathcal{L}(\mathbf{W}^h, \mathbf{b}^h, \mathbf{W}^m, \mathbf{b}^m, \theta) \\
            =& \frac{1}{n}\left[\sum_{i \in [n]} \delta_i \log g_{\theta}\left(e^{\widehat{m}(Z_i)}\int_{0}^{T_i}e^{\widehat{h}(s)}ds\right) +\delta_i \widehat{h}(T_i)+\delta_i \widehat{m}(Z_i) -G_{\theta}\left(e^{\widehat{m}(Z_i)}\int_{0}^{T_i}e^{\widehat{h}(s)}ds\right)\right].
        \end{aligned}
    \end{align}
    Here we define $g_\theta(x) = \frac{\partial}{\partial x}G_\theta (x)$. Let $(\widehat{\mathbf{W}}^h_n, \widehat{\mathbf{b}}^h_n, \widehat{\mathbf{W}}^m_n, \widehat{\mathbf{b}}^m_n, \widehat{\theta}_n)$ be the maximizer of \eqref{eqn: pf_obj} and further denote $\widehat{h}_n(t) = \widehat{h}(t; \widehat{\mathbf{W}}^h_n, \widehat{\mathbf{b}}^h_n)$ and $\widehat{m}_n(Z) = \widehat{m}(Z; \widehat{\mathbf{W}}^m_n, \widehat{\mathbf{b}}^m_n)$. 
    The resulting estimators for conditional cumulative hazard and survival functions are:
    \begin{align}
        \begin{aligned}
            &\widehat{\Lambda}_{\tsf{PF}}(t|Z) = G_{\widehat{\theta}_n}\left(\int_0^t e^{\widehat{h}_n(s) + \widehat{m}_n(Z)} ds\right),\\
            &\widehat{S}_{\tsf{PF}}(t|Z) = e^{-\widehat{\Lambda}_{\tsf{PF}}(t|Z)},
        \end{aligned}
    \end{align}
    For the FN scheme, we use $\widehat{\nu} = \widehat{\nu}(t, Z; \mathbf{W}^\nu, \mathbf{b}^\nu)$ to approximate $\nu(t, Z)$ parameterized by $(\mathbf{W}^\nu, \mathbf{b}^\nu)$. The OLL objective is written as:
    % \begin{align}\label{eqn: mlp}
    %     \text{MLP}\left(x; \mathbf{W}, \mathbf{b}\right) = W_L \sigma(\cdots \sigma(W_2\sigma(W_1 x + b_1) + b_2)+\cdots)+b_L, 
    % \end{align}
    % with input $x \in \mathbb{R}^{d_I}$ and output a scalar. The parameters of the MLP is the collection of weight matrices $\mathbf{W} = \{W_l\}_{l \in [L]}$ with $W_1 \in \mathbb{R}^{d_I \times d_H}$, $W_l \in \mathbb{R}^{d_H \times d_H}$ for $l\ in \{2, \ldots, L-1\}$ and $W_L \in \mathbb{R}^{d_H}$, as well as the collection of bias vectors $\mathbf{b} = \{b_l\}_{l \in [L]}$.
    % The following multi-layer perceptron is devised as the function approximator of $\nu(t, Z)$:
    % \begin{align}
    %     \widehat{\nu}(t, Z; \mathbf{W}, \mathbf{b}) = W_L \sigma(\cdots \sigma(W_2\sigma(W_1 [t\|Z] + b_1) + b_2)+\cdots)+b_L.
    % \end{align}
    % Here we use $[t \| Z]$ to denote the concatenation of $t$ and $Z$, the parameters of the MLP is the collection of weight matrices $\mathbf{W} = \{W_l\}_{l \in [L]}$ and bias vectors $\mathbf{b} = \{b_l\}_{l \in [L]}$, with $L$ being the \emph{depth} of the neural network. According to standard results on censored data likelihood \cite{kalbfleisch2002statistical}, we write the learning objective as:
    \begin{align}\label{eqn: fn_obj}
        \begin{aligned}
            &\mathcal{L}(\mathbf{W}^\nu, \mathbf{b}^\nu, \theta) \\
            =& \frac{1}{n}\left[\sum_{i \in [n]} \delta_i \log g_\theta\left(\int_0^{T_i} e^{\widehat{\nu}(s, Z_i; \mathbf{W}^\nu, \mathbf{b}^\nu)}ds\right) + \delta_i \widehat{\nu}(T_i, Z_i; \mathbf{W}^\nu, \mathbf{b}^\nu) - G_\theta\left(\int_0^{T_i} e^{\widehat{\nu}(s, Z_i; \mathbf{W}^\nu, \mathbf{b}^\nu)}ds\right)\right].
        \end{aligned}
    \end{align}
    Let $(\widehat{\mathbf{W}}^\nu_n, \widehat{\mathbf{b}}^\nu_n, \widehat{\theta}_n)$ be the maximizer of \eqref{eqn: fn_obj}, and further denote $\widehat{\nu}_n(t, Z) = \widehat{\nu}(t, Z; \widehat{\mathbf{W}}^\nu_n, \widehat{\mathbf{b}}^\nu_n)$. The conditional cumulative hazard and survival functions are therefore estimated as:
    \begin{align}
        \begin{aligned}
            &\widehat{\Lambda}_{\tsf{FN}}(t|Z) = G_{\widehat{\theta}_n}\left(\int_0^t e^{\widehat{\nu}_n(s, Z)} ds\right), \\
            &\widehat{S}_{\tsf{FN}}(t|Z) = e^{-\widehat{\Lambda}_{\tsf{FN}}(t|Z)}.
        \end{aligned}
    \end{align}
    The evaluation of objectives like \eqref{eqn: fn_obj} and its gradient requires computing a definite integral of an exponentially transformed MLP function. Instead of using exact computations that are available for only a restricted type of activation functions and network structures, we use numerical integration for such kinds of evaluations, using the method of Clenshaw-Curtis quadrature \cite{boyd2001chebyshev}, which has shown competitive performance and efficiency in recent applications to monotonic neural networks \cite{wehenkel2019unconstrained}.
    \begin{remark}
        The interpretation of frailty terms differs in the two schemes. In the PF scheme, introducing the frailty effect strictly increases the modeling capability (i.e., the capability of modeling crossing hazard) in comparison to \ph or neural variants of \ph \cite{kosorok2004robust}. In the FN scheme, it is arguable that in the i.i.d. case, the marginal hazard function is a reparameterization of the hazard function in the context of NHR. Therefore, we view the incorporation of frailty effect as injecting a domain-specific inductive bias that has proven to be useful in survival analysis and time-to-event regression modeling and verify this claim empirically in section \ref{sec: benchmark_data}. Moreover, frailty becomes especially helpful when handling correlated or clustered data where the frailty term is assumed to be shared among certain groups of individuals \cite{parner1998asymptotic}. Extending NFM to such scenarios is valuable and we left it to future explorations.
    \end{remark}

    \section{Theoretical results}\label{sec: theory}
    In this section, we present theoretical properties of both NFM estimates by characterizing their rates of convergence when the underlying event data follows corresponding model assumptions. The proof technique is based on the method of sieves \cite{shen1994convergence, shen1997methods, chen2007large} that views neural networks as a special kind of nonlinear sieve \cite{chen2007large} that satisfies desirable approximation properties \cite{yarotsky2017error}. Since both models produce estimates of function parameters, we need to specify a suitable function space to work with. Here we choose the following H\"older ball as was also used in previous works on nonparametric estimation using neural networks \cite{schmidt2020nonparametric, farrell2021deep, zhong2021partially}
    \begin{align}\label{eqn: holder_ball}
        \holderspace{\beta}{M}{\mathcal{X}} = \left\lbrace f: \max_{\mathbf{\alpha}: \left|\mathbf{\alpha}\right|\le \beta }\underset{x \in \mathcal{X}}{\esssup} \left|D^{\mathbf{\alpha}}(f(x))\right| \le M\right\rbrace,
    \end{align}
    where the domain $\mathcal{X}$ is assumed to be a subset of $d$-dimensional euclidean space. $\mathbf{\alpha} = (\alpha_1, \ldots, \alpha_d)$ is a $d$-dimensional tuple of nonnegative integers satisfying $\left|\mathbf{\alpha}\right| = \alpha_1 + \cdots + \alpha_d$ and $D^{\mathbf{\alpha}}f = \frac{\partial^{\left|\mathbf{\alpha}\right|}f}{\partial x_1^{\alpha_1} \cdots x_d^{\alpha_d}}$ is the weak derivative of $f$. Now assume that $M$ is a reasonably large constant, and let $\Theta$ be a closed interval over the real line. We make the following assumptions for the \emph{true parameters} under both schemes:
    \begin{condition}[True parameter, PF scheme]\label{cond: param_PF}
        The euclidean parameter $\theta_0 \in \Theta \subset \mathbb{R}$, and the two function parameters $m_0 \in \holderspace{\beta}{M}{[-1, 1]^d}, h_0 \in \holderspace{\beta}{M}{[0, \tau]}$, and $\tau > 0$ is the ending time of the study duration, which is usually adopted in the theoretical studies in survival analysis \cite{van2000asymptotic}.
    \end{condition}
    \begin{condition}[True parameter, FN scheme]\label{cond: param_FN}
        The euclidean parameter $\theta_0 \in \Theta \subset \mathbb{R}$, and the function parameter $\nu_0 \in \holderspace{\beta}{M}{[0, \tau] \times [-1, 1]^d}$, %where $M_\nu$ is a sufficiently large constant.
    \end{condition}
    
    Next, we construct sieve spaces for function parameter approximation via restricting the complexity of the MLPs to "scale" with the sample size $n$. 
    \begin{condition}[Sieve space, PF scheme]\label{cond: sieve_PF}
        % The estimated frailty parameter $\widehat{\theta}$ lies in $\Theta$. The depth of both approximating networks $\widehat{h}$ and $\widehat{m}$ is of order $O(\log n)$. For $\widehat{h}$, the total number of parameters is of the order $O(n^{\frac{1}{\beta + d}}\log n)$; For $\widehat{m}$, the total number of parameters is of the order $O(n^{\frac{d}{\beta + d}}\log n)$. Suppose that $\widehat{h}\in \holderspace{\beta}{M_{h}}{[0, \tau]}$ and $\widehat{m}\in \holderspace{\beta}{M_{m}}{[-1, 1]^d}$
        The sieve space $\mathcal{H}_n$ is constructed as a set of MLPs satisfying $\widehat{h} \in \holderspace{\beta}{M_{h}}{[0, \tau]}$, with depth of order $O(\log n)$ and total number of parameters of order $O(n^{\frac{1}{\beta + d}}\log n)$. The sieve space $\mathcal{M}_n$ is constructed as a set of MLPs satisfying $\widehat{m} \in \holderspace{\beta}{M_{m}}{[-1, 1]^d}$, with depth of order $O(\log n)$ and total number of parameters of order $O(n^{\frac{d}{\beta + d}}\log n)$. Here $M_h$ and $M_m$ are sufficiently large constants such that every function in $\holderspace{\beta}{M}{[-1, 1]^d}$ and $\holderspace{\beta}{M}{[0, \tau]}$ could be accurately approximated by functions inside $\mathcal{H}_n$ and $\mathcal{M}_n$, according to \cite[Theorem 1]{yarotsky2017error}.
    \end{condition}
    \begin{condition}[Sieve space, FN scheme]\label{cond: sieve_FN}
        % The estimated frailty parameter $\widehat{\theta}$ still lies in $\Theta$. The depth of the approximating network $\widehat{\nu}$ is of order $O(\log n)$ and the number of parameters is of the order $O(n^{\frac{d+1}{\beta + d + 1}}\log n)$. Suppose that $\widehat{\nu}\in  \holderspace{\beta}{M_{\nu}}{[0, \tau] \times [-1, 1]^d}$.
        The sieve space $\mathcal{V}_n$ is constructed as a set of MLPs satisfying $\widehat{\nu} \in \holderspace{\beta}{M_{\nu}}{[0, \tau]}$, with depth of order $O(\log n)$ and total number of parameters of order $O(n^{\frac{d+1}{\beta + d + 1}}\log n)$. Here $M_\nu$ is a sufficiently large constant such that $\mathcal{V}_n$ satisfies approximation properties, analogous to condition \ref{cond: sieve_PF}.
    \end{condition}
    For technical reasons, we will assume the nonparametric function estimators are constrained to fall inside the corresponding sieve spaces, i.e., $\widehat{h}_n \in \mathcal{H}_n$, $\widehat{m}_n \in \mathcal{M}_n$ and $\widehat{\nu} \in \mathcal{V}_n$. This will not affect the implementation of optimization routines as was discussed in \cite{farrell2021deep}. Furthermore, we restrict the estimate $\widehat{\theta}_n \in \Theta$ in both PF and FN schemes.
    
    Additionally, we need the following regularity condition on the function $G_\theta(x)$:
    \begin{condition}\label{cond: G}
        $G_{\theta}(x)$ is viewed as a bivariate function $G: \Theta \times \mathcal{B} \mapsto \mathbb{R}$, where $\mathcal{B}$ is a compact set on $\mathbb{R}$. 
        The functions $G_{\theta}(x)$,$\frac{\partial}{\partial \theta}G_{\theta}(x)$,$\frac{\partial}{\partial x}G_{\theta}(x)$,$\log g_{\theta}(x)$,$\frac{\partial}{\partial \theta}\log g_{\theta}(x)$, $\frac{\partial}{\partial x}\log g_{\theta}(x)$ are bounded on $\Theta \times \mathcal{B}$.
    \end{condition}
    We define two metrics that measures convergence of parameter estimates: For the PF scheme, let $\phi_0 = (h_0, m_0, \theta_0)$ be the true parameters and $\widehat{\phi}_n = (\widehat{h}_n, \widehat{m}_n, \widehat{\theta}_n)$ be the estimates. We abbreviate $\mathbb{P}_{\phi_0, Z=z}$ as the conditional probability distribution of $(T, \delta)$ given $Z=z$ under the true parameter, and $ \mathbb{P}_{\widehat{\phi}_n, Z=z} $ as the conditional probability distribution of $(T, \delta)$ given $Z=z$ under the estimates. Define the following metric
    \begin{align}
        d_{\tsf{PF}}\left(\widehat{\phi}_n, \phi_0\right) = \sqrt{\mathbb{E}_{z\sim \mathbb{P}_Z}\left[H^{2}(\mathbb{P}_{\widehat{\phi}_n, Z=z}\parallel\mathbb{P}_{\phi_0, Z=z})\right]},
    \end{align}
    where $H^2(\mathbb{P}\parallel \mathbb{Q}) = \int \left(\sqrt{d\mathbb{P}} - \sqrt{d\mathbb{Q}}\right)^2$ is the squared Hellinger distance between probability distributions $\mathbb{P}$ and $\mathbb{Q}$. The case for the FN scheme is similar: Let $\psi_0 = (\nu_0, \theta_0)$ be the parameters and $\widehat{\nu}_n = (\widehat{\nu}_n, \widehat{\theta}_n)$ be the estimates. Analogous to the definitions above, we define $\mathbb{P}_{\psi_0, Z=z}$ as the true conditional distribution given $Z=z$, and $ \mathbb{P}_{\widehat{\psi}_n, Z=z} $ be the estimated conditional distribution, we will use the following metric in the FN scheme:
    \begin{align}
        d_{\tsf{FN}}\left(\widehat{\psi}_n, \psi_0\right) = \sqrt{\mathbb{E}_{z\sim \mathbb{P}_Z}\left[H^{2}(\mathbb{P}_{\widehat{\psi}_n, Z=z}\parallel\mathbb{P}_{\psi_0, Z=z})\right]}.
    \end{align}
    Now we state our main theorems. We denote $\mathbb{P}$ as the data generating distribution and use $\widetilde{O}$ to hide poly-logarithmic factors in the big-O notation.
    \begin{theorem}[Rate of convergence, PF scheme]\label{thm: rate_pf}
        In the PF scheme, under condition \ref{cond: param_PF}, \ref{cond: sieve_PF}, \ref{cond: G}, we have that $d_{\tsf{PF}}\left(\widehat{\phi}_n, \phi_0\right) = \widetilde{O}_\mathbb{P}\left(n^{-\frac{\beta}{2\beta+2d}}\right)$. 
    \end{theorem}
    \begin{theorem}[Rate of convergence, FN scheme]\label{thm: rate_fn}
        In the FN scheme, under condition \ref{cond: param_FN}, \ref{cond: sieve_FN}, \ref{cond: G}, we have that $d_{\tsf{FN}}\left(\widehat{\psi}_n, \psi_0\right) = \widetilde{O}_\mathbb{P}\left(n^{-\frac{\beta}{2\beta+2d+2}}\right)$.
    \end{theorem}
    \begin{remark}
        The idea of using Hellinger distance to measure the convergence rate of sieve MLEs was proposed in \cite{wong1995probability}. Obtaining rates under a stronger topology such as $L_2$ is possible if the likelihood function satisfies certain conditions such as the curvature condition \cite{farrell2021deep}. However, such kind of conditions are in general too stringent for likelihood-based objectives, instead, we use Hellinger convergence that has minimal requirements. Consequently, our proof strategy is applicable to many other survival models that rely on neural function approximation such as \cite{rindt2022a}, with some modification to the regularity conditions. For proper choices of metrics in sieve theory, see also the discussion in \cite[Chapter 2]{chen2007large}.
    \end{remark}
    \section{Experiments}\label{sec: experiments}
    In this section, we assess the empirical performance of NFM. We first conduct synthetic experiments for verifying the theoretical convergence guarantees developed in section \ref{sec: theory}. To further illustrate the empirical efficacy of NFM, we evaluate the predictive performance of NFM over $6$ benchmark datasets ranging from small scale to large scale, against state-of-the-art baselines.
    \subsection{Synthetic experiments}
    We conduct synthetic experiments to validate our proposed theory. The underlying data generating scheme is as follows: First, we generate a $5$-dimensional feature $Z$ that is independently sampled from the uniform distribution over the interval $[0, 1]$. The (true) conditional hazard function of the event time takes the form of the proportional frailty model \eqref{eqn: proportional_frailty}, with $h(t) = t$ and $m(Z) = \sin(\langle Z, \beta \rangle) + \langle\sin(Z), \beta \rangle$, where $\beta = (0.1, 0.2, 0.3, 0.4, 0.5)$. The frailty $\omega$ is generated according to a gamma distribution with mean and variance equal to 1. 
    We use this generating model to assess the recovery guarantee of both NFM modeling schemes via inspecting the empirical recovery of $\nu(t, Z)$. For the PF scheme, we have more underlying information about the generating model, and we present an additional assessment regarding the recovery of $m(Z)$ in appendix \ref{sec: m_z}. We generate three training datasets of different scales, with $n \in \{1000, 5000, 10000\}$. A censoring mechanism is applied such that the censoring ratio is around $40\%$ for each dataset. The assessment will be made on a fixed test sample of $100$ hold-out points that are independently drawn from the generating scheme of the event time. We report a more detailed description of the implementation of the data generating scheme and model architectures in appendix \ref{sec: synthetic_details}. We present the results of our synthetic data experiments in figure \ref{fig: synthesis_log_hazard}. The evaluation results suggest that both NFM schemes are capable of approximating complicated nonlinear functions using a moderate amount of data, i.e., $n \ge 1000$. 
    
    \begin{figure}
        \centering
        % \begin{tabular}{ccc}
        % \input{m_1000_pf} & \input{m_1000_pf} & \input{m_1000_pf} \\
        % \input{hazard_10000_pf}  & \input{hazard_10000_pf} & \input{hazard_10000_pf}
        % \end{tabular}
        % }
        \begin{subfigure}[b]{0.3\textwidth}
         \input{figs/log_hazard_1000_pf}
        \end{subfigure}
        \begin{subfigure}[b]{0.3\textwidth}
         \input{figs/log_hazard_5000_pf}
        \end{subfigure}
        \begin{subfigure}[b]{0.3\textwidth}
         \input{figs/log_hazard_10000_pf}
        \end{subfigure}
        \begin{subfigure}[b]{0.3\textwidth}
         \input{figs/log_hazard_1000_fn}
        \end{subfigure}
        \begin{subfigure}[b]{0.3\textwidth}
         \input{figs/log_hazard_5000_fn}
        \end{subfigure}
        \begin{subfigure}[b]{0.3\textwidth}
         \input{figs/log_hazard_10000_fn}
        \end{subfigure}
        % \caption{Visualizations of synthetic data results under the PF scheme of NFM framework. The plots in the first row compare the empirical estimates of the nonparametric component $m(Z)$ in \eqref{eqn: proportional_frailty} to its oracle value over $100$ test points. The second row uses the same set of test points and compares the estimates and true values of $\nu(t, Z)$ in \eqref{eqn: frailty_general}. The horizontal axis of each plot stands for the indices of the test points.}
        \caption{Visualizations of synthetic data results under the NFM framework. The plots in the first row compare the empirical estimates of the nonparametric component $\nu(t, Z)$ against its true value evaluated on $100$ hold-out points, under the PF scheme. The plots in the second row are obtained using the FN scheme, with analogous semantics to the first row.}
        \label{fig: synthesis_log_hazard}
    \end{figure}
    
    \subsection{Real-world data experiments}\label{sec: benchmark_data}
    \textbf{Datasets} We use five survival datasets and one non-survival dataset for evaluation. The survival datasets include the Molecular Taxonomy of Breast Cancer International Consortium (METABRIC) \cite{curtis2012metabric}, the Rotterdam tumor bank and German Breast Cancer Study Group (RotGBSG)\cite{knaus1995support}, the Assay Of Serum Free Light Chain (FLCHAIN) \cite{dispenzieri2012flchain}, the Study to Understand Prognoses Preferences Outcomes and Risks of Treatment (SUPPORT) \cite{knaus1995support}, and the Medical Information Mart for Intensive Care (MIMIC-III) \cite{johnson2016mimic}. For all the survival datasets, the event of interest is defined as the mortality after admission. In our experiments, we view METABRIC, RotGBSG, FLCHAIN, and SUPPORT as small-scale datasets and MIMIC-III as a moderate-scale dataset. We additionally use the KKBOX dataset \cite{kvamme2019time} as a large-scale evaluation. In this dataset, an event time is observed if a customer churns from the KKBOX platform. We summarize the basic statistics of all the datasets in table \ref{tab: datasets}.\par
    \textbf{Baselines} We compare NFM with $12$ baselines. The first one is the linear \ph model \cite{cox1972regression}. Gradient Boosting Machine (GBM) \cite{friedman2001greedy, chen2016xgboost} and Random Survival Forests (RSF) \cite{ishwaran2008random} are two tree-based nonparametric survival regression methods. DeepSurv \cite{katzman2018deepsurv} and CoxTime \cite{kvamme2019time} are two models that adopt neural variants of partial likelihood as objectives. SuMo-net \cite{rindt2022a} is a neural variant of NHR. We additionally chose six latest state-of-the-art neural survival models: DeepHit \cite{lee2018deephit}, SurvNode \cite{groha2020general}, DeepEH \cite{zhong2021deep}, DCM \cite{nagpal2021deep}, DeSurv \cite{danks2022derivative} and SODEN \cite{tang2022soden}. Among the chosen baselines, DeepSurv and SuMo-net are viewed as implementations of neural \ph and neural NHR and are therefore of particular interest for the empirical verification of the efficacy of frailty. \par
    \begin{table}[]
        \centering
        \caption{Survival prediction results measured in IBS and INBLL metric (\%) on four small-scale survival datasets. In each column, the \textbf{boldfaced} score denotes the best result and the \underline{underlined} score represents the second-best result.}
        \resizebox{\textwidth}{!}{%
            \input{tables/moderate_data_results_rebuttal}
        }
        \label{tab: survival_results}
    \end{table}
    \begin{table}[]
        \centering
        \small
        \caption{Survival prediction results measured in IBS and INBLL metric (\%) on two larger datasets. In each column, the \textbf{boldfaced} score denotes the best result and the \underline{underlined} score represents the second-best result. Two models are not reported, namely SODEN and DeepEH, as we found empirically that their computational/memory cost is significantly worse than the rest, and we fail to obtain reasonable performances over the two datasets for these two models.}
        % \resizebox{0.6\textwidth}{!}{%
            \input{tables/big_data_results_rebuttal}
        % }
        \label{tab: kkbox}
    \end{table}
    \textbf{Evaluation strategy} We use two standard metrics in survival predictions for evaluating model performance: integrated Brier score (IBS) and integrated negative binomial log-likelihood (INBLL). Both metrics are derived from the following:
    \begin{align}
        \begin{aligned}
            \mathcal{S}(\ell, t_1, t_2) =\int_{t_2}^{t_1}\dfrac{1}{n}\sum_{i=1}^n \left[\dfrac{\ell(0, \widehat{S}(t|Z_i)) I(T_i \le t, \delta_i = 1)}{\widehat{S}_C(T_i)} + \dfrac{\ell(1, \widehat{S}(t|Z_i))I(T_i > t)}{\widehat{S}_C(t)}\right] dt.
        \end{aligned}
    \end{align}
    Where $\widehat{S}_C(t)$ is an estimate of the survival function $S_C(t)$ of the censoring variable, obtained by the Kaplan-Meier estimate \cite{kaplan1958nonparametric} of the censored observations on the test data. $\ell: \{0, 1\} \times [0, 1] \mapsto \mathbb{R}^+$ is some proper loss function for binary classification \cite{gneiting2007strictly}. The IBS metric corresponds to $\ell$ being the square loss, and the INBLL metric corresponds to $\ell$ being the negative binomial (Bernoulli) log-likelihood \cite{graf1999assessment}. Both IBS and INBLL are proper scoring rules if the censoring times and survival times are independent. 
    \footnote{Otherwise, one may pose a covariate-dependent model on the censoring time and use $\widehat{S}_C(t|Z)$ instead of $\widehat{S}_C(t)$. We adopt the Kaplan-Meier approach since it's still the prevailing practice in evaluations of survival predictions.} We additionally report the result of another widely used metric, the concordance index (C-index), in appendix \ref{sec: additional_experiments}.
    Since all the survival datasets do not have standard train/test splits, we follow previous practice \cite{zhong2021deep} that uses $5$-fold cross-validation (CV): $1$ fold is for testing, and $20\%$ of the rest is held out for validation. In our experiments, we observed that a single random split into $5$ folds does not produce stable results for most survival datasets. Therefore we perform $10$ different CV runs for each survival dataset and report average metrics as well as their standard deviations. For the KKBOX dataset, we use the standard train/valid/test splits that are available via the \texttt{pycox} package \cite{kvamme2019time} and report results based on $10$ trial runs. \par
    \textbf{Experimental setup} We follow standard preprocessing strategies \cite{katzman2018deepsurv, kvamme2019time, zhong2021deep} that standardize continuous features into zero mean and unit variance, and do one-hot encodings for all categorical features. 
    We adopt MLP with ReLU activation for all function approximators, including $\widehat{h}$, $\widehat{m}$ in PF scheme, and $\widehat{\nu}$ in FN scheme, across all datasets, with the number of layers (depth) and the number of hidden units (width) within each layer being tunable. We tune the frailty transform over several standard choices detailed in appendix \ref{sec: public_data_details}. We find that the gamma frailty configuration performs reasonably well across all tasks and is recommended to be the default choice. 
    % Across all the datasets, we train $100$ epochs with tunable batch size using the Adam \cite{kingma2014adam} optimizer with tunable learning rates and weight decay coefficient. An early stopping strategy is applied according to the loss over validation data. 
    A more detailed description of the tuning procedure, as well as training configurations for baseline models, are reported in appendix \ref{sec: public_data_details}.\par
    \textbf{Results} we report experimental results of small-scale datasets in table \ref{tab: survival_results}, and results of two larger datasets in table \ref{tab: kkbox}. The proposed NFM framework achieves the best performance on $5$ of the $6$ datasets. The improvement over baselines is particularly evident in METABRIC, SUPPORT, and MIMIC-III datasets. \par
    % Moreover, in comparison to their non-frailty counterparts (DeepSurv for PF scheme and SuMo for FN scheme), the corresponding NFM models exhibit significantly increases performance, thereby verifying the efficacy of the frailty formulation.\
    \textbf{Benefits of frailty} to better understand the additional benefits of introducing the frailty formulation, we compute the (relative) performance gain of NFM-PF and NFM-FN, against their non-frailty counterparts, namely DeepSurv \cite{katzman2018deepsurv} and SuMo-net \cite{rindt2022a}. The evaluation is conducted for all three metrics mentioned in this paper. The results are shown in table \ref{tab: frailty_benefits}. The results suggest a solid improvement in incorporating frailty, as the relative increase in performance could be over $10\%$ for both NFM models. A more detailed discussion is presented in section \ref{sec: benefits_frailty}.
    % \vspace{-1mm}
    \section{Conclusion}
    % \vspace{-1mm}
    In this paper, we make principled explorations on applying the idea of frailty models in modern survival analysis to neural survival regressions. A flexible and scalable framework called NFM is proposed that includes many useful survival models as special cases. Under the framework, we study two derived model architectures both theoretically and empirically. Theoretically, we obtain the rates of convergences of the nonparametric function estimators based on neural function approximation. Empirically, we demonstrate the superior predictive performance of the proposed models by evaluating several benchmark datasets. 
    \bibliography{transformation}
    \bibliographystyle{unsrtnat}
    % \bibliographystyle{plainnat}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
% \section{You \emph{can} have an appendix here.}

% You can have as much text here as you want. The main body must be at most $8$ pages long.
% For the final version, one more page can be added.
% If you want, you can use an appendix like this one, even using the one-column format.
    \section{Examples of frailty specifications}\label{sec: frailty_spec}
    We list several commonly used frailty models, and specify their corresponding characteristics via their frailty transform $G_\theta$:
    \begin{description}
        \item[Gamma frailty:] Arguably the gamma frailty is the most widely used frailty model \cite{murphy1994consistency, murphy1995asymptotic, parner1998asymptotic, wienke2010frailty, duchateau2007frailty}, with 
        \begin{align}
            G_\theta(x) = \frac{1}{\theta} \log (1 + \theta x), \theta \ge 0.
        \end{align}
        When $\theta = 0$, $G_0(x) = \lim_{\theta \rightarrow 0} G_\theta (x)$ is defined as the (pointwise) limit. A notable fact of the gamma frailty specification is that when the proportional frailty (PF) assumption \eqref{eqn: proportional_frailty} is met, if $\theta = 0$, the model degenerates to \ph. Otherwise if $\theta = 1$, the model corresponds to the proportional odds (PO) model \cite{bennett1983analysis}.
        \item[Box-Cox transformation frailty:] Under this specification, we have
        \begin{align}
            G_\theta(x) = \dfrac{(1+x)^\theta-1}{\theta}, \theta \ge 0.
        \end{align}
        The case of $\theta = 0$ is defined analogously to that of gamma frailty, which corresponds to the PO model under the PF assumption. When $\theta = 1$, the model reduces to \ph under the PF assumption. 
        \item[$\text{IGG}(\alpha)$ frailty:] This is an extension of gamma frailty \cite{kosorok2004robust} and includes other types of frailty specifications like the inverse gaussian frailty \cite{hougaard1984life}, with
        \begin{align}
            G_\theta(x) = \frac{1 - \alpha}{\alpha \theta} \left[ \left(1 + \frac{\theta x}{1 - \alpha}\right)^\alpha - 1\right], \theta \ge 0, \alpha \in [0, 1).
        \end{align}
        In the one-dimensional parameter paradigm, the parameter $\alpha$ is assumed known instead of being learnable. When $\alpha = 1/2$, we obtain the gamma frailty model. When $\alpha \rightarrow 0$, the limit corresponds to the inverse Gaussian frailty. 
    \end{description}
    \textbf{Satistiability of regularity condition \ref{cond: G}} In \cite[Proposition 1]{kosorok2004robust}, the authors verified the regularity condition of gamma and $\text{IGG}(\alpha)$ frailties. Using a similar argument, it is straightforward to verify the regularity of Box-Cox transformation frailty. 
    \section{Proofs of theorems}
    \input{appendix_final}
    \section{Experimental details}
    \subsection{Dataset summary}\label{sec: dataset_summary}
    We report summaries of descriptive statistics of the $6$ benchmark datasets used in section \ref{sec: benchmark_data} in table \ref{tab: datasets}.
    \begin{table}[]
        \centering
        \caption{Descriptive statistics of benchmark datasets}
        % \resizebox{\textwidth}{!}{%
        \begin{tabular}{l c c c c c c}
            \toprule
                              & METABRIC & RotGBSG    & FLCHAIN & SUPPORT & MIMIC-III & KKBOX     \\
            \midrule
            Size              & $1904$   & $2232$  & $6524$  & $8873$     & $35953$ & $2646746$ \\
            Censoring rate    & $0.423$  & $0.432$ & $0.699$ & $0.320$    & $0.901$ & $0.280$   \\  
            Features          & $9$      & $7$     & $8$     & $14$       & $26$    & $15$      \\
            \bottomrule
        \end{tabular}
        % }
        \label{tab: datasets}
    \end{table}
    \subsection{Details of synthetic experiments}\label{sec: synthetic_details}
    Since the true model is assumed to be of PF form, we generate event time according to the following transformed regression model \cite{dabrowska1988partial}:
    \begin{align}\label{eqn: transformation_mdoel}
        \log H(\tilde{T}) = -m(Z) + \epsilon,
    \end{align}
    where $H(t) = \int_0^t e^{h(s)} ds$ with $h$ defined in \eqref{eqn: proportional_frailty}. The error term $\epsilon$ is generated such that $e^{\epsilon}$ has cumulative hazard function $G_\theta$. The formulation \eqref{eqn: transformation_mdoel} is the equivalent to \eqref{eqn: proportional_frailty} \cite{dabrowska1988partial, cuzick1988rank, kosorok2004robust}. In our experiments, the covariates are of dimension $5$, sampled independently from the uniform distribution over $[0, 1]$. We set $h(t) = t$ and hence $H(t) = e^t$. The function form of $m(Z)$ is set to be $m(Z) = \sin(\langle Z, \beta \rangle) + \langle\sin(Z), \beta \rangle$, where $\beta = (0.1, 0.2, 0.3, 0.4, 0.5)$. Then censoring time $C$ is generated according to 
    \begin{align}
        \log H(C) = -m(Z) + \epsilon_C,
    \end{align}
    which reuses covariate $Z$, and draws independently a noise vector $\epsilon_C$ such that the censoring ratio is controlled at around $40\%$. We generate three datasets with $n \in \{1000, 5000, 10000\}$ respectively. \par
    \textbf{Hyperparameter configurations} We specify below the network architectures and optimization configurations used in all the tasks:
    \begin{description}
        \item[PF scheme: ] For both $\widehat{m}$ and $\widehat{h}$, we use $64$ hidden units for $n=1000$, $128$ hidden units for $n=5000$ and $256$ hidden units for $n=10000$. We train each model for $100$ epochs with batch size $128$, optimized using Adam with learning rate $0.0001$, and no weight decay.
        \item[FN scheme: ] For both $\widehat{\nu}$, we use $64$ hidden units for $n=1000$, $128$ hidden units for $n=5000$ and $256$ hidden units for $n=10000$. We train each model for $100$ epochs with batch size $128$, optimized using Adam with learning rate $0.0001$, and no weight decay.
    \end{description}
    \subsection{Details of public data experiments}\label{sec: public_data_details}
    \textbf{Dataset preprocessing} For METABRIC, RotGBSG, FLCHAIN, SUPPORT and KKBOX dataset, we take the version provided in the {\fontfamily{qcr}\selectfont pycox} package \cite{kvamme2019time}. We standardize continuous features into zero mean and unit variance and do one-hot encodings for all categorical features. For the MIMIC-III dataset, we follow the preprocessing routines in \cite{purushotham2018benchmarking} which extracts $26$ features. The event of interest is defined as the mortality after admission, and the censored time is defined as the last time of being discharged from the hospital. The definition is similar to that in \cite{tang2022soden}. But since the dataset is not open sourced, according to our implementation the resulting dataset exhibits a much higher censoring rate ($90.2\%$ as compared to $61.0\%$ as reported in the SODEN paper \cite{tang2022soden}). Since the major purpose of this paper is for the proposal of the NFM framework, We use our own version of the processed dataset to further verify the predictive performance of NFM.\par 
    \textbf{Hyperparameter configurations} We follow the general training template that uses MLP as all nonparametric function approximators (i.e., $\widehat{m}$ and $\widehat{h}$ in the PF scheme, and $\widehat{\nu}$ in the FN scheme), and train for $100$ epochs across all datasets using Adam as the optimizer. The tunable parameters and their respective tuning ranges are reported as follows:
    \begin{description}
        \item[Number of layers (network depth)] We tune the network depth $L \in \{2, 3, 4\}$. Typically, the performance of two-layer MLPs is sufficiently satisfactory.
        \item[Number of hidden units in each layer (network width)] We tune the network width $W \in \{2^k, 5 \le k \le 10 \}$.  
        \item[Optional dropout] We optionally apply dropout with probability $p \in \{0.1, 0.2, 0.3, 0.5, 0.7\}$. 
        \item[Batch size] We tune batch size within the range $\{128, 256, 512\}$, in the KKBOX dataset, we also tested with larger batch sizes $\{1024\}$.
        \item[Learning rate and weight decay] We tune both the learning rate and weight decay coefficient of Adam within range $\{0.01, 0.001, 0.0001\}$.
        \item[Frailty specification] We tested gamma frailty, Box-Cox transformation frailty, and $\text{IGG}(\alpha)$ frailty with $\alpha \in \{0, 0.25, 0.75\}$. Here note that $\text{IGG}(0.5)$ is equivalent to gamma frailty. We also empirically tried to set $\alpha$ to be a learnable parameter and found that this additional flexibility provides little performance improvement regarding the datasets used for evaluation.
    \end{description}
    
    \subsection{Implementations}
    We use \qcr{pytorch} to implement NFM. \textbf{The source code is provided in the supplementary material}. For the baseline models:
    \begin{itemize}[leftmargin=*]
        \item We use the implementations of \ph, GBM, and RSF from the \texttt{sksurv} package \cite{sksurv}, for the KKBOX dataset, we use the XGBoost library \cite{chen2016xgboost} to implement GBM and RSF, which might yield some performance degradation.
        \item We use the \qcr{pycox} package to implement DeepSurv, CoxTime, and DeepHit models.
        \item We use the official code provided in the SODEN paper \cite{tang2022soden} to implement SODEN.
        \item We obtain results of SuMo and DeepEH based on our re-implementations.
    \end{itemize}
     
    \section{Additional experiments}\label{sec: additional_experiments}
    \subsection{Recovery assessment of $m(Z)$ in PF scheme}\label{sec: m_z}
    We plot empirical recovery results targeting the $m$ function in \eqref{eqn: proportional_frailty} in figure \ref{fig: synthesis_pf_m}. The result demonstrates satisfactory recovery with a moderate amount of data, i.e., $n \ge 1000$.
    \begin{figure}
        % \centering
        \begin{subfigure}[b]{.33\linewidth}
         \input{figs/m_1000_pf}
        \end{subfigure}
        \begin{subfigure}[b]{.33\linewidth}
         \input{figs/m_5000_pf}
        \end{subfigure}
        \begin{subfigure}[b]{.33\linewidth}
         \input{figs/m_10000_pf}
        \end{subfigure}
        \caption{Visualizations of synthetic data results under the PF scheme of NFM framework, regarding empirical recovery of the $m$ function in \eqref{eqn: proportional_frailty}}
        \label{fig: synthesis_pf_m}
    \end{figure}
    

    \subsection{Recovery assessment of survival functions}\label{sec: surv}
    To assess the recovery performance of NFM with respect to survival functions, we consider the following setup: under the same data generation framework as in section \ref{sec: synthetic_details}, we compute the test feature $\bar{Z}$ as the sample mean of all the $100$ hold-out test points. And plot $\widehat{S}(t|\bar{Z})$ against the ground truth $S(t|\bar{Z})$ regarding both PF and FN schemes. The results are shown in figure \ref{fig: surv_recovery}. The results suggest that both scheme provides accurate estimation of survival functions when the sample size is sufficiently large. 
    \begin{figure}
        \centering
        \begin{subfigure}[b]{.3\linewidth}
         \input{figs/surv_1000_pf}
        \end{subfigure}
        \begin{subfigure}[b]{.3\linewidth}
         \input{figs/surv_5000_pf}
        \end{subfigure}
        \begin{subfigure}[b]{.3\linewidth}
         \input{figs/surv_10000_pf}
        \end{subfigure}
        \begin{subfigure}[b]{.3\linewidth}
         \input{figs/surv_1000_fn}
        \end{subfigure}
        \begin{subfigure}[b]{.3\linewidth}
         \input{figs/surv_5000_fn}
        \end{subfigure}
        \begin{subfigure}[b]{.3\linewidth}
         \input{figs/surv_10000_fn}
        \end{subfigure}
        \caption{Visualizations of synthetic data results under the NFM framework. The plots in the first row compare the empirical estimates of the survival function $S(t|\bar{Z})$ against its true value with $\bar{Z}$ being the average of the features of the $100$ hold-out points, under the PF scheme. The plots in the second row are obtained using the FN scheme, with analogous semantics to the first row.}
        \label{fig: surv_recovery}
    \end{figure}
    
    \subsection{Performance evaluations under the concordance index (C-index)}\label{sec: c_index}
    The concordance index (C-index) \cite{antolini2005time} is yet another evaluation metric that is commonly used in survival analysis. The C-index estimates the probability that, for a random pair of individuals, the predicted survival times of the two individuals have the same ordering as their true survival times. Formally, C-index is defined as
    \begin{align}\label{eqn: c_index}
        \mathcal{C} = \mathbb{P}\left[\widehat{S}(T_i \mid Z_i) < \widehat{S}(T_j \mid Z_j) \mid T_i < T_j, \delta_i = 1\right].
    \end{align}
    We report performance evaluations based on C-index over all the $6$ benchmark datasets in table \ref{tab: cindex}. 
    \begin{table}[]
        \centering
        \caption{Survival prediction results measured in C-index (\%) on all the $6$ benchmark datasets. In each column, the \textbf{boldfaced} score denotes the best result and the \underline{underlined} score represents the second-best result. The average rank of each model is reported in the rightmost column. We did not manage to obtain reasonable results for DeepEH and SODEN on two larger datasets MIMIC-III and KKBOX, and we set corresponding ranks to be the worst on those datasets.}
        % \resizebox{\textwidth}{!}{%
            \input{tables/cindex_results_rebuttal}
        % }
        \label{tab: cindex}
    \end{table}
    From table \ref{tab: cindex}, it appears that there's no clear winner regarding the C-index metric across the $6$ selected datasets. We conjecture this phenomenon to be closely related to the loose correlation between the C-index and the likelihood-based learning objective, as was observed in \cite{rindt2022a}. Therefore we compute the average rank of each model as an overall assessment of performance, as illustrated in the last column in table \ref{tab: cindex}. The results suggest that the two NFM models perform better on average.
    \subsection{Benefits of frailty}\label{sec: benefits_frailty}
    We compute the (relative) performance gain of NFM-PF and NFM-FN, against their non-frailty counterparts, namely DeepSurv \cite{katzman2018deepsurv} and SuMo-net \cite{rindt2022a} based on results in table \ref{tab: survival_results}, table \ref{tab: kkbox} and table \ref{tab: cindex}. The results are shown in table \ref{tab: frailty_benefits}
    \begin{table}[]
        \centering
        \caption{Relative improvement of NFM models in comparison to their non-frailty counterparts, measured in IBS, INBLL, and C-index.}
        \begin{tabular}{l c c c c c c}
            \toprule
            Dataset           & \multicolumn{3}{c}{NFM-PF vs DeepSurv} & \multicolumn{3}{c}{NFM-FN vs SuMo-net}\\
                            & IBS   & INBLL  & C-index  & IBS  & INBLL  & C-index \\
            \midrule
            METABRIC            & $+1.33\%$ & $+1.56\%$ & $+1.61\%$ & $+2.30\%$ & $+3.08\%$  & $+2.79\%$ \\
            RotGBSG             & $+1.11\%$ & $+0.95\%$ & $+0.84\%$ & $+0.62\%$ & $+0.40\%$ & $+0.79\%$ \\
            FLCHAIN             & $+1.29\%$ & $+1.32\%$ & $+0.52\%$ & $+0.20\%$ & $+0.27\%$ & $+0.01\%$ \\
            SUPPORT             & $+0.31\%$ & $+0.23\%$ & $+0.69\%$ & $+2.22\%$ & $+1.76\%$ & $+0.05\%$ \\
            MIMIC-III           & $+12.38\%$ & $+12.15\%$ & \cellcolor{gray!25}$-0.64\%$ & $+6.18\%$ & $+5.56\%$ & $+5.18\%$ \\
            KKBOX               & $+2.56\%$ & $+0.51\%$ & $+0.75\%$ & $+8.20\%$ & $+10.38\%$ & $+2.17\%$ \\
            % RotGBSG             & \result{17.70}{0.00} & \result{52.30}{0.00} & \result{11.81}{0.00}    & \result{38.15}{0.00} \\
            % FLCHAIN             & \result{17.79}{0.19} & \result{53.34}{0.41} & \result{14.46}{0.00} & \result{44.39}{0.00} \\
            % SUPPORT        & \result{18.58}{0.92} & \result{55.98}{2.43} & \result{11.31}{0.05} & \result{35.28}{0.15}\\
            % MIMIC-III         & \result{17.68}{1.36} & \result{52.08}{3.06} & \results{10.70}{0.06} & \results{33.10}{0.21}\\
            % KKBOX         & \result{19.80}{1.31} & \result{59.03}{4.20} & \result{16.00}{0.34} & \result{48.64}{1.04}\\
            \bottomrule
        \end{tabular}
        \label{tab: frailty_benefits}
    \end{table}
    The results suggest solid improvement in incorporating frailty, especially for IBS and INBLL metrics, as the relative increase in performance could be over $10\%$ for both NFM models. For the IBS and INBLL metrics, the performance improvement is consistent across all datasets. The only performance degradation appears on the MIMIC-III dataset evaluated under C-index. This phenomenon is also understandable: Since the DeepSurv model utilized a variant of partial likelihood (PL) for model training, as previous works \cite{NIPS2007_33e8075e} pointed out that PL type objective is closely related to the ranking problem. As C-index could be considered a certain type of ranking measure, it is possible that DeepSurv obtains better ranking performance than NFM-type models which are trained using scale-sensitive likelihood objective. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}