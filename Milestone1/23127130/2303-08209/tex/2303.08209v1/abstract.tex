The ability to learn new tasks and quickly adapt to different variations and dimensions is an important attribute in agile robotics. In previous work, we have explored Behavior Trees and Motion Generators BTMGs) as a robot arm policy representation to facilitate the learning and execution of assembly tasks. The current implementation of the BTMGs for a specific task may not be robust to the changes in the environment and  may not generalize well to different variations of tasks. To address this limitation, we propose to extend the BTMG policy representation by learning a modeling function that maps task variations to BTMG parameters. To achieve this, we first train a Gaussian process to predict performance measure or reward that takes BTMG parameters and task variations as input. We also train a classifier to check the feasibility of the predicted policy. Subsequently, we optimize the performance measure over BTMG parameters for a fixed task variation.
To demonstrate the effectiveness of our proposed approach, we conducted experimental evaluations on push and obstacle avoidance tasks in simulation and also performed physical experiments using a \textit{KUKA iiwa} robot. Furthermore, we compared the performance of our approach with four baseline methods.