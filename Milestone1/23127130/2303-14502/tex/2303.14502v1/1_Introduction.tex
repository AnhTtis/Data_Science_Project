\section{Introduction} \label{sec:Intro}
% [DONE] Make navigating through vegetation more general
% Why is navigating these environments hard? 
    % [DONE] How height and density of grass poses a challenge
    % Talk about robot dynamics
% [DONE] Define pliability formally
% Ref for lidar failing in tall grass
% [DONE] Remove getting stuck. Instead define freezing
% Explain negative experiences needed for some methods

% Add refs
In recent times, mobile robots have been used for many outdoor applications in agriculture \cite{harvesting-robots,milioto2018real,borges2022survey} (automatic seeding, harvesting, and measuring plant and soil health), gardening \cite{trimbot}, forest exploration, search and rescue \cite{borges2022survey}, etc. Operating in such environments entails navigating in the presence of vegetation with varying height, density, and rigidity. 

% Chellenges
In such dense and unstructured vegetation, the robot may not always find free space to circumvent the flora. This causes the robot to freeze \cite{frozone}; a phenomenon where its planner cannot compute any collision-free velocity to reach its goal. The robot either halts or starts oscillating indefinitely, leading to collisions and not progressing to its goal. Additionally, a small wheeled or legged robot could get physically entrapped in vegetation when its wheels or legs get intertwined in dried tall grass, bushes, etc. In such cases, the robot's dynamics determines whether it can autonomously recover itself \cite{vision-aided-quadruped}. 

To effectively navigate such environments, the robot must assess the traversability of the various flora around it. Firstly, it must differentiate flora based on their \textit{pliability} \cite{char-traversal-pliable-veg}. We define a plant's pliability as its degree of flexibility or ability to bend such that a robot can navigate through it. For instance, robots can traverse \textit{through} tall grass (high pliability) whereas trees are non-pliable and should be avoided. Secondly, the robot must detect the height and density of pliable vegetation since they affect the resistance offered to the robot's motion. 

% such as the unevenness of the terrain \cite{terp}, poor traction, the deformability of the surface \cite{terrapn}, and obstacles such as dense, unstructured vegetation in the environment, etc.  

A major challenge in differentiating pliable/traversable from non-pliable/untraversable flora around the robot stems from sensors (e.g., laser scans, point clouds, and ultrasound) detecting all plants as solid obstacles \cite{badgr}. Furthermore, vegetation such as tall grass scatters laser beams from lidars and leads to poor characterization of their shape and structure \cite{multiwavelength-lidar}. In RGB images, the shape and structure of various plants are accurately represented. However, there is a lack of research on differentiating flora based on their pliability from images. 

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth,height=5.5cm]{Images/cover.png}
    \caption{\small{Comparison of VERN with other methods navigating a Spot robot through a complex environment (scenario 3) with traversable (e.g. tall grass), and untraversable (e.g. tree, bush) vegetation. In this trial, we observe that only VERN successfully reaches its goal due to its vegetation classification, height estimation, and novel cost map clearing scheme. Other methods either collide (GrASPE \cite{graspe}, Spot's in-built autonomy), or freeze (DWA \cite{fox1997dwa}, GA-Nav \cite{ganav}) due to the density of vegetation.}}
    \label{fig:cover_image}
    \vspace{-15pt}
\end{figure}

%  Problem with existing works
% TODO: Add more refs
There are several works in computer vision to detect and segment simple vegetation such as trees, and short grass \cite{milioto2018real,ganav,semantic-mapping-auto-off-road-nav}. However, such works require extensive datasets with intricate annotations to train, requiring significant human effort. Additionally, segmenting traversable versus untraversable regions in dense vegetation is still an unsolved problem \cite{offroad-mobility}.

Navigation methods for outdoor domains have dealt with flora such as tall grass \cite{badgr}, trees, etc. in isolation. Such methods do not consider scenarios where plants of all pliability/traversability are in close proximity. Therefore, such methods cause the robot to collide or get entrapped, and do not have autonomous mechanisms to recover in such environments. Navigation methods based on end-to-end learning \cite{badgr,model-error-katyal} require real-world negative experiences such as collisions with non-pliable obstacles for training. This would be impractical for highly unstructured regions where rates of collision and entrapment are high. 

\textbf{Main Contributions:} To address these limitations and navigate in densely vegetated environments, we present VERN (\textbf{VE}getation-aware \textbf{R}obot \textbf{N}avigation) using multi-modal perception sensors. The novel components of our work include:

% First, to differentiate vegetation with various pliabilities, VERN uses a few-shot learning approach to train a vegetation classifier. It detects features such as texture, density of the vegetation, etc. to classify an image into four classes: sparse grass, dense grass, bushes, and trees. Using the predicted classes and combining them with multiple 2D lidar scans, VERN constructs a \textit{Vegetation-aware} Cost Map (VCM) that accounts for regions with pliable (and therefore traversable) vegetation. The VCM is made resilient to misclassifications from the vegetation classifier by fusing multiple cost maps corresponding to different heights of lidar scans and a novel cost map clearing algorithm. Finally, using VCM, VERN navigates a robot through highly unstructured vegetation and executes novel recovery behaviors when the robot freezes or is entrapped. The novel components of our work include:

% Main Contributions
%  1. Vegetation classifier -> Siamese network, very few images needed 
%  2. Error-resistant cost map -> Multi-view costmaps, Using confusion matrix of classifer to account for misclassifications. 
%  3. Navigation and recovery behaviors, Stuck-locations memory 

\begin{itemize}
    \item A novel classifier to differentiate vegetation of various pliability/traversability from RGB images. We propose a novel few-shot learning approach and a siamese network framework to train our classifier with only a few hundred images of different kinds of vegetation (tall grass, bushes/shrubs, and trees) with minimal human labeling. This is a significant decrease in the required dataset size and human effort compared to existing methods for outdoor terrain perception. 
    
    % This is a drastically smaller the dataset and less human effort than required for training existing methods for outdoor terrain perception. 

    \item A novel method to compute a \textit{vegetation-aware} traversability cost map by accounting for estimated vegetation height, pliability classification, and the classification confidence. Our method accounts for misclassifications in the vegetation classifier and leads to a more accurate representation of the traversable vegetation in the robot's surroundings in the cost map. This leads to an improvement of 25-90\% in terms of success rate and a decrease of up to 65\% false positive rate.

    % \item A novel method to compute a \textit{vegetation-aware} cost map using multiple cost maps corresponding to different angles of laser scan from a 3D lidar (henceforth referred to as multi-view cost maps). Our method accounts for the  classification errors in the vegetation classifier and leads to a more accurate representation of pliable/traversable vegetation in the robot's surroundings. Using multi-view cost maps leads to an improvement of 35\% in terms of success rate and a low false positive rate. 

    % \item A local planner to navigate a robot in environments with unstructured vegetation in a dynamically feasible, collision-free manner.  Additionally, the planner initiates novel behaviors to recover the robot if it is entrapped in extremely dense vegetation. This improves the success rate by 35\%, freezing rate by 42\%.
    \item A local planner that produces cautious navigation behaviors when in highly unstructured vegetation or regions with low confidence pliability classification. Additionally, the planner initiates novel holonomic behaviors to recover the robot if it freezes or gets physically entrapped in dense vegetation. This improves the success rate by up to 50\%, and the freezing rate by 75\%.
\end{itemize}

