@article{McGeer01041990,
  author = {McGeer, Tad}, 
  title = {\href{http://ijr.sagepub.com/content/9/2/62.abstract}{Passive Dynamic Walking}}, 
  volume = {9}, 
  number = {2}, 
  pages = {62-82}, 
  year = {1990}, 
  doi = {10.1177/027836499000900206}, 
  URL = {http://ijr.sagepub.com/content/9/2/62.abstract}, 
  eprint = {http://ijr.sagepub.com/content/9/2/62.full.pdf+html}, 
  journal = {The International Journal of Robotics Research}
}

@inproceedings{RUGD2019IROS,
  author = {Wigness, Maggie and Eum, Sungmin and Rogers, John G and Han, David and Kwon, Heesung},
  title = {A RUGD Dataset for Autonomous Navigation and Visual Perception in Unstructured Outdoor Environments},
  booktitle = {International Conference on Intelligent Robots and Systems (IROS)},
  year = {2019}
} 

@misc{jiang2020rellis3d,
      title={RELLIS-3D Dataset: Data, Benchmarks and Analysis}, 
      author={Peng Jiang and Philip Osteen and Maggie Wigness and Srikanth Saripalli},
      year={2020},
      eprint={2011.12954},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{kalman1960new,
  title={A new approach to linear filtering and prediction problems},
  author={Kalman, R.E.},
  journal={Journal of Basic Engineering},
  volume={82},
  number={1},
  pages={35--45},
  year={1960},
  publisher={Citeseer}
}

@INPROCEEDINGS{terrapn,
  author={Sathyamoorthy, Adarsh Jagan and Weerakoon, Kasun and Guan, Tianrui and Liang, Jing and Manocha, Dinesh},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={TerraPN: Unstructured Terrain Navigation using Online Self-Supervised Learning}, 
  year={2022},
  volume={},
  number={},
  pages={7197-7204},
  doi={10.1109/IROS47612.2022.9981942}}

@INPROCEEDINGS{model-error-katyal,
  author={Polevoy, Adam and Knuth, Craig and Popek, Katie M. and Katyal, Kapil D.},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)}, 
  title={Complex Terrain Navigation via Model Error Prediction}, 
  year={2022},
  volume={},
  number={},
  pages={9411-9417},
  doi={10.1109/ICRA46639.2022.9811644}}

@ARTICLE{badgr,
  author={Kahn, Gregory and Abbeel, Pieter and Levine, Sergey},
  journal={IEEE Robotics and Automation Letters}, 
  title={BADGR: An Autonomous Self-Supervised Learning-Based Navigation System}, 
  year={2021},
  volume={6},
  number={2},
  pages={1312-1319},
  doi={10.1109/LRA.2021.3057023}}

@article{vineyard,
author = {Astolfi, Pietro and Gabrielli, Alessandro and Bascetta, Luca and Matteucci, Matteo},
year = {2018},
month = {01},
pages = {704-709},
title = {Vineyard Autonomous Navigation in the Echord++ GRAPE Experiment},
volume = {51},
doi = {10.1016/j.ifacol.2018.08.401}
}

@INPROCEEDINGS{Overbye-1,
  author={Overbye, Timothy and Saripalli, Srikanth},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Fast Local Planning and Mapping in Unknown Off-Road Terrain}, 
  year={2020},
  volume={},
  number={},
  pages={5912-5918},
  doi={10.1109/ICRA40945.2020.9196848}}

@INPROCEEDINGS{Overbye-2,
  author={Overbye, Timothy and Saripalli, Srikanth},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Path Optimization for Ground Vehicles in Off-Road Terrain}, 
  year={2021},
  volume={},
  number={},
  pages={7708-7714},
  doi={10.1109/ICRA48506.2021.9561291}}


@article{thesis,
author={Alicea, Ryan Luis},
title={Efficient Control and Locomotion Strategies in Unstructured, Natural Environments: A Study of Vegetation-Rich and Fluid-Covered Terrain},
year={2019}
}

@article{terrain-semantics-multi-legged,
author = {Belter, Dominik and Wietrzykowski, Jan and Skrzypczyński, Piotr},
year = {2019},
month = {03},
pages = {},
title = {Employing Natural Terrain Semantics in Motion Planning for a Multi-Legged Robot},
volume = {93},
journal = {Journal of Intelligent and Robotic Systems},
doi = {10.1007/s10846-018-0865-x}
}

@article{veg-laser-data-structured-outdoor,
author = {Wurm, Kai and Kretzschmar, Henrik and Kümmerle, Rainer and Stachniss, Cyrill and Burgard, Wolfram},
year = {2014},
month = {05},
pages = {675–684},
title = {Identifying vegetation from laser data in structured outdoor environments},
volume = {62},
journal = {Robotics and Autonomous Systems},
doi = {10.1016/j.robot.2012.10.003}
}

@INPROCEEDINGS{double-check-passable,
  author={Nguyen, D.-V. and Kuhnert, L. and Thamke, S. and Schlemper, J. and Kuhnert, K.-D.},
  booktitle={2012 15th International IEEE Conference on Intelligent Transportation Systems}, 
  title={A novel approach for a double-check of passable vegetation detection in autonomous ground vehicles}, 
  year={2012},
  volume={},
  number={},
  pages={230-236},
  doi={10.1109/ITSC.2012.6338752}}

@article{quadruped-locomotion-challenging-terrain,
author = {Joonho Lee  and Jemin Hwangbo  and Lorenz Wellhausen  and Vladlen Koltun  and Marco Hutter },
title = {Learning quadrupedal locomotion over challenging terrain},
journal = {Science Robotics},
volume = {5},
number = {47},
pages = {eabc5986},
year = {2020},
doi = {10.1126/scirobotics.abc5986},
URL = {https://www.science.org/doi/abs/10.1126/scirobotics.abc5986},
eprint = {https://www.science.org/doi/pdf/10.1126/scirobotics.abc5986},
abstract = {A learning-based locomotion controller enables a quadrupedal ANYmal robot to traverse challenging natural environments. Legged locomotion can extend the operational domain of robots to some of the most challenging environments on Earth. However, conventional controllers for legged locomotion are based on elaborate state machines that explicitly trigger the execution of motion primitives and reflexes. These designs have increased in complexity but fallen short of the generality and robustness of animal locomotion. Here, we present a robust controller for blind quadrupedal locomotion in challenging natural environments. Our approach incorporates proprioceptive feedback in locomotion control and demonstrates zero-shot generalization from simulation to natural environments. The controller is trained by reinforcement learning in simulation. The controller is driven by a neural network policy that acts on a stream of proprioceptive signals. The controller retains its robustness under conditions that were never encountered during training: deformable terrains such as mud and snow, dynamic footholds such as rubble, and overground impediments such as thick vegetation and gushing water. The presented work indicates that robust locomotion in natural environments can be achieved by training in simple domains.}}


@article{multiwavelength-lidar,
title = {A Multi-Wavelength Canopy LiDAR for Vegetation Monitoring: System Implementation and Laboratory-Based Tests},
journal = {Procedia Environmental Sciences},
volume = {10},
pages = {2775-2782},
year = {2011},
note = {2011 3rd International Conference on Environmental Science and Information Application Technology ESIAT 2011},
issn = {1878-0296},
doi = {https://doi.org/10.1016/j.proenv.2011.09.430},
url = {https://www.sciencedirect.com/science/article/pii/S1878029611006256},
author = {Zhu Bo and Gong Wei and Shi Shuo and Song Shalei},
keywords = {Multi-wavelength, LiDAR intensity, vegetation monitoring},
abstract = {The instrumentation of a Multi-Wavelength Canopy LiDAR system (MWCL) for vegetation monitoring was tested by using low power, solid and semiconductor lasers. The proposed instrument takes measurements at four wavelengths which are highly interrelated to the chlorophyll concentration, Nitrogen content and other biochemical properties. The receiver consists of four channels, which would capture the LiDAR back-scatter signals of the four wavelengths separately at 556nm, 670nm, 700nm and 780nm. It is shown that the MWCL could not only provide structure information on vegetation canopy, but could also pick up the LiDAR intensity information. A 3-D reconstruction procedure based on the LiDAR back-scatter waveform has been done, and a supervised classification based on the intensity data is also accomplished. The results showed that the MWCL was able to significantly improve the retrieval accuracy of photosynthetically active biomass opposed to using a single-wavelength LiDAR alone.}
}

@inproceedings{offroad-mobility,
title={Off-Road Autonomous Mobility},
author={Lacaze, Alberto and Mottern, Edward and Brilhart, Bryan},
booktitle={2019 NDIA Ground Vehicle Systems Engineering and Technology Symposium},
year={2019}
}

@ARTICLE{frozone,
  author={Sathyamoorthy, Adarsh Jagan and Patel, Utsav and Guan, Tianrui and Manocha, Dinesh},
  journal={IEEE Robotics and Automation Letters}, 
  title={Frozone: Freezing-Free, Pedestrian-Friendly Navigation in Human Crowds}, 
  year={2020},
  volume={5},
  number={3},
  pages={4352-4359},
  doi={10.1109/LRA.2020.2996593}}


@article{fox1997dwa,
  title={The dynamic window approach to collision avoidance},
  author={Fox, Dieter and Burgard, Wolfram and Thrun, Sebastian},
  journal={IEEE Robotics \& Automation Magazine},
  volume={4},
  number={1},
  pages={23--33},
  year={1997},
  publisher={IEEE}
}

@inproceedings{SiameseNN,
  title={Siamese Neural Networks for One-Shot Image Recognition},
  author={Gregory R. Koch},
  year={2015}
}

@inproceedings{terp,
  title={Terp: Reliable planning in uneven outdoor environments using deep reinforcement learning},
  author={Weerakoon, Kasun and Sathyamoorthy, Adarsh Jagan and Patel, Utsav and Manocha, Dinesh},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)},
  pages={9447--9453},
  year={2022},
  organization={IEEE}
}

@article{robust-perceptive-locomotion-quad,
author = {Takahiro Miki  and Joonho Lee  and Jemin Hwangbo  and Lorenz Wellhausen  and Vladlen Koltun  and Marco Hutter },
title = {Learning robust perceptive locomotion for quadrupedal robots in the wild},
journal = {Science Robotics},
volume = {7},
number = {62},
pages = {eabk2822},
year = {2022},
doi = {10.1126/scirobotics.abk2822},
URL = {https://www.science.org/doi/abs/10.1126/scirobotics.abk2822},
eprint = {https://www.science.org/doi/pdf/10.1126/scirobotics.abk2822},
abstract = {Legged robots that can operate autonomously in remote and hazardous environments will greatly increase opportunities for exploration into underexplored areas. Exteroceptive perception is crucial for fast and energy-efficient locomotion: Perceiving the terrain before making contact with it enables planning and adaptation of the gait ahead of time to maintain speed and stability. However, using exteroceptive perception robustly for locomotion has remained a grand challenge in robotics. Snow, vegetation, and water visually appear as obstacles on which the robot cannot step or are missing altogether due to high reflectance. In addition, depth perception can degrade due to difficult lighting, dust, fog, reflective or transparent surfaces, sensor occlusion, and more. For this reason, the most robust and general solutions to legged locomotion to date rely solely on proprioception. This severely limits locomotion speed because the robot has to physically feel out the terrain before adapting its gait accordingly. Here, we present a robust and general solution to integrating exteroceptive and proprioceptive perception for legged locomotion. We leverage an attention-based recurrent encoder that integrates proprioceptive and exteroceptive input. The encoder is trained end to end and learns to seamlessly combine the different perception modalities without resorting to heuristics. The result is a legged locomotion controller with high robustness and speed. The controller was tested in a variety of challenging natural and urban environments over multiple seasons and completed an hour-long hike in the Alps in the time recommended for human hikers. A legged locomotion controller achieves high robustness and speed in the wild by combining multimodal information.}}

@INPROCEEDINGS{support-surface-legged-robot,
  author={Homberger, Timon and Wellhausen, Lorenz and Fankhauser, Péter and Hutter, Marco},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)}, 
  title={Support Surface Estimation for Legged Robots}, 
  year={2019},
  volume={},
  number={},
  pages={8470-8476},
  doi={10.1109/ICRA.2019.8793646}}


@conference{semantic-mapping-auto-off-road-nav,
author = {Daniel Maturana and Po-Wei Chou and Masashi Uenoyama and Sebastian Scherer},
title = {Real-time Semantic Mapping for Autonomous Off-Road Navigation},
booktitle = {Proceedings of 11th International Conference on Field and Service Robotics (FSR '17)},
year = {2017},
month = {September},
pages = {335 - 350},
keywords = {semantic mapping, semantic segmentation, autonmous vehicles, off-road, all-terrain vehicles},
}

@techreport{Bradley-2004-8857,
author = {David Bradley and Scott Thayer and Anthony (Tony) Stentz and Peter Rander},
title = {Vegetation Detection for Mobile Robot Navigation},
year = {2004},
month = {February},
institution = {Carnegie Mellon University},
address = {Pittsburgh, PA},
number = {CMU-RI-TR-04-12},
keywords = {Mobile Robot Perception, Outdoor Mobile Robotics, Vegetation Detection},
}

@INPROCEEDINGS{auto-terrain-characterization-modeling,
  author={Talukder, A. and Manduchi, R. and Castano, R. and Owens, K. and Matthies, L. and Castano, A. and Hogg, R.},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Autonomous terrain characterisation and modelling for dynamic control of unmanned vehicles}, 
  year={2002},
  volume={1},
  number={},
  pages={708-713 vol.1},
  doi={10.1109/IRDS.2002.1041474}}

@article{nguyen-1,
author = {Nguyen, Duong-Van and Kuhnert, Lars and Kuhnert, Klaus},
year = {2012},
month = {04},
pages = {498–508},
title = {Structure overview of vegetation detection. A novel approach for efficient vegetation detection using an active lighting system},
volume = {60},
journal = {Robotics and Autonomous Systems},
doi = {10.1016/j.robot.2011.11.012}
}

@Article{sensing-tech-obstacle-detect,
AUTHOR = {Lohar, Shreya and Zhu, Lei and Young, Stanley and Graf, Peter and Blanton, Michael},
TITLE = {Sensing Technology Survey for Obstacle Detection in Vegetation},
JOURNAL = {Future Transportation},
VOLUME = {1},
YEAR = {2021},
NUMBER = {3},
PAGES = {672--685},
URL = {https://www.mdpi.com/2673-7590/1/3/36},
ISSN = {2673-7590},
ABSTRACT = {This study reviews obstacle detection technologies in vegetation for autonomous vehicles or robots. Autonomous vehicles used in agriculture and as lawn mowers face many environmental obstacles that are difficult to recognize for the vehicle sensor. This review provides information on choosing appropriate sensors to detect obstacles through vegetation, based on experiments carried out in different agricultural fields. The experimental setup from the literature consists of sensors placed in front of obstacles, including a thermal camera; red, green, blue (RGB) camera; 360° camera; light detection and ranging (LiDAR); and radar. These sensors were used either in combination or single-handedly on agricultural vehicles to detect objects hidden inside the agricultural field. The thermal camera successfully detected hidden objects, such as barrels, human mannequins, and humans, as did LiDAR in one experiment. The RGB camera and stereo camera were less efficient at detecting hidden objects compared with protruding objects. Radar detects hidden objects easily but lacks resolution. Hyperspectral sensing systems can identify and classify objects, but they consume a lot of storage. To obtain clearer and more robust data of hidden objects in vegetation and extreme weather conditions, further experiments should be performed for various climatic conditions combining active and passive sensors.},
DOI = {10.3390/futuretransp1030036}
}

@inproceedings{char-traversal-pliable-veg,
author = {Ordonez, Camilo and Alicea, Ryan and Rothrock, Brandon and Ladyko, Kyle and Nash, Jeremy and Thakker, Rohan and Daftry, Shreyansh and Harper, Mario and Collins, Emmanuel and Matthies, Larry},
year = {2018},
month = {11},
pages = {},
title = {Characterization and Traversal of Pliable Vegetation for Robot Navigation}
}

@INPROCEEDINGS{momentum-traversal-mobility-challenges,
  author={Ordonez, Camilo and Gupta, Nikhil and Chuy, Oscar and Collins, Emmanuel G.},
  booktitle={2013 IEEE International Conference on Robotics and Automation}, 
  title={Momentum based traversal of mobility challenges for autonomous ground vehicles}, 
  year={2013},
  volume={},
  number={},
  pages={752-759},
  doi={10.1109/ICRA.2013.6630657}}


@inproceedings{modeling-traversal-pliable-materials,
author = {Camilo Ordonez and Ryan Alicea and Brandon Rothrock and Kyle Ladyko and Mario Harper and Sisir  Karumanchi and Larry Matthies and Emmanuel Collins},
title = {{Modeling and traversal of pliable materials for tracked robot navigation}},
volume = {10640},
booktitle = {Unmanned Systems Technology XX},
editor = {Robert E. Karlsen and Douglas W. Gage and Charles M. Shoemaker and Hoa G. Nguyen},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {106400F},
keywords = {Vegetation Modeling, Obstacle Traversal, Vegetation Traversal, Tracked based platform, Offroad navigation},
year = {2018},
doi = {10.1117/12.2304431},
URL = {https://doi.org/10.1117/12.2304431}
}

@ARTICLE{ganav,
  author={Guan, Tianrui and Kothandaraman, Divya and Chandra, Rohan and Sathyamoorthy, Adarsh Jagan and Weerakoon, Kasun and Manocha, Dinesh},
  journal={IEEE Robotics and Automation Letters}, 
  title={GA-Nav: Efficient Terrain Segmentation for Robot Navigation in Unstructured Outdoor Environments}, 
  year={2022},
  volume={7},
  number={3},
  pages={8138-8145},
  doi={10.1109/LRA.2022.3187278}}


@inproceedings{mobilenetv3,
  title={Searching for mobilenetv3},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1314--1324},
  year={2019}
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@ARTICLE{graspe,
       author = {{Weerakoon}, Kasun and {Jagan Sathyamoorthy}, Adarsh and {Liang}, Jing and {Guan}, Tianrui and {Patel}, Utsav and {Manocha}, Dinesh},
        title = "{GrASPE: Graph based Multimodal Fusion for Robot Navigation in Unstructured Outdoor Environments}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Robotics},
         year = 2022,
        month = sep,
          eid = {arXiv:2209.05722},
        pages = {arXiv:2209.05722},
          doi = {10.48550/arXiv.2209.05722},
archivePrefix = {arXiv},
       eprint = {2209.05722},
 primaryClass = {cs.RO},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220905722W},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


%%%%%% New References 

@INPROCEEDINGS{Bradley2007vegetation_detection,
  author={Bradley, David M. and Unnikrishnan, Ranjith and Bagnell, James},
  booktitle={Proceedings 2007 IEEE International Conference on Robotics and Automation}, 
  title={Vegetation Detection for Driving in Complex Environments}, 
  year={2007},
  volume={},
  number={},
  pages={503-508},
  doi={10.1109/ROBOT.2007.363836}}

@article{trimbot,
author = {Strisciuglio, Nicola and Tylecek, Radim and Petkov, Nicolai and Bieber, Peter and Hemming, Jochen and Van Henten, E.J. and Sattler, Torsten and Pollefeys, Marc and Gevers, Theo and Brox, Thomas and Fisher, Robert},
year = {2018},
month = {04},
pages = {},
title = {TrimBot2020: an outdoor robot for automatic gardening}
}

@article{harvesting-robots,
  title={Selective harvesting robotics: current research, trends, and future directions},
  author={Kootstra, Gert and Wang, Xin and Blok, Pieter M and Hemming, Jochen and Van Henten, Eldert},
  journal={Current Robotics Reports},
  volume={2},
  pages={95--104},
  year={2021},
  publisher={Springer}
}

@inproceedings{wurm2009improving,
  title={Improving robot navigation in structured outdoor environments by identifying vegetation from laser data},
  author={Wurm, Kai M and K{\"u}mmerle, Rainer and Stachniss, Cyrill and Burgard, Wolfram},
  booktitle={2009 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={1217--1222},
  year={2009},
  organization={IEEE}
}

@article{borges2022survey,
  title={A Survey on Terrain Traversability Analysis for Autonomous Ground Vehicles: Methods, Sensors, and Challenges},
  author={Borges, Paulo and Peynot, Thierry and Liang, Sisi and Arain, Bilal and Wildie, Matthew and Minareci, Melih and Lichman, Serge and Samvedi, Garima and Sa, Inkyu and Hudson, Nicolas and others},
  journal={Field Robotics},
  volume={2},
  number={1},
  pages={1567--1627},
  year={2022},
  publisher={Field Robotics Publication Society}
}

@INPROCEEDINGS{vision-aided-quadruped,
  author={Kim, D. and Carballo, D. and Di Carlo, J. and Katz, B. and Bledt, G. and Lim, B. and Kim, S.},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Vision Aided Dynamic Exploration of Unstructured Terrain with a Small-Scale Quadruped Robot}, 
  year={2020},
  volume={},
  number={},
  pages={2464-2470},
  doi={10.1109/ICRA40945.2020.9196777}}


@inproceedings{milioto2018real,
  title={Real-time semantic segmentation of crop and weed for precision agriculture robots leveraging background knowledge in CNNs},
  author={Milioto, Andres and Lottes, Philipp and Stachniss, Cyrill},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={2229--2235},
  year={2018},
  organization={IEEE}
}

@inproceedings{offline-rl,
  title={Offline Reinforcement Learning for Visual Navigation},
  author={Shah, Dhruv and Bhorkar, Arjun and Leen, Hrishit and Kostrikov, Ilya and Rhinehart, Nicholas and Levine, Sergey},
  booktitle={6th Annual Conference on Robot Learning}
}

@article{vision_transformer,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}