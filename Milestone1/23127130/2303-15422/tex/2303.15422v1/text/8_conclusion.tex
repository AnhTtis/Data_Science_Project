\section{Conclusion}
In this paper, we propose a fine-grained semantic-based 
evaluation framework for keyphrase extraction and generation systems. The framework addresses the limitations of existing methods and focuses on six critical dimensions: naturalness, faithfulness, saliency, coverage, diversity, and utility. For each dimension, we design advanced semantic-based metrics that align with the evaluation objectives. Our rigorous empirical studies demonstrate that our evaluation strategy correlates better with human preferences compared to a range of previously used metrics. We benchmark 18 keyphrase systems using our framework and find that there is no single model performing the best for all dimensions. We also find that the utility in downstream applications does not always agree with reference-based metrics, and that GPT-3.5 exhibits near state-of-the-art performance in reference-free evaluation. We hope that our work provides a novel perspective for developing methods and metrics for keyphrase extraction and keyphrase generation.

% \section*{Limitations}
% \diwu{Retrieal may need long time to run}

% \section*{Ethics Statement}

\section*{Acknowledgments}
The research is partly supported by Taboola and an Amazon AWS credit award. We thank the Taboola team for helpful discussions on the challenges of keyphrase evaluation in real applications. We thank Wasi Ahmad, Yizuo Chen, as well as the members of the UCLA-NLP group for providing their valuable feedback. We also thank Jingnong Qu, Xiaoxian Shen and Xueer Li for their help on expert annotations for a meta-evaluation pilot study. 