\setlength{\tabcolsep}{3.5pt}
\begin{table*}[]
 \centering
 % \resizebox{\columnwidth}{!}{%
 \resizebox{\linewidth}{!}{
 \begin{tabular}{l | c | c | c c c c c c}
 \hline
 \multirow{2}{*}{\textbf{ID}} & \multirow{2}{*}{\textbf{Model}} & \multirow{2}{*}{\textbf{\#KP}} & \multirow{2}{*}{\textbf{Naturalness $\uparrow$}} & \multirow{2}{*}{\textbf{Faithfulness $\uparrow$}} & \multicolumn{2}{c}{\textbf{Diversity}} & \multicolumn{2}{c}{\textbf{Utility}} \\
& & & & & $dup\_token\_ratio\downarrow$ &$emb\_sim\downarrow$ & $RR@5\uparrow$ & $Spare_5@5\uparrow$ \\
 \hline
 \textbf{M0} & Human References & 5.3 & 0.884 & 0.788 & \underline{\textbf{0.073}} & 0.133 & 0.698 & 0.500 \\
\textbf{M1} & TF-IDF & 10.0 & 0.717 & 0.811 & 0.396 & 0.161 & 0.848 & 0.393 \\
\textbf{M2} & TextRank & 10.0 & 0.843 & 0.809 & 0.391 & 0.180 & 0.877 & 0.416 \\
\textbf{M3} & MultipartiteRank & 10.0 & 0.843 & 0.796 & 0.148 & \textbf{0.092} & 0.922 & 0.472 \\
\textbf{M4} & Kea & 10.0 & 0.717 & 0.823 & 0.445 & 0.175 & 0.861 & 0.388 \\
\textbf{M5} & BERT+CRF & 3.6 & 0.832 & \underline{\textbf{0.868}} & 0.137 & 0.399 & 0.633 & 0.487 \\
\textbf{M6} & CatSeq & 7.2 & 0.884 & 0.849 & 0.370 & 0.310 & 0.809 & 0.571 \\
\textbf{M7} & CatSeqTF+2RF1 & 7.9 & \underline{\textbf{0.910}} & 0.809 & 0.355 & 0.251 & 0.795 & \textbf{0.613} \\
\textbf{M8} & ExHiRD-h & 5.5 & \textbf{0.895} & 0.834 & 0.214 & 0.195 & 0.880 & 0.576 \\
\textbf{M9} & Transformer & 8.2 & 0.882 & 0.831 & 0.289 & 0.239 & 0.863 & 0.587 \\
\textbf{M10} & SetTrans & 7.7 & \textbf{0.897} & 0.839 & 0.308 & 0.203 & 0.909 & 0.541 \\
\textbf{M11} & SciBERT-G & 6.1 & 0.888 & 0.838 & 0.152 & 0.177 & 0.848 & 0.579 \\
\textbf{M12} & BART-large & 6.6 & 0.891 & 0.834 & 0.144 & 0.168 & 0.872 & 0.568 \\
\textbf{M13} & KeyBART & 6.0 & 0.892 & 0.835 & 0.130 & 0.163 & 0.864 & 0.568 \\
\textbf{M14} & SciBART-large+OAGKX & 6.1 & 0.892 & 0.840 & \textbf{0.129} & 0.158 & 0.871 & 0.571 \\
\textbf{M15} & text-davinci-003 (0-shot) & 9.5 & 0.877 & \textbf{0.853} & 0.143 & 0.110 & \textbf{0.979} & \textbf{0.599} \\
\textbf{M16} & text-davinci-003 (5-shot) & 6.5 & 0.874 & \textbf{0.866} & \textbf{0.087} & 0.114 & \underline{\textbf{0.985}} & \underline{\textbf{0.620}} \\
\textbf{M17} & Amazon Comprehend & 10.0 & 0.880 & 0.697 & 0.436 & \textbf{0.103} & 0.565 & 0.254 \\
\textbf{M18} & Azure Cognitive Services & 10.0 & 0.855 & 0.841 & 0.198 & \underline{\textbf{0.068}} & \textbf{0.955} & 0.552 \\
 \hline
 \end{tabular}
 }
 % \vspace{-2mm}
 \caption{Reference-free evaluation results on KPTimes for all the benchmarked models. The best result is underlined and the top three results are boldfaced.} 
 \label{tab:all-results-ref-free-kp20k}
 % \vspace{-3mm}
 
\end{table*}


\setlength{\tabcolsep}{3.5pt}
\begin{table*}[]
 \centering
 % \resizebox{\columnwidth}{!}{%
 \resizebox{\linewidth}{!}{
 \begin{tabular}{l | c | c | c c c c c c}
 \hline
 \multirow{2}{*}{\textbf{ID}} & \multirow{2}{*}{\textbf{Model}} & \multirow{2}{*}{\textbf{\#KP}} & \multirow{2}{*}{\textbf{Naturalness $\uparrow$}} & \multirow{2}{*}{\textbf{Faithfulness $\uparrow$}} & \multicolumn{2}{c}{\textbf{Diversity}} & \multicolumn{2}{c}{\textbf{Utility}} \\
& & & & & $dup\_token\_ratio\downarrow$ &$emb\_sim\downarrow$ & $RR@5\uparrow$ & $Spare_5@5\uparrow$ \\
 \hline
 \textbf{M0} & Human References & 5.0 & 0.882 & 0.757 & \textbf{0.069} & 0.203 & 0.515 & 0.420 \\
\textbf{M1} & TF-IDF & 10.0 & 0.756 & 0.743 & 0.175 & 0.163 & 0.798 & 0.406 \\
\textbf{M2} & TextRank & 10.0 & 0.803 & 0.739 & 0.371 & 0.246 & 0.745 & 0.347 \\
\textbf{M3} & MultipartiteRank & 10.0 & 0.827 & 0.749 & 0.123 & \textbf{0.150} & \textbf{0.837} & 0.437 \\
\textbf{M4} & Kea & 10.0 & 0.756 & 0.769 & 0.219 & 0.175 & \textbf{0.843} & 0.420 \\
\textbf{M5} & BERT+CRF & 2.3 & 0.838 & \underline{\textbf{0.816}} & 0.072 & 0.556 & 0.402 & 0.372 \\
\textbf{M6} & CatSeq & 5.9 & 0.877 & 0.734 & 0.191 & 0.257 & 0.524 & 0.469 \\
\textbf{M7} & CatSeqTG+2RF1 & n/a & n/a & n/a & n/a & n/a & n/a & n/a \\
\textbf{M8} & ExHiRD-h & 5.8 & 0.868 & 0.733 & 0.149 & 0.238 & 0.535 & 0.474 \\
\textbf{M9} & Transformer & 5.7 & 0.865 & 0.716 & 0.133 & 0.231 & 0.522 & 0.474 \\
\textbf{M10} & SetTrans & 8.4 & 0.873 & 0.710 & 0.210 & 0.232 & 0.584 & 0.410 \\
\textbf{M11} & SciBERT-G & 4.5 & 0.879 & 0.761 & 0.064 & 0.208 & 0.594 & 0.473 \\
\textbf{M12} & BART-large & 5.4 & 0.873 & 0.755 & 0.074 & 0.203 & 0.641 & \textbf{0.482} \\
\textbf{M13} & KeyBART & 5.9 & 0.872 & 0.749 & 0.086 & 0.206 & 0.639 & 0.480 \\
\textbf{M14} & SciBART-large+OAGKX & 4.8 & 0.876 & 0.763 & \textbf{0.069} & 0.203 & 0.628 & \textbf{0.482} \\
\textbf{M15} & text-davinci-003 (0-shot) & 14.1 & \textbf{0.896} & 0.785 & 0.082 & \textbf{0.137} & \underline{\textbf{0.871}} & \underline{\textbf{0.597}} \\
\textbf{M16} & text-davinci-003 (5-shot) & 6.7 & \underline{\textbf{0.907}} & \textbf{0.799} &  \underline{\textbf{0.044}} & 0.188 & 0.829 & \textbf{0.582} \\
\textbf{M17} & Amazon Comprehend & 10.0 & \textbf{0.902} & 0.668 & 0.291 & 0.203 & 0.492 & 0.123 \\
\textbf{M18} & Azure Cognitive Services & 10.0 & 0.814 & \textbf{0.803} & 0.140 & \underline{\textbf{0.133}} & 0.564 & 0.338 \\
 \hline
 \end{tabular}
 }
 % \vspace{-2mm}
 \caption{Reference-free evaluation results on KPTimes for all the benchmarked models. The best result is underlined and the top three results are boldfaced.} 
 \label{tab:all-results-ref-free-kptimes}
 % \vspace{-3mm}
 
\end{table*}
