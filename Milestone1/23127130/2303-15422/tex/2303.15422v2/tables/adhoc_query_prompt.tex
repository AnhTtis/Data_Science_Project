\begin{figure}[h]
    \centering
    \small
    \resizebox{\linewidth}{!}{
    \fbox{\begin{tabular}{ p{1.1\columnwidth} }
    % \hline
    \textbf{KP20k}: \\
    For each paper, write a short citation text that summarizes some idea reflected in the abstract without copying anything here. Use a fake paper id like [3] or [5] to refer to the paper. Do not present in a summary format. Instead, write as if you are citing the paper in another paper. \\\\

    Title: How Should I Explain? A Comparison of Different Explanation Types for Recommender Systems \\
    Abstract: Recommender systems help users locate possible items of interest more quickly by filtering and ranking them in a personalized way. Some of these systems provide the end user not only with such a personalized item list but also with an explanation which describes why a specific item is recommended and why the system supposes that the user will like it. Besides helping the user understand the output and rationale of the system, the provision of such explanations can also improve the general acceptance, perceived quality, or effectiveness of the system. In recent years, the question of how to automatically generate and present system-side explanations has attracted increased interest in research. Today some basic explanation facilities are already incorporated in e-commerce Web sites such as Amazon.com. In this work, we continue this line of recent research and address the question of how explanations can be communicated to the user in a more effective way. In particular, we present the results of a user study in which users of a recommender system were provided with different types of explanation. We experimented with 10 different explanation types and measured their effects in different dimensions. The explanation types used in the study include both known visualizations from the literature as well as two novel interfaces based on tag clouds. Our study reveals that the content-based tag cloud explanations are particularly helpful to increase the user-perceived level of transparency and to increase user satisfaction even though they demand higher cognitive effort from the user. Based on these insights and observations, we derive a set of possible guidelines for designing or selecting suitable explanations for recommender systems. \\
    Citation: The ability for an artificially intelligent system to explain recommendations has been shown to be an important factor for user acceptance and satisfaction [13].  \\ \\ 
    
    ... two examples omitted ... \\\\ 
    
    Title: [document\_title] \\
    Abstract: [document\_abstract] \\
    Citation:  \\
    \vspace{1pt} \\
    \hdashline
    \vspace{1pt} \\
    \textbf{KPTimes}: \\
    For each piece of news, write several phrases as ad-hoc queries that some people might write if they want to find this article on the Internet. Write your response in 3-5 phrases and separate the phrases with commas. \\
    Title: [document\_title] \\
    Abstract: [document\_abstract] \\
    Citation: \\
    % \hline
    \end{tabular}}}
    % \vspace{-2mm}
    \caption{Prompts used for instructing GPT-4 to generate the ad-hoc queries for utility evaluation.}
    % \vspace{-1mm}
    \label{adhoc-query-prompt}
    % \vspace{-4mm}
\end{figure}
