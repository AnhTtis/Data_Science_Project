\setlength{\tabcolsep}{3.5pt}
\begin{table*}[]
 \centering
 % \resizebox{\columnwidth}{!}{%
 \resizebox{\linewidth}{!}{
 \begin{tabular}{l | c | c | c c c c c c c c}
 \hline
 \multirow{2}{*}{\textbf{ID}} & \multirow{2}{*}{\textbf{Model}} & \multirow{2}{*}{\textbf{\#KP}} & \multicolumn{2}{c}{\textbf{Naturalness}} & \multicolumn{2}{c}{\textbf{Faithfulness}} & \multicolumn{2}{c}{\textbf{Diversity}} & \multicolumn{2}{c}{\textbf{Utility}} \\
& & & $U \uparrow$& $G \uparrow$ & $U \uparrow$ & $G \uparrow$& $dup\downarrow$ &$emb\_sim\downarrow$ & $RR@5\uparrow$ & $Spare_5@5\uparrow$ \\
 \hline
 \textbf{M0} & Human References & 5.3 & 0.833 & 4.26 & 0.697 & 3.86 & \underline{\textbf{0.073}} & 0.133 & 0.698 & 0.500 \\
\textbf{M1} & TF-IDF & 10.0 & 0.610 & 3.76 & 0.696 & 4.52 & 0.396 & 0.161 & 0.848 & 0.393 \\
\textbf{M2} & TextRank & 10.0 & 0.761 & 3.76 & 0.737 & 4.57 & 0.391 & 0.180 & 0.877 & 0.416 \\
\textbf{M3} & MultipartiteRank & 10.0 & 0.742 & 3.77 & 0.712 & 4.35 & 0.148 & \textbf{0.092} & 0.922 & 0.472 \\
\textbf{M4} & Kea & 10.0 & 0.611 & 3.76 & 0.715 & 4.51 & 0.445 & 0.175 & 0.861 & 0.388 \\
\textbf{M5} & BERT+CRF & 3.6 & 0.762 & 4.05 & \underline{\textbf{0.801}} & \textbf{4.63} & 0.137 & 0.399 & 0.633 & 0.487 \\
\textbf{M6} & HyperMatch & 10.0 & 0.708 & 3.45 & 0.772 & 4.14 & 0.297 & 0.233 & 0.854 & 0.496 \\
\textbf{M7} & CatSeq & 7.2 & 0.837 & 4.27 & 0.774 & 4.51 & 0.370 & 0.310 & 0.809 & 0.571 \\
\textbf{M8} & CatSeqTF+2RF1 & 7.9 & \underline{\textbf{0.872}} & \underline{\textbf{4.47}} & 0.734 & 3.98 & 0.355 & 0.251 & 0.795 & \textbf{0.613} \\
\textbf{M9} & ExHiRD-h & 5.5 & 0.851 & 4.31 & \textbf{0.781} & 4.50 & 0.214 & 0.195 & 0.880 & 0.576 \\
\textbf{M10} & SEG-Net & 11.0 & 0.793 & 3.88 & 0.757 & 4.50 & 0.260 & 0.177 & 0.922 & 0.587 \\
\textbf{M11} & Transformer & 8.2 & 0.837 & \textbf{4.32} & 0.747 & 4.37 & 0.289 & 0.239 & 0.863 & 0.587 \\
\textbf{M12} & SetTrans & 7.7 & \textbf{0.855} & \textbf{4.33} & 0.766 & 4.38 & 0.308 & 0.203 & 0.909 & 0.541 \\
\textbf{M13} & SciBERT-G & 6.1 & 0.841 & 4.28 & 0.762 & 4.40 & 0.152 & 0.177 & 0.848 & 0.579 \\
\textbf{M14} & BART-large & 6.6 & 0.847 & 4.23 & 0.759 & 4.25 & 0.144 & 0.168 & 0.872 & 0.568 \\
\textbf{M15} & KeyBART & 6.0 & 0.849 & 4.27 & 0.765 & 4.32 & 0.130 & 0.163 & 0.864 & 0.568 \\
\textbf{M16} & SciBART-large+OAGKX & 6.1 & 0.846 & 4.29 & 0.766 & 4.44 & \textbf{0.129} & 0.158 & 0.871 & 0.571 \\
\textbf{M17} & text-davinci-003 (0-shot) & 9.5 & 0.838 & 4.08 & 0.777 & \textbf{4.72} & 0.143 & 0.110 & \underline{\textbf{0.979}} & \textbf{0.599} \\
\textbf{M18} & text-davinci-003 (5-shot) & 6.5 & \textbf{0.857} & 4.21 & \textbf{0.790} & \underline{\textbf{4.74}} & \textbf{0.084} & 0.113 & \textbf{0.975} & \underline{\textbf{0.630}} \\
\textbf{M19} & Amazon Comprehend & 10.0 & 0.822 & 3.25 & 0.693 & 3.91 & 0.436 & \textbf{0.103} & 0.565 & 0.254 \\
\textbf{M20} & Azure Cognitive Services & 10.0 & 0.818 & 3.77 & 0.778 & 4.53 & 0.198 & \underline{\textbf{0.068}} & \textbf{0.955} & 0.552 \\
 \hline
 \end{tabular}
 }
 % \vspace{-2mm}
 \caption{Reference-free evaluation results on KP20k for all the benchmarked models. The best result is underlined and the top three results are boldfaced. $U$ = UniEval, $G$ = ChatGPT, $dup$ = $dup\_token\_ratio$. Due to cost constraints, the scores reported in $G$ columns are measured with the first 500 documents. } 
 \label{tab:all-results-ref-free-kp20k}
 % \vspace{-3mm}
 
\end{table*}


\setlength{\tabcolsep}{3.5pt}
\begin{table*}[]
 \centering
 % \resizebox{\columnwidth}{!}{%
 \resizebox{\linewidth}{!}{
 \begin{tabular}{l | c | c | c c c c c c c c}
 \hline
 \multirow{2}{*}{\textbf{ID}} & \multirow{2}{*}{\textbf{Model}} & \multirow{2}{*}{\textbf{\#KP}} & \multicolumn{2}{c}{\textbf{Naturalness}} & \multicolumn{2}{c}{\textbf{Faithfulness}} & \multicolumn{2}{c}{\textbf{Diversity}} & \multicolumn{2}{c}{\textbf{Utility}} \\
& & & $U \uparrow$& $G \uparrow$ & $U \uparrow$ & $G \uparrow$& $dup\downarrow$ &$emb\_sim\downarrow$ & $RR@5\uparrow$ & $Spare_5@5\uparrow$ \\
 \hline
 \textbf{M0} & Human References & 5.0 & 0.812 & \textbf{4.61} & 0.701 & 3.48 & \textbf{0.069} & 0.203 & 0.515 & 0.420 \\
\textbf{M1} & TF-IDF & 10.0 & 0.616 & 4.11 & 0.658 & 3.98 & 0.175 & 0.163 & 0.798 & 0.406 \\
\textbf{M2} & TextRank & 10.0 & 0.679 & 4.12 & 0.667 & 4.03 & 0.371 & 0.246 & 0.745 & 0.347 \\
\textbf{M3} & MultipartiteRank & 10.0 & 0.693 & 4.18 & 0.670 & \textbf{4.05} & 0.123 & \textbf{0.150} & \textbf{0.837} & 0.437 \\
\textbf{M4} & Kea & 10.0 & 0.615 & 4.10 & 0.699 & \textbf{4.07} & 0.219 & 0.175 & \textbf{0.843} & 0.420 \\
\textbf{M5} & BERT+CRF & 2.3 & 0.704 & 3.98 & \underline{\textbf{0.769}} & 3.90 & 0.072 & 0.556 & 0.402 & 0.372 \\
\textbf{M6} & HyperMatch & 10.0 & 0.695 & 4.24 & 0.703 & 3.68 & 0.124 & 0.271 & 0.679 & 0.320 \\
\textbf{M7} & CatSeq & 5.9 & 0.812 & 4.59 & 0.683 & 3.34 & 0.191 & 0.257 & 0.524 & 0.469 \\
\textbf{M8} & CatSeqTG-2RF1 & n/a & n/a & n/a & n/a & n/a & n/a & n/a & n/a & n/a \\
\textbf{M9} & ExHiRD-h & 5.8 & 0.801 & 4.58 & 0.680 & 3.30 & 0.149 & 0.238 & 0.535 & 0.474 \\
\textbf{M10} & SEG-Net & n/a & n/a & n/a & n/a & n/a & n/a & n/a & n/a & n/a \\
\textbf{M11} & Transformer & 5.7 & 0.803 & 4.60 & 0.658 & 3.10 & 0.133 & 0.231 & 0.522 & 0.474 \\
\textbf{M12} & SetTrans & 8.4 & 0.808 & 4.60 & 0.645 & 3.00 & 0.210 & 0.232 & 0.584 & 0.410 \\
\textbf{M13} & SciBERT-G & 4.5 & 0.812 & 4.60 & 0.716 & 3.51 & 0.064 & 0.208 & 0.594 & 0.473 \\
\textbf{M14} & BART-large & 5.4 & 0.809 & 4.60 & 0.706 & 3.43 & 0.074 & 0.203 & 0.641 & \textbf{0.482} \\
\textbf{M15} & KeyBART & 5.9 & 0.806 & 4.55 & 0.696 & 3.35 & 0.086 & 0.206 & 0.639 & 0.480 \\
\textbf{M16} & SciBART-large+OAGKX & 4.8 & 0.810 & 4.60 & 0.718 & 3.52 & \textbf{0.069} & 0.203 & 0.628 & \textbf{0.482} \\
\textbf{M17} & text-davinci-003 (0-shot) & 14.1 & \textbf{0.840} & \textbf{4.65} & 0.690 & 3.98 & 0.082 & \textbf{0.137} & \underline{\textbf{0.871}} & \underline{\textbf{0.597}} \\
\textbf{M18} & text-davinci-003 (5-shot) & 6.7 & \underline{\textbf{0.859}} & \underline{\textbf{4.78}} & \textbf{0.725} & \underline{\textbf{4.28}} &  \underline{\textbf{0.044}} & 0.188 & 0.829 & \textbf{0.582} \\
\textbf{M19} & Amazon Comprehend & 10.0 & \textbf{0.818} & 3.62 & 0.617 & 3.17 & 0.291 & 0.203 & 0.492 & 0.123 \\
\textbf{M20} & Azure Cognitive Services & 10.0 & 0.769 & 4.09 & \textbf{0.728} & 3.71 & 0.140 & \underline{\textbf{0.133}} & 0.564 & 0.338 \\
 \hline
 \end{tabular}
 }
 % \vspace{-2mm}
 \caption{Reference-free evaluation results on KPTimes for all the benchmarked models. The best result is underlined and the top three results are boldfaced. $U$ = UniEval, $G$ = ChatGPT, $dup$ = $dup\_token\_ratio$. Due to cost constraints, the scores reported in $G$ columns are measured with the first 500 documents. } 
 \label{tab:all-results-ref-free-kptimes}
 % \vspace{-3mm}
 
\end{table*}
