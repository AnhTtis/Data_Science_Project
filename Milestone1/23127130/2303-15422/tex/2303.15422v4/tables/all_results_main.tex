\setlength{\tabcolsep}{3.5pt}
\begin{table*}[!ht]
 \centering
 % \resizebox{\columnwidth}{!}{%
 \vspace{-3mm}
 \resizebox{\linewidth}{!}{
 \begin{tabular}{c | c | c | c c c | c | c c | c c }
 \hline
 \multirow{2}{*}{\textbf{ID}} & \multirow{2}{*}{\textbf{Model}} & \multirow{2}{*}{\textbf{\#KP}} & \multicolumn{3}{c|}{\textbf{Reference Agreement}} & \textbf{Faithfulness} & \multicolumn{2}{c|}{\textbf{Diversity}} & \multicolumn{2}{c}{\textbf{Utility}} \\
& & & $SemP \uparrow$ & $SemR \uparrow$ & $SemF1 \uparrow$ & $UniEval\uparrow$ & $dup \downarrow$ &$emb\_sim \downarrow$ & $RR@5 \uparrow$ & $Recall@5 \uparrow$ \\
 \hline
 \multicolumn{8}{l}{\textbf{\textit{KP20k}}} \\
 \hdashline
% \textbf{M0} & Human References & 5.3 & n/a & n/a & n/a & 0.697 & xx86 & \textbf{0.073}$^\dagger$& 0.133 & 0.824 & 0.722 \\
\textbf{M1} & TF-IDF\textsuperscript{\ding{107}} & 10.0 & 0.431 & 0.524 & 0.463 & 0.696  & 0.396 & 0.161 & \underline{0.889} & \underline{0.805} \\
\textbf{M2} & TextRank\textsuperscript{\ding{107}} & 10.0 & 0.432 & 0.518 & 0.460 & 0.737  & 0.391 & 0.180 & 0.882 & 0.796 \\
\textbf{M3} & RAKE\textsuperscript{\ding{107}} & 10.0 & 0.401 & 0.499 & 0.437 & 0.733 & 0.295 & 0.170 & 0.855 & 0.783
\\
\textbf{M4} & MultipartiteRank\textsuperscript{\ding{107}} & 10.0 & 0.364 & 0.548 & 0.429 & 0.712 & 0.148 & \underline{0.092} & 0.881 & 0.794 \\
\textbf{M5} & YAKE!\textsuperscript{\ding{107}} & 10.0 & 0.434 & 0.508 & 0.459 & 0.778 & 0.372 & 0.190 & 0.859 & 0.786 \\
\textbf{M6} & PromptRank\textsuperscript{\ding{107}}\textsuperscript{\ding{95}} & 10.0 & 0.414 & 0.556 & 0.465 & 0.755 & 0.133 & 0.159 & 0.866 & 0.786 \\
\textbf{M7} & Kea\textsuperscript{\ding{107}}\textsuperscript{\ding{169}} & 10.0 & 0.452 & 0.533 & 0.479 & 0.715 & 0.445 & 0.175 & \textbf{0.892} &  \textbf{0.809}$^\dagger$ \\
\textbf{M8} & BERT+CRF\textsuperscript{\ding{107}}\textsuperscript{\ding{169}}\textsuperscript{\ding{95}} & 10.0 & \textbf{0.675}$^\dagger$ & 0.447 & 0.515 & \textbf{0.801}$^\dagger$ & 0.137 & 0.399 &  0.879 & 0.796\\
\textbf{M9} & HyperMatch\textsuperscript{\ding{107}}\textsuperscript{\ding{169}}\textsuperscript{\ding{95}} & 10.0 & 0.505 & \textbf{0.631}$^\dagger$ & 0.549 & 0.772 & 0.297 & 0.233 & 0.881 & 0.798 \\
\textbf{M10} & CatSeq\textsuperscript{\ding{169}} & 7.2 & 0.596 & 0.531 & 0.548 & 0.774 & 0.370 & 0.310 & 0.884 & 0.797 \\
\textbf{M11} & CatSeqTG-2RF1\textsuperscript{\ding{169}} & 7.9 & 0.550 & 0.579 & 0.553 & 0.734 & 0.355 & 0.251 & 0.886 & 0.801 \\
\textbf{M12} & ExHiRD-h\textsuperscript{\ding{169}} & 5.5 & 0.587 & 0.559 & 0.562 & 0.781 & 0.214 & 0.195 & 0.878 & 0.791 \\
\textbf{M13} & SEG-Net\textsuperscript{\ding{169}} & 11.0 & 0.560 & 0.596 & 0.565 & 0.757 & 0.260 & 0.177 & \underline{0.889} & 0.804 \\
\textbf{M14} & Transformer\textsuperscript{\ding{169}} & 8.2 & 0.558 & 0.593 & 0.562 & 0.747 & 0.289 & 0.239 & 0.878 & 0.791 \\
\textbf{M15} & SetTrans\textsuperscript{\ding{169}} & 7.7 & 0.570 & \underline{0.623} & \underline{0.583} & 0.766 & 0.308 & 0.203 & \underline{0.889} & 0.803 \\
\textbf{M16} & SciBERT-G\textsuperscript{\ding{169}}\textsuperscript{\ding{95}} & 6.1 & 0.587 & 0.590 & 0.577 & 0.762 & 0.152 & 0.177 & 0.878 & 0.791 \\
\textbf{M17} & BART-large\textsuperscript{\ding{169}}\textsuperscript{\ding{95}} & 6.6 & 0.567 & \textbf{0.607} & 0.574 & 0.759 & 0.144 & 0.168 & 0.877 & 0.790 \\
\textbf{M18} & KeyBART\textsuperscript{\ding{169}}\textsuperscript{\ding{95}} & 6.0 & 0.580 & 0.599 & 0.577 & 0.765 & 0.130 & 0.163 & 0.883 & 0.792 \\
\textbf{M19} & SciBART-large+OAGKX\textsuperscript{\ding{169}}\textsuperscript{\ding{95}} & 6.1 & \underline{0.601} & \underline{0.623} & \textbf{0.601}$^\dagger$ & 0.766 & \underline{0.129} & 0.158 & 0.879 & 0.793 \\
\textbf{M20} & text-davinci-003 (0-shot)\textsuperscript{\ding{95}} & 9.5 & 0.433 & 0.616 & 0.498 & 0.777 & 0.143 & 0.110 & 0.888 & 0.799 \\
\textbf{M21} & text-davinci-003 (5-shot)\textsuperscript{\ding{95}} & 6.5 & 0.503 & 0.599 & 0.535 & \underline{0.790} & \textbf{0.084}$^\dagger$ & 0.113 & 0.886 & 0.802 \\
\textbf{M22} & Amazon Comprehend\textsuperscript{\ding{107}} & 10.0 & 0.224 & 0.324 & 0.259 & 0.693 & 0.436 & 0.103 & 0.855 & 0.758 \\
\textbf{M23} & Azure Cognitive Services\textsuperscript{\ding{107}} & 10.0 & 0.387 & 0.536 & 0.440 & 0.778 & 0.198 & \textbf{0.068}$^\dagger$ & 0.874 & 0.780 \\
 \hline
 \multicolumn{8}{l}{\textbf{\textit{KPTimes}}} \\
 \hdashline
% \textbf{M0} & Human References & 5.0 & n/a & n/a & n/a & 0.701 & xx48 & 0.069 & 0.203 & 0.324 & 0.230 \\
\textbf{M1} & TF-IDF\textsuperscript{\ding{107}} & 10.0 & 0.403 & 0.557 & 0.461 & 0.658 & 0.175 & 0.163 & 0.589 & 0.482 \\
\textbf{M2} & TextRank\textsuperscript{\ding{107}} & 10.0 & 0.457 & 0.532 & 0.483 & 0.667 & 0.371 & 0.246 & 0.598 & 0.485 \\
\textbf{M3} & RAKE & 10.0 & 0.284 & 0.380 & 0.321 & 0.693 & 0.157 & 0.140 & 0.555 & 0.442 \\
\textbf{M4} & MultipartiteRank\textsuperscript{\ding{107}} & 10.0 & 0.410 & 0.575 & 0.472 & 0.670 & 0.123 & 0.150 & 0.589 & 0.483 \\
\textbf{M5} & YAKE! & 10.0 & 0.387 & 0.442 & 0.405 & 0.639 & 0.317 & 0.225 & 0.564 & 0.441 \\
\textbf{M6} & PromptRank\textsuperscript{\ding{107}}\textsuperscript{\ding{95}} & 10.0 & 0.427 & 0.574 & 0.483 & 0.699 & 0.233 & \underline{0.134} & 0.569 & 0.458\\
\textbf{M7} & Kea\textsuperscript{\ding{107}}\textsuperscript{\ding{169}} & 10.0 & 0.427 & 0.575 & 0.484 & 0.699 & 0.219 & 0.175 & \textbf{0.607}$^\dagger$ & \textbf{0.500}$^\dagger$ \\
\textbf{M8} & BERT+CRF\textsuperscript{\ding{107}}\textsuperscript{\ding{169}}\textsuperscript{\ding{95}} & 2.3 & 0.741 & 0.459 & 0.550 & \textbf{0.769}$^\dagger$ & 0.072 & 0.556 & 0.583 & 0.478 \\
\textbf{M9} & HyperMatch\textsuperscript{\ding{107}}\textsuperscript{\ding{169}}\textsuperscript{\ding{95}} & 10.0 & 0.493 & 0.655 & 0.554 & 0.703 & 0.124 & 0.271 & 0.587 & 0.477 \\
\textbf{M10} & CatSeq\textsuperscript{\ding{169}} & 5.9 & 0.723 & 0.714 & 0.708 & 0.683 & 0.191 & 0.257 & 0.569 & 0.454 \\
\textbf{M11} & CatSeqTG-2RF1\textsuperscript{\ding{169}} & n/a & n/a & n/a & n/a & n/a & n/a & n/a & n/a & n/a \\
\textbf{M12} & ExHiRD-h\textsuperscript{\ding{169}} & 5.8 & 0.725 & 0.713 & 0.709 & 0.680 & 0.149 & 0.238 & 0.572 & 0.454 \\
\textbf{M13} & SEG-Net\textsuperscript{\ding{169}} & n/a & n/a & n/a & n/a & n/a & n/a & n/a & n/a & n/a \\
\textbf{M14} & Transformer\textsuperscript{\ding{169}} & 5.7 & 0.720 & 0.736 & 0.717 & 0.658 & 0.133 & 0.231 & 0.569 & 0.456 \\
\textbf{M15} & SetTrans\textsuperscript{\ding{169}} & 8.4 & 0.662 & \underline{0.801} & 0.716 & 0.645 & 0.210 & 0.232 & 0.572 & 0.454 \\
\textbf{M16} & SciBERT-G\textsuperscript{\ding{169}}\textsuperscript{\ding{95}} & 4.5 & \textbf{0.784} & 0.737 & 0.749 & 0.716 & \underline{0.064} & 0.208 & 0.579 & 0.468 \\
\textbf{M17} & BART-large\textsuperscript{\ding{169}}\textsuperscript{\ding{95}} & 5.4 & 0.768 & 0.796 & \textbf{0.770}$^\dagger$ & 0.706 & 0.074 & 0.203 & 0.582 & 0.469 \\
\textbf{M18} & KeyBART\textsuperscript{\ding{169}}\textsuperscript{\ding{95}} & 5.9 & 0.751 & \textbf{0.807}$^\dagger$ & \underline{0.766} & 0.696 & 0.086 & 0.206 &  0.579 & 0.466 \\
\textbf{M19} & SciBART-large+OAGKX\textsuperscript{\ding{169}}\textsuperscript{\ding{95}} & 4.8 & \underline{0.782} & 0.766 & 0.763 & 0.718 & 0.069 & 0.203 & 0.581 & 0.472 \\
\textbf{M20} & text-davinci-003 (0-shot)\textsuperscript{\ding{95}} & 14.1 & 0.383 & 0.620 & 0.467 & 0.690 & 0.082 & 0.137 & \underline{0.599} & \underline{0.487} \\
\textbf{M21} & text-davinci-003 (5-shot)\textsuperscript{\ding{95}} & 6.7 & 0.549 & 0.643 & 0.582 & 0.725 & \textbf{0.044}$^\dagger$ & 0.188 & 0.590 & 0.479 \\
\textbf{M22} & Amazon Comprehend\textsuperscript{\ding{107}} & 10.0 & 0.258 & 0.347 & 0.292 & 0.617 & 0.291 & 0.203 & 0.544 & 0.433 \\
\textbf{M23} & Azure Cognitive Services\textsuperscript{\ding{107}} & 10.0 & 0.312 & 0.425 & 0.355 & \underline{0.728} & 0.140 & \textbf{0.133}$^\dagger$ & 0.543 & 0.425 \\
 \hline
 \end{tabular}
 }
 % \vspace{-4mm}
 \caption{Evaluation results for 23 evaluated keyphrase systems. Due to budget constraints, we only sample 1000 documents per dataset for utility evaluation. For the other aspects, the complete test sets are used. \#KP = Number of keyphrases. $dup$ = $dup\_token\_ratio$. We use $\uparrow$ for the higher the better and $\downarrow$ for the reverse. The best is boldfaced and the second best is underlined. $^\dagger$ indicates statistically significantly better than the second best with $p < 0.01$ via a paired t-test. \textsuperscript{\ding{107}} = KPE systems. \textsuperscript{\ding{169}} = supervised models. \textsuperscript{\ding{95}} = pre-trained language models. }
 \label{tab:all-results-main}
 % \vspace{-4mm}
\end{table*}