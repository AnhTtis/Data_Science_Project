{
    "arxiv_id": "2303.12735",
    "paper_title": "SMUG: Towards robust MRI reconstruction by smoothed unrolling",
    "authors": [
        "Hui Li",
        "Jinghan Jia",
        "Shijun Liang",
        "Yuguang Yao",
        "Saiprasad Ravishankar",
        "Sijia Liu"
    ],
    "submission_date": "2023-03-14",
    "revised_dates": [
        "2023-03-23"
    ],
    "latest_version": 1,
    "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG",
        "physics.med-ph"
    ],
    "abstract": "Although deep learning (DL) has gained much popularity for accelerated magnetic resonance imaging (MRI), recent studies have shown that DL-based MRI reconstruction models could be oversensitive to tiny input perturbations (that are called 'adversarial perturbations'), which cause unstable, low-quality reconstructed images. This raises the question of how to design robust DL methods for MRI reconstruction. To address this problem, we propose a novel image reconstruction framework, termed SMOOTHED UNROLLING (SMUG), which advances a deep unrolling-based MRI reconstruction model using a randomized smoothing (RS)-based robust learning operation. RS, which improves the tolerance of a model against input noises, has been widely used in the design of adversarial defense for image classification. Yet, we find that the conventional design that applies RS to the entire DL process is ineffective for MRI reconstruction. We show that SMUG addresses the above issue by customizing the RS operation based on the unrolling architecture of the DL-based MRI reconstruction model. Compared to the vanilla RS approach and several variants of SMUG, we show that SMUG improves the robustness of MRI reconstruction with respect to a diverse set of perturbation sources, including perturbations to the input measurements, different measurement sampling rates, and different unrolling steps. Code for SMUG will be available at https://github.com/LGM70/SMUG.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12735v1"
    ],
    "publication_venue": "Accepted by ICASSP 2023"
}