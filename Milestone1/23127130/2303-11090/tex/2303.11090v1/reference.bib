@article{Li2022VisionLanguageIT,
  title={Vision-Language Intelligence: Tasks, Representation Learning, and Large Models},
  author={Feng Li and Hao Zhang and Yi-Fan Zhang and Shi Tong Liu and Jian Guo and Lionel M. Ni and Pengchuan Zhang and Lei Zhang},
  journal={ArXiv},
  year={2022},
  volume={abs/2203.01922}
}

@article{wang2018learning,
  title={Learning two-branch neural networks for image-text matching tasks},
  author={Wang, Liwei and Li, Yin and Huang, Jing and Lazebnik, Svetlana},
  journal={TPAMI},
  volume={41},
  number={2},
  pages={394--407},
  year={2018},
  publisher={IEEE}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}


@inproceedings{lee2018stacked,
  title={Stacked cross attention for image-text matching},
  author={Lee, Kuang-Huei and Chen, Xi and Hua, Gang and Hu, Houdong and He, Xiaodong},
  booktitle={ECCV},
  pages={201--216},
  year={2018}
}

@inproceedings{ijcai2019p526,
  title     = {Position Focused Attention Network for  Image-Text Matching},
  author    = {Wang, Yaxiong and Yang, Hao and Qian, Xueming and Ma, Lin and Lu, Jing and Li, Biao and Fan, Xin},
  booktitle = {IJCAI},
  //publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {3792--3798},
  year      = {2019},
  //month     = {7},
  doi       = {10.24963/ijcai.2019/526},
  url       = {https://doi.org/10.24963/ijcai.2019/526},
}

@inproceedings{liu2020graph,
  title={Graph structured network for image-text matching},
  author={Liu, Chunxiao and Mao, Zhendong and Zhang, Tianzhu and Xie, Hongtao and Wang, Bin and Zhang, Yongdong},
  booktitle={CVPR},
  pages={10921--10930},
  year={2020}
}

@inproceedings{wei2020multi,
  title={Multi-modality cross attention network for image and sentence matching},
  author={Wei, Xi and Zhang, Tianzhu and Li, Yan and Zhang, Yongdong and Wu, Feng},
  booktitle={CVPR},
  pages={10941--10950},
  year={2020}
}

@inproceedings{ijcai2021p106,
  title     = {Step-Wise Hierarchical Alignment Network for Image-Text Matching},
  author    = {Ji, Zhong and Chen, Kexin and Wang, Haoran},
  booktitle = {IJCAI},
  //publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {765--771},
  year      = {2021},
  //month     = {8},
  //note      = {Main Track},
  doi       = {10.24963/ijcai.2021/106},
  url       = {https://doi.org/10.24963/ijcai.2021/106},
}


@inproceedings{wang2020cross,
  title={Cross-modal scene graph matching for relationship-aware image-text retrieval},
  author={Wang, Sijin and Wang, Ruiping and Yao, Ziwei and Shan, Shiguang and Chen, Xilin},
  booktitle={WACV},
  pages={1508--1517},
  year={2020}
}

@article{Nguyen2021ADL,
  title={A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval},
  author={Manh-Duy Nguyen and Binh T. Nguyen and Cathal Gurrin},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.02400}
}

@article{nagrani2021attention,
  title={Attention bottlenecks for multimodal fusion},
  author={Nagrani, Arsha and Yang, Shan and Arnab, Anurag and Jansen, Aren and Schmid, Cordelia and Sun, Chen},
  journal={NeurIPS},
  volume={34},
  pages={14200--14213},
  year={2021}
}

@inproceedings{zhang2020context,
  title={Context-aware attention network for image-text retrieval},
  author={Zhang, Qi and Lei, Zhen and Zhang, Zhaoxiang and Li, Stan Z},
  booktitle={CVPR},
  pages={3536--3545},
  year={2020}
}


@inproceedings{zhou2021deepvit,
  title={Deepvit: Towards deeper vision transformer},
  author={Zhou, Daquan and Kang, Bingyi and Jin, Xiaojie and Yang, Linjie and Lian, Xiaochen and Jiang, Zihang and Hou, Qibin and Feng, Jiashi},
  booktitle={CVPR},
  year={2021}
}


@inproceedings{chen2021crossvit,
  title={Crossvit: Cross-attention multi-scale vision transformer for image classification},
  author={Chen, Chun-Fu Richard and Fan, Quanfu and Panda, Rameswar},
  booktitle={ICCV},
  pages={357--366},
  year={2021}
}

@inproceedings{wu2019learning,
  title={Learning fragment self-attention embeddings for image-text matching},
  author={Wu, Yiling and Wang, Shuhui and Song, Guoli and Huang, Qingming},
  booktitle={ACM MM},
  pages={2088--2096},
  year={2019}
}


@article{cong2022reltr,
  title={RelTR: Relation Transformer for Scene Graph Generation},
  author={Cong, Yuren and Yang, Michael Ying and Rosenhahn, Bodo},
  journal={arXiv preprint arXiv:2201.11460},
  year={2022}
}

@inproceedings{plummer2015flickr30k,
  title={Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models},
  author={Plummer, Bryan A and Wang, Liwei and Cervantes, Chris M and Caicedo, Juan C and Hockenmaier, Julia and Lazebnik, Svetlana},
  booktitle={ICCV},
  pages={2641--2649},
  year={2015}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  pages={740--755},
  year={2014},
  _organization={Springer}
}

@inproceedings{diao2021similarity,
  title={Similarity reasoning and filtration for image-text matching},
  author={Diao, Haiwen and Zhang, Ying and Ma, Lin and Lu, Huchuan},
  booktitle={AAAI},
  volume={35},
  pages={1218--1226},
  year={2021}
}


@article{li2021multi,
  title={Multi-scale Fine-grained Alignments for Image and Sentence Matching},
  author={Li, Wenhui and Wang, Yan and Su, Yuting and Li, Xuanya and Liu, Anan and Zhang, Yongdong},
  journal={IEEE Trans Multimedia},
  year={2021},
  publisher={IEEE}
}