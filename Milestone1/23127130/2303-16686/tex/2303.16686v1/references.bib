
@INPROCEEDINGS{gyekye2008,
  author={Nkansah-Gyekye, Yaw and Agbinya, Johnson I.},
  booktitle={2008 Third International Conference on Broadband Communications, Information Technology   Biomedical Applications}, 
  title={A Vertical Handoff Decision Algorithm for Next Generation Wireless Networks}, 
  year={2008},
  volume={},
  number={},
  pages={358-364},
  }

@INPROCEEDINGS{slsstart,  author={Kang, Jikun and Chen, Xi and Wu, Di and Xu, Yi Tian and Liu, Xue and Dudek, Gregory and Lee, Taeseop and Park, Intaik},  booktitle={ICC 2021 - IEEE International Conference on Communications},   title={Hierarchical Policy Learning for Hybrid Communication Load Balancing},   year={2021},  volume={},  number={},  pages={1-6},  doi={10.1109/ICC42927.2021.9500379}}

% all papers with SLS

@ARTICLE{slsend,  author={Feriani, Amal and Wu, Di and Xu, Yi Tian and Li, Jimmy and Jang, Seowoo and Hossain, Ekram and Liu, Xue and Dudek, Gregory},  journal={IEEE Journal on Selected Areas in Communications},   title={Multiobjective Load Balancing for Multiband Downlink Cellular Networks: A Meta- Reinforcement Learning Approach},   year={2022},  volume={40},  number={9},  pages={2614-2629},  doi={10.1109/JSAC.2022.3191114}}

@ARTICLE{mwanjeSON2016,
  author={Mwanje, Stephen S. and Schmelz, Lars Christoph and Mitschele-Thiel, Andreas},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Cognitive Cellular Networks: A Q-Learning Framework for Self-Organizing Networks}, 
  year={2016},
  volume={13},
  number={1},
  pages={85-98},
  doi={10.1109/TNSM.2016.2522080}}

@INPROCEEDINGS{kudoHnets2014,  
    author={Kudo, Toshihito and Ohtsuki, Tomoaki},  
    booktitle={2014 IEEE 80th Vehicular Technology Conference (VTC2014-Fall)},   
    title={Q-Learning Based Cell Selection for UE Outage Reduction in Heterogeneous Networks},   year={2014},  
    volume={},  
    number={},  
    pages={1-5},  
    doi={10.1109/VTCFall.2014.6966140}}
    
@INPROCEEDINGS{nasri2007,
  TITLE = {{Handover adaptation for dynamic load Balancing in 3GPP Long Term Evolution Systems}},
  AUTHOR = {Nasri, Ridha and Altman, Zwi},
  URL = {https://hal.inria.fr/hal-00918897},
  BOOKTITLE = {{5th International Conf. on Advances in Mobile Computing \\& Multimedia (MoMM2007)}},
  ADDRESS = {Jakarta, Indonesia},
  YEAR = {2007},
  MONTH = Jan,
  PDF = {https://hal.inria.fr/hal-00918897/file/zwi2.pdf},
  HAL_ID = {hal-00918897},
  HAL_VERSION = {v1},
}

@INPROCEEDINGS{kwan2010,  
    author={Kwan, Raymond and Arnott, Rob and Paterson, Robert and Trivisonno, Riccardo and Kubota, Mitsuhiro},  booktitle={2010 IEEE 72nd Vehicular Technology Conference - Fall},   title={On Mobility Load Balancing for LTE Systems},  
    year={2010},
    volume={},
    number={},
    pages={1-5},  doi={10.1109/VETECF.2010.5594565}}
    
@INPROCEEDINGS{zhang2010,  
    author={Zhang, Heng and Qiu, Xuesong and Meng, Luoming and Zhang, Xidong},  
    booktitle={2010 IEEE 72nd Vehicular Technology Conference - Fall},   title={Design of Distributed and Autonomic Load Balancing for Self-Organization LTE},   year={2010},  
    volume={}, 
    number={}, 
    pages={1-5},  doi={10.1109/VETECF.2010.5594567}}
    
@ARTICLE{xuUDN2019,
  author={Xu, Yue and Xu, Wenjun and Wang, Zhi and Lin, Jiaru and Cui, Shuguang},
  journal={IEEE Internet of Things Journal}, 
  title={Load Balancing for Ultradense Networks: A Deep Reinforcement Learning-Based Approach}, 
  year={2019},
  volume={6},
  number={6},
  pages={9399-9412},
  doi={10.1109/JIOT.2019.2935010}}

@article{afsar2021reinforcement,
  title={Reinforcement learning based recommender systems: A survey},
  author={Afsar, M Mehdi and Crump, Trafford and Far, Behrouz},
  journal={arXiv preprint arXiv:2101.06286},
  year={2021}
}
@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{munoz2012fuzzy,
  title={Fuzzy rule-based reinforcement learning for load balancing techniques in enterprise LTE femtocells},
  author={Mu{\~n}oz, Pablo and Barco, Raquel and Ruiz-Avil{\'e}s, Jos{\'e} Mar{\'\i}a and De La Bandera, Isabel and Aguilar, Alejandro},
  journal={IEEE Transactions on Vehicular Technology},
  volume={62},
  number={5},
  pages={1962--1973},
  year={2012},
  publisher={IEEE}
}

@inproceedings{lee2001stock,
  title={Stock price prediction using reinforcement learning},
  author={Lee, Jae Won},
  booktitle={ISIE 2001. 2001 IEEE International Symposium on Industrial Electronics Proceedings (Cat. No. 01TH8570)},
  volume={1},
  pages={690--695},
  year={2001},
  organization={IEEE}
}

@book{holma2012lte,
  title={LTE advanced: 3GPP solution for IMT-Advanced},
  author={Holma, Harri and Toskala, Antti},
  year={2012},
  publisher={John Wiley \& Sons}
}

@inproceedings{brown2019extrapolating,
  title={Extrapolating beyond suboptimal demonstrations via inverse reinforcement learning from observations},
  author={Brown, Daniel and Goo, Wonjoon and Nagarajan, Prabhat and Niekum, Scott},
  booktitle={International conference on machine learning},
  pages={783--792},
  year={2019},
  organization={PMLR}
}

@INPROCEEDINGS{Ng00algorithmsfor,
    author = {Andrew Y. Ng and Stuart Russell},
    title = {Algorithms for Inverse Reinforcement Learning},
    booktitle = {in Proc. 17th International Conf. on Machine Learning},
    year = {2000},
    pages = {663--670},
    publisher = {Morgan Kaufmann}
}

@article{sharifzadeh2016learning,
  title={Learning to drive using inverse reinforcement learning and deep q-networks},
  author={Sharifzadeh, Sahand and Chiotellis, Ioannis and Triebel, Rudolph and Cremers, Daniel},
  journal={arXiv preprint arXiv:1612.03653},
  year={2016}
}
@inproceedings{finn2016guided,
  title={Guided cost learning: Deep inverse optimal control via policy optimization},
  author={Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={49--58},
  year={2016},
  organization={PMLR}
}

@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and others},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}


@InProceedings{schulman2015trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1889--1897},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/schulman15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/schulman15.html},
}


@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{abbeel2004irl,
author = {Abbeel, Pieter and Ng, Andrew Y.},
title = {Apprenticeship Learning via Inverse Reinforcement Learning},
year = {2004},
isbn = {1581138385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/1015330.1015430},
booktitle = {Proceedings of the Twenty-First International Conference on Machine Learning},
pages = {1},
location = {Banff, Alberta, Canada},
series = {ICML '04}
}

@inproceedings{ziebart2008maxent,
author = {Ziebart, Brian D. and Maas, Andrew and Bagnell, J. Andrew and Dey, Anind K.},
title = {Maximum Entropy Inverse Reinforcement Learning},
year = {2008},
isbn = {9781577353683},
publisher = {AAAI Press},
booktitle = {Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 3},
pages = {1433–1438},
numpages = {6},
location = {Chicago, Illinois},
series = {AAAI'08}
}

@article{jaynes1957information,
  title={Information theory and statistical mechanics},
  author={Jaynes, Edwin T},
  journal={Physical review},
  volume={106},
  number={4},
  pages={620},
  year={1957},
  publisher={APS}
}

@INPROCEEDINGS{yingyang2012,
  author={Yang, Ying and Li, Pengfei and Chen, Xiaohui and Wang, Weidong},
  booktitle={2012 IEEE Vehicular Technology Conference (VTC Fall)},
  title={A High-Efficient Algorithm of Mobile Load Balancing in LTE System}, 
  year={2012},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/VTCFall.2012.6398873}}


@INPROCEEDINGS{yuexu2019drlMLB,
  author={Xu, Yue and Xu, Wenjun and Wang, Zhi and Lin, Jiaru and Cui, Shuguang},
  booktitle={2019 IEEE International Conference on Communications}, 
  title={Deep Reinforcement Learning Based Mobility Load Balancing Under Multiple Behavior Policies}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ICC.2019.8761343}}

@INPROCEEDINGS{mwanje2013Q-learn,
  author={Mwanje, Stephen S. and Mitschele-Thiel, Andreas},
  booktitle={2013 IEEE 24th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)}, 
  title={A Q-Learning strategy for LTE mobility Load Balancing}, 
  year={2013},
  volume={},
  number={},
  pages={2154-2158},
  doi={10.1109/PIMRC.2013.6666500}}

@INPROCEEDINGS{baros2019D2D,
  author={Barros, Pedro H. and Cardoso-Pereira, Isadora and Foschini, Luca and Corradi, Antonio and Ramos, Heitor S.},
  booktitle={2019 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={Load balancing in D2D networks Using Reinforcement Learning}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ISCC47284.2019.8969767}}

@misc{globalinternetmap,
  title = {Global internet map},
  howpublished = {\url{https://global-internet-map-2021.telegeography.com/}},
  note = {Accessed: 2022-01-17}
}

@book{holma2012LTE-Advanced,
  title     = "LTE‐Advanced: 3GPP Solution for IMT‐Advanced",
  author    = "Holma, Harri and Toskala, Antti",
  year      = 2012,
  publisher = "John Wiley & Sons, Ltd",
  doi={10.1002/9781118399439}
}
@book{ciscoreport2017,
  title     = {Cisco visual networking index: Global mobile data traffic
forecast update, 2017–2022},
  author    = {Cisco},
  year      = {2017},
  publisher = {White Paper},
}

@InProceedings{activity_forecast_rhinehard_2017,
author = {Rhinehart, Nicholas and Kitani, Kris M.},
title = {First-Person Activity Forecasting With Online Inverse Reinforcement Learning},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
} 

@inproceedings{ziebart2008navigate,
  title={Navigate like a cabbie: Probabilistic reasoning from observed context-aware behavior},
  author={Ziebart, Brian D and Maas, Andrew L and Dey, Anind K and Bagnell, J Andrew},
  booktitle={Proceedings of the 10th international conference on Ubiquitous computing},
  pages={322--331},
  year={2008}
}

@inproceedings{das2014effects,
  title={The effects of feedback on human behavior in social media: An inverse reinforcement learning model},
  author={Das, Sanmay and Lavoie, Allen},
  booktitle={Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems},
  pages={653--660},
  year={2014},
  organization={Citeseer}
}

@article{human_motion_analysis_Li_2020,
author = {Kun Li and Joel W Burdick},
title ={Human motion analysis in medical robotics via high-dimensional inverse reinforcement learning},
journal = {The International Journal of Robotics Research},
volume = {39},
number = {5},
pages = {568-585},
year = {2020},
doi = {10.1177/0278364920903104},
URL = {https://doi.org/10.1177/0278364920903104},
eprint = {https://doi.org/10.1177/0278364920903104},
}

@inproceedings{kuderer2015learning,
  title={Learning driving styles for autonomous vehicles from demonstration},
  author={Kuderer, Markus and Gulati, Shilpa and Burgard, Wolfram},
  booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2641--2646},
  year={2015},
  organization={IEEE}
}

@article{sharifzadeh2016learning,
  title={Learning to drive using inverse reinforcement learning and deep q-networks},
  author={Sharifzadeh, Sahand and Chiotellis, Ioannis and Triebel, Rudolph and Cremers, Daniel},
  journal={arXiv preprint arXiv:1612.03653},
  year={2016}
}

@inproceedings{zou2018inverse,
  title={Inverse reinforcement learning via neural network in driver behavior modeling},
  author={Zou, QiJie and Li, Haoyu and Zhang, Rubo},
  booktitle={2018 IEEE Intelligent Vehicles Symposium (IV)},
  pages={1245--1250},
  year={2018},
  organization={IEEE}
}

@inproceedings{xie2019learning,
  title={Learning virtual grasp with failed demonstrations via bayesian inverse reinforcement learning},
  author={Xie, Xu and Li, Changyang and Zhang, Chi and Zhu, Yixin and Zhu, Song-Chun},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1812--1817},
  year={2019},
  organization={IEEE}
}

@article{zhang2021learning,
  title={Learning variable impedance control via inverse reinforcement learning for force-related tasks},
  author={Zhang, Xiang and Sun, Liting and Kuang, Zhian and Tomizuka, Masayoshi},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={2},
  pages={2225--2232},
  year={2021},
  publisher={IEEE}
}


@INPROCEEDINGS{elbv_shorabi2021, 
    author={Sohrabi, Vahid and Esmaeili, Mohammad Esmaeil and Dolati, Mahdi and Khonsari, Ahmad and Dadlanit, Aresh},  
    booktitle={2021 IEEE Global Communications Conference (GLOBECOM)},   title={EVBLB: Efficient Voronoi Tessellation-Based Load Balancing in Edge Computing Networks},   
    year={2021}, 
    volume={}, 
    number={}, 
    pages={1-6},
    doi={10.1109/GLOBECOM46510.2021.9685358}}
    
    
@INPROCEEDINGS{zhang2021STD,  
    author={Zhang, Yuejie and Sun, Kai and Gao, Xueliang and Huang, Wei and Zhang, Haijun},  
    booktitle={2021 IEEE Global Communications Conference (GLOBECOM)},  
    title={Load Balancing and User Association Based on Historical Data},   
    year={2021},  
    volume={}, 
    number={}, 
    pages={1-6},
    doi={10.1109/GLOBECOM46510.2021.9685782}}
    
    
@INPROCEEDINGS{wu2021dataefficientRL,
    author={Wu, Di and Kang, Jikun and Xu, Yi Tian and Li, Hang and Li, Jimmy and Chen, Xi and Rivkin, Dmitriy and Jenkin, Michael and Lee, Taeseop and Park, Intaik and Liu, Xue and Dudek, Gregory}, 
    booktitle={2021 IEEE Global Communications Conference}, 
    title={Load Balancing for Communication Networks via Data-Efficient Deep Reinforcement Learning},  
    year={2021},  
    volume={},  
    number={}, 
    pages={01-07}, 
    doi={10.1109/GLOBECOM46510.2021.9685294}}
    
@INPROCEEDINGS{gupta2021DRL, 
    author={Gupta, Manan and Dreifuerst, Ryan M. and Yazdan, Ali and Huang, Po-Han and Kasturia, Sanjay and Andrews, Jeffrey G.}, 
    booktitle={2021 IEEE Global Communications Conference (GLOBECOM)},   
    title={Load Balancing and Handover Optimization in Multi-band Networks using Deep Reinforcement Learning},  
    year={2021},  
    volume={}, 
    number={}, 
    pages={1-6}, 
    doi={10.1109/GLOBECOM46510.2021.9685781}}
    
@misc{wikipedia-contributors-2022,
	author={{Wikipedia contributors}},
	month={03},
	title={{Pearson correlation coefficient}},
	url={https://en.wikipedia.org/wiki/Pearson\_correlation\_coefficient},
	year={2022},
}
@INPROCEEDINGS{mujoco,
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={MuJoCo: A physics engine for model-based control}, 
  year={2012},
  volume={},
  number={},
  pages={5026-5033},
  doi={10.1109/IROS.2012.6386109}}

@INPROCEEDINGS{Li2022clusteringRL,
    author={Li, Jimmy and Wu, Di and Xu, Yi Tian, Li, Tiyanu and Jang, Seowoo and Liu, Xue and Dudek, Gregory },
    booktitle={2022 IEEE International Conference on Communications},
    title={Traffic Scenario Clustering and load balancing with distilled reinforcement learning policies},
    year={2022},}
    
@INPROCEEDINGS{YangAdaptiveRule2012, 
    author={Yang, Ying and Li, Pengfei and Chen, Xiaohui and Wang, Weidong},  booktitle={2012 IEEE Vehicular Technology Conference (VTC Fall)},   
    title={A High-Efficient Algorithm of Mobile Load Balancing in LTE System},   year={2012},  volume={},  number={},  pages={1-5},  doi={10.1109/VTCFall.2012.6398873}}
    
@inproceedings{nairRectifiedLinearUnits2010,
  title = {Rectified Linear Units Improve Restricted Boltzmann Machines},
  booktitle = {ICML},
  author = {Nair, Vinod and Hinton, Geoffrey E.},
  year = {2010},
  month = jun,
  pages = {807--814},
  publisher = {{Omnipress}},
  address = {{Madison, WI, USA}},
  isbn = {978-1-60558-907-7},
}

@misc{yahoo,
  title = {{Yahoo News} global traffic},
  howpublished = {\url{https://yhoo.it/3vT1DEC}},
  note = {Accessed: 2022-04-20}
}
@INPROCEEDINGS{kangHierarchy2021,
  author={Kang, Jikun and Chen, Xi and Wu, Di and Xu, Yi Tian and Liu, Xue and Dudek, Gregory and Lee, Taeseop and Park, Intaik},
  booktitle={IEEE International Conference on Communications}, 
  title={Hierarchical Policy Learning for Hybrid Communication Load Balancing}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ICC42927.2021.9500379}}

@inproceedings{fang2021maximum,
  title={A Maximum Entropy Inverse Reinforcement Learning Algorithm for Automatic Parking},
  author={Fang, Peiyuan and Yu, Zhuoping and Xiong, Lu and Fu, Zhiqiang and Li, Zhuoren and Zeng, Dequan},
  booktitle={2021 5th CAA International Conference on Vehicular Control and Intelligence (CVCI)},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@INPROCEEDINGS{zhang2022,  
   author={Zhang, Ruichen and Xiong, Ke and Tian, Xingcong and Lu, Yang and Fan, Pingyi and Letaief, Khaled Ben},  
   booktitle={IEEE INFOCOM 2022 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)},   
   title={Inverse Reinforcement Learning Meets Power Allocation in Multi-user Cellular Networks},   
   year={2022},  
   volume={},  
   number={},  
   pages={1-2},  
   }
   
   
@article{feriani2022multiobjective,
  title={Multiobjective load balancing for multiband downlink cellular networks: A meta-reinforcement learning approach},
  author={Feriani, Amal and Wu, Di and Xu, Yi Tian and Li, Jimmy and Jang, Seowoo and Hossain, Ekram and Liu, Xue and Dudek, Gregory},
  journal={IEEE Journal on Selected Areas in Communications},
  volume={40},
  number={9},
  pages={2614--2629},
  year={2022},
  publisher={IEEE}
}
@inproceedings{ma2022coordinated,
  title={Coordinated Load Balancing in Mobile Edge Computing Network: a Multi-Agent DRL Approach},
  author={Ma, Manyou and Wu, Di and Xu, Yi Tian and Li, Jimmy and Jang, Seowoo and Liu, Xue and Dudek, Gregory},
  booktitle={ICC 2022-IEEE International Conference on Communications},
  pages={619--624},
  year={2022},
  organization={IEEE}
}

@inproceedings{kang2021hierarchical,
  title={Hierarchical policy learning for hybrid communication load balancing},
  author={Kang, Jikun and Chen, Xi and Wu, Di and Xu, Yi Tian and Liu, Xue and Dudek, Gregory and Lee, Taeseop and Park, Intaik},
  booktitle={ICC 2021-IEEE International Conference on Communications},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@inproceedings{li2022traffic,
  title={Traffic scenario clustering and load balancing with distilled reinforcement learning policies},
  author={Li, Jimmy and Wu, Di and Xu, Yi Tian and Li, Tianyu and Jang, Seowoo and Liu, Xue and Dudek, Gregory},
  booktitle={ICC 2022-IEEE International Conference on Communications},
  pages={1536--1541},
  year={2022},
  organization={IEEE}
}

@article{zhang2022metaems,
  title={MetaEMS: A Meta Reinforcement Learning-based Control Framework for Building Energy Management System},
  author={Zhang, Huiliang and Wu, Di and Boulet, Benoit},
  journal={arXiv preprint arXiv:2210.12590},
  year={2022}
}



@book{wu2018machine,
  title={Machine learning algorithms and applications for sustainable smart grid},
  author={Wu, Di},
  year={2018},
  publisher={McGill University (Canada)}
}

@article{huang2021modellight,
  title={Modellight: Model-based meta-reinforcement learning for traffic signal control},
  author={Huang, Xingshuai and Wu, Di and Jenkin, Michael and Boulet, Benoit},
  journal={arXiv preprint arXiv:2111.08067},
  year={2021}
}

@inproceedings{fucloser,
  title={A Closer Look at Offline RL Agents},
  author={Fu, Yuwei and Wu, Di and Boulet, Benoit},
  booktitle={Advances in Neural Information Processing Systems}
}

@inproceedings{fu2022reinforcement,
  title={Reinforcement learning based dynamic model combination for time series forecasting},
  author={Fu, Yuwei and Wu, Di and Boulet, Benoit},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={6},
  pages={6639--6647},
  year={2022}
}