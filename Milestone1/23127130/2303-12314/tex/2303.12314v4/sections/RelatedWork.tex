\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/main.pdf}
    \caption{The framework of SUPMER. We employ task interpolation to enrich the distribution of self-supervised meta-training tasks. Concurrently, we integrate a meta-gradient regularization function into meta-prompt learning. Furthermore, during meta-prompt learning we also dynamically adapt the mixing ratio of task interpolation, upgrading the vanilla task augmentation into a curriculum-based one.}
    \label{fig:main}
    \vspace{-1.3em}
\end{figure*}

\section{Related Work}
\paragraph{Soft Prompt Tuning.} Soft prompt tuning is one of the most parameter-efficient tuning methods widely used in NLP~\citep{liu2023pre} and vision-language tasks~\citep{zhou2022learning, li2023gradient}, which only tunes a small number of (extra) parameters to attain strong performance. Specifically, it freezes the PLM parameters and prepends some trainable continuous embeddings (\textit{i.e.}, soft prompts) to the input sequence~\citep{prompt_tuning} or every layer of the pre-trained model~\citep{prefix_tuning, ptuning-v2}. 

To efficiently train task-adaptive soft prompts in few-shot scenarios, some studies~\citep{spot, attempt, mp2} employ task adaptation techniques, obtaining source prompts from source tasks in a supervised way and interpolating them into the target prompts. Other works focus on training improved prompt initializations. PPT~\citep{ppt} pre-trains the soft prompts with some self-supervised tasks on unlabeled corpora, but it doesn't explicitly optimize the fast adaptation ability of the model. MetaPrompting\citep{metaprompting} utilizes supervised meta-learning for soft prompt initialization, splitting each dataset into two sets with disjoint data classes. One split is used to initialize soft prompts while the other serves as the downstream task. In comparison, SUPMER differs from MetaPrompting in the following ways: 1) for each downstream task MetaPrompting focuses on a fixed supervised dataset to reinitialize soft prompts, whereas SUPMER can universally generalize to different unseen tasks with large-scale unlabeled corpora for initialization; 2) MetaPrompting doesn't freeze PLM parameters, while SUPMER only tunes the soft prompts as the general soft prompt tuning methods do.


\paragraph{Meta-Learning.} Meta-learning, also known as learning to learn, optimizes the ability to learn new tasks quickly and efficiently, utilizing experience from previously seen tasks. It can be classified into three types: metric-based methods~\citep{siamese, matching_networks, prototypical}, model-based methods~\citep{neural_turing, meta_learner, img_recog}, and gradient-based methods~\citep{learning_to_learn, opt_model_fewshot, reptile, li2020unsupervised}. In this work, we focus on a gradient-based meta-learning algorithm (\textit{i.e.}, MAML~\citealp{maml}). Compared to typical meta-learning methods that rely on human-annotated meta-training tasks, we automatically generate abundant tasks in a self-supervised way, also integrating a meta-gradient regularization function into MAML to steer gradients towards a domain-generalizable direction.
