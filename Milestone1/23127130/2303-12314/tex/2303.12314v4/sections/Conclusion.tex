\section{Conclusion}

In this paper, we present SUPMER, a self-supervised meta-prompt learning framework with meta-gradient regularization. With a diverse set of well-designed self-supervised meta-training tasks, SUPMER jointly meta-learns a universal prompt initialization and an effective gradient regularization function for efficient few-shot generalization. Extensive experiments on few-shot learning and domain generalization show that ~{SUPMER} outperforms other prompt methods and full-model tuning, achieving state-of-the-art performance. 