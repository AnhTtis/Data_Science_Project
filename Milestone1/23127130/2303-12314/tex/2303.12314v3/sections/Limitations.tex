\section*{Limitations}

Although SUPMER performs superbly in a variety of problem scenarios, there still exist some limitations in our work: 1) Our experiments are solely conducted on English tasks, and also do not involve some kinds of NLP tasks such as language generation. 2) In this work, we mainly propose SUPMER to enhance prompt tuning. In fact, SUPMER is a model-agnostic framework with the potential for application in diverse problem scenarios using a plug-and-play fashion, not limited to just soft prompt initialization. And we have not yet conducted an extensive exploration into this aspect in our paper.

To address these limitations, in the future we plan to evaluate the few-shot performance of our framework in the multilingual setting and also broaden the scope of tasks, including language generation and relation extraction. Besides, we intend to explore the integration of SUPMER in other problem scenarios. For instance, we think SUPMER can also effectively synergize with instruction tuning, realizing fast adaption and mitigating overfitting. Furthermore, we hope our work could pave the way for future research on better leveraging parameter-efficient methods under few-shot settings. 
