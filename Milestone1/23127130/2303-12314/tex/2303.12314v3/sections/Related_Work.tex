\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/main.pdf}
    \caption{The framework of SUPMER. We make curriculum-based task augmentation to enrich self-supervised meta task distribution. And we integrate a meta-gradient regularization method into meta-prompt learning.}
    \label{fig:main}
    \vspace{-1em}
\end{figure*}

\section{Related Work}
\paragraph{Soft Prompt Tuning.} Soft prompt tuning is a kind of parameter-efficient tuning method (e.g., Adapter~\citealp{adapter1, adapter2}, prompt tuning~\citealp{prompt_tuning}), which only tunes a small number of (extra) parameters to attain strong performance. Specifically, Prefix-tuning~\citep{prefix_tuning} freezes the model parameters and tunes the prefix activations prepended to each layer in the encoder stack. Prompt tuning~\citep{prompt_tuning} and P-tuning~\citep{ptuning} insert some trainable continuous prompts to the input sequence, and only update these continuous prompts during training. Further, \citet{ptuning-v2} optimizes the original prompt tuning by applying continuous prompts for every layer of the pre-trained model, instead of the mere input layer.

However, soft prompts heavily rely on good initialization to take effect, especially under few-shot settings. PPT~\citep{ppt} pre-trains the soft prompts with some self-supervised tasks on large-scale unlabeled corpora, but it doesn't explicitly optimize the fast adaptation ability of the model. MetaPrompting\citep{metaprompting} utilizes supervised meta-learning for soft prompt initialization. It splits each dataset into disjoint sets according to the data classes so that no class spans two splits. One split is used to initialize soft prompts while another is considered as the downstream task. Our SUPMER compares to MetaPrompting with the following differences: 1) for each downstream task MetaPrompting focuses on a fixed supervised dataset to reinitialize soft prompts. In contrast, SUPMER leverages large-scale unlabeled corpora for prompt initialization and can efficiently generalize to different unseen downstream tasks. 2) MetaPrompting doesn't freeze PLM parameters, while SUPMER only tunes the soft prompts as the general soft prompt tuning methods do.

\paragraph{Meta-Learning.} Meta-learning, also known as learning to learn, optimizes the ability to learn new tasks quickly and efficiently, utilizing experience from previously seen tasks. It can be classified into three types: metric-based methods~\citep{matching_networks, prototypical}, model-based methods~\citep{neural_turing, meta_learner}, and gradient-based methods~\citep{learning_to_learn, opt_model_fewshot, maml, reptile}. In this work, we focus on a gradient-based meta-learning algorithm (i.e., MAML~\citealp{maml}). And our method mainly has two differences from the original algorithm: 1) typical meta-learning assumes access to a set of supervised meta-training tasks while we automatically generate abundant tasks in a self-supervised way. 2) We also integrate a meta-gradient regularization method into MAML to alleviate the problem that typical meta-learning may easily result in overfitting under few-shot settings.
