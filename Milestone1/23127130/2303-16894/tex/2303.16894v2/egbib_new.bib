
@inproceedings{achlioptas2020referit3d,
  title={Referit3d: Neural listeners for fine-grained 3d object identification in real-world scenes},
  author={Achlioptas, Panos and Abdelreheem, Ahmed and Xia, Fei and Elhoseiny, Mohamed and Guibas, Leonidas},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part I 16},
  pages={422--440},
  year={2020},
  organization={Springer}
}

@inproceedings{chen2020scanrefer,
  title={Scanrefer: 3d object localization in rgb-d scans using natural language},
  author={Chen, Dave Zhenyu and Chang, Angel X and Nie{\ss}ner, Matthias},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XX},
  pages={202--221},
  year={2020},
  organization={Springer}
}

@inproceedings{dai2017scannet,
  title={Scannet: Richly-annotated 3d reconstructions of indoor scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5828--5839},
  year={2017}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{feng2021free,
  title={Free-form description guided 3d visual graph network for object grounding in point cloud},
  author={Feng, Mingtao and Li, Zhen and Li, Qi and Zhang, Liang and Zhang, XiangDong and Zhu, Guangming and Zhang, Hui and Wang, Yaonan and Mian, Ajmal},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3722--3731},
  year={2021}
}

@inproceedings{he2021transrefer3d,
  title={Transrefer3d: Entity-and-relation aware transformer for fine-grained 3d visual grounding},
  author={He, Dailan and Zhao, Yusheng and Luo, Junyu and Hui, Tianrui and Huang, Shaofei and Zhang, Aixi and Liu, Si},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={2344--2352},
  year={2021}
}

@inproceedings{liu2019learning,
  title={Learning to assemble neural module tree networks for visual grounding},
  author={Liu, Daqing and Zhang, Hanwang and Wu, Feng and Zha, Zheng-Jun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4673--4682},
  year={2019}
}

@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{roh2022languagerefer,
  title={Languagerefer: Spatial-language model for 3d visual grounding},
  author={Roh, Junha and Desingh, Karthik and Farhadi, Ali and Fox, Dieter},
  booktitle={Conference on Robot Learning},
  pages={1046--1056},
  year={2022},
  organization={PMLR}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{yang2021sat,
  title={Sat: 2d semantics assisted training for 3d visual grounding},
  author={Yang, Zhengyuan and Zhang, Songyang and Wang, Liwei and Luo, Jiebo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1856--1866},
  year={2021}
}

@inproceedings{yuan2021instancerefer,
  title={Instancerefer: Cooperative holistic understanding for visual grounding on point clouds through instance multi-level contextual referring},
  author={Yuan, Zhihao and Yan, Xu and Liao, Yinghong and Zhang, Ruimao and Wang, Sheng and Li, Zhen and Cui, Shuguang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1791--1800},
  year={2021}
}

@inproceedings{zhao20213dvg,
  title={3DVG-Transformer: Relation modeling for visual grounding on point clouds},
  author={Zhao, Lichen and Cai, Daigang and Sheng, Lu and Xu, Dong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2928--2937},
  year={2021}
}

@inproceedings{huang2022multi,
  title={Multi-view transformer for 3d visual grounding},
  author={Huang, Shijia and Chen, Yilun and Jia, Jiaya and Wang, Liwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15524--15533},
  year={2022}
}

@inproceedings{luo20223d,
  title={3d-sps: Single-stage 3d visual grounding via referred point progressive selection},
  author={Luo, Junyu and Fu, Jiahui and Kong, Xianghao and Gao, Chen and Ren, Haibing and Shen, Hao and Xia, Huaxia and Liu, Si},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16454--16463},
  year={2022}
}

@inproceedings{kamath2021mdetr,
  title={Mdetr-modulated detection for end-to-end multi-modal understanding},
  author={Kamath, Aishwarya and Singh, Mannat and LeCun, Yann and Synnaeve, Gabriel and Misra, Ishan and Carion, Nicolas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1780--1790},
  year={2021}
}

@inproceedings{yang2019fast,
  title={A fast and accurate one-stage approach to visual grounding},
  author={Yang, Zhengyuan and Gong, Boqing and Wang, Liwei and Huang, Wenbing and Yu, Dong and Luo, Jiebo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4683--4693},
  year={2019}
}

@inproceedings{zhu2020vision,
  title={Vision-language navigation with self-supervised auxiliary reasoning tasks},
  author={Zhu, Fengda and Zhu, Yi and Chang, Xiaojun and Liang, Xiaodan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10012--10022},
  year={2020}
}

@inproceedings{wang2019reinforced,
  title={Reinforced cross-modal matching and self-supervised imitation learning for vision-language navigation},
  author={Wang, Xin and Huang, Qiuyuan and Celikyilmaz, Asli and Gao, Jianfeng and Shen, Dinghan and Wang, Yuan-Fang and Wang, William Yang and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6629--6638},
  year={2019}
}

@inproceedings{savva2019habitat,
  title={Habitat: A platform for embodied ai research},
  author={Savva, Manolis and Kadian, Abhishek and Maksymets, Oleksandr and Zhao, Yili and Wijmans, Erik and Jain, Bhavana and Straub, Julian and Liu, Jia and Koltun, Vladlen and Malik, Jitendra and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9339--9347},
  year={2019}
}

@article{duan2022survey,
  title={A survey of embodied ai: From simulators to research tasks},
  author={Duan, Jiafei and Yu, Samson and Tan, Hui Li and Zhu, Hongyuan and Tan, Cheston},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence},
  volume={6},
  number={2},
  pages={230--244},
  year={2022},
  publisher={IEEE}
}

@inproceedings{hausler2021patch,
  title={Patch-netvlad: Multi-scale fusion of locally-global descriptors for place recognition},
  author={Hausler, Stephen and Garg, Sourav and Xu, Ming and Milford, Michael and Fischer, Tobias},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14141--14152},
  year={2021}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{kirillov2019panoptic,
  title={Panoptic segmentation},
  author={Kirillov, Alexander and He, Kaiming and Girshick, Ross and Rother, Carsten and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9404--9413},
  year={2019}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@inproceedings{tgnn,
  title={Text-guided graph neural networks for referring 3d instance segmentation},
  author={Huang, Pin-Hao and Lee, Han-Hung and Chen, Hwann-Tzong and Liu, Tyng-Luh},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={2},
  pages={1610--1618},
  year={2021}
}

@inproceedings{jiang2020pointgroup,
  title={Pointgroup: Dual-set point grouping for 3d instance segmentation},
  author={Jiang, Li and Zhao, Hengshuang and Shi, Shaoshuai and Liu, Shu and Fu, Chi-Wing and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and Pattern recognition},
  pages={4867--4876},
  year={2020}
}
@inproceedings{feng2021free,
  title={Free-form description guided 3d visual graph network for object grounding in point cloud},
  author={Feng, Mingtao and Li, Zhen and Li, Qi and Zhang, Liang and Zhang, XiangDong and Zhu, Guangming and Zhang, Hui and Wang, Yaonan and Mian, Ajmal},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3722--3731},
  year={2021}
}

@inproceedings{su2015multi,
  title={Multi-view convolutional neural networks for 3d shape recognition},
  author={Su, Hang and Maji, Subhransu and Kalogerakis, Evangelos and Learned-Miller, Erik},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={945--953},
  year={2015}
}

@inproceedings{brazil2019m3d,
  title={M3d-rpn: Monocular 3d region proposal network for object detection},
  author={Brazil, Garrick and Liu, Xiaoming},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9287--9296},
  year={2019}
}

@inproceedings{shi2019pointrcnn,
  title={Pointrcnn: 3d object proposal generation and detection from point cloud},
  author={Shi, Shaoshuai and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={770--779},
  year={2019}
}

@inproceedings{goyal2021revisiting,
  title={Revisiting point cloud shape classification with a simple and effective baseline},
  author={Goyal, Ankit and Law, Hei and Liu, Bowei and Newell, Alejandro and Deng, Jia},
  booktitle={International Conference on Machine Learning},
  pages={3809--3820},
  year={2021},
  organization={PMLR}
}
@inproceedings{zhang2022pointclip,
  title={Pointclip: Point cloud understanding by clip},
  author={Zhang, Renrui and Guo, Ziyu and Zhang, Wei and Li, Kunchang and Miao, Xupeng and Cui, Bin and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8552--8562},
  year={2022}
}

@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{yu2021vector,
  title={Vector-quantized image modeling with improved VQGAN},
  author={Yu, Jiahui and Li, Xin and Koh, Jing Yu and Zhang, Han and Pang, Ruoming and Qin, James and Ku, Alexander and Xu, Yuanzhong and Baldridge, Jason and Wu, Yonghui},
  journal={arXiv preprint arXiv:2110.04627},
  year={2021}
}

@article{tan2019lxmert,
  title={Lxmert: Learning cross-modality encoder representations from transformers},
  author={Tan, Hao and Bansal, Mohit},
  journal={arXiv preprint arXiv:1908.07490},
  year={2019}
}

@article{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}
@article{gao2021clip,
  title={Clip-adapter: Better vision-language models with feature adapters},
  author={Gao, Peng and Geng, Shijie and Zhang, Renrui and Ma, Teli and Fang, Rongyao and Zhang, Yongfeng and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2110.04544},
  year={2021}
}
@inproceedings{zhang2022tip,
  title={Tip-adapter: Training-free adaption of clip for few-shot classification},
  author={Zhang, Renrui and Zhang, Wei and Fang, Rongyao and Gao, Peng and Li, Kunchang and Dai, Jifeng and Qiao, Yu and Li, Hongsheng},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXV},
  pages={493--510},
  year={2022},
  organization={Springer}
}
@article{coop,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={arXiv preprint arXiv:2109.01134},
  year={2021}
}
@inproceedings{cocoop,
  title={Conditional prompt learning for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16816--16825},
  year={2022}
}
@inproceedings{lin2022frozen,
  title={Frozen clip models are efficient video learners},
  author={Lin, Ziyi and Geng, Shijie and Zhang, Renrui and Gao, Peng and de Melo, Gerard and Wang, Xiaogang and Dai, Jifeng and Qiao, Yu and Li, Hongsheng},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXV},
  pages={388--404},
  year={2022},
  organization={Springer}
}
@article{guo2022calip,
  title={Calip: Zero-shot enhancement of clip with parameter-free attention},
  author={Guo, Ziyu and Zhang, Renrui and Qiu, Longtian and Ma, Xianzheng and Miao, Xupeng and He, Xuming and Cui, Bin},
  journal={arXiv preprint arXiv:2209.14169},
  year={2022}
}
@inproceedings{zhang2022can,
  title={Can Language Understand Depth?},
  author={Zhang, Renrui and Zeng, Ziyao and Guo, Ziyu and Li, Yafeng},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={6868--6874},
  year={2022}
}
@article{qiu2021vt,
  title={Vt-clip: Enhancing vision-language models with visual-guided texts},
  author={Qiu, Longtian and Zhang, Renrui and Guo, Ziyu and Zeng, Ziyao and Li, Yafeng and Zhang, Guangnan},
  journal={arXiv preprint arXiv:2112.02399},
  year={2021}
}
@article{zhu2022pointclip,
  title={PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning},
  author={Zhu, Xiangyang and Zhang, Renrui and He, Bowei and Zeng, Ziyao and Zhang, Shanghang and Gao, Peng},
  journal={arXiv preprint arXiv:2211.11682},
  year={2022}
}
@article{wu2022eda,
  title={EDA: Explicit Text-Decoupling and Dense Alignment for 3D Visual and Language Learning},
  author={Wu, Yanmin and Cheng, Xinhua and Zhang, Renrui and Cheng, Zesen and Zhang, Jian},
  journal={arXiv preprint arXiv:2209.14941},
  year={2022}
}
@article{zhang2022collaboration,
  title={Collaboration of Pre-trained Models Makes Better Few-shot Learner},
  author={Zhang, Renrui and Deng, Hanqiu and Li, Bohao and Zhang, Wei and Dong, Hao and Li, Hongsheng and Gao, Peng and Qiao, Yu},
  journal={arXiv preprint arXiv:2209.12255},
  year={2022}
}

@inproceedings{afham2022crosspoint,
  title={Crosspoint: Self-supervised cross-modal contrastive learning for 3d point cloud understanding},
  author={Afham, Mohamed and Dissanayake, Isuru and Dissanayake, Dinithi and Dharmasiri, Amaya and Thilakarathna, Kanchana and Rodrigo, Ranga},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9902--9912},
  year={2022}
}
@article{zhang2023prompt,
  title={Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners},
  author={Zhang, Renrui and Hu, Xiangfei and Li, Bohao and Huang, Siyuan and Deng, Hanqiu and Li, Hongsheng and Qiao, Yu and Gao, Peng},
  journal={arXiv preprint arXiv:2303.02151},
  year={2023}
}
@article{xu2021image2point,
  title={Image2Point: 3D Point-Cloud Understanding with 2D Image Pretrained Models},
  author={Xu, Chenfeng and Yang, Shijia and Galanti, Tomer and Wu, Bichen and Yue, Xiangyu and Zhai, Bohan and Zhan, Wei and Vajda, Peter and Keutzer, Kurt and Tomizuka, Masayoshi},
  journal={arXiv preprint arXiv:2106.04180},
  year={2021}
}
@article{zhang2021dspoint,
  title={DSPoint: Dual-scale point cloud recognition with high-frequency fusion},
  author={Zhang, Renrui and Zeng, Ziyao and Guo, Ziyu and Gao, Xinben and Fu, Kexue and Shi, Jianbo},
  journal={arXiv preprint arXiv:2111.10332},
  year={2021}
}

@article{chen2023pimae,
  title={PiMAE: Point Cloud and Image Interactive Masked Autoencoders for 3D Object Detection},
  author={Chen, Anthony and Zhang, Kevin and Zhang, Renrui and Wang, Zihan and Lu, Yuheng and Guo, Yandong and Zhang, Shanghang},
  journal={arXiv preprint arXiv:2303.08129},
  year={2023}
}
@article{zhang2022learning,
  title={Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders},
  author={Zhang, Renrui and Wang, Liuhui and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  journal={arXiv preprint arXiv:2212.06785},
  year={2022}
}
@article{guo2023joint,
  title={Joint-mae: 2d-3d joint masked autoencoders for 3d point cloud pre-training},
  author={Guo, Ziyu and Li, Xianzhi and Heng, Pheng Ann},
  journal={arXiv preprint arXiv:2302.14007},
  year={2023}
}
@inproceedings{zhang2021self,
  title={Self-supervised pretraining of 3d features on any point-cloud},
  author={Zhang, Zaiwei and Girdhar, Rohit and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10252--10263},
  year={2021}
}
@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

@article{zhang2023parameter,
  title={Parameter is Not All You Need: Starting from Non-Parametric Networks for 3D Point Cloud Analysis},
  author={Zhang, Renrui and Wang, Liuhui and Wang, Yali and Gao, Peng and Li, Hongsheng and Shi, Jianbo},
  journal={arXiv preprint arXiv:2303.08134},
  year={2023}
}
@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={652--660},
  year={2017}
}
@article{zhang2022point,
  title={Point-M2AE: multi-scale masked autoencoders for hierarchical point cloud pre-training},
  author={Zhang, Renrui and Guo, Ziyu and Gao, Peng and Fang, Rongyao and Zhao, Bin and Wang, Dong and Qiao, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2205.14401},
  year={2022}
}
@article{huang2022tig,
  title={TiG-BEV: Multi-view BEV 3D Object Detection via Target Inner-Geometry Learning},
  author={Huang, Peixiang and Liu, Li and Zhang, Renrui and Zhang, Song and Xu, Xinli and Wang, Baichao and Liu, Guoyi},
  journal={arXiv preprint arXiv:2212.13979},
  year={2022}
}
@inproceedings{hong2022cross,
  title={Cross-Modality Knowledge Distillation Network for Monocular 3D Object Detection},
  author={Hong, Yu and Dai, Hang and Ding, Yong},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part X},
  pages={87--104},
  year={2022},
  organization={Springer}
}
@inproceedings{wang2022detr3d,
  title={Detr3d: 3d object detection from multi-view images via 3d-to-2d queries},
  author={Wang, Yue and Guizilini, Vitor Campagnolo and Zhang, Tianyuan and Wang, Yilun and Zhao, Hang and Solomon, Justin},
  booktitle={Conference on Robot Learning},
  pages={180--191},
  year={2022},
  organization={PMLR}
}
@inproceedings{liu2022petr,
  title={Petr: Position embedding transformation for multi-view 3d object detection},
  author={Liu, Yingfei and Wang, Tiancai and Zhang, Xiangyu and Sun, Jian},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXVII},
  pages={531--548},
  year={2022},
  organization={Springer}
}
@inproceedings{zhang2023nearest,
  title={Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis},
  author={Zhang, Renrui and Wang, Liuhui and Guo, Ziyu and Shi, Jianbo},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1246--1255},
  year={2023}
}
@article{ape,
  title={Not All Features Matter: Enhancing Few-shot CLIP with Adaptive Prior Refinement},
  author={Zhu, Xiangyang and Zhang, Renrui and He, Bowei and Zhou, Aojun and Wang, Dong and Zhao, Bin and Gao, Peng},
  journal={arXiv preprint arXiv:2304.01195},
  year={2023}
}