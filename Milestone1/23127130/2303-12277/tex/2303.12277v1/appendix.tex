
\section{Extension to Arbitrary Norms\label{sec:general-norm}}

In this section, we relax $\ell_{2}$ norm used in the previous assumptions
(see Section \ref{sec:Preliminaries}) to an arbitrary norm $\|\cdot\|$
on $\R^{d}$. $\|\cdot\|_{*}$ denotes the dual norm of $\|\cdot\|$
induced by $\langle\cdot,\cdot\rangle$. Additionally, let $\psi$
be a differentiable and $1$-strongly convex function with respect
to $\|\cdot\|$ on $\dom$, i.e.,
\[
\psi(x)\geq\psi(y)+\langle\na\psi(y),x-y\rangle+\frac{1}{2}\left\Vert x-y\right\Vert ^{2},\forall x,y\in\dom.
\]
We note that, rigorously speaking, $y$ can only be chosen in $\mathrm{int}(\dom)$.
However, one can think there is $\dom\subseteq\mathrm{int}(\mathrm{dom}(\psi))$
to avoid this potential issue. Now, define the Bregman divergence
with respect to $\psi$ as
\[
D_{\psi}(x,y)=\psi(x)-\psi(y)-\langle\na\psi(y),x-y\rangle.
\]
Note that $D_{\psi}(x,y)\geq\frac{1}{2}\|x-y\|^{2}$ from the $1$-strongly
convexity assumption of $\psi$. In particular $D_{\psi}(x,y)=\frac{\|x-y\|_{2}^{2}}{2}$
when considering $\|\cdot\|=\|\cdot\|_{2}$ as used in the main text
and $\psi(x)=\frac{1}{2}\|x\|_{2}^{2}$.

\subsection{New Assumptions and A Useful Fact}

With the above preparations, we can provide new assumptions under
the general norm.

\textbf{1. Existence of a local minimizer}: $\exists x_{*}\in\argmin_{x\in\dom}F(x)$
satisfying $F(x_{*})>-\infty$.

\textbf{2'. Relatively }$\mu$\textbf{-strongly convex}: $\exists\mu\geq0$
such that $F(x)\geq F(y)+\langle g,x-y\rangle+\mu D_{\psi}(x,y),\forall x,y\in\dom,g\in\pa F(y)$.

\textbf{3'. }$G$\textbf{-Lipschitz}: $\exists G>0$ such that $\|g\|_{*}\leq G,\forall x\in\dom,g\in\pa F(x)$ 

\textbf{4. Unbiased gradient estimator}: We are able to access a history-independent,
unbiased gradient estimator $\hp F(x)$ for any $x\in\dom$. In other
words, $\E[\widehat{\pa}F(x)\vert x]\in\pa F(x),\forall x\in\dom$.

\textbf{5'. Bounded $p$th moment noise}: There exist $p\in(1,2]$
and $\sigma\geq0$ denoting the noise level such that $\E[\|\hp F(x)-\E[\widehat{\pa}F(x)\vert x]\|_{*}^{p}\vert x]\leq\sigma^{p}$.

The concept of relatively strong convexity in Assumption 2' is introduced
in \cite{lu2018relatively}. Note that when $\|\cdot\|=\|\cdot\|_{2}$,
Assumptions 2', 3' and 5' are the same as Assumptions 2, 3 and 5 in
Section \ref{sec:Preliminaries}. Hence, these new assumptions are
more general. Next, we provide a useful fact under Assumptions 1,
2' and 3'. This result can help us to simplify the final bound in
the proof of Theorem \ref{thm:str-prob}.
\begin{fact}
\label{fact:fact}Under Assumption 1, 2' and 3' with $\mu>0$, there
is
\[
\left\Vert x-x_{*}\right\Vert ^{2}\leq2D_{\psi}(x,x_{*})\leq\frac{G^{2}}{\mu^{2}},\forall x\in\dom.
\]
\end{fact}
%
\begin{proof}
Given $x\in\dom$, by assumption 2', for any fixed $g\in\pa F(x)$,
we have
\begin{align*}
F(x_{*})\geq & F(x)+\langle g,x_{*}-x\rangle+\mu D_{\psi}(x_{*},x)\\
\overset{(a)}{\geq} & F(x)-\left\Vert g\right\Vert _{*}\left\Vert x_{*}-x\right\Vert +\mu D_{\psi}(x_{*},x)\\
\overset{(b)}{\geq} & F(x)-\left\Vert g\right\Vert _{*}\left\Vert x_{*}-x\right\Vert +\frac{\mu}{2}\left\Vert x_{*}-x\right\Vert ^{2}\\
\overset{(c)}{\geq} & F(x)-\frac{\left\Vert g\right\Vert _{*}^{2}}{2\mu}\overset{(d)}{\geq}F(x)-\frac{G^{2}}{2\mu}\\
\Rightarrow\frac{G^{2}}{2\mu}\geq & F(x)-F(x_{*})
\end{align*}
where $(a)$ is due to Cauchy-Schwarz inequality; $(b)$ is by $D_{\psi}(x,y)\geq\frac{1}{2}\left\Vert x-y\right\Vert ^{2}$;
$(c)$ is because of Young's inequality; $(d)$ is by Assumption 3'. 

Now by Assumption 2' again, for any fixed $g\in\pa F(x_{*})$, we
have
\begin{align*}
F(x)\geq & F(x_{*})+\langle g,x-x_{*}\rangle+\mu D_{\psi}(x,x_{*})\\
\overset{(e)}{\geq} & F(x_{*})+\mu D_{\psi}(x,x_{*})\overset{(f)}{\geq}F(x_{*})+\frac{\mu}{2}\left\Vert x-x_{*}\right\Vert ^{2}\\
\Rightarrow F(x)-F(x_{*})\geq & \mu D_{\psi}(x,x_{*})
\end{align*}
where $(e)$ is by $\langle g,x-x_{*}\rangle\geq0$ due to $g\in\pa F(x_{*})$
and $x_{*}\in\argmin_{x\in\dom}F(x)$; $(f)$ is by $D_{\psi}(x,y)\geq\frac{1}{2}\left\Vert x-y\right\Vert ^{2}$.

Finally, we know
\[
\frac{\mu}{2}\left\Vert x-x_{*}\right\Vert ^{2}\leq\mu D_{\psi}(x,x_{*})\leq F(x)-F(x_{*})\leq\frac{G^{2}}{2\mu}\Rightarrow\left\Vert x-x_{*}\right\Vert ^{2}\leq2D_{\psi}(x,x_{*})\leq\frac{G^{2}}{\mu^{2}}.
\]
\end{proof}


\subsection{Algorithm with the General Norm}

\begin{algorithm}[h]
\caption{\label{alg:algo-md}Projected Stochastic MD with Clipping}

\textbf{Input}: $x_{1}\in\dom$, $M_{t}>0$, $\eta_{t}>0$.

\textbf{for} $t=1$ \textbf{to} $T$ \textbf{do}

$\quad$$g_{t}=\left(1\land\frac{M_{t}}{\left\Vert \hp F(x_{t})\right\Vert _{*}}\right)\hp F(x_{t})$

$\quad$$x_{t+1}=\argmin_{x\in\dom}\langle g_{t},x-x_{t}\rangle+\frac{1}{\eta_{t}}D_{\psi}(x,x_{t}).$

\textbf{end for}
\end{algorithm}

With the new assumptions, we provide a general version of Algorithm
\ref{alg:algo} as shown in Algorithm \ref{alg:algo-md}, which employs
the mirror descent framework. Note that when $\left\Vert \cdot\right\Vert =\left\Vert \cdot\right\Vert _{2}$
and $\psi(x)=\frac{1}{2}\left\Vert x\right\Vert _{2}^{2}$, Algorithm
\ref{alg:algo-md} is totally the same as Algorithm \ref{alg:algo}.

\subsection{Generalized Lemmas}

In this section, we present the generalized fundamental lemmas used
in the proof. First, recall the notations used in the main text:
\begin{align*}
\Delta_{t}\coloneqq & \Delta_{t}(x_{*});\quad\pa_{t}\coloneqq\E_{t}\left[\hp F(x_{t})\right]\in\pa F(x_{t});\\
\xi_{t}\coloneqq & g_{t}-\pa_{t};\quad\xi_{t}^{u}\coloneqq g_{t}-\E_{t}\left[g_{t}\right];\quad\xi_{t}^{b}=\E_{t}\left[g_{t}\right]-\pa_{t};\\
d_{t}\coloneqq & \left\Vert x_{t}-x_{*}\right\Vert ;\quad D_{t}\coloneqq\max_{s\in\left[t\right]}d_{s};\quad\mathfrak{D}_{t}\coloneqq D_{t}\lor2\alpha;
\end{align*}
where $\F_{t}=\sigma(\hp F(x_{1}),\cdots,\hp F(x_{t}))$ is the natural
filtration. $\E_{t}\left[\cdot\right]$ is used to denote $\E\left[\cdot\mid\F_{t-1}\right]$
for brevity. Now we are able to present the general version of Lemmas
\ref{lem:err-bound}, \ref{lem:basic} and \ref{lem:normalize}, which
play the most important roles in the proof. 

The proof of Lemma \ref{lem:err-bound-general} is by extending the
ideas in \cite{liu2023breaking} to general norms. The modification
appears when bounding the term $\E_{t}\left[\|\xi_{t}^{u}\|_{*}^{2}\right]$.
But the final bound is still in the order of $O(\sigma^{p}M_{t}^{2-p})$.
\begin{lem}
\label{lem:err-bound-general}For any $t\in\left[T\right]$, if $M_{t}\geq2G$,
we have
\begin{align*}
\left\Vert \xi_{t}^{u}\right\Vert _{*} & \le2M_{t};\quad\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}\right]\le\begin{cases}
10\sigma^{p}M_{t}^{2-p} & \text{if }\left\Vert \cdot\right\Vert =\left\Vert \cdot\right\Vert _{2}\\
40\sigma^{p}M_{t}^{2-p} & \text{o.w.}
\end{cases};\\
\left\Vert \xi_{t}^{b}\right\Vert _{*} & \le2\sigma^{p}M_{t}^{1-p};\quad\left\Vert \xi_{t}^{b}\right\Vert _{*}^{2}\leq10\sigma^{p}M_{t}^{2-p}.
\end{align*}
\end{lem}
%
\begin{proof}
First, $\|\xi_{t}^{u}\|_{*}\le2M_{t}$ is always true due to 
\[
\left\Vert \xi_{t}^{u}\right\Vert _{*}=\left\Vert g_{t}-\E_{t}\left[g_{t}\right]\right\Vert _{*}\leq\left\Vert g_{t}\right\Vert _{*}+\left\Vert \E_{t}\left[g_{t}\right]\right\Vert _{*}\leq2M_{t}.
\]

Next, let us prove the bound on $\E_{t}\left[\|\xi_{t}^{u}\|_{*}^{2}\right]$.
Note that if $\left\Vert \cdot\right\Vert $ is the general norm,
we have
\begin{align*}
\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}\right]= & \E_{t}\left[\left\Vert g_{t}-\E_{t}\left[g_{t}\right]\right\Vert _{*}^{2}\right]\leq\E_{t}\left[2\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}+2\left\Vert \pa_{t}-\E_{t}\left[g_{t}\right]\right\Vert _{*}^{2}\right]\\
\leq & \E_{t}\left[2\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}+2\E_{t}\left[\left\Vert \pa_{t}-g_{t}\right\Vert _{*}^{2}\right]\right]=4\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\right].
\end{align*}
If $\left\Vert \cdot\right\Vert =\left\Vert \cdot\right\Vert _{2}$,
then $\left\Vert \cdot\right\Vert _{*}=\left\Vert \cdot\right\Vert _{2}$.
In this case, we know
\begin{align*}
\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert _{2}^{2}\right]= & \E_{t}\left[\left\Vert g_{t}-\E_{t}\left[g_{t}\right]\right\Vert _{2}^{2}\right]\\
= & \E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{2}^{2}+2\langle g_{t}-\pa_{t},\pa_{t}-\E_{t}\left[g_{t}\right]\rangle+\left\Vert \pa_{t}-\E_{t}\left[g_{t}\right]\right\Vert _{2}^{2}\right]\\
= & \E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{2}^{2}\right]-\left\Vert \pa_{t}-\E_{t}\left[g_{t}\right]\right\Vert _{2}^{2}\leq\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{2}^{2}\right].
\end{align*}
Thus, there is
\[
\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}\right]\le\begin{cases}
\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\right] & \text{if }\left\Vert \cdot\right\Vert =\left\Vert \cdot\right\Vert _{2}\\
4\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\right] & \text{o.w.}
\end{cases}.
\]
So our next goal is to bound $\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\right]$
by noticing that
\begin{align}
\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\right]= & \E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}\geq M_{t}}+\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}<M_{t}}\right]\nonumber \\
= & \E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}\geq M_{t}}+\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2-p}\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}<M_{t}}\right]\nonumber \\
\overset{(a)}{\leq} & \E_{t}\left[\frac{9}{4}M_{t}^{2}\indi_{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\geq M_{t}/2}+\left(\frac{9}{4}M_{t}\right)^{2-p}\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}<M_{t}}\right]\nonumber \\
\overset{(b)}{\leq} & \frac{9}{4}M_{t}^{2}\cdot\frac{\sigma^{p}}{\left(M_{t}/2\right)^{p}}+\left(\frac{9}{4}\right)^{2-p}M_{t}^{2-p}\cdot\sigma^{p}\leq10\sigma^{p}M_{t}^{2-p}\label{eq:mid}
\end{align}
where $(a)$ is due to $\left\Vert g_{t}-\pa_{t}\right\Vert _{*}\leq\left\Vert g_{t}\right\Vert _{*}+\left\Vert \pa_{t}\right\Vert _{*}\leq M_{t}+M_{t}/2=3M_{t}/2$;
$(b)$ is by using Markov's inequality to get
\[
\E_{t}\left[\mathds{1}_{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\geq M_{t}/2}\right]=\Pr\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\geq\left(M_{t}/2\right)^{p}\mid\F_{t-1}\right]\leq\frac{\sigma^{p}}{\left(M_{t}/2\right)^{p}}
\]
and by Assumption 5' to obtain
\[
\E_{t}\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}<M_{t}}\right]\leq\E_{t}\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\right]\leq\sigma^{p}.
\]
Hence, we know
\[
\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}\right]\le\begin{cases}
10\sigma^{p}M_{t}^{2-p} & \text{if }\left\Vert \cdot\right\Vert =\left\Vert \cdot\right\Vert _{2}\\
40\sigma^{p}M_{t}^{2-p} & \text{o.w.}
\end{cases}.
\]

Then, we prove $\left\Vert \xi_{t}^{b}\right\Vert _{*}\le2\sigma^{p}M_{t}^{1-p}$
by
\begin{align*}
\left\Vert \xi_{t}^{b}\right\Vert _{*}= & \left\Vert \E_{t}\left[g_{t}\right]-\pa_{t}\right\Vert _{*}=\left\Vert \E_{t}\left[g_{t}-\hp F(x_{t})\right]\right\Vert _{*}\\
\leq & \E_{t}\left[\left\Vert g_{t}-\hp F(x_{t})\right\Vert _{*}\right]=\E_{t}\left[\left\Vert \frac{M_{t}}{\left\Vert \hp F(x_{t})\right\Vert _{*}}\hp F(x_{t})-\hp F(x_{t})\right\Vert _{*}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}\geq M_{t}}\right]\\
= & \E_{t}\left[\left(\left\Vert \hp F(x_{t})\right\Vert _{*}-M_{t}\right)\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}\geq M_{t}}\right]\overset{(c)}{\leq}\E_{t}\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}\geq M_{t}}\right]\\
\overset{(d)}{\leq} & \E_{t}\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\indi_{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\geq M_{t}/2}\right]\overset{(e)}{\leq}\E_{t}\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\cdot\left(\frac{2}{M_{t}}\right)^{p-1}\right]\\
\overset{(f)}{\leq} & 2^{p-1}\sigma^{p}M_{t}^{1-p}\leq2\sigma^{p}M_{t}^{1-p}
\end{align*}
where $(c)$ is due to $\left\Vert \hp F(x_{t})\right\Vert _{*}-M_{t}\leq\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}+\left\Vert \pa_{t}\right\Vert _{*}-M_{t}\leq\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}$
when $M_{t}\geq2G$ and $\left\Vert \pa_{t}\right\Vert _{*}\leq G$;
$(d)$ is by 
\begin{align*}
M_{t}\leq & \left\Vert \hp F(x_{t})\right\Vert _{*}\leq\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}+\left\Vert \pa_{t}\right\Vert _{*}\leq\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}+G\\
\leq & \left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}+M_{t}/2\\
\Rightarrow M_{t}/2\leq & \left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}
\end{align*}
which implies 
\[
\mathds{1}_{\left\Vert \hp F(x_{t})\right\Vert _{*}\geq M_{t}}\leq\mathds{1}_{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\geq M_{t}/2};
\]
$(e)$ is by 
\[
\mathds{1}_{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\geq M_{t}/2}\leq\left(\frac{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}}{M_{t}/2}\right)^{p-1}\indi_{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\geq M_{t}/2}\leq\left(\frac{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}}{M_{t}/2}\right)^{p-1};
\]
$(f)$ is due to the new Assumption 5', i.e., $\E_{t}\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\right]\leq\sigma^{p}$.

Finally, we show $\left\Vert \xi_{t}^{b}\right\Vert _{*}^{2}\leq10\sigma^{p}M_{t}^{2-p}$.
Note that
\[
\left\Vert \xi_{t}^{b}\right\Vert _{*}^{2}=\left\Vert \E_{t}\left[g_{t}\right]-\pa_{t}\right\Vert _{*}^{2}\leq\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\right]\leq10\sigma^{p}M_{t}^{2-p}
\]
where the last step is by (\ref{eq:mid}).
\end{proof}

Next, we inroduce Lemma \ref{lem:basic-general}, which will degenerate
to Lemma \ref{lem:basic} when $\|\cdot\|=\|\cdot\|_{2}$ and $\psi(x)=\frac{1}{2}\|x\|_{2}^{2}$. 
\begin{lem}
\label{lem:basic-general}For any $t\in\left[T\right]$, we have
\[
\Delta_{t}+\eta_{t}^{-1}D_{\psi}\left(x_{*},x_{t+1}\right)-\left(\eta_{t}^{-1}-\mu\right)D_{\psi}\left(x_{*},x_{t}\right)\leq\langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}+2\left\Vert \xi_{t}^{b}\right\Vert _{*}^{2}+G^{2}\right).
\]
\end{lem}
%
\begin{proof}
We start with the relative $\mu$-stronogly convexity assumption
\begin{align*}
\Delta_{t}\leq & \langle\pa_{t},x_{t}-x_{*}\rangle-\mu D_{\psi}\left(x_{t},x_{*}\right)\\
= & \langle g_{t},x_{t+1}-x_{*}\rangle+\langle g_{t},x_{t}-x_{t+1}\rangle+\langle\xi_{t},x_{*}-x_{t}\rangle-\mu D_{\psi}\left(x_{t},x_{*}\right)\\
\overset{(a)}{\leq} & \left(\eta_{t}^{-1}-\mu\right)D_{\psi}\left(x_{*},x_{t}\right)-\eta_{t}^{-1}D_{\psi}\left(x_{*},x_{t+1}\right)+\langle\xi_{t},x_{*}-x_{t}\rangle\\
 & +\langle g_{t},x_{t}-x_{t+1}\rangle-\eta_{t}^{-1}D_{\psi}\left(x_{t+1},x_{t}\right)\\
\overset{(b)}{\leq} & \left(\eta_{t}^{-1}-\mu\right)D_{\psi}\left(x_{*},x_{t}\right)-\eta_{t}^{-1}D_{\psi}\left(x_{*},x_{t+1}\right)+\langle\xi_{t},x_{*}-x_{t}\rangle\\
 & +\langle g_{t},x_{t}-x_{t+1}\rangle-\frac{\eta_{t}^{-1}}{2}\left\Vert x_{t}-x_{t+1}\right\Vert ^{2}\\
\overset{(c)}{\leq} & \left(\eta_{t}^{-1}-\mu\right)D_{\psi}\left(x_{*},x_{t}\right)-\eta_{t}^{-1}D_{\psi}\left(x_{*},x_{t+1}\right)+\langle\xi_{t},x_{*}-x_{t}\rangle+\frac{\eta_{t}}{2}\left\Vert g_{t}\right\Vert _{*}^{2}\\
\overset{(d)}{\leq} & \left(\eta_{t}^{-1}-\mu\right)D_{\psi}\left(x_{*},x_{t}\right)-\eta_{t}^{-1}D_{\psi}\left(x_{*},x_{t+1}\right)+\langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}+2\left\Vert \xi_{t}^{b}\right\Vert _{*}^{2}+G^{2}\right)
\end{align*}
where for $(a)$, we use the optimality condition for $x_{t+1}=\argmin_{x\in\dom}\langle g_{t},x-x_{t}\rangle+\frac{1}{\eta_{t}}D_{\psi}(x,x_{t})$
to get for any $x\in\dom$
\begin{align*}
\langle g_{t}+\eta_{t}^{-1}\left(\na\psi(x_{t+1})-\na\psi(x_{t})\right),x_{t+1}-x\rangle\leq & 0\\
\Rightarrow\langle g_{t},x_{t+1}-x\rangle\leq & \eta_{t}^{-1}\langle\na\psi(x_{t})-\na\psi(x_{t+1}),x_{t+1}-x\rangle\\
= & \eta_{t}^{-1}\left(D_{\psi}\left(x,x_{t}\right)-D_{\psi}\left(x,x_{t+1}\right)-D_{\psi}\left(x_{t+1},x_{t}\right)\right).
\end{align*}
$(b)$ is by $D_{\psi}\left(x_{t+1},x_{t}\right)\geq\frac{\left\Vert x_{t}-x_{t+1}\right\Vert ^{2}}{2}$.
In $(c)$, we apply Cauchy--Schwarz inequality to get 
\[
\langle g_{t},x_{t}-x_{t+1}\rangle\leq\frac{\eta_{t}^{-1}}{2}\left\Vert x_{t}-x_{t+1}\right\Vert ^{2}+\frac{\eta_{t}}{2}\left\Vert g_{t}\right\Vert _{*}^{2}.
\]
$(d)$ is by $\left\Vert g_{t}\right\Vert _{*}^{2}\leq2\left\Vert \xi_{t}\right\Vert _{*}^{2}+2\left\Vert \pa_{t}\right\Vert _{*}^{2}\leq2\left\Vert \xi_{t}\right\Vert _{*}^{2}+2G^{2}$
and $\left\Vert \xi_{t}\right\Vert _{*}^{2}\leq2\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}+2\left\Vert \xi_{t}^{b}\right\Vert _{*}^{2}$.
After rearranging the terms, we finish the proof.
\end{proof}

The last task is to generalize Lemma \ref{lem:normalize} as shown
in Lemma \ref{lem:normalize-general}.
\begin{lem}
\label{lem:normalize-general}When $\mu=0$, under our choices of
$M_{t}$ and $\eta_{t}$ whenever $T$ is known or not, for any $t\in\left[T\right]$,
we have
\[
\eta_{t}M_{t}\leq2\alpha\text{ and }d_{t}\leq d_{1}+2\alpha(t-1).
\]
\end{lem}
%
\begin{proof}
First, we check that
\begin{itemize}
\item under the choice of $M_{t}=2G\lor\sigma t^{\frac{1}{p}}$ and $\eta_{t}=\frac{\alpha}{\sqrt{\left(G^{2}+\sigma^{2}\right)t}}\land\frac{\alpha}{\sigma t^{\frac{1}{p}}}$,
we have :
\[
\eta_{t}M_{t}\leq\left(\frac{\alpha}{\sqrt{\left(G^{2}+\sigma^{2}\right)t}}\land\frac{\alpha}{\sigma t^{\frac{1}{p}}}\right)\cdot\left(2G\lor\sigma t^{\frac{1}{p}}\right)=2\alpha\lor\alpha=2\alpha.
\]
\item under the choice of $M_{t}=2Gt^{\frac{1}{p}}$ and $\eta_{t}=\frac{\alpha}{Gt^{\frac{1}{p}}}$,
we have :
\[
\eta_{t}M_{t}=\frac{\alpha}{Gt^{\frac{1}{p}}}\cdot2Gt^{\frac{1}{p}}=2\alpha.
\]
\end{itemize}
Note that when replacing $t$ by $T$ in $\eta_{t}$ and $M_{t}$
for the case of known $T$, the above results still hold.

Next, from the the assumption of $\psi$ being $1$-strongly convex
with respect to $\left\Vert \cdot\right\Vert $, we have
\[
\left\Vert x_{t+1}-x_{t}\right\Vert ^{2}\leq\langle\na\psi(x_{t+1})-\psi(x_{t}),x_{t+1}-x_{t}\rangle.
\]
Recall that $x_{t+1}=\argmin_{x\in\dom}\langle g_{t},x-x_{t}\rangle+\frac{1}{\eta_{t}}D_{\psi}(x,x_{t})$.
Hence, by the optimality condition, there is
\begin{align*}
\langle\eta_{t}g_{t}+\na\psi(x_{t+1})-\na\psi(x_{t}),x_{t+1}-x_{t}\rangle & \leq0\\
\Rightarrow\langle\na\psi(x_{t+1})-\na\psi(x_{t}),x_{t+1}-x_{t}\rangle & \leq\langle\eta_{t}g_{t},x_{t}-x_{t+1}\rangle
\end{align*}
which implies
\begin{align*}
\left\Vert x_{t+1}-x_{t}\right\Vert ^{2}\leq & \langle\eta_{t}g_{t},x_{t}-x_{t+1}\rangle\leq\eta_{t}\left\Vert g_{t}\right\Vert _{*}\left\Vert x_{t+1}-x_{t}\right\Vert \\
\leq & \eta_{t}M_{t}\left\Vert x_{t+1}-x_{t}\right\Vert \leq2\alpha\left\Vert x_{t+1}-x_{t}\right\Vert \\
\Rightarrow\left\Vert x_{t+1}-x_{t}\right\Vert \leq & 2\alpha
\end{align*}
where we use $\eta_{t}M_{t}\leq2\alpha$ proved above.

Therefore
\[
d_{t+1}=\left\Vert x_{t+1}-x_{*}\right\Vert \leq\left\Vert x_{t}-x_{*}\right\Vert +\left\Vert x_{t+1}-x_{t}\right\Vert \leq d_{t}+2\alpha
\]
Unrolling this recursion, we get the desired result.
\end{proof}

With the above three lemmas, one can follow almost the same line to
prove the general version of the convergence theorems both in expectation
and probability. We leave this simple extension to the interested
reader and finish this section.

\section{A Technical Tool\label{sec:app-tech}}

In this section, we provide a technical tool, Freedman's inequality,
in Lemma \ref{lem:freedman}, the omitted proof of which can be found
in \cite{bennett1962probability,freedman1975tail,dzhaparidze2001bernstein}.
This famous inequality can help us to quantify the concentration phenomenon
of a bounded martingale difference sequence. 
\begin{lem}
\label{lem:freedman}(Freedman's inequality) Suppose $X_{t\in\left[T\right]}\in\R$
is a martingale difference sequence adapted to the filtration $\F_{t\in\left[T\right]}$
satisfying $\left|X_{t}\right|\leq R$ almost surely for some constant
$R$. Let $\sigma_{t}^{2}=\E\left[\left|X_{t}\right|{}^{2}\mid\F_{t-1}\right]$,
then for any $a>0$ and $F>0$, there is
\[
\Pr\left[\exists\tau\in\left[T\right],\left|\sum_{t=1}^{\tau}X_{t}\right|>a\text{ and }\sum_{t=1}^{\tau}\sigma_{t}^{2}\leq F\right]\leq2\exp\left(-\frac{a^{2}}{2F+2Ra/3}\right).
\]
\end{lem}
%
Next, we provide two simple corollaries of Lemma \ref{lem:freedman},
which are easier to use in the analysis. For example, the high-probability
bound of $\sum_{t=1}^{\tau}\eta_{t}^{2}(\|\xi_{t}^{u}\|^{2}-\E_{t}[\|\xi_{t}^{u}\|^{2}])$
in Lemma \ref{lem:xi-u-lip} is done by Corollary \ref{cor:ez-any-freedman}.
\begin{cor}
\label{cor:ez-any-freedman}Under the same settings in Lemma \ref{lem:freedman}.
If $\sum_{t=1}^{T}\sigma_{t}^{2}\leq F$ with probability $1$, by
choosing $a=\frac{R}{3}\log\frac{4}{\delta}+\sqrt{\left(\frac{1}{3}R\log\frac{4}{\delta}\right)^{2}+2F\log\frac{4}{\delta}}$,
we have
\[
\Pr\left[\forall\tau\in\left[T\right],\left|\sum_{t=1}^{\tau}X_{t}\right|\leq\frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\right]\geq1-\frac{\delta}{2}.
\]
\end{cor}
%
\begin{cor}
\label{cor:ez-freedman}Under the same settings in Lemma \ref{lem:freedman}.
If $\sum_{t=1}^{T}\sigma_{t}^{2}\leq F$ with probability $1$, by
choosing $a=\frac{R}{3}\log\frac{4T}{\delta}+\sqrt{\left(\frac{1}{3}R\log\frac{4T}{\delta}\right)^{2}+2F\log\frac{4T}{\delta}}$,
we have
\[
\Pr\left[\left|\sum_{t=1}^{T}X_{t}\right|\leq\frac{2R}{3}\log\frac{4T}{\delta}+\sqrt{2F\log\frac{4T}{\delta}}\right]\geq1-\frac{\delta}{2T}.
\]
\end{cor}
%

\section{Missing Proofs in Section \ref{sec: analysis}\label{sec:app-missing-proofs}}

In this section, we provide the missing proofs in Section \ref{sec: analysis}.

\subsection{Proof of Lemma \ref{lem:basic-lip-prob}}

\begin{proof}
We first invoke Lemma \ref{lem:basic} for $\mu=0$ to get
\[
\Delta_{t}+\frac{\eta_{t}^{-1}}{2}\left\Vert x_{t+1}-x_{*}\right\Vert ^{2}-\frac{\eta_{t}^{-1}}{2}\left\Vert x_{t}-x_{*}\right\Vert ^{2}\leq\langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right).
\]
Multiplying both sides by $\eta_{t}$, we obtain
\begin{align}
\eta_{t}\Delta_{t}+\frac{\left\Vert x_{t+1}-x_{*}\right\Vert ^{2}-\left\Vert x_{t}-x_{*}\right\Vert ^{2}}{2}\leq & \eta_{t}\langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}^{2}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\nonumber \\
= & \eta_{t}\langle\xi_{t},x_{*}-x_{t}\rangle+2\eta_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\nonumber \\
 & +\eta_{t}^{2}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right).\label{eq:lip-prob-1}
\end{align}
Next, summing up (\ref{eq:lip-prob-1}) from $t=1$ to $\tau$ , there
is
\begin{align*}
\frac{\left\Vert x_{\tau+1}-x_{*}\right\Vert ^{2}-\left\Vert x_{1}-x_{*}\right\Vert ^{2}}{2}+\sum_{t=1}^{\tau}\eta_{t}\Delta_{t}\leq & \sum_{t=1}^{\tau}\eta_{t}\langle\xi_{t},x_{*}-x_{t}\rangle+2\eta_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\\
 & +\sum_{t=1}^{\tau}\eta_{t}^{2}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right).
\end{align*}

Now we bound $\E_{t}[\|\xi_{t}^{u}\|^{2}]\le10\sigma^{p}M_{t}^{2-p}$
and $\|\xi_{t}^{b}\|^{2}\le10\sigma^{p}M_{t}^{2-p}$ by Lemma \ref{lem:err-bound}
to know
\begin{align*}
2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}\leq & 40\sigma^{p}M_{t}^{2-p}.
\end{align*}
Hence, we have
\begin{itemize}
\item under the choice of $M_{t}=2G\lor\sigma t^{\frac{1}{p}}$ and $\eta_{t}=\frac{\alpha}{\sqrt{\left(G^{2}+\sigma^{2}\right)t}}\land\frac{\alpha}{\sigma t^{\frac{1}{p}}}$,
we have
\begin{align*}
2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\leq & 40\sigma^{p}M_{t}^{2-p}+G^{2}\\
\leq & 40\sigma^{p}\left(2^{2-p}G^{2-p}\lor\sigma^{2-p}t^{\frac{2}{p}-1}\right)+G^{2}\\
\leq & 40\cdot2^{2-p}\sigma^{p}G^{2-p}+G^{2}+40\sigma^{2}t^{\frac{2}{p}-1}\\
\leq & 45\left(G^{2}+\sigma^{2}\right)+40\sigma^{2}t^{\frac{2}{p}-1}\\
\Rightarrow\sum_{t=1}^{\tau}\eta_{t}^{2}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\leq & \sum_{t=1}^{\tau}\left(\frac{\alpha^{2}}{\left(G^{2}+\sigma^{2}\right)t}\land\frac{\alpha^{2}}{\sigma^{2}t^{\frac{2}{p}}}\right)\left(45\left(G^{2}+\sigma^{2}\right)+40\sigma^{2}t^{\frac{2}{p}-1}\right)\\
\leq & \sum_{t=1}^{\tau}\frac{95\alpha^{2}}{t}\leq95\alpha^{2}\left(\log\tau+1\right)=h(\tau).
\end{align*}
\item under the choice of $M_{t}=2Gt^{\frac{1}{p}}$ and $\eta_{t}=\frac{\alpha}{Gt^{\frac{1}{p}}}$,
we have
\begin{align*}
2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\leq & 40\sigma^{p}M_{t}^{2-p}+G^{2}\\
\leq & 40\sigma^{p}\cdot2^{2-p}G^{2-p}t^{\frac{2}{p}-1}+G^{2}\\
\leq & 80\sigma^{p}G^{2-p}t^{\frac{2}{p}-1}+G^{2}\\
\Rightarrow\sum_{t=1}^{\tau}\eta_{t}^{2}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\leq & \sum_{t=1}^{\tau}\frac{\alpha^{2}}{G^{2}t^{\frac{2}{p}}}\left(80\sigma^{p}G^{2-p}t^{\frac{2}{p}-1}+G^{2}\right)\\
= & \sum_{t=1}^{\tau}\frac{80\alpha^{2}(\sigma/G)^{p}}{t}+\frac{\alpha^{2}}{t^{\frac{2}{p}}}\\
\leq & \sum_{t=1}^{\tau}\frac{80\left(1+(\sigma/G)^{p}\right)\alpha^{2}}{t}\\
\leq & 80\left(1+(\sigma/G)^{p}\right)\alpha^{2}\left(\log\tau+1\right)=h(\tau).
\end{align*}
\end{itemize}
\end{proof}


\subsection{Proof of Lemma \ref{lem:lip-prob-loglog}}

\begin{proof}
We first define $k_{\max}\coloneqq\left\lfloor \log_{2}(4T)\right\rfloor $
and introduce the following two sequences 
\[
c_{k}\coloneqq2^{k-1}\mathfrak{D}_{1},\forall k\in\left[k_{\max}\right];\quad k_{t}\coloneqq\left\lceil \log_{2}\frac{\mathfrak{D}_{t}}{\mathfrak{D_{1}}}\right\rceil +1,\forall t\in\left[T\right];
\]
Note that $k_{t\in\left[T\right]}$ is an integer-valued non-decreasing
random sequence. Next, observe that
\begin{align*}
k_{T}< & \log_{2}\frac{\mathfrak{D}_{T}}{\mathfrak{D_{1}}}+2=\log_{2}\left(\frac{d_{T}\lor2\alpha}{d_{1}\lor2\alpha}\right)+2\\
\overset{(a)}{\leq} & \log_{2}\left(\frac{\left(d_{1}+2\alpha(T-1)\right)\lor2\alpha}{d_{1}\lor2\alpha}\right)+2\leq\log_{2}(T)+2\\
\Rightarrow k_{T}\leq & k_{\max}.
\end{align*}
where $(a)$ is by Lemma \ref{lem:normalize}. Thus, $k_{t}$ is uniformly
bounded by $k_{\max}$. A useful fact from the definition of $k_{t}$
is that 
\begin{equation}
D_{t}\leq\mathfrak{D}_{t}\leq c_{k_{t}}<2\mathfrak{D}_{t}.\label{eq:binary}
\end{equation}

Given $k\in\left[k_{\max}\right]$, we consider the following sequence
\[
Z_{t}^{k}=\eta_{t}\left\langle \xi_{t}^{u},\Pi_{\mathcal{B}(1)}\left(\frac{x_{*}-x_{t}}{c_{k}}\right)\right\rangle ,\forall t\in\left[T\right]
\]
where $\Pi_{\mathcal{B}(1)}(x)=\frac{x}{1\lor\left\Vert x\right\Vert }$
denotes the projection to the unit ball. First, note that $X_{t}^{k}\in\F_{t}$
is a martingale difference sequence for any $k\in\left[k_{\max}\right]$.
Next, observe that
\begin{align*}
\left|Z_{t}^{k}\right|\leq & \left|\eta_{t}\left\langle \xi_{t}^{u},\Pi_{\mathcal{B}(1)}\left(\frac{x_{*}-x_{t}}{c_{k}}\right)\right\rangle \right|\leq\eta_{t}\left\Vert \xi_{t}^{u}\right\Vert \overset{(b)}{\leq}2\eta_{t}M_{t}\overset{(c)}{\leq}4\alpha;\\
\E_{t}\left[\left(Z_{t}^{k}\right)^{2}\right]= & \E_{t}\left[\eta_{t}^{2}\left\langle \xi_{t}^{u},\Pi_{\mathcal{B}(1)}\left(\frac{x_{*}-x_{t}}{c_{k}}\right)\right\rangle ^{2}\right]\leq\eta_{t}^{2}\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\overset{(d)}{\leq}10\eta_{t}^{2}\sigma^{p}M_{t}^{2-p};
\end{align*}
where $\|\xi_{t}^{u}\|\leq2M_{t}$ in $(b)$ and $\E_{t}[\|\xi_{t}^{u}\|^{2}]\leq10\sigma^{p}M_{t}^{2-p}$
in $(d)$ are both by Lemma \ref{lem:err-bound}; $\eta_{t}M_{t}\leq2\alpha$
in $(c)$ is by Lemma \ref{lem:normalize}.

Now we know
\begin{itemize}
\item under the choice of $M_{t}=2G\lor\sigma t^{\frac{1}{p}}$ and $\eta_{t}=\frac{\alpha}{\sqrt{\left(G^{2}+\sigma^{2}\right)t}}\land\frac{\alpha}{\sigma t^{\frac{1}{p}}}$:
\begin{align*}
10\eta_{t}^{2}\sigma^{p}M_{t}^{2-p}\leq & 10\cdot\left(\frac{\alpha^{2}}{\left(G^{2}+\sigma^{2}\right)t}\land\frac{\alpha^{2}}{\sigma^{2}t^{\frac{2}{p}}}\right)\cdot\left(2^{2-p}\sigma^{p}G^{2-p}\lor\sigma^{2}t^{\frac{2}{p}-1}\right)\leq\frac{20\alpha^{2}}{t}\\
\Rightarrow\sum_{t=1}^{T}\E_{t}\left[\left(Z_{t}^{k}\right)^{2}\right]\leq & \sum_{t=1}^{T}\frac{20\alpha^{2}}{t}\leq20\alpha^{2}\log(eT).
\end{align*}
Let $R=4\alpha$, $F=20\alpha^{2}\log(eT)$. By Freedman's inequality
(Corollary \ref{cor:ez-any-freedman}), we know with probability at
least $1-\frac{\delta}{2}$, for any $\tau\in\left[T\right]$
\begin{align*}
\left|\sum_{t=1}^{\tau}Z_{t}^{k}\right|\leq & \frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\\
= & \frac{8\alpha}{3}\log\frac{4}{\delta}+\sqrt{40\alpha^{2}\log(eT)\log\frac{4}{\delta}}\\
\leq & 7\left(\log\frac{4}{\delta}+\sqrt{\log(eT)\log\frac{4}{\delta}}\right)\alpha.
\end{align*}
We replace $\delta$ by $\frac{\delta}{k_{\max}}$ and apply the union
bound to all $k\in\left[k_{\max}\right]$ to get with probability
at least $1-\frac{\delta}{2}$, there is
\[
\max_{k\in\left[k_{\max}\right]}\left|\sum_{t=1}^{\tau}Z_{t}^{k}\right|\leq7\left(\log\frac{4k_{\max}}{\delta}+\sqrt{\log(eT)\log\frac{4k_{\max}}{\delta}}\right)\alpha,\forall\tau\in\left[T\right].
\]
\item under the choice of $M_{t}=2Gt^{\frac{1}{p}}$ and $\eta_{t}=\frac{\alpha}{Gt^{\frac{1}{p}}}$:
\begin{align*}
10\eta_{t}^{2}\sigma^{p}M_{t}^{2-p}\leq & 10\cdot\frac{\alpha^{2}}{G^{2}t^{\frac{2}{p}}}\cdot2^{2-p}\sigma^{p}G^{2-p}t^{\frac{2}{p}-1}\cdot2K\leq\frac{20(\sigma/G)^{p}\alpha^{2}}{t}\\
\Rightarrow\sum_{t=1}^{T}\E_{t}\left[\left(Z_{t}^{k}\right)^{2}\right]\leq & \sum_{t=1}^{T}\frac{20(\sigma/G)^{p}\alpha^{2}}{t}\leq20(\sigma/G)^{p}\alpha^{2}\log(eT).
\end{align*}
Let $R=4\alpha$, $F=20(\sigma/G)^{p}\alpha^{2}\log(eT)$. By Freedman's
inequality (Corollary \ref{cor:ez-any-freedman}), we know with probability
at least $1-\frac{\delta}{2}$, for any $\tau\in\left[T\right]$
\begin{align*}
\left|\sum_{t=1}^{\tau}Z_{t}^{k}\right|\leq & \frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\\
= & \frac{8\alpha}{3}\log\frac{4}{\delta}+\sqrt{40(\sigma/G)^{p}\alpha^{2}\log(eT)\log\frac{4}{\delta}}\\
\leq & 7\left(\log\frac{4}{\delta}+\sqrt{(\sigma/G)^{p}\log(eT)\log\frac{4}{\delta}}\right)\alpha.
\end{align*}
We replace $\delta$ by $\frac{\delta}{k_{\max}}$ and apply the union
bound to all $k\in\left[k_{\max}\right]$ to get with probability
at least $1-\frac{\delta}{2}$, there is
\[
\max_{k\in\left[k_{\max}\right]}\left|\sum_{t=1}^{\tau}Z_{t}^{k}\right|\leq7\left(\log\frac{4k_{\max}}{\delta}+\sqrt{(\sigma/G)^{p}\log(eT)\log\frac{4k_{\max}}{\delta}}\right)\alpha,\forall\tau\in\left[T\right].
\]
\end{itemize}
Now, for any $\tau\in\left[T\right]$, note that 
\begin{align*}
\sum_{t=1}^{\tau}\eta_{t}\langle\xi_{t}^{u},x_{*}-x_{t}\rangle= & c_{k_{\tau}}\sum_{t=1}^{\tau}\eta_{t}\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{c_{k_{\tau}}}\right\rangle \overset{(e)}{\leq}c_{k_{\tau}}\sum_{t=1}^{\tau}\eta_{t}\left\langle \xi_{t}^{u},\Pi_{\mathcal{B}(1)}\left(\frac{x_{*}-x_{t}}{c_{k_{\tau}}}\right)\right\rangle \\
\overset{(f)}{\leq} & 2\mathfrak{D}_{\tau}\left|\sum_{t=1}^{\tau}\eta_{t}\left\langle \xi_{t}^{u},\Pi_{\mathcal{B}(1)}\left(\frac{x_{*}-x_{t}}{c_{k_{\tau}}}\right)\right\rangle \right|\\
= & 2\mathfrak{D}_{\tau}\max_{k\in\left[k_{\max}\right]}\left|\sum_{t=1}^{\tau}\eta_{t}\left\langle \xi_{t}^{u},\Pi_{\mathcal{B}(1)}\left(\frac{x_{*}-x_{t}}{c_{k}}\right)\right\rangle \right|\\
= & 2\mathfrak{D}_{\tau}\max_{k\in\left[k_{\max}\right]}\left|\sum_{t=1}^{\tau}Z_{t}^{k}\right|
\end{align*}
where $(e)$ is by noticing that for any $t\leq\tau$, from (\ref{eq:binary}),
we have
\[
\left\Vert \frac{x_{*}-x_{t}}{c_{k_{\tau}}}\right\Vert =\frac{d_{t}}{c_{k_{\tau}}}\leq\frac{\mathfrak{D}_{\tau}}{c_{k_{\tau}}}\leq1\Rightarrow\frac{x_{*}-x_{t}}{c_{k_{\tau}}}=\Pi_{\mathcal{B}(1)}\left(\frac{x_{*}-x_{t}}{c_{k_{\tau}}}\right).
\]
$(f)$ is due to $c_{k_{\tau}}\leq2\mathfrak{D}_{\tau}$, which is
also from (\ref{eq:binary}). Finally, plugging in the bounds on $\max_{k\in\left[k_{\max}\right]}\left|\sum_{t=1}^{\tau}Z_{t}^{k}\right|$
for two cases respectively and using $k_{\max}=\left\lfloor \log_{2}(4T)\right\rfloor \leq\log_{2}(4T)$,
the proof is finished.
\end{proof}


\subsection{Proof of Lemma \ref{lem:xi-u-lip}}

\begin{proof}
We first note that $\eta_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\in\F_{t}$
is a martingale difference sequence. Next, observe that
\begin{align*}
\eta_{t}^{2}\left|\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right|\leq & \eta_{t}^{2}\left\Vert \xi_{t}^{u}\right\Vert ^{2}+\eta_{t}^{2}\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\overset{(a)}{\leq}8\eta_{t}^{2}M_{t}^{2}\overset{(b)}{\leq}32\alpha^{2};\\
\E_{t}\left[\eta_{t}^{4}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)^{2}\right]\leq & \eta_{t}^{4}\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{4}\right]\overset{(c)}{\leq}\eta_{t}^{4}\cdot4M_{t}^{2}\cdot10\sigma^{p}M_{t}^{2-p}=40\sigma^{p}\eta_{t}^{4}M_{t}^{4-p};
\end{align*}
where both $(a)$ and $(c)$ are due to Lemma \ref{lem:err-bound}.
$(b)$ is due to Lemma \ref{lem:normalize}. Now considering
\begin{itemize}
\item under the choice of $M_{t}=2G\lor\sigma t^{\frac{1}{p}}$ and $\eta_{t}=\frac{\alpha}{\sqrt{\left(G^{2}+\sigma^{2}\right)t}}\land\frac{\alpha}{\sigma t^{\frac{1}{p}}}$,
we have :
\begin{align*}
\sum_{t=1}^{T}40\sigma^{p}\eta_{t}^{4}M_{t}^{4-p}\leq & \sum_{t=1}^{T}40\sigma^{p}\cdot\left(\frac{\alpha^{4}}{\left(G^{2}+\sigma^{2}\right)^{2}t^{2}}\land\frac{\alpha^{4}}{\sigma^{4}t^{\frac{4}{p}}}\right)\cdot\left(2^{4-p}G^{4-p}\lor\sigma^{4-p}t^{\frac{4}{p}-1}\right)\\
\leq & \sum_{t=1}^{T}\frac{320\alpha^{4}}{t}\leq320\alpha^{4}\left(\log T+1\right).
\end{align*}
Let $R=32\alpha^{2}$, $F=320\alpha^{4}(\log T+1)$. By Freedman's
inequality (Corollary \ref{cor:ez-any-freedman}), we know with probability
at least $1-\frac{\delta}{2}$, for any $\tau\in\left[T\right]$,
\begin{align*}
\sum_{t=1}^{\tau}\eta_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\leq & \frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\\
= & \frac{64\alpha^{2}}{3}\log\frac{4}{\delta}+\sqrt{640\alpha^{4}\left(\log T+1\right)\log\frac{4}{\delta}}\\
\leq & 26\left(\log\frac{4}{\delta}+\sqrt{\left(\log T+1\right)\log\frac{4}{\delta}}\right)\alpha^{2}\\
= & 26\left(\log\frac{4}{\delta}+\sqrt{\log(eT)\log\frac{4}{\delta}}\right)\alpha^{2}.
\end{align*}
\item under the choice of $M_{t}=2Gt^{\frac{1}{p}}$ and $\eta_{t}=\frac{\alpha}{Gt^{\frac{1}{p}}}$,
we have :
\begin{align*}
\sum_{t=1}^{T}40\sigma^{p}\eta_{t}^{4}M_{t}^{4-p}\leq & \sum_{t=1}^{T}40\sigma^{p}\cdot\frac{\alpha^{4}}{G^{4}t^{\frac{4}{p}}}\cdot2^{4-p}G^{4-p}t^{\frac{4}{p}-1}\\
\leq & \sum_{t=1}^{T}\frac{320(\sigma/G)^{p}\alpha^{4}}{t}\leq320(\sigma/G)^{p}\alpha^{4}\left(\log T+1\right).
\end{align*}
Let $R=32\alpha^{2}$, $F=320(\sigma/G)^{p}\alpha^{4}(\log T+1)$.
By Freedman's inequality (Corollary \ref{cor:ez-any-freedman}), we
know with probability at least $1-\frac{\delta}{2}$, for any $\tau\in\left[T\right]$,
\begin{align*}
\sum_{t=1}^{\tau}\eta_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\leq & \frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\\
= & \frac{64\alpha^{2}}{3}\log\frac{4}{\delta}+\sqrt{640(\sigma/G)^{p}\alpha^{4}\left(\log T+1\right)\log\frac{4}{\delta}}\\
\leq & 26\left(\log\frac{4}{\delta}+\sqrt{(\sigma/G)^{p}\left(\log T+1\right)\log\frac{4}{\delta}}\right)\alpha^{2}\\
= & 26\left(\log\frac{4}{\delta}+\sqrt{(\sigma/G)^{p}\log(eT)\log\frac{4}{\delta}}\right)\alpha^{2}.
\end{align*}
\end{itemize}
\end{proof}


\subsection{Proof of Lemma \ref{lem:basic-lip-exp}}

\begin{proof}
We invoke Lemma \ref{lem:basic-lip-prob} to get for any $\tau\in\left[T\right]$
\[
\frac{\left\Vert x_{\tau+1}-x_{*}\right\Vert ^{2}-\left\Vert x_{1}-x_{*}\right\Vert ^{2}}{2}+\sum_{t=1}^{\tau}\eta_{t}\Delta_{t}\leq h(\tau)+\sum_{t=1}^{\tau}\eta_{t}\langle\xi_{t},x_{*}-x_{t}\rangle+2\eta_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)
\]
Taking expectations on both sides, we have
\begin{align*}
 & \frac{\E\left[\left\Vert x_{\tau+1}-x_{*}\right\Vert ^{2}\right]-\E\left[\left\Vert x_{1}-x_{*}\right\Vert ^{2}\right]}{2}+\sum_{t=1}^{\tau}\eta_{t}\E\left[\Delta_{t}\right]\\
\leq & h(\tau)+\sum_{t=1}^{\tau}\eta_{t}\E\left[\langle\xi_{t},x_{*}-x_{t}\rangle\right]+2\eta_{t}^{2}\E\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right]\\
\overset{(a)}{=} & h(\tau)+\sum_{t=1}^{\tau}\eta_{t}\E\left[\langle\xi_{t}^{b},x_{*}-x_{t}\rangle\right]\\
\overset{(b)}{\leq} & h(\tau)+\sum_{t=1}^{\tau}\eta_{t}\E\left[\left\Vert \xi_{t}^{b}\right\Vert \left\Vert x_{*}-x_{t}\right\Vert \right]\\
\overset{(c)}{\leq} & h(\tau)+\sum_{t=1}^{\tau}2\eta_{t}\sigma^{p}M_{t}^{1-p}\E\left[\left\Vert x_{*}-x_{t}\right\Vert \right]\\
\overset{(d)}{\leq} & h(\tau)+\sum_{t=1}^{\tau}2\eta_{t}\sigma^{p}M_{t}^{1-p}\sqrt{\E\left[\left\Vert x_{*}-x_{t}\right\Vert ^{2}\right]}
\end{align*}
where we use 
\[
\E\left[\langle\xi_{t},x_{*}-x_{t}\rangle\right]=\E\left[\E_{t}\left[\langle\xi_{t},x_{*}-x_{t}\rangle\right]\right]=\E\left[\langle\E_{t}\left[\xi_{t}\right],x_{*}-x_{t}\rangle\right]=\E\left[\langle\xi_{t}^{b},x_{*}-x_{t}\rangle\right]
\]
and $\E[\|\xi_{t}^{u}\|^{2}]=\E[\E_{t}[\|\xi_{t}^{u}\|^{2}]]$ in
$(a)$; $\langle\xi_{t}^{b},x_{*}-x_{t}\rangle\leq\|\xi_{t}^{b}\|\|x_{*}-x_{t}\|$
in $(b)$ is due to Cauchy--Schwarz inequality; The bound of $\|\xi_{t}^{b}\|\leq2\sigma^{p}M_{t}^{1-p}$
in $(c)$ is from Lemma \ref{lem:err-bound}. $(d)$ is because of
$\E\left[X\right]\leq\sqrt{\E\left[X^{2}\right]}$. Fianlly, we consider
the following two cases to finish the proof.
\begin{itemize}
\item under the choice of $M_{t}=2G\lor\sigma t^{\frac{1}{p}}$ and $\eta_{t}=\frac{\alpha}{\sqrt{\left(G^{2}+\sigma^{2}\right)t}}\land\frac{\alpha}{\sigma t^{\frac{1}{p}}}$,
we have :
\[
2\eta_{t}\sigma^{p}M_{t}^{1-p}\leq2\cdot\frac{\alpha}{\sigma t^{\frac{1}{p}}}\cdot\sigma t^{\frac{1}{p}-1}=\frac{2\alpha}{t}.
\]
\item under the choice of $M_{t}=2Gt^{\frac{1}{p}}$ and $\eta_{t}=\frac{\alpha}{Gt^{\frac{1}{p}}}$,
we have :
\[
2\eta_{t}\sigma^{p}M_{t}^{1-p}=2\cdot\frac{\alpha}{Gt^{\frac{1}{p}}}\cdot\sigma^{p}\left(2Gt^{\frac{1}{p}}\right)^{1-p}=\frac{2\alpha(\sigma/G)^{p}}{t}.
\]
\end{itemize}
\end{proof}


\section{Additional Theoretical Analysis When $\mu>0$\label{sec:app-str}}

In this section, we aim to prove Theorems and \ref{thm:str-prob}
and \ref{thm:str-exp}.

\subsection{High-Probability Analysis When $\mu>0$\label{subsec:app-str-prob}}

To start with, we introduce a basic inequality in Lemma \ref{lem:basic-str-prob}.
\begin{lem}
\label{lem:basic-str-prob}When $\mu>0$, under the choices of $M_{t}=2Gt^{\frac{1}{p}}$
and $\eta_{t}=\frac{4}{\mu(t+1)}$, for any $\tau\in\left[T\right]$,
we have :
\begin{align*}
\frac{\mu(\tau+1)\tau}{8}\left\Vert x_{\tau+1}-x_{*}\right\Vert ^{2}+\sum_{t=1}^{\tau}t\Delta_{t}\leq & \sum_{t=1}^{\tau}t\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\frac{8}{\mu}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\\
 & +\frac{640\sigma^{p}G^{2-p}+8\sigma^{2p}G^{2-2p}+4G^{2}}{\mu}\tau^{\frac{2}{p}}.
\end{align*}
\end{lem}
%
\begin{proof}
We first invoke Lemma \ref{lem:basic} to get
\begin{align}
\Delta_{t}+\frac{\eta_{t}^{-1}}{2}\left\Vert x_{t+1}-x_{*}\right\Vert ^{2}-\frac{\eta_{t}^{-1}-\mu}{2}\left\Vert x_{t}-x_{*}\right\Vert ^{2}\leq & \langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\nonumber \\
= & \langle\xi_{t}^{b},x_{*}-x_{t}\rangle+\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\nonumber \\
\overset{(a)}{\leq} & \frac{\left\Vert \xi_{t}^{b}\right\Vert ^{2}}{\mu}+\frac{\mu\left\Vert x_{t}-x_{*}\right\Vert ^{2}}{4}+\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\nonumber \\
\Rightarrow\Delta_{t}+\frac{\eta_{t}^{-1}}{2}\left\Vert x_{t+1}-x_{*}\right\Vert ^{2}-\frac{\eta_{t}^{-1}-\mu/2}{2}\left\Vert x_{t}-x_{*}\right\Vert ^{2}\leq & \langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\frac{\left\Vert \xi_{t}^{b}\right\Vert ^{2}}{\mu}+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\label{eq:str-1}
\end{align}
where $(a)$ is by $\langle\xi_{t}^{b},x_{*}-x_{t}\rangle\leq\left\Vert \xi_{t}^{b}\right\Vert ^{2}/\mu+\mu\left\Vert x_{t}-x_{*}\right\Vert ^{2}/4$.
Now, plugging $\eta_{t}=\frac{4}{\mu(t+1)}$ into (\ref{eq:str-1})
and multiplying both sides by $t$ to obtain
\begin{align}
t\Delta_{t}+\frac{\mu(t+1)t}{8}\left\Vert x_{t+1}-x_{*}\right\Vert ^{2}-\frac{\mu t(t-1)}{8}\left\Vert x_{t}-x_{*}\right\Vert ^{2}\leq & t\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}+\left\Vert \xi_{t}^{b}\right\Vert ^{2}\right)+t\left\Vert \xi_{t}^{b}\right\Vert ^{2}+4G^{2}}{\mu}\nonumber \\
= & t\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\frac{8}{\mu}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\nonumber \\
 & +\frac{8\left(\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+\left\Vert \xi_{t}^{b}\right\Vert ^{2}\right)+t\left\Vert \xi_{t}^{b}\right\Vert ^{2}+4G^{2}}{\mu}.\label{eq:str-2}
\end{align}
Next, we bound $\E_{t}[\|\xi_{t}^{u}\|^{2}]\le10\sigma^{p}M_{t}^{2-p}$,
$\|\xi_{t}^{b}\|^{2}\leq10\sigma^{p}M_{t}^{2-p}$ and $\|\xi_{t}^{b}\|\le2\sigma^{p}M_{t}^{1-p}$
by using Lemma \ref{lem:err-bound} to get
\begin{align}
 & \frac{8\left(\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+\left\Vert \xi_{t}^{b}\right\Vert ^{2}\right)+t\left\Vert \xi_{t}^{b}\right\Vert ^{2}+4G^{2}}{\mu}\nonumber \\
\leq & \frac{160\sigma^{p}M_{t}^{2-p}+4t\sigma^{2p}M_{t}^{2-2p}+4G^{2}}{\mu}\nonumber \\
= & \frac{160\sigma^{p}(2Gt^{\frac{1}{p}})^{2-p}+4t\sigma^{2p}(2Gt^{\frac{1}{p}})^{2-2p}+4G^{2}}{\mu}\nonumber \\
\leq & \frac{320\sigma^{p}G^{2-p}+4\sigma^{2p}G^{2-2p}}{\mu}t^{\frac{2}{p}-1}+\frac{4G^{2}}{\mu}\label{eq:str-3}
\end{align}

Finally, combining (\ref{eq:str-2}) and (\ref{eq:str-3}) and summing
up from $t=1$ to $\tau$, we have
\begin{align}
 & \frac{\mu(\tau+1)\tau}{8}\left\Vert x_{t+1}-x_{*}\right\Vert ^{2}+\sum_{t=1}^{\tau}t\Delta_{t}\nonumber \\
\leq & \sum_{t=1}^{\tau}t\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\frac{8}{\mu}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\nonumber \\
 & +\sum_{t=1}^{\tau}\frac{320\sigma^{p}G^{2-p}+4\sigma^{2p}G^{2-2p}}{\mu}t^{\frac{2}{p}-1}+\frac{4G^{2}}{\mu}\nonumber \\
\leq & \sum_{t=1}^{\tau}t\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\frac{8}{\mu}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\nonumber \\
 & +\frac{320\sigma^{p}G^{2-p}+4\sigma^{2p}G^{2-2p}}{\mu}\cdot\frac{p}{2}((\tau+1)^{\frac{2}{p}}-1)+\frac{4G^{2}}{\mu}\tau\nonumber \\
\leq & \sum_{t=1}^{\tau}t\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\frac{8}{\mu}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\nonumber \\
 & +\frac{640\sigma^{p}G^{2-p}+8\sigma^{2p}G^{2-2p}}{\mu}\tau^{\frac{2}{p}}+\frac{4G^{2}}{\mu}\tau\label{eq:str-finer}
\end{align}
Finally, we use $\frac{4G^{2}}{\mu}\tau\leq\frac{4G^{2}}{\mu}\tau^{\frac{2}{p}}$
to finish the proof.
\end{proof}

The same as the case of $\mu=0$. Our goal is to find a high-probability
bound of $\sum_{t=1}^{\tau}t\langle\xi_{t}^{u},x_{*}-x_{t}\rangle$
and $\sum_{t=1}^{\tau}\frac{8}{\mu}(\|\xi_{t}^{u}\|^{2}-\E_{t}[\|\xi_{t}^{u}\|^{2}])$.
The first one is kind of tricky, which will be bounded via an induction-based
method during proving Theorem \ref{thm:str-prob} in the last of this
section. The latter one is easy as we can use Freedman's inequality
again, the bound of which is shown in Lemma \ref{lem:xi-u-str}.
\begin{lem}
\label{lem:xi-u-str}When $\mu>0$, under the choice of $M_{t}=2Gt^{\frac{1}{p}}$,
for any $\tau\in\left[T\right]$, we have with probability at least
$1-\frac{\delta}{2T}$
\[
\sum_{t=1}^{\tau}\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\leq51\left(G^{2}+\sigma^{\frac{p}{2}}G^{2-\frac{p}{2}}\right)\log\left(\frac{4T}{\delta}\right)\tau^{\frac{2}{p}}.
\]
\end{lem}
%
\begin{proof}
We first note that $\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\in\F_{t}$
is a martingale difference sequence. Next, observe that
\[
\left|\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right|\leq\left\Vert \xi_{t}^{u}\right\Vert ^{2}+\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\leq8M_{t}^{2}=8\cdot4G^{2}t^{\frac{2}{p}}\leq32G^{2}\tau^{\frac{2}{p}}.
\]
Besides, we know
\begin{align*}
\sum_{t=1}^{\tau}\E_{t}\left[\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)^{2}\right]\leq & \sum_{t=1}^{\tau}\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{4}\right]\leq\sum_{t=1}^{\tau}4M_{t}^{2}\cdot10\sigma^{p}M_{t}^{2-p}\\
= & \sum_{t=1}^{\tau}40\sigma^{p}M_{t}^{4-p}=\sum_{t=1}^{\tau}40\sigma^{p}\cdot2^{4-p}G^{4-p}t^{\frac{4}{p}-1}\\
\leq & \sum_{t=1}^{\tau}320\sigma^{p}G^{4-p}t^{\frac{4}{p}-1}\leq320\sigma^{p}G^{4-p}\cdot\frac{p}{4}\left((\tau+1)^{\frac{4}{p}}-1\right)\\
\leq & 1280\sigma^{p}G^{4-p}\tau^{\frac{4}{p}}.
\end{align*}
Let $R=32G^{2}\tau^{\frac{2}{p}}$, $F=1280\sigma^{p}G^{4-p}\tau^{\frac{4}{p}}$.
By Freedman's inequality (Corollary \ref{cor:ez-freedman}), with
probability at least $1-\frac{\delta}{2T}$, we have
\begin{align*}
\sum_{t=1}^{\tau}\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\leq & \frac{2R}{3}\log\frac{4T}{\delta}+\sqrt{2F\log\frac{4T}{\delta}}\\
= & \left(\frac{64G^{2}}{3}\log\frac{4T}{\delta}+16\sqrt{10\sigma^{p}G^{4-p}\log\frac{4T}{\delta}}\right)\tau^{\frac{2}{p}}\\
\leq & 51\left(G^{2}+\sigma^{\frac{p}{2}}G^{2-\frac{p}{2}}\right)\log\left(\frac{4T}{\delta}\right)\tau^{\frac{2}{p}}.
\end{align*}
\end{proof}

With the above two lemmas, we are able to prove Theorem \ref{thm:str-prob}.

\begin{proof}[Proof of Theorem \ref{thm:str-prob}]
Our goal is to use induction to prove the following event 
\[
E_{\tau}=\left\{ \frac{\mu(t+1)t}{8}\left\Vert x_{t+1}-x_{*}\right\Vert ^{2}+\sum_{s=1}^{t}s\Delta_{s}\leq Kt^{\frac{2}{p}},\forall t\in\left\{ 0\right\} \cup\left[\tau\right]\right\} 
\]
holds with probability at least $1-\frac{\tau\delta}{T}$ for any
$\tau\in\left\{ 0\right\} \cup\left[T\right]$ where
\[
K=O\left(\left(\frac{\sigma^{2}+G^{2}+\sigma^{2p}G^{2-2p}}{\mu}\right)\log^{2}\frac{T}{\delta}\right)
\]
satisfies
\begin{align}
K & =A\sqrt{K}+B;\label{eq:str-def-k-1}\\
A & =\frac{36\left(G+\sigma^{\frac{p}{2}}G^{1-\frac{p}{2}}\right)}{\sqrt{\mu}}\log\frac{4T}{\delta};\label{eq:str-def-k-2}\\
B & =\frac{415\left(G^{2}+\sigma^{\frac{p}{2}}G^{2-\frac{p}{2}}\right)}{\mu}\log\frac{4T}{\delta}+\frac{640\sigma^{p}G^{2-p}+8\sigma^{2p}G^{2-2p}+4G^{2}}{\mu};\label{eq:str-def-k-3}
\end{align}

First, when $\tau=0$, $E_{0}=\left\{ 0\leq0\right\} $ holds with
probability $1=1-\frac{\tau\delta}{T}$. Next, suppose that $\Pr\left[E_{\tau-1}\right]\geq1-\frac{(\tau-1)\delta}{T}$
for some $\tau\in\left[T\right]$, we will show $\Pr\left[E_{\tau}\right]\geq1-\frac{\tau\delta}{T}$.
We consider the the following random variable for any $t\in\left[\tau\right]$:
\[
Z_{t}=\begin{cases}
x_{*}-x_{t} & \frac{\mu t(t-1)}{8}\left\Vert x_{t}-x_{*}\right\Vert ^{2}\leq K(t-1)^{\frac{2}{p}}\\
\bzero & \text{o.w.}
\end{cases}.
\]
The first observation is that $Z_{t}\in\F_{t-1}$. Additionally, note
that under $E_{\tau-1}$, we have
\[
\frac{\mu t(t-1)}{8}\left\Vert x_{t}-x_{*}\right\Vert ^{2}\leq\frac{\mu t(t-1)}{8}\left\Vert x_{t}-x_{*}\right\Vert ^{2}+\sum_{s=1}^{t-1}s\Delta_{s}\leq K(t-1)^{2/p},\forall t\in\left[\tau\right]
\]
which implies $Z_{t}=x_{*}-x_{t},\forall t\in$$\left[\tau\right]$
if $E_{\tau-1}$ happens. Another useful result is that
\[
\left\Vert Z_{t}\right\Vert \leq\begin{cases}
\left\Vert x_{1}-x_{*}\right\Vert \overset{(a)}{\leq}\frac{G}{\mu} & t=1\\
\frac{2\sqrt{2K}}{\sqrt{\mu}}t^{\frac{1}{p}-1} & 2\leq t\leq\tau
\end{cases}
\]
where $(a)$ is due to Fact \ref{fact:fact}.

Assuming $E_{\tau-1}$ happens, we use Lemma \ref{lem:basic-str-prob}
for time $\tau$ to get
\begin{align}
\frac{\mu(\tau+1)\tau}{8}\left\Vert x_{\tau+1}-x_{*}\right\Vert ^{2}+\sum_{t=1}^{\tau}t\Delta_{t}\leq & \sum_{t=1}^{\tau}t\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\frac{8}{\mu}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\nonumber \\
 & +\frac{640\sigma^{p}G^{2-p}+8\sigma^{2p}G^{2-2p}+4G^{2}}{\mu}\tau^{\frac{2}{p}}\nonumber \\
= & \sum_{t=1}^{\tau}t\langle\xi_{t}^{u},Z_{t}\rangle+\frac{8}{\mu}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\nonumber \\
 & +\frac{640\sigma^{p}G^{2-p}+8\sigma^{2p}G^{2-2p}+4G^{2}}{\mu}\tau^{\frac{2}{p}}.\label{eq:str-4}
\end{align}
Before proceed with the terms $\sum_{t=1}^{\tau}t\langle\xi_{t}^{u},Z_{t}\rangle$
and $\sum_{t=1}^{\tau}\frac{8}{\mu}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)$,
first recall $M_{t}=2Gt^{\frac{1}{p}}$ and $\eta_{t}=\frac{4}{\mu(t+1)}$.
\begin{itemize}
\item Bounding the term $\sum_{t=1}^{\tau}t\langle\xi_{t}^{u},Z_{t}\rangle$:
Note that $\E_{t}\left[t\langle\xi_{t}^{u},Z_{t}\rangle\right]=0$.
Beisdes, for $t=1$, $\langle\xi_{1}^{u},Z_{1}\rangle\leq\left\Vert \xi_{1}^{u}\right\Vert \left\Vert Z_{1}\right\Vert \leq2M_{1}\cdot\frac{G}{\mu}=\frac{4G^{2}}{\mu}$;
for $2\leq t\leq\tau$
\begin{align*}
\left|t\langle\xi_{t}^{u},Z_{t}\rangle\right|\leq & t\left\Vert \xi_{t}^{u}\right\Vert \left\Vert Z_{t}\right\Vert \leq t\cdot2M_{t}\cdot\frac{2\sqrt{2K}}{\sqrt{\mu}}t^{\frac{1}{p}-1}\\
= & \frac{8\sqrt{2K}G}{\sqrt{\mu}}t^{\frac{2}{p}}\leq\frac{8\sqrt{2K}G}{\sqrt{\mu}}\tau^{\frac{2}{p}}.
\end{align*}
Hence, we have for any $t\in\left[\tau\right]$
\begin{align*}
\left|t\langle\xi_{t}^{u},Z_{t}\rangle\right|\leq & \frac{4G^{2}}{\mu}+\frac{8\sqrt{2K}G}{\sqrt{\mu}}\tau^{\frac{2}{p}}.
\end{align*}
Additionally, for $t\geq2$
\begin{align*}
\E_{t}\left[t^{2}\langle\xi_{t}^{u},Z_{t}\rangle^{2}\right]\leq & t^{2}\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\left\Vert Z_{t}\right\Vert ^{2}\leq t^{2}\cdot10\sigma^{p}M_{t}^{2-p}\cdot\frac{8K}{\mu}t^{\frac{2}{p}-2}\leq\frac{160\sigma^{p}G^{2-p}K}{\mu}t^{\frac{4}{p}-1}.
\end{align*}
which implies
\begin{align*}
\sum_{t=1}^{\tau}\E_{t}\left[t^{2}\langle\xi_{t}^{u},Z_{t}\rangle^{2}\right]\leq & \E_{1}\left[\langle\xi_{1}^{u},Z_{1}\rangle^{2}\right]+\sum_{t=2}^{\tau}\frac{160\sigma^{p}G^{2-p}K}{\mu}t^{\frac{4}{p}-1}\\
\leq & 10\sigma^{p}M_{1}^{2-p}\cdot\frac{G^{2}}{\mu^{2}}+\frac{160\sigma^{p}G^{2-p}K}{\mu}\cdot\frac{p}{4}\left(\left(\tau+1\right)^{\frac{4}{p}}-2^{\frac{4}{p}}\right)\\
\leq & \frac{20\sigma^{p}G^{4-p}}{\mu^{2}}+\frac{640\sigma^{p}G^{2-p}K}{\mu}\tau^{\frac{4}{p}}.
\end{align*}
Let $R=\frac{4G^{2}}{\mu}+\frac{8\sqrt{2K}G}{\sqrt{\mu}}\tau^{\frac{2}{p}}$,
$F=\frac{20\sigma^{p}G^{4-p}}{\mu^{2}}+\frac{640K\sigma^{p}G^{2-p}}{\mu}\tau^{\frac{4}{p}}$.
By Freedman's inequality (Corollary \ref{cor:ez-freedman}), we know
with probability at least $1-\frac{\delta}{2T}$
\begin{align}
\sum_{t=1}^{\tau}t\langle\xi_{t}^{u},Z_{t}\rangle\leq & \frac{2R}{3}\log\frac{4T}{\delta}+\sqrt{2F\log\frac{4T}{\delta}}\nonumber \\
= & \left(\frac{8G^{2}}{3\mu}+\frac{16\sqrt{2K}G}{3\sqrt{\mu}}\tau^{\frac{2}{p}}\right)\log\frac{4T}{\delta}+\sqrt{\left(\frac{40\sigma^{p}G^{4-p}}{\mu^{2}}+\frac{1280\sigma^{p}G^{2-p}K}{\mu}\tau^{\frac{4}{p}}\right)\log\frac{4T}{\delta}}\nonumber \\
\leq & \left[\frac{7\left(G^{2}+\sigma^{\frac{p}{2}}G^{2-\frac{p}{2}}\right)}{\mu}\log\frac{4T}{\delta}+\frac{36\left(G+\sigma^{\frac{p}{2}}G^{1-\frac{p}{2}}\right)}{\sqrt{\mu}}\log\frac{4T}{\delta}\sqrt{K}\right]\tau^{\frac{2}{p}}.\label{eq:str-5}
\end{align}
\item Bounding the term $\sum_{t=1}^{\tau}\frac{8}{\mu}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)$:
By Lemma \ref{lem:xi-u-str}, with probability at least $1-\frac{\delta}{2T}$,
we have
\begin{equation}
\sum_{t=1}^{\tau}\frac{8}{\mu}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\leq\frac{408\left(G^{2}+\sigma^{\frac{p}{2}}G^{2-\frac{p}{2}}\right)}{\mu}\log\frac{4T}{\delta}\tau^{\frac{2}{p}}.\label{eq:str-6}
\end{equation}
\end{itemize}
Combining bounds in (\ref{eq:str-5}) and (\ref{eq:str-6}), we know
with probability at least $1-\frac{\delta}{T}$, the following event
holds
\[
C=\left\{ \sum_{t=1}^{\tau}t\langle\xi_{t}^{u},Z_{t}\rangle+\frac{8}{\mu}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\leq\left[\frac{415\left(G^{2}+\sigma^{\frac{p}{2}}G^{2-\frac{p}{2}}\right)}{\mu}\log\frac{4T}{\delta}+\frac{36\left(G+\sigma^{\frac{p}{2}}G^{1-\frac{p}{2}}\right)}{\sqrt{\mu}}\log\frac{4T}{\delta}\sqrt{K}\right]\tau^{\frac{2}{p}}\right\} .
\]
Recall that (\ref{eq:str-4}) holds under the event $E_{\tau-1}$,
therefore we consider the event $E_{\tau-1}\cap C$, which holds with
probability at least $1-\frac{\tau\delta}{T}$ due to $\Pr\left[E_{\tau-1}\right]\geq1-\frac{(\tau-1)\delta}{T}$
(by the induction hypothesis) and $\Pr\left[C\right]\geq1-\frac{\delta}{T}$.
Now we know with probability at least $1-\frac{\tau\delta}{T}$
\begin{align*}
 & \frac{\mu(\tau+1)\tau}{8}\left\Vert x_{\tau+1}-x_{*}\right\Vert ^{2}+\sum_{t=1}^{\tau}t\Delta_{t}\\
\leq & \left[\frac{415\left(G^{2}+\sigma^{\frac{p}{2}}G^{2-\frac{p}{2}}\right)}{\mu}\log\frac{4T}{\delta}+\frac{36\left(G+\sigma^{\frac{p}{2}}G^{1-\frac{p}{2}}\right)}{\sqrt{\mu}}\log\frac{4T}{\delta}\sqrt{K}\right]\tau^{\frac{2}{p}}\\
 & +\frac{640\sigma^{p}G^{2-p}+8\sigma^{2p}G^{2-2p}+4G^{2}}{\mu}\tau^{\frac{2}{p}}\\
= & \frac{36\left(G+\sigma^{\frac{p}{2}}G^{1-\frac{p}{2}}\right)}{\sqrt{\mu}}\log\frac{4T}{\delta}\sqrt{K}\tau^{\frac{2}{p}}\\
 & +\left[\frac{415\left(G^{2}+\sigma^{\frac{p}{2}}G^{2-\frac{p}{2}}\right)}{\mu}\log\frac{4T}{\delta}+\frac{640\sigma^{p}G^{2-p}+8\sigma^{2p}G^{2-2p}+4G^{2}}{\mu}\right]\tau^{\frac{2}{p}}\\
= & K\tau^{\frac{2}{p}}
\end{align*}
where the last step is due the definition of $K$ (see (\ref{eq:str-def-k-1}),
(\ref{eq:str-def-k-2}) and (\ref{eq:str-def-k-3})). Hence we have
\begin{align*}
\Pr\left[E_{\tau}\right] & =\Pr\left[E_{\tau-1}\cap\left\{ \frac{\mu(\tau+1)\tau}{8}\left\Vert x_{\tau+1}-x_{*}\right\Vert ^{2}+\sum_{t=1}^{\tau}t\Delta_{t}\leq K\tau^{\frac{2}{p}}\right\} \right]\\
 & \geq\Pr\left[E_{\tau-1}\cap C\cap\left\{ \frac{\mu(\tau+1)\tau}{8}\left\Vert x_{\tau+1}-x_{*}\right\Vert ^{2}+\sum_{t=1}^{\tau}t\Delta_{t}\leq K\tau^{\frac{2}{p}}\right\} \right]\\
 & =\Pr\left[E_{\tau-1}\cap C\right]\geq1-\frac{\tau\delta}{T}.
\end{align*}
Thuts, the induction is completed.

Finally, we consider time $T$ to get with probability at least $1-\delta$
\[
\frac{\mu(T+1)T}{8}\left\Vert x_{T+1}-x_{*}\right\Vert ^{2}+\frac{T(T+1)}{2}\left(F(\bar{x}_{T})-F(x_{*})\right)\leq\frac{\mu(T+1)T}{8}\left\Vert x_{T+1}-x_{*}\right\Vert ^{2}+\sum_{t=1}^{T}t\Delta_{t}\leq KT^{\frac{2}{p}}
\]
where $\sum_{t=1}^{T}t\Delta_{t}\geq\frac{T(T+1)}{2}\left(F(\bar{x}_{T})-F(x_{*})\right)$
is by the convexity of $F$ and $\bar{x}_{T}=\frac{2}{T(T+1)}\sum_{t=1}^{T}x_{t}$.
Now we conclude
\[
F(\bar{x}_{T})-F(x_{*})\leq2KT^{\frac{2}{p}-2}\text{ and }\left\Vert x_{T+1}-x_{*}\right\Vert ^{2}\leq\frac{8K}{\mu}T^{\frac{2}{p}-2}.
\]
Plugging in $K=O\left(\frac{\sigma^{2}+G^{2}+\sigma^{2p}G^{2-2p}}{\mu}\log^{2}\frac{4T}{\delta}\right)$,
we get the desired result.
\end{proof}


\subsection{In-Expectaion Analysis When $\mu>0$\label{subsec:app-str-exp}}

The proof of Theorem \ref{thm:str-exp} is inispired by \cite{zhang2020adaptive}.

\begin{proof}[Proof of Theorem \ref{thm:str-exp}]
We take expectations on both sides of (\ref{eq:str-finer}) in Lemma
\ref{lem:basic-str-prob} to get for any any $\tau\in\left[T\right]$,
\[
\frac{\mu(\tau+1)\tau}{8}\E\left[\left\Vert x_{\tau+1}-x_{*}\right\Vert ^{2}\right]+\sum_{t=1}^{\tau}t\E\left[\Delta_{t}\right]\leq\frac{640\sigma^{p}G^{2-p}+8\sigma^{2p}G^{2-2p}}{\mu}\tau^{\frac{2}{p}}+\frac{4G^{2}}{\mu}\tau.
\]
Choosing $\tau=T$ and using $\sum_{t=1}^{T}t\E\left[\Delta_{t}\right]\geq\frac{T(T+1)}{2}\E\left[F(\bar{x}_{T})-F(x_{*})\right]$
by the convexity of $F$ and $\bar{x}_{T}=\frac{2}{T(T+1)}\sum_{t=1}^{T}x_{t}$,
we conclude
\begin{align*}
\E\left[F(\bar{x}_{T})-F(x_{*})\right] & \leq O\left(\frac{G^{2}}{\mu T}+\frac{\sigma^{p}G^{2-p}+\sigma^{2p}G^{2-2p}}{\mu T^{\frac{2(p-1)}{p}}}\right);\\
\E\left[\left\Vert x_{T+1}-x_{*}\right\Vert ^{2}\right] & \leq O\left(\frac{G^{2}}{\mu^{2}T}+\frac{\sigma^{p}G^{2-p}+\sigma^{2p}G^{2-2p}}{\mu^{2}T^{\frac{2(p-1)}{p}}}\right).
\end{align*}
\end{proof}

