
\section{Extension to Arbitrary Norms\label{sec:general-norm}}

In this section, we relax the $\ell_{2}$ norm used in the previous
assumptions (see Section \ref{sec:Preliminaries}) to an arbitrary
norm $\|\cdot\|$ on $\R^{d}$. $\|\cdot\|_{*}$ denotes the dual
norm of $\|\cdot\|$ induced by $\langle\cdot,\cdot\rangle$. Additionally,
let $\psi$ be a differentiable and $1$-strongly convex function
with respect to $\|\cdot\|$ on $\dom$, i.e.,
\[
\psi(x)\geq\psi(y)+\langle\na\psi(y),x-y\rangle+\frac{1}{2}\left\Vert x-y\right\Vert ^{2},\forall x,y\in\dom.
\]
We note that, rigorously speaking, $y$ can only be chosen in $\mathrm{int}(\dom)$.
However, one can think there is $\dom\subseteq\mathrm{int}(\mathrm{dom}(\psi))$
to avoid this potential issue. Now, define the Bregman divergence
with respect to $\psi$ as
\[
D_{\psi}(x,y)=\psi(x)-\psi(y)-\langle\na\psi(y),x-y\rangle.
\]
Note that $D_{\psi}(x,y)\geq\frac{1}{2}\|x-y\|^{2}$ from the $1$-strongly
convexity assumption of $\psi$. In particular $D_{\psi}(x,y)=\frac{\|x-y\|_{2}^{2}}{2}$
when considering $\|\cdot\|=\|\cdot\|_{2}$ as used in the main text
and $\psi(x)=\frac{1}{2}\|x\|_{2}^{2}$.

\subsection{New Assumptions and A Useful Fact}

With the above preparations, we can provide new assumptions under
the general norm.

\textbf{1. Existence of a local minimizer}: $\exists x_{*}\in\argmin_{x\in\dom}F(x)$
satisfying $F(x_{*})>-\infty$.

\textbf{2'. Relatively }$\mu$\textbf{-strongly convex}: $\exists\mu\geq0$
such that $F(x)\geq F(y)+\langle g,x-y\rangle+\mu D_{\psi}(x,y),\forall x,y\in\dom,g\in\pa F(y)$.

\textbf{3'. }$G$\textbf{-Lipschitz}: $\exists G>0$ such that $\|g\|_{*}\leq G,\forall x\in\dom,g\in\pa F(x)$ 

\textbf{4. Unbiased gradient estimator}: We are able to access a history-independent,
unbiased gradient estimator $\hp F(x)$ for any $x\in\dom$. In other
words, $\E[\widehat{\pa}F(x)\vert x]\in\pa F(x),\forall x\in\dom$.

\textbf{5'. Bounded $p$th moment noise}: There exist $p\in(1,2]$
and $\sigma\geq0$ denoting the noise level such that $\E[\|\hp F(x)-\E[\widehat{\pa}F(x)\vert x]\|_{*}^{p}\vert x]\leq\sigma^{p}$.

The concept of relatively strong convexity in Assumption 2' is introduced
in \cite{lu2018relatively}. Note that when $\|\cdot\|=\|\cdot\|_{2}$,
Assumptions 2', 3' and 5' are the same as Assumptions 2, 3 and 5 in
Section \ref{sec:Preliminaries}. Hence, these new assumptions are
more general. Next, we provide a useful fact under Assumptions 1,
2' and 3'. This result can help us to simplify the final bound in
the proof of Theorem \ref{thm:str-prob}.
\begin{fact}
\label{fact:fact}Under Assumption 1, 2' and 3' with $\mu>0$, there
is
\[
\left\Vert x-x_{*}\right\Vert ^{2}\leq2D_{\psi}(x,x_{*})\leq\frac{G^{2}}{\mu^{2}},\forall x\in\dom.
\]
\end{fact}
%
\begin{proof}
Given $x\in\dom$, by assumption 2', for any fixed $g\in\pa F(x)$,
we have
\begin{align*}
F(x_{*})\geq & F(x)+\langle g,x_{*}-x\rangle+\mu D_{\psi}(x_{*},x)\\
\overset{(a)}{\geq} & F(x)-\left\Vert g\right\Vert _{*}\left\Vert x_{*}-x\right\Vert +\mu D_{\psi}(x_{*},x)\\
\overset{(b)}{\geq} & F(x)-\left\Vert g\right\Vert _{*}\left\Vert x_{*}-x\right\Vert +\frac{\mu}{2}\left\Vert x_{*}-x\right\Vert ^{2}\\
\overset{(c)}{\geq} & F(x)-\frac{\left\Vert g\right\Vert _{*}^{2}}{2\mu}\overset{(d)}{\geq}F(x)-\frac{G^{2}}{2\mu}\\
\Rightarrow\frac{G^{2}}{2\mu}\geq & F(x)-F(x_{*})
\end{align*}
where $(a)$ is due to Cauchy-Schwarz inequality; $(b)$ is by $D_{\psi}(x,y)\geq\frac{1}{2}\left\Vert x-y\right\Vert ^{2}$;
$(c)$ is because of Young's inequality; $(d)$ is by Assumption 3'. 

Now by Assumption 2' again, for any fixed $g\in\pa F(x_{*})$, we
have
\begin{align*}
F(x)\geq & F(x_{*})+\langle g,x-x_{*}\rangle+\mu D_{\psi}(x,x_{*})\\
\overset{(e)}{\geq} & F(x_{*})+\mu D_{\psi}(x,x_{*})\overset{(f)}{\geq}F(x_{*})+\frac{\mu}{2}\left\Vert x-x_{*}\right\Vert ^{2}\\
\Rightarrow F(x)-F(x_{*})\geq & \mu D_{\psi}(x,x_{*})
\end{align*}
where $(e)$ is by $\langle g,x-x_{*}\rangle\geq0$ due to $g\in\pa F(x_{*})$
and $x_{*}\in\argmin_{x\in\dom}F(x)$; $(f)$ is by $D_{\psi}(x,y)\geq\frac{1}{2}\left\Vert x-y\right\Vert ^{2}$.

Finally, we know
\[
\frac{\mu}{2}\left\Vert x-x_{*}\right\Vert ^{2}\leq\mu D_{\psi}(x,x_{*})\leq F(x)-F(x_{*})\leq\frac{G^{2}}{2\mu}\Rightarrow\left\Vert x-x_{*}\right\Vert ^{2}\leq2D_{\psi}(x,x_{*})\leq\frac{G^{2}}{\mu^{2}}.
\]
\end{proof}


\subsection{Algorithm with the General Norm}

\begin{algorithm}[h]
\caption{\label{alg:algo-md}Projected Stochastic MD with Clipping}

\textbf{Input}: $x_{1}\in\dom$, $M_{t}>0$, $\eta_{t}>0$.

\textbf{for} $t=1$ \textbf{to} $T$ \textbf{do}

$\quad$$g_{t}=\left(1\land\frac{M_{t}}{\left\Vert \hp F(x_{t})\right\Vert _{*}}\right)\hp F(x_{t})$

$\quad$$x_{t+1}=\argmin_{x\in\dom}\langle g_{t},x-x_{t}\rangle+\frac{1}{\eta_{t}}D_{\psi}(x,x_{t}).$

\textbf{end for}
\end{algorithm}

With the new assumptions, we provide a general version of Algorithm
\ref{alg:algo} as shown in Algorithm \ref{alg:algo-md}, which employs
the mirror descent framework. Note that when $\left\Vert \cdot\right\Vert =\left\Vert \cdot\right\Vert _{2}$
and $\psi(x)=\frac{1}{2}\left\Vert x\right\Vert _{2}^{2}$, Algorithm
\ref{alg:algo-md} is totally the same as Algorithm \ref{alg:algo}.

\subsection{Generalized Fundamental Lemmas}

In this section, we present the generalized fundamental lemmas used
in the proof. First, recall the notations used in the main text:
\begin{align*}
\Delta_{t}\coloneqq & \Delta_{t}(x_{*});\quad\pa_{t}\coloneqq\E_{t}\left[\hp F(x_{t})\right]\in\pa F(x_{t});\\
\xi_{t}\coloneqq & g_{t}-\pa_{t};\quad\xi_{t}^{u}\coloneqq g_{t}-\E_{t}\left[g_{t}\right];\quad\xi_{t}^{b}=\E_{t}\left[g_{t}\right]-\pa_{t};\\
d_{t}\coloneqq & \left\Vert x_{t}-x_{*}\right\Vert ;\quad D_{t}\coloneqq\max_{s\in\left[t\right]}d_{s};\quad\mathfrak{D}_{t}\coloneqq D_{t}\lor\alpha;
\end{align*}
where $\F_{t}=\sigma(\hp F(x_{1}),\cdots,\hp F(x_{t}))$ is the natural
filtration. $\E_{t}\left[\cdot\right]$ is used to denote $\E\left[\cdot\mid\F_{t-1}\right]$
for brevity. Now we are able to present the general version of Lemmas
\ref{lem:err-bound}, \ref{lem:basic} and \ref{lem:normalize}, which
play the most important roles in the proof. 

The proof of Lemma \ref{lem:err-bound-general} is by extending the
ideas in \cite{liu2023breaking} to general norms. The modification
appears when bounding the term $\E_{t}\left[\|\xi_{t}^{u}\|_{*}^{2}\right]$.
But the final bound is still in the order of $O(\sigma^{p}M_{t}^{2-p})$.
\begin{lem}
\label{lem:err-bound-general}For any $t\in\left[T\right]$, if $M_{t}\geq2G$,
we have
\begin{align*}
\left\Vert \xi_{t}^{u}\right\Vert _{*} & \le2M_{t};\quad\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}\right]\le\begin{cases}
10\sigma^{p}M_{t}^{2-p} & \text{if }\left\Vert \cdot\right\Vert =\left\Vert \cdot\right\Vert _{2}\\
40\sigma^{p}M_{t}^{2-p} & \text{o.w.}
\end{cases};\\
\left\Vert \xi_{t}^{b}\right\Vert _{*} & \le2\sigma^{p}M_{t}^{1-p};\quad\left\Vert \xi_{t}^{b}\right\Vert _{*}^{2}\leq10\sigma^{p}M_{t}^{2-p}.
\end{align*}
\end{lem}
%
\begin{proof}
First, $\|\xi_{t}^{u}\|_{*}\le2M_{t}$ is always true due to 
\[
\left\Vert \xi_{t}^{u}\right\Vert _{*}=\left\Vert g_{t}-\E_{t}\left[g_{t}\right]\right\Vert _{*}\leq\left\Vert g_{t}\right\Vert _{*}+\left\Vert \E_{t}\left[g_{t}\right]\right\Vert _{*}\leq2M_{t}.
\]

Next, let us prove the bound on $\E_{t}\left[\|\xi_{t}^{u}\|_{*}^{2}\right]$.
Note that if $\left\Vert \cdot\right\Vert $ is the general norm,
we have
\begin{align*}
\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}\right]= & \E_{t}\left[\left\Vert g_{t}-\E_{t}\left[g_{t}\right]\right\Vert _{*}^{2}\right]\leq\E_{t}\left[2\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}+2\left\Vert \pa_{t}-\E_{t}\left[g_{t}\right]\right\Vert _{*}^{2}\right]\\
\leq & \E_{t}\left[2\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}+2\E_{t}\left[\left\Vert \pa_{t}-g_{t}\right\Vert _{*}^{2}\right]\right]=4\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\right].
\end{align*}
If $\left\Vert \cdot\right\Vert =\left\Vert \cdot\right\Vert _{2}$,
then $\left\Vert \cdot\right\Vert _{*}=\left\Vert \cdot\right\Vert _{2}$.
In this case, we know
\begin{align*}
\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert _{2}^{2}\right]= & \E_{t}\left[\left\Vert g_{t}-\E_{t}\left[g_{t}\right]\right\Vert _{2}^{2}\right]\\
= & \E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{2}^{2}+2\langle g_{t}-\pa_{t},\pa_{t}-\E_{t}\left[g_{t}\right]\rangle+\left\Vert \pa_{t}-\E_{t}\left[g_{t}\right]\right\Vert _{2}^{2}\right]\\
= & \E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{2}^{2}\right]-\left\Vert \pa_{t}-\E_{t}\left[g_{t}\right]\right\Vert _{2}^{2}\leq\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{2}^{2}\right].
\end{align*}
Thus, there is
\[
\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}\right]\le\begin{cases}
\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\right] & \text{if }\left\Vert \cdot\right\Vert =\left\Vert \cdot\right\Vert _{2}\\
4\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\right] & \text{o.w.}
\end{cases}.
\]
So our next goal is to bound $\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\right]$
by noticing that
\begin{align}
\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\right]= & \E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}\geq M_{t}}+\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}<M_{t}}\right]\nonumber \\
= & \E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}\geq M_{t}}+\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2-p}\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}<M_{t}}\right]\nonumber \\
\overset{(a)}{\leq} & \E_{t}\left[\frac{9}{4}M_{t}^{2}\indi_{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\geq M_{t}/2}+\left(\frac{9}{4}M_{t}\right)^{2-p}\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}<M_{t}}\right]\nonumber \\
\overset{(b)}{\leq} & \frac{9}{4}M_{t}^{2}\cdot\frac{\sigma^{p}}{\left(M_{t}/2\right)^{p}}+\left(\frac{9}{4}\right)^{2-p}M_{t}^{2-p}\cdot\sigma^{p}\leq10\sigma^{p}M_{t}^{2-p}\label{eq:mid}
\end{align}
where $(a)$ is due to $\left\Vert g_{t}-\pa_{t}\right\Vert _{*}\leq\left\Vert g_{t}\right\Vert _{*}+\left\Vert \pa_{t}\right\Vert _{*}\leq M_{t}+M_{t}/2=3M_{t}/2$;
$(b)$ is by using Markov's inequality to get
\[
\E_{t}\left[\mathds{1}_{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\geq M_{t}/2}\right]=\Pr\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\geq\left(M_{t}/2\right)^{p}\mid\F_{t-1}\right]\leq\frac{\sigma^{p}}{\left(M_{t}/2\right)^{p}}
\]
and by Assumption 5' to obtain
\[
\E_{t}\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}<M_{t}}\right]\leq\E_{t}\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\right]\leq\sigma^{p}.
\]
Hence, we know
\[
\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}\right]\le\begin{cases}
10\sigma^{p}M_{t}^{2-p} & \text{if }\left\Vert \cdot\right\Vert =\left\Vert \cdot\right\Vert _{2}\\
40\sigma^{p}M_{t}^{2-p} & \text{o.w.}
\end{cases}.
\]

Then, we prove $\left\Vert \xi_{t}^{b}\right\Vert _{*}\le2\sigma^{p}M_{t}^{1-p}$
by
\begin{align*}
\left\Vert \xi_{t}^{b}\right\Vert _{*}= & \left\Vert \E_{t}\left[g_{t}\right]-\pa_{t}\right\Vert _{*}=\left\Vert \E_{t}\left[g_{t}-\hp F(x_{t})\right]\right\Vert _{*}\\
\leq & \E_{t}\left[\left\Vert g_{t}-\hp F(x_{t})\right\Vert _{*}\right]=\E_{t}\left[\left\Vert \frac{M_{t}}{\left\Vert \hp F(x_{t})\right\Vert _{*}}\hp F(x_{t})-\hp F(x_{t})\right\Vert _{*}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}\geq M_{t}}\right]\\
= & \E_{t}\left[\left(\left\Vert \hp F(x_{t})\right\Vert _{*}-M_{t}\right)\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}\geq M_{t}}\right]\overset{(c)}{\leq}\E_{t}\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\indi_{\left\Vert \hp F(x_{t})\right\Vert _{*}\geq M_{t}}\right]\\
\overset{(d)}{\leq} & \E_{t}\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\indi_{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\geq M_{t}/2}\right]\overset{(e)}{\leq}\E_{t}\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\cdot\left(\frac{2}{M_{t}}\right)^{p-1}\right]\\
\overset{(f)}{\leq} & 2^{p-1}\sigma^{p}M_{t}^{1-p}\leq2\sigma^{p}M_{t}^{1-p}
\end{align*}
where $(c)$ is due to $\left\Vert \hp F(x_{t})\right\Vert _{*}-M_{t}\leq\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}+\left\Vert \pa_{t}\right\Vert _{*}-M_{t}\leq\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}$
when $M_{t}\geq2G$ and $\left\Vert \pa_{t}\right\Vert _{*}\leq G$;
$(d)$ is by 
\begin{align*}
M_{t}\leq & \left\Vert \hp F(x_{t})\right\Vert _{*}\leq\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}+\left\Vert \pa_{t}\right\Vert _{*}\leq\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}+G\\
\leq & \left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}+M_{t}/2\\
\Rightarrow M_{t}/2\leq & \left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}
\end{align*}
which implies 
\[
\mathds{1}_{\left\Vert \hp F(x_{t})\right\Vert _{*}\geq M_{t}}\leq\mathds{1}_{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\geq M_{t}/2};
\]
$(e)$ is by 
\[
\mathds{1}_{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\geq M_{t}/2}\leq\left(\frac{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}}{M_{t}/2}\right)^{p-1}\indi_{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}\geq M_{t}/2}\leq\left(\frac{\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}}{M_{t}/2}\right)^{p-1};
\]
$(f)$ is due to the new Assumption 5', i.e., $\E_{t}\left[\left\Vert \hp F(x_{t})-\pa_{t}\right\Vert _{*}^{p}\right]\leq\sigma^{p}$.

Finally, we show $\left\Vert \xi_{t}^{b}\right\Vert _{*}^{2}\leq10\sigma^{p}M_{t}^{2-p}$.
Note that
\[
\left\Vert \xi_{t}^{b}\right\Vert _{*}^{2}=\left\Vert \E_{t}\left[g_{t}\right]-\pa_{t}\right\Vert _{*}^{2}\leq\E_{t}\left[\left\Vert g_{t}-\pa_{t}\right\Vert _{*}^{2}\right]\leq10\sigma^{p}M_{t}^{2-p}
\]
where the last step is by (\ref{eq:mid}).
\end{proof}

Next, we inroduce Lemma \ref{lem:basic-general}, which will degenerate
to Lemma \ref{lem:basic} when $\|\cdot\|=\|\cdot\|_{2}$ and $\psi(x)=\frac{1}{2}\|x\|_{2}^{2}$. 
\begin{lem}
\label{lem:basic-general}For any $t\in\left[T\right]$, we have
\[
\Delta_{t}+\eta_{t}^{-1}D_{\psi}\left(x_{*},x_{t+1}\right)-\left(\eta_{t}^{-1}-\mu\right)D_{\psi}\left(x_{*},x_{t}\right)\leq\langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}+2\left\Vert \xi_{t}^{b}\right\Vert _{*}^{2}+G^{2}\right).
\]
\end{lem}
%
\begin{proof}
We start with the relative $\mu$-stronogly convexity assumption
\begin{align*}
\Delta_{t}\leq & \langle\pa_{t},x_{t}-x_{*}\rangle-\mu D_{\psi}\left(x_{t},x_{*}\right)\\
= & \langle g_{t},x_{t+1}-x_{*}\rangle+\langle g_{t},x_{t}-x_{t+1}\rangle+\langle\xi_{t},x_{*}-x_{t}\rangle-\mu D_{\psi}\left(x_{t},x_{*}\right)\\
\overset{(a)}{\leq} & \left(\eta_{t}^{-1}-\mu\right)D_{\psi}\left(x_{*},x_{t}\right)-\eta_{t}^{-1}D_{\psi}\left(x_{*},x_{t+1}\right)+\langle\xi_{t},x_{*}-x_{t}\rangle\\
 & +\langle g_{t},x_{t}-x_{t+1}\rangle-\eta_{t}^{-1}D_{\psi}\left(x_{t+1},x_{t}\right)\\
\overset{(b)}{\leq} & \left(\eta_{t}^{-1}-\mu\right)D_{\psi}\left(x_{*},x_{t}\right)-\eta_{t}^{-1}D_{\psi}\left(x_{*},x_{t+1}\right)+\langle\xi_{t},x_{*}-x_{t}\rangle\\
 & +\langle g_{t},x_{t}-x_{t+1}\rangle-\frac{\eta_{t}^{-1}}{2}\left\Vert x_{t}-x_{t+1}\right\Vert ^{2}\\
\overset{(c)}{\leq} & \left(\eta_{t}^{-1}-\mu\right)D_{\psi}\left(x_{*},x_{t}\right)-\eta_{t}^{-1}D_{\psi}\left(x_{*},x_{t+1}\right)+\langle\xi_{t},x_{*}-x_{t}\rangle+\frac{\eta_{t}}{2}\left\Vert g_{t}\right\Vert _{*}^{2}\\
\overset{(d)}{\leq} & \left(\eta_{t}^{-1}-\mu\right)D_{\psi}\left(x_{*},x_{t}\right)-\eta_{t}^{-1}D_{\psi}\left(x_{*},x_{t+1}\right)+\langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}+2\left\Vert \xi_{t}^{b}\right\Vert _{*}^{2}+G^{2}\right)
\end{align*}
where for $(a)$, we use the optimality condition for $x_{t+1}=\argmin_{x\in\dom}\langle g_{t},x-x_{t}\rangle+\frac{1}{\eta_{t}}D_{\psi}(x,x_{t})$
to get for any $x\in\dom$
\begin{align*}
\langle g_{t}+\eta_{t}^{-1}\left(\na\psi(x_{t+1})-\na\psi(x_{t})\right),x_{t+1}-x\rangle\leq & 0\\
\Rightarrow\langle g_{t},x_{t+1}-x\rangle\leq & \eta_{t}^{-1}\langle\na\psi(x_{t})-\na\psi(x_{t+1}),x_{t+1}-x\rangle\\
= & \eta_{t}^{-1}\left(D_{\psi}\left(x,x_{t}\right)-D_{\psi}\left(x,x_{t+1}\right)-D_{\psi}\left(x_{t+1},x_{t}\right)\right).
\end{align*}
$(b)$ is by $D_{\psi}\left(x_{t+1},x_{t}\right)\geq\frac{\left\Vert x_{t}-x_{t+1}\right\Vert ^{2}}{2}$.
In $(c)$, we apply Cauchy--Schwarz inequality to get 
\[
\langle g_{t},x_{t}-x_{t+1}\rangle\leq\frac{\eta_{t}^{-1}}{2}\left\Vert x_{t}-x_{t+1}\right\Vert ^{2}+\frac{\eta_{t}}{2}\left\Vert g_{t}\right\Vert _{*}^{2}.
\]
$(d)$ is by $\left\Vert g_{t}\right\Vert _{*}^{2}\leq2\left\Vert \xi_{t}\right\Vert _{*}^{2}+2\left\Vert \pa_{t}\right\Vert _{*}^{2}\leq2\left\Vert \xi_{t}\right\Vert _{*}^{2}+2G^{2}$
and $\left\Vert \xi_{t}\right\Vert _{*}^{2}\leq2\left\Vert \xi_{t}^{u}\right\Vert _{*}^{2}+2\left\Vert \xi_{t}^{b}\right\Vert _{*}^{2}$.
After rearranging the terms, we finish the proof.
\end{proof}

With the above two lemmas, one can follow almost the same line to
prove the general version of the convergence theorems (except Theorem
\ref{thm:lip-dog-prob}) both in expectation and probability. We leave
this simple extension to the interested reader and finish this section.

\section{A Technical Tool\label{sec:app-tech}}

In this section, we provide a technical tool, Freedman's inequality,
in Lemma \ref{lem:freedman}, the omitted proof of which can be found
in \cite{bennett1962probability,freedman1975tail,dzhaparidze2001bernstein}.
This famous inequality can help us to quantify the concentration phenomenon
of a bounded martingale difference sequence.
\begin{lem}
\label{lem:freedman}(Freedman's inequality) Suppose $X_{t\in\mathbb{N}^{+}}\in\R$
is a martingale difference sequence adapted to the filtration $\F_{t\in\mathbb{N}}$
satisfying $\left|X_{t}\right|\leq R$ almost surely for some constant
$R$. Let $\sigma_{t}^{2}=\E\left[\left|X_{t}\right|{}^{2}\mid\F_{t-1}\right]$,
then for any $a>0$ and $F>0$, there is
\[
\Pr\left[\exists\tau\geq1,\left|\sum_{t=1}^{\tau}X_{t}\right|>a\text{ and }\sum_{t=1}^{\tau}\sigma_{t}^{2}\leq F\right]\leq2\exp\left(-\frac{a^{2}}{2F+2Ra/3}\right).
\]
\end{lem}
%
Next, we provide a simple corollary of Lemma \ref{lem:freedman},
which is easier to use in the analysis. For example, the high-probability
bound of $\sum_{t=1}^{\tau}\eta_{t}^{2}(\|\xi_{t}^{u}\|^{2}-\E_{t}[\|\xi_{t}^{u}\|^{2}])$
in Lemma \ref{lem:xi-u-lip} is done by Corollary \ref{cor:ez-any-freedman-1}.
\begin{cor}
\label{cor:ez-any-freedman-1}Under the same settings in Lemma \ref{lem:freedman}.
If $\sum_{t=1}^{T}\sigma_{t}^{2}\leq F$ with probability $1$ for
some $T\in\N_{+}$, by choosing $a=\frac{R}{3}\log\frac{4}{\delta}+\sqrt{\left(\frac{1}{3}R\log\frac{4}{\delta}\right)^{2}+2F\log\frac{4}{\delta}}$,
we have
\[
\Pr\left[\forall\tau\in\left[T\right],\left|\sum_{t=1}^{\tau}X_{t}\right|\leq\frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\right]\geq1-\frac{\delta}{2}.
\]
\end{cor}
%
For the initial distance adaptive choices, we need the following stronger
version of Corollary \ref{cor:ez-any-freedman-1}.
\begin{cor}
\label{cor:ez-any-freedman-2}Under the same settings in Lemma \ref{lem:freedman}.
If $\sum_{t=1}^{T}\sigma_{t}^{2}\leq F$ with probability $1$ for
any $T\geq1$, by choosing $a=\frac{R}{3}\log\frac{4}{\delta}+\sqrt{\left(\frac{1}{3}R\log\frac{4}{\delta}\right)^{2}+2F\log\frac{4}{\delta}}$,
we have
\[
\Pr\left[\forall\tau\geq1,\left|\sum_{t=1}^{\tau}X_{t}\right|\leq\frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\right]\geq1-\frac{\delta}{2}.
\]
\end{cor}
%

\section{Missing Proofs in Section \ref{sec: analysis}\label{sec:app-missing-proofs}}

In this section, we provide the missing proofs in Section \ref{sec: analysis}.

\subsection{Proof of Lemma \ref{lem:basic-lip-prob}}

\begin{proof}
We first invoke Lemma \ref{lem:basic} for $\mu=0$ to get
\[
\Delta_{t}+\frac{\eta_{t}^{-1}}{2}d_{t+1}^{2}-\frac{\eta_{t}^{-1}}{2}d_{t}^{2}\leq\langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right).
\]
Multiplying both sides by $\eta_{t}/\mathfrak{D}_{t}$, we obtain
\begin{align}
\frac{\eta_{t}\Delta_{t}}{\mathfrak{D}_{t}}+\frac{d_{t+1}^{2}-d_{t}^{2}}{2\mathfrak{D}_{t}}\leq & \eta_{t}\left\langle \xi_{t},\frac{x_{*}-x_{t}}{\mathfrak{D}_{t}}\right\rangle +\frac{\eta_{t}^{2}}{\mathfrak{D}_{t}}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\nonumber \\
\overset{(a)}{\leq} & \eta_{t}\left\langle \xi_{t},\frac{x_{*}-x_{t}}{\mathfrak{D}_{t}}\right\rangle +\frac{\eta_{t}^{2}}{\alpha}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\nonumber \\
= & \eta_{t}\left\langle \xi_{t},\frac{x_{*}-x_{t}}{\mathfrak{D}_{t}}\right\rangle +\frac{2\eta_{t}^{2}}{\alpha}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\nonumber \\
 & +\frac{\eta_{t}^{2}}{\alpha}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right),\label{eq:lip-prob-1}
\end{align}
where $(a)$ is by $\mathfrak{D}_{\tau}\geq\alpha$. Next, summing
up (\ref{eq:lip-prob-1}) from $t=1$ to $\tau$ , there is
\begin{align*}
\frac{d_{\tau+1}^{2}}{2\mathfrak{D}_{\tau}}-\frac{d_{1}^{2}}{2\mathfrak{D}_{1}}+\sum_{t=2}^{\tau}\left(\frac{1}{2\mathfrak{D}_{t-1}}-\frac{1}{2\mathfrak{D}_{t}}\right)d_{t}^{2}+\sum_{t=1}^{\tau}\frac{\eta_{t}\Delta_{t}}{\mathfrak{D}_{t}}\leq & \sum_{t=1}^{\tau}\eta_{t}\left\langle \xi_{t},\frac{x_{*}-x_{t}}{\mathfrak{D}_{t}}\right\rangle +\frac{2\eta_{t}^{2}}{\alpha}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\\
 & +\sum_{t=1}^{\tau}\frac{\eta_{t}^{2}}{\alpha}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right),
\end{align*}
which yields
\begin{align*}
\frac{d_{\tau+1}^{2}}{2\mathfrak{D}_{\tau}}-\frac{d_{1}^{2}}{2\mathfrak{D}_{1}}+\sum_{t=1}^{\tau}\frac{\eta_{t}\Delta_{t}}{\mathfrak{D}_{t}}\leq & \sum_{t=1}^{\tau}\eta_{t}\left\langle \xi_{t},\frac{x_{*}-x_{t}}{\mathfrak{D}_{t}}\right\rangle +\frac{2\eta_{t}^{2}}{\alpha}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\\
 & +\sum_{t=1}^{\tau}\frac{\eta_{t}^{2}}{\alpha}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)
\end{align*}
by noticing that $\mathfrak{D}_{t}\geq\mathfrak{D}_{t-1}$. Finally,
by using $\mathfrak{D}_{1}\geq d_{1}$, $\mathfrak{D}_{\tau}\geq\mathfrak{D}_{t}$
for $t\leq\tau$ and rearranging the terms, we know
\begin{align*}
d_{\tau+1}^{2}+\sum_{t=1}^{\tau}2\eta_{t}\Delta_{t}\leq & \mathfrak{D}_{\tau}\left(\sum_{t=1}^{\tau}2\eta_{t}\left\langle \xi_{t},\frac{x_{*}-x_{t}}{\mathfrak{D}_{t}}\right\rangle +\frac{4\eta_{t}^{2}}{\alpha}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\right)\\
 & +\mathfrak{D}_{\tau}\left(d_{1}+\sum_{t=1}^{\tau}\frac{2\eta_{t}^{2}}{\alpha}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\right).
\end{align*}

Now we bound $\E_{t}[\|\xi_{t}^{u}\|^{2}]\le10\sigma^{p}M_{t}^{2-p}$
and $\|\xi_{t}^{b}\|^{2}\le10\sigma^{p}M_{t}^{2-p}$ by Lemma \ref{lem:err-bound}
to get
\begin{align*}
2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}\leq & 40\sigma^{p}M_{t}^{2-p}.
\end{align*}
Hence, we have
\begin{align*}
\frac{2\eta_{t}^{2}}{\alpha}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\leq & \frac{2\eta_{t}^{2}}{\alpha}\left(40\sigma^{p}M_{t}^{2-p}+G^{2}\right)\\
\leq & \frac{80\sigma^{p}(\eta_{t}M_{t})^{2}}{\alpha M_{t}^{p}}+\frac{2\eta_{t}^{2}G^{2}}{\alpha}\\
\overset{(b)}{\leq} & \frac{80\alpha(\sigma/M)^{p}}{t}+\frac{2\alpha}{t}\\
\Rightarrow\sum_{t=1}^{\tau}\frac{2\eta_{t}^{2}}{\alpha}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\leq & 2\left(1+40(\sigma/M)^{p}\right)\alpha\log(e\tau)=h(\tau)
\end{align*}
where $(b)$ is by $\eta_{t}M_{t}\leq\alpha$ from Lemma \ref{lem:normalize},
$M_{t}\geq Mt^{\frac{1}{p}}$ and $\eta_{t}\leq\frac{\alpha}{G\sqrt{t}}$
from our choices.
\end{proof}


\subsection{Proof of Lemma \ref{lem:lip-prob-concen}}

\begin{proof}
We first note that $Z_{t}\coloneqq\eta_{t}\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathfrak{D}_{t}}\right\rangle \in\F_{t},\forall t\in\left[T\right]$
is a martingale difference sequence. Next, observe that
\begin{align*}
\left|Z_{t}\right|\leq & \eta_{t}\left\Vert \xi_{t}^{u}\right\Vert \frac{d_{t}}{\mathfrak{D}_{t}}\overset{(a)}{\leq}\eta_{t}\left\Vert \xi_{t}^{u}\right\Vert \overset{(b)}{\leq}2\eta_{t}M_{t}\overset{(c)}{\leq}2\alpha;\\
\E_{t}\left[\left(Z_{t}\right)^{2}\right]= & \E_{t}\left[\eta_{t}^{2}\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathfrak{D}_{t}}\right\rangle ^{2}\right]\leq\eta_{t}^{2}\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\overset{(d)}{\leq}10\eta_{t}^{2}\sigma^{p}M_{t}^{2-p}\overset{(e)}{\leq}\frac{10(\sigma/M)^{p}\alpha^{2}}{t};
\end{align*}
where $(a)$ is due to $d_{t}\leq\mathfrak{D}_{t}$; $\|\xi_{t}^{u}\|\leq2M_{t}$
in $(b)$ and $\E_{t}[\|\xi_{t}^{u}\|^{2}]\leq10\sigma^{p}M_{t}^{2-p}$
in $(d)$ are both by Lemma \ref{lem:err-bound}; $\eta_{t}M_{t}\leq\alpha$
in $(c)$ is by Lemma \ref{lem:normalize}; $\eta_{t}^{2}\sigma^{p}M_{t}^{2-p}\leq(\sigma/M)^{p}\alpha^{2}/t$
in $(e)$ is by $\eta_{t}M_{t}\leq\alpha$ from Lemma \ref{lem:normalize}
again and $M_{t}\geq Mt^{\frac{1}{p}}$ from our choice.

Now we know
\[
\sum_{t=1}^{T}\E_{t}\left[\left(Z_{t}\right)^{2}\right]\leq\sum_{t=1}^{T}\frac{10(\sigma/M)^{p}\alpha^{2}}{t}\leq10(\sigma/M)^{p}\alpha^{2}\log(eT)
\]
Let $R=2\alpha$, $F=10(\sigma/M)^{p}\alpha^{2}\log(eT)$. By Freedman's
inequality (Corollary \ref{cor:ez-any-freedman-1}), we know with
probability at least $1-\frac{\delta}{2}$, for any $\tau\in\left[T\right]$
\begin{align*}
\left|\sum_{t=1}^{\tau}Z_{t}\right|\leq & \frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\\
= & \frac{4\alpha}{3}\log\frac{4}{\delta}+\sqrt{20(\sigma/M)^{p}\alpha^{2}\log(eT)\log\frac{4}{\delta}}\\
\leq & 5\left(\log\frac{4}{\delta}+\sqrt{(\sigma/M)^{p}\log(eT)\log\frac{4}{\delta}}\right)\alpha.
\end{align*}
\end{proof}


\subsection{Proof of Lemma \ref{lem:xi-u-lip}}

\begin{proof}
We first note that $\eta_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\in\F_{t}$
is a martingale difference sequence. Next, observe that
\begin{align*}
\eta_{t}^{2}\left|\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right|\leq & \eta_{t}^{2}\left\Vert \xi_{t}^{u}\right\Vert ^{2}+\eta_{t}^{2}\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\overset{(a)}{\leq}8\eta_{t}^{2}M_{t}^{2}\overset{(b)}{\leq}8\alpha^{2};\\
\E_{t}\left[\eta_{t}^{4}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)^{2}\right]\leq & \eta_{t}^{4}\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{4}\right]\overset{(c)}{\leq}\eta_{t}^{4}\cdot4M_{t}^{2}\cdot10\sigma^{p}M_{t}^{2-p}\overset{(d)}{\leq}\frac{40(\sigma/M)^{p}\alpha^{4}}{t};
\end{align*}
where both $(a)$ and $(c)$ are due to Lemma \ref{lem:err-bound}.
$(b)$ is due to Lemma \ref{lem:normalize}. $(d)$ is by Lemma \ref{lem:normalize}
again and $M_{t}\geq Mt^{\frac{1}{p}}$. Now we know
\[
\sum_{t=1}^{T}\E_{t}\left[\eta_{t}^{4}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)^{2}\right]\leq\sum_{t=1}^{T}\frac{40(\sigma/M)^{p}\alpha^{4}}{t}\leq40(\sigma/M)^{p}\alpha^{4}\log(eT).
\]
Let $R=8\alpha^{2}$, $F=40(\sigma/G)^{p}\alpha^{4}\log(eT))$. By
Freedman's inequality (Corollary \ref{cor:ez-any-freedman-1}), we
know with probability at least $1-\frac{\delta}{2}$, for any $\tau\in\left[T\right]$,
\begin{align*}
\sum_{t=1}^{\tau}\eta_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\leq & \frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\\
= & \frac{16\alpha^{2}}{3}\log\frac{4}{\delta}+\sqrt{80(\sigma/M)^{p}\alpha^{4}\log(eT)\log\frac{4}{\delta}}\\
\leq & 9\left(\log\frac{4}{\delta}+\sqrt{(\sigma/M)^{p}\log(eT)\log\frac{4}{\delta}}\right)\alpha^{2}\\
\Rightarrow\sum_{t=1}^{\tau}\frac{\eta_{t}^{2}}{\alpha}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\leq & 9\left(\log\frac{4}{\delta}+\sqrt{(\sigma/M)^{p}\log(eT)\log\frac{4}{\delta}}\right)\alpha.
\end{align*}
\end{proof}


\subsection{Proof of Lemma \ref{lem:basic-lip-exp}}

\begin{proof}
We first invoke Lemma \ref{lem:basic} for $\mu=0$ to get
\[
\Delta_{t}+\frac{\eta_{t}^{-1}}{2}d_{t+1}^{2}-\frac{\eta_{t}^{-1}}{2}d_{t}^{2}\leq\langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right).
\]
Multiplying both sides by $\eta_{t}$, we obtain
\begin{align*}
\eta_{t}\Delta_{t}+\frac{d_{t+1}^{2}-d_{t}^{2}}{2}\leq & \eta_{t}\langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}^{2}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\\
= & \eta_{t}\langle\xi_{t},x_{*}-x_{t}\rangle+2\eta_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\\
 & +\eta_{t}^{2}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right).
\end{align*}
Next, summing up from $t=1$ to $\tau$ , there is
\begin{align*}
\frac{d_{\tau+1}^{2}-d_{1}^{2}}{2}+\sum_{t=1}^{\tau}\eta_{t}\Delta_{t}\leq & \sum_{t=1}^{\tau}\eta_{t}\langle\xi_{t},x_{*}-x_{t}\rangle+2\eta_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\\
 & +\sum_{t=1}^{\tau}\eta_{t}^{2}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right).
\end{align*}
From the proof of Lemma \ref{lem:basic-lip-prob}, we have
\[
\sum_{t=1}^{\tau}\eta_{t}^{2}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\leq\frac{\alpha h(\tau)}{2}.
\]

Hence, there is
\[
\frac{d_{\tau+1}^{2}-d_{1}^{2}}{2}+\sum_{t=1}^{\tau}\eta_{t}\Delta_{t}\leq\frac{\alpha h(\tau)}{2}+\sum_{t=1}^{\tau}\eta_{t}\langle\xi_{t},x_{*}-x_{t}\rangle+2\eta_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right).
\]
Taking expectations on both sides to obtain
\begin{align*}
 & \frac{\E\left[d_{\tau+1}^{2}\right]-\E\left[d_{1}^{2}\right]}{2}+\sum_{t=1}^{\tau}\eta_{t}\E\left[\Delta_{t}\right]\\
\leq & \frac{\alpha h(\tau)}{2}+\sum_{t=1}^{\tau}\eta_{t}\E\left[\langle\xi_{t},x_{*}-x_{t}\rangle\right]+2\eta_{t}^{2}\E\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right]\\
\overset{(a)}{=} & \frac{\alpha h(\tau)}{2}+\sum_{t=1}^{\tau}\eta_{t}\E\left[\langle\xi_{t}^{b},x_{*}-x_{t}\rangle\right]\overset{(b)}{\leq}\frac{\alpha h(\tau)}{2}+\sum_{t=1}^{\tau}\eta_{t}\E\left[\left\Vert \xi_{t}^{b}\right\Vert \left\Vert x_{*}-x_{t}\right\Vert \right]\\
\overset{(c)}{\leq} & \frac{\alpha h(\tau)}{2}+\sum_{t=1}^{\tau}2\eta_{t}\sigma^{p}M_{t}^{1-p}\E\left[\left\Vert x_{*}-x_{t}\right\Vert \right]\frac{\alpha h(\tau)}{2}+\sum_{t=1}^{\tau}2\eta_{t}\sigma^{p}M_{t}^{1-p}\sqrt{\E\left[\left\Vert x_{*}-x_{t}\right\Vert ^{2}\right]}\\
= & \frac{\alpha h(\tau)}{2}+\sum_{t=1}^{\tau}2\eta_{t}\sigma^{p}M_{t}^{1-p}\sqrt{\E\left[d_{t}^{2}\right]}
\end{align*}
where we use 
\[
\E\left[\langle\xi_{t},x_{*}-x_{t}\rangle\right]=\E\left[\E_{t}\left[\langle\xi_{t},x_{*}-x_{t}\rangle\right]\right]=\E\left[\langle\E_{t}\left[\xi_{t}\right],x_{*}-x_{t}\rangle\right]=\E\left[\langle\xi_{t}^{b},x_{*}-x_{t}\rangle\right]
\]
and $\E[\|\xi_{t}^{u}\|^{2}]=\E[\E_{t}[\|\xi_{t}^{u}\|^{2}]]$ in
$(a)$; $\langle\xi_{t}^{b},x_{*}-x_{t}\rangle\leq\|\xi_{t}^{b}\|\|x_{*}-x_{t}\|$
in $(b)$ is due to Cauchy--Schwarz inequality; The bound of $\|\xi_{t}^{b}\|\leq2\sigma^{p}M_{t}^{1-p}$
in $(c)$ is from Lemma \ref{lem:err-bound}. $(d)$ is because of
$\E\left[X\right]\leq\sqrt{\E\left[X^{2}\right]}$. Fianlly, we use
\[
2\eta_{t}\sigma^{p}M_{t}^{1-p}=\frac{2\sigma^{p}\eta_{t}M_{t}}{M_{t}^{p}}\leq\frac{2(\sigma/M)^{p}\alpha}{t}
\]
 to finish the proof.
\end{proof}


\section{Additional Theoretical Analysis for Initial Distance Adaptive Choices
When $\mu=0$\label{sec:app-dog}}

First we prove Fact \ref{fact:dog-order}

\begin{proof}
When $w_{t}=1+\log^{2}(t)$, note that
\[
\sum_{t=1}^{T}\frac{1}{tw_{t}}\leq\frac{1}{w_{1}}+\int_{1}^{\infty}\frac{1}{t(1+\log^{2}(t))}\mathrm{d}t=1+\arctan(\log(t))\big\vert_{1}^{\infty}=1+\frac{\pi}{2}=W.
\]

When $w_{t}=\left[y^{(n+1)}(t)\right]^{1+\varepsilon}\prod_{i=1}^{n}y^{(i)}(t)$
where $y(t)=1+\log(t)$, $y^{(n)}(t)=y(y^{(n-1)}(t))$ is the $n$-times
composition with itself for some non-negative integer $n$, and $\varepsilon>0$
can be chosen arbitrarily, note that
\[
\sum_{t=1}^{T}\frac{1}{tw_{t}}\leq\frac{1}{w_{1}}+\int_{1}^{\infty}\frac{1}{tw_{t}}\mathrm{d}t=1+\left(-\frac{1}{\varepsilon}\left[y^{(n+1)}(t)\right]^{-\varepsilon}\right)\big\vert_{1}^{\infty}=1+\frac{1}{\varepsilon}=W.
\]
\end{proof}

Now let's start the proof of Theorem \ref{thm:lip-dog-prob}. We begin
with the following basic inequality.
\begin{lem}
\label{lem:basic-dog}When $\mu=0$, under the choices described in
Theorem \ref{thm:lip-dog-prob}, for any $\tau\geq1$, we have
\begin{align*}
d_{\tau+1}^{2}-d_{1}^{2}+\sum_{t=1}^{\tau}2r_{t}\gamma_{t}\Delta_{t}\leq & 4D_{\tau}r_{\tau}\max_{t\in\left[\tau\right]}\left|\sum_{s=1}^{t}\gamma_{s}\left\langle \xi_{s}^{u},\frac{x_{*}-x_{s}}{D_{s}}\right\rangle \right|+2r_{\tau}^{2}\sum_{t=1}^{\tau}\gamma_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\\
 & +4D_{\tau}r_{\tau}\alpha_{2}\log(4/\delta)W+r_{\tau}^{2}\left(80\alpha_{2}^{2}\log(4/\delta)+2\alpha_{1}^{2}\right)W.
\end{align*}
\end{lem}
%
\begin{proof}
For any fixed $\tau\geq1$, we first invoke Lemma \ref{lem:basic}
for $\mu=0$ to get
\begin{align*}
\Delta_{t}+\frac{\eta_{t}^{-1}}{2}d_{t+1}^{2}-\frac{\eta_{t}^{-1}}{2}d_{t}^{2} & \leq\langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right).
\end{align*}
Multiplying both sides by $2\eta_{t}=2r_{t}\gamma_{t}$, we obtain
\begin{align*}
2r_{t}\gamma_{t}\Delta_{t}+d_{t+1}^{2}-d_{t}^{2}\leq & 2\eta_{t}\left\langle \xi_{t},x_{*}-x_{t}\right\rangle +2\eta_{t}^{2}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\\
= & 2r_{t}\gamma_{t}\left\langle \xi_{t}^{u},x_{*}-x_{t}\right\rangle +2r_{t}\gamma_{t}\left\langle \xi_{t}^{b},x_{*}-x_{t}\right\rangle \\
 & +2r_{t}^{2}\gamma_{t}^{2}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\\
\overset{(a)}{\leq} & 2D_{t}r_{t}\gamma_{t}\left\langle \xi_{t},\frac{x_{*}-x_{t}}{D_{t}}\right\rangle +2D_{\tau}r_{\tau}\gamma_{t}\left\Vert \xi_{t}^{b}\right\Vert \\
 & +2r_{\tau}^{2}\gamma_{t}^{2}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\\
= & 2D_{t}r_{t}\gamma_{t}\left\langle \xi_{t},\frac{x_{*}-x_{t}}{D_{t}}\right\rangle +2D_{\tau}r_{\tau}\gamma_{t}\left\Vert \xi_{t}^{b}\right\Vert \\
 & +2r_{\tau}^{2}\gamma_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)+2r_{\tau}^{2}\gamma_{t}^{2}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)
\end{align*}
where $(a)$ is by $||x_{t}-x_{*}\|\leq D_{t}\leq D_{\tau}$ and $r_{t}\leq r_{\tau}$
for $t\leq\tau$. Now summing up from $t=1$ to $\tau$ to obtain
\begin{align}
d_{\tau+1}^{2}-d_{1}^{2}+\sum_{t=1}^{\tau}2\mathfrak{r}_{t}\gamma_{t}\Delta_{t}\leq & \sum_{t=1}^{\tau}2D_{t}r_{t}\gamma_{t}\left\langle \xi_{t},\frac{x_{*}-x_{t}}{D_{t}}\right\rangle +D_{\tau}r_{\tau}\sum_{t=1}^{\tau}2\gamma_{t}\left\Vert \xi_{t}^{b}\right\Vert \nonumber \\
 & +r_{\tau}^{2}\sum_{t=1}^{\tau}2\gamma_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\nonumber \\
 & +r_{\tau}^{2}\sum_{t=1}^{\tau}2\gamma_{t}^{2}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right).\label{eq:dog}
\end{align}

By Lemma 5 in \cite{ivgi2023dog}, we have
\begin{equation}
\sum_{t=1}^{\tau}2D_{t}r_{t}\gamma_{t}\left\langle \xi_{t},\frac{x_{*}-x_{t}}{D_{t}}\right\rangle \leq4D_{\tau}r_{\tau}\max_{t\in\left[\tau\right]}\left|\sum_{s=1}^{t}\gamma_{s}\left\langle \xi_{s}^{u},\frac{x_{*}-x_{s}}{D_{s}}\right\rangle \right|.\label{eq:dog-1}
\end{equation}

Then we use $\|\xi_{t}^{b}\|\leq2\sigma^{p}M_{t}^{1-p}$ from Lemma
\ref{lem:err-bound} to obtain
\begin{align}
\sum_{t=1}^{\tau}2\gamma_{t}\left\Vert \xi_{t}^{b}\right\Vert \leq & \sum_{t=1}^{\tau}4\cdot\gamma_{t}M_{t}\cdot\frac{\sigma^{p}}{M_{t}^{p}}\leq\sum_{t=1}^{\tau}4\cdot\alpha_{2}\cdot\frac{\log(4/\delta)}{tw_{t}}\leq4\alpha_{2}\log(4/\delta)W.\label{eq:dog-2}
\end{align}

Next we bound $\E_{t}[\|\xi_{t}^{u}\|^{2}]\le10\sigma^{p}M_{t}^{2-p}$
and $\|\xi_{t}^{b}\|^{2}\le10\sigma^{p}M_{t}^{2-p}$ by Lemma \ref{lem:err-bound}
to get
\begin{align*}
2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}\leq & 40\sigma^{p}M_{t}^{2-p}.
\end{align*}
Hence, there is
\begin{align}
2\gamma_{t}^{2}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\leq & 2\gamma_{t}^{2}\left(40\sigma^{p}M_{t}^{2-p}+G^{2}\right)\nonumber \\
\leq & 80(\gamma_{t}M_{t})^{2}\cdot\frac{\sigma^{p}}{M_{t}^{p}}+2\gamma_{t}^{2}G^{2}\nonumber \\
\overset{(b)}{\leq} & \frac{80\alpha_{2}^{2}\log(4/\delta)+2\alpha_{1}^{2}}{tw_{t}}\nonumber \\
\Rightarrow\sum_{t=1}^{\tau}2\gamma_{t}^{2}\left(2\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\leq & \sum_{t=1}^{\tau}\frac{80\alpha_{2}^{2}\log(4/\delta)+2\alpha_{1}^{2}}{tw_{t}}\nonumber \\
= & \left(80\alpha_{2}^{2}\log(4/\delta)+2\alpha_{1}^{2}\right)W\label{eq:dog-3}
\end{align}
where $(b)$ is by $\gamma_{t}\leq\frac{\alpha_{2}}{M_{t}}$, $M_{t}\geq\sigma(tw_{t}/\log(4/\delta)){}^{\frac{1}{p}}$
and $\gamma_{t}\leq\frac{\alpha_{1}}{G\sqrt{tw_{t}}}$ from our choices.

Finally, plugging (\ref{eq:dog-1}), (\ref{eq:dog-2}) and (\ref{eq:dog-3})
into (\ref{eq:dog}), we obtain
\begin{align*}
d_{\tau+1}^{2}-d_{1}^{2}+\sum_{t=1}^{\tau}2\mathfrak{r}_{t}\gamma_{t}\Delta_{t}\leq & 4D_{\tau}r_{\tau}\max_{t\in\left[\tau\right]}\left|\sum_{s=1}^{t}\gamma_{s}\left\langle \xi_{s}^{u},\frac{x_{*}-x_{s}}{D_{s}}\right\rangle \right|+2r_{\tau}^{2}\sum_{t=1}^{\tau}\gamma_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\\
 & +4D_{\tau}r_{\tau}\alpha_{2}\log(4/\delta)W+r_{\tau}^{2}\left(80\alpha_{2}^{2}\log(4/\delta)+2\alpha_{1}^{2}\right)W.
\end{align*}
\end{proof}

Next, as before, we bound the martingale difference sequences$|\sum_{s=1}^{t}\gamma_{s}\langle\xi_{s}^{u},\frac{x_{*}-x_{s}}{D_{s}}\rangle|$
and $\sum_{t=1}^{\tau}\gamma_{t}^{2}(\|\xi_{t}^{u}\|^{2}-\E_{t}[\|\xi_{t}^{u}\|^{2}])$
respectively.
\begin{lem}
\label{lem:dog-inner}When $\mu=0$, under the choices described in
Theorem \ref{thm:lip-dog-prob}, we have with probability at least
$1-\frac{\delta}{2}$, for any $\tau\geq1$,
\[
\left|\sum_{t=1}^{\tau}\gamma_{t}\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{D_{t}}\right\rangle \right|\leq\alpha_{2}\left(\frac{4}{3}+2\sqrt{5W}\right)\log\frac{4}{\delta}.
\]
\end{lem}
%
\begin{proof}
Note that $Z_{t}\coloneqq\gamma_{t}\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{D_{t}}\right\rangle \in\F_{t}$
is a martingale difference sequence. Besides, there is
\begin{align*}
\left|Z_{t}\right| & \leq\gamma_{t}\left\Vert \xi_{t}^{u}\right\Vert \leq\gamma_{t}\cdot2M_{t}\le2\alpha_{2};\\
\E_{t}\left[\left(Z_{t}\right)^{2}\right] & \leq\gamma_{t}^{2}\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\leq\gamma_{t}^{2}\cdot10\sigma^{p}M_{t}^{2-p}\leq\frac{10\alpha_{2}^{2}\log(4/\delta)}{tw_{t}}.
\end{align*}
Note that for any $T\geq1$
\[
\sum_{t=1}^{T}\E_{t}\left[\left(Z_{t}\right)^{2}\right]\leq10\alpha_{2}^{2}\log(4/\delta)\sum_{t=1}^{T}\frac{1}{tw_{t}}\leq10\alpha_{2}^{2}\log(4/\delta)W.
\]
Now let $R=2\alpha_{2}$ and $F=10\alpha_{2}^{2}\log(4/\delta)W$,
by Freedman's inequality (Corollary \ref{cor:ez-any-freedman-2}),
we have with probability at least $1-\frac{\delta}{2}$, for any $\tau\geq1$
\[
\left|\sum_{t=1}^{\tau}\gamma_{t}\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{D_{t}}\right\rangle \right|\leq\frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\leq\alpha_{2}\left(\frac{4}{3}+2\sqrt{5W}\right)\log\frac{4}{\delta}.
\]
\end{proof}

\begin{lem}
\label{lem:dog-xi-u}When $\mu=0$, under the choices described in
Theorem \ref{thm:lip-dog-prob}, we have with probability at least
$1-\frac{\delta}{2}$, for any $\tau\geq1$,
\[
\sum_{t=1}^{\tau}\gamma_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\leq\alpha_{2}^{2}\left(\frac{16}{3}+4\sqrt{5W}\right)\log\frac{4}{\delta}.
\]
\end{lem}
%
\begin{proof}
Note that $Z_{t}\coloneqq\gamma_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\in\F_{t}$
is a martingale difference sequence. Besides, there is
\begin{align*}
\left|Z_{t}\right| & \leq\gamma_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}+\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\leq\gamma_{t}^{2}\cdot8M_{t}^{2}\le8\alpha_{2}^{2};\\
\E_{t}\left[\left(Z_{t}\right)^{2}\right] & \leq\gamma_{t}^{4}\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{4}\right]\leq\gamma_{t}^{4}\cdot4M_{t}^{2}\cdot10\sigma^{p}M_{t}^{2-p}\leq\frac{40\alpha_{2}^{4}\log(4/\delta)}{tw_{t}}
\end{align*}
Note that for any $T\geq1$
\[
\sum_{t=1}^{T}\E_{t}\left[\left(Z_{t}\right)^{2}\right]\leq40\alpha_{2}^{2}\log(4/\delta)\sum_{t=1}^{T}\frac{1}{tw_{t}}\leq40\alpha_{2}^{4}\log(4/\delta)W.
\]
Now let $R=8\alpha_{2}^{2}$ and $F=40\alpha_{2}^{4}\log(4/\delta)W$,
by Freedman's inequality (Corollary \ref{cor:ez-any-freedman-2}),
we have with probability at least $1-\frac{\delta}{2}$, for any $\tau\geq1$
\[
\sum_{t=1}^{\tau}\gamma_{t}^{2}\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)\leq\frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\leq\alpha_{2}^{2}\left(\frac{16}{3}+4\sqrt{5W}\right)\log\frac{4}{\delta}.
\]
\end{proof}

The next inequality is inspired by Lemma 3 in \cite{ivgi2023dog}.
Our result is slightly tighter than the bound given in \cite{ivgi2023dog}.
\begin{lem}
\label{lem:dog-sequnce}Suppose $y_{t\geq1}>0$ is a non-decreasing
sequence, then for any $T\geq1$, there is
\[
\max_{t\in\left[T\right]}\sum_{s=1}^{t}\frac{y_{s}}{y_{t+1}}\geq\frac{T}{\left(\frac{y_{T+1}}{y_{1}}\right)^{\frac{1}{T}}\left(1+\log\frac{y_{T+1}}{y_{1}}\right)}.
\]
\end{lem}
%
\begin{proof}
Let $Y_{t}=\sum_{s=1}^{t}\frac{y_{s}}{y_{t+1}}$ where $Y_{0}=0$,
then we have
\begin{align*}
y_{t+1}Y_{t}-y_{t}Y_{t-1}= & y_{t}\\
\Rightarrow Y_{t}-\frac{y_{t}}{y_{t+1}}Y_{t-1}= & \frac{y_{t}}{y_{t+1}}.
\end{align*}
Summing up from $t=1$ to $T$ to get
\begin{align*}
Y_{T}+\sum_{t=1}^{T-1}\left(1-\frac{y_{t+1}}{y_{t+2}}\right)Y_{t}= & \sum_{t=1}^{T}\frac{y_{t}}{y_{t+1}}\overset{(a)}{\geq}T\left(\frac{y_{1}}{y_{T+1}}\right)^{\frac{1}{T}}\\
\Rightarrow\left(\max_{t\in\left[T\right]}Y_{t}\right)\left(1+\sum_{t=1}^{T-1}1-\frac{y_{t+1}}{y_{t+2}}\right)\geq & T\left(\frac{y_{1}}{y_{T+1}}\right)^{\frac{1}{T}}.
\end{align*}
Where $(a)$ is due to AM-GM inequality. Now by using $1-\frac{1}{x}\leq\log x$,
we obtain
\[
\sum_{t=1}^{T-1}1-\frac{y_{t+1}}{y_{t+2}}\leq\sum_{t=1}^{T-1}\log\frac{y_{t+2}}{y_{t+1}}=\log\frac{y_{T+1}}{y_{2}}\leq\log\frac{y_{T+1}}{y_{1}}.
\]
Finally, we conclude
\begin{align*}
\left(\max_{t\in\left[T\right]}Y_{t}\right)\left(1+\log\frac{y_{T+1}}{y_{1}}\right)\geq & T\left(\frac{y_{1}}{y_{T+1}}\right)^{\frac{1}{T}}\\
\Rightarrow\max_{t\in\left[T\right]}Y_{t}\geq & \frac{T}{\left(\frac{y_{T+1}}{y_{1}}\right)^{\frac{1}{T}}\left(1+\log\frac{y_{T+1}}{y_{1}}\right)}.
\end{align*}
\end{proof}

Now we are ready to prove Theorem \ref{thm:lip-dog-prob}.

\begin{proof}[Proof of Theorem \ref{thm:lip-dog-prob}]
By Applying Lemma \ref{lem:basic-dog}, \ref{lem:dog-inner} and
\ref{lem:dog-xi-u}, we have with probability at least $1-\delta$,
for any $\tau\geq1$
\begin{align*}
d_{\tau+1}^{2}-d_{1}^{2}+\sum_{t=1}^{\tau}2r_{t}\gamma_{t}\Delta_{t}\leq & D_{\tau}r_{\tau}\alpha_{2}\left(\frac{16}{3}+8\sqrt{5W}\right)\log\frac{4}{\delta}+r_{\tau}^{2}\alpha_{2}^{2}\left(\frac{32}{3}+8\sqrt{5W}\right)\log\frac{4}{\delta}\\
 & +4D_{\tau}r_{\tau}\alpha_{2}\log(4/\delta)W+r_{\tau}^{2}\left(80\alpha_{2}^{2}\log(4/\delta)+2\alpha_{1}^{2}\right)W\\
= & D_{\tau}r_{\tau}\alpha_{2}\left(\frac{16}{3}+8\sqrt{5W}+4W\right)\log\frac{4}{\delta}+r_{\tau}^{2}\left[2\alpha_{1}^{2}W+\alpha_{2}^{2}\left(\frac{32}{3}+8\sqrt{5W}+80W\right)\log\frac{4}{\delta}\right].
\end{align*}
Note that we choose
\begin{align*}
\alpha_{1} & =\frac{1}{\sqrt{32W}}\Rightarrow2\alpha_{1}^{2}W=\frac{1}{16};\\
\alpha_{2} & =\frac{1}{8\left(\frac{16}{3}+8\sqrt{5W}+4W\right)\log\frac{4}{\delta}}\land\frac{1}{\sqrt{16\left(\frac{32}{3}+8\sqrt{5W}+80W\right)\log\frac{4}{\delta}}}\\
 & \Rightarrow\begin{cases}
\alpha_{2}\left(\frac{16}{3}+8\sqrt{5W}+4W\right)\log\frac{4}{\delta}\leq\frac{1}{8}\\
\alpha_{2}^{2}\left(\frac{32}{3}+8\sqrt{5W}+80W\right)\log\frac{4}{\delta}\leq\frac{1}{16}
\end{cases}.
\end{align*}
Hence, there is
\begin{equation}
d_{\tau+1}^{2}-d_{1}^{2}+\sum_{t=1}^{\tau}2\mathfrak{r}_{t}\gamma_{t}\Delta_{t}\leq\frac{D_{\tau}r_{\tau}+r_{\tau}^{2}}{8}.\label{eq:dog-final}
\end{equation}
Recall that 
\begin{align*}
r_{t}= & \left(\max_{s\in\left[t\right]}\|x_{1}-x_{s}\|\right)\lor r\leq\left(\max_{s\in\left[t\right]}\|x_{s}-x_{*}\|+d_{1}\right)\lor r=\left(D_{t}+d_{1}\right)\lor r.
\end{align*}
Thus
\begin{align*}
\frac{D_{\tau}r_{\tau}+r_{\tau}^{2}}{8}\leq & \frac{D_{\tau}\left[\left(D_{\tau}+d_{1}\right)\lor r\right]+\left[\left(D_{\tau}+d_{1}\right)\lor r\right]^{2}}{8}\\
\leq & \frac{\left[\left(D_{\tau}+d_{1}\right)\lor r\right]^{2}}{4}\leq\frac{D_{\tau}^{2}+d_{1}^{2}+r^{2}/2}{2}
\end{align*}
which implies
\begin{align*}
d_{\tau+1}^{2}-d_{1}^{2}+\sum_{t=1}^{\tau}2r_{t}\gamma_{t}\Delta_{t}\leq & \frac{D_{\tau}^{2}+d_{1}^{2}+r^{2}/2}{2}\\
\Rightarrow d_{\tau+1}^{2}+\sum_{t=1}^{\tau}2r_{t}\gamma_{t}\Delta_{t}\leq & \frac{D_{\tau}^{2}+3d_{1}^{2}+r^{2}/2}{2}.
\end{align*}

Noticing that $\sum_{t=1}^{\tau}2\mathfrak{r}_{t}\gamma_{t}\Delta_{t}\geq0,\forall\tau\geq1$,
then by a simple induction, we have for any $\tau\geq1$
\[
d_{\tau+1}^{2}\leq3d_{1}^{2}+r^{2}/2,
\]
which immediately implies $D_{\tau}^{2}\leq3d_{1}^{2}+r^{2}/2$. As
a consequence, there are
\[
d_{\tau}=(d_{1}+r),D_{\tau}=O(d_{1}+r),r_{\tau}=O(d_{1}+r),\forall\tau\geq1.
\]
Now we employ (\ref{eq:dog-final}) again to get for any $\tau\geq1$
\begin{align*}
\sum_{t=1}^{\tau}2r_{t}\gamma_{t}\Delta_{t}\leq & \frac{D_{\tau}r_{\tau}+r_{\tau}^{2}}{8}+d_{1}^{2}-d_{\tau+1}^{2}\\
= & \frac{D_{\tau}r_{\tau}+r_{\tau}^{2}}{8}+\left(d_{1}-d_{\tau+1}\right)\left(d_{1}+d_{\tau+1}\right)\\
\leq & \frac{D_{\tau}r_{\tau}+r_{\tau}^{2}}{8}+\left\Vert x_{1}-x_{\tau+1}\right\Vert \left(d_{1}+d_{\tau+1}\right)\\
\leq & \left(\frac{D_{\tau}+r_{\tau}}{8}+d_{1}+d_{\tau+1}\right)r_{\tau+1}\\
\leq & \left(\frac{D_{\tau}+\left(D_{\tau}+d_{1}\right)\lor r}{8}+d_{1}+d_{\tau+1}\right)r_{\tau+1}\\
= & O(d_{1}+r)r_{\tau+1}.
\end{align*}
Recall that
\[
\gamma_{t}=\frac{\alpha_{1}}{G\sqrt{tw_{t}}}\land\frac{\alpha_{2}}{M_{t}},M_{t}=2G\lor\sigma(tw_{t}/\log(4/\delta)){}^{\frac{1}{p}},w_{t}\text{ is non-decreasing}.
\]
So we have
\[
2\gamma_{\tau}\sum_{t=1}^{\tau}r_{t}\Delta_{t}\leq\sum_{t=1}^{\tau}2r_{t}\gamma_{t}\Delta_{t}\leq O(d_{1}+r)r_{\tau+1}\Rightarrow F(\bar{x}_{\tau})-F(x_{*})\leq\frac{O(d_{1}+r)}{\gamma_{\tau}\sum_{t=1}^{\tau}\frac{r_{t}}{r_{\tau+1}}}
\]
where $\bar{x}_{\tau}=\frac{\sum_{t=1}^{\tau}r_{t}x_{t}}{\sum_{t=1}^{\tau}r_{t}}$.

Now we have with probability at least $1-\delta$, for any $T\geq1$
(relabeling $\tau$ by $T$)
\[
F(\bar{x}_{T})-F(x_{*})\leq\frac{O(d_{1}+r)}{\gamma_{T}\sum_{t=1}^{T}\frac{r_{t}}{r_{T+1}}}.
\]
Invoking Lemma \ref{lem:dog-sequnce} for $r_{t}$ to get
\[
\sum_{t=1}^{I(T)}\frac{r_{t}}{r_{I(T)+1}}\geq\frac{T}{\left(\frac{r_{T+1}}{r_{1}}\right)^{\frac{1}{T}}\left(1+\log\frac{r_{T+1}}{r_{1}}\right)}=\frac{T}{\left(\frac{r_{T+1}}{r}\right)^{\frac{1}{T}}\left(1+\log\frac{r_{T+1}}{r}\right)}\geq\frac{T}{O\left(\left(\frac{r+d_{1}}{r}\right)^{\frac{1}{T}}\left(1+\log\frac{r+d_{1}}{r}\right)\right)}
\]
where $I(T)\in\mathrm{argmax}_{t\in\left[T\right]}\sum_{s=1}^{t}\frac{r_{s}}{r_{t+1}}$
and the last inequality holds because $r_{T+1}=O(d_{1}+r)$ is uniformly
upper bounded. Then
\begin{align*}
F(\bar{x}_{I(T)})-F(x_{*})\leq & O\left(\left(1+\log\frac{r+d_{1}}{r}\right)\left(r+d_{1}\right)\frac{\left(\frac{r+d_{1}}{r}\right)^{\frac{1}{T}}}{T\gamma_{I(T)}}\right)\\
\leq & O\left(\left(1+\log\frac{r+d_{1}}{r}\right)\left(r+d_{1}\right)\frac{\left(\frac{r+d_{1}}{r}\right)^{\frac{1}{T}}}{T\gamma_{T}}\right).
\end{align*}
When $T\geq\Omega(\log\frac{r+d_{1}}{r})$, we have $\left(\frac{r+d_{1}}{r}\right)^{\frac{1}{T}}=O(1)$,
which implies
\[
F(\bar{x}_{I(T)})-F(x_{*})\leq O\left(\left(1+\log\frac{r+d_{1}}{r}\right)\left(r+d_{1}\right)\frac{1}{T\gamma_{T}}\right).
\]
By plugging in
\begin{align*}
M_{t}= & 2G\lor\sigma(tw_{t}/\log(4/\delta)){}^{\frac{1}{p}},\\
\gamma_{t}= & \frac{\alpha_{1}}{G\sqrt{tw_{t}}}\land\frac{\alpha_{2}}{M_{t}},\\
\alpha_{1}= & \frac{1}{\sqrt{32W}},\\
\alpha_{2}= & \frac{1}{8\left(\frac{16}{3}+8\sqrt{5W}+4W\right)\log\frac{4}{\delta}}\land\frac{1}{\sqrt{16\left(\frac{32}{3}+8\sqrt{5W}+80W\right)\log\frac{4}{\delta}}},
\end{align*}
we conclude the proof.
\end{proof}


\section{Additional Theoretical Analysis When $\mu>0$\label{sec:app-str}}

In this section, we aim to prove Theorems \ref{thm:str-prob} and
\ref{thm:str-exp}.

\subsection{High-Probability Analysis When $\mu>0$\label{subsec:app-str-prob}}

To start with, we introduce a basic inequality in Lemma \ref{lem:basic-str-prob}.
\begin{lem}
\label{lem:basic-str-prob}When $\mu>0$, under the choices of $M_{t}=2G\lor Mt^{\frac{1}{p}}$
and $\eta_{t}=\frac{4}{\mu(t+1)}$, for any $\tau\in\left[T\right]$,
we have
\begin{align*}
\frac{\mu(\tau+1)\tau}{8}d_{\tau+1}^{2}+\sum_{t=1}^{\tau}t\Delta_{t}\leq & \mathbb{D}_{\tau}\left(\sum_{t=1}^{\tau}t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle +\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)}{\mu C}\right)\\
 & +320\mathbb{D}_{\tau}\left(M\sqrt{(\sigma/M)^{p}+(\sigma/M)^{2p}}T^{\frac{1}{p}}+G\sqrt{1+(\sigma/G)^{p}}\sqrt{T}\right)
\end{align*}
where
\begin{align*}
\mathbb{D}_{t} & \coloneqq C\lor\max_{s\in\left[t\right]}\sqrt{s(s-1)}d_{s};\\
C & \coloneqq\frac{G\sqrt{1+(\sigma/G)^{p}}}{\mu}\sqrt{T}\lor\frac{M\sqrt{(\sigma/M)^{p}+(\sigma/M)^{2p}}}{\mu}T^{\frac{1}{p}}\lor\frac{M_{T}}{\mu}.
\end{align*}
\end{lem}
%
\begin{proof}
We first invoke Lemma \ref{lem:basic} to get
\begin{align}
\Delta_{t}+\frac{\eta_{t}^{-1}}{2}d_{t+1}^{2}-\frac{\eta_{t}^{-1}-\mu}{2}d_{t}^{2}\leq & \langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\nonumber \\
= & \langle\xi_{t}^{b},x_{*}-x_{t}\rangle+\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\nonumber \\
\overset{(a)}{\leq} & \frac{\left\Vert \xi_{t}^{b}\right\Vert ^{2}}{\mu}+\frac{\mu d_{t}^{2}}{4}+\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\nonumber \\
\Rightarrow\Delta_{t}+\frac{\eta_{t}^{-1}}{2}d_{t+1}^{2}-\frac{\eta_{t}^{-1}-\mu/2}{2}d_{t}^{2}\leq & \langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\frac{\left\Vert \xi_{t}^{b}\right\Vert ^{2}}{\mu}+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\label{eq:str-1}
\end{align}
where $(a)$ is by $\langle\xi_{t}^{b},x_{*}-x_{t}\rangle\leq\left\Vert \xi_{t}^{b}\right\Vert ^{2}/\mu+\mu\left\Vert x_{t}-x_{*}\right\Vert ^{2}/4=\left\Vert \xi_{t}^{b}\right\Vert ^{2}/\mu+\mu d_{t}^{2}/4$.
Now, plugging $\eta_{t}=\frac{4}{\mu(t+1)}$ into (\ref{eq:str-1})
and multiplying both sides by $t/\mathbb{D}_{t}$ to obtain
\begin{align}
\frac{t\Delta_{t}}{\mathbb{D}_{t}}+\frac{\mu(t+1)t}{8\mathbb{D}_{t}}d_{t+1}^{2}-\frac{\mu t(t-1)}{8\mathbb{D}_{t}}d_{t}^{2}\leq & t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle +\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}+\left\Vert \xi_{t}^{b}\right\Vert ^{2}\right)+t\left\Vert \xi_{t}^{b}\right\Vert ^{2}+4G^{2}}{\mu\mathbb{D}_{t}}\nonumber \\
\leq & t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle +\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}+\left\Vert \xi_{t}^{b}\right\Vert ^{2}\right)+t\left\Vert \xi_{t}^{b}\right\Vert ^{2}+4G^{2}}{\mu C}\nonumber \\
= & t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle +\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)}{\mu C}\nonumber \\
 & +\frac{8\left(\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+\left\Vert \xi_{t}^{b}\right\Vert ^{2}\right)+t\left\Vert \xi_{t}^{b}\right\Vert ^{2}+4G^{2}}{\mu C}.\label{eq:str-2}
\end{align}

Next, we bound $\E_{t}[\|\xi_{t}^{u}\|^{2}]\le10\sigma^{p}M_{t}^{2-p}$,
$\|\xi_{t}^{b}\|^{2}\leq10\sigma^{p}M_{t}^{2-p}$ and $\|\xi_{t}^{b}\|\le2\sigma^{p}M_{t}^{1-p}$
by using Lemma \ref{lem:err-bound} to get
\begin{align}
 & \frac{8\left(\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+\left\Vert \xi_{t}^{b}\right\Vert ^{2}\right)+t\left\Vert \xi_{t}^{b}\right\Vert ^{2}+4G^{2}}{\mu C}\nonumber \\
\leq & \frac{160\sigma^{p}M_{t}^{2-p}+4t\sigma^{2p}M_{t}^{2-2p}+4G^{2}}{\mu C}\nonumber \\
= & \frac{160\sigma^{p}(2G\lor Mt^{\frac{1}{p}})^{2-p}+4t\sigma^{2p}(2G\lor Mt^{\frac{1}{p}})^{2-2p}+4G^{2}}{\mu C}\nonumber \\
\leq & \frac{\left(160\sigma^{p}M^{2-p}+4\sigma^{2p}M^{2-2p}\right)t^{\frac{2}{p}-1}+320\sigma^{p}G^{2-p}+4G^{2}}{\mu C}\nonumber \\
\leq & 160M\sqrt{(\sigma/M)^{p}+(\sigma/M)^{2p}}\cdot\frac{t^{\frac{2}{p}-1}}{T^{\frac{1}{p}}}+320G\sqrt{1+(\sigma/G)^{p}}\cdot\frac{1}{\sqrt{T}}\label{eq:str-3}
\end{align}

Combining (\ref{eq:str-2}) and (\ref{eq:str-3}) and summing up from
$t=1$ to $\tau$, we have
\begin{align*}
 & \frac{\mu(\tau+1)\tau}{8\mathbb{D}_{\tau}}d_{\tau+1}^{2}+\sum_{t=2}^{\tau}\left(\frac{1}{\mathbb{D}_{t-1}}-\frac{1}{\mathbb{D}_{t}}\right)\frac{\mu t(t-1)}{8}d_{t}^{2}+\sum_{t=1}^{\tau}\frac{t\Delta_{t}}{\mathbb{D}_{t}}\\
\leq & \sum_{t=1}^{\tau}t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle +\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)}{\mu C}\\
 & +\sum_{t=1}^{\tau}160M\sqrt{(\sigma/M)^{p}+(\sigma/M)^{2p}}\cdot\frac{t^{\frac{2}{p}-1}}{T^{\frac{1}{p}}}+320G\sqrt{1+(\sigma/G)^{p}}\cdot\frac{1}{\sqrt{T}}\\
\leq & \sum_{t=1}^{\tau}t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle +\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)}{\mu C}\\
 & +160M\sqrt{(\sigma/M)^{p}+(\sigma/M)^{2p}}\frac{\frac{p}{2}\cdot((\tau+1)^{\frac{2}{p}}-1)}{T^{\frac{1}{p}}}+320G\sqrt{1+(\sigma/G)^{p}}\frac{\tau}{\sqrt{T}}\\
\leq & \sum_{t=1}^{\tau}t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle +\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)}{\mu C}\\
 & +320M\sqrt{(\sigma/M)^{p}+(\sigma/M)^{2p}}T^{\frac{1}{p}}+320G\sqrt{1+(\sigma/G)^{p}}\sqrt{T}.
\end{align*}
Finally, we use $\frac{1}{\mathbb{D}_{t-1}}-\frac{1}{\mathbb{D}_{t}}\geq0$
and $\mathbb{\mathbb{D}_{\tau}\geq}\mathbb{D}_{t},\forall t\leq\tau$
to finish the proof.
\end{proof}

The same as the case of $\mu=0$. Our goal is to find a high-probability
bound of $\sum_{t=1}^{\tau}t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle $
and $\sum_{t=1}^{\tau}\frac{8}{\mu C}(\|\xi_{t}^{u}\|^{2}-\E_{t}[\|\xi_{t}^{u}\|^{2}])$.
Note that both of them are martingale difference sequences, hence,
we can use Freedman's inequality again. The formal results are presented
in the following Lemmas \ref{lem:inner-str} and \ref{lem:xi-u-str}.
\begin{lem}
\label{lem:inner-str}When $\mu>0$, under the choice of $M_{t}=2G\lor Mt^{\frac{1}{p}}$,
we have with probability at least $1-\frac{\delta}{2}$, for any $\tau\in\left[T\right]$,
\[
\sum_{t=1}^{\tau}t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle \leq3G\log\frac{4}{\delta}+13\left(M\log\frac{4}{\delta}+\sqrt{\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}\right)T^{\frac{1}{p}}.
\]
\end{lem}
%
\begin{proof}
We first note that $Z_{t}\coloneqq t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle \in\F_{t}$
is a martingale difference sequence. Next, observe that
\[
\frac{td_{t}}{\mathbb{D}_{t}}\leq\frac{td_{t}}{\sqrt{t(t-1)}d_{t}\lor\frac{G\sqrt{1+(\sigma/G)^{p}}}{\mu}\sqrt{T}}\leq\begin{cases}
\sqrt{\frac{t}{t-1}}\leq2 & t\geq2\\
\frac{d_{1}}{\frac{G}{\mu}}\leq2 & t=1
\end{cases}.
\]
Hence, we know
\[
\left|Z_{t}\right|\leq\left\Vert \xi_{t}^{u}\right\Vert \frac{td_{t}}{\mathbb{D}_{t}}\leq2M_{t}\leq2M_{T}=4G\lor2MT^{\frac{1}{p}}.
\]
Besides, we know
\begin{align*}
\sum_{t=1}^{\tau}\E_{t}\left[Z_{t}^{2}\right]\leq & \sum_{t=1}^{\tau}\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\frac{t^{2}d_{t}^{2}}{\mathbb{D}_{t}^{2}}\right]\leq\sum_{t=1}^{\tau}10\sigma^{p}M_{t}^{2-p}\cdot4\\
= & \sum_{t=1}^{\tau}40\sigma^{p}M_{t}^{2-p}=\sum_{t=1}^{\tau}40\sigma^{p}\cdot\left(2G\lor Mt^{\frac{1}{p}}\right)^{2-p}\\
\leq & \sum_{t=1}^{\tau}80\sigma^{p}G^{2-p}+40\sigma^{p}M^{2-p}t^{\frac{2}{p}-1}\\
\leq & 80\sigma^{p}G^{2-p}\tau+40\sigma^{p}M^{2-p}\cdot\frac{p}{2}\left((\tau+1)^{\frac{2}{p}}-1\right)\\
\leq & 80\sigma^{p}G^{2-p}T+80\sigma^{p}M^{2-p}T^{\frac{2}{p}}\\
\leq & 80\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)T^{\frac{2}{p}}.
\end{align*}
Let $R=4G\lor2MT^{\frac{1}{p}}$, $F=80\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)T^{\frac{2}{p}}$.
By Freedman's inequality (Corollary \ref{cor:ez-any-freedman-1}),
with probability at least $1-\frac{\delta}{2}$, we have
\begin{align*}
\sum_{t=1}^{\tau}Z_{t}\leq & \frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\\
= & \frac{8G\lor4MT^{\frac{1}{p}}}{3}\log\frac{4}{\delta}+\sqrt{160\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}T^{\frac{1}{p}}\\
\leq & 3G\log\frac{4}{\delta}+13\left(M\log\frac{4}{\delta}+\sqrt{\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}\right)T^{\frac{1}{p}}.
\end{align*}
\end{proof}

\begin{lem}
\label{lem:xi-u-str}When $\mu>0$, under the choice of $M_{t}=2G\lor Mt^{\frac{1}{p}}$,
we have with probability at least $1-\frac{\delta}{2}$, for any $\tau\in\left[T\right]$,
\[
\sum_{t=1}^{\tau}\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)}{\mu C}\leq88G\log\frac{4}{\delta}+104\left(M\log\frac{4}{\delta}+\sqrt{\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}\right)T^{\frac{1}{p}}.
\]
\end{lem}
%
\begin{proof}
We first note that $\frac{\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]}{\mu C}\in\F_{t}$
is a martingale difference sequence. Next, observe that
\[
\frac{\left|\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right|}{\mu C}\leq\frac{\left\Vert \xi_{t}^{u}\right\Vert ^{2}+\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]}{\mu C}\leq\frac{8M_{t}^{2}}{\mu C}\leq\frac{8M_{t}^{2}}{M_{T}}\leq8M_{T}=16G\lor8MT^{\frac{1}{p}}.
\]
Besides, we know
\begin{align*}
\sum_{t=1}^{\tau}\E_{t}\left[\frac{\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)^{2}}{\mu^{2}C^{2}}\right]\leq & \sum_{t=1}^{\tau}\frac{\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{4}\right]}{\mu^{2}C^{2}}\leq\sum_{t=1}^{\tau}\frac{4M_{t}^{2}\cdot10\sigma^{p}M_{t}^{2-p}}{M_{T}^{2}}\\
= & \sum_{t=1}^{\tau}40\sigma^{p}M_{t}^{2-p}=\sum_{t=1}^{\tau}40\sigma^{p}\cdot\left(2G\lor Mt^{\frac{1}{p}}\right)^{2-p}\\
\leq & 80\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)T^{\frac{2}{p}}.
\end{align*}
Let $R=16G\lor8MT^{\frac{1}{p}}$, $F=80\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)T^{\frac{2}{p}}$.
By Freedman's inequality (Corollary \ref{cor:ez-any-freedman-1}),
with probability at least $1-\frac{\delta}{2}$, we have
\begin{align*}
\sum_{t=1}^{\tau}\frac{\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]}{\mu C}\leq & \frac{2R}{3}\log\frac{4}{\delta}+\sqrt{2F\log\frac{4}{\delta}}\\
= & \frac{32G\lor16MT^{\frac{1}{p}}}{3}\log\frac{4}{\delta}+\sqrt{160\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}T^{\frac{1}{p}}\\
= & 11G\log\frac{4}{\delta}+13\left(M\log\frac{4}{\delta}+\sqrt{\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}\right)T^{\frac{1}{p}}\\
\Rightarrow\sum_{t=1}^{\tau}\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)}{\mu C}\leq & 88G\log\frac{4}{\delta}+104\left(M\log\frac{4}{\delta}+\sqrt{\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}\right)T^{\frac{1}{p}}.
\end{align*}
\end{proof}

With the above lemmas, we are able to prove Theorem \ref{thm:str-prob}.

\begin{proof}[Proof of Theorem \ref{thm:str-prob}]
We first define a constant $K$ as follows
\begin{align}
K\coloneqq & \frac{\mu C^{2}}{8}+\frac{16}{\mu}\left[91G\log\frac{4}{\delta}+117\left(M\log\frac{4}{\delta}+\sqrt{\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}\right)T^{\frac{1}{p}}\right]^{2}\nonumber \\
 & +\frac{16}{\mu}\left[320\left(M\sqrt{(\sigma/M)^{p}+(\sigma/M)^{2p}}T^{\frac{1}{p}}+G\sqrt{1+(\sigma/G)^{p}}\sqrt{T}\right)\right]^{2}\label{eq:str-prob-def-k}\\
= & O\left(\log^{2}(1/\delta)\left(\frac{G^{2}+\sigma^{2}}{\mu}T+\frac{M^{2}+\sigma^{2p}M^{2-2p}+\sigma^{p}G^{2-p}}{\mu}T^{\frac{2}{p}}\right)\right)\nonumber 
\end{align}
where $C=\frac{G\sqrt{1+(\sigma/G)^{p}}}{\mu}\sqrt{T}\lor\frac{M\sqrt{(\sigma/M)^{p}+(\sigma/M)^{2p}}}{\mu}T^{\frac{1}{p}}\lor\frac{M_{T}}{\mu}$
is defined in Lemma \ref{lem:basic-str-prob}.

We sart with Lemma \ref{lem:basic-str-prob} to get for any $\tau\in\left[T\right]$,
there is
\begin{align}
\frac{\mu(\tau+1)\tau}{8}d_{\tau+1}^{2}+\sum_{t=1}^{\tau}t\Delta_{t}\leq & \mathbb{D}_{\tau}\left(\sum_{t=1}^{\tau}t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle +\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)}{\mu C}\right)\nonumber \\
 & +320\mathbb{D}_{\tau}\left(M\sqrt{(\sigma/M)^{p}+(\sigma/M)^{2p}}T^{\frac{1}{p}}+G\sqrt{1+(\sigma/G)^{p}}\sqrt{T}\right).\label{eq:str-prob}
\end{align}
\begin{itemize}
\item Bounding the term $\sum_{t=1}^{\tau}t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle $:
By Lemma \ref{lem:inner-str}, we have with probability at least $1-\frac{\delta}{2}$,
for any $\tau\in\left[T\right]$:
\begin{equation}
\sum_{t=1}^{\tau}t\left\langle \xi_{t}^{u},\frac{x_{*}-x_{t}}{\mathbb{D}_{t}}\right\rangle \leq3G\log\frac{4}{\delta}+13\left(M\log\frac{4}{\delta}+\sqrt{\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}\right)T^{\frac{1}{p}}.\label{eq:str-prob-inner}
\end{equation}
\item Bounding the term $\sum_{t=1}^{\tau}\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)}{\mu C}$:
By Lemma \ref{lem:xi-u-str}, we have with probability at least $1-\frac{\delta}{2}$,
for any $\tau\in\left[T\right]$:
\begin{equation}
\sum_{t=1}^{\tau}\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}-\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]\right)}{\mu C}\leq88G\log\frac{4}{\delta}+104\left(M\log\frac{4}{\delta}+\sqrt{\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}\right)T^{\frac{1}{p}}.\label{eq:str-prob-xi-u-2}
\end{equation}
\end{itemize}
Combining (\ref{eq:str-prob}), (\ref{eq:str-prob-inner}), (\ref{eq:str-prob-xi-u-2}),
we have with probability at least $1-\delta$, for any $\tau\in\left[T\right]$:
\begin{align*}
\frac{\mu(\tau+1)\tau}{8}d_{\tau+1}^{2}+\sum_{t=1}^{\tau}t\Delta_{t}\leq & \mathbb{D}_{\tau}\left[91G\log\frac{4}{\delta}+117\left(M\log\frac{4}{\delta}+\sqrt{\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}\right)T^{\frac{1}{p}}\right]\\
 & +320\mathbb{D}_{\tau}\left(M\sqrt{(\sigma/M)^{p}+(\sigma/M)^{2p}}T^{\frac{1}{p}}+G\sqrt{1+(\sigma/G)^{p}}\sqrt{T}\right)\\
\leq & \frac{\mu\mathbb{D}_{\tau}^{2}}{16}+\frac{8}{\mu}\left[91G\log\frac{4}{\delta}+117\left(M\log\frac{4}{\delta}+\sqrt{\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}\right)T^{\frac{1}{p}}\right]^{2}\\
 & +\frac{8}{\mu}\left[320\left(M\sqrt{(\sigma/M)^{p}+(\sigma/M)^{2p}}T^{\frac{1}{p}}+G\sqrt{1+(\sigma/G)^{p}}\sqrt{T}\right)\right]^{2}\\
\overset{(a)}{\leq} & \frac{\mu\left(\max_{s\in\left[\tau\right]}s(s-1)d_{s}^{2}+C^{2}\right)}{16}\\
 & +\frac{8}{\mu}\left[91G\log\frac{4}{\delta}+117\left(M\log\frac{4}{\delta}+\sqrt{\left(\sigma^{p}G^{2-p}+\sigma^{p}M^{2-p}\right)\log\frac{4}{\delta}}\right)T^{\frac{1}{p}}\right]^{2}\\
 & +\frac{8}{\mu}\left[320\left(M\sqrt{(\sigma/M)^{p}+(\sigma/M)^{2p}}T^{\frac{1}{p}}+G\sqrt{1+(\sigma/G)^{p}}\sqrt{T}\right)\right]^{2}\\
\overset{(b)}{=} & \frac{\max_{s\in\left[\tau\right]}\frac{\mu s(s-1)}{8}d_{s}^{2}}{2}+\frac{K}{2}
\end{align*}
where $(a)$ is by $\mathbb{D}_{\tau}^{2}=(C\lor\max_{s\in\left[\tau\right]}\sqrt{s(s-1)}d_{s})^{2}\leq\max_{s\in\left[\tau\right]}s(s-1)d_{s}^{2}+C^{2}$;
$(b)$ is due to the definition of $K$ (see (\ref{eq:str-prob-def-k})).
Hence, by using $\Delta_{t}\geq0$, we have for any $\tau\in\left[T\right]$,
\[
\frac{\mu(\tau+1)\tau}{8}d_{\tau+1}^{2}\leq\frac{\max_{s\in\left[\tau\right]}\frac{\mu s(s-1)}{8}d_{s}^{2}}{2}+\frac{K}{2},
\]
which implies $\frac{\mu t(t-1)}{8}d_{t}^{2}\leq K$ for any $t\in\left[T+1\right]$
by simple induction.

Finally, we consider time $T$ to get with probability at least $1-\delta$
\[
\frac{\mu(T+1)T}{8}d_{T+1}^{2}+\sum_{t=1}^{\tau}t\Delta_{t}\leq K.
\]
Note that $F(\bar{x}_{T})-F(x_{*})\leq\frac{2}{T(T+1)}\sum_{t=1}^{T}t\Delta_{t}$
by the convexity of $F$ where $\bar{x}_{T}=\frac{2}{T(T+1)}\sum_{t=1}^{T}tx_{t}$,
we conclude that
\[
\frac{\mu(T+1)T}{8}d_{T+1}^{2}+F(\bar{x}_{T})-F(x_{*})\leq K.
\]
We get the desired result by plugging $K$.
\end{proof}


\subsection{In-Expectaion Analysis When $\mu>0$\label{subsec:app-str-exp}}

The proof of Theorem \ref{thm:str-exp} is inispired by \cite{zhang2020adaptive}.

\begin{proof}[Proof of Theorem \ref{thm:str-exp}]
We first invoke Lemma \ref{lem:basic} to get
\begin{align}
\Delta_{t}+\frac{\eta_{t}^{-1}}{2}d_{t+1}^{2}-\frac{\eta_{t}^{-1}-\mu}{2}d_{t}^{2}\leq & \langle\xi_{t},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\nonumber \\
= & \langle\xi_{t}^{b},x_{*}-x_{t}\rangle+\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\nonumber \\
\overset{(a)}{\leq} & \frac{\left\Vert \xi_{t}^{b}\right\Vert ^{2}}{\mu}+\frac{\mu d_{t}^{2}}{4}+\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\nonumber \\
\Rightarrow\Delta_{t}+\frac{\eta_{t}^{-1}}{2}d_{t+1}^{2}-\frac{\eta_{t}^{-1}-\mu/2}{2}d_{t}^{2}\leq & \langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\frac{\left\Vert \xi_{t}^{b}\right\Vert ^{2}}{\mu}+\eta_{t}\left(2\left\Vert \xi_{t}^{u}\right\Vert ^{2}+2\left\Vert \xi_{t}^{b}\right\Vert ^{2}+G^{2}\right)\label{eq:str-exp-1}
\end{align}
where $(a)$ is by $\langle\xi_{t}^{b},x_{*}-x_{t}\rangle\leq\left\Vert \xi_{t}^{b}\right\Vert ^{2}/\mu+\mu\left\Vert x_{t}-x_{*}\right\Vert ^{2}/4=\left\Vert \xi_{t}^{b}\right\Vert ^{2}/\mu+\mu d_{t}^{2}/4$.
Now, plugging $\eta_{t}=\frac{4}{\mu(t+1)}$ into (\ref{eq:str-exp-1})
and multiplying both sides by $t$ to obtain
\begin{align}
t\Delta_{t}+\frac{\mu(t+1)t}{8}d_{t+1}^{2}-\frac{\mu t(t-1)}{8}d_{t}^{2}\leq & t\langle\xi_{t}^{u},x_{*}-x_{t}\rangle+\frac{8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}+\left\Vert \xi_{t}^{b}\right\Vert ^{2}\right)+t\left\Vert \xi_{t}^{b}\right\Vert ^{2}+4G^{2}}{\mu}\nonumber \\
\Rightarrow\E\left[t\Delta_{t}\right]+\frac{\mu(t+1)t}{8}\E\left[d_{t+1}^{2}\right]-\frac{\mu t(t-1)}{8}\E\left[d_{t}^{2}\right]\leq & \frac{\E\left[8\left(\left\Vert \xi_{t}^{u}\right\Vert ^{2}+\left\Vert \xi_{t}^{b}\right\Vert ^{2}\right)+t\left\Vert \xi_{t}^{b}\right\Vert ^{2}+4G^{2}\right]}{\mu}\nonumber \\
= & \frac{\E\left[8\left(\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+\left\Vert \xi_{t}^{b}\right\Vert ^{2}\right)+t\left\Vert \xi_{t}^{b}\right\Vert ^{2}+4G^{2}\right]}{\mu}.\label{eq:str-exp-2}
\end{align}

Next, we bound $\E_{t}[\|\xi_{t}^{u}\|^{2}]\le10\sigma^{p}M_{t}^{2-p}$,
$\|\xi_{t}^{b}\|^{2}\leq10\sigma^{p}M_{t}^{2-p}$ and $\|\xi_{t}^{b}\|\le2\sigma^{p}M_{t}^{1-p}$
by using Lemma \ref{lem:err-bound} to get
\begin{align}
 & \frac{8\left(\E_{t}\left[\left\Vert \xi_{t}^{u}\right\Vert ^{2}\right]+\left\Vert \xi_{t}^{b}\right\Vert ^{2}\right)+t\left\Vert \xi_{t}^{b}\right\Vert ^{2}+4G^{2}}{\mu}\nonumber \\
\leq & \frac{160\sigma^{p}M_{t}^{2-p}+4t\sigma^{2p}M_{t}^{2-2p}+4G^{2}}{\mu}\nonumber \\
= & \frac{160\sigma^{p}(2G\lor Mt^{\frac{1}{p}})^{2-p}+4t\sigma^{2p}(2G\lor Mt^{\frac{1}{p}})^{2-2p}+4G^{2}}{\mu}\nonumber \\
\leq & \frac{160\sigma^{p}M^{2-p}+4\sigma^{2p}M^{2-2p}}{\mu}t^{\frac{2}{p}-1}+\frac{320\sigma^{p}G^{2-p}+4G^{2}}{\mu}.\label{eq:str-exp-3}
\end{align}
Combining (\ref{eq:str-exp-2}) and (\ref{eq:str-exp-3}) and summing
up from $t=1$ to $\tau$, we have
\begin{align*}
 & \frac{\mu(\tau+1)\tau}{8}\E\left[d_{\tau+1}^{2}\right]+\sum_{t=1}^{\tau}\E\left[t\Delta_{t}\right]\\
\leq & \frac{160\sigma^{p}M^{2-p}+4\sigma^{2p}M^{2-2p}}{\mu}t^{\frac{2}{p}-1}+\frac{320\sigma^{p}G^{2-p}+4G^{2}}{\mu}\\
\leq & \frac{160\sigma^{p}M^{2-p}+4\sigma^{2p}M^{2-2p}}{\mu}\cdot\frac{p}{2}((\tau+1)^{\frac{2}{p}}-1)+\frac{320\sigma^{p}G^{2-p}+4G^{2}}{\mu}\tau\\
\leq & \frac{320\sigma^{p}M^{2-p}+8\sigma^{2p}M^{2-2p}}{\mu}\tau^{\frac{2}{p}}+\frac{320\sigma^{p}G^{2-p}+4G^{2}}{\mu}\tau\\
\leq & \frac{320\sigma^{p}M^{2-p}+8\sigma^{2p}M^{2-2p}}{\mu}\tau^{\frac{2}{p}}+\frac{320\sigma^{2}+324G^{2}}{\mu}\tau.
\end{align*}

Finally, choosing $\tau=T$ and using $\sum_{t=1}^{T}t\E\left[\Delta_{t}\right]\geq\frac{T(T+1)}{2}\E\left[F(\bar{x}_{T})-F(x_{*})\right]$
by the convexity of $F$ and $\bar{x}_{T}=\frac{2}{T(T+1)}\sum_{t=1}^{T}x_{t}$,
we conclude
\begin{align*}
\E\left[F(\bar{x}_{T})-F(x_{*})\right] & \leq O\left(\frac{G^{2}+\sigma^{2}}{\mu T}+\frac{\sigma^{p}M^{2-p}+\sigma^{2p}M^{2-2p}}{\mu T^{\frac{2(p-1)}{p}}}\right);\\
\E\left[\left\Vert x_{T+1}-x_{*}\right\Vert ^{2}\right] & \leq O\left(\frac{G^{2}+\sigma^{2}}{\mu^{2}T}+\frac{\sigma^{p}M^{2-p}+\sigma^{2p}M^{2-2p}}{\mu^{2}T^{\frac{2(p-1)}{p}}}\right).
\end{align*}
\end{proof}

