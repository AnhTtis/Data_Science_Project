\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,amsbsy,amsfonts,latexsym,amsthm,mathrsfs}
\usepackage{graphicx}
\usepackage{float}
\usepackage{color}
\usepackage{todonotes}
%\input defr
\oddsidemargin=0cm \textwidth=16.5cm \textheight=24cm
\topmargin=-1.5cm
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{application}[theorem]{Application}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\begin{document}
\title{Asymptotic results for compound sums in Banach Spaces}
\author{Claudio Macci\thanks{Address: Dipartimento di Matematica,
Universit\`a di Roma Tor Vergata, Via della Ricerca Scientifica,
I-00133 Rome, Italy. e-mail: \texttt{macci@mat.uniroma2.it}} \and
Barbara Pacchiarotti\thanks{Address: Dipartimento di Matematica,
Universit\`a di Roma Tor Vergata, Via della Ricerca Scientifica,
I-00133 Rome, Italy. e-mail: \texttt{pacchiar@mat.uniroma2.it}}}
%\date{}
\maketitle
\begin{abstract}
	\noindent We prove large and moderate deviation results for sequences of compound sums,
	where the summands are i.i.d. random variables taking values on a Banach space. We establish
	that the results hold by proving that we are dealing with exponentially tight sequences. We 
	present two moderate deviation results: in the first one the summands are centered, in the 
	second one the compound sums are centered.\\
	
	\noindent\textbf{Mathematics Subject Classification:} 60F10, 60G50, 60B12.\\
	%60F10 Large deviations
	%60G50 Sums of independent random variables; random walks
	%60B12 Limit theorems for vector-valued random variables (infinite-dimensional case)
	\textbf{Keywords:} exponential tightness, large deviations, moderate deviations.
\end{abstract}

\section{Introduction}
Large deviations give an asymptotic computation of small probabilities on an exponential scale (see e.g. \cite{DZ:97} as a reference 
on this topic). We recall some basic definitions (see e.g. Section 1.2 in \cite{DZ:97}). Throughout this paper a speed function is a 
sequence $\{v_n:n\geq 1\}$ such that $\lim_{n\to\infty}v_n=\infty$. A sequence of random variables $\{Z_n:n\geq 1\}$ defined on the 
same probability space $(\Omega,\mathcal{F},P)$ and taking values on a topological space $\mathcal{X}$, satisfies the large deviation 
principle (LDP for short) with rate function $I$ and speed function $v_n$ if the following conditions hold: the function 
$I:\mathcal{X}\to[0,\infty]$ is lower semicontinuous,
$$\liminf_{n\to\infty}\frac{1}{v_n}\log P(Z_n\in O)\geq-\inf_{x\in O}I(x)\quad\quad\mbox{for all open sets $O$,}$$
and
$$\limsup_{n\to\infty}\frac{1}{v_n}\log P(Z_n\in C)\leq-\inf_{x\in C}I(x)\quad\quad\mbox{for all closed sets $C$.}$$
Finally we say that the rate function $I$ is \emph{good} if all its level sets $\{\{z\in\mathcal{Z}:I(z)\leq\eta\}:\eta\geq 0\}$ are 
compact.

We remark that, in view of the proof of the results in this paper, here we always deal with sequences of random variables because 
this allows to refer to some useful properties. However, at least in some cases, some results could be stated for families of random 
variables with continuous parameter $t$ in place of the discrete parameter $n$.

The concept of exponential tightness plays a crucial role in large deviations; in fact this condition is often required to establish
that the large deviation principle holds for a sequence of random variables taking values on an infinite dimensional topological space.
For completeness we recall that the sequence of random variables $\{Z_n:n\geq 1\}$ is exponentially tight with respect to the speed 
function $v_n$ if, for all $b>0$, there exists a compact $K_b\subset\mathcal{X}$ such that
$$\limsup_{n\to\infty}\frac{1}{v_n}\log P(Z_n\notin K_b)\leq-b.$$

In this paper we consider sequences of random variables taking values on an infinite dimensional topological space. Indeed we consider
sequences of compound sums $\{S_{N_n}:n\geq 1\}$, where 
$$S_n:=X_1+\cdots+X_n\quad\quad\mbox{for every}\ n\geq 1,$$
$\{X_n:n\geq 1\}$ are superexponential i.i.d. random variables taking values on a Banach space $B$ (see Condition 
\ref{cond:superexponential-tails-summands}), and independent of some integer-valued nonnegative random variables $\{N_n:n\geq 1\}$ 
which satisfies some suitable properties (see Condition \ref{cond:LD-*}).

In this paper we prove a \emph{reference LDP} with speed $v_n=n$ (Proposition \ref{prop:LD}). Moreover we prove two results on 
\emph{moderate deviations}: the first one concerns the case of ``centered summands'' (Proposition \ref{prop:MD-summands-are-centered}), 
while the second one (Proposition \ref{prop:MD-centered-compound-sum}) concerns the case of ``centered compound sums''. In view of
these two results we refer to a further condition (Condition \ref{cond:MD-*}) together with a family of positive sequences (called 
\emph{scalings}) $\{a_n:n\geq 1\}$ such that
\begin{equation}\label{eq:MD-conditions}
	a_n\to 0\quad\mathrm{and}\quad na_n\to 0.
\end{equation}
The class of all positive scalings allows to fill the gap between a convergence to a constant (at least in probability) governed by 
a LDP (i.e. the \emph{reference LDP} cited above), and a weak convergence to a centered Normal distribution. In general we can say that:
\begin{itemize}
	\item for $a_n=\frac{1}{v_n}=\frac{1}{n}$, we have the convergence to a constant;
	\item for $a_n=1$, we have the weak convergence to a centered Normal distribution.
\end{itemize}
Note that in these two cases one condition in eq. \eqref{eq:MD-conditions} holds, and the other one fails.

We remark that, when we prove the exponential tightness conditions for large and moderate deviations, we follow the same lines of
the content of two papers of de Acosta (see \cite{deAcosta1} and \cite{deAcosta3}, respectively) for non-compound sums.
Obviously in this paper the situation is more intricate because we deal with compound sums.

We conclude with the outline of the paper. We start with some preliminaries in Section \ref{sec:preliminaries}. Large and moderate 
deviations results are presented in Sections \ref{sec:LD} and \ref{sec:MD}, respectively. Finally Section \ref{sec:examples}
concerns some examples for the sequence $\{N_n:n\geq 1\}$.

\section{Preliminaries}\label{sec:preliminaries}
We start with the following condition.

\begin{condition}\label{cond:superexponential-tails-summands}
Let $B$ be a Banach Space, with norm $\|\cdot\|$. Moreover, let $\{X_n:n\geq 1\}$ be a sequence of i.i.d. 
$B$-valued random variables such that $\mathbb{E}[e^{t\|X_1\|}]<\infty$ for all $t>0$. Moreover let
$\{S_n:n\geq 1\}$ be defined by $S_n:X_1+\cdots+X_n$ for all $n\geq 1$.
\end{condition}

Moreover, as far as the Banach space $B$ in Condition \ref{cond:superexponential-tails-summands}, we denote the dual space 
of $B$ by $B^*$, the null vector in $B$ by $\widehat{0}$, the null vector in $B^*$ by $\widehat{0}^*$, and the \emph{duality 
between $B^*$ and $B$} by $\langle\cdot,\cdot\rangle$. Then, if we refer to the random variables $\{X_n:n\geq 1\}$
in Condition \ref{cond:superexponential-tails-summands}, we consider the function $\Lambda_X$ defined by
$$\Lambda_X(\theta):=\log\mathbb{E}[e^{\langle\theta,X_1\rangle}]\quad\quad\mbox{for all}\ \theta\in B^*,$$
and the Legendre transform of $\Lambda_X$, i.e. the function $\Lambda_X^*$ defined by
$$\Lambda_X^*(x):=\sup_{\theta\in B^*}\{\langle\theta,x\rangle-\Lambda_X(\theta)\}\quad\quad\mbox{for all}\ x\in B.$$
In particular (see e.g. \cite{Ba-McK}) we can say what follows:
\begin{equation}\label{eq:condition-for-the-mean}
	\mbox{there exists $\mu_X\in B$ such that $\langle v,\mu_X\rangle=\mathbb{E}[\langle v,X_1\rangle]$}\quad\quad (\mbox{for}\ v\in B^*)
\end{equation}
(this is related to the concept of \emph{Pettis integral});
\begin{equation}\label{eq:condition-for-the-covariance}
	\left.\begin{array}{l}
		\mbox{there exists a linear operator $\Sigma_X:B^*\to B$ such that}\\
		\mbox{$\langle u,\Sigma_Xv\rangle=\langle\Sigma_Xu,v\rangle=\mathrm{Cov}(\langle u,X_1\rangle,\langle v,X_1\rangle)$}\quad\quad (\mbox{for}\ u,v\in B^*).
	\end{array}\right.
\end{equation}

In this paper we consider the following Condition \ref{cond:LD-*} which plays a crucial role in view of the proof of the 
reference LDP (Proposition \ref{prop:LD}).

\begin{condition}\label{cond:LD-*}
Let $\{N_n:n\geq 1\}$ be a family of integer-valued nonnegative random variables such that the function
$$\Lambda_N(\eta):=\lim_{n\to\infty}\frac{1}{n}\log\mathbb{E}[e^{\eta N_n}]\quad\quad\mbox{for all}\ \eta\in\mathbb{R}$$
is well-defined, finite valued and differentiable; note that, since $\Lambda_N$ is a non-decreasing function,
it is well-defined $\Lambda_N(-\infty):=\lim_{\eta\to-\infty}\Lambda_N(\eta)$. Moreover, let $\{X_n:n\geq 1\}$ be a 
sequence of i.i.d. $B$-valued random variables as in Condition \ref{cond:superexponential-tails-summands}, and 
independent of $\{N_n:n\geq 1\}$.
\end{condition}

Moreover we consider the assumptions collected in the next Condition \ref{cond:MD-*}. These assumptions play a crucial role
in the proofs of the moderate deviation results (Propositions \ref{prop:MD-summands-are-centered} and 
\ref{prop:MD-centered-compound-sum}).

\begin{condition}\label{cond:MD-*}
Assume that Condition \ref{cond:LD-*} holds, and there exists $\Lambda_N^{\prime\prime}(0)$. Moreover assume that
\begin{itemize}
\item $\frac{N_n-\mathbb{E}[N_n]}{\sqrt{n}}$ converges weakly to the centered Normal distribution with variance 
$\Lambda_N^{\prime\prime}(0)>0$ as $n\to\infty$;
\item for every positive sequence $\{a_n:n\geq 1\}$ such that eq. \eqref{eq:MD-conditions} holds, we have
\begin{equation}\label{eq:MD-limit-for-marginal-N}
\lim_{n\to\infty}a_n\log\mathbb{E}\left[e^{\eta\frac{N_n-\mathbb{E}[N_n]}{\sqrt{na_n}}}\right]
=\frac{\Lambda_N^{\prime\prime}(0)}{2}\eta^2\quad\quad\mbox{for all}\ \eta\in\mathbb{R}.
\end{equation}
\end{itemize}
\end{condition}
Note that in our setting we can have $\Lambda_N^{\prime\prime}(0)\geq 0$ and we require the strict positiveness in order
to avoid degenerating cases.

\section{Large deviations}\label{sec:LD}
In this section we prove Proposition \ref{prop:LD}. In particular we show that we have an exponentially tight sequence, and this will 
be done separately in Section \ref{sub:LD-ET}.

\subsection{The result and a part of the proof}
We have the following result.

\begin{proposition}\label{prop:LD}
Assume that Condition \ref{cond:LD-*} holds. Then $\left\{\left(\frac{S_{N_n}}{n},\frac{N_n}{n}\right):n\geq 1\right\}$ satisfies the LDP 
with speed $n$, and good rate function $I_{S,N}$ defined by
\begin{equation}\label{eq:LD-rf-LT}
I_{S,N}(x,y):=\sup_{\theta\in B^*,\eta\in\mathbb{R}}\{\langle\theta,x\rangle+\eta y-\Lambda_N(\eta+\Lambda_X(\theta))\}
\quad\quad\mbox{for all}\ (x,y)\in B\times\mathbb{R}.
\end{equation}
Moreover, we have
\begin{equation}\label{eq:LD-rf-explicit}
I_{S,N}(x,y):=\left\{\begin{array}{ll}
y\Lambda_X^*\left(\frac{x}{y}\right)+\Lambda_N^*(y)&\ \mbox{if}\ y>0\\
-\Lambda_N(-\infty)&\ \mbox{if}\ (x,y)=(\widehat{0},0)\\
\infty&\ \mbox{otherwise}.
\end{array}\right.
\end{equation}
\end{proposition}
\begin{proof}
We prove the LDP as an application of Corollary 4.5.27 in \cite{DZ:97}. Firstly, by G\"artner Ellis Theorem
(see e.g. Theorem 2.3.6 in \cite{DZ:97}), $\left\{\frac{N_n}{n}:n\geq 1\right\}$ satisfies the LDP with good
rate function $\Lambda_N^*$ defined by
$$\Lambda_N^*(y):=\sup_{\eta\in\mathbb{R}}\{\eta y-\Lambda_N(\eta)\}.$$
Then $\{\frac{N_n}{n}:n\geq 1\}$ is exponentially tight at speed $n$ (see, for example, Lemma 2.6 in \cite{Lyn-Set}); therefore,
for all $R>0$, there exists $L_R>0$ such that, for some $n_0\geq 1$,
\begin{equation}\label{eq:LD-ET-counting-processes}
P\left(\frac{N_n}{n}>L_R\right)\leq e^{-nR}\quad\quad\mbox{for all}\ n\geq n_0.
\end{equation}
Moreover, as we shall explain in in Subsection \ref{sub:LD-ET}, the sequence
$\left\{\left(\frac{S_{N_n}}{n},\frac{N_n}{n}\right):n\geq 1\right\}$ is exponentially tight at speed $n$
(this is stated in Proposition \ref{prop:LD-ET}).

Now, in view of the application of Corollary 4.5.27 in \cite{DZ:97} (see also Theorem 4.5.20 in the
same reference), we remark that
$$\mathbb{E}[e^{\langle\theta,S_{N_n}\rangle+\eta N_n}]
=\mathbb{E}[\mathbb{E}[e^{\langle\theta,X_1\rangle}]^{N_n}e^{\eta N_n}]
=\mathbb{E}[e^{(\eta+\Lambda_X(\theta))N_n}]\quad\quad\mbox{for all}\ (\theta,\eta)\in B^*\times\mathbb{R};$$
thus we have
\begin{equation}\label{eq:def-LambdaSN}
\Lambda_{S,N}(\theta,\eta):=\lim_{n\to\infty}\frac{1}{n}\log\mathbb{E}[e^{\langle\theta,S_{N_n}\rangle+\eta N_n}]
=\Lambda_N(\eta+\Lambda_X(\theta))\quad\quad\mbox{for all}\ (\theta,\eta)\in B^*\times\mathbb{R}.
\end{equation}
Then, by taking into account our hypotheses, we can say that: the function $\Lambda_{S,N}$ is finite valued and 
Gateaux differentiable (obvious); the function $\Lambda_{S,N}$ is lower semicontinuous with respect to the weak$^*$ 
topology because
$$\lim_{n\to\infty}\Lambda_N(\eta_n+\Lambda_X(\theta_n))$$
for every pair of sequences $\{\theta_n:n\geq 1\}$ and $\{\eta_n:n\geq 1\}$ such that $\eta_n$ converges to $\eta$
and $\theta_n$ converges weakly to $\theta$ (indeed $\Lambda_N$ is a continuous function and, moreover, since
$\langle\theta_n,X_1\rangle$ converges to $\langle\theta,X_1\rangle$ almost surely, $\langle\theta_n,X_1\rangle$ 
converges weakly to $\langle\theta,X_1\rangle$, and this yields that $\Lambda_X(\theta_n)$ converges to 
$\Lambda_X(\theta)$). In conclusion we can apply Corollary 4.5.27 in \cite{DZ:97}, and we get the desired LDP  
with good rate function $I_{S,N}$ defined by eq. \eqref{eq:LD-rf-LT}.

In the final part of the proof we show that eq. \eqref{eq:LD-rf-explicit} holds. We have the following cases.
\begin{itemize}
\item If $y<0$, then
$$I_{S,N}(x,y)\geq\langle\widehat{0},x\rangle+\eta y-\Lambda_N(\eta+\Lambda_X(\widehat{0}))
=\eta y-\Lambda_N(\eta);$$
moreover, since $\Lambda_N(\eta)\leq 0$ for $\eta\leq 0$ (because $\Lambda_N$ is a non-decreasing function),
for $\eta\leq 0$ we have $I_{S,N}(x,y)\geq\eta y$ and we conclude by letting $\eta$ go to $-\infty$.
\item If $y>0$, then
\begin{multline*}
I_{S,N}(x,y)\leq\sup_{\theta\in B^*}\{\langle\theta,x\rangle-y\Lambda_X(\theta)\}
+\sup_{\theta\in B^*,\eta\in\mathbb{R}}\{(\eta+\Lambda_X(\theta))y-\Lambda_N(\eta+\Lambda_X(\theta))\}\\
=y\sup_{\theta\in B^*}\{\langle\theta,x/y\rangle-\Lambda_X(\theta)\}+\Lambda_N^*(y)
=y\Lambda_X^*\left(\frac{x}{y}\right)+\Lambda_N^*(y);
\end{multline*}
moreover, if we take two maximizing sequences $\{\theta_n:n\geq 1\}$ and $\{\alpha_n:n\geq 1\}$ such that
$$\Lambda_X^*\left(\frac{x}{y}\right)=\lim_{n\to\infty}\langle\theta_n,x/y\rangle-\Lambda_X(\theta_n)\quad
\mbox{and}\quad \Lambda_N^*(y)=\lim_{n\to\infty}\alpha_ny-\Lambda_N(\alpha_n),$$
for every $n\geq 1$ we get
\begin{multline*}
I_{S,N}(x,y)\geq\left.\langle\theta_n,x\rangle+\eta y-\Lambda_N(\eta+\Lambda_X(\theta_n))\right|_{\eta=-\Lambda_X(\theta_n)+\alpha_n}\\
=\langle\theta_n,x\rangle-y\Lambda_X(\theta_n)+\alpha_ny-\Lambda_N(\alpha_n)
=y(\langle\theta_n,x/y\rangle-\Lambda_X(\theta_n))+\alpha_ny-\Lambda_N(\alpha_n),
\end{multline*}
and we conclude by letting $n$ go to infinity (because we have shown that the inverse ineqality holds).
\item If $y=0$ and $x=\widehat{0}$, then
$$I_{S,N}(\widehat{0},0)=\sup_{\theta\in B^*,\eta\in\mathbb{R}}\{-\Lambda_N(\eta+\Lambda_X(\theta))\}
=-\lim_{\eta\to-\infty}\Lambda_N(\eta)=-\Lambda_N(-\infty)$$
because $\Lambda_N$ is a non-decreasing function.
\item If $y=0$ and $x\neq\widehat{0}$, then we take $\theta_x\in B^*$ such that $\langle\theta_x,x\rangle>0$;
thus for every $n\geq 1$ we get
$$I_{S,N}(\widehat{0},0)\geq
\left.\langle n\theta_x,x\rangle+\eta\cdot 0-\Lambda_N(\eta+\Lambda_X(n\theta_x))\right|_{\eta=-n\Lambda_X(\eta_x)}
=n\langle\theta_x,x\rangle-\Lambda_N(0)=n\langle\theta_x,x\rangle,$$
and we conclude by letting $n$ go to infinity.
\end{itemize}
\end{proof}

\begin{remark}\label{rem:typical-features-for-N-only}
Proposition \ref{prop:LD} concerns the bivariate sequence $\left\{\left(\frac{S_{N_n}}{n},\frac{N_n}{n}\right):n\geq 1\right\}$.
If one consider the second components $\{\frac{N_n}{n}:n\geq 1\}$, one typically has the following limits:
\begin{equation}\label{eq:limit-mean-tf-N}
\lim_{n\to\infty}\mathbb{E}[N_n/n]=\Lambda_N^\prime(0);
\end{equation}
\begin{equation}\label{eq:limit-variance-tf-N}
\lim_{n\to\infty}n\mathrm{Var}[N_n/n]=\Lambda_N^{\prime\prime}(0).
\end{equation}
In particular the limit in eq. \eqref{eq:limit-variance-tf-N} has some relationship with moderate deviations and with asymptotic 
normality result. Suitable versions of the limits in eqs. \eqref{eq:limit-mean-tf-N} and \eqref{eq:limit-variance-tf-N} will 
be presented in Section \ref{sub:some-typical-features} for the bivariate sequence in Proposition \ref{prop:LD}.
\end{remark}

\subsection{The exponential tightness of $\left\{\left(\frac{S_{N_n}}{n},\frac{N_n}{n}\right):n\geq 1\right\}$ at speed $n$}\label{sub:LD-ET}
We start with some preliminaries. For some $K\subset B$, we introduce the Minkowski functional
$$q_K(x):=\inf\{a>0:x\in aK\}.$$
We say that a set $K$ is well-balanced if $aK\subset K$ for $a\in[0,1]$. If a convex set is well-balanced then 
$a_1K\subset a_2K$ for $0<a_1\leq a_2$, which yields $x\notin aK$ if and only if $q_K(x)>a$.
Furthermore recall that for a convex well-balanced set, the Minkowski functional is a semi-norm. See e.g, 
\cite{Schechter} or \cite{Nar-Beck}.

Then we have the following lemmas.

\begin{lemma}\label{lem:LD-*}
Assume that Condition \ref{cond:superexponential-tails-summands} holds. Then there exists a well-balanced 
compact convex set $K\subset B$ such that $\mathbb{E}[e^{q_K(X_1)}]<\infty$.
\end{lemma}
\begin{proof}
See e.g. Theorem 3.1 in \cite{deAcosta1}.
\end{proof}

\begin{lemma}\label{lem:LD-**}
Assume that Condition \ref{cond:superexponential-tails-summands} and let $K$ be the set in Lemma \ref{lem:LD-*}.
Then, for $R,L>0$, there exists $\delta=\delta(R,L,K)>0$ such that
$$\sup_{1\leq h\leq Ln}P\left(\frac{S_h}{n}\notin\delta K\right)\leq e^{-nR}\quad\quad\mbox{for all integers}\ n\geq 1.$$
\end{lemma}
\begin{proof}
Let $\delta>0$ be arbitrarily fixed. Then, for $n\geq 1$ and for all integers $h\in[1,Ln]$, we have
\begin{multline*}
P\left(\frac{S_h}{n}\notin\delta K\right)=P(S_h\notin n\delta K)=P(q_K(S_h)>\delta n)\\
\leq\mathbb{E}[e^{q_K(S_h)}]e^{-n\delta}\leq\mathbb{E}^h[e^{q_K(X_1)}]e^{-n\delta}
=e^{-n(\delta-\frac{h}{n}\log\mathbb{E}[e^{q_K(X_1)}])};
\end{multline*}
here we take into account that $K$ is a well-balanced set and the sublinearity of $q_K(x)$ 
because $q_K$ is a semi-norm. So we conclude by taking $\delta=\delta(R,L,K)>0$ such that
$$\delta-\frac{h}{n}\log\mathbb{E}[e^{q_K(X_1)}]>R\quad\quad\mbox{for all integers}\ h\in[1,Ln];$$
indeed this is possible by taking $\delta>R+L\max\{\log\mathbb{E}[e^{q_K(X_1)}],0\}$.
\end{proof}

Now we are able to prove the desired exponential tightness condition.

\begin{proposition}\label{prop:LD-ET}
Assume that Condition \ref{cond:LD-*} holds. Then $\left\{\left(\frac{S_{N_n}}{n},\frac{N_n}{n}\right):n\geq 1\right\}$ 
is exponentially tight at speed $n$.
\end{proposition}
\begin{proof}
In this proof we show that, for all $R>0$, there exists a compact set $\widehat{K}_R\subset B\times\mathbb{R}$
such that, for some $n_2\geq 1$,
$$P\left(\left(\frac{S_{N_n}}{n},\frac{N_n}{n}\right)\notin\widehat{K}_R\right)\leq 2e^{-nR}
\quad\quad\mbox{for all}\ n\geq n_2.$$	
More precisely we consider the set
$$\widehat{K}_R:=(\delta_R K)\times [0,L_R],$$
where $\delta_R:=\delta(R,L_R,K)>0$ according to the notation in Lemma \ref{lem:LD-**} (with the compact $K$ in that lemma),
and $L_R>0$ as in eq. \eqref{eq:LD-ET-counting-processes}. Then we have
\begin{multline*}
P\left(\left(\frac{S_{N_n}}{n},\frac{N_n}{n}\right)\notin\widehat{K}_R\right)
=P\left(\left(\left\{\frac{S_{N_n}}{n}\in\delta_RK\right\}\cap
\left\{\frac{N_n}{n}\in[0,L_R]\right\}\right)^c\right)\\
=P\left(\left\{\frac{S_{N_n}}{n}\notin\delta_RK\right\}\cup
\left\{\frac{N_n}{n}>L_R\right\}\right)\\
=P\left(\frac{N_n}{n}>L_R\right)+P\left(\left\{\frac{S_{N_n}}{n}\notin\delta_RK\right\}\cap
\left\{\frac{N_n}{n}\leq L_R\right\}\right).
\end{multline*}
Now we have to estimate these two terms. For the first one we can refer to eq. \eqref{eq:LD-ET-counting-processes}.
For the second one we can say that, by Lemma \ref{lem:LD-**} with $L=L_R$ (and by taking into account the definition of
$\delta_R$), for some $n_1\geq 1$ we have (here, without loss of generality, we think that $L_R$ is integer)
\begin{multline*}
P\left(\left\{\frac{S_{N_n}}{n}\notin\delta_RK\right\}\cap
\left\{\frac{N_n}{n}\leq L_R\right\}\right)
=\sum_{j=0}^{nL_R}P\left(\left\{\frac{S_{N_n}}{n}\notin\delta_RK\right\}\cap\{N_n=j\}\right)\\
=\sum_{j=0}^{nL_R}P\left(\frac{S_j}{n}\notin\delta_RK\right)P(N_n=j)
\leq e^{-nR}\sum_{j=0}^{nL_R}P(N_n=j)\leq e^{-nR}.
\end{multline*}
Thus, by taking $n_2:=\max\{n_0,n_1\}$, the statement at the beginning of the proof is proved.
This completes the proof. 
\end{proof}

\section{Moderate deviations (MD)}\label{sec:MD}
In this Section we prove two results: Proposition \ref{prop:MD-summands-are-centered} for the case in which ``the summands 
are centered'' and Proposition \ref{prop:MD-centered-compound-sum} for the case in which ``the compound sum is centered''.
In the first case, for $\mu_X\in B$ as in eq. \eqref{eq:condition-for-the-mean}, we mean
$$\sum_{i=1}^{N_n}(X_i-\mu_X)=S_{N_n}-N_n\mu_X;$$
in the second case we mean
$$S_{N_n}-\mathbb{E}[S_{N_n}]=S_{N_n}-\mathbb{E}[N_n]\mu_X;$$
obviously the two cases coincide if and only if $\mu_X=\widehat{0}$. In particular, for the proof of the first result we 
show that we have an exponentially tight sequence, and this will be done separately in Section \ref{sub:MD-summands-are-centered-ET}.
Proposition \ref{prop:MD-centered-compound-sum}, which appears in Section \ref{sub:MD-centered-compound-sum}, will be a 
consequence of Proposition \ref{prop:MD-summands-are-centered} and an application of the contraction principle. A final 
Section \ref{sub:some-typical-features} is devoted to the discussion of some typical features.

Finally, in view of what follows, we recall that we can define the inverse of the function $\Sigma_X$ in eq.
\eqref{eq:condition-for-the-covariance}; more precisely we mean $\Sigma_X^{-1}:\mathrm{Im}(\Sigma_X)\to B^*$, where
$$\mathrm{Im}(\Sigma_X):=\{x\in B:\Sigma_Xu=x\ \mbox{for some}\ u\in B^*\},$$
such that $\Sigma_X^{-1}\Sigma_Xu=u$ for all $u\in B^*$.

\subsection{MD when ``the summands are centered'' and a part of the proof}
We have the following result.

\begin{proposition}\label{prop:MD-summands-are-centered}
Assume that Condition \ref{cond:MD-*} and the limit in eq. \eqref{eq:limit-mean-tf-N} hold. Let $\mu_X\in B$ and the linear 
operator $\Sigma_X$ be defined in eqs. \eqref{eq:condition-for-the-mean} and \eqref{eq:condition-for-the-covariance}, respectively;
in particular we assume that $\langle\theta,\Sigma_X\theta\rangle>0$ for all $\theta\neq\widehat{0}^*$. Then, for every positive
sequence $\{a_n:n\geq 1\}$ such that eq. \eqref{eq:MD-conditions} holds, the sequence 
$\left\{\left(\frac{S_{N_n}-N_n\mu_X}{\sqrt{n/a_n}},\frac{N_n-\mathbb{E}[N_n]}{\sqrt{n/a_n}}\right):n\geq 1\right\}$ satisfies
the LDP with speed $1/a_n$, and good rate function $J_{S,N}^{(1)}$ defined by
$$J_{S,N}^{(1)}(x,y):=\left\{\begin{array}{ll}
\frac{\langle x,\Sigma_X^{-1}x\rangle}{2\Lambda_N^\prime(0)}+\frac{y^2}{2\Lambda_N^{\prime\prime}(0)}&\ \mbox{if}\ x\in\mathrm{Im}(\Sigma_X)\\
\infty&\ \mbox{otherwise}.
\end{array}\right.$$
\end{proposition}
\begin{proof}
We consider an arbitrarily fixed positive sequence $\{a_n:n\geq 1\}$ such that eq. \eqref{eq:MD-conditions} holds and, as we did 
for Proposition \ref{prop:LD}, we prove the LDP as an application of Corollary 4.5.27 in \cite{DZ:97}. Firstly, by G\"artner Ellis 
Theorem (see e.g. Theorem 2.3.6 in \cite{DZ:97}) and the limit in eq. \eqref{eq:MD-limit-for-marginal-N}, 
$\left\{\frac{N_n-\mathbb{E}[N_n]}{\sqrt{n/a_n}}:n\geq 1\right\}$ satisfies the LDP with good rate function $J_N$ defined by
$$J_N^*(y):=\sup_{\eta\in\mathbb{R}}\left\{\eta y-\frac{\eta^2}{2}\Lambda_N^{\prime\prime}(0)\right\}
=\frac{y^2}{2\Lambda_N^{\prime\prime}(0)}.$$
Then, again by Lemma 2.6 in \cite{Lyn-Set}, $\{\frac{N_n-\mathbb{E}[N_n]}{\sqrt{n/a_n}}:n\geq 1\}$ is exponentially 
tight at speed $1/a_n$; therefore, for all $R>0$, there exists $L_R>0$ such that, for some $n_0\geq 1$,
\begin{equation}\label{eq:MD-summands-are-centered-ET-counting-processes}
P\left(\frac{|N_n-\mathbb{E}[N_n]|}{\sqrt{n/a_n}}>L_R\right)\leq e^{-R/a_n}\quad\quad\mbox{for all}\ n\geq n_0.
\end{equation}
Moreover, as we shall explain in Subsection \ref{sub:MD-summands-are-centered-ET}, the sequence
$\left\{\left(\frac{S_{N_n}-N_n\mu_X}{\sqrt{n/a_n}},\frac{N_n-\mathbb{E}[N_n]}{\sqrt{n/a_n}}\right):n\geq 1\right\}$ is 
exponentially tight at speed $1/a_n$ (this is stated in Proposition \ref{prop:MD-summands-are-centered-ET}).

Now, in view of the application of Corollary 4.5.27 in \cite{DZ:97} (see also Theorem 4.5.20 in the
same reference), we remark that
\begin{multline*}
\mathbb{E}[e^{\langle\theta,S_{N_n}-N_n\mu_X\rangle+\eta (N_n-\mathbb{E}[N_n])}]\\
=\mathbb{E}[\mathbb{E}[e^{\langle\theta,X_1-\mu_X\rangle}]^{N_n}e^{\eta N_n}]e^{-\eta\mathbb{E}[N_n]}
=\mathbb{E}[e^{(\eta+\Lambda_X(\theta)-\langle\theta,\mu_X\rangle)N_n}]e^{-\eta\mathbb{E}[N_n]}\\
=\mathbb{E}[e^{(\eta+\Lambda_X(\theta)-\langle\theta,\mu_X\rangle)(N_n-\mathbb{E}[N_n])}]
e^{(\Lambda_X(\theta)-\langle\theta,\mu_X\rangle)\mathbb{E}[N_n]}\quad\quad\mbox{for all}\ (\theta,\eta)\in B^*\times\mathbb{R};
\end{multline*}
thus we have
\begin{multline*}
a_n\log\mathbb{E}\left[e^{\langle\theta,\frac{S_{N_n}-N_n\mu_X}{\sqrt{na_n}}\rangle+\eta\frac{N_n-\mathbb{E}[N_n]}{\sqrt{na_n}}}\right]\\
=a_n\log\mathbb{E}[e^{(\eta/\sqrt{na_n}+\Lambda_X(\theta/\sqrt{na_n})-\langle\theta/\sqrt{na_n},\mu_X\rangle)(N_n-\mathbb{E}[N_n])}]
+a_n(\Lambda_X(\theta/\sqrt{na_n})-\langle\theta/\sqrt{na_n},\mu_X\rangle)\mathbb{E}[N_n],
\end{multline*}
and we have to study the limit of the two terms. 

It is easy to see (and we omit the details) that for the second term we have
$$\lim_{n\to\infty}a_n(\Lambda_X(\theta/\sqrt{na_n})-\langle\theta/\sqrt{na_n},\mu_X\rangle)\mathbb{E}[N_n]
=\frac{\Lambda_N^\prime(0)}{2}\langle\theta,\Sigma_X\theta\rangle\quad\quad\mbox{for all}\ \theta\in B^*,$$
where we take into account the limit in eq. \eqref{eq:limit-mean-tf-N}. So we complete the proof showing that
\begin{equation}\label{eq:MD-summands-are-centered-limit-to-prove}
\lim_{n\to\infty}a_n\log\mathbb{E}[e^{(\eta/\sqrt{na_n}+\Lambda_X(\theta/\sqrt{na_n})-\langle\theta/\sqrt{na_n},\mu_X\rangle)(N_n-\mathbb{E}[N_n])}]
=\frac{\Lambda_N^{\prime\prime}(0)}{2}\eta^2\quad\quad\mbox{for all}\ (\theta,\eta)\in B^*\times\mathbb{R};
\end{equation}
indeed, if we consider the function $\Psi_{S,N}$ defined by
\begin{equation}\label{eq:def-PsiSN}
\Psi_{S,N}(\theta,\eta):=\frac{\Lambda_N^\prime(0)\langle\theta,\Sigma_X\theta\rangle}{2}+\frac{\Lambda_N^{\prime\prime}(0)}{2}\eta^2,
\end{equation}
the desired LDP holds with rate function $J_{S,N}^{(1)}$ defined by
\begin{equation}\label{eq:MD-rf-LT-summands-are-centered}
J_{S,N}^{(1)}(x,y):=\sup_{\theta\in B^*,\eta\in\mathbb{R}}\{\langle\theta,x\rangle+\eta y-\Psi_{S,N}(\theta,\eta)\}
\quad\quad\mbox{for all}\ (x,y)\in B\times\mathbb{R},
\end{equation}
which coincides with the rate function $J_{S,N}^{(1)}$ (this can be checked with some standard computations and we omit the
details).

In order to prove eq. \eqref{eq:MD-summands-are-centered-limit-to-prove} we remark that it is trivial for $\theta=\widehat{0}^*$ because 
it is an immediate consequence of the limit in eq. \eqref{eq:MD-limit-for-marginal-N}. So from now on we can restrict the attention on 
the case $\theta\neq\widehat{0}^*$. Moreover we note that, if we set
$$\eta_n=\eta+\frac{1}{2\sqrt{na_n}}\langle\theta,\Sigma_X\theta\rangle+\sqrt{na_n}o\left(\frac{1}{na_n}\right),$$
we have $\lim_{n\to\infty}\eta_n=\eta$ and
$$\mathbb{E}[e^{(\eta/\sqrt{na_n}+\Lambda_X(\theta/\sqrt{na_n})-\langle\theta/\sqrt{na_n},\mu_X\rangle)(N_n-\mathbb{E}[N_n])}]
=\mathbb{E}[e^{\eta_n/\sqrt{na_n}(N_n-\mathbb{E}[N_n])}];$$
so, if we show that
\begin{equation}\label{eq:MD-summands-are-centered-limit-to-prove-2}
\lim_{n\to\infty}a_n\log\mathbb{E}[e^{\eta_n/\sqrt{na_n}(N_n-\mathbb{E}[N_n])}]
=\frac{\Lambda_N^{\prime\prime}(0)}{2}\eta^2\quad\quad\mbox{for all}\ (\theta,\eta)\in (B^*\setminus\{\widehat{0}^*\})\times\mathbb{R},
\end{equation}
we can say that eq. \eqref{eq:MD-summands-are-centered-limit-to-prove} holds and the proof is complete. We have two cases.

\paragraph{Case $\eta\neq 0$.} We can consider the sequence $\{b_n:n\geq 1\}$ defined by $b_n:=\frac{\eta}{\eta_n}$; 
this sequence is well-defined and positive (at least for $n$ large enough) and converges to 1 (as $n\to\infty$), and 
therefore eq. \eqref{eq:MD-summands-are-centered-limit-to-prove-2} holds noting that
$$\lim_{n\to\infty}a_n\log\mathbb{E}[e^{\eta_n/\sqrt{na_n}(N_n-\mathbb{E}[N_n])}]
=\lim_{n\to\infty}\frac{1}{b_n^2}a_nb_n^2\log\mathbb{E}[e^{\eta/\sqrt{na_nb_n^2}(N_n-\mathbb{E}[N_n])}]=\frac{\Lambda_N^{\prime\prime}(0)}{2}\eta^2,$$
by taking into account eq. \eqref{eq:MD-limit-for-marginal-N} with $\{a_nb_n^2:n\geq 1\}$ in place of $\{a_n:n\geq 1\}$.

\paragraph{Case $\eta=0$.} We start assuming that there exists
$$\ell:=\lim_{n\to\infty}\frac{\eta_n}{\sqrt{a_n}}$$
possibly not finite; note that
$$\sqrt{na_n}\eta_n=\frac{1}{2}\langle\theta,\Sigma_X\theta\rangle+na_no\left(\frac{1}{na_n}\right)\to \frac{1}{2}\langle\theta,\Sigma_X\theta\rangle>0$$
(we recall that we assume that $\langle\theta,\Sigma_X\theta\rangle>0$ for $\theta\neq\widehat{0}^*$) and therefore 
$\ell\in[0,\infty]$ and the sequence $\{\eta_n:n\geq 1\}$ is eventually nonnegative. Then, if $\ell<\infty$, eq.
\eqref{eq:MD-summands-are-centered-limit-to-prove-2} holds noting that
$$\lim_{n\to\infty}\log\mathbb{E}[e^{\eta_n/\sqrt{na_n}(N_n-\mathbb{E}[N_n])}]$$
exists (by the weak convergence in Condition \ref{cond:MD-*}) and it is finite. On the other hand, if $\ell=\infty$, 
we trivially have 
$\frac{a_n}{\eta_n^2}\to 0$, we can easily check that 
$$n\frac{a_n}{\eta_n^2}=\frac{(na_n)^2}{\frac{1}{4}\langle\theta,\Sigma_X\theta\rangle+o(1)}\to\infty,$$
and therefore eq. \eqref{eq:MD-summands-are-centered-limit-to-prove-2} holds noting that
$$a_n\log\mathbb{E}[e^{\eta_n/\sqrt{na_n}(N_n-\mathbb{E}[N_n])}]=
\eta_n^2\frac{a_n}{\eta_n^2}\log\mathbb{E}[e^{1/\sqrt{n(a_n/\eta_n^2)}(N_n-\mathbb{E}[N_n])}]\to 0$$
because $\eta_n\to 0$ and, by eq. \eqref{eq:MD-limit-for-marginal-N} with $\{a_n/\eta_n^2:n\geq 1\}$ in place of $\{a_n:n\geq 1\}$, 
$$\frac{a_n}{\eta_n^2}\log\mathbb{E}[e^{1/\sqrt{n(a_n/\eta_n^2)}(N_n-\mathbb{E}[N_n])}]\to\frac{\Lambda_N^{\prime\prime}(0)}{2}.$$
Finally, if $\eta=0$ and the limit of $\{\eta_n/\sqrt{a_n}:n\geq 1\}$ does not exist, we can find a subsequence which
converges to
$$\liminf_{n\to\infty}\frac{a_n}{\eta_n^2}\log\mathbb{E}[e^{1/\sqrt{n(a_n/\eta_n^2)}(N_n-\mathbb{E}[N_n])}]$$
and, if the subsequence of $\{\eta_n/\sqrt{a_n}:n\geq 1\}$ does not admit a limit, for every its subsequence which admits
a limit we can adapt the procedure above to say that
$$\liminf_{n\to\infty}\frac{a_n}{\eta_n^2}\log\mathbb{E}[e^{1/\sqrt{n(a_n/\eta_n^2)}(N_n-\mathbb{E}[N_n])}]=0.$$
We can do the same
$$\limsup_{n\to\infty}\frac{a_n}{\eta_n^2}\log\mathbb{E}[e^{1/\sqrt{n(a_n/\eta_n^2)}(N_n-\mathbb{E}[N_n])}]$$
showing that it is equal to zero, and therefore eq. \eqref{eq:MD-summands-are-centered-limit-to-prove-2} holds.
\end{proof}

\subsection{The exponential tightness of 
$\left\{\left(\frac{S_{N_n}-N_n\mu_X}{\sqrt{n/a_n}},\frac{N_n-\mathbb{E}[N_n]}{\sqrt{n/a_n}}\right):n\geq 1\right\}$ 
at speed $1/a_n$}\label{sub:MD-summands-are-centered-ET}
Here we refer again to the Minkowski functional $q_K$ of some $K\subset B$ and some of its properties (see the 
beginning of Section \ref{sub:LD-ET}). We have the following lemmas; as usual we refer to $\mu_X\in B$ defined in eq.
\eqref{eq:condition-for-the-mean}.

\begin{lemma}\label{lem:MD-summands-are-centered-*}
Assume that Condition \ref{cond:MD-*} holds. Let $\{a_n:n\geq 1\}$ be positive sequence such that eq. \eqref{eq:MD-conditions}
holds. Then there exists a well-balanced compact convex set $K\subset B$ such that, for every $L>0$, there exists a 
constant $c=c(L,K)>0$ such that
$$\sup_{1\leq h\leq Ln}\mathbb{E}[e^{q_K(S_h-h\mu_X)/\sqrt{na_n}}]\leq c^{1/a_n}.$$
\end{lemma}
\begin{proof}
We start noting that, by taking into account the first part	of the proof of Lemma 2.1 in \cite{deAcosta3}, we can 
say what follows:
$$\beta:=\sup\left\{\mathbb{E}\left[\exp\left(\frac{q_K(S_n-n\mu_X)}{\sqrt{n}}\right)\right]:n\geq 1\right\}<\infty;$$
for every $\lambda\in(0,1)$ we have
$$\mathbb{E}\left[\exp\left(\lambda(q_K(S_n-n\mu_X)-\mathbb{E}[q_K(S_n-n\mu_X)])\right)\right]\leq\exp(\lambda^2n\alpha)
\quad\quad\mbox{for all integers}\ n\geq 1,$$
where
$$\alpha:=\mathbb{E}[\exp(2q_K(X_1-\mu_X)-\mathbb{E}[q_K(X_1-n\mu_X)])]<\infty$$
(indeed $\alpha$ is finite because $\mathbb{E}[\exp(2q_K(X_1-\mu_X))]<\infty$, as shown in the proof of Lemma 2.1 in 
\cite{deAcosta3}). Then, for $n$ large enough, we take $\lambda=\frac{1}{\sqrt{na_n}}$ and, for all integers $h\in[1,Ln]$,
we have
$$\mathbb{E}\left[\exp\left(\frac{1}{\sqrt{na_n}}(q_K(S_h-h\mu_X)-\mathbb{E}[q_K(S_h-h\mu_X)])\right)\right]
\leq\exp(h\alpha/(na_n))\leq e^{L\alpha/a_n}$$
and therefore (here we take into account the sublinearity of $q_K(x)$ because $q_K$ is a semi-norm)
$$\mathbb{E}[\exp(q_K(S_h-h\mu_X)/\sqrt{na_n})]\leq\mathbb{E}[\exp(\mathbb{E}[q_K((S_h-h\mu_X)/\sqrt{n})]/\sqrt{a_n})]e^{L\alpha/a_n}.$$
Moreover, again for all integers $h\in[1,Ln]$, for  $\beta$ defined above we get
$$\mathbb{E}[q_K((S_h-h\mu_X)/\sqrt{n})]=\mathbb{E}[\sqrt{h/n}q_K((S_h-h\mu_X)/\sqrt{h})]\leq\sqrt{L}\mathbb{E}[q_K((S_h-h\mu_X)/\sqrt{h})]\leq\sqrt{L}\beta$$
and therefore
$$\mathbb{E}[e^{q_K(S_h-h\mu_X)/\sqrt{na_n}}]\leq e^{\sqrt{L}\beta/\sqrt{a_n}+L\alpha/a_n}\leq e^{(\sqrt{L}\beta+L\alpha)/a_n},$$
and the proof is complete by setting $c=e^{\sqrt{L}\beta+L\alpha}$.
\end{proof}

\begin{lemma}\label{lem:MD-summands-are-centered-**}
Assume that Condition \ref{cond:MD-*} holds, and let $K$ be the set in Lemma \ref{lem:MD-summands-are-centered-*}.
Let $\{a_n:n\geq 1\}$ be positive sequence such that eq. \eqref{eq:MD-conditions} holds.
Then, for $R,L>0$, there exists $\delta=\delta(R,L,K)>0$ such that
$$\sup_{1\leq h\leq Ln}P\left(\frac{S_h-h\mu_X}{\sqrt{n/a_n}}\notin\delta K\right)\leq e^{-R/a_n}\quad\quad\mbox{for all integers}\ n\geq 1.$$
\end{lemma}
\begin{proof}
Let $c$ be the quantity in Lemma \ref{lem:MD-summands-are-centered-*} which depends on $L$ and let $\delta>0$ be arbitrarily fixed.
Then, for $n\geq 1$ and for all integers $h\in[1,Ln]$, we have
\begin{multline*}
P\left(\frac{S_h-h\mu_X}{\sqrt{n/a_n}}\notin\delta K\right)=P\left(\frac{S_h-h\mu_X}{\sqrt{na_n}}\notin\frac{\delta}{a_n}K\right)
=P\left(\frac{q_K(S_h-h\mu_X)}{\sqrt{na_n}}>\frac{\delta}{a_n}\right)\\
\leq\mathbb{E}[e^{q_K(S_h-h\mu_X)/\sqrt{na_n}}]e^{-\delta/a_n}\leq c^{1/a_n}e^{-\delta/a_n}
=e^{-(\delta-\log c)/a_n};
\end{multline*}
(in the second equality we take into account that $K$ is a well-balanced set and the sublinearity of $q_K(x)$ 
because $q_K$ is a semi-norm; then we consider the Markov inequality and Lemma \ref{lem:MD-summands-are-centered-*}). 
So we conclude by taking $\delta=\delta(R,L,K)>0$ such that $\delta-\log c>R$.
\end{proof}

Now we are able to prove the desired exponential tightness condition.

\begin{proposition}\label{prop:MD-summands-are-centered-ET}
Assume that Condition \ref{cond:MD-*} and the limit in eq. \eqref{eq:limit-mean-tf-N} hold.
Let $\{a_n:n\geq 1\}$ be positive sequence such that eq. \eqref{eq:MD-conditions} holds. Then 
$\left\{\left(\frac{S_{N_n}}{n},\frac{N_n}{n}\right):n\geq 1\right\}$ is exponentially tight at speed $1/a_n$.
\end{proposition}
\begin{proof}
In this proof we show that, for all $R>0$, there exists a compact set $\widehat{K}_R\subset B\times\mathbb{R}$
such that, for some $n_2\geq 1$,
$$P\left(\left(\frac{S_{N_n}-N_n\mu_X}{\sqrt{n/a_n}},\frac{N_n-\mathbb{E}[N_n]}{\sqrt{n/a_n}}\right)\notin\widehat{K}_R\right)\leq 2e^{-R/a_n}
\quad\quad\mbox{for all}\ n\geq n_2.$$	
More precisely we consider the set
$$\widehat{K}_R:=(\delta_R K)\times [-L_R,L_R],$$
where $\delta_R:=\delta(R,L,K)>0$ according to the notation in Lemma \ref{lem:MD-summands-are-centered-**} (with the compact $K$ in that lemma),
$L>\Lambda_N^\prime(0)$, and $L_R>0$ as in eq. \eqref{eq:MD-summands-are-centered-ET-counting-processes}. Then we have
\begin{multline*}
P\left(\left(\frac{S_{N_n}-N_n\mu_X}{\sqrt{n/a_n}},\frac{N_n-\mathbb{E}[N_n]}{\sqrt{n/a_n}}\right)\notin\widehat{K}_R\right)\\
=P\left(\left(\left\{\frac{S_{N_n}-N_n\mu_X}{\sqrt{n/a_n}}\in\delta_RK\right\}\cap
\left\{\frac{|N_n-\mathbb{E}[N_n]|}{\sqrt{n/a_n}}\leq L_R\right\}\right)^c\right)\\
=P\left(\left\{\frac{S_{N_n}-N_n\mu_X}{\sqrt{n/a_n}}\notin\delta_RK\right\}\cup
\left\{\frac{|N_n-\mathbb{E}[N_n]|}{\sqrt{n/a_n}}>L_R\right\}\right)\\
=P\left(\frac{|N_n-\mathbb{E}[N_n]|}{\sqrt{n/a_n}}>L_R\right)+P\left(\left\{\frac{S_{N_n}-N_n\mu_X}{\sqrt{n/a_n}}\notin\delta_RK\right\}\cap
\left\{\frac{|N_n-\mathbb{E}[N_n]|}{\sqrt{n/a_n}}\leq L_R\right\}\right).
\end{multline*}
Now we have to estimate these two terms. For the first one we can refer to eq. \eqref{eq:MD-summands-are-centered-ET-counting-processes}.
For the second one we can say that, by Lemma \ref{lem:MD-summands-are-centered-**} with $L>\Lambda_N^\prime(0)$ (and by taking into account 
the definition of $\delta_R$), for some $n_1\geq 1$ we have
\begin{multline*}
P\left(\left\{\frac{S_{N_n}-N_n\mu_X}{\sqrt{n/a_n}}\notin\delta_RK\right\}\cap
\left\{\frac{|N_n-\mathbb{E}[N_n]|}{\sqrt{n/a_n}}\leq L_R\right\}\right)\\
=\sum_{j=\mathbb{E}[N_n]-\sqrt{n/a_n}L_R}^{\mathbb{E}[N_n]+\sqrt{n/a_n}L_R}
P\left(\left\{\frac{S_{N_n}-N_n\mu_X}{\sqrt{n/a_n}}\notin\delta_RK\right\}\cap\{N_n=j\}\right)\\
\leq\sum_{j=0}^{nL}P\left(\frac{S_j-j\mu_X}{\sqrt{n/a_n}}\notin\delta_RK\right)P(N_n=j)
\leq e^{-R/a_n}\sum_{j=0}^{nL}P(N_n=j)\leq e^{-R/a_n};
\end{multline*}
actually we also take into account the limit in eq. \eqref{eq:limit-mean-tf-N} for the first inequality.
Thus, by taking $n_2:=\max\{n_0,n_1\}$, the statement at the beginning of the proof is proved.
This completes the proof.
\end{proof}

\subsection{MD when ``the compound sum is centered''}\label{sub:MD-centered-compound-sum}
We have the following result.

\begin{proposition}\label{prop:MD-centered-compound-sum}
Consider the hypotheses in Proposition \ref{prop:MD-summands-are-centered}.
Then, for every positive sequence $\{a_n:n\geq 1\}$ such that eq. \eqref{eq:MD-conditions} holds, the sequence
$\left\{\left(\frac{S_{N_n}-\mathbb{E}[N_n]\mu_X}{\sqrt{n/a_n}},\frac{N_n-\mathbb{E}[N_n]}{\sqrt{n/a_n}}\right):n\geq 1\right\}$ satisfies
the LDP with speed $1/a_n$, and good rate function $J_{S,N}^{(2)}$ defined by
\begin{multline*}
J_{S,N}^{(2)}(x,y):=\left\{\begin{array}{ll}
\frac{\langle x-y\mu_X,\Sigma_X^{-1}(x-y\mu_X)\rangle}{2\Lambda_N^\prime(0)}+\frac{y^2}{2\Lambda_N^{\prime\prime}(0)}&
\ \mbox{if}\ \frac{x-y\mu_X}{\Lambda_N^\prime(0)}\in\mathrm{Im}(\Sigma_X)\\
\infty&\ \mbox{otherwise}.
\end{array}\right.
\quad\quad\mbox{for all}\ (x,y)\in B\times\mathbb{R}.
\end{multline*}
%
%$$H_{S,N}(x,y):=\sup_{\theta\in B^*,\eta\in\mathbb{R}}\{\langle\theta,x\rangle+\eta y-\Theta_{S,N}(\theta,\eta)\}$$
%where
%$$\Theta_{S,N}(\theta,\eta):=\frac{1}{2}(\Lambda_N^{\prime\prime}(0)(\eta+\langle\theta,\mu_X\rangle)^2+\Lambda_N^\prime(0)\langle\theta,\Sigma_X\theta\rangle).$$
\end{proposition}
\begin{proof}
We consider the function $G:B\times\mathbb{R}$ defined by
$$G(x,y):=(x+y\mu_X,y).$$
It is a continuous function and we have
$$\left(\frac{S_{N_n}-\mathbb{E}[N_n]\mu_X}{\sqrt{n/a_n}},\frac{N_n-\mathbb{E}[N_n]}{\sqrt{n/a_n}}\right)
=G\left(\left(\frac{S_{N_n}-N_n\mu_X}{\sqrt{n/a_n}},\frac{N_n-\mathbb{E}[N_n]}{\sqrt{n/a_n}}\right)\right)\quad\quad\mbox{for all}\ n\geq 1.$$
Then, by the contraction principle and Proposition \ref{prop:MD-summands-are-centered} (see the rate function $J_{S,N}^{(1)}$ in that
proposition), the desired LDP holds with good rate function $J_{S,N}^{(2)}$ defined by
$$J_{S,N}^{(2)}(x,y):=\inf\{J_{S,N}^{(1)}(z,w):G(z,w)=(x,y)\};$$
so $J_{S,N}^{(2)}(x,y)=J_{S,N}^{(1)}(x-y\mu_X,y)$ and we obtain the expression of $J_{S,N}^{(2)}$ in the statement of the proposition.
\end{proof}

\begin{remark}\label{rem:MD-coincidence-of-two-cases}
The rate functions in Propositions \ref{prop:MD-summands-are-centered} and \ref{prop:MD-centered-compound-sum}, i.e. $J_{S,N}^{(1)}$ and 
$J_{S,N}^{(2)}$, coincide if and only if $\mu_X=\widehat{0}$; indeed we have
$$\sum_{i=1}^{N_n}(X_i-\mu_X)=\sum_{i=1}^{N_n}X_i-\mathbb{E}[N_n]\mu_X\quad\quad\mbox{for all}\ n\geq 1$$
if and only if $\mu_X=\widehat{0}$ (when $N_n$ is not deterministic). Thus Propositions \ref{prop:MD-summands-are-centered} 
and \ref{prop:MD-centered-compound-sum} provide the same result if $\mu_X=\widehat{0}$.
\end{remark}

\begin{remark}\label{rem:MD-GET-for-centered-compound-sum}
One could try to prove Proposition \ref{prop:MD-centered-compound-sum} by following the same lines of the proof of Proposition 
\ref{prop:MD-summands-are-centered}. In such a case, if we refer again to the function $\Psi_{S,N}$ in eq. \eqref{eq:def-PsiSN}, the analogue 
of eq. \eqref{eq:MD-rf-LT-summands-are-centered} for $J_{S,N}^{(2)}$ is
\begin{equation}\label{eq:MD-rf-LT-centered-compound-sum}
J_{S,N}^{(2)}(x,y):=\sup_{\theta\in B^*,\eta\in\mathbb{R}}\{\langle\theta,x\rangle+\eta y-\Psi_{S,N}(\theta,\eta+\langle\theta,\mu_X\rangle)\}
\quad\quad\mbox{for all}\ (x,y)\in B\times\mathbb{R}.
\end{equation}
Indeed, by setting $\eta+\langle\theta,\mu_X\rangle=\xi$, we get
\begin{multline*}
J_{S,N}^{(2)}(x,y)=\sup_{\theta\in B^*,\xi\in\mathbb{R}}\{\langle\theta,x\rangle+(\xi-\langle\theta,\mu_X\rangle)y-\Psi_{S,N}(\theta,\xi)\}\\
=\sup_{\theta\in B^*,\xi\in\mathbb{R}}\{\langle\theta,x-y\mu_X\rangle+\xi y-\Psi_{S,N}(\theta,\xi)\}=J_{S,N}^{(1)}(x-y\mu_X,y),
\end{multline*}
and we can conclude as we did in the proof of Proposition \ref{prop:MD-centered-compound-sum}.
\end{remark}

\subsection{Some typical features}\label{sub:some-typical-features}
The aim of this section is to obtain the analogue of the limits in Remark \ref{rem:typical-features-for-N-only} (see eqs.
\eqref{eq:limit-mean-tf-N} and \eqref{eq:limit-variance-tf-N}) for the bivariate sequence in Proposition \ref{prop:LD}. 
In some sense we illustrate some typical features of moderate deviations related to the application of the G\"artner Ellis Theorem. 
In view of what follows, we introduce some notation and preliminaries. We refer to $\mu_X$ in eq. \eqref{eq:condition-for-the-mean} and to 
$\Sigma_X$ in eq. \eqref{eq:condition-for-the-covariance}. Moreover we refer to the function $\Lambda_{S,N}$ in eq. \eqref{eq:def-LambdaSN} 
which appears in the rate function expression in Proposition \ref{prop:LD} (see $I_{S,N}$ in eq. \eqref{eq:LD-rf-LT}); we use the symbols 
$\partial_\eta$ for the standard derivative with respect to $\eta$, $D_\theta$ for the first Gateaux derivative with respect to $\theta$ 
(which is a linear functional defined on $B^*$) and $D_{\theta\theta}^{(2)}$ for the second Gateaux derivative with respect
to $\theta$ (which is a bilinear form defined on $B^*$). Then we have
$$\left.D_\theta\Lambda_X(\theta)\right|_{\theta=\widehat{0}}(v)=\langle v,\mu_X\rangle\quad\quad (\mbox{for}\ v\in B^*)$$
and
$$\left.D_{\theta\theta}^{(2)}\Lambda_X(\theta)\right|_{\theta=\widehat{0}}(u,v)=\langle u,\Sigma_Xv\rangle\quad\quad (\mbox{for}\ u,v\in B^*).$$

Now we are ready to present the limits that we want to prove.
\begin{itemize}
\item The analogue of eq. \eqref{eq:limit-mean-tf-N} consists of two limits:
\begin{equation}\label{eq:limit-mean-tf-S}
\lim_{n\to\infty}\mathbb{E}[\langle S_{N_n},v\rangle/n]=
\left.D_\theta\Lambda_{S,N}(\theta,\eta)\right|_{(\theta,\eta)=(\widehat{0},0)}(v)\quad\quad (\mbox{for}\ v\in B^*),
\end{equation}
and eq. \eqref{eq:limit-mean-tf-N} itself.
\item The analogue of eq. \eqref{eq:limit-variance-tf-N} consists of three limits:
\begin{equation}\label{eq:limit-cov-tf-S,S}
\lim_{n\to\infty}n\mathrm{Cov}\left(\frac{\langle S_{N_n},u\rangle}{n},\frac{\langle S_{N_n},v\rangle}{n}\right)=
\left.D_{\theta\theta}^{(2)}\Lambda_{S,N}(\theta,\eta)\right|_{(\theta,\eta)=(\widehat{0},0)}(u,v)\quad\quad (\mbox{for}\ u,v\in B^*),
\end{equation}
\begin{equation}\label{eq:limit-cov-tf-N,S}
\lim_{n\to\infty}n\mathrm{Cov}\left(\frac{N_n}{n},\frac{\langle S_{N_n},v\rangle}{n}\right)=
\left.\partial_\eta D_\theta\Lambda_{S,N}(\theta,\eta)\right|_{(\theta,\eta)=(\widehat{0},0)}(v)\quad\quad (\mbox{for}\ v\in B^*),
\end{equation}
and eq. \eqref{eq:limit-variance-tf-N} itself.
\end{itemize}

\begin{remark}\label{rem:typical-features}
If we consider $\Psi_{S,N}(\theta,\eta+\langle\theta,\mu_X\rangle)$ which appears in eq. \eqref{eq:MD-rf-LT-centered-compound-sum}, after
some computations we can say that
$$\Psi_{S,N}(\theta,\eta+\langle\theta,\mu_X\rangle)=\frac{1}{2}\left(b_1(\theta)+2b_2(\theta)\eta+\Lambda_N^{\prime\prime}(0)\eta^2\right)
\quad\quad\mbox{for all}\ (\theta,\eta)\in B^*\times\mathbb{R},$$
where
$$b_1(\theta):=\Lambda_N^{\prime\prime}(0)(\langle\theta,\mu_X\rangle)^2+\Lambda_N^\prime(0)\langle\theta,\Sigma_X\theta\rangle\quad\quad\mbox{and}
\quad\quad b_2(\theta):=\Lambda_N^{\prime\prime}(0)\langle\theta,\mu_X\rangle.$$
Then $b_1(\theta)$ coincides with the limit value in eq. \eqref{eq:limit-cov-tf-S,S} with $u=v=\theta$ (see also eq. \eqref{eq:limit-cov-tf-S,S-explicit}) 
and $b_2(\theta)$ coincides with the limit value in eq. \eqref{eq:limit-cov-tf-N,S} with $v=\theta$ (see also eq. \eqref{eq:limit-cov-tf-N,S-explicit});
moreover we recall the limit in eq. \eqref{eq:limit-variance-tf-N} for the coefficient $\Lambda_N^{\prime\prime}(0)$ of $\eta^2$.
\end{remark}

We start with more explicit expressions of the limit values in eqs. \eqref{eq:limit-mean-tf-S}, \eqref{eq:limit-cov-tf-S,S} and 
\eqref{eq:limit-cov-tf-N,S}. Firstly we take $v\in B^*$ and we have
$$D_\theta\Lambda_{S,N}(\theta,\eta)(v)=\Lambda_N^\prime(\eta+\Lambda_X(\theta))D_\theta\Lambda_X(\theta)(v)$$
and
$$\partial_\eta D_\theta\Lambda_{S,N}(\theta,\eta)(v)=\Lambda_N^{\prime\prime}(\eta+\Lambda_X(\theta))D_\theta\Lambda_X(\theta)(v);$$
therefore we get
$$\left.D_\theta\Lambda_{S,N}(\theta,\eta)\right|_{(\theta,\eta)=(\widehat{0},0)}(v)=\Lambda_N^\prime(0)\langle v,\mu_X\rangle$$
for the limit value in eq. \eqref{eq:limit-mean-tf-S}, and
\begin{equation}\label{eq:limit-cov-tf-N,S-explicit}
\left.\partial_\eta D_\theta\Lambda_{S,N}(\theta,\eta)\right|_{(\theta,\eta)=(\widehat{0},0)}(v)=\Lambda_N^{\prime\prime}(0)\langle v,\mu_X\rangle.
\end{equation}
for the limit value in eq. \eqref{eq:limit-cov-tf-N,S}. Moreover we take $u,v\in B^*$ and we have
$$D_{\theta\theta}^{(2)}\Lambda_{S,N}(\theta,\eta)(u,v)
=\Lambda_N^{\prime\prime}(\eta+\Lambda_X(\theta))D_\theta\Lambda_X(\theta)(u)D_\theta\Lambda_X(\theta)(v)
+\Lambda_N^\prime(\eta+\Lambda_X(\theta))D_{\theta\theta}^{(2)}\Lambda_X(\theta)(u,v);$$
therefore we get
\begin{equation}\label{eq:limit-cov-tf-S,S-explicit}
\left.D_{\theta\theta}^{(2)}\Lambda_{S,N}(\theta,\eta)\right|_{(\theta,\eta)=(\widehat{0},0)}(u,v)=
\Lambda_N^{\prime\prime}(0)\langle u,\mu_X\rangle\langle v,\mu_X\rangle+\Lambda_N^\prime(0)\langle u,\Sigma_Xv\rangle
\end{equation}
for the limit value in eq. \eqref{eq:limit-cov-tf-S,S}.

Now some details on the computations of the limits. The limit in eq. \eqref{eq:limit-mean-tf-S} can be easily obtained noting that
$$\mathbb{E}[\langle S_{N_n},v\rangle/n]=\mathbb{E}[N_n/n]\mathbb{E}[\langle X_1,v\rangle]
=\mathbb{E}[N_n/n]\langle v,\mu_X\rangle,$$
and by taking into account the limit in eq. \eqref{eq:limit-mean-tf-N}.
The limit in eq. \eqref{eq:limit-cov-tf-N,S} can be easily obtained noting that (after some easy computations)
$$n\mathrm{Cov}\left(\frac{N_n}{n},\frac{\langle S_{N_n},v\rangle}{n}\right)=n\mathrm{Var}[N_n/n]\langle v,\mu_X\rangle,$$
and by taking into account the limit in eq. \eqref{eq:limit-variance-tf-N}.
The limit in eq. \eqref{eq:limit-cov-tf-S,S} can be obtained noting that
\begin{multline*}
n\mathrm{Cov}\left(\frac{\langle S_{N_n},u\rangle}{n},\frac{\langle S_{N_n},v\rangle}{n}\right)
=n\left(\mathbb{E}[N_n/n^2]\mathbb{E}[\langle X_1,u\rangle\langle X_1,v\rangle]\right.\\
\left.+\mathbb{E}[N_n(N_n-1)/n^2]\mathbb{E}[\langle X_1,u\rangle]\mathbb{E}[\langle X_1,v\rangle]
-\mathbb{E}^2[N_n/n]\mathbb{E}[\langle X_1,u\rangle]\mathbb{E}[\langle X_1,v\rangle]\right)\\
=\mathbb{E}[N_n/n]\mathrm{Cov}(\langle X_1,u\rangle,\langle X_1,v\rangle)
+n\mathrm{Var}[N_n/n]\mathbb{E}[\langle X_1,u\rangle]\mathbb{E}[\langle X_1,v\rangle]\\
=\mathbb{E}[N_n/n]\langle u,\Sigma_Xv\rangle
+n\mathrm{Var}[N_n/n]\langle u,\mu_X\rangle\langle v,\mu_X\rangle,
\end{multline*}
and by taking into account the limit in eqs. \eqref{eq:limit-mean-tf-N} and \eqref{eq:limit-variance-tf-N}.

\paragraph{A particular case: $B=C(K,\mathbb{R})$, where $K$ is a compact set.}
Here we consider the case in which $B$ is the Banach space formed by the real-valued continuous function defined on a compact set $K$.
In this case $B^*$ is the family of signed measures on $K$ and, for every $f\in B$ and $\theta\in B^*$, we have
$$\langle f,v\rangle=\int_K f(s)v(ds).$$
Then eq. \eqref{eq:condition-for-the-mean} holds with $\mu_X(\cdot)=\mathbb{E}[X_1(\cdot)]\in B$ because we have
$$\mathbb{E}[\langle X_1,v\rangle]=\int_K\mathbb{E}[X_1(s)]dv(s)$$
for every $v\in B^*$. The statement in eq. \eqref{eq:condition-for-the-covariance} holds because, for every $v\in B^*$,
we can consider $\Sigma_Xv\in B=C(K,\mathbb{R})$ defined by
$$\Sigma_Xv(s):=\int_K\mathrm{Cov}(X_1(s),X_1(t))dv(t)\quad\quad (s\in K),$$
and we have
$$\langle u,\Sigma_Xv\rangle=\langle\Sigma_Xu,v\rangle=\int_{K\times K}\mathrm{Cov}(X_1(s),X_1(t))du(s)dv(t)
=\mathrm{Cov}(\langle X_1,u\rangle,\langle X_1,v\rangle)$$
for every $u,v\in B^*$.

\section{Examples for the sequence $\{N_n:n\geq 1\}$}\label{sec:examples}
In this section we present some examples for the sequence $\{N_n:n\geq 1\}$ and, in particular, we refer to Conditions \ref{cond:LD-*}
and \ref{cond:MD-*}, and to the limits in Remark \ref{rem:typical-features-for-N-only} (see eqs. \eqref{eq:limit-mean-tf-N} and
\eqref{eq:limit-variance-tf-N}). We start with Examples \ref{ex:random-walk} and \ref{ex:NHPP} and we omit the details; we only say that we 
can refer to the proof of Theorem 3.7.1 in \cite{DZ:97} (case $d=1$) for the limit in eq. \eqref{eq:MD-limit-for-marginal-N} for Example 
\ref{ex:random-walk}.

\begin{example}\label{ex:random-walk}
	Let $\{Z_n:n\geq 1\}$ be a sequence of i.i.d. nonegative integer valued random variables with moment generating function 
	$\mathcal{G}_Z(\eta):=\mathbb{E}[e^{\eta Z_1}]$ assumed to be finite for every $\eta\in\mathbb{R}$.
	Then, if we set
	$$N_n:=Z_1+\cdots+Z_n\quad\quad\mbox{for every}\ n\geq 1,$$
    we have $\Lambda_N(\eta)=\log\mathcal{G}_Z(\eta)$ for every $\eta\in\mathbb{R}$, $\Lambda_N^\prime(0)=\mathbb{E}[Z_1]$ and 
    $\Lambda_N^{\prime\prime}(0)=\mathrm{Var}[Z_1]$.
\end{example}

\begin{example}\label{ex:NHPP}
	Let $\{M(t):t\geq 0\}$ be a homogeneous Poisson process, and let $t\mapsto\lambda(t)$ be a locally integrable intensity
	(i.e. a a locally integrable positive function) such that
	$$\lim_{t\to\infty}\frac{\int_0^t\lambda(s)ds}{t}=\widetilde{\lambda}\in(0,\infty).$$
	Then, if we set
	$$N_n:=M\left(\int_0^n\lambda(s)ds\right)\quad\quad\mbox{for every}\ n\geq 1,$$
	we have $\Lambda_N(\eta)=\widetilde{\lambda}(e^\eta-1)$ for every $\eta\in\mathbb{R}$, $\Lambda_N^\prime(0)=\widetilde{\lambda}$ and
	$\Lambda_N^{\prime\prime}(0)=\widetilde{\lambda}$.
\end{example}

We can also present other examples. The first one concerns the so-called alternative fractional Poisson process; see the family of the 
random variables presented in \cite{BeghinMacciSPL2013} as a suitable deterministic time-change of the one defined by eq. (4.1) in 
\cite{BeghinOrsingherEJP2009}.

\begin{example}\label{ex:FPP-alternative}
	Let $\nu\in(0,1]$ and $\lambda>0$ be arbitrarily fixed. Then, for every $n\geq 1$, by a suitable modified version of eq. (4.4) in 
	\cite{BeghinOrsingherEJP2009} we have
	$$\mathbb{E}[e^{\eta N_n}]=\frac{E_{\nu,1}(e^\eta\lambda n^\nu)}{E_{\nu,1}(\lambda n^\nu)}\quad\quad\mbox{for every}\ \eta\in\mathbb{R},$$
	where $E_{\nu,\beta}(x):=\sum_{r\geq 0}\frac{x^r}{\Gamma(\nu r+\beta)}$ is the two-parametric Mittag-Leffler function (see e.g. 
	\cite{GorenfloKilbasMainardiRogosin2014}). Then we have $\Lambda_N(\eta)=\lambda^{1/\nu}(e^{\eta/\nu}-1)$ for every $\eta\in\mathbb{R}$, 
	$\Lambda_N^\prime(0)=\frac{\lambda^{1/\nu}}{\nu}$ and $\Lambda_N^{\prime\prime}(0)=\frac{\lambda^{1/\nu}}{\nu^2}$. Here we give a list
	of references of interest: the proof of Proposition 4.1 in \cite{BeghinMacciSPL2013} for the limit which gives the definition of the 
	function $\Lambda_N$ in Condition \ref{cond:LD-*}; Remark 7 and the proof of Proposition 2 (for the case $m=1$) in \cite{BeghinMacciSPL2017}
	for the statements in Condition \ref{cond:MD-*}; the equality
	$$\mathbb{E}[N_n]=\frac{\lambda n^\nu}{\nu}\frac{E_{\nu,\nu}(\lambda n^\nu)}{E_{\nu,1}(\lambda n^\nu)}$$
	(which is a suitable modified version of eq. (4.6) in \cite{BeghinOrsingherEJP2009}) for the limit in eq. \eqref{eq:limit-mean-tf-N}, 
	indeed this limit can be checked by taking into account the asymptotic behavior of $E_{\nu,\beta}(x)$ as $x$ goes to infinity (see e.g. eq. 
	(4.4.16) in \cite{GorenfloKilbasMainardiRogosin2014}).
\end{example}

A further example concerns sums of independent Bernoulli random variables. In this way we consider a generalization of the results presented in
\cite{GiulianoMacciPacchiarottiJSPI2015} (Sections 3.1 and 3.2) for runs. We recover that case by taking $\mathcal{X}=[0,1]$, 
$p(x):=e^{-\lambda cx}$ for $\lambda,c>0$, and $x_{j,n}:=(j-1)\varepsilon_n$ for $1\leq j\leq n$, where $\varepsilon_n\sim\frac{1}{n}$; therefore
the weak convergence in eq. \eqref{eq:weak-convergence-in-runs-generalization} holds (see below) and $R$ is the Lebesgue measure on $\mathcal{X}$.

\begin{example}\label{ex:runs-generalization}
	Let $\mathcal{X}$ be a topological space, let $R$ be a positive measure on $\mathcal{X}$, and let $p:\mathcal{X}\to[0,1]$ be a continuous
	function. Moreover let $\{x_{j,n}:1\leq j\leq n\}$ be a family of points in $\mathcal{X}$ such that
	\begin{equation}\label{eq:weak-convergence-in-runs-generalization}
	    \frac{1}{n}\sum_{j=1}^n1_{\{x_{j,n}\in\cdot\}}\ \mbox{converges weakly to}\ R(\cdot)\quad\quad\mbox{as}\ n\to\infty,
	\end{equation}
	and let $\{Z_{j,n}:1\leq j\leq n\}$ be a sequence of random variables such that, for every $n\geq 1$, $Z_{1,n},\ldots,Z_{n,n}$ are 
	independent and
	$$P(Z_{j,n}=1)=1-P(Z_{j,n}=0)=p(x_{j,n})\quad\quad\mbox{for}\ 1\leq j\leq n.$$
    Then, if we set
    $$N_n:=Z_{1,n}+\cdots+Z_{n,n}\quad\quad\mbox{for every}\ n\geq 1,$$
    we have $\Lambda_N(\eta)=\int_{\mathcal{X}}\log(1+p(x)(e^\eta-1))R(dx)$ for every $\eta\in\mathbb{R}$, 
    $\Lambda_N^\prime(0)=\int_{\mathcal{X}}p(x)R(dx)$ and $\Lambda_N^{\prime\prime}(0)=\int_{\mathcal{X}}p(x)(1-p(x))R(dx)$. It is
    possible to check all these statements by adapting all the arguments and computations in \cite{GiulianoMacciPacchiarottiJSPI2015}.
\end{example}

A final example concerns renewal processes.

\begin{example}\label{ex:renewal-process}
	Let $\{T_n:n\geq 1\}$ be a sequence of i.i.d. positive random variables. We set $\kappa_T(\eta):=\log\mathbb{E}[e^{\eta T_1}]$ 
	and we assume that it is finite in a neighbourhood of the origin $\eta=0$, and $\kappa_T(-\infty)=-\infty$. Then, if we set
	$$N_n:=\sum_{k\geq 1}1_{\{T_1+\cdots+T_k\leq n\}},\quad\quad\mbox{for every}\ n\geq 1,$$
	the limit which gives the definition of the function $\Lambda_N$ in Condition \ref{cond:LD-*} holds with
	$\Lambda_N(\eta):=-(\kappa_T)^{-1}(-\eta)$ for every $\eta\in\mathbb{R}$, which is finite everywhere because 
	$\kappa_T(-\infty)=-\infty$ (see eqs. (12) and (13) in Theorem 1 in \cite{GlynnWhittQS1994}); moreover 
	$\Lambda_N^\prime(0)=1/(\kappa_T)^\prime(0)$ and $\Lambda_N^{\prime\prime}(0)=(\kappa_T)^{\prime\prime}(0)/((\kappa_T)^\prime(0))^3$.
	Moreover the first statement in Condition \ref{cond:MD-*} (the weak convergence to the Normal distribution) holds by Problem 27.15 
	in \cite{Billingsley-Probability-and-Measure-1995}. Then, if one can prove the second statement in Condition \ref{cond:MD-*} (i.e. 
	the limit in eq. \eqref{eq:MD-limit-for-marginal-N}) and the limit in eq. \eqref{eq:limit-mean-tf-N}, we can apply the results in 
	this paper. Note that this happens if the random variables $\{T_n:n\geq 1\}$ are exponentially distributed, and therefore 
	$\{N_n:n\geq 1\}$ is the discrete time version of the Poisson process; in particular, for $\lambda>0$, we have
	$$\kappa_T(\eta)=\log\frac{\lambda}{\lambda-\eta}\quad\quad\mbox{for}\ \eta<\lambda$$
	and $\kappa_T(\eta)=\infty$ otherwise, and $\Lambda_N(\eta)=\lambda(e^\eta-1)$ for all $\eta\in\mathbb{R}$.
\end{example}

\paragraph{Acknowledgements.}
The idea to study the problems addressed in this article was inspired by some discussions of one of the authors with Nikolai Leonenko.

\paragraph{Funding.}
The authors are supported by MIUR Excellence Department Project awarded to the Department of Mathematics, University
of Rome Tor Vergata (CUP E83C23000330006), by University of Rome Tor Vergata (project ``Asymptotic Properties in Probability''
(CUP E83C22001780005)) and by Indam-GNAMPA.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliography{bibbase}
\bibliographystyle{amsplain}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
