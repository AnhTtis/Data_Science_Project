\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.
\usepackage{booktabs}
\usepackage[table,xcdraw]{xcolor}
\usepackage{multirow}
% \usepackage{floatrow}
% \usepackage{subcaption}

\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\mca}[1]{\mathcal{#1}}
\newcommand{\mrm}[1]{\mathrm{#1}}
\newcommand{\deriv}[1]{\, \mathrm{d} #1 }

\newcommand\figcaption{\def\@captype{figure}\caption} 
\newcommand\tabcaption{\def\@captype{table}\caption} 


% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{7364} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{Uncertainty-Aware Pedestrian Trajectory Prediction via Distributional Diffusion}

\author{Yao Liu$^{1,~*}$
\and 
Zesheng Ye$^{1,}$  \thanks{Yao Liu and Zesheng Ye are co-first authors with equal contributions.}
\and 
Binghao Li$^2$
\and 
Lina Yao$^{3,1}$
\and 
$^{1}$School of Computer Science and Engineering, University of New South Wales, Sydney, Australia.\\
$^{2}$School of Minerals and Energy Resources Engineering, University of New South Wales, Sydney, Australia.\\
$^{3}$Data 61, CSIRO, Sydney, Australia.\\
{\tt\small \{yao.liu3, zesheng.ye, binghao.li, lina.yao\}@unsw.edu.au}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
% \and
% Second Author\\
% Institution2\\
% First line of institution2 address\\
% {\tt\small secondauthor@i2.org}
% \thanks{222 }
% \thanks{Yao Liu and Zesheng Ye are co-first authors with equal contributions.}
}
% \renewcommand{\thefootnote}{\fnsymbol{footnote}}
% \footnotetext[1]{Yao Liu and Zesheng Ye are co-first authors with equal contributions.}


\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% ABSTRACT
\begin{abstract}
   Tremendous efforts have been devoted to pedestrian trajectory prediction using generative modeling for accommodating uncertainty and multi-modality in human behaviors.
   % Yet the issue of whether to set up an explicit density function has long been debated.
   % Assuming a clear structure of the data ensures that explicit models are interpretable and robust. 
   % They can, however, sometimes lack expressivity.
   % On the other hand, implicit models are often more flexible but also prone to unstable training and overconfident predictions.
   % To this end, we propose to combine the merits of both worlds by modeling an implicit distribution that describes complex pedestrians' movement, whereas incorporating the predictive uncertainty of future locations with explicit density functions.
   % Specifically, we are concerned with the trajectory distribution rather than the trajectory itself.
   % Starting from random noise, we parameterize a denoising process that progressively recovers sufficient statistics of an explicit distribution for each future step.
   % The obtained explicit trajectory distribution enables to readily generate plausible future trajectories in line with the multi-modal nature.
   An individual's inherent uncertainty, e.g., change of destination, can be masked by complex patterns resulting from the movements of interacting pedestrians.
   However, latent variable-based generative models often entangle such uncertainty with complexity, leading to either limited expressivity or overconfident predictions.
   In this work, we propose to separately model these two factors by implicitly deriving a flexible distribution that describes complex pedestrians' movements, whereas incorporating predictive uncertainty of individuals with explicit density functions over their future locations.
   More specifically, we present an uncertainty-aware pedestrian trajectory prediction framework, parameterizing sufficient statistics for the distributions of locations that jointly comprise the multi-modal trajectories.
   We further estimate these parameters of interest by approximating a denoising process that progressively recovers pedestrian movements from noise.
   Unlike prior studies, we translate the predictive stochasticity to the explicit distribution, making it readily used to generate plausible future trajectories indicating individuals' self-uncertainty.
   Moreover, our framework is model-agnostic for compatibility with different neural network architectures.
   We empirically show the performance advantages of our framework on widely-used benchmarks, outperforming state-of-the-art in most scenes even with lighter backbones.
   
\end{abstract}

% The backward diffusion process can be used to gradually remove uncertainty by estimating the probability distribution of the system at earlier time points.
% This allows the model to make more confident predictions as the time horizon approaches the present.

%%%%%%%%% BODY TEXT


\section{Introduction}
% background
% Predicting human movements and pedestrian trajectories forms the basis of developing safe human-interaction autonomous systems, such as autonomous driving and intelligent surveillance in mine excavation sites.
Predicting human movements and pedestrian trajectories forms the cornerstone of safe autonomous human-machine interaction systems, such as intelligent transportation, urban planning, and underground mine automation~\cite{survey_bg01,Camera_bg2,mine_bg3}.
Large volumes of vehicles and crowded crossroads can easily pose a safety hazard to pedestrians;
detecting and anticipating peoples' future movements may, however, reduce the risk significantly.
Despite being valuable, this task is challenged by highly uncertain human behaviors resulting from interleaved self- and inter-pedestrian uncertainties.
In one sense, while following the same historical path, two trajectories originating from one pedestrian can sometimes have different futures due to their different destinations.
Meanwhile, pedestrians cannot ascertain each other's intentions and destinations but must uphold a certain amount of spatial separation, further amplifying the indeterminacy of the system.
These uncertainties highlight the complex and multi-modal nature of human motion~\cite{gupta2018social, sun2021three}.

% previous works
% The complexity and multi-modality are generally examined from two perspectives in previous studies.
In terms of complexity, trajectory prediction is viewed as a sequence-to-sequence task from a spatial-temporal viewpoint.
In particular, the spatial correlation among pedestrians is attributed to the result of social factors~\cite{helbing1995social, alahi2016social, liu2021social}.
For example, people also pay attention to not colliding with others while walking closely with companions sometimes.
This motivates the use of increasingly powerful non-linear function approximators to represent such complex correlations when further taking into account temporal dependencies, most notably importance-weighted neighboring aggregation~\cite{vemula2018social, liang2019peeking, gupta2018social, sadeghian2019sophie} with Transformers~\cite{vaswani2017attention} and dynamic social-temporal graphs~\cite{zhang2019sr, huang2019stgat, ivanovic2019trajectron, salzmann2020trajectron++}.

\begin{figure}
    \begin{center}
        \begin{small}
            \includegraphics[width=\linewidth]{figs/fig_1_1.pdf}        
        \end{small}
    \end{center}
    \caption{Illustrative difference between vanilla diffusion models~(VDMs)\protect\footnotemark[1] and UPDD. While VDMs rely on noises throughout the diffusion to introduce stochasticity, UPDD involves predictive uncertainty by modeling distributions rather than trajectories. }
    \label{fig: motivation}
\end{figure}

\footnotetext[1]{The approaches~(e.g.,~\cite{gu2022stochastic}) implementing diffusion models~\cite{NEURIPS2020_4c5bcfec} directly on {\it trajectory} are termed vanilla diffusion models.}

Upon this, it is now a standard practice to forecast multi-modal trajectories using generative models with latent variables~\cite{gupta2018social} , whereby the plausibility of future trajectories can hopefully be covered by a predictive distribution conditioned on a fixed historical context.
By harnessing latent stochasticity, models predict the distribution~(either explicitly or implicitly) of credible trajectories to approach the uncertainty.
Specifically, the methods with explicit density functions for predictive distribution mostly rely on conditional variational autoencoders~\cite{lee2017desire, ivanovic2019trajectron, salzmann2020trajectron++, mohamed2020social, chai2019multipath, chen2021personalized} that assume Gaussian outputs.
The trade-off results in latent representations with limited expressivity~\cite{burda2015importance, mescheder2017adversarial, tomczak2018vae}, often leading to unnatural generation~\cite{gu2022stochastic}.
Conversely, those implicit counterparts~\cite{gupta2018social, sadeghian2019sophie, zhao2019multi, dendorfer2021mg} could benefit from more flexible generations without a fixed density form, thanks to the adoption of Generative Adversarial Networks~(GANs)~\cite{goodfellow2020generative}.
Still, training GANs has proven difficult to mitigate mode collapse~\cite{gulrajani2017improved, radford2015unsupervised} and unstable gradients~\cite{karnewar2020msg, kodali2017convergence}.
Moreover, GANs sometimes make overconfident predictions~\cite{gawlikowski2021survey}, rendering difficulty in expressing predictive uncertainty.
These latent variable models may struggle to balance expressivity with uncertainty since there is an inherent entanglement between multi-pedestrian complexity and self-uncertainty.
% Moreover, there has been another long debate on the trade-off between network capacity and the expressiveness of latent representation
% It can be difficult to balance expressivity and uncertainty with latent variable models, since there is an inherent entanglement between task complexity and uncertainty.

% motivation of diffusion
A recent bloom has been witnessed in denoising diffusion probabilistic models~(i.e., diffusion models)~\cite{NEURIPS2020_4c5bcfec} applied to image and text generation~\cite{rombach2022high, austin2021structured}.
Diffusion models draw inspiration from non-equilibrium thermodynamics that simulates particle diffusion by progressively injecting noise into data until the signal is destroyed.
Then sampling high-fidelity data from random noise is achievable by learning to reverse such a diffusion process~\cite{sohl2015deep}.
Intuitively, this setting lends itself well to modeling pedestrian motion.
% The set of positions of the pedestrian in the time series forms a trajectory, and if the pedestrian is not subject to any constraints, he can move to any position in the open space, which is similar to the motion of a particle in thermodynamics [====MID?].
The movements of pedestrians within a system are determined by certain constraints, e.g., destinations and social regulations.
Adding noise can therefore be viewed as discarding these constraints, resulting in more indeterminate human behaviors.
In due course, the trajectories will become completely unpredictable once the system behaves like random noise.
Of interest in trajectory prediction is the likelihood of trajectory density functions, though it is too complex to be derived directly.
Alternatively, one can recover the true trajectory density function from a noisy system by approximating the reverse of the aforementioned diffusion process.
% Under high indeterminacy, particles move randomly throughout space, and as the indeterminacy decreases, particles gradually converge to a certain region.
% The most fundamental difference between pedestrian motion and particle motion is that humans are subjective, and they can adjust their speed and destination according to their will, and the uncertainty brought by this subjectivity cannot be learned accurately.
% The current consensus [====] is that pedestrian trajectory prediction is a multi-modal problem, where the future trajectory of a pedestrian can be one of many plausible future trajectories, and we need to predict the probability distribution of plausible future trajectories.
% Current work on trajectory prediction using the diffusion model, MID[====], simulates the diffusion process by gradually adding noise to the trajectory, and then recovers the trajectory by reversing the diffusion process.
In light of this, diffusion models were previously applied to trajectory prediction as attempted in vanilla diffusion models~(VDMs).
For instance, MID~\cite{gu2022stochastic} assumes the indeterminacy of pedestrians' movements can be simulated by a Markovian diffusion process resembling our motivation.
% Resembling our motivation, MID also assumes the indeterminacy of pedestrians' movements can be simulated by a Markovian diffusion process.
% However, the diffusion process is restricted to a constant dimensionality throughout - the dimension of input data.
However, given that diffusion models limit the latent dimension to the input data, VDMs propose to generate the exact coordinates of every trajectory with a complete single reverse process.
% Due to this inherent property, MID uses the true coordinates of a trajectory as input and eventually reconstructs the exact coordinates of a single trajectory as well.
% Limited by the requirement that the feature dimension is always constant in the diffusion model, MID uses two-dimensional features of pedestrian velocity for diffusion and reverse diffusion, which results in predicting clear trajectories rather than trajectory probability distributions.
% When performing multi-modal sampling of trajectories, the MID can only sample multiple different noises in the initial Gaussian distribution for reverse diffusion to recover trajectories, which transfers the subjective uncertainty of the pedestrian motion to the Gaussian distribution sampled over the whole space, without being able to obtain the probability distribution of the pedestrian trajectory.
When it comes to multi-modal predictions, this process has to be repeated multiple times with different sampled noises, not to mention that even generating an individual sample requires many iterations.
% A multi-modal prediction must be repeated multiple times with different sampled noises, not to mention generating an individual sample requires many iterations.
% MID is the first effective implementation of diffusion model for trajectory prediction, but it cannot explicitly obtain the probability distribution of pedestrian trajectories.
% This makes VDMs efficiency-costly for being much slower than previous approaches~(roughly $\times 39$~than~\cite{salzmann2020trajectron++}) since it generally takes many iterations to generate an individual sample.
In this sense, VDMs are inefficient for being much slower than previous approaches~(e.g., roughly $\times 39$ slower than~\cite{salzmann2020trajectron++}).

% In this paper, we propose uncertainty-aware trajectory prediction via distributional diffusion, where the reverse diffusion process eventually arrives at the distribution of trajectories, and thus can reasonably represent the subjective uncertainty of pedestrians.
Accordingly, we propose to explicitly parameterize the predictive distribution of trajectories rather than future trajectories themselves.
As such, individuals' self-uncertainty can be separated from modeling complex multi-pedestrian movements.
% so that both self- and inter-pedestrian uncertainty can be reasonably taken into account.
The key insight is to transform each pedestrian's exact trajectory into a readily sampled distribution, by assuming the bi-variate Gaussian form and computing their sufficient statistics.
Then, we can operate the diffusion model with a joint parametric distribution over all pedestrians in future timesteps.
By doing so, our approach transfers the predictive stochasticity from noises to the dedicated predictive distribution, allowing us to easily sample multiple trajectories and avoid running reverse diffusion intensively.

% Specifically, we obtain the prior probabilities of the trajectory distributions through a designed likelihood method, and then gradually add noise to them until the trajectory distributions become Gaussian noise to simulate the diffusion process, while the prior probabilities of the trajectory distributions are continuously corrected to the posterior probabilities to approximate the real probability distributions.
In more detail, our first step involves mapping ground-truth future trajectory data into sufficient statistics for a predictive trajectory distribution, using a neural network-based {\it Distribution Converter}.
Following, we encode the historical and neighboring information of each pedestrian with a {\it guidance encoder}, providing guidance information~\cite{ho2022classifier} for a conditional diffusion model-based {\it trajectory generator}\footnote[2]{There might be some ambiguity in the naming of {\it trajectory generator}. More precisely, we generate sufficient statistics, i.e., the distribution of trajectory, and then we sample trajectories therefrom.}, an approximation of the true reverse diffusion.
% Then we sample in Gaussian noise and obtain the probability distribution of the sample through the learned likelihood function, followed by the reverse diffusion process to gradually discard indeterminacy to obtain the probability distribution of the pedestrian trajectory.
% To ensure that the generated trajectory distributions are relevant, we encode historical and social interaction information as guidance information to lead the diffusion process and reverse diffusion process.
% Implementing the Diffusion model for trajectory prediction is undoubtedly costly, so we consider using only Convolutional Neural Network structures for both the guidance information extraction module and the Diffusion model backbone network, without the Recurrent Neural Network and Transformer structures to make our model more lightweight.
% In the Diffusion model, we adopt the DDIM paradigm [====] based on non-Markovian chains, because we end up with the probability distribution of the trajectories that allows us to ignore the effect of adding random noise to the reverse diffusion process in the DDPM paradigm, consequently increasing efficiency through the DDIM paradigm.
Moreover, concerning the efficiency issue, we follow~\cite{song2020denoising} that relaxes the Markovian assumption of~\cite{NEURIPS2020_4c5bcfec, gu2022stochastic} to accelerate sampling from noise, through the addition of multiple Markov jumps at once with deterministic transitions.
Notably, a deterministic generative process like~\cite{song2020denoising} inevitably challenges its use in MID to generate multi-modal predictions;
on the other hand, our method leans stochasticity on the predictive distribution rather than sampling from noise.
In summary, our contributions are:
\begin{itemize}
\item We present an Uncertainty-aware trajectory Prediction framework through Distributional Diffusion~(UPDD). UPDD parameterizes the trajectory distribution by approximating reverse diffusion transitions that smoothly improve predictive confidence of future movements.
% \item We design the likelihood method, which gradually corrects the prior probability of the trajectory distribution to obtain the posterior probability during the diffusion process; it obtains the probability distribution of the Gaussian noise sampling during the reverse diffusion process and thus recovers the probability distribution of the trajectory. Furthermore, in order to deal with the expensive costs of diffusion models, we design the guidance information extraction module and the diffusion model backbone network based on Convolutional Neural Networks.
\item 
% We examine an effective workaround for adapting diffusion models to probabilistic trajectory predictions with explicit likelihood, which facilitates interpretable predictions and straightforward sampling.
We separate explicit uncertainty estimation of trajectories from complex motion prediction with denoising diffusion models.
Our method generalizes previous diffusion model-based trajectory prediction approach to incorporate predictive uncertainty even with a single reverse outcome,
% by substituting exact predictions with distributions, 
enabling faster sampling with deterministically accelerated generative models.
% \item Numerous experiments and visualisations demonstrate the superiority of our model; the results of the ablation experiments analyze the contribution of the individual modules.
\item We demonstrate that our method empirically outperforms the state-of-the-art on real-world pedestrian trajectory prediction benchmarks.
In addition, we show that the expressivity of a powerful generative framework is not overwhelmed by the complexity of integrated neural networks, thus suggesting design choices with smaller model sizes when efficiency is prioritized.
\end{itemize}

\section{Related Work}
% ##############################################################################
\noindent \textbf{Trajectory Forecasting as Spatial-temporal Prediction}.
Often referred to as a sequence-to-sequence task, pedestrian trajectory forecasting uses historical trajectory data as input to predict the locations of multiple agents along future timesteps, taking their spatial correlations into account.
This sequential nature makes autoregressive recurrent structures~\cite{hochreiter1997long, chung2014empirical} a fruitful option.
Social-LSTM~\cite{alahi2016social} is a pioneering work that incorporates social interactions between agents into a recurrent neural network~(RNN) to capture both spatial and temporal dependencies.
Later studies focus mainly on encoding dynamic influences from neighbors effectively.
The attention-based methods~\cite{vemula2018social, liang2019peeking, gupta2018social, sadeghian2019sophie} aggregate neighboring information with different significance, while others construct a spatial-temporal graph to represent social interactions~\cite{zhang2019sr, huang2019stgat, ivanovic2019trajectron, salzmann2020trajectron++}.
Despite their popularity in sequential modeling, RNNs have been criticized for their inability to parallelize.
This motivates the use of powerful Transformer~\cite{vaswani2017attention} as an alternative.
For instance, STAR~\cite{yu2020spatio} employs both temporal and spatial Transformers to capture complex spatial-temporal interactions in each dimension, respectively.
In place of that, AgentFormer~\cite{yuan2021agentformer} proposes modeling two dimensions concurrently using a Transformer to prevent potential information loss caused by the independent encoding of either dimension.
Even so, Transformers can sometimes pose challenges to model efficiency due to their parameter-intensive characteristics~\cite{shi2021sgcn}.
Instead, we discuss an alternative with both spatial and temporal convolutions toward a parameter-efficient solution of trajectory prediction.
We empirically demonstrate that one can choose to use lightweight backbone networks, provided that a flexible generative framework is effectively employed.

\noindent \textbf{Trajectory Forecasting as Conditional Generative Modeling}.
Recent studies have embraced generative models to predict pedestrian trajectory distributions to account for uncertainty and multi-modality of future dynamics, conditioned on intermediate representations of historical trajectories.
One can be categorized into either type depending on whether the model outputs an explicit predictive distribution.
Centering around conditional variational autoencoders~(cVAEs), the explicit models~\cite{lee2017desire, ivanovic2019trajectron, salzmann2020trajectron++, mohamed2020social, chai2019multipath, chen2021personalized} are learned by maximizing the likelihood of predictive distribution with concrete function form.
As an example,~\cite{mohamed2020social, chai2019multipath} assume the locations subject to a bi-variate Gaussian at each timestep.
While the explicit function form allows for easier sampling and optimization, it comes with a cost of limited expressivity and jagged trajectory generation~\cite{gu2022stochastic}.
The implicit generation~\cite{gupta2018social, sadeghian2019sophie, zhao2019multi, dendorfer2021mg}, on the other hand, is shown to be more flexible by following generative adversarial networks~(GANs)~\cite{goodfellow2020generative}.
Specifically, these methods generate trajectories from random noise and adopt a discriminator to distinguish those generated from the ground-truth.
However, training GAN is notorious for being unstable, despite subsequent efforts to alleviate mode collapses, such as reversible transformations~\cite{huang2019stgat} and multiple generators~\cite{dendorfer2021mg}.
Furthermore, the latest framework MID~\cite{gu2022stochastic} sheds light on addressing the issues in both GANs and cVAEs worlds by leveraging diffusion models~\cite{NEURIPS2020_4c5bcfec}.
Similar to our motivation, MID regards the future trajectory as a whole and gradually reduces the prediction indeterminacy by learning to reverse a diffusion process that transforms a deterministic ground-truth trajectory into the stochastic Gaussian noise.
As such, MID is easier to train than GAN-based approaches whilst producing more accurate predictions than cVAE-based counterparts.
Nevertheless, MID predicts exact coordinates rather than a distribution. 
In this case, obtaining multiple plausible paths are time-consuming since each sample can only be obtained with a complete denoising process.
Unlike MID, our method enforces a mixture of bi-variate Gaussian predictions per timestep, thus enabling faster sampling from the explicit density function while still handling complex patterns of multi-pedestrian movements.

% ##############################################################################


\section{Methodology}

\subsection{Problem Formulation}
% I need first to define terminology here, otherwise can't write equations for diffusion model.
We consider the pedestrian trajectory prediction without auxiliary information, e.g., scene context and destination.
Assume $N$ pedestrians walking in a scene. 
Having observed their historical 2D locations $\mbf{X} = \{ \mbf{x}^{(n)} \}_{n=1:N} \in \mbb{R}^{N \times T \times 2}$ with $\mbf{x}^{(n)} = \{ \bs{x}^{(n)}_{t} \}_{t=1:T}$ throughout $T$ timesteps, we generate multiple plausible trajectories for each pedestrian indicating future locations. 
As of all $N$ pedestrians, we have the prediction $\hat{\mbf{Y}} = \{ \mbf{y}^{(n)} \}_{n=1:N} \in \mbb{R}^{N \times T^{\prime} \times 2} $ in the next $T^{\prime}$ timesteps by parameterizing a conditional predictive distribution $p_{\theta}(\mbf{Y} | \mbf{X})$.
Since $p_{\theta}(\mbf{Y} | \mbf{X})$ actually describes a joint outcome over $N \times T^{\prime}$ variables, we can sample multiple predicted trajectories for any pedestrian therefrom.

% We focus on the field of pedestrian trajectory prediction and expect to predict the trajectories $Traj_{pred}$ of pedestrians in the future $T_{pred}$ time by observing their historical trajectories $Traj_{obs}$ in $T_{obs}$ time. 
% Our model expects to generate distribution probabilities of future pedestrian trajectories, which are sampled under the multi-modal paradigm to predict plausible trajectories.

\subsection{Method Overview}
As part of generative approaches, we aim to learn the true distribution of future trajectories
$p(\mbf{Y} | \mbf{X})$ with a parametric approximation $p_{\theta}(\mbf{Y} | \mbf{X})$.
For each pedestrian~(indexed by~$n$), let $p(\bs{y}_{n}^{t} | \bs{y}_{n}^{t-1}, \mbf{X}) = \mathcal{N}(\bs{y}_{n}^{t}; \mu_1, \mu_2, \sigma_1, \sigma_2, \rho)$ be a bi-variate Gaussian distribution parameterized by its sufficient statistics, where $\mu_1, \mu_2, \sigma_1, \sigma_2$ are predictive means and standard deviations for each 2D coordinate, $\rho$ measures the correlation between two dimensions.
To capture complex and multi-modal $p(\mbf{Y} | \mbf{X})$, we build our generative process upon flexible diffusion models, equipped with explicit density forms at each location\footnote[3]{We only assume the bi-variate Gaussian density in each location, but not the concrete form of $p_{\theta}(\mbf{Y} | \mbf{X})$.}.
Specifically, we estimate predictive sufficient statistics by parameterizing a reverse diffusion chain that starts from random noise and progressively reduces the uncertainty of possible future trajectories.

\begin{figure*}
    \begin{center}
        \begin{small}
            \includegraphics[width=\textwidth]{figs/fig_overall.pdf}
        \end{small}
    \end{center}
    \caption{The overview of UPDD, consisting of {\color[HTML]{AFEEEE} {\it guidance extractor}} (in Sec.~\ref{sec: guidance}), {\color[HTML]{FFB6C1} {\it distribution converter}} (in Sec.~\ref{sec: mapping}) and {\color[HTML]{FFD700} {\it distributional diffusion}} (in Sec.~\ref{sec: diffusion}).
    To account for multi-modal human movements, UPDD approximates the distributions of future trajectories under a diffusion model-based generative framework.
    We encode historic and neighboring effects for each pedestrian to guide conditional diffusion;
    we map future trajectories into sufficient statistics of a parametric distribution approximating the true distribution, enabling fast sampling of future trajectories therefrom;
    we also speed up the generation with a non-Markovian ``diffusion'' chain by skipping certain steps.
    } 
    \label{fig: overall}
\end{figure*}

Fig.~\ref{fig: overall} overviews the proposed Uncertainty-Aware trajectory Prediction framework with Distributional Diffusion~(UPDD).
UPDD includes four trainable modules $\Theta := \{ \phi, \psi, \varphi, \theta \}$.
(a) {\it guidance information extractor} is applied to each pedestrian, encoding historical trajectory with $\phi(\cdot)$ and social information with $\psi(\cdot)$, respectively;
(b) {\it distribution converter} $\varphi(\cdot)$ establishes a mapping from exact future trajectories to the parameters ;
(c) {\it trajectory generator} $\theta(\cdot)$ approximates the true denoising transition and parameterizes the distribution of future trajectory.
These trainable modules are optimized jointly under a supervised paradigm.
% Our model uses a framework based on the diffusion process, where the observed trajectories serve as the guiding information to lead the diffusion and reverse diffusion process. 
% In the forward process we diffuse the sufficient statistics of the future trajectory until Gaussian noise, and in the reverse process we discard the indeterminacy of the sufficient statistics of the sample from Gaussian noise until we recover the sufficient statistics of the trajectory.
% Guidance information includes historical information and social interaction information.
% The historical information is extracted from the observed trajectories and it represents the temporal features of the current pedestrian itself.
% The social interaction information is aggregated from the historical information of the neighbors around the current pedestrian, which represents the spatial features of the current pedestrian.
% Pedestrians at the same time are neighbors of each other, and the number of pedestrians at each time point may not be consistent.
% In the diffusion process, we deal with the sufficient statistics of the trajectory rather than the trajectory itself, thus preserving the subjective uncertainty of the pedestrian; in the reverse diffusion process, we discard the indeterminacy of the sufficient statistics of the noise sample, which is the stochastic nature of the motion and it is the content that the model needs to learn, and finally generate the sufficient statistics of the trajectory, which contains the subjective uncertainty of the pedestrian that should be preserved.


\subsection{Extracting Guidance Information}
\label{sec: guidance}
% The observations of raw trajectory describe the relative coordinates of pedestrians.
% To enrich input features, we also compute velocity and acceleration solely based on coordinates.
% Unlike previous feature extraction modules based on RNN or Transformer, we design a lightweight and elegant CNN-based feature extraction module.
% The guidance information obtained by the feature extraction module is used to lead the subsequent diffusion and inverse diffusion process. For the whole system the feature extraction module can be easily replaced by other similar modules, essentially our system is model agnostic.
Commonsense says that pedestrians' trajectories depend on their past movements and surroundings.
To this end, we explore two pure CNN-based encoders $\phi(\cdot)$ and $\psi(\cdot)$ for extracting each pedestrian's historical and neighboring information, respectively.
Nonetheless, one can substitute them with any RNN-based (e.g.,~\cite{gupta2018social, sadeghian2019sophie}) or Transformer-based (e.g.,~\cite{yu2020spatio, yuan2021agentformer}) spatial-temporal encoders, since UPDD is essentially a model-agnostic probabilistic framework.

\noindent \textbf{Encoding Historical Information}.
The raw trajectory data describes the relative coordinates of pedestrians.
% To enrich the input features, we also compute velocity and acceleration solely based on coordinates.
Generally, the historical encoder $\phi$ performs the following operations.
For each pedestrian $n$ with historical observations of $T$ steps, we first apply a 1D-CNN with $T$ kernels on the input features to calculate the influences of previous steps on the last~(current) timestep.
Given that $t=T$ is the most influential step for $t=T+1$, we then concatenate the last timestep of the resulting $T$ feature maps;
and lastly adjust the importance of the concatenation using self-attention~\cite{vaswani2017attention} to obtain the historical context encoding $\hat{\mbf{x}}^{(n)}_{\phi}$.

\noindent \textbf{Encoding Neighboring Influences}.
The neighboring effects are believed to be substantial for each pedestrian, typically referred to as social interaction information~\cite{alahi2016social, gupta2018social, sadeghian2019sophie}.
Thus, we design a neighbor encoder $\psi(\cdot)$ to encode all of the neighbors' historical information for each pedestrian as well.
As the number of neighbors may vary over time, we first aggregate the input features of neighbors for each timestep $t$, leading to $T$ aggregated input features of pedestrian $n$.
Accordingly, the subsequent operations are analogous to $\phi(\cdot)$ but handle the features of neighbors, eventually producing the neighboring context encoding $\hat{\mbf{x}}^{(n)}_{\psi}$.
We include more details of $\phi(\cdot)$ and $\psi(\cdot)$ in Appendix A.

Having obtained both historical $\hat{\mbf{x}}^{(n)}_{\phi}$ and neighboring information $\hat{\mbf{x}}^{(n)}_{\psi}$, we concatenate them into pedestrian guidance information used in the generative model discussed in Sec.~\ref{sec: diffusion}.
In the following sections, we overload the term $\mbf{X}$ to denote the guidance information of all pedestrians and omit the subscript $\phi, \psi$ for clarity unless mentioned.

\subsection{Mapping Trajectory to Sufficient Statistics}
\label{sec: mapping}
To preserve the predictive uncertainty of future trajectories, we map the exact trajectory data into sufficient statistics of the bi-variate Gaussian density function at each timestep, i.e., $\varphi: \mathbb{R}^{N \times T^{\prime} \times 2} \to \mathbb{R}^{N \times T^{\prime} \times 5}$.
In other words, we aim to establish a deterministic non-linear transformation over all samples in the location space.
Our implementation is a CNN here~(can still be any other function approximators), such that
\begin{equation}
    \resizebox{0.6\linewidth}{!}{$
    \begin{aligned}
        \bs{y}_{t, \varphi}^{(n)} & = \varphi ( \bs{y}_{t}^{(n)} ), \; \text{for} \;
    % \forall \, n \in \left\{1, N \right\}, \forall \, t \in \left\{ T + 1, T^{\prime} \right\}
    \forall n, \forall t \\
    \text{with} \; \bs{y}_{t, \varphi}^{(n)} & := \left\{ \mu_1, \mu_2, \sigma_1, \sigma_2, \rho \right\} \in \mbb{R}^{5}
    \end{aligned}
    $}
\end{equation}
Each of these 5D vectors determines each pedestrian's approximated distribution and constitutes the joint event $\mbf{Y}_{\varphi}$ taking all pedestrians and timesteps into account.
% We consider them as ``samples'' in the following diffusion model-based generation process, described in Sec.~\ref{sec: diffusion}.
% We discuss the optimization of $\varphi$ in Sec.~\ref{sec: optimization}.

% \begin{equation}
%     Loss~1=MSE~ (Traj_{ss}[0,~1],~Traj_{pred})
% \end{equation}
% \begin{equation}
%     Loss~2=negative~log\text{-}likelihood~ (Traj_{ss},~Traj_{pred}) % -log_prob
% \end{equation}


\subsection{Parameterizing Predictive Distribution}
\label{sec: diffusion}
% forward: 5 to noise; diffusion; loss3
We now detail the diffusion process for reconstructing future trajectories over all pedestrians with the aforementioned sufficient statistics by considering them as ``samples'' in the generative model.
We overload and slightly abuse the term $\mbf{Y}_{0}$ to denote these samples for brevity.
As discussed in~\cite{NEURIPS2020_4c5bcfec}, the diffusion process defines a $K$-iteration Markov chain $\{ \mbf{Y}_0, \dots, \mbf{Y}_K | \mbf{X} \}$ corrupting the samples $\mbf{Y}_0$ to the noises $\mbf{Y}_K$ that span over the whole walkable area in our case.
The diffusion chain is fixed to $q(\mbf{Y}_{1:K} | \mbf{Y}_{0}, \mbf{X}) = \prod_{k=1}^{K} q(\mbf{Y}_k | \mbf{Y}_{k-1}, \mbf{X})$ in an autoregressive manner, with each intermediate transition defined as a Gaussian, parameterized by strictly decreased $\alpha_{k-1} > \alpha_{k} \in (0, 1]$:
\begin{equation}
    \resizebox{0.7\linewidth}{!}{$
    \begin{aligned}
        q & (\mbf{Y}_k | \mbf{Y}_{k-1}, \mbf{X}) \\
        & = \mathcal{N} \left( \mbf{Y}_k | \mbf{X}; \sqrt{\frac{\alpha_{k}}{\alpha_{k-1}}} \mbf{Y}_{k-1}, \left( 1 - \frac{\alpha_{k}}{\alpha_{k-1}} \mbf{I} \right)  \right)    
    \end{aligned}
    $}
\end{equation}
Notably, we can directly compute a closed-form final state $\mbf{Y}_K$ using input $\mbf{Y}_0$, enabled by recursive sampling with the reparameterization trick~\cite{kingma2013auto} in Gaussian transitions,
\begin{equation}\label{eq: ddqpm_forward_final}
    \resizebox{0.75\linewidth}{!}{$
    \begin{aligned}
        q(\mbf{Y}_K | \mbf{Y}_{0}, \mbf{X}) & = \int q( \mbf{Y}_{1:K} | \mbf{Y}_{0}, \mbf{X}) \deriv \mbf{Y}_{1:K-1}  \\
                                   & = \mca{N} \left( \mbf{Y}_K | \mbf{X}; \sqrt{\alpha_K} \mbf{Y}_0, \left(1 - \alpha_K \right) \mbf{I} \right)
    \end{aligned}
    $}
\end{equation}
That is, by sequentially adding noise to $\mbf{Y}_{0}$, the forward diffusion eventually converts it into a standard Gaussian noise $\mbf{Y}_{K}$ when $\alpha_K$ is sufficiently close to 0.
Learning to reverse the forward process allows us to recover input samples from noise.
With the guidance information extracted from historical observations $\mbf{X}$, we thus have the conditional generation process by marginalizing all the intermediate variables,
\begin{equation}
    \resizebox{0.8\linewidth}{!}{$
    \begin{aligned}
        % p_{\theta}(\mbf{Y}_0 | \mbf{X}) & = \int p_{\theta}(\mbf{Y}_{0:K} | \mbf{X}) \deriv{\mbf{Y}_{1:K}} \\
        % \text{with} \; p_{\theta}(\mbf{Y}_{0:K} | \mbf{X}) & = p_{\theta}(\mbf{Y}_{K})  \prod_{k=1}^{K} p_{\theta}(\mbf{Y}_{k-1} | \mbf{Y}_{k}, \mbf{X} ), \\
        p_{\theta}(\mbf{Y}_0 | \mbf{X}) & = \int p_{\theta} (\mbf{Y}_{0:K} | \mbf{X}) \deriv{\mbf{Y}_{1:K}} \\
        & = \int p_{\theta}(\mbf{Y}_{K})  \prod_{k=1}^{K} p_{\theta}(\mbf{Y}_{k-1} | \mbf{Y}_{k}, \mbf{X} ) \deriv{\mbf{Y}_{1:K}} \\
        \text{with} \; p_{\theta}(\mbf{Y}_{K}) & = \mca{N}(0, \mbf{I}).
    \end{aligned}
    $}
\end{equation}
where the parameters of $\theta$ are shared throughout the reverse chain, implemented as {\it trajectory generator}.
Since the true reverse process $q(\mbf{Y}_{k-1} | \mbf{Y}_{k}, \mbf{X})$ is generally intractable, we optimize a variational lower bound under instead:
\begin{equation}\label{eq: ddpm_elbo}
    \resizebox{0.8\linewidth}{!}{$
    \begin{aligned}
        & \max_{\theta} \,\mbb{E}_{p(\mbf{Y}_0 | \mbf{X})} \left[ \log p_{\theta}(\mbf{Y}_0 | \mbf{X}) \right]  \\
        & \geq \max_{\theta} \mbb{E}_{p(\mbf{Y}_{0}, \mbf{Y}_{1}, \dots, \mbf{Y}_{K} | \mbf{X})} \left[ \log \frac{ p_{\theta} (\mbf{Y}_{0:K} | \mbf{X}) }{ q(\mbf{Y}_{1:K} | \mbf{Y}_{0}, \mbf{X}) } \right] \\
        & = \max_{\theta} \mbb{E}_{p(\mbf{Y}_{0}, \mbf{Y}_{1}, \dots, \mbf{Y}_{K}  | \mbf{X})} \\ 
        & \quad \left[ \log p_{\theta} (\mbf{Y}_{K}) - \sum_{k=1}^{K} \log \frac{ p_{\theta} ( \mbf{Y}_{k-1} | \mbf{Y}_{k}, \mbf{X} ) }{ q(\mbf{Y}_{K} | \mbf{Y}_{k-1}, \mbf{X}) }  \right]
    \end{aligned}
    $}
\end{equation}
where the true distribution is termed by $p(\mbf{Y}_0 | \mbf{X})$ to be fitted with $p_{\theta}(\mbf{Y}_0 | \mbf{X})$.
Empirically, Eq.~\ref{eq: ddpm_elbo} can be simplified to the mean squared error between the ``predicted'' noise added to the sample and a noise $\epsilon_k$ randomly drawn from a standard diagonal Gaussian throughout $K$ steps,
\begin{equation}\label{eq: ddpm_elbo_emp}
    \resizebox{0.8\linewidth}{!}{$
    \begin{aligned}
        \min_{\Theta} \mca{L}_{\text{emp}} & = \sum_{k=1}^{K} \mbb{E}_{\mbf{Y}_0 \sim p(\mbf{Y}_0 | \mbf{X}), \epsilon_k \sim \mca{N}(0, \mbf{I})} \left[ || \theta( \hat{\epsilon}_k ) - \epsilon_k ||_2^2 \right] \\
        \text{with} \, \hat{\epsilon}_k & = \sqrt{\alpha_k} \mbf{Y}_0 + \sqrt{1 - \alpha_k} \epsilon_k
    \end{aligned}
    $}
\end{equation}
when we sample $\mbf{Y}_k$ by applying the reparameterization trick on $q(\mbf{Y}_k | \mbf{Y}_0, \mbf{X})$ each step\footnote[4]{While Eq.~\ref{eq: ddpm_elbo} and Eq.~\ref{eq: ddpm_elbo_emp} are designed for $\theta$, the variables $\mbf{Y}_0$ and $\mbf{X}$ are parameterized by $\varphi$ and $\phi, \psi$, so they are jointly optimized.}.

Moreover, we can follow~\cite{song2020denoising} that potentially ``shorten'' the Markovian diffusion process by adding certain Markov jumps simultaneously, as a way to accelerate sampling from diffusion models with a similar surrogate objective.

\noindent \textbf{Non-Markovian Forward Process}.
\label{sec: non_markov_fp}
Observing a large~$K$ in Eq.~\ref{eq: ddqpm_forward_final} introduces a trade-off 
between how close~$p(\mbf{Y}_K)$ gets to a standard Gaussian~\cite{sohl2015deep} and the running efficiency of autoregressive sampling, we adopt a non-Markovian forward process that generalizes a Markovian diffusion while maintaining Gaussianity in Eq.~\ref{eq: ddqpm_forward_final}.
Consider a forward process where the transition also depends on $\mbf{Y}_0$, we have its joint distribution as,
\begin{equation}
    \resizebox{0.7\linewidth}{!}{$
    \begin{aligned}
        q_{\gamma} & (\mbf{Y}_{1:K} | \mbf{Y}_0, \mbf{X}) \\
                   & = q_{\gamma} ( \mbf{Y}_{K} | \mbf{Y}_{0}, \mbf{X}) \prod_{k = 2}^{K} q_{\gamma} ( \mbf{Y}_{k-1} | \mbf{Y}_{k}, \mbf{Y}_{0}, \mbf{X})    
    \end{aligned}
    $}
\end{equation}
To ensure Gaussianity in each intermediate state depending on $\mbf{Y}_0$, such that
\begin{equation}
\resizebox{0.8\linewidth}{!}{$
q_{\gamma}( \mbf{Y}_{k} | \mbf{Y}_{0}, \mbf{X}) =\mca{N}(\mbf{Y}_{k} | \mbf{X}; \sqrt{\alpha_k} \mbf{Y}_0, (1 - \alpha_k) \mbf{I})
$}
\end{equation}
for all $k > 0$, we define the true reverse transition as
\begin{equation}\label{eq: non_mk_denoise}
    \resizebox{0.8\linewidth}{!}{$
    \begin{aligned}
        & q_{\gamma} ( \mbf{Y}_{k-1} | \mbf{Y}_{k}, \mbf{Y}_{0}, \mbf{X}) = \\
        & \mca{N}\left( \sqrt{\alpha_{k-1}} \mbf{Y}_0 + \sqrt{1 - \alpha_{k-1} - \gamma_k^2} \frac{ \mbf{Y}_k - \sqrt{\alpha_k} \mbf{Y}_0 }{ \sqrt{ 1 - \alpha_k} }, \gamma_k^{2} \mbf{I} \right)
    \end{aligned}
    $}
\end{equation}
where $\gamma \in \mbb{R}^{K}$ controls the stochasticity added to each step.
That is, the transition becomes deterministic if $\gamma \to 0$.
Resembling Eq.~\ref{eq: ddpm_elbo}, the variational lower bound is empirically approximated by,
\begin{equation}~\label{eq: ddim_elbo}
    \resizebox{0.8\linewidth}{!}{$
    \begin{aligned}
        & \max_{\theta} \mbb{E}_{q_\gamma(\mbf{Y}_{0:T})} \left[  \log \frac{p_{\theta}(\mbf{Y}_{0:K} | \mbf{X})}{ q_{\gamma}(\mbf{Y}_{1:K} | \mbf{Y}_{0}, \mbf{X}) } \right] \\
        & = \mbb{E}_{q_\gamma(\mbf{Y}_{0:T})} \left[  \log p_{\theta} (\mbf{Y}_K) + \sum_{k=1}^{K} \log p_{\theta} ( \mbf{Y}_{k-1} | \mbf{Y}_{k}, \mbf{X} )  \right. \\ 
        & \quad \left. - \log q_{\gamma} (\mbf{Y}_{K} | \mbf{Y}_{0}, \mbf{X}) - \sum_{k=2}^{K} (q_{\gamma} ( \mbf{Y}_{k-1} | \mbf{Y}_{k}, \mbf{Y}_{0}, \mbf{X} ) \right]
    \end{aligned}
    $}
\end{equation}
where $\log p_{\theta} ( \mbf{Y}_{k-1} | \mbf{Y}_{k}, \mbf{X} )$ approximates the true denoising step and is parameterized by our {\it trajectory generator}, whereas the other three terms have been derived previously.
Still, the gradients are calculated with respect to the mean square error as in Eq.~\ref{eq: ddpm_elbo_emp}.
More precisely, the generation starts from noise $p_{\theta}(\mbf{Y}_K) = \mca{N}(0, \mbf{I})$ and sequentially parameterizes next transition by replacing $\mbf{Y}_0$ in Eq.~\ref{eq: non_mk_denoise}:
\begin{equation}
    \resizebox{0.7\linewidth}{!}{$
    \begin{aligned}
        & p_{\theta}(\mbf{Y}_{k-1} | \mbf{Y}_{k}, \mbf{X}) \\ 
        & = q_{\gamma} \left( \mbf{Y}_{k-1} | \mbf{Y}_{k}, \frac{\mbf{Y}_k - \sqrt{1 - \alpha_k} \cdot \theta(\mbf{Y}_{k} | \mbf{X})}{\sqrt{\alpha_k}} \right)
    \end{aligned}
    $}
\end{equation}
where $\theta(\mbf{Y}_{k} | \mbf{X})$ is our {\it trajectory generator} conditioned on guide information $\mbf{X}$.
See details of $\theta(\cdot)$ in Appendix A.

\noindent \textbf{Accelerated Deterministic Reverse Process}.
As we have shown, a non-Markovian forward process that conditions each intermediate step on $\mbf{Y}_0$ allows us to express the joint $q_{\gamma}(\mbf{Y}_{0:T} | \mbf{Y}_0)$ in a flexible way, so long as the Gaussianity in $q_{\gamma}(\mbf{Y}_{t} | \mbf{Y}_0)$ for all $t > 0$ is ensured.
% This is a key takeaway concerning reducing the number of iterations $K$ in the reverse process.
Intuitively, this implies reducing the number of iterations with another forward process fulfilling such requirements.
Specifically, we can arbitrarily sample a sub-sequence $\tau \subset \{1, \dots, K \}$~(with length $S < T$) to form a forward process with $q_{\gamma}(\mbf{Y}_{\tau_{i}} | \mbf{Y}_0) = \mca{N}(\mbf{Y}_{\tau_{i}}; \sqrt{\alpha_{\tau_i}} \mbf{Y}_0, \sqrt{1 - \alpha_{\tau_i}} \mbf{I})$.
As such, the joint distribution can be factorized into
\begin{equation}\label{eq: ddim_joint}
    \resizebox{0.8\linewidth}{!}{$
    \begin{aligned}
        & q_{\gamma}(\mbf{Y}_{1:K} | \mbf{Y}_0) \\
        & = q_{\gamma}(\mbf{Y}_{\tau_S} | \mbf{Y}_0) \prod_{i \in \tau_{S}} q_{\gamma}(\mbf{Y}_{\tau_{i-1}} | \mbf{Y}_{\tau_{i}}, \mbf{Y}_0) \prod_{j \in \bar{\tau}} q_{\gamma}( \mbf{Y}_j | \mbf{Y}_0).
    \end{aligned}
    $}
\end{equation}
where $\bar{\tau}$ involves steps not included in $\tau$, thereby decreasing the required steps of forward iterations from $K$ to $S$.
Reversely, the generative process is also shortened to $S$ steps.
Having derived each term's closed form in Sec.~\ref{sec: non_markov_fp}, we can optimize the reverse process defined by Eq.~\ref{eq: ddim_joint} with Eq.~\ref{eq: ddim_elbo}.
Further, upon sampling the noise $\mbf{Y}_{S} \sim p_{\theta}(\mbf{Y}_{S})$, we get a deterministic generative process by setting $\gamma = 0$, proven to be more semantically meaningful in the latent space~\cite{song2020denoising}.

% \begin{equation}
%     Noise_{diff} = Diffuse~(Traj_{ss})
% \end{equation}

% \begin{equation}
%     Loss~3=MSE~ (Noise_{diff},~Noise)
% \end{equation}

% \begin{equation}
%     Loss=\lambda_1 Loss~1+\lambda_2 Loss~2+\lambda_3 Loss~3
% \end{equation}



% \begin{equation}
%     Noise_{ss} = SSmodule~(Noise_{sample})
% \end{equation}

% \begin{equation}
%     Traj_{ss} = Re\text{-}Diffuse~(Noise_{ss})
% \end{equation}

% \subsubsection{Diffusion BackBone}

% \begin{equation}
%     Guid=Concat~(Hist, Soci)
% \end{equation}

% \begin{equation}
%     Guid_k=Sum~(Attn~(Guid+\beta_k[ori,sin.cos]))
% \end{equation}

% \begin{equation}
%     Feat_{in}=Posi~(Guid_k,Traj_{ss})
% \end{equation}
% \begin{equation}
%     Feat_t=1d~CNN~(Feat_{in};k=2t-1,p=t-1)~|~t\in [1,T_{pred}/2]
% \end{equation}
% \begin{equation}
%     Feat=Concat~(Feat_1,~\dots,~Feat_{T_{pred}/2})
% \end{equation}
% \begin{equation}
%     Feat_{out}=Linear~(Guid_k,Feat)
% \end{equation}

\subsection{Sampling from Predictive Distribution}
% Gaussian sampling
From $p(\mbf{Y}_S)$, one can generate $\hat{\mbf{Y}}_0$ by running the approximate reverse transition $p_{\theta}(\mbf{Y}_{k-1} | \mbf{Y}_{k}, \mbf{X})$ iteratively.
Recall that we parameterize the explicit density function of all pedestrians at each future timestep, i.e., $\hat{\mbf{Y}}_0$ being sufficient statistics of the multi-modal predictions.
For any pedestrian $n$, the future trajectory can be generated by sampling from $p_{\theta}(\mbf{Y}_0 | \mbf{X})$ throughout every future timestep as
\begin{equation}
\resizebox{0.8\linewidth}{!}{$
    \hat{\mbf{y}}^{(n)}_{t} := (\hat{\mu}_{t,1}^{(n)}, \hat{\mu}_{t,2}^{(n)}) \sim \mca{N} \left(\mu_{t,1}^{(n)}, \mu_{t,2}^{(n)}, \sigma_{t,1}^{(n)}, \sigma_{t,2}^{(n)}, \rho_{t}^{(n)} \right)
$}
\end{equation}
for all $n \in [1, N]$ and $T < t < T^{\prime}$.
In this way, we can further easily sample trajectory predictions {\it as much as we want} from even with a single reverse run.

% \begin{equation}
%     \hat{Traj_{pred}}=(\hat{x},\hat{y}) \sim Traj_{ss}=\mathcal{N}(\mu,\sigma,\rho)
% \end{equation}
% \begin{equation}
%     \mu=(\mu_{x},\mu_{y})
% \end{equation}
% \begin{equation}
%     \sigma=(\sigma_{x},\sigma_{y})
% \end{equation}

\subsection{Multi-task Optimization}
\label{sec: optimization}
In addition to Eq.~\ref{eq: ddim_elbo}, we place two optimization objectives to account for the multi-modal nature of trajectories, and the consistency of predicted trajectories, respectively.
One, we maximize the log-likelihood of ground-truth future trajectories $\mbf{Y}$ w.r.t the predictive bi-variate Gaussian parameterized by $\mbf{Y}_{\varphi}$, towards an improved interpretation of true trajectories,
\begin{equation}\label{eq: loss_llh}
    \resizebox{0.7\linewidth}{!}{$
    \min_{\Theta} \mca{L}_{\text{llh}} = - \sum_{n=1}^{N} \sum_{t=T+1}^{T^{\prime}} \log \mca(\bs{y}_{t}^{(n)}; \, \bs{y}_{t, \varphi}^{(n)})
    $}
\end{equation}
Second, to ensure that each predictive bi-variate Gaussian matches the correct exact location, we preserve their consistencies by minimizing the mean squared error as
\begin{equation}\label{eq: loss_consistency}
    \resizebox{0.65\linewidth}{!}{$
    \min_{\Theta} \mca{L}_{\text{con}} = \sum_{n=1}^{N} || \bs{y}^{(n)}_{T+1} - \bs{\mu}^{(n)}_{T+1} ||_2^2.
    $}
\end{equation}
where $\bs{\mu}^{(n)}_{T+1}$ are predictive means of $\bs{y}_{\varphi}^{(n)}$ at the first step of predictions, i.e., $t=T+1$.
We then express the overall training objective as a linear combination of Eq.~\ref{eq: ddim_elbo}, Eq.~\ref{eq: loss_llh} and Eq.~\ref{eq: loss_consistency} with trade-off parameters $\lambda_1, \lambda_2$ and $\lambda_3$.


% log L(θ|data) = Σi=1 to n log f(xi|θ)

% \subsection{Implementation Details}
% \label{sec: network_implementation}

% \noindent \textbf{Details of} $\phi$.
% The historical path of each pedestrian is described by consecutive 2D coordinates in $T$ timesteps.
% To enrich the input features, we also compute velocity and acceleration solely based on coordinates.
% We then have the 1D-CNN encoder with $T$ kernels applied to these inputs
% \begin{equation}
%     \text{conv}()
% \end{equation}

% \begin{equation}
%     Hist_{in}=Traj_{obs} ~ [Position,~Velocity,~cceleration]
% \end{equation}
% \begin{equation}
%     Hist_t=1d~CNN~(Hist_{in};k=t,p=0)~|~t\in [1,T_{obs}]
% \end{equation}
% \begin{equation}
%     Hist_{cat}=Concat~(Hist_1[-1],~\dots,~Hist_{T_{obs}}[-1])
% \end{equation}
% \begin{equation}
%     Hist=Sum~(Attn~(Hist_{concat}))
% \end{equation}

% \noindent \textbf{Details of} $\psi$.

% \begin{equation}
%     Soci_{in}=Sum~(Hist_{in} ~of ~Neighbor_n) ~|~n\in [1,N]
% \end{equation}
% \begin{equation}
%     Soci_t=1d~CNN~(Soci_{in};k=t,p=0)~|~t\in [1,T_{obs}]
% \end{equation}
% \begin{equation}
%     Soci_{cat}=Concat~(Soci_1[-1],~\dots,~Soci_{T_{obs}}[-1])
% \end{equation}
% \begin{equation}
%     Soci=Sum~(Attn~(Soci_{cat}))
% \end{equation}

% \noindent \textbf{Details of} $\theta$.


\section{Experiments and Analysis}

\begin{table*}[ht]
    \centering
    \resizebox{0.7\linewidth}{!}{%
    \begin{tabular}{l|c|ccccc|c}
        \toprule
        \textbf{Method}                                      & \textbf{N} & \textbf{ETH}          & \textbf{HOTEL}        & \textbf{UNIV}                     & \textbf{ZARA1}              & \textbf{ZARA2}        & \textbf{AVG}          \\
        \midrule
        SocialLSTM~\cite{alahi2016social}                    & 20         & 1.09/2.94             & 0.86/1.91             & 0.61/1.31                         & 0.41/0.88                   & 0.52/1.11             & 0.70/1.52             \\
        STT~\cite{monti2022many}                             & 20         & 0.54/1.10             & 0.24/0.46             & 0.57/1.15                         & 0.45/0.94                   & 0.36/0.77             & 0.43/0.88             \\
        \midrule
        SocialGAN~\cite{gupta2018social}                     & 20         & 0.81/1.52             & 0.72/1.61             & 0.60/1.26                         & 0.34/0.69                   & 0.42/0.84             & 0.58/1.18             \\
        SoPhie~\cite{sadeghian2019sophie}~$^{\dagger}$          & 20         & 0.70/1.43             & 0.76/1.67             & 0.54/1.24                         & 0.30/0.63                   & 0.38/0.78             & 0.54/1.15             \\
        Social-BIGAT~\cite{kosaraju2019social}~$^{\dagger}$     & 20         & 0.69/1.29             & 0.49/1.01             & 0.55/1.32                         & 0.30/0.62                   & 0.36/0.75             & 0.48/1.00             \\
        MG-GAN~\cite{dendorfer2021mg}~$^{\dagger}$              & 20         & 0.47/0.91             & 0.14/0.24             & 0.54/1.07                         & 0.36/0.73                   & 0.29/0.60             & 0.36/0.71             \\
        \midrule
        Trajectron++$^*$~\cite{salzmann2020trajectron++}     & 20         & 0.67/1.18             & {\bf 0.18}/{\bf 0.28} & 0.30/0.54                         & \underline{0.25}/{\bf 0.41} & {\bf 0.18}/{\bf 0.32} & 0.32/0.55             \\
        S-STGCNN~\cite{mohamed2020social}                    & 20         & 0.64/1.11             & 0.49/0.85             & 0.44/0.79                         & 0.34/0.53                   & 0.30/0.48             & 0.44/0.75             \\
        C-STGCNN~\cite{chen2021human}                        & 20         & 0.64/1.00             & 0.38/0.45             & 0.49/0.81                         & 0.34/0.53                   & 0.32/0.49             & 0.43/0.66             \\
        N-STGCNN~\cite{liu2021social}                        & 20         & 0.66/1.22             & 0.44/0.68             & 0.47/0.88                         & 0.33/0.52                   & 0.29/0.48             & 0.44/0.76             \\
        DMRGCN~\cite{bae2021disentangled}                    & 20         & 0.60/1.09             & 0.21/\underline{0.30} & 0.35/0.63                         & 0.29/\underline{0.47}       & 0.25/0.41             & 0.34/0.58             \\
        \midrule
        {\color[HTML]{C0C0C0} STAR}~\cite{yu2020spatio}      & 20         & 0.36/0.65             & 0.17/0.36             & 0.26/0.55                         & 0.22/0.46                   & 0.31/0.62             & 0.26/0.53             \\
        {\color[HTML]{C0C0C0} PECNet}~\cite{mangalam2020not} & 20         & 0.54/0.87             & 0.18/0.24             & 0.35/0.60                         & 0.22/0.39                   & 0.17/0.30             & 0.29/0.48             \\
        \midrule
        MID$^*$~\cite{gu2022stochastic}                      & 20         & 0.54/\underline{0.82} & 0.20/0.31             & 0.30/0.57                         & 0.27/0.46                   & \underline{0.20/0.37} & 0.30/\textbf{0.51} \\
        \midrule
        UPDD(10/100)                                         & 10+10      & {\bf 0.40}/{\bf 0.82} & 0.22/0.43             & \underline{0.24}/\underline{0.49} & 0.31/0.64                   & 0.25/0.50             & \underline{0.28}/0.58 \\
        UPDD(100/200)                                        & 10+10      & \underline{0.41}/0.86 & \underline{0.19}/0.36 & {\bf 0.23}/{\bf 0.49}             & {\bf 0.23}/0.49             & 0.21/0.43             & {\bf 0.25}/\underline{0.53} \\
        % UPDD(100/200)                                        & 10/10      & {\it 0.30}/{\it 0.50} & {\it 0.18}/{\it 0.30} & {\it 0.17}/{\it 0.31}             & {\it 0.18}/{\it 0.33}       & {\it 0.17}/{\it 0.30} & {\it 0.20}/{\it 0.35} \\
        \bottomrule
    \end{tabular}
    }
    \caption{
    Overall quantitative comparisons with baselines in terms of ADE/FDE results (meters).
    $\dagger$ indicates models use auxiliary image information of scene context.
    $*$ indicates a correction of results caused by the leakage of future paths.
    {\color[HTML]{C0C0C0} STAR} and {\color[HTML]{C0C0C0} PECNet} are not included for a fair comparison because they use different settings.
    We {\bf bolded} the best results, while \underline{underlining} the second best in each scene.
    }
    \label{tab: overall_comparison}
\end{table*}

\subsection{Experiment Setup}

\noindent \textbf{Datasets}.
Our empirical evaluations are based on the ETH/UCY~\cite{ETH,UCY} benchmarks, a widely-studied real-world trajectory prediction dataset consisting of five scenes: ETH, HOTEL, UNIV, ZARA1, ZARA2.
Pedestrians in open areas are positioned in world coordinates for all scenes.
Following common settings~\cite{salzmann2020trajectron++}, we sample pedestrian movements every 0.4 seconds within each 8-second long video and convert the world coordinates to relative coordinates.
Having observed the first 8 frames~(3.2 seconds), prediction models are tasked with estimating pedestrian coordinates for the upcoming 12 frames~(4.8 seconds).

\noindent \textbf{Baselines}.
We compare UPDD with a range of state-of-the-art trajectory prediction approaches.
Other than the deterministic approaches SocialLSTM~\cite{alahi2016social} and STT~\cite{monti2022many}, the rest include models with implicit density functions: SocialGAN~\cite{gupta2018social}, SoPhie~\cite{sadeghian2019sophie}, Social-BIGAT~\cite{kosaraju2019social}, MG-GAN~\cite{dendorfer2021mg}, as well as the explicit ones: Trajectron++~\cite{salzmann2020trajectron++}, S-STGCNN~\cite{mohamed2020social}, C-STGCNN~\cite{chen2021human}, N-STGCNN~\cite{liu2021social} and DMRGCN~\cite{bae2021disentangled}.
Notably, MID~\cite{gu2022stochastic} also employs a diffusion model for trajectory prediction comparable to UPDD.
More details of baselines are outlined in Appendix B.

\noindent \textbf{Metrics}.
We report Average Displacement Error~(ADE) and Final Displacement Error~(FDE) for quantitative evaluation as per most studies.
ADE computes the average predictive error between the best estimation and the ground-truth trajectory.
FDE measures the displacement error at the last point.
We follow the leave-one-out evaluation criteria as in~\cite{salzmann2020trajectron++}: training on four out of five scenes and testing on the remaining scene.
We report the Best-of-N result.

\subsection{Comparison with State-of-the-Arts}
\label{sec: quantitative}
% \footnote[5]{The original results of both Trajectron++~\cite{salzmann2020trajectron++} and MID~\cite{gu2022stochastic} are upon leaked information\url{https://github.com/StanfordASL/Trajectron-plus-plus/issues/53}; we report the corrected results.}.

\noindent \textbf{Quantitative Evaluation}.
Tab.~\ref{tab: overall_comparison} compares UPDD with state-of-the-art in terms of ADE and FDE.
% Trajectron++~\cite{salzmann2020trajectron++}, and the MID~\cite{gu2022stochastic} based on its data pre-processing methods, overperform in their original papers due to the leakage of future trajectories during data pre-processing, which has been publicly pointed out in the open source community. Here we use the results of Trajectron++ corrected in the open source community, and the results of our reproduced MID.
% STAR~\cite{yu2020spatio} and PECNet~\cite{mangalam2020not} use the data pre-processing of SR-LSTM~\cite{zhang2019sr}, which has a different time interval of the trajectories than the other baselines. Their shorter time interval results in less time to represent the same number of frames (same 8 frames for observation and 12 frames for prediction), so they obtain better results. Here we are for demonstration purposes only, and not for a fair comparison. Even if they perform shorter time predictions, our model still has advantages in some results.
We include two diffusion schemes with UPDD, in the form of $S/K$ indicating execution steps and lengths of Markovian diffusion, respectively.
% Two schemes are used in our UPDD. 10/100 indicates that the total step size of reverse diffusion is 100 and the actual execution step size is 10; 100/200 indicates that the total step size is 200 and the actual execution step size is 100.
% Our UPDD uses a non-Markovian chain-based form of DDIM~\cite{song2020denoising}, so that acceleration can be performed by skipping steps without having to actually iterate through the total number of steps to perform reverse diffusion.
Given the hybrid nature of UPDD, we sample credible trajectories in a 10+10 manner, i.e., run reverse diffusion 10 times, select the ``best'' prediction based on the predictive means in $\varphi$, and then sample 10 multi-modal trajectories therefrom with the explicit Gaussian density.
Observe that UPDD in both schemes consistently demonstrates promising performances with ETH, UNIV and AVG results\footnote[5]{The original results of both Trajectron++~\cite{salzmann2020trajectron++} and MID~\cite{gu2022stochastic} are obtained upon leaked information~\url{https://github.com/StanfordASL/Trajectron-plus-plus/issues/53}; 
we report the corrected results reproduced by the community and ourselves.
STAR~\cite{yu2020spatio} and PECNet~\cite{mangalam2020not} sample trajectories per 0.24 seconds. 
Their prediction horizons are also shortened, making their results unfair to be involved in our comparison.
}
% Our UPDD employs a 10+10 sampling scheme, i.e., we sample 10 times in Gaussian noise to perform the reverse diffusion process for obtaining the probability distribution of the pedestrian trajectory, then select the closest probability distribution by the mean before performing 10 multi-modal samples.
% Our UPDD reports better results in most cases; even when using an actual step size of 10, it still has advantages on some datasets.
Generated approaches are generally advantageous provided they output multi-modal predictions.
Moreover, both diffusion model-based approaches, MID and UPDD reports the lowest AVG errors among all approaches, showing improved expressiveness thanks to the flexible diffusion models.
Nevertheless, UPDD consistently outperforms MID apart from ZARA2.

\noindent \textbf{Qualitative Results}.
In addition, we showcase visual comparisons of UPDD and MID with respect to the ground-truth trajectory as in Fig.~\ref{fig: qualitative}. 
In most scenes, the best output of UPDD appears to successfully identify and follow the underlying pattern of data, while MID's predictions generally stray more from the ground-truth.
\begin{figure*}
    \begin{center}
        \begin{small}
            \includegraphics[width=0.85\textwidth]{figs/fig_vis_1.pdf}
        \end{small}
    \end{center}
    \caption{Qualitative Visualization}
    \label{fig: qualitative}
\end{figure*}

% \noindent \textbf{Qualitative Visualization}.

% \begin{table}[t]
% \centering
% \resizebox{0.6\linewidth}{!}{
% \begin{tabular}{ccc}
% \toprule
% Method & Space  & Time \\ \midrule
% MID    & 3.79 M parameters & 10.33 B FLOPs   \\ \midrule
% UPDD   & 1.48 M parameters & 3.27 B FLOPS    \\ \bottomrule
% \end{tabular}
% }
% \caption{
% Complexity Analysis. 
% }
% \label{tab: complexity}
% \end{table}

\noindent \textbf{Efficiency}.
% The paradigm of diffusion for trajectory prediction is a novel concept. Reverse diffusion is a process that gradually removes uncertainty, and this process usually requires hundreds or thousands of iterations to execute.
Despite the great potential in learning complex data distribution, diffusion models are notoriously costly because it often takes hundreds or even thousands of reverse transitions to approach the data distribution from standard Gaussian noises.
To address such a significant limitation of diffusion model-based approaches, we present an effective workaround for adapting deterministically accelerated ``diffusion'' models~\cite{song2020denoising} to trajectory prediction.
Upon comparing both the time and space complexity, we observe that UPDD is only with $40\%$ parameters than that of MID and enjoys $3\times$ decreases in FLOPs with 1 iteration.
Notably, while UPDD can benefit from the boost in speed, it is not the case for MID.
Although both use diffusion models, UPDD parameterizes the explicit density functions for future locations whereas MID predicts the exact coordinates.
This being the case, MID leans all its predictive stochasticity~(for multi-modal generations) on sampled noises along with reverse diffusion, leaving it incompatible with deterministic acceleration.
On the other hand, UPDD can (theoretically) abandon noise-induced randomness from each reverse transition, since the explicit predictive distribution naturally caters to the self-uncertainty of pedestrians.
% The MID model is a direct implementation of the vanilla diffusion model in trajectory prediction, specifically it takes the paradigm of a Markov chain-based DDPM~\cite{NEURIPS2020_4c5bcfec} model, the diffusion backbone network uses a Transformer-based model, and the historical and social interaction information is extracted by the RNN-based model.
% Our UPDD model adopts the DDIM paradigm for acceleration because it uses sufficient statistics of trajectories for diffusion, taking into account pedestrian uncertainty, omitting the effect of adding randomness to each reverse diffusion in the DDPM paradigm.
% Our UPDD model employs a pure CNN structure for both diffusion backbone network as well as historical and social interaction information extraction.
% Given that the reverse diffusion process requires iterative execution of multiple steps, e.g., 100 steps for MID and 10 or 100 steps for our UPDD, we compare the complexity of the diffusion backbone network in Table~\ref{tab: complexity}.
Moreover, the time complexity can be accentuated by the fact that the reverse diffusion must run many iterations, e.g., 100 steps for MID.
Thus, the complexity scales linearly with the actual steps of execution, further emphasizing the benefits of shortening the reverse chain.
% For a single backbone network, our UPDD is 39\% of the MID in terms of spatial complexity and 32\% of the MID in terms of time complexity.
% Due to the iterative execution of reverse diffusion, the time complexity is theoretically linearly related to the step size, and the gap in time complexity is further magnified when it is actually operated.
% The results in Table~\ref{tab: overall_comparison} show that we still achieve promising results in the UPDD 10/100 mode.
% Therefore, it makes sense for UPDD to abandon adding randomness to the reverse diffusion by generating trajectories in the form of probability distributions, which gives us the inception of adopting a non-Markov chain-based DDIM paradigm acceleration.

\subsection{Ablation Studies}

% \begin{table}[t]
% \centering
% \resizebox{0.5\linewidth}{!}{
% \begin{tabular}{ccc}
% \toprule
% \textbf{Variant} & \textbf{Steps} & \textbf{ADE/FDE} \\ \midrule
% UPDD            & 100/100        & 0.25/0.49       \\
% UPDD            & 100/200        & 0.23/0.49       \\
% UPDD            & 100/300        & 0.23/0.50       \\ \midrule
% UPDD w/ DDPM    & 10             & 0.36/0.66       \\
% UPDD w/ DDPM    & 100            & 0.26/0.51       \\ \bottomrule
% \end{tabular}
% }
% \caption{
% Ablation with diffusion steps, with \# of samplings fixed to 10+10.
% }
% \label{tab: diffusion}
% \end{table}

\begin{table}[t]
    \begin{minipage}[t]{0.49\linewidth}
        \centering
        \resizebox{\linewidth}{!}{
            \begin{tabular}{ccc}
                \toprule
                \textbf{Variant} & \textbf{Steps} & \textbf{ADE/FDE}            \\ \midrule
                UPDD(I)          & 10/100         & 0.24/0.49                   \\ \midrule
                UPDD(I)          & 100/100        & 0.25/0.49                   \\
                UPDD(I)          & 100/200        & \textbf{0.23}/\textbf{0.49} \\
                UPDD(I)          & 100/300        & 0.23/0.50                   \\ \midrule
                UPDD(P)          & 10             & 0.36/0.66                   \\
                UPDD(P)          & 100            & 0.26/0.51                   \\ \bottomrule
            \end{tabular}
        }
        \caption{
            Ablation with diffusion steps, with \# of samplings fixed to 10+10.
        }
        \label{tab: diffusion}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\linewidth}
        \centering
        \resizebox{\linewidth}{!}{
            \begin{tabular}{ccc}
                \toprule
                \textbf{Variant} & \textbf{Sample} & \textbf{ADE/FDE}            \\ \midrule
                A             & 10+10           & \textbf{0.23}/\textbf{0.49} \\
                B             & 20/1            & 0.34/0.77                   \\
                C             & 1/20            & 0.41/0.79                   \\ \bottomrule
            \end{tabular}
        }
        % \vspace{12pt}
        \rule{0pt}{12pt}
        \caption{
            Ablation with different sampling strategies, retaining all other factors the same.
        }

        \label{tab: sample}
    \end{minipage}
    % \caption{Caption}
    % \label{tab:my_label}
\end{table}

% \begin{table}[t]
%     \begin{floatrow}
%         \ffigbox[]{

%         }{

%         }
%         \ffigbox[]{

%         }{

%         }
%     \end{floatrow}
% \end{table}

\noindent \textbf{Diffusion Steps}.
We now discuss the effects of varying hyperparameters of the diffusion model in Tab.~\ref{tab: diffusion}.
% No.2 is our standard UPDD model with diffusion steps 100/200 indicated by a total diffusion step of 200 and an actual execution step of 100; No.1 and No.3 have a total diffusion step of 100 and 300, respectively, and the actual execution step is still 100.
% The experiment results show that the change of the total step size has little effect on the trajectory prediction, and the ratio of the actual step size to the total step size can be chosen appropriately.
We include variants with different total diffusion steps $K = 100, 200, 300$, but share the same execution steps $S=100$.
We find that changes in $K$ do not seem to significantly affect the predictive performance; thus, a suitable ratio for shortening the chain may be chosen gently.
We also showcase a variant with $K=100$ and $S=10$, which considerably slashes the generation time, while still remaining effective.
Thus, one may consider this configuration if efficiency is of paramount importance.
% As seen in Table~\ref{tab: overall_comparison}, the results achieve promising performance on some datasets, so this model can be used when considering efficiency priorities.
% No.4 and No.5 abandon the DDIM paradigm in our UPDD in favor of the Markov chain-based DDPM paradigm, in which case the total step size is always the same as the actual step size, and they are 10 and 100, respectively.
In addition, we replace the deterministically accelerated diffusion model in UPDD with the stochastic DDPM~\cite{NEURIPS2020_4c5bcfec} used in MID, denoted by UPDD(P).
% No.4 has an incomplete diffusion process due to the small total step size, which leads to the performance degradation.
% No.5 and No.1 are close in performance because they have the same total step size.
In the case of $K=10$, UPDD(P) may suffer from incomplete diffusion, leading to a performance gap with other competitors.
The performance of UPDD(P) almost catches up with UPDD(I) when extending $K$ to 100.
The results suggest that UPDD naturally fits with deterministic ``diffusion'' chains since the stochasticity has been transferred to the predictive distribution, thereby no longer relying on noise sampling throughout the diffusion.
% This result also shows that it makes sense to discard the randomness in the reverse diffusion process on No.1, where the pedestrian uncertainty is contained in the generated trajectory distribution and does not depend on the added random noise.


% \begin{table}[t]
% \centering
% \resizebox{0.9\linewidth}{!}{
% \begin{tabular}{c|c|c|c|c}
% \toprule
% No. & Method & Diffusion Step & Sample & ADE/FDE on UNIV \\ \midrule
% 1   & UPDD   & 100/200        & 10+10         & 0.23/0.49       \\ \midrule
% 2   & UPDD   & 100/200        & 20$\times$1   & 0.34/0.77       \\ \midrule
% 3   & UPDD   & 100/200        & 1$\times$20   & 0.41/0.79       \\ \bottomrule
% \end{tabular}
% }
% \caption{
% Sampling Method Analysis. 
% }
% \label{tab: sample}
% \end{table}

\noindent \textbf{Hybrid Sampling}.
% We explore the effect of sampling method on performance and the results are shown in Table~\ref{tab: sample}.
Tab.~\ref{tab: sample} shows our exploration of how UPDD is affected by different sampling strategies.
Variant A refers to the standard UPDD, where we first run the reverse diffusion process 10 times and choose a ``best'' diffusion outcome~(sufficient statistics of the trajectory distribution) with respect to the predictive means.
We then sample 10 trajectories therefrom.
% for each pedestrian to obtain the trajectory distribution, then select a closest distribution based on the mean of the trajectory distribution, and then perform the subsequent 10 times of multi-modal sampling.
In variant B, reverse diffusion is run 20 times with one trajectory sampled from each outcome, resembling MID.
In variant C, a single run of reverse diffusion is conducted, but 20 trajectory samples are taken.
% No.2 is to directly reverse diffuse each pedestrian 20 times without multi-modal sampling; No.3 is to reverse diffuse each pedestrian 1 time and then perform 20 times multi-modal sampling.
% No.2 pins the sampling process entirely on the random noise of the reverse diffusion from. This sampling on the standard Gaussian distribution does not represent the pedestrian uncertainty well, hence the poor performance.
% No.3 samples only once on the Gaussian distribution and then 20 times on the obtained trajectory distribution. This way, if the random noise sampled at the very beginning does not represent the current pedestrian well, the future trajectory of the pedestrian cannot be well fitted even with subsequent multi-modal sampling.
In this sense, B attributes all stochasticity to random noise throughout the diffusion, disregarding the self-uncertainty in terms of the Gaussian predictions.
Conversely, C may deteriorate due to a random sample given by the starting point of reverse diffusion (it only randomly samples a Gaussian noise once).
It appears that both samplings degrade model performance, suggesting that the diffusion model becomes more effective when combined with Gaussian predictive distributions.

\section{Conclusion and Outlook}

We have presented an Uncertainty-aware Trajectory Prediction framework with distributional diffusion, which simulates the complex pedestrians' movements with a flexible diffusion model, and predicts uncertain future locations with explicit bi-variate Gaussian distributions, respectively.
While the distributional diffusion approximates the true denoising process that steadily improves confidence about future movement, the explicit predictive distributions of locations preserve inherent individual uncertainty that should not be eliminated.
By doing so, we can even bypass expensive sampling of diffusion models with deterministic accelerated means which previous models cannot.

\noindent \textbf{Limitation}.
UPDD requires careful choices for hybrid sampling with both diffusion and bi-variate Gaussian.
While sampling from the explicit Gaussian can accelerate the process, the quality of generations depends on the outcome of reverse diffusion.
It is worth exploring how to strike the right balance between efficiency and effectiveness.

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}



\end{document}