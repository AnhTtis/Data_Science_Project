%% bare_jrnl_compsoc.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% Computer Society journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE!
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/


\documentclass[10pt,conference]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[10pt,journal,compsoc]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.
%
% Note that some packages require special options to format as the Computer
% Society requires. In particular, Computer Society  papers do not use
% compressed citation ranges as is done in typical IEEE papers
% (e.g., [1]-[4]). Instead, they list every citation separately in order
% (e.g., [1], [2], [3], [4]). To get the latter we need to load the cite
% package with the nocompress option which is supported by cite.sty v4.0
% and later. Note also the use of a CLASSOPTION conditional provided by
% IEEEtran.cls V1.7 and later.





% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at:
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex






% *** MATH PACKAGES ***
%
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a sans serif font rather
% than the serif font used in traditional IEEE formatting and thus the need
% to invoke different subfig.sty package options depending on whether
% compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and
% Axel Sommerfeldt. This package may be useful when used in conjunction with
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/pkg/endfloat
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a
% page by themselves.




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\usepackage{balance}  % to better equalize the last page
\usepackage{graphics} % for EPS, load graphicx instead
%\usepackage[T1]{fontenc}
\usepackage{txfonts}
\usepackage{times}    % comment if you want LaTeX's default font
\usepackage[pdftex]{hyperref}
% \usepackage{url}      % llt: nicely formatted URLs
\usepackage{color}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{ccicons}


\usepackage{cite}
\usepackage{url}
\usepackage{fancybox}
\usepackage{multirow}
\usepackage{flushend}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{comment}
\usepackage{array}
\usepackage[flushleft]{threeparttable}
\usepackage{mdframed}
\graphicspath{{}{images/}{dia/}}
\DeclareGraphicsExtensions{.pdf,.png}


\usepackage{listings}
\usepackage{courier}
\usepackage{hyperref}

\usepackage{xpatch}
\xdef\scr{}

\xpatchcmd{\refstepcounter}{%
  \stepcounter{#1}%
}{%
  \stepcounter{#1}%
  \xdef\scr{\number\value{#1}}%
}{\typeout{success}}{\typeout{failure}}


\newcounter{o}
\setcounter{o}{0}

\usepackage{tikz}
%colors
\definecolor{1c1}{RGB}{188,162,6}
\definecolor{1c2}{RGB}{137,129,80}
\definecolor{1c3}{RGB}{239,167,31}
\definecolor{1c4}{RGB}{88,194,241}
\definecolor{1c5}{RGB}{6,180,188}

% stiles used
\tikzset{mynode/.style={draw=white,solid,circle,fill=green,inner sep=1pt, thick,
text=black}}
%draw=black to get a black circle, fill=white so it actually has a
%background and text=black to not get that rendered in the specified color
\tikzset{arrow line/.style={dashed, line width= 2.5pt, color=#1}}

\def\bf{\textbf}
\def\eq {Equation~}
\def\eqm {Eq~}
\def\eqs {Equations~}
\def\fig {Figure~}
\def\figs {Figures~}
\def\tbl {Table~}
\def\tbls {Tables~}
\def\ie{\textit{i.e.,}}
\def\eg{\textit{e.g.,}}
\def\sec {Section~}
\def\secs {Sections~}
\def\alg {Algorithm~}
\def\algs {Algorithms~}
\def\app {Appendix~}
\def\it{\textit}
\def\tr{\textrm}
\def\tt{\mct}
\newcommand{\ib}[1]{{\textbf {\textit { #1}}}}
\newcommand{\ts}[1]{{\textsc {{ #1}}}}
\newcommand{\mct}[1]{{\footnotesize {\texttt {#1}}}}
\newcommand{\Foutse}[1]{\textcolor{red}{{\it [Foutse says: #1]}}}
\newcommand{\qu}[1]{{\it{``#1''}}}
\newcommand{\api}[1]{{\sf{\texttt\small{#1}}}}
\newcommand{\callout}[1]{{\vspace{1mm}\noindent{\fbox{\parbox{0.97\columnwidth}{#1}}}\vspace{1mm}}}
\usepackage{paralist}

\let\labelindent\relax

\newcommand{\nd}{\vspace{1mm}\noindent}
\usepackage[small,bf]{caption}
%\usepackage[toc,page]{appendix}
\usepackage{tikz}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=1pt] (char) {#1};}}

 \lstset{
         language=Java,
         basicstyle=\scriptsize\ttfamily, % Standardschrift
         %numbers=left,               % Ort der Zeilennummern
         numberstyle=\tiny,          % Stil der Zeilennummern
         %stepnumber=2,               % Abstand zwischen den Zeilennummern
         numbersep=5pt,              % Abstand der Nummern zum Text
         tabsize=2,                  % Groesse von Tabs
        % extendedchars=true,         %
         breaklines=true,            % Zeilen werden Umgebrochen
%         keywordstyle=\color{black},
 %   	 frame=single,
 %        keywordstyle=[1]\textbf,    % Stil der Keywords
 %        keywordstyle=[2]\textbf,    %
 %        keywordstyle=[3]\textbf,    %
 %        keywordstyle=[4]\textbf,   \sqrt{\sqrt{}} %
         stringstyle=\color{white}\ttfamily, % Farbe der String
         showspaces=false,           % Leerzeichen anzeigen ?
         showtabs=false,             % Tabs anzeigen ?
         xleftmargin=17pt,
         framexleftmargin=17pt,
         framexrightmargin=5pt,
         framexbottommargin=4pt,
         %backgroundcolor=\color{lightgray},
         showstringspaces=false,      % Leerzeichen in Strings anzeigen ?
     %    escapeinside={\%*}{*)}
 }

\lstdefinestyle{inlinecode}{basicstyle={\ttfamily\scriptsize\bfseries}}
\newcommand\code{\lstinline[style=inlinecode]}
\newcommand{\urls}[1]{{\scriptsize\url{#1}}}
\usepackage{tcolorbox}
\newcommand{\emt}[1]{\emph{``#1''}}
\newcommand{\rev}[1]{\textcolor{blue}{#1}}
\newcommand{\anindya}[1] { \textcolor{green}{\\Anindya: #1\\}}
%\newcommand{\Foutse}[1]{\textcolor{blue}{{\it [Foutse says: #1]}}}
\usepackage{paralist}
\usepackage[outercaption]{sidecap}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
\newcounter{scn}
\setcounter{scn}{1}
\usepackage[shortlabels]{enumitem}
\usepackage{bchart}

\newcounter{finding_counter}
\setcounter{finding_counter}{1}

\newtoggle{comment}
\toggletrue{comment}

\newcommand{\topicquote}[1]{\\ \hspace*{2em}\emph{``#1"}}

\newcommand{\gias}[1] { 
    \iftoggle{comment}{
        \textcolor{red}{\\ Gias:#1 \\}
     }
}

%%%%%%%%%%%%%%%%

\usepackage{caption}
\usepackage{subcaption}

%%%%%%%%%%%%%%%%


\begin{document}
\title{On the Automatic Detection of Five API Documentation Smells: A Benchmark Study}
%\author{}% <-this % stops a
%\author{Gias Uddin and Foutse Khomh \\ SWAT Lab, Polytechnique Montr\'{e}al}% <-this % stops a
% space

%\markboth{IEEE TRANSACTIONS ON SOFTWARE ENGINEERING,~Vol.~X, No.~X,
%Month~2018}%
%{Uddin \MakeLowercase{\textit{et al.}}: Opinion Value Analysis in
%API Reviews}

\IEEEtitleabstractindextext{%
\begin{abstract}
Documentation smells are described as a bad documentation writing practice that do not make documentation incorrect but make the documentation difficult to properly understand and use the underlying method/class. In this study, we present a catalog of API documentation smells by performing exploratory analysis of the API documentation literature. We validate the catalog by conducting a survey on software developers to find out the perceived impact of these smells. To detect these documentation smells, which has been hitherto unexplored in the literature, we develop a benchmark dataset by manually validating the presence of the smells in Java official API reference and instruction documentation. We explore a suite of ML classifiers to automatically detect the smells in the documentation. Our best performing model (BERT) achieves 84\% exact match ratio in detecting the documentation smells.

%We present a catalog of API documentation smells. We develop a benchmark by manually validating the presence of the smells in Java official API reference and instructional documentation. We develop a suite of ML classifiers to automatically detect the smells in the documentation.
\end{abstract}


\begin{IEEEkeywords}
API Documentation, Smell, Empirical Study.
\end{IEEEkeywords}}

%
%\ccsdesc[500]{Software and its engineering~Software libraries and repositories}
%\ccsdesc[300]{Computer systems organization~Redundancy}
%\ccsdesc{Computer systems organization~Robotics}
%\ccsdesc[100]{Networks~Network reliability}


%\keywords{API, Usage Scenario, Crowd-Sourced API Documentation, Summarization}


\maketitle



\IEEEdisplaynontitleabstractindextext
% \IEEEdisplaynontitleabstractindextext has no effect when using
% compsoc or transmag under a non-conference mode.



% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

% https://stackoverflow.com/questions/50634335/golang-errors-and-documentation/50634506
% https://stackoverflow.com/questions/7058294/problem-with-ruby-documentation
% https://stackoverflow.com/questions/5361112/io-documentation-question
% https://stackoverflow.com/questions/51895479/documentation-about-error-in-callback-functions-of-mongoose-methods?rq=1
% https://stackoverflow.com/questions/532338/what-to-do-with-star-developers-who-dont-document-their-work
% https://stackoverflow.com/questions/55971626/problem-with-mapping-values-of-document-from-mongodb
% https://stackoverflow.com/questions/58867678/here-maps-errorunauthorized-error-descriptionapikey-invalid-apikey-no
% https://stackoverflow.com/questions/60800757/sortedset-not-working-as-per-documentation
% https://stackoverflow.com/questions/56051905/inexplicable-syntax-error-when-i-write-one-code-from-the-documentation
% https://stackoverflow.com/questions/43368110/interface-builder-where-is-the-documentation?rq=1
% https://stackoverflow.com/questions/48860513/there-is-error-on-python-documentation
% https://www.google.com/search?q=documentation+problem+site:stackoverflow.com&safe=active&rlz=1C1GCEJ_enCA805CA805&sxsrf=ALeKk00-NhuD8gojWObnmu19zxAGhH1BsA:1591039570299&ei=UlbVXq3cEYOytAaDpKSYCQ&start=50&sa=N&ved=2ahUKEwitzaSjrOHpAhUDGc0KHQMSCZM4KBDw0wN6BAgLED8&cshid=1591039584827092&biw=1920&bih=969

% %------------------------------------------
\section{Introduction}\label{sec:introduction}
% %------------------------------------------
APIs (Application Programming Interfaces) are interfaces to reusable software libraries and frameworks. The proper learning of APIs is paramount to support modern day rapid software development. To achieve this goal, APIs typically are supported by official documentation. An API documentation is a product itself, which warrants the creation and maintenance principles similar to any existing software product. A good documentation can facilitate the proper usage of an API, while a bad documentation can severely harm its adoption~\cite{Robillard-APIsHardtoLearn-IEEESoftware2009a}.
Unfortunately, research shows that API official documentation can be often incomplete, incorrect, and outdated~\cite{Uddin-HowAPIDocumentationFails-IEEESW2015}. 

We conducted an empirical study of five documentation smells in API documentation. 
We answer the following research questions: 
\begin{enumerate}[label=RQ\arabic{*}]
  \item How prevalent are the documentation smells in API official documentation?
  \item How accurate are machine learning models to automatically detect the documentation smells?
  %\item How accurate is each feature dimension the best performing ML model?
  %\item How well does hypertuning work in the ML models?
\end{enumerate}

\section{API Documentation Smells}
Similar to code and design artifacts, software documentation can exhibit smells, if the design of the documentation has problems. Documentation smells refer to presentation issues of the documentations that do not make a documentation incorrect, rather they hinder the proper usage of the documentation. A smell in an API documentation unit can inform us of the bad design in the documentation unit. A documentation unit can be the documentation of a method, a type (e.g., a class), a package, and an API overall. Following previous works in API documentation \cite{Petrosyan-DiscoverAPITypeInformation-ICSE2015, ibm_survey_paper_uddin2015api}, we consider documentation unit as the documentation of a method/type. In this section, we present a catalog of 5 documentation smells based on previous studies \cite{ibm_survey_paper_uddin2015api} and exploratory analysis of API official documentation (i.e., JAVA API documentations), and a survey conducted on software developers to validate the found smells.

%%step 1. determination of the five smells by consulting API documentation literature + developer discussions in online forums 

%%step 2. do an exploratory analysis of API official documentation to find traces of the five documentation smells.

%%step 3. consult with professional software developers of the validity of the found documentation smells.

%%step 4. finalize the list of documentation smells for our study (i.e., automatic detection)

%%step 5. create a benchmark of the documentation smells for study

%%step 6. conduct study on the automatic detection of the documentation smells using machine learning algorithms.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%
%%%%%%%%%%%%%   Full WorkFlow Image
%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]%[!htb]
  \centering
  %\vspace{-6mm}
   \hspace*{-.7cm}%
  \includegraphics[scale=.6]{new_images/FlowChartDocSmell.png}
 % \vspace{-4mm}
  \caption{Workflow of our study.}

  \label{fig:workflow_of_study}
%\vspace{-4mm}
\end{figure*}






\subsection{Catalog}
%present the five API documentation  smells with examples. this is basically your presentation to me describing the smells.
We present 5 types of documentation smells where the first 4 types (i.e., Bloated, Excess Structural Information, Tangled, Fragmented) were cited by the IBM developers in a previous study \cite{ibm_survey_paper_uddin2015api} and the last one (i.e., Lazy) is introduced for the first time, being motivated by developers' discussion on various online forums (see Figure \ref{fig:motivating_lazy_example}). We believe that this catalog will help the developers to get a better understanding of documentation smells, and will facilitate future researches in this direction.

%%%%%%%%%%%%
%%  Motivating Example of Lazy
%%%%%%%%%%%%
\begin{figure}[t]%[!htb]
  \centering
  %\vspace{-6mm}
   \hspace*{-.7cm}%
  \includegraphics[scale=.18]{new_images/motivating_example_lazy.JPG}
 % \vspace{-4mm}
  \caption{Tweet complaining about lazy documentation of code}

  \label{fig:motivating_lazy_example}
%\vspace{-4mm}
\end{figure}


%\gias{give a visual example of each documentation smell}

\gias{describe each smell in the following format: what it is (texts + a figure), why it is chosen (mention previous research + discussion of the smell in web discussions) + what do developers in the survey think about it.}
\subsubsection{Bloated}
By `Bloated’ we mean those documentations whose description (of an API element type) is verbose or excessively extensive. It is difficult to understand lengthy documentations and use them properly. Moreover, they cannot be effectively handled that makes them hard to modify when needed, i.e. in case of any update in the API source codes. In our evaluation, we found many documentations that are larger than necessary. For example, the documentation shown in Figure \ref{fig:bloated_example} is so verbose and lengthy that it is hard to follow and use it. Hence, it is a bloated documentation.   


%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Example Image 
%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[t]%[!htb]
  \centering
  %\vspace{-6mm}
   \hspace*{-.7cm}%
  \includegraphics[scale=.5]{new_images/bloated_example.png}
 % \vspace{-4mm}
  \caption{Example of Bloated Smell}

  \label{fig:bloated_example}
%\vspace{-4mm}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%







\subsubsection{Excess Structural Information}
A documentation with `Excess Structural Information’ smell contains too many structural syntax or information, e.g., the Javadoc of the java.lang.Object class Javadoc lists all the hundreds of subclasses of the class. In our study, we find this type of documentation to contain many class and package names. For instance, the documentation of Figure \ref{fig:excess_struct_example} contains many structural information (marked in red rectangle) that are unnecessary to understand and use the underlying method. 

%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Example Image 
%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[t]%[!htb]
  \centering
  %\vspace{-6mm}
   \hspace*{-.7cm}%
  \includegraphics[scale=.5]{new_images/excess_struct_example.png}
 % \vspace{-4mm}
  \caption{Example of Excess Structural Information}

  \label{fig:excess_struct_example}
%\vspace{-4mm}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%




\subsubsection{Tangled}
We call a documentation `Tangled’ if its’ description is tangled with various information that makes it complex, reduces the readability and understandability of the description. Figure \ref{fig:tangled_example} depicts an example of tangled documentation which is hard to follow and understand.

%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Example Image 
%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[t]%[!htb]
  \centering
  %\vspace{-6mm}
   \hspace*{-.7cm}%
  \includegraphics[scale=.5]{new_images/tangled_example.png}
 % \vspace{-4mm}
  \caption{Example of Tangled Smell}

  \label{fig:tangled_example}
%\vspace{-4mm}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsubsection{Fragmented}
Sometimes it is seen that the information of documentation (related to an API element) is scattered over too many pages or sections. We consider them in the “Fragmented” category. In our empirical study, we found a good number of documentation that contain many URLs, and references that indicate possible fragmentation smell.
%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Example Image 
%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[t]%[!htb]
  \centering
  %\vspace{-6mm}
   \hspace*{-.7cm}%
  \includegraphics[scale=.5]{new_images/fragmented_example.png}
 % \vspace{-4mm}
  \caption{Example of Fragmented Smell}

  \label{fig:fragmented_example}
%\vspace{-4mm}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsubsection{Lazy}
We categorize a documentation as `Lazy’ if it contains very small information to convey to the readers. In many cases, it is seen that the documentation does not contain any extra information except what can be perceived directly from the function name. So this kind of documentation does not have much to offer to the readers. We can see a lazy documentation in Figure \ref{fig:lazy_example}. 

%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Example Image 
%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[t]%[!htb]
  \centering
  %\vspace{-6mm}
   \hspace*{-.7cm}%
  \includegraphics[scale=.5]{new_images/lazy_example.png}
 % \vspace{-4mm}
  \caption{Example of Lazy Smell}

  \label{fig:lazy_example}
%\vspace{-4mm}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%






\subsection{Description of the survey}
How do developers feel about the smells?
talk very briefly about the survey by simply motivating the detection of the smells.


\section{Study Setup}
\subsection{Benchmark of Documentation Smells}
\subsubsection{Data Collection}
talk about how data is collected, i.e., how we created the dataset for everyone to label for benchmarks.
\subsubsection{Process}
talk briefly about the benchmark creation process
\subsection{Studied Features}
\gias{put the feature summaries in a table}
%discuss the features, group the features into a set of feature dimensions.
In this subsection, we describe the features that we used to train our SVM and \it{k}NN-based models (see section \ref{subsubsec:ovr_svm} to \ref{subsubsec:ml_knn}) for documentation smell detection.

\subsubsection{Documentation Length}
We use the length of every documentation in order to capture the extensiveness of the bloated documentations.

\subsubsection{Readability Metrics}
We measure Flesch readability metrics for the documentations and use them as a feature to analyze the understandability of documentation. This feature might be useful to detect tangled documentations.
\gias{justify using an example why this feature is chosen}
\subsubsection{Number of Acronyms and Jargons}
Since acronyms and jargons increase the complexity of a reading passage, we use the number of acronyms and jargon in every documentation to detect the tangled documentation by estimating the understandability.

\subsubsection{Number of URLs}
As URLs are hints of possible fragmentations in the documentation, we use the number of URLs to capture these smells.

\subsubsection{Number of function, class and package name mentioned}
We use the number of functions, classes, packages mentioned in documentation to capture excess structural information and fragmentation.

\subsubsection{Edit Distance}
From the definition of lazy documentation, it can be said that the edit distance of a lazy documentation and its’ unit definition (method prototype) will be comparatively small. So we calculate the edit distance between the documentation description and method prototype and use it as a feature for our machine learning models.

\subsubsection{Average Cosine Similarity}
We calculate the avg. cosine similarity of the documentations’ description. For this, we calculate the cosine similarities between each possible pair of that documentation and take their avg value for normalization. This feature will help to detect redundancy in the documentations.


\subsection{Studied Algorithms}
We applied both traditional and deep learning algorithms to detect documentation smells. We employed different decomposition approaches (i.e., One-Vs-Rest, Label Powerset, Classifier Chains)~\cite{multilabel_decomp_1_MultilabelClassificationAnOverview,multilabel_decomp_2_AReviewOnMultilabelLearning,multilabel_decomp_3_ATutorialOnMultilabelClassification,multilabel_decomp_4_LearningFromMultilabelData} with Support Vector Machine (SVM) \cite{SVM_SupportVectorNetworks} as the base estimator for multi-label classification of documentation smells. We chose SVM since it has been successfully used with these decomposition approaches for multi-label classification in previous studies \cite{SVM_multi_1_AKernelMethodForMultilabelled, SVM_multi_2_TextCategorizationWithSVM}. SVM has also shown great performance in text classification tasks \cite{svm_text_classification_1, svm_text_classification_2}. We also evaluated adapted approaches like ML-$k$NN \cite{MLkNN_ALazyLearningApproach}, and deep learning models like Bi-LSTM \cite{bi_lstm_BidirectionalRecurrentNeuralNetworks}, and BERT \cite{bert_base_BertPretrainingOfDeepBidirectionalTransformers}. 
\gias{group the studied algorithms into shallow vs deep maybe?}
\subsubsection{OVR-SVM}
\label{subsubsec:ovr_svm}
One-Vs-Rest is a heuristic method that works by decomposing the multi-label classification problem into multiple independent binary classification problems (one per class) \cite{multilabel_decomp_1_MultilabelClassificationAnOverview, multilabel_decomp_3_ATutorialOnMultilabelClassification}. It trains a single classifier per class, with the samples of that class as positive samples and all other samples as negatives. All the independent classifiers then separately give individual class predictions for unseen data. We evaluated One-Vs-Rest (OVR) approach with SVM (as the base estimator) for detecting documentation smells. One-Vs-Rest support vector machine (OVR-SVM) has been successfully applied in several problems \cite{SVM_multi_1_AKernelMethodForMultilabelled, SVM_multi_2_TextCategorizationWithSVM, multilabel_decomp_1_MultilabelClassificationAnOverview}. We used RBF kernel for the SVM classifiers as recommended by earlier works \cite{svm_rbf_1_AComparisonStudyOfDifferentKernelFunctions, svm_rbf_2_APracticalGuideToSVM}.

\subsubsection{LPS-SVM}
\label{subsubsec:lps_svm}
Label Power Set (LPS) treats every combination of labels as a new class and approaches in a multiclass classification manner \cite{LearningMultiLabelSceneClassification}. As a result, this method has high computational complexity. However, it is capable of taking label correlation into account. We used SVM (with RBF kernel) as the base estimator of the Label Power Set method \cite{SVM_multi_1_AKernelMethodForMultilabelled, SVM_multi_2_TextCategorizationWithSVM}.


\subsubsection{CC-SVM}
\label{subsubsec:cc_svm}
Classifier Chains (CC) constructs a chain of binary classifiers, where every classifier uses the predictions of all the previous classifiers of the chain \cite{CC_1_ClassifierChainsForMultilabel, CC_2_ClassifierChainsForMultilabel}. This way the method can take label correlations into account. We constructed a Classifier Chain (CC) of SVMs and evaluated its’ performance for documentation smell detection.



\subsubsection{ML-$k$NN}
\label{subsubsec:ml_knn}
Multi-label $k$ Nearest Neighbors (ML-$k$NN) is derived from the traditional $k$-nearest neighbor ($k$NN) algorithm \cite{MLkNN_ALazyLearningApproach}. It finds the $k$ nearest neighborhood of an input instance using $k$NN, then uses Bayesian inference to determine the label set of the instance. We studied this method because it has been reported to achieve considerable performance for different multi-label classification tasks in previous studies \cite{MLkNN_ALazyLearningApproach, mlknn_MultilabelTextClassificationUsingSemanticFeatures}. We used ML-$k$NN with the number of nearest neighbors, $K$ = 10 during our experiment as recommended by \cite{mlknn_MultilabelTextClassificationUsingSemanticFeatures}.


\subsubsection{Bi-LSTM}
Bidirectional LSTM is more capable of exploiting contextual information than the unidirectional LSTM \cite{bilstm_FramewisePhonemeClassificationWithBiLSTM}. Hence, the Bi-LSTM network can detect the documentation smell by capturing the information of the API documentations from both directions. We constructed a Bi-LSTM model with 300 hidden states and initialized it using the pre-trained GloVe embedding \cite{Glove_GlobalVectorsForWordRepresentation} of 100 dimensions. We used ADAM optimizer \cite{adam_optimizer} with an initial learning rate of 0.001. We trained the model with batch size 256 over 10 epochs.


\subsubsection{BERT}
Considering the great success of BERT (Bidirectional Encoder Representations from Transformers) in various natural language processing and text classification tasks \cite{bert_success_1,bert_success_2,bert_success_3,bert_success_4,bert_success_5,bert_success_6,bert_success_7}, we feel motivated to evaluate its’ performance in documentation smell detection. BERT is a  pre-trained model which was designed to learn contextual word representations of unlabeled texts \cite{bert_base_BertPretrainingOfDeepBidirectionalTransformers}. We used BERT-Base for this study which has 12 layers with 12 attention heads and 110 million parameters. We trained it on our labeled dataset for 10 epochs with a mini-batch size of 32. We used early-stop to avoid overfitting \cite{early_stop_bert_1} and considered validation loss as the metric of the early-stopping \cite{early_stop_bert_2}. The maximum length of the input sequence was set to 256. We used AdamW optimizer \cite{adam_w} with the learning rate set to 4e\textsuperscript{-5}, ß1 to 0.9, ß2 to 0.999, and epsilon to 1e\textsuperscript{-8} \cite{bert_base_BertPretrainingOfDeepBidirectionalTransformers, bert_fine_tuning}. We used binary cross-entropy to calculate the loss \cite{binary_cross_AreLossFunctionSame}. 


\subsection{Performance Metrics}
We analyze and report the performance of each of the techniques developed and experimented as part of the algorithms development steps. We used 5-fold iterative stratified cross-validation for reporting performances that has been recommended for a multilabel dataset in \cite{iterative_stratified_cross_valid}. We report the performances using standard multi-label classification metrics, i.e., Exact Match Ratio, Hamming Loss \cite{a_literature_survey_on_algorithms_for_multilabel}. We also report separate Accuracy, Precision, Recall, and F1-score for each class.

\subsubsection{Iterative Stratified Cross-Validation}
Traditional $k$-fold cross-validation is a statistical method of evaluating machine learning algorithms which divides data into $k$ equally sized folds and runs for $k$ iterations \cite{traditional_cross_validation_paper}. In each iteration, each of the $k$ folds is used as the held-out set for validation while the remaining $k-1$ folds are used as training sets. Stratified cross-validation is used to make sure that each fold is an appropriate representative of the original data by producing folds where the proportion of different classes is maintained \cite{stratified_cross_validation_paper}. However, stratification is not sufficient for multi-label classification problems as the number of distinct labelsets (i.e., different combinations of labels) is often quite large. For example, there can be 32 combinations of labels in our study as there are 5 types of documentation smells. In such cases, original stratified $k$-fold cross-validation is impractical since most groups might consist of just a single example. Iterative stratification, proposed by \cite{iterative_stratified_cross_valid}, solves this issue by employing a greedy approach of selecting the rarest groups first and adding them to the smallest folds while splitting. Hence, we used this iterative stratified cross-validation in our experiment. 

\subsubsection{Exact Match Ratio}
In multi-label classification, prediction for an instance is a set of labels. Hence, it has a notion of partially correct prediction (along with fully correct and incorrect). The Exact Match Ratio ($EMR$) ignores the partially correct prediction and considers only those predictions as correct which exactly match the true label sets.

\begin{equation}
EMR  = \frac{1}{N} \sum_{i=1}^{N} I (L_i^{pred} = L_i^{true})
\label{eq:EMR}
\end{equation} %&

{$I$ is the indicator function. Its' value is 1 if the prediction, $L_i^{pred}$ matches the actual label, $L_i^{true}$, and 0 otherwise. $N$ is the total number of data.
}


\subsubsection{Hamming Loss}
Hamming Loss ($HL$) is the fraction of labels in labelsets that are incorrectly predicted, i.e., the fraction of the wrong labels to the total number of labels \cite{hamming_loss_paper}. It takes the notion of partially correct prediction into account.  
\begin{equation}
HL  = \frac{1}{N\cdot L} \sum_{i=1}^{N} \sum_{j=1}^{L} xor (y_{i,j}^{pred}, y_{i,j}^{true}) \label{eq:HL}
\end{equation}

{$N$ is the total number of data, $L$ is the total number of labels.}

\subsubsection{Accuracy}
Accuracy ($A$) is the number of correctly predicted instances out of all the instances. We reported accuracy separately for each class.
\begin{equation}
A = \frac{TP+TN}{TP+FN+TN+FP}
\label{eq:acc}
\end{equation}

{$TP$ is the number of true positives, $FN$ is the number of false
negatives, $FP$ is the number of false positives, $TN$ is the number of true
negatives.}


\subsubsection{Precision}
Precision ($P$) is the ratio between the number of correctly predicted instances and all the predicted instances for a given class.
\begin{equation}
P  = \frac{TP}{TP+FP} 
\label{eq:precision}
\end{equation} %&


\subsubsection{Recall}
Recall ($R$) represents the ratio of the number of correctly predicted instances and all instances belonging to a given class.

\begin{equation}
 R = \frac{TP}{TP+FN}
 \label{eq:recall}
 \end{equation} 
 

\subsubsection{F1-score}
F1-score is the harmonic mean of precision and recall.
\begin{equation}
F1 = \frac{2\cdot P\cdot R}{P+R}
\label{eq:f-score}    
\end{equation}



\section{Study Results}

\subsection{How prevalent are the smells in the benchmark?}
give two statistics: all the documentation unit you analyzed and the percentage of which was finally considered as smells.
then describe how the different documentation smells are prevalent in the benchmark. 
\subsection{How accurate are the smell detectors?}

%%%% Table %%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\begin{table}[!ht]
\caption{Performance of the models on the overall smell types detection}
%\begin{center}
%\scalebox{1.0}
\resizebox{\columnwidth}{!} %new add
{
%\renewcommand*{\arraystretch}{2}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Model}   & \textbf{Exact Match Ratio} & \textbf{Hamming Loss} \\ \hline
\textbf{OVR-SVM} & .50                        & \textbf{.14}          \\ %\hline
\textbf{LPS-SVM} & .48                        & .15                   \\ %\hline
\textbf{CC-SVM}  & .50                        & \textbf{.14}          \\ %\hline
\textbf{ML-$k$NN}  & .47                        & .15                   \\ %\hline
\textbf{Bi-LSTM} & .80                        & .20                   \\ %\hline
\textbf{BERT}    & \textbf{.84}               & .15                   \\ \hline
\end{tabular}
}
\label{table_overall_performance}
%\end{center}
\end{table}
%%%% Table %%%%%%%%%
%%%%%%%%%%%%%%%%%%%


Table \ref{table_overall_performance} represents the performance of the ML models for detecting documentation smell as a multi-label classification problem. We observe that OneVsRest (OVR) and Classifier Chain (CC) achieved equal results. CC-based models are generally superior to OVR-based models because of the capability of capturing label correlation. Since the labels (types) of the documentation smells are not correlated, the CC-based SVM could not exhibit higher performance than the OVR-based SVM. However, Label Powerset (LPS) achieved lower performance than the OVR and CC-based models. To show better results, LPS-based SVM would require sufficient instances for all 32 classes of 5 smell types. Deep learning-based models like Bi-LSTM and BERT, on the other hand, outperformed the SVM and $k$NN-based models by achieving higher exact match ratios. Although Bi-LSTM showed higher Hamming loss, BERT achieved similar to the SVM and $k$NN-based models. Therefore, in terms of Hamming loss, deep learning-based models did not show any improvement. However, considering both exact match ratio and Hamming loss as the performance metrics, we can deduce that BERT is the most suitable of all the models experimented in detecting the documentation documentation smell.

%%%% Table %%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\begin{table*}[!ht]
\caption{Performance on different type of documentation smells}
\begin{center}
\scalebox{1.0}
{
%\renewcommand*{\arraystretch}{3}
\begin{tabular}{ccccccccccccccccccccc}
                                       & \multicolumn{20}{c}{}                                         \\ \cline{2-21} 
\multicolumn{1}{c|}{}                  & \multicolumn{4}{c|}{\textbf{Bloated}}                                                                     & \multicolumn{4}{c|}{\textbf{Lazy}}                                                                        & \multicolumn{4}{c|}{\textbf{Excess   Struct}}                                                             & \multicolumn{4}{c|}{\textbf{Tangled}}                                                                     & \multicolumn{4}{c|}{\textbf{Fragmented}}                                                                  \\ \hline
\multicolumn{1}{|c|}{\textbf{Model}}   & \multicolumn{1}{c}{A}   & \multicolumn{1}{c}{P}   & \multicolumn{1}{c}{R}   & \multicolumn{1}{c|}{F1}   & \multicolumn{1}{c}{A}   & \multicolumn{1}{c}{P}   & \multicolumn{1}{c}{R}   & \multicolumn{1}{c|}{F1}   & \multicolumn{1}{c}{A}   & \multicolumn{1}{c}{P}   & \multicolumn{1}{c}{R}   & \multicolumn{1}{c|}{F1}   & \multicolumn{1}{c}{A}   & \multicolumn{1}{c}{P}   & \multicolumn{1}{c}{R}   & \multicolumn{1}{c|}{F1}   & \multicolumn{1}{c}{A}   & \multicolumn{1}{c}{P}   & \multicolumn{1}{c}{R}   & \multicolumn{1}{c|}{F1}  \\ \hline
\multicolumn{1}{|c|}{\textbf{OVR-SVM}} & \multicolumn{1}{c}{\textbf{.97}} & \multicolumn{1}{c}{.88} & \multicolumn{1}{c}{.89} & \multicolumn{1}{c|}{.89} & \multicolumn{1}{c}{.93} & \multicolumn{1}{c}{.85} & \multicolumn{1}{c}{.92} & \multicolumn{1}{c|}{.88} & \multicolumn{1}{c}{\textbf{.77}} & \multicolumn{1}{c}{.48} & \multicolumn{1}{c}{.23} & \multicolumn{1}{c|}{.31} & \multicolumn{1}{c}{\textbf{.85}} & \multicolumn{1}{c}{.72} & \multicolumn{1}{c}{.54} & \multicolumn{1}{c|}{.62} & \multicolumn{1}{c}{\textbf{.76}} & \multicolumn{1}{c}{\textbf{.77}} & \multicolumn{1}{c}{.44} & \multicolumn{1}{c|}{.56} \\ %\hline
\multicolumn{1}{|c|}{\textbf{LPS-SVM}} & \multicolumn{1}{c}{.96} & \multicolumn{1}{c}{.90} & \multicolumn{1}{c}{.77} & \multicolumn{1}{c|}{.83} & \multicolumn{1}{c}{.94} & \multicolumn{1}{c}{.84} & \multicolumn{1}{c}{.96} & \multicolumn{1}{c|}{.89} & \multicolumn{1}{c}{\textbf{.77}} & \multicolumn{1}{c}{.50} & \multicolumn{1}{c}{.24} & \multicolumn{1}{c|}{.33} & \multicolumn{1}{c}{.83} & \multicolumn{1}{c}{.71} & \multicolumn{1}{c}{.42} & \multicolumn{1}{c|}{.54} & \multicolumn{1}{c}{.73} & \multicolumn{1}{c}{.64} & \multicolumn{1}{c}{.49} & \multicolumn{1}{c|}{.56} \\ %\hline
\multicolumn{1}{|c|}{\textbf{CC-SVM}}  & \multicolumn{1}{c}{\textbf{.97}} & \multicolumn{1}{c}{.88} & \multicolumn{1}{c}{.90} & \multicolumn{1}{c|}{.89} & \multicolumn{1}{c}{.93} & \multicolumn{1}{c}{.83} & \multicolumn{1}{c}{.93} & \multicolumn{1}{c|}{.87} & \multicolumn{1}{c}{\textbf{.77}} & \multicolumn{1}{c}{.49} & \multicolumn{1}{c}{.21} & \multicolumn{1}{c|}{.29} & \multicolumn{1}{c}{\textbf{.85}} & \multicolumn{1}{c}{.72} & \multicolumn{1}{c}{.54} & \multicolumn{1}{c|}{.62} & \multicolumn{1}{c}{\textbf{.76}} & \multicolumn{1}{c}{.75} & \multicolumn{1}{c}{.45} & \multicolumn{1}{c|}{.56} \\ %\hline
\multicolumn{1}{|c|}{\textbf{ML-$k$NN}}  & \multicolumn{1}{c}{.95} & \multicolumn{1}{c}{.77} & \multicolumn{1}{c}{.82} & \multicolumn{1}{c|}{.80} & \multicolumn{1}{c}{.91} & \multicolumn{1}{c}{.83} & \multicolumn{1}{c}{.84} & \multicolumn{1}{c|}{.84} & \multicolumn{1}{c}{.76} & \multicolumn{1}{c}{.46} & \multicolumn{1}{c}{.39} & \multicolumn{1}{c|}{.42} & \multicolumn{1}{c}{.82} & \multicolumn{1}{c}{.65} & \multicolumn{1}{c}{.55} & \multicolumn{1}{c|}{.60} & \multicolumn{1}{c}{\textbf{.76}} & \multicolumn{1}{c}{.65} & \multicolumn{1}{c}{.64} & \multicolumn{1}{c|}{.65} \\ %\hline
\multicolumn{1}{|c|}{\textbf{Bi-LSTM}} & \multicolumn{1}{c}{.92} & \multicolumn{1}{c}{.92} & \multicolumn{1}{c}{.92} & \multicolumn{1}{c|}{.91} & \multicolumn{1}{c}{.89} & \multicolumn{1}{c}{.90} & \multicolumn{1}{c}{.89} & \multicolumn{1}{c|}{.90} & \multicolumn{1}{c}{.76} & \multicolumn{1}{c}{.72} & \multicolumn{1}{c}{\textbf{.76}} & \multicolumn{1}{c|}{.73} & \multicolumn{1}{c}{.78} & \multicolumn{1}{c}{.74} & \multicolumn{1}{c}{.78} & \multicolumn{1}{c|}{.74} & \multicolumn{1}{c}{.67} & \multicolumn{1}{c}{.64} & \multicolumn{1}{c}{.67} & \multicolumn{1}{c|}{.63} \\ %\hline
\multicolumn{1}{|c|}{\textbf{BERT}}    & \multicolumn{1}{c}{.93} & \multicolumn{1}{c}{\textbf{.93}} & \multicolumn{1}{c}{\textbf{.93}} & \multicolumn{1}{c|}{\textbf{.93}} & \multicolumn{1}{c}{\textbf{.97}} & \multicolumn{1}{c}{\textbf{.97}} & \multicolumn{1}{c}{\textbf{.97}} & \multicolumn{1}{c|}{\textbf{.97}} & \multicolumn{1}{c}{.76} & \multicolumn{1}{c}{\textbf{.75}} & \multicolumn{1}{c}{\textbf{.76}} & \multicolumn{1}{c|}{\textbf{.76}} & \multicolumn{1}{c}{.83} & \multicolumn{1}{c}{\textbf{.83}} & \multicolumn{1}{c}{\textbf{.83}} & \multicolumn{1}{c|}{\textbf{.83}} & \multicolumn{1}{c}{.75} & \multicolumn{1}{c}{.75} & \multicolumn{1}{c}{\textbf{.75}} & \multicolumn{1}{c|}{\textbf{.75}} \\ \hline
\end{tabular}
}
\label{table_individual_performance}
\end{center}
\end{table*}
%%%% Table %%%%%%%%%
%%%%%%%%%%%%%%%%%%%

Table \ref{table_individual_performance} shows the performance of the ML models on each type of documentation smells. Although SVM and $k$NN-based models achieved slightly better accuracy than Bi-LSTM and BERT, the later models outperformed SVM and $k$NN-based models in F1-score. This behavior is due to the unequal distribution of the smell types over the dataset. SVM and $k$NN-based models produced more false-negative results because the number of positive instances for an individual smell type is significantly lower than the number of negative instances for that type. As a result, SVM and $k$NN-based models showed quite low recalls for some types (Excess Struct, Tangled, and Fragmented) and consequently resulted in low F1-scores. On the other hand, Bi-LSTM and BERT focused on capturing generalized attributes for each smell type and as a result, achieved impressive performance in all the performance metrics. Overall, BERT showed promising 
results among all the models in accurately detecting each of the individual documentation smells. 

TODO: misclassification analysis (see Review4Repair shared by Anindya. See Section 7.3 from here \url{https://arxiv.org/pdf/2010.01544.pdf})

\subsection{Ablation Study (RQ3)}
BERT - epoch change
SVM - feature change.

\subsection{Correlation Analysis (RQ4)}
move correlation analysis from Section V-A

\subsection{User Feedback (RQ5)}
user feedback

%\subsection{How accurate is each feature dimension?}
%answer RQ

%\subsection{How well does hypertuning work in the ML models?}
%answer RQ.

\section{Discussions}

\subsection{Correlation Analysis of Documentation Smells}
In multi-label learning, the labels might be interdependent and correlated \cite{label_correlation_paper_1}.We used Phi Coefficients to determine such interdependencies and correlations between different documentation smells. The Phi Coefficient is a measure of association between two binary variables \cite{phi_coefficient_paper}. It ranges from -1 to +1, where ±1 indicates a perfect positive or negative correlation, and 0 indicates no relationship. We report the Phi Coefficients between each pair of labels in Figure \ref{fig:label_correlation}. We find that there is almost no correlation between `Fragmented’ and any other smell (except `Lazy’). By definition, the information of fragmented documentation is scattered in many sections or pages. Hence, it has little to do with smells like `Bloated’, `Excess Structural Information’, `Tangled’. We also observe that there is a weak positive correlation (+0.2 to +0.4) among the `Bloated’, `Excess Structural Information’, and `Tangled’ smells. One possible reason might be that if a documentation is filled with complex and unorganized information (Tangled), and unnecessary structural information (Excess Structural Information), it might be prone to become bloated as well. On the other hand, `Lazy’ smell has a weak negative correlation (-0.2 to -0.3) with all other groups since these kinds of documentation are often too small to contain other smells. However, none of these coefficients is high enough to imply a strong or moderate correlation between any pair of labels. Hence, it justifies our catalog by indicating that all the smells that we proposed are sufficiently unique in nature. 


\begin{figure}[t]%[!htb]
  \centering
  %\vspace{-6mm}
   \hspace*{-.7cm}%
  \includegraphics[scale=.5]{new_images/label_correlation.png}
 % \vspace{-4mm}
  \caption{Correlation of different documentation smells. Red, Blue, and Gray mean positive, negative, and no correlation respectively. Intensity of color indicates the level of correlation.}

  \label{fig:label_correlation}
%\vspace{-4mm}
\end{figure}




\subsection{Implications of Results}
%implication of findings.
While the documentation smells do not necessarily make an API documentation incorrect, they can hinder the productivity of the developers, according to the survey response. Therefore, in this work, we focus on defining the catalog for the documentation smells. We show that these documentation smells are prevalent in Java official API documentation and by leveraging ML algorithms, we can detect them from the documentation texts. The catalog presented in this work can be extended to point out the documentation smells more accurately. Moreover, the documentation codes can be taken into account along with the documentation texts to find out how the detection of the documentation smells can vary depending on the documentation codes. The ultimate objective of this research requires manual curation of the defected documentations in order to build an automated system for correcting the documentation smells.

\subsection{Threats to Validity}
%threats to validity
In this work, we conducted our experiments on a relatively small dataset. Since, to the best of our knowledge, detecting the documentation smells is the first of its kind, we manually labeled a small portion of the Java API documentation due to the time constraint. However, we randomly sampled the documentations for manual labeling, therefore, we expect that the actual distributions of the documentation smells will remain identical in case of adding more documentation examples. Furthermore, we performed cross-validation on our dataset to reduce the effect of any non-representative subset. The number of participants in our survey is too low to get a clear picture of how the documentation smells affect productivity on the large scale. We conducted the survey with an aim to validate the catalog we developed by the software developers. As the developers agreed with the catalog and its negative impact on the productivity, in the future extension of this study, we can include more participants to categorize the documentations into different documentation smells based on this catalog.

\section{Related Work}
related work

\section{Conclusions}
conclusions

\begin{small}
\bibliographystyle{abbrv}
%\bibliography{bibtex}
\bibliography{consolidated}
\end{small}


\end{document}
=======

>>>>>>> branch 'master' of https://github.com/anonsubmissions2/DocSmellCatalog.git
