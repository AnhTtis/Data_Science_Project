\documentclass[10pt,twocolumn,letterpaper]{article}
\pdfoutput=1

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{xcolor}
\usepackage{bbding} % add Checkmark
\usepackage{enumerate}
\usepackage{float}
\usepackage{subcaption}
\usepackage{tabularx}
\usepackage{authblk}


\newcommand{\myEqRef}[1]{Equation~\ref{#1}}
\newcommand{\myFigRef}[1]{Figure~\ref{#1}}
\newcommand{\mySecRef}[1]{Section~\ref{#1}}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{Learning Optical Flow from Event Camera with Rendered Dataset}


\author{
Xinglong Luo\textsuperscript{\rm 1,\rm 3},
Kunming Luo\textsuperscript{\rm 2},
Ao Luo\textsuperscript{\rm 3},
Zhengning Wang\textsuperscript{\rm 1},
Ping Tan\textsuperscript{\rm 2},
and Shuaicheng Liu\textsuperscript{\rm 1,\rm 3}\thanks{Corresponding author}\\
\textsuperscript{\rm 1}University of Electronic Science and Technology of China\\
\textsuperscript{\rm 2}The Hong Kong University of Science and Technology \qquad
\textsuperscript{\rm 3}Megvii Technology\\
\tt\small \{luoboom@std.,zhengning.wang@,liushuaicheng@\}uestc.edu.cn \\
\tt\small kluoad@connect.ust.hk luoao02@megvii.com pingtan@sfu.ca
}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi

%%%%%%%%% ABSTRACT
\begin{abstract}
We study the problem of estimating optical flow from event cameras. One important issue is how to build a high-quality event-flow dataset with accurate event values and flow labels. Previous datasets are created by either capturing real scenes by event cameras or synthesizing from images with pasted foreground objects. The former case can produce real event values but with calculated flow labels, which are sparse and inaccurate. The later case can generate dense flow labels but the interpolated events are prone to errors. In this work, we propose to render a physically correct event-flow dataset using computer graphics models. In particular, we first create indoor and outdoor 3D scenes by Blender with rich scene content variations. Second, diverse camera motions are included for the virtual capturing, producing images and accurate flow labels. Third, we render high-framerate videos between images for accurate events. The rendered dataset can adjust the density of events, based on which we further introduce an adaptive density module (ADM). Experiments show that our proposed dataset can facilitate event-flow learning, whereas previous approaches when trained on our dataset can improve their performances constantly by a relatively large margin. In addition, event-flow pipelines when equipped with our ADM can further improve performances.

\end{abstract}

\input{tex/introduction}
\input{tex/related_work}
\input{tex/method}
\input{tex/results}



\section{Conclusion}
In this work, we have created a rendered dataset for event-flow learning. Indoor and outdoor virtual scenes have been created using Blender with rich scene contents. Various camera motions are placed for the capturing of the virtual world, which can produce frames as well as accurate flow labels. The event values are generated by render high frame rate videos between two frames. In this way, the flow labels and event values are physically correct and accurate. The rendered dataset can adjust density of events by modifying the event trigger threshold. We have introduced a novel adaptive density module (ADM), which has shown its effectiveness by plugin into various event-flow pipelines. When trained on our dataset, previous approaches can improve their performances constantly.  
%------------------------------------------------------------------------


{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
