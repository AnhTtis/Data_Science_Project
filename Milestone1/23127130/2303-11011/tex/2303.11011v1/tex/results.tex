
%----------------------------Table and figure------------------------------


\begin{table*}[t]
	\centering
	\resizebox*{0.9 \linewidth}{!}{
		\begin{tabular}
			{   >{\arraybackslash}p{3.4cm}| % backbone
                >{\centering\arraybackslash}p{1.0cm}| % train type
				>{\centering\arraybackslash}p{0.8cm}| % train set
				>{\centering\arraybackslash}p{0.7cm} % EPE indoor flying1
				>{\centering\arraybackslash}p{0.7cm}| % out indoor flying1
				>{\centering\arraybackslash}p{0.7cm} % EPE indoor flying2
				>{\centering\arraybackslash}p{0.7cm}| % out indoor flying2
    			>{\centering\arraybackslash}p{0.7cm} % EPE indoor flying3
				>{\centering\arraybackslash}p{0.7cm}| % out indoor flying3
    			>{\centering\arraybackslash}p{0.7cm} % EPE outdoor day1
				>{\centering\arraybackslash}p{0.7cm}| % out outdoor day1
        		>{\centering\arraybackslash}p{0.7cm} % EPE avg
				>{\centering\arraybackslash}p{0.7cm} % out avg
			}
			\hline
             \multirow{2}{*}{Method ($dt=1$)} & Train&Train& \multicolumn{2}{c|}{indoor flying1} &  \multicolumn{2}{c|}{indoor flying2} &  \multicolumn{2}{c|}{indoor flying3} &  \multicolumn{2}{c|}{outdoor day1} &  \multicolumn{2}{c}{Avg} \\
             & D.Type&D.Set& EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out \\
             \hline
            EST$_S$~\cite{gehrig2019EST} & $\rm{E}$      & M & 0.97  & 0.91  & 1.38  & 8.20  & 1.43  & 6.47  & -     & -     & 1.26  & 5.19  \\
    EV-Flownet$_S$~\cite{zhu2018ev} & $\rm{I_{1},I_{2},E}$ & M & 1.03  & 2.20  & 1.72  & 15.1  & 1.53  & 11.9  & 0.49  & 0.20  & 1.19  & 7.35  \\
    Deng et al.$_S$~\cite{deng2021learning} & $\rm{E}$      & M & 0.89  & 0.66  & 1.31  & 6.44  & 1.13  & 3.53  & -     & -     & 1.11  & 3.54  \\
    Paredes et al.$_S$~\cite{paredes2021back} & $\rm{E}$      & M & 0.79  & 1.20  & 1.40  & 10.9  & 1.18  & 7.40  & 0.92  & 5.40  & 1.07  & 6.22  \\
    Matrix-LSTM$_S$~\cite{cannici2020Matrix-LSTM} & $\rm{I_{1},I_{2},E}$ & M & 0.82  & 0.53  & 1.19  & 5.59  & 1.08  & 4.81  & -     & -   & 1.03  & 3.64  \\
    LIF-EV-FlowNet$_S$~\cite{hagenaars2021LIF-EV-FlowNet} & $\rm{E}$      & FPV   & 0.71  & 1.41  & 1.44  & 12.8  & 1.16  & 9.11  & 0.53  & 0.33  & 0.96  & 5.90  \\
    Spike-FlowNet$_S$~\cite{lee2020spikeflownet} & $\rm{I_{1},I_{2},E}$ & M & 0.84  & -     & 1.28  & -     & 1.11  & -     & 0.49  & -     & 0.93  & - \\
    Fusion-FlowNet$_D$~\cite{lee2022Fusion-FlowNet} & $\rm{I_{1},I_{2},E}$ & M & 0.62  & -     & 0.89  & -     & 0.85  & -     & 1.02  & -     & 0.84  & - \\
    Fusion-FlowNet$_S$~\cite{lee2022Fusion-FlowNet} & $\rm{I_{1},I_{2},E}$ & M & 0.56  & -     & 0.95  & -     & 0.76  & -     & 0.59  & -     & 0.71  & - \\
    Zhu et al.$_S$~\cite{zhu2019unsupervised} & $\rm{E}$      & M & 0.58  & \textcolor{red}{0.00}  & 1.02  & 4.00  & 0.87  & 3.00  & \textcolor{red}{ 0.32}  & \textcolor{blue}{ 0.00 }  & 0.69  & 1.75  \\
    DCEIFlow$_D$~\cite{wan2022DCEI} & $\rm{I_{1},I_{2},E}$ & C2    & 0.56  & 0.28  & \textcolor{blue}{ 0.64 }  & \textcolor{red}{ 0.16 } & 0.57  & 0.12  & 0.91  & 0.71  & 0.67  & 0.31  \\
    DCEIFlow$_S$~\cite{wan2022DCEI}& $\rm{I_{1},I_{2},E}$ & C2    & 0.57  & 0.30 & 0.70  & \textcolor{blue}{ 0.30 }  & 0.58  & 0.15  & 0.74  & 0.29  & 0.64  & \textcolor{blue}{ 0.26 } \\
    Stoffregen et al.$_S$~\cite{stoffregen2020reducing} & $\rm{E}$      & ESIM  & 0.56  & 1.00  & 0.66  & 1.00  & 0.59  & 1.00  & 0.68  & 0.99  & 0.62  & 0.99  \\
    STE-FlowNet$_S$~\cite{ding2022STE-FLOWNET}& $\rm{I_{1},I_{2},E}$ & M & 0.57  & \textcolor{blue}{ 0.10 }  & 0.79  & 1.60  & 0.72  & 1.30  & 0.42  & 0.00  & 0.62  & 0.75  \\
    \bf ADM-Flow$_D$(ours) & $\rm{E}$      & MDR   & \textcolor{red}{ 0.48 } & 0.11  & \textcolor{red}{ 0.56 } & 0.40  & \textcolor{red}{ 0.47 } & \textcolor{red}{ 0.02 } & 0.52  & 0.00 & \textcolor{red}{ 0.51 } & \textcolor{red}{ 0.14 }   \\
    \bf ADM-Flow$_S$(ours) & $\rm{E}$      & MDR   & \textcolor{blue}{ 0.52 } & 0.14  & 0.68  & 1.18  & \textcolor{blue}{ 0.52 }  & \textcolor{blue}{0.04}  & \textcolor{blue}{ 0.41 }  & \textcolor{red}{ 0.00 } & \textcolor{blue}{ 0.53 }  & 0.34  \\
	\hline
    \multirow{2}{*}{Method ($dt=4$)} & Train&Train& \multicolumn{2}{c|}{indoor flying1} &  \multicolumn{2}{c|}{indoor flying2} &  \multicolumn{2}{c|}{indoor flying3} &  \multicolumn{2}{c|}{outdoor day1} &  \multicolumn{2}{c}{Avg} \\
 & D.Type&D.Set& EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out \\
 \hline
 LIF-EV-FlowNet$_S$~\cite{hagenaars2021LIF-EV-FlowNet} & $\rm{E}$      & FPV   & 2.63  & 29.6  & 4.93  & 51.1  & 3.88  & 41.5  & 2.02  & 18.9  & 3.36  & 35.3  \\
    EV-Flownet$_S$~\cite{zhu2018ev} & $\rm{I_{1},I_{2},E}$ & M & 2.25  & 24.7  & 4.05  & 45.3  & 3.45  & 39.7  & 1.23  & \textcolor{blue}{ 7.30 } & 2.74  & 29.3  \\
    Zhu et al.$_S$~\cite{zhu2019unsupervised} & $\rm{E}$      & M & 2.18  & 24.2  & 3.85  & 46.8  & 3.18  & 47.8  & 1.30  & 9.70  & 2.62  & 32.1  \\
    Spike-FlowNet$_S$~\cite{lee2020spikeflownet} & $\rm{I_{1},I_{2},E}$ & M & 2.24  & -     & 3.83  & -     & 3.18  & -     & \textcolor{blue}{ 1.09 }  & -     & 2.58  & - \\
    Fusion-FlowNet$_D$~\cite{lee2022Fusion-FlowNet} & $\rm{I_{1},I_{2},E}$ & M & 1.81  & -     & 2.90  & -     & 2.46  & -     & 3.06  & -     & 2.55  & - \\
    Fusion-FlowNet$_S$~\cite{lee2022Fusion-FlowNet}& $\rm{I_{1},I_{2},E}$ & M & 1.68  & -     & 3.24  & -     & 2.43  & -     & 1.17  & -     & 2.13  & - \\
    STE-FlowNet$_S$~\cite{ding2022STE-FLOWNET} & $\rm{I_{1},I_{2},E}$ & M & 1.77  & 14.7  & 2.52  & 26.1  & 2.23  & 22.1  & \textcolor{red}{ 0.99 } & \textcolor{red}{ 3.90 } & 1.87  & 16.7  \\
    DCEIFlow$_D$~\cite{wan2022DCEI} & $\rm{I_{1},I_{2},E}$ & C2    & 1.49  & 8.14  & 1.97  & 17.4  & 1.69  & 12.3  & 1.87  & 19.1  & 1.75  & 14.24  \\
    DCEIFlow$_S$~\cite{wan2022DCEI} & $\rm{I_{1},I_{2},E}$ & C2    & 1.52  & 8.79  & 2.21  & 22.1  & 1.74  & 13.3  & 1.37  & 8.54  & 1.71  & 13.2  \\
    \bf ADM-Flow$_D$(ours) & $\rm{E}$      & MDR    & \textcolor{red}{ 1.39 } & \textcolor{red}{ 7.33 } & \textcolor{red}{ 1.63 } & \textcolor{red}{ 11.5 } & \textcolor{red}{ 1.51 } & \textcolor{red}{ 9.34 } & 1.91  & 19.2  & \textcolor{blue}{ 1.61 }  & \textcolor{blue}{ 11.8 } \\
    \bf ADM-Flow$_S$(ours) & $\rm{E}$      & MDR   & \textcolor{blue}{ 1.42 }  & \textcolor{blue}{ 7.78 } & \textcolor{blue}{ 1.88 } & \textcolor{blue}{ 16.7 } & \textcolor{blue}{ 1.61 } & \textcolor{blue}{ 11.4 }  & 1.51  & 10.23  & \textcolor{red}{ 1.60 } & \textcolor{red}{ 11.5 } \\
 \hline
	\end{tabular}}
    \caption{Quantitative comparison of our method with previous methods on the MVSEC dataset \cite{zhu2018multivehicle}.
    Subscripts $S$ and $D$ donate the \emph{sparse} and \emph{dense} evaluation, respectively. We mark the best results in \textcolor{red}{red} and the second best results in \textcolor{blue}{blue}.}
	\label{tab:mvsec_result}
\end{table*}


% \begin{table*}[]
% \centering
% \resizebox{\linewidth}{!}{
%     \begin{tabular}{l|c|c|cc|cc|cc|cc|cc}
%     \toprule
%     \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Method ($dt=1$)\end{tabular}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Train \\ D.Type\end{tabular}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Train \\ D.Set\end{tabular}} & \multicolumn{2}{c|}{indoor\_flying1} & \multicolumn{2}{c|}{indoor\_flying2} & \multicolumn{2}{c|}{indoor\_flying3} & \multicolumn{2}{c|}{outdoor\_day1} & \multicolumn{2}{c}{AVG} \\
%           &       &       & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out \\
%     \midrule
%     EST$_S$~\cite{gehrig2019EST} & $\rm{E}$      & M & 0.97  & 0.91  & 1.38  & 8.20  & 1.43  & 6.47  & -     & -     & 1.26  & 5.19  \\
%     EV-Flownet$_S$~\cite{zhu2018ev} & $\rm{I_{1},I_{2},E}$ & M & 1.03  & 2.20  & 1.72  & 15.10  & 1.53  & 11.90  & 0.49  & 0.20  & 1.19  & 7.35  \\
%     Deng et al.$_S$~\cite{deng2021learning} & $\rm{E}$      & M & 0.89  & 0.66  & 1.31  & 6.44  & 1.13  & 3.53  & -     & -     & 1.11  & 3.54  \\
%     Paredes et al.$_S$~\cite{paredes2021back} & $\rm{E}$      & M & 0.79  & 1.20  & 1.40  & 10.90  & 1.18  & 7.40  & 0.92  & 5.40  & 1.07  & 6.22  \\
%     Matrix-LSTM$_S$~\cite{cannici2020Matrix-LSTM} & $\rm{I_{1},I_{2},E}$ & M & 0.82  & 0.53  & 1.19  & 5.59  & 1.08  & 4.81  & -     & -   & 1.03  & 3.64  \\
%     LIF-EV-FlowNet$_S$~\cite{hagenaars2021LIF-EV-FlowNet} & $\rm{E}$      & FPV   & 0.71  & 1.41  & 1.44  & 12.75  & 1.16  & 9.11  & 0.53  & 0.33  & 0.96  & 5.90  \\
%     Spike-FlowNet$_S$~\cite{lee2020spikeflownet} & $\rm{I_{1},I_{2},E}$ & M & 0.84  & -     & 1.28  & -     & 1.11  & -     & 0.49  & -     & 0.93  & - \\
%     Fusion-FlowNet$_D$~\cite{lee2022Fusion-FlowNet} & $\rm{I_{1},I_{2},E}$ & M & 0.62  & -     & 0.89  & -     & 0.85  & -     & 1.02  & -     & 0.84  & - \\
%     Fusion-FlowNet$_S$~\cite{lee2022Fusion-FlowNet} & $\rm{I_{1},I_{2},E}$ & M & 0.56  & -     & 0.95  & -     & 0.76  & -     & 0.59  & -     & 0.71  & - \\
%     Zhu et al.$_S$~\cite{zhu2019unsupervised} & $\rm{E}$      & M & 0.58  & 0.00  & 1.02  & 4.00  & 0.87  & 3.00  & \textbf{ 0.32}  & 0.00  & 0.69  & 1.75  \\
%     DCEIFlow$_D$~\cite{wan2022DCEI} & $\rm{I_{1},I_{2},E}$ & C2    & 0.56  & 0.28  & 0.64  & 0.16  & 0.57  & 0.12  & 0.91  & 0.71  & 0.67  & 0.31  \\
%     DCEIFlow$_S$~\cite{wan2022DCEI}& $\rm{I_{1},I_{2},E}$ & C2    & 0.57  & 0.30  & 0.70  & 0.30  & 0.58  & 0.15  & 0.74  & 0.29  & 0.64  & 0.26  \\
%     Stoffregen et al.$_S$~\cite{stoffregen2020reducing} & $\rm{E}$      & ESIM  & 0.56  & 1.00  & 0.66  & 1.00  & 0.59  & 1.00  & 0.68  & 0.99  & 0.62  & 0.99  \\
%     STE-FlowNet$_S$~\cite{ding2022STE-FLOWNET}& $\rm{I_{1},I_{2},E}$ & M & 0.57  & \textbf{ 0.10 }  & 0.79  & 1.60  & 0.72  & 1.30  & 0.42  & 0.00  & 0.62  & 0.75  \\
%     \bf ADM-Flow$_D$ & $\rm{E}$      & MDR   & \textbf{ 0.48 } & 0.11  & \textbf{ 0.56 } & 0.40  & \textbf{ 0.47 } & \textbf{ 0.02 } & 0.52  & \textbf{ 0.00 } & \textbf{ 0.51 } & \textbf{ 0.14 }   \\
%     \bf ADM-Flow$_S$ & $\rm{E}$      & MDR   & 0.52  & 0.14  & 0.68  & 1.18  & 0.52  & 0.04  & 0.41  & 0.00  & 0.53  & 0.34  \\
%     \midrule
%     \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Method ($dt=4$)\end{tabular}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Train \\ D.Type\end{tabular}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Train \\ D.Set\end{tabular}} & \multicolumn{2}{c|}{indoor\_flying1} & \multicolumn{2}{c|}{indoor\_flying2} & \multicolumn{2}{c|}{indoor\_flying3} & \multicolumn{2}{c|}{outdoor\_day1} & \multicolumn{2}{c}{AVG} \\
%           &       &       & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out \\
%     \midrule
%     LIF-EV-FlowNet$_S$~\cite{hagenaars2021LIF-EV-FlowNet} & $\rm{E}$      & FPV   & 2.63  & 29.55  & 4.93  & 51.10  & 3.88  & 41.49  & 2.02  & 18.91  & 3.36  & 35.26  \\
%     EV-Flownet$_S$~\cite{zhu2018ev} & $\rm{I_{1},I_{2},E}$ & M & 2.25  & 24.70  & 4.05  & 45.30  & 3.45  & 39.70  & 1.23  & 7.30  & 2.74  & 29.25  \\
%     Zhu et al.$_S$~\cite{zhu2019unsupervised} & $\rm{E}$      & M & 2.18  & 24.20  & 3.85  & 46.80  & 3.18  & 47.80  & 1.30  & 9.70  & 2.62  & 32.12  \\
%     Spike-FlowNet$_S$~\cite{lee2020spikeflownet} & $\rm{I_{1},I_{2},E}$ & M & 2.24  & -     & 3.83  & -     & 3.18  & -     & 1.09  & -     & 2.58  & - \\
%     Fusion-FlowNet$_D$~\cite{lee2022Fusion-FlowNet} & $\rm{I_{1},I_{2},E}$ & M & 1.81  & -     & 2.90  & -     & 2.46  & -     & 3.06  & -     & 2.55  & - \\
%     Fusion-FlowNet$_S$~\cite{lee2022Fusion-FlowNet}& $\rm{I_{1},I_{2},E}$ & M & 1.68  & -     & 3.24  & -     & 2.43  & -     & 1.17  & -     & 2.13  & - \\
%     STE-FlowNet$_S$~\cite{ding2022STE-FLOWNET} & $\rm{I_{1},I_{2},E}$ & M & 1.77  & 14.70  & 2.52  & 26.10  & 2.23  & 22.10  & \textbf{ 0.99 } & \textbf{ 3.90 } & 1.87  & 16.70  \\
%     DCEIFlow$_D$~\cite{wan2022DCEI} & $\rm{I_{1},I_{2},E}$ & C2    & 1.49  & 8.14  & 1.97  & 17.37  & 1.69  & 12.34  & 1.87  & 19.13  & 1.75  & 14.24  \\
%     DCEIFlow$_S$~\cite{wan2022DCEI} & $\rm{I_{1},I_{2},E}$ & C2    & 1.52  & 8.79  & 2.21  & 22.13  & 1.74  & 13.33  & 1.37  & 8.54  & 1.71  & 13.19  \\
%     \bf ADM-Flow$_D$ & $\rm{E}$      & MDR    & \textbf{ 1.39 } & \textbf{ 7.33 } & \textbf{ 1.63 } & \textbf{ 11.45 } & \textbf{ 1.51 } & \textbf{ 9.34 } & 1.91  & 19.19  & 1.61  & 11.83  \\
%     \bf ADM-Flow$_S$ & $\rm{E}$      & MDR   & 1.42  & 7.78  & 1.88  & 16.74  & 1.61  & 11.39  & 1.51  & 10.23  & \textbf{ 1.60 } & \textbf{ 11.53 } \\
%     \bottomrule
%     \end{tabular}
%     }
%     \caption{Quantitative evaluation on the MVSEC dataset \cite{zhu2018multivehicle} compared with existing event-based methods. 
%     %The comparison method's results are taken directly from the original study.
%     $S$ and $D$ donate the \emph{sparse} and \emph{dense} evaluation, respectively.
%     }
%   \label{tab:mvsec_result}
% \end{table*}


% \begin{table}[htbp]
%   \centering
%     \resizebox{\linewidth}{!}{
%     \begin{tabular}{l|cc|cc|cc|cc|cc}
%     \toprule
%     \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Method ($dt=1$)\end{tabular}} & \multicolumn{2}{c|}{0.09-0.21} & \multicolumn{2}{c|}{0.21-0.36} & \multicolumn{2}{c|}{0.36-0.57} & \multicolumn{2}{c|}{0.57-0.69} & \multicolumn{2}{c}{AVG} \\
%           & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out \\
%     \midrule
%     Spike-Flow$_S$~\cite{lee2020spikeflownet} & 1.13  & 5.25  & 1.20  & 5.27  & 1.33  & 3.78  & 2.01  & 18.66  & 1.42  & 8.24  \\
%     STE-Flow$_S$~\cite{ding2022STE-FLOWNET} & 0.82  & 0.98  & 1.00  & 1.55  & 0.87  & 0.44  & 0.82  & 0.35  & 0.88  & 0.83  \\
%     E-RAFT$_D$~\cite{gehrig2021raft} & 0.93  & 2.58  & 0.85  & 3.64  & 0.69  & 1.29  & 0.92  & 4.35  & 0.85  & 2.97  \\
%     E-RAFT$_S$~\cite{gehrig2021raft} & 1.02  & 4.77  & 1.13  & 7.57  & 0.89  & 5.51  & 1.14  & 7.12  & 1.05  & 6.24  \\
%     DCEIFlow$_D$~\cite{wan2022DCEI} & 0.79  & \textbf{0.76 } & 0.72  & 0.45  & 0.67  & 0.23  & 0.62  & 0.28  & 0.70  & 1.43  \\
%     DCEIFlow$_S$~\cite{wan2022DCEI} & 0.90  & 0.95  & 0.66  & 1.22  & 0.60  & 0.07  & 0.98  & 0.44  & 0.79  & 0.67  \\
%     \bf ADM-Flow$_D$ & \textbf{0.73 } & 1.79  & 0.53  & \textbf{0.01 } & 0.51  & \textbf{0.00 } & \textbf{0.56 } & \textbf{0.15 } & \textbf{0.58 } & \textbf{0.49 } \\
%     \bf ADM-Flow$_S$ & 0.96  & 2.38  & \textbf{0.47 } & 0.01  & \textbf{0.47 } & 0.00  & 0.63  & 0.19  & 0.63  & 0.65  \\
%     \midrule
%     \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Method \\ $dt=4$\end{tabular}} & \multicolumn{2}{c|}{0.09-0.21} & \multicolumn{2}{c|}{0.21-0.36} & \multicolumn{2}{c|}{0.36-0.57} & \multicolumn{2}{c|}{0.57-0.69} & \multicolumn{2}{c}{AVG} \\
%           & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out \\
%     \midrule
%     Spike-Flow$_S$~\cite{lee2020spikeflownet} & 3.95  & 66.93  & 1.96  & 17.18  & 2.09  & 18.44  & 2.87  & 36.21  & 2.72  & 34.69  \\
%     STE-Flow$_S$~\cite{ding2022STE-FLOWNET} & 2.71  & 36.20  & 2.17  & 24.30  & 1.72  & 14.19  & 1.73  & 12.26  & 2.08  & 21.74  \\
%     DCEIFlow$_D$~\cite{wan2022DCEI} & 1.72  & 17.74  & 1.66  & 11.25  & 1.16  & 2.31  & 2.14  & 17.08  & 1.67  & 12.10  \\
%     DCEIFlow$_S$~\cite{wan2022DCEI} & 2.87  & 42.92  & 1.35  & 3.33  & 1.16  & 1.24  & 2.24  & 17.87  & 1.90  & 16.34  \\
%     \bf ADM-Flow$_D$ & \textbf{1.89 } & \textbf{15.84 } & \textbf{1.25 } & 17.17  & \textbf{0.98 } & 4.91  & \textbf{1.75 } & \textbf{10.34 } & \textbf{1.47 } & \textbf{12.07 } \\
%     \bf ADM-Flow$_S$ & 2.54  & 46.86  & 1.27  & \textbf{2.88 } & 1.09  & \textbf{1.11 } & 2.17  & 15.17  & 1.77  & 16.50  \\
%     \bottomrule
%     \end{tabular}% 
%     }\caption{Quantitative evaluation on our MDR dataset. The methods in table are all trained on MVSEC dataset. $S$ and $D$ donate the \emph{sparse} and \emph{dense} evaluation, respectively.}
%     \label{tab:mdr_result}
% \end{table}

% \begin{table}[htbp]
%   \centering
%     \resizebox{0.8\linewidth}{!}{
%     \begin{tabular}{l|c|cc|c|cc}
%     \toprule
%     \multicolumn{1}{l|}{\multirow{2}[1]{*}{Method}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Train \\ D.Set\end{tabular}} & \multicolumn{2}{c|}{AVG($dt=1$)} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Train \\ D.Set\end{tabular}} & \multicolumn{2}{c}{AVG($dt=4$)} \\
%           &       & EPE   & \%Out &       & EPE   & \%Out \\
%     \midrule
%     \multicolumn{1}{l|}{\multirow{2}[0]{*}{PWCNet~\cite{Hur:2019:IRR}}} & M     & 1.25  & 5.41  & M     & 4.03  & 51.48  \\
%           & MDR   & 1.14  & 3.48  & MDR   & 2.92  & 38.62  \\
%     \midrule
%     \multicolumn{1}{l|}{\multirow{2}[0]{*}{RAFT~\cite{teed2020raft}}} & M     & 1.19  & 4.90  & M     & 3.33  & 39.78  \\
%           & MDR   & 0.59  & 0.51  & MDR   & 2.57  & 30.24  \\
%     \midrule
%     \multicolumn{1}{l|}{\multirow{2}[0]{*}{GMFlowNet~\cite{zhao2022GMFlowNet}}} & M     & 1.00  & 3.75  & M     & 3.61  & 42.31  \\
%           & MDR   & 0.82  & 1.66  & MDR   & 2.70  & 31.53  \\
%     \midrule
%     \multicolumn{1}{l|}{\multirow{2}[0]{*}{FlowFromer~\cite{huang2022flowformer}}} & M     & 0.87  & 3.08  & M     & 3.38  & 41.04  \\
%           & MDR   & 0.61  & 0.40  & MDR   & 2.49  & 28.83  \\
%     \midrule
%     \multicolumn{1}{l|}{\multirow{2}[0]{*}{SKFlow~\cite{sun2022skflow}}} & M     & 1.07  & 3.97  & M     & 3.41  & 40.87  \\
%           & MDR   & 0.59  & 0.33  & MDR   & 2.46  & 27.64  \\
%     \midrule
%     \multicolumn{1}{l|}{\multirow{2}[0]{*}{GMA~\cite{jiang2021gma}}} & M     & 0.88  & 4.05  & M     & 2.99  & 34.80  \\
%           & MDR   & 0.58  & 0.44  & MDR   & \textbf{2.19 } & \textbf{23.00 } \\
%     \midrule
%     \multicolumn{1}{l|}{\multirow{2}[1]{*}{KPAFlow~\cite{luo2022kpa}}} & M     & 0.86  & 2.86  & M     & 3.19  & 38.32  \\
%           & MDR   & \textbf{0.58 } & \textbf{0.39 } & MDR   & 2.33  & 26.10  \\
%     \bottomrule
%     \end{tabular}
%   }\caption{Comparison of training sets between MVSEC and our MDR. Each model is trained using MVSEC and MDR datasets, and evaluated using MVSEC test set for dense optical flow.}
%   \label{tab:dataset_comparison}
% \end{table}


% \begin{figure}[!t]
%     \centering
%     \includegraphics[width=\linewidth]{images/densities.pdf}
%     \caption{Visualization of the event sequence predictions from various densities of KPA-Flow input. The input of events with various densities is shown above, and the flow predictions is shown below.}
%     \label{fig:densities}
% \end{figure}


% \begin{table}[htbp]
%   \centering
%   \resizebox{1.0\linewidth}{!}{
%     \begin{tabular}{l|cc|cc|cc|cc}
%     \toprule
%     \multirow{2}[2]{*}{Method} & \multicolumn{2}{c|}{M($dt=1$)} & \multicolumn{2}{c|}{MDR($dt=1$)} & \multicolumn{2}{c|}{M($dt=4$)} & \multicolumn{2}{c}{MDR($dt=4$)} \\
%           & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out & EPE   & \%Out \\
%     \midrule
%     PWCNet~\cite{Hur:2019:IRR} & 1.25  & 5.41  & 1.14  & 3.48  & 4.03  & 51.48  & 2.92  & 38.62  \\
%     ADM-PWCNet & 1.07  & 4.52  & 0.76  & 1.48  & 2.95  & 33.31  & 1.94  & 18.74  \\
%     \midrule
%     RAFT~\cite{teed2020raft} & 1.19  & 4.90  & 0.59  & 0.51  & 3.33  & 39.78  & 2.57  & 30.24  \\
%     ADM-RAFT & 0.82  & 3.03  & 0.56  & 0.24  & 2.73  & 30.91  & 1.72  & 13.83  \\
%     \midrule
%     GMFlowNet~\cite{zhao2022GMFlowNet} & 1.00  & 3.75  & 0.82  & 1.66  & 3.61  & 42.31  & 2.70  & 31.53  \\
%     ADM-GMFlowNet & 0.87  & 3.05  & 0.58  & 0.32  & 2.78  & 31.26  & 1.81  & 14.45  \\
%     \midrule
%     FlowFromer~\cite{huang2022flowformer} & 0.87  & 3.08  & 0.61  & 0.40  & 3.38  & 41.04  & 2.49  & 28.83  \\
%     ADM-FlowFromer & 0.78  & 2.87  & 0.53  & 0.15  & 2.56  & 26.57  & 1.67  & 12.78  \\
%     \midrule
%     SKFlow~\cite{sun2022skflow} & 1.07  & 3.97  & 0.59  & 0.33  & 3.41  & 40.87  & 2.46  & 27.64  \\
%     ADM-SKFlow & 0.84  & 3.18  & 0.53  & 0.14  & 2.67  & 28.17  & 1.69  & 12.61  \\
%     \midrule
%     GMA~\cite{jiang2021gma} & 0.88  & 4.05  & 0.58  & 0.44  & 2.99  & 34.80  & 2.19  & 23.00  \\
%     ADM-GMA & \textbf{0.76 } & \textbf{2.65 } & 0.54  & 0.22  & \textbf{2.45 } & \textbf{25.75 } & 1.63  & 11.95  \\
%     \midrule
%     KPAFlow~\cite{luo2022kpa} & 0.86  & 2.86  & 0.58  & 0.39  & 3.19  & 38.32  & 2.33  & 26.10  \\
%     ADM-KPAFlow & 0.80  & 2.81  & \textbf{0.51 } & \textbf{0.14 } & 2.64  & 28.58  & \textbf{1.61 } & \textbf{11.83 } \\
%     \bottomrule
%     \end{tabular}%
%     } \caption{Quantitative comparison of whether or not with ADM.  All model is both trained on the MVSEC(i.e. M) ans MDR training set, then evaluated on the MVSDC test sets for average EPE with dt = 1 and dt = 4.}
%   \label{tab:comparisonforADM}
% \end{table}

% \begin{table}[htbp]
%   \centering
%   \resizebox{1.0\linewidth}{!}{  
%     \begin{tabular}{c|c|c|c|c|c|cc|cc}
%     \toprule
%     \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Method \\ ID\end{tabular}}  & \multicolumn{1}{c|}{\multirow{2}[2]{*}{MDC}} & \multicolumn{1}{c|}{\multirow{2}[2]{*}{$L_{\mathrm{MDC}}$}} & \multicolumn{1}{c|}{\multirow{2}[2]{*}{MSFF}} & \multicolumn{1}{c|}{\multirow{2}[2]{*}{MDS}} & \multicolumn{1}{c|}{\multirow{2}[2]{*}{$L_{\mathrm{MDS}}$}} & \multicolumn{2}{c|}{AVG($dt=1$)} & \multicolumn{2}{c}{AVG($dt=4$)} \\
%           &       &       &       &       &       & \multicolumn{1}{c}{EPE} & \%Out & \multicolumn{1}{c}{EPE} & \%Out \\
%     \midrule
%     (a)   & \ding{53} & \ding{53} & \ding{53} & \ding{53} & \ding{53} & 0.58  & 0.39  & 2.33  & 26.10  \\
%     (b)   & \ding{51} & \ding{53} & \ding{53} & \ding{53} & \ding{53} & 0.57  & 0.33  & 2.20  & 23.78  \\
%     (c)   & \ding{51} & \ding{51} & \ding{53} & \ding{53} & \ding{53} & 0.55  & 0.26  & 2.01  & 19.26  \\
%     (d)   & \ding{51} & \ding{51} & \ding{51} & \ding{53} & \ding{53} & 0.55  & 0.22  & 1.96  & 18.15  \\
%     (e)   & \ding{51} & \ding{51} & \ding{53} & \ding{51} & \ding{53} & 0.52  & 0.18  & 1.72  & 15.12  \\
%     (f)   & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{53} & 0.52  & 0.16  & 1.66  & 13.29  \\
%     (g)   & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \textbf{0.51 } & \textbf{0.14 } & \textbf{1.61 } & \textbf{11.83 } \\
%     \bottomrule
%     \end{tabular}
%     }
%     \caption{The results of ablation study. All model is trained on the MDR training set, and directly evaluated on the MVSDC test sets for average EPE with $dt=1$ and $dt=4$.}
%   \label{tab:ablation}
% \end{table}

%----------------------------Table and figure------------------------------

\section{Experiments}
\subsection{Datasets}
\noindent{\bf MVSEC:} The MVSEC dataset \cite{zhu2018multivehicle} is a real-world dataset collected in indoor and outdoor scenarios with sparse optical flow labels. As a common setting, $28,542$ data pairs of the `outdoor day2' sequence are used as the train set, and $8,410$ data pairs of the other sequences are used as the validation set. The density ranges of MVSEC train set and validation set are $[0.0003, 0.47]$ and $[0.001, 0.31]$, respectively.

\noindent{\bf MDR:} We create the MDR dataset using the graphics engine blender. We use various 3D scenes for data generation. There are $80,000$ training samples and $6,000$ validation samples with accurate dense optical flow ground truth. 
Each sample has event sequences with different density produced by using different threshold $C$. By default, for training on MDR, we use the combination of all these samples with different densities to train flow networks. For the learning of our ADM module, we choose events with density between 0.45 and 0.55 as the lable for $L_\mathrm{MDC}$ and $L_\mathrm{MDS}$.

%Some previous methods also train their models on other training datasets, such as synthetic datasets C2~\cite{wan2022DCEI} and ESIM~\cite{stoffregen2020reducing}, and the real-world captured dataset FPV~\cite{Delmerico19icra}. We also compare them on the validation set of MVSEC dataset. Following ~\cite{ding2022STE-FLOWNET}, we train and evaluate all the methods with event sequences sampled in two frequence: 60 Hz (denoted as $dt=1$) and 15 Hz (denoted as $dt=4$).
Previous methods also train their models on other datasets, including synthetic datasets C2~\cite{wan2022DCEI} and ESIM~\cite{stoffregen2020reducing}, as well as the real-world captured dataset FPV~\cite{Delmerico19icra}. We also compare with tham on the validation set of the MVSEC dataset. Following~\cite{ding2022STE-FLOWNET}, We train and evaluate all the methods using event sequences sampled at 60 Hz (denoted as $dt=1$) and 15 Hz (denoted as $dt=4$).
%time window between two successive video frames ($dt=1$) and between four video frames ($dt=4$).


%\Kunming{say density of MDR, say how to setup the dt=1 and dt=4 dataset for What. Say other dataset in table1: C2, FPV, ESIM, all with citations.}.

% \paragraph{Training set.} The MVSEC dataset \cite{zhu2018multivehicle} is collected in two different scenarios, e.g. indoor (recorded in rooms) and outdoor (recorded while driving on public roads). 

% Following the prior works \cite{zhu2019unsupervised}, we use the outdoor day2 sequence as the training set of MVSEC. 
% However, the flow annotation of MVSEC is sparse which is not suitable for dense optical flow estimation. 

% So, we also select the training data in our MDR dataset to supervisingly train the networks for dense optical flow estimation and conduct the comparison experiments between the MVSEC training set and ours. We generate events data with different densities by decreasing the threshold $C$ from 1.5 to 0.1 in 0.1 intervals, and then select the events with density between 0.09 and 0.69 and the corresponding flow labels as the training set for MDR, and pair each sample with the label of the best density. In this way, we obtained a training set of about 80,000 samples, some examples can be seen in Fig.~\ref{fig:ourdatasets}.
% \paragraph{Test set.}Following the split of \cite{stoffregen2020reducing} for the test set of MVSEC, each indoor and outdoor sequence in MVSEC contains about 1880 and 2700 samples, respectively. We divide the test set of our MDR according to four different density intervals and got a total of about 6000 samples. Follow \cite{zhu2019unsupervised}, we train and test two models for two different time window lengths. In more detail, one is for 1 image frame apart ($dt = 1$) and another is for 4 images frame apart ($dt = 4$).

\subsection{Implementation details}
% We implement our method using PyTorch.
% In our experiments, we use the same setting to train all the networks. We use AdamW optimizer to train networks with batch size of 6 and learning rate of $4 \times10^{-4}$ for 150k iterations.
% Since the MVSEC dataset do not have multiple density event streams for the learning of our ADM module, we disable $L_{\mathrm{MDC}}$ and $L_{\mathrm{MDS}}$ when training on MVSEC dataset. As for the evaluation metric, we use the average End-point Error (EPE) and the percentage of points with EPE greater than 3 pixels and 5\% of the magnitude of the flow ground truth, denoted as \%Out. We calculate errors at the pixel with valid flow annotation for \emph{dense} evaluation, and at the pixel with valid flow annotation and triggered at least one event for \emph{sparse} evaluation.
We use PyTorch to implement our method and train all networks using the same setting. The networks are trained with the AdamW optimizer, with a batch size of 6 and learning rate of $4 \times10^{-4}$ for 150k iterations. Since the MVSEC dataset lacks multiple density event streams required for the learning of our ADM module, we disable $L_{\mathrm{MDC}}$ and $L_{\mathrm{MDS}}$ when training on the MVSEC dataset. For evaluation, we use the average End-point Error (EPE) and the percentage of points with EPE greater than 3 pixels and 5\% of the ground truth flow magnitude, denoted as \%Out. We calculate errors at the pixel with valid flow annotation for \emph{dense} evaluation, and at the pixel with valid flow annotation and triggered at least one event for \emph{sparse} evaluation.

% Besides, we also report the percentage of points with EPE greater than 3 pixels and 5\% of the magnitude of the flow vector, denoted as \% Outlier. During the evaluation, we estimate the optical flow on the center cropped $256 \times 256$ of input event voxel.

% \paragraph{Evaluation metrics.} The average End-point Error (EPE) is used as evaluation metric, which measures the mean distance between the predicted flow and the ground truth. For \emph{dense} evaluation, we calculate errors at the pixel with valid flow annotation. For \emph{sparse} evaluation, we calculate errors at the pixel with valid flow annotation and triggered at least one event.
% Besides, we also report the percentage of points with EPE greater than 3 pixels and 5\% of the magnitude of the flow vector, denoted as \% Outlier. During the evaluation, we estimate the optical flow on the center cropped $256 \times 256$ of input event voxel.

\subsection{Comparison with State-of-the-Arts} 
\paragraph{Results on MVSEC.} 
In Table~\ref{tab:mvsec_result}, we compare our model trained on the MDR train set with previous methods on the MVSEC evaluation set, and report detailed results for each sequence. We provide information on the data types (Train D.Type) and the training sets (Train D.Set) used in the training process for each method. Specifically, `$\rm{I_{1},I_{2},E}$' indicates that both image data and event data are used in the training and inference processes of the model, while `$\rm{E}$' indicates that only event data is used. As shown in Table~\ref{tab:mvsec_result}, our model trained on the MDR dataset achieves state-of-the-art performance for both EPE and outlier metrics in settings of $dt=1$ and $dt=4$. Notably, our method demonstrates a 23.9\% improvement (reducing EPE from 0.67 to 0.51) for dense optical flow estimation in $dt=1$ settings, and an 8.0\% improvement (reducing EPE from 1.75 to 1.61) in $dt=4$ settings, surpassing previous methods. Qualitative comparison results are shown in row 1 and row 2 in Fig.~\ref{fig:comparison}.



\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{images/comparison.pdf}
    \caption{Qualitative comparisons compared with existing event-based methods. Row 1 and 2 are from MVSEC, whereas row 3 and 4 are from MDR. Row 1 and 3 visualize the dense predictions, whereas row 2 and 4 show the sparse.}
    \label{fig:comparison}
\end{figure*}

\paragraph{Results on MDR.} 
In Table~\ref{tab:mdr_result}, we compare our method with previous methods for training on MVSEC dataset and testing on MDR dataset. We use different threshold $C$ to generate test data with different density ranges for evaluation. For the average EPE error of dense optical flow estimation, our model obtains the best result, which is a 17.1\% improvement (reducing EPE from 0.70 to 0.58) in $dt=1$ settings, and a 12.0\% improvement (reducing EPE from 1.67 to 1.47) in $dt=4$ settings. We also show some qualitative comparison results in row 3 and row 4 in Fig.~\ref{fig:comparison}.

% \paragraph{Qualitative comparisons.} As shown in Fig.~\ref{fig:comparison}, we make qualitative comparisons with some event-based methods, which have open-sourced pretrained models. Since SpikeFlownet~\cite{lee2020spikeflownet} and STE-Flownet~\cite{ding2022STE-FLOWNET} are unsupervised learning networks that can only predict sparse flow, many of the pixels that do not trigger events are unable to estimate the flow, giving the visualizations of their prediction a highly shabby appearance. And they make a lot of incorrect predictions, particularly in row 4 under the sparse flow prediction of an outdoor scene where a lot of the pixels are colored differently from the flow GT and have the wrong direction of motion. E-RAFT~\cite{gehrig2021raft} and DCEIFlow~\cite{wan2022DCEI} are supervised training to estimate dense flows, but DCEIFlow fuses the features of events and images as input. Some artifacts appear at the bottom of the E-RAFT visualization results, and the flow prediction error for indoor scenes is large. DCEIFlow also has some wrong predictions, such as the bottom left corner of the sampe in row 4. No matter how dense or sparse the data is or whether it is indoors or outdoors, our flow prediction is closest to Flow GT when compared to the previous methods, which is consistent with our prior quantitative comparison findings.

\paragraph{Analysis of the MDR dataset.}  
To demonstrate the effectiveness of our proposed MDR dataset, we train several optical flow networks~\cite{sun2018pwc,gehrig2021raft,zhao2022GMFlowNet,huang2022flowformer,sun2022skflow,jiang2021gma,luo2022kpa} on both MDR and MVSEC train sets using identical training settings. For training, we use a combination of data samples from the MDR dataset with a density range of $[0.09, 0.69]$. We evaluate the trained networks on the MVSEC validation set, and the results, presented in Table~\ref{tab:dataset_comparison}, demonstrate that all networks trained on the MDR dataset outperform those trained on the MVSEC dataset.
%As shown in Table~\ref{tab:dataset_comparison}, all supervised optical flow networks perform better in evaluations after training on MDR than MVSEC, regardless of whether the model parameters are greater or less. The camera causes the majority of the motion in the MVSEC dataset, and the flow labels are derived using sparse depth and camera motion. As a result, there are spatial inconsistencies between events and optical flow in some settings. Moreover, the MVSEC training set only includes an outdoor scene. So it is more challenging for the supervised optical flow estimation. Our MDR dataset has multiple densities of events and matching dense flow labels, and includes both indoor and outdoor scenes, making it more suitable for supervised optical flow estimation networks than the former.

\begin{table}[t]
	\centering
	\resizebox*{0.99 \linewidth}{!}{
		\begin{tabular}
			{   >{\arraybackslash}p{2.9cm}| % backbone
				>{\centering\arraybackslash}p{1.4cm}| % EPE indoor flying1
				>{\centering\arraybackslash}p{1.4cm}| % out indoor flying1
				>{\centering\arraybackslash}p{1.4cm}| % EPE indoor flying2
				>{\centering\arraybackslash}p{1.4cm}| % out indoor flying2
				>{\centering\arraybackslash}p{0.65cm} % avg
			}
\hline
\multirow{2}{*}{Method ($dt=1$)} &  \multicolumn{4}{c|}{density range} & \multirow{2}{*}{Avg}  \\
\cline{2-5}
&0.09-0.21&0.21-0.36&0.36-0.57&0.57-0.69&\\
\hline
Spike-Flow$_S$~\cite{lee2020spikeflownet} & 1.13   & 1.20   & 1.33    & 2.01    & 1.42    \\
STE-Flow$_S$~\cite{ding2022STE-FLOWNET} & 0.82   & 1.00    & 0.87    & 0.82    & 0.88   \\
E-RAFT$_D$~\cite{gehrig2021raft} & 0.93   & 0.85    & 0.69   & 0.92    & 0.85    \\
E-RAFT$_S$~\cite{gehrig2021raft} & 1.02    & 1.13   & 0.89    & 1.14    & 1.05    \\
DCEIFlow$_D$~\cite{wan2022DCEI} & \textcolor{blue}{0.79}   & 0.72    & 0.67    & \textcolor{blue}{0.62}    & 0.70   \\
DCEIFlow$_S$~\cite{wan2022DCEI} & 0.90    & 0.66    & 0.60    & 0.98   & 0.79    \\
\bf ADM-Flow$_D$(ours) & \textcolor{red}{0.73}  & \textcolor{blue}{0.53}  & \textcolor{blue}{0.51}  &  \textcolor{red}{0.56}  &  \textcolor{red}{0.58}  \\
\bf ADM-Flow$_S$(ours) & 0.96   &  \textcolor{red}{0.47}   &  \textcolor{red}{0.47}   & 0.63    & \textcolor{blue}{0.63}  \\
\hline
\multirow{2}{*}{Method ($dt=4$)} &  \multicolumn{4}{c|}{density range} & \multirow{2}{*}{Avg}  \\
\cline{2-5}
&0.09-0.21&0.21-0.36&0.36-0.57&0.57-0.69&\\
\hline
Spike-Flow$_S$~\cite{lee2020spikeflownet} & 3.95    & 1.96    & 2.09  & 2.87    & 2.72   \\
STE-Flow$_S$~\cite{ding2022STE-FLOWNET} & 2.71   & 2.17    & 1.72   & \textcolor{red}{1.73}   & 2.08    \\
DCEIFlow$_D$~\cite{wan2022DCEI} &  \textcolor{red}{1.72}    & 1.66   & 1.16    & 2.14    & \textcolor{blue}{1.67}    \\
DCEIFlow$_S$~\cite{wan2022DCEI} & 2.87   & 1.35    & 1.16    & 2.24   & 1.90    \\
\bf ADM-Flow$_D$(ours) & \textcolor{blue}{1.89}  &  \textcolor{red}{1.25}   &  \textcolor{red}{0.98}  &  \textcolor{blue}{1.75}  &  \textcolor{red}{1.47} \\
\bf ADM-Flow$_S$(ours) & 2.54   & \textcolor{blue}{1.27}   & \textcolor{blue}{1.09}  & 2.17   & 1.77   \\
\hline
	\end{tabular}}
    \caption{Quantitative evaluation on our MDR dataset. The methods in table are all trained on MVSEC dataset. $S$ and $D$ donate the \emph{sparse} and \emph{dense} evaluation, respectively. We use EPE as the evaluation metric. }
	\label{tab:mdr_result}
\end{table}

\subsection{Ablation study.} 

\paragraph{Training with different densities.\label{densities_comparison}}
We examine the impact of input event sequence density on optical flow learning, as our MDR dataset contains event data with various densities and corresponding dense flow labels. We train SKFlow~\cite{sun2022skflow}, GMA~\cite{jiang2021gma}, FlowFormer~\cite{huang2022flowformer} and KPA-Flow~\cite{luo2022kpa} on the same sequence from our MDR dataset but with different average densities produced by using different threshold $C$, and then test them on MVSEC dataset. 
Figure~\ref{fig:density} shows the results, indicating that these models perform better as the average density of the training set increases. However, their performance diminishes as the average density continues to increase. This phenomenon highlights the importance of selecting an appropriate density for the training set when learning event optical flow.
% In order to compute the average EPE on the test set of MVSEC, we train several supervised optical flow networks on ten training sets with various average densities. The experimental results demonstrate that, within a given range, the trained model performs better as the average density of the training set increases, but as average density increases, performance diminishes. The trend of this relationship curve is shown in Fig.~\ref{density}. The visualization results are displayed in Fig.~\ref{density2}. We thereby establish the ADM's experimental foundation.

\paragraph{Ablation for ADM.} 
In order to verify the impact of our proposed ADM module, we conduct ablation experiments by plugging the ADM module into several optical flow network to selectively adjust the densities of the input events. 
We train these networks on both MDR and MVSEC datasets with the same setting except that the ADM module is disabled or not, and test them on MVSEC dataset.
The experiment results are shown in  Table~\ref{tab:comparisonforADM}, where we can notice that our ADM module can bring performance improvement for all supervised methods.% in Table~\ref{tab:comparisonforADM}, both on the MDR and on the training set of MVSEC. 

%Ultimately, with the dual gain of MDR and ADM, our module ADM-Flow is based on KPA-Flow~\cite{luo2022kpa} achieves the state-of-the-art performance on both the test sets of MVSEC and MDR.

\begin{table}[!t]
	\centering
	\resizebox*{0.99 \linewidth}{!}{
		\begin{tabular}
			{   >{\arraybackslash}p{2.4cm}| % backbone
				>{\centering\arraybackslash}p{0.8cm}| % EPE indoor flying1
				>{\centering\arraybackslash}p{1.2cm} % out indoor flying1
				>{\centering\arraybackslash}p{1.2cm}| % EPE indoor flying2
				>{\centering\arraybackslash}p{1.2cm} % out indoor flying2
				>{\centering\arraybackslash}p{1.2cm} % avg
			}
\hline
\multirow{2}{*}{Method } & Train& \multicolumn{2}{c|}{$dt=1$} & \multicolumn{2}{c}{$dt=4$}  \\
% \cline{3-4}\cline{5-6}
&D.Set&EPE & \%Out&EPE & \%Out\\
\hline
\multirow{2}{*}{PWCNet~\cite{Hur:2019:IRR}} & M    & 1.25  & 5.41    & 4.03  & 51.48  \\
          & MDR   & 1.14  & 3.48   & 2.92  & 38.62  \\
\hline
\multirow{2}{*}{E-RAFT~\cite{gehrig2021raft}}  & M     & 1.19  & 4.90     & 3.33  & 39.78  \\
          & MDR   & 0.59  & 0.51   & 2.57  & 30.24  \\
\hline
\multirow{2}{*}{GMFlowNet~\cite{zhao2022GMFlowNet}}  & M     & 1.00  & 3.75    & 3.61  & 42.31  \\
          & MDR   & 0.82  & 1.66   & 2.70  & 31.53  \\
\hline
\multirow{2}{*}{FlowFromer~\cite{huang2022flowformer}} & M     & 0.87  & 3.08    & 3.38  & 41.04  \\
 & MDR   & 0.61  & 0.40    & 2.49  & 28.83  \\
\hline
\multirow{2}{*}{SKFlow~\cite{sun2022skflow}}& M     & 1.07  & 3.97      & 3.41  & 40.87  \\
          & MDR   & 0.59  &\textcolor{blue}{0.33}  & 2.46  & 27.64  \\
\hline
\multirow{2}{*}{GMA~\cite{jiang2021gma}}& M     & 0.88  & 4.05    & 2.99  & 34.80  \\
          & MDR   & \textcolor{blue}{0.58}  & 0.44  & \textcolor{red}{2.19} & \textcolor{red}{23.00} \\
\hline
\multirow{2}{*}{KPAFlow~\cite{luo2022kpa}}& M     & 0.86  & 2.86    & 3.19  & 38.32  \\
          & MDR   & \textcolor{red}{0.58} & \textcolor{red}{0.39} & \textcolor{blue}{2.33}  & \textcolor{blue}{26.10}  \\
\hline
	\end{tabular}}
    \caption{Comparison of training on MVSEC vs. our MDR. Models are evaluated on MVSEC data set for dense optical flow estimation. }
	\label{tab:dataset_comparison}
\end{table}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{images/densityEPE.png}
    \caption{The performance of some supervised optical flow networks with different densities of the training set. X-axis is the average density of events in the training set, and y-axis is their average EPE in the test set of MVSEC.}
    \label{fig:density}
\end{figure}

\paragraph{Ablation for the design of ADM.} 
We conduct ablation experiments to verify the effectiveness of each component in our ADM module, including MDC, MDS, and the two training loss functions $L_{\mathrm{MDC}}$ and $L_{\mathrm{MDS}}$. We train models using the same settings on the MDR dataset and evaluate on the MVSEC dataset to show the individual impact of each component in our ADM module. The results are presented in Table~\ref{tab:ablation}.
Comparison of (a)\&(b) shows that adding only the MDC plugin results in a slight performance gain. Comparison of (b)\&(c) reveals that enabling the density selection function through the MDS module brings a significant improvement. Comparing (c)\&(d) and (d)\&(e), we notice that with the guidance of two loss functions, ADM can learn to selectively choose the best density for optical flow estimation, resulting in a relatively significant improvement.

% We also conduct the ablation experiments to confirm the effectiveness of each part in our ADM module, including MDC, MDS and two training loss functions $L_{\mathrm{MDC}}$ and $L_{\mathrm{MDS}}$. 
% We use the same setting to train models on the MDR dataset and test on MVSEC dataset to show the impact of each individual part in our ADM module. 
% The results are shown in Table~\ref{tab:ablation}.
% By comparing (a)\&(b), we can notice that only add the MDC plugin results in a slight performance gain. 
% By comparing (b)\&(c), we can notice that enabling the density selection function by MDS module can bring in a considerable improvement.
% By comparing (c)\&(d) and (d)\&(e), we can notice that with the guidance of two loss functions, ADM can learn to selectively pick the best density for optical flow estimation, bringing a relatively large improvement.  



\begin{table}[t]
	\centering
	\resizebox*{0.99 \linewidth}{!}{
		\begin{tabular}
			{   >{\arraybackslash}p{2.8cm}| % backbone
				>{\centering\arraybackslash}p{0.7cm} % EPE 
				>{\centering\arraybackslash}p{0.7cm}| % out 
				>{\centering\arraybackslash}p{0.7cm} % EPE indoor flying2
				>{\centering\arraybackslash}p{0.7cm}| % out indoor flying2
				>{\centering\arraybackslash}p{0.7cm} % avg
                >{\centering\arraybackslash}p{0.7cm}| % out indoor flying2
                >{\centering\arraybackslash}p{0.7cm} % avg
                >{\centering\arraybackslash}p{0.7cm} % out indoor flying2
			}
\hline
\multirow{2}{*}{Method} &\multicolumn{2}{c|}{M($dt=1$)} & \multicolumn{2}{c|}{MDR($dt=1$)}  & \multicolumn{2}{c|}{M($dt=4$)}  & \multicolumn{2}{c}{MDR($dt=4$)} \\
% \cline{2-4}\cline{5-6}
 &EPE & \%Out & EPE & \%Out & EPE & \%Out & EPE & \%Out\\
\hline
    PWCNet~\cite{Hur:2019:IRR} & 1.25  & 5.41  & 1.14  & 3.48  & 4.03  & 51.48  & 2.92  & 38.62  \\
    ADM-PWCNet & 1.07  & 4.52  & 0.76  & 1.48  & 2.95  & 33.31  & 1.94  & 18.74  \\
\hline
    E-RAFT~\cite{gehrig2021raft} & 1.19  & 4.90  & 0.59  & 0.51  & 3.33  & 39.78  & 2.57  & 30.24  \\
    ADM-ERAFT & 0.82  & 3.03  & 0.56  & 0.24  & 2.73  & 30.91  & 1.72  & 13.83  \\
\hline
    GMFlowNet~\cite{zhao2022GMFlowNet} & 1.00  & 3.75  & 0.82  & 1.66  & 3.61  & 42.31  & 2.70  & 31.53  \\
    ADM-GMFlowNet & 0.87  & 3.05  & 0.58  & 0.32  & 2.78  & 31.26  & 1.81  & 14.45  \\
\hline
    FlowFromer~\cite{huang2022flowformer} & 0.87  & 3.08  & 0.61  & 0.40  & 3.38  & 41.04  & 2.49  & 28.83  \\
    ADM-FlowFromer & 0.78  & 2.87  & 0.53  & 0.15  & \textcolor{blue}{2.56}  & \textcolor{blue}{26.57}  & 1.67  & 12.78  \\
\hline
    SKFlow~\cite{sun2022skflow} & 1.07  & 3.97  & 0.59  & 0.33  & 3.41  & 40.87  & 2.46  & 27.64  \\
    ADM-SKFlow & 0.84  & 3.18  & \textcolor{blue}{0.53}  & \textcolor{blue}{0.14}  & 2.67  & 28.17  & 1.69  & 12.61  \\
\hline
    GMA~\cite{jiang2021gma} & 0.88  & 4.05  & 0.58  & 0.44  & 2.99  & 34.80  & 2.19  & 23.00  \\
    ADM-GMA & \textcolor{red}{0.76} & \textcolor{red}{2.65} & 0.54  & 0.22  & \textcolor{red}{2.45} & \textcolor{red}{25.75} & \textcolor{blue}{1.63}  & \textcolor{blue}{11.95}  \\
\hline
    KPAFlow~\cite{luo2022kpa} & 0.86  & 2.86  & 0.58  & 0.39  & 3.19  & 38.32  & 2.33  & 26.10  \\
    ADM-KPAFlow & \textcolor{blue}{0.80}  & \textcolor{blue}{2.81}  & \textcolor{red}{0.51} & \textcolor{red}{0.14} & 2.64  & 28.58  & \textcolor{red}{1.61} & \textcolor{red}{11.83} \\
\hline
	\end{tabular}}
    \caption{Quantitative comparison of whether using ADM. Models are trained on the MVSEC (i.e. M) and MDR training set, and evaluated on the MVSEC test sets for dense optical flow estimation in $dt = 1$ and $dt = 4$ settings.}
	\label{tab:comparisonforADM}
\end{table}



\begin{table}[t]
	\centering
	\resizebox*{0.99 \linewidth}{!}{
		\begin{tabular}
			{   >{\arraybackslash}p{1.0cm}| % backbone
				>{\centering\arraybackslash}p{0.8cm}| % EPE 
				>{\centering\arraybackslash}p{0.8cm}| % out 
				>{\centering\arraybackslash}p{0.8cm}| % EPE indoor flying2
				>{\centering\arraybackslash}p{0.8cm}| % out indoor flying2
                >{\centering\arraybackslash}p{0.8cm}| % 
                >{\centering\arraybackslash}p{0.7cm} % out indoor flying2
                >{\centering\arraybackslash}p{0.7cm}| % avg
                >{\centering\arraybackslash}p{0.7cm} % out indoor flying2
                >{\centering\arraybackslash}p{0.7cm} % out indoor flying2
			}
\hline
\multirow{2}{*}{Method} & \multirow{2}{*}{MDC}  & \multirow{2}{*}{MDS} & \multirow{2}{*}{$L_{\mathrm{MDC}}$}  & \multirow{2}{*}{$L_{\mathrm{MDS}}$}  & \multirow{1}{*}{Param.}  & \multicolumn{2}{c|}{$dt=1$}  & \multicolumn{2}{c}{$dt=4$} \\
% \cline{2-4}\cline{5-6}
  & & & & &(M) & EPE & \%Out & EPE & \%Out\\
    \hline
    (a)   & \ding{53} & \ding{53} & \ding{53} & \ding{53} & 6.01  & 0.58  & 0.39  & 2.33  & 26.10 \\
    (b)   & \ding{51} & \ding{53} & \ding{53} & \ding{53} & 7.71  & 0.57  & 0.33  & 2.20   & 23.78 \\
    (c)   & \ding{51} & \ding{51} & \ding{53} & \ding{53} & 7.72  & 0.54  & 0.26  & 1.92  & 18.26 \\
    (d)   & \ding{51} & \ding{51} & \ding{51} & \ding{53} & 7.72  & \textcolor{blue}{0.52}  & \textcolor{blue}{0.16}  & \textcolor{blue}{1.66}  & \textcolor{blue}{13.29}  \\
    (e)   & \ding{51} & \ding{51} & \ding{51} & \ding{51} & 7.72  & \textcolor{red}{0.51 } & \textcolor{red}{0.14 } & \textcolor{red}{1.61} & \textcolor{red}{11.83} \\
\hline
	\end{tabular}}
    \caption{Ablation study. Models are trained on the MDR training set, and evaluated on the MVSEC test sets for dense optical flow estimation in $dt = 1$ and $dt = 4$ settings.}
	\label{tab:ablation}
\end{table}

%In model (b)\&(c), with the best density label of the MDR dataset as the Gound truth, using $L_{\mathrm{MDC}}$ to supervise the training of MDC to change the densities of events will bring a comparable improvement. In model (c)\&(d) and (e)\&(f), gains can result from using MSFF to fuse multi-scale features to add useful information. In model (c)\&(e) and (d)\&(f), with the addition of the MDS module, ADM can selectively pick the best density for each pixel, bringing a relatively large improvement. In model (f)\&(g), adding $L_{\mathrm{MDS}}$ will supervise the training ADM more strictly, so that the density adjusted by ADM is closer to the best. In summary, the model with both parts obtains the best results, which demonstrates the effectiveness of each component in our module.
