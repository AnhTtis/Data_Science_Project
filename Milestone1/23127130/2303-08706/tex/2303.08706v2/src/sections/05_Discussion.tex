\section{State of the Art Comparison}\label{section:Discussion}

\input{src/tables/soa_table}

\Cref{tab:soa_table} shows the details of our implementation alongside the State of the Art. Compared with ARM, their TCLS~\cite{iturbe_arm_2019} implementation features a split-lock mechanism that is based on resetting the system to configure it in independent or \gls{tmode}. Furthermore, the recovery routine they propose takes 2351 clock periods to conclude, meaning $6.5\times$ slower than our software-based \gls{tmode}. ARM's DCLS~\cite{iturbe_soft_2016} also features split-lock functionalities decided during system reset. Our split-lock allows for higher flexibility and performance, making the cluster capable of runtime switching between independent and \gls{dmode} or \gls{tmode} in 681 and 597 clock cycles, respectively, with further $1.17\times$ and $1.08\times$ reduction with the \textit{rapid recovery} hardware support. Moreover, ARM's TCLS implementation introduces $27\%$ area overhead over the single core implementation, while the \gls{hmr} unit with \textit{rapid recovery} features proposed in this work introduces just $9\%$ area overhead over the baseline implementation. 

\citeauthor{kempf_adaptive_2021}~\cite{kempf_adaptive_2021} propose a dual-core adaptive runtime-selectable lockstep processor based on a LEON core with internal modifications for instruction comparison. The fault recovery is software-based, with a time-to-recovery that is application dependent. Our \textit{rapid recovery} hardware extension on the other hand allows for fixed 24 cycles to recover from occurring faults. Also, the area overhead of the solution proposed by~\citeauthor{kempf_adaptive_2021} accounts for $21.3\%$ in terms of CLBs over the regular LEON implementation, while our full \gls{hmr} unit accounts for just $9\%$ of area overhead over a standard 12-cores \gls{pulp} cluster, with a similar dual-core configuration needing only $8.4\%$.

CEVERO~\cite{silva_cevero_2020} proposes a DCLS system with no split-lock capabilities and with a similar \textit{rapid recovery} hardware extension to ours, with a recovery procedure that takes $1.67\times$ longer than ours. Furthermore, CEVERO disregards copying the \glspl{csr}, which are fundamental in defining the complete recovery state of the core, and the backup copies of \gls{pc} and \gls{rf} are not protected by error correction, meaning there is no guarantee that the backup state is reliable.

\citeauthor{shukla_low-overhead_2022}~\cite{shukla_low-overhead_2022} present a quad-core RISC-V-based processor re-configurable for DCLS operation, introducing up to $17.9\%$ area overhead over the base implementation, while our \gls{hmr} unit offers more flexibility by introducing just $9\%$ area overhead over a standard 12-cores \gls{pulp} cluster. In addition, \citeauthor{shukla_low-overhead_2022} rely on saving just the last executed \gls{pc} for the recovery, which is insufficient to determine the entire state of the grouped cores.

In \Cref{tab:soa_table}, we also compare our design with other works, such as SHATKI-F~\cite{gupta_shakti-f_2015}, Duck Core~\cite{li_duckcore_2021}, and \citeauthor{gkiokas_fault-tolerant_2019}~\cite{gkiokas_fault-tolerant_2019}. The first two works propose modifications to RISC-V cores' internal microarchitecture for pipeline rollback. On the other hand, the third proposes extending a RISC architecture with triple repetition of all the pipeline stages until the execution stage. The results produced by the three execution stages are then voted and propagated to the memory and write-back stages of the pipeline. The latter two pipeline stages do not enforce any redundancy technique to guarantee consistency, thus leaving the memory and write-back stages unprotected. The proposed solutions show a valuable approach that leads to just 3-to-0 clock cycles to perform a fault recovery, allowing for a single core to be reliable without the need for redundant grouping, thus saving resources. In contrast, the extensive modifications required by the internal architecture of the core can significantly change the behaviour, compromising its formal verification.

We also compared our work with SafeDE~\cite{bas_safede_2021} and SafeDM~\cite{bas_safedm_2022}, proposing hardware monitors to enforce diverse redundancy in a multicore RISC-V system, tackling the coverage of common cause failures in redundant threads. In SafeDE, the only way to understand if the diversity exists in the executed thread is to compute the distance, in terms of instructions count, between the head and the trailer core, with the trailer core being stalled for the required clock cycles to respect the diversity constraint. However, there is no description of how to mitigate the case in which one of the two executions is corrupted by a fault, so we assume that the two cores are reset and forced to re-execute the code. Similar considerations apply to SafeDM, where it is unclear if a fault between the two redundant executions can even be detected.

Finally, \Cref{tab:soa_table} also shows qualitative comparisons to the industry-standard approach of \gls{radhard} technology augmented with \gls{ecc} for memories. This approach, adopted by Gaisler~\cite{hijorth_gr740_2015}, BAE~\cite{berger_quad-core_2015}, Ramon Chips~\cite{ginosar_rc64_2016}, and the DAHLIA project with the NG-ultra~\cite{danard_ng-ultra_2022}, significantly simplifies integration of reliability. However, these devices generally feature lower performance and lower efficiency than counterparts built on commercial technologies and often come at a significant price premium due to the use of \gls{radhard} technology. Furthermore, in contrast to our solution, they offer no way to disable these reliability methods in case they are not needed, sacrificing performance in case they are still used in these cases. If a large-scale device deployment requires certain nodes with reliability and certain nodes without, either different devices need to be used, requiring additional development overhead, or certain nodes pay in performance, efficiency, and cost. Finally, architectural solutions can more easily benefit from advances in technology, as these can more easily be ported to the most modern commercial technologies, not requiring additional development of new radiation-hardened libraries and design kits.
