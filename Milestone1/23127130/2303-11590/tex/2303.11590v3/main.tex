%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.
\renewcommand{\baselinestretch}{0.955}


%%% BEGIN YTC shortcuts
\newcommand{\ub}{\underline{\bf{}}}
% \renewcommand{\baselinestretch}{1}

\newtheorem{Theorem}{Theorem}[section]
\newtheorem{Lemma}[Theorem]{Lemma}
\newtheorem{Proposition}[Theorem]{Proposition}
\newtheorem{Definition}[Theorem]{Definition}
\newtheorem{Corollary}[Theorem]{Corollary}
\newtheorem{Notation}{Notation}
\newtheorem{Remark}[Theorem]{Remark}
% \numberwithin{equation}{section}

\def\no{\noindent} \def\p{\partial} \def\nb{\nonumber}
\def \Vh0{\stackrel{\circ}{V}_h} \def\to{\rightarrow}
\def\cl{\centerline}   \def\ul{\underline}
\def\Om{\mathcal{T}}  \def\om{\mathcal{T}} \def\I{ {\rm (I) } }
\newcommand{\q}{\quad}   \newcommand{\qq}{\qquad} \def\R{{\mathbb R}}
\def\l{\label}  \def\f{\frac}  \def\fa{\forall}
%\def\D{\end{document}}
\def\b{\beta}  \def\a{\alpha} \def\eps{\varepsilon}
\def\m{\mbox} \def\t{\times}  \def\lam{\lambda}
\def\Box{\sharp}
\def\fn{\footnote}

\def\u{{\bf u}} \def\v{{\bf v}} \def\w{{\bf w}}
\def\n{{\bf n}}  \def\x{{\boldsymbol x}} \def\A{{\bf A}}
\def\E{{\bf E}} \def\H{{\bf H}} \def\J{{\bf J}}

\newcommand{\lc}
{\mathrel{\raise2pt\hbox{${\mathop<\limits_{\raise1pt\hbox
{\mbox{$\sim$}}}}$}}}

\newcommand{\gc}
{\mathrel{\raise2pt\hbox{${\mathop>\limits_{\raise1pt\hbox{\mbox{$\sim$}}}}$}}}

\newcommand\zgnote[1]{\textcolor{blue}{[ZG: #1]}}

\newcommand{\ec}
{\mathrel{\raise2pt\hbox{${\mathop=\limits_{\raise1pt\hbox{\mbox{$\sim$}}}}$}}}

\def\bb{\begin{equation}} \def\ee{\end{equation}}
\def\beqn{\begin{eqnarray}}  \def\eqn{\end{eqnarray}}
\def\beqnx{\begin{eqnarray*}} \def\eqnx{\end{eqnarray*}}
\def\bn{\begin{enumerate}} \def\en{\end{enumerate}}
\def\i{\item}
\def\bd{\begin{description}} \def\ed{\end{description}}
%%% END YTC shortcuts


\input{packages}

\title{\LARGE \bf
Koopman-Hopf Hamilton-Jacobi Reachability and Control % tempting
% Koopman-Hopf for Approximate Hamilton-Jacobi Reachability in \\ High-Dimensional, Nonlinear Systems % OG
% Koopman-Hopf Procedure for Hamilton-Jacobi Reachability and Control \\ in High-Dimensional, Nonlinear Systems % yes but bleh
% A Koopman-Hopf approach for Hamilton-Jacobi Reachability in High Dimensonal Non-Linear Systems % too long
}

\author{Will Sharpless, Nikhil U. Shinde, Matthew Kim, Yat Tin Chow and Sylvia Herbert
\thanks{Sharpless, Shinde, Kim, and Herbert are with University of California, San Diego. Chow is with the University of California, Riverside. 
\{\href{mailto:wsharpless@ucsd.edu}{wsharpless}, \href{mailto:nshinde@ucsd.edu}{nshinde}, \href{mailto:mak009@ucsd.edu}{mak009}, \href{mailto:sherbert@ucsd.edu}{sherbert}\}@ucsd.edu, \href{mailto:yattinc@ucr.edu}{yattinc}@ucr.edu
This work is supported by NIH training grant T32 EB009380 (McCulloch) and ONR YIP N00014-22-1-2292. The content is solely the responsibility of the authors.}
}

%
%, 

\begin{document}
\maketitle
\thispagestyle{empty}
\pagestyle{empty}
\begin{abstract}
The Hopf formula for Hamilton-Jacobi Reachability analysis has been proposed for solving high-dimensional differential games as a space-parallelizeable method. In exchange, however, a complex optimization problem must be solved, limiting its application to linear time-varying systems. To compute Hamilton-Jacobi backwards reachable sets (BRS) and synthesize the corresponding online controllers for high-dimensional nonlinear systems, we pair the Hopf solution with Koopman theory. We find that this is a viable method for approximating the BRS and performs better than local linearizations. Furthermore, we construct a Koopman-Hopf controller for robustly driving a 10-dimensional, nonlinear, glycolysis model and find that it significantly out-competes expectation-minimizing and game-theoretic Model Predictive Controllers with the same Koopman linearization in the presence of bounded stochastic disturbance. In summary, we propose and validate a dimension-robust method to approximately solve HJ Reachability, allowing novel application to control high-dimensional, nonlinear systems with bounded disturbance.
\end{abstract}

\section{Introduction}

There are several active directions for designing safe autonomous systems with myriad approaches to overcoming the difficulty of the problem. The technical rigor involved in planning for success while simultaneously avoiding failure tends to force methods to sacrifice guarantees (e.g. data-driven methods where success is higher but failure is too) or feasibility (e.g. differential inclusion where solutions are often over-conservative or burdensome to solve).  

Among these approaches, Hamilton-Jacobi Reachability (HJR) is well known for being a robust approach to optimal control and safe path planning \cite{bansal2017hamilton, chen2017exact, donggun19iterativehopf, Kirchner_2018, chow2017algorithm}. When feasible, it is often the top choice in robotics, autonomous driving and other stochastic control problems because of its derivation from the theory of differential games \cite{evans1984differential, lions1986hopf} which describes how to optimally posture a system to counter antagonistic or stochastic, bounded disturbances \cite{bacsar1998dynamic}. HJR is, however, not the most practical approach because of its dependency on spatial gradient approximations which makes it sensitive to the \textit{curse of dimensionality} \cite{bansal2017hamilton}. If this theory could be extended to higher dimensional systems, engineering efforts in diverse domains, particularly in medicine, finance and other large systems, could make strides where simpler (dimension-robust) controllers are unable to overcome disturbances. 

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{BRS_duffing_2s_scatter_nice.png}    
    \caption{Here the $\pm \epsilon$ boundary of a target $\mathcal{T}$ (black), the DP-solved reachable set $\mathcal{R}(\mathcal{T},t)$ (blue), the local-linearization Hopf BRS $\mathcal{R}( \mathcal{T}_{\text{Taylor}},t)$ (green), and our 15D Koopman-Hopf BRS $\mathcal{R}(\widetilde{\mathcal{T}}_\mathcal{G},t)$ (gold) are plotted for the Duffing oscillator at $t=2s$ with control and disturbance and $\epsilon=0.1$.  We show the scatter plot to emphasize that Koopman-Hopf solution is solved in a space-parallizeable fashion, hence, each point is solved independently.
 %\zgnote{for this figure, seems like the gold one approximates the best right? Maybe try to use bigger points to emphisize the good results and use smaller points to weak the 'not so good' resutls. (or maybe darker vs lighter color)}
    \vspace{-2em}}
    \label{fig:BRSapprox} 
\end{figure}

\subsection{Related Work}

Toward this end, several directions have been developed, including set-based propagation, often called the method of zonotopes \cite{althoff2011zonotope}, to over-approximate the Hamilton-Jacobi reachable states with linear systems \cite{althoff2011zonotope,Bak} and in some special classes of nonlinear systems \cite{majumdar2014convex}. The only shortcomings with these methods are that they do not inherently provide an optimal controller and also tend to be overly-conservative.

Another direction is the method of decomposition and system reduction for HJR. The authors of \cite{chen2017exact} define the system structures that can be decomposed into exponentially-faster, low-dimension problems, however, any coupled dimensions cannot be decomposed. There is also a method of projecting coupled systems to independent, lower-dimensional subsystems such that the inverted solution is a conjectured over-approximation \cite{Ian03}, however, this is often highly conservative and lacks guarantee.

More recently, the Hopf formula was revived \cite{darbon2016algorithms,chow2017algorithm,chow2019algorithm} as yet another route to HJR without sensitivity to dimension or sacrificing guarantees but in limited cases. This method involves interchanging a dynamic-programming (DP) problem for an abstract optimization problem over the characteristic curves of the Lagrange multiplier \cite{darbon2016algorithms}. Note, it does not lend a ``free lunch", instead the difficulty appears now as a so-called \textit{curse of complexity} because the optimization problem requires sophisticated approaches (see \cite{darbon2016algorithms, chow2017algorithm, chow2019algorithm} for detailed analysis). Nonetheless, certain classes of systems, namely linear time-varying systems, can be robustly solved in both one-player \cite{doggn2020hopf, donggun19iterativehopf} and two-player optimal cases \cite{Kirchner_2018, chow2017algorithm}. Notably, \cite{Kirchner_2018} was paired with a naive linearization methods to control a pursuit-evasion nonlinear systems with success, although without random disturbance. 

In this work, we build on the aforementioned strides by novely pairing the Hopf solution with Koopman theory for global linearization. Koopman theory involves 'lifting' nonlinear dynamics to high dimensional spaces in order to linearize them with higher accuracy \cite{koopman1931hamiltonian, mezic2021koopman}. Multiple works have found that the Koopman procedure can yield highly accurate predictions over a short horizon, suitable for Model Predictive Control (MPC) and LQR \cite{proctor2014dynamic, korda2018linear, yeung2019learning,CompKoop,kaiser2021data}. Furthermore, we are inspired by recent, impressive work into Koopman theory applied to the method of Zonotopes for general (non-optimal) reachability \cite{Bak}. 

% Our resulting Koopman-Hopf method can be used to solve HJ backwards reachable sets (BRSs); a BRS is the set of states from which the system can reach a target set at a desired time. A BRS generally may expand in all directions of the state space, and we hypothesized a spatially-balanced linearization would be necessary for accuracy. We find that this has much to do with \cite{Ian03} and solving HJR in a ``parallel" space. Although optimizing the resulting Hopf problem is not simple, we find that with sophisticated formulations such as the alternating direction method of multipliers (ADMM), close approximations of the true BRS can be achieved (see Figure~\ref{fig:BRSapprox}). Moreover, we show that the resulting controller fares better than a stochastic Koopman-MPC (expectation-minimizing) or game-theoretic Koopman-MPC for a 10-dimensional glycolysis model. Ultimately, the accuracy of the BRS's and the robust navigation through a high dimensional, stochastic nonlinear system defend that the proposed pairing is not only valid, but a prudent choice when juxtaposed with other linearization methods or controllers in the Koopman space.

In this work, we use Koopman theory to define a 'lifted', linear reachability problem which approximates our true problem and can be solved by the dimension-insensitive Hopf solution. Note, this sacrifices guarantees but yields accurate approximations of HJ Backwards Reachable Sets (BRSs) - the states from which a system can be driven to a target set at a desired time for any bounded disturbance - and their corresponding optimal controllers for high-dimensional, nonlinear systems for which no other method is available.

\subsection{Contributions and Organization}

\noindent We make the following contributions:
\begin{enumerate}

    \item We formulate a novel method to approximately solve differential games skirting the \textit{curse of dimensionality}.

    \item We propose definitions for the corresponding Koopman reachability problem that satisfy the Hopf assumptions.
    
    \item We compare the BRS of our method to that of the DP solution and a Taylor-based solution for both a convex and non-convex game in the Duffing system.
    
    \item We synthesize a novel Koopman-Hopf controller and compare it to two Koopman-MPC formulations in a 10-D glycolysis model with bounded, stochastic disturbance.
    
\end{enumerate}

The paper is structured as follows. Sec. \ref{sec:HJR} formally introduces HJR, BRSs and the DP solution. Sec. \ref{subsec:hopf} introduces the Hopf solution and it's limitations. Sec. \ref{sec:Koop} introduces Koopman theory to counter these limitations. Sec. \ref{sec:koopman_hopf} proposes a method of lifting the reachability problem to the Koopman space that satisfies the Hopf assumptions. Sec. \ref{sec:results} demonstrates the Koopman-Hopf method, first, in the Duffing system where (because of the low dimensionality) its feasible to compare to DP (Sec. \ref{subsec:BRSapprox}) and, second, in a 10D Glycolysis system where we compare the novel controller with Koopman-MPC's (Sec. \ref{subsec:Glycolysis}). Finally, Sec. \ref{sec:conclusion} summarizes the work and describes future directions.

% Sec. \ref{subsec:BRSapprox} demonstrates the proposed method by comparing the BRS of the true solution in both convex and non-convex games in the Duffing system. Sec. \ref{subsec:Glycolysis} 

% \begin{enumerate}
%     \item HJR
%     \item Linear reachability (zonotopes etc)
%     \item Hopf, 1-Player or naive linearizations 
%     \item Koopman, Koopman-MPC, Koopman-LQR
%     \item Koopman Reachability (stanley bak)
% \end{enumerate}


% \subsection{Hopf Reachability Analysis of 2-Player Games}
% \begin{enumerate}
%     \item great for LTV systems with bounds on input, disturbance
%     \item if nonlinear, optimization of the 2-Player Hopf solution suffers from the curse of complexity
% \end{enumerate}

% \subsection{Koopman Lifting of Nonlinear Systems}
% \begin{enumerate}
%     \item can capture nonlinearities by lifting to higher dim
%     \item since hopf can handle higher dimensions, we propose merging these
% \end{enumerate}

\section{Preliminaries}\label{sec:prelims}
This paper focuses on control-affine and disturbance-affine systems of the form
\beqn
\dot x = f_x(x, t) + B_1(t)u + B_2(t)d \triangleq f(x, u, d, t)
\label{Dynamics}
\eqn
%where $x(\cdot) \subset \mathcal{X} := \mathbb{R}^{n_x}$ is the state trajectory evolving from initial state $x$, $u(\cdot) \subset \mathcal{U} \subset \mathbb{R}^{n_u}$ is the control trajectory and $d(\cdot) \subset \mathcal{D} \subset \mathbb{R}^{n_d}$ is the disturbance trajectory, and $\mathcal{U}$ and $\mathcal{D}$ are convex sets constraining the respective inputs. 
where control and disturbance inputs $u$ and $d$ are drawn from convex sets $\mathcal{U} \subset \R^{n_u}$, $\mathcal{D} \subset \R^{n_d}$, 
and the control and disturbance functions $u(\cdot)$ and $d(\cdot)$ are assumed to be of the set of measurable functions $\mathbb U : [t,0] \mapsto \mathcal{U}$, $\mathbb D : [t,0] \mapsto \mathcal{D}$.
Assuming that the dynamics \eqref{Dynamics} is Lipschitz continuous in $(x,u)$ and continuous in $t$, there exists a unique trajectory $x(\cdot) \subset \mathcal{X} := \mathbb{R}^{n_x}$ of the system given initial state $x$, control function $u(\cdot)$, and disturbance function $d(\cdot)$. 

% \zgnote{Here, $\mathcal {X,U,D}$ are sets, denoting the control you take at a specific time right? and the corresponding trajectory should be a function: $u(\cdot): [t,T] \mapsto \mathcal U$ right? Then probably need another set denote mesurable function, i.e. $\mathbb U$ to denote these trajectory.}

\subsection{Hamilton-Jacobi Reachability Problem}\label{sec:HJR}
% Consider a system,
% \beqn
% \dot x(\tau) = f(x(\tau)), u(\tau), d(\tau), \tau) \quad \forall \tau \in [t, T],\: x(t)= x
% \label{Dynamics}
% \eqn

% \beqn
% ||f(x, u, d, t) - f(x', u, d, t)|| \leq L_f||x - x'|| \quad x, x' \in \mathbb{R}^{n_x}.
% % \label{Lipchitz}
% \eqn

To design a safe autonomous controller, HJ reachability solves for the optimal control that counters an adversarial disturbance in a differential game. Here, the control player's objective is to minimize the game cost while the disturbance player seeks to maximize it \cite{chow2017algorithm}. 
The game is defined by the cost functional
\beqn
P(x, u(\cdot), d(\cdot), t) = J(x(T)) + \int_t^T L(u(\tau), d(\tau)) d\tau ,
\label{GameCost}
\eqn
where $x(T)$ is the solution of (\ref{Dynamics}) at time $T$. The terminal cost $J:\mathbb{R}^{n_x} \rightarrow \mathbb{R}$ is a convex, proper, lower semicontinuous function chosen such that
\beqnx
\begin{cases}
J(x) < 0 \:\: \text{ for } \:\:x \in \mathcal{T} \setminus \partial\mathcal{T} \\
J(x) = 0 \:\: \text{ for }\:\:x \in \partial\mathcal{T} \\
J(x) > 0 \:\: \text{ for } \:\:x \notin \mathcal{T} \\
\end{cases}
\label{InitialValue}
\eqnx
where $\mathcal{T} \subset \mathcal X$ is a user-defined closed set representing the target to reach (or avoid, if the max/min are switched) and $\partial \mathcal{T}$ its boundary. The running cost $L:\mathbb{R}^{n_u} \times \mathbb{R}^{n_d} \rightarrow \mathbb{R}$ serves only to constrain the inputs and, thus, takes the form,
\beqn
L(u, d) = \mathcal{I}_\mathcal{U}(u) - \mathcal{I}_\mathcal{D}(d)
\label{RunningCost}
\eqn
where $\mathcal{I}_\mathcal{C}$ are the indicator functions of $\mathcal{U}$ and $\mathcal{D}$,
\beqn
\mathcal{I}_\mathcal{C}(c) = \{0 \text{ if } c \in \mathcal{C}, +\infty \text{ else} \}.
\label{Indicator}
\eqn
We have now defined the game such that for trajectory $x(\cdot)$ arising from a given $x$, $u(\cdot)\subset \mathcal{U}$, $d(\cdot)\subset \mathcal{D}$, $t$, and (\ref{Dynamics}), 
\beqn
P(x, u(\cdot), d(\cdot), t) \leq 0 \iff x(T) \in \mathcal{T}.
\label{GameMeaning}
\eqn


% where $p\in\mathbb{R}^{n_x}$ is the Lagrange multiplier of the dynamics constraint. In this paper we assume that $\forall t$ the Hamiltonian obtains a unique Nash equilibrium (saddle point) for the control and disturbance strategies (Isaac's condition). While restrictive, this assumption applies to a large class of systems, namely linearly-affine systems of the form,
% \beqn
% \dot x = f(x, t) + B_1(t)u + B_2(t)d.
% \label{DynamicsAffine}
% \eqn
% Isaac's condition guarantees that the game has value, i.e. that the lower and upper value of the game coincide and, thus, can be defined unanimously by
The function  $V:\mathbb{R} \times R \rightarrow \mathbb{R}$ corresponding to the optimal value of the game is defined as
\beqn
V(x,t) = \sup_{\mathit{d} (\cdot) \subset \Gamma(t)} \inf_{u(\cdot) \subset \mathcal{U}} P(x, u(\cdot), d(\cdot), t)
\label{GameValue}
\eqn
where $\Gamma(t)$ is the set of non-anticipative strategies defined in \cite{bacsar1998dynamic, darbon2016algorithms, chow2017algorithm, chow2019algorithm} and we assume Isaac's condition \cite{bacsar1998dynamic}.
This function is useful because by the same logic of (\ref{GameMeaning}),
\beqn
V(x,t) \leq 0 \iff x \in \mathcal{R}(\mathcal{T},t)
\label{ValueMeaning}
\eqn
where $\mathcal{R}(\mathcal{T},t)$, the BRS, is the set of all states which can be driven to the target for any bounded disturbance, formally defined by
\beqn
\mathcal{R}(\mathcal{T},t) =\{x \:\:  | \:\:  \exists u(\cdot)\subset \mathcal{U} \:\: \forall d(\cdot)\subset \mathcal{D} \text{ s.t. } \\ x(\cdot) \text{ satisfies } (\ref{Dynamics}) \land x(T) \in \mathcal{T}\}.
\label{BRS}
\eqn
Notably, applying Bellman's principle of optimality to this time-varying value function $V$ leads to the following well known theorem.
\begin{mytheorem}
[Evans 84] \cite{evans1984differential}
Given the assumptions (2.1)-(2.5) in [Evan 84], the value function $V$ defined in (\ref{GameValue}) is the viscosity solution to the following Hamilton-Jacobi Partial Differential Equation,
\beqn
\begin{aligned}
\frac{\partial V}{\partial t}  + H(x, \nabla_x V, t) &= 0 \qquad \text{ on } \mathbb{R}^{n_x} \times [t,T], \\
V(x,T) &= J(x(T)) \:\: \text{ on } \mathbb{R}^{n_x} 
\end{aligned}
\label{HJPDE-V}
\eqn
where the Hamiltonian $H:\mathbb{R}^{n_x} \times \mathbb{R}^{n_x} \times [t,T] \rightarrow \mathbb{R}$ is defined as 
\beqn
H(x, p, t) = \min_{u \in \mathcal{U}} \max_{d \in \mathcal{D}} p \cdot f(x, u, d, t).
\label{Hamiltonian}
\eqn
\end{mytheorem}

To solve this PDE, therefore, yields the value function and corresponding BRS. Additionally, the value function can be used to derive the optimal control strategy for any point in space and time with:
\beqn
\begin{aligned}
u^*(t) = \arg \min_{u \in \mathcal{U}} \nabla_x V(x,t) \cdot B_1(t)u.
\end{aligned}
\label{HJoc}
\eqn

The main challenge of HJR lies in solving this PDE in (\ref{HJPDE-V}); DP methods propagate $V(x, t)$ by finite-differences over a grid of points that grows exponentially with respect to $n_x$ \cite{bansal2017hamilton}. In practice, this is computationally intractable for systems of $n_x \geq 6$ and constrained to offline planning.
    
\subsection{The Hopf Solution to HJ-PDE's}\label{subsec:hopf}

An alternative to the brute-force grid solving of $V(x,t)$ is the Hopf formula, which offers a solution to (\ref{HJPDE-V}) in the form of a space-parallelizeable optimization problem. 
First, we define $\phi(x,t):=V(x, T-t)$ to change the aforementioned final-value problem into an initial-value problem for simplicity. $\phi$ is now the solution of
\beqn
\begin{aligned}
- \frac{\partial \phi}{\partial t}  + H(x, \nabla_x \phi, t) &= 0 \qquad \text{ on } \mathbb{R}^{n_x} \times [0,t], \\
\phi(x,0) &= J(x) \:\: \text{ on } \mathbb{R}^{n_x} 
\end{aligned}
\label{HJPDE-phi}
\eqn
with Hamiltonian,
\beqn
H(x, p, t) = \max_{u \in \mathcal{U}} \min_{d \in \mathcal{D}} -p \cdot f(x, u, d, T-t).
\label{HamiltonianPhi}
\eqn
% and $f$ defined in (\ref{Dynamics}).

Note, for systems $f(x,u,d,t)=f(u,d,t)$ without state dependence, the Hamiltonian $H(x,p,t) = H(p,t)$ also lacks state-dependence and in this setting the following Hopf formula is available with limitation. This formula was conjectured in \cite{hopf1965generalized}, proved to be the viscosity solution in \cite{bardi1984hopf} and \cite{lions1986hopf} for $H(p)$, and generalized to some $H(t,p)$ in \cite{rublev2000generalized, kurzhanski2014dynamics}. Recently, \cite{darbon2016algorithms} devised a fast method of solving this formula and \cite{chow2019algorithm} conjectured a general form for $H(x,t,p)$.


% {\color{red}
% You probably want to cite [11, 21, 35] in [CDOY 17], especially [35], for this time dependant formula.
% Please look into Section 2.3 for the rigorous statement of the theorem right after (2.7).  You see a technical assumption that H is required to be pseudo-convex w.r.t.the argument p in the set of minimum arguments S(t,x) in [CDOY 17]
% I think you would like to shorten it, so perhaps again you may refer to the conditions in [35] in [CDOY 17] and [CDOY 17] both for reference of the conditions.

% [35] in [CDOY 17]: 
% I.V. Rublev, Generalized Hopf formulas for the nonautonomous Hamilton-Jacobi equation, Computational
% Mathematics and Modeling 11.4,pp. 391-400 (2000).

% In there, again there will be Lipschitz conditions etc, and the above "pseudo-convex" assumption.  

% P.S. the formula gives minimax-viscosity solution, which is slightly different from viscosity solution, the two definitions are not the sme.  (Again See section 2.3 in [CDOY 17].)  The two coincides when H is convex, but in general they may differ.
% You may want to weaken this point though.

% In the "control" case instead of game, when H is convex, another citation you may have is [21, Section 5.3.2, p. 215] from the [Kirchner] paper for IEEE Control Systems Letters

% A. B. Kurzhanski and P. Varaiya. Dynamics and Control of Trajectory
% Tubes: Theory and Computation, volume 85. Springer, 2014.

% You may want to follow the Kirchner paper to weaken the difference if you want.

% }

\begin{mytheorem} [Rublev 2000] 
We assume $J(x)$ convex and Lipchitz, and that $H(t,p)$ is pseudoconvex in $p$ and satisfies (B.i-B.iii) in [Rublev 00], then the minimax-viscosity solution \cite{subbotin1996minimax} of (\ref{HJPDE-phi}) is given by the time-dependent Hopf formula,
\beqn
\phi(x,t) = -\min_{p \in \mathbb{R}^{n_x}} \bigg\{ J^\star(p) - x \cdot p + \int_0^t H(p, \tau) d\tau \bigg\}
\label{HopfFormula}
\eqn
where $J^\star(p):\mathbb{R}^{n_x} \rightarrow \mathbb{R} \cup \{+\infty\}$ is the Fenchel-Legendre transform (i.e. convex-conjugate) of a convex, proper, lower semicontinuous function $J:\mathbb{R}^{n_x} \rightarrow \mathbb{R}$ defined by
\beqn
J^\star(p) = \sup_{x\in \mathbb{R}^{n_x}} \{ p \cdot x - J(x) \}.
\label{FL}
\eqn
Note, under these assumptions, the minimax-viscosity and viscosity solutions are the same when $H(s,p)$ is entirely convex or entirely concave in $p$ for $s\in [0,t]$ \cite{rublev2000generalized, subbotin1996minimax}.
\end{mytheorem}
See \cite{rublev2000generalized, subbotin1996minimax, chow2019algorithm} for analysis and comparison of minimax-viscosity and viscosity solutions. Note, only the latter corresponds to the solution of the differential game when different. For general non-convex $H$, the question of when these solutions coincide remains open, however, like \cite{chow2019algorithm}, we observe agreement in numerical examples below. 

% We may note, from the definition of the Fenchel-Legendre (FL) transform, (\ref{HopfFormula}) may be rewritten as \cite{lions1986hopf}
% \beqn
% \phi(x,t) = \bigg(J^\star + \small\int_0^t H\bigg)^\star (x).
% \label{FLphi}
% \eqn
% This illustrates that the value function is itself an FL transform and from the well known property of FL transforms \cite{lions1986hopf}, $\nabla_x \phi(x,t)$ is the minimum argument of (\ref{HopfFormula}), which we may use to compute the optimal control strategy.

The strength of Hopf is that now we may compute (\ref{HJPDE-V} \& \ref{HJPDE-phi}) and solve our problem by solving a space-parallizeable optimization problem (i.e. $\phi(x,t)$ does not depend on $\phi(x',t'<t)$, unlike DP) \cite{darbon2016algorithms, chow2017algorithm, chow2019algorithm}, avoiding the so called \textit{curse of dimensionality}. However, to require a state-independent Hamiltonian limits this method greatly. Furthermore, we can not guarantee we have the solution which solves the game if the Hamiltonian is non-convex, which can occur based on the relative sizes of $\mathcal{U}$ and $\mathcal{D}$.

It was noted in \cite{kurzhanski2014dynamics, darbon2016algorithms, chow2017algorithm} that any linear time-varying system can be mapped to a state-independent system 
\beqn
\begin{aligned}
\dot x = A(t)x + B_1(t) u + B_2(t) d \\ \rightarrow \dot z = \Phi(t)(B_1(t) u + B_2(t) d)
\end{aligned}
\label{LinearStateIndependent}
\eqn
with the linear time-varying mapping $z(t):=\Phi(t)x(t)$ defined by the fundamental matrix $\dot \Phi = A(t) \Phi(t), \Phi(0) = I $. After the change of variable, the Hamiltonian for $\phi$ becomes,
\beqn
\begin{aligned}
H_\mathcal{Z} (p, t) =& \max_{u \in \mathcal{U}} -p \cdot \Phi(T-t) B_1(T-t) u \\ 
& - \max_{d \in \mathcal{D}} -p \cdot \Phi(T-t) B_2(T-t) d .
\end{aligned}
\label{HamiltonianLinear}
\eqn
Since the mapping $x\rightarrow z$ is one-to-one, we know $\phi_\mathcal{Z}(z,t) = \phi(x,t)$ and
\beqn
\phi_\mathcal{Z}(x,t) = -\min_{p \in \mathbb{R}^{n_x}} \bigg\{ J_\mathcal{Z}^\star(p) - z \cdot p + \int_0^t H_\mathcal{Z}(p, \tau) d\tau \bigg\}
\label{HopfFormulaZ}
\eqn
where $\phi(z, 0) = J_\mathcal{Z}(z,0) = J(\Phi(T)x(T))$ and we define $T=0$, thus, $J_\mathcal{Z}(z) = J(x)$ and $J_\mathcal{Z}^\star(p) = J^\star(p)$.
% \beqn
% \begin{aligned}
% z = z(0) = x(0) = x &\implies J_\mathcal{Z}(z) = J(x)  \\
% &\implies J_\mathcal{Z}^\star(p) = J^\star(p).
% % \label{eqn}
% \end{aligned}
% \eqn

Given the convexity of $\mathcal{U}$ and $\mathcal{D}$, the Hamiltonian in (\ref{HamiltonianLinear}) can be rewritten as the difference of two positively homogeneous Hamiltonians corresponding to the convex-conjugates of their Indicator functions  \cite{chow2017algorithm},
\beqn
\begin{aligned}
H_\mathcal{Z} (p,t) = \mathcal{I}_\mathcal{U}^\star(R_1 p) - \mathcal{I}_\mathcal{D}^\star(R_2 p), \\ R_i:=-B_i(T-t)^\dagger \Phi(T-t)^\dagger .
\end{aligned}
\label{HamiltonianIndicator} 
\eqn
This allows rapid and efficient computation of (\ref{HopfFormulaZ}) that has been observed to scale linearly with $n_x$ for a fixed $t$ \cite{chow2017algorithm} and demonstrated in online guidance with naive linearizations \cite{Kirchner_2018}. Notably, when $\mathcal{U}$ and $\mathcal{D}$, are constrained by norms, these functions have analytical solutions, namely the dual norms. Given $Q\in\mathbb{R}^{n \times n}$, consider two popular input constraints \cite{chow2017algorithm} and their $\mathcal{I}^\star$:
\beqn
\begin{aligned}
 \mathcal{C}_{\mathcal{E}}(Q) := \{c\:\:|\:\:||c||_Q \leq 1\} \implies \:\: \mathcal{I}_\mathcal{C}^\star(\cdot) = ||\cdot||_{Q^{-1}}, \\
 \mathcal{C}_{\mathcal{R}}(Q) := \{c\:\:|\:\:||Qc||_\infty \leq 1\} \implies \:\: \mathcal{I}_\mathcal{C}^\star(\cdot) = ||Q\cdot||_1.
\end{aligned}
\label{InputConstraint} 
\eqn
% where $||\cdot||_Q = ||\Sigma V^T \cdot||_2$ is the elliptical norm described by $Q^{-1}$ and $||Q\cdot||_\infty$ the rectangular norm. 
If $\mathcal{U}$ and $\mathcal{D}$ are defined by the same set type in (\ref{InputConstraint}) with $Q_u$ and $Q_d$ respectively, then convexity of the Hamiltonian is given when $Q_u \succeq Q_d$ i.e. when the control authority exceeds the disturbance authority.


\subsection{Koopman Theory}\label{sec:Koop}

We would like to apply dimension-robust Hopf theory to high-dimensional, nonlinear systems with a highly accurate linearization to approximate BRS's and synthesize safe control. Moreover, we would like a non-local linearization method due to the need for global analysis across the state space. Koopman theory is known for outperforming other linearization methods in these regards \cite{proctor2014dynamic, korda2018linear, yeung2019learning}.

Consider the discretized mapping of a nonlinear system,
$
x(t_{i+1}) = F(x(t_i))$.
The Koopman operator \cite{koopman1931hamiltonian, mezic2021koopman} $\mathcal{K}:\mathcal{F} \rightarrow \mathcal{F}$ is defined as
% \beqn
$\mathcal{K} g:=g \circ F$,
% \label{KoopDef}
% \eqn
where $\mathcal{F}$ is the collection of all functions that form an infinite Hilbert space, often called observables or lifting functions, and $g \in \mathcal{F}:\mathcal{X} \rightarrow \mathbb{R}$ \cite{mezic2021koopman, CompKoop}. By definition, the operator has the property,
\beqn
(\mathcal{K}g)(x(t_i)) = g(F(x(t_i))) = g(x(t_{i+1}))
\label{mezic2021koopman, KoopProperty}
\eqn
and we assume this holds for a finite space such that $Kg \in \mathcal{G}$ \cite{mezic2021koopman, CompKoop}, where $\mathcal{G}$ is an invariant subspace of the Koopman space. We assume this space is spanned by a finite basis of lifting functions $\Psi(x):= \{ \psi_1(x),\: \dots, \psi_{n_k}(x) \}$ and, thus, $K \in \mathbb{R}^{n_k \times n_k}$ is a finite matrix.

%Despite that Koopman and Von Neumann did not consider a system with external inputs, several group 
Recent works have found this theory can be extended to systems with external inputs \cite{proctor2014dynamic, korda2018linear, mezic2021koopman, kaiser2021data,CompKoop} such that for $x(t_{i+1}) = F(x(t_i),u(t_i),d(t_i))$,
\beqn
g(t_{i+1}) \approx Kg(t_i) + L_1 u(t_i) + L_2 d(t_i),
\label{KoopControl}
\eqn
where $L_1$ and $L_2$ are the Koopman control and disturbance matrices. Moreover, although absent from the original theory, we have found it useful, like others \cite{proctor2014dynamic, korda2018linear, yeung2019learning}, to define a `lowering' function $\widetilde{\psi}:\mathcal{G} \rightarrow \mathcal{X}$ which is not injective in general because the approximate nature of (\ref{KoopControl}). 

\section{Koopman-Hopf Reachability}\label{sec:koopman_hopf}

% \subsection{Reachability in Lifted Spaces}\label{sec:lifted_reach}

We now seek to approximate the value and BRS (\ref{sec:HJR}) of our differential game by solving the Hopf formula (\ref{HopfFormulaZ}) with approximate linear dynamics derived from Koopman methods. We will first show how to define the target set in the lifted Koopman space. We will then discuss the Koopman lifting functions that are well-suited to the Hopf solution. Finally, we describe how to solve the resulting Hopf reachability analysis using the lifted target set and dynamics.

\subsection{Defining the lifted target set}Given a target $\mathcal{T}$ defined in (\ref{sec:HJR}), our target can be lifted directly to the Koopman space with $\Psi$,
\beqn
\mathcal{T}_\mathcal{G} := \{ g \:\: |  \:\: g = \Psi(x), \: x \in \mathcal{T}\}.
\label{KoopTarget}
\eqn
However, given that we may not have an exact linearization, we also propose an approximate target,
\beqn
\widetilde{\mathcal{T}}_\mathcal{G} := \{ g \:\: | \:\: \widetilde{\psi} (g) \in \mathcal{T}\}
\label{KoopTargetApprox}
\eqn
as the preimage of the target in the Koopman space under the lowering function $\widetilde{\psi}$. This captures the Koopman trajectories which might evolve off of the manifold defined by the true states $g = \Psi(x) \subset \mathcal{G}$ to $g' \in \mathcal{G}$ for which $\nexists x'$ such that $g' = \Psi(x')$.

%On the contrary, we are only concerned with finding the value of the states $\phi_\mathcal{G}(g,t)$ in the Koopman space such that $\exists x$ mapping to $g = \Psi(x)$. The value of states off of the true-state manifold might be the result of backwards-propagating a trajectory which may not ever have a real initial condition.

\subsection{Lifting the target set and dynamics}
The choice of lifting functions will impact the shape of the lifted target sets $\mathcal{T}_\mathcal{G}$ and $\widetilde{\mathcal{T}}_\mathcal{G}$. To provide guarantees that the Hopf analysis will return the optimal solution, the cost function (and therefore target set) must be convex. This can be enforced by either (a) using lifting functions $\Psi$ that are convex, or (b) taking the inner (for reach) or outer (for avoid) ball or convex-hull of $\Psi(\mathcal{T})$\footnote{alternatively, one could use the Lax formula \cite{chow2019algorithm}, which swaps the convexity assumption between $J$ and $H$. This approach has its own challenges for implementation beyond the scope of this paper.}.
% An important requirement for utilization of the Hopf solution is convexity of $J(x)$. This is true if the Target $\mathcal{T}$ is convex, thus, we need $\mathcal{T}_\mathcal{G}$ convex. We propose a couple solutions: \zgnote{Here you are saying that the target is convex is the sufficient condition for a convex cost right? Is this always true? Or maybe you want to say if the target is convex, we can always define a convex cost?}
% \begin{itemize}
%     \item Take the inner (for reach) or outer (for avoid) ball or convex-hull of $\Psi(\mathcal{T})$
%     \item Use the Lax formula [YTC19], which swaps the convexity assumption between $J$ and $H$
%     \item Use lifting functions $\Psi$ that are convex
% \end{itemize}
Using convex lifting functions is challenging, given that the difference of convex functions is not necessarily convex, and thus, the notion of a basis is ill-defined.  On the other hand, simply ``convexifying'' a lifted target from non-convex lifting functions might be drastically conservative.
%(not to mention convex-hull methods also suffer from the \textit{curse of dimensionality}), the non-convex Lax formula would ultimately trouble our numerical optimization all the same, 
%and the notion of a convex basis is troubled as the difference of convex functions is not necessarily convex.

We were thus motivated to demonstrate the proposed method with two simple cases of lifting functions:
\begin{enumerate}
    \item the identity mapping, $I:\mathbb{R}^{n_x} \rightarrow \mathbb{R}^{n_x}$ (i.e. DMD \cite{proctor2014dynamic})
    \item the multivariate polynomial of degree $l$, 
$P_l:\mathbb{R}^{n_x} \rightarrow \mathbb{R}^{M}, M = {n_x + l \choose l}  - 1$.
\end{enumerate}
Both cases have been extensively studied in Koopman literature; the former corresponds to Dynamic-Mode-Decomposition with control (DMDc) \cite{proctor2014dynamic} while the latter is a case of Extended-DMD with control \cite{korda2018linear, kaiser2021data}. 

The identity mapping is trivial and thus
\beqn
I(\mathcal{X}) = \mathcal{X} \implies \mathcal{T} = \mathcal{T}_\mathcal{G} = \widetilde{\mathcal{T}}_\mathcal{G} \implies \phi_\mathcal{G}(g,t) = \phi(x,t),
\label{IdentityTarget}
\eqn
assuming we also define $\widetilde{\psi} = I$; this implies that our lifted target will be convex if our initial target is convex. 

%Although, we find it successful for one example of Koopman-based high-dimensional nonlinear control (\ref{sec:ctrl}), the 
The polynomial mapping $P_l(x)$ is more expressive and therefore produces more accurate linearizations of dynamics.
%identity mapping is known to be less "expressive" and yields less accurate linearizations than EDMD procedures [cites]. %On the other hand, the polynomial mapping  is better able to capture nonlinear dynamics with standard Koopman methods [cites], but requires some caution. 
The trouble with the polynomial mapping is in the negative domain $\mathbb{R}^{n_x}_{<0}:=\{x|x_i\le 0\}$. On this region, the mapping is not-invertible and non-convex, and therefore impacts the Hopf reachability solution. 

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{Glycolysis_experiment_half.png}    
    \caption{Four controlled evolutions of the 10D glycolysis model (based on the same Koopman lift) with the same disturbance trajectory and initial condition. `Auto' signifies the controller which is disturbed but always chooses the trivial input. The Koopman-Hopf controller amplifies the cycle of the phosphate, glucose and ATP states to achieve the target in a manner that translates to the nonlinear system.}
    \label{fig:glycolysis}\vspace{-1em}
\end{figure*}
%\zgnote{if the legend can be bigger, this will be a great figure}

% However, with a polynomial mapping, the following lemma proves that the mapping of the target set can be bounded to over-approximate the set. Here we consider the mapping of a spherical target $\mathcal{T}:=\mathcal{B}_r(x_c)=\{ x\:|\: ||x - x_c||_2 \le r\}$, however, the results might be extended to other norms.

% \begin{mytheorem}[\shnote{ name}]
% Given the boundary of a spherical target $\partial \mathcal{B}_r(x_c):=\{ x\:|\: ||x - x_c||_2 = r\}$, the $x_c$ shifted polynomial mapping, $g(x) := P_l(x-x_c)$ will be bounded by,
% \beqn
% \begin{aligned}
% % ||g(x) - g(x_c)||^2 \le \sum_k^L r^{2k} \quad x \in \partial \mathcal{B} \\
% ||\bar g(x) - \bar g(x_c)||^2 = \sum_k^l r^{2k} =: r_l \quad x \in \partial \mathcal{B}
% \end{aligned}
% \eqn
% if $\bar g(x) := T g(x) $ and $T := \text{Diag}(\{ \sqrt{{n_i \choose l_j}} \}_{i \in [1, l], j \in [1, n_x]})$.
% \label{PolynomialBound}
% \end{mytheorem}
% Hence, the surface of the ball will map to the surface of a larger ball of radius $r_l$ if we linearly scale the polynomial map by the square root of the binomial coefficients.
% This provides us with a method to approximate the non-convex mapping of the target $P_l(\mathcal{T})$ with a convex $\mathcal{T}_\mathcal{G} := \mathcal{B}_{r_l}$ such that 
% %\beqn
% $\forall g \in \mathcal{T}_\mathcal{G}, \quad (g = \Phi(x), x \in \mathcal{T}) \lor (g \notin \text{Im}(\Psi)).$ 
% %\eqn

To resolve this issue, one could consider reachable problems on the complement of $\mathbb{R}^{n_x}_<0$, the positive vectors $\mathbb{R}_{\ge 0}^{n_x}$, where the map is one-to-one.
However, in applications for safety, this would require a temporal bound on the BRS growth to know when we might be incorporating ambiguous trajectories in the solution of our game. Furthermore, this would constrain our lifting procedure undesirably. 

It is common to circumvent the issues above by using the first-degree polynomial terms \cite{proctor2014dynamic} to return to $\mathcal{X}$ such that
%\beqn
$\widetilde{\psi}(g) := \text{Proj}_\mathcal{X}(g).$
%\label{PolynomialReturn}
%\eqn
This would imply that $\widetilde{\mathcal{T}}_\mathcal{G}$ is the infinite extrusion of our target, and if our target were defined by either of the sets in (\ref{InputConstraint}) and a PSD matrix $A\in\mathbb{R}^{n_x \times n_x}$ (e.g. an ellipsoid or box), then
\beqn
\widetilde{\mathcal{T}}_{\mathcal{G}, \mathcal{C}} = \mathcal{C}(\hat A), \:\: \hat A:=\begin{bmatrix}A & 0 \\ 0 & 0\end{bmatrix} \in \mathbb{R}^{M \times M}
\label{PolynomialTargetApprox}
\eqn
is an infinite cylinder or rectangualr prism. In practice, we find that finite-relaxations of this set defined by $\mathcal{C}(\hat A + \epsilon I)$ for $\epsilon << 1$ are required for quickly solving the Hopf optimization problem.

Finally, we note that to guarantee convergence to the global optimum, we also need convexity of the Hamiltonian. If the control and disturbance enter the Koopman space as in (\ref{KoopControl}), the sets will remain convex, however, there is a chance the $L$ matrices may change the relative sizes and break convexity. One could limit to disturbances on the control input only to guarantee this, but we also find in practice that the non-convex/minimax-viscosity problem can be solved with a powerful optimizer like ADMM and matches the viscosity solution closely.

% Requirements
% \begin{enumerate}
%     \item For hard guarantees, need exact linearization and maintain convexity. Only in specific cases, i.e. with convex lifting functions and with disturbance on control only can we guarantee convexity.
%     \item If relax these requirements, lose guarantees but using a powerful solver which is known to perform well in non-convex cases, we gain approximations for high-dim nonlinear systems. Can be used as-is or to guide e.g. training.
%     \item how to lift target set / function to high-dim space and back.
% \end{enumerate}

\section{Results}\label{sec:results}

All results are computed using our codebase \href{https://github.com/UCSD-SASLab/HopfReachability}{\textit{HopfReachability.jl}}, an open-source package designed for solving 2-player linear differential games.

% \subsection{Exactly Linearizeable Systems}\label{subsec:EL}

% We begin by considering the well-known slow manifold system \cite{proctor2014dynamic}, which can be Koopman-linearized exactly. Although simple, we use this example to validate our codebase \href{https://github.com/UCSD-SASLab/HopfReachability}{\textit{HopfReachability.jl}}, an open-source package designed for solving 2-player linear differential games. Let us specifically consider an $N$-dimensional generalization of the slow manifold system, with control and disturbance, defined by
% \beqn
% \begin{aligned}
% \dot x_i =& \mu_i x_i + x_i^{-1}(u_i +d_i) \quad (i < N), \\
% \dot x_N =& \lambda \big(x_N - \frac{1}{N-1}\sum^{N-1} x_i^{k_i} \big) + u_i + d_i.
% \label{ExactLinearizeable}
% \end{aligned} 
% \eqn
% Akin to the traditional model, it can be linearized by defining $g_i(x) := x_i^{k_i} \implies \dot g_i = k_ix_i^{k_i - 1} \dot x_i = k_i \mu_i g_i$, leading to, $\dot g = Kg + Bu + Bd$. 

% We might note, however, that the system is bizarre near the origin; both control and disturbance tend to $\infty$. Moreover, we are faced with the previously discussed ambiguous lack of invertibility near the origin. Hence, to study Koopman-HJR in this canonical example, we consider a target defined at $5*\mathbf{1}$. Given that our mapping is locally one-to-one and exactly linearizeable, we use the direct lifted target $\mathcal{T}_\mathcal{G}$ as defined in (\ref{KoopTarget}). We compare our results with an HJR dynamic programming method, namely \textit{hj\_reachability.py}, considered to be close to ground truth. We quantify the error with the Jaccard Index over a common descritized grid,
% \beqn
% JI(\mathcal{R}_1,\mathcal{R}_2)= \frac{|\mathcal{R}_1 \cap \mathcal{R}_2|}{|\mathcal{R}_1 \cup \mathcal{R}_2|}.
% \label{Jaccard}
% \eqn
%  The results for the index and compute time versus dimension $N$ are displayed in Table~\ref{}.\shnote{where is this table}



\subsection{Approximate BRS of the lifted Duffing Oscillator}\label{subsec:BRSapprox}

Here, we test the Koopman-Hopf approach on the nonlinear Duffing oscillator in both the cases with disturbance on the control input (convex Hamiltonian) and disturbance on the full state (non-convex Hamiltonian) with the previously discussed ellipsoidal target (\ref{KoopTarget}). We solve the BRS's evolving from the lifted targets, backwards in time with Koopman dynamics derived from a 4-degree polynomial $P_4(x)$ (with 15 dimensions) that was hyper-tuned by the \textit{autokoopman.py} package written by the authors of \cite{Bak}. 

We compare our results with an HJR DP method, namely \textit{hj\_reachability.py}, considered to be highly-accurate. Figure ~\ref{fig:BRSapprox} compares the BRS's at $t = 2$ in the problem with disturbance on all states and non-convex Hamiltonian.

We quantify the error with the Jaccard Index over a common discritized grid ($1 \implies$ perfect matching), 
\beqn
JI(\mathcal{R}_1,\mathcal{R}_2)= \frac{|\mathcal{R}_1 \cap \mathcal{R}_2|}{|\mathcal{R}_1 \cup \mathcal{R}_2|}.
\label{Jaccard}
\eqn
The Jaccard index is used to quantify the similarity of these sets to the \textit{hj\_reachability.py} BRS, and we include a baseline derived from the Taylor series approximate dynamics with a localization point at the center of the target in $\mathcal{X}$. The numerical results can be viewed in Table~\ref{table:BRSresults}.

\begin{table}[h]
\caption{BRS similarity results compared to true BRS, $JI(\mathcal{R}(\mathcal{T}), \cdot)$ for disturbance on control and convex (left), disturbance on all states, non-convex (right)}
\label{table:BRSresults}
\begin{center}
\begin{tabular}{|c||c|c||c|c|}
\hline
t & $\mathcal{R}(\mathcal{T}_{Taylor})$ & $\mathcal{R}(\widetilde{\mathcal{T}}_\mathcal{G})$ &  $\mathcal{R}(\mathcal{T}_{Taylor})$ & $\mathcal{R}(\widetilde{\mathcal{T}}_\mathcal{G})$  \\
\hline
\hline
  0.0  & 1.0 & 0.97    & 1.0 & 0.97   \\
-0.33  & 0.90 & 0.96   & 0.92 & 0.91    \\
-0.66  & 0.80 & 0.88   & 0.85 & 0.80    \\
-0.99  & 0.61 & 0.82   & 0.71 & 0.66    \\
-1.32  & 0.47 & 0.78   & 0.50 & 0.60    \\
-1.65  & 0.37 & 0.79   & 0.37 & 0.59    \\
-1.98  & 0.30 & 0.76   & 0.30 & 0.58    \\
\hline
\end{tabular}
\end{center}
\end{table}

%We do not include $\tilde{\mathcal{T}_G}$ here as it proved to be a massive under approximation of the reachable space, likely a consequence of the inexact nature of the linearization. 
Note, in the non-convex case we lose guaranteed convergence to the global optimum (minimax) and agreement between the minimax and viscosity solutions, which likely explains why the Koopman-Hopf results.% the equal $JI$ with the Taylor series and worse performance compared with the convex case, but overall, the similarity is decent.

\subsection{Comparison of Koopman controllers on the 10D Glycolysis Model}\label{subsec:Glycolysis}

Next, we compare the ability of a Koopman-Hopf controller to navigate the true nonlinear dynamics of a 10D glycolysis model extended from \cite{yeung2019learning,ruoff2003temperature,daniels2015efficient} given its 10D DMDc linearization derived from the \textit{pykoopman.py} package. The Koopman-Hopf controller uses the standard Hopf controller formulation  \cite{donggun19iterativehopf,doggn2020hopf,Kirchner_2018} to solve for the minimum time $T^*$ for which the target is reachable given the current state $x$,
\beqn
T^* = \text{argmin}_T \phi(x, t) = \text{argmin}_T \phi(g, t), \quad g = \Psi(x).
\label{MinT}
\eqn
The controller then applies the optimal control at this time which is derived from,
\beqn
\nabla_p H(\nabla_{z_g} \phi(z_{g_0}, T^*), T^*) = e^{-tK} L_1 u^* + e^{-tK} L_2 d^*.
\label{HJocHopf}
\eqn

We compare this Koopman-Hopf controller with two basic Koopman-MPC formulations that also evolve their dynamics in the Koopman space \cite{bemporad2002model, korda2018linear}. The MPC game (MPCg) solves the optimal control for a random fixed disturbance with a one-step horizon, and then the disturbance does the same for the previous control, and this iterates for 3 iterations (where improvement plateaued). The standard MPC (MPCs) is a stochastic MPC \cite{mesbah2016stochastic} where the controller samples 20 random disturbance trajectories and minimizes the expectation of the cost given evolution with those samples. %In both cases, the MPC's are defined by a terminal cost alone to match the Hopf controller.

The goal of all controllers is to achieve a target ATP concentration, as a bioengineer might desire for cell growth, by manipulating the external glucose, total NAD+/NADH pool, and ADP/ATP pool. After the controllers compute a $u(t)$, the system is then progressed with the true nonlinear dynamics (using Radau). The system is complex because of the highly-stiff nonlinearities, state constraints ($x_i > 0$) and inter-connectivity of the metabolic network; naively driving the ATP/ADP pool up leads to counter-productive results, as demonstrated by MPCg and MPCs.

The simulation was run 50 times, with each controller subjected to the same random initial conditions sampled from the realistic concentration bounds given in \cite{ruoff2003temperature, daniels2015efficient} and same random disturbance trajectory. The success of the Koopman-Hopf controller can be observed in Table~\ref{MPCresults} and Figure~\ref{fig:glycolysis}. The Koopman-Hopf controller appears to overcome the nonlinearity of the system by amplifying the oscillations of ATP to reach the target.

\begin{table}[h]
\caption{Controller Results for 50 random $x_0$ bounded by \cite{daniels2015efficient} and random $d(\cdot)$. The per-point computation time is given as $t_c$.}
\label{MPCresults}
\begin{center}
\begin{tabular}{|c||c|c|c|c|}
\hline
Controller & Success \% & Mean, Max ATP [m] & Mean $t_c$/step [s] \\
\hline
\hline
Auto & 20 & 2.07 & $\emptyset$ \\
Hopf & 96 & 3.06 & 0.81 \\
MPCg & 22 & 2.14 & 0.02 \\
MPCs & 16 & 1.96 & 0.36 \\
\hline
\end{tabular}
\end{center}
\end{table}



\section{Conclusion}\label{sec:conclusion}

We propose a Koopman-Hopf method in order to approximate Hamilton-Jacobi Reachability in high-dimensional, nonlinear systems. Although preliminary, we find this approach works well for approximating BRS's and driving high-dimensional, nonlinear systems with bounded disturbance. We hope to extend this work along several exciting directions, including expansion to more complicated lifting functions such as Radial Basis Functions and Neural Networks, applying this to black box systems, and quantifying the uncertainty based on the Koopman linearization error. We believe that the proposed method will ultimately become valuable for robustly maneuvering a wide range of otherwise intractable systems.

\section*{Acknowledgements}

We thank Steven Brunton, Stanley Bak and Masih Haseli for discussions about Koopman theory, Gary Hewer and Matthew Kirchner for discussions about applying Hopf to Naval applications, and Somil Bansal for thought-provoking discussions. Finally, we thank Zheng Gong and Sander Tonkens for valuable feedback on the paper.


\bibliographystyle{IEEEtran}
\bibliography{main}
\end{document}







