\subsection{Dynamic Graphs}\label{sec:dynamic graphs}

We now show that our method can also be applied to certain dynamic graph settings, that is, when the network structure may be different in each round. While it is generally agreed upon that dynamic problem settings are highly relevant for practical applications, it is still not so clear what is a good theoretical model for dynamicity. For rumor spreading problems, the only work regarding dynamic graphs~\cite{ClementiCDFPS16} considers the two models (i) that in each round independently the network is a $G(n,p)$ random graph and (ii)~that each possible edge has its own independent two-state Markov chain describing how it changes between being present and not (edge-Markovian dynamic graphs). For both models, it is proven that the push protocol informs all nodes in logarithmic time with high probability (when the parameters are chosen reasonably).

It is clear that the edge-Markovian model due to the time-dependence cannot be analyzed with our methods. For the other result, we now show that our method quite easily gives a very precise analysis. We only treat the case of $\Theta(1/n)$ edge probabilities, as this seems to be the most interesting one (the graph is not connected, but has nodes with degrees varying between $0$ and $\Theta(\log(n)/\log\log(n))$; when $p \ge (1+\eps)/n$, a giant component encompassing a linear number of nodes exists). 

To make the model precise, we assume that in each round independently, before the communication starts, the communication graph is sampled as $G(n,p)$ random graph, where $p = a/n$ for some positive constant $a$. That is, between any two nodes there is an edge, independently, with probability $a/n$. In the communication part of the round, each informed node chooses a communication partner uniformly at random from its neighbors in the communication graph and sends a copy of the rumor to it. Isolated informed nodes, naturally, do not communicate in this round.

%
%
%In this section we consider the rumor spreading on the dynamic Erd\H{o}s-R\'enyi Graph $G(n,p)$ where $p = \tfrac{a}{n}$ for some constant $a$.
%Before each round we resample the graph and though we ensure the property of the symmetry which is critical in our analysis.
%The choice of $p = \tfrac an$ is caused by the fact that for each node there is a finite probability to have no neighbors in current round, so the behavior of the protocol is significantly different from the classic rumor spreading on the complete graph.

%\subsubsection*{Push Protocol}
%
%\begin{lemma}\label{lem:Erdos-Renyi-call-prob}
%    Consider one round of Erdos-Renyi push protocol.
%    Let $E$ be the set of edges of the communication graph.
%    Then we have
%    \[
%        \Pr[y \to x | xy \in E] = \tfrac{1-e^{-a}}{a} + O\left(\tfrac1n\right).
%    \]
%\end{lemma}
%\begin{proof}
%    The probability that $y$ calls $x$ is equal to $\tfrac1{\deg y}$.
%    Since we know that $xy \in E$, then $\deg y - 1$ has the binomial distribution with parameters $n-1$ and $p=\tfrac{a}{n}$.
%    Therefore,
%    \begin{align*}
%        \Pr[y \to x | xy \in E]
%        & = \sum_{i=0}^{n-1} \tfrac1{i+1} \cdot \Pr[\deg y=i+1|xy \in E] \\
%        & = \sum_{i=0}^{n-1} \tfrac1{i+1} \cdot {n-1\choose i} \cdot \left(\tfrac{a}{n}\right)^i \cdot \left(1-\tfrac{a}{n}\right)^{n-i-1} \\
%        & = \tfrac1a \sum_{i=0}^{n-1} \tfrac{a^{i+1}}{(i+1)!} \cdot \left(1-\tfrac1n\right) \cdot \ldots \left(1-\tfrac{i}{n}\right) \\
%        & = \tfrac{1-e^{-a}}{a} + O\left(\tfrac1n\right).
%    \end{align*}
%\end{proof}
%
%\begin{observation}\label{obs:Erdos-Renyi-call-prob-w/o-triangles}
%	For any set of nodes $\{x_1, \ldots, x_\ell\}$ not containing $x$ we have
%    \[
%        \Pr[y \to x | xy \in E, \{x_1y, \ldots, x_\ell y\} \cap E = \emptyset]
%        \ge \Pr[y \to x | xy \in E].
%    \]
%\end{observation}
%
%\begin{lemma}\label{lem:Erdos-Renyi-push-pk}
%    Consider one round of Erdos-Renyi push protocol started with $k$ informed nodes.
%    The probability that an uninformed node $x$ is called (i.e., informed) is equal to
%    $\tfrac{k}{n} \cdot \left(1-e^{-a} + O\left(\tfrac1n\right)\right).$
%\end{lemma}
%%\begin{proof}[this proof contains a mistake \ldots]
%%    By union bound, the probability that node $x$ is called is at most
%%    \[
%%        k \cdot \Pr[y \to x | xy \in E] \cdot \tfrac1n = \tfrac{k}{n} \cdot \left(1-e^{-a}+ O\left(\tfrac1n\right)\right).
%%    \]
%%
%%	Suppose that $x$ does not belong to any cycle of length 3, i.e., all neighbors of $x$ do not have common edges.
%%	Consequently the degrees of all neighbors of $x$ are independent.
%%    Observe that for any set of nodes $\{x_1, \ldots, x_\ell\}$ not containing $x$ we have
%%    \[
%%        \Pr[y \to x | xy \in E, \{x_1y, \ldots, x_\ell y\} \cap E = \emptyset]
%%        \ge \Pr[y \to x | xy \in E].
%%    \]
%%    Since the probability that there is no cycle of length 3 containing $x$, we have
%%    Let us consider all edges in $E$ which are adjacent to $x$ or to neighbors of $x$.
%%    Such subgraph is a tree if
%%    By union bound we can show that the corresponding probability is at least $1-O\left(\tfrac1n\right)$.
%%    Let nodes $y_1, \ldots, y_k$ are informed.
%%    Therefore,
%%    \begin{align*}
%%    	\Pr[X=1]
%%    	& = \E[X] = \E[X|x \notin \text{cycles of len. 3}] \cdot \left(1-O\left(\tfrac1n\right)\right) \\
%%    	& = \left(1-O\left(\tfrac1n\right)\right)
%%    		\cdot \E\left[1-\left(1-\Pr[y\to x|xy \in E, x \notin \text{cycles of len. 3}]\right)^{\deg x}\right] \\
%%    	& \ge \left(1-O\left(\tfrac1n\right)\right)
%%    		\cdot \E\left[1-\left(1-\Pr[y\to x|xy \in E]\right)^{\deg x}\right].
%%    \end{align*}
%%    Clearly, $\deg x = X_1 + \ldots + X_k$, where $X_i$ is the random indicator variable for an event ``$xy_i \in E$''.
%%    Therefore, the probability that node $x$ is called is at least
%%    \begin{align*}
%%    	\left(1-O\left(\tfrac1n\right)\right)
%%    		\cdot \left(1 - \prod_{i=1}^k\E\left[\left(1-\Pr[y\to x|xy \in \E]\right)^{X_i}\right]\right).
%%    \end{align*}
%%    Since by Lemma~\ref{lem:Erdos-Renyi-call-prob} we have $\E\left[\left(1-\Pr[y\to x|xy \in E]\right)^{X_i}\right]
%%    	= 1 - \tfrac{1-e^{-a}}{n} + O\left(\tfrac1{n^2}\right)$, we compute
%%    \begin{align*}
%%    	\Pr[X=1]
%%    	& \ge \left(1-O\left(\tfrac1n\right)\right)
%%    		\cdot \left(1 - \left(1-\tfrac{1-e^{-a}}{n}+O\left(\tfrac1{n^2}\right)\right)^k\right) \\
%%    	& = \left(1-O\left(\tfrac1n\right)\right)
%%    		\cdot \left( 1 - \left(1-\tfrac{k}{n}\left(1-e^{-a}\right)\right)
%%    			+ O\left(\tfrac{k}{n^2}\right)\right) \\
%%    	& = \tfrac{k}{n} \cdot \left(1-e^{-a} + O\left(\tfrac1n\right)\right).
%%    \end{align*}
%%\end{proof}
%
%\begin{proof}
%    By the union bound and Lemma~\ref{lem:Erdos-Renyi-call-prob} we have
%    \[
%    	\Pr[X=1] \le k \Pr[xy \in E] \cdot \Pr[x \leftarrow y | xy \in E]
%    	\le \tfrac{k}{n}\left(1-e^{-a}\right) + k\cdot O\left(\tfrac1{n^2}\right).
%    \]
%    
%    Although the degrees of nodes in the Erdos-Renyi graph are not independent, we can consider the informed neighbors of $x$ independently if we suppose that there is no edges between all such neighbors.
%    Formally, let event $A$ be ``there is no cycle of length 3 in graph $G$ formed by $x$ and 2 informed nodes''.
%    Clearly, $\Pr[A] \ge 1 - k^2 \cdot \tfrac{a^3}{n^3}$.
%    Therefore,
%    \begin{equation}
%    	\Pr[X=1] = 1 - \Pr[X=0]
%    	\ge 1 - \Pr[\NOT A] - \Pr[X=0 \AND A]
%    	\ge 1 - k^2 \cdot \tfrac{a^3}{n^3} - \Pr[X=0 \AND A]. \label{eq:Erdos-Renyi-eq1}
%    \end{equation}
%    Suppose that $\deg_{inf} x = \ell$.
%    If we condition on $A$, informed neighbors $\{y_1, \ldots, y_\ell\}$ of $x$ have no common edges.
%    Thus the events $\Pr[x \leftarrow y_i | xy_i \in E; A]$ for $i = 1,\ldots,\ell$ are independent.
%    Using Observation~\ref{obs:Erdos-Renyi-call-prob-w/o-triangles}, we estimate
%    \begin{align}
%    	\Pr[X=0 \AND A]
%    	& \le \sum_{\ell=0}^k \Pr[\deg_{inf} x = \ell]
%    		\cdot \Pr[X=0 | \deg_{inf} x = \ell \AND A] \notag\\
%    	& \le \sum_{\ell=0}^k \tbinom{k}{\ell} \left(\tfrac{a}{n}\right)^\ell \left(1-\tfrac{a}{n}\right)^{k-\ell} \cdot (1-p_0)^\ell \notag\\
%    	& = \left(1-\tfrac{a}{n}p_0\right)^{k}
%    		= \left(1-\tfrac1{n}\left(1-e^{-a}\right)+O\left(\tfrac1{n^2}\right)\right)^k.
%    		\label{eq:Erdos-Renyi-eq2}
%    \end{align}
%    %Therefore, $\Pr[X=1] \ge 1 - k^2\tfrac{a^3}{n^3} - \left(1-\tfrac1{n}\left(1-e^{-a}\right)+O\left(\tfrac1{n^2}\right)\right)^k$.
%    Substituting in~\eqref{eq:Erdos-Renyi-eq1} $\Pr[X=0 \AND A]$ by its bound from~\eqref{eq:Erdos-Renyi-eq2}, it is easy to see that there exists $f \in ]0,1[$ such that for any $k < fn$ we have $\Pr[X=1] \ge \tfrac{k}{n}\left(1-e^{-a}\right) + k\cdot O\left(\tfrac1{n^2}\right)$.
%\end{proof}
%
%%\begin{observation}
%%    $\sum_{\ell=0}^k {k\choose\ell} (pq)^\ell(1-p)^{k-\ell} = (1-p(1-q))^k$.
%%\end{observation}
%
%\subsection*{Covariance (briefly)}
%Suppose nodes $x$ and $y$ are uninformed.
%Denote by $X$ (resp. $Y$) the random indicator variables for the events $x$ (resp. $y$) gets informed in current round.
%To ease the notation, we will denote the corresponding positive events by the same capital letters.
%In addition we introduce the event $close$: $\dist(x,y) \le 3$ and the complementary event $far$: $\dist(x,y) \ge 4$.
%
%\begin{lemma*}
%	$\Cov[X,Y] \le \Pr[close] \cdot \Pr[X] = \Pr[close] \cdot \Pr[Y]$.
%\end{lemma*}
%\begin{proof}
%	Since $X$ and $Y$ are random indicator variables, we have
%	$$\Cov[X,Y] \le \Pr[X \AND Y] - \Pr[X]\cdot\Pr[Y].$$
%	Then we cut the probability space according to events $far/close$ as follows.
%	$$\Pr[X \AND Y] = \Pr[close]\cdot\Pr[X \AND Y|close] + \Pr[far]\cdot\Pr[X \AND Y|far].$$
%	First, we note that $\Pr[X \AND Y|close] \le \Pr[X|close] \le \Pr[X]$.
%	The last inequality follows from the observation that the event $close$ privileges some potentially successful calls to go to $Y$ instead of $Y$.
%	
%	Second, one can see that $\Pr[far] \le 1$ and $\Pr[X \AND Y|far] \le \Pr[X]\cdot\Pr[Y]$, since 
%\end{proof}



%\subsubsection{Push Protocol}
%\subsubsection{Push Protocol}
%\subsubsection{Push Protocol}
%\begin{itemize}
%	\item we define $p_0 := \Pr[x \leftarrow y | xy \in E]$
%	\item Lem. $p_0 = \tfrac{1-e^{-a}}{a} + O\left(\tfrac1n\right)$
%	\item Obs. $p_0 \le \Pr[x \leftarrow y | xy \in E, \{x_1y, \ldots, x_\ell y\} \cap E = \emptyset]$
%	\item Th. $\Pr[int \to x] \sim \left(1-\tfrac{a}{n}p_0\right)^k$ ($k$ nodes informed)
%	\item Cor. exp shrinking
%	\item Cor. exp growth
%	\item $T = \ldots$
%\end{itemize}


We introduce the following notation. We consider one round and aim at showing the exponential growth and shrinking conditions. Let $E$ be the set of edges of the communication graph $G(n,\tfrac an)$ of this round. We write $xy \in E$ as shorthand for $\{x,y\} \in E$. We write $x \to y$ to denote the event that $x$ calls $y$. By $\deg_{\inf} x$ we denote the number of informed neighbors of $x$.


%In addition, we write $inf \to x$ if $x$ is called by at least one informed node.
%Similarly, $x \to inf$ means that $x$ calls an informed node.

%Consider uninformed node $x$ and informed node $y$.
%Suppose that $xy \in E$.
%Let us study the probablity $p_0 := \Pr[y \to x \mid xy \in E]$.
%The following observation follows from the definition of $p_0$.

%\begin{lemma}\label{lem:Erdos-Renyi-call-prob}
%    \[
%        p_0 = \tfrac{1-e^{-a}}{a} + O\left(\tfrac1n\right).
%    \]
%\end{lemma}
%\begin{proof}
%    The probability that $y$ calls $x$ is equal to $\tfrac1{\deg y}$.
%    Since we know that $xy \in E$, then $\deg y - 1$ has the binomial distribution with parameters $n-1$ and $p=\tfrac{a}{n}$.
%    Therefore,
%    \begin{align*}
%        \Pr[y \to x | xy \in E]
%        & = \sum_{i=0}^{n-1} \tfrac1{i+1} \cdot \Pr[\deg y=i+1|xy \in E] \\
%        & = \sum_{i=0}^{n-1} \tfrac1{i+1} \cdot {n-1\choose i} \cdot \left(\tfrac{a}{n}\right)^i \cdot \left(1-\tfrac{a}{n}\right)^{n-i-1} \\
%        & = \tfrac1a \sum_{i=0}^{n-1} \tfrac{a^{i+1}}{(i+1)!} \cdot \left(1-\tfrac1n\right) \cdot \ldots \left(1-\tfrac{i}{n}\right) \\
%        & = \tfrac{1-e^{-a}}{a} + O\left(\tfrac1n\right).
%    \end{align*}
%\end{proof}
%\begin{observation}\label{obs:Erdos-Renyi-call-prob-w/o-triangles}
%	For any set of nodes $\{x_1, \ldots, x_\ell\}$ not containing $x$ we have
%    \[
%        \Pr[y \to x | xy \in E, \{x_1y, \ldots, x_\ell y\} \cap E = \emptyset]
%        \ge \Pr[y \to x | xy \in E].
%    \]
%\end{observation}
%\merk{this lemma replaces previous one\ldots}
\begin{lemma}\label{lemma: Erdos-Renyi - call probability}
	Consider an uninformed node $x$ and an informed node $y$.
	Let $\ell \le n/2$ and let $A_\ell$ be the event that $\{y_1y, \ldots, y_\ell y\} \cap E = \emptyset$.
	Then
	$$\Pr[y \to x \mid xy \in E \AND A_\ell] = \tfrac{1-e^{-a}}{a} + (\ell+1) \cdot O\left(\tfrac1n\right).$$
\end{lemma}
\begin{proof}
    Assume that $xy \in E$. Then the number of other neighbors of $y$, that is,  the random variable $\deg y - 1$, has a binomial distribution with parameters $n-2-\ell$ and $\tfrac{a}{n}$.
    The probability that $y$ calls $x$ is equal to $\tfrac1{\deg y}$.
	Using the fact that $\binom{m+1}{k+1} = \tfrac{k+1}{m+1} \binom{m}{k}$, we compute
	\begin{align*}
		\Pr[y \to x & \mid xy \in E \AND A_\ell]
		= \sum_{i=0}^{n-2-\ell} \tfrac1{i+1} \binom{n-2-\ell}{i} \left(\tfrac an\right)^i \left(1-\tfrac an\right)^{n-2-\ell-i} \\
		& = \tfrac na \cdot \tfrac1{n-2-\ell+1}
			\cdot \sum_{i=0}^{n-2-\ell} \binom{n-2-\ell+1}{i+1} \left(\tfrac an\right)^{i+1} \left(1-\tfrac an\right)^{n-2-\ell+1-(i+1)} \\
		& = \tfrac1a \cdot \left(1-\tfrac{\ell+1}{n-\ell-1}\right)
			\cdot \left(1 - \Pr[\Bin(n-2-\ell+1,\tfrac an)=0]\right) \\
		& = \tfrac1a \cdot \left(1-\tfrac{\ell+1}{n-\ell-1}\right)
			\cdot \left(1 - \left(1-\tfrac an\right)^{n-\ell-1}\right) \\
		& = \tfrac{1-e^{-a}}{a} + (\ell+1) \cdot O\left(\tfrac 1n\right),
	\end{align*}
	where above we denoted by $\Bin(m,p)$ a random variable having a binomial distribution with parameters $m$ and $p$.
\end{proof}


\begin{lemma} \label{lemma: Erdos-Renyi - growth and shrinking}
	Consider one round starting with $k<n$ informed nodes.
	The probability $1-p_k$ that an uninformed node $x$ stays uninformed in this round is at most
	$(1 - \tfrac{1-e^{-a}}{n})^k + k \cdot O(\tfrac1{n^2})$.
\end{lemma}

\begin{proof}
	Let $A$ be the event that $G\left(n,\tfrac an\right)$ contains no triangle formed by $x$ and two other informed nodes.
	By the first moment method, $\Pr[A] \ge 1 - k^2\cdot\tfrac{a^3}{n^3}$. Let $X$ be the indicator random variable for the event that $x$ is called by an informed node. Then
	\begin{align*}
		\Pr[X=0] \le \Pr[\NOT A] + \Pr[X=0 \AND A] \le k^2\tfrac{a^3}{n^3} + \Pr[X=0 \AND A].
	\end{align*}
	We compute $\Pr[X=0 \AND A]$ by conditioning on $\deg_{\inf} x$, which has a binomial distribution with parameters $k$ and $\tfrac an$.
	In addition, we observe that the conditioning on $A$ makes the actions of the informed neighbors of $x$ independent (in the probability space composed of the random actions of the nodes and the not yet determined random edges). Hence
	\[
		\Pr[X=0 \mid \deg_{\inf}x = \ell \AND A]
		= \left(1-\Pr[y \to x \mid xy \in E \AND A_{\ell-1}]\right)^\ell
		\le \left(1-\tfrac{1-e^{-a}}{a} + O\left(\tfrac1n\right)\right)^\ell
	\]
	by Lemma~\ref{lemma: Erdos-Renyi - call probability}.
%	The last inequality follows from the fact that in the construction of $A_{\ell-1}$, $\{y_1, \ldots, y_{\ell-1}\}$ are the other neighbors of $x$.
%	event $A \AND \deg_{\inf} x = \ell$ is nothing but $A_\ell$ introduced in Lemma~\ref{lemma: Erdos-Renyi - call probability}.
%	Then $\Pr[X=0 \mid A_l] \le \left(\Pr[y \to x \mid A_\ell]\right)^k$
%	Then, using Lemma~\ref{lemma: Erdos-Renyi - call probability}, w
We compute.
	\begin{align*}
		\Pr[X=0 \AND A]
		& = \sum_{\ell=0}^k \Pr[\deg_{inf} x = \ell] \cdot \Pr[A \mid \deg_{inf} x = \ell] \cdot \Pr[X=0 \mid \deg_{\inf}x = \ell \AND A] \\
		& \le \sum_{\ell=0}^k \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell}
			\cdot 1 %\left(1-\tfrac an\right)^{\ell^2}
			\cdot \left(1-\tfrac{1-e^{-a}}{a} + O\left(\tfrac1n\right)\right)^\ell \\
		& \le \left[\tfrac an\left(1-\tfrac{1-e^{-a}}{a} + O\left(\tfrac1n\right)\right)
			+ 1 - \tfrac an\right]^k \\
		& = \left(1 - \tfrac{1-e^{-a}}{n}\right)^k + k \cdot O\left(\tfrac1{n^2}\right).
	\end{align*}
%	$\deg_{\inf} x$ which has a binomial distribution with parameters $k$ and $\tfrac an$.
%	
%	\merk{---------------------}
%	
%	Clearly, $\Pr[X=0] \ge \Pr[X=0 \AND A]$.
%	Therefore,
%	\begin{align*}
%		\Pr[x=0 \AND A] = \sum_{\ell=0}^k \Pr[\deg_{inf} x = \ell] \cdot \Pr[A | \deg_{inf} x = \ell] \cdot \Pr[X=0 | \deg_{inf} x = \ell \AND A] \\
%		\ge \sum_{\ell=0}^k \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell} \cdot \left(1-\tfrac an\right)^{\ell^2} \left(1-p(\ell)\right)^\ell \\
%		= \sum_{\ell=0}^k \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell} \cdot \left(1-\tfrac an\right)^{\ell^2} \left(1-p_0\right)^\ell \left(1 + \ell^2O\left(\tfrac1n\right)\right).
%	\end{align*}
\end{proof}

\begin{lemma} \label{lemma: Erdos-Renyi - growth}
	Consider one round starting with $k < n$ informed nodes. The probability $p_k$ that an uninformed node $x$ becomes informed in the current round is at most
	$\tfrac kn \cdot \left(1-e^{-a} + O\left(\tfrac1n\right)\right)$.
\end{lemma}
\begin{proof}
	Consider an uninformed node $x$ and an informed node $y$.
	Applying Lemma~\ref{lemma: Erdos-Renyi - call probability} with $\ell = 0$, we compute
	\[
		\Pr[y \to x] = \Pr[xy \in E] \cdot \Pr[y \to x \mid xy \in E]
		= \tfrac an \cdot \left(\tfrac{1-e^{-a}}{a} + O\left(\tfrac1n\right)\right).
	\]
	A union bound over the $k$ informed nodes proves the claim.
\end{proof}

\begin{lemma}\label{lemma: Erdos-Renyi - shrinking}
%	Let $g \in ]0,1[$.
	Consider one round starting with $k = \Omega(n)$ informed nodes.
	The probability $1-p_k$ that an uninformed node $x$ stays uninformed in current round is at least
	$\left(1 - \tfrac{1-e^{-a}}{n}\right)^k - O\left(\tfrac{\log^2 n}{n}\right)$.
\end{lemma}
\begin{proof}
	Let again $A$ denote the event that $G\left(n,\tfrac an\right)$ contains no cycle of length 3 formed by $x$ and two other informed nodes, and let $X$ be the indicator random variable for the event that $x$ becomes informed.
	Then $\Pr[X=0] \ge \Pr[X=0 \AND A]$.
	Similar to the proof of Lemma~\ref{lemma: Erdos-Renyi - growth and shrinking}, we compute $\Pr[X=0]$ by conditioning on the number $\deg_{\inf} x$ of its informed neighbors.
	\begin{align*}
		\Pr[X=0 \AND A]
		& = \sum_{\ell=0}^k \Pr[\deg_{\inf} x = \ell]
			\cdot \Pr[A \mid \deg_{\inf} x = \ell] \cdot \Pr[X=0 \mid \deg_{\inf}x =\ell \AND A] \\
		& = \sum_{\ell=0}^{k} \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell}
			\cdot \left(1-\tfrac an\right)^{\ell^2}
			\cdot \left(1 - \tfrac{1-e^{-a}}{a} - (\ell+1) \cdot O\left(\tfrac 1n\right)\right)^\ell
	\end{align*}
	To simplify the notation, we denote
	$x_\ell := \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell}$ and $q := 1 - \tfrac{1-e^{-a}}{a}$.
%	Since $k = \Theta(n)$, we bound $\sum_{\ell=0}^k$ by $\sum_{\ell=0}^{c\log n}$ for some constant $c > 0$.
	Then
		\begin{align*}
		\Pr[X=0 \AND A]
		& \ge \sum_{\ell=0}^{c\log n} x_\ell
			\cdot \left(1-\tfrac an\right)^{\ell^2}
			\cdot \left(q - \ell \cdot O\left(\tfrac 1n\right)\right)^\ell \\
		& \ge \sum_{\ell=0}^{c\log n} x_\ell \cdot \left(1-\tfrac an\right)^{c^2\log^2n} \left(q-O\left(\tfrac{\log n}{n}\right)\right)^\ell \\
%		& \ge \sum_{\ell=0}^{c\log n} \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell} \cdot \left(1-a\tfrac{c^2\log^2n}{n}\right) (1-p_0)^\ell \left(1-\tfrac{c^2\log^2n}{n}\right) \\
		& \ge \left(1-O\left(\tfrac{\log^2n}{n}\right)\right)\sum_{\ell=0}^{c\log n} x_\ell q^\ell.
	\end{align*}
%	\begin{align*}
%		\Pr[X=0]
%		& \ge \sum_{\ell=0}^{c\log n} \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell}
%			\cdot \left(1-\tfrac an\right)^{\ell^2}
%			\cdot \left(1 - \tfrac{1-e^{-a}}{a} - \ell \cdot O\left(\tfrac 1n\right)\right)^\ell \\
%		& \ge \sum_{\ell=0}^{c\log n} \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell} \cdot \left(1-\tfrac an\right)^{c^2\log^2n} \left(1-p_0-\tfrac{c\log n}{n}\right)^\ell \\
%		& \ge \sum_{\ell=0}^{c\log n} \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell} \cdot \left(1-a\tfrac{c^2\log^2n}{n}\right) (1-p_0)^\ell \left(1-\tfrac{c^2\log^2n}{n}\right) \\
%		& \ge \sum_{\ell=0}^{c\log n} \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell} (1-p_0)^\ell \\
%		& \qquad + O\left(\tfrac{\log^2n}{n}\right) \sum_{\ell=0}^{c\log n} \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell} (1-p_0)^\ell
%	\end{align*}
	By Lemma~\ref{lemma: log degree}, there exists $c > 0$ such that $\sum_{\ell=c\log n}^{k} x_\ell q^\ell \le \tfrac1n$.
%	\[
%		\sum_{\ell=c\log n}^{k} x_\ell q^\ell
%		\le \sum_{\ell=c\log n}^{k} \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell} (1-p_0)^\ell \le \tfrac1n.
%	\]
	Since $\sum_{\ell=0}^{k} x_\ell q^\ell = \left(1-\tfrac{1-e^{-a}}{n}\right)^k$, we have 
	\begin{align*}
		\Pr[X=0 \AND A] \ge \left(1-O\left(\tfrac{\log^2n}{n}\right)\right) \left(1-\tfrac{1-e^{-a}}{n}\right)^k.
	\end{align*}
%	\[
%		\sum_{\ell=0}^{c\log n} \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell} (1-p_0)^\ell \ge \sum_{\ell=0}^{k} \binom kl \left(\tfrac an\right)^\ell \left(1-\tfrac an\right)^{k-\ell} (1-p_0)^\ell - \tfrac1n.
%	\]
%	Using this bound we obtain that 
%	\begin{align*}
%		\Pr[X=0] \ge \left(1-\tfrac{1-e^{-a}}{n}\right)^k - O\left(\tfrac{\log^2 n}{n}\right).
%	\end{align*}
\end{proof}

\begin{lemma} \label{lemma: Erdos-Renyi - covariance}
	Consider a round starting with $k$ informed nodes. Let $x_1$ and $x_2$ be two uninformed nodes.
	Then the corresponding random indicator variables $X_1$ and $X_2$ for the events of these becoming informed are negatively correlated.
\end{lemma}
\begin{proof}
	By symmetry, we can assume that in this round we first generate the random communication graph, then we let each node choose a potential communication partner (uniformly among its neighbors), and then we decide randomly which $k$ nodes are informed, and finally those nodes which are informed actually call the potential partner chosen before. In this joint probability space, let $x_1$ and $x_2$ be two nodes. We condition in the following on (i) the outcome of the random graph, (ii) the outcome of the potential communication partners, and (iii) $x_1$ and $x_2$ being uninformed. In other words, all randomness is already decided except which set $I$ of $k$ nodes different from $x_1$ and $x_2$ is informed. 

	Let $S_1$ and $S_2$ be the sets of nodes having chosen $x_1$ and $x_2$ as potential partner. Now we have $X_1=1$ if and only if $S_1 \cap I \ne \emptyset$.	Similarly, $X_2 = 1$ is equivalent to $S_2 \cap I \ne \emptyset$.
	Since $S_1 \cap S_2 = \emptyset$ by construction, $X_1$ and $X_2$ are negatively correlated.
\end{proof}

\begin{theorem}
	The expected rumor spreading time is $\log_{2-e^{-a}}n + \tfrac1{1-e^{-a}}\ln n \pm O(1)$.
	In addition, there are constant $A' \alpha' > 0$ such that for any $r \in \N$ we have $\Pr[|T - \E[T]| \ge r] \le A' e^{-\alpha' r}$.
\end{theorem}
\begin{proof}
	By Lemma~\ref{lemma: Erdos-Renyi - covariance}, the covariance conditions are satisfied for both exponential growth and exponential shrinking.

	From Lemma~\ref{lemma: Erdos-Renyi - growth and shrinking} together with Corollary~\ref{cor:prelim:(1-p/n)^k} it follows that for any $k < n$ we have
	$$p_k \ge \tfrac kn \left(1-e^{-a}\right) - \tfrac{k^2}{2n^2}\left(1-e^{-a}\right)^2 - k\cdot O\left(\tfrac1{n^2}\right).$$
	Combining this with Lemma~\ref{lemma: Erdos-Renyi - growth}, we see that the process satisfies the exponential growth conditions with $\gamma_n = 1-e^{-a}$ in interval $[1,fn]$ for any constant $0 < f < 1$.
    
    For $k = \Theta(n)$, Lemma~\ref{lemma: Erdos-Renyi - growth and shrinking} and Lemma~\ref{lemma: Erdos-Renyi - shrinking} yield that
    \[
    	\left(1 - \tfrac{1-e^{-a}}{n}\right)^k - O\left(\tfrac{\log^2 n}{n}\right)
    	\le 1-p_k
    	\le \left(1 - \tfrac{1-e^{-a}}{n}\right)^k + k \cdot O\left(\tfrac1{n^2}\right).
    \]
    Substituting $k$ by $n-u$ and applying Corollary~\ref{cor:prelim:(1-p/n)^(n-u)}, we obtain for any $u < n$ that
    \[
    	\exp\left(-1+e^{-a}\right) - O\left(\tfrac{\log^2 n}{n}\right)
    	\le 1-p_{n-u}
    	\le \exp\left(-1+e^{-a}\right) \left(1 + 2\left(1-e^{-a}\right)\tfrac un\right) + O\left(\tfrac1n\right).
    \]
    Therefore, the protocol satisfies the upper exponential shrinking conditions with $\rho_n = 1-e^{-a}$ and the lower exponential shrinking conditions with $\rho_n = 1-e^{-a} + O\left(\tfrac{\log^2n}{n}\right)$ in the interval $[n-gn,n]$ for any $0 < g < 1$.

	Since the intervals of exponential growth and exponential shrinking overlap, it follows from Theorems~\ref{th:exp-growth-upper},~\ref{th:exp-growth-lower},~\ref{th:exp-shrinking-upper},~and~\ref{th:exp-shrinking-lower} that the expected spreading time $\E[T]$ is equal to $\log_{1-e^{-a}}n + \tfrac1{1-e^{-a}}\ln n \pm O(1)$ and $\Pr[|T-\E[T]| \ge r] \le A' e^{-\alpha' r}$ for suitable constants $A', \alpha' > 0$.
\end{proof}

%\subsubsection{Pull Protocol}
%\subsubsection*{Push-Pull Protocol}
%
%Idea. The goal is to estimate the probability that node $x$ gets informed simultaneously by push and pull call.
%The naive way to model such situation is the following.
%\begin{enumerate}
%	\item Create the random graph.
%	\item If $\deg x > 0$, make the pull call.
%	\item Modelize the push calls of all informed neighbors of $x$.
%\end{enumerate}
%In this case "the destiny" of $x$'s pull call depends on the ratio between number of informed and uninformed neighbors of $x$.
%Such object is very hard to calculate.
%Hence we will study the following model which seems to be equivalent.
%
%\begin{enumerate}
%	\item Throw a coin w.p. $1-\left(1-\tfrac an\right)^{n-1}$, i.e., probability that $\deg x > 0$.
%		Continue only if we won.
%	\item
%		Make an $x$'s pull call uniformly at random. And add the corresponding edge to the graph.
%	\item
%		Fill the remaining graph.
%	\item
%		Modelize the push calls of all informed neighbors of $x$.
%\end{enumerate}
%In such model it is relatively easy to compute the conditional probability such as $\Pr[push|pull]$.