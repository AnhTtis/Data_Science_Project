%-----------------------------------------------------------------------------------
%-----------------      Exponential Shrinking Regime. Upper Bound       -----------------------
%-----------------------------------------------------------------------------------

\subsection{Exponential Shrinking Regime. Upper Bound}

We now regard the regime that at most $gn$, $g$ a small constant, nodes are not informed, and that in each round each of these nodes has an approximately constant chance of becoming informed. From a very distant point of view, this part of the process vaguely resembles the exponential growth regime with time running backwards, but the details are too different to simply transfer our previous results to this setting.

We start in this section with the upper bound on the runtime. Throughout this section, we assume that our homogeneous epidemic protocol satisfies the following \emph{upper exponential shrinking conditions} including the covariance condition.

\begin{defn}[upper exponential shrinking conditions] \label{def:upper-exp-shrinking-conditions}
    Let $\rho_n$ be bounded between two positive constants.
	Let $0 < g < 1$ and $a, c \in \R_{\ge0}$ such that $e^{-{\rho_n}} + ag < 1$.
	We say that a homogeneous epidemic protocol satisfies \emph{the upper exponential shrinking conditions} if for any $n \in \N$ big enough, the following properties are satisfied, for all $u = n-k \le gn$.
	\renewcommand{\theenumi}{(\roman{enumi})}%
	\begin{enumerate}
		\item
			$1-p_k = 1-p_{n-u} \le e^{-{\rho_n}} + a\frac{u}{n}$;
		\item
			$c_k = c_{n-u} \le \frac{c}{u}$.
	\end{enumerate}
\end{defn}
Let us note that in this section we study the number of uninformed nodes $u := n-k$ instead of $k$, i.e., the number of informed ones.
We will show that $u$ shrinks by almost a constant factor each round.
So the main result of the section is the following theorem.

\begin{theorem}[upper bound for spreading time] \label{th:exp-shrinking-upper}
	Consider a homogeneous epidemic protocol satisfying the upper exponential shrinking conditions.
  Then there are constant $A', \alpha' > 0$ such that
	\begin{eqnarray*}
		&& \Expect[T(n-\lfloor g n \rfloor, n)] \le \tfrac1{\rho_n}\ln n + O(1), \\
		&& \Pr[T(n-\lfloor g n \rfloor, n) > \tfrac1{\rho_n}\ln n + r] \le A' e^{-\alpha r}\,
			\mbox{ for all $r \in \N$}.
	\end{eqnarray*}
\end{theorem}

We first note that the upper exponential shrinking conditions imply that nodes remain uninformed with at most a constant probability. Hence Lemma~\ref{lem:general-connect} shows that we reach any constant fraction of uninformed nodes in expected constant time. For this reason, we may conveniently assume that \emph{$g$ is an arbitrarily small constant} in the following. We shall also always assume that \emph{$n$ is large enough}.

The proof below follows the general principle established in this work, that is, we define for each number $u$ of uninformed nodes a suitable target $E_0(u)$ such that with sufficiently high probability $1-q(u)$ (following from the covariance condition and Chebyshev's inequality), one round started with at most $u$ uninformed nodes ends with at most $E_0(u)$ uninformed nodes. The choice of $E_0(u)$ is such that the sequence $u_0 = gn, u_1 = E_0(u_0), u_2 = E_0(u_1), \dots$ within $J = \frac 1{\rho_n} \ln(n) + O(1)$ steps reaches a constant $u_J$ and such that failure probabilities $q(u_i)$, $i = 0, \dots, J-1$, imply that only an expected constant number of rounds in addition to $J$ are needed to reach at most $u_J$ nodes. For the constant number of  $u_J$ or less remaining uninformed nodes, we use the simple waiting time argument that each of them needs an expected constant number of rounds to be informed, adding another constant number of rounds to the expected spreading time.


\subsubsection{Round Targets and Failure Probabilities}

Let us introduce the random variable $Y(u)$ being equal to the number of uninformed nodes at the end of a round started with $u$ uninformed ones.
Since $\Expect[Y(u)] = u(1-p_{n-u})$, the exponential shrinking conditions imply that
\begin{equation}
	\Expect[Y(u)] \le E(u) := u\left(e^{-{\rho_n}} + a\tfrac{u}{n}\right) \notag.
\end{equation}

As before, the Lemma~\ref{lem:exp-shrinking-failure-upper} shows that with good probability, $Y(u)$ is less than the $\emph{target value}$
\begin{equation}
	E_0(u) := E(u) + A u^{1-B} \label{eq:def-E0-upper-expshr},
\end{equation}
where $A > 0$ and $0 < B < 1/2$ are some constants chosen uniformly for all values of $u$ and $n$.
In addition we will choose $g$ and $A$ small enough (relative to $g$) to ensure that for all $u \le gn$, the target value $E_0(u)$ is less than $u$ (see Lemma~\ref{lem:exp-shrinking-E0-decrease}) and that the "chain" of consequent target values forms an exponentially decreasing sequence (see Lemma~\ref{lem:exp-shrinking-expk-upper}).

\begin{lemma}\label{lem:exp-shrinking-E0-decrease}
	Assume that $g$ and $A$ are sufficiently small constants. Then for all $u \in [1,gn]$, we have $E_0(u) < u$.
\end{lemma}
\begin{proof}
	Indeed, it suffices to show that
	\begin{equation}
		\tfrac{E_0(u)}{u} = e^{-{\rho_n}} + a\tfrac{u}{n} + Au^{-B} < 1 \notag.
	\end{equation}
	Since $u \in [1, gn]$, we have
	\begin{equation}
		\tfrac{E_0(u)}{u} \le e^{-{\rho_n}} + ag + A \notag.
	\end{equation}
	Clearly there exist positive $A$ and $g$ small enough such that the expression above is less than 1.
\end{proof}

We assume in the following that $g$ and $A$ are small enough to make the assertion of the lemma above true. We compute the target failure probabilities as follows.

\begin{lemma} \label{lem:exp-shrinking-failure-upper}
	For any $1 \le u < gn$,
	\begin{equation}
		\Pr[Y(u) \ge E_0(u)] \le q(u) := \tfrac{(1+a)e^{-{\rho_n}}+c}{A^2} \cdot \tfrac1{u^{1-2B}}\notag.
	\end{equation}
\end{lemma}
\begin{proof}
	Like in the proofs of Lemma~\ref{lem:exp-growth-failure}~and~\ref{lem:exp-growth-failure-lower}, using Chebyshev's inequality and taking into account $E(u) \ge \Expect[Y(u)]$, we compute
	\begin{align}
		\Pr&[Y(u) \ge E_0(u)]
		\le \Pr\left[Y(u) \ge \Expect[Y(u)] + Au^{1-B}\right]
		\le \tfrac{\Var[Y(u)]}{(Au^{1-B})^2} \notag.
	\end{align}
	From Lemma~\ref{lem:prelim:variance} and the covariance condition it follows that
	\begin{equation}
		\Var[Y(u)] \le \Expect[Y(u)] + cu \le \E[Y(u)] + cu \notag.
	\end{equation}
	Therefore,
	\begin{align}
		\Pr[Y(u) \ge E_0(u)]
			% \le \tfrac{\Expect[Y(u)] + cu}{A^2u^{2-2B}}
			\le \tfrac{E(u) + cu}{A^2u^{2-2B}}
			\le \tfrac{(1+a)e^{-{\rho_n}}+c}{A^2} \cdot \tfrac1{u^{1-2B}} \notag.
	\end{align}
\end{proof}

%\merk{The Cantelli inequality is needed only to show that $q(u) < 1$, for any $u$. Should we use it?}
%
%One can see that for smaller values of $u$, $q(u)$ might be more than one.
%To avoid this, it suffices to replace Chebyshev's inequality by Cantelli's one.
%Then, taking into account that $q(u)$ is decreasing in $u$, we obtain the following.
%\merk{check if we do need Cantelli's inequality}
%\begin{corollary} \label{cor:exp-shrinking-error-prob}
%	$\Pr[Y(u) \ge E_0(u)] \le \min\left\{q(u), \tfrac1{1+1/q(1)}\right\}$.
%\end{corollary}

\subsubsection{The Phase Calculus}

Let us define the sequence $u_j$ recursively by
\begin{equation}
	u_0 = gn, \quad u_{j+1} := E_0(u_j) \notag.
\end{equation}
The next observation follows from the definition.

\begin{observation}\label{obs:exp-shrinking-expk-upper}
	For any $j \ge 1$ we have $u_j \ge u_0e^{-j{\rho_n}}$.
	In particular, for any $j \le \tfrac1{\rho_n} \ln n$ we have $u_j \ge \tfrac{u_0}{n}$.
\end{observation}

%\begin{lemma}\label{lem:exp-shrinking-expk-upper}
%	There exists $J \le \tfrac1{\rho_n}\ln n + O(1)$ such that
%	\begin{equation}
%		1 \le u_j \le 2u_0e^{-j{\rho_n}} \text{ for all } j < J \text{ and } u_J < 1 \notag.
%	\end{equation}
%\end{lemma}
%\merk{A: in the proof of the next lemma we need $g$ to be small. I don't now how to mention it (see the remark at the end of the proof).}
\begin{lemma}\label{lem:exp-shrinking-expk-upper}
	By choosing $A$ in~\eqref{eq:def-E0-upper-expshr} and $g$ sufficiently small, we can assume that for all $j \le \tfrac1{\rho_n} \ln n$, we have $u_j \le 2u_0 e^{-j{\rho_n}}$.
\end{lemma}
\begin{proof}
	For $j=0$, there is nothing to prove.
	Consider $1 \le j \le \tfrac1{\rho_n} \ln n$ and assume that for all $i < j$ we have $u_i \le 2u_0 e^{-i{\rho_n}}$.
	We will show that $u_j \le 2u_0e^{-j{\rho_n}}$.
%	Let us proof by induction on $j$ that if $u_{j-1} \ge 1$ and for all $i < j$, $u_i \ge \alpha a^{-j{\rho_n}}$, then $u_j \ge \alpha u_0 e^{-(j+1){\rho_n}}$.
%	(The base for $j=0$ is trivial.)
	By definition,
	\begin{align}
		u_j & = u_0 e^{-j{\rho_n}}
			\prod_{i=0}^{j-1}\left(1 + ae^{\rho_n} \tfrac{u_i}{n} + Ae^{\rho_n} u_i^{-B}\right) \notag\\
		& \le u_0 e^{-j{\rho_n}}
			\prod_{i=0}^{j-1} \exp\left(ae^{\rho_n} \tfrac{u_i}{n} + Ae^{\rho_n} u_i^{-B}\right) \notag\\
		& \le u_0 e^{-j{\rho_n}} \exp\left(\sum_{i=0}^{j-1}ae^{\rho_n} \tfrac{u_i}{n}
			+ \sum_{i=0}^{j-1}Ae^{\rho_n} u_i^{-B}\right) \label{eq:exp-shrinking-upper-eq1}.
	\end{align}
	We estimate separately the two sums.
	Since $u_i \le 2u_0 e^{-i{\rho_n}}$ for $i<j$, the first sum can be bounded by a geometric series:
	\begin{equation}
		\sum_{i=0}^{j-1}ae^{\rho_n} \tfrac{u_i}{n}
		\le \tfrac{ae^{\rho_n}}{n} \sum_{i=0}^{j-1} 2u_0e^{-i{\rho_n}}
		\le ae^{\rho_n} \cdot \tfrac{2u_0}{n} \cdot \tfrac1{1-e^{-{\rho_n}}} \notag.
	\end{equation}
	This expression is proportional to $\tfrac{u_0}{n} = g$, so by choosing $g$ small enough, we can bound it by $\tfrac{\ln2}{2}$.
	For the second sum we use Observation~\ref{obs:exp-shrinking-expk-upper} and obtain
	\begin{align}
		\sum_{i=0}^{j-1}Ae^{\rho_n} u_i^{-B}
		& \le Ae^{\rho_n} \sum_{i=0}^{j-1} u_0^{-B}e^{i{\rho_n} B}
			\le Ae^{\rho_n} u_0^{-B} \frac{e^{j{\rho_n} B}}{e^{{\rho_n} B}-1} \notag \\
		& \le Ae^{\rho_n} \left(\tfrac{n}{u_0}\right)^B \tfrac1{e^{{\rho_n} B}-1}
			\le Ae^{\rho_n} g^{-B} \tfrac1{e^{{\rho_n} B}-1} \label{eq:exp-shrinking-upper-eq42}.
	\end{align}
	By taking $A$ small enough, the result is also at most $\tfrac{\ln2}{2}$.
%	Indeed, we must only show that $u_0^{-B} e^{j{\rho_n} B}$ is at most a constant.
%	By observation above, $\tfrac{u_0}{n} \le u_{j-1}$ and by the induction hypothesis, $u_{j-1} \le 2u_0e^{-(j-1){\rho_n}}$.
%	Then $e^{j{\rho_n}} \le 2 n e^{\rho_n}$.
%	Therefore,
%	\begin{equation}
%		u_0^{-B} e^{j{\rho_n} B} \le 2^B\left(\tfrac{n}{u_0}\right)^B e^{{\rho_n} B}
%		= 2^B g^{-B} e^{{\rho_n} B} = O(1) \notag.
%	\end{equation}
	Substituting the sums in~\eqref{eq:exp-shrinking-upper-eq1} by their bounds of $\tfrac{\ln 2}{2}$, we obtain
	\begin{equation}
		u_j \le u_0 e^{-j{\rho_n}} \exp\left(\tfrac{\ln2}{2} + \tfrac{\ln2}{2}\right)
		= 2u_0 e^{-j{\rho_n}} \notag.
	\end{equation}
\end{proof}
We assume in the following that $A$ and $g$ are as in Lemma~\ref{lem:exp-shrinking-expk-upper}.
%\begin{remark}
%	In the proof above we assume that $\tfrac{u_0}{n} = g$ is small enough.
%	This does not have any impact on the main theorem by the following simple argument.
%	We construct the sequence $u_j$ from $u_0$ such that $\tfrac{u_0}{n}$ is small enough.
%	By Lemma~\ref{lem:general-connect} the number of rounds between $gn$ and $u_0$ uninformed nodes is $O(1)$ for any choice of $u_0$ such that $\tfrac{u_0}{n} = \Theta(1)$.
%\end{remark}
Combining the lemma above with the definition of $q(u)$ in Lemma~\ref{lem:exp-shrinking-failure-upper}, one can easily see the following.
\begin{corollary}\label{cor:exp-shrinking-nphases-upper}
	There exists $J \le \tfrac1{\rho_n} \ln n$ such that (i) $q(u_J) < \tfrac12$ and (ii) $u_J = O(1)$.
\end{corollary}
%\merk{A: I don't see why we need $\tfrac12$ instead of $1$.}
%\begin{proof}
%	For $j=0$, there is nothing to prove.
%	Let $j \ge 1$ be such that $u_{j-1} \ge 1$ and for all $i < j$, $u_i \le 2u_0 e^{-i{\rho_n}}$.
%	We show that $u_j \le 2u_0e^{-j{\rho_n}}$.
%%	Let us proof by induction on $j$ that if $u_{j-1} \ge 1$ and for all $i < j$, $u_i \ge \alpha a^{-j{\rho_n}}$, then $u_j \ge \alpha u_0 e^{-(j+1){\rho_n}}$.
%%	(The base for $j=0$ is trivial.)
%	By definition,
%	\begin{align}
%		u_j & = u_0 e^{-j{\rho_n}}
%			\prod_{i=0}^{j-1}\left(1 + ae^{\rho_n} \tfrac{u_i}{n} + Ae^{\rho_n} u_i^{-B}\right) \notag\\
%		& \le u_0 e^{-j{\rho_n}}
%			\prod_{i=0}^{j-1} \exp\left(ae^{\rho_n} \tfrac{u_i}{n} + Ae^{\rho_n} u_i^{-B}\right) \notag\\
%		& \le u_0 e^{-j{\rho_n}} \exp\left(\sum_{i=0}^{j-1}ae^{\rho_n} \tfrac{u_i}{n}
%			+ \sum_{i=0}^{j-1}Ae^{\rho_n} u_i^{-B}\right) \label{eq:exp-shrinking-upper-eq1}.
%	\end{align}
%	We estimate separately the two sums.
%	Since $u_i \le 2u_0 e^{-i{\rho_n}}$, the first sum is bounded by a geometric series as follows.
%	\begin{equation}
%		\sum_{i=0}^{j-1}ae^{\rho_n} \tfrac{u_i}{n}
%		\le \tfrac{ae^{\rho_n}}{n} \sum_{i=0}^{j-1} 2u_0e^{-i{\rho_n}}
%		\le ae^{\rho_n} \cdot \tfrac{2u_0}{n} \cdot \tfrac1{1-e^{-{\rho_n}}} \notag.
%	\end{equation}
%	The bound is proportional to $\tfrac{u_0}{n}$, so by choosing $g$ small enough, we can bound it by any positive constant, in particular by $\tfrac{\ln2}{2}$.
%	The second sum can be bounded by the simple argument that $u_j \ge u_0e^{-j{\rho_n}}$ for any $j$.
%	Thus
%	\begin{equation}\sum_{i=0}^{j-1}Ae^{\rho_n} u_i^{-B}
%		\le Ae^{\rho_n} \sum_{i=0}^{j-1} u_0^{-B}e^{i{\rho_n} B}
%		\le Ae^{\rho_n} u_0^{-B} \frac{e^{j{\rho_n} B}}{e^{{\rho_n} B}-1} \notag.
%	\end{equation}
%	There exists an $A$ small enough such that the result is also at most $\tfrac{\ln2}{2}$.
%	Indeed, we must only show that $u_0^{-B} e^{j{\rho_n} B}$ is at most a constant.
%	By the induction hypothesis, $1 \le u_{j-1} \le 2u_0e^{-(j-1){\rho_n}}$.
%	Then $e^{j{\rho_n}} \le 2 u_0 e^{\rho_n}$.
%	Therefore, $u_0^{-B} e^{j{\rho_n} B} \le 2^B e^{{\rho_n} B} = O(1)$.
%	
%	Substituting the sums in~\eqref{eq:exp-shrinking-upper-eq1} for their bounds of $\tfrac{\ln 2}{2}$, we get
%	\begin{equation}
%		u_j \le u_0 e^{-j{\rho_n}} \exp\left(\tfrac{\ln2}{2} + \tfrac{\ln2}{2}\right)
%		= 2u_0 e^{-j{\rho_n}} \notag.
%	\end{equation}
%	Finally, we observe that since $u_0 = gn$, the smallest index $j$ such that $u_j \ge 1$ is at most $\tfrac1{\rho_n} \ln n + O(1)$.
%	This completes the proof of Lemma~\ref{lem:exp-shrinking-expk-upper}.
%\end{proof}

By Lemma~\ref{lem:exp-shrinking-E0-decrease}, $u_j$ form a decreasing sequence.
We say that the rumor spreading process is in \emph{phase} $j$, $j \in \{0, \ldots, J-1\}$, if the number of informed nodes is in $[u_{j+1}, u_j[$.

%\merk{A: The "failure" means that $Y(u) \ge E_0(u)$, i.e., to stay in phase $\Rightarrow u_{j+1}$ is included.}

%\begin{lemma} \label{lem:exp-shrinking-ETj-upper}
%	If the process is in phase $j$ ($j < J$), then the expected number of rounds to leave phase $j$ is at most
%	\begin{equation}
%		1 + \tfrac{Q_j}{1-Q_j},
%		\text{ where } Q_j := \min\left\{q(u_{j+1}), \tfrac1{1+1/q(1)}\right\} \notag.
%	\end{equation}
%\end{lemma}
\begin{lemma}\label{lem:exp-shrinking-ETj-upper}
	If the process is in phase $j < J$, then the number of rounds to leave phase $j$ is stochastically dominated by $1 + \Geom(1-Q_j)$, where $Q_j := q(u_{j+1})$.
	%at most $1 + \tfrac{Q_j}{1-Q_j}$, where $Q_j := q(u_{j+1})$.
\end{lemma}
\begin{proof}
	Consider a round with $u$ uninformed nodes.
	By definition, the process leaves the phase $j$ if $Y(u) < u_{j+1} = E_0(u_j)$.
	Since $E_0(u)$ is an increasing function, the upper bound for the probability to stay in phase $j$ in current round is the following.
	\begin{equation}
		\max_{u \in [u_{j+1},u_j[} \Pr[Y(u) \ge E_0(u_j)]
		\le \max_{u \in [u_{j+1},u_j[} \Pr[Y(u) \ge E_0(u)]
		\le q(u_{j+1}) \notag.
	\end{equation}
%	Thus, by Corollary~\ref{cor:exp-shrinking-error-prob}, the probability to stay in phase $j$ is bounded by
%	\begin{equation}
%		\max_{u \in [u_{j+1},u_j[} \min\left\{q(u), \tfrac1{1+1/q(1)}\right\} \notag.
%	\end{equation}
	So the number of rounds to leave phase $j$ is stochastically dominated by $1 + \Geom(1-Q_j)$.
%	Therefore, the expected number of rounds to leave phase $j$ is at most $1 + \tfrac{Q_j}{1-Q_j}$.
\end{proof}

\begin{lemma} \label{lem:exp-shrinking-sum-Qj-upper}
	$\sum_{j=0}^{J-1} Q_j = O(1)$.
\end{lemma}
\begin{proof}
	%By definition, $Q_j \le q(u_{j+1})$.
	By Lemma~\ref{lem:exp-shrinking-failure-upper}, we have
	\begin{equation}
		\sum_{j=0}^{J-1} Q_j \le O(1) \cdot \sum_{j=1}^J \tfrac1{u_j^{1-2B}} = O(1) \notag,
	\end{equation}
	where the last equality follows as in~\eqref{eq:exp-shrinking-upper-eq42}, using that $J \le \tfrac1{\rho_n} \ln n$.
%	From Lemma~\ref{lem:exp-shrinking-expk-upper} it follows that $u_j$ is bounded by a decreasing geometric sequence.
%	Since $B < 1/2$, $\sum Q_j$ is bounded from above by the sum of an increasing geometric series.
%	Such sum is of order of its last term, i.e.,
%	\begin{equation}
%		\sum_{j=0}^{J-1} Q_j = O(Q_{J-1}) = O\left(\tfrac1{u_J^{1-2B}}\right) \notag.
%	\end{equation}
%	To conclude the proof, it remains to note that $u_J = O(1)$.
\end{proof}
%\begin{proof}
%	We apply the estimate for $q(u_j)$ from Lemma~\ref{lem:exp-shrinking-failure-upper} and the bounds for $u_j$ from Lemma~\ref{lem:exp-shrinking-expk-upper}.
%	Therefore,
%	\begin{align}
%		\sum_{j=0}^{J-1} Q_j
%		& \le \sum_{j=0}^{J-1} q(u_j)
%			\le \sum_{j=0}^{J-1} \tfrac{(1+a)e^{-{\rho_n}}+c}{A^2} \cdot \tfrac1{u_j^{1-2B}} \notag \\
%		& \le O(1) \cdot \sum_{j=0}^{J-1} \tfrac1{(2u_0)^{1-2B}} \cdot e^{j{\rho_n}(1-2B)} \notag \\
%		& \le O(1) \cdot \tfrac1{(2u_0)^{1-2B}} \cdot \tfrac{e^{J{\rho_n}(1-2B)}}{1-e^{{\rho_n}(1-2B)}} \notag \\
%		& = O(1) \cdot \tfrac1{u_J^{1-2B}} = O(1) \notag.
%	\end{align}
%	\merk{check the last equality \ldots}
%\end{proof}

Now we can proof the main result of this section, i.e., Theorem~\ref{th:exp-shrinking-upper}.
\begin{proof}[Proof of Theorem~\ref{th:exp-shrinking-upper}]
%    \merk{A: paragraph added to avoid $g'$ in the statement of the theorem.}
    First, let $g' > 0$ be smaller than $g$.
    Then,
    \begin{equation}
        \Expect[T(n-\lfloor gn\rfloor, n)]
        \le \Expect[T(n-\lfloor gn \rfloor, n-\lceil g'n \rceil)]
        + \Expect[T(n- \lfloor g'n \rfloor, n)] \notag.
    \end{equation}
    By Lemma~\ref{lem:general-connect}, the exponential shrinking conditions imply that $\Expect[T(n-\lfloor gn \rfloor, n-\lceil g'n \rceil)]$ is at most a constant.
    In addition there exist $A'_0, \alpha'_0 > 0$ such that $\Pr[T(n-\lfloor gn \rfloor, n-\lceil g'n \rceil) > r/3] \le A'_0 e^{-\alpha'_0 r}$.
    We can hence assume that $g$ is small enough so that all Lemma~\ref{lem:exp-shrinking-E0-decrease}~and~\ref{lem:exp-shrinking-expk-upper} are satisfied.

	We denote by the random variable $T_j$ the number of rounds spent in phase $j$.
	With Corollary~\ref{cor:exp-shrinking-nphases-upper} and Lemma~\ref{lem:exp-shrinking-sum-Qj-upper}, we compute
	\begin{align}
		\Expect[T(n-\lfloor gn \rfloor, n-\lceil u_J \rceil)]
		& \le \sum_{j=0}^{J-1} \Expect[T_j]
			\le \sum_{j=0}^{J-1} \left(1 + \tfrac{Q_j}{1-Q_j}\right) \notag \\
		& = J + \sum_{j=0}^{J-1} \tfrac{Q_j}{1-Q_j}
			\le J + \tfrac1{1-Q_J} \cdot \sum_{j=0}^{J-1} Q_j \notag \\
		& = J + O(1) \notag.
	\end{align}
	Since $Q_j$ form a geometrical sequence, it follows from Lemma~\ref{lemma:sum geometrical-2} that there exist $A', \alpha' > 0$ such that
	\begin{equation}
		\Pr[T(n-\lfloor gn \rfloor, \lceil u_J \rceil) > J+r/2] \le A' e^{-\alpha' r}. \label{eq:1/th-30}
	\end{equation}
%	Then let $q = 1-\min_{k\in[n-u_J,n]}p_k$.
%	\merk{check if the sum should be up to $J$ or up to $J-1$ (also in Exponential Growth).}
	For the last at most $u_J$ uninformed nodes, we argue as follows.
	Consider one uninformed node.
	From the exponential shrinking conditions it follows that the expected number of rounds until this node is informed is at most $O(1)$.
	So, $\Expect[T(n-\lfloor u_J\rfloor, n)] \le u_J \cdot O(1) = O(1)$.
	Finally,
	\begin{equation}
		\Expect[T(n-\lfloor gn \rfloor, n)]
		\le \Expect[T(n-\lfloor gn \rfloor, n-\lceil u_J \rceil)]
			+ \Expect[T(n-\lfloor u_J\rfloor, n)]
		\le \tfrac1{\rho_n} \ln n + O(1) \notag.
	\end{equation}
	
	To prove the tail bound statement, let $q = 1-\min_{k\in[n-u_J,n]}p_k$.
	Now we consider the epidemic protocol with $m = O(1)$ uninformed nodes.
	Since an uninformed node stays uninformed for $r/2$ rounds with probability at most $q^{r/2}$, we have $\Pr[T(n-m,n) > r/2] \le m \cdot q^{r/2}$.
	Combining the last inequation with~\eqref{eq:1/th-30}, we obtain
	\[
		\Pr[T(n-\lfloor gn \rfloor, n) > J + r]
		\le (u_J+A') \exp\left(-r\cdot\min\right\{\alpha', \tfrac{\ln q}2\left\}\right) \,.
	\]
	Since $u_J = O(1)$, the tail bound statement directly follows as in the proof of Theorem~\ref{th:exp-growth-upper}.
\end{proof}
%\merk{check if we need to add a constant number of rounds to inform a constant number of last uninformed nodes.}
%\begin{corollary}
%	There exist $A, \alpha > 0$ such that for any integer $r > 0$ we have
%	$$\Pr[T(n-\lfloor gn \rfloor,n) \le \E[T(n-\lfloor gn \rfloor,n)] + r] \le Ae^{-\alpha r}.$$
%\end{corollary}
%\begin{proof}
%	We observe first that by Lemma~\ref{lemma:sum geometrical-2}, there exist some $A', \alpha' > 0$ such that
%	$$\Pr[T(n-\lfloor gn \rfloor, \lceil u_J \rceil) > J+r] \le A'e^{-\alpha'r}.$$
%	Then let $q = 1-\min_{k\in[n-u_J,n]}p_k$.
%	Now we consider the epidemic protocol with $m = O(1)$ uninformed nodes.
%	Since an uninformed node stays uninformed for $r$ rounds with probability at most $q^r$, we have $\Pr[T(n-m,n) > r] \le m \cdot q^r$.
%	Since $u_J = O(1)$, the claim of corollary directly follows from the fact that both probabilities above are exponentially small in $r$.
%\end{proof}

%-----------------------------------------------------------------------------------
%-----------------             Lower       BOUND             -----------------------
%-----------------------------------------------------------------------------------

\subsection{Exponential Shrinking Regime. Lower Bound}

\subsubsection{Exponential Shrinking Conditions}
\begin{defn}[lower exponential shrinking conditions] \label{def:upper-exp-shrinking-conditions}
    Let $\rho_n$ be bounded between two positive constants.
	Let $0 < g < 1$ and $a, c \in \R_{\ge0}$.
	We say that a homogeneous epidemic protocol satisfies \emph{the lower exponential shrinking conditions} if for any $n \in \N$ big enough, the following properties are satisfied, for all $u \le gn$ (resp. $k \in [n-\lfloor gn \rfloor, n]$).
	\renewcommand{\theenumi}{(\roman{enumi})}%
	\begin{enumerate}
		\item
			$1 - p_k = 1-p_{n-u} \ge e^{-{\rho_n}} - a\frac{u}{n}$;
		\item
			$c_k = c_{n-u} \le \frac{c}{u}$.
	\end{enumerate}
\end{defn}

\begin{theorem}[lower bound of spreading time] \label{th:exp-shrinking-lower}
	Consider a homogeneous epidemic protocol satisfying the lower exponential shrinking conditions (see definition above). There is a constant $g' \in ]0, 1[$ and further constants $A', \alpha'>0$ such that for any positive $g < g'$,
	\begin{align*}
		&\Expect[T(n-\lfloor gn \rfloor, n)] \ge \tfrac1{\rho_n}\ln n + O(1),\\
		&\Pr[T(n-\lfloor gn \rfloor, n) \le \tfrac1{\rho_n}\ln n - r] \le A' \exp(-\alpha'r)\, \mbox{ for all $r \in \N$}.\\
	\end{align*}
\end{theorem}

\subsubsection{Round Targets and Failure Probabilities}

Let $Y(u)$ be the number of uninformed nodes at the end of the round with $u$ uninformed ones.
%Since $\Expect[Y(u)] = u(1-p_{n-u})$, the exponential shrinking conditions imply that
From the exponential shrinking conditions it follows that
\begin{equation}
	\Expect[Y(u)] \ge E(u) := u \left(e^{-{\rho_n}} - a\tfrac{u}{n}\right) \notag.
\end{equation}
We define the \emph{target value} in the same way as for the upper bound.
\begin{equation}
	E_0(u) := E(u) - Au^{1-B}, \label{eq:def-E0-lower-expshr}
\end{equation}
where $A>0$ and $B \in ]0,1/2[$ are some constants chosen uniformly for all values of $u$ and $n$.
In addition $A$ is required to be small enough to satisfy Lemma~\ref{lem:exp-shrinking-expk-lower}.

%\begin{lemma}
%	$E_0(u)$ is increasing.
%\end{lemma}
%\begin{proof}
%	\merk{todo}
%\end{proof}

\begin{lemma}~\label{lem:exp-shrinking-failure-lower}
	For any $u > gn$ and $u \in \N$,
	\begin{equation}
		\Pr[Y(u) \le E_0(u)] \le q(u) := \tfrac{e^{-{\rho_n}}+c}{A^2} \cdot \tfrac1{u^{1-2B}} \notag.
	\end{equation}
\end{lemma}
\begin{proof}
	As before, using Chebyshev's inequality and taking into account that $E(u) \le \Expect[Y(u)]$, we compute
	\begin{align}
		\Pr&[Y(u) \le E_0(u)]
			= \Pr\left[Y(u) \le E(u) \cdot \left(1-\tfrac{Au^{1-B}}{E(u)}\right) \right] \notag \\
		& \le \Pr\left[Y(u) \le \Expect[Y(u)]-Au^{1-B}\cdot\tfrac{\Expect[Y(u)]}{E(u)}\right] \notag \\
		& \le \tfrac{\Var[Y(u)]}{(Au^{1-B})^2} \cdot \tfrac{E(u)^2}{\Expect[Y(u)]^2} \notag.
	\end{align}
    From covariance condition, it follows that $\Var[Y(u)] \le \Expect[Y(u)] + cu$.
    Therefore,
    \begin{align}
        \Pr[Y(u) \le E_0(u)]
        & \le \left(1 + \tfrac{cu}{\Expect[Y(u)]}\right) \cdot \tfrac{E(u)}{\Expect[Y(u)]}
    	   		\cdot \tfrac{E(u)}{(Au^{1-B})^2} \notag \\
    	& \le \left(1 + \tfrac{cu}{E(u)}\right) \cdot \tfrac{E(u)}{(Au^{1-B})^2} \notag \\
        & = (E(u)+cu) \cdot \tfrac1{(Au^{1-B})^2}
        	\le \tfrac{e^{-{\rho_n}}+c}{A^2} \cdot \tfrac1{u^{1-2B}} \notag.
    \end{align}
\end{proof}

\subsubsection{The Phase Calculus}

We define the sequence $u_j$ recursively by
\begin{equation}
	u_0 := gn, \qquad u_{j+1} := E_0(u_j) \notag.
\end{equation}
The next observation follows from the definition.
\begin{observation} \label{obs:exp-shrinking-expk-lower}
	For any $j \ge 0$ we have $u_j \le u_0 e^{-j{\rho_n}}$.
\end{observation}

\begin{lemma}\label{lem:exp-shrinking-expk-lower}
	By choosing $A$ in~\eqref{eq:def-E0-lower-expshr} and $g$ sufficiently small, we can assume that for all $j \le \tfrac1{\rho_n} n$, we have $u_j \le \tfrac12 u_0 e^{-j{\rho_n}}$.
\end{lemma}
\begin{proof}
	For $j=0$, there is nothing to prove.
	Consider $1 \le j \le \tfrac1{\rho_n} \ln n$ and assume that for all $i<j$ we have $u_i \ge \tfrac12 u_0 e^{-i{\rho_n}}$.
	We will show that $u_j \ge \tfrac12 u_0 e^{-j{\rho_n}}$.
	By definition,
	\begin{align}
		u_j & = u_0e^{-j{\rho_n}} \prod_{i=0}^{j-1}
			\left(1-e^{\rho_n} a\tfrac{u_i}{n} - A\tfrac1{u_i^B}\right) \notag \\
		& \ge u_0e^{-j{\rho_n}} \left(1
			-\tfrac{e^{\rho_n} a}{n}\sum_{i=0}^{j-1}u_i - A\sum_{i=0}^{j-1}\tfrac1{u_i^B}\right) \notag
	\end{align}
	Like in the proof of Lemma~\ref{lem:exp-shrinking-expk-upper}, we estimate separately the two sums.
	Using Observation~\ref{obs:exp-shrinking-expk-lower}, we obtain for the first sum that
	\begin{equation}
		\tfrac{e^{\rho_n} a}{n}\sum_{i=0}^{j-1}u_i
		\le e^{\rho_n} a \tfrac{u_0}{n} \sum_{i \ge 0} e^{-i{\rho_n}}
		= \tfrac{e^{\rho_n} a}{1-e^{-{\rho_n}}} \cdot \tfrac{u_0}{n}
		= g \cdot O(1) \notag.
	\end{equation}
	By the hypothesis of induction, for any $i < j$, $u_i \ge \tfrac12 u_0 e^{-i{\rho_n}}$.
	Since $j < \tfrac1{\rho_n} \ln n$,
	\begin{align}
		A \sum_{i=0}^{j-1}\tfrac1{u_i^B}
		& \le \tfrac{A}{2^B u_0^B} \sum_{i=0}^{j-1} e^{-i{\rho_n} B}
			\le \tfrac{A}{2^B u_0^B} \cdot \tfrac{e^{j{\rho_n} B}}{e^{{\rho_n} B} - 1} \notag \\
		& = \tfrac{A}{2^B(e^{{\rho_n} B}-1)} \cdot \tfrac{n^B}{u_0^B}
			= \tfrac{A}{2^B(e^{{\rho_n} B}-1)} \cdot g^{-B}
			= Ag^{-B} \cdot O(1) \notag.
	\end{align}
	Then, by choosing $A$ and $g$ small enough, we can bound both sums by 1/4, so that
	\begin{equation}
		u_j \ge u_0 e^{-j{\rho_n}} \left(1 - \tfrac14 - \tfrac14\right)
		\ge \tfrac12 u_0 e^{j-{\rho_n}} \notag.
	\end{equation}
\end{proof}

Having $u_j$ bounded from above and below, one can easily see the following.
\begin{corollary} \label{cor:exp-shrinking-nphases-lower}
	There exists $J = \tfrac1{\rho_n} \ln n + O(1)$ such that $u_J > 1$ for any $n$ big enough.
\end{corollary}

By definition, the $u_j$ form a non-decreasing sequence.
We say that the rumor spreading process is in phase $j$, $j \in \{0,\ldots,J-1\}$, if the number of informed nodes is in $[u_{j+1}, u_j[$.

\begin{lemma}
	If the process is in phase $j < J-1$, then the probability that it "leapfrogs" phase $j+1$ (i.e., proceeds to phase $j+2$ or further in current round) is at most $q(u_j)$.
\end{lemma}
\begin{proof}
    Consider a round with $u \in [u_{j+1}, u_j[$ uninformed nodes.
    The protocol jumps over the phase $j+1$, if at the end of current round $Y(u) < u_{j+2} = E_0(u_{j+1})$.
    Since $E_0$ is increasing,
	\begin{equation}
		\Pr[u < u_{j+2}]
		%= \Pr[u < E_0(u_{j+1})]
		\le Pr[u < E_0(u)]
		\le q(u) \notag.
	\end{equation}
	Since $q(u)$ is a decreasing function, the upper bound for the probability to jump over phase $j+1$ is  the following.
	\begin{equation}
		\max_{u \in [u_{j+1}, u_j[} \Pr[u < u_{j+2}]
		\le q(u_{j+1}) \notag.
	\end{equation}
\end{proof}

Now we can proof the main result of this section, i.e., Theorem~\ref{th:exp-shrinking-lower}.

\begin{proof}[Proof of Theorem~\ref{th:exp-shrinking-lower}]
    Let $\tau$ be the first round $t$ (of this shrinking phase) in which the process leapfrogs a phase. Let $\tau = \infty$ if such an event does not occur. 
    By Corollary~\ref{cor:exp-shrinking-nphases-lower}, the interval $[1,gn]$ is cut into at least $J = \tfrac1{\rho_n} \ln n + O(1)$ phases.
    Clearly, if $\tau < J$, then $T(n-\lfloor gn \rfloor, n) \ge \tau$, and if $\tau \ge J$, then $T(n-\lfloor gn \rfloor, n) \ge J$.

    If $\tau = J-t$, then the process in phase $J-t$, that is, from some number $u$ of uninformed nodes belonging to phase $J-t$, makes an exceptionally large progress from. Since $q(u)$ is a decreasing function, we have $\Pr[\tau = J-t] \le q(u_{J-t})$. Consequently, using the fact that $q(u_j)$ forms a decreasing geometric sequence, we obtain %.using $u_{J-t} \ge O(1) \cdot u_J \cdot e^{{\rho_n} t}$, %\merk{double-check the previous
    \begin{align*}
    \Pr[T(n-\lfloor gn \rfloor, n) \le J-t] \le \Pr[\tau \le J-t] \le q(u_0) + q(u_1) + \ldots + q(u_{J-t}) = O(q(u_{J-t})).
    \end{align*}
    Then, using $u_{J-t} \ge O(1) \cdot u_J \cdot e^{{\rho_n} t}$, we compute
    \begin{align*}
    \Pr[T(n-\lfloor gn \rfloor, n) \le J-t]
    & \le O(q(u_{J-t})) \le O(1) u_{J-t}^{-2B+1} \\
    & \le O(1) (u_J e^{\rho_n t})^{-2B+1} \le O(1) \exp(-\Omega(t)).
		\end{align*}
    Applying Lemma~\ref{lem:exp-shrinking-failure-lower}, we obtain
    \begin{align*}
        \Expect[T(n-\lfloor gn \rfloor, n)]
        &\ge J \Pr[\tau > J] + \sum_{t=1}^{J-1} t\cdot\Pr[\tau = t]
        = J - \sum_{t=1}^{J-1} t \Pr[\tau = J-t] \\
        &\ge J - \sum_{t=1}^{J-1} t q(u_{J-t})
        \ge J - \tfrac{e^{\rho_n}+a+c}{A^2} \cdot \sum_{t=1}^{J-1} \tfrac{t}{u_{J-t}^{1-2B}}.
    \end{align*}
    Since $B < 1/2$ and $u_{J-t} \ge O(1) \cdot u_J \cdot e^{{\rho_n} t}$, the sum above converges.
    Therefore,
    \begin{align}
    	\Expect[T(n-\lfloor gn \rfloor, n)] \ge J + O(1) \notag.
    \end{align}
%        \ge J - O(1) \sum_{t=1}^{J-1} \tfrac t{(u_0 e^{-(J-t){\rho_n}})^{1-2B}}
%        = J - \tfrac{O(1)}{(u_0 e^{-J{\rho_n}})^{1-2B}} \sum_{t=1}^{J-1} te^{-t(1-2B)}
%        = J - O(1)
%    \end{align}
\end{proof} 