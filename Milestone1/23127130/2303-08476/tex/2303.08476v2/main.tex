\documentclass[twocolumn,10pt]{article}

%%%some pkgs added by XZ..
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{pbox}
\usepackage{booktabs}
\usepackage{amsmath,amssymb}
\usepackage{amsthm}
\usepackage{verbatim} % for comments
%%% end pkgs added by XZ
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor, soul}
\sethlcolor{yellow}
\newcommand{\mathcolorbox}[2]{\colorbox{#1}{$\displaystyle #2$}}
\usepackage{hyperref}
\usepackage{pdfpages}
\usepackage{balance}

\usepackage{bm}
\usepackage{graphicx}
\usepackage[absolute,overlay]{textpos}% by XZ: for the text in the top margin..

\newcommand{\squishlist}{
	\begin{list}{$\bullet$}
		{ \setlength{\itemsep}{2pt}    \setlength{\parsep}{0pt}
			\setlength{\topsep}{5pt}     \setlength{\partopsep}{0pt}
			\setlength{\leftmargin}{1.35em} \setlength{\labelwidth}{1em}
			\setlength{\labelsep}{0.5em} } }
	
	\newcommand{\squishend}{
\end{list}  }

\makeatletter
\renewcommand{\fnum@figure}{\textbf{Fig.~\thefigure}}
\makeatother

\DeclareMathOperator{\E}{\mathbb{E}}
\newcommand*\diff{\mathop{}\!\mathrm{d}} %XZ added 

%%%added by XZ to define theorems etc..
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
%%%%

\usepackage{hyperref}
\usepackage{mathtools}

\usepackage{geometry}
\geometry{margin=1.62cm}  % change margin

%%% for comments to ourselves
\newcount\Comments  % 0 suppresses notes to selves in text
\Comments=1  % TODO: set to 0 for final version
% macros for comments
\usepackage{color}
\definecolor{darkgreen}{rgb}{0,0.5,0}
\definecolor{purple}{rgb}{1,0,1}
% \kibitz{color}{comment} inserts a colored comment in the text
\newcommand{\kibitz}[2]{\ifnum\Comments=1\textcolor{#1}{#2}\fi}
% add yourself here:
\newcommand{\simos}[1]{\kibitz{magenta}      {[SG: #1]}}
\newcommand{\radu}[1]{\kibitz{blue}       {[Radu: #1]}}
\newcommand{\xingyu}[1]  {\kibitz{darkgreen}   {[Xingyu: #1]}}
\newcommand{\david}[1]  {\kibitz{yellow}   {[David: #1]}}
\newcommand{\valentin}[1]{\kibitz{purple}       {[Valentin: #1]}}


\usepackage{helvet}
\usepackage[T1]{fontenc}
\renewcommand{\familydefault}{\sfdefault}

\usepackage[superscript]{cite}
\renewcommand{\thefootnote}{\alph{footnote}}

\usepackage{abstract}
\renewcommand{\abstractname}{}    % clear the title
\renewcommand{\absnamepos}{empty}

\usepackage[subtle]{savetrees}

% \url{https://www.nature.com/natmachintell/content}:
% \begin{itemize}
%     \item 3500 words, excluding abstract, Methods, references and figure legends.
%     \item up to 150 words for abstract
%     \item ``Display items – up to 6 items (figures and/or tables).''
%     \item ``References – as a guideline, we typically recommend up to 50.''
%     \item ``Article should be divided as follows: Introduction (without heading), Results, Discussion, Methods.''
%     \item ``Methods section should not exceed 3,500 words, and should ideally sit somewhere closer to 2,500-3,000.'' 
%     \item ``Results and Methods should be divided by topical subheadings; the Discussion does not contain subheadings.''
% \end{itemize}


% Word count (estimate):
% Abstract: 137
% Intro: 598
% Sec 1.1: 203
% Sec 1.2: 210
% Sec 1.3: 425
% Sec 1.4: 431
% Sec 1.5: 237
% Sec 2.1: 335
% Sec 2.2: 192
% Sec 2.3: 361
% Sec 3 (Discussion): 443

% Sec 4.1 (methods): 596
% Sec 4.2 (methods): 774
% Sec 4.3 (methods): 181
% Sec 4.4 (methods): 406
% Sec 4.5 (methods): 417

% Total (non-methods): ~3435
% Total (methods): ~2374

\begin{document}
	\begin{textblock*}{20cm}(1cm,1cm)
		\textcolor{red}{Preprint accepted by Nature Communications Engieering \url{https://www.nature.com/commseng/}}
	\end{textblock*}
	
	%\title{Robust verification of critical robotic missions in harsh environments}
	%\title{Bayesian Learning for Robust Quantitative Verification under Parametric Uncertainty}
	%\title{Bayesian Learning for Robust Verification of Autonomous Systems in Mission-Critical Applications}
	\title{Bayesian Learning for the Robust Verification of Autonomous Robots}
	
	
	\author{Xingyu Zhao\thanks{Warwick Manufacturing Group, University of Warwick, Coventry, UK.} ,
		Simos Gerasimou\thanks{Department of Computer Science, University of York, York, UK.} , 
		Radu Calinescu\thanks{Department of Computer Science and Assuring Autonomy International Programme, University of York, York, UK.} ,
		Calum Imrie\footnotemark[3] ,
		Valentin Robu\thanks{Intelligent and Autonomous Systems Group, Centrum Wiskunde \& Informatica, Amsterdam, NL.},
		\thanks{Electrical Engineering Department, Eindhoven University of Technology, Eindhoven, NL}
		and 
		David Flynn\thanks{James Watt School of Engineering, University of Glasgow, Glasgow, UK}
	}
	\date{}
	%\thanksmarkseries{arabic}
	
	% make the title and abstract area
	\twocolumn[
	\begin{@twocolumnfalse}
		\maketitle
		\begin{abstract}
			
			%\vspace*{-3mm}
			\textbf{
				%We develop a novel Bayesian learning framework that enables the runtime verification of autonomous robots performing critical missions in uncertain environments. Our framework exploits prior knowledge and observations of the verified robotic system to learn expected ranges of values for the occurrence rates of its events. We support both events observed regularly during system operation, and singular events such as catastrophic failures or the completion of difficult one-off tasks. Furthermore, we use the learnt event-rate ranges to assemble interval continuous-time Markov models, and we apply quantitative verification to these models to compute expected intervals of variation for key system properties. These intervals reflect the uncertainty intrinsic to many real-world systems, enabling the robust verification of their quantitative properties under parametric uncertainty. We apply the proposed framework to the case study of verification of an autonomous robotic mission for underwater infrastructure inspection and repair. 
				\noindent
				Abstract -- Autonomous robots used in infrastructure inspection, space exploration and other critical missions operate in highly dynamic environments. As such, they must continually verify their ability to complete the tasks associated with these missions safely and effectively. Here we present a Bayesian learning framework that enables this runtime verification of autonomous robots. The framework uses prior knowledge and observations of the verified robot to learn expected ranges for the occurrence rates of regular and singular (e.g., catastrophic failure) events. Interval continuous-time Markov models defined using these ranges are then analysed to obtain expected intervals of variation for system properties such as mission duration and success probability. We apply the framework to an autonomous robotic mission for underwater infrastructure inspection and repair. The formal proofs and experiments presented in the paper show that our framework produces results that reflect the uncertainty intrinsic to many real-world systems, enabling the robust verification of their quantitative properties under parametric uncertainty. 
			}
		\end{abstract}
		
		\vspace*{3mm}
	\end{@twocolumnfalse}
	]
	\saythanks
	
	\noindent
	
	\section{Introduction}
	
	Mobile robots are increasingly used to perform critical missions in extreme environments, which are %that are 
	inaccessible or hazardous to humans.~\cite{japan-strategy-2015,EU-Robotics-2020,UK-RAS-2014,christensen2021roadmap}
	These missions range from the inspection %of subsea oil-rig pipelines 
	and 
	%the 
	maintenance of offshore wind-turbine mooring chains and high-voltage cables to nuclear reactor repair and deep-space exploration.~\cite{richardson2017robotic,UK-RAS-space-2018}
	
	Using robots for such missions poses major challenges.~\cite{lane_new_2016,EU-Robotics-2020} First and foremost, the robots need to operate with high levels of autonomy, as in these harsh environments their interaction and communication with human operators is severely restricted. Additionally, they frequently need to make complex mission-critical decisions, with errors endangering not just the robot---itself an expensive asset, but also the important system or environment being inspected, repaired or explored. Last but not least, they need to cope with the considerable uncertainty associated with these missions, which often comprise one-off tasks or are carried out in settings not encountered before. 
	
	Addressing these major challenges is the focus of intense research worldwide. In the UK alone, a recent \pounds 44.5M research programme has %is underway (\url{https://cutt.ly/RoboticsHubs})\xingyu{TODO: update this link} % https://www.gov.uk/government/news/robotics-and-ai-projects-to-create-safer-work-for-people
	%to 
	tackled technical and certification challenges associated with the use of robotics and AI in the extreme environments encountered in offshore energy (\url{https://orcahub.org}), space exploration (\url{https://www.fairspacehub.org}), nuclear infrastructure (\url{https://rainhub.org.uk}), and management of nuclear waste (\url{https://www.ncnr.org.uk}). This research has initiated a step change in the assurance and certification of autonomous robots---not least through the emergence of new concepts such as dynamic assurance~\cite{calinescu2017engineering} and self-certification~\cite{robu_train_2018} for robotic systems. 
	
	Dynamic assurance requires a robot to respond to failures, environmental changes and other disruptions not only by reconfiguring accordingly,~\cite{calinescu2012self} but also by producing new assurance evidence which guarantees that the reconfigured robot will continue to achieve its mission goals.~\cite{calinescu2017engineering} Self-certifying robots must continually verify their health and ability to complete missions in dynamic, risk-prone environments.~\cite{robu_train_2018} In line with the ``defence in depth'' safety engineering paradigm,~\cite{INSAG-10} this runtime verification has to be performed independently of the front-end planning and control engine of the robot. 
	
	%Nevertheless, 
	Despite these advances, 
	current dynamic assurance and self-certi\-fi\-ca\-tion methods rely on quantitative verification techniques (e.g., probabilistic~\cite{Kwi07,katoen_probabilistic_2016} and statistical~\cite{legay_statistical_2010} model checking) that do not handle well the parametric uncertainty that autonomous robots encounter in extreme environments. Indeed, quantitative verification  operates with stochastic models that demand single-point estimates of uncertain parameters such as task execution and failure rates. These estimates capture neither epistemic nor aleatory parametric uncertainty. As such, they are affected by arbitrary estimation errors which---because stochastic models are often nonlinear---can be amplified in the verification process~\cite{calinescu_2016_formal}, and may lead to invalid robot reconfiguration decisions, dynamic assurance and self-certification.
	
	In this paper, we present a robust quantitative verification framework that employs Bayesian learning techniques to overcome this limitation. Our framework requires only partial and limited prior knowledge about the verified robotic system, and exploits its runtime observations (or lack thereof) to learn ranges of values for the system parameters. These parameter ranges are then used to compute  the quantitative properties that underpin the robot's decision making (e.g., probability of mission success, and expected energy usage) as intervals that---unique to our framework---capture the parametric uncertainty of the mission. 
	Our framework is underpinned by probabilistic model checking, a technique that is broadly used to assess quantitative properties, e.g., reliability, performance and energy cost of systems exhibiting stochastic behaviour. Such systems include 
	autonomous robots from numerous domains{\cite{kwiatkowska_probabilistic_2022}}, e.g., mobile service robots{\cite{lacerda2019probabilistic}}, spacecraft{\cite{nardone2016probabilistic}}, drones{\cite{fraser2020collaborative}} and robotic swarms{\cite{liu2010modeling}}. While we present a case study involving an autonomous underwater vehicle (AUV), the generalisability of our approach stems from the broad adoption of probabilistic model checking for the modelling and verification of this wide range of autonomous robots. As such, we anticipate that our results are applicable to autonomous agents across all these domains.
	
	We start by introducing our robust verification framework, which comprises Bayesian techniques for learning the occurrence rates of both singular events (e.g., catastrophic failures and completion of one-off tasks) and events observed regularly during system operation. Next, we describe the use of the framework for an offshore wind turbine inspection and maintenance robotic mission. Finally, we discuss the framework in the context of related work, and we suggest directions for further research.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section{Robust Bayesian verification framework}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\subsection{Quantitative verification}
	Quantitative verification is a mathematically based technique for analysing the correctness, reliability, performance and other key properties of systems with stochastic behaviour.~\cite{Baier-etal-2003,Kwiatkowska2007:SFM} The technique captures this behaviour into {Markov models}, formalises the properties of interest as {probabilistic temporal logic} formulae over these models, and employs efficient algorithms for their analysis. Examples of such properties include the probability of mission failure for an autonomous robot, and the expected battery energy required to complete a robotic mission.
	
	In this paper, we focus on the quantitative verification of {continuous-time Markov chains} (CMTCs). CTMCs are Markov models for continuous-time stochastic processes over countable state spaces comprising (i)~a finite set of {states} corresponding to real-world states of the system that are relevant for the analysed properties; and (ii)~the {rates of transition} between these states. 
	We use the following definition adapted from the probabilistic model checking literature~\cite{Baier-etal-2003,Kwiatkowska2007:SFM}.
	%Efficient quantitative verification algorithms for CTMCs are available, and are implemented by widely used probabilistic model checkers such as PRISM~\cite{kwiatkowska_prism_2011} and Storm~\cite{storm2017}.
	%%
	%While the transition rates of the CTMCs verified in this way must be known and constant, recent advances in quantitative verification~\cite{brim-etal-2013} support the analysis of CTMCs whose transition rates are {intervals}. %The technique has been used to synthesise CTMCs corresponding to process configurations and system designs that satisfy quantitative constraints and optimisation criteria~\cite{calinescu_efficient_2018,ceska_prism_psy_2016}, under the assumption that these bounded intervals are available. 
	%Here we introduce a Bayesian framework for computing these intervals in ways that reflect the parametric uncertainty of real-world systems such as autonomous robots.
	
	\begin{definition}
		\label{def:CTMC}
		A continuous-time Markov chain is a tuple
		\begin{equation}
		\mathcal{M}\!=\!(S,s_0,\mathbf{R}),
		\label{eq:CTMC} 
		\end{equation}
		where $S$ is a finite set of states, $s_0\!\in\! S$ is the initial state, and $\mathbf{R}\!:\! S\!\times\! S\!\to\! \mathbb{R}$ is a transition rate matrix such that the probability that the CTMC will leave state $s_i \!\in\! S$ within $t\!>\!0$ time units is  $1\!-\!e^{-t\cdot \sum_{s_k\!\in\! S\setminus\! \{s_i\}} \mathbf{R}(s_i,s_k)}$ and the probability that the new state is $s_j\in S\setminus\{s_i\}$ is $p_{ij}=$ $\mathbf{R}(s_i,s_j)\; /\;\sum_{s_k\in S\setminus\{s_i\}}\;\! \mathbf{R}(s_i,s_k)$.
	\end{definition}
	
	The range of properties that can be verified using CTMCs can be extended by annotating the states and transitions with non-negative quantities called {rewards}.
	
	\begin{definition}
		\label{def:rewards}
		A reward structure over a CTMC $\mathcal{M}\!=\!(S,s_0,$ $\mathbf{R})$ is a pair of functions $(\underline{\rho}, \bm{\iota})$ such that 
		$\underline{\rho} : S\to \mathbb{R}_{\geq 0}$ is a {state reward function} (a vector), and 
		$\bm{\iota} : S\times S\to \mathbb{R}_{\geq 0}$ is a {transition reward function} (a matrix).
	\end{definition}
	
	CTMCs support the verification of quantitative properties expressed in continuous stochastic logic (CSL)~\cite{aziz1996} extended with rewards~\cite{Kwiatkowska2007:SFM}. 
	
	\begin{definition}
		Given a set of atomic propositions $\mathit{AP}$, $a\!\in\!\mathit{AP}$, $p\! \in\! [0,1]$, $I\subseteq\mathbb{R}_{\geq 0}$, $r,t\!\in\!\mathbb{R}_{\geq 0}$ and $\bowtie\,\in\! \{\geq, >, <, \leq \}$, a CSL formula $\Phi$ is defined by the grammar:
		\begin{equation*}
		\begin{array}{ll}
		\!\!\!\Phi\; ::= &\hspace*{-2.3mm} true\; |\;  a\; |\; \Phi \wedge \Phi\; |\; \neg\Phi\; |\; P_{\bowtie p}[X\, \Phi]\; |\; P_{\bowtie p}[\Phi\, U^{I}\, \Phi]\; |\; \mathcal{S}_{\bowtie p}[\Phi]\; | \\
		&\hspace*{-2.3mm} R_{\bowtie r}[I^{=t}]\; | \; R_{\bowtie r}[C^{\leq t}]\; | \; R_{\bowtie r}[F\, \Phi]\; | \; R_{\bowtie r}[S].
		%\Psi ::= X \Phi\, |\, \Phi U^{I} \Phi  
		\end{array}
		\end{equation*}
	\end{definition}
	
	\noindent
	Given a CTMC $\mathcal{M}\!=\!(S,s_0,$ $\mathbf{R})$ with states {labelled} with atomic propositions from $AP$ by a function $L\! :\! S\! \to\! 2^{AP}$, and a reward structure $(\underline{\rho}, \bm{\iota})$ over $\mathcal{M}$, the CSL semantics is defined with a satisfaction relation $\models$ over the states and {paths} (i.e., feasible sequences of successive states) of $\mathcal{M}$~\cite{Baier-etal-2003}. 
	%
	The notation $s\models \Phi$ means ``$\Phi$ is satisfied in state $s$''. For any state $s\!\in\! S$, we have: 
	
	\squishlist
	\item $s\models true$, %; 
	%\item 
	$s \models a$ iff $a\in L(s)$, %;
	%\item 
	$s \models \neg \Phi$ iff $\neg (s\models \Phi)$, and %; 
	%\item 
	$s\models \Phi_1 \wedge \Phi_2$ iff $s\models \Phi_1$ and $s\models \Phi_2$;
	\item $s\models \mathcal{P}_{\bowtie p} [X\, \Phi]$ iff the probability $x$ that $\Phi$ holds in the state  following $s$ satisfies $x \bowtie p$ ({probabilistic next} formula); 
	%The probabilistic ``next'' formula $\mathcal{P}_{\bowtie p} [X \Phi]$ holds in a state $s$ iff the probability that $\Phi$ is true in the state that follows $s$ satisfies $\bowtie p$; 
	\item $s\models \mathcal{P}_{\bowtie p} [\Phi_1\, U^{I}\, \Phi_2]$ iff, across all paths starting at $s$, the probability $x$ of going through only states where $\Phi_1$ holds until reaching a state where $\Phi_2$ holds at a time $t\in I$ satisfies $x\bowtie p$  ({probabilistic until} formula);
	%\item The probabilistic ``until'' formula $\mathcal{P}_{\bowtie p} [\Phi_1 U^{I} \Phi_2]$ holds iff, across all paths starting at $s$, the probability $x$ of going through only states where $\Phi_1$ holds until reaching a state where $\Phi_2$ holds at a time $t\in I$ satisfies $x\bowtie p$;
	\item $s\models \mathcal{S}_{\bowtie p}[\Phi]$ iff, having started in state $s$, the probability $x$ of $\mathcal{M}$ reaching a state where $\Phi$ holds {in the long run} satisfies $x \bowtie p$  ({probabilistic steady-state} formula);
	\item the {instantaneous ($R_{\bowtie r}[I^{=t}]$), cumulative ($R_{\bowtie r}[C^{\leq t}]$), future-state ($R_{\bowtie r}[F\, \Phi]$)} and {steady-state ($R_{\bowtie r}[S]$) reward} formulae hold iff, having started in state $s$, the expected reward $x$ at time instant $t$, cumulated up to time $t$, cumulated until reaching a state where $\Phi$ holds, and achieved at steady state, respectively, satisfies $x\bowtie r$.
	\squishend
	
	Probabilistic model checkers such as PRISM~\cite{kwiatkowska_prism_2011} and Storm~\cite{storm2017} use efficient analysis techniques to compute the actual probabilities and expected rewards associated with probabilistic and reward formulae, respectively. The formulae are then verified by comparing the computed values to the bounds $p$ and $r$. Furthermore, the extended CSL syntax $P_{=?}[X\, \Phi]$, $P_{=?}[\Phi_1\, U^{I}\, \Phi_2]$, $R_{=?}[I^{=t}]$, etc. can be used to obtain these values from the model checkers. 
	
	While the transition rates of the CTMCs verified in this way must be known and constant, advanced quantitative verification techniques~\cite{brim-etal-2013} support the analysis of CTMCs whose transition rates are specified as {intervals}. 
	The technique has been used to synthesise CTMCs corresponding to process configurations and system designs that satisfy quantitative constraints and optimisation criteria~\cite{calinescu_efficient_2018,ceska_prism_psy_2016,calinescu2017rodes}, under the assumption that these bounded intervals are available. 
	Here we introduce a Bayesian framework for computing these intervals in ways that reflect the parametric uncertainty of real-world systems such as autonomous robots.
	
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\subsection{Bayesian learning of CTMC transition rates} 
	Given two states $s_i$ and $s_j$ of a CTMC such that transitions from $s_i$ to $s_j$ are possible and occur with rate $\lambda$, each transition from $s_i$ to $s_j$ is independent of how state $s_i$ was reached (the Markov property). Furthermore, the time spent in state $s_i$ before a transition to $s_j$ is modelled by a homogeneous Poisson process of rate $\lambda$. Accordingly, the likelihood that `data' collected by observing the CTMC shows $n$ such transitions occurring within a combined time $t$ spent in state $s_i$ is given by the conditional probability:
	\begin{equation}
	\label{eq_likelihood_poisson_process}
	l(\lambda) = \mathit{Pr}\left(\textmd{data} \mid \lambda\right)=\frac{\left(\lambda t\right)^{n}}{n!}e^{-\lambda t}
	\end{equation}
	
	In practice, the rate $\lambda$ is typically unknown, but prior beliefs about its value are available (e.g., from domain experts or from past missions performed by the system modelled by the CTMC) in the form of a probability (density or mass) function $f(\lambda)$. In this common scenario, the Bayes Theorem can be used to derive a {posterior probability function} that combines the likelihood $l(\lambda)$ and the prior $f(\lambda)$ into a better estimate for $\lambda$ at time $t$:
	\begin{equation}
	f(\lambda\mid \textmd{data}) = \frac{l(\lambda)f(\lambda)}{\int_{0}^{\infty} l(\lambda)f(\lambda) \diff \lambda}
	\label{eq_bayes}
	\end{equation}
	where the Lebesgue-Stieltjes integral from the denominator is introduced to ensure that $f(\lambda\mid \textmd{data})$ is a probability function. We note, we use Lebesgue-Stieltjes integration to cover in a compact way both continuous and discrete prior distributions $f(\lambda)$, as these integrals naturally reduce to sums for discrete distributions.
	We calculate the posterior estimate for the rate $\lambda$ at time $t$ as the expectation of~\eqref{eq_bayes}:
	\begin{equation}
	\label{eq_posterior_mean_lambda}
	\lambda^{(t)}=\E\left[\Lambda \mid \text{data}\right]
	=\frac{\int_{0}^{\infty} \lambda l(\lambda)f(\lambda) \diff \lambda}{\int_{0}^{\infty} l(\lambda)f(\lambda) \diff \lambda}\;.
	\end{equation}
	where we use capital letters for random variables and lower case for their realisations.
	
	
	\subsection{Interval Bayesian inference for singular events} In the autonomous-robot missions considered in our paper, certain events are extremely rare, and treated as {unique} from a modelling viewpoint. 
	These events include major failures (after each of which the system is modified to remove or mitigate the cause of the failure), and the successful completion of difficult one-off tasks. Using Bayesian inference to estimate the CTMC transition rates associated with such events is challenging because, with no  observations of these events, the posterior estimate is highly sensitive to the choice of a suitable prior distribution. Furthermore, only limited domain knowledge is often available to select and justify a prior distribution for these singular events. 
	
	To address this challenge, we develop a {Bayesian inference using partial priors} (BIPP) estimator that requires only \textit{limited, partial prior knowledge} instead of the complete prior distribution typically needed for Bayesian inference. For one-off events, such knowledge is both more likely to be available and easier to justify. BIPP provides bounded posterior estimates that are robust in the sense that the ground truth rate values are within the estimated intervals.
	
	To derive the BIPP estimator, we note that for one-off events the likelihood~(\ref{eq_likelihood_poisson_process}) becomes 
	%
	%Once an one-off happened, e.g., a catastrophic failure or an attempt to complete very different task, it will not happen again during the operation, so the practical interest is to estimate the event-rate before we observe it. Thus, the typical form of one-off event data is observing no event in time $t$, which has a likelihood function 
	%
	\begin{equation}
	l(\lambda)=Pr(\text{data}|\lambda)=e^{-\lambda \cdot t}
	\label{eq_likelihood_f}
	\end{equation}
	because $n=0$. 
	Instead of a prior distribution $f(\lambda)$ (required to compute the posterior expectation~(\ref{eq_posterior_mean_lambda})), we assume that we only have limited partial knowledge consisting of $m\geq 2$ confidence bounds on $f(\lambda)$:
	\begin{equation}
	\label{eq_prior_constraints}
	Pr(\epsilon_{i-1} < \lambda \leq \epsilon_i)=\theta_i 
	\end{equation}
	where $1\leq i \leq m$, $\theta_i>0$, and $\sum_{i=1}^{m} \theta_i=1$. The use of such bounds is a common practice for safety-critical systems. As an example, the IEC61508 safety standard \cite{iec_61508_2010} defines {safety integrity levels} (SILs) for the critical functions of a system based on the bounds for their probability of failure on demand ($\mathit{pfd}$): $\mathit{pfd}$ between $10^{-2}$ and $10^{-1}$ corresponds to SIL~1, $\mathit{pfd}$ between $10^{-3}$ and $10^{-2}$ corresponds to SIL~2, etc.; and testing can be used to estimate the probabilities that a critical function has different SILs. We note that $Pr(\lambda\geq \epsilon_0)=Pr(\lambda\leq \epsilon_m)=1$ and that, when no specific information is available, we can use $\epsilon_0=0$ and $\epsilon_m=+\infty$.
	
	%Naturally we know:
	%\begin{itemize}
	%   \item The $\epsilon_0$ and $\epsilon_m$ are respectively the certain lower and upper bounds, i.e. $Pr(\lambda\geq \epsilon_0)=1$ and $Pr(\lambda\leq \epsilon_m)=1$.
	%   Normally, without further information, $\epsilon_0=0$ and $\epsilon_m=+\infty$ for a transition rate. Note, the very first interval is closed on both sides $[\epsilon_{0},\epsilon_{1}]$ which holds throughout the paper.
	%    \item There is the constraint $\sum_{i=1..m} \theta_i=1$, meaning we only need to elicit $m-1$ confidence bounds from the assessor, and the confidence in the $m$-th interval can be calculated automatically from the constraint.
	%\end{itemize}
	
	The partial knowledge encoded by the constraints~(\ref{eq_prior_constraints}) is far from a complete prior distribution: an infinite number of distributions $f(\lambda)$ satisfy these constraints, and the result below provides bounds for the estimate rate~\eqref{eq_posterior_mean_lambda} across these distributions.
	
	\begin{theorem}
		\label{theorem_BIPP_bounds}
		The set $S_\lambda$ of posterior estimate rates~\eqref{eq_posterior_mean_lambda} computed for all prior distributions $f(\lambda)$ that satisfy~\eqref{eq_prior_constraints} has an infinum $\lambda_l$ and a supremum $\lambda_u$ given by:
		\begin{align}
		\label{eq_reachable_BIPP_lower_bound}
		\!\!\!\!\!\lambda_l = \min \left\{ \frac{\sum_{i=1}^m \left[\epsilon_i l(\epsilon_i)(1-x_i)\theta_i+\epsilon_{i-1}l(\epsilon_{i-1})x_i\theta_i\right]}
		{\sum_{i=1}^{m} [l(\epsilon_{i})(1-x_i)\theta_i+l(\epsilon_{i-1})x_i\theta_i]} \right|
		\nonumber\\
		\forall 1\!\leq\! i\!\leq\! m . x_i\in[0,1] \biggr\}\,,
		\end{align}
		\begin{align}
		\!\!\!\!\lambda_u
		= \max\left\{ \biggl. \frac{\sum_{i=1}^{m} \lambda_{i}l(\lambda_{i})\theta_i}
		{\sum_{i=1}^{m} l(\lambda_{i})\theta_i} \biggr| \,\forall 1\!\leq\! i\!\leq\! m . \lambda_i\!\in\!(\epsilon_{i-1},\epsilon_i] \right\}\!.
		\label{eq_reachable_BIPP_upper_bound}
		\end{align}
	\end{theorem}
	
	\noindent
	We provide a formal proof of Theorem~{\ref{theorem_BIPP_bounds}} in
	Section~{\hyperlink{bippProof}{4.1}}.
	
	The values $\lambda_l$ and $\lambda_u$ can be computed using numerical optimisation software packages available, for instance, within widely used mathematical computing tools like MATLAB and Maple. For applications where computational resources are limited or the BIPP estimator is used online with tight deadlines, we provide closed-form estimator bounds for $m=3$ (with $m=2$ as a subcase).
	
	%In situations where computational resources are limited and/or there are strict real-time requirements, online estimators using closed-form results are certainly preferable. In what follows, we present the closed-form results for $m=3$ (where $m=2$ as a special case) which we implemented in our case studies.
	
	\begin{corollary}
		\label{corollary_closed_form_BIPP_3}
		When $m=3$, the bounds~\eqref{eq_reachable_BIPP_lower_bound}  and~\eqref{eq_reachable_BIPP_upper_bound} satisfy:
		\begin{align}
		\lambda_l
		\geq 
		\begin{cases} \frac{\epsilon_{1}l(\epsilon_{1})\theta_2}{\theta_1+l(\epsilon_{1})\theta_2}, & \text{if } \frac{\theta_2 (\epsilon_{1}-\epsilon_2)}{\theta_1}
		>\frac{\epsilon_{2}l(\epsilon_{2})- \epsilon_{1}l(\epsilon_{1}) }{l(\epsilon_{1})l(\epsilon_{2})}
		\\[1mm]
		\frac{\epsilon_{2}l(\epsilon_{2})\theta_2}{\theta_1+l(\epsilon_{2})\theta_2}, & \text{otherwise}\end{cases}
		\label{eq:closed-form-lower-bound}
		\end{align}	
		and
		\begin{align}
		\lambda_u < \begin{cases}
		\frac{\epsilon_1 l(\epsilon_1) \theta_1 +\epsilon_2 l(\epsilon_2) \theta_2+\frac{1}{t} l(\frac{1}{t})(1-\theta_1-\theta_2)}
		{ l(\epsilon_1) \theta_1 }, & \text{if } t < \frac{1}{\epsilon_{2}}
		\\[1mm]
		\frac{\epsilon_1 l(\epsilon_1) \theta_1 +\frac{1}{t} l(\frac{1}{t}) \theta_2+\epsilon_2 l(\epsilon_2)(1-\theta_1-\theta_2)}
		{ l(\epsilon_1) \theta_1 }, & \text{if }  \frac{1}{\epsilon_{2}} \leq t \leq \frac{1}{\epsilon_{1}}
		\\[1mm]
		\frac{\epsilon_1 l(\epsilon_1) (\theta_1+\theta_2) +\epsilon_2 l(\epsilon_2)(1-\theta_1-\theta_2)}
		{ l(\epsilon_1) \theta_1 }, & \text{otherwise} %  t > \frac{1}{\epsilon_{1}}
		\end{cases}
		\label{eq:closed-form-upper-bound}
		\end{align}
	\end{corollary}
	
	\begin{corollary}
		\label{corollary_closed_form_BIPP_2}
		Closed-form BIPP bounds for $m=2$ can be obtained
		%Note, for the simplest case that $m=2$ (i.e. the only prior knowledge is a single confidence bound), the above closed-form results still hold 
		by setting $\epsilon_2=\epsilon_1$ and $\theta_2=0$ in \eqref{eq:closed-form-lower-bound} and \eqref{eq:closed-form-upper-bound}.
	\end{corollary}
	
	
	\if 0
	The values taken by the posterior estimate~(\ref{eq_posterior_mean_lambda}) for these distributions form a set $\mathcal{S}_\lambda$, and the following results provide an upper bound and a lower bound for $\mathcal{S}_\lambda$.
	
	\begin{theorem}
		\label{theorem_BIPP_m_point_for_upper_bound}
		\mbox{$\!$There exist $m$ values $\lambda_1\!\in\!(\epsilon_0,\epsilon_1]$, $\lambda_2\!\in\!(\epsilon_1,\epsilon_2]$,} \ldots, $\lambda_m\!\in\!(\epsilon_{m-1},\epsilon_m]$ such that $\sup \mathcal{S}_\lambda$ is the posterior estimate~(\ref{eq_posterior_mean_lambda}) obtained by using as prior the $m$-point discrete distribution with probability mass $f(\lambda_i)=\mathit{Pr}(\lambda=\lambda_i)=\theta_i$ %at a point $\lambda_i\in (\epsilon_{i-1},\epsilon_i]$ 
		for $i=1,2,\ldots,m$. %, and maximises the posterior expectation~(\ref{eq_posterior_mean_lambda}). %\xingyu{A minor: I feel it would be ``safer'' to use a proper PMF notation to replace the PDF notation $f_u(\lambda_i)=\theta_i$, since we are now talking about a point distribution. $Pr(\lambda=\lambda_i)=\theta_i$. Same for the next theorem. Having said that, now I tend to change all the PDF $f(\cdot)$ to CDF $F(\cdot)$ to avoid any confusion. Or it is not necessary?}
		%		To maximise the objective function of Eq.~\eqref{eq_posterior_mean_lambda} subject to the $m$ constraints of Eq.~\eqref{eq_prior_constratints}, there exists a m-point distribution $f_u(\lambda)$ with probability mass $\theta_i$ at $\lambda=\lambda_i$, where $\epsilon_{i-1} < \lambda_i \leq \epsilon_i $. 
		%\radu{Is this additional result proved in the theorem, or is it actually the result detailed below in (5)? The values of $\lambda_i$ can be obtained numerically, depends on other model parameters.} 
	\end{theorem}
	
	Theorem \ref{theorem_BIPP_m_point_for_upper_bound} implies that the posterior estimate for $\lambda$ over all priors that satisfy the constraints~\eqref{eq_prior_constraints} has a supremum
	\begin{align}
	%\E(\Lambda \mid \text{data})
	\!\!\!\!\lambda_u
	= %\max_{\{\epsilon_{i-1} < \lambda_i \leq \epsilon_i\}} \max_{(\lambda_1,\ldots,\lambda_m)\in (\epsilon_{0},\epsilon_1]\times\ldots\times(\epsilon_{m-1},\epsilon_m]}\\
	\max\left\{ \biggl. \frac{\sum_{i=1}^{m} \lambda_{i}l(\lambda_{i})\theta_i}
	{\sum_{i=1}^{m} l(\lambda_{i})\theta_i} \biggr| \,\forall 1\!\leq\! i\!\leq\! m . \lambda_i\!\in\!(\epsilon_{i-1},\epsilon_i] \right\}\!,
	\label{eq_reachable_bound_m_CBI}
	\end{align}
	which we obtained by using the prior $f(\lambda)$ from Theorem~\ref{theorem_BIPP_m_point_for_upper_bound} in (\ref{eq_posterior_mean_lambda}). %We have $\lambda_u\in \Lambda$ because this prior satisfies the constraints~\eqref{eq_prior_constraints}. 
	The value $\lambda_u$
	%The bound $\lambda_u$ 
	can be computed using numerical optimisation software packages available, for instance, within widely used mathematical computing tools like MATLAB and Maple.
	%\radu{such as~\cite{???}}\xingyu{I use Maple GloblelOptimasation toolbox and Python-Scipy a lot.. I guess it is a personal preference and depends on the applications? or maybe we need to cite a survey paper if there is any.. e.g. \cite{boukouvala_global_2016}? While I think we don't want to discuss in details that which type of optimisation we have in our case. Just a useful website that may of your interest..\url{https://www.mat.univie.ac.at/~neum/glopt/software_g.html}}.
	
	%which reduces the problem to an optimisation in the $m$-dimensional parametric space of $\lambda_i$s, which can be solved numerically by optimisation software-libraries.
	
	\begin{theorem}
		\label{theorem_BIPP_m_point_for_lower_bound}
		There exist $m$ values $x_1,x_2,\ldots,x_m\in[0,1]$ such that $\inf \mathcal{S}_\lambda$ is the posterior estimate~(\ref{eq_posterior_mean_lambda}) obtained by using as prior the $(m+1)$-point discrete distribution with probability mass $f(\epsilon_0)=\mathit{Pr}(\lambda=\epsilon_0)=x_1\theta_1$,  $f(\epsilon_i)=\mathit{Pr}(\lambda=\epsilon_i)=(1-x_{i})\theta_{i}+x_{i+1}\theta_{i+1}$ for $1\leq i<m$, and $f(\epsilon_m)=\mathit{Pr}(\lambda=\epsilon_m)=(1-x_m)\theta_m$. %, and minimises the posterior expectation~(\ref{eq_posterior_mean_lambda}).
		%\xingyu{Rigorously speaking, this (m+1)-point distribution is not satisfying the constraints. Please note the the left endpoint of each interval is open (apart from the 1st one). So the way of my original statement of this theorem says: this (m+1) point distribution derives a infimum of all the posterior results calculated by the priors satisfying the constraints, although there is no difference from a engineering application point of view of using numerical solutions.. }
		%There exists a $2m$-point distribution\footnote{The points on the boundaries of two successive intervals are overlapping which effectively reduces the number of points from $2m$ to $m+1$. For clarity, we omit the overlapping effect and simply say it is a $2m$-point distribution. Moreover, in the later optimisation step, the $m+1$ points can be further reduced to $m$ points depends on the optimised allocation of probability mass given other model parameters.} $f_l(\lambda)$ yielding a posterior estimate of the objective function Eq.~\eqref{eq_posterior_mean_lambda} which is no greater than the results calculated by using any distributions satisfying the $m$ constraints of Eq.~\eqref{eq_prior_constratints}. On the distribution $f_l(\lambda)$, for each interval $[\epsilon_{i-1},\epsilon_{i}]$, there are two points located at $\lambda=\epsilon_{i-1}$ and $\lambda=\epsilon_{i}$, and the probability mass associated with them are $r_i\theta_i$ and $(1-r_i)\theta_i$ respectively where $r_i\in[0,1]$. The values of $r_i$s can be obtained numerically based on other model parameters.
	\end{theorem}
	
	Theorem \ref{theorem_BIPP_m_point_for_lower_bound} implies that the posterior estimate for $\lambda$ over all priors that satisfy the constraints~\eqref{eq_prior_constraints} has an infinum
	\begin{align}
	\label{eq_reachable_lower_bound}
	\!\!\!\!\!\lambda_l = \min \left\{ \frac{\sum_{i=1}^m \left[\epsilon_i l(\epsilon_i)(1-x_i)\theta_i+\epsilon_{i-1}l(\epsilon_{i-1})x_i\theta_i\right]}
	{\sum_{i=1}^{m} [l(\epsilon_{i})(1-x_i)\theta_i+l(\epsilon_{i-1})x_i\theta_i]} \right|
	\nonumber\\
	\forall 1\!\leq\! i\!\leq\! m . x_i\in[0,1] \biggr\}\,,
	\end{align}
	which we obtained by using the prior $f(\lambda)$ from Theorem~\ref{theorem_BIPP_m_point_for_lower_bound} in (\ref{eq_posterior_mean_lambda}). %Because this prior does not satisfy the constraints~\eqref{eq_prior_constraints}, we have  $\lambda_l\notin \Lambda$. 
	As before, $\lambda_l$ can be computed using numerical optimisation techniques.
	
	%which we obtained by using $f_l(\lambda)$ in (\ref{eq_posterior_mean_lambda}). 
	
	%where the $r_i$ is:
	%	\begin{equation}
	%		r_i=\frac{l(\lambda_{i})-l(\epsilon_i)}{l(\epsilon_{i-1})-l(\epsilon_i)}
	%	\end{equation}
	%Again, it reduces the problem to an optimisation in a $m-$dimensional parametric spaces of $r_i$s, which can be done numerically given other model parameters.
	\fi
	
	
	\begin{figure*}
		\centering
		\includegraphics[width=\hsize]{images/integration-diagram.pdf}
		\caption{\textbf{Robust Bayesian verification framework.} The integration of Bayesian inference
			using partial priors (BIPP) and Bayesian inference using imprecise probability with sets of priors (IPSP)  
			% IPSP Bayesian inference 
			with interval continuous-time Markov chain (CMTC) model checking supports the online robust quantitative verification and reconfiguration of autonomous systems under parametric uncertainty.}
		\label{fig:integration}
	\end{figure*}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\subsection{Interval Bayesian inference for regular events}
	For CTMC transitions that correspond to regular events within the modelled system, we follow the common practice~\cite{bernardo_bayesian_1994} of using a Gamma prior distribution for each uncertain transition rate $\lambda$:
	\begin{equation}
	f(\lambda) = \Gamma[\lambda;\alpha,\beta]=\frac{\beta^\alpha}{(\alpha-1)!}\lambda^{\alpha-1}e^{-\beta\lambda}.
	\label{eq_gamma}
	\end{equation}
	The Gamma distribution is a frequently adopted conjugate prior distribution for the likelihood~\eqref{eq_likelihood_poisson_process} and, if the prior knowledge assumes an initial value $\lambda^{(0)}$ for the transition rate, the parameters $\alpha>0$ and $\beta>0$ must satisfy 
	\begin{equation}
	\E(\Gamma[\lambda;\alpha,\beta])=\frac{\alpha}{\beta}=\lambda^{(0)}.
	\end{equation}
	The posterior value $\lambda^{(t)}$ for the transition rate after observing $n$ transitions within $t$ time units is then obtained by using the prior~\eqref{eq_gamma} in the expectation~\eqref{eq_posterior_mean_lambda}, as in the following derivation adapted from classical Bayesian theory~\cite{bernardo_bayesian_1994}:%\xingyu{Yes, it is better in our story that we show this re-parameterisation of using beta in a Bayesian inference. I am a bit concerned that readers may find this long (13) ``less exciting'' since it is well-established results elsewhere (as I remember I did cite it from a Bayesian textbook\cite[pp.266--277]{bernardo_bayesian_1994}. Are we reinventing the wheel?). Or not? Just a minor concern, but I am ok if you prefer to leave it in if we have the space. }
	\begin{multline}
	\lambda^{(t)} = \frac{\int_0^\infty \lambda\left(\frac{(\lambda t)^n}{n!}e^{-\lambda t}\right)\left(\frac{\beta}{(\alpha-1)!}\lambda^{\alpha-1}e^{-\beta\lambda}\right)\diff \lambda}{\int_0^\infty \left(\frac{(\lambda t)^n}{n!}e^{-\lambda t}\right)\left(\frac{\beta}{(\alpha-1)!}\lambda^{\alpha-1}e^{-\beta\lambda}\right)\diff \lambda}\\
	= \frac{\int_0^\infty \lambda^{n+\alpha}e^{-\lambda(t+\beta)}\diff \lambda}{\int_0^\infty \lambda^{n+\alpha-1}e^{-\lambda(t+\beta)}\diff \lambda}
	= \frac{\int_0^\infty \lambda^{n+\alpha}\left(\frac{e^{-\lambda(t+\beta)}}{-(t+\beta)}\right)'\diff \lambda}{\int_0^\infty \lambda^{n+\alpha-1}e^{-\lambda(t+\beta)}\diff \lambda}\\
	= \frac{\left. \left(\lambda^{n+\alpha}\frac{e^{-\lambda(t+\beta)}}{-(t+\beta)}\right) \right|_0^\infty - \int_0^\infty (n+\alpha)\lambda^{n+\alpha-1}\frac{e^{-\lambda(t+\beta)}}{-(t+\beta)}\diff \lambda}{\int_0^\infty \lambda^{n+\alpha-1}e^{-\lambda(t+\beta)}\diff \lambda}\\
	= \frac{0+\frac{n+\alpha}{t+\beta}\int_0^\infty \lambda^{n+\alpha-1}e^{-\lambda(t+\beta)}\diff \lambda}{\int_0^\infty \lambda^{n+\alpha-1}e^{-\lambda(t+\beta)}\diff \lambda}
	=\frac{n+\alpha}{t+\beta}
	=\frac{n+\beta\lambda^{(0)}}{t+\beta}\\
	=\frac{\beta}{t+\beta}\lambda^{(0)} +\frac{t}{t+\beta}\frac{n}{t}
	=\frac{t^{(0)}}{t+t^{(0)}}\lambda^{(0)} +\frac{t}{t+t^{(0)}}\frac{n}{t},
	\label{eq_posterior_rate_gamma}
	\end{multline}
	where $t^{(0)}=\beta$. This notation reflects the way in which the posterior rate $\lambda^{(t)}$ is computed as a weighted sum of the mean rate $\frac{n}{t}$ observed over a time period $t$, and of the prior $\lambda^{(0)}$ deemed as trustworthy as a mean rate calculated from observations over a time period $t^{(0)}$.
	%
	%use of conjugate priors is a common practice, thus a Gamma distribution is the natural choice for the likelihood depicted by Eq.~\eqref{eq_likelihood_poisson_process}. This Gamma-Poisson setup is known to be the case of Bayesian inference in the regular, linear canonical exponential families (cf. the Proposition 5.4 and Example 5.5 in \cite[pp.266--277]{bernardo_bayesian_1994}). That is, if, instead of using the common shape $\alpha$ and rate $\beta$ parameters, we reparametrise the Gamma distribution by:
	%\begin{equation}
	%r_{ij}^{(0)}=\frac{\alpha}{\beta} \quad,\quad t_{i}^{(0)}=\beta
	%\label{eq_reparameterisation_of_gamma}
	%\end{equation}
	%then, after seeing the data, the updating of the parameter $r_{ij}^{(0)}$ of the prior is linear given the second parameter $t_{i}^{(0)}$.
	%
	%More precisely, after observing $n_{ij}$ transitions in a total $t_{i}$ sojourn time in state $i$, via Bayes Theorem, we can obtain a posterior Gamma distribution with parameters of $r_{ij}^{(t_i)},t_{i}^{(t_i)}$ where\footnote{Note, the upper index $^{(0)}$ is used to identify the prior parameters, in contrast, the upper index $^{(t_i)}$ denotes the posterior parameters after observing outgoing transitions in a total $t_{i}$ sojourn time in state $i$.}:
	%\begin{align}
	%t_i^{(t_i)}&=t_i^{(0)}+t_i
	%\\
	%r_{ij}^{(t_i)}&=\frac{t_i^{(0)}}{t_i^{(0)}+t_i}\cdot %r_{ij}^{(0)}+\frac{t_i}{t_i^{(0)}+t_i} \cdot \frac{n_{ij}}{t_i} 
	%\label{eq_post_r_ij_fundamental}
	%\end{align}
	%Indeed, the posterior mean of a Gamma distribution with the common shape $\alpha$ and rate $\beta$ parameters is $\frac{\alpha+n_{ij}}{\beta+t_i}$ \cite{filieri_formal_2012}, which is exactly the posterior mean $r_{ij}^{(t_i)}$ by substituting $\alpha$ and $\beta$ with the relations in Eq.~\eqref{eq_reparameterisation_of_gamma}.
	%
	%This reparametrization of the Gamma distribution provides intuitive interpretations of the parameters. $r_{ij}^{(0)}$ is the prior expectation for the transition probability $p_{ij}$, and larger $t_i^{(0)}$ leads to more concentrated probability measure around $r_{ij}^{(0)}$ \footnote{Since we know the variance of a Gamma is $\frac{\alpha}{\beta^2}=\frac{r_{ij}^{(0)}}{t_i^{(0)}}$. A larger $t_i^{(0)}$ decreases the variance.}. Thus, $t_i^{(0)}$ is quantifying the strength of beliefs in the prior estimation (i.e. $r_{ij}^{(0)}$), or a ``pseudo-count'' which can be interpreted as the size of an imaginary sample that gives the prior estimation \cite{walter_imprecision_2009}.
	%
	%As Eq.~\eqref{eq_post_r_ij_fundamental} shows, after seeing $n_{ij}$ transitions in the time period $t_i$ as data, the posterior expected $r_{ij}^{(t_i)}$ is a \textit{weighted} sum of two terms: (i) the prior estimate of $r_{ij}^{(0)}$ and (ii) the ${n_{ij}}/{t_i}$ which is the frequency of the transition in the data. The weights are proportional to the $t_i^{(0)}$ (the ``pseudo-count'' of prior simple size) and $t_i$ (the ``actual-count'' of data sample size). Smaller $t_i^{(0)}$ represents lower confidence in the priors and the new data will dominate the posteriors. 
	When $t^{(0)}\ll t$ (either because we have low trust in the prior $\lambda^{(0)}$ and thus $t^{(0)}\simeq 0$, or because the system was observed for a time period $t$ that is much longer than $t^{(0)}$), the posterior~\eqref{eq_posterior_rate_gamma} reduces to the maximum likelihood estimator, i.e.\ $\lambda^{(t)} \simeq \frac{n}{t}$. In this scenario, the observations fully dominate the estimator~\eqref{eq_posterior_rate_gamma}, with no contribution from the prior.
	
	The selection of suitable values for the parameters $t^{(0)}$ and $\lambda^{(0)}$ of the traditional Bayesian estimator~\eqref{eq_posterior_rate_gamma} is very challenging. What constitutes a suitable choice often depends on unknown attributes of the environment, or several domain experts may each propose different values for these parameters. In line with recent advances in imprecise probabilistic modelling,
	%that we leverage here~
	\cite{krpelik2018imprecise,walter_bayesian_2017,walter_imprecision_2009} we address this challenge by defining a robust transition rate estimator for {Bayesian inference using imprecise probability with sets of priors} (IPSP).
	The IPSP estimator uses ranges $[\underline{t}^{(0)},\overline{t}\textrm{}^{(0)}]$ and $[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$ (corresponding to the  environmental uncertainty, or to input obtained from multiple domain experts) for the two parameters instead of point values. %\xingyu{Are we giving enough credit to [51] or more general -- the *imprecise probability* community? I mean, even the motivation and initial idea of using sets of prior parameters are not ours... Am I being ``too honest''? Actually, I think it makes our arguments more convincing that there is a whole community of people sharing the same concern of using Bayesian estimators in practice on eliciting priors..}
	
	The following theorem quantifies the uncertainty that the use of parameter ranges for $t^{(0)}$ and $\lambda^{(0)}$ induces on the posterior rate~\eqref{eq_posterior_rate_gamma}. 
	%
	%Now, via the KAMI estimator (Eq. \eqref{eq_post_p_ij_fundamental} and \eqref{eq_post_r_ij_fundamental} for DTMCs and CTMCs respectively) and given the trace of transitions derived from collected data, the unknown transition parameter of interest (i.e. $p_{ij}$ or $r_{ij}$ in different contexts) can be estimated in a Bayesian manner taking into account both useful prior knowledge and up-to-date data. We use KAMI as a baseline in this paper to compare with the new features of our novel Bayesian estimators. Numerical examples can be found in later sections and case studies.
	%
	%The question now remains of (i) how to justify a particular choice of prior parameters, i.e. the $t_i^{(0)}$ and $r_{ij}^{(0)}$, for the unknown transition rate in a CTMC? In other words, whether one can truly express the subjective and imprecise prior knowledge with the \textit{exactness} that a single particular prior distribution requires; and (ii) how to measure the error of single point estimates yielded by Eq.~\eqref{eq_post_r_ij_fundamental} which will be propagated and compounded in the later model checking in ways that are unknown but likely to be significant, as pointed in \cite{calinescu_2016_formal}. 
	%
	%Although \cite{calinescu_2016_formal} is the first work to synthesise bounds for unknown transition parameters, it is based on the theory of \textit{simultaneous confidence intervals} which is not a Bayesian approach thus without the distinct advantage of being able to embed useful prior knowledge.
	%
	%To answer those questions, we introduce the IPSP approach developed in 
	%
	This theorem specialises and builds on generalised Bayesian inference results~\cite{walter_imprecision_2009} that we adapt for the estimation of CTMC transition rates.
	%and integrate it with PMC, in the new formal verification context, to:
	%\begin{itemize}
	%    \item get upper and lower bounds on the posterior estimates of the transition parameters whose range measures the estimation errors. Such imprecision will be propagated in the PMC, leading to bounded verification results of system QoS properties;
	%    \item allow modelling vague and imperfect prior knowledge (e.g. from experts, historical records) in a more practical and flexible way using bounded priors; 
	%    \item detect \textit{prior-data conflict} \cite{evans_checking_2006} when observe surprising data (that conflicts our prior knowledge) in the operation to provide extra alarms of the dynamic environments.
	%\end{itemize}
	
	%\footnote{Note the elicited intervals for $p_{ij}^{(0)}$ should satisfy the unit simplex constraint $\sum_{j=1}^k p_{ij}^{(0)}=1 $.}
	%To be exact, in a CTMC context, instead of a single value, we elicit an interval for the two prior parameters $t_i^{(0)}$ and $r_{ij}^{(0)}$, and denote them as:
	%\begin{equation}
	%t_i^{(0)} \in \left[\underline{t_i}^{(0)},\overline{t_i}^{(0)}\right]\quad , \quad r_{ij}^{(0)} \in \left[\underline{r_{ij}}^{(0)},\overline{r_{ij}}^{(0)}\right] %\nonumber
	%\end{equation}
	
	%\radu{Let's change the propositions into theorems. I would really like to see more detail in the proof below, i.e., not point the reader to the proof from \cite[p.266]{walter_imprecision_2009} quite so quickly. I don't immediately know how to best expand the proof, but I suggest that the second sentence is expanded, i.e., show the calculations that lead to a generalised iLUCK Bayesian inference model, e.g.: intermediate\_result\_1; intermediate\_result\_2; \ldots; final\_result; and explain that final\_result is a generalised iLUCK Bayesian inference model according to the definition from [X], and end with `As such, the theorem Y from \cite[p.266]{walter_imprecision_2009}, and the posterior bounds can be calculated as -- show a bit of calculation here too, unless the results from \cite[p.266]{walter_imprecision_2009} are identical in format to eqs. (9) and (10).}
	
	\begin{theorem}
		\label{theorem_CTMC_IPSP}
		Given uncertain prior parameters $t^{(0)}\in[\underline{t}^{(0)},$ $\overline{t}\textrm{}^{(0)}]$ and $\lambda^{(0)}\in[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$, the posterior rate $\lambda^{(t)}$ from~\eqref{eq_posterior_rate_gamma} can range in the interval  $[\underline{\lambda}^{(t)},\overline{\lambda}\textrm{}^{(t)}]$, where:
		%
		%In a CTMC, if an unknown transition rate $r_{ij}$ follows a Gamma prior distribution whose parameters (after the reparametrization of Eq.~\eqref{eq_reparameterisation_of_gamma}) are bounded by $\left[\underline{t_i}^{(0)},\overline{t_i}^{(0)}\right]$ and $\left[\underline{r_{ij}}^{(0)},\overline{r_{ij}}^{(0)}\right]$, then after seeing $n_{ij}$ transitions from the state $i$ to $j$ in an accumulated $t_i$ sojourn time in state $i$, the lower and upper bounds for the posterior expected $r_{ij}$ are:
		%\begin{align}
		\begin{equation}
		\underline{\lambda}^{(t)}=\begin{cases} \frac{\overline{t}\text{}^{(0)}\underline{\lambda}^{(0)}+n}{\overline{t}\text{}^{(0)}+t}, & \text{if } \frac{n}{t} \geq \underline{\lambda}^{(0)}  
		\\[2mm] 
		\frac{\underline{t}^{(0)}\underline{\lambda}^{(0)}+n}{\underline{t}^{(0)}+t}, & \text{otherwise} %\quad \frac{n}{t} <\underline{\lambda}^{(0)}
		\end{cases}
		%\nonumber
		\\[1mm]
		\label{eq_post_lower_bound_rij}
		\end{equation}
		and
		\begin{equation}
		\overline{\lambda}^{(t)}=\begin{cases} \frac{\overline{t}\text{}^{(0)}\overline{\lambda}\text{}^{(0)}+n}{\overline{t}\text{}^{(0)}+t}, & \text{if } \frac{n}{t} \leq \overline{\lambda}\text{}^{(0)}  
		\\[2mm]
		\frac{\underline{t}^{(0)}\overline{\lambda}\text{}^{(0)}+n}{\underline{t}^{(0)}+t}, & \text{otherwise} %\quad \frac{n}{t} >\overline{\lambda}\text{}^{(0)}
		\end{cases}.
		\label{eq_post_upper_bound_rij}
		\end{equation}
		%\end{align}
	\end{theorem}
	
	\noindent
	We provide a formal proof of Theorem~{\ref{theorem_CTMC_IPSP}} in 
	Section~{\hyperlink{ipspProof}{4.2}}.
	
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\subsection{Robust verification and adaptation} 
	
	Based on the methods defined earlier, we developed an end-to-end verification framework for the online computation of bounded intervals of CTMC properties. The verification framework integrates our BIPP and IPSP Bayesian interval estimators with interval CTMC model checking~\cite{brim-etal-2013}.  
	As shown in Fig.~\ref{fig:integration}, this involves devising a parametric CTMC model that captures the structural aspects of the system under verification through a \textsc{System Modeller}.
	This activity is typically performed once at design time, i.e., before the system is put into operation.
	By monitoring the system under verification, our framework enables observing both the occurrence of regular events and {the lack of singular events} during times when such events could have occurred (e.g., a catastrophic failure not happening when the system performs a dangerous operation). Our online \textsc{BIPP Estimator} and \textsc{IPSP Estimator} use these observations to calculate expected ranges for the rates of the monitored events, enabling a \textsc{Model Generator} to continually synthesise up-to-date interval CTMCs that model the evolving behaviour of the system. 
	
	The interval CTMCs, which are synthesised from the parametric CTMC model,
	%that captures the structural aspects of the system under verification. They 
	are then continually verified by the \textsc{PRISM-PSY Model Checker}~\cite{ceska_prism_psy_2016}, to compute value intervals for key system properties. As shown in Fig.~\ref{fig:integration} and illustrated in the next section, these properties range from dependability (e.g., safety, reliability and availability) \cite{avizienis_basic_2004} and performance (e.g., response time and throughput) properties to resource use and system utility. Finally, changes in the value ranges of these properties may prompt the dynamic reconfiguration of the system by a \textsc{Controller} module responsible for ensuring that the system requirements are satisfied at all times. 
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section{Results: Robust verification of robotic mission}
	
	\begin{figure*}[t!]
		\centering
		\includegraphics[width=\hsize]{images/ctmc4.pdf}
		\caption{\textbf{Floating chain continuous-time Markov chain (CMTC) model. }CTMC of the floating chain cleaning and inspection mission, where $e_1$, $e_2$, \ldots, $e_k$ represent the mean energy required to clean chains $1$, $2$, \ldots, $k$, respectively. %$e_i=x_ie_c+(1-x_i)e_t$ for $i=1,2,\ldots,k$.
			The rate $r^{\mathsf{fail}}_i$ corresponds to a regular event and is therefore modelled using Bayesian inference using imprecise probability with sets of priors (IPSP) from {\eqref{eq_post_lower_bound_rij}} and {\eqref{eq_post_upper_bound_rij}}. 
			The rates $r_{i}^{\mathsf{clean}}$ and $r^{\mathsf{damage}}$ correspond to singular events and are thus modelled using Bayesian inference using partial priors (BIPP) from~{\eqref{eq_reachable_BIPP_lower_bound}} and {\eqref{eq_reachable_BIPP_upper_bound}}.}
		% \textcolor{red}{Move all energy rewards to transitions (only power rewards go in CTMC states.)}}
		\label{fig:ctmc}
	\end{figure*}
	
	\begin{table*}[th!]
		\renewcommand{\arraystretch}{1.2}
		\centering
		\caption{System requirements for the AUV floating chain inspection and cleaning mission}
		
		%	\vspace*{-3mm}
		\begin{small}
			\begin{tabular}{p{.2cm} p{10.8cm} p{5cm}} %
				\toprule
				\textbf{ID} 
				&\textbf{Informal description} 
				&{\raggedright\textbf{Formal specification$^\dagger$}}
				\\
				\midrule
				\textbf{R1}
				&The probability of mission failure  must not exceed 5\%
				&$P_{\leq 0.05} [F \textsf{ damage}]$\\
				\textbf{R2} 
				&The expected energy consumption must not exceed the remaining energy $E_\mathrm{left}$
				&$R^\mathrm{energy}_{\leq E_\mathrm{left}} [F \textsf{ finish}]$\\
				\textbf{R3}
				& Subject to R1 and R2 being met, maximise the number of cleaned chains
				&{\raggedright find 
					{argmax} $\sum_{i=1}^k x_i$ 
					such that $R1 \land R2$}\\
				\bottomrule
				\multicolumn{3}{l}{$^\dagger$expressed in rewards-extended continuous stochastic logic (see Methods section)}
			\end{tabular}
		\end{small}
		\label{table:reqs}	
	\end{table*}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\subsection{Offshore infrastructure maintenance} We demonstrate how our online robust verification and reconfiguration framework can support an AUV to execute a structural health inspection and cleaning mission of the substructure of an offshore wind farm. 
	%AUVs with similar capabilities have been developed 
	Similar scenarios for AUV use in remote, subsea environments have been described in other large-scale robotic demonstration projects, such as the PANDORA EU FP7 project~\cite{pandora2015}. 
	Compared to remotely operated vehicles that must be tethered with expensive oceanographic surface vessels run by specialised personnel, AUVs bring important advantages, including reduced environmental footprint (since no surface vessel consuming fuel is needed), reduced cognitive fatigue for the involved personnel, increased frequency of mission execution, and reduced operational and maintenance cost. 
	%our BIPP and IPSP Bayesian interval estimators combined with the \textsc{PRISM-PSY} model checker~\cite{brim-etal-2013} 
	%can support the online  robust quantitative verification and reconfiguration of an autonomous underwater vehicle (AUV) executing an autonomous inspection and maintenance mission of subsea installations of an offshore wind farm.  
	
	The offshore wind farm comprises multiple floating wind turbines, with each turbine being a buoyant foundation structure secured to the sea bed with floating chains tethered to anchors weighing several tons.  Wind farms with floating wind turbines offer increased wind exploitation (since they can be installed in deeper waters where  winds are stronger and more consistent), reduced installation costs (since there is no need to build solid foundations), and reduced impact on the visual and maritime life (since they are further from the shore)~\cite{myhr2014levelised}. 
	
	The AUV is deployed to collect data about the condition of $k \geq 1$ floating chains to enable the post-mission identification of problems that could
	%assessing 
	affect the structural integrity of the asset (floating chain). 
	%When a floating chain has accumulated biofouling or marine growth, the AUV can use its on-board high-pressure water jet to clean the chain and complete the inspection task~\cite{pandora2015}. 
	When the visual inspection of a chain is hindered due to accumulated biofouling or marine growth, the AUV can use its on-board high-pressure water jet to clean the chain and continue with the inspection task~\cite{pandora2015}. 
	
	The high degrees of \textit{aleatoric uncertainty} in navigation and the perception of the marine environment entail that the AUV might fail to clean a chain. This uncertainty originates from the dynamic conditions of the underwater medium that includes unexpected water perturbations coupled with difficulties in scene understanding due to reduced visibility and the need to operate close to the floating chains. When this occurs, the AUV can retry the cleaning task or skip the chain and move to the next.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\subsection{Stochastic mission modelling}
	
	%The operating environment is only partially known since the exact location of some of the floating chains might have changed as a result of strong water currents or interference with sea creatures.
	
	Fig.~\ref{fig:ctmc} shows the parametric CTMC model of the floating chain inspection and cleaning mission. 
	The AUV inspects the $i$-th chain with rate $r^\mathrm{inspect}$ and consumes energy $e_{ins}$. 
	%The inspection is successful and the AUV moves to the  next chain, or the chain needs cleaning with probabilities $p$ and $1-p$, respectively. 
	The chain is clean with probability $p_{\mathsf{c}}$ and the AUV travels to the  next chain with rate $r^\mathrm{travel}$ consuming energy $e_t$, or the chain needs cleaning with probability $1-p_{\mathsf{c}}$.
	%When the AUV is in the cleaning stage, 
	%decides to perform or skip the task by setting the control parameter $x_i \in \{0,1\}$  for all the remaining chains so that the system requirements are satisfied. 
	When the AUV attempts the cleaning ($x_i=1$), the task succeeds with chain-dependent rate $r_i^\mathrm{clean}$, causes catastrophic damage to the floating chain or itself with rate $r^\mathrm{damage}$ or fails with chain-dependent 
	rate $r^\mathrm{fail}_i$. If the cleaning fails, the AUV prepares to retry with known and fixed rate $r^\mathrm{prepare}$ requiring energy $e_p$, and it either retries cleaning ($x_i=1$) or skips the current chain and moves to chain $i\!+\!1$ ($x_i=0$). 
	After executing the tasks on the $k$-th chain, the AUV returns to its base and completes the mission. 
	%All tasks consume energy given by 
	
	Since the AUV can fail to clean the $i$-th chain with non-negligible probability and multiple times, this is a regular event whose  transition rate $r^\mathrm{fail}_i$ is modelled using the IPSP estimator from (7) and (8).
	In contrast, 
	%each chain can be cleaned once during a mission and 
	the AUV is expected to not cause catastrophic damage but, with extremely low probability, may do so only once (after which the AUV and/or its mission are likely to be revised); thus, the corresponding transition rates $r^\mathrm{clean}_i$ and $r^\mathrm{damage}$ are modelled using the BIPP estimator from (14) and (15). The other transition rates, i.e., those for inspection ($r^\mathrm{inspect}$), travelling ($r^\mathrm{travel}$) and preparation ($r^\mathrm{prepare}$), are less influenced by the chain conditions and therefore assumed to be known, e.g., from previous trials and missions; hence, we fixed these transition rates.
	
	%When cleaning is needed, the decision to attempt cleaning or skip the chain is made by the AUV controller that synthesises a plan by determining the control parameter $x_i \in \{0,1\}$  for all remaining chains $i, i+1, ...n$ so that the following system requirements are satisfied. 
	When cleaning is needed for the $i$-th chain, the AUV controller synthesises a plan by determining the control parameter $x_i \in \{0,1\}$  for all remaining chains $i, i+1, ...k$ so that the system requirements in Table~\ref{table:reqs} are satisfied. 
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\subsection{Robust verification results}
	We demonstrate our solution for robust verification and adaptation using a mission in which the AUV was deployed  to inspect and, if needed, clean six chains placed in a hexagonal arrangement (Fig.~\ref{fig:uuv}). 
	We used $m=3$ and the BIPP estimator {\eqref{eq_reachable_BIPP_lower_bound}} and {\eqref{eq_reachable_BIPP_upper_bound}} for the transition rates $r^\mathrm{clean}_i$ and $r^\mathrm{damage}$, which correspond to singular events. For $r^\mathrm{clean}_i$, we used 
	$\epsilon_1=0.12 + \mathcal{U}(0,0.12)$, 
	$\theta_1=0.10 + \mathcal{U}(0,0.001)$, 
	$\epsilon_2=0.90 + \mathcal{U}(0,0.90)$,
	$\theta_2=0.85 + \mathcal{U}(0,0.0085)$, where $\mathcal{U}(x, y)$ denotes a continuous uniform distribution with $x$ and $y$ being its minimum and maximum values, respectively. 
	For $r^\mathrm{damage}$, we used
	$\epsilon_1=1e\textrm{-8} + \mathcal{U}(0,1e\textrm{-8})$, 
	$\theta_1=0.88 + \mathcal{U}(0,0.0088)$, 
	$\epsilon_2=1e\textrm{-7} + \mathcal{U}(0,1e\textrm{-7})$,
	$\theta_2=0.10 + \mathcal{U}(0,0.001)$.
	For $r^\mathrm{fail}_i$, we used $t^{(0)} = [10 + \mathcal{U}(0,10)]$ and 
	$\lambda ^{(0)} = [0.0163 + \mathcal{U}(0,0.00163)]$.
	During the mission execution, the AUV performs the model checking at every cleaning attempt so that runtime observations are incorporated into the decision making process entailing also 
	%The current approach will perform the model checking at every cleaning attempt, meaning 
	that the currently synthesised plan is not necessarily used at subsequent chains. 
	Hence, the AUV only needs to check system configurations where at least the current chain is to be cleaned, thus halving the number of configurations to be checked (since configurations with $x_i=0$ need not be checked). If all of these checks that consider $x_i=1$ fail to satisfy the requirements from Table~\ref{table:reqs}, then the AUV decides to skip the current chain and proceed to inspect and clean the next chain. 
	%check again at the next chain cleaning attempt.
	
	
	\begin{figure*}[h!]
		\centering
		% \includegraphics[width=0.85\hsize]{fig_simulation_arrow_simple.pdf}
		% \includegraphics[width=0.83\hsize]{images/fig3_simulation_corrected.pdf}
		\includegraphics[width=0.83\hsize]{images/fig_3_labelling_extra_uniform_corrected.pdf}
		
		\caption{ \textbf{Demonstration of autonomous underwater
				vehicle (AUV) inspection and cleaning mission. } 
			\textbf{a} Simulated AUV mission involving the inspection of six wind farm chains and, if required, their cleaning. \textbf{i)} Start of mission; \textbf{ii)} cleaning chain 3; \textbf{iii)} cleaning final chain. At this point, the AUV cleaned three chains, skipped one, and one chain did not require cleaning. 
			% \textbf{a} We simulated an AUV mission involving the inspection of six wind farm chains and, if required, their cleaning. At each chain that requires cleaning, the AUV decides whether to attempt to clean or skip the current chain. The middle screenshot, \textbf{a ii)}, from the simulation timeline shows the AUV at the third chain; with four chains remaining, there will be $2^{3}=8$ system configurations to consider, corresponding to $x_3=1$ and $x_4,x_5,x_6\in\{0,1\}$. 
			\textbf{b} Plots of the outcome of the model checking carried out by the AUV at chain~3. Each row shows the configurations against the requirements. \textbf{(i-iii)} Results during the first attempt at cleaning chain 3. \textbf{(iv-vi)} Results during the second attempt at cleaning. \textbf{(vii-ix)} Results at the third and successful attempt at cleaning the chain. The configurations highlighted in yellow is the chosen configuration for the corresponding attempt.
			% The AUV only succeeded to clean this chain at the third attempt, and the results of the model checking analyses for these attempts are shown in successive columns, with each row depicting the analysis of one of the requirements from Table~\ref{table:reqs}. A system configuration is feasible if it satisfies requirements R1---the AUV will not encounter a catastrophic failure with probability of at least 0.95 (\textbf{b (i,iv,vii)}), and R2---the energy consumption does not exceed what the AUV has remaining (\textbf{b (ii, v, viii)}). If multiple feasible configurations exist, then the winner is the configuration that maximises the number of chains cleaned (requirement R3, \textbf{b (iii, vi, ix)}). If there is still a tie, the configuration is chosen randomly from those that clean the most chains. In the AUV first attempt at chain~3 (\textbf{b (i, ii, iii)}), all the configurations are feasible, so configuration 1 (highlighted, and corresponding to the highest number of chains cleaned) is selected. This attempt fails and a second assessment is made (\textbf{b (iv, v, vi)}). This time, only system configurations 2--8 are feasible, and as configurations~2, 3, and~5 maximise R3, a configuration is chosen randomly from this subset (in this case configuration~3). This attempt also fails, and on the third attempt (\textbf{b (vii, viii, ix)}) only configurations 4--8 are feasible, with 5 maximising R3, and the AUV adopts this configuration and succeeds in cleaning the chain.
		}
		\label{fig:uuv}
	\end{figure*}
	
	If a cleaning attempt at chain $i$ failed, %say $x_{i}$, 
	the AUV integrates this observation in \eqref{eq_post_lower_bound_rij}\eqref{eq_post_upper_bound_rij}, and performs model checking to determine whether to retry the cleaning or skip the chain. 
	Since the AUV has consumed energy for the failed cleaning attempt, the energy available is reduced accordingly, which in turn can reduce the number of possible system configurations that can be employed and need checking.
	%The first immediate change is $E_{left}$ will decrease which can reduce the number of possible system configurations that can be employed. 
	The observation of a failed attempt reduces the lower bound for the reliability of cleaning $x_i$, and may result in a violation of the reliability requirement R1 (Table~\ref{table:reqs}), which may further reduce the number of feasible configurations.
	%The second difference is that the bounds for the reliability of cleaning $x_i$ will increase due to the additional observation of a failed attempt. 
	%This may now also further reduce the number of feasible configurations, which is a key behaviour of the system. 
	If the AUV fails to clean chain $i$ repeatedly, this lower bound will continue to decrease, potentially resulting in the AUV having no feasible configuration, and having to skip the current chain.
	Although skipping a chain overall decreases the risk of a catastrophic failure (as the number of cleaning attempts is reduced), leaving uncleaned chains will incur additional cost as a new inspection mission will need to be launched, e.g., using another AUV or human personnel.
	%This overall decreases the possibility of a catastrophic failure as the number of cleaning attempts are reduced.   
	
	
	% \begin{figure*}[h!]
	% 	\centering
	%     % \includegraphics[width=0.85\hsize]{fig_simulation_arrow_simple.pdf}
	%     % \includegraphics[width=0.83\hsize]{images/fig3_simulation_corrected.pdf}
	%     \includegraphics[width=0.83\hsize]{images/fig_3_labelling_corrected.pdf}
	%     % \includegraphics[width=0.85\hsize]{fig_simulation_arrow_cut.pdf}
	% %	\caption{A complete simulation of a AUV tasked with inspecting six chains and, if required, cleaning them, left image. At each chain the AUV decides whether to attempt to clean or skip the current chain. The middle image is the AUV at the $3^{\text{rd}}$ chain, and with four chains remaining there will be $2^{4-1}=8$ system configurations to consider. The plots below the mission execution are of the AUV's evaluation at the $3^{\text{rd}}$ chain, middle image. The AUV performed multiple attempts to clean this chain, where each column contains an attempt's evaluation, and each row plots the configurations with respect to a requirement. A system configuration is feasible if it satisfies the two requirements (Table~\ref{table:reqs}); there is at least 95\% reliability that the AUV will not encounter a catastrophic failure (\textbf{R1}; row 1), and that the energy consumption is less than what the AUV has remaining (\textbf{R2}, row 2). If there are multiple feasible configurations then winner is determined by whichever configuration maximises number of chains cleaned (\textbf{R3}, row 3). If there is still a tie the configuration is chosen randomly from those that clean the most chains. Here, all the configurations are feasible, and as system configuration 1 cleans the highest number of chains it is selected (highlighted in gold). This attempt fails and a second assessment is made, this time system configurations 2-8 are feasible, and as configurations 2, 3, and 5 maximises \textbf{R3} a configuration is chosen randomly from this subset, in this case 3. This attempt also fails, and on the third attempt only configurations 4-8 are feasible, with 5 maximising \textbf{R3}, and the AUV succeeds in cleaning the chain.
	% %	}
	% 	\caption{ \textbf{Demonstration of autonomous underwater
	% vehicle (AUV) inspection and cleaning mission. } 
	% \textbf{a} We simulated an AUV mission involving the inspection of six wind farm chains and, if required, their cleaning. At each chain that requires cleaning, the AUV decides whether to attempt to clean or skip the current chain. The middle screenshot from the simulation timeline shows the AUV at the third chain; with four chains remaining, there will be $2^{3}=8$ system configurations to consider, corresponding to $x_3=1$ and $x_4,x_5,x_6\in\{0,1\}$. 
	% \textbf{b} Plots of the outcome of the model checking carried out by the AUV at 3rd chain. The AUV only succeeded to clean this chain at the third attempt, and the results of the model checking analyses for these attempts are shown in successive columns, with each row depicting the analysis of one of the requirements from Table~\ref{table:reqs}. A system configuration is feasible if it satisfies requirements \textbf{R1}---the AUV will not encounter a catastrophic failure with probability of at least 0.95 (row~1), and \textbf{R2}---the energy consumption does not exceed what the AUV has remaining (row~2). If multiple feasible configurations exist, then the winner is the configuration that maximises the number of chains cleaned (requirement \textbf{R3}, row 3). If there is still a tie, the configuration is chosen randomly from those that clean the most chains. In the AUV first attempt at chain~3, all the configurations are feasible, so configuration 1 (highlighted, and corresponding to the highest number of chains cleaned) is selected. This attempt fails and a second assessment is made. This time, only system configurations 2--8 are feasible, and as configurations~2, 3, and~5 maximise \textbf{R3}, a configuration is chosen randomly from this subset (in this case configuration~3). This attempt also fails, and on the third attempt only configurations 4--8 are feasible, with 5 maximising \textbf{R3}, and the AUV adopts this configuration and succeeds in cleaning the chain.
	% \simos{TBC}
	% }
	% 	\label{fig:uuv}
	% \end{figure*}
	
	
	
	
	Fig.~\ref{fig:uuv} shows a simulated run of the AUV performing an inspection and cleaning mission (Fig.~\ref{fig:uuv}a).  At each chain that requires cleaning, the AUV decides whether to attempt to clean or skip the current chain.  
	Fig.~\ref{fig:uuv}b provides details of the probabilistic model checking carried out during the inspection and cleaning of chain~3 (Fig.~\ref{fig:uuv}a ii). 
	Overall, the AUV performed multiple attempts to clean chain~3, succeeding on the third attempt.
	
	The results of the model checking analyses for these attempts are shown in successive columns in Fig.~\ref{fig:uuv}b, while each row depicts the analysis of one of the requirements from Table~\ref{table:reqs}. 
	A system configuration is feasible if it satisfies requirements R1 --- the AUV will not encounter a catastrophic failure with a probability of at least 0.95, and R2 --- the expected energy consumption does not exceed the remaining AUV energy. 
	Lastly, if multiple configurations satisfy requirements R1 and R2, then the winner is the configuration that maximises the number of chains cleaned. 
	If there is still a tie, the configuration is chosen randomly from those that clean the most chains.
	% if multiple configurations satisfy requirements R1 and R2, then the configuration that maximises R3 --- maximal chains cleaned, is selected. 
	% The AUV controller is concerned with cleaning the maximum number of chains and ensuring the AUV returns safely. Therefore, if the configurations satisfying with R1 and R2 and there is a tie with respect to R3 a winning configuration is chosen randomly from this subset.  
	
	In the AUV's first attempt at chain~3 (Fig.~\ref{fig:uuv}{b (i, ii, iii)}), all the configurations are feasible, so configuration 1 (highlighted, and corresponding to the highest number of chains cleaned) is selected. 
	This attempt fails, and a second assessment is made (Fig.~\ref{fig:uuv}{b (iv, v, vi)}). 
	This time, only system configurations 2--8 are feasible, and as configurations~2, 3, and~5 maximise R3, a configuration is chosen randomly from this subset (in this case, configuration~3). 
	This attempt also fails, and on the third attempt (Fig.~\ref{fig:uuv}{b (vii, viii, ix)}), only configurations 4--8 are feasible, with 5 maximising R3, and the AUV adopts this configuration and succeeds in cleaning the chain.
	
	In this AUV mission instance, the AUV controller is concerned with cleaning the maximum number of chains and ensuring the AUV returns safely.
	In other variants of our AUV mission, the system properties from requirements R1 and R2 could also be used to determine a winning configuration in the event of a tie between multiple feasible configurations. For example, it might be optimal for the AUV to consume minimal energy in this scenario. Thus, the energy consumption from requirement R2 can be used as a metric to choose a configuration as a tie-breaker.
	
	We also measured the overheads associated with executing the online verification process. 
	Figure~{\ref{fig:verification}} shows the computation overheads incurred by the RBV framework for executing the AUV-based mission. 
	The values comprising each boxplot have been collected over 10 independent runs. Each value denotes the time consumed for a single online robust quantitative verification and reconfiguration step when the AUV attempts to clean the indicated chain. 
	For instance, the boxplot associated with the `Chain 1' (`Chain 2') label on the x-axis signifies that the AUV attempts to clean chain 1  (chain 2) and corresponds to the time consumed by the RBV framework to analyse 64 (32) configurations. 
	Overall, the time overheads are reasonable for the purpose of this mission.
	Since the AUV has more configurations to analyse at the earlier stages of the mission (e.g., when inspecting chain 1), the results follow the anticipated exponential pattern. 
	The number of configurations decreases by half each time the AUV progresses further into the mission and moves to the next chain.  
	Another interesting observation is that the length of each boxplot is small, i.e., the lower and upper quartiles are very close, indicating that the RBV framework showcases a consistent behaviour in the time taken for its execution.
	
	
	The consumed time comprises (1) the time required to compute the posterior estimate bounds of the modelled transition rates,  $r_i^\textrm{clean}$, $r^{\textrm{fail}}$, $1 \leq i \leq k$, and  $r^{\textrm{damage}}$, using the BIPP and IPSP estimators; (2) the time required to compute the value intervals for requirements R1 and R2 using the probabilistic model checker \textsc{Prism- Psy}~{\cite{ceska_prism_psy_2016}}; and (3) the time needed to find the best configuration satisfying requirements R1 and R2, and maximising requirement R3. 
	Our empirical analysis provided evidence that the execution of the BIPP and IPSP estimators and the  selection of the best configuration have negligible overheads with almost all time incurred by \textsc{Prism-Psy}. 
	This outcome is not surprising and is aligned with the results reported in~{\cite{ceska_prism_psy_2016}} concerning the execution overheads of the model checker.
	
	The simulator used for the AUV mission, developed on top of the open-source MOOS-IvP middleware,~\cite{Benjamin2013MRO} and a video showing the execution of this AUV mission instance are available at~\url{http://github.com/gerasimou/RBV}.
	
	
	\begin{figure}[t]
		\centering
		\includegraphics[width=\linewidth]{images/verificationTimes.pdf}
		\caption{\textbf{Verification time overheads. }
			Time taken by our robust Bayesian verification framework to execute the online quantitative verification and reconfiguration step over 10 independent runs when the robot attempts to clean the indicated chain.}
		\label{fig:verification}
	\end{figure}
	
	% \textcolor{blue}{Experimental results to report: a detailed description of one mission; scalability (as the number of chains increases)?; what is the effect of changing the level of confidence placed in the priors, or other parameters? or the value of $m$ for the BIPP estimator? should we examine what happens if the ground truth changes (leading to different observations)?}
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section{Discussion \& Conclusions}
	
	Unlike %existing approaches, which mostly do 
	single-point estimators of Markov model parameters \cite{epifani_model_2009,filieri_formal_2012,calinescu_adaptive_2014,filieri_lightweight_2015}, our Bayesian framework provides interval estimates that capture the inherent uncertainty of these parameters, enabling the robust quantitative verification of systems such as autonomous robots. Through its ability to exploit prior knowledge, the framework differs fundamentally from, and is superior to, a recently introduced approach to synthesising intervals for unknown transition parameters based on the frequentist theory of simultaneous confidence intervals.~\cite{calinescu_2016_formal,10.1007/978-3-662-49674-9_32,calinescu2017rodes} Furthermore, instead of applying the same estimator to all Markov model transition parameters like existing approaches, our framework is the first to handle parameters corresponding to singular and regular events differently. This is an essential distinction, especially for the former type of parameter, for which the absence of observations violates a key premise of existing estimators. Our BIPP estimator avoids this invalid premise, and computes two-sided bounded estimates for singular CTMC transition rates---a considerable extension of our preliminary work to devise one-sided bounded estimates for the singular transition probabilities of discrete-time Markov chains.~\cite{zhao_probabilistic_2019}
	
	The proposed Bayesian framework is underpinned by the theoretical foundations of imprecise probabilities \cite{walter_imprecision_2009,walter_bayesian_2017} and Conservative Bayesian Inference (CBI), \cite{bishop_toward_2011,strigini_software_2013,zhao_assessing_2020} integrated with recent advances in the verification of interval CTMCs.~\cite{ceska_prism_psy_2016} In particular, our BIPP theorems for singular events extend CBI significantly in several ways. First, BIPP operates in the continuous domain for a Poisson process, while previous CBI theorems are applicable to Bernoulli processes in the discrete domain. As such, BIPP enables the runtime quantitative verification of interval CTMCs, and thus the analysis of important properties that are not captured by discrete-time Markov models. Second, CBI is one-side (upper) bounded, and therefore % bounded assuming the upper bound is always being conservative for 
	only supports the analysis of undesirable singular events (e.g., catastrophic failures). In contrast, BIPP provides two-sided bounded estimates, therefore also enabling the analysis of ``positive'' singular events (e.g., the completion of difficult one-off tasks). Finally, BIPP can operate with any  \textit{arbitrary} number of confidence bounds as priors, which greatly increases the flexibility of exploiting different types of prior knowledge. 
	%Given CBI has been shown useful in a wider context than PMC, e.g., \cite{zhao_conservative_2018,zhao_modeling_2017,zhao_assessing_2019}, we believe the new BIPP may also contribute to wider statistical inference problems. 
	
	As illustrated by its application to an AUV infrastructure maintenance mission, our robust quantitative verification framework removes the need for 
	%
	%We illustrated our robust estimators in a robotics runtime verification case study which is publicly accessible at \url{https://the_git_hub_page_XXXX}. \xingyu{More descriptions here on the case study results once we got them.}
	%
	% We conclude our robust estimators remove 
	%the major difficulty of trusting more 
	precise prior beliefs, which are typically unavailable in many real-world verification tasks that require Bayesian inference. Instead, the framework enables the exploitation of Bayesian combinations of partial or imperfect prior knowledge, which it uses to derive informed estimation errors (i.e., intervals) for the predicted model parameters. Combined with existing techniques for obtaining this prior knowledge, e.g., the Delphi method and its variants~\cite{ishikawa1993max} or reference class forecasting~\cite{flyvbjerg2008curbing}, the framework increases the trustworthiness of Bayesian inference in highly uncertain scenarios such as those encountered in the verification of autonomous robots.
	
	Based on recent survey papers {\cite{araujo_testing_2023,luckcuck_formal_2019,gleirscher_new_2019}} that provide in-depth discussions on the challenges and opportunities in the field of autonomous robot verification, it has become evident that a common taxonomy emerges, primarily revolving around two key dimensions. The first dimension centres on the specification of properties under verification, which includes various types of temporal logic languages.~{\cite{araujo_testing_2023}} The second dimension pertains to how system behaviours are modeled/structured. In this regard, formal models such as Belief Desire Intention, Petri Nets, and finite state machines, along with their diverse extensions, have emerged as popular approaches to capturing the intricate dynamics of autonomous systems. Our approach falls within the category of methods utilising CSL and CTMCs for the verification of robots. However, unlike the existing methods from this category~{\cite{gerasimou_undersea_2017,younes_numerical_2006}}, we introduced treatments of the model parameters uncertainty via robust Bayesian learning methods, and integrated them with recent research on interval CMTC model checking.
	
	Another important approach for verifying the behaviour of autonomous agents under uncertainty uses hidden Markov models (HMMs).~{\cite{zhang2005logic,hernandez_marimba_2015,WEI2002129}} HMM-based verification supports the analysis of stochastic systems whose true state is not observable, and can only be estimated (with aleatoric uncertainty given by a predefined probability distribution) through monitoring a separate process whose observable state depends on the unknown state of the system. In contrast, our verification framework supports the analysis of autonomous agents whose true state is observable but for which the rates of transition between these known states are affected by epistemic uncertainty and need to be learnt from system observations (as shown in Figure~\ref{fig:integration}). As such, HMM-based verification and our robust verification framework differ substantially by tackling different types of autonomous agent uncertainty. Because autonomous agents may be affected by both types of uncertainty, the complementarity of the two verification approaches can actually be leveraged by using our BIPP and IPSP Bayesian estimators in conjunction with HMM-based verification, i.e., to learn the transition rates associated with continuous-time HMMs that model the behaviour of an autonomous agent. Nevertheless, achieving this integration will first require the development of generic continuous-time HMM verification techniques since, to the best of our knowledge, only verification techniques and tools for the verification of discrete-time HMMs are currently available.
	
	\if 0
	{While our work uses Bayesian estimators to estimate CTMCs parameters based on observations at runtime which may seem similar to Hidden Markov Models (HMMs), it is important to note the distinctions between our approach and the verification framework based on Hidden Markov Models, as follows.
		The work in {\cite{zhang2005logic}} (and its tool paper {\cite{hernandez_marimba_2015}}) appears to be the first doing formal verification based on discrete-time HMMs. To the best of our knowledge, there is no formal verification framework based on \textit{continuous-time} HMM, although there is a significant body of research that uses continuous-time HMM to evaluate/calculate system performance in a case-by-case manner, e.g., {\cite{WEI2002129}}. Even in evaluation works using continuous-time HMM, we are not aware of any Bayesian estimators that yield interval estimates according to the two types of real-world events (regular and one-off) at runtime. More precisely, our IPSP estimator is the first one incorporating imprecise prior knowledge for regular events, and the BIPP estimator is the first that incorporates partial prior knowledge for rare events.
		Taken together, by focusing on learning the transition rates between states, our Bayesian estimators are orthogonal to the modelling paradigm and, therefore, can equally be used in conjunction with CTMC-based verification and continuous-time HMM-enabled verification.}
	\fi
	
	Although our method demonstrates promising potential, it is not without limitations. One limitation is scalability---as the complexity of the robot's behaviour and the environment grow, the number of unknown parameters to be estimated at runtime may increase, leading to increased computational overheads for our Bayesian estimators. Additionally, the method requires a certain level of expertise to construct the underlying CTMC model structure. This demands understanding both the robot's dynamics and the environment in order to model them as a CTMC, making the approach less accessible to those without specialised knowledge. Last but not least, a challenge inherent to all Bayesian methods involves the acquisition of appropriate priors. While our robust Bayesian estimators mitigate this issue by eliminating the need for complete and precise prior knowledge, establishing the required partial and vague priors can still pose challenges. These limitations suggest important areas for future work.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section{Methods}
	
	%% \begin{small}
	%	\noindent
	%	\textbf{4.1 Quantitative verification of CTMCs.} CTMCs are formal models for continuous-time stochastic processes over countable
	%	state spaces. We use the following definition adapted from the probabilistic model checking literature~\cite{Baier-etal-2003,Kwiatkowska2007:SFM}.
	%	
	%	\begin{definition}
	%		\label{def:CTMC}
	%		A continuous-time Markov chain is a tuple
	%		\begin{equation}
	%			\mathcal{M}\!=\!(S,s_0,\mathbf{R}),
	%			\label{eq:CTMC} 
	%		\end{equation}
	%		where $S$ is a finite set of states, $s_0\!\in\! S$ is the initial state, and $\mathbf{R}\!:\! S\!\times\! S\!\to\! \mathbb{R}$ is a transition rate matrix such that the probability that the CTMC will leave state $s_i \!\in\! S$ within $t\!>\!0$ time units is  $1\!-\!e^{-t\cdot \sum_{s_k\!\in\! S\setminus\! \{s_i\}} \mathbf{R}(s_i,s_k)}$ and the probability that the new state is $s_j\in S\setminus\{s_i\}$ is $p_{ij}=$ $\mathbf{R}(s_i,s_j)\; /\;\sum_{s_k\in S\setminus\{s_i\}}\;\! \mathbf{R}(s_i,s_k)$.
	%	\end{definition}
	%	
	%	%\noindent
	%	The range of properties that can be verified using CTMCs can be extended by annotating the states and transitions with non-negative quantities called {rewards}.
	%	
	%	\begin{definition}
	%		\label{def:rewards}
	%		A reward structure over a CTMC $\mathcal{M}\!=\!(S,s_0,$ $\mathbf{R})$ is a pair of functions $(\underline{\rho}, \bm{\iota})$ such that 
	%		$\underline{\rho} : S\to \mathbb{R}_{\geq 0}$ is a {state reward function} (a vector), and 
	%		$\bm{\iota} : S\times S\to \mathbb{R}_{\geq 0}$ is a {transition reward function} (a matrix).
	%	\end{definition}
	%	
	%	CTMCs support the verification of quantitative properties expressed in continuous stochastic logic (CSL)~\cite{aziz1996} extended with rewards~\cite{Kwiatkowska2007:SFM}. 
	%	
	%	\begin{definition}
	%		Given a set of atomic propositions $\mathit{AP}$, $a\!\in\!\mathit{AP}$, $p\! \in\! [0,1]$, $I\subseteq\mathbb{R}_{\geq 0}$, $r,t\!\in\!\mathbb{R}_{\geq 0}$ and $\bowtie\,\in\! \{\geq, >, <, \leq \}$, a CSL formula $\Phi$ is defined by the grammar:
	%		\begin{equation*}
	%			\begin{array}{ll}
	%				\!\!\!\Phi\; ::= &\hspace*{-2.3mm} true\; |\;  a\; |\; \Phi \wedge \Phi\; |\; \neg\Phi\; |\; P_{\bowtie p}[X\, \Phi]\; |\; P_{\bowtie p}[\Phi\, U^{I}\, \Phi]\; |\; \mathcal{S}_{\bowtie p}[\Phi]\; | \\
	%				&\hspace*{-2.3mm} R_{\bowtie r}[I^{=t}]\; | \; R_{\bowtie r}[C^{\leq t}]\; | \; R_{\bowtie r}[F\, \Phi]\; | \; R_{\bowtie r}[S].
	%				%\Psi ::= X \Phi\, |\, \Phi U^{I} \Phi  
	%			\end{array}
	%		\end{equation*}
	%	\end{definition}
	%	
	%	\noindent
	%	Given a CTMC $\mathcal{M}\!=\!(S,s_0,$ $\mathbf{R})$ with states {labelled} with atomic propositions from $AP$ by a function $L\! :\! S\! \to\! 2^{AP}$, and a reward structure $(\underline{\rho}, \bm{\iota})$ over $\mathcal{M}$, the CSL semantics is defined with a satisfaction relation $\models$ over the states and {paths} (i.e., feasible sequences of successive states) of $\mathcal{M}$~\cite{Baier-etal-2003}. 
	%	%
	%	The notation $s\models \Phi$ means ``$\Phi$ is satisfied in state $s$''. For any state $s\!\in\! S$, we have: 
	%	
	%	\squishlist
	%	\item $s\models true$, %; 
	%	%\item 
	%	$s \models a$ iff $a\in L(s)$, %;
	%	%\item 
	%	$s \models \neg \Phi$ iff $\neg (s\models \Phi)$, and %; 
	%	%\item 
	%	$s\models \Phi_1 \wedge \Phi_2$ iff $s\models \Phi_1$ and $s\models \Phi_2$;
	%	\item $s\models \mathcal{P}_{\bowtie p} [X\, \Phi]$ iff the probability $x$ that $\Phi$ holds in the state  following $s$ satisfies $x \bowtie p$ ({probabilistic next} formula); 
	%	%The probabilistic ``next'' formula $\mathcal{P}_{\bowtie p} [X \Phi]$ holds in a state $s$ iff the probability that $\Phi$ is true in the state that follows $s$ satisfies $\bowtie p$; 
	%	\item $s\models \mathcal{P}_{\bowtie p} [\Phi_1\, U^{I}\, \Phi_2]$ iff, across all paths starting at $s$, the probability $x$ of going through only states where $\Phi_1$ holds until reaching a state where $\Phi_2$ holds at a time $t\in I$ satisfies $x\bowtie p$  ({probabilistic until} formula);
	%	%\item The probabilistic ``until'' formula $\mathcal{P}_{\bowtie p} [\Phi_1 U^{I} \Phi_2]$ holds iff, across all paths starting at $s$, the probability $x$ of going through only states where $\Phi_1$ holds until reaching a state where $\Phi_2$ holds at a time $t\in I$ satisfies $x\bowtie p$;
	%	\item $s\models \mathcal{S}_{\bowtie p}[\Phi]$ iff, having started in state $s$, the probability $x$ of $\mathcal{M}$ reaching a state where $\Phi$ holds {in the long run} satisfies $x \bowtie p$  ({probabilistic steady-state} formula);
	%	\item the {instantaneous ($R_{\bowtie r}[I^{=t}]$), cumulative ($R_{\bowtie r}[C^{\leq t}]$), future-state ($R_{\bowtie r}[F\, \Phi]$)} and {steady-state ($R_{\bowtie r}[S]$) reward} formulae hold iff, having started in state $s$, the expected reward $x$ at time instant $t$, cumulated up to time $t$, cumulated until reaching a state where $\Phi$ holds, and achieved at steady state, respectively, satisfies $x\bowtie r$.
	%	\squishend
	%	
	%	Probabilistic model checkers such as PRISM~\cite{kwiatkowska_prism_2011} and Storm~\cite{storm2017} use efficient analysis techniques to compute the actual probabilities and expected rewards associated with probabilistic and reward formulae, respectively. The formulae are then verified by comparing the computed values to the bounds $p$ and $r$. Furthermore, the extended CSL syntax $P_{=?}[X\, \Phi]$, $P_{=?}[\Phi_1\, U^{I}\, \Phi_2]$, $R_{=?}[I^{=t}]$, etc. can be used to obtain these values from the model checkers. 
	%	
	%	While the transition rates of the CTMCs verified in this way must be known and constant, advanced quantitative verification techniques~\cite{brim-etal-2013} support the analysis of CTMCs whose transition rates are specified as intervals. The technique has been used to synthesise CTMCs corresponding to process configurations and system designs that satisfy quantitative constraints and optimisation criteria~\cite{calinescu_efficient_2018,ceska_prism_psy_2016,calinescu2017rodes}, under the assumption that these bounded intervals are available. %In the next section we introduce a Bayesian framework for computing these intervals.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\medskip
	\hypertarget{bippProof}{}
	\noindent
	\subsection{BIPP estimator proofs.} To prove Theorem~\ref{theorem_BIPP_bounds}, we require the following preliminary results.
	
	\begin{lemma}
		\label{lemma_concave}
		If $l(\cdot)$ is the likelihood function defined in \eqref{eq_likelihood_f}, then $g:(0,\infty)\rightarrow \mathbb{R}$, $g(w)=w \cdot l^{-1}(w)$ is a concave function.
	\end{lemma}
	\begin{proof}
		Since $g(w)=w\cdot \left(-\frac{\ln w}{t}\right)$ and $t>0$, the second derivative of $g$ satisfies 
		%		the second derivative of it is (note, $t>0$):
		\begin{align}
		\frac{d^2 g}{dw^2}=\frac{d}{dw}\left[-\frac{\ln w}{t}-\frac{1}{t}\right]=-\frac{1}{wt}<0.
		\end{align}
		Thus, $g(w)$ is concave.
	\end{proof}
	
	
	\begin{proposition} %[BIPP-upper]
		\label{prop_BIPP_m_point_for_upper_bound}
		With the notation from Theorem~\ref{theorem_BIPP_bounds}, there exist $m$ values $\lambda_1\!\in\!(\epsilon_0,\epsilon_1]$, $\lambda_2\!\in\!(\epsilon_1,\epsilon_2]$, \ldots, $\lambda_m\!\in\!(\epsilon_{m-1},\epsilon_m]$ such that $\sup\; {\mathcal S}_\lambda$ is the posterior estimate~(\ref{eq_posterior_mean_lambda}) obtained by using as prior the $m$-point discrete distribution with probability mass $f(\lambda_i)=\mathit{Pr}(\lambda=\lambda_i)=\theta_i$ for $i=1,2,\ldots,m$. 
	\end{proposition}
	\begin{proof}
		\label{proof_theorem_BIPP_m_point_for_upper_bound}
		%As we are dealing with a discrete distribution, t
		Since $f(\lambda)=0$ for $\lambda\notin [\epsilon_0,\epsilon_m]$, the Lebesgue-Stieltjes integration from the objective function \eqref{eq_posterior_mean_lambda} can be rewritten as:
		%
		\begin{equation}
		\E(\Lambda \mid \text{data})
		=\frac{\sum\limits_{i=1}^{m}\int_{\epsilon_{i-1}}^{\epsilon_i}\lambda l(\lambda)  f(\lambda)\diff \lambda}{\sum\limits_{i=1}^{m}\int_{\epsilon_{i-1}}^{\epsilon_i} l(\lambda)  f(\lambda)\diff \lambda}
		\label{eq_OB_in_proof}
		\end{equation}
		%
		The first mean value theorem for integrals (e.g.\ \cite[p.~249]{zwillinger_table_2015}) ensures that, for every $i=1,2,\ldots,m$,
		there are points $\lambda_i, \lambda'_{i} \in [\epsilon_{i-1},\epsilon_{i}]$ such that:
		\begin{align}
		\int_{\epsilon_{i-1}}^{\epsilon_i} l(\lambda)f(\lambda) \diff \lambda &=l(\lambda_i)\int_{\epsilon_{i-1}}^{\epsilon_i} f(\lambda) \diff \lambda= l(\lambda_i) \theta_i
		\label{eq_mean_val_theory1}
		\\
		\int_{\epsilon_{i-1}}^{\epsilon_i} \lambda l(\lambda)f(\lambda) \diff \lambda &=\lambda'_{i}l(\lambda'_{i})\int_{\epsilon_{i-1}}^{\epsilon_i} f(\lambda) \diff \lambda=\lambda'_{i} l(\lambda'_{i}) \theta_i
		\label{eq_mean_val_theory2}
		\end{align}
		%where $\epsilon_{i-1} \leq \lambda_i \leq \epsilon_i$ and $\epsilon_{i-1} \leq  \lambda_{m+i} \leq \epsilon_i$. 
		or, after simple algebraic manipulations of the previous results, %Rearrange the equations above, we have:
		\begin{align}
		l(\lambda_i)&=\E[l(\Lambda) \mid \epsilon_{i-1}\leq \Lambda \leq \epsilon_i ]
		\\
		\lambda'_{i} l(\lambda'_{i})&=\E[\Lambda \cdot l(\Lambda) \mid \epsilon_{i-1}\leq \Lambda \leq \epsilon_i ]
		\label{eq_temp_mark}
		\end{align}
		
		\noindent
		Using the shorthand notation $w=l(\lambda)$ for the likelihood function \eqref{eq_likelihood_f} (hence $w>0$), we define $g:(0,\infty)\rightarrow \mathbb{R}$, $g(w)=w \cdot l^{-1}(w)$. According to Lemma~\ref{lemma_concave}, $g(\cdot)$ is a concave function, and thus we have:
		%If we denote the likelihood function \eqref{eq_likelihood_f} as $w=l(\lambda)$ (thus, $w>0$), and introduce a new function $g(w):=w \cdot l^{-1}(w)$, then $g(\cdot)$ is a concave function (cf. Lemma \ref{lemma_concave}), we know\footnote{The initial idea of applying Jensen's Inequality of step \eqref{eq_Jensen_inequality} is credited to Dr. Andrey Povyakalo who firstly utilises it in \cite{bishop_toward_2011}.}:
		\begin{align}
		\lambda'_{i} l(\lambda'_{i}) 
		& = \E[\Lambda \cdot l(\Lambda) \mid \epsilon_{i-1}\leq \Lambda \leq \epsilon_i ] \nonumber
		\\
		&=\E[ W \cdot l^{-1}(W) \mid \epsilon_{i-1} \leq l^{-1}(W) \leq \epsilon_i] \nonumber
		\\
		&=\E[g(W) \mid \epsilon_{i-1} \leq l^{-1}(W) \leq \epsilon_i] \nonumber
		\\
		&\leq g\left(\E[ W \mid\epsilon_{i-1} \leq l^{-1}(W) \leq \epsilon_i]\right) \label{eq_Jensen_inequality}
		\\
		&= \E[ W\! \mid \epsilon_{i-1} \leq l^{-1}(W) \leq \epsilon_i] \cdot \nonumber\\
		& \hspace*{15mm} l^{-1}\!\left( \E[ W \!\mid\epsilon_{i-1} \leq l^{-1}(W) \leq \epsilon_i] \right)
		\nonumber
		\\
		&=\E[ l(\Lambda) \mid \epsilon_{i-1} \leq \Lambda \leq \epsilon_i] \cdot l^{-1}\left( \E[l(\Lambda) \mid \epsilon_{i-1} \leq \Lambda \leq \epsilon_i] \right) \nonumber
		\\
		&=l(\lambda_i) \cdot l^{-1}\left( l(\lambda_i)\right) \nonumber
		\\
		&=  \lambda_i \cdot l(\lambda_i),
		\label{eq_inequality}
		\end{align}
		where the inequality step \eqref{eq_Jensen_inequality} is obtained by applying Jensen's inequality.\cite{jensen_sur_1906,
			bishop_toward_2011}
		
		We can now use 
		%Now, by the results of 
		\eqref{eq_mean_val_theory1}, \eqref{eq_mean_val_theory2} and \eqref{eq_inequality} to establish an upper bound for the objective function~\eqref{eq_OB_in_proof}: %can be bounded by:
		
		\begin{align}
		\E(\Lambda \mid \text{data})
		&=\frac{\sum\limits_{i=1}^{m} \lambda'_{i}l(\lambda'_{i})\theta_i}
		{\sum\limits_{i=1}^{m} l(\lambda_{i})\theta_i} \leq \frac{\sum\limits_{i=1}^{m} \lambda_{i}l(\lambda_{i})\theta_i}
		{\sum\limits_{i=1}^{m} l(\lambda_{i})\theta_i}
		\label{eq_reachable_bound}
		\end{align}
		%
		This upper bound 
		%Clearly the bound of \eqref{eq_reachable_bound} 
		is attained %when one chooses 
		by selecting an $m$-point discrete distribution $f_u(\lambda)$ with probability mass $\theta_i$ at $\lambda=\lambda_i$, for $i=1,2,\ldots,m$ (since substituting $f(\cdot)$ from \eqref{eq_OB_in_proof} with this $f_u(\cdot)$ yields the rhs result of \eqref{eq_reachable_bound}). %where $\epsilon_{i-1} \leq \lambda_i \leq \epsilon_i $. 
		%Now, to further maximise the bound of \eqref{eq_reachable_bound}, 
		As such, maximising this bound 
		%the problem is 
		reduces to an optimisation problem in the $m$-dimensional space of $(\lambda_1,\lambda_2,\ldots,\lambda_m)\in(\epsilon_0,\epsilon_1]\times(\epsilon_1,\epsilon_2]\times\cdots\times(\epsilon_{m-1},\epsilon_m]$.
		%s (the only constraints are the range of each $\lambda_i$),
		This optimisation problem can be solved numerically, %given the other model parameters, 
		yielding a supremum (rather than a maximum) for $\mathcal{S}_\lambda$ in the case when the optimised prior distribution has points located at $\lambda_{i}=\epsilon_{i-1}$ for  $i=1,2,\ldots,m$.
		%Note, the range of each $\lambda_{i}$ defined by \eqref{eq_prior_constraints} is $\epsilon_{i-1} < \lambda_i \leq \epsilon_i$, thus the posterior estimates is a supremum (rather than a maximum) of $\mathcal{S}_\lambda$ when the optimised prior distribution has points located at $\lambda_{i}=\epsilon_{i-1}$.
	\end{proof}
	
	\begin{proposition}
		\label{prop_BIPP_m_point_for_lower_bound}
		With the notation from Theorem~\ref{theorem_BIPP_bounds}, there exist $m$ values $x_1,x_2,\ldots,x_m\in[0,1]$ such that $\inf \mathcal{S}_\lambda$ is the posterior estimate~(\ref{eq_posterior_mean_lambda}) obtained by using as prior the $(m+1)$-point discrete distribution with probability mass $f(\epsilon_0)=\mathit{Pr}(\lambda=\epsilon_0)=x_1\theta_1$,  $f(\epsilon_i)=\mathit{Pr}(\lambda=\epsilon_i)=(1-x_{i})\theta_{i}+x_{i+1}\theta_{i+1}$ for $1\leq i<m$, and $f(\epsilon_m)=\mathit{Pr}(\lambda=\epsilon_m)=(1-x_m)\theta_m$.
	\end{proposition}
	\begin{proof}
		We reuse the reasoning steps from Proposition~\ref{prop_BIPP_m_point_for_upper_bound} up to  inequality \eqref{eq_Jensen_inequality}, which we replace with the following alternative inequality derived from the Converse Jensen's Inequality \cite{lah_converse_1973,bakula_converse_2012} and the fact that $g(w)$ is a concave function (cf. Lemma \ref{lemma_concave}):
		\begin{align}
		\textrm{\hspace*{-2.7mm}}\lambda'_{i} l(\lambda'_{i}) 
		%&= \E[\Lambda \cdot l(\Lambda) \mid \epsilon_{i-1}\leq \Lambda \leq \epsilon_i ] \nonumber
		%\\
		%&=\E[ W \cdot l^{-1}(W) \mid \epsilon_{i-1} \leq l^{-1}(W) \leq \epsilon_i] \nonumber
		%\\
		&=\E[g(W) \mid \epsilon_{i-1} \leq l^{-1}(W) \leq \epsilon_i] \nonumber
		\\
		&\geq \frac{l(\epsilon_{i-1})-\E[W \mid \epsilon_{i-1} \leq l^{-1}(W) \leq \epsilon_i ]}{l(\epsilon_{i-1})-l(\epsilon_i)}g(l(\epsilon_i))  \nonumber\\
		&\quad+\frac{\E[W \mid \epsilon_{i-1} \leq l^{-1}(W) \leq \epsilon_i]-l(\epsilon_i)}{l(\epsilon_{i-1})-l(\epsilon_i)}g(l(\epsilon_{i-1})) \nonumber
		\\
		&=\frac{l(\epsilon_{i-1})-l(\lambda_{i})}{l(\epsilon_{i-1})-l(\epsilon_i)}\epsilon_i l(\epsilon_i)+\frac{l(\lambda_{i})-l(\epsilon_i)}{l(\epsilon_{i-1})-l(\epsilon_i)}\epsilon_{i-1}l(\epsilon_{i-1})
		\label{eq_converse_inequality}
		\end{align}
		%
		We can now establish a lower bound for~\eqref{eq_OB_in_proof}:
		
		
		\begin{align}
		\E(\Lambda \mid \text{data})
		&=\frac{\sum\limits_{i=1}^{m} \lambda'_{i}l(\lambda'_{i})\theta_i}
		{\sum\limits_{i=1}^{m} l(\lambda_{i})\theta_i} \nonumber
		\\
		&\hspace*{-12mm}
		\geq \frac{\sum\limits_{i=1}^{m} \left(\frac{l(\epsilon_{i-1})-l(\lambda_{i})}{l(\epsilon_{i-1})-l(\epsilon_i)}\epsilon_i l(\epsilon_i)+\frac{l(\lambda_{i})-l(\epsilon_i)}{l(\epsilon_{i-1})-l(\epsilon_i)}\epsilon_{i-1}l(\epsilon_{i-1})\right)\theta_i}
		{\sum\limits_{i=1}^{m} l(\lambda_{i})\theta_i}
		\\
		&=\frac{\sum\limits_{i=1}^{m} \left[\epsilon_i l(\epsilon_i)(1-x_i)\theta_i+\epsilon_{i-1}l(\epsilon_{i-1})x_i\theta_i\right]}
		{\sum\limits_{i=1}^{m} [l(\epsilon_{i})(1-x_i)\theta_i+l(\epsilon_{i-1})x_i\theta_i]}
		\label{eq_reachable_lower_bound}
		\end{align}
		where $x_i$ is defined as:%\footnote{The initial observation of introducing the neat ratio $x_i$ is credited to Kizito Salako in \cite{salako_loss_2020}.\xingyu{I wonder if we still need this footnote...}
		\begin{equation}
		x_i=\frac{l(\lambda_{i})-l(\epsilon_i)}{l(\epsilon_{i-1})-l(\epsilon_i)}
		\label{eq_ri_def}
		\end{equation}
		
		The result \eqref{eq_reachable_lower_bound} is essentially in the same form as the result obtained by using a $2m$-point distribution in which, for each interval $[\epsilon_{i-1},\epsilon_{i}]$, there are two points located at $\lambda=\epsilon_{i-1}$ and $\lambda=\epsilon_{i}$ and the probability mass associated with these points is $x_i\theta_i$ and $(1-x_i)\theta_i$ respectively. Intuitively, $x_i$ is the ratio of splitting the probability mass $\theta_i$ between the two points since, according to~\eqref{eq_ri_def},  $x_i \in [0,1]$.
		
		Furthermore, the points on the boundaries of two successive intervals are overlapping, which effectively reduces the number of points from $2m$ to $m+1$. Expanding~\eqref{eq_reachable_lower_bound} yields an $(m+1)$-point discrete distribution $f_l(\lambda)$ with probability mass $f_l(\epsilon_0)=x_1\theta_1$,  $f_l(\epsilon_i)=(1-x_{i})\theta_{i}+x_{i+1}\theta_{i+1}$ for $1\leq i<m$ and $f_l(\epsilon_m)=(1-x_m)\theta_m$. As such, minimising~\eqref{eq_reachable_lower_bound} reduces to an $m$-dimensional optimisation problem in $x_1,x_2,\ldots,x_m$, which can be solved numerically given other model parameters. Finally, since~\eqref{eq_prior_constraints} requires that $\epsilon_{i-1} < \lambda_i \leq \epsilon_i$, we have $0\leq x_i <1$, and thus the posterior estimate is an infimum (rather than a minimum) of $\mathcal{S}_\lambda$ when the solution of the optimisation problem corresponds to a combination of $x_1,x_2,\ldots,x_m$ values that includes one or more values of $1$.	
	\end{proof}
	
	\noindent We can now prove the main theoretical result from Section~1.2. In the supplementary material, we use this result to prove Corollaries~\ref{corollary_closed_form_BIPP_3} and~\ref{corollary_closed_form_BIPP_2}.
	
	\renewenvironment{proof}{\medskip\noindent{\bfseries Proof of Theorem~\ref{theorem_BIPP_bounds}.}}{\qed\smallskip}
	\begin{proof}
		Propositions~\ref{prop_BIPP_m_point_for_upper_bound} and~\ref{prop_BIPP_m_point_for_lower_bound} imply that the set of posterior estimates $\lambda$ over all priors that satisfy the constraints~\eqref{eq_prior_constraints} has:
		\begin{enumerate}
			\item the infinum $\lambda_l$ from~\eqref{eq_reachable_BIPP_lower_bound}, obtained by using the prior $f(\lambda)$ from Proposition~\ref{prop_BIPP_m_point_for_lower_bound} in~\eqref{eq_posterior_mean_lambda};
			\item the supremum $\lambda_u$ from~\eqref{eq_reachable_BIPP_upper_bound}, obtained by using the prior $f(\lambda)$ from Proposition~\ref{prop_BIPP_m_point_for_upper_bound} in \eqref{eq_posterior_mean_lambda}.
		\end{enumerate}
		
		\vspace*{-2mm}
	\end{proof}
	\renewenvironment{proof}{\medskip\noindent{Proof.}}{\qed\smallskip}
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\medskip
	\hypertarget{ipspProof}{}
	\noindent
	\subsection{IPSP estimator proofs.} A formal proof for the results from~\eqref{eq_post_lower_bound_rij} and~\eqref{eq_post_upper_bound_rij} is provided below.
	
	\renewenvironment{proof}{\medskip\noindent{\bfseries Proof of Theorem~\ref{theorem_CTMC_IPSP}.}}{\qed\smallskip}
	\begin{proof}
		To find the extrema for the posterior rate $\lambda^{(t)}$, we first differentiate~\eqref{eq_posterior_rate_gamma} with respect to $\lambda^{(0)}$: 
		\[
		\frac{d}{d \lambda^{(0)}} \left(\lambda^{(t)}\right) = \frac{t^{(0)}}{t+t^{(0)}}.
		\]
		As $t^{(0)}>0$ and $t>0$, this derivative is always positive, so \begin{equation}
		\underline{\lambda}^{(t)}=\min_{t^{(0)}\in[\underline{t}^{(0)},\overline{t}^{(0)}]} \frac{t^{(0)}\underline{\lambda}^{(0)}+n}{t^{(0)}+t}
		\label{eq:th2-step1a}
		\end{equation}
		and 
		\begin{equation}
		\overline{\lambda}^{(t)}=\max_{t^{(0)}\in[\underline{t}^{(0)},\overline{t}^{(0)}]} \frac{t^{(0)}\overline{\lambda}^{(0)}+n}{t^{(0)}+t}.
		\label{eq:th2-step1b}
		\end{equation}
		We now differentiate the quantity that needs to be minimised in~\eqref{eq:th2-step1a} with respect to $t^{(0)}$:
		\[
		\frac{d}{d t^{(0)}} \left(\frac{t^{(0)}\underline{\lambda}^{(0)}+n}{t^{(0)}+t}\right) = \frac{\underline{\lambda}^{(0)}(t^{(0)}+t)-(t^{(0)}\underline{\lambda}^{(0)}+n)\cdot 1}{(t^{(0)}+t)^2} = \frac{\underline{\lambda}^{(0)}t-n}{(t^{(0)}+t)^2},
		\]
		As this derivative is non-positive for $\underline{\lambda}^{(0)}\in\left(0,\frac{n}{t}\right]$ and positive for $\underline{\lambda}^{(0)}>\frac{n}{t}$, the minimum from~\eqref{eq:th2-step1a} is attained for $t^{0}=\overline{t}^{(0)}$ in the former case, and for $t^{0}=\underline{t}^{(0)}$ in the latter case, which yields the result from~\eqref{eq_post_lower_bound_rij}.
		Similarly, the derivative of the quantity to maximise in~\eqref{eq:th2-step1b}, i.e., 
		\[
		\frac{d}{d t^{(0)}} \left(\frac{t^{(0)}\overline{\lambda}^{(0)}+n}{t^{(0)}+t}\right) = \frac{\overline{\lambda}^{(0)}t-n}{(t^{(0)}+t)^2},
		\]
		is non-positive for $\overline{\lambda}^{(0)}\in\left(0,\frac{n}{t}\right]$ and positive for $\overline{\lambda}^{(0)}>\frac{n}{t}$, so the maximum from~\eqref{eq:th2-step1b} is attained for $t^{0}=\underline{t}^{(0)}$ in the former case, and for $t^{0}=\overline{t}^{(0)}$ in the latter case, which yields the result from~\eqref{eq_post_upper_bound_rij} and completes the proof.
	\end{proof}
	\renewenvironment{proof}{\medskip\noindent{Proof.}}{\qed\smallskip}
	
	
	% calibration, hyperparameter analysis
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\medskip
	\noindent
	\subsection{BIPP estimator evaluation.} 
	Fig.~\ref{fig:bippResults} shows the results of experiments we carried out to evaluate the BIPP estimator in scenarios with $m=3$ (Figs.~\ref{fig:BIPPResultsA}--\ref{fig:BIPPResultsC}) and $m=2$ (Fig.~\ref{fig:BIPPResultsD}) confidence bounds by varying the characteristics of the partial prior knowledge. 
	For $m=3$, the upper bound computed by the estimator exhibits a three-stage behaviour as the time over which no singular event occurs increases. These stages correspond to the three $\lambda_u$ regions from \eqref{eq:closed-form-upper-bound}. They start with a steep $\lambda_u$ decrease for $t < \frac{1}{\epsilon_2}$ in stage~1, followed by a slower $\lambda_u$ decreasing trend for $\frac{1}{\epsilon_2} \leq t \leq \frac{1}{\epsilon_1}$ in stage~2, and approaching the asymptotic value $\frac{\epsilon_1(\theta_1+\theta_2)}{\theta_1}$ as the mission progresses through stage~3.  
	Similarly, the lower bound $\lambda_l$ demonstrates a two-stage behaviour, as expected given its two-part definition~\eqref{eq:closed-form-lower-bound}, 
	with the overall value approaching 0 as the mission continues and no singular event modelled by this estimator (e.g., a catastrophic failure) occurs. 
	
	
	Fig.~\ref{fig:BIPPResultsA} shows the behaviour of the estimator for different $\theta_1$ values and fixed $\theta_2$, $\epsilon_1$ and $\epsilon_2$ values. 
	For  higher $\theta_1$ values, more probability mass is allocated to the confidence bound  $(\epsilon_0, \epsilon_1]$, yielding a steeper decrease in the upper bound $\lambda_u$ and a lower $\lambda_u$ value at the end of the mission.  
	The lower bound $\lambda_l$ presents limited variability across the different $\theta_1$ values, becoming almost constant and close to $0$ as $\theta_1$ increases. 
	
	
	A similar decreasing pattern is observed in Fig.~\ref{fig:BIPPResultsB}, which depicts the results of experiments with $\theta_1, \epsilon_1$ and $\epsilon_{2}$ fixed, and $\theta_2$ variable.
	The upper bound $\lambda_u$ in the long-term is larger for higher $\theta_2$ values, resulting in a wider posterior estimate bound as $\lambda_u$ converges towards its theoretical asymptotic value. 
	
	
	Allocating the same probability mass to the confidence bounds, i.e., $\theta_1 = \theta_2 = 0.3$ and changing the prior knowledge bounds $\epsilon_1$ and $\epsilon_2$ affects greatly the behaviour of the BIPP estimator (Fig.~\ref{fig:BIPPResultsC}). 
	When $\epsilon_1$ and $\epsilon_2$ have relatively high values compared to the duration of the mission (e.g., see the first three plots in Fig~\ref{fig:BIPPResultsC}), the upper bound $\lambda_u$ of the BIPP estimator rapidly converges to its asymptotic value, leaving no room for subsequent improvement as the mission progresses. 
	Similarly, the earlier the triggering point for switching between the two parts of the lower bound $\lambda_l$ calculation~\eqref{eq:closed-form-lower-bound}, the earlier $\lambda_l$ reaches a plateau close to 0. 
	
	
	Finally, Fig.~\ref{fig:BIPPResultsD} shows experimental results for the special scenario comprising only $m=2$ confidence bounds. In this scenario, replacing $\theta_2=0$ in~\eqref{eq:closed-form-lower-bound} as required by Corollary~\ref{corollary_closed_form_BIPP_2} gives a constant lower bound $\lambda_l = 0$ irrespective of the other BIPP estimator parameters. 
	As expected, the upper bound $\lambda_u$ demonstrates a twofold behaviour, featuring a rapid decrease until $t=\frac{1}{\epsilon1}$, followed by a steady state behaviour where $\lambda_u = \frac{\epsilon_1}{\theta_1}$. 
	% \simos{Check this\xingyu{Looks correct to me, refereing to Proposition 1 and 2 \url{https://www.overleaf.com/project/5ded9194bf9c85000170856d}}}
	
	
	
	
	\begin{figure*}[t!]
		\centering
		\begin{subfigure}[!ht]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/BIPPResultsA2.pdf}
			\vspace*{-5mm}
			\caption{BIPP estimator for $m=3$, $\theta_1  \in \{0.1, 0.3, 0.6, 0.8\}$, $\theta_2=0.1$, $\epsilon_1=\frac{1}{5000}$, $\epsilon_2=\frac{1}{1000}$
			}
			\label{fig:BIPPResultsA}
		\end{subfigure}
		\hfill
		\vspace*{4mm}
		\begin{subfigure}[!ht]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/BIPPResultsB2.pdf}
			\vspace*{-5mm}
			\caption{BIPP estimator for $m=3$, $\theta_1=0.1$, $\theta_2 \in \{0.1, 0.3, 0.6, 0.8\}$, $\epsilon_1=\frac{1}{5000}$, $\epsilon_2=\frac{1}{1000}$
				%   		For  higher $\theta_1$ values, more probability mass is allocated 	to the confidence bound  $(\epsilon_0, \epsilon_1]$, reflecting the steeper decreasing trend in the upper bound and the lower overall value at the end of the mission. 
				%         	The lower bound has a generally decreasing trend, irrespective of $\theta_2$ until it reaches 
			}
			\label{fig:BIPPResultsB}
		\end{subfigure}
		\hfill
		\vspace*{4mm}
		\begin{subfigure}[!ht]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/BIPPResultsC2.pdf}
			\vspace*{-5mm}
			\caption{BIPP estimator for $m=3$, $\theta_1=0.3$, $\theta_2=0.3$, $\left(\epsilon_1,\epsilon_2\right)  \in \left\{\left(\frac{1}{500},\frac{1}{100}\right),\left(\frac{1}{1000},\frac{1}{500}\right),\left(\frac{1}{2000},\frac{1}{1000}\right), \left(\frac{1}{5000},\frac{1}{2000}\right)\right\}$
			}
			\label{fig:BIPPResultsC}
		\end{subfigure}
		\hfill
		\vspace*{4mm}
		\begin{subfigure}[!ht]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/BIPPResultsD2.pdf}
			\vspace*{-5mm}
			\caption{BIPP estimator for $m=2$, $\theta_1 \in \{0.3,0.5\}$, $\theta_2=0$, $\left(\epsilon_1,\epsilon_2\right)  \in \left\{\left(\frac{1}{500},\frac{1}{500}\right),\left(\frac{1}{5000},\frac{1}{5000}\right)\right\}$
			}
			\label{fig:BIPPResultsD}
		\end{subfigure}
		\caption{\textbf{Experimental analysis of the Bayesian inference using partial priors (BIPP) estimator.} Systematic experimental analysis of the BIPP estimator showing the bounds $\lambda_l$ and $\lambda_u$ of the posterior estimates for the occurrence probability of singular events for the duration of a mission. 
			Each plot shows the effect of different partial prior knowledge encoded in \eqref{eq_prior_constraints} on the calculation of the lower \eqref{eq_reachable_BIPP_lower_bound} and upper \eqref{eq_reachable_BIPP_upper_bound} posterior estimate bounds. The red circles indicate the time points when the different formulae for the lower and upper bounds in \eqref{eq:closed-form-lower-bound} and \eqref{eq:closed-form-upper-bound}, respectively, become active. 
		}
		\label{fig:bippResults}
	\end{figure*}
	
	
	\begin{figure*}[t!]
		\centering
		\begin{subfigure}[!ht]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/IPSPResultsA_VayingT0.pdf}
			\caption{
				IPSP estimator results showing the impact of different sets of priors $[\underline{t}^{(0)},\overline{t}\textrm{}^{(0)}]$ and $[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$. In each plot, the blue dotted line (\textcolor{blue}{$\cdots\cdot$}) and green dashed line ({\textcolor{darkgreen}{$---$}}) show the posterior estimation bounds $\underline{\lambda}^{(t)}$ and $\overline{\lambda}\textrm{}^{(t)}$ for narrow and wide $[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$ intervals, respectively. 
				Each column of plots corresponds to assigning different strength to the prior knowledge, ranging from uninformative (leftmost column) to strong belief (rightmost column). 
				The first row shows scenarios in which the actual rate $\overline{\lambda}=3$ belongs to the prior knowledge interval $[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$. 
				In the second and third rows, the prior intervals overestimate and underestimate $\overline{\lambda}$, respectively. }
			\label{fig:ipspResultsA}
		\end{subfigure}
		\hfill
		\vspace*{4mm}
		\begin{subfigure}[!ht]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/IPSPResultsB.pdf}
			\caption{IPSP estimator results illustrating the behaviour of IPSP across different actual rate values 
				$\overline{\lambda} \in \{0.03, 0.3, 3, 30\}$. The experiments were carried out for $[\underline{t}^{(0)},\overline{t}\textrm{}^{(0)}] = [1000, 1000]$ and included both narrow and wide $[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$ intervals, which are shown in blue dotted lines (\textcolor{blue}{$\cdots\cdot$}) and green dashed lines (\textcolor{darkgreen}{$---$}), respectively. In all experiments, the unknown actual rate $\overline{\lambda}$ was in the prior interval $[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$.
			}
			\label{fig:ipspResultsb}
		\end{subfigure}
		\caption{\textbf{Experimental analysis of the Bayesian inference using imprecise probability with sets of priors (IPSP) estimator. } Systematic experimental analysis of the IPSP estimator showing the bounded posterior estimators for regular events. }
		%for the duration of a mission.}
		\label{fig:ipspResults}
	\end{figure*}
	
	
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\medskip
	\noindent
	\subsection{IPSP estimator evaluation.} 
	Fig.~\ref{fig:ipspResults} shows the results of experiments we performed to analyse the behaviour of the IPSP estimator in scenarios with varying ranges for the prior knowledge
	$[\underline{t}^{(0)},\overline{t}\textrm{}^{(0)}]$ and $[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$.
	A general observation is that the posterior rate intervals $[\underline{\lambda}^{(t)},\overline{\lambda}^{(t)}]$ become narrower as the mission progresses, irrespective of the level of trust assigned to the prior knowledge, i.e., across all columns of plots (which correspond to different $[\underline{t}^{(0)},\overline{t}\textrm{}^{(0)}]$ intervals) from Fig.~\ref{fig:ipspResultsA}.
	Nevertheless, this trust level affects how the estimator incorporates observations into the calculation of the posterior interval. 
	When the trust in the prior knowledge is weak (in the plots from the leftmost columns of Fig.~\ref{fig:ipspResultsA}), the impact of the prior knowledge on the posterior estimation is low, and the IPSP calculation is heavily influenced by the observations, resulting in a narrow interval. 
	In contrast, when the trust in the prior knowledge is stronger (in the plots from the rightmost columns), the contribution of the prior knowledge to the posterior estimation becomes higher, and the IPSP estimator produces a wider interval. 
	
	
	In the experiments from the first row of plots in Fig.~\ref{fig:ipspResultsA}, the (unknown) actual rate $\overline{\lambda}=3$ belongs to the prior knowledge interval 
	$[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$. As a result, the posterior rate interval $[\underline{\lambda}^{(t)},\overline{\lambda}\textrm{}^{(t)}]$  progressively becomes narrower, approximating $\overline{\lambda}$ with high accuracy.  
	As expected, the narrower prior knowledge (blue dotted line) produces a narrower posterior rate interval than the wider and more conservative prior knowledge (green dashed line). 
	
	When the prior knowledge interval $[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$ overestimates or underestimates the actual rate $\overline{\lambda}$ (second and third rows of plots from Fig.~\ref{fig:ipspResultsA}, respectively), the ability of IPSP to adapt its estimations to reflect the observations heavily depends on the characteristics of the sets of priors. 
	For example, if the width of the prior knowledge $[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$  is close to  $\overline{\lambda}$ and $t^{(0)}\ll t$, then IPSP more easily approaches $\overline{\lambda}$, as shown by the narrow prior knowledge (blue dotted line) in {Fig~\ref{fig:ipspResultsA}} for $[\underline{t}^{(0)},\overline{t}\textrm{}^{(0)}] \in \{[5,15], [75,125], [750,1250]\}$.
	In contrast,  wider narrow prior knowledge (green dashed line) combined with higher levels of trust in the prior, e.g., $[\underline{t}^{(0)},\overline{t}\textrm{}^{(0)}] \in \{[1500,2500]\}$, entails that more observations are needed for the posterior rate to approach the actual rate $\overline{\lambda}$. When the actual rate is, in addition, nonstationary, change-point detection methods can be employed to identify these changes~\cite{epifani_change_point_2010,zhao2020interval} and recalibrate the IPSP estimator. 
	Finally, Fig.~\ref{fig:ipspResultsb} shows the behaviour of IPSP for different actual rate $\overline{\lambda}$ values, i.e., $\overline{\lambda} \in \{0.03, 0.3, 3, 30\}$. 
	As $\overline{\lambda}$ increases, more observations are produced in the same time period, resulting in a smoother and narrower posterior bound estimate.
	
	
	
	% use section* for acknowledgment
	\bigskip
	\noindent
	\textbf{Data availability}
	\ \\ \noindent
	The data supporting the RBV findings and a video of the robotic mission in simulation are available at~\url{https://gerasimou.github.io/RBV}.
	
	% use section* for acknowledgment
	\bigskip
	\noindent
	\textbf{Code availability}
	\ \\ \noindent
	All code developed in this project is freely available at~\url{http://github.com/gerasimou/RBV}.
	
	
	
	%The authors would like to thank Kizito Salako for suggesting the simplification from~\eqref{eq_ri_def} inspired by his recent research.\cite{salako_loss_2020} %% After two years, now I feel this step might be too minor to put a thank in acknowledgement, given we already have a footnote..
	
	% Can use something like this to put references on a page
	% by themselves when using endfloat and the captionsoff option.
	%\ifCLASSOPTIONcaptionsoff
	%  \newpage
	%\fi
	
	
	
	% trigger a \newpage just before the given reference
	% number - used to balance the columns on the last page
	% adjust value as needed - may need to be readjusted if
	% the document is modified later
	%\IEEEtriggeratref{8}
	% The "triggered" command can be changed if desired:
	%\IEEEtriggercmd{\enlargethispage{-5in}}
	
	% references section
	
	% can use a bibliography generated by BibTeX as a .bbl file
	% BibTeX documentation can be easily obtained at:
	% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
	% The IEEEtran BibTeX style support page is at:
	% http://www.michaelshell.org/tex/ieeetran/bibtex/
	%\bibliographystyle{IEEEtran}
	% argument is your BibTeX string definitions and bibliography database(s)
	%\bibliography{IEEEabrv,../bib/paper}
	%
	% <OR> manually copy in the resultant .bbl file
	% set second argument of \begin to the number of references
	% (used to reserve space for the reference number labels box)
	
	
	\balance
	% \bibliographystyle{plain}
	\bibliographystyle{unsrt}
	\bibliography{ref.bib}
	
	
	% \vspace*{5cm}
	% \section*{Old text for reuse}
	
	% We develop new Bayesian techniques for computing CTMC {transition rate intervals} based on prior knowledge and observations of the verified system, leveraging recent advances in interval CTMC model checking~\cite{brim-etal-2013,calinescu_efficient_2018}, i.e., probabilistic model checking of CTMCs with transition rates specified as intervals.  
	
	% A key problem in designing Bayesian verification techniques in these extreme environment settings is that some events are very rare, and have limited prior observations to base the learning on. Consider, for example, the case of rare, but damaging failures: in practice, we cannot observe sufficient data of catastrophic failures to provide good estimations, and sometimes we can only observe prior failure-free data. The reason is that even is such a failure were to happen in operation, the robot or system undergoing it would be significantly redesigned/updated, making existing failure data obsolete.
	% Conversely, in some missions, tasks are achieved with much better outcomes than the model expected from prior testing and data (e.g. NASA's Mars Opportunity rover exceeded its expected lifespan by a factor of 55~\cite{marsRovers}. 
	
	% Hence, the Bayesian learning techniques we develop support both scenarios where transitions happen regularly while the system is monitored or tested (normal operation), as well as scenarios where the transitions are observed at most once in the mission (``singular" events). To achieve this, our work joins and considerably extends existing state of the art in a number of ways:
	% \begin{itemize}
	%     \item For transition parameters representing singular events, we start with \textit{partial and limited} prior knowledge (e.g., due to sparse prior data) and extend the state of the art in Conservative Bayesian Inference -- a technique first introduced for assessing the reliability of safety-critical systems when seeing none or rare failures while avoiding optimistic biases \cite{bishop_toward_2011,littlewood_reliability_2020,strigini_software_2013,zhao_assessing_2019} -- to both negative-singular events (e.g., catastrophic failures) and positive-singular events (e.g., finishing an one-off sub-task). 
	%     \item For parameters representing regularly observed transitions, we start with \textit{sets of priors} and perform Bayesian inference based on imprecise probabilities \cite{walter_bayesian_2017,walter_imprecision_2009} to: (i) get bounded posterior estimates whose width measures estimation errors; (ii) allow modelling vague/imperfect prior data from experts/lab-simulations in a flexible way; and (iii) detect prior-data conflict \cite{evans_checking_2006} when observing surprising runtime data during the mission.
	%     \item Both Bayesian estimators are then integrated with recent advances in the automatic verification of {interval Markov chains}, e.g., PRISM-PSY \cite{ceska_prism_psy_2016}.
	% \end{itemize}
	
	%when dealing with rare events, standard Bayesian estimators tend to be inaccurate, so a key area of interest for the community has been on Conservative Bayesian Inference (CBI) methods. While CBI in robotic verification has been proposed before in a previous conference work by the authors \cite{AAAI19_Paper}, that work only only deals with discrete state spaces and....
	
	%  The paper is structured as follows. Section~\ref{sec_preliminaries} provides the required  mathematical background for introducing our methodology. % novel probabilistic model checking methods. Next, Section~\ref{sec_Bayesian_techniques} describes the core Bayesian interval estimator methods for computing CTMC transition rate intervals, while Section~\ref{sec_framework} integrates these techniques with interval model checking. %for the two transition types supported by our verification framework. The integration of these techniques with interval model checking is presented in Section~\ref{sec_framework}.
	%  Section~\ref{sec_evalution} shows the use of the framework to verify simulated autonomous robotic missions for underwater infrastructure inspection and repair, while Section~\ref{sec_conclusion} concludes with a discussion.
	
	
	
	
	%\section{Methods: Bayesian interval estimators for CTMC transition rates}
	%\label{sec_Bayesian_techniques}
	
	%\section{Bayesian interval estimators for\\ CTMC transition rates}\label{sec_Bayesian_techniques}
	
	%In this section, we introduce two Bayesian estimators for two different types of transition rates that corresponds to the one-off events regularly-observed events respectively.
	%high transition rates, we can take the advantage of using a conjugate Gamma prior.
	
	%\subsection{Bayesian inference using partial prior knowledge (BIPP) for singular events
	%\label{subsect:BIPP}}
	
	
	
	
	
	%\subsection{Bayesian inference using imprecise\\ probability with sets of priors (IPSP)}
	
	% \if 0
	% For CTMC transitions that correspond to regular events within the modelled system, we follow the common practice~\cite{bernardo_bayesian_1994} of using a Gamma prior distribution for each uncertain transition rate $\lambda$:
	% \begin{equation}
	%   f(\lambda) = \Gamma[\lambda;\alpha,\beta]=\frac{\beta}{(\alpha-1)!}\lambda^{\alpha-1}e^{-\beta\lambda}.
	%   \label{eq_gamma}
	% \end{equation}
	% The Gamma distribution is a frequently adopted conjugate prior distribution for the likelihood~\eqref{eq_likelihood_poisson_process} and, if the prior knowledge assumes an initial value $\lambda^{(0)}$ for the transition rate, the parameters $\alpha>0$ and $\beta>0$ must satisfy 
	% \begin{equation}
	% \E(\Gamma[\lambda;\alpha,\beta])=\frac{\alpha}{\beta}=\lambda^{(0)}.
	% \end{equation}
	% The posterior value $\lambda^{(t)}$ for the transition rate after observing $n$ transitions within $t$ time units is then obtained by using the prior~\eqref{eq_gamma} in the expectation~\eqref{eq_posterior_mean_lambda}, as shown in the following derivation adapted from~\cite{bernardo_bayesian_1994}:%\xingyu{Yes, it is better in our story that we show this re-parameterisation of using beta in a Bayesian inference. I am a bit concerned that readers may find this long (13) ``less exciting'' since it is well-established results elsewhere (as I remember I did cite it from a Bayesian textbook\cite[pp.266--277]{bernardo_bayesian_1994}. Are we reinventing the wheel?). Or not? Just a minor concern, but I am ok if you prefer to leave it in if we have the space. }
	% \begin{multline}
	%   \lambda^{(t)} = \frac{\int_0^\infty \lambda\left(\frac{(\lambda t)^n}{n!}e^{-\lambda t}\right)\left(\frac{\beta}{(\alpha-1)!}\lambda^{\alpha-1}e^{-\beta\lambda}\right)\diff \lambda}{\int_0^\infty \left(\frac{(\lambda t)^n}{n!}e^{-\lambda t}\right)\left(\frac{\beta}{(\alpha-1)!}\lambda^{\alpha-1}e^{-\beta\lambda}\right)\diff \lambda}\\
	%   = \frac{\int_0^\infty \lambda^{n+\alpha}e^{-\lambda(t+\beta)}\diff \lambda}{\int_0^\infty \lambda^{n+\alpha-1}e^{-\lambda(t+\beta)}\diff \lambda}
	%   = \frac{\int_0^\infty \lambda^{n+\alpha}\left(\frac{e^{-\lambda(t+\beta)}}{-(t+\beta)}\right)'\diff \lambda}{\int_0^\infty \lambda^{n+\alpha-1}e^{-\lambda(t+\beta)}\diff \lambda}\\
	%   = \frac{\left. \left(\lambda^{n+\alpha}\frac{e^{-\lambda(t+\beta)}}{-(t+\beta)}\right) \right|_0^\infty - \int_0^\infty (n+\alpha)\lambda^{n+\alpha-1}\frac{e^{-\lambda(t+\beta)}}{-(t+\beta)}\diff \lambda}{\int_0^\infty \lambda^{n+\alpha-1}e^{-\lambda(t+\beta)}\diff \lambda}\\
	%   = \frac{0+\frac{n+\alpha}{t+\beta}\int_0^\infty \lambda^{n+\alpha-1}e^{-\lambda(t+\beta)}\diff \lambda}{\int_0^\infty \lambda^{n+\alpha-1}e^{-\lambda(t+\beta)}\diff \lambda}
	%   =\frac{n+\alpha}{t+\beta}
	%   =\frac{n+\beta\lambda^{(0)}}{t+\beta}\\
	%   =\frac{\beta}{t+\beta}\lambda^{(0)} +\frac{t}{t+\beta}\frac{n}{t}
	%   =\frac{t^{(0)}}{t+t^{(0)}}\lambda^{(0)} +\frac{t}{t+t^{(0)}}\frac{n}{t},
	%   \label{eq_posterior_rate_gamma}
	% \end{multline}
	% where $t^{(0)}=\beta$. This notation reflects the way in which the posterior rate $\lambda^{(t)}$ is computed as a weighted sum of the mean rate $\frac{n}{t}$ observed over a time period $t$, and of the prior $\lambda^{(0)}$ deemed as trustworthy as a mean rate calculated from observations over a time period $t^{(0)}$.
	% %
	% %use of conjugate priors is a common practice, thus a Gamma distribution is the natural choice for the likelihood depicted by Eq.~\eqref{eq_likelihood_poisson_process}. This Gamma-Poisson setup is known to be the case of Bayesian inference in the regular, linear canonical exponential families (cf. the Proposition 5.4 and Example 5.5 in \cite[pp.266--277]{bernardo_bayesian_1994}). That is, if, instead of using the common shape $\alpha$ and rate $\beta$ parameters, we reparametrise the Gamma distribution by:
	% %\begin{equation}
	% %r_{ij}^{(0)}=\frac{\alpha}{\beta} \quad,\quad t_{i}^{(0)}=\beta
	% %\label{eq_reparameterisation_of_gamma}
	% %\end{equation}
	% %then, after seeing the data, the updating of the parameter $r_{ij}^{(0)}$ of the prior is linear given the second parameter $t_{i}^{(0)}$.
	% %
	% %More precisely, after observing $n_{ij}$ transitions in a total $t_{i}$ sojourn time in state $i$, via Bayes Theorem, we can obtain a posterior Gamma distribution with parameters of $r_{ij}^{(t_i)},t_{i}^{(t_i)}$ where\footnote{Note, the upper index $^{(0)}$ is used to identify the prior parameters, in contrast, the upper index $^{(t_i)}$ denotes the posterior parameters after observing outgoing transitions in a total $t_{i}$ sojourn time in state $i$.}:
	% %\begin{align}
	% %t_i^{(t_i)}&=t_i^{(0)}+t_i
	% %\\
	% %r_{ij}^{(t_i)}&=\frac{t_i^{(0)}}{t_i^{(0)}+t_i}\cdot %r_{ij}^{(0)}+\frac{t_i}{t_i^{(0)}+t_i} \cdot \frac{n_{ij}}{t_i} 
	% %\label{eq_post_r_ij_fundamental}
	% %\end{align}
	% %Indeed, the posterior mean of a Gamma distribution with the common shape $\alpha$ and rate $\beta$ parameters is $\frac{\alpha+n_{ij}}{\beta+t_i}$ \cite{filieri_formal_2012}, which is exactly the posterior mean $r_{ij}^{(t_i)}$ by substituting $\alpha$ and $\beta$ with the relations in Eq.~\eqref{eq_reparameterisation_of_gamma}.
	% %
	% %This reparametrization of the Gamma distribution provides intuitive interpretations of the parameters. $r_{ij}^{(0)}$ is the prior expectation for the transition probability $p_{ij}$, and larger $t_i^{(0)}$ leads to more concentrated probability measure around $r_{ij}^{(0)}$ \footnote{Since we know the variance of a Gamma is $\frac{\alpha}{\beta^2}=\frac{r_{ij}^{(0)}}{t_i^{(0)}}$. A larger $t_i^{(0)}$ decreases the variance.}. Thus, $t_i^{(0)}$ is quantifying the strength of beliefs in the prior estimation (i.e. $r_{ij}^{(0)}$), or a ``pseudo-count'' which can be interpreted as the size of an imaginary sample that gives the prior estimation \cite{walter_imprecision_2009}.
	% %
	% %As Eq.~\eqref{eq_post_r_ij_fundamental} shows, after seeing $n_{ij}$ transitions in the time period $t_i$ as data, the posterior expected $r_{ij}^{(t_i)}$ is a \textit{weighted} sum of two terms: (i) the prior estimate of $r_{ij}^{(0)}$ and (ii) the ${n_{ij}}/{t_i}$ which is the frequency of the transition in the data. The weights are proportional to the $t_i^{(0)}$ (the ``pseudo-count'' of prior simple size) and $t_i$ (the ``actual-count'' of data sample size). Smaller $t_i^{(0)}$ represents lower confidence in the priors and the new data will dominate the posteriors. 
	% When $t^{(0)}\ll t$ (either because we have low trust in the prior $\lambda^{(0)}$ and thus $t^{(0)}\simeq 0$, or because the system was observed for a time period $t$ that is much longer than $t^{(0)}$), the posterior~\eqref{eq_posterior_rate_gamma} reduces to the maximum likelihood estimator, i.e.\ $\lambda^{(t)} \simeq \frac{n}{t}$. In this scenario, the observations fully dominate the estimator~\eqref{eq_posterior_rate_gamma}, with no contribution from the prior.
	
	% The selection of suitable values for the parameters $t^{(0)}$ and $\lambda^{(0)}$ of the traditional Bayesian estimator~\eqref{eq_posterior_rate_gamma} is very challenging. What constitutes a suitable choice often depends on unknown attributes of the environment, or several domain experts may each propose different values for these parameters. In line with recent advances in imprecise probabilistic modelling that we leverage here (e.g.,~\cite{krpelik2018imprecise,walter_bayesian_2017,walter_imprecision_2009}), we address this challenge by defining a robust transition rate estimator for {Bayesian inference using imprecise probability with sets of priors} (IPSP).
	% The IPSP estimator uses ranges $[\underline{t}^{(0)},\overline{t}\textrm{}^{(0)}]$ and $[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$ (corresponding to the  environmental uncertainty, or to input obtained from multiple domain experts) for the two parameters instead of point values. %\xingyu{Are we giving enough credit to [51] or more general -- the *imprecise probability* community? I mean, even the motivation and initial idea of using sets of prior parameters are not ours... Am I being ``too honest''? Actually, I think it makes our arguments more convincing that there is a whole community of people sharing the same concern of using Bayesian estimators in practice on eliciting priors..}
	
	% The following theorem quantifies the uncertainty that the use of parameter ranges for $t^{(0)}$ and $\lambda^{(0)}$ induces on the posterior rate~\eqref{eq_posterior_rate_gamma}. 
	% %
	% %Now, via the KAMI estimator (Eq. \eqref{eq_post_p_ij_fundamental} and \eqref{eq_post_r_ij_fundamental} for DTMCs and CTMCs respectively) and given the trace of transitions derived from collected data, the unknown transition parameter of interest (i.e. $p_{ij}$ or $r_{ij}$ in different contexts) can be estimated in a Bayesian manner taking into account both useful prior knowledge and up-to-date data. We use KAMI as a baseline in this paper to compare with the new features of our novel Bayesian estimators. Numerical examples can be found in later sections and case studies.
	% %
	% %The question now remains of (i) how to justify a particular choice of prior parameters, i.e. the $t_i^{(0)}$ and $r_{ij}^{(0)}$, for the unknown transition rate in a CTMC? In other words, whether one can truly express the subjective and imprecise prior knowledge with the \textit{exactness} that a single particular prior distribution requires; and (ii) how to measure the error of single point estimates yielded by Eq.~\eqref{eq_post_r_ij_fundamental} which will be propagated and compounded in the later model checking in ways that are unknown but likely to be significant, as pointed in \cite{calinescu_2016_formal}. 
	% %
	% %Although \cite{calinescu_2016_formal} is the first work to synthesise bounds for unknown transition parameters, it is based on the theory of \textit{simultaneous confidence intervals} which is not a Bayesian approach thus without the distinct advantage of being able to embed useful prior knowledge.
	% %
	% %To answer those questions, we introduce the IPSP approach developed in 
	% %
	% This theorem specialises and builds on results from~\cite{walter_imprecision_2009}, which we adapt here for the estimation of CTMC transition rates,
	% %and integrate it with PMC, in the new formal verification context, to:
	% %\begin{itemize}
	% %    \item get upper and lower bounds on the posterior estimates of the transition parameters whose range measures the estimation errors. Such imprecision will be propagated in the PMC, leading to bounded verification results of system QoS properties;
	% %    \item allow modelling vague and imperfect prior knowledge (e.g. from experts, historical records) in a more practical and flexible way using bounded priors; 
	% %    \item detect \textit{prior-data conflict} \cite{evans_checking_2006} when observe surprising data (that conflicts our prior knowledge) in the operation to provide extra alarms of the dynamic environments.
	% %\end{itemize}
	
	% %\footnote{Note the elicited intervals for $p_{ij}^{(0)}$ should satisfy the unit simplex constraint $\sum_{j=1}^k p_{ij}^{(0)}=1 $.}
	% %To be exact, in a CTMC context, instead of a single value, we elicit an interval for the two prior parameters $t_i^{(0)}$ and $r_{ij}^{(0)}$, and denote them as:
	% %\begin{equation}
	% %t_i^{(0)} \in \left[\underline{t_i}^{(0)},\overline{t_i}^{(0)}\right]\quad , \quad r_{ij}^{(0)} \in \left[\underline{r_{ij}}^{(0)},\overline{r_{ij}}^{(0)}\right] %\nonumber
	% %\end{equation}
	
	% %\radu{Let's change the propositions into theorems. I would really like to see more detail in the proof below, i.e., not point the reader to the proof from \cite[p.266]{walter_imprecision_2009} quite so quickly. I don't immediately know how to best expand the proof, but I suggest that the second sentence is expanded, i.e., show the calculations that lead to a generalised iLUCK Bayesian inference model, e.g.: intermediate\_result\_1; intermediate\_result\_2; \ldots; final\_result; and explain that final\_result is a generalised iLUCK Bayesian inference model according to the definition from [X], and end with `As such, the theorem Y from \cite[p.266]{walter_imprecision_2009}, and the posterior bounds can be calculated as -- show a bit of calculation here too, unless the results from \cite[p.266]{walter_imprecision_2009} are identical in format to eqs. (9) and (10).}
	
	% \begin{theorem}
	% \label{theorem_CTMC_IPSP}
	% Given uncertain prior parameters $t^{(0)}\in[\underline{t}^{(0)},$ $\overline{t}\textrm{}^{(0)}]$ and $\lambda^{(0)}\in[\underline{\lambda}^{(0)},\overline{\lambda}\textrm{}^{(0)}]$, the posterior rate $\lambda^{(t)}$ from~\eqref{eq_posterior_rate_gamma} can range in the interval  $[\underline{\lambda}^{(t)},\overline{\lambda}\textrm{}^{(t)}]$, where:
	% %
	% %In a CTMC, if an unknown transition rate $r_{ij}$ follows a Gamma prior distribution whose parameters (after the reparametrization of Eq.~\eqref{eq_reparameterisation_of_gamma}) are bounded by $\left[\underline{t_i}^{(0)},\overline{t_i}^{(0)}\right]$ and $\left[\underline{r_{ij}}^{(0)},\overline{r_{ij}}^{(0)}\right]$, then after seeing $n_{ij}$ transitions from the state $i$ to $j$ in an accumulated $t_i$ sojourn time in state $i$, the lower and upper bounds for the posterior expected $r_{ij}$ are:
	% %\begin{align}
	% \begin{equation}
	% \underline{\lambda}^{(t)}=\begin{cases} \frac{\overline{t}\text{}^{(0)}\underline{\lambda}^{(0)}+n}{\overline{t}\text{}^{(0)}+t}, & \text{if } \frac{n}{t} \geq \underline{\lambda}^{(0)}  
	% \\[2mm] 
	% \frac{\underline{t}^{(0)}\underline{\lambda}^{(0)}+n}{\underline{t}^{(0)}+t}, & \text{otherwise} %\quad \frac{n}{t} <\underline{\lambda}^{(0)}
	% \end{cases}
	% %\nonumber
	% \\[1mm]
	% \label{eq_post_lower_bound_rij}
	% \end{equation}
	% and
	% \begin{equation}
	% \overline{\lambda}^{(t)}=\begin{cases} \frac{\overline{t}\text{}^{(0)}\overline{\lambda}\text{}^{(0)}+n}{\overline{t}\text{}^{(0)}+t}, & \text{if } \frac{n}{t} \leq \overline{\lambda}\text{}^{(0)}  
	% \\[2mm]
	% \frac{\underline{t}^{(0)}\overline{\lambda}\text{}^{(0)}+n}{\underline{t}^{(0)}+t}, & \text{otherwise} %\quad \frac{n}{t} >\overline{\lambda}\text{}^{(0)}
	% \end{cases}.
	% \label{eq_post_upper_bound_rij}
	% \end{equation}
	% %\end{align}
	% \end{theorem}
	
	% %A more general result of Proposition \ref{theorem_CTMC_IPSP} and its proof sketch are firstly presented as a iLUCK-model (imprecise Linearly Updated Conjugate prior Knowledge model) defined in \cite{walter_imprecision_2009}. We specialise it for CTMCs with a detailed proof in the supplementary materials. 
	
	
	% \section{Robust CTMC verification}
	% \label{sec_framework}
	
	% Based on the methods defined in Sections~\ref{sec_preliminaries} and~\ref{sec_Bayesian_techniques} above, 
	% we developed an end-to-end verification framework for the online computation of bounded intervals of CTMC properties. The new verification framework integrates our BIPP and IPSP Bayesian interval estimators with interval CTMC model checking~\cite{brim-etal-2013}.  As shown in Fig.~\ref{fig:integration}, this involves monitoring the system under verification, to observe both the occurrence of regular events, and {the lack of singular events} during times when such events could have occurred (e.g., a catastrophic failure not happening when the system performs a dangerous operation). Our online \textsc{BIPP Estimator} and \textsc{IPSP Estimator} use these observations to calculate expected ranges for the rates of the monitored events, enabling a \textsc{Model Generator} to continually synthesise up-to-date interval CTMCs that model the evolving behaviour of the system. 
	
	% The interval CTMCs are synthesised from a parametric CTMC model that captures the structural aspects of the system under verification. They are then continually verified by the \textsc{PRISM-PSY Model Checker}~\cite{ceska_prism_psy_2016}, to compute value intervals for key system properties. As shown in Fig.~\ref{fig:integration} and illustrated in the next section, these properties range from dependability (e.g., safety, reliability and availability) \cite{avizienis_basic_2004} and performance (e.g., response time and throughput) properties to resource use and system utility. Finally, changes in the value ranges of these properties may prompt the dynamic reconfiguration of the system by a \textsc{Controller} module responsible for ensuring that the system requirements are satisfied at all times. 
	
	
	% %So far, we have presented advanced Bayesian estimators on learning uncertain transition parameters of a CTMC/DTMC when new transition data is collected at runtime. However, what we are really interested in is the verification result of system QoS properties. In this section, we discuss how to compound and propagate the estimated bounds on the transition parameters into intervals for system-level properties. 
	
	
	
	% %cleaning is needed, the AUV controller determines the control parameter $x_i \in \{0,1\}$  for all the remaining chains $i, i+1, ...n$ so that the system requirements are satisfied. 
	
	
	
	
	% \section{Discussion and Conclusion \label{sec_conclusion}}
	
	
	
	% %Markov models are widely used for the verification of quantitative properties of many kinds of systems, especially with an recent trend in robotics \cite{gerasimou_undersea_2017,gainer_probabilistic_2016,PathakShashank2018Varo,zhao_towards_2019,zhao_probabilistic_2019}, 
	% %network and multimedia protocols \cite{kwiatkowska_analysis_2008,basagiannis_quantitative_2011,zayani_probabilistic_2010}, power management systems \cite{sesic_dynamic_2008,hildmann_influence_2011}. 
	% %Although some of the systems under study in previous work are of safety-critical nature, we are the first to explore more robust ways in online learning of transition parameters of CTMCs modelling safety-critical systems. Specifically, we classify two types of transition parameters based on their frequencies and severity of consequences, then propose bespoke Bayesian estimators to provide robust estimates when seeing runtime data.
	
	
	
	% %There is a challenging problem for most (if not all) formal verification techniques that is the verification assumes the formal model (e.g., a CTMC in PMC) accurately reflects the actual behaviour of the real-world system \cite{calinescu_2016_formal}. It becomes even more challenging for systems in changing, unexpected environments like robots deployed in extreme environments, as the case study in this paper. In the quantitative verification domain, the appealing idea of doing runtime PMC was proposed in \cite{calinescu_2012_self-adaptive} whose essence is to keep the formal model alive and continuously update it when seeing new data at runtime. There are two important research themes for runtime PMC -- reducing the runtime computational overheads (cf. \cite{calinescu_using_2017} for a review) and the robust learning of transition parameters. We focus on the latter in this paper, while considering the former by deriving closed-form results.
	
	% %One important theme in recent research aims to reduce the overheads of runtime PMC, e.g., by compositional methods \cite{kwiatkowska_assume-guarantee_2010}, incremental methods \cite{meedeniya_efficient_2010}, pre-computation-based \cite{filieri_supporting_2016} methods and other software engineering methods \cite{gerasimou_efficient_2014}. For a detailed overview, cf. \cite{calinescu_using_2017}. Most of these methods are compatible with the Bayesian estimators proposed in this paper.
	
	% Unlike existing approaches, which mostly do single point estimates for Markov model parameters \cite{epifani_model_2009,filieri_formal_2012,calinescu_adaptive_2014,filieri_lightweight_2015}, our new estimators provide more robust bounded estimates. While, although the work in \cite{calinescu_2016_formal} is the first to synthesise bounds for unknown transition parameters, it is based on the frequentist theory of simultaneous confidence intervals which is fundamentally different to our Bayesian estimators that has the distinct advantage of being able to embed prior knowledge. Furthermore, instead of treating the transition parameters indistinguishably like all existing approaches, we are the first to explicitly consider different types of parameters representing one-off or regular events, by extending our preliminary work \cite{zhao_probabilistic_2019} (for DTMC parameters with one-side bounded estimates for one-off events).
	
	% Our new estimators are underpinned by theoretical foundations of imprecise probabilities \cite{walter_imprecision_2009,walter_bayesian_2017} and Conservative Bayesian Inference (CBI) \cite{bishop_toward_2011,strigini_software_2013,littlewood_reliability_2020} integrated with recent advances in the verification of {interval Markov chains}, e.g., PRISM-PSY \cite{ceska_prism_psy_2016}. In particular, the new BIPP theorems for singular events are significant extensions of CBI in the following directions: (i) BIPP is in the continuous domain for a Poisson point process rather than previous CBI theorems developed for Bernoulli processes in the discrete domain. Thus BIPP works for runtime PMC of CTMCs which allows the verification of more types of properties (compared with DTMCs); (ii) CBI is one-side bounded assuming the upper bound is always being conservative for ``negative singular'' event-probability (e.g., catastrophic failures). While BIPP provides two-side bounded estimates to cope with ``positive singualr'' event as well where the lower bound is of more practical interest to be conservative; (iii) For the first time, the new  BIPP theorems deal with an \textit{arbitrary} number of confidence bounds as priors which increases the flexibility of eliciting prior knowledge. Given CBI has been shown useful in a wider context than PMC, e.g., \cite{zhao_conservative_2018,zhao_modeling_2017,zhao_assessing_2019}, we believe the new BIPP may also contribute to wider statistical inference problems. 
	
	
	% %One of the initial methods to learn the transition probabilities of DTMCs is KAMI \cite{epifani_model_2009}, which later has been retrofitted for CTMCs \cite{filieri_formal_2012} and extended with ageing factors of collected data to accurately estimate time-varying transition probabilities \cite{calinescu_adaptive_2014}. To reduce the noise and provide smooth estimates, a lightweight adaptive filter is proposed in \cite{filieri_lightweight_2015}. However, all above mentioned approaches yield point estimations, which can be affected by unquantified and potentially significant errors \cite{calinescu_2016_formal}. While, we propose bounded estimates in this paper, and instead of treating all transition parameters indistinguishably like the existing approaches, we explicitly consider different types of transition parameters:
	% %\begin{itemize}
	% %    \item For transitions with very small rates (thus, effectively represent one-off events at runtime, e.g., catastrophic failures for safety-critical systems), we propose the bespoke BIPP estimator. A related research theme, in the more general model checking field, is to deal with rare events in \textit{Statistical Model Checking} (SMC) \cite{clarke_statistical_2011,legay_rare_2016,budde_statistical_2018}. However, SMC address the verification as a statistical inference problem: it Monte Carlo samples behaviours of the system model, and then use frequentist statistical techniques to compute the ``classical'' probability of the property being satisfied. Thus, it is distinct from the numerical PMC technique we consider in this paper \cite{younes_numerical_2006}. To the best of our knowledge, extending the preliminary work \cite{zhao_probabilistic_2019} (only one-side bounded estimates for DTMC parameters), we are the first to estimate ``ultra-small'' transition parameters with robust bounds in PMC.
	% %    \item For transitions representing regularly observed events, e.g., sensor readings of robots. We introduce IPSP to provide bounded estimates whose interval width measures the estimation errors that will be propagated to the system level verification results. As a Bayesian estimator, it not only allows to flexibly model imperfect prior knowledge but also detects prior-data conflict phenomenon to alert dangerous situations, e.g., a sudden change-point. The work in \cite{calinescu_2016_formal} is the first to synthesise bounds for unknown transition parameters. However, it is based on the frequentist theory of simultaneous confidence intervals, which is fundamentally different to our Bayesian estimators that has the distinct advantage of being able to embed prior knowledge.
	% %\end{itemize}
	
	
	% We illustrated our robust estimators in a robotics runtime verification case study which is publicly accessible at \url{https://the_git_hub_page_XXXX}. \xingyu{More descriptions here on the case study results once we got them.}
	
	
	% We conclude our robust estimators remove the major difficulty of trusting more detailed/precise prior beliefs than the evidence typically allows one to use in Bayesian inference. One can, thus, take advantage of Bayesian combination of either limited/partial or imperfect/vague prior knowledge while with informed estimation errors (measured by the bounds). Although our approach does not solve all problems faced by runtime PMC (e.g., how to scientifically obtain those prior knowledge from historical-data/experts), it does allow one to trust the statistical inference step (i.e. the estimators) itself.
	
	
	
	% %This paper builds on significant extensions, both in theoretical results and experimental studies, of the preliminary work \cite{zhao_probabilistic_2019},\xingyu{I guess we don't want to say this paper is an extension of the AAAI19 one for some reasons...}
	
	% %To recap, our main contributions are:\begin{itemize}
	% %    \item We classify two types of transition parameters in CTMCs based on the expected transition frequencies, and introduce two robust Bayesian estimators -- IPSP and BIPP that both provide bounded estimates.
	%  %   \item The new BIPP theorems are significant extensions of the existing Conservative Bayesian Inference (CBI) approach \cite{bishop_toward_2011,strigini_software_2013,zhao_conservative_2018,zhao_modeling_2017,zhao_assessing_2019} in the following senses: (i) BIPP is in the continuous domain for a Poisson point process rather than previous CBI theorems developed for Bernoulli processes in the discrete domain; (ii) CBI is one-side bounded assuming the upper bound is always being conservative for some very small event-rate, while we extend the meaning of being conservative and provide two-side bounded estimates by BIPP; (iii) For the first time, the new  BIPP theorems deal with an arbitrary number of confidence bounds as priors. Given CBI has been shown useful in a wider context than PMC, we believe the new BIPP may also be retrofitted for other statistical inference problems.
	% %    \item Our simulated robotics case study in this paper can be extended and reused as an exemplar for future research.
	% %\end{itemize}
	
	% %In future, we plan to: (i).. (ii) ..
	
	
	% % if have a single appendix:
	% %\appendix[Proof of the Zonklar Equations]
	% % or
	% %\appendix  % for no appendix heading
	% % do not use \section anymore after \appendix, only \section*
	% % is possibly needed
	
	% % use appendices with more than one appendix
	% % then use \section to start each appendix
	% % you must declare a \section before using any
	% % \subsection or using \label (\appendices by itself
	% % starts a section numbered zero.)
	% %
	% \fi
	
	
	% use section* for acknowledgment
	\bigskip
	\noindent
	\textbf{Acknowledgments}\\
	This project has received funding from the ORCA-Hub PRF project `COVE', the Assuring Autonomy International Programme, the UKRI project EP/V026747/1 `Trustworthy Autonomous Systems Node in Resilience', and the European Union’s Horizon 2020 project SESAME (grant agreement No 101017258). 
	
	
	%link: https://docs.google.com/spreadsheets/d/1pjSd2tr80gXpqlxKUfBf61Z1sqm9MpY4z0YyRLM_-ew/edit#gid=0
	\bigskip
	\noindent
	\textbf{Author contributions}\\
	\noindent
	X.Z: Conceptualisation, Data curation, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Software, Supervision, Validation, Writing - original draft, Writing - review and editing;
	S.G.: Conceptualisation, Data curation, Funding acquisition, Investigation, Methodology, Project administration, Software, Supervision, Validation, Visualisation, Writing - original draft, Writing - review and editing;
	R.C.: Conceptualisation, Formal analysis, Funding acquisition, Methodology, Project administration, Supervision, Visualisation, Writing - original draft, Writing - review and editing;
	C.I.: Data curation, Investigation,  Validation, Visualisation, Writing - original draft, Writing - review and editing;
	V.R.: Conceptualisation,  Funding acquisition, Methodology, Project administration, Supervision, Writing - review and editing;
	D.F.:  Conceptualisation,  Funding acquisition, Methodology, Project administration, Supervision, Writing - review and editing.
	
	\bigskip
	\noindent
	\textbf{Competing interests}\\
	The authors declare no competing interests.
	
	
	\bigskip
	\noindent
	\textbf{Additional information}\\
	\textbf{Supplementary information} The online version contains supplementary material available at~\url{https://arxiv.org/abs/2303.08476}.
	
	
	\bigskip
	\noindent
	\textbf{Correspondence} should be addressed to Xingyu Zhao or Simos Gerasimou.



\includepdf[pages={-},pagecommand={\thispagestyle{headings}},scale=1]{sup.pdf}
\end{document}