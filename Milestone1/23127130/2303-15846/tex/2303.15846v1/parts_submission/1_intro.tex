\section{Introduction}
\label{sec:Ã¯ntro}
In the Netherlands, general practitioners (GPs) act as a gatekeeper between patients and the secondary healthcare system: GPs decide who should be referred to specialist care.
They also oversee the same patients for many years.
A patient's visit to their GP is registered in narrative form as \textit{free-text notes}, and collectively these provide a unique lens into years of a patient's health and medical history.
In previous work, Luik et al. \cite{torec-et-al2021w2vlungcancer} have used free-text patient notes in the early prediction of lung cancer with \textit{context-independent} word embedding methods (WEMs) and a simple logistic regression objective, with promising preliminary results.
Ideally, one would like to use state-of-the-art contextualised pretrained language models (PLMs) instead of simpler context-independent WEMs, since PLMs typically show improved performance across a range of different Natural Language Processing tasks~\cite{wang-etal-2018-glue,NEURIPS2019_superglue} including tasks in the (bio)medical domain \cite{fries2022bigbio,Naseem2022}.
However, there are at least two important reasons that make using PLMs difficult for predicting lung cancer from patient free-text notes:
i) Even though PLMs are language models pretrained on large amounts of raw text using self-supervised learning~\cite{delobelle-etal-2020-robbert,Verkijk_Vossen_2021}, such models are data-hungry and typically need large amounts of supervised training data to achieve good predictive performance on any specific task.
Conversely, lung cancer has a low prevalence (about $0.4\%$ in our dataset), which makes adapting PLMs to this task difficult.
ii) A single patient may have many years worth of health records, meaning possibly thousands of words in their medical notes.
A PLM's complexity is quadratic with respect to input length, making them non-trivial to apply in this use-case.

In this work, we propose methods to deal with the aforementioned issues by addressing the following research questions.
\textbf{RQ1.} \textit{How does soft-prompt tuning compare to standard model fine-tuning in terms of discrimination and calibration?}
In this work, we use \textit{soft prompt-tuning}~\cite{lester-etal-2021-power,liu-etal-2022-p}, an NLP technique used to adapt PLMs using small amounts of training data, and compare it to standard model fine-tuning.
Overall, we find that soft-prompt tuning compares favourably to standard model fine-tuning, but similar to fune-tuning when models are trained on small numbers of patients.
\textbf{RQ2.} \textit{How does the number of patients used for model training affect model performance in terms of discrimination and calibration?}
We empirically evaluate models trained on very small numbers of patients---a setting also known as \textit{few-shot learning}~\cite{wang2020fewshot}---and models trained on datasets with different degrees of class imbalance.
We report discrimination and calibration metrics, since both should be assessed for clinical prediction models~\cite{PMID:30596876}.
\textbf{RQ3.} \textit{How do PLMs compare to simpler static WEMs in terms of discrimination and calibration?}
Overall, contextualised PLMs outperform static WEMs in terms of discrimination, but WEMs show better calibration in both balanced and imbalanced classification settings.
However, results we obtain for few-shot experiments show mixed results, indicating that WEMs may be an alternative to PLMs in this setting.

%The remainder of this paper is as follows.
%In Section~\ref{sec:methods} we introduce the methods we use to answer the research questions RQ1--2 and we provide details on the patients we use in our experiments, who are patients from the primary care network associated with the Amsterdam University Medical Centers in Amsterdam, the Netherlands.
%In Section~\ref{sec:results} we report our main findings and discuss the most important results.
%In Section~\ref{sec:related} we contextualise our work within the existing research in pretrained language models in the (bio)medical domain.
%Finally, in Section~\ref{sec:conclusions}, we present our main conclusions and provide some avenues for future work.