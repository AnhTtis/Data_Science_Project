\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}
\IEEEPARstart{T}{ransformer} models have demonstrated outstanding performance on tasks in natural language processings (NLP)~\cite{vaswani2017attention,devlin2019bert,liu2019roberta} and time-series forecastings~\cite{lim2021temporal}. Recently, their success has also been extended to the vision domain, and the resulting vision transformer (ViT) has achieved on-par and even better performance than the state-of-the-art CNNs~\cite{dosovitskiy2020image}.
%
ViT converts a 2D image into a 1D sequence by decomposing it into many patches and arranging the patches sequentially. Each patch is analogous to a token of sequential data, and the multi-head self-attentions are then applied to the sequence to learn the relation among tokens.

Despite the superb performance, it remains unclear how ViT works internally, especially how the multi-head self-attention works on image patches. To be specific, we found ViT designers are often puzzled by the following questions: 

\begin{itemize}[leftmargin=12pt, topsep=0pt,itemsep=0pt,parsep=0pt,partopsep=0pt]
\item \textit{First}, how important are individual heads, and is their importance consistent across images? 
As different heads emphasize different pair-wise attentions, their contributions to the prediction are also different. Identifying the important ones would limit the scope of model analysis. 

\item \textit{Second}, how strong is the attention between two patches that are nearby or far away from each other, and does the attention strength show any trend across layers?
It is widely known that CNNs extract basic shapes/colors in early layers but complex objects/concepts in later layers. Since ViTs demonstrate on-par performance with CNNs, it becomes a natural question to ask if the models have any learning heuristic from early to later layers.

\item \textit{Third}, what attention patterns have individual heads learned, and are those patterns related to image contents? We have observed heads with interesting patterns, e.g., always attending to the patch itself regardless of the image content (content-agnostic) or only attending to patches with target objects (content-relevant). But, there lacks an exhaustive summary of all possible patterns.
\end{itemize}

\noindent Answering these questions will provide a fundamental understanding of ViTs and assist their further development.

\begin{figure*}
\centering
 \includegraphics[width=\textwidth]{fig/teaser.pdf}
 \vspace{-0.3in}
 \caption{Our system contains four components. The \imageoverview{} (A) lays out all images for selection. The \headimportance{} (B) shows all heads in different importance metrics (B1) and dissects a head's importance through partial pruning (B2, B3). The attention strengths between patches in a head are shown in the \attnstrength{} (C), where users first obtain an overview of all heads (C1), and then focus on one head (C2, C3). 
 The \attnpattern{} (D) clusters all heads by their attention pattern (D1), and presents the pattern details in one head (D2${\sim}$D5).}
 \label{fig:teaser}
\end{figure*}

However, there are multiple challenges in answering them.
\textit{First}, Michel and Levy~\cite{michel2019aresixteen} proved that heads are not equally important in transformers through intensive ablation studies. Hao et al.~\cite{hao2021self} proposed a self-attention attribution score for each head to quantify its importance through token interactions. These works focus on NLP tasks and use a head's impact on the prediction to verify its importance. In ViTs, however, we find that heads with little impact on the ultimate predictions may considerably influence the intermediate representations, indicating the need to profile head importance from multiple perspectives. 
\textit{Second}, for attention strengths and attention patterns, multiple works have proposed to visualize them with heatmap, flow map, or matrix visualizations~\cite{kovaleva2019revealing, park2019sanvis, derose2020attention,li2021t3}. However, all these works focus on language transformers with 1D attentions (forward/backward). ViTs, though rearrange image patches into 1D, still present 2D attention behaviors in the 2D spatial context (e.g., upward/downward attention). 
The 2D attention behavior results in much richer attention patterns, and the patches' attention strength to their neighbors needs to be redefined considering the spatial distance in 2D.
\textit{Lastly}, based on our collaborations with domain experts, existing ViT analyses are often piece-by-piece and lack a fluent analytical workflow. For example, to understand the attention between image patches, the patches and attentions between them need to be presented intuitively and explored coordinately. However, most ViT researchers still connect the two parts manually by eyeballing them back and forth.

Our work interprets ViTs from three aspects: \textit{head importance}, \textit{head attention strengths}, and \textit{head attention patterns}.
For head importance, we introduce multiple pruning-based head importance metrics, which are computed offline and can be easily plugged into our system to support head exploration and importance analysis.
For attention strengths, we profile a patch's attention strength to its $k$-hop neighbors as a $k$-dimensional vector. Aggregating the vectors from all patches of a head reflects the head's attention strength distribution. For attention patterns, we train an autoencoder for the heads' attention matrices, and summarize all possible attention patterns by clustering the latent representations of all heads. The three parts are integrated into a coordinated visual analytics (VA) system. We validate the system's efficacy by studying different ViTs with experienced deep learning experts. In short, our contributions include:
\begin{enumerate}[leftmargin=15pt, topsep=0pt,itemsep=0pt,parsep=0pt,partopsep=0pt]
    \item Multiple pruning-based metrics describing ViT heads' importance from different perspectives.
    \item A characterization of heads' attention strength across image patches' $k$-hop neighbors.
    \item A comprehensive summary of the possible attention patterns in ViTs using an autoencoder-based solution.
    \item An interactive visual analytics system integrating the above three parts for coordinated interpretations of ViTs.
\end{enumerate}

