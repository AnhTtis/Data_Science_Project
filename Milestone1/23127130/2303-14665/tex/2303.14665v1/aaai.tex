% Template for producing ESWA-format journal articles using LaTeX    
% Written by Miha Ravber                
% Programming methodologies laboratory                    
% Faculty of Electrical Engineering and Computer Science 
% University of Maribor                              
% Koroška cesta 46, 2000 Maribor                                       
% E-mail: miha.ravber@um.si                           
% WWW: https://lpm.feri.um.si/en/members/ravber/    
% Created: November 20, 2020 by Miha Ravber                                          
% Modified: November 20, 2020 by Miha Ravber                     
% Use at your own risk :) 
% Please submit your issues on the github page: https://github.com/Ravby/eswa-template


\documentclass[review]{elsarticle}
\graphicspath{ {./figures/} }
\usepackage{hyperref}
\usepackage{float}
\usepackage{verbatim} %comments
\usepackage{apalike}


\usepackage{graphicx}

\usepackage{hyperref}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{amsmath,amssymb}
\usepackage{amsthm}
\usepackage{caption}
\usepackage{multirow}
% \usepackage{lipsum}
\usepackage{adjustbox}
\usepackage{upgreek}
% \usepackage{enumitem}
% \usepackage{subcaption}
% \usepackage{minipage}

% \let\proof\relax
% \let\endproof\relax
% \let\example\relax
% \let\endexample\relax


\usepackage{amsmath,amsfonts,amssymb}
% \usepackage{amsmath}
\usepackage{mathtools}
\usepackage{commath}
\usepackage{color}
% \usepackage{subfig}
% \usepackage[sc,osf]{mathpazo}
% \newtheorem{theorem}{Theorem}[section]
% \newtheorem{lemma}{Lemma}[section]
% \newtheorem{definition}{Definition}
% \newtheorem{prop}{Proposition}[section]
% \newtheorem{thm}{Theorem}[]
% \newtheorem{lemma}[thm]{Lemma}
% \newtheorem{prop}[thm]{Proposition}
% \newtheorem{cor}[thm]{Corollary}
% \newtheorem{defn}[thm]{Definition}
% \newtheorem{examp}[thm]{Example}
% \newtheorem{conj}[thm]{Conjecture}
% \newtheorem{rmk}[thm]{Remark}
% \newtheorem{assumption}{Assumption}[section]


% \setcounter{secnumdepth}{3}
% \newtheorem{thm}{Theorem}[subsection]
% \renewcommand{\thethm}{\arabic{thm}}

% \newtheorem{defn}[thm]{Definition}
% \renewcommand{\thethm}{\arabic{thm}}

% \newtheorem{prop}{Proposition}[subsection] 
% \renewcommand{\theproposition}{\arabic{proposition}}

% \newtheorem{assumption}{Assumption}[subsection]  \renewcommand{\theassumption}{\arabic{assumption}}

% \newtheorem{lemma}{Lemma}[subsection] 
% \renewcommand{\thelemma}{\arabic{lemma}}

% \newtheorem{corollary}{Corollary}[subsection] 
% \renewcommand{\thecorollary}{\arabic{corollary}}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}{Proposition}[section] 



\let\oldnorm\norm   % <-- Store original \norm as \oldnorm
\let\norm\undefined % <-- "Undefine" \norm
\DeclarePairedDelimiter\norm{\lVert}{\rVert}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

% \DeclareMathOperator*{\argmax}{arg\,max}
% \DeclareMathOperator*{\argmin}{arg\,min}
% \newcommand\norm[1]{\left\lVert#1\right\rVert}
\definecolor{todocolor}{rgb}{0.9,0.1,0.1}
\definecolor{lcolor}{rgb}{0.7,0.7,0.3}
\definecolor{qcolor}{rgb}{0,0,1}

\newcommand{\nbc}[3]{
		{\colorbox{#3}{\bfseries\sffamily\scriptsize\textcolor{white}{#1}}}
		{\textcolor{#3}{\sf\small$\blacktriangleright$\textit{#2}$\blacktriangleleft$}}
}
\newcommand{\qli}[1]{\nbc{Qian}{#1}{qcolor}}
\newcommand{\duong}[1]{\nbc{Duong}{#1}{lcolor}}

\restylefloat{figure}
\restylefloat{table}

\journal{Expert Systems with Applications}

%% For ESWA journal you need to use APA style
\bibliographystyle{model5-names}\biboptions{authoryear}

\begin{document}
\begin{frontmatter}


\begin{titlepage}
\begin{center}
\vspace*{1cm}

\textbf{ \large Achieving counterfactual fairness \\ with imperfect structural causal model}

\vspace{1.5cm}

% Author names and affiliations
Tri Dung Duong$^{a}$ (TriDung.Duong@student.uts.edu.au), Qian Li$^b$ (qli@curtin.edu.au), Guandong Xu$^a$ (Guandong.Xu@uts.edu.au) \\

\hspace{10pt}

\begin{flushleft}
\small  
$^a$ University of Technology Sydney (UTS), Australia \\
$^b$ Curtin University, Australia

% \begin{comment}
% Clearly indicate who will handle correspondence at all stages of refereeing and publication, also post-publication. Ensure that phone numbers (with country and area code) are provided in addition to the e-mail address and the complete postal address. Contact details must be kept up to date by the corresponding author.
% \end{comment}

\vspace{1cm}
\textbf{Corresponding Author:} \\
Guandong Xu \\
61 Broadway, Ultimo NSW 2007, Australia \\
Tel: (+61)295143788 \\
Email: Guandong.Xu@uts.edu.au

\end{flushleft}        
\end{center}
\end{titlepage}

\title{Achieving Counterfactual Fairness \\ with Imperfect Structural Causal Model}

\author[label1]{Tri Dung Duong}
\ead{TriDung.Duong@student.uts.edu.au}

\author[label1]{Qian Li}
\ead{qli@curtin.edu.au}

\author[label1]{Guandong Xu \corref{cor1}}
\ead{Guandong.Xu@uts.edu.au}

\cortext[cor1]{Corresponding author.}
\address[label1]{University of Technology Sydney (UTS), Australia}
\address[label2]{Curtin University, Australia}
% \address[label3]{Full address of last author, including the country name}

\begin{abstract}
%\qli{The abstract already starts with two sentences that do not make much (up to any) sense. Alleviate does not mean what is implied here. The second statement starts with a true-ism ('existing methods for counterfactual fairness require an SCM') but then goes off the rails ('that captures correlations'). It then continues with statements regarding that misspecification of the SCM could lead to poor performance, but leaves this topic completely unexplored in the entire manuscript. The statement that the work achieves 'the counterfactual fair decision without the pre-defined causal model' is equally untrue here as it is in the rest of the paper.}\duong{revised}
Counterfactual fairness alleviates the discrimination between the model prediction toward an individual in the actual world (observational data) and that in 
%\qli{del 'that in the'}\duong{done} 
counterfactual world (i.e., what if the individual belongs to other sensitive groups). The existing studies need to pre-define the structural causal model that captures the correlations among variables for counterfactual inference; however, the underlying causal model is usually unknown and difficult to be validated in real-world scenarios. Moreover, the misspecification of the causal model potentially leads to poor performance in model prediction and thus makes unfair decisions. In this research, we propose a novel minimax game-theoretic model for counterfactual fairness that can produce accurate results meanwhile achieve a counterfactually fair decision with the relaxation of strong assumptions of structural causal models. In addition, we also theoretically prove the error bound of the proposed minimax model.
Empirical experiments on multiple real-world datasets illustrate our superior performance in both accuracy and fairness. Source code is
available at \url{https://github.com/tridungduong16/counterfactual_fairness_game_theoretic}.
\end{abstract}

\begin{keyword}
counterfactual fairness \sep game theoretic approach \sep individual fairness.
\end{keyword}

\end{frontmatter}


\section{Introduction}
%\qli{check the reference style of the journal to be submitted, make sure it is correct}\duong{change format}

% It is important to develop fairness-aware machine learning al-
% gorithms and models such that the decisions made with their assistance are subject to fairness requirements. In recent years, the research community has studied fairness-aware machine learning from the causal perspective [Zhang et al., 2017b; Zhang et al., 2017a; Zhang and Bareinboim, 2018; Nabi and Shpitser, 2018; Zhang et al., 2018b; Zhang et al., 2018a] using causal modeling [Pearl, 2009]. In these works, fairness is generally formulated and quantified as the aver- age causal effect of the sensitive attribute on the decision at- tribute. The effect is evaluated by the intervention through the post-interventional distributions. Different from above works, [Kusner et al., 2017] introduced counterfactual fair- ness, based on the counterfactual inference, which considers the causal effect within a particular individual/group specified by of observational profile attributes. The

% As 


As machine learning (ML) is increasingly leveraged in high-stake domains such as criminal justice \cite{angwin2016machine,berk2021fairness} or credit assessment \cite{zhang2019fairness}, the concerns regarding ethical issues in designing ML algorithms have arisen recently. Fairness is one of the most important concerns to avoid discrimination in the model prediction towards an individual or a population. 
Recent years witness an increasing number of studies that have explored fairness-aware machine learning under the causal perspective \cite{nabi2018fair,kusner2017counterfactual,zhang2018fairness,chiappa2019path}. Causal models specifically \cite{pearl2009causal} provide an intuitive and powerful way of reasoning the causal effect of sensitive attribution on the final decision. Among these studies in this line of work, counterfactual fairness is a causal and individual-level fairness notion first proposed by \cite{kusner2017counterfactual}, which considers a model counterfactually fair if its predictions are identical in both a) the original world and b) the counterfactual world where an individual belongs to another demographic group. 





% there are several important concerns arising about the possibility of discrimination of these decisions towards an individual or sub-population. Machine learning fairness is a much more important field that pays attention to avoiding discrimination in the model decisions. 
% Recent years witness an increasing number of studies that have explored fairness-aware machine learning under the causal perspective \cite{nabi2018fair,kusner2017counterfactual,zhang2018fairness,chiappa2019path}. Causal model \cite{pearl2009causal} provides an intuitive and powerful way of reasoning the causal effect of sensitive attribution on the final decision. Among these studies in this line of work, counterfactual fairness is a causal and individual-level fairness notion first proposed by \cite{kusner2017counterfactual}, which considers a model counterfactually fair if its predictions are identical in both a) the original world and b) the counterfactual world where an individual belongs to another sensitive group. 
% The unidentifiable situations are big barriers to the appli-
% cation of counterfactual fairness. In [Kusner et al., 2017], the authors proposed three methods to evade the unidentifiabil- ity issue: 1) only non-descendants of the sensitive attribute are used in classification, 2) the non-deterministic substitu- tions of the hidden variables are postulated and inferred based on domain knowledge, or 3) the complete causal model is postulated and estimated, e.g., , being treated as the additive noise model then estimating the errors
%Despite the utility of such causal criteria, they are often contested, because they are based on strong assumptions that are hard to verify in practice.
% Also, it is over-simplified to postulate the substitutions and their distri- butions, since the exogenous variables represent all possible sources of randomness; or presuppose that the causal model, which is supposed to represent the underlying mechanism of the world, is an additive mode
% It is important to note that causal fairness models can indeed help us overcome many of the
% challenges encountered with respect to fair prediction tasks; however, in practice, it is difficult to
% obtain the correct causal model. Moreover, removing all correlated features found through a causal
% model may significantly compromise accuracy.
% big barriers to the application of counterfactual fairness.
%where the individual(s) had belonged to a different demographic grou
% 1) only non-descendants of the sensitive attribute
% are used in classification, 2) the non-deterministic substitutions of the hidden variables are postulated and inferred based
% on domain knowledge, or 3) the complete causal model is
% postulated and estimated, e.g., , being treated as the additive
% noise model then estimating the errors


%% checked 
% \begin{proof}
% \end{proof}

As the first practice of counterfactual fairness,  \cite{kusner2017counterfactual} first constructs a structural causal model using prior domain knowledge. Unobserved variables are then inferred which are independent of and have no causal relationship to the sensitive attributes. %\qli{What does it mean "infers the unobserved variables that are not children of the sensitive attributes"?}\duong{revise to "are independent from has no causal relationship of the sensitive attributes"}
The inferred latent variables are thereafter used as the input for the predictive models. The main limitation of the study is that the strong assumption of the causal model is required which is however hard to achieve in a real-world setting, %\qli{the sentence ''it has a xxx'' is not clear}\duong{revised}
especially when it comes to a large-scale dataset with a great number of features \cite{vanderweele2009concerning,peters2016causal}. 
%\qli{Pearl (2009) showed, however, that it is *mathematically impossibile* to reason about counterfactuals *without* assuming an SCM. Counterfactual fairness, as the name implies, is concerned with counterfactuals. Trying to achieve this without making assumptions on the underlying SCM is doomed to fail, yet this is exactly the premise of this paper.} \duong{revised}
Additionally, even if prior knowledge of causal structure is available, counterfactual fairness algorithms
% \qli{what does it refer?}\duong{done} 
involves computing counterfactuals in the true underlying structural causal model (SCM) \cite{pearl2009causality}, and thus relies on strong impractical assumptions.
% \qli{split the sentence here, replace it to a specific subject}\duong{done} 
Specifically, the algorithm requires complete knowledge of the true structural equations \cite{fong2013causal,bollen2013eight,pearl2012causal}. Another obstacle is that the tabular data contains both continuous and categorical data, making them difficult to be represented by the probabilistic equations. Moreover, when removing all other features and only using non-descendants of sensitive ones, there are possibly insufficient features used for model training which can degrade the model capability and significantly deteriorate the accuracy performance. 
% Moreover, evaluation is a ground challenge in counterfactual fairness.  An ideal way to evaluate the performance of counterfactual fairness algorithms is to have the samples in both the factual world and counterfactual world \cite{kilbertus2020sensitivity,kusner2017counterfactual}. 
% However, from the observational data, we only have observations in the factual world. Given the majority of research \cite{kusner2017counterfactual,russell2017worlds,wu2019counterfactual} on counterfactual fairness, they assume the structure of causal models, generate samples based on it and then evaluate the performance of such samples. The evaluation approach used by these methods is unreliable due to the misspecification of the causal model.


%%%%%%%%%%%%%%%% revising 
% In this context, recent work [22] has argued for the need of taking into account the causal structure
% between features to find a minimal set of actions (in the form of interventions) that guarantees
% recourse. However, while this approach is theoretically sound, it involves computing counterfactuals
% in the true underlying structural causal model (SCM) [35], and thus relies on strong impractical assumptions; specifically, it requires complete knowledge of the true structural equations. While for
% many applications it is possible to draw a causal diagram from expert knowledge, assumptions about
% the form of structural equations are, in general, not testable and may thus not hold in practice [38]. As a result, counterfactuals computed using a misspecified causal model may be inaccurate and
% recommend actions that are sub-optimal or, even worse, ineffective to achieve recourse. 
% In this work, we focus on the problem of algorithmic recourse when only limited causal knowledge is
% available (as it is generally the case). To this end, we propose two probabilistic approaches which
% allow to relax the strong assumption of a fully-specified SCM made in [22]. In the first approach, we
% assume that, while the underlying SCM is unknown, it belongs to the family of additive Gaussian
% noise models [16, 37]. We then make use of Gaussian processes (GPs) [62] to average predictions
% over a whole family of SCMs and thus to obtain a distribution over counterfactual outcomes which
% forms the basis for individualised algorithmic recourse. The second approach considers a different
% subpopulation-based notion of algorithmic recourse by estimating the effect of interventions for
% individuals similar to the one for which we aim to achieve recourse. It thus addresses a different
% (rung 2) target quantity than the counterfactual/individualised (rung 3) approach which allows us to
% further relax our assumptions by removing any assumptions on the form of the structural equations.
% This approach is based on the idea of the conditional average treatment effect (CATE) [1], and relies
% on conditional variational autoencoders (CVAEs) [48] to estimate the interventional distribution. In
% both cases, we assume that the causal graph is known or can be postulated from expert knowledge, as
% without such an assumption causal reasoning from observational data is not possible [38, Prop. 4.1].
%%%%%%%%%%%%%%%%%%%%%%%%%%

To tackle the above limitations, we propose a novel counterfactual fairness approach with the knowledge about structural causal models is limited. In particular, we aim to minimize the sensitive information impact on model decisions, while maintaining satisfactory model accuracy. To achieve the optimal solutions that maximize the fairness-accuracy trade-offs, we propose a minimax game-theoretic approach that consists of three main components. As shown in Figure~\ref{fig:arch}, the invariant-encoder model $p_{\theta}$ learns the invariant representation that is unchangeable from sensitive attributes. After that, the fair-learning predictive model utilizes the invariant representation as the input with the purpose of not only guaranteeing the main learning tasks but also assuring the fairness aspect, while sensitive-awareness model used both the invariant representation and sensitive information that can produce the good learning performance. For theoretical proof, we provide a theoretical analysis for the generalization bound of the minimax objective functions. To illustrate the effectiveness of our proposed method, we compare our method with state-of-the-art methods on three benchmark datasets including \texttt{Law}, \texttt{Compas} and \texttt{Adult} datasets. 
% Moreover, we also propose a new counterfactual fairness evaluation way via individual fairness. 
The experimental results indicate that our proposed method can achieve outstanding fairness performance in comparison with other baselines. Specifically, our contributions can be summarized as follows:






% 1) invariant-encoder model learning the invariant representation that is unchangeable from sensitive attributes; 2) fair-learning predictive model which not only guarantees the main learning tasks but also assures the fairness aspect; 3) sensitive-awareness model that contains the sensitive information which can produce the good learning performance. For theoretical proof, we provide a theoretical analysis for the generalization bound of the minimax objective functions. To illustrate the effectiveness of our proposed method, we compare our method with state-of-the-art methods on three benchmark datasets including \texttt{Law}, \texttt{Compas} and \texttt{Adult} datasets. Moreover, we also propose a new counterfactual fairness evaluation way via individual fairness. The experimental results indicate that our proposed method can achieve the outstanding fairness performance in comparison with other baselines. Specifically, our contributions can be summarized as follows:

%% review 
% Motivated by all the above limitations, we introduce a novel approach to achieve counterfactual fairness in case that the structure of causal model is unavailable. We design a  that consists of three main components: 1) invariant-encoder model learning the invariant representation that is unchangeable from sensitive attributes, 2) fair-learning predictive model which not only optimizes the main performance tasks but also pays attention to achieving the fairness aspect, 3) sensitive-awareness model that contains the sensitive information which can produce the good accuracy performance. To illustrate the effectiveness of our proposed method, we conduct intensive experiments in three datasets: Law, Compas and Adult datasets and make comparisons with several baselines. We also propose a way to evaluate the counterfactual fairness performance via individual fairness. The results illustrate that our proposed method can achieve the outstanding performance in comparison with others. Specifically, our contributions can be summarized as follows:
% Motivated by the above points, we propose a novel deep
% common and unique feature extraction technique for mul-
% timodal data fusion, which we call as DeepCU. Our pro-
% posed DeepCU has two components 1) unique sub-network
% which obtains information specific to individual modalities
% and; 2) common sub-network which obtains combined infor-
% mation from joint (multi-mode) representations by using pro-
% posed deep-convolution tensor networks. Information from
% the common and the unique sub-networks is integrated by a
% fusion layer to obtain an integrated output.

%% checked 
\begin{itemize}
    \item We introduce a minimax game-theoretic approach to obtain the invariant-encoder model and fair-learning predictive model that can jointly produce the counterfactually fair prediction and obtain the competitive performance on both classification and regression tasks. 
    \item We prove the theoretical generalization bounds for the adversarial algorithm of the proposed minimax model. 
    % \item We propose an approach for counterfactual evaluation by approximately measuring the performance of counterfactual fairness via individual fairness. 
    % \qli{My personal favourite is that the authors raise that it is difficult to evaluate counterfactuals because we only measure one out of all possible factuals. That sounds like the definition of counterfactuals, the authors then promise a more practical evaluation scheme, but fail to deliver; Section 6 verbosely describes what seems to be a matching scheme, but this is never formalized and neither used in the evaluation.}\qli{Section 6 verbosely describes what seems to be a matching scheme, but this is never formalized and neither used in the evaluation}
    \item We perform the extensive experiments on three datasets and demonstrate the effectiveness of the proposed method to achieve satisfactory fairness and accuracy. 
\end{itemize}


% In Section 2, we provide a summary of basic concepts in fairness and causal modeling. In Section 3, we provide the formal definition of counterfactual fairness, which enforces that a distribution over possible predictions for an individual should remain unchanged in a world where an individual’s protected attributes had been different in a causal sense. In Section 4, we describe an algorithm to implement this definition, while distinguishing it from existing approaches. In Section 5, we illustrate the algorithm with a case of fair assessment of law school success.

% The paper is organized as follows. We first present the studies related to the counterfactual fairness and show the possible issues relating to these methods. We thereafter provide the preliminaries including the notations, problem settings and definitions which are essential to formally define our approach. We then describe the methodology to achieve the counterfactual fairness by constructing the minimax game-theoretic objective function. In the experiments, we evaluate our approach and compare it with the existing ones via three real-world datasets. Finally, discussions and conclusions are given. 



% We prove the effectiveness of our approach via experiments on three datasets and making a comparison with several baselines. 
% \section{Related works}

% % We focus our review on recent neural based frameworks for
% % multimodal data fusion proposed in the literature. In [Lin et
% % al., 2015] a bilinear-CNN is proposed to obtain bi-modal in-
% % teractions among features obtained from two heterogeneous
% % CNNs. However, the bilinear layer required parameter es-
% % timation of a quadratic number of neurons and hence prone
% % to over-fitting. This limitation is alleviated in [Fukui et al.,
% % 2016] which introduces an alternate formulation of the bilin-
% % ear layer and obtains its compact representation by utilizing
% % sophisticated neural based factorization schemes

% % Most prior work has focused on generating explanations using feature visualization and attribution.


% This section focuses on the research related to our work and then highlights the main limitation of these studies.




% % Second, an earlier approach to individual fairness by
% % Dwork et al. (2012) based on the appealing postulate
% % that “similar individuals should be treated similarly” has
% % proven hard to operationalize in practice. Specifically,
% % it shifts the issue from defining what is fair to defining
% % similarity with respect to the task at hand both between
% % individuals as well as between outcomes.

% \textbf{Individual fairness}. 
% Since counterfactual fairness analyses fairness at the individual level, our work is closely related to individual fairness works. \cite{dwork2012fairness} first captures the main idea of individual fairness that two individuals having the same particular task should be treated similarly. This principle draws much attention with a plethora of studies \cite{miconi2017impossibility,biega2018equity,mukherjee2020two,sharifi2019average}. However, this concept is hard to apply in practice due to the barrier of defining the similarity regarding the individual tasks. This leads to the shift from achieving fairness decisions to defining similar tasks. Another recent study \cite{speicher2018unified} provides a unified approach to evaluate the performance of individual fairness algorithms by using a generalized entropy index that has been previously used widely in economics as a measure of income inequality in the population. Our work utilizes the generalized entropy index as the primary metric for evaluation purposes. 

% % #only non-descendants of the sensitive attribute are used in classification

% \textbf{Counterfactual fairness}. 
% In order to achieve fairness in the model decision, the traditional approach is the unawareness model \cite{grgic2016case} that only uses the non-sensitive attributes as the input for predictive models. This approach seems to be reasonable but neglects the bias effect of sensitive attributes into the normal features. Thus, the study \cite{kusner2017counterfactual} first proposed the approach of counterfactual fairness by only using the non-descendants of the sensitive attribute for prediction tasks. They first assume the causal graph structure with the latent variables independent from the sensitive attributes. The study thereafter fits the data into the causal model and produces the posterior distribution for unobserved variables. The inferred variables are finally utilized as an input for the predictive model. Apart from that, multi-world counterfactual fairness \cite{russell2017worlds} introduces another alternative method to deal with the uncertainty of the ground-truth causal model. They firstly have an assumption that there are several possible causal diagrams that represent different counterfactual worlds. Thereafter, the authors build a neural network and then use the gradient descent algorithm to minimize the difference in the predictions between the different worlds. Although this approach seems to be promising, it also needs a list of causal models to be taken into consideration. To sum up, all of the above methods require strong assumptions about causal graphs to infer the latent variables. Moreover, since the sensitive attribute is frequently inherent nature that can affect all other features, removing all features affected by sensitive attributes can degrade the model accuracy.



% % The existing study \cite{kusner2017counterfactual} in counterfactual fairness claims that 
% % aims to infer the latent variables, which are not the children nodes of the sensitive attributes. In order to obtain the unobserved variables, the study fits the data into the causal model and produces the posterior distribution for unobserved variables. The inferred variables are thereafter utilized as an input for the predictive model. Apart from that, multi-world counterfactual fairness \cite{russell2017worlds} proposes an approach to deal with the uncertainty of the ground-truth causal model. They firstly have an assumption that there are several possible causal diagrams that represent different counterfactual worlds. Thereafter, the authors build a neural network and then use the gradient descent algorithm to minimize the difference in the predictions between the different worlds. Although this approach seems to be promising, it also needs a list of causal models to be taken into consideration. To sum up, all of the above methods require strong assumptions about causal graphs to infer the latent variables. 


% % \textbf{Minimax theorem} One of the well-known applicaiton of minimax theorem is the generative adversarial network which trains two different neural network together. 



% % This section first outlines the research related to counterfactual fairness and then highlights the main limitation of these studies. The majority of existing studies \cite{kusner2017counterfactual} in counterfactual fairness pay attention to inferring the latent variables which are not the children nodes of the sensitive attributes. In order to have the latent variable, the studies fit the data into the causal model, and produce the posterior distribution for unobserved variables, and thereafter use them as an input for the predictive model.  Multi-world counterfactual fairness \cite{russell2017worlds} proposed an approach to deal with the unknown ground-truth causal model by minimizing the difference between the prediction in the original world and counterfactual world. However, this approach also needs to have a set of candidate causal models to take into consideration. To sum up, all of the above methods require quite strong assumptions about causal graphs to infer the latent variables. 

\section{Preliminaries}
\label{sec:pre}
% This section\qli{In this section, we provide} aims to 
In this section, we provide notations and problem statements and then review individual and counterfactual fairness notions. 

%\subsection{Notations and problem settings}
%\qli{it is wired usage of X and x, $\mathbf{X}$ should be a matrix, $\boldsymbol{x}$ should be a vector, the matrix should be a upper bold symbol, the vector should be lower bold symbol}

Throughout the paper, upper-cased letters $X$ and $\boldsymbol{X}$ represent the random scalars and vectors respectively, while lower-cased letters $x$ and $\boldsymbol{x}$ denote the deterministic scalars and vectors, respectively. We consider a dataset $\mathcal{D} = \{x_i, s_i, y_i\}^n_{i=1}$ consisting of $n$ instances, where $x_i \in \boldsymbol{X}$ is the normal features (e.g. age, working hours,..), $s_i \in \boldsymbol{S}$ is the sensitive feature (e.g. race and gender), and $y_i \in Y$ is the target variable regarding individuals $i$. Sensitive features specify an individual's belongings to socially salient groups (e.g. women and Asian). $H(.)$ and $I(.)$ are the corresponding Shannon entropy and mutual information \cite{cover1991entropy}, and $\mathcal{L}(.)$ is the loss function (e.g. cross-entropy for classification tasks, mean square error for regression tasks). Finally, $f_{\theta}$ represents a neural network model parameterized by $\theta$. 

% The value of $Y$ if $Z$ had taken value $z$ for two observarable variable $Z$ and $Y$. We denote the equation for $Z$ are replaced $Z = z$. $Y_{Z \leftarrow z}$


% \qli{can you introduce more about the main purpose of each model, I know you discussed each component in the following section, it's better to use one sentence as explanations for the figure.} \duong{revised} 
Figure~\ref{fig:arch} generally illustrates our proposed approach that consists of an invariant-encoder model ($q_\theta$) generating the invariant features, a fair-learning predictor ($f_{\phi_1}$) trained by invariant features and a sensitive-aware predictor ($f_{\phi_2}$) trained on invariant and sensitive representation. 

% The framework also includes a pre-trained auto-encoder model ($q_{\uppsi}$) that produces latent representation from sensitive features. 

% \qli{Figure 1's font could be bigger.}\duong{done}
\begin{figure*}[t]
  \includegraphics[width=\textwidth]{cf_architecture.pdf}
  \caption{The framework consists of three trainable components: the invariant-encoder model $p_\phi$, fair-learning model $f_{\phi_1}$ and sensitive-awareness $f_{\phi_2}$ model.}
\label{fig:arch}
\end{figure*}

%\subsection{Individual and counterfactual fairness notions}



% \begin{figure}[t]
%   \includegraphics[width=0.5\textwidth]{figure/architecture.pdf}
%   \caption{The framework consists of three components: the invariant-encoder model, fair-learning model $f_{\phi_1}$ and sensitive-awareness $f_{\phi_2}$ model. The
% solid lines and dash lines are the corresponding inputs and backpropogations. Yellow, blue, orange color represent features, models, and loss, respectively.}
% \end{figure}



% \begin{defn}[Structural causal model \cite{pearl2000models}] A structural causal model $\mathcal{M} = \{\mathbf{U}, \mathbf{V}, \mathbf{F}\}$ consists of three main components which are defined as:

% \begin{itemize}
%     \item $\mathbf{U}$ is the set of unobserved variables of any data types such as continuous, discrete and mixed type. Unobserved variables are normally assumed to be independent from any other nodes in the graph. 
%     \item $\mathbf{V}$ is the set of observed random variables which are endogenous nodes. 
%     \item $\mathbf{F}$ is the set of structural causal functions describing the causal relationship among the unobserved and observed variables. Specifically, for each node $\boldsymbol{X} \in V$, a function $f_X \in F$ such that $X = f_X(\text{Pa}(X), \mathbf{U}_X)$ where $\text{Pa}(X)$ is the parent nodes of $X$. 
% \end{itemize}
% \end{defn}

% A causal model induces a causal diagram $\mathcal{G} = \{\mathcal{V}, \mathcal{E}\}$ that is a probabilistic graphical model representing the assumptions about data-generating mechanism. A causal graph consists of a set of nodes and edges where each node represents a random variable, and each edge illustrates the causal relationship. The causal effect in causal model is facilitated by \textit{do-operator} or intervention \cite{pearl2000models} that assigns value $x$ to a random variable $X$ denoted by $do(x)$. $do(x)$ represents model manipulations meaning that a causal model $\mathcal{M}$ is defined as substitution of causal equation $X = f_X(\text{Pa}(X)_\mathcal{G}, \mathbf{U}_X)$ with $X=x$




% \begin{defn}[Individual fairness \cite{dwork2012fairness}]
% An algorithm is considered as fair at individual level if it produces the similar predictions to similar individuals. $\hat{y}(x_i, s_i) \approx \hat{y}(x_j, s_j)$
% \end{defn}

% Individual fairness is first mentioned in the study \cite{dwork2012fairness} capturing the fairness principle that individuals owning the similar properties should be treated similarly. 


%\qli{definition 1 is not at all, for example what are the variables with hat, what is the meaning of $Y_S<-s$ in the formula.} \duong{revised}



\begin{definition}[Counterfactual fairness \cite{kusner2017counterfactual}]
A classifier is considered as counterfactual fair given the sensitive attribute $S=s$ if:
\begin{equation}
\label{eqn:cf}
\small
    P(\hat{Y}_{S \leftarrow s} = y| X = x, S = s) = P(\hat{Y}_{S \leftarrow \hat{s}} = y| X = x, S = \hat{s}) 
\end{equation}
where $\hat{Y}$ denotes the model prediction depends on $X$ and $S$, while model prediction for intervention $S \leftarrow \hat{s}$ is denoted as $\hat{Y}_{S \leftarrow s}$. Meanwhile, $P(\hat{Y}_{S \leftarrow \hat{s}} = y| X = x, S = \hat{s})$ is the counterfactual prediction where we change the value $S=s$ to $S=\hat{s}$.

% where $\hat{Y}$ is the model prediction, $S \leftarrow \hat{s}$ is the operation that assign the value $\hat{s}$ to variable $S$, $P(\hat{Y}_{S \leftarrow \hat{s}} = y| X = x, S = \hat{s})$ is the counterfactual prediction where we change the value $S=s$ to $S=\hat{s}$.
% $A=a$ to $A=\hat{a}$
\end{definition}


The Eq.~\eqref{eqn:cf} ensures that the distribution over possible predictions is the same in both the actual world and a counterfactual world where the sensitive attribute(s) were modified while all other conditions remain unchanged.



% \qli{What does $Y_{S \leftarrow s} $ mean } \duong{added above}
% \qli{$\hat{s} $ is generally an estimate of s, not a counterfactually set value. What do the authors mean by do(S)? Under what assumed causal model are they operating? What are the causal assumptions? Is this model identifiable?}

% Counterfactual fairness is an individual-level fairness notion proposed by \cite{kusner2017counterfactual}, which formulates fairness as the equivalence of two counterfactual quantities.


% Consider an individual has a set of characteristics and a sensitive attribute $s$. We assume that 




\section{Related work}
%\qli{Related work misses highly relevant work, and what it consideres it disucsses in insufficient detail. See for example, Sanchez-Martin et al (2021) and Karimi et al (2020) for two highly relevant works on counterfactual fairness and algorithmic recourse. The authors will be particularily interested in the impossibility theorem in the latter.} \duong{added}
This section focuses on the research related to our work and then highlights the main limitation of these studies.

%\qli{The related work section is concise but well-written and effective. Perhaps, some papers, like the following, could be added and commented in order to have a more complete overview of the state-of-the-art.Grari, V., Lamprier, S., & Detyniecki, M. (2020). Adversarial learning for counterfactual fairness. arXiv preprint arXiv:2008.13122.Kim, H., Shin, S., Jang, J., Song, K., Joo, W., Kang, W., & Moon, I. C. (2021, February). Counterfactual fairness with disentangled causal effect variational autoencoder. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 35, No. 9, pp. 8128-8136).Di Stefano, P. G., Hickey, J. M., & Vasileiou, V. (2020). Counterfactual fairness: removing direct effects through regularization. arXiv preprint arXiv:2002.10774. Also, some of the referenced papers in the manuscript are not cited using their most updated and published version. } \duong{revised}

\textbf{Individual fairness}. 
Since counterfactual fairness analyses fairness at the individual level, our work is closely related to individual fairness works. \cite{dwork2012fairness} first captures the main idea of individual fairness that two individuals having the same particular task should be treated similarly. This principle draws much attention with a plethora of studies \cite{miconi2017impossibility,biega2018equity,mukherjee2020two,sharifi2019average}. However, this concept is hard to apply in practice due to the barrier of defining the similarity regarding the individual tasks. This leads to the shift from achieving fairness decisions to defining similar tasks. Another recent study \cite{speicher2018unified} provides a unified approach to evaluate the performance of individual fairness algorithms by using a generalized entropy index that has been previously used widely in economics as a measure of income inequality in the population. Our work utilizes the generalized entropy index as the primary metric for evaluation purposes. 

% #only non-descendants of the sensitive attribute are used in classification

\textbf{Counterfactual fairness}. 
In order to achieve fairness in the model decision, the traditional approach is the unawareness model \cite{grgic2016case} that only uses the non-sensitive attributes as the input for predictive models. This approach seems to be reasonable but neglects the biased effect of sensitive attributes on normal features. Thus, the study \cite{kusner2017counterfactual} first proposed the approach of counterfactual fairness by only using the non-descendants of the sensitive attribute for prediction tasks. They first assume the causal graph structure with the latent variables independent from the sensitive attributes. The study thereafter fits the data into the causal model and produces the posterior distribution for unobserved variables. The inferred variables are finally utilized as inputs for the predictive model. Apart from that, multi-world counterfactual fairness \cite{russell2017worlds} introduces another alternative method to deal with the uncertainty of the ground-truth causal model. They first have an assumption that there are several possible causal diagrams that represent different counterfactual worlds. Thereafter, the authors build a neural network and then use the gradient descent algorithm to minimize the difference in the predictions between the different worlds. Although this approach seems to be promising, it also needs a list of causal models to be taken into consideration. To sum up, all of the above methods require strong assumptions about causal graphs to infer the latent variables. Moreover, sensitive attributes such as race, gender, and nationality are personally intrinsic attributes and immensely influential that normally have a causal relationship to other features.
%\qli{what is the meaning}\duong{revise "inherent nature" to "personally intrinsic attributes and immensely influential that normally have a causal relationship to other features"} 
% Therefore, removing all features affected by sensitive attributes can degrade the model accuracy. Another line of research proposes disentangled causal effect Variational Autoencoder (DCEVAE) to resolve this limitation by disentangling the exogenous uncertainty into two latent variables: either 1) independent to interventions or 2) correlated to interventions without causality. Particularly, the disentangling approach preserves the latent variable correlated to interventions in generating counterfactual examples. 






\section{Methodology}


This section illustrates our proposed method, which can achieve counterfactual fairness without the assumption of structural causal models. In summary, our proposed method aims to learn a representation along with a predictive model which together can make a counterfactual fair prediction and maintain the prediction accuracy. In summary, our proposed approach contains three main components:  1) invariant-encoder model learning the invariant representation that is unchangeable from sensitive attributes; 2) fair-learning predictive model which not only guarantees the main learning tasks but also assures the fairness aspect; 3) sensitive-awareness model that contains the sensitive information which can produce the good learning performance. Each component would be discussed in detail in Section~\ref{three}.


% Our proposed framework is illustrated in Figure~\ref{fig:arch} that describes the training and backpropagation process as well as inputs and different components. In general, the proposed framework has three main trainable models including an invariant-encoder model ($q_\theta$) that generates the invariant features, a fair-learning predictor ($f_{\phi_1}$) that predicts outcomes based on invariant features and a sensitive-aware predictor ($f_{\phi_2}$) that predicts outcomes based on both invariant and sensitive representation. The framework also includes a pre-trained auto-encoder model ($q_{\uppsi}$) that produces latent representation from sensitive features. 



% For clarity, we will briefly describe the auto-encoder model and then present the two predictors followed by the invariant-encoder model.


%\qli{The caption of figure 2 should be rephrased as it is not really understandable.}\duong{revised}
\begin{figure}[t]
\centering
\label{fig:graph}
  \includegraphics[width=0.4\textwidth]{invariant_graph.pdf}
  \caption{A structural causal model illustrates the causal relationships between different features.  $\boldsymbol{S}_1$ and $\boldsymbol{S}_2$ are sensitive features (e.g., gender or race), $\boldsymbol{X}_1$, $\boldsymbol{X}_2$ and $\boldsymbol{X}_3$ are the non-sensitive features (e.g., education or working hours), $\boldsymbol{Z}$ is a latent representation that is independent of sensitive attributes and $Y$ is the target variable. The large white arrows from $\boldsymbol{S}_1$ and $\boldsymbol{S}_2$ represent that $\boldsymbol{S}_1$ and $\boldsymbol{S}_2$ have the causal effects to every variables ($\boldsymbol{X}_1$, $\boldsymbol{X}_2$, $\boldsymbol{X}_3$) and target variable ($Y$) contained in the box. }
  \label{fig:graph}
\end{figure}


\subsection{Motivation}
% \qli{Although the authors do not refer to it, the proposed method is extremely reminiscient of the work by Zemel et al (2016) who propose to learn an representation Z that is independent of S and Y given Z. They, however do not claim to achieve counterfactual fairness, but 'only' aim to achieve statistical parity, which is a purely observational notion.}
%review 

% .\qli{In a nutshell, the authors learn a latent representation Z over the measured variables X, such that they achieve conditional independence between the protected attributes S and the target variable Y given Z. Note that this does neither require assumptions on the graphical structure (rung 2) nor SCM (rung 3) and means we are squarely in the space of associations (rung 1).} 

We first consider an example of probabilistic graphical model in Figure~\ref{fig:graph}, we have two sensitive features: $\boldsymbol{S_1}$ and $\boldsymbol{S}_2$,
%\qli{Why are $S_1$ and $S_2$ both bold? Why is it not just one bold S? Same for X_1, 2, 3. }\duong{fixed} 
non-sensitive features $\boldsymbol{X}_1$, $\boldsymbol{X}_2$, and $\boldsymbol{X}_3$, and the target variable $Y$. We want to find a latent representation $\boldsymbol{Z}$ that is independent of the sensitive attributes. Producing the latent representation that is invariant across different sensitive attributes is a challenging task. However, we can handle this challenge if we have information about sensitive attributes. We make an assumption that the probability $p(Y|\boldsymbol{Z})$ remains the same across different sensitive attributes $\boldsymbol{S}_1$ and $\boldsymbol{S}_2$ because $\boldsymbol{Z}$ has the direct causal relationship to target variable $Y$ and also does not rely on $\boldsymbol{S}_1$ and $\boldsymbol{S}_2$. Meanwhile, other remaining features $\boldsymbol{X}_1$, $\boldsymbol{X}_2$ and $\boldsymbol{X}_3$ are causally influenced by $\boldsymbol{S}_1$ and $\boldsymbol{S}_2$; thus, the probability of $p(Y|\boldsymbol{X}_1)$, $p(Y|\boldsymbol{X}_2)$ and $p(Y|\boldsymbol{X}_3)$ will change if we change the value of $\boldsymbol{S}_1$ and $\boldsymbol{S}_2$. %\qli{What do you mean by "will change if we change the value for it"?}\duong{revised}


% Meanwhile, since sensitive attributes are the exogenous nodes which has no parents in the causal graph and \qli{explain more about exogenous nodes, what are they}\duong{revise} have causal effects on remaining features, the probability of $p(Y|\boldsymbol{X}_1)$, $p(Y|\boldsymbol{X}_2)$ and $p(Y|\boldsymbol{X}_3)$ will change if we change the value of $\boldsymbol{S}_1$ and $\boldsymbol{S}_2$. \qli{What do you mean by "will change if we change the value for it"?}\duong{revised}




% In particular, we aim to eliminate the sensitive information in model decisions, as well as maintain the model accuracy. To achieve the saddle point that maximizes the fairness-accuracy tradeoff, we propose a minimax game-theoretic approach that consists of three main components:

% \subsection{Three-player model for invariant fairness}


In general, our main purpose is to find a representation ($\boldsymbol{Z}$) that is invariant across different sensitive attributes. We want to design an invariant-encoder model $p_{\theta}: \boldsymbol{X} \rightarrow \boldsymbol{Z}$ that learns the representation ($\boldsymbol{Z}$) from the input ($\boldsymbol{X}$). An ideal invariant representation should satisfy the following conditions.
\begin{equation} 
\small
\label{eqn:overall}
    Y \perp do(\boldsymbol{S}) | \boldsymbol{Z} \iff H(Y|\boldsymbol{Z},do(\boldsymbol{S})) = H(Y|\boldsymbol{Z})
\end{equation}
%\qli{The formula (2° is not understandable and should be explained in a more detailed way and authors should explain every constituent of the formula., e.g., explain left and right side separately, what does H mean, what is do}\duong{revised}


where $\perp$ denotes probabilistic independence. $Y$ is independent
of $do(\boldsymbol{S})$ only when conditioned on latent representation $\boldsymbol{Z}$ and we call this variance property. Moreover, the Eq.~\eqref{eqn:overall} means that the representation ($\boldsymbol{Z}$) is unchangeable, and sensitive attributes ($\boldsymbol{S}$) do not provide extra information to predict target variables ($Y$). This means that making an intervention on sensitive attribute ($\boldsymbol{S}$) does not lead to changes in the model prediction ($Y$).


% where $\perp$ denotes probabilistic independence, $Y$ is independent
% of $do(\boldsymbol{S})$ only when conditioned on latent representation $\boldsymbol{Z}$. We call this property invariance. The Eq.~\eqref{eqn:overall} means that the representation ($\boldsymbol{Z}$) is unchangeable, and sensitive attributes ($\boldsymbol{S}$) do not provide extra information to predict target variables ($Y$). This means that making an intervention on sensitive attribute ($\boldsymbol{S}$) does not lead to the changes in the model prediction ($Y$).

% This section introduces our basic three-player model. The proposed model includes three players: invariant fairness model concludes $p_\theta$ and $q_\psi$ that generate the invariant features and latent representation of sensitive features from data, a fair-learning predictor $f_{\phi_1}$ that predicts outcomes based on invariant features, a sensitive-aware predictor $f_{\phi_2}$ that predicts outcomes based on both invariant and sensitive representation. Figure~\ref{fig:arch} illustrates the proposed three-player
% model in our work. In general, we aim to train the models that can exclude the sensitive information and main the high accuracy performance. \qli{one sentence to explain why is minimax game}. For clarity, we will describe the two predictors followed by the invariant-encoder model.


% This section introduces our basic three-player model.


%% checked 
% \qli{this should be put at the beginning of methodology}
% \duong{done}

\subsection{Three-player model for invariant fairness}
\label{three}
Our proposed framework is illustrated in Figure~\ref{fig:arch} which describes the training and backpropagation process as well as inputs and different components. In general, the proposed framework has three main trainable models including an invariant-encoder model ($q_\theta$) that generates the invariant features, a fair-learning predictor ($f_{\phi_1}$) that predicts outcomes based on invariant features and a sensitive-aware predictor ($f_{\phi_2}$) that predicts outcomes based on both invariant and sensitive representation. The framework also includes a pre-trained auto-encoder model ($q_{\uppsi}$) that produces latent representation from sensitive features. 
For clarity, we will briefly describe the auto-encoder model and then present the two predictors followed by the invariant-encoder model.

% Our proposed framework is illustrated in Figure~\ref{fig:arch} that describes the training and backpropagation process as well as inputs and different components. In general, the proposed framework has three main trainable models including an invariant-encoder model ($q_\theta$) that generates the invariant features, a fair-learning predictor ($f_{\phi_1}$) that predicts outcomes based on invariant features and a sensitive-aware predictor ($f_{\phi_2}$) that predicts outcomes based on both invariant and sensitive representation. The framework also includes a pre-trained auto-encoder model ($q_{\uppsi}$) that produces latent representation from sensitive features. For clarity, we will briefly describe the auto-encoder model and then present the two predictors followed by the invariant-encoder model.



% The proposed model includes three players: invariant fairness model concludes $p_\theta$ and $q_\psi$ that generate the invariant features and latent representation of sensitive features from data, a fair-learning predictor $f_{\phi_1}$ that predicts outcomes based on invariant features, a sensitive-aware predictor $f_{\phi_2}$ that predicts outcomes based on both invariant and sensitive representation. Figure~\ref{fig:arch} illustrates the proposed three-player
% model in our work. In general, we aim to train the models that can exclude the sensitive information and main the high accuracy performance. \qli{one sentence to explain why is minimax game}. For clarity, we will describe the two predictors followed by the invariant-encoder model.

%\qli{The paragraph about auto-encoder is not clear and should be revised.}
\textbf{Auto-encoder model. }%\duong{revised}
 Sensitive attributes ($\boldsymbol{S}$) are in the categorical form and discrete values, which is hard to utilize in neural networks. Therefore, we construct the auto-encoder model ($q_{\uppsi}$) with the purpose of 1) converting discrete values to continuous form which is more suitable to the complicated models, 2) capturing the intrinsic relationship between categorical groups, and flexibly control the dimensional number of embedding vector. The auto-encoder model ($q_{\uppsi}$)\cite{ng2011sparse} is trained beforehand by using all of the features as the input. The encoder-decoder architecture with an embedding layer is used that aims to project sensitive attributes $\boldsymbol{S}$ onto an $e$-dimensional latent space $\mathcal{R}^e$ ($q_{\uppsi}: \boldsymbol{S} \rightarrow \boldsymbol{S}^e$). The latent representation of sensitive attributes ($\boldsymbol{S}^e$) would be thereafter utilized to be injected into the sensitive-aware predictor later.

% Note that since sensitive attributes ($\boldsymbol{S}$) are in the categorical form, 
% our aim when constructing the auto-encoder model ($q_{\uppsi}$) is to capture intrinsic nature between categorical groups and flexibly control the dimensional number of embedding vector. The auto-encoder model ($q_{\uppsi}$)\cite{ng2011sparse} is trained beforehand by using all of the features as the input. The encoder-decoder architecture with an embedding layer is used that aims to project sensitive attributes $\boldsymbol{S}$ onto an $e$-dimensional latent space $\mathcal{R}^e$ ($q_{\uppsi}: \boldsymbol{S} \rightarrow \boldsymbol{S}^e$). The latent representation of sensitive attributes ($\boldsymbol{S}^e$) would be thereafter utilized to be injected into the sensitive-aware predictor later.

\textbf{Two predictors.} The fair-learning predictor $f_{\phi_1}: \boldsymbol{Z} \rightarrow Y$ that predicts target variable ($Y$) from the latent representation ($\boldsymbol{Z}$). Meanwhile, the sensitive-aware predictive model $f_{\phi_2}:(\boldsymbol{Z},\boldsymbol{S}^e) \rightarrow Y$ makes a prediction ($Y$) from latent representation ($\boldsymbol{Z}$) and sensitive attributes information ($\boldsymbol{S}^e$). The only difference between them is that the sensitive-aware predictor can access to sensitive information, while the fair-learning one only uses the invariant representation. The loss functions for the fair-learning and sensitive-aware predictive model are $\mathcal{L}(Y, f_{\phi_1}(\boldsymbol{Z}))$ and 
$\mathcal{L}(Y, f_{\phi_2}(\boldsymbol{Z}, \boldsymbol{S}^e))$, respectively. Thus, the optimal solutions for both of them can be defined%\qli{defined}\duong{fixed} 
as follows:
\begin{equation}
\label{eqn:pred1}
\small
    \phi_i^* = \argmin_{\phi_1} \mathbb{E}[\mathcal{L}(Y, f_{\phi_1}(\boldsymbol{Z}))]
\end{equation}
\begin{equation}
\label{eqn:pred2}
\small
    \phi_2^* = \argmin_{\phi_2} \mathbb{E}[\mathcal{L}(Y, f_{\phi_2}(\boldsymbol{Z}, \boldsymbol{S}^e))]
\end{equation}
% \qli{put \left(p_{\phi}\right) and \left(p_{\psi}\right) in this part} 

% \textbf{Invariant fairness model.} The invariant fairness model consists of two components: an invariant-encoder for fairness learning ($p_\theta$) and auto-encoder for sensitive attributes learning ($q_\uppsi$). The auto-encoder model $q_{\uppsi}$ is trained beforehand with an embedding layer that aims to project sensitive attributes $\boldsymbol{S}$ onto an $e$-dimensional latent space $\mathcal{R}^e$. The latent representation of sensitive attributes ($\boldsymbol{S}^e$) would be thereafter used to be injected into the sensitive-aware predictor. Note that since sensitive attributes ($\boldsymbol{S}$) are in the categorical form, the auto-encoder model $q_{\uppsi}$ allows us to capture intrinsic nature between categorical groups and flexibly control the dimensional number of embedding vector. Meanwhile, the invariant-encoder model $q_{\theta}: \boldsymbol{X} \rightarrow \boldsymbol{Z}$ that learns the representation $\boldsymbol{Z}$ from the input $\boldsymbol{X}$. The aim of the invariant-encoder model is first to optimize the fair-learning predictive model, and the second is to minimize the gap between invariant prediction loss and the original prediction loss to ensure the model accuracy in the prediction task and exclude the sensitive information in model decisions. This leads to the optimal solution for the invariant-encoder model is:

\textbf{Invariant-encoder model.} The invariant-encoder model $q_{\theta}: \boldsymbol{X} \rightarrow \boldsymbol{Z}$ learns the representation ($\boldsymbol{Z}$) from the input ($\boldsymbol{X}$). The aims of the invariant-encoder model are first to optimize the fair-learning predictive model, and then to minimize the gap between the predictions of two predictive models. This allows to ensure the model accuracy in the prediction task and excludes sensitive information in model decisions. Therefore, the learning objective for the invariant-encoder model is:
\begin{equation}
\label{eqn:encoder}
\small
    \theta^* = \argmin_{\theta} \mathcal{L}(Y, f_{\phi^*_1}(\boldsymbol{Z})) + \lambda h(f_{\phi^*_1}(\boldsymbol{Z}) - f_{\phi^*_2}(\boldsymbol{Z},\boldsymbol{S}^e))
\end{equation}
where $h(t)$ is a strictly monotonic function that increases when $t > 0$, and decreases when $t < 0$. 
% where L(·) is a loss function which measures the prediction error,
% �� (·) is a predictor based on the sensitive feature �� and non-sensitive
% features �� . The conditional independence constraint ensures that
% for each individual, an intervention on �� will not influence the
% result of the predictor
% Figure~\ref{fig:arch} illustrates our framework that contains three trainable model: 
% Figure~\ref{fig:arch} illustrates our framework that contains three trainable model: 
% The auto-encoder model $q_{\uppsi}$ is trained beforehand with an embedding layer that aims to project sensitive attributes $\boldsymbol{S}$ onto an $e$-dimensional latent space $\mathcal{R}^e$. The latent representation of sensitive attributes ($\boldsymbol{S}^e$) would be thereafter used to be injected into the sensitive-aware predictor. Note that since sensitive attributes ($\boldsymbol{S}$) are in the categorical form, the auto-encoder model $q_{\uppsi}$ allows us to capture intrinsic nature between categorical groups and flexibly control the dimensional number of embedding vector. The proposed framework is shown in Figure~\ref{fig:arch} that describes the training and backpropagation process as well as the input and different components. Specifically, our framework consists of  three main trainable models:



% \textbf{Objective function and training.} With the latent representation $\boldsymbol{Z} = q_{\theta}(\boldsymbol{X})$, the final objective function from Eq.~\eqref{eqn:pred1}, ~\eqref{eqn:pred2} and~\eqref{eqn:encoder} can be rewritten in the minimax form Eq.~\eqref{eqn:objective}. Overall, the loss function represents the minimax game where the invariant-encoder model plays cooperative games with the fair-learning predictor, and adversarial games with the sensitive-aware predictor.


\textbf{Objective function and training.} By combining learning objectives from Eq.~\eqref{eqn:pred1}, ~\eqref{eqn:pred2} and~\eqref{eqn:encoder}, we can produce the final objective function in the minimax form Eq.~\eqref{eqn:objective} with the latent representation $\boldsymbol{Z} = q_{\theta}(\boldsymbol{X})$. Overall, the loss function represents the minimax game where the invariant-encoder model plays cooperative games with the fair-learning predictor and adversarial games with the sensitive-aware predictor. The objective functions first aims to minimize the prediction of function $f_{\phi_1}$ and make the gap between $f_{\phi_2}$ and $f_{\phi_1}$ as small as possible. 
%\qli{Better explain the intuition about formula (6) and the introduction of minmax game.}\duong{revising}

\begin{equation}
\small
\label{eqn:objective}
     \argmin_{\theta, \phi_1} \argmax_{\phi_2} \mathcal{L}(Y,f_{\phi_1}(\boldsymbol{Z})) + \lambda h(f_{\phi_1}(\boldsymbol{Z}) - f_{\phi_2}(\boldsymbol{Z},\boldsymbol{S}^e))
\end{equation}

%% checked 
Regarding the training process for three models, the loss functions corresponding to each model are first calculated. 
We thereafter update each model by descending stochastic gradients regarding invariant-encoder model, fair-learning predictor and ascending stochastic gradient of sensitive-aware predictor. We perform updating procedure with a number of steps, and only one model is updated for each step. In our experiments, we used Adam optimization algorithm \cite{kingma2014adam} to optimize~\eqref{eqn:objective}. 


 
% With the latent representation $Z = q_{\theta}(\boldsymbol{X})$, the final objective function from Eq.~\eqref{eqn:pred1}, ~\eqref{eqn:pred2} and~\eqref{eqn:encoder} is in the minimax form:
% \begin{equation}
% \small
% \label{eqn:objective}
%      \argmin_{\theta, \phi_1} \argmax_{\phi_2} \mathcal{L}(Y,f_{\phi_1}(\boldsymbol{Z})) + \lambda h(f_{\phi_1}(\boldsymbol{Z}) - f_{\phi_2}(\boldsymbol{Z},\boldsymbol{S}^e))
% \end{equation}



% On the other hand, the first aim of the invariant-encoder model is to optimize the loss function of the fair-learning predictive model, which ensures the performance accuracy in the main task. Its second goal is to minimize the gap between invariant prediction loss and the original prediction loss that aims to eliminate the sensitive information in latent representation. 
% This leads to the optimal solution for the invariant-encoder model is:

% Formally, an embedding is a mapping of a categorical variable into an n-dimensional vector.
% This provides us with 2 advantages. First, we limit the number of columns we need per category. Second, embeddings by nature intrinsically group similar variables together.

% The goal of the fair-learning and sensitive-aware predictive model is to minimize the prediction which are 


% \begin{equation}
%     \mathcal{L}(Y, f_{\phi_1}(\boldsymbol{Z}))
% \end{equation}

% \begin{equation}
%     \mathcal{L}(Y, f_{\phi_2}(\boldsymbol{Z}, \boldsymbol{S_e}))
% \end{equation}
% The goal of the environment-agnostic and environment- aware predictors is to predict Y from the rationale Z. The only difference between them is that the latter has access to E as another input feature but the former does not. Formally, denote L(Y; f) as the cross-entropy loss on a single instance. Then the learning objective of these two predictors can be written as follows.

% Meanwhile, the aim of the invariant-encoder model is first to optimize the fair-learning predictive model, and the second is to minimize the gap between invariant prediction loss and the original prediction loss to ensure the model accuracy in the prediction task and exclude the sensitive information in latent representation. This leads to the optimal solution for the invariant-encoder model is:



% \begin{equation}
% \label{eqn:encoder}
% \small
%     \theta^* = \argmin_{\theta} \mathcal{L}(Y, f_{\phi^*_1}(\boldsymbol{Z})) + \lambda h(f_{\phi^*_1}(\boldsymbol{Z}) - f_{\phi^*_2}(\boldsymbol{Z},\boldsymbol{S}^e))
% \end{equation}
% where $h(t)$ is a strictly monotonic function that increases when $t > 0$ and decreases when $t < 0$. 


% Regarding the training progress for the three models (invariant-encoder model, fair-learning, and sensitive-aware predictive models), the loss functions are firstly calculated for each of them by using target variable and models' prediction. Thereafter, we perform gradient descent steps by descending their stochastic gradients respect to their own losses. Any gradient-based optimization algorithms can be deployed. In our works, we used Adam optimization \cite{kingma2014adam}. \qli{add the algorithm you used and explain how to optmize each component}. 





% Regarding training progress, the three models (invariant-encoder model, fair-learning, and sensitive-aware predictive models) perform gradient descent steps with respect to their own losses. In particular, the loss functions are calculated for each model. Thereafter, we update the invariant-encoder model, fair-learning, and sensitive-aware predictive models by descending their stochastic gradients. For each model, we would perform backpropagation in turn. Any gradient-based optimization algorithms can be deployed. In our works, we used Adam optimization \cite{kingma2014adam}. \qli{add the algorithm you used and explain how to optmize each component}. 

% Update the generator by descending its stochastic gradient:

% The gradient-based updates can use any standard gradient-based learning rule. We used momen-
% tum in our experiments


            % path = step % 7
            % if path in [0]:
            %     gen_loss.backward()
            %     optimizer1.step()
            % elif path in [1, 2, 3]:
            %     loss_agnostic.backward()
            %     optimizer2.step()
            % elif path in [4, 5, 6]:
            %     loss_awareness.backward()
            %     optimizer3.step()
            % step += 1
            

% Figure~\ref{fig:arch} specifically describes the training and backpropagation process. 


% \begin{Properties}
%   \item First
%   \item Second
% \end{Properties}

\section{Theoretical analysis}
%% review 
This section provides the generalization bound for our proposed method under the minimax setting.
Remember we consider the local minimax empirical risk minimization problem
\begin{equation}
\small 
\underset{\theta, \phi_{1}}{\min }\, \underset{\phi_{2}}{\max } \,\mathbb{E}[\mathcal{L}\left(Y, f_{\phi_{1}}(\boldsymbol{Z})\right)]
\label{eq:obj}
\end{equation}
By applying a duality argument, we reformulate the dual problem via the probability of sensitive attributes.
Let $P^{*}$ be the ideal fair sample distribution corresponding to $P/Q_0$, according to the underlying exposure mechanism $Q_0$ and data distribution $P$.  We choose the Wasserstein distance to investigate how to transport from the observed data distribution
to an ideal data distribution that is independent of the sensitive attributes. The reason is that unlike the Kullback-Leibler divergence, the Wasserstein metric is a true probability metric and considers both the probability of and the distance between various outcome events. Wasserstein distance provides a meaningful and smooth representation of the distance between distributions.The Wasserstein Distance is furthermore to measure distances between probability distributions on a given metric space. The use of the Wasserstein distance is motivated because this distance is defined and computable even between distributions with
disjoint supports. 
%\qli{explain a bit more clearly the technical formulas, for example why do you introduce Wasserstein distance, and then what is the intuition supporting proposition 3.}\duong{revised}. 

%%%%%%%%
%%%%%%%%%


\begin{definition}[Wasserstein Distance]
The Wasserstein distance for our problem is defined as:
\begin{equation}
\small
% \begin{split}
W_{c}\left(\hat{P}, P^{*}\right)=
    \inf _{\gamma \in \Pi\left(\hat{P}, P^{*}\right)} \mathbb{E}_{\left((\mathbf{x}, \mathbf{z}, y),\left(\mathbf{x}^{\prime}, \mathbf{z}^{\prime}, y^{\prime}\right)\right) \sim \gamma}\left[c\left((\mathbf{x}, \mathbf{z}, y),\left(\mathbf{x}^{\prime}, \mathbf{z}^{\prime}, y^{\prime}\right)\right)\right]
% \end{split}
\label{eq:wd}
\end{equation}
where $c: \mathcal{X} \times \mathcal{X} \rightarrow[0,+\infty)$ is the convex, lower semicontinuous transport cost function with $c(\mathbf{t}, \mathbf{t})=0$, and $\Pi\left(\hat{P}, P^{*}\right)$ is the set of all distributions whose marginals are given by $\hat{P}$ and $P^{*}$.
\end{definition}
The Wasserstein distance intuitively refers to the minimum cost associated with transporting mass between probability measures.
% \begin{equation}
% \begin{split}
% &\sup _{\hat{P} \in \mathcal{P}} \mathbb{E}_{\hat{P}}\left[\delta\left(Y, f_{\theta}(\mathbf{X}, \mathbf{Z})\right)\right]
%  &   =\inf _{\alpha \geq 0}\left\{\alpha \rho+\sup _{\hat{Q}}\left\{\mathbb{E}_{P}\left[\frac{\delta\left(Y, f_{\theta}(\mathbf{X}, \mathbf{Z})\right)}{\hat{q}(\mathbf{Z}\mid \mathbf{X} )}\right]-c_{0} \alpha W_{c}\left(\hat{Q}^{-1}, Q_{0}^{-1}\right)\right\}\right\}
% \end{split}
% \end{equation}
\begin{prop}
% \setcounter{prop}{1}
Suppose that the transportation cost $c$ in~\eqref{eq:wd} is continuous and the probability of fair representation is bounded away from zero, i.e., $f_{\phi_1}(\boldsymbol{Z})$, then the minimax objective~\eqref{eq:obj} has a desirable formulation as
% \begin{equation}
% \small
%     \underset{f_{\theta} \in \mathcal{F}}{\operatorname{min}} \sup _{\hat{q}} \mathbb{E}_{P}\left[\frac{\delta\left(Y, f_{\theta}(\mathbf{X}, \mathbf{Z})\right)}{\hat{q}(\mathbf{Z}\mid \mathbf{X} )}\right]-\lambda W_{c}\left(\hat{q}(\mathbf{Z}\mid \mathbf{X}), q_{*}\right)
%     \label{eq:obj2}
% \end{equation}
\begin{equation}
\small
    \underset{f_{\theta} \in \mathcal{F}}{\operatorname{min}} \sup _{\hat{q}} \mathbb{E}_{P}\left[\frac{\delta\left(Y, f_{\phi_1}(\boldsymbol{Z})\right)}{\hat{q}(\mathbf{Z}|\mathbf{X})}\right]-\lambda W_{c}\left(\hat{q}(\boldsymbol{Z}\mid \boldsymbol{X}), q_{*}\right)
    \label{eq:obj23}
\end{equation}
\label{prop51}
\end{prop}
To make sense of~\eqref{eq:obj23}, we see that while $\hat{q}(\boldsymbol{Z}\mid \boldsymbol{X})$ is acting adversarially against $f_{\phi_1}$ as the inverse weights in the first term, it cannot arbitrarily increase the objective function, since the second terms act as a regularizer that keeps $\hat{q}(\boldsymbol{Z}\mid \boldsymbol{X})$ close to the fair representation $\boldsymbol{Z}$.
The objective loss in~\eqref{eq:obj23} can be converted to a two-model adversarial game:
\begin{equation}
\small 
\underset{f_{\phi_1} \in \mathcal{F}}{\operatorname{min}} \sup _{f_{\phi_2} \in \mathcal{G}} \mathbb{E}_{P}\left[\frac{\mathcal{L}\left(Y, f_{\phi_1}( \boldsymbol{Z})\right)}{G\left(f_{\phi_1}( \boldsymbol{Z})\right)}\right]-\lambda W_{c}\left(G\left(f_{\phi_1}(\mathbf{Z})\right), G\left(f^{*}_{\phi_1}\right)\right)
\label{eq:obj1}
\end{equation}

\begin{theorem}[McDiarmid Inequality]~\cite{mcdiarmid1989method} Let \(\Omega_{1}, \ldots, \Omega_{m}\) be probability spaces. Let \(\Omega=\prod_{k=1}^{m} \Omega_{k}\)
and let \(X\) be a random variable on \(\Omega\) which is uniformly difference-bounded by \(\frac{\lambda}{m} \cdot\) Let
\(\mu=\mathrm{E}(X) .\) Then, for any \(\tau>0\)
\begin{equation}
    P(X-\mu \geq \tau) \leq \exp \left(-\frac{2 \tau^{2} m}{\lambda^{2}}\right)
\end{equation}
\label{eq:mcd}
\end{theorem}
\begin{prop}
Suppose that the transportation cost $c$ is continuous and the probability of fair representation is bounded away from zero, i.e., $\hat{q}(\mathbf{Z}\mid \mathbf{X} )$, then the minimax objective has a desirable formulation as
\begin{equation}
    \underset{f_{\phi_1} \in \mathcal{F}}{\operatorname{min}} \sup _{\hat{q}} \mathbb{E}_{P}\left[\frac{\delta\left(Y, f_{\phi_1}(\mathbf{Z})\right)}{\hat{q}(\mathbf{Z}\mid \mathbf{X} )}\right]-\lambda W_{c}\left(\hat{q}(\mathbf{Z}\mid \mathbf{X}), q_{*}\right)
    \label{eq:obj2}
\end{equation}
\label{prop:2}
\end{prop}
The following theorem discusses the theoretical guarantees for the generalization error of Eq.~\eqref{eq:obj1}.

\begin{theorem}
Suppose the mapping \(G\) from \(f_{\phi_1}\) to \(\hat{q}(\boldsymbol{Z}\mid \boldsymbol{X})\) is one-to-one and surjective with
\(g_{\psi} \in \mathcal{G} .\) Let \(\tilde{\mathcal{G}}(\rho)=\left\{g_{\psi} \in \mathcal{G} \mid W_{c}\left(G\left(g_{\psi}\right), G\left(g^{*}\right)\right) \leq \rho\right\} .\) Then under the conditions specified in Proposition~\ref{prop51}. for all \(\gamma \geq 0\) and \(\rho>0\), the following inequality holds with probability at least \(1-\epsilon\):
\begin{equation}
\small
\begin{split}
\sup _{g_{\psi} \in \tilde{\mathcal{G}}(\rho)} \mathbb{E}_{P}\left[\frac{\mathcal{L}\left(Y, f_{\phi_1}(\boldsymbol{Z})\right)}{G\left(f_{\phi_1}(\boldsymbol{Z})\right)}\right] \leq c_{1} \gamma \rho+\mathbb{E}_{P_{n}}\left[\Delta_{\gamma}\left(f_{\phi_1}; (\boldsymbol{Z}, Y)\right)\right]+\frac{24 \mathcal{J}(\tilde{\mathcal{F}})+c_{2}\left(M, \sqrt{\log \frac{2}{\epsilon}}, \gamma\right)}{\sqrt{n}}
\end{split}
\end{equation}
where $\mathbb{E}_{P_{n}}\left[\Delta_{\gamma}\left(f_{\phi_1}; (\boldsymbol{Z}, Y)\right)\right]$ is a cost-regulated loss given in Proof part below, \(c_{1}\) is a positive constants and \(c_{2}\) is a simple linear function with positive weights. 
\end{theorem}

The above theorem states our main theoretical result on the worst-case generalization bound under the minimax setting.


\begin{proof}
We introduce a cost-regulated loss which is defined as 
\begin{equation}
    \Delta_{\gamma}\left(f_{\phi_1} ;(\mathbf{z}, y)\right)=\sup _{\left( \mathbf{z}^{\prime}, y^{\prime}\right) \in \mathcal{X}}\left\{\frac{\delta\left(y^{\prime},f_{\phi_1}(\mathbf{Z}^{\prime})\right)}{q\left(o=1 \mid  \mathbf{z}^{\prime}\right)}-\right.\left.\gamma c\left((\mathbf{z}, y),\left( \mathbf{z}^{\prime}, y^{\prime}\right)\right)\right\}
\end{equation}
Based on definition of $\Delta_{\gamma}$, we have
\begin{equation}
    \begin{split}
        &\sup _{f_{\phi_1} \in \tilde{\mathcal{G}}(\rho)} \mathbb{E}_{P}\left[\frac{\delta\left(Y, f_{\phi_1}(\mathbf{Z})\right)}{G\left(f_{\phi_1}(\mathbf{X}, \mathbf{Z})\right)}\right]\\
&\leq \inf _{\gamma \geq 0}\left\{\gamma \rho+\int \sup _{\mathbf{h} \in \mathcal{X}}\left(\frac{\delta_{f_{\phi_1}}(\mathbf{h})}{\hat{q}(\mathbf{h})}-\gamma c\left(\mathbf{h}, \mathbf{h}^{\prime}\right)\right) d P(\mathbf{h})\right\}\\
&=\inf _{\gamma \geq 0}\left\{\gamma \rho+\mathbb{E}_{P}\left[\Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}\right)\right]\right\} \quad\left(\right. \text{by the definition of} \left.\Delta_{\gamma}\right)\\
&\leq \inf _{\gamma \geq 0}\left\{\gamma \rho+\mathbb{E}_{P_{n}}\left[\Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}\right)\right]+\sup _{f_{\phi_1} \in \mathcal{F}}\left(\mathbb{E}_{P}\left[\Delta_{\gamma}\left(f_{\phi_1};\mathbf{H}\right)\right]-\mathbb{E}_{P_{n}}\left[\Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}\right)\right]\right)\right\}
    \end{split}
    \label{eq:3}
\end{equation}
Let $W_{\gamma}=\sup _{f_{\phi_1} \in \mathcal{F}}\left(\mathbb{E}_{P}\left[\Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}\right)\right]-\mathbb{E}_{P_{n}}\left[\Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}\right)\right]\right)$, then we have 
\begin{equation}
    W_{\gamma}=\frac{1}{n} \sup _{f_{\phi_1} \in \mathcal{F}}\left[\sum_{i=1}^{N} \mathbb{E}_{P}\left[\Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}\right)\right]-\Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}_{i}\right)\right] \quad \gamma \geq 0
    \label{eq:wr}
\end{equation}
According to Theorem~\ref{eq:mcd} and the fact that \(\left|\delta_{f_{\phi_1}}(\mathbf{h})\right| \leq \mu M\) holds uniformly, we have
\begin{equation}
    p\left(W_{\gamma}-\mathbb{E} W_{\gamma} \geq \mu M \sqrt{\frac{\log 1 / \epsilon}{2 N}}\right) \leq \epsilon
        \label{eq:5}
\end{equation}
where \(\epsilon_{1}, \ldots, \epsilon_{N}\) is denoted as the i.i.d Rademacher random variables independent of \(\mathbf{H}\), and \(\mathbf{H}_{i}^{\prime}\) is the i.i.d
copy of \(\mathbf{H}_{i}\) for \(i=1, \ldots, N\).

Considering Eq.~\eqref{eq:wr}, we use the symmetrization argument to reformulate $\mathbb{E} W_{\gamma}$ in Eq.~\eqref{eq:5} as

\begin{equation}
    \begin{aligned} \mathbb{E} W_{\gamma} &=\mathbb{E}\left[\sup _{f_{\phi_1} \in \mathcal{F}}\left|\sum_{i=1}^{N} \Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}_{i}^{\prime}\right)-\sum_{i=1}^{N} \Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}_{i}\right)\right|\right] \\ &=\mathbb{E}\left[\sup _{f_{\phi_1} \in \mathcal{F}}\left|\frac{1}{N} \sum_{i=1}^{N} \epsilon_{i} \Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}_{i}^{\prime}\right)-\frac{1}{N} \sum_{i=1}^{N} \Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}_{i}\right)\right|\right] \\ & \leq 2 \mathbb{E}\left[\sup _{f_{\phi_1} \in \mathcal{F}}\left|\frac{1}{N} \sum_{i=1}^{N} \epsilon_{i} \Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}_{i}\right)\right|\right] \end{aligned}
\end{equation}
% Define $\gamma_n$ as a data-dependent variable and we have
% \(\gamma_{n}=\max _{i} \sup _{\mathbf{h}^{\prime} \in \mathcal{H}}\left(\frac{\delta_{f_{\phi_1}}\left(\mathbf{h}^{\prime}\right)}{q\left(\mathbf{h}^{\prime}\right)}-\frac{\delta_{f_{\phi_1}}\left(\mathbf{h}_{i}\right)}{q\left(\mathbf{h}_{i}\right)}\right) / c\left(\mathbf{h}_{i}, \mathbf{h}^{\prime}\right)\)
Apparently, each \(\epsilon_{i} \Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}_{i}\right)\) is zero-mean, and now we show that it is sub-Gaussian as well.
The bounded difference between two \(f_{\phi_1}, f_{\phi_1}^{\prime}\) is
\begin{equation}
    \begin{split}
        &\mathbb{E}\left[\exp \left(\lambda\left(\frac{1}{\sqrt{N}} \epsilon_{i} \Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}_{i}\right)-\frac{1}{\sqrt{N}} \epsilon_{i} \Delta_{\gamma}\left(f_{\phi_1}^{\prime} ; \mathbf{H}_{i}\right)\right)\right)\right]\\
        &=\left(\mathbb{E}\left[\exp \left(\frac{\lambda}{\sqrt{N}} \epsilon_{1}\left(\Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}_{1}\right)-\Delta_{\gamma}\left(f_{\phi_1}^{\prime} ; \mathbf{H}_{1}\right)\right)\right)\right]\right)^{N}\\
        &=\left(\mathbb{E}\left[\exp \left(\frac{\lambda}{\sqrt{N}} \epsilon_{1}\left(\sup _{\mathbf{h}^{\prime}} \inf _{\mathbf{h}^{\prime \prime}}\left\{\frac{\delta_{f_{\phi_1}}\left(\mathbf{h}^{\prime}\right)}{q\left(\mathbf{h}^{\prime}\right)}-\gamma c\left(\mathbf{H}_{1}, \mathbf{h}^{\prime}\right)-\frac{\delta_{f_{\phi_1}^{\prime}}\left(\mathbf{h}^{\prime \prime}\right)}{q\left(\mathbf{h}^{\prime \prime}\right)}\right\}+\gamma c\left(\mathbf{H}_{1}, \mathbf{h}^{\prime \prime}\right)\right)\right)\right]\right)^{N}\\
        &\leq\left(\mathbb{E}\left[\exp \left(\frac{\lambda}{\sqrt{N}} \epsilon_{1}\left(\sup _{\mathbf{h}^{\prime}}\left\{\frac{\delta_{f_{\phi_1}}\left(\mathbf{h}^{\prime}\right)}{q\left(\mathbf{h}^{\prime}\right)}-\frac{\delta_{f_{\phi_1}^{\prime}}\left(\mathbf{h}^{\prime}\right)}{q\left(\mathbf{h}^{\prime}\right)}\right\}\right)\right)\right]\right)^{N}\\
        &\leq \exp \left(\lambda^{2}\left\|\frac{\delta_{f_{\phi_1}}}{q}-\frac{\delta_{f_{\phi_1}^{\prime}}}{q}\right\|_{\infty}^{2} / 2\right) \quad \text{(by Hoeffding's inequality)}
    \end{split}
\end{equation}
Hence we see that \(\frac{1}{\sqrt{N}} \epsilon_{i} \Delta_{\gamma}\left(f_{\phi_1} ; \mathbf{H}_{i}\right)\) is sub-Gaussian with respect to \(\left\|\frac{\delta_{f_{\phi_1}}}{q}-\frac{\delta_{f_{\phi_1}^{\prime}}}{q}\right\|_{\infty}^{2} .\) Therefore,
\(\mathbb{E} W_{\gamma}\) can be bounded| by using the standard technique for Rademacher complexity and Dudley's
entropy integral
\begin{equation}
    \mathbb{E} W_{\gamma} \leq \frac{24}{N} \mathcal{J}(\tilde{\mathcal{F}})
        \label{eq:8}
\end{equation}
Based on all above bounds in ~\eqref{eq:3}, ~\eqref{eq:5} and ~\eqref{eq:8} we obtain the desired result.
\end{proof}





% \begin{proof}
%     Assume that $R$ decides $\mathrm{HALT}_{\mathrm{TM}}$, and obtain a contradiction. Construct $S$ to decide $A_{\mathrm{TM}}$, where $S$ operates as follows: 

%     $S={}$ ``On input $\langle M, w \rangle$, an encoding of a TM $M$ and a string $w$:
%     \begin{enumerate}
%     \item Run TM $r$ on input $\langle M, w \rangle$.
%     \item If $R$ rejects, reject
%     \item If $R$ accepts, accept
%     \item If $M$ has accepted, accept; if $M$ has rejected, reject."
%     \end{enumerate}

%      If $R$ decides $\mathrm{HALT}_{\mathrm{TM}}$, then $S$ decides $A_{\mathrm{TM}}$. Because $A_{\mathrm{TM}}$ is undecidable, $\mathrm{HALT}_{\mathrm{TM}}$ must also be undecidable. 
%     \end{proof}


% \begin{equation}
%     \mathcal{L}(\boldsymbol{Z}) = H(p(Y|\boldsymbol{Z}, s_a);  p(Y|\boldsymbol{Z}, s_t))
% \end{equation}

% \qli{why you define $Z_i$ like this? $\boldsymbol{Z} \cap \{\boldsymbol{U}\}$ is definitely equal U since $Z \in [\boldsymbol{X}_1, \boldsymbol{X}_2, \boldsymbol{U}]$}
% \begin{equation}
% \boldsymbol{Z}_{I} = \boldsymbol{Z} \cap \{\boldsymbol{U}\} 
%   \quad\text{and}\quad 
% \boldsymbol{Z}_{V} = \boldsymbol{Z} \cap \{\boldsymbol{X}_1, \boldsymbol{X}_2\} 
% \end{equation}

% \qli{why the following holds?}
% \begin{equation}
%     p(Y|\boldsymbol{Z}, s_a) = p(Y|\boldsymbol{Z}_I, s_a)
% \end{equation}

% Therefore:
% \begin{equation}
% \begin{split}
% \mathcal{L}(\boldsymbol{Z}, p_1, p_2, p_u)
% ={}&  H(p(Y|\boldsymbol{Z}, s_a);  p(Y|\boldsymbol{Z}, s_t))
% \\ 
% ={}& H(p(Y|\boldsymbol{Z}_I, s_a);  p(Y|\boldsymbol{Z}, s_t))
% \\
% \ge & H(p(Y|\boldsymbol{Z}_I, s_a))
% \\
% \ge & H(p(Y|\boldsymbol{U}, s_a))
% \\
% = & H(p(Y|\boldsymbol{U}, s_a), H(p(Y|\boldsymbol{U}, s_t)))
% \\
% = & \mathcal{L}_\text{test}(\boldsymbol{U}, p_1, p_2, p_u)
% \end{split}
% \end{equation}


% \begin{equation}
%      \max_{p_1, p_2, p_u} \mathcal{L}(\boldsymbol{Z}, p_1, p_2, p_u) \ge \max_{p_1, p_2, p_u} \mathcal{L}(\boldsymbol{U}, p_1, p_2, p_u)
% \end{equation}

% which draws to:

% \begin{equation}
%     \boldsymbol{U} = \argmin_{\boldsymbol{Z}} \max_{p_1, p_2, p_u} \mathcal{L}^*_\text{test}(\boldsymbol{Z}, p_1, p_2, p_u)
% \end{equation}


% \end{proof}


% \begin{theorem}[Error rate]
% % \label{pythagorean}
% \end{theorem}


% \begin{theorem}[Convergence rate]
% \label{pythagorean}
% \end{theorem}


% \begin{theorem}[Generalization error]
% % \label{pythagorean}
% \end{theorem}



% \begin{defn}[Expected risk]
% Given a function $f: \boldsymbol{X} \rightarrow Y$, the expected risk  of a predictive function is defined as:
% \begin{equation}
% \mathcal{R}(f) = \mathbb{E}[\mathcal{L}(Y, f(\boldsymbol{X})]
% \end{equation}

% % where  $\Gamma(\mu, \hat{\mu})$ denotes the set of all couplings of $\mu$ and $\hat{\mu}$
% \end{defn}





% Let $\mathcal{F}$ be all the measurable functions, $\mu$ and $\nu$ be distribution, which is defined as follows:

% \begin{equation}
% \hat{Y} = f(\boldsymbol{X},\boldsymbol{S}) \sim \mu 
%   \quad\text{and}\quad 
% \hat{Y} = f(\boldsymbol{Z}) \sim \nu
% \end{equation}

% We have the lower bound for the price of fairness:

% % With the price for fairness 
% \begin{equation}
%   \xi_\text{Fair} := \inf_{f_1 \in \mathcal{F}_\text{fair}} \mathcal{R}(f_1) - \inf_{f_2 \in \mathcal{F}} \mathcal{R}(f_2) \ge  \mathcal{W}^2_2(\mu,\nu) 
% \end{equation}

% with \begin{equation}
%     \mathcal{F_\text{fair}} = \{ f(\boldsymbol{Z}) \text{ s.t.\ $\hat{Y} \perp do(S) | \boldsymbol{Z}$}  \}
% \end{equation}

% % We have:
% % \begin{equation}
% %     \xi_\text{Fair} \ge  \mathcal{W}_p(\mu,\nu) 
% % \end{equation}


% \label{pythagorean}


% We denote $\eta = \mathbb{E}[Y | (X,S)$. 

% \begin{equation}
% \begin{split}
% \xi_\text{Fair}
% ={}&  \inf_{f_1 \in \mathcal{F}_\text{fair}} \mathcal{R}(f_1) - \inf_{f_2 \in \mathcal{F}} \mathcal{R}(f_2)
% \\ 
% ={}& \inf \mathbb{E}[\mathcal{L}(Y, f_1(\boldsymbol{X})] - \inf \mathbb{E}[\mathcal{L}(Y, f_2(\boldsymbol{X})]
% \\
% ={}& (\inf \mathbb{E}[|Y - f_1(\boldsymbol{X}|^2])^\frac{1}{2} - (\mathbb{E}[|Y - f_2(\boldsymbol{X})|^2])^\frac{1}{2}
% \\
% ={}& (\inf \mathbb{E}[|f_1(\boldsymbol{X}) - f_2(\boldsymbol{X})|^2])^{\frac{1}{2}}
% \\
% \numgeq{1}{}&  \mathcal{W}^2_2(\mu, \nu)
% \end{split}
% \end{equation}

% (1) the distribution of $Y$ and $\hat{Y}$ are the coupling between $\mu$ and $\nu$

%\end{proof}



% \textit{Proof.}


% \begin{equation}
%   \mathbb{E}[f(Z) - \mathbb{E}(Y|X,S)| S] \ge \mathcal{W}_2^2(\mu, \nu) 
% \end{equation}


% \begin{thm}[The error lower bound] Let $f_{\phi^*_1}(\boldsymbol{\boldsymbol{Z}})$ be the optimal solution for objective function \ref{eqn:objective}, $\mu_0$ and $mu_1$ are the corresponding conditional distribution of $Y$ given $S=0$ and $S=1$.
% We have:

% \begin{equation}
%     \mathbb{E}_{\mu_0}[\mathcal{L}(Y, f_{\phi^*_1}(\boldsymbol{Z}))] + \mathbb{E}_{\mu_1}[\mathcal{L}(Y, f_{\phi^*_1}(\boldsymbol{Z}))] \ge \mathcal{W}^2_2(\mu_0, \mu_1)
% \end{equation}

% % \label{pythagorean}
% \end{thm}

% \begin{proof}

% \textit{Proof.}

% \begin{equation}
% \begin{split}
% \mathcal{W}^2_2(\mu_0, \mu_1)
% \leq{}&  \mathcal{W}^2_2(\mu_0, \nu_0) + \mathcal{W}^2_2(\nu_0, \nu_1) + \mathcal{W}^2_2(\nu_1, \mu_1)
% \\ 
% \numleq{1}{}&  \mathcal{W}^2_2(\mu_0, \nu_0) + \mathcal{W}^2_2(\nu_1, \mu_1)
% \\
% \numleq{2}{}& (\mathbb{E}_{\mu_0}[|Y - \hat{Y}|^2])^{\frac{1}{2}} + (\mathbb{E}_{\mu_1}[|Y - \hat{Y}|^2])^{\frac{1}{2}}
% \\
% \numleq{3}{}& \mathbb{E}_{\mu_0}[\mathcal{L}(Y, \hat{Y})] + \mathbb{E}_{\mu_1}[\mathcal{L}(Y, \hat{Y})]
% \\
% ={}& \mathbb{E}_{\mu_0}[\mathcal{L}(Y, f_{\phi^*_1}(\boldsymbol{Z}))] + \mathbb{E}_{\mu_1}[\mathcal{L}(Y, f_{\phi^*_1}(\boldsymbol{Z}))]
% \end{split}
% \end{equation}
% (1) $\mathcal{W}^2_2(\nu_0, \nu_1)$ is zero since the conditional distributions of $f(z)$ given $S=0$ and $S=1$ are equal when $f(Z) \perp S$.  
% \end{proof}












% \subsection{Approximate performance evaluation}
% \subsection{Counterfactual evaluation}
% \section{Counterfactual fairness evaluator}
% \qli{Why is Section 6 even included? It does not say anything new.}
% \qli{Section 6 verbosely describes what seems to be a matching scheme, but this is never formalized and neither used in the evaluation}
% Compared to machine learning in the more standard su-
% pervised learning setting, evaluation of methods in a contex-
% tual bandit setting is frustratingly difficult. 
% Compared to 
% compared to other fairness criteria, evaluating the performance of counterfactual fairness algorithm is quite challenging since from the real-world dataset, we do not have the ground-truth samples for both the actual world and counterfactual world

%% checked
% Compared to other fairness criteria, evaluating the performance of counterfactual fairness is frustratingly difficult due to the absence of ground truth samples. In fact, from the observational data, we are unable to observe the characteristic of individuals in the counterfactual world where we make an intervention into their sensitive attributes. In fact, we cannot simply change the values of sensitive attributes since the intervention on the sensitive features can lead to changes in some non-sensitive features due to the causal effects. For example, we have an observational individual $x$, but do not have its counterfactual version $\hat{x}$; therefore, it is not feasible to evaluate the performance of predictive model $f(.)$ by measuring the distance of $f(x)$ and $f(\hat{x})$. In the previous studies \cite{kusner2017counterfactual,russell2017worlds,wu2019counterfactual}, they generate both the original samples and counterfactual samples from the structural causal model. However, it is hard to verify the trustworthiness of the samples due to the unidentifiability of the causal model. In this research, by getting a pair of similar individuals sharing the same properties, we thus can approximately evaluate the model performance. To sum up, for evaluation purposes, instead of evaluating in the counterfactual space, we can approximately evaluate the performance of counterfactual fairness via the individual fairness criteria. 


% \qli{a better way is to put your equations of evaluation here, not just describe it in words}.


% \begin{lemma}
% If a machine learning model $f^*$ achieves counterfactual fairness, $f^*$ also maintains its properties in individual fairness. With $x$ and $\hat{x}$ are the corresponding individual and counterfactual individual if $f^*$ performs well in the pair $(x,\hat{x})$, $f^*$ also performs well in the pair $(a,b)$ where $(a,b)$ are the similar individuals in the observational data. 
% \end{lemma}




% $x$, 


% \textit{Proof.}

% \begin{equation}
%       X \sim \mathcal{N}(\mu,\,\sigma^{2})\
% \end{equation}




% x, \hat{x}


%  In this study, we use generalized entropy index \cite{speicher2018unified} to evaluate the performance on the fairness aspect. 
% \begin{equation}
%     \begin{split}\mathcal{E}(\alpha) = \begin{cases}
%     \frac{1}{n \alpha (\alpha-1)}\sum_{i=1}^n\left[\left(\frac{b_i}{\mu}\right)^\alpha - 1\right],& \alpha \ne 0, 1,\\
%     \frac{1}{n}\sum_{i=1}^n\frac{b_{i}}{\mu}\ln\frac{b_{i}}{\mu},& \alpha=1,\\
%     -\frac{1}{n}\sum_{i=1}^n\ln\frac{b_{i}}{\mu},& \alpha=0.
% \end{cases}\end{split}
% \end{equation}

% When $\mathcal{E}(1)$ and $\mathcal{E}(2)$ are called Theil index (TI) and coefficient of variation (CV), respectively. 







% $x = [male, highschool, 200]$
% dont have $\hat{x} = [female, ]$

% f(x) = f(]hatx)





\section{Experiments}\label{sec:expr}
% We conducted extensive human subject experiments to quantitatively and qualitatively assess the effectiveness of the
% proposed fault-line explanations in helping expert human
% users and non-expert human users understand the internal workings of the underlying model. We chose an image classification task for our experiments (although the
% proposed approach is generic and can be applied to any
% task). We use the following metrics (Hoffman et al. 2018;
% Hoffman 2017) to compare our method with the baselines

Compared to other fairness criteria, evaluating the performance of counterfactual fairness is frustratingly difficult due to the absence of ground truth samples. In fact, from the observational data, we are unable to observe the characteristic of individuals in the counterfactual world where we make an intervention into their sensitive attributes. In fact, we cannot simply change the values of sensitive attributes since the intervention on the sensitive features can lead to changes in some non-sensitive features due to the causal effects. For example, we have an observational individual $x$, but do not have its counterfactual version $\hat{x}$; therefore, it is not feasible to evaluate the performance of predictive model $f(.)$ by measuring the similarity of $f(x)$ and $f(\hat{x})$. In the previous studies \cite{kusner2017counterfactual,russell2017worlds,wu2019counterfactual}, they generate both the original samples and counterfactual samples from the structural causal model. However, it is hard to verify the trustworthiness of the samples due to the unidentifiability of the causal model. In this research, by getting a pair of similar individuals sharing the same properties, we thus can approximately evaluate the model performance. This means that instead of evaluating in the counterfactual space, we can approximately evaluate the performance of counterfactual fairness via the individual fairness criteria. We conducted extensive experiments on three real-world datasets with different evaluation metrics for two tasks including regression and classification tasks. 


% In this research, by getting a pair of similar individuals sharing the same properties, we thus can approximately evaluate the model performance. To sum up, for evaluation purposes, instead of evaluating in the counterfactual space, we can approximately evaluate the performance of counterfactual fairness via the individual fairness criteria. To quantitatively assess the effectiveness of the proposed method, we conducted extensive experiments on three real-world datasets. 



% \qli{The empirical evaluation is hard to follow and does not permit reliable conclusions. Why do the authors assume a causal model in 7.2? The authors only consider three datasets, for which for the first their method gets beaten on both performance and fairness by existing ones (the authors conveniently ignore the standard deviation, but when one doesnt their method loses), and on the other two their method 'wins' on fairness but does so by a metric that they do not define }
% \qli{(!) I do not know how Wasserstein or MMD would measure fairness, let alone individual fairness notions like counterfactuals. The authors do not consider synthetic data to evaluate whether their method actually does what it should when we do know the data generating process, they do not explore any corner cases where it may break down. All in all, the empirical evaluation sums up to 'we ran our method and we got numbers'.}

% Particularly, we consider two predictive tasks: regression task on \textbf{LSAC}\footnote{Download at: \url{http://www.seaphe.org/databases.php}} dataset and classification task on \textbf{Compas}\footnote{Download at: \url{https://www.propublica.org}} and \textbf{Adult}\footnote{Download at: \url{https://archive.ics.uci.edu/ml/datasets/adult}} dataset. 


\subsection{Datasets}

%% checked

We evaluate our approach via regression datasets including \texttt{LSAC} \cite{wightman1998lsac} and classification datasets including \texttt{Compas} \cite{larson2016we} and \texttt{Adult}.

\begin{itemize}
    \item \texttt{LSAC}\footnote{Download at: \url{http://www.seaphe.org/databases.php}} \cite{wightman1998lsac}. \texttt{LSAC} dataset provides information about law students including their gender, race, entrance exam scores (LSAT), grade-point average (GPA) and first-year average grade (FYA). The main task is to determine which applicants would have a high possibility to obtain high FYA. The school also ensures that model decisions are not biased by sensitive attribtues including race and gender. We pay attention to predict the FYA of a student. 
    \item \texttt{Compas}\footnote{Download at: \url{https://www.propublica.org}} \cite{larson2016we}. \texttt{Compas} dataset has been released by ProPublica about prisoners in Florida (US) and also has been previously explored for fairness studies in criminal justice \cite{berk2021fairness}. The dataset contains information about 6,167 prisoners, and each individual has two sensitive attributes including gender, race and other attributes related to prior conviction and age. The main task is to predict whether or not a prisoner will re-offend within two years after being released from prison.  
    \item \texttt{Adult}\footnote{Download at: \url{https://archive.ics.uci.edu/ml/datasets/adult}}\cite{Dua:2019}. \texttt{Adult} dataset is the real-world dataset providing information about loan applicants in the financial organization. The dataset consists of both continuous features and categorical features. The main task is to determine whether a person has an annual income exceeding \$50k dollars. The sensitive attributes are gender and race. 
\end{itemize}

To evaluate the generalization capability of models, we randomly split each dataset into 80\% training and 20\% test set. We conduct 100 repeated experiments, then evaluate performance on the test set and finally report the average statistics. 

% We evaluate our approach via regression dataset including \texttt{LSAC} \cite{wightman1998lsac} and classification datasets including \texttt{Compas} \cite{larson2016we} and \texttt{Adult} \cite{Dua:2019}\qli{add texttt for dataset name in previous content}. More details about dataset descriptions can be found in the supplement\qli{there is no dataset information in supplementary, probably you can combine some content in the following causal model description in this paragraph}. Meanwhile, to evaluate the generalization capability of models, we randomly split each dataset into 80\% training and 20\% test set. We conduct 100 repeated experiments, then evaluate performance on the test set and finally report the average statistics. 

% \qli{Is it possible to make a link between the experiments and models on page 11 and what is introduced on page 6 with the different functions?}
% \subsection{Causal models}
% Since there is no ground truth causal model, we follow the previous studies \cite{kusner2017counterfactual,russell2017worlds,xu2019achieving} to assume the structure of the causal diagram. For each dataset, we consider two different non-deterministic causal models. Figure~\ref{fig:scm} illustrates causal models for \texttt{Law}, \texttt{Compas} and \texttt{Adult} dataset.

%\qli{combine the Figure 3,4,5 into one, and put these three in one arrow}\duong{done}

% \begin{figure}[!htb]% [H] is so declass\'e!
% \centering
% \begin{minipage}{0.4\textwidth}
% \includegraphics[width=\textwidth]{figure/law_graph.pdf}
% \caption{Causal diagram for Law dataset. $\epsilon$, $\epsilon_1$, $\epsilon_2$ and $\epsilon_3$ are the unobserved variables.}
% \label{fig:law}
% \end{minipage}\hfill
% \begin{minipage}{0.4\textwidth}
% \includegraphics[width=\textwidth]{figure/compas_graph.pdf}
% \caption{Causal diagram for Compas dataset. $\epsilon_J$ and $\epsilon_D$ are the unobserved variables. The large white arrows represents that each variable has the causal effect to every variables contained in the box.}
% \label{fig:compas}
% \end{minipage}\par
% \vskip\floatsep% normal separation between figures
% \includegraphics[width=0.4\textwidth]{figure/adult_graph.pdf}
% \caption{Causal diagram for Adult dataset. $\epsilon_1$ and $\epsilon_2$ are the unobserved variables. The large white arrows represents that each variable has the causal effect to every variables contained in the box.}
% \label{fig:adult}
% \end{figure}
% \begin{equation}
%     GPA \sim \mathcal{N}(bG + wGKK + wGRR + wGS S; σG); FYA \sim N(wFKK + wFRR + wFS S; 1);
% LSAT \sim Poisson(exp(bL + wLKK + wLRR + wLSS))
% K \sim \mathcal{N}(0; 1)
% \end{equation}


%\qli{use $\epsilon_1\cdots \epsilon_{12}$}\duong{done}
\begin{figure}[!htb]
\minipage{0.32\textwidth}
  \includegraphics[width=\linewidth]{law_graph.pdf}
\caption*{\small \texttt{Law} dataset}
\endminipage\hfill
\minipage{0.32\textwidth}
  \includegraphics[width=\linewidth]{compas_graph.pdf}
  \caption*{\small Compas dataset}
\endminipage\hfill
\minipage{0.32\textwidth}%
  \includegraphics[width=\linewidth]{adult_graph.pdf}
\caption*{\small \texttt{Adult} dataset}
\endminipage
\caption{Causal diagrams for Law, Compas and \texttt{Adult} dataset. $\{\epsilon_1\cdots \epsilon_{12}\}$ are the unobserved variables. The large white arrows represent that each variable has a causal effect on every variables contained in the box.}
\label{fig:scm}
\end{figure}


%\qli{Figure 3 in page 11 is not readable.}\duong{removed}
%\qli{Figure 3 is not very useful since the causal structure is not used by the model. It is therefore sufficient to report the sensitive attributes for each dataset.} \duong{removed}

\subsection{Baselines}
We make a comparison with several state-to-the-art methods as below.
% \qli{The experiments provide the reliability and improvement for this approach. However, the comparison is only performed against "baseline approaches" or against the "building blocks" of the proposal. }

\begin{itemize}
    \item \textbf{Full features (Full)} \cite{kusner2017counterfactual} is the standard technique that uses all the features including both the sensitive and non-sensitive ones.
    \item \textbf{Unaware features (Unaware)} \cite{chen2019fairness} does not consider sensitive features such as race or gender in the input and only utilizes non-sensitive features.
    \item \textbf{Counterfactual fairness model (CF)} \cite{kusner2017counterfactual} uses the causal graph and infers the latent variables which are not the child nodes of the sensitive features. Since there is no ground truth causal model, we consider two causal diagrams illustrated in Figure~\ref{fig:scm} for each dataset as \textbf{CF$_1$} and \textbf{CF$_2$}. \textbf{CF$_1$} and \textbf{CF$_2$} correspond to two different structural causal models
    \item \textbf{Multi-world models (Multi-wolrd)} \cite{russell2017worlds} minimizes the model predictions when considering different structural causal models. Specifically, with two causal diagrams in Figure~\ref{fig:scm} for each dataset, we build a neural network and use the gradient descent algorithm to minimize the model output from two causal models. 
    \item \textbf{Auto-encoder model (AE)} \cite{ng2011sparse} uses the encoder-decoder architecture to learn the latent representation. This model utilizes all the features including the sensitive and non-sensitive ones as the input. 
\end{itemize}
%\qli{On the other hand, in order to show its effectiveness, the proposed approach should be compared against some counterfactual fairness approaches from the state-of-the-art among those cited in the paper or among those recommended in the list above. Some examples are Coston, A., Mishler, A., Kennedy, E. H., & Chouldechova, A. (2020, January). Counterfactual risk assessments, evaluation, and fairness. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 582-593) or Kilbertus, N., Ball, P. J., Kusner, M. J., Weller, A., & Silva, R. (2020, August). The sensitivity of counterfactual fairness to unmeasured confounding. In Uncertainty in artificial intelligence (pp. 616-626). PMLR. Also, after this experimentation, statistical tests should be performed in order proof the statistical significance of the tests (see Demšar, J. (2006). Statistical comparisons of classifiers over multiple data sets. The Journal of Machine Learning Research, 7, 1-30. for details)} \duong{add the table for p-value for statistical significance testing}
Note that \textbf{Full}, \textbf{Unaware}, \textbf{CF$_1$}, \textbf{CF$_2$} and \textbf{Autoencoder} are the representation methods that only produce features, so we use these features as an input and construct predictive models including Linear Regression \textbf{(LR)} and Gradient Boosting Regression \textbf{(GBboostR)} for regression task, and Logistic Regression \textbf{(Log)} and Gradient Boosting Classifier \textbf{(GBboostC)} for the classification task. As our method aims to output a fair and informative representation, we use two models: Invariant-encoder model and Fair-learning predictive model. In order to gain more insights into model behaviors, we first utilize {Invariant-encoder model} \textbf{(InvEnc)} to generate the latent representation, and also combine with {LR}, {GBboostR}, and {GBboostC}. Finally, we adopt the fair-learning predictive model and invariant-encoder together, referred as \textbf{InvFair}. 
% We make a comparison with several state-to-the-art methods. Firstly, we compare with \textbf{Full features (Full)}\cite{kusner2017counterfactual}, \textbf{Unaware features (Unaware)} that use all of the observed features and non-sensitive features, respectively. We also consider two counterfactual fairness method including \textbf{Counterfactual fairness model (CF)}\cite{kusner2017counterfactual}, \textbf{Multi-world models (Multi-wolrd)}\cite{russell2017worlds}. Another baselines is \textbf{Auto-encoder model (AE)}\cite{ng2011sparse} that constructs the encoder-decoder architecture to learn the latent representation. More details about baselines and causal model structures can be found in the supplement. Since \textbf{Full}, \textbf{Unaware}, \textbf{CF$_1$}, \textbf{CF$_2$} and \textbf{Autoencoder} are the representation method that only produces features, we use these features as an input and construct predictive models including Linear Regression \textbf{(LR)} and Gradient Boosting Regression \textbf{(GBboostR)} for regression task, and Logistic Regression \textbf{(Log)} and Gradient Boosting Classifier \textbf{(GBboostC)} for the classification task. For our proposed method, after the training process, we used two models: Invariant-encoder model and Fair-learning predictive model. In order to gain more insights into model behaviors, we first utilized the \textbf{Invariant-encoder model} to generate the latent representation, and also combine with {LR}, {GBboostR}, and {GBboostC}. Finally, we adopted the fair-learning predictive model and invariant-encoder together, referring as \textbf{Invariant-fair model}. 



% \begin{itemize}
%     \item \textbf{Full features (Full)} \cite{kusner2017counterfactual} are the standard technique that uses all the features including both the sensitive and non-sensitive ones.
%     \item \textbf{Unaware features (Unaware)} \cite{chen2019fairness} does not consider the sensitive features such as race or gender in the input.
%     \item \textbf{Counterfactual fairness model (CF)} \cite{kusner2017counterfactual} uses the causal graph and infers the latent variables which are not the child nodes of the sensitive features. Since there is no ground truth causal model, we consider two causal diagrams for each dataset providing in the supplementary file which refers as \textbf{CF$_1$} and \textbf{CF$_2$}. 
%     \item \textbf{Multi-world models (Multi-wolrd)} \cite{russell2017worlds} minimizes the model predictions when considering different structural causal models. Specifically, with two causal diagrams for each dataset providing in the supplementary file, we build a neural network and use gradient descent algorithm to minimize the model output from two causal models. 
%     \item \textbf{Auto-encoder model (AE)} \cite{ng2011sparse} uses the encoder-decoder architecture to learn the latent representation. This model utilizes all the features including the sensitive and non-sensitive ones as the input. 
% \end{itemize}


% We use each feature generated by \textbf{Full}, \textbf{Unaware}, \textbf{CF$_1$}, \textbf{CF$_2$} and \textbf{Autoencoder} as the input and construct the predictive models including Linear Regression \textbf{(Lin)} and Gradient Boosting Regression \textbf{(GBboostR)} for regression task, and Logistic Regression \textbf{(Logistic)} and Gradient Boosting Classifier \textbf{(GBboostC)} for the classification task. 

% (*-Lin) / (*-GBR) / (*-Log) / ((*-GBC)




% model to produce the latent representation which is thereafter used as the input for the fair-learning model to gain the final prediction. This method refers as \textbf{Fair-learning model}. 


% \subsection{Implementation detail}

% We generate the features based on the structural causal model based on counterfactual fairness, and thereafter utilize the Linear Regression, Gradient Boosting Regression, Logistic Regression and Gradient Boosting Classifier to build the model. Counterfactual fairness infers the latent variables and use them as an input for the predictive model. 



% Constant prediction 


% \textbf{Learn fair representation}


% \begin{table*}[t]
% \begin{adjustbox}{width=2.\columnwidth,center}
% \begin{tabular}{@{}ccccccc@{}}
% \toprule
% \multirow{2}{*}{\textbf{Method}} & \multicolumn{3}{c}{\textbf{Regression metric}}                                             & \multicolumn{3}{c}{\textbf{Fairness metric}}    
% \\
%         \cmidrule(lr){2-4} \cmidrule(lr){5-7} 
%                                  & \textbf{RMSE}                & \textbf{MAE}                 & \textbf{R2score}              & \textbf{Sinkhorn}            & \textbf{Gaussian}            & \textbf{Laplacian}           \\
% % \addlinespace[10pt]
% %  \cmidrule(lr){}
% \midrule
% Full Lin                         & \textbf{0.870 $\pm$ 3.2e-03} & \textbf{0.705 $\pm$ 7.4e-03} & 0.120 $\pm$ 5.0e-03             & 0.522 $\pm$ 2.2e-03          & 0.719 $\pm$ 3.2e-03          & 0.544 $\pm$ 2.6e-03          \\
% Full GBoostR                     & 0.935 $\pm$ 2.8e-03          & 0.751 $\pm$ 3.2e-03          & \textbf{-0.014 $\pm$ 4.9e-03} & 0.018 $\pm$ 6.5e-03          & 0.037 $\pm$ 5.5e-03          & 0.055 $\pm$ 8.3e-03          \\
% \midrule
% Unaware Lin                      & 0.889 $\pm$ 7.5e-03          & 0.718 $\pm$ 3.2e-03          & 0.083 $\pm$ 2.4e-03           & 0.097 $\pm$ 4.5e-03          & 0.194 $\pm$ 2.1e-03          & 0.170 $\pm$ 4.7e-03          \\
% Unaware GBoostR                  & 1.034 $\pm$ 7.8e-03          & 0.829 $\pm$ 5.1e-03          & \textbf{-0.242 $\pm$ 3.2e-03} & 0.001 $\pm$ 4.8e-03          & 0.040 $\pm$ 5.1e-03          & 0.018 $\pm$ 3.2e-03          \\
% \midrule

% CF$_1$ Lin                          & 0.906 $\pm$ 4.1e-03          & 0.730 $\pm$ 5.1e-03          & 0.048 $\pm$ 4.8e-03           & 0.019 $\pm$ 3.1e-03          & 0.045 $\pm$ 3.0e-03          & 0.056 $\pm$ 5.1e-03          \\
% CF$_1$  GBoostR                     & 0.909 $\pm$ 2.1e-03          & 0.732 $\pm$ 4.6e-03          & 0.041 $\pm$ 5.1e-03           & 0.013 $\pm$ 7.6e-03          & 0.037 $\pm$ 4.3e-03          & 0.045 $\pm$ 4.6e-03          \\
% CF$_2$    Lin                       & 0.914 $\pm$ 7.3e-03          & 0.736 $\pm$ 5.1e-03          & 0.030 $\pm$ 6.4e-03           & 0.007 $\pm$ 7.5e-03          & 0.020 $\pm$ 8.1e-03          & 0.028 $\pm$ 7.8e-03          \\
% CF$_2$ GBoostR                      & 0.913 $\pm$ 4.9e-03          & 0.734 $\pm$ 3.6e-03          & 0.034 $\pm$ 7.5e-03           & 0.007 $\pm$ 7.3e-03          & 0.022 $\pm$ 8.5e-03          & 0.031 $\pm$ 8.0e-03          \\
% Multi-world                      & 0.917 $\pm$ 3.9e-03          & 0.736 $\pm$ 7.1e-03          & 0.025 $\pm$ 7.1e-03           & 0.003 $\pm$ 5.8e-03          & 0.036 $\pm$ 4.7e-03          & 0.019 $\pm$ 7.9e-03          \\
% % \midrule

% AE Lin                           & \textbf{0.870 $\pm$ 7.1e-03} & \textbf{0.705 $\pm$ 4.1e-03} & 0.121 $\pm$ 6.0e-03           & 0.532 $\pm$ 2.1e-03          & 0.705 $\pm$ 8.1e-03          & 0.538 $\pm$ 5.8e-03          \\
% AE GBoostR                       & 0.889 $\pm$ 3.6e-03          & 0.715 $\pm$ 8.1e-03          & 0.221 $\pm$ 5.1e-03           & 0.425 $\pm$ 8.1e-03          & 0.815 $\pm$ 4.8e-03          & 0.705 $\pm$ 8.6e-03          \\
% Invariant-encoder Lin            & 0.910 $\pm$ 3.4e-03          & 0.727 $\pm$ 7.1e-03          & 0.040 $\pm$ 2.1e-03           & 0.131 $\pm$ 8.1e-03          & 0.160 $\pm$ 5.4e-03          & 0.125 $\pm$ 5.7e-03          \\
% Invariant-encoder GBoostR        & 0.987 $\pm$ 7.1e-03          & 0.773 $\pm$ 3.1e-03          & 0.131 $\pm$ 3.2e-03           & 0.183 $\pm$ 1.9e-03          & 0.179 $\pm$ 7.1e-03          & 0.122 $\pm$ 7.1e-03          \\
% \midrule

% Invariant-fair model (Ours)             & 0.920 $\pm$ 2.2e-03          & 0.739 $\pm$ 2.5e-03          & 0.017 $\pm$ 4.1e-03           & \textbf{0.001 $\pm$ 8.6e-03} & \textbf{0.031 $\pm$ 2.1e-03} & \textbf{0.014 $\pm$ 8.1e-03}
% \\\bottomrule
% \end{tabular}
% \end{adjustbox}
% \caption{Performance comparison on Law dataset. The mean and variance for each method are obtained via 100 repeated experiments. For \textbf{R2score}, we bold the negative results representing that the model is unreliable. For the \textbf{remaining metrics}, the best results are bold.}
% \label{table:law}
% \end{table*}

\begin{table*}[t]
\begin{adjustbox}{width=1.\columnwidth,center}
\begin{tabular}{@{}cccccc@{}}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{3}{c}{\textbf{Regression metric}}     & \multicolumn{2}{c}{\textbf{Fairness metric}}       \\ \cmidrule(lr){2-4} \cmidrule(lr){5-6} 
                                 & \textbf{RMSE}                & \textbf{MAE}                 & \textbf{R2score}              & \textbf{Wasserstein}            & \textbf{Gaussian}            \\ \midrule
Full-LR                         & \textbf{0.870 $\pm$ 3.2e-03} & \textbf{0.705 $\pm$ 7.4e-03} & 0.120 $\pm$ 5.0e-03           & 0.522 $\pm$ 2.2e-03          & 0.719 $\pm$ 3.2e-03          \\
Full-GBoostR                     & 0.935 $\pm$ 2.8e-03          & 0.751 $\pm$ 3.2e-03          & \textbf{-0.014 $\pm$ 4.9e-03} & 0.010 $\pm$ 6.5e-03          & 0.037 $\pm$ 5.5e-03          \\ \midrule
Unaware-LR                      & 0.889 $\pm$ 7.5e-03          & 0.718 $\pm$ 3.2e-03          & 0.083 $\pm$ 2.4e-03           & 0.097 $\pm$ 4.5e-03          & 0.194 $\pm$ 2.1e-03          \\
Unaware-GBoostR                  & 1.034 $\pm$ 7.8e-03          & 0.829 $\pm$ 5.1e-03          & \textbf{-0.242 $\pm$ 3.2e-03} & \textbf{0.009 $\pm$ 4.8e-03}          & 0.030 $\pm$ 5.1e-03          \\ \midrule
CF$_1$-LR                          & 0.906 $\pm$ 4.1e-03          & 0.730 $\pm$ 5.1e-03          & 0.048 $\pm$ 4.8e-03           & 0.019 $\pm$ 3.1e-03          & 0.045 $\pm$ 3.0e-03          \\
CF$_1$-GBoostR                     & 0.909 $\pm$ 2.1e-03          & 0.732 $\pm$ 4.6e-03          & 0.0410 $\pm$ 5.1e-03           & 0.013 $\pm$ 7.6e-03          & 0.037 $\pm$ 4.3e-03          \\
CF$_2$-LR                       & 0.914 $\pm$ 7.3e-03          & 0.736 $\pm$ 5.1e-03          & 0.030 $\pm$ 6.4e-03           & 0.070 $\pm$ 7.5e-03          & 0.030 $\pm$ 8.1e-03          \\
CF$_2$-GBoostR                      & 0.913 $\pm$ 4.9e-03          & 0.734 $\pm$ 3.6e-03          & 0.034 $\pm$ 7.5e-03           & 0.070 $\pm$ 7.3e-03          & 0.032 $\pm$ 8.5e-03          \\
Multi-world                      & 0.917 $\pm$ 3.9e-03          & 0.736 $\pm$ 7.1e-03          & 0.025 $\pm$ 7.1e-03           & 0.030 $\pm$ 5.8e-03          & 0.036 $\pm$ 4.7e-03          \\
\midrule
AE-LR                           & \textbf{0.870 $\pm$ 7.1e-03} & \textbf{0.705 $\pm$ 4.1e-03} & 0.121 $\pm$ 6.0e-03           & 0.532 $\pm$ 2.1e-03          & 0.705 $\pm$ 8.1e-03          \\
AE-GBoostR                       & 0.889 $\pm$ 3.6e-03          & 0.715 $\pm$ 8.1e-03          & 0.221 $\pm$ 5.1e-03           & 0.425 $\pm$ 8.1e-03          & 0.815 $\pm$ 4.8e-03          \\
InvEnc-LR            & 0.905 $\pm$ 3.4e-03          & 0.727 $\pm$ 7.1e-03          & 0.040 $\pm$ 2.1e-03           & 0.131 $\pm$ 8.1e-03          & 0.160 $\pm$ 5.4e-03          \\
InvEnc-GBoostR        & 0.904 $\pm$ 7.1e-03          & 0.773 $\pm$ 3.1e-03          & 0.131 $\pm$ 3.2e-03           & 0.183 $\pm$ 1.9e-03          & 0.179 $\pm$ 7.1e-03          \\
\midrule
InvFair (Ours)      & 0.900 $\pm$ 2.2e-03          & 0.739 $\pm$ 2.5e-03          & 0.087 $\pm$ 4.1e-03           & \textbf{0.009 $\pm$ 8.6e-03} & \textbf{0.029 $\pm$ 2.1e-03} \\ \bottomrule
\end{tabular}
\end{adjustbox}
%%% note 
\caption{Performance comparisons on \texttt{Law} dataset. The mean and variance for each method are obtained via 100 repeated runs. For \textbf{R2score}, results in bold font show the corresponding models are unreliable. For the \textbf{remaining metrics}, the best results are bold. For each method, we use (baseline)-LR/GBoostR to show the baseline combined with Logistic regression or Gradient boosting.}
\label{table:law}
\end{table*}





\begin{table*}[t]
\begin{adjustbox}{width=0.7\columnwidth,center}
\begin{tabular}{@{}cccccc@{}}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{3}{c}{\textbf{Regression metric}}     & \multicolumn{2}{c}{\textbf{Fairness metric}}       \\ \cmidrule(lr){2-4} \cmidrule(lr){5-6} 
                                 & \textbf{RMSE}                & \textbf{MAE}                 & \textbf{R2score}              & \textbf{Wasserstein}            & \textbf{Gaussian}            \\ \midrule
Full-LR                          & 0.0356                                             & 0.0178                                            & 0.0227                                                & 0.0388                                                    & 0.019                                                  \\
Full-GBoostR                     & 0.0262                                             & 0.0475                                            & 0.031                                                 & 0.0433                                                    & 0.034                                                  \\ \midrule
Unaware-LR                       & 0.0106                                             & 0.0085                                            & 0.0234                                                & 0.0161                                                    & 0.0432                                                 \\
Unaware-GBoostR                  & 0.0371                                             & 0.0324                                            & 0.0322                                                & 0.028                                                     & 0.0392                                                 \\ \midrule
CF$_1$-LR                           & 0.0416                                             & 0.0302                                            & 0.0251                                                & 0.0262                                                    & 0.0495                                                 \\
CF$_1$-GBoostR                      & 0.0115                                             & 0.0214                                            & 0.0089                                                & 0.0161                                                    & 0.0215                                                 \\
CF$_2$-LR                           & 0.0449                                             & 0.0325                                            & 0.041                                                 & 0.0253                                                    & 0.0376                                                 \\
CF$_2$-GBoostR                      & 0.0444                                             & 0.0308                                            & 0.0314                                                & 0.0464                                                    & 0.0479                                                 \\
Multi-world                       & 0.0253                                             & 0.0377                                            & 0.0440                                                 & 0.0402                                                    & 0.0136                                                 \\ \midrule
AE-LR                            & 0.0426                                             & 0.0124                                            & 0.0254                                                & 0.0229                                                    & 0.0284                                                 \\
AE-GBoostR                       & 0.0438                                             & 0.0238                                            & 0.0264                                                & 0.0251                                                    & 0.0289                                                 \\
InvEnc-LR                        & 0.0162                                             & 0.0321                                            & 0.0215                                                & 0.0154                                                    & 0.0278                                                 \\
InvEnc-GBoostR                   & 0.0285                                             & 0.0474                                            & 0.0259                                                & 0.0489                                                    & 0.0349                                         \\         \bottomrule                                          
\end{tabular}
\end{adjustbox}
%%% note 
\caption{We compute $p$-value by conducting a paired $t$-test between our approach and baselines with 100 repeated experiments for each metric on Law dataset.}
\label{tab:p1}
\end{table*}






\subsection{Evaluation metrics}
Our method aims to learn the fair and informative representation that can be used for downstream classification or regression.
We use two metrics for prediction and fairness performance, and consider both regression and classification tasks. 




% \begin{equation}
% \small
%     \begin{split}k(x,y) = \begin{cases}
% \frac{1}{2} \|x-y\|^2_2, & \text{Sinkhorn distance} \\ 
%     e^{\frac{-\|x-y\|_2^2}{2\sigma^2}},& \text{Gaussian kernel}
%     %  e^{\frac{-\|x-y\|_2}{2\sigma^2}},& \text{Laplacian kernel}
% \end{cases}\end{split}
% \end{equation}
For the prediction performance, we use root mean squared error {(RMSE)} and mean absolute error {(MAE)} for the {regression task}. 
For the {classification task}, we use {Precision}, {Recall}, {F$_1$ score}, and {Balanced Accuracy} \cite{brodersen2010balanced} for evaluation purpose. 
We emphasize that since the \texttt{Adult} and \texttt{Compas} datasets are highly imbalanced, we use the Balanced Accuracy instead of the traditional accuracy, which is defined as $\text{Balanced Acc} = \frac{\text{TPR} + \text{TNR}}{2}$ where \text{TPR} and \text{TNR} are true positive rate, and true negative rate, respectively.


For the fairness performance, we use Wasserstein distance (Wasserstein) \cite{ruschendorf1985wasserstein} and maximum mean discrepancy (MMD) with Gaussian kernel \cite{gretton2012kernel,oh2019kernel} (Gaussian) in the regression task. On the other hand, we utilize generalized entropy index \cite{speicher2018unified} to evaluate the performance in the classification task. Generalized entropy index that has been previously used widely in economics is explored by \cite{speicher2018unified} as the unified approach to evaluate the performance of individual fairness algorithms defined as follows: 


% \begin{equation}
%     M(P,Q) = ||\mu_P - \mu_Q||
% \end{equation}

% \begin{equation}
%     Mk(P,Q) = ||\mu_P − \mu_Q||^2_{H} = E\mahtcal{P}[k(x,x)] - 2E_{\mathcal{P},\mathcal{Q}}[k(x,y)] + EQ[k(y,y)]
% \end{equation}

% with P and Q are two distributions, and Gaussian kernel $\text{k}(x,y) = e^{\frac{-\|x-y\|_2^2}{2\sigma^2}}$

%  \begin{equation}
%  \small
%  \label{eqn:gausss}
     
%  \end{equation}

 
 

 
%   \begin{equation}
% \small
%     \begin{split}k(x,y) = \begin{cases}
%     e^{\frac{-\|x-y\|_2^2}{2\sigma^2}},& \text{Gaussian distance}
%     %  e^{\frac{-\|x-y\|_2}{2\sigma^2}},& \text{Laplacian kernel}
% \end{cases}\end{split}
% \end{equation}

 
\begin{equation} \small
    \begin{split}\mathcal{E}(\alpha) = \begin{cases}
    \frac{1}{n \alpha (\alpha-1)}\sum_{i=1}^n\left[\left(\frac{b_i}{\mu}\right)^\alpha - 1\right],& \alpha \ne 0, 1,\\
    \frac{1}{n}\sum_{i=1}^n\frac{b_{i}}{\mu}\ln\frac{b_{i}}{\mu},& \alpha=1,\\
    -\frac{1}{n}\sum_{i=1}^n\ln\frac{b_{i}}{\mu},& \alpha=0.
\end{cases}\end{split}
\end{equation}
where $b_i = \hat{y}_i - y_i + 1
$, $\mu = \frac{1}{n}\sum_i^n b_i$. In this study, we use  $\mathcal{E}(1)$ and $\mathcal{E}(2)$ which are called Theil index {(TI)} and coefficient of variation {(CV)}, respectively.
For all metrics except Precision, Recall, F$_1$ score, and Balanced Accuracy, lower values are better. 



% Another recent study \cite{speicher2018unified} provides a unified approach to evaluate the performance of individual fairness algorithms by using a generalized entropy index that has been previously used widely in economics as a measure of income inequality in the population. Our work utilizes the generalized entropy index as the primary metric for evaluation purposes. 

% \begin{equation} \small
%     \text{Balanced Acc} = \frac{\text{TPR} + \text{TNR}}{2}
% \end{equation}

% with 

% \begin{equation} \small
% \text{TPR} = \frac{\text{FP}}{\text{FP}+\text{TN}}
%   \quad\text{and}\quad 
% \text{TNR} = \frac{\text{TN}}{\text{TN}+\text{FP}}
% \end{equation}

% where TN and FP are the true negative and false positive respectively. 


% where \text{TPR} and \text{TNR} are true positive rate, and true negative rate. 


% On the other hand, since counterfactual fairness is an individual-fairness level, we use generalized entropy index \cite{speicher2018unified} to evaluate the performance on the fairness aspect. 
% \begin{equation} \small
%     \begin{split}\mathcal{E}(\alpha) = \begin{cases}
%     \frac{1}{n \alpha (\alpha-1)}\sum_{i=1}^n\left[\left(\frac{b_i}{\mu}\right)^\alpha - 1\right],& \alpha \ne 0, 1,\\
%     \frac{1}{n}\sum_{i=1}^n\frac{b_{i}}{\mu}\ln\frac{b_{i}}{\mu},& \alpha=1,\\
%     -\frac{1}{n}\sum_{i=1}^n\ln\frac{b_{i}}{\mu},& \alpha=0.
% \end{cases}\end{split}
% \end{equation}

% where $b_i = \hat{y}_i - y_i + 1
% $, $\mu = \frac{1}{n}\sum_i^n b_i$. In this study, we use  $\mathcal{E}(1)$ and $\mathcal{E}(2)$ which are called Theil index \textbf{(TI)} and coefficient of variation \textbf{(CV)}, respectively.


% GE(1) is the Theil index, and GE(2) is half the squared coefficient of variation


% \begin{table*}[ht]
% \caption{Wide single-column table in a twocolumn document.}
% \centering
% \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
% \hline
% Method                  & Balanced Accuracy & F$_1$ Score       & Precision      & Recall         & Coefficient of Variation & Theil index    & All Groups Theil Index & Group Coefficient of Variation \\ \hline
% Fully Aware Logistic    & 0.606             & 0.741          & 0.743          & 0.771          & 0.745                    & 0.215          & 1.46e-05                       & 7.66e-03                               \\ \hline
% Fully Aware GBR         & 0.730             & \textbf{0.820} & 0.818          & 0.827          & 0.616                    & 0.142          & 5.12e-05                       & 1.44e-02                               \\ \hline
% Unaware Logistic        & 0.551             & 0.700          & 0.697          & 0.747          & 0.801                    & 0.249          & 4.15e-03                       & 4.11e-02                               \\ \hline
% Unaware GBR             & 0.725             & 0.816          & 0.815          & \textbf{0.824} & 0.622                    & 0.145          & 1.28e-03                       & 2.28e-02                               \\ \hline
% CF$_1$ Logistic            & 0.515             & 0.670          & 0.675          & 0.749          & 0.814                    & 0.272          & 8.14e-03                       & 5.78e-02                               \\ \hline
% CF$_1$ GBR                 & 0.513             & 0.666          & 0.712          & 0.757          & 0.801                    & 0.273          & 9.78e-03                       & 6.35e-02                               \\ \hline
% CF$_2$ Logistic            & 0.515             & 0.669          & 0.671          & 0.747          & 0.817                    & 0.272          & 8.07e-03                       & 5.76e-02                               \\ \hline
% CF$_2$ GBR                 & 0.520             & 0.674          & 0.700          & 0.756          & 0.802                    & 0.269          & 8.50e-03                       & 5.91e-02                               \\ \hline
% CF3 Logistic            & 0.510             & 0.664          & 0.664          & 0.747          & 0.819                    & 0.275          & 8.47e-03                       & 5.90e-02                               \\ \hline
% CF3 GBR                 & 0.502             & 0.653          & 0.669          & 0.754          & 0.807                    & 0.280          & 1.14e-03                       & 6.85e-02                               \\ \hline
% Autoencoder Logistic    & 0.730             & 0.817          & 0.815          & 0.823          & 0.619                    & 0.142          & 2.99e-05                       & 1.10e-02                               \\ \hline
% Generator GBR           & 0.724             & 0.815          & 0.814          & 0.823          & 0.623                    & 0.145          & 1.43e-03                       & 2.41e-02                               \\ \hline
% Generator Logistic      & 0.723             & 0.812          & 0.810          & 0.819          & 0.627                    & 0.146          & 1.43e-03                       & 2.40e-02                               \\ \hline
% Generator GBR           & 0.724             & 0.815          & 0.814          & 0.823          & 0.623                    & 0.145          & 1.43e-03                       & 2.41e-02                               \\ \hline
% Generator Discriminator & \textbf{0.778}    & 0.728          & \textbf{0.835} & 0.707          & \textbf{0.541}           & \textbf{0.077} & \textbf{4.09e-05}              & \textbf{1.28e-02}                      \\ \hline
% \end{tabular}

% \end{table*}


\begin{table*}[!htb]
\begin{adjustbox}{width=1.\columnwidth,center}
\begin{tabular}{@{}ccccccc@{}}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{4}{c}{\textbf{Classification metric}}                                             & \multicolumn{2}{c}{\textbf{Fairness metric}}    
\\
        \cmidrule(lr){2-5} \cmidrule(lr){6-7} 
                                 & \textbf{Balanced Acc}                & \textbf{F$_1$}                 & \textbf{Precision}              & \textbf{Recall}            & \textbf{CV}            & \textbf{TI}           \\
% \addlinespace[10pt]
%  \cmidrule(lr){}
\midrule
Full-Log    & 0.660 $\pm$ 5.3e-03                           & 0.664 $\pm$ 7.5e-03                           & 0.672 $\pm$ 3.1e-03                           & 0.670 $\pm$ 3.0e-03                           & 0.891 $\pm$ 4.5e-03                           & 0.285 $\pm$ 2.8e-03                           \\
Full-GBoostC      & 0.665 $\pm$ 1.8e-03                           & 0.670 $\pm$ 7.5e-03                           & 0.675 $\pm$ 7.8e-03                           & 0.674 $\pm$ 7.6e-03                           & 0.872 $\pm$ 6.5e-03                           & 0.271 $\pm$ 8.2e-03                           \\ \midrule
Unaware-Log & 0.662 $\pm$ 4.5e-03                           & 0.666 $\pm$ 7.9e-03                           & 0.674 $\pm$ 7.9e-03                           & 0.672 $\pm$ 6.0e-03                           & 0.887 $\pm$ 1.8e-03                           & 0.282 $\pm$ 4.6e-03                           \\
Unaware-GBoostC   & 0.662 $\pm$ 7.9e-03                           & 0.666 $\pm$ 7.7e-03                           & 0.672 $\pm$ 4.2e-03                           & 0.672 $\pm$ 4.9e-03                           & 0.880 $\pm$ 3.1e-03                           & 0.276 $\pm$ 5.0e-03                           \\  \midrule
CF$_1$-Log     & 0.500 $\pm$ 8.0e-03                           & 0.381 $\pm$ 2.3e-03                           & 0.522 $\pm$ 5.8e-03                           & 0.540 $\pm$ 4.6e-03                           & 1.306 $\pm$ 6.5e-03                           & 0.615 $\pm$ 1.4e-03                           \\
CF$_1$-GBoost       & 0.534 $\pm$ 3.7e-03                           & 0.517 $\pm$ 2.7e-03                           & 0.551 $\pm$ 5.4e-03                           & 0.556 $\pm$ 1.4e-03                           & 1.159 $\pm$ 3.2e-03                           & 0.463 $\pm$ 6.0e-03                           \\
CF$_2$-Log     & 0.623 $\pm$ 2.5e-03                           & 0.627 $\pm$ 5.7e-03                           & 0.628 $\pm$ 7.5e-03                           & 0.629 $\pm$ 7.2e-03                           & 0.904 $\pm$ 3.7e-03                           & 0.286 $\pm$ 6.8e-03                           \\
CF$_2$-GBoost       & 0.573 $\pm$ 8.5e-03                           & 0.572 $\pm$ 5.6e-03                           & 0.576 $\pm$ 5.5e-03                           & 0.571 $\pm$ 3.4e-03                           & 0.871 $\pm$ 4.7e-03                           & 0.262 $\pm$ 6.9e-03                           \\
Multi-world     & 0.500 $\pm$ 7.5e-03                           & 0.381 $\pm$ 8.6e-03                           & 0.522 $\pm$ 2.1e-03                           & 0.540 $\pm$ 8.5e-03                           & 1.306 $\pm$ 4.5e-03                           & 0.615 $\pm$ 3.6e-03                           \\
\midrule
% Multi-world GBoost       & 0.535 $\pm$ 5.0e-03                           & 0.518 $\pm$ 7.0e-03                           & 0.552 $\pm$ 8.5e-03                           & 0.557 $\pm$ 7.6e-03                           & 1.159 $\pm$ 3.5e-03                           & 0.462 $\pm$ 6.8e-03                           \\ \hline
AE-Log               & 0.659 $\pm$ 6.2e-03                           & 0.663 $\pm$ 4.8e-03                           & 0.667 $\pm$ 4.3e-03                           & 0.667 $\pm$ 5.4e-03                           & 0.876 $\pm$ 6.9e-03                           & 0.272 $\pm$ 4.0e-03                           \\
AE-GBoostC             & 0.666 $\pm$ 5.3e-03                           & 0.670 $\pm$ 6.4e-03                           & 0.676 $\pm$ 6.8e-03                           & 0.675 $\pm$ 8.6e-03                           & 0.874 $\pm$ 5.8e-03                           & 0.273 $\pm$ 1.6e-03                           \\
InvEnc-Log               & \textbf{0.670 $\pm$ 1.5e-03} & \textbf{0.675 $\pm$ 2.9e-03} & \textbf{0.681 $\pm$ 6.8e-03} & \textbf{0.680 $\pm$ 8.5e-03} & 0.869 $\pm$ 4.1e-03                           & 0.270 $\pm$ 1.6e-03                           \\
InvEnc-GBoostC             & 0.666 $\pm$ 5.8e-03                           & 0.670 $\pm$ 1.4e-03                            & 0.676 $\pm$ 8.7e-03                           & 0.675 $\pm$ 5.7e-03                           & 0.874 $\pm$ 6.3e-03                           & 0.273 $\pm$ 2.1e-03                           \\ \midrule
InvFair (Ours)               & 0.668 $\pm$ 2.7e-03                           & 0.672 $\pm$ 2.5e-03                           & 0.672 $\pm$ 2.6e-03                           & 0.673 $\pm$ 5.9e-03                           & \textbf{0.836 $\pm$ 5.1e-03} & \textbf{0.211 $\pm$ 2.2e-03}
\\\bottomrule
\end{tabular}
\end{adjustbox}
\caption{Performance comparison on \texttt{Compas} dataset. The mean and variance for each method are obtained via 100 repeated experiments. The best results are bold. For each method, we name (*)-Log/GBoostC with (*) representing the baseline method.}
\label{table:compas}
\end{table*}



\begin{table*}[!htb]
\label{tab:pvaluecompas}
\begin{adjustbox}{width=0.7\columnwidth,center}
\begin{tabular}{@{}ccccccc@{}}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{4}{c}{\textbf{Classification metric}}                                             & \multicolumn{2}{c}{\textbf{Fairness metric}}    
\\
        \cmidrule(lr){2-5} \cmidrule(lr){6-7} 
                                 & \textbf{Balanced Acc}                & \textbf{F$_1$}                 & \textbf{Precision}              & \textbf{Recall}            & \textbf{CV}            & \textbf{TI}           \\
% \addlinespace[10pt]
%  \cmidrule(lr){}
\midrule
Full-Log                         & 0.0419                                                     & 0.0498                                           & 0.040                                                    & 0.0489                                               & 0.0214                                           & 0.031                                            \\
Full-GBoostC                     & 0.0112                                                     & 0.0482                                           & 0.0101                                                  & 0.0261                                               & 0.014                                            & 0.027                                            \\ \midrule
Unaware-Log                      & 0.0106                                                     & 0.0450                                            & 0.0458                                                  & 0.0342                                               & 0.047                                            & 0.0184                                           \\
Unaware-GBoostC                  & 0.0476                                                     & 0.0164                                           & 0.0347                                                  & 0.0364                                               & 0.0391                                           & 0.0159                                           \\ \midrule
CF$_1$-Log                          & 0.0364                                                     & 0.0367                                           & 0.0323                                                  & 0.017                                                & 0.0305                                           & 0.0173                                           \\
CF$_1$-GBoost                       & 0.0386                                                     & 0.0302                                           & 0.0331                                                  & 0.0144                                               & 0.0105                                           & 0.049                                            \\
CF$_2$-Log                          & 0.0343                                                     & 0.0475                                           & 0.0459                                                  & 0.0122                                               & 0.0384                                           & 0.0148                                           \\
CF$_2$-GBoost                       & 0.0184                                                     & 0.0259                                           & 0.0104                                                  & 0.0173                                               & 0.0475                                           & 0.0302                                           \\
Multi-world                       & 0.0258                                                     & 0.0129                                           & 0.0473                                                  & 0.0186                                               & 0.0316                                           & 0.0344                                           \\ \midrule
AE-Log                           & 0.0164                                                     & 0.0363                                           & 0.0166                                                  & 0.0468                                               & 0.0454                                           & 0.0151                                           \\
AE-GBoostC                       & 0.0401                                                     & 0.0387                                           & 0.0183                                                  & 0.0207                                               & 0.0335                                           & 0.0171                                           \\
InvEnc-Log                       & 0.0208                                                     & 0.036                                            & 0.0272                                                  & 0.0147                                               & 0.0481                                           & 0.0398                                           \\
InvEnc-GBoostC                   & 0.0377                                                     & 0.0364                                           & 0.0157         & 0.030                                                 & 0.0117                                           & 0.0333 
\\\bottomrule
\end{tabular}
\end{adjustbox}
\caption{We compute $p$-value by conducting a paired $t$-test between our approach and baselines with 100 repeated experiments for each metric on Compas dataset.}
\label{tab:p2}
\end{table*}


\begin{table*}[!htb]
% \label{table:adult}
\begin{adjustbox}{width=1.\columnwidth,center}
\begin{tabular}{@{}ccccccc@{}}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{4}{c}{\textbf{Classification metric}}                                             & \multicolumn{2}{c}{\textbf{Fairness metric}}    
\\
        \cmidrule(lr){2-5} \cmidrule(lr){6-7} 
                                 & \textbf{Balanced Acc}                & \textbf{F$_1$}                 & \textbf{Precision}              & \textbf{Recall}            & \textbf{CV}            & \textbf{TI}           \\
% \addlinespace[10pt]
%  \cmidrule(lr){}
\midrule
Full-Log    & 0.606 $\pm$ 7.6e-03          & 0.741 $\pm$ 6.4e-03                          & 0.743 $\pm$ 6.5e-03          & 0.771 $\pm$ 3.4e-03                           & 0.745 $\pm$ 8.7e-03          & 0.215 $\pm$ 7.7e-03          \\
Full-GBoostC      & 0.730 $\pm$ 6.5e-03           & \textbf{0.820 $\pm$ 1.8e-03} & 0.818 $\pm$ 6.2e-03          & \textbf{0.827 $\pm$ 3.8e-03} & 0.616 $\pm$ 3.4e-03          & 0.142 $\pm$ 3.4e-03          \\  \midrule
Unaware-Log & 0.551 $\pm$ 1.9e-03          & 0.700 $\pm$ 7.8e-03                          & 0.697 $\pm$ 7.2e-03          & 0.747 $\pm$ 2.5e-03                           & 0.801 $\pm$ 8.3e-03          & 0.249 $\pm$ 8.6e-03          \\
Unaware-GBoostC   & 0.725 $\pm$ 7.8e-03          & 0.816 $\pm$ 8.4e-03                          & 0.815 $\pm$ 7.8e-03          & 0.824 $\pm$ 7.2e-03                           & 0.622 $\pm$ 3.7e-03          & 0.145 $\pm$ 6.7e-03          \\ \midrule
CF$_1$-Log     & 0.515 $\pm$ 8.6e-03          & 0.670 $\pm$ 5.8e-03                          & 0.675 $\pm$ 2.3e-03          & 0.749 $\pm$ 8.2e-03                           & 0.814 $\pm$ 3.2e-03          & 0.272 $\pm$ 8.4e-03          \\
CF$_1$-GBR          & 0.513 $\pm$ 2.1e-03          & 0.666 $\pm$ 3.3e-03                          & 0.712 $\pm$ 6.8e-03          & 0.757 $\pm$ 2.4e-03                           & 0.801 $\pm$ 7.0e-03          & 0.273 $\pm$ 6.0e-03          \\
CF$_2$-Log     & 0.515 $\pm$ 4.1e-03          & 0.669 $\pm$ 1.3e-03                          & 0.671 $\pm$ 7.7e-03          & 0.747 $\pm$ 6.4e-03                           & 0.817 $\pm$ 8.0e-03          & 0.272 $\pm$ 3.7e-03          \\
CF$_2$-GBoostC       & 0.520 $\pm$ 5.2e-03          & 0.674 $\pm$ 1.9e-03                          & 0.700 $\pm$ 5.5e-03          & 0.756 $\pm$ 8.1e-03                           & 0.802 $\pm$ 6.4e-03          & 0.269 $\pm$ 3.6e-03          \\
Multi-world     & 0.510 $\pm$ 3.9e-03          & 0.664 $\pm$ 5.1e-03                          & 0.664 $\pm$ 7.0e-03            & 0.747 $\pm$ 2.5e-03                           & 0.819 $\pm$ 3.6e-03          & 0.275 $\pm$ 7.8e-03          \\
% Multi-world GBoostC       & 0.502 $\pm$ 2.9e-03          & 0.653 $\pm$ 6.8e-03                          & 0.669 $\pm$ 5.0e-03          & 0.754 $\pm$ 8.3e-03                           & 0.807 $\pm$ 3.4e-03          & 0.280 $\pm$ 1.9e-03          \\ \hline
\midrule
AE-Log                & 0.730 $\pm$ 2.1e-03          & 0.817 $\pm$ 6.0e-03                          & 0.815 $\pm$ 4.2e-03          & 0.823 $\pm$ 8.2e-03                           & 0.819 $\pm$ 8.2e-03          & 0.242 $\pm$ 2.3e-03          \\
AE-GBoostC             & 0.724 $\pm$ 5.5e-03          & 0.815 $\pm$ 1.9e-03                          & 0.814 $\pm$ 7.6e-03          & 0.823 $\pm$ 2.7e-03                           & 0.823 $\pm$ 3.3e-03          & 0.245 $\pm$ 5.4e-03          \\
InvEnc-Log              & 0.723 $\pm$ 7.9e-03          & 0.812 $\pm$ 6.9e-03                          & 0.810 $\pm$ 4.9e-03           & 0.819 $\pm$ 6.2e-03                           & 0.627 $\pm$ 8.1e-03          & 0.146 $\pm$ 2.8e-03          \\
InvEnc-GBoostC             & 0.724 $\pm$ 3.6e-03          & 0.815 $\pm$ 2.3e-03                          & 0.814 $\pm$ 8.2e-03          & 0.823 $\pm$ 1.4e-03                           & 0.623 $\pm$ 2.6e-03          & 0.145 $\pm$ 7.4e-03          \\  \midrule
InvFair (Ours)                & \textbf{0.778 $\pm$ 8.6e-03} & 0.728 $\pm$ 5.4e-03                          & \textbf{0.835 $\pm$ 3.5e-03} & 0.707 $\pm$ 7.2e-03                           & \textbf{0.556 $\pm$ 4.7e-03} & \textbf{0.090 $\pm$ 7.4e-03} 
\\\bottomrule
\end{tabular}
\end{adjustbox}
\caption{Performance comparison on \texttt{Adult} dataset. The mean and variance for each method are obtained via 100 repeated experiments. The best results are bold. For each method, we name (*)-Log/GBoostC with (*) representing features generated by baseline method.}
\label{table:adult}
\end{table*}



\begin{table*}[!htb]
% \label{table:adult}
\begin{adjustbox}{width=0.7\columnwidth,center}
\begin{tabular}{@{}ccccccc@{}}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{4}{c}{\textbf{Classification metric}}                                             & \multicolumn{2}{c}{\textbf{Fairness metric}}    
\\
        \cmidrule(lr){2-5} \cmidrule(lr){6-7} 
                                 & \textbf{Balanced Acc}                & \textbf{F$_1$}                 & \textbf{Precision}              & \textbf{Recall}            & \textbf{CV}            & \textbf{TI}           \\
% \addlinespace[10pt]
%  \cmidrule(lr){}
\midrule
Full-Log                         & 0.0288                                                     & 0.0341                                           & 0.0443                                                  & 0.0145                                               & 0.014                                            & 0.0257                                           \\
Full-GBoostC                     & 0.0275                                                     & 0.0149                                           & 0.0458                                                  & 0.0193                                               & 0.0111                                           & 0.0091                                           \\ \midrule
Unaware-Log                      & 0.0122                                                     & 0.0173                                           & 0.0151                                                  & 0.0398                                               & 0.038                                            & 0.0478                                           \\
Unaware-GBoostC                  & 0.0369                                                     & 0.0476                                           & 0.0431                                                  & 0.0385                                               & 0.0177                                           & 0.0352                                           \\ \midrule
CF$_1$-Log                          & 0.0473                                                     & 0.0366                                           & 0.0144                                                  & 0.0222                                               & 0.0446                                           & 0.0337                                           \\
CF$_1$-GBoost                       & 0.0473                                                     & 0.0338                                           & 0.0193                                                  & 0.0492                                               & 0.0109                                           & 0.0298                                           \\
CF$_2$-Log                          & 0.0405                                                     & 0.0269                                           & 0.0393                                                  & 0.0441                                               & 0.0254                                           & 0.0203                                           \\
CF$_2$-GBoost                       & 0.0361                                                     & 0.0348                                           & 0.021                                                   & 0.0151                                               & 0.0107                                           & 0.0233                                           \\
Multi-world                       & 0.0378                                                     & 0.0264                                           & 0.011                                                   & 0.0137                                               & 0.0326                                           & 0.0242                                           \\ \midrule
AE-Log                           & 0.0369                                                     & 0.0307                                           & 0.0325                                                  & 0.0092                                               & 0.0143                                           & 0.013                                            \\
AE-GBoostC                       & 0.0285                                                     & 0.0294                                           & 0.0155                                                  & 0.0409                                               & 0.0175                                           & 0.025                                            \\
InvEnc-Log                       & 0.0372                                                     & 0.0321                                           & 0.048                                                   & 0.0258                                               & 0.0311                                           & 0.0164                                           \\
InvEnc-GBoostC                   & 0.0239                                                     & 0.0466                                           & 0.0218                                                  & 0.0456                                               & 0.0218                                           & 0.0253                                       
\\\bottomrule
\end{tabular}
\end{adjustbox}
\caption{We compute $p$-value by conducting a paired $t$-test between our approach and baselines with 100 repeated experiments for each metric on Adult dataset.}
\label{tab:p3}
\end{table*}

\begin{figure*}[!htb]
\centering
\includegraphics[width=1.0\textwidth]{lambda.pdf}
\caption{We report the performance of our approach with different hyperparameter $\lambda$ on \texttt{Law}, \texttt{Compas} and \texttt{Adult} datasets. For each $\lambda$, we repeat the experiment 100 times to get the mean and variance.}
\label{fig:lambda}
\end{figure*}
%\qli{figures are not readable and their reading could be better explained.}\duong{fixed}



\subsection{Implementation details}
%% checked 
All implementations are conducted in Python 3.7.7 with 64-bit Red Hat, Intel(R) Xeon(R) Gold 6150 CPU @ 2.70GHz.
The models for all datasets were trained with the following settings: 200 epochs, batch size of 64, Adam optimizer with the learning rate of $10^{-3}$, smooth loss function \cite{girshick2015fast} for \texttt{Law} dataset and cross-entropy loss function for \texttt{Adult} and \texttt{Compas} dataset. We used LeakyReLu \cite{maas2013rectifier} as the $h(.)$ function. We implemented the baseline methods by using Pyro library \cite{bingham2019pyro}, while our method was implemented by Pytorch. 
As regards the evaluation metric, we utilized the available functions from library AI360 \cite{aif360-oct-2018} and GeomLoss \cite{feydy2019interpolating}. More details of implementation settings can be found in the provided source code. 







\subsection{Comparison results}
% working 

% As the key contributions of this work are on Bi-Interaction pooling
% in neural network modelling and the design of NFM for sparse
% data prediction, we conduct experiments to answer the following
% research questions:
% RQ1 Can Bi-Interaction pooling effectively capture the second-
% order feature interactions? How does dropout and batch
% normalization work for Bi-Interaction pooling?
% RQ2 Are hidden layers of NFM useful for capturing higher-
% order interactions between features and improving the
% expressiveness of FM?
% RQ3 How does NFM perform as compared to higher-order FM
% and the state-of-the-art deep learning methods Wide&Deep
% and DeepCross?
% In what follows, we rst present the experimental seings, fol-
% lowed by answering the above research questions one by one


In this section, we report the empirical performance of different methods across three datasets on both the regression and classification tasks. In general, we aim to investigate the following research questions 1) how our approach achieves better fairness and accuracy tradeoff compared to other baselines; 2) how the model performance fluctuates with different hyperparameter $\lambda$ (the values of $\lambda$ for competitive and stable performance). 

% In this section, we aim to report the experimental results of 1) how our proposed estimator (SIE) can accurately estimate the average treatment effect; 2) how our optimization algorithm (Ge-SIO) can be used for finding optimal stochastic intervention in online promotion application; and 3) how the impacts of data size and stochastic degree are. 
% In general, we aim to investigate the experimental results of  1) how our approach perform in comparison with other baselines; 2) how the model performance fluctuates when we vary parameter $\lambda$ from 0 to 250. 



\textbf{Regression task.} Table~\ref{table:law} indicates  the performance comparison for \texttt{Law} dataset. In particular, Full-LR and AE-LR models result in the best accuracy outcome with the lowest RMSE and MAE; however, this model fails to produce the fair prediction demonstrated by the highest fairness metrics. The possible reason is that both Full-LR and AE-LR use all features including the sensitive features, which is beneficial for the accuracy aspect but contains bias. The counterfactual fairness (CF$_1$- and CF$_2$-) and Multi-world methods in contrast witness a good performance when they come to fairness with a significantly low Wasserstein and Gaussian distance, but have quite high regression metrics. Meanwhile, our proposed method (InvFair) consistently produces the lowest results in Wasserstein and Gaussian distance and achieves quite competitive results in RMSE and MAE. We also observe that Linear Regression (-LR) performs better than Gradient Boosting Regression (-GBoostR). Finally, we notice that although the outstanding results are also recorded with Unaware-GBoostR in fairness aspects (0.009 for Wasserstein and 0.03 for Gaussian), its R2score is a negative number which implies the poor performance in the regression task.


% Figure \ref{fig:lambda} meanwhile show that when it comes to Law dataset, our method witness a slight fluctuation in Energy and Gaussian distance, while demonstrating a steady performance in regards RMSE and Wasserstein. 


\textbf{Classification task.} We analyze the task of classification on \texttt{Compas} and \texttt{Adult} datasets on Table ~\ref{table:compas} and Table~\ref{table:adult}, respectively. It is illustrated from Table~\ref{table:compas} that the poor performance is recorded with counterfactual fairness (CF$_1$- and CF$_2$-) and Multi-world approach with low results for classification metrics. In contrast, the latent representation produced from InvEnc combined with Logistic Regression and GBooost achieves the greatest results in terms of the classification metric including Balanced Accuracy, Precision, Recall and f-measure. Meanwhile, our proposed method surpasses all of the other methods regarding fairness metrics (CV and TI). It is moreover ranked second regarding Balanced Accuracy and F$_1$ score and ranked third regarding Precision and Recall. On the other hand, Table~\ref{table:adult} shows the results of different methods in \texttt{Adult} dataset. This dataset is highly imbalanced with the ratio of positive and negative classes being 70\% and 30\%. Our proposed approach produces the best Balanced Accuracy and Precision, while Full-GBoostC has the greatest F$_1$ and Recall score. Regarding fairness metrics, our method consistently surpasses all of the remaining methods. Moreover, gradient boosting classification (-GBoostC) performs better Logistic Regression model (-Log). As seen from the classification task, counterfactual fairness (CF$_1$- and CF$_2$-) and Multi-world model perform poorly in the classification task, possibly due to the misspecification of structural causal models. The invariant-encoder model (InvEnc) that minimizes the prediction of sensitive-awareness and fair-learning models allows the latent representation to achieve favorable outcomes in terms of accuracy aspects. Furthermore, when combined with the fair-learning models in our final approach (InvFair), it produces competitive results in both the prediction and fairness performance.

% Figure~\ref{fig:lambda} meanwhile shows the variation of proposed method performance on Compas and Adult datasets; in general, precision and recall share the same pattern in Compas and Adult datasets. For Compas dataset, the performance of precision, and recall have a slight fluctuation of 0.66 and 0.68, while CV and TI vary marginally around 0.8-0.85 and 0.2-0.25, respectively. For Adult dataset, the performance witnesses a quite big variation before $\lambda$ reaches $100$, and thereafter achieves the outstanding and stable performance when $\lambda$ is greater than $100$. 


% Figure \ref{fig:lambda} shows the variation of our proposed method performance with different hyperparameter $\lambda$\qli{what hyperparameter you want to explore? what does x-axis represent for}. For Law dataset, Gaussian distance fluctuates slightly from 0.01 to 0.02, while RMSE, MAE and Wasserstein is recorded at steady results. In terms of our proposed method performance on Compas and Adult datasets. In general, precision and recall share the same patterns, while CV and TI demonstrates similar trends. For Compas dataset, the performance of precision, and recall have a slight fluctuation of 0.66 and 0.68, while CV and TI vary marginally around 0.8-0.85 and 0.2-0.25, respectively. For Adult dataset, the performance witnesses a quite big variation before $\lambda$ reaches $100$, and thereafter achieves the outstanding and stable performance when $\lambda$ is greater than $100$.

\textbf{Statistical significance.} To better comprehend the effectiveness of our proposed method in producing counterfactual samples compared with other approaches, we also perform a statistical significance test (paired $t$-test)
between our approach and other methods on each dataset and each metric with the obtained results on 100 randomly repeated experiments and report the result of $p$-value in Table~\ref{tab:p1}, Table~\ref{tab:p2} and Table~\ref{tab:p3}. We find that our model is statistically significant with $p < 0.05$, thus demonstrating the effectiveness of our proposed method in achieving counterfactual fairness. 



\textbf{Sensitivity of hyperparameter.}
Figure \ref{fig:lambda} shows the variation of our proposed method performance with different settings of hyperparameter $\lambda$. For \texttt{Law} dataset, Gaussian distance fluctuates slightly from 0.01 to 0.02, while RMSE, MAE and Wasserstein are recorded at steady results. In terms of our proposed method performance on \texttt{Compas} and \texttt{Adult} datasets. In general, Precision and Recall share the same patterns, while CV and TI demonstrate similar trends. For \texttt{Compas} dataset, the performance of Precision and Recall have slight fluctuations of 0.66 and 0.68, while CV and TI vary marginally around 0.8-0.85 and 0.2-0.25, respectively. For \texttt{Adult} dataset, the performance witnesses a quite big variation before $\lambda$ reaches $100$, and thereafter achieves the outstanding and stable performance when $\lambda$ is greater than $100$. 


%% checked
% \textbf{Summary.} Our proposed approach (InvFair) performs best regarding fairness metrics and also achieves a favorable fairness-accuracy tradeoff. We believe that training minimax objective functions for invariant-encoder model and fair-learning predictive model allows excluding the sensitive information in models' decision, and also maintain the high performance in model accuracy. 






% \qli{the link with causality is really missing and there is no discussion about it as well a comparison with similar methods using a prior causal model.
% Causality or more precisely "causal model" is in the title of the paper and is not at all discussed.
% Authors should really revise the section 7.6 end of the paper.}


\section{Conclusion}
%% checked
This paper proposes a minimax game-theoretic approach that can maintain competitive performance in predictive tasks and make counterfactually fair decisions at the individual level.
We believe that training minimax objective functions for invariant-encoder model and fair-learning predictive model allow us
to exclude the sensitive information in models' decisions, and also maintain high accuracy performance. Empirical results on three real-world datasets demonstrated that our proposed approach (InvFair) performs best regarding fairness metrics and also achieves a favorable fairness-accuracy tradeoff. Most importantly, our approach does not require prior knowledge about the structural causal model, making it attractive in real-world applications. In future work, we plan to investigate how to estimate fair causal effects.%\qli{investigate how to estimate fair causal effect}\duong{done}.  

% In this paper, we propose a minimax game-theoretic approach that can maintain competitive performance in the regression and classification task as well as make counterfactually fair decisions at the individual level. Empirical results on three real-world datasets with several metrics demonstrated the effectiveness of our approach in comparison with other state-of-the-art baselines. Most importantly, our approach does not require the prior knowledge about structural causal model which make it attractive in real-world application. In the future work, we plan to address the problem of achieving fair causal effect of sensitive attribute into model decisions. 


% \bibliography{aaai}
% \bibliographystyle{spbasic}
% \bibliographystyle{spmpsci}
% \bibliographystyle{spmpsci}



% \section{Introduction}
% \label{introduction}

% This template helps you to create a properly formatted \LaTeX\ manuscript for the ESWA journal. ESWA is a refereed international journal whose focus is on exchanging information relating to expert and intelligent systems applied in industry, government, and universities worldwide. The thrust of the journal is to publish papers dealing with the design, development, testing, implementation, and/or management of expert and intelligent systems, and also to provide practical guidelines in the development and management of these systems. 

% \section{Essential title page information}
% \label{title_page}

% \begin{enumerate}
%     \item \textbf{Title.} Concise and informative. Titles are often used in information-retrieval systems. Avoid abbreviations and formulae where possible.
%     \item \textbf{Author names and affiliations.} Where the family name may be ambiguous (e.g., a double name), please indicate this clearly. Present the authors' affiliation addresses (where the actual work was done) below the names. Indicate all affiliations with a lower-case superscript letter immediately after the author's name and in front of the appropriate address. Provide the full postal address of each affiliation, including the country name and, the e-mail address of each author.
%     \item \textbf{Corresponding author.} Clearly indicate who will handle correspondence at all stages of refereeing and publication, also post-publication. Ensure that phone numbers (with country and area code) are provided in addition to the e-mail address and the complete postal address. Contact details must be kept up to date by the corresponding author.
%     \item \textbf{Present/permanent address.} If an author has moved since the work described in the article was done, or was visiting at the time, a 'Present address' (or 'Permanent address') may be indicated as a footnote to that author's name. The address at which the author actually did the work must be retained as the main, affiliation address. Superscript Arabic numerals are used for such footnotes.
% \end{enumerate}

% \section{Reference style and reference list}
% \label{reference_style}

% All paper submissions must completely comply with ESWA/ESWA X reference style and reference list (see details at
% \href{https://www.elsevier.com/journals/expert-systems-with-applications/0957-4174/guide-for-authors}{https://www.elsevier.com/journals/\\expert-systems-with-applications/0957-4174/guide-for-authors}).

% \subsection{Reference Style}
% Citations in the text should follow the referencing style used by the American Psychological Association. You are referred to the Publication Manual of the American Psychological Association, Sixth Edition, ISBN 978-1-4338-0561-5.  APA's in-text citations require the author's last name and the year of publication. You should cite publications in the text, for example, (Smith, 2020).  However, you should not use [Smith, 2020].

% \subsection{Reference List}
% References should be arranged first alphabetically by the surname of the first author followed by initials of the author's given name, and then further sorted chronologically if necessary. More than one reference from the same author(s) in the same year must be identified by the letters 'a', 'b', 'c', etc., placed after the year of publication. For example, Van der Geer, J., Hanraads, J. A. J., \& Lupton, R. A. (2010). The art of writing a scientific article. Journal of Scientific Communications, 163, 51-59. https://doi.org/10.1016/j.Sc.2010.00372. There should be no [1], [2], [3], etc in your references list.


% For textual citations use \textbackslash cite\{\}. Here is an example \cite{Feynman1963118,Dirac1953888}. For parenthetical citations use \textbackslash citep\{\}. Another example for citing \citep{Smith2012qr,Smith2013jd,art}: 


% \section*{Acknowledgements}
% Collate acknowledgements in a separate section at the end of the article before the references and do not, therefore, include them on the title page, as a footnote to the title or otherwise. List here those individuals who provided help during the research (e.g., providing language help, writing assistance or proof reading the article, etc.).


\bibliography{aaai}

\end{document}
