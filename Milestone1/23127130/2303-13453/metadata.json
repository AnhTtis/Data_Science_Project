{
    "arxiv_id": "2303.13453",
    "paper_title": "Better Together: Dialogue Separation and Voice Activity Detection for Audio Personalization in TV",
    "authors": [
        "Matteo Torcoli",
        "EmanuÃ«l A. P. Habets"
    ],
    "submission_date": "2023-03-23",
    "revised_dates": [
        "2023-03-24"
    ],
    "latest_version": 1,
    "categories": [
        "eess.AS",
        "cs.SD"
    ],
    "abstract": "In TV services, dialogue level personalization is key to meeting user preferences and needs. When dialogue and background sounds are not separately available from the production stage, Dialogue Separation (DS) can estimate them to enable personalization. DS was shown to provide clear benefits for the end user. Still, the estimated signals are not perfect, and some leakage can be introduced. This is undesired, especially during passages without dialogue. We propose to combine DS and Voice Activity Detection (VAD), both recently proposed for TV audio. When their combination suggests dialogue inactivity, background components leaking in the dialogue estimate are reassigned to the background estimate. A clear improvement of the audio quality is shown for dialogue-free signals, without performance drops when dialogue is active. A post-processed VAD estimate with improved detection accuracy is also generated. It is concluded that DS and VAD can improve each other and are better used together.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13453v1"
    ],
    "publication_venue": "Paper accepted to the 2023 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2023), Rhodes, Greece"
}