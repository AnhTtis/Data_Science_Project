\section{Limitations and Failure Case}
Similar to all existing methods for single-image-based novel view synthesis, our method also fails when there are large changes or translations of view angles (e.g. $>60^{\circ}$). In this case, almost the whole novel-view image is in the occlusion part. A single-image input doesn't provide enough information for predicting such novel views and thus will produce many artifacts.    

\section{Conclusion}

In this paper, we have proposed DT-NeRF for photorealistic novel view rendering using only a single view image as input.
This is achieved by combining plane rendering and volume rendering for better rendering quality and better generalizations to new scenes. 
 We also design an effective depth teacher network that produces dense pseudo depths to supervise the joint rendering and learn consistent 3D geometries. 
 DT-NeRF is shown able to outperform state-of-the-art single-view NeRFs in both the RGB and the depth rendering. 