

Continuing the approach in Section~\ref{sec:counting:preview} for proving equivalence between \AEExactTriCount{} and \AEExactTri{},
we now derive more equivalence results between other counting and detection problems.

\subsection{Min-Plus Product}

In this section, we use $A$ and $B$ to denote the inputs to  a \MinPlus{} or  \MinPlusCount{} instance, and we use $W_{ij}$ to denote the set of $k$ where $A_{ik}+B_{kj} = (A\star B)_{ij}$, i.e., the set of witnesses for $(i, j)$. 

\begin{lemma}
\label{lem:min-plus}
Given two $n \times n$ matrices $A, B$ and a subset $S \subseteq [n]$, we can compute a matrix $D$ in $\OO(|S| \cdot n^{(3+\omega)/2})$ time such that $D_{ij} = |W_{ij}|$ for pairs of $(i, j)$ where $S \cap W_{ij} \ne \emptyset$. 
\end{lemma}
\begin{proof}
For every $s \in S$, we do the following. Let $A^{(s)}$ be a matrix where $A^{(s)}_{ik} = A_{ik} - A_{is}$ and $B^{(s)}_{kj} = B_{sj} - B_{kj}$. Then we  compute the equality product $C^{(s)}$ of $A^{(s)}$ and $B^{(s)}$ in $\OO(n^{(3+\omega)/2})$ time for each $s$ using Matou{\v{s}}ek's algorithm~\cite{MatIPL}. Finally, let $D_{ij}$ be $C^{(s)}_{ij}$ where  $A_{is} + B_{sj}$ is the smallest over all $s \in S$ (breaking ties arbitrarily). The running time for computing $D$ is clearly $\OO(|S| \cdot n^{(3+\omega)/2})$. 

Suppose $S \cap W_{ij} \ne \emptyset$ for some $(i, j)$. Then $D_{ij}$ equals $C^{(s)}_{ij}$ where $A_{is} + B_{sj} = (A \star B)_{ij}$. For any $k$,  $A^{(s)}_{ik} = B^{(s)}_{kj}$ if and only if $A_{ik} + B_{kj} = A_{is} + B_{sj} = (A \star B)_{ij}$ by Fredman's trick. Therefore, $D_{ij} = C^{(s)}_{ij} = |W_{ij}|$.
\end{proof}

\begin{theorem}
\label{thm:minplus-count}
If \MinPlus{} for $n \times n$ matrices has an $O(n^{3-\eps})$ time algorithm for some $\eps > 0$, then \MinPlusCount{} for $n \times n$ matrices  has an $O(n^{3-\eps'})$ time algorithm for some $\eps' > 0$.
\end{theorem}
\begin{proof}
Given a \MinPlusCount{} instance on $n \times n$ matrices $A, B$, we first list up to $n^{0.99}$ elements in $W_{ij}$ for every $i, j$. 
By well-known techniques (e.g.\  \cite{focsyj}), an $O(n^{3-\eps})$ time \MinPlus{} algorithm implies an $O(n^{3-\eps''})$ for $\eps'' > 0$ time algorithm for listing up to $n^{0.99}$ witnesses for each $(i, j)$ in a \MinPlus{} instance. 

If we list less than $n^{0.99}$ elements for some $(i, j)$, then these elements are all the elements in $W_{ij}$. Thus we can output the number of elements we list as the exact witness count for $(i, j)$. For each of the remaining pairs of $(i, j)$, we have found $n^{0.99}$ witnesses. By the standard greedy algorithm for hitting set, in $\OO(n^{2.99})$ time, we can find a set $S$ of size $\OO(n^{0.01})$ that intersects with $W_{ij}$ for each of these remaining $(i, j)$ pairs. Therefore, we can apply Lemma~\ref{lem:min-plus} to compute the number of witnesses for these remaining $(i, j)$ pairs in $\OO(|S| \cdot n^{(3+\omega)/2}) \le O(n^{2.70})$ time. 

The total running time for the \MinPlusCount{} instance is thus $\OO(n^{3-\eps''} + n^{2.99}+n^{2.70})$, which is truly subcubic. 
\end{proof}

We then show the reduction in the other direction. 
The proof is similar to the reduction from a certain version of Min-Plus product to certain versions of  APSP counting in unweighted directed graphs~\cite{CVXicalp21}.
\begin{theorem}
\label{thm:minplus-count-rev}
If \MinPlusCount{} for $n \times n$ matrices has an $O(n^{3-\eps})$ time algorithm for some $\eps > 0$, then \MinPlus{} for $n \times n$ matrices  has an $O(n^{3-\eps'})$ time algorithm for some $\eps' > 0$.
\end{theorem}
\begin{proof}

Let $A, B$ be two $n \times n$ matrices of a \MinPlus{} instance. Let $A'$ be another $n \times n$ matrix where $A'_{ik} = M \cdot A_{ik} + k$ for some large enough integer $M$ (say $M > n$). Similarly, we create an $n \times n$ matrix $B'$ where $B'_{kj} = M \cdot B_{kj}$. This way, for every $i, j$, there exists exactly one $k_{ij}$ such that $A'_{ik_{ij}} + B'_{k_{ij}j} = (A'\star B')_{ij}$. Furthermore, we clearly also have $A_{i,k_{ij}} + B_{k_{ij},j} = (A \star B)_{ij}$. 

Then for each integer $p \in \left[\lceil \log(n) \rceil\right]$, we do the following. Let $A'^{(p)}$ be a copy of $A'$, but we duplicate all columns $k$ where the $p$-th bit in $k$'s binary representation is $1$. We similarly create $B'^{(p)}$ which is a copy of $B'$ but we duplicate all rows $k$ where the $p$-th bit in $k$'s binary representation is $1$. Then we run the $O(n^{3-\eps})$ time  \MinPlusConvCount{} algorithm for $A'^{(p)}$ and $B'^{(p)}$. Suppose for some $i, j$, the number of witnesses is $2$, then we know that the $p$-th bit of  $k_{ij}$ is $1$; otherwise, the $p$-th bit of $k_{ij}$ is $0$. 

After all $\left[\lceil \log(n) \rceil\right]$ rounds, we can compute $k_{ij}$ for every $i, j$. Since $A_{i, k_{ij}} + B_{k_{ij}, j} = (A \star B)_{ij}$, we can then compute the Min-Plus product between $A$ and $B$ in $\OO(n^2)$ time. 
\end{proof}




\subsection{\texorpdfstring{$3$}{3}SUM Convolution and Min-Plus Convolution}
Let $A, B$ and $C$ be the inputs of an \AllThreeSUMConv{} or  \AllThreeSUMConvCount{} instance, and let $W_{k}$ be the set of $i$ where $A_{i}+B_{k-i} =C_{k}$, i.e., the set of witnesses for $k$. 


\begin{lemma}
\label{lem:3sum-conv}
Given a \AllThreeSUMConvCount{} instance for length $n$ arrays $A, B, C$, we can compute $|W_k|$ for every $k$ such that $|W_k| \ge L$ in $\OO(n^{(9+\omega)/4}/L)$ randomized time. 
\end{lemma}
\begin{proof}
First, we find an arbitrary prime $p$ between $2n$ and $4n$, which can be done in $\OO(n)$ time. Also, let $x$ be a uniformly random number sampled from $\mathbb{F}_p \setminus \{0\}$ and let $y$ be a uniformly random number sampled from  $\mathbb{F}_p$. 
Then we create three arrays $A', B'$ and $C'$, indexed by $\mathbb{F}_p$ as follows:
\begin{equation*}
    \begin{split}
        A'_{i} &= \left\{
  \begin{array}{ll}
    A_{x^{-1} (i-y) \bmod{p}} & : x^{-1} (i-y) \bmod{p} \in [n]\\
    M & : \text{otherwise}
  \end{array}
\right.,\\
B'_{i} &= \left\{
  \begin{array}{ll}
    B_{x^{-1} (i+y) \bmod{p}} & :  x^{-1} (i+y) \bmod{p} \in [n]\\
    M & : \text{otherwise}
  \end{array}
\right.,\\
C'_{i} &= \left\{
  \begin{array}{ll}
    C_{x^{-1} i \bmod{p}\phantom{(+y)}}  & :  x^{-1} i \bmod{p} \in [n]\\
    3M & : \text{otherwise}
  \end{array}
\right.,
    \end{split}
\end{equation*}
where $M$ is a large enough number (say $M$ is larger than $10$ times the largest absolute value of the input numbers). 

If we use $W'_k$ to denote the set of $i$ such that $A'_{i} + B'_{(k - i) \bmod{p}} = C'_k$, then it is not difficult to verify that $|W'_{xk \bmod{p}}| = |W_k|$. Thus, from now on, we aim to compute $|W'_k|$ for indices $k$ where $|W'_k| \ge L$. 

We start with the following claim. 
\begin{claim}
\label{cl:3sum-conv-algo}
Let $\mathcal{I} \subseteq \mathbb{F}_p$ be any fixed interval of length $\Theta(\sqrt{n})$ and let $1 \le L' \le \sqrt{n}$ be a fixed value. Then there exists an $\OO(n^{(5+\omega)/4}/L')$ time algorithm that computes $|W_k' \cap \mathcal{I}|$ for every $k$ such that $|W_k' \cap \mathcal{I}| \ge L'$, with high probability. Furthermore, for other values of $k$, we either also compute $|W_k' \cap \mathcal{I}|$ correctly, or declare that we don't know the value of $|W_k' \cap \mathcal{I}|$. 
\end{claim}
\begin{proof}
We first reduce the problem of computing $|W_k' \cap \mathcal{I}|$ to an instance of \AEExactTriCount{}. Similar reductions from convolution problems to matrix-product type problems were known before \cite{bremner2006necklaces, VWfindingcountingj}. Without loss of generality, we assume $\mathcal{I} = \{0, 1, \ldots, \ell - 2, \ell - 1\}$ for some $\ell = \Theta(\sqrt{n})$, by subtracting $\min \mathcal{I}$ from all indices of $A'$ and adding $\min \mathcal{I}$ to all indices of $B'$. 

We then create the following tripartite weighted graph $G$ with three parts $I, J, T$, where $|I| = \ell, |J| = [\lceil p/\ell \rceil]$ and $|T| = 2\ell - 1$. We use $I_i$ to denote the $i$-th node in $I$, $J_j$ to denote the $j$-th node in $J$ and $T_t$ to denote the $t$-th node in $T$. We then add the following edges to the graph: 
\begin{itemize}
    \item For every $i \in [|I|], t \in [|T|]$ such that $i - t + \ell - 1 \in \mathcal{I}$, we add an edge between $I_i$ and $T_t$ with weight $w(I_i, T_t) = A'_{i - t + \ell - 1}$.
    \item For every $t \in [|T|]$ and $j \in [|J|]$, we add an edge between $T_t$ and $J_j$ with weight $w(T_t, J_j) = B'_{((j-1)\ell + t - \ell) \bmod{p}}$. 
    \item For every $i \in [|I|], j \in [|J|]$ such that $(j-1)\ell + i - 1 < p$, we add an edge between $I_i$ and $J_j$ with weight $w(I_i, J_j) = -C'_{(j-1)\ell + i - 1}$. 
\end{itemize}
Consider any $(i, j) \in [\ell] \times [\lceil p/\ell \rceil]$ such that $(j-1)\ell + i - 1 < p$. The nodes $T_t$ such that $i - t + \ell - 1 \in \mathcal{I}$ form triangles with edge $(I_i, J_j)$. The multiset of the weights of these triangles is 
\begin{equation*}
    \begin{split}
        \left\{w(I_i, T_t) + w(J_j, T_t) + w(I_i, J_j) \right\}_{t=i}^{i+\ell-1} &= \left\{A'_{i - t + \ell - 1} + B'_{((j-1)\ell + t - \ell) \bmod{p}} - C'_{(j-1)\ell + i - 1} \right\}_{t=i}^{i+\ell-1}\\
        &= \left\{A'_r + B'_{\left( (j-1)\ell + (i-1) - r\right) \bmod{p}} -C'_{(j-1)\ell + i - 1}\right\}_{r=0}^{\ell - 1}.
    \end{split}
\end{equation*}
Thus, the number of triangles with weight $0$ containing edge $(I_i, J_j)$ in $G$ is exactly  $|W'_k \cap \mathcal{I}|$ for $k = (j-1)\ell + i - 1$.
In particular, if $|W'_k \cap \mathcal{I}| \ge L'$, then the number of witnesses for $(I_i, J_j)$ in the \AEExactTriCount{} instance on graph $G$ and target value $0$ is also at least $L'$. Now let $S$ be a random subset of $V(G)$ of size $C n^{0.5} \log n/L'$ for a sufficiently large constant $C$. Then with high probability, $S$ intersects with the set of witnesses for every edge $(I_i, J_j)$ for which  $k=(j-1)\ell + (i-1)$ has at least $L'$ witnesses in $\mathcal{I}$. Now we can apply Lemma~\ref{lem:exact-tri} on graph $G$, target value $0$ and set $S$ to compute the number of witnesses for these edges $(I_i, J_j)$ in $\OO(|S| \sqrt{n}^{(3+\omega)/2}) = \OO(n^{(5+\omega)/4}/L')$ time. 

If $S$ does not intersect with the witnesses for some edge $(I_i, J_j)$ (which is easy to check in $O(|S|n)$ total time), we declare that we don't know the value of $|W_k' \cap \mathcal{I}|$ for  $k=(j-1)\ell + (i-1)$.
\end{proof}

\begin{claim}
\label{cl:3sum-conv-chebyshev}
Let $\mathcal{I} \subseteq \mathbb{F}_p$ be any fixed interval and $k \in [n]$ be any fixed index. If $|W_k| \ge L$, then 
$$\Pr_{\substack{x \sim \mathbb{F}_p \setminus \{0\} \\ y \sim \mathbb{F}_p}}\left[ \left| W'_{xk \pmod{p}} \cap \mathcal{I} \right| \le \frac{L|\mathcal{I}|}{2p}\right] = O(\frac{n}{L|\mathcal{I}|}).$$
\end{claim}
\begin{proof}
First, note that $W'_{xk \pmod{p}} = \{xw + y \pmod{p}: w \in W_k\}$. Let $X$ be the random variable denoting $\left| W'_{xk \pmod{p}} \cap \mathcal{I}\right|$. First, since for any $w \in W_k$, $xw + y \pmod{p}$ is uniformly at random, $\Pr[xw + y \pmod{p} \in \mathcal{I}] = \frac{|\mathcal{I}|}{p}$, and consequently $\mathbb{E}[X] = \frac{|W_k||\mathcal{I}|}{p}$. 

For any $w, w' \in W_k$ where $w \ne w'$, the probability that both $xw + y \pmod{p}$ and $xw' + y \pmod{p}$ fall in $\mathcal{I}$ can be expressed as
$$\sum_{i_1, i_2 \in \mathcal{I}} \Pr[xw+y \equiv i_1 \pmod{p} \wedge xw'+y \equiv i_2 \pmod{p}]. $$
If $i_1 = i_2$, then $xw+y \equiv i_1 \pmod{p}$ and $xw'+y \equiv i_2 \pmod{p}$ cannot both happen; otherwise, there exists at most one pair $(x, y) \in \mathbb{F}_p \times \mathbb{F}_p$ for which $xw+y \equiv i_1 \pmod{p}$ and $xw'+y \equiv i_2 \pmod{p}$ are both true. Thus, $\Pr[xw + y \pmod{p} \in \mathcal{I} \wedge xw' + y \pmod{p} \in \mathcal{I}] \le \frac{|\mathcal{I}|(|\mathcal{I}|-1)}{p(p-1)} \le \frac{|\mathcal{I}|^2}{p^2}$. Thus, $$\Var[X] = \mathbb{E}[X^2] - \mathbb{E}[X]^2 \le \left(|W_k|(|W_k|-1)\frac{|\mathcal{I}|^2}{p^2} + \mathbb{E}[X] \right)- \mathbb{E}[X]^2 \le \mathbb{E}[X].$$
Also, 
\begin{equation*}
    \Pr\left[X \le \frac{L|\mathcal{I}|}{2p}\right] \le \Pr\left[X \le \frac{|W_k||\mathcal{I}|}{2p}\right] \le \Pr\left[\left|X - \mathbb{E}[X] \right| \le \frac{1}{2} \mathbb{E}[X]\right].
\end{equation*}
By Chebyshev's inequality, this probability can be upper bounded by $\frac{\Var[X]}{(\frac{1}{2} \mathbb{E}[X])^2} = O(\frac{n}{L|\mathcal{I}|})$. 
\end{proof}

We now describe our algorithm for computing $|W_k|$. First, we split $\mathbb{F}_p$ into $\ell = \Theta(\sqrt{n})$ intervals $\mathcal{I}_1, \mathcal{I}_2, \ldots, \mathcal{I}_\ell$, each of size $\Theta(\sqrt{n})$. Then it suffices to compute $|W'_{xk \bmod{p}} \cap \mathcal{I}_i|$ for each $i \in [\ell]$, since $|W_k| = |W'_{xk \bmod{p}}| = \sum_{i=1}^\ell |W'_{xk \bmod{p}} \cap \mathcal{I}_i|$. 

We first run the algorithm in Claim~\ref{cl:3sum-conv-algo} for each $i$ with $L' = \frac{L |\mathcal{I}_i|}{2p}$, which takes $\OO(n^{(5+\omega)/4} / L') = \OO(n^{(7+\omega)/4}/L)$ time. Claim~\ref{cl:3sum-conv-algo}  computes $|W'_{xk \bmod{p}} \cap \mathcal{I}_i|$ as long as $|W'_{xk \bmod{p}} \cap \mathcal{I}_i| \ge L'$. For each fixed $k$, it fails to compute $|W'_{xk \bmod{p}} \cap \mathcal{I}_i|$ with probability $O(\sqrt{n}/L)$ by Claim~\ref{cl:3sum-conv-chebyshev}. For these $k$, we enumerate over $j \in \mathcal{I}_i$, check if $j \in W'_{xk \bmod{p}}$, and then compute  $|W'_{xk \bmod{p}} \cap \mathcal{I}_i|$. In expectation, the cost of these $k$ is $O(\frac{n \cdot \sqrt{n}}{L}  \cdot |\mathcal{I}_i|) = O(n^2 / L)$. 

Summing over all $i \in [\ell]$, the total expected running time of the algorithm is $\OO(n^{(9+\omega)/4}/L)$. 
\end{proof}


\begin{theorem}
\label{thm:all-3sum-conv-count}
If \AllThreeSUMConv{} for length $n$ arrays has an $O(n^{2-\eps})$ time algorithm for some $\eps > 0$, then \AllThreeSUMConvCount{} for length $n$ arrays  has an $O(n^{2-\eps'})$ time randomized algorithm for some $\eps' > 0$
\end{theorem}
\begin{proof}

Similar as before, given an \AllThreeSUMConvCount{} instance on length $n$ arrays $A, B, C$, we can count the number of witnesses for $C_k$ that have at most $n^{0.99}$ witnesses in $O(n^{2-\eps''})$ time by well-known techniques~\cite{focsyj} when \AllThreeSUMConv{} has a truly subquadratic algorithm.




For the rest values of $k$, we run the algorithm in Lemma~\ref{lem:3sum-conv} which runs in $\OO(n^{(9+\omega)/4} / n^{0.99}) = O(n^{1.86})$ time. 

Overall, the algorithm for \AllThreeSUMConvCount{} runs in $O(n^{2-\eps''} + n^{1.86})$ time, which is truly subquadratic. 
\end{proof}

As in Remark~\ref{rem:exact-tri-count}, Theorem~\ref{thm:all-3sum-conv-count} implies that \ThreeSUMConv{} is subquadratically equivalent to \ThreeSUMConvCount{}.

\begin{theorem}
\label{thm:minplus-conv-count}
If \MinPlusConv{} for length $n$ arrays has an $O(n^{2-\eps})$ time algorithm for some $\eps > 0$, then \MinPlusConvCount{} for length $n$ arrays  has an $O(n^{2-\eps'})$ time randomized algorithm for some $\eps' > 0$.
\end{theorem}
\begin{proof}

Given an \MinPlusConvCount{} instance for length $n$ arrays $A, B$, we first run the assumed \MinPlusConv{} algorithm to compute the Min-Plus convolution $C$ of $A$ and $B$ in $O(n^{2-\eps})$ time. 

Similar as before, given the $O(n^{2-\eps})$ time algorithm for \MinPlusConv{}, we can count the number of witnesses for $C_k$ that have at most $n^{0.99}$ witnesses in $O(n^{2-\eps''})$ time by well-known techniques~\cite{focsyj}. 



For the rest values of $k$, we run the algorithm in Lemma~\ref{lem:3sum-conv} with arrays $A, B, C$ and $L = n^{0.99}$ which runs in $\OO(n^{(9+\omega)/4} / n^{0.99}) = O(n^{1.86})$ time. 

Overall, the algorithm for \MinPlusConvCount{} runs in $O(n^{2-\eps}+ n^{2-\eps''} + n^{1.86})$ time, which is truly subquadratic. 
\end{proof}

We then show a reduction from \MinPlusConv{} to \MinPlusConvCount{}. 
\begin{theorem}
\label{thm:minplus-conv-count-rev}
If \MinPlusConvCount{} for length $n$ arrays has an $O(n^{2-\eps})$ time algorithm for some $\eps > 0$, then \MinPlusConv{} for length $n$ arrays  has an $O(n^{2-\eps'})$ time randomized algorithm for some $\eps' > 0$.
\end{theorem}
\begin{proof}
Let $A$ and $B$ be two length $n$ arrays for a \MinPlusConv{} instance. Let $C$ be their Min-Plus convolution. As in proof of Theorem~\ref{thm:minplus-count-rev},
we can assume $|W_k|=1$ for every $k$, i.e., there exists a unique $i_k$ such that $A_{i_k} +B_{k - i_k} = C_k$. 

For each $p \in \left[ \lceil \log(n)\rceil\right]$, we perform the following round. Let $A'$ be a length $2n$ array such that $A'_{2i-1} = A_i$ for every $i \in [n]$, $A'_{2i} = A_i$ for every $i \in [n]$ whose $p$-th bit in its binary representation is $1$, and $A'_{2i} = \infty$ for the rest of $i$. Also, let $B'$ be a length $2n$ array such that $B'_{2i-1} = B'_{2i} = B_i$ for every $i \in [n]$. Now we use the \MinPlusConvCount{} algorithm for arrays $A'$ and $B'$. Suppose $C'$ is the Min-Plus convolution between $A'$ and $B'$. Clearly, for any $k \in [n]$, $C'_{2k-1} = C_k$. Also, suppose $C'_{2k-1}$ has $2$ witnesses, then we know that $A'_{2i_k} = A_{i_k}$ and thus the $p$-th bit in $i_k$-th binary representation is $1$; otherwise the $p$-th bit in $i_k$-th binary representation is $0$. 

Thus, after the $\lceil \log(n)\rceil$ rounds, we can compute $i_k$ for each $k \in [n]$, which can then be used to compute the Min-Plus convolution $C$ between $A$ and $B$ in $O(n)$ time. 
\end{proof}

\subsection{All-Numbers 3SUM}


\begin{theorem}
\label{thm:all-3sum-count}
If \AllThreeSUM{} for  sets of $n$ numbers has an $O(n^{2-\eps})$ time algorithm for some $\eps > 0$, then \AllThreeSUMCount{} for sets of $n$ numbers  has an $O(n^{2-\eps'})$ time randomized algorithm for some $\eps' > 0$.
\end{theorem}
\begin{proof}
If \AllThreeSUM{} for sets of $n$ numbers has an $O(n^{2-\eps})$ time algorithm for $\eps > 0$, then so does \AllThreeSUMConv{} for length $n$ arrays, since \AllThreeSUMConv{} is not harder than \AllThreeSUM{}. Then by Theorem~\ref{thm:all-3sum-conv-count}, \AllThreeSUMConvCount{} for length $n$ arrays has an $O(n^{2-\eps''})$ time algorithm for some $\eps'' > 0$. Therefore, it suffices to reduce \AllThreeSUMCount{} to \AllThreeSUMConvCount{}. Some previous reductions from \ThreeSUM{} to \ThreeSUMConv{} actually work for the counting variants as well~\cite{patrascu2010towards, ChanHe}. Arguably the simplest such reduction is given in~\cite[Section 3]{ChanHe}. Applying their reduction finishes the proof.
\end{proof}










As in Remark~\ref{rem:exact-tri-count}, Theorem~\ref{thm:all-3sum-count} implies that \ThreeSUM{} is subquadratically equivalent to \ThreeSUMCount{}.

Still more equivalence results for other counting and detection problems are given in Appendix~\ref{sec:more_counting}.

\subsection{Discussion}\label{sec:counting:discuss}

Abboud, Feller and Weimann \cite{AbboudFW20} showed that counting the number of Negative Triangles in a graph (even mod 2) can solve \ExactTri, thus presenting a barrier to showing that the Negative Triangle  problem ({\sf Neg-Tri}) is equivalent to its counting variant: Vassilevska W. and Williams \cite{focsyj} showed that {\sf Neg-Tri} is equivalent to \APSP{} under subcubic fine-grained reductions; then if {\sf \#Neg-Tri} can be reduced to {\sf Neg-Tri}, one can also reduce it to \APSP, and since there are fine-grained reductions from \ThreeSUM{}  to \ExactTri{} \cite{VWfindingcountingj}, and from \ExactTri{} to {\sf \#Neg-Tri} \cite{AbboudFW20}, one would get a very surprising reduction from \ThreeSUM{} to \APSP. There is some evidence that such a reduction would be difficult to obtain: for instance, while \APSP{} has a superlogarithmic improvement over its simple cubic algorithm \cite{Williams18}, the best improvement over the simple quadratic algorithm of \ThreeSUM{} only shaves two logarithmic factors (e.g. \cite{baran2005subquadratic})!

Our equivalences between \MinPlus{} (and thus Minimum Weight Triangle) and \ExactTri{} respectively with their counting variants exhibit a strange phenomenon: {\sf Neg-Tri} seems different from these problems! Or, perhaps, if we believe that {\sf Neg-Tri} is like these problems and is equivalent to {\sf \#Neg-Tri}, then we should be more optimistic about the existence of a fine-grained reduction from \ThreeSUM{} to \APSP.


Another line of work in which counting variants of fine-grained problems have been considered is in worst-case to average-case reductions and {\em fine-grained cryptography} \cite{BallRSV17,BallRSV18,Boix-AdseraBB19,GO2020,DalirrooyfardLW20,LaVigneLW19,merkle}: building cryptographic primitives from worst-case fine-grained assumptions that might still hold even if $\text{P}=\text{NP}$. The known techniques 
 for worst-case to average-case reductions for fine-grained problems only work for counting problems, whereas the design of fine-grained public key protocols \cite{LaVigneLW19,merkle} seem to require that the decision variants are hard on average.





Suppose that one can use the known toolbox for worst-case to average-case reductions for counting problems to show that \ExactTriCount{} or \ThreeSUMCount{} is hard on average.
Then via our reductions back to \ExactTri{} and \ThreeSUM{}, one would get some distributions for which these decision problems are actually hard. This could pave the way to new public-key protocols.
