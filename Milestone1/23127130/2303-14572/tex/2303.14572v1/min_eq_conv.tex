
In this section, we prove conditional lower bounds for the \MinEqualityConv{}
problem under \StrongAPSP{}, the \uAPSPH{}, and the
\StrongConv{}.  
The lower bound under the \StrongAPSP{} or \uAPSPH{}
follows just by combining Corollary~\ref{cor:strong-intapsp-imply} %
with the known reduction from \uAPSP{} to \MinWitnessEq{} \cite{CVXicalp21} (and noticing that \MinWitnessEq{} is easier than \MinEqualityProd{}), and then using known ideas for reducing matrix product problems to convolution problems (more specifically, the unpublished reduction from \BMM{} to pattern-to-text Hamming distances, attributed to Indyk -- see e.g.\  \cite{GawrychowskiU18}). 
The lower bound under the \StrongConv{} is more delicate: %
interestingly, we will combine ideas that we have developed
for conditional lower bounds for intermediate matrix product problems, with
one of our new versions of the BSG Theorem from the previous section.


\begin{theorem}
\label{thm:min-equal-conv-under-product}
Under the \StrongAPSP{}, \MinEqualityConv{} for length $n$ arrays  requires $n^{1+1/6-o(1)}$ time.
\end{theorem}
\begin{proof}
First, by Corollary~\ref{cor:strong-intapsp-imply}, \uAPSP{} requires $n^{7/3-o(1)}$ time under the Strong Integer-APSP Hypothesis. Zwick's algorithm \cite{zwickbridge} can be seen as a reduction from \uAPSP{} to $\OO(1)$ instances of \MinPlus{} between $n \times n^\alpha$ matrices and $n^\alpha \times n$ matrices with weights in $[n^{1-\alpha}]$ for various values of $\alpha \in [0, 1]$. As shown in \cite{CVXicalp21}, each  instance of \MinPlus{} in this form can be reduced to an instance of \MinWitnessEq{} for $O(n) \times O(n)$ matrices (they only stated the reduction for $\alpha = \rho$ for a particular value of $\rho$,  but their proof works for any $\alpha \in [0, 1]$). Therefore, \MinWitnessEq{} requires $n^{7/3-o(1)}$ time under the Strong Integer-APSP Hypothesis. 

We can easily reduce a \MinWitnessEq{} instance to a \MinEqualityProd{} instance. Suppose the input of a \MinWitnessEq{} instance is $A, B$. Assume all entries are in $[2n]$ without loss of generality. We can create two $n \times n$ matrices $A'$ and $B'$, where $A'_{ik} = A_{ik}+2nk$ and $B'_{kj} = B_{kj} + 2nk$, then the Min-Witness Equality product between $A$ and $B$ can be computed in $\OO(n^2)$ time given the Min-Equality product between $A'$ and $B'$. 

Finally, we reduce \MinEqualityProd{} to \MinEqualityConv{}, following the strategy of the unpublished reduction from Boolean matrix multiplication to  pattern-to-text Hamming distances, attributed to Indyk, see e.g. \cite{GawrychowskiU18}. 

Let $A$ and $B$ be the inputs of \MinEqualityProd{}. W.l.o.g., we can assume all entries of $A$ and $B$ are integers in $[2n^2]$. 
We first create two length $2n^2$ arrays $a$ and $b$, where initially all entries of $a$ and $b$ are $\infty$. For every $(i, k) \in [n] \times [n]$, we set $a_{(n+1)(i-1) + k}$ to $n A_{ik} + k - 1$; for every $(k, j) \in [n] \times [n]$, we set $b_{jn-k}$ to $n B_{kj} + k - 1$. 

Suppose the Min-Equality product between $A$ and $B$ is $C$ and the Min-Equality convolution between $a$ and $b$ is $c$, we will show that $C_{ij} = \lfloor c_{(n+1)(i-1)+jn} / n \rfloor$ (and  $C_{ij} = \infty$ if $c_{(n+1)(i-1)+jn}$ is  $\infty$), which will complete the reduction. 

To show the equality, first notice that 
\begin{equation}
\label{eqn:min-equal-conv}
\begin{split}
    &\min \left\{a_{(n+1)(i-1) + k} : k \in [n] \wedge a_{(n+1)(i-1) + k} = b_{jn-k} \right\} \\
    =& \min \left\{nA_{ik} + k -1 : k \in [n] \wedge A_{ik}=B_{kj} \right\}
\end{split}
\end{equation}
contributes to the minimization of $c_{(n+1)(i-1)+jn}$. Also, no other terms less than $\infty$ can contribute: suppose there exists some $x$ such that $a_x = b_{y} < \infty$ and $x+y = (n+1)(i-1)+jn$, then $a_x \bmod{n}$ must match $b_y \bmod{n}$. Thus, there must exist $i', j', k' \in [n]$ such that $x = (n+1)(i'-1)+k'$ and $y = j'n - k'$, so $(n+1)(i'-1) + j'n = (n+1)(i-1) + jn$. Then it must be the case that $i=i'$ and $j=j'$, so $a_x$ corresponds to one of the terms in Equation~(\ref{eqn:min-equal-conv}).
\end{proof}
The reduction in the proof of Theorem~\ref{thm:min-equal-conv-under-product} from \uAPSP{} to \MinEqualityConv{} also easily imply the following:

\begin{theorem}
\label{thm:min-equal-conv-under-uAPSP}
Under the \uAPSPH{}, \MinEqualityConv{} for length $n$ arrays requires $n^{1+\rho/2-o(1)}$ time, where $\rho$ is the constant satisfying $\omega(1, \rho, 1) = 1 + 2\rho$, or $n^{1.25-o(1)}$ time if $\omega = 2$. 
\end{theorem}


We finally show the lower bound of \MinEqualityConv{} under the \StrongConv{}. 

\begin{theorem}
\label{thm:min-equal-conv-under-conv}
Under the \StrongConv{}, \MinEqualityConv{} for length $n$ arrays  requires $n^{1+1/11-o(1)}$ time.
\end{theorem}
\begin{proof}

We will show that if \MinEqualityConv{} for length $n$ arrays has an $\OO(n^{1+\delta})$ time algorithm for some $\delta \ge 0$, then \MinPlusConv{} for length $n$ arrays of entries that are bounded by $O(n)$  has an $\OO(n^{2 - \frac{1-11\delta}{21}})$ time randomized algorithm.

Let $A$ and $B$ be the input arrays of a \MinPlusConv{} instance. Let $t$ be a parameter to be fixed later, and let $g = \lceil n/t\rceil$. Similar to the proof of Theorem~\ref{thm:main}, we can assume $(A_i \bmod{g}) < g/2$ and $(B_i \bmod{g}) < g/2$
for each $i \in [n]$. Also, for each $i$, we can write $A_i$ as $A'_i g + A''_i$, for $0 \le A'_i \le t$ and $0 \le A''_i < g/2$. Similarly, we can write $B_i$ as $B'_i g + B''_i$. 

We first compute the Min-Plus convolution $C'$ of $A'$ and $B'$ in $\OO(tn)$ time. Let $W_k = \{i \in [n]: k - i \in [n] \wedge C'_k = A'_i + B'_{k - i}\}$. Suppose we can compute $C''$, which is defined as $C''_k = \min_{i \in W_k} (A''_i + B''_{k-i})$, then we can compute the Min-Plus convolution $C$ of $A$ and $B$ as $C_k = C'_k g + C''_k$. 

We then compute $C''_k$ by two methods depending on whether $|W_k|$ is greater than $n/s$ or not, for some parameter $s$ to be determined. 


\begin{claim}
\label{cl:min-equal-conv-heavy}
For any parameter $\sss$, 
we can compute $C''_k$ for every $k$ where $|W_k| > n / s$ in $\OO(n^2 / \sss + s^5 \sss^4 n^2 / t)$ time. 
\end{claim}
\begin{proof}
We create the following indexed set $\mathcal{A}$ of size $O(n)$:
$$\left\{(i, A'_i): i \in [n]\right\} \cup \left\{(i+n, \infty) : i \in [n]\right\} \cup \left\{(3n + 1 - i, -B'_i): i \in [n] \right\}.$$
Note that for any $k \in [n]$, $|W_k| = \pop_{\mathcal{A}}((k - 3n - 1, C'_k))$. Then we apply Theorem~\ref{thm:bsg:gower:fast} with the index set $\mathcal{A}$ and parameters $s, \sss$ to find a collection of $\ell = \OO(s^2 \sss)$ subsets $\mathcal{A}^{(1)}, \ldots, \mathcal{A}^{(\ell)}$, and a set $R$ of $\OO(n^2/\sss)$ pairs in $\mathcal{A} \times \mathcal{A}$ in $\OO(n^2/\sss + s^2 \sss n )$ randomized time. Furthermore, Theorem~\ref{thm:bsg:gower:fast} guarantees that
\begin{enumerate}
    \item[\rm(i)] $\{(a,b)\in \mathcal{A}\times \mathcal{A}: \pop_\mathcal{A}(a-b) > n/s\}\ \subseteq\ 
R\,\cup\, \bigcup_\lambda (\mathcal{A}^{(\lambda)}\times \mathcal{A}^{(\lambda)})$. This further means that, for every $k$ where $|W_k| > n/s$, $$\left\{ \left((i, A'_i), (3n+1-(k-i), -B'_{k-i}) \right): i \in W_k\right\} \subseteq\ 
R\,\cup\, \bigcup_\lambda (\mathcal{A}^{(\lambda)}\times \mathcal{A}^{(\lambda)}).$$
\item[\rm(ii)] $\sum_\lambda |\mathcal{A}^{(\lambda)} - \mathcal{A}^{(\lambda)}| = \OO(s^5 \sss^4 n)$. 
\end{enumerate}
Then we first enumerate $((i_1, v_1), (i_2, v_2)) \in R$. If this pair corresponds to some $A'_i$ and $B'_j$ (i.e., this pair has $i_1 = i, i_2 = 3n+1-j$), we use $A''_i + B''_j$ to update $C''_{i+j}$ if $A'_i + B'_j = C'_{i+j}$. This takes $\OO(|R|) = \OO(n^2 / \sss)$ time. 

For each $\lambda \in [\ell]$, we consider the possible witnesses in $\mathcal{A}^{(\lambda)} \times \mathcal{A}^{(\lambda)}$. We prepare a map $f$ from $\mathcal{A}^{(\lambda)}$ to $[g] \cup \{\infty\}$ as follows: if $a \in \mathcal{A}^{(\lambda)}$ corresponds to some $A'_i$ (i.e., $a = (i, A'_i)$), we set $f(a) = A''_i$; if $a$ corresponds to some $B'_j$ (i.e., $a = (3n+1-j, -B'_j)$), we set $f(a) = B''_j$; otherwise, we set $f(a) = \infty$. Then we compute the following Min-Plus ``convolution'' $\mathcal{C}^{(\lambda)}$:
$$\mathcal{C}^{(\lambda)}_c = \min_{\substack{(a, b) \in \mathcal{A}^{(\lambda)} \times \mathcal{A}^{(\lambda)} \\ a - b = c}} (f(a) + f(b)).$$
By known techniques for solving Min-Plus convolution with small integer weights \cite{ALONGM1997}, we can instead solve a normal convolution with weights bounded by $2^{\OO(g)}$. More specifically, let $h(a) = M^{f(a)}$ if $f(a) \ne \infty$ and $f(a) = 0$ otherwise, where $M = |\mathcal{A}^{(\lambda)}|+1$. Then it suffices to compute the following for every $c$:
$$\sum_{\substack{(a, b) \in \mathcal{A}^{(\lambda)} \times \mathcal{A}^{(\lambda)} \\ a - b = c}} h(a) \cdot h(b).$$
By known output-sensitive algorithms~\cite{ColeHariharanSTOC02,ChanLewenstein, BringmannFN}, it takes $\OO(|\mathcal{A}^{(\lambda)} - \mathcal{A}^{(\lambda)}|)$ arithmetic operations to compute the above convolution, and each  arithmetic operation takes $\OO(g)$ time. Thus, it takes $\OO(g|\mathcal{A}^{(\lambda)} - \mathcal{A}^{(\lambda)}|)$ time to compute $\mathcal{C}^{(\lambda)}$. 

After we compute $\mathcal{C}^{(\lambda)}$ for every $\lambda$, we use the value of $\mathcal{C}^{(\lambda)}_{(k-3n-1, C'_k)}$ to update $C''_k$ for every $k, \lambda$. 

Overall, the running time is $\OO(n^2/\sss + s^2 \sss n + g \sum_i |\mathcal{A}^{(\lambda)} - \mathcal{A}^{(\lambda)}|) = \OO(n^2/\sss + s^5 \sss^4 n g) = \OO(n^2/\sss + s^5 \sss^4 n^2 / t)$. 
\end{proof}

Next we show the following algorithm for the rest values of $k$ where $|W_k|$ is small. Recall that we assumed  \MinEqualityConv{} for length $n$ arrays has an $\OO(n^{1+\delta})$ time algorithm. 
\begin{claim}
\label{cl:min-equal-conv-light}
We can compute $C''_k$ for every $k$ where $|W_k| \le n / s$ in $\OO(\frac{n}{s} \cdot n^{1+\delta})$ time as long as $t\sqrt{s} = O(\sqrt{n})$.
\end{claim}
\begin{proof}
Let $I \subseteq [n]$ be a random subset of indices for which each index is kept in $I$ independently with probability $\frac{\sqrt{s}}{\sqrt{n}}$. Similarly let $J \subseteq [n]$ be such a random subset as well. With high probability, $|I|, |J| = O(\sqrt{sn})$.

In the sparse Min-Plus convolution between the two sparse arrays $A'_I$ and $B'_J$, we need to compute a length $n$ array $D$ where $D_k = \min_{i \in I, k - i \in J} (A'_i + B'_j)$. 

For every $k \in [n]$  and $i \in W_k$, the probability that $i \in I$ and $k - i \in J$ is $\frac{s}{n}$. Thus, for any particular $i \in W_k$, the probability that $i$ is the unique witness for $D_k$ in the sparse Min-Plus convolution between $A_I'$ and $B_J'$ is $\frac{s}{n} \cdot (1 - \frac{s}{n})^{|W_k| - 1}$, which is $\Theta(\frac{s}{n})$ if $|W_k| \le n/s$. Thus, if we keep sampling $I$ and $J$ for $\tO(\frac{n}{s})$ times, all indices in $W_k$ will be the unique witness for $D_k$ in at least one  time with high probability, as in  standard sampling techniques (see e.g. \cite{AlonGMN92, seidel1995}).

Suppose $i$ is indeed the unique witness for $D_k$, then we can find $i$ by repeatedly computing some instances of sparse Min-Plus convolutions. More specifically, in the $p$-th round, let $I^{(p)}$ be $I$ but only keeping the indices  whose $p$-th bit in the binary representation is $1$. Say the sparse Min-Plus convolution between $A'_{I^{(p)}}$ and $B'_J$ is $D^{(p)}$. Then if $D^{(p)}_k = D_k$, then we know the $p$-th bit of $i$ is $1$, and otherwise it is $0$. Thus, we can recover $i$ after $O(\log n)$ rounds. After we have $i$, we can use $A_i'' + B_{k-i}''$ to update $C''_k$. 

Therefore, it remains to show how to compute the sparse Min-Plus convolution between $A'_I$ and $B'_J$ for $|I|, |J| = O(\sqrt{sn})$.

Let $F: [t] \times [t] \rightarrow [n]$ be a random function (independent to the choice of $I, J$). We then create two arrays $X, Y$ each of length $O(n)$ as follows. Initially, all entries in $X$ and $Y$ are set to some distinct values out side of $[t] \times [t]$. 
For every $i \in I$ and $y \in [t]$, we set $X_{i + F(A'_i, y)}$ to $(A'_i, y)$; for every $j \in J$ and $x \in [t]$, we set $Y_{j + n - F(x, B'_j)}$ to $(x, B'_j)$. Suppose all entries are only set at most once. Then we compute the Min-Equality convolution $Z$ between $X$ and $Y$, where we compare two pairs $(x, y)$ and $(x', y')$ by comparing $x+y$ and $x' + y'$ and breaking ties arbitrarily. Then the sum of the two integers in the pair $Z_{k+n}$ equals $$\min_{\substack{(i, j, x, y) \in I \times J \times [t] \times [t] \\ i + F(A'_i, y) + j + n - F(x, B'_j) = k + n \\ (A'_i, y) = (x, B'_j)}} (A'_i + y) = \min_{\substack{(i, j) \in I \times J \\ i + j  = k}} (A'_i + B'_j).$$
Thus, computing a \MinEqualityConv{} instance gives the result of sparse Min-Plus convolution between $A'_I$ and $B'_J$. 

We then remove the assumption that each entry of $X$ and $Y$ is only set once by standard techniques. Consider a fixed entry $X_q$. For every $(x, y) \in t$, we set $X_q$ to $(x, y)$ if and only if $q-F(x, y) \in I$ and $A_{q - F(x, y)}' = x$. Since $F(x, y)$ is sampled from $[n]$ uniformly at random, the probability that we set $X_q$ to $(x, y)$ is at most $\frac{\left| \left\{i\in I: A'_i = x \right\}\right|}{n}$. Summing over all $x, y$, the expected number of times  that $X_q$ is set is $O(\frac{|I| t}{n}) = O(\frac{t\sqrt{s}}{\sqrt{n}}) = O(1)$ since $t \sqrt{s} = O(\sqrt{n})$. Since the values of $F(x, y)$ are independent for different $(x, y)$, by Chernoff bound, we conclude that $X_q$ is set only $O(\log n)$ times with high probability. Similarly, all indices in $Y$ are set only $O(\log n)$ times with high probability. Thus, we can create $O(\log n)$ arrays $X^{(a)}$, where $X^{(a)}_p$ equals the value of $X_p$ when we attempt to set it the $a$-th time. We can similarly create $O(\log n)$ arrays $Y^{(b)}$. Then it suffices to compute the \MinEqualityConv{} between $X^{(a)}$ and $Y^{(b)}$ for every $(a, b) \in [O(\log n)]^2$. 

Overall, the running time is $\tO(\frac{n}{s} \cdot n^{1+\delta})$ as long as $t\sqrt{s} = O(\sqrt{n})$, assuming   \MinEqualityConv{} for length $n$ arrays has an $\OO(n^{1+\delta})$ time algorithm.
\end{proof}

By Claim~\ref{cl:min-equal-conv-heavy} and Claim~\ref{cl:min-equal-conv-light}, we can compute $C''$ and thus $C$ in $\OO(n^2 / \sss + s^5 \sss^4 n^2 / t + \frac{n}{s} \cdot n^{1+\delta})$ time as long as $t\sqrt{s} = O(\sqrt{n})$. We can set $t = n^{\frac{10-5\delta}{21}}$, $s = n^{\frac{1+10\delta}{21}}$ and $\sss = n^{\frac{1-11\delta}{21}}$ to get the $\OO(n^{2 - \frac{1-11\delta}{21}})$ randomized running time. 
\end{proof}


Note that in order for the proof for Theorem~\ref{thm:min-equal-conv-under-conv} to work,  the more difficult BSG covering of Theorem~\ref{thm:bsg:gower:fast} that builds on Gower's proof~\cite{Gowers01} is necessary. If we instead use the simpler BSG covering of Theorem~\ref{thm:bsg:simple}, we will have an $s^{O(1)}n^{2.5} / t$ term from Claim~\ref{cl:min-equal-conv-heavy}, which cannot give subquadratic running time considering the $t\sqrt{s} = O(\sqrt{n})$ requirement in Claim~\ref{cl:min-equal-conv-light}. 