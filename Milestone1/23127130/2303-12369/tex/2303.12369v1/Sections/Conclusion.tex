\section{Conclusion}
\label{sec:Con}
In this work, we presented an Unbiased Multiple Instance Learning (UMIL) scheme that learns an unbiased anomaly classifier and a tailored representation for Weakly Supervised Video Anomaly Detection (WSVAD). Specifically, the existing MIL training scheme suffers from the context bias by only training on the confident set containing apparent normal/abnormal video snippets. We replace it with an unbiased one---seeking the invariant predictor that simultaneously distinguishes the normal/abnormal snippets in the confident set, and separates the two unsupervised clusters in the rest ambiguous snippets. Hence the context bias that fails among the ambiguous ones is removed. Our approach is empirically validated by the state-of-the-art performance and extensive ablations on standard WSVAD benchmarks. In future, we will seek additional prior beyond unsupervised clustering to discover the intrinsic differences between the ambiguous normal and abnormal snippets and adopt principled representation learning paradigm (\eg, disentanglement) to highlight the anomaly features.