\section{Introduction}
\label{sec:intro}
Video Anomaly Detection (VAD) aims to detect events among video sequences that deviate from expectation, which is widely applied in real-world tasks such as intelligent manufacturing~\cite{Huang2022Survey}, TAD surveillance~\cite{kamijo2000traffic,lv2021localizing} and public security~\cite{mohammadi2016angry,sultani2018real}. To learn such a detector, conventional fully-supervised VAD~\cite{acsintoae2022ubnormal} is impractical as the scattered but diverse anomalies require extremely expensive labeling cost. On the other hand, unsupervised VAD~\cite{zhao2011online,kratz2009anomaly,wu2010chaotic,li2013anomaly,antic2011video} by only learning on normal videos to detect open-set anomalies often triggers false alarms, as it is essentially ill-posed to define what is normal and abnormal by giving only normal videos without any prior knowledge. Hence, we are interested in a more practical setting: Weakly Supervised VAD (WSVAD)~\cite{zhong2019graph,li2022self}, where only video-level binary labels (\ie, normal \textit{vs.} abnormal) are available.

\begin{figure}[t]
    \centering
    \footnotesize
    \begin{subfigure}[t]{0.23\textwidth}
         \includegraphics[width=\textwidth]{figure/abstract_a.pdf}
         \caption{}
         \label{fig:1a}
    \end{subfigure}
    \begin{subfigure}[t]{0.23\textwidth} % the hidden unwanted image
         \includegraphics[width=\textwidth]{figure/abstract_b.pdf}
         \caption{}
         \label{fig:1b}   
    \end{subfigure}
    \vspace{-2mm}
	\caption{Two anomalies of Explosion and Vandalism are illustrated. Among each video sequence, we use red boxes to highlight the ground-truth anomaly regions as in the first row. The corresponding anomaly curves of an MIL-based model are depicted below. False alarms and real anomalies are linked to the curves with blue arrows and green arrows respectively. Best viewed in color.}
    \vspace{-6mm}
	\label{fig:abstract}
\end{figure}

In WSVAD, each video sequence is partitioned into multiple snippets. Hence, all the snippets are normal in a normal video, and at least one snippet contains the anomaly in an abnormal one. The goal of WSVAD is to train a snippet-level anomaly detector using video-level labels. The mainstream method is Multiple Instance Learning (MIL)~\cite{lv2021localizing,sultani2018real}---multiple instances refer to the snippets in each video, and learning is conducted by decreasing the predicted anomaly score for each snippet in a normal video, and increasing that only for  the snippet with the largest anomaly score in an abnormal video. For example, Figure~\ref{fig:1a} shows an abnormal video containing an explosion scene, and the detector is trained by MIL to increase the anomaly score for the most anomalous explosion snippet (green link).

However, MIL is easily biased towards the simplest context shortcut in a video. We observe in Figure~\ref{fig:1a} that the detector is biased to smoke, as the pre-explosion snippet with only smoke is also assigned a large anomaly score (blue link). This biased detector can trigger false alarms on smoke snippets without anomaly, \eg, a smoking chimney. Moreover, it could also fail in videos with multiple anomalies of different contexts. In Figure~\ref{fig:1b}, the video records two men vandalizing a car, where only the second one has substantial motions. We notice that the two snippets of them have large differences in the anomaly scores, and only the latter is predicted as an anomaly. This shows that the detector is biased to the drastic motion context while being less sensitive to the subtle vandalism behavior, which is the true anomaly.

\begin{figure}
    \centering
    \footnotesize
    \begin{subfigure}[t]{\linewidth}
         \includegraphics[width=\textwidth]{figure/motivation.pdf}
         \phantomcaption
         \label{fig:2a}
    \end{subfigure}
    \begin{subfigure}[t]{0\textwidth} % the hidden unwanted image
         \includegraphics[width=\textwidth]{example-image-b}
         \phantomcaption
         \label{fig:2b}   
    \end{subfigure}
    \begin{subfigure}[t]{0\textwidth} % the hidden unwanted image
         \includegraphics[width=\textwidth]{example-image-b}
         \phantomcaption
         \label{fig:2c}   
    \end{subfigure}
    \vspace*{-8mm}
    \caption{\textcolor{red}{Red}: Confident Set, \textcolor{iconblue}{Blue}: Ambiguous Set. {\scriptsize \CIRCLE}: Normal sample, $\blacktriangle$: Abnormal sample, \textcolor{gray}{Gray instances}: Failure cases. The red line denotes the classifier trained under MIL. The invariant classifier (black line) can be learned by combining confident snippets learning in MIL (red line) and the ambiguous snippets clustering (blue line). Best viewed in color.}
    \vspace{-6mm}
    \label{fig:2}
\end{figure}

The root of MIL's biased predictions lies in its training scheme with biased sample selection. As shown in Figure~\ref{fig:2}, the bottom-left cluster (denoted as the red ellipse) corresponds to the confident normal snippets, \eg, an empty crossroad or an old man standing in a room, which are either from normal videos as the ground truth or from abnormal videos but visually similar to the ground-truth ones. On the contrary, the top-right cluster denotes the confident abnormal ones, which not only contain the true anomaly features (\eg, explosion and vandalism) but also include the context features commonly appearing with anomaly under a context bias (\eg, smoke and motions). In MIL, the trained detector is dominated by the confident samples, corresponding to the top-right cluster with the abnormal representation and the bottom-left cluster with the normal representation. Hence the learned detector (red line) inevitably captures the context bias in the confident samples. Consequently, the biased detector generates ambiguous predictions on snippets with a different context bias (the red line mistakenly crossing the blue points), \eg, smoke but normal (industrial exhaust in Figure~\ref{fig:2a}), substantial motion but normal (equipment maintenance in Figure~\ref{fig:2b}), or subtle motion but abnormal (vandalizing the rear-view mirror in Figure~\ref{fig:2c}), leading to the aforementioned failure cases.

To this end, we aim to build an unbiased MIL detector by training with both the confident abnormal/normal and the ambiguous ones.
Specifically, at each UMIL training iteration, we divide the snippets into two sets using the current detector: 1) the confident set with abnormal and normal snippets and 2) the ambiguous set with the rest snippets, \eg, the two sets are enclosed with red circles and blue circles in Figure~\ref{fig:2}, respectively.
The ambiguous set is grouped into two unsupervised clusters (\eg, the two blue circles separated by the blue line) to discover the intrinsic difference between normal and abnormal snippets.
Then, we seek an invariant binary classifier between the two sets that separate the abnormal/normal in the confident set and the two clusters in the ambiguous one. The rationale of the proposed invariance pursuit is that the snippets in the ambiguous set must have a different context bias from the confident set, otherwise, they will be selected into the same set.
Therefore, given a different context but the same true anomaly, the invariant pursuit will turn to the true anomaly (\eg, the black line).

Overall, we term our approach as \textbf{Unbiased MIL (UMIL)}.
Our contributions are summarized below:
\begin{itemize}[leftmargin=+0.1in,itemsep=5pt,topsep=5pt,parsep=0pt]
    \item UMIL is a novel WSVAD method that learns an unbiased anomaly detector by pursuing the invariance across the confident and ambiguous snippets with different context biases.
    \item Thanks to the unbiased objective, UMIL is the first WSVAD method that combines feature fine-tuning and detector learning into an end-to-end training scheme. This leads to a more tailored feature representation for VAD.
    \item UMIL is equipped with a fine-grained video partitioning strategy for preserving the subtle anomaly information in video snippets.
    \item These contribute to the improved performance over the current state-of-the-art methods on UCF-Crime~\cite{sultani2018real} ( $1.4\%$ AUC) and TAD~\cite{lv2021localizing} ($3.3\%$ AUC) benchmarks. Note that UMIL brings more than 2\% AUC gain compared with the MIL baseline on both datasets, which justifies the effectiveness of UMIL.
\end{itemize}