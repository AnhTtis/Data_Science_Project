%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% This is a (brief) model paper using the achemso class
%% The document class accepts keyval options, which should include
%% the target journal and optionally the manuscript type. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[journal=jacsat,manuscript=suppinfo]{achemso}
%\documentclass{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Place any additional packages needed here.  Only include packages
%% which are essential, to avoid problems later. Do NOT use any
%% packages which require e-TeX (for example etoolbox): the e-TeX
%% extensions are not currently available on the ACS conversion
%% servers.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[version=3]{mhchem} % Formula subscripts using \ce{}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{subcaption}
\captionsetup[subfigure]{font={bf,small}, skip=1pt, singlelinecheck=false}
\usepackage{booktabs}       % professional-quality tables
\usepackage{multirow}
\usepackage{makecell}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% If issues arise when submitting your manuscript, you may want to
%% un-comment the next line.  This provides information on the
%% version of every file you have used.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%\listfiles

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Place any additional macros here.  Please use \newcommand* where
%% possible, and avoid layout-changing macros (which are not used
%% when typesetting).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand*\mycommand[1]{\texttt{\emph{#1}}}
\renewcommand{\thesection}{S\arabic{section}}
\renewcommand{\thepage}{S\arabic{page}} \renewcommand{\theequation}{S\arabic{equation}}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Meta-data block
%% ---------------
%% Each author should be given as a separate \author command.
%%
%% Corresponding authors should have an e-mail given after the author
%% name as an \email command. Phone and fax numbers can be given
%% using \phone and \fax, respectively; this information is optional.
%%
%% The affiliation of authors is given after the authors; each
%% \affiliation command applies to all preceding authors not already
%% assigned an affiliation.
%%
%% The affiliation takes an option argument for the short name.  This
%% will typically be something like "University of Somewhere".
%%
%% The \altaffiliation macro should be used for new address, etc.
%% On the other hand, \alsoaffiliation is used on a per author basis
%% when authors are associated with multiple institutions.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{Janghoon Ock}
% \altaffiliation{First Author}
\author{Tian Tian}
\author{John Kitchin}
\author{Zachary Ulissi}
\email{zulissi@andrew.cmu.edu}
\affiliation[CMU]
{Department of Chemical Engineering, Carnegie Mellon University, 5000 Forbes Avenue
Pittsburgh, USA}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The document title should be given as usual. Some journals require
%% a running title from the author: this should be supplied as an
%% optional argument to \title.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title[]
  {Beyond Independent Error Assumptions in Large GNN Atomistic Models}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Some journals require a list of abbreviations or keywords to be
%% supplied. These should be set up here, and will be printed after
%% the title and author information, if needed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \abbreviations{IR,NMR,UV}
\keywords{Graph Neural Networks, Machine Learning Potential, Uncertainty Quantification, Error Cancellation, \LaTeX}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The manuscript does not need to include \maketitle, which is
%% executed automatically.
\SectionNumbersOn
\begin{document}

\tableofcontents
%\clearpage
% \appendix
% \counterwithin{figure}{section}

\newpage

\section{Error cancellation in BEEF-vdW}
\label{sec:s1}
\begin{figure}[h] %[t!]
\begin{subfigure}{.9\textwidth}
  \centering
  \caption[]{\small All-swap}
  \includegraphics[width=.99\textwidth]{si/S1_prop.jpg}
  \label{fig:s1_a}
\end{subfigure}
\vskip\baselineskip
\begin{subfigure}{.9\textwidth}
  \centering
  \caption[]{\small Conf-swap}
  \includegraphics[width=.99\textwidth]{si/S1_cancel.jpg}
  \label{fig:s1_b}
\end{subfigure}
\caption{Example cases of subtraction of energy ensembles. (a) All-swap (system \textit{i}: \ce{N4Ni8Mo12}/\ce{CH}, system \textit{j}: \ce{Sc4In2}/\ce{CHO}). (b) Conf-swap (system \textit{i}, \textit{j}: \ce{Pd4Sb8}/\ce{CH} with different configurations).}
\label{fig:s1}
\end{figure}


The error in the difference between two predicted values (X, Y) depends on the propagation of errors from the individual predictions, which can either partially cancel each other out or amplify the error. The propagated error ($\sigma_{\text{X, Y}}$) is determined by the individual error ($\sigma_{\text{X}}, \sigma_{\text{Y}}$) and their covariance (cov(X,Y)). Cancellation of individual errors can occur during subtraction when two predictions are correlated and have positive covariance. However, if the predictions are independent or have negative covariance, the error in the difference will be larger than the individual errors. Specifically, random error propagation is the term used to describe the case where the covariance is zero, assuming independent errors.

\begin{equation}
    \centering
    \sigma_{\text{X, Y}}^2 =\sigma_{\text{X}}^2 + \sigma_{\text{Y}}^2 - 2 \text{cov(X,Y)}
    \label{error_prob}
\end{equation}


This principle is also applicable to the subtraction of energy ensembles derived from BEEF-vdW calculations. When the energy ensembles of two pairs of systems are dissimilar and exhibit no positive correlation or covariance, the error distribution will be amplified after subtraction, as demonstrated in Figure \ref{fig:s1_a}. The resulting standard deviation of the energy difference ensemble is 0.44 eV, which is larger than the error propagation under the assumption of independent errors ($\sqrt{0.68^2 + 0.19^2}=0.42$ eV). Conversely, systems with similar electronic structures will show a reduced error distribution after subtraction, owing to the positive correlation and covariance between their energy ensembles, as illustrated in Figure \ref{fig:s1_b}. In such cases, the individual ensembles cancel out to some extent, resulting in a reduced standard deviation of the energy difference ensemble, namely, 0.17 eV, compared to the independent error propagation ($\sqrt{0.18^2 + 0.25^2}=0.31$ eV).

\newpage
\section{Error distributions of GNN predictions}
\label{sec:s2}

\begin{figure}[h!]
\centering
  \includegraphics[width=.76\linewidth]{si/S2_error_dist.jpg}
\caption{Error distributions of energy difference predictions across subgroups and GNNs. The error distributions are obtained by calculating the residuals of GNN predictions ($\Delta \Delta E^{DFT} - \Delta \Delta E^{GNN}$). Narrowing down the subgroup results in a sharper error distribution for all GNNs. The error distribution becomes sharper across GNN models in the order of their accuracies: SchNet $<$ DimeNet++ $<$ PaiNN $<$ GemNet-OC $\simeq$ GemNet-OC-Large.}
\label{fig:s2}
\end{figure}

% For all GNNs, narrowing down the subgroup results in a sharper error distribution. Additionally, the error distribution becomes sharper across GNN models in the order of their accuracies: SchNet $\textless$ DimeNet++ $\textless$ PaiNN $\textless$ GemNet-OC $\simeq$ GemNet-OC-Large.


\newpage
\section{Contribution of ads-NN embeddings in energy prediction}
\label{sec:s3}

\begin{figure}[h]
\centering
  \includegraphics[width=.75\linewidth]{si/S3_ads-NN_E.jpg}
\caption{Distribution of ratio between the energy predicted by the adsorbate atoms and their nearest neighbors on the catalytic surface (ads-NN) and the adsorption energy predicted by all atom nodes in the system.}
\label{fig:s3}
\end{figure}


The contribution of a specific set of atoms ($S$) to the energy prediction is quantified as $\left\lvert \sum_{i \in S}{e_i} / E \right\rvert$. In this study, $S$ corresponds to the atoms in ads-NN, and $E$ is the adsorption energy ($\Delta E_{\text{ads}}$). Data points clustered around 1 on the horizontal axis indicate a closer match between the energy predicted by ads-NN atoms and the actual adsorption energy. Notably, despite their small fraction of the systems, the ads-NN fraction accounts for 0.8 to 1.2 times the actual adsorption energy in approximately 76\% of cases, underscoring their significant role in predicting adsorption energy.

\newpage
\section{Embedding similarity analysis using the RV coefficient}
\label{sec:s4}

\begin{subequations}
\label{eq:RV_Coeff}
\begin{align}
\text{RV}(H_{i}^{n \times d}, H_{j}^{m \times d}) &= \frac{\text{COV}(H_{i}^{n \times d}, H_{j}^{m \times d})}{\sqrt{\text{VAR}(H_{i}^{n \times d}) \text{VAR}(H_{j}^{m \times d})}} \label{eq:rv} \\
\text{COV}(H_{i}^{n \times d}, H_{j}^{m \times d}) &= \sum_{l=1}^m \sum_{k=l+1}^n \text{cov}^2(h^k_i, h^l_j) \label{eq:cov} \\
\text{VAR}(H_i^{n \times d}) &= \sum_{l=1}^n \sum_{k=l+1}^n \text{cov}^2(h^k_i, h^l_i) \label{eq:var} 
\end{align}
\end{subequations}

To compare the similarity between two embedding matrices with different dimensionality, we use the RV coefficient, a multivariate generalization of the squared Pearson correlation coefficient. This coefficient enables comparisons between matrices of different sizes, as each catalyst system contains a distinct number of atoms in ads-NN, and measures the similarity of embedding matrices on a scale from 0 to 1. The RV coefficient normalizes the correlation between embedding matrices by the variance of each respective matrix, as shown in Equation \ref{eq:rv}. It provides a measure of the proximity of two sets of matrices in the latent space, and we calculate the average RV coefficient for pairs within a subgroup for comparison with other subgroups.

\end{document}