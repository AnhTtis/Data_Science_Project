% !TEX root = ../main.tex

%--------------------------------------------------------
\IEEEraisesectionheading{\section{Introduction}
	\label{sec:Introduction}}
%--------------------------------------------------------

\IEEEPARstart{C}{amera} calibration is a fundamental and indispensable field in computer vision and it has a long research history \cite{duane1971close, maybank1992theory, weng1992camera, zhang2000flexible}, tracing back to around 60 years ago\cite{brown1966decentering}. The first step for many vision and robotics tasks is to calibrate the intrinsic (image sensor and distortion parameters) and/or extrinsic (rotation and translation) camera parameters, ranging from computational photography, and multi-view geometry, to 3D reconstruction. In terms of the task type, there are different techniques to calibrate the standard pinhole camera, fisheye lens camera, stereo camera, light field camera, event camera, and LiDAR-camera system, etc. Figure~\ref{fig:teaser} shows the popular calibration objectives, models, and extended applications in camera calibration.

\begin{figure}[!t]
  \centering
  \includegraphics[width=.45\textwidth]{figures/teaser.pdf}
  %\vspace{-20pt}
  \caption{Popular calibration objectives, models, and extended applications in camera calibration.}
  \label{fig:teaser}
  \vspace{-0.4cm}
\end{figure}

Traditional methods for camera calibration generally depend on hand-crafted features and model assumptions. These methods can be broadly divided into three categories. The most prevalent one involves using a known calibration target (\textit{e.g.}, a checkerboard) as it is deliberately moved in the 3D scene \cite{zhang1999flexible, gasparini2009plane, shah1994simple}. Then, the camera captures the target from different viewpoints and the checkerboard corners are detected for calculating the camera parameters. However, such a procedure requires cumbersome manual interactions and it cannot achieve automatic calibration ``in the wild''. To pursue better flexibility, the second category of camera calibration, \textit{i.e.}, the geometric-prior-based calibration has been largely studied \cite{barreto2005geometric, Carroll, Bukhari, Miguel}. To be specific, the geometric structures are leveraged to model the 3D-2D correspondence in the scene, such as lines and vanishing points. However, this type of method heavily relies on structured man-made scenes containing rich geometric priors, leading to poor performance when applied to general environments. The third category is self-calibration\cite{faugeras1992camera, fraser1997digital, hartley1994self}. Such a solution takes a sequence of images as inputs and estimates the camera parameters using multi-view geometry. The accuracy of self-calibration, however, is constrained by the limits of the feature detectors, which can be influenced by diverse lighting conditions and textures. 

Since there are many standard techniques for calibrating cameras in an industry/laboratory implementation\cite{opencv, matlab}, this process is usually ignored in recent development. However, calibrating single and wild images remains challenging, especially when images are collected from websites and unknown camera models. This challenge motivates the researchers to investigate a new paradigm.

Recently, deep learning has brought new inspirations to camera calibration and its applications. Learning-based methods achieve state-of-the-art performances on various tasks with higher efficiency. In particular, diverse deep neural networks (DNNs) have been developed, such as convolutional neural networks (CNNs), generative adversarial networks (GANs), PointNet, and vision transformers (ViTs), of which the high-level semantic features show more powerful representation capability compared with the hand-crafted features. Moreover, diverse learning strategies have been exploited to boost the geometric perception of neural networks. Learning-based methods offer a \textit{fully automatic} camera calibration solution, without manual interventions or calibration targets, which sets them apart from traditional methods. Furthermore, some of these methods achieve camera model-free and label-free calibration, showing promising and meaningful applications.

With the rapid increase in the number of learning-based camera calibration methods, it has become increasingly challenging to keep up with new advances. Consequently, there is an urgent need to analyze existing works and foster a community dedicated to this field. Previously, some surveys, \textit{e.g.}, \cite{salvi2002comparative, hughes2008review, fan2022wide} only focused on a specific task/camera in camera calibration or one type of approach. For instance, Salvi et al. \cite{salvi2002comparative} reviewed the traditional camera calibration methods in terms of the algorithms. Hughes et al. \cite{hughes2008review} provided a detailed review for calibrating fisheye cameras with traditional solutions. While Fan et al. \cite{fan2022wide} discussed both the traditional methods and deep learning methods, their survey only considers calibrating the wide-angle cameras. In addition, due to the few amount of reviewed learning-based methods (around 10 papers), the readers are difficult to picture the development trend of general camera calibration in Fan et al. \cite{fan2022wide}. 

In this paper, we provide a comprehensive and in-depth overview of recent advances in learning-based camera calibration, covering over 100 papers. We also discuss potential directions for further improvements and examine various types of cameras and targets. To facilitate future research on different topics, we categorize the current solutions according to calibration objectives and applications. In addition to fundamental parameters such as focal length, rotation, and translation, we also provide detailed reviews for correcting image distortion (radial distortion and rolling shutter distortion), estimating cross-view mapping, calibrating camera-LiDAR systems, and other applications. Such a trend follows the development of cameras and market demands for virtual reality, autonomous driving, neural rendering, etc. 

To our best knowledge, this is the first survey of the learning-based camera calibration and its extended applications, it has the following unique contributions. (1) Our work mainly follows recent advances in deep learning-based camera calibration. In-depth analysis and discussion in various aspects are offered, including publications, network architecture, loss functions, datasets, evaluation metrics, learning strategies, implementation platforms, etc. The detailed information of each literature is listed in Table \ref{table:methods}. (2) Despite the calibration algorithm, we comprehensively review the classical camera models and their extended models. In particular, we summarize the redesigned calibration objectives in deep learning since some traditional calibration objectives are verified to be hard to learn by neural networks. (3) We collect a dataset containing images and videos captured by different cameras in different environments, which can serve as a platform to evaluate the generalization of existing methods. (4) We discuss the open challenges of learning-based camera calibration and propose some future directions to provide guidance for further research in this field. (5) An open-source repository is created that provides a taxonomy of all reviewed works and benchmarks. The repository will be updated regularly in \url{https://github.com/KangLiao929/Awesome-Deep-Camera-Calibration}.

In the following sections, we discuss and analyze various aspects of learning-based camera calibration. The remainder of this paper is organized as follows. In Section~\ref{sec2}, we provide the concrete learning paradigms and learning strategies of the learning-based camera calibration. Subsequently, we introduce and discuss the specific methods based on the standard camera model, distortion model, cross-view model, and cross-sensor model in Section~\ref{sec:pure}, Section~\ref{sec:distortion}, Section~\ref{sec:projection}, and Section~\ref{sec:hybrid}, respectively (see Figure~\ref{fig:taxonomy}). The collected benchmark for calibration methods is depicted in Section~\ref{sec:evaluation}. Finally, we conclude the learning-based camera calibration and suggest the future directions of this community in Section~\ref{sec:Future}.

\vspace{-0.1cm}




