\section{Future Research Directions}
\label{sec:Future}
Camera calibration is a fundamental and challenging research topic. From the above technical reviews and limitation analysis, we can conclude there is still room for improvement with deep learning. From Section~\ref{sec:pure} to Section~\ref{sec:hybrid}, specific future efforts are discussed for each model. In this section, we suggest more general future research directions. 
\vspace{-0.3cm}
\subsection{Sequences}
Most studies focus on calibrating a single image. However, the rich spatiotemporal correlation among sequences that offers useful information on calibration has been overlooked. Learning the spatiotemporal correlation can provide the network with knowledge of structure from motion, which aligns with the principles of traditional calibrations. Directly applying existing calibration methods to the first frame and then propagating the calibrated objectives to subsequent frames is a straightforward approach. However, there are no methods that can perfectly calibrate every uncalibrated input, and the calibration error will persist throughout the entire sequence. Another solution is to calibrate all frames simultaneously. However, the calibration results of learning-based methods heavily rely on the semantic features of the image. As a result, unstable jitter effects may occur in calibrated sequences when the scenes change slightly. To this end, exploring video stabilization for sequence calibration is an interesting future direction.
\vspace{-0.3cm}
\subsection{Learning Target}
Due to the implicit relationship to image features, conventional calibration objectives can be challenging for neural networks to learn. To this end, some works have developed novel learning targets that replace conventional calibration objectives, providing learning-friendly representations for neural networks. Additionally, intermediate geometric representations have been presented to bridge the gap between image features and calibration objectives, such as reflective amplitude coefficient maps~\cite{Zheng}, rectification flow~\cite{BlindCor}, surface geometry~\cite{UprightNet}, and normal flow~\cite{DiffPoseNet}, etc. Looking ahead to the future development of this community, we believe there is still great potential for designing more explicit and reasonable learning targets for calibration objectives.
\vspace{-0.3cm}
\subsection{Pre-training}
Pre-training on ImageNet~\cite{ImageNet} has become a widely used strategy in deep learning. However, recent studies~\cite{STD} have shown that this approach provides less benefit for specific camera calibration tasks, such as wide-angle camera calibration. This is due to two main reasons: the data gap and the task gap. The ImageNet dataset only contains perspective images without distortions, making the initialized weights of neural networks irrelevant to distortion models. Furthermore, He et al.~\cite{he_rethinking} demonstrated that the task of ImageNet pre-training has limited benefits when the final task is more sensitive to localization. As a result, the performance of extrinsics estimation may be impacted by this task gap. Moreover, pre-training beyond a single image and a single modality, to our knowledge, has not been thoroughly investigated in the related field. We suggest that designing a customized pre-training strategy for learning-based camera calibration is an interesting area of research.
\vspace{-0.3cm}

\subsection{Implicit Unified Model}
Deep learning-based camera calibration methods use traditional parametric camera models, which lack the flexibility to fit complex situations. Non-parametric camera models relate each pixel to its corresponding 3D observation ray, overcoming parametric model limitations. However, they require strict calibration targets and are more complex for undistortion, projection, and unprojection. Deep learning methods show potential for calibration tasks, making non-parametric models worth revisiting and potentially replacing parametric models in the future. Moreover, they allow for implicit and unified calibration, fitting all camera types through pixel-level regression and avoiding explicit feature extraction and geometry solving. Researchers combined the advantages of implicit and unified representation with the Neural Radiance Field (NeRF) for reconstructing 3D structures and synthesizing novel views. Self-calibration NeRF~\cite{jeong2021self} has been proposed for generic cameras with arbitrary non-linear distortions, and end-to-end pipelines have been explored to learn depth and ego-motion without calibration targets. We believe the implicit and unified camera models could be used to optimize learning-based algorithms or integrated into downstream 3D vision tasks.
\vspace{-0.2cm}

\section{Conclusion}
In this paper, we present a comprehensive survey of the recent efforts in the area of deep learning-based camera calibration. Our survey covers conventional camera models, classified learning paradigms and learning strategies, detailed reviews of the state-of-the-art approach, a public benchmark, and future research directions. To exhibit the development process and link the connections between existing works, we provide a fine-grained taxonomy that categorizes literature by jointly considering camera models and applications. Moreover, the relationships, strengths, distinctions, and limitations are thoroughly discussed in each category. An open-source repository will keep updating regularly with new works and datasets. We hope that this survey could promote future research in this field. 
\vspace{-0.2cm}

\section*{Acknowledgment}
We thank Leidong Qin and Shangrong Yang at Beijing Jiaotong University for the partial dataset collection. We thank Jinlong Fan at the University of Sydney for the insightful discussion.
