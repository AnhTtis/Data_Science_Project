\section{Future Research Directions}
\label{sec:Future}
Camera calibration is a fundamental and challenging research topic. From the above technical reviews and limitation analysis, we can conclude there is still room for improvement with deep learning. From Section~\ref{sec:pure} to Section~\ref{sec:hybrid}, specific future efforts are discussed for each model. In this section, we suggest more general future research directions. 
\subsection{Sequences}
Bundle adjustment is a well-established technique central to Multi-View Stereo (MVS) and Simultaneous Localization and Mapping (SLAM) using multi-view constraints. Traditional bundle adjustment focuses on pose estimation, often under the assumption of pre-calibrated cameras, thus sidelining the nuances of camera parameter fine-tuning. While learning-based camera calibration has made significant strides, most methods are tailored for a single image. We have highlighted intrinsics calibration to underscore how sequence constraints bolster prediction accuracy. Notably, there is a burgeoning interest in integrating bundle adjustment into end-to-end deep learning pipelines. By transitioning from conventional keypoint extraction and matching to learning-based methods, recent works~\cite{tang2018ba, teed2018deepv2d,wei2020deepsfm,gu2023dro, DroidCalib, teed2021droid, teed2021tangent} propose differentiable bundle adjustment layers to refine pose, depth, and camera parameters together. Consequently, there is immense potential in further harnessing sequence constraints for accurate calibration. Current methods combine front-end matching with a back-end solver, which can be inefficient and unreliable in cases like fast motion. We suggest separating front-end and back-end refinements, using large models for features and introducing more trainable parameters in optimization.
\subsection{Learning Target}
Due to the implicit relationship to image features, conventional calibration objectives can be challenging for neural networks to learn. To this end, some works have developed novel learning targets that replace conventional calibration objectives, providing learning-friendly representations for neural networks. Additionally, intermediate geometric representations have been presented to bridge the gap between image features and calibration objectives, such as reflective amplitude coefficient maps~\cite{Zheng}, rectification flow~\cite{BlindCor}, surface geometry~\cite{UprightNet}, and normal flow~\cite{DiffPoseNet}, etc. Looking ahead to the future development of this community, we believe there is still great potential for designing more explicit and reasonable learning targets for calibration objectives.
\subsection{Pre-training}
Pre-training on ImageNet~\cite{ImageNet} has become a widely used strategy in deep learning. However, recent studies~\cite{STD} have shown that this approach provides less benefit for specific camera calibration tasks, such as wide-angle camera calibration. This is due to two main reasons: the data gap and the task gap. The ImageNet dataset only contains perspective images without distortions, making the initialized weights of networks irrelevant to distortion models. Furthermore, He et al.~\cite{he_rethinking} demonstrated that the task of ImageNet pre-training has limited benefits when the final task is more sensitive to localization. As a result, the performance of extrinsics estimation may be impacted by this task gap. Moreover, pre-training beyond a single image and a single modality, to our knowledge, has not been investigated in the related field. We suggest that designing a customized pre-training strategy for camera calibration is an interesting area of research.

\subsection{Implicit Unified Model}
Deep learning-based camera calibration methods use traditional parametric camera models, which lack the flexibility to fit complex situations. Non-parametric camera models relate each pixel to its corresponding 3D observation ray, overcoming parametric model limitations. However, they require strict calibration targets and are more complex for undistortion, projection, and unprojection. Deep learning methods show potential for calibration tasks, making non-parametric models worth revisiting and potentially replacing parametric models. Moreover, they allow for implicit and unified calibration, fitting all camera types through pixel-level regression and avoiding explicit feature extraction and geometry solving. Researchers combined the advantages of implicit and unified representation with the Neural Radiance Field (NeRF) for reconstructing 3D structures and synthesizing novel views. Self-calibration NeRF~\cite{jeong2021self} has been proposed for generic cameras with arbitrary non-linear distortions, and end-to-end pipelines have been explored to learn depth and ego-motion without calibration targets. We believe the implicit and unified camera models could be used to optimize learning-based algorithms or integrated into downstream 3D vision tasks.

\section{Conclusion}
In this paper, we present a comprehensive survey of the recent efforts in deep learning-based camera calibration. Our survey covers conventional camera models, classified learning paradigms and learning strategies, detailed reviews of the state-of-the-art approach, a public benchmark, and future research directions. To exhibit the development process and link the connections between existing works, we provide a fine-grained taxonomy that categorizes literature by jointly considering camera models and applications. Moreover, the relationships, strengths, distinctions, and limitations are thoroughly discussed in each category. An open-source repository will keep updating regularly with new works and datasets. We hope that this survey could promote future research in this field. 

\section*{Acknowledgment}
We thank Leidong Qin and Shangrong Yang at Beijing Jiaotong University for the partial dataset collection. We thank Jinlong Fan at the University of Sydney for the insightful discussion. We appreciate all reviewers for their insightful comments and invaluable suggestions.
