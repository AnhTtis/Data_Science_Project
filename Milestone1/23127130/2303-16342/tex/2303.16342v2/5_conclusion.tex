\section{Conclusion}
In summary, we introduce a self-supervised approach for learning to separate audio based on a language query, or a video. In the absence of object labels, we propose to extract latent captions to provide pseudo-language supervision. Furthermore, we introduce the novel tri-modal and audio-language alignment objectives that use the latent captions to improve the alignment of the audio, language and video modalities. By reducing the training need for object labels, our work opens up the possibility of large-scale pretraining on unlabeled videos with diverse visual concepts. 

\noindent 
\textbf{Acknowledgements}: This material is based upon work supported, in part, by DARPA under agreement number HR00112020054 and a gift from Adobe Research.