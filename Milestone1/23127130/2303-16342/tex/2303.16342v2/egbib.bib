@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@inproceedings{zhao2018sound,
  title={The sound of pixels},
  author={Zhao, Hang and Gan, Chuang and Rouditchenko, Andrew and Vondrick, Carl and McDermott, Josh and Torralba, Antonio},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={570--586},
  year={2018}
}

@InProceedings{Materzynska_2022_CVPR,
    author    = {Materzy\'nska, Joanna and Torralba, Antonio and Bau, David},
    title     = {Disentangling Visual and Written Concepts in CLIP},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16410-16419}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@inproceedings{gao2019co,
  title={Co-separating sounds of visual objects},
  author={Gao, Ruohan and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3879--3888},
  year={2019}
}

@misc{gal2022textual,
      doi = {10.48550/ARXIV.2208.01618},
      url = {https://arxiv.org/abs/2208.01618},
      author = {Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H. and Chechik, Gal and Cohen-Or, Daniel},
      title = {An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion},
      publisher = {arXiv},
      year = {2022},
      primaryClass={cs.CV}
}
@inproceedings{rahimi2022reading,
  title={Reading To Listen at the Cocktail Party: Multi-Modal Speech Separation},
  author={Rahimi, Akam and Afouras, Triantafyllos and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10493--10502},
  year={2022}
}
@inproceedings{chatterjee2021visual,
  title={Visual scene graphs for audio source separation},
  author={Chatterjee, Moitreya and Le Roux, Jonathan and Ahuja, Narendra and Cherian, Anoop},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1204--1213},
  year={2021}
}
@article{chen2019audio,
  title={Audio-visual embodied navigation},
  author={Chen, Changan and Jain, Unnat and Schissler, Carl and Gari, Sebastia Vicenc Amengual and Al-Halah, Ziad and Ithapu, Vamsi Krishna and Robinson, Philip and Grauman, Kristen},
  journal={environment},
  volume={97},
  pages={103},
  year={2019}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@inproceedings{wang2005musical,
  title={Musical audio stream separation by non-negative matrix factorization},
  author={Wang, Beiming and Plumbley, Mark D},
  booktitle={Proc. DMRN summer conf},
  pages={23--24},
  year={2005}
}
@inproceedings{fitzgerald2005shifted,
  title={Shifted non-negative matrix factorisation for sound source separation},
  author={Fitzgerald, Derry and Cranitch, Matt and Coyle, Eugene},
  booktitle={IEEE/SP 13th Workshop on Statistical Signal Processing, 2005},
  pages={1132--1137},
  year={2005},
  organization={IEEE}
}
@article{canadas2014percussive,
  title={Percussive/harmonic sound separation by non-negative matrix factorization with smoothness/sparseness constraints},
  author={Canadas-Quesada, Francisco Jesus and Vera-Candeas, Pedro and Ruiz-Reyes, Nicolas and Carabias-Orti, Julio and Cabanas-Molero, Pablo},
  journal={EURASIP Journal on Audio, Speech, and Music Processing},
  volume={2014},
  number={1},
  pages={1--17},
  year={2014},
  publisher={Springer}
}
@inproceedings{zellers2022merlot,
  title={Merlot reserve: Neural script knowledge through vision and language and sound},
  author={Zellers, Rowan and Lu, Jiasen and Lu, Ximing and Yu, Youngjae and Zhao, Yanpeng and Salehi, Mohammadreza and Kusupati, Aditya and Hessel, Jack and Farhadi, Ali and Choi, Yejin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16375--16387},
  year={2022}
}
@article{carreira2018short,
  title={A short note about kinetics-600},
  author={Carreira, Joao and Noland, Eric and Banki-Horvath, Andras and Hillier, Chloe and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1808.01340},
  year={2018}
}
@inproceedings{miech2019howto100m,
  title={Howto100m: Learning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2630--2640},
  year={2019}
}
@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}
@article{scao2021many,
  title={How many data points is a prompt worth?},
  author={Scao, Teven Le and Rush, Alexander M},
  journal={arXiv preprint arXiv:2103.08493},
  year={2021}
}
@article{tong2022videomae,
  title={Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training},
  author={Tong, Zhan and Song, Yibing and Wang, Jue and Wang, Limin},
  journal={arXiv preprint arXiv:2203.12602},
  year={2022}
}

@inproceedings{montesinos2020solos,
    author    = {Juan F. Montesinos and
                 Olga Slizovskaia and
                 Gloria Haro},
    title     = {Solos: A Dataset for Audio-Visual Music Analysis},
    booktitle = {22st {IEEE} International Workshop on Multimedia Signal Processing,
                {MMSP} 2020, Tampere, Finland, September 21-24, 2020},
    publisher = {IEEE},
    year      = {2020},
}

@inproceedings{gemmeke2017audio,
  title={Audio set: An ontology and human-labeled dataset for audio events},
  author={Gemmeke, Jort F and Ellis, Daniel PW and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle={2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={776--780},
  year={2017},
  organization={IEEE}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{spiertz2009source,
  title={Source-filter based clustering for monaural blind source separation},
  author={Spiertz, Martin and Gnann, Volker},
  booktitle={Proceedings of the 12th International Conference on Digital Audio Effects},
  volume={4},
  year={2009}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01618},
  year={2022}
}
@article{cohen2022my,
  title={" This is my unicorn, Fluffy": Personalizing frozen vision-language representations},
  author={Cohen, Niv and Gal, Rinon and Meirom, Eli A and Chechik, Gal and Atzmon, Yuval},
  journal={arXiv preprint arXiv:2204.01694},
  year={2022}
}

@inproceedings{wu2022wav2clip,
    title={Wav2CLIP: Learning Robust Audio Representations From CLIP},
    author={Wu, Ho-Hsiang and Seetharaman, Prem and Kumar, Kundan and Bello, Juan Pablo},
    booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    year={2022}
}

@article{scao2021many,
  title={How many data points is a prompt worth?},
  author={Scao, Teven Le and Rush, Alexander M},
  journal={arXiv preprint arXiv:2103.08493},
  year={2021}
}

@article{akbari2021vatt,
  title={Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text},
  author={Akbari, Hassan and Yuan, Liangzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={24206--24221},
  year={2021}
}

@inproceedings{seo2022end,
  title={End-to-end generative pretraining for multimodal video captioning},
  author={Seo, Paul Hongsuck and Nagrani, Arsha and Arnab, Anurag and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17959--17968},
  year={2022}
}

@inproceedings{raffel2014mir_eval,
  title={mir\_eval: A transparent implementation of common MIR metrics},
  author={Raffel, Colin and McFee, Brian and Humphrey, Eric J and Salamon, Justin and Nieto, Oriol and Liang, Dawen and Ellis, Daniel PW and Raffel, C Colin},
  booktitle={In Proceedings of the 15th International Society for Music Information Retrieval Conference, ISMIR},
  year={2014},
  organization={Citeseer}
}

@inproceedings{rix2001perceptual,
  title={Perceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs},
  author={Rix, Antony W and Beerends, John G and Hollier, Michael P and Hekstra, Andries P},
  booktitle={2001 IEEE international conference on acoustics, speech, and signal processing. Proceedings (Cat. No. 01CH37221)},
  volume={2},
  pages={749--752},
  year={2001},
  organization={IEEE}
}

@article{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@article{kilgour2022text,
  title={Text-Driven Separation of Arbitrary Sounds},
  author={Kilgour, Kevin and Gfeller, Beat and Huang, Qingqing and Jansen, Aren and Wisdom, Scott and Tagliasacchi, Marco},
  journal={arXiv preprint arXiv:2204.05738},
  year={2022}
}

@inproceedings{audiocaps,
  title={AudioCaps: Generating Captions for Audios in The Wild},
  author={Kim, Chris Dongjoo and Kim, Byeongchang and Lee, Hyunmin and Kim, Gunhee},
  booktitle={NAACL-HLT},
  year={2019}
}

@inproceedings{rao2022denseclip,
  title={Denseclip: Language-guided dense prediction with context-aware prompting},
  author={Rao, Yongming and Zhao, Wenliang and Chen, Guangyi and Tang, Yansong and Zhu, Zheng and Huang, Guan and Zhou, Jie and Lu, Jiwen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18082--18091},
  year={2022}
}

@article{zhou2021denseclip,
  title={Denseclip: Extract free dense labels from clip},
  author={Zhou, Chong and Loy, Chen Change and Dai, Bo},
  journal={arXiv preprint arXiv:2112.01071},
  year={2021}
}

@article{gu2021open,
  title={Open-vocabulary object detection via vision and language knowledge distillation},
  author={Gu, Xiuye and Lin, Tsung-Yi and Kuo, Weicheng and Cui, Yin},
  journal={arXiv preprint arXiv:2104.13921},
  year={2021}
}

@article{gal2022stylegan,
  title={Stylegan-nada: Clip-guided domain adaptation of image generators},
  author={Gal, Rinon and Patashnik, Or and Maron, Haggai and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={41},
  number={4},
  pages={1--13},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@article{tan2021look,
  title={Look at what iâ€™m doing: Self-supervised spatial grounding of narrations in instructional videos},
  author={Tan, Reuben and Plummer, Bryan and Saenko, Kate and Jin, Hailin and Russell, Bryan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14476--14487},
  year={2021}
}

@inproceedings{piergiovanni2020evolving,
  title={Evolving losses for unsupervised video representation learning},
  author={Piergiovanni, AJ and Angelova, Anelia and Ryoo, Michael S},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={133--142},
  year={2020}
}

@inproceedings{han2020memory,
  title={Memory-augmented dense predictive coding for video representation learning},
  author={Han, Tengda and Xie, Weidi and Zisserman, Andrew},
  booktitle={European conference on computer vision},
  pages={312--329},
  year={2020},
  organization={Springer}
}

@article{rouditchenko2020avlnet,
  title={Avlnet: Learning audio-visual language representations from instructional videos},
  author={Rouditchenko, Andrew and Boggust, Angie and Harwath, David and Chen, Brian and Joshi, Dhiraj and Thomas, Samuel and Audhkhasi, Kartik and Kuehne, Hilde and Panda, Rameswar and Feris, Rogerio and others},
  journal={arXiv preprint arXiv:2006.09199},
  year={2020}
}

@inproceedings{anne2017localizing,
  title={Localizing moments in video with natural language},
  author={Anne Hendricks, Lisa and Wang, Oliver and Shechtman, Eli and Sivic, Josef and Darrell, Trevor and Russell, Bryan},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5803--5812},
  year={2017}
}

@inproceedings{zhao2019sound,
  title={The sound of motions},
  author={Zhao, Hang and Gan, Chuang and Ma, Wei-Chiu and Torralba, Antonio},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1735--1744},
  year={2019}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{mccallum2022supervised,
  title={Supervised and Unsupervised Learning of Audio Representations for Music Understanding},
  author={McCallum, Matthew C and Korzeniowski, Filip and Oramas, Sergio and Gouyon, Fabien and Ehmann, Andreas F},
  journal={arXiv preprint arXiv:2210.03799},
  year={2022}
}

@inproceedings{gong2022ssast,
  title={Ssast: Self-supervised audio spectrogram transformer},
  author={Gong, Yuan and Lai, Cheng-I and Chung, Yu-An and Glass, James},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={10},
  pages={10699--10709},
  year={2022}
}

@inproceedings{wang2022long,
  title={Long-short temporal contrastive learning of video transformers},
  author={Wang, Jue and Bertasius, Gedas and Tran, Du and Torresani, Lorenzo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14010--14020},
  year={2022}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{ephrat2018looking,
  title={Looking to listen at the cocktail party: A speaker-independent audio-visual model for speech separation},
  author={Ephrat, Ariel and Mosseri, Inbar and Lang, Oran and Dekel, Tali and Wilson, Kevin and Hassidim, Avinatan and Freeman, William T and Rubinstein, Michael},
  journal={arXiv preprint arXiv:1804.03619},
  year={2018}
}

@article{feng2022sslnet,
  title={SSLNet: A network for cross-modal sound source localization in visual scenes},
  author={Feng, Fan and Ming, Yue and Hu, Nannan},
  journal={Neurocomputing},
  volume={500},
  pages={1052--1062},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{chowdhury2021listen,
  title={Listen to the pixels},
  author={Chowdhury, Sanjoy and Dasgupta, Subhrajyoti and Das, Sudip and Bhattacharya, Ujjwal},
  booktitle={2021 IEEE International Conference on Image Processing (ICIP)},
  pages={2568--2572},
  year={2021},
  organization={IEEE}
}

@inproceedings{hu2022mix,
  title={Mix and localize: Localizing sound sources in mixtures},
  author={Hu, Xixi and Chen, Ziyang and Owens, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10483--10492},
  year={2022}
}