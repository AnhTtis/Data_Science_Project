\section{Related work}

\noindent\textbf{Face Swapping.} The topic of face swapping has received significant attention in research and is highly relevant, as evidenced by the large body of works dedicated to it  \cite{nirkin2019fsgan,li2019faceshifter,perov2020deepfacelab,chen2020simswap,zhu2021one,xu2022high}. %xu2022region
% there are several key differences worth noticing. First of all, their objectives are different. 
However, it presents inherent and important differences compared to face anonymization/de-identification. 
Face swapping aims to change the original identity to a specified target identity, whereas face anonymization shall not rely on actual identities, as it would otherwise compromise both target and source individuals. 
Moreover, the two domains consider different performance indicators and evaluation metrics. Anonymization aims at providing privacy-preserving guarantees, including face anonymization rate and non-re-identifiability \cite{gross2005integrating,liu2021dp,croft2021obfuscation,tolle2022content}, which implies additional mechanisms compared to the face-swapping methods that prioritize preserving facial attributes while reckoning the visual quality of the injected identity \cite{nirkin2019fsgan,xu2022high}.

\noindent\textbf{Face Anonymization.} Although traditional methods such as blacking out, pixelation, and Gaussian blur \cite{boyle2000effects,gross2006model,gross2009face,neustaedter2006blur,newton2005preserving} are effective in removing privacy-sensitive information, they drastically alter the original data distribution, resulting in a significant loss in \textit{utility}. In other words, these methods generate anonymized images that are not suitable for downstream tasks such as gaze estimation \cite{kellnhofer2019gaze360,Zhang2020ETHXGaze}, head-pose prediction \cite{zhou2020whenet,hempel20226d}, facial-landmarks regression \cite{deng2020retinaface,dlib09}, and expression estimation \cite{wen2021distract,savchenko2022video} due to the lack of necessary visual information.

A significant amount of research on face anonymization approaches the problem as an image inpainting task, where the face region is first erased and then replaced with another. 
Early methods \cite{gross2005integrating,padilla2015visual} use a database of real faces to aggregate the new identity, while more recent methods \cite{hukkelaas2019deepprivacy,maximov2020ciagan,liu2021dp} use generative models to synthesize fake identities based on the learned distribution. DeepPrivacy \cite{hukkelaas2019deepprivacy} is one of the pioneering works in this field, which reconstructs the missing face by taking the masked face and facial landmarks as inputs. However, the reconstructed face distribution suffers from bias as it is solely conditioned on its training data, leading to a tendency to generate smiling, young-looking faces. 
% regardless of the original facial expression and age.  
CIAGAN \cite{maximov2020ciagan} is another work that uses facial masks and landmarks to generate new faces. % It uses a generative-adversarial network (GAN) \cite{goodfellow2020generative} conditioned on a one-hot identity vector. 
% Since the generated face identity depends on the encoding of the fixed dimension one-hot vector, it does not provide guidance for the selection of the one-hot vector to achieve optimal anonymization effect. 
% it does not guide optimal anonymization vector selection. In addition, 
However, it tends to generate faces with duplicated identities due to the length limitation of the one-hot vector.
%, which reveals the identity of the training dataset and makes the resulting image suspicious. It also suffers from low visual quality and large artifacts. 
RePaint \cite{lugmayr2022repaint}, a recent method based on diffusion models, generates photo-realistic faces with large facial variances, but it fails to maintain the utility of the faces and is sensitive to input distributions.
%, which may result in highly distorted faces due to distribution shifts. Additionally, it is computationally prohibitive because it involves a large number of forward passes of diffusion models.

\input{figures/fig-pipeline}

Some methods \cite{gu2020password,cao2021personalized,proencca2021uu} have focused on making the anonymization process reversible, such as \textit{Password}~\cite{gu2020password} and \textit{RiDDLE}~\cite{li2023riddle}, which generate anonymized faces conditioned on a password that can be used to de-anonymize them. While such a feature can be desirable in some scenarios, it violates privacy regulations like GDPR~\cite{voigt2017eu} that protects \textit{pseudonymous} data (data that has been de-identified from the data's subject but can be re-identified as needed by the use of additional information). In this work, we propose to anonymize faces in an irreversible manner.
Other solutions \cite{li2019anonymousnet,chen2021perceptual,li2021differentially,liu2021dp} incorporate notions of differential privacy \cite{duchi2013local,dwork2014algorithmic,abadi2016deep} by adding adequately-calibrated random noise either at training or inference time, ensuring privacy levels linked to their parameter $\epsilon$. Or directly optimize in the latent space of StyleGAN \cite{barattin2023attribute}. However, they often neglect utility preservation (\eg, they edit image background and utility attributes) and require complex post-processing, making them not readily applicable to anonymization tasks.
% , \ie, also editing residual (\eg, image background) and utility attributes. They thus require non-trivial  and are not readily applicable to anonymization tasks.

% anonymization they require a source image to provide the new identity for each target image, which will cause privacy leakage for the ID provider. Our method does not need any source images to perform anonymization.


% (emphasize the difference between face swapping)

% \noindent\textbf{Face verification.} 

% \noindent\textbf{Utility tasks (related to face images).} 