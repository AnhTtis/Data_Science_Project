


% % resolve indexing issue
% \makeatletter
% \def\mysequence#1{\expandafter\@mysequence\csname c@#1\endcsname}
% \def\@mysequence#1{%
%   \ifcase#1\or -\or - \or -\or -\or -\or A\or B\or C\or D\or E\or F\or G\or H\else\@ctrerr\fi}
% \makeatother
% \renewcommand\thesection{\mysequence{section}}


\section*{Summary}
In this supplementary material, we provide more implementation details of our framework \textit{Disguise} (Section \ref{sec:implementation}), and additional qualitative comparison with other methods on images in the wild, including images in medical settings and images with multiple faces (Section \ref{sec:qualitative}). In addition, we also present quantitative evaluation and corresponding analyses of our solution, demonstrating the impact of different ID extraction models and effect of noise in ID obfuscation (Section \ref{sec:quantitative}).


\section{Further Implementation Details}
\label{sec:implementation}

\subsection{Training}

As mentioned in Subsection \refwithdefault{sec:protocol}{4.1}, while our solution is end-to-end differentiable, we observe better optima when splitting the training regimen into two phases: (1) we first pre-train the face-swapper $g_{\text{fs}}$ according to \cite{chen2020simswap} for 1M iterations; (2) then we fine-tune it together with utility module and ID transformer for another 100k iterations. This is illustrated in Figure \ref{fig:training_phases}.

% \bpnote{opt. present additional SimSwap training losses.}

\subsection{Evaluation}

For the de-correlation evaluation presented in \refwithdefault{sec:exp-privacy}{4.2}, the MLP attacker networks consist of three layers of feature sizes [512, 2048, 1024, 512], tasked to reconstruct the original identity embedding from the obfuscated one extracted from the edited image. 
We train one attacker specific to each obfuscation method (CIAGAN \cite{maximov2020ciagan}, DeepPrivacy \cite{hukkelaas2019deepprivacy}, ours, \etc). 
We use Adam optimizer with a learning rate of $1e-3$ and a total epoch of 100 epochs. We trained the decoders on CelebA-HQ and evaluated them on LFW.

% \bpnote{opt. provide training loss detail for  HRNetv2-W18 applied to landmark detection.}

% \zgnote{We train a decoder consisting of three layers of MLP with feature sizes [512, 2048, 1024, 512] to reconstruct the original embedding from the obfuscated embedding, rather than from the ground truth image. This is because the identity embedding lacks facial pose, expression, and background information, making it challenging to reconstruct the ground truth image from the obfuscated embedding alone. We use Adam optimizer with a learning rate of $1e-3$ and a total epoch of 100 epochs. We trained the decoders on CelebA-HQ and evaluated them on LFW.}

\section{More Qualitative Evaluation}
\label{sec:qualitative}
\subsection{Comparison with Other Methods}



In this section, we provide additional qualitative results highlighting the quality of privacy and utility preservation provided by the proposed method, compared to the most popular face anonymization methods, such as blurring \cite{frome2009large}, pixelation \cite{zhou2020personal}, Password \cite{gu2020password}, CIAGAN \cite{maximov2020ciagan}, DeepPrivacy \cite{hukkelaas2019deepprivacy}, and Repaint \cite{lugmayr2022repaint}.

\noindent\textbf{More qualitative comparisons on LFW.} \ref{fig:sup_qualities} complements Figure \refwithdefault{fig:qualities}{4} with more comparisons. Simpler methods, such as blurring and pixelation, provide effective anonymization, but the resulting facial images cannot be leveraged for downstream tasks. 
For the other deep-learning-based solutions, the observations are similar to those made \wrt Figure \refwithdefault{fig:qualities}{4}. 
Password \cite{gu2020password} fails at removing identifying features; whereas RePaint \cite{lugmayr2022repaint} has difficulties hallucinating entire new faces, resulting in images too distorted to be useful. CIAGAN \cite{maximov2020ciagan} and DeepPrivacy \cite{hukkelaas2019deepprivacy} provide strong anonymization and pseudo-realistic results, but they still suffer from artifacts that can also impair usability (in terms of saliency and utility attributes).
Our method sometimes struggles with out-of-distribution images (\eg, facial images with lighting conditions hiding key features) causing some utility loss, but it overall yields realistic images sharing utility attributes with the original ones while successfully altering identifying traits (nose width, thickness of the eyebrows, shape of cheeks, \etc).



\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/pipeline_cropped3.pdf}
    % \vspace{-8pt}
    \caption{Detailed training pipeline of \textit{Disguise}, in supplement to Figure \refwithdefault{fig:architecure}{2}. The proposed solution is end-to-end differentiable. However, in practice, to guide the optimization process, we train the network in two phases. Firstly, we train the face-swapping network (the branch marked in dark green); then in the second phase, we add the ID obfuscation branch (marked in light green) and the utility-guaranteeing module (the branch on top) to finetune the whole network.}
    \label{fig:training_phases}
    % \vspace{-7pt}
\end{figure*}

\input{figures/fig-qualities-sup}
\input{figures/fig-qualities-sup3}

\noindent\textbf{Sensitive images taken in medical settings.} Closer to the target use-cases discussed in the Introduction, we also share additional results on sensitive images taken in medical settings (the images were taken, edited, and shared with the consent of the depicted volunteers), \cf Figure \ref{fig:sup_qualities_medical}. Once again, we note the superiority of the proposed method in terms of image quality and usability. For example, the gaze and facial expression are better preserved, and so are elements occluding the faces (oxygen mask, glasses). If the obfuscated data were to be used for training algorithms on face-focused tasks for medical environments, preserving such challenging non-facial features would be important to ensure the robustness of these methods after deployment. 

\noindent\textbf{Group photos with multiple faces.} Figure \ref{fig:sup_qualities_group} shows some results when applying the evaluated methods to group images, again highlighting the performance of our method compared to the state-of-the-art. \Eg, while DeepPrivacy is able to generate high-quality \textit{fake} faces, it does not preserve key utility attributes as well as our method (\eg, changing gaze directions or facial expressions, adding glasses, \etc). 

Note that for such group images or images showing more than just a face (\cf Figure \ref{fig:sup_qualities_group}), we first apply InsightFace \cite{noauthor_insightface_2022,deng2019arcface}, a face detection model, to obtain the region for each face present in the image; then we apply the de-identification methods to each corresponding crop separately; before merging everything back into the obfuscated image.


\subsection{Noise-based Tampering of ID Vectors}
\label{sec:sup_noise}

Other methods \cite{li2019anonymousnet,liu2021dp,li2021differentially,wen2022identitydp}, have been recently proposed that also tackle de-identification of facial images by extracting identity features from the target data, altering it, and decoding it back into a similar but obfuscated image.
While we could not satisfyingly reproduce their results (no implementation has been released), we could approximate their solution using our own framework.
Indeed, most of these methods can be described as a subset of our modular solution, \ie, minus our main contributions. 
This is especially true for DP-Image \cite{liu2021dp} (not peer-reviewed yet) and IdentityDP \cite{wen2022identitydp} (published in August, the \nth{28}, 2022), which use an image encoder-decoder combined with an ID extractor \cite{deng2019arcface} and ID/image feature mixer, similar to ours. 
However, they do not provide our additional guarantees in terms of disentanglement of the facial attributes and preservation of the utility ones by using mixture-of-experts supervision. 
More importantly, they obfuscate the extracted ID vector (before injecting it with the residual image features and decoding it back into an image) only by adding Laplace noise to them. They do not leverage additional transformations in the ID latent space to ensure optimal de-identification, such as our MLP and VED neural functions.

To highlight the impact of our proposed ID transformation functions and indirectly compare to these other solutions, we direct the readers to Figure \ref{fig:sup_qualinoise}.
For each original image, we display the results obtained by transforming the extracted ID features either after only adding Laplace-based noise to them (first row); after applying our proposed $\psi^\epsilon_{\text{mlp}}$, \ie, adding  Laplace noise and then passing the vector to our MLP (\cf Subsection \refwithdefault{sec:solution}{3.2}) 
optimized to ensure de-identification (second row); or after passing the vector to our VED $\psi^\epsilon_{\text{ved}}$, which also applies $\epsilon$-controlled noise to the data in its own latent space (third row).
For each solution, we provide several results with different privacy budgets ($\beta$ parameter, encompassing $\epsilon$).

We observe that applying only $\epsilon$-controlled noise to the ID vector results in images barely obfuscated (\eg, same nose/cheek/eyebrow shapes) compared to additionally using our proposed neural functions, for the same privacy budgets $\beta$. Furthermore, our VED-based solution provides better continuity in the obfuscated results \wrt $\beta$ compared to the other two variants. Such continuity makes choosing an adequate privacy budget much more intuitive and straightforward for users.


\section{Further Quantitative Evaluation}
\label{sec:quantitative}
\input{figures/fig-hist-roc-all}

\subsection{Impact of ID Extraction Models}

Complementing Tables \refwithdefault{tab:compare-deid}{1}, \refwithdefault{tab:compare-utility}{2}, and 
\refwithdefault{tab:compare-invertibility}{4} and the corresponding analysis shared in the main paper, we further evaluate the impact that the usage of different ID extraction method(s) can have on the overall obfuscation pipeline.
Other existing solutions also leverage out-of-the-box identification networks (ArcFace \cite{deng2019arcface} is the most common), but they do not provide any analysis on the possible bias that these pretrained methods may have and how such bias may impact the de-identification process, \eg, by improperly disentangling some facial features.

\input{tables/tab-supp-invertibility.tex}
\input{tables/tab-supp-utility.tex}
\input{tables/tab-supp-direct-noise.tex}

We provide such an analysis in Tables \ref{tab:supp-invertibility} and \ref{tab:supp-utility}. Since our method can leverage multiple ID extractors, we compare various versions of our solutions, \ie, either relying on ArcFace \cite{deng2019arcface}, AdaFace \cite{kim2022adaface}, SphereFace \cite{Liu_2017_CVPR}, or a combination of these three methods (note that for fairness, we do not use SphereFace to evaluate the methods using SphereFace as ID extractor).

Table \ref{tab:supp-invertibility} shows that combining multiple ID extractors can achieve better de-identification and non-invertibility. This is especially visible for the pipeline versions relying on AdaFace. By itself, it seems like this solution suffers from some bias or lack of performance (at least compared to the adversarial FaceNet \cite{schroff2015facenet} or SphereFace \cite{Liu_2017_CVPR} used for re-identification) and probably misses some biometric features, causing higher re-identification rate of the obfuscated images compared to versions relying on other ID extractors. But once combined with another identification method, \eg, ArcFace \cite{deng2019arcface}, the re-identification rate drops.
More significantly even, combining multiple identity extractors makes our solution much more robust to inversion attacks (\cf last two columns in Table \ref{tab:supp-invertibility}), as expected from mixture-of-experts solutions.

However, we still observe a trade-off between privacy preservation and utility preservation. As shown in Table \ref{tab:supp-utility}, our solutions relying on multiple ID extractors tend to have a slightly bigger impact on utility features, causing some accuracy drop \wrt the selected downstream tasks. Navigating this trade-off and coming up with a solution that better disentangles identity and utility features (given that they do not overlap) remains an open problem, though we believe \textit{Disguise} to be a significant step forward (\cf comparison to state-of-the-art in the main paper and in this document).

\subsection{Noise-based Tampering of ID Vectors}

Figure \ref{fig:hist-all} extends the analysis presented in Figure \refwithdefault{fig:hist}{6}, highlighting the superiority of our VED-based obfuscation scheme compared to the other MLP-based proposed solution, as well as their superiority compared to prior art. 


As a reminder, we define $\alpha$ and $\beta$ as inversely proportional to $\epsilon$, \cf $\alpha = \frac{\Delta\psi}{\epsilon}$ and $\beta = {\frac{\Delta\psi_{\text{mlp}}}{\epsilon}}$.
As a measure of privacy budget, the higher $\epsilon$ is fixed (\ie, the lower  $\alpha$ or $\beta$), the higher the privacy loss, \cf $\log{\mathrm{P}(\widetilde{z}|z)} - \log{\mathrm{P}(\widetilde{z}|z') \leq \epsilon}$ according to the formal definition in Subsection \refwithdefault{sec:formalism}{3.1}.
Local differential privacy (LDP) guarantees that an adversary observing $\widetilde{z}$ cannot determine with some degree of confidence if it comes from $z$ or $z'$. \Eg, $\epsilon = 0$ would mean zero confidence in linking a masked ID to a specific input one, as only noise would be transferred (\cf Laplacian noise with $\alpha = \frac{\Delta\psi}{\epsilon} = \infty$). 
To choose $\epsilon$ (and thus $\alpha$) adequately based on privacy budget, one should first estimate the sensitivity $\Delta$ of the processing function. Following standard practice \cite{liu2021dp,wen2022identitydp}, we measure the sensitivity of ours empirically: \eg, over LFW dataset, we obtain $\Delta\psi_{\text{ved}} = \sup_{z, z'}\left\|\psi(z) - \psi(z')\right\|_1 = 33.92$ (\eg, hence fixing $\alpha = 2$ means opting for a relative privacy budget equals to $\epsilon = 67.84$). 

We also complement the qualitative analysis provided in Subsection \ref{sec:sup_noise} with Table \ref{tab:supp_noise}, showing the de-identification and non-invertibility performance of the ID transformation scheme which consists of applying only $\epsilon$-controlled Laplace noise to the features (without any additional neural functions to further obfuscate the vector). This table should be compared to similar Table \refwithdefault{tab:both-noise}{3} in the main paper, which showcases our ID transformation schemes (with MLP/VED) on the same metrics.

As discussed in the aforementioned section, the proposed MLP and VED greatly improve identity obfuscation, compared to only applying noise to the features. However, their continuous property makes them more prone to inversion attacks, for similar privacy budgets (\eg, for small noise values, they may be mapping different inputs to the same fake identity). Nevertheless, we believe that our proposed VED-based solution provides the best trade-off between maximal de-identification and non-invertibility, as shown in the table.


\input{figures/fig-qualities-medical-supp.tex}
\input{figures/fig-qualities-group.tex}