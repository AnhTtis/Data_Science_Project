@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}
@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}
@article{jiang2017exploiting,
  title={Exploiting feature and class relationships in video categorization with regularized deep neural networks},
  author={Jiang, Yu-Gang and Wu, Zuxuan and Wang, Jun and Xue, Xiangyang and Chang, Shih-Fu},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={2},
  pages={352--364},
  year={2017},
  publisher={IEEE}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{graves2013speech,
  title={Speech recognition with deep recurrent neural networks},
  author={Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
  booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
  pages={6645--6649},
  year={2013},
  organization={Ieee}
}
@article{hinton2012improving,
  title={Improving neural networks by preventing co-adaptation of feature detectors},
  author={Hinton, Geoffrey E and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R},
  journal={arXiv preprint arXiv:1207.0580},
  year={2012}
}
@article{denil2013predicting,
  title={Predicting parameters in deep learning},
  author={Denil, Misha and Shakibi, Babak and Dinh, Laurent and Ranzato, Marc'Aurelio and De Freitas, Nando},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}
@article{lebedev2014speeding,
  title={Speeding-up convolutional neural networks using fine-tuned cp-decomposition},
  author={Lebedev, Vadim and Ganin, Yaroslav and Rakhuba, Maksim and Oseledets, Ivan and Lempitsky, Victor},
  journal={arXiv preprint arXiv:1412.6553},
  year={2014}
}

@article{kim2015compression,
  title={Compression of deep convolutional neural networks for fast and low power mobile applications},
  author={Kim, Yong-Deok and Park, Eunhyeok and Yoo, Sungjoo and Choi, Taelim and Yang, Lu and Shin, Dongjun},
  journal={arXiv preprint arXiv:1511.06530},
  year={2015}
}
@article{novikov2015tensorizing,
  title={Tensorizing neural networks},
  author={Novikov, Alexander and Podoprikhin, Dmitrii and Osokin, Anton and Vetrov, Dmitry P},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}


@inproceedings{lane2015early,
  title={An early resource characterization of deep learning on wearables, smartphones and internet-of-things devices},
  author={Lane, Nicholas D and Bhattacharya, Sourav and Georgiev, Petko and Forlivesi, Claudio and Kawsar, Fahim},
  booktitle={Proceedings of the 2015 international workshop on internet of things towards applications},
  pages={7--12},
  year={2015}
}

@article{hitchcock1927expression,
  title={The expression of a tensor or a polyadic as a sum of products},
  author={Hitchcock, Frank L},
  journal={Journal of Mathematics and Physics},
  volume={6},
  number={1-4},
  pages={164--189},
  year={1927},
  publisher={Wiley Online Library}
}

@article{tucker1963implications,
  title={Implications of factor analysis of three-way matrices for measurement of change},
  author={Tucker, Ledyard R},
  journal={Problems in Measuring Change},
  volume={15},
  pages={122--137},
  year={1963},
  publisher={University of Wisconsin Press Madison}
}


@article{jaderberg2014speeding,
  title={Speeding up convolutional neural networks with low rank expansions},
  author={Jaderberg, Max and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1405.3866},
  year={2014}
}

@inproceedings{wang2018wide,
  title={Wide compression: Tensor ring nets},
  author={Wang, Wenqi and Sun, Yifan and Eriksson, Brian and Wang, Wenlin and Aggarwal, Vaneet},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={9329--9338},
  year={2018}
}
@inproceedings{yin2021towards,
  title={Towards efficient tensor decomposition-based dnn model compression with optimization framework},
  author={Yin, Miao and Sui, Yang and Liao, Siyu and Yuan, Bo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10674--10683},
  year={2021}
}
@inproceedings{yin2022batude,
  title={Batude: Budget-aware neural network compression based on tucker decomposition},
  author={Yin, Miao and Phan, Huy and Zang, Xiao and Liao, Siyu and Yuan, Bo},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2022}
}

@article{ruder2016overview,
  title={An overview of gradient descent optimization algorithms},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1609.04747},
  year={2016}
}

@article{dauphin2015equilibrated,
  title={Equilibrated adaptive learning rates for non-convex optimization},
  author={Dauphin, Yann and De Vries, Harm and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}
@article{zhang2015accelerating,
  title={Accelerating very deep convolutional networks for classification and detection},
  author={Zhang, Xiangyu and Zou, Jianhua and He, Kaiming and Sun, Jian},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={38},
  number={10},
  pages={1943--1955},
  year={2015},
  publisher={IEEE}
}

@inproceedings{haastad1989tensor,
  title={Tensor rank is NP-complete},
  author={H{\aa}stad, Johan},
  booktitle={International Colloquium on Automata, Languages, and Programming},
  pages={451--460},
  year={1989},
  organization={Springer}
}
@inproceedings{allen2012sparse,
  title={Sparse higher-order principal components analysis},
  author={Allen, Genevera},
  booktitle={Artificial Intelligence and Statistics},
  pages={27--36},
  year={2012},
  organization={PMLR}
}

@article{de2000multilinear,
  title={A multilinear singular value decomposition},
  author={De Lathauwer, Lieven and De Moor, Bart and Vandewalle, Joos},
  journal={SIAM journal on Matrix Analysis and Applications},
  volume={21},
  number={4},
  pages={1253--1278},
  year={2000},
  publisher={SIAM}
}
@article{de2000best,
  title={On the best rank-1 and rank-(r 1, r 2,..., rn) approximation of higher-order tensors},
  author={De Lathauwer, Lieven and De Moor, Bart and Vandewalle, Joos},
  journal={SIAM journal on Matrix Analysis and Applications},
  volume={21},
  number={4},
  pages={1324--1342},
  year={2000},
  publisher={SIAM}
}

@article{tucker1966some,
  title={Some mathematical notes on three-mode factor analysis},
  author={Tucker, Ledyard R},
  journal={Psychometrika},
  volume={31},
  number={3},
  pages={279--311},
  year={1966},
  publisher={Springer}
}

@article{de2008decompositions,
  title={Decompositions of a higher-order tensor in block terms—Part II: Definitions and uniqueness},
  author={De Lathauwer, Lieven},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={30},
  number={3},
  pages={1033--1066},
  year={2008},
  publisher={SIAM}
}
@article{ye2020block,
  title={Block-term tensor neural networks},
  author={Ye, Jinmian and Li, Guangxi and Chen, Di and Yang, Haiqin and Zhe, Shandian and Xu, Zenglin},
  journal={Neural Networks},
  volume={130},
  pages={11--21},
  year={2020},
  publisher={Elsevier}
}
@article{grasedyck2010hierarchical,
  title={Hierarchical singular value decomposition of tensors},
  author={Grasedyck, Lars},
  journal={SIAM journal on matrix analysis and applications},
  volume={31},
  number={4},
  pages={2029--2054},
  year={2010},
  publisher={SIAM}
}
@article{grasedyck2011introduction,
  title={An introduction to hierarchical (H-) rank and TT-rank of tensors with examples},
  author={Grasedyck, Lars and Hackbusch, Wolfgang},
  journal={Computational methods in applied mathematics},
  volume={11},
  number={3},
  pages={291--304},
  year={2011},
  publisher={De Gruyter}
}
@article{wu2020hybrid,
  title={Hybrid tensor decomposition in neural network compression},
  author={Wu, Bijiao and Wang, Dingheng and Zhao, Guangshe and Deng, Lei and Li, Guoqi},
  journal={Neural Networks},
  volume={132},
  pages={309--320},
  year={2020},
  publisher={Elsevier}
}
@article{oseledets2011tensor,
  title={Tensor-train decomposition},
  author={Oseledets, Ivan V},
  journal={SIAM Journal on Scientific Computing},
  volume={33},
  number={5},
  pages={2295--2317},
  year={2011},
  publisher={SIAM}
}


@article{zhao2016tensor,
  title={Tensor ring decomposition},
  author={Zhao, Qibin and Zhou, Guoxu and Xie, Shengli and Zhang, Liqing and Cichocki, Andrzej},
  journal={arXiv preprint arXiv:1606.05535},
  year={2016}
}

@article{garipov2016ultimate,
  title={Ultimate tensorization: compressing convolutional and fc layers alike},
  author={Garipov, Timur and Podoprikhin, Dmitry and Novikov, Alexander and Vetrov, Dmitry},
  journal={arXiv preprint arXiv:1611.03214},
  year={2016}
}

@article{thakker2019compressing,
  title={Compressing rnns for iot devices by 15-38x using kronecker products},
  author={Thakker, Urmish and Beu, Jesse and Gope, Dibakar and Zhou, Chu and Fedorov, Igor and Dasika, Ganesh and Mattina, Matthew},
  journal={arXiv preprint arXiv:1906.02876},
  year={2019}
}
@inproceedings{hameed2022convolutional,
  title={Convolutional neural network compression through generalized Kronecker product decomposition},
  author={Hameed, Marawan Gamal Abdel and Tahaei, Marzieh S and Mosleh, Ali and Nia, Vahid Partovi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={771--779},
  year={2022}
}



@article{cheng2007survey,
  title={A survey on semi-tensor product of matrices},
  author={Cheng, Daizhan and Qi, Hongsheng and Xue, Ancheng},
  journal={Journal of Systems Science and Complexity},
  volume={20},
  number={2},
  pages={304--322},
  year={2007},
  publisher={Springer}
}
@article{zhao2021semi,
  title={Semi-tensor Product-based TensorDecomposition for Neural Network Compression},
  author={Zhao, Hengling and Liu, Yipeng and Huang, Xiaolin and Zhu, Ce},
  journal={arXiv preprint arXiv:2109.15200},
  year={2021}
}
@article{nakajima2013global,
  title={Global analytic solution of fully-observed variational Bayesian matrix factorization},
  author={Nakajima, Shinichi and Sugiyama, Masashi and Babacan, S Derin and Tomioka, Ryota},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={1--37},
  year={2013},
  publisher={JMLR. org}
}
@book{reeves1993modern,
  title={Modern heuristic techniques for combinatorial problems},
  author={Reeves, Colin R},
  year={1993},
  publisher={John Wiley \& Sons, Inc.}
}
@article{liebenwein2021compressing,
  title={Compressing neural networks: Towards determining the optimal layer-wise decomposition},
  author={Liebenwein, Lucas and Maalouf, Alaa and Feldman, Dan and Rus, Daniela},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={5328--5344},
  year={2021}
}
@inproceedings{cheng2020novel,
  title={A novel rank selection scheme in tensor ring decomposition based on reinforcement learning for deep neural networks},
  author={Cheng, Zhiyu and Li, Baopu and Fan, Yanwen and Bao, Yingze},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3292--3296},
  year={2020},
  organization={IEEE}
}
@inproceedings{samragh2019autorank,
  title={AutoRank: Automated rank selection for effective neural network customization},
  author={Samragh, Mohammad and Javaheripi, Mojan and Koushanfar, Farinaz},
  booktitle={Proceedings of the ML-for-Systems Workshop at the 46th International Symposium on Computer Architecture (ISCA’19)},
  year={2019}
}
@inproceedings{phan2020stable,
  title={Stable low-rank tensor decomposition for compression of convolutional neural network},
  author={Phan, Anh-Huy and Sobolev, Konstantin and Sozykin, Konstantin and Ermilov, Dmitry and Gusak, Julia and Tichavsk{\`y}, Petr and Glukhov, Valeriy and Oseledets, Ivan and Cichocki, Andrzej},
  booktitle={European Conference on Computer Vision},
  pages={522--539},
  year={2020},
  organization={Springer}
}
@article{phan2022train,
  title={How to Train Unstable Looped Tensor Network},
  author={Phan, Anh-Huy and Sobolev, Konstantin and Ermilov, Dmitry and Vorona, Igor and Kozyrskiy, Nikolay and Tichavsky, Petr and Cichocki, Andrzej},
  journal={arXiv preprint arXiv:2203.02617},
  year={2022}
}

@article{krijnen2008non,
  title={On the non-existence of optimal solutions and the occurrence of “degeneracy” in the Candecomp/Parafac model},
  author={Krijnen, Wim P and Dijkstra, Theo K and Stegeman, Alwin},
  journal={Psychometrika},
  volume={73},
  number={3},
  pages={431--439},
  year={2008},
  publisher={Springer}
}

@inproceedings{harshman2004problem,
  title={The problem and nature of degenerate solutions or decompositions of 3-way arrays},
  author={Harshman, Richard A},
  booktitle={Talk at the Tensor Decompositions Workshop, Palo Alto, CA, American Institute of Mathematics},
  year={2004}
}
@article{mitchell1994slowly,
  title={Slowly converging PARAFAC sequences: swamps and two-factor degeneracies},
  author={Mitchell, Ben C and Burdick, Donald S},
  journal={Journal of Chemometrics},
  volume={8},
  number={2},
  pages={155--168},
  year={1994},
  publisher={Wiley Online Library}
}
@article{denton2014exploiting,
  title={Exploiting linear structure within convolutional networks for efficient evaluation},
  author={Denton, Emily L and Zaremba, Wojciech and Bruna, Joan and LeCun, Yann and Fergus, Rob},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}
@inproceedings{astrid2017cp,
  title={Cp-decomposition with tensor power method for convolutional neural networks compression},
  author={Astrid, Marcella and Lee, Seung-Ik},
  booktitle={2017 IEEE International Conference on Big Data and Smart Computing (BigComp)},
  pages={115--118},
  year={2017},
  organization={IEEE}
}


@article{espig2011optimization,
  title={Optimization problems in contracted tensor networks},
  author={Espig, Mike and Hackbusch, Wolfgang and Handschuh, Stefan and Schneider, Reinhold},
  journal={Computing and visualization in science},
  volume={14},
  number={6},
  pages={271--285},
  year={2011},
  publisher={Springer}
}



@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{li2022heuristic,
  title={Heuristic rank selection with progressively searching tensor ring network},
  author={Li, Nannan and Pan, Yu and Chen, Yaran and Ding, Zixiang and Zhao, Dongbin and Xu, Zenglin},
  journal={Complex \& Intelligent Systems},
  volume={8},
  number={2},
  pages={771--785},
  year={2022},
  publisher={Springer}
}
@article{zoph2016neural,
  title={Neural architecture search with reinforcement learning},
  author={Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1611.01578},
  year={2016}
}
@article{deb2002fast,
  title={A fast and elitist multiobjective genetic algorithm: NSGA-II},
  author={Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, TAMT},
  journal={IEEE transactions on evolutionary computation},
  volume={6},
  number={2},
  pages={182--197},
  year={2002},
  publisher={IEEE}
}
@article{hawkins2021bayesian,
  title={Bayesian tensorized neural networks with automatic rank selection},
  author={Hawkins, Cole and Zhang, Zheng},
  journal={Neurocomputing},
  volume={453},
  pages={172--180},
  year={2021},
  publisher={Elsevier}
}
@inproceedings{rai2014scalable,
  title={Scalable Bayesian low-rank decomposition of incomplete multiway tensors},
  author={Rai, Piyush and Wang, Yingjian and Guo, Shengbo and Chen, Gary and Dunson, David and Carin, Lawrence},
  booktitle={International Conference on Machine Learning},
  pages={1800--1808},
  year={2014},
  organization={PMLR}
}
@article{guhaniyogi2017bayesian,
  title={Bayesian tensor regression},
  author={Guhaniyogi, Rajarshi and Qamar, Shaan and Dunson, David B},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={2733--2763},
  year={2017},
  publisher={JMLR. org}
}
@article{bazerque2013rank,
  title={Rank regularization and Bayesian inference for tensor completion and extrapolation},
  author={Bazerque, Juan Andr{\'e}s and Mateos, Gonzalo and Giannakis, Georgios B},
  journal={IEEE transactions on signal processing},
  volume={61},
  number={22},
  pages={5689--5703},
  year={2013},
  publisher={IEEE}
}
@article{alvarez2017compression,
  title={Compression-aware training of deep networks},
  author={Alvarez, Jose M and Salzmann, Mathieu},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{cai2010singular,
  title={A singular value thresholding algorithm for matrix completion},
  author={Cai, Jian-Feng and Cand{\`e}s, Emmanuel J and Shen, Zuowei},
  journal={SIAM Journal on optimization},
  volume={20},
  number={4},
  pages={1956--1982},
  year={2010},
  publisher={SIAM}
}
@inproceedings{xu2019trained,
  title={Trained rank pruning for efficient deep neural networks},
  author={Xu, Yuhui and Li, Yuxi and Zhang, Shuai and Wen, Wei and Wang, Botao and Dai, Wenrui and Qi, Yingyong and Chen, Yiran and Lin, Weiyao and Xiong, Hongkai},
  booktitle={2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing-NeurIPS Edition (EMC2-NIPS)},
  pages={14--17},
  year={2019},
  organization={IEEE}
}
@article{avron2012efficient,
  title={Efficient and practical stochastic subgradient descent for nuclear norm regularization},
  author={Avron, Haim and Kale, Satyen and Kasiviswanathan, Shiva and Sindhwani, Vikas},
  journal={arXiv preprint arXiv:1206.6384},
  year={2012}
}
@inproceedings{yang2020learning,
  title={Learning low-rank deep neural networks via singular vector orthogonality regularization and singular value sparsification},
  author={Yang, Huanrui and Tang, Minxue and Wen, Wei and Yan, Feng and Hu, Daniel and Li, Ang and Li, Hai and Chen, Yiran},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={678--679},
  year={2020}
}

@inproceedings{idelbayev2020low,
  title={Low-rank compression of neural nets: Learning the rank of each layer},
  author={Idelbayev, Yerlan and Carreira-Perpin{\'a}n, Miguel A},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8049--8059},
  year={2020}
}
@inproceedings{carreira2018learning,
  title={“learning-compression” algorithms for neural net pruning},
  author={Carreira-Perpin{\'a}n, Miguel A and Idelbayev, Yerlan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8532--8541},
  year={2018}
}


@article{boyd2011distributed,
  title={Distributed optimization and statistical learning via the alternating direction method of multipliers},
  author={Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan and others},
  journal={Foundations and Trends{\textregistered} in Machine learning},
  volume={3},
  number={1},
  pages={1--122},
  year={2011},
  publisher={Now Publishers, Inc.}
}
@ARTICLE{4100845,
  author={Xu, Peng and Tian, Yin and Chen, Huafu and Yao, Dezhong},
  journal={IEEE Transactions on Biomedical Engineering}, 
  title={Lp Norm Iterative Sparse Solution for EEG Source Localization}, 
  year={2007},
  volume={54},
  number={3},
  pages={400-409},
  doi={10.1109/TBME.2006.886640}}
  
@article{dalton1920measurement,
  title={The measurement of the inequality of incomes},
  author={Dalton, Hugh},
  journal={The Economic Journal},
  volume={30},
  number={119},
  pages={348--361},
  year={1920},
  publisher={JSTOR}
}

@article{lorenz1905methods,
  title={Methods of measuring the concentration of wealth},
  author={Lorenz, Max O},
  journal={Publications of the American statistical association},
  volume={9},
  number={70},
  pages={209--219},
  year={1905},
  publisher={Taylor \& Francis}
}

@inproceedings{rickard2006sparse,
  title={Sparse sources are separated sources},
  author={Rickard, Scott},
  booktitle={2006 14th European signal processing conference},
  pages={1--5},
  year={2006},
  organization={IEEE}
}
@article{hurley2005parameterized,
  title={Parameterized lifting for sparse signal representations using the gini index},
  author={Hurley, Niall and Rickard, Scott and Curran, Paul},
  journal={Signal Processing with Adaptative Sparse Structured Representations (SPARS05), Rennes, France},
  year={2005}
}

@article{hoyer2004non,
  title={Non-negative matrix factorization with sparseness constraints.},
  author={Hoyer, Patrik O},
  journal={Journal of machine learning research},
  volume={5},
  number={9},
  year={2004}
}
@inproceedings{goyal2019compression,
  title={Compression of deep neural networks by combining pruning and low rank decomposition},
  author={Goyal, Saurabh and Choudhury, Anamitra Roy and Sharma, Vivek},
  booktitle={2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  pages={952--958},
  year={2019},
  organization={IEEE}
}
@article{chen2020deep,
  title={Deep neural network acceleration based on low-rank approximated channel pruning},
  author={Chen, Zhen and Chen, Zhibo and Lin, Jianxin and Liu, Sen and Li, Weiping},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers},
  volume={67},
  number={4},
  pages={1232--1244},
  year={2020},
  publisher={IEEE}
}
@article{molchanov2016pruning,
  title={Pruning convolutional neural networks for resource efficient inference},
  author={Molchanov, Pavlo and Tyree, Stephen and Karras, Tero and Aila, Timo and Kautz, Jan},
  journal={arXiv preprint arXiv:1611.06440},
  year={2016}
}
@inproceedings{li2020group,
  title={Group sparsity: The hinge between filter pruning and decomposition for network compression},
  author={Li, Yawei and Gu, Shuhang and Mayer, Christoph and Gool, Luc Van and Timofte, Radu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8018--8027},
  year={2020}
}

@article{ruan2020edp,
  title={Edp: An efficient decomposition and pruning scheme for convolutional neural network compression},
  author={Ruan, Xiaofeng and Liu, Yufan and Yuan, Chunfeng and Li, Bing and Hu, Weiming and Li, Yangxi and Maybank, Stephen},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  volume={32},
  number={10},
  pages={4499--4513},
  year={2020},
  publisher={IEEE}
}
@article{kumar2022vision,
  title={Vision Transformer Compression with Structured Pruning and Low Rank Approximation},
  author={Kumar, Ankur},
  journal={arXiv preprint arXiv:2203.13444},
  year={2022}
}
@article{alvarez2016learning,
  title={Learning the number of neurons in deep networks},
  author={Alvarez, Jose M and Salzmann, Mathieu},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
@article{han2015learning,
  title={Learning both weights and connections for efficient neural network},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{han2016eie,
  title={EIE: Efficient inference engine on compressed deep neural network},
  author={Han, Song and Liu, Xingyu and Mao, Huizi and Pu, Jing and Pedram, Ardavan and Horowitz, Mark A and Dally, William J},
  journal={ACM SIGARCH Computer Architecture News},
  volume={44},
  number={3},
  pages={243--254},
  year={2016},
  publisher={ACM New York, NY, USA}
}
@inproceedings{liu2013efficient,
  title={Efficient sparse matrix-vector multiplication on x86-based many-core processors},
  author={Liu, Xing and Smelyanskiy, Mikhail and Chow, Edmond and Dubey, Pradeep},
  booktitle={Proceedings of the 27th international ACM conference on International conference on supercomputing},
  pages={273--282},
  year={2013}
}
@inproceedings{liu2015sparse,
  title={Sparse convolutional neural networks},
  author={Liu, Baoyuan and Wang, Min and Foroosh, Hassan and Tappen, Marshall and Pensky, Marianna},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={806--814},
  year={2015}
}
@inproceedings{wen2020learning,
  title={Learning low-rank structured sparsity in recurrent neural networks},
  author={Wen, Weijing and Yang, Fan and Su, Yangfeng and Zhou, Dian and Zeng, Xuan},
  booktitle={2020 IEEE International Symposium on Circuits and Systems (ISCAS)},
  pages={1--4},
  year={2020},
  organization={IEEE}
}
@article{swaminathan2020sparse,
  title={Sparse low rank factorization for deep neural network compression},
  author={Swaminathan, Sridhar and Garg, Deepak and Kannan, Rajkumar and Andres, Frederic},
  journal={Neurocomputing},
  volume={398},
  pages={185--196},
  year={2020},
  publisher={Elsevier}
}
@inproceedings{lebedev2016fast,
  title={Fast convnets using group-wise brain damage},
  author={Lebedev, Vadim and Lempitsky, Victor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2554--2564},
  year={2016}
}
@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}
@inproceedings{li2019learning,
  title={Learning filter basis for convolutional neural network compression},
  author={Li, Yawei and Gu, Shuhang and Gool, Luc Van and Timofte, Radu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5623--5632},
  year={2019}
}
@inproceedings{obukhov2020t,
  title={T-basis: a compact representation for neural networks},
  author={Obukhov, Anton and Rakhuba, Maxim and Georgoulis, Stamatios and Kanakis, Menelaos and Dai, Dengxin and Van Gool, Luc},
  booktitle={International Conference on Machine Learning},
  pages={7392--7404},
  year={2020},
  organization={PMLR}
}
@article{sun2020deep,
  title={Deep convolutional neural network compression via coupled tensor decomposition},
  author={Sun, Weize and Chen, Shaowu and Huang, Lei and So, Hing Cheung and Xie, Min},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={15},
  number={3},
  pages={603--616},
  year={2020},
  publisher={IEEE}
}
@article{chetlur2014cudnn,
  title={cudnn: Efficient primitives for deep learning},
  author={Chetlur, Sharan and Woolley, Cliff and Vandermersch, Philippe and Cohen, Jonathan and Tran, John and Catanzaro, Bryan and Shelhamer, Evan},
  journal={arXiv preprint arXiv:1410.0759},
  year={2014}
}
@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
  journal={arXiv preprint arXiv:1503.02531},
  volume={2},
  number={7},
  year={2015}
}

@article{lin2018holistic,
  title={Holistic cnn compression via low-rank decomposition with knowledge transfer},
  author={Lin, Shaohui and Ji, Rongrong and Chen, Chao and Tao, Dacheng and Luo, Jiebo},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={12},
  pages={2889--2905},
  year={2018},
  publisher={IEEE}
}
@inproceedings{li2020few,
  title={Few sample knowledge distillation for efficient network compression},
  author={Li, Tianhong and Li, Jianguo and Liu, Zhuang and Zhang, Changshui},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14639--14647},
  year={2020}
}
@article{tee2020information,
  title={Is information in the brain represented in continuous or discrete form?},
  author={Tee, James and Taylor, Desmond P},
  journal={IEEE Transactions on Molecular, Biological and Multi-Scale Communications},
  volume={6},
  number={3},
  pages={199--209},
  year={2020},
  publisher={IEEE}
}
@article{vanrullen2003perception,
  title={Is perception discrete or continuous?},
  author={VanRullen, Rufin and Koch, Christof},
  journal={Trends in cognitive sciences},
  volume={7},
  number={5},
  pages={207--213},
  year={2003},
  publisher={Elsevier}
}
@article{chaudhuri2016computational,
  title={Computational principles of memory},
  author={Chaudhuri, Rishidev and Fiete, Ila},
  journal={Nature neuroscience},
  volume={19},
  number={3},
  pages={394--403},
  year={2016},
  publisher={Nature Publishing Group}
}
@article{faisal2008noise,
  title={Noise in the nervous system},
  author={Faisal, A Aldo and Selen, Luc PJ and Wolpert, Daniel M},
  journal={Nature reviews neuroscience},
  volume={9},
  number={4},
  pages={292--303},
  year={2008},
  publisher={Nature Publishing Group}
}
@article{khaw2017discrete,
  title={Discrete adjustment to a changing environment: Experimental evidence},
  author={Khaw, Mel Win and Stevens, Luminita and Woodford, Michael},
  journal={Journal of Monetary Economics},
  volume={91},
  pages={88--103},
  year={2017},
  publisher={Elsevier}
}
@article{latimer2015single,
  title={Single-trial spike trains in parietal cortex reveal discrete steps during decision-making},
  author={Latimer, Kenneth W and Yates, Jacob L and Meister, Miriam LR and Huk, Alexander C and Pillow, Jonathan W},
  journal={Science},
  volume={349},
  number={6244},
  pages={184--187},
  year={2015},
  publisher={American Association for the Advancement of Science}
}
@article{varshney2006optimal,
  title={Optimal information storage in noisy synapses under resource constraints},
  author={Varshney, Lav R and Sj{\"o}str{\"o}m, Per Jesper and Chklovskii, Dmitri B},
  journal={Neuron},
  volume={52},
  number={3},
  pages={409--423},
  year={2006},
  publisher={Elsevier}
}
@inproceedings{lin2016fixed,
  title={Fixed point quantization of deep convolutional networks},
  author={Lin, Darryl and Talathi, Sachin and Annapureddy, Sreekanth},
  booktitle={International conference on machine learning},
  pages={2849--2858},
  year={2016},
  organization={PMLR}
}
@article{gholami2021survey,
  title={A survey of quantization methods for efficient neural network inference},
  author={Gholami, Amir and Kim, Sehoon and Dong, Zhen and Yao, Zhewei and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2103.13630},
  year={2021}
}
@article{nagel2021white,
  title={A white paper on neural network quantization},
  author={Nagel, Markus and Fournarakis, Marios and Amjad, Rana Ali and Bondarenko, Yelysei and van Baalen, Mart and Blankevoort, Tijmen},
  journal={arXiv preprint arXiv:2106.08295},
  year={2021}
}

@article{kuzmin2022quantized,
  title={Quantized Sparse Weight Decomposition for Neural Network Compression},
  author={Kuzmin, Andrey and van Baalen, Mart and Nagel, Markus and Behboodi, Arash},
  journal={arXiv preprint arXiv:2207.11048},
  year={2022}
}

@article{kozyrskiy2020cnn,
  title={CNN acceleration by low-rank approximation with quantized factors},
  author={Kozyrskiy, Nikolay and Phan, Anh-Huy},
  journal={arXiv preprint arXiv:2006.08878},
  year={2020}
}

@article{nekooei2022compression,
  title={Compression of Deep Neural Networks based on quantized tensor decomposition to implement on reconfigurable hardware platforms},
  author={Nekooei, Amirreza and Safari, Saeed},
  journal={Neural Networks},
  volume={150},
  pages={350--363},
  year={2022},
  publisher={Elsevier}
}

@article{lee2021qttnet,
  title={QTTNet: Quantized tensor train neural networks for 3D object and video recognition},
  author={Lee, Donghyun and Wang, Dingheng and Yang, Yukuan and Deng, Lei and Zhao, Guangshe and Li, Guoqi},
  journal={Neural Networks},
  volume={141},
  pages={420--432},
  year={2021},
  publisher={Elsevier}
}

@article{recanatesi2019dimensionality,
  title={Dimensionality compression and expansion in deep neural networks},
  author={Recanatesi, Stefano and Farrell, Matthew and Advani, Madhu and Moore, Timothy and Lajoie, Guillaume and Shea-Brown, Eric},
  journal={arXiv preprint arXiv:1906.00443},
  year={2019}
}

@article{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={arXiv preprint arXiv:1510.00149},
  year={2015}
}

@article{ziv1977universal,
  title={A universal algorithm for sequential data compression},
  author={Ziv, Jacob and Lempel, Abraham},
  journal={IEEE Transactions on information theory},
  volume={23},
  number={3},
  pages={337--343},
  year={1977},
  publisher={IEEE}
}
@article{ziv1978compression,
  title={Compression of individual sequences via variable-rate coding},
  author={Ziv, Jacob and Lempel, Abraham},
  journal={IEEE transactions on Information Theory},
  volume={24},
  number={5},
  pages={530--536},
  year={1978},
  publisher={IEEE}
}
@article{welch1984technique,
  title={A technique for high-performance data compression},
  author={Welch, Terry A.},
  journal={Computer},
  volume={17},
  number={06},
  pages={8--19},
  year={1984},
  publisher={IEEE Computer Society}
 }
@article{effros2002universal,
  title={Universal lossless source coding with the Burrows Wheeler transform},
  author={Effros, Michelle and Visweswariah, Karthik and Kulkarni, Sanjeev R and Verd{\'u}, Sergio},
  journal={IEEE Transactions on Information Theory},
  volume={48},
  number={5},
  pages={1061--1081},
  year={2002},
  publisher={IEEE}
}
@article{choi2020universal,
  title={Universal deep neural network compression},
  author={Choi, Yoojin and El-Khamy, Mostafa and Lee, Jungwon},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={14},
  number={4},
  pages={715--726},
  year={2020},
  publisher={IEEE}
}

@article{wiedemann2020deepcabac,
  title={Deepcabac: A universal compression algorithm for deep neural networks},
  author={Wiedemann, Simon and Kirchhoffer, Heiner and Matlage, Stefan and Haase, Paul and Marban, Arturo and Marin{\v{c}}, Talmaj and Neumann, David and Nguyen, Tung and Schwarz, Heiko and Wiegand, Thomas and others},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={14},
  number={4},
  pages={700--714},
  year={2020},
  publisher={IEEE}
}

@inproceedings{chen2021efficient,
  title={Efficient Tunstall Decoder for Deep Neural Network Compression},
  author={Chen, Chunyun and Wang, Zhe and Chen, Xiaowei and Lin, Jie and Aly, Mohamed M Sabry},
  booktitle={2021 58th ACM/IEEE Design Automation Conference (DAC)},
  pages={1021--1026},
  year={2021},
  organization={IEEE}
}
@article{oktay2019scalable,
  title={Scalable model compression by entropy penalized reparameterization},
  author={Oktay, Deniz and Ball{\'e}, Johannes and Singh, Saurabh and Shrivastava, Abhinav},
  journal={arXiv preprint arXiv:1906.06624},
  year={2019}
}
@article{cosson2022gradient,
  title={Gradient Descent for Low-Rank Functions},
  author={Cosson, Romain and Jadbabaie, Ali and Makur, Anuran and Reisizadeh, Amirhossein and Shah, Devavrat},
  journal={arXiv preprint arXiv:2206.08257},
  year={2022}
}

@article{logan1975optimal,
  title={Optimal reconstruction of a function from its projections},
  author={Logan, Benjamin F and Shepp, Larry A},
  journal={Duke mathematical journal},
  volume={42},
  number={4},
  pages={645--659},
  year={1975},
  publisher={Duke University Press}
}

@article{donoho1989projection,
  title={Projection-based approximation and a duality with kernel methods},
  author={Donoho, David L and Johnstone, Iain M},
  journal={The Annals of Statistics},
  pages={58--106},
  year={1989},
  publisher={JSTOR}
}

@article{constantine2015exploiting,
  title={Exploiting active subspaces to quantify uncertainty in the numerical simulation of the HyShot II scramjet},
  author={Constantine, Paul G and Emory, Michael and Larsson, Johan and Iaccarino, Gianluca},
  journal={Journal of Computational Physics},
  volume={302},
  pages={1--20},
  year={2015},
  publisher={Elsevier}
}

@article{gur2018gradient,
  title={Gradient descent happens in a tiny subspace},
  author={Gur-Ari, Guy and Roberts, Daniel A and Dyer, Ethan},
  journal={arXiv preprint arXiv:1812.04754},
  year={2018}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}



@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization.},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={7},
  year={2011}
}

@article{li2022low,
  title={Low dimensional trajectory hypothesis is true: Dnns can be trained in tiny subspaces},
  author={Li, Tao and Tan, Lei and Huang, Zhehao and Tao, Qinghua and Liu, Yipeng and Huang, Xiaolin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
  publisher={IEEE}
}

@inproceedings{2020Knowledge,
  title={Knowledge Distillation Inspired Fine-Tuning Of Tucker Decomposed CNNS and Adversarial Robustness Analysis},
  author={ Sadhukhan, R.  and  Saha, A.  and  Mukhopadhyay, J.  and  Patra, A. },
  booktitle={2020 IEEE International Conference on Image Processing (ICIP)},
  year={2020},
}


@article{byrd1994representations,
  title={Representations of quasi-Newton matrices and their use in limited memory methods},
  author={Byrd, Richard H and Nocedal, Jorge and Schnabel, Robert B},
  journal={Mathematical Programming},
  volume={63},
  number={1},
  pages={129--156},
  year={1994},
  publisher={Springer}
}

@inproceedings{roy2007effective,
  title={The effective rank: A measure of effective dimensionality},
  author={Roy, Olivier and Vetterli, Martin},
  booktitle={2007 15th European signal processing conference},
  pages={606--610},
  year={2007},
  organization={IEEE}
}


@article{deng2020model,
  title={Model compression and hardware acceleration for neural networks: A comprehensive survey},
  author={Deng, Lei and Li, Guoqi and Han, Song and Shi, Luping and Xie, Yuan},
  journal={Proceedings of the IEEE},
  volume={108},
  number={4},
  pages={485--532},
  year={2020},
  publisher={IEEE}
}
@article{choudhary2020comprehensive,
  title={A comprehensive survey on model compression and acceleration},
  author={Choudhary, Tejalal and Mishra, Vipul and Goswami, Anurag and Sarangapani, Jagannathan},
  journal={Artificial Intelligence Review},
  volume={53},
  number={7},
  pages={5113--5155},
  year={2020},
  publisher={Springer}
}

@article{gong2014compressing,
  title={Compressing deep convolutional networks using vector quantization},
  author={Gong, Yunchao and Liu, Liu and Yang, Ming and Bourdev, Lubomir},
  journal={arXiv preprint arXiv:1412.6115},
  year={2014}
}

@inproceedings{wu2016quantized,
  title={Quantized convolutional neural networks for mobile devices},
  author={Wu, Jiaxiang and Leng, Cong and Wang, Yuhang and Hu, Qinghao and Cheng, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4820--4828},
  year={2016}
}

@inproceedings{luo2017thinet,
  title={Thinet: A filter level pruning method for deep neural network compression},
  author={Luo, Jian-Hao and Wu, Jianxin and Lin, Weiyao},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5058--5066},
  year={2017}
}

@inproceedings{zhang2018systematic,
  title={A systematic dnn weight pruning framework using alternating direction method of multipliers},
  author={Zhang, Tianyun and Ye, Shaokai and Zhang, Kaiqi and Tang, Jian and Wen, Wujie and Fardad, Makan and Wang, Yanzhi},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={184--199},
  year={2018}
}

@article{ullrich2017soft,
  title={Soft weight-sharing for neural network compression},
  author={Ullrich, Karen and Meeds, Edward and Welling, Max},
  journal={arXiv preprint arXiv:1702.04008},
  year={2017}
}

@article{huang2011learning,
  title={Learning with Structured Sparsity.},
  author={Huang, Junzhou and Zhang, Tong and Metaxas, Dimitris},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={11},
  year={2011}
}



@inproceedings{abdul2011accelerating,
  title={Accelerating learning performance of back propagation algorithm by using adaptive gain together with adaptive momentum and adaptive learning rate on classification problems},
  author={Abdul Hamid, Norhamreeza and Mohd Nawi, Nazri and Ghazali, Rozaida and Mohd Salleh, Mohd Najib},
  booktitle={International Conference on Ubiquitous Computing and Multimedia Applications},
  pages={559--570},
  year={2011},
  organization={Springer}
}

@article{lee2016regularized,
  title={Regularized computation of approximate pseudoinverse of large matrices using low-rank tensor train decompositions},
  author={Lee, Namgil and Cichocki, Andrzej},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={37},
  number={2},
  pages={598--623},
  year={2016},
  publisher={SIAM}
}
@inproceedings{pan2022unified,
  title={A Unified Weight Initialization Paradigm for Tensorial Convolutional Neural Networks},
  author={Pan, Yu and Su, Zeyong and Liu, Ao and Jingquan, Wang and Li, Nannan and Xu, Zenglin},
  booktitle={International Conference on Machine Learning},
  pages={17238--17257},
  year={2022},
  organization={PMLR}
}

@inproceedings{osawa2017evaluating,
  title={Evaluating the compression efficiency of the filters in convolutional neural networks},
  author={Osawa, Kazuki and Yokota, Rio},
  booktitle={International Conference on Artificial Neural Networks},
  pages={459--466},
  year={2017},
  organization={Springer}
}

@inproceedings{huang2018learning,
  title={Learning to prune filters in convolutional neural networks},
  author={Huang, Qiangui and Zhou, Kevin and You, Suya and Neumann, Ulrich},
  booktitle={2018 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  pages={709--718},
  year={2018},
  organization={IEEE}
}

@article{chen2018shallowing,
  title={Shallowing deep networks: Layer-wise pruning based on feature representations},
  author={Chen, Shi and Zhao, Qi},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={12},
  pages={3048--3056},
  year={2018},
  publisher={IEEE}
}

@article{zou2006sparse,
  title={Sparse principal component analysis},
  author={Zou, Hui and Hastie, Trevor and Tibshirani, Robert},
  journal={Journal of computational and graphical statistics},
  volume={15},
  number={2},
  pages={265--286},
  year={2006},
  publisher={Taylor \& Francis}
}

@incollection{liu2022tensor,
  title={Tensor Decomposition in Deep Networks},
  author={Liu, Yipeng and Liu, Jiani and Long, Zhen and Zhu, Ce},
  booktitle={Tensor Computation for Data Analysis},
  pages={241--263},
  year={2022},
  publisher={Springer}
}



@article{blalock2020state,
  title={What is the state of neural network pruning?},
  author={Blalock, Davis and Gonzalez Ortiz, Jose Javier and Frankle, Jonathan and Guttag, John},
  journal={Proceedings of machine learning and systems},
  volume={2},
  pages={129--146},
  year={2020}
}

@inproceedings{chen2015compressing,
  title={Compressing neural networks with the hashing trick},
  author={Chen, Wenlin and Wilson, James and Tyree, Stephen and Weinberger, Kilian and Chen, Yixin},
  booktitle={International conference on machine learning},
  pages={2285--2294},
  year={2015},
  organization={PMLR}
}

@article{sze2020evaluate,
  title={How to evaluate deep neural network processors: Tops/w (alone) considered harmful},
  author={Sze, Vivienne and Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel S},
  journal={IEEE Solid-State Circuits Magazine},
  volume={12},
  number={3},
  pages={28--41},
  year={2020},
  publisher={IEEE}
}
@inproceedings{horowitz20141,
  title={1.1 computing's energy problem (and what we can do about it)},
  author={Horowitz, Mark},
  booktitle={2014 IEEE International Solid-State Circuits Conference Digest of Technical Papers (ISSCC)},
  pages={10--14},
  year={2014},
  organization={IEEE}
}
@article{sze2017efficient,
  title={Efficient processing of deep neural networks: A tutorial and survey},
  author={Sze, Vivienne and Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel S},
  journal={Proceedings of the IEEE},
  volume={105},
  number={12},
  pages={2295--2329},
  year={2017},
  publisher={Ieee}
}
@article{wang2023tensor,
  title={Tensor Networks Meet Neural Networks: A Survey},
  author={Wang, Maolin and Pan, Yu and Yang, Xiangli and Li, Guangxi and Xu, Zenglin},
  journal={arXiv preprint arXiv:2302.09019},
  year={2023}
}

@inproceedings{yin2022hodec,
  title={HODEC: Towards Efficient High-Order DEcomposed Convolutional Neural Networks},
  author={Yin, Miao and Sui, Yang and Yang, Wanzhao and Zang, Xiao and Gong, Yu and Yuan, Bo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12299--12308},
  year={2022}
}

@inproceedings{veeramacheneni2022canonical,
  title={Canonical convolutional neural networks},
  author={Veeramacheneni, Lokesh and Wolter, Moritz and Klein, Reinhard and Garcke, Jochen},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2022},
  organization={IEEE}
}
@article{kolda2009tensor,
  title={Tensor decompositions and applications},
  author={Kolda, Tamara G and Bader, Brett W},
  journal={SIAM review},
  volume={51},
  number={3},
  pages={455--500},
  year={2009},
  publisher={SIAM}
}
@article{zimmer2022compression,
  title={Compression-aware Training of Neural Networks using Frank-Wolfe},
  author={Zimmer, Max and Spiegel, Christoph and Pokutta, Sebastian},
  journal={arXiv preprint arXiv:2205.11921},
  year={2022}
}

@article{eo2023effective,
  title={An effective low-rank compression with a joint rank selection followed by a compression-friendly training},
  author={Eo, Moonjung and Kang, Suhyun and Rhee, Wonjong},
  journal={Neural Networks},
  volume={161},
  pages={165--177},
  year={2023},
  publisher={Elsevier}
}


@book{liu2021tensors,
  title={Tensors for Data Processing: Theory, Methods, and Applications},
  author={Liu, Yipeng},
  year={2021},
  publisher={Academic Press}
}


@article{liu2021tensor,
  title={Tensor Regression},
  author={Liu, Jiani and Zhu, Ce and Long, Zhen and Liu, Yipeng and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={14},
  number={4},
  pages={379--565},
  year={2021},
  publisher={Now Publishers, Inc.}
}

@article{huang2015two,
  title={Two-level $\ell_1$ minimization for compressed sensing},
  author={Huang, Xiaolin and Liu, Yipeng and Shi, Lei and Van Huffel, Sabine and Suykens, Johan AK},
  journal={Signal Processing},
  volume={108},
  pages={459--475},
  year={2015},
  publisher={Elsevier}
}

@article{bogdan2013statistical,
  title={Statistical estimation and testing via the sorted L1 norm},
  author={Bogdan, Malgorzata and Berg, Ewout van den and Su, Weijie and Candes, Emmanuel},
  journal={arXiv preprint arXiv:1310.1969},
  year={2013}
}


@article{shi2019sparse,
  title={Sparse kernel regression with coefficient-based lq-regularization},
  author={Shi, Lei and Huang, Xiaolin and Feng, Yunlong and Suykens, Johan},
  journal={Journal of Machine Learning Research},
  volume={20},
  year={2019},
  publisher={Microtome Publishing}
}


@article{liu2013multi,
  title={Multi-structural signal recovery for biomedical compressive sensing},
  author={Liu, Yipeng and De Vos, Maarten and Gligorijevic, Ivan and Matic, Vladimir and Li, Yuqian and Van Huffel, Sabine},
  journal={IEEE Transactions on Biomedical Engineering},
  volume={60},
  number={10},
  pages={2794--2805},
  year={2013},
  publisher={IEEE}
}


@article{liu2018image,
  title={Image completion using low tensor tree rank and total variation minimization},
  author={Liu, Yipeng and Long, Zhen and Zhu, Ce},
  journal={IEEE Transactions on Multimedia},
  volume={21},
  number={2},
  pages={338--350},
  year={2018},
  publisher={IEEE}
}


@article{liu2020low,
  title={Low-rank tensor train coefficient array estimation for tensor-on-tensor regression},
  author={Liu, Yipeng and Liu, Jiani and Zhu, Ce},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={12},
  pages={5402--5411},
  year={2020},
  publisher={IEEE}
}


@article{huang2020robust,
  title={Robust low-rank tensor ring completion},
  author={Huang, Huyan and Liu, Yipeng and Long, Zhen and Zhu, Ce},
  journal={IEEE Transactions on Computational Imaging},
  volume={6},
  pages={1117--1126},
  year={2020},
  publisher={IEEE}
}


@article{huang2020provable,
  title={Provable tensor ring completion},
  author={Huang, Huyan and Liu, Yipeng and Liu, Jiani and Zhu, Ce},
  journal={Signal Processing},
  volume={171},
  pages={107486},
  year={2020},
  publisher={Elsevier}
}

@article{liu2020smooth,
  title={Smooth compact tensor ring regression},
  author={Liu, Jiani and Zhu, Ce and Liu, Yipeng},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={34},
  number={9},
  pages={4439--4452},
  year={2020},
  publisher={IEEE}
}

@article{long2021bayesian,
  title={Bayesian low rank tensor ring for image recovery},
  author={Long, Zhen and Zhu, Ce and Liu, Jiani and Liu, Yipeng},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={3568--3580},
  year={2021},
  publisher={IEEE}
}


@article{liu2019low,
  title={Low CP rank and tucker rank tensor completion for estimating missing components in image data},
  author={Liu, Yipeng and Long, Zhen and Huang, Huyan and Zhu, Ce},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={30},
  number={4},
  pages={944--954},
  year={2019},
  publisher={IEEE}
}