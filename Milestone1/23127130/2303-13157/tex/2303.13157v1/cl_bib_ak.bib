@article{nunamaker1990systems,
  title={Systems development in information systems research},
  author={Nunamaker Jr, Jay F and Chen, Minder and Purdin, Titus DM},
  journal={Journal of management information systems},
  volume={7},
  number={3},
  pages={89--106},
  year={1990},
  publisher={Taylor \& Francis}
}

@inproceedings{abadi2016tensorflow,
  title={Tensorflow: a system for large-scale machine learning.},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={Osdi},
  volume={16},
  number={2016},
  pages={265--283},
  year={2016},
  organization={Savannah, GA, USA}
}

%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SURVEYS & REVIEWS %%%
%%%%%%%%%%%%%%%%%%%%%%%%%
% VERY BROAD AND THEORETIC REVIEW, GOOD STARTING POINT %
@article{hadsell2020embracing,
  title = {Embracing Change: Continual Learning in Deep Neural Networks},
  journal = {Trends in Cognitive Sciences},
  volume = {24},
  number = {12},
  pages = {1028-1040},
  year = {2020},
  issn = {1364-6613},
  doi = {https://doi.org/10.1016/j.tics.2020.09.004},
  url = {https://www.sciencedirect.com/science/article/pii/S1364661320302199},
  author = {Raia Hadsell and Dushyant Rao and Andrei A. Rusu and Razvan Pascanu},
  keywords = {artificial intelligence, memory, meta-learning, non-stationary, lifelong},
}
% DEFINITION OF CL / LIFELONG LEARNING %
@article{mundt2020wholistic,
  title={A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning},
  author={Mundt, Martin and Hong, Yong Won and Pliushch, Iuliia and Ramesh, Visvanathan},
  journal={arXiv preprint arXiv:2009.01797},
  year={2020}
}
% BIG REVIEW: BIOLOGICAL ASPECTS IN REPLAY TRAINING %
@article{hayes2021replay,
  title={Replay in deep learning: Current approaches and missing biological elements},
  author={Hayes, Tyler L and Krishnan, Giri P and Bazhenov, Maxim and Siegelmann, Hava T and Sejnowski, Terrence J and Kanan, Christopher},
  journal={Neural Computation},
  volume={33},
  number={11},
  pages={2908--2950},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
% BIG REVIEW: BIOLOGICAL ASPECTS, LL AND CF WITH DIFFERENT APPROACHES, AUTONOMOUS AGENTS %
@article{parisi2019continual,
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural Networks},
  volume={113},
  pages={54--71},
  year={2019},
  publisher={Elsevier}
}
% BIG REVIEW %
@article{delange2021continual,
  title={A continual learning survey: Defying forgetting in classification tasks},
  author={Delange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Ales and Slabaugh, Greg and Tuytelaars, Tinne},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2021},
  publisher={IEEE}
}

% BIG REVIEW FOR CV TASKS %
@article{qu2021recent,
  title={Recent Advances of Continual Learning in Computer Vision: An Overview},
  author={Qu, Haoxuan and Rahmani, Hossein and Xu, Li and Williams, Bryan and Liu, Jun},
  journal={arXiv preprint arXiv:2109.11369},
  year={2021}
}

% EVAL FOR CLASS-INCREMENTAL LEARNING, REHEARSAL STRATEGIES %
@article{masana2020class,
  title={Class-incremental learning: survey and performance evaluation on image classification},
  author={Masana, Marc and Liu, Xialei and Twardowski, Bartlomiej and Menta, Mikel and Bagdanov, Andrew D and van de Weijer, Joost},
  journal={arXiv preprint arXiv:2010.15277},
  year={2020}
}

% (RL) Beyond Supervised Review
@article{bagus2022beyond,
  title={Beyond Supervised Continual Learning: a Review},
  author={Bagus, Benedikt and Gepperth, Alexander and Lesort, Timoth{\'e}e},
  journal={arXiv preprint arXiv:2208.14307},
  year={2022}
}

% (RL) BIG REVIEW FOR REINFORCEMENT LEARNING %
@misc{khetarpal2020continual,
  title={Towards Continual Reinforcement Learning: A Review and Perspectives}, 
  author={Khimya Khetarpal and Matthew Riemer and Irina Rish and Doina Precup},
  year={2020},
  eprint={2012.13490},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

% (RL) BIG REVIEW & FRAMEWORK TO LINK CL TO ROBOTICS %
@article{lesort2020continual,
  title={Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges},
  author={Lesort, Timoth{\'e}e and Lomonaco, Vincenzo and Stoian, Andrei and Maltoni, Davide and Filliat, David and D{\'\i}az-Rodr{\'\i}guez, Natalia},
  journal={Information fusion},
  volume={58},
  pages={52--68},
  year={2020},
  publisher={Elsevier}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% EMPIRICAL, METRICS & EVALUATION %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{zhou2022fortuitous,
  title={Fortuitous forgetting in connectionist networks},
  author={Zhou, Hattie and Vani, Ankit and Larochelle, Hugo and Courville, Aaron},
  journal={arXiv preprint arXiv:2202.00155},
  year={2022}
}

@article{mundt2021cleva,
  title={CLEVA-compass: A continual learning evaluation assessment compass to promote research transparency and comparability},
  author={Mundt, Martin and Lang, Steven and Delfosse, Quentin and Kersting, Kristian},
  journal={arXiv preprint arXiv:2110.03331},
  year={2021}
}

@misc{cossu2021is,
  doi = {10.48550/ARXIV.2112.02925},
  url = {https://arxiv.org/abs/2112.02925},
  author = {Cossu, Andrea and Graffieti, Gabriele and Pellegrini, Lorenzo and Maltoni, Davide and Bacciu, Davide and Carta, Antonio and Lomonaco, Vincenzo},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Is Class-Incremental Enough for Continual Learning?},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{diaz2018don,
  title={Don't forget, there is more than forgetting: new metrics for Continual Learning},
  author={D{\'\i}az-Rodr{\'\i}guez, Natalia and Lomonaco, Vincenzo and Filliat, David and Maltoni, Davide},
  journal={arXiv preprint arXiv:1810.13166},
  year={2018}
}

@inproceedings{maltoni2016semi,
  title={Semi-supervised tuning from temporal coherence},
  author={Maltoni, Davide and Lomonaco, Vincenzo},
  booktitle={2016 23rd International Conference on Pattern Recognition (ICPR)},
  pages={2509--2514},
  year={2016},
  organization={IEEE}
}

@article{cossu2021continual,
  title={Continual learning for recurrent neural networks: an empirical evaluation},
  author={Cossu, Andrea and Carta, Antonio and Lomonaco, Vincenzo and Bacciu, Davide},
  journal={Neural Networks},
  volume={143},
  pages={607--627},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{stojanov2019incremental,
  title={Incremental object learning from contiguous views},
  author={Stojanov, Stefan and Mishra, Samarth and Thai, Ngoc Anh and Dhanda, Nikhil and Humayun, Ahmad and Yu, Chen and Smith, Linda B and Rehg, James M},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8777--8786},
  year={2019}
}

@inproceedings{lomonaco2020rehearsal,
  title={Rehearsal-Free Continual Learning over Small Non-IID Batches.},
  author={Lomonaco, Vincenzo and Maltoni, Davide and Pellegrini, Lorenzo},
  booktitle={CVPR Workshops},
  volume={1},
  number={2},
  pages={3},
  year={2020}
}

@inproceedings{kemker2018measuring,
  title={Measuring catastrophic forgetting in neural networks},
  author={Kemker, Ronald and McClure, Marc and Abitino, Angelina and Hayes, Tyler and Kanan, Christopher},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{hayes2018new,
  title={New metrics and experimental paradigms for continual learning},
  author={Hayes, Tyler L and Kemker, Ronald and Cahill, Nathan D and Kanan, Christopher},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={2031--2034},
  year={2018}
}

@article{van2019three,
  title={Three scenarios for continual learning},
  author={Van de Ven, Gido M and Tolias, Andreas S},
  journal={arXiv preprint arXiv:1904.07734},
  year={2019}
}

% Compares different task setups (class-increment, task-incremental, domain-incremental) %
@article{hsu2018re,
  title={Re-evaluating continual learning scenarios: A categorization and case for strong baselines},
  author={Hsu, Yen-Chang and Liu, Yen-Cheng and Ramasamy, Anita and Kira, Zsolt},
  journal={arXiv preprint arXiv:1810.12488},
  year={2018}
}

@inproceedings{prabhu2020gdumb,
  title={Gdumb: A simple approach that questions our progress in continual learning},
  author={Prabhu, Ameya and Torr, Philip HS and Dokania, Puneet K},
  booktitle={European conference on computer vision},
  pages={524--540},
  year={2020},
  organization={Springer}
}

% Untersuchung über Rehearsal (MIR,GEM,Gdumb), Overfitting to border of first low-loss region %
@inproceedings{verwimp2021rehearsal,
  title={Rehearsal revealed: The limits and merits of revisiting samples in continual learning},
  author={Verwimp, Eli and De Lange, Matthias and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9385--9394},
  year={2021}
}

% CF Untersuchung, EWC hauptsächlich %
@article{pfulb2019comprehensive,
  title={A comprehensive, application-oriented study of catastrophic forgetting in dnns},
  author={Pf{\"u}lb, Benedikt and Gepperth, Alexander},
  journal={arXiv preprint arXiv:1905.08101},
  year={2019}
}

% Replay-Verfahren für CL Untersuchung (GEM,TEM,iCARL)
@inproceedings{bagus2021investigation,
  title={An Investigation of Replay-based Approaches for Continual Learning},
  author={Bagus, Benedikt and Gepperth, Alexander},
  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--9},
  year={2021},
  organization={IEEE}
}

% CF Untersuchung in LSTMs %
@inproceedings{schak2019study,
  title={A study on catastrophic forgetting in deep LSTM networks},
  author={Schak, Monika and Gepperth, Alexander},
  booktitle={International Conference on Artificial Neural Networks},
  pages={714--728},
  year={2019},
  organization={Springer}
}

% DL for network traffic forecasting %
@inproceedings{pfulb2019study,
  title={A study of deep learning for network traffic data forecasting},
  author={Pf{\"u}lb, Benedikt and Hardegen, Christoph and Gepperth, Alexander and Rieger, Sebastian},
  booktitle={International Conference on Artificial Neural Networks},
  pages={497--512},
  year={2019},
  organization={Springer}
}

% (AG) Untersuchung, Generatoren VAE/GANs %
@inproceedings{dzemidovich2022empirical,
  title={An empirical comparison of generators in replay-based continual learning},
  author={Dzemidovich, Nadzeya and Gepperth, Alexander},
  booktitle={European Symposium on Artificial Neural Networks (ESANN)},
  year={2022}
}

% GANs and GMMs, probabilistic modelling
@article{richardson2018gans,
  title={On gans and gmms},
  author={Richardson, Eitan and Weiss, Yair},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

% THEORETICAL DRIFT/SHIFT EXPLANATION OF CL %
@misc{lesort2021understanding,
  title={Understanding Continual Learning Settings with Data Distribution Drift Analysis}, 
  author={Timothée Lesort and Massimo Caccia and Irina Rish},
  year={2021},
  eprint={2104.01678},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

% THEORETICAL ANALYSIS OF CF %
@misc{doan2021theoretical,
  title={A Theoretical Analysis of Catastrophic Forgetting through the NTK Overlap Matrix}, 
  author={Thang Doan and Mehdi Bennani and Bogdan Mazoure and Guillaume Rabusseau and Pierre Alquier},
  year={2021},
  eprint={2010.04003},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

% EVAL: EWC, GR, Rehearsal & Baselines %
@inproceedings{lesort2019generative,
  title={Generative models from the perspective of continual learning},
  author={Lesort, Timoth{\'e}e and Caselles-Dupr{\'e}, Hugo and Garcia-Ortiz, Michael and Stoian, Andrei and Filliat, David},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%
%%% Theory, Oldies %%%
%%%%%%%%%%%%%%%%%%%%%%

% CF Phänomen %
@incollection{mccloskey1989catastrophic, 
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}
% Lebenslanges Lernen für autonome Roboter %
@article{thrun1995lifelong, 
  title={Lifelong robot learning},
  author={Thrun, Sebastian and Mitchell, Tom M},
  journal={Robotics and autonomous systems},
  volume={15},
  number={1-2},
  pages={25--46},
  year={1995},
  publisher={Elsevier}
}
% Stabilität-Plastizität Dilemma %
@article{carpenter1987art, 
  title={ART 2: Self-organization of stable category recognition codes for analog input patterns},
  author={Carpenter, Gail A and Grossberg, Stephen},
  journal={Applied optics},
  volume={26},
  number={23},
  pages={4919--4930},
  year={1987},
  publisher={Optical Society of America}
}
% Pseudo-rehearsal to mitigate CF % 
@article{robins1995catastrophic,
  title={Catastrophic forgetting, rehearsal and pseudorehearsal},
  author={Robins, Anthony},
  journal={Connection Science},
  volume={7},
  number={2},
  pages={123--146},
  year={1995},
  publisher={Taylor \& Francis}
}
% Dual-Memory (pseudo-recurrent) connectionist networks to mitigate CF %
@article{french1997pseudo, 
  title={Pseudo-recurrent connectionist networks: An approach to the'sensitivity-stability'dilemma},
  author={French, Robert M},
  journal={Connection Science},
  volume={9},
  number={4},
  pages={353--380},
  year={1997},
  publisher={Taylor \& Francis}
}
% DNN Interpretability (Black-Box models) %
@article{lipton2018mythos,
  title={The Mythos of Model Interpretability: In machine learning, the concept of interpretability is both important and slippery.},
  author={Lipton, Zachary C},
  journal={Queue},
  volume={16},
  number={3},
  pages={31--57},
  year={2018},
  publisher={ACM New York, NY, USA}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Use Cases, Application %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Shows importance for "on the job learning" for AI systems %
@inproceedings{liu2020learning,
  title={Learning on the job: Online lifelong and continual learning},
  author={Liu, Bing},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={09},
  pages={13544--13549},
  year={2020}
}
% Review für CL Use-Cases %
@article{shaheen2021continual, 
  title={Continual Learning for Real-World Autonomous Systems: Algorithms, Challenges and Frameworks},
  author={Shaheen, Khadija and Hanif, Muhammad Abdullah and Hasan, Osman and Shafique, Muhammad},
  journal={arXiv preprint arXiv:2105.12374},
  year={2021}
}
% ImageNet CNN %
@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  pages={1097--1105},
  year={2012}
}
 % Object Detection: Face Detection - F R-CNN %
@inproceedings{jiang2017face,
  title={Face detection with the faster R-CNN},
  author={Jiang, Huaizu and Learned-Miller, Erik},
  booktitle={2017 12th IEEE international conference on automatic face \& gesture recognition (FG 2017)},
  pages={650--657},
  year={2017},
  organization={IEEE}
}
% Object Detection: Pedestrian Detection - F R-CNN %
@inproceedings{zhang2016faster, 
  title={Is faster R-CNN doing well for pedestrian detection?},
  author={Zhang, Liliang and Lin, Liang and Liang, Xiaodan and He, Kaiming},
  booktitle={European conference on computer vision},
  pages={443--457},
  year={2016},
  organization={Springer}
}
% One-Stage OD Framework, YOLO mit Experience Replay %
@article{shieh2020continual, 
  title={Continual Learning Strategy in One-Stage Object Detection Framework Based on Experience Replay for Autonomous Driving Vehicle},
  author={Shieh, Jeng-Lun and Haq, Muhamad Amirul and Karam, Said and Chondro, Peter and Gao, De-Qin and Ruan, Shanq-Jang and others},
  journal={Sensors},
  volume={20},
  number={23},
  pages={6777},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}
% Traffic sign recognition with subset GAN (GR) %
@inproceedings{brahma2018subset, 
  title={Subset replay based continual learning for scalable improvement of autonomous systems},
  author={Brahma, Pratik Prabhanjan and Othon, Adrienne},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  pages={1179--11798},
  year={2018},
  organization={IEEE}
}
% Robotics learning %
@article{cangelosi2018babies,
  title={From babies to robots: the contribution of developmental robotics to developmental psychology},
  author={Cangelosi, Angelo and Schlesinger, Matthew},
  journal={Child Development Perspectives},
  volume={12},
  number={3},
  pages={183--188},
  year={2018},
  publisher={Wiley Online Library}
}
% CL ist Machine Learning Antwort zu Developmental Robotics %
@article{lungarella2003developmental,
  title={Developmental robotics: a survey},
  author={Lungarella, Max and Metta, Giorgio and Pfeifer, Rolf and Sandini, Giulio},
  journal={Connection science},
  volume={15},
  number={4},
  pages={151--190},
  year={2003},
  publisher={Taylor \& Francis}
}
% Robotic Framework für Object Tracking %
@article{cassimatis2004integrating,
  title={Integrating cognition, perception and action through mental simulation in robots},
  author={Cassimatis, Nicholas L and Trafton, J Gregory and Bugajska, Magdalena D and Schultz, Alan C},
  journal={Robotics and Autonomous Systems},
  volume={49},
  number={1-2},
  pages={13--23},
  year={2004},
  publisher={Elsevier}
}
% Freehand Gesture Recognition %
@inproceedings{schak2020multi,
  title={On Multi-modal Fusion for Freehand Gesture Recognition},
  author={Schak, Monika and Gepperth, Alexander},
  booktitle={International Conference on Artificial Neural Networks},
  pages={862--873},
  year={2020},
  organization={Springer}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%
%%% Replay Methods %%%
%%%%%%%%%%%%%%%%%%%%%%%
%
% REPLAY:	
	% GEN REPLAY:
		% VAE-BASED:
			% CCLUGM \cite{lavda2018continual}
			% LLGM \cite{ramapuram2020lifelong}
			% DMN \cite{kamra2017deep}
			% S-TRIGGER (RL) \cite{caselles2021s} 		
		% GAN-BASED:
			% DGR \cite{shin2017continual}
			% PR \cite{atkinson2018pseudo}
			% RePR \cite{atkinson2021pseudo}
			% DGM \cite{ostapenko2019learning}
			% CloGAN \cite{rios2018closed}
			% MeRGAN \cite{wu2018memory}
			% ESGR \cite{he2018exemplar}
			% ORDisCo \cite{wang2021ordisco}
			
		% OTHER:
			% PR \cite{robins1995catastrophic} - Oldie.. but Gen. Replay!
			% MRGR \cite{lesort2019marginal} - Presents both... GAN & VAE
			% L-VAEGAN \cite{ye2020learning} - Mix of VAE/GAN
			
			% FearNet \cite{kemker2017fearnet}
			% CCG \cite{abati2020conditional}
			% CER \cite{rostami2019complementary}
			% DMRSO \cite{parisi2018lifelong}
			% FRCL \cite{titsias2019functional}
			% HNET \cite{von2019continual}
			% MNEMONICS \cite{liu2020mnemonics}

			% GMR \cite{pfulb2021overcoming} 
			
	% GEN. REPRESENTATIONAL REPLAY:
		% BI-R \cite{van2020brain}
		% DAFR \cite{lao2020continuous}
		
	% CONSTRAINT-BASED:
		% GEM \cite{lopez2017gradient}
		% A-GEM \cite{chaudhry2018efficient}
		% TEM \cite{chaudhry2019tiny}
		% GSS \cite{aljundi2019gradient}
		% MIR \cite{
		% NSR(+) \cite{bagus2021investigation}

	% REHEARSAL:
		% iCaRL \cite{rebuffi2017icarl}
		% ER \cite{rolnick2019experience}
		% SER \cite{isele2018selective}
		% CoPE \cite{de2021continual}
		% GeppNet \cite{gepperth2016bio}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% GENERATIVE-REPLAY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%
%%% GANs %%%
%%%%%%%%%%%%

% Generative replay: Deep Generative Replay (DGR) %
@article{shin2017continual,
  title={Continual learning with deep generative replay},
  author={Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
  journal={arXiv preprint arXiv:1705.08690},
  year={2017}
}

% Generative replay: Pseudo-Rehearsal (PR) %
@article{atkinson2018pseudo,
  title={Pseudo-recursal: Solving the catastrophic forgetting problem in deep neural networks},
  author={Atkinson, Craig and McCane, Brendan and Szymanski, Lech and Robins, Anthony},
  journal={arXiv preprint arXiv:1802.03875},
  year={2018}
}

% Generative replay: Pseudo-Rehearsal for RL (RePR) %
@article{atkinson2021pseudo,
  title={Pseudo-rehearsal: Achieving deep reinforcement learning without catastrophic forgetting},
  author={Atkinson, Craig and McCane, Brendan and Szymanski, Lech and Robins, Anthony},
  journal={Neurocomputing},
  volume={428},
  pages={291--307},
  year={2021},
  publisher={Elsevier}
}

% Generative replay: Dynamic Generative Memory with neural masking (DGM) %
@inproceedings{ostapenko2019learning,
  title={Learning to remember: A synaptic plasticity driven framework for continual learning},
  author={Ostapenko, Oleksiy and Puscas, Mihai and Klein, Tassilo and Jahnichen, Patrick and Nabi, Moin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11321--11329},
  year={2019}
}

% Generative replay: Closed-Loop Memory GAN (CloGAN) %
@article{rios2018closed,
  title={Closed-loop memory GAN for continual learning},
  author={Rios, Amanda and Itti, Laurent},
  journal={arXiv preprint arXiv:1811.01146},
  year={2018}
}

% Generative replay: Memory Replay GAN (MeRGAN) %
@article{wu2018memory,
  title={Memory replay gans: Learning to generate new categories without forgetting},
  author={Wu, Chenshen and Herranz, Luis and Liu, Xialei and van de Weijer, Joost and Raducanu, Bogdan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

% Generative replay: Exemplar-Supported Generative Reproduction (ESGR) %
@inproceedings{he2018exemplar,
  title={Exemplar-Supported Generative Reproduction for Class Incremental Learning.},
  author={He, Chen and Wang, Ruiping and Shan, Shiguang and Chen, Xilin},
  booktitle={BMVC},
  pages={98},
  year={2018}
}

% Generative replay: Online Replay with Discriminator Consistency (ORDisCo) %
@inproceedings{wang2021ordisco,
  title={Ordisco: Effective and efficient usage of incremental unlabeled data for semi-supervised continual learning},
  author={Wang, Liyuan and Yang, Kuo and Li, Chongxuan and Hong, Lanqing and Li, Zhenguo and Zhu, Jun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5383--5392},
  year={2021}
}

%%%%%%%%%%%%
%%% VAEs %%%
%%%%%%%%%%%%

% Generative replay: Continual Classification Learning Using Generative Models (CCLUGM) %
@article{lavda2018continual,
  title={Continual classification learning using generative models},
  author={Lavda, Frantzeska and Ramapuram, Jason and Gregorova, Magda and Kalousis, Alexandros},
  journal={arXiv preprint arXiv:1810.10612},
  year={2018}
}

% Generative replay: Lifelong Generative Modelling (LLGM) %
@article{ramapuram2020lifelong,
  title={Lifelong generative modeling},
  author={Ramapuram, Jason and Gregorova, Magda and Kalousis, Alexandros},
  journal={Neurocomputing},
  volume={404},
  pages={381--400},
  year={2020},
  publisher={Elsevier}
}

% Generative replay: Deep generative dual memory network (DMN) %
@article{kamra2017deep,
  title={Deep generative dual memory network for continual learning},
  author={Kamra, Nitin and Gupta, Umang and Liu, Yan},
  journal={arXiv preprint arXiv:1710.10368},
  year={2017}
}

% Generative replay (RL): Self-Triggered Generative Replay (S-TRIGGER) %
@inproceedings{caselles2021s,
  title={S-trigger: Continual state representation learning via self-triggered generative replay},
  author={Caselles-Dupr{\'e}, Hugo and Garcia-Ortiz, Michael and Filliat, David},
  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--7},
  year={2021},
  organization={IEEE}
}

%%%%%%%%%%%%%
%%% OTHER %%%
%%%%%%%%%%%%%

% Generative replay: Condition & Marginal Replay (CR/MR) %
@inproceedings{lesort2019marginal,
  title={Marginal replay vs conditional replay for continual learning},
  author={Lesort, Timoth{\'e}e and Gepperth, Alexander and Stoian, Andrei and Filliat, David},
  booktitle={International Conference on Artificial Neural Networks},
  pages={466--480},
  year={2019},
  organization={Springer}
}

% Generative replay: Lifelong VAEGAN (L-VAEGAN) %
@inproceedings{ye2020learning,
  title={Learning latent representations across multiple data domains using lifelong vaegan},
  author={Ye, Fei and Bors, Adrian G},
  booktitle={European Conference on Computer Vision},
  pages={777--795},
  year={2020},
  organization={Springer}
}

% Generative replay: Conditional Channel Gated Network (CCG) %
@inproceedings{abati2020conditional,
  title={Conditional channel gated networks for task-aware continual learning},
  author={Abati, Davide and Tomczak, Jakub and Blankevoort, Tijmen and Calderara, Simone and Cucchiara, Rita and Bejnordi, Babak Ehteshami},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3931--3940},
  year={2020}
}

% Generative replay: Brain-insipired Model (FearNet) %
@article{kemker2017fearnet,
  title={Fearnet: Brain-inspired model for incremental learning},
  author={Kemker, Ronald and Kanan, Christopher},
  journal={arXiv preprint arXiv:1711.10563},
  year={2017}
}

% Generative replay: Complementary Learning using Experience Replay (CER) %
@article{rostami2019complementary,
  title={Complementary learning for overcoming catastrophic forgetting using experience replay},
  author={Rostami, Mohammad and Kolouri, Soheil and Pilly, Praveen K},
  journal={arXiv preprint arXiv:1903.04566},
  year={2019}
}

% Generative replay: Dual-Memory Recurrent Self-Organization (DMRSO) %
@article{parisi2018lifelong,
  title={Lifelong learning of spatiotemporal representations with dual-memory recurrent self-organization},
  author={Parisi, German I and Tani, Jun and Weber, Cornelius and Wermter, Stefan},
  journal={Frontiers in neurorobotics},
  volume={12},
  pages={78},
  year={2018},
  publisher={Frontiers Media SA}
}

% Generative replay: Functional Regularisation with Gaussian Processes (FRCL) %
@article{titsias2019functional,
  title={Functional regularisation for continual learning with gaussian processes},
  author={Titsias, Michalis K and Schwarz, Jonathan and Matthews, Alexander G de G and Pascanu, Razvan and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1901.11356},
  year={2019}
}

% Generative replay: Hypernetworks (HNET) %
@article{von2019continual,
  title={Continual learning with hypernetworks},
  author={Von Oswald, Johannes and Henning, Christian and Sacramento, Jo{\~a}o and Grewe, Benjamin F},
  journal={arXiv preprint arXiv:1906.00695},
  year={2019}
}

% Generative replay: Mnemonics Training (Mnemonics) %
@inproceedings{liu2020mnemonics,
  title={Mnemonics training: Multi-class incremental learning without forgetting},
  author={Liu, Yaoyao and Su, Yuting and Liu, An-An and Schiele, Bernt and Sun, Qianru},
  booktitle={Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition},
  pages={12245--12254},
  year={2020}
}

% Generative replay: Pseudo-Rehearsal (PR) %
% CHECK: robins1995catastrophic %


% (AG) Generative replay: Gaussian Mixture Replay (GMR) %
@article{pfulb2021overcoming,
  title={Overcoming Catastrophic Forgetting with Gaussian Mixture Replay},
  author={Pf{\"u}lb, Benedikt and Gepperth, Alexander},
  journal={arXiv preprint arXiv:2104.09220},
  year={2021}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% REPRESENTATIONAL-REPLAY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Representational replay: Replay through feedback (RTF) %
@article{van2020brain,
  title={Brain-inspired replay for continual learning with artificial neural networks},
  author={van de Ven, Gido M and Siegelmann, Hava T and Tolias, Andreas S},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={1--14},
  year={2020},
  publisher={Nature Publishing Group}
}

% Representational replay: Domain-Agnostic Feature Replay (DAFR) %
@article{lao2020continuous,
  title={Continuous domain adaptation with variational domain-agnostic feature replay},
  author={Lao, Qicheng and Jiang, Xiang and Havaei, Mohammad and Bengio, Yoshua},
  journal={arXiv preprint arXiv:2003.04382},
  year={2020}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% CONSTRAINT-REPLAY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% CONSTRAINT: Gradient Episodic Memory (GEM) %
@article{lopez2017gradient,
  title={Gradient episodic memory for continual learning},
  author={Lopez-Paz, David and Ranzato, Marc'Aurelio},
  journal={Advances in neural information processing systems},
  volume={30},
  pages={6467--6476},
  year={2017}
}

% CONSTRAINT: A-GEM %
@article{chaudhry2018efficient,
  title={Efficient lifelong learning with a-gem},
  author={Chaudhry, Arslan and Ranzato, Marc'Aurelio and Rohrbach, Marcus and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:1812.00420},
  year={2018}
}

% CONSTRAINT: Gradient based Sample Selection (GSS) %
@article{aljundi2019gradient,
  title={Gradient based sample selection for online continual learning},
  author={Aljundi, Rahaf and Lin, Min and Goujaud, Baptiste and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1903.08671},
  year={2019}
}

% CONSTRAINT: Maximally Interfered Retrieval (MIR) %
@article{aljundi2019online,
  doi = {10.48550/ARXIV.1908.04742},
  url = {https://arxiv.org/abs/1908.04742},
  author = {Aljundi, Rahaf and Caccia, Lucas and Belilovsky, Eugene and Caccia, Massimo and Lin, Min and Charlin, Laurent and Tuytelaars, Tinne},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Online Continual Learning with Maximally Interfered Retrieval},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% REHEARSAL %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% (AG) Rehearsal: GeppNet %
@article{gepperth2016bio,
  title={A bio-inspired incremental learning architecture for applied perceptual problems},
  author={Gepperth, Alexander and Karaoguz, Cem},
  journal={Cognitive Computation},
  volume={8},
  number={5},
  pages={924--934},
  year={2016},
  publisher={Springer}
}

% Rehearsal: ICARL %
@inproceedings{rebuffi2017icarl,
  title={icarl: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={2001--2010},
  year={2017}
}

% Rehearsal: Experience Replay (ER) %
@article{rolnick2019experience,
  title={Experience replay for continual learning},
  author={Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy and Wayne, Gregory},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={350--360},
  year={2019}
}

% Rehearsal: Selective Experience Replay (SER) %
@inproceedings{isele2018selective,
  title={Selective experience replay for lifelong learning},
  author={Isele, David and Cosgun, Akansel},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

% Rehearsal: Tiny Episodic Memories (TEM) %
@article{chaudhry2019tiny,
  title={On tiny episodic memories in continual learning},
  author={Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Ajanthan, Thalaiyasingam and Dokania, Puneet K and Torr, Philip HS and Ranzato, Marc'Aurelio},
  journal={arXiv preprint arXiv:1902.10486},
  year={2019}
}

% Rehearsal: Continual Prototype Evolution (CoPE) %
@inproceedings{de2021continual,
  title={Continual prototype evolution: Learning online from non-stationary data streams},
  author={De Lange, Matthias and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8250--8259},
  year={2021}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Regularization Methods %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% REGULARIZATION-BASED:
	% PRIOR-FOCUSED:
		% EWC \cite{kirkpatrick2017overcoming}
		% R-EWC \cite{liu2018rotate}
		% Online-EWC (P&C) \cite{schwarz2018progress}
		% IMM \cite{lee2017overcoming}
		% SI \cite{zenke2017continual}
		% MAS \cite{aljundi2018memory}
		% Online-MAS \cite{aljundi2019task}
		% R-WALK \cite{chaudhry2018riemannian}
		% VCL \cite{nguyen2017variational}
		% BGD \cite{zeno2018task}
		% UCL \cite{ahn2019uncertainty}
	% KNOWLEDGE DISTILLATION (DATA-FOCUSED):
		% LwF \cite{li2017learning}
		% LfL \cite{jung2016less}
		% DMC \cite{zhang2020class}
		% EBLL \cite{rannen2017encoder}
		% AR1 \cite{maltoni2019continuous}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PRIOR-FOCUSED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Prior-focused: Elastic Weight Consolidation (EWC) %
@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

% Prior-focused: Rotate EWC (R-EWC) %
@inproceedings{liu2018rotate,
  title={Rotate your networks: Better weight consolidation and less catastrophic forgetting},
  author={Liu, Xialei and Masana, Marc and Herranz, Luis and Van de Weijer, Joost and Lopez, Antonio M and Bagdanov, Andrew D},
  booktitle={2018 24th International Conference on Pattern Recognition (ICPR)},
  pages={2262--2268},
  year={2018},
  organization={IEEE}
}

% Prior-focused: Online EWC (Progress & Compress) %
@inproceedings{schwarz2018progress,
  title={Progress \& compress: A scalable framework for continual learning},
  author={Schwarz, Jonathan and Czarnecki, Wojciech and Luketina, Jelena and Grabska-Barwinska, Agnieszka and Teh, Yee Whye and Pascanu, Razvan and Hadsell, Raia},
  booktitle={International Conference on Machine Learning},
  pages={4528--4537},
  year={2018},
  organization={PMLR}
}

% Prior-focused: Incremental Moment Matching (IMM) %
@article{lee2017overcoming,
  title={Overcoming catastrophic forgetting by incremental moment matching},
  author={Lee, Sang-Woo and Kim, Jin-Hwa and Jun, Jaehyun and Ha, Jung-Woo and Zhang, Byoung-Tak},
  journal={arXiv preprint arXiv:1703.08475},
  year={2017}
}

% Prior-focused: Synaptic Intelligence (SI) %
@inproceedings{zenke2017continual,
  title={Continual learning through synaptic intelligence},
  author={Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  booktitle={International Conference on Machine Learning},
  pages={3987--3995},
  year={2017},
  organization={PMLR}
}

% Prior-focused: Memory Aware Synapses (MAS) %
@inproceedings{aljundi2018memory,
  title={Memory aware synapses: Learning what (not) to forget},
  author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={139--154},
  year={2018}
}

% Prior-focused: MAS in a Online Setting %
@inproceedings{aljundi2019task,
  title={Task-free continual learning},
  author={Aljundi, Rahaf and Kelchtermans, Klaas and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11254--11263},
  year={2019}
}

% Prior-focused: Riemannian-Walk (RW) %
@inproceedings{chaudhry2018riemannian,
  title={Riemannian walk for incremental learning: Understanding forgetting and intransigence},
  author={Chaudhry, Arslan and Dokania, Puneet K and Ajanthan, Thalaiyasingam and Torr, Philip HS},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={532--547},
  year={2018}
}

% Prior-focused: Variational Continual Learning (VCL) %
@article{nguyen2017variational,
  title={Variational continual learning},
  author={Nguyen, Cuong V and Li, Yingzhen and Bui, Thang D and Turner, Richard E},
  journal={arXiv preprint arXiv:1710.10628},
  year={2017}
}

% Prior-focused: Bayesian Gradient Descent (BGD) %
@article{zeno2018task,
  title={Task agnostic continual learning using online variational bayes},
  author={Zeno, Chen and Golan, Itay and Hoffer, Elad and Soudry, Daniel},
  journal={arXiv preprint arXiv:1803.10123},
  year={2018}
}

% Prior-focused: Uncertainty-regularized Continual Learning (UCL) %
@article{ahn2019uncertainty,
  title={Uncertainty-based continual learning with adaptive regularization},
  author={Ahn, Hongjoon and Cha, Sungmin and Lee, Donggyu and Moon, Taesup},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% KNOWLEDGE DISTILL %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Knowledge Distillation/Data focused: OG paper %
@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
  journal={arXiv preprint arXiv:1503.02531},
  volume={2},
  number={7},
  year={2015}
}

% Knowledge Distillation/Data focused: Learning without Forgetting (LwF) %
@article{li2017learning,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={12},
  pages={2935--2947},
  year={2017},
  publisher={IEEE}
}

% Knowledge Distillation/Data focused: Less Forgetting Learning (LFL) %
@article{jung2016less,
  title={Less-forgetting learning in deep neural networks},
  author={Jung, Heechul and Ju, Jeongwoo and Jung, Minju and Kim, Junmo},
  journal={arXiv preprint arXiv:1607.00122},
  year={2016}
}

% Knowledge Distillation/Data focused: Deep Model Consolidation (DMC) %
@inproceedings{zhang2020class,
  title={Class-incremental learning via deep model consolidation},
  author={Zhang, Junting and Zhang, Jie and Ghosh, Shalini and Li, Dawei and Tasci, Serafettin and Heck, Larry and Zhang, Heming and Kuo, C-C Jay},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1131--1140},
  year={2020}
}

% Knowledge Distillation/Data focused: Encoder Based Lifelong Learning (EBLL) %
@inproceedings{rannen2017encoder,
  title={Encoder based lifelong learning},
  author={Rannen, Amal and Aljundi, Rahaf and Blaschko, Matthew B and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1320--1328},
  year={2017}
}

% Knowledge Distillation/Data focused: AR1 %
@article{maltoni2019continuous,
  title={Continuous learning in single-incremental-task scenarios},
  author={Maltoni, Davide and Lomonaco, Vincenzo},
  journal={Neural Networks},
  volume={116},
  pages={56--73},
  year={2019},
  publisher={Elsevier}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Parameter Isolation Methods %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PARAMETER ISOLATION
	% FIXED NETWORK / ROUTING:
		% HAT \cite{serra2018overcoming}
		% PackNet \cite{mallya2018packnet}
		% PathNet \cite{fernando2017pathnet}
		% Piggyback \cite{mallya2018piggyback}
	
	% DYNAMIC ARCHITECTURE:
		% ExpertGate \cite{aljundi2017expert}
		% Online-EWC (P&C) \cite{schwarz2018progress}
		% PNN \cite{rusu2016progressive}
		% RCL \cite{xu2018reinforced}
		% DAN \cite{rosenfeld2018incremental}
		% DEN \cite{yoon2017lifelong}
		% XdG \cite{masse2018alleviating}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% FIXED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Fixed Network / Routing: HAT %
@inproceedings{serra2018overcoming,
  title={Overcoming catastrophic forgetting with hard attention to the task},
  author={Serra, Joan and Suris, Didac and Miron, Marius and Karatzoglou, Alexandros},
  booktitle={International Conference on Machine Learning},
  pages={4548--4557},
  year={2018},
  organization={PMLR}
}

% Fixed Network / Routing: PackNet %
@inproceedings{mallya2018packnet,
  title={Packnet: Adding multiple tasks to a single network by iterative pruning},
  author={Mallya, Arun and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={7765--7773},
  year={2018}
}

% Fixed Network / Routing: PathNet %
@article{fernando2017pathnet,
  title={Pathnet: Evolution channels gradient descent in super neural networks},
  author={Fernando, Chrisantha and Banarse, Dylan and Blundell, Charles and Zwols, Yori and Ha, David and Rusu, Andrei A and Pritzel, Alexander and Wierstra, Daan},
  journal={arXiv preprint arXiv:1701.08734},
  year={2017}
}

% Fixed Network / Routing: Piggyback %
@inproceedings{mallya2018piggyback,
  title={Piggyback: Adapting a single network to multiple tasks by learning to mask weights},
  author={Mallya, Arun and Davis, Dillon and Lazebnik, Svetlana},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={67--82},
  year={2018}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DYNAMIC %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Dynamic Architecture: ExpertGate %
@inproceedings{aljundi2017expert,
  title={Expert gate: Lifelong learning with a network of experts},
  author={Aljundi, Rahaf and Chakravarty, Punarjay and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3366--3375},
  year={2017}
}

% Dynamic Architecture: Online-EWC/Progress&Compress (P&C) %
% see under regularization-based approaches \cite{schwarz2018progress}

% Dynamic Architecture: Progressive Neural Network (PNN) %
@article{rusu2016progressive,
  title={Progressive neural networks},
  author={Rusu, Andrei A and Rabinowitz, Neil C and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
  journal={arXiv preprint arXiv:1606.04671},
  year={2016}
}

% Dynamic Architecture: Reinforced Continual Learning (RCL) %
@article{xu2018reinforced,
  title={Reinforced continual learning},
  author={Xu, Ju and Zhu, Zhanxing},
  journal={arXiv preprint arXiv:1805.12369},
  year={2018}
}

% Dynamic Architecture: ICL with Deep Adaptation (DAN) %
@article{rosenfeld2018incremental,
  title={Incremental learning through deep adaptation},
  author={Rosenfeld, Amir and Tsotsos, John K},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={42},
  number={3},
  pages={651--663},
  year={2018},
  publisher={IEEE}
}

% Dynamic Architecture: Neurogenesis Deep Learning (NDL) %
@inproceedings{draelos2017neurogenesis,
  title={Neurogenesis deep learning: Extending deep networks to accommodate new classes},
  author={Draelos, Timothy J and Miner, Nadine E and Lamb, Christopher C and Cox, Jonathan A and Vineyard, Craig M and Carlson, Kristofor D and Severa, William M and James, Conrad D and Aimone, James B},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
  pages={526--533},
  year={2017},
  organization={IEEE}
}

% Dynamic Architecture: Dynamically expandable networks (DEN) % 
@article{yoon2017lifelong,
  title={Lifelong learning with dynamically expandable networks},
  author={Yoon, Jaehong and Yang, Eunho and Lee, Jeongtae and Hwang, Sung Ju},
  journal={arXiv preprint arXiv:1708.01547},
  year={2017}
}

% Dynamic Architecture: Context-dependent gating (XdG) % 
@article{masse2018alleviating,
  title={Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization},
  author={Masse, Nicolas Y and Grant, Gregory D and Freedman, David J},
  journal={Proceedings of the National Academy of Sciences},
  volume={115},
  number={44},
  pages={E10467--E10475},
  year={2018},
  publisher={National Acad Sciences}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Incremental Learning (AG) %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{gepperth2016incremental,
  title={Incremental learning algorithms and applications},
  author={Gepperth, Alexander and Hammer, Barbara},
  booktitle={European symposium on artificial neural networks (ESANN)},
  year={2016}
}

@inproceedings{gepperth2018incremental,
  title={Incremental learning with deep neural networks using a test-time oracle.},
  author={Gepperth, Alexander and Gondal, Saad Abdullah},
  booktitle={ESANN},
  year={2018}
}

% SOM %
@inproceedings{gepperth2017incremental,
  title={Incremental learning with self-organizing maps},
  author={Gepperth, Alexander and Karaoguz, Cem},
  booktitle={2017 12th International Workshop on Self-Organizing Maps and Learning Vector Quantization, Clustering and Data Visualization (WSOM)},
  pages={1--8},
  year={2017},
  organization={IEEE}
}

@article{gepperth2020incremental,
  title={Incremental learning with a homeostatic self-organizing neural model.},
  author={Gepperth, Alexander},
  journal={Neural Computing \& Applications},
  volume={32},
  number={24},
  year={2020}
}

% FIM computation for EWC,IMM %
@inproceedings{gepperth2019simplified,
  title={Simplified computation and interpretation of fisher matrices in incremental learning with deep neural networks},
  author={Gepperth, Alexander and Wiech, Florian},
  booktitle={International Conference on Artificial Neural Networks},
  pages={481--494},
  year={2019},
  organization={Springer}
}

%%%%%%%%%%%
%%% GMM %%%
%%%%%%%%%%%

% DCGMMs image modelling %
@inproceedings{gepperth2021new,
title={A new perspective on probabilistic image modeling},
year = {2022},
booktitle={International Joint Conference on Neural Networks({IJCNN})},
author={Gepperth, A},
}

% CL mit GMR %
@article{pfulb2021continual,
  title={Continual Learning with Fully Probabilistic Models},
  author={Pf{\"u}lb, Benedikt and Gepperth, Alexander and Bagus, Benedikt},
  journal={arXiv preprint arXiv:2104.09240},
  year={2021}
}
% DCGMMs %
@article{gepperth2021image,
  title={Image Modeling with Deep Convolutional Gaussian Mixture Models},
  author={Gepperth, Alexander and Pf{\"u}lb, Benedikt},
  journal={arXiv preprint arXiv:2104.12686},
  year={2021}
}
% SGD training of GMMs %
@article{gepperth2021gradient,
  title={Gradient-based training of Gaussian Mixture Models for High-Dimensional Streaming Data},
  author={Gepperth, Alexander and Pf{\"u}lb, Benedikt},
  journal={Neural Processing Letters},
  volume={53},
  number={6},
  pages={4331--4348},
  year={2021},
  publisher={Springer}
}


%%%%%%%%%%%
%%% VAE %%%
%%%%%%%%%%%

% Variational Autoencoder %
@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

% conditional VAE%
@article{sohn2015learning,
  title={Learning structured output representation using deep conditional generative models},
  author={Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

% beta-VAE %
@article{higgins2016beta,
  title={beta-vae: Learning basic visual concepts with a constrained variational framework},
  author={Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
  year={2016}
}

% disentanglement %
@article{burgess2018understanding,
  title={Understanding disentangling in $$\backslash$beta $-VAE},
  author={Burgess, Christopher P and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
  journal={arXiv preprint arXiv:1804.03599},
  year={2018}
}

%%%%%%%%%%%
%%% GAN %%%
%%%%%%%%%%%

% Goodfellow Original (mathy) %
@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

% Goodfellow Short (non-mathy) %
@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

% Conditional GANs %
@article{mirza2014conditional,
  title={Conditional generative adversarial nets},
  author={Mirza, Mehdi and Osindero, Simon},
  journal={arXiv preprint arXiv:1411.1784},
  year={2014}
}

% Wasserstein GAN %
@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

% NVIDIA Style-based GANs %
@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4401--4410},
  year={2019}
}

% Overview/Review of GANs %
@article{creswell2018generative,
  title={Generative adversarial networks: An overview},
  author={Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A},
  journal={IEEE Signal Processing Magazine},
  volume={35},
  number={1},
  pages={53--65},
  year={2018},
  publisher={IEEE}
}

% MODE COLLAPSE %
@inproceedings{bau2019seeing,
  title={Seeing what a gan cannot generate},
  author={Bau, David and Zhu, Jun-Yan and Wulff, Jonas and Peebles, William and Strobelt, Hendrik and Zhou, Bolei and Torralba, Antonio},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4502--4511},
  year={2019}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%
%%% DATASETS %%%
%%%%%%%%%%%%%%%%

% MNIST %
@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

% EMNIST %
@inproceedings{cohen2017emnist,
  title={EMNIST: Extending MNIST to handwritten letters},
  author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and Van Schaik, Andre},
  booktitle={2017 international joint conference on neural networks (IJCNN)},
  pages={2921--2926},
  year={2017},
  organization={IEEE}
}

% iNaturalist %
@inproceedings{van2018inaturalist,
  title={The inaturalist species classification and detection dataset},
  author={Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8769--8778},
  year={2018}
}

% STL-10 (Unsupervised) %
@inproceedings{coates2011analysis,
  title={An analysis of single-layer networks in unsupervised feature learning},
  author={Coates, Adam and Ng, Andrew and Lee, Honglak},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={215--223},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

% CIFAR-100 %
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

% Fashion-MNIST %
@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}

% SVHN %
@article{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  year={2011}
}

% ImageNet %
@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

% CUB200 %
@article{wah2011caltech,
  title={The caltech-ucsd birds-200-2011 dataset},
  author={Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},
  year={2011},
  publisher={California Institute of Technology}
}

% CORe50 %
@inproceedings{lomonaco2017core50,
  title={Core50: a new dataset and benchmark for continuous object recognition},
  author={Lomonaco, Vincenzo and Maltoni, Davide},
  booktitle={Conference on Robot Learning},
  pages={17--26},
  year={2017},
  organization={PMLR}
}
