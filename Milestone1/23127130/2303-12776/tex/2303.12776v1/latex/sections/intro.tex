\begin{abstract} One-to-one label assignment in object detection has successfully obviated the need for non-maximum suppression (NMS) as postprocessing and makes the pipeline end-to-end. However, it triggers a new dilemma as the widely used sparse queries cannot guarantee a high recall, while dense queries inevitably bring more similar queries and encounter optimization difficulties. As both sparse and dense queries are problematic, then what are the expected queries in end-to-end object detection? This paper shows that the solution should be Dense Distinct Queries (DDQ). Concretely, we first lay dense queries like traditional detectors and then select distinct ones for one-to-one assignments. DDQ blends the advantages of traditional and recent end-to-end detectors and significantly improves the performance of various detectors including FCN, R-CNN, and DETRs. Most impressively, DDQ-DETR achieves 52.1 AP on MS-COCO dataset within 12 epochs using a ResNet-50 backbone, outperforming all existing detectors in the same setting. DDQ also shares the benefit of end-to-end detectors in crowded scenes and achieves 93.8 AP on CrowdHuman. We hope DDQ can inspire researchers to consider the complementarity between traditional methods and end-to-end detectors.  The source code can be found at \url{https://github.com/jshilong/DDQ}.

\end{abstract}
\section{Introduction} \label{sec:intro} Object detection is one of the most fundamental tasks in computer vision, which aims at answering \emph{what objects are in an image and where they are.} To achieve the objective, the detector is expected to detect all objects and mark each object with only one bounding box.

Due to the complex spatial distribution and the vast shape variance of objects, detecting all objects is quite challenging. To solve the problem, traditional detectors ~\cite{ren2015faster, lin2017focal, tian2019fcos}  first lay predefined dense grid queries$^1$\footnote{1 Anchors ~\cite{ren2015faster, lin2017focal} or anchor points ~\cite{tian2019fcos}  in conventional detectors play the same role as sparse object queries in \cite{carion2020end}. Hence, we collectively refer to densely distributed anchor boxes and anchor points as dense queries.} to achieve a high recall. Convolutions with shared weights are then applied to quickly process dense queries in a sliding-window manner. At last, one ground truth bounding box is assigned to multiple similar candidate queries for optimization. However, the one-to-many assignment results in redundant predictions and thus requires extra duplicate-removal operations  (\emph{e.g.}, non-maximum suppression) during inference, which causes misaligned inference with training and hinders the pipeline from being end-to-end (as shown in Fig.~\ref{fig:framework}(a)). 


This paradigm is broken by DETR~\cite{carion2020end}, which assigns only one positive query to each ground truth bounding box (one-to-one assignment) to achieve end-to-end. This scheme requires heavy computation to refine queries and adopts self-attention to model interactions between queries to facilitate the optimization of one-to-one assignment, which unfortunately limits the number of queries. For example, DETR only initializes hundreds of learnable object queries. Therefore, compared to the densely distributed queries in conventional detectors, the sparse queries fall short in recall rate, as shown in Fig.~\ref{fig:framework}(b).

Some recent works have also tried to integrate dense queries into one-to-one assignment~\cite{wang2021end, pmlr-v139-sun21b, yao2021efficient}. However, dense queries in end-to-end detectors face unique challenges. For example, our analysis shows that this paradigm would inevitably introduce many similar queries (potentially representing the same instance) and that it suffers difficult and inefficient optimization as similar queries are assigned opposite labels under one-to-one assignment.(Fig.~\ref{fig:framework}.(c)). 


Now that both sparse queries (low recall) and dense queries (optimization difficulty) under one-to-one assignment are sub-optimal, \emph{what are the expected queries in
end-to-end object detection?}

In this study, we demonstrate that the solution should be \emph{dense distinct queries (DDQ)}, meaning that the queries for object detection should be both densely distributed to detect all objects and also distinct from each other to facilitate the optimization of one-to-one label assignment. Guided by such a principle, we consistently improve the performance of various detector architectures, including FCN, R-CNN, and DETRs. For one-stage detectors composed of fully convolutional networks (FCN), we first propose a pyramid shuffle operation to replace heavy self-attentions to model the interaction between dense queries. Then, a distinct queries selection scheme ensures that the one-to-one assignment is only imposed on the selected distinct queries, preventing contradictory labels from being assigned to similar queries.  Such an end-to-end one-stage detector is named \textbf{DDQ FCN} and achieves state-of-the-art performance in one-stage detectors. DDQ also naturally extends to DETR and R-CNN structures~\cite{zhu2020deformable, liu2021dab, dai2021dynamicdetr, sun2021sparse} by first laying dense queries as in~\cite{zhu2020deformable} and then selecting distinct queries for later refining stages, which are respectively dubbed \textbf{DDQ R-CNN} and \textbf{DDQ DETR}.


We have conducted experiments on two datasets---MS-COCO~\cite{lin2014microsoft} and CrowdHuman~\cite{shao2018crowdhuman}.  DDQ FCN and DDQ R-CNN obtain 41.5/44.6 AP, respectively, on the MS-COCO detection dataset ~\cite{lin2014microsoft} with the standard 1x schedule\cite{ren2015faster,lin2017focal}. Compared to recent DETRs, DDQ DETR achieved 52.1 AP in just 12 epochs with the DETR-style augmentation~\cite{carion2020end}.  The strong performance demonstrates that DDQ overcomes the optimization difficulty in end-to-end detectors and converges as fast as traditional detectors with higher performance. 

Object detection in crowded scenes such as CrowdHuman~\cite{shao2018crowdhuman} is another arena to testify to the effectiveness of DDQ. It is extremely cumbersome to tune the post-processing NMS in traditional detectors, as a low IoU threshold leads to missing overlapping objects, while a high threshold brings too many false positives. Recent end-to-end structures also struggle to distinguish between duplicated predictions and overlapping objects due to their difficult optimization. In this study, DDQ FCN/R-CNN/DETR achieve  92.7/93.5/93.8 AP and 98.2/98.6/98.7 recall on CrowdHuman~\cite{shao2018crowdhuman}, surpassing both traditional and end-to-end detectors by a large margin. 

