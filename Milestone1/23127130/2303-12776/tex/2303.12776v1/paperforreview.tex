% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
%\usepackage[review]{cvpr}      % To produce the EVIEW version
%\usepackage{cvpr}              % To produce the CAMERA-READY version
\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{multicol}


\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}
\usepackage{tablefootnote}
\usepackage[table]{xcolor}  % to use more color with table

\usepackage[accsupp]{axessibility}  % Improves PDF readability for those with disabilities.





\usepackage{algorithm}



\definecolor{deemph}{gray}{0.6}
\definecolor{ourscolor}{gray}{.9}
\newcommand{\ours}[1]{\cellcolor{ourscolor}{#1}}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\newcommand{\shilong}[1]{{\color{red}{(shilong: #1)}}}
\newcommand{\wxj}[1]{{\color{red}{(WXJ: #1)}}}

\renewcommand{\thefootnote}{} 
\pagenumbering{arabic}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{ Dense Distinct Query for End-to-End Object Detection}



\author{Shilong Zhang\textsuperscript{\rm 1,3 *},  \space\space
        Xinjiang Wang\textsuperscript{\rm 2 *},\space\space
        Jiaqi Wang\textsuperscript{\rm 1},\space\space
        Jiangmiao Pang\textsuperscript{\rm 1}, \\
        Chengqi Lyu\textsuperscript{\rm 1},\space\space
        Wenwei Zhang\textsuperscript{\rm 4,1},\space\space
        Ping Luo\textsuperscript{\rm 3,1},\space\space
        Kai Chen\textsuperscript{\rm 1}\\
        \small
        \textsuperscript{\rm 1}Shanghai AI Laboratory  \space \space
        \small\textsuperscript{\rm 2} SenseTime Research \\
        \small\textsuperscript{\rm 3} The University of Hong Kong \space \space
        \small\textsuperscript{\rm 4} S-Lab, Nanyang Technological University  \\
   %\tt\small \{zhangshilong, chenkai\}@pjlab.org.cn, wangxinjiang@sensetime.com 
    }




\twocolumn[{
\maketitle  
\vspace{-14mm}
\centering

\begin{figure}[H]
\hspace{6mm}
\hsize=\textwidth
\includegraphics[width=0.95\textwidth]{latex/resources/fig1v8.pdf} 
\caption{Pros and Cons of different queries and their corresponding learning paradigms. }
\label{fig:framework}
\end{figure}
}]

\footnotetext{* Equal contribution.}
\input{latex/sections/intro}
\input{latex/sections/related_works}
\input{latex/sections/method}
\input{latex/sections/results}

\section{Acknowledgement}
This project is supported by the National Key R\&D Program of China No.2022ZD0161600, No.2022ZD0161000 and the General Research Fund of HK No.17200622.


\section{Conclusions}

This paper reveals that both sparse and dense queries in end-to-end detection are problematic. We propose that the expected queries should be both dense and distinct. Such a paradigm significantly improves the performance
of various detectors including FCN, R-CNN, and DETRs. This proves the paradigm blends advantages from the traditional detectors and the recent end-to-end detectors. We hope it can inspire researchers to consider the complementarity between traditional methods and end-to-end detectors.

\clearpage
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\clearpage
\appendix
\input{latex/sections/sub}
\clearpage

\end{document}
