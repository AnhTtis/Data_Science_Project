\section{Experiments}
\label{sec:results}
In this section, we first introduce two standard benchmarks MS COCO~\cite{lin2014microsoft} and CrowdHuman~\cite{shao2018crowdhuman}. Then we introduce the setting of training and inference on both datasets. We also present three examples to show how  end-to-end detectors with different architectures evolve to our DDQ step by step. At last, we compare DDQ with state-of-the-art conventional detectors and recent end-to-end detectors on MS COCO and CrowdHuman, which show that DDQ blends the advantages of two design paradigms. The latency of current popular models and DDQ is compared in our supplementary material.

\subsection{Datasets}
MS COCO 2017~\cite{lin2014microsoft} detection dataset is mainly used for comparison and ablation studies. It contains 118k training, 5k validation images, and 20k test images without annotations. There are on average 7 instances per image in this dataset. We report bounding box mean average precision (AP) as the performance metric, which is the mean average precision over multiple thresholds. If not specified, AP on the validation set is set as default. 

Besides, we also report the performance on the CrowdHuman dataset~\cite{shao2018crowdhuman}, which has 15k training images and 4.4k validation images with around 23 heavily occluded instances per image. For evaluation, we use AP, mMR, and Recall as the metrics. mMR means the average log miss rate over false positives per image ranging in $\left[10^{-2}, 10^0\right]$ following the official report \cite{shao2018crowdhuman}. A lower value of mMR means a better quality of high-scoring bounding boxes. All evaluation results are reported on the CrowdHuman validation subset. 

\subsection{Setting}
\noindent\textbf{COCO} ResNet-50~\cite{he2016deep} is the default backbone in this study if not specified. Most models adopt the 1x(12 epochs) training protocol in MMDetection~\cite{chen2019mmdetection}. AdamW~\cite{loshchilov2018decoupled} optimizer is used. For DDQ FCN, we set the initial learning rate to \textbf{$5\times 10^{-5}$} and weight decay to 0.1. For DDQ R-CNN, we used a learning rate of \textbf{$10^{-4}$} and weight decay of 0.05. The learning rate for both two CNN-based detectors decayed with a ratio of 0.1 at epoch 9 and epoch 12. For DDQ DETR, we utilized a learning rate of \textbf{$2\times 10^{-4}$} and a weight decay of 0.05, and the learning rate decayed with a ratio of 0.1 at epoch 12 only. To ensure a fair comparison with other studies, we classified our data augmentation into three types \label{link:aug}: \emph{Normal}, \emph{Multi-Scale}, and \emph{DETR}. \emph{Normal} augmentation rescaled images to a short side of 800 pixels, with only random flips applied. For \emph{Multi-Scale} augmentation, we used the classic multi-scale training range (480--800). Finally, the \emph{DETR} augmentation followed that of the study by Carion et al.~\cite{carion2020end}. 

\noindent\textbf{CrowdHuman} ResNet-50~\cite{he2016deep} is the default backbone. All conventional detectors and DDQ  adopt the 3x (36 epochs) schedule with multi-scale training~(480-800). All optimizer-related parameters are consistent with the setting on COCO. For end-to-end detectors with sparse queries, we follow the schedule(50 epochs) in Sparse R-CNN due to their slow convergence. The max detected instance number is changed to 500 for all conventional detectors following the \cite{wang2021end}. For a fair comparison, We increase the number of queries to 500 for DDQ FCN/R-CNN, Sparse R-CNN, and Deform DETR. For DDQ DETR, we just keep the same 900 queries as COCO.

\subsection{Evolving to DDQ}
In this section, we show how  detectors of different architectures evolve to DDQ. We can validate the importance of both density and distinctness from such a progressive development.

\noindent\textbf{From FCOS* to DDQ FCN} In Table.~\ref{tab:fcos-ddq},  We start from an FCOS equipped with the bipartite matching algorithm in DETR~\cite{carion2020end} and our main loss components mentioned in Sec.~\ref{sec:mainloss}, which is denoted as FCOS*. We adopt the \emph{normal} augmentation that is mentioned in \ref{link:aug} and train the model for 12 epochs. Due to the lack of cross-level interaction, its performance is quite unstable and fluctuates between 24.5 AP and 36.5 AP in a few successful experiments. We select the best result 36.5 as our baseline. After adding pyramid shuffle operations to interact with cross-level queries, the training becomes stable and gets 1.1 AP improvement with only 0.2 G flops and 0.2 ms latency increase. Adding a distinct queries selection operation boosts the performance from 37.6 AP to 40.6 AP with only 0.3 ms latency. Such a 3 AP improvement demonstrates that the distinctness of queries is vital for the one-to-one assignment. After adding an auxiliary loss for dense queries following DeFCN~\cite{wang2021end}, we get DDQ FCN with a state-of-the-art performance of 41.5 AP. DQS on the strong baseline (equipped with pyramid shuffle and
auxiliary loss) can be found in Table.~\ref{tab:distinct}. DQS still improves 2 AP (from 39.5 to 41.5).
\begin{table}[!h]
    \centering
    \vspace{-2mm}
    \caption{\textbf{From FCOS* to DDQ FCN.} PS stands for pyramid shuffle, and DQS means distinct queries selection operation. We also report the latency(L) and the flops(F).}
     \scalebox{0.90}{
    \begin{tabular}{l|c|c|c|c|c}
    \hline
        Method  & AP & AP$_{50}$ & AP$_{75}$ & L(ms) & F(G) \\
        \hline
        FCOS*  &36.5 & 54.4 & 40.3 & 21.9 & 200.5 \\
        \hline
        + \textbf{PS}  & 37.6  & 56.3 & 41.3& 22.1 & 200.7 \\
        \hline
        +\textbf{DQS}  & 40.6  & 60.3 & 44.5 & 22.4 & 200.7 \\
        \hline
        DDQ FCN  & 41.5 & 60.9 & 45.4 & 22.4 & 200.7  \\


\end{tabular}}
\vspace{-3mm}
\label{tab:fcos-ddq}
\end{table}


\noindent\textbf{From Sparse R-CNN to DDQ R-CNN} Table. \ref{tab:sparse-ddq} shows a progressive development from Sparse R-CNN to DDQ R-CNN. Sparse R-CNN with 300 queries achieves 39.4 AP within 12 epochs using the \emph{normal} augmentation that is mentioned in Sec.\ref{link:aug}. Increasing the number of queries to 7000 improves the performance to 40.6 AP, at the cost of a quite heavy detector. Applying a distinct queries selection at the beginning of each stage boosts the performance by 2.5 AP to 43.1 AP. At last, by replacing the first four refining stages with our DDQ FCN, which not only makes the structure more light-weighted but also allows even denser input queries, the performance further increases to 44.6 AP.
%Such an implementation has almost the same latency compared with the original Sparse R-CNN while being significantly superior in performance. 

\begin{table}[!h]
    \centering
    \caption{\textbf{From Sparse R-CNN to DDQ R-CNN}. Q means the query, and DQS stands for the distinct queries selection }
     \scalebox{0.90}{
    \begin{tabular}{l|c|c|c|c|c}
    \hline
        Method & AP & AP$_{50}$ & AP$_{75}$  & L(ms) & F(G) \\
        \hline
        Sparse R-CNN  & 39.4 & 57.7 & 42.5  & 31.0 &160.2 \\
        \hline
        +7000Q  & 40.6 & 58.7  & 44.0 & 135.0 & 781.0\\
        \hline
        +\textbf{DQS}  & 43.1 & 62.6 &  47.1& 135.0 & 781.0 \\
        \hline
        DDQ R-CNN & 44.6 & 63.0 & 48.8 & 31.3 & 248.5  \\

    \end{tabular}}
\vspace{-3mm}
    \label{tab:sparse-ddq}
\end{table}


\noindent\textbf{From Deformable DETR* to DDQ DETR} Table \ref{tab:ddq-detr} illustrates the progressive development from Deformable DETR* to DDQ DETR. Deformable DETR* achieves 45.4 AP with 900 queries within 12 epochs using the DETR augmentation mentioned in Sec.\ref{link:aug}. By employing a linear layer to process the dense queries on the feature pyramid and constructing content parts with feature embeddings, the performance increases to 48.5 AP. However, initializing the content part as Two-Stage Deformable DETR(TS D-DETR) with mapped coordinates only achieves 46.7 AP, which is due to the lack of distinctness in the coordinates compared to the feature embedding. Adding an auxiliary loss for the decoder improves performance to 50.0 AP. Furthermore, by adding DQS before each refining stage, the performance further increases to 50.7 AP. Finally, by adding the P2 feature and 100 CDN queries as in DINO~\cite{zhang2022dino}, we achieve an impressive 52.1 AP, surpassing all detectors in the same setting. We show  distinctness can be complementary to CDN in Table.~\ref{tab:distinct} and analyze the reason in our supplementary material.  

\begin{table}[!h]
    \centering
    \caption{\textbf{From Deformable DETR*(D-DETR)  to DDQ DETR}. TS D-DETR stands for the naive two-stage version. Dense means initializing the content part with feature embedding. DQS stands for distinct queries selection. AUX-Decoder means the auxiliary loss for dense queries in the decoder. The flops only has comparative meaning and does not contain custom cuda operators}
     \scalebox{0.90}{
    \begin{tabular}{l|c|c|c|c|c}
    \hline
        Method & AP & AP$_{50}$ & AP$_{75}$  & L(ms) & F(G) \\
        \hline
        D-DETR*  & 45.4 & 63.0 & 49.1  & 45 & 264 \\
        \hline
        TS D-DETR  & 46.7 & 64.5 & 50.8  & 46 & 269 \\
        \hline
        +\textbf{Dense}  & 48.5 & 66.2  & 52.7 & 47 & 270 \\
        \hline
        +AUX-Decoder  & 50.0 & 67.4 & 54.8 & 47 &  270 \\
        \hline
        +\textbf{DQS}  & 50.7 & 68.1 & 55.7 & 58 & 270 \\
        \hline
        DDQ DETR$_{5 scale}$ & 52.1 & 68.9 &  57.3 & 114 & 860 \\
        \hline

    \end{tabular}}
\vspace{-3mm}
    \label{tab:ddq-detr}
\end{table}

\subsection{Comparison with Other Detectors}

\noindent \textbf{Results on CrowdHuman}  We select some recent representative studies for comparison with DDQ on crowded scenes. It is seen that traditional detectors struggle between a low recall rate and a high false positive rate. Although DW~\cite{li2022dual} assignment is the recent state-of-the-art one-to-many assignment strategy and shows a clear increase in Recall compared to ATSS, it suffers from more serious false predictions and thus leads to a high mMR. The performance of such traditional detectors is limited by the post-processing NMS. In the supplementary material, we also show it can not be properly handled by adjusting the IoU threshold because it is training unaware.

End-to-end detectors can achieve a higher theoretical recall rate due to the removal of NMS as a post-process. However, a high recall is not guaranteed in Sparse R-CNN and Deformable DETR due to their sparse query design. Although DeFCN~\cite{wang2021end} achieves a better performance than other end-to-end methods by adopting dense queries, it is still difficult for DeFCN to distinguish between crowded objects and duplicated predictions(optimization difficulty) which affects the mMR.

\begin{table}[!h]

    \begin{center}
    \caption{Performance on CrowdHuman}
    \label{tab:crowdhuman}
     \scalebox{0.90}{
    \begin{tabular}{l|c|c|c|c}
    \hline
    Method &Epochs & AP$_{50}$& mMR & Recall \\
    \hline
    ATSS &36 & 89.6 & 44.4 & 95.9 \\
    DW &36 & 89.0 & 57.6 & 97.4 \\
    Cascade R-CNN &36  & 86.0 & 44.1 & 89.2 \\
    Sparse R-CNN & 50 & 89.2  & 48.3 & 95.9 \\
    Deform DETR & 50 & 89.1 & 50.0 &  95.3 \\
    DeFCN &36  & 91.0 & 46.5  & 97.9 \\
   % T-Deform DETR & 50 & 91.7 & 47.5 &  98.0 \\
    \ours{\textbf{DDQ FCN} }&\ours{36 }&\ours{\textbf{92.7} }&\ours{\textbf{41.0} }&\ours{\textbf{98.2}} \\
    \ours{\textbf{DDQ R-CNN} }&\ours{36  }&\ours{\textbf{93.5} }&\ours{\textbf{40.4}}&\ours{\textbf{98.6}} \\
    \ours{\textbf{DDQ DETR} }&\ours{36  }&\ours{\textbf{93.8} }&\ours{\textbf{39.7}}&\ours{\textbf{98.7}} \\
    \end{tabular}}
    \end{center}
\vspace{-4mm}
\end{table}

In contrast, DDQ surpasses these detectors on all metrics by a clear margin. For one thing, DDQ leads in Recall due to the dense queries that could cover most objects. For the other, DDQ also achieves the lowest mMR, as a merit of the distinctness among queries so that the detector can better differentiate false predictions.


\begin{table*}[!h]
    \vspace{-5mm}
    \centering
        \caption{Results on COCO Dataset. For DW, the * means we have retrained it with the same augmentation(480-800) as other methods using official implementation.} 
                \vspace{-1mm}
                
            \scalebox{0.90}{
    \begin{tabular}{l|c|c|c|c|c|c|c|c|c}
    \hline
        Method & Backbone  &  Val$/$Test   & Epochs   & AP & AP$_{50}$ & AP$_{75}$  & AP$_s$ & AP$_m$ & AP$_l$ \\
        \hline
        \hline
        \emph{\textbf{Aug:DETR}} \\

        Cascade R-CNN~\cite{cai2018cascade}  & ResNet-50 & val  & 36 & 44.3 & 62.4 & 48 & 26.6 & 47.7 & 57.7\\
        DAB DETR\cite{liu2021dab} & ResNet-50 & val & 50 &  42.6 & 63.2 & 45.6 & 21.8 & 46.2 & 61.1 \\
        DN-DETR\cite{Li_2022_CVPR} & ResNet-50 & val & 50 &  44.1 & 64.4 & 46.7 & 22.9 & 48.0 & 63.4 \\
        Deformable DETR~\cite{zhu2020deformable}& ResNet-50 & val  & 50  & 46.2 & 65.2 & 50.0 & 28.8 & 49.2 & 61.7 \\
        Efficient DETR ~\cite{yao2021efficient} & ResNet-50 & val & 36 & 44.2  & 62.2 & 48.0 & 28.4 & 47.5 & 56.6 \\
        Sparse R-CNN~\cite{sun2021sparse}& ResNet-50 & val & 36 & 45.0 & 63.4 &48.2& 26.9& 47.2 &59.5 \\
        DINO$_{4 scales}$~\cite{zhang2022dino}& ResNet-50 & val & 36 & 50.9 & 69.0 & 55.3 & 34.6 & 54.1 & 64.6 \\
        DINO$_{5 scales}$~\cite{zhang2022dino}& ResNet-50 & val & 36 & 51.2 & 69.0 & 55.8 & 35.0 & 54.3 & 65.3 \\

        \ours{\textbf{DDQ FCN}}& \ours{ResNet-50 }& \ours{val }& \ours{36 }& \ours{\textbf{44.8} }& \ours{64.1 }& \ours{49.4 }& \ours{29.9 }& \ours{47.8 }& \ours{56.0} \\
       \ours{\textbf{DDQ R-CNN}}& \ours{ResNet-50 }& \ours{val }& \ours{36 }& \ours{\textbf{48.1} }& \ours{66.6 }& \ours{53.0 }& \ours{32.3 }& \ours{51.2 }& \ours{60.7} \\
       \ours{\textbf{DDQ R-CNN}$_{with\_encoder}$}& \ours{ResNet-50 }& \ours{val }& \ours{36 }& \ours{\textbf{51.0} }& \ours{69.0 }& \ours{56.0 }& \ours{34.0 }& \ours{54.4 }& \ours{64.6} \\
                \ours{\textbf{DDQ DETR}$_{4 scales}$}& \ours{ResNet-50 }& \ours{val }& \ours{24}& \ours{\textbf{52.0} }& \ours{69.5}& \ours{57.2}& \ours{35.2}& \ours{54.9}& \ours{65.9} \\
                     \ours{\textbf{DDQ DETR}$_{5 scales}$}& \ours{ResNet-50 }& \ours{val }& \ours{24 }& \ours{\textbf{52.8} }& \ours{69.9}& \ours{58.1}& \ours{37.4}& \ours{55.7}& \ours{66.0} \\
                     \hline

                     
        Sparse R-CNN & ResNeXt-64x4d-101 & test-dev  & 36  & 46.9 & 66.3   &  51.2 & 28.6  & 49.2 & 58.7 \\
        Deformable DETR & ResNeXt-64x4d-101 & test-dev   & 50  & 49 & 68.5  & 53.2 & 29.7 & 51.7 & 62.8  \\
      \ours{\textbf{DDQ FCN}} & \ours{ResNeXt-64x4d-101} & \ours{test-dev }& \ours{36  }& \ours{\textbf{47.7} }& \ours{67.0  }& \ours{52.6 }& \ours{30.4 }& \ours{49.9 }& \ours{58.3} \\
    \ours{\textbf{DDQ R-CNN}} & \ours{ResNeXt-64x4d-101 }& \ours{test-dev }& \ours{36  }& \ours{\textbf{49.9} }& \ours{68.8  }& \ours{54.8 }& \ours{31.8 }& \ours{52.2 }& \ours{61.7} \\
    \hline
        Sparse R-CNN~\cite{sun2021sparse}& Swin-B & val & 36 & 50.8 & 70.4 & 55.6 & 33.9 & 53.7 & 65.9 \\
       \ours{\textbf{DDQ R-CNN}}& \ours{Swin-B }& \ours{val }& \ours{36 }& \ours{\textbf{52.8} }& \ours{72.2}& \ours{57.9 }& \ours{37.6 }& \ours{56.2 }& \ours{66.9} \\
    \hline
                     
        \hline
        H-DeformableDETR$_{4 scales}$& Swin-L & val & 36 & 57.6&  76.5&  63.2&  41.4&  61.7& 73.9 \\
                DINO$_{4 scales}$& Swin-L & val & 36 & 58.0 & 76.1 & 64.0 & 40.1 & 62.2 & 74.3  \\
                \ours{\textbf{DDQ DETR}$_{4 scales}$}& \ours{Swin-L }& \ours{val }& \ours{30}& \ours{\textbf{58.7}}& \ours{76.8}& \ours{64.5}& \ours{41.6}& \ours{62.9}& \ours{74.3} \\
            \ours{\textbf{DDQ DETR}$_{4 scales}$}& \ours{Swin-L }& \ours{test-dev }& \ours{30 }& \ours{\textbf{58.8} }& \ours{77.0 }& \ours{64.6 }& \ours{39.4}& \ours{62.1}& \ours{74.0} \\

    
        \hline
        \hline
        \emph{\textbf{Aug:Multi-Scale }} \\

        ATSS~\cite{zhang2020bridging} & ResNet-101 & test-dev & 24 & 43.6 & 62.1  &  47.4  &  26.1 &  47.0 & 53.6 \\
        PAA~\cite{kim2020probabilistic}  & ResNet-101 & test-dev & 24 & 44.8 & 63.3 & 48.7   & 26.5  & 48.8 & 56.3 \\

        OTA~\cite{ge2021ota} & ResNet-101 & test-dev & 24 & 45.3 & 63.5 & 49.3   & 26.9  & 48.8 & 56.1 \\
        DW* \cite{li2022dual} & ResNet-101 & test-dev & 24 & 45.8 & 64.6 & 49.6  & 27.3  & 48.9 & 57.0 \\
      \ours{\textbf{DDQ FCN}} & \ours{ResNet-101} & \ours{test-dev} & \ours{24} & \ours{\textbf{45.9}} & \ours{65.1} & \ours{50.7} & \ours{28.3} &\ours{48.6} & \ours{55.6} \\


    \end{tabular}}

    \label{tab:comparison_coco}
\end{table*}

\noindent \textbf{Results on COCO} We adopt heavier backbones and longer schedules to fairly compare with other detectors on COCO. As shown in Table.~\ref{tab:comparison_coco}, we get all the results from the original study except those marked with *. We divide the results into two parts according to the augmentation. The first part adopts the augmentations in DETR~\cite{carion2020end} and reports the results on COCO validation dataset. DDQ remains its advantage among end-to-end object detectors using different backbone structures. It is worth emphasizing that DDQ FCN without any refinement architecture can already surpass most end-to-end detectors. DDQ R-CNN surpasses these methods by a large margin with only two refining heads and without encoder architecture. The performance of DDQ R-CNN (R-50) can be further improved by adopting an encoder structure as in SEPC~\cite{Wang_2020_CVPR} or DyHead~\cite{dai2021dynamichead}. For example, It achieves an impressive 51.0 AP by adopting 6 blocks in DyHead as encoder structure, which is denoted as DDQ R-CNN$_{with\_encoder}$(details about this model can be found in supplementary material). DDQ DETR outperforms recent DETR with a clear margin using R-50 as its backbone. When adopting a Swin-L backbone, it also surpasses the SOTA method DINO~\cite{zhang2022dino} by 0.7 AP.

The second part adopts a multi-scale training (480-800) strategy for 24 epochs and reports the results on the COCO test-dev using ResNet-101, which is widely used by conventional detectors.

\section{Ablation study}
\subsection{The Recall Improvement of Dense Queries}
\begin{table}[!h]
    \centering
    \vspace{-0.15cm}
    \caption{Recall improvement of dense distinct queries. Q means queries and DQS stands for the distinct queries selection. L stands for the latency of the model.}
     \scalebox{0.90}{
    \begin{tabular}{l|c|c|c|c}
    \hline
        Method   & AR$_{100}$    & AR$_{200}$  & AR$_{300}$ & L(ms) \\
        \hline
        Sparse R-CNN  & 78.4  & 83.4  & 85.5 &  31.0 \\
        \hline
        7000 Q \& DQS & 88.6 & 92.3  & 93.6 & 135.0  \\

        \hline
        \ours{DDQ R-CNN} &\ours{88.5} & \ours{91.8} & \ours{93.2} & \ours{31.3} \\

    \end{tabular}}

    \label{tab:recall}
\end{table}
We analyze the recall of IoU threshold 0.5. As shown in Table.~\ref{tab:recall}, we report the recall of the 5th stage input queries of Sparse R-CNN to make a fair comparison with the input queries of the refinement head in DDQ R-CNN. It can be seen that the Sparse R-CNN with 300 queries has a significantly lower recall(10.2 AR$_{100}$) than that with 7000 queries. In DDQ R-CNN, the queries from the DDQ FCN achieve a comparable recall to 7000 queries but with much less latency.
\vspace{-2mm}

\subsection{ DQS with Different IoU Threshold }
In this section, we show the robustness of distinct queries selection(DQS) with different IoU thresholds.  As shown in  Table.~\ref{tab:distinct}, the performance of DDQ FCN/R-CNN is quite robust when the IoU threshold ranges from 0.6 to 0.8. The performance drops slightly when the threshold is lower than 0.6, which is due to the lower recall rate for overlapping objects. The performance also starts to degrade when the IoU threshold is larger than 0.8 due to its incapability to suppress similar queries that slow the optimization. DDQ DETR exhibits a similar trend, as observed in Table~\ref{tab:ddq-detr}. We can find even though CDN training in ~\cite{zhang2022dino} has been adopted in DDQ DETR, distinctness still improves the performance. By the way, we also report the performance of ATSS~\cite{zhang2020bridging} at different post-processing NMS IoU thresholds and show its sensitivity to this hyperparameter, in contrast to the robust behavior of DDQ in which a class-agnostic NMS is adopted in both training and inference to filter out distinct queries.


\begin{table}[!h]
 \vspace{-2mm}
    \begin{center}
         \caption{Performance of DDQ on COCO when DQS adopts different IoU thresholds. Results of ATSS adopting different IoU thresholds in post-processing are also reported. None means we remove DQS or post-processing from the inference pipeline.* means the results are not stable and we report the average performance}
    \label{tab:distinct}
\scalebox{0.90}{
    \begin{tabular}{l|c|c|c|c|c|c}
     %\hspace{-7mm}
    \hline
         COCO   & 0.5 & 0.6 & 0.7 & 0.8 & 0.9 & None\\
      \hline
        DDQ FCN  &  40.8 & 41.4 & \ours{\textbf {41.5}}  & 41.4 & 40.5 & 39.5*  \\
         DDQ R-CNN & 44.0 & 44.5 & \ours{\textbf {44.6}} & 44.4 &  43.8  & 42.7* \\
        DDQ DETR & 50.1 & 50.7 & 50.9 & \ours{\textbf{51.3}} & 51.0 &   50.7*  \\
          
          ATSS  & 39.3 & \textbf{39.5} & 39.3 &38.7& 36.7 & 19.6\\


    \end{tabular}}
    \vspace{-5mm}
    \end{center}
\end{table}

\vspace{-2mm}


























