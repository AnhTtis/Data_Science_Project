\documentclass[11pt]{article}
\input{preamble}

\title{Learning linear dynamical systems under convex constraints}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

%\author{Denis Efimov \\ \texttt{denis.efimov@inria.fr} \and Hemant Tyagi\blfootnote{Authors in alphabetical order.}\\ \texttt{hemant.tyagi@inria.fr}} 
\author{ Hemant Tyagi\\ \texttt{hemant.tyagi@inria.fr} \and Denis Efimov\\ \texttt{denis.efimov@inria.fr}} 

\date{Inria, Univ. Lille, CNRS, UMR 8524 - Laboratoire Paul Painlev\'{e}, F-59000 \newline\newline
\today
} 

\begin{document}
\maketitle

%----------------
% Abstract
%
\begin{abstract}
  We consider the problem of finite-time identification of linear dynamical systems from a single trajectory. Recent results have predominantly focused on the setup where no structural assumption is made on the system matrix $A^* \in \matR^{n \times n}$, and have consequently analyzed the ordinary least squares (OLS) estimator in detail. We assume prior structural information on $A^*$ is available, which can be captured in the form of a convex set $\calK$ containing $\calA^*$. For the solution of the ensuing constrained least squares estimator, we derive non-asymptotic error bounds in the Frobenius norm which depend on the local size of the tangent cone of $\calK$ at $A^*$. To illustrate the usefulness of this result, we instantiate it for the settings where, (i) $\calK$ is a $d$ dimensional subspace of $\mathbb{R}^{n \times n}$, or (ii) $A^*$ is $k$-sparse and $\calK$ is a suitably scaled $\ell_1$ ball. In the regimes where $d, k \ll n^2$, our bounds improve upon those obtained from the OLS estimator.   
\end{abstract}

% Introduction
\input{intro}

% Problem setup and results
\input{prob_setup}

% Proof outline 
\input{proofs}

% Acknowledgment
\input{acks}

\newpage
\bibliographystyle{plain}
\bibliography{references}

\end{document}