\onecolumn 

\section*{A.1. Additional Results}

We extensively analyze our method on in-the-wild images across various domains such as nature, indoor settings, hypothetical scenarios, human actions, etc. All our ground-view input images are from Google Images, Flickr, and the TEDBench dataset~\cite{kawar2022imagic}. We present the results in Fig. $8 - 16$. 

\begin{figure*}
    \centering
    \includegraphics[scale=0.5]{Figures/supp_results1.png}
    \caption{\textbf{Results - Part 1.} We apply Aerial Diffusion on diverse images such as animals/ birds, natural scenes, human actions, indoor settings, etc and show that our method is able to generate high-quality high-fidelity aerial images.}
    \label{fig:supp_results1}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.5]{Figures/supp_results2.png}
    \caption{\textbf{Results - Part 2.} We apply Aerial Diffusion on diverse images such as animals/ birds, natural scenes, human actions, indoor settings, etc and show that our method is able to generate high-quality high-fidelity aerial images.}
    \label{fig:supp_results2}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.5]{Figures/supp_results3.png}
    \caption{\textbf{Results - Part 3.} We apply Aerial Diffusion on diverse images such as animals/ birds, natural scenes, human actions, indoor settings, etc and show that our method is able to generate high-quality high-fidelity aerial images.}
    \label{fig:supp_results3}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.5]{Figures/supp_results4.png}
    \caption{\textbf{Results - Part 4.} Based on the text description, Aerial Diffusion can generate aerial views with scene entities slightly different from the ground-view. The hallucination of background and unseen parts of the scene can also be controlled by text.}
    \label{fig:supp_results4}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.5]{Figures/supp_results8.png}
    \caption{\textbf{Results - Part 5.} Based on the text description, Aerial Diffusion can generate aerial views with scene entities slightly different from the ground-view. The hallucination of background and unseen parts of the scene can also be controlled by text.}
    \label{fig:supp_results4}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.5]{Figures/supp_results9.png}
    \caption{\textbf{Results - Part 6.} Based on the text description, Aerial Diffusion can generate aerial views with scene entities slightly different from the ground-view. The hallucination of background and unseen parts of the scene can also be controlled by text.}
    \label{fig:supp_results4}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.48]{Figures/supp_results5.png}
    \caption{\textbf{Effect of $\alpha$.} Low values of $\alpha$ generate images that are less aerial, high values of $\alpha$ generate low-fidelity images. A trade-off between the viewpoint and fidelity generates high-fidelity aerial images. The transformation, with $\alpha$, is not smooth, reinforcing Postulate 2.}
    \label{fig:supp_results5}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.5]{Figures/supp_results6.png}
    \caption{\textbf{State-of-the-art comparisons.} We compare with the state-of-the-art text-based image translation method, IMAGIC~\cite{kawar2022imagic} (CVPR 2023). IMAGIC is unable to generate a high-fidelity {\bf aerial-view} image. It merely reproduces the ground-view image, despite tuning all hyperparameters exhaustively. The hyperparameter $\eta$ (in IMAGIC~\cite{kawar2022imagic}) takes values between $0$ and $1$, and is unable to generate a high fidelity {\em aerial} image for any value of $\eta$. When $\eta$ is increased to a value higher than $1$, the model generates an aerial image but the fidelity with respect to the ground-view is completely lost. Other methods (contemporary/prior to IMAGIC~\cite{kawar2022imagic} (CVPR 2023)) such as DDIB~\cite{su2022dual} (ICLR 2023), DreamBooth~\cite{ruiz2022dreambooth} (CVPR 2023), SINE~\cite{zhang2022sine} (CVPR 2023), SDEdit~\cite{meng2021sdedit}(ICLR 2022) and Text2LIVE~\cite{bar2022text2live}(ECCV 2022) face the same issues. These are due to the challenges involved in ground-to-aerial translation described in Section 1 and Section 3.1 of our paper.}
    \label{fig:supp_results6}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.45]{Figures/supp_results7.png}
    \caption{\textbf{Failure cases.} Our method is unable to generate high fidelity aerial views of scenes that have high complexity with multiple objects or scene entities, especially when the {\em text description} of the scene is {\em brief and inadequate}. This is a direction for future work.}
    \label{fig:supp_results7}
\end{figure*}

\section*{A.2. User study}

We quantitatively evaluate Aerial Diffusion's performance via a human perceptual evaluation study. We conduct the following types of evaluation:
\begin{enumerate}
    \item {\bf Image Quality: } Given a ground-view image and an aerial-view image generated using Aerial Diffusion, we ask participants to determine if the generated aerial-view image is a high fidelity (w.r.t. ground-view image) aerial-view image; and rate the image on the 5-point Likert scale. The average rating over 10 images (rated by 49 participants) is 3.289.   
    
    \item {\bf Alternating Sampling: } Given a ground-view image and two aerial-view images generated using Aerial Diffusion and Ablation 2 (i.e. Aerial Diffusion without the Alternating Sampling method) respectively, we ask participants to choose the better high fidelity aerial-view image. {\bf 83.05}$\%$ of the participants rate the image generated using Aerial Diffusion as the one with a higher quality. 
        
    \item {\bf Reference for Aerial Diffusion:} Given a ground-view image and two aerial-view images generated using Aerial Diffusion and Ablation 3 (Aerial Diffusion with $e_{tgt}$ instead of $e_{src}$ while training) respectively, we ask participants to choose the higher fidelity aerial-view image. {\bf 78.125}$\%$ of the participants rate the image generated using Aerial Diffusion as the one with a higher quality. 

\end{enumerate}
