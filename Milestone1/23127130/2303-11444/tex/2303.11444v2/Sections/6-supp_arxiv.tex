\begin{figure*}
    \centering
    \includegraphics[scale=0.5]{Figures/supp_results2.png}
    \caption{\textbf{Results.} We apply Aerial Diffusion on diverse images such as animals/ birds, natural scenes, human actions, indoor settings, etc and show that our method is able to generate high-quality high-fidelity aerial images.}
    \label{fig:supp_results2}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.5]{Figures/supp_results3.png}
    \caption{\textbf{Results.} We apply Aerial Diffusion on diverse images such as animals/ birds, natural scenes, human actions, indoor settings, etc and show that our method is able to generate high-quality high-fidelity aerial images.}
    \label{fig:supp_results3}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.45]{Figures/supp_results4.png}
    \caption{\textbf{Results.} Based on the text description, Aerial Diffusion can generate aerial views with scene entities slightly different from the ground-view. The hallucination of background and unseen parts of the scene can also be controlled by text.}
    \label{fig:supp_results4}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.5]{Figures/supp_results8.png}
    \caption{\textbf{Results.} Based on the text description, Aerial Diffusion can generate aerial views with scene entities slightly different from the ground-view. The hallucination of background and unseen parts of the scene can also be controlled by text.}
    \label{fig:supp_results4}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.5]{Figures/supp_results9.png}
    \caption{\textbf{Results.} Based on the text description, Aerial Diffusion can generate aerial views with scene entities slightly different from the ground-view. The hallucination of background and unseen parts of the scene can also be controlled by text.}
    \label{fig:supp_results4}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.42]{Figures/supp_results6.png}
    \caption{\textbf{State-of-the-art comparisons.} We compare with the state-of-the-art text-based image translation method, IMAGIC~\cite{kawar2022imagic} (CVPR 2023). IMAGIC is unable to generate a high-fidelity {\bf aerial-view} image. It merely reproduces the ground-view image, despite tuning all hyperparameters exhaustively. The hyperparameter $\eta$ (in IMAGIC~\cite{kawar2022imagic}) takes values between $0$ and $1$, and is unable to generate a high fidelity {\em aerial} image for any value of $\eta$. When $\eta$ is increased to a value higher than $1$, the model generates an aerial image but the fidelity with respect to the ground-view is completely lost. Other methods (contemporary/prior to IMAGIC~\cite{kawar2022imagic} (CVPR 2023)) such as DDIB~\cite{su2022dual} (ICLR 2023), DreamBooth~\cite{ruiz2022dreambooth} (CVPR 2023), SINE~\cite{zhang2022sine} (CVPR 2023), SDEdit~\cite{meng2021sdedit}(ICLR 2022) and Text2LIVE~\cite{bar2022text2live}(ECCV 2022) face the same issues. These are due to the challenges involved in ground-to-aerial translation described in Section 1 and Section 3.1 of our paper.}
    \label{fig:supp_results6}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.48]{Figures/supp_results5.png}
    \caption{\textbf{Effect of $\alpha$.} Low values of $\alpha$ generate images that are less aerial, high values of $\alpha$ generate low-fidelity images. A trade-off between the viewpoint and fidelity generates high-fidelity aerial images. The transformation, with $\alpha$, is not smooth, reinforcing Postulate 2.}
    \label{fig:supp_results5}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[scale=0.45]{Figures/supp_results7.png}
    \caption{\textbf{Failure cases.} Our method is unable to generate high fidelity aerial views of scenes that have high complexity with multiple objects or scene entities, especially when the {\em text description} of the scene is {\em brief and inadequate}. This is a direction for future work.}
    \label{fig:supp_results7}
\end{figure*}

