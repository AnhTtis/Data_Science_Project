\section{The Model}
\label{sec:model}

A stage game $G = (n, A_1, \dots, A_n, u_1, \dots, u_n)$ in normal form consists of $n$ players, each player $i$'s strategy space $A_i$, and each player $i$'s payoff function $u_i: A \rightarrow \real$, where $A = A_1 \times A_2 \times \dots \times A_n$. We assume $n$ and $A$ are finite. Throughout this chapter, we use $a$ to denote pure strategies (or actions) in the stage game and $\sigma$ to denote mixed strategies in the stage game, e.g. $a_i\in A_i$ denotes a pure strategy for player $i$ and $\sigma_i \in \Delta A_i$ denotes a mixed strategy for player $i$, both for the stage game, where $\Delta S$ denotes the set of probability distributions over set $S$. We use $S_{\sigma_i} = \condSet{a}{a\in A_i, \sigma_i(a) > 0}$ to denote the support for mixed strategy $\sigma_i$. A strategy profile $\vsigma = (\sigma_1, \dots, \sigma_n)$ is a set of strategies for all players. In general, we use bold symbols to represent collections over players. For convenience, we use $u_i(\vsigma)$ to denote the expected payoff of player $i$ under the (mixed) strategy profile $\vsigma$. A strategy $\sigma_i$ is a \textit{best response} to the strategy profile of the other players $\vsigma_{-i}$ if $u_i(\sigma_i, \vsigma_{-i}) = \max_{\sigma_i' \in \Delta A_i} u_i(\sigma_i', \vsigma_{-i})$. A strategy profile $\vsigma$ is a \textit{Nash equilibrium} (NE) if for all player $i\in[n]$ ($[n]$ denotes the set $\{1,\dots, n\}$), $\sigma_i$ is a best response to $\vsigma_{-i}$. We use $\textrm{Nash}(G)$ to denote the set of all Nash equilibria of the stage game $G$. We use $V_i = \condSet{u_i(\vsigma)}{\vsigma\in\Nash(G)}$ to denote the set of payoff values attainable at Nash equilibria for player $i$.

We use $G(T)$ to denote the game where $G$ is played repeatedly for $T$ rounds, where $T$ is a positive integer. Denote the \textit{outcome} in round $t\in[T]$ as $\va^t \in A$. Player $i$'s total payoff in the repeated game $G(T)$ is $U_i = \sum_{t=1}^T u_i(\va^t)$. A strategy of player $i$ in $G(T)$ specifies which actions to take in each round given any history of play in the previous rounds. Formally, denote a \textit{history} of play in the first $k$ rounds as $h(k) = (\va^1, \dots, \va^k)$, and the set of all possible $k$-round histories as $H(k) = A^k$ ($H(0)$ denotes the singleton set containing the empty history). A (mixed) strategy of player $i$ in $G(T)$ can be represented as $\mu_i: H \rightarrow \Delta A_i$, where $H = \cup_{k=0}^{T-1} H(k)$ is the set of all histories. This form of representation is also commonly known as \textit{behavior strategies}. We use $\vmu = (\mu_1,\dots,\mu_n)$ to denote strategy profiles of $G(T)$, and the concept of best response and Nash equilibrium are defined in the same way as for the stage game. 

In this paper, we focus on \textit{subgame-perfect equilibria} (SPE) of $G(T)$. SPE was originally introduced by \cite{Selten1965,Selten1975} to eliminate NEs that involve non-credible threats off the equilibrium path. Given a strategy $\mu_i$ of player $i$ for $G(T)$, denote $\mu_{i|h(k)}$ as the resulting strategy for subgame $G(T-k)$ obtained by conditioning $\mu_i$ on some history $h(k)$.
Formally, given $h(k) = (\va^1, \dots, \va^k)$, $\mu_{i|h(k)}$ is given by: 1) $\mu_{i|h(k)}(h(0)) = \mu_i(\va^1, \dots, \va^k)$; 2) for any $t<T-k$ and any $(\vc^1, \vc^2, \dots, \vc^t)\in H(t)$, $\mu_{i|h(k)}(\vc^1, \vc^2, \dots, \vc^t) = \mu_i(\va^1, \dots, \va^k, \vc^1, \vc^2, \dots, \vc^t)$.
And denote $\vmu_{|h(k)} = (\mu_{1|h(k)}, \dots, \mu_{n|h(k)})$. A strategy profile $\vmu$ is an SPE if for all $0\leq k < T$ and all $h(k)\in H(k)$, $\vmu_{|h(k)}$ is an NE of $G(T-k)$. We use $\spe(G,T)$ to denote the set of all SPEs of the repeated game $G(T)$.

The phenomenon we are interested in is when in some SPE of the repeated game $G(T)$, the behavior strategy profile in some round does not form an NE of the stage game $G$. In other words, some player uses a locally suboptimal strategy in some round, in the sense that the strategy is not a best response for that round, as part of an SPE in the repeated game. We formally define this phenomenon of \phenom{} as follows.
\begin{definition}[\Phenom{}]
\label{def:local-sub}
\Phenom{} occurs in some SPE $\vmu$ of some repeated game $G(T)$ if there exists some $0\leq k < T$ and play history $h(k)\in H(k)$ where $\vmu(h(k)) = \Big(\mu_1(h(k)), \dots, \mu_n(h(k))\Big) \notin \textrm{Nash}(G)$, i.e. the behavior strategy profile at some round does not form an NE of the stage game. 
\end{definition}
We refer to such behavior strategy profiles that do not form an NE of the stage game as {\em off-(stage-game)-Nash} plays, or {\em off-Nash} plays in short.

Denote the set of all stage games $G$ as $\mathcal{G}$ ($\mathcal{G}$ is an infinite set). $\mathcal{G}$ can be partitioned into two disjoint subsets $\gls$ and $\glo$. $\gls$ is the set of stage games $G$ where \phenom{} occurs in some SPE of $G(T)$ for some $T$; $\glo$ is the set of stage games $G$ where \phenom{} never occurs in any SPE of $G(T)$ for any $T$ (LO stands for locally optimal). Our central research questions stated in \Cref{ques:cond} and \Cref{ques:comp} are essentially about solving the following problems: 1) completely characterize $\gls$ (thus $\glo$) using mathematical conditions, and 2) given any stage game $G$, algorithmically determine if $G$ is in $\gls$ or $\glo$.
