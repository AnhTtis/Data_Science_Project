%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%        5. Conclusion         %%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}
\label{sec:conclusion}
Our proposed speech enhancement model utilizes a speech quality MOS assessment metric in a joint learning manner and incorporate quantized ASR-style language model for better performance. The results show that it outperforms other models in both noisy and reverberant environments, as well as in unseen real-world noisy conditions. It shows that perceptually-relevant embeddings are useful for speech enhancement. However, we evaluate our model's subjective score using a MOS-estimation model. Additionally, our assessment model provides utterance-level feedback, which may be sub-optimal since the model's embeddings are calculated at the frame level. In our proposed LM, we consider only bi-gram spectral models which are generated by considering only along-time transitions.
In the future, we will explore higher-order N-gram models that consider both temporal and spectral transitions to enhance both magnitude and phase responses. We will address per-frame or window level perceptual score generation in future work.