
\documentclass[10pt]{article} % For LaTeX2e
%\usepackage{tmlr}
% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{tmlr}
% To de-anonymize and remove mentions to TMLR (for example for posting to preprint servers), instead use the following:
%\usepackage[preprint]{tmlr}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}

\usepackage{graphicx}
\usepackage{longtable}
\usepackage{amsmath}
\DeclareMathOperator{\trace}{tr}
\usepackage{enumerate}
\usepackage[edges]{forest}
% landscape orientation
\usepackage{lscape}

\newcommand{\indep}{\perp \!\!\! \perp}

% definition
\newtheorem{definition}{Definition}





%\title{Formatting Instructions for TMLR \\Journal Submissions}
%\title{A Survey on Causal Discovery Methods for Temporal and Non-Temporal Data}
\title{A Survey on Causal Discovery Methods for I.I.D. and Time Series Data}

% Authors must not appear in the submitted version. They should be hidden
% as long as the tmlr package is used without the [accepted] or [preprint] options.
% Non-anonymous submissions will be rejected without review.

% \author{\name Kyunghyun Cho \email kyunghyun.cho@nyu.edu \\
%       \addr Department of Computer Science\\
%       University of New York
%       \AND
%       \name Raia Hadsell \email raia@google.com \\
%       \addr DeepMind
%       \AND
%       \name Hugo Larochelle \email hugolarochelle@google.com\\
%       \addr Mila, Universit\'e de Montr\'eal \\
%       Google Research\\
%       CIFAR Fellow}


\author{\name Uzma Hasan \email uzmahasan@umbc.edu\\
       \addr Causal AI Lab\\
       Department of Information Systems\\
       University of Maryland, Baltimore County\\
       Baltimore, MD, USA
       \AND
       \name Emam Hossain \email emamh1@umbc.edu \\
       \addr  Causal AI Lab\\
       Department of Information Systems\\
       University of Maryland, Baltimore County\\
       Baltimore, MD, USA
       \AND
       \name Md Osman Gani \email mogani@umbc.edu \\
       \addr  Causal AI Lab\\
       Department of Information Systems\\
       University of Maryland, Baltimore County\\
       Baltimore, MD, USA}

% The \author macro works with any number of authors. Use \AND 
% to separate the names and addresses of multiple authors.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\def\month{MM}  % Insert correct month for camera-ready version
%\def\year{YYYY} % Insert correct year for camera-ready version
\def\month{09}  % Insert correct month for camera-ready version
\def\year{2023} % Insert correct year for camera-ready version
%\def\openreview{\url{https://openreview.net/forum?id=XXXX}} % Insert correct link to OpenReview for camera-ready version
\def\openreview{\url{https://openreview.net/forum?id=YdMrdhGx9y}} % Insert correct link to OpenReview for camera-ready version


\begin{document}


\maketitle

\begin{abstract}
The ability to understand causality from data is one of the major milestones of human-level intelligence. Causal Discovery (CD) algorithms can identify the cause-effect relationships among the variables of a system from related observational data with certain assumptions. Over the years, several methods have been developed primarily based on the statistical properties of data to uncover the underlying causal mechanism. In this study, we present an extensive discussion on the methods designed to perform causal discovery from both independent and identically distributed (I.I.D.) data and time series data. For this purpose, we first introduce the common terminologies used in causal discovery literature and then provide a comprehensive discussion of the algorithms designed to identify causal relations in different settings. We further discuss some of the benchmark datasets available for evaluating the algorithmic performance, off-the-shelf tools or software packages to perform causal discovery readily, and the common metrics used to evaluate these methods. We also evaluate some widely used causal discovery algorithms on multiple benchmark datasets and compare their performances. Finally, we conclude by discussing the research challenges and the applications of causal discovery algorithms in multiple areas of interest.
%involved in causal discovery, and also, discuss 

\end{abstract}

%% Competing Interests Declaration - Keeping it here for future reference
% The authors have no competing financial or non-financial interests including personal or professional relations with organizations and individuals that could potentially be perceived to influence the submitted work.


\section{Introduction}
\label{Introduction}
The identification of the cause-effect relationships among the variables of a system from the corresponding data is called Causal Discovery (CD). A major part of the causal analysis involves unfolding the \emph{cause and effect relationships} among the entities in complex systems that can help us build better solutions in health care, earth science, politics, business, education, and many other diverse areas (\cite{causalAnalysis}, \cite{nogueira2021causal}). The \emph{causal explanations} precisely the causal factors obtained from a causal analysis play an important role in decision-making and policy formulation as well as in foreseeing the consequences of interventions without actually doing them. Causal discovery algorithms enable the \emph{discovery of the underlying causal structure} given a set of observations. The underlying causal structure also known as a causal graph (CG) is a representation of the cause-effect relationships between the variables in the data (\cite{pearl2009causality}). Causal graphs represent the causal relationships with directed arrows from the cause to the effect. 
\begin{figure}[!b]
\centering
\includegraphics[width=0.43\linewidth]{CD.JPG} 
\caption{Causal Discovery: Identification of a causal graph from data.}
\label{CG}
\end{figure}
Discovering the causal relations, and thereby, the estimation of their effects would enable us to understand the underlying\textit{ data generating mechanism} (DGM) better, and take necessary interventional actions. %that are not possible by considering mere correlations only. 
However, traditional Artificial Intelligence (AI) applications rely solely on predictive models and often ignore causal knowledge. Systems without the knowledge of causal relationships often cannot make rational and informed decisions (\cite{marwala2015causality}). The result may be devastating when correlations are mistaken for causation. Because two variables can be highly correlated, and yet not have any causal influence on each other. There may be a third variable often called a latent confounder or hidden factor that may be causing both of them (see Figure \ref{Con} (a)). Thus, \emph{embedding the knowledge of causal relationships} in black-box AI systems is important to improve their explainability and reliability (\cite{dubois2020glance}, \cite{ganguly2023review}). In multiple fields such as healthcare, politics, economics, climate science, business, and education, the ability to understand causal relations can facilitate the formulation of better policies with a greater understanding of the data. 

\begin{figure}[h]
\centering
\includegraphics[width=0.2\linewidth] {LC.png} 
 \includegraphics[width=0.25\textwidth] {CANCER.png}\\
 (a) \hspace{3.9cm} (b)
\caption{(a) Latent confounder $L$ causes both variables $S$ and $C$, and the association between $S$ and $C$ is denoted by  $\textbf{?}$ which can be mistaken as causation. The graph in (b) is a causal graph depicting the causes and effects of cancer (\cite{CANCER}).}
\label{Con}
\end{figure}

% AI applications equipped with causal knowledge can perform a virtual experiment when conducting randomized control trials (RCTs) are impossible. 
The standard approach to discover the cause-effect relationships is to perform randomized control trials (RCTs) (\cite{sibbald1998understanding}). However, RCTs are often infeasible to conduct due to high costs and some ethical reasons (\cite{resnik2008randomized}). As a result, over the last few decades, researchers have developed a variety of methods to unravel causal relations from purely observational data (\cite{s1}, \cite{s3}). These methods are often based on some assumptions about the data and the underlying mechanism. The \emph{outcome} of any causal discovery method is a causal graph or a causal adjacency matrix where the cause and effect relations among the entities or variables are represented. The structure of a causal graph is often similar to a \emph{directed acyclic graph (DAG)} where directed edges from one variable to another represent the cause-effect relationship between them. Figure \ref{Con} (b) represents a causal graph showing the factors that are responsible for causing Cancer. This type of structural representation of the underlying data-generating mechanism is beneficial for understanding how the system entities interact with each other.  

There exists a wide range of approaches for performing causal discovery under different settings or assumptions. Some approaches are designed particularly for \emph{independent and identically distributed (I.I.D.) data} (\cite{pc}, \cite{chickering2002optimal}) i.e. non-temporal data while others are focused on \emph{time series data} (\cite{pcmci}, \cite{varlingam}) or temporal data. Since in real-world settings, both types of data are available in different problem domains, it is essential to have approaches to perform causal structure recovery from both of these. Recently, there has been a growing body of research that considers \emph{prior knowledge incorporation} for recovering the causal relationships (\cite{mooij2020joint}, \cite{KCRL}, \cite{KGS}). Although there exist some surveys (see Table \ref{tab_survey}) on causal discovery approaches (\cite{s0}, \cite{s1}, \cite{guo2020survey}, \cite{s3}, \cite{s4}), none of these present a comprehensive review of the different approaches designed for structure recovery from both I.I.D. and time series data. Also, these surveys do not discuss the approaches that perform causal discovery in the presence of background knowledge. Hence, the goal of this survey is to provide an overview of the wide range of existing approaches for performing causal discovery from I.I.D. as well as time series data under different settings. Existing surveys lack a combined overview of the approaches present for both I.I.D. and time series data. So in this survey, we want to introduce the readers to the methods available in both domains. We discuss prominent methods based on the different approaches such as conditional independence (CI) testing, score function usage, functional causal models (FCMs), continuous optimization strategy, prior knowledge infusion, and miscellaneous ones. These methods primarily differ from each other based on the primary strategy they follow. Apart from introducing the different causal discovery approaches and algorithms for I.I.D. and time series data, we also discuss the different tools, metrics, and benchmark datasets used for performing CD and the challenges and applications of CD in a wide range of areas.


\begin{table}[!h]
    %\centering
    \small
    \caption{Comparison among the existing surveys for causal discovery approaches. A discussion on the different approaches can be found in section \ref{Section-3} and section \ref{section-4}.}
    \label{tab_survey}
    \vspace{0.5\baselineskip}
    %\centering
    \begin{center}
    %\begin{tabular}{ | c{2.5cm} | c{6cm} | c{1.5cm} | c{2.1cm} |}
    \begin{tabular}{ | c | p{5cm} | c | c |}
    \hline
    \textbf{Survey} & \textbf{Focused Approaches} & \textbf{I.I.D. Data} & \textbf{Time Series Data}\\ \hline
    \cite{s0} & Constraint, Score, Hybrid \& FCM-based approaches. & $\checkmark$ & $\times$\\ \hline
    \cite{s1} & Traditional Constraint-based, Score-based, \& FCM-based approaches. & $\checkmark$ & $\times$\\ \hline
    \cite{guo2020survey} & Constraint-based, Score-based, \& FCM-based approaches. & $\checkmark$ & $\times$ \\ \hline
    \cite{s3} & Continuous Optimization-based. & $\checkmark$ & $\times$ \\ \hline
    \cite{s4} & Constraint-based, Score-based, FCM-based, etc. approaches for time series data. & $\times$ & $\checkmark$\\ \hline
    This study & Constraint-based, Score-based, FCM-based, Hybrid-based, Continuous-Optimization-based, Prior-Knowledge-based, and Miscellaneous. %for both I.I.D. and time series data. 
    & $\checkmark$ & $\checkmark$\\ \hline
    \end{tabular}
    \end{center}
\end{table}


To summarize, the structure of this paper is as follows: \textit{First}, we provide a brief introduction to the common terminologies in the field of causal discovery (section \ref{Sec-2}). \textit{Second}, we discuss the wide range of causal discovery approaches that exist for both I.I.D. (section \ref{Section-3}) and time-series data (section \ref{section-4}). \textit{Third}, we briefly overview the common evaluation metrics (section \ref{Metrics}) and datasets (section \ref{Datasets}) used for evaluating the causal discovery approaches, and report the performance comparison of some causal discovery approaches in section \ref{section-7}. \textit{Fourth}, we list the different technologies and open-source software (section \ref{tool_boxes}) available for performing causal discovery.\textit{ Fifth}, we discuss the challenges (section \ref{challenges}) and applications (section \ref{Applications}) of causal discovery in multiple areas such as healthcare, business, social science, economics, and so on. \textit{Lastly}, we conclude by discussing the scopes of improvement in future causal discovery research, and the importance of causality in improving the existing predictive AI systems which can thereby impact informed and reliable decision-making in different areas of interest (section \ref{discussion}).  


%\section{Background}
\section{Preliminaries of Causal Discovery}
\label{Sec-2}

In this section, we briefly discuss the important terminologies and concepts that are widely used in causal discovery. Some common notations used to explain the terminologies are presented in Table \ref{tab:1}.

\begin{table}[h]
    \small
    \caption{Common notations.}
    \vspace{0.5\baselineskip}
    \centering
    \begin{tabular}{ | c | c |}
    \hline
    \textbf{Notation} & \textbf{Description}\\ \hline
    $G$ & A graph or DAG or ground-truth graph \\ \hline
    $G'$ & An estimated graph \\ \hline
    $X,Y,Z,W$ & Observational variables \\ \hline
    $X$ — $Y$ & An unoriented or undirected edge between $X$ and $Y$ \\\hline
    $X$ → $Y$ & A directed edge from $X$ to $Y$ where $X$ is the cause and Y is the effect \\\hline
    $X$ $\not\to$ $Y$ & Absence of an edge or causal link between $X$ and $Y$ \\ \hline
    $X$ → $Z$ ← $Y$ & V-structure or Collider where $Z$ is the common child of $X$ and $Y$ \\\hline
    $\indep$ & Independence or d-separation \\ \hline
    $X$ $\indep$ $Y$ $|$ $Z$ & $X$ is d-separated from $Y$ given $Z$ \\\hline
    %P(X|Y) & Conditional probability that of X given Y
    \end{tabular}
    \label{tab:1}
\end{table}


\subsection{Graphical Models}

A graph \textit{G = (V, E)} consists of a set of vertices (nodes) \textit{V} and a set of edges \textit{E} where the edges represent the relationships among the vertices. Figure \ref{DAGs&Skeleton} (a) represents a graph $G$ with vertices $V = [X,Y,Z]$ and edges $E = [(X,Y), (X,Z), (Z,Y)]$. There can be different types of edges in a graph such as directed edges (→), undirected edges (-), bi-directed edges ($\leftrightarrow$), etc. (\cite{rfci}). %nondirected edges, partially undirected edges, partially directed edges
A graph that consists of only undirected edges (-) between the nodes which represent their adjacencies %the edges present in $G$ without specifying any edge directions 
is called a \emph{\textbf{skeleton graph}} $S_{G}$. This type of graph is also known as an \emph{\textbf{undirected graph}} (Figure \ref{DAGs&Skeleton} (b)). A graph that has a mixture of different types of edges is known as a \emph{\textbf{mixed graph}} $M_{G}$ (Figure \ref{DAGs&Skeleton} (c)). A \emph{\textbf{path}} $p$ between two nodes $X$ and $Y$ is a sequence of edges beginning from $X$ and ending at $Y$. A \emph{\textbf{cycle}} $c$ is a path that begins and ends at the same vertex. A graph with no cycle $c$ is called an \emph{\textbf{acyclic graph}}. 
And, a directed graph in which the edges have directions (→) and has no cycle is called a \textit{\textbf{directed acyclic graph}} (DAG).
%And, a graph in which the edges $E$ are directed (→), and there can be no cycle among the edges is a \textit{\textbf{directed acyclic graph}} (DAG). 
In a DAG $G$,  a directed path from $X$ to $Y$ implies that $X$ is an ancestor of $Y$, and $Y$ is a descendant of $X$. The graph $G$ in Figure \ref{DAGs&Skeleton} (a) is a DAG as it is acyclic, and consists of directed edges. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{Graph_G_and_Skeleton_graph.PNG}\\ %\hspace{1.5cm}\includegraphics[width=0.2\textwidth]{Skeleton.png}\\
\caption{(a) A graph $G$, (b) its \emph{skeleton} graph $S_{G}$, (c) a \emph{mixed graph} $M_{G}$ with directed \& undirected edges. %The graph $G$ is also a DAG and causal graph (CG).
}
\label{DAGs&Skeleton}
\end{figure}

There can be different kinds of DAGs based on the type of edges they contain. A class of DAG known as \textbf{\textit{partially directed acyclic graph} }(PDAG) contains both directed ($\rightarrow$) and undirected (-) edges. The mixed graph of Figure \ref{DAGs&Skeleton} (c) is also a PDAG. A \textbf{\textit{completed PDAG}} (CPDAG) consists of directed ($\rightarrow$) edges that exist in every DAG $G$ having the same conditional dependencies, and undirected (-) edges that are reversible in $G$. An extension of DAGs that retain many of the significant properties that are associated with DAGs is known as \textit{\textbf{ancestral graphs}} (AGs). 
%Two different AGs can represent the same set of conditional independence (CI) relations similar to DAGs (\cite{MEforAG}). 
Two different DAGs may lead to the same ancestral graph (\cite{AG2}). Often there are hidden confounders and selection biases in real-world data. Ancestral graphs can represent the data-generating mechanisms that may involve latent confounders and/or selection bias, without explicitly modeling the unobserved variables. There exist different types of ancestral graphs. A \textit{\textbf{maximal ancestral graph}} (MAG) is a mixed graph that can have both directed (→) and bidirectional ($\leftrightarrow$) edges (\cite{richardson2002ancestral}). A \textit{\textbf{partial ancestral graph}} (PAG) can have four types of edges such as directed (→), bi-directed ($\leftrightarrow$), partially directed (o→), and undirected ($-$) (\cite{anytime}). That is, edges in a PAG can have three kinds of endpoints: $-$, o, or $>$. An ancestral graph without bi-directed edges ($\leftrightarrow$) is a DAG (\cite{paper7}). 

%**A detailed discussion on the different types of DAGs and ancestral graphs is available in \autoref{sub5}.** 

% \begin{definition} [Directed Acyclic Graph]
%     A directed acyclic graph (DAG) is a type of graph $G$ in which the edges $E$ are directed (→), and no cycle among the edges is allowed.
% \end{definition}

%A directed acyclic graph (DAG) consists of directed edges (→) between the nodes where no cycle among the edges is allowed.



% \begin{figure}[h]
% \centering
% \includegraphics[width=0.65\textwidth]{MixedGraph_V-Structure.PNG}\\ %\hspace{1.5cm}\includegraphics[width=0.21\textwidth]{v-struc.png}\\
% (a)\hspace{5cm} (b) 
% \caption{(a) A \emph{mixed graph} with directed and undirected edges and  
% (b) a \emph{v-structure.}}
% \label{Mixed&v-struc}
% \end{figure}


%\begin{figure}[h]
%\centering
%\includegraphics[width=0.2\textwidth]{Mixed.JPG} 
%\caption{A \emph{mixed graph} with both directed and %undirected edges.}
%\label{Mixed}
%\end{figure}

\subsection{Causal Graphical Models}

% A \textit{\textbf{causal graphical model}} (CGM) or causal graph (CG) consists of a DAG $G$ and a joint distribution $P$ over a set of random variables $X = (X_{1}, X_{2}, … , X_{d})$ where $P$ is Markovian with respect to $G$ (\cite{ida}). 
A \textit{\textbf{causal graphical model}} (CGM) or \textbf{\textit{causal graph}} (CG) is a DAG $G$ that represents a joint probability distribution $P$ over a set of random variables $X = (X_{1}, X_{2}, … , X_{d})$ where $P$ is Markovian with respect to $G$. In a CGM, the nodes represent variables $X$, and the arrows represent causal relationships between them. The joint distribution $P$ can be factorized as follows where $pa(x_{i},G)$ denotes the parents of $x_{i}$ in $G$.\\
\begin{equation}
    P(x_{1}, …, x_{d}) =  \prod_{i=1}^d P(x_{i}|pa(x_{i},G))
    \label{eq1}
\end{equation}

%*******: Extra Lines
% *****A set of DAGs having the same conditional independencies belong to the same equivalence class. 
%  ******

% \begin{definition} [Causal Graph]
%     A causal graph (CG) is a representation of the underlying data generating mechanism that encodes the cause-effect relationships in data $D$ using directed edges ($\rightarrow$) from cause to effect.
% \end{definition}

% \noindent 
% \textbf{Definition 2. (Causal Graph)} \emph{A causal graph (CG) is a representation of the underlying data generating mechanism that encodes the cause-effect relationships in data using directed edges ($\rightarrow$) from cause to effect.} 

Causal graphs are often used to study the underlying data-generating mechanism in real-world problems. For any dataset $D$ with variables $X$, causal graphs can encode the cause-effect relationships among the variables using directed edges ($\rightarrow$) from cause to the effect. Most of the time causal graphs take the form of a DAG. In  Figure \ref{DAGs&Skeleton} (a), $X$ is the cause that effects both $Y$ and $Z$ (i.e. $Y$ $\leftarrow$ $X$ $\rightarrow$ $Z$). Also, $Z$ is a cause of $Y$ (i.e. $Z$ $\rightarrow$ $Y$). The mechanism that enables the estimation of a causal graph $G$ from a dataset $D$ is called \emph{\textbf{causal discovery} (CD)} (Figure \ref{CG}). The outcome of any causal discovery algorithm is a causal graph $G$ where the directed edges ($\rightarrow$) represent the cause-and-effect relationship between the variables $X$ in $D$. However, some approaches have different forms of graphs (PDAGs, CPDAGs, ancestral graphs, etc.) as the output causal graph. Table \ref{table-3} lists the output causal graphs of some common approaches which are discussed in section \ref{Section-3}.
% A detailed discussion about the other forms of causal graph is available in \autoref{sub5}.

\begin{table}[!h]
\small
\centering
\caption{List of some CD algorithms with their output causal graphs. A detailed discussion of the algorithms is in section \ref{Section-3}. The cells with $\checkmark$ represent the type of graph produced by the corresponding algorithm.}
\label{table-3}
\vspace{0.5\baselineskip}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Algorithms} & \textbf{DAG} & \textbf{PDAG} & \textbf{CPDAG} & \textbf{MAG} & \textbf{PAG} \\ \hline
PC &  &  & $\checkmark$ &  &  \\ \hline
FCI &  &  &  &  & $\checkmark$ \\ \hline
RFCI &  &  &  &  & $\checkmark$ \\ \hline
GES &  &  & $\checkmark$ &  &  \\ \hline
GIES &  & $\checkmark$ &  &  &  \\ \hline
MMHC & $\checkmark$ &  &  &  &  \\ \hline
LiNGAM & $\checkmark$ &  &  &  &  \\ \hline
NOTEARS & $\checkmark$ &  &  &  &  \\ \hline
GSMAG &  &  &  & $\checkmark$ &  \\ \hline
\end{tabular}
\end{table}


%\subsubsection{Directed Acyclic Graphs (DAGs) \& Causal Discovery} 

%%A \textit{directed acyclic graph (DAG)} consists of directed edges (→) between the nodes where no cycle among the edges is allowed. In a DAG,  a directed path from X to Y implies that X is an ancestor of Y and Y is a descendant of X. The graph in \autoref{DAGs&Skeleton} (a) is a DAG as it is acyclic with directed edges.



%%\textit{Causal Discovery} enables the estimation of a causal graph from data (\autoref{CD}). The outcome of  a causal discovery approach is a causal graph, particularly a DAG where the directed edges represent the cause-and-effect relationship between the variables. That is, the properties of a causal graph are similar to a DAG.
\subsubsection{Key Structures in Causal Graphs} 

% There can be three building blocks (key structures) commonly observed in causal graphs: \textbf{chains, forks, and colliders}. 

There are three fundamental \textit{\textbf{building blocks}} (key structures) commonly observed in the graphical models or causal graphs, namely, \textbf{\emph{Chain}, \emph{Fork},} and \textbf{\emph{Collider}.} Any graphical model consisting of at least three variables is composed of these key structures. We discuss these basic building blocks and their implications in dependency relationships below.

 \begin{definition} [Chain]

    A chain $X \rightarrow Y \rightarrow Z$ is a graphical structure or a configuration of three variables $X$, $Y$, and $Z$ in graph $G$ where $X$ has a directed edge to $Y$ and $Y$ has a directed edge to $Z$ (see Figure \ref{Blocks} (a)). Here, $X$ causes $Y$ and $Y$ causes $Z$, and $Y$ is called a mediator.
    
    % This building block represents a relation of the form X → Y → Z, where $Y$ is called a mediator (see \autoref{Blocks} (a)).
\end{definition}




% {\bf Chain:} A chain $X \rightarrow Y \rightarrow Z$ is a graphical structure or a configuration of three variables $X$, $Y$, and $Z$ in graph $G$ where $X$ has a directed edge to $Y$ and $Y$ has a directed edge to $Z$ (see \autoref{Blocks} (a)). Here, $X$ causes $Y$ and $Y$ causes $Z$, and $Y$ is called a mediator.

\begin{definition}[Fork]
    A fork $Y \leftarrow X \rightarrow Z$ is a triple of variables $X$, $Y$, and $Z$ where one variable is the common parent of the other two variables. In Figure \ref{Blocks} (b),  the triple ($X$, $Y$, $Z$) is a fork where $X$ is a common parent of $Y$ and $Z$.
\end{definition}

% \noindent 
% \textbf{Definition 4. (Fork)} A fork is a triple of variables where one variable is the common parent of the other two variables. In \autoref{Blocks} (b),  the triple ($X$, $Y$, $Z$) is a fork where $X$ is a common parent of $Y$ and $Z$.

\begin{definition}[Collider/V-structure]
    A v-structure or collider $X \rightarrow Z \leftarrow Y $ is a triple of variables $X$, $Y$, and $Z$ where one variable is a common child of the other two variables which are non-adjacent. In Figure \ref{Blocks} (c),  the triple ($X$, $Y$, $Z$) is a v-structure where $Z$ is a common child of $X$ and $Y$, but $X$ and $Y$ are non-adjacent in the graph. Figure \ref{Blocks} (d) is also a collider with a descendant $W$.
\end{definition}

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{Building_Blocks.PNG} 
\caption{Fundamental building blocks in causal graphical models.} %(a) Chain, (b) Fork and (c and d) Collider.}
\label{Blocks}
\end{figure}


% \noindent 
% \textbf{Definition 5. (Collider/v-structures)} \emph{A v-structure is a triple of variables where one variable is a common child of the other two variables which are non-adjacent.} In \autoref{Blocks} (c),  the triple ($X$, $Y$, $Z$) is a v-structure where $Z$ is a common child of $X$ and $Y$, but $X$ and $Y$ are non-adjacent in the graph. \autoref{Blocks} (d) is also a collider with descendant $W$.

%\begin{figure}[h]
%\centering
%\includegraphics[width=0.25\textwidth]{%v-struc.png} 
%\caption{v-structure.}
%\label{v-struc}
%\end{figure}


% \subsection{%$d$-separation \& 
% Conditional Independence in Graphical Models}

\subsubsection{%$d$-separation \& 
Conditional Independence in Causal Graphs}

Testing for \textit{\textbf{conditional independence}} (CI) between the variables is one of the most important techniques to find the causal relationships among the variables. Conditional independence between two variables $X$ and $Y$ results when they are independent of each other given a third variable $Z$ (i.e. $X$ $\indep$ $Y$ $|$ $Z$). In the case of causal discovery, CI testing allows deciding if any two variables are causally connected or disconnected. An important criterion for CI testing is the \textit{d-separation }criterion which is formally defined below. 

% \noindent \\
% \textbf{Definition 6. (d-separation)} \emph{d-separation is a criterion to decide if two variables are independent when conditioned on a set of variables.} The conditioning variable can be a single variable or a set of variables. For example, in \autoref{Blocks} (b), using the d-separation criterion it can be checked whether $X$ and $Y$ are d-separated (independent) or not by conditioning on $Z$ (i.e if $X$ $\indep$ $Y$ $|$ $Z$). However, two variables with a directed edge ($\rightarrow$) between them are always dependent.


% A path $p$ between two variables refers to any consecutive sequence of edges in a graph $G$ where the direction of the edges is not taken into account. However, if the direction of edges is taken into account then $p$ is a \emph{directed} or \emph{causal path}.

\begin{definition}[d-separation](\cite{pearl:88})
\label{defn-d-separation}
A path $p$ in $G$ is blocked by a set of nodes $N$ if either 
\begin{enumerate}[i.]
    \item $p$ contains a chain of nodes $X \rightarrow Y \rightarrow Z$ or a fork $X \leftarrow Y \rightarrow Z$ such that the middle node $Y$ is in $N$,
    \item $p$ contains a collider $X \rightarrow Y \leftarrow Z$ such that the collision node $Y$ is not in $N$, and no descendant of $Y$ is in $N$.
\end{enumerate}

If $N$ blocks every path between two nodes, then they are d-separated, conditional on N, and thus are independent conditional on N.
\end{definition}

% Here, a path $p$ between two variables refers to any consecutive sequence of edges in a graph $G$, and 

In \textit{d-separation}, \emph{d} stands for \textit{directional}. The d-separation criterion provides a set of rules to check if two variables are independent when conditioned on a set of variables. The conditioning variable can be a single variable or a set of variables. However, two variables with a directed edge ($\rightarrow$) between them are always dependent.  %allows to systematically list the conditional independencies implied by the structural model from the graph. It 
The set of testable implications provided by \emph{d-separation} can be benchmarked with the available data $D$. If a graph $G$ might have been generated from a dataset $D$, then \emph{d-separation} tells us which variables in $G$ must be independent conditional on other variables. If every \emph{d-separation} condition matches a conditional independence in data, then no further test can refute the model (\cite{pearl:88}). If there is at least one path between two variables that is unblocked, then they are \emph{d-connected}. If two variables are \emph{d-connected}, then they are most likely dependent (except intransitive cases) (\cite{pearl:88}). The d-separation or conditional independence between the variables in the \textbf{key structures} (Figure \ref{Blocks}) or building blocks of causal graphs follow some rules which are discussed below:

\begin{enumerate}[i.]
    \item \emph{Conditional Independence in Chains:} If there is only one unidirectional path between variables $X$ and $Z$ (Figure \ref{Blocks} (a)), and $Y$ is any variable or set of variables that intercept that path, then $X$ and $Z$ are conditionally independent given $Y$, i.e. $X$ $\indep$ $Z$ $|$ $Y$.

    \item \emph{Conditional Independence in Forks:} If a variable $X$ is a common cause of variables $Y$ and $Z$, and there is only one path between $Y$ and $Z$, then $Y$ and $Z$ are independent conditional on $X$ (i.e. $Y$ $\indep$ $Z$ $|$ $X$) (Figure \ref{Blocks}(b)).

    \item \emph{Conditional Independence in Colliders:} If a variable $Z$ is the collision node between two variables $X$ and $Y$ (Figure \ref{Blocks}(c)), and there is only one path between $X$ and $Y$, then $X$ and $Y$ are unconditionally independent (i.e. $X$ $\indep$ $Y$). But, they become dependent when conditioned on $Z$ or any descendants of $Z$ (Figure \ref{Blocks}(d)). 
\end{enumerate}

% • \emph{\textbf{Conditional Independence in Chains:}} Two variables, $X$ and $Y$, are conditionally independent given $Z$, $X$ $\indep$ $Y$ $|$ $Z$, if there is only one unidirectional path between $X$ and $Y$ (\autoref{Blocks} (a)) and, $Z$ is any set of variables that intercepts that path.


% \noindent
% • \emph{\textbf{Conditional Independence in Forks:}} If a variable $X$ is a common cause of variables $Y$ and $Z$, and there is only one path between $Y$ and $Z$, then $Y$ and $Z$ are independent conditional on $X$ (i.e. $Y$ $\indep$ $Z$ $|$ $X$) (\autoref{Blocks}(b)).

% \noindent
% • \emph{\textbf{Conditional Independence in Colliders:}} If a variable $Z$ is the collision node between two variables $X$ and $Y$, and there is only one path between $X$ and $Y$, then $X$ and $Y$ are unconditionally independent (i.e. $X$ $\indep$ $Y$) but are dependent conditional on $Z$ (\autoref{Blocks}(c)) and any descendants of $Z$ (\autoref{Blocks}(d)). 



%\subsubsection{Markov Equivalence Class (MEC)}
\subsubsection{Markov Equivalence in Causal Graphs}
\label{sub5}
A set of causal graphs having the same set of conditional independencies is known as a \textit{\textbf{Markov equivalence class}} (MEC). %In other words, causal DAGs that encode the same set of d-separations given the Markov assumptions are called \textit{Markov equivalent}. 
Two DAGs that are Markov equivalent have the \textit{(i) same skeleton }(the underlying undirected graph) and (ii) \textit{ same v-structures (colliders) \textbf{ }}(\cite{verma2022equivalence}). That is, all DAGs in a MEC share the same edges, regardless of the direction of those edges, and the same colliders whose parents are not adjacent. \textit{Chain} and \textit{Fork} share the same independencies, hence, they belong to the same MEC (Figure \ref{Markov}). 

\begin{definition}[Markov Blanket]
    For any variable X, its Markov blanket (MB) is the set of variables such that X is independent of all other variables given MB. The \textbf{members} in the Markov blanket of any variable will include all of its \textbf{parents, children, and spouses}.
\end{definition}


\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{Markov_Equivalence.PNG} 
\caption{Markov Equivalence in Chains and Fork.}
\label{Markov}
\end{figure}

%A set of DAGs that are Markov equivalent forms a MEC. 
Markov equivalence in different types of DAGs may vary. A \textit{partial} DAG (PDAG) a.k.a an essential graph (\cite{CPDAGwithBG}) can represent an equivalence class of DAGs. 
% Two DAGs are equivalent iff they have the same skeletons and they share the same v-structures. 
Each equivalent class of DAGs can be uniquely represented by a PDAG. A \textit{completed} PDAG or CPDAG represents the union (over the set of edges) of Markov equivalent DAGs, and can uniquely represent an MEC (\cite{malinsky2016estimating}). %A CPDAG has all the adjacencies similar to each DAG in the equivalence class but may contain undirected edges ($-$) along with directed edges (→). 
More specifically, in a CPDAG, an undirected edge between any two nodes $X$ and $Y$ indicates that some DAG in the equivalence class contains the edge $X$→$Y$ and some DAG may contain $Y$→$X$. Figure \ref{CPDAG} shows a CPDAG %$C_{g}$ 
and the DAGs ($G$ and $H$) belonging to an equivalence class.




% \textbf{Definition 7. (Markov Blanket)} \emph{For any variable X, its Markov blanket (MB) is the set of variables such that X is independent of all other variables given MB}. The \textbf{members} in the Markov Blanket of any variable will include all of its \textbf{parents, children, and spouses}.



% \noindent
% \textbf{Markov Equivalence in Different Types of DAGs.} There can be different types of DAGs depending on the types of edges present in them. 



%\paragraph{Partially Directed Acyclic Graph (PDAG).} A partially directed graph is the one that may contain both directed and undirected edges. 
% A PDAG a.k.a an essential graph is a partially directed graph without directed cycles (\cite{CPDAGwithBG}) and represents an equivalence class of DAGs. 
% % Two DAGs are equivalent iff they have the same skeletons and they share the same v-structures. 
% Each equivalent class of DAGs can be uniquely represented by a PDAG. %A PDAG may contain both directed and undirected edges. 

% A \textit{Completed Partially Directed Graph (CPDAG)} represents the union (over the set of edges) of Markov equivalent DAGs and can uniquely represent a Markov equivalence class (MEC). A CPDAG has all the same adjacencies as each DAG in the equivalence class but may contain undirected edges ($-$) along with directed edges (→) (\cite{malinsky2016estimating}). More specifically, in a CPDAG, an undirected edge between two nodes $X$ and $Y$ indicates that some DAG in the equivalence class contains the edge $X$→$Y$ and some DAG may contain $Y$→$X$. \autoref{CPDAG} shows a CPDAG %$C_{g}$ 
% and the DAGs ($G$ and $H$) belonging to its equivalence class.



% \paragraph{Maximal PDAG (MPDAG).} A PDAG is a maximally oriented PDAG if and only if the edge orientations in the PDAG are closed under the orientation rules by Meek. Maximal PDAGs originate restrictions that are imposed on a Markov Equivalence Class (MEC) of DAGs, or equivalently on its graphical representation as a CPDAG, such as when prior knowledge is considered for certain edge orientations (\cite{CPDAGwithBG}). Maximal PDAGs are capable of representing more information than CPDAGs about causal interactions. Let, from prior knowledge, we know that the edge $X$ → $Y$ exists in a DAG $G$. If we add this edge to the CPDAG of $G$, the resultant graph will be the maximal PDAG of $G$.\\

Markov equivalence in the case of ancestral graphs works as follows. A \textit{maximal ancestral graph} (MAG) represents a DAG where all hidden variables are marginalized out and preserves all conditional independence relations among the variables that are true in the underlying DAG. That is, MAGs can model causality and conditional independencies in causally insufficient systems (\cite{paper7}). \textit{Partial ancestral graphs} (PAGs) represent an equivalence class of MAGs where all common edge marks shared by all members in the class are displayed, and also, circles for those marks that are uncommon are presented.  PAGs represent all of the observed d-separation relations in a DAG. Different PAGs that represent distinct equivalence classes of MAGs involve different sets of conditional independence constraints. %PAGs are fully testable with observational data given the \textit{causal faithfulness} assumption. 
An MEC of MAGs can be represented by a PAG (\cite{malinsky2016estimating}).


\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{CPDAG.PNG} 
\caption{DAGs $G$ and $H$ belong to the same MEC. The leftmost graph is a CPDAG of $G$ and $H$ with an undirected edge ($-$) between $X$ and $Z$, and the rest of the edges same as in $G$ and $H$.}
\label{CPDAG}
\end{figure}


% \begin{table}[!h]
% \centering
% \caption{ }
% \label{tab:my-table}
% \begin{tabular}{|c|c|}
% \hline
% \textbf{Output Causal Graph} & \textbf{Algorithms} \\ \hline
% DAG & MMHC, LiNGAM, NOTEARS \\ \hline
% PDAG & GIES \\ \hline
% CPDAG & PC, GES \\ \hline
% MPDAG &  \\ \hline
% MAG & GSMAG \\ \hline
% PAG & FCI, RFCI\\ \hline
% \end{tabular}
% \end{table}



%\end{itemize}

\subsection{Structural Causal Models}

\cite{pearl2009causality} defined a \emph{class of models} for formalizing structural knowledge about the \emph{data-generating process} known as the \textit{structural causal models (SCMs)}. The SCMs are valuable tools for reasoning and decision-making in causal analysis since they are capable of representing the underlying causal story of data (\cite{CML}). 

%It is possible to estimate what will happen to data after changes or interventions are made to its generating process (\cite{CML}). 

% \noindent \\
% \textbf{Definition 8. (Structural Causal Models (SCMs))} %\emph{Mathematically, an SCM consists of:\\ 
% \emph{An SCM consists of:\\ 
% (i) Two sets of variables: \textit{Exogenous} (U) and \textit{Endogenous} (V) variables, \\
% (ii) A set of functions $f$ that assigns each variable in $V$ a value based on the values of the other variables in the model,\\
% (iii) An associated graphical causal model G, where each node is a variable in $U$ or $V$ and each edge is a function $f$.} 


\begin{definition} [Structural Causal Model]
	\label{def_scm}	%\singlespacing
	\cite{pearl2009causality}; A structural causal model is a 4-tuple $M = \langle U, V, F, P(u) \rangle$, where
	\begin{enumerate}[i.]
	\item $U$ is a set of background variables (also called exogenous) that are determined by factors outside the model.
	\item $V$ is a set $\{V_1, V_2,\hdots,V_n\}$ of endogenous variables that are determined by variables in the model, viz.\ variables in $U \cup V$.
	\item $F$ is a set of functions $\{f_1, f_2,\hdots, f_n\}$ such that each $f_i$ is a mapping from the respective domains of $U_i \cup {PA}_i $ to $V_i$ and the entire set $F$ forms a mapping from $U$ to $V$. In other words, each $f_i$ assigns a value to the corresponding $V_i \in V$, $v_i \leftarrow f_i(pa_i, u_i),$ for $i = 1, 2, \hdots n$.
	\item $P(u)$ is a probability function defined over the domain of $U$.
	\end{enumerate}
\end{definition}

Each SCM $M$ is associated with a \textit{causal graphical model} $G$ that is a DAG, and a set of functions $f_i$. \textit{Causation in SCMs} can be interpreted as follows: a variable $Y$ is directly caused by $X$ if $X$ is in the function $f$ of $Y$. In other words, each $f_i$ assigns a value to the corresponding $V_i \in V$, $v_i \leftarrow f_i(pa_i, u_i),$ for $i = 1, 2, \hdots n$.  In the SCM of Figure \ref{SCM}, $X$ is a direct cause of $Y$ as $X$ appears in the function that assigns $Y$’s value. That is, if a variable $Y$ is the child of another variable $X$, then $X$ is a direct cause of $Y$. In Figure \ref{SCM}, $U_{X}$, $U_{Y}$ and $U_{Z}$ are the exogenous variables; $X$, $Y$ and $Z$ are the endogenous variables, and $f_{X}$, $f_{Y}$ \& $f_{Z}$ are the functions that assign values to the variables in the system. Any variable is \textit{an exogenous variable} if $(i)$ it is an unobserved or unmeasured variable and $(ii)$ it cannot be a descendant of any other variables. Every \textit{endogenous variable} is a descendant of at least one exogenous variable.
%Causal models and graphs, represent causal relationships and encode causal assumptions ~\citep{pearl2009causality}. 


\begin{figure}[h]
\centering
\includegraphics[width=0.435\textwidth]{SCM.png} 
\caption{A Structural Causal Model (SCM) with causal graph $G$ and functions $f_{X}$, $f_{Y}$ and $f_{Z}$ which denotes how the variables $X$, $Y$, and $Z$ are generated respectively.}
\label{SCM}
\end{figure}




%\begin{equation}
%    Y\leftarrow f_{Y}(X) 
%    \label{Y}
%\end{equation}

%\begin{equation}
%    Z \leftarrow f_{Z}(X)
%    \label{Z}
%\end{equation}


%\subsubsection{$d$-SEPARATION}


\subsection{Causal Assumptions}

Often, the available data provide only partial information about the underlying causal story. Hence, it is essential to make some assumptions about the world for performing causal discovery (\cite{rrcd}). Following are the common assumptions usually made by causal discovery algorithms.

\begin{enumerate}[i.]
    \item \emph{\textbf{Causal Markov Condition (CMC):}} The causal Markov assumption states that a variable $X$ is independent of every other variable (except its descendants) conditional on all of its direct causes (\cite{CMU}). That is, the CMC requires that every variable in the causal graph is independent of its non-descendants conditional on its parents (\cite{CEwithAG}). In Figure \ref{Assumption11}, $W$ is the only descendant of $X$. As per the CMC, $X$ is independent of $Z$ conditioned on its parent $Y$ ($X$ $\indep$ $Z$ $|$ $Y$).

\begin{figure}[h]
\centering
\includegraphics[width=0.38\textwidth]{CMC_assumption.png} 
\caption{Illustration of the causal Markov condition (CMC) among four variables.}
\label{Assumption11}
\end{figure}


    \item \emph{\textbf{Causal Faithfulness Condition (CFC):}} The faithfulness assumption states that except for the variables that are d-separated in a DAG, all other variables are dependent. More specifically, for a set of variables $V$ whose causal structure is represented by a DAG $G$, no conditional independence holds unless entailed by the causal Markov condition (\cite{AFCCI}). That is, the CFC a.k.a the Stability condition is a converse principle of the CMC. CFC can be also explained in terms of d-separation as follows: For every three disjoint sets of variables $X$, $Y$, and $Z$, if $X$ and $Y$ are not d-separated by $Z$ in the causal DAG, then $X$ and $Y$ are not independent conditioned on $Z$ (\cite{AFCCI}). The faithfulness assumption may fail in certain scenarios. For example, it fails whenever there exist two paths with equal and opposite effects between variables. It also fails in systems with deterministic relationships among variables, and also, when there is a failure of transitivity along a single path (\cite{FCC}).

    \item \emph{\textbf{Causal Sufficiency:}} The causal sufficiency assumption states that there exist no latent/hidden/unobserved confounders, and all the common causes are measured. Thus, the assumption of causal sufficiency is satisfied only when all the common causes of the measured variables are measured. This is a strong assumption as it restricts the search space of all possible DAGs that may be inferred. However, real-world datasets may have hidden confounders which might frequently cause the assumption to be violated in such scenarios. Algorithms that violate the causal sufficiency assumption may observe degradation in their performance. The causal insufficiency in real-world datasets may be overcome by leveraging domain knowledge in the discovery pipeline. The CMC tends to fail for a causally insufficient set of variables. %(Spirtes et al., 1993).

    \item \emph{\textbf{Acyclicity:}} It is the most common assumption which states that \textit{there are no cycles in a causal graph}. That is, a graph needs to be acyclic in order to be a causal graph. As per the acyclicity condition, there can be no directed paths starting from a node and ending back to itself. This resembles the structure of a directed acyclic graph (DAG). A recent approach (\cite{notears}) has formulated a new function (Equation \ref{acyclicity}) to enforce the acyclicity constraint during causal discovery in continuous optimization settings. The weighted adjacency matrix $W$ in Equation \ref{acyclicity} is a DAG if it satisfies the following condition where $\circ$ is the Hadamard product, $e^{W \circ W}$  is the matrix exponential of $W \circ W$, and $d$ is the total number of vertices.

    
\begin{equation}
    h(W) = tr(e^{W \circ W}) - d = 0
    \label{acyclicity}
\end{equation}


    \item \emph{\textbf{Data Assumptions:}} There can be different types of assumptions about the data. Data may have linear or nonlinear dependencies and can be continuously valued or discrete valued in nature. Data can be independent and identically distributed (I.I.D.) or the data distribution may shift with time (e.g. time-series data). Also, the data may belong to different noise distributions such as Gaussian, Gumbel, or Exponential noise. Occasionally, some other data assumptions such as the existence of selection bias, missing variables, hidden confounders, etc. are found. However, in this survey, we do not focus much on the methods with these assumptions.

\end{enumerate}
% \paragraph{i) Causal Markov Condition (CMC)} The causal Markov assumption states that a variable X is independent of every other variable (except its descendents) conditional on all of its direct causes (\cite{CMU}). That is, the CMC requires that every variable in the causal graph is independent of its non-descendents conditional on its parents (\cite{CEwithAG}). In \autoref{Assumption11}, $W$ is the only descendant of $X$. As per the CMC, $X$ is independent of $Z$ conditioned on its parent $Y$ ($X$ $\indep$ $Z$ $|$ $Y$).


% \noindent
% \paragraph{ii) Causal Faithfulness Condition (CFC)} The Causal Faithfulness assumption can be stated as follows:
% Except for the variables that are d-separated in a DAG, all other variables will be dependent. More specifically, for a set of variables $V$ whose causal structure is represented by a DAG, no conditional independence (CI) holds unless entailed by the causal Markov condition (CMC) (\cite{AFCCI}). That is, the CFC a.k.a the Stability condition is a converse principle of the CMC. A definition of CFC based on the concept of d-separation: For every three disjoint sets of variables $X$, $Y$ and $Z$, if $X$ and $Y$ are not d-separated by $Z$ in the causal DAG, then $X$ and $Y$ are not independent conditioned on $Z$ (\cite{AFCCI}). The faithfulness assumption may fail in certain scenarios. For example, it fails whenever there exists two paths with equal and opposite effects between variables. %(\cite{FCC}).
% It also fails in systems with deterministic relationships among variables and also, when there is failure of transitivity along a single path (\cite{FCC}).

% \noindent
% \paragraph{iii) Causal Sufficiency} The Causal Sufficiency assumption states that there exists no latent/hidden/unobserved confounders and all the common causes are measured. Thus, the assumption of causal sufficiency is satisfied only when all the common causes of the measured variables are measured. This is a strong assumption as it constrains the search space of all possible DAGs that may be inferred which is mostly violated in real-world scenarios. Algorithms that violate the causal sufficiency assumption may observe a degradation in their performance. Causal insufficiency in real-world datasets can be overcomed by leveraging domain knowledge in the discovery pipeline [CITE]. CMC tends to fail for a causally insufficient set of variables. %(Spirtes et al., 1993).


% \paragraph{iv) Acyclicity} It is the most common assumption which states that \textit{there are no cycles in a causal graph}. That is, a graph needs to be acyclic in order to be a causal graph. As per the acyclicity condition, there can be no directed paths starting from a node and ending back to itself. This resembles the structure of a directed acyclic graph (DAG). A recent approach (\cite{notears}) have formulated a new function (\autoref{acyclicity}) to enforce the acyclicity constraint during causal discovery. A weighted adjacency matrix $W$ is a DAG if it satisfies the following condition where $\circ$ is the Hadamard product, $e^{W \circ W}$  is the matrix exponential of $W \circ W$, and $d$ is the total number of vertices.


% \paragraph{v) Data Assumptions}
% Data may have linear or nonlinear dependencies, and can be continuously-valued or discrete data. Data can be independent and identically distributed (I.I.D.) or the distribution may shift with time (e.g. time-series data). Also, the data may come from different noise distributions such as a Gaussian, Gumbel or Exponential noise.


% \begin{figure}[h]
% \centering
% \includegraphics[width=1\textwidth]{Taxonomy_of_CD_algos.PNG} 
% \caption{ %General procedure of constraint-based structure learning.
% Taxonomy of some causal discovery approaches for I.I.D. data.}
% \label{Assumption}
% \end{figure}



% https://tex.stackexchange.com/questions/495962/hierarchy-diagram

\begin{figure}
    \centering
        {\footnotesize % to reduce the size of forest tree
        \begin{forest}
        forked edges,
        for tree={draw,align=left,l=1.7cm,edge={-latex}}
          [Causal Discovery Algorithms \\ \hspace{0.7cm} (for I.I.D. data)
            [Contraint-based
                [PC (\ref{PC})\\FCI (\ref{fci})\\Anytime FCI (\ref{anytimefci})\\RFCI (\ref{rfci})\\FCI with {TBK}$^\ast$  (\ref{fci-tiered})\\PC-stable (\ref{pcstable})\\{PKCL}$^\ast$ (\ref{pkcl})\\]
            ]
            [Score-based
                [GES (\ref{ges})\\FGS (\ref{fgs})\\SGES (\ref{sges})\\RL-BIC (\ref{rlbic})\\A-star search (\ref{a-star-search}) \\Triplet A-star (\ref{tripleta*})\\{KCRL}$^\ast$ (\ref{kcrl})]
            ]
            [FCM-based
                [LiNGAM (\ref{lingam-section})\\ANM (\ref{anm_section})\\PNL (\ref{pnl})\\{DirectLiNGAM}$^\ast$ (\ref{directlingam})\\SAM (\ref{sam})\\CGNN (\ref{cgnn})\\CAM (\ref{cam})\\]
            ]
            [Gradient-based %Continuous \\Optimization-based
                [{NOTEARS}$^\diamond$ (\ref{notears})\\{GraN-DAG}$^\diamond$ (\ref{gran-dag})\\GAE (\ref{gae})\\{DAG-GNN}$^\diamond$ (\ref{daggnn})\\{GOLEM}$^\diamond$ (\ref{golem})\\DAG-NoCurl (\ref{dag-nocurl})\\{ENCO}$^\diamond$ (\ref{enco})]
            ]
            [Miscellaneous
                [FRITL (\ref{fritl})\\HCM (\ref{hcm})\\ {ETIO}$^\ast$ (\ref{etio})\\ {JCI}$^\ast$ (\ref{jci})\\{Kg2Causal}$^\ast$ (\ref{kg2causal})\\ Meta-RL (\ref{meta-rl})\\LFCM (\ref{lfcm})]
            ]
            %[Hybrid]
            %CORL (\ref{corl})\\
          ]
        \end{forest}
        }
    \caption{Taxonomy of some causal discovery approaches for I.I.D. data. The approaches are classified based on their core contribution or the primary strategy they adopt for causal structure recovery. The approaches that leverage prior knowledge are marked by an $\ast$ symbol. Some of the gradient-based optimization approaches that use a score function are indicated by a $\diamond$ symbol. They are primarily classified as gradient-based methods because of the use of gradient descent for optimization. However, they can be a score-based method too as they compute data likelihood scores on the way.}
    \label{Taxonomy-iid}
\end{figure}

\section{Causal Discovery Algorithms for I.I.D. Data}
\label{Section-3}
Causal graphs are essential as they represent the underlying causal story embedded in the data. %In this section, we broadly discuss the existing approaches for causal discovery in different settings. 
There are two very common approaches to recovering the causal structure from observational data, \emph{i) Constraint-based} (\cite{pc}, \cite{anytime}, \cite{rfci}) and \emph{ii) Score-based} (\cite{chickering2002optimal}). Among the other types of approaches, \emph{functional causal models (FCMs)-based} (\cite{LiNGAM}, \cite{anm}) approaches and \emph{hybrid} approaches (\cite{mmhc}) are noteworthy. Recently, some \emph{gradient-based} approaches have been proposed based on neural networks (\cite{neuralnet}) and a modified definition (\autoref{acyclicity}) of the acyclicity constraint (\cite{notears}, \cite{dag-gnn}). Other approaches include the ones that prioritize the use of \emph{background knowledge} and provides ways to incorporate prior knowledge and experts’ opinion into the search process (\cite{PKCL,kg2causal}). In this section, we provide an overview of the causal discovery algorithms for I.I.D. data based on the different types of approaches mentioned above. The algorithms primarily distinguish from each other based on the core approach they follow to perform causal discovery. We further discuss noteworthy similar approaches specialized for non-I.I.D. or time series data in section \ref{section-4}.


\subsection{Constraint-based}
Testing for conditional independence (CI) is a core objective of constraint-based causal discovery approaches. Conditional independence tests can be used to recover the causal skeleton if the probability distribution of the observed data is faithful to the underlying causal graph (\cite{marx2019testing}). Thus, constraint-based approaches conduct CI tests between the variables to check for the presence or absence of edges. These approaches infer the conditional independencies within the data using the \emph{d-separation criterion} to search for a DAG that entails these independencies, and detect which variables are d-separated and which are d-connected (\cite{paper7}). $X$ is conditionally independent of $Z$ given $Y$ i.e. $X$ $\indep$ $Z$ $|$ $Y$ in Figure \ref{cons} (a) and in Figure \ref{cons} (b), $X$ and $Z$ are independent, but are not conditionally independent given $Y$. Table \ref{tab:2} lists different types of CI tests used by constraint-based causal discovery approaches. 

\begin{figure}[h]
\centering
\includegraphics[width=0.35\textwidth]{Cons_based.png} 
\caption{(a) $X$ $\indep$ $Z$ $|$ $Y$ and (b) $X$ and $Z$ are not conditionally independent given $Y$.}
\label{cons}
\end{figure}

\begin{table}[!h]
\small
\caption{Types of conditional independence (CI) tests. Please refer to the study \cite{CMIknn} for a detailed discussion on CI tests.}
\vspace{0.5\baselineskip}
\begin{center}
    \begin{tabular}{ | c | p{8.5cm} | c | }
    \hline
      & \textbf{Conditional Independence Test} & \textbf{Ref.}\\ \hline
     1. & Conditional Distance Correlation (CDC) test & \cite{CDC_wang}\\ \hline
     2. & Momentary Conditional Independence (MCI) & \cite{pcmci}\\ \hline
3. & Kernel-based CI test (KCIT) & \cite{KCIT} \\ \hline
4. & Randomized Conditional Correlation Test (RCoT) & \cite{RCIT}\\ \hline
5. & Generative Conditional Independence Test (GCIT) & \cite{GCIT} \\ \hline
6. & Model-Powered CI test & \cite{ModelPoweredCI} \\ \hline
7. & Randomized Conditional Independence Test (RCIT) & \cite{RCIT} \\ \hline
8. &  Kernel Conditional Independence
Permutation Test& \cite{KCPIT} \\ \hline
9. & Gaussian Processes and Distance Correlation-based (GPDC)& \cite{GPDC}\\ \hline
10. & Conditional mutual information estimated with a k-nearest neighbor estimator (CMIKnn) & \cite{CMIknn}\\ \hline
    \end{tabular}
\end{center}
    \label{tab:2}
\end{table}


\subsubsection{PC} \label{PC}
The Peter-Clark (PC) algorithm (\cite{pc}) is one of the oldest constraint-based algorithms for causal discovery. To learn the underlying causal structure, this approach depends largely on conditional independence (CI) tests. This is because it is based on the concept that two statistically independent variables are not causally linked. The outcome of a PC algorithm is a CPDAG. It learns the CPDAG of the underlying DAG in three steps: \emph{Step 1 - Skeleton identification, Step 2 - V-structures determination, and Step 3 - Edge orientations}. It starts with a fully connected undirected graph using every variable in the dataset, then eliminates the unconditionally and conditionally independent edges (skeleton detection), then it finds and orients the v-structures or colliders (i.e. X → Y ← Z) based on the d-separation set of node pairs, and finally orients the remaining edges based on two aspects: i) availability of no new v-structures, and ii) not allowing any cycle formation. The assumptions made by the PC algorithm include acyclicity, causal faithfulness, and causal sufficiency. It is computationally more feasible for sparse graphs. An implementation of this algorithm can be found in the CDT repository (\url{https://github.com/ElementAI/causal_discovery_toolbox}) and also, in the gCastle toolbox (\cite{gcastle}). A number of the constraint-based approaches namely FCI, RFCI, PCMCI, PC-stable, etc. use the PC algorithm as a backbone to perform the CI tests. 

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{PC.PNG} 
\caption{ %General procedure of constraint-based structure learning.
Step-by-step workflow of the PC (\cite{pc}) algorithm.}
\label{Assumption}
\end{figure}




\subsubsection{FCI} \label{fci}
The Fast Causal Inference (FCI) algorithm (\cite{FCI}) is a variant of the PC algorithm that can infer conditional independencies and learn causal relations in the presence of many arbitrary latent and selection variables. As a result, it is accurate in the large sample limit with a high probability even when there exists \textit{hidden variables}, and \textit{selection bias} (\cite{berk1983introduction}). The first step of the FCI algorithm is similar to the PC algorithm where it starts with a complete undirected graph to perform the skeleton determination. After that, it requires additional tests to learn the correct skeleton and has additional orientation rules. In the worst case, the number of conditional independence tests performed by the algorithm grows exponentially with the number of variables in the dataset. This can affect both the speed and the accuracy of the algorithm in the case of small data samples. To improve the algorithm, particularly in terms of speed, there exist different variants such as the RFCI (\cite{rfci}) and the Anytime FCI (\cite{anytime}) algorithms. 

\subsubsection{Anytime FCI} \label{anytimefci}
Anytime FCI (\cite{anytime}) is a modified and faster version of the FCI (\cite{FCI}) algorithm. The number of CI tests required by FCI makes it infeasible if the model has a large number of variables. Moreover, when the FCI requires independence tests conditional on a large set of variables, the accuracy decreases for a small sample size. The outer loop of the FCI algorithm performs independence tests conditional on the increasing size of variables. In the anytime FCI algorithm, the authors showed that this outer loop can be stopped anytime during the execution for any smaller variable size. As the number of variables in the conditional set reduces, anytime FCI becomes much faster for the large sample size. More importantly, it is also more reliable on limited samples since the statistical tests with the lowest power are discarded. To support the claim, the authors provided proof for the change in FCI that guarantees good results despite the interruption. The result of the interrupted anytime FCI algorithm is still valid, but as it cannot provide answers to most questions, the results could be less informative compared to the situation if it was allowed to run uninterrupted.


\subsubsection{RFCI} \label{rfci}
Really Fast Causal Inference (RFCI) (\cite{rfci}) is a much faster variant of the traditional FCI for learning PAGs that uses fewer CI tests than FCI. Unlike FCI, RFCI assumes that causal sufficiency holds. To ensure soundness, RFCI performs some additional tests before orienting v-structures and discriminating paths. It conditions only on subsets of the adjacency sets and unlike FCI, avoids the CI tests given subsets of possible d-separation sets which can become very large even for sparse graphs. As a result, the number of these additional tests and the size of their conditioning sets are small for sparse graphs which makes RFCI much faster and computationally feasible than FCI for high-dimensional sparse graphs. Also, the lower computational complexity of RFCI leads to high-dimensional consistency results under weaker conditions than FCI.

\subsubsection{FCI with Tiered Background Knowledge} \label{fci-tiered}
\cite{tiredFCI} show that the Fast Causal Inference (FCI) algorithm (\cite{FCI}) is sound and complete with tiered background knowledge (TBK). By \emph{tiered background knowledge}, it means any knowledge where the variables may be partitioned into two or more mutually exclusive and exhaustive subsets among which there is a known causal order. Tiered background knowledge may arise in many different situations, including but not limited to instrumental variables, data from multiple contexts and interventions, and temporal data with contemporaneous confounding. The proof that FCI is complete with TBK suggests that the algorithm is able to find all of the causal relationships that are identifiable from tiered background knowledge and observational data under the typical assumptions.

\subsubsection{PC-stable} \label{pcstable}
% Most of the constraint-based algorithms including FCI, RFCI, etc. use the original PC algorithm in the first stage to perform the independence tests. 

The independence tests in the original PC method are prone to errors in the presence of a few samples. Additionally, because the graph is updated dynamically, maintaining or deleting an edge incorrectly will affect the neighboring sets of other nodes. As a result, the sequence in which the CI tests are run will affect the output graph. 
% To put it another way, the output graph will be impacted by the input data variables given a lexical order for executing the tests. 
Despite the fact that this order dependency is not a significant issue in low-dimensional situations, it is a severe problem in high-dimensional settings. To solve this problem, \cite{PC-stable} suggested changing the original PC technique to produce a stable output skeleton that is independent of the input dataset's variable ordering. This approach, known as the stable-PC algorithm, queries and maintains the neighbor (adjacent) sets of every node at each distinct level. Since the conditioning sets of the other nodes are unaffected by an edge deletion at one level, the outcome is independent of the variable ordering. They demonstrated that this updated version greatly outperforms the original algorithm in high-dimensional settings while maintaining the original algorithms’ low-dimensional settings performance. However, this modification lengthens the algorithm's runtime even more by requiring additional CI checks to be done at each level. The R-package \href{https://cran.r-project.org/web/packages/pcalg/index.html}{pcalg} contains the source code for PC-stable.


% \subsubsection{RRCD} \label{rrcd}
% To learn the causal structure from relational data, \cite{rrcd} developed a reliable method called RRCD (Robust Relational Causal Discovery). For establishing and orienting causal linkages in such a situation, existing techniques rely on \textit{relational conditional independence }(RCI) oracle queries. However, using relational data to identify RCI creates numerous distinct difficulties for RCI testing. %In reality, valid RCI tests on the available data must take the role of queries to an RCI oracle. 
% Existing CI tests are either not appropriate for RCI or have little power, making them unable to identify RCI. When used on small samples, even a well-designed RCI test might not be trustworthy enough. %Early on in the structure learning algorithm's execution, incorrect RCI test results might lead to irreparable algorithm misdirection. 
% Early on during the algorithm's execution, incorrect RCI test results might misguide the algorithm. A generic RCI test may produce insufficient findings by not taking into consideration the unique properties of a certain relational dataset. In this study the authors demonstrated how a CI test created for I.I.D. data can be successfully used to test for RCI against relational data. The \textit{Relational Causal Markov Condition} (RCMC) (\cite{RCMC}), which states that a relational variable must be independent of its non-descendants given its direct causes, enables the test to correctly establish relational conditional independence. However, when independence does not hold, the relational data's non-I.I.D.-ness aids the test in rejecting independence. Python implementation of RRCD is available at \url{https://github.com/sanghack81/RRCD}.

\subsubsection{PKCL} \label{pkcl}
\cite{PKCL} proposed an algorithm, \textbf{P}rior-\textbf{K}nowledge-driven Local \textbf{C}ausal Structure \textbf{L}earning (PKCL), to discover the underlying causal mechanism between \textit{bone mineral density} (BMD) and its factors from clinical data. It first discovers the neighbors of the target variables and then detects the MaskingPCs to eliminate their effect. After that, it finds the spouse of target variables utilizing the neighbors set. This way the skeleton of the causal network is constructed. In the global stage, PKCL leverages the \emph{Markov blanket (MB)} sets learned in the local stage to learn the global causal structure in which prior knowledge is incorporated to guide the global learning phase. Specifically, it learns the causal direction between feature variables and target variables by combining the constraint-based and score-based structure search methods. Also, in the learning phase, it automatically adds casual direction according to the available prior knowledge.  


\subsection{Score-based}

Score-based causal discovery algorithms search over the space of all possible DAGs to find the graph that best explains the data. Typically, any score-based approach has two main components:\textit{ (i) a search strategy} to explore the possible search states or space of candidate graphs\textit{ $G^{'}$, and (ii) a score function} to assess the candidate causal graphs. The search strategy along with a score function helps to optimize the search over the space of all possible DAGs. More specifically, a score function  $S(G^{'}, D)$  maps causal graphs $G^{'}$ to a numerical score, based on how well $G^{'}$ fits a given dataset $D$. A commonly used score function to select causal models is the \textit{Bayesian Information Criterion (BIC)} (\cite{BIC}) which is defined below: 

% \begin{equation}
%     S_{BIC} = -2 * loglikelihood + k * log(n),
% \end{equation} 
% where $n$ is the sample size used for training and $k$ is the total number of parameters. 

\begin{equation}
        \mathcal{S}(G^{'}, D) = -2\text{log} \ \mathcal{L}\{G^{'}, D\} + k \text{log} \ n,
\end{equation}
where $n$ is the number of samples in $D$, $k$ is the dimension of $G^{'}$ and $\mathcal{L}$ is the maximum-likelihood function associated with the candidate graph $G^{'}$. The lower the BIC score, the better the model. BDeu, BGe, MDL, etc. (listed in Table \ref{score-func}) are some of the other commonly used score functions. These objective functions are optimized through a heuristic search for model selection. After evaluating the quality of the candidate causal graphs using the score function, the score-based methods output one or more causal graphs that achieve the highest score (\cite{huang2018generalized}).  
We discuss some of the well-known approaches in this category below.
%They try to learn the causal graph by using a \emph{score function} such as $S(D,G)$ which returns the score of the causal graph $G$ given data $D$. 

\begin{figure}[h]
\centering
\includegraphics[width=0.4\textwidth]{Score-based-CD.PNG}
\caption{General components of a score-based causal discovery approach.}
\label{Score-based_CD}
\end{figure}

  

\begin{table}[!b]
\small
\centering
\caption{Some commonly used score functions for causal discovery. Please refer to the study \cite{generalized_score_func} for a detailed discussion of the score functions.}
\label{score-func}
\vspace{0.5\baselineskip}
\begin{tabular}{|c|c|}
\hline
\textbf{Score Function/Criterion} & \textbf{Ref.}  \\ \hline
Minimum description length (MDL) & \cite{MDL} \\ \hline
Bayesian information criterion (BIC) & \cite{BIC} \\ \hline
Akaike information criterion (AIC) & \cite{akaike1998information} \\ \hline
Bayesian Dirichlet equivalence score (BDeU) & \cite{BDeu-score} \\ \hline
Bayesian metric for Gaussian networks (BGe) & \cite{BGe-score} \\ 
\hline
Factorized normalized maximum likelihood (fNML) & \cite{fNML} \\ \hline
\end{tabular}
\end{table}


 
\subsubsection{GES} \label{ges}
%To identify the underlying Bayesian network from observational data, Christopher Meek proposed the so-called “Meek Conjecture” (\cite{Meek1997GraphicalMS}). “Meek Conjecture” states that if G and H are two DAGs where DAG H is an independence map of DAG G, then, for G, there is a finite sequence of edge additions and edge reversals that have the following characteristics: (1) G is a DAG after every edge change, and H continues to be G's independence map, and (2) G is equal to H after all edges are modified. But the validity of the “Meek Conjecture” was unknown until \cite{chickering2002optimal} provided the proof. Chickering proposed a score-based CD algorithm known as the Greedy Equivalence Search (GES) for figuring out the precise series of edge changes that convert G into H while maintaining H's independence from G after each modification. 



Greedy Equivalence Search (GES) (\cite{chickering2002optimal}) is one of the oldest score-based causal discovery algorithms that perform a greedy search over the space of equivalence classes of DAGs. 
%In GES, it is assumed that the data are produced from parameterizations of a real causal model that is represented by a DAG. GES further assumes that no variables are having a shared latent cause in the graph over the measured variables. 
Each search state is represented by a CPDAG where some insert and delete operators allow for single-edge additions and deletions respectively. Primarily GES works in two phases: i) Forwards Equivalence Search (FES), and ii) Backward Equivalence Search (BES). In the first phase, FES starts with an empty CPDAG (no-edge model), and greedily adds edges by taking into account every single-edge addition that could be performed to every DAG in the current equivalence class. After an edge modification is done to the current CPDAG, a score function is used to score the model. If the new score is better than the current score, only then the modification is allowed. When the forward phase reaches a local maximum, the second phase, BES starts where at each step, it takes into account all single-edge deletions that might be allowed for all DAGs in the current equivalence class. The algorithm terminates once the local maximum is found in the second phase. Implementation of GES is available at the following Python packages: Causal Discovery Toolbox or CDT (\cite{CDT}) and gCastle (\cite{gcastle}). GES assumes that the score function is decomposable and can be expressed as a sum of the scores of individual nodes and their parents. A summary workflow of GES is shown in Figure \ref{GES}.

% \begin{equation}
%     S(G,D) = \sum_{i=1}^{d} s(x_{i}, pa(x_{i},G))
% \end{equation}

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{GES.PNG}
\caption{Different stages in the GES algorithm.}
\label{GES}
\end{figure}

% The experiments in the paper show that GES provides superior performance against two other greedy search algorithms (D-space search and E-space search) for synthetic data. They referred to "D-space search" as a conventional DAG-space greedy method that takes into account the addition, deletion, and reversal of edges at each step. Another greedy approach that searches across equivalence classes, which they named E-space search. However, when applied to six real-world datasets, GES does not exceed the performance of the other two greedy algorithms and on top of that, it is comparatively slower than D-space and E-space search. 



\subsubsection{FGS} \label{fgs}
Fast Greedy Search (FGS) (\cite{ramsey2015scaling}) is another score-based method that is an optimized version of the GES algorithm (\cite{chickering2002optimal}). 
%This optimized algorithm can be applied to continuous variables and it is based on the faithfulness assumption. 
This optimized algorithm is based on the faithfulness assumption and uses an alternative method to reduce scoring redundancy. An ascending list $L$ is introduced which stores the score difference of arrows. After making a thorough search, the first edge e.g. $X$ $\rightarrow$ $Y$ is inserted into the graph and the graph pattern is reverted. For variables that are adjacent to $X$ or $Y$ with positive score differences, new edges are added to $L$. This process in the forward phase repeats until the $L$ becomes empty. Then the reverse phase starts, filling the list $L$ and continuing until $L$ is empty. This study considered the experiment where GES was able to search over 1000 samples with 50,000 variables in 13 minutes using a 4-core processor and 16GB RAM computer. Following the new scoring method, FGS was able to complete the task with 1000 samples on 1,000,000 variables for sparse models in 18 hours using a supercomputer having 40 processors and 384GB RAM at the Pittsburgh Supercomputing Center. %The authors believe that this work can be further optimized by extending it for discrete variables. 
The code for FGS is available on GitHub as a part of the Tetrad project: \url{https://github.com/cmu-phil/tetrad}. 

\subsubsection{SGES} \label{sges}
Selective Greedy Equivalence Search (SGES) (\cite{chickering2015selective}) is another score-based causal discovery algorithm that is a restrictive variant of the GES algorithm (\cite{chickering2002optimal}). By assuming perfect generative distribution, SGES provides a polynomial performance guarantee yet maintains the asymptotic accuracy of GES. While doing this, it is possible to keep the algorithm's large sample guarantees by ignoring all but a small fraction of the backward search operators that GES considered. In the forward phase, SGES uses a polynomial number of insert operation calls to the score function. %which results in an independence map (IMAP) of the graph. %An I-map is a network in which each disconnected pair of nodes stands for a different set of independent variables (\cite{iqbal2015overview}).
In the backward phase, it consists of only a subset of delete operators of GES which include, consistent operators to preserve GES’s consistency over large samples. The authors demonstrated that, for a given set of graph-theoretic complexity features, such as maximum-clique size, the maximum number of parents, and v-width, the number of score assessments by SGES can be polynomial in the number of nodes and exponential in these complexity measurements.



\subsubsection{RL-BIC} \label{rlbic}
RL-BIC is a score-based approach that uses \emph{Reinforcement Learning (RL)} and a BIC score to search for the DAG with the best reward  (\cite{rlbic}). For data-to-graph conversion, it uses an \emph{encoder-decoder architecture} that takes observational data as input and generates graph adjacency matrices that are used to compute rewards. The reward incorporates a BIC score function and two penalty terms for enforcing acyclicity. The \emph{actor-critic RL algorithm} is used as a \emph{search strategy} and the final output is the causal graph that achieves the best reward among all the generated graphs. The approach is applicable to small and medium graphs of up to 30 nodes. However, dealing with large and very large graphs is still a challenge for it. This study mentions that their future work involves developing a more efficient and effective score function since computing scores is much more time-consuming than training NNs. The original implementation of the approach is available at: \url{https://github.com/huawei-noah/trustworthyAI}.

\begin{figure}[h]
\centering
\includegraphics[width=0.63\textwidth]{RL-BIC.PNG}
\caption{Components of the RL-BIC (\cite{rlbic}) approach.}
\label{RL-BIC}
\end{figure}


\subsubsection{A* search} \label{a-star-search}
\cite{A-star-search} proposed a one-stage method for learning sparse network structures with continuous variables using the A* search algorithm with lasso in its scoring system. This method increased the computational effectiveness of popular exact methods based on dynamic programming. The study demonstrated how the proposed approach achieved comparable or better accuracy with significantly faster computation time when compared to two-stage approaches, including L1MB and SBN. Along with that, a heuristic approach was added that increased A* lasso's effectiveness while maintaining the accuracy of the outcomes. In high-dimensional spaces, this is a promising approach for learning sparse Bayesian networks.

\subsubsection{Triplet A*} \label{tripleta*}
\cite{tripletA*} uses the \emph{A* exhaustive search} (\cite{yuan2013learning}) combined with an optimal BIC score that requires milder assumptions on data than conventional CD approaches to guarantee its asymptotic correctness. The optimal BIC score combined with the exhaustive search finds the MEC of the true DAG if and only if the true DAG satisfies the optimal BIC Condition. To gain scalability, they also developed an approximation algorithm for complex large systems based on the A* method. This extended approach is named Triplet A* which can scale up to more than 60 variables. This extended method is rather general and can be used to scale up other exhaustive search approaches as well. Triplet A* can particularly handle linear Gaussian and non-Gaussian networks. It works in the following way. Initially, it makes a guess about the parents and children of each variable. Then for each variable $X$ and its neighbors $(Y, Z)$, it forms a cluster consisting of $X, Y, Z$ with their direct neighbors and runs an exhaustive search on each cluster. Lastly, it combines the results from all clusters. The study shows that empirically Triplet A* outperforms GES for large dense networks.

\subsubsection{KCRL} \label{kcrl}
Prior \textbf{K}nowledge-based \textbf{C}ausal Discovery Framework with\textbf{ R}einforcement \textbf{L}earning a.k.a. KCRL (\cite{KCRL}) is a framework for causal discovery that utilizes prior knowledge as constraints and penalizes the search process for violation of these constraints. This utilization of background knowledge significantly improves performance by reducing the search space, and also, enabling a faster convergence to the optimal causal structure. KCRL leverages reinforcement learning (RL) as the search strategy where the RL agent is penalized each time for the violation of any imposed knowledge constraints. In the KCRL framework (Figure \ref{KCRL}), at first, the observational data is fed to an RL agent. Here, data-to-adjacency matrix conversion is done using an encoder-decoder architecture which is a part of the RL agent. At every iteration, the agent produces an equivalent adjacency matrix of the causal graph. A comparator compares the generated adjacency matrix with the true causal edges in the prior knowledge matrix $P_{m}$, and thereby, computes a penalty $p$ for the violation of any ground truth edges in the produced graph. Each generated graph is also scored using a standard scoring function such as BIC. A reward $R$ is estimated as a sum of the BIC score $S_{BIC}$, the penalty for acyclicity $h(W)$, and $\beta$ weighted prior knowledge penalty $\beta p$. Finally, the entire process halts when the stopping criterion $S_{c}$ is reached, and the best-rewarded graph is the final output causal graph. Although originally KCRL was designed for the healthcare domain, it can be used in any other domain for causal discovery where some prior knowledge is available. Code for KCRL is available at \url{https://github.com/UzmaHasan/KCRL}.


\begin{equation}
    R = S_{BIC} + \beta p + h(W) 
\end{equation}


\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{KCRL.png}
\caption{The KCRL (\cite{KCRL}) framework.}
\label{KCRL}
\end{figure}


Another recent method called \textbf{\textit{KGS}} (\cite{KGS}) leverages prior causal information such as the presence or absence of a causal edge to guide a greedy score-based causal discovery process towards a more restricted and accurate search space. It demonstrates how the search space as well as scoring candidate graphs can be reduced when different edge constraints are leveraged during a search over equivalence classes of causal networks. It concludes that any type of edge information is useful to improve the accuracy of the graph discovery as well as the run time.

\subsubsection{ILP-based structure learning}\label{ILP}
\cite{ILP} looked into the application of integer linear programming (ILP) to the structure learning problem. To boost the effectiveness of ILP-based Bayesian network learning, they suggested adding auxiliary implied constraints. Experiments were conducted to determine the effect of each constraint on the optimization process. It was discovered that the most effective configuration of these constraints could significantly boost the effectiveness and speed of ILP-based Bayesian network learning. The study made a significant contribution to the field of structure learning and showed how well ILP can perform under non-essential constraints.

\subsection{Functional Causal Model-based}
Functional Causal Model (FCM) based approaches describe the causal relationship between variables in a specific functional form. FCMs represent variables as a function of their parents (direct causes) together with an independent noise term $E$ (see Equation \ref{FCM}) (\cite{zhang2015estimation}). FCM-based methods can distinguish among different DAGs in the same equivalence class by imposing additional assumptions on the data distributions and/or function classes (\cite{zhang2021gcastle}). Some of the noteworthy FCM-based causal discovery approaches are listed below.


\begin{equation}
    X = f(PA_{X}) + E
    \label{FCM}
\end{equation}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\textwidth] {FCM.png}
    \caption{A functional causal model (FCM) with four variables.}
    \label{FCM-fig}
\end{figure}




\subsubsection{L$i$NGAM} \label{lingam-section}
Linear Non-Gaussian Acyclic Model (LiNGAM) aims to discover the causal structure from observational data under the assumptions that the data generating process is linear, there are no unobserved confounders, and noises have non-Gaussian distributions with non-zero variances (\cite{LiNGAM}). It uses the statistical method known as independent component analysis (ICA) (\cite{ICA}), and states that when the assumption of \textbf{non-Gaussianity} is valid, the complete causal structure can be estimated. That is, the causal direction is identifiable if the variables have a linear relation, and the noise ($\varepsilon$) distribution is non-Gaussian in nature. Figure \ref{Lin-3-cases} depicts three scenarios where when $X$ and $\varepsilon$ are Gaussian (case 1), the predictor and regression residuals are independent of each other. For the other two cases, $X$ and $\varepsilon$ are non-Gaussian, and we see that for the regression in the anti-causal or backward direction ($X$ given $Y$), the regression residual and the predictor are not independent as earlier. That is, for the non-Gaussian cases, independence between regression residual and predictor occurs only for the correct causal direction. There are 3 properties of a LiNGAM. \textit{First}, the variables $x_{i} = {x_{1},x_{2}, ..., x_{n}}$ are arranged in a causal order $k(i)$ such that the cause always preceedes the effect. \textit{Second}, each variable $x_{i}$ is assigned a value as per the Equation \ref{lingam} where $e_{i}$ is the noise/disturbance term and $b_{ij}$ denotes the causal strength between $x_{i}$ and $x_{j}$. \textit{Third}, the exogenous noise $e_{i}$ follows a non-Gaussian distribution, with zero mean and non-zero variance, and are independent of each other which implies that there is no hidden confounder. Python implementation of the LiNGAM algorithm is available at \url{https://github.com/cdt15/lingam} as well as in the gCastle package (\cite{zhang2021gcastle}). Any standard ICA algorithm which can estimate independent components of many different distributions can be used in LiNGAM. However, the original implementation uses the FastICA (\cite{FastICA}) algorithm. 
\begin{equation}
    x_{i} = \sum_{k(j)<k(i)} b_{ij}x_{j} + e_{i}
    \label{lingam}
\end{equation}

\begin{figure}[h]
\centering
\includegraphics[width=0.75\textwidth]{Lingam-three-cases.png} 
\caption{Causal asymmetry between two variables having a linear relation (\cite{s1}). Here, the causal direction is from $X$ to $Y$. A total of three scenarios are depicted where both $X$ and $\varepsilon$ follow the i) Gaussian, ii) Uniform, or iii) Super-Gaussian distribution for each of the scenarios.}
\label{Lin-3-cases}
\end{figure}
%without any pre-specified time-ordering of the variables. A 

\subsubsection{ANM} \label{anm_section}
\cite{anm} performs causal discovery with additive noise models (ANMs) and provides a generalization of the linear non-Gaussian causal discovery framework to deal with nonlinear functional dependencies where the variables have an additive noise. It mentions that nonlinear causal relationships typically help to break the symmetry between the observed variables and help in the identification of causal directions. ANM assumes that the data generating process of the observed variables is as per the Equation \ref{anm} where a variable $x_{i}$ is a function of its parents and the noise term $e_{i}$ which is an independent additive noise. An implementation of ANM is available in the gCastle package (\cite{gcastle}).
\begin{equation}
    x_{i} = f(PA_{x_{i}}) + e_{i}
    \label{anm}
\end{equation}


\subsubsection{PNL} \label{pnl}
% Model-based causal discovery techniques are being used for differentiating causes from effects. In order to understand how the data are generated, model-based causal discovery relies on a generative model. These techniques might not only identify the causal relationships but also figure out how one variable influences the others when the presumed model is close to the real one. Model-based causal discovery, however, may produce false results if the given model is incorrect. As a result, the assumed model should be sufficiently broad such that it may be modified to roughly represent the real process of data generation when previous knowledge of the data model is not provided. The model should, nevertheless, be recognizable enough to be able to separate causes from consequences. 

% To solve these issues, \cite{PNL} provided a highly realistic model, the post-nonlinear (PNL) acyclic causal model with inner additive noise. Under the assumption that the relevant nonlinearities are invertible, they demonstrated the identifiability of this model in the two-variable situation. In their proposed model, 

Post-nonlinear (PNL) acyclic causal model with additive noise (\cite{PNL}) is a highly realistic model where each observed continuous variable is made up of additive noise-filled nonlinear functions of its parents, followed by a nonlinear distortion. The influence of sensor distortions, which are frequently seen in practice, is taken into account by the second stage's nonlinearity. A two-step strategy is proposed to separate the cause from the effect in a two-variable situation, consisting of restricted nonlinear ICA followed by statistical independence tests. The PNL model was able to effectively separate causes from effects when applied to solve the "CauseEffectPairs" task proposed by \cite{PNL2} in the Pot-luck challenge. That is, it successfully distinguished the cause from the effect, even if the nonlinear function of the cause is not invertible.


\subsubsection{Direct-L$i$NGAM} \label{directlingam}
\cite{directlingam} proposed DirectLiNGAM, a direct method for learning a linear non-Gaussian structural equation model (SEM) which is a direct method to estimate causal ordering and connection strengths based on non-Gaussianity. This approach estimates a causal order of variables by successively reducing each independent component from given data in the model which is completed in steps equal to the number of the variables in the model. Once the causal order of variables is identified, their connection strengths are estimated using conventional covariance-based methods such as least squares and maximum likelihood approaches. If the data strictly follows the model i.e. if all the model assumptions are met and the sample size is infinite, it converges to the right solution within a small number of steps. If some prior knowledge on a part of the structure is available, it suggests using those for more efficient learning. Doing so will reduce the number of causal orders and connection strengths to be estimated. Its implementation can be found at: \url{https://github.com/huawei-noah/trustworthyAI/tree/master/gcastle}.

\subsubsection{SAM} \label{sam}
\cite{SAM} proposed the algorithm known as  \textit{Structural Agnostic Modeling }(SAM) that uses an \emph{adversarial learning} approach to find the causal graphs. Particularly, it searches for an FCM using \emph{Generative Adversarial Neural-networks (GANs)}  and enforces the discovery of sparse causal graphs through adequate regularization terms. A learning criterion that combines distribution estimation, sparsity, and acyclicity constraints is used to enforce the end-to-end optimization of the graph structure and parameters through stochastic gradient descent. SAM leverages both conditional independencies and distributional asymmetries in the data to find the underlying causal mechanism. It aims to achieve an optimal complexity/fit trade-off while modeling the causal mechanisms. SAM enforces the acyclicity constraint of a DAG using the function in Equation \ref{SAM} where, $A$ is the adjacency matrix of the ground-truth graph $G$, and $d$ denotes the total number of nodes in $G$. The latest implementation of SAM is available in the CDT package (\cite{CDT}). Also, an older version of SAM is available at \url{https://github.com/Diviyan-Kalainathan/SAM}.

\begin{equation}
    \sum_{i=1}^d = \frac{\trace (A^{i})}{i!} = 0
    \label{SAM}
\end{equation}

\subsubsection{CGNN} \label{cgnn}
\textbf{C}ausal \textbf{G}enerative \textbf{N}eural \textbf{N}etworks (CGNN) is an FCM-based framework that uses \emph{neural networks (NNs)} to learn the joint distribution of the observed variables (\cite{cgnn}). Particularly, it uses a generative model that minimizes the \emph{maximum mean discrepancy} (MMD) between the generated and observed data. CGNN has a high computational cost. However, it proposes an approximate learning criterion to scale the computational cost to linear complexity in the number of observations. This framework can also be used to simulate interventions on multiple variables in the dataset. An implementation of CGNN in Pytorch is available at \url{https://github.com/FenTechSolutions/CausalDiscoveryToolbox}. 

\subsubsection{CAM} \label{cam}
\textbf{C}ausal \textbf{A}dditive \textbf{M}odel (CAM) is a method for estimating high-dimensional additive structural equation models which are logical extensions of linear structural equation models (\cite{cam}). In order to address the difficulties of computation and statistical accuracy in the absence of prior knowledge about underlying structure, the authors established consistency of the maximum likelihood estimator and developed an effective computational algorithm. The technique was demonstrated using both simulated and actual data and made use of tools in sparse regression techniques. The authors also discussed identifiability problems and the enormous size of the space of potential models, which presents significant computational and statistical accuracy challenges.

\subsubsection{CAREFL} \label{carefl}
Causal Autoregressive Flows (CAREFL) uses \emph{autoregressive flow models} (\cite{autoregressiveflows}) for causal discovery by interpreting the ordering of variables in an autoregressive flow based on structural equation models (SEMs) (\cite{carefl}). In general, SEMs define a generative model for data based on causal relationships. CAREFL shows that particularly \textit{affine flows} define a new class of causal models where the noise is modulated by the cause. For such models, it proves a new causal identifiability result that generalizes additive noise models. To learn the causal structure efficiently, it selects the ordering with the highest test log-likelihood and reports a measure of causal direction based on the likelihood ratio for non-linear SEMs. Autoregressive flow models also enable CAREFL to evaluate interventional queries by fixing the interventional variable while sampling from the flow. Moreover, the invertible property of autoregressive flows facilitates counterfactual queries as well. Code implementation of CAREFL is available at \url{https://github.com/piomonti/carefl}. 





%\subsection{Continuous Optimization-based} 
\subsection{Gradient-based} 
Some of the recent studies in causal discovery formulate the structure learning problem as a continuous optimization task using the least squares objective and an algebraic characterization of DAGs (\cite{notears}, \cite{golem}). Specifically, the combinatorial structure learning problem has been transformed into a continuous one and solved using gradient-based optimization methods (\cite{gae}). These methods leverage gradients of an objective function with respect to a parametrization of a DAG matrix. Apart from the usage of well-studied gradient-based solvers, they also leverage GPU acceleration which has changed the nature of the task (\cite{golem}). Furthermore, to accelerate the task they often employ deep learning models that are capable of capturing complex nonlinear mappings (\cite{dag-gnn}). As a result, they usually have a faster training time as deep learning is known to be highly parallelizable on GPU, which gives a promising direction for causal discovery with gradient-based methods (\cite{gae}). In general, these methods are more global than other approximate greedy methods. This is because they update all edges at each step based on the gradient of the score and as well as based on the acyclicity constraint. %It also allows the replacement of task-specific greedy algorithms with appropriate off-the-shelf numerical solvers (\cite{gran-dag}). 



\subsubsection{NOTEARS} \label{notears}
DAGs with NO TEARS (\cite{notears}) is a recent breakthrough in the field of causal discovery that formulates the structure learning problem as a purely continuous constrained optimization task. It leverages an algebraic characterization of DAGs and provides a novel characterization of acyclicity that allows for a smooth global search, in contrast to a combinatorial local search. The full form of the acronym NOTEARS is \textbf{N}on-combinatorial \textbf{O}ptimization via \textbf{T}race \textbf{E}xponential and \textbf{A}ugmented lag\textbf{R}angian for \textbf{S}tructure learning which particularly handles linear DAGs.  It assumes a linear dependence between random variables and thus models data $D$ as a structural equation model. %It adopts a least squares loss with $l_{1}$ penalty and imposes acyclicity as a constraint. 
To discover the causal structure, it imposes the proposed acyclicity function (Equation \ref{acyc}) as a constraint combined with a weighted adjacency matrix $W$ with least squares loss.  %To ensure that a matrix W is a DAG, it must follow the proposed acyclicity constraint (cite equation 1) where 0 is the Hadamard product and $e^{W0W}$ is the matrix exponential of WoW. 
The algorithm aims to convert the traditional combinatorial optimization problem into a continuous constrained optimization task by leveraging an algebraic characterization of DAGs via the trace exponential acyclicity function as follows: 
% \[ \underset{ \text{subject to } G(W) \in DAGs}{ \mathop{\min}_{W \in \mathbb{R}^{d \times d}} F(W) } \iff \underset{ \text{subject to } h(W) = 0}{ \mathop{\min}_{W \in \mathbb{R}^{d \times d}} F(W) } \]
\begin{equation}
    \underset{ \text{subject to } G(W) \in DAGs}{ \mathop{\min}_{W \in \mathbb{R}^{d \times d}} F(W) } \iff \underset{ \text{subject to } h(W) = 0}{ \mathop{\min}_{W \in \mathbb{R}^{d \times d}} F(W) },
    \label{optimization}
\end{equation}
where $G(W)$ is a graph with $d$ nodes induced by the weighted adjacency matrix $W$, $F: \mathbb{R}^{d \times d} \rightarrow \mathbb{R}$ is a regularized score function with a least-square loss $\ell$, and $h:\mathbb{R}^{d \times d} \rightarrow \mathbb{R}$ is a smooth function over real matrices that enforces acyclicity. Overall, the approach is simple and can be executed in about 50 lines of Python code. Its implementation in Python is publicly available at \url{https://github.com/xunzheng/notears}. The acyclicity function proposed in NOTEARS is as follows where $\circ$ is the Hadamard product and $e^{W \circ W}$ is the matrix exponential of $W \circ W$.

 
\begin{equation}
h(W) = \trace (e^{W \circ W}) - d =0
\label{acyc}  
\end{equation}



% They modeled $D \in \mathbb{R}^{n \times d}$ as a structural equation model (SEM) by a random vector $X = (X_{1}, ... , X_{d})$ defined by weighted adjacency matrix $W$. The structure
% of $G(W)$ is defined by the nonzero coefficients in $W$, i.e., $X_{i} \rightarrow X_{j} \in  G$ if and only if $W(i,j)$ is nonzero. This enables search in continuous space of $d \times d$ real matrices. 

% For linear SEM (both Gaussian and non-Gaussian) and the LS loss, the regularized score function is $F(W) = \ell(W; X) + \lambda {||W||}_{1} = \frac{1}{2n} ||X - XW||^{2} + \lambda {||W||}_{1}$. Here, $\lambda$ is a regularization parameter or penalty coefficient.


% \begin{equation}
%     \min_{M \in R^{d\times d}} F(W)
% \end{equation}

\subsubsection{GraN-DAG} \label{gran-dag}
Gradient-based Neural DAG Learning (GraN-DAG) is a causal structure learning approach that uses \emph{neural networks (NNs)} to deal with non-linear causal relationships (\cite{gran-dag}). It uses a stochastic gradient method to train the NNs to improve scalability and allow implicit regularization. It formulates a \emph{novel characterization of acyclicity} for NNs based on NOTEARS (\cite{notears}). To ensure acyclicity in non-linear models, it uses an argument similar to NOTEARS and applies it first at the level of neural network paths and then at the graph paths level. For regularization, GraN-DAG uses a procedure called \textit{preliminary neighbors selection} (PNS) to select a set of potential parents for each variable. It uses a final pruning step to remove the false edges. The algorithm works well mostly in the case of non-linear Gaussian additive noise models. An implementation of GraN-DAG can be found at \url{https://github.com/kurowasan/GraN-DAG}.


\subsubsection{GAE} \label{gae}
\textbf{G}raph\textbf{ A}uto\textbf{e}ncoder (GAE) approach is a gradient-based approach to causal structure learning that uses a \emph{graph autoencoder framework} to handle nonlinear structural equation models (\cite{gae}). GAE is a \textit{special case} of the causal additive model (CAM) that provides an alternative generalization of NOTEARS for handling nonlinear causal relationships. GAE is easily applicable to vector-valued variables. The architecture of GAE consists of a variable-wise encoder and decoder which are basically multi-layer perceptrons (MLPs) with shared weights across all variables $X_{i}$. The encoder-decoder framework allows the reconstruction of each variable $X_{i}$ to handle the nonlinear relations. The final goal is to optimize the reconstruction error of the GAE with $l_{1}$ penalty where the optimization problem is solved using the augmented Lagrangian method (\cite{augmentedLag}). The approach is competitive in terms of scalability as it has a near-linear training time when scaling up the graph size to 100 nodes. Also, in terms of time efficiency, GAE performs well with an average training time of fewer than 2 minutes even for graphs of 100 nodes. Its implementation can be found at the gCastle (\cite{gcastle}) repository.


\subsubsection{DAG-GNN} \label{daggnn}
DAG Structure Learning with Graph Neural Networks (DAG-GNN) is a graph-based deep generative model that tries to capture the sampling distribution faithful to the ground-truth DAG (\cite{dag-gnn}). It leverages variational inference and a parameterized pair of \emph{encoder-decoders} with specially designed \emph{graph neural networks (GNN)}. Particularly, it uses \emph{Variational Autoencoders (VAEs)} to capture complex data distributions and sample from them. The weighted adjacency matrix $W$ of the ground-truth DAG is a learnable parameter with other neural network parameters. The VAE model naturally handles various data types both continuous and discrete in nature. In this study, the authors also propose a \emph{variant of the acyclicity function} (Equation \ref{dag-gnn}) which is more suitable and practically convenient for implementation with the existing deep learning methods. In the acyclicity function, $d$ = the number of nodes, $\alpha$ is a hyperparameter, and $I$ is an identity matrix. An implementation of the DAG-GNN algorithm is available at \url{https://github.com/fishmoon1234/DAG-GNN}.

\begin{equation}
\trace[(I +\alpha W \circ W)^{d}] - d = 0
\label{dag-gnn}  
\end{equation}




\subsubsection{GOLEM} \label{golem}
Gradient-based Optimization of DAG-penalized Likelihood for learning linear DAG Models (GOLEM) is a \emph{likelihood-based} causal structure learning approach with \emph{continuous unconstrained optimization} (\cite{golem}). It studies the asymptotic role of the sparsity and DAG constraints for learning DAGs in both linear Gaussian and non-Gaussian cases. It shows that when the optimization problem is formulated using a likelihood-based objective instead of least squares (used by NOTEARS), then instead of a hard DAG constraint, applying only soft sparsity and DAG constraints is enough for learning the true DAG under mild assumptions. Particularly, GOLEM tries to optimize the score function in Equation \ref{GOLEM-equation} w.r.t. the weighted adjacency matrix $B$ representing a directed graph. Here, $L(B;x)$ is the maximum likelihood estimator, $R_{sparse}(B)$ is a penalty to encourage sparsity (i.e. fewer edges), and $R_{DAG}(B)$ is the penalty that enforces DAGness on $B$. 

\begin{equation}
    S(B;x) = L(B;x) + R_{sparse}(B) + R_{DAG}(B)
    \label{GOLEM-equation}
\end{equation}

In terms of denser graphs, GOLEM seems to outperform NOTEARS since it can reduce the number of optimization iterations which makes it robust in terms of scalability. With gradient-based optimization and GPU acceleration, it can easily handle thousands of nodes while retaining high accuracy. An implementation of GOLEM can be found at the gCastle (\cite{gcastle}) repository.



\subsubsection{DAG-NoCurl} \label{dag-nocurl}
DAG-NoCurl also known as DAGs with No Curl uses a two-step procedure for the causal DAG search (\cite{dagNOcurl}). At first, it finds an initial cyclic solution to the optimization problem and then employs the \emph{Hodge decomposition} (\cite{hodge}) of graphs to learn an acyclic graph by projecting the cyclic graph to the gradient of a potential function. The goal of this study is to investigate how the causal structure can be learned without any explicit DAG constraints by directly optimizing the DAG space. To do so, it proposes the method DAG-NoCurl based on the graph Hodge theory that implicitly enforces the acyclicity of the learned graph. As per the Hodge theory on graphs (\cite{lim2020hodge}), a DAG is a sum of three components: \textit{a curl-free, a divergence-free, }and \textit{a harmonic component}. The curl-free component is an acyclic graph that motivates the naming of this approach. An implementation of the method can be found at the link \url{https://github.com/fishmoon1234/DAG-NoCurl}. 

\subsubsection{ENCO} \label{enco}
Efficient Neural Causal Discovery without Acyclicity Constraints (ENCO) \emph{uses both observational and interventional data} by modeling a probability for every possible directed edge between pairs of variables (\cite{enco}). It formulates the graph search as an optimization of independent edge likelihoods, with the edge orientation being modeled as a separate parameter. This approach guarantees convergence when interventions on all variables are available and do not require explicitly constraining the score function with respect to acyclicity. However, the algorithm works on partial intervention sets as well. Experimental results suggest that ENCO is robust in terms of scalability, and \textit{is able to detect latent confounders}. When applied to large networks having 1000 nodes, it is capable of recovering the underlying structure due to the benefit of its low-variance gradient estimators. The source code of ENCO is available at this site: \url{https://github.com/phlippe/ENCO}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.7\textwidth] {ENCO.png}
    \caption{Graph optimization mechanism of ENCO.}
    \label{fig:my_label}
\end{figure}


\subsubsection{MCSL} \label{mcsl}
\textbf{M}asked Gradient-based \textbf{C}ausal \textbf{S}tructure \textbf{L}earning (MCSL) (\cite{mcsl}) utilizes a reformulated structural equation model (SEM) for causal discovery using gradient-based optimization that leverages the \emph{Gumbel-Softmax approach} (\cite{Gumbel}). This approach is used to approximate a binary adjacency matrix and is often used to approximate samples from a categorical distribution. MCSL reformulates the SEM with additive noises in a form parameterized by the binary graph adjacency matrix. It states that, if the original SEM is identifiable, then the adjacency matrix can be identified up to super-graphs of the true causal graph under some mild conditions. For experimentation, MCSL uses multi-layer perceptrons (MLPs), particularly having 4-layers as the model function which is denoted as MCSL-MLP. An implementation of the approach can be found in the gCastle (\cite{gcastle}) package.

\subsubsection{DAGs with No Fears} \label{nofears}
\cite{DAG-no-fear} provides an in-depth analysis of the NOTEARS framework for causal structure learning. The study proposed a local search post-processing algorithm that significantly increased the precision of NOTEARS and other algorithms and deduced Karush-Kuhn-Tucker (KKT) optimality conditions for an equivalent reformulation of the NOTEARS problem. Additionally, the authors compared the effectiveness of NOTEARS and Abs-KKTS on various graph types and discovered that Abs-KKTS performed better than NOTEARS in terms of accuracy and computational efficiency. The authors concluded that this work improved the understanding of optimization-based causal structure learning and may result in further advancements in precision and computational effectiveness. The code implementation is available at \url{https://github.com/skypea/DAG_No_Fear}.








% \subsubsection{CAMML} \label{camml}

% CaMML incorporates multiple kinds of prior expert knowledge into its search to test and compare unbiased discovery with discovery biased with different kinds of expert opinion (\cite{CAMML}). It uses adjacency matrices enhanced with numerical and color labels to assist with the interpretation of the results. CaMML attempts to learn the best underlying causal structure using a minimum message length (MML) metric with a two-phase search, where simulated annealing is followed by a \emph{Markov Chain Monte Carlo (MCMC)} search over the model space. CaMML allows the incorporation of several levels of structural information having a confidence level. 






%\subsection{Hybrid Approaches}
\subsection{Miscellaneous Approaches}
Apart from the types of approaches mentioned so far, there are some other causal discovery approaches that use some specialized or unique techniques to search for the graph that best describes the data. There also exists some methods that are specialized to handle latent or unobserved confounders. Also, there are some approaches that are hybrid in nature, i.e. they are based on the combination of constraint-based, score-based, FCM-based, gradient-based, etc. causal discovery approaches. For example, some approaches integrate conditional independence testing along with score functions to design a hybrid approach for causal discovery. A detailed discussion can be found below.


\subsubsection{MMHC} \label{mmhc}
\textbf{M}ax-\textbf{M}in \textbf{H}ill \textbf{C}limbing (MMHC) is a hybrid causal discovery technique that incorporates the concepts from both score-based and constraint-based algorithms (\cite{mmhc}). A challenge in causal discovery is the identification of causal relationships within a reasonable time in the presence of thousands of variables. MMHC can reliably learn the causal structure in terms of time and quality for high-dimensional settings. MMHC is a two-phase algorithm that assumes faithfulness. In the first phase, MMHC uses Max-Min Parents and Children (MMPC) (\cite{tsamardinos2003time}) to initially learn the skeleton of the network. In the second phase, using a greedy Bayesian hill-climbing search, the skeleton is oriented. In the sample limit, MMHC's skeleton identification phase is reliable, but the orientation phase offers no theoretical assurances. From the results of the experiments performed, MMHC outperformed PC (\cite{pc}), Sparse Candidate (\cite{friedman2013learning}), Optimal Reinsertion (\cite{moore2003optimal}),  and GES (\cite{chickering2002optimal}) in terms of computational efficiency. Considering the quality of reconstruction, MMHC performs better than all the above-mentioned algorithms except for GES when the sample size is 1000. The authors also proved the correctness of the results. The implementation of MMHC is available at \url{http://www.dsl-lab.org/supplements/mmhc paper/mmhc index.html} as part of Causal Explorer 1.3, a library of Bayesian network learning and local causal discovery methods.

\subsubsection{FRITL} \label{fritl}
To discover causal relationships in linear and non-Gaussian models, \cite{fritl} proposed a hybrid model named FRITL. FRITL works in the \textit{presence or absence of latent confounders} by incorporating independent noise-based techniques and constraint-based techniques. FRITL makes causal Markov assumption, causal faithfulness assumption, linear acyclic non-Gaussianity assumption, and one latent confounder assumption. In the \textit{first phase} of FRITL, the FCI algorithm is used to generate asymptotically accurate results. Unfortunately, relatively few unconfounded direct causal relations are normally determined by the FCI since it always reveals the presence of confounding factors. In the \textit{second phase}, FRITL identifies the unconfounded causal edges between observable variables within just those neighboring pairings that have been influenced by the FCI results. The \textit{third stage} can identify confounders and the relationships that cause them to affect other variables by using the Triad condition (\cite{triad}). If further causal relationships remain, \textit{Independent Component Analysis }(ICA) is finally applied to a notably reduced group of graphs. The authors also theoretically proved that the results obtained from FRITL are efficient and accurate. FRITL produces results that are in close accord with neuropsychological opinion and in exact agreement with a causal link that is known from the experimental design when applied to real functional magnetic MRI data and the SACHS (\cite{sachs2005causal}) dataset.

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{FRITL.png}
\caption{Stages of the FRITL model.}
\label{FRITL}
\end{figure}


\subsubsection{HCM} \label{hcm}
Most of the causal discovery algorithms are applicable only to either discrete or continuous data. However, in reality, we often have to work with mixed-type data (e.g., shopping behavior of people) which don’t receive enough attention in causal discovery. \cite{hcm} proposed the approach \emph{\textbf{H}ybrid \textbf{C}ausal Discovery on \textbf{M}ixed-type Data (HCM)} to identify causal relationships with mixed variables. HCM works under the causal faithfulness and causal Markov assumption. HCM has three phases where in the \textit{first phase}, the skeleton graph is learned in order to limit the search space. To do this, they used the PC-stable approach along with their proposed Mixed-type Randomized Causal Independence Test (MRCIT) which can handle mixed-type data. They also introduced a generalized score function called Cross-Validation based Mixed Information Criterion (CVMIC). In the \textit{second phase}, starting with an empty DAG, they add edges to the DAG based on the highest CVMIC score. In order to reduce false positives, the learned causal structure is pruned using MRCIT once again in the \textit{final phase} with a slightly bigger conditional set. They compared their approach with other causal discovery approaches for mixed data and showed HCM’s superiority. However, they didn’t consider any unobserved confounders in the dataset which allows for further improvement. They made the code available on the following GitHub site: \url{https://github.com/DAMO-DI-ML/AAAI2022-HCM}.


\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{HCM.png}
\caption{Different phases of the method HCM.}
\label{HCM}
\end{figure}






%%\subsubsection{CCHM}............................

%%\subsubsection{GFCI}................................




\subsubsection{SADA} \label{sada}
One of the biggest limitations of the traditional causal discovery methods is that these models cannot identify causal relations when the problem domain is large or there is a small number of samples available. To solve this problem, \cite{sada} proposed a \emph{Split-and-Merge} causal discovery method named SADA which assumes causal faithfulness. Even in situations when the sample size is substantially less than the total number of variables, SADA can reliably identify the causal factors. SADA divides the main problem into two subproblems and works in three phases. Initially, SADA separates the variables of the causal model into two sets $V_{1}$ and $V_{2}$ using a causal cut set $C$ where all paths between $V_{1}$ and $V_{2}$ are blocked by $C$. This partitioning is continued until the variables in each subproblem are less than some threshold. In the next phase, any arbitrary causal algorithm is applied to both subproblems and the causal graphs are generated. Here, they used LiNGAM as the causal algorithm. Then these graphs are merged in the final step. But to handle the conflicts while merging, they only kept the most significant edge and eliminated the others whenever there existed multiple causal paths between two variables in the opposite direction. They compared the performance of SADA against baseline LiNGAM (without splitting and merging), and the results showed that SADA achieved better performance in terms of the metrics precision, recall, and F1 score.

\subsubsection{CORL} \label{corl}
Ordering-based Causal Discovery with Reinforcement Learning (CORL) formulates the ordering search problem as a \emph{multi-step Markov decision process} (MDP) to learn the causal graph (\cite{corl}). It implements the ordering generating process with an \emph{encoder-decoder architecture} and finally uses RL to optimize the proposed model based on the reward mechanisms designed for each order. A generated ordering is then processed using variable selection to obtain the final causal graph. According to the empirical results, CORL performs better than existing RL-based causal discovery approaches. This could happen because CORL does not require computing the matrix exponential term with O($d^3$) cost because of using ordering search. CORL is also good in terms of scalability and has been applied to graphs with up to 100 nodes. The gCastle package contains an implementation of CORL.

\subsubsection{ETIO} \label{etio}
ETIO is a versatile \emph{logic-based} causal discovery algorithm specialized for business applications (\cite{etio}). Its features include i) the ability to utilize prior causal knowledge, ii) addressing selection bias, hidden confounders, and missing values in data, and iii) analyzing data from pre and post-interventional distribution. ETIO follows a \emph{query-based approach}, where the user queries the algorithm about the causal relations of interest. In the first step, ETIO performs several CI tests on the input dataset. Particularly, it performs non-Bayesian tests that return p-values of the null hypothesis of conditional independencies. Then it employs an empirical Bayesian method that converts the p-values of dependencies and interdependencies into probabilities. Later, it selects a consistent subset of dependence, and prior knowledge constraints to resolve conflicts which are ranked in order of confidence. Particularly, ETIO imposes an m-separation constraint if a given independence is more probable than the corresponding dependence. These imposed constraints are the ones that correspond to test results, in order of probability, while removing conflicting test results. Finally, it identifies all invariant features based on input queries using the well-known declarative programming language, answer set programming (\cite{ASP}). 

\subsubsection{$b$QCD}
Discovering causal relationships from observational data has been a challenging task, especially for the bivariate cases as it is difficult to determine whether there actually exists a cause-effect relationship or whether it is the effect of a \textit{hidden confounder}. \cite{bqcd} proposed the approach \textbf{b}ivariate \textbf{Q}uantile \textbf{C}ausal \textbf{D}iscovery (bQCD) to determine causal relationships in bivariate settings. Although they made no assumptions on the class of causal mechanisms, they did assume that there exists no confounder, feedback, or selection bias. They utilized \emph{quantile scoring} in place of Kolmogorov complexity (\cite{kolmogorov1963tables}), and used conditional quantiles, pinball loss instead of conditional mean, and squared loss. The approach bQCD performs almost similarly to the state-of-the-art techniques but it is much more computationally inexpensive. Also, the usage of quantile conditioning instead of mean conditioning makes bQCD more robust to heavy tails as the mean is more susceptible to outliers than the quantile. Moreover, not making any assumptions about the parametric class allows bQCD to be applied to a variety of processes where baseline methods perform significantly poorly when the assumptions do not hold. The source code of bQCD written in R is available on this site: \url{https://github.com/tagas/bQCD}.


\subsubsection{JCI} \label{jci}
\textbf{J}oint \textbf{C}ausal \textbf{I}nference (JCI) leverages prior knowledge by combining data from multiple datasets from different contexts  (\cite{mooij2020joint}). Particularly, JCI is a \emph{causal modeling framework} rather than a specific algorithm, and it can be implemented using any causal discovery algorithm that can take into account some background knowledge. The main idea of JCI is to first, consider auxiliary context variables that describe the context of each data set, then, pool all the data from different contexts, including the values of the context variables, into a single data set, and finally apply standard causal discovery methods to the pooled data, incorporating appropriate background knowledge on the causal relationships involving the context variables. The framework is simple and easily applicable as it deals with latent confounders, cycles (if the causal discovery method supports this), and various types of interventions in a unified way. The JCI framework also facilitates analysis of data from almost arbitrary experimental designs which allow researchers to trade off the number and complexity of experiments to be done with the reliability of the analysis for the purpose of causal discovery.


\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{JCI.png}
\caption{Workflow of the JCI framework.}
\label{JCI}
\end{figure}



% \subsubsection{CausalVAE}
% \cite{CausalVAE} proposed a generative model named CausalVAE which learns disentangled and causally meaningful representation of the data by combining ideas of Variational Autoencoder (VAE) with the Structural Causal Model (SCM). They introduced a Causal Layer inside the vanilla VAE model which converts independent exogenous factors into causal endogenous ones. They didn’t provide the causal graph to the model. Instead, they used the label of the causal variables as additional information, and the causal layer generated the causal graph from that. They evaluated the model on two synthetic datasets and the popular benchmark dataset CelebA. Once the true causal graph is identified, CausalVAE could generate counterfactual images and perform interventions effectively using the “do-operator”. CausalVAE outperformed non-causal VAE models ($\beta$-VAE (\cite{higgins2017beta}), LadderVAE (\cite{sonderby2016ladder}), ConditionVAE (\cite{sohn2015learning})) in terms of the degree of information relevance between the learned representation and ground truth.


\subsubsection{Kg2Causal} \label{kg2causal}
Kg2Causal (\cite{kg2causal}) uses a large-scale general-purpose biomedical knowledge graph as a prior for data-driven causal discovery. With a set of observed nodes in a dataset and some relationship edges between the nodes derived from a knowledge graph, Kg2Causal uses the knowledge graph-derived edges to guide the data-driven discovery of a causal graph. The main ideas of this approach are first, mapping each variable in the dataset to a node in the knowledge graph, and querying relationships between them; next, extracting a subgraph containing the connected variables with edges between them; and then this edge set is used as prior knowledge to guide an optimizing scoring step for inferring the causal graph. An implementation of Kg2Causal is available at \url{https://github.com/meghasin/Kg2Causal} %\href{ https://github.com/meghasin/Kg2Causal}{this repository} 
in R language.

\subsubsection{C-MCMC} \label{c-mcmc}
\textbf{C}onstrained MCMC (C-MCMC) introduces \emph{prior knowledge} into the \emph{Markov chain Monte Carlo (MCMC)} algorithm for structure learning (\cite{CMCM}). C-MCMC uses the following \emph{three types of prior knowledge}: the existence of parent nodes, absence of parent nodes, and distribution knowledge including the conditional probability distribution (CPD) of edges and the probability distribution (PD) of nodes. All prior knowledge should be given by domain experts. Existence knowledge means that for any node $X_{i}$, a node-set $pa(X_{i})$ includes all parent nodes of $X_{i}$. The absence of knowledge means that for a node $X_{i}$, a node-set $pa(X_{i})$ does not include any parent node of $X_{i}$. PD/CPD knowledge means that the PD of a node and the CPD of an edge are known. Considering that the prior knowledge may not be consistent and reliable, a confidence lambda is assigned by domain experts on each of the prior knowledge that ranges from 0 to 1. This denotes the certainty level of prior knowledge. A \emph{lambda} value of 1 indicates very high confidence in this knowledge.



\subsubsection{M$eta$-RL} \label{meta-rl}
Meta-RL is a \emph{meta-learning algorithm} in a Reinforcement Learning (RL) setting where the agent learns to \emph{perform interventions} to construct a causal graph (\cite{metaRL}). The goal is to be able to use previous learning experiences during training to generalize in unseen environments. This approach has some strong assumptions such as i) each environment is defined by an acyclic SCM, ii) every observable variable can be intervened on, iii) for each environment in the training set, the underlying SCM is given, and iv) intervention can be performed on at most one variable at a time. Meta-RL has two phases: i) Training, and ii) Application. The training phase starts by randomly choosing an SCM from a set of environments. There are mainly two sets of actions that an agent performs: \emph{a) interventional actions}, and \emph{b) structure actions}. In each step, any one action can be performed on the set of variables to generate a PDAG. The \emph{agent policy is updated} via the \emph{interventional actions} in each step. However, in case of the structural actions (e.g. add, delete, or reverse), the agent policy only gets updated at the end of the training procedure where a reward is sent to the agent. The reward is computed by comparing the hamming distance of the generated PDAG to the true causal structure when the training is completed. A \emph{recurrent LSTM layer} enables the policy to remember samples from the post-interventional distributions in the earlier steps. This should help to better identify causal relations since the results of sequential interventions can be used to estimate the distribution. Once trained, Meta-RL can then be applied to environments that have a structure unseen during training. For training, 24 SCMs with 3 observable variables, and 542 SCMs with 4 observable variables were created. Code to reproduce experiments or run Meta-RL is available at \url{https://github.com/sa-and/interventional_RL}. One limitation of this approach is that it needs modification in terms of scalability. Also, in real-world scenarios, every variable might not be accessible for intervention.

\begin{figure}[!h]
\centering
\includegraphics[width=0.5\textwidth]{Meta-RL.png}
\caption{Training phase of the Meta-RL algorithm (\cite{metaRL}).}
\label{Meta-RL}
\end{figure}


\subsubsection{Tabu search for SEM} \label{tabu}
\cite{tabu-search-SEM} presents an approach to structural equation modeling (SEM) specification search that makes use of Tabu search, a heuristic optimization algorithm. Using a neighborhood of the current solution as its focus, the tabu search technique avoids local optimality by examining the area around the current solution. To prevent cycling, it assigns recently involved attributes a \textit{tabu status}. A number of definitions and parameters, such as the neighborhood definition and the model selection criterion, are necessary to implement the Tabu search procedure for SEM specification search. The authors conclude that Tabu search is a promising strategy for SEM specification search after demonstrating its efficacy in a number of example analyses. 

\subsubsection{LFCM} \label{lfcm}
\textbf{L}atent \textbf{F}actor \textbf{C}ausal \textbf{M}odels (LFCMs) (\cite{LFCM}) perform causal discovery in the \emph{presence of latent variables}. These models are motivated by gene regulatory networks. LFCMs work in three stages where they discover: (i) clusters of observed nodes, (ii) a partial ordering over clusters, and (iii) finally, the entire structure over both observed and latent nodes. A graph $G$ is called a latent factor causal model (LFCM) if it satisfies the following conditions: (a) Unique cluster assumption: Each observed node has exactly one latent parent, (b) Bipartite assumption: There are no edges between pairs of observed nodes or between pairs of latent nodes, (c) Triple-child assumption: Each latent node has at least 3 observed children and (d) Double-parent assumption. The other assumption of LFCMs is that it allows non-exogenous latent variables. For cluster formation, LFCMs rely on t-separation (\cite{t-separation}). When two ordered pairs of variables [e.g. ($X_{i}$, $X_{j}$) and ($X_{u}$, $X_{v}$)] are t-separated, then they belong to the same cluster. LFCMs are a biologically motivated class of causal models with latent variables. The limitations of LFCMs include their applicability to only a linear Gaussian SEM, some major structural restrictions, and that it can fail when the true graph violates the double parent assumption.

\begin{figure}[h]
\centering
\includegraphics[width=0.55\textwidth]{LFCM.png}
\caption{The graph $G$ on the left is a latent factor causal model (LFCM), and the graph on the right is the latent graph $L(G)$ for $G$ (\cite{LFCM}).}
\label{HCM}
\end{figure}

There are some other noteworthy methods that are specialized to handle latent variables or unobserved confounders. \cite{LVM-1} presented a non-parametric algorithm for learning a causal graph in the presence of hidden variables. The study took a stage-by-stage approach, first to learn the induced graph between observational variables, and then use it to discover the existence and location of the latent variables. The authors further proposed an algorithm to discover the latent structure between variables depending on the adjacency. To identify ancestral relationships and transitive closure of the causal graph, the algorithm employed a pairwise independence test under interventions. Then \cite{LVM-2} addressed causal discovery by linking conditional independencies from observed data to graphical constraints using the d-separation criterion. It broadened the application of this strategy to scenarios involving numerous experimental and observational distributions. The authors proposed that CIs and d-separation constraints are just a subset of broader constraints obtained from comparing various distributions, which is especially useful in the context of do-calculus for soft interventions. They introduced the notion \textit{interventional equivalence class of causal graphs with latent variables}, which linked graphical structures to groups of interventional distributions that adhered to do-calculus. Two causal graphs are interventionally equivalent if they produce identical interventional distributions that can not be distinguished by invariances.

Sometimes complex systems require the knowledge of both observations and experiments for recovering the underlying causal relationships. Utilizing both observational and interventional data from various domains, the authors in \cite{LVM4} proposed a novel approach for identifying causal structures in semi-Markovian systems with latent confounders. They made a link between learning from interventional data within a single domain and learning from observational data across domains. They introduced the idea of S-Markov, a property connecting multi-domain distributions to pairs of causal graphs and interventional targets, to navigate the complexities of observational and experimental data. A new causal discovery algorithm called S-FCI was introduced that builds on the S-Markov property and is capable of effectively learning from a mixture of observational and interventional data from various domains.  

\cite{LVM-3} integrates soft experimental and observational data to find the structure in non-Markovian systems with latent variables. They introduced the idea of $\Psi$-Markov in this context when the intervention targets were unidentified. This idea links a causal graph \textit{G} and a list of interventional targets \textit{I} to the causal invariances found in both observational and interventional data distributions. They also introduced a graphical method for evaluating equivalence between causal graphs with various interventional targets and an algorithm for learning the equivalence class. 

Recently, \cite{LVM-5-score} studied structure learning in discrete models with arbitrary latent dependencies, and proposed a new score based on the asymptotic expansion of the marginal likelihood to capture both equality and inequality constraints in observational data. Furthermore, it claims to be the first score-based method to learn causal models with latent variables.

The different methods discussed in this section so far use a variety of strategies to perform causal discovery under diverse settings and assumptions. Therefore, we present a comparative analysis of some of the common methods in Table~\ref{table-IID-comparison} based on their assumptions, output causal graph, techniques used, advantages, and disadvantages. This comparative analysis will help readers to find the similar and dissimilar methods, and also help in deciding which method could be appropriate for performing causal discovery given the data and its assumptions.

%**************COMPARISON-TABLE*****************%%**************COMPARISON-TABLE*****************%%**************COMPARISON-TABLE*****************%

\begin{landscape}
\centering
\scriptsize
\begin{longtable}{|c|c|c|c|c|c|}
\caption{Comparison among some causal discovery algorithms for I.I.D. data.}\\
\hline
\label{table-IID-comparison} 
\textbf{Methods} & \textbf{Assumptions} & \begin{tabular}[c]{@{}c@{}} \textbf{Outcome} \end{tabular} & \textbf{Technique used} & \textbf{Advantages} & \textbf{Disadvantages} \\ \hline
PC & Faithfulness, Sufficiency & CPDAG & Conditional Independence (CI) Tests & \begin{tabular}[c]{@{}c@{}}Computationally more \\ feasible for sparse graphs.\end{tabular} & \begin{tabular}[c]{@{}c@{}}Lacks scalability as less \\ feasible for denser graphs\end{tabular} \\ \hline
FCI & \begin{tabular}[c]{@{}c@{}}Causal Markov \\ condition, faithfulness\end{tabular} & PAG &  \begin{tabular}[c]{@{}c@{}} CI tests, Skeleton \\ finding step same as PC \end{tabular} & \begin{tabular}[c]{@{}c@{}}Handles latent and\\ selection variables.\end{tabular} & \begin{tabular}[c]{@{}c@{}}In the worst case, the no. of \\ CI tests performed grows \\ exponentially with the no. \\ of variables.\end{tabular} \\ \hline
RFCI & CMC, faithfulness & PAG & Conditional Independence tests & \begin{tabular}[c]{@{}c@{}}Faster variant of FCI, uses \\ fewer CI tests, computationally feasible \\ for high-dimensional sparse graphs\end{tabular} & \begin{tabular}[c]{@{}c@{}}Performs some additional tests \\ before orienting v-structures \\ and discriminating paths\end{tabular} \\ \hline
GES & \begin{tabular}[c]{@{}c@{}}Decomposable   \\ score function\end{tabular} & CPDAG & Score-based greedy search & \begin{tabular}[c]{@{}c@{}}Run time faster compared to \\ the constraint-based methods\end{tabular} & \begin{tabular}[c]{@{}c@{}}Search space can grow \\ exponentially with the growing \\ no. of variables\end{tabular} \\ \hline
FGS & Weak Faithfulness & DAG & Score-based greedy search & \begin{tabular}[c]{@{}c@{}}Faster variant of GES, reduces scoring \\ redundancy, enables parallelization\end{tabular} & \begin{tabular}[c]{@{}c@{}}Require high power \\ computing to run\end{tabular} \\ \hline
RL-BIC & \begin{tabular}[c]{@{}c@{}} Decomposable score \\ function, acyclicity \end{tabular}& DAG & \begin{tabular}[c]{@{}c@{}} BIC score-based \\ reinforcement learning search \end{tabular} & \begin{tabular}[c]{@{}c@{}}Model gets feedback to update\\ /correct its search strategy\end{tabular} & \begin{tabular}[c]{@{}c@{}}Scalable only up to a few \\ (around 30) variables\end{tabular} \\ \hline
Triplet A* & Acyclicity & DAG & \begin{tabular}[c]{@{}c@{}} A* search combined \\ with BIC score \end{tabular}& \begin{tabular}[c]{@{}c@{}}Can handle both linear Gaussian \& \\ non-Gaussian networks, scales up to \\ more than 60 variables\end{tabular} & Has complexity issues \\ \hline
KCRL & \begin{tabular}[c]{@{}c@{}}Decomposable score-function, \\ unbiased prior knowledge\end{tabular} & DAG & Score-based RL search strategy & \begin{tabular}[c]{@{}c@{}}Considers prior \\ knowledge constraints\end{tabular} & Lacks scalability \\ \hline
LiNGAM & \begin{tabular}[c]{@{}c@{}}Linear DGP,  no unobserved \\ confounders, non-Gaussian noises \end{tabular} & DAG & \begin{tabular}[c]{@{}c@{}}FCM-based, uses independent \\ component analysis \end{tabular} & \begin{tabular}[c]{@{}c@{}}Determines the direction of \\ every causal arrow, does not r\\ require the faithfulness assumption.\end{tabular} & \begin{tabular}[c]{@{}c@{}}Estimated results may \\ vary in case of mixed data \\ (categorical values)\end{tabular} \\ \hline
SAM & Acyclicity & DAG & Searches for an FCM using GANs & Good for sparse causal graphs & \begin{tabular}[c]{@{}c@{}}Not suitable for \\ dense graphs\end{tabular} \\ \hline
Tabu search & \begin{tabular}[c]{@{}c@{}}Finite search space, \\ well-defined objective function\end{tabular} & DAG & \begin{tabular}[c]{@{}c@{}}Iteratively modifies the model \\ and evaluates its fit to the data \\ by examining a neighborhood of the \\ current solution\end{tabular} & \begin{tabular}[c]{@{}c@{}}Considers avoiding local optima \\ and also, cycle avoidance\end{tabular} & \begin{tabular}[c]{@{}c@{}}Quality of the results depends \\ on the quality of the initial \\ solution and the choice \\ of parameters\end{tabular} \\ \hline
CAM & Sufficiency, Acyclicity & DAG & \begin{tabular}[c]{@{}c@{}}FCM-based, uses sparse \\ regression techniques and decouples \\ order search among the variables\end{tabular} & \begin{tabular}[c]{@{}c@{}}Establishes consistency of the \\ maximum likelihood estimator \\ for low and high-dimensional cases\end{tabular} & \begin{tabular}[c]{@{}c@{}}Faces performance and \\ computational challenges \\ as the number of \\ variables increases\end{tabular} \\ \hline
NOTEARS & \begin{tabular}[c]{@{}c@{}}Acyclicity, linear dependence \\ between variables\end{tabular} & DAG & \begin{tabular}[c]{@{}c@{}}Models data as a SEM, \\ uses a regularized score-function \\ with a least-square loss\end{tabular} & \begin{tabular}[c]{@{}c@{}}Simple method, \\ easy to implement\end{tabular} & \begin{tabular}[c]{@{}c@{}}Works well mostly for \\ continuous data\end{tabular} \\ \hline
GAE & \begin{tabular}[c]{@{}c@{}}Structure learning under \\ additive noise models\end{tabular} & DAG & \begin{tabular}[c]{@{}c@{}}Gradient-based approach that uses a\\ graph autoencoder framework\end{tabular} & \begin{tabular}[c]{@{}c@{}}Can scale up to 100 nodes, \\ Lower run time, easily applicable \\ to vector-valued variables, \& handles \\ non-linear relations well\end{tabular} & \begin{tabular}[c]{@{}c@{}}May not work well for \\ linear causal relations\end{tabular} \\ \hline
DAG-GNN & Faithfulness, sufficiency & DAG & \begin{tabular}[c]{@{}c@{}}Gradient-based, uses blackbox \\ stochastic optimization solvers \\ to solve the sub problem of \\ maximizing the ELBO\end{tabular} & \begin{tabular}[c]{@{}c@{}}Can handle both discrete and \\ vector-valued variables, and is \\ capable of capturing complex \\ nonlinear mappings\end{tabular} & \begin{tabular}[c]{@{}c@{}}Assumes acyclic causal \\ relationships, which may not \\ always be the case \\ in real-world scenarios\end{tabular} \\ \hline
MMHC & \begin{tabular}[c]{@{}c@{}}Faithfulness, sufficiency, \\ decomposable score-function\end{tabular} & DAG & \begin{tabular}[c]{@{}c@{}}Hybrid: uses both score and \\ constraint-based techniques such as  \\ MMPC to initially learn the skeleton of \\ the network, then  uses greedy \\ Bayesian hill-climbing search\end{tabular} & \begin{tabular}[c]{@{}c@{}}Good computational efficiency, \\ scalability, and applicable for \\ high-dimensional settings\end{tabular} & \begin{tabular}[c]{@{}c@{}}Scales up better only with \\ large number of samples\end{tabular} \\ \hline
FRITL & \begin{tabular}[c]{@{}c@{}}Faithfulness, non-Gaussianity, \\ latent confounder assumption\end{tabular} & PAG & \begin{tabular}[c]{@{}c@{}}Hybrid, uses FCI, Triad \\ condition and ICA\end{tabular} & \begin{tabular}[c]{@{}c@{}}Works in presence or \\ absence of latent confounders\end{tabular} & \begin{tabular}[c]{@{}c@{}}Not generalizable in \\ non-linear gaussian cases\end{tabular} \\ \hline
% JCI & \begin{tabular}[c]{@{}c@{}}Faithfulness, Joint SCM, \\ Exogeneity, Complete Randomized \\ Context, Generic Context Model\end{tabular} & DAG & \begin{tabular}[c]{@{}c@{}}Hybrid, constraint-based methods, \\ score-based methods\end{tabular} & \begin{tabular}[c]{@{}c@{}}Can discover causal relations \\ from multiple contexts, and \\ can leverage prior knowledge\end{tabular} & \begin{tabular}[c]{@{}c@{}}Computationally expensive \\ for large datasets\end{tabular} \\ \hline
Kg2Causal & \begin{tabular}[c]{@{}c@{}}Presence of a knowledge graph\end{tabular} & DAG & \begin{tabular}[c]{@{}c@{}}Prior knowledge constraints \\ added in a score-based method\end{tabular} & \begin{tabular}[c]{@{}c@{}}Leverages information from \\ existing literature or domain\end{tabular} & Requires a knowledge graph \\ \hline
% LFCM & \begin{tabular}[c]{@{}c@{}}Faithfulness, Sufficiency, and \\ Double-parent assumption\end{tabular} & DAG & \begin{tabular}[c]{@{}c@{}}Uses rank constraints on submatrices \\ of the covariance matrix to estimate \\ the model parameters\end{tabular} & \begin{tabular}[c]{@{}c@{}}Can identify causal relations \\ between variable clusters that \\ share the same latent parent\end{tabular} & \begin{tabular}[c]{@{}c@{}}May fail under a \\ violation of the double\\ parent assumption\end{tabular} \\ \hline
\end{longtable}
\end{landscape}

%**************COMPARISON-TABLE*****************%%**************COMPARISON-TABLE*****************%%**************COMPARISON-TABLE*****************%



\section{Causal Discovery Algorithms for Time Series Data} 
\label{section-4}
%Causal Discovery Approaches for Time-series Data

Time series data arise when observations are collected over a period of time. So far the methods that we have discussed are specialized for causal discovery from I.I.D. or time-independent data. However, often, real-world data in different domains can be a time series (non-I.I.D. data). For this type of data, there are different specialized causal discovery approaches based on CI testing, SEM/FCMs, Granger causality (\cite{GC}), or deep neural networks. In this section, first, we provide a brief introduction to some of the common terminologies related to time-series data and temporal causal discovery. Then, we discuss the notable causal discovery approaches for time-series data.

%deep neural networks \cite{dnn}

\begin{definition}[Time Series Data]
    Time series data is a collection of observations measured over consistent intervals of time. The observation of a time series variable $X^{j}$ at time $t$ is denoted by $X^{j}_{t}$. 
\end{definition}

Examples of time series data include retail sales, stock prices, climate data, heart rate of patients, brain activity recordings, temperature readings, etc. Any time series data may have the following \textbf{\emph{properties}}:

\begin{enumerate}[i]
    \item \emph{\textbf{Trend}:} When the data show a long-term rise or fall, a trend is present. Such long-term increases or decreases in the data might not be always linear. The trend is also referred to as \textit{changing direction} when it might switch from an upward trend to a downward trend.
    
    \item \emph{\textbf{Seasonality}:} It refers to the seasonal characteristics of time series data. Seasonality exists when the data regularly fluctuates based on different time spans (e.g. daily/weekly/
    monthly/quarterly/yearly). An example is temperature data, where it is mostly observed that the temperature is higher in the summer, and lower in the winter. Any analysis related to time series usually takes advantage of the seasonality in data to develop more robust models.

    \item \textit{\textbf{Autocorrelation}:} Autocorrelation or self-correlation is the degree of similarity between a given time series and a lagged version of itself over successive time intervals. Time series data is usually autocorrelated i.e., the past influences the present and future (\cite{auto-corr}).

    \item \textit{\textbf{Stationarity \& Non-stationarity}:} Stationarity means that the joint probability distribution of the stochastic process does not change when shifted in time. A time series is stationary if it has causal links such that for variables $X^{i}$ and $X^{j}$, if $X^{i}$ → $X^{j}$ at any timestamp $t$, then $X^{i}$ → $X^{j}$ also holds for all $t'$ $\not=$ $t$. This condition does not hold for a non-stationary time series where $X^{i}$ → $X^{j}$  at a particular time $t$ need not necessarily be true at any other time stamp $t'$.
\end{enumerate}



Let $X^{j}_{1:t}$ = \{$X^{1}_{1:t}$, $X^{2}_{1:t}$, …, $X^{n}_{1:t}$\} be a multivariate time series with $n$ variables and $t$ time steps. At any particular timestamp $t$, the state of the $n$ variables can be represented as $X^{j}_{t}$ = \{$X^{1}_{t}$, $X^{2}_{t}$, …, $X^{n}_{t}$\}. The past of a variable $X^{j}_{t}$ is denoted by $X^{j}_{1:t-1}$. The parent set of a variable includes all the nodes with an edge towards it. The goal of any temporal causal discovery approach is to discover the causal relationships between the time series variables. Any time series causal graph may have the following \emph{\textbf{types of causal relationships/edges}}: \textit{(i) Instantaneous edges}, and \textit{(ii) Lagged edges}.

\begin{figure}[!h]
\centering
\includegraphics[width=0.4\textwidth]{Temporal_Causal_edges.PNG} 
\caption{Types of causal relationships: Instantaneous edges (red), Lagged edges (blue), and Changing modules (green).}
\label{Temporal-Edges}
\end{figure}


\begin{definition} [Instantaneous Causal Effect]
     When the delay between cause and effect is 0 timesteps, i.e. causal effects are of the form $X^{i}_{t}$ $\rightarrow$ $X^{j}_{t}$ or $X^{i}_{t}$ $\rightarrow$ $X^{i}_{t}$ (self-causation), then it is known as an instantaneous or contemporaneous causal relationship/effect (\cite{TCDF}). 
\end{definition}

\begin{definition}[Lagged Causal Effect]
    When the delay between cause and effect is at least 1 or more timesteps (i.e. causal effects of the form $X^{i}_{t-}$ $\rightarrow$ $X^{j}_{t}$ or $X^{i}_{t-}$ $\rightarrow$ $X^{i}_{t}$), then it is known as a lagged causal relationship/effect. That is, a lagged causal effect occurs when a variable causes another variable or itself with a time lag = 1 or more. 
\end{definition}

In Figure \ref{Temporal-Edges}, the red-colored edges represent the instantaneous causal effect (relationships among the variables at the same time step), and the blue edges represent the lagged causal effect. The green edges represent a special form of temporal causal relationships known as the \emph{\textbf{changing modules}} (CM). The CMs represent the direct effect of a time stamp on a variable (e.g. $t \rightarrow X^{1}_{t}$ in Figure \ref{Temporal-Edges}). Details on CM are available in \cite{ferdous2023cdans}. \\

% \begin{enumerate}[i]
%     \item \textit{Instantaneous Causal Effect:} When the delay between cause and effect is 0-time steps, then it is known as an instantaneous causal relationship/effect (\cite{TCDF}). In \autoref{Temporal-Edges}, the red-colored edges are the instantaneous edges (relationships among the variables at the same time step).

%     \item \textit{Lagged Causal Effect:} When the delay between cause and effect is 1 or more time steps, then it is known as a lagged causal relationship/effect. That is, a lagged causal effect occurs when one variable causes another variable or itself with a time lag = 1 or more. 

% \end{enumerate}





The causal graphs produced by different temporal causal discovery algorithms vary based on the details of the relationships they represent. Any temporal causal discovery algorithm may produce any of the following two \textit{\textbf{types of temporal causal graph}} as its outcome: a \textit{full-time causal graph} or a \textit{summary causal graph} (see Figure \ref{temporal_grpph_type}). 

\begin{definition}[Full-time Causal Graph]
     A full-time causal graph represents both the instantaneous ($X^{i}_{t}$ $\rightarrow$ $X^{j}_{t}$ or $X^{i}_{t}$ $\rightarrow$ $X^{i}_{t}$) and time-lagged ($X^{i}_{t-}$ $\rightarrow$ $X^{j}_{t}$ or $X^{i}_{t-}$ $\rightarrow$ $X^{i}_{t}$) causal edges where the lag between a cause and effect is specified in the graph. A full-time casual graph may sometimes present the changing modules as well.
\end{definition}


\begin{figure}[h]
\centering
\includegraphics[width=0.4\textwidth]{Full-time-causal-graph.jpeg} \hspace{1cm}\includegraphics[width=0.2\textwidth]{Summary_Causal_Graph.jpeg} 
\caption{Full-time causal graph (Left) \& Summary causal graph (Right)}
\label{temporal_grpph_type}
\end{figure}



Figure \ref{temporal_grpph_type} (left) represents a full-time causal graph where both instantaneous relations (e.g. $X^{1}_{t}$ $\rightarrow$ $X^{2}_{t}$, $X^{1}_{t-1}$ $\rightarrow$ $X^{2}_{t-1}$), and lagged relations (e.g. $X^{2}_{t-1}$ $\rightarrow$ $X^{3}_{t}$, $X^{3}_{t-1}$ $\rightarrow$ $X^{3}_{t}$) among the variables are depicted.  



\begin{definition}[Summary Causal Graph]
    A summary causal graph is a reduced version of a full-time causal graph where each lagged node represents the entire past ($X^{j}_{t-}$) of its corresponding instantaneous node ($X^{j}_{t}$), and the exact time lag between the cause and effect is not specified in the graph.
\end{definition}

%\autoref{temporal_grpph_type} (right) represents a summary causal graph.

% \begin{enumerate}[i]
%     \item \textit{Full-time Causal Graph:} A full-time causal graph represents both the instantaneous and time-lagged causal edges where all the lags between a cause and effect is specified in the graph. A full-time casual graph may sometimes present the changing modules as well.

%     \item \textit{Summary Causal Graph:} A summary causal graph is a reduced version of a full-time causal graph where each lagged node represents the entire past ($X^{j}_{t-}$) of its corresponding instantaneous node ($X^{j}_{t}$) and the exact time lag between the cause and effect is not specified in the graph.
% \end{enumerate}



% \begin{definition}[Granger Causality]
    
% \end{definition}
In the following subsections, we describe briefly some of the notable causal discovery algorithms that focus on time series data. Figure \ref{tax-time-series} presents a taxonomy of some of the discussed approaches.

% https://tex.stackexchange.com/questions/495962/hierarchy-diagram

\begin{figure}
    \centering
        {\footnotesize % to reduce the size of forest tree
        \begin{forest}
        forked edges,
        for tree={draw,align=left,l=1.7cm,edge={-latex}}
            [Causal Discovery Algorithms\\\hspace{0.5cm}(for time series data)
                [Contraint-based
                    [tsFCI (\ref{tsfci})\\PCMCI (\ref{pcmci})\\{LPCMCI}$^\ast$ (\ref{lpcmci})\\{CDANs} (\ref{cdans})]
                ]
                [FCM-based
                    [VarLiNGAM (\ref{varlingam})\\TiMINo (\ref{timino})]
                ]
                [Gradient-based
                    [{DYNOTEARS}$^\diamond$ (\ref{dynotears})\\{NTS-NOTEARS}$^\diamond$$^\ast$ (\ref{nts-notears})]
                ]
                [Granger Causality-based
                    [GVAR (\ref{gvar})\\NAVAR (\ref{navar})\\ACD (\ref{acd})]
                ]
                [Miscellaneous
                    [oCSE (\ref{ocse})\\TCDF (\ref{tcdf})\\NBCB (\ref{nbcb})\\PCTMI (\ref{pctmi})\\]
                ]
          ]
        \end{forest}
        }
    \caption{Taxonomy of some of the discussed causal discovery approaches for time series data. The approaches are classified based on their core contribution or the primary strategy they adopt for causal structure recovery. The approaches that can leverage prior knowledge are marked by an $\ast$ symbol. Some of the gradient-based approaches that use a score function are indicated by a $\diamond$ symbol. They are primarily classified as such as they use gradient descent for optimization. However, they can be a score-based method too as they compute data likelihood scores on the way.}
    \label{tax-time-series}
\end{figure}


% \begin{figure}[h]
% \centering
% \includegraphics[width=1\textwidth]{Taxonomy_of_Time_Series_CD_algos.PNG}
% \caption{Taxonomy of some causal discovery approaches for time series data.}
% \label{tax-time-series}
% \end{figure}

%%So far the methods that we have discussed are specialized for causal discovery from i.i.i or stationary data. However, often, real-world data can be a time series (non-I.I.D. data) or have temporal components. For such types of data, there are different specialized CD approaches based on CI testing, SEM/FCMs, or deep neural networks. This subsection discusses some of the notable causal discovery approaches for time-series data. Usually, the outcome of a time-series CD algorithm is any of the two types of graph such as a full-time causal graph or a summary causal graph. A \emph{full-time causal graph} represents both the instantaneous and time-lagged causal relationships by explicitly specifying the lags whereas a \emph{summary causal graph} is a reduced version of a full-time causal graph where each node represents an entire time series.



\subsection{Constraint-based}

\subsubsection{$ts$FCI} \label{tsfci}

The algorithm \textit{time series} FCI or tsFCI (\cite{tsFCIl}) adapts the Fast Causal Inference (\cite{FCI}) algorithm (developed for the causal analysis of non-temporal variables) to infer causal relationships from time series data. It works in two phases: (i) an \textit{adjacency phase}, and (ii) an \textit{orientation phase}. It makes use of temporal priority and consistency throughout time to orient edges and restrict conditioning sets. It provides a window causal graph, and an advantage is that it \emph{can detect lagged hidden confounders}. However, a disadvantage is that it cannot model cyclic contemporaneous causation, and also instantaneous relationships. A code package that implements tsFCI is available at \url{https://sites.google.com/site/dorisentner/publications/tsfci}.

\subsubsection{PCMCI} \label{pcmci}
A problem with large-scale time series data is that although adding more variables makes causal analysis more interpretable, if the additional variables don’t have a significant effect on the causal model, this, in turn, makes the analysis less powerful, and original causal relations may also be overlooked. Moreover, at large dimensions, certain nonlinear tests even lose their ability to limit false positive rates (FPRs). \cite{pcmci} proposed a two-stage algorithm PCMCI that can overcome this problem. In \textit{Step-1}, the model selects conditions using $PC_{1}$ (a variant of the skeleton discovery part of the PC algorithm) to remove irrelevant variables which solve the issue of low power in the causal discovery process. In \textit{Step-2}, the momentary conditional independence (MCI) test is used which helps to reduce the FPR even when the data is highly correlated. The MCI test measures if two variables are independent or not given their parent sets (see Equation \ref{MCI_equation}). 

\begin{equation}
    X^{i}_{t-\tau} \indep X^{j}_{t} | P_{A}(X^{j}_{t}), P_{A}(X^{i}_{t-\tau})
    \label{MCI_equation}
\end{equation}

PCMCI assumes that the data is stationary, has time-lagged dependencies, and also assumes causal sufficiency. Even when the stationary assumption is violated (probably by obvious confounders), PCMCI still provides a more robust performance than Lasso regression or the PC algorithm. However, for highly predictable systems where little new information is produced at each time step, PCMCI is not a good fit. Python implementation of PCMCI is available in the\textit{ Tigramite }package (\url{https://github.com/jakobrunge/tigramite}).

%Lasso regression (\cite{tibshirani1996regression})
\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{PCMCI.PNG}
\caption{Steps involved in the PCMCI method for time series causal discovery.}
\label{PCMCI}
\end{figure}







\subsubsection{PCMCI+} \label{pcmci+}
PCMCI+ (\cite{pcmci+}) is an extension of the PCMCI algorithm to discover contemporary or instantaneous causal links. PCMCI+ also assumes causal sufficiency like the PCMCI algorithm. It is also a two-stage algorithm where in the first stage, irrelevant edges from the causal model are eliminated. Unlike PCMCI, the edges are removed separately for lagged and contemporary conditioning sets where the contemporary phase employs more CI tests than the lagged phase. In the second stage, PCMCI+ employs the notion of momentary conditional independence (MCI) to improve the selection of conditioning sets for the various CI tests, improving their autocorrelation calibration, and boosting their detection power. The results show that when there is high autocorrelation in the data, PCMCI+ can achieve better performance in terms of higher recall, lower false positives, and faster execution compared to the PC algorithm. For lower autocorrelation, PCMCI+ performs almost similarly to PC. Implementation of PCMCI+ is also available in the Tigramite package (\url{https://github.com/jakobrunge/tigramite}).


\subsubsection{LPCMCI} \label{lpcmci}
Latent PCMCI (LPCMCI) is a constraint-based causal discovery algorithm to determine causal relationships from large-scale time series data (\cite{LPCMCI}). This is another extension of the PCMCI algorithm as it can discover causal relationships \textit{even in the presence of latent confounders}. Moreover, it gives the flexibility to use the model when the data is linear or nonlinear, and also when the data has lagged or contemporary conditioning sets. The authors identified that when the CI tests have a low effect size, existing techniques like FCI suffer from low recall in the presence of autocorrelation. They demonstrated that this issue can be solved by including causal parents in the conditioning sets. By utilizing the orientation rules, these parents can be identified as early as in the edge removal stage. The results show that the proposed LPCMCI method can achieve higher recall than the baseline model SVAR-FCI. However, LPCMCI cannot differentiate all members of the Markov class, and also, when the faithfulness assumption doesn’t hold, LPCMCI might lead to an incorrect conclusion. Along with PCMCI and PCMCI+, the Python code of LPCMCI is also available in the Tigramite GitHub package.


\subsubsection{CD-NOD} \label{cd-nod}
Many existing approaches assume that the causal model is static, and therefore, there will be a fixed joint distribution of the observed data. However, these methods fail when the underlying data changes over time, and causal parameters vary during the period. \cite{CDNOD} proposed a causal discovery method that assumes that the parameter of the causal model can change over time or different datasets, and they named the method CD-NOD, \textit{Constraint-based Causal Discovery from Heterogeneous/Nonstationary Data}. The proposed method can determine causal direction by taking advantage of distribution shifts, and these distribution changes, in the presence of stationary confounders, are helpful for causal discovery. The distribution shifts can be either time or domain indexes and are denoted by a surrogate variable $C$. Broadly, CD-NOD has two phases where in the \textit{first phase} it recovers the causal skeleton $S_{G}$, and in the \textit{second phase} it orients the edges as per some orientation rules. Given that the causal model offers a concise summary of how the joint distribution changes, they demonstrated that distribution shift contains important information for causal discovery. Recently, researchers discovered that this idea could help solve machine learning problems of domain adaptation and forecasting in nonstationary situations (\cite{scholkopf2012causal, zhang2013domain}). The conducted experiments in this study demonstrate the changes of causal influence between the different states of brain functions, and the empirical results show that CD-NOD has improved precision and F1 score. However, they didn’t consider that the causal directions might flip, and the power of conditional independence tests might reduce because of the distribution shifts. The algorithm's source code is available in the following link: \url{https://github.com/Biwei-Huang/Causal-Discovery-from-Nonstationary-Heterogeneous-Data}.

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{CDNOD.PNG}
\caption{Illustration of CD-NOD's phase-1.}
\label{cdnod}
\end{figure}

\subsubsection{CDANs} \label{cdans}
\cite{ferdous2023cdans} introduces a constraint-based causal discovery approach called CDANs for autocorrelated and non-stationary time series data that handles high dimensionality issues. The method identifies both lagged and instantaneous causal edges along with changing modules that vary over time. By optimizing the conditioning sets in a constraint-based search, and also considering lagged parents instead of conditioning on the entire past, it tries to address the high dimensionality problem. CDANs first detect the lagged adjacencies, then identify the changing modules and instantaneous adjacencies, and finally determine the causal direction. The code to implement this method is available at \url{https://github.com/hferdous/CDANs}. An extended version of this study is presented in \cite{Ferdous_Hasan_Gani_2023}, where the method called \textbf{\textit{eCDANs}} is introduced that is capable of detecting lagged and instantaneous causal relationships along with temporal changes. The method eCDANs addresses high dimensionality by optimizing the conditioning sets while conducting CI tests and identifies the changes in causal relations by introducing a proxy variable to represent time dependency.


\subsection{Functional Causal Model (FCM)-based}

\subsubsection{VarLiNGAM} \label{varlingam}
VarLiNGAM (\cite{varlingam}) combines the non-Gaussian instantaneous models with autoregressive models and shows that a non-Gaussian model is identifiable without prior knowledge of network structure. It estimates both instantaneous and lagged causal effects in models that are an example of structural vector autoregressive (SVAR) models. These models are a combination of structural equation models (SEM) and vector autoregressive (VAR) models. VarLiNGAM also shows that taking instantaneous influences into account can change the values of the time-lagged coefficients to a great extent. Thus, neglecting instantaneous influences can lead to misleading interpretations of causal effects. It also assesses the significance of the estimated causal relations. An implementation of this method is available at: \url{https://lingam.readthedocs.io/en/latest/tutorial/var.html}. 

\subsubsection{T$i$MINo} \label{timino}
\textbf{Ti}me-series \textbf{M}odels with \textbf{I}ndependent \textbf{No}ise (TiMINo) (\cite{TiMINO}) studies a class of restricted structural equation models (SEMs) for time-series data that include nonlinear and instantaneous effects. It assumes $X_{t}$ to be a function of all direct causes and some noise variable, the collection of which is supposed to be jointly independent. The algorithm is based on unconditional independence tests and is applicable to multivariate, linear, nonlinear, and instantaneous interactions. If the model assumptions are not satisfied by the data, TiMINo remains mostly undecided instead of making wrong causal decisions. While methods like Granger causality are built on the asymmetry of time direction, TiMINo additionally takes into account identifiability emerging from restricted SEMs. This leads to a straightforward way of dealing with unknown time delays in different time series. An implementation of TiMINo is available in this repository: \url{https://github.com/ckassaad/causal_discovery_for_time_series}.


\subsection{Gradient-based}

\subsubsection{DYNOTEARS} \label{dynotears}
\cite{dynotears} proposed the Dynamic NOTEARS (DYNOTEARS) which is a structure learning approach for dynamic data that simultaneously estimates contemporaneous (intra-slice) and time-lagged (inter-slice) relationships between variables in a time-series. DYNOTEARS revolves around minimizing a penalized loss subject to an acyclicity constraint. The optimization finds the conditional dependencies that are best supported by the data. It leverages insight from the approach NOTEARS (\cite{notears}) which uses an algebraic characterization of acyclicity in directed graphs for static data. The assumptions made by DYNOTEARS include that the structure of the network is fixed through time, and is identical for all time series in the data. This approach is scalable to high-dimensional datasets. An implementation of this approach is available in the CausalNex library (\url{https://github.com/quantumblacklabs/causalnex}), and also at \url{https://github.com/ckassaad/causal_discovery_for_time_series}.

\subsubsection{NTS-NOTEARS} \label{nts-notears}
NTS-NOTEARS (\cite{nts-notears}) is a causal discovery method for time series data that uses 1-D convolutional neural networks (CNNs) to capture linear, nonlinear, lagged, and instantaneous relations among variables in a time series data along with ensuring the acyclicity property of a DAG. It extends the continuous optimization-based approach NOTEARS for learning nonparametric instantaneous DAGs, and adapts the acyclicity constraint from that approach. It assumes that there are no latent confounders in the data, and the underlying data-generating process is fixed and stationary over time. NTS-NOTEARS is faster than other constraint-based methods because of the use of nonlinear conditional independence tests. It incorporates prior knowledge into the learning process to promote the use of optimization constraints on convolutional layers for better casual discovery. Its implementation is available at: \url{https://github.com/xiangyu-sun-789/NTS-NOTEARS/}.




\subsection{Granger Causality (GC)-based} 

\cite{GC} investigated the causal relationships between the variables in a time series data which is known as Granger Causality (GC). It is based on the basic assumption that \emph{causes precede their effects}. The author defines GC as follows: \textit{A time series variable $X^{i}$ causes $X^{j}$, if the probability of $X^{j}$ conditional on its own past, and the past of $X^{i}$ (besides the set of the available information) does not equal the probability of $X^{j}$ conditional on its own past alone. }The GC test can’t be performed directly on non-stationary data. The non-stationary data needs to be transformed into stationary data by differencing it, either using first-order or second-order differencing. Granger Causality can be used when there are no latent confounders, and also, no instantaneous effects exist, i.e., no variable causes another variable at the same time stamp. %A code implementation of GC can be found at .......

\subsubsection{GVAR} \label{gvar}
\textbf{G}eneralized \textbf{V}ector \textbf{A}uto\textbf{R}egression (GVAR) (\cite{GVAR}) is a framework for inferring multivariate Granger causality under nonlinear dynamics based on autoregressive modeling with self-explaining neural networks. It allows the detection of signs of Granger-causal effects and inspection of their variability over time in addition to relational inference. It focuses on two aspects: first, inferring Granger-causal relationships in multivariate time series under nonlinear dynamics, and second, inferring signs of Granger-causal relationships. A reproducible code of the approach is available at: \url{https://github.com/i6092467/GVAR}.

\subsubsection{NAVAR} \label{navar}
\cite{NAVAR} proposed the approach \textbf{N}eural \textbf{A}dditive \textbf{V}ector \textbf{A}uto\textbf{R}egression (NAVAR) which is a causal discovery approach for capturing nonlinear relationships using \emph{neural networks}. It is particularly trained using deep neural networks that extract the (additive) Granger causal influences from the time evolution in multivariate time series. NAVAR assumes an additive structure where the predictions depend linearly on independent nonlinear functions of the individual input variables. These nonlinear functions are modeled using neural networks. The additive structure of NAVAR allows scoring and ranking the causal relationships. Currently, NAVAR is implemented with MLPs and LSTMs as the backbone using Python which is available at: \url{https://github.com/bartbussmann/NAVAR}. However, more complex architectures such as dilated CNNs and transformers can also be used to model NAVAR. 

\subsubsection{ACD} \label{acd}
Most causal discovery algorithms applied for time-series analysis find a causal graph for the data, and then refit the model whenever new samples do not fit with the underlying causal graph. But in many cases, samples share connections among them, for example, the brain activity of different regions at different times. When the algorithms fit a new model, this dynamic nature between the samples is lost, and can no longer identify the actual causal relation. To solve this problem, \cite{ACD} proposed the \textbf{A}mortized \textbf{C}ausal \textbf{D}iscovery (ACD) technique which can identify the causal relations when samples are from different causal graphs but share common dynamics. ACD consists of an encoder and a decoder. The encoder predicts the causal graph’s edges by learning Granger causal relations, and under the assumed causal model, the decoder simulates the dynamics of the system for the next time-step. Implementation of the model is available at: \url{https://github.com/loeweX/AmortizedCausalDiscovery}.

% The results showed that ACD performs better than existing causal discovery models for fully observed models, and also in the \textit{presence of hidden confounders} and noise. However, experimentation is done only with simulated data which gives no guarantee that it will perform in the same way as more complex realistic data. Furthermore, ACD assumes that there exists a function that can specify the dynamics shared by all samples, but this cannot be verified in practice. 




\subsection{Miscellaneous Approaches}

\subsubsection{oCSE} \label{ocse}
Causal network inference by Optimal Causation Entropy (oCSE) (\cite{ocse}) is based on the \emph{optimal causation entropy principle} which utilizes a two-step process (\emph{aggregative discovery and progressive removal}) to jointly infer the \emph{set of causal parents} of each node. It proposes a theoretical development of \emph{causation entropy}, an information-theoretic statistic designed for causal inference. Particularly, it proves the optimal causation entropy principle for Markov processes which is as follows: \textit{the set of nodes that directly cause a given node is the unique minimal set of nodes that maximizes causation entropy}. This principle transforms the problem of causal inference into the optimization of causation entropy. Causation entropy can be regarded as a type of conditional mutual information designed for causal structure inference which generalizes the traditional, unconditioned version of transfer entropy. Causation entropy when applied to Gaussian variables also generalizes Granger causality and conditional Granger causality. An advantage of the method oCSE is that it often requires a relatively smaller number of samples, and fewer computations to achieve high accuracy. Due to its aggregative nature, the conditioning set encountered in entropy estimation remains relatively low-dimensional for sparse networks. An implementation of the oCSE algorithm is available on this website: \url{https://github.com/ckassaad/causal_discovery_for_time_series}.


\subsubsection{TCDF} \label{tcdf}
\textbf{T}emporal \textbf{C}ausal \textbf{D}iscovery \textbf{F}ramework (TCDF) (\cite{TCDF})  is a \emph{deep learning framework} that discovers the causal relationships in observational time series data. Broadly, TCDF has the following steps: (i) Time series prediction, (ii) Attention interpretation, (iii) (a) Causal validation, (iii) (b) Delay discovery, and (iv) Temporal causal graph construction. TCDF consists of $N$ independent \emph{attention-based convolutional neural networks (CNNs)} all with the same architecture but a different target time series. Each network receives all observed time series as input. The goal of each network is to predict one time series based on the past values of all time series in the dataset. A time series $X_{i}$ is considered a potential cause of the target time series $X_{j}$ if the attention score is beyond a certain threshold. By comparing all attention scores, a set of potential causes is formed for each time series. TCDF validates whether a potential cause (found by the attention mechanism) is an actual cause of the predicted time series by applying a causal validation step. TCDF uses \emph{permutation importance (PI)} as a causal validation method which measures how much an error score increases when the values of a variable are randomly permuted. Finally, all validated causal relationships are included in a temporal causal graph. TCDF learns the time delay between cause and effect by interpreting the network’s kernel weights. This framework has experimented with simulated financial market data and FMRI data. It discovered roughly $95$--$97$\% of the time delays correctly. However, it performs slightly worse on short time series in FMRI data since a deep learning method has many parameters to fit. An implementation of TCDF can be found at: \url{https://github.com/M-Nauta/TCDF}. 

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{TCDF.PNG}
\caption{Interpretation of how the TCDF (\cite{TCDF}) method works. The numbers on the causal edges denote the time delay between the cause and effect.}
\label{TCDF}
\end{figure}

\subsubsection{NBCB} \label{nbcb}
NBCB (\cite{CKASSAD}) or Noise-based/Constraint-based approach is a \textit{hybrid} approach that learns a \emph{summary causal graph} from observational time series data without being restricted to the Markov equivalent class even in the case of instantaneous relations. A \emph{summary causal graph} is one that represents the causal relations between time series without including lags. That is, it only represents the cause-effect relations in a given time series without the time delay between the cause and the effect. To find the summary graph, NBCB uses a hybrid approach which is divided into two steps. First, it uses a noise-based procedure to find the potential causes of each time series under the assumption of additive noise models (ANMs). Then, it uses a constraint-based approach to prune all unnecessary causes and hence ends up with an oriented causal graph. The second step is based on a new temporal causation entropy measure proposed by this study that is an extension of the causation entropy to time series data for handling lags bigger than one time step. Furthermore, this study relies on a lighter version of the faithfulness hypothesis, namely adjacency faithfulness. An implementation of NBCB is available in the site \url{https://github.com/ckassaad/causal_discovery_for_time_series}. 




\subsubsection{PCTMI} \label{pctmi}
PCTMI (\cite{pctmi}) is an entropy-based approach that discovers the summary causal graph for time series data with potentially different sampling rates. To do so this study proposes a new \emph{temporal mutual information measure} defined on a window-based representation of time series. Then it shows how this measure relates to an entropy reduction principle that can be seen as a special case of the \textit{probabilistic raising principle}. PCTMI combines these two concepts in a PC-like algorithm (\cite{pc}) to construct the summary causal graph. PCTMI focuses particularly on the summary graph, rather than the full-time graph. It has mainly two steps: \emph{(i) Skeleton construction and (ii) Edge orientation}. The skeleton construction as well as the orientation of instantaneous relations is similar to the PC algorithm but adapted for time series data. To orient the lagged relations, it uses the rules of an \emph{entropic reduction} (ER) principle (\cite{suppes}). PCTMI assumes both the causal Markov condition and faithfulness of the data distribution, common assumptions for constraint-based CD approaches. An implementation of PCTMI is available on this website: \url{https://github.com/ckassaad/causal_discovery_for_time_series}. 


The methods discussed above use different strategies to perform causal discovery under a variety of settings and assumptions. Therefore, we present a comparative analysis of some of the common approaches in Table~\ref{table-time-series-comparison} based on their assumptions, output, techniques used, advantages, and disadvantages.

%%%%%%%%%%%%%%%%%%%%%%%%Temporal-Comparison-Table%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%55%%%%%%%%%%%%%%%%%%%%%%%%Temporal-Comparison-Table%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%55

\begin{landscape}
\centering
\scriptsize
\begin{longtable}{|c|c|c|c|c|c|}
\caption{Comparison of some causal discovery algorithms for time series data.}\\ %The table lists the assumptions made by the approaches, their outcome graph, the technique used for causal discovery, their advantages and disadavntages.}\\
\hline
\label{table-time-series-comparison}
\textbf{Methods} & \textbf{Assumptions} & \textbf{Outcome Graph} & \begin{tabular}[c]{@{}c@{}}\textbf{Technique used}\end{tabular} & \textbf{Advantages} & \textbf{Disadvantages }\\ \hline
tsFCI & \begin{tabular}[c]{@{}c@{}} Causal Markov condition, \\ faithfulness \end{tabular}& Partial ancestral graph & \begin{tabular}[c]{@{}c@{}}Constraint-based, \\ FCI adaptation \\ for time series data\end{tabular} & \begin{tabular}[c]{@{}c@{}}Handles hidden confounders\end{tabular} & \begin{tabular}[c]{@{}c@{}}Non-stationarity property\\ is not handled\end{tabular} \\ \hline
PCMCI & \begin{tabular}[c]{@{}c@{}}Data stationarity, \\ causal sufficiency\end{tabular} & \begin{tabular}[c]{@{}c@{}}Full time graph \\ with lagged edges\end{tabular} & \begin{tabular}[c]{@{}c@{}}Constraint-based, \\ momentary CI (MCI) test\end{tabular} & \begin{tabular}[c]{@{}c@{}}Handles high-dimensional \\ networks, applicable on linear \\ or nonlinear, and continuous\\ or discrete data\end{tabular} & \begin{tabular}[c]{@{}c@{}}Contemporaneous edges is \\not identified, some causal \\links remain unoriented\end{tabular} \\ \hline
PCMCI+ & Causal sufficiency & \begin{tabular}[c]{@{}c@{}}Full time graph \\ with lagged and \\ contemporaneous edges\end{tabular} & \begin{tabular}[c]{@{}c@{}}Constraint-based, \\ MCI test\end{tabular} & \begin{tabular}[c]{@{}c@{}}Detects both contemporaneous \\ and lagged causal links\end{tabular} & \begin{tabular}[c]{@{}c@{}}Some causal links \\ remain unoriented\end{tabular} \\ \hline
LPCMCI & \begin{tabular}[c]{@{}c@{}}Causal faithfulness, \\ absence of selection bias\end{tabular} & \begin{tabular}[c]{@{}c@{}}Time series directed \\ maximal ancestral \\ graphs (DMAGs)\end{tabular} & Constraint-based & \begin{tabular}[c]{@{}c@{}}Handles large-scale  time series \\data, latent confounders, and \\discrete/continuous-valued data, \\incorporates prior knowledge\end{tabular} & \begin{tabular}[c]{@{}c@{}}May lead to wrong conclusions \\ if faithfulness is violated, \\ can’t distinguish all \\ members of MEC\end{tabular} \\ \hline
CD-NOD & \begin{tabular}[c]{@{}c@{}}Pseudo Causal \\ Sufficiency, faithfulness, \\ no selection bias\end{tabular} & \begin{tabular}[c]{@{}c@{}}Summary or full time \\ graph incorporating \\ the changing modules\end{tabular} & Constraint-based & Detects changing modules & \begin{tabular}[c]{@{}c@{}}Some causal directions may \\ not be identifiable, if the\\ identifiability conditions \\ are not satisfied\end{tabular} \\ \hline
VarLiNGAM & \begin{tabular}[c]{@{}c@{}}DGP is linear, there are \\ no unobserved confounders,\\ and non-Gaussian noises \\ with non-zero variances\end{tabular} & \begin{tabular}[c]{@{}c@{}}Full-time causal DAG \\(with causal strengths)\end{tabular} & FCM/SEM-based & \begin{tabular}[c]{@{}c@{}}Detects both lagged \\ and instantaneous \\ temporal edges\end{tabular} & \begin{tabular}[c]{@{}c@{}}Hidden confounders are not \\handled, and  inapplicable to \\non-linear data\end{tabular} \\ \hline
TiMINO & Independent noise, identifiability & \begin{tabular}[c]{@{}c@{}}Causal summary \\ time graph\end{tabular} & FCM/SEM-based & \begin{tabular}[c]{@{}c@{}}Applicable to multivariate, \\ linear, nonlinear and \\ instantaneous cases\end{tabular} & \begin{tabular}[c]{@{}c@{}}Rigid about the model \\assumptions, sometimes \\remain undecided\end{tabular} \\ \hline
DYNOTEARS & \begin{tabular}[c]{@{}c@{}}Acyclicity,\\ network structure is fixed\\  through time and is identical for\\ all time series in the data\end{tabular} & Full time causal graph & Score-based approach & \begin{tabular}[c]{@{}c@{}}Scalable to high-dimensional \\ datasets, produces both lagged \\ and instantaneous edges\end{tabular} & \begin{tabular}[c]{@{}c@{}}Undersampling is not handled \\ well, inapplicable to \\ non-linear data\end{tabular} \\ \hline
NTS-NOTEARS & \begin{tabular}[c]{@{}c@{}}No latent confounders, \\ DGP is fixed and \\ stationary over time.\end{tabular} & Full time causal graph & \begin{tabular}[c]{@{}c@{}}Gradient-based, \\ uses 1-D CNNs\end{tabular} & Incorporates prior knowledge & \begin{tabular}[c]{@{}c@{}}Inapplicable when there \\exists latent confounders\end{tabular} \\ \hline
NAVAR & Additive structure & \begin{tabular}[c]{@{}c@{}}Full time causal graph \\(with lagged edges only)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Granger-causality \\ based\end{tabular} & \begin{tabular}[c]{@{}c@{}}Easy to implement, can detect \\ nonlinear relations\end{tabular} & \begin{tabular}[c]{@{}c@{}}Produced score-matrix \\ can be analyzed only by \\ the CausaMe platform\end{tabular} \\ \hline
oCSE & Faithfulness, Acyclicity & \begin{tabular}[c]{@{}c@{}}Summary causal graph\end{tabular} & \begin{tabular}[c]{@{}c@{}}Optimal Causation \\ Entropy principle\end{tabular} & \begin{tabular}[c]{@{}c@{}}Often requires a relatively\\  smaller number of samples\end{tabular} & \begin{tabular}[c]{@{}c@{}}Takes very long to run \\ time for dense graphs\end{tabular} \\ \hline
TCDF & \begin{tabular}[c]{@{}c@{}}Temporal precedence: \\ the cause precedes its effect\end{tabular} & Full time causal graph & Attention-based CNNs & \begin{tabular}[c]{@{}c@{}}Easy to implement, can detect\\  hidden confounders\end{tabular} & \begin{tabular}[c]{@{}c@{}}Performs slightly worse\\  on short time series, \\ does not ensure acyclicity\end{tabular} \\ \hline
NBCB & \begin{tabular}[c]{@{}c@{}}Adjacency\\ faithfulness\end{tabular} & \begin{tabular}[c]{@{}c@{}}Summary causal graph\end{tabular} & \begin{tabular}[c]{@{}c@{}}Hybrid (constraint and \\ noise-based),  causation entropy\end{tabular} & \begin{tabular}[c]{@{}c@{}}Not restricted \\ to the MEC\end{tabular} & \begin{tabular}[c]{@{}c@{}}Does not estimate \\ a full-time causal graph\end{tabular} \\ \hline
PCTMI & \begin{tabular}[c]{@{}c@{}}Causal Markov \\ condition and faithfulness\end{tabular} & \begin{tabular}[c]{@{}c@{}}Summary causal graph\end{tabular} & \begin{tabular}[c]{@{}c@{}}Constraint-based, skeleton \\ construction using PC, uses ER \\ principle to orient lagged edges\end{tabular} & Lower complexity & \begin{tabular}[c]{@{}c@{}}Does not estimate a \\ full-time causal graph\end{tabular} \\ \hline
\end{longtable}
\end{landscape}

%%%%%%%%%%%%%%%%%%%%%%%%Temporal-Comparison-Table%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%55%%%%%%%%%%%%%%%%%%%%%%%%Temporal-Comparison-Table%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%55


\section{Evaluation Metrics for Causal Discovery} \label{Metrics}
In this section, we discuss the common metrics used to evaluate the performance of causal discovery algorithms. These metrics are common for both I.I.D. and time series causal discovery evaluation. \newline

%A summary of these metrics is presented in \autoref{metrics-table}.

% \begin{table}[h]
% \centering
% \caption{Causal Discovery Metrics - Summarised}
% \label{metrics-table}
%     \begin{tabular}{ | p{0.3cm} | p{2cm} | p{3.9cm} | p{6.1cm} |}
%     \hline
%      & \textbf{Metric} & \textbf{Formula} & \textbf{Description} \\ \hline
%      1 &\textbf{ SHD} & \begin{equation*}
%      SHD = A + D +R
%      \end{equation*} & A = total number of edge additions \newline D = total number of edge deletions \newline R = total number of edge reversals \\ \hline
%      2 &\textbf{ FDR} & \begin{equation*}
%      FDR = \frac{FP}{TP+FP}
%      \end{equation*} & FP = total number of false positives \newline
%      TP = total number of true positives\\ \hline
%      3 & \textbf{TPR}/\newline \textbf{Recall} & \begin{equation*}
%      TPR = \frac{TP}{TP+FN}
%      \end{equation*}& 
%      %TP = total number of true positives 
%      FN = total number of false negatives \\ \hline
%      4 &\textbf{ FPR} & \begin{equation*}
%      FPR = \frac{FP}{TN+FP}
%      \end{equation*} & 
%      %FP = total number of false positives 
%      TN = total number of true negatives\\ \hline
%      5 &\textbf{ Precision} & \begin{equation*}
%      Precision = \frac{TP}{TP+FP}
%      \end{equation*} & \\ \hline
% %TP = total number of true positives \newline
% %FP = total number of false positives 
%     \end{tabular}
% \end{table}

• \textbf{Structural Hamming Distance (SHD):} SHD is the total number of edge additions, deletions, or reversals that are needed to convert the estimated graph $G'$ into its ground-truth graph $G$ (\cite{notears, cheng2022evaluation}). It is estimated by determining the missing edges, extra edges, and edges with incorrect direction in the produced graph compared to its true graph. A lower hamming distance means the estimated graph is closer to the true graph, and vice versa. An estimated graph is fully accurate when its SHD = 0.
%\autoref{eq1} computes SHD where $A$ = total number of edge additions, $D$ = total number of edge deletions and $R$ = total number of edge reversals. 
We show the calculation of SHD for the graphs in Figure \ref{SHD} using the formula in Equation \ref{eq1} where $A$ = total number of edge additions, $D$ = total number of edge deletions, and $R$ = total number of edge reversals. In Figure \ref{SHD}, we need to \textit{add} the edge $D$ → $C$, \textit{delete} the edges $D$ → $B$ and $D$ → $A$, and \textit{reverse} the edges $C$ → $B$ and $C$ → $A$ in the generated graph (graph b) to convert it into the true graph (graph a). Therefore, the $SHD = 1 + 2 + 2 = 5$ means a total of 5 actions are required to reach the true graph (graph a). 

\begin{equation}
    SHD = A + D + R
\label{eq1}
\end{equation}

\begin{figure}[h]
\centering
\includegraphics[width=0.4\textwidth]{GT_SHD.png}
\caption{(a) Ground-truth graph $G$, and (b) Estimated graph $G'$.}
\label{SHD}
\end{figure}


• \textbf{Structural Intervention Distance (SID):} SID is a distance metric for DAGs proposed by \cite{peters2015structural}. It measures the closeness between DAGs in terms of their capacities for causal effects. Specifically, it computes the number of falsely inferred intervention distributions (\cite{cheng2022evaluation}) to reflect how false edges in the generated graph can influence the effects obtained.


• \textbf{False Discovery Rate (FDR):} FDR is the expected fraction of false discoveries among all the discoveries. In terms of causal discovery, FDR represents the ratio of the extra edges over the sum of the true edges and extra edges. Here, extra edges mean the edges that are present in the estimated graph but not present in the actual graph or the false positives (FP), and true edges mean edges that are present in both the graphs or the true positives (TP). The lower the FDR, the better the performance of causal discovery. 

%\autoref{fdr} is used to compute FDR where $FP$ = total number of false positives and $TP$ = total number of true positives.

\begin{equation}
     FDR = \frac{FP}{TP+FP}
\label{fdr}
\end{equation}
 

• \textbf{True Positive Rate (TPR):} TPR denotes the proportion of the positives in the data correctly identified as positives. In terms of causal graphs, TPR is the ratio of the edges in the estimated graph that are also present in the true graph (TP) to the total number of true edges (true positives (TP) and false negatives (FN)). The higher the TPR of an estimated graph, the better the discovery. 

\begin{equation}
    TPR = \frac{TP}{Actual Positive} = \frac{TP}{TP+FN}
\end{equation}

• \textbf{False Positive Rate (FPR):} In general terms, FPR is the proportion of negatives that are incorrectly identified as positives. In terms of causal graphs, FPR is the ratio of the false edges produced by the estimated graph that are absent in the true graph (false positives/extra edges) over the sum of true negatives (TN) and false positives (FP). The lower the FPR, the better the causal discovery performance. 
\begin{equation}
    FPR = \frac{FP}{Actual Negative} = \frac{FP}{TN+FP}
\end{equation}

• \textbf{Precision:} Precision returns the proportion of true positives (TP) among all the values predicted as positive. That is, out of all the positives predicted, what percentage is truly positive. In terms of causal discovery, precision is the fraction of the correct or semi-correct edges over all the produced edges (\cite{shen2020challenges}).
\begin{equation}
    Precision = \frac{TP}{TP + FP}
\end{equation}

• \textbf{Recall:} Recall returns the proportion of the correctly predicted positive values. That is, out of the total positives, what percentage are predicted as positive? In causal discovery, recall is the fraction of edges in the ground-truth graph that are correctly or semi-correctly estimated (\cite{shen2020challenges}). The recall metric is the same as TPR.

\begin{equation}
    Recall = \frac{TP}{TP+FN}
\end{equation}

• \textbf{F1 Score:}
The F1 score metric combines the precision and recall metrics into a single metric. It is the harmonic mean of precision and recall and is mostly used in cases of imbalanced data.

\begin{equation}
    F1\;score = \frac{2TP}{2TP+FN+FP}
    \label{f1-score}
\end{equation}

• \textbf{Matthews Correlation Coefficient (MCC):} MCC is a single-value metric that summarizes the confusion matrix. It takes into account all four entries of the confusion matrix (TP, TN, FP, and FN). The value of MCC is 1 when the discovery of edges is fully accurate (FP = FN = 0), indicating perfect causal discovery. On the contrary, when the algorithm always misidentifies (TP = TN = 0), then the MCC is -1, representing the worst possible discovery. Thus, the MCC value lies between -1 and 1.

\begin{equation}
    MCC = \frac{TP \times TN - FP \times FN}{\sqrt{(TN+FN)(FP+TP)(TN+FP)(FN+TP)}}
    \label{MCC}
\end{equation}
    
%    \item Area under the ROC curve (AUROC)/(AOC)

%discussion on the usefulness of the metrics
From the above-listed metrics, the SHD metric is more insightful compared to the others as it allows us to know how far the estimated graph is from the ground-truth graph. SHD provides insight into the total number of modifications that need to be done in the estimated graph to transform it into the ground-truth graph. The MCC metric is also good in terms of summarizing the outcome of a CD algorithm as it is the only metric that takes into account all of TP, TN, FP, and FN. The F1 score metric is quite useful too as it combines the precision and recall metrics. One should consider using the SHD metric in order to understand how far the estimated graph is from the ground-truth graph. The TPR metric can be used if one is interested only in knowing the proportion of the true edges discovered. One can use the FDR metric to get an idea about the proportion of the false estimated edges by the algorithm. However, consideration of only a single metric for the performance evaluation of the algorithms can be problematic. A single metric can not fully express the actual performance of the approach.


\section{Datasets for Causal Discovery}
\label{Datasets}
There are a couple of benchmark causal discovery datasets from different domains that are often used for the evaluation of causal discovery approaches. In this section, we discuss briefly some commonly used I.I.D. and time series datasets.

\subsection{I.I.D. datasets}
\begin{itemize}
    \item \textbf{ASIA:} ASIA is a synthetic dataset, also known as the Lung Cancer dataset (\cite{asia}). The associated graph (Figure \ref{ASIA} (a)) is a small toy network that models lung cancer in patients from Asia. Particularly, it is about different lung diseases (tuberculosis, lung cancer, or bronchitis), their relations to smoking, and patients' visits to Asia. This dataset is often used for benchmarking causal graphical models. The ground-truth graph has 8 nodes and 8 edges. \cite{enco}, and \cite{KCRL} have used this dataset for the evaluation of their approaches. It is available here: \url{https://www.bnlearn.com/bnrepository/discrete-small.html#asia}.
    
    \item \textbf{LUCAS}: The LUCAS (Lung Cancer Simple Set) is a synthetic dataset that contains toy data generated artificially by causal Bayesian networks with binary variables (\cite{lucas2004bayesian}). Here, the target variable is \textit{Lung Cancer}. The data-generating model of the LUCAS dataset is a Markov process, which means that the state of the children is entirely determined by the state of the parents. The ground-truth graph (Figure \ref{ASIA} (b)) is a small network with 12 variables and 12 edges. \cite{KCRL} used this dataset to evaluate their framework. The dataset and ground truth can be found here: \url{https://www.causality.inf.ethz.ch/data/LUCAS.html}.

\begin{figure}[h]
\centering
\includegraphics[width=0.4\textwidth]{ASIA.png} \includegraphics[width=0.4\textwidth]{LUCAS.png}
\caption{Ground-truth network of the ASIA (left), and LUCAS (right) datasets.}
\label{ASIA}
\end{figure}




% \begin{table}[]
% \scriptsize
% \centering
% \caption{Benchmarking of common causal discovery algorithms for I.I.D. data.}
% \label{Benchmarks_table}
% \begin{tabular}{|c|ccc|ccc|ccc|ccc|}
% \hline
%  & \multicolumn{3}{c|}{ASIA} & \multicolumn{3}{c|}{CHILD} & \multicolumn{3}{c|}{ALARM} & \multicolumn{3}{c|}{HEPAR2} \\ \hline
% Methods & \multicolumn{1}{c|}{TPR} & \multicolumn{1}{c|}{FDR} & SHD & \multicolumn{1}{c|}{TPR} & \multicolumn{1}{c|}{FDR} & SHD & \multicolumn{1}{c|}{TPR} & \multicolumn{1}{c|}{FDR} & SHD & \multicolumn{1}{c|}{TPR} & \multicolumn{1}{c|}{FDR} & SHD \\ \hline
% PC & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  \\ \hline
% GES & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  \\ \hline
% LiNGAM & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  \\ \hline
% NOTEARS & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  \\ \hline
% \end{tabular}
% \end{table}

    \item \textbf{SACHS}: SACHS (\cite{sachs2005causal}) is a real dataset that measures the expression levels of multiple phosphorylated protein and phospholipid components in human cells. It is the most commonly used dataset for evaluating causal discovery approaches. It has a small network with 11 nodes and 17 edges (Figure \ref{SACHS}). The dataset has both observational and interventional samples. Most of the CD approaches use the $n = 853$ observational samples to evaluate their method. This dataset has been used by many approaches such as \cite{notears}, \cite{rlbic}, \cite{golem}, \cite{gran-dag} \& \cite{mcsl}, \cite{enco} for evaluation purposes. Link: \url{https://www.bnlearn.com/bnrepository/discrete-small.html#sachs}.

\begin{figure}[h]
\centering
\includegraphics[width=0.41\textwidth]{SACHS.png} %\includegraphics[width=0.52\textwidth]{LUCAS.png}
\caption{Ground-truth network of the SACHS dataset.}
\label{SACHS}
\end{figure}

    \item \textbf{CHILD}: The CHILD (\cite{Child}) dataset is a medical Bayesian network for diagnosing congenital heart disease in a newborn "blue baby". The ground-truth network is a medium graph that consists of $20$ nodes and $25$ edges (Figure \ref{CHILD}). The dataset includes features such as patient demographics, physiological characteristics, and lab test reports (Chest X-ray, CO2 reports, etc.). This dataset was used by \cite{enco} in their study, and can be found here: \url{https://www.bnlearn.com/bnrepository/discrete-medium.html#child}.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{CHILD.png} %\includegraphics[width=0.52\textwidth]{LUCAS.png}
\caption{Ground-truth network of the CHILD dataset.}
\label{CHILD}
\end{figure}


    \item \textbf{ALARM}: A Logical Alarm Reduction Mechanism (ALARM) is a patient monitoring system (\cite{alarm}) designed to provide an alarm message for patients, and has an associated synthetic dataset. In particular, it implements a cautionary alarm message for patient monitoring. The ground-truth graph is a medium-sized network with 37 nodes and 46 edges. This dataset was used by \cite{dag-gnn}, and \cite{sada} to evaluate their approaches. The ground-truth network is available in this repository: \url{https://www.bnlearn.com/bnrepository/}.
    
    \item \textbf{HEPAR2}: It is a probabilistic causal model for the diagnosis of liver disorders (\cite{hepar2}). This causal Bayesian network tries to capture the causal links among different risk factors, diseases, symptoms, and test results. The ground-truth graph is a large network with $70$ nodes and $123$ edges which is available in the bnlearn (\cite{bnlearn}) repository: \url{https://www.bnlearn.com/bnrepository/discrete-large.html#hepar2}.
\end{itemize}


\subsection{Time Series datasets}
\begin{itemize}
    \item \textbf{fMRI} datasets: Functional Magnetic Resonance Imaging (fMRI) is a popular approach to investigating dynamic brain networks (\cite{cao2019functional}). Different types of fMRI data are often used to evaluate time-series causal discovery approaches. \cite{zhang2017causal} used the fMRI Hippocampus dataset (\cite{laumann2015functional}) that contains signals from six separate brain regions. \cite{TCDF} used a simulated blood oxygen level-dependent (BOLD) fMRI dataset that has 28 different underlying networks from 50 brain regions. It measures the neural activity of different brain regions based on the changes in blood flow. \cite{CDNOD} tested their approach using the task fMRI data to learn information flows between brain regions, and how causal influences change across resting state and task states. Some simulated fMRI data is available here: \url{https://github.com/M-Nauta/TCDF/tree/master/data/fMRI}.
    
    \item \textbf{CauseMe - Earth Sciences} data: CauseMe (\cite{causeme}) is a platform that contains benchmark causal discovery datasets to evaluate, and compare the performance of different CD approaches. It contains datasets generated from both synthetic models mimicking real challenges and real-world data sets from the earth science domain where the ground-truth network is known with high confidence. \cite{NAVAR} used different datasets from the CauseMe platform in their study. Specifically, they used the synthetic nonlinear VAR dataset, the hybrid climate and weather dataset, and the real-world river run-off dataset to evaluate their algorithm. It was also used by \cite{pcmci} in their experiments. The datasets can be found at: \url{https://causeme.uv.es/}.

    \item \textbf{causaLens} datasets: \cite{causalLENS} from causaLens proposed a framework for generating synthetic time series data with a known ground truth causal structure for evaluating time series causal discovery approaches. They have an open-source repository (\url{https://github.com/causalens/cdml-neurips2020}) that captures the source code and datasets of their proposed framework. Datasets can be generated specifying different assumptions (causal sufficiency, I.I.D., instantaneous effects, etc.) using an example script in the repository. This facilitates the users to generate data as per their requirements. Located in England, \href{https://www.causalens.com/}{causaLens} is a leading software company with a focus on developing intelligent machines based on causal AI. 
    
    \item \textbf{DREAM3 challenge} datasets: DREAM3 (\cite{dream}) is a simulated gene expression dataset often used for evaluating time-series causal discovery algorithms. It has five different datasets of E. coli and yeast gene networks (Ecoli1, Ecoli2, Yeast1, Yeast2, and Yeast3), each consisting of a maximum of 100 variables. \cite{NAVAR} used this dataset to evaluate their approach. Every dataset has 46 time series and every time series consists of only 21 timesteps. Some of these datasets can be found here: \url{https://github.com/bartbussmann/NAVAR}.
    
    \item \textbf{Stock market} datasets: Stock market datasets contain multiple continuous time series data which are very useful to assess temporal causal discovery algorithms. \cite{CDNOD} used two different stock market datasets downloaded from Yahoo Finance to test their approach. It contains daily returns of stocks from Hong Kong and the United States. Link to a simulated Finance dataset from the study by \cite{TCDF}: \url{https://github.com/M-Nauta/TCDF/tree/master/data/Finance}.

\end{itemize}

\section{Benchmarking Causal Discovery Algorithms}\label{section-7}
In this section, we report the performance of some common causal discovery approaches on I.I.D. and time series datasets. We compare the approaches in terms of three common metrics: \textit{SHD}, \textit{TPR}, and \textit{FDR}. 

\subsection{Experiments on I.I.D. data}
For causal discovery on the I.I.D. datasets, we choose the following commonly used datasets with available ground-truth graphs: \textit{ASIA} (small network), \textit{CHILD} and \textit{ALARM} (medium networks), and \textit{HEPAR2 }(large network). The CSV version of the datasets and their corresponding ground-truths are available in the causal-learn repository: \url{https://github.com/py-why/causal-learn}. The causal discovery approaches that are benchmarked for the I.I.D. datasets are: \textit{PC, GES, LiNGAM, Direct-LiNGAM, NOTEARS, DAG-GNN, GraN-DAG, GOLEM, }and \textit{MCSL}. The implementations of the algorithms have been adopted from the gCastle (\cite{gcastle}) package.

\begin{table}[!h]
\small
%\scriptsize
\centering
\caption{The benchmarking of some common causal discovery algorithms for I.I.D. datasets. The best results w.r.t each metric (SHD, TPR, and FDR) are boldfaced. Lower SHD and FDR are better, while a higher TPR signifies a better performance.}
\label{Benchmarks_table}
\vspace{0.5\baselineskip}
\begin{tabular}{|c|ccc|ccc|ccc|ccc|}
\hline
 & \multicolumn{3}{c|}{\textbf{ASIA}} & \multicolumn{3}{c|}{\textbf{CHILD}} & \multicolumn{3}{c|}{\textbf{ALARM}} & \multicolumn{3}{c|}{\textbf{HEPAR2}} \\ \hline
\textbf{Methods} & \multicolumn{1}{c|}{SHD} & \multicolumn{1}{c|}{TPR} & FDR & \multicolumn{1}{c|}{SHD} & \multicolumn{1}{c|}{TPR} & FDR & \multicolumn{1}{c|}{SHD} & \multicolumn{1}{c|}{TPR} & FDR & \multicolumn{1}{c|}{SHD} & \multicolumn{1}{c|}{TPR} & FDR \\ \hline
PC & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{0.6} & 0.3 & \multicolumn{1}{c|}{43} & \multicolumn{1}{c|}{0.24} & 0.86 & \multicolumn{1}{c|}{55} & \multicolumn{1}{c|}{0.67} & 0.6 & \multicolumn{1}{c|}{172} & \multicolumn{1}{c|}{0.35} & 0.75 \\ \hline
GES & \multicolumn{1}{c|}{\textbf{4}} & \multicolumn{1}{c|}{\textbf{0.63}} & 0.38 & \multicolumn{1}{c|}{34} & \multicolumn{1}{c|}{0.38} & 0.89 & \multicolumn{1}{c|}{56} & \multicolumn{1}{c|}{\textbf{0.74}} & 0.61 & \multicolumn{1}{c|}{\textbf{70}} & \multicolumn{1}{c|}{0.5} & 0.23 \\ \hline
LiNGAM & \multicolumn{1}{c|}{7} & \multicolumn{1}{c|}{0.25} & 0.6 & \multicolumn{1}{c|}{23} & \multicolumn{1}{c|}{0.28} & 0.63 & \multicolumn{1}{c|}{43} & \multicolumn{1}{c|}{0.43} & 0.55 & \multicolumn{1}{c|}{111} & \multicolumn{1}{c|}{0.1} & 0.32 \\ \hline
Direct-LiNGAM & \multicolumn{1}{c|}{\textbf{4}} & \multicolumn{1}{c|}{0.5} & \textbf{0} & \multicolumn{1}{c|}{28} & \multicolumn{1}{c|}{0.12} & 0.82 & \multicolumn{1}{c|}{40} & \multicolumn{1}{c|}{0.39} & 0.5 & \multicolumn{1}{c|}{110} & \multicolumn{1}{c|}{0.1} & 0.07 \\ \hline
NOTEARS & \multicolumn{1}{c|}{12} & \multicolumn{1}{c|}{0.13} & 0.83 & \multicolumn{1}{c|}{\textbf{22}} & \multicolumn{1}{c|}{0.16} & 0.64 & \multicolumn{1}{c|}{41} & \multicolumn{1}{c|}{0.17} & 0.38 & \multicolumn{1}{c|}{123} & \multicolumn{1}{c|}{-} & - \\ \hline
DAG-GNN & \multicolumn{1}{c|}{7} & \multicolumn{1}{c|}{0.25} & 0.5 & \multicolumn{1}{c|}{24} & \multicolumn{1}{c|}{0.24} & 0.7 & \multicolumn{1}{c|}{\textbf{39}} & \multicolumn{1}{c|}{0.196} & \textbf{0.31} & \multicolumn{1}{c|}{123} & \multicolumn{1}{c|}{0} & 1 \\ \hline
GraN-DAG & \multicolumn{1}{c|}{7} & \multicolumn{1}{c|}{0.13} & \textbf{0} & \multicolumn{1}{c|}{24} & \multicolumn{1}{c|}{0.04} & \textbf{0} & \multicolumn{1}{c|}{44} & \multicolumn{1}{c|}{0.044} & 0.75 & \multicolumn{1}{c|}{122} & \multicolumn{1}{c|}{0.008} & \textbf{0} \\ \hline
GOLEM & \multicolumn{1}{c|}{11} & \multicolumn{1}{c|}{0.25} & 0.75 & \multicolumn{1}{c|}{49} & \multicolumn{1}{c|}{0.2} & 0.88 & \multicolumn{1}{c|}{60} & \multicolumn{1}{c|}{0.26} & 0.71 & \multicolumn{1}{c|}{157} & \multicolumn{1}{c|}{0.05} & 0.89 \\ \hline
MCSL & \multicolumn{1}{c|}{19} & \multicolumn{1}{c|}{0.5} & 0.82 & \multicolumn{1}{c|}{140} & \multicolumn{1}{c|}{\textbf{0.56}} & 0.91 & \multicolumn{1}{c|}{464} & \multicolumn{1}{c|}{0.72} & 0.93 & \multicolumn{1}{c|}{1743} & \multicolumn{1}{c|}{\textbf{0.45}} & 0.97 \\ \hline
\end{tabular}
\end{table}

From the results reported in Table \ref{Benchmarks_table}, we see that for the ASIA dataset, both GES and Direct-LiNGAM approaches have the best (lowest) SHD. MCSL on the other hand has the worst (highest) SHD for ASIA. For the CHILD dataset, NOTEARS performs the best w.r.t. SHD, and once again MCSL has the worst SHD. A reason for the poor performance of MCSL could be due to its tendency to produce as many as possible edges without caring much about the false positives. DAG-GNN has the best (lowest) SHD for the ALARM dataset, and once again GES outperforms others with the lowest SHD in the case of the HEPAR2 dataset. In terms of TPR, GES, and MCSL both outperform others twice. That is GES has the best TPR for the ASIA and ALARM networks, and MCSL has the highest TPR for the CHILD and HEPAR2 networks. With respect to FDR, GraN-DAG outperforms the other algorithms with the lowest FDR in the case of all the datasets except the ALARM dataset. DAG-GNN has the best FDR in the case of ALARM. PC and GES seem to do well comparatively for the datasets with small graphs. Gradient-based methods such as NOTEARS, DAG-GNN, and GraN-DAG seem to be on par w.r.t. the SHD metric across all the datasets. However, the metrics of all the approaches in the case of the HEPAR2 dataset which has a large ground-truth network are quite poor. This signifies that most of the existing approaches are not fully sufficient to handle large or very large networks, and should focus on improving their scalability. The development of new approaches should consider the scalability factor of the algorithm so that they can handle real-world large networks having 100 to 1000 nodes. 


\begin{figure}[!t]
\centering
\includegraphics[width=0.49\textwidth]{SHD_IID.png} \includegraphics[width=0.5\textwidth]{TPR_IID.png}
\includegraphics[width=0.5\textwidth]{FDR_IID.png}
\caption{SHD, TPR, and FDR plots of the different benchmarked approaches on some I.I.D. datasets. Lower SHD and FDR are better, while a higher TPR signifies a better performance.}
\label{CHILD}
\end{figure}



\subsection{Experiments on time series data}
We compared the performance of some temporal causal discovery algorithms namely PCMCI, PCMCI+, VarLiNGAM, DyNOTEARS, and TCDF on two time series datasets. The first dataset is the \textit{Syn-6} data which is a synthetic dataset with 6 variables and a lag period of 2. The details of data generation can be found in the study \cite{ferdous2023cdans}. The second dataset is \textit{fMRI} data with 10 variables having a lag period of 1. Please refer to the study \cite{TCDF} for the details of this dataset. The ground-truth graphs of both datasets are also available in the listed studies. Some of the temporal algorithms only produce summary causal graphs that lack any information about the time lag between the cause and effect. Since both of our experimental datasets have ground-truth graphs with specified time lags, we tested and compared only those temporal algorithms that specify the time lags (i.e. produce full-time causal graphs). The implementation of the PCMCI and PCMCI+ have been adopted from the following repository: \url{https://github.com/jakobrunge/tigramite}, VarLiNGAM and DyNOTEARS from \url{https://github.com/ckassaad/causal_discovery_for_time_series}, and TCDF from \url{https://github.com/M-Nauta/TCDF}. The performance metrics from the conducted experiments are reported in Table~\ref{table-temporal-comparison}. 


\begin{table}[!h]
\centering
\small
\caption{The benchmarking of some common causal discovery algorithms for time series data. The best results w.r.t each metric (SHD, TPR, and FDR) are boldfaced. A lower SHD and FDR are better. While a higher TPR signifies a better performance. \newline}
\label{table-temporal-comparison}
\begin{tabular}{|c|ccc|ccc|}
\hline
 & \multicolumn{3}{c|}{\textbf{Syn-6 data}} & \multicolumn{3}{c|}{\textbf{fMRI data}} \\ \hline
\textbf{Methods} & \multicolumn{1}{c|}{SHD} & \multicolumn{1}{c|}{TPR} & FDR & \multicolumn{1}{c|}{SHD} & \multicolumn{1}{c|}{TPR} & FDR \\ \hline
PCMCI & \multicolumn{1}{c|}{14} & \multicolumn{1}{c|}{0.63} & 0.69 & \multicolumn{1}{c|}{61} & \multicolumn{1}{c|}{0.52} & 0.82 \\ \hline
PCMCI+ & \multicolumn{1}{c|}{\textbf{11}} & \multicolumn{1}{c|}{0.50} & \textbf{0.63} & \multicolumn{1}{c|}{\textbf{26}} & \multicolumn{1}{c|}{0.43} &\textbf{ 0.61} \\ \hline
VarLiNGAM & \multicolumn{1}{c|}{15} & \multicolumn{1}{c|}{0.50} & 0.73 & \multicolumn{1}{c|}{30} & \multicolumn{1}{c|}{0.48} & 0.66 \\ \hline
DyNOTEARS & \multicolumn{1}{c|}{28} & \multicolumn{1}{c|}{\textbf{0.83}} & 0.83 & \multicolumn{1}{c|}{95} & \multicolumn{1}{c|}{\textbf{0.81}} & 0.84 \\ \hline
TCDF & \multicolumn{1}{c|}{10} & \multicolumn{1}{c|}{0} & 1 & \multicolumn{1}{c|}{27} & \multicolumn{1}{c|}{0.38} & 0.64 \\ \hline
\end{tabular}
\end{table}


\begin{figure}[!h]
\centering
\includegraphics[width=0.325\textwidth]{SHD-temporal.png} \includegraphics[width=0.325\textwidth]{TPR-temporal.png}
\includegraphics[width=0.325\textwidth]{FDR-temporal.png}
\caption{SHD, TPR, and FDR plots of the benchmarked approaches on the time series datasets. A lower SHD and FDR are better. While a higher TPR signifies a better performance.}
\label{temporal-plots}
\end{figure}


The above results demonstrate that PCMCI+ performs the best in the case of both datasets w.r.t. the metrics SHD and FDR. This signifies that PCMCI+ produces lower false edges compared to the other approaches. DyNOTEARS has the best TPR in the case of both datasets. This signifies its ability to discover more true edges than others. However, it does not perform well in terms of SHD and FDR. TCDF performs very poorly in the case of the Syn-6 data. It couldn't discover a single true edge which causes its TPR to be 0 and a very high FDR. Although in the case of fMRI data, it has good SHD and FDR, it still has the lowest TPR signifying its tendency to produce a low amount of true edges. 


%other table without lags-algos
\begin{table}[!h]
\centering
\small
\caption{Performance results of two other temporal causal discovery algorithms. These are compared separately since the edges produced by these methods do not provide any time lag information.\newline}
\label{temporal-2}
\begin{tabular}{|c|ccc|ccc|}
\hline
 & \multicolumn{3}{c|}{\textbf{Syn-6 data}} & \multicolumn{3}{c|}{\textbf{fMRI data}} \\ \hline
\textbf{Methods} & \multicolumn{1}{c|}{SHD} & \multicolumn{1}{c|}{TPR} & FDR & \multicolumn{1}{c|}{SHD} & \multicolumn{1}{c|}{TPR} & FDR \\ \hline
oCSE & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{0.75} & 0.54 & \multicolumn{1}{c|}{15} & \multicolumn{1}{c|}{0.48} & 0.29 \\ \hline
GrangerPW & \multicolumn{1}{c|}{15} & \multicolumn{1}{c|}{1} & 0.65 & \multicolumn{1}{c|}{19} & \multicolumn{1}{c|}{0.57} & 0.45 \\ \hline
\end{tabular}
\end{table}

We further tested the ability of some temporal algorithms which only produce a summary time graph as their outcome. Their performance results are reported in Table~\ref{temporal-2}. The graphs produced by these methods do not incorporate any time lag information. Hence, only partial information may be obtained from these summary graphs. From the empirical results, we see that in the case of both datasets, oCSE performs better than GrangerPW in terms of the SHD and FDR metrics. While GrangerPW outperforms oCSE in both cases w.r.t. TPR.

 


\section{Tools for Causal Discovery}
\label{tool_boxes}
We briefly introduce the tools and software publicly available for users to perform causal discovery. These tools include the implementations of some benchmark causal discovery approaches as well as famous datasets, and commonly used evaluation metrics. Please refer to the table in the following page for the details of the tools or software packages.
\label{tools}

%\begin{tabular}
\begin{landscape}
\begin{center}
\small
%\scriptsize
%\tiny
    \begin{longtable}{ | c | p{1.7cm} | p{1.5cm} | p{3cm} | c | p{13.5cm} |}
    \caption{A brief overview of the tools/packages for Causal Discovery.} \\
    \hline
     & \textbf{Repository} & \textbf{Language} & \textbf{Developer} & \textbf{Year} & \textbf{Available algorithms/ datasets/ APIs} \\ \hline
    1 & bnlearn & R	& Marco Scutari, Ph.D. &2007 & • Implements a variety of score-based, constraint-based, hybrid algorithms. \newline • Also, contains famous benchmark networks in different formats such as BIF, DSC, NET, RDA, and RDS. • Link: \url{https://www.bnlearn.com/}.\\\hline
2 & CDT &Python	&FenTech \newline solutions	&2018	& •  Causal Discovery Toolbox has algorithms from the bnlearn package, pcalg packages, etc. based on observational data. \newline •Link: \url{https://github.com/FenTechSolutions/CausalDiscoveryToolbox}\\ \hline
3& Tigramite	&Python	&Jakob Runge	&2017	& • Temporal CD algorithms such as PCMCI, PCMCI+ and LPCMCI. \newline • Link: \url{https://github.com/jakobrunge/tigramite} \newline • A GUI version of the package is also available for easy user control. \\ \hline

4 & causal-learn & Python & CMU-CLeaR group & 2022 &  • Implements state-of-the art CD approaches and relevant useful APIs. Also implements CI tests like the Fisher-z test, Chi-Square test, etc., and score-functions such as BIC, BDeu.\newline • Contains several benchmark causal datasets. \newline • Link: \url{https://github.com/cmu-phil/causal-learn}\\ \hline

5 & gCastle & Python &  Huawei Noah's Ark Lab & 2021 & • Includes some recently developed gradient-based causal discovery methods with optional GPU acceleration. \newline
• Contains functions for generating data from either simulator or real-world dataset.
\newline
• Link: \url{https://github.com/huawei-noah/trustworthyAI} \\ \hline

6 & CausalNEX & Python & QuantumBlack Labs & 2021 & • Implements the NOTEARS algorithm and uses NetworkX to visualize the causal edges. \newline • Contains functions that allow users/experts to add the known causal edges or remove the false edges to model the relationships better. \newline • Link: \url{https://github.com/quantumblacklabs/causalnex} %Also, implements methods to perform counterfactual analysis.
\\ \hline

7 & Tetrad& JAVA & cmu-phil& 2018& • Allows graph creation by hand, using a random graph generator, or a search algorithm. \newline • It has a user-friendly GUI which allows users to input data and background knowledge and it outputs the causal graph based on the search algorithm selected by the user. It also allows learning the generated graph's parameters. \newline
• Link: \url{https://github.com/cmu-phil/tetrad}\\ \hline

8 & Causal MGM & R & Neha Abraham \& Benos Lab & 2017 & • Implements  Mixed Graphical Models (MGMs) to learn causal connections from directed or undirected graphs. Provides a framework for learning causal structure from mixed data (both continuous and discrete). • Link: \url{https://github.com/benoslab/causalMGM} \\ \hline

9 & py-causal & Python & BD2K Center \newline for Causal Discovery (UPitt-CMU) & 2016 & • Implements CD algorithms (FGES, GFCI, RFCI, FCI, etc. ) for continuous data, discrete data, and mixed data. \newline • Link: \url{https://github.com/bd2kccd/py-causal} \\ \hline

% 10 & CDTS & Python & C.K.ASSAD & & causal discovery for time series (CDTS) \\ \hline

10 & do-why & Python & Microsoft & 2018 & • Focuses on causal assumption and their validation \newline • Contains CausalDataFrame, an extension of pandas DataFrame \newline • Provides general API for the four steps of causal inference (modeling, identification, estimation, and refutation) • Link: \url{https://github.com/py-why/dowhy} \\ \hline

    \end{longtable}
\end{center}
\label{Tab7}

\end{landscape}
%\end{tabular}


\section{Challenges and Applications of Causal Discovery}
%In this section, we discuss the common challenges and applications of causal discovery in various fields. 

\subsection{Challenges} 
\label{challenges}
Despite the years of progress made in developing different approaches for causal discovery, there exist some concerns, and challenges that need to be addressed during the development of any causal discovery approach. One of the major concerns about the causal discovery algorithms is the strong \emph{assumptions} they make to recover the underlying causal graph from data. These assumptions make the task really challenging when \emph{any of these are violated}. One such assumption is the causal sufficiency which considers that \emph{there are no unobserved/latent variables}. Several methods estimate the causal relationships assuming there are no unobserved confounders. However, this might not be the case in real-world data. When real-world data violates this assumption and has hidden confounders, the estimation results could be distorted, and lead to false conclusions. Often \emph{real datasets have hidden confounders} that must be taken into account to obtain a true causal graph that represents the data generating process efficiently. Otherwise, this may lead to the \emph{possibility of biases} in the analysis. Therefore, the collected observational data with latent confounders is insufficient to infer the true underlying causal structure (\cite{LFCM}). Some studies such as \cite{latent1}, \cite{latent2}, etc. address the presence of latent variables in causal discovery. Another assumption which is the causal faithfulness condition also fails in multiple cases (e.g., if some variables are completely determined by others). 

Most of the CD algorithms are based on the assumption that the data samples are \emph{independent and identically distributed (I.I.D.)}. However, in many real-world scenarios, the data may have been generated in a different way, and thus, the iid assumption is violated (\cite{rrcd}). In such cases, using CD algorithms that assume that the data is I.I.D. may produce spurious and misleading relationships. Apart from failures of the assumptions, some approaches may get stuck to a local optimum. Especially, greedy methods (e.g. GES (\cite{chickering2002optimal}), SGES (\cite{chickering2015selective}), etc.) can get trapped in local optimum, even with large datasets. These methods may often produce sub-optimal graphs in the absence of infinite data. \emph{Computational complexity} is another challenge for causal discovery algorithms. The \emph{search space grows super-exponentially} due to the \emph{combinatorial nature of the solution space}, which makes even simple methods computationally expensive (\cite{chickering1996learning}). In the case of the score-based approaches, the \emph{large search space} over all possible DAGs is a major drawback. Hence, score-based methods seem to work well when there are a few or moderate number of nodes. However, these methods suffer when the space of equivalence classes tends to grow super exponentially for dense networks. \emph{Lack of abundant observational data} is another major concern for many CD approaches. For constraint-based approaches such as PC (\cite{pc}), FCI (\cite{FCI}), etc., accurate CI testing is possible only when an infinite amount of data is available. With a \emph{finite amount of data, conditional independence (CI) tests become really challenging}. Another disadvantage of the constraint-based approaches is that with a \emph{large sample size or high dimensionality}, the \emph{number of CI tests grows exponentially}. Even, in some cases, the algorithm might take weeks to provide the output. That is, the run time of the algorithm becomes way too long. 

Structure \emph{identifiability} of the underlying causal model (\cite{LiNGAM}) is another issue in causal discovery. A causal graph $G$ is typically not identifiable given observational data only, as a set of possible graphs could have generated the data. Also, the statistical issues stemming from high-dimensional datasets are of concern. Apart from these, a major challenge is the \emph{lack of enough benchmark datasets} with ground truth to train and evaluate the developed causal models. The lack of a comprehensive public data repository consisting of ground-truth graphs hinders the proper evaluation of CD approaches. This problem is severe for areas such as climate science where there is almost never any exact ground truth available (\cite{ICSD}). Hence, the only way to analyze the produced graphs in such scenarios is to let domain experts inspect those and see if they actually make sense (\cite{ebert2017causal}, \cite{gani2023structural}). 

In the case of causal discovery from \textit{time series data}, along with the aforementioned challenges, there are some other challenges too which cause research in this area to be still growing.  In many real-world applications, the observed data are obtained by applying subsampling or temporal aggregation to the original causal processes, which makes it tough to discover the underlying causal graph (\cite{gong2017causal}). Also, it is difficult to infer the causal relations across samples with different underlying causal graphs (\cite{ACD}). Some approaches also suffer from nonlinear relations in time-series data. Another important challenge is the discovery of causal relations from large-scale observational time series datasets which is an active area of research. 

\subsection{Applications}
\label{Applications}

Causal discovery is widely used in various fields, ranging from healthcare, economics, earth science, education, machine learning, natural language processing, and many more. The challenges faced with correlation-based machine learning have facilitated the development of several causal discovery techniques and increased their applications in many domains.

In \textbf{biomedical and healthcare}\textbf{ domains,} the %main goal of solving any problem is not just to build a method that gives the highest accuracy. Rather the 
key research questions revolve around identifying the underlying causal mechanism to find the risk factors that can be changed to cure a disease. To serve this purpose, researchers have been using causal discovery techniques for a long time. %In 1999, S. Mani and G.F. Cooper
\cite{mani1999study} used a modified local causal discovery technique to identify the factors contributing to infant mortality in the USA. \cite{wang2006causal} used a stepwise causal discovery method %named Stepwise Causal Adjacent Relationship Discovery (STEPCARD) 
to identify active components or combinations of the components in herbal medicine. The \textit{Fast Causal Inference (FCI) } and \textit{Fast Greedy Equivalence Search (FGS)} methods were used by \cite{shen2020challenges} to see how accurately these techniques can generate the ‘gold standard’ graph of Alzheimer’s Disease. They evaluated the performance of the algorithms on the dataset collected from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) and found that the causal graphs generated by FCI and FGES are almost identical to the ‘gold standard’ graph created from the literature. They also suggested that using longitudinal data with as much prior knowledge as feasible will maximize the effectiveness of causal discovery algorithms. More recently, \cite{shen2021novel} proposed a causal discovery technique that can be applied to large-scale Electronic Health Record (EHR) data and has been applied to identify the causal structure for type-2 diabetes mellitus. Before applying the algorithm, they utilized a data transformation method that converts longitudinal data to disease events. The algorithm uses a BIC score to find the causal graph which overlaps 81\% with the graph validated by the professionals. Some studies (\cite{bikak2020}, \cite{gani2023structural}) have combined the outcomes from several causal discovery algorithms with the opinions of healthcare experts to develop more reliable and plausible causal graphs. \cite{gani2023structural} studies the effect of liberal versus conservative oxygen therapy on the mortality of ICU patients where they present an expert-augmented causal estimation framework. The framework systematically combines results from a set of causal discovery algorithms with expert opinions to produce the final causal graph (Figure \ref{OT_graph}) that is used to answer some important clinical causal queries. 

\begin{figure}[!h]
\centering
\includegraphics[width=1\textwidth]{OT}
\caption{Causal factors determining the influence of oxygen therapy on the mortality of critical care patients (\cite{gani2023structural}). This causal graph was determined by the majority voting of 7 causal discovery algorithms combined with opinions from the domain experts.}
\label{OT_graph}
\end{figure}




%STEPCARD was used in order to explore the link between chemical composition and bioactivity and it detected active ingredients from QX Formulation with great success. 

%A Bayesian Structural Equation Model (BSEM) technique was proposed to evaluate the causative relationships between numerous parameters associated with lipid metabolism using the data from the 2005–2006 National Health and Nutrition Examination Survey (NHANES) (\cite{yang2013causal}). 

%The BSEM method successfully blends simultaneous equation modeling methods with local learning concepts and works with continuous data having any arbitrary distribution. 

%Empirical results showed that BSEM successfully identified the relationships among the causal factors of lipid metabolism. 

\textbf{Earth science and climate} related research is another domain where causality has been widely adopted. The well-known \textit{PC algorithm} was applied to find the causal links between Eastern Pacific Oscillation (EPO), Western Pacific Oscillation (WPO), North Atlantic Oscillation (NAO), and Pacific-North America (PNA) patterns which are four important patterns of atmospheric low-frequency variability in boreal winter (\cite{ebert2012causal}). The results, which support earlier research on dynamical processes, suggested that WPO and EPO are almost identical from a cause-and-effect standpoint due to their high contemporaneous coupling. The \textit{PC} and \textit{ PC stable} algorithms were applied to daily geopotential height data at 500MB over the boreal winter (\cite{ebertusing}). The results showed that the atmospheric interactions become less strong on average over the whole Northern Hemisphere. Reduced interconnectedness across various geographic places is the result of this weakening, particularly in the tropics. Causal discovery methods were also applied to verify the results obtained from dynamic climate models. \cite{hammerling2015can} used the \textit{PC algorithm} to learn the causal signatures from the output of the dynamic model. These causal signatures can provide an additional layer of error checking and identify whether the results of dynamic models are accurate or not. \cite{ombadi2020evaluation} applied Granger causality, PC, convergence cross-mapping, and transfer entropy to hydrological models. The authors used these causal discovery methods to identify and investigate the causes of evaporation and transpiration in shrubland areas throughout the course of the summer and winter. Furthermore, the study \cite{Dr-Wangs-paper} investigated the causal relations between multiple atmospheric processes and sea ice variations using three different data-driven causal discovery algorithms, and based on their experiments, they found that it is very challenging to directly apply the state-of-the-art data-driven causal discovery approaches to the specific climate topic considered. Recently, \cite{Sahara} studied the causal relation between Greenland blocking and sea ice melt using some deep learning-based causal analysis techniques. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.55\textwidth]{Climate_application_causal_graph.png} %\includegraphics[width=0.52\textwidth]{LUCAS.png}
\caption{Causal influence of climate and environmental factors on the collapse of an Arctic ecosystem from a storm surge (\cite{shepherd2021meaningful}).}
\label{LUCAS}
\end{figure}

The \textbf{education sector} has leveraged causal discovery techniques for decades now. \cite{druzdzel1995college} performed an experiment based on the \textit{Tetrad II} (\cite{tetrad}) causal discovery program on why the retention rate of U.S. universities is low compared to their reputation. The causal discovery model identified that the retention rate mostly depends on the quality of incoming students. \cite{fancsali2014causal} used the \textit{PC} and \textit{FCI} algorithms to answer questions based on their causal effect. They specifically considered the situation given that a student who plays computer games scored poorly in his exam, can the algorithms answer whether reducing gaming time will improve his results? \cite{quintana2020structure} employed the \textit{PC} and \textit{FGS} algorithms to find which social and economic factors are directly related to academic achievements. The algorithms found earlier accomplishment, executive functions such as thinking skills, sustained attention focusing, and ambition as the primary drivers of academic performance, which is in line with other studies.

Over the past few years, the intersection of causality with \textbf{Machine Learning (ML) }\textbf{ and} \textbf{Artificial Intelligence (AI)} techniques is quite a topic of interest. \cite{sun2015using} utilized \textit{Granger causality} for selecting machine learning features in two-dimensional space. This approach outperformed the traditional feature selection techniques like Principal Component Analysis (PCA) (\cite{PCA}),  Functional Connectome (FC) (\cite{bishop1995neural}), and  Recursive Feature Elimination (RFE) (\cite{guyon2002gene}) due to the ability of \textit{Granger} causality to identify the causal connection between the input variable and the chosen time series. \cite{nogueira2021causal} published a survey paper that mainly focused on the applications of causal discovery in machine learning. They discussed how the constraint-based and score-based approaches, as well as causal neural networks and causal decision trees, were applied along with machine learning in various topics. Although previously researchers were not much interested in applying causal techniques in \textbf{Natural Language Processing (NLP)}, an important sub-field of AI, recently several causal discovery methods have been applied in this area. To get a deeper explanation, one can read the survey written by \cite{feder2021causal} that discusses the applications of different causal discovery techniques in NLP and how these techniques can help to improve this domain further.

In addition to the abovementioned domains, causal discovery techniques are also being used in \textbf{business, macroeconomics, manufacturing, and software engineering,} to name a few.  \cite{hu2013software} used a causal Bayesian network with some specialized constraints to analyze the risks associated with software development projects. %The causal discovery technique produced findings that were consistent with the understanding of experts and outperformed more conventional machine learning models. 
\cite{luo2021causal} used causal discovery models to identify the relationship between flight delays and service nodes. \cite{hall2022causal} employed causal discovery in macroeconomic dynamic stochastic general equilibrium (DSGE) models to learn the underlying causal structure. \cite{vukovic2022causal} wrote a review paper identifying the applications of causal discovery in manufacturing where root cause analysis, causality in a facilitator role, fault detection, analysis, and management have been highlighted as important areas of application. In business, the understanding of causal relations plays a vital role in designing effective interventions such as launching a new advertising campaign or a promotion (\cite{etio}). 

Apart from these applications, to learn the causal structure from relational data, \cite{rrcd} developed a method called RRCD (Robust Relational Causal Discovery) where they demonstrated how a CI test created for I.I.D. data can be successfully used to test for relational conditional independence (RCI) against relational data. Moreover, some methods model casual relationships by the incorporation of background knowledge obtained from several sources including experts’ opinions, domain knowledge, prior evidence, relevant literature, etc. An importance of such a knowledge-based strategy is that additional causal relationships may become identifiable with the incorporation of background knowledge (\cite{KCRL}). Even specifying one variable as the cause of another, can further refine the set of potential graphs, thereby increasing the number of identifiable causal relationships (\cite{PKCL}). Some studies (\cite{gani2023structural}, \cite{CKH}, \cite{adib2022causal}) even highlight the importance of human-in-the-loop, and recommend taking into account domain experts' opinions to verify the graphs produced by different causal discovery algorithms. Other than these, causal discovery have been applied in representation learning as well. \cite{CausalVAE} proposed a generative model named CausalVAE which learns disentangled and causally meaningful representations of the data by combining ideas of VAE with the SCM. They introduced a \textit{causal layer} with a DAG structure to be learned inside the vanilla VAE model which converts independent exogenous factors into causal endogenous ones.

All in all, causal discovery approaches and techniques have been widely adopted in several areas for understanding the underlying causal relationships, and thereby deriving actionable insights. However, while applying causal discovery methods it is very important to consider the \textit{corresponding assumptions}. If the assumptions made by the respective algorithm are violated by the data, then it may often lead to biased results. Thus, it is important to ensure that the assumptions hold for unbiased discovery of causal graphs.




% %\subsection{Causal Discovery with Prior Knowledge}
% \subsection{Knowledge-based}
% *************Over the years, some causal discovery approaches have been developed to model casual relationships by the incorporation of background knowledge obtained from several sources including experts’ opinions, domain knowledge, prior evidence, relevant literature, etc. Infusion of informative priors can enhance model efficiency and also overcome the weaknesses of smaller datasets (\cite{mooij2020joint}). Often some prior knowledge is available in most domains that may come from different sources. For example, in medicine, most cases have prior knowledge about symptoms, diseases, and treatments which can be obtained from clinical literature or knowledge bases. Additional causal relationships may become identifiable with the incorporation of background knowledge (\cite{KCRL}). Even specifying one variable as the cause of another, can further refine the set of DAGs, thereby increasing the number of identifiable causal relationships (\cite{PKCL}). Some studies (\cite{CKH}, \cite{gani2023structural}) highlight the importance of human-in-the-loop, and recommend taking into account domain experts' opinions to verify the graphs produced by different causal discovery algorithms.  Below we list some notable knowledge-based approaches to causal discovery.



\section{Discussion}
\label{discussion}

Traditional AI applications that solely rely upon predictions lack explainability and are often difficult to comprehend due to their black-box nature. \textit{Causal analysis} can overcome the lack of explainability in the existing AI models by embedding casual knowledge into them. These models have greater transparency, and thereby, achieve greater reliability. A crucial part of the causal analysis is \textit{causal discovery}. It is the recovery of the underlying causal structure represented in a graphical form. Such visualizations of causal relationships are easy to comprehend as well as more appealing to a user. In this survey, we introduce a wide variety of existing approaches to perform causal discovery. We also provide a brief overview of the common terminologies used in the area of causal discovery and summarize the different types of algorithms available for structure learning from both I.I.D. and time series data. Apart from discussing the approaches, we also discuss the commonly used datasets, metrics, and toolboxes for performing causal discovery efficiently. In order to select an appropriate approach for learning the causal structure, one can consider some of the following aspects. Selecting the approach whose assumptions are met by the data is very crucial. For example, some methods work well for either linear or non-linear data while some may need a very high amount of samples to operate efficiently. So, before choosing an algorithm, it is important to understand if the assumptions made are also supported by the data or not. When the assumptions are violated by the data, there is a high chance of obtaining misleading results from the algorithm. Also, some algorithms have a faster run time while others are comparatively much slower. Particularly, some constraint-based methods tend to be much slower when the number of variables are high as they need to conduct a huge amount of CI tests. Therefore, one should also select the approach considering the time available to perform the experiments. 

With the growing number of approaches for causal structure learning, an essential \textit{future research direction} is to look deeper into the common challenges or limitations faced during the process. Towards the end of this paper, we discuss some of the common challenges as well as a wide variety of applications of causal discovery in multiple fields. \textit{Future causality research} should focus on the nature of real-world datasets, and develop methods that take into account these practical constraints for better and more reliable structure recovery. It is often observed during experiments that different methods produce causal graphs that disagree with each other to a great extent. In fact, in the experiments (benchmarking) that we performed, we also observed a significant disagreement among the approaches w.r.t. their estimated causal graphs. Therefore, it is needed to accurately quantify the uncertainty of the inferred structures. This is particularly important for the areas such as the healthcare sector which is related to the well-being of humans. It is also important to consider any available background knowledge such as domain expertise, literature evidence, etc. during the causal discovery process which may help to overcome the existing challenges. Once the causal community becomes successful in addressing the existing challenges, we may hope to have better approaches with greater accuracy and reliability.
%and review a couple of CD methods that incorporate prior knowledge into the structure search process. 

%Even widely used deep learning models such as neural networks are highly efficient in finding intricate patterns in data. However, these models are a “black box” as no one understands what is happening inside it. Simple linear regression models, although have greater transparency, are usually very restrictive to be useful in solving complex problems. Thus, there exists a trade-off between complexity and explainability in traditional ML algorithms. 


 

% \subsubsection*{Broader Impact Statement}
% In this optional section, TMLR encourages authors to discuss possible repercussions of their work,
% notably any potential negative impact that a user of this research should be aware of. 
% Authors should consult the TMLR Ethics Guidelines available on the TMLR website
% for guidance on how to approach this subject.

% \subsubsection*{Author Contributions}
% If you'd like to, you may include a section for author contributions as is done
% in many journals. This is optional and at the discretion of the authors. Only add
% this information once your submission is accepted and deanonymized. 

% \subsubsection*{Acknowledgments}
% Use unnumbered third level headings for the acknowledgments. All
% acknowledgments, including those to funding agencies, go at the end of the paper.
% Only add this information once your submission is accepted and deanonymized. 

\subsubsection*{Acknowledgments} We sincerely thank the anonymous reviewers and action editor for their valuable feedback, which greatly contributed to the enhancement of this survey. We would like to express our sincere gratitude to Professor Elias Bareinboim for his insightful feedback.  This research received partial support from the National Science Foundation (NSF Award  2118285) and the UMBC Strategic Awards for Research Transitions (START). The views expressed in this work do not necessarily reflect the policies of the NSF, and endorsement by the Federal Government should not be inferred.

\bibliography{main}
\bibliographystyle{tmlr}

%\appendix
%\section{Appendix}
%You may include other additional sections here.

\end{document}
