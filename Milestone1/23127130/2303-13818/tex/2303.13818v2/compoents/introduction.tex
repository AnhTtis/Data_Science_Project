In recent years, deep learning (DL) methods have significantly improved the computer-assisted diagnosis of chest X-ray (CXR) images. DL methods have been used in multiple ways. For instance, Ma and Lv~\cite{Pneumonia} used a Swin transformer with fully-connected layers to classify CXR images as either normal or indicative of pneumonia. Cicero et al.~\cite{Cicero2017TrainingAV} modeled the diagnosis process as a multi-label classification problem and used GoogleNet to classify CXR images into six categories. In comparison to these classification methods, generated free-text radiology reports can provide more comprehensive information about the impression and findings~\cite{radgraph}. Shin et al.~\cite{LearnToRead} were among the first to utilize the CNN-RNN architecture for generating descriptive text automatically. Wang et al.~\cite{TieNet} introduced TieNet, which generates long text reports and simultaneously detects common thorax diseases. Hou et al.~\cite{RATCHET} proposed RATCHET, which utilizes transformer \cite{transformer} to generate reports from CXR images and uses an attention mechanism to identify regions of interest in the image for the corresponding generated text. Despite the potential benefits of automating medical reporting, existing approaches for automation mainly rely on generating free text, which poses challenges for clinical evaluation~\cite{pino2021clinically,few_shot}. To address this issue, RadGraph Benchmark~\cite{radgraph} was introduced. It uses a novel data extraction schema to extract structured clinical information from free-text radiology reports and represents them as a radiology graph. Each node in a radiology graph corresponds to a unique entity, such as an anatomical structure or an observation and its presence and uncertainty. Although these graph representations of reports have been used to evaluate the clinical correctness of reports~\cite{yu2022evaluating}, generating radiology graphs directly from CXR images has not been explored. In contrast, diverse interactions between object pairs in natural images in the form of scene graph generation have been extensively investigated \cite{lu2016visual}. Li et al.~\cite{Li_2022_CVPR}, and Lu et al.~\cite{lu2021seq2seq} employed two-stage methods to propose dense relationships between predicted connected object pairs. In recent work, Shit et al.~\cite{relationformer} introduced Relationformer, a unified one-stage framework based on DETR \cite{detr} that facilitates the end-to-end generation of graphs from images. It is a state-of-the-art method for detecting and generating graphs from natural images. However, it requires bounding boxes for the detected objects (nodes of the graph) and is not directly applicable to radiology graphs since some nodes (entities) in radiology graphs do not have exact locations, such as ``left`` or ``clear``, and most datasets do not provide bounding boxes annotations.\looseness=-1

Therefore, we propose a detection-free method, Prior-RadGraphFormer, to generate radiology graphs directly from CXR images without requiring bounding boxes for each entity. The method incorporates prior knowledge in the form of probabilistic knowledge graphs (PKG) \cite{prob_prior,graph_embedding,volker2018,cls_by_attention} that model the statistical relationship between anatomies and pathological observations. Experimental results show that Prior-RadGraphFormer achieves competitive results in the radiology-graph-generation task. Moreover, the generated graphs can be used for multiple downstream tasks such as generating free-text reports based on predefined rules, cheXpert labels \cite{chexpert} classification, and populating templates for structured reporting.

In summary, our contributions are the following: 1) proposing a novel detection-free method that generates radiology graphs directly from CXR images; 2) enhancing this method by incorporating prior knowledge, leading to improved performance; 3) extensively evaluating our method using RadGraph metrics and the two downstream tasks of report generation and multi-label classification of pathologies.





