\begin{figure}[ht]
     \centering
     % \begin{subfigure}
    \includegraphics[width=0.9\linewidth]{viz/figure2-2_croped.pdf}
     % \end{subfigure}
     
     % \begin{subfigure}
    \includegraphics[width=0.9\linewidth,,page=2]{viz/figure2-2_croped.pdf}
     % \end{subfigure}
  \caption{\textbf{Qualitative results}. On the left and middle are the CXR images and the corresponding predicted radiology graphs by our model. On the right, we present the outputs of two downstream tasks derived via the predicted graph: free-text clinical report and pathologies classification result. True positives, false negatives, and false positives are represented by green, gray, and red, respectively.}%
  \label{qualitative_results}
\end{figure}

\begin{table}[ht]
    \centering
    \caption{\textbf{Results comparisons on the validation set.} (P: precision, R: recall; B-1: BLEU-1, MET.: METEOR, R\_L: ROUGE\_L scores; At: Atelectasis, Ed: Edema, PE: Pleural Effusion, LO: Lung Opacity.) Best quality performance in bold.}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
    \hline
    \hline
    \multirow{3}*{Method} & \multicolumn{6}{c|}{RadGraph Metrics} & \multicolumn{4}{c|}{NLP Metrics} &  \multicolumn{4}{c}{Classification F1}\\
    \cline{2-15}
    & \multicolumn{3}{c|}{Entity} & \multicolumn{3}{c|}{Relation} & \multirow{2}*{B-1} & \multirow{2}*{MET.} & \multirow{2}*{R\_L} & \multirow{2}*{SPICE} & \multirow{2}*{At} & \multirow{2}*{Ed} & \multirow{2}*{PE} & \multirow{2}*{LO}\\
    \cline{2-7}
    & P & R & F1 & P & R & F1 & & & & & & & & \\
    \hline
    RATCHET & - & - & - & - & - & - & \textbf{0.18} & \textbf{0.09} & 0.19 & \textbf{0.09} & 0.38 & 0.27 & 0.47 & 0.17 \\
    RATCHET $\rightarrow$ RadGraph Benchmark & 0.45 & 0.16 & 0.24 & 0.11 & 0.03 & 0.05 & - & - & - & - & - & - & - & - \\
    vanilla RadGraphFormer & 0.58 & 0.47 & 0.52 & 0.35 & 0.19 & 0.25 & 0.14 & 0.08 &\textbf{0.21} & 0.08 & \textbf{0.40} & 0.26 & \textbf{0.82} & \textbf{0.24} \\
    Prior-RadGraphFormer & \textbf{0.63} & \textbf{0.55} & \textbf{0.59} & \textbf{0.44} & \textbf{0.21} & \textbf{0.28} & 0.07 & 0.07 & 0.19 & 0.08 & 0.39 & \textbf{0.29} & 0.81 & 0.22 \\
    \hline
    \hline
    \end{tabular}
    }
    \label{main_result}
\end{table}


\section{Results and Discussion} 

\subsection{Main Results}
Given that no prior work has addressed our task, we create a baseline that can be evaluated via RadGraph metrics. The baseline is constructed by two separate pretrained models, where RATCHET{~\cite{RATCHET}} is used to predict free-text reports from CXR images and followed by RadGraph Benchmark{~\cite{radgraph}} to produce radiology graphs from predicted reports. Note that radiology graphs generated from ground truth reports via pretrained RadGraph Benchmark are essentially ground truth labels as discussed in Section. {\ref{datasets}} hence they are not directly comparable with our results. Additionally, we compare the performance of vanilla RadGraphFormer with Prior-RadGraphFormer. As is shown in Table.~\ref{main_result}, both vanilla RadGraphFormer and Prior-RadGraphFormer demonstrate superior performance over the baseline in all RadGraph metrics. In particular, Prior-RadGraphFormer shows better performance than vanilla RadGraphFormer, indicating the significance of leveraging prior knowledge for radiology graphs generation. 

\subsection{Downstream Tasks}
For downstream tasks, we compare our methods with RATCHET~\cite{RATCHET} using free-text NLP metrics and cheXpert label classification F1 score. However, please note that there may be variations in the numerical results of RATCHET due to differences in the validation set used in our experiments compared to the original paper. Table.~\ref{main_result} shows that our radiology graphs directly generated from CXR images can be properly transformed into free-text reports and pathologies classification results. They have reasonable performance in the corresponding evaluation and demonstrate the utility of a graph-based representation in the context of a clinical study. 

From Table.~\ref{main_result} it is evident that vanilla RadGraphFormer exhibits better performance with respect to BLEU-1 score and F1 score of several pathologies as compared to Prior-RadGraphFormer. This disparity in performance can be explained by a more varied set of entities in radiology graphs generated by vanilla RadGraphFormer.
Also, it is worth noting that the NLP metrics of RATCHET are generally better than our methods. However, higher NLP metrics may not indicate better clinical usefulness~\cite{pino2021clinically}. One example is shown in Table.~\ref{compare_metric_study}. Qualitative results can be seen in Fig.~\ref{qualitative_results}. 

\begin{table}[ht]
    \centering
    \caption{\textbf{Example of evaluating clinical reports with NLP metrics.} In this case, our report exhibits superior clinical accuracy compared to RATCHET, but NLP metrics associated with it are significantly lower.}
    \begin{tabularx}{\linewidth}{L|c|c|c|c|c}
    \hline
    \hline
       \multirow{2}*{Report section} & \multicolumn{4}{c|}{NLP Metrics} & \multicolumn{1}{c}{Classification}\\
       \cline{2-6}
       &B-1 & MET. & R\_L & SPICE & PE\\
       \hline
       \textbf{Ground Truth}: As compared to the previous radiograph, small left and moderate  layering right pleural effusions have increased in size. & - & - & - & - & Positive\\
       \hline
       \textbf{RATCHET}: As compared to the previous radiograph, the patient has been intubated. & 0.36 & 0.19 & 0.47 & 0.24 & Negative \\
       \hline
       \textbf{Prior\&Vanilla-RadGraphFormer}: There is enlarged effusion located at bilateral of pleural. & 0.07 & 0.06 & 0.13 & 0.12 & Positive\\
    \hline
    \hline
    \end{tabularx}
    \label{compare_metric_study}
\end{table}



\begin{table}[ht]
    \centering
    \caption{\textbf{Ablation studies on the validation set.} (AECS: additional entity class supervision)}\looseness=-1
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|c|c|c|c|c|c}
    \hline
    \hline
       \multirow{2}*{Method} & \multicolumn{3}{c|}{Entity} & \multicolumn{3}{c}{Relation}\\
       \cline{2-7}
       & Precision & Recall & F1-score & Precision & Recall & F1-score\\
       \hline
       vanilla RadGraphFormer & 0.58 & 0.47 & 0.52 & 0.35 & 0.19 & 0.25\\
       Prior-RadGraphFormer w/o PKG & 0.61 & 0.50 & 0.55 & 0.39 & 0.17 & 0.23 \\
       Prior-RadGraphFormer w/o AECS & 0.63 & 0.49 & 0.55 & 0.43 & 0.17 & 0.24 \\
       Prior-RadGraphFormer & \textbf{0.63} & \textbf{0.55} & \textbf{0.59} & \textbf{0.44} & \textbf{0.21} & \textbf{0.28} \\
    \hline
    \hline
    \end{tabular}
    }
    \label{ablation_study}
\end{table}

\subsection{Ablation Studies} In our ablation studies, we aim to investigate two key aspects. Firstly, we aim to determine whether the integration of PKG truly improves performance or whether it is the graph transformers that enhance the model. Secondly, we aim to explore the impact of incorporating additional entity class supervision on entity and relation metrics. 

 To assess the impact of PKG integration, we simply use nodes features and edges features after graph transformers without assimilation to generate classification outputs. The results presented in Table.~\ref{ablation_study} demonstrate that Prior-RadGraphFormer without PKG is inferior to Prior-RadGraphFormer, thereby highlighting the importance of incorporating PKG as priors in Prior-RadGraph-Former.

 As for the influence of incorporating additional entity class supervision in the assimilation step, we conduct a comparative experiment by removing it and analyzing the resulting performance. The experimental results displayed in Table.~\ref{ablation_study} show that the impact is positive.

 \subsection{Limitations and Outlook} In this work, we evaluated the performance without directly using the graph itself. In the future work we plan to investigate additional graph-specific metrics \cite{rolinek2020deep,wills2020metrics}  to provide a more comprehensive evaluation. Furthermore, we acknowledge that the number of baselines is limited and aim to explore more comparative models in our ongoing research. Additionally, the inclusion of PKG increases the training time. In future work, we plan to optimize the integration of PKG to accelerate the training without compromising performance.