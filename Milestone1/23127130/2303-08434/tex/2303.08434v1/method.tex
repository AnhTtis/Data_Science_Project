
\section{Methodology}

A number of signal processing methods such as Fourier transform, Radon transform and Hough transform involve a process of mapping discrete signals from image space to another functional space.
We call this new space accumulator space, because the value of each cell in the new space is a weighted sum of values from the complete set of cells in the original image space. 
One desirable property of the accumulator space for our application is that local convolutions in the accumulator space such as Hough and sinogram space leads to global aggregation of structural features such as lines \cite{lin2020deep,zhao2021deep} in the feature map space, which is beneficial for integrating geometric priors into neural networks.
Unlike attention based methods \cite{wang2018non,zhang2021efficient}, this accumulator space convolution captures long-range information explicitly by direct geometric prior parameterization.

\subsection{Differentiable Directed Accumulation}
\label{sec:deda}

The process of transforming an image to an accumulator space involves a critical step, directed accumulation (DA), in which a cell from the accumulator space is pointed by multiple cells from the image space.
Fig.~\ref{fig:deda-gs}, Eq.~\eqref{eq:gs} and Eq.~\eqref{eq:deda-back} have shown that this DA operation is a symmetric operation to the grid sampling \cite{jaderberg2015spatial} within the forward-backward learning framework, where the backward pass of DA possesses the same structure as the forward pass of grid sampling if only one sampling grid is given, and vice versa for the forward pass.
In addition, DA is further generalized to allow multiple sampling grids to accumulate values from the source feature map.
Here we briefly review the grid sampling method and then derive the proposed DeDA.
% The most related operation to the directed accumulation is the grid sampling. 
% method that is first introduced in spatial transformer networks \cite{jaderberg2015spatial} which gives neural networks the ability to spatially transform feature maps.
% A successful application of the spatial transformer in the medical field is the deformable image registration \cite{balakrishnan2019voxelmorph}.
% As can seen from Fig. \ref{fig:deda-gs}, the proposed DeDA can be regarded as a generalized symmetric operation of the grid sampling with value accumulation from multiple flow-field grids.
% The proposed DeDA differs from the grid sampling in two folds: 
% 1) The backward pass of DeDA is the same as the forward pass of the grid sampling if only one flow-field is given, and vice versa for the forward pass.
% 2) DeDA is further generalized to allow multiple flow-field grids to accumulate values from the source feature map. 
% Here we briefly review the grid sampling method and then derive the proposed DeDA.

\textbf{Grid Sampling}:
Given a source feature map $\mathbf{U} \in \mathbb{R}^{C\times H \times W}$, a sampling grid $\mathbf{G} \in \mathbb{R}^{2\times H' \times W'}=(\mathbf{G}^x, \mathbf{G}^y)$ specifying pixel locations to read from $\mathbf{U}$, and a kernel function $\mathcal{K}()$ defining the image interpolation, then the output value of a particular position $(i,j)$ at the target feature map $\mathbf{V} \in \mathbb{R}^{C\times H' \times W'}$ can be written as follows:

\begin{equation}
    \mathbf{V}_{ij}^{c} = \sum_n^{H}\sum_m^{W} \mathbf{U}_{nm}^{c}\mathcal{K}(\mathbf{G}_{ij}^x,n)\mathcal{K}(\mathbf{G}_{ij}^y,m),
    \label{eq:gs}
\end{equation}
where the kernel function $\mathcal{K}()$ can be replaced with any other specified kernels, e.g. integer sampling kernel $\delta(\lfloor\mathbf{G}_{ij}^x+0.5\rfloor-n)\cdot \delta(\lfloor\mathbf{G}_{ij}^y+0.5\rfloor-m)$ and bilinear sampling kernel $\text{max}(0,1-|\mathbf{G}_{ij}^x-n|) \cdot \text{max}(0,1-|\mathbf{G}_{ij}^y-m|)$. 
Here $\lfloor x+0.5\rfloor$ rounds $x$ to the nearest integer and $\delta()$ is the Kronecker delta function.
The gradients with respect to $\mathbf{U}$ and $\mathbf{G}$ for back propagation can be defined accordingly \cite{jaderberg2015spatial}.

\textbf{DeDA}:
% 2) Reading values from the source feature map can only be done using the whole cell in the DeDA, while the grid sampling can read weighted values based on the sampling kernel. 
% 3) The DeDA can write weighted values to the target feature map, while writing values to the target feature map can only done using the whole cell in the grid sampling.
Given a source feature map $\mathbf{U} \in \mathbb{R}^{C\times H \times W}$, a target feature map $\mathbf{V} \in \mathbb{R}^{C\times H' \times W'}$, a set of sampling grids $\mathcal{G} = \{\mathbf{G}[k] \in \mathbb{R}^{2\times H \times W}=(\mathbf{G}^x[k], \mathbf{G}^y[k])~|~k \in \mathbb{Z}^+, 1 \leq k \leq N \}$ ($N\geq 1$ is the number of grids), and a kernel function $\mathcal{K}()$, the output value of a particular position $(i,j)$ at the target feature map $\mathbf{V}$ can be written as follows:
\vspace{-1ex}
\begin{equation}
    \mathbf{V}_{ij}^{c} = \sum_k^{N}\sum_n^{H}\sum_m^{W} \mathbf{U}_{nm}^{c}\mathcal{K}(\mathbf{G}_{nm}^x[k],i)\mathcal{K}(\mathbf{G}_{nm}^y[k],j).
    \label{eq:deda}
    \vspace{-1ex}
\end{equation}
It is worth noting that the spatial dimension of the grid $\mathbf{G}[k]$ should be the same as that of $\mathbf{U}$, but the first dimension of $\mathbf{G}[k]$ can be an arbitrary number as long as it aligns with the number of spatial dimensions of $\mathbf{V}$, e.g. if given $\mathbf{U} \in \mathbb{R}^{H \times W}$ and $\mathbf{G}[k] \in \mathbb{R}^{3\times H \times W}$, it is expected that $\mathbf{V} \in \mathbb{R}^{H' \times W' \times D'}$.
Basically, the DeDA operation in Eq.~\eqref{eq:deda} performs a function mapping by $\mathcal{D}:(\mathbf{U},\mathcal{G};\mathcal{K})\rightarrow \mathbf{V}$, where $\mathcal{K}$ is the sampling kernel.
For simplicity, function $\mathcal{D}()$ will be used to denote the DeDA forward for the rest of the paper.

\begin{figure}[!t]
	\centering
        \vspace{-1ex}
	\includegraphics[width=1.0\columnwidth]{./deda_gs.png}
	\vspace{-1ex}
        \caption{
    Visual illustration of the proposed method. 
    The left panel shows differences between the grid sampling and the proposed DeDA using bilinear sampling kernel.
    The right panel shows the schematic for rim parameterization, where the knowledge of a triple $(x,y,\theta)$ is mapped to a straight line (marked in orange) in the accumulator space.
    % In the forward pass of DeDA, the feature value in the source feature map flows along the given direction into the target cell in the accumulator space, and the final value in the target cell is the sum of all values that flow into it. 
    % In the backward pass, the gradient flows back from the accumulator cell along the opposite direction into the previous value cell.
    % From the figure we can see that the backward pass of DeDA is similar to the grid sampling except the allowance of multiple flow-field grids. 
    % Basically, the proposed DeDA is a symmetric operation to the grid sampling operation, and is further generalized to allow accumulation of values from multiple flow-field grids.
    } 
    \label{fig:deda-gs}
\end{figure}
To allow back propagation for training networks with DeDA, the gradients with respect to $\mathbf{U}$ are derived using the chain rule as follows:
\vspace{-1ex}
\begin{equation}
\label{eq:deda-back}
    \dfrac{\partial\mathcal{L}}{\partial \mathbf{V}_{nm}^{c}}\dfrac{\partial\mathbf{V}_{nm}^{c}}{\partial\mathbf{U}_{ij}^{c}} = \sum_k^{N}\sum_n^{H'}\sum_m^{W'} \mathbf{A}_{nm}^{c}\mathcal{K}(\mathbf{G}_{ij}^x[k],n)\mathcal{K}(\mathbf{G}_{ij}^y[k],m),
    \vspace{-1ex}
\end{equation}
where $\mathbf{A}$ is the gradient tensor with respect to $\mathbf{V}$. 
We can see that the structure of Eq. \eqref{eq:deda-back} reduces to Eq. \eqref{eq:gs} 
by setting $N=1$, meaning that DeDA is a symmetric operation to grid sampling.
Note that both the forward and backward pass of DeDA transforms each channel $c$ in an identical way and thus without loss of generality, the feature map is denoted with spatial dimensions only for the rest of the paper.

% To guide the generation of flow-field grid coordinates and allow loss gradients flow back to corresponding network weights, we further derive the the gradients with respect to $\mathbf{G}^x$ as follows:
% \begin{equation}
% % \resizebox{1\columnwidth}{!}{
%      \dfrac{\partial\mathcal{L}}{\partial \mathbf{V}_{nm}^{c}}\dfrac{\partial\mathbf{V}_{nm}^{c}}{\mathbf{G}_{ij}^x} = \sum_k^{N}\sum_n^{H'}\sum_m^{W'} \mathbf{A}_{nm}^{c}\mathbf{U}_{ij}^{c}\mathcal{K}(\mathbf{G}_{ij}^y[k],m) t,
%      \label{eq:deda-back-coord}
% % }
% \end{equation}
% where the value of $t$ depends on the sampling kernel. 
% Taking bilinear sampling kernel as an example, where $\mathcal{K}(\mathbf{G}_{ij}^x[k],n)=\text{max}(0,1-|\mathbf{G}_{ij}^x[k]-n|)$, then we can describe $t$ in Eq.~\eqref{eq:deda-back-coord} as follows:
% \begin{equation}
%     t = \begin{cases}
%       0 & \text{if} ~~ |\mathbf{G}_{ij}^x[k]-n|\geqslant 1\\
%       1 & \text{if} ~~ \mathbf{G}_{ij}^x[k] \leqslant n \\
%      -1 & \text{if} ~~ \mathbf{G}_{ij}^x[k] > n,
%     \end{cases}   
% \end{equation}
% where sub-gradients are used to address the discontinuity in the sampling kernel function. 
% Similar derivation for $ \dfrac{\partial\mathcal{L}}{\partial \mathbf{V}_{nm}^{c}}\dfrac{\partial\mathbf{V}_{nm}^{c}}{\mathbf{G}_{ij}^y}$ can be obtained as well.

\subsection{DeDA-based Transformation Layer for Rim Parameterization}
\label{sec:rim}

In this section, we derive DeDA-based transformation and its convolution layers for rim parameterization.
As shown in Fig.~\ref{fig:lesion-grads}, a rim+ lesion can be characterized by a hyperintense rim at the lesion edge on QSM and differs from a rim- lesion in both image intensities and gradients at the edge. 
% be parameterized as follows:
% \begin{equation}
%     (x-a)^2 + (y-b)^2 = r^2,
%     \label{eq:hct}
% \end{equation}
% where $(a,b)$ and $r$ are parameters describing the center coordinates and the radius of the circle.
% The HCT uses Eq.~\eqref{eq:hct} to map each image pixel $(x,y)$ into a inverted right angled cone with its apex at $(x,y,0)$ embedded in a 3D accumulator space.
% To simplify the accumulator space, we follow the adaptive HCT \cite{illingworth1987adaptive} and parameterize a 2D accumulator space with $(a,b)$ only, in which we impose a mild constraint that all vectors normal to the circle edge should intersect at the circle center.
To account for both image intensities and gradients, the rim is parameterized as $\tan(\theta) = \dfrac{y-b}{x-a}$,
where $(a, b)$ are parameters of coordinates for the rim center in the accumulator space and $\theta$ represents the gradient direction at $(x,y)$ in the image space.
% In our application, the normal vector of each pixel $(x,y)$ can be obtained by local image gradients, leading to a $\theta$ representing the gradient direction.
As can be seen from the right panel of Fig. \ref{fig:lesion-grads}, mapping a single $(x,y,\theta)$ to the accumulator space produces a straight line, and thus coordinates of the rim center can be identified by the intersection of many of these lines.
% \begin{equation}
%     \tan(\theta) = \dfrac{y-b}{x-a},
%     % b = \tan(\theta)a+ (y-x\tan(\theta)),
%     \label{eq:s-hct}
% \end{equation}

\textbf{DeDA Transformation of the Rim}:
Given a source feature map $\mathbf{U} \in \mathbb{R}^{H \times W}$, the magnitude of image gradients can be obtained as follows $\mathbf{S} = \sqrt{\mathbf{U}_x\odot\mathbf{U}_x + \mathbf{U}_y\odot\mathbf{U}_y}$, where $\odot$ denotes the Hadamard product, $\mathbf{U}_x = \dfrac{\partial \mathbf{U}}{\partial x}$, and $\mathbf{U}_y = \dfrac{\partial \mathbf{U}}{\partial y}$.
The image gradient tensor $\mathbf{U}_x$ and $\mathbf{U}_y$ can be efficiently computed using convolution kernels such as the Sobel operator.
Normalized gradients can be obtained by $\hat{\mathbf{U}}_x = \dfrac{\mathbf{U}_x}{\mathbf{S}+\epsilon}$ and $\hat{\mathbf{U}}_y = \dfrac{\mathbf{U}_y}{\mathbf{S}+\epsilon}$, where $\epsilon$ is a small real value to avoid zero denominator.
The mesh grids of $\mathbf{U}$ are denoted as $\mathbf{M}_x$ (value range: $(0,H-1)$) and $\mathbf{M}_y$ (value range: $(0,W-1)$).
We can then generate a set of sampling grids as follows:
\begin{equation}
    \mathcal{G} = \{\mathbf{G}[k]=(\mathbf{G}^x[k], \mathbf{G}^y[k])~|~k \in \mathbb{Z}^+, 1 \leq k \leq N \},
\end{equation}
where $\mathbf{G}[k] \in \mathbb{R}^{2\times H \times W}$, $\mathbf{G}^x[k]=k\hat{\mathbf{U}}_x+\mathbf{M}_x$, $\mathbf{G}^y[k]=k\hat{\mathbf{U}}_y+\mathbf{M}_y$, and $N=\text{max}(H,W)$.
% Let $\mathcal{G}^{-}$ be the sampling grid set having gradients in the opposite direction, where  $\mathbf{G}^x[k]^{-}=-k\hat{\mathbf{U}}_x+\mathbf{M}_x$, $\mathbf{G}^y[k]^{-}=-k\hat{\mathbf{U}}_y+\mathbf{M}_y$.
Now the DeDA-based transformation of Rim (DA-TR) can be formulated as $\mathbf{V}_s = \mathcal{D}(\mathbf{S},\mathcal{G};\mathcal{K})$  and $\mathbf{V}_u = \mathcal{D}(\mathbf{U},\mathcal{G};\mathcal{K})$, where the integer sampling kernel is used.
It is worth noting that feature and gradient magnitude values are accumulated separately due to differences of image intensity and gradients between rim+ and rim- lesions (see Fig.~\ref{fig:lesion-grads}).
% To add symmetric information of rim to the accumulator space, an additional sampling grid set $\mathcal{G}^{-}$ is applied.


\begin{figure}[!t]
	\centering
	\vspace{-1ex}
        \includegraphics[width=1.0\columnwidth]{./da_rim_block.png}
	\vspace{-1ex}
        \caption{
            Schematic of the network layer for DA-TR.
            Conv denotes a convolutional layer, and each of these layers consists a $3\times3\times3$ or $1\times1\times1$ convolution, a batch normalization, and a ReLU activation.
        }
	\label{fig:da-rim}
\end{figure}
\textbf{Network Layer for DA-TR}:
To gain more representation ability and capture long-range contextual information, DA-TR is applied to both intermediate feature maps and original images. 
As can be seen from Fig.~\ref{fig:da-rim}, image patches of lesions are processed through a set of convolutional layers with each consisting of a $3\times3\times3$ or $1\times1\times1$ convolution, a batch normalization \cite{ioffe2015batch} and a ReLU activation function, followed by a DA-TR layer and a $1\times1\times1$ convolutional layer.
The first $1\times1\times1$ conv layer is used to fuse feature maps and original image patches for better feature embedding, and the second one is used to fuse DeDA transformed gradient magnitude maps $\mathbf{V}_s$ and feature maps $\mathbf{V}_u$. 
It is worth noting that only in-plane rims are observed, and thus the DA-TR is performed on the 2D feature map slices along the axial direction.

