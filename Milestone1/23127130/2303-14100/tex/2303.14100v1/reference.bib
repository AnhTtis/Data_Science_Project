% Limiting the number of authors in the references with IEEEtran 
@IEEEtranBSTCTL{IEEEexample:BSTcontrol,
CTLuse_forced_etal       = "yes",
CTLmax_names_forced_etal = "2",
CTLnames_show_etal       = "1",
CTLdash_repeated_names = "no"
}

@article{10.1126/science.abc2986,
  title={A universal system for digitization and automatic execution of the chemical synthesis literature},
  author={Mehr, S Hessam M and Craven, Matthew and Leonov, Artem I and Keenan, Graham and Cronin, Leroy},
  journal={Science},
  volume={370},
  number={6512},
  pages={101--108},
  year={2020},
  publisher={American Association for the Advancement of Science}
}

@article{10.48550/arXiv.2107.03374,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv:2107.03374},
  year={2021}
}

@inproceedings{pddlstream,
  title     = {{PDDLStream}: Integrating Symbolic Planners and Blackbox Samplers via Optimistic Adaptive Planning},
  author    = {Caelan Reed Garrett and Tom{\'{a}}s Lozano-P{\'{e}}rez and Leslie Pack Kaelbling},
  booktitle = {Proc. ICAPS Conf.},
  publisher = {{AAAI} Press},
  pages     = {440--448},
  year      = {2020}
}
@article{10.48550/arXiv.2212.09672,
  title={An Adaptive Robotics Framework for Chemistry Lab Automation},
  author={Yoshikawa, Naruki and Li, Andrew Zou and Darvish, Kourosh and Zhao, Yuchi and Xu, Haoping and Aspuru-Guzik, Alan and Garg, Animesh and Shkurti, Florian},
  journal={arXiv:2212.09672},
  year={2022}
}

@inproceedings{perry-2021-lighttag,
  title = "{L}ight{T}ag: Text Annotation Platform",
  author = "Perry, Tal",
  booktitle = "Proc. EMNLP Conf.",
  month = nov,
  year = "2021",
  pages = "20--27",
}

@article{10.48550/arXiv.2210.05359,
  title={Mind's Eye: Grounded Language Model Reasoning through Simulation},
  author={Liu, Ruibo and Wei, Jason and Gu, Shixiang Shane and Wu, Te-Yen and Vosoughi, Soroush and Cui, Claire and Zhou, Denny and Dai, Andrew M},
  journal={arXiv:2210.05359},
  year={2022}
}

@book{johansen-bartenderens,
  title={Bartenderens grundbog: historien, opskrifter, tips \& tricks},
  author={Johansen, H.B. and Rasmussen, T.L.},
  isbn={9788740601879},
  publisher={Turbine},
  year={2015}
}
@article{10.1021/ed069p66.1,
  title={Demonstrations with red cabbage indicator},
  author={Fortman, John J and Stubbs, Katherine M},
  journal={J. Chem. Educ.},
  volume={69},
  number={1},
  pages={66},
  year={1992},
  publisher={ACS Publications}
}

@article{manna1971toward,
  title={Toward automatic program synthesis},
  author={Manna, Zohar and Waldinger, Richard J},
  journal={Communications of the ACM},
  volume={14},
  number={3},
  pages={151--165},
  year={1971},
  publisher={ACM New York, NY, USA}
}
@inproceedings{le2022coderl,
title={Code{RL}: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning},
author={Hung Le and Yue Wang and Akhilesh Deepak Gotmare and Silvio Savarese and Steven Hoi},
booktitle={Adv. Neural. Inf. Process. Syst.},
year={2022}
}
@article{10.48550/arXiv.2302.08468,
  title={LEVER: Learning to Verify Language-to-Code Generation with Execution},
  author={Ni, Ansong and Iyer, Srini and Radev, Dragomir and Stoyanov, Ves and Yih, Wen-tau and Wang, Sida I and Lin, Xi Victoria},
  journal={arXiv:2302.08468},
  year={2023}
}

@misc{https://doi.org/10.5281/zenodo.3955107,
  doi = {10.5281/ZENODO.3955107},
  url = {https://zenodo.org/record/3955107},
  author = {Mehr,  Hessam and Craven,  Matthew and Leonov,  Artem and Keenan,  Graham and Cronin,  Leroy},
  title = {{Benchmarking results and the XDL XML schema.}},
  publisher = {Zenodo},
  year = {2020},
  copyright = {Creative Commons Attribution 4.0 International}
}
@article{park2023extensible,
  title={An extensible platform for enabling artificial intelligence guided design of catalysts and materials},
  author={Park, Nathaniel and Manica, Matteo and Born, Jannis and Hedrick, James and Erdmann, Tim and Zubarev, Dmitry and Mill, Nil and Arrechea, Pedro},
  year={2023},
  journal={ChemRxiv}
}
@article{liang2022code,
  title={Code as policies: Language model programs for embodied control},
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  journal={arXiv:2209.07753},
  year={2022}
}

@inproceedings{singh2022progprompt,
  title={ProgPrompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={IEEE Int. Conf. Robot. Autom.},
  ign-journal={arXiv:2209.11302},
  year={2023}
}

@article{huang2022inner,
  title={Inner monologue: Embodied reasoning through planning with language models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  journal={arXiv:2207.05608},
  year={2022}
}

@article{brohan2022can,
  title={{Do As I Can, Not As I Say}: Grounding Language in Robotic Affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and others},
  journal={arXiv:2204.01691},
  year={2022}
}
@inproceedings{xu2018neural,
  title={Neural task programming: Learning to generalize across hierarchical tasks},
  author={Xu, Danfei and Nair, Suraj and Zhu, Yuke and Gao, Julian and Garg, Animesh and Fei-Fei, Li and Savarese, Silvio},
  booktitle={IEEE Int. Conf. Robot. Autom.},
  year={2018},
}
@inproceedings{huang2019neural,
  title={{Neural Task Graphs: Generalizing to unseen tasks from a single video demonstration}},
  author={Huang, De-An and Nair, Suraj and Xu, Danfei and Zhu, Yuke and Garg, Animesh and Fei-Fei, Li and Savarese, Silvio and Niebles, Juan Carlos},
  booktitle={IEEE Comput. Vis. Pattern Recognit.},
  year={2019}
}
@article{schick2023toolformer,
  title={Toolformer: Language Models Can Teach Themselves to Use Tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={arXiv:2302.04761},
  year={2023}
}
@misc{zhang2022planning,
  title={Planning with Large Language Models for Code Generation},
  author={Zhang, Shun and Chen, Zhenfang and Shen, Yikang and Ding, Mingyu and Tenenbaum, Joshua B and Gan, Chuang},
  booktitle={NeurIPS 2022 Foundation Models for Decision Making Workshop}
}

@article{gulwani2017program,
  title={Program synthesis},
  author={Gulwani, Sumit and Polozov, Oleksandr and Singh, Rishabh and others},
  journal={Foundations and Trends{\textregistered} in Programming Languages},
  volume={4},
  number={1-2},
  pages={1--119},
  year={2017},
  publisher={Now Publishers, Inc.}
}
@article{li2022competition,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022},
  publisher={American Association for the Advancement of Science}
}
@article{wang2021codet5,
  title={{CodeT5}: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation},
  author={Wang, Yue and Wang, Weishi and Joty, Shafiq and Hoi, Steven CH},
  journal={arXiv:2109.00859},
  year={2021}
}

@inproceedings{devlin2018bert,
  title={{BERT: Pre-training of deep bidirectional transformers for language understanding}},
  author={Devlin, Jacob and Chang, Ming{-}Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle = {North American Chapter of the Association for Computational Linguistics},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Adv. Neural. Inf. Process. Syst.},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{thoppilan2022lamda,
  title={{LaMDA}: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv:2201.08239},
  year={2022}
}
@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv:2112.11446},
  year={2021}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv:2203.15556},
  year={2022}
}

@article{chowdhery2022palm,
  title={{PaLM}: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv:2204.02311},
  year={2022}
}
@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv:2205.01068},
  year={2022}
}
@article{black2022gpt,
  title={{GPT-NeoX-20B}: An open-source autoregressive language model},
  author={Black, Sid and Biderman, Stella and Hallahan, Eric and Anthony, Quentin and Gao, Leo and Golding, Laurence and He, Horace and Leahy, Connor and McDonell, Kyle and Phang, Jason and others},
  journal={arXiv:2204.06745},
  year={2022}
}
@article{mcclelland2020placing,
  title={Placing language in an integrated understanding system: Next steps toward human-level performance in neural language models},
  author={McClelland, James L and Hill, Felix and Rudolph, Maja and Baldridge, Jason and Sch{\"u}tze, Hinrich},
  journal={Proc. Natl. Acad. Sci. U.S.A.},
  volume={117},
  number={42},
  pages={25966--25974},
  year={2020},
  publisher={National Acad Sciences}
}

@article{lin2021truthfulqa,
  title={{TruthfulQA}: Measuring how models mimic human falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv:2109.07958},
  year={2021}
}
@article{petroni2020context,
  title={How context affects language models' factual predictions},
  author={Petroni, Fabio and Lewis, Patrick and Piktus, Aleksandra and Rockt{\"a}schel, Tim and Wu, Yuxiang and Miller, Alexander H and Riedel, Sebastian},
  journal={arXiv:2005.04611},
  year={2020}
}
@inproceedings{patel2022mapping,
title={Mapping Language Models to Grounded Conceptual Spaces},
author={Roma Patel and Ellie Pavlick},
booktitle={Int. Conf. Learn. Repr.},
year={2022}
}
@article{peng2023check,
  title = {Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback},
  author = {Peng, Baolin and Galley, Michel and He, Pengcheng and Cheng, Hao and Xie, Yujia and Hu, Yu and Huang, Qiuyuan and Liden, Lars and Yu, Zhou and Chen, Weizhu and Gao, Jianfeng},
  journal={arXiv:2302.12813},
  year = {2023}
}
@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv:2206.07682},
  year={2022}
}
@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={arXiv:2205.11916},
  year={2022}
}
@article{zhou2022large,
  title={Large language models are human-level prompt engineers},
  author={Zhou, Yongchao and Muresanu, Andrei Ioan and Han, Ziwen and Paster, Keiran and Pitis, Silviu and Chan, Harris and Ba, Jimmy},
  journal={arXiv:2211.01910},
  year={2022}
}
@inproceedings{wei2022finetuned,
  title={Finetuned Language Models are Zero-Shot Learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  booktitle={Int. Conf. Learn. Repr.},
  year={2022}
}
@article{de2019synthetic,
  title={Synthetic organic chemistry driven by artificial intelligence},
  author={de Almeida, A Filipa and Moreira, Rui and Rodrigues, Tiago},
  journal={Nat. Rev. Chem.},
  volume={3},
  number={10},
  pages={589--604},
  year={2019},
  publisher={Nature Publishing Group UK London}
}
@article{schneider2016big,
  title={Big data from pharmaceutical patents: a computational analysis of medicinal chemistsâ€™ bread and butter},
  author={Schneider, Nadine and Lowe, Daniel M and Sayle, Roger A and Tarselli, Michael A and Landrum, Gregory A},
  journal={J. Med. Chem.},
  volume={59},
  number={9},
  pages={4385--4402},
  year={2016},
  publisher={ACS Publications}
}
@phdthesis{lowe2012extraction,
  title={Extraction of chemical structures and reactions from the literature},
  author={Lowe, Daniel Mark},
  year={2012},
  school={University of Cambridge}
}
@article{hammer2021chemputation,
  title={Chemputation and the standardization of chemical informatics},
  author={Hammer, Alexander JS and Leonov, Artem I and Bell, Nicola L and Cronin, Leroy},
  journal={JACS Au},
  volume={1},
  number={10},
  pages={1572--1587},
  year={2021},
  publisher={ACS Publications}
}
@article{seifrid2022autonomous,
  title={Autonomous chemical experiments: Challenges and perspectives on establishing a self-driving lab},
  author={Seifrid, Martin and Pollice, Robert and Aguilar-Granda, Andr{\'e}s and Morgan Chan, Zamyla and Hotta, Kazuhiro and Ser, Cher Tian and Vestfrid, Jenya and Wu, Tony C and Aspuru-Guzik, Al{\'a}n},
  journal={Acc. Chem. Res.},
  year={2022},
}
@phdthesis{winograd1971procedures,
  title={Procedures as a representation for data in a computer program for understanding natural language},
  author={Winograd, Terry},
  year={1971},
  school={Mass. Inst. Technol.}
}
@article{tellex2020robots,
  title={Robots that use language},
  author={Tellex, Stefanie and Gopalan, Nakul and Kress-Gazit, Hadas and Matuszek, Cynthia},
  journal={Annu. Rev. Control Robot. Auton. Syst.},
  volume={3},
  pages={25--55},
  year={2020},
  publisher={Annual Reviews}
}

@article{Vaucher2020,
  doi = {10.1038/s41467-020-17266-6},
  year = {2020},
  publisher = {Springer Science and Business Media {LLC}},
  author = {Alain C. Vaucher and Federico Zipoli and Joppe Geluykens and Vishnu H. Nair and Philippe Schwaller and Teodoro Laino},
  title = {Automated extraction of chemical synthesis actions from experimental procedures},
  journal = {Nat. Commun.}
}

@article{xu2019regression,
  title={Regression planning networks},
  author={Xu, Danfei and Mart{\'\i}n-Mart{\'\i}n, Roberto and Huang, De-An and Zhu, Yuke and Savarese, Silvio and Fei-Fei, Li F},
  journal={Adv. Neural. Inf. Process. Syst.},
  volume={32},
  year={2019}
}

@article{eysenbach2019search,
  title={Search on the replay buffer: Bridging planning and reinforcement learning},
  author={Eysenbach, Ben and Salakhutdinov, Russ R and Levine, Sergey},
  journal={Adv. Neural. Inf. Process. Syst.},
  volume={32},
  year={2019}
}

@article{mirchandani2021ella,
  title={{ELLA}: Exploration through learned language abstraction},
  author={Mirchandani, Suvir and Karamcheti, Siddharth and Sadigh, Dorsa},
  journal={Adv. Neural. Inf. Process. Syst.},
  year={2021}
}

@article{sharma2021skill,
  title={Skill induction and planning with latent language},
  author={Sharma, Pratyusha and Torralba, Antonio and Andreas, Jacob},
  journal={arXiv:2110.01517},
  year={2021}
}

@article{shah2021value,
  title={Value function spaces: Skill-centric state abstractions for long-horizon reasoning},
  author={Shah, Dhruv and Xu, Peng and Lu, Yao and Xiao, Ted and Toshev, Alexander and Levine, Sergey and Ichter, Brian},
  journal={arXiv:2111.03189},
  year={2021}
}

@article{baier2009heuristic,
  title={A heuristic search approach to planning with temporally extended preferences},
  author={Baier, Jorge A and Bacchus, Fahiem and McIlraith, Sheila A},
  journal={Artif. Intell.},
  year={2009},
}

@article{gu2021domain,
  title={Domain-specific language model pretraining for biomedical natural language processing},
  author={Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
  journal={ACM Trans. Comput. Healthcare},
  volume={3},
  number={1},
  pages={1--23},
  year={2021},
  publisher={ACM New York, NY}
}
@article{mishra2021cross,
  title={Cross-task generalization via natural language crowdsourcing instructions},
  author={Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Hajishirzi, Hannaneh},
  journal={arXiv:2104.08773},
  year={2021}
}
@inproceedings{bannour-2021-evaluating,
    title = "Evaluating the carbon footprint of {NLP} methods: a survey and analysis of existing tools",
    author = "Bannour, Nesrine  and
      Ghannay, Sahar  and
      N{\'e}v{\'e}ol, Aur{\'e}lie  and
      Ligozat, Anne-Laure",
    booktitle = "SustaiNLP",
    month = nov,
    year = "2021",
    pages = "11--21",
}
@inproceedings{kaelbling2011hierarchical,
  title={Hierarchical task and motion planning in the now},
  author={Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  booktitle={IEEE Inter. Conf. Robot. Autom.},
  pages={1470--1477},
  year={2011},
  organization={IEEE}
}
@inproceedings{wang2021want,
    title = "Want To Reduce Labeling Cost? {GPT}-3 Can Help",
    author = "Wang, Shuohang and Liu, Yang and Xu, Yichong  and Zhu, Chenguang and Zeng, Michael",
    booktitle = "Proc. EMNLP Conf.",
    year = "2021",
    pages = "4195--4205",
}