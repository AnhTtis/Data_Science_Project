\begin{figure*}
\centering
    \includegraphics[width=\textwidth]{figure/vision_new_fig1.pdf}
    %%\vskip-5pt
    \caption{Visual comparisons on images with fine details on Urban100 test dataset (\textbf{Zoom in for more details}).}
    \label{fig:visual_results}
    %%\vskip-10pt
\end{figure*}

\newcommand{\red}[1] {\textcolor[rgb]{1.0,0.0,0.0}{{#1}}}
%\linespread{1.1}
% \setlength\tabcolsep{2pt}
\begin{table*}[htb]
  \caption{Quantitative comparison with some representation SR approaches on five widely used benchmark datasets. The best and second results are highlighted in \textcolor{red}{red} and \textcolor{blue}{blue}.}
  \label{tab:main_results}
  %\centering
  \resizebox{\textwidth}{!}{
  \begin{tabular}{cllcccccc}
    \toprule
    \multirow{2}{*}{Scale} & \multirow{2}{*}{Method} &\multirow{2}{*}{Avenue}     &\multirow{2}{*}{Params} & Set5 & Set14 &B100 & Urban100 & Manga109 \\
    %\cmidrule(r){3-7}
       &  &  &    & PSNR/SSIM & PSNR/SSIM& PSNR/SSIM & PSNR/SSIM & PSNR/SSIM \\
    \midrule
    
  \multirow{11}{*}{$\times2$}
%     & SRCNN     & 57K     & 36.66/0.9542 & 32.45/0.9067 & 31.36/0.8879 & 29.50/0.8946 & 35.60/0.9663 \\
% 	&	FSRCNN & 13K & 37.00/0.9558 &32.63/0.9088 &31.53/0.8920 &29.88/0.9020 &36.67/0.9710 \\
	&	VDSR \cite{VDSR} & CVPR'16 & 666K    & 37.53/0.9587 & 33.03/0.9124 & 31.90/0.8960 & 30.76/0.9140 & 37.22/0.9750 \\
% 	&	DRCN      & 1,774K  & 37.63/0.9588 & 33.04/0.9118 & 31.85/0.8942 & 30.75/0.9133 & 37.55/0.9732 \\
	&	LapSRN \cite{LapSRN} & CVPR'17  & 251K    & 37.52/0.9591 & 32.99/0.9124 & 31.80/0.8952 & 30.41/0.9103 & 37.27/0.9740 \\
% 	&	DRRN      & 298K    & 37.74/0.9591 & 33.23/0.9136 & 32.05/0.8973 & 31.23/0.9188 & 37.88/0.9749 \\
% 	&	MemNet    & 678K    & 37.78/0.9597 & 33.28/0.9142 & 32.08/0.8978 & 31.31/0.9195 & 37.72/0.9740 \\
% 	&   CARN-M & 412.00 &   37.53/0.9583 & 33.26/0.9141 & 31.92/0.8960 & 31.23/0.9193 & 35.62/0.9420 \\
	&	SRResNet \cite{SRGAN}& CVPR'17  & 1,370K & 38.05/0.9607  & 33.64/0.9178  & 32.22/0.9002  & 32.23/0.9295  & 38.05/0.9607 \\
	&	CARN  \cite{CARN} & ECCV'18 & 1,592K  & 37.76/0.9590 & 33.52/0.9166 & 32.09/0.8978 & 31.92/0.9256 & 38.36/0.9765 \\
	&	IMDN \cite{IMDN} & ACM MM'19  & 694K    & 38.00/0.9605 & 33.63/0.9177 & 32.19/0.8996 & 32.17/0.9283 &  38.88/0.9774 \\
% 	&   LAPAR-C   & 87K     & 37.65/0.9593 & 33.20/0.9141 & 31.95/0.8969 & 31.10/0.9178 & 37.75/0.9752 \\
	&   LAPAR-A \cite{LAPAR}&  NeurIPS'20  & 548K    & 38.01/0.9605  & 33.62/0.9183 & 32.19/0.8999 & 32.10/0.9283 & 38.67/0.9772\\
	& SMSR \cite{SMSR} & CVPR'21 & 985K & 38.00/0.9601  & 33.64/0.9179  & 32.17/0.8990  & 32.19/0.9284  & 38.76/0.9771 \\
	& ECBSR  & ACM MM'21 & 596K & 37.90/0.9615 & 33.34/0.9178 & 32.10/0.9018 & 31.71/0.9250 & 35.79/0.9430 \\
% 	&	PAN \cite{PAN} &  ECCVW`2020    & 272K    & 38.00/0.9605 & 33.59/0.9181 & 32.18/0.8997 & 32.01/0.9273 & 38.70/0.9773  \\ 
	& SwinIR-light \cite{SwinIR} &ICCV'21 &  878K & 38.14/0.9611   &\textcolor{blue}{33.86}/0.9206 &  \textcolor{blue}{32.31}/\textcolor{blue}{0.9012}  & \textcolor{red}{32.76}/\textcolor{blue}{0.9340} & \textcolor{blue}{39.12}/\textcolor{blue}{0.9783}\\
	&	FDIWN \cite{FDIWN} &AAAI'22& 629K & 38.07/0.9608 &33.75/0.9201 &32.23/0.9003& 32.40/0.9305 & 38.85/0.9774\\
	& ShuffleMixer \cite{shufflemixer}&NeurIPS'22 & 394K& 38.01/0.9606& 33.63/0.9180 &32.17/0.8995& 31.89/0.9257 & 38.83/0.9774 \\
	\cmidrule(lr){2-9}

		&   \textbf{TCSR-B} & 2022 & 628K  & \textcolor{blue}{38.14}/\textcolor{blue}{0.9611} &  33.83/\textcolor{blue}{0.9209} & 32.28/0.9010 & \textcolor{blue}{32.55}/0.9327 & 39.11/0.9780	 \\
		&   \textbf{TCSR-L}& 2022 & 881K &  \red{38.19}/\red{0.9613}  & \red{33.94}/\red{0.9218} & 	 \red{32.33}/\red{0.9015} & 	 \red{32.76}/\red{0.9345} & 	 \red{39.28}/\red{0.9782}\\
     \midrule

	  \multirow{11}{*}{$\times3$} 
% 	&	SRCNN     & 57K     & 32.75/0.9090 & 29.30/0.8215 & 28.41/0.7863 & 26.24/0.7989 & 30.48/0.9117 \\
% 	&	FSRCNN    & 13K     & 33.18/0.9140 & 29.37/0.8240 & 28.53/0.7910 & 26.43/0.8080 & 31.10/0.9210 \\
	&	VDSR \cite{VDSR}   & CVPR'16 & 666K    & 33.66/0.9213 & 29.77/0.8314 & 28.82/0.7976 & 27.14/0.8279 & 32.01/0.9340 \\
% 	&	DRCN      & 1,774K  & 33.82/0.9226 & 29.76/0.8311 & 28.80/0.7963 & 27.15/0.8276 & 32.24/0.9343 \\
% 	&	DRRN      & 298K    & 34.03/0.9244 & 29.96/0.8349 & 28.95/0.8004 & 27.53/0.8378 & 32.71/0.9379 \\
	&	LapSRN \cite{LapSRN}  & CVPR'17 & 502K    & 33.81/0.9220 & 29.79/0.8325 & 28.82/0.7980 & 27.07/0.8275 & 32.21/0.9350 \\
% 	&	MemNet    & 678K    & 34.09/0.9248 & 30.00/0.8350 & 28.96/0.8001 & 27.56/0.8376 & 32.51/0.9369 \\
	&	SRResNet \cite{SRGAN}  & CVPR'17 & 1,554K  & 34.41/0.9274 & 30.36/0.8427 & 29.11/0.8055 & 28.20/0.8535   & 33.54/0.9448 \\
	&	CARN \cite{CARN}      & ECCV'18& 1,592K  & 34.29/0.9255 & 30.29/0.8407 & 29.06/0.8034 & 28.06/0.8493 & 33.50/0.9440 \\
%   & EDSR-baseline & 1,555K &  34.37/0.9270 & 30.28/0.8417 & 29.09/0.8052 & 28.15/0.8527 & 33.45/0.9439 \\
	&	IMDN \cite{IMDN}     &ACM MM'19  & 703K    & 34.36/0.9270 & 30.32/0.8417 & 29.09/0.8046 & 28.17/0.8519 & 33.61/0.9445 \\
% 	&   LAPAR-C   & 99K     & 33.91/0.9235 & 30.02/0.8358 & 28.90/0.7998 & 27.42/0.8355 & 32.54/0.9373 \\
%     & LAPAR-B & 276K &  34.20/0.9256 & 30.17/0.8387 & 29.03/0.8032&  27.85/0.8459 & 33.15/0.9417 \\
	&   LAPAR-A \cite{LAPAR}  &NeurlIPS'20& 594K    & 34.36/0.9267 & 30.34/0.8421 & 29.11/0.8054 & 28.15/0.8523 & 33.51/0.9441 \\
% 	&	PAN \cite{PAN}     & 2020 & 261K    & 34.40/0.9271 & 30.36/0.8423 & 29.11/0.8050 & 28.11/0.8511 & 33.61/0.9448 \\ 
    & SMSR \cite{SMSR}  &CVPR'21 &  993K & 34.40/0.9270 & 30.33/0.8412&  29.10/0.8050 & 28.25/0.8536&  33.68/0.9445 \\
	&SwinIR-light \cite{SwinIR}  &ICCV'21 & 886K & \textcolor{blue}{34.62}/\textcolor{blue}{0.9289} & 30.54/\textcolor{blue}{0.8463} & 29.20/\textcolor{blue}{0.8082} & \textcolor{blue}{28.66}/\textcolor{blue}{0.8624} & 33.98/0.9478 \\
	& FDIWN \cite{FDIWN}     &AAAI'22 & 645K & 34.52/0.9281 &  30.42/0.8438 & 29.14/0.8065 & 28.36/0.8567&  33.77/0.9456 \\
	& ShuffleMixer \cite{shufflemixer}  & NeurIPS'22&  415K &  34.40/0.9272 & 30.37/0.8423 & 29.12/0.8051 & 28.08/0.8498 & 33.69/0.9448 \\

	\cmidrule(lr){2-9}
	
   &\textbf{TCSR-B} &2022 &  589K & 34.56/0.9285 & \textcolor{blue}{30.55}/0.8463 & \textcolor{blue}{29.22}/0.8081 & 28.58/0.8610 & \textcolor{blue}{34.06}/\textcolor{blue}{0.9479} \\
   & \textbf{TCSR-L} & 2022& 1,066K  	 & \red{34.72}/\red{0.9294}		 & \red{30.61}/\red{0.8474}		 & \red{29.27}/\red{0.8093}		 & \red{28.75}/\red{0.8648}	 & \red{34.32}/\red{0.9491}	 \\
    \midrule

\multirow{11}{*}{$\times4$} 
% 	&	SRCNN           & 57K   & 30.48/0.8628 & 27.49/0.7503 & 26.90/0.7101 & 24.52/0.7221 & 27.66/0.8505 \\
% 	&	FSRCNN          & 12K   & 30.71/0.8657 & 27.59/0.7535 & 26.98/0.7105 & 24.62/0.7280 & 27.90/0.8517 \\
	&	VDSR \cite{VDSR}   &CVPR'16  & 665K       & 31.35/0.8838 & 28.01/0.7674 & 27.29/0.7251 & 25.18/0.7524 & 28.83/0.8809 \\
% 	&	DRCN       & 1,774K     & 31.53/0.8854 & 28.02/0.7670 & 27.23/0.7233 & 25.14/0.7510 & 28.98/0.8816 \\
% 	&	DRRN            & 297K  & 31.68/0.8888 & 28.21/0.7720 & 27.38/0.7284 & 25.44/0.7638 & 29.46/0.8960 \\
    &	LapSRN \cite{LapSRN} &CVPR'17 & 813K       & 31.54/0.8850 & 29.19/0.7720 & 27.32/0.7280 & 25.21/0.7560 & 29.09/0.8845 \\
    % &	MemNet     & 677K       & 31.74/0.8893 & 28.26/0.7723 & 27.40/0.7281 & 25.50/0.7630 & 29.42/0.8942 \\
    % &   CARN-M&  412K           & 31.92/0.8903 & 28.42/0.7762 & 27.44/0.7304 & 25.62/0.7694  & 25.62/0.7694\\
    &	SRResNet \cite{SRGAN} & CVPR'17 & 1,518K     & 32.17/0.8951 & 28.61/0.7823 & 27.59/0.7365 & 26.12/0.7871 & 30.48/0.9087  \\
    &	CARN \cite{CARN} &ECCV'18& 1,592K     & 32.13/0.8937 & 28.60/0.7806 & 27.58/0.7349 & 26.07/0.7837 & 30.47/0.9084 \\
    % & EDSR-baseline  & 1,518K & 32.09/0.8938 & 28.58/0.7813 & 27.57/0.7357&  26.04/0.7849 & 30.35/0.9067 \\
    &	IMDN \cite{IMDN} &ACM MM'19 & 715K       & 32.21/0.8948 & 28.58/0.7811 & 27.56/0.7353 & 26.04/0.7838 & 30.45/0.9075 \\
    & SRFBN-S \cite{SRFBN} &CVPR'19&   483K & 31.98/0.8923 & 28.45/0.7779 & 27.44/0.7313 & 25.71/0.7719 & 29.91/0.9008 \\
	&   LAPAR-A \cite{LAPAR} &NeurIPS'20  & 659K       & 32.15/0.8944 &28.61/0.7818 &27.61/0.7366 &26.14/0.7871 &30.42/0.9074 \\
%     &   LAPAR-B      &  313K & 31.94/0.8917 & 28.46/0.7784 & 27.52/0.7335 & 25.85/0.7772 &  30.03/0.9025 \\
% 	&   LAPAR-C         & 115K  & 31.72/0.8884 & 28.31/0.7740 & 27.40/0.7292 & 25.49/0.7651 & 29.50/0.8951 \\
% 	&	PAN \cite{PAN}  & 2020  & 272K  & 32.13/0.8948 & 28.61/0.7822 & 27.59/0.7363 & 26.11/0.7854 & 30.51/0.9095 \\ 
	& SMSR \cite{SMSR} &CVPR'21 & 1,006K & 32.12/0.8932 & 28.55/0.7808 & 27.55/0.7351 & 26.11/0.7868 & 30.54/0.9085 \\
	& ECBSR \cite{ECBSR}  &ACM MM'21 &603K & 31.92/0.8946& 28.34/0.7817 &27.48/0.7393 &25.81/0.7773& 30.15/0.8315 \\
	& SwinIR-light \cite{SwinIR} &ICCV'21  &844K & \textcolor{blue}{32.44}/0.8976 &  28.77/0.7858 &  27.69/0.7406  & 26.47/0.7980  & 30.92/0.9151\\
    & FDIWN \cite{FDIWN}  &AAAI'22 & 664K & 32.23/0.8955& 28.66/0.7829 & 27.62/0.7380 & 26.28/0.7919 & 30.63/0.9098\\
    & ShuffleMixer \cite{shufflemixer} &NeurIPS'22  & 411K & 32.21/0.8953 &28.66/0.7827 &27.61/0.7366& 26.08/0.7835 &30.65/0.9093 \\
	\cmidrule(lr){2-9}
    % & \textbf{TCSR-T} & 509K & 32.30/0.8957	 & 28.70/0.7838 &	27.62/0.7379	 & 26.14/0.7870 & 	30.55/0.9105 \\
    & \textbf{TCSR-B}  &2022 & 682K &  32.43/\textcolor{blue}{0.8977} & \textcolor{blue}{28.84}/\textcolor{blue}{0.7871} & \textcolor{blue}{27.72}/\textcolor{blue}{0.7412} & \textcolor{blue}{26.51}/\textcolor{blue}{0.7994} & \textcolor{blue}{31.01}/\textcolor{blue}{0.9153} \\
     & \textbf{TCSR-L}  &2022 & 1,030K & \red{32.55}/\red{0.8992} & \red{28.89}/\red{0.7886} & \red{27.75}/\red{0.7423} & 	\red{26.67}/\red{0.8039}	 & \red{31.17}/\red{0.9170}\\
\bottomrule
 \end{tabular}}
\end{table*}


\section{Experiments}

\subsection{Experiment Setup}
We take 800 images from DIV2K \cite{DIV2K} and 2650 images from Flickr2K for training. Datasets for testing include Set5 \cite{Set5}, Set14 \cite{Set14}, B100 \cite{B100}, Urban100 \cite{Urban100}, and Manga109 \cite{Manga109} with the up-scaling factor 2, 3, and 4. We crop the image patches with the fixed size of $64\times64$ and set the batch size to 32 for training. The optimizer is ADAM \cite{ADAM} with the settings of $\beta_1$ = 0.9, $\beta_2$ = 0.999. 

We compare the proposed TCSR with representative efficient SR models, including  VDSR \cite{VDSR}, LapSRN \cite{LapSRN}, DRRN \cite{DRRN}, CARN \cite{CARN}, IMDN \cite{IMDN}, LAPAR \cite{LAPAR}, SMSR \cite{SMSR}, ECBSR \cite{ECBSR}, FDIWN \cite{FDIWN}, and ShuffleMixer \cite{shufflemixer} on $\times4$ up-scaling tasks. For comparison, we measure PSNR, and SSIM \cite{SSIM} on the Y channel of transformed YCbCr space.


\subsection{Main Results}
\textbf{Quantitative Evaluation.}
Results of different SR models on five test datasets with scale 2, 3, and 4 are reported in \cref{tab:main_results}. In addition to PSNR/SSIM, we also report the number of parameters. One can find that our base model TCSR-B with 16 NAT blocks outperforms all CNN-based models and obtains comparable performance to SwinIR-light. When we take deeper architectures, our TCSR-L with 32 NAT blocks achieves new SOTA results on all test datasets. The promising performance demonstrates the effectiveness of the proposed TCSR, which contains both local feature aggregation and large receptive fields.
\begin{figure}[htb]
\centering
    \includegraphics[width=0.475\textwidth]{figure/vision_new_detail.pdf}
    %\vskip-5pt
    \caption{Visual Comparisons (\textbf{Zoom in for more details}).}
    \label{fig:example_patch}
    %\vskip-10pt
\end{figure}

\textbf{Qualitative Evaluation.}
Several visual results of VDSR \cite{VDSR}, CARN \cite{CARN}, IMDN \cite{IMDN}, SwinIR-light \cite{SwinIR}, and the proposed TCSR on $\times4$ up-scaling task are shown in \cref{fig:visual_results}. One can limpidly see that the proposed TCSR-L can recover the main structures with clear and accurate textures. Here we take the $img_092$ in Urban100 as the example, results of some detail patches are shown in \cref{fig:example_patch}. Compared to the  One can find that our TCSR-L obtains clear and accurate edges while some other methods cannot. 

\subsection{Ablation and Analysis}


\begin{figure}
\centering
%%\vskip-5pt
    \includegraphics[width=0.495\textwidth]{figure/LAM_EFFN.pdf}
    \caption{LAM \cite{LAM} comparison between the TCSR with or without the EFFN.  \label{fig:lam}}

\end{figure}


%\textbf{Basic NAT Block.}
In this paper, our core contributions are to propose the sliding window-based self-attention mechanism NA and a enhance feed-forward network (EFFN). NA decouples the number of model parameters and feature aggregation, which can effectively build the long-range relation. The sliding window-based NA combines the self-attention mechanism with the inductive bias of the convolution. In addition, the proposed EFFN involve the local feature aggregation and advanced feature enhancement is obtained.

In this section, we present detailed ablations to better understand the effectiveness of these different components.


% \begin{figure}
% \centering
%     \includegraphics[width=0.495\textwidth]{figure/figure.pdf}
%     %%\vskip-5pt
%     \caption{Ablation on the kernel size. Results of the tiny TCSR with different kernel sizes on B100 with scale 4.}
%     \label{fig:ablation_kernel_size}
%     %%\vskip-10pt
% \end{figure}
\begin{table}[htb]
\centering
    \caption{Ablation on the kernel size. Results of the tiny TCSR with different kernel sizes on B100 for scale 4.}
    \label{fig:ablation_kernel_size}
%%\vskip-5pt
  \resizebox{0.48\textwidth}{!}{
  \begin{tabular}{ccccccc}
    \toprule
    Kernel Size & 3 & 5 & 7 & 9 & 11 & 13 \\
    \midrule
    PSNR (dB) & 27.52 & 27.56& 27.58&  27.61 & 27.62 & 27.66\\ 
\bottomrule
 \end{tabular}}
 %%\vskip-5pt
\end{table}

\textbf{Kernel Size.}
In this study, we use a tiny TCSR model, which contains only 8 NAT blocks, as the benchmark. Compared to conventional convolutions, the proposed TCSR is scalable and flexible in its ability to exploit large kernel sizes. We train the tiny TCSR model with different kernel sizes, and the results are summarized in \cref{fig:ablation_kernel_size}. Notably, we observe that performance improves as the kernel size increases, indicating the scalability and flexibility of TCSR for working with different kernel sizes. Specifically, the tiny TCSR model with kernel size 9 achieves comparable performance to well-designed CNN-based methods such as LAPAR\cite{LAPAR}, shufflemixer\cite{shufflemixer}, and FDIWN\cite{FDIWN}.
%\setlength{\tabcolsep}{1.50pt}


\begin{figure*}[tb]
\centering
\begin{minipage}[ht]{0.45\textwidth}
\centering
    \includegraphics[width=\textwidth]{figure/TCSR_kernel_shift.png}
    \caption{Results of the proposed TCSR with or without spatial-shift operation against different kernel sizes on Set14 for scale 4.}
    \label{fig:effn_kernel}
\end{minipage}
\begin{minipage}[ht]{0.45\textwidth}
\centering
    \includegraphics[width=\textwidth]{figure/TCSR_blocks_shift.png}
    \caption{Results of the proposed TCSR with or without spatial-shift operation against different model capacities on Set14 for scale 4.}
    \label{fig:effn_model}
\end{minipage}
\end{figure*}

\begin{table*}[htb]
\centering
  \caption{Results of SwinIR-light with or without spatial-shift operation.}
  \label{tab:swinir_spatial_shift}
%\vskip-5pt
  \resizebox{0.8\textwidth}{!}{
  \begin{tabular}{clccccc}
    \toprule
    \multirow{2}{*}{Scale} &\multirow{2}{*}{EFFN} & Set5 & Set14 &B100 & Urban100 & Manga109 \\
    %\cmidrule(r){3-7}
        &      & PSNR/SSIM & PSNR/SSIM& PSNR/SSIM& PSNR/SSIM& PSNR/SSIM \\
    \midrule
\multirow{2}{*}{$\times4$} 

	& w/o & 32.44/0.8976 &  28.77/0.7858 &  27.69/0.7406  & 26.47/0.7980  & 30.92/0.9151 \\
    & w & 32.45/0.8977 &  28.82/0.7869 &  27.71/0.7410  & 26.53/0.8002  & 30.97/0.9157 \\

\bottomrule
 \end{tabular}}
 %\vskip-5pt
\end{table*}

\begin{figure}
\centering
    \includegraphics[width=0.495\textwidth]{figure/SwinIR_EFFN_LAM.pdf}
    %%\vskip-5pt
    \caption{LAM \cite{LAM} comparison. (a) The ground truth of the reference image. (b) Activated map of the SwinIR-light. (C) Activated map of the SwinIR-light with the proposed EFFN.}
    \label{fig:lam_swinir_effn}
    %%\vskip-10pt
\end{figure}

\textbf{Enhanced Feed Forward Network.} The FFN module contains a basic MLP, which captures pixel-wise interactions but lacks feature aggregation across pixels. To address this limitation, we incorporate a spatial-shift operation to enable local feature aggregation within the FFN module and propose the EFFN module.

We evaluate the performance of our proposed TCSR with and without the EFFN module across different kernel sizes and model sizes. The results are presented in \cref{fig:effn_kernel} and \cref{fig:effn_model}, respectively. As shown in \cref{fig:effn_kernel}, our proposed EFFN module consistently outperforms the models without EFFN across all kernel sizes. This demonstrates the importance of local feature aggregation within the FFN module for enhancing feature representations. Specifically, we observe that when the kernel size is 7, the TCSR model with EFFN outperforms the TCSR model with kernel size 9 but without EFFN. This reveals that the spatial-shift operation can effectively extend the receptive fields by leveraging the NA module output for feature aggregation. Additionally, we take LAM \cite{LAM} to analyze the receptive fields, shown in \cref{fig:lam}. There are more activated pixels around the target region, which demonstrates that the proposed EFFN can further improve the long-range relation modeling as well.

Further ablations on the performance of our proposed EFFN module across different model sizes are presented in \cref{fig:effn_model}. The results demonstrate that the EFFN module is scalable to model capacity. Notably, even the smallest TCSR model with 4 NAT blocks and kernel size 11 achieves comparable performance to many existing CNN-based models, while the TCSR model with 8 NAT blocks outperforms them. This indicates the potential of large receptive fields in the SISR task.


Moreover, our proposed EFFN module is generic and can be integrated into other Transformer-based SR models. Specifically, we replace the original FFN in SwinIR-light with our proposed EFFN module, which is trained using the same settings as the original SwinIR-light \cite{SwinIR}. The results in \cref{tab:swinir_spatial_shift} show that SwinIR-light with the EFFN module outperforms the original SwinIR-light on all five test datasets. This further highlights the effectiveness of our proposed EFFN module for local feature aggregation and extended long-range modeling. In addition, the visualization of receptive fields in \cref{fig:lam_swinir_effn} reveals that our EFFN module yields larger activated regions than the original SwinIR-light, demonstrating its efficacy in enhancing feature representations.

\paragraph{Inference Comparison.}  More comparisons between SwinIR-light and TCSR on the computational cost and inference speed are presented in \ref{tab:inference}. The latency is tested on a RTX3090 GPU. One can find that even SRResNet is the most complexity but the inference speed is faster than SwinIR-light and TCSRs. It is reasonable that the most widely utilized convolutional operation is optimized. Compared to the SwinIR-light, the prposed TCSR-B has the similar complexity while the SwinIR-light brings near 400\% more
time consuming. Because there are much time-consuming image shift operations in SwinIR.


%\textbf{Model Capacity.}


\subsection{Discussion}
In this section, we provide quantitative and qualitative comparisons and conduct thorough ablations to demonstrate the effectiveness of the proposed TCSR. As previously mentioned, TCSR can scale to larger kernel sizes while maintaining a lightweight model size, resulting in significant improvements in both subjective and objective results. Additionally, our EFFN further enhances performance across different kernel sizes and model sizes.  We observe that performance improves as the kernel size increases, indicating the scalability and flexibility of TCSR for working with different kernel sizes. Furthermore, we perform an ablation study to investigate the effect of the EFFN in TCSR. Results of the ablation studies indicate that the proposed EFFN significantly improves the performance of benchmark SwinIR-light and the proposed TCSR, verifying its ability to enable more effective local feature aggregation and extend long-range modeling. The implementation of the proposed TCSR and its model weights are available on our project page for reproducibility and further research.

\section{Limitation}
In this paper, we attempt to exploit the large kernel design in lightweight SISR and provide a scalable TCSR architecture. However, the computational cost of the TCSR is relatively high, as shown in \cref{tab:inference}. We believe that well-designed architectures for lightweight models are essential to achieve an advanced trade-off between effectiveness and efficiency. Although optimizing the architecture is beyond the scope of this paper, we are currently working on developing more efficient ways to exploit the large receptive fields. The proposed TCSR architecture is a general approach that can flexibly model large kernels. Despite its current application to the lightweight SISR task, we believe that it can be extended to address other image restoration tasks and be scaled to large models for future research.




\begin{table}[htb]
  \caption{Computational comparisons.}
  %\vskip-5pt
  \label{tab:inference}
  %\centering
  \resizebox{0.475\textwidth}{!}{
  \begin{tabular}{clccccc}
    \toprule
    \multirow{2}{*}{Scale} &\multirow{2}{*}{Method} & Params & PSNR & \#FLOPs & Latency \\
    %\cmidrule(r){3-7}
        &     &(K) & (dB) & (G) & (ms) \\
    \midrule
\multirow{5}{*}{$\times4$} 
    &IMDN           &   715     & 28.97 &   40 & 5 \\
    &TCSR-B         &   880     & 29.30 &   52 & 52 \\
	&SwinIR-light   &   910     & 29.26 &   49 & 297 \\
    &TCSR-L         &   1030    & 29.43 &   93 & 96 \\
	&SRResNet       &   1550    & 29.00 &  114 & 12 \\
\bottomrule
 \end{tabular}}
\end{table}