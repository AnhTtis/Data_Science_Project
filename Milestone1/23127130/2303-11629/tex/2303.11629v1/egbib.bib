@inproceedings{raft,
  title={Raft: Recurrent all-pairs field transforms for optical flow},
  author={Teed, Zachary and Deng, Jia},
  booktitle={European conference on computer vision},
  pages={402--419},
  year={2020},
  organization={Springer}
}

@inproceedings{flownet,
  title={Flownet: Learning optical flow with convolutional networks},
  author={Dosovitskiy, Alexey and Fischer, Philipp and Ilg, Eddy and Hausser, Philip and Hazirbas, Caner and Golkov, Vladimir and Van Der Smagt, Patrick and Cremers, Daniel and Brox, Thomas},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2758--2766},
  year={2015}
}

@inproceedings{flownet2,
  title={Flownet 2.0: Evolution of optical flow estimation with deep networks},
  author={Ilg, Eddy and Mayer, Nikolaus and Saikia, Tonmoy and Keuper, Margret and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2462--2470},
  year={2017}
}

@inproceedings{pwcnet,
  title={Pwc-net: Cnns for optical flow using pyramid, warping, and cost volume},
  author={Sun, Deqing and Yang, Xiaodong and Liu, Ming-Yu and Kautz, Jan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8934--8943},
  year={2018}
}

@article{evflownet,
  title={EV-FlowNet: Self-supervised optical flow estimation for event-based cameras},
  author={Zhu, Alex Zihao and Yuan, Liangzhe and Chaney, Kenneth and Daniilidis, Kostas},
  journal={arXiv preprint arXiv:1802.06898},
  year={2018}
}

@article{distancePAMI,
  title={Distance surface for event-based optical flow},
  author={Almatrafi, Mohammed and Baldwin, Raymond and Aizawa, Kiyoharu and Hirakawa, Keigo},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={42},
  number={7},
  pages={1547--1556},
  year={2020},
  publisher={IEEE}
}

@inproceedings{eraft,
  title={E-RAFT: Dense optical flow from event cameras},
  author={Gehrig, Mathias and Millh{\"a}usler, Mario and Gehrig, Daniel and Scaramuzza, Davide},
  booktitle={2021 International Conference on 3D Vision (3DV)},
  pages={197--206},
  year={2021},
  organization={IEEE}
}

@inproceedings{CM,
  title={A unifying contrast maximization framework for event cameras, with applications to motion, depth, and optical flow estimation},
  author={Gallego, Guillermo and Rebecq, Henri and Scaramuzza, Davide},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3867--3876},
  year={2018}
}

@inproceedings{yeego,
  title={Unsupervised Learning of Dense Optical Flow, Depth and Egomotion with Event-Based Sensors},
  author={Ye, Chengxi and Mitrokhin, Anton and Ferm{\"u}ller, Cornelia and Yorke, James A and Aloimonos, Yiannis},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5831--5838},
  year={2020},
  organization={IEEE}
}

@inproceedings{zhuego,
  title={Unsupervised event-based learning of optical flow, depth, and egomotion},
  author={Zhu, Alex Zihao and Yuan, Liangzhe and Chaney, Kenneth and Daniilidis, Kostas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={989--997},
  year={2019}
}

@inproceedings{ssl,
  title={Back to event basics: Self-supervised learning of image reconstruction for event cameras via photometric constancy},
  author={Paredes-Vall{\'e}s, Federico and de Croon, Guido CHE},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3446--3455},
  year={2021}
}

@inproceedings{motioncomp,
  title={Event-based motion segmentation by motion compensation},
  author={Stoffregen, Timo and Gallego, Guillermo and Drummond, Tom and Kleeman, Lindsay and Scaramuzza, Davide},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7244--7253},
  year={2019}
}

@article{survey,
  title={Event-based vision: A survey},
  author={Gallego, Guillermo and Delbr{\"u}ck, Tobi and Orchard, Garrick and Bartolozzi, Chiara and Taba, Brian and Censi, Andrea and Leutenegger, Stefan and Davison, Andrew J and Conradt, J{\"o}rg and Daniilidis, Kostas and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={1},
  pages={154--180},
  year={2020},
  publisher={IEEE}
}
@inproceedings{STE,
  title={Spatio-temporal recurrent networks for event-based optical flow estimation},
  author={Ding, Ziluo and Zhao, Rui and Zhang, Jiyuan and Gao, Tianxiao and Xiong, Ruiqin and Yu, Zhaofei and Huang, Tiejun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={1},
  pages={525--533},
  year={2022}
}

@inproceedings{peking2,
  title={Optical flow estimation for spiking camera},
  author={Hu, Liwen and Zhao, Rui and Ding, Ziluo and Ma, Lei and Shi, Boxin and Xiong, Ruiqin and Huang, Tiejun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17844--17853},
  year={2022}
}


@article{lowhigh,
  title={Real-Time Optical Flow for Vehicular Perception with Low-and High-Resolution Event Cameras},
  author={Brebion, Vincent and Moreau, Julien and Davoine, Franck},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2021},
  publisher={IEEE}
}

@article{dsec,
  title={Dsec: A stereo event camera dataset for driving scenarios},
  author={Gehrig, Mathias and Aarents, Willem and Gehrig, Daniel and Scaramuzza, Davide},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={3},
  pages={4947--4954},
  year={2021},
  publisher={IEEE}
}

@article{mvsec,
  title={The multivehicle stereo event camera dataset: An event camera dataset for 3D perception},
  author={Zhu, Alex Zihao and Thakur, Dinesh and {\"O}zaslan, Tolga and Pfrommer, Bernd and Kumar, Vijay and Daniilidis, Kostas},
  journal={IEEE Robotics and Automation Letters},
  volume={3},
  number={3},
  pages={2032--2039},
  year={2018},
  publisher={IEEE}
}

@inproceedings{firenet,
  title={Fast image reconstruction with an event camera},
  author={Scheerlinck, Cedric and Rebecq, Henri and Gehrig, Daniel and Barnes, Nick and Mahony, Robert and Scaramuzza, Davide},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={156--163},
  year={2020}
}

@inproceedings{monodepth,
  title={Learning monocular dense depth from events},
  author={Hidalgo-Carri{\'o}, Javier and Gehrig, Daniel and Scaramuzza, Davide},
  booktitle={2020 International Conference on 3D Vision (3DV)},
  pages={534--542},
  year={2020},
  organization={IEEE}
}

@inproceedings{spynet,
  title={Optical flow estimation using a spatial pyramid network},
  author={Ranjan, Anurag and Black, Michael J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4161--4170},
  year={2017}
}

@inproceedings{liteflownet,
  title={Liteflownet: A lightweight convolutional neural network for optical flow estimation},
  author={Hui, Tak-Wai and Tang, Xiaoou and Loy, Chen Change},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8981--8989},
  year={2018}
}

@article{liteflownet2,
  title={A lightweight optical flow CNNâ€”Revisiting data fidelity and regularization},
  author={Hui, Tak-Wai and Tang, Xiaoou and Loy, Chen Change},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={8},
  pages={2555--2569},
  year={2020},
  publisher={IEEE}
}

@inproceedings{liteflownet3,
  title={LiteFlowNet3: Resolving correspondence ambiguity for more accurate optical flow estimation},
  author={Hui, Tak-Wai and Loy, Chen Change},
  booktitle={European Conference on Computer Vision},
  pages={169--184},
  year={2020},
  organization={Springer}
}

@article{VCN,
  title={Volumetric correspondence networks for optical flow},
  author={Yang, Gengshan and Ramanan, Deva},
  journal={Advances in neural information processing systems},
  volume={32},
  pages={794--805},
  year={2019}
}

@inproceedings{IRR,
  title={Iterative residual refinement for joint optical flow and occlusion estimation},
  author={Hur, Junhwa and Roth, Stefan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5754--5763},
  year={2019}
}
@article{grumod,
  title={On the properties of neural machine translation: Encoder-decoder approaches},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.1259},
  year={2014}
}

@inproceedings{separable,
  title={Separable Flow: Learning Motion Cost Volumes for Optical Flow Estimation},
  author={Zhang, Feihu and Woodford, Oliver J and Prisacariu, Victor Adrian and Torr, Philip HS},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10807--10817},
  year={2021}
}

@inproceedings{improveflowpyramid,
  title={Improving optical flow on a pyramid level},
  author={Hofinger, Markus and Bul{\`o}, Samuel Rota and Porzi, Lorenzo and Knapitsch, Arno and Pock, Thomas and Kontschieder, Peter},
  booktitle={European Conference on Computer Vision},
  pages={770--786},
  year={2020},
  organization={Springer}
}

@inproceedings{1Dattention,
  title={High-Resolution Optical Flow from 1D Attention and Correlation},
  author={Xu, Haofei and Yang, Jiaolong and Cai, Jianfei and Zhang, Juyong and Tong, Xin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10498--10507},
  year={2021}
}

@inproceedings{ganet,
  title={Ga-net: Guided aggregation net for end-to-end stereo matching},
  author={Zhang, Feihu and Prisacariu, Victor and Yang, Ruigang and Torr, Philip HS},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={185--194},
  year={2019}
}

@inproceedings{domain,
  title={Domain-invariant stereo matching networks},
  author={Zhang, Feihu and Qi, Xiaojuan and Yang, Ruigang and Prisacariu, Victor and Wah, Benjamin and Torr, Philip},
  booktitle={European Conference on Computer Vision},
  pages={420--439},
  year={2020},
  organization={Springer}
}

@article{asynchronous,
  title={Asynchronous frameless event-based optical flow},
  author={Benosman, Ryad and Ieng, Sio-Hoi and Clercq, Charles and Bartolozzi, Chiara and Srinivasan, Mandyam},
  journal={Neural Networks},
  volume={27},
  pages={32--37},
  year={2012},
  publisher={Elsevier}
}

@article{eofdection,
  title={On event-based optical flow detection},
  author={Brosch, Tobias and Tschechne, Stephan and Neumann, Heiko},
  journal={Frontiers in neuroscience},
  volume={9},
  pages={137},
  year={2015},
  publisher={Frontiers}
}

@article{evisualflow,
  title={Event-based visual flow},
  author={Benosman, Ryad and Clercq, Charles and Lagorce, Xavier and Ieng, Sio-Hoi and Bartolozzi, Chiara},
  journal={IEEE transactions on neural networks and learning systems},
  volume={25},
  number={2},
  pages={407--417},
  year={2013},
  publisher={IEEE}
}

@inproceedings{eofsimu,
  title={Simultaneous optical flow and intensity estimation from an event camera},
  author={Bardow, Patrick and Davison, Andrew J and Leutenegger, Stefan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={884--892},
  year={2016}
}

@article{snnunsupervised,
  title={Unsupervised learning of a hierarchical spiking neural network for optical flow estimation: From events to global motion perception},
  author={Paredes-Vall{\'e}s, Federico and Scheper, Kirk YW and de Croon, Guido CHE},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={42},
  number={8},
  pages={2051--2064},
  year={2019},
  publisher={IEEE}
}

@inproceedings{snnflow,
  title={A spiking neural network architecture for visual motion estimation},
  author={Orchard, Garrick and Benosman, Ryad and Etienne-Cummings, Ralph and Thakor, Nitish V},
  booktitle={2013 IEEE Biomedical Circuits and Systems Conference (BioCAS)},
  pages={298--301},
  year={2013},
  organization={IEEE}
}

@inproceedings{single,
  title={Single image optical flow estimation with an event camera},
  author={Pan, Liyuan and Liu, Miaomiao and Hartley, Richard},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1669--1678},
  year={2020},
  organization={IEEE}
}

@article{aperture-robust,
  title={Real-time high speed motion prediction using fast aperture-robust event-driven visual flow},
  author={Akolkar, Himanshu and Ieng, Sio-Hoi and Benosman, Ryad},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={1},
  pages={361--372},
  year={2020},
  publisher={IEEE}
}

@inproceedings{spikeflownet,
  title={Spike-flownet: event-based optical flow estimation with energy-efficient hybrid neural networks},
  author={Lee, Chankyu and Kosta, Adarsh Kumar and Zhu, Alex Zihao and Chaney, Kenneth and Daniilidis, Kostas and Roy, Kaushik},
  booktitle={European Conference on Computer Vision},
  pages={366--382},
  year={2020},
  organization={Springer}
}

@inproceedings{unet,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{onecycle,
  title={Super-convergence: Very fast training of neural networks using large learning rates},
  author={Smith, Leslie N and Topin, Nicholay},
  booktitle={Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications},
  volume={11006},
  pages={1100612},
  year={2019},
  organization={International Society for Optics and Photonics}
}

@inproceedings{evstereo,
  title={Learning an event sequence embedding for dense event-based deep stereo},
  author={Tulyakov, Stepan and Fleuret, Francois and Kiefel, Martin and Gehler, Peter and Hirsch, Michael},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1527--1537},
  year={2019}
}

@inproceedings{evdepth,
  title={Learning monocular dense depth from events},
  author={Hidalgo-Carri{\'o}, Javier and Gehrig, Daniel and Scaramuzza, Davide},
  booktitle={2020 International Conference on 3D Vision (3DV)},
  pages={534--542},
  year={2020},
  organization={IEEE}
}

@inproceedings{CBAM,
  title={Cbam: Convolutional block attention module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}
@inproceedings{SENet,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}
@inproceedings{sknet,
  title={Selective kernel networks},
  author={Li, Xiang and Wang, Wenhai and Hu, Xiaolin and Yang, Jian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={510--519},
  year={2019}
}
@article{attentionsurvey,
  title={Attention Mechanisms in Computer Vision: A Survey},
  author={Guo, Meng-Hao and Xu, Tian-Xing and Liu, Jiang-Jiang and Liu, Zheng-Ning and Jiang, Peng-Tao and Mu, Tai-Jiang and Zhang, Song-Hai and Martin, Ralph R and Cheng, Ming-Ming and Hu, Shi-Min},
  journal={arXiv preprint arXiv:2111.07624},
  year={2021}
}
@article{secrets,
  title={Secrets of Event-based Optical Flow},
  author={Shiba, Shintaro and Aoki, Yoshimitsu and Gallego, Guillermo},
  journal={arXiv preprint arXiv:2207.10022},
  year={2022}
}
@article{self,
  title={Self-supervised learning of event-based optical flow with spiking neural networks},
  author={Hagenaars, Jesse and Paredes-Vall{\'e}s, Federico and De Croon, Guido},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={7167--7179},
  year={2021}
}
@article{continuous,
  title={Dense Continuous-Time Optical Flow from Events and Frames},
  author={Gehrig, Mathias and Muglikar, Manasi and Scaramuzza, Davide},
  journal={arXiv preprint arXiv:2203.13674},
  year={2022}
}

@article{attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{gmflow,
  title={GMFlow: Learning Optical Flow via Global Matching},
  author={Xu, Haofei and Zhang, Jing and Cai, Jianfei and Rezatofighi, Hamid and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8121--8130},
  year={2022}
}

@inproceedings{gma,
  title={Learning to estimate hidden motions with global motion aggregation},
  author={Jiang, Shihao and Campbell, Dylan and Lu, Yao and Li, Hongdong and Hartley, Richard},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9772--9781},
  year={2021}
}

@article{TIP,
  title={Learning Dense and Continuous Optical Flow From an Event Camera},
  author={Wan, Zhexiong and Dai, Yuchao and Mao, Yuxin},
  journal={IEEE Transactions on Image Processing},
  volume={31},
  pages={7237--7251},
  year={2022},
  publisher={IEEE}
}

@article{adamw,
  title={Fixing weight decay regularization in adam},
  author={Loshchilov, Ilya and Hutter, Frank},
  year={2017}
}

@inproceedings{block,
  title={Adaptive time-slice block-matching optical flow algorithm for dynamic vision sensors},
  author={Liu, Min and Delbruck, Tobi},
  year={2018},
  organization={BMVC}
}

@article{dlev,
  title={Deep Learning for Event-based Vision: A Comprehensive Survey and Benchmarks},
  author={Zheng, Xu and Liu, Yexin and Lu, Yunfan and Hua, Tongyan and Pan, Tianbo and Zhang, Weiming and Tao, Dacheng and Wang, Lin},
  journal={arXiv preprint arXiv:2302.08890},
  year={2023}
}

@article{evimo2,
  title={EVIMO2: An event camera dataset for motion segmentation, optical flow, structure from motion, and visual inertial odometry in indoor scenes with monocular or stereo algorithms},
  author={Burner, Levi and Mitrokhin, Anton and Ferm{\"u}ller, Cornelia and Aloimonos, Yiannis},
  journal={arXiv preprint arXiv:2205.03467},
  year={2022}
}

@inproceedings{timelens,
  title={Time lens: Event-based video frame interpolation},
  author={Tulyakov, Stepan and Gehrig, Daniel and Georgoulis, Stamatios and Erbach, Julius and Gehrig, Mathias and Li, Yuanyou and Scaramuzza, Davide},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16155--16164},
  year={2021}
}

@inproceedings{timelens++,
  title={Time lens++: Event-based frame interpolation with parametric non-linear flow and multi-scale fusion},
  author={Tulyakov, Stepan and Bochicchio, Alfredo and Gehrig, Daniel and Georgoulis, Stamatios and Li, Yuanyou and Scaramuzza, Davide},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17755--17764},
  year={2022}
}

@ARTICLE{EDFlow,
  author={Liu, Min and Delbruck, Tobi},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={EDFLOW: Event Driven Optical Flow Camera With Keypoint Detection and Adaptive Block Matching}, 
  year={2022},
  volume={32},
  number={9},
  pages={5776-5789},
  doi={10.1109/TCSVT.2022.3156653}}