\documentclass[journal]{IEEEtran}


%
%\newtheorem{Problem}{Problem}[section]
%\usepackage{subfig}
\usepackage{graphicx}
%\usepackage{cite}
%\usepackage{color}
\usepackage{amsmath,bm}
\usepackage{amssymb,mathrsfs}
\newtheorem{remark}{Remark}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{assumption}{Assumption}[section]
\newtheorem{example}{Example}[section]
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage[caption=false]{subfig}
%\usepackage{enumitem}
% \usepackage{tikz}
% \usetikzlibrary{calc}
%\usetikzlibrary{shapes.geometric, arrows}
%\tikzstyle{process} = [rectangle, draw, minimum width = 2.5cm, minimum height = 1cm, text badly centered, inner sep=2pt, draw=black]
%\tikzstyle{decision} = [diamond, draw, text badly centered, inner sep=2pt, text centered, draw=black]
%\tikzstyle{arrow} = [thick,->,>=stealth]
%\usepackage{pgfplots}
%\usetikzlibrary{backgrounds}
\usepackage[switch,pagewise]{lineno}
\newcommand*\patchAmsMathEnvironmentForLineno[1]{%
\expandafter\let\csname old#1\expandafter\endcsname\csname #1\endcsname
\expandafter\let\csname oldend#1\expandafter\endcsname\csname end#1\endcsname
\renewenvironment{#1}%
{\linenomath\csname old#1\endcsname}%
{\csname oldend#1\endcsname\endlinenomath}}%
\newcommand*\patchBothAmsMathEnvironmentsForLineno[1]{%
\patchAmsMathEnvironmentForLineno{#1}%
\patchAmsMathEnvironmentForLineno{#1*}}%
\AtBeginDocument{%
\patchBothAmsMathEnvironmentsForLineno{equation}%
\patchBothAmsMathEnvironmentsForLineno{align}%
}
%\pagewiselinenumbers
%\linenumbers
%\linenumbersep 3pt\relax
\newcommand{\m}[1]{\mathbf{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\ms}[1]{\bm{#1}}

\begin{document}
%
\title{Matrix-Scaled Consensus over Undirected Networks}
%

\author{ Minh Hoang Trinh$^{\dagger,\ast}$,~\IEEEmembership{Member,~IEEE},~Hoang Huy Vu$^{\ddagger}$,~Nhat-Minh Le-Phan$^{\ddagger,\sharp}$, Quyen Ngoc Nguyen$^{\ddagger}$
        %and % <-this % stops a space
\thanks{$^{\dagger}$ AI Department, FPT University, An Thinh Phu New Urban Area, Nhon Binh Ward, Quy Nhon City, Binh Dinh 55117, Vietnam.}
\thanks{$^{\ddagger}$ Department of Automation Engineering, School of Electrical and Electronic Engineering, Hanoi University of Science and Technology (HUST), 1 Dai Co Viet Str., Hai Ba Trung Dist., Hanoi 11615, Vietnam.}
\thanks{$^{\sharp}$ Research and Development in Navigation, Guidance and Control
Technologies Center, Viettel Aerospace Institute, Hanoi 13151, Vietnam.}
\thanks{$^*$ Corresponding author. Email: \texttt{minhtrinh@ieee.org}}
\thanks{Manuscript received ...}}


% make the title area
\maketitle

\begin{abstract}
In this paper, we propose matrix-scaled consensus algorithms for linear dynamical agents interacting over an undirected network. The goal of these algorithms is making {the state vectors of all agents to asymptotically agree up to some matrix scaling weights. First, the matrix scaled Laplacian and its algebraic properties are examined.} Second, we propose matrix-scaled consensus algorithms for networks of single integrators with or without constant parametric uncertainties. Third, observer-based matrix-scaled consensus algorithms for  homogeneous or heterogeneous linear agents are designed. The effectiveness of the proposed algorithms are asserted by rigorous mathematical analysis and supported by numerical simulations.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
multi-agent systems, consensus, multi-dimensional opinion dynamics
\end{IEEEkeywords}

%\IEEEpeerreviewmaketitle

\section{Introduction}
\label{sec:introduction}

Collective behaviors displayed in nature such as bird flocking, fish schooling, synchronous fireflies, have inspired a lot of research works. Though simple, the consensus algorithm has been widely used for modeling and studying such striking phenomena \cite{Olfati2007consensuspieee}. It is interesting that a lot of multiagent systems such as autonomous vehicle formations, electrical system, sensor networks, or social networks can be coordinated by appropriately applying consensus algorithms and its modifications \cite{Ren2007magazine,Proskurnikov2017tutorial}.

Consider a network in which the interactions between subsystems, or agents, is modeled by a graph. In the consensus algorithm, each agent updates its state based on the sum of the relative states with its nearby agents. If the interaction graph is connected, the agents' states asymptotically converge to a common point in the space, and {the system is said to asymptotically achieve} a consensus \cite{Olfati2007consensuspieee}. 

A (scalar) scaled consensus model was proposed in \cite{Roy2015scaled}, in which each agent has a {nonzero} scalar scaling gain and updates its state variable based on the sum of differences in the scaled states. Under the scaled consensus model, the scaled states of all agents agree to the same virtual consensus value, and the state variable of each agent converges to a value differing from the virtual consensus value by an inverse of the scaling gain. Thus, under the scalar scaled consensus algorithm \cite{Roy2015scaled}, {and suppose that each agent has a state vector, the state vectors of all agents asymptotically distributed along a straight line through the origin.} The scaled consensus system can describe a cooperative network, where agents have different levels of consensus on a single topic. Further studies of the scalar scaled consensus algorithm with consideration to switching graphs, time delays, disturbance attenuation, or different agents' models can be found in the literature \cite{Meng2015scaled,Meng2015TIE,Aghbolagh2016scaled,Shang2017delayed,Hanada2019new,Wu2021adaptive,Chen2022scaled}.

This paper proposes a multi-dimensional generalization of the scaled consensus model in \cite{Roy2015scaled}. We firstly consider an undirected network of single integrator agents {as a basic setup.} Each agent has a state vector and a possibly non-symmetric positive or negative definite scaling matrix. {The} agent updates the state variables based on the relative matrix-scaled state vectors. Several algebraic properties of the matrix scaled Laplacian, which determines the asymptotic behavior of the whole system{, are derived.}  Specifically, it is shown that the matrix-scaled states eventually agree to a virtual consensus vector. {The state vector of each agent asymptotically converges to a vector, which can be obtained from the virtual consensus point by a linear transformation determined by the inverse of its scaling matrix.} Thus, all agents with the same scaling matrix converge to a common point in the space, and clustering behaviors usually happen. {To accommodate more complicated interactions,} nonlinear matrix-scaled consensus algorithms and corresponding Lyapunov-based analysis {are} also provided. It is worth noting that in the proposed matrix-scaled consensus model, the scaling matrices are not limited to rotation matrices such as the algorithms considered in \cite{Ren2009collective,Ramirez2010distributed,Tran2018ecc,Lee2018distributed,Ahn2019consensus}.  In \cite{Trinh2022matrix}, the proposed model {was}  interpreted as a multi-dimensional model opinion {dynamics}, where the positive/negative definite scaling matrix weight{s} capture the private belief system of an individual on $d$ logically dependent topics. {Clustering happens as the private belief system of each individual is usually different from each other and not perfectly aligned with a social norm.} 
{Second, we study the matrix-scaled consensus algorithm for a system of single integrators with parametric uncertainties. An adaptive scheme is developed, which guarantees the system to eventually achieve matrix-scaled consensus.} If in addition, a persistently exciting condition is satisfied, the estimate variables eventually {converge to the precise} parameters. Third, we consider a network of homogeneous linear agents and propose an observer-based matrix-scaled {consensus} algorithm. It is shown that the agents asymptotically achieve matrix-scaled consensus with regard to a {trajectory of a virtual agent}. If we {specify} the agents to be linear oscillators in 2D, and the scaling matrices to {be a composition of rotation and expansion/compression matrices, the asymptotic biases in phase and magnitude of each agent's trajectory with a common oscillator can be determined by the scaling matrices}. {Thus, the algorithms can be used for designing robot's trajectories, referenced voltages in circuits, or explaining the alternation of temperature during four seasons.}  Lastly, as practical networks often consists of agents with different sizes and capacities, we propose a matrix-scaled consensus algorithm for a network of heterogeneous linear agents. {The proposed algorithm combines the corresponding matrix-scaled consensus algorithm for homogeneous linear agents with a disturbance observer which compensates the differences between each agent's model and a pre-specified one. The main challenges and differences in the analysis of our proposed algorithms with regard to the existing {consensus algorithms for general linear agents} in the literature, e.g., \cite{Scardovi2009synchronization,Kim2010output,Li2009consensus,Li2013distributed,Panteley2017synchronization,Tuna2016synchronization,Burbano2019distributed}, are originated from the asymmetry of the matrix scaled Laplacian and the multi-dimension of the problem.}

The remainder of this paper is organized as follows. Section~\ref{sec:2} provides theoretical background, problem formulation, and several properties of the matrix-scaled Laplacian. Matrix-scaled consensus algorithms for single  integrator agents with and without parametric uncertainties are proposed and examined in Section~\ref{sec:single_integrator}. Section \ref{sec:linear_agents} studies matrix-scaled consensus for networks of homogeneous and heterogeneous linear agents. Simulations  are given in Section~\ref{sec:5} to support the theoretical results. Finally, Section~\ref{sec:6} concludes the paper. 

\section{Preliminaries}
\label{sec:2}
\subsection{Notations}
In this paper, the sets of real, complex, and natural numbers are denoted by $\mb{R}, \mb{C}$ and $\mb{N}$, respectively. Scalars are denoted by lowercase letters, while bold font normal and capital letters are used for vectors and matrices, respectively. {We denote $\m{1}_d \in \mb{R}^d$ the $d$-dimensional vector of all 1 an $\m{0}_{m\times n} \in \mb{R}^{m\times n}$ the matrix of all zeros.} The transpose of a matrix $\m{A} \in \mb{R}^{m\times n}$ is denoted by $\m{A}^\top$. The kernel, image, rank, and determinant of $\m{A}$ are respectively denoted as ker$(\m{A})$, im$(\m{A})$, rank($\m{A}$), and $\text{det}(\m{A})$. The 2-norm ($\infty$-norm) of a vector $\m{x} = [x_1, \ldots, x_d]^\top$ is denoted by $\|\m{x}\| = \sqrt{\sum_{i=1}^{d} x_i^2}$ (correspondingly, $\|\m{x}\|_{\infty} = \max_{i\in \{1,\ldots,d\}} |x_i|$). The 2-norm of a real matrix $\m{A}$, denoted by $\|\m{A}\|$, is defined as $\max_{\|\m{x}\|=1}\|\m{A}\m{x}\|$. A matrix $\m{A} \in \mb{R}^{d\times d}$ is positive definite (negative definite) if and only if $\forall \m{x} \in \mb{R}^d$, $\m{x}\neq \m{0}_d$, then $\m{x}^\top \m{A} \m{x}>0$ (resp., $\m{x}^\top \m{A} \m{x} < 0$). For a real, symmetric positive semidefinite matrix $\m{A} \in \mb{R}^{d\times d}$, which can be diagonalized as $\m{T}^{-1}\m{A}\m{T}=\text{diag}(\omega_1,\ldots,\omega_d)$, we use $\sqrt{\m{A}}$ to denote its square root $\m{T}\text{diag}(\sqrt{\omega_1},\ldots,\sqrt{\omega_d})\m{T}^{-1}$. Let $\m{x}_1, \ldots, \m{x}_n \in \mb{R}^d$, the vectorization operator is defined as vec$(\m{x}_1,\ldots,\m{x}_n) = [\m{x}_1^\top,\ldots,\m{x}_n^\top]^\top \in \mb{R}^{dn}$. Given matrices $\m{A}_1,\ldots,\m{A}_n$, we use blkdiag$(\m{A}_1,\ldots,\m{A}_n)$ as the block diagonal matrix with $\m{A}_k$, $k=1,\ldots,n$ in the main diagonal.

\subsection{Graph theory}
Consider a undirected graph $\mc{G} = (\mc{V},\mc{E},\mc{W})$, where $\mc{V}=\{1,\ldots,n\}$ is the set of $n$ vertices, $\mc{E}=\{e_k=(i,j),~k=1,\ldots,m\} \subset \mc{V}^2$ is the set of $m$ edges, and $\mc{W}=\{w_{ij}>0\}_{(i,j) \in \mc{E}}$ is the set of positive scalar weights corresponding to each edge of $\mc{G}$. By undirectedness, if $(i,j) \in \mc{E}$, then $(j,i)\in \mc{E}$. Further, it is assumed that there is no self-loop (an edge with the same end vertices $(i,i)$, $i \in \mc{V}$) in the graph. The neighbor set of a vertex $i$ is defined as $\mc{N}_i = \{j \in \mc{N}_i|~(j,i) \in \mc{E}\}$. A path is a sequences of vertices connected by edges in $\mc{E}$, where each vertex appears one time, except for possibly the starting and the ending vertices. For examples, the path $\mc{P}=i_1i_2\ldots i_p$ from $i_1$ to $i_p$ has $(i_k,i_{k+1})\in \mc{E}$, $k=1,\ldots,p-1$. A cycle is a path with the same starting and ending vertices. A graph is connected if there exists a path between any two vertices in $\mc{V}$. 
 A spanning subgraph $\mc{G}'=(\mc{V}',\mc{E}',\mc{W}')$ of $\mc{G}$ has $\mc{V}'= \mc{V}$ and $\mc{E}\subseteq \mc{E}'$. A spanning tree of $\mc{G}$ is a connected spanning sub-graph of $\mc{G}$ with $n-1$ edges. Let $\mc{T}$ be a spanning tree of $\mc{G}$ and consider an arbitrary labeling and orientation of the edges in $\mc{E}$ so that $n-1$ edges of $\mc{E}(\mc{T})$ are $e_1,\ldots,e_{n-1}$. Let $\m{H} \in \mb{R}^{m\times n}$, $\m{H}_{\mc{T}} \in \mb{R}^{(n-1)\times n}$, and $\m{H}_{\mc{C}} \in \mb{R}^{(m-n+1) \times n}$ denote the corresponding incidence matri{ces} of $\mc{G}$, $\mc{T}$, and the subgraph $(\mc{V},\mc{E}\setminus\mc{E}(\mc{T}),\mc{W}\setminus\mc{W}(\mc{T}))$. Then, the incidence matrix can be expressed as
\begin{align*}
\m{H} = \begin{bmatrix}
\m{H}_{\mc{T}} \\ 
\m{H}_{\mc{C}}
\end{bmatrix} 
= \begin{bmatrix}
\m{I}_{n-1} \\ 
\m{T}
\end{bmatrix} \m{H}_{\mc{T}} = \m{R} \m{H}_{\mc{T}},
\end{align*}
where $\m{H}_{\mc{T}} \in \mb{R}^{(n-1)\times n}$, $\m{H}_{\mc{C}} \in \mb{R}^{(m-n+1)\times n}$, and $\m{T} = \m{H}_{\mc{C}} \m{H}_{\mc{T}} (\m{H}_{\mc{T}} \m{H}_{\mc{T}}^\top)^{-1}$ \cite{Zelazo2010tac}. The graph Laplacian of $\mc{G}$ can be defined as $\m{L} =[l_{ij}] = \m{H}^\top \m{W} \m{H} \in \mb{R}^{n\times n},$ 
where $\m{W} = \text{diag}(\ldots,w_{ij},\ldots) = \text{diag}(w_1,\ldots,w_m)$. The matrix $\m{L}$ of a connected graph is symmetric positive semidefinite, with spectrum $0=\lambda_1 <\lambda_2 \leq \ldots \leq \lambda_n$, and ker$(\m{L})=\text{im}(\m{1}_n)$.

\subsection{Agents' models and the group's objective}
In this paper, we consider an $n$-agent system interacted via an undirected weighted graph $\mc{G}$. The dynamics of each agent is modeled by either
\begin{enumerate}%[label=(\roman*)]
\item[(i)]  single-integrator with parametric uncertainty:
\begin{align} \label{eq:model}
\dot{\m{x}}_i = \m{u}_i + \bm{\phi}_i(t,\m{x}_i) \bm{\theta}_i,~i=1,\ldots, n,
\end{align}
where $\m{x}_i,\m{u}_i \in \mb{R}^d$ are the state variable vector and the control input, $\bm{\phi}_i(t,\m{x}_i),~\dot{\bm{\phi}}_i(t,\m{x}_i)\in \mb{R}^{d\times r}$ are the matrices of known bounded continuous functions, and $\bm{\theta}_i\in \mb{R}^r$ is a vector of constant unknown parameters; or
\item[(ii)]  homogeneous linear agents
\begin{subequations} \label{eq:homogeneous_linear}
\begin{align}
\dot{\m{x}}_i &= \m{A} \m{x}_i + \m{B} \m{u}_i,\\
\m{y}_i &= \m{C} \m{x}_i,~i=1,\ldots,n,
\end{align}
\end{subequations}
where $(\m{A},\m{B})$ is controllable and $(\m{A},\m{C})$ is observable. %and
\item[(iii)]  heterogeneous linear agents
\begin{subequations} \label{eq:heterogeneous_linear}
\begin{align}
\dot{\m{x}}_i &= \m{A}_i \m{x}_i + \m{B}_i \m{u}_i,\\
\m{y}_i &= \m{C}_i \m{x}_i,~i=1,\ldots,n,
\end{align}
\end{subequations}
where $(\m{A}_i,\m{B}_i)$ is controllable and $(\m{A}_i,\m{C}_i)$ is observable, $\forall i \in \{1,\ldots, n\}$.
\end{enumerate}

We associate to each agent a scaling matrix $\m{S}_i \in \mb{R}^{d\times d}$ ($d\ge 2$) and a state vector $\m{x}_i \in \mb{R}^d$. The matrix $\m{S}_i$ is either positive definite or negative definite.  For each scaling matrix, we define a matrix signum function 
\begin{align}
\text{sign}(\m{S}_i) = \left\{ {\begin{array}{*{20}{ll}}
{1},& \text{if $\m{S}_i$ is positive definite},\\
{-1},& \text{if $\m{S}_i$ is negative definite}.
\end{array}} \right.
\end{align}
and an absolute matrix function $|\m{S}_i| = \text{sign}(\m{S}_i)\m{S}_i$. It is not hard to see that $\text{sign}(\m{S}_i) = \text{sign}(\m{S}_i^\top) = \text{sign}(\m{S}_i^{-1})$, and $|\m{S}_i^{-1}| = |\m{S}_i|^{-1}$. {Let $\m{x} = \text{vec}(\m{x}_1,\ldots,\m{x}_n)$, $\m{S}=\text{blkdiag}(\m{S}_1,\ldots,\m{S}_n)$, and $|\m{S}|=\text{blkdiag}(|\m{S}_1|,\ldots,|\m{S}_n|)$, we aim to design matrix-scaled consensus algorithms so that $\m{x}(t) \to \mc{C}_S$ as $t\to\infty$, $\forall \m{x}(0)$, where  
\begin{align}
\mc{C}_S = \{\m{x} \in \mb{R}^{dn}|~ \m{S}_i\m{x}_i = \m{S}_j \m{x}_j,~\forall i, j = 1,\ldots, n\}.
\end{align}
is the matrix-scaled consensus (MSC) set.}

The following lemma will be used throughout this paper.
\begin{lemma} \label{lem:omega} The matrix $\bm{\Omega} = (\text{sign}(\m{S})\m{L}\otimes \m{I}_d)\m{S}$ has $d$ zero eigenvalues and $dn-d$ eigenvalues with positive real parts. The left and right kernels of $\bm{\Omega}$ are spanned by columns of $(\text{sign}(\m{S})\m{1}_n)\otimes \m{I}_d$ and $\m{S}^{-1}(\m{1}_n\otimes \m{I}_d)$, respectively.
\end{lemma}
\begin{IEEEproof} Consider $\m{M}=\m{S} \bm{\Omega} \m{S}^{-1} = |\m{S}|(\m{L}\otimes \m{I}_d)$, then $\m{M}$ and $\bm{\Omega}$ are similar and thus, having the same spectrum. Since $|\m{S}|$ is positive definite, rank$(\m{M}) = \text{rank}(\m{L}\otimes \m{I}_d) = dn-d$, and thus $\m{M}$ has $d$ zero eigenvalues. Next, let $\bar{\m{H}} = \m{H}\otimes \m{I}_d$, $\bar{\m{W}} = \m{W}\otimes \m{I}_d$, $\bar{\m{L}}=\m{L}\otimes \m{I}_d$,
{\small
\begin{align*}
\m{X} = \begin{bmatrix}
\m{I}_{dn} & s^{-1}\m{|S|} \bar{\m{H}}^\top \sqrt{\overline{\m{W}}}\\
\sqrt{\overline{\m{W}}}\bar{\m{H}} & \m{I}_{dm}
\end{bmatrix},~
\m{Y} = \begin{bmatrix}
\m{I}_{dn} &  \m{0}_{dn\times dm}\\
-\sqrt{\overline{\m{W}}}\bar{\m{H}} & \m{I}_{dm}
\end{bmatrix},
\end{align*}}
for any $0\neq s\in \mb{C}$, we have
{\small
\begin{align*}
\m{X}\m{Y} &= \begin{bmatrix}
\m{I}_{dn}-s^{-1}\m{|S|} \bar{\m{L}} & s^{-1}\m{|S|}\bar{\m{H}}^\top\sqrt{\overline{\m{W}}}\\
\m{0}_{dm\times dn} & \m{I}_{dm}
\end{bmatrix}, \\ 
\m{Y}\m{X} &= \begin{bmatrix}
\m{I}_{dn} & s^{-1} \m{|S|}\bar{\m{H}}^\top\sqrt{\overline{\m{W}}}\\
\m{0}_{dm\times dn} & \m{I}_{dm}-s^{-1}\sqrt{\overline{\m{W}}}\bar{\m{H}}\m{|S|} \bar{\m{H}}^\top\sqrt{\overline{\m{W}}}
\end{bmatrix}.
\end{align*}}
From the fact that $\text{det}(\m{X}\m{Y}) = \text{det}(\m{Y}\m{X})$, one has
{\small
\begin{align*} %\label{eq:Sylvester}
&\text{det}(\m{I}_{dn}-s^{-1}\m{|S|} \bar{\m{L}}) = \text{det}(\m{I}_{dm}-s^{-1}\sqrt{\overline{\m{W}}}\bar{\m{H}}\m{|S|} \bar{\m{H}}^\top\sqrt{\overline{\m{W}}}), \nonumber\\
&s^{d(m-n)}\text{det}(s\m{I}_{dn}-\m{|S|} \bar{\m{L}}) = \text{det}(s\m{I}_{dm}-\sqrt{\overline{\m{W}}}\bar{\m{H}}\m{|S|} \bar{\m{H}}^\top\sqrt{\overline{\m{W}}}).
\end{align*}}
Thus, the nonzero eigenvalues of two matrices $\m{M} = \m{|S|} \bar{\m{L}}$ and $\m{N} = \sqrt{\overline{\m{W}}}\bar{\m{H}}\m{|S|} \bar{\m{H}}^\top\sqrt{\overline{\m{W}}}$ are the same. Since $\m{|S|}$ and $\sqrt{\overline{\m{W}}}$ are positive definite, $\forall \m{y} \in \mb{R}^{dm}$, $\m{y}^{\top}\m{N}\m{y}= \frac{1}{2}\m{y}^{\top}(\m{N}+\m{N}^\top)\m{y} = \frac{1}{2}\m{y}^{\top}\sqrt{\overline{\m{W}}}\bar{\m{H}}(\m{|S|} + \m{|S|}^\top)\bar{\m{H}}^\top \sqrt{\overline{\m{W}}}\m{y} \geq 0$. Therefore, $\m{N}$, and thus $\bm{\Omega}$, have $dn-d$ eigenvalues with positive real parts.\footnote{It is noted that ker$(\m{N})$=ker$(\bar{\m{H}}^\top\sqrt{\overline{\m{W}}})$, and ker$(\bar{\m{H}}^\top\sqrt{\overline{\m{W}}})$ is referred to as the cycle space of $\mc{G}$.} Finally, the claim on ker$(\bm{\Omega})$ follows by direct computation.
\end{IEEEproof}
% The next sections will propose and analyze matrix-scaled consensus laws for the $n$-agent system. 

%The following remark gives a refined estimation of the locations of the eigenvalues of the matrix $\bm{\Omega}$.
\begin{remark} \label{rem:2.1}
We will refer to $\bm{\Omega}$ as {the} matrix-scaled Laplacian since its structure resembles a Laplacian with block matrix weights \cite{Trinh2018matrix}. 
%More specifically, $\bm{\Omega}=[\bm{\Omega}_{ij}]$ has the $ij$-th block matrix weight $\bm{\Omega}_{ij}=\text{sign}(\m{S}_i)l_{ij}\m{S}_j$, $i,j=1,\ldots, n$. Using the Gerschgorin's theorem for block matrix \cite{FeingoldVarga1962} for each block column of $\bm{\Omega}$, we have $\|(l_{ii}|\m{S}_i|-\lambda\m{I}_d)^{-1}\|^{-1} \leq \sum_{i=1,i\neq j}^n l_{ij}\|\m{S}_i\|$ or $\|(d_{i}|\m{S}_i|-\lambda\m{I}_d)^{-1}\|^{-1} \leq d_i \|\m{S}_i\|$, where $d_i = \sum_{j\in \mc{N}_i} w_{ij}$ is the degree of vertex $i$. Thus, the eigenvalues of the matrix $\bm{\Omega}$ are contained in the union of $n$ Gerschgorin sets \[C_i = \{\lambda\in \mb{C}|~\|(\lambda\m{I}_d -d_i|\m{S}_i|)^{-1}\|^{-1}\leq d_i \|\m{S}_i\|\}.\]
If we further assume that $\m{S}_i=\m{S}_i^\top,~\forall i = 1,\ldots,n$, based on \cite{Ostrowski1959}[Thm. 3], all eigenvalues $\Lambda_1,\ldots,\Lambda_{dn}$ of $\bm{\Omega}$ are real and 
    \begin{align} \label{eq:eigenvalue_omega}
    \begin{split}
        \Lambda_1 &= \ldots=\Lambda_d = 0,\\
        \Lambda_k &= \theta_k \lambda_{\lceil k/d\rceil},~k=d+1,\ldots,dn,
    \end{split}
    \end{align}
where $\lceil x \rceil$ denotes the closest natural number that is greater than or equal to $x$, $\lambda_k$ is the $k$-smallest eigenvalue of $\m{L}$ and $\theta_k \in [p_{\min},p_{\max}]$, $p_{\min}$ and $p_{\max}$ are respectively the smallest and the largest eigenvalue of all $|\m{S}_i|$.

For example, consider $\mc{G} = \mc{C}_6$ - the cycle of length six, and $\m{S}_i$ are given as {\small $\m{S}_1=\m{S}_2= \begin{bmatrix}
        2 & -\frac{\sqrt{3}}{4}\\
        -\frac{\sqrt{3}}{4} & \frac{7}{4}
    \end{bmatrix},~\m{S}_3=\m{S}_4 = \begin{bmatrix}
        2 & 0\\
        0 & 1
    \end{bmatrix},~
    \m{S}_5=\m{S}_6 = \begin{bmatrix}
        -3 & 0\\
        0 & -1
    \end{bmatrix}.$} 
Then, $0=\lambda_1<\lambda_2=\lambda_3=1<\lambda_4=\lambda_5=3<\lambda_6=4$, $p_{\min}=0.5$, $p_{\max}=3$, and the eigenvalues of $\bm{\Omega}$ are $\{0,~0,~1.059,~1.264,~2.088,2.387,3.406,3.477,~5.051,~6.657,$
$~7.388,~10.222\}$, which all belong to the interval $[0.5,~12]$.
\end{remark}

\section{Matrix-scaled consensus algorithms for a network of single-integrator agents}
\label{sec:single_integrator}
\subsection{Matrix-scaled consensus of single-integrators}
% 
We firstly consider the ideal case, where agents are modeled by single integrators. The matrix-scaled consensus algorithm is proposed as follows
\begin{align} \label{eq:msc_single_integrator}
\dot{\m{x}}_i &=\m{u}_i = - \text{sign}(\m{S}_i) \sum_{j \in \mc{N}_i} (\m{S}_i\m{x}_i - \m{S}_j \m{x}_j),\, i=1,\ldots,n.
\end{align}
The asymptotic behavior of the system \eqref{eq:msc_single_integrator} is summarized in the following theorem. 
\begin{theorem} \label{thm:msc_single_integrator} Let the graph $\mc{G}$ be connected. Under the algorithm \eqref{eq:msc_single_integrator}, $\m{x}(t)$ exponentially converges to a point in $\mc{C}_S$.
\end{theorem}
\begin{IEEEproof}
The system can be expressed in the matrix form as follows:
\begin{align}
\dot{\m{x}} = - \bm{\Omega} \m{x}.
\end{align}
Let $\m{V} = [\m{v}_1,\ldots,\m{v}_{dn}]$ and $\m{V}^{-1}=\m{Z}^\top$ be real invertible matrices such that $\m{V}_{[1:d]}=\m{S}^{-1}(\m{1}_n\otimes \m{P})$, $\m{Z}_{[1:d]}=(\text{sign}(\m{S})\m{1}_n\otimes \m{I}_d)$, where $\m{P} \in \mb{R}^{d\times d}$ has yet to be determined.\footnote{$\m{V}_{[k:r]}, k<r,$ denotes a sub-matrix containing columns $k,\ldots,r$ of $\m{V}$.} Since $\m{V}^{-1}\m{V}=\m{I}_{dn}$, we have 
%\begin{align}
$ (\m{1}_n^\top \text{sign}(\m{S})\otimes \m{I}_d) \m{S}^{-1}(\m{1}_n\otimes \m{I}_d) \m{P} = (\m{1}_n^\top\otimes \m{I}_d)|\m{S}|^{-1}(\m{1}_n\otimes \m{I}_d)\m{P} = \m{I}_d$, which implies that 
$\m{P} = \left(\sum_{i=1}^n |\m{S}_i|^{-1}\right)^{-1}.$ 
%\end{align}
Moreover, 
\begin{align}
(\m{1}_n^\top \text{sign}(\m{S})\otimes \m{I}_d) \m{V}_{[d+1:dn]} = \m{0}_{d\times d(n-1)}.
\end{align}
Thus, we can express
{\small
\begin{align}
\m{V}^{-1}\bm{\Omega}\m{V} = \begin{bmatrix}
\m{0}_{d\times d} & \m{0}_{d\times d(n-1)}\\
\m{0}_{d(n-1)\times d} & \bm{\Omega}'
\end{bmatrix},
\end{align}}
where $\bm{\Omega}'= \m{Z}_{[d+1:d(n-1)]}^\top \bm{\Omega} \m{V}_{[d+1:dn]}$ is Hurwitz. Note that we can always find $\m{V}$ with real entries. From linear control theory, we have $\m{x}(t) = \text{exp}(-\bm{\Omega}' t) \m{x}(0) = \m{V} \begin{bmatrix}
\m{I}_{d} & \m{0}_{d\times d(n-1)}\\
\m{0}_{d(n-1)\times d} & \text{exp}(-\bm{\Omega}' t)
\end{bmatrix} \m{V}^{-1} \m{x}(0),$ and thus,
{\small
\begin{align}
\lim_{t\to\infty} \m{x}(t) &= \m{V} \begin{bmatrix}
\m{I}_{d} & \m{0}_{d\times d(n-1)} \nonumber\\
\m{0}_{d(n-1)\times d} & \m{0}_{d(n-1)\times d(n-1)}
\end{bmatrix} \m{V}^{-1} \m{x}(0),\nonumber\\
&= \m{S}^{-1}(\m{1}_n\otimes \m{I}_d) \m{P} (\m{1}_n^\top \text{sign}(\m{S})\otimes \m{I}_d) \m{x}(0)\nonumber \\
&= \m{S}^{-1} (\m{1}_n\otimes \m{x}^a),
\end{align}}
where $\m{x}^a:= \m{P} \sum_{i=1}^n \text{sign}(\m{S}_i)\m{x}_i(0)$ and the convergence rate is exponential. It follows that $\m{x}(t) \to \m{S}^{-1}(\m{1}_n\otimes\m{x}^a) \in \mc{C}_S$, as $t\to \infty$.
\end{IEEEproof}

%\begin{remark} \label{rem:lyap_msc} Note that as discussed in \cite{Trinh2022matrix}, the proof that $\lim_{t\to\infty}\m{x}(t)=\m{S}\m{x}^a$ can be shown by considering the Lyapunov candidate function $V=\m{x}^\top\m{S}^\top(\m{L}\otimes \m{I}_d)\m{S}\m{x}$.
%\end{remark}

\begin{remark} Let $\m{f}: \mb{R}^N \to \mb{R}^N\,(N\in\mb{N}_+)$ be a {Lipschitz continuous} function that satisfies
%\begin{align} \label{eq:nonlinear-interaction}
$\m{y}^\top\m{f}(\m{y}) > \m{0},~\forall \m{0}_N\neq \m{y}\in \mc{D} \subseteq \mb{R}^N,\, \m{0}_d \in \mc{D},~\m{f}(\m{0}_N)=\m{0}_N.$ 
%\end{align}
Consider the following nonlinear MSC algorithm
\begin{align} \label{eq:msc_nonl}
    {\m{u}}_i = -\text{sign}(\m{S}_i) \sum_{j\in \mc{N}_i} \m{f}(\m{S}_i\m{x}_i-\m{S}_j\m{x}_j),~i=1,\ldots,n.
\end{align}
The matrix-scaled consensus {system with generalized interaction} \eqref{eq:msc_nonl} can be expressed in matrix form as
\begin{align}
\dot{\m{x}} = -(\text{sign}(\m{S}){\m{H}}^\top\m{W} \otimes \m{I}_d)\m{f}((\m{H}\otimes \m{I}_d)\m{S}\m{x}).
\end{align}
It is not hard to see that $(\m{1}_n^\top\text{sign}(\m{S})\otimes \m{I}_d)\dot{\m{x}} = \m{0}_d$, which implies that $\m{x}^a$ is time-invariant under \eqref{eq:msc_nonl}.

For stability analysis, consider the Lyapunov function $V(\m{x}) = \int_{\m{0}_{dn}}^{\m{x}}\m{f}(\bar{\m{H}}\m{S}\m{y})^\top \bar{\m{W}}\bar{\m{H}}\m{S} d\m{y},$ 
which is positive semidefinite and continuously differentiable in $\mc{D}$. Along any trajectory of \eqref{eq:msc_nonl}, we have
{\small $\dot{V} =-\m{f}(\bar{\m{H}}\m{S}\m{x})^\top \bar{\m{W}}\bar{\m{H}}|\m{S}|\bar{\m{H}}^\top\bar{\m{W}}\m{f}(\bar{\m{H}}\m{S}\m{x}) 
= -\m{f}(\bar{\m{H}}\m{S}\m{x})^\top \bar{\m{W}}\bar{\m{H}}(|\m{S}|+|\m{S}|^\top)\bar{\m{H}}^\top\bar{\m{W}}\m{f}(\bar{\m{H}}\m{S}\m{x}) \leq 0.$}
Based on LaSalle invariance principle, each trajectory of the system approaches the largest invariant set in $\Omega = \{\m{x}|~\dot{V} = 0\}$. Solving $\dot{V}=0$ gives $\bar{\m{H}}^\top\bar{\m{W}}\m{f}(\bar{\m{H}}\m{S}\m{x})=\m{0}$, which further implies $\m{x}^\top\m{S}^\top\bar{\m{H}}^\top\bar{\m{W}}\m{f}(\bar{\m{H}}\m{S}\m{x})={0}$, or $\m{S}\m{x}\in \text{im}(\m{1}_n\otimes \m{I}_d)$. Combining with $\m{x}^a(t)=\m{x}^a(0)$ yields $\m{S}\m{x} \equiv \m{1}_n \otimes \m{x}^a$. Thus, $\m{x}(t) \to \m{S}^{-1}(\m{1}_n\otimes\m{x}^a) \in \mc{C}_S$, as $t\to \infty$.

This result expands the classes of possible interaction functions. For example, if $\|\dot{\m{x}}\|_{\infty}=\|\m{u}\|_{\infty}$ must be upper bounded by a constant $\beta>0$ {for all $t\geq 0$}, we may choose $\m{f}(\cdot)=\frac{\beta}{\max_{i\in \{1,\ldots,n\}}|\mc{N}_i|}\tanh(\cdot)$. Moreover, a larger class of nonlinearly output-coupled systems can be considered, for examples, the Kuramoto oscillators model has $\m{f}(\cdot)=\sin(\cdot)$ and $\mc{D}=\left(-\frac{\pi}{2},\frac{\pi}{2}\right)$.
\end{remark}
\subsection{Adaptive matrix-scaled consensus of single-integrators with parametric uncertainties}
Let each agent be modeled by the single integrator with {uncertain parameters} \eqref{eq:model}. The following adaptive matrix-scaled consensus law is designed based on certainty equivalence {principle}
{\small \begin{subequations}
\begin{align}
\m{u}_i &= - \text{sign}(\m{S}_{i}) \sum_{j\in \mc{N}_i} (\m{S}_{i}\m{x}_i - \m{S}_{j}\m{x}_j) - \bm{\phi}_i(t,\m{x}_i) \hat{\bm{\theta}}_i, \label{eq:AMWC-1}\\
\dot{\hat{\bm{\theta}}}_i &= \gamma_i \bm{\phi}_i(t,\m{x}_i)^\top \m{S}_{i}^\top \sum_{j\in \mc{N}_i} (\m{S}_{i}\m{x}_i - \m{S}_{j}\m{x}_j), \label{eq:AMWC-2}
\end{align}
\end{subequations}}
where $\gamma_i>0$ are adaptive rates, $i=1,\ldots,n$. We can rewrite the system~\eqref{eq:model} under the matrix-scaled consensus algorithm \eqref{eq:AMWC-1}--\eqref{eq:AMWC-2} in matrix form as follows:
{ \begin{subequations}
\begin{align}
\dot{\m{x}} &= -\bm{\Omega}\m{x} +  \text{blkdiag}(\ms{\phi}_1,\ldots,\ms{\phi}_n) (\ms{\theta}  - \hat{\ms{\theta}} ), \label{eq:AMWC-3}\\
\dot{\hat{\ms{\theta}}} & = \text{blkdiag}(\gamma_1\ms{\phi}_1,\ldots,\gamma_n \ms{\phi}_n)^\top\m{S}^\top(\m{L}\otimes \m{I}_d)\m{S}\m{x}, \label{eq:AMWC-4}
\end{align}
\end{subequations}}
where $\m{x} = \text{vec}(\m{x}_1,\ldots,\m{x}_n) \in \mb{R}^{dn}$, $\ms{\theta} = \text{vec}(\ms{\theta}_1,\ldots,\ms{\theta}_n) \in \mb{R}^{nr}$, $\hat{\ms{\theta}} = \text{vec}(\hat{\ms{\theta}}_1,\ldots,\hat{\ms{\theta}}_n) \in \mb{R}^{nr}$, and $\bm{\phi}(t)=\text{blkdiag}(\bm{\phi}_1,\ldots,\bm{\phi}_n) \in \mb{R}^{dn\times dr}$.

\begin{theorem} \label{thm:msc_single_integrator_adaptive} Suppose that the graph $\mc{G}$ is connected and $\bm{\phi}(t)$ is uniformly bounded. Under the adaptive matrix-scaled algorithm \eqref{eq:AMWC-1}--\eqref{eq:AMWC-2}, we have
\begin{enumerate}%[label=(\roman*)]
\item[(i)] $\m{x}(t)\to \mc{C}_S$ and $\bm{\theta}(t) \to \bm{\theta}^*$, as $t\to \infty$, and 
\item[(ii)] if additionally, $\bm{\phi}_i(t)$ is  persistently exciting (PE), i.e., there exist $\mu_1\ge\mu_2>0$, $T>0$ such that for any $t\ge 0$, 
%\begin{align}
$\mu_1\m{I}_d \ge \int_t^{t+T} \ms{\phi}_i(\tau) \ms{\phi}_i(\tau)^\top d\tau \ge \mu_2\m{I}_d,$
%\end{align}
then $\hat{\ms{\theta}}_i(t) \to \ms{\theta}_i,~\forall i=1, \ldots, n,$ as $t\to\infty$.
\end{enumerate} 
\end{theorem}
%

\begin{IEEEproof}
(i) Consider the function $V = \frac{1}{2} \m{x}^\top \m{S}^\top\bar{\m{L}}\m{S}\m{x} + \sum_{i=1}^n \frac{1}{2\gamma_i} (\ms{\theta}_i- \hat{\ms{\theta}}_i)^\top (\ms{\theta}_i- \hat{\ms{\theta}}_i).$ 
Since $\m{S}$ is invertible and $\bar{\m{L}}$ is symmetric, $\m{S}^\top\bar{\m{L}}\m{S}$ has the same number of positive, negative and zero eigenvalues as $\bar{\m{L}}$. It follows that $\m{S}^\top\bar{\m{L}}\m{S}$ is symmetric positive semidefinite. As a result, $V$ is continuously differentiable, positive definite and radially unbounded with regard to $\text{vec}(\sqrt{\overline{\m{W}}}\bar{\m{H}}\m{S}\m{x}, \ms{\theta}- \hat{\ms{\theta}})$. Moreover, $\frac{1}{4}\|\sqrt{\overline{\m{W}}}\bar{\m{H}}\m{S}\m{x}\|^2 + \frac{1}{2\max_{i \in \mc{V}}\gamma_{i}}\|\ms{\theta}- \hat{\ms{\theta}}\|^2 \leq V \leq \|\sqrt{\overline{\m{W}}}\bar{\m{H}}\m{S}\m{x}\|^2 + \frac{1}{2\min_{i \in \mc{V}}\gamma_{i}}\|\ms{\theta}- \hat{\ms{\theta}}\|^2$, and along any trajectory of the system,
\begin{align*}
\dot{V}(t) = -\m{x}^\top \m{S}^\top \bar{\m{L}} \left(|\m{S}|+|\m{S}^{\top}| \right) \bar{\m{L}} \m{S}\m{x} \leq 0,
\end{align*}
which implies that $\|\bar{\m{L}}\m{S}\m{x}\|$, $\|\bm{\theta} - \hat{\bm{\theta}}\|$ are uniformly bounded, and $\lim_{t\to\infty}V(t)$ exists and is finite. As $\bm{\theta}$ is a constant vector, it follows that $\hat{\bm{\theta}}$ is uniformly bounded. Further, $\|\dot{\m{x}}(t)\| \le \|\bar{\m{L}}\m{S}\m{x}(t)\| + \|\text{blkdiag}(\bm{\phi}_1,\ldots,\bm{\phi}_n)\| \|\ms{\theta} - \hat{\bm{\theta}}\|$ is uniformly bounded. Therefore, 
%\begin{align*}
$\ddot{V}(t) = -2 \m{x}^\top \m{S}^\top \bar{\m{L}} \left(|\m{S}|+|\m{S}|^{\top} \right) \bar{\m{L}} \m{S} \dot{\m{x}} 
\le -2 \lambda_{\min}\left(|\m{S}|+|\m{S}|^{\top} \right) \|\bar{\m{L}} \m{S} \m{x}\| \|\bar{\m{L}}\| \|\m{S}\| \|\dot{\m{x}}\|$
%\end{align*}
is also uniformly bounded. It follows from Barbalat's lemma that $\lim_{t\to\infty} \dot{V}(t) = 0$, or $\lim_{t\to\infty} \bar{\m{L}} \m{S} \m{x}(t) = \m{0}_{dn}$. This implies that $\m{S}_i\m{x}_i \to \m{S}_j\m{x}_j$ as $t\to \infty$, or $\m{x}(t)$ approaches the set $\mc{C}_S$ as $t\to\infty$. As $\lim_{t\to\infty} V(t)$ exists and $\lim_{t\to \infty}\m{x}^\top \m{S}^\top \bar{\m{L}} \m{S}\m{x}(t) = {0}$, it follows that $\lim_{t\to \infty}\bm{\theta}(t) = \bm{\theta}^*$ exists and is finite.

(ii) Next, let $\tilde{\ms{\theta}} = \hat{\ms{\theta}} - \ms{\theta}$ and 
$\m{y} = [\m{y}_{\mc{T}}^\top, \m{y}_{\mc{C}}^\top]^\top = \bar{\m{H}} \m{S} \m{x} = \left(\begin{bmatrix} \m{I}_{n-1} \\ \m{T} \end{bmatrix} \otimes \m{I}_d \right) (\m{H}_{\mc{T}}\otimes \m{I}_d)\m{S}\m{x} = \left(\m{R} \otimes \m{I}_d \right) \m{y}_{\mc{T}} = \bar{\m{R}} \m{y}_{\mc{T}},$ 
it follows that
{\small
\begin{subequations}
\begin{align}
%= \bar{\m{H}}_{\mc{T}} \m{S}\dot{\m{x}}
\dot{\m{y}}_{\mc{T}} & =  \ms{\varphi}(\m{y}_{\mc{T}}) + \bar{\m{H}}_{\mc{T}} \m{S} \text{blkdiag}(\ms{\phi}_1,\ldots,\ms{\phi}_n) \tilde{\ms{\theta}}, \label{eq:AMWC-5}\\
\dot{\tilde{\ms{\theta}}} & = \ms{\psi}(t). \label{eq:AMWC-6}
\end{align}
\end{subequations}}
Observe that $\lim_{t\to \infty} \m{y}_{\mc{T}}(t) = \m{0}_{d(n-1)}$, $
\lim_{t\to \infty} \ms{\varphi}(\m{y}_{\mc{T}}(t)) = - \bar{\m{H}}_{\mc{T}} |\m{S}| \lim_{t\to \infty} \bar{\m{L}}\m{S}\m{x}(t) = \m{0}_{d(n-1)}$, 
$\lim_{t\to \infty} \ms{\psi}(t) = -\lim_{t \to \infty} \text{blkdiag}(\gamma_1\ms{\phi}_1,\ldots,\gamma_n\ms{\phi}_n)\m{S}^\top\bar{\m{L}} \m{S} \m{x}= \m{0}_{nr}$, and
{\small
\begin{align*}
W(t)&=\int_t^{t+T} \bar{\m{H}}_{\mc{T}} \m{S} \ms{\phi}_i(\tau) \ms{\phi}_i(\tau)^\top \m{S}^\top \bar{\m{H}}_{\mc{T}}^\top d\tau \\
&= \bar{\m{H}}_{\mc{T}} \m{S} \left( \int_t^{t+T} \ms{\phi}_i(\tau) \ms{\phi}_i(\tau)^\top d\tau \right) \m{S}^\top \bar{\m{H}}_{\mc{T}}^\top 
\end{align*}}
satisfies 
{\small
\begin{subequations}
\begin{align}
\mu_1 \bar{\m{H}}_{\mc{T}}\m{S}\m{S}^\top\bar{\m{H}}_{\mc{T}}^\top \le W(t) \le  \mu_2 \bar{\m{H}}_{\mc{T}}\m{S}\m{S}^\top\bar{\m{H}}_{\mc{T}}^\top,\\ 
\mu_1 \lambda_{\max}(\m{L}_e) \m{I}_{dn} \le W(t) \le  \mu_2 \lambda_{\max}(\m{L}_e) \m{I}_{dn}.
\end{align}
\end{subequations}}
As $\m{L}_e = \bar{\m{H}}_{\mc{T}}\m{S}\m{S}^\top \bar{\m{H}}_{\mc{T}}^\top=\m{L}_e^\top$ is positive semidefinite, rank$(\m{L}_e)$=rank$(\bar{\m{H}}_{\mc{T}})= d(n-1)$, it follows that $\m{L}_e$ is positive definite. Since all conditions of \cite{Besanccon2000remarks}[Lemma A.1] are satisfied, $\lim_{t\to\infty}\tilde{\ms{\theta}}(t) = \m{0}_{nr}$ or $\lim_{t\to\infty}\hat{\ms{\theta}}(t) = {\ms{\theta}}$.
\end{IEEEproof}


\section{Matrix-scaled consensus algorithms for a network of linear dynamical agents}
\label{sec:linear_agents}
%\cite{Mei2018model}
%\cite{Nguyen2022VCCA}
%\cite{Nguyen2022adaptive,Trinh2022adaptive}
In this section, we firstly propose two matrix scaled consensus algorithms for the simplified general linear models \eqref{eq:homogeneous_linear} and \eqref{eq:heterogeneous_linear}. The proposed algorithms and stability analyses in Subsection \ref{subsec:4.1} prepare for Subsections \ref{subsec:4.2} and \ref{subsec:4.3}, where the general linear models \eqref{eq:homogeneous_linear} and \eqref{eq:heterogeneous_linear} will be considered. 

\subsection{Simplified linear agents}
\label{subsec:4.1}
\subsubsection{The agents' dynamics are identical}
\label{sss:1}
Let the agents {be} modeled by \eqref{eq:homogeneous_linear} with $\m{B}=\m{I}_d$. We assume that each agent has information on the state variable $\m{x}_i$ and exchanges the matrix-scaled state $\m{S}_i\m{x}_i$ with its neighboring agents. The following matrix-scaled consensus algorithm is proposed
\begin{align}
\m{u}_i = -c \text{sign}(\m{S}_i) \sum_{j \in\mc{N}_i} (\m{S}_i\m{x}_i - \m{S}_j \m{x}_j),~i=1,\ldots,n,
\end{align}
where $c>0$ is a coupling gain. 
% The dynamics of each agent can be written as follows
%\begin{align} \label{eq:simple_homo_agents_i}
%\dot{\m{x}}_i = \m{A}\m{x}_i - c \text{sign}(\m{S}_i)\sum_{j \in\mc{N}_i} (\m{S}_i\m{x}_i - \m{S}_j \m{x}_j),
%\end{align}
%for $i=1,\ldots,n$. 
The $n$-agent system can be written in matrix form as
\begin{align} \label{eq:simple_homo_allagents}
\dot{\m{x}} = (\m{I}_n\otimes \m{A} - c \bm{\Omega})\m{x}.
\end{align}

For stability analysis of the system \eqref{eq:simple_homo_allagents}, the following lemma whose proof is given in Appendix \ref{append:A} will be used.
\begin{lemma}\label{lem:matrix_stability} Let $\bm{\Theta}$ be a Hurwitz matrix, $\bm{\Delta}_{\Theta}$ is a perturbation matrix of the same dimension with $\|\bm{\Delta}_{\Theta}\|=\delta_{\Theta}$, and $\m{Q}=\m{Q}^\top>0$ is the unique solution to the Lyapunov equation $\m{Q}\bm{\Theta}+\bm{\Theta}^\top\m{Q} = - \m{I}$. For any $c > 2\delta_{\Theta} \lambda_{\max}(\m{Q})$, the matrix $c\bm{\Theta}+\bm{\Delta}_{\Theta}$ is Hurwitz.
\end{lemma}

Let $\m{y} = \m{V}^{-1}\m{x} \in \mb{R}^{dn}$, and define $\m{y}_{[k:r]} = [y_k,y_{k+1},\ldots,y_r]^\top$, for $k<r$, it follows that
%\begin{align}
$\dot{\m{y}}_{[1:d]}=(\m{1}_n^\top\text{sign}(\m{S}))\otimes \m{I}_d) (\m{I}_n\otimes \m{A} - c \bm{\Omega})\m{V}\m{y}  
=\m{A} \m{y}_{[1:d]},$ 
%\label{eq:simple_homo_agents_matrix1}\end{align}
and
{\small
\begin{align}
&\dot{\m{y}}_{[d+1:dn]}=\underbrace{\left(\m{Z}_{[d+1:dn]}^\top(\m{I}_n\otimes \m{A})\m{V}_{[d+1:dn]}-c\bm{\Omega}'\right)}_{:=\bm{\Theta}_c}\m{y}_{[d+1:dn]}. \nonumber
\end{align}}
We have the following theorem on the system  \eqref{eq:simple_homo_allagents}:
\begin{theorem} \label{thm:simple_homo_agents}
Suppose that the graph $\mc{G}$ is connected. Let $\m{Q}=\m{Q}^\top>0$ be the unique solution of the Lyapunov equation $\m{Q}{\bm{\Omega}'}+(\bm{\Omega}')^\top\m{Q} = -\m{I}_{d(n-1)}$ and $c> 2\|\m{A}\| \lambda_{\max}(\m{Q})$. Then, $\m{x}(t) \to \mc{C}_S$, as $t\to\infty$. 
\end{theorem}

\begin{IEEEproof}
We have $\|\m{Z}_{[d+1:dn]}^\top(\m{I}_n\otimes \m{A})\m{V}_{[d+1:dn]}\| \leq \|\m{V}^{-1}(\m{I}_n\otimes \m{A})\m{V}\|=\|\m{I}_n\otimes \m{A}\| = \|\m{A}\|$. Based on Lemma~\ref{lem:matrix_stability}, the matrix $\bm{\Theta}_c$ is Hurwitz. It follows that $\m{y}_{[d+1:dn]}$ globally exponentially  converges to $\m{0}_{d(n-1)}$.

The solution of \eqref{eq:simple_homo_allagents} is $\m{x}(t)= \m{V}\m{y}(t)=\m{V}
\text{blkdiag}(\text{exp}(\m{A}t),
\text{exp}(\bm{\Theta}_c t)) \m{y}(0)
= \m{S}^{-1}(\m{1}_n\otimes \m{P})\text{exp}(\m{A}t) (\m{1}_n^\top \text{sign}(\m{S})\otimes \m{I}_d)\m{x}(0) +\bm{\xi}(t),$ 
where $\bm{\xi}(t)=\m{V}_{[d+1:dn]} \text{exp}(\bm{\Theta}_c t)\m{Z}_{[d+1:dn]}^\top\m{x}(0) \to \m{0}_{dn}$ exponentially fast. Thus, $\lim_{t\to\infty} (\m{x}_i(t)-\m{S}_i^{-1}\m{P}\text{exp}(\m{A}t)\m{P}^{-1}\m{x}^a) = \m{0}_d,~\forall i=1,\ldots,n,$ or $\m{x}(t)\to \mc{C}_S$, as $t\to\infty$. 
\end{IEEEproof}

\subsubsection{Simplified heterogeneous linear agents with unknown system matrix and full control input}
\label{sss:2}
In this subsection, we design an adaptive matrix-scaled consensus law for a system of heterogeneous linear dynamics with full control input
\begin{equation} \label{eq:linear_model}
\dot{\m{x}}_i = \m{A}_i \m{x}_i + \m{u}_i,
\end{equation}
where $\m{A}_i \in \mb{R}^{d\times d}$ is unknown to each agent $i$. Let $\m{A}_i = \m{A} + (\m{A}_i-\m{A}) = \m{A} + \bar{\m{A}}_i$, where $\m{A}$ is a pre-selected matrix such that $\m{W}_{d+1:dn}^\top\otimes \m{A}\m{V}_{[d+1:dn]} - c\bm{\Omega}'$ is Hurwitz. 

{Let the $k$-th row of the matrix $\bar{\m{A}}_i$ be denoted by $\bar{\m{A}}_{ik}$}, we have the representation \cite{Burbano2019distributed}:
{\small
\begin{equation*}
\bar{\m{A}}_i \m{x}_i = \begin{bmatrix}
\bar{\m{A}}_{i1}^\top \m{x}_i\\
\vdots \\
\bar{\m{A}}_{in}^\top \m{x}_i
\end{bmatrix} 
= \begin{bmatrix}
\m{x}_i^\top \bar{\m{A}}_{i1} \\
\vdots \\
\m{x}_i^\top \bar{\m{A}}_{id} 
\end{bmatrix} = (\m{I}_d \otimes \m{x}_i^\top) \text{vec}(\bar{\m{A}}_i).
\end{equation*}}

By setting $\ms{\phi}_i := \m{I}_d \otimes \m{x}_i^\top \in \mb{R}^{d\times d^2}$ and $\ms{\theta}_i:=\text{vec}(\bar{\m{A}}_i)$, the linear model \eqref{eq:linear_model} is transformed into the single-integrator with uncertain parameters \eqref{eq:model}. 

To make the system achieves matrix-scaled consensus, the effect of the uncertainty should be compensated faster than the evolution of $\|\m{x}\|$ (exponential rate). The matrix-scaled consensus algorithm is proposed as follows
{\small
\begin{subequations} \label{eq:msc_dtb_obsv}
\begin{align}
    \dot{\m{z}}_i &= \m{A}\m{x}_i - c \text{sign}(\m{S}_i)\sum_{j\in\mc{N}_i}(\m{S}_i\m{x}_i-\m{S}_j\m{x}_j),\\
    \m{u}_i &= - c \text{sign}(\m{S}_i)\sum_{j\in\mc{N}_i}(\m{S}_i\m{x}_i-\m{S}_j\m{x}_j) +\beta_1 \text{sgn}(\m{e}_i)\nonumber\\
    &\qquad  + \beta_2 \text{diag}(\text{sgn}(\m{e}_i))(\m{I}_d\otimes |\m{x}_i|^\top)\m{1}_{d^2},
\end{align}
\end{subequations}}
where $|\m{x}_i| := [|x_{i1}|,\ldots,|x_{id}|]^\top$, $\m{e}_i = {\m{z}}_i - \m{x}_i,$ $\beta_1, \beta_2 >0$ are control gains, and sgn$(\cdot)$ denotes the signum function, defined as sgn$(x)=1$ if $x>0$, sgn$(x)=-1$ if $x<0$, and sgn$(x)=0$ if $x=0$. The following theorem will be proved.

\begin{theorem} \label{thm:msc_dtb_obsv}
    Let $\mc{G}$ be connected and $\beta_2\geq \max_i\|\text{vec}(\m{\bar{A}}_i)\|_{\infty}$. Under the algorithm \eqref{eq:msc_dtb_obsv}, $\m{x}(t) \to \mc{C}_S$ as $t\to \infty$.
\end{theorem}

\begin{IEEEproof}
We have $\dot{\m{e}}_i = \bar{\m{A}}_i\m{x}_i - \beta_1 \text{sgn}(\m{e}_i) - \beta_2 \text{sgn}(\m{e}_i)(|\m{x}_i|^\top \otimes \m{I}_d) \m{1}_{d^2} = - \beta_1 \text{sgn}(\m{e}_i) + \ms{\phi}_i(t) \bm{\theta}_i - \beta_2 \text{diag}(\text{sgn}(\m{e}_i))(\m{I}_d \otimes |\m{x}_i|^\top) \m{1}_{d^2}.$ As the right-hand side of the above equation is discontinuous, the solution of  $\m{e}_i$ is understood in Filippov sense. Using the Lyapunov function $V=\frac{1}{2}\|\m{e}_i\|^2$, we have
{\small
\begin{align}
&\dot{V} \in^{\text{a.e.}} \tilde{V} = \bigcap_{\bm{\nu}\in \partial V} \bm{\nu}^\top K[\dot{\m{e}}_i] \nonumber\\
    &= \m{e}_i^\top \Big(-\beta_1 \text{sgn}(\m{e}_i) - \beta_2 \text{diag}(\text{sgn}(\m{e}_i))(|\m{x}_i|^\top \otimes \m{I}_d) \m{1}_{d^2} + \ms{\phi}_i(t) \bm{\theta}_i \Big) \nonumber\\
    &\leq -\beta \|\m{e}_i\|_1 - \beta_2 \sum_{k=1}^d|\m{e}_{ik}| \|\m{x}_i\|_{1} + \sum_{k=1}^d |\m{e}_{ik}| \|\m{x}_i\|_{1} \|\bm{\theta}_i\|_{\infty} \nonumber\\
    & \leq -\beta \|\m{e}_i\|_1 \leq - \epsilon V^{1/2},
\end{align}}
for $\epsilon= \beta\sqrt{2}$, and this implies that $V(t)\to 0$ in finite time \cite{Nguyen2022mca,Moreno2012strict}. Therefore, there exists $T>0$ such that $\m{e}_i = \m{0}_d$ or $\m{x}_i = \m{z}_i$ for $t\geq T$. For $t\geq T$, $\m{x}_i$ dynamics becomes the simplified homogeneous linear agent \eqref{eq:simple_homo_allagents}. Thus, the system eventually achieves a matrix-scaled consensus.
\end{IEEEproof}

%It should be noted that in practice, it is hard to perfectly realize the signum function due to two reasons: (i) the exact switching time is hard to determine, and (ii) real actuators have inertia, which cause delays. The chattering effect may wear-out mechanical parts and could be avoided by using saturation function, however, the trade-off is that we can only guarantee $\|\m{e}_i\|$ be be bounded by some prespecified upper bound.

\subsection{Homogeneous general linear agents}
\label{subsec:4.2}
In this subsection, we consider the $n$-agent system with identical general linear model \eqref{eq:homogeneous_linear}. The following observer-based  matrix-scaled consensus algorithm is proposed
{\small
\begin{subequations}
\label{eq:homo_obsv}
\begin{align}
&\dot{\hat{\m{x}}}_i = \m{A}\hat{\m{x}}_i +  \m{B}\m{u}_i + \m{H}(\m{C}{\hat{\m{x}}}_i-\m{y}_i), \label{eq:homo_obsv_i1}\\
&\dot{\bm{\eta}}_i = \m{A}{\bm{\eta}}_i + \m{B}\m{u}_i + \m{H}(\m{C}{\hat{\m{x}}}_i-\m{y}_i) \nonumber\\&\qquad + c\text{sign}(\m{S}_i) \sum_{j\in \mc{N}_i}(\m{S}_i(\hat{\m{x}}_i -\bm{\eta}_i)+ \m{S}_j(\hat{\m{x}}_j - \bm{\eta}_j)), \label{eq:homo_obsv_i2}\\
&\m{u}_i = \m{K} \bm{\eta}_i,\, i=1,\ldots, n, \label{eq:homo_obsv_i4}
\end{align}
\end{subequations}}
where the matrices $\m{H}$ and $\m{K}$ are designed so that $\m{A}+\m{H}\m{C}$ and $\m{A}+\m{B}\m{K}$ are Hurwitz, and $c>0$ is a coupling gain. 

In the proposed algorithm, \eqref{eq:homo_obsv_i1} is a Luenberger observer used to estimate the state $\m{x}$. The matrix-scaled consensus algorithm is conducted via the auxiliary state ${\bm{\zeta}}_i=\hat{\m{x}}_i-\bm{\eta}_i$. It is worth noting that $c\text{sign}(\m{S}_i)(\m{S}_i(\hat{\m{x}}_i -\bm{\eta}_i)+ \m{S}_j(\hat{\m{x}}_j - \bm{\eta}_j))=c\text{sign}(\m{S}_i)(\m{S}_i\bm{\zeta}_i - \m{S}_j\bm{\zeta}_j)$ acts as a proportional control input for the scaled consensus process. When the coupling gain $c$ is sufficiently large, it becomes a high-gain controller and the auxiliary variables are forced to synchronize in matrix scale to a solution of the system $\dot{\bm{\zeta}}_0 = \m{P}\m{A}\m{P}^{-1}{\bm{\zeta}}_0$. Finally, the state variables $\m{x}_i$ achieve a matrix-scaled consensus by forcing $\m{\bm{\eta}}_i$ converge to $\m{0}_d$ under the control law \eqref{eq:homo_obsv_i4}.

For stability analysis, from Eq.~\eqref{eq:homo_obsv}, we can write
{\small\begin{subequations}
\begin{align}
\dot{\tilde{\m{x}}}_i &= (\m{A}+\m{H}\m{C}){\tilde{\m{x}}}_i,\\
\dot{\bm{\zeta}}_i &= \m{A}{\bm{\zeta}}_i-c\text{sign}(\m{S}_i)\sum_{j\in \mc{N}_i} (\m{S}_i\bm{\zeta}_i - \m{S}_j\bm{\zeta}_j),~i=1,\ldots,n,
\end{align}
\end{subequations}}
where $\tilde{\m{x}}_i = \hat{\m{x}}_i - \m{x}_i$. Denoting $\bm{{\tilde{\m{x}}}}=\text{vec}({\tilde{\m{x}}}_1,\ldots,{\tilde{\m{x}}}_n)$, ${\bm{\zeta}}=\text{vec}({\bm{\zeta}}_1,\ldots,{\bm{\zeta}}_n)$, and ${\bm{\eta}}=\text{vec}({\bm{\eta}}_1,\ldots,{\bm{\eta}}_n)$, we prove a theorem regarding the  system
{\small
\begin{subequations}
\begin{align}
\dot{\tilde{\m{x}}} &=\m{I}_n\otimes(\m{A}+\m{H}\m{C}) \tilde{\m{x}}, \label{eq:tildex_matrix}\\
\dot{\bm{\zeta}} &= (\m{I}_n\otimes \m{A}-c\bm{\Omega}){\bm{\zeta}}, \label{eq:zeta_matrix}\\
\dot{\bm{\eta}} &= (\m{I}_n\otimes (\m{A}+\m{B}\m{K})){\bm{\eta}} + c(\m{I}_n\otimes(\m{H}\m{C})) \tilde{\m{x}}+\bm{\Omega}{\bm{\zeta}}. \label{eq:eta_matrix}
\end{align}
\end{subequations}}

\begin{theorem} \label{thm:homo_general_linear}
Suppose that $\mc{G}$ is connected, $\m{A}+\m{H}\m{C}$ and $\m{A}+\m{B}\m{K}$ are Hurwitz, and the control gain $c$ is chosen so that $\bm{\Theta}_c = \m{Z}_{[d+1:dn]}^\top(\m{I}_n\otimes \m{A})\m{V}_{[d+1:dn]}-c\bm{\Omega}'$ is Hurwitz. Under the algorithm \eqref{eq:homo_obsv}, $\m{x}(t) \to \mc{C}_S$ as $t \to \infty$. Each trajectory of $\m{x}_i(t),~i=1,\ldots,n,$ differs from a common solution of $\dot{\bm{\zeta}}_0 = \m{P}\m{A}\m{P}^{-1}\bm{\zeta}_0$ by the scaling matrix {$\m{S}_i^{-1}$}.
%More specifically, $\m{x}_i$ eventually reaches to a matrix-scaled solution of the system $\dot{\bm{\zeta}}_0 = \m{P}\m{A}\m{P}^{-1}\bm{\zeta}_0$.
\end{theorem}

\begin{IEEEproof}
(i) Because $\m{A}+\m{H}\m{C}$ is Hurwitz, ${\tilde{\m{x}}}$ converges to $\m{0}_{dn}$ exponentially fast.

(ii) It follows from Thm.~\ref{thm:simple_homo_agents} that $\bm{\zeta}(t)$ exponentially converges to $\mc{C}_S$. More specifically, 
%\begin{align}
$\lim_{t\to\infty} (\bm{\zeta}_i(t)-\m{S}_i^{-1}\m{P}\text{exp}(\m{A}t)\m{P}^{-1}\bm{\zeta}^a) = \m{0}_d,~\forall i=1,\ldots,n$, and $\bm{\zeta}^a = (\m{1}_n^\top \text{sign}(\m{S})\otimes \m{P})\bm{\zeta}(0)= \m{P} \sum_{i=1}^n \text{sign}(\m{S}_i)\bm{\zeta}_i(0)$.

(iii) Consider equation \eqref{eq:eta_matrix} with $\tilde{\m{x}}=\m{0}_{dn}$ and $\bm{\zeta} \in \mc{C}_S$, we have the unforced system $\dot{\bm{\eta}} = (\m{I}_n\otimes (\m{A}+\m{B}\m{K})) \bm{\eta}$. 
As $\m{A}+\m{B}\m{K}$ is Hurwitz, the unforced system is globally exponentially stable, and \eqref{eq:eta_matrix} is input-to-state stable \cite{Khalil2015nonlinear}. As the external input $(\m{I}_n\otimes(\m{H}\m{C})) \tilde{\m{x}}+\bm{\Omega}{\bm{\zeta}}$ converges to $\m{0}_{dn}$ exponentially fast according to (i) and (ii),  ${\bm{\eta}} \to \m{0}_{dn}$ exponentially fast.

(iv) Finally, as $\bm{\zeta} = \hat{\m{x}} - \bm{\eta}= \m{x}-\tilde{\m{x}}-\bm{\eta}$, $\lim_{t\to\infty}\bm{\eta} = \lim_{t\to\infty}\tilde{\m{x}} = \m{0}_{dn}$, we conclude that 
%\begin{align}
$\lim_{t\to\infty} (\m{x}_i(t)-\m{S}_i^{-1}\m{P}\text{exp}(\m{A}t)\m{P}^{-1}\bm{\zeta}^a) = \m{0}_d,~\forall i=1,\ldots,n$.
%\end{align}
%for $i=1,\ldots,n.$ 
Thus, $\m{x}(t)\to \mc{C}_S$, as $t\to \infty$, and the convergence rate is exponential.
% We can think of the $\bm{\eta}$-system as a perturbed system
%Consider \eqref{eq:eta_matrix}, as in the previous subsection, we can uniquely decompose ${\bm{\zeta}} = {\bm{\zeta}}^{\perp} + {\bm{\zeta}}^{||}$, where ${\bm{\zeta}}^{||} \in \text{im}(\m{1}_n\otimes \m{I}_d)$ and ${\bm{\zeta}}^{\perp} \perp \text{im}(\m{1}_n\otimes \m{I}_d)$. Thus, we have
%Next, the matrix $\bm{\Omega}$ is similar to $\m{M} = \m{S}\bm{\Omega}\m{S}^{-1}=|\m{S}|(\m{L}(\m{c})\otimes \m{I}_d)$, where $\m{L}(\m{c})=\text{sign}(\m{S})(\m{H}^\top\text{diag}(w_{ij}c_{ij}(t)\m{H}\otimes \m{I}_d)$. Due to the symmetry of $\m{S}$, the matrix $|\m{S}|$ is symmetric positive definite. 
%Let $0=\lambda_1 < \lambda_2(\m{c}) \leq \ldots \leq \lambda_{n}(\m{c})$, and $0<\mu_1\leq \mu_2 \leq \ldots \leq \mu_{dn}$ be the eigenvalues of $\m{L}(\m{c})$ and $|\m{S}|$, respectively. According to \cite{Ostrowski1959}[Thm. 3] and Lemma~\ref{lem:omega}, let $\Lambda_1\leq \ldots \leq \Lambda_{dn}$ be the eigenvalues of $\m{M}$ (and also of $\bm{\Omega}$), then
%\begin{subequations}
%\begin{align}
%\Lambda_1&=\ldots = \Lambda_{d} = 0, \\
%\Lambda_{k} &= \theta_{k} \lambda_k>0,~k=d+1,\ldots,dn,
%\end{align}
%\end{subequations}
%where $\theta_k$ lies between $\mu_1$ and $\mu_{dn}$. As the smallest positive eigenvalue $\lambda_2$ of $\m{L}$ is a non-decreasing function of $c_{ij}(t)$, it follows that $\Lambda_{d+1}$ is also a non-decreasing function of $c_{ij}(t)$. Notice that $\bm{\Omega}'$ contains all positive eigenvalues of $\bm{\Omega}$, and $\bm{\Omega}+\bm{\Omega}^\top$ is symmetric positive semidefinite due to Lemma~\ref{lem:omega}, the smallest eigenvalue of $\bm{\Omega}'$ is also non-decreasing function of $c_{ij}(t)$, and $\bm{\Omega}'+(\bm{\Omega}')^\top$ is symmetric positive definite.  
%
%Thus, given a positive number $c>0$, there exists $c^*$ such that if $c_{ij}(t)>c^*,~\forall (i,j) \in \mc{E}$, we have %$\Lambda_{d+1}(\m{c}=c^*\m{1}_m)$
%%
%%
%%as $\bm{\Omega}'(\m{c}) = \m{W}_{d+1:d(n-1)}^\top(\text{sign}(\m{S})\m{H}^\top\text{diag}(w_{ij}c_{ij}(t))_{(i,j)\in \mc{E}} \m{H}\otimes \m{I}_d)\m{S} \m{V}_{[d+1:dn]}$ is Hurwitz, there exists $c^*$ such that for ${c}_{ij} \geq c^*$, we have
%\begin{align}
%\m{W}_{d+1:d(n-1)}^\top(\m{I}_n\otimes \m{A})\m{V}_{[d+1:dn]} - \bm{\Omega}'(\m{c}=c^*\m{1}_m)
%\end{align}
%is Hurwitz.
%
%Consider the Lyapunov function $V(\bm{\zeta},\m{c})=\frac{1}{2}\bm{\zeta}^\top |\m{S}|\bm{\zeta} + \frac{1}{2}\sum_{(i,j)\in \mc{E}} (c_{ij}-c)^2$, where $c>2\|\m{S}\|_2\|\m{A}+\m{A}^\top\|_2$. We have
%\begin{align}
%\dot{V} &= \bm{\zeta}^\top|\m{S}|(\m{I}_n\otimes(\m{A}+\m{A}^\top))\bm{\zeta} - \bm{\zeta}^\top\m{S}(\m{L}(\m{c})\otimes \m{I}_d)\m{S}\bm{\zeta} \nonumber\\
%&\qquad + \sum_{(i,j)\in \mc{E}} (c_{ij}(t)-c) \|\m{S}_i \bm{\zeta}_i - \m{S}_j \bm{\zeta}_j\|^2 \nonumber \\
%&= \bm{\zeta}^\top|\m{S}|(\m{I}_n\otimes(\m{A}+\m{A}^\top))\bm{\zeta} - \sum_{(i,j)\in \mc{E}} c_{ij}(t)\|\m{S}_i \bm{\zeta}_i - \m{S}_j \bm{\zeta}_j\|^2 \nonumber\\
%&\qquad + \sum_{(i,j)\in \mc{E}} (c_{ij}(t)-c) \|\m{S}_i \bm{\zeta}_i - \m{S}_j \bm{\zeta}_j\|^2 \nonumber \\
%&\leq 2\|\m{S}\|_2\|\m{A}+\m{A}^\top\|_2 \|\bm{\zeta}\|^2 - c\sum_{(i,j)\in \mc{E}} \|\m{S}_i \bm{\zeta}_i - \m{S}_j \bm{\zeta}_j\|^2 \nonumber\\
%&\leq 2\|\m{S}\|_2\|\m{A}+\m{A}^\top\|_2 \|\bm{\zeta}\|^2 - c \bm{\zeta}^\top\m{S}(\m{L}\otimes \m{I}_d)\m{S}\bm{\zeta}
%\end{align}
\end{IEEEproof}

\subsection{Heterogeneous general linear agents}
\label{subsec:4.3}
Finally, we design a matrix-scaled consensus algorithm for the system with $n$ heterogenenous linear agents \eqref{eq:heterogeneous_linear}. The main idea is combining the control strategy in subsection~\ref{subsec:4.2} and the disturbance observer in~\ref{sss:2}. Consider the algorithm 
{\small
\begin{subequations} \label{eq:msc_heterogeneous}
\begin{align}
&\dot{\hat{\m{x}}}_i = \m{A}_i\hat{\m{x}}_i +  \m{B}_i\m{u}_i + \m{H}_i(\m{C}_i{\hat{\m{x}}}_i-\m{y}_i), \label{eq:het_obsv_i1}\\
&\dot{\bm{\eta}}_i = \m{A}_i{\bm{\eta}}_i + \m{B}_i\m{u}_i + \m{H}_i(\m{C}_i{\hat{\m{x}}}_i-\m{y}_i) - \hat{\m{u}}_i, \label{eq:het_obsv_i2}\\
&\dot{\m{z}}_i = \m{A}\bm{\zeta}_i - c \text{sign}(\m{S}_i)\sum_{j\in\mc{N}_i}(\m{S}_i\bm{\zeta}_i-\m{S}_j\bm{\zeta}_j),\\
&\hat{\m{u}}_i = - c \text{sign}(\m{S}_i)\sum_{j\in\mc{N}_i}(\m{S}_i\bm{\zeta}_i-\m{S}_j\bm{\zeta}_j) \nonumber\\
&\qquad +\beta_1 \text{sgn}(\m{e}_i) + \beta_2 \text{diag}(\text{sgn}(\m{e}_i))(\m{I}_d\otimes |\bm{\zeta}_i|^\top)\m{1}_{d^2}, \label{eq:het_obsv_i3}\\
&\m{u}_i = \m{K}_i \bm{\eta}_i,~ i=1,\ldots, n, \label{eq:het_obsv_i4}
\end{align}
\end{subequations}}
where $\bm{\zeta}_i = \hat{\m{x}}_i - \bm{\eta}_i$, $\m{e}_i = {\m{z}}_i - \bm{\zeta}_i$, $\m{A}_i+\m{B}_i\m{K}_i$ and $\m{A}_i + \m{H}_i\m{C}_i$ are Hurwitz. We have the following theorem: % on the system \eqref{eq:msc_heterogeneous}:

\begin{theorem} \label{thm:heterogeneous_general_linear}
Suppose that $\mc{G}$ is connected, $\m{A}_i+\m{H}_i\m{C}_i$ and $\m{A}_i+\m{B}_i\m{K}_i$ are Hurwitz, $\forall i = 1,\ldots, n$, $\beta_2\geq \max_{i}\|\bar{\m{A}}_i\|_{\infty}$, and the control gain $c$ is chosen so that $\bm{\Theta}_c = \m{Z}_{[d+1:dn]}^\top(\m{I}_n\otimes \m{A})\m{V}_{[d+1:dn]}-c\bm{\Omega}'$ is Hurwitz. Under the matrix scaled consensus algorithm \eqref{eq:msc_heterogeneous}, $\m{x}(t) \to \mc{C}_S$ as $t \to \infty$. %More specifically, $\m{x}_i$ eventually reaches to a matrix-scaled solution of the system $\dot{\bm{\zeta}}_0 = \m{P}\m{A}\m{P}^{-1}\bm{\zeta}_0$.
\end{theorem}

\begin{IEEEproof}
We have
{\small
    \begin{subequations} \label{eq:het_msc_dtb_obs}
    \begin{align} 
        \dot{\bm{\zeta}}_i &= \m{A}_i {\bm{\zeta}}_i + \hat{\m{u}}_i, \label{eq:het_msc_dtb_obs1} \\
        \dot{\m{z}}_i &= \m{A}\bm{\zeta}_i - c \text{sign}(\m{S}_i)\sum_{j\in\mc{N}_i}(\m{S}_i\bm{\zeta}_i-\m{S}_j\bm{\zeta}_j), \label{eq:het_msc_dtb_obs2}\\
        \dot{\m{e}}_i &= \bar{\m{A}}_i\bm{\zeta}_i - \beta_1\text{sgn}(\m{e}_i) - \beta_2 \text{diag}(\text{sgn}(\m{e}_i))(\m{I}_d\otimes |\bm{\zeta}_i|^\top)\m{1}_{d^2}.
    \end{align}
    \end{subequations}}
By a similar analysis as in the proof of Thm.~\ref{thm:msc_dtb_obsv}, $\m{e}_i = \m{z}_i - \bm{\zeta}_i= \m{0}_d$ for $t\ge T$. Thus, for $t\geq T$, we may consider $\bm{\zeta}_i$ to evolve according to the equation $\dot{\bm{\zeta}}_i = \m{A} \bm{\zeta}_i - c \text{sign}(\m{S}_i)\sum_{j\in\mc{N}_i}(\m{S}_i\bm{\zeta}_i-\m{S}_j\bm{\zeta}_j),~i=1,\ldots,n.$ 

Similar to the proof of Thm.~\ref{thm:homo_general_linear}, it follows that ${\bm{\zeta}}_i(t)$ asymptotically achieves matrix-scaled consensus to a solution of the system $\dot{\bm{\zeta}}_0 = \m{P}\m{A}\m{P}^{-1}\bm{\zeta}_0$. As $\m{A}_i + \m{B}_i \m{K}_i$ and $\m{A}_i+\m{H}_i\m{C}_i$ are Hurwitz, $\tilde{\m{x}}_i = \m{x}_i - \hat{\m{x}}_i \to \m{0}_d$ exponentially fast, and the unforced system 
%\begin{align}
$\dot{\bm{\eta}}_i = (\m{A}_i + \m{B}_i\m{K}_i)\bm{\eta}_i$
%\end{align}
is globally exponentially stable. Moreover, the system \eqref{eq:het_msc_dtb_obs2} has the external input $\m{H}_i\m{C}_i\tilde{\m{x}}_i - \hat{\m{u}}_i$, which vanishes to $\m{0}_d$ exponentially fast. Thus, $\bm{\eta}_i \to \m{0}_d$, as $t\to \infty$. 

Finally, from $\m{x}_i - \bm{\zeta}_i = \tilde{\m{x}}_i + \bm{\eta}_i$, it follows that $\m{x}_i$ asymptotically achieves matrix-scaled consensus with regard to a solution of $\dot{\bm{\zeta}}_0 = \m{P}\m{A}\m{P}^{-1}\bm{\zeta}_0$.
\end{IEEEproof}
\section{Simulation results}
\label{sec:5}
\begin{figure}[t]
\centering
\subfloat[$\m{x}_i(t)$]{\includegraphics[width=0.25\linewidth]{msc_sim1.png}}
\hfill
\subfloat[$x_{i1}(t)$]{\includegraphics[width=0.25\linewidth]{msc_sim1a.png}}
\hfill
\subfloat[$x_{i2}(t)$]{\includegraphics[width=0.25\linewidth]{msc_sim1b.png}}\hfill
\subfloat[$\|\m{u}\|_{\infty}$]{\includegraphics[width=0.25\linewidth]{msc_sim1_umax.eps}}\\
\subfloat[$\m{x}_i(t)$]{\includegraphics[width=0.25\linewidth]{msc1_nonl_traj.png}}
\hfill
\subfloat[$x_{i1}(t)$]{\includegraphics[width=0.25\linewidth]{msc1_nonl_x1.png}}
\hfill
\subfloat[$x_{i2}(t)$]{\includegraphics[width=0.25\linewidth]{msc1_nonl_x2.png}}\hfill
\subfloat[$\|\m{u}\|_{\infty}$]{\includegraphics[width=0.25\linewidth]{msc1_nonl_umax.png}}
% \hfill
% \subfloat[]{\includegraphics[width=0.25\textwidth]{fig24.png}}
\caption{The agents converge to three clusters in 2D under the matrix-scaled consensus algorithms \eqref{eq:msc_single_integrator} (Figs. (a)--(d)) and \eqref{eq:msc_nonl} (Figs. (e)--(h)).}
\label{fig:msc_sim1}
\end{figure}
In this section, we provide simulations of the theoretical results in Sections \ref{sec:single_integrator}, \ref{sec:linear_agents}. In all simulations, a 6-agent system in two dimensional space ($d=2$) is considered. The interaction between agents are captured by an undirected cycle of six vertices. Denote the SO(2) rotation matrix of angle $\theta$ (rad) by {\small$\mathbf{R}(\theta) = \begin{bmatrix}
\cos(\theta)&-\sin(\theta)\\\sin(\theta) & \cos(\theta)
\end{bmatrix} $}. The scaling matrices are chosen as $\mathbf{S}_1 =  \mathbf{S}_2=\mathbf{R}(\frac{\pi}{3})$ (positive definite), $\mathbf{S}_3 =  \mathbf{S}_{4}=-\mathbf{I}_2$ (negative definite), and $\mathbf{S}_{5} = \mathbf{S}_{6}=\mathbf{R}(\frac{5\pi}{3})$ (positive definite).
\begin{figure}
\centering
\subfloat[$\m{x}_i(t)$]{\includegraphics[width=0.24\linewidth]{msc_sim2.png}}
\hfill
\subfloat[$\bm{\theta}_i(t),\hat{\bm{\theta}}_i(t)$]{\includegraphics[width=0.24\linewidth]{msc_sim2c.png}}
\hfill
\subfloat[$x_{i1}(t)$]{\includegraphics[width=0.24\linewidth]{msc_sim2a.png}}
\hfill
\subfloat[$x_{i2}(t)$]{\includegraphics[width=0.24\linewidth]{msc_sim2b.png}}
\caption{The six-agent system under the adaptive algorithm \eqref{eq:AMWC-1}--\eqref{eq:AMWC-2}.}
    \label{fig:msc_sim2_adaptive}
\end{figure}
\subsection{MSC of single integrators}
\label{subsec:single-integrator}
% We simulate the six-single integrator system under the matrix-scaled consensus algorithm \eqref{eq:msc_single_integrator}.   
Figures \ref{fig:msc_sim1} (a)--(d) shows a simulation of the 6-agent system under the matrix-scaled consensus algorithm \eqref{eq:msc_single_integrator} for 20 seconds, where the initial condition $\m{x}(0)$ was randomly selected. The agents' trajectories asymptotically converge to three clusters in 2D, which are vertices of an equilateral triangle.

Next, we consider the six-agent system under the nonlinear matrix-scaled algorithm \eqref{eq:msc_nonl} with the same initial state $\m{x}(0)$. We would like the input of each agent to satisfy $\|\m{u}_i(t)\|_{\infty}<\beta=1$. This objective is achieved by selecting $\m{f}(\cdot)=(\max_i|N_i|)^{-1}\text{tanh}(\cdot)=0.5\text{tanh}(\cdot)$. Simulation results are depicted in Figs.~\ref{fig:msc_sim1}(e)--(h). Observe that $\m{x}(t)$ converges to the same point as  the previous simulation, $\|\m{u}_i\|_{\infty}\le 1,\forall t\ge 0$, the settling time (which is defined as the first time $\m{x}(t)$ enters without escaping $B_{5\%}=\{\|\m{x}(t)-\lim_{t\to\infty}\m{x}(t)\|<0.05\}$) becomes larger (approx. 10 sec in comparison with 5 sec). 

\subsection{MSC of single-integrators with uncertain parameters}
\label{subsec:single-integrator-disturbance}
%  Matrices $\phi_i(t) \in \mathbb{R}^{2\times2}$ is defined as $\phi_i(t)=\begin{bmatrix}
% \sin(t+\frac{\pi}{3})&\cos(t)\\ 2\sin(2i)& -\cos(t+\pi/3)
% \end{bmatrix}$. The initial condition $\begin{bmatrix}x(0)\\ \hat{\theta}(0)\end{bmatrix}$ is randomly selected. Simulation results are shown in Fig.~\ref{fig:B1}.
Next, we consider the 6-single-integrator system with parametric uncertainties, with 
{\small
\begin{align*}
    \bm{\phi}_i(t)= \begin{bmatrix}
        0.2\sin(t) & 0.5-0.2\sin(\frac{it}{\pi})\\
        -0.2\sin(\frac{t}{i\pi}) & 0.1\cos(\frac{t}{\pi})
    \end{bmatrix},~i=1,\ldots, 6,
\end{align*}}
satisfy the PE condition, and $\gamma_i>0$ are randomly chosen between $[1,10]$. The constant unknown parameters are $\bm{\theta}_i = [i-0.5,~i]^\top$, and the initial estimates $\hat{\bm{\theta}}_i(0)$ are randomly generated. Simulation results depicted in Fig.~\ref{fig:msc_sim2_adaptive} show that $\m{x}_i \to \mc{C}_{S}$, $\hat{\bm{\theta}}_i(t) \approx \bm{\theta}_i$ at $t=200$ seconds (Fig.~\ref{fig:msc_sim2_adaptive} (b)). Due to the unknown parameters, the convergence rate, however, is much slower in comparison with the ideal case.

% Next, we consider another simulation in 3-dimensional space $(d=3)$.  In this simulation, let the SO(3) rotaion of angle $\theta$ (rad) be denoted by $\mathbf{R}(\theta) = \begin{bmatrix}
% \cos(\theta)&-\sin(\theta)&0\\\sin(\theta) & \cos(\theta)&0 \\ 0&0&1
% \end{bmatrix} $. We choose the scaling matrices as follows $\mathbf{S}_1 = \mathbf{S}_2=\mathbf{R}(0) = \mathbf{I}_3$ , $\mathbf{S}_3 = \mathbf{S}_{4}=\mathbf{R}(\frac{\pi}{3})$ (positive definite), $\mathbf{S}_{5} =  \mathbf{S}_{6}=-\mathbf{R}(\frac{\pi}{3})$ (negative definite). Matrices $\phi_i(t) \in \mathbb{R}^{3\times3}$ are selected as $\phi_i(t)=\begin{bmatrix}
% 2\sin(t)&\cos\left(\frac{t}{2}\right)&-\sin(t+\frac{\pi}{4})\\ 2\sin(t)& -\cos\left(t+\frac{\pi}{3}\right)&\cos(t)\\ \cos(t) & \sin\left(t+\frac{\pi}{5}\right) &\sin(it)
% \end{bmatrix}$. The initial condition $\begin{bmatrix}x(0)\\ \hat{\theta}(0)\end{bmatrix}$ is randomly selected. Simulation results are shown in Fig.\ref{fig:B2}.
% \begin{figure*}
%     \centering
% \subfloat[]{\includegraphics[width=0.3\textwidth]{fig31.png}}
% \hfill
% \subfloat[]{\includegraphics[width=0.3\textwidth]{fig32.png}}
% \hfill
% \subfloat[]{\includegraphics[width=0.3\textwidth]{fig33.png}}
% \hfill
% \\
% \subfloat[]{\includegraphics[width=0.3\textwidth]{fig34.png}}
% \qquad \qquad
% \subfloat[]{\includegraphics[width=0.3\textwidth]{fig35.png}}
% % \hfill
% % \subfloat[]{\includegraphics[width=0.25\textwidth]{fig24.png}}
% \caption{The agents converge to 3 clusters in 3D space under the matrix-scaled consensus algorithm}
%     \label{fig:B2}
% \end{figure*}
\begin{figure}[t]
    \centering
\subfloat[$\m{A}$ is Hurwitz.]{\includegraphics[width=0.3\linewidth]{msc_sim5_stable.png}}
\hfill
\subfloat[$\m{A}$ has a pair of imaginary eigenvalues, $\m{A}+\m{A}^\top \neq \m{0}_{d\times d}$.]{\includegraphics[width=0.3\linewidth]{msc_sim5_margin.eps}}
\hfill
\subfloat[$\m{A}$ is unstable.]{\includegraphics[width=0.3\linewidth]{msc_sim5_unstable.png}}\\
\subfloat[$\m{A}=-\m{A}^\top$ and has a pair of imaginary eigenvalues.]{\includegraphics[width=0.3\linewidth]{msc_sim4.png}}
\hfill
\subfloat[State variables $x_{i1}(t)$ corresponding to trajectories in (d).]{\includegraphics[width=0.3\linewidth]{msc_sim4a.png}}
\hfill
\subfloat[State variables $x_{i2}(t)$ corresponding to trajectories in (d).]{\includegraphics[width=0.3\linewidth]{msc_sim4b.png}}
\caption{The six-agent system modeled by the simplified linear model \eqref{eq:simple_homo_allagents} with different choices of the matrix $\m{A}$.}
\label{fig:msc_sim4}
\end{figure}

\subsection{MSC of simplified linear dynamical agents}
We simulate the matrix-scaled consensus algorithm for the six-agent system with the simplified linear model \eqref{eq:simple_homo_allagents} for  different matrices $\m{A}$ as follows
\begin{itemize}
    \item {\small $\m{A}=0.5\begin{bmatrix}
      -1 & 1 \\ -1 & 0  
    \end{bmatrix}$} has eigenvalues $-0.25\pm \frac{\sqrt{3}}{4}\imath$,
    \item {\small $\m{A}=\begin{bmatrix}
      0 & 1 \\ -1 & 0  
    \end{bmatrix}$} is skew-symmetric, has eigenvalues $\pm \imath$,
    \item {\small $\m{A}=0.5\begin{bmatrix}
      0 & 1 \\ -0.5 & 0  
    \end{bmatrix}$} has a pair of imaginary eigenvalues, $\m{A}$ is not skew-symmetric, 
    \item {\small $\m{A}=0.5\begin{bmatrix}
      1 & 1 \\ -1 & 0  
    \end{bmatrix}$} has eigenvalues $0.25\pm \frac{\sqrt{3}}{4}\imath$,
\end{itemize}
where $\imath^2 = -1$. In this subsection, the coupling gain is chosen as $c=2$. Simulation results depicted in Fig.~\ref{fig:msc_sim4} show that the agents' trajectories are affected by both the unforced dynamics (determined by $\m{A}\m{x}_i$) and the matrix-scaled consensus algorithm. Clearly, if $\m{A}$ is stable (unstable), all agents' states converge to 0 (resp., grow unbounded). In case $\m{A}$ is marginally stable, the agents asymptotically reach a matrix scaled consensus with regard to a trajectory of the system $\dot{\m{r}}=\m{P}\m{A}\m{P}^{-1}\m{r}$. In case $\m{A}$ is skew-symmetric, agents move on a circle centered at the origin, and if $\m{A}$ is not skew-symmetric, agents with the same scaling matrix move on a same elliptical trajectory. Each trajectory of $\m{x}_i(t)$ differs from a common solution of $\dot{\m{r}}=\m{P}\m{A}\m{P}^{-1}\m{r}$ by the scaling matrix $\m{S}_i$.
\subsection{MSC of general homogeneous linear dynamical agents}
\begin{figure}[t]
    \subfloat[$\|\hat{\m{x}}_i(t)\|$]{\includegraphics[width=0.3\linewidth]{msc_homo_xhat.png}}\hfill
    \subfloat[$\eta_{i1}(t)$]{\includegraphics[width=0.3\linewidth]{msc_homo_eta1.eps}}\hfill
    \subfloat[$\eta_{i2}(t)$]{\includegraphics[width=0.3\linewidth]{msc_homo_eta2.eps}}\hfill\\
    \subfloat[$\m{x}_i$]{\includegraphics[width=0.3\linewidth]{msc_homo_traj.png}}\hfill
    \subfloat[${x}_{i1}$]{\includegraphics[width=0.3\linewidth]{msc_homo_x1.png}}\hfill
    \subfloat[${x}_{i2}$]{\includegraphics[width=0.3\linewidth]{msc_homo_x2.png}}
    \caption{The six-agent system \eqref{eq:sim_homo} under the algorithm \eqref{eq:homo_obsv}.\label{fig:sim_homo}}
\end{figure}

In this subsection, let the agent be modeled by a linear oscillator with a control input
{\small
\begin{subequations}\label{eq:sim_homo}
\begin{align}
    \dot{x}_{i1} &= x_{i2}, \\
    \dot{x}_{i2} &= -\omega^2 x_{i1} + u_i,\\
    y_{i} &=x_{i1},~\, i=1,\ldots, 6,
\end{align}
\end{subequations}}
and $\omega = 1$. The corresponding system matrices are {\small $\m{A} = \begin{bmatrix}
      0 & 1 \\ -1 & 0  
\end{bmatrix}$, $\m{B} = \begin{bmatrix}
      0 \\ 1
\end{bmatrix}$, $\m{C} = [1,~0]$, $\m{K}=[-3,-4]$, $\m{H}=[-8, -15]^\top$}, and $c=2$. Simulation corresponding to a randomly generated initial condition is displayed in Fig.~\ref{fig:sim_homo}. The state estimate error $\tilde{\m{x}}_i=\hat{\m{x}}_i -\m{x}_i$ and the auxiliary variable $\bm{\eta}$ vanish exponentially fast. Figures \ref{fig:sim_homo}(d), (e), (f) depict the trajectories of 6 agents; Each agent's trajectory differ to a common solution of $\dot{\m{r}}=\m{P}\m{A}\m{P}^{-1}\m{r}$ by its scaling matrix.

\subsection{MSC of general heterogeneous linear dynamical agents}
Consider a system of six heterogeneous linear agents, where matrix $\m{A}$ is the same as in the previous subsection, $\bar{\m{A}}_i$ are randomly generated with entries belong to $[-0.2,~0.2]$. The matrices $\m{B}_i=\m{B} + \bm{\Delta}_B$, where $\bm{\Delta}_B=\begin{bmatrix}
    0 & \delta_{b_i}
\end{bmatrix}^\top$, with $\delta_{b_i}$ be randomly generated to take values on the interval $[-0.5,0.5]$, and $\m{C}_i = \m{C},~~\forall i=1,\ldots,n$. The matrices $\m{K}_i$ and $\m{H}_i$ are designed so that each matrix $\m{A}_i+\m{B}_i\m{K}_i$ have eigenvalues $-2,-2$ and each matrix $\m{A}_i+\m{H}_i\m{C}_i$ have eigenvalues $-4, -4$, for $i=1,\ldots,6$. The control gains are given as $c=2$, $\beta_1=2$ and $\beta_2=5$. 

Figures~\ref{fig:sim_heterogeneous_systems}(a), (b), (c) show that $\m{x}(t) \to \mc{C}_S$ asymptotically under the algorithm \eqref{eq:het_msc_dtb_obs}. The system eventually achieves matrix-scaled consensus on a trajectory of $\dot{\m{r}}=\m{P}\m{A}\m{P}^{-1}\m{r}$. For comparison, the same heterogeneous system is simulated without using the control law \eqref{eq:het_msc_dtb_obs}. Without the signum terms, Fig.~\ref{fig:sim_heterogeneous_systems}(d), (e), (f) show that the system diverges. %Thus, simulation results show the effectiveness of the proposed algorithm.

\begin{figure}
\centering
    \subfloat[$\m{x}_i$]{\includegraphics[width=0.3\linewidth]{msc_heter_traj.eps}} \hfill
    \subfloat[$x_{i1}$]{\includegraphics[width=0.3\linewidth]{msc_heter_x1.eps}} \hfill
    \subfloat[$x_{i2}$]{\includegraphics[width=0.3\linewidth]{msc_heter_x2.eps}} \\
    \subfloat[$\m{x}_i$]{\includegraphics[width=0.3\linewidth]{msc_heter_wo_traj.eps}} \hfill
    \subfloat[$x_{i1}$]{\includegraphics[width=0.3\linewidth]{msc_heter_wo_x1.eps}} \hfill
    \subfloat[$x_{i2}$]{\includegraphics[width=0.3\linewidth]{msc_heter_wo_x2.eps}}
    \caption{Simulation of the heterogeneous linear systems when the agents: (i) employ the algorithm \eqref{eq:het_msc_dtb_obs}: (a), (b), (c); and (ii) do not include the signum term in $\hat{\m{u}}$ in \eqref{eq:het_msc_dtb_obs}: (d), (e), (f).}
    \label{fig:sim_heterogeneous_systems}
\end{figure}

\section{Conclusions}
\label{sec:6}
{In this paper, the matrix-scaled consensus model has been proposed and studied in detail. Several matrix-scaled consensus algorithms were designed for linear agents interacting over an undirected network. The asymptotic behaviors of the proposed algorithms associate with the algebraic properties of the matrix-scaled Laplacian $(\text{sign}(\m{S})\m{L}\otimes\m{I}_d)\m{S}$. Main difficulties in the stability analysis comes from the asymmetry and multi-dimensionality of the matrix-scaled Laplacian.} 

As the study of the matrix-scaled consensus algorithm in this paper also focused on undirected graphs and linear agents, further research will consider the matrix-scaled consensus algorithm with {directed or signed graphs}.

%\appendices
%\section{Asymptotic behavior of an adaptive system}
%\label{append:A}
%\begin{lemma}\cite{Besanccon2000remarks} \label{lemma:PE} Given the system in the following form
%\begin{subequations}
%\begin{align}
%\dot{\m{x}}_1 & = \m{h}(t) \m{x}_2 + \ms{\varphi}(t),~\m{x}_1\in \mb{R}^n,~\m{x}_2\in \mb{R}^m,\\
%\dot{\m{x}}_2 & = \ms{\psi}(t),
%\end{align}
%\end{subequations}
%where the functions $\m{h}: \mb{R}^+ \to \mb{R}^{n\times m}$, $\ms{\varphi}: \mb{R}^+ \to \mb{R}^n$, and $\ms{\psi}: \mb{R}^+ \to \mb{R}^m$ are such that (i) $\lim_{t\to \infty} \|\m{x}_1(t)\| = \lim_{t\to \infty} \|\ms{\varphi}(t)\| = \lim_{t\to \infty} \|\ms{\psi}(t)\| = {0}$, (ii) $\m{h}(t)$, $\dot{\m{h}}(t)$ are bounded and (iii) there exist positive constants $T, \mu_1, \mu_2$ and $l$ such that for all $t\ge 0$, $\mu_1 \m{I}_n \ge \int_t^{t+T}\m{h}(\tau)^\top\m{h}(\tau) d\tau \ge \mu_2 \m{I}_n$, then $\lim_{t\to \infty} \|\m{x}_2(t)\| = 0$.
%\end{lemma}

\section{Proof of Lemma \ref{lem:matrix_stability}}
\label{append:A}
Let $\bm{\Theta}_c=c\m{\Theta} + \bm{\Delta}_{\Theta}$, and consider the dynamical system 
%\begin{align}
$\dot{\m{x}} = \bm{\Theta}_c\m{x}.$
%\end{align}
Consider the Lyapunov function $V=\m{x}^\top \m{Q}\m{x}$, we have, $\dot{V} =\m{x}^\top(\m{Q}\bm{\Theta}_c + \bm{\Theta}_c^\top\m{Q})\m{x} 
= - c\|\m{x}\|^2 + 2\m{x}^\top\m{Q}\bm{\Delta}_{\Theta}\m{x} 
\leq -(c - 2 \|\m{Q}\|\|\bm{\Delta}_{\Theta}\|) \|\m{x}\|^2 
\leq -(c - 2 {\delta}_{\Theta} \lambda_{\max}(\m{Q}))\lambda_{\min}^{-1}(\m{Q})V.$ 
Thus, $\m{x}(t)$ is globally exponentially stable. Equivalently, the matrix $\bm{\Theta}_c$ is Hurwitz.

\bibliographystyle{IEEEtran}
\bibliography{minh2021}
\end{document}