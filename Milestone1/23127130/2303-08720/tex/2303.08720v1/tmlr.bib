@article{chexpert,
  author    = {Jeremy Irvin and
               Pranav Rajpurkar and
               Michael Ko and
               Yifan Yu and
               Silviana Ciurea{-}Ilcus and
               Chris Chute and
               Henrik Marklund and
               Behzad Haghgoo and
               Robyn L. Ball and
               Katie S. Shpanskaya and
               Jayne Seekins and
               David A. Mong and
               Safwan S. Halabi and
               Jesse K. Sandberg and
               Ricky Jones and
               David B. Larson and
               Curtis P. Langlotz and
               Bhavik N. Patel and
               Matthew P. Lungren and
               Andrew Y. Ng},
  title     = {CheXpert: {A} Large Chest Radiograph Dataset with Uncertainty Labels
               and Expert Comparison},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.07031},
  eprinttype = {arXiv},
  eprint    = {1901.07031},
}



@ARTICLE{Bengio_rep,
  author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Representation Learning: A Review and New Perspectives}, 
  year={2013},
  volume={35},
  number={8},
  pages={1798-1828},
  doi={10.1109/TPAMI.2013.50}}

@article{castro_causality_2020,
	title = {Causality matters in medical imaging},
	volume = {11},
	issn = {2041-1723},
	abstract = {Causal reasoning can shed new light on the major challenges in machine learning for medical imaging: scarcity of high-quality annotated data and mismatch between the development dataset and the target environment. A causal perspective on these issues allows decisions about data collection, annotation, preprocessing, and learning strategies to be made and scrutinized more transparently, while providing a detailed categorisation of potential biases and mitigation techniques. Along with worked clinical examples, we highlight the importance of establishing the causal relationship between images and their annotations, and offer step-by-step recommendations for future studies.},
	number = {1},
	journal = {Nature Communications},
	author = {Castro, Daniel C. and Walker, Ian and Glocker, Ben},
	month = jul,
	year = {2020},
	pages = {3673},
}
@article{germain_linear,
           title = {{PAC}-{Bayesian} learning of linear classifiers},
            author = {Germain, Pascal and Lacasse, Alexandre and Laviolette, François and Marchand, Mario},
           url = {https://www.academia.edu/15612271/PAC_Bayesian_learning_of_linear_classifiers},
           language = {en},
           year=2009,
           journal = {Proceedings of the 26th Annual International Conference on Machine Learning - ICML \&\#39;09},
           
   }

@article{albadawy_deep_2018,
	title = {Deep learning for segmentation of brain tumors: {Impact} of cross-institutional training and testing},
	volume = {45},
	abstract = {Background and purpose Convolutional neural networks (CNNs) are commonly used for segmentation of brain tumors. In this work, we assess the effect of cross-institutional training on the performance of CNNs. Methods We selected 44 glioblastoma (GBM) patients from two institutions in The Cancer Imaging Archive dataset. The images were manually annotated by outlining each tumor component to form ground truth. To automatically segment the tumors in each patient, we trained three CNNs: (a) one using data for patients from the same institution as the test data, (b) one using data for the patients from the other institution and (c) one using data for the patients from both of the institutions. The performance of the trained models was evaluated using Dice similarity coefficients as well as Average Hausdorff Distance between the ground truth and automatic segmentations. The 10-fold cross-validation scheme was used to compare the performance of different approaches. Results Performance of the model significantly decreased (P {\textless} 0.0001) when it was trained on data from a different institution (dice coefficients: 0.68 ± 0.19 and 0.59 ± 0.19) as compared to training with data from the same institution (dice coefficients: 0.72 ± 0.17 and 0.76 ± 0.12). This trend persisted for segmentation of the entire tumor as well as its individual components. Conclusions There is a very strong effect of selecting data for training on performance of CNNs in a multi-institutional setting. Determination of the reasons behind this effect requires additional comprehensive investigation.},
	number = {3},
	journal = {Medical Physics},
	author = {AlBadawy, Ehab A. and Saha, Ashirbani and Mazurowski, Maciej A.},
	year = {2018},
	keywords = {brain tumor segmentation, CNN, glioblastoma, impact of cross-institutional training, magnetic resonance imaging},
	pages = {1150--1158},
}
@article{perone_unsupervised_2019,
	title = {Unsupervised domain adaptation for medical imaging segmentation with self-ensembling},
	volume = {194},
	issn = {1053-8119},
	doi = {10.1016/j.neuroimage.2019.03.026},
	abstract = {Recent advances in deep learning methods have redefined the state-of-the-art for many medical imaging applications, surpassing previous approaches and sometimes even competing with human judgment in several tasks. Those models, however, when trained to reduce the empirical risk on a single domain, fail to generalize when applied to other domains, a very common scenario in medical imaging due to the variability of images and anatomical structures, even across the same imaging modality. In this work, we extend the method of unsupervised domain adaptation using self-ensembling for the semantic segmentation task and explore multiple facets of the method on a small and realistic publicly-available magnetic resonance (MRI) dataset. Through an extensive evaluation, we show that self-ensembling can indeed improve the generalization of the models even when using a small amount of unlabeled data.},
	journal = {NeuroImage},
	author = {Perone, Christian S and Ballester, Pedro and Barros, Rodrigo C and Cohen-Adad, Julien},
	month = jul,
	year = {2019},
	pages = {1--11},
}
@inproceedings{zhou2019nonvacuous,
      title={Non-Vacuous Generalization Bounds at the ImageNet Scale: A PAC-Bayesian Compression Approach}, 
      author={Wenda Zhou and Victor Veitch and Morgane Austern and Ryan P. Adams and Peter Orbanz},
      year={2019},
      booktitle={International Conference on Learning Representations},
      }
@inproceedings{
gulrajani2021in,
title={In Search of Lost Domain Generalization},
author={Ishaan Gulrajani and David Lopez-Paz},
booktitle={International Conference on Learning Representations},
year={2021},
}
@article{scholkopf_causal_nodate,
	title = {On {Causal} and {Anticausal} {Learning}},
	abstract = {We consider the problem of function estimation in the case where an underlying causal model can be inferred. This has implications for popular scenarios such as covariate shift, concept drift, transfer learning and semi-supervised learning. We argue that causal knowledge may facilitate some approaches for a given problem, and rule out others. In particular, we formulate a hypothesis for when semi-supervised learning can help, and corroborate it with empirical results.},
	language = {en},
	author = {Schölkopf, Bernhard and Janzing, Dominik and Peters, Jonas and Sgouritsa, Eleni and Zhang, Kun and Mooij, Joris},
	pages = {8},
	annote = {Good intro paper to causality. Gives methods/strategies to use in different settings with causality. In particular, it looks at semi-supervised learning in the anticausal direction and finds that it may be useful.    },
	}
	@article{lecun_gradient-based_1998,
           title = {Gradient-{Based} {Learning} {Applied} to {Document} {Recognition}},
           volume = {86},
           language = {en},
           number = {11},
           journal = {proceedings of the IEEE},
           author = {Lecun, Yann},
           year = {1998},
           pages = {47},
}
   @article{hansen2008,
       author = {Hansen, Ben B.},
       title = "{The prognostic analogue of the propensity score}",
       journal = {Biometrika},
       volume = {95},
       number = {2},
       pages = {481-488},
       year = {2008},
       month = {06},
       abstract = "{The propensity score collapses the covariates of an observational study into a single measure summarizing their joint association with treatment conditions; prognostic scores summarize covariates' association with potential responses. As with propensity scores, stratification on prognostic scores brings to uncontrolled studies a concrete and desirable form of balance, a balance that is more familiar as an objective of experimental control. Like propensity scores, prognostic scores can reduce the dimension of the covariate, yet causal inferences conditional on them are as valid as are inferences conditional only on the unreduced covariate. As a method of adjustment unto itself, prognostic scoring has limitations not shared with propensity scoring, but it holds promise as a complement to the propensity score, particularly in certain designs for which unassisted propensity adjustment is difficult or infeasible.}",
      issn = {0006-3444},
      doi = {10.1093/biomet/asn004},
      url = {https://doi.org/10.1093/biomet/asn004},
      eprint = {https://academic.oup.com/biomet/article-pdf/95/2/481/623094/asn004.pdf},
  }

   @article{DAMOUR21,
   title = {Overlap in observational studies with high-dimensional covariates},
   journal = {Journal of Econometrics},
  volume = {221},
   number = {2},
   pages = {644-654},
   year = {2021},
   issn = {0304-4076},
   doi = {https://doi.org/10.1016/j.jeconom.2019.10.014},
   url = {https://www.sciencedirect.com/science/article/pii/S0304407620302694},
  author = {Alexander D’Amour and Peng Ding and Avi Feller and Lihua Lei and Jasjeet Sekhon},
 keywords = {Causal inference, Overlap, Information theory, Curse of dimensionality},
  abstract = {Estimating causal effects under exogeneity hinges on two key assumptions: unconfoundedness and overlap. Researchers often argue that unconfoundedness is more plausible when more covariates are i    ncluded in the analysis. Less discussed is the fact that covariate overlap is more difficult to satisfy in this setting. In this paper, we explore the implications of overlap in observational studies with h    igh-dimensional covariates and formalize curse-of-dimensionality argument, suggesting that these assumptions are stronger than investigators likely realize. Our key innovation is to explore how strict overl    ap restricts global discrepancies between the covariate distributions in the treated and control populations. Exploiting results from information theory, we derive explicit bounds on the average imbalance i    n covariate means under strict overlap and show that these bounds become more restrictive as the dimension grows large. We discuss how these implications interact with assumptions and procedures commonly deployed in observational causal inference, including sparsity and trimming.}
  }
	@ARTICLE{bsds500,
  author={Arbeláez, Pablo and Maire, Michael and Fowlkes, Charless and Malik, Jitendra},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Contour Detection and Hierarchical Image Segmentation}, 
  year={2011},
  volume={33},
  number={5},
  pages={898-916},
}
@article{Ben-David2010a,
  title     = "A theory of learning from different domains",
  author    = "Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza,
               Alex and Pereira, Fernando and Vaughan, Jennifer Wortman",
  journal   = "Mach. Learn.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  79,
  number    = "1-2",
  pages     = "151--175",
  month     =  may,
  year      =  2010,
  language  = "en"
}
@article{steinke_reasoning_2020,
	title = {Reasoning {About} {Generalization} via {Conditional} {Mutual} {Information}},
	abstract = {We provide an information-theoretic framework for studying the generalization properties of machine learning algorithms. Our framework ties together existing approaches, including uniform convergence bounds and recent methods for adaptive data analysis. Specifically, we use Conditional Mutual Information (CMI) to quantify how well the input (i.e., the training data) can be recognized given the output (i.e., the trained model) of the learning algorithm. We show that bounds on CMI can be obtained from VC dimension, compression schemes, differential privacy, and other methods. We then show that bounded CMI implies various forms of generalization.},
	urldate = {2020-09-09},
	journal = {arXiv:2001.09122 [cs, math, stat]},
	author = {Steinke, Thomas and Zakynthinou, Lydia},
	month = jun,
	year = {2020},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Data Structures and Algorithms, Computer Science - Information Theory, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 58 pages. Changes from previous version: Added discussion on related work and updated references. Simplified part of the proof of Theorem 4.10},
	annote = {Only skimmed part of it. Seems to be a information theoretic take on generalisation error and such. Might be good to read the whole thing.},
	}

@misc{pratt_experiments_1994,
	title = {Experiments on the transfer of knowledge between neural networks},
	abstract = {Semantic Scholar extracted view of \&quot;Experiments on the transfer of knowledge between neural networks\&quot; by Lorien Y. Pratt},
	language = {en},
	urldate = {2020-08-14},
	journal = {undefined},
	author = {Pratt, Lorien Y.},
	year = {1994},
	}
@phdthesis{redkothesis,
  author  = "Ievgen Redko",
  title   = "Nonnegative matrix factorization for transfer learning",
  school  = "Paris North University",
  year    = "2015",
}
@inproceedings{johansson_support_2019,
  title={Support and invertibility in domain-invariant representations},
  author={Johansson, Fredrik D and Sontag, David and Ranganath, Rajesh},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={527--536},
  year={2019},
  organization={PMLR}
	}

@inproceedings{kleinberg_multi-armed_2008,
	address = {Victoria, British Columbia, Canada},
	title = {Multi-armed bandits in metric spaces},
	isbn = {978-1-60558-047-0},
	abstract = {In a multi-armed bandit problem, an online algorithm chooses from a set of strategies in a sequence of n trials so as to maximize the total payoff of the chosen strategies. While the performance of bandit algorithms with a small ﬁnite strategy set is quite well understood, bandit problems with large strategy sets are still a topic of very active investigation, motivated by practical applications such as online auctions and web advertisement. The goal of such research is to identify broad and natural classes of strategy sets and payoff functions which enable the design of efﬁcient solutions.},
	language = {en},
	urldate = {2020-08-25},
	booktitle = {Proceedings of the fourtieth annual {ACM} symposium on {Theory} of computing - {STOC} 08},
	publisher = {ACM Press},
	author = {Kleinberg, Robert and Slivkins, Aleksandrs and Upfal, Eli},
	year = {2008},
	pages = {681},
	}

@article{zhang2021understanding,
  title={Understanding deep learning (still) requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={Communications of the ACM},
  volume={64},
  number={3},
  pages={107--115},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{gretton2012kernel,
  title={A kernel two-sample test},
  author={Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
  journal={The Journal of Machine Learning Research},
  volume={13},
  number={1},
  pages={723--773},
  year={2012},
  publisher={JMLR. org}
}

@article{bickel_discriminative_nodate,
	title = {Discriminative {Learning} {Under} {Covariate} {Shift}},
	abstract = {We address classiﬁcation problems for which the training instances are governed by an input distribution that is allowed to differ arbitrarily from the test distribution—problems also referred to as classiﬁcation under covariate shift. We derive a solution that is purely discriminative: neither training nor test distribution are modeled explicitly. The problem of learning under covariate shift can be written as an integrated optimization problem. Instantiating the general optimization problem leads to a kernel logistic regression and an exponential model classiﬁer for covariate shift. The optimization problem is convex under certain conditions; our ﬁndings also clarify the relationship to the known kernel mean matching procedure. We report on experiments on problems of spam ﬁltering, text classiﬁcation, and landmine detection.},
	language = {en},
	author = {Bickel, Steffen and De, Cs Uni-Potsdam and De, Cs Uni-Potsdam and De, Cs Uni-Potsdam},
	pages = {19},
	}

@misc{williams_domain_nodate,
	title = {Domain {Adaptation} with {Conditional} {Transferable} {Components} {\textbar} {Max} {Planck} {Institute} for {Intelligent} {Systems}},
	abstract = {Our goal is to understand the principles of Perception, Action and Learning in autonomous systems that successfully interact with complex environments and to use this understanding to design future systems.},
	language = {en},
	urldate = {2020-08-25},
	author = {Williams, Jon},
	}

@incollection{munos_optimistic_2011,
	title = {Optimistic {Optimization} of a {Deterministic} {Function} without the {Knowledge} of its {Smoothness}},
	urldate = {2020-08-25},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 24},
	publisher = {Curran Associates, Inc.},
	author = {Munos, Rémi},
	editor = {Shawe-Taylor, J. and Zemel, R. S. and Bartlett, P. L. and Pereira, F. and Weinberger, K. Q.},
	year = {2011},
	pages = {783--791},
	}

@article{daume_iii_bayesian_2014,
	title = {Bayesian {Multitask} {Learning} with {Latent} {Hierarchies}},
	abstract = {We learn multiple hypotheses for related tasks under a latent hierarchical relationship between tasks. We exploit the intuition that for domain adaptation, we wish to share classifier structure, but for multitask learning, we wish to share covariance structure. Our hierarchical model is seen to subsume several previously proposed multitask learning models and performs well on three distinct real-world data sets.},
	urldate = {2020-08-25},
	journal = {arXiv:1408.2032 [cs, stat]},
	author = {Daume III, Hal},
	month = aug,
	year = {2014},
	note = {arXiv: 1408.2032},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)},
	}

@article{mhasawade_population-aware_2018,
	title = {Population-aware {Hierarchical} {Bayesian} {Domain} {Adaptation}},
	abstract = {Population attributes are essential in health for understanding who the data represents and precision medicine efforts. Even within disease infection labels, patients can exhibit significant variability; "fever" may mean something different when reported in a doctor's office versus from an online app, precluding directly learning across different datasets for the same prediction task. This problem falls into the domain adaptation paradigm. However, research in this area has to-date not considered who generates the data; symptoms reported by a woman versus a man, for example, could also have different implications. We propose a novel population-aware domain adaptation approach by formulating the domain adaptation task as a multi-source hierarchical Bayesian framework. The model improves prediction in the case of largely unlabelled target data by harnessing both domain and population invariant information.},
	urldate = {2020-08-25},
	journal = {arXiv:1811.08579 [cs, stat]},
	author = {Mhasawade, Vishwali and Rehman, Nabeel Abdur and Chunara, Rumi},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.08579},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Machine Learning for Health (ML4H) Workshop at NeurIPS 2018 arXiv:1811.07216},
	}

@article{wilson_survey_2020,
	title = {A {Survey} of {Unsupervised} {Deep} {Domain} {Adaptation}},
	abstract = {Deep learning has produced state-of-the-art results for a variety of tasks. While such approaches for supervised learning have performed well, they assume that training and testing data are drawn from the same distribution, which may not always be the case. As a complement to this challenge, single-source unsupervised domain adaptation can handle situations where a network is trained on labeled data from a source domain and unlabeled data from a related but different target domain with the goal of performing well at test-time on the target domain. Many single-source and typically homogeneous unsupervised deep domain adaptation approaches have thus been developed, combining the powerful, hierarchical representations from deep learning with domain adaptation to reduce reliance on potentially-costly target data labels. This survey will compare these approaches by examining alternative methods, the unique and common elements, results, and theoretical insights. We follow this with a look at application areas and open research directions.},
	urldate = {2020-08-25},
	journal = {arXiv:1812.02849 [cs, stat]},
	author = {Wilson, Garrett and Cook, Diane J.},
	month = feb,
	year = {2020},
	note = {arXiv: 1812.02849},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	}

@article{mhasawade_population-aware_2020,
	title = {Population-aware {Hierarchical} {Bayesian} {Domain} {Adaptation} via {Multiple}-component {Invariant} {Learning}},
	abstract = {While machine learning is rapidly being developed and deployed in health settings such as influenza prediction, there are critical challenges in using data from one environment in another due to variability in features; even within disease labels there can be differences (e.g. "fever" may mean something different reported in a doctor's office versus in an online app). Moreover, models are often built on passive, observational data which contain different distributions of population subgroups (e.g. men or women). Thus, there are two forms of instability between environments in this observational transport problem. We first harness knowledge from health to conceptualize the underlying causal structure of this problem in a health outcome prediction task. Based on sources of stability in the model, we posit that for human-sourced data and health prediction tasks we can combine environment and population information in a novel population-aware hierarchical Bayesian domain adaptation framework that harnesses multiple invariant components through population attributes when needed. We study the conditions under which invariant learning fails, leading to reliance on the environment-specific attributes. Experimental results for an influenza prediction task on four datasets gathered from different contexts show the model can improve prediction in the case of largely unlabelled target data from a new environment and different constituent population, by harnessing both environment and population invariant information. This work represents a novel, principled way to address a critical challenge by blending domain (health) knowledge and algorithmic innovation. The proposed approach will have a significant impact in many social settings wherein who and where the data comes from matters.},
	urldate = {2020-08-25},
	journal = {Proceedings of the ACM Conference on Health, Inference, and Learning},
	author = {Mhasawade, Vishwali and Rehman, Nabeel Abdur and Chunara, Rumi},
	month = apr,
	year = {2020},
	note = {arXiv: 1908.09222},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {182--192},
	}

@article{barak_approximating_2020,
	title = {Approximating a {Target} {Distribution} using {Weight} {Queries}},
	abstract = {A basic assumption in classical learning and estimation is the availability of a random sample from the target distribution. In domain adaptation this assumption is replaced with the availability of a sample from a source distribution, and a smaller or unlabeled sample from the target distribution. In this work, we consider a setting in which no random sampling from the target distribution is possible. Instead, given a large data set, it is possible to query the probability (weight) of a data point, or a set of data points, according to the target distribution. This can be the case when access to the target distribution is mediated, e.g., by specific measurements or by user relevance queries. We propose an algorithm for finding a reweighing of the data set which approximates the target distribution weights, using a limited number of target weight queries. The weighted data set may then be used in estimation and learning tasks, as a proxy for a sample from the target distribution. Given a hierarchical tree structure over the data set, which induces a class of weight functions, we prove that the algorithm approximates the best possible function, and upper bound the number of weight queries. In experiments, we demonstrate the advantage of the proposed algorithm over several baselines. A python implementation of the proposed algorithm and all experiments can be found at https://github.com/Nadav-Barak/AWP.},
	urldate = {2020-08-25},
	journal = {arXiv:2006.13636 [cs, stat]},
	author = {Barak, Nadav and Sabato, Sivan},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.13636},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	}

@article{van_nee_flexible_2020,
	title = {Flexible co-data learning for high-dimensional prediction},
	abstract = {Clinical research often focuses on complex traits in which many variables play a role in mechanisms driving, or curing, diseases. Clinical prediction is hard when data is high-dimensional, but additional information, like domain knowledge and previously published studies, may be helpful to improve predictions. Such complementary data, or co-data, provide information on the covariates, such as genomic location or p-values from external studies. Our method enables exploiting multiple and various co-data sources to improve predictions. We use discrete or continuous co-data to define possibly overlapping or hierarchically structured groups of covariates. These are then used to estimate adaptive multi-group ridge penalties for generalised linear and Cox models. We combine empirical Bayes estimation of group penalty hyperparameters with an extra level of shrinkage. This renders a uniquely flexible framework as any type of shrinkage can be used on the group level. The hyperparameter shrinkage learns how relevant a specific co-data source is, counters overfitting of hyperparameters for many groups, and accounts for structured co-data. We describe various types of co-data and propose suitable forms of hypershrinkage. The method is very versatile, as it allows for integration and weighting of multiple co-data sets, inclusion of unpenalised covariates and posterior variable selection. We demonstrate it on two cancer genomics applications and show that it may improve the performance of other dense and parsimonious prognostic models substantially, and stabilises variable selection.},
	urldate = {2020-08-25},
	journal = {arXiv:2005.04010 [stat]},
	author = {van Nee, Mirrelijn M. and Wessels, Lodewyk F. A. and van de Wiel, Mark A.},
	month = may,
	year = {2020},
	note = {arXiv: 2005.04010},
	keywords = {Statistics - Machine Learning, Statistics - Methodology},
	annote = {Comment: Document consists of main content (20 pages, 10 figures) and supplementary material (14 pages, 13 figures)},
	}

@article{mihalkova_transfer_nodate,
	title = {Transfer {Learning} by {Mapping} with {Minimal} {Target} {Data}},
	abstract = {This paper introduces the single-entity-centered setting for transfer across two relational domains. In this setting, target domain data contains information about only a single entity. We present the SR2LR algorithm that ﬁnds an effective mapping of the source model to the target domain in this setting and demonstsrate its effectiveness in three relational domains. Our experiments additionally show that the most accurate model for the source domain is not always the best model to use for transfer.},
	language = {en},
	author = {Mihalkova, Lilyana and Mooney, Raymond J},
	pages = {6},
	}

@misc{noauthor_supervised_nodate,
	title = {The {Supervised} {Machine} {Learning} book},
	abstract = {An upcoming textbook},
	language = {en-US},
	urldate = {2020-08-14},
	journal = {sml-book-page},
	}

@misc{noauthor_pdf_nodate-2,
	title = {[{PDF}] {Transfer} {Learning} by {Mapping} with {Minimal} {Target} {Data} {\textbar} {Semantic} {Scholar}},
	urldate = {2020-08-14}
}

@article{omohundro_family_nodate,
	title = {Family {Discovery}},
	abstract = {Family discovery" is the task of learning the dimension and structure of a parameterized family of stochastic models. It is especially appropriate when the training examples are partitioned into "episodes" of samples drawn from a single parameter value. We present three family discovery algorithms based on surface learning and show that they significantly improve performance over two alternatives on a parameterized classification task.},
	language = {en},
	author = {Omohundro, Stephen M},
	pages = {7},
	}

@article{sharkey_adaptive_1993,
	title = {Adaptive generalisation},
	volume = {7},
	issn = {1573-7462},
	abstract = {Adaptive generalisation is the ability to use prior knowledge in the performance of novel tasks. Thus, if we are to model intelligent behaviour with neural nets, they must be able to generalise across task domains. Our objective is to elucidate the aetiology of transfer of information between connectionist nets. First, a method is described that provides a standardised score for the quantification of how much task structure a net has extracted, and to what degree knowledge has been transferred between tasks. This method is then applied in three simulation studies to examine Input-to-Hidden (IH) and Hidden-to-Output (HO) decision hyperplanes as determinants of transfer effects. In the first study, positive transfer is demonstrated between functions that require the vertices of their spaces to be divided similarly, and negative transfer between functions that require decision regions of different shapes. In the other two studies, input and output similarity are varied independently in a series of paired associate learning tasks. Further explanation of transfer effects is provided through the use of a new technique that permits better visualisation of the entire computational space by showing both the relative position of inputs in Hidden Unit space, and the HO decision regions implemented by the set of weights.},
	language = {en},
	number = {5},
	urldate = {2020-08-14},
	journal = {Artificial Intelligence Review},
	author = {Sharkey, Noel E. and Sharkey, Amanda J. C.},
	month = oct,
	year = {1993},
	pages = {313--328}
}

@misc{noauthor_direct_nodate,
	title = {Direct {Transfer} of {Learned} {Information} {Among} {Neural} {Networks}},
	urldate = {2020-08-14},
	}

@inproceedings{pratt_non-literal_1993,
	title = {Non-literal {Transfer} {Among} {Neural} {Network} {Learners}},
	abstract = {In recent years, neural networks have been used for a wide variety of applications, from medical screening [ Rutenberg, 1992, Weber, 1990 ] to municipal power grid security [ Atlas et al., 1990c ] . Furthermore, comparisons between neural networks and more traditional techniques have shown that neural networks often produce competitive, and sometimes superior, results ( [ Weiss and Kulikowski, 1991, Shavlik et al., 1991, Thrun et al., 1991, Atlas et al., 1990b, Atlas et al., 1990c, Cole et al., 1990, Atlas et al., 1990a, Dietterich et al., 1990, Fisher and McKusick, 1989, Mooney et al., 1989, Pratt, 1990 ] ). Neural network training techniques still have room for improvement, however. Though they eventually achieve good performance levels, neural networks often require more computing time than competing methods (cf. [ Maren et al., 1990, Page 92 ] , [ Waibel et al., 1989 ] , [ Hertz et al., 1991, Page 120 ] ). One source of power which, if properly utilized, may help to alleviate these problems is networks that have been trained on tasks that are related to the one at hand. For example, a network trained for heart disease diagnosis in Hungary might be used to initialize one that's to be trained for heart disease diagnosis of Swiss patients. Or a speech recognition network trained on only British speakers might be used to facilitate training on a network for American speakers. This paper explores this issue of transfer of information from a trained neural network to a new learning task. It presents an algorithm for modifying network weights during transfer from a source to a target problem. Empirical results on benchmark problems from several domains illustrate that this algorithm can improve learning speed. This work was partially supported by DOE \#DE-FG02-91ER61129, through subcontract \#097P753 from the University of Wisconsin.},
	author = {Pratt, Lorien Y.},
	year = {1993}
}

@article{utrera_adversarially-trained_2020,
	title = {Adversarially-{Trained} {Deep} {Nets} {Transfer} {Better}},
	abstract = {Transfer learning has emerged as a powerful methodology for adapting pre-trained deep neural networks to new domains. This process consists of taking a neural network pre-trained on a large feature-rich source dataset, freezing the early layers that encode essential generic image properties, and then fine-tuning the last few layers in order to capture specific information related to the target situation. This approach is particularly useful when only limited or weakly labelled data are available for the new task. In this work, we demonstrate that adversarially-trained models transfer better across new domains than naturally-trained models, even though it's known that these models do not generalize as well as naturally-trained models on the source domain. We show that this behavior results from a bias, introduced by the adversarial training, that pushes the learned inner layers to more natural image representations, which in turn enables better transfer.},
	urldate = {2020-08-13},
	journal = {arXiv:2007.05869 [cs, stat]},
	author = {Utrera, Francisco and Kravitz, Evan and Erichson, N. Benjamin and Khanna, Rajiv and Mahoney, Michael W.},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.05869},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	}

@article{santurkar_breeds_2020,
	title = {{BREEDS}: {Benchmarks} for {Subpopulation} {Shift}},
	shorttitle = {{BREEDS}},
	abstract = {We develop a methodology for assessing the robustness of models to subpopulation shift---specifically, their ability to generalize to novel data subpopulations that were not observed during training. Our approach leverages the class structure underlying existing datasets to control the data subpopulations that comprise the training and test distributions. This enables us to synthesize realistic distribution shifts whose sources can be precisely controlled and characterized, within existing large-scale datasets. Applying this methodology to the ImageNet dataset, we create a suite of subpopulation shift benchmarks of varying granularity. We then validate that the corresponding shifts are tractable by obtaining human baselines for them. Finally, we utilize these benchmarks to measure the sensitivity of standard model architectures as well as the effectiveness of off-the-shelf train-time robustness interventions. Code and data available at https://github.com/MadryLab/BREEDS-Benchmarks .},
	urldate = {2020-08-13},
	journal = {arXiv:2008.04859 [cs, stat]},
	author = {Santurkar, Shibani and Tsipras, Dimitris and Madry, Aleksander},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.04859},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	}

@misc{lab_benchmarks_nodate,
	title = {Benchmarks for {Subpopulation} {Shift}},
	abstract = {Research highlights and perspectives on machine learning and optimization from MadryLab.},
	urldate = {2020-08-13},
	journal = {gradient science},
	author = {Lab, Madry},
	}

@article{shimodaira_improving_2000,
	title = {Improving predictive inference under covariate shift by weighting the log-likelihood function},
	volume = {90},
	issn = {0378-3758},
	abstract = {A class of predictive densities is derived by weighting the observed samples in maximizing the log-likelihood function. This approach is effective in cases such as sample surveys or design of experiments, where the observed covariate follows a different distribution than that in the whole population. Under misspecification of the parametric model, the optimal choice of the weight function is asymptotically shown to be the ratio of the density function of the covariate in the population to that in the observations. This is the pseudo-maximum likelihood estimation of sample surveys. The optimality is defined by the expected Kullback–Leibler loss, and the optimal weight is obtained by considering the importance sampling identity. Under correct specification of the model, however, the ordinary maximum likelihood estimate (i.e. the uniform weight) is shown to be optimal asymptotically. For moderate sample size, the situation is in between the two extreme cases, and the weight function is selected by minimizing a variant of the information criterion derived as an estimate of the expected loss. The method is also applied to a weighted version of the Bayesian predictive density. Numerical examples as well as Monte-Carlo simulations are shown for polynomial regression. A connection with the robust parametric estimation is discussed.},
	language = {en},
	number = {2},
	urldate = {2020-08-12},
	journal = {Journal of Statistical Planning and Inference},
	author = {Shimodaira, Hidetoshi},
	month = oct,
	year = {2000},
	keywords = {Akaike information criterion, Design of experiments, Importance sampling, Kullback–Leibler divergence, Misspecification, Sample surveys, Weighted least squares},
	pages = {227--244},
	}

@article{arjovsky_invariant_2020,
	title = {Invariant {Risk} {Minimization}},
	abstract = {We introduce Invariant Risk Minimization (IRM), a learning paradigm to estimate invariant correlations across multiple training distributions. To achieve this goal, IRM learns a data representation such that the optimal classifier, on top of that data representation, matches for all training distributions. Through theory and experiments, we show how the invariances learned by IRM relate to the causal structures governing the data and enable out-of-distribution generalization.},
	urldate = {2020-08-12},
	journal = {arXiv:1907.02893 [cs, stat]},
	author = {Arjovsky, Martin and Bottou, Léon and Gulrajani, Ishaan and Lopez-Paz, David},
	month = mar,
	year = {2020},
	note = {arXiv: 1907.02893},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	}

@inproceedings{mansour_domain_2009,
	title = {Domain {Adaptation}: {Learning} {Bounds} and {Algorithms}},
	shorttitle = {Domain {Adaptation}},
	abstract = {This paper addresses the general problem of domain adaptation which arises in a variety of applications where the distribution of the labeled sample available somewhat differs from that of the test data. Building on previous work by Ben-David et al. (2007), we introduce a novel distance between distributions, discrepancy distance, that is tailored to adaptation problems with arbitrary loss functions. We give Rademacher complexity bounds for estimating the discrepancy distance from finite samples for different loss functions. Using this distance, we derive novel generalization bounds for domain adaptation for a wide family of loss functions. We also present a series of novel adaptation bounds for large classes of regularization-based algorithms, including support vector machines and kernel ridge regression based on the empirical discrepancy. This motivates our analysis of the problem of minimizing the empirical discrepancy for various loss functions for which we also give novel algorithms. We report the results of preliminary experiments that demonstrate the benefits of our discrepancy minimization algorithms for domain adaptation.},
	urldate = {2020-08-12},
	booktitle = {Proceedings of the Conference on Learning Theory},
	author = {Mansour, Yishay and Mohri, Mehryar and Rostamizadeh, Afshin},
	month = feb,
	year = {2009},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: 12 pages, 4 figures},
	}
@book{sugiyama_density_2012,
	series = {Cambridge books online},
	title = {Density {Ratio} {Estimation} in {Machine} {Learning}},
	isbn = {978-0-521-19017-6},
	publisher = {Cambridge University Press},
	author = {Sugiyama, M. and Suzuki, T. and Kanamori, T.},
	year = {2012},
	lccn = {2011051726},
}
@article{cortes2019,
  author  = {Corinna Cortes and Mehryar Mohri and Andr{{\'e}}s Mu{{\~n}}oz Medina},
  title   = {Adaptation Based on Generalized Discrepancy},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {1},
  pages   = {1--30},
  url     = {http://jmlr.org/papers/v20/15-192.html}
}
@techreport{thrun_learning_1994,
	address = {Fort Belvoir, VA},
	title = {Learning {One} {More} {Thing}:},
	shorttitle = {Learning {One} {More} {Thing}},
	abstract = {Most research on machine learning has focused on scenarios in which a learner faces a single, isolated learning task. The lifelong learning framework assumes that the learner encounters a multitude of related learning tasks over its lifetime, providing the opportunity for the transfer of knowledge among these. This paper studies lifelong learning in the context of binary classiﬁcation. It presents the invariance approach, in which knowledge is transferred via a learned model of the invariances of the domain. Results on learning to recognize objects from color images demonstrate superior generalization capabilities if invariances are learned and used to bias subsequent learning.},
	language = {en},
	urldate = {2020-08-12},
	institution = {Defense Technical Information Center},
	author = {Thrun, Sebastian and Mitchell, Tom M.},
	month = sep,
	year = {1994},
	annote = {Early paper about transfer learning as a concept. Uses some weird definitions of invariance but is still informative. Empirical tests show that training on other tasks have some effect on later tasks. Hopefully beneficial.},
	}

@misc{noauthor_pdf_nodate-3,
	title = {[{PDF}] {On} learning how to learn learning strategies {\textbar} {Semantic} {Scholar}},
	abstract = {This paper introduces the \&quot;incremental self-improvement paradigm\&quot;. Unlike previous methods, incremental self-improvement encourages a reinforcement learning system to improve the way it learns, and to improve the way it improves the way it learns ... , without significant theoretical limitations the system is able to \&quot;shift its inductive bias\&quot; in a universal way. Its major features are: (1\vphantom{\{}\} There is no explicit difference between \&quot;learning\&quot;, \&quot;meta-learning\&quot;, and other kinds of information processing. Using a Turing machine equivalent programming language, the system itself occasionally executes self-delimiting, initially highly random \&quot;self-modification programs\&quot; which modify the context-dependent probabilities of future action sequences (including future self-modification programs\vphantom{\{}\}. (2\vphantom{\{}\} The system keeps only those probability modifications computed by \&quot;useful\&quot; selfmodification programs: those which bring about more payoff (reward, reinforcement\vphantom{\{}\} per time than all previous self-modification programs. (3) The computation of payoff per time takes into account all the computation time required for learning the entire system life is considered: boundaries between learning trials are ignored (if there are any). A particular implementation based on the novel paradigm is presented. It is designed to exploit what conventional digital machines are good at: fast storage addressing, arithmetic operations etc. Experiments illustrate the system\&\#39;s mode of},
	language = {en},
	urldate = {2020-08-12},
	annote = {A very general take on algorithms which improve themselves over their runtime. The analogy with knowledge transfer between timesteps and transfer learning is obvious.},
	}

@article{pan_survey_2010,
	title = {A {Survey} on {Transfer} {Learning}},
	volume = {22},
	issn = {1041-4347},
	abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classiﬁcation task in one domain of interest, but we only have sufﬁcient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classiﬁcation, regression and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as co-variate shift. We also explore some potential future issues in transfer learning research.},
	language = {en},
	number = {10},
	urldate = {2020-08-03},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Pan, Sinno Jialin and Yang, Qiang},
	month = oct,
	year = {2010},
	pages = {1345--1359},
	annote = {Good general overview of the theory and definitions of different types of transfer learning.
 
1},
	}

@article{caruana_multitask_1997,
	title = {Multitask {Learning}},
	volume = {28},
	issn = {1573-0565},
	abstract = {Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. This paper reviews prior work on MTL, presents new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals, and presents new results for MTL with k-nearest neighbor and kernel regression. In this paper we demonstrate multitask learning in three domains. We explain how multitask learning works, and show that there are many opportunities for multitask learning in real domains. We present an algorithm and results for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Because multitask learning works, can be applied to many different kinds of domains, and can be used with different learning algorithms, we conjecture there will be many opportunities for its use on real-world problems.},
	language = {en},
	number = {1},
	urldate = {2020-08-12},
	journal = {Machine Learning},
	author = {Caruana, Rich},
	month = jul,
	year = {1997},
	pages = {41--75},
	annote = {foundational paper on multi task learning, i.e training on several tasks at the same time. Goes into detail to show that it does work and is not a fluke and show how. Very nice.
Does make some assertions which are not obvious if true..}
}

@article{zhang_domain_2020,
	title = {Domain {Adaptation} {As} a {Problem} of {Inference} on {Graphical} {Models}},
	abstract = {This paper is concerned with data-driven unsupervised domain adaptation, where it is unknown in advance how the joint distribution changes across domains, i.e., what factors or modules of the data distribution remain invariant or change across domains. To develop an automated way of domain adaptation with multiple source domains, we propose to use a graphical model as a compact way to encode the change property of the joint distribution, which can be learned from data, and then view domain adaptation as a problem of Bayesian inference on the graphical models. Such a graphical model distinguishes between constant and varied modules of the distribution and specifies the properties of the changes across domains, which serves as prior knowledge of the changing modules for the purpose of deriving the posterior of the target variable \$Y\$ in the target domain. This provides an end-to-end framework of domain adaptation, in which additional knowledge about how the joint distribution changes, if available, can be directly incorporated to improve the graphical representation. We discuss how causality-based domain adaptation can be put under this umbrella. Experimental results on both synthetic and real data demonstrate the efficacy of the proposed framework for domain adaptation.},
	urldate = {2020-10-07},
	journal = {arXiv:2002.03278 [cs, stat]},
	author = {Zhang, Kun and Gong, Mingming and Stojanov, Petar and Huang, Biwei and Glymour, Clark},
	month = jun,
	year = {2020},
	note = {arXiv: 2002.03278},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 19 pages; 8 figures},
	}

@article{wu_information-theoretic_2020,
	title = {Information-theoretic analysis for transfer learning},
	abstract = {Transfer learning, or domain adaptation, is concerned with machine learning problems in which training and testing data come from possibly different distributions (denoted as \${\textbackslash}mu\$ and \${\textbackslash}mu'\$, respectively). In this work, we give an information-theoretic analysis on the generalization error and the excess risk of transfer learning algorithms, following a line of work initiated by Russo and Zhou. Our results suggest, perhaps as expected, that the Kullback-Leibler (KL) divergence \$D(mu{\textbar}{\textbar}mu')\$ plays an important role in characterizing the generalization error in the settings of domain adaptation. Specifically, we provide generalization error upper bounds for general transfer learning algorithms and extend the results to a specific empirical risk minimization (ERM) algorithm where data from both distributions are available in the training phase. We further apply the method to iterative, noisy gradient descent algorithms, and obtain upper bounds which can be easily calculated, only using parameters from the learning algorithms. A few illustrative examples are provided to demonstrate the usefulness of the results. In particular, our bound is tighter in specific classification problems than the bound derived using Rademacher complexity.},
	urldate = {2020-10-09},
	journal = {arXiv:2005.08697 [cs, stat]},
	author = {Wu, Xuetong and Manton, Jonathan H. and Aickelin, Uwe and Zhu, Jingge},
	month = may,
	year = {2020},
	note = {arXiv: 2005.08697},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Accepted paper in 2020 IEEE International Symposium on Information Theory (ISIT)},
	annote = {Information theoretic paper. Gives bounds on generalisation and excessive risk in the transfer learning setting.},
	}

@article{polo_covariate_2020,
	title = {Covariate {Shift} {Adaptation} in {High}-{Dimensional} and {Divergent} {Distributions}},
	abstract = {In real world applications of supervised learning methods, training and test sets are often sampled from the distinct distributions and we must resort to domain adaptation techniques. One special class of techniques is Covariate Shift Adaptation, which allows practitioners to obtain good generalization performance in the distribution of interest when domains differ only by the marginal distribution of features. Traditionally, Covariate Shift Adaptation is implemented using Importance Weighting which may fail in high-dimensional settings due to small Effective Sample Sizes (ESS). In this paper, we propose (i) a connection between ESS, high-dimensional settings and generalization bounds and (ii) a simple, general and theoretically sound approach to combine feature selection and Covariate Shift Adaptation. The new approach yields good performance with improved ESS.},
	urldate = {2020-10-09},
	journal = {arXiv:2010.01184 [cs, stat]},
	author = {Polo, Felipe Maia and Vicente, Renato},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.01184
version: 1},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology, Computer Science - Artificial Intelligence},
	}

@article{robey_model-based_2020,
	title = {Model-{Based} {Robust} {Deep} {Learning}},
	abstract = {While deep learning has resulted in major breakthroughs in many application domains, the frameworks commonly used in deep learning remain fragile to artificially-crafted and imperceptible changes in the data. In response to this fragility, adversarial training has emerged as a principled approach for enhancing the robustness of deep learning with respect to norm-bounded perturbations. However, there are other sources of fragility for deep learning that are arguably more common and less thoroughly studied. Indeed, natural variation such as lighting or weather conditions can significantly degrade the accuracy of trained neural networks, proving that such natural variation presents a significant challenge for deep learning. In this paper, we propose a paradigm shift from perturbation-based adversarial robustness toward \{{\textbackslash}em model-based robust deep learning\}. Our objective is to provide general training algorithms that can be used to train deep neural networks to be robust against natural variation in data. Critical to our paradigm is first obtaining a {\textbackslash}emph\{model of natural variation\} which can be used to vary data over a range of natural conditions. Such models may be either known a priori or else learned from data. In the latter case, we show that deep generative models can be used to learn models of natural variation that are consistent with realistic conditions. We then exploit such models in three novel model-based robust training algorithms in order to enhance the robustness of deep learning with respect to the given model. Our extensive experiments show that across a variety of naturally-occurring conditions and across various datasets, deep neural networks trained with our model-based algorithms significantly outperform both standard deep learning algorithms as well as norm-bounded robust deep learning algorithms.},
	urldate = {2020-10-12},
	journal = {arXiv:2005.10247 [cs, stat]},
	author = {Robey, Alexander and Hassani, Hamed and Pappas, George J.},
	month = may,
	year = {2020},
	note = {arXiv: 2005.10247},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Can learn to transfer if we know the thing that changes between the domains? Can we learn to model that specific thing?
 
Ex: weather effects for images, can we use image-to-image networks to learn the nuisance variable that govern the effects and then apply for radically different image settings?},
	}

@article{javanmard_precise_2020,
	title = {Precise {Tradeoffs} in {Adversarial} {Training} for {Linear} {Regression}},
	abstract = {Despite breakthrough performance, modern learning models are known to be highly vulnerable to small adversarial perturbations in their inputs. While a wide variety of recent {\textbackslash}emph\{adversarial training\} methods have been effective at improving robustness to perturbed inputs (robust accuracy), often this benefit is accompanied by a decrease in accuracy on benign inputs (standard accuracy), leading to a tradeoff between often competing objectives. Complicating matters further, recent empirical evidence suggest that a variety of other factors (size and quality of training data, model size, etc.) affect this tradeoff in somewhat surprising ways. In this paper we provide a precise and comprehensive understanding of the role of adversarial training in the context of linear regression with Gaussian features. In particular, we characterize the fundamental tradeoff between the accuracies achievable by any algorithm regardless of computational power or size of the training data. Furthermore, we precisely characterize the standard/robust accuracy and the corresponding tradeoff achieved by a contemporary mini-max adversarial training approach in a high-dimensional regime where the number of data points and the parameters of the model grow in proportion to each other. Our theory for adversarial training algorithms also facilitates the rigorous study of how a variety of factors (size and quality of training data, model overparametrization etc.) affect the tradeoff between these two competing accuracies.},
	urldate = {2020-10-12},
	journal = {arXiv:2002.10477 [cs, math, stat]},
	author = {Javanmard, Adel and Soltanolkotabi, Mahdi and Hassani, Hamed},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.10477},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
	}

@article{saxe_information_2019,
	title = {On the information bottleneck theory of deep learning},
	volume = {2019},
	issn = {1742-5468},
	abstract = {The practical successes of deep neural networks have not been matched by theoretical progress that satisfyingly explains their behavior. In this work, we study the information bottleneck (IB) theory of deep learning, which makes three speciﬁc claims: ﬁrst, that deep networks undergo two distinct phases consisting of an initial ﬁtting phase and a subsequent compression phase; second, that the compression phase is causally related to the excellent generalization performance of deep networks; and third, that the compression phase occurs due to the diffusion-like behavior of stochastic gradient descent. Here we show that none of these claims hold true in the general case. Through a combination of analytical results and simulation, we demonstrate that the information plane trajectory is predominantly a function of the neural nonlinearity employed: double-sided saturating nonlinearities like tanh yield a compression phase as neural activations enter the saturation regime, but linear activation functions and single-sided saturating nonlinearities like the widely used ReLU in fact do not. Moreover, we ﬁnd that there is no evident causal connection between compression and generalization: networks that do not compress are still capable of generalization, and vice versa. Next, we show that the compression phase, when it exists, does not arise from stochasticity in training by demonstrating that we can replicate the IB ﬁndings using full batch gradient descent rather than stochastic gradient descent. Finally, we show that when an input domain consists of a subset of task-relevant and task-irrelevant information, hidden representations do compress the task-irrelevant information, although the overall information about the input may monotonically increase with training time, and that this compression happens concurrently with the ﬁtting process rather than during a subsequent compression period.},
	language = {en},
	number = {12},
	urldate = {2020-11-05},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	author = {Saxe, Andrew M and Bansal, Yamini and Dapello, Joel and Advani, Madhu and Kolchinsky, Artemy and Tracey, Brendan D and Cox, David D},
	month = dec,
	year = {2019},
	pages = {124020},
	}

@article{salthe_hierarchical_2012,
	title = {Hierarchical {Structures}},
	volume = {22},
	issn = {1122-1151, 1572-8390},
	abstract = {This paper compares the two known logical forms of hierarchy, both of which have been used in models of natural phenomena, including the biological. I contrast their general properties, internal formal relations, modes of growth (emergence) in applications to the natural world, criteria for applying them, the complexities that they embody, their dynamical relations in applied models, and their informational relations and semiotic aspects.},
	language = {en},
	number = {3},
	urldate = {2020-11-05},
	journal = {Axiomathes},
	author = {Salthe, Stanley N.},
	month = sep,
	year = {2012},
	pages = {355--383},
	annote = {A more philosophically minded paper about the prevalence of hierarchical structures in science and how to think about them.},
	}

@InProceedings{acuna_fdiv_2021,
  title = 	 {f-Domain Adversarial Learning: Theory and Algorithms},
  author =       {Acuna, David and Zhang, Guojun and Law, Marc T. and Fidler, Sanja},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {66--75},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/acuna21a/acuna21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/acuna21a.html}
}

@InProceedings{wu_asymmetric_2019,
  title = 	 {Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment},
  author =       {Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {6872--6881},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/wu19f/wu19f.pdf},
  url = 	 {https://proceedings.mlr.press/v97/wu19f.html}
  }

@article{zhang_localized_2020,
	title = {On {Localized} {Discrepancy} for {Domain} {Adaptation}},
	abstract = {We propose the discrepancy-based generalization theories for unsupervised domain adaptation. Previous theories introduced distribution discrepancies defined as the supremum over complete hypothesis space. The hypothesis space may contain hypotheses that lead to unnecessary overestimation of the risk bound. This paper studies the localized discrepancies defined on the hypothesis space after localization. First, we show that these discrepancies have desirable properties. They could be significantly smaller than the pervious discrepancies. Their values will be different if we exchange the two domains, thus can reveal asymmetric transfer difficulties. Next, we derive improved generalization bounds with these discrepancies. We show that the discrepancies could influence the rate of the sample complexity. Finally, we further extend the localized discrepancies for achieving super transfer and derive generalization bounds that could be even more sample-efficient on source domain.},
	urldate = {2020-11-04},
	journal = {arXiv:2008.06242 [cs, stat]},
	author = {Zhang, Yuchen and Long, Mingsheng and Wang, Jianmin and Jordan, Michael I.},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.06242},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Looks at discrepancy measures between localised parts of two distributions. This shows to be better than the previous measures which were suprema over the whole hypothesis class. This takes subsets of the class which hopefully contains the optimal one.
 
They consider hypotheses which are better than some threshold on the training set.
 },
	}

@misc{noauthor_papers_nodate,
	title = {Papers with {Code} - {Nonvacuous} {Loss} {Bounds} with {Fast} {Rates} for {Neural} {Networks} via {Conditional} {Information} {Measures}},
	abstract = {No code available yet.},
	language = {en},
	urldate = {2020-11-04},
	}

@article{zhou_non-vacuous_2018,
	title = {Non-{Vacuous} {Generalization} {Bounds} at the {ImageNet} {Scale}: {A} {PAC}-{Bayesian} {Compression} {Approach}},
	volume = {1804},
	shorttitle = {Non-{Vacuous} {Generalization} {Bounds} at the {ImageNet} {Scale}},
	abstract = {Modern neural networks are highly overparameterized, with capacity to 
substantially overfit to training data. Nevertheless, these networks
often generalize well in practice. It has also been observed that
trained networks can often be "compressed" to much smaller
representations. The purpose of this paper is to connect these two
empirical observations. Our main technical result is a generalization
bound for compressed networks based on the compressed size. Combined
with off-the-shelf compression algorithms, the bound leads to state of
the art generalization guarantees; in particular, we provide the first
non-vacuous generalization guarantees for realistic architectures
applied to the ImageNet classification problem. As additional evidence
connecting compression and generalization, we show that compressibility
of models that tend to overfit is limited: We establish an absolute
limit on expected compressibility as a function of expected
generalization error, where the expectations are over the random choice
of training examples. The bounds are complemented by empirical results
that show an increase in overfitting implies an increase in the number
of bits required to describe a trained network.},
	urldate = {2020-11-04},
	journal = {arXiv e-prints},
	author = {Zhou, Wenda and Veitch, Victor and Austern, Morgane and Adams, Ryan P. and Orbanz, Peter},
	month = apr,
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {arXiv:1804.05862},
	}

@article{tishby_deep_2015,
	title = {Deep {Learning} and the {Information} {Bottleneck} {Principle}},
	abstract = {Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.},
	urldate = {2020-10-31},
	journal = {arXiv:1503.02406 [cs]},
	author = {Tishby, Naftali and Zaslavsky, Noga},
	month = mar,
	year = {2015},
	note = {arXiv: 1503.02406},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: 5 pages, 2 figures, Invited paper to ITW 2015; 2015 IEEE Information Theory Workshop (ITW) (IEEE ITW 2015)},
	annote = {Paper which says a lot but shows very little. They claim that there exists a strong link between the mutual information between input and output and this can be computed between layers in a DNN and thus be used as a metric for successful learning.
 
It feels a bit hazy and many details are left out as well as any empirical proofs of concept.
 
Claims:
First, that deep networks undergo two distinct phases consisting of aninitial fitting phase and a subsequent compression phase.
Second, that the compression phase is causally related to the excellent generalization performance of deepnetworks
Third, that the compression phase occurs due to the diffusion-likebehavior of stochastic gradient descent.},
	}

@article{jose_information-theoretic_2020,
	title = {Information-{Theoretic} {Bounds} on {Transfer} {Generalization} {Gap} {Based} on {Jensen}-{Shannon} {Divergence}},
	abstract = {In transfer learning, training and testing data sets are drawn from different data distributions. The transfer generalization gap is the difference between the population loss on the target data distribution and the training loss. The training data set generally includes data drawn from both source and target distributions. This work presents novel information-theoretic upper bounds on the average transfer generalization gap that capture \$(i)\$ the domain shift between the target data distribution \$P'\_Z\$ and the source distribution \$P\_Z\$ through a two-parameter family of generalized \$({\textbackslash}alpha\_1,{\textbackslash}alpha\_2)\$-Jensen-Shannon (JS) divergences; and \$(ii)\$ the sensitivity of the transfer learner output \$W\$ to each individual sample of the data set \$Z\_i\$ via the mutual information \$I(W;Z\_i)\$. For \${\textbackslash}alpha\_1 {\textbackslash}in (0,1)\$, the \$({\textbackslash}alpha\_1,{\textbackslash}alpha\_2)\$-JS divergence can be bounded even when the support of \$P\_Z\$ is not included in that of \$P'\_Z\$. This contrasts the Kullback-Leibler (KL) divergence \$D\_\{KL\}(P\_Z{\textbar}{\textbar}P'\_Z)\$-based bounds of Wu et al. [1], which are vacuous under this assumption. Moreover, the obtained bounds hold for unbounded loss functions with bounded cumulant generating functions, unlike the \${\textbackslash}phi\$-divergence based bound of Wu et al. [1]. We also obtain new upper bounds on the average transfer excess risk in terms of the \$({\textbackslash}alpha\_1,{\textbackslash}alpha\_2)\$-JS divergence for empirical weighted risk minimization (EWRM), which minimizes the weighted average training losses over source and target data sets. Finally, we provide a numerical example to illustrate the merits of the introduced bounds.},
	urldate = {2020-10-31},
	journal = {arXiv:2010.09484 [cs, eess, math]},
	author = {Jose, Sharu Theresa and Simeone, Osvaldo},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.09484},
	keywords = {Computer Science - Information Theory, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
	annote = {Comment: Submitted for conference publication},
	}

@article{bach_submodular_2016,
	title = {Submodular {Functions}: from {Discrete} to {Continous} {Domains}},
	shorttitle = {Submodular {Functions}},
	abstract = {Submodular set-functions have many applications in combinatorial optimization, as they can be minimized and approximately maximized in polynomial time. A key element in many of the algorithms and analyses is the possibility of extending the submodular set-function to a convex function, which opens up tools from convex optimization. Submodularity goes beyond set-functions and has naturally been considered for problems with multiple labels or for functions defined on continuous domains, where it corresponds essentially to cross second-derivatives being nonpositive. In this paper, we show that most results relating submodularity and convexity for set-functions can be extended to all submodular functions. In particular, (a) we naturally define a continuous extension in a set of probability measures, (b) show that the extension is convex if and only if the original function is submodular, (c) prove that the problem of minimizing a submodular function is equivalent to a typically non-smooth convex optimization problem, and (d) propose another convex optimization problem with better computational properties (e.g., a smooth dual problem). Most of these extensions from the set-function situation are obtained by drawing links with the theory of multi-marginal optimal transport, which provides also a new interpretation of existing results for set-functions. We then provide practical algorithms to minimize generic submodular functions on discrete domains, with associated convergence rates.},
	urldate = {2020-11-27},
	journal = {arXiv:1511.00394 [cs, math]},
	author = {Bach, Francis},
	month = feb,
	year = {2016},
	note = {arXiv: 1511.00394},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
	}

@article{alvarez-melis_structured_2017,
	title = {Structured {Optimal} {Transport}},
	abstract = {Optimal Transport has recently gained interest in machine learning for applications ranging from domain adaptation, sentence similarities to deep learning. Yet, its ability to capture frequently occurring structure beyond the "ground metric" is limited. In this work, we develop a nonlinear generalization of (discrete) optimal transport that is able to reflect much additional structure. We demonstrate how to leverage the geometry of this new model for fast algorithms, and explore connections and properties. Illustrative experiments highlight the benefit of the induced structured couplings for tasks in domain adaptation and natural language processing.},
	urldate = {2020-11-27},
	journal = {arXiv:1712.06199 [cs, stat]},
	author = {Alvarez-Melis, David and Jaakkola, Tommi S. and Jegelka, Stefanie},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.06199},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	}

@article{nickel_poincare_2017,
	title = {Poincar{\textbackslash}'e {Embeddings} for {Learning} {Hierarchical} {Representations}},
	abstract = {Representation learning has become an invaluable approach for learning from symbolic data such as text and graphs. However, while complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space -- or more precisely into an n-dimensional Poincar{\textbackslash}'e ball. Due to the underlying hyperbolic geometry, this allows us to learn parsimonious representations of symbolic data by simultaneously capturing hierarchy and similarity. We introduce an efficient algorithm to learn the embeddings based on Riemannian optimization and show experimentally that Poincar{\textbackslash}'e embeddings outperform Euclidean embeddings significantly on data with latent hierarchies, both in terms of representation capacity and in terms of generalization ability.},
	urldate = {2020-11-27},
	journal = {arXiv:1705.08039 [cs, stat]},
	author = {Nickel, Maximilian and Kiela, Douwe},
	month = may,
	year = {2017},
	note = {arXiv: 1705.08039},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Interesting paper about the process of learning the embedding of data with a latent hierarchy in hyperbolic space .
 },
	}

@article{kipf_semi-supervised_2017,
	title = {Semi-{Supervised} {Classification} with {Graph} {Convolutional} {Networks}},
	abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
	urldate = {2020-11-27},
	journal = {arXiv:1609.02907 [cs, stat]},
	author = {Kipf, Thomas N. and Welling, Max},
	month = feb,
	year = {2017},
	note = {arXiv: 1609.02907},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Published as a conference paper at ICLR 2017},
	}

@article{hamilton_representation_2018,
	title = {Representation {Learning} on {Graphs}: {Methods} and {Applications}},
	shorttitle = {Representation {Learning} on {Graphs}},
	abstract = {Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.},
	urldate = {2020-11-27},
	journal = {arXiv:1709.05584 [cs]},
	author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
	month = apr,
	year = {2018},
	note = {arXiv: 1709.05584},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks},
	annote = {Comment: Published in the IEEE Data Engineering Bulletin, September 2017; version with minor corrections},
	}

@article{melis_optimal_nodate,
	title = {Optimal {Transport} in {Structured} {Domains}: {Algorithms} and {Applications}},
	abstract = {Optimal transport provides a powerful mathematical framework for comparing probability distributions, and has found successful application in various problems in machine learning, including point cloud matching, generative modeling, and document comparison. However, some important limitations curtail its broader applicability. In many applications there is often additional structural information that is not captured by the classic formulation of the problem. This information can range from explicit tree and graph-like structure, to global structural invariances. Failure to fully model this structure can hinder—if not preclude—the use of optimal transport-based approaches. This thesis presents several extensions of the optimal transport problem to incorporate structural information. First, a non-linear generalization of the cost objective based on submodularity is proposed. The resulting formulation provides a ﬂexible framework to model explicit or latent discrete structure in the data and admits eﬃcient optimization. Next, we investigate the issue of geometric invariances when matching embedded representations, for which a general framework for optimal transport in the presence of latent global transformations is developed. Various approaches to solve the resulting optimization problem are proposed and compared. The last part of the thesis addresses the problem of aligning datasets in which the structure is encoded through non-Euclidean manifolds, such as hyperbolic spaces. In response to an unexpected type of invariance that hyperbolic embeddings learned from data exhibit, a novel framework that interweaves optimal transport and hyperbolic nonlinear registration with deep neural networks is proposed.},
	language = {en},
	author = {Melis, David Alvarez},
	pages = {172},
	}

@article{courty_optimal_2016,
	title = {Optimal {Transport} for {Domain} {Adaptation}},
	abstract = {Domain adaptation from one data space (or domain) to another is one of the most challenging tasks of modern data analytics. If the adaptation is done correctly, models built on a specific data space become more robust when confronted to data depicting the same semantic concepts (the classes), but observed by another observation system with its own specificities. Among the many strategies proposed to adapt a domain to another, finding a common representation has shown excellent properties: by finding a common representation for both domains, a single classifier can be effective in both and use labelled samples from the source domain to predict the unlabelled samples of the target domain. In this paper, we propose a regularized unsupervised optimal transportation model to perform the alignment of the representations in the source and target domains. We learn a transportation plan matching both PDFs, which constrains labelled samples in the source domain to remain close during transport. This way, we exploit at the same time the few labeled information in the source and the unlabelled distributions observed in both domains. Experiments in toy and challenging real visual adaptation examples show the interest of the method, that consistently outperforms state of the art approaches.},
	urldate = {2020-11-27},
	journal = {arXiv:1507.00504 [cs]},
	author = {Courty, Nicolas and Flamary, Rémi and Tuia, Devis and Rakotomamonjy, Alain},
	month = jun,
	year = {2016},
	note = {arXiv: 1507.00504},
	keywords = {Computer Science - Machine Learning},
	}

@article{ambrosio_users_nodate,
	title = {A user’s guide to optimal transport},
	language = {en},
	author = {Ambrosio, Luigi and Gigli, Nicola},
	pages = {141},
	}

@article{kolouri_transport-based_2016,
	title = {Transport-based analysis, modeling, and learning from signal and data distributions},
	abstract = {Transport-based techniques for signal and data analysis have received increased attention recently. Given their abilities to provide accurate generative models for signal intensities and other data distributions, they have been used in a variety of applications including content-based retrieval, cancer detection, image super-resolution, and statistical machine learning, to name a few, and shown to produce state of the art in several applications. Moreover, the geometric characteristics of transport-related metrics have inspired new kinds of algorithms for interpreting the meaning of data distributions. Here we provide an overview of the mathematical underpinnings of mass transport-related methods, including numerical implementation, as well as a review, with demonstrations, of several applications.},
	urldate = {2020-11-27},
	journal = {arXiv:1609.04767 [cs]},
	author = {Kolouri, Soheil and Park, Serim and Thorpe, Matthew and Slepčev, Dejan and Rohde, Gustavo K.},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.04767},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	}
@inproceedings{hoffman_2018,
author = {Hoffman, Judy and Mohri, Mehryar and Zhang, Ningshan},
title = {Algorithms and Theory for Multiple-Source Adaptation},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present a number of novel contributions to the multiple-source adaptation problem. We derive new normalized solutions with strong theoretical guarantees for the cross-entropy loss and other similar losses. We also provide new guarantees that hold in the case where the conditional probabilities for the source domains are distinct. Moreover, we give new algorithms for determining the distribution-weighted combination solution for the cross-entropy loss and other losses. We report the results of a series of experiments with real-world datasets. We find that our algorithm outperforms competing approaches by producing a single robust model that performs well on any target mixture distribution. Altogether, our theory, algorithms, and empirical results provide a full solution for the multiple-source adaptation problem with very practical benefits.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {8256–8266},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@article{oberst_characterization_2020,
	title = {Characterization of {Overlap} in {Observational} {Studies}},
	abstract = {Overlap between treatment groups is required for non-parametric estimation of causal effects. If a subgroup of subjects always receives the same intervention, we cannot estimate the effect of intervention changes on that subgroup without further assumptions. When overlap does not hold globally, characterizing local regions of overlap can inform the relevance of causal conclusions for new subjects, and can help guide additional data collection. To have impact, these descriptions must be interpretable for downstream users who are not machine learning experts, such as policy makers. We formalize overlap estimation as a problem of finding minimum volume sets subject to coverage constraints and reduce this problem to binary classification with Boolean rule classifiers. We then generalize this method to estimate overlap in off-policy policy evaluation. In several real-world applications, we demonstrate that these rules have comparable accuracy to black-box estimators and provide intuitive and informative explanations that can inform policy making.},
	urldate = {2020-12-04},
	journal = {arXiv:1907.04138 [cs, stat]},
	author = {Oberst, Michael and Johansson, Fredrik D. and Wei, Dennis and Gao, Tian and Brat, Gabriel and Sontag, David and Varshney, Kush R.},
	month = jun,
	year = {2020},
	note = {arXiv: 1907.04138},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: To appear at AISTATS 2020},
	}

@article{makar_estimation_2020,
	title = {Estimation of {Bounds} on {Potential} {Outcomes} {For} {Decision} {Making}},
	abstract = {Estimation of individual treatment effects is commonly used as the basis for contextual decision making in fields such as healthcare, education, and economics. However, it is often sufficient for the decision maker to have estimates of upper and lower bounds on the potential outcomes of decision alternatives to assess risks and benefits. We show that, in such cases, we can improve sample efficiency by estimating simple functions that bound these outcomes instead of estimating their conditional expectations, which may be complex and hard to estimate. Our analysis highlights a trade-off between the complexity of the learning task and the confidence with which the learned bounds hold. Guided by these findings, we develop an algorithm for learning upper and lower bounds on potential outcomes which optimize an objective function defined by the decision maker, subject to the probability that bounds are violated being small. Using a clinical dataset and a well-known causality benchmark, we demonstrate that our algorithm outperforms baselines, providing tighter, more reliable bounds.},
	urldate = {2020-12-04},
	journal = {arXiv:1910.04817 [cs, stat]},
	author = {Makar, Maggie and Johansson, Fredrik D. and Guttag, John and Sontag, David},
	month = aug,
	year = {2020},
	note = {arXiv: 1910.04817},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	}

@article{ben-david_impossibility_nodate,
	title = {Impossibility {Theorems} for {Domain} {Adaptation}},
	abstract = {The domain adaptation problem in machine learning occurs when the test data generating distribution diﬀers from the one that generates the training data. It is clear that the success of learning under such circumstances depends on similarities between the two data distributions. We study assumptions about the relationship between the two distributions that one needed for domain adaptation learning to succeed. We analyze the assumptions in an agnostic PAC-style learning model for a the setting in which the learner can access a labeled training data sample and an unlabeled sample generated by the test data distribution. We focus on three assumptions: (i) similarity between the unlabeled distributions, (ii) existence of a classiﬁer in the hypothesis class with low error on both training and testing distributions, and (iii) the covariate shift assumption. I.e., the assumption that the conditioned label distribution (for each data point) is the same for both the training and test distributions. We show that without either assumption (i) or (ii), the combination of the remaining assumptions is not suﬃcient to guarantee successful learning. Our negative results hold with respect to any domain adaptation learning algorithm, as long as it does not have access to target labeled examples. In particular, we provide formal proofs that the popular covariate shift assumption is rather weak and does not relieve the necessity of the other assumptions.},
	language = {en},
	author = {Ben-David, Shai and Luu, Teresa and Lu, Tyler and Pal, David},
	pages = {8},
	annote = {Very good paper about showing that certain assumptions cannot imply succesful domain adaptation. Something like this would probably be what I am supposed to achieve.},
	}
	@inproceedings{mansour_domain_2008,
          title = {Domain {Adaptation} with {Multiple} {Sources}},
           abstract = {This paper presents a theoretical analysis of the problem of domain adaptation with multiple sources. For each source domain, the distribution over the input points as well as a hypothes    is with error at most ǫ are given. The problem con- sists of combining these hypotheses to derive a hypothesis with small error with respect to the target domain. We present several theoretical results rela    ting to this problem. In particular, we prove that standard convex combinations of the source hypotheses may in fact perform very poorly and that, instead, combinations weighted by the source distributions     benefit from favorable theoretical guarantees. Our main result shows that, remarkably, for any fixed target f unction, there exists a distribution weighted combining rule that has a loss of at most ǫ with r    espect to any target mixture of the source distributions. We further generalize the setting from a single target function to multiple consistent target functions and show the existence of a combining rule w    ith error at most 3ǫ. Finally, we report empirical results for a multiple source adaptation problem with a real-world dataset.},
           author = {Mansour, Yishay and Mohri, Mehryar and Rostamizadeh, Afshin},
           booktitle = {Proceedings of the Conference on Neural Information Processing Systems (NIPS)},
           month = jan,
           year = {2008},
           pages = {1041--1048},
           file = {Mansour et al. - Domain Adaptation with Multiple Sources.pdf:/home/adam/Zotero/storage/GX89FX7Y/Mansour et al. - Domain Adaptation with Multiple Sources.pdf:application/pdf},
   }
@inproceedings{mansour_2009b,
title = "Multiple source adaptation and the R{\'e}nyi divergence",
author = "Yishay Mansour and Mehryar Mohri and Afshin Rostamizadeh",
year = "2009",
language = "English (US)",
series = "Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence, UAI 2009",
publisher = "AUAI Press",
pages = "367--374",
booktitle = "Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence, UAI 2009",
}
	@inproceedings{cortes_adaptation_2015,
           address = {Sydney NSW Australia},
          title = {Adaptation {Algorithm} and {Theory} {Based} on {Generalized} {Discrepancy}},
           isbn = {978-1-4503-3664-2},
           abstract = {We present a new algorithm for domain adaptation improving upon the discrepancy minimization algorithm (DM), which was previously shown to outperform a number of popular algorithms desig    ned for this task. Unlike most previous approaches adopted for domain adaptation, our algorithm does not consist of a ﬁxed reweighting of the losses over the training sample. Instead, it uses a reweighting     that depends on the hypothesis considered and is based on the minimization of a new measure of generalized discrepancy. We give a detailed description of our algorithm and show that it can be formulated as     a convex optimization problem. We also present a detailed theoretical analysis of its learning guarantees, which helps us select its parameters. Finally, we report the results of experiments demonstrating t    hat it improves upon the DM algorithm in several tasks.},
           language = {en},
           urldate = {2022-04-12},
          booktitle = {Proceedings of the 21th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
          publisher = {ACM},
          author = {Cortes, Corinna and Mohri, Mehryar and Muñoz Medina, Andrés},
          month = aug,
          year = {2015},
          pages = {169--178},
          file = {Cortes et al. - 2015 - Adaptation Algorithm and Theory Based on Generaliz.pdf:/home/adam/Zotero/storage/2HHHCC63/Cortes et al. - 2015 - Adaptation Algorithm and Theory Based on Generaliz.pdf    :application/pdf},
  }

@article{kuroki_unsupervised_2019,
           title = {Unsupervised {Domain} {Adaptation} {Based} on {Source}-{Guided} {Discrepancy}},
           volume = {33},
           number = {01},
           journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
           author = {Kuroki, Seiichi and Charoenphakdee, Nontawat and Bao, Han and Honda, Junya and Sato, Issei and Sugiyama, Masashi},
           month = jul,
           year = {2019},
           pages = {4122--4129},
  }

@inproceedings{ben-david_analysis_nodate,
	title = {Analysis of {Representations} for {Domain} {Adaptation}},
	abstract = {Discriminative learning methods for classiﬁcation perform well when training and test data are drawn from the same distribution. In many situations, though, we have labeled training data for a source domain, and we wish to learn a classiﬁer which performs well on a target domain with a different distribution. Under what conditions can we adapt a classiﬁer trained on the source domain for use in the target domain? Intuitively, a good feature representation is a crucial factor in the success of domain adaptation. We formalize this intuition theoretically with a generalization bound for domain adaption. Our theory illustrates the tradeoffs inherent in designing a representation for domain adaptation and gives a new justiﬁcation for a recently proposed model. It also points toward a promising new model for domain adaptation: one which explicitly minimizes the difference between the source and target domains, while at the same time maximizing the margin of the training set.},
	language = {en},
	author = {Ben-David, Shai and Blitzer, John and Crammer, Koby and Pereira, Fernando},
	pages = {8},
	}

@article{blitzer_learning,
	title = {Learning {Bounds} for {Domain} {Adaptation}},
	abstract = {Empirical risk minimization offers well-known learning guarantees when training and test data come from the same domain. In the real world, though, we often wish to adapt a classiﬁer from a source domain with a large amount of training data to different target domain with very little training data. In this work we give uniform convergence bounds for algorithms that minimize a convex combination of source and target empirical risk. The bounds explicitly model the inherent trade-off between training on a large but inaccurate source data set and a small but accurate target training set. Our theory also gives results when we have multiple source domains, each of which may have a different number of instances, and we exhibit cases in which minimizing a non-uniform combination of source risks can achieve much lower target error than standard empirical risk minimization.},
	language = {en},
	year ={2008},
	journal={Proceedings of the Conference on Neural Information Processing Systems (NIPS)},
	author = {Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Wortman, Jennifer},
	pages = {8},
	}

@book{quinonero-candela_dataset_2009,
	address = {Cambridge, Mass},
	series = {Neural information processing series},
	title = {Dataset shift in machine learning},
	isbn = {978-0-262-17005-5},
	language = {en},
	publisher = {MIT Press},
	editor = {Quiñonero-Candela, Joaquin},
	year = {2009},
	note = {OCLC: ocn227205909},
	keywords = {Machine learning},
	}

@inproceedings{sugiyama_generalization_2005,
	title = {Generalization error estimation under covariate shift},
	abstract = {Abstract: In supervised learning, it is almost always assumed that the training and test input points follow the same probability distribution. However, this assumption is violated, e.g., in interpolation, extrapolation, active learning, or classification with imbalanced data. In such situations—known as the covariate shift, cross-validation estimate of the general-ization error is biased, which results in poor model selection. In this paper, we propose an alternative estimator of the generalization error which is under the covariate shift exactly unbiased if model includes the learning target function and is asymptotically unbiased in general. We also show that, in addition to the unbiasedness, the proposed generalization error estimator can accurately estimate the difference of the generalization error among different models, which is a desirable property in model selection. Numerical studies show that the proposed method compares favorably with cross-validation.},
	booktitle = {In {Workshop} on {Information}-{Based} {Induction} {Sciences}},
	author = {Sugiyama, Masashi},
	year = {2005},
	pages = {21--26},
	}

@article{sugiyama_input-dependent_nodate,
	title = {Input-{Dependent} {Estimation} of {Generalization} {Error} under {Covariate} {Shift}},
	abstract = {A common assumption in supervised learning is that the training and test input points follow the same probability distribution. However, this assumption is not fulﬁlled, e.g., in interpolation, extrapolation, active learning, or classiﬁcation with imbalanced data. The violation of this assumption—known as the covariate shift—causes a heavy bias in standard generalization error estimation schemes such as cross-validation or Akaike’s information criterion, and thus they result in poor model selection. In this paper, we propose an alternative estimator of the generalization error for the squared loss function when training and test distributions are diﬀerent. The proposed generalization error estimator is shown to be exactly unbiased for ﬁnite samples if the learning target function is realizable and asymptotically unbiased in general. We also show that, in addition to the unbiasedness, the proposed generalization error estimator can accurately estimate the diﬀerence of the generalization error among diﬀerent models, which is a desirable property in model selection. Numerical studies show that the proposed method compares favorably with existing model selection methods in regression for extrapolation and in classiﬁcation with imbalanced data.},
	language = {en},
	author = {Sugiyama, Masashi and Muller, Klaus-Robert},
	pages = {33},
	}

@inproceedings{ben-david_exploiting_2003,
	title = {Exploiting {Task} {Relatedness} for {Multiple} {Task} {Learning}},
	abstract = {The approach of learning of multiple "related" tasks simultaneously  has proven quite successful in practice; however, theoretical  justi  cation for this success has remained elusive. The starting point for  previous work on multiple task learning has been that the tasks to be  learned jointly are somehow "algorithmically related", in the sense that  the results of applying a speci  c learning algorithm to these tasks are  assumed to be similar. We oer an alternative approach, de  ning relatedness  of tasks on the basis of similarity between the example generating  distributions that underline these task.},
	author = {Ben-david, Shai and Schuller, Reba},
	year = {2003},
	}

@inproceedings{blitzer_domain_2006,
	address = {Sydney, Australia},
	title = {Domain adaptation with structural correspondence learning},
	isbn = {978-1-932432-73-2},
	abstract = {Discriminative learning methods are widely used in natural language processing. These methods work best when their training and test data are drawn from the same distribution. For many NLP tasks, however, we are confronted with new domains in which labeled data is scarce or non-existent. In such cases, we seek to adapt existing models from a resourcerich source domain to a resource-poor target domain. We introduce structural correspondence learning to automatically induce correspondences among features from different domains. We test our technique on part of speech tagging and show performance gains for varying amounts of source and target training data, as well as improvements in target domain parsing accuracy using our improved tagger.},
	language = {en},
	urldate = {2020-12-11},
	booktitle = {Proceedings of the 2006 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} - {EMNLP} '06},
	publisher = {Association for Computational Linguistics},
	author = {Blitzer, John and McDonald, Ryan and Pereira, Fernando},
	year = {2006},
	pages = {120},
	}

@article{crammer_learning_nodate,
	title = {Learning from {Data} of {Variable} {Quality}},
	abstract = {We initiate the study of learning from multiple sources of limited data, each of which may be corrupted at a different rate. We develop a complete theory of which data sources should be used for two fundamental problems: estimating the bias of a coin, and learning a classiﬁer in the presence of label noise. In both cases, efﬁcient algorithms are provided for computing the optimal subset of data.},
	language = {en},
	author = {Crammer, Koby and Kearns, Michael and Wortman, Jennifer},
	pages = {8},
	}

@article{teh_sharing_nodate,
	title = {Sharing {Clusters} {Among} {Related} {Groups}: {Hierarchical} {Dirichlet} {Processes}},
	abstract = {We propose the hierarchical Dirichlet process (HDP), a nonparametric Bayesian model for clustering problems involving multiple groups of data. Each group of data is modeled with a mixture, with the number of components being open-ended and inferred automatically by the model. Further, components can be shared across groups, allowing dependencies across groups to be modeled effectively as well as conferring generalization to new groups. Such grouped clustering problems occur often in practice, e.g. in the problem of topic discovery in document corpora. We report experimental results on three text corpora showing the effective and superior performance of the HDP over previous models.},
	language = {en},
	author = {Teh, Yee Whye and Jordan, Michael I and Beal, Matthew J and Blei, David M},
	pages = {8},
	}

@article{csurka_domain_2017,
	title = {Domain {Adaptation} for {Visual} {Applications}: {A} {Comprehensive} {Survey}},
	shorttitle = {Domain {Adaptation} for {Visual} {Applications}},
	abstract = {The aim of this paper is to give an overview of domain adaptation and transfer learning with a specific view on visual applications. After a general motivation, we first position domain adaptation in the larger transfer learning problem. Second, we try to address and analyze briefly the state-of-the-art methods for different types of scenarios, first describing the historical shallow methods, addressing both the homogeneous and the heterogeneous domain adaptation methods. Third, we discuss the effect of the success of deep convolutional architectures which led to new type of domain adaptation methods that integrate the adaptation within the deep architecture. Fourth, we overview the methods that go beyond image categorization, such as object detection or image segmentation, video analyses or learning visual attributes. Finally, we conclude the paper with a section where we relate domain adaptation to other machine learning solutions.},
	urldate = {2020-12-11},
	journal = {arXiv:1702.05374 [cs]},
	author = {Csurka, Gabriela},
	month = mar,
	year = {2017},
	note = {arXiv: 1702.05374},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Book chapter to appear in "Domain Adaptation in Computer Vision Applications", Springer Series: Advances in Computer Vision and Pattern Recognition, Edited by Gabriela Csurka},
	}

@article{wang_deep_2018,
	title = {Deep {Visual} {Domain} {Adaptation}: {A} {Survey}},
	shorttitle = {Deep {Visual} {Domain} {Adaptation}},
	abstract = {Deep domain adaption has emerged as a new learning technique to address the lack of massive amounts of labeled data. Compared to conventional methods, which learn shared feature subspaces or reuse important source instances with shallow representations, deep domain adaption methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning. There have been comprehensive surveys for shallow domain adaption, but few timely reviews the emerging deep learning based methods. In this paper, we provide a comprehensive survey of deep domain adaptation methods for computer vision applications with four major contributions. First, we present a taxonomy of different deep domain adaption scenarios according to the properties of data that define how two domains are diverged. Second, we summarize deep domain adaption approaches into several categories based on training loss, and analyze and compare briefly the state-of-the-art methods under these categories. Third, we overview the computer vision applications that go beyond image classification, such as face recognition, semantic segmentation and object detection. Fourth, some potential deficiencies of current methods and several future directions are highlighted.},
	urldate = {2020-12-11},
	journal = {arXiv:1802.03601 [cs]},
	author = {Wang, Mei and Deng, Weihong},
	month = may,
	year = {2018},
	note = {arXiv: 1802.03601},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Manuscript accepted by Neurocomputing 2018},
	}

@article{kouw_review_2019,
	title = {A review of domain adaptation without target labels},
	abstract = {Domain adaptation has become a prominent problem setting in machine learning and related fields. This review asks the question: how can a classifier learn from a source domain and generalize to a target domain? We present a categorization of approaches, divided into, what we refer to as, sample-based, feature-based and inference-based methods. Sample-based methods focus on weighting individual observations during training based on their importance to the target domain. Feature-based methods revolve around on mapping, projecting and representing features such that a source classifier performs well on the target domain and inference-based methods incorporate adaptation into the parameter estimation procedure, for instance through constraints on the optimization procedure. Additionally, we review a number of conditions that allow for formulating bounds on the cross-domain generalization error. Our categorization highlights recurring ideas and raises questions important to further research.},
	urldate = {2020-12-16},
	journal = {arXiv:1901.05335 [cs, stat]},
	author = {Kouw, Wouter M. and Loog, Marco},
	month = jul,
	year = {2019},
	note = {arXiv: 1901.05335},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 20 pages, 5 figures},
	}

@article{dubois_learning_2020,
	title = {Learning {Optimal} {Representations} with the {Decodable} {Information} {Bottleneck}},
	abstract = {We address the question of characterizing and finding optimal representations for supervised learning. Traditionally, this question has been tackled using the Information Bottleneck, which compresses the inputs while retaining information about the targets, in a decoder-agnostic fashion. In machine learning, however, our goal is not compression but rather generalization, which is intimately linked to the predictive family or decoder of interest (e.g. linear classifier). We propose the Decodable Information Bottleneck (DIB) that considers information retention and compression from the perspective of the desired predictive family. As a result, DIB gives rise to representations that are optimal in terms of expected test performance and can be estimated with guarantees. Empirically, we show that the framework can be used to enforce a small generalization gap on downstream classifiers and to predict the generalization ability of neural networks.},
	urldate = {2020-12-17},
	journal = {arXiv:2009.12789 [cs, math, stat]},
	author = {Dubois, Yann and Kiela, Douwe and Schwab, David J. and Vedantam, Ramakrishna},
	month = sep,
	year = {2020},
	note = {arXiv: 2009.12789},
	keywords = {Computer Science - Information Theory, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Accepted at NeurIPS 2020},
	}

@article{ueberla_domain_1997,
	title = {Domain {Adaptation} with {Clustered} {Language} {Models}},
	abstract = {In this paper, a method of domain adaptation for clustered language models is developed. It is based on a previously developed clustering algorithm, but with a modified optimisation criterion. The results are shown to be slightly superior to the previously published 'Fillup' method, which can be used to adapt standard n-gram models. However, the improvement both methods give compared to models built from scratch on the adaptation data is quite small (less than 11\% relative improvement in word error rate). This suggests that both methods are still unsatisfactory from a practical point of view.},
	urldate = {2020-12-17},
	journal = {arXiv:cmp-lg/9703001},
	author = {Ueberla, Joerg P.},
	month = mar,
	year = {1997},
	note = {arXiv: cmp-lg/9703001},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: preprint - to appear in ICASSP 97},
	}

@article{zhao_fundamental_2020,
	title = {Fundamental {Limits} and {Tradeoffs} in {Invariant} {Representation} {Learning}},
	abstract = {Many machine learning applications involve learning representations that achieve two competing goals: To maximize information or accuracy with respect to a subset of features (e.g.{\textbackslash} for prediction) while simultaneously maximizing invariance or independence with respect to another, potentially overlapping, subset of features (e.g.{\textbackslash} for fairness, privacy, etc). Typical examples include privacy-preserving learning, domain adaptation, and algorithmic fairness, just to name a few. In fact, all of the above problems admit a common minimax game-theoretic formulation, whose equilibrium represents a fundamental tradeoff between accuracy and invariance. Despite its abundant applications in the aforementioned domains, theoretical understanding on the limits and tradeoffs of invariant representations is severely lacking. In this paper, we provide an information-theoretic analysis of this general and important problem under both classification and regression settings. In both cases, we analyze the inherent tradeoffs between accuracy and invariance by providing a geometric characterization of the feasible region in the information plane, where we connect the geometric properties of this feasible region to the fundamental limitations of the tradeoff problem. In the regression setting, we also derive a tight lower bound on the Lagrangian objective that quantifies the tradeoff between accuracy and invariance. This lower bound leads to a better understanding of the tradeoff via the spectral properties of the joint distribution. In both cases, our results shed new light on this fundamental problem by providing insights on the interplay between accuracy and invariance. These results deepen our understanding of this fundamental problem and may be useful in guiding the design of adversarial representation learning algorithms.},
	urldate = {2020-12-28},
	journal = {arXiv:2012.10713 [cs, stat]},
	author = {Zhao, Han and Dan, Chen and Aragam, Bryon and Jaakkola, Tommi S. and Gordon, Geoffrey J. and Ravikumar, Pradeep},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.10713},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	}

@article{hellstrom_nonvacuous_2020,
	title = {Nonvacuous {Loss} {Bounds} with {Fast} {Rates} for {Neural} {Networks} via {Conditional} {Information} {Measures}},
	abstract = {We present a framework to derive bounds on the test loss of randomized learning algorithms for the case of bounded loss functions. This framework leads to bounds that depend on the conditional information density between the the output hypothesis and the choice of the training set, given a larger set of data samples from which the training set is formed. Furthermore, the bounds pertain to the average test loss as well as to its tail probability, both for the PAC-Bayesian and the single-draw settings. If the conditional information density is bounded uniformly in the size \$n\$ of the training set, our bounds decay as \$1/n\$, which is referred to as a fast rate. This is in contrast with the tail bounds involving conditional information measures available in the literature, which have a less benign \$1/{\textbackslash}sqrt\{n\}\$ dependence. We demonstrate the usefulness of our tail bounds by showing that they lead to estimates of the test loss achievable with several neural network architectures trained on MNIST and Fashion-MNIST that match the state-of-the-art bounds available in the literature.},
	urldate = {2020-12-21},
	journal = {arXiv:2010.11552 [cs, math, stat]},
	author = {Hellström, Fredrik and Durisi, Giuseppe},
	month = dec,
	year = {2020},
	note = {arXiv: 2010.11552
version: 2},
	keywords = {Computer Science - Information Theory, Computer Science - Machine Learning, Statistics - Machine Learning},
	}

@article{sriperumbudur_integral_2009,
	title = {On integral probability metrics, {\textbackslash}phi-divergences and binary classification},
	abstract = {A class of distance measures on probabilities -- the integral probability metrics (IPMs) -- is addressed: these include the Wasserstein distance, Dudley metric, and Maximum Mean Discrepancy. IPMs have thus far mostly been used in more abstract settings, for instance as theoretical tools in mass transportation problems, and in metrizing the weak topology on the set of all Borel probability measures defined on a metric space. Practical applications of IPMs are less common, with some exceptions in the kernel machines literature. The present work contributes a number of novel properties of IPMs, which should contribute to making IPMs more widely used in practice, for instance in areas where \${\textbackslash}phi\$-divergences are currently popular. First, to understand the relation between IPMs and \${\textbackslash}phi\$-divergences, the necessary and sufficient conditions under which these classes intersect are derived: the total variation distance is shown to be the only non-trivial \${\textbackslash}phi\$-divergence that is also an IPM. This shows that IPMs are essentially different from \${\textbackslash}phi\$-divergences. Second, empirical estimates of several IPMs from finite i.i.d. samples are obtained, and their consistency and convergence rates are analyzed. These estimators are shown to be easily computable, with better rates of convergence than estimators of \${\textbackslash}phi\$-divergences. Third, a novel interpretation is provided for IPMs by relating them to binary classification, where it is shown that the IPM between class-conditional distributions is the negative of the optimal risk associated with a binary classifier. In addition, the smoothness of an appropriate binary classifier is proved to be inversely related to the distance between the class-conditional distributions, measured in terms of an IPM.},
	urldate = {2020-12-21},
	journal = {arXiv:0901.2698 [cs, math]},
	author = {Sriperumbudur, Bharath K. and Fukumizu, Kenji and Gretton, Arthur and Schölkopf, Bernhard and Lanckriet, Gert R. G.},
	month = oct,
	year = {2009},
	note = {arXiv: 0901.2698},
	keywords = {Computer Science - Information Theory},
	annote = {Comment: 18 pages},
	}
@inproceedings{germain_pac-bayesian_2013,
         title = {A {PAC}-{Bayesian} {Approach} for {Domain} {Adaptation} with {Specialization} to {Linear} {Classifiers}},
         abstract = {We provide a first PAC-Bayesian analysis for domain adaptation (DA) which arises     when the learning and test distributions differ. It relies on a novel distribution pseudodistance b    ased on a disagre...},
         language = {en},
        urldate = {2021-02-25},
         booktitle = {International {Conference} on {Machine} {Learning}},
       publisher = {PMLR},
         author = {Germain, Pascal and Habrard, Amaury and Laviolette, François and Morvant, Emilie},
       month = may,
        year = {2013},
         note = {ISSN: 1938-7228},
         pages = {738--746},
          }
@InProceedings{germain16, title = {A New PAC-Bayesian Perspective on Domain Adaptation}, author = {Pascal Germain and Amaury Habrard and François Laviolette and Emilie Morvant}, booktitle = {Proceedings of The 33rd International Conference on Machine Learning}, pages = {859--868}, year = {2016}, editor = {Maria Florina Balcan and Kilian Q. Weinberger}, volume = {48}, series = {Proceedings of Machine Learning Research}, address = {New York, New York, USA}, month = {20--22 Jun}, publisher = {PMLR},  abstract = {We study the issue of PAC-Bayesian domain adaptation: We want to learn, from a source domain, a majority vote model dedicated to a target one. Our theoretical contribution brings a new perspective by deriving an upper-bound on the target risk where the distributions’ divergence - expressed as a ratio - controls the trade-off between a source error measure and the target voters’ disagreement. Our bound suggests that one has to focus on regions where the source data is informative. From this result, we derive a PAC-Bayesian generalization bound, and specialize it to linear classifiers. Then, we infer a learning algorithm and perform experiments on real data.} 
}
@article{germain_pac-bayes_2020,
	title = {{PAC}-{Bayes} and {Domain} {Adaptation}},
	volume = {379},
	issn = {09252312},
	abstract = {We provide two main contributions in PAC-Bayesian theory for domain adaptation where the objective is to learn, from a source distribution, a well-performing majority vote on a different, but related, target distribution. Firstly, we propose an improvement of the previous approach we proposed in Germain et al. (2013), which relies on a novel distribution pseudodistance based on a disagreement averaging, allowing us to derive a new tighter domain adaptation bound for the target risk. While this bound stands in the spirit of common domain adaptation works, we derive a second bound (introduced in Germain et al., 2016) that brings a new perspective on domain adaptation by deriving an upper bound on the target risk where the distributions' divergence-expressed as a ratio-controls the trade-off between a source error measure and the target voters' disagreement. We discuss and compare both results, from which we obtain PAC-Bayesian generalization bounds. Furthermore, from the PAC-Bayesian specialization to linear classifiers, we infer two learning algorithms, and we evaluate them on real data.},
	urldate = {2021-01-06},
	journal = {Neurocomputing},
	author = {Germain, Pascal and Habrard, Amaury and Laviolette, François and Morvant, Emilie},
	month = feb,
	year = {2020},
	note = {arXiv: 1707.05712},
	keywords = {Statistics - Machine Learning},
	pages = {379--397},
	annote = {A paper which provides some theory on DA in the PAC bayes setting. The main contribution is a bound which instead of the earlier additive divergence terms of the two distributions we get a multiplicative weight on the importance of the source information.},
	annote = {Comment: Neurocomputing, Elsevier, 2019. arXiv admin note: substantial text overlap with arXiv:1503.06944},
	}
@article{awasthi_pac-bayes_2020, 
         title = {{PAC}-{Bayes} {Learning} {Bounds} for {Sample}-{Dependent} {Priors}}, 
          volume = {33}, 
           language = {en},
          urldate = {2021-02-23},
        journal = {Advances in Neural Information Processing Systems},
          author = {Awasthi, Pranjal and Kale, Satyen and Karp, Stefani and Mohri, Mehryar},
         year = {2020},
          pages = {4403--4414}
 }
 @book{wainwright_book, place={Cambridge}, series={Cambridge Series in Statistical and Probabilistic Mathematics}, title={High-Dimensional Statistics: A Non-Asymptotic Viewpoint}, DOI={10.1017/9781108627771}, publisher={Cambridge University Press}, author={Wainwright, Martin J.}, year={2019}, collection={Cambridge Series in Statistical and Probabilistic Mathematics}}
 @book{vladimirvapnik1998,
 Author = {Vladimir N. Vapnik},
 title = {Statistical Learning Theory},
 description = {Statistical Learning Theory (Book, 1998)},
 publisher = {Wiley-Interscience},
 interhash = {3f25359c44f7b32e37ce6124aec280f9},
 intrahash = {d6d7ec3a0076183de8ec80a00c2d6596},
 year = {1998},
 month = {9},
 isbn = {0471030031},
 }
@inproceedings{
neyshabur2018a,
title={A {PAC}-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks},
author={Behnam Neyshabur and Srinadh Bhojanapalli and Nathan Srebro},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=Skz_WfbCZ},
}
  @inproceedings{ambroladze2007,
  author = {Ambroladze, Amiran and Parrado-hern\'{a}ndez, Emilio and Shawe-taylor, John},
  booktitle = {Advances in Neural Information Processing Systems},
   editor = {B. Sch\"{o}lkopf and J. Platt and T. Hoffman},
   pages = {},
   publisher = {MIT Press},
   title = {Tighter PAC-Bayes Bounds},
   volume = {19},
   year = {2007}
 }
  

@article{guedj_still_2019,
	title = {Still no free lunches: the price to pay for tighter {PAC}-{Bayes} bounds},
	shorttitle = {Still no free lunches},
	abstract = {"No free lunch" results state the impossibility of obtaining meaningful bounds on the error of a learning algorithm without prior assumptions and modelling. Some models are expensive (strong assumptions, such as as subgaussian tails), others are cheap (simply finite variance). As it is well known, the more you pay, the more you get: in other words, the most expensive models yield the more interesting bounds. Recent advances in robust statistics have investigated procedures to obtain tight bounds while keeping the cost minimal. The present paper explores and exhibits what the limits are for obtaining tight PAC-Bayes bounds in a robust setting for cheap models, addressing the question: is PAC-Bayes good value for money?},
	urldate = {2021-01-06},
	journal = {arXiv:1910.04460 [cs, math, stat]},
	author = {Guedj, Benjamin and Pujol, Louis},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.04460},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Statistics Theory},
	annote = {Good short paper going through why we probably will need more assumptions for good bounds in PAC-Bayes settings. This is due to fundamental problems when deriving the bounds themselves and seem hard to overcome.},
	}

@inproceedings{baum_supervised_1988,
	title = {Supervised {Learning} of {Probability} {Distributions} by {Neural} {Networks}},
	urldate = {2021-01-06},
	booktitle = {Neural {Information} {Processing} {Systems}},
	publisher = {American Institute of Physics},
	author = {Baum, Eric and Wilczek, Frank},
	editor = {Anderson, D.},
	year = {1988},
	pages = {52--61},
	}

@article{ganin_domain-adversarial_2016,
	title = {Domain-{Adversarial} {Training} of {Neural} {Networks}},
	abstract = {We introduce a new representation learning approach for domain adaptation, in which data at training and test time come from similar but different distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for effective domain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains. The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of features that are (i) discriminative for the main learning task on the source domain and (ii) indiscriminate with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation and stochastic gradient descent, and can thus be implemented with little effort using any of the deep learning packages. We demonstrate the success of our approach for two distinct classification problems (document sentiment analysis and image classification), where state-of-the-art domain adaptation performance on standard benchmarks is achieved. We also validate the approach for descriptor learning task in the context of person re-identification application.},
	urldate = {2021-01-06},
	journal = {arXiv:1505.07818 [cs, stat]},
	author = {Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, François and Marchand, Mario and Lempitsky, Victor},
	month = may,
	year = {2016},
	note = {arXiv: 1505.07818},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: Published in JMLR: http://jmlr.org/papers/v17/15-239.html},
	}

@article{srivastava_dropout_nodate,
	title = {Dropout: {A} {Simple} {Way} to {Prevent} {Neural} {Networks} from {Overﬁtting}},
	abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overﬁtting is a serious problem in such networks. Large networks are also slow to use, making it diﬃcult to deal with overﬁtting by combining the predictions of many diﬀerent large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of diﬀerent “thinned” networks. At test time, it is easy to approximate the eﬀect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This signiﬁcantly reduces overﬁtting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classiﬁcation and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
	language = {en},
	author = {Srivastava, Nitish and Hinton, Geoﬀrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	pages = {30},
	}

@article{long_deep_nodate,
	title = {Deep {Transfer} {Learning} with {Joint} {Adaptation} {Networks}},
	abstract = {Deep networks have been successfully applied to learn transferable features for adapting models from a source domain to a different target domain. In this paper, we present joint adaptation networks (JAN), which learn a transfer network by aligning the joint distributions of multiple domain-speciﬁc layers across domains based on a joint maximum mean discrepancy (JMMD) criterion. Adversarial training strategy is adopted to maximize JMMD such that the distributions of the source and target domains are made more distinguishable. Learning can be performed by stochastic gradient descent with the gradients computed by back-propagation in linear-time. Experiments testify that our model yields state of the art results on standard datasets.},
	language = {en},
	author = {Long, Mingsheng and Zhu, Han and Wang, Jianmin and Jordan, Michael I},
	pages = {10},
	}

@misc{noauthor_dashboard_nodate,
	title = {Dashboard},
	urldate = {2021-01-19},
	}

@article{bousquet_theory_nodate,
	title = {A {Theory} of {Universal} {Learning}},
	abstract = {How quickly can a given class of concepts be learned from examples? It is common to measure the performance of a supervised machine learning algorithm by plotting its “learning curve”, that is, the decay of the error rate as a function of the number of training examples. However, the classical theoretical framework for understanding learnability, the PAC model of Vapnik-Chervonenkis and Valiant, does not explain the behavior of learning curves: the distribution-free PAC model of learning can only bound the upper envelope of the learning curves over all possible data distributions. This does not match the practice of machine learning, where the data source is typically ﬁxed in any given scenario, while the learner may choose the number of training examples on the basis of factors such as computational resources and desired accuracy.},
	language = {en},
	author = {Bousquet, Olivier and Hanneke, Steve and Moran, Shay},
	pages = {51},
	}

@article{guedj_primer_2019,
	title = {A {Primer} on {PAC}-{Bayesian} {Learning}},
	abstract = {Generalised Bayesian learning algorithms are increasingly popular in machine learning, due to their PAC generalisation properties and flexibility. The present paper aims at providing a self-contained survey on the resulting PAC-Bayes framework and some of its main theoretical and algorithmic developments.},
	urldate = {2021-01-19},
	journal = {arXiv:1901.05353 [cs, stat]},
	author = {Guedj, Benjamin},
	month = may,
	year = {2019},
	note = {arXiv: 1901.05353},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	}

@article{zhang_mixup_2018,
	title = {mixup: {Beyond} {Empirical} {Risk} {Minimization}},
	shorttitle = {mixup},
	abstract = {Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.},
	urldate = {2021-01-20},
	journal = {arXiv:1710.09412 [cs, stat]},
	author = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and Lopez-Paz, David},
	month = apr,
	year = {2018},
	note = {arXiv: 1710.09412
version: 2},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: ICLR camera ready version. Changes vs V1: fix repo URL; add ablation studies; add mixup + dropout etc},
	}

@article{wang_transfer_2020,
	title = {Transfer {Learning} with {Dynamic} {Distribution} {Adaptation}},
	volume = {11},
	issn = {2157-6904, 2157-6912},
	abstract = {Transfer learning aims to learn robust classifiers for the target domain by leveraging knowledge from a source domain. Since the source and the target domains are usually from different distributions, existing methods mainly focus on adapting the cross-domain marginal or conditional distributions. However, in real applications, the marginal and conditional distributions usually have different contributions to the domain discrepancy. Existing methods fail to quantitatively evaluate the different importance of these two distributions, which will result in unsatisfactory transfer performance. In this paper, we propose a novel concept called Dynamic Distribution Adaptation (DDA), which is capable of quantitatively evaluating the relative importance of each distribution. DDA can be easily incorporated into the framework of structural risk minimization to solve transfer learning problems. On the basis of DDA, we propose two novel learning algorithms: (1) Manifold Dynamic Distribution Adaptation (MDDA) for traditional transfer learning, and (2) Dynamic Distribution Adaptation Network (DDAN) for deep transfer learning. Extensive experiments demonstrate that MDDA and DDAN significantly improve the transfer learning performance and setup a strong baseline over the latest deep and adversarial methods on digits recognition, sentiment analysis, and image classification. More importantly, it is shown that marginal and conditional distributions have different contributions to the domain divergence, and our DDA is able to provide good quantitative evaluation of their relative importance which leads to better performance. We believe this observation can be helpful for future research in transfer learning.},
	number = {1},
	urldate = {2021-01-20},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	author = {Wang, Jindong and Chen, Yiqiang and Feng, Wenjie and Yu, Han and Huang, Meiyu and Yang, Qiang},
	month = feb,
	year = {2020},
	note = {arXiv: 1909.08531
version: 1},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {1--25},
	annote = {Comment: Accepted to ACM Transactions on Intelligent Systems and Technology (ACM TIST) 2019, 25 pages. arXiv admin note: text overlap with arXiv:1807.07258},
	}

@article{sun_deep_2016,
	title = {Deep {CORAL}: {Correlation} {Alignment} for {Deep} {Domain} {Adaptation}},
	shorttitle = {Deep {CORAL}},
	abstract = {Deep neural networks are able to learn powerful representations from large quantities of labeled input data, however they cannot always generalize well across changes in input distributions. Domain adaptation algorithms have been proposed to compensate for the degradation in performance due to domain shift. In this paper, we address the case when the target domain is unlabeled, requiring unsupervised adaptation. CORAL is a "frustratingly easy" unsupervised domain adaptation method that aligns the second-order statistics of the source and target distributions with a linear transformation. Here, we extend CORAL to learn a nonlinear transformation that aligns correlations of layer activations in deep neural networks (Deep CORAL). Experiments on standard benchmark datasets show state-of-the-art performance.},
	urldate = {2021-01-20},
	journal = {arXiv:1607.01719 [cs]},
	author = {Sun, Baochen and Saenko, Kate},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.01719},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: Extended Abstract},
	}
@article{viallard_general_2021,
	title = {A {General} {Framework} for the {Disintegration} of {PAC}-{Bayesian} {Bounds}},
	abstract = {PAC-Bayesian bounds are known to be tight and informative when studying the generalization ability of randomized classifiers. However, when applied to some family of deterministic models such as neural networks, they require a loose and costly derandomization step. As an alternative to this step, we introduce new PAC-Bayesian generalization bounds that have the originality to provide disintegrated bounds, i.e., they give guarantees over one single hypothesis instead of the usual averaged analysis. Our bounds are easily optimizable and can be used to design learning algorithms. We illustrate the interest of our result on neural networks and show a significant practical improvement over the state-of-the-art framework.},
	urldate = {2022-01-18},
	journal = {arXiv:2102.08649 [cs, stat]},
	author = {Viallard, Paul and Germain, Pascal and Habrard, Amaury and Morvant, Emilie},
	month = oct,
	year = {2021},
	note = {arXiv: 2102.08649},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{yu_learning_2020,
	title = {Learning to {Match} {Distributions} for {Domain} {Adaptation}},
	abstract = {When the training and test data are from different distributions, domain adaptation is needed to reduce dataset bias to improve the model's generalization ability. Since it is difficult to directly match the cross-domain joint distributions, existing methods tend to reduce the marginal or conditional distribution divergence using predefined distances such as MMD and adversarial-based discrepancies. However, it remains challenging to determine which method is suitable for a given application since they are built with certain priors or bias. Thus they may fail to uncover the underlying relationship between transferable features and joint distributions. This paper proposes Learning to Match (L2M) to automatically learn the cross-domain distribution matching without relying on hand-crafted priors on the matching loss. Instead, L2M reduces the inductive bias by using a meta-network to learn the distribution matching loss in a data-driven way. L2M is a general framework that unifies task-independent and human-designed matching features. We design a novel optimization algorithm for this challenging objective with self-supervised label propagation. Experiments on public datasets substantiate the superiority of L2M over SOTA methods. Moreover, we apply L2M to transfer from pneumonia to COVID-19 chest X-ray images with remarkable performance. L2M can also be extended in other distribution matching applications where we show in a trial experiment that L2M generates more realistic and sharper MNIST samples.},
	urldate = {2021-01-20},
	journal = {arXiv:2007.10791 [cs, stat]},
	author = {Yu, Chaohui and Wang, Jindong and Liu, Chang and Qin, Tao and Xu, Renjun and Feng, Wenjie and Chen, Yiqiang and Liu, Tie-Yan},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.10791
version: 3},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Preprint. 20 Pages. Code available at https://github.com/jindongwang/transferlearning/tree/master/code/deep/Learning-to-Match},
	}

@article{cheng_posterior_2020,
	title = {Posterior {Differential} {Regularization} with f-divergence for {Improving} {Model} {Robustness}},
	abstract = {We address the problem of enhancing model robustness through regularization. Specifically, we focus on methods that regularize the model posterior difference between clean and noisy inputs. Theoretically, we provide a connection of two recent methods, Jacobian Regularization and Virtual Adversarial Training, under this framework. Additionally, we generalize the posterior differential regularization to the family of \$f\$-divergences and characterize the overall regularization framework in terms of Jacobian matrix. Empirically, we systematically compare those regularizations and standard BERT training on a diverse set of tasks to provide a comprehensive profile of their effect on model in-domain and out-of-domain generalization. For both fully supervised and semi-supervised settings, our experiments show that regularizing the posterior differential with \$f\$-divergence can result in well-improved model robustness. In particular, with a proper \$f\$-divergence, a BERT-base model can achieve comparable generalization as its BERT-large counterpart for in-domain, adversarial and domain shift scenarios, indicating the great potential of the proposed framework for boosting model generalization for NLP models.},
	urldate = {2021-01-20},
	journal = {arXiv:2010.12638 [cs, stat]},
	author = {Cheng, Hao and Liu, Xiaodong and Pereira, Lis and Yu, Yaoliang and Gao, Jianfeng},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.12638
version: 1},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
	}

@article{hendrycks_augmix_2020,
	title = {{AugMix}: {A} {Simple} {Data} {Processing} {Method} to {Improve} {Robustness} and {Uncertainty}},
	shorttitle = {{AugMix}},
	abstract = {Modern deep neural networks can achieve high accuracy when the training distribution and test distribution are identically distributed, but this assumption is frequently violated in practice. When the train and test distributions are mismatched, accuracy can plummet. Currently there are few techniques that improve robustness to unforeseen data shifts encountered during deployment. In this work, we propose a technique to improve the robustness and uncertainty estimates of image classifiers. We propose AugMix, a data processing technique that is simple to implement, adds limited computational overhead, and helps models withstand unforeseen corruptions. AugMix significantly improves robustness and uncertainty measures on challenging image classification benchmarks, closing the gap between previous methods and the best possible performance in some cases by more than half.},
	urldate = {2021-01-20},
	journal = {arXiv:1912.02781 [cs, stat]},
	author = {Hendrycks, Dan and Mu, Norman and Cubuk, Ekin D. and Zoph, Barret and Gilmer, Justin and Lakshminarayanan, Balaji},
	month = feb,
	year = {2020},
	note = {arXiv: 1912.02781
version: 2},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Code available at https://github.com/google-research/augmix},
	}

@article{long_learning_2015,
	title = {Learning {Transferable} {Features} with {Deep} {Adaptation} {Networks}},
	abstract = {Recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation. However, as deep features eventually transition from general to specific along the network, the feature transferability drops significantly in higher layers with increasing domain discrepancy. Hence, it is important to formally reduce the dataset bias and enhance the transferability in task-specific layers. In this paper, we propose a new Deep Adaptation Network (DAN) architecture, which generalizes deep convolutional neural network to the domain adaptation scenario. In DAN, hidden representations of all task-specific layers are embedded in a reproducing kernel Hilbert space where the mean embeddings of different domain distributions can be explicitly matched. The domain discrepancy is further reduced using an optimal multi-kernel selection method for mean embedding matching. DAN can learn transferable features with statistical guarantees, and can scale linearly by unbiased estimate of kernel embedding. Extensive empirical evidence shows that the proposed architecture yields state-of-the-art image classification error rates on standard domain adaptation benchmarks.},
	urldate = {2021-01-20},
	journal = {arXiv:1502.02791 [cs]},
	author = {Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael I.},
	month = may,
	year = {2015},
	note = {arXiv: 1502.02791},
	keywords = {Computer Science - Machine Learning},
	}

@article{pan_domain_2011,
	title = {Domain {Adaptation} via {Transfer} {Component} {Analysis}},
	volume = {22},
	issn = {1045-9227, 1941-0093},
	abstract = {Domain adaptation solves a learning problem in a target domain by utilizing the training data in a different but related source domain. Intuitively, discovering a good feature representation across domains is crucial. In this paper, we propose to ﬁnd such a representation through a new learning method, transfer component analysis (TCA), for domain adaptation. TCA tries to learn some transfer components across domains in a Reproducing Kernel Hilbert Space (RKHS) using Maximum Mean Discrepancy (MMD). In the subspace spanned by these transfer components, data distributions in different domains are close to each other. As a result, with the new representations in this subspace, we can apply standard machine learning methods to train classiﬁers or regression models in the source domain for use in the target domain. The main contribution of our work is that we propose a novel feature representation in which to perform domain adaptation via a new parametric kernel using feature extraction methods, which can dramatically minimize the distance between domain distributions by projecting data onto the learned transfer components. Furthermore, our approach can handle large datsets and naturally lead to out-of-sample generalization. The effectiveness and efﬁciency of our approach in are veriﬁed by experiments on two real-world applications: cross-domain indoor WiFi localization and cross-domain text classiﬁcation.},
	language = {en},
	number = {2},
	urldate = {2021-01-20},
	journal = {IEEE Transactions on Neural Networks},
	author = {Pan, Sinno Jialin and Tsang, Ivor W. and Kwok, James T. and Yang, Qiang},
	month = feb,
	year = {2011},
	pages = {199--210},
	}

@inproceedings{zhao_learning_2019,
	title = {On {Learning} {Invariant} {Representation} for {Domain} {Adaptation}},
	abstract = {Due to the ability of deep neural nets to learn rich representations, recent advances in unsupervised domain adaptation have focused on learning domain-invariant features that achieve a small error on the source domain. The hope is that the learnt representation, together with the hypothesis learnt from the source domain, can generalize to the target domain. In this paper, we first construct a simple counterexample showing that, contrary to common belief, the above conditions are not sufficient to guarantee successful domain adaptation. In particular, the counterexample exhibits {\textbackslash}emph\{conditional shift\}: the class-conditional distributions of input features change between source and target domains. To give a sufficient condition for domain adaptation, we propose a natural and interpretable generalization upper bound that explicitly takes into account the aforementioned shift. Moreover, we shed new light on the problem by proving an information-theoretic lower bound on the joint error of {\textbackslash}emph\{any\} domain adaptation method that attempts to learn invariant representations. Our result characterizes a fundamental tradeoff between learning invariant representations and achieving small joint error on both domains when the marginal label distributions differ from source to target. Finally, we conduct experiments on real-world datasets that corroborate our theoretical findings. We believe these insights are helpful in guiding the future design of domain adaptation and representation learning algorithms.},
	urldate = {2021-01-20},
	booktitle = {Proceedings of the 36th International Conference on Machine Learning},
	author = {Zhao, Han and Combes, Remi Tachet des and Zhang, Kun and Gordon, Geoffrey J.},
	month = jan,
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: Compared with the last version, the current one adds a new corollary for the case of different feature transformations (encoders) on source/target domains. Fix a typo in Fig. 1},
	}

@article{zhang_bridging_2019,
	title = {Bridging {Theory} and {Algorithm} for {Domain} {Adaptation}},
	abstract = {This paper addresses the problem of unsupervised domain adaption from theoretical and algorithmic perspectives. Existing domain adaptation theories naturally imply minimax optimization algorithms, which connect well with the domain adaptation methods based on adversarial learning. However, several disconnections still exist and form the gap between theory and algorithm. We extend previous theories (Mansour et al., 2009c; Ben-David et al., 2010) to multiclass classification in domain adaptation, where classifiers based on the scoring functions and margin loss are standard choices in algorithm design. We introduce Margin Disparity Discrepancy, a novel measurement with rigorous generalization bounds, tailored to the distribution comparison with the asymmetric margin loss, and to the minimax optimization for easier training. Our theory can be seamlessly transformed into an adversarial learning algorithm for domain adaptation, successfully bridging the gap between theory and algorithm. A series of empirical studies show that our algorithm achieves the state of the art accuracies on challenging domain adaptation tasks.},
	urldate = {2021-01-20},
	journal = {arXiv:1904.05801 [cs, stat]},
	author = {Zhang, Yuchen and Liu, Tianle and Long, Mingsheng and Jordan, Michael I.},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.05801
version: 1},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Proceedings of the 36th International Conference on Machine Learning, Long Beach, California, PMLR 97, 2019},
	}

@article{wang_visual_2018,
	title = {Visual {Domain} {Adaptation} with {Manifold} {Embedded} {Distribution} {Alignment}},
	abstract = {Visual domain adaptation aims to learn robust classifiers for the target domain by leveraging knowledge from a source domain. Existing methods either attempt to align the cross-domain distributions, or perform manifold subspace learning. However, there are two significant challenges: (1) degenerated feature transformation, which means that distribution alignment is often performed in the original feature space, where feature distortions are hard to overcome. On the other hand, subspace learning is not sufficient to reduce the distribution divergence. (2) unevaluated distribution alignment, which means that existing distribution alignment methods only align the marginal and conditional distributions with equal importance, while they fail to evaluate the different importance of these two distributions in real applications. In this paper, we propose a Manifold Embedded Distribution Alignment (MEDA) approach to address these challenges. MEDA learns a domain-invariant classifier in Grassmann manifold with structural risk minimization, while performing dynamic distribution alignment to quantitatively account for the relative importance of marginal and conditional distributions. To the best of our knowledge, MEDA is the first attempt to perform dynamic distribution alignment for manifold domain adaptation. Extensive experiments demonstrate that MEDA shows significant improvements in classification accuracy compared to state-of-the-art traditional and deep methods.},
	urldate = {2021-01-20},
	journal = {arXiv:1807.07258 [cs]},
	author = {Wang, Jindong and Feng, Wenjie and Chen, Yiqiang and Yu, Han and Huang, Meiyu and Yu, Philip S.},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.07258},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: ACM Multimedia conference 2018 (ACM MM) ORAL paper; top 10 papers; 9 pages; code available at http://transferlearning.xyz},
	}

@article{tzeng_deep_2014,
	title = {Deep {Domain} {Confusion}: {Maximizing} for {Domain} {Invariance}},
	shorttitle = {Deep {Domain} {Confusion}},
	abstract = {Recent reports suggest that a generic supervised deep CNN model trained on a large-scale dataset reduces, but does not remove, dataset bias on a standard benchmark. Fine-tuning deep models in a new domain can require a significant amount of data, which for many applications is simply not available. We propose a new CNN architecture which introduces an adaptation layer and an additional domain confusion loss, to learn a representation that is both semantically meaningful and domain invariant. We additionally show that a domain confusion metric can be used for model selection to determine the dimension of an adaptation layer and the best position for the layer in the CNN architecture. Our proposed adaptation method offers empirical performance which exceeds previously published results on a standard benchmark visual domain adaptation task.},
	urldate = {2021-01-20},
	journal = {arXiv:1412.3474 [cs]},
	author = {Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.3474},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	}

@article{wang_transferable_nodate,
	title = {Transferable {Normalization}: {Towards} {Improving} {Transferability} of {Deep} {Neural} {Networks}},
	abstract = {Deep neural networks (DNNs) excel at learning representations when trained on large-scale datasets. Pre-trained DNNs also show strong transferability when ﬁnetuned to other labeled datasets. However, such transferability becomes weak when the target dataset is fully unlabeled as in Unsupervised Domain Adaptation (UDA). We envision that the loss of transferability mainly stems from the intrinsic limitation of the architecture design of DNNs. In this paper, we delve into the components of DNN architectures and propose Transferable Normalization (TransNorm) in place of existing normalization techniques. TransNorm is an end-to-end trainable layer to make DNNs more transferable across domains. As a general method, TransNorm can be easily applied to various deep neural networks and domain adaption methods, without introducing any extra hyper-parameters or learnable parameters. Empirical results justify that TransNorm not only improves classiﬁcation accuracies but also accelerates convergence for mainstream DNN-based domain adaptation methods.},
	language = {en},
	author = {Wang, Ximei and Jin, Ying and Long, Mingsheng and Wang, Jianmin and Jordan, Michael I},
	pages = {11},
	}

@article{saito_maximum_2018,
	title = {Maximum {Classifier} {Discrepancy} for {Unsupervised} {Domain} {Adaptation}},
	abstract = {In this work, we present a method for unsupervised domain adaptation. Many adversarial learning methods train domain classifier networks to distinguish the features as either a source or target and train a feature generator network to mimic the discriminator. Two problems exist with these methods. First, the domain classifier only tries to distinguish the features as a source or target and thus does not consider task-specific decision boundaries between classes. Therefore, a trained generator can generate ambiguous features near class boundaries. Second, these methods aim to completely match the feature distributions between different domains, which is difficult because of each domain's characteristics. To solve these problems, we introduce a new approach that attempts to align distributions of source and target by utilizing the task-specific decision boundaries. We propose to maximize the discrepancy between two classifiers' outputs to detect target samples that are far from the support of the source. A feature generator learns to generate target features near the support to minimize the discrepancy. Our method outperforms other methods on several datasets of image classification and semantic segmentation. The codes are available at {\textbackslash}url\{https://github.com/mil-tokyo/MCD\_DA\}},
	urldate = {2021-01-20},
	journal = {arXiv:1712.02560 [cs]},
	author = {Saito, Kuniaki and Watanabe, Kohei and Ushiku, Yoshitaka and Harada, Tatsuya},
	month = apr,
	year = {2018},
	note = {arXiv: 1712.02560},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Accepted to CVPR2018 Oral, Code is available at https://github.com/mil-tokyo/MCD\_DA},
	}

@article{damodaran_deepjdot_2018,
	title = {{DeepJDOT}: {Deep} {Joint} {Distribution} {Optimal} {Transport} for {Unsupervised} {Domain} {Adaptation}},
	shorttitle = {{DeepJDOT}},
	abstract = {In computer vision, one is often confronted with problems of domain shifts, which occur when one applies a classifier trained on a source dataset to target data sharing similar characteristics (e.g. same classes), but also different latent data structures (e.g. different acquisition conditions). In such a situation, the model will perform poorly on the new data, since the classifier is specialized to recognize visual cues specific to the source domain. In this work we explore a solution, named DeepJDOT, to tackle this problem: through a measure of discrepancy on joint deep representations/labels based on optimal transport, we not only learn new data representations aligned between the source and target domain, but also simultaneously preserve the discriminative information used by the classifier. We applied DeepJDOT to a series of visual recognition tasks, where it compares favorably against state-of-the-art deep domain adaptation methods.},
	urldate = {2021-01-20},
	journal = {arXiv:1803.10081 [cs]},
	author = {Damodaran, Bharath Bhushan and Kellenberger, Benjamin and Flamary, Rémi and Tuia, Devis and Courty, Nicolas},
	month = sep,
	year = {2018},
	note = {arXiv: 1803.10081},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	annote = {Comment: European Conference on Computer Vision 2018 (ECCV-2018)},
	}

@article{courty_joint_nodate,
	title = {Joint distribution optimal transportation for domain adaptation},
	abstract = {This paper deals with the unsupervised domain adaptation problem, where one wants to estimate a prediction function f in a given target domain without any labeled sample by exploiting the knowledge available from a source domain where labels are known. Our work makes the following assumption: there exists a nonlinear transformation between the joint feature/label space distributions of the two domain Ps and Pt that can be estimated with optimal transport. We propose a solution of this problem that allows to recover an estimated target Ptf = (X, f (X)) by optimizing simultaneously the optimal coupling and f . We show that our method corresponds to the minimization of a bound on the target error, and provide an efﬁcient algorithmic solution, for which convergence is proved. The versatility of our approach, both in terms of class of hypothesis or loss functions is demonstrated with real world classiﬁcation and regression problems, for which we reach or surpass state-of-the-art results.},
	language = {en},
	author = {Courty, Nicolas and Flamary, Rémi and Habrard, Amaury and Rakotomamonjy, Alain},
	pages = {10},
	}

@article{courty_joint_2017,
	title = {Joint {Distribution} {Optimal} {Transportation} for {Domain} {Adaptation}},
	abstract = {This paper deals with the unsupervised domain adaptation problem, where one wants to estimate a prediction function \$f\$ in a given target domain without any labeled sample by exploiting the knowledge available from a source domain where labels are known. Our work makes the following assumption: there exists a non-linear transformation between the joint feature/label space distributions of the two domain \${\textbackslash}mathcal\{P\}\_s\$ and \${\textbackslash}mathcal\{P\}\_t\$. We propose a solution of this problem with optimal transport, that allows to recover an estimated target \${\textbackslash}mathcal\{P\}{\textasciicircum}f\_t=(X,f(X))\$ by optimizing simultaneously the optimal coupling and \$f\$. We show that our method corresponds to the minimization of a bound on the target error, and provide an efficient algorithmic solution, for which convergence is proved. The versatility of our approach, both in terms of class of hypothesis or loss functions is demonstrated with real world classification and regression problems, for which we reach or surpass state-of-the-art results.},
	urldate = {2021-01-20},
	journal = {arXiv:1705.08848 [cs, stat]},
	author = {Courty, Nicolas and Flamary, Rémi and Habrard, Amaury and Rakotomamonjy, Alain},
	month = oct,
	year = {2017},
	note = {arXiv: 1705.08848},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Accepted for publication at NIPS 2017},
	}
	
@inproceedings{courty2017joint,
  title={Joint distribution optimal transportation for domain adaptation},
  author={Courty, Nicolas and Flamary, R{\'e}mi and Habrard, Amaury and Rakotomamonjy, Alain},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={3733--3742},
  year={2017}
}

@article{salman_adversarially_2020,
	title = {Do {Adversarially} {Robust} {ImageNet} {Models} {Transfer} {Better}?},
	abstract = {Transfer learning is a widely-used paradigm in deep learning, where models pre-trained on standard datasets can be efficiently adapted to downstream tasks. Typically, better pre-trained models yield better transfer results, suggesting that initial accuracy is a key aspect of transfer learning performance. In this work, we identify another such aspect: we find that adversarially robust models, while less accurate, often perform better than their standard-trained counterparts when used for transfer learning. Specifically, we focus on adversarially robust ImageNet classifiers, and show that they yield improved accuracy on a standard suite of downstream classification tasks. Further analysis uncovers more differences between robust and standard models in the context of transfer learning. Our results are consistent with (and in fact, add to) recent hypotheses stating that robustness leads to improved feature representations. Our code and models are available at https://github.com/Microsoft/robust-models-transfer .},
	urldate = {2021-01-20},
	journal = {arXiv:2007.08489 [cs, stat]},
	author = {Salman, Hadi and Ilyas, Andrew and Engstrom, Logan and Kapoor, Ashish and Madry, Aleksander},
	month = dec,
	year = {2020},
	note = {arXiv: 2007.08489},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: NeurIPS 2020},
	}

@article{zhao_domain_nodate,
	title = {Domain {Generalization} via {Entropy} {Regularization}},
	abstract = {Domain generalization aims to learn from multiple source domains a predictive model that can generalize to unseen target domains. One essential problem in domain generalization is to learn discriminative domain-invariant features. To arrive at this, some methods introduce a domain discriminator through adversarial learning to match the feature distributions in multiple source domains. However, adversarial training can only guarantee that the learned features have invariant marginal distributions, while the invariance of conditional distributions is more important for prediction in new domains. To ensure the conditional invariance of learned features, we propose an entropy regularization term that measures the dependency between the learned features and the class labels. Combined with the typical task-related loss, e.g., cross-entropy loss for classiﬁcation, and adversarial loss for domain discrimination, our overall objective is guaranteed to learn conditional-invariant features across all source domains and thus can learn classiﬁers with better generalization capabilities. We demonstrate the effectiveness of our method through comparison with state-of-the-art methods on both simulated and real-world datasets. Code is available at: https://github.com/sshan-zhao/DG\_via\_ER.},
	language = {en},
	author = {Zhao, Shanshan and Gong, Mingming and Liu, Tongliang and Fu, Huan and Tao, Dacheng},
	pages = {12},
	}

@article{mancini_towards_2020,
	title = {Towards {Recognizing} {New} {Semantic} {Concepts} in {New} {Visual} {Domains}},
	abstract = {Deep learning models heavily rely on large scale annotated datasets for training. Unfortunately, datasets cannot capture the infinite variability of the real world, thus neural networks are inherently limited by the restricted visual and semantic information contained in their training set. In this thesis, we argue that it is crucial to design deep architectures that can operate in previously unseen visual domains and recognize novel semantic concepts. In the first part of the thesis, we describe different solutions to enable deep models to generalize to new visual domains, by transferring knowledge from a labeled source domain(s) to a domain (target) where no labeled data are available. We will show how variants of batch-normalization (BN) can be applied to different scenarios, from domain adaptation when source and target are mixtures of multiple latent domains, to domain generalization, continuous domain adaptation, and predictive domain adaptation, where information about the target domain is available only in the form of metadata. In the second part of the thesis, we show how to extend the knowledge of a pretrained deep model to new semantic concepts, without access to the original training set. We address the scenarios of sequential multi-task learning, using transformed task-specific binary masks, open-world recognition, with end-to-end training and enforced clustering, and incremental class learning in semantic segmentation, where we highlight and address the problem of the semantic shift of the background class. In the final part, we tackle a more challenging problem: given images of multiple domains and semantic categories (with their attributes), how to build a model that recognizes images of unseen concepts in unseen domains? We also propose an approach based on domain and semantic mixing of inputs and features, which is a first, promising step towards solving this problem.},
	urldate = {2021-01-20},
	journal = {arXiv:2012.09058 [cs]},
	author = {Mancini, Massimiliano},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.09058
version: 1},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Ph.D. thesis. Sapienza University of Rome (2020)},
	}

@article{wang_respecting_2020,
	title = {Respecting {Domain} {Relations}: {Hypothesis} {Invariance} for {Domain} {Generalization}},
	shorttitle = {Respecting {Domain} {Relations}},
	abstract = {In domain generalization, multiple labeled non-independent and non-identically distributed source domains are available during training while neither the data nor the labels of target domains are. Currently, learning so-called domain invariant representations (DIRs) is the prevalent approach to domain generalization. In this work, we define DIRs employed by existing works in probabilistic terms and show that by learning DIRs, overly strict requirements are imposed concerning the invariance. Particularly, DIRs aim to perfectly align representations of different domains, i.e. their input distributions. This is, however, not necessary for good generalization to a target domain and may even dispose of valuable classification information. We propose to learn so-called hypothesis invariant representations (HIRs), which relax the invariance assumptions by merely aligning posteriors, instead of aligning representations. We report experimental results on public domain generalization datasets to show that learning HIRs is more effective than learning DIRs. In fact, our approach can even compete with approaches using prior knowledge about domains.},
	urldate = {2021-01-20},
	journal = {arXiv:2010.07591 [cs]},
	author = {Wang, Ziqi and Loog, Marco and van Gemert, Jan},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.07591
version: 1},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: accepted at ICPR 2020},
	}

@article{garg_learn_2020,
	title = {Learn to {Expect} the {Unexpected}: {Probably} {Approximately} {Correct} {Domain} {Generalization}},
	shorttitle = {Learn to {Expect} the {Unexpected}},
	abstract = {Domain generalization is the problem of machine learning when the training data and the test data come from different data domains. We present a simple theoretical model of learning to generalize across domains in which there is a meta-distribution over data distributions, and those data distributions may even have different supports. In our model, the training data given to a learning algorithm consists of multiple datasets each from a single domain drawn in turn from the meta-distribution. We study this model in three different problem settings---a multi-domain Massart noise setting, a decision tree multi-dataset setting, and a feature selection setting, and find that computationally efficient, polynomial-sample domain generalization is possible in each. Experiments demonstrate that our feature selection algorithm indeed ignores spurious correlations and improves generalization.},
	urldate = {2021-01-20},
	journal = {arXiv:2002.05660 [cs, stat]},
	author = {Garg, Vikas K. and Kalai, Adam and Ligett, Katrina and Wu, Zhiwei Steven},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.05660
version: 1},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	}

@article{azizzadenesheli_importance_2020,
	title = {Importance {Weight} {Estimation} and {Generalization} in {Domain} {Adaptation} under {Label} {Shift}},
	abstract = {We study generalization under label shift in domain adaptation where the learner has access to labeled samples from the source domain but unlabeled samples from the target domain. Prior works deploy label classifiers and introduce various methods to estimate the importance weights from source to target domains. They use these estimates in importance weighted empirical risk minimization to learn classifiers. In this work, we theoretically compare the prior approaches, relax their strong assumptions, and generalize them from requiring label classifiers to general functions. This latter generalization improves the conditioning on the inverse operator of the induced inverse problems by allowing for broader exploitation of the spectrum of the forward operator. The prior works in the study of label shifts are limited to categorical label spaces. In this work, we propose a series of methods to estimate the importance weight functions for arbitrary normed label spaces. We introduce a new operator learning approach between Hilbert spaces defined on labels (rather than covariates) and show that it induces a perturbed inverse problem of compact operators. We propose a novel approach to solve the inverse problem in the presence of perturbation. This analysis has its own independent interest since such problems commonly arise in partial differential equations and reinforcement learning. For both categorical and general normed spaces, we provide concentration bounds for the proposed estimators. Using the existing generalization analysis based on Rademacher complexity, R{\textbackslash}'enyi divergence, and MDFR lemma in Azizzadenesheli et al. [2019], we show the generalization property of the importance weighted empirical risk minimization on the unseen target domain.},
	urldate = {2021-01-21},
	journal = {arXiv:2011.14251 [cs]},
	author = {Azizzadenesheli, Kamyar},
	month = nov,
	year = {2020},
	note = {arXiv: 2011.14251
version: 1},
	keywords = {Computer Science - Machine Learning},
	}

@article{deshmukh_generalization_2019,
	title = {A {Generalization} {Error} {Bound} for {Multi}-class {Domain} {Generalization}},
	abstract = {Domain generalization is the problem of assigning labels to an unlabeled data set, given several similar data sets for which labels have been provided. Despite considerable interest in this problem over the last decade, there has been no theoretical analysis in the setting of multi-class classification. In this work, we study a kernel-based learning algorithm and establish a generalization error bound that scales logarithmically in the number of classes, matching state-of-the-art bounds for multi-class classification in the conventional learning setting. We also demonstrate empirically that the proposed algorithm achieves significant performance gains compared to a pooling strategy.},
	urldate = {2021-01-21},
	journal = {arXiv:1905.10392 [cs, stat]},
	author = {Deshmukh, Aniket Anand and Lei, Yunwen and Sharma, Srinagesh and Dogan, Urun and Cutler, James W. and Scott, Clayton},
	month = may,
	year = {2019},
	note = {arXiv: 1905.10392
version: 1},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	}
@article{bartlett_vcdim,
	title = {Nearly-tight {VC}-dimension and {Pseudodimension} {Bounds} for {Piecewise} {Linear} {Neural} {Networks}},
	author = {Bartlett, Peter L and Harvey, Nick and Liaw, Christopher and Mehrabian, Abbas},
	journal="Journal of Machine Learning Research",
	pages = {1--17},
	year = "2019",	
}

@inproceedings{cortes_learning_2010,
	title = {Learning {Bounds} for {Importance} {Weighting}},
	volume = {23},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Cortes, Corinna and Mansour, Yishay and Mohri, Mehryar},
	editor = {Lafferty, J. and Williams, C. and Shawe-Taylor, J. and Zemel, R. and Culotta, A.},
	year = {2010},
	pages = {442--450}
}

@article{redko_survey_2020,
	title = {A survey on domain adaptation theory: learning bounds and theoretical guarantees},
	shorttitle = {A survey on domain adaptation theory},
	abstract = {All famous machine learning algorithms that comprise both supervised and semi-supervised learning work well only under a common assumption: the training and test data follow the same distribution. When the distribution changes, most statistical models must be reconstructed from new collected data, which for some applications can be costly or impossible to obtain. Therefore, it has become necessary to develop approaches that reduce the need and the effort to obtain new labeled samples by exploiting data that are available in related areas, and using these further across similar ﬁelds. This has given rise to a new machine learning framework known as transfer learning: a learning setting inspired by the capability of a human being to extrapolate knowledge across tasks to learn more efﬁciently. Despite a large amount of different transfer learning scenarios, the main objective of this survey is to provide an overview of the state-of-the-art theoretical results in a speciﬁc, and arguably the most popular, sub-ﬁeld of transfer learning, called domain adaptation. In this sub-ﬁeld, the data distribution is assumed to change across the training and the test data, while the learning task remains the same. We provide a ﬁrst up-to-date description of existing results related to domain adaptation problem that cover learning bounds based on different statistical learning frameworks.},
	language = {en},
	urldate = {2021-02-03},
	journal = {arXiv:2004.11829 [cs, stat]},
	author = {Redko, Ievgen and Morvant, Emilie and Habrard, Amaury and Sebban, Marc and Bennani, Younès},
	month = aug,
	year = {2020},
	note = {arXiv: 2004.11829},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	}

@article{redko_survey_2020-1,
	title = {A survey on domain adaptation theory: learning bounds and theoretical guarantees},
	shorttitle = {A survey on domain adaptation theory},
	abstract = {All famous machine learning algorithms that comprise both supervised and semi-supervised learning work well only under a common assumption: the training and test data follow the same distribution. When the distribution changes, most statistical models must be reconstructed from newly collected data, which for some applications can be costly or impossible to obtain. Therefore, it has become necessary to develop approaches that reduce the need and the effort to obtain new labeled samples by exploiting data that are available in related areas, and using these further across similar fields. This has given rise to a new machine learning framework known as transfer learning: a learning setting inspired by the capability of a human being to extrapolate knowledge across tasks to learn more efficiently. Despite a large amount of different transfer learning scenarios, the main objective of this survey is to provide an overview of the state-of-the-art theoretical results in a specific, and arguably the most popular, sub-field of transfer learning, called domain adaptation. In this sub-field, the data distribution is assumed to change across the training and the test data, while the learning task remains the same. We provide a first up-to-date description of existing results related to domain adaptation problem that cover learning bounds based on different statistical learning frameworks.},
	urldate = {2021-02-03},
	journal = {arXiv:2004.11829 [cs, stat]},
	author = {Redko, Ievgen and Morvant, Emilie and Habrard, Amaury and Sebban, Marc and Bennani, Younès},
	month = aug,
	year = {2020},
	note = {arXiv: 2004.11829},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	}
@ARTICLE{usps,
  author={Hull, J.J.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A database for handwritten text recognition research}, 
  year={1994},
  volume={16},
  number={5},
  pages={550-554},
  doi={10.1109/34.291440}}
@article{zhang_unsupervised_2020,
	title = {Unsupervised {Multi}-{Class} {Domain} {Adaptation}: {Theory}, {Algorithms}, and {Practice}},
	issn = {1939-3539},
	shorttitle = {Unsupervised {Multi}-{Class} {Domain} {Adaptation}},
	abstract = {In this paper, we study the formalism of unsupervised multi-class domain adaptation (multi-class UDA), which underlies a few recent algorithms whose learning objectives are only motivated empirically. Multi-Class Scoring Disagreement (MCSD) divergence is presented by aggregating the absolute margin violations in multi-class classification, and this proposed MCSD is able to fully characterize the relations between any pair of multi-class scoring hypotheses. By using MCSD as a measure of domain distance, we develop a new domain adaptation bound for multi-class UDA; its data-dependent, probably approximately correct bound is also developed that naturally suggests adversarial learning objectives to align conditional feature distributions across source and target domains. Consequently, an algorithmic framework of Multi-class Domain-adversarial learning Networks (McDalNets) is developed, and its different instantiations via surrogate learning objectives either coincide with or resemble a few recently popular methods, thus (partially) underscoring their practical effectiveness. Based on our identical theory for multi-class UDA, we also introduce a new algorithm of Domain-Symmetric Networks (SymmNets), which is featured by a novel adversarial strategy of domain confusion and discrimination. SymmNets affords simple extensions that work equally well under the problem settings of either closed set, partial, or open set UDA. We conduct careful empirical studies to compare different algorithms of McDalNets and our newly introduced SymmNets. Experiments verify our theoretical analysis and show the efficacy of our proposed SymmNets. In addition, we have made our implementation code publicly available.},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Zhang, Y. and Deng, B. and Tang, H. and Zhang, L. and Jia, K.},
	year = {2020},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Machine learning, Task analysis, Training, Testing, Training data, Adaptation models, Domain adaptation, adversarial training, multi-class classification, partial or open set domain adaptation, Standards},
	pages = {1--1},
	}
@misc{maurer2004,
author ={Andreas Maurer},
title= {A note on the PAC Bayesian theorem},
eprint={cs.LG/0411099}
}

@article{fang2020rethinking,
  title={Rethinking importance weighting for deep learning under distribution shift},
  author={Fang, Tongtong and Lu, Nan and Niu, Gang and Sugiyama, Masashi},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11996--12007},
  year={2020}
}

@article{zhang_generalization_2012,
           title = {Generalization {Bounds} for {Domain} {Adaptation}},
           volume = {25},
           language = {en},
           urldate = {2021-02-10},
           journal = {Advances in Neural Information Processing Systems},
           author = {Zhang, Chao and Zhang, Lei and Ye, Jieping},
           year = {2012},
          pages = {3320--3328},
          file = {Full Text PDF:/home/adam/Zotero/storage/V89LJTD9/Zhang et al. - 2012 - Generalization Bounds for Domain Adaptation.pdf:application/pdf;Snapshot:/home/adam/Zotero/storage/UI5R9B5E/ca8155f4d27    f205953f9d3d7974bdd70-Abstract.html:text/html},
  }

@InProceedings{dhouib_2020,
  title = 	 {Margin-aware Adversarial Domain Adaptation with Optimal Transport},
  author =       {Dhouib, Sofien and Redko, Ievgen and Lartizien, Carole},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {2514--2524},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  abstract = 	 {In this paper, we propose a new theoretical analysis of unsupervised domain adaptation that relates notions of large margin separation, adversarial learning and optimal transport. This analysis generalizes previous work on the subject by providing a bound on the target margin violation rate, thus reflecting a better control of the quality of separation between classes in the target domain than bounding the misclassification rate. The bound also highlights the benefit of a large margin separation on the source domain for adaptation and introduces an optimal transport (OT) based distance between domains that has the virtue of being task-dependent, contrary to other approaches. From the obtained theoretical results, we derive a novel algorithmic solution for domain adaptation that introduces a novel shallow OT-based adversarial approach and outperforms other OT-based DA baselines on several simulated and real-world classification tasks.}
}
@article{li_bayesian_2007,
           title = {A {Bayesian} {Divergence} {Prior} for {Classiffier} {Adaptation}.},
           volume = {2},
           abstract = {Adaptation of statistical classiers is criti- cal when a target (or testing) distribution is dieren t from the distribution that gov- erns training data. In such cases, a classier optimi    zed for the training distribution needs to be adapted for optimal use in the target distribution. This paper presents a Bayesian {\textbackslash}divergence prior" for generic classier adap- tation. Instanti    ations of this prior lead to simple yet principled adaptation strategies for a variety of classiers, which yield su- perior performance in practice. In addition, this paper derives several adaptation error     bounds by applying the divergence prior in the PAC-Bayesian setting.},
           journal = {Journal of Machine Learning Research - Proceedings Track},
           author = {Li, Xiao and Bilmes, Jeff},
           month = jan,
           year = {2007},
           pages = {275--282},
  }

@article{shen_wasserstein_2018,
           title = {Wasserstein {Distance} {Guided} {Representation} {Learning} for {Domain} {Adaptation}},
           abstract = {Domain adaptation aims at generalizing a high-performance learner on a target domain via utilizing the knowledge distilled from a source domain which has a different but related data dis    tribution. One solution to domain adaptation is to learn domain invariant feature representations while the learned representations should also be discriminative in prediction. To learn such representations    , domain adaptation frameworks usually include a domain invariant representation learning approach to measure and reduce the domain discrepancy, as well as a discriminator for classification. Inspired by Wa    sserstein GAN, in this paper we propose a novel approach to learn domain invariant feature representations, namely Wasserstein Distance Guided Representation Learning (WDGRL). WDGRL utilizes a neural networ    k, denoted by the domain critic, to estimate empirical Wasserstein distance between the source and target samples and optimizes the feature extractor network to minimize the estimated Wasserstein distance i    n an adversarial manner. The theoretical advantages of Wasserstein distance for domain adaptation lie in its gradient property and promising generalization bound. Empirical studies on common sentiment and i    mage classification adaptation datasets demonstrate that our proposed WDGRL outperforms the state-of-the-art domain invariant representation learning approaches.},
           urldate = {2021-02-09},
           journal = {arXiv:1707.01217 [cs, stat]},
           author = {Shen, Jian and Qu, Yanru and Zhang, Weinan and Yu, Yong},
           month = mar,
           year = {2018},
          note = {arXiv: 1707.01217},
         keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
          annote = {Comment: The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI 2018)},
          file = {arXiv Fulltext PDF:/home/adam/Zotero/storage/EUANZPU2/Shen et al. - 2018 - Wasserstein Distance Guided Representation Learnin.pdf:application/pdf;arXiv.org Snapshot:/home/adam/Zotero/storage    /ZR8B39DZ/1707.html:text/html},
  }

@InProceedings{redko_2019,
  title = 	 {Optimal Transport for Multi-source Domain Adaptation under Target Shift},
  author =       {Redko, Ievgen and Courty, Nicolas and Flamary, R\'emi and Tuia, Devis},
  booktitle = 	 {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
  pages = 	 {849--858},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {16--18 Apr},
  publisher =    {PMLR},
  abstract = 	 {In this paper, we tackle the problem of reducing discrepancies between multiple domains, i.e. multi-source domain adaptation, and consider it under the target shift assumption: in all domains we aim to solve a classification problem with the same output classes, but with different labels proportions. This problem, generally ignored in the vast majority of domain adaptation papers, is nevertheless critical in real-world applications, and we theoretically show its impact on the success of the adaptation. Our proposed method is based on optimal transport, a theory that has been successfully used to tackle adaptation problems in machine learning. The introduced approach, Joint Class Proportion and Optimal Transport (JCPOT), performs multi-source adaptation and target shift correction simultaneously by learning the class probabilities of the unlabeled target sample and the coupling allowing to align two (or more) probability distributions. Experiments on both synthetic and real-world data (satellite image pixel classification) task show the superiority of the proposed method over the state-of-the-art.}
}

@article{dhouib_revisiting_2018,
	title = {Revisiting ( $\epsilon$ , $\gamma$, $\tau$ )-similarity learning for domain adaptation},
	abstract = {Similarity learning is an active research area in machine learning that tackles the problem of ﬁnding a similarity function tailored to an observable data sample in order to achieve eﬃcient classiﬁcation. This learning scenario has been generally formalized by the means of a ( , γ, τ )−good similarity learning framework in the context of supervised classiﬁcation and has been shown to have strong theoretical guarantees. In this paper, we propose to extend the theoretical analysis of similarity learning to the domain adaptation setting, a particular situation occurring when the similarity is learned and then deployed on samples following diﬀerent probability distributions. We give a new deﬁnition of an ( , γ)−good similarity for domain adaptation and prove several results quantifying the performance of a similarity function on a target domain after it has been trained on a source domain. We particularly show that if the source distribution dominates the target one, then principally new domain adaptation learning bounds can be proved.},
	language = {en},
	journal={NeurIPS},
	author = {Dhouib, Soﬁen and Redko, Ievgen},
	pages = {7408–7417},
	year={2018}
	}
@InProceedings{wang2017chestxray,author    = {Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald},title     = {ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases},booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition(CVPR)},pages     = {3462--3471},year      = {2017}}
@inproceedings{Irvin2019CheXpertAL,
  title={CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison},
  author={Jeremy A. Irvin and Pranav Rajpurkar and M. Ko and Yifan Yu and Silviana Ciurea-Ilcus and Chris Chute and H. Marklund and Behzad Haghgoo and Robyn L. Ball and K. Shpanskaya and J. Seekins and D. Mong and S. Halabi and J. Sandberg and Ricky H Jones and D. Larson and C. Langlotz and B. Patel and M. Lungren and A. Ng},
  booktitle={AAAI},
  year={2019}
}
@article{byrd_what_2019,
	title = {What is the {Effect} of {Importance} {Weighting} in {Deep} {Learning}?},
	abstract = {Importance-weighted risk minimization is a key ingredient in many machine learning algorithms for causal inference, domain adaptation, class imbalance, and off-policy reinforcement learning. While the effect of importance weighting is well-characterized for low-capacity misspecified models, little is known about how it impacts over-parameterized, deep neural networks. This work is inspired by recent theoretical results showing that on (linearly) separable data, deep linear networks optimized by SGD learn weight-agnostic solutions, prompting us to ask, for realistic deep networks, for which many practical datasets are separable, what is the effect of importance weighting? We present the surprising finding that while importance weighting impacts models early in training, its effect diminishes over successive epochs. Moreover, while L2 regularization and batch normalization (but not dropout), restore some of the impact of importance weighting, they express the effect via (seemingly) the wrong abstraction: why should practitioners tweak the L2 regularization, and by how much, to produce the correct weighting effect? Our experiments confirm these findings across a range of architectures and datasets.},
	urldate = {2021-02-04},
	journal = {arXiv:1812.03372 [cs, stat]},
	author = {Byrd, Jonathon and Lipton, Zachary C.},
	month = jun,
	year = {2019},
	note = {arXiv: 1812.03372},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	}

@article{germain_pac-bayes_2020-1,
	title = {{PAC}-{Bayes} and domain adaptation},
	volume = {379},
	issn = {0925-2312},
	abstract = {We provide two main contributions in PAC-Bayesian theory for domain adaptation where the objective is to learn, from a source distribution, a well-performing majority vote on a different, but related, target distribution. Firstly, we propose an improvement of the previous approach we proposed in [1], which relies on a novel distribution pseudodistance based on a disagreement averaging, allowing us to derive a new tighter domain adaptation bound for the target risk. While this bound stands in the spirit of common domain adaptation works, we derive a second bound (introduced in [2]) that brings a new perspective on domain adaptation by deriving an upper bound on the target risk where the distributions’ divergence—expressed as a ratio—controls the trade-off between a source error measure and the target voters’ disagreement. We discuss and compare both results, from which we obtain PAC-Bayesian generalization bounds. Furthermore, from the PAC-Bayesian specialization to linear classifiers, we infer two learning algorithms, and we evaluate them on real data.},
	language = {en},
	urldate = {2021-02-09},
	journal = {Neurocomputing},
	author = {Germain, Pascal and Habrard, Amaury and Laviolette, François and Morvant, Emilie},
	month = feb,
	year = {2020},
	keywords = {Domain adaptation, PAC-Bayesian theory},
	pages = {379--397},
	}

@article{mcnamara_risk_2017,
	title = {Risk {Bounds} for {Transferring} {Representations} {With} and {Without} {Fine}-{Tuning}},
	abstract = {A popular machine learning strategy is the transfer of a representation (i.e. a feature extraction function) learned on a source task to a target task. Examples include the re-use of neural network weights or word embeddings. We develop sufﬁcient conditions for the success of this approach. If the representation learned from the source task is ﬁxed, we identify conditions on how the tasks relate to obtain an upper bound on target task risk via a VC dimension-based argument. We then consider using the representation from the source task to construct a prior, which is ﬁne-tuned using target task data. We give a PAC-Bayes target task risk bound in this setting under suitable conditions. We show examples of our bounds using feedforward neural networks. Our results motivate a practical approach to weight transfer, which we validate with experiments.},
	language = {en},
	journal={ICML},
	author = {McNamara, Daniel and Balcan, Maria-Florina},
	pages = {9},
	year={2017}
	}
	 @article{du_hypothesis_2017,
           title = {Hypothesis {Transfer} {Learning} via {Transformation} {Functions}},
           url = {http://arxiv.org/abs/1612.01020},
           abstract = {We consider the Hypothesis Transfer Learning (HTL) problem where one incorporates a hypothesis trained on the source domain into the learning procedure of the target domain. Existing the    oretical analysis either only studies specific algorithms or only presents upper bounds on the generalization error but not on the excess risk. In this paper, we propose a unified algorithm-dependent framew    ork for HTL through a novel notion of transformation function, which characterizes the relation between the source and the target domains. We conduct a general risk analysis of this framework and in particu    lar, we show for the first time, if two domains are related, HTL enjoys faster convergence rates of excess risks for Kernel Smoothing and Kernel Ridge Regression than those of the classical non-transfer lea    rning settings. Experiments on real world data demonstrate the effectiveness of our framework.},
           urldate = {2021-02-09},
           journal = {arXiv:1612.01020 [cs, stat]},
           author = {Du, Simon Shaolei and Koushik, Jayanth and Singh, Aarti and Poczos, Barnabas},
           month = nov,
           year = {2017},
          note = {arXiv: 1612.01020},
          keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
          annote = {Comment: Accepted by NIPS 2017},
          file = {arXiv Fulltext PDF:/home/adam/Zotero/storage/URUEJ3GJ/Du et al. - 2017 - Hypothesis Transfer Learning via Transformation Fu.pdf:application/pdf;arXiv.org Snapshot:/home/adam/Zotero/storage/6    AGTL2B9/1612.html:text/html},
  }
@inproceedings{perrot_theoretical_2015,
           title = {A {Theoretical} {Analysis} of {Metric} {Hypothesis} {Transfer} {Learning}},
           abstract = {We consider the problem of transferring some a priori knowledge in the context of supervised metric learning approaches. While this setting has been successfully applied in some empirica    l contexts, no theoretical evidence exists to justify this approach. In this paper, we provide a theoretical justiﬁcation based on the notion of algorithmic stability adapted to the regularized metric learn    ing setting. We propose an on-averagereplace-two-stability model allowing us to prove fast generalization rates when an auxiliary source metric is used to bias the regularizer. Moreover, we prove a consiste    ncy result from which we show the interest of considering biased weighted regularized formulations and we provide a solution to estimate the associated weight. We also present some experiments illustrating     the interest of the approach in standard metric learning tasks and in a transfer learning problem where few labelled data are available.},
           booktitle={ICML},
           language = {en},
           author = {Perrot, Michaël and Habrard, Amaury},
           year = {2015},
           pages = {1708--1717},
           file = {Perrot and Habrard - A Theoretical Analysis of Metric Hypothesis transf.pdf:/home/adam/Zotero/storage/QVUENL4N/Perrot and Habrard - A Theoretical Analysis of Metric Hypothesis Transf.pdf:app    lication/pdf},
   }

	@article{morvant_parsimonious_2012,
           title = {Parsimonious unsupervised and semi-supervised domain adaptation with good similarity functions},
           volume = {33},
           issn = {0219-1377, 0219-3116},
           abstract = {In this paper, we address the problem of domain adaptation for binary classiﬁcation. This problem arises when the distributions generating the source learning data and target test data a    re somewhat different. From a theoretical standpoint, a classiﬁer has better generalization guarantees when the two domain marginal distributions of the input space are close. Classical approaches try mainl    y to build new projection spaces or to reweight the source data with the objective of moving closer the two distributions. We study an original direction based on a recent framework introduced by Balcan et     al. enabling one to learn linear classiﬁers in an explicit projection space based on a similarity function, not necessarily symmetric nor positive semi-deﬁnite. We propose a well founded general method for     learning a low-error classiﬁer on target data which is effective with the help of an iterative procedure compatible with Balcan et al.’s framework. A reweighting scheme of the similarity function is then in    troduced in order to move closer the distributions in a new projection space. The hyperparameters and the reweighting quality are controlled by a reverse validation procedure. Our approach is based on a lin    ear programming formulation and shows good adaptation performances with very sparse models. We ﬁrst consider the challenging unsupervised case where no target label is accessible, which can be helpful when     no manual annotation is possible. We also propose a generalisation to the semi-supervised case allowing us to consider some few target labels when available. Finally, we evaluate our method on a synthetic p    roblem and on a real image annotation task.},
           language = {en},
           number = {2},
          urldate = {2021-02-09},
          journal = {Knowledge and Information Systems},
          author = {Morvant, Emilie and Habrard, Amaury and Ayache, Stéphane},
          month = nov,
          year = {2012},
          pages = {309--349},
          file = {Morvant et al. - 2012 - Parsimonious unsupervised and semi-supervised doma.pdf:/home/adam/Zotero/storage/PTD2ESF2/Morvant et al. - 2012 - Parsimonious unsupervised and semi-supervised doma.p    df:application/pdf},
  }

	@article{kuzborskij_fast_2017,
          title = {Fast rates by transferring from auxiliary hypotheses},
          volume = {106},
          issn = {1573-0565},
          url = {https://doi.org/10.1007/s10994-016-5594-4},
          doi = {10.1007/s10994-016-5594-4},
          abstract = {In this work we consider the learning setting where, in addition to the training set, the learner receives a collection of auxiliary hypotheses originating from other tasks. We focus on     a broad class of ERM-based linear algorithms that can be instantiated with any non-negative smooth loss function and any strongly convex regularizer. We establish generalization and excess risk bounds, show    ing that, if the algorithm is fed with a good combination of source hypotheses, generalization happens at the fast rate \$\${\textbackslash}mathcal \{O\}(1/m)\$\$O(1/m)instead of the usual \$\${\textbacksla    sh}mathcal \{O\}(1/{\textbackslash}sqrt\{m\})\$\$O(1/m). On the other hand, if the source hypotheses combination is a misfit for the target task, we recover the usual learning rate. As a byproduct of our st    udy, we also prove a new bound on the Rademacher complexity of the smooth loss class under weaker assumptions compared to previous works.},
          language = {en},
          number = {2},
          urldate = {2021-02-09},
          journal = {Machine Learning},
          author = {Kuzborskij, Ilja and Orabona, Francesco},
          month = feb,
          year = {2017},
          pages = {171--195},
          file = {Springer Full Text PDF:/home/adam/Zotero/storage/VZT8KXR8/Kuzborskij and Orabona - 2017 - Fast rates by transferring from auxiliary hypothes.pdf:application/pdf},
 }

	 @inproceedings{kuzborskij_stability_2013,
           title = {Stability and {Hypothesis} {Transfer} {Learning}},
           abstract = {We consider the transfer learning scenario, where the learner does not have access to the source domain directly, but rather operates on the basis of hypotheses induced from it – the Hyp    othesis Transfer Learning (HTL) problem. Particularly, we conduct a theoretical analysis of HTL by considering the algorithmic stability of a class of HTL algorithms based on Regularized Least Squares with     biased regularization. We show that the relatedness of source and target domains accelerates the convergence of the Leave-OneOut error to the generalization error, thus enabling the use of the Leave-One-Out     error to ﬁnd the optimal transfer parameters, even in the presence of a small training set. In case of unrelated domains we also suggest a theoretically principled way to prevent negative transfer, so that     in the limit we recover the performance of the algorithm not using any knowledge from the source domain.},
           language = {en},
           author = {Kuzborskij, Ilja and Orabona, Francesco},
           year = {2013},
           booktitle={ICML},
           pages = {942--950},
           file = {Kuzborskij and Orabona - Stability and Hypothesis Transfer Learning.pdf:/home/adam/Zotero/storage/R4ITCR7R/Kuzborskij and Orabona - Stability and Hypothesis Transfer Learning.pdf:application    /pdf},
   }

@article{mansour_robust_2014,
          title = {Robust domain adaptation},
          volume = {71},
          issn = {1573-7470},
          url = {https://doi.org/10.1007/s10472-013-9391-5},
          doi = {10.1007/s10472-013-9391-5},
          abstract = {We derive a generalization bound for domain adaptation by using the properties of robust algorithms. Our new bound depends on λ-shift, a measure of prior knowledge regarding the similari    ty of source and target domain distributions. Based on the generalization bound, we design SVM variants for binary classification and regression domain adaptation algorithms.},
          language = {en},
          number = {4},
         urldate = {2021-02-09},
          journal = {Annals of Mathematics and Artificial Intelligence},
          author = {Mansour, Yishay and Schain, Mariano},
          month = aug,
          year = {2014},
          pages = {365--380},
          file = {Springer Full Text PDF:/home/adam/Zotero/storage/KHJRN7EU/Mansour and Schain - 2014 - Robust domain adaptation.pdf:application/pdf},
  }

@inproceedings{dziugaite_role_2020,
	title = {On the role of data in {PAC}-{Bayes} bounds},
	abstract = {The dominant term in PAC-Bayes bounds is often the Kullback--Leibler divergence between the posterior and prior. For so-called linear PAC-Bayes risk bounds based on the empirical risk of a fixed posterior kernel, it is possible to minimize the expected value of the bound by choosing the prior to be the expected posterior, which we call the oracle prior on the account that it is distribution dependent. In this work, we show that the bound based on the oracle prior can be suboptimal: In some cases, a stronger bound is obtained by using a data-dependent oracle prior, i.e., a conditional expectation of the posterior, given a subset of the training data that is then excluded from the empirical risk term. While using data to learn a prior is a known heuristic, its essential role in optimal bounds is new. In fact, we show that using data can mean the difference between vacuous and nonvacuous bounds. We apply this new principle in the setting of nonconvex learning, simulating data-dependent oracle priors on MNIST and Fashion MNIST with and without held-out data, and demonstrating new nonvacuous bounds in both cases.},
	urldate = {2021-02-09},
	booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence and Statistics (AISTATS)},
	author = {Dziugaite, Gintare Karolina and Hsu, Kyle and Gharbieh, Waseem and Arpino, Gabriel and Roy, Daniel M.},
	month = oct,
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 28 pages, 8 figures},
	}
@inproceedings{dziugaite2017,
  author    = {Gintare Karolina Dziugaite and
               Daniel M. Roy},
  title     = {Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural
               Networks with Many More Parameters than Training Data},
year="2017",
series="UAI, 2017"

}
@inproceedings{ben-david_analysis,
    author = {Ben-David, Shai and Blitzer, John and Crammer, Koby and Pereira, Fernando},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {B. Sch\"{o}lkopf and J. Platt and T. Hoffman},
    pages = {},
    publisher = {MIT Press},
   title = {Analysis of Representations for Domain Adaptation},
    volume = {19},
    year = {2007}
  }

@article{dziugaite_data-dependent_2019,
	title = {Data-dependent {PAC}-{Bayes} priors via differential privacy},
	abstract = {The Probably Approximately Correct (PAC) Bayes framework (McAllester, 1999) can incorporate knowledge about the learning algorithm and (data) distribution through the use of distribution-dependent priors, yielding tighter generalization bounds on data-dependent posteriors. Using this flexibility, however, is difficult, especially when the data distribution is presumed to be unknown. We show how an \{{\textbackslash}epsilon\}-differentially private data-dependent prior yields a valid PAC-Bayes bound, and then show how non-private mechanisms for choosing priors can also yield generalization bounds. As an application of this result, we show that a Gaussian prior mean chosen via stochastic gradient Langevin dynamics (SGLD; Welling and Teh, 2011) leads to a valid PAC-Bayes bound given control of the 2-Wasserstein distance to an \{{\textbackslash}epsilon\}-differentially private stationary distribution. We study our data-dependent bounds empirically, and show that they can be nonvacuous even when other distribution-dependent bounds are vacuous.},
	urldate = {2021-02-09},
	journal = {arXiv:1802.09583 [cs, stat]},
	author = {Dziugaite, Gintare Karolina and Roy, Daniel M.},
	month = apr,
	year = {2019},
	note = {arXiv: 1802.09583},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 18 pages, 2 figures; equivalent to camera ready, but includes supplementary materials; subsumes and extends some results first reported in arXiv:1712.09376},
	}

@misc{kuzborskij_theory_2018,
	title = {Theory and {Algorithms} for {Hypothesis} {Transfer} {Learning}},
	abstract = {The design and analysis of machine learning algorithms typically considers the problem of learning on a single task, and the nature of learning in such scenario is well explored. On the other hand, very often tasks faced by machine learning systems arrive sequentially, and therefore it is reasonable to ask whether a better approach can be taken than retraining such systems from scratch given newly available data. Indeed, by drawing analogy from human learning, a novel skill could be acquired more easily whenever the learner shares a relevant past experience. In response to this observation, the machine learning community has drawn its attention towards a form of learning known as transfer learning - learning a novel task by leveraging upon auxiliary information extracted from previous tasks. Tangible progress has been made in both theory and practice of transfer learning; however, many questions are still to be addressed.
 
 In this thesis we will focus on an efficient type of transfer learning, known as the Hypothesis Transfer Learning (HTL), where auxiliary information is retained in a form of previously induced hypotheses. This is in contrast to the large body of work where one transfers from the data associated with previously encountered tasks. In particular, we theoretically investigate conditions when HTL guarantees improved generalization on a novel task subject to the relevant auxiliary (source) hypotheses. We investigate HTL theoretically by considering three scenarios: HTL through regularized least squares with biased regularization, through convex empirical risk minimization, and through stochastic optimization, which also touches the theory of non-convex transfer learning problems. In addition, we demonstrate the benefits of HTL empirically, by proposing two algorithms tailored for real-life situations with application to visual learning problems - learning a new class in a multi-class classification setting by transferring from known classes, and an efficient greedy HTL algorithm for learning with large number of source hypotheses.
 
 From theoretical point of view this thesis consistently identifies the key quantitative characteristics of relatedness between novel and previous tasks, and explicitates them in generalization bounds. These findings corroborate many previous works in the transfer learning literature and provide a theoretical basis for design and analysis of new HTL algorithms.},
	language = {en},
	urldate = {2021-02-09},
	journal = {Infoscience},
	author = {Kuzborskij, Ilja},
	year = {2018},
	note = {Number: THESIS
Publisher: EPFL},
	}

@article{cortes_domain_2014,
	series = {Algorithmic {Learning} {Theory}},
	title = {Domain adaptation and sample bias correction theory and algorithm for regression},
	volume = {519},
	issn = {0304-3975},
	abstract = {We present a series of new theoretical, algorithmic, and empirical results for domain adaptation and sample bias correction in regression. We prove that the discrepancy is a distance for the squared loss when the hypothesis set is the reproducing kernel Hilbert space induced by a universal kernel such as the Gaussian kernel. We give new pointwise loss guarantees based on the discrepancy of the empirical source and target distributions for the general class of kernel-based regularization algorithms. These bounds have a simpler form than previous results and hold for a broader class of convex loss functions not necessarily differentiable, including Lq losses and the hinge loss. We also give finer bounds based on the discrepancy and a weighted feature discrepancy parameter. We extend the discrepancy minimization adaptation algorithm to the more significant case where kernels are used and show that the problem can be cast as an SDP similar to the one in the feature space. We also show that techniques from smooth optimization can be used to derive an efficient algorithm for solving such SDPs even for very high-dimensional feature spaces and large samples. We have implemented this algorithm and report the results of experiments both with artificial and real-world data sets demonstrating its benefits both for general scenario of adaptation and the more specific scenario of sample bias correction. Our results show that it can scale to large data sets of tens of thousands or more points and demonstrate its performance improvement benefits.},
	language = {en},
	urldate = {2021-02-09},
	journal = {Theoretical Computer Science},
	author = {Cortes, Corinna and Mohri, Mehryar},
	month = jan,
	year = {2014},
	keywords = {Domain adaptation, Learning theory, Machine learning, Optimization},
	pages = {103--126},
	}

@article{mcallester_pac-bayesian_1999,
	title = {Some {PAC}-{Bayesian} {Theorems}},
	volume = {37},
	issn = {1573-0565},
	abstract = {This paper gives PAC guarantees for “Bayesian” algorithms—algorithms that optimize risk minimization expressions involving a prior probability and a likelihood for the training data. PAC-Bayesian algorithms are motivated by a desire to provide an informative prior encoding information about the expected experimental setting but still having PAC performance guarantees over all IID settings. The PAC-Bayesian theorems given here apply to an arbitrary prior measure on an arbitrary concept space. These theorems provide an alternative to the use of VC dimension in proving PAC bounds for parameterized concepts.},
	language = {en},
	number = {3},
	urldate = {2021-02-09},
	journal = {Machine Learning},
	author = {McAllester, David A.},
	month = dec,
	year = {1999},
	pages = {355--363},
	}

@article{redko_theoretical_2017,
	title = {Theoretical {Analysis} of {Domain} {Adaptation} with {Optimal} {Transport}},
	abstract = {Domain adaptation (DA) is an important and emerging field of machine learning that tackles the problem occurring when the distributions of training (source domain) and test (target domain) data are similar but different. Current theoretical results show that the efficiency of DA algorithms depends on their capacity of minimizing the divergence between source and target probability distributions. In this paper, we provide a theoretical study on the advantages that concepts borrowed from optimal transportation theory can bring to DA. In particular, we show that the Wasserstein metric can be used as a divergence measure between distributions to obtain generalization guarantees for three different learning settings: (i) classic DA with unsupervised target data (ii) DA combining source and target labeled data, (iii) multiple source DA. Based on the obtained results, we provide some insights showing when this analysis can be tighter than other existing frameworks.},
	urldate = {2021-02-09},
	journal = {arXiv:1610.04420 [cs, stat]},
	author = {Redko, Ievgen and Habrard, Amaury and Sebban, Marc},
	month = jul,
	year = {2017},
	note = {arXiv: 1610.04420},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	}
@article{He2016DeepRL,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and X. Zhang and Shaoqing Ren and Jian Sun},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={770-778}
}
@article{parrado-hernandez_pac-bayes,
author = {Parrado-Hern\'{a}ndez, Emilio and Ambroladze, Amiran and Shawe-Taylor, John and Sun, Shiliang},
title = {PAC-Bayes Bounds with Data Dependent Priors},
year = {2012},
issue_date = {January 2012},
publisher = {JMLR.org},
volume = {13},
number = {1},
issn = {1532-4435},
abstract = {This paper presents the prior PAC-Bayes bound and explores its capabilities as a tool to provide tight predictions of SVMs' generalization. The computation of the bound involves estimating a prior of the distribution of classifiers from the available data, and then manipulating this prior in the usual PAC-Bayes generalization bound. We explore two alternatives: to learn the prior from a separate data set, or to consider an expectation prior that does not need this separate data set. The prior PAC-Bayes bound motivates two SVM-like classification algorithms, prior SVM and ν-prior SVM, whose regularization term pushes towards the minimization of the prior PAC-Bayes bound. The experimental work illustrates that the new bounds can be significantly tighter than the original PAC-Bayes bound when applied to SVMs, and among them the combination of the prior PAC-Bayes bound and the prior SVM algorithm gives the tightest bound.},
journal = {J. Mach. Learn. Res.},
month = {dec},
pages = {3507–3531},
numpages = {25},
keywords = {generalization capability prediction, support vector machine, classification, PAC-Bayes bound}
}
@inproceedings{ShaweWilliamson97,
author = {Shawe-Taylor, John and Williamson, Robert C.},
title = {A PAC Analysis of a Bayesian Estimator},
year = {1997},
isbn = {0897918916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the Tenth Annual Conference on Computational Learning Theory},
pages = {2–9},
numpages = {8},
location = {Nashville, Tennessee, USA},
series = {COLT '97}
}
@misc{noauthor_parrado-hernandez_nodate,
	title = {Parrado-{Hernández}: {PAC}-{Bayes} bounds with data dependent... - {Google} {Scholar}},
	urldate = {2021-02-09},
	}
@incollection{kivinen_domain_2011,
          address = {Berlin, Heidelberg},
        title = {Domain {Adaptation} in {Regression}},
          volume = {6925},
          isbn = {978-3-642-24411-7 978-3-642-24412-4},
         abstract = {This paper presents a series of new results for domain adaptation in the regress    ion setting. We prove that the discrepancy is a distance for the squared loss when the hypothesis se    t is the reproducing kernel Hilbert space induced by a universal kernel such as the Gaussian kernel.     We give new pointwise loss guarantees based on the discrepancy of the empirical source and target d    istributions for the general class of kernel-based regularization algorithms. These bounds have a si    mpler form than previous results and hold for a broader class of convex loss functions not necessari    ly differentiable, including Lq losses and the hinge loss. We extend the discrepancy minimization ad    aptation algorithm to the more signiﬁcant case where kernels are used and show that the problem can     be cast as an SDP similar to the one in the feature space. We also show that techniques from smooth     optimization can be used to derive an efﬁcient algorithm for solving such SDPs even for very high-di    mensional feature spaces. We have implemented this algorithm and report the results of experiments d    emonstrating its beneﬁts for adaptation and show that, unlike previous algorithms, it can scale to l    arge data sets of tens of thousands or more points.},
          language = {en},
         urldate = {2021-02-09},
        booktitle = {Algorithmic {Learning} {Theory}},
         publisher = {Springer Berlin Heidelberg},
         author = {Cortes, Corinna and Mohri, Mehryar},
         editor = {Kivinen, Jyrki and Szepesvári, Csaba and Ukkonen, Esko and Zeugmann, Thomas},
          year = {2011},
         note = {Series Title: Lecture Notes in Computer Science},
         pages = {308--323},
          }
@article{li_transfer_2019,
	title = {Transfer {Independently} {Together}: {A} {Generalized} {Framework} for {Domain} {Adaptation}},
	volume = {49},
	issn = {2168-2275},
	shorttitle = {Transfer {Independently} {Together}},
	abstract = {Currently, unsupervised heterogeneous domain adaptation in a generalized setting, which is the most common scenario in real-world applications, is under insufficient exploration. Existing approaches either are limited to special cases or require labeled target samples for training. This paper aims to overcome these limitations by proposing a generalized framework, named as transfer independently together (TIT). Specifically, we learn multiple transformations, one for each domain (independently), to map data onto a shared latent space, where the domains are well aligned. The multiple transformations are jointly optimized in a unified framework (together) by an effective formulation. In addition, to learn robust transformations, we further propose a novel landmark selection algorithm to reweight samples, i.e., increase the weight of pivot samples and decrease the weight of outliers. Our landmark selection is based on graph optimization. It focuses on sample geometric relationship rather than sample features. As a result, by abstracting feature vectors to graph vertices, only a simple and fast integer arithmetic is involved in our algorithm instead of matrix operations with float point arithmetic in existing approaches. At last, we effectively optimize our objective via a dimensionality reduction procedure. TIT is applicable to arbitrary sample dimensionality and does not need labeled target samples for training. Extensive evaluations on several standard benchmarks and large-scale datasets of image classification, text categorization and text-to-image recognition verify the superiority of our approach.},
	number = {6},
	journal = {IEEE Transactions on Cybernetics},
	author = {Li, J. and Lu, K. and Huang, Z. and Zhu, L. and Shen, H. T.},
	month = jun,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Cybernetics},
	keywords = {Adaptation models, arbitrary sample dimensionality, Data preprocessing, Dimensionality reduction, Domain adaptation, effective formulation, fast integer arithmetic, feature extraction, feature vectors, float point arithmetic, floating point arithmetic, generalized setting, graph optimization, graph theory, image classification, labeled target samples, landmark selection, landmark selection algorithm, large-scale datasets, map data, matrix algebra, multiple transformations, optimisation, Optimization, pivot samples, real-world applications, robust transformations, sample features, sample geometric relationship, shared latent space, standard benchmarks, Standards, subspace learning, Task analysis, text analysis, text categorization, text-to-image recognition, TIT, Training, transfer learning, unified framework, unsupervised heterogeneous domain adaptation, vectors},
	pages = {2144--2155},
	}
@inproceedings{mcallester1999,
author = {McAllester, David A.},
title = {PAC-Bayesian Model Averaging},
year = {1999},
isbn = {1581131674},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the Twelfth Annual Conference on Computational Learning Theory},
pages = {164–170},
numpages = {7},
location = {Santa Cruz, California, USA},
series = {COLT '99}
}
@article{livni_limitation_2020,
	title = {A {Limitation} of the {PAC}-{Bayes} {Framework}},
	abstract = {PAC-Bayes is a useful framework for deriving generalization bounds which was introduced by McAllester ('98). This framework has the flexibility of deriving distribution- and algorithm-dependent bounds, which are often tighter than VC-related uniform convergence bounds. In this manuscript we present a limitation for the PAC-Bayes framework. We demonstrate an easy learning task that is not amenable to a PAC-Bayes analysis. Specifically, we consider the task of linear classification in 1D; it is well-known that this task is learnable using just \$O({\textbackslash}log(1/{\textbackslash}delta)/{\textbackslash}epsilon)\$ examples. On the other hand, we show that this fact can not be proved using a PAC-Bayes analysis: for any algorithm that learns 1-dimensional linear classifiers there exists a (realizable) distribution for which the PAC-Bayes bound is arbitrarily large.},
	urldate = {2021-02-09},
	journal = {arXiv:2006.13508 [cs, stat]},
	author = {Livni, Roi and Moran, Shay},
	month = dec,
	year = {2020},
	note = {arXiv: 2006.13508},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Added references about similar "failures" of the Minmax in the context of PAC learning with bounded mutual information},
	}

@article{rivasplata_pac-bayes_2020,
	title = {{PAC}-{Bayes} {Analysis} {Beyond} the {Usual} {Bounds}},
	abstract = {We focus on a stochastic learning model where the learner observes a finite set of training examples and the output of the learning process is a data-dependent distribution over a space of hypotheses. The learned data-dependent distribution is then used to make randomized predictions, and the high-level theme addressed here is guaranteeing the quality of predictions on examples that were not seen during training, i.e. generalization. In this setting the unknown quantity of interest is the expected risk of the data-dependent randomized predictor, for which upper bounds can be derived via a PAC-Bayes analysis, leading to PAC-Bayes bounds. Specifically, we present a basic PAC-Bayes inequality for stochastic kernels, from which one may derive extensions of various known PAC-Bayes bounds as well as novel bounds. We clarify the role of the requirements of fixed 'data-free' priors, bounded losses, and i.i.d. data. We highlight that those requirements were used to upper-bound an exponential moment term, while the basic PAC-Bayes theorem remains valid without those restrictions. We present three bounds that illustrate the use of data-dependent priors, including one for the unbounded square loss.},
	urldate = {2021-02-09},
	journal = {arXiv:2006.13057 [cs, stat]},
	author = {Rivasplata, Omar and Kuzborskij, Ilja and Szepesvari, Csaba and Shawe-Taylor, John},
	month = dec,
	year = {2020},
	note = {arXiv: 2006.13057},
	keywords = {Computer Science - Machine Learning, Statistics - Applications, Statistics - Machine Learning},
	annote = {Comment: In NeurIPS 2020. Version 3 is the final published paper. Note that this paper is an enhanced version of the short paper with the same title that was presented at the NeurIPS 2019 Workshop on Machine Learning with Guarantees. Important update: the PAC-Bayes type inequality for unbounded loss functions (Section 2.3) is new},
	}

@misc{noauthor_pdf_nodate-4,
	title = {[{PDF}] {A} {PAC}-{Bayesian} {Tutorial} with {A} {Dropout} {Bound} {\textbar} {Scinapse}},
	urldate = {2021-02-09},
	}

@article{mcallester_pac-bayesian_2013,
	title = {A {PAC}-{Bayesian} {Tutorial} with {A} {Dropout} {Bound}},
	volume = {1307},
	abstract = {This tutorial gives a concise overview of existing PAC-Bayesian theory focusing on three generalization bounds. The first is an Occam bound which handles rules with finite precision parameters and which states that generalization loss is near training loss when the number of bits needed to write the rule is small compared to the sample size. The second is a PAC-Bayesian bound providing a generalization guarantee for posterior distributions rather than for individual rules. The
PAC-Bayesian bound naturally handles infinite precision rule parameters, \$L\_2\$ regularization, \{{\textbackslash}em provides a bound for dropout training\}, and defines a natural notion of a single distinguished PAC-Bayesian
posterior distribution. The third bound is a training-variance bound --- a kind of bias-variance analysis but with bias replaced by expected training loss. The training-variance bound dominates the other bounds but is more difficult to interpret. It seems to suggest variance reduction methods such as bagging and may ultimately provide a more meaningful analysis of dropouts.},
	urldate = {2021-02-09},
	journal = {arXiv e-prints},
	author = {McAllester, David A.},
	month = jul,
	year = {2013},
	keywords = {Computer Science - Machine Learning},
	pages = {arXiv:1307.2118},
	}

@article{mcallester_pac-bayesian_2013-1,
	title = {A {PAC}-{Bayesian} {Tutorial} with {A} {Dropout} {Bound}},
	abstract = {This tutorial gives a concise overview of existing PAC-Bayesian theory focusing on three generalization bounds. The first is an Occam bound which handles rules with finite precision parameters and which states that generalization loss is near training loss when the number of bits needed to write the rule is small compared to the sample size. The second is a PAC-Bayesian bound providing a generalization guarantee for posterior distributions rather than for individual rules. The PAC-Bayesian bound naturally handles infinite precision rule parameters, \$L\_2\$ regularization, \{{\textbackslash}em provides a bound for dropout training\}, and defines a natural notion of a single distinguished PAC-Bayesian posterior distribution. The third bound is a training-variance bound --- a kind of bias-variance analysis but with bias replaced by expected training loss. The training-variance bound dominates the other bounds but is more difficult to interpret. It seems to suggest variance reduction methods such as bagging and may ultimately provide a more meaningful analysis of dropouts.},
	urldate = {2021-02-09},
	journal = {arXiv:1307.2118 [cs]},
	author = {McAllester, David},
	month = jul,
	year = {2013},
	note = {arXiv: 1307.2118},
	keywords = {Computer Science - Machine Learning},
	}
@inproceedings{lacasse2006,
author = {Lacasse, Alexandre and Laviolette, Francois and Marchand, Mario and Germain, Pascal and Usunier, Nicolas},
year = {2006},
month = {01},
pages = {769-776},
title = {PAC-Bayes Bounds for the Risk of the Majority Vote and the Variance of the Gibbs Classifier.},
journal = {Advances in Neural Information Processing Systems}
}
@InProceedings{thiemann17a,
   title =        {A Strongly Quasiconvex PAC-Bayesian Bound},
   author =       {Niklas Thiemann and Christian Igel and Olivier Wintenberger and Yevgeny Seldin},
   booktitle =    {Proceedings of the 28th International Conference on Algorithmic Learning Theory},
   pages =        {466--492},
   year =         {2017},
   editor =       {Steve Hanneke and Lev Reyzin},
   volume =       {76},
   series =       {Proceedings of Machine Learning Research},
   address =      {Kyoto University, Kyoto, Japan},
   month =        {10},
   publisher =    {PMLR},
   pdf =          {http://proceedings.mlr.press/v76/thiemann17a/thiemann17a.pdf},
   url =          {http://proceedings.mlr.press/v76/thiemann17a.html},
   abstract =     {We propose a new PAC-Bayesian bound and a way of constructing a hypothesis space, so that the bound is convex in the posterior distribution and also convex in a trade-off parameter between     empirical performance of the posterior distribution and its complexity. The complexity is measured by the Kullback-Leibler divergence to a prior. We derive an alternating procedure for minimizing the bound    . We show that the bound can be rewritten as a one-dimensional function of the trade-off parameter and provide sufficient conditions under which the function has a single global minimum. When the conditions     are satisfied the alternating minimization is guaranteed to converge to the global minimum of the bound. We provide experimental results demonstrating that rigorous minimization of the bound is competitive     with cross-validation in tuning the trade-off between complexity and empirical performance. In all our experiments the trade-off turned to be quasiconvex even when the sufficient conditions were violated.}
 }
 @article{Shimodaira2000ImprovingPI,
  title={Improving predictive inference under covariate shift by weighting the log-likelihood function},
  author={Hidetoshi Shimodaira},
  journal={Journal of Statistical Planning and Inference},
  year={2000},
  volume={90},
  pages={227-244}
}

 @article{valle2020generalization,
  title={Generalization bounds for deep learning},
  author={Valle-P{\'e}rez, Guillermo and Louis, Ard A},
  journal={arXiv preprint arXiv:2012.04115},
  year={2020}
}
 
@article{catoni2007,
    ISSN = {07492170},
    author = {Olivier Catoni},
    journal = {Lecture Notes-Monograph Series},
    pages = {i--163},
    publisher = {Institute of Mathematical Statistics},
    title = {Pac-Bayesian Supervised Classification: The Thermodynamics of Statistical Learning},
    volume = {56},
    year = {2007}
 }
@inproceedings{mcallester_pac-bayesian_1998,
	address = {New York, NY, USA},
	series = {{COLT}' 98},
	title = {Some {PAC}-{Bayesian} theorems},
	isbn = {978-1-58113-057-7},
	urldate = {2021-02-09},
	booktitle = {Proceedings of the eleventh annual conference on {Computational} learning theory},
	publisher = {Association for Computing Machinery},
	author = {McAllester, David A.},
	month = jul,
	year = {1998},
	pages = {230--234},
	}

@Article{valiant1984,
  author = 	 "L. G. Valiant",
  title = 	 "A theory of the Learnable",
  journal = 	 "Communications of the ACM",
  year = 	 "1984",
  pages = 	 "1134-1142"
}

@inproceedings{mcallester_pac-bayesian_1998-1,
	address = {New York, NY, USA},
	series = {{COLT}' 98},
	title = {Some {PAC}-{Bayesian} {Theorems}},
	isbn = {1-58113-057-0},
	booktitle = {Proceedings of the {Eleventh} {Annual} {Conference} on {Computational} {Learning} {Theory}},
	publisher = {Association for Computing Machinery},
	author = {McAllester, David A.},
	year = {1998},
	note = {event-place: Madison, Wisconsin, USA},
	pages = {230--234}
}

@article{seeger_pac-bayesian_2003,
	title = {Pac-bayesian generalisation error bounds for gaussian process classification},
	issn = {1532-4435},
	abstract = {Approximate Bayesian Gaussian process (GP) classification techniques are powerful non-parametric learning meth {\textbar} Matthias Seeger  {\textbar} Journal of Machine Learning Research {\textbar}},
	language = {en},
	urldate = {2021-02-09},
	journal = {Journal of Machine Learning Research},
	author = {Seeger, Matthias},
	month = mar,
	year = {2003},
	}

@article{seeger_pac-bayesian_2003-1,
	title = {Pac-bayesian generalisation error bounds for gaussian process classification},
	volume = {3},
	issn = {1532-4435},
	abstract = {Approximate Bayesian Gaussian process (GP) classification techniques are powerful non-parametric learning methods, similar in appearance and performance to support vector machines. Based on simple probabilistic models, they render interpretable results and can be embedded in Bayesian frameworks for model selection, feature selection, etc. In this paper, by applying the PAC-Bayesian theorem of McAllester (1999a), we prove distribution-free generalisation error bounds for a wide range of approximate Bayesian GP classification techniques. We also provide a new and much simplified proof for this powerful theorem, making use of the concept of convex duality which is a backbone of many machine learning techniques. We instantiate and test our bounds for two particular GPC techniques, including a recent sparse method which circumvents the unfavourable scaling of standard GP algorithms. As is shown in experiments on a real-world task, the bounds can be very tight for moderate training sample sizes. To the best of our knowledge, these results provide the tightest known distribution-free error bounds for approximate Bayesian GPC methods, giving a strong learning-theoretical justification for the use of these techniques.},
	number = {null},
	urldate = {2021-02-09},
	journal = {The Journal of Machine Learning Research},
	author = {Seeger, Matthias},
	month = mar,
	year = {2003},
	keywords = {Bayesian learning, convex duality, Gaussian processes, generalisation error bounds, Gibbs classifier, Kernel machines, PAC-Bayesian framework, sparse approximations},
	pages = {233--269},
	}