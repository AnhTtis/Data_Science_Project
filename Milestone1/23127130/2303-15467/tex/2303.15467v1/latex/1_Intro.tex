\section{Introduction}
\label{sec:intro}

Deep learning methods for video action recognition have developed very fast and achieved remarkable performance in recent years~\cite{lin2019tsm, feichtenhofer2019slowfast, i3d, yang2020temporal}. 
%
\begin{figure}[t]
    \centering
    \includegraphics[width=0.99\linewidth]{docu/figs/fig_1_f.pdf}
    \vspace{-0.5cm}
    \caption{(a) Richer semantic features brought by the pretraining can significantly improve the open-set performance. (b) Information in the feature is divided into IS and CS information. $s_4$ can be identified as OoD since it has distinct IS information (IS bars in different colors) with $s_1$ and $s_2$, while $s_5$ has distinct CS information (CS bars in different colors) with all InD samples so it may be OoD. Our PSL aims to learn more IS and CS information (bars in longer lengths) than Cross-Entropy (C.E.). (c) Both enlarged IS and CS information boosts the open-set performance. (d) Our PSL achieves the best OSAR performance.}
    \label{fig:1}
\end{figure}
However, these methods operate under the \emph{closed-set} condition, \textit{i.e.}, to classify all videos into one of the classes encountered during training. This closed-set condition is not practical in the real-world scenario, as videos whose classes are beyond the range of the training set will be misclassified as one of the known classes. 
Therefore, \emph{open-set action recognition} (OSAR) is proposed to require the network to correctly classify in-distribution (InD) samples and identify out-of-distribution (OoD) samples. InD and OoD classes refer to classes involved and not involved in the training set, respectively.

Open-set video action recognition is systematically studied in the recent work~\cite{bao2021evidential}, in which they transfer the existing methods for open-set image recognition into the video domain~\cite{hendrycks2016baseline,gal2016dropout,bendale2016towards,kendall2017uncertainties} as the baselines, and propose their own method to introduce deep evidential learning~\cite{amini2020deep} to calculate the uncertainty and propose a contrastive evidential debiasing module to alleviate the appearance bias issue in the video domain. All of these methods tend to improve the OSAR performance by calculating a better uncertainty score, based on the feature representations extracted by the neural network (NN). However, the main purpose of training in these methods is still to classify InD samples, which determines the learned feature representations are merely sufficient for InD classification. We find that almost all methods have a significantly better open-set performance when the NN is pretrained with a large dataset (\cref{fig:1} (a)), so we argue that the diversity of feature representation is extremely important for the OSAR task. Therefore, we propose to boost the open-set ability from the feature representation perspective rather than finding a better uncertainty score.

We first analyze the feature representation behavior in the open-set problem based on the information bottleneck (IB) theory~\cite{tishby2015deep,wang2022rethinking}. We divide the information of the feature into \emph{Instance-Specific (IS)}
and \emph{Class-Specific (CS) information}. CS information is used for inter-class recognition, so it is similar for samples within the same class but different for samples from other classes. IS information is the special information of each sample within the same class, as two samples cannot be exactly the same even if they belong to the same class. Both CS and IS information are crucial for the open-set task, as illustrated in \cref{fig:1} (b), where $s_4$ and $s_5$ can be identified as OoD samples based on the IS and CS information, respectively. We find that the closed-set classification setting tends to eliminate IS information during training, and cannot fully extract the minimum sufficient CS information for the classification task, so we aim to enlarge IS and CS information in learned feature representations for better OSAR performance.

To enlarge the IS information, we propose the \emph{Prototypical Similarity Learning} (PSL) framework, in which the representation of an instance is encouraged to have less than 1 similarity with the corresponding prototype. In this way, we encourage the IS information to be retained and not eliminated. In addition, \cite{bao2021evidential} finds that OoD videos can be easily classified as InD videos in a similar appearance. To alleviate this issue, we introduce the shuffled video into PSL and make it have less than 1 similarity with the original sample. As the shuffled video almost shares the same appearance information with the original one, we encourage the similarity to be less than 1 so that the network can extract the distinct temporal information among them. We find this technique actually enlarges the CS information in the feature representation. \cref{fig:1} (c) shows that enlarging the IS information is helpful for the open-set performance, and more CS information can further benefit the open-set and closed-set performance. 
To summarize, our contributions include:
\begin{itemize}[leftmargin=*, itemsep=0 pt, topsep=0 pt, parsep=0 pt]
    \item We provide a novel perspective to analyze the open-set recognition task based on the information bottleneck theory, and find that the classical closed-set cross-entropy tends to eliminate the IS information which is helpful to identify OoD samples.
    \item We propose to enlarge the IS and CS information for better OSAR performance. Specifically, PSL is designed to retain the IS information in the features, and we involve video shuffling in PSL to learn more CS information. 
    \item Experiments on multiple datasets and backbones show our PSLâ€™s superiority over a large margin compared to other state-of-the-art counterparts, as shown in \cref{fig:1} (d).
\end{itemize}