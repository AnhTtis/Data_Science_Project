{
    "arxiv_id": "2303.13340",
    "paper_title": "Increasing Textual Context Size Boosts Medical Image-Text Matching",
    "authors": [
        "Idan Glassberg",
        "Tom Hope"
    ],
    "submission_date": "2023-03-23",
    "revised_dates": [
        "2023-03-24"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "cs.CV"
    ],
    "abstract": "This short technical report demonstrates a simple technique that yields state of the art results in medical image-text matching tasks. We analyze the use of OpenAI's CLIP, a general image-text matching model, and observe that CLIP's limited textual input size has negative impact on downstream performance in the medical domain where encoding longer textual contexts is often required. We thus train and release ClipMD, which is trained with a simple sliding window technique to encode textual captions. ClipMD was tested on two medical image-text datasets and compared with other image-text matching models. The results show that ClipMD outperforms other models on both datasets by a large margin. We make our code and pretrained model publicly available.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13340v1"
    ],
    "publication_venue": null
}