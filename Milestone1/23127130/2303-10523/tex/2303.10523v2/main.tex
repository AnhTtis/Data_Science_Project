\documentclass[journal]{IEEEtai}

\usepackage[colorlinks,urlcolor=blue,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{color,array}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} %
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{relsize}
\usepackage{caption}
\usepackage{bbm}
\usepackage{hyperref}
\usepackage{changes}
\setcounter{page}{1}

\input{defs}

\begin{document}

\title{Unsupervised Interpretable Basis Extraction for Concept -- Based Visual Explanations} 

\author{Alexandros Doumanoglou, Stylianos Asteriadis, and Dimitrios Zarpalas
\thanks{A. Doumanoglou is with the Information Technologies Institute (ITI), Centre for Research and Technology HELLAS (CERTH), Thessaloniki, Greece and the Department of Advanced Computing Sciences, University of Maastricht, Maastricht, Netherlands (e-mail: aldoum@iti.gr).}
\thanks{S. Asteriadis is with the Department of Advanced Computing Sciences, University of Maastricht, Maastricht, Netherlands (e-mail: stelios.asteriadis@maastrichtuniversity.nl)..}
\thanks{D. Zarpalas is with the Information Technologies Institute (ITI), Centre for Research and Technology HELLAS (CERTH), Thessaloniki, Greece (e-mail: zarpalas@iti.gr).}
}

\markboth{}
{A. Doumanoglou \MakeLowercase{\textit{et al.}}: UIBE}

\maketitle
\begin{abstract}
An important line of research attempts to explain CNN image classifier predictions and intermediate layer representations in terms of human understandable concepts. In this work, we expand on previous works in the literature that use annotated concept datasets to extract interpretable feature space directions and propose an unsupervised post-hoc method to extract a disentangling interpretable basis by looking for the rotation of the feature space that explains sparse one-hot thresholded transformed representations of pixel activations. We do experimentation with existing popular CNNs and demonstrate the effectiveness of our method in extracting an interpretable basis across network architectures and training datasets. We make extensions to the existing basis interpretability metrics found in the literature and show that, intermediate layer representations become more interpretable when transformed to the bases extracted with our method. Finally, using the basis interpretability metrics, we compare the bases extracted with our method with the bases derived with a supervised approach and find that, in one aspect, the proposed unsupervised approach has a strength that constitutes a limitation of the supervised one and give potential directions for future research.
\end{abstract}

\begin{IEEEImpStatement}
CNN image classifiers have demonstrated outstanding performance in real-world tasks. They can be used in robotics, visual understanding, automatic risk assessment and more. However, to a human expert, CNNs are often black-boxes and the reasoning behind their predictions can be unclear.  Recent advances in explainable and interpretable artificial intelligence (XAI and IAI), attempt to shed light on this process. In an attempt to understand intermediate layer representations, one can project them onto a feature space basis that quantifies the presence of different concepts in the representation. This basis is called interpretable because it can make representations more understandable. In the typical approach, constructing an interpretable basis requires access to annotations. This work proposes a novel unsupervised method to learn such a basis, without the need for explicit labels. This can ease the process of obtaining explanations, eliminate annotation costs, save time, and eventually help humans debug and trust deep models.

\end{IEEEImpStatement}

\begin{IEEEkeywords}
Explainable Artificial Intelligence (XAI), Interpretable Artificial Intelligence (IAI), Interpretable Basis, Unsupervised Learning.
\end{IEEEkeywords}

\vspace{5cm}
\section{Introduction}
\label{sec:introduction}
\input{sections/introduction}

\section{Background \& Related Work}
\label{sec:related_work}
\input{sections/related_work}

\section{Motivation}
\label{sec:motivation}
\input{sections/motivation}

\section{Proposed Method}
\label{sec:proposed_method}
\input{sections/proposed_method}

\section{Basis orthogonality}
\label{sec:orthogonality}
\input{sections/orthogonality}

\section{Evaluation Metrics}
\label{sec:evaluation_metrics}
\input{sections/evaluation_metrics}

\section{Experimental Results}
\label{sec:experimental_results}
\input{sections/experimental_results}
\vspace{-7pt}
\section{Conclusion}
\label{sec:conclsion}
\input{sections/conclusion}

\input{sections/qualitative}




\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,refs.bib}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photos/alex.jpg}}]{Alexandros Doumanoglou}{\space} has received the diploma of Electrical and Computer Engineer from the Aristotle University of Thessaloniki (A.U.Th) and is currently doing his PhD in Explainable and Interpretable Artificial Intelligence at the department of Advanced Computing Sciences at Maastricht University, under the supervision of Prof. Stylianos Asteriadis.

    He joined the Information Technologies Institute in 2012 and since then he is working as a research assistant in the fields of computer vision, 3d graphics and machine learning. His research interests includes real-time 3D computer vision, 3D reconstruction, real-time 3D content streaming, camera pose estimation and 3D mesh compression. His current research focus is on unsupervised learning, and explainable and interpretable methods for deep learning models.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photos/stelios.png}}]{Stylianos Asteriadis}{\space} has received the diploma of Electrical and Computer Engineer from the Aristotle University of Thessaloniki (A.U.Th), an MSc in Digital Media from School of Informatics of the same University and a PhD in Electrical and Computer Engineering from the National Technical University of Athens (NTUA).

    He is an Associate Professor at the Department of Advanced Computing Sciences at Maastricht University in the Netherlands. He is conducting research in ambient assisted living and automated human emotion recognition, with particular focus on in-the-wild applications, making use of various sensorial cues and deep learning. He is currently the coordinator of the Cognitive Systems Research Group at the University of Maastricht, and teaches the courses of Human-Computer Interaction and Affective Computing, Artificial Intelligence, and Computer Vision.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photos/dimitris.jpg}}]{Dimitrios Zarpalas}{\space} holds the diploma of Electrical and Computer Engineer from Aristotle University of Thessaloniki, A.U.Th, an MSc in Electrical Engineering (focusing on computer vision) from The Pennsylvania State University, and a PhD in medical informatics (Health Science School, department of Medicine, A.U.Th).

   He has joined the Information Technologies Institute in 2007, and is currently a researcher, grade C. His research interests include real time tele-immersion applications (3D reconstruction of moving
   humans and their compression), 3D computer vision, 3D medical image processing, shape analysis of anatomical structures, 3D object recognition, motion capturing and evaluation, while in the past has also worked in indexing, search and retrieval, classification of 3D objects and 3D model watermarking.
\end{IEEEbiography}

\end{document}
