\subsection{Basis labeling and classifier validation scores}
To quantitatively evaluate for interpretability the bases extracted with our method, we use a two step process. First, after deriving a basis, we use %
the work of Bau at al. \cite{bau_NetDissection_CVPR, zhou_NetDissection_PAMI}, to assign a concept label to each classifier associated with the basis vectors. Let $\phi(i,c,\K) \in [0,1]$ denote a metric score function that is used to measure the \textit{suitability} of the classifier $i$ ($\{\w_i,b_i\}$) to accurately detect concept $c$ in the annotated concept dataset $\K$. The concept label that is assigned to classifier $i$ is the one that maximizes $\phi(i,c,\Ktr)$ across $c$ over the training split $\Ktr$ of the concept dataset. Subsequently, in the second step, and using the validation split of the concept dataset $\Kvl$, each classifier is assigned a validation score $\phi(i,\cstar_i,\Kvl)$, with $\cstar_i$ denoting the concept label assigned to the classifier during the first step.  For the choice of $\phi$ we use Intersection Over Union (IoU), as originally proposed in \cite{bau_NetDissection_CVPR} and also used in \cite{mu2020compositional,fong_Net2Vec}:
\begin{equation}
    \phi(i,c,\K) = \frac{\sum_{\k \in \K} |\M^i(\k) \cap \L^c(\k)|}{\sum_{\k \in \K} |\M^i(\k)\cup \L^c(\k)|}
    \label{eq:iou}
\end{equation}
In (\ref{eq:iou}), $\M^i(\k)$ denotes the upsampled, hard-thresholded (binarized) map of image $\k$. $\M^i(\k)$ is obtained by applying the rule of the $i$-th classifier ($\wi^T\xp - b_i > 0)$ to each $\xp$ of the upsampled image's representation. Moreover, $\L^c(\k)$ denotes the ground truth segmentation map of image $\k$ for concept $c$ and $|\cdot|$ denotes the cardinality of a set. %
Overall, to label the bases and compute classifier validation scores, we use the exact scheme of \cite{bau_NetDissection_CVPR} with two differences. First, we consider a train/test split of the concept dataset as originally proposed in \cite{fong_Net2Vec} and second, for hard-thresholding in $\M^i(\k)$, we use the biases learned from our method, instead of using the statistical quantile learning of \cite{bau_NetDissection_CVPR}.

\subsection{Overall basis interpretability scores}
Inspired from \cite{bau_NetDissection_CVPR} and \cite{Losch_Fritz_Schiele_2021} we propose two metrics $\Score1$ and $\Score2$ that can be used to measure the interpretability of a basis. Those metrics, essentially aggregate the aforementioned individual classifier validation scores into scalar values that can summarize the interpretability of a basis. 

The first, counts the number of concept detectors in the basis with a validation score better than a threshold $\xi$. In order to make it threshold agnostic, we measure the area under the indicator function ($\mathbbm{1}(x)$) for all $\xi \in [0,1]$:
\begin{equation}
\label{eq:score1}
\Score{1} = \int_{0}^{1} \sum_{i=0}^{I-1} \mathbbm{1}_{x\ge \xi}\big(\phi(i,c^*_i,\Kvl)\big)d\xi
\end{equation}
\noindent This metric is similar to what was proposed in \cite{Losch_Fritz_Schiele_2021} with two differences. First, we use IoU as the choice of $\phi$ in order to comply with our intention to use \cite{bau_NetDissection_CVPR} for labeling the basis. And second, unlike \cite{Losch_Fritz_Schiele_2021},  we do not normalize (\ref{eq:score1}) with the number of vectors in the basis, in order to be able to make absolute comparisons between scores for bases of different sizes. 

The second metric, counts the number of unique concept labels over the set of labels whose respective concept detectors exhibit performance better than $\xi$. This metric is the same as the one proposed in \cite{bau_NetDissection_CVPR}. Inspired by \cite{Losch_Fritz_Schiele_2021}, and with the intention to also make it agnostic to the threshold $\xi$, we use the area under curve:
\begin{equation}
\label{eq:score2}
\Score{2} = \int_{0}^{1} \psi(\xi)d\xi
\end{equation}
with $\psi(\xi) = |\{\cstar_i \,| \, \exists \, i: \phi(i,\cstar,\Kvl) \ge \xi\}|$, i.e. the number of unique concept detectors exhibiting performance better than $\xi$.







