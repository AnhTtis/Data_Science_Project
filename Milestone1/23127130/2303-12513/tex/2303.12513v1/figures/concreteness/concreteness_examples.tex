\begin{figure}[t]
        \centering
        \begin{subfigure}[t]{.245\linewidth}
            \centering
            \begin{tabular}{c}
\begin{lstlisting}
snowman
liar
lettuce 
mailman
couch
\end{lstlisting}
             \end{tabular}
             \caption*{BERT}
        \end{subfigure}%
        \begin{subfigure}[t]{.245\linewidth}
            \centering
            \begin{tabular}{c}
\begin{lstlisting}
sink
bench
chalk
splinter
pinecone
\end{lstlisting}
\end{tabular}
\caption*{CLIP}
\end{subfigure} 
\begin{subfigure}[t]{.245\linewidth}
            \centering
            \begin{tabular}{c}
\begin{lstlisting}
seed
jelly
cash
lightning
pudding
\end{lstlisting}
\end{tabular}
\caption*{BERT}
\end{subfigure}%
\begin{subfigure}[t]{.245\linewidth}
\centering
\begin{tabular}{c}
\begin{lstlisting}
friend 
story
name
thanks
fun
\end{lstlisting}
\end{tabular}
\caption*{CLIP}
\end{subfigure}
    \textbf{Most \emph{concrete}} \hspace{48pt} \textbf{Most \emph{abstract} }
\caption{Basic nouns selected as most (and least) concrete using BERT-base and CLIP, according the method described in Section \ref{sec:concreteness}. As these illustrate, concreteness can be reasonably predicted from CLIP text embeddings, whereas this knowledge is not readily accessible for the unimodally trained text encoders.}
\label{fig:concreteness_examples}
\end{figure}



