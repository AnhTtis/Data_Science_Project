\begin{table}[t]
  \centering
  \setlength{\tabcolsep}{3.2pt}
  \def\arraystretch{0.95}
  \begin{tabularx}{0.52\columnwidth}{lll}
    \toprule
    Model             &   & AUC (95\% CI)          \\
    \midrule
    BERT          &   & 0.789 $\pm$ 0.0007 \\
    RoBERTa       &   & 0.799 $\pm$ 0.0005 \\
    ERNIE         &   & 0.766 $\pm$ 0.0006 \\
    CLIP              &   &\textbf{0.822 $\pm$ 0.0007}          \\
    \bottomrule
  \end{tabularx}
  \vspace{3pt}
  \caption{\textbf{Groundability Classification Evaluation}. We report ROC-AUC with 95\% bootstrap confidence intervals scores for a manually assembled test set comparing linear probing for text based encoders and V\&L CLIP model. As shown above, CLIP significantly outperforms the unimodally trained models.}
\label{tab:groundabilityresults}
\end{table}
