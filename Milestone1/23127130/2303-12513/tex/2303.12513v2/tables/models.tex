\begin{table*}[t]
  \centering
  \setlength{\tabcolsep}{3.2pt}
  \def\arraystretch{0.90}
  \begin{tabularx}{\textwidth}{llllclccc}
    \toprule
    Model family    & Size   & Pretraining  & Params    &  MLM head? & Checkpoint \\
    \midrule
    BERT~\cite{devlin2018bert}            & base  & text    & 110M   & Y       & \texttt{bert-base-uncased}    \\
    BERT~\cite{devlin2018bert}            & large & text    & 340M   &  Y      & \texttt{bert-large-uncased}   \\
    RoBERTa~\cite{liu2019roberta}         & base  & text    & 124M   &  Y      & \texttt{roberta-base}         \\
    RoBERTa~\cite{liu2019roberta}         & large & text    & 355M   &  Y      & \texttt{roberta-large}     \\
    ERNIEv2~\cite{sun2019ernie,sun2020ernie}           & base  & text  & 109M   &  \hspace{5px}Y$^*$       &  \texttt{ernie-2.0-base-en}   \\
    ERNIEv2~\cite{sun2019ernie,sun2020ernie}           & large & text  & 335M   &  \hspace{5px}Y$^*$       &  \texttt{ernie-2.0-large-en}   \\
    DistilBERT~\cite{sanh2019distilbert}               & base  & text  & 66M    &  Y       &  \texttt{distilbert-base-uncased} \\
    DistilRoBERTa~\cite{sanh2019distilbert}            & base  & text  & 82M    &  Y       &  \texttt{distilroberta-base} \\
    SBERT~\cite{reimers2019sentence}                   & --    & text  & 23M  &  N         &  \texttt{paraphrase-MiniLM-L6-v2} \\
    FLAVA~\cite{singh2022flava}                        & --    & text \& VLP  & 109M    &  Y        &  \texttt{facebook/flava-full}  \\
    CLIP~\cite{radford2021learning}                    & --    & VLP  & 63M    &  N        &  \texttt{openai/clip-vit-base-patch32}  \\
    OpenCLIP~\cite{ilharco_gabriel_2021_5143773}       & --    & VLP  & 352M    &  N        &  \texttt{laion/CLIP-ViT-H-14-laion2B-s32B-b79K}  \\
    \bottomrule
  \end{tabularx}
  \vspace{3pt}
  \caption{\textbf{Models table}. Note that the number of parameters listed for CLIP, OpenCLIP and FLAVA refers to their text encoder components alone. $^*$ Note: ERNIE was trained with an MLM head, but because the public checkpoints provided do not include this, we do not evaluate it with MLM probing.}
\label{tab:models}
\end{table*}