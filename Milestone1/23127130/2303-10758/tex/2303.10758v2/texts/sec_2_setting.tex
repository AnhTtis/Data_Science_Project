\section{Preliminaries} \label{sec: setting}
Following ... , We study the generalization error of \emph{stochastic convex optimization (SCO)} problem. We receive a dataset of finite samples $S = \{z_1, \dots, z_n\}$, where each $z_i$ is i.i.d. drawn from an unknown distribution $D$ over sample space $\cZ$ and $n$ is the size of dataset.  Our goal is to find a model parameterized by $w \in \cW \subseteq \bbR^d$ that minimizes the \emph{population} (or expected) risk over $D$, defined as:
\begin{equation}
    F(w) = \bbE_{z \sim D}[f(w,z)]
\end{equation}
where $f(w, z): \bbR^d \times \cZ \to \bbR$ is the loss function evaluated on a single example $z \in \cZ$.

Since the population loss $F$ is typically inaccessible, we instead employ an averaged substitute on sample $S$, known as the \emph{empirical} risk:
\begin{equation}
    F_S(w) = \frac{1}{n} \sum_{i=1}^n f(w,z_i), \qquad S \sim D^n.
\end{equation}

Given dataset $S$ and any (stochastic) algorithm $\cA$, we denote $\cA[S]$ as the output of running $\cA$ on the training sample $S$. In this paper, we are interested in bounding the \emph{excess population risk} of $\cA[S]$:
\begin{equation*}
    \bbE_{S,\cA}[F(\cA[S])] - \min_{w \in \cW} F(w),
\end{equation*}
where the expectation is taken over the randomness of sample $S$ and algorithm $\cA$.

\subsection{Gradient Methods}
In this work, we focus on understanding the excess risk for two simplified algorithms: Gradient Descent (GD) and Stochastic Gradient Descent (SGD). Gradient descent is one of the most well-known optimization methods. At iteration $t$, GD employs the following recurrence:
\begin{equation} \label{eq: gd}
    w_{t+1} = w_t - \eta \nabla F_S(w_t),  
\end{equation}
where $\eta > 0$ is the step-size and $\nabla F_S(w)$ is the average stochastic gradient on sample set $S$. We usually employ the time average $w_{\gd} := \bar{w}_T = \frac{1}{T} \sum_{t=1}^T w_t$ as the output of GD.  

In practice, many practitioners favor the Stochastic Gradient Descent (SGD) method over GD for its computational efficiency. In this work, we study standard SGD, i.e., in iteration $t \in [T]$,
\begin{equation} \label{eq: sgd}
    w_{t+1} = w_t - \eta \nabla f(w_t,z_{i_t}), 
\end{equation}
where $z_{i_t}$ is uniformly sampled from $S$ \emph{with replacement} as $i_t \sim \text{Unif}([n])$. 
%We will keep the convention and use SGD to denote the with-replacement version throughout the paper. 
The output for SGD is the average $w_{\sgd} := \bar{w}_T = \frac{1}{T} \sum_{t=1}^T w_t$.  

\subsection{Smooth Stochastic Convex  Optimization}
In order to derive non-vacuous bounds on the excess risk for SCO, we make assumptions on the properties of $f(w, z)$. First, we assume the access to the value $f(w,z)$ and the unbiased stochastic gradient estimator $\nabla f(w, z)$ for any $w \in \cW$ and $z \in \cZ$. 

When the function is nonsmooth, this problem has been extensively studied \citep{bassily2020stability}, and known rates were proven to be optimal \citep{amir2021sgd,sekhari2021sgd,nemirovskij1983problem}.
However, less is known when the function is differentiable and smooth. Indeed, while upper bounds have been well-established in literature \citep{hardt2016train,lei2020fine,nikolakakis2022beyond}, the optimality of these results are yet to be certified by corresponding lower bounds. In this work, we aim to provide lower bounds for the smooth SCO setting and make the following assumptions.
%\begin{definition} \label{def: lipschitz}
%$f(w, z)$ has $G$-Lipschitz gradient if for any $w$, it holds $\| \nabla f(w, z) \| \leq G$ and $z \in \cZ$.
%\end{definition}

\begin{definition} \label{def: smooth}
$f(w, z)$ is $L$-smooth if it satisfies $\| \nabla f(w_1, z) - \nabla f(w_2, z) \| \leq L \| w_1 - w_2 \|$ for any $w_1, w_2$ and $z \in \cZ$.
\end{definition}

%\begin{definition} \label{def: bounded}
%Each $f(w, z)$ is $L$-smooth, i.e. $\| \nabla f(w_1, z) - \nabla f(w_2, z) \| \leq L \| w_1 - w_2 \|$ for any $w_1, w_2$.
%\end{definition}

\begin{definition} \label{def: convex}
$f(w, z)$ is convex if it satisfies $f(w_1, z) \geq f(w_2, z) + \langle w_1 - w_2, \nabla f(w_2, z)\rangle$ for any $w_1, w_2$ and $z \in \cZ$.
\end{definition}

\begin{table}[t]
\centering
\begin{threeparttable}
\begin{tabular}{ M{0.4cm} M{2.3cm}  M{3.5cm}  M{2.8cm} M{2.1cm} M{2.0cm}  }
\toprule
& & & & \\[-0.3cm]
& & GD & SGD & Best Sample Complexity & Overfitting for large $\eta T$\\[0.1cm] 
 \midrule 
& & & & \\[-0.2cm]
\multirow{4}{*}{\begin{sideways}Non-realizable\end{sideways}}
%\multirow{4}{*}{\begin{sideways}\ \end{sideways}}
\multirow{4}{*}{%\begin{sideways}(Any $T$) $\quad$ \end{sideways}
}
& Upper bound & \thead{{\normalsize	 $\bigO{\frac{1}{\eta T} + \frac{\eta T}{n} }$} \\{\footnotesize\citep{hardt2016train}}}  & \thead{{\normalsize	 $\bigO{\frac{1}{\eta T} + \frac{\eta T}{n} }$} \\{\footnotesize\citep{hardt2016train}}} & $\bigO{1/\sqrt{n}}$ & Yes  \\[0.3cm]
& & & & \\[-0.1cm]
& Lower bound & \thead{{\normalsize	 $\bigOmega{\frac{1}{\eta T} + \frac{\eta T}{n} }$} \\ {(\footnotesize Theorem.~\ref{thm: lb-sco-gd})}} & \thead{{\normalsize	 $\bigOmega{\frac{1}{\eta T} + \frac{\eta T}{n} }$} \\{(\footnotesize Theorem.~\ref{thm: lb-sco-sgd})}} & $\bigOmega{1/\sqrt{n}}$ & Yes \\[0.4cm]
\midrule 

& & & & \\[-0.2cm]
\multirow{7}{*}{\begin{sideways}Realizable \end{sideways}}
\multirow{7}{*}{%\begin{sideways}\ \end{sideways}
}
\multirow{7}{*}{%\begin{sideways}$\quad $($T = \bigO{n}$) \end{sideways}
}
& Upper bound  & $\bigO{\frac{1}{\eta T} + \frac{1}{n} + \frac{\eta T}{n^2} }$\tnote{$\dag$}  {\footnotesize \citep{nikolakakis2022beyond}} & $\bigO{\frac{1}{\eta T} + \frac{\eta}{n} + \frac{\eta T}{n^2} }$ {\footnotesize	 \citep{lei2020fine}} & $\bigO{1/n}$ & Yes \\[0.3cm]
& & & & \\[-0.1cm]
& Lower bound ($\eta T = O(n)$) & $\bigOmega{\frac{1}{\eta T} + \frac{1}{n} + \frac{\eta T}{n^2}}$ {(\footnotesize Theorem.~\ref{thm: lb-1})} & $\bigOmega{\frac{1}{\eta T} + \frac{1}{n} + \frac{\eta T}{n^2}}$ {(\footnotesize Theorem.~\ref{thm: lb-1})} & $\bigOmega{1/n}$ & N.A.\\[0.4cm] %\cmidrule{2-5}
%\midrule 

%& & & & \\[-0.2cm]
%\multirow{4}{*}{\begin{sideways}Realizable \end{sideways}}
%\multirow{4}{*}{%\begin{sideways}\ \end{sideways}
%}
%\multirow{4}{*}{%\begin{sideways}$\ $($T = \bigOmega{n}$) \end{sideways}
%}
% & & & & \\[-0.2cm]
%& Upper bound   &  $\bigO{\frac{1}{\eta T} + \frac{1}{n} + \frac{\eta T}{n^2} }$\tnote{$\dag$}  {\footnotesize \citep{nikolakakis2022beyond}} & $\bigO{\frac{1}{\eta T} + \frac{\eta}{n} + \frac{\eta T}{n^2} }$ {\footnotesize	 \citep{lei2020fine}} & $\bigO{1/n}$ & $\Theta(n)$  \\[0.3cm] 
 & & & & \\[-0.1cm]
& Lower bound ($\eta T = \Omega(n)$) & $\bigOmega{\frac{1}{\eta T} + \frac{1}{n}}$ {(\footnotesize Theorem.~\ref{thm: lb-2})} & $\bigOmega{\frac{1}{\eta T} + \frac{1}{n} }$ {(\footnotesize Theorem.~\ref{thm: lb-2})} & $\bigOmega{1/n}$ & No \\[0.4cm] 
\bottomrule
\end{tabular}
\caption{\small Summary of our results. We present our lower bounds and compare with existing upper bounds. In particular, we split to three setting: non-realizable, realizable under $\eta T = \bigO{n}$ and realizable under $\eta T = \bigOmega{n}$. For each setting, we provide lower bounds for the excess risk of GD, SGD. We also provide the best possible sample complexity and whether overfitting happens when $\eta T$ is large.}
\label{tab: summary}
\begin{tablenotes}
\item[$\dag$] The bound in $\eta, T$ and $n$ is not explicitly stated in \citet{nikolakakis2022beyond}. For the expression, please refer to a derivation in Appendix~\ref{appendix: gd-ub}.
\end{tablenotes}
\end{threeparttable}
\vspace{-0.3cm}
\end{table}

\paragraph{Realizable smooth SCO.}
The smooth SCO problem can be divided into two cases depending whether the optimal solution minimizes all data points simultaneously. When this happens, it is usually referred as a \emph{realizable} setting, formally defined below. %this A SCO problem is said to be realizable if there exists a solution that simultaneously minimizes over all the instance loss function $f(w,z)$ for any $z \in \cZ$. 
% We give the formal definition below.
\begin{definition} \label{def: realizable}
We say that $f(w, z)$, $z \in \cZ$ formalizes a realizable setting if for any $z \in \cZ$ $$f(w^*, z) = \min_{w} f(w, z), \quad \text{where} \quad w^* = \argmin_{w}F(w).$$
\end{definition}
If $f(w,z)$ is smooth, convex, and realizable, we refer the setting as the \emph{realizable} smooth SCO. The realizable condition implies immediately the property called \emph{weak growth condition}, which is stated in the following lemma.
\begin{lemma} \label{lemma: growth-condition} If $f(w, z), z \in \cZ$ is realizable and $L$-smooth, then for any $w, z \in \cZ$ it holds 
    \begin{equation*}
        \| \nabla f(w, z) \|^2 \leq 2L \left( f(w, z)  - f(w^*, z)\right).
    \end{equation*}
\end{lemma}
The growth condition connects the rates at which the stochastic gradients shrink relative to its value. It is widely employed in stochastic optimization literature to improve the convergence rate of SGD and GD under overparameterized or realizable setting \citep{vaswani2019fast}. Recent papers \citep{lei2020fine,schliserman2022stability,nikolakakis2022beyond} focused on the generalization bound under realizable smooth SCO also suggest that such an assumption improves the sample complexity upper bounds.

\paragraph{Non-realizable smooth SCO.} 
We say a convex learning problem is non-realizable if it does not satisfy the condition in Definition~\ref{def: realizable}. In this setting, known upper bounds for sample complexity actually yield a slower convergence rate at $\bigO{1/\sqrt{n}}$~\citep{hardt2016train} when we set $\eta T = \Theta(\sqrt{n})$, which suggests that longer training leads to overfit.

Next, we discuss our main results in the settings introduced above, and explain why a gap exists for the realizable setting when $\eta T$ is large.

\section{Overview of Results: Training Horizon $\eta T$ and Overfitting}
In this section, we present and discuss our main result on generalization lower bounds. Also, we give a comparison with existing upper bounds. 

Before proceeding to our lower bounds, we motivate the study of the role of the training horizon $\eta T$. Intuitively, compared with the number of iterations $T$, the product of the step-size $\eta$ and $T$ provides a more accurate measure of the intensity of the training process. This is because an arbitrarily small step-size with a large $T$ does not necessarily decrease the optimization error to convergence. Moreover, the importance of $\eta T$ is showcased by existing generalization upper bounds for SGD: \citet{lei2020fine} established the first excess risk upper bound for SGD under realizable smooth SCO:
\begin{equation} \label{eq: ub-sgd-tn}
     \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\eta}{n} + \frac{\eta T}{n^2}}.
\end{equation}
The upper bound suggests the generalization error will first decrease and then increase when training horizon $\eta T$ becomes large. Compared with the non-realizable case, a fast rate $O(1/n)$ of sample complexity can be obtained only if training horizon satisfies $\eta T = O(n)$. Otherwise, if $\eta T$ is sufficiently large, say $\eta T = n^2$, overfitting will happen and the generalization error becomes $O(1)$. This similar to the overfitting behavior of non-realizable upper bound  $\bigO{\tfrac{1}{\eta T} + \tfrac{\eta T}{n} }$.

These upper bound results differ from the empirical observation that often longer training helps generalization. To bridge the gap between theory and practice, in this work, we analyze the relationship between overfitting, generalization error and training horizon $\eta T$ from a \emph{lower bound} perspective. Our lower bound construction indicates the generalization error has different regimes depending on the horizon $\eta T$: when $\eta T = O(n)$, the lower bound for SGD is (per Theorem~\ref{thm: lb-1})
\begin{equation}
     \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigOmega{\frac{1}{\eta T} + \frac{1}{n} + \frac{\eta T}{n^2}},
\end{equation}
whereas when $\eta T = \Omega(n)$, we have (per Theorem~\ref{thm: lb-2})
\begin{equation}
     \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigOmega{\frac{1}{\eta T} + \frac{1}{n}}.
\end{equation}
Our lower bound result suggests overfitting will \emph{not} happen, and the sample complexity $\Omega(1/n)$ can be achieved even when the training horizon $\eta T$ is sufficiently large. This is in contrast with the existing upper bounds, nevertheless, corresponds to the empirical results. To bridge the gap, we conjecture that the upper bound can be improved under the setting $\eta T = \Omega(n)$, and provide evidences in Section~\ref{sec: infinite}. Similar conclusion also applies to GD.

%The analysis presented in the previous section also applies to the generalization error of GD under the realizable setting. 
Moreover, in this work, we provide novel results on the lower bounds of both GD and SGD in the non-realizable setting, which to the best of our knowledge have not been previously reported. Specifically, these non-realizable lower bounds tightly match the existing upper bounds, which suggests that overfitting always occurs when the training horizon $\eta T$ is sufficiently large under the non-realizable condition. We report our lower bound results and compare them with the corresponding upper bounds in Table~\ref{tab: summary}. To give a sense of the role of realizable condition in improving generalization, we include the best possible sample complexity under each setting. Additionally, to illustrate the role of $\eta T$, we indicate whether overfitting will occur as $\eta T$ tends to infinity.
%Although upper bounds for non-realizable and realizable problems differ, they share one thing in common, that the excess risk first decreases and then grows with the number of iterations. Based on this, we classify the bounds into two categories according to their assumptions on the number of iterations $T$ as below. Specially, we use the product $\eta T$ instead of $T$ to measure how long the training actually process lasts, since a large $T$ with a sufficiently small step-size $\eta$ does not even decrease the optimization error.

% We highlight the difference between the small time horizon regime $T = \bigO{n}$ and large time horizon regime $T = \bigOmega{n}$. Existing results suggest a gap between the two regimes for the realizable setting. In particular, we will use SGD as an example to shed some light on the gap: the two regimes are known as the \emph{single-pass} and \emph{multi-pass} SGD. 

%\citet{lei2020fine} established the first excess risk upper bound for SGD under realizable smooth SCO:
%\begin{equation} \label{eq: ub-sgd-tn}
%     \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\eta}{n} + \frac{\eta T}{n^2}}.
%\end{equation}
%For a fixed $n$, by choosing any $\eta = 1$ and $T = n $, we obtain a sample complexity upper bound of $\bigO{1/n}$ under the small time horizon $T = \Omega(n)$. Nevertheless, the bound in Eq.~\eqref{eq: ub-sgd-tn} suffers from the weakness under large time horizon $T = \bigOmega{n}$: it requires $\eta T = n$ to achieve $\bigO{1/n}$ sample complexity, whereas longer training will hurt the generalization and overfit. When $T$ goes to infinity, we need the step-size to be arbitrarily small to achieve best sample complexity. Similar results hold for GD under realizable smooth SCO \citep{nikolakakis2022beyond,schliserman2022stability} and are summarized in Table~\ref{tab: summary}. 

%This leads to different results in the second setting $T = \bigOmega{n}$. \citet{schliserman2022stability} provided an alternative bound for excess population risk:
%\begin{equation} 
% \label{eq: ub-sgd-t}
%     \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\sqrt{\eta T}}{n}}.
%\end{equation}
%This result gives non-vacuous sample complexity lower bound under the large or infinite time regime $T = \bigOmega{n}$: for any such $T$, we can set $\eta = n^{2/3}/T$ and obtain sample complexity bound of $\bigO{1/n^{2/3}}$. Compared with the optimal $\bigO{1/n}$ from Eq.~\eqref{eq: ub-sgd-tn} under regime $T = \bigO{n}$, this is \emph{suboptimal} in the rate of $n$, but holds for a more general choice of $T$. 



%Similar phenomenon also holds in the non-realizable setting. The upper bound for SGD is characterized in the seminal paper of \citet{hardt2016train} are as follows:
%\begin{align*}
%    \label{eq: ub-sgd-sco}
%     \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\eta T}{n}}.
%\end{align*}
%This implies a sample complexity bound of $\bigO{1/\sqrt{n}}$ when we set $\eta = \sqrt{n}/T$ for any $T$. And when we use large $\eta$, longer training will lead to overfit. Also, the best known lower bound $\bigOmega{1/\sqrt{n}}$ is established \emph{only} in the single-pass regime $T = n$ \citep{nemirovskij1983problem}. For GD, there is currently no lower bound result for \emph{either} small or large time horizons.

%The above upper bounds for both realizable and non-realizable problems increase as $\eta T$ increases. However, in practice we often observe that training for longer periods does not lead to a larger generalization gap. In the next section, we provide lower bounds to show that realizability can be a key factor in understanding when models trained for longer periods would overfit.


%  is obtained from Eq.~\eqref{eq: ub-gd-t} for any $\eta,T$ satisfying $\eta T = n^{2/3}$, which is suboptimal compared with the optimal $\bigO{1/n}$ from Eq.~\eqref{eq: ub-gd-tn}. %Nevertheless, the bound in Eq.~\eqref{eq: ub-gd-t} has an advantage since it achieves $\bigO{1/n^{2/3}}$ for any large time horizon $T = \bigOmega{n}$ when choosing small step-size $\eta = n^{2/3}/T$.


%\paragraph{Algorithm stability and generalization.}
%Excess population risk
%\begin{equation}
%    \bbE_{S,A}[F(w_{A})] \leq F(w^*) + \epsilon
%\end{equation}

% \paragraph{Gradient descent.}
% % \jiaye{I do not think it is wise to mention SCO above and introduce GD here}
% The most well-known optimization method is perhaps the \emph{Gradient Descent} (GD) method. At iteration $t$, GD employs the following recurrence:
% \begin{equation} \label{eq: gd}
%     w_{t+1} = w_t - \eta \nabla F_S(w_t),  
% \end{equation}
% where $\eta > 0$ is the step-size and $\nabla F_S(w)$ is the average stochastic gradient on sample set $S$. We usually employ the time average $w_{\gd} = \bar{w}_T = \frac{1}{T} \sum_{t=1}^T w_t$ as the output of SGD. \peiyuan{Comment on last-iterate.} 

% \citet{nikolakakis2022beyond} established the first generalization bound for GD under the realizable smooth SCO setting: \jiaye{I check the bound and believe that it is 1/n. I put the bound in the appendix. }
% \begin{equation} \label{eq: ub-gd-tn}
%     \bbE[F(w_{\gd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\eta}{n} + \frac{\eta T}{n^2}}.
% \end{equation}
% In particular, choosing $T = n$ and $\eta = 1$, we obtain an sample complexity upper bound of $\bigO{1/n}$. However, the bound in Eq.~\eqref{eq: ub-gd-tn} suffers from the weakness that the optimal bound of $\bigO{1/n}$ only holds when $T = \bigO{n}$ and becomes vacuous under infinite time horizon $T = \bigOmega{n}$. To overcome this issue, \citet{schliserman2022stability}  provided an alternative bound for excess population risk:
% \begin{equation} 
% \label{eq: ub-gd-t}
%     \bbE[F(w_{\gd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\sqrt{\eta T}}{n}}.
% \end{equation}
% This result gives non-vacuous sample complexity lower bound under the large or infinite time regime $T = \bigOmega{n}$: for any such $T$, we can set $\eta = n^{2/3}/T$ and obtain sample complexity bound of $\bigO{1/n^{2/3}}$. Compared with the optimal $\bigO{1/n}$ from Eq.~\eqref{eq: ub-gd-tn} under regime $T = \bigO{n}$, this is \emph{suboptimal} in the rate of $n$, but holds for a more general choice of $T$.%  is obtained from Eq.~\eqref{eq: ub-gd-t} for any $\eta,T$ satisfying $\eta T = n^{2/3}$, which is suboptimal compared with the optimal $\bigO{1/n}$ from Eq.~\eqref{eq: ub-gd-tn}. %Nevertheless, the bound in Eq.~\eqref{eq: ub-gd-t} has an advantage since it achieves $\bigO{1/n^{2/3}}$ for any large time horizon $T = \bigOmega{n}$ when choosing small step-size $\eta = n^{2/3}/T$.
% \jiaye{The logic here is a little bit strange, I am not sure about the role of Schliserman et al. here. It also cannot generalize to infinite cases. It might be better if we can reorganize it as GD-SGD-O(n) bound - Omega(n) bound}

% \paragraph{Stochastic gradient descent.}
% Many practitioners in learning applications favor the \emph{Stochastic Gradient Descent} (SGD) method over GD due to its computational efficiency. More precisely, the variant people usually refer as SGD is the the \emph{with-replacement} version, i.e., in iteration $t \in [T]$,
% \begin{equation} \label{eq: sgd}
%     w_{t+1} = w_t - \eta \nabla f(w_t,z_{i_t}), 
% \end{equation}
% where $i_t \sim \text{Unif}([n])$ is uniformly sampled from $S$ with replacement. %This is in contrast with the without-replacement version stated below. 
% We will keep the convention and use SGD to denote the with-replacement version throughout the paper. The output for SGD is the average $w_{\sgd} = \frac{1}{T} \sum_{t=1}^T w_t$.  

% Similar to GD, the generalization upper bound for SGD under realizable smooth SCO is also \emph{bipartite} with respect to the condition between $T$ and $n$. In particular, \cite{lei2020fine} provided a bound\footnote{The Theorem in \citet{lei2020fine} requires an additional condition $f(w,z)$ is nonnegative to enforce the self-boundedness of $\nabla f(w,z)$. In our setting, this can be replaced by considering realizable condition and Lemma~\ref{lemma: growth-condition}. We make a remark to avoid the incompatibility of assumptions. } of 
% \begin{equation} \label{eq: ub-sgd-tn}
%      \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\eta}{n} + \frac{\eta T}{n^2}},
% \end{equation}
% which leads to an optimal $\bigO{1/n}$ when we set $\eta = 1$, $T = n$ albeit the bound holds only when $T = \bigOmega{n}$. Concurrently, the alternative bound 
% \begin{equation} \label{eq: ub-sgd-t}
%      \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\sqrt{\eta T}}{n}},
% \end{equation}
% established by \citet{schliserman2022stability}, holds for large and infinite time horizon case $T = \bigOmega{n}$ but only yields an suboptimal $\bigO{1/n^{2/3}}$ when we set $\eta = n^{2/3}/T$.

% % \paragraph{Without-replacement SGD.} In contrast to the with-replacement SGD, the without-replacement variant has become an essential topic in optimization community. In this work we focus on the Single Shuffling version of without-replacement methods.  comes with a fixed permutation of stochastic loss function from the sample set $S$. Without the loss of generality we assume permutation $\vpi(i) = i$ for any $i \in [n]$ to simplify the analysis. Therefore, we can formulate the iterations of single-shuffling SGD as
% % \begin{equation} \label{eq: ss}
% %     w^k_{t+1} = w^k_t - \eta \nabla f(w^k_t,z_t),  
% % \end{equation}
% % where.

% We remark that we will use compact notation $w_{\gd}$, $w_{\sgd}$ and $w_{\sgdss}$ to denote the output of respective methods, i.e., the value $w_T$ at final iteration $T$.

