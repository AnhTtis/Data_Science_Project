\section{Problem Setup and Background} \label{sec: setting}
We focus on the standard setting of stochastic convex optimization (SCO) problem. Consider an element $z$ in a sample space $\cZ$. We receive a dataset of finite samples $S = \{z_1, \dots, z_n\}$, where each $z_i$ is i.i.d. drawn from an unknown distribution $D$ and $n$ is the size of dataset.  Our goal is to find a model parameterized by $w \in \cW \subseteq \bbR^d$ that minimizes the \emph{population} (or expected) risk over $D$, defined as:
\begin{equation}
    F(w) = \bbE_{z \sim D}[f(w,z)]
\end{equation}
where $f(w, z): \bbR^d \times \cZ \to \bbR$ is the loss function evaluated on a single example $z \in \cZ$.

Since the population loss $F$ is typically inaccessible, we instead employ an averaged substitute on sample $S$, known as the \emph{empirical} risk:
\begin{equation}
    F_S(w) = \frac{1}{n} \sum_{i=1}^n f(w,z), \qquad S \sim D^n.
\end{equation}

Given dataset $S$ and any (stochastic) algorithm $\cA$, we denote $\cA[S]$ as the output of running $\cA$ on the training sample $S$. In this paper, we are interested in bounding the \emph{excess population risk} of $\cA[S]$:
\begin{equation*}
    \bbE_{S,\cA}[F(\cA[S])] - \min_{w \in \cW} F(w),
\end{equation*}
where the expectation is taken over the randomness of sample $S$ and algorithm $\cA$.

\subsection{Gradient methods}
In this work, we focus on understanding the excess risk for two simplified algorithms: Gradient Descent (GD) and Stochastic Gradient Descent (SGD). Gradient descent is one of the most well-known optimization methods. At iteration $t$, GD employs the following recurrence:
\begin{equation} \label{eq: gd}
    w_{t+1} = w_t - \eta \nabla F_S(w_t),  
\end{equation}
where $\eta > 0$ is the step-size and $\nabla F_S(w)$ is the average stochastic gradient on sample set $S$. We usually employ the time average $w_{\gd} = \hat{w}_T = \frac{1}{T} \sum_{t=1}^T w_t$ as the output of GD.  

In practice, many practitioners in learning applications favor the Stochastic Gradient Descent (SGD) method over GD due to its computational efficiency. More precisely, the variant people usually refer as SGD is the the \emph{with-replacement} version, i.e., in iteration $t \in [T]$,
\begin{equation} \label{eq: sgd}
    w_{t+1} = w_t - \eta \nabla f(w_t,z_{i_t}), 
\end{equation}
where $z_{i_t}$ is uniformly sampled from $S$ with replacement as $i_t \sim \text{Unif}([n])$. We will keep the convention and use SGD to denote the with-replacement version throughout the paper. The output for SGD is the average $w_{\sgd} = \frac{1}{T} \sum_{t=1}^T w_t$.  

\subsection{Smooth stochastic convex  optimization}
In order to derive non-vacuous bounds on the excess risk for SCO, we put standard assumptions on the properties of $f(w, z)$. We assume the access to the value $f(w,z)$ and the unbiased stochastic gradient estimator $\nabla f(w, z)$ for any $w \in \cW$ and $z \in \cZ$. When the function is nonsmooth, this problem has been extensively studied \citep{bassily2020stability}, and known rates were proven to be optimal \citep{amir2021sgd,sekhari2021sgd,nemirovskij1983problem}.

However, less is known when the function is differentiable and smooth. Indeed, while upper bounds have been well-established in literature \citep{hardt2016train,lei2020fine,nikolakakis2022beyond}, the optimality of these results need to be certified by corresponding lower bound constructions. In this work, we focus on the smooth SCO setting and make the following assumptions.
%\begin{definition} \label{def: lipschitz}
%$f(w, z)$ has $G$-Lipschitz gradient if for any $w$, it holds $\| \nabla f(w, z) \| \leq G$ and $z \in \cZ$.
%\end{definition}

\begin{definition} \label{def: smooth}
$f(w, z)$ is $L$-smooth if it satisfies $\| \nabla f(w_1, z) - \nabla f(w_2, z) \| \leq L \| w_1 - w_2 \|$ for any $w_1, w_2$ and $z \in \cZ$.
\end{definition}

%\begin{definition} \label{def: bounded}
%Each $f(w, z)$ is $L$-smooth, i.e. $\| \nabla f(w_1, z) - \nabla f(w_2, z) \| \leq L \| w_1 - w_2 \|$ for any $w_1, w_2$.
%\end{definition}

\begin{definition} \label{def: convex}
$f(w, z)$ is convex if it satisfies $f(w_1, z) \geq f(w_2, z) + \langle w_1 - w_2, \nabla f(w_2, z)\rangle$ for any $w_1, w_2$ and $z \in \cZ$.
\end{definition}


\begin{table}[t]
\centering
\begin{threeparttable}
\begin{tabular}{ M{0.9cm} M{2.5cm}  M{3.6cm}  M{3.6cm} M{2.3cm}  }
\toprule
& & & & \\[-0.3cm]
& & GD & SGD & Best Sample Complexity \\[0.1cm] 
 \midrule 
& & & & \\[-0.2cm]
\multirow{4}{*}{\begin{sideways}Non-realizable\end{sideways}}
%\multirow{4}{*}{\begin{sideways}\ \end{sideways}}
\multirow{4}{*}{\begin{sideways}(Any $T$) $\quad$ \end{sideways}}
& Upper bound & \thead{{\normalsize	 $\bigO{\frac{1}{\eta T} + \frac{\eta T}{n} }$} \\{\footnotesize\citep{hardt2016train}}}  & \thead{{\normalsize	 $\bigO{\frac{1}{\eta T} + \frac{\eta T}{n} }$} \\{\footnotesize\citep{hardt2016train}}} & $\bigO{1/\sqrt{n}}$ \\[0.3cm]
& & & & \\[-0.1cm]
& Lower bound & \thead{{\normalsize	 $\bigOmega{\frac{1}{\eta T} + \frac{\eta T}{n} }$} \\ {(\footnotesize Theorem.~\ref{thm: lb-sco-gd})}} & \thead{{\normalsize	 $\bigOmega{\frac{1}{\eta T} + \frac{\eta T}{n} }$} \\{(\footnotesize Theorem.~\ref{thm: lb-sco-sgd})}} & $\bigOmega{1/\sqrt{n}}$  \\[0.4cm]
\midrule 

& & & & \\[-0.2cm]
\multirow{4}{*}{\begin{sideways}Realizable \end{sideways}}
\multirow{4}{*}{\begin{sideways}\ \end{sideways}}
\multirow{4}{*}{\begin{sideways}$\quad $($T = \bigO{n}$) \end{sideways}}
& Upper bound  & $\bigO{\frac{1}{\eta T} + \frac{1}{n} + \frac{\eta T}{n^2} }$\tnote{$\dag$}  {\footnotesize \citep{nikolakakis2022beyond}} & $\bigO{\frac{1}{\eta T} + \frac{\eta}{n} + \frac{\eta T}{n^2} }$ {\footnotesize	 \citep{lei2020fine}} & $\bigO{1/n}$  \\[0.3cm]
& & & & \\[-0.1cm]
& Lower bound  & $\bigOmega{\frac{1}{\eta T} + \frac{1}{n} + \frac{\eta T}{n^2}}$ {(\footnotesize Theorem.~\ref{thm: lb-1})} & $\bigOmega{\frac{1}{\eta T} + \frac{1}{n} + \frac{\eta T}{n^2}}$ {(\footnotesize Theorem.~\ref{thm: lb-1})} & $\bigOmega{1/n}$ \\[0.4cm] %\cmidrule{2-5}
\midrule 

& & & & \\[-0.2cm]
\multirow{4}{*}{\begin{sideways}Realizable \end{sideways}}
\multirow{4}{*}{\begin{sideways}\ \end{sideways}}
\multirow{4}{*}{\begin{sideways}$\ $($T = \bigOmega{n}$) \end{sideways}}
% & & & & \\[-0.2cm]
& Upper bound   & $\bigO{\frac{1}{\eta T} + \frac{\sqrt{\eta T}}{n}}$ {\footnotesize	 \citep{schliserman2022stability}} & $\bigO{\frac{1}{\eta T} + \frac{\sqrt{\eta T}}{n}}$ {\footnotesize	 \citep{schliserman2022stability}} & $\bigO{1/n^{2/3}}$  \\[0.3cm] 
 & & & & \\[-0.1cm]
& Lower bound  & $\bigOmega{\frac{1}{\eta T} + \frac{1}{n} + \frac{\eta T}{n^2}}$ {(\footnotesize Theorem.~\ref{thm: lb-2})} & $\bigOmega{\frac{1}{\eta T} + \frac{1}{n} + \frac{\eta T}{n^2}}$ {(\footnotesize Theorem.~\ref{thm: lb-2})} & $\bigOmega{1/n}$ \\[0.4cm] 
\bottomrule
\end{tabular}
\caption{\small Summary of our results. We present our lower bounds and compare with existing upper bounds. In particular, we split to three setting: non-realizable, realizable under $T = \bigO{n}$ and realizable under $T = \bigOmega{n}$. For each setting, we provide lower bounds for the excess risk of GD, SGD, and corresponding best possible sample complexity bounds.}
\label{tab: summary}
\begin{tablenotes}
\item[$\dag$] The bound in $\eta, T$ and $n$ is not explicitly stated in \citet{nikolakakis2022beyond}. For the expression, please refer to a derivation in Appendix~\ref{appendix: gd-ub}.
\end{tablenotes}
\end{threeparttable}
%\hspace{-0.3cm}
\end{table}

The smooth SCO problem can be divided into two cases depending whether the optimal solution minimizes all data points simultaneously. 

\paragraph{Realizable smooth SCO.}
A SCO problem is said to be realizable if there exists a solution that simultaneously minimizes over all the instance loss function $f(w,z)$ for any $z \in \cZ$. We give the formal definition below.
\begin{definition} \label{def: realizable}
We say that $f(w, z)$, $z \in \cZ$ formalizes a realizable setting if for any $z \in \cZ$ $$f(w^*, z) = \min_{w} f(w, z), \quad \text{where} \quad w^* = \argmin_{w}F(w).$$
\end{definition}
Combined with the above definitions, we assume $f(w,z)$ to be smooth, convex, and also realizable. We will refer to the setting as the \emph{realizable} smooth SCO. The realizable condition implies immediately the property called \emph{weak growth condition}, which is stated in the following lemma.
\begin{lemma} \label{lemma: growth-condition} If $f(w, z), z \in Z$ is realizable and $L$-smooth, then for any $w, z \in \cZ$ it holds 
    \begin{equation*}
        \| \nabla f(w, z) \|^2 \leq 2L \left( f(w, z)  - f(w^*, z)\right).
    \end{equation*}
\end{lemma}
The growth condition connects the rates at which the stochastic gradients shrink relative to its value. It is widely employed in stochastic optimization literature to improve the convergence rate of SGD and GD under overparameterized or realizable setting \citep{vaswani2019fast}. Recent papers \citep{lei2020fine,schliserman2022stability,nikolakakis2022beyond} focused on the generalization bound under realizable smooth SCO also suggest that such an assumption improves the sample complexity upper bounds beyond the rate of $\bigO{1/\sqrt{n}}$, which is the well-known result for GD and SGD without the realizable assumption \citep{hardt2016train}.

\paragraph{Non-realizable smooth SCO.} 
We say a convex learning problem is non-realizable if it does not satisfy the condition in Definition~\ref{def: realizable}. In this setting, known upper bounds for sample complexity actually yield a slower convergence rate at $\bigO{1/\sqrt{n}}$. 

\paragraph{Different complexities in small and large time horizon.}
Although upper bounds for non-realizable and realizable problems differ, they share one thing in common, that the excess risk first decreases and then grows with the number of iterations. Based on this, we classify the bounds into two categories according to their assumptions on the number of iterations $T$.

We highlight the difference between the small time horizon regime $T = \bigO{n}$ and large time horizon regime $T = \bigOmega{n}$. Existing results suggest a gap between the two regimes for the realizable setting. In particular, we will use SGD as an example to shed some light on the gap: the two regimes are known as the \emph{single-pass} and \emph{multi-pass} SGD. In the setting $T = \bigO{n}$, \citet{lei2020fine} established the first excess risk upper bound for SGD under realizable smooth SCO:
\begin{equation} \label{eq: ub-sgd-tn}
     \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\eta}{n} + \frac{\eta T}{n^2}}.
\end{equation}
By choosing $T = n$ and $\eta = 1$, we obtain a sample complexity upper bound of $\bigO{1/n}$. However, the bound in Eq.~\eqref{eq: ub-sgd-tn} suffers from the weakness that the optimal bound of $\bigO{1/n}$ only holds when $T = \bigO{n}$ and becomes vacuous under large time horizon $T = \bigOmega{n}$. To overcome this issue, \citet{schliserman2022stability} provided an alternative bound for excess population risk:
\begin{equation} 
 \label{eq: ub-sgd-t}
     \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\sqrt{\eta T}}{n}}.
\end{equation}
This result gives non-vacuous sample complexity lower bound under the large or infinite time regime $T = \bigOmega{n}$: for any such $T$, we can set $\eta = n^{2/3}/T$ and obtain sample complexity bound of $\bigO{1/n^{2/3}}$. Compared with the optimal $\bigO{1/n}$ from Eq.~\eqref{eq: ub-sgd-tn} under regime $T = \bigO{n}$, this is \emph{suboptimal} in the rate of $n$, but holds for a more general choice of $T$. Similar results hold for GD under realizable smooth SCO \citep{nikolakakis2022beyond,schliserman2022stability} and are summarized in Table~\ref{tab: summary}. 

In the non-realizable setting, the upper bound for SGD is characterized in the seminal paper of \citet{hardt2016train}:
\begin{align*}
    \label{eq: ub-sgd-sco}
     \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\eta T}{n}}.
\end{align*}
This implies a sample complexity bound of $\bigO{1/\sqrt{n}}$ when we set $\eta = \sqrt{n}/T$ for any $T$. Nevertheless, the best known result for lower bound $\bigOmega{1/\sqrt{n}}$ is established \emph{only} in the single-pass regime $T = n$ \citep{nemirovskij1983problem}. For GD, there is currently no lower bound result for \emph{either} small or large time horizons.

Although the above upper bounds for both realizable and non-realizable problems exhibit an increase for a large time horizon, in practice, we often observe that training for longer periods does not lead to a larger generalization gap. In the next section, we provide tight lower bounds to show that realizability can be a key factor in understanding when models trained for longer periods will overfit.


%  is obtained from Eq.~\eqref{eq: ub-gd-t} for any $\eta,T$ satisfying $\eta T = n^{2/3}$, which is suboptimal compared with the optimal $\bigO{1/n}$ from Eq.~\eqref{eq: ub-gd-tn}. %Nevertheless, the bound in Eq.~\eqref{eq: ub-gd-t} has an advantage since it achieves $\bigO{1/n^{2/3}}$ for any large time horizon $T = \bigOmega{n}$ when choosing small step-size $\eta = n^{2/3}/T$.


%\paragraph{Algorithm stability and generalization.}
%Excess population risk
%\begin{equation}
%    \bbE_{S,A}[F(w_{A})] \leq F(w^*) + \epsilon
%\end{equation}

% \paragraph{Gradient descent.}
% % \jiaye{I do not think it is wise to mention SCO above and introduce GD here}
% The most well-known optimization method is perhaps the \emph{Gradient Descent} (GD) method. At iteration $t$, GD employs the following recurrence:
% \begin{equation} \label{eq: gd}
%     w_{t+1} = w_t - \eta \nabla F_S(w_t),  
% \end{equation}
% where $\eta > 0$ is the step-size and $\nabla F_S(w)$ is the average stochastic gradient on sample set $S$. We usually employ the time average $w_{\gd} = \hat{w}_T = \frac{1}{T} \sum_{t=1}^T w_t$ as the output of SGD. \peiyuan{Comment on last-iterate.} 

% \citet{nikolakakis2022beyond} established the first generalization bound for GD under the realizable smooth SCO setting: \jiaye{I check the bound and believe that it is 1/n. I put the bound in the appendix. }
% \begin{equation} \label{eq: ub-gd-tn}
%     \bbE[F(w_{\gd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\eta}{n} + \frac{\eta T}{n^2}}.
% \end{equation}
% In particular, choosing $T = n$ and $\eta = 1$, we obtain an sample complexity upper bound of $\bigO{1/n}$. However, the bound in Eq.~\eqref{eq: ub-gd-tn} suffers from the weakness that the optimal bound of $\bigO{1/n}$ only holds when $T = \bigO{n}$ and becomes vacuous under infinite time horizon $T = \bigOmega{n}$. To overcome this issue, \citet{schliserman2022stability}  provided an alternative bound for excess population risk:
% \begin{equation} 
% \label{eq: ub-gd-t}
%     \bbE[F(w_{\gd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\sqrt{\eta T}}{n}}.
% \end{equation}
% This result gives non-vacuous sample complexity lower bound under the large or infinite time regime $T = \bigOmega{n}$: for any such $T$, we can set $\eta = n^{2/3}/T$ and obtain sample complexity bound of $\bigO{1/n^{2/3}}$. Compared with the optimal $\bigO{1/n}$ from Eq.~\eqref{eq: ub-gd-tn} under regime $T = \bigO{n}$, this is \emph{suboptimal} in the rate of $n$, but holds for a more general choice of $T$.%  is obtained from Eq.~\eqref{eq: ub-gd-t} for any $\eta,T$ satisfying $\eta T = n^{2/3}$, which is suboptimal compared with the optimal $\bigO{1/n}$ from Eq.~\eqref{eq: ub-gd-tn}. %Nevertheless, the bound in Eq.~\eqref{eq: ub-gd-t} has an advantage since it achieves $\bigO{1/n^{2/3}}$ for any large time horizon $T = \bigOmega{n}$ when choosing small step-size $\eta = n^{2/3}/T$.
% \jiaye{The logic here is a little bit strange, I am not sure about the role of Schliserman et al. here. It also cannot generalize to infinite cases. It might be better if we can reorganize it as GD-SGD-O(n) bound - Omega(n) bound}

% \paragraph{Stochastic gradient descent.}
% Many practitioners in learning applications favor the \emph{Stochastic Gradient Descent} (SGD) method over GD due to its computational efficiency. More precisely, the variant people usually refer as SGD is the the \emph{with-replacement} version, i.e., in iteration $t \in [T]$,
% \begin{equation} \label{eq: sgd}
%     w_{t+1} = w_t - \eta \nabla f(w_t,z_{i_t}), 
% \end{equation}
% where $i_t \sim \text{Unif}([n])$ is uniformly sampled from $S$ with replacement. %This is in contrast with the without-replacement version stated below. 
% We will keep the convention and use SGD to denote the with-replacement version throughout the paper. The output for SGD is the average $w_{\sgd} = \frac{1}{T} \sum_{t=1}^T w_t$.  

% Similar to GD, the generalization upper bound for SGD under realizable smooth SCO is also \emph{bipartite} with respect to the condition between $T$ and $n$. In particular, \cite{lei2020fine} provided a bound\footnote{The Theorem in \citet{lei2020fine} requires an additional condition $f(w,z)$ is nonnegative to enforce the self-boundedness of $\nabla f(w,z)$. In our setting, this can be replaced by considering realizable condition and Lemma~\ref{lemma: growth-condition}. We make a remark to avoid the incompatibility of assumptions. } of 
% \begin{equation} \label{eq: ub-sgd-tn}
%      \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\eta}{n} + \frac{\eta T}{n^2}},
% \end{equation}
% which leads to an optimal $\bigO{1/n}$ when we set $\eta = 1$, $T = n$ albeit the bound holds only when $T = \bigOmega{n}$. Concurrently, the alternative bound 
% \begin{equation} \label{eq: ub-sgd-t}
%      \bbE[F(w_{\sgd})] - \min_{w \in \cW} F(w) = \bigO{\frac{1}{\eta T} + \frac{\sqrt{\eta T}}{n}},
% \end{equation}
% established by \citet{schliserman2022stability}, holds for large and infinite time horizon case $T = \bigOmega{n}$ but only yields an suboptimal $\bigO{1/n^{2/3}}$ when we set $\eta = n^{2/3}/T$.

% % \paragraph{Without-replacement SGD.} In contrast to the with-replacement SGD, the without-replacement variant has become an essential topic in optimization community. In this work we focus on the Single Shuffling version of without-replacement methods.  comes with a fixed permutation of stochastic loss function from the sample set $S$. Without the loss of generality we assume permutation $\vpi(i) = i$ for any $i \in [n]$ to simplify the analysis. Therefore, we can formulate the iterations of single-shuffling SGD as
% % \begin{equation} \label{eq: ss}
% %     w^k_{t+1} = w^k_t - \eta \nabla f(w^k_t,z_t),  
% % \end{equation}
% % where.

% We remark that we will use compact notation $w_{\gd}$, $w_{\sgd}$ and $w_{\sgdss}$ to denote the output of respective methods, i.e., the value $w_T$ at final iteration $T$.

