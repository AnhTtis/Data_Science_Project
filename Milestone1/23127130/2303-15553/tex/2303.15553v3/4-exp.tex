\section{Experiments}

\subsubsection{Datasets.} 
Evaluations are performed on two datasets curated from different modalities.
% 
(1) 
Histology Image Dataset: \textit{NCT-CRC-HE-100K} is a public Hematoxylin \& Eosin (H\&E) stained histology image dataset with $100,000$ patches without overlap, curated from $N=86$ colorectal cancer samples~\cite{dataset}.
% 
All RGB images are scaled to $224\times224$ pixels at the magnification of $20\times$. 
% 
To simulate various data availability conditions, some experiments use a subset from \textit{NCT-CRC-HE-100K} as the training set.
% 
In terms of the test set, an external public dataset \textit{CRC-VAL-HE-7K} with 7180 patches from $N=50$ patients is employed.
% 
This dataset was designed to classify the nine tissue categories from histology image patches, and we use the top-1 test accuracy as the evaluation metric.
% 
(2) 
MRI Dataset: This in-house dataset includes $147$ scans with malignant gliomas curated from $N=92$ patients.
All data has been deidentified properly to comply with the Institutional Review Board (IRB). 
% 
Each scan contains five MRI sequences, namely T1-weighted (T1w), T2-weighted (T2w), fluid-attenuated inversion recovery (FLAIR), gadolinium enhanced T1-weighted (Gd-T1w), and amide proton transfer-weighted (APTw). 
% 
% 
The corresponding slices from each scan are concentrated after co-registration and z-score normalization, resulting in an input size of $256\times256\times5$.
% 
A proportion of 80\% of the patients are divided into the training set, and the remaining 20\% as the test set \ie, 1770 training samples and 435 test samples.
% 
This is a binary classification task to distinguish malignant gliomas from normal tissue.
% 
We use accuracy, area under the ROC curve (AUC), precision, recall, and F1-score as the evaluation metrics.


\begin{figure}[t!]
    \centering
    \includegraphics[width=0.65\linewidth]{fig/result1.png}
    \caption{Performance comparisons of MoViT plugged into the last layer of ViT-Tiny with counterparts, using a varying number of training samples from the Histology image dataset ($0.1\%$ to $1\%$ data employed).
    % 
    The solid line and shadow regions represent the average and the standard deviation of test accuracy computed from seven random runs, respectively.
    % 
    The dashed line denotes the performance of the baseline (vanilla ViT) trained with the entire dataset, regarded as the performance upper bound.
    }
    \label{fig:result1}
\end{figure}



\begin{table}[hb!]
\caption{Performance comparison trained on the entire dataset in terms of test accuracy (\%). 
We employ three ViT configurations \ie ViT-Tiny, ViT-Small, and ViT-Base.} \label{tab:result1}
\begin{center}   
% \resizebox{\linewidth}{!}{ 
\begin{tabular}{l|ccc} 
% \hline
\toprule
Method & ViT-Tiny & ViT-Small & ViT-Base \\
\midrule
Baseline & $96.462$\tiny{$\pm0.213$} & $95.850$\tiny{$\pm0.503$} &  $94.231$\tiny{$\pm0.511$}\\
MT \cite{mem_vit} & $96.511$\tiny{$\pm0.312$} & $96.621$\tiny{$\pm0.108$} & $95.102$\tiny{$\pm0.272$}\\
DeiT \cite{touvron2021training} & $96.439$\tiny{$\pm0.331$} & $96.216$\tiny{$\pm0.213$} & $93.246$\tiny{$\pm0.259$} \\
ProtoPFormer \cite{xue2022protopformer} & $96.712$\tiny{$\pm0.521$} & $96.032$\tiny{$\pm0.364$} & $93.002$\tiny{$\pm0.752$}\\
\hline
MoViT (Ours) & \bm{$97.792$}\tiny{$\pm0.293$} & \bm{$97.326$}\tiny{$\pm0.138$}& \bm{$95.989$}\tiny{$\pm0.205$}\\
\bottomrule
\end{tabular}
% }
\end{center}
\end{table}




\subsubsection{Implementations.} 
All experiments are performed on one NVIDIA GeForce RTX 3090 GPU with 24 GB memory. 
% 
An AdamW optimizer is used with a Cosine Annealing learning rate scheduler, where the initial learning rates are $2\times10^{-3}$ for the MRI dataset, $5\times10^{-4}$ for the Histology image dataset; with the maximum number of training epochs set to $100$.
% 
We plug the MoViT into the last layer of ViT-Tiny, \ie 12 transformer layers with 3, and set $k=32$ for the kNN lookup.
% 
In PAL, we set the number of prototypes $P=\#(\text{number of class})\times 32$, and temperature $\tau=0.5$ for Eq.~\eqref{eq:avg}.
% 
Comparisons are made to Memorizing Transformer (MT)~\cite{mem_vit}, DeiT~\cite{touvron2021training}, and ProtoPFormer \ie a prototypical part network framework for ViT~\cite{xue2022protopformer}, where the vanilla ViT is regarded as the baseline.
% 
To compute the mean and standard deviation of the metrics, all models are trained from scratch for seven random runs.



\begin{table}[b!]
\caption{Quantitative comparison on the MRI dataset.
% 
MoViT achieves the highest performance across all metrics, further suggesting its ability to perform well in applications where limited data is available.
} \label{tab:result2}
\begin{center}   
% \resizebox{\linewidth}{!}{ 
\begin{tabular}{l|cccccc} 
% \hline
\toprule
Method & Accuracy($\uparrow$) & AUC($\uparrow$) & Precision($\uparrow$) & Recall($\uparrow$) & F1-score($\uparrow$) \\
\midrule
Baseline & $74.01$\tiny{$\pm0.40$} & $80.62$\tiny{$\pm0.40$} & $57.64$\tiny{$\pm0.66$} & $79.01$\tiny{$\pm0.68$} & $66.64$\tiny{$\pm0.54$} \\
MT \cite{mem_vit} & $77.92$\tiny{$\pm0.36$} & $84.83$\tiny{$\pm0.40$} & $62.54$\tiny{$\pm0.68$} & $81.84$\tiny{$\pm0.64$} & $70.95$\tiny{$\pm0.56$} \\
DeiT \cite{touvron2021training}& $78.63$\tiny{$\pm0.40$} & $85.65$\tiny{$\pm0.39$} & $63.07$\tiny{$\pm0.67$} & $84.68$\tiny{$\pm0.56$} & $72.20$\tiny{$\pm0.54$}\\
ProtoPFormer \cite{xue2022protopformer} &
$77.53$\tiny{$\pm0.40$} & $85.74$\tiny{$\pm0.38$} & $61.12$\tiny{$\pm0.67$} & $86.07$\tiny{$\pm0.53$} & $71.54$\tiny{$\pm0.55$} \\
\hline
Ours & \bm{$82.05$}\tiny{$\pm0.36$} & \bm{$88.38$}\tiny{$\pm0.30$} & \bm{$65.94$}\tiny{$\pm0.66$} & \bm{$94.43$}\tiny{$\pm0.36$} & \bm{$77.67$}\tiny{$\pm0.47$}\\
\bottomrule
\end{tabular}
% }
\end{center}
\end{table}

\subsubsection{Results on Histology Image Dataset.} 
To simulate the case where only small data is available as in many medical image analysis tasks, we use a limited proportion of the training set, across varied data regimes, and use the whole \textit{NCT-CRC-HE-100K} as the test set for a fair comparison.
% 
As shown in \figref{fig:result1}, MoViT improves over the baseline at any data scale, especially when the number of samples is particularly small, \ie $0.1\%$, where we can observe a similar trend with a large proportion of the data between 1\%-100\%.
% 
Notably, our method can achieve a close margin to the entire-dataset-trained model ($96.462\%\pm$0.213\%) using only 1.0\% data ($94.927\%\pm$0.378\%), and a competitive performance ($96.341\%\pm$0.201\%) with 3.0\% data.
% 
Additionally, our approach also significantly reduces the performance fluctuations \ie standard deviation, leading to a more stable performance.
% 
For example, vanilla ViT is $20.901\%$ when trained with $0.1\%$ data and ours is $5.452\%$ \ie approximately four times smaller.
% 
Moreover, our method can consistently outperform state-of-the-art data-efficient transformer DeiT~\cite{touvron2021training} and pure prototype learning method ProtoPFormer~\cite{xue2022protopformer}.
% 
We notice that Memorizing Transformer (MT) \cite{mem_vit} performs worse than the baseline although achieving almost 100\% training accuracy, where the gap becomes significant with $0.1\%-0.4\%$ data, which we attribute to the overfitting issue. 
% 
The large margin between the performance of MT and MoViT implies that ATMA and PAL can alleviate the overfitting issues during the memorization of the facts.  
% 
Performance comparison is also performed on the entire training set \ie using $100\%$ \textit{NCT-CRC-HE-100K} as the training set, with different ViT configurations. 
% 
In \tabref{tab:result1}, our method can consistently outperform its counterparts with a large margin, which demonstrates its applicability and scalability to large datasets.
% 
This suggests that MoViT scales well to a wide range of data scales as a by-product.
% 
The averaged training times per epoch on ViT-Tiny are 162.61(s) for baseline ViT, 172.22(s) for MT, 109.8(s) for DeiT, 639.4(s) for ProtoPFormer, and 171.49(s) for our approach.
% 
Our method can boost performance with a reduced training data scale.






\subsubsection{Results on MRI Dataset.} 
As depicted in~\tabref{tab:result2}, our proposed MoViT achieves the highest performance in terms of all metrics on the MRI dataset, where the dataset scale is relatively small, by nature.
% 
Specifically, MoViT can improve the AUC by a margin of $0.026$ to the state-of-the-art transformer \ie $0.857$ achieved by ProtoPFromer; and can achieve better performance (AUC of $0.821$) than baseline with 30\% training data.
% 
Empirically, our method is superior to other modalities in the generalization ability.


\subsubsection{Ablation Study.}
To investigate the contribution of each functional block, ablation studies are performed on the MRI dataset. 
% 
As shown in~\tabref{tab:result3}, the proposed MoViT benefits from both ATMA and PAL. 
% 
Although each module brings a similar AUC improvement from $0.010$ to $0.013$, the exclusion of the two modules suffers an AUC decline of $0.022$.
% 
Conclusively, the reported results suggest the effectiveness and indispensability of ATMA and PAL.



\begin{table}[t!]
\caption{Ablations on MRI dataset with MoViT-Tiny as the backbone. We can observe that the exclusion of either ATMA or PAL results in decreased performance with varying degrees.
} \label{tab:result3}
\begin{center}   
% \resizebox{\linewidth}{!}{ 
\begin{tabular}{ll|cccccc} 
% \hline
\toprule
ATMA & PAL & Accuracy($\uparrow$) & AUC($\uparrow$) & Precision($\uparrow$) & Recall($\uparrow$) & F1-score($\uparrow$) \\
\midrule
 &  & $78.63$\tiny{$\pm0.39$} & $86.14$\tiny{$\pm0.38$} & $62.75$\tiny{$\pm0.68$} & $86.07$\tiny{$\pm0.60$} & $72.62$\tiny{$\pm0.54$}\\
 &  \checkmark  & $79.35$\tiny{$\pm0.34$} & $87.43$\tiny{$\pm0.31$} & $61.92$\tiny{$\pm0.63$} & $96.55$\tiny{$\pm0.31$} & $75.57$\tiny{$\pm0.49$}\\
\checkmark  &  &  $79.54$\tiny{$\pm0.38$} & $87.13$\tiny{$\pm0.32$} & $62.27$\tiny{$\pm0.66$} & $95.85$\tiny{$\pm0.31$} & $75.49$\tiny{$\pm0.48$} \\
\checkmark & \checkmark & $82.05$\tiny{$\pm0.36$} & $88.38$\tiny{$\pm0.30$} & $65.94$\tiny{$\pm0.66$} & $94.43$\tiny{$\pm0.36$} & $77.67$\tiny{$\pm0.47$} \\
\bottomrule
\end{tabular}
% }
\end{center}
\end{table}

