\section{Introduction}
Mixtures of experts (MoEs) are powerful models, that leverage a divide-and-conquer approach to conditional density estimation by assigning experts to smaller sub-tasks. They are capable of representing highly complex multimodal distributions but are inherently hard to train which often yields poor performance due to a sub-optimal optimization outcome. We hypothesize that these problems are due to training by maximizing the likelihood via gradient ascent \cite{bishop1994mixture} or expectation maximization \cite{dempster1977maximum}. It is well known that maximum likelihood estimation corresponds to a moment projection which causes the model to average over modes that it cannot represent, leading to poor generative capabilities \cite{murphy2012machine}. Moreover, these methods are often susceptible to poor solutions found due to local maxima, and finding an appropriate model complexity is difficult as the number of experts has to be specified a-priori. 
% Despite these drawbacks, common optimization objectives assign equal weights to all samples rendering the model prone to outliers and harming generalization \cite{bengio2009curriculum}. 


% Despite this drawback, the moment projection is often paired with the assumption that that samples stem from the same data distribution \cite{bishop2006pattern}. As a consequence, easy and difficult samples are weighted equally, rendering the model prone to outliers. % we could mentoin here that the mode averaging propoerty can be problematic in applications such as behavior learning.

%Despite this drawback, 
% a more general problem is that 
%common optimization objectives assume that samples stem from the same data distribution (i.i.d. assumption). As a consequence, all samples are assigned equal importance, rendering the model prone to outliers and leading to an unnatural learning progression as easy samples are treated equally as difficult ones. 
%This is contradictory to the way humans learn, where skills are often learned on a basic level before gradually increasing the difficulty to become an expert.

In this work, we propose \textit{Information Maximizing Curriculum} (IMC), a novel approach for training mixtures of experts that combines the information projection \cite{murphy2012machine} with curriculum learning (CL) to address the aforementioned problems with existing optimizing schemes. The information projection minimizes the reverse KL divergence which forces the model to ignore non-representable modes, leading to good generative models that are able to produce high quality samples. IMC assigns weights to samples according to their difficulty, resulting in reduced outlier sensitivity and better generalization capabilities \cite{bengio2009curriculum}. 
% While early work relies on a manual assignment of these weights, more recent work that goes by self-paced learning, automatically generates the curriculum by adapting to the pace of the learner \cite{kumar2010self}. 

IMC employs a curriculum for each expert, which adapts to their performance and allows them to specialize on samples that they are able to represent. Moreover, the information projection is employed to compute the joint curriculum of all experts, which results in components that specialize to different subsets of the data. The curriculum also enables a modular architecture  capable of online adaptation of the model complexity by adding experts to the model.
 
% In this work... tackle both problems using a novel objective and epirically show that iid invalid... we base our objective on the I-projection and build on curriculu learning.

We show that our method is able to outperform state-of-the-art generative models on challenging multimodal conditional density estimation problems. In particular, we focus on complex behavior learning tasks where data is collected by human demonstrators. The inherent versatility in human behavior leads to highly multimodal data distributions. In our experiments, we assess the ability of the models to \textit{i)} avoid mode averaging and \textit{ii)} extract all modes present in the data distribution.  

%Despite the performance we particularly focus whether all models can cover the different modes in the data, which we include in our performance metrics.
%In all experiments, we assess the models ability to learn the inherent versatility in human behavior   focus on the question of whether our method can 