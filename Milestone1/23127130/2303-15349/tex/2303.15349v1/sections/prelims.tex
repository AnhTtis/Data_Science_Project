\section{Preliminaries}
\definecolor{forestgreen4416044}{RGB}{44,160,44}
\definecolor{steelblue31119180}{RGB}{31,119,180}
Our approach heavily builds on mixtures of experts as well as minimizing Kullback-Leibler divergences. Hence, we will briefly review both concepts.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mixtures of Experts}
Mixtures of experts are conditional discrete latent variable models. Given some input $\mathbf{x}\in \mathcal{X}$ and target $\mathbf{y} \in \mathcal{Y}$, the marginal likelihood is decomposed into individual components $o$, that is,
\begin{equation*}
    p(\mathbf{y}|\mathbf{x}) = \sum_o p(o|\mathbf{x}) p(\mathbf{y}|\mathbf{x}, o).
\end{equation*}
The gating $p(o|\mathbf{x})$ is responsible for soft-partitioning the input space $\mathcal{X}$ into sub-regions where the corresponding experts $p(\mathbf{y}|\mathbf{x}, o)$ approximate the target density. Typically the experts and the gating are parameterized and learned by maximizing the likelihood via expectation-maximization \cite{dempster1977maximum} or gradient ascent \cite{bishop1994mixture}.
In order to sample from the marginal likelihood, that is, $\mathbf{y}' \sim p(\mathbf{y}|\mathbf{x}')$ for some $\mathbf{x}'$, we first sample a component index from the gating, i.e., $o' \sim p(o|\mathbf{x})'$. The component index selects the respective expert to obtain $\mathbf{y}' \sim p(\mathbf{y}|\mathbf{x}', o')$.
% Using Bayes' rule, the gating can be further decomposed as $p(o|\mathbf{x}) \propto p(o) p(\mathbf{x}|o)$. Typically, the input components $p(\mathbf{x}|o)$ and mixture weights $p(o)$ are learned implicitly by optimizing a parameterized gating network \cite{jacobs1991adaptive, bishop1994mixture}. [To make the last part less random we can say that the gating is defined by mixture model using Bayes' rule; Explain sample procedure]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Moment and Information Projection}
The Kullback-Leibler (KL) divergence \cite{kullback1951information} is a similarity measure for probability distributions and is defined as $\KL ( p\Vert p') = \sum_{\mathbf{x}} p(\mathbf{x}) \log p(\mathbf{x})/p'(\mathbf{x})$. Due to its asymmetry, the KL divergence offers two different optimization problems for fitting a model distribution $p$ to a target distribution $p^*$ \cite{murphy2012machine}, that is,
\begin{equation*}
\begin{aligned}
\underbrace{\argmin_{\textcolor{forestgreen4416044}{p}} \ \KL ( \textcolor{steelblue31119180}{p^*}\Vert \textcolor{forestgreen4416044}{p})}_{\text{M(oment)-Projection}} \quad
\end{aligned}
 \begin{minipage}[t!]{0.14\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figures/m_proj_vis.pdf}
            % \captionof{figure}{Information}
            \vspace{0.03cm}
\end{minipage}
\end{equation*}
\vspace{-0.7cm}
and 
\begin{equation*}
\begin{aligned}
\underbrace{\argmin_{\textcolor{forestgreen4416044}{p}} \ \KL  ( \textcolor{forestgreen4416044}{p} \Vert \textcolor{steelblue31119180}{p^*})}_{\text{I(nformation)-Projection}}. \quad
\end{aligned}
 \begin{minipage}[t!]{0.14\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figures/i_proj_vis.pdf}
            \vspace{0.05cm}
            % \captionof{figure}{Moment}
\end{minipage}
\end{equation*}
% \begin{equation*}
% \begin{aligned}
% \underbrace{\min_{p}\KL ( {p^*}\Vert {p}) = \max_p \E_{p^*}[\log p(\mathbf{x})]}_{\text{M(oment)-Projection}}
% \end{aligned}
% \end{equation*}
% % \vspace{-0.7cm}
% and 
% \begin{equation*}
% \begin{aligned}
% \underbrace{{\min_{p}\KL  ( p \Vert {p^*})
% = \max_p \E_{p}[\log p^*(\mathbf{x})] + \mathcal{H}(\mathbf{x})}
% }_{\text{I(nformation)-Projection}}.
% \end{aligned}
% \end{equation*}
The M-projection - or equivalently maximum likelihood estimation (MLE) \cite{bishop2006pattern} - is \textit{probability forcing}, meaning that the model is optimized to match the moments of the target distribution, causing it to average over modes that it cannot represent. In contrast, the I-projection is \textit{zero forcing} which leads the model to ignore modes of the target distribution that it is not able to represent. The I-projection can be rewritten as maximization problem, i.e., 
\begin{equation}
\label{eq:i_proj}
    \argmax_p\  \E_{p(\mathbf{x})}[\log p^*(\mathbf{x})] + \mathcal{H}(\mathbf{x}).
\end{equation}
Using this formulation, it can be seen that the optimization balances between fitting the target distribution and keeping the entropy $\mathcal{H}(\mathbf{x}) = - \sum_{\mathbf{x}}p(\mathbf{x})\log p(\mathbf{x})$ high. 
% [Rewriting the KL as maximization problem.. expand the reverse KL.. Trade-off between fitting target density and match entropy. A trade of factor is often introduced to handle this exploration exploitation trade-off (cite max-ent RL). $\mathcal{H}(\mathbf{x}) = - \sum_{\mathbf{x}}p(\mathbf{x})\log p(\mathbf{x})$]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%