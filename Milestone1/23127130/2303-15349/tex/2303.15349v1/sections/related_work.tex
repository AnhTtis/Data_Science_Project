\section{Related Work}
\label{section:rw}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Mixtures of Experts.}
The mixture of experts model was first proposed by \citet{jacobs1991adaptive} and used expectation maximization \cite{dempster1977maximum} for optimizing the model parameters. 
Several studies are dedicated to increasing the flexibility of the model \cite{jordan1994hierarchical, waterhouse1998classification, bishop2012bayesian}.
% To obtain a more flexible model \citet{jordan1994hierarchical} introduced the hierarchical mixture of experts model where each component is a mixture model itself. Later, \citet{waterhouse1998classification} leveraged neural networks to parameterize the gating and experts. 
% So far, these models are all trained using the EM algorithm (\cite{dempster1977maximum}). 
On another note, \citet{bishop1994mixture} introduced the mixture density network (MDN) which uses a neural network whose parameters are shared between gating and experts, allowing for an end-to-end training using the backpropagation algorithm \cite{rumelhart1986learning}. All of these works maximize the likelihood to optimize the model parameters which corresponds to a moment projection. This differs from our approach which is inspired by the information projection. Recently, \citet{becker2020expected} introduced expected information maximization (EIM), an approach for computing the expected information projection based on samples from a dataset.
While EIM was mainly introduced in the context of density estimation, the authors mention that the algorithm is also applicable to conditional models. However, EIM relies on an intermediate density ratio estimation step, causing stability issues and preventing scaling to high dimensional problems. We, therefore, do not consider EIM as a competitive baseline. For an elaborate survey on mixture of experts models, the reader is referred to \citet{yuksel2012twenty} and \citet{masoudnia2014mixture}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Curriculum Learning.}
\citet{bengio2009curriculum} introduced curriculum learning (CL) as a new paradigm for training machine learning models by gradually increasing the difficulty of samples that are exposed to the model. Several studies followed this definition \cite{spitkovsky2009baby, soviany2022curriculum, chen2015webly, tudor2016hard, pentina2015curriculum, shi2015recurrent, zaremba2014learning}. Other studies used the term curriculum learning for gradually increasing the model complexity \cite{karras2017progressive, morerio2017curriculum, sinha2020curriculum} or task complexity \cite{caubriere2019curriculum, florensa2017reverse, lotter2017multi, sarafianos2017curriculum}. 
All of these approaches assume that the difficulty-ranking of the samples is known a-priori.
In contrast, we consider dynamically adapting the curriculum according to the learning progress of the model which is known as self-paced learning (SPL). 
Pioneering work in SPL was done by \citet{ kumar2010self} which is related to our work in that the authors propose to update the curriculum as well as model parameters iteratively. However, their method is based on maximum likelihood which is different from our approach. Moreover, their algorithm is restricted to latent structural support vector machines. 
% Less related work in SPL include work by \citet{jiang2014self} which encourages sample diversity in the curriculum and \citet{zhang2015self} which incorporates prior knowledge in the curriculum. More recent work applied SPL to the domain of reinforcement learning \cite{klink2020self, klink2020self2, celik2022specializing}.
For a comprehensive survey on curriculum learning, the reader is referred to \cite{soviany2022curriculum}.
