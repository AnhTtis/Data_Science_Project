\section{Conclusion}
% We introduced Information Maximizing Curriculum (IMC), a novel approach to learning mixture of expert policies. IMC is a curriculum-based approach that allows each expert to select its own subset of the training data for learning. The curriculum allows the MoE model to automatically ignore data points that it can not represent, which reduces the susceptibility to local optima and in particular to mode-averaging, a common problem associated with maximum likelihood-based optimization for multimodal density estimation. The maximization of the entropy of the joint curriculum of all experts incentivizes the MoE to cover all data samples.
% IMC is able to adapt the model complexity online by adding more experts during training which is enabled by the proposed objective. We motivated our objective for a single expert and generalized it to the MoE case. 
% We showed that our method is able to outperform existing optimization schemes for MoE and state-of-the-art generative models on challenging multimodal conditional density estimation problems. In particular, we employed behavior learning tasks to show that IMC is able \textit{i)} avoid mode averaging and \textit{ii)} extract all modes present in the data distribution.


% We introduced Information Maximizing Curriculum (IMC), a novel approach to conditional density estimation. In particular, IMC addresses mode-averaging, a common problem associated with maximum likelihood-based optimization for multimodal density estimation. This is important in imitation learning from human demonstrations, as the data distribution from human demonstrations is often highly multimodal due to the inherent versatility of their behavior.

We presented \textit{Information Maximizing Curriculum} (IMC), a novel approach for conditional density estimation, specifically designed to address mode-averaging issues commonly encountered when using maximum likelihood-based optimization in the context of multimodal density estimation. IMC's focus on mitigating mode-averaging is particularly relevant in imitation learning from human demonstrations, where the data distribution is often highly multimodal due to the diverse and versatile nature of human behavior.

IMC uses a curriculum to assign weights to the training data allowing the policy to focus on samples it can represent, effectively mitigating the mode-averaging problem. We extended our approach to a mixture of experts (MoE) policy, where each mixture component selects its own subset of the training data for learning, allowing the model to imitate the rich and versatile behavior present in the demonstration data. 

Our experimental results demonstrate the superior performance of our method compared to state-of-the-art policy learning algorithms and mixture of experts (MoE) policies trained using competing optimization algorithms. Specifically, on complex multimodal simulated control tasks with data collected from human demonstrators, our method exhibits the ability to effectively address two key challenges: \textit{i)} avoiding mode averaging and \textit{ii)} covering all modes present in the data distribution.

\textbf{Limitations.} 
While our current approach achieves state-of-the-art performance, there are still areas for improvement in parameterizing our model. Presently, we employ simple multilayer perceptrons to parameterize the expert policies. However, incorporating image observations would require a convolutional neural network (CNN) \cite{lecun1989backpropagation} backbone. Additionally, our current model relies on the Markov assumption, but relaxing this assumption and adopting history-based models like transformers \cite{vaswani2017attention} could potentially yield significant performance improvements.
Lastly, although this work primarily concentrates on continuous domains, an intriguing prospect for future research would be to explore the application of IMC in discrete domains.

\textbf{Broader Impact.} Improving imitation learning algorithms holds the potential to enhance the accessibility of robotic systems in real-world applications, with both positive and negative implications. We acknowledge that identifying and addressing any potential adverse effects resulting from the deployment of these robotic systems is a crucial responsibility that falls on sovereign governments.