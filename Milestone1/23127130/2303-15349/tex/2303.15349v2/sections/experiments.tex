\section{Experiments}
\begin{figure*}[t]
        \centering
        \begin{minipage}[t!]{0.235\textwidth}
            \centering 
            \includegraphics[width=\textwidth]{supplementary_material/figures/oa_env_final.png}
        \end{minipage}
        \hfill
        \begin{minipage}[t!]{0.235\textwidth}
            \centering 
            \includegraphics[width=\textwidth]{supplementary_material/figures/hbp_env_final.png}
        \end{minipage}
         \hfill
        \centering
        \begin{minipage}[t!]{0.35\textwidth}
            \centering 
            \includegraphics[width=\textwidth]{supplementary_material/figures/Fig_MT_table_tennis_env.pdf}
        \end{minipage}
         \hfill
        \caption[ ]
        {  \textbf{Behavior learning environments:} Visualization of the obstacle avoidance task (left), the block pushing task (middle), and the table tennis task (right).}
        \label{fig:environments}
    \end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
        \centering
        \begin{minipage}[t!]{0.17\textwidth}
            \centering
            \includegraphics[width=\textwidth]{results/obs_avoid/obsavoid_gt.pdf}
        \end{minipage}
        \hfill
         \begin{minipage}[t!]{0.17\textwidth}
            \centering
            \includegraphics[width=\textwidth]{results/obs_avoid/obsavoid_mdn.pdf}
        \end{minipage}
        \hfill
            \begin{minipage}[t!]{0.17\textwidth}
            \centering
            \includegraphics[width=\textwidth]{results/obs_avoid/obsavoid_em.pdf}
        \end{minipage}
        \hfill
        \begin{minipage}[t!]{0.17\textwidth}
            \centering 
            \includegraphics[width=\textwidth]{results/obs_avoid/obsavoid_diffusion.pdf}
        \end{minipage}
        \hfill
            \begin{minipage}[t!]{0.17\textwidth}
            \centering
            \includegraphics[width=\textwidth]{results/obs_avoid/obsavoid_nf.pdf}
        \end{minipage}
        \hfill
            \begin{minipage}[t!]{0.17\textwidth}
            \centering
            \includegraphics[width=\textwidth]{results/obs_avoid/obsavoid_vae.pdf}
        \end{minipage}
        \hfill
            \begin{minipage}[t!]{0.17\textwidth}
            \centering
            \includegraphics[width=\textwidth]{results/obs_avoid/obsavoid_ibc.pdf}
        \end{minipage}
        \hfill
            \begin{minipage}[t!]{0.17\textwidth}
            \centering
            \includegraphics[width=\textwidth]{results/obs_avoid/obsavoid_bet.pdf}
        \end{minipage}
        \hfill
        \begin{minipage}[t!]{0.17\textwidth}
            \centering 
            \includegraphics[width=\textwidth]{supplementary_material/ablations/franka/oa_ml_cur.pdf}
        \end{minipage}
        \hfill
        \begin{minipage}[t!]{0.17\textwidth}
            \centering 
            \includegraphics[width=\textwidth]{results/obs_avoid/obsavoid_imc.pdf}
        \end{minipage}
         \hfill
        \caption[ ]
        {  \textbf{Obstacle Avoidance:} Visualization of $100$ end-effector trajectories for all trained models. Every method is trained on diverse demonstration data (left). 
        MDN, NF, and IBC mostly fail to successfully solve the task. Other methods (EM, DDPM, CVAE, BET, ML-Cur) either fail to have high success rates or disregard modes in the data. Only IMC is able to perform well on both metrics.}
        \label{fig:planar_reacher_vis}
    \end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We briefly outline the key aspects of our experimental setup.

\textbf{Experimental Setup.} For all experiments, we employ conditional Gaussian expert policies, i.e., $p_{\vtheta_{\comp}}(\act|\obs,\comp) = \mathcal{N}(\act|\vmu_{\vtheta_{\comp}}(\obs), \sigma^2\textbf{I})$. Please note that we parameterize the expert means $\vmu_{\vtheta_{\comp}}$ using neural networks. For complex high-dimensional tasks, we share features between different expert policies by introducing a deep neural network backbone. 
Moreover, we use a fixed variance of $\sigma^2=1$ and $N_z = 50$ components for all experiments and tune the curriculum pacing $\eta$. For more details see Appendix \ref{section:imc_experiment_details}.

\textbf{Baselines.} We compare our method to state-of-the-art generative models including denoising diffusion probabilistic models (DDPM) \cite{ho2020denoising}, normalizing flows (NF) \cite{papamakarios2021normalizing} and conditional variational autoencoders (CVAE) \cite{sohn2015learning}. Moreover, we consider energy-based models for behavior learning (IBC) \cite{florence2022implicit} and the recently proposed behavior transformer (BeT) \cite{shafiullah2022behavior}. Lastly, we compare against mixture of experts trained using expectation maximization (EM) \cite{jacobs1991adaptive} and backpropagation (MDN) \cite{bishop1994mixture} and the ML-Cur algorithm \cite{li2023curriculum}. We extensively tune the hyperparameters of the baselines using Bayesian optimization \cite{snoek2012practical} on all experiments. 

\textbf{Evaluation.} For all experiments we perform multiple simulations using the trained policies to compute the performance metrics. Firstly, we report the \textit{success rate}, which is the fraction of simulations that led to successful task completion, reflecting the susceptibility to mode averaging. Secondly, we compute a task-specific (categorical) distribution over pre-defined behaviors that lead to successful task completion. Thereafter, we compute the \textit{entropy} over this distribution to quantify the diversity in the learned behaviors and therefore the ability to cover multiple modes present in the data distribution. An entropy of 0 implies that a model executes the same behavior, while higher entropy values indicate that the model executes different behaviors. Further details are provided in the descriptions of individual tasks. 
%
%
%
%
% \red{
% \textbf{Evaluation.} For all experiments we perform multiple simulations using the trained policies to compute the performance metrics. Firstly, we report the \textit{success rate}, which is the fraction of simulations that led to successful task completion which reflects the susceptibility to mode averaging. Secondly, we compute a task-specific distribution $p(\beta)$ which is a categorical distribution over diverse behaviors $\tau \in \mathcal{T}$ that lead to successful task completion. We use $p(\beta)$ to quantify if a model is able to cover all modes present in the data distribution via \textit{entropy}, i.e., 
% \begin{equation}
% \label{eq:ent}
%     \mathcal{H}(\beta) = - \sum_{\beta\in \mathcal{T}} p(\beta) \log_{|\mathcal{T}|} p(\beta).
% \end{equation}
%  We use a base of $|\mathcal{T}|$ in the logarithm to ensure that the entropy value is between 0 and 1. An entropy of 0 implies that a model executes the same behavior, while an entropy of 1 indicates that the model executes all behaviors $\tau \in \mathcal{T}$ with equal probability. Further details about the behavior space $\mathcal{T}$ are provided in the descriptions of individual tasks.
% %
% %
% %
% %
% }

We report the mean and the standard deviation over ten random seeds for all experiments. For a detailed explanation of tasks, data, performance metrics, and hyperparameters see Appendix \ref{appendix:experiment_setup}. For further experimental results see Appendix \ref{appendix:algo_details}. The
code is available online \footnote{\url{https://github.com/ALRhub/imc}}.%\red{Ablation studies.}
% \begin{itemize}
%     \item Briefly mention structure of experiments: We introduce the environment with goals. Then the data. Then the metrics. 
% \end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{sections/result_table.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{section:experiments}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{UCI Regression}
% \begin{table}[t]
% \caption{\textbf{UCI regression}: Comparison between various combining methods on UCI regression datasets.}
% \label{table:obs_avoid}
% \vskip 0.15in
% \begin{center}
% \begin{small}
% \begin{sc}
% \begin{tabular}{lcccc}
% \toprule
%     Dataset & {Na\"ive} & {EM} & {MDN} &  {IMC}  \\ 
%     \midrule
%     Boston
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     \\
%     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Concrete
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     \\
%     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Energy
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     \\
%     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Kin8nm
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$ 
%     \\
%     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Power
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     \\
%     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Protein
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     \\
%     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Wine
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     \\
%     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Yacht
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     & $- \scriptstyle{\pm -}$
%     \\
%     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     \bottomrule
%   \end{tabular}
% \end{sc}
% \end{small}
% \end{center}
% \vskip -0.1in
% \end{table}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Obstacle Avoidance}
\label{section:obs_avoid}
The obstacle avoidance environment is visualized in Figure \ref{fig:environments} (left) and consists of a seven DoF Franka Emika Panda robot arm equipped with a cylindrical end effector simulated using the MuJoCo physics engine \cite{todorov2012mujoco}.  The goal of the task is to reach the green finish line without colliding with one of the six obstacles.
% There are $24$ different ways to avoid the obstacles and solve the task. For each way there are four human demonstrations in the dataset collected using a game-pad controller.
The dataset contains four human demonstrations for all ways of avoiding obstacles and completing the task. It is collected using a game-pad controller and inverse kinematics (IK) in the xy-plane amounting to $7.3$k $(\obs, \act)$ pairs.
The observations $\obs \in \mathbb{R}^{4}$ contain the end-effector position and velocity of the robot. 
The actions $\act \in \mathbb{R}^{2}$ represent the desired position of the robot. 
There are 24 different ways of avoiding obstacles and reaching the green finish line, each of which we define as a different behavior $\beta$. At test time, we perform $1000$ simulations for computing the success rate and the entropy $\mathcal{H}(\beta) = - \sum_{\beta} p(\beta) \log_{24} p(\beta)$. Please note that we use $\log_{24}$ for the purpose of enhancing interpretability, as it ensures $\mathcal{H}(\beta)\in [0,1]$. An entropy value of 0 signifies a policy that consistently executes the same behavior, while an entropy value of 1 represents a diverse policy that executes all behaviors with equal probability and hence matches the true behavior distribution by design of the data collection process.
The results are shown in Table \ref{table:result_table}. Additionally, we provide a visualization of the learned curriculum in Figure \ref{fig:cur_vis}. Further details are provided in Appendix \ref{appendix:obs_avoidance}.
% To evaluate the susceptibility to mode averaging, we use the \textit{success rate}, i.e., the percentage of trajectories that reach the finish line. Moreover, we assess a model's ability to learn multimodal distributions by computing the \textit{entropy} of the categorical distribution that contains the  probabilities of a model completing the different ways of avoiding obstacles.  
% % successful trajectories $\beta$, that is, $\mathcal{H}_{24}(\beta) = - \sum_\beta p(\beta) \log_{24} p(\beta)$. Note that we use $\log_{24}$ for easier comparison since $\mathcal{H}_{24}(\beta)\in [0, 1]$. 
% For more details see Appendix \ref{appendix:obs_avoidance}. For a visual illustration of end-effector trajectories see Figure \ref{fig:planar_reacher_vis}. The results  and are generated using $1000$ evaluation trajectories for each seed. \red{Add visual explanation.}
% CVAE achieves the highest success rate but only discovers few modes as indicated by the low entropy value. In contrast, IMC achieves the highest entropy while closely following the success rate of CVAE. 
% [Put the exact number of samples in the appendix]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t!]
        \centering
        \begin{minipage}[t!]{\textwidth}
            \centering
            \begin{minipage}[t!]{0.19\textwidth}
            \includegraphics[width=\textwidth]{figures/curr_vis/oa_cur_nc1.pdf}
            \subcaption[]{\scriptsize{$N_z=1$}}
            \label{fig:oa_cur_nc1}
            \end{minipage}
            \begin{minipage}[t!]{0.19\textwidth}
            \includegraphics[width=\textwidth]{figures/curr_vis/oa_cur_nc3.pdf}
            \subcaption[]{\scriptsize{$N_z=3$}}
            \label{fig:oa_cur_nc3}
            \end{minipage}
            \begin{minipage}[t!]{0.19\textwidth}
            \includegraphics[width=\textwidth]{figures/curr_vis/oa_cur_nc5.pdf}
            \subcaption[]{\scriptsize{$N_z=5$}}
            \label{fig:oa_cur_nc5}
            \end{minipage}
            \begin{minipage}[t!]{0.19\textwidth}
            \includegraphics[width=\textwidth]{figures/curr_vis/oa_cur_nc10.pdf}
            \subcaption[]{\scriptsize{$N_z=10$}}
            \label{fig:oa_cur_nc10}
            \end{minipage}
            \begin{minipage}[t!]{0.19\textwidth}
            \includegraphics[width=\textwidth]{figures/curr_vis/oa_imc_curr.pdf}
            \subcaption[]{\scriptsize{Dataset}}
            \label{fig:oa_cur_data}
            \end{minipage}
        \end{minipage}
        \caption[ ]
        %Performance comparison between the EM and IMC algorithm for an increasing number of components.
        {\textbf{Curriculum Visualization:} Visualization of the curricula $\curpc$ for a different number of components $N_z$ on the obstacle avoidance task. The color indicates different components $z$ and the size of the dots is proportional to $p(\obs_n, \act_n|z)$. For $N_z=1$ we observe that the model ignores most samples in the dataset as a single expert is not able to achieve high log-likelihood values $p_{\vtheta_z}$ on all samples (Figure \ref{fig:oa_cur_nc1}). Adding more components to the model results in higher coverage of samples as shown in Figure \ref{fig:oa_cur_nc3}-\ref{fig:oa_cur_nc10}. Figure \ref{fig:oa_cur_data} visualizes all samples contained in the dataset.}
        \label{fig:cur_vis}
    \end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{figure}[t]
% \centering
% \resizebox{0.23\textwidth}{!}{\includegraphics[width=\textwidth]{results/obs_avoid/Fig:ICML23:obsavoid_success.pdf}}
% \resizebox{0.23\textwidth}{!}{\includegraphics[width=\textwidth]{results/obs_avoid/Fig:ICML23:obsavoid_entropy.pdf}}
%     \caption{\small \textbf{Obstacle Avoidance.} Comparison between the EM and IMC algorithm for training mixtures of experts for an increasing number of components.
%     }
%     \label{fig:obs_avoid_res}
% \end{figure}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Block Pushing}
The block pushing environment is visualized in Figure \ref{fig:environments} (middle) and uses the setup explained in Section \ref{section:obs_avoid}. The robot manipulator is tasked to push blocks into target zones. 
Having two blocks and target zones amounts to four different push sequences (see e.g. Figure \ref{fig:box_env_trajs}), each of which we define as a different behavior $\beta$.
Using a gamepad, we recorded $500$ demonstrations for each of the four push sequences with randomly sampled initial block configurations $\obs_0$ (i.e., initial positions and orientations),
amounting to a total of $463$k $(\obs, \act)$ pairs. The observations $\obs \in \mathbb{R}^{16}$ contain information about the robot's state and the block configurations. The actions $\act \in \mathbb{R}^{2}$ represent the desired position of the robot.
We evaluate the models using three different metrics: Firstly, the \textit{success rate} which is the proportion of trajectories that manage to push both boxes to the target zones.
Secondly, the \textit{entropy}, which is computed over different push sequences $\beta$. Since high entropy values can be achieved by following different behaviors for different initial block configurations $\obs_0$ in a deterministic fashion, the entropy of $p(\beta)$ can be a poor metric
for quantifying diversity. Hence, we evaluate the expected entropy conditioned on the
initial state $\obs_0$, i.e., $\E_{p(\obs_0)} \big[\mathcal{H}(\beta|\obs_0) \big] \approx - \frac{1}{N_0} \sum_{\obs_0 \sim p(\obs_0)} \sum_{\beta} p(\beta|\obs_0) \log_{4} p(\beta| \obs_0)$. If, for the same $\obs_0$, all behaviors can be achieved, the expected entropy is high. In contrast, the entropy is 0 if the same behavior is executed for the same $\obs_0$. Here, $p(\obs_0)$ and $N_0$ denote the distribution over initial block configurations and the number of samples respectively. See Appendix  \ref{appendix:block_pushing} for more details. 
% The expected \textit{entropy} over
% a categorical distribution containing the probabilities of a model completing different push sequences conditioned on the initial block configuration. 
Lastly, we quantify the performance on non-successful trajectories, via \textit{distance error}, i.e., the distance from the blocks to the target zones at the end of a trajectory. The success rate and distance error indicate whether a model is able to avoid averaging over different behaviors. The entropy assesses the ability to represent multimodal data distributions by completing different push sequences. 
The results are reported in Table \ref{table:result_table} and generated by simulating $16$ evaluation trajectories for $30$ different initial block configurations $\obs_0$ per seed. The difficulty of the task is reflected by the low success rates of most models. Besides being a challenging manipulation task, the high task complexity is caused by having various sources of multimodality in the data distribution: First, the inherent versatility in human behavior. Second, multiple human demonstrators, and lastly different push sequences for the same block configuration.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{figure}[t]
%         \centering
%         \begin{minipage}[t!]{0.11\textwidth}
%             \centering 
%             \includegraphics[width=\textwidth]{supplementary_material/figures/gg_rr_env_023_05.pdf}
%         \end{minipage}
%         \hfill
%         \begin{minipage}[t!]{0.11\textwidth}
%             \centering 
%             \includegraphics[width=\textwidth]{supplementary_material/figures/rr_gg_env_009_05.pdf}
%         \end{minipage}
%          \hfill
%         \centering
%         \begin{minipage}[t!]{0.11\textwidth}
%             \centering 
%             \includegraphics[width=\textwidth]{supplementary_material/figures/gr_rg.pdf}
%         \end{minipage}
%         \hfill
%         \begin{minipage}[t!]{0.11\textwidth}
%             \centering 
%             \includegraphics[width=\textwidth]{supplementary_material/figures/rg_gr.pdf}
%         \end{minipage}
%          \hfill
%         \caption[ ]
%         {\small Bird view of the block push data for 4 modes. In this task, robot starts from a fixed position and the gray lines refer to the trajectory of the robot's end effector. Two push boxes' trajectories are represented by red box and green box.}
%         \label{fig:box_env}
%     \end{figure}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Franka Kitchen}
The Franka kitchen environment was introduced in \cite{gupta2019relay} and uses a seven DoF Franka Emika Panda robot with a two DoF gripper to interact with a simulated kitchen environment. The corresponding dataset contains $566$ human-collected trajectories recorded using a virtual reality setup amounting to $128$k $(\obs, \act)$ pairs. Each trajectory executes a sequence completing four out of seven different tasks. The observations $\obs \in \mathbb{R}^{30}$ contain information about the position and orientation of the task-relevant objects in the environment. The actions $\act \in \mathbb{R}^{9}$ represent the control signals for the robot and gripper. To assess a model's ability to avoid mode averaging we again use the \textit{success rate} over the number of tasks solved within one trajectory. For each number of solved tasks $\in \{1,2,3,4\}$, we define a behavior $\beta$ as the order in which the task is completed and use the entropy $\mathcal{H}(\beta) = - \sum_{\beta} p(\beta) \log p(\beta)$ to quantify diversity. The results are shown in Figure \ref{fig:kitchen_res} and are generated using $100$ evaluation trajectories for each seed. There are no results reported for IBC, MDN and ML-Cur as we did not manage to obtain reasonable results. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{figure*}[t]
% \centering
% \resizebox{0.4\textwidth}{!}{\includegraphics[width=\textwidth]{results/kitchen/fk_legend.pdf}}
% \resizebox{0.23\textwidth}{!}{\includegraphics[width=\textwidth]{results/kitchen/fk_success.pdf}}
% \resizebox{0.23\textwidth}{!}{\includegraphics[width=\textwidth]{results/kitchen/fk_entropy.pdf}}
%     \caption{\textbf{Franka Kitchen:} Performance comparison between various generative models.
%     }
%     \label{fig:kitchen_res}
% \end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{wrapfigure}{R}{0.6\textwidth}
% \centering
% \resizebox{0.59\textwidth}{!}{\includegraphics[width=\textwidth]{results/kitchen/fk_legend.pdf}}
% \resizebox{0.29\textwidth}{!}{\includegraphics[width=\textwidth]{results/kitchen/fk_success.pdf}}
% \resizebox{0.29\textwidth}{!}{\includegraphics[width=\textwidth]{results/kitchen/fk_entropy.pdf}}
%       % \vspace{-0.7cm}
%     \caption{\textbf{Franka Kitchen:} 
%     % Performance comparison between various policy learning algorithms, evaluating the success rate and entropy for a varying number of task completions. IMC is able to outperform the baselines in both metrics, achieving a high success rate while showing a higher diversity in the task sequences. 
%     Performance comparison between various policy learning algorithms. IMC is more successful in completing tasks (success rate) while at the same time having the highest diversity in the sequence of task completions (entropy).
%     }
%     \label{fig:kitchen_res}
%     \vspace{-0.35cm}
% \end{wrapfigure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
        \centering
        \begin{minipage}[t!]{\textwidth}
            \centering 
            \includegraphics[width=.8\textwidth]{results/kitchen/fk_legend.pdf}
            \includegraphics[width=0.4\textwidth]{results/kitchen/fk_success.pdf}
            \includegraphics[width=0.4\textwidth]{results/kitchen/fk_entropy.pdf}
        \end{minipage}
         \hfill
        \caption[ ]
        %Performance comparison between the EM and IMC algorithm for an increasing number of components.
        { \textbf{Franka Kitchen:} Performance comparison between various policy learning algorithms, evaluating the success rate and entropy for a varying number of task completions. IMC is able to outperform the baselines in both metrics, achieving a high success rate while showing a higher diversity in the task sequences. 
    Performance comparison between various policy learning algorithms. IMC is more successful in completing tasks (success rate) while at the same time having the highest diversity in the sequence of task completions (entropy). }
        \label{fig:ablation}
    \end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Table Tennis}
The table tennis environment is visualized in Figure \ref{fig:environments} (right) and consists of a seven DOF robot arm equipped with a table tennis racket and is simulated using the MuJoCo physics engine. The goal is to return the ball to varying target positions after it is launched from a randomized initial position. Although not collected by human experts, the $5000$ demonstrations are generated using a reinforcement learning (RL) agent that is optimized for highly multimodal behavior such as backhand and forehand strokes \cite{celik2022specializing}. Each demonstration consists of an observation $\obs \in \mathbb{R}^4$ defining the initial and target ball position. Movement primitives (MPs) \cite{paraschos2013probabilistic} are used to describe the joint space trajectories of the robot manipulator using two basis functions per joint and thus $\act \in \mathbb{R}^{14}$. We evaluate the model performance using the \textit{success rate}, that is, how frequently the ball is returned to the other side. Moreover, we employ the \textit{distance error}, i.e., the Euclidean distance from the landing position of the ball to the target position. Both metrics reflect if a model is able to avoid averaging over different movements. 
For this experiment, we do not report the entropy as we do not know the various behaviors executed by the RL agent.
% For this experiment, there is no metric to assess multimodality as it is difficult to quantify the diversity in the model behavior. 
The results are shown in Table \ref{table:result_table} and are generated using $500$ different initial and target positions. Note that the reinforcement learning agent used to generate the data achieves an average success rate of $0.91$ and a distance error of $0.14$ which is closely followed by IMC. 
% \begin{figure}[t]
% \centering
% % \resizebox{0.46\textwidth}{!}{\includegraphics[width=\textwidth]{results/Fig:TableTennisLegend.pdf}}
% \resizebox{0.23\textwidth}{!}{\includegraphics[width=\textwidth]{results/Fig:TableTennisStrike.pdf}}
% \resizebox{0.23\textwidth}{!}{\includegraphics[width=\textwidth]{results/Fig:TableTennisDistance.pdf}}
%     \caption{\small \textbf{Table Tennis.} Comparison between the EM and IMC algorithm for training mixtures of experts for an increasing number of components. Additionally, the expert performance is reported. 
%     }
%     \label{fig:tt_algocomp}
% \end{figure}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Ablation Studies}

Additionally, we compare the performance of IMC with EM for a varying number of components on the obstacle avoidance and table tennis task.
 The results are shown in Figure \ref{fig:ablation} and highlight the properties of the moment and information projection: Using limited model complexity, e.g. $1$ or $5$ components, EM suffers from mode averaging, resulting in poor performances (Figure \ref{fig:ablation_performance_{\comp}bstacle_avoidance} and Figure \ref{fig:ablation_performance_tabletennis}). This is further illustrated in Figure \ref{fig:ablation_EM_{\comp}bstacle_avoidance}. In contrast, the zero forcing property of the information projection allows IMC to avoid mode averaging (see Figure \ref{fig:ablation_IMC_{\comp}bstacle_avoidance}) which is reflected in the success rates and distance error for a small number of components. The performance gap between EM and IMC for high model complexities suggests that EM still suffers from averaging problems. Moreover, the results show that IMC needs fewer components to achieve the same performance as EM.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
        \centering
        \begin{minipage}[t!]{0.49\textwidth}
            \centering
            \includegraphics[width=.49\textwidth]{results/obs_avoid/obsavoid_success.pdf}
            \includegraphics[width=.49\textwidth]{results/obs_avoid/obsavoid_entropy.pdf}
            \subcaption[]{\scriptsize{Obstacle avoidance performance comparison.}}
            \label{fig:ablation_performance_{\comp}bstacle_avoidance}
        \end{minipage}
                \hfill
        \begin{minipage}[t!]{0.49\textwidth}
            \centering 
            \includegraphics[width=.49\textwidth]{results/TableTennisStrike.pdf}
            \includegraphics[width=.49\textwidth]{results/TableTennisDistance.pdf}
            \subcaption[]{\scriptsize{Table tennis performance comparison.}}
            \label{fig:ablation_performance_tabletennis}
        \end{minipage}
         \hfill
         \begin{minipage}[t!]{0.49\textwidth}
            \centering 
            \includegraphics[width=.32\textwidth]{supplementary_material/figures/obstacle_avoid_figures/obsavoid_em_1c.pdf}
            \includegraphics[width=.32\textwidth]{supplementary_material/figures/obstacle_avoid_figures/obsavoid_em_5c.pdf}
            \includegraphics[width=.32\textwidth]{supplementary_material/figures/obstacle_avoid_figures/obsavoid_em_10c.pdf}
            \subcaption[]{\scriptsize{Obstacle avoidance end-effector trajectories for EM.}}
            \label{fig:ablation_EM_{\comp}bstacle_avoidance}
        \end{minipage}
         \hfill
         \begin{minipage}[t!]{0.49\textwidth}
            \centering 
            \includegraphics[width=.32\textwidth]{supplementary_material/figures/obstacle_avoid_figures/obsavoid_imc_1c.pdf}
            \includegraphics[width=.32\textwidth]{supplementary_material/figures/obstacle_avoid_figures/obsavoid_imc_5c.pdf}
            \includegraphics[width=.32\textwidth]{supplementary_material/figures/obstacle_avoid_figures/obsavoid_imc_10c.pdf}
            \subcaption[]{\scriptsize {Obstacle avoidance end-effector trajectories for IMC.}}
            \label{fig:ablation_IMC_{\comp}bstacle_avoidance}
        \end{minipage}
         \hfill
        \caption[ ]
        %Performance comparison between the EM and IMC algorithm for an increasing number of components.
        { \textbf{Obstacle Avoidance:} IMC and EM improve the success rate and entropy with an increasing number of components (a). For a small number of components, IMC archives a high success rate, as it allows the policy to focus on data that it can represent. In contrast, the policy trained with EM fails as it is forced to cover the whole data. This is visualized in the end-effector trajectories (c + d).  Similar observations can be made for \textbf{Table Tennis:} Both performance metrics increase with a higher number of components. IMC manages to achieve good performance with a small number of components. }
        \label{fig:kitchen_res}
    \end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%