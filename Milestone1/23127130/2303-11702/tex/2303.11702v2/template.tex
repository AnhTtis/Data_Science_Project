\documentclass{article}

\usepackage{arxiv}
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc}  
\usepackage{hyperref}      
\usepackage{url}           
\usepackage{booktabs}       
\usepackage{amsfonts}       
\usepackage{nicefrac}       
\usepackage{microtype}     
\usepackage{lipsum}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{diagbox}
\usepackage{subcaption}
\usepackage{lineno}
\usepackage{biblatex}
\usepackage{algorithm} 
\usepackage{algpseudocode} 
\usepackage{amssymb}
\usepackage{caption} 
\usepackage[flushleft]{threeparttable}
\usepackage{setspace}
\usepackage{wrapfig}

\captionsetup[table]{skip=10pt}

\setlength{\tabcolsep}{10pt}
\renewcommand{\arraystretch}{1.5}


\addbibresource{references.bib}

\title{Linking generative semi-supervised learning and generative open-set recognition}

\author{
  Emile Reyn Engelbrecht \\
  Main author \\
  Electronic Engineering \\
  Stellenbosch University \\
  South Africa \\
  \texttt{18174310@sun.ac.za} \\
  %% examples of more authors
   \And
  Johan A. du Preez \\
  Co-author \\
  Electronic Engineering \\
  Stellenbosch University \\
  South Africa \\
  \texttt{dupreez@sun.ac.za} \\
}

\begin{document}
\maketitle
\begin{abstract}
\doublespacing
This study investigates the relationship between semi-supervised learning (SSL) and open-set recognition (OSR) in the context of generative adversarial networks (GANs). Although no previous study has formally linked SSL and OSR, their respective methods share striking similarities. Specifically, SSL-GANs and OSR-GANs require their generators to produce samples in the complementary space. Subsequently, by regularising networks with generated samples, both SSL and OSR classifiers generalize the open space. To demonstrate the connection between SSL and OSR, we theoretically and experimentally compare state-of-the-art SSL-GAN methods with state-of-the-art OSR-GAN methods. Our results indicate that the SSL optimised margin-GANs, which have a stronger foundation in literature, set the new standard for the combined SSL-OSR task and achieves new state-of-other art results in certain general OSR experiments. However, the OSR optimised adversarial reciprocal point (ARP)-GANs still slightly out-performed margin-GANs at other OSR experiments. This result indicates unique insights for the combined optimisation task of SSL-OSR.
\end{abstract} 

% keywords can be removed
\keywords{\doublespacing Inductive classification \and Novelty detection \and Open-set recognition \and Semi-supervised learning \and LACU \and Unknown category \and Augmented category }



%labelling vs annotation
%Classifier vs model
\newpage

\section{Introduction}
\doublespacing
Classification involves categorizing input data samples into known/labeled categories. However, classifiers must also be equipped to handle novel categories that may emerge over time~\cite{geng2020recent, yang2021generalized}. Two important applications of such classifiers are 1) automated diagnostic tools~\cite{pang2021semi, pahar2021automatic} and 2) self-driving cars~\cite{wu2019semi}. In both cases, it is crucial that classifiers make very few mistakes, as misclassifications can lead to fatal consequences. To address this, classifiers must be able to detect and separate novel categories that were not present during training but appeared during testing. For example, 1) classifiers should call on human doctors when encountering an unknown disease (e.g. SARS-CoV-2 pre-December 2020~\cite{andersen2020proximal}), and 2) classifiers must alert driving modules to safely manoeuvre out of the way or demand manual takeover in case of unexpected driving scenes (e.g. unexpected obstacles~\cite{ramos2017detecting}, or high-risk scenarios~\cite{puertas2021should}).

Open-set recognition (OSR) tests classifiers' ability to handle both labeled categories and novel categories unobserved during training~\cite{geng2020recent}. More specifically, OSR requires classifiers to correctly classify samples belonging to the $K$ labeled categories and accurately detect and separate samples that belong to unobserved novel categories. Although OSR is defined independently of the training method, most OSR studies use supervised learning. More specifically, OSR models are generally trained from datasets wherein all training samples have one of $K$ labels. This approach can be costly in real-world applications, and so it is often preferred to use the alternative of semi-supervised learning (SSL), which can achieve high accuracy using fewer labeled samples~\cite{van2020survey}. However, despite its cost-effectiveness, SSL has rarely been linked to OSR, with no previous study exploring this relationship on a theoretical level.

SSL and OSR have striking similarities in their methods, particularly when using generative adversarial networks (GANs) (SSL -~\cite{NIPS2016_8a3363ab, dai2017good, kumar2017semi, NEURIPS2019_517f24c0, li2020semi} and OSR -~\cite{ge2017generative, neal2018open, jo2018open, chen2021adversarial}). Consider the classification boundaries of a typical closed-set classifying network with a softmax output activation function (\cite{goodfellow_deep_learning}) for $K$ output nodes in Fig.~\ref{fig:1a} and Fig.~\ref{fig:1b}. Clearly, closed-set classifiers aim to maximize the classification boundaries or margins between categories, but this is insufficient for both SSL~\cite{dai2017good} and OSR~\cite{chen2021adversarial}. More specifically, for high accuracy SSL, the classifier must also generalize the complementary space~\cite{NIPS2016_8a3363ab, dai2017good} (see Fig. \ref{fig:2a}). Similarly, for high-accuracy OSR, the classifier must appropriately generalize the open space~\cite{chen2021adversarial} (see Fig. \ref{fig:2b}). However, through theoretical and experimental comparisons, we will show that generalizing the complementary and open spaces result in similar classifiers.

% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol

The general idea behind SSL-GANs and OSR-GANs is to generalize an additional $K + 1$'th category to represent necessary embedding spaces. In SSL-GANs, this additional category represents the complementary space to the labeled categories or the area around the classification boundaries of labeled categories. In OSR-GANs, this additional category represents the open space where novel categories reside. SSL-GANs and OSR-GANs use generated samples from GAN variations to generalize their respective $K + 1$'th categories. However, because of their similar nature, the $K + 1$'th categories of both SSL-GANs and OSR-GANs end up representing the same areas in the embedding space. More specifically, our results show that the generated samples of both SSL-GANs and OSR-GANs lie within the complementary space. Furthermore, when using these complementary samples to generalize the $K + 1$'th category, classifiers in both SSL-GANs and OSR-GANs generalize the open space. 

Considering the cost-efficiency of SSL, and the safety of OSR, it is clearly beneficial to train models using an SSL approach and test them under OSR conditions. This study provides the foundation for more practical SSL-OSR training by theoretically linking SSL and OSR under the common framework of GANs. The study is divided into two phases. The first phase examines the state-of-the-art OSR-GAN, namely adversarial reciprocal point (ARP)-GANs~\cite{chen2021adversarial}. In this first phase we integrate an established SSL-GAN, namely feature-matching (FM)-GANs~\cite{NIPS2016_8a3363ab}, into the ARP-GAN codebase. Both models are evaluated under SSL, OSR, and combined SSL-OSR experiments. The results show that both models perform similarly, with FM-GANs displaying slightly better SSL performance and ARP-GANs displaying slightly better OSR performance. Furthermore, a closer examination of the resulting embedding spaces reveals that both ARP-GANs and FM-GANs end up generalizing the same areas within their $K + 1$'th categories. 

The first phase establishes a clear theoretical connection between SSL-GANs and OSR-GANs. However, since the ARP-GAN codebase was optimized for OSR, the SSL results do not compare to the current state-of-the-art SSL-GAN methods. Therefore, in the second phase, we turn to the state-of-the-art SSL-GAN method of margin-GANs~\cite{NEURIPS2019_517f24c0}. Margin-GANs propose margin-theory which is directly related to the discussion of the complementary and open space. However, margin-GANs have never before been applied to OSR. Through thorough experiments, this second phase shows that margin-GANs also generate samples in the complementary space and so also generalize the open space within the resulting classifier. Furthermore, margin-GANs are found to set the new standard for the combined task of SSL-OSR while also outperforming ARP-GANs in certain OSR tasks.

\begin{figure*}[!t]
\centering
\subfloat[Example domain]{\includegraphics[width=0.35\textwidth]{1.png}
\label{fig:1a}}
\hfil
\centering
\subfloat[Classification boundaries]{\includegraphics[width=0.35\textwidth]{2.png}
\label{fig:1b}}
\caption{\doublespacing Different classification boundaries of a 2D example domain with $K = 3$ - (a) describes the 2D domain with each category represented by a different shape and colour; (b) describes the classification boundaries of a typical closed set classifier with a softmax output activation function.}
\label{fig:1}
\end{figure*}

It is important to note that this study does not focus on optimisation. Instead, we only aim to prove the hypothesis that SSL-GANs and OSR-GANs function similarly, meaning models from either fields could be used for their opposite fields and the combined SSL-OSR field. Nevertheless, since margin-GANs were optimised for SSL, these models are found to outperform the OSR optimised ARP-GANs by a significant degree. Future studies could certainly optimise ARP-GANs for SSL to provide stronger baselines for these models, yet our results conclude that SSL-GANs and OSR-GANs function similarly. Our results also establish the foundation for future studies to combine the theory of SSL and OSR to uniformly optimise models for the SSL-OSR task. 
 
The remainder of this paper is structured as follows: in Section~2, we provide background information on SSL, OSR, and the previous research on the links between these fields; in Section~3, we conduct the first phase by comparing FM-GANs and ARP-GANs under the same experimental conditions; in Section~4, we conduct the second phase by thoroughly experimenting on margin-GANs; in Section~5, we discuss the results from both phases; and in Section~6, we conclude the study. The main contributions of this study include being the first study to theoretically link SSL and OSR, being the first to conduct thorough SSL-OSR experiments, and setting the new standard for SSL-OSR and general OSR performance.  

\begin{figure*}[!t]
\centering
\centering
\subfloat[Complementary space]{\includegraphics[width=0.35\textwidth]{4.png}
\label{fig:2a}}
\hfil
\centering
\subfloat[Open space]{\includegraphics[width=0.35\textwidth]{3.png}
\label{fig:2b}}
\caption{\doublespacing Visual representation of the embedding spaces generalised within the $K + 1$'th categories (a) shows the complementary space of the each category as required for SSL, which is depicted by the 'x's around each category; and (b) shows the open space of the domain which is represented by the white area as required for OSR.}
\label{fig:2}
\end{figure*}

\section{Background}
Novel categories are formally defined as groups of anomalous samples with similar patterns that do not match any of the labeled categories~\cite{gruhl2021novelty}. Within open-set recognition (OSR), novel categories are further described as only appearing after training~\cite{pimentel2014review, geng2020recent, yang2021generalized}. In other words, OSR defines novel categories as unobserved categories that appear over time in changing environments~\cite{din2021data}. Models handle unobserved novel categories in one of two ways: 1) in class-incremental learning (CIL), a new label is defined for each novel category as it is discovered~\cite{belouadah2020comprehensive, zhang2020class}; or 2) in OSR, samples that belong to novel categories are separated into a different pile commonly referred to as the 'background/unknown' category. This study focuses on on OSR, which we note is a natural pre-step to achieving CIL.

OSR requires trained models to accurately classify samples that belong to $K > 1$ number of labeled categories and simultaneously separate samples that belong to any number of unobserved novel categories into an additional $K + 1$'th category. Unobserved novel categories are in contrast to observed novel categories found in variations of semi-supervised learning (SSL) research~\cite{yu2020multi, da2014learning, blanchard2010semi, chen2020semi}. More specifically, the fields of open-set semi-supervised learning (open-SSL)~\cite{yu2020multi}, learning with augmented category by exploiting unlabeled data (LACU)~\cite{da2014learning, engelbrecht2020learning}, semi-supervised novelty detection (SSND)~\cite{blanchard2010semi} and mismatched semi-supervised learning (MSSL)~\cite{chen2020semi}, define novel categories as those with samples scattered in unlabeled training sets. However, these novel categories are instead described as observed novel categories~\cite{engelbrecht2020open}, where OSR focuses on unobserved novel categories.

With regards to training, supervised learning uses a labeled training set, $\mathcal{D}_{\text{train}} := \mathcal{D}_{\text{lab-train}}$, that consists of paired samples $(x, y)$, where $x$ is the input sample and $y$ is the category label. The set $C_K := \{1, 2, ..., K\}$ is defined, where each entry in $C_K$ represents a unique label for one of the $K$ labeled categories. All training labels in supervised learning fall within $C_K$, or ${y \sim \mathcal{D}_{\text{lab-train}}} \in C_K$. SSL extends supervised learning by incorporating an additional set of unlabeled training samples, $\mathcal{D}_{\text{train}} := \mathcal{D}_{\text{lab-train}} \cup \mathcal{D}_{\text{unlab-train}}$. According to the SSL cluster assumption~\cite{van2020survey}, unlabeled training samples are assumed to belong to one of the labeled categories. Thus, samples in $\mathcal{D}_{\text{unlab-train}}$ can be represented as $(x, y_a)$, where $x$ is the input sample, and $y_a$ is the anticipated category label. In turn, general SSL has all ${y \sim \mathcal{D}_{\text{lab-train}}} \in C_K$ and ${y_a \sim \mathcal{D}_{\text{unlab-train}}} \in C_K$. 

It is important to note that GANs have been extensively studied for traditional SSL~\cite{sajun2022survey}. Initially, GAN based SSL methods transformed the discriminator to classify real samples into their respective labeled categories~\cite{springenberg2015unsupervised, odena2016semi, NIPS2016_8a3363ab, dai2017good, kumar2017semi, xu2021semi}. However, state-of-the-art models now prefer a three-network game, with the discriminator unchanged to the original GAN and a separate classifier added to the model~\cite{dong2019margingan, li2021triple}. Of all SSL-GANs, the bad-GAN by Dai et al.~\cite{dai2017good} is especially noteworthy, as Dai theoretically and experimentally showed that good SSL-GANs must generate bad-looking samples that lie in the complementary space. More specifically, generating samples that lie around the classification boundaries of labeled categories forces the classifier to tighten classification boundaries for improved generalisation. The bad-GAN approach is interesting as several OSR GAN-based models have also used a similar notion of bad looking samples.

Let the testing set, $\mathcal{D}_{\text{test}}$, also consist of input samples with anticipated labels, $(x, y_a)$. OSR inserts unobserved novel categories into this testing set to ensure the classifier can handle new emerging patterns. For general supervised learning and general SSL, the testing set is closed in relation to the training set. In other words, all testing samples belong to one of the labeled categories, i.e. all ${y_a \sim \mathcal{D}_{\text{test}}} \in C_K$. In OSR, novel categories that were not present during training are included in the testing set. However, these novel categories are not individually classified but are grouped and separated into an additional $K + 1$'th category. In other words, OSR updates the testing set to have all ${y_a \sim \mathcal{D}_{\text{test}}} \in C_K \cup \{K + 1\}$. OSR methods generally train under a supervised setting and test under this OSR setting. However, this study focuses on the combined SSL and OSR setting, meaning all ${y \sim \mathcal{D}_{\text{lab-train}}} \in C_K$, all ${y_a \sim \mathcal{D}_{\text{unlab-train}}} \in C_K$ and all ${y_a \sim \mathcal{D}_{\text{test}}} \in C_K \cup \{K + 1\}$. 

Before exploring the combination of SSL and OSR, it is important to consider the use of GANs for novelty detection and OSR. General novelty detection is a one-class classification problem that distinguishes unseen novel categories from a single positive labeled category~\cite{pimentel2014review}. The discriminator networks in GANs have been widely studied in this context~\cite{perera2019ocgan, sabokrou2018adversarially, zhang2021adversarially}. For OSR, three previous OSR-GAN studies are noteworthy as these also use GANs to generate bad-looking samples, similar to previous SSL-GANs. For example, the counter-factual (counter)-GAN by Neal et al.~\cite{neal2018open} combines an auto-encoder and a GAN to generate bad-looking samples that are then labeled into the $K + 1$th category, allowing for generalization in open space. Similarly, Jo et al.~\cite{jo2018open} use a feature-matching (FM)-GAN and a denoising auto-encoder to generate bad-looking samples, which are then used to regularize the classifier for the $K$ observed labeled categories. However, these previous studies were outperformed by significant degrees by the adversarial reciprocal point learning GAN (ARP-GAN) proposed by Chen et al.~\cite{chen2021adversarial} (which is discussed in the upcoming section).

To the best of our knowledge, only three studies have explored the combined SSL-OSR setting. Capazzo et al.~\cite{cappozzo2020anomaly} used traditional machine learning techniques to address label noise under the SSL-OSR setting, but these methods are unsuitable for high-dimensional image data. Then, the unpublished study by Kliger et al.~\cite{kliger2018novelty2} (later accepted as a patent~\cite{kliger2018novelty}) applied neural networks for SSL-OSR, but their results were unclear, and they did not make a theoretical link between SSL and OSR. Finally, difference-seeking (DS)-GANs by Sung et al.~\cite{sung2019difference} applied manually chosen operations to the training data and used FM-GANs to match this pseudo-data. However, Sung et al. did not provide justification on the choice of operations, while they also experimented on SSL and OSR independently, without linking the two. This study aims to formally and theoretically bridge SSL with OSR under the unified framework of GANs.

\section{First phase}
The aim of this study is to demonstrate that SSL-GANs and OSR-GANs theoretically and experimentally function similarly. In this first phase, we present two GAN models that were designed specifically for SSL and OSR - feature-matching GANs (FM-GANs)~\cite{NIPS2016_8a3363ab} for SSL and adversarial reciprocal point GANs (ARP-GANs)~\cite{chen2021adversarial} for OSR. To maintain fairness in our experiments, we will use the ARP-GAN code-base, noting that these models hold state-of-the-art results in OSR. In other words, the same optimization tools, network architectures, and hyper-parameter choices will be used throughout all experiments in this first phase. The results will demonstrate the similarities between these two GAN models, laying the foundation for our conclusion on the theoretical link between SSL-OSR.

\subsection{Technical preliminaries}
This section thoroughly describes FM-GANs and ARP-GANs, explicitly highlighting their theoretical similarities. As we delve into each model, it is important to pay attention to the $K + 1$'th categories. Specifically, both models use the additional $K + 1$'th category to represent unique areas in the embedding space. FM-GANs use the $K + 1$'th category to represent the complementary space of each labeled category (as shown in Fig. \ref{fig:2a}), while ARP-GANs use the $K + 1$'th category to represent the open space where novel categories lie (as shown in Fig. \ref{fig:2b}). This study proposes that the $K + 1$ categories in these different models ultimately represent the same areas in the embedding space, leading to both models functioning in a similar fashion.

\subsubsection{Feature-matching GANs}
Semi-supervised learning (SSL) has been widely studied using various methods~\cite{van2020survey} including GANs~\cite{sajun2022survey}. One SSL-GAN model, namely (FM)-GANs~\cite{NIPS2016_8a3363ab}, has been the foundation for multiple other SSL-GAN methods~\cite{dai2017good, kumar2017semi, sung2019difference, li2020semi}. Interestingly, FM-GANs have also been the foundation of an OSR-GAN method~\cite{jo2018open}. Consequently, FM-GANs provide a key insights into the link between SSL-OSR. However, we present FM-GANs as they were originally intended for SSL. It is also important to note that a basic understanding of GANs is required to understand the concepts discussed in this study. Readers who need to become more familiar with GANs should first study the fundamentals of these models~\cite{goodfellow2020generative}.

As a summary, vanilla GANs consist of two networks - a generator and a discriminator. The discriminator is trained to differentiate between real training data and fake data generated by the generator. In turn, the generator is trained to mimic the real data distribution to trick the discriminator into classifying the generated samples as real, creating an adversarial relationship between the two networks. At equilibrium, the discriminator will have learnt the low-dimensional manifolds of the training data~\cite{arjovsky2017wasserstein}, and the generator produces new samples that match the distribution of the real data. However, in SSL-GANs and OSR-GANs, the GAN loss functions are altered so that the generator produces "bad-looking" samples instead~\cite{dai2017good}. Specifically, in the case of FM-GANs, these generated samples must fall within the complementary space. 

SSL-GANs transform the discriminator into a classifier network which distinguishes real and fake samples and classifies real samples into their respective $K$ labeled categories~\cite{springenberg2015unsupervised, odena2016semi}. For the sake of clarity, the classifier network, denoted as $C(x)$ for input sample $x$, is generally described to have $K + 1$ output nodes, with the additional node used for fake samples~\cite{NIPS2016_8a3363ab}. More formally, the classifier network produces a probability score for a sample belonging to class $j$ through its softmax activation function as $p_{\text{class}}(y == j | x) = \frac{\text{exp}[C^{j}(x)]}{\sum_{i=1}^{K + 1} \text{exp}[C^{i}(x)]}$, where $C^{i}(x)$ is the logit value of node $i$. The classifier's loss function in an SSL-GAN is a combination of a supervised loss for samples in $D_{\text{lab-train}}$ and a supervised loss for generated samples, $G(z)$ (generated from a uniform distribution $\mathbb{P}^{\text{(z)}}$), which are labeled into the $K + 1$'th category. This combined supervised loss function is given as:

\begin{equation}
\begin{split}
 \underset{\text{SSL-GAN}}{\text{C-Loss}} = 
 & - \; \mathbb{E}_{(x, y) \sim D_{\text{lab-train}}} [\log(p_{\text{class}}(y|x) \;)] \\
 & - \; \mathbb{E}_{z \sim \mathbb{P}^{\text{(z)}}} [\log( \; p_{\text{class}}(y = K + 1| \; G(z) \;)]
    \label{eq:cost_c_ssl}
\end{split}
\end{equation} 

For such a $K + 1$ classifier, the probability of a sample being fake (i.e. being classified into the $K + 1$'th category) is given as $p_{\text{class}}(y == K + 1 | x) = \frac{\text{exp}[C^{K + 1}(x)]}{\sum_{i=1}^{K+1} \text{exp}[C^{i}(x)]}$. However, no testing sample is ever a fake sample, so the $K + 1$ setup is over-parameterised. Consequently, FM-GANs and subsequent follow up-studies~\cite{dai2017good, kumar2017semi, li2020semi}, proposed fixing the output value at the $K + 1$'th node to zero, i.e. $C^{K+1}(x) = 0 \; \; \forall x$. Thus, the probability of a sample being fake in an FM-GAN is transformed to $p_{\text{class}}(y == K + 1 | x) = \frac{1}{\sum_{i=1}^{K} \text{exp}[C^{i}(x)] + 1}$. With this new criterion, the classifier network no longer has $K + 1$ output nodes, but only $K$ nodes as a general classifier. However, the classifier still has $K + 1$ categories, with the $K + 1$'th category fixed as the zero'th vector over all $K$ nodes. In turn, and with the aid of the softplus function ($\text{softplus}(x) = \log(1 + x)$), the SSL classifier loss function in eq.~\ref{eq:cost_c_ssl} is transformed to: \footnote{See https://jostosh.github.io/ssl-gan/ for the full derivation}:

\begin{equation}
\label{eq:cost_c_fm}
\begin{split}
  \underset{\text{FM-GAN}}{\text{C-Loss}} = 
 & \; 0.5 \cdot \mathbb{E}_{(x, y) \sim D_{\text{train}}} [\text{softplus}(\log(\sum_{i = 1}^{K} \exp{C^i(x)})) \\
 & -  \log(\sum_{i = 1}^{K} \exp{C^i(x)})] \\
 & + \; 0.5 \cdot \mathbb{E}_{z \sim \mathbb{P}^{\text{(z)}}} [\text{softplus}(\log(\sum_{i = 1}^{K} \exp{C^i(G(z))}))] \\
 & - \; \mathbb{E}_{(x, y) \sim D_{\text{lab-train}}} [\log(p_{\text{class}}(y|x))] 
\end{split}
\end{equation}

When using vanilla GANs, the $K + 1$ category setup becomes problematic. In a standard GAN, the generator is tasked to produce samples that match the training data distribution. However, if the generator succeeds, the classifier network trained with eq.~\ref{eq:cost_c_fm} will struggle to generalize the labeled categories. More specifically, a generator that has accurately mimicked the training data distribution will produce samples that fall within the classification boundaries of the labeled categories. Labelling these realistic-looking samples into the $K + 1$ category (albeit the zero'th vector over $K$ nodes) would confuse the classifier, as samples that belong to the same categories now belong to two different categories. To overcome this, FM-GANs modify the original GAN loss function to instead generate samples that lie in the complementary space of the labeled categories. 

The complementary space refers to the area surrounding the boundaries of the labeled categories (as shown in Figure \ref{fig:2a}). Generated samples in the complementary space can be labeled into the $K + 1$th category without affecting generalization performance. In fact, by doing so, the classifier is forced to tighten its classification boundaries which improves SSL accuracy~\cite{dai2017good}. To learn representation of the complementary space, FM-GANs propose a feature-matching loss function for the generator. The FM loss function is based on the idea that the last hidden layer of the classifier network ($C'(x)$) represents the features of the input data. FM-GANs minimize the L2 distance between the activations of this hidden layer for real-training samples and the activations for fake-generated samples. Although FM-GANs do not guarantee that generated samples will always fall within the complementary space, they provide a foundation for complementary space theory. Formally, the FM-GAN generator loss function is given as follows:

\begin{equation}
\label{eq:cost_g_fm}
 \underset{\text{FM-GAN}}{\text{G-Loss}} \; = \; ||\mathbb{E}_{x \sim D_{\text{train}}} C'(x) - \mathbb{E}_{z \sim \mathbb{P}^{\text{(z)}}} C'(G(z))||_2^2
\end{equation}

In summary, FM-GANs convert the traditional two-player GAN game into a SSL framework by minimizing the loss functions $\text{C-Loss}_{\text{\; FM-GAN}}$ for the classifier network and $\text{G-Loss}_{\text{\; FM}}$ for the generator network. Although various improvements have been proposed for FM-GANs, this study focuses on this foundational theory. By learning the representation of the complementary space within the generator network and labelling generated samples into the $K + 1$'th category, this study hypothesizes that the $K + 1$'th category in FM-GANs would actually end up generalizing to the open space. More concretely, because generated samples lie around the classification boundaries of labeled categories, the $K + 1$'th category ends up representing all outside these boundaries which is the open space. 

\subsubsection{Adversarial reciprocal point GANs}
The open space represents the area of 'all that the labeled categories are not' (see Fig. \ref{fig:2b}). Consequently, generalising the open space achieves unobserved novelty detection. Several studies have proposed generative methods to generalize the open space within an additional $K + 1$'th category~\cite{ge2017generative, neal2018open, jo2018open, sung2019difference}. Specifically, generative networks are trained to produce samples that, when placed into the $K + 1$'th category, would appropriately generalize the open space. Although several generative OSR approaches have been developed, this study focuses on the state-of-the-art OSR method of ARP-GANs by Chen et al.~\cite{chen2021adversarial}. ARP-GANs rely on a new learning technique based on a novel concept of reciprocal points. The following is a thorough description of ARP-GANs. 

In ARP-GANs, each of the $K$ labeled categories is assigned a reciprocal point, $P^j$, which represents everything that category $j$ is not. More specifically, $P^j$ is a learned prototype that must be updated during training until it lies in the centre of the combined embedding space of all other labeled categories ($\neq j$) and the open space. The probability of a sample belonging to category $j$ is defined based on the distance of the sample to the category's reciprocal point, $P^j$. The sample is classified into the category with the farthest reciprocal point, as determined by a chosen distance metric. Formally, ARP-GANs produce probability scores as $p_{\text{class-ARP}}(y == j | x) = \frac{\text{exp}[d(C(x), P^j)]}{\sum_{i=1}^{K} \text{exp}[d(C(x), P^i)]}$, where $d(C(x), P^j)$ is the distance between the reciprocal point and the classifier's output for input sample $x$.

The distance metric used in ARP-GANs is a combination between the euclidean distance and the dot product, $d(C(x), P^j) = d_e(C(x), P^j) - d_d(C(x), P^j) = (\frac{1}{m} \; \cdot \; || C(x) - P^j ||^2_2) \; \; - \; \; (C(x) \cdot P^j)$. Note that $m$ is the dimension of the reciprocal point and the classifier's output (e.g. 128 in the ARP-GAN setup), meaning the classifier's output must match the size of the reciprocal points. ARP-GANs do not rely on general neural network classification techniques (i.e. one-hot encoded labels and cross-entropy loss). Instead, the distance, $d(C(x), P^j)$, between input samples and reciprocal points represent the classifier's logits. During training, ARP-GANs maximise the distance between labeled training samples and their categories' corresponding reciprocal points. However, maximisation between input samples and reciprocal points does not bind or generalize the open space. 

To generalize the open space within the $K + 1$'th category, classifiers in ARP-GANs also bind the euclidean distance ($d_e(C(x), P^j) = (\frac{1}{m} \; \cdot \; || C(x) - P^j ||^2_2)$) between labeled training samples and their corresponding reciprocal points to a learned range, $R$. By doing so between multiple labeled categories and their corresponding reciprocal points, the open space is pushed to the centre of the embedding space. It is important to note that the $K + 1$'th category in ARP-GANs has a similar structure to the $K + 1$'th category of FM-GANs. Specifically, FM-GANs and ARP-GANs do not explicitly define $K + 1$'th output nodes for the $K + 1$'th category. Instead, the $K + 1$'th category in FM-GANs is represented by the zero'th vector over $K$ nodes, and in ARP-GANs is represented as the center of the embedding space over $K$ nodes. Relating these representations of the $K + 1$'th category is the crux of our theoretical argument on the link between SSL-GANs and OSR-GANs.

In summary, an ARP-GAN classifier must maximise the distance $d(C(x), P^j)$ between labeled training samples and corresponding reciprocal points to push labeled categories to the edges of the embedding space. Furthermore, the classifier must minimise the distance  $d_e(C(x), P^j)$ to a range smaller than $R$ to limit the open space to the centre of the embedding space  (see Fig. 3 in~\cite{chen2021adversarial}). With $\gamma$ generally set to $\gamma = 0.1$, this adversarial loss function for the classifier network is described as: 

\begin{equation}
\begin{split}
    \underset{\text{ARP}}{\text{C-Loss}} = 
    &- \; \mathbb{E}_{(x, y) \sim D_{\text{lab-train}}} [\log(p_{\text{class-ARP}}(y|x))] \\
    & + \gamma \cdot \text{max}(d_e(C(x), P^j) - R, 0)
    \label{eq:cost_c_arp}
\end{split}
\end{equation}

$\text{C-Loss}_{\text{ARP}}$ is the categorical cross-entropy equivalent for supervised classifiers based on reciprocal points. With this classifier setup, Chen et al.~\cite{chen2021adversarial} appended an additional GAN criterion to $\text{C-Loss}_{\text{\; ARP}}$ to further improve results. In contrast to the two network setup of FM-GANs, ARP-GANs have three networks - a classifier, a discriminator and a generator. With a general GAN's discriminator (see eq. \ref{eq:cost_d_arpgan} below), the generator in ARP-GANs is tasked to match a mixture distribution between the real-training data and the reciprocal points. In other words, the generator is tasked to confuse the discriminator (i.e. match the real data distribution) and match the reciprocal points (i.e. match the reciprocal distribution of the real data). Subsequently, by including an information entropy loss function between generated samples and reciprocal points, the classifier can further improve binding the open space to the centre of the embedding space. 

Given $S(G(z), P^j) = \text{softmax}(d_e(C(G(z)), P^j))$, the information entropy loss is defined as $I(G(z)) = \sum^{K}_{i = 1} S(G(z), P^i) \cdot \log(S(G(z), P^i))$. To match the real data distribution and the reciprocal thereof, the generator's loss function within ARP-GANs includes the original GAN's loss function and $I(G(z))$. Furthermore, to ensure the classifier uses generated samples to constrain the open space, $I(G(z))$ is also appended to the classifier loss function in eq. \ref{eq:cost_c_arp}.  Thus, the three loss functions for the discriminator, generator and classifier in ARP-GANs are formally given as:

\begin{equation}
\begin{split}
    \underset{\text{ARP-GAN}}{\text{D-Loss}} = 
    & - \; \mathbb{E}_{(x) \sim D_{\text{train}}} [\log(D(x))] \\
    & - \; \mathbb{E}_{z \sim \mathbb{P}^{\text{(z)}}} [\log(1 - D(G(z)))] 
    \label{eq:cost_d_arpgan}
\end{split}
\end{equation}

\begin{equation}
    \underset{\text{ARP}-GAN}{\text{G-Loss}} = - \; \mathbb{E}_{z \sim \mathbb{P}^{\text{(z)}}} [\log(D(G(z))) \; + \; I(G(z))]
    \label{eq:cost_g_arpgan}
\end{equation}

\begin{equation}
\label{eq:cost_c_arpgan}
\begin{split}
\underset{\text{ARP-GAN}}{\text{C-Loss}} = 
& - \; \mathbb{E}_{(x, y) \sim D_{\text{lab-train}}} [\log(p_{\text{class-ARP}}(y|x))] \\
& + \gamma \cdot \text{max}(d_e(C(x), P^j) - R, 0) \; \\
& + \; \mathbb{E}_{z \sim \mathbb{P}^{\text{(z)}}} [I(G(z))]
\end{split}
\end{equation}

The generator within an ARP-GAN juggles between the real data distribution and the reciprocal thereof. Thus, Chen et al.~\cite{chen2021adversarial} argue that generated samples fall within the global open space at the centre of the embedding space. If we assume that the global open space indeed lies in the exact centre of the embedding space, then samples in the open space would have an equal probability spread across $K$ categories (i.e. $1/K$ \% of belonging to every labeled category). Any sample outside this centre would not lie within the global open space but instead fall on the boundary of the global open space and the labeled categories (i.e. the complementary space). Considering an imperfect generator, it is clear that the generated samples within ARP-GANs fall in the complementary space, similar to FM-GANs, and are used to lower the lower the confidence of the classifier's predictions. In turn, better separation of labeled and novel categories can be achieved realised.

\subsection{Experiments}
\begin{table*}[t]
\centering
%\begin{tabular}{m{3.2cm} m{2.2cm} m{2.2cm} m{0.3cm} m{2.2cm} m{2.2cm}}
\begin{tabular}{ p{3.2cm} p{2.2cm} p{2.2cm} p{0.3cm} p{2.2cm} p{2.2cm} }
\hline
 \multicolumn{1}{c}{} & \multicolumn{2}{c}{\textbf{Semi-supervised}} & \multicolumn{3}{c}{\textbf{Supervised}} \\
\hline
    & SVHN & CIFAR10 & & CIFAR10$\dagger$ & CIFAR10$\star$ \\
Labels per class & 100     & 400  & & Full  & Full \\
\hline
\textbf{Baselines} & & & & &  \\
Softmax & 13.83 $|$ 41.18 & 62.66 $|$ 67.04 &   & 90.24 $|$ 83.79 & 93.36 $|$ 85.26 \\
ARP     & 10.32 $|$ 53.65 &  61.54 $|$ 69.46 &   & 89.19 $|$ 84.53 & \textit{93.90} $|$ \textit{90.10 }   \\
\hline
\textbf{GANs} & & & & &  \\
FM-GAN  & 83.40 $|$ 88.02 & 78.70 $|$ 75.17  &  & 92.23 $|$ 85.91  & 95.62 $|$ 87.75   \\
ARP-GAN &  81.51 $|$ 90.16 &  77.62 $|$ 77.02  &  & 90.13 $|$ 87.07 & \textit{94.50} $|$ \textit{91.00}    \\
&  &   &   &  &   \\
bad-GAN~\cite{dai2017good}  &  \textit{95.75} $|$ - - -  &  \textit{85.59} $|$ - - - &   &   &  \\
Triple-GAN~\cite{li2021triple}  &  \textit{96.04} $|$ - - - &  \textit{87.59} $|$ - - - &   &  &   \\
Margin-GAN~\cite{NEURIPS2019_517f24c0}  &  &  \textit{93.56} $|$ - - - &   &  &   \\
Negative-GAN~\cite{jo2018open} &  &   &  & - - - $|$ \textit{72.90}  &     \\
Counter-GAN~\cite{neal2018open} &  &  &   &  &  - - -  $|$ \textit{83.80} \\
\hline
\end{tabular} \\ 
\begin{tablenotes}
\centering
\item \textit{\doublespacing Results are averaged over five randomized trials}
\end{tablenotes}
\caption{\doublespacing Results for our SSL, OSR and SSL-OSR experiments in the first phase. Each result is split as $a \; | \; b $ with $a$ representing the percentage accuracy for labeled categories and $b$ representing the $\text{AUROC} * 100$. Results in italics are previously published results using different code-bases, which we show for ease of reference.}
\label{table:1}
\end{table*}

This first phase aims to show that SSL-GANs and OSR-GANs function similarly. More specifically, we propose that FM-GANs and ARP-GANs both generate samples within the complementary space, and thus both models generalize the open space in the $K + 1$'th category. To test this theory, FM-GANs are integrated into the ARP-GAN codebase, and both FM-GANs and ARP-GANs are evaluated under SSL, OSR, and combined SSL-OSR criteria. Note that using the same codebase ensures fair experiments as the same network architectures, optimization tools, and hyperparameter choices are used, as in the ARP-GAN study~\cite{chen2021adversarial}. The primary difference between ARP-GANs and FM-GANs are the loss functions and that FM-GANs do not utilize the third discriminator network. We will examine the direct SSL-OSR results of both models as well as their embedding space outputs to determine the theoretical link between the two. 

The evaluation metrics within this study are the accuracy scores over the labeled categories and the area under the receiver operating characteristic (AUROC) curve. The AUROC is appropriate due to the unique $K + 1$ category setup in FM-GANs and ARP-GANs. More specifically, to separate novel categories, the models' inference is determined through thresholds applied to the maximum probability score of the classifying networks over $K$ logits. Samples below the threshold are classified into the $K + 1$ category and samples above the threshold being classified into the corresponding maximum logit's category. The prediction scores of samples from labeled categories will be used to gather a range of threshold values to create the ROC, while the AUROC will provide a numerical metric for the resulting graph (note that we opt to show the $\text{AUROC} * 100$ for ease of reading). Finally, the embedding space of the resulting classifiers will also be analyzed using margin-theory~\cite{dong2019margingan}, which will provide insight on where the complementary space lies. 

The margin of a sample $x$ belonging to category $y$ is a single numeric description of its position in the embedding space. The following equation gives the margin of a sample: $\text{margin}(x, y) = C_y(x) - \max_{i \neq y}C_i(x)$. More specifically, the margin measures the confidence of the classifier in its prediction by subtracting the maximum output probability of all other categories, $\max_{i \neq y}C_i(x)$, from the output probability of the true category, $C_y(x)$. The larger the absolute value of the margin, the more confident the classifier is, while a positive margin represents a correct prediction and a negative margin represents an incorrect prediction. By calculating the average margins of testing samples and generated samples, the embedding space can be visualized and analyzed in a meaningful way. Note that the true category for novel categories and generated samples is designated as the predicted category by the classifier. 

All experiments are conducted using the SVHN and CIFAR10 datasets with training and testing setups as per standard SSL and OSR protocols. For SSL, 100 and 400 labeled training samples are provided per category for SVHN and CIFAR10, respectively. During testing, the CIFAR10 test set is used to introduce novel categories within the SVHN experiments, and the CIFAR100 test set is used to introduce novel categories within the CIFAR10 experiments. For the supervised experiments, we conduct two variations using the CIFAR10 dataset. Specifically, the CIFAR10$\dagger$ supervised experiment uses all training samples from the original dataset and testing samples from CIFAR10 and CIFAR100 to insert unobserved novel categories into the domain. For the CIFAR10$\star$, $K = 6$ random categories out of the possible $10$ are defined as labeled categories, while the remaining $4$ categories are used as unobserved novel categories. 

The results for the ARP-GAN, FM-GAN, and their respective baselines (i.e. a traditional supervised classifier or a supervised ARP classifier) are presented in the semi-supervised and supervised columns of Table \ref{table:1}. It is clear that both GAN models improve over the baselines and that ARP-GANs perform competitively with FM-GANs in SSL, and FM-GANs compare competitively with ARP-GANs in OSR. We do note that FM-GANs consistently produce slightly better accuracy scores and ARP-GANs consistently provide slightly better AUROC scores, yet they still achieve similar results. It is also interesting to note that the SVHN baselines fail to learn, which we attribute to the SVHN images containing multiple digit categories in a single image. Thus, only when the model has access to the entire training set (i.e. labeled and unlabeled data) can the classifier generalize appropriately.  

To further study the theoretical similarities between FM-GANs and ARP-GANs, Fig. \ref{fig:3} presents bar graphs that visualise the embedding space of different categories and generated samples for the CIFAR10 supervised experiment. More specifically, the bar graphs show the average margins for all testing samples across the $K$ labeled categories, the average margins for all novel category testing samples, and the average margins for $100$ batches of generated samples. From these bar graphs, we can see that the embedding space of both ARP-GANs and FM-GANs are similar for labeled and novel categories, as would be expected considering their similar results. It is also important to note that generated samples generally exhibit lower margins than novel categories (although ARP-GANs have larger margins for generated samples than FM-GANs), and that novel categories consistently exhibit lower margins compared to the labeled categories. 

\begin{figure*}[!t]
\centering
\subfloat[FM-GAN]{\includegraphics[width=0.49\textwidth, height=6.0cm]{margins-sup-fm.png}
\label{fig:3a}}
\subfloat[ARP-GAN]{\includegraphics[width=0.49\textwidth, height=6.0cm]{margins-sup-arp.png}
\label{fig:3b}}
\caption{\doublespacing Visualising the embedding space through average margins of trained FM-GANs and ARP-GANs for the CIFAR10 supervised experiment. The true categories for novel category samples and generated samples is designated as their predicted categories.}
\label{fig:3}
\end{figure*}

Lower margins for novel categories compared labeled categories is expected to ensure separation of novel categories using thresholds. Furthermore, lower margins of generated samples compared to labeled categories is expected as the generated samples aim to lower the confidence of the classifier's predictions. Finally, lower margins for generated samples from FM-GANs compared to ARP-GANs might indicate a unique insight into the performance of these models. However, this specific result extends directly into the second phase and so will be discussed further on. Besides this, another noteworthy result are the variations in the differences between margins for different categories. A larger difference between labeled and novel categories suggests an easier separation via thresholding, while a smaller difference indicates a greater challenge for the classifier (i.e. categories 3 and 5 for both models). To the best of our knowledge, no previous study has used average margins to visualize the embedding space, and these results could certainly be used to address so-called problematic categories in the domain. 

Finally, as an ad-hoc experiment, we also conducted the SSL-OSR experiment from the unpublished study by Kliger et al.~\cite{kliger2018novelty2}. Specifically, Kliger conducted the same SSL CIFAR10 experiment as described above, yet they defined $3000$ labels per labeled category. Their results showed an AUROC of $80.128$\% (while they did not indicate the SSL accuracy), where our FM-GAN achieves an AUROC of $83.87$\%, and the ARP-GAN achieves and AUROC of $85.09$\%. Our results outperform their proposed model, and so this study boasts state-of-the-art SSL-OSR performance. Considering that FM-GANs and ARP-GANs consistently achieve similar results in both evaluation metrics and their resulting embedding spaces, we can conclude that these models function in a similar fashion. More specifically, both FM-GANs and ARP-GANs generate samples in the complementary space and both models use these samples to generalize the open space in the $K + 1$'th category. However, it is not yet clear where the optimal complementary space for generated samples lies in the embedding space. Furthermore, the SSL results from this first-phase do not compare well to previously published studies. Therefore, we move to study the state-of-the-art SSL-GAN.

\section{Second phase}
The first phase of the study demonstrated that the foundational SSL FM-GANs inserted into the ARP-GAN codebase achieve comparable results to the state-of-the-art OSR methods. However, since ARP-GANs were optimized for OSR and not SSL, the SSL results from the first phase did not compare well to the current state-of-the-art SSL methods (see Table~\ref{table:1}). In this second phase, we aim to reinforce our hypothesis on the link between SSL-OSR by thoroughly experimenting with the state-of-the-art SSL-GAN. Specifically, we apply margin-GANs by Dong et al.~\cite{NEURIPS2019_517f24c0} in the OSR and SSL-OSR settings. The results from this second phase will further our understanding of the SSL-OSR link and provide a new standard for SSL-OSR. We follow the same layout as the first phase by discussing the technical overview of margin-GANs and then conducting experiments.

\subsection{Technical preliminaries}
This section provides a technical overview of margin-GANs. Margin-GANs adopt a similar setup as ARP-GANs by developing a three-player game between the generator, discriminator, and classifier. Although margin-GANs do not explicitly discuss an additional $K+1$'th category, the loss functions still use generated samples to refine the boundaries around labeled categories. Specifically, the classifier decreases the margins for generated samples, while the generator increases the margins for generated samples. By doing so, we will show that generated samples fall within complementary space. Margin-GANs also appropriately fit into the overarching conversation of this study, namely that regularizing a classifier with generated samples that fall within the complementary space results in generalizing the open space.

\subsection{Margin-GANs}
Margin-GANs apply a unique GAN framework to the mean-teacher (MT) SSL model~\cite{tarvainen2017mean}. The MT model is based on a student-teacher training approach, where the teacher network is the exponential moving average of the student network's parameters. In addition to a general supervised loss for labeled data, the student network is trained on unlabeled data by minimizing a consistency loss (such as mean squared error) between its predictions for the unlabeled data and the teacher network's predictions for the same data. This consistency loss ensures that the student's predictions remain consistent throughout its updates and provides feedback to the model for unlabeled training samples.

It is important to highlight the similarity between MT models and pseudo-labelling models~\cite{lee2013pseudo, pham2021meta}. Pseudo-labelling uses the classifier network's output predictions for unlabeled data as the ground-truth labels for these samples, thus reinforcing the network's predictions. However, this approach is heavily dependent on the accuracy of these predictions, as any incorrect pseudo-label would negatively impact the generalization of the model. MT models offer improved performance as the "pseudo-labels" generated by the model are not treated as absolute ground-truth labels but instead as soft-pseudo labels over all $K$ categories. Margin-GANs build on the MT model by incorporating a GAN into the training process, creating a three-player game between the discriminator, generator, and student-teacher networks.

In margin-GANs, the discriminator's task is similar to that in vanilla GANs, which is to distinguish between real training samples in $D_{\text{train}}$ and generated samples $\mathbb{E}_{z \sim \mathbb{P}^{\text{(z)}}} G(z)$. However, unlike vanilla GANs, the generator in margin-GANs must deceive both the discriminator and the student-teacher into believing that the generated samples are real. As a result, the student-teacher network also plays a crucial role in the game by having to accurately differentiate between real and fake samples, similar to FM-GANs. However, margin-GANs propose a unique variation to the FM-GAN cost function in eq.~\ref{eq:cost_c_fm} to separate real and fake samples using a $K$-classifier network. Specifically, margin-GANs deploy the inverse cross-entropy loss function. 

Margin-GANs aim to minimize the classification margin of fake generated samples. As previously mentioned, the classification margin is calculated as the difference between the predicted probability for the true category and the highest predicted probability for all other categories (i.e. $\text{margin}(x, y) = C_y(x) - \max_{i \neq y}C_i(x)$). The classifying network must maximize the margin for real training samples and minimize the margin for fake generated samples. The cross-entropy loss function, $ -\mathbb{E}{(x, y) \sim D_{\text{lab-train}}} [\log(p_{\text{class}}(y|x))]$, already maximizes the margin for the correct category $y \in C_K$. To minimize the margin for fake generated samples, margin-GANs minimize the inverted cross-entropy in the form of $- \mathbb{E}_{z \sim \mathbb{P}^{\text{(z)}}} [\log(1 - p_{\text{class}}(y'|G(z)))]$, where $y'$ is the pseudo-label for the generated sample or the classifier's prediction. The loss functions for the three networks in margin-GANs are as follows:

\begin{equation}
\label{eq:cost_g_mg}
\begin{split}
   \text{G-Loss}_{\text{\; MG}} = 
   & - \; \mathbb{E}_{z \sim \mathbb{P}^{\text{(z)}}} [\log(D(G(z))) \\
   & - \; \log(1 - p_{\text{class}}(y'|G(z)) \;)]   
\end{split}
\end{equation}

\begin{equation}
 \label{eq:cost_d_mg}
 \begin{split}
 \text{D-Loss}_{\text{\; MG}} =
 & - \mathbb{E}_{x \sim D_{\text{train}}} [\log(D(x))] \\
 & - \mathbb{E}_{z \sim \mathbb{P}^{\text{(z)}}} [\log(1 - D(G(z)))]
 \end{split} 
\end{equation}

\begin{equation}
\label{eq:cost_c_mg}
\begin{split}
  \text{C-Loss}_{\text{\; MG}} = 
 & - \; \mathbb{E}_{z \sim \mathbb{P}^{\text{(z)}}} [\log(1 - p_{\text{class}}(y'|G(z)) \;) \\
 & - \; \mathbb{E}_{(x, y) \sim D_{\text{lab-train}}} [\log(p_{\text{class}}(y|x))] \\
  & - \; \mathbb{E}_{(x) \sim D_{\text{unlab-train}}} [\log(p_{\text{class}}(y'|x))]  \\
\end{split}
\end{equation}

The last term of the classifying network cost function in eq.~\ref{eq:cost_c_mg} represents the pseudo-labelling cost function for unlabeled training samples. However, as mentioned above, margin-GANs use MT models as their classifying networks. Therefore, instead of the pseudo-labelling cost function, margin-GANs use the consistency loss between the student's and teacher's predictions for unlabeled training samples. Let $T(x)$ represent the teacher network (which is the exponential moving average of the student's parameters), then the classifier's loss function becomes:

\begin{equation}
\label{eq:cost_c_mg2}
\begin{split}
  \text{C-Loss}_{\text{\; MG-MT}} = 
 & - \; \mathbb{E}_{z \sim \mathbb{P}^{\text{(z)}}} [\log(1 - p_{\text{class}}(y'|G(z)) \;) \\
 & - \; \mathbb{E}_{(x, y) \sim D_{\text{lab-train}}} [\log(p_{\text{class}}(y|x))] \\
  & - \; \mathbb{E}_{(x) \sim D_{\text{unlab-train}}} [(C(x) - T(x))^2] \\
\end{split}
\end{equation}

The loss functions used in margin-GANs make it clear that the generator aims to 1) produce realistic-looking samples according to the discriminator and 2) produce samples that fall inside the boundaries of labeled categories according to the classifier. However, in the adversarial game, the discriminator sees generated samples as fake, and the classifier updates so that generated samples fall outside the classification boundaries. As a result, the generated samples jump in and out of the classification boundaries, arguable placing them in the complementary space (see Fig. \ref{fig:2a}). In the first phase of this study, we concluded that using generated samples within the complementary space to generalize the $K+1$'th category generalizes the open space. Therefore, considering that margin-GANs minimize the margins for generated samples in the complementary space, we can expect also margin-GANs to perform well in OSR. 

\subsection{Experiments}
In this second phase, we focus our experiments on the CIFAR10 dataset, which is widely considered one of the most challenging datasets in image classification research. Specifically, the SSL-OSR experiment from the first phase is repeated, again using 400 labels per category and the rest of the samples as unlabeled. The test set includes both the CIFAR10 and CIFAR100 test sets. Subsequently, we also repeat the supervised experiments, again referred to as CIFAR10$\dagger$ and CIFAR10$\star$. In CIFAR10$\dagger$, all labels in the CIFAR10 training set are revealed for training and the full CIFAR10 and CIFAR100 testing sets are used for testing. In CIFAR10$\star$, $K = 6$ random categories are selected as labeled categories for which all training labels are revealed, while the full CIFAR10 test set is used for testing. Thus, the remaining 4 categories are treated as novel categories. All experiments are conducted using the margin-GAN codebase~\footnote{See https://github.com/DJjjjhao/MarginGAN}, and so the same optimisation and hyperparameter choices are used for all experiments. 

The results of each experiment are presented in Table~\ref{table:2}, along with a comparison to ARP-GANs from the first phase. These results have several noteworthy observations: 1) margin-GANs significantly outperform ARP-GANs in terms of SSL performance, which was expected; 2) margin-GANs set a new standard for OSR performance under the combined SSL-OSR setting; 3) margin-GANs surpass ARP-GANs in the CIFAR10$\dagger$ experiment, establishing a new benchmark for general OSR, and 4) however, margin-GANs do not outperform ARP-GANs in the CIFAR10$\star$ experiment, suggesting that ARP-GANs are better suited for detecting novel categories that are closely related to the labeled categories. In conclusion, margin-GANs are at the forefront of SSL-OSR and either achieve state-of-the-art results or perform competitively for general OSR. 

\begin{table}[t]
\centering
%\begin{tabular}{m{3.2cm} m{2.2cm} m{2.2cm} m{0.3cm} m{2.2cm} m{2.2cm}}
\begin{tabular}{p{0.9cm} p{1.5cm} p{1.5cm} p{1.5cm}}
\hline
 & \multicolumn{1}{c}{\textbf{Semi-supervised}} & \multicolumn{2}{c}{\textbf{Supervised}} \\
\hline
 & CIFAR10 & CIFAR10$\dagger$ & CIFAR10$\star$ \\
\hline
\textbf{GANs} & & & \\
ARP-GAN & 77.62 $|$ 77.02  & 89.84 $|$ 86.32 & 94.5 $|$ 91.00  \\
Margin-GAN & 92.93 $|$ 88.91 & 96.35 $|$ 91.75  & 96.22 $|$ 87.75  \\
\hline
\end{tabular} \\
\begin{tablenotes}
\centering
\item \textit{\doublespacing Results are averaged over five randomized trials}
\end{tablenotes}
\caption{\doublespacing Results for our SSL, OSR and SSL-OSR experiments in the second phase. Each result is split as $a \; | \; b $ with $a$ representing the accuracy for labeled categories and $b$ representing the $\text{AUROC} * 100$.}
\label{table:2}
\end{table}

To further the discussion on the complementary space and the open space, it is important to examine the generated samples from margin-GANs. Fig.~\ref{fig:5} presents examples of real CIFAR10 images and generated images from the supervised CIFAR10 experiment. The images generated by the generator are visibly of lower quality compared to the real images. More specifically, it is clear that the generated images have indistinct features, lack sharp definition and have a blurred and amorphous appearance. This demonstrates that the generated images do not conform to the real training distribution, which matches the notion of generating 'bad-looking' samples in the complementary space. However, these samples do still produce similar qualities (e.g. colors and contrast) to the real images, as required to be on the classification boundaries of labeled categories. 

The average margins of labeled categories, novel categories and generated samples for the supervised CIFAR10 experiment is shown in Fig. \ref{fig:4}. Similar to the results in the first phase, novel categories consistently produce margins lower than labeled categories as required to separate novel categories using thresholds. Furthermore, generated samples generally produce lower predictions compared to labeled and novel categories. It is also clear that margin-GANs produce generated samples with lower margins than those from FM-GANs and ARP-GANs in the first phase (as seen in Fig. \ref{fig:3}). Although lower margins for generated samples seems necessary for higher accuracy SSL, it is still unclear if lower margins are required for OSR. Nevertheless, considering that margin-GANs also perform well at OSR, we can conclude that SSL-GANs and OSR-GANs function similarly. 

\begin{figure}[!t]
\centering
\includegraphics[width=3.7in]{margins-sup-mg.png}
%where an .eps filename suffix will be assumed under latex, 
%and a .pdf suffix will be assumed for pdflatex; or what has been declared
%via \DeclareGraphicsExtensions.
\caption{\doublespacing Visualising the embedding space through average margins of the trained margin-GAN for the CIFAR10 supervised experiment. The true categories for novel category samples and generated samples is designated as their predicted categories.}
\label{fig:4}
\end{figure}

\section{Discussion}
The primary hypothesis of this study is that SSL-GANs and OSR-GANs function in the same manner. In particular, the generators in SSL-GANs and OSR-GANs are tasked with producing samples that lie in the complementary space, which are then used to regularize the classifying networks. In turn, the classifier generalizes the open space within the $K + 1$'th category, facilitating the separation of novel categories. The results from both the first and second phases clearly show that generated samples produce margins that are lower than those of any labeled and novel categories. This outcome is expected, as generated samples are intended to lower the confidence of classifiers and allow for the separation of novel categories. However, it is still being determined what the ideal margins would be for samples in complementary space.

For SSL-GANs, the complementary space is defined as the region surrounding the classification boundaries of labeled categories. For OSR-GANs, the open space is defined as the center of the the embedding space. In other words, OSR-GANs define samples in the global open space as those with an equal probability spread across all $K$ categories. Considering our results, both SSL-GANs and OSR-GANs clearly generalize the open space within the $K + 1$'th category. We are therefore warranted to extend the definition of the complementary to that of the open space. To do so, two factors must be taken into consideration - 1) the definition of the $K + 1$'th category in FM-GANs, and 2) the definition of the complementary space in margin-GANs. 

According to the theory of FM-GANs, the $K + 1$'th category is set as the zero'th vector across $K$ nodes. In other words, generated samples in the complementary space should produce prediction scores as low as possible. However, a softmax output activation function means the probability distribution over $K$ nodes will always sum to one, and so no sample can ever output the zero'th vector. Nevertheless, generated samples should output as low logits as possible across all $K$ output nodes. For OSR, generated samples should produce prediction scores of $1/K$ at every output node. However, our results show that the margins of generated samples in SSL-GANs and OSR-GANs do not produce very low predictions scores. Although we could attribute this to overconfident neural networks, a closer look at the difference between margins of SSL-GANs and OSR-GANs shows unique insights. 

If, as we suggest, we extend the definition of the complementary space to that of the open space, the complementary space would not only represent the area around the classification boundaries of labeled categories, but also represent the regions between categories in the embedding space. Consider a domain with $K = 2$ categories. In such a case, the reciprocal points of each category would produce predictions equal to $1/K = 0.5$, setting the boundary between the two categories. Subsequently, the complementary space of each category would be any sample with a prediction between $0.5$ and the lowest prediction score for samples known to belong to that category. In the case of $K = 2$, defining the complementary space in relation to the open space is trivial. However, as $K$ increases, so the curse of higher dimensionality leads to an increasingly complicated definition.

Suppose we extend the domain to $K = 3$. The definitions of the complementary space and the open space would now need to consider several regions - 1) the area between categories one and two, 2) the area between categories one and three, 3) the area between categories two and three, and 4) the area between categories one, two and three (which is the global open space). For the open space, reciprocal points of each category would now produce predictions equal to $1/3$. In this case, the complementary space would be between $1/3$ and the lowest prediction of the specific category. Clearly, if we assume that each category's lowest prediction remains generally the same no matter the number of categories, then the complementary space of each category increases in size as the number of categories increase. However, the margins of generated samples within our experiments (see Fig. \ref{fig:2} and Fig. \ref{fig:4}) indicate that the complementary space is far bigger than the proposed $1/K = 1/10$. 

\begin{figure*}[!t]
\centering
\subfloat[Real images]{\includegraphics[width=0.4\textwidth]{real.png}
\label{fig:5a}}
\hfil
\centering
\subfloat[Generated images]{\includegraphics[width=0.4\textwidth]{generated.png}
\label{fig:5b}}
\caption{\doublespacing Comparing real and generated images from SSL margin-GANs - (a) shows examples of real CIFAR10 images; (b) shows examples of generated images from the trained margin-GAN on the SSL CIFAR10 experiment. }
\label{fig:5}
\end{figure*}

Margin-theory provides further understanding of why generated samples have much higher predictions than the theorised $1/K$. Again, consider over overconfident neural networks. For such classifiers, the prediction for the primary category is so high that the remaining spread of the probability distribution is heavily weighted towards the secondary category. Therefore, margin-theory is a better representation of the embedding space than viewing all $K$ categories concurrently. More specifically, only the category in question and its most similar category is considered. Under margin-theory, the global open space would not be at $1/K$ but rather at $1/2$, no matter the number of categories. Subsequently, the complementary space of a category would always be between $1/2$ and the lowest prediction score of that category. 

Considering the margins of generated samples from our experiments, it is clear that the complementary space lies around $1/2$ instead of $1/K$ in the embedding space. This result could be utilised by both SSL-GANs and OSR-GANs in future optimisation studies, as the generator can now be fine-tuned to exactly match the complementary space. However, it still remains unclear why margin-GANs produce the highest SSL results but have the lowest margins for generated samples. Furthermore, ARP-GANs produce the highest OSR results (particularly for the more complicated CIFAR10$\star$ experiment), but have the highest margins for generated samples. Although further experimentation is required, these discrepancies indicate a possible trade-off between SSL and OSR performance. However, such experiments are left for future work that aims to simultaneously optimise SSL and OSR. 

\section{Conclusion}
This study concludes that generative SSL models and generative OSR models operate in a similar fashion. More specifically, both SSL-GANs and OSR-GANs require their generators to produce samples that lie within the complementary space. Subsequently, when using generated samples to regularize the classifying network, the open space is generalized in the $K + 1$'th category. Our findings suggest that SSL-GANs are capable of OSR and OSR-GANs are capable of SSL. With a stronger theoretical foundation, our results indicate that the SSL optimised margin-GANs produce state-of-the-art results for SSL-OSR and certain general OSR experiments. However, OSR optimised ARP-GANs still outperform margin-GANs in other general OSR experiments. Thus, future studies should explore the relationship between SSL-OSR under the overarching conversation of the complementary space, reciprocal points and margin-theory. Nevertheless, the link between SSL-OSR is clearly established on a theoretical foundation, establishing a new combined research path. 


\clearpage
\printbibliography
\begin{wrapfigure}{l}{25mm} 
    \includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{engelbrecht.png}
  \end{wrapfigure} \par 
  \textbf{Emile Reyn Engelbrecht} is a PhD candidate in Electronic Engineering at Stellenbosch University in South Africa. He received a PhD upgrade from his Master's degree in 2020 and is currently working on his dissertation. Reyn's research focuses on synthesizing various fields to develop more practical and effective classifier training methods. He aims to apply his methods on a variety of real-word applications and aspires to become a Professor, lecturer and entrepreneur. Reyn is passionate about politics, and using technology to better the lives of the many.  \paragraph{}



\begin{wrapfigure}{l}{25mm} 
    \includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{dupreez.png}
  \end{wrapfigure} \par
  \textbf{Johan A. du Preez} received his PhD degree in electronic engineering from Stellenbosch University, in 1998. He joined the Department of Electrical and Electronic Engineering at Stellenbosch in 1989. He is active in the broader fields of signal processing and pattern recognition, with a particular research interest that includes developing advanced structured probabilistic models to address speech, image and text processing problems, and advanced inference methods. \par


  
\end{document}

\end{document}