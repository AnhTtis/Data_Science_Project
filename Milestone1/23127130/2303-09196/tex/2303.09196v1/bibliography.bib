@book{Shalev-Shwartz2013,
  abstract        = {Machine learning is one of the fastest growing areas of computer science, with far-reaching applications. The aim of this textbook is to introduce machine learning, and the algorithmic paradigms it offers, in a principled way. The book provides an extensive theoretical account of the fundamental ideas underlying machine learning and the mathematical derivations that transform these principles into practical algorithms. Following a presentation of the basics of the field, the book covers a wide array of central topics that have not been oaddressed by previous textbooks. These include a discussion of the computational complexity of learning and the concepts of convexity and stability; important algorithmic paradigms including stochastic gradient descent, neural networks, and structured output learning; and emerging theoretical concepts such as the PAC-Bayes approach and compression-based bounds. Designed for an advanced undergraduate or beginning graduate course, the text makes the fundamentals and algorithms of machine learning accessible to students and non-expert readers in statistics, computer science, mathematics, and engineering.},
  author          = {Shalev-Shwartz, Shai and Ben-David, Shai},
  doi             = {10.1017/CBO9781107298019},
  file            = {:C\:/Users/pcoppens/Workspace/references/books/Schalev-Schwarz (2014) - Understanding Machine Learning.pdf:pdf},
  isbn            = {9781107057135},
  mendeley-groups = {Workspace/Projects/Essential Covering/VC},
  omonth           = {may},
  publisher       = {Cambridge University Press},
  title           = {{Understanding Machine Learning}},
  url             = {https://www.cambridge.org/core/product/identifier/9781107298019/type/book},
  year            = {2014}
}

@book{Vapnik1998,
  author          = {Vapnik, Vladimir},
  file            = {:C\:/Users/pcoppens/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vapnik - 1998 - Statistical Learning Theory.pdf:pdf},
  isbn            = {978-0-471-03003-4},
  mendeley-groups = {Workspace/Projects/Essential Covering/VC},
  publisher       = {John Wiley \& Sons},
  title           = {{Statistical Learning Theory}},
  year            = {1998}
}

@book{Shapiro2021,
  abstract        = {Third edition. "This third edition covers optimization problems involving uncertain parameters, for which stochastic models are available"-- Stochastic programming models -- Two-stage problems -- Multistage problems -- Optimization models with probabilistic constraints -- Statistical inference -- Risk averse optimization -- Distributionally robust stochastic programming -- Computational methods -- Background material -- Bibliographical remarks.},
  oaddress         = {Philadelphia, PA},
  author          = {Shapiro, Alexander and Dentcheva, Darinka and Ruszczynski, Andrzej},
  odoi             = {10.1137/1.9781611976595},
  file            = {:C\:/Users/pcoppens/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shapiro, Dentcheva, Ruszczynski - 2021 - Lectures on Stochastic Programming Modeling and Theory, Third Edition.pdf:pdf},
  oisbn            = {978-1-61197-658-8},
  mendeley-groups = {Workspace/Projects/Essential Covering/Distributionally Robust},
  omonth           = {jul},
  publisher       = {SIAM},
  title           = {{Lectures on Stochastic Programming: Modeling and Theory, Third Edition}},
  ourl             = {https://epubs.siam.org/doi/book/10.1137/1.9781611976595},
  year            = {2021}
}

@article{Lorenzen2017,
  abstract        = {Constraint tightening to non-conservatively guarantee recursive feasibility and stability in Stochastic Model Predictive Control is oaddressed. Stability and feasibility requirements are considered separately, highlighting the difference between existence of a solution and feasibility of a suitable, a priori known candidate solution. Subsequently, a Stochastic Model Predictive Control algorithm which unifies previous results is derived, leaving the designer the option to balance an increased feasible region against guaranteed bounds on the asymptotic average performance and convergence time. Besides typical performance bounds, under mild assumptions, we prove asymptotic stability in probability of the minimal robust positively invariant set obtained by the unconstrained LQ-optimal controller. A numerical example, demonstrating the efficacy of the proposed approach in comparison with classical, recursively feasible Stochastic MPC and Robust MPC, is provided.},
  archiveprefix   = {arXiv},
  arxivid         = {1511.03488},
  author          = {Lorenzen, Matthias and Dabbene, Fabrizio and Tempo, Roberto and Allgower, Frank},
  doi             = {10.1109/TAC.2016.2625048},
  eprint          = {1511.03488},
  file            = {:C\:/Users/pcoppens/Workspace/references/papers/Lorenzen2017c.pdf:pdf},
  issn            = {0018-9286},
  journal         = {IEEE Transactions on Automatic Control},
  keywords        = {Chance constraints,constrained control,discrete-time stochastic systems,predictive control,randomized algorithms,receding horizon control,stochastic model predictive control},
  mendeley-groups = {Workspace/Publications/CDC2021/Core,Workspace/Projects/Tube MPC},
  omonth           = {jul},
  number          = {7},
  pages           = {3165--3177},
  publisher       = {IEEE},
  title           = {{Constraint-Tightening and Stability in Stochastic Model Predictive Control}},
  url             = {http://ieeexplore.ieee.org/document/7733074/},
  volume          = {62},
  year            = {2017}
}

@article{Rockafellar2014,
  abstract        = {Random variables can be described by their cumulative distribution functions, a class of nondecreasing functions on the real line. Those functions can in turn be identified, after the possible vertical gaps in their graphs are filled in, with maximal monotone relations. Such relations are known to be the subdifferentials of convex functions. Analysis of these connections yields new insights. The generalized inversion operation between distribution functions and quantile functions corresponds to graphical inversion of monotone relations. In subdifferential terms, it corresponds to passing to conjugate convex functions under the Legendre–Fenchel transform. Among other things, this shows that convergence in distribution for sequences of random variables is equivalent to graphical convergence of the monotone relations and epigraphical convergence of the associated convex functions. Measures of risk that employ quantiles (VaR) and superquantiles (CVaR), either individually or in mixtures, are illuminated in this way. Formulas for their calculation are seen from a perspective that reveals how they were discovered. The approach leads further to developments in which the superquantiles for a given distribution are interpreted as the quantiles for an overlying “superdistribution.” In this way a generalization of Koenker–Basset error is derived which lays a foundation for superquantile regression as a higher-order extension of quantile regression.},
  author          = {Rockafellar, R. T. and Royset, J. O.},
  doi             = {10.1007/s10107-014-0801-1},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Rockafellar2014/Rockafellar2014.pdf:pdf},
  issn            = {14364646},
  journal         = {Mathematical Programming},
  keywords        = {Comonotonicity,Conditional-value-at-risk,Conjugate duality,Convergence in distribution,Convex analysis,Measures of risk,Quantiles,Random variables,Stochastic dominance,Stochastic optimization,Superdistributions,Superexpectations,Superquantiles,Value-at-risk},
  mendeley-groups = {Workspace/Projects/Essential Covering/Distortion Risk},
  number          = {1-2},
  pages           = {297--331},
  title           = {{Random variables, monotone relations, and convex analysis}},
  volume          = {148},
  year            = {2014}
}

@article{Delage2010,
  abstract        = {We propose a robust optimization approach to oaddress a multiperiod inventory control problem under ambiguous demands,that is, only limited information of the demand distributions such as mean, support, and some measures of deviations. Our framework extends to correlated demands and is developed around a factor-based model, which has the ability to incorporate business factors as well as time-oseries forecast effects of trend, seasonality, and cyclic variations. We can obtain the parameters of the replenishment policies by solving a tractable deterministic optimization problem in the form of a second-order cone optimization problem (SOCP), with solution time; unlike dynamic programming approaches, it is polynomial and independent on parameters such as replenishment lead time, demand variability, and correlations. Theproposed truncated linear replenishment policy (TLRP), which is piecewise linear with respect to demand history, improves upon static and linear policies, and achieves objective values that are reasonably close to optimal. {\textcopyright} 2010 INFORMS.},
  author          = {Delage, Erick and Ye, Yinyu},
  doi             = {10.1287/opre.1090.0741},
  file            = {:C\:/Users/pcoppens/Workspace/references/papers/Delage2010.pdf:pdf},
  issn            = {0030-364X},
  journal         = {Operations Research},
  keywords        = {Distributionally Robust,Moment},
  mendeley-groups = {Workspace/Publications/L4DC2019/Core,Workspace/Publications/CDC2021/Core},
  mendeley-tags   = {Distributionally Robust,Moment},
  omonth           = {jun},
  number          = {3},
  pages           = {595--612},
  title           = {{Distributionally Robust Optimization Under Moment Uncertainty with Application to Data-Driven Problems}},
  url             = {http://pubsonline.informs.org/doi/abs/10.1287/opre.1090.0741},
  volume          = {58},
  year            = {2010}
}

@article{Esfahani2018b,
  abstract        = {We consider stochastic programs where the distribution of the uncertain parameters is only observable through a finite training dataset. Using the Wasserstein metric, we construct a ball in the space of (multivariate and non-discrete) probability distributions centered at the uniform distribution on the training samples, and we seek decisions that perform best in view of the worst-case distribution within this Wasserstein ball. The state-of-the-art methods for solving the resulting distributionally robust optimization problems rely on global optimization techniques, which quickly become computationally excruciating. In this paper we demonstrate that, under mild assumptions, the distributionally robust optimization problems over Wasserstein balls can in fact be reformulated as finite convex programs—in many interesting cases even as tractable linear programs. Leveraging recent measure concentration results, we also show that their solutions enjoy powerful finite-sample performance guarantees. Our theoretical results are exemplified in mean-risk portfolio optimization as well as uncertainty quantification.},
  archiveprefix   = {arXiv},
  arxivid         = {1505.05116},
  author          = {{Mohajerin Esfahani}, Peyman and Kuhn, Daniel},
  doi             = {10.1007/s10107-017-1172-1},
  oeprint          = {1505.05116},
  file            = {:C\:/Users/pcoppens/Workspace/references/papers/Esfahani2018.pdf:pdf},
  isbn            = {1010701711},
  issn            = {0025-5610},
  journal         = {Mathematical Programming},
  keywords        = {Distributionally Robust,Wasserstein},
  mendeley-groups = {Workspace/Background/Interesting},
  mendeley-tags   = {Distributionally Robust,Wasserstein},
  omonth           = {sep},
  number          = {1-2},
  pages           = {115--166},
  publisher       = {Springer Berlin Heidelberg},
  title           = {{Data-driven distributionally robust optimization using the Wasserstein metric: performance guarantees and tractable reformulations}},
  url             = {http://link.springer.com/10.1007/s10107-017-1172-1},
  volume          = {171},
  year            = {2018}
}

@article{Bertsimas2018,
	title = {Data-driven robust optimization},
	volume = {167},
	oissn = {1436-4646},
	ourl = {https://doi.org/10.1007/s10107-017-1125-8},
	odoi = {10.1007/s10107-017-1125-8},
	abstract = {The last decade witnessed an explosion in the availability of data for operations research applications. Motivated by this growing availability, we propose a novel schema for utilizing data to design uncertainty sets for robust optimization using statistical hypothesis tests. The approach is flexible and widely applicable, and robust optimization problems built from our new sets are computationally tractable, both theoretically and practically. Furthermore, optimal solutions to these problems enjoy a strong, finite-sample probabilistic guarantee whenever the constraints and objective function are concave in the uncertainty. We describe concrete procedures for choosing an appropriate set for a given application and applying our approach to multiple uncertain constraints. Computational evidence in portfolio management and queueing confirm that our data-driven sets significantly outperform traditional robust optimization techniques whenever data are available.},
	number = {2},
	journal = {Mathematical Programming},
	author = {Bertsimas, Dimitris and Gupta, Vishal and Kallus, Nathan},
	omonth = feb,
	year = {2018},
	pages = {235--292},
}


@article{Ben-Tal2013,
  abstract        = {In this paper we focus on robust linear optimization problems with uncertainty regions defined by $\phi$-divergences (for example, chi-squared, Hellinger, Kullback-Leibler). We show how uncertainty regions based on $\phi$-divergences arise in a natural way as confidence sets if the uncertain parameters contain elements of a probability vector. Such problems frequently occur in, for example, optimization problems in inventory control or finance that involve terms containing moments of random variables, expected utility, etc. We show that the robust counterpart of a linear optimization problem with $\phi$-divergence uncertainty is tractable for most of the choices of $\phi$ typically considered in the literature. We extend the results to problems that are nonlinear in the optimization variables. Several applications, including an asset pricing example and a numerical multi-item newsvendor example, illustrate the relevance of the proposed approach. {\textcopyright} 2013 INFORMS.},
  author          = {Ben-Tal, Aharon and {Den Hertog}, Dick and {De Waegenaere}, Anja and Melenberg, Bertrand and Rennen, Gijs},
  doi             = {10.1287/mnsc.1120.1641},
  file            = {:C\:/Users/pcoppens/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ben-Tal et al. - 2013 - Robust solutions of optimization problems affected by uncertain probabilities.pdf:pdf},
  issn            = {00251909},
  journal         = {Management Science},
  keywords        = {Goodness-of-fit statistics,Robust optimization,phi-divergence,$\phi$-divergence},
  mendeley-groups = {Ben/Background/Robustness},
  mendeley-tags   = {phi-divergence},
  omonth           = {feb},
  number          = {2},
  pages           = {341--357},
  title           = {{Robust solutions of optimization problems affected by uncertain probabilities}},
  volume          = {59},
  year            = {2013}
}

@article{Duchi2021b,
  abstract        = {We study statistical inference and distributionally robust solution methods for stochastic optimization problems, focusing on confidence intervals for optimal values and solutions that achieve exact coverage asymptotically. We develop a generalized empirical likelihood framework—based on distributional uncertainty sets constructed from nonparametric f-divergence balls—for Hadamard differentiable functionals, and in particular, stochastic optimization problems. As consequences of this theory, we provide a principled method for choosing the size of distributional uncertainty regions to provide one- and two-sided confidence intervals that achieve exact coverage. We also give an asymptotic expansion for our distributionally robust formulation, showing how robustification regularizes problems by their variance. Finally, we show that optimizers of the distributionally robust formulations we study enjoy (essentially) the same consistency properties as those in classical sample average approximations. Our general approach applies to quickly mixing stationary sequences, including geometrically ergodic Harris recurrent Markov chains.},
  archiveprefix   = {arXiv},
  arxivid         = {1610.03425},
  author          = {Duchi, John C. and Glynn, Peter W. and Namkoong, Hongseok},
  doi             = {10.1287/MOOR.2020.1085},
  oeprint          = {1610.03425},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Duchi2021/Duchi2021.pdf:pdf},
  isbn            = {0000000257084},
  issn            = {15265471},
  journal         = {Mathematics of Operations Research},
  keywords        = {Empirical likelihood,Robust optimization,Stochastic optimization},
  mendeley-groups = {Ben/Projects/Elementary Coverage/Asymptotic},
  number          = {3},
  pages           = {946--969},
  title           = {{Statistics of robust optimization: A generalized empirical likelihood approach}},
  volume          = {46},
  year            = {2021}
}
@article{Lam2019,
  abstract        = {We investigate the use of distributionally robust optimization (DRO) as a tractable tool to recover the asymptotic statistical guarantees provided by the central limit theorem, for maintaining the feasibility of an expected value constraint under ambiguous probability distributions. We show that using empirically defined Burg-entropy divergence balls to construct the DRO can attain such guarantees. These balls, however, are not reasoned from the standard data-driven DRO framework because, by themselves, they can have low or even zero probability of covering the true distribution. Rather, their superior statistical performances are endowed by linking the resulting DRO with empirical likelihood and empirical processes. We show that the sizes of these balls can be optimally calibrated using X2-process excursion. We conduct numerical experiments to support our theoretical findings.},
  archiveprefix   = {arXiv},
  arxivid         = {1605.09349},
  author          = {Lam, Henry},
  doi             = {10.1287/opre.2018.1786},
  oeprint          = {1605.09349},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Duchi2021/Lam2019.pdf:pdf},
  issn            = {15265463},
  journal         = {Operations Research},
  keywords        = {Central limit theorem,Chi-square process,Distributionally robust optimization,Empirical likelihood,Empirical process},
  mendeley-groups = {Ben/Projects/Elementary Coverage/Asymptotic},
  number          = {4},
  pages           = {1090--1105},
  title           = {{Recovering best statistical guarantees via the empirical divergence-based distributionally robust optimization}},
  volume          = {67},
  year            = {2019}
}

@techreport{Anderson1969,
  author          = {Anderson, Theodore Wilbur},
  file            = {:C\:/Users/pcoppens/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Anderson - 1969 - Confidence limits for the expected value of an arbitrary bounded random variable with a continuous distribution functi.pdf:pdf},
  institution     = {Stanford University },
  mendeley-groups = {Ben/Projects/Elementary Coverage/Mean Confidence},
  title           = {{Confidence limits for the expected value of an arbitrary bounded random variable with a continuous distribution function}},
  year            = {1969}
}

@book{Shorack2009,
  author          = {Shorack, Galen R. and Wellner, Jon A.},
  doi             = {10.1137/1.9780898719017},
  file            = {:C\:/Users/pcoppens/Workspace/references/books/Shorack & Wellner (2009) - Empirical Processes with Applications to Statistics.pdf:pdf},
  isbn            = {978-0-89871-684-9},
  mendeley-groups = {Ben/Projects/Elementary Coverage/Mean Confidence},
  omonth           = {jan},
  opublisher       = {SIAM},
  publisher       = {SIAM},
  title           = {{Empirical Processes with Applications to Statistics}},
  url             = {http://epubs.siam.org/doi/book/10.1137/1.9780898719017},
  year            = {2009}
}

@article{Moscovich2020,
  abstract        = {We present a method for computing exact p-values for a large family of one-sided continuous goodness-of-fit statistics. This includes the higher criticism statistic, one-sided weighted Kolmogorov-Smirnov statistics, and the one-sided Berk-Jones statistics. For a sample size of 10,000, our method takes merely 0.15 seconds to run and it scales to sample sizes in the hundreds of thousands. This allows practitioners working on genome-wide association studies and other high-dimensional analyses to use exact finite-sample computations instead of statistic-specific approximation schemes. Our work has other applications in statistics, including power analysis, finding alpha-level thresholds for goodness-of-fit tests, and the construction of confidence bands for the empirical distribution function. The algorithm is based on a reduction to the boundary-crossing probability of a pure jump process and is also applicable to fields outside of statistics, for example in financial risk modeling.},
  archiveprefix   = {arXiv},
  arxivid         = {2009.04954},
  author          = {Moscovich, Amit},
  eprint          = {2009.04954},
  file            = {:C\:/Users/pcoppens/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Moscovich - 2020 - Fast calculation of p-values for one-sided Kolmogorov-Smirnov type statistics.pdf:pdf},
  mendeley-groups = {Ben/Projects/Elementary Coverage/Kolmogorov-Smirnov},
  omonth           = {sep},
  title           = {{Fast calculation of p-values for one-sided Kolmogorov-Smirnov type statistics}},
  url             = {http://arxiv.org/abs/2009.04954},
  year            = {2020}
}

@article{Rockafellar2000,
  abstract        = {A new approach to optimizing or hedging a portfolio of financial instruments to reduce risk is presented and tested on applications. It focuses on minimizing conditional value-at-risk (CVaR) rather than minimizing value-at-risk (VaR), but portfolios with low CVaR necessarily have low VaR as well. CVaR, also called mean excess loss, mean shortfall, or tail VaR, is in any case considered to be a more consistent measure of risk than VaR. Central to the new approach is a technique for portfolio optimization which calculates VaR and optimizes CVaR simultaneously. This technique is suitable for use by investment companies, brokerage firms, mutual funds, and any business that evaluates risk. It can be combined with analytical or scenario-based methods to optimize portfolios with large numbers of instruments, in which case the calculations often come down to linear programming or nonsmooth programming. The methodology can also be applied to the optimization of percentiles in contexts outside of finance.},
  author          = {Rockafellar, R. Tyrrell and Uryasev, Stanislav},
  doi             = {10.21314/jor.2000.038},
  file            = {:C\:/Users/pcoppens/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rockafellar, Uryasev - 2000 - Optimization of conditional value-at-risk.pdf:pdf},
  issn            = {14651211},
  journal         = {The Journal of Risk},
  mendeley-groups = {Ben/General,Ben/Projects/Elementary Coverage/Mean Confidence},
  number          = {3},
  pages           = {21--41},
  title           = {{Optimization of conditional value-at-risk}},
  volume          = {2},
  year            = {2000}
}

@article{Chun2012,
  abstract        = {We discuss linear regression approaches to the estimation of law-invariant conditional risk measures. Two estimation procedures are considered and compared; one is based on residual analysis of the standard least-squares method, and the other is in the spirit of the M-estimation approach used in robust statistics. In particular, value-at-risk and average valueat- risk measures are discussed in detail. Large sample statistical inference of the estimators is derived. Furthermore, finite sample properties of the proposed estimators are investigated and compared with theoretical derivations in an extensive Monte Carlo study. Empirical results on the real data (different financial asset classes) are also provided to illustrate the performance of the estimators. {\textcopyright} 2012 INFORMS.},
  author          = {Chun, So Yeon and Shapiro, Alexander and Uryasev, Stan},
  doi             = {10.1287/opre.1120.1072},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Akensu2016/Chun2012.pdf:pdf},
  issn            = {0030364X},
  journal         = {Operations Research},
  mendeley-groups = {Workspace,Workspace/Projects/Elementary Coverage/Distortion Risk},
  number          = {4},
  pages           = {739--756},
  title           = {{Conditional value-at-risk and average value-at-risk: Estimation and asymptotics}},
  volume          = {60},
  year            = {2012}
}

@book{Wilks1964,
  oaddress         = {New York},
  author          = {Wilks, Samuel Stanley},
  file            = {:C\:/Users/pcoppens/Workspace/references/books/Wilks (1962) - Mathematical Statistics.pdf:pdf},
  mendeley-groups = {Workspace/Projects/Elementary Coverage,Workspace/Projects/Elementary Coverage/Tolerance Intervals},
  publisher       = {John Wiley \& Sons, Inc.},
  title           = {{Mathematical Statistics}},
  year            = {1964}
}

@book{Marshall2011,
  oaddress         = {New York, NY},
  author          = {Marshall, Albert W and Olkin, Ingram and Arnold, Barry C},
  doi             = {10.1007/978-0-387-68276-1},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Ebhard2021/Marshall et. al. (2011) - Theory of Majorization and Its Applications.pdf:pdf},
  isbn            = {978-0-387-40087-7},
  mendeley-groups = {Workspace/Projects/Elementary Coverage/Majorization},
  publisher       = {Springer New York},
  oseries          = {Springer Series in Statistics},
  title           = {{Inequalities: Theory of Majorization and Its Applications}},
  url             = {http://link.springer.com/10.1007/978-0-387-68276-1},
  year            = {2011}
}

@article{Ruszczynski2006,
  abstract        = {We consider optimization problems involving convex risk functions. By employing techniques of convex analysis and optimization theory in vector spaces of measurable functions, we develop new representation theorems for risk models, and optimality and duality theory for problems with convex risk functions. {\textcopyright} 2006 INFORMS.},
  author          = {Ruszczy{\'{n}}ski, Andrzej and Shapiro, Alexander},
  doi             = {10.1287/moor.1050.0186},
  file            = {:C\:/Users/pcoppens/Workspace/references/papers/Ruszczyinsk2006b.pdf:pdf},
  issn            = {0364765X},
  journal         = {Mathematics of Operations Research},
  keywords        = {Convex analysis,Duality,Risk measures,Stochastic optimization},
  mendeley-groups = {Workspace/Publications/CDC2021/Core},
  number          = {3},
  pages           = {433--452},
  title           = {{Optimization of convex risk functions}},
  volume          = {31},
  year            = {2006}
}

@article{Bertsimas2009b,
  abstract        = {In this paper, we propose a methodology for constructing uncertainty sets within the framework of robust optimization for linear optimization problems with uncertain parameters. Our approach relies on decision maker risk preferences. Specifically, we utilize the theory of coherent risk measures initiated by Artzner et al. (1999) [Artzner, P., F. Delbaen, J. Eber, D. Heath. 1999. Coherent measures of risk. Math. Finance 9 203-228.], and show that such risk measures, in conjunction with the support of the uncertain parameters, are equivalent to explicit uncertainty sets for robust optimization. We explore the structure of these sets in detail. In particular, we study a class of coherent risk measures, called distortion risk measures, which give rise to polyhedral uncertainty sets of a special structure that is tractable in the context of robust optimization. In the case of discrete distributions with rational probabilities, which is useful in practical settings when we are sampling from data, we show that the class of all distortion risk measures (and their corresponding polyhedral sets) are generated by a finite number of conditional value-at-risk (CVaR) measures. A subclass of the distortion risk measures corresponds to polyhedral uncertainty sets symmetric through the sample mean. We show that this subclass is also finitely generated and can be used to find inner approximations to arbitrary, polyhedral uncertainty sets. {\textcopyright} 2009 INFORMS.},
  author          = {Bertsimas, Dimitris and Brown, David B.},
  doi             = {10.1287/opre.1080.0646},
  file            = {:C\:/Users/pcoppens/Workspace/references/papers/Bertsimas2009.pdf:pdf},
  issn            = {0030-364X},
  journal         = {Operations Research},
  mendeley-groups = {Workspace/Projects/Concentration},
  omonth           = {dec},
  number          = {6},
  pages           = {1483--1495},
  title           = {{Constructing Uncertainty Sets for Robust Linear Optimization}},
  url             = {http://pubsonline.informs.org/doi/abs/10.1287/opre.1080.0646},
  volume          = {57},
  year            = {2009}
}

@book{Bonnans2000,
  oaddress         = {New York, NY},
  author          = {Bonnans, J. Fr{\'{e}}d{\'{e}}ric and Shapiro, Alexander},
  booktitle       = {Analysis},
  doi             = {10.1007/978-1-4612-1394-9},
  file            = {:C\:/Users/pcoppens/Workspace/references/books/Bonnans&Shapiro(2000) - Perturbation analysis of optimization problems.pdf:pdf},
  isbn            = {978-1-4612-7129-1},
  keywords        = {and financial engineering,inger oseries in operations,research},
  mendeley-groups = {Workspace/General},
  pages           = {524},
  publisher       = {Springer New York},
  title           = {{Perturbation Analysis of Optimization Problems}},
  url             = {http://link.springer.com/10.1007/978-1-4612-1394-9},
  year            = {2000}
}

@article{Shapiro2013,
  abstract        = {In this paper we discuss representations of law invariant coherent risk measures in a form of integrals of the average value-at-risk measures. We show that such an integral representation exists iff the dual set of the considered risk measure is generated by one of its elements, and this representation is uniquely defined. On the other hand, representation of risk measures as a maximum of such integral forms is not unique. The suggested approach gives a constructive way for writing such representations. {\textcopyright}2013 INFORMS.},
  author          = {Shapiro, Alexander},
  doi             = {10.1287/moor.1120.0563},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Bowman1972/Shapiro2013.pdf:pdf},
  issn            = {0364765X},
  journal         = {Mathematics of Operations Research},
  keywords        = {Average value-at-risk,Coherent risk measures,Comonotonic risk measures,Fenchel-moreau theorem,Law invariance},
  mendeley-groups = {Workspace/Projects/Elementary Coverage/Distortion Risk},
  number          = {1},
  pages           = {142--152},
  title           = {{On kusuoka representation of law invariant risk measures}},
  volume          = {38},
  year            = {2013}
}

@article{Best2000,
  author          = {Best, Michael J and Chakravarti, Nilotpal and Ubhaya, Vasant A},
  doi             = {10.1137/S1052623497314970},
  file            = {:C\:/Users/pcoppens/Workspace/references/papers/Best2000.pdf:pdf},
  issn            = {1052-6234},
  journal         = {SIAM Journal on Optimization},
  keywords        = {26a48,68q25,90c25,ams subject classifications,computational complexity,convex,functions,isotonic regression,median regression,pii,pool adjacent violators algorithm,s1052623497314970},
  mendeley-groups = {Workspace/Projects/Elementary Coverage/Isotonic},
  omonth           = {jan},
  number          = {3},
  pages           = {658--672},
  title           = {{Minimizing Separable Convex Functions Subject to Simple Chain Constraints}},
  url             = {http://epubs.siam.org/doi/10.1137/S1052623497314970},
  volume          = {10},
  year            = {2000}
}

@book{Beck2017,
  author    = {Beck, Amir},
  title     = {First-Order Methods in Optimization},
  publisher = {SIAM},
  year      = {2017},
  doi       = {10.1137/1.9781611974997},
  oaddress   = {Philadelphia, PA},
  edition   = {},
  ourl       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611974997},
  oeprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611974997}
}

@book{Rockafellar1998,
  oaddress         = {Berlin, Heidelberg},
  author          = {Rockafellar, R. Tyrrell and Wets, Roger J. B.},
  doi             = {10.1007/978-3-642-02431-3},
  file            = {:C\:/Users/pcoppens/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rockafellar, Wets - 1997 - Variational Analysis.pdf:pdf},
  isbn            = {978-3-540-62772-2},
  issn            = {10895639},
  mendeley-groups = {Workspace/General},
  pmid            = {18348555},
  publisher       = {Springer Berlin Heidelberg},
  oseries          = {Grundlehren der mathematischen Wissenschaften},
  title           = {{Variational Analysis}},
  url             = {http://link.springer.com/10.1007/978-3-642-02431-3},
  volume          = {317},
  year            = {1998}
}

@book{Meeker2017,
   title =     {Statistical Intervals: A Guide for Practitioners and Researchers},
   author =    {William Q. Meeker, Gerald J. Hahn, Luis A. Escobar},
   publisher = {Wiley},
   year =      {2017},
   oseries =    {Wiley Series in Probability and Statistics},
   edition =   {2ed.}
}

@article{coppens2021data,
  title     = {Data-driven distributionally robust MPC for constrained stochastic systems},
  author    = {Coppens, Peter and Patrinos, Panagiotis},
  journal   = {IEEE Control Systems Letters},
  volume    = {6},
  pages     = {1274--1279},
  year      = {2021},
  publisher = {IEEE}
}
@book{Pflug2007,
  author          = {Pflug, Georg Ch and R{\"{o}}misch, Werner},
  doi             = {10.1142/6478},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Bowman1972/Pflug & Romisch (2007) - Modeling, Measuring and Managing Risk.pdf:pdf},
  isbn            = {978-981-270-740-6},
  mendeley-groups = {Workspace/Projects/Elementary Coverage/Distortion Risk},
  omonth           = {aug},
  publisher       = {World Scientific},
  title           = {{Modeling, Measuring and Managing Risk}},
  url             = {https://www.worldscientific.com/worldscibooks/10.1142/6478},
  year            = {2007}
}

@article{Mehta2022,
  abstract        = {Spectral risk objectives - also called $L$-risks - allow for learning systems to interpolate between optimizing average-case performance (as in empirical risk minimization) and worst-case performance on a task. We develop stochastic algorithms to optimize these quantities by characterizing their subdifferential and oaddressing challenges such as biasedness of subgradient estimates and non-smoothness of the objective. We show theoretically and experimentally that out-of-the-box approaches such as stochastic subgradient and dual averaging are hindered by bias and that our approach outperforms them.},
  archiveprefix   = {arXiv},
  arxivid         = {2212.05149},
  author          = {Mehta, Ronak and Roulet, Vincent and Pillutla, Krishna and Liu, Lang and Harchaoui, Zaid},
  eprint          = {2212.05149},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Rockafellar2014/Mehta2022.pdf:pdf},
  mendeley-groups = {Workspace/Projects/Elementary Coverage/Distortion Risk},
  title           = {{Stochastic Optimization for Spectral Risk Measures}},
  url             = {http://arxiv.org/abs/2212.05149},
  year            = {2022}
}

@book{David2003,
  oaddress         = {Hoboken, NJ, USA},
  author          = {David, H. A. and Nagaraja, H. N.},
  doi             = {10.1002/0471722162},
  file            = {:C\:/Users/pcoppens/Workspace/references/books/David & Nagaraja (2003) - Order Statistics.pdf:pdf},
  isbn            = {9780471722168},
  mendeley-groups = {Workspace/Background/Scenario Approach,Workspace/Projects/Elementary Coverage,Workspace/Projects/Elementary Coverage/Tolerance Intervals},
  omonth           = {jul},
  publisher       = {John Wiley \& Sons, Inc.},
  oseries          = {Wiley Series in Probability and Statistics},
  title           = {{Order Statistics}},
  url             = {http://doi.wiley.com/10.1002/0471722162},
  year            = {2003}
}

@book{Scholkopf2002,
  title     = {Learning with kernels: support vector machines, regularization, optimization, and beyond},
  author    = {Sch{\"o}lkopf, Bernhard and Smola, Alexander J and Bach, Francis and others},
  year      = {2002},
  publisher = {MIT press}
}


@inproceedings{Zhu2021,
  title     = { Kernel Distributionally Robust Optimization: Generalized Duality Theorem and Stochastic Approximation },
  author    = {Zhu, Jia-Jie and Jitkrittum, Wittawat and Diehl, Moritz and Sch{\"o}lkopf, Bernhard},
  booktitle = {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
  pages     = {280--288},
  year      = {2021},
  editor    = {Banerjee, Arindam and Fukumizu, Kenji},
  volume    = {130},
  oseries    = {Proceedings of Machine Learning Research},
  omonth     = {13--15 Apr},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v130/zhu21a/zhu21a.pdf},
  url       = {https://proceedings.mlr.press/v130/zhu21a.html},
  abstract  = { We propose kernel distributionally robust optimization (Kernel DRO) using insights from the robust optimization theory and functional analysis. Our method uses reproducing kernel Hilbert spaces (RKHS) to construct a wide range of convex ambiguity sets, which can be generalized to sets based on integral probability metrics and finite-order moment bounds. This perspective unifies multiple existing robust and stochastic optimization methods. We prove a theorem that generalizes the classical duality in the mathematical problem of moments. Enabled by this theorem, we reformulate the maximization with respect to measures in DRO into the dual program that searches for RKHS functions. Using universal RKHSs, the theorem applies to a broad class of loss functions, lifting common limitations such as polynomial losses and knowledge of the Lipschitz constant. We then establish a connection between DRO and stochastic optimization with expectation constraints. Finally, we propose practical algorithms based on both batch convex solvers and stochastic functional gradient, which apply to general optimization and machine learning tasks. }
}

@book{Bauschke2011,
  oaddress         = {New York, NY},
  author          = {Bauschke, Heinz H. and Combettes, Patrick L.},
  doi             = {10.1007/978-1-4419-9467-7},
  file            = {:C\:/Users/pcoppens/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bauschke, Combettes - 2011 - Convex Analysis and Monotone Operator Theory in Hilbert Spaces.pdf:pdf},
  isbn            = {978-1-4419-9466-0},
  mendeley-groups = {Workspace/General,Workspace/Projects/Elementary Coverage/SVM},
  publisher       = {Springer New York},
  oseries          = {CMS Books in Mathematics},
  title           = {{Convex Analysis and Monotone Operator Theory in Hilbert Spaces}},
  url             = {http://link.springer.com/10.1007/978-1-4419-9467-7 https://link.springer.com/10.1007/978-1-4419-9467-7},
  year            = {2011}
}

@book{Hardy1952,
  title     = {Inequalities},
  author    = {Hardy, Godfrey Harold and Littlewood, John Edensor and P{\'o}lya, George and P{\'o}lya, Gy{\"o}rgy and others},
  year      = {1952},
  publisher = {Cambridge university press}
}

@book{Campi2018,
  author    = {Campi, Marco C. and Garatti, Simone},
  title     = {Introduction to the Scenario Approach},
  publisher = {SIAM},
  year      = {2018},
  doi       = {10.1137/1.9781611975444},
  oaddress   = {Philadelphia, PA},
  edition   = {},
  ourl       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611975444},
  oeprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611975444}
}

@inproceedings{Garatti2021,
  author    = {Garatti, Simone and Campi, Marco C.},
  booktitle = {2021 60th IEEE Conference on Decision and Control (CDC)},
  title     = {On the consistency of the risk evaluation in the scenario approach},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {1468-1473},
  doi       = {10.1109/CDC45484.2021.9682992}
}

@article{Chouzenoux2019,
  archiveprefix   = {arXiv},
  arxivid         = {1904.11707v2},
  author          = {Chouzenoux, {\'{E}}milie and G{\'{e}}rard, Henri and Pesquet, Jean-Christophe},
  doi             = {10.3934/fods.2019011},
  oeprint          = {1904.11707v2},
  file            = {:C\:/Users/pcoppens/Workspace/references/papers/Chouzenoux2019.pdf:pdf},
  issn            = {2639-8001},
  journal         = {Foundations of Data Science},
  keywords        = {convex opti-,divergences,machine learning,mization,risk measures,robust statistics,wasserstein distance},
  mendeley-groups = {Workspace/Projects/Elementary Coverage/Divergence},
  number          = {3},
  pages           = {249--269},
  title           = {{General risk measures for robust machine learning}},
  url             = {http://aimsciences.org//article/doi/10.3934/fods.2019011},
  volume          = {1},
  year            = {2019}
}

@article{Pichler2021,
  abstract        = {Distributionally robust optimization involves various probability measures in its problem formulation. They can be bundled to constitute a risk functional. For this equivalence, risk functionals constitute a fundamental building block in distributionally robust stochastic programming. Multistage programming requires conditional versions of risk functionals to re-assess future risk after partial realizations and after preceding decisions. This paper discusses a construction of the conditional counterpart of a risk functional by passing its genuine characteristics to its conditional counterparts. The conditional risk functionals turn out to be different from the nested analogues of the original (law invariant) risk measure. It is demonstrated that the initial measure and its nested decomposition can be used in a distributionally robust multistage setting.},
  archiveprefix   = {arXiv},
  arxivid         = {2101.02498},
  author          = {Pichler, Alois and Shapiro, Alexander},
  eprint          = {2101.02498},
  file            = {:C\:/Users/pcoppens/Workspace/references/papers/Pichler2021.pdf:pdf},
  keywords        = {60b05,62p05,90c08,90c15,90c31,ams subject classification,con-,distributional robustness,ditional risk measures,stochastic programming},
  mendeley-groups = {Workspace/Background/Interesting},
  omonth           = {jan},
  opages           = {1--29},
  title           = {{Mathematical Foundations of Distributionally Robust Multistage Optimization}},
  url             = {http://arxiv.org/abs/2101.02498},
  year            = {2021}
}

@article{Rahimian2019,
  abstract        = {The concepts of risk-aversion, chance-constrained optimization, and robust optimization have developed significantly over the last decade. Statistical learning community has also witnessed a rapid theoretical and applied growth by relying on these concepts. A modeling framework, called distributionally robust optimization (DRO), has recently received significant attention in both the operations research and statistical learning communities. This paper surveys main concepts and contributions to DRO, and its relationships with robust optimization, risk-aversion, chance-constrained optimization, and function regularization.},
  archiveprefix   = {arXiv},
  arxivid         = {1908.05659},
  author          = {Rahimian, Hamed and Mehrotra, Sanjay},
  eprint          = {1908.05659},
  file            = {:C\:/Users/pcoppens/Workspace/references/papers/Rahimian2019.pdf:pdf},
  ojournal         = {arXiv preprint arXiv:1908.05659},
  keywords        = {Distributionally Robust,Survey,chance-constrained optimization,distributionally robust optimization,risk-averse optimization,robust optimization,statistical learning,stochastic optimization},
  mendeley-groups = {Workspace,Workspace/General},
  mendeley-tags   = {Distributionally Robust,Survey},
  title           = {{Distributionally Robust Optimization: A Review}},
  url             = {http://arxiv.org/abs/1908.05659},
  year            = {2019}
}

@article{Lin2022,
  abstract        = {In this paper, we survey the primary research on the theory and applications of distributionally robust optimization (DRO). We start with reviewing the modeling power and computational attractiveness of DRO approaches, induced by the ambiguity sets structure and tractable robust counterpart reformulations. Next, we summarize the efficient solution methods, out-of-sample performance guarantee, and convergence analysis. Then, we illustrate some applications of DRO in machine learning and operations research, and finally, we discuss the future research directions.},
  author          = {Lin, Fengming and Fang, Xiaolei and Gao, Zheming},
  doi             = {10.3934/naco.2021057},
  file            = {:C\:/Users/pcoppens/Workspace/references/papers/Lin2022.pdf:pdf},
  issn            = {2155-3289},
  journal         = {Numerical Algebra, Control \& Optimization},
  mendeley-groups = {Workspace/General,Workspace/Active},
  number          = {1},
  pages           = {159},
  title           = {{Distributionally Robust Optimization: A review on theory and applications}},
  url             = {https://www.aimsciences.org/article/doi/10.3934/naco.2021057},
  volume          = {12},
  year            = {2022}
}

@article{Eberhard2020,
  abstract        = {In this paper we discuss the use of group symmetries in optimisation, in particular with respect to the structure of subdifferentials and projection operators. This allows us to study the normal cone structure of orbitopes associated with group majorisations. In particular we emphasis the utility of the “fundamental chamber” as a tool to simplify analysis. This allows us to simplify and generalise results on projections onto symmetric sets, in particular, we study projections and normal cones to sparsity constraints used in sparse signal recovery and compressed sensing using this framework.},
  author          = {Eberhard, Andrew},
  doi             = {10.1007/s10013-020-00418-y},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Ebhard2021/Eberhard2020.pdf:pdf},
  issn            = {2305-221X},
  journal         = {Vietnam Journal of Mathematics},
  keywords        = {Compressed sensing,Group symmetries,Projecions,Subdfferentials},
  mendeley-groups = {Workspace/Projects/Elementary Coverage/Majorization},
  omonth           = {sep},
  number          = {3},
  pages           = {537--567},
  publisher       = {Vietnam Journal of Mathematics},
  title           = {{Orbital Geometry and Group Majorisation in Optimisation}},
  url             = {https://link.springer.com/10.1007/s10013-020-00418-y},
  volume          = {48},
  year            = {2020}
}

@inproceedings{Negrinho2014,
  author          = {Negrinho, Renato and Martins, Andre},
  booktitle       = {Advances in Neural Information Processing Systems},
  editor          = {Weinberger, Z. Ghahramani and Welling, M. and Cortes, C. and Lawrence, N. and Weinberger, K.Q.},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Ebhard2021/Negrinho2014.pdf:pdf},
  mendeley-groups = {Workspace/Projects/Elementary Coverage/Majorization},
  publisher       = {Curran Associates, Inc.},
  title           = {{Orbit Regularization}},
  url             = {https://proceedings.neurips.cc/paper/2014/file/f670ef5d2d6bdf8f29450a970494dd64-Paper.pdf},
  volume          = {27},
  year            = {2014}
}


@article{Barlow1972,
  author          = {Barlow, R. E. and Brunk, H. D.},
  doi             = {10.1080/01621459.1972.10481216},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Ebhard2021/Barlow1972.pdf:pdf},
  issn            = {0162-1459},
  journal         = {Journal of the American Statistical Association},
  mendeley-groups = {Workspace/Projects/Elementary Coverage/Majorization},
  omonth           = {mar},
  number          = {337},
  pages           = {140--147},
  title           = {{The Isotonic Regression Problem and its Dual}},
  url             = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1972.10481216},
  volume          = {67},
  year            = {1972}
}

@incollection{Eaton1984,
  abstract        = {Orderings defined by compact groups of linear transformations acting on vector spaces are studied. In some cases, these orderings induce orderings on convex cones similar to those defined by reflection groups. In these cases the monotone functions can be conveniently characterized. Convolution theorems for monotone functions are discussed.},
  author          = {Eaton, Morris L.},
  doi             = {10.1214/lnms/1215465625},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Ebhard2021/Eaton1980.pdf:pdf},
  keywords        = {and phrases,group induced orderings,monotone functions,reflection groups,schur convexity},
  mendeley-groups = {Workspace/Projects/Elementary Coverage/Majorization},
  pages           = {13--25},
  title           = {{On group induced orderings, monotone functions, and convolution theorems}},
  url             = {http://projecteuclid.org/euclid.lnms/1215465625},
  volume          = {5},
  year            = {1984}
} 

@article{Steerneman1990,
  author          = {Steerneman, A.G.M.},
  doi             = {10.1016/0024-3795(90)90338-D},
  file            = {:C\:/Users/pcoppens/OneDrive/Documents/active/Ebhard2021/Steerneman1990.pdf:pdf},
  issn            = {00243795},
  journal         = {Linear Algebra and its Applications},
  mendeley-groups = {Workspace/Projects/Elementary Coverage/Majorization},
  pages           = {107--119},
  title           = {{G-Majorization, group-induced cone orderings, and reflection groups}},
  url             = {https://linkinghub.elsevier.com/retrieve/pii/002437959090338D},
  volume          = {127},
  year            = {1990}
}

@article{Schuurmans2023,
  author={Schuurmans, Mathijs and Patrinos, Panagiotis},
  journal={IEEE Transactions on Automatic Control}, 
  title={A General Framework for Learning-Based Distributionally Robust MPC of Markov Jump Systems}, 
  year={2023},
  volume={},
  number={},
  pages={1-16},
  doi={10.1109/TAC.2023.3237999}
}

@book{Boyd2004,
  title={Convex optimization},
  author={Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}