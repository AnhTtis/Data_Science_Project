\section{Introduction}
The problem of \emph{expected risk minimization} is ubiquitous in machine learning and statistics \cite{Shalev-Shwartz2013,Vapnik1998}.
It is based on the idea that the quality of a model can be assessed by measuring its expected error, quantified by some loss function. The expectation 
should be evaluated with respect to the data-generating distribution. However, in practice, only samples are available. So the expectation 
needs to be replaced with a data-driven proxy, which aggregates the data. The common solution is \emph{empirical risk minimization}
or the \emph{sample average approach (SAA)}, where one takes an average over the losses at the sampled data points. 

Despite its advantages, the SAA often exhibits excessive sensitivity to the specific data realizations, particularly in high-dimensional settings \cite[\S8.H]{Royset2022}, 
leading to diminished generalization capabilities of the model. To address this, researchers have turned to \emph{Distributionally Robust Optimization (DRO)}, aiming to robustify against disparities 
between the empirical and true data-generating distributions.

In DRO, a worst-case expectation with respect to distributions in an \emph{ambiguity set} centered on the empirical distribution serves as a proxy for the true expected risk. 
This set can be based on the Wasserstein distance \cite{Esfahani2018b}, $\phi$-divergences \cite{Ben-Tal2013}, hypothesis tests \cite{Bertsimas2009b}, and others. 
See \cite{Rahimian2019,Lin2022} for recent surveys. However, DRO faces challenges when determining the ambiguity set's size. 
Current approaches rely on concentration inequalities \cite{Delage2010} or asymptotic bounds \cite{Ben-Tal2013}, ensuring that true distribution is contained within the ambiguity 
set with high probability. Unfortunately, this often results in conservatism, caused by either loose constants in the concentration 
inequalities or the shape of the ambiguity set. As an alternative,  
bootstrapping or cross validation techniques are often employed (cf. \cite{Esfahani2018b}).
These can be computationally expensive and lack statistical guarantees for finite samples, similarly to the asymptotic bounds. 
Such guarantees are a requirement in safety-critical applications like control (e.g. constraint tightening in tube-based MPC \cite{Lorenzen2017, Aolaritei2023}).

To address conservativeness issues, \cite{Duchi2021b,Lam2019} focus on bounding the expectation directly as an alternative 
to creating a confidence bound for the entire distribution. 
This mimics the focus on the expectation in the statistical learning framework of \cite[\S1]{Vapnik1998}. However, their bounds are 
asymptotic and therefore also lack strong statistical guarantees. In this paper, we take the first steps towards a finite-sample version of their scheme. 
To achieve this, we draw inspiration from results in \emph{order statistics} \cite{David2003} and \emph{stochastic orders} \cite{Shaked2007} to motivate 
the use of permutation invariant ambiguity sets. Notably, the $\phi$-divergences used in \cite{Duchi2021b,Lam2019,Van2021} produce a specific case. We coin the term \emph{ordered risk minimization}
to emphasize our statistical motivations. We demonstrate how to calibrate the ambiguity set's size to upper bound the true 
expectation with high probability, even when the true distribution does not fall within the ambiguity set. 
This probability serves as an intuitive tuning parameter.

The remainder of the paper continues as follows. We first present some notation, before moving on the the problem statement in \cref{sec:problem}. 
There the proxy costs we use are presented as well as the calibration problem. We present the statistical interpretation of these proxy costs 
as high confidence upper bounds in \cref{sec:statistics} and solve the calibration problem in \cref{sec:calibration}. Numerical experiments are 
then presented in \cref{sec:case-studies}.

\paragraph*{Notation} Let $\Re$ denote the reals\ilarxiv{{ }and $\eRe$ the extended reals}. 
For some convex function $\phi \colon \Re^n \to \ilarxiv{\eRe}\ilpub{\Re}$, let $\phi^*$ denote the convex conjugate\ilarxiv{, $\partial \phi$ the subgradient}\ilarxiv{{ }and
$\dom \phi$ its domain}. 
\ilarxiv{For a set $\set{X}$ let $\iota_{\set{X}}(x) = 0$ if $x \in \set{X}$ and $+\infty$ otherwise be the indicator function of $\set{X}$.}
For integers $a, b$ let $[a, b] = \{a, \dots, b\}$ and $[b] = \{1, \dots, b\}$. Let $[x]_+ = \max(0, x)$. 
For real vectors $x, y \in \Re^n$ we use $\< x, y\>$ to denote the Euclidean inner product\ilarxiv{{ }and $\one_n \in \Re^n$ is the vector of all ones}. 
For a cone $\set{K}$ let $\set{K}^\circ \dfn \{y \colon \<x, y\> \leq 0, \forall x \in \set{K}\}$ denote its polar cone. 
%We use $x \leqc{K} y$ to denote that $y - x \in \set{K}$. 
Let $\Pi^n$ denote the permutations of $[n]$ (i.e., all bijections $[n] \to [n]$). We write $\pi x = (x_{\pi(1)}, \dots, x_{\pi(n)})$
for $\pi \in \Pi^n$, $x \in \Re^n$ and % and similarly for sets $\pi \set{X} = \{\pi x \colon x \in \set{X}\}$. 
similarly let $\Pi^n y = \{\pi y \colon \pi \in \Pi^n\}$ denote the orbit of $y$ under $\Pi^n$.
Let $\Re^n_{\uparrow} \dfn \{x \colon x_{1} \leq x_2 \leq \dots \leq x_n\}$ 
denote the monotone cone and $\major{n}$ its polar (cf. \cref{prop:dual-monotone-cone} and \cref{eq:majorization-cone}). 
Let $\Delta^n \dfn \{\mu \colon \sum_{i=1}^n \mu_i = 1, \mu_i \geq 0, i \in [n]\}$ denote the probability simplex.
For a vector $x \in \Re^n$ let $x_{(1)} \leq x_{(2)} \leq \dots \leq x_{(n)}$ be the increasing permutation of the elements of $x$
with $x_{\uparrow} = (x_{(1)}, x_{(2)}, \dots, x_{(n)})$. 
For sets $A$, $B$ let $A + B \dfn \{a + b \colon a \in {A}, b \in {B}\}$
denote the Minkowski sum. 
For random variables $X, Y$ we write $X \deq Y$ to say $X$ is identically distributed to $Y$. Let $\esssup[X]$ 
denote the essential supremum. Let $X \deq \mathrm{U}[\ell, u]$ imply $X$ is uniformly distributed over $[\ell, u]$. For a set $A$, $X \deq \mathrm{U}[A]$ is then
uniformly distributed over $A$. Finally let $X \deq \mathcal{N}(\mu, \Sigma)$ 
denote $X$ that is normally distributed with mean $\mu$ and covariance $\Sigma$. 



\section{Problem Statement} \label{sec:problem}
We consider expected risk minimization 
\begin{equation} \label{eq:erm}
    \minimize_{\theta \in \Theta} \quad \E[\ell(\theta, \xi)].
\end{equation}
Here $\Theta \subseteq \Re^{n_\theta}$ and $\xi \colon \Omega \to \Xi \subseteq \Re^{n_\xi}$ is a random vector on a 
probability space $(\Omega, \F, \prob)$. As is common \cite{Vapnik1998,Shalev-Shwartz2013}, we then assume access to 
\emph{independent and identically distributed (iid) samples} $\xi^{(1)}, \dots, \xi^{(n-1)}$. Let $\ell_i(\theta) = \ell(\theta, \xi^{(i)})$ for $i=1, \dots, n-1$ and 
take $\ell_n(\theta)$ such that it upper bounds the cost almost surely. That is $\prob[\ell(\theta, \xi) \leq \ell_n(\theta)] = 1$.
It is assumed that $\ell_n(\theta)$ is finite for any $\theta$. We do so for two reasons: \emph{(i)} an assumption on the tail of the distribution of 
$\ell(\theta, \xi)$ is required to find a confidence interval for the mean \cite{Bahadur1956}; \emph{(ii)} the scheme is simplified considerably. 
An example of a valid bound is $\ell_n(\theta) = \sup_{\xi \in \Xi} \, \ell(\theta, \xi)$. 

We will use a data-driven proxy for the expectation by introducing \emph{permutation invariant ambiguity sets}.
These are subsets $\amb$ of the probability simplex $\Delta^n$ such that, for each $\mu \in \amb$ any permutation of $\mu$ is also in $\amb$. 
The \emph{ordered risk minimization} problem is then: 
\begin{equation} \label{eq:ordered-risk}
    \minimize_{\theta \in \Theta} \quad \sup_{\mu \in \amb} \, \sum_{i=1}^{n} \mu_i \ell_i(\theta). 
\end{equation}
This proxy cost interpolates between the robust case for $\amb = \Delta^n$
and the sample average (including a term associated with $\ell_n(\theta)$) when $\amb = \{\one_n/n\}$.
The interpolation interpretation is also common in DRO \cite{Ben-Tal2013}. To find a good balance, our goal is to select $\amb$ such that, for all $\theta \in \Theta$,
\begin{equation} \label{eq:calibration}
    \prob\left[ \sup_{\mu \in \amb} \, \sum_{i=1}^{n} \mu_i \ell_i(\theta) \geq \E[\ell(\theta, \xi)] \right] \geq 1 - \delta,
\end{equation}
We refer to this problem as the \emph{calibration problem}. It robustifies against disparities between the empirical and true distributions. 
The parameter $\delta$ then serves as an intuitive, user-determined parameter that controls the conservativeness of the method. However, as illustrated by experiments, 
our method is relatively insensitive to the value of $\delta$. 

To find an ambiguity set $\amb$ satisfying \cref{eq:calibration} we need to somehow parametrize it. 
A well known class of permutation invariant ambiguity sets uses $\phi$-divergences \cite{Ben-Tal2013}. 
Let $\phi \colon \Re_+ \to \Re$ be lower semicontinuous, convex and $\phi(1) = 0$. 
Also, let\footnote{We take the 
lower semicontinuous envelope of the terms inside the sum \cite[Def.~6]{Chouzenoux2019} to handle cases where $\nu_i$ equals zero.}
$I_{\phi}(\mu, \nu) \dfn \ssum_{i=1}^{n} \nu_i \phi(\mu_i / \nu_i)$ for all $\mu, \nu \in \Delta^n$. 
A \emph{(centered) $\phi$-divergence ambiguity set} is then
\begin{equation} \label{eq:ambiguity-phi-div}
    \amb_{\alpha} \dfn \left\{ \mu \in \Delta^{n} \colon I_{\phi}\left(\mu, \frac{\one_{n}}{n}\right) = \sum_{i=1}^{n}  \frac{\phi(n \mu_i)}{n} \leq \alpha \right\}.
\end{equation}
In this work we consider two examples: \emph{total variation (TV)} for which $\phi(t) = |t - 1|$ and 
\emph{Kullback Leibler (KL)} divergence for which $\phi(t) = t \log t - t + 1$. However, our method works for any divergence. See \cite{Ben-Tal2013} for more examples.

To calibrate $\amb_\alpha$ the radius $\alpha \in \Re$ should then be the smallest value such that \cref{eq:calibration} still holds. We also provide an alternative parametrization, 
related to a well known bound by Anderson \cite{Anderson1969} and the conditional value-at-risk. 

% In this work, we investigate the selection of $\alpha$. It should be selected such that \cref{eq:divrm} is likely to upper bound 
% the true expectation in \cref{eq:erm}, as motivated in the introduction. 
% That is, find the lowest $\alpha \in \Re$ such that
% \begin{equation} \label{eq:point-wise}
%      \prob\left[ \max_{\mu \in \amb_{\alpha}} \, \sum_{i=1}^{n} \mu_i \ell_{i}(\theta) \geq \E[\ell(\theta, \xi)] \right] \geq 1-\delta,
% \end{equation}
% for all $\theta \in \Theta$. We refer to this problem as the \emph{calibration problem}. It robustifies against disparities between the empirical and true distributions. 
% The parameter $\delta$ then serves as an intuitive, user-determined parameter that controls the conservativeness of the method. However, as discussed in 
% the experimental results, our method is not that sensitive to the choice of this parameter. 

It is important to note that the constraint in \cref{eq:calibration} is less stringent compared to DRO, which guarantees 
that the supremum in \cref{eq:calibration} acts as a high-confidence upper bound, uniformly over $\theta$\footnote{%
The mean bound will be uniform when 
\begin{equation*}
    \prob\left[ \sup_{\mu \in \amb} \, \sum_{i=1}^{n} \mu_i \ell_{i}(\theta) \geq \E[\ell(\theta, \xi)],\, \forall \theta \in \Theta \right] \geq 1-\delta.
\end{equation*}%
}. 
After all, we never require that the true distribution is contained within $\amb$ (as is the case in \cite{Beck2017}). 
The gap between the point-wise \cref{eq:calibration}
and the uniform equivalent is examined for $\phi$-divergences in \cite{Duchi2021b,Lam2019} in the asymptotic regime. 

We numerically approximate the calibration problem without samples from $\xi$. 
So the parameters of the set $\amb$ only need to be computed once and can be tabulated afterwards. This contrasts the complex derivations
and the resulting conservative constants associated with analytical approaches used to compute the radius of an 
ambiguity set in DRO \cite{Delage2010,Ben-Tal2013,Esfahani2018b}. 
We show experimentally how our calibration of $\amb$ according to \cref{eq:calibration} greatly improves generalization. 

