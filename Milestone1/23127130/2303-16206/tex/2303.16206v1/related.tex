\section{Related Work}
\label{sec:related}
\textbf{Steganography.}
Classic steganography methods operate directly on the spatial image domain to encode data.  
Least Significant Bit (LSB) Steganography encodes data by replacing the least significant bits of the input image pixels with bits from the secret data sequentially~\citep{chan2004hiding}. Pixel-value Differencing (PVD)~\citep{wu2003steganographic} hides data by comparing the differences between the intensity values of two successive pixels. Following this, many methods were presented to hide data while minimizing distortion to the input images and these methods differed in how the distortion was measured. 
Highly Undetectable Steganography (HUGO)~\citep{pevny2010using}  identifies pixels that can be modified without resulting in a large distortion based on handcrafted steganalytic features. 
Wavelet Obtained Weights (WOW)~\citep{holub2012designing} uses syndrome-trellis codes to minimize the expected distortion and to identify noisy or high-textured regions to modify.

With the advent of deep learning, many deep learning approaches have been proposed for steganography. 
These approaches either use neural networks in some stages of the pipeline (e.g., as a feature extractor) or learn networks end-to-end for message encoding and decoding. 
HiDDeN~\citep{zhu2018hidden} proposed an end-to-end encoder-decoder architecture to hide up to 0.4 bpp of information in images.
% TODO check why adversarial training
\citet{hayes2017generating} uses adversarial training to approximately hide 0.4 bpp in $32\times 32$ images.
SteganoGAN~\cite{zhang2019steganogan} adopts adversarial training to generate steganographic images with better quality, and can hide up to 6 bpp with error rates of about 13-33\%.
\citet{tan2021channel} improved upon SteganoGAN and introduce CHAT-GAN which uses an additional channel attention module to identify favorable channels in feature maps to hide bits of information.

HiDDeN, SteganoGAN, and CHAT-GAN hide arbitrary bit strings but other methods hide a (structured) image within an image~\citep{baluja2017hiding,dong2018invisible,yu2020attention,rahim2018end} by learning image priors and condensing information; arbitrary bit strings can not be similarly condensed.  
%Building on this line of work, to hide images in images,
Invertible Steganography Network~\citep{lu2021large} hides multiple images in a single cover image using an invertible neural network. 
Deep Multi-Image Steganography with Private Keys~\citep{shang2020enhancing} hides multiple images in a cover image while producing many secret keys, each of which is used to extract exactly one of the hidden images. 
HiNet~\citep{jing2021hinet} is an invertible network to hide information in the wavelet domain.
\citet{zhang2020udh} explore finding cover-agnostic universal perturbations that can be added to any natural image to hide a secret image. 
% These methods can condense structural information to encode images, but % that needs to be hidden, but when an arbitrary bit string needs to be hidden, condensing is not possible. 
There have also been attempts to conduct steganography with non-digital images~\citep{tancik2020stegastamp, wengrowski2019light}, but in this paper we focus on digital images. 
% , but when an arbitrary bit string needs to be hidden, condensing is not possible.

% There have also been attempts to conduct steganography with non-digital images. StegaStamp~\citep{tancik2020stegastamp} uses a deep neural network to make perturbations that are robust to distortions resulting from printing to paper. Light Field Messaging~\citep{wengrowski2019light} uses convolutional networks to transmit hidden information in a video that is displayed on a screen and is then captured by a camera. In this paper, we focus on digital images. 

\textbf{Steganalysis.}
Many applications require that steganographic images are indistinguishable from natural images.
Steganalysis systems are used to detect whether secret information is hidden in images and they can broadly be divided into two categories -- statistical and neural. 
The former makes use of statistical tests on pixels to determine whether a message is encoded in an image~\citep{dumitrescu2002detection,fridrich2001detecting,westfeld1999attacks,dumitrescu2002steganalysis}, while the latter employs neural networks to detect the existence of hidden messages. 
Classic steganography methods can be easily detected by statistical tools, but more recent methods are complex and harder to detect with statistical tools and require neural tools. 
Neural steganalysis methods have shown state-of-the-art performances for detecting steganography with high accuracy even when low payloads of information are hidden. 
GNCNN~\citep{qian2016learning} used handcrafted features and CNNs to perform steganalysis. 
Following that, many methods have used deep networks to automatically extract features and perform steganalysis~\citep{you2020siamese,qian2015deep,chen2017jpeg,wu2019novel,qian2018feature}. 
% optional
In response to the advances in steganalysis, neural steganography methods add steganalysis systems into their end-to-end pipeline in order to find robust perturbations that evade detection by steganalysis systems~\citep{shang2020enhancing,dong2018invisible}.

\textbf{Learning to Optimize.}
Recent methods have investigated incorporating optimization problems into neural network architectures~\citep{amos2017optnet,agrawal2019differentiable,pmlr-v97-wang19e}. 
These methods design custom neural network layers that mimic certain canonical optimization problems. 
As a result, parametrized optimization problems can be inserted into neural networks. Not all optimization algorithms can easily be written as a layer and another strategy is to train a network to learn iterative updates from data~\citep{adler2018learned,flynn2019deepview,gregor2010learning}. 
% LISTA~\citep{} introduces a trainable version of coordinate descent for sparse coding. 
Most similar to our approach is arguably RAFT~\citep{teed2020raft}, which poses optical flow estimation as an optimization problem and uses a recurrent neural network to find an optimal descent direction. In a similar vein, we aim to learn the steganography optimization problem with a convolutional neural network without specially designed optimization layers. 
