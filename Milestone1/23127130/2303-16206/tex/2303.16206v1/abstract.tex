%Recent research has shown that deep neural networks can be successfully trained to perform image steganography, where data is hidden in images through imperceptible changes. Existing neural approaches can hide messages at high bit rates, but they also result in high recovery error --- up to 25\% for 4 bits per pixel (bpp). A different line of work has explored using per-image optimization-based methods for image steganography. These methods have low recovery error, but they are also much slower. 
%In this paper, we use ideas from both learned methods and optimization methods to introduce a new hybrid method that has low recovery error and is fast. 
Image steganography is the process of concealing secret information in images through imperceptible changes. 
Recent work has formulated this task as a classic constrained optimization problem. In this paper, we argue that image steganography is inherently performed on the (elusive) manifold of natural images, and propose an iterative neural network trained to perform the optimization steps. 
In contrast to classical optimization methods like L-BFGS or projected gradient descent, we train the neural network to also stay close to the manifold of natural images throughout the optimization. 
We show that our learned neural optimization is faster and more reliable than classical optimization approaches. 
In comparison to previous state-of-the-art encoder-decoder based steganography methods, it reduces the recovery error rate by multiple orders of magnitude and achieves zero error up to 3 bits per pixel (bpp) without the need for error-correcting codes. 
% Our code is available at \url{https://github.com/cxy1997/LISO}.



% Recent research has shown that deep neural networks can be successfully trained to perform image steganography, where data is hidden in images through imperceptible changes. Existing neural approaches can hide messages at high bit rates, but they also result in high recovery error --- up to 25\% for 4 bits per pixel (bpp). A different line of work has explored using per-image optimization-based methods for image steganography. These methods have low recovery error, but they are also much slower. In this paper, we use ideas from both learned methods and optimization methods to introduce a new hybrid method that has low recovery error and is fast. We propose a neural iterative encoder architecture that is trained to perform an iterative gradient-based optimization on the input image. We show that our learned neural optimization far outperforms classical approaches, such as projected gradient descent, and second-order methods such as L-BFGS. This is because we obtain a better descent direction with out learned encoder when compared to performing a per-image optimization with no image prior. Our learned optimization procedure is fast, reliable and achieves new state-of-the-art results for hiding different payloads of information. Notably, we reduce the recovery error rate by multiple orders of magnitude over the previous state-of-the-art encoder-decoder based approach, and achieve zero error up to 3 bits per pixel (bpp) without having to use error correcting codes. 
