\section{Introduction}

The evolution of our universe can be uniquely determined by its initial conditions and the laws of physics. To understand this cosmic history, %\st{the evolution of universe}, 
astrophysicists use a large number of surveys \cite{Amendola_2018, survey_spergel} and simulations \cite{Bagla_2002, villaescusa}. 
%to extract meaningful information. 
These simulations %\st{try to predict the nonlinear structure} \drew{
compute the gravitational evolution of a system of N-body particles given %\st{the} \drew{
a set of nearly uniform and typically Gaussian initial conditions, representing the early universe. 
%\st{of these particles}. 
\vj{These simulations, though, come with a substantial computational cost and demand an extensive investment of both time and computational resources.}

% \albert{and can take multiple days to finish running.}\vj{any citation for time??}

In recent years, deep-learning techniques have been shown to be extremely helpful in accelerating the forward modeling process \cite{he2019, jamieson} by several orders of magnitude. These deep-learning models learn the mapping between pairs of inputs and outputs from numerical N-body simulations and act as fast and accurate approximators for these simulators. %These deep-learning surrogates speed up the forward modeling process by several orders of magnitude. %Since neural networks are theoretically proven to be universal function approximators \cite{HORNIK1989359}, the forward modeling of N-body simulations fits perfectly into the regime of neural networks.

\begin{figure*}[t!]
\begin{center}
\centerline{\includegraphics[width=0.8\textwidth]{images/N128/slices_lin.png}}
\caption{Qualitative comparison of the $x,y, \text{and } z$ displacements for a $128 \times 128$ slice of particles from a linear field sampled using the training parameters and the 
corresponding linear field predicted by our inverse model.}
\label{slices:lin}
\end{center}
\end{figure*}


The problem of inferring the initial state that generates a specific redshift $z=0$ state of the universe is an inverse problem and poses \albert{a more difficult challenge.} Inverse problems are hard as they require a search over \albert{an intractable} space of \albert{all possible} input configurations, and typically involve a one-to-many mapping if learned as a reverse mapping. Standard neural networks are one-to-one mappings and are thus not expected to work well in these problems. \albert{Sampling approaches such as Hamiltonian Monte Carlo used by Bayesian Origin Reconstruction of Galaxies (BORG) \cite{borg, borg2} are computationally prohibitive, requiring thousands of CPU hours to generate a single posterior sample. One could resort to more complex generative neural networks such as the recently proposed diffusion models \cite{legin2023posterior}. However, they are significantly more difficult and expensive to train compared to deterministic neural networks. Moreover, as we show in this paper, they are potentially an overkill to this problem as the distribution of initial conditions is typically Gaussian, where a simple deterministic neural network like ours already works surprisingly well.} 

%\drew{maybe we should be specific about what the challenges are for these alternative approaches: is it that they require more training data? more computational resources/time to train? Do they require very finely tuned hyperparameters? ``harder to train'' seems too vague}. 
%\sh{we also know that the diffusion models should work quite well... so }
%\sh{I rewrote the above sentence to make it a bit less strong}
%This is because multiple different initial states could lead to the same final state, i.e., it is a many-to-one function. Thus, the mapping from final states to the initial states is not a function, but rather a one-to-many relation. 
%\aarti{One cannot simply run the N-body simulations to go back in time to the initial states. - True, but is the reason many-to-one mapping or that the equations don't work backwards in time? If latter, maybe just say "Moreover, one cannot simply ..."} \drew{The equations are time reversible, but we cannot solve them that way on a computer. Additionally, our discretization scheme (representing chunks of the matter field by discrete particles) leads to problems of shell-crossing. The actual continuous limit of the matter field that we are modeling with point-like particles will stream through itself (multi-streaming), so that the association of a region of the matter field with one or another N-body particle becomes ambiguous, or ill-defined. Then if we run a sequence of simulations in increasing resolution, we will find that some high-resolution particles end up far away from the lower resolution particles we would naively assign them to based on starting location.} 
%Therefore, there is no direct way of determining the initial conditions, and, we must resort to progressive sampling based methods \aarti{mention some refs? BORG?} to infer the possible initial states. 

Importantly, cosmological simulations are often deterministic, and therefore they are reversible in principle. The one-to-many backward problem arises primarily due to numerical and computational errors which get exacerbated only at small scales which are dominated by nonlinear effects, \albert{causing divergent backward trajectories.} This motivates the approach we demonstrate here: training a standard deterministic neural network to learn the reverse map and output the initial states of the N-body simulations using the final states as input. 

\albert{We show that despite the one-to-many nature of the reverse mapping at small scales, a simple deterministic neural network can do a surprisingly excellent job of predicting the initial states not only at large scales but even down to relatively small scales ($k>0.1\ \mathrm{Mpc}^{-1}\,h$) where the nonlinear dynamics of gravitational clustering become important. \albert{In fact,} our model continues to have $<1-2\%$ error down to \albert{$k \simeq 0.8$ -- $0.9\ \mathrm{Mpc}^{-1}\,h$.}} Our results empirically motivate the use of neural networks as approximate inverse-mapping black boxes that could directly generate reliable initial states for a given output state, \albert{which could then be used as starting points for more fine-grained sampling-based inverse modeling methods.}
