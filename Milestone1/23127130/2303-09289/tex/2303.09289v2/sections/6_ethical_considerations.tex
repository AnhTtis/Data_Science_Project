\section{Ethical Considerations}\label{sec:ethical_considerations}
Our work demonstrates that common face recognition models leak sensitive information about individuals from the training data. The results of our research might be misused to infer sensitive information through unethical or illegal means. Since face recognition models are already widespread in real-life and privacy-critical applications, e.g., mobile devices, smart home applications, and law enforcement, our proposed Class Attribute Inference Attack (\textsc{Caia}) could be applied to infer sensitive information from such systems and, therefore, lead to a privacy breach and potential harm to individuals and service providers.

However, we believe it is critical to enhance user awareness and educate practitioners about the existence and feasibility of such attacks. Moreover, \textsc{Caia} paves the way for future research into the factors facilitating such attacks and the development of potential countermeasures. Understanding such threats enables researchers and service providers to respond early, develop potential security measures, and create more reliable models. These advantages, in our opinion, outweigh any possible concerns. With our research, we also hope to highlight the necessity for users to keep a model's potential privacy leakage in mind, even if its training data is successfully protected from unauthorized access.
