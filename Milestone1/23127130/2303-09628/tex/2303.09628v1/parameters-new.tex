\begin{table}[ht]
\small
\centering
\begin{adjustbox}{width=0.5\textwidth}
\begin{tabular}{ccc}
    \toprule
    \textbf{Parameter}  & \textbf{Value}\\ 
    \midrule
    Q-network architecture  & MLP [128, 256]\\
    Batch size       & 256\\
    Exploration technique  & $\epsilon$-greedy with exponential decay\\
    Initial $\epsilon$ & 0.5 \\
    Decay rate for $\epsilon$  & 5e-5 \\
    Discount $\gamma$  & 0.97 \\
    Optimizer & Adam ($\beta_1=0.9, \beta_2=0.999$) \cite{kingma2014}\\
    Learning rate $\eta$ & 1e-4 \\
    Episode length $T$ & 100 \\
    Experience replay size & 1e6 \\
    Initial exploration steps & 2000 \\
    Steps before training starts & 1000 \\
    Steps between parameter updates & 50 \\
    Soft target update parameter $\mu$ & 0.995 \\
    Threshold $\rho$ & 0.01 \\
   \bottomrule
\end{tabular}
\end{adjustbox}
\caption{Architecture parameters and hyperparameters used for all the baselines and \alg.}
\label{table:hyperparams-new}
\end{table}
