@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{barto2003recent,
  title={Recent advances in hierarchical reinforcement learning},
  author={Barto, Andrew G and Mahadevan, Sridhar},
  journal={Discrete event dynamic systems},
  volume={13},
  number={1},
  pages={41--77},
  year={2003},
  publisher={Springer}
}

@article{duan_one-shot_2017,
  title={One-shot imitation learning},
  author={Duan, Yan and Andrychowicz, Marcin and Stadie, Bradly and Jonathan Ho, OpenAI and Schneider, Jonas and Sutskever, Ilya and Abbeel, Pieter and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{mandlekar_learning_2021,
	title = {Learning to {Generalize} {Across} {Long}-{Horizon} {Tasks} from {Human} {Demonstrations}},
	journal = {arXiv:2003.06085 [cs]},
	author = {Mandlekar, Ajay and Xu, Danfei and Martín-Martín, Roberto and Savarese, Silvio and Fei-Fei, Li},
	year = {2021}
}

@inproceedings{bain1995framework,
  title={A Framework for Behavioural Cloning.},
  author={Bain, Michael and Sammut, Claude},
  booktitle={Machine Intelligence 15},
  pages={103--129},
  year={1995}
}

@article{singh_parrot_2020,
	title = {Parrot: {Data}-{Driven} {Behavioral} {Priors} for {Reinforcement} {Learning}},
	journal = {arXiv:2011.10024 [cs]},
	author = {Singh, Avi and Liu, Huihan and Zhou, Gaoyue and Yu, Albert and Rhinehart, Nicholas and Levine, Sergey},
	year = {2020},
}

@article{gupta_relay_2019,
  title={Relay Policy Learning: Solving Long Horizon Tasks via Imitation and Reinforcement Learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={Conference on Robot Learning (CoRL)},
  year={2019}
}

@article{lynch_learning_2019,
  title   = {Learning Latent Plans from Play},
  author  = {Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash
             and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  journal = {Conference on Robot Learning (CoRL)},
  year    = {2019},
  biburl  = {https://github.com/sermanet/sermanet.github.io/blob/master/assets/bib/Lynch2019Play.bib},
}

@inproceedings{
li_sub-policy_2020,
title={Sub-policy Adaptation for Hierarchical Reinforcement Learning},
author={Alexander Li and Carlos Florensa and Ignasi Clavera and Pieter Abbeel},
booktitle={International Conference on Learning Representations},
year={2020}
}

@article{zhang_hierarchical_2021,
	title = {Hierarchical {Reinforcement} {Learning} {By} {Discovering} {Intrinsic} {Options}},
	journal = {arXiv:2101.06521 [cs]},
	author = {Zhang, Jesse and Yu, Haonan and Xu, Wei},
	year = {2021}
}

@article{chane-sane_goal-conditioned_2021,
	title = {Goal-{Conditioned} {Reinforcement} {Learning} with {Imagined} {Subgoals}},
	journal = {arXiv:2107.00541 [cs]},
	author = {Chane-Sane, Elliot and Schmid, Cordelia and Laptev, Ivan},
	year = {2021},
}

@INPROCEEDINGS{Kaelbling93learningto,
    author = {Leslie Pack Kaelbling},
    title = {Learning to Achieve Goals},
    booktitle = {IN PROC. OF IJCAI-93},
    year = {1993},
    pages = {1094--1098}
}

@inproceedings{
hafner_dream_2020,
title={Dream to Control: Learning Behaviors by Latent Imagination},
author={Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
booktitle={International Conference on Learning Representations},
year={2020}
}

@book{sutton_reinforcement_2018,
	edition = {Second edition},
	series = {Adaptive computation and machine learning series},
	title = {Reinforcement learning: an introduction},
	shorttitle = {Reinforcement learning},
	publisher = {The MIT Press},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	year = {2018}
}

@inproceedings{pastor_learning_2009,
	address = {Kobe},
	title = {Learning and generalization of motor skills by learning from demonstration},
	booktitle = {2009 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Pastor, Peter and Hoffmann, Heiko and Asfour, Tamim and Schaal, Stefan},
	year = {2009},
	pages = {763--768},
}

@article{florence_implicit_2021,
	title = {Implicit {Behavioral} {Cloning}},
	journal = {arXiv:2109.00137 [cs]},
	author = {Florence, Pete and Lynch, Corey and Zeng, Andy and Ramirez, Oscar and Wahid, Ayzaan and Downs, Laura and Wong, Adrian and Lee, Johnny and Mordatch, Igor and Tompson, Jonathan},
	year = {2021},
}

@article{peng_deepmimic_2018,
	title = {{DeepMimic}: example-guided deep reinforcement learning of physics-based character skills},
	volume = {37},
	shorttitle = {{DeepMimic}},
	journal = {ACM Transactions on Graphics},
	author = {Peng, Xue Bin and Abbeel, Pieter and Levine, Sergey and van de Panne, Michiel},
	month = aug,
	year = {2018},
	pages = {1--14},
}

@article{mandlekar_what_2021,
  title={What matters in learning from offline human demonstrations for robot manipulation},
  author={Mandlekar, Ajay and Xu, Danfei and Wong, Josiah and Nasiriany, Soroush and Wang, Chen and Kulkarni, Rohun and Fei-Fei, Li and Savarese, Silvio and Zhu, Yuke and Mart{\'\i}n-Mart{\'\i}n, Roberto},
  journal={arXiv preprint arXiv:2108.03298},
  year={2021}
}

@article{mandlekar_what_2021-1,
  title={What matters in learning from offline human demonstrations for robot manipulation},
  author={Mandlekar, Ajay and Xu, Danfei and Wong, Josiah and Nasiriany, Soroush and Wang, Chen and Kulkarni, Rohun and Fei-Fei, Li and Savarese, Silvio and Zhu, Yuke and Mart{\'\i}n-Mart{\'\i}n, Roberto},
  journal={arXiv preprint arXiv:2108.03298},
  year={2021}
}

@article{mcgovern1998macro,
  title={Macro-actions in reinforcement learning: An empirical analysis},
  author={McGovern, Amy and Sutton, Richard S},
  journal={Computer Science Department Faculty Publication Series},
  pages={15},
  year={1998}
}
@inproceedings{schmidhuber1991learning,
  title={Learning to generate sub-goals for action sequences},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Artificial neural networks},
  pages={967--972},
  year={1991}
}
@inproceedings{hovland1996skill,
  title={Skill acquisition from human demonstration using a hidden markov model},
  author={Hovland, Geir E and Sikka, Pavan and McCarragher, Brenan J},
  booktitle={Proceedings of IEEE international conference on robotics and automation},
  volume={3},
  pages={2706--2711},
  year={1996}
}

@inproceedings{bagaria2019option,
  title={Option discovery using deep skill chaining},
  author={Bagaria, Akhil and Konidaris, George},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{nasiriany2022augmenting,
  title={Augmenting reinforcement learning with behavior primitives for diverse manipulation tasks},
  author={Nasiriany, Soroush and Liu, Huihan and Zhu, Yuke},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)},
  pages={7477--7484},
  year={2022},
  organization={IEEE}
}

@inproceedings{bacon2017option,
  title={The option-critic architecture},
  author={Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={31},
  number={1},
  year={2017}
}

@article{zhu2022bottom,
  title={Bottom-Up Skill Discovery from Unsegmented Demonstrations for Long-Horizon Robot Manipulation},
  author={Zhu, Yifeng and Stone, Peter and Zhu, Yuke},
  journal={IEEE Robotics and Automation Letters},
  year={2022}
}

@article{konidaris2009skill,
  title={Skill discovery in continuous reinforcement learning domains using skill chaining},
  author={Konidaris, George and Barto, Andrew},
  journal={Advances in neural information processing systems},
  volume={22},
  year={2009}
}

@article{konidaris2010constructing,
  title={Constructing skill trees for reinforcement learning agents from demonstration trajectories},
  author={Konidaris, George and Kuindersma, Scott and Grupen, Roderic and Barto, Andrew},
  journal={Advances in neural information processing systems},
  volume={23},
  year={2010}
}

@inproceedings{niekum2015online,
  title={Online bayesian changepoint detection for articulated motion models},
  author={Niekum, Scott and Osentoski, Sarah and Atkeson, Christopher G and Barto, Andrew G},
  booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1468--1475},
  year={2015}
}

@book{lavalle2006planning,
  title={Planning algorithms},
  author={LaValle, Steven M},
  year={2006},
  publisher={Cambridge university press}
}
@article{kavraki1996probabilistic,
  title={Probabilistic roadmaps for path planning in high-dimensional configuration spaces},
  author={Kavraki, Lydia E and Svestka, Petr and Latombe, J-C and Overmars, Mark H},
  journal={IEEE transactions on Robotics and Automation},
  volume={12},
  number={4},
  pages={566--580},
  year={1996}
}

@article{lavalle2001randomized,
  title={Randomized kinodynamic planning},
  author={LaValle, Steven M and Kuffner Jr, James J},
  journal={The international journal of robotics research},
  volume={20},
  number={5},
  pages={378--400},
  year={2001}
}

@article{karaman2011sampling,
  title={Sampling-based algorithms for optimal motion planning},
  author={Karaman, Sertac and Frazzoli, Emilio},
  journal={The international journal of robotics research},
  volume={30},
  number={7},
  pages={846--894},
  year={2011}
}

@inproceedings{mainprice2020interior,
  title={An interior point method solving motion planning problems with narrow passages},
  author={Mainprice, Jim and Ratliff, Nathan and Toussaint, Marc and Schaal, Stefan},
  booktitle={2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
  pages={547--552},
  year={2020}
}

@article{bellicoso2018,
author = {Bellicoso, Dario and Bjelonic, Marko and Wellhausen, Lorenz and Holtmann, Kai and Günther, Fabian and Tranzatto, Marco and Fankhauser, Péter and Hutter, Marco},
year = {2018},
month = {10},
title = {Advances in Real-World Applications for Legged Robots},
journal = {Journal of Field Robotics}
}

@inproceedings{ratliff2009chomp,
  title={CHOMP: Gradient optimization techniques for efficient motion planning},
  author={Ratliff, Nathan and Zucker, Matt and Bagnell, J Andrew and Srinivasa, Siddhartha},
  booktitle={2009 IEEE International Conference on Robotics and Automation},
  pages={489--494},
  year={2009}
}
@article{schulman2014motion,
  title={Motion planning with sequential convex optimization and convex collision checking},
  author={Schulman, John and Duan, Yan and Ho, Jonathan and Lee, Alex and Awwal, Ibrahim and Bradlow, Henry and Pan, Jia and Patil, Sachin and Goldberg, Ken and Abbeel, Pieter},
  journal={The International Journal of Robotics Research},
  volume={33},
  number={9},
  pages={1251--1270},
  year={2014}
}

@inproceedings{dai2014whole,
  title={Whole-body motion planning with centroidal dynamics and full kinematics},
  author={Dai, Hongkai and Valenzuela, Andr{\'e}s and Tedrake, Russ},
  booktitle={2014 IEEE-RAS International Conference on Humanoid Robots},
  pages={295--302},
  year={2014}
}

@phdthesis{winkler2018optimization,
  title={Optimization-based motion planning for legged robots},
  author={Winkler, Alexander W},
  year={2018},
  school={ETH Zurich}
}

@article{winkler2018gait,
  title={Gait and trajectory optimization for legged systems through phase-based end-effector parameterization},
  author={Winkler, Alexander W and Bellicoso, C Dario and Hutter, Marco and Buchli, Jonas},
  journal={IEEE Robotics and Automation Letters},
  volume={3},
  number={3},
  pages={1560--1567},
  year={2018}
}
@article{bjelonic2022offline,
  title={Offline motion libraries and online MPC for advanced mobility skills},
  author={Bjelonic, Marko and Grandia, Ruben and Geilinger, Moritz and Harley, Oliver and Medeiros, Vivian S and Pajovic, Vuk and Jelavic, Edo and Coros, Stelian and Hutter, Marco},
  journal={The International Journal of Robotics Research},
  year={2022}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={30},
  year={2016}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015}
}

@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International conference on machine learning},
  pages={1587--1596},
  year={2018}
}
@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={279--292},
  year={1992}
}
%invalid action masking
@article{vinyals2017new,
  title={A new challenge for reinforcement learning},
  author={Vinyals, O and Ewalds, T and Bartunov, S and Georgiev, P and Vezhnevets, AS and Yeo, M and Makhzani, A and K{\"u}ttler, H and Agapiou, J and Schrittwieser, J and others},
  journal={arXiv preprint ArXiv:1708.04782},
  volume={5},
  year={2017}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@inproceedings{ye2020mastering,
  title={Mastering complex control in moba games with deep reinforcement learning},
  author={Ye, Deheng and Liu, Zhao and Sun, Mingfei and Shi, Bei and Zhao, Peilin and Wu, Hao and Yu, Hongsheng and Yang, Shaojie and Wu, Xipeng and Guo, Qingwei and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={6672--6679},
  year={2020}
}
@article{huang2020closer,
  title={A closer look at invalid action masking in policy gradient algorithms},
  author={Huang, Shengyi and Onta{\~n}{\'o}n, Santiago},
  journal={arXiv preprint arXiv:2006.14171},
  year={2020}
}

% rl for complex manip behaviors
@article{kalashnikov2018qt,
  title={Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation (2018)},
  author={Kalashnikov, D and Irpan, A and Pastor, P and Ibarz, J and Herzog, A and Jang, E and Quillen, D and Holly, E and Kalakrishnan, M and Vanhoucke, V and others},
  journal={arXiv preprint arXiv:1806.10293},
  year={2018}
}
@article{kalashnikov2021mt,
    title={MT-OPT:
    Continuous Multi-Task Robotic Reinforcement Learning at Scale},
    author={Dmitry Kalashnkov and Jake Varley and 
            Yevgen Chebotar and Ben Swanson and 
            Rico Jonschkowski and Chelsea Finn and 
            Sergey Levine and Karol Hausman},
  journal={arXiv preprint arXiv:2104.08212},
    year={2021}
}

@article{akkaya2019solving,
  title={Solving rubik's cube with a robot hand},
  author={Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
  journal={arXiv preprint arXiv:1910.07113},
  year={2019}
}

@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={3--20},
  year={2020}
}
% curse of dimensionality
@inproceedings{bertsekas1995neuro,
  title={Neuro-dynamic programming: an overview},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  booktitle={Proceedings of 1995 34th IEEE conference on decision and control},
  volume={1},
  pages={560--564},
  year={1995}
}

@article{dayan1992feudal,
  title={Feudal reinforcement learning},
  author={Dayan, Peter and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={5},
  year={1992}
}
@article{wiering1997hq,
  title={HQ-learning},
  author={Wiering, Marco and Schmidhuber, J{\"u}rgen},
  journal={Adaptive Behavior},
  volume={6},
  number={2},
  pages={219--246},
  year={1997}
}
@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999}
}
@article{dietterich2000hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={Journal of artificial intelligence research},
  volume={13},
  pages={227--303},
  year={2000}
}

@MISC{coumans2021,
author =   {Erwin Coumans and Yunfei Bai},
title =    {PyBullet, a Python module for physics simulation for games, robotics and machine learning},
howpublished = {\url{http://pybullet.org}},
year = {2016--2021}
}

@book{lin1992reinforcement,
  title={Reinforcement learning for robots using neural networks},
  author={Lin, Long-Ji},
  year={1992},
  publisher={Carnegie Mellon University}
}

@article{garrett2020integrated,
  title={Integrated task and motion planning},
  author={Garrett, Caelan Reed and Chitnis, Rohan and Holladay, Rachel and Kim, Beomjoon and Silver, Tom and Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  journal={Annual review of control, robotics, and autonomous systems},
  volume={4},
  pages={265--293},
  year={2021},
  publisher={Annual Reviews}
}
@inproceedings{toussaint2015logic,
  title={Logic-geometric programming: An optimization-based approach to combined task and motion planning},
  author={Toussaint, Marc},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}
@inproceedings{toussaint2017multi,
  title={Multi-bound tree search for logic-geometric programming in cooperative manipulation domains},
  author={Toussaint, Marc and Lopes, Manuel},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4044--4051},
  year={2017}
}
@inproceedings{braun2021rhh,
  title={RHH-LGP: Receding Horizon And Heuristics-Based Logic-Geometric Programming For Task And Motion Planning},
  author={Braun, Cornelius V and Ortiz-Haro, Joaquim and Toussaint, Marc and Oguz, Ozgur S},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={13761--13768},
  year={2022},
  organization={IEEE}
}


@article{kaelbling2013integrated,
  title={Integrated task and motion planning in belief space},
  author={Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={9-10},
  pages={1194--1227},
  year={2013}
}
% unstabililites hrl
@article{nachum2018data,
  title={Data-efficient hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang Shane and Lee, Honglak and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{eysenbach2019search,
  title={Search on the replay buffer: Bridging planning and reinforcement learning},
  author={Eysenbach, Ben and Salakhutdinov, Russ R and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{zahavy2018learn,
  title={Learn what not to learn: Action elimination with deep reinforcement learning},
  author={Zahavy, Tom and Haroush, Matan and Merlis, Nadav and Mankowitz, Daniel J and Mannor, Shie},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{dulac2015deep,
  title={Deep reinforcement learning in large discrete action spaces},
  author={Dulac-Arnold, Gabriel and Evans, Richard and van Hasselt, Hado and Sunehag, Peter and Lillicrap, Timothy and Hunt, Jonathan and Mann, Timothy and Weber, Theophane and Degris, Thomas and Coppin, Ben},
  journal={arXiv preprint arXiv:1512.07679},
  year={2015}
}
@inproceedings{van2009using,
  title={Using continuous action spaces to solve discrete problems},
  author={Van Hasselt, Hado and Wiering, Marco A},
  booktitle={2009 International Joint Conference on Neural Networks},
  pages={1149--1156},
  year={2009}
}
@inproceedings{even2003action,
  title={Action elimination and stopping conditions for reinforcement learning},
  author={Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay},
  booktitle={Proceedings of the 20th International Conference on Machine Learning (ICML-03)},
  pages={162--169},
  year={2003}
}
@article{levy2018hierarchical,
  title={Hierarchical reinforcement learning with hindsight},
  author={Levy, Andrew and Platt, Robert and Saenko, Kate},
  journal={arXiv preprint arXiv:1805.08180},
  year={2018}
}

@misc{spot-sdk,
  title = {boston-dynamics/spot-sdk},
  author = {.},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/boston-dynamics/spot-sdk}},
}
@misc{pybind11,
  title = {pybind/pybind11},
  author = {.},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/pybind/pybind11.git}},
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}

@inproceedings{pertsch2020spirl,
  title={Accelerating Reinforcement Learning with Learned Skill Priors},
  author={Karl Pertsch and Youngwoon Lee and Joseph J. Lim},
  booktitle={Conference on Robot Learning (CoRL)},
  year={2020},
}

@article{pertsch2021skild,
  title={Demonstration-Guided Reinforcement Learning with Learned Skills},
  author={Karl Pertsch and Youngwoon Lee and Yue Wu and Joseph J. Lim},
  journal={5th Conference on Robot Learning},
  year={2021},
}

@inproceedings{
  singh2021parrot,
  title={Parrot: Data-Driven Behavioral Priors for Reinforcement Learning},
  author={Avi Singh and Huihan Liu and Gaoyue Zhou and Albert Yu and Nicholas Rhinehart and Sergey Levine},
  booktitle={International Conference on Learning Representations},
  year={2021},
}


@article{tirumala2022behavior,
  title={Behavior Priors for Efficient Reinforcement Learning},
  author={Tirumala, Dhruva and Galashov, Alexandre and Noh, Hyeonwoo and Hasenclever, Leonard and Pascanu, Razvan and Schwarz, Jonathan and Desjardins, Guillaume and Czarnecki, Wojciech Marian and Ahuja, Arun and Teh, Yee Whye and others},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={221},
  pages={1--68},
  year={2022}
}


@article{gibson1977theory,
  title={The theory of affordances},
  author={Gibson, James J},
  journal={Hilldale, USA},
  volume={1},
  number={2},
  pages={67--82},
  year={1977}
}

@inproceedings{khetarpal2020what,
  author={Khimya Khetarpal and Zafarali Ahmed and Gheorghe Comanici and David Abel and Doina Precup},
  title={What can I do here? A Theory of Affordances in Reinforcement Learning},
  year={2020},
  booktitle={ICML}
}

@inproceedings{costales2022possibility,
title={Possibility Before Utility: Learning And Using Hierarchical Affordances},
author={Robby Costales and Shariq Iqbal and Fei Sha},
booktitle={International Conference on Learning Representations},
year={2022}
}

@Book{puterman1994,
  author =       "Puterman, Martin L.",
  title =        "Markov Decision Processes",
  publisher =    "Wiley",
  year =         "1994"
}

@inproceedings{lattimore2012pac,
  title={PAC bounds for discounted MDPs},
  author={Lattimore, Tor and Hutter, Marcus},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={320--334},
  year={2012}
}

@book{kakade2003sample,
  title={On the sample complexity of reinforcement learning},
  author={Kakade, Sham Machandranath},
  year={2003},
  publisher={University of London, University College London (United Kingdom)}
}

@inproceedings{strehl2006pac,
  title={PAC model-free reinforcement learning},
  author={Strehl, Alexander L and Li, Lihong and Wiewiora, Eric and Langford, John and Littman, Michael L},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={881--888},
  year={2006}
}

@inproceedings{sermanet2021broadly,
  title={Broadly-Exploring, Local-Policy Trees for Long-Horizon Task Planning},
  author={Sermanet, Pierre and Lynch, Corey and others},
  booktitle={5th Annual Conference on Robot Learning},
  year={2021}
}

@inproceedings{zimmermann2022dca,
  title={Differentiable collision avoidance using collision primitives},
  author={Zimmermann, Simon and Busenhart, Matthias and Huber, Simon and Poranne, Roi and Coros, Stelian},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={8086--8093},
  year={2022},
  organization={IEEE}
}


@inproceedings{zimmermann2021go,
  title={Go Fetch!-Dynamic grasps using Boston Dynamics Spot with external robotic arm},
  author={Zimmermann, Simon and Poranne, Roi and Coros, Stelian},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4488--4494},
  year={2021}
}

@misc{noauthor_spot_nodate,
	title = {Spot® {\textbar} {Boston} {Dynamics}},
	year = 2022,
    howpublished = {\url{https://www.bostondynamics.com/products/spot}}
}
}

@inproceedings{boutilier2018planning,
  title     = {Planning and Learning with Stochastic Action Sets},
  author    = {Craig Boutilier and Alon Cohen and Avinatan Hassidim and Yishay Mansour and Ofer Meshi and Martin Mladenov and Dale Schuurmans},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence, {IJCAI-18}},
pages     = {4674--4682},
  year      = {2018}
}

@book{bertsekas1996neuro,
  author    = {Dimitri P. Bertsekas and
               John N. Tsitsiklis},
  title     = {Neuro-dynamic programming},
  series    = {Optimization and neural computation series},
  volume    = {3},
  publisher = {Athena Scientific},
  year      = {1996}
}

@article{fulda2017can,
  title={What can you do with a rock? affordance extraction via word embeddings},
  author={Fulda, Nancy and Ricks, Daniel and Murdoch, Ben and Wingate, David},
  journal={arXiv preprint arXiv:1703.03429},
  year={2017}
}

@article{kingma2014,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{masson2016reinforcement,
  title={Reinforcement learning with parameterized actions},
  author={Masson, Warwick and Ranchod, Pravesh and Konidaris, George},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{ICLR16-hausknecht,
title={Deep Reinforcement Learning in Parameterized Action Space},
author={Matthew Hausknecht and Peter Stone},
booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
month={May},
address={San Juan, Puerto Rico},
url="http://www.cs.utexas.edu/users/ai-lab?hausknecht:iclr16",
year={2016}
}

@article{dalal2021accelerating,
  title={Accelerating robotic reinforcement learning via parameterized action primitives},
  author={Dalal, Murtaza and Pathak, Deepak and Salakhutdinov, Russ R},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={21847--21859},
  year={2021}
}

@INPROCEEDINGS{relmogen2021,
  author={Xia, Fei and Li, Chengshu and Martín-Martín, Roberto and Litany, Or and Toshev, Alexander and Savarese, Silvio},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={ReLMoGen: Integrating Motion Generation in Reinforcement Learning for Mobile Manipulation}, 
  year={2021},
  volume={},
  number={},
  pages={4583-4590},
  doi={10.1109/ICRA48506.2021.9561315}}


@InProceedings{yamada21a,
  title = 	 {Motion Planner Augmented Reinforcement Learning for Robot Manipulation in Obstructed Environments},
  author =       {Yamada, Jun and Lee, Youngwoon and Salhotra, Gautam and Pertsch, Karl and Pflueger, Max and Sukhatme, Gaurav and Lim, Joseph and Englert, Peter},
  booktitle = 	 {Proceedings of the 2020 Conference on Robot Learning},
  pages = 	 {589--603},
  year = 	 {2021},
  editor = 	 {Kober, Jens and Ramos, Fabio and Tomlin, Claire},
  volume = 	 {155},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {16--18 Nov},
  publisher =    {PMLR},
  }

@ARTICLE{angelov2020,  author={Angelov, Daniel and Hristov, Yordan and Burke, Michael and Ramamoorthy, Subramanian},  journal={IEEE Robotics and Automation Letters},   title={Composing Diverse Policies for Temporally Extended Tasks},   year={2020},  volume={5},  number={2},  pages={2658-2665},  doi={10.1109/LRA.2020.2972794}}

@inproceedings{saycan2022arxiv,
    title={Do As I Can and Not As I Say: Grounding Language in Robotic Affordances},
    author={Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng},
    booktitle={arXiv preprint arXiv:2204.01691},
    year={2022}
}

@ARTICLE{christen2020hide,
  author={{Christen}, Sammy and {Jendele}, Lukas and {Aksan}, Emre and {Hilliges}, Otmar},
  journal={IEEE Robotics and Automation Letters},
  title={Learning Functionally Decomposed Hierarchies for Continuous Control Tasks With Path Planning},
  year={2021},
  volume={6},
  number={2},
  pages={3623-3630},
  doi={10.1109/LRA.2021.3060403}}
