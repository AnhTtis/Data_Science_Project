%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% % The following packages can be found on http:\\www.ctan.org
% \usepackage{graphics} % for pdf, bitmapped graphics files
% \usepackage{epsfig} % for postscript graphics files
% \usepackage{mathptmx} % assumes new font selection scheme installed
% \usepackage{times} % assumes new font selection scheme installed
% \usepackage{amsmath} % assumes amsmath package installed
% \usepackage{amssymb}  % assumes amsmath package installed


\usepackage{cite}
\usepackage{dsfont}
\usepackage{xspace}
% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}
\usepackage{color}
\usepackage{comment}
\usepackage{ulem}
\usepackage{algorithmic}
\usepackage[ruled,vlined]{algorithm2e}       % algorithm
\usepackage{graphicx}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{bbm}
\usepackage{wrapfig}
\usepackage{adjustbox}
\usepackage{multicol}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newcommand{\alg}{ELF-P\xspace}
\newcommand{\env}{\textit{Spot-Desk}\xspace}
\newcommand{\suppl}{Appendix\xspace} %Cref{appendix:experiments}

\newcommand{\todo}[1]{\textcolor{blue}{\textbf{TODO: }#1}}
\newcommand{\geo}[1]{\textcolor{red}{\textbf{Geo: }#1}}
\newcommand{\code}[1]{\texttt{#1}}
\usepackage{booktabs}       % professional-quality tables
\usepackage{multirow}
\newcommand{\STAB}[1]{\begin{tabular}{@{}c@{}}#1\end{tabular}}
\newcommand{\OurAppendix}{\href{https://nuria95.github.io/elf-p/}{Appendix} }

% Flags and options
\graphicspath{{figures/}}

\usepackage{hyperref}
\usepackage{cleveref}

\input{00commands.tex}

\title{\LARGE \bf
Efficient Learning of High Level Plans from Play
}


\author{Núria Armengol Urpí$^{1}$, Marco Bagatella$^{1}$, Otmar Hilliges$^{1}$, Georg Martius$^{2}$ and Stelian Coros$^{1}$
\thanks{$^{1}$Department of Computer Science, ETH Zurich, Switzerland {\tt\small \{nuria.armengolurpi,  mbagatella, scoros, otmar.hilliges\}@inf.ethz.ch}}%
\thanks{$^{2}$Max Planck Institute for Intelligent Systems, Tübingen, Germany\newline {\tt\small georg.martius@tuebingen.mpg.de}}
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Real-world robotic manipulation tasks remain an elusive challenge, since they involve both fine-grained environment interaction, as well as the ability to plan for long-horizon goals. Although deep reinforcement learning (RL) methods have shown encouraging results when planning end-to-end in high-dimensional environments, they remain fundamentally limited by poor sample efficiency due to inefficient exploration, and by the complexity of credit assignment over long horizons.
In this work, we present Efficient Learning of High-Level Plans from Play (\alg), a framework for robotic learning that bridges motion planning and deep RL to achieve long-horizon complex manipulation tasks.
We leverage task-agnostic \textit{play} data to learn a discrete behavioral prior over object-centric primitives, modeling their feasibility given the current context.
We then design a high-level goal-conditioned policy which (1) uses primitives as building blocks to scaffold complex long-horizon tasks and (2) leverages the behavioral prior to accelerate learning.
We demonstrate that \alg has significantly better sample efficiency than relevant baselines over multiple realistic manipulation tasks and learns policies that can be easily transferred to physical hardware.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{01introduction.tex}
\input{02previous.tex}
\input{03problem_statement}
\input{03method.tex}
\input{04results.tex}
\input{05discussion.tex}
\input{06acknowledgments.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newpage
\bibliographystyle{IEEEtran}
\bibliography{references}
\newpage
\input{appendix-experiments}

\end{document}