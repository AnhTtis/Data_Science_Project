% !TEX root = main.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                           		Experiment                         		 %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Experiment Results}
\label{sec:experiment}

\subsection{Experiment data set}
% hardware 
In March 2021, we have conducted an under-ice experiment under the frozen Keweenaw Waterway, Michigan using a modified BlueROV2~\cite{UnderIce-ROV_Zhao_2021} with a suite of sensors shown in Fig.~\ref{fig:rov}. 
The ice thickness is about 30 cm.
A big ice hole was cut for deploying the ROV while several small ice holes (shown in Fig. \ref{fig:metashape}) were also drilled along the transect.
During the experiment, the ROV is remotely controlled by the pilot to drive along a straight line multiple times (roughly 40 meters each), resulting in a total traveling distance of about 200 m and a total duration of about 20 minutes.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.35]{images/rov}
    \caption{The modified BlueROV-2 used in the  experiment.}
    \label{fig:rov}
\end{figure}
\vspace{-2ex}

\begin{figure*}[t] \centering
 \includegraphics[width=0.99\textwidth,height=0.2\textwidth]{images/metashape.png}
    \vspace{-6ex}
    \caption{The Metashape reconstructed result. The largest ice-hole on the left side is the starting point for the vehicle, the total length of this reconstructed result is roughly 40 meters} \label{fig:metashape}
\end{figure*}

We used the experiment data set to validate our proposed sensor fusion framework.
In the data set, the camera (FLIR BFS-U3-19S4C-C) is running at 15 Hz with a raw image size of 1616 by 1240 pixels, the upward-looking DVL (Nortek DVL1000) is pinging at 4Hz, the IMU (MicroStrain 3DM-GX5-25 AHRS) is running at 100 Hz, and the pressure sensor on the DVL is sampling at 2Hz.
The original result shown in \cite{UnderIce-ROV_Zhao_2021} used the robot localization without correcting the time delays (about 10 seconds) between the IMU and DVL due to the DVL driver issue.
Even though the localization in \cite{UnderIce-ROV_Zhao_2021} shows a low drift, it may be a coincidence.
In this data set, we have corrected the delays during the validation process.
One unique feature in this data set is that, occasionally, the ROV is controlled to hover in place.
Such maneuvers will challenge the visual SLAM performance since during the hovering no significant translation is available for feature triangulation. 
In application, hovering may be needed in several key locations during an under-ice exploration to collect more measurements on abnormal biogeochemical processes, e.g., a salt brine injection and algae bloom.
The ground truth vehicle path is generated using Agisoft Metashape based on Structure-from-motion technique, a rendering of the ice surface is shown in Fig.~\ref{fig:metashape}.

\subsection{Results}
For comparison, we use the evo~\cite{evo_Grupp_2017} toolbox to align (recovery rotation and scale) ground truth path and estimated odometry created from different sensor fusion methods.
We only selected a short amount of time (90 seconds about 10 meters) at the beginning for alignment.
Herein, we compare the localization results from 7 settings, as shown in Table~\ref{tab:odom_setting} against the ground truth path.
\begin{table}[h]
    \caption{Setup with different sensor suites and features. "Y" means used and "N" means not used.}
    \label{tab:odom_setting}
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|c}
    \hline
    \textbf{Case \#} &\textbf{1} &\textbf{2} &\textbf{3} &\textbf{4} &\textbf{5} &\textbf{6} &\textbf{7}\\
    \hline
    Visual  &N &Y &Y &Y &Y &Y &Y\\    
    \hline
    DVL  &Y &Y &Y &Y &Y &N &N\\
    \hline
    IMU  &Y &Y &Y & Y &Y & Y &Y\\
    \hline
    Pressure  &Y &Y &Y &Y &Y &N &N\\
    \hline
    Feature enhancement &N &Y &N &N &Y &N &N\\
    \hline
    Keyframe selection &N &Y &Y &N &N &N &Y\\
    \hline
    \end{tabular}
\end{table} 
\vspace{-2ex}

For all tracks, we used identical parameters in the MSCKF besides the enhancement and keyframe options and system initialization is conducted using the method from~\cite{INS-DVL-Pressure_Zhao_2022}. 
We currently used CLAHE~\cite{CLAHE_Pizer_1987} with KLT~\cite{KLT_Lucas_1981} method for the front-end feature tracking because the descriptor based methods, such as the ORB and KAZE, didn't provide us with a consistent tracking result. 
Instead, the descriptor-based method will be confused by the air bubbles in the ice which appear in similar shapes, sizes and colors.
We present all the resulting vehicle paths estimated from case $1\thicksim5$ in Fig.~\ref{fig:aligned_traj} with different colors. Noted that VIO options (case $6\thicksim7$) are not visualized since those runs failed quickly at the beginning because of the hovering maneuvers.  
From Fig.~\ref{fig:aligned_traj}, we can easily observe that the odometry generated without the visual assist is drifting away from the ground truth. 
In contrast, the paths generated with visual assistant stay closer to the ground truth path, especially, during the first and the second transects.
We believe that the angle offset between in tracks and the ground truth during the third and fourth segments may due to the hovering maneuverings (2-3 minutes) near the ROV deployment hole at the end of the second segment. 

\vspace{-2ex}
\textbf{\begin{figure}[h] \centering
\includegraphics[width=0.5\textwidth,height=0.3\textwidth]{images/aligned_traj.png}
    \caption{The resulting trajectories for all the cases.} \label{fig:aligned_traj}
\end{figure}}
\vspace{-2ex}

To further compare the performance in the different cases, we computed the error in x and y and the x-y plane euclidean distance between the ground truth path and each odometry.  
The errors are presented in Fig. ~\ref{fig:errors} and the statistical values are listed in Table~\ref{tab:rmse}.
In Fig. \ref{fig:errors}, we could see that the integration of visual measurement into the MSCKF will help with reducing the errors. 
Overall, the drift in the Y direction (transversal to the vehicle transects) is higher than in the x direction. 
This may because of the fact that the vehicle's sway velocity is slightly small than its surge speed.
Therefore, a higher noise-to-signal ratio may be expected in the transversal direction, causing the increased drift.

\begin{table}[h!]
  \begin{center}
    \caption{RMSE for Different Case Studies.}
    \label{tab:rmse}
    \begin{tabular}{c|c|c|c|c|c} 
      \hline
      \textbf{Case \#} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5}\\
      \hline
      RMSE(X)   & 3.54 & \textbf{0.39} & 0.42 & 1.23 & 1.34 \\
      RMSE(Y)   & 2.87 & \textbf{1.82} & 1.86 & 2.29 & 2.09 \\
      RMSE(X-Y) & 3.21 & \textbf{1.11} & 1.14 & 1.76 & 1.71 \\
      \hline
    \end{tabular}
  \end{center}
\end{table}
\vspace{-2ex}

When comparing the statistical values in Table~\ref{tab:rmse}, we have several findings.
First, visual-fused solutions are better than case 1 which only used the DVL velocity measurements, IMU acceleration and angular velocity measurements, and the pressure sensor depth measurement.
Second, case 2 and 3 are better than case 4 and 5. 
This comparison allows us to highlight the benefit of having keyframe selection mechanism which allows a longer translation for a better result in feature triangulation, ultimately affecting the localization.
Third, our method (case 2 with DVL-aided feature enhancement and keyframe selection enabled) produced the lowest RMSE. 
However, case 3 (with DVL-aided feature enhancement disabled but keyframe selection enabled) is only slightly worse than case 2.
This small improvement may be mainly caused by two following reasons.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.35]{images/error.png}
    \caption{The errors in X-axis, Y-axis and X-Y plane.}
    \label{fig:errors}
\end{figure}
\vspace{-2ex}

First, the detected visual features are too close to the vehicle (roughly between 1-2 meters). 
Therefore, the feature's position in z corrected by the DVL measurements is relatively small (even though the improvement is visible in Fig.~\ref{fig:depth_enhance}), resulting in a small impact on the state estimation.
Second, the feature measurements noise is set to 0.09 pixel which is relatively high compared to 0.0035 we set when testing the VIO on simulated data from OpenVINs.
We also tried 0.01 for our field data set, the localization error was larger than the result shown in here.
Therefore, we think there is still room for improvement, especially, in the front-end feature tracking.


% init alignment RMSE:
%   - DIPO:  0.04372366500998966
%   - VDIPO: 0.042506709947047125
%   - VDIPO-wo-enhance: 0.041838946871800786
%   - VDIPO-wo-enhance-keyframe: 0.04293661481755104
%   - VDIPO-wo-keyframe: 0.04353596573555296 
