% !TEX root = main.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                              Related Work                            %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}
\label{sec:related_work}
% Underwater localization strategies can be generally divided into two types: external-aided approaches and self-contained methods.
% External-aided approaches normally use distributed acoustic arrays to locate a underwater vehicle based on the time-of-flight of acoustic signals transmitted between the vehicle and the acoustic array. 
% xxx give several examples.
% Then, go to the DVL-fused methods, then SLAM (terrain-aided navigation), and visual-aided approaches.
% (In each types, you have to have a sentence to mention the limitation in ice-water boundary environment, this section is more of a detailed discussion of the related work to support your goals and application discussed in Section I).

%%% related 1: DVL-fused(velocity, pointcloud) 
When an underwater vehicle is operated close to a target (e.g., seafloor or sea-ice), the measurements from DVL and INS are commonly fused for dead-reckoning (DR).
To increase localization accuracy, DR integrated with a pressure sensor in a tightly-coupled EKF for under-ice navigation was presented in ~\cite{INS-DVL-Pressure_Zhao_2022}. 
In addition, acoustic beacon aided DR solutions using LBL~\cite{INS-DVL-LBL_Miller_2010} or USBL~\cite{INS-DVL-USBL_Li_2023} have existed for years to bound the odometry drift.
When other acoustic sensors, such as multibeam echosounder (MBES)~\cite{INS-DVL-MBES_Palomer_2016} and multibeam forward-looking sonar (MFLS)~\cite{INS-DVL-MFLS_Cheng_2022}, are available, geophysical observations made by the sonars could further improve localization robustness.
Besides velocity measurements, DVL also generates sparse point clouds to provide additional measurements for localization. 
For example, in~\cite{DVL-Cloud-aided_Ozog_2013}, the author presented the factor-graph SLAM using parameterized planar features from sparse point clouds.

%%% related 2: visual-fused(IMU, sonar, DVL ...)
Compared to acoustic sensors, visual data contain more information and could be leveraged for localization. 
Recently, visual-based SLAM~\cite{OpenVINS_Geneva_2020,ORB-SLAM3_Campos_2021} has been significantly researched in the robotic community across various domains and applications.
Even though there is significant SLAM research done in the marine robotics community, significant technological hurdles remain, such as poor image quality in a low light environment, featureless ice terrain, and limited onboard processing capability.

Offline methods, such as the Structure From Motion (SfM), have been applied to recover large-scale underwater 3D scenes and camera poses~\cite{Underwater-SFM_Singh_2007,Mono-Mosaicing_Nicosevici_2009}. 
Yet, these methods are computationally expensive and not realistic to run online on an AUV. 
On the other hand, VO is capable of processing images at high frame rates (e.g., 10-20Hz), and the uses of monocular camera and stereo-camera have been investigated for underwater scenarios~\citeleft\citenum{Mono-VO-Mosaic_Gracias_2003,Mono-VO-Turbid_Ferrera_2019,Stereo-VO_OpticalFlow_Corke_2007,Stereo-VO-Selective_Bellavia_2017}\citeright.
As mentioned in the survey~\cite{Underwater-VIO-Survey_Joshi_2019}, visual measurements are usually combined with other sensors (e.g., IMU) for improved performance. 
For example, the pressure sensor can be used to aid the VIO algorithms using filter-based and optimization-based methods~\cite{VIPO-Filter_Shkurti_2011} and~\cite{VIPO-Optimization_Hu_2022}.  
The SVIn2~\cite{SVIn2_Rahman_2019} took another step forward, which fuses the measurements from stereo cameras, IMU, depth sensor and profiling sonar in a keyframe-based nonlinear optimization for underwater localization.
Similar to our method presented in this paper, DVL velocity fused VIO are developed in~\citeleft\citenum{DVIO-HullInspection_Kim_2013, DVIO-Habor_Vargas_2021,DVIO-DeepSea_Chavez_2019}\citeright ~for hull inspection, harbor exploration and deep-sea operation. 
However, our work herein furthers the field by using the sparse point cloud from the DVL to enhance the feature estimation for vehicle pose updates.

%%% related 3: Range based enhacement

Dense point clouds fusing with images have been widely used to enhance feature 3D position estimation in computer vision. 
In~\cite{LiDAR-SfM_Zhen_2020}, the authors presented a LiDAR-enhanced SfM pipeline that fuses the dense LiDAR point clouds with the matched visual features in a joint optimization to solve camera motion and feature position. 
In \cite{Depth-VO_Zhang_2014,LVI-SAM_Shan_2021}, LiDAR point cloud is used to interpolate the depth for the detected camera features.
However, such dense point clouds are typically not available for underwater robotics, or a power-hungry multibeam sonar is needed.
To our best knowledge, there is limited research on using sparse point clouds for Visual SLAM.
For example, the method presented in~\cite{Echosounder-VO_Roznere_2020,Depth-VIO-Underwater_Xu_2021} used the sparse range measurements from a single-beam echosounder to recover the depth information for a monocular SLAM system.
To further advance the visual SLAM using sparse point clouds, our method in this paper will employ non-uniform sparse point clouds from a DVL sensor to aid feature 3D position estimation.
%%
