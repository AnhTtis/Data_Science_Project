% !TEX root = main.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                     				 Conclusions                      			 %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \vspace{-2mm}
\section{Conclusions and Future Plan}
\label{sec:conclusions}

In this paper, we presented a tightly-couple Visual-DVL-Inertial odometry for underwater robots.
A modified keyframe selection and marginalization method was introduced, and a DVL-aided feature enhancement approach is realized to further improve the localization performance.
With those key contributions, we have validated the complete framework with a challenging under-ice data set.
Based on the statistical values, we found our method has the lowest error with an RMSE of 1.11 meters for X-Y plane translation. 

We are planning our future research in two directions, upgrading the existing frame and integrating more perception sensors.
Currently, our visual measurement noise is set relatively high.
But, we expect the improved front-end feature tracking could allow us to lower the measurement noise for better localization results.
Previous research~\cite{DVL-IMU-Calib_Troni_2015} has shown that a well-calibrated transform between DVL and IMU will improve navigation accuracy.  
We are also interested in integrating extra perception sensors such as a forward-looking sonar that could provide feature measurements at a further distance with scales.
However, imaging sonar normally has a wide elevation angle that could not be directly resolved from the image, which will pose challenges in feature detection and tracking.
In the future, we are also interested in evaluating our algorithm on other underwater datasets and comparing it with the state-of-art SLAM such as SVIn2~\cite{SVIn2_Rahman_2019} and OpenVINS~\cite{OpenVINS_Geneva_2020}. 
