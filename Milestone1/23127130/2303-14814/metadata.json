{
    "arxiv_id": "2303.14814",
    "paper_title": "WinCLIP: Zero-/Few-Shot Anomaly Classification and Segmentation",
    "authors": [
        "Jongheon Jeong",
        "Yang Zou",
        "Taewan Kim",
        "Dongqing Zhang",
        "Avinash Ravichandran",
        "Onkar Dabeer"
    ],
    "submission_date": "2023-03-26",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
    ],
    "abstract": "Visual anomaly classification and segmentation are vital for automating industrial quality inspection. The focus of prior research in the field has been on training custom models for each quality inspection task, which requires task-specific images and annotation. In this paper we move away from this regime, addressing zero-shot and few-normal-shot anomaly classification and segmentation. Recently CLIP, a vision-language model, has shown revolutionary generality with competitive zero-/few-shot performance in comparison to full-supervision. But CLIP falls short on anomaly classification and segmentation tasks. Hence, we propose window-based CLIP (WinCLIP) with (1) a compositional ensemble on state words and prompt templates and (2) efficient extraction and aggregation of window/patch/image-level features aligned with text. We also propose its few-normal-shot extension WinCLIP+, which uses complementary information from normal images. In MVTec-AD (and VisA), without further tuning, WinCLIP achieves 91.8%/85.1% (78.1%/79.6%) AUROC in zero-shot anomaly classification and segmentation while WinCLIP+ does 93.1%/95.2% (83.8%/96.4%) in 1-normal-shot, surpassing state-of-the-art by large margins.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.14814v1"
    ],
    "publication_venue": "Accepted to Conference on Computer Vision and Pattern Recognition (CVPR) 2023"
}