
\section{Software Description}
\label{sec: software description}

Saihu's analyses are done in 3 steps: describe a network to be analyzed (Sec.~\ref{sec: network description file}); execute analyses with selected tools (Sec.~\ref{sec: tool usage}); and export analysis reports back to the user (Sec.~\ref{sec: analysis reports}). 

\subsection{Network Description File}
\label{sec: network description file}

\begin{figure}
\centering
\begin{subfigure}[b]{0.63\textwidth}
    \centering
    \includegraphics[width=\linewidth]{phy_net.png}
    \caption{
    Physical Network. 
    }
    \label{fig: physical network}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.35\textwidth}
    \centering
    \includegraphics[width=0.7\linewidth]{op_net.png}
    \caption{Output Port Network.}
    \label{fig: output port network}
\end{subfigure}
\caption{Physical and output port network examples}
\label{fig: physical and op network}
\end{figure}


Saihu allows the user to write a network in either a \textit{physical network} or an \textit{output port network} format. Examples are shown in Fig.~\ref{fig: physical and op network}. Briefly speaking, a physical network represents the physical connections between multiple switches and stations and flows that travel through different input and output ports of switches; it represents the view of a real-world network. On the other hand, as a physical network includes more than enough information, we provide the output port network format as a simplified form to define a network. As the queuing is only on output ports even if we provide full network information, we only describe output ports as service units instead of the entire device. 

To allow easy access to the tool, we provide both physical and output port networks as available input file forms. People may prefer to directly write in the physical network format to avoid the translation to an output port format, and some people may prefer the output port network to write a network concisely.
While xTFA takes a physical network as an XML file and the others parse from an output port network as a JSON file, one can choose the format they prefer to define a network as Saihu automatically converts a file when needed. 

\subsubsection{Option 1: Physical Network in XML}
\label{sec: physical network xml}
A physical network is written as an XML file in the same format as in xTFA, and at least contains \textbf{General network information}, \textbf{Servers}, \textbf{Links}, and \textbf{Flows}. 
Listing.~\ref{lst: xml example} demonstrates a minimal example.

\begin{lstlisting}[language=XML,caption={Example of a physical network representation},
label={lst: xml example}]
<network name="demo" technology="FIFO+IS" minimum-packet-size="50B"/>
<station name="src0"/>
<switch name="s0" service-latency="10us" service-rate="4Mbps"/>
<station name="sink0"/>
<link name="src0-s0" from="src0" to="s0" fromPort="o0" toPort="i0"/>
<link name="s0-sink0" from="s0" to="sink0" fromPort="o0" toPort="i0" transmission-capacity="10Mbps"/>
<flow name="f0" arrival-curve="leaky-bucket" lb-burst="10B" lb-rate="10kbps" maximum-packet-size="50B" source="src0">
    <target>
        <path node="s0"/>
        <path node="sink0"/>
    </target>
</flow>
\end{lstlisting}

First, one \texttt{network} element defines the general network information as its attributes: the network's name (\texttt{name}), analysis parameters concatenated by the plus sign (\texttt{technology}, \texttt{IS} stands for \textit{Input Shaping}), and optionally some default value (e.g. \texttt{minimum-packet-size}) across the network. 

Second, a server can be either a \texttt{station} or a \texttt{switch} representing a physical node. Although they are physically different, they both serve as service-providing devices in our tools as mentioned in Sec.~\ref{sec: system model}, or sources/sinks of a data flow. The service parameters \texttt{service-latency} and \texttt{service-rate} define a default service curve for all the output ports on this device.

Third, a \texttt{link} connects two devices. Saihu tools consider output ports as processing units, so the physical link must be defined \texttt{from} a physical node \texttt{to} another node with the input and output ports used by the link. Namely, it goes from an output port of one server to an input port of another server.
Since a link directly attaches to an output port, users can define service via a link. The \texttt{transmission-capacity} of the link can also be specified to consider line shaping. Without defined values, the system will apply the default values defined at the upper levels (\texttt{switch/station} or \texttt{network}).

Finally, a \texttt{flow} element defines a flow. Flow paths are surrounded by \texttt{target} elements, where each node it traverses is listed as a \texttt{path} element with its \texttt{node} attribute indicating the name of the physical node. In this format, a multicast flow is possible and is obtained by defining multiple \texttt{target} elements within the same flow.
A token-bucket curve at the \texttt{source} is defined by \texttt{arrival-curve}, \texttt{lb-burst}, and \texttt{lb-rate} keywords. Packetization is considered with maximum and minimum packet sizes. Saihu analyzes all the output ports in the order of the flow path.

\subsubsection{Option 2: Output Port Network in JSON}
\label{sssec: json}

Output port format is designed by the authors to write the network concisely. The file contains at least \textbf{General network information}, \textbf{Servers}, and \textbf{Flows}. An example is shown as Listing~\ref{lst: json example}.

First, a \texttt{network} object defines the general network information, the default values, and units throughout the network.

Second, \texttt{servers} defines all servers as an array. The parameters can be either a \textit{string} as a number followed by a unit, e.g. \texttt{"10us"} for 10 microseconds; or a \textit{number} that uses the predefined unit.
The service curve is taken as the maximum of all rate-latency curves defined in \texttt{service\_curve} (see Sec.~\ref{sec: system model}). 
Each rate-latency curve is described by a pair of rate and latency values with the same index. For example, the service curve of server \texttt{s0-o0} is derived from 2 rate-latency curves: the first has a 10 microseconds latency and 4 megabits per second rate, and the second has a 1000 microseconds latency and 50 megabits per second rate.

Notice that in the output port network format, we use \textit{graph-induced-by-flows} as the network topology instead of manually defining links. A link between two servers exists only when at least one flow crosses these two servers consecutively. Therefore, the link's transmission capacity attached to an output port is directly defined on a server with the keyword \texttt{capacity}.

\begin{lstlisting}[float,language=json,caption={Network information with default values},label={lst: json example}]
{
    "network": {
        "name": "demo",
        "multiplexing": "FIFO",
        "rate_unit": "Mbps"
    },
    "servers": [
        {
            "name": "s0-o0",
            "service_curve": {
                "latencies": ["10us", "1ms"],
                "rates": [4, "50Mbps"]
            },
            "capacity": "200Mbps"
        }
    ],
    "flows": [
        {
            "name": "f0",
            "path": ["s0-o0"],
            "arrival_curve": {
                "bursts": ["10B", "2kB"],
                "rates": ["10kbps", 0.5]
            },
            "max_packet_length": "50B",
        }
    ]
}
\end{lstlisting}
\lstsetblack

Finally, \texttt{flows} represents the flows as an array. Each flow is defined by a \texttt{path} as an array of servers, and an \texttt{arrival\_curve} at its source.
The arrival curve is defined as the minimum of the multiple token-bucket curves with each pair of burst and rate values represents a token-bucket curve (see Sec.~\ref{sec: system model}). For example, \texttt{f0}'s arrival curve is composed of a token-bucket curve of burst 10 bytes and rate 10 kilobits per second, and a curve of burst 2 kilobytes and rate 0.5 megabits per second.

All flows written in the output port network format are assumed to be unicast flows. When being converted from a physical network with multicast flows, it separates the paths into multiple unicast flows with the same source and arrival curve (see Section \ref{sec: system model}).


\subsection{Tool Usage}
\label{sec: tool usage}


Saihu analysis execution can be done via the command line tool \texttt{main.py} or by importing the interface from \texttt{interface.py}. We demonstrate the simplest way to analyze a network file, say \textit{demo.json}, with both possibilities. Listing~\ref{lst: cmd example} and Listing~\ref{lst: package example} show two ways to analyze \textit{demo.json} with all the tools and methods available inside Saihu.

\begin{lstlisting}[float,language=bash,caption={Use Saihu as command line tool},label={lst: cmd example}]
python main.py demo.json -a
\end{lstlisting}

\begin{lstlisting}[float,style=pythonstyling,caption={Use Saihu as package},label={lst: package example}]
from saihu.interface import TSN_Analyzer
analyzer = TSN_Analyzer("demo.json")
analyzer.analyze_all()
analyzer.export("demo")
\end{lstlisting}

Manual selection of tools or methods is possible via specifying different flags in the command line interface, or using different function names as \texttt{analyze\_xxx}, with the \texttt{analyze\_all} in the above example representing analyzing with all tools.

\subsection{Analysis Reports}
\label{sec: analysis reports}

Saihu can generate 2 kinds of reports:
\begin{enumerate}
    \item A \textit{human-friendly report} is generated as a Markdown file that gives the per-flow end-to-end delay, per-server delay, and execution time for each tool. The delay bounds are presented in tables where each row is a flow or a server, and each column is a method executed by a tool. The last column contains the minimum result obtained in the current round of analysis. Fig.~\ref{fig: human friendly report} demonstrates an example of per-flow end-to-end delay and execution time as a reference.

    The report also contains some reminders about the user inputs: network topology using the graph-induced-by-flows (Sec.~\ref{sssec: json}), flow paths, and link utilization by nodes. Link utilization is defined as the ratio between the aggregated arrival rate at a node and its service rate.

    \item A \textit{machine-friendly report} is written in JSON format for easy parsing from other programs. It stores the execution outputs, i.e. the per-flow end-to-end delay, per-server delay, and execution time. An example is shown in Listing~\ref{lst: machine friendly report}. 
    Note that the numbers in a human-friendly report are always rounded to 3 decimal digits while there's no such rounding for a machine-friendly report. As a result, one should read the machine-friendly report if they require a very precise result.

\end{enumerate}

\begin{figure}[!tbh]
\centering
\begin{subfigure}[t]{0.72\textwidth}
    \centering
    \includegraphics[width=\linewidth]{e2e_delay.png}
    \caption{Flow end-to-end delay.}
    \label{fig: e2e delay}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.26\textwidth}
    \centering
    \includegraphics[width=\linewidth]{exec_time.png}
    \caption{Execution time.}
    \label{fig: exec time}
\end{subfigure}
\caption{Human-friendly Markdown report
}
\label{fig: human friendly report}
\end{figure}

\begin{lstlisting}[language=json,caption={JSON report},label={lst: machine friendly report}]
{
    "name": "demo",
    "flow_e2e_delay": {
        "f0": {
            "xTFA_TFA": 99.32394489448944,
            "Panco_PLP": 80.05,
            "Panco_ELP": 80.05,
            "DNC_SFA": 80.0501253132832,
            "DNC_PMOO": 80.20050125313283,
            "DNC_LUDB": 80.0501253132832
        },
...
    "execution_time": {
        "xTFA_TFA": 5.716085433959961,
        "Panco_PLP": 147.26519584655762,
        "Panco_ELP": 129.76408004760742,
        "DNC_SFA": 12.0,
        "DNC_PMOO": 9.0,
        "DNC_LUDB": 172.0
    },
    "units": {
        "flow_delay": "us",
        "server_delay": "us",
        "execution_time": "ms"
    }
}
\end{lstlisting}
\lstsetblack
