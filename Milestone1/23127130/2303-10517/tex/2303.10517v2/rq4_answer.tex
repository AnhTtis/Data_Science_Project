\section{RQ4 Overlap Analysis} \label{sec:rq4}
In this section, we investigate to which extent the tools agree in their judgments.
We use the SWC registry as a common frame of reference and map all findings to an appropriate SWC class, if any.

This excludes findings that do not fit any SWC class.
More specifically, the following nine %10 
findings are omitted for that reason: 
one finding of Ethainter (\emph{unchecked\_tainted\_static call}), 
one of Securify (\emph{missing\_input\_validation}),
one %two 
of Maian (\emph{Ether\_lock}
), 
five of Osiris (\emph{Callstack\_bug}, \emph{Division\_bugs}, \emph{Modulo\_bugs}, \emph{Signedness\_bugs}, \emph{Truncation\_bugs}), and one of Oyente \linebreak(\emph{Callstack\_Depth\_Attack\_Vulnerability}).

\newcommand\flagged{\mathrm{Flagged}}%
\newcommand\swc{\mathrm{Swc}}%
\newcommand\overlap{\mathrm{Overlap}}%
To determine the degree of overlap, we use the following measure.
For a tool~$t$, let $\swc(t)$ be the set of SWC classes that $t$ is able to detect, and let $\flagged(t,s)$ be the set of contracts that $t$ flags for having a weakness of class~$s$.
We define the overlap between two tools $t_1$ and $t_2$ as
\[ \overlap(t_1,t_2) = \frac
{\sum_{s\in\swc(t_1)\cap\swc(t_2)}\lvert\flagged(t_1,s)\cap\flagged(t_2,s)\rvert}
  {\sum_{s\in\swc(t_1)\cap\swc(t_2)}\lvert\flagged(t_1,s)\rvert}
\]
The numerator counts, per weakness, the contracts flagged by both tools, while the denominator gives the number of all contracts flagged by the first tool.
This measure is not symmetric. $\overlap(t_1,t_2)=100\,\%$ means that for the SWC classes in common, $t_1$ flags a subset of the contracts flagged by~$t_2$.
If additionally $\overlap(t_2,t_1)=100\,\%$ holds, then the two tools are in perfect agreement, something to be expected for $t_1=t_2$ only.

\begin{table}
  \caption{Overlap of Tool Findings [\%]}
  \label{tab:agreement}
  \centering
  \renewcommand\tabcolsep{1pt}
\def\cca#1{%
  \ifx\relax#1\relax\else
    %\cellcolor{darkgray!#1}%
    \cellcolor{DarkGreen!#1}%
    \ifdim #1pt>49pt\color{white}\fi
    #1%
  \fi}
  \makebox[0pt]{\small
  \pgfplotstabletypeset[
    col sep=semicolon,
    precision=1,
    fixed zerofill,
    every head row/.style={before row=\toprule, after row=\midrule},
    every last row/.style={after row=\bottomrule},
    tool/.style={column type=r, assign cell content/.style={@cell content=\cca{##1}}},
    tool/.list={1,2,3,4,5,6,7,8,9,10,11,12},
    columns/Tool/.style={string type, column type=l, column name=$t_1{\downarrow}$\hskip 0pt plus 1filll$t_2{\rightarrow}$},
]{overlaptable.csv}}
\end{table}

\autoref{tab:agreement} shows the overlap between any two tools, with $t_1$ listed vertically and $t_2$ horizontally.
Since eThor detects reentrancy only, its row and column in the table give an idea of how differently a weakness may be assessed by the tools.
For Vandal, we find high values in its column and low ones in its row, which indicates that most weaknesses it reports are not backed by other tools.
As discussed in \autoref{sec:tool_reports}, a large number of Vandal's findings are likely to be false positives, and the numbers in \autoref{tab:agreement} reflect that.

Another observation concerns Osiris and Oyente.
We expect a high overlap as Osiris extends Oyente.
In fact, \np[\%]{90.2} of Oyente's findings are backed by Osiris, while Oyente covers \np[\%]{58.5} of Osiris' findings.
Apparently, Osiris not only detects additional weaknesses (not considered in the comparison), but also flags additional contracts with weaknesses the tools have in common.

\autoref{fig:agreement} shows the overlap in more detail.
We exclude Vandal (due to its overreporting) and Oyente (as Osiris extends it), to avoid an inflation of overlaps.
Each row gives a breakdown of the contracts flagged by a specific tool, for each SWC class covered by at least two tools.
Blue identifies the share of contracts flagged exclusively by the tool, whereas red, green, and purple indicate the share also flagged by one, two, or more other tools.
A good agreement shows as purple where four or more tools check for the SWC class (101, 105, 107), green where three tools detect it (104, 106, 112, 114, 116), and red for two tools (113, 124).
\input{figure_agreement}


\ITEM{SWC 101~-- \SWC{101}:}
We find hardly any agreement of all four tools. 
MadMax, by construction, checks for a subcase of 101 that is not covered by the other tools, but even green (overlap of three) is rare.
In \autoref{sec:relation}, we analyze the evolution of overlaps for this weakness in more detail.

\ITEM{SWC 104~-- \SWC{104}:}
The three tools show some agreement, as red and green dominate blue.

\ITEM{SWC 105~-- \SWC{105}:}
Detected by six tools, we see the highest amount of purple among all classes.

\ITEM{SWC 106~-- \SWC{106}:}
Virtually all of Maian's findings coincide with at least one other tool, while Ethainter and Mythril show a fair amount of blue.
The top plot of \autoref{fig:errors} provides an explanation: In the second half of the timeline, the error rate of Maian increases, as the tool fails to handle more recent contracts with new types of instructions, so Maian stops reporting weaknesses.

\ITEM{SWC 107~-- \SWC{107}:}
Even though reentrancy is one of the best-researched weaknesses and is detected by five tools, agreement of more than three tools is rare.
In \autoref{sec:relation}, we analyze the evolution of overlaps for this weakness in more detail.

\ITEM{SWC 112~-- \SWC{112}:}
This weakness is detected by three tools, hence the large amount of green actually indicates the best agreement in the chart.
Ethainter seems to implement a more liberal definition of the vulnerability, as it flags many additional contracts (blue).

\ITEM{SWC 113~-- \SWC{113}:}
MadMax has been designed to detect specific gas-related issues, which partly map to this class.
There is some overlap with Mythril, but since the latter flags many more contracts under this label, the red share is not visible in Mythril's bar.

\ITEM{SWC 114~-- \SWC{114}:}
The bars are mainly blue and red, indicating little agreement between all three tools.

\ITEM{SWC 116~-- \SWC{116}:}
Virtually all contracts flagged by Osiris are also flagged by one of the other tools, in most cases by both.
The other tools, however, flag many more contracts, as the comparatively small size of the green part~-- representing the same group of contracts in all three bars~-- shows.
Like in the case of Maian and SWC~106 above, the error rate of Osiris increases in the second half of the study period, as new instructions prevent it from reporting weaknesses (\autoref{fig:errors}).

\ITEM{SWC 124~-- \SWC{124}:}
The contracts flagged by Mythril are essentially a subset of those flagged by Ethainter, but a small one, as the blue part of Ethainter's bar dominates.

\begin{mdframed}[style=mpdframe]
\textbf{Observation 4.}
There is little agreement between the tools regarding the findings, even for well-researched and frequently analyzed weaknesses such as reentrancy.
Contributing factors are the lack of commonly accepted, precise definitions for the weaknesses as well as diverging approaches to detect them.
A mutually low agreement suggests that the tools are rather complementary.
\end{mdframed}
