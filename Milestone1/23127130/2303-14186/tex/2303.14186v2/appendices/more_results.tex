
\subsection{Correlation distribution}

\paragraph{Generalization across $\alpha$'s.} In \Cref{fig:jointplot} left, we compare the linear datamodeling scores (LDS) evaluated on $\alpha=0.5$ sub-sampled training sets to those evaluated on $\alpha=0.75$.
(The numbers are overall lower as these are evaluated on data where only one model was trained on each subset,instead of averaging over 5 models; hence, there is more noise in the data.) As we observe, the LDS scores on different $\alpha$'s are highly correlated, suggesting that \trak scores computed on a single $\alpha$ generalize well.

\paragraph{LDS correlation between \trak and datamodels.} In \Cref{fig:jointplot} right, we compare the LDS correlations of datamodels to that of \trak and find that they are correlated across examples; in general, \trak also performs better on examples on which datamodels perform better.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.45\linewidth]{figures/cifar2_off_dist.pdf}
    \includegraphics[width=0.45\linewidth]{figures/cifar2_dm_vs_trak.pdf}
\caption{{\bf (Left)} The LDS of \cifartwo \trak scores computed with $\alpha=0.5$ models then evaluated on either models trained with either $\alpha=0.5$ or $\alpha=0.75$. Each point corresponds to a validation example. {\bf (Right)} The LDS of \cifartwo datamodel scores compared with that of \trak. Here, the LDS is measured on two different estimators.}
\label{fig:jointplot}
\end{figure}



\clearpage
\subsection{Table for LDS evaluation}

\begin{table}[h]
    \centering
    \begin{tabular}{llrrrrrrrrr}
        \toprule
        Dataset & & TRAK & TracIn \citep{pruthi2020estimating} & Infl. \citep{koh2017understanding} & Datamodels \citep{ilyas2022datamodels} \\
        \midrule
        \cifartwo & \# models & 5 & 100 & - & 1,000 \\
        & Time (min.) & 3 & 100 & - & 500  \\
        & LDS & {\bf 0.203(3)} & 0.056(2) & - & 0.162(5)  \\
        \midrule
        \cifarten & \# models & 20 & 20 & 1 & 5,000 \\
        & Time (min.) & 20 & 60 & 20,000 & 2,500 \\
        & LDS & {\bf 0.271(4)} & 0.056(7) & 0.037(13) & 0.199(4) \\
        \midrule
        \qnli & \# models & 10 & 1 &  1 & 20,000 \\
        & Time (min.) & 640 & 284 & 18,000 & 176,000 \\
        & LDS & {\bf 0.416(10)} & 0.077(29) & 0.114(43) & 0.344(32) \\
        \midrule
        ImageNet & \# models & 100 & 1 &  20 & 30,000 \\
        & Time (min.) & 2920 & 76 & $>$100,000 &   525,000  \\
        & LDS & {\bf 0.188(6)} & 0.008(6) &   0.037(6) & 0.1445(6) \\
        \bottomrule
        \end{tabular}
        \caption{{\em Comparison of different data attribution methods.} We quantify various data attribution methods in terms of both their {\em predictiveness}---as
        measured by the linear datamodeling score---as well as their {\em
        computational efficiency}---as measured by either the total computation
        time (wall-time measured in minutes on a single A100 GPU; see
        \Cref{app:wall_time} for details) or the number of trained models used
        to compute the attribution scores. The errors indicate 95\%
        bootstrap confidence intervals.
        Sampling-based methods (datamodels and
        empirical influences) can outperform \trak when allowed to use more
        computation, but this leads to a significant
        increase in computational cost.
        }
        \label{tab:all_best}
\end{table}





\clearpage
\subsection{\trak examples}
\label{app:more_examples}
We display more examples identified with \trak scores in \Cref{fig:imagenet_nns_extra} (ImageNet), \Cref{tab:qnli_more} (\qnli), and \Cref{fig:clip_examples_extra} (\clip on \mscoco).

\begin{figure}[!b]
    \centering
    \includegraphics[width=.9\linewidth,trim={0 0 0 0},clip]{figures/imagenet_nns_extra.pdf}
\caption{
     {\em \trak attributions for ResNets trained on ImageNet.}
    We display random test examples and their corresponding
    most helpful (highest-scoring) and most detracting (lowest-scoring)
    training examples according to \trak.
}
\label{fig:imagenet_nns_extra}
\end{figure}


\clearpage
\begin{figure}
    \centering
    \begin{tabular}{p{0.33\textwidth}p{0.30\textwidth}p{0.30\textwidth}}
    \toprule
    \textbf{Example} & \textbf{Highest \trak score (+)} & \textbf{Lowest \trak score (-)} \\
    \midrule
    \scriptsize {\bf Q:} What was a major success, especially in rebuilding Warsaw? {\bf A:} Like many cities in Central and Eastern Europe, infrastructure in Warsaw suffered considerably during its time as an Eastern Bloc economy – though it is worth mentioning that the initial Three-Year Plan to rebuild Poland (especially Warsaw) was a major success, but what followed was very much the opposite. {\bf (Yes)} & \scriptsize {\bf Q:} In 1998, the deal was renewed for what amount over four years? {\bf A:} Television money had also become much more important; the Football League received £6.3 million for a two-year agreement in 1986, but when that deal was renewed in 1988, the price rose to £44 million over four years. {\bf (Yes)} & \scriptsize {\bf Q:} Who was a controversial figure due to a corked-bat incident? {\bf A:} Already a controversial figure in the clubhouse after his corked-bat incident, Sammy's actions alienated much of his once strong fan base as well as the few teammates still on good terms with him, (many teammates grew tired of Sosa playing loud salsa music in the locker room) and possibly tarnished his place in Cubs' lore for years to come. {\bf (No)} \\
    \midrule
    \scriptsize {\bf Q:} What is the name associated with the eight areas that make up a part of southern California? {\bf A:} Southern California consists of one Combined Statistical Area, eight Metropolitan Statistical Areas, one international metropolitan area, and multiple metropolitan divisions. {\bf (Yes)} & \scriptsize {\bf Q:} Was was the name given to the Alsace provincinal court? {\bf A:} The province had a single provincial court (Landgericht) and a central administration with its seat at Hagenau. {\bf (Yes)} & \scriptsize {\bf Q:} What do six of the questions asses? {\bf A:} For each question on the scale that measures homosexuality there is a corresponding question that measures heterosexuality giving six matching pairs of questions. {\bf (No)} \\
    \midrule
    \scriptsize {\bf Q:} What words are inscribed on the mace of parliament? {\bf A:} The words There shall be a Scottish Parliament, which are the first words of the Scotland Act, are inscribed around the head of the mace, which has a formal ceremonial role in the meetings of Parliament, reinforcing the authority of the Parliament in its ability to make laws. {\bf (No)} & \scriptsize {\bf Q:} Whose name is on the gate-house fronting School Yard? {\bf A:} His name is borne by the big gate-house in the west range of the cloisters, fronting School Yard, perhaps the most famous image of the school. {\bf (No)} & \scriptsize {\bf Q:} What kind of signs were removed form club Barcelona? {\bf A:} All signs of regional nationalism, including language, flag and other signs of separatism were banned throughout Spain. {\bf (Yes)} \\
    \midrule
    \scriptsize {\bf Q:} What was the percentage of a female householder with no husband present? {\bf A:} There were 158,349 households, of which 68,511 (43.3\%) had children under the age of 18 living in them, 69,284 (43.8\%) were opposite-sex married couples living together, 30,547 (19.3\%) had a female householder with no husband present, 11,698 (7.4\%) had a male householder with no wife present. {\bf (Yes)} & \scriptsize {\bf Q:} What percent of household have children under 18? {\bf A:} There were 46,917 households, out of which 7,835 (16.7\%) had children under the age of 18 living in them, 13,092 (27.9\%) were opposite-sex married couples living together, 3,510 (7.5\%) had a female householder with no husband present, 1,327 (2.8\%) had a male householder with no wife present. {\bf (Yes)} & \scriptsize {\bf Q:} Roughly how many same-sex couples were there? {\bf A:} There were 46,917 households, out of which 7,835 (16.7\%) had children under the age of 18 living in them, 13,092 (27.9\%) were opposite-sex married couples living together, 3,510 (7.5\%) had a female householder with no husband present, 1,327 (2.8\%) had a male householder with no wife present. {\bf (No)} \\
        \midrule
        \scriptsize {\bf Q:} What did Warsz own? {\bf A:} In actuality, Warsz was a 12th/13th-century nobleman who owned a village located at the modern-day site of Mariensztat neighbourhood. {\bf (Yes)} & \scriptsize {\bf Q:} What company did Ray Kroc own? {\bf A:} It was founded in 1986 through the donations of Joan B. Kroc, the widow of McDonald's owner Ray Kroc. {\bf (Yes)} & \scriptsize {\bf Q:} What did Cerberus guard? {\bf A:} In Norse mythology, a bloody, four-eyed dog called Garmr guards Helheim. {\bf (No)} \\
        \midrule
        \scriptsize {\bf Q:} What words are inscribed on the mace of parliament? {\bf A:} The words There shall be a Scottish Parliament, which are the first words of the Scotland Act, are inscribed around the head of the mace, which has a formal ceremonial role in the meetings of Parliament, reinforcing the authority of the Parliament in its ability to make laws. {\bf (No)} & \scriptsize {\bf Q:} Whose name is on the gate-house fronting School Yard? {\bf A:} His name is borne by the big gate-house in the west range of the cloisters, fronting School Yard, perhaps the most famous image of the school. {\bf (No)} & \scriptsize {\bf Q:} What kind of signs were removed form club Barcelona? {\bf A:} All signs of regional nationalism, including language, flag and other signs of separatism were banned throughout Spain. {\bf (Yes)} \\
    \bottomrule
\end{tabular}
\caption{{\em Top \trak attributions for \qnli examples.} Yes/No indicates the label (entailment vs. no entailment).}
\label{tab:qnli_more}
\end{figure}

\clearpage
\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth,trim={0 0 0 0},clip]{figures/CLIP_examples/clip_examples_0.pdf}
    \includegraphics[width=\linewidth,trim={0 0 0 0},clip]{figures/CLIP_examples/clip_examples_1.pdf}
    \includegraphics[width=\linewidth,trim={0 0 0 0},clip]{figures/CLIP_examples/clip_examples_2.pdf}
\caption{
     {\em Top attributions for \clip models trained on \mscoco.}
    We display random test examples and their corresponding
    most helpful (highest-scoring) and most detracting (lowest-scoring)
    training examples according to \trak, \clip similarity distance, and \tracin.
    }
\label{fig:clip_examples_extra}
\end{figure}






\clearpage
\subsection{\modeldiff with \trak}
\Cref{fig:modeldiff} shows how we apply \trak to dramatically accelerate the
\modeldiff algorithm.
\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth,trim={0 0 0 0},clip]{figures/modeldiff_pipeline.pdf}
\caption{
{\em Accelerating learning algorithm comparisons with \trak.}
The \modeldiff framework from \citep{shah2022modeldiff} uses datamodel
representations to surface features that distinguish two learning algorithms. In
the case study here, we compare models trained on the \textsc{Living17} dataset {\em with} and {\em without} data
augmentation. Applying \modeldiff involves three stages: (1) computing datamodel
representations; (2) applying the \modeldiff algorithm to extract {\em
distinguishing subpopulations} of inputs on which two model classes behave
differently; (3) counterfactually testing the inferred feature associated
with the subpopulation. \citet{shah2022modeldiff} find that models trained with
data augmentation latch onto the presence of spider webs as a spurious
correlation to predict the class spider. Here, we recover their result by using
\trak scores instead of datamodel scores in step (1); doing so reduces the
computational cost of \modeldiff by 100x.
}
\label{fig:modeldiff}
\end{figure}