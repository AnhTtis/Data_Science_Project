% model-based RL

@inproceedings{
hafner2021mastering,
title={Mastering Atari with Discrete World Models},
author={Danijar Hafner and Timothy P Lillicrap and Mohammad Norouzi and Jimmy Ba},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=0oabwyZbOu}
}

@inproceedings{
Hafner2020Dream,
title={Dream to Control: Learning Behaviors by Latent Imagination},
author={Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1lOTC4tDS}
}

@inproceedings{hafner2019learning,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle={International Conference on Machine Learning},
  pages={2555--2565},
  year={2019},
  organization={PMLR}
}



% overfitting related work
@article{zhang2018study,
  title={A study on overfitting in deep reinforcement learning},
  author={Zhang, Chiyuan and Vinyals, Oriol and Munos, Remi and Bengio, Samy},
  journal={arXiv preprint arXiv:1804.06893},
  year={2018}
}

@article{zhang2018dissection,
  title={A dissection of overfitting and generalization in continuous reinforcement learning},
  author={Zhang, Amy and Ballas, Nicolas and Pineau, Joelle},
  journal={arXiv preprint arXiv:1806.07937},
  year={2018}
}

@article{packer2018assessing,
  title={Assessing generalization in deep reinforcement learning},
  author={Packer, Charles and Gao, Katelyn and Kos, Jernej and Kr{\"a}henb{\"u}hl, Philipp and Koltun, Vladlen and Song, Dawn},
  journal={arXiv preprint arXiv:1810.12282},
  year={2018}
}

@article{raileanu2020automatic,
  title={Automatic Data Augmentation for Generalization in Reinforcement Learning},
  author={Raileanu, Roberta and Goldstein, Maxwell and Yarats, Denis and Kostrikov, Ilya and Fergus, Rob},
  year={2020}
}

@inproceedings{
Song2020Observational,
title={Observational Overfitting in Reinforcement Learning},
author={Xingyou Song and Yiding Jiang and Stephen Tu and Yilun Du and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJli2hNKDH}
}

@inproceedings{jiang2015dependence,
  title={The dependence of effective planning horizon on model accuracy},
  author={Jiang, Nan and Kulesza, Alex and Singh, Satinder and Lewis, Richard},
  booktitle={Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
  pages={1181--1189},
  year={2015},
  organization={Citeseer}
}

@article{arumugam2018mitigating,
  title={Mitigating planner overfitting in model-based reinforcement learning},
  author={Arumugam, Dilip and Abel, David and Asadi, Kavosh and Gopalan, Nakul and Grimm, Christopher and Lee, Jun Ki and Lehnert, Lucas and Littman, Michael L},
  journal={arXiv preprint arXiv:1812.01129},
  year={2018}
}

@article{chua2018deep,
  title={Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011},
  organization={Citeseer}
}


@article{strand1974theory,
  title={Theory and methods related to the singular-function expansion and Landweberâ€™s iteration for integral equations of the first kind},
  author={Strand, Otto Neall},
  journal={SIAM Journal on Numerical Analysis},
  volume={11},
  number={4},
  pages={798--825},
  year={1974},
  publisher={SIAM}
}

@article{anderssen1981formal,
  title={A formal comparison of methods proposed for the numerical solution of first kind integral equations},
  author={Anderssen, RS and Prenter, PM},
  journal={The ANZIAM Journal},
  volume={22},
  number={4},
  pages={488--500},
  year={1981},
  publisher={Cambridge University Press}
}
@article{morgan1989generalization,
  title={Generalization and parameter estimation in feedforward nets: Some experiments},
  author={Morgan, Nelson and Bourlard, Herv{\'e}},
  journal={Advances in neural information processing systems},
  volume={2},
  pages={630--637},
  year={1989}
}

@article{dropout,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929-1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@inproceedings{
schwarzer2021dataefficient,
title={Data-Efficient Reinforcement Learning with Self-Predictive Representations},
author={Max Schwarzer and Ankesh Anand and Rishab Goel and R Devon Hjelm and Aaron Courville and Philip Bachman},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=uCQfPZwRaUu}
}

@article{laskin2020reinforcement,
  title={Reinforcement Learning with Augmented Data},
  author={Laskin, Misha and Lee, Kimin and Stooke, Adam and Pinto, Lerrel and Abbeel, Pieter and Srinivas, Aravind},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


% hyperparameter optimization for RL related work
@inproceedings{zhang2021importance,
  title={On the importance of hyperparameter optimization for model-based reinforcement learning},
  author={Zhang, Baohe and Rajan, Raghu and Pineda, Luis and Lambert, Nathan and Biedenkapp, Andr{\'e} and Chua, Kurtland and Hutter, Frank and Calandra, Roberto},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4015--4023},
  year={2021},
  organization={PMLR}
}

@article{chen2018bayesian,
  title={Bayesian optimization in alphago},
  author={Chen, Yutian and Huang, Aja and Wang, Ziyu and Antonoglou, Ioannis and Schrittwieser, Julian and Silver, David and de Freitas, Nando},
  journal={arXiv preprint arXiv:1812.06855},
  year={2018}
}

@article{parker2022automated,
  title={Automated Reinforcement Learning (AutoRL): A Survey and Open Problems},
  author={Parker-Holder, Jack and Rajan, Raghu and Song, Xingyou and Biedenkapp, Andr{\'e} and Miao, Yingjie and Eimer, Theresa and Zhang, Baohe and Nguyen, Vu and Calandra, Roberto and Faust, Aleksandra and others},
  journal={arXiv preprint arXiv:2201.03916},
  year={2022}
}

@inproceedings{dorka2021adaptively,
  title={Adaptively Calibrated Critic Estimates for Deep Reinforcement Learning},
  author={Dorka, Nicolai and Boedecker, Joschka and Burgard, Wolfram},
  booktitle={Deep RL Workshop NeurIPS 2021},
  year={2021}
}

@inproceedings{badia2020agent57,
  title={Agent57: Outperforming the atari human benchmark},
  author={Badia, Adri{\`a} Puigdom{\`e}nech and Piot, Bilal and Kapturowski, Steven and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Zhaohan Daniel and Blundell, Charles},
  booktitle={International Conference on Machine Learning},
  pages={507--517},
  year={2020},
  organization={PMLR}
}

@article{schaul2019adapting,
  title={Adapting behaviour for learning progress},
  author={Schaul, Tom and Borsa, Diana and Ding, David and Szepesvari, David and Ostrovski, Georg and Dabney, Will and Osindero, Simon},
  journal={arXiv preprint arXiv:1912.06910},
  year={2019}
}


% RL stuff
@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@book{introdrl2018,
  author    = {Richard S. Sutton and
               Andrew G. Barto},
  title     = {Reinforcement learning: An introduction},
  publisher = {{MIT} Press},
  year      = {2018},
  isbn      = {78-0262039246},
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group}
}

% experiments

@inproceedings{Kaiser2020Model,
  title={Model Based Reinforcement Learning for Atari},
  author={Kaiser, {\L}ukasz and Babaeizadeh, Mohammad and Mi{\l}os, Piotr and Osi{\'n}ski, B{\l}a{\.z}ej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  booktitle={International Conference on Learning Representations},
  year={2019}
}


@article{tassa2018deepmind,
  title={Deepmind control suite},
  author={Tassa, Yuval and Doron, Yotam and Muldal, Alistair and Erez, Tom and Li, Yazhe and Casas, Diego de Las and Budden, David and Abdolmaleki, Abbas and Merel, Josh and Lefrancq, Andrew and others},
  journal={arXiv preprint arXiv:1801.00690},
  year={2018}
}

@article{agarwal2021deep,
  title={Deep reinforcement learning at the edge of the statistical precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@Article{pineda2021MBRL,
  author  = {Luis Pineda and Brandon Amos and Amy Zhang and Nathan O. Lambert and Roberto Calandra},
  journal = {Arxiv},
  title   = {MBRL-Lib: A Modular Library for Model-based Reinforcement Learning},
  year    = {2021},
  url     = {https://arxiv.org/abs/2104.10159},
}








