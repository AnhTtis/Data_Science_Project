{
    "arxiv_id": "2303.13651",
    "paper_title": "Building artificial neural circuits for domain-general cognition: a primer on brain-inspired systems-level architecture",
    "authors": [
        "Jascha Achterberg",
        "Danyal Akarca",
        "Moataz Assem",
        "Moritz Heimbach",
        "Duncan E. Astle",
        "John Duncan"
    ],
    "submission_date": "2023-03-21",
    "revised_dates": [
        "2023-03-27"
    ],
    "latest_version": 1,
    "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
    ],
    "abstract": "There is a concerted effort to build domain-general artificial intelligence in the form of universal neural network models with sufficient computational flexibility to solve a wide variety of cognitive tasks but without requiring fine-tuning on individual problem spaces and domains. To do this, models need appropriate priors and inductive biases, such that trained models can generalise to out-of-distribution examples and new problem sets. Here we provide an overview of the hallmarks endowing biological neural networks with the functionality needed for flexible cognition, in order to establish which features might also be important to achieve similar functionality in artificial systems. We specifically discuss the role of system-level distribution of network communication and recurrence, in addition to the role of short-term topological changes for efficient local computation. As machine learning models become more complex, these principles may provide valuable directions in an otherwise vast space of possible architectures. In addition, testing these inductive biases within artificial systems may help us to understand the biological principles underlying domain-general cognition.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13651v1"
    ],
    "publication_venue": "This manuscript is part of the AAAI 2023 Spring Symposium on the Evaluation and Design of Generalist Systems (EDGeS)"
}