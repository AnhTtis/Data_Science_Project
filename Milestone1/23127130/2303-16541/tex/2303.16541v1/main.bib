
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }
% TMM
@ARTICLE{9465696,
  author={Yu, Lingyun and Xie, Hongtao and Zhang, Yongdong},
  journal={IEEE Transactions on Multimedia}, 
  title={Multimodal Learning for Temporally Coherent Talking Face Generation With Articulator Synergy}, 
  year={2022},
  volume={24},
  number={},
  pages={2950-2962},
  doi={10.1109/TMM.2021.3091863}}
@ARTICLE{9681173,
  author={Ye, Zipeng and Xia, Mengfei and Yi, Ran and Zhang, Juyong and Lai, Yu-Kun and Huang, Xuwei and Zhang, Guoxin and Liu, Yong-jin},
  journal={IEEE Transactions on Multimedia}, 
  title={Audio-Driven Talking Face Video Generation with Dynamic Convolution Kernels}, 
  year={2022},
  volume={},
  number={},
  pages={1-1},
  doi={10.1109/TMM.2022.3142387}}
@ARTICLE{DMEE,
  author={Kim, Nayoung and Kang, Je-Won},
  journal={IEEE Transactions on Multimedia}, 
  title={Dynamic Motion Estimation and Evolution Video Prediction Network}, 
  year={2021},
  volume={23},
  number={},
  pages={3986-3998},
  doi={10.1109/TMM.2020.3035281}}
@ARTICLE{videosum,
  author={Xie, Jiehang and Chen, Xuanbai and Zhang, Tianyi and Zhang, Yixuan and Lu, Shao-Ping and Cesar, Pablo and Yang, Yulu},
  journal={IEEE Transactions on Multimedia}, 
  title={Multimodal-based and Aesthetic-guided Narrative Video Summarization}, 
  year={2022},
  volume={},
  number={},
  pages={1-15},
  doi={10.1109/TMM.2022.3183394}}

@inproceedings{audiocaps,
  author    = {Chris Dongjoo Kim and
               Byeongchang Kim and
               Hyunmin Lee and
               Gunhee Kim},
  title     = {AudioCaps: Generating Captions for Audios in The Wild},
  booktitle = {Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies},
  pages     = {119--132},
  year      = {2019},
}
%Entries
@article{passt,
  title={Efficient training of audio transformers with patchout},
  author={Koutini, Khaled and Schl{\"u}ter, Jan and Eghbal-zadeh, Hamid and Widmer, Gerhard},
  journal={arXiv preprint arXiv:2110.05069},
  year={2021}
}

@article{kinetics,
  author    = {Will Kay and
               Jo{\~{a}}o Carreira and
               Karen Simonyan and
               Brian Zhang and
               Chloe Hillier and
               Sudheendra Vijayanarasimhan and
               Fabio Viola and
               Tim Green and
               Trevor Back and
               Paul Natsev and
               Mustafa Suleyman and
               Andrew Zisserman},
  title     = {The Kinetics Human Action Video Dataset},
  journal = {arXiv preprint arXiv:1705.06950},
  year      = {2017},
}
@article{cogvideo,
  title={CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  journal={arXiv preprint arXiv:2205.15868},
  year={2022}
}
@article{slowfast,
  author    = {Fanyi Xiao and
               Yong Jae Lee and
               Kristen Grauman and
               Jitendra Malik and
               Christoph Feichtenhofer},
  title     = {Audiovisual SlowFast Networks for Video Recognition},
  journal   = {arXiv preprint arXiv:2001.08740},
  year      = {2020},
}
@article{cmac,
  author    = {Shaobo Min and
               Qi Dai and
               Hongtao Xie and
               Chuang Gan and
               Yongdong Zhang and
               Jingdong Wang},
  title     = {Cross-Modal Attention Consistency for Video-Audio Unsupervised Learning},
  journal   = {arXiv preprint arXiv:2106.06939},
  year      = {2021},
}
@article{nuwa,
  title={N{\"U}wa: Visual synthesis pre-training for neural visual world creation},
  author={Wu, Chenfei and Liang, Jian and Ji, Lei and Yang, Fan and Fang, Yuejian and Jiang, Daxin and Duan, Nan},
  journal={European Conference on Computer Vision},
  year={2022}
}
@article{videogpt,
  author    = {Wilson Yan and
               Yunzhi Zhang and
               Pieter Abbeel and
               Aravind Srinivas},
  title     = {VideoGPT: Video Generation using {VQ-VAE} and Transformers},
  journal   = {arXiv preprint arXiv:2104.10157},
  year      = {2021},
}
@article{ucf101,
  author    = {Khurram Soomro and
               Amir Roshan Zamir and
               Mubarak Shah},
  title     = {{UCF101:} {A} Dataset of 101 Human Actions Classes From Videos in
               The Wild},
  journal   = {arXiv preprint arXiv:1212.0402},
  year      = {2012},
}
@inproceedings{bair,
  title={Self-Supervised Visual Planning with Temporal Skip Connections.},
  author={Ebert, Frederik and Finn, Chelsea and Lee, Alex X and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={344--356},
  year={2017}
}
@article{godiva,
  author = {Wu, Chenfei and Huang, Lun and Zhang, Qianxi and Li, Binyang and Ji, Lei and Yang, Fan and Sapiro, Guillermo and Duan, Nan},
  title = {GODIVA: Generating Open-DomaIn Videos from nAtural Descriptions},
  journal   = {arXiv preprint arXiv:2104.14806},
  year = {2021},
}
% ACL
@inproceedings{bpe,
  author    = {Rico Sennrich and
               Barry Haddow and
               Alexandra Birch},
  title     = {Neural Machine Translation of Rare Words with Subword Units},
  booktitle = {Proceedings of the Association for Computational Linguistics},
  year      = {2016}
}
% NIPS:     Proceedings of the International Conference on Neural Information Processing Systems
@article{xdc,
  title={Self-supervised learning by cross-modal audio-video clustering},
  author={Alwassel, Humam and Mahajan, Dhruv and Korbar, Bruno and Torresani, Lorenzo and Ghanem, Bernard and Tran, Du},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9758--9770},
  year={2020}
}
@article{threedworld,
  title={Threedworld: A platform for interactive multi-modal physical simulation},
  author={Gan, Chuang and Schwartz, Jeremy and Alter, Seth and Mrowca, Damian and Schrimpf, Martin and Traer, James and De Freitas, Julian and Kubilius, Jonas and Bhandwaldar, Abhishek and Haber, Nick and others},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}
@article{gan,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
}
@article{vatt,
  title={Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text},
  author={Hassan Akbari and
               Liangzhe Yuan and
               Rui Qian and
               Wei{-}Hong Chuang and
               Shih{-}Fu Chang and
               Yin Cui and
               Boqing Gong},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}
@article{portaspeech,
  title={PortaSpeech: Portable and High-Quality Generative Text-to-Speech},
  author={Ren, Yi and Liu, Jinglin and Zhao, Zhou},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}
@article{melgan,
  title={Melgan: Generative adversarial networks for conditional waveform synthesis},
  author={Kumar, Kundan and Kumar, Rithesh and de Boissiere, Thibault and Gestin, Lucas and Teoh, Wei Zhen and Sotelo, Jose and de Br{\'e}bisson, Alexandre and Bengio, Yoshua and Courville, Aaron C},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@article{hifigan,
  title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17022--17033},
  year={2020}
}
@inproceedings{supcon,
  author    = {Prannay Khosla and
               Piotr Teterwak and
               Chen Wang and
               Aaron Sarna and
               Yonglong Tian and
               Phillip Isola and
               Aaron Maschinot and
               Ce Liu and
               Dilip Krishnan},
  title     = {Supervised Contrastive Learning},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020},
}
@inproceedings{vgan,
  author    = {Carl Vondrick and
               Hamed Pirsiavash and
               Antonio Torralba},
  title     = {Generating Videos with Scene Dynamics},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {613--621},
  year      = {2016}
}
@article{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}
@inproceedings{fid,
  author    = {Martin Heusel and
               Hubert Ramsauer and
               Thomas Unterthiner and
               Bernhard Nessler and
               Sepp Hochreiter},
  title     = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {6626--6637},
  year      = {2017},
}
@inproceedings{cogview,
  title={CogView: Mastering Text-to-Image Generation via Transformers},
  author={Ding, Ming and Yang, Zhuoyi and Hong, Wenyi and Zheng, Wendi and Zhou, Chang and Yin, Da and Lin, Junyang and Zou, Xu and Shao, Zhou and Yang, Hongxia and others},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021}
}
@inproceedings{vqvae,
  author    = {A{\"{a}}ron van den Oord and
               Oriol Vinyals and
               Koray Kavukcuoglu},
  title     = {Neural Discrete Representation Learning},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {6306--6315},
  year      = {2017}
}
@inproceedings{vqvae2,
  author    = {Ali Razavi and
               A{\"{a}}ron van den Oord and
               Oriol Vinyals},
  title     = {Generating Diverse High-Fidelity Images with {VQ-VAE-2}},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {14837--14847},
  year      = {2019}
}
@article{globallocal,
  title={Contrastive Learning of Global and Local Video Representations},
  author={Ma, Shuang and Zeng, Zhaoyang and McDuff, Daniel and Song, Yale},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}
@inproceedings{fastspeech,
  author    = {Yi Ren and
               Yangjun Ruan and
               Xu Tan and
               Tao Qin and
               Sheng Zhao and
               Zhou Zhao and
               Tie{-}Yan Liu},
  title     = {FastSpeech: Fast, Robust and Controllable Text to Speech},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {3165--3174},
  year      = {2019},
}
@inproceedings{audeo,
  author    = {Kun Su and
               Xiulong Liu and
               Eli Shlizerman},
  title     = {Audeo: Audio Generation for a Silent Performance Video},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020},
}
% ICML      {Proceedings of the International Conference on Machine Learning
@inproceedings{dalle,
  author    = {Aditya Ramesh and
               Mikhail Pavlov and
               Gabriel Goh and
               Scott Gray and
               Chelsea Voss and
               Alec Radford and
               Mark Chen and
               Ilya Sutskever},
  title     = {Zero-Shot Text-to-Image Generation},
  booktitle = {Proceedings of the International Conference on Machine Learning},
  pages     = {8821--8831},
  year      = {2021}
}
@inproceedings{clip,
  author    = {Alec Radford and
               Jong Wook Kim and
               Chris Hallacy and
               Aditya Ramesh and
               Gabriel Goh and
               Sandhini Agarwal and
               Girish Sastry and
               Amanda Askell and
               Pamela Mishkin and
               Jack Clark and
               Gretchen Krueger and
               Ilya Sutskever},
  title     = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle = {Proceedings of the International Conference on Machine Learning},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {8748--8763},
  year      = {2021},
}

% CVPR
@inproceedings{vis,
  title={Visually indicated sounds},
  author={Owens, Andrew and Isola, Phillip and McDermott, Josh and Torralba, Antonio and Adelson, Edward H and Freeman, William T},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2405--2413},
  year={2016}
}
@inproceedings{owens2016visually,
  title={Visually indicated sounds},
  author={Owens, Andrew and Isola, Phillip and McDermott, Josh and Torralba, Antonio and Adelson, Edward H and Freeman, William T},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2405--2413},
  year={2016}
}
@inproceedings{resnet,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  booktitle = {Proceedings of the International Conference on Machine Learning},
  pages     = {770--778},
  year      = {2016},
}
@inproceedings{taming,
  author    = {Patrick Esser and
               Robin Rombach and
               Bj{\"{o}}rn Ommer},
  title     = {Taming Transformers for High-Resolution Image Synthesis},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition},
  pages     = {12873--12883},
  year      = {2021}
}
@inproceedings{3dresnet50,
  author={Kensho Hara and Hirokatsu Kataoka and Yutaka Satoh},
  title={Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?},
  booktitle={{IEEE} Conference on Computer Vision and Pattern Recognition},
  pages={6546--6555},
  year={2018},
}
@inproceedings{mocogan,
  author    = {Sergey Tulyakov and
               Ming{-}Yu Liu and
               Xiaodong Yang and
               Jan Kautz},
  title     = {MoCoGAN: Decomposing Motion and Content for Video Generation},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition},
  pages     = {1526--1535},
  year      = {2018}
}
@inproceedings{imagenet,
  author    = {Jia Deng and
               Wei Dong and
               Richard Socher and
               Li{-}Jia Li and
               Kai Li and
               Li Fei{-}Fei},
  title     = {ImageNet: {A} large-scale hierarchical image database},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition},
  pages     = {248--255},
  year      = {2009},
}

% ICLR      International Conference on Learning Representations
@inproceedings{mocogan-hd,
  author    = {Yu Tian and
               Jian Ren and
               Menglei Chai and
               Kyle Olszewski and
               Xi Peng and
               Dimitris N. Metaxas and
               Sergey Tulyakov},
  title     = {A Good Image Generator Is What You Need for High-Resolution Video
               Synthesis},
  booktitle = {International Conference on Learning Representations},
  year      = {2021},
}
@inproceedings{sgdr,
  author    = {Ilya Loshchilov and
               Frank Hutter},
  title     = {{SGDR:} Stochastic Gradient Descent with Warm Restarts},
  booktitle = {International Conference on Learning Representations},
  year      = {2017},
}
@inproceedings{adam,
    author  = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {International Conference on Learning Representations},
  year      = {2015}
}
@inproceedings{vgg,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  booktitle = {International Conference on Learning Representations},
  year      = {2015},
}
% IJCAI
@inproceedings{tfgan,
  author    = {Yogesh Balaji and
               Martin Renqiang Min and
               Bing Bai and
               Rama Chellappa and
               Hans Peter Graf},
  title     = {Conditional {GAN} with Discriminative Filter Generation for Text-to-Video
               Synthesis},
  booktitle = {Proceedings of the International Joint Conference on Artificial Intelligence},
  pages     = {1995--2001},
  year      = {2019},
}

% AAAI
@inproceedings{t2v,
  author    = {Yitong Li and
               Martin Renqiang Min and
               Dinghan Shen and
               David E. Carlson and
               Lawrence Carin},
  title     = {Video Generation From Text},
  booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence},
  pages     = {7065--7072},
  year      = {2018},
}

% mm
@inproceedings{cmt,
  author    = {Shangzhe Di and
               Zeren Jiang and
               Si Liu and
               Zhaokai Wang and
               Leyan Zhu and
               Zexin He and
               Hongming Liu and
               Shuicheng Yan},
  title     = {Video Background Music Generation with Controllable Music Transformer},
  booktitle = {{ACM} Multimedia Conference},
  pages     = {2037--2045},
  year      = {2021},
}

%iccv
@inproceedings{ddt,
  title={The sound of motions},
  author={Zhao, Hang and Gan, Chuang and Ma, Wei-Chiu and Torralba, Antonio},
  booktitle={International Conference on Computer Vision},
  pages={1735--1744},
  year={2019}
}
@inproceedings{webvid,
  author    = {Max Bain and
               Arsha Nagrani and
               G{\"{u}}l Varol and
               Andrew Zisserman},
  title     = {Frozen in Time: {A} Joint Video and Image Encoder for End-to-End Retrieval},
  booktitle = {International Conference on Computer Vision},
  pages     = {1708--1718},
  year      = {2021},
}
@inproceedings{howto,
  author    = {Antoine Miech and
               Dimitri Zhukov and
               Jean{-}Baptiste Alayrac and
               Makarand Tapaswi and
               Ivan Laptev and
               Josef Sivic},
  title     = {HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million
               Narrated Video Clips},
  booktitle = {International Conference on Computer Vision},
  pages     = {2630--2640},
  year      = {2019},
}
@inproceedings{tgan,
  author    = {Masaki Saito and
               Eiichi Matsumoto and
               Shunta Saito},
  title     = {Temporal Generative Adversarial Nets with Singular Value Clipping},
  booktitle = {IEEE International Conference on Computer Vision},
  pages     = {2849--2858},
  year      = {2017},
}

% bmcv
@InProceedings{specvqgan,
  title={Taming Visually Guided Sound Generation},
  author={Iashin, Vladimir and Rahtu, Esa},
  booktitle={British Machine Vision Conference},
  year={2021}
}

@inproceedings{lvt,
  author    = {Ruslan Rakhimov and
               Denis Volkhonskiy and
               Alexey Artemov and
               Denis Zorin and
               Evgeny Burnaev},
  title     = {Latent Video Transformer},
  booktitle = {Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
  pages     = {101--112},
  year      = {2021},
}

@inproceedings{bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies},
  pages     = {4171--4186},
  year      = {2019},
}

@article{gpt,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}
% Interspeech
@inproceedings{,
  author    = {Adam Polyak and
               Yossi Adi and
               Jade Copet and
               Eugene Kharitonov and
               Kushal Lakhotia and
               Wei{-}Ning Hsu and
               Abdelrahman Mohamed and
               Emmanuel Dupoux},
  title     = {Speech Resynthesis from Discrete Disentangled Self-Supervised Representations},
  booktitle = {Annual Conference of the International Speech
               Communication Association},
  pages     = {3615--3619},
  year      = {2021},
}

@inproceedings{audioset,
  author    = {Jort F. Gemmeke and
               Daniel P. W. Ellis and
               Dylan Freedman and
               Aren Jansen and
               Wade Lawrence and
               R. Channing Moore and
               Manoj Plakal and
               Marvin Ritter},
  title     = {Audio Set: An ontology and human-labeled dataset for audio events},
  booktitle = {International Conference on Acoustics, Speech and Signal Processing},
  pages     = {776--780},
  year      = {2017},
}
@inproceedings{vggsound,
  author    = {Honglie Chen and
               Weidi Xie and
               Andrea Vedaldi and
               Andrew Zisserman},
  title     = {Vggsound: {A} Large-Scale Audio-Visual Dataset},
  booktitle = {International Conference on Acoustics, Speech and Signal
               Processing},
  pages     = {721--725},
  year      = {2020}
}
@article{vas,
  author    = {Peihao Chen and
               Yang Zhang and
               Mingkui Tan and
               Hongdong Xiao and
               Deng Huang and
               Chuang Gan},
  title     = {Generating Visually Aligned Sound From Videos},
  journal   = {{IEEE} Trans. Image Process.},
  volume    = {29},
  pages     = {8292--8302},
  year      = {2020},
}
@article{tsne,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}
@article{groupnorm,
  author    = {Yuxin Wu and
               Kaiming He},
  title     = {Group Normalization},
  journal   = {Int. J. Comput. Vis.},
  volume    = {128},
  number    = {3},
  pages     = {742--755},
  year      = {2020},
}
@article{li2018deep,
  title={Deep collaborative embedding for social image understanding},
  author={Li, Zechao and Tang, Jinhui and Mei, Tao},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={9},
  pages={2070--2083},
  year={2018},
}
@article{li2016weakly,
  title={Weakly supervised deep matrix factorization for social image understanding},
  author={Li, Zechao and Tang, Jinhui},
  journal={IEEE Transactions on Image Processing},
  volume={26},
  number={1},
  pages={276--288},
  year={2016},
}
@article{li2020weakly,
  title={Weakly-supervised semantic guided hashing for social image retrieval},
  author={Li, Zechao and Tang, Jinhui and Zhang, Liyan and Yang, Jian},
  journal={International Journal of Computer Vision},
  volume={128},
  pages={2265--2278},
  year={2020},
}
@article{li2021ctnet,
  title={CTNet: Context-based tandem network for semantic segmentation},
  author={Li, Zechao and Sun, Yanpeng and Zhang, Liyan and Tang, Jinhui},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={12},
  pages={9904--9917},
  year={2021},
}
@inproceedings{foley,
  title={Foley music: Learning to generate music from videos},
  author={Gan, Chuang and Huang, Deng and Chen, Peihao and Tenenbaum, Joshua B and Torralba, Antonio},
  booktitle={European Conference on Computer Vision},
  pages={758--775},
  year={2020},
}
@inproceedings{zhao2018sound,
  title={The sound of pixels},
  author={Zhao, Hang and Gan, Chuang and Rouditchenko, Andrew and Vondrick, Carl and McDermott, Josh and Torralba, Antonio},
  booktitle={European Conference on Computer Vision},
  pages={570--586},
  year={2018}
}
@article{cnn,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Communications of the ACM},
  volume={60},
  number={6},
  pages={84--90},
  year={2017},
}
@article{lstm,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
}