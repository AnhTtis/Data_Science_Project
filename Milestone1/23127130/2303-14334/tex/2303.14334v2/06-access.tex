
\section{Dynamic Documents for Improved Accessibility}
\label{sec:accessibility}



A range of disabilities cause people to read scientific documents using a wide variety of devices and reading tools.
For example, blind and low vision readers may use assistive reading technology such as screen readers, screen magnification, or text-to-speech to read documents~\cite{Szpiro2016HowPW}.
Furthermore, people without disabilities face situational impairments, such as the inability to view a screen while driving or may have a preference for consuming content on a small, mobile device. 

Many of these reading tools, such as screen readers, do not function properly on document formats designed for print such as PDF unless the document has been manually post-processed  to add information about reading order, content type, etc., which is rarely performed on scientific documents~\cite{bigham-uninteresting-tour,wang-2021-accessibility}. 
Further, certain content elements such as figures require the addition of alternative text in order to be read aloud at all (figure captions typically assume the reader can see the figure and do not provide the same semantic content as alt text).
High magnification reduces the viewport (the amount of visible content) and can dramatically increase the amount of scrolling and panning required, especially for multi-columnar formats that are commonly used by scientific documents. Visual scanning for information may be impacted or unavailable in these settings, making it more difficult to find and navigate between content in the document~\cite{park-cscw22}.


One way to render legacy PDF content more accessibly is to parse and convert it into a more flexible format, such as XML or HTML, which can then be formatted for mobile devices and augmented for reading by screen readers. The SciA11y system\footnote{A demo of a subsequent version is available at \url{https://papertohtml.org/}}
demonstrates this approach, automatically converting 12M academic PDFs to HTML~\cite{wang-2021-scia11y}; a user study with blind and low vision participants demonstrated strong user appreciation of the output, though some errors remain (e.g., failing in certain cases to distinguish footnotes from body text, difficulty parsing math equations)~\cite{wang-2021-accessibility}.
When available, alt text can be automatically categorized into semantic content types, enabling new reading experiences that allow skipping or prioritizing certain types~\cite{chintalapati-alt-text}.
Other approaches provide complementary benefits, such as interfaces tailored for low-vision readers (\S~\ref{sec:ocean}), as well as the range of reading support systems outlined above.


















