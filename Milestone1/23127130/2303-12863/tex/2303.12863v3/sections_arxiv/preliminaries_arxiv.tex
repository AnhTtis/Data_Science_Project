\section{Preliminaries}
\label{sec:preliminaries}
% \subsection{Acronyms/Initialisms}
\input{sections/acronym}

\subsection{Notation}

The $n$-dimensional real Euclidean vector space is $\R^n$. The set of natural numbers is $\N$, and the set of $n$-dimensional multi-indices is $\N^n$. The degree of a multi-index $\alpha \in \N^n$ is $\abs{\alpha} = \sum_{i=1}^n \alpha_i$.
The set of polynomials with real coefficients in an indeterminate $x$ is $\R[x]$. Each polynomial $p(x) \in \R[x]$ has a unique representation in terms of a finite index set $\mathcal{J} \subset \N^n$ and coefficients $\{p_\alpha\}_{\alpha \in \mathcal{J}}$ with $p_\alpha \neq 0$ as $p(x) = \sum_{\alpha \in \mathcal{J}} p_\alpha \left(\prod_{i=1}^n x_i^{\alpha_{i}}\right) = \sum_{\alpha \in \mathcal{J}} p_\alpha x^\alpha$. The degree of a polynomial $\deg p(x)$ is equal to $\max_{\alpha \in \mathcal{J}} \abs{\alpha_j}$. The subset of polynomials with degree at most $d$ is $\R[x]_{\leq d} \subset \R[x]$.

\subsection{Analysis and Measure Theory}
Let $X$ be a topological space.
The set of continuous functions over a space $X$ is $C(X)$, and its subcone of nonnegative functions over $X$ is $C_+(X)$. The subset of once-differentiable functions over $X$ is $C^1(X) \subset C(X)$. A single-variable function $g(t)$ is \ac{PC}  over the domain $[a, b]$ if there exist $B \in \N \backslash \{0\}$ and a finite number of time-breaks $t_0 = a < t_1 < t_2 <  \cdots < t_{B} < b = t_{B+1}$ such that the function $g(t)$ is continuous in each interval $[t_k, t_{k+1})$ for $k = 0..B$.
The class of \ac{PC} functions from the time interval $[-\tau, 0]$ to $X$ is $PC([-\tau, 0], X)$.

The set of nonnegative Borel measures over $X$ is $\Mp{X}$. A pairing exists between functions $p \in C(X)$ and measures $\mu \in \Mp{X}$ by Lebesgue integration with $\inp{p}{\mu} = \int_X p(x) d \mu(x)$. 
This pairing is a duality pairing and defines an inner product 
% \MK{Milan: This is typically not called inner product, just duality pairing. When  you say inner product, a (pre)-Hilbert structure is typically assumed, which we don't have here.} 
between $C_+(X)$ and $\Mp{X}$ when $X$ is compact. The $\mu$-measure of a set $A \subseteq X$ may be defined in terms of $A$'s indicator function ($I_A(x)=1$ if $x \in A$ and $I_A(x)=0$ otherwise) as $\mu(A) = \inp{I_A(x)}{\mu(x)}$. The quantity $\mu(X)$ is called the mass of $\mu$, and $\mu$ is a probability distribution if $\mu(X) = 1$. The support of $\mu$ is the set of all points $x$ such that all open neighborhoods $N_x \ni x$ satisfy $\mu(N_x) > 0$. 
Two special measures are the Dirac delta and the Lebesgue measure. The Dirac delta $\delta_{x}$ with respect to a point $x \in X$ obeys the point-evaluation pairing $\inp{p}{\delta_{x}} = p(x)$ for all $p \in C(X)$. The Lebesgue (volume) distribution has the definition $\inp{p}{\lambda_X} = \int_X p(x) dx$. Further details about measure theory are available in \cite{tao2011introduction}.

Given spaces $X$ and $Y$, the projection $\pi^x: X \times Y \rightarrow X$ is the map $(x, y) \mapsto x$.
For measures $\mu \in \Mp{X}$ and $\nu \in \Mp{Y}$, the product measure $\mu \otimes \nu \in \Mp{X \times Y}$ is the unique measure satisfying $(\mu\otimes \nu)(A \times B) = \mu(A)\nu(B)$ for all subsets $A \subseteq X, \ B \subseteq Y$. For two measures $\mu, \xi \in \Mp{X}$, the measure $\mu$ dominates $\xi$ ($\xi \leq \mu$) if $\xi(A) \leq \mu(A), \ \forall A \subset X$. To every dominated measure $\xi \leq \mu$, there exists a slack measure $\hat{\xi} \in \Mp{X}$ such that 
$\xi + \hat{\xi} = \mu$.

% and observe that $\hat\mu$ is nonnegative since $\xi \le \mu$.
% \MK{Milan: The notation $\xi \ll \mu$ is typically used to denote that $\xi$ is absolutely continuous wrt $\mu$, which is not equivalent to what's written here.} 
% \victor{It seems that this notation is never used.}
% By the Jordan decomposition, there exists a slack measure $\hat{\mu} \in \Mp{X}$ such that $\mu = \hat{\mu} + \xi$. \MK{Milan: The previous statement does not need a Jordan decomposition. Simply define $\hat \mu = \mu - \xi$ and observe that $\hat\mu$ is nonnegative since $\xi \le \mu$. }



The pushforward of a map $Q: X \rightarrow Y$ along a measure $\mu$ is $Q_\# \mu$, with the relation $\inp{z}{Q_\# \mu} = \inp{z \circ Q }{\mu}$ holding for all $z \in C(Y)$. Given $\eta \in \Mp{X \times Y}$, the projection-pushforward $\pi^x_\# \eta$ is the $x$-marginalization of $\eta$. The pairing of $p \in C(X)$ with $\pi^x_\#\eta$ may be equivalently expressed as $\inp{p}{\pi^x_\#\eta} = \inp{p}{\eta}$.
The adjoint of a linear map $\Lie: C(X)\rightarrow C(Y)$ is a mapping $\Lie^\dagger:M(Y)\to M(X)$ satisfying $\inp{\Lie p}{\nu} = \inp{p}{\Lie^\dagger \nu}$ for all $p \in C(X)$ and $\nu \in M(Y)$.

% \urg{Topics in Measures
% \begin{itemize}
%     \item Nonnegative Measure
%     \item Pushforwards and Marginalization
%     \item Absolute Continuity
% \end{itemize}}

\subsection{Time Delay Systems}



A single-variable function $g(t)$ is \ac{PC}  over the domain $[a, b]$ if there exist $B \in \N \backslash \{0\}$ and a finite number of time-breaks $t_0 = a < t_1 < t_2 <  \cdots < t_{B} < b = t_{B+1}$ such that the function $g(t)$ is continuous in each interval $[t_k, t_{k+1})$ for $k = 0..B$.
The class of \ac{PC} functions from the time interval $[-\tau, 0]$ to $X$ is $PC([-\tau, 0], X)$.


% \MK{Milan: Do we need PC in the next statement instead of Borel measurable?} 
Given a \ac{PC} state history $t \mapsto x_h(t), \ t \in [-\tau, 0]$,  a unique forward trajectory $x(t \mid x_h)$ of \eqref{eq:delay_dynamics} exists on  $t \in [0, T]$ if the function $(t,x_0,x_1) \mapsto f(t, x_0, x_1)$ is locally Lipschitz in all variables. 

% Such Lipschitz dynamics satisfy a smoothing property: the order of trajectory time-derivatives that are continuous will increase by 1 every $\tau$ time steps \cite{fridman2014intro}. 
% \MK{Milan: Any reference to the last statement?}


Trajectories of time-delay systems with the form of \eqref{eq:delay_dynamics} with $f$ locally Lipschitz satisfy a smoothing property as shown in Figure \ref{fig:increasing_continuity}. The order of derivatives that are continuous will increase by 1 every $\tau$ time steps \cite{fridman2014intro}. An example of such a time-delay system with increasing continuity  is visualized in Figure \ref{fig:increasing_continuity} with system dynamics
\begin{equation}
    x'(t) = -2x(t)-2x(t-1). \label{eq:time_delay_fig}
\end{equation} 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{fig/increasing_continuity.pdf}
    \caption{Continuity of \eqref{eq:time_delay_fig} trajectories increases every $\tau=1$ time step}
    \label{fig:increasing_continuity}
\end{figure}


Figure \ref{fig:same_initial} plots multiple trajectories of \eqref{eq:time_delay_fig} whose histories are lines passing through $x_h(0)=1$, but whose evolution after time $t = 0$ is different.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{fig/same_initial_point.pdf}
    \caption{All histories of Figure \eqref{eq:time_delay_fig} pass through $x_h(0)=1$}
    \label{fig:same_initial}
\end{figure}

The behavior of time-delay systems may change and bifurcate as the time delays change. A well-studied example of $\dot{x} = -x(t-\tau)$ 
is plotted in Figure 
\eqref{fig:stability_switch} \cite{fridman2014intro}, 
in which the system is stable (to $x=0$) for all bounded \ac{PC} histories with $\tau \in [0, \pi/2)$, has bounded oscillations for some initial histories at $\tau=\pi/2$ (e.g., constant $x_h$ in time), and is unstable (divergent oscillations to $\pm \infty$) for all similar histories with $\tau > \pi/2$ \cite{fridman2014intro}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{fig/stability_switch.pdf}
    \caption{Bifurcation of stability as $\tau$ exceeds $\pi/2$ in $\dot{x}=-x(t-\tau)$}
    \label{fig:stability_switch}
\end{figure}

Problem \eqref{eq:peak_delay_traj} involves a class of histories $\hs$. In this paper, we will impose that $\hs$ is graph-constrained:
\begin{defn}
\label{defn:graph_constrained}
    The history class $\hs$ is \textbf{graph-constrained} if $\hs$ is the set of histories whose graph lies within a given set $H_0 \subseteq [-\tau, 0] \times X$,
\begin{align*}
    \hs = \{x_h \in PC([-\tau, 0], X) \mid (t, x_h(t)) \in H_0 \ \forall t \in [-\tau, 0]\},
\end{align*} 
and there are no other continuity restrictions on histories.
\end{defn}

\subsection{Occupation Measures}

The \textbf{occupation measure} associated with an interval $[a, b]  \subset \R$ and a curve $t \mapsto x(t) \in PC([a, b], X)$ is the pushforward of the Lebesgue distribution (in time) $\lambda_{[a, b]}$ along the curve evaluation. 
Such an occupation measure $\mu_{x(\cdot)} \in \Mp{[a, b] \times X}$ satisfies a relation for all $v \in C([a, b] \times X):$
\begin{align}
    \inp{v}{\mu_{x(\cdot)}} & = \textstyle \int_{a}^b v(t, x(t)) dt.
\end{align}
% \MK{Milan: I would suggest the notation $\mu_{x(\cdot)}$ instead of $\mu_{(t, x(t))}$.}

% \MK{Milan: There is a jump in the thought process. You never speak about control and now it pops up out of the blue.} 

Occupation measures can be extended to controlled dynamics.
Let $U \subset \R^m$ be a set of input-values and define the following controlled dynamics (in which $u(t) \in U$ for all $t \in [0, T]$) :
\begin{align}
    \dot{x}(t) &= f(t, x(t), u(t)). \label{eq:dynamics_u}
\end{align}

The  occupation measure of a trajectory of \eqref{eq:dynamics_u} given a stopping time $t^*$, an initial condition $x_0 \in X_0 \subset X$ and a measurable  control $u(\cdot)$ (such that $u(t)$ is a probability distribution over $U$ for each $t \in [0, t^*]$) for sets $A \subseteq [0, T], \ B \subseteq X, \ C \subseteq U$, is
\begin{align}   
\label{eq:occ_free_single}
    &\mu(A \times B\times C \mid t^*, x_0) = \\
    &\int_{[0, t^*] \times X_0\times U} I_{A \times B \times C}\left((t, x(t \mid x_0,  u(\cdot)), u(t)\right) dt. \nonumber
\end{align}
% \MK{Milan: $\mathcal{U}$ is not properly defined. Also, why is $u$ in a feedback form in \eqref{eq:occ_free_single}? Normally it is required to depend only on time.}

The occupation measure in \eqref{eq:occ_free_single} may be averaged over a distribution of initial conditions  $\mu_0(x_0)$:
\begin{align}
    \label{eq:avg_free_occ}
    &\mu(A \times B\times C \mid t^*) = \\
    &\int_{X_0} \mu(A \times B\times C \mid t^*, x_0) d\mu_0(x_0). \nonumber
\end{align}

% is defined with respect to 
% $\tilde{v} \in C([0, T] \times X \times U):$
% \begin{align}
%  % \label{eq:avg_free_occ}
%     \inp{\tilde{v}}{\mu_{(t, x(t), u(t))}} & = \textstyle \int_{a}^b \tilde{v}(t, x(t), u(t)) dt.
% \end{align}

% A free-terminal-time averaged occupation measure posed over a stopping time $t^* \in [0, T]$, a control $u(\cdot) \in \mathcal{U}$, and a distribution of initial conditions $\mu_0$ is,



% \urg{Is this definition correct? There must be an easier way to phrase this, such as in Section 3.1 of \cite{henrion2013convex}.}

% \MK{Define the Lie derivative $\Lie$ of a function $v \in C^1([-\tau,T]\times \R^n)$  along~\eqref{eq:dynamics_u} by}
A linear operator $\Lie_f$ may be defined for every $v \in C^1([-\tau,T]\times \R^n)$ by
\begin{equation}
\label{eq:lie}
    \Lie_f v(t, x) = \partial_t v(t,x) + f(t,x, u) \cdot \nabla_x v(t,x).
\end{equation}
% \MK{Note that $\Lie_f$ is a linear operator}. \MK{Milan: I probably wouldn't call $\Lie_f$ a Lie derivative. }
A distribution of initial conditions $\mu_0 \in \Mp{X_0}$, free-terminal-time values $\mu_p \in \Mp{[0, T] \times X}$, and occupation measures $\mu \in \Mp{[0, T] \times X \times U}$ from \eqref{eq:avg_free_occ} are connected together by Liouville's equation for all $v \in C^1([0, T] \times X)$:
\begin{subequations}
\label{eq:liou}
\begin{align}
\inp{v}{\mu_p} &= \inp{v(0, x)}{\mu_0(x)} + \inp{\Lie_f v}{\mu} \label{eq:liou_int}\\
\mu_p &= \delta_0 \otimes \mu_0 + \pi^{t x}_\# \Lie_f^\dagger \mu. \label{eq:liou_weak}
\end{align}
\end{subequations}
Equation \eqref{eq:liou_weak} is a shorthand notation for \eqref{eq:liou_int} when applied to all $C^1$  functions $v$. Note that the $\pi^{t x}_\#$ marginalizes out the input $u$ in the occupation measure $\mu$. Any $\mu$ as part of a tuple of measures $(\mu_0, \mu_p, \mu)$ satisfying \eqref{eq:liou}
is referred to as a \textbf{relaxed occupation measure}.


% \Iac{ODE} peak estimation problem with adverse time-dependent uncertainty and variables $(t, x_0, u(\cdot))$
% \begin{subequations}
% \label{eq:peak_unc_traj}
%     \begin{align}
%     P^* = & \max_{t^* \in [0, T], \; x_0 \in X_0, \; u(\cdot)} p(x(t^* \mid x_0, u(\cdot))\\
%     & \dot{x} =  f(t, x(t), u(t)), \ u(t) \in U \qquad \forall t \in [0, T]    \\
%     &x(0) = X_0,
%     \end{align}
% \end{subequations}
% has an upper-bounding measure-\ac{LP} with variables $(\mu_0, \mu_p, \mu)$ yielding $p^* \geq P^*$ \cite{miller2021uncertain, lewis1980relaxation}
% \begin{subequations}
% \label{eq:peak_unc_meas}
%     \begin{align}
%         p^* = & \ \sup \quad \inp{p}{\mu_p} \label{eq:peak_meas_obj} \\
%     & \mu_p = \delta_0 \otimes\mu_0 + \pi^{tx}_\# \Lie_f^\dagger \mu \label{eq:peak_meas_flow}\\
%     & \inp{1}{\mu_0} = 1 \label{eq:peak_meas_prob}\\    
%     & \mu_0 \in \Mp{X_0} \label{eq:peak_meas_init} \\
%     & \mu_p \in \Mp{[0, T] \times X} \label{eq:peak_meas_peak} \\
%     & \mu \in \Mp{[0, T] \times X \times U}.\label{eq:peak_meas_occ}    
%     \end{align}
% \end{subequations}
% There is no gap $(P^* = p^*)$ when $[0, T] \times X \times U$ is compact, $p$ is continuous, and $f$ is Lipschitz in $[0, T] \times X \times U$.

 
% A Young Measure \cite{young1942generalized} is a family of probability distributions $\mu_t(u) \in \Mp{U}$ indexed by time. The Young Measure-applied dynamics of \eqref{eq:dynamics_u} is,
% \begin{align}
%     \dot{x}(t) &= \int_U f(t, x(t), u) d \mu_t(u) \label{eq:dynamics_u_young}
% \end{align}

% The conditional Young Measure $\mu_u(u \mid t, x) \in \Mp{U}$ probability distribution may be used to abstract a feedback law. An free-terminal-time averaged occupation measure $\mu$ posed over a stopping time $t^*$, a probability distribution of initial conditions $\mu_0 \in \Mp{X_0}$, and a Young measure $\mu_u(u \mid t, x)$ may be defined with respect to \eqref{eq:dynamics_u_young} and subsets $A \in [0, T], \ B \in X, \ C \in U$,

% \begin{equation}
%     \label{eq:avg_free_occ}
%     \mu(A \times B\times C) = \int_{[0, t^*] \times X_0} I_{A \times B \times C}\left((t, x(t \mid x_0,  u(\cdot)), 
% \end{equation}





% \subsection{Moment-SOS Hierarchy}