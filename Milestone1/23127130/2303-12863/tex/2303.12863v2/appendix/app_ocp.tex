\section{Subvalue Functionals and DDE Control}
\label{app:ocp}

This appendix analyzes \iac{DDE} \ac{OCP} when posed over a given history $x_h(\cdot)$. The function $J(t, x_0, x_1, u)$ is a running cost evaluated on the trajectory starting from $x_h$, and $J_T(x)$ is a terminal cost at time $T$. The final point $x(T)$ must reside in the terminal set $X_T \subseteq X$. The controller $u(\cdot)$ must reside inside the compact set $U \subset \R^m$ at each time. The  \ac{DDE} \ac{OCP} under these constraints is
\begin{subequations}
    \label{eq:u_traj}
    \begin{align}
    P^* = & \inf_{u(t)}  \int_{t=0}^T{J(t, x(t), x(t-\tau), u(t)) dt} + J_T(x(T))\\
    & \dot{x} =  f(t, x(t), x(t -\tau), u(t)) & & \forall t \in [0, T] \label{eq:dynamics_delay_u}\\
    & u(t) \in U& & \forall  t \in [0, T]  \\
    & x(t) = x_h(t) & & \forall t \in [-\tau, 0] \\
    & x(T) \in X_T.
    \end{align}
\end{subequations}

Problem \ref{eq:u_traj} was addressed in works such as \cite{warga1974optimal, rosenblueth1991relaxation, rosenblueth1992proper, rosenblueth1992strongly, plaksin2020minimax}, and was completely solved in the case of linear \ac{DDE} dynamics and a quadratic objective in \cite{santos2009linear, ortega2021comments}.

A pair of infinite-dimensional \acp{LP} are synthesized to bound the \ac{OCP} in \eqref{eq:u_traj}. 

This appendix assumes that the terminal time $T$ is fixed to simplify analysis.  
The \ac{MV}-solution from Section \ref{sec:peak_lp} involves a free terminal time, multiple histories, and zero running cost $(J=0)$.

\subsection{Control Measure Program}

The deterministic control law $u(t, x_0, x_1)$ at each time $t$ is relaxed into a probability distribution $\xi_u(u \mid t, x_0, x_1)$  \cite{young1942generalized}. 

The measures involved in \iac{MV}-solution of \eqref{eq:u_traj} are
\begin{subequations}
\label{eq:weak_solution_u}
    \begin{align}
       & \textrm{Initial} & \mu_0 &\in \Mp{X_0} \\
       &\textrm{Peak}  &\mu_p &\in \Mp{[0, T] \times X} \\
        &\textrm{Occupation Start }  & \bmu_0 &\in \Mp{[0, \kappa T] \times X^2 \times U} \label{eq:weak_solution_start_u}
         \\        
        &\textrm{Occupation End }  & \bmu_1 &\in \Mp{[\kappa T, T] \times X^2 \times U}. \label{eq:weak_solution_end_u}
    \end{align}
\end{subequations}

The time-slack measure is set to $\nu=0$ because of the fixed-terminal-time setting ($t^*=T$). The symbol $\mu_{x_h(\cdot)}$ is the occupation measure of $t \mapsto (t, x_h(t))$ between $t \in [-\tau, 0]$.
The history measure $\mu_h$ from \eqref{eq:weak_solution} is set equal to $\mu_{x_h(\cdot)}$ in the case of a single history. Similarly, the initial measure $\mu_0$ is set to the Dirac delta $\delta_{x=x_h(0^+)}$.

A measure relaxation to the optimal program in \eqref{eq:u_traj} is
\begin{subequations}
\label{eq:u_meas}
\begin{align}
p^* =  & \inf \quad \inp{J}{\bar{\mu}} + \inp{J_T}{\mu_T} \\
    & \delta_T \otimes \mu_T = \delta_{t=0, x=x_h(0^+)} + \pi^{t x_0}_\# \Lie_f^\dagger (\bmu_0 + \bmu_1)\\
    & \pi^{t x_1}_\# (\bmu_0 + \bmu_1) = S^\tau_\#( \mu_{x_h(\cdot)} + \pi^{t x_0}_\# \bmu_0)\\
    & \text{Measures from \eqref{eq:weak_solution_u}.}
\end{align}
\end{subequations}

This measure relaxation is based on the optimal control framework of \cite{lewis1980relaxation, henrion2008nonlinear}. Young measure formulations for \ac{DDE} \ac{OCP} have been developed in \cite{warga1974optimal, rosenblueth1991relaxation, rosenblueth1992proper, rosenblueth1992strongly, warga2014optimal}, but Liouville equations began use only in \cite{barati2012optimal}.

\subsection{Control Function Program}





Dual variables $v \in C^1([0, T] \times X)$ and $\phi \in C([0, T] \times X)$ may be introduced to form the dual program of \eqref{eq:u_meas}:
\begin{subequations}
\label{eq:u_cont}
\begin{align}
    d^* = & \ \sup \quad v(0, x_h(0)) +\textstyle \textstyle\int_{-\tau}^{0} \phi(t + \tau, x_h(t)) dt\label{eq:u_cont_obj}& \\
    &J_T(x) - v(T, x) \geq 0 \label{eq:u_cont_term} & & \forall x \in X_T \\
    & \Lie_f v + J(t, x_0, u) -  \phi(t, x_1)  +  \phi(t+\tau, x_0) \geq 0 \label{eq:u_cont_f} & & \forall (t, x_0, x_1 ,u) \in [0, T-\tau] \times X^2 \times U\\
    & \Lie_f v + J(t, x_0, u) -  \phi(t, x_1) \geq 0 \label{eq:u_cont_f_end} & &  \forall (t, x_0, x_1 ,u) \in [T-\tau, T] \times X^2 \times U\\
    &v \in C^1([0, T] \times X) & \label{eq:u_cont_v} \\
    &\phi \in C([0, T] \times X)  \label{eq:u_cont_phi}.
\end{align}
\end{subequations}

This dual program is obtained (with strong duality) by following nearly identical steps to Appendix \ref{app:strong_duality_delay}.


\subsection{True Value Functional}
\label{sec:value_functional}

Let $\mathcal{U}$ be the admissible class of control inputs (such as $\mathcal{U} = \{u : [0, T] \rightarrow U\}$).
Given a time $t \in [0, T]$, a current state $z \in X$, and a history $w(\cdot) \in PC([-\tau, 0], X)$, the value functional $V^*$ associated with the \ac{OCP} \eqref{eq:u_traj} is

\begin{align}
    V^*(t, z, w(\cdot)) = & \min_{u \in \mathcal{U}} \int_{t'=t}^T{J(t', x(t' \mid t, w, u), u(t')) dt'} + J_T(x(T \mid t,  w, u)) \nonumber\\
    & \dot{x} =  f(t, x(t), x(t - \tau), u(t)) & & \forall t \in [0, T] \nonumber\\
    & x(t') = w(t') & & \forall t \in [t-\tau, t) \nonumber\\
    & x(t) = z \\
        & x(T) \in X_T \nonumber \\
    & u(t) \in U& & \forall  t \in [0, T]. \nonumber
\end{align}

The value functional $V^*$ is the cost of solving Problem \eqref{eq:u_traj} starting at time $t$ and state $z$ with history $w(\cdot)$. The convention of arguments $t, z, w(\cdot)$ was taken from \cite{plaksin2020minimax}.

The \ac{HJB} equation of optimality is \cite{liberzon2011calculus}
\begin{subequations}
\label{eq:hjb}
\begin{align}
    0 &= J_T(x(T)) - V^*(T, x(T)) \label{eq:hjb_term_true}\\
    0 &= \inf_{u \in U} \left(\dot{V}^*(t, x(t), x_{\tau}(\cdot), u) + J(t, x(t), u(t)) \right) & \forall t \in [0, T].  \label{eq:hjb_traj_true}
\end{align}
\end{subequations}

The Cauchy problem of (7, 8) in \cite{plaksin2020minimax} has the form of \eqref{eq:hjb}.

\subsection{Subvalue Functional}

The solution of program \eqref{eq:u_cont} can create a lower-bound on the value functional $V^*$.

\subsubsection{Properties of Subvalue Functionals}

\begin{defn}
\label{def:subvalue}
A \textit{subvalue functional} is a functional $\mathcal{V}(t, x, w)$ such that
\begin{align}
   \mathcal{V}(t, x, w) &\leq V^*(t, x, w)  & & \forall t \in [0, T], x \in X, \ w \in PC([-\tau, 0], X).
\end{align}
\end{defn}

\begin{thm}
    Any functional $\mathcal{V}(t, x, x_\tau)$ with derivative $\dot{\mathcal{V}}(t, x, x_\tau, u)$ that satisfies the following two properties is a subvalue functional for $V^*$:
    \begin{subequations}        
    \begin{align}
        &J_T(x) - \mathcal{V}(T, x, w) \geq 0 & & \forall x \in X_T, \ w \in PC([-\tau, 0], X) \label{eq:hjb_term}\\
        &J(t, x, u) + \dot{\mathcal{V}}(t, x, w, u) \geq 0, & & \forall t \in T, \ x \in X, \ w \in PC([-\tau, 0], X), \ u \in U. \label{eq:hjb_lie}
    \end{align}
    \end{subequations}
\end{thm}

\begin{proof}
This result follows by following the steps of Proposition 1's proof from \cite{jones2021polynomial}.

Let $\tilde{u} \in \mathcal{U}$ be an arbitrary control policy starting at the initial condition $(t_0, z, w)$, resulting in a trajectory $\tilde{x}(t)$. Denote $\tilde{x}_\tau(\cdot)$ as the history function $\tilde{x}_t(t') = \tilde{x}(t + t') \ \forall t' \in [-\tau, 0]$. 


Relation \eqref{eq:hjb_lie} ensures that for all $t \in [t_0, T]$,
\begin{equation}
    \dot{\mathcal{V}}(t, \tilde{x}(t), \tilde{x}_t(\cdot), \tilde{u}(t)) + J(t, \tilde{x}(t), \tilde{u}(t)) \geq 0.
\end{equation}
Integrating the above term with respect to $t$ yields
\begin{subequations}
\begin{align}
    0 &\leq \int_{t=t_0}^T \dot{\mathcal{V}}(t, \tilde{x}(t), \tilde{x}_t(\cdot), \tilde{u}(t)) + J(t, \tilde{x}(t), \tilde{u}(t))dt \\
    0&\leq \underbracket{\mathcal{V}(T, \tilde{x}(T), \tilde{x}_T(\cdot))}_{V(T)}- \underbracket{\mathcal{V}(t_0, \tilde{x}(t_0), \tilde{x}_{t_0}(\cdot))}_{\mathcal{V}(t_0)} +  \int_{t=t_0}^T
    J(t, \tilde{x}(t), \tilde{u}(t))dt \\
    \mathcal{V}(t_0) &\leq \mathcal{V}(T) + \int_{t=t_0}^T
    J(t, \tilde{x}(t), \tilde{u}(t))dt \label{eq:subvalue_vt1}\\
    \mathcal{V}(t_0) &\leq J_T(\tilde{x}(T)) + \int_{t=t_0}^T
    J(t, \tilde{x}(t), \tilde{u}(t))dt. \label{eq:subvalue_jt1}
\end{align}
\end{subequations}

The transformation of \eqref{eq:subvalue_vt1} to  \eqref{eq:subvalue_jt1} follows from relations \eqref{eq:value_term} and \eqref{eq:u_cont_term} $(\mathcal{V}(T) \leq J(\tilde{x}(T))$. When $\tilde{u}$ is a minimizing control  $u^*$ (if it exists), then the right-hand side of \eqref{eq:subvalue_jt1} is the optimal value functional $V^*(t_0, z, w(\cdot))$ and the left-hand side is $\mathcal{V}(t_0, z, w(\cdot))$. The proof that $\mathcal{V}$ is a lower bound on $V^*$ is therefore complete, given that $\mathcal{V}(t_0, z, w(\cdot)) \leq V^*(t_0, z, w(\cdot))$ will hold for all choices of $(t_0, z, w(\cdot))$.
\end{proof}



% \subsection{Recovered Subvalue Functional}
% A value functional may be formed in accordance with the relaxed optimal control program \eqref{eq:u_cont},

\subsubsection{Recovery of a Subvalue Functional}
The dual solution $(v, \phi)$ from \eqref{eq:u_cont} may be assembled into a functional,
\begin{equation}
\label{eq:subvalue}
    V(t, x, z(\cdot)) = v(t, x) + \int_{t}^{\min(t+\tau, T)} \phi(s, z(s-\tau)) ds.
\end{equation}
 
 
The bias term $\phi$ in \eqref{eq:u_cont_phi} is defined and is $C^0$ continuous only between times $t \in [0, T]$. If the hard integration limit at $T$ was not present, then $\phi$ would be queried at undefined values $t \in (T, T + \tau]$. 
The terminal value of the value functional is
\begin{equation}
    V(T) = V(t, x(T), x([T-\tau, T])) = v(T, x(T)) + \int_{T}^{T} \phi_i(s, x(s-\tau))ds = v(T, x(T)). \\ \label{eq:value_term}
\end{equation}

The objective in \eqref{eq:u_cont_obj} is the evaluation of the value functional at time $t=0$ along the optimal controlled trajectory $x^*(t)$:
\begin{equation}
    V(0) = V(0, x_h(0), x_h) = v(0, x_h(0)) + \int_{0}^{\tau} \phi_i(s, x_h(s-\tau))ds. \label{eq:value_init}
\end{equation}



The time-derivative (co-invariant derivative) of the value functional $\dot{V}$ is
\begin{align}
\label{eq:v_dot}
    \dot{V}(t, z, w(\cdot), u) &= \Lie_f v(t, x(t)) + I_{[0, T-\tau]}(t) \phi(t+\tau, z) -\phi(t, w(- \tau)).
\end{align}

\begin{thm}
    The functional \eqref{eq:subvalue} is a subvalue functional in the sense of \eqref{def:subvalue}.
\end{thm}
\begin{proof}
    The terminal constraint \eqref{eq:u_cont_term} satisfies \eqref{eq:hjb_term} given the terminal value evaluation in \eqref{eq:value_term}. The combination of \eqref{eq:u_cont_f} and \eqref{eq:u_cont_f_end} together satisfy \eqref{eq:hjb_lie} under the derivative value expression in \eqref{eq:v_dot}.
\end{proof}

% \urg{A more complete expression would involve coinvariant derivatives with respect to $(t, w)$ in the $\phi$ expressions, see \cite{plaksin2020minimax} for more details. 

% The coinvariant derivative of $V$ is,
% \begin{align}
% \label{eq:coinvariant}
%     \partial_{t,w}^{ci} \phi(t, z, w(\cdot)) = q(t, z) - q(t - \tau, w(-\tau)).
% \end{align}

% Note that the argument of the first term in \eqref{eq:coinvariant} is $z$ rather than $w(0)$.


% I believe that the  \eqref{eq:v_dot} should remain accurate.
% }

\subsubsection{Continuity of the Recovered Value Functional}
\label{sec:continuity_subvalue}
Let $u^*(t) \in \mathcal{U}$ be the optimal (infimizing) trajectory of problem \eqref{eq:u_traj} given $z, w(\cdot)$, inducing a controlled trajectory $x^*(t) = x(t \mid z, w(\cdot))$.
The value functional evaluated along the optimal trajectory $V^*(t) = V(t, x^*(t), x^*([t-\tau, t])$ is $C^0$-continuous in $t$, but is not necessarily $C^1$-continuous in $t$. At the time $t=T-\tau$, define the value functional evaluations
\begin{align}
    V_-^* &= \lim_{t \rightarrow (T - \tau)^-} V^*(t) & V_+^* &= \lim_{t \rightarrow (T - \tau)^+} V^*(t).
\end{align}


The difference in these evaluations for every lag $i^*$ is
\begin{align}
   \Delta V^* = V_-^*-V_+^* &= \left(\int_{T - \tau^-}^{T^-} - \int_{T - \tau^+}^{T^+}\right) \phi(s, x(s-\tau_{i})) ds = 0.
\end{align}

The value functional $V^*(t)$ is therefore a member of $C^0([0, T])$ given that $v \in C^1([0, T] \times X)$ and $\phi \in C^0([0, T] \times X)$.

The value functional derivative evaluations are
\begin{align}
    \dot{V}_-^* &= \lim_{t \rightarrow (T - \tau)^-} \dot{V}^*(t) & \dot{V}_+^* &= \lim_{t \rightarrow (T - \tau_{i})^+} \dot{V}^*(t).
\end{align}

The difference in the derivative evaluations on both sides of $t=T-\tau$ is
\begin{align}
   \Delta \dot{V}^* = \dot{V}_-^*-\dot{V}_+^* &= \phi(T, x(T -\tau)).
\end{align}

It is not guaranteed that $\phi(T, x(T -\tau)) = 0$, so the value functional $V^*$ may have discontinuous first derivatives. The value functional is therefore $C^0$ in time along trajectories, and fails to be $C^1$ at the time $t=T-\tau$.

We form an additional conjecture to \ref{conj:delay} in the \ac{OCP} case based on the tightness conditions in \cite{lewis1980relaxation}.
\begin{conj}
Assume for the purposes of this conjecture that:
\begin{itemize}
    \item[A1'] The sets $\{[-\tau, T], X, X_T, U\}$ are all compact.
    \item[A2'] The costs $J, J_T$ are continuous.
    \item[A3'] The dynamics $f(t, x_0, x_1, u)$ are Lipschitz in their arguments.
    \item[A4'] The history $x_h$ is inside $PC([-\tau, 0], X)$.
    \item[A5'] The image of $f(t, x_0, X, U)$ is convex for each fixed $(t, x_0)$.
    \item[A6'] The mapping $v \mapsto \inf_{u \in U} J(t, x_0, x_1, u): f(t, x_0, x_1, u) = v$ is convex in $v \in \R^n$.
\end{itemize}
Then there is no relaxation gap between \eqref{eq:u_traj} and \eqref{eq:u_cont} ($P^*=p^*$).
\end{conj}


\subsection{Approximate Recovery}
A control policy $u(t)$ may be extracted from the value functional $V$ through the trajectory condition \eqref{eq:hjb_traj_true} by
\begin{subequations}
\begin{align}
    \label{eq:u_recovery}
    u(t) &= \argmin_u  \Lie_f v(t, x(t)) +  I_{[0, T-\tau]}(t) \phi(t+\tau, x(t))* - \phi(t, x(t - \tau)) + J(t, x(t), u(t))\\
    &=\argmin_u  f(t, x(t),  x(t - \tau), u) \cdot \nabla_{x} 
    v(t, x(t)) + J(t, x(t), u).
\end{align}
\end{subequations}

The work in \cite{jones2021polynomial} quantifies performance bounds of polynomial value function approximations for \ac{ODE} systems in terms of $W^1$ Sobolev norms away from the true value function. Quantifying performance bounds of the extracted controller of \eqref{eq:u_recovery} is an open problem.


% \urg{Quantify the performance of the approximate extracted controller, such as in \cite{jones2021polynomial}.}

% \section{Example of Optimal Control}

% \urg{Find examples of systems where the value functionals are analytically known. See if this scheme can match them.

% Will likely need to write a matlab package (YALMIP without Gloptipoly) to generate examples and outputs, unless I am doing it all by hand.}

% \section{Box Control}

% The task of finding an optimal control of systems with control-affine structure may be simplified if the set $U$ is a box, as explored by \cite{majumdar2014convex, korda2014controller}. In this setting the dynamics are,
% \begin{equation}
%     \label{eq:dynamics_u_aff}
%     x'(t) = f(t, x_0, x_1, \ldots, x_r) + \sum_{\ell=1}^m g_\ell(t, x, x_1, \ldots, x_r) u_\ell,
% \end{equation}
% The variables $x$ and $x_i$ are written as shorthand for $x(t \mid x_h)$ and $x(t - \tau \mid x_h)$ for each $i = 1, \ldots, r$ respectively. Dynamics in \eqref{eq:dynamics_u_aff} are `control-affine' because it is an affine combination of control terms $u_\ell$. If $U$ is a box, dynamics in \eqref{eq:dynamics_u_aff} can be scaled such that $U = [0, 1]^m$.

% A control occupation measure $\sigma_\ell \in \Mp{[0, T] \times X^{r+1}}$ may be defined for each input $u_\ell$ such that for each $A \in [0, T], \ B_i \in X, \ i = 0, \ldots, r$,
% \begin{equation}
%     \int_{A\times  \prod_{i=0}^r B_i} u_k(t) d \bar{\mu} = \int_{A \times \prod_{i=0}^r B_i} d \sigma_\ell
% \end{equation}

% Each control occupation measure $\sigma_\ell$ is absolutely continuous respect to the joint occupation measure $\bar{\mu}$. Refer to \ref{sec:abscont} for a primer of absolute continuity. The Liouville equation \eqref{eq:liou_meas_delay} with control occupation measures $\sigma_\ell$ is,
% \begin{align}
%     \delta_T \otimes \mu_T &= \delta_0 \otimes \mu_0 + \Lie_f^\dagger \bar{\mu} + \sum_{\ell=1}^m (g_\ell \cdot \nabla_x)^\dagger \sigma_\ell \label{eq:liou_meas_delay_aff}
% \end{align}

% \subsection{Box Measure Program}
% A measure program for control-affine time-delay optimal control given histories $\mu_{-i}$ is,
% \begin{subequations}
% \label{eq:box_u_meas}
% \begin{align}
% p^* = & \ \textrm{max} \quad -\inp{J(t, x, u)}{\bar{\mu}}-\inp{p(x)}{\mu_T} \label{eq:box_u_meas_obj} \\
%     & \delta_T \otimes \mu_T = \delta_0 \otimes \delta_{x=x_h(0)} + \pi^{t x_0}_\# \left(\Lie_f^\dagger \bar{\mu} + \textstyle \sum_{\ell=1}^m (g_\ell \cdot \nabla_x)^\dagger \sigma_\ell\right) \label{eq:box_u_meas_flow}\\
%      & \sigma_\ell + \hat{\sigma}_\ell = \bar{\mu} \label{eq:box_u_meas_abscont} \\
%     & \pi^{t x_i}_\# \bar{\mu} = (t + \tau, x)_\# \left( \textstyle\sum_{j=-i}^{r-i}\nu_j  \right) & & \forall i = 0, \ldots, r\label{eq:box_u_meas_delay} \\
%     & \mu_T \in \Mp{X} \label{eq:box_u_meas_peak}\\
%     & \bar{\mu} \in \Mp{[0, T] \times X^{r+1}} \label{eq:box_u_meas_occ} \\
%     & \sigma_\ell, \ \hat{\sigma}_\ell \in \Mp{[0, T] \times X^{r+1}} \qquad & & \forall \ell = 1, \ldots, m \label{eq:box_u_meas_occ_abscont} \\
%     &\nu_i \in \Mp{\Omega_i} & & \forall i = 0, \ldots, r
% \end{align}
% \end{subequations}


% Exploiting the control-affine structure reduces the maximal size of measures in \eqref{eq:box_u_meas} as compared to \eqref{eq:u_meas}. Approximate controllers $u_\ell$ may be recovered from a finite-degree LMI relaxation of \eqref{eq:box_u_meas}.
% Assume that $\M_{d}[\mathbf{y}]$ is the moment matrix with entries up to order $2d$ corresponding to $\bar{\mu}$, and $\mathbf{y}^\ell_{\leq d}$ is a sequence of moments up to order $d$ for the measure $\sigma_\ell$. Given an ordering of monomials $m_d(t, x, x_1, \ldots, x_r)$ up to order $d$ aligned with the moment sequence $\sigma_\ell$, the approximate extracted optimal controllers are,
% \begin{align}
%     u_\ell(t) &= m_d(t, x(t), x(t - \tau_1), \ldots, x(t - \tau_r))^T (\M_{d}[\mathbf{y}]^{-1}\mathbf{y}^\ell_{\leq d}) \label{eq:box_control_law}
% \end{align}
% The controllers extracted from \eqref{eq:box_control_law} are polynomial in terms of time $t$, the current state $x(t)$, and delayed states $x(t - \tau)$. These are approximate controllers that may not be strictly feasible solutions of SOS constraints.


% % \section{Dead Time}

% % A controlled system has `dead time' if there is a time delay between a control input and the effect of that input on system behavior. \urg{Get some references on why dead time is a critical issue when designing controllers.} 

% % For state delays $\tau$ and input delays $\tilde{\tau}_k$, dynamics are, 
% % \begin{equation}
% % \label{eq:dynamics_dead_time}
% %     x'(t) = f(t, \cup_{i=0}^r x(t - \tau), \cup_{i=k}^{\tilde{r}} u(t - \tilde{\tau}_k))
% % \end{equation}

% % Control with dead time requires an input history $u_h(t)$ for $t \in [-\tilde{\tau}_{\tilde{r}}, 0]$ as well as a  state history $x_h(t)$ over $t \in [-\tau_r, 0]$
% % The lags $\tau$ and $\tilde{\tau}_k$ do not necessarily need to match.

% % % Generated bounds may be tighter if the sequences $\{\tau\}$ and $\{\tilde{\tau}_k\}$ are the 

% % The joint occupation measure $\bar{\mu} \in \Mp{[0, T] \times X^{r+1} \times U^{\tilde{r} + 1}}$ now has additional copies of $U$ to handle the delayed control. Given subsets $A \in [0, T], \ B_i \in X \ \forall i,  \ C_k \in U \ \forall k$, the joint occupation has a value of,

% % \begin{equation}
% % \label{eq:occ_measure_delay_joint_single_u}
% %     \bar{\mu}\left(A \times \prod_{i=0}^r B_i \times  \prod_{k=0}^{\tilde{r}} C_k\mid x_h, u_h\right) = \int_{A} \left(\prod_{i=0}^r I(x(t - \tau \mid x_h) \in B_i)\right)\left(\prod_{k=0}^{\tilde{r}} I(u(t - \tilde{\tau}_k \mid u_h) \in C_i)\right) dt.
% % \end{equation}

% % An averaged joint occupation measure can be computed given a distribution of state controls and histories.

% % \subsection{Dead Time Only Example}
% % An example of a system with dead time is the following dynamics,
% % % \urg{Fill this in}
% % % Example:
% % \begin{equation}
% % \label{eq:dynamics_dead_time_1}
% %     x'(t) = f(t, x(t), u(t - \tilde{\tau}))
% % \end{equation}
% % There is only one input delay and there are zero state delays. An \ac{OCP} can be formulated with running cost $J$, terminal cost $p$, initial history $u_h$, and initial state $x_0$ using component measures $\omega_{-1}, \ \omega_{0}, \  \omega_{1}$. The history measure $\omega_{-1}$ satisfies,
% % \begin{align}
% %     \int_{[-\tilde{\tau}, 0]\times U} w(t, u) d \omega_{-1} = \int_{t= -\tilde{\tau}}^0 w(t, u_h(t))dt & & \forall w(t, u) \in C(-\tilde{\tau}, 0]\times U)
% % \end{align}
% % The measure relaxation of the \ac{OCP} is,
% % \begin{subequations}
% % \label{eq:u_dead_meas}
% % \begin{align}
% % p^* = & \ \textrm{max} \quad -\inp{J(t, x, u)}{\bar{\mu}}-\inp{p(x)}{\mu_T} \label{eq:u_dead_meas_obj} \\
% %     & \delta_T \otimes \mu_T = \delta_0 \otimes \delta_{x=x_0} + \pi^{t x}_\# \Lie_f^\dagger \bar{\mu} \label{eq:u_dead_meas_flow}\\
% %     & \pi^{t u_0}_\# \bar{\mu} = \omega_0 + \omega_1\\
% %     & \pi^{t u_1}_\# \bar{\mu} = S^{\tilde{\tau}}_\# \left(\textstyle \omega_{-1} + \omega_0 \right)  & & \label{eq:u_dead_meas_delay} \\
% %     & \mu_T \in \Mp{X} \label{eq:u_dead_meas_peak}\\
% %     & \bar{\mu} \in \Mp{[0, T] \times X \times U^2} \label{eq:u_dead_meas_occ} \\
% %     &\omega_0 \in \Mp{[0, T - \tilde{\tau}] \times U} & &  \\
% %     &\omega_1 \in \Mp{[T - \tilde{\tau}, T] \times U}
% % \end{align}
% % \end{subequations}

% % The measure $\omega_1$ has no effect on system dynamics due to dead time, and can be set arbitrarily to minimize the running cost $J(t, x(t), u(t))$. In the case of a quadratic such as cost $J = x^T Q x + u^T R u$ where $0 \in U$, the measure $\omega_1$ may be Lesbegue-distributed on the graph $(t, 0)$ for $t \in [T-\tilde{\tau}, 0]$.

% % \subsection{General Dead Time}
% % For a system with $r$ state lags and $\tilde{r}$ input lags, the joint occupation measure is $\bar{\mu} \in \Mp{[0, T] \times X^{r+1} \times  U^{\tilde{r} +1}}$. Component measures $\nu \in \Mp{I_t \times X \times U}$ for some interval $I_t \subseteq [-\min(\tau_r, \tilde{\tau}_{\tilde{r}}, T]$ may be defined to simultaneously shift the state and controls.
% % For the case where $\tau$ and $\tilde{\tau}$ are identical sequences, a measure relaxation to optimal control is,
% % \begin{subequations}
% % \begin{align}
% % p^* = & \ \textrm{max} \quad -\inp{J(t, x_0, u)}{\bar{\mu}}-\inp{p(x_0)}{\mu_T} \label{eq:u_dead_s_meas_obj} \\
% %     & \delta_T \otimes \mu_T = \delta_0 \otimes \delta_{x=x_h(0)} + \pi^{t x_0}_\# \Lie_f^\dagger \bar{\mu} \label{eq:u_dead_s_meas_flow}\\
% %     & \pi^{t x_i u_i}_\# \bar{\mu} = S^{\tau}_\# \left(\textstyle \sum_{j=-i}^{r-i} \nu_j \right)  & & \forall i = 0, \ldots, r\label{eq:u_dead_s_meas_delay} \\
% %     & \mu_T \in \Mp{X} \label{eq:u_dead_s_meas_peak}\\
% %     & \bar{\mu} \in \Mp{[0, T] \times X^{r+1} \times U^{r+1}} \label{eq:u_dead_s_meas_occ} \\
% %     &\nu_i \in \Mp{\Omega_i \times U} & & \forall i = 0, \ldots, r
% % \end{align}
% % \end{subequations}

% % The component measures $\nu_i$ have $(t, x, u)$ together in \eqref{eq:u_dead_s_meas_delay}, and the bound $p^*$ is likely to be stronger than if shifting was enforced for $(t, x)$ and $(t, u)$ individually. \urg{Is this sufficiently clear?}


% % \urg{Could dead time be merged with box control? Like if dynamics were
% % \begin{equation}
% %     x'(t) = \sum_{\ell=1}^m f_{\ell}(t, x(t)) u(t - \tilde{\tau} \mid u_h)_\ell ?
% % \end{equation}
% % Maybe this could reduce the size of the occupation measure. Would need to shift the control-occupation measures.
% % }




\subsection{Example of Optimal Control}
\label{sec:u_example}

An example of optimal control is presented on the one-dimensional linear system:
\begin{align}
x'(t) &= -3x(t) - 5x(t-0.25) + u & &\forall t \in [0, 1] \nonumber \\
x_h(t) &= -1 & & \forall t \in [-0.25, 0].
\end{align}
This system has one lag with $\tau = 0.25$ and a time horizon of $T = 1$. The state and control constraints are $X = [-1, 1]$ and $U = [-1, 1]$. With a control weight of $R = 0.01$, the penalties are
\begin{equation}
    J(t, x, u) = 0.5 x^2 + 0.5 R u^2 \qquad J_T(x) = 0.\end{equation}

The open loop total cost is $0.0674$. Table \ref{tab:linear_bounds} lists optimal control value approximations for this system.
\begin{table}[h]
    \centering
    \caption{\label{tab:linear_bounds}\ac{SDP} approximation bounds to program \eqref{eq:u_meas}}
    \begin{tabular}{c|c c c c c c}
        order&	1&	2	&3	&4	&5	&6  \\
        bound	&7.90E-05	&0.0322&	0.0386&	0.0391	&0.0393	&0.0393 
    \end{tabular}
\end{table}

The applied control $u(t)$ may be recovered through equation \eqref{eq:u_recovery} as

\begin{equation}
    u(t) = \text{Saturate}_{[-1,1]} \left( -\frac{1}{R}\partial_x v(t,x(t))  \right).
\end{equation}

The trajectories and nonnegative functions are plotted for order 4 in Figures \ref{fig:traj}-\ref{fig:aux_value}. The order 4 control bound is 0.0391, and the cost evaluated along the controlled trajectory is 0.0394. 
% \urg{The bounds in Gloptipoly and Yalmip are the same, and Gloptipoly runs much faster. The functions $(v, \phi)$ returned by Gloptipoly are invalid, and I don't yet know why. Constraint \eqref{eq:u_cont_flow} sometimes takes on negative or large positive values in the Gloptipoly solution, but the value function seems accurate. Figures \ref{fig:traj}-\ref{fig:nonneg} were generated in Yalmip. I will need to figure out the dual recovery bug in my Gloptipoly implementation, and will separately need write Yalmip code to generically solve time-delay \ac{OCP}s. I need to demonstrate on nonlinear systems with state and control constraints, which is particularly challenging for other methods (likely, also need to find out the literature and what is state-of-the-art).}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{fig/linear_traj.pdf}
    \caption{Open and closed loop trajectory with control}
    \label{fig:traj}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{fig/linear_aux_value.pdf}
    \caption{Auxiliary function $v$ and value functional $V$ from \eqref{eq:subvalue}}
    \label{fig:aux_value}
\end{figure}

