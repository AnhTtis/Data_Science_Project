\section{Related Work}
% %TODO

\noindent\textbf{Conventional Cryo-EM Reconstruction.}
Traditional cryo-EM reconstruction involves the creation of a low-resolution model~\cite{leschziner2006orthogonal, punjani2017cryosparc} followed by the iterative refinement of the initial model~\cite{scheres2012relion, 
 punjani2017cryosparc, hohn2007sparx}.
%
Standard approaches for addressing structural heterogeneity~\cite{scheres2010maximum, lyumkis2013likelihood} involve discretization of dynamics and are not able to continuously reconstruct the motion process.
%
Most algorithms perform reconstruction in the Fourier domain since it allows for efficient computation of the forward-projection and back-projection operations.
%
Some approaches are based on reconstruction in the spatial domain and using a flow field to model the structural motion~\cite{punjani20213d, chen2021deep}.
%
Our approach also conveys reconstruction in the spatial domain, while instead of utilizing a flow field to model, we propose a query-based transformer architecture to tackle conformational heterogeneity.

% The involvement of projection operations in spatial domain reconstruction can lead to computational expenses, and our method is no exception to this. This is particularly the case when dealing with neural representations, as accessing the entire volume can be necessary.


% \TODO{
% Cryo-EM reconstruction is typically accomplished in two stages: 
% %
% 1) generation of an initial low-resolution model followed by 2) iterative refinement of the initial model with a coordinate ascent procedure alternating between projection matching and
% refinement of the structure. 
% XXX: conventional methods such as RELION, CryoSPARC}

% xxx: other cryo-em/et papers in CV/ML top conference, try citing them somewhere.
% cryoposenet~\cite{cryoposenet}
% symmetry~\cite{cesasymmetries}
% xxx~\cite{nasiri2022unsupervised}
% xxx~\cite{Huang_2022_WACV}
% xxx~\cite{Yang_2021_ICCV}
% xxx~\cite{huang2022accurate}

\begin{figure*}[th]
\begin{center}
    \includegraphics[width=1\linewidth]{figures/method.pdf}
\end{center}
\caption{\textbf{Pipeline of \ours.}
%
\textbf{1)} An input image is fed into image encoders that output the orientation feature and the deformation feature.
%
\textbf{2)} 
Rotated coordinates are fed into our implicit neural spatial feature volume to produce a spatial feature.
\textbf{3)} 
The spatial feature and the deformation image feature interact in the deformation transformer decoder to output the density prediction. 
}
\label{fig:method}
\end{figure*}

\noindent\textbf{Neural Representations for Cryo-EM Reconstruction.}
Neural representations learn to encode a coordinate-to-value mapping for 3D shape modeling.
%
Instead of storing the discrete signal values in a grid, neural representations model discrete data as samples of a continuous manifold using multi-layer perceptions (MLP). They have notably contributed to novel view synthesis~\cite{mildenhall2020nerf, barron2021mip}, geometry~\cite{wang2021neus, oechsle2021unisurf,zhao2022human} and dynamic scene modeling~\cite{dnerf, zhang2021stnerf,park2021hypernerf}.

Efforts have been made to use neural representations for volume reconstruction in cryo-EM.
%
CryoDRGN~\cite{cryodrgn, zhongreconstructing} first proposed using a Multi-Layer Perceptron (MLP) with positional encoding to represent biological structures.
%
% Their neural representation takes 3D coordinates in the Fourier domain and a latent vector encoding the conformational state as input to estimate the density value.
%
This usage of neural representation allows for the continuous modeling of deformations, leading to excellent results in accounting for the molecule's continuous changes. 
%
Following this success, cryoDRGN-like architectures were utilized to develop reconstruction approaches without the need for pre-computed poses, also known as \textit{ab}-initio reconstruction~\cite{cryodrgn2, cryoai, cryofire}. 
%
Sparse Fourier Backpropagation~\cite{sfbp} proposed to express the cryoDRGN-like VAE reconstruction on a volumetric grid and lower computational cost.
%
ResMFN~\cite{ResMFN} proposes a  coordinate network architecture that enables coarse-to-fine optimization with fine-grained control over the frequency support of learned reconstructions to deal with cryo-EM reconstruction where coarse-to-fine estimation is required.
%
Different from previous work building neural representations in the Fourier domain for cryo-EM reconstruction, our approach directly reconstructs continuous conformations of 3D structures using an implicit feature volume in the 3D spatial domain to model local changes of conformations.





% Continuous dynamic
% ab-initial
% time-domain reconstruction
\noindent\textbf{Transformers.}
Transformers have become a ubiquitous learning architecture capable of capturing long-range dependencies in sequential data, and have demonstrated remarkable success across a range of applications, including natural language processing~\cite{vaswani2017attention, devlin2018bert, brown2020language}, computer vision~\cite{dosovitskiy2020image, liu2021swin}, and protein structure determination~\cite{jumper2021highly}.
%
Various downstream tasks in computer vision have adopted Transformer-based models, including image classification~\cite{dosovitskiy2020image}, object detection~\cite{carion2020end}, semantic/instance segmentation~\cite{chen2021pre, strudel2021segmenter, xie2021segformer, zheng2021rethinking}, video understanding~\cite{zhou2018end, arnab2021vivit, liu2022video, chen2022iquery}.
%
Transformers also benefit neural representations in training with sparse input views and generalization across scenes~\cite{wang2021ibrnet, reizenstein2021common, wang2022attention}.
%
In this work, we incorporate a transformer decoder where structure queries interact with the deformation and spatial features to predict the potential field.
