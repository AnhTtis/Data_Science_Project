\section{On the range of $p_n$-\Nametwo{}}\label{sec:rangeERW}

% In this section we prove Theorem~\ref{thm:SLLN}. 
% The proof is based on  two results which combined provide a Strong Law of Large Numbers (SLLN) for $\Rr^X_{n}$ when the dimension is either $d=2$ or $d\geq 22$. The first result is a tight upper bound that works in any dimension $d\geq3$. The second is a tight lower bound which only works (due to the proof technique employed) for $d\geq 22$. 
% Considering the representation in \eqref{xn-incremnto1} for $X$ a $p_n$-\Nametwo{} (see, Section~\ref{sec:p_n-ERW}), 
% Let us denote by $\pi_d$ the probability of a random walk with i.i.d. increments (with zero mean and finite variance) given by the corresponding $\{\xi_i\}_{i\geq 0}$ never returning to the origin. 
%
% \begin{proposition}\label{prop:RangeERW} 
% Let  $X$ be a $p_n$-\Nametwo{} in direction $\ell$ on $\ZZ^d$ with $d\geq 2$, $p_n= \mathcal{C} n^{-\beta} \wedge 1$ and $\beta \ge 1/2$. Then, it holds that
% \begin{align*}
%     \limsup_{n \to \infty} \frac{|\Rr_n^X|}{n} \le \pi_d \ \text{ a.s.}\,.
% \end{align*}
% \comu{Parece valer para $\beta \in (0,1)$}
% \end{proposition}

% %
% Note that for $d=2$, we have that $\pi_d=0$, whereas for $d\geq 3 $, $\pi_d\in (0,1]$.  %Below, we propose a conjecture about the range of the $p_n$-\Nametwo{} on $\ZZ^d$, in direction $\ell \in \mathbb{S}^{d-1}$,  with $p_n= \mathcal{C}n^{-\beta} \wedge 1$, with $\beta\geq 1/2$ and  $d \ge 2$.
% %
% \begin{proposition}\label{prop:RangeERW_lower} 
% Let  $X$ be a $p_n$-\Nametwo{} in direction $\ell$ on $\ZZ^d$ with $d\geq 22$, $p_n= \mathcal{C} n^{-\beta} \wedge 1$ and $\beta \ge 1/2$. Then, it holds that
% \begin{align*}
% \liminf_{n \to \infty} \frac{|\Rr_n^X|}{n} \ge \pi_d \ \text{ a.s.}\,.
% \end{align*}
% \end{proposition}

% \comu{voltei com o trecho abaixo. Vamos precisar dos grandes desvios para o range do passeio não excitado. Acho que o enunciado aqui ajuda. Também tem notação que estará sendo usada e parece bem introduzida aqui. Vamos ter que acertar o comentário sobre aperiodicidade.}

We begin by introducing some notation and recalling a well-known large deviation principle for the range of a random walk with i.i.d. increments.

Here $\{\xi_i\}_{i \ge 1}$ is a sequence of i.i.d. $\ZZ^d$-valued random variables with zero-mean vector and finite covariance matrix. Let $\{Y_n\}_{n \ge 0}$ be the random walk on $\ZZ^d$ with increments $\{\xi_i\}_{i \ge 1}$ starting at $Y_0 = 0$, thus $Y_n = \sum_{i=1}^{n} \xi_i$, $n\ge 1$.  For $m \leq n$ define 
\[ \Rr_{[m,n]} ^Y := \{Y_m, Y_{m+1}, \ldots, Y_n\}\;,\]
and denote by $\Rr^Y_{n} = \Rr^Y_{[0,n]}$,  the range of the random walk $\{Y_n\}_{n \geq 0}$. Recall 
% from the statement of Proposition~\ref{prop:RangeERW} 
that $\pi_d$ denotes the probability that $\{Y_n\}_{n \geq 0}$ never returns to the origin. 

\begin{theorem}[{\cite[Theorem 1]{hamana2001large}}]\label{teo: RnZ>}
Let $\{Y_n\}_{n \geq 0}$ be a genuinely  $d$-dimensional random walk on $\ZZ^d$, with $d\geq 2$. It holds that 
\begin{align*}
\tag{L}&\lim_{n \to \infty} \PP[|\Rr_{n}^Y| \geq \theta n]= 1\,, &&  \text{for every $\theta < \pi_d$}\,, 
\\
\tag{U}&\PP[|\Rr_{n}^Y| \geq \theta' n] \leq e^{-c_{\theta'}n}\,,    && \text{for every  $\theta' > \pi_d$ and $n$ sufficiently large}\,, 
\end{align*}
where $c_{\theta'}$ is a positive constant that depends of $\theta'$.
% (note that for $d=2$, we have that $\pi_d=0$, whereas for $d\geq 3 $, $\pi_d\in (0,1]$. 
\end{theorem}

\begin{remark}
 Note  that~\cite[Theorem 1]{hamana2001large} is stated for ``aperiodic''  random walks (see,  (\cite[Condition (1.9)]{hamana2001large}). % with a definition of aperiodicity which is distinct than the usual one related to the periodicity of markov chains (see \cite{yuval}). Following \cite{spitzer2001principles}, a random walk is aperiodic if (\comu{completar}).
However,  as explained in~\cite[page 188-Section 2]{hamana2001large} the  result also holds for any genuinely $d$-dimensional random walk. 
% can be extended to periodic random walks and the aperiodicity does not entail a loss of generality. \comu{é isso mesmo?}
\end{remark}


\subsection{Upper bound for the range (proof of  Proposition~\ref{prop:RangeERW})}

\hfill \\

The heuristic of the proof of Proposition~~\ref{prop:RangeERW} is the following: 
suppose that the $p_n$-\Nametwo{} at time $j$ visits a new site and gets excited. Then, after $k$ further steps it visits another new site and gets excited again and  no excitation occurs between time $j+1$ and $j+k-1$. Thus,  we know that between time $j+2$ and $j+k$ the process evolves as a random walk with i.i.d. increments. Specifically, in each of these time windows between two consecutive excitations, we can use the range of the random walk with i.i.d. increments to  upper bound the range of the $p_n$-\Nametwo{}.

%The main idea of this proof is we know that the $p_n$-\Nametwo{} behaves like random walk biased in direction $\ell$ \comu{"drift random walk" não é um bom termo} when it eats a cookie. Then between two cookies we have that the process behaves like an i.i.d. random walk. Hence in this lengths, we think as independent i.i.d. random walks \comu{"i.i.d. random walk" não é um bom termo, talvez "random walk with i.i.d. increments. Recorrente.} and use the ranges of those process to upper bound the range of the $p_n$-\Nametwo{}. By Lemma~\ref{RnY_upperb} we can control the range of each independent random walk, thus we obtain the desired result.  \comu{Só neste parágrafos há vários problemas de inglês}

\begin{proof}[Proof of Proposition~\ref{prop:RangeERW}]
%\textcolor{red}{Let us denote $(N_i, i \geq 0)$  as the sequence of times that the process $X$ is allowed to eat a cookie, this happens if the position is being visited for the first time and the Bernoulli trial in the site goes in favor of the process with a drift

%\texttt{The above paragraph is confusing: $N_i$ only looks at the Bernoulli variables regardless if the sites visited at the corresponding time has already been visited before or not!}}. %, that is, it behaves like process with a drift to the right. 
%\cm{Let us denote $\{N_i\}_{i \geq 0}$ as the sequence of times that the Bernoulli trial goes in favor of the $p_n$-\Nametwo{} behaves like a random walk biased in direction $\ell$.}


The proof for $\beta>1$ is straightforward, since from a simple Borel-Cantelli argument it follows that the number of excitations is finite almost surely. So let us proceed assuming $\beta \in (0,1]$.

Denote by $\{N_i\}_{i \geq 0}$ the sequence of stopping times 
\[ N_0 \equiv 0 \ \ \mathrm{and} \ \ N_i := \inf\{ k > N_{i-1}: Z_k = 1 \} \, , \ i\ge 1 \,, \]
where $Z_k = \um_{\{U_k \le k^{{-\beta}} \}}$, $k \geq 1$, are independent random variables with Bernoulli distribution of parameter $k^{{-\beta}}$, respectively.
%
Set $\Delta N_i = N_i - N_{i-1} $ and define 
\[ M_n := \inf \Big\{ i \geq 1 : \sum_{j=1}^i \Delta N_j \geq n \Big\} \,. \]

Note that $|\Rr_n ^X| - 1  = \sum_{t=1}^n \um_{\{X_t \neq X_l, \forall l < t \}}$ is bounded from above by 
\begin{align*}
 &  \sum_{t=1}^{N_1} \um_{\{X_t \neq X_l, \forall l < t \}} + \sum_{t=N_1 +1}^{N_2} \um_{\{X_t \neq X_l, \forall l < t \}} + \dots + \sum_{t=N_{M_n -1} +1}^{N_{M_n}} \um_{\{X_t \neq X_l, \forall l < t \}}
 \\
 & \leq M_n + \sum_{j = 1}^{M_n} \sum_{t = N_{j-1} + 2}^{N_j} \um_{\{X_t \neq X_l, \forall l < t \}} \\
 &\leq M_n + \sum_{j = 1}^{M_n} \sum_{t = N_{j-1} + 2}^{N_j} \um_{\{X_t \neq X_l, \forall l \in [N_{j-1} + 1, t) \}} \,.
\end{align*}
In each time interval $[N_{j-1} + 2, N_j]$ the process $X$ behaves like a random walk with i.i.d. increments. In order to have some control on the length of these intervals, or equivalently on $\{\Delta N_j\}_{j \geq 1}$, we proceed as follows: Let $\varepsilon \in (0, 1)$ and note that 
\begin{equation}\label{eq: Rn<}
|\Rr_n ^X| \leq |\Rr_{[0,n^{\varepsilon}]} ^X| + |\Rr_{[n^{\varepsilon}, n]} ^X| \leq n^{\varepsilon} + |\Rr_{[n^{\varepsilon}, n]} ^X|\; , 
\end{equation}
this last step will be necessary to guarantee that after time $n^\varepsilon$ the time intervals $\Delta N_j$ are (in distribution) sufficiently large. Thus, we may just redefine $N_0 \equiv n^{\varepsilon}$ and apply the very same decomposition as before to obtain %\comu{Qual o efeito da escolha do $N_0$ do lado direito?} {\color{blue} (note que não podemos usar $\Rr^Y_{\Delta N_j}$ na soma abaixo, porque teríamos ranges sobre intervalos que não são disjuntos.)}
\begin{align} \label{pR_DNj}
|\Rr_{[n^{\varepsilon}, n]} ^X| -1 &\leq
 M_n + \sum_{j = 1}^{M_n} \sum_{t = N_{j-1} + 2}^{N_j} \um_{\{X_t \neq X_l, \forall l \in [N_{j-1}+1, t) \}} \nonumber
 \\ 
 & \leq  M_n + \sum_{j = 1}^{M_n} |\Rr_{[N_{j-1} + 2, N_j]} ^Y| \,. 
\end{align}
%where $\{Y_n\}_{n \geq 0}$ denotes a random walk whose i.i.d.~increments in $\ZZ^2$ are $\{\xi_i\}_{i \ge 1}$. 
%\cm{ Important to notice that $Y$ is independent of $N$, since the increments of $Y$ are determined by the sequence of $\{ \xi_i \}_{i \ge 1}$ which occur in the length $[N_{j-1}+ 2, N_j]$. ??} \comu{importante mencionar que Y é independente dos N's pois seus incrementos são deteminados pelos $\xi$'s.}
%
We pointed out that to deal properly with the rightmost sum in~\eqref{pR_DNj}, we need to keep in mind that $Y$ is independent of  $\{N_j\}_{j\ge 1}$.
Now, for any $k \in \{1, 2, \dots, n \}$ fixed, we define  the  random set 
\[
A_{n,k} \coloneqq \{ j \in \{1, 2, \dots, M_n \} : \Delta N_j \leq k \}\,,
\] 
and we write 
\begin{align*}
 \sum_{j = 1}^{M_n} |\Rr_{[N_{j-1} + 2, N_j]}^Y| & = \sum_{j \in A_{n,k}} |\Rr_{[N_{j-1} + 2, N_j]}^Y| + \sum_{j \in A_{n,k}^{c}} |\Rr_{[N_{j-1} + 2, N_j]}^Y| 
\\
& \leq (k-1)|A_{n,k}| + \sum_{j \in A_{n,k}^c} |\Rr_{[N_{j-1} + 2, N_j]}^Y| \;. 
\end{align*}
Using the simple inequality
$$
M_n = |A_{n,k}| + |A_{n,k}^c| \le |A_{n,k}| + \frac{M_n}{k} \le |A_{n,k}| + \frac{n}{k}\,,
$$
and \eqref{pR_DNj}, we obtain that 
\begin{equation}\label{R_DNj}
|\Rr_{[n^{\varepsilon}, n]} ^X| \le \Big(1 +  \frac{n}{k}\Big) + k |A_{n,k}| + \sum_{j \in A_{n,k}^c} |\Rr_{[N_{j-1} + 2, N_j]}^Y|\,.
\end{equation}
To control the right-hand side of \eqref{R_DNj}, we begin with estimates on $|A_{n,k}|$. By coupling arguments, if $G$ denotes a Geometric random variable with parameter $n^{-\varepsilon{\beta}}$, since we redefined $N_0 = n^{\epsilon}$, we have that  $G \preceq \Delta N_j$ for all for all $j \ge 1 $,  
%$j \in \{1, 2, \dots, M_n \}$, 
where $\preceq$ means stochastic dominance. Thus, it holds that
\begin{equation}\label{eq: DNj<k}
\PP[\Delta N_j \leq k] \leq \mathbb{P}[G\le k]= 1 - \left( 1 - \frac{1}{n^{\varepsilon{\beta}}} \right)^k  \,.    
\end{equation}

Since $|A_{n,k}| = \sum_{j=1}^{M_n} \um_{\{\Delta N_j \leq k \}}$ and $\{\Delta N_j\}_{j=1}^n$ are independent, using \eqref{eq: DNj<k},   for every $a>0$ and $n$ sufficiently large, it holds that
\begin{align*}
\PP\Big[  \sum_{j=1}^{M_n} \um_{\{\Delta N_j \leq k \}}  > a \Big]  &\leq  \PP\Big[  \sum_{j=1}^{n} \um_{\{\Delta N_j \leq k \}}  > a \Big]\\
%& \leq \PP\left[  \sum_{j=1}^{n} 1_{\{\Delta N_j \leq k \}}  > a \right]
%\\
 &\leq \binom{n}{\lceil a \rceil} \Big( 1 - \Big( 1 - \frac{1}{n^{\varepsilon{\beta}}} \Big)^k \Big)^{\lceil a \rceil}\,  
\\
& \leq \Big( \frac{ne}{\lceil a \rceil} \Big)^a \Big( 1 - \Big( 1 - \frac{1}{n^{\varepsilon{ \beta}}} \Big)^k \Big)^{\lceil a \rceil}\\
&
 \leq \Big( \frac{ne}{a} \Big)^{\lceil a \rceil} \Big( 1 - \exp{-\frac{3}{2}\frac{k} {n^{\varepsilon{\beta}}}} \Big)^{\lceil a \rceil} 
 \\&\leq \Big( \frac{ne}{a} \times \frac{3k}{2n^{\varepsilon{\beta}}} \Big)^{\lceil a \rceil} \,,
\end{align*}
where in the last inequalities we used that 
$\left(1-\frac{1}{x}\right)^x\geq e^{-3/2}$, $\forall x\geq 2$ (with $n$ sufficiently large) and that $1-e^{-x}\leq x$. 
Setting   $a= n^{1-\varepsilon \beta/2}$ we obtain that 
\begin{equation}\label{eq:1_DNj<k}
\PP\Big[  \sum_{j=1}^{M_n} \um_{\{\Delta N_j \leq k \}}  > n^{1-\varepsilon {\beta/2}} \Big] 
% \leq \Big( \frac{3ek}{2n^{\frac{\varepsilon}{4}}} \Big)^{n^{1-\varepsilon}} 
{ \leq \Big( \frac{3ek}{2n^{\frac{\varepsilon \beta}{2}}} \Big)^{n^{1-\varepsilon \beta/2}}} \,.  
\end{equation}


We now set $k = \lceil \log^2 (n) \rceil$. With this choice, the deterministic first term in \eqref{R_DNj} divided by $n$ converges to zero.  Moreover, the sum in $n$ of the probabilities of the events $\{ |A_{n, \lceil \log^2 (n) \rceil}|  > n^{1-\varepsilon {\beta/2}} \}$ is finite by \eqref{eq:1_DNj<k}, { for every $\beta \in (0,1]$}. Thus, by Borel-Cantelli,  the second term in \eqref{R_DNj} divided by $n$ converges to zero almost surely.

Now we are left with the  analysis of the third term in~\eqref{R_DNj}. 
% First we will obtain an upper bound on the probability of the event that there exist at least one $j \in A_{n, \lceil \log^2 (n) \rceil}^c$, such that $|\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma \Delta N_j$, where $\gamma \in (\pi_d, 1]$.
%\begin{align}\label{eq: R_DNj>y}
%\PP[\exists j \in A_{n, \lceil \log^2 (n) \rceil}^c : |\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma \Delta N_j] & = \sum_{j=1}^{n} 1_{\{j \in A_{n, \lceil \log^2 (n) \rceil}^c \}} \PP[\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma \Delta N_j]
%\\
%& \leq \sum_{j \in A_{n, \lceil \log^2 (n) \rceil}^c} \PP[\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma (\Delta N_j-2)] \nonumber
%\\
%& \leq |A_{n, \lceil \log^2 (n) \rceil}^c| \exp \left(-c_{\gamma} \lceil \log^2 (n) -2\rceil \right) \nonumber
%\\
%& \leq \frac{n}{\lceil \log^2 (n) \rceil} \exp\left(-c_{\gamma} \lceil \log^2 (n) -2\rceil \right) \nonumber
%\\
%& \leq \exp\left( \log\left( \frac{n}{\lceil \log^2 (n) \rceil} \right) - c_{\gamma} \lceil \log^2 (n)-2 \rceil \right) \;. \nonumber
%\end{align}
%In the third inequality in~\eqref{eq: R_DNj>y} we use Lemma~\ref{RnY_upperb}. 
%
%Let us now analyze the probability term in~\eqref{eq: R_DNj>y}, remembering that $j \in A_{n, \lceil \log^2 (n) \rceil}^c$, then we have $\Delta N_j > \lceil \log^2 (n) \rceil$, for all $j$ 
%\begin{align}\label{eq: R_DNj>y2}
%\PP[\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma \Delta N_j] & = \sum_{i=\lceil \log^2 (n) \rceil +1}^{\infty} 1_{\{\Delta N_j = i \}} \PP[\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma(i-2)]
%\\
%& \leq \sum_{i=\lceil \log^2 (n) \rceil +1}^{\infty} 1_{\{\Delta N_j = i \}} \exp \left(-c_{\gamma} ( i -2)\right) \nonumber
%\\
%& \leq \exp \left(-c_{\gamma} \lceil \log^2 (n)\rceil -2 \right) \;. \nonumber
%\end{align}
%In the second inequality in~\eqref{eq: R_DNj>y2} we use Lemma~\ref{RnY_upperb}.
%
%Since we have
%\begin{equation}\label{eq: R_DNj>y3}
%|A_{n, \lceil \log^2 (n) \rceil}^c| \leq  \frac{n}{\lceil \log^2 (n) \rceil} \;,    
%\end{equation}
%for all $n$. We obtain in~\eqref{eq: R_DNj>y} from~\eqref{eq: R_DNj>y2} and~\eqref{eq: R_DNj>y3}
%\begin{align}\label{eq: gDNj}
%\PP[\exists j \in A_{n, \lceil \log^2 (n) \rceil}^c : |\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma \Delta N_j] & \leq \frac{n}{\lceil \log^2 (n) \rceil} \exp\left(-c_{\gamma} \lceil \log^2 (n) -2\rceil \right)
%\\
%& \leq \exp\left( \log\left( \frac{n}{\lceil \log^2 (n) \rceil} \right) - c_{\gamma} \lceil \log^2 (n)-2 \rceil \right) \;. \nonumber
%\end{align}
%
First,  we observe that for all $n\geq 2 $
\begin{equation}\label{eq: R_DNj>y3}
|A_{n, \lceil \log^2 (n) \rceil}^c| \leq  \frac{n}{\lceil \log^2 (n) \rceil} \,.    
\end{equation}

By Theorem~\ref{teo: RnZ>},  for all $i> \lceil \log^2(n) \rceil$ (with   $n$ sufficiently large) and for all $\gamma \in (\pi_d,1]$, it holds that 
\begin{align}\label{eq: RYi}
\begin{split}
\PP[|\Rr_{i-2}^Y| > \gamma i] &\leq  \PP[|\Rr_{i-2}^Y| > \gamma (i-2)]
 \leq \exp(-c_{\gamma}(i-2)) 
\\
& \leq \exp(-c_{\gamma}(\lceil \log^2(n) \rceil-2)) \,.
\end{split}
\end{align}
Recalling that for all $j \in A_{n, \lceil \log^2 (n) \rceil}^c$ it holds that $\Delta N_j > \lceil \log^2 (n) \rceil$,   by~\eqref{eq: R_DNj>y3} and~\eqref{eq: RYi} we obtain that
\begin{align}\label{eq: gDNj}
\begin{split}
\PP & \left[\exists j \in A_{n, \lceil \log^2 (n) \rceil}^c : |\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma \Delta N_j\right] 
 \leq \frac{n \exp\left(-c_{\gamma} \lceil \log^2 (n) -2\rceil \right)}{\lceil \log^2 (n) \rceil}  
\\
& \leq \exp\left( \log\left( \frac{n}{\lceil \log^2 (n) \rceil} \right) - c_{\gamma} \lceil \log^2 (n)-2 \rceil \right) \,.
\end{split}
\end{align}
%\textcolor{purple}{Remember that, for all $j \in A_{n, \lceil \log^2 (n) \rceil}^c$, then we have $\Delta N_j \in ( \lceil \log^2 (n) \rceil$, n]. Hence we obtain
%\begin{align*}
%\PP[\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma \Delta N_j] & \leq \sum_{i=\lceil \log^2 (n) \rceil +1}^{n} \PP[\Rr_{i-2}^Y| > \gamma i| \Delta N_j = i]
%\\
%& \leq \sum_{i=\lceil \log^2 (n) \rceil +1}^{n} \PP[\Rr_{i-2}^Y| > \gamma (i-2)| \Delta N_j = i]
%\\
%& \leq \sum_{i=\lceil \log^2 (n) \rceil +1}^{n} \exp(-c_{\gamma}(i-2))
%\\
%& \leq (n-\lceil \log^2 (n) \rceil)\exp\left(-c_{\gamma} \lceil \log^2 (n) -2\rceil \right)\;. 
%end{align*}}
Since it holds that
% $\big\{ \exists j \in A_{n, \lceil \log^2 (n) \rceil}^c : |\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma \Delta N_j\big\}$ contains 
\begin{align*}
&\left\{ \exists j \in A_{n, \lceil \log^2 (n) \rceil}^c : |\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma \Delta N_j\right\} \\
&\supseteq
\Big\{\sum_{j \in A_{n,\lceil \log^2 (n) \rceil}^c} |\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma n\Big\}\,,
\end{align*}
then this last event has probability bounded above by the rightmost term in \eqref{eq: gDNj}
%\begin{equation}\label{eq: sumRy}
%\begin{split}    
%    \PP\Big[ \sum_{j \in A_{n,k}^c} |\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma n \Big] & \leq \exp\Big( \log\Big( \frac{n}{\lceil \log^2 (n) \rceil} \Big) - c_{\gamma} \lceil \log^2 (n)-2 \rceil \Big) \,.
    %\\
    %& \to 0 \quad \text{as } n \to \infty \,.
%\end{split}    
%\end{equation}
which is summable.
%$$\Big\{ \sum_{j \in A_{n,k}^c} |\Rr_{[N_{j-1} + 2, N_j]}^Y| > \gamma n \Big\}$$ 
Thus, by Borell-Cantelli Lemma, the third term in~\eqref{R_DNj} divided by $n$ is bigger than $\gamma$ only finitely many times almost surely.
%
Hence,  letting $\gamma\downarrow \pi_d$ completes the proof. 
\end{proof}

\subsection{Lower bound for the range (proof of Proposition~\ref{prop:RangeERW_lower})}
\hfill \\

% \begin{comment}
% Given  $\beta\geq 1/2$ and  $\ell \geq 1$ set $Z_\ell^\beta=\um_{\{U_\ell \leq  \ell^{-\beta/2}\}}$, i.e., $Z_\ell^\beta$ is a random variable with Bernoulli distribution with parameter $\ell^{-\beta/2}$. 
% Let us define the following set:
% \begin{align}\label{eq:set_A}
% A_{k,\delta, \beta} := \left\{\sum_{\ell = k}^{k + \lfloor k^\delta \rfloor}Z_\ell^\beta=0\right\}\,,
% \end{align}
% i.e.,  the event that in the first $\lfloor k^\delta \rfloor$ steps after time $k$ none of the corresponding Bernoulli are successful. In particular, the occurrence of the  event $A_{k,\delta, \beta}$ implies that the random walk does not get excited in the time window from $k$ to $k + \lfloor k^\delta \rfloor$. 

% Before proving Proposition~\ref{prop:RangeERW_lower} we state a couple of auxiliary results. 
% %
% \begin{lemma}\label{lemma_1}  
% Given $\beta\geq 1/2$ and  $\delta \in (0, 1/2)$  consider the sequence of events $\{A_{k, \delta,\beta}\}_{k\geq 1}$ defined in \eqref{eq:set_A}. Then, it holds that 
% \begin{equation*}			
% \lim_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n \um_{A_{k,\delta, \beta}^c} = 0 \,, \quad  \text{ a.s.}\,.
% \end{equation*}
% \comu{Parece valer para $\beta <1/2$ se tomamos $\delta \in (0,\beta)$.}
% \end{lemma}

% %%%%%% OLD LEMA %%%%%%%%%
% % \begin{lemma}\label{lemma_1}  \com{maybe we should state this lemma for $\beta \geq 1/2$ to be more coherent with the rest....} 
% % Let $\delta$ be a positive real number such that $\delta \in (0, 1/2)$ and we consider the event $A_{k, \delta}$ for $k \ge 1$. Then we have
% % \begin{equation*}			
% % \lim_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n \um_{A_{k,\delta}^c} = 0\,, \, \text{ a.s.}.
% % \end{equation*}
% % \end{lemma}

% The proof of Lemma~\ref{lemma_1} is given in  Appendix~\ref{sec:appendixC}.

% \medskip

% Given a $\mathbb{Z}^d$-valued process $\{S_n\}_{n\ge 1}$, we set
% $$
% e_k^S := \um_{\{ S_m \neq S_k \text{ for all } m > k \}} \,.
% $$
% Let $\mathcal{D}_n^S$ denote  the set of sites visited by the process $S$ up to time $n$  which are never revisited later. Then,  
% \begin{equation*}
%   |\mathcal{D}_n^S|= \sum_{k = 0}^{n} e_k^S \,.
% \end{equation*}

% \begin{lemma}\label{compXY}
% Let  $X$ be a $p_n$-\Nametwo{} in direction $\ell$, on $\ZZ^d$ with $d\geq 22$, $p_n= \mathcal{C} n^{-\beta} \wedge 1$ and $\beta \ge 1/2$. For $k\ge 1$, let $Y^k =\{Y^k_i\}_{i\ge 0}$ denote a random walk on $\ZZ^d$ defined by $Y_0^k = X_k$ and for $n\geq 1$
% \begin{equation*}
%      Y_n^k = X_k + \sum_{i = 1}^{n}\xi_{k + i}\,.
% \end{equation*}
% Then, for any $\delta \in (0, 1/2)$ it holds that  
% \begin{equation*}
% \sum_{k = 1}^{\infty} \mathbb{P} \left( e_k^{X} \um_{A_{k,\delta,\beta}} < e_0^{Y^k} \um_{A_{k, \delta,\beta}} \right) < \infty \,.   
% \end{equation*}
% \comu{parece que vai valer para $\beta < 1/2$ com a dimensão dependendo de $\beta$.}
% \end{lemma}

% Before proving Lemma~\ref{compXY}, we show how the proof of Proposition~\ref{prop:RangeERW_lower} follows from it.
% \medskip

% \begin{proof}[Proof of Proposition~\ref{prop:RangeERW_lower}]
% Note that $|\Rr_n^X| \ge |\mathcal{D}_n^X|$, since if $x \in \mathcal{D}_n^X$ then $x \in \Rr_n^X$. Therefore, it holds that 
% \begin{align}\label{eq_4.10}
% \liminf_{n \to \infty} \frac{|\Rr_n^X|}{n} &\ge \liminf_{n \to \infty} \frac{|\mathcal{D}_n^X|}{n}\nonumber \\
% &= \liminf_{n \to \infty} \frac{1}{n}\sum_{k=1}^n e_k^X \um_{A_{k,\delta,\beta}} + \liminf_{n \to \infty} \frac{1}{n}\sum_{k=1}^n e_k^X \um_{A_{k,\delta,\beta}^c}\,.  
% \end{align}
% For $\delta \in (0, 1/2)$, Lemma~\ref{lemma_1} implies that 
% \begin{equation}\label{eq_4.11}
%     \liminf_{n \to \infty} \frac{1}{n}\sum_{k=1}^n e_k^X \um_{A_{k,\delta,\beta}^c}=0\,, \quad  \text{ a.s.}\,,
% \end{equation}
% whereas, from Lemma~\ref{compXY} together with Borel-Cantelli's Lemma, we conclude that 
% \begin{equation}\label{eq_4.12}
% \liminf_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_k^X \um_{A_{k, \delta,\beta}} \ge \liminf_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_0^{Y^k} \um_{A_{k, \delta,\beta}}\,, \quad  \text{ a.s.}\,.
% \end{equation}
% Note that
% \begin{align*}
%     e_0^{Y^k} = \um_{\{\sum_{i = k+1}^m\xi_{i} \neq 0, \, \forall \, m\ge k + 1\}} = \um_{\{\sum_{i = 1}^m\xi_{i} + Y_0\neq \sum_{i = 1}^k\xi_{i} + Y_0, \, \forall \, m\ge k + 1\}} =e^Y_k\,,
% \end{align*}
% where $Y=Y^0$ on the RHS above denotes a random walk with i.i.d. increments $\{\xi_i\}_{i\geq 1}$. 
% Hence
% \begin{equation}\label{eq_4.13}
%     \liminf_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_0^{Y^k} \um_{A_{k, \delta,\beta}} = \liminf_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_k^{Y} \um_{A_{k, \delta,\beta}}\,. 
% \end{equation}
% Using again Lemma~\ref{lemma_1} and the known fact that $\lim_{n \to \infty} \frac{|\mathcal{D}_n^Y|}{n} = \pi_d$ (see e.g.~\cite{spitzer2001principles} page 39) we obtain that 
% \begin{equation}\label{eq_4.14}
% \lim_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_k^Y \um_{A_{k, \delta,\beta}} = \pi_d\,, \quad  \text{ a.s.}\,.
% \end{equation}
% Then,  by equations \eqref{eq_4.10},\eqref{eq_4.11},\eqref{eq_4.12},\eqref{eq_4.13} and \eqref{eq_4.14}, we obtain that
% $$
%     \liminf_{n \to \infty} \frac{|\Rr_n^X|}{n} \ge \pi_d \,, \quad  
%     \text{ a.s.}\,.
% $$
% \end{proof}

% \begin{proof}[Proof of Lemma~\ref{compXY}] 
% We conduct the proof for $\beta = 1/2$, which represents the most  challenging scenario. The case  $\beta > 1/2$ follows using the same computations and techniques presented here. To avoid clutter  we will denote $A_{k,\delta, 1/2}$ just by $A_{k,\delta}$.

% Let $\nu_k^X$ be the first time the process $X$ returns to the site it visited at time $k$.  We also introduce the sequence $\{ \tau_i^k \}_{i \ge 0}$ where $\tau_i^k$ for $i \ge 1$ represents the $i$-th time  the  random walk gets excited  after time $k$. Specifically, 
% \begin{align*}
% & \nu^{X}_k:= \inf \{n \geq 1: X_{k+n}= X_{k}\}\,,
% \\
% & \tau^k_0\equiv 0, \text{ and }  \tau_i^k:=\inf\{n> \tau^k_{i-1}: X_{k+n} \text{ gets excited}\}, \text{ for $i\geq 1$}\,.
% \end{align*}

% For $k \geq 1$, let us also define a sequence of independent random variables $\{H_j^k\}_{j \ge 1}$, such that each $H_j^k$ has a geometric distribution with parameter $(k + j)^{-1/2}$ for all $j \ge 1$. Additionally, we introduce the following definitions   
% \begin{align*}
% & \mathcal{G}_m^k = \sum_{j = 1}^m H_j^k \,,
% \\
% & G^k_0\equiv 0 \text{ and }  G^k_i:= \inf\{\ell > G_{i-1}^k: Z_{\ell + k} =1\},  \text{ for $i\geq 1$}\,,
% \end{align*}
% where, $Z_\ell=\um_{\{U_\ell \leq  \ell^{-1/2}\}}$.
% %\textcolor{red}{For each fixed $k \ge 1$ we define a coupling $\hat{\mathbb{P}}^k$ between the excited random walk $X$ and the random walk $Y$ with i.i.d. increments, defined such that $Y_0 = X_k$ and $Y_n := X_k + \sum_{i = k + 1}^{k + n} \xi_i$ for $n \ge 1$.} Suppose we have $\delta \in (0, 1/2)$. The first step in our proof is to establish the following
% % \begin{equation*}
% % \sum_{k = 1}^{\infty} \hat{\mathbb{P}} \left( e_k^{X} \um_{A_{k, \delta}} < e_k^{Y} \um_{A_{k, \delta}} \right) < \infty \,.   
% % \end{equation*}
% %
% What we are after is to provide an upper bound for $\PP ( e_k^{X} \um_{A_{k, \delta}} < e_0^{Y^k} \um_{A_{k, \delta}} )$ for all $k \ge 1$. Recall that the process $X$ can be rewritten as in~\eqref{xn-incremento2}, i.e.
% $$
% X_0 = 0, \text{ and }\; X_n  = \sum_{i=1}^n \big( \um_{B_i^c} \xi_i + \um_{B_i} \gamma_i \big) \, , \ n\ge 1\,,
% $$
% where $B_i:= E_{i-1}^c \cap \{U_i \le i^{-1/2}\}$ for any $i \ge 1$. Then, we have that
% \begin{equation*}
% \begin{split}
% & \mathbb{P}( e^{X}_k \um_{A_{k,\delta}} < e^{Y^k}_0 \um_{A_{k, \delta}})= \mathbb{P}(e^{X}_k=0, e^{Y^k}_0 =1, A_{k, \delta}) 
% \\
% & = \mathbb{P}(\nu^{X}_k < +\infty, e^{X}_k=0, e^{Y^k}_0 = 1, A_{k,\delta}) 
% \\
% & = \sum_{m=1}^{\infty} \mathbb{P}\left( \tau_{m}^k < \nu^{X}_k \leq \tau_{m+1}^k, e^{X}_k=0, e^{Y^k}_0 =1, A_{k, \delta} \right)
% \\
% & \le \sum_{m=1}^{\infty} \mathbb{P}\Big(\tau_{m}^k < \nu^{X}_k \leq \tau_{m+1}^k, \sum_{j = k+1}^{k+\nu^{X}_k} \left( \um_{B^{c}_j} \xi_j + \um_{B_j} \gamma_j \right) = 0, \sum_{j = k+1}^{k+\nu^{X}_k} \xi_j\neq 0, A_{k, \delta} \Big)\,.
% \end{split}
% \end{equation*}

% It is important to notice that $\tau^k_i\geq G^k_i$ for all $i\geq 0$. Thus, we have that

% % \textcolor{brown}{leonel: acho que o evento $A_{k,\delta}$ sobra nas fórmulas a seguir, uma vez que temos $G_m^k = l  + \lfloor k^{\delta}\rfloor$}\comu{concordo.}

% \begin{equation*}
% \begin{split}
% & \mathbb{P}  ( e^{X}_k \um_{A_{k,\delta}} < e^{Y^k}_0 \um_{A_{k, \delta}})
% \\
% & \le \sum_{m=1}^{\infty} \sum_{\ell = m}^{\infty} \mathbb{P}\Big( G_m^k < \nu^{X}_k, \sum_{j=k+1}^{k+\nu^{X}_k} \xi_j = \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big), G_m^k = \ell + \lfloor k^{\delta} \rfloor, A_{k, \delta} \Big)
% \\
% & \leq \sum_{m=1}^{\infty} \sum_{\ell=m}^\infty \sum_{n=\ell+\lfloor k^\delta\rfloor + 1}^{\infty} \mathbb{P}\Big( \nu^{X}_k=n, \sum_{j=k+1}^{k+n} \xi_j = \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big), G_m^k = \ell + \lfloor k^\delta\rfloor \Big) 
% \\
% & \leq \sum_{m=1}^{\infty} \sum_{\ell=m}^\infty \sum_{n=\ell+\lfloor k^\delta\rfloor + 1}^{\infty} \mathbb{P}\Big(\sum_{j=k+1}^{k+n}\xi_j = \sum_{j=1}^{m}\big(\xi_{\tau_j^k} - \gamma_{\tau_j^k}\big), G_m^k = \ell + \lfloor k^\delta\rfloor \Big) \,.
% \end{split}    
% \end{equation*}

% Let $\alpha \in (1/2,1)$ be a parameter to be determined later and let $\mu$ denote the mean vector of $\gamma$. For $m\geq 1$,  let us define 
% \[
% D_m:= \left\{x+y: x \in B(0, 2Km^\alpha) \text{ and } y \in B(m\mu, 2Km^\alpha)\right\}\,,
% \]
% where   $B(a, R):=\{x\in \mathbb{Z}^d: \Vert x-a\Vert^2\leq R\}$ with  $a \in \mathbb{Z}^d$ and $R \in [0,+\infty)$. 
% Then we have that
% \begin{equation}\label{eq:decomposition}
% \begin{split}
% & \mathbb{P}\Big(\sum_{j=k+1}^{k+n}\xi_j = \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k}\big), G_m^k = \ell + \lfloor k^\delta\rfloor \Big) 
% =  
% \\
% & \sum_{z \in D_m} \mathbb{P}\Big(
% %\nu^{\rm ERW}_k=n,
% \sum_{j=k+1}^{k+n}\xi_j =z, \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) = z, G_m^k = \ell + \lfloor k^\delta\rfloor  \Big)
% \\
% &+ \sum_{z \in D^\complement_m} \mathbb{P} \Big(
% %\nu^{\rm ERW}_k=n, 
% \sum_{j=k+1}^{k+n}\xi_j = z, \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) = z, G_m^k = \ell + \lfloor k^\delta\rfloor \Big)\,.    
% \end{split}
% \end{equation}

% We will analyze the two terms on the RHS of ~\eqref{eq:decomposition} separately. For the  first sum portion it holds that
% \begin{equation}\label{eq_sum1<1}
% \begin{split}
% \sum_{z \in D_m} & \mathbb{P} \Big(
% \sum_{j=k+1}^{k+n} \xi_j = z, \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) = z, G_m^k = \ell + \lfloor k^\delta\rfloor \Big)
% \\
% & \leq \sum_{z \in D_m} \mathbb{P}\Big(
% \sum_{j=k+1}^{k+n}\xi_j = z \Big) \mathbb{P} ( G_m^k = \ell + \lfloor k^\delta\rfloor) 
% % \\
% % & \leq |D_m| \frac{C_d}{n^{d/2}} \hat{\mathbb{P}}(A_k, G_m^k = \ell + \lfloor k^\delta\rfloor) 
% \\
% & \leq (4Km^\alpha)^d \frac{C_d}{n^{d/2}} \mathbb{P}( G_m^k = \ell + \lfloor k^\delta\rfloor)\,,    
% \end{split}    
% \end{equation}
% where, in the second inequality in~\eqref{eq_sum1<1} we use the fact that $|D_m| \le (4Km^{\alpha})^d$ and the Local Central Limit Theorem 
% % (see inequality (2.4) in \cite[Theorem 2.1.1]{lawler2010random} and commentary in page 24)  
% see, e.g., Inequality (2.8) in \cite[Theorem 2.1.3]{lawler2010random}  and the fact that $\Bar{p}_n(x) \le C_d n^{-d/2}$, with $C_d$ a positive constant. For the second term in~\eqref{eq:decomposition} we have
% \begin{equation}\label{eq_sum<2}
% \begin{split}
% &\sum_{z \in D^c_m} \mathbb{P}\Big(
% %\nu^{\rm ERW}_k=n, 
% \sum_{j=k+1}^{k+n} \xi_j = z, \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) = z, G_m^k = \ell + \lfloor k^\delta\rfloor \Big)
% \\
% & \le \sum_{z \in D^c_m \cap B(0,2Km)} \mathbb{P}\Big(
% %\nu^{\rm ERW}_k=n, 
% \sum_{j=k+1}^{k+n} \xi_j = z,\sum_{j=1}^{m}\big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) = z \Big) %, A_k, G_m^k = \ell + \lfloor k^\delta\rfloor \right)
% \\
% &\leq \mathbb{P}\Big(
% %\nu^{\rm ERW}_k=n, 
% \sum_{j=k+1}^{k+n} \xi_j \in B(0,2Km) \setminus D_m, \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) \in B(0,2Km) \setminus D_m \Big) %, A_k, G^k_m = \ell + \lfloor k^\delta\rfloor \right) 
% \\
% &\leq \mathbb{P}\Big(
% %\nu^{\rm ERW}_k=n, 
% \sum_{j=k+1}^{k+n} \xi_j \in B(0,2Km) \setminus D_m \Big)^{1/2} \mathbb{P}\Big( \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) \in B(0,2Km) \setminus D_m \Big)^{1/2} \,, \end{split}    
% \end{equation}
% where, in the last  inequality above, we used Cauchy-Schwarz inequality. Regarding the first term in~\eqref{eq_sum<2}, by using again the Local Central Limit Theorem, it holds that 
% \begin{equation}\label{eq_sum<2.1}
% \begin{split}
% \mathbb{P}\Big(
% %\nu^{\rm ERW}_k=n, 
% \sum_{j=k+1}^{k+n}\xi_j \in B(0,2Km) \setminus D_m \Big) & = \sum_{z \in D^c_m \cap B(0,2Km)} \mathbb{P}\Big(
% %\nu^{\rm ERW}_k=n, 
% \sum_{j=k+1}^{k+n} \xi_j = z\Big)
% \\
% & \leq \frac{C_d}{n^{d/2}} |B(0,2Km)|\,.
% \end{split}
% \end{equation}
% For the second term in~\eqref{eq_sum<2}, let us define $F := B(0,2Km) \setminus D_m$, $G := B(0,2Km) \setminus B(0,2Km^{\alpha})$ and $A := B(0, 2Km) \setminus B(m\mu, 2Km^{\alpha})$. We then  obtain
% \begin{equation}\label{eq_sum<2.2}
% \begin{split}
% & \mathbb{P}\Big(\sum_{j=1}^{m} \big(\xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) \in F \Big) \leq \mathbb{P}\Big( \sum_{j=1}^{m} \xi_{\tau^k_j} \in G \Big)  + \mathbb{P}\Big(\sum_{j=1}^{m} \gamma_{\tau^k_j} \in A \Big) %\Big| A_k, G^k_m = \ell + \lfloor k^\delta\rfloor \right)
% \\
% & = \mathbb{P}\Big(\sum_{j=1}^{m}\xi_{j} \in G \Big) + \hat{\mathbb{P}}\Big(\sum_{j=1}^{m}\gamma_{j} \in A \Big) 
% \\
% & = \mathbb{P}\Big(\sum_{j=1}^{m}\xi_{j} \in G \Big) + \mathbb{P}\Big( \sum_{j=1}^{m}(\gamma_{j}-\mu) \in B(-m\mu,2Km) \setminus  B(0,2Km^\alpha)\Big) 
% % \\
% % & \leq 2|B(0,2Km)| \Hat{C}_{d,K} \Big[ e^{-2dK^2m^{2\alpha-1}}\Big(\frac{1}{m^{\frac{d}{2}}} + m^{\frac{7d-2}{2}} + \frac{1}{m^{\frac{d+2}{2}}} \Big)  + \frac{1}{m^{\frac{9d-1}{2}}} \Big]
% % \\
% % & \leq 2|B(0,2Km)| \Hat{C}_{d,K} \Big(m^{4d} e^{-2dK^2m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{2}}} \Big)\,. 
% \\
% & 
% \leq 2|B(0,2Km)| \Hat{C}_{d,K} \Big[ e^{-2d\delta K^2m^{2\alpha-1}}\Big(\frac{1}{m^{\frac{d}{2}}} + \frac{(2Km)^{8d}}{m^{4d}m^{\frac{d+2}{2}}} + \frac{1}{m^{\frac{d+2}{2}}} \Big)  + \frac{1}{m^{\frac{9d-1}{2}}} \Big]
% \\
% & 
% \leq 2|B(0,2Km)| \widetilde{C}_{d,K} \Big(m^{4d} e^{-2d \delta K^2m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{2}}} \Big)\,. 
% \end{split}    
% \end{equation}
% In~\eqref{eq_sum<2.2}, we applied Lemma~\ref{lem: iid} to achieve the first equality. For the first inequality, we utilized the Local Central Limit Theorem see, e.g., Inequality (2.8) in \cite[Theorem 2.1.3]{lawler2010random} with $k=8d$
%  and the fact that $\Bar{p}_n(x) \le C_d n^{-d/2}\exp(-||x||^2 \delta d/2n)$), with $\delta >0$ and the constant $C_d$ depending on the covariance matrix of $\xi$ (see, e.g., Equations~2.2 and 1.1 and Proposition~1.1.1 (c) in \cite{lawler2010random}).  
%  %along with the observation that $(2Km^{\alpha})^2 > m$, which follows since, by definition, $\alpha > 1/2$. The final inequality is derived from the fact that $\alpha < 1$. 
% %
% Thus, using~\eqref{eq_sum<2.1} and~\eqref{eq_sum<2.2} we obtain that the rightmost term in~\eqref{eq_sum<2} is bounded above by 
% \begin{equation}\label{eq:sum<2.3}
% \begin{split}
% %\sum_{z \in D^\complement_m} &\hat{\mathbb{P}}\left(
% %\nu^{\rm ERW}_k=n, 
% %\sum_{j=k+1}^{k+n}\xi_j =z, \sum_{j=1}^{m}\left(\xi_{\tau_j^k} - \gamma_{\tau_j^k}\right)=z \right) %, A_k, G_m^k = \ell + \lfloor k^\delta\rfloor  \right)
% %\\
% \Big[ 2 & |B(0,2Km)| \widetilde{C}_{d,K} \Big(m^{4d} e^{-2d\delta K^2m^{2\alpha-1}} + m^{-\frac{9d-1}{2}} \Big) \Big]^{1/2} \Big[ \frac{C_d}{n^{d/2}} |B(0,2Km)|\Big]^{1/2}
% %\Big(4 & |B(0,2Km)|  \frac{C_d^2}{n^{d/2}}\Big)^{1/2} \Big( 2m^{3d+9} e^{-\frac{d(2Km^\alpha)^2}{2m}} + m^{-(d+8)}\Big)^{1/2} %\hat{\mathbb{P}}\left(A_k, G_m^k = \ell + \lfloor k^\delta\rfloor  \right)
% \\
% & \le \frac{m^d\Tilde{C}_{d,K}}{n^{d/4}} \Big(m^{4d} e^{-2d\delta K^2m^{2\alpha-1}} + m^{-\frac{9d-1}{2}} \Big)^{1/2} 
% \\
% & \le \frac{m^d\Tilde{C}_{d,K}}{n^{d/4}} \Big(m^{2d} e^{-d\delta K^2 m^{2\alpha-1}} + m^{-\frac{9d-1}{4}} \Big)\,.
% %&\leq 2(2Km)^{d/2} \frac{C_d}{n^{d/4}} \Big( 2^{\frac{1}{2}}m^{\frac{3}{2}(d+3)} e^{-\frac{d(2Km^\alpha)^2}{4m}} + m^{-\frac{1}{2}(d+8)}\Big) \,.
% % \hat{\mathbb{P}}\left(A_k, G_m^k = \ell + \lfloor k^\delta\rfloor  \right) 
% % \\
% % &=2^{1/2} (2Km)^d \left(\frac{C_d}{m^{d/2}}\right)^{1/2}  e^{-\frac{d(2Km^\alpha)^2}{4m}} \left(\frac{C_d}{n^{d/2}}\right)^{1/2} 
% % %\hat{\mathbb{P}}\left(A_k, G_m^k = \ell + \lfloor k^\delta\rfloor  \right) 
% % \,.
% \end{split}
% \end{equation}
% Overall, by~\eqref{eq_sum1<1} and~\eqref{eq:sum<2.3} we obtain that

% \begin{equation*}
% \begin{split}
% & \hat{\mathbb{P}}  ( e^{X}_k \um_{A_{k,\delta}} < e^{Y}_k \um_{A_{k, \delta}})  \leq\underbrace{\sum_{m=1}^{\infty} \sum_{\ell=m}^\infty  \sum_{n=\ell+ \lfloor k^\delta\rfloor + 1}^{\infty} (4Km^\alpha)^d \frac{C_d}{n^{d/2}} \mathbb{P}(G_m^k = \ell + \lfloor k^\delta\rfloor) }_{SUM_1}
% \\
% &+\underbrace{\sum_{m=1}^{\infty} \sum_{\ell = m}^\infty \sum_{n = \ell + \lfloor k^\delta\rfloor + 1}^{\infty} \frac{m^d\Tilde{C}_{d,K}}{n^{d/4}} \Big(m^{2d} e^{-d\delta K^2 m^{2\alpha-1}} + m^{-\frac{9d-1}{4}} \Big) }_{SUM_2}\,. %\hat{\mathbb{P}}\left(A_k, G_m^k = \ell + \lfloor k^\delta\rfloor \right)}_{SUM_2} \,. 
% \end{split}
% \end{equation*}

% We will prove that $ \sum_{k \ge 1}\mathbb{P} ( e^{X}_k \um_{A_{k,\delta}} < e^{Y^k}_0 \um_{A_{k, \delta}}) < \infty$ by demonstrating that both $SUM_1$ and $SUM_2$ are summable over $k$. We begin with $SUM_1$  for which we obtain that 
% \begin{equation*}
% \begin{split}
% & SUM_1 = \sum_{m=1}^{\infty} (4Km^\alpha)^d \sum_{\ell=m}^\infty \mathbb{P}(G_m^k = \ell + \lfloor k^\delta\rfloor) \sum_{n=\ell+ \lfloor k^\delta\rfloor + 1}^{\infty}  \frac{C_d}{n^{d/2}} 
% \\
% & \le C_d \sum_{m=1}^{\infty} (4Km^\alpha)^d \sum_{\ell = m}^\infty \mathbb{P}( G_m^k = \ell + \lfloor k^\delta\rfloor) \int_{\ell + \lfloor k^\delta\rfloor}^\infty  \frac{1}{x^{d/2}}dx
% \\
% & \overset{d>2}{=} \frac{C_d (4K)^d}{d/2-1}\sum_{m=1}^{\infty}    m^{\alpha d}   \sum_{\ell=m}^\infty \mathbb{P} (G_m^k = \ell + \lfloor k^\delta\rfloor) \frac{1}{(\ell + \lfloor k^\delta\rfloor)^{d/2-1}}
% \\
% & \leq C_{d,K} \sum_{m=1}^{\infty}    m^{\alpha d}   \sum_{\ell=m}^\infty \mathbb{P}(G_m^k = \ell) \frac{1}{(\ell + \lfloor k^\delta\rfloor)^{d/2-1}} 
% \\
% & \leq C_{d,K} \sum_{m=1}^{\infty}    m^{\alpha d} \,\mathbb{E}\Big[ \frac{1}{( G_m^k + \lfloor k^\delta\rfloor)^{d/2-1}} \Big] \,.
% \end{split}    
% \end{equation*}

% We first note that $G^k_m \ge m$ and stochastically dominates $\mathcal{G}_m^k$, and recall that $ \mathcal{G}_m^k = \sum_{j=1}^m H^k_j$, where $\{H^k_j\}_{j\geq 1}$ are independent random variables with geometric distribution with parameter $(k+j)^{-1/2}$ for each $j \ge 1$. Now, we will compute an upper bound for $\mathbb{E}[(G_m^k + \lfloor k^\delta \rfloor)^{1-d/2}]$. 
% \begin{equation*}
% \begin{split}
% &\mathbb{E}[(G_m^k + \lfloor k^\delta \rfloor)^{1-d/2}] = 
% \\
% & \mathbb{E}\Big[ \frac{1}{( G_m^k + \lfloor k^\delta\rfloor)^{d/2-1}} ; G_m^k < \frac{m^{\frac{3}{2}}}{6} \Big] +  \mathbb{E}\Big[ \frac{1}{( G_m^k + \lfloor k^\delta\rfloor)^{d/2-1}} ; G_m^k \ge \frac{m^{\frac{3}{2}}}{6} \Big]
% \\
% & \leq \frac{1}{( m + \lfloor k^\delta\rfloor)^{d/2-1}} \mathbb{P} \Big[ G_m^k < \frac{m^{\frac{3}{2}}}{6} \Big] + \frac{6^{d/2-1}}{(m^{3/2} + 6 \lfloor k^\delta\rfloor)^{d/2-1}}
% \\
% & \leq \frac{1}{( m + \lfloor k^\delta\rfloor)^{d/2-1}} \mathbb{P} \Big[ \mathcal{G}_m^k < \frac{m^{\frac{3}{2}}}{6} \Big] + \frac{6^{d/2-1}}{(m^{3/2} + 6 \lfloor k^\delta\rfloor)^{d/2-1} }\,.
% \end{split}
% \end{equation*}
% %
% Then, we use Lemma~\ref{lem:geo_sum_bound} for $\PP[\mathcal{G}_m^k < 6^{-1}m^{\frac{3}{2}}]$ with $\theta = 5$ and choose $\alpha=1/2 + 1/(cd)>1/2$, where $c$ is a sufficiently large positive constant, to obtain  the following 
% \begin{equation}\label{eq:sum1_2}
% \begin{split}
% & SUM_1  \leq C_{d,K} \Big(\sum_{m=1}^{\infty}    \frac{m^{d/2 + 1/c - 5}}{(m+\lfloor k^\delta\rfloor)^{d/2-1}} + 6^{d/2-1} \sum_{m = 1}^{\infty} \frac{m^{d/2 + 1/c} }{(m^{3/2} + 6 \lfloor k^\delta\rfloor)^{d/2-1}}\Big)
% \\
% & \leq C_{d,K}' \Big(\sum_{m=1+\lfloor k \rfloor^\delta}^{\infty}    \frac{m^{d/2 + 1/c - 5}}{m^{d/2-1}} +  \int_0^{\infty} \frac{(u^{2/3})^{d/2 + 1/c}}{(u + 6 \lfloor k^{\delta} \rfloor)^{d/2 - 1}} \times \frac{2}{3} u^{-1/2} du \Big)
% \\
% & \leq C_{d,K}' \Big(\int_{\lfloor k^\delta \rfloor}^{\infty}\frac{1}{x^{4-1/c}}dx + 
% \int_0^{\infty} \frac{(u + 6\lfloor k^{\delta} \rfloor)^{2/3(d/2 + 1/c) - 1/2}}{(u + 6 \lfloor k^{\delta} \rfloor)^{d/2 - 1}} du \Big)
% \\
% & \le C_{d,K,c} \Big( \frac{1}{(\lfloor k^\delta \rfloor)^{(3 -1/c)}} + 
% \int_{6\lfloor k^{\delta} \rfloor}^{\infty} \frac{w^{2/3(d/2 + 1/c) - 1/2}}{w^{d/2 - 1}} dw \Big)
% \\
% & \le C_{d,K,c}'' \Big( \frac{1}{(\lfloor k^\delta \rfloor)^{(3 -1/c)}} + \frac{1}{\lfloor k^{\delta} \rfloor^{d/6 - 3/2 -2/3c}} \Big)\,,
% \end{split}    
% \end{equation}
% \comu{parece ter um problema aqui. Não seria $u = m^{3/2}$ com $dm = u^{-1/3}du$? Isso mudaria a condição de convergência para $d\ge 23$.}
% where, in the second inequality of~\eqref{eq:sum1_2}, we used the change of variable  $u = m^{2/3}$ and, in the fifth inequality, we again changed variable with $w = u + 6\lfloor k^{\delta} \rfloor$. 

% Now we will compute an upper bound for $SUM_2$.
% \begin{equation}\label{eq:sum2_1}
% \begin{split}
% & SUM_2 = \Tilde{C}_{d,K} \sum_{m=1}^{\infty} m^d \Big( m^{2d} e^{-d\delta K^2 m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{4}}} \Big) \sum_{\ell = m}^\infty \sum_{n = \ell + \lfloor k^\delta\rfloor + 1}^{\infty} n^{-d/4}
% \\
% & \le \Tilde{C}_{d,K} \sum_{m=1}^{\infty} m^d \Big( m^{2d} e^{-d\delta K^2 m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{4}}} \Big) 
% \sum_{\ell = m}^\infty \frac{1}{(\lfloor k^\delta\rfloor + \ell)^{\frac{d}{4}-1}}
% \\
% & \le \Tilde{C}_{d,K} \sum_{m=1}^{\infty} m^d \Big( m^{2d} e^{-d\delta K^2 m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{4}}} \Big) 
% \sum_{\ell = \lfloor k^\delta\rfloor + m}^\infty \frac{1}{\ell^{\frac{d}{4}-1}}
% \\
% & \le \Tilde{C}_{d,K} \sum_{m=1}^{\infty} m^d \Big( m^{2d} e^{-d\delta K^2 m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{4}}} \Big)  \frac{1}{(m+ \lfloor k^\delta\rfloor -1)^{\frac{d}{4}-2}}
% \\
% & \le \frac{C_{d,K}'}{\lfloor k^\delta\rfloor^{d/4-2}} \sum_{m=1}^{\infty} m^d \Big( m^{2d} e^{-d\delta K^2 m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{4}}} \Big) \le \frac{C_{d,K}''}{\lfloor k^\delta\rfloor^{d/4-2}} \,,
% \end{split}    
% \end{equation}
% where, in the last inequality of~\eqref{eq:sum2_1} we used that $\alpha > 1/2$. 
% %
% Now we use the bounds in~\eqref{eq:sum1_2} and~\eqref{eq:sum2_1} and, since $d \ge 22$, we finally obtain that
% \begin{equation*}
% \begin{split}
% & \sum_{k=1}^\infty \mathbb{P}  ( e^{X}_k \um_{A_{k,\delta}} < e^{Y^k}_0 \um_{A_{k, \delta}}) 
% \\
% & \le \sum_{k = 1}^\infty \left(C_{d,K,c}'' \Big( \frac{1}{(\lfloor k^\delta \rfloor)^{(3 -1/c)}} + \frac{1}{\lfloor k^{\delta} \rfloor^{d/6 - 3/2 -2/3c}} \Big) +  \frac{C_{d,K}''}{\lfloor k^\delta\rfloor^{d/4-2}} \right)< \infty \,.
% \end{split}
% \end{equation*}
% \end{proof}
% \end{comment}

As for Proposition~\ref{prop:RangeERW}, the proof for $\beta>1$ is straightforward. Let $\beta \in (0,1]$ and for $\ell \geq 1$ set $Z_\ell^\beta=\um_{\{U_\ell \leq  \ell^{-\beta}\}}$. 
Given $k\geq 1$ and $\delta \in (0,1)$, let us define the following set:
\begin{align}\label{eq:set_A}
A_{k,\delta, \beta} := \left\{\sum_{\ell = k}^{k + \lfloor k^\delta \rfloor}Z_\ell^\beta=0\right\}\,,
\end{align}
i.e.,  the event that in the first $\lfloor k^\delta \rfloor$ steps after time $k$ none of the corresponding Bernoulli are successful. In particular, the occurrence of the  event $A_{k,\delta, \beta}$ implies that the random walk does not get excited in the time window from $k$ to $k + \lfloor k^\delta \rfloor$. 

Before proving Proposition~\ref{prop:RangeERW_lower} we state a couple of auxiliary results. 
%
\begin{lemma}\label{lemma_1}  
Given { $\beta \in (0,1]$}  consider the sequence of events $\{A_{k, \delta,\beta}\}_{k\geq 1}$ defined in \eqref{eq:set_A}. Then, { for every $\delta \in (0, \beta)$}  it holds that 
\begin{equation*}			
\lim_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n \um_{A_{k,\delta, \beta}^c} = 0 \,, \quad  \text{ a.s.}\,.
\end{equation*}

\end{lemma}

%%%%%% OLD LEMA %%%%%%%%%
% \begin{lemma}\label{lemma_1}  \com{maybe we should state this lemma for $\beta \geq 1/2$ to be more coherent with the rest....} 
% Let $\delta$ be a positive real number such that $\delta \in (0, 1/2)$ and we consider the event $A_{k, \delta}$ for $k \ge 1$. Then we have
% \begin{equation*}			
% \lim_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n \um_{A_{k,\delta}^c} = 0\,, \, \text{ a.s.}.
% \end{equation*}
% \end{lemma}

The proof of Lemma~\ref{lemma_1} is given in  Appendix~\ref{sec:appendixC}.

\medskip

Given a $\mathbb{Z}^d$-valued process $\{S_n\}_{n\ge 1}$, we set
$$
e_k^S := \um_{\{ S_m \neq S_k \text{ for all } m > k \}} \,.
$$
Let $\mathcal{D}_n^S$ denote  the set of sites visited by the process $S$ up to time $n$  which are never revisited later. Then,  
\begin{equation*}
  |\mathcal{D}_n^S|= \sum_{k = 0}^{n} e_k^S \,.
\end{equation*}

\begin{lemma}\label{compXY}
Let  $X$ be a $p_n$-\Nametwo{} in direction $\ell$, on $\ZZ^d$ with  $p_n= \mathcal{C} n^{-\beta} \wedge 1$ and $\beta \in (0,1]$. For $k\ge 1$, let $Y^k =\{Y^k_i\}_{i\ge 0}$ denote a random walk on $\ZZ^d$ defined by $Y_0^k = X_k$ and for $n\geq 1$
\begin{equation*}
     Y_n^k = X_k + \sum_{i = 1}^{n}\xi_{k + i}\,.
\end{equation*}
{ If $d> \max\{ 2 \frac{\beta^2 + 3 \beta +1}{\beta^2}, 4 \frac{2\beta +1}{\beta}\}$,  there exists $\delta \in (0,\beta)$ such that }
\begin{equation*}
\sum_{k = 1}^{\infty} \mathbb{P} \left( e_k^{X} \um_{A_{k,\delta,\beta}} < e_0^{Y^k} \um_{A_{k, \delta,\beta}} \right) < \infty \,.   
\end{equation*}
\end{lemma}



Before proving Lemma~\ref{compXY}, we show how the proof of Proposition~\ref{prop:RangeERW_lower} follows from it.
\medskip

\begin{proof}[Proof of Proposition~\ref{prop:RangeERW_lower}]
Note that $|\Rr_n^X| \ge |\mathcal{D}_n^X|$, since if $x \in \mathcal{D}_n^X$ then $x \in \Rr_n^X$. Therefore, it holds that 
\begin{align}\label{eq_4.10}
\liminf_{n \to \infty} \frac{|\Rr_n^X|}{n} &\ge \liminf_{n \to \infty} \frac{|\mathcal{D}_n^X|}{n}\nonumber \\
&= \liminf_{n \to \infty} \frac{1}{n}\sum_{k=1}^n e_k^X \um_{A_{k,\delta,\beta}} + \liminf_{n \to \infty} \frac{1}{n}\sum_{k=1}^n e_k^X \um_{A_{k,\delta,\beta}^c}\,.  
\end{align}
For {$\delta \in (0, \beta)$}, Lemma~\ref{lemma_1} implies that 
\begin{equation}\label{eq_4.11}
    \liminf_{n \to \infty} \frac{1}{n}\sum_{k=1}^n e_k^X \um_{A_{k,\delta,\beta}^c}=0\,, \quad  \text{ a.s.}\,,
\end{equation}
whereas, from Lemma~\ref{compXY} together with Borel-Cantelli's Lemma, we conclude that { there exists $\delta \in (0,\beta)$ such that }
\begin{equation}\label{eq_4.12}
\liminf_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_k^X \um_{A_{k, \delta,\beta}} \ge \liminf_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_0^{Y^k} \um_{A_{k, \delta,\beta}}\,, \quad  \text{ a.s.}\,.
\end{equation}
Note that
\begin{align*}
    e_0^{Y^k} = \um_{\{\sum_{i = k+1}^m\xi_{i} \neq 0, \, \forall \, m\ge k + 1\}} = \um_{\{\sum_{i = 1}^m\xi_{i} + Y_0\neq \sum_{i = 1}^k\xi_{i} + Y_0, \, \forall \, m\ge k + 1\}} =e^Y_k\,,
\end{align*}
where $Y=Y^0$ on the RHS above denotes a random walk with i.i.d. increments $\{\xi_i\}_{i\geq 1}$. 
Hence
\begin{equation}\label{eq_4.13}
    \liminf_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_0^{Y^k} \um_{A_{k, \delta,\beta}} = \liminf_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_k^{Y} \um_{A_{k, \delta,\beta}}\,. 
\end{equation}
Using again Lemma~\ref{lemma_1} and the known fact that $\lim_{n \to \infty} \frac{|\mathcal{D}_n^Y|}{n} = \pi_d$ (see e.g.~\cite{spitzer2001principles} page 39) we obtain that 
\begin{equation}\label{eq_4.14}
\lim_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_k^Y \um_{A_{k, \delta,\beta}} = \pi_d\,, \quad  \text{ a.s.}\,.
\end{equation}
Then,  by equations \eqref{eq_4.10},\eqref{eq_4.11},\eqref{eq_4.12},\eqref{eq_4.13} and \eqref{eq_4.14}, we obtain that
$$
    \liminf_{n \to \infty} \frac{|\Rr_n^X|}{n} \ge \pi_d \,, \quad  
    \text{ a.s.}\,.
$$
\end{proof}

\begin{proof}[Proof of Lemma~\ref{compXY}] 
To avoid clutter  we will denote $A_{k,\delta, \beta}$ just by $A_{k,\delta}$.
%
Let $\nu_k^X$ be the first time the process $X$ returns to the site it visited at time $k$.  We also introduce the sequence $\{ \tau_i^k \}_{i \ge 0}$ where $\tau_i^k$ for $i \ge 1$ represents the $i$-th time  the  random walk gets excited  after time $k$. Specifically, 
\begin{align*}
& \nu^{X}_k:= \inf \{n \geq 1: X_{k+n}= X_{k}\}\,,
\\
& \tau^k_0\equiv 0, \text{ and }  \tau_i^k:=\inf\{n> \tau^k_{i-1}: X_{k+n} \text{ gets excited}\}, \text{ for $i\geq 1$}\,.
\end{align*}

For $k \geq 1$, let us also define a sequence of independent random variables $\{H_j^k\}_{j \ge 1}$, such that each $H_j^k$ has a geometric distribution with parameter {$(k + j)^{-\beta}$ for all $j \ge 1$ and $\beta \in (0,1]$}. Additionally, we introduce the following definitions   
\begin{align*}
& \mathcal{G}_m^k = \sum_{j = 1}^m H_j^k \,, \, 
\\
& G^k_0\equiv 0 \text{ and }  G^k_i:= \inf\{\ell > G_{i-1}^k: Z_{\ell + k} =1\},  \text{ for $i\geq 1$}\,,
\end{align*}
where, { $Z_\ell=\um_{\{U_\ell \leq  \ell^{-\beta}\}}$}.
%\textcolor{red}{For each fixed $k \ge 1$ we define a coupling $\hat{\mathbb{P}}^k$ between the excited random walk $X$ and the random walk $Y$ with i.i.d. increments, defined such that $Y_0 = X_k$ and $Y_n := X_k + \sum_{i = k + 1}^{k + n} \xi_i$ for $n \ge 1$.} Suppose we have $\delta \in (0, 1/2)$. The first step in our proof is to establish the following
% \begin{equation*}
% \sum_{k = 1}^{\infty} \hat{\mathbb{P}} \left( e_k^{X} \um_{A_{k, \delta}} < e_k^{Y} \um_{A_{k, \delta}} \right) < \infty \,.   
% \end{equation*}
%
What we are after is to provide an upper bound for $\PP ( e_k^{X} \um_{A_{k, \delta}} < e_0^{Y^k} \um_{A_{k, \delta}} )$ for all $k \ge 1$. The process $X$ can be rewritten as (see, ~\eqref{xn-incremento2})
$$
X_0 = 0, \text{ and }\; X_n  = \sum_{i=1}^n \xi_i + \sum_{i=1}^n\um_{B_i}\big( \gamma_i - \xi_i\big) \, , \ n\ge 1\,,
$$
where {$B_i:= E_{i-1}^c \cap \{U_i \le i^{-\beta}\}$} for any $i \ge 1$. Then, we have that
\begin{equation*}
\begin{split}
 \mathbb{P}( e^{X}_k \um_{A_{k,\delta}} < e^{Y^k}_0 \um_{A_{k, \delta}}) &= \mathbb{P}(e^{X}_k=0, e^{Y^k}_0 =1, A_{k, \delta}) 
\\
& = \mathbb{P}(\nu^{X}_k < +\infty, e^{Y^k}_0 = 1, A_{k,\delta}) 
\\
& \le \sum_{m=1}^{\infty} \mathbb{P}\left( \tau_{m}^k < \nu^{X}_k \leq \tau_{m+1}^k, A_{k, \delta} \right)\,.
\end{split}
\end{equation*}
On the event $\{\tau_m^k < \nu_k^X \le \tau_{m+1}^k$\} we have that
$$
    0 = X_{\nu_k} = \sum_{j=k + 1}^{k + \nu_k^X} \xi_i + \sum_{j= k + 1}^{k + \nu_k^X}\um_{B_i}\big( \gamma_i - \xi_i\big) = \sum_{j=k + 1}^{k + \nu_k^X} \xi_i + \sum_{j= 1}^{m}\big( \gamma_{\tau_j^k} - \xi_{\tau_j^k}\big)\,. 
$$
Since $\tau^k_i\geq G^k_i$ for all $i\geq 0$ and on the event $A_{k, \delta}$ it holds that $G_i^k >  i + \lfloor k^{\delta}\rfloor$, we obtain that
\begin{equation*}
\begin{split}
& \mathbb{P}  ( e^{X}_k \um_{A_{k,\delta}} < e^{Y^k}_0 \um_{A_{k, \delta}})
\\
& \le \sum_{m=1}^{\infty} \sum_{\ell = m}^{\infty} \mathbb{P}\Big( G_m^k < \nu^{X}_k, \sum_{j=k+1}^{k+\nu^{X}_k} \xi_j = \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big), G_m^k = \ell + \lfloor k^{\delta} \rfloor, A_{k, \delta} \Big)
\\
& \leq \sum_{m=1}^{\infty} \sum_{\ell=m}^\infty \sum_{n=\ell+\lfloor k^\delta\rfloor + 1}^{\infty} \mathbb{P}\Big( \nu^{X}_k=n, \sum_{j=k+1}^{k+n} \xi_j = \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big), G_m^k = \ell + \lfloor k^\delta\rfloor \Big) 
\\
& \leq \sum_{m=1}^{\infty} \sum_{\ell=m}^\infty \sum_{n=\ell+\lfloor k^\delta\rfloor + 1}^{\infty} \mathbb{P}\Big(\sum_{j=k+1}^{k+n}\xi_j = \sum_{j=1}^{m}\big(\xi_{\tau_j^k} - \gamma_{\tau_j^k}\big), G_m^k = \ell + \lfloor k^\delta\rfloor \Big) \,.
\end{split}    
\end{equation*}

Note that 
$$
  \sum_{j=1}^{m}\big(\xi_{\tau_j^k} - \gamma_{\tau_j^k}\big) =  \sum_{j=1}^{m}\xi_{\tau_j^k}  -  \Big[m\mu + \sum_{j=1}^{m}\big(\gamma_{\tau_j^k} - \mu\big)\Big] \,, 
$$
where $\mu$ denote the mean vector of $\gamma$ and  by the Central Limit Theorem, both terms $\sum_{j=1}^{m}\xi_{\tau_j^k} $ and $\sum_{j=1}^{m}\big(\gamma_{\tau_j^k} -\mu) $ are of order $\sqrt{m}$. In view of this, let $\alpha \in (1/2,1)$ be a parameter to be determined later. For $m\geq 1$,  let us define 
\[
D_m:= \left\{x+y: x \in B(0, 2Km^\alpha) \text{ and } y \in B(m\mu, 2Km^\alpha)\right\}\,,
\]
where   $B(a, R):=\{x\in \mathbb{Z}^d: \Vert x-a\Vert^2\leq R\}$ with  $a \in \mathbb{Z}^d$ and $R \in [0,+\infty)$. 

Then we have that
\begin{equation}\label{eq:decomposition}
\begin{split}
& \mathbb{P}\Big(\sum_{j=k+1}^{k+n}\xi_j = \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k}\big), G_m^k = \ell + \lfloor k^\delta\rfloor \Big) 
=  
\\
& \sum_{z \in D_m} \mathbb{P}\Big(
%\nu^{\rm ERW}_k=n,
\sum_{j=k+1}^{k+n}\xi_j =z, \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) = z, G_m^k = \ell + \lfloor k^\delta\rfloor  \Big)
\\
&+ \sum_{z \in D^\complement_m} \mathbb{P} \Big(
%\nu^{\rm ERW}_k=n, 
\sum_{j=k+1}^{k+n}\xi_j = z, \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) = z, G_m^k = \ell + \lfloor k^\delta\rfloor \Big)\,.    
\end{split}
\end{equation}

We will analyze the two terms on the RHS of ~\eqref{eq:decomposition} separately. For the  first sum portion it holds that
\begin{equation}\label{eq_sum1<1}
\begin{split}
\sum_{z \in D_m} & \mathbb{P} \Big(
\sum_{j=k+1}^{k+n} \xi_j = z, \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) = z, G_m^k = \ell + \lfloor k^\delta\rfloor \Big)
\\
& \leq \sum_{z \in D_m} \mathbb{P}\Big(
\sum_{j=k+1}^{k+n}\xi_j = z \Big) \mathbb{P} ( G_m^k = \ell + \lfloor k^\delta\rfloor) 
% \\
% & \leq |D_m| \frac{C_d}{n^{d/2}} \hat{\mathbb{P}}(A_k, G_m^k = \ell + \lfloor k^\delta\rfloor) 
\\
& \leq (4Km^\alpha)^d \frac{C_d}{n^{d/2}} \mathbb{P}( G_m^k = \ell + \lfloor k^\delta\rfloor)\,,    
\end{split}    
\end{equation}
where, in the second inequality in~\eqref{eq_sum1<1} we use the fact that $|D_m| \le (4Km^{\alpha})^d$ and the Local Central Limit Theorem 
% (see inequality (2.4) in \cite[Theorem 2.1.1]{lawler2010random} and commentary in page 24)  
see, e.g., Inequality (2.8) in \cite[Theorem 2.1.3]{lawler2010random}  and the fact that $\Bar{p}_n(x) \le C_d n^{-d/2}$, with $C_d$ a positive constant. For the second term in~\eqref{eq:decomposition} we have
\begin{equation}\label{eq_sum<2}
\begin{split}
&\sum_{z \in D^c_m} \mathbb{P}\Big(
%\nu^{\rm ERW}_k=n, 
\sum_{j=k+1}^{k+n} \xi_j = z, \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) = z, G_m^k = \ell + \lfloor k^\delta\rfloor \Big)
\\
& \le \sum_{z \in D^c_m \cap B(0,2Km)} \mathbb{P}\Big(
%\nu^{\rm ERW}_k=n, 
\sum_{j=k+1}^{k+n} \xi_j = z,\sum_{j=1}^{m}\big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) = z \Big) %, A_k, G_m^k = \ell + \lfloor k^\delta\rfloor \right)
\\
&\leq \mathbb{P}\Big(
%\nu^{\rm ERW}_k=n, 
\sum_{j=k+1}^{k+n} \xi_j \in B(0,2Km) \setminus D_m, \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) \in B(0,2Km) \setminus D_m \Big) %, A_k, G^k_m = \ell + \lfloor k^\delta\rfloor \right) 
\\
&\leq \mathbb{P}\Big(
%\nu^{\rm ERW}_k=n, 
\sum_{j=k+1}^{k+n} \xi_j \in B(0,2Km) \setminus D_m \Big)^{1/2} \mathbb{P}\Big( \sum_{j=1}^{m} \big( \xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) \in B(0,2Km) \setminus D_m \Big)^{1/2} \,, \end{split}    
\end{equation}
where, in the last  inequality above, we used Cauchy-Schwarz inequality. Regarding the first term in~\eqref{eq_sum<2}, by using again the Local Central Limit Theorem, it holds that 
\begin{equation}\label{eq_sum<2.1}
\begin{split}
\mathbb{P}\Big(
%\nu^{\rm ERW}_k=n, 
\sum_{j=k+1}^{k+n}\xi_j \in B(0,2Km) \setminus D_m \Big) & = \sum_{z \in D^c_m \cap B(0,2Km)} \mathbb{P}\Big(
%\nu^{\rm ERW}_k=n, 
\sum_{j=k+1}^{k+n} \xi_j = z\Big)
\\
& \leq \frac{C_d}{n^{d/2}} |B(0,2Km)|\,.
\end{split}
\end{equation}
For the second term in~\eqref{eq_sum<2}, let us define $F := B(0,2Km) \setminus D_m$, $G := B(0,2Km) \setminus B(0,2Km^{\alpha})$ and $A := B(0, 2Km) \setminus B(m\mu, 2Km^{\alpha})$. We then  obtain
\begin{equation}\label{eq_sum<2.2}
\begin{split}
& \mathbb{P}\Big(\sum_{j=1}^{m} \big(\xi_{\tau_j^k} - \gamma_{\tau_j^k} \big) \in F \Big) \leq \mathbb{P}\Big( \sum_{j=1}^{m} \xi_{\tau^k_j} \in G \Big)  + \mathbb{P}\Big(\sum_{j=1}^{m} \gamma_{\tau^k_j} \in A \Big) %\Big| A_k, G^k_m = \ell + \lfloor k^\delta\rfloor \right)
\\
& = \mathbb{P}\Big(\sum_{j=1}^{m}\xi_{j} \in G \Big) + \hat{\mathbb{P}}\Big(\sum_{j=1}^{m}\gamma_{j} \in A \Big) 
\\
& = \mathbb{P}\Big(\sum_{j=1}^{m}\xi_{j} \in G \Big) + \mathbb{P}\Big( \sum_{j=1}^{m}(\gamma_{j}-\mu) \in B(-m\mu,2Km) \setminus  B(0,2Km^\alpha)\Big) 
% \\
% & \leq 2|B(0,2Km)| \Hat{C}_{d,K} \Big[ e^{-2dK^2m^{2\alpha-1}}\Big(\frac{1}{m^{\frac{d}{2}}} + m^{\frac{7d-2}{2}} + \frac{1}{m^{\frac{d+2}{2}}} \Big)  + \frac{1}{m^{\frac{9d-1}{2}}} \Big]
% \\
% & \leq 2|B(0,2Km)| \Hat{C}_{d,K} \Big(m^{4d} e^{-2dK^2m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{2}}} \Big)\,. 
\\
& 
\leq 2|B(0,2Km)| \Hat{C}_{d,K} \Big[ e^{-2d\zeta K^2m^{2\alpha-1}}\Big(\frac{1}{m^{\frac{d}{2}}} + \frac{(2Km)^{8d}}{m^{4d}m^{\frac{d+2}{2}}} + \frac{1}{m^{\frac{d+2}{2}}} \Big)  + \frac{1}{m^{\frac{9d-1}{2}}} \Big]
\\
& 
\leq 2|B(0,2Km)| \widetilde{C}_{d,K} \Big(m^{4d} e^{-2d \zeta K^2m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{2}}} \Big)\,. 
\end{split}    
\end{equation}
In~\eqref{eq_sum<2.2}, we applied Lemma~\ref{lem: iid} to achieve the first equality. For the first inequality, we utilized the Local Central Limit Theorem see, e.g., Inequality (2.8) in \cite[Theorem 2.1.3]{lawler2010random} with $k=8d$
 and the fact that $\Bar{p}_n(x) \le C_d n^{-d/2}\exp(-||x||^2 \zeta d/2n)$), with $\zeta >0$ and the constant $C_d$ depending on the covariance matrix of $\xi$ (see, e.g., Equations~2.2 and 1.1 and Proposition~1.1.1 (c) in \cite{lawler2010random}).  
 %along with the observation that $(2Km^{\alpha})^2 > m$, which follows since, by definition, $\alpha > 1/2$. The final inequality is derived from the fact that $\alpha < 1$. 
%
Thus, using~\eqref{eq_sum<2.1} and~\eqref{eq_sum<2.2} we obtain that the rightmost term in~\eqref{eq_sum<2} is bounded above by 
\begin{equation}\label{eq:sum<2.3}
\begin{split}
%\sum_{z \in D^\complement_m} &\hat{\mathbb{P}}\left(
%\nu^{\rm ERW}_k=n, 
%\sum_{j=k+1}^{k+n}\xi_j =z, \sum_{j=1}^{m}\left(\xi_{\tau_j^k} - \gamma_{\tau_j^k}\right)=z \right) %, A_k, G_m^k = \ell + \lfloor k^\delta\rfloor  \right)
%\\
\Big[ 2 & |B(0,2Km)| \widetilde{C}_{d,K} \Big(m^{4d} e^{-2d\zeta K^2m^{2\alpha-1}} + m^{-\frac{9d-1}{2}} \Big) \Big]^{1/2} \Big[ \frac{C_d}{n^{d/2}} |B(0,2Km)|\Big]^{1/2}
%\Big(4 & |B(0,2Km)|  \frac{C_d^2}{n^{d/2}}\Big)^{1/2} \Big( 2m^{3d+9} e^{-\frac{d(2Km^\alpha)^2}{2m}} + m^{-(d+8)}\Big)^{1/2} %\hat{\mathbb{P}}\left(A_k, G_m^k = \ell + \lfloor k^\delta\rfloor  \right)
\\
& \le \frac{m^d\Tilde{C}_{d,K}}{n^{d/4}} \Big(m^{4d} e^{-2d\zeta K^2m^{2\alpha-1}} + m^{-\frac{9d-1}{2}} \Big)^{1/2} 
\\
& \le \frac{m^d\Tilde{C}_{d,K}}{n^{d/4}} \Big(m^{2d} e^{-d\zeta K^2 m^{2\alpha-1}} + m^{-\frac{9d-1}{4}} \Big)\,.
%&\leq 2(2Km)^{d/2} \frac{C_d}{n^{d/4}} \Big( 2^{\frac{1}{2}}m^{\frac{3}{2}(d+3)} e^{-\frac{d(2Km^\alpha)^2}{4m}} + m^{-\frac{1}{2}(d+8)}\Big) \,.
% \hat{\mathbb{P}}\left(A_k, G_m^k = \ell + \lfloor k^\delta\rfloor  \right) 
% \\
% &=2^{1/2} (2Km)^d \left(\frac{C_d}{m^{d/2}}\right)^{1/2}  e^{-\frac{d(2Km^\alpha)^2}{4m}} \left(\frac{C_d}{n^{d/2}}\right)^{1/2} 
% %\hat{\mathbb{P}}\left(A_k, G_m^k = \ell + \lfloor k^\delta\rfloor  \right) 
% \,.
\end{split}
\end{equation}
Overall, by~\eqref{eq_sum1<1} and~\eqref{eq:sum<2.3} we obtain that

\begin{equation*}
\begin{split}
& \mathbb{P}  ( e^{X}_k \um_{A_{k,\delta}} < e^{Y}_k \um_{A_{k, \delta}})  \leq\underbrace{\sum_{m=1}^{\infty} \sum_{\ell=m}^\infty  \sum_{n=\ell+ \lfloor k^\delta\rfloor + 1}^{\infty} (4Km^\alpha)^d \frac{C_d}{n^{d/2}} \mathbb{P}(G_m^k = \ell + \lfloor k^\delta\rfloor) }_{SUM_1}
\\
&+\underbrace{\sum_{m=1}^{\infty} \sum_{\ell = m}^\infty \sum_{n = \ell + \lfloor k^\delta\rfloor + 1}^{\infty} \frac{m^d\Tilde{C}_{d,K}}{n^{d/4}} \Big(m^{2d} e^{-d\zeta K^2 m^{2\alpha-1}} + m^{-\frac{9d-1}{4}} \Big) }_{SUM_2}\,. %\hat{\mathbb{P}}\left(A_k, G_m^k = \ell + \lfloor k^\delta\rfloor \right)}_{SUM_2} \,. 
\end{split}
\end{equation*}

We will prove that $ \sum_{k \ge 1}\mathbb{P} ( e^{X}_k \um_{A_{k,\delta}} < e^{Y^k}_0 \um_{A_{k, \delta}}) < \infty$ by demonstrating that both $SUM_1$ and $SUM_2$ are summable over $k$. We begin with $SUM_1$  for which we obtain that 
\begin{equation*}
\begin{split}
& SUM_1 = \sum_{m=1}^{\infty} (4Km^\alpha)^d \sum_{\ell=m}^\infty \mathbb{P}(G_m^k = \ell + \lfloor k^\delta\rfloor) \sum_{n=\ell+ \lfloor k^\delta\rfloor + 1}^{\infty}  \frac{C_d}{n^{d/2}} 
\\
& \le C_d \sum_{m=1}^{\infty} (4Km^\alpha)^d \sum_{\ell = m}^\infty \mathbb{P}( G_m^k = \ell + \lfloor k^\delta\rfloor) \int_{\ell + \lfloor k^\delta\rfloor}^\infty  \frac{1}{x^{d/2}}dx
\\
& \overset{d>2}{=} \frac{C_d (4K)^d}{d/2-1}\sum_{m=1}^{\infty}    m^{\alpha d}   \sum_{\ell=m}^\infty \mathbb{P} (G_m^k = \ell + \lfloor k^\delta\rfloor) \frac{1}{(\ell + \lfloor k^\delta\rfloor)^{d/2-1}}
\\
& \leq C_{d,K} \sum_{m=1}^{\infty}    m^{\alpha d}   \sum_{\ell=m}^\infty \mathbb{P}(G_m^k = \ell) \frac{1}{(\ell + \lfloor k^\delta\rfloor)^{d/2-1}} 
\\
& \leq C_{d,K} \sum_{m=1}^{\infty}    m^{\alpha d} \,\mathbb{E}\Big[ \frac{1}{( G_m^k + \lfloor k^\delta\rfloor)^{d/2-1}} \Big] \,.
\end{split}    
\end{equation*}

We first note that $G^k_m \ge m$ and also that stochastically dominates $\mathcal{G}_m^k$, where $ \mathcal{G}_m^k = \sum_{j=1}^m H^k_j$, with $\{H^k_j\}_{j\geq 1}$  independent random variables with geometric distribution with parameter {$(k+j)^{-\beta}$} for each $j \ge 1$. Now, we  compute an upper bound for $\mathbb{E}[(G_m^k + \lfloor k^\delta \rfloor)^{1-d/2}]$. 
{ Given $\lambda<1$, we decompose the latter expectation as follows
\begin{equation*}
\begin{split}
&\mathbb{E}[(G_m^k + \lfloor k^\delta \rfloor)^{1-d/2}] = 
\\
& \mathbb{E}\Big[ \frac{1}{( G_m^k + \lfloor k^\delta\rfloor)^{d/2-1}} ; G_m^k < \frac{\lambda m^{1+\beta}}{1+\beta} \Big] +  \mathbb{E}\Big[ \frac{1}{( G_m^k + \lfloor k^\delta\rfloor)^{d/2-1}} ; G_m^k \ge \frac{\lambda m^{1+\beta}}{1+\beta} \Big]
\\
& \leq \frac{1}{( m + \lfloor k^\delta\rfloor)^{d/2-1}} \mathbb{P} \Big[ G_m^k < \frac{\lambda m^{1+\beta}}{1+\beta} \Big] + \frac{(1+\beta)^{d/2-1}}{(\lambda m^{1+\beta} + (1+\beta) \lfloor k^\delta\rfloor)^{d/2-1}}
\\
& \leq \frac{1}{( m + \lfloor k^\delta\rfloor)^{d/2-1}} \mathbb{P} \Big[ \mathcal{G}_m^k < \frac{\lambda m^{1+\beta}}{1+\beta} \Big] + \frac{(1+\beta)^{d/2-1}}{(\lambda m^{1+\beta} + (1+\beta) \lfloor k^\delta\rfloor)^{d/2-1}}\,.
\end{split}
\end{equation*}
Then, using Lemma~\ref{lem:geo_sum_bound} we obtain that  $\PP[\mathcal{G}_m^k < \frac{\lambda m^{1+\beta}}{1+\beta}]\leq e^{-\frac{C_{\lambda}}{1+\beta}m }$. 
%
Choosing $\alpha=1/2 + 1/(cd)>1/2$ in $SUM_1$, with $c$ is a sufficiently large positive constant, and setting $\rho_{\beta, \lambda}:= \frac{1+\beta}{\lambda}$ and $\eta_{\beta, \lambda}:= \frac{C_\lambda}{1+\beta}$ (both positive),  we obtain  
\begin{equation*}
\begin{split}
& SUM_1  \leq C_{d,K} \Big(\sum_{m=1}^{\infty}    \frac{m^{d/2 + 1/c} e^{-\eta_{\beta, \lambda}m} }{( m + \lfloor k^\delta\rfloor)^{d/2-1}} +  \sum_{m = 1}^{\infty} \frac{\rho_{\beta, \lambda}^{d/2-1} m^{d/2 + 1/c}}{\big(m^{1+\beta} + \rho_{\beta, \lambda} \lfloor k^\delta\rfloor\big)^{d/2-1}} \Big)\,.
\end{split}
\end{equation*}
The first summation above can be bounded by 
\begin{align*}
\sum_{m=1}^{\infty} &   \frac{m^{d/2 + 1/c} e^{-\eta_{\beta, \lambda}m} }{( m + \lfloor k^\delta\rfloor)^{d/2-1}} \leq \int_{\lfloor k^\delta \rfloor}^{\infty} x^{1+ 1/c}e^{-\eta_{\beta, \lambda}x}dx 
\\
&\leq  \frac{1}{\eta_{\beta, \lambda}} e^{-\eta_{\beta, \lambda} \lfloor k^\delta \rfloor} \left( \lfloor k^\delta \rfloor^{1+1/c}  + \frac{1+1/c}{\eta_{\beta, \lambda}} \big(\lfloor k^\delta \rfloor^{1/c} + \frac{1}{\eta_{\beta, \lambda}}\big) \right)\,,
\end{align*}
which is summable in $k$. 
The second summation above instead can be bounded by 
\begin{align*}
&\sum_{m = 1}^{\infty} \frac{\rho_{\beta, \lambda}^{d/2-1} m^{d/2 + 1/c}}{\big(m^{1+\beta} + \rho_{\beta, \lambda} \lfloor k^\delta\rfloor\big)^{d/2-1}}  \leq\int_{0}^\infty \frac{\rho_{\beta, \lambda}^{d/2-1} x^{d/2 + 1/c}}{\big(x^{1+\beta} + \rho_{\beta, \lambda} \lfloor k^\delta\rfloor\big)^{d/2-1}} dx
\\
&= \frac{\rho_{\beta, \lambda}^{d/2-1}}{1+\beta}\int_{0}^\infty \frac{ y^{\frac{d/2 + 1/c - \beta}{1+\beta}}}{\big(y + \rho_{\beta, \lambda} \lfloor k^\delta\rfloor\big)^{d/2-1}}   dy \leq \frac{\rho_{\beta, \lambda}^{d/2-1}}{1+\beta} \int_{\rho_{\beta, \lambda}\lfloor k^\delta \rfloor}^{\infty} y^{-\frac{\beta (d/2+1) -1/c}{1+\beta} +1}dy
\\
&\overset{(*)}{=} \frac{\rho_{\beta, \lambda}^{d/2-1}}{ \beta(d/2+1) - 1/c -2(1+\beta)} \frac{1}{\big(\rho_{\beta, \lambda} \cdot \lfloor  k^\delta \rfloor\big)^{\frac{1}{1+\beta} \big( \beta(d/2+1) - 1/c\big) -2} }\,, 
\end{align*}
where, in the second equality above we used the change of variable  $y = x^{1+\beta}$. Note that in $(*)$ we assumed that 
$2-\frac{\beta}{1+\beta}(d/2 +1) + \frac{1/c}{1+\beta}<0$, which is satisfied by choosing  $d>2\frac{\beta+2}{\beta}$ and $c$ sufficiently large. 
 The expression on the RHS of $(*)$ is summable in $k$ whenever $d$ and $\delta$ satisfy the following inequality 
\begin{align}\label{eq:thres1}
\delta \left( \frac{\beta}{1+\beta}(d/2+1) - \frac{1}{c(1+\beta)} -2 \right)>1\,.    
\end{align}
Note that, if  $d$ satisfy 
\begin{equation}\label{eq:threshold}
d> 2 \frac{\beta^2 + 3 \beta +1}{\beta^2}\,,  
\end{equation}
we can choose  $\delta$ sufficiently close to $\beta$  and $c$ sufficiency large such that the summability condition in \eqref{eq:thres1} is satisfied. 
%
% As far as $SUM_1$ is concerned, we thus obtain 
% \begin{equation}\label{eq:sum1_2}
% \begin{split}
% SUM_1& \leq   \frac{C_{d,K}}{\eta_{\beta, \lambda}} e^{-\eta_{\beta, \lambda} \lfloor k^\delta \rfloor} \left( \lfloor k^\delta \rfloor^{1+1/c}  + \frac{1+1/c}{\eta_{\beta, \lambda}} \big(\lfloor k^\delta \rfloor^{1/c} + \frac{1}{\eta_{\beta, \lambda}}\big) \right)
% \\
% + &\frac{C_{d,K} \,\rho_{\beta, \lambda}^{d/2-1}}{ \beta(d/2+1) - 1/c -2(1+\beta)} \frac{1}{\big(\rho_{\beta, \lambda} \cdot \lfloor  k^\delta \rfloor\big)^{\frac{1}{1+\beta} \big( \beta(d/2+1) - 1/c\big) -2} } \,.
% \end{split}    
% \end{equation}
%


 
We now compute an upper bound for $SUM_2$.
\begin{equation}\label{eq:sum2_1}
\begin{split}
& SUM_2 = \Tilde{C}_{d,K} \sum_{m=1}^{\infty} m^d \Big( m^{2d} e^{-d\zeta K^2 m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{4}}} \Big) \sum_{\ell = m}^\infty \sum_{n = \ell + \lfloor k^\delta\rfloor + 1}^{\infty} n^{-d/4}
\\
& \le \Tilde{C}_{d,K} \sum_{m=1}^{\infty} m^d \Big( m^{2d} e^{-d\zeta K^2 m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{4}}} \Big) 
\sum_{\ell = m}^\infty \frac{1}{(\lfloor k^\delta\rfloor + \ell)^{\frac{d}{4}-1}}
\\
& \le \Tilde{C}_{d,K} \sum_{m=1}^{\infty} m^d \Big( m^{2d} e^{-d\zeta K^2 m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{4}}} \Big) 
\sum_{\ell = \lfloor k^\delta\rfloor + m}^\infty \frac{1}{\ell^{\frac{d}{4}-1}}
\\
& \le \Tilde{C}_{d,K} \sum_{m=1}^{\infty} m^d \Big( m^{2d} e^{-d\zeta K^2 m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{4}}} \Big)  \frac{1}{(m+ \lfloor k^\delta\rfloor -1)^{\frac{d}{4}-2}}
\\
& \le \frac{C_{d,K}'}{\lfloor k^\delta\rfloor^{d/4-2}} \sum_{m=1}^{\infty} m^d \Big( m^{2d} e^{-d\zeta K^2 m^{2\alpha-1}} + \frac{1}{m^{\frac{9d-1}{4}}} \Big) \le \frac{C_{d,K}''}{\lfloor k^\delta\rfloor^{d/4-2}} \,,
\end{split}    
\end{equation}
where, in the last inequality of~\eqref{eq:sum2_1} we used that $\alpha > 1/2$. 
%
Observe that $SUM_2$ is summable in $k$ whenever $\delta (d/4-2)>1$. As before, if  $d> 4 \frac{2\beta +1}{\beta}$,  choosing $\delta$ arbitrarily close to $\beta$ we obtain that the summability is assured. Using the latter condition together with \eqref{eq:threshold},  we finally obtain that if  $d> \max\{ 2 \frac{\beta^2 + 3 \beta +1}{\beta^2}, 4 \frac{2\beta +1}{\beta}\}$, then there exists $\delta \in (0,\beta)$ such that 
\begin{equation*}
\begin{split}
& \sum_{k=1}^\infty \mathbb{P}  ( e^{X}_k \um_{A_{k,\delta}} < e^{Y^k}_0 \um_{A_{k, \delta}}) 
%\\
% & \le \sum_{k = 1}^\infty \left(C_{d,K,c}'' \Big( \frac{1}{(\lfloor k^\delta \rfloor)^{(3 -1/c)}} + \frac{1}{\lfloor k^{\delta} \rfloor^{d/6 - 3/2 -2/3c}} \Big) +  \frac{C_{d,K}''}{\lfloor k^\delta\rfloor^{d/4-2}} \right)
< \infty \,.
\end{split}
\end{equation*}
Note that $2 \frac{\beta^2 + 3 \beta +1}{\beta^2}< 4 \frac{2\beta +1}{\beta}$ for $\beta$ close to $1$, whereas the opposite occurs when $\beta$ is close to $0$. 
}
\end{proof}

%{\color{red} I will state the  result as a lemma.... something like
%\begin{lemma}\label{compXY}
%Let  $X$ be a $p_n$-\Nametwo{} in direction $\ell$, on $\ZZ^d$ with $d\geq 22$, $p_n= \mathcal{C} n^{-\beta} \wedge 1$ and $\beta \ge 1/2$ and let $Y$ denote a random walk on $\ZZ^d$ with i.i.d. increments given by  $\{\xi_i\}_i$. For $\delta \in (0, 1/2)$ and for every fixed $k\geq 1$ there exists a coupling  $\hat{\mathbb{P}}_k$ between $X$ and  $Y$ such that 
%\begin{equation*}
%\sum_{k = 1}^{\infty} \hat{\mathbb{P}}_k \left( e_k^{X} \um_{A_{k, \delta}} < e_k^{Y} \um_{A_{k, \delta}} \right) < \infty \,.   
%\end{equation*}
%\end{lemma}

%\begin{proof}[Proof of Proposition~\ref{prop:RangeERW_lower}]
%Note that $|\Rr_n^X| \ge |\mathcal{D}_n^X|$, since if $x \in \mathcal{D}_n^X$ then $x \in \Rr_n^X$ (and it is possible for a $x \in \Rr_n^X$ to be  revisited later on, thus implying $x \notin \mathcal{D}_n^X $). Therefore, it holds that 
%\begin{align*}
%\liminf_{n \to \infty} \frac{|\Rr_n^X|}{n} \ge \liminf_{n \to \infty} \frac{|\mathcal{D}_n^X|}{n} = \liminf_{n \to \infty} \frac{1}{n}\sum_{k=1}^n e_k^X \um_{A_{k,\delta}} + \liminf_{n \to \infty} \frac{1}{n}\sum_{k=1}^n e_k^X \um_{A_{k,\delta}^c}\,.  
%\end{align*}
%For $\delta \in (0, 1/2)$, Lemma~\ref{lemma_1} implies that $\liminf_{n \to \infty} \frac{1}{n}\sum_{k=1}^n e_k^X \um_{A_{k,\delta}^c}=0$ a.s., whereas from Lemma~\ref{compXY} together with Borel-Cantelli's Lemma we conclude that 
%\begin{equation*}
%\liminf_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_k^X \um_{A_{k, \delta}} \ge \liminf_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_k^Y \um_{A_{k, \delta}} \,, 
%\end{equation*}
%almost surely \texttt{with respect to which measure....}. Then using again Lemma~\ref{lemma_1} and the known fact that $\lim_{n \to \infty} \frac{|\mathcal{D}_n^Y|}{n} = \pi_d$ (see e.g.~\cite{spitzer2001principles} page 39) we obtain that 
%\[
%\liminf_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n e_k^Y \um_{A_{k, \delta}} = \pi_d \,, \text{a.s..}
%\]
%\end{proof}
%}