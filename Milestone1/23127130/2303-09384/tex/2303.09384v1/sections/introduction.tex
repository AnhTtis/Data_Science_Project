\section{Introduction} \label{sec:introduction}

%Increased computing power - LLMs with billions of parameters - trained on tons of different kinds of data - LLMs for automatic code generation - examples of LLMs - NL query can generate code - the functional correctness of it is evaluated - already used in coding tools such as copilot. 
%Increased computation power has led to the emergence of several Large Language Models (LLMs) with billions of parameters. A few examples include GPT-3 \cite{gpt-3}, GPT-Neo, Codex \cite{codex}, PolyCoder \cite{polycoder}, CodeT5 \cite{codet5} and so on. These LLMs are trained on a broad range of textual data such as news, articles and online forums. Furthermore they are also \cite{HanZDGLHQYZZHHJ21}. In addition to natural language processing capabilities, they have demonstrated their competence in tasks such as code completion and generation of functional code from natural language (NL) descriptions \cite{DesaiGHJKMRR16}. Models that can generate code for a given NL description can significantly reduce the efforts of a developer. 

Increased computation power has led to the emergence of several Large Language Models (LLMs) encompassing billions of parameters with high natural language processing capabilities. LLMs like Codex \cite{codex} or PolyCoder \cite{polycoder} are heavily trained on data mined from open-source projects to perform tasks such as code completion, generation, and summarization. Thereby, these models can understand the structure and syntax of various programming languages, as well as common patterns that are used in real-world software development projects. Moreover, they are even capable of producing code from Natural Language (NL) descriptions\cite{HanZDGLHQYZZHHJ21} (e.g., \textit{``generate Python code to create a login page that authenticates a user''}), thus reducing significantly developers' coding efforts.
%They have demonstrated the ability to synthesize code from natural language descriptions \cite{HanZDGLHQYZZHHJ21} by learning  programming languages and common coding practices from popular developer platforms such as GitHub.
%Through the  analysis of large amounts of code data from developer platforms such as GitHub, these models have demonstrated the ability to understand the structure and syntax of various programming languages, as well as common patterns that are used in real-world software development projects. LLMs trained for code generation are thus able to write code that is functional when given a natural language (NL) description of a desired programming task \cite{HanZDGLHQYZZHHJ21}. This can significantly support developers in reducing the time and effort required in writing code. 

%Developers are already leveraging the code-generation capabilities of these models to create real-world applications \cite{Kalliamvakou2022}. For instance, the Codex model is used in GitHub Copilot \cite{copilot}, a tool that can be integrated into IDEs to provide assistance to developers in writing programs. 

\subsubsection*{\textbf{Motivation}}

%At their core, LLMs with code generation capabilities are trained with billions of lines of code from open-source projects, including public GitHub repositories

At their core, such LLMs are trained with billions of lines of code mined from open-source projects, including public GitHub repositories. Despite their large contribution to LLMs' performance, these sources often contain security vulnerabilities stemming from insecure API calls, outdated algorithms/packages, insufficient validation, and poor coding practices, among others \cite{WickertREDM19, PontaPSBD19, Tony2022}. It was observed that around 85\% of the security APIs are misused on GitHub \cite{HazhirpasandGN20}. Hence, it is also possible that the code generated by LLMs may contain security flaws and vulnerabilities.

%in their regular programming tasks to

LLMs are getting more and more popular among software practitioners thanks to tools like GitHub Copilot\cite{Kalliamvakou2022}, which include powerful code completion capabilities. Therefore, as developers start adopting such LLMs to create real-world applications, it becomes critical to assess the security of the code they generate from NL descriptions. Such an assessment would require, in principle, a collection of NL prompts describing security-relevant software instructions. That is, prompts covering scenarios or use cases prone to security vulnerabilities to verify whether LLMs produce secure implementations or not. Nevertheless, to the extent of our knowledge, a dataset of such characteristics has not yet been proposed nor documented in the current literature, which calls for further investigations and efforts in this regard.


%... It is important to evaluate the security of code generated by LLMs in response to NL prompts before they are used in production-level code. A prompt in this context is a natural language query that describes the programming task to be performed. For instance, \textit{"generate Python code to create a login page that authenticates a user"} is an NL prompt example.
%The security of code generated by LLMs in response to natural language queries is yet to be thoroughly researched.
%making it necessary to carefully evaluate the security of this code to ensure the protection of software systems and data. 


\subsubsection*{\textbf{Contribution}}
%Our aim is to facilitate further research on the security of code generated by LLMs in response to natural language (NL) queries. 

In this work, we present \textit{LLMSecEval}, a dataset consisting of 150 NL prompts for assessing the security of code produced by LLMs. Each prompt is a textual description of a piece of software prone to some security vulnerability listed among MITRE's Top 25 Common Weakness Enumeration (CWE) ranking \cite{cwe}. Additionally, the dataset contains secure code examples for each prompt to facilitate comparative evaluations against LLM-generated deployments. We have carefully evaluated the quality of the NL prompts using both language- and content-related metrics. As a practical demonstration, we developed an application that (i) uses GPT-3 and Codex to generate code from the prompts available in LLMSecEval, and (ii) employs CodeQL \cite{codeql}, a code analysis engine, to identify security vulnerabilities in such code.

%we create a dataset of 151 NL queries - covers the top 25 CWE scenarios of 2021 and 2022 - evaluate the quality of such a dataset using different metrics (naturalness, expressiveness, conciseness and content adequacy) - this dataset contains NL queries that are language agnostic and can be used to evaluate any LLMs in the future in terms of security - codeql queries for checking top 25 CWEs in the generated code using these NL descriptions.

%Other ideas: generate the corresponding secure code for each of the descriptions in python, java and C. 
%base code from copilot - basically mining from GitHub. 