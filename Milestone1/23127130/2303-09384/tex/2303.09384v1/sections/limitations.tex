\section{Limitations and Future Improvements}

Currently, we have considered only 18 out of the top 25 CWEs released in 2021 for the generation of our NL prompts dataset. We plan to extend the dataset to cover more CWE scenarios and update it annually based on MITRE's yearly list. This can be achieved using the code examples provided by CWE documentation \cite{cwe} for different weaknesses to generate NL prompts. Additionally, we will also design unit tests for security, tailored to each prompt in our dataset. Another limitation is associated with the language-agnostic nature of the prompts. There are CWEs that are relevant to specific programming languages only. Although we made the prompts in \textit{LLMSecEval} language-agnostic, prompts covering such CWEs may not be suitable to evaluate code across different programming languages.



% language agnostic nature is limited as some attack scenarios are only relevant to certain programming languages
% prompt engineering techniques are not used in the creation of this dataset because our aim is not to create the ideal prompts at the moment, rather evaluate how the models repond to average prompts.

