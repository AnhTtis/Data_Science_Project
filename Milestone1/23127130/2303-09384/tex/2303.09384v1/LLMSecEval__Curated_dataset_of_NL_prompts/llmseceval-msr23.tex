%\documentclass[conference]{IEEEtran}
%\documentclass[10pt,conference,anonym]{IEEEtran}
\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[T1]{fontenc}


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\newcommand\todo[1]{\COMMENTX{TODO: }{{{\color{red}#1}}}}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations
%LLMSecEval: A Curated Dataset of Natural Language Prompts for Evaluating the Security of Generated Code
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
%should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
}

% Catherine Tony, Markus Mutas, Nicolas Diaz Ferreyra, Riccardo Scandariato


\author{
	\IEEEauthorblockN{
	    Catherine Tony, Markus Mutas, Nicol\'{a}s E. D\'{i}az Ferreyra, Riccardo Scandariato
	}
\IEEEauthorblockA{\textit{Institute of Software Security} \\
\textit{Hamburg University of Technology, Germany}\\
\{catherine.tony, markus.mutas, nicolas.diaz-ferreyra, riccardo.scandariato\}@tuhh.de}
	
}

%\author{\IEEEauthorblockN{Anonymous}
%\IEEEauthorblockA{\textit{Institution} \\
%\textit{name of organization (of Aff.)}\\
%Country \\
%email}
%\and
%\IEEEauthorblockN{Anonymous}
%\IEEEauthorblockA{\textit{Institution} \\
%\textit{name of organization (of Aff.)}\\
%Country \\
%email}
%\and
%\IEEEauthorblockN{Anonymous}
%\IEEEauthorblockA{\textit{Institution} \\
%\textit{name of organization (of Aff.)}\\
%Country \\
%email}
%}

\maketitle
\begin{abstract}
%Large Language Models (LLMs) with billions of parameters,  use mined code data from open-source projects to perform tasks such as code completion and code generation. They have shown the ability to synthesize code from natural language descriptions by learning programming languages and common coding practices from platforms like GitHub. Many developers are already using the code-generation capabilities of these models to create real-world applications. However, the security of the code generated by LLMs has not yet been thoroughly researched. In order to understand the extent to which LLMs can be used as reliable interactive tools for secure code generation, we present a dataset called LLMSecEval, consisting of 150 natural language prompts that address common software vulnerabilities in the top Common Weakness Enumeration (CWE) list along with a secure code example for each prompt. We also provide an application to demonstrate the use of the dataset and identify vulnerabilities in code generated by LLMs using the prompts.

 %Large Language Models (LLMs) with billions of parameters are able to perform tasks such as code completion and code generation by using code mined from open-source projects. 

%Large Language Models (LLMs) like Codex can easily perform code completion and code generation tasks as they are trained with billions of publicly-available sources. 

 Large Language Models (LLMs) like Codex are powerful tools for performing code completion and code generation tasks as they are trained on billions of lines of code from publicly available sources. Moreover, these models are capable of generating code snippets from Natural Language (NL) descriptions by learning languages and programming practices from public GitHub repositories. Although LLMs promise an effortless NL-driven deployment of software applications, the security of the code they generate has not been extensively investigated nor documented. In this work, we present \textit{LLMSecEval}, a dataset containing 150 NL prompts that can be leveraged for assessing the security performance of such models. Such prompts are NL descriptions of code snippets prone to various security vulnerabilities listed in MITRE's \textit{Top 25 Common Weakness Enumeration (CWE)} ranking. Each prompt in our dataset comes with a secure implementation example to facilitate comparative evaluations against code produced by LLMs. As a practical application, we show how \textit{LLMSecEval} can be used for evaluating the security of snippets automatically generated from NL descriptions.


%While many developers are using these models to create real-world applications, the security of the code generated by these models has not yet been thoroughly evaluated. To understand the extent to which LLMs can be used as reliable interactive tools for secure code generation, we have created a dataset called LLMSecEval, which includes 150 natural language prompts that address common software vulnerabilities from the top Common Weakness Enumeration (CWE) list, along with a secure code example for each prompt. We also provide an application to demonstrate the use of the dataset and identify vulnerabilities in code generated by large language models using these prompts.
\end{abstract}

%While there is a great potential in this models for generating ...while thise models have a great potential to automatically generate 

%Although LLMs promise a NL-driven deployment of software applications, their security performance has not been yet extensively investigated.





\begin{IEEEkeywords}
LLMs, code security, NL prompts, CWE
\end{IEEEkeywords}

\maketitle

\input{sections/introduction}
\input{sections/related_work}
%\input{sections/background}
\input{sections/dataset-creation.tex}
\input{sections/dataset-description.tex}
\input{sections/dataset-analysis.tex}
\input{sections/dataset-usage.tex}
\input{sections/limitations.tex}
\input{sections/conclusion}
%\input{sections/acknowledgements}
%\bibliographystyle{IEEEtran}
%\bibliography{refs}



%\balance
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,refs}

\end{document}
