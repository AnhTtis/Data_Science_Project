\section{Conclusion}

\textit{LLMSecEval} encompasses 150 NL prompts covering 18 of the Top 25 CWE scenarios from 2021 and their corresponding secure code examples. 
Such a dataset facilitates the security evaluation of code generated by LLMs trained on a large number of open-source projects. These NL prompts are language-agnostic, allowing for the evaluation of code in a variety of programming languages. An example application was developed to showcase the use of the dataset to assess the security of code generated by GPT-3 and Codex. The dataset and the application are available for further experimentation through a public GitHub repository. In the future, we plan to extend to cover more CWEs and use this dataset to evaluate the security of popular LLMs with code generation capabilities.

%CWEPrompts: A Dataset of Natural Language Prompts for Security Evaluation/Assessment
%for the Security Assessment of Large Language Models
