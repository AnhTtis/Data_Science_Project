{
    "arxiv_id": "2303.08385",
    "paper_title": "Generating symbolic music using diffusion models",
    "authors": [
        "Lilac Atassi"
    ],
    "submission_date": "2023-03-15",
    "revised_dates": [
        "2023-03-16"
    ],
    "latest_version": 1,
    "categories": [
        "cs.SD",
        "cs.LG",
        "eess.AS"
    ],
    "abstract": "Probabilistic Denoising Diffusion models have emerged as simple yet very powerful generative models. Diffusion models unlike other generative models do not suffer from mode collapse nor require a discriminator to generate high quality samples. In this paper, we propose a diffusion model that uses a binomial prior distribution to generate piano-rolls. The paper also proposes an efficient method to train the model and generate samples. The generated music has coherence at time scales up to the length of the training piano-roll segments. We show how such a model is conditioned on the input and can be used to harmonize a given melody, complete an incomplete piano-roll or generate a variation of a given piece. The code is shared publicly to encourage the use and development of the method by the community.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.08385v1"
    ],
    "publication_venue": null
}