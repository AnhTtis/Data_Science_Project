% iresnet
@inproceedings{duta2021improved,
  title={Improved residual networks for image and video recognition},
  author={Duta, Ionut Cosmin and Liu, Li and Zhu, Fan and Shao, Ling},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)},
  pages={9415--9422},
  year={2021},
  organization={IEEE}
}

% AffectNet
@article{mollahosseini2017affectnet,
  title={Affectnet: A database for facial expression, valence, and arousal computing in the wild},
  author={Mollahosseini, Ali and Hasani, Behzad and Mahoor, Mohammad H},
  journal={IEEE Transactions on Affective Computing},
  volume={10},
  number={1},
  pages={18--31},
  year={2017},
  publisher={IEEE}
}

% AFEW
@article{kossaifi2017afew,
  title={AFEW-VA database for valence and arousal estimation in-the-wild},
  author={Kossaifi, Jean and Tzimiropoulos, Georgios and Todorovic, Sinisa and Pantic, Maja},
  journal={Image and Vision Computing},
  volume={65},
  pages={23--36},
  year={2017},
  publisher={Elsevier}
}

% EfficientNet
@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

% openSmile
@inproceedings{eyben2010opensmile,
  title={Opensmile: the munich versatile and fast open-source audio feature extractor},
  author={Eyben, Florian and W{\"o}llmer, Martin and Schuller, Bj{\"o}rn},
  booktitle={Proceedings of the 18th ACM international conference on Multimedia},
  pages={1459--1462},
  year={2010}
}

% glint360k
@inproceedings{an2021partial,
  title={Partial fc: Training 10 million identities on a single machine},
  author={An, Xiang and Zhu, Xuhan and Gao, Yuan and Xiao, Yang and Zhao, Yongle and Feng, Ziyong and Wu, Lan and Qin, Bin and Zhang, Ming and Zhang, Debing and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1445--1449},
  year={2021}
}

% egemaps
@article{eyben2015geneva,
  title={The Geneva minimalistic acoustic parameter set (GeMAPS) for voice research and affective computing},
  author={Eyben, Florian and Scherer, Klaus R and Schuller, Bj{\"o}rn W and Sundberg, Johan and Andr{\'e}, Elisabeth and Busso, Carlos and Devillers, Laurence Y and Epps, Julien and Laukka, Petri and Narayanan, Shrikanth S and others},
  journal={IEEE transactions on affective computing},
  volume={7},
  number={2},
  pages={190--202},
  year={2015},
  publisher={IEEE}
}

% ComParE 2016
@inproceedings{schuller2016interspeech,
  title={The interspeech 2016 computational paralinguistics challenge: Deception, sincerity \& native language},
  author={Schuller, Bj{\"o}rn and Steidl, Stefan and Batliner, Anton and Hirschberg, Julia and Burgoon, Judee K and Baird, Alice and Elkins, Aaron and Zhang, Yue and Coutinho, Eduardo and Evanini, Keelan and others},
  booktitle={17TH Annual Conference of the International Speech Communication Association (Interspeech 2016), Vols 1-5},
  pages={2001--2005},
  year={2016}
}

% wav2vec
@article{schneider2019wav2vec,
  title={wav2vec: Unsupervised pre-training for speech recognition},
  author={Schneider, Steffen and Baevski, Alexei and Collobert, Ronan and Auli, Michael},
  journal={arXiv preprint arXiv:1904.05862},
  year={2019}
}

% VGGish
@inproceedings{hershey2017cnn,
  title={CNN architectures for large-scale audio classification},
  author={Hershey, Shawn and Chaudhuri, Sourish and Ellis, Daniel PW and Gemmeke, Jort F and Jansen, Aren and Moore, R Channing and Plakal, Manoj and Platt, Devin and Saurous, Rif A and Seybold, Bryan and others},
  booktitle={2017 ieee international conference on acoustics, speech and signal processing (icassp)},
  pages={131--135},
  year={2017},
  organization={IEEE}
}

% youtube-8m
@article{abu2016youtube,
  title={Youtube-8m: A large-scale video classification benchmark},
  author={Abu-El-Haija, Sami and Kothari, Nisarg and Lee, Joonseok and Natsev, Paul and Toderici, George and Varadarajan, Balakrishnan and Vijayanarasimhan, Sudheendra},
  journal={arXiv preprint arXiv:1609.08675},
  year={2016}
}

% librispeech
@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}

% audioset
@inproceedings{gemmeke2017audio,
  title={Audio set: An ontology and human-labeled dataset for audio events},
  author={Gemmeke, Jort F and Ellis, Daniel PW and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle={2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={776--780},
  year={2017},
  organization={IEEE}
}

% wav2vec 2.0
@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

% ferplus
@inproceedings{BarsoumICMI2016,
    title={Training Deep Networks for Facial Expression Recognition with Crowd-Sourced Label Distribution},
    author={Barsoum, Emad and Zhang, Cha and Canton Ferrer, Cristian and Zhang, Zhengyou},
    booktitle={ACM International Conference on Multimodal Interaction (ICMI)},
    year={2016}
}

% densenet
@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

% ABAW cite all start ---------------------

@article{kollias2022abaw, title={ABAW: Learning from Synthetic Data \& Multi-Task Learning Challenges}, author={Kollias, Dimitrios}, journal={arXiv preprint arXiv:2207.01138}, year={2022} }


@article{kollias2021distribution, title={Distribution Matching for Heterogeneous Multi-Task Learning: a Large-scale Face Study}, author={Kollias, Dimitrios and Sharmanska, Viktoriia and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2105.03790}, year={2021} }

@inproceedings{kollias2021analysing, title={Analysing affective behavior in the second abaw2 competition}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages={3652--3660}, year={2021}}

@article{kollias2021affect, title={Affect Analysis in-the-wild: Valence-Arousal, Expressions, Action Units and a Unified Framework}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2103.15792}, year={2021}}

@inproceedings{kollias2020analysing, title={Analysing Affective Behavior in the First ABAW 2020 Competition}, author={Kollias, D and Schulc, A and Hajiyev, E and Zafeiriou, S}, booktitle={2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)(FG)}, pages={794--800}}

@article{kollias2019expression, title={Expression, Affect, Action Unit Recognition: Aff-Wild2, Multi-Task Learning and ArcFace}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:1910.04855}, year={2019}}

@article{kollias2019face,title={Face Behavior a la carte: Expressions, Affect and Action Units in a Single Network}, author={Kollias, Dimitrios and Sharmanska, Viktoriia and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:1910.11111}, year={2019}}

@article{kollias2019deep, title={Deep affect prediction in-the-wild: Aff-wild database and challenge, deep architectures, and beyond}, author={Kollias, Dimitrios and Tzirakis, Panagiotis and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Schuller, Bj{\"o}rn and Kotsia, Irene and Zafeiriou, Stefanos}, journal={International Journal of Computer Vision}, pages={1--23}, year={2019}, publisher={Springer} }

@inproceedings{zafeiriou2017aff, title={Aff-wild: Valence and arousal ‘in-the-wild’challenge}, author={Zafeiriou, Stefanos and Kollias, Dimitrios and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Kotsia, Irene}, booktitle={Computer Vision and Pattern Recognition Workshops (CVPRW), 2017 IEEE Conference on}, pages={1980--1987}, year={2017}, organization={IEEE} } 


@inproceedings{kollias2017recognition,
  title={Recognition of affect in the wild using deep neural networks},
  author={Kollias, Dimitrios and Nicolaou, Mihalis A and Kotsia, Irene and Zhao, Guoying and Zafeiriou, Stefanos},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={26--33},
  year={2017}
}

% ABAW cite all end ---------------------

% RAF-DB
@inproceedings{li2017reliable,
  title={Reliable Crowdsourcing and Deep Locality-Preserving Learning for Expression Recognition in the Wild},
  author={Li, Shan and Deng, Weihong and Du, JunPing},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={2584--2593},
  year={2017},
  organization={IEEE}
}
@article{li2019reliable,
  title={Reliable Crowdsourcing and Deep Locality-Preserving Learning for Unconstrained Facial Expression Recognition},
  author={Li, Shan and Deng, Weihong},
  journal={IEEE Transactions on Image Processing},
  volume={28},
  number={1},
  pages={356--370},
  year={2019},
  publisher={IEEE}
}

% Aff-Wild label method
@inproceedings{cowie2000feeltrace,
  title={'FEELTRACE': An instrument for recording perceived emotion in real time},
  author={Cowie, Roddy and Douglas-Cowie, Ellen and Savvidou*, Susie and McMahon, Edelle and Sawey, Martin and Schr{\"o}der, Marc},
  booktitle={ISCA tutorial and research workshop (ITRW) on speech and emotion},
  year={2000}
}

% related works about 
(ICMI 2017)
@inproceedings{vielzeuf2017temporal,
  title={Temporal multimodal fusion for video emotion classification in the wild},
  author={Vielzeuf, Valentin and Pateux, St{\'e}phane and Jurie, Fr{\'e}d{\'e}ric},
  booktitle={Proceedings of the 19th ACM International Conference on Multimodal Interaction},
  pages={569--576},
  year={2017}
}

% CAER-Net (ICCV 2019)
@inproceedings{lee2019context,
  title={Context-aware emotion recognition networks},
  author={Lee, Jiyoung and Kim, Seungryong and Kim, Sunok and Park, Jungin and Sohn, Kwanghoon},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10143--10152},
  year={2019}
}

% DDA Loss (CVPR 2020)
@inproceedings{farzaneh2020discriminant,
  title={Discriminant distribution-agnostic loss for facial expression recognition in the wild},
  author={Farzaneh, Amir Hossein and Qi, Xiaojun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={406--407},
  year={2020}
}

% PMR (CVPR 2021)
@inproceedings{lv2021progressive,
  title={Progressive modality reinforcement for human multimodal emotion recognition from unaligned multimodal sequences},
  author={Lv, Fengmao and Chen, Xiang and Huang, Yanyong and Duan, Lixin and Lin, Guosheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2554--2562},
  year={2021}
}

% DACL (WACV 2021)
@inproceedings{farzaneh2021facial,
  title={Facial expression recognition in the wild via deep attentive center loss},
  author={Farzaneh, Amir Hossein and Qi, Xiaojun},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={2402--2411},
  year={2021}
}

% LSTM
@article{sak2014long,
  title={Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition},
  author={Sak, Ha{\c{s}}im and Senior, Andrew and Beaufays, Fran{\c{c}}oise},
  journal={arXiv preprint arXiv:1402.1128},
  year={2014}
}

% Transformer
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% emotion intelligence
@article{salovey1990emotional,
  title={Emotional intelligence},
  author={Salovey, Peter and Mayer, John D},
  journal={Imagination, cognition and personality},
  volume={9},
  number={3},
  pages={185--211},
  year={1990},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}
% fer2013
@article{carrier2013fer,
  title={FER-2013 face database},
  author={Carrier, Pierre-Luc and Courville, Aaron and Goodfellow, Ian J and Mirza, Medhi and Bengio, Yoshua},
  journal={Universit de Montral},
  year={2013}
}


@inproceedings{liu2018multi,
  title={Multi-feature based emotion recognition for video clips},
  author={Liu, Chuanhe and Tang, Tianhao and Lv, Kui and Wang, Minghao},
  booktitle={Proceedings of the 20th ACM International Conference on Multimodal Interaction},
  pages={630--634},
  year={2018}
}
@inproceedings{liu2020group,
  title={Group level audio-video emotion recognition using hybrid networks},
  author={Liu, Chuanhe and Jiang, Wenqiang and Wang, Minghao and Tang, Tianhao},
  booktitle={Proceedings of the 2020 International Conference on Multimodal Interaction},
  pages={807--812},
  year={2020}
}

%adam
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

%DenseNet
@article{iandola2014densenet,
  title={Densenet: Implementing efficient convnet descriptor pyramids},
  author={Iandola, Forrest and Moskewicz, Matt and Karayev, Sergey and Girshick, Ross and Darrell, Trevor and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1404.1869},
  year={2014}
}

@ARTICLE{8715409,  
 author={Guo, Wenzhong and Wang, Jianwen and Wang, Shiping},  journal={IEEE Access},   
 title={Deep Multimodal Representation Learning: A Survey},   
 year={2019},  volume={7},  number={},  pages={63373-63394}, 
 doi={10.1109/ACCESS.2019.2916887}
 }
 
 @article{2016Multimodal,
  title={Multimodal Emotion Recognition - ScienceDirect},
  author={ Abhang, P. A.  and  Gawali, B. W.  and  Mehrotra, S. C. },
  journal={Introduction to EEG- and Speech-Based Emotion Recognition},
  pages={113-125},
  year={2016},
}





%% test dataset tops
% flyingpigs
@article{zhang2022continuous,
  title={Continuous Emotion Recognition using Visual-audio-linguistic information: A Technical Report for ABAW3},
  author={Zhang, Su and An, Ruyi and Ding, Yi and Guan, Cuntai},
  journal={arXiv preprint arXiv:2203.13031},
  year={2022}
}

%PRL
@article{nguyen2022ensemble,
  title={An Ensemble Approach for Facial Expression Analysis in Video},
  author={Nguyen, Hong-Hai and Huynh, Van-Thong and Kim, Soo-Hyung},
  journal={arXiv preprint arXiv:2203.12891},
  year={2022}
}

%HSE-NN
@article{savchenko2022frame,
  title={Frame-level Prediction of Facial Expressions, Valence, Arousal and Action Units for Mobile Devices},
  author={Savchenko, Andrey V},
  journal={arXiv preprint arXiv:2203.13436},
  year={2022}
}

%AU-NN
@article{karas2022continuous,
  title={Continuous-Time Audiovisual Fusion with Recurrence vs. Attention for In-The-Wild Affect Recognition},
  author={Karas, Vincent and Tellamekala, Mani Kumar and Mallol-Ragolta, Adria and Valstar, Michel and Schuller, Bj{\"o}rn W},
  journal={arXiv preprint arXiv:2203.13285},
  year={2022}
}

%LIVIA-2022
@article{rajasekar2022joint,
  title={A Joint Cross-Attention Model for Audio-Visual Fusion in Dimensional Emotion Recognition},
  author={Rajasekar, Gnana Praveen and de Melo, Wheidima Carneiro and Ullah, Nasib and Aslam, Haseeb and Zeeshan, Osama and Denorme, Th{\'e}o and Pedersoli, Marco and Koerich, Alessandro and Cardinal, Patrick and Granger, Eric},
  journal={arXiv preprint arXiv:2203.14779},
  year={2022}
}

% Netease Fuxi Virtual Human
@article{zhang2022transformer,
  title={Transformer-based Multimodal Information Fusion for Facial Expression Analysis},
  author={Zhang, Wei and Zhang, Zhimeng and Qiu, Feng and Wang, Suzhen and Ma, Bowen and Zeng, Hao and An, Rudong and Ding, Yu},
  journal={arXiv preprint arXiv:2203.12367},
  year={2022}
}


% rdrop
@article{wu2021r,
  title={R-drop: Regularized dropout for neural networks},
  author={Wu, Lijun and Li, Juntao and Wang, Yue and Meng, Qi and Qin, Tao and Chen, Wei and Zhang, Min and Liu, Tie-Yan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={10890--10905},
  year={2021}
}

% hubert
@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

% ecapatdnn
@article{desplanques2020ecapa,
  title={Ecapa-tdnn: Emphasized channel attention, propagation and aggregation in tdnn based speaker verification},
  author={Desplanques, Brecht and Thienpondt, Jenthe and Demuynck, Kris},
  journal={arXiv preprint arXiv:2005.07143},
  year={2020}
}

%intro
@book{darwin1998expression,
  title={The expression of the emotions in man and animals},
  author={Darwin, Charles and Prodger, Phillip},
  year={1998},
  publisher={Oxford University Press, USA}
}


%MAE
@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

%AVEC2019
@inproceedings{DBLP:conf/mm/RingevalSVCCTSA19,
  author    = {Fabien Ringeval and
               Bj{\"{o}}rn W. Schuller and
               Michel F. Valstar and
               Nicholas Cummins and
               Roddy Cowie and
               Leili Tavabi and
               Maximilian Schmitt and
               Sina Alisamir and
               Shahin Amiriparian and
               Eva{-}Maria Me{\ss}ner and
               Siyang Song and
               Shuo Liu and
               Ziping Zhao and
               Adria Mallol{-}Ragolta and
               Zhao Ren and
               Mohammad Soleymani and
               Maja Pantic},
  editor    = {Fabien Ringeval and
               Bj{\"{o}}rn W. Schuller and
               Michel F. Valstar and
               Nicholas Cummins and
               Roddy Cowie and
               Maja Pantic},
  title     = {{AVEC} 2019 Workshop and Challenge: State-of-Mind, Detecting Depression
               with AI, and Cross-Cultural Affect Recognition},
  booktitle = {Proceedings of the 9th International on Audio/Visual Emotion Challenge
               and Workshop, AVEC@MM 2019, Nice, France, October 21-25, 2019},
  pages     = {3--12},
  publisher = {{ACM}},
  year      = {2019},
  url       = {https://doi.org/10.1145/3347320.3357688},
  doi       = {10.1145/3347320.3357688},
  timestamp = {Thu, 09 Jun 2022 12:17:46 +0200},
  biburl    = {https://dblp.org/rec/conf/mm/RingevalSVCCTSA19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



%DFEW
@inproceedings{jiang2020dfew,
title={DFEW: A Large-Scale Database for Recognizing Dynamic Facial Expressions in the Wild},
author={Jiang, Xingxun and Zong, Yuan and Zheng, Wenming and Tang, Chuangao and Xia, Wanchuang and Lu, Cheng and Liu, Jiateng},
booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
pages={2881--2889},
year={2020}}


%Emotionet
@inproceedings{DBLP:conf/cvpr/Benitez-QuirozS16,
  author    = {Carlos Fabian Benitez{-}Quiroz and
               Ramprakash Srinivasan and
               Aleix M. Mart{\'{\i}}nez},
  title     = {EmotioNet: An Accurate, Real-Time Algorithm for the Automatic Annotation
               of a Million Facial Expressions in the Wild},
  booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2016, Las Vegas, NV, USA, June 27-30, 2016},
  pages     = {5562--5570},
  publisher = {{IEEE} Computer Society},
  year      = {2016},
  url       = {https://doi.org/10.1109/CVPR.2016.600},
  doi       = {10.1109/CVPR.2016.600},
  timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/Benitez-QuirozS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

%FERV39k
@inproceedings{DBLP:conf/cvpr/WangSHLGZGZ22,
  author    = {Yan Wang and
               Yixuan Sun and
               Yiwen Huang and
               Zhongying Liu and
               Shuyong Gao and
               Wei Zhang and
               Weifeng Ge and
               Wenqiang Zhang},
  title     = {FERV39k: {A} Large-Scale Multi-Scene Dataset for Facial Expression
               Recognition in Videos},
  booktitle = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2022, New Orleans, LA, USA, June 18-24, 2022},
  pages     = {20890--20899},
  publisher = {{IEEE}},
  year      = {2022},
  url       = {https://doi.org/10.1109/CVPR52688.2022.02025},
  doi       = {10.1109/CVPR52688.2022.02025},
  timestamp = {Thu, 06 Oct 2022 08:12:33 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/WangSHLGZGZ22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

%MEC2017
@INPROCEEDINGS{8470342,
  author={Li, Ya and Tao, Jianhua and Schuller, Björn and Shan, Shiguang and Jiang, Dongmei and Jia, Jia},
  booktitle={2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia)}, 
  title={MEC 2017: Multimodal Emotion Recognition Challenge}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ACIIAsia.2018.8470342}
}



% mobilenet-v3
@inproceedings{howard2019searching,
  title={Searching for mobilenetv3},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1314--1324},
  year={2019}
}