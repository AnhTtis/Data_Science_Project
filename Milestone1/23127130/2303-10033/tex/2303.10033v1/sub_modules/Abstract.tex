\begin{abstract}
   This paper presents our submission to the Expression Classification Challenge of the fifth Affective Behavior Analysis in-the-wild (ABAW) Competition. 
   In our method, multimodal feature combinations extracted by several different pre-trained models are applied to capture more effective emotional information. For these combinations of visual and audio modal features, we utilize two temporal encoders to explore the temporal contextual information in the data. In addition, we employ several ensemble strategies for different experimental settings to obtain the most accurate expression recognition results. 
   Our system achieves the average F1 Score of $0.45774$ on the validation set.
   %Our method utilizes the multi-modal information, i.e., the visual and audio information, and employs a temporal encoder to model the temporal context in the videos. 
   %Besides, a smooth processor is applied to get more reasonable predictions, and a model ensemble strategy is used to improve the performance of our proposed method.
   %Based on multimodal feature representations that fuse the visual and aural information, we utilize two types of temporal encoder to capture the temporal context information in the video, including the transformer based encoder and LSTM based encoder. 
   %With the temporal context-aware representations, we employ fully-connected layers to predict the valence and arousal values of the video frames.
   %In addition, smoothing processing is applied to refine the initial predictions, and a model ensemble strategy is used to combine multiple results from different model setups.
   %Our system achieves the performance in Concordance Correlation Coefficients (ccc) of $0.606$ for valence, $0.602$  for arousal, and mean ccc of $0.601$, which ranks the first place in the challenge.
   %he Concordance Correlation Coefficient
   %$0.606$ ccc for valence, $0.602$ ccc for arousal, and $0.601$ mean ccc on the test set of the Aff-Wild2 dataset, and achieves the best overall performance in the challenge
  % , which proves the effectiveness of our proposed method. 
\end{abstract}
