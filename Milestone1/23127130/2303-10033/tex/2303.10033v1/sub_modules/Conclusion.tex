\section{Conclusion}

In this paper, we propose our framework for the Expression Classification Challenge of the fifth Affective Behavior Analysis in-the-wild (ABAW) Competition. Our approach leverages information from multiple modalities in the spatio-temporal dimension. Various temporal encoders are applied to capture the temporal contextual information in the video. In addition, we design multiple high-quality feature combinations to extract more effective emotional information. Our method achieves a performance of $0.45774$ on the validation set.
%The experiment results show that our method achieves $65.55\%$ ccc for valence and $70.88\%$ ccc for arousal on the validation set of the Aff-Wild2 dataset, 
%The experiment results show that our method achieves $0.606$ ccc for valence, $0.602$ ccc for arousal and $0.601$ mean ccc on the test set of the Aff-Wild2 dataset, which ranks the first place in the challenge.