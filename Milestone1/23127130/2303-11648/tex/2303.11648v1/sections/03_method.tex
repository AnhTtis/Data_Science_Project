\section{Controllable Query Generation}

In this section, we first describe the three main components of the proposed \cqg{} followed by different applications for the generated queries. Figure~\ref{fig:model_diagram} displays a diagram of the model, as well as two different ways to employ the synthetic queries. The serialization module is required to obtain a text representation for a given entity so that text-based models can use that as input. The second component is called weak labeling, which is able to bypass the need for a large amount of labeled data. Finally, the last component is the intent-aware generation, which is able to control for different types of intent (broad and narrow).

\subsection{Model Components}

\subsubsection{Serialization}
This module takes as input an entity $e$ and outputs a string representation of the entity: $e_{serialized} = s(e)$. The serialization function $s$ concatenates every metadata column of the entity with their respective values, using a special token: $ s(e) = \textcolor{brown}{col_{1}}: val_{1} [SEP] \textcolor{brown}{col_{2}}: val_{2} [SEP] ... [SEP] \textcolor{brown}{col_{n}}: val_{n}$. So for example the book with the title \textit{The Fellowship of the Ring} becomes:

    \vspace{4mm} 
     \fbox{\begin{minipage}{23em}
    %  \small
    \textit{\textcolor{brown}{title}:  The Fellowship of the Ring [SEP] \textcolor{brown}{series name}: The Lord of the Rings \#1 [SEP] \textcolor{brown}{author names}: J.R.R. Tolkien [SEP] \textcolor{brown}{publication year}: 1954 [SEP] \textcolor{brown}{language}: EN [SEP] \textcolor{brown}{genres}: Fantasy, Classics, Fiction, Adventure, High Fantasy, ...[SEP] \textcolor{brown}{description}: One Ring to rule them all, One Ring to find them ...[SEP] \textcolor{brown}{review}: This book is full of wonder and adventure with fantastic writing ... [SEP] \textcolor{brown}{lists}: fantasy, uk-and-ireland, witches-wizards, fiction, british, ...}
    \end{minipage}}
    \vspace{4mm} 



\subsubsection{Weak Labeling}
In order to train \cqg{} we require a dataset $\set{D}=\{(e_i, i_i, q_i)\}_{i=1}^{M}$ with training triplets of entity, intent, and query, which are the input, control variable, and output respectively. In each triplet, the query $q$ has the underlying intent $i$ (\narrow{} or \broad{}) when matching with the entity $e$. One option to acquire such data is to ask annotators to create \narrow{} and \broad{} queries for a given entity. Alternatively, we can employ weak labeling functions that generate such data based on heuristics.

We present here two flavors of weak labeling functions. The first is completely \emph{unsupervised} (\weaklabelsun{}), and thus is able to generate both query and intents for any given entity. The second requires queries that are related to each entity and thus is based on \emph{intent prediction} of the given query (\weaklabelsip{}).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.50\textwidth]{img/WeakLabeling.pdf}
    \caption{Two variants of the weak labeling functions. While \weaklabelsun{} (top) outputs query and intents for a given entity, \weaklabelsip{} (bottom) outputs an intent label for a given pair of entity and query. }
    \label{fig:weak_labeling_diagram} 
\end{figure}

\textbf{\weaklabelsun{}}. The core intuition is that we can define a set of metatada columns that are inherently associated with narrow intent queries since they can identify the entity (\narrowcols{}), e.g. title and artists, and a set of metadata columns that capture characteristics of the entity that other entities might also have, e.g. genres, and thus can be considered to be broad columns (\broadcols{}). In order to generate a set of queries and intents for a given entity we rely on randomly sampling terms from all possible combinations of the respective fields. So for example to generate a narrow intent query in the music domain, we could use either the title of a track, the album, the artist, or a combination of the three. After sampling terms from such the respective columns for the query, we apply a number of functions to generate query variations in a stochastic manner: shuffling words, adding misspellings, and removing prefixes\footnote{Since the datasets considered come from a large-scale online platform with \emph{instant search}, many log queries are not complete and are just prefixes of the entity titles. This happens because the user might stop before the end of the query as the result could be already found in the list of results.}. 

Specifically, when generating broad queries, we differentiate between metadata columns that are based on free text (\broadcolsft{}), e.g. reviews, and the ones which are already category-like terms (\broadcols{}), e.g. genres. For the free text columns, in order to avoid selecting terms that are uninformative, we apply a sampling strategy that prioritizes terms with higher IDF. As another weak labeling function for the free text columns, we apply a text summarization model to select more informative terms.

\textbf{\weaklabelsip{}} In order to take advantage of existing data of entities and queries, e.g. query logs with clicked entities, this variant predicts if the query is \broad{} or \narrow{} based on its narrow and broad columns. If the similarity\footnote{We employ here a transformer sentence representation and cosine similarity.} of the query and the values of the narrow queries is higher than the similarity of the query with the values of the broad queries then the weak label will be \narrow{}, otherwise \broad{}. So for example, if the entity is a book with the title ``\textit{The Brothers Karamazov}'', and the input query is ``\textit{Karamazov}'', the label would be \narrow{} whereas if the input query is ``\textit{russian theological fiction}'' the label would be \broad{} as it would be more similar to the categories of the book. 

\subsubsection{Intent-aware Generation}
Given the training dataset $\set{D}=\{(e_i, i_i, q_i)\}_{i=1}^{M}$, we train an encoder-decoder model $G$ that receives as input the entity and the underlying intent to control for, and it outputs the query: $G(e,i) = q$. In order to achieve that we rely on adding the control variable as part of the language model prompt. We train the model with the following prompt: ``\textit{Generate a query with \narrow{}/\broad{} intent from: <serialized\_entity>}'' and its respective query as the output. So for example the query ``\textit{lord of th}'' with intent \narrow{} would lead to the following training instance:
    
    \vspace{4mm} 
     \fbox{\begin{minipage}{23em}
    %  \small
    \textit{\textbf{Input} Generate a \textbf{narrow} query from: \textit{\textcolor{brown}{title}:  The Fellowship of the Ring [SEP] \textcolor{brown}{series name}: The Lord of the Rings \#1 [SEP] \textcolor{brown}{author names}: J.R.R. Tolkien [SEP] \textcolor{brown}{publication year}: 1954 [SEP] \textcolor{brown}{language}: EN [SEP] \textcolor{brown}{genres}: Fantasy, Classics, Fiction, Adventure, High Fantasy, ...[SEP] \textcolor{brown}{description}: One Ring to rule them all, One Ring to find them ...[SEP] \textcolor{brown}{review}: This book is full of wonder and adventure with fantastic writing ... [SEP] \textcolor{brown}{lists}: fantasy, uk-and-ireland, witches-wizards, fiction, brittish, ...}}
    
    \textbf{Output} \textit{lord of th}
    \end{minipage}}
    \vspace{4mm} 


\subsection{Applications}

\subsubsection{Synthetic training data}
We can use the generated queries to train Bi-Encoder retrieval models, as shown on the right top part of Figure~\ref{fig:model_diagram}. For a randomly sampled set of entities $\set{E'}$ from the collection $\set{E}$ we apply \cqg{} with both desired intents $q'_{narrow} = G(e, \narrow{})$ and $q'_{broad} = G(e, \broad{})$ for each $e$ in $\set{E'}$. After that, given a desired weight proportion of broad queries and narrow queries ($P_{narrow}$, $P_{broad}$) we can sample training instances from the synthetic generated queries $\set{Q'}$ for training the Bi-Encoder. This gives us a dataset of pairs of synthetic queries and respective relevant entities that can be used to train Bi-Encoder models, controlling for the desired proportion of underlying intents.

\subsubsection{Query suggestion} We can employ the \cqg{} model to perform query suggestion, as shown on the bottom right part of Figure ~\ref{fig:model_diagram}. Since the majority of the queries for entities have a narrow intent behind them, one approach to modifying the user's behavior is to suggest broader queries. In order to do that, we can employ the generated queries in the following manner. First, for a given input query $q$, we can obtain a list $\set{R}_q$ with the top-k entities ranked for it using a ranking model. For each entity in the top-k ranked list, we apply \cqg{} to generate a set of broad queries $\set{Q'}$ to recommend: $\set{Q'} = \{G(e_{i}, \broad{})\}$ for $e_{i}$ in $\set{R}_q$\footnote{In our experiments this set of queries $\set{Q'}$ is appended, according to a percentage of acceptance, to the set of log queries $\set{Q}$ in order to calculate the retrievability bias.}. The complexity of this approach is $O(n^2 *d * k)$, where $n$ is the sequence
length, $d$ is the number of dimensions of the transformer model and $k$ is the size of the list considered to generate suggestions.