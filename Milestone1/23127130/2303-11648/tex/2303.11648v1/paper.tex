%%
%% This is file `sample-authordraft.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `authordraft')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-authordraft.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\PassOptionsToPackage{table,xcdraw,dvipsnames}{xcolor}
% \documentclass[sigconf,authordraft,anonymous]{acmart}
\documentclass[sigconf]{acmart}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{arydshln}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{float}
\usepackage{makecell}
\usepackage{pythonhighlight}

\settopmatter{printacmref=false}

\newcommand{\set}[1]{\mathcal{#1}}

\newcommand{\tracks}{\texttt{Tracks}}
\newcommand{\podcasts}{\texttt{Podcasts}}
\newcommand{\books}{\texttt{Books}}

\newcommand{\reptitle}{\textit{title}}
\newcommand{\reptitleaug}{\textit{title+aug}}

\newcommand{\clicks}{\texttt{Click}}
\newcommand{\qgen}{\texttt{QGen}}
\newcommand{\inpars}{\texttt{InPars}}
\newcommand{\cqg}{\texttt{CtrlQGen}}

\newcommand{\broad}{\texttt{broad}}
\newcommand{\narrow}{\texttt{narrow}}

\newcommand{\podcastbroad}{\texttt{Podcasts$_{\broad{}}$}}
\newcommand{\tracksbroad}{\texttt{Tracks$_{\broad{}}$}}

\newcommand{\narrowcols}{\textit{narrow-fields}}
\newcommand{\broadcols}{\textit{broad-fields}}
\newcommand{\broadcolsft}{\textit{broad-fields-ft}}

\newcommand{\bm}[1]{\texttt{BM25}}
\newcommand{\biencoder}[1]{\texttt{Bi-Encoder}}

\newcommand{\weaklabelsun}[1]{\texttt{WeakLabeling-Un}}
\newcommand{\weaklabelsip}[1]{\texttt{WeakLabeling-IP}}

\newcommand{\maryam}[1]{\textcolor{red}{#1}}
\newcommand{\hugues}[1]{\textcolor{green}{#1}}

%% NOTE that a single column version may required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
% % \setcopyright{none}

% \setcopyright{acmcopyright}
% \copyrightyear{2018}
% \acmYear{2018}
% \acmDOI{XXXXXXX.XXXXXXX}

\copyrightyear{2023}
\acmYear{2023}
\setcopyright{acmlicensed}\acmConference[WWW '23]{Proceedings of the ACM Web Conference 2023}{May 1--5, 2023}{Austin, TX, USA}
\acmBooktitle{Proceedings of the ACM Web Conference 2023 (WWW '23), May 1--5, 2023, Austin, TX, USA}
\acmPrice{15.00}
\acmDOI{10.1145/3543507.3583261}
\acmISBN{978-1-4503-9416-1/23/04}

% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[Conference acronym 'XX]{Make sure to enter the correct
%   conference title from your rights confirmation emai}{June 03--05,
%   2018}{Woodstock, NY}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Improving Content Retrievability in Search with Controllable Query Generation}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Gustavo Penha$^1$, Enrico Palumbo$^2$, Maryam Aziz$^3$, Alice Wang$^3$, Hugues Bouchard$^4$}
\affiliation{
\institution{Spotify}
\country{$^1$Netherlands, $^2$Italy, $^3$USA, $^4$Spain}
}
\email{{gustavop,enricop,maryama,alicew,hb}@spotify.com}  % emails


% \author{Gustavo Penha}
% \affiliation{%
% \institution{Spotify}
% % \city{Delft}
% \country{Netherlands}}
% \email{gustavop@spotify.com}

% \author{Enrico Palumbo}
% \affiliation{%
% \institution{Spotify}
% % \city{}
% \country{Italy}
% }
% \email{enricop@spotify.com}

% \author{Maryam Aziz}
% \affiliation{%
% \institution{Spotify}
% % \city{}
% \country{USA}
% }
% % \email{@spotify.com}

% \author{Alice Wang}
% \affiliation{%
% \institution{Spotify}
% % \city{}
% \country{USA}
% }
% % \email{@spotify.com}

% \author{Hugues Bouchard}
% \affiliation{%
% \institution{Spotify}
% % \city{}
% \country{Spain}
% }
% % \email{@spotify.com}



%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
% \maryam{I think it might be. better to open the abstract by giving a broader but crisp context and introduce the problem and your solution right away, something line "Users' search intents are often varied from "narrow" to "broad" but online content platforms are mainly tailored for narrow intent queries overlooking much of users' complex information needs and the content matching those needs. In this work, ...''}

% \hugues{ I would suggest to open the abstract by stressing the importance of retrievability, and the challenges in online platforms dedicated to music, podcast and books. Then, we can make the distinction between narrow and broad intents. And finally, propose the solution CtrlQGen.}

An important goal of online platforms is to enable content discovery, i.e. allow users to find a catalog entity they were not familiar with. A pre-requisite to discover an entity, e.g. a book, with a search engine is that the entity is \emph{retrievable}, i.e. there are queries for which the system will surface such entity in the top results. However, machine-learned search engines have a high retrievability bias, where the majority of the queries return the same entities. This happens partly due to the predominance of narrow intent queries, where users create queries using the title of an already known entity, e.g. in book search ``\textit{harry potter}''. The amount of broad queries where users want to discover new entities, e.g. in music search ``\textit{chill lyrical electronica with an atmospheric feeling to it}'', and have a higher tolerance to what they might find, is small in comparison.  We focus here on two factors that have a negative impact on the retrievability of the entities (I) the training data used for dense retrieval models and (II) the distribution of narrow and broad intent queries issued in the system. We propose \cqg{}, a method that generates queries for a chosen underlying intent---narrow or broad. We can use \cqg{} to improve factor (I) by generating training data for dense retrieval models comprised of diverse synthetic queries. \cqg{} can also be used to deal with factor (II) by suggesting queries with broader intents to users. Our results on datasets from the domains of music, podcasts, and books reveal that we can significantly decrease the retrievability bias of a dense retrieval model when using \cqg{}. First, by using the generated queries as training data for dense models we make 9\% of the entities retrievable---go from zero to non-zero retrievability. Second, by suggesting broader queries to users, we can make 12\% of the entities retrievable in the best case.
\end{abstract}

% In addition, search engines of online content platforms are tailored for narrow intent queries and are often not able to handle complex information needs.

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>10010520.10010553.10010562</concept_id>
%   <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010575.10010755</concept_id>
%   <concept_desc>Computer systems organization~Redundancy</concept_desc>
%   <concept_significance>300</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010553.10010554</concept_id>
%   <concept_desc>Computer systems organization~Robotics</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10003033.10003083.10003095</concept_id>
%   <concept_desc>Networks~Network reliability</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
% </ccs2012>
\end{CCSXML}

% \ccsdesc[500]{Computer systems organization~Embedded systems}
% \ccsdesc[300]{Computer systems organization~Redundancy}
% \ccsdesc{Computer systems organization~Robotics}
% \ccsdesc[100]{Networks~Network reliability}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
% \keywords{retrievability, dense retrieval, query generation, controllable generation, query suggestion}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\input{sections/01_intro}
\input{sections/02_related}
\input{sections/03_method}
\input{sections/04_setup}
\input{sections/05_results}
\input{sections/06_conclusion}


% \section{Acknowledgments}
% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

\appendix
\section{Unsupervised Weak Labeling Functions}
In this appendix, we define the functions used in \weaklabelsun{}.
\subsection{Random Terms Selection}
Samples words from the entity $e$, given possible $P$ length percentages for the query with probability $Pr$.
\begin{python}
def sample_words(e, P, Pr):
    words = tokenize(e)
    p_words_to_sample = np.random.choice(P, 1, p=Pr)
    n = int(len(words) * p_words_to_sample)
    words = np.random.choice(words, n, replace=False)
    return words
\end{python}

\subsection{Query Variation Ordering}
Generates a query variation by shuffling two random words from the query.
\begin{python}
def qv_ordering(q):
    words = tokenize(q)
    idxs = [i for i in range(0, len(words))]
    p1, p2 = np.random.choice(idxs, 2, replace=False)
    words[p1], words[p2] = words[p2], words[p1]
    return " ".join(words)
\end{python}

\subsection{Query Variation Misspelling}
Generates a query variation by adding a misspelling error with $P$ probabilities of removing and addition.
\begin{python}
def qv_misspelling(q, P):
    t = np.random.choice(["rem", "mdf"], 1, p=P)
    idxs=[i for i in range(len(query))]
    l=string.ascii_letters
    if t == "rem":
        idx_rem = np.random.choice(idxs, 1)[0]
        qv = q[0:idx_rem] + q[idx_rem+1:]
    elif t == "mdf":
        idx_mdf = np.random.choice(idxs, 1)[0]
        char_add = np.random.choice(len(l), 1)[0]
        qv = q[0:idx_mdf] + l[char_add] + q[idx_mdf+1:]
    return qv
\end{python}

\subsection{Query Variation Prefix}
Generates a query variation by removing $P$ percentages of the suffix of the query with probabilities $Pr$.
\begin{python}
def qv_prefix_query(q, P, Pr):
    rem = np.random.choice(P, 1, p=Pr)    
    return q[:int((1-rem)*len(q))]
\end{python}

\subsection{Query from Free-Text Column by Summarization}
Generates a query by summarizing the value of a free-text column (\broadcolsft{}). For our experiments we rely on the pre-trianed summarizer model \textit{snrspeaks/t5-one-line-summary}\footnote{\url{https://huggingface.co/snrspeaks/t5-one-line-summary}}.
\begin{python}
from transformers import pipeline
def q_summarizer(ft, m):
    pipe = pipeline("text2text-generation", 
                    model = m)
    return pipe("summarize: {}".format(ft))[0]
\end{python}

% \subsection{Query from Free-Text Column by IDF selection}
% Generates a query by selecting terms using sampling based on top $T$ \% of terms sorted by IDF.

% \begin{python}
% def q_idf(ft, idf_dict, T):
%     idfs = {w: idf[w] for w in tokenize(ft)}
%     s = sorted(idfs.entities(), 
%                 key=operator.entitygetter(1))
%     w = [v[0] for v in s]
%     return " ".join(w[int(len(w)*T):])
% \end{python}

\section{Bias mitigation for the \clicks{} dataset}
In this appendix, we investigate if it is possible to mitigate the biases of the \clicks{} data with a simpler approach.

When fine-tuning the Bi-Encoder with \clicks{} data in our experiments we do not employ the same combination of queries and entities twice, even if that pair is highly popular in the logs. This is already a way of reducing the bias in the \clicks{} dataset. However, there are still many query variations that lead to the same entities, i.e. queries with different forms but with the same underlying information need, which are not removed when we get distinct queries for training. In order to mitigate this bias from the \clicks{} data by removing multiple queries that lead to the same entity, we randomly select only one of the queries for each entity to train the \biencoder{} model on. 

The result of this experiment is that such a bias mitigation strategy indeed improves the retrievability of the system: the Gini scores go from 0.856 to 0.803 for \tracks{} and from 0.763 to 0.713 for \podcasts{}. However the mitigated \clicks{} data approach still leads to 30\% and 5\% more retrievability bias than \cqg{}, for \tracks{} and \podcasts{} respectively.

\section{Scaling \inpars{} with GPT-3}
In this appendix, we test if increasing the model size of the InPars model using GPT-3 as the language model has a significant effect on the Bi-Encoder trained with such synthetic queries. 

We see from \ref{fig:gpt3} that this is not the case for both datasets, and the highest R@100 is reached when using the 1.2B GPT-3 model (\textit{babbage-001}). Similar results were found in the InPars paper~\cite{bonifacio2022inpars}.
\begin{figure}[H]
    \centering
    \includegraphics[width=.45\textwidth]{img/gpt3.png}
    \caption{Scaling \inpars{} baseline using GPT-3.}
    \label{fig:gpt3}
\end{figure}

\section{Overlap of generated queries}
In this appendix, we check if the queries generated by \cqg{} have a significant overlap with either the log queries (is \cqg{} just copying existing queries?) or with the input entity (is \cqg{} just copying words from the input entity?).

\subsection{With log queries from \clicks{}}
Out of the 10k narrow queries generated by 
\cqg{} to test the first hypothesis (results from Tables~\ref{table:results_narrow}), there are only 6\% and 12\% exact matches with set of queries from the logs (\clicks{}) for the \tracks{} and \podcasts{} datasets respectively. For the second hypothesis, out of the 376k broad queries generated, there are only 2\% and 1\% are exact matches with the set of queries from the logs. This shows the diversity of the generated queries from \cqg{}, and that it is not just copying input queries from the log.

\subsection{With the input entity}
Out of the 10k narrow queries generated by 
\cqg{} to test the first hypothesis, 25\% and 48\% are not a subset of the serialized entity for \tracks{} and \podcasts{} datasets respectively. For the second hypothesis, out of the 376k broad queries generated, a total of ~70\% of queries are not subsets of the serialized entity for both datasets. This shows that while for narrow queries substrings of the entity are the majority of the cases when generating broad queries this is not the case. Also, this indicates that for both cases the model is not always selecting parts of the input as the query.

\section{Dataset details}

For the \books{} dataset, we take into account the top two most-voted reviews and use the first 50 tokens. For the \tracks{} dataset, we use the first lyric line and the most frequent lyric line and employ a maximum of 25 descriptors. For the \podcasts{} dataset, we use the first 50 tokens of the description and of the transcript. For the \books{} and \tracks{} datasets we use a maximum of 25 playlists.

\end{document}
\endinput
%%
%% End of file `sample-authordraft.tex'.
