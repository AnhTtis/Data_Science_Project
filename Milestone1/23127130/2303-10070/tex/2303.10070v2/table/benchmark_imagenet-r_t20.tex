\begin{table}
  \renewcommand\arraystretch{1.0}
  \caption{20-Task Benchmark Results on ImageNet-R. The PET modules are inserted into the first 5 transformer blocks of the standard ViT-B/16 pre-trained on the ImageNet21k dataset. The ``5, 10, 20'' indicate the size of PET modules.}
  \vskip -0.25in
  \label{table:imagenet-r_t20}
  \begin{center}
    \resizebox{\columnwidth}{!}{
      \begin{tabular}{lcccr}
        \toprule
        Approach                      & PET Module & $A_{20}$ (↑)            & $\bar{A}_{20}$ (↑)      \\
        \midrule
        L2P~\cite{l2p}                & Prompt     & 59.85$\pm$1.38          & 66.33$\pm$2.46          \\
        DualPrompt~\cite{dual_prompt} & Prefix20   & 66.61$\pm$0.24          & 76.94$\pm$1.39          \\
        ESN~\cite{esn}                & Prompt     & 58.65$\pm$0.83          & 70.94$\pm$1.88          \\
        \midrule
        \multirow{6}{*}{LAE (Ours)}   & Adapter5   & 69.66$\pm$1.16          & 81.69$\pm$1.00          \\
                                      & Adapter10  & 69.19$\pm$1.25          & \textbf{81.78}$\pm$0.77 \\
                                      & LoRA5      & 68.91$\pm$1.40          & 80.99$\pm$1.17          \\
                                      & LoRA10     & 69.07$\pm$1.49          & 81.12$\pm$1.09          \\
                                      & Prefix10   & \textbf{69.67}$\pm$0.86 & 79.97$\pm$0.97          \\
                                      & Prefix20   & 69.34$\pm$0.84          & 79.90$\pm$1.08          \\
        \bottomrule
      \end{tabular}
    }
  \end{center}
  \vskip -0.4in
\end{table}