\section{Introduction}

   \input{figures/intro_fig}

    % Paragraph 1: Introduce problem
    Natural language has been shown to provide a strong signal for training visual representations, even for complex tasks such as object detection. A visual-text alignment model operating at the region-word level can be pretrained with image-caption data and used as a starting point for supervised object detection training. While the noun word embeddings that represent object categories are often used as classifier weights, the roles of other caption information (\eg adjectives, prepositions, verbs, other nouns) are less clear. For example, consider the caption in Fig \ref{intro_fig}:
    %(from COCO \cite{lin2014microsoft}):
    ``A very \textbf{large} \textbf{furry} \textbf{brown} \underline{bear} on a \underline{rock} by the \underline {water}.''
    There are three object categories (underlined), but \underline{bear} is also described with fine-grained attributes specified through (bolded) adjectives (i.e. the image has a \textbf{large} \textbf{furry} \textbf{brown} \underline{bear}). Does the alignment model use the adjectives to learn \underline{bear}, or is this information wasted? 
    
    %Older notes: 
    % and difficult to learn from. 
    % But the image actually contains a ``tuk tuk'', a much more specific type of vehicle. 

    % Paragraph 2: Role of attributes 
    Contextual elements in captions, and in particular attributes, can aid detection in various ways. Attributes can serve as a proxy for a fine-grained category which is not explicitly mentioned (\eg a \textit{small, young cat} is a \textit{kitten}). They can ensure that the alignment model is paying attention to the right features, rather than dataset artifacts (\eg that a \textit{bear} is being grounded as such because it is \textit{brown/black/white}, rather than because its background is a \textit{forest}). They can be used to specify subcategories, \eg when a user wants to only detect instances that match a certain property (a \textit{red car}, but not a \textit{blue car}).  

    With this motivation, we explore how existing work in region-word alignment uses context, and we study ways to enhance language context to benefit object-level tasks. We particularly contribute answers to the following questions:   
    \begin{itemize}[itemsep=1mm, parsep=0pt]

    \item Do region-word alignment models use caption context (\eg adjectives) to effectively ground objects? How is detection affected by context removal? 

    \item What are the strengths and weaknesses of learning grounding and open-vocabulary object detection with contextualized word embeddings? How do effects differ in base, target, and generalized scenarios?

    %\item Are visual object embeddings sensitive to the adjectives that contextualize object word embeddings? Are fine-grained concepts (\eg red car) learned? 
    
    \item  Does increasing the sensitivity of visual grounding to the attributes mentioned in language benefit object detection? Can enhanced attribute sensitivity provide utility in other fine-grained tasks?

    \end{itemize}

    We find that detection does \textit{not} significantly use language context, so to increase its role, we propose (1) \textit{a contextualized grounding objective}, with training strategies to maximize its effectiveness, and (2) \textit{a contrastive, caption-based, adjective and noun negative sampling strategy} that encourages the model to attend to objects with their attributes. The increased \textit{context-sensitivity} and \textit{attribute-sensitivity} that these methods provide enhance OVR-CNN \cite{zareian2021open}, a state-of-the-art open-vocabulary object detection method, by +0.9, +1.0, +0.9 AP$_{50}$ on base, target, and all classes in a generalized, full-scale setting and by +3.0 and +2.5 AP$_{50}$ in base and generalized settings on a smaller scale. Fine-grained utility of our approach is also exhibited through text-region retrieval and phrase grounding analysis.
    
