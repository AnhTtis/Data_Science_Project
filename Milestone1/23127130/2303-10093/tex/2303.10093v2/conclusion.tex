% Conclusion

\section{Conclusion}

    \label{sec:conclusion}

    We answer these questions (Sec. \ref{sec:intro}):
    %about the impact of attributes in VL models for object recognition and detection: 
    (1) Attribute context can show limited impact in region-word pretraining for detection. (2) Grounding objects to contextualized word embeddings increases attribute consideration only to a limited degree.
    (3) Describing CLIP's classes by only their attributes results in poor accuracy. 
    Also, models struggle at fine-grained retrieval.
    (4) Adjective-based negative caption sampling is promising to increase model sensitivity to attribute meaning and especially boosts fine-grained retrieval.
    %and to increase benefits from such context. 
    (5) Plausible and random adjective sampling are competitive in detection/retrieval following OVR-CNN grounding; with CLIP, random sampling has higher retrieval gains.

    \noindent \textbf{Acknowledgements:} This work was supported by a National Science Foundation Grant No. 2006885.

    %In the future, testing and extending such strategies into larger-scale pretraining will be important to improve model utility in attribute-based tasks.

    %\textbf{Ethics note} Training with natural language likely introduces biases in model decisions. To avoid perpetuating harmful gender, racial, or other discriminatory biases, care should be taken with use of methods, models, and datasets.  

    %Using descriptions with CLIP results in poor accuracy when describing classes solely with attributes.

    % of objects described with attributes