{
    "arxiv_id": "2303.14773",
    "paper_title": "BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning",
    "authors": [
        "Changdae Oh",
        "Hyeji Hwang",
        "Hee-young Lee",
        "YongTaek Lim",
        "Geunyoung Jung",
        "Jiyoung Jung",
        "Hosik Choi",
        "Kyungwoo Song"
    ],
    "submission_date": "2023-03-26",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
    ],
    "abstract": "With the surge of large-scale pre-trained models (PTMs), fine-tuning these models to numerous downstream tasks becomes a crucial problem. Consequently, parameter efficient transfer learning (PETL) of large models has grasped huge attention. While recent PETL methods showcase impressive performance, they rely on optimistic assumptions: 1) the entire parameter set of a PTM is available, and 2) a sufficiently large memory capacity for the fine-tuning is equipped. However, in most real-world applications, PTMs are served as a black-box API or proprietary software without explicit parameter accessibility. Besides, it is hard to meet a large memory requirement for modern PTMs. In this work, we propose black-box visual prompting (BlackVIP), which efficiently adapts the PTMs without knowledge about model architectures and parameters. BlackVIP has two components; 1) Coordinator and 2) simultaneous perturbation stochastic approximation with gradient correction (SPSA-GC). The Coordinator designs input-dependent image-shaped visual prompts, which improves few-shot adaptation and robustness on distribution/location shift. SPSA-GC efficiently estimates the gradient of a target model to update Coordinator. Extensive experiments on 16 datasets demonstrate that BlackVIP enables robust adaptation to diverse domains without accessing PTMs' parameters, with minimal memory requirements. Code: \\url{https://github.com/changdaeoh/BlackVIP}",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.14773v1"
    ],
    "publication_venue": "Accepted to CVPR 2023"
}