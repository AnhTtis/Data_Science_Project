\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[final]{cvpr}

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

\usepackage[accsupp]{axessibility}  % Improves PDF readability for those with disabilities.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref,breaklinks,colorlinks,bookmarks=false]{hyperref}

\usepackage{multirow}
\usepackage{enumitem}
\usepackage{rotating}
\usepackage{makecell}
\usepackage{marvosym}

\usepackage{ragged2e}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[normalem]{ulem}
%\usepackage[breaklinks=true,colorlinks,bookmarks=false]{hyperref}

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}
\usepackage{color}
\usepackage{xcolor}
\usepackage{color, colortbl}
\usepackage{booktabs}
% \usepackage{subfigure}
\usepackage{float}
\usepackage{wrapfig}
\definecolor{Gray}{gray}{0.9}
\definecolor{Red}{RGB}{230, 57, 70}
\definecolor{Blue}{RGB}{0, 100, 148}
\usepackage{mmstyle}
\usepackage{xspace}
\newcommand{\TODO}[1]{\textcolor{red}{(TODO: #1)}}
\newcommand{\modelname}{\emph{OSX}\xspace}
\newcommand{\dataname}{\emph{UBody}\xspace}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}


%%%%%%%%% PAPER ID  - PLEASE UPDATE



\def\cvprPaperID{3184} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}
\begin{document}
%%%%%%%%% TITLE - PLEASE UPDATE
\title{One-Stage 3D Whole-Body Mesh Recovery with Component Aware Transformer}  % **** Enter the paper title here

\author{%
	Jing Lin$^{1,2\S}$, Ailing Zeng$^{1\P}$, Haoqian Wang$^{2}$, Lei Zhang$^{1}$, Yu Li$^{1}$ \\
		$^{1}$ International Digital Economy Academy (IDEA), \\ $^2$  Shenzhen International Graduate School, Tsinghua University \\
		\url{https://osx-ubody.github.io}
}
%\maketitle 


\vspace{-0.75cm}
\twocolumn[{%
    \renewcommand\twocolumn[1][]{#1}%
    \maketitle
    \centering
    \captionsetup{type=figure}
    \includegraphics[width=0.9\linewidth]{fig/teaser.pdf}
    % \vspace{-0.2cm}
    \caption{A comparison of existing whole-body mesh recovery methods and ours. Most existing methods leverage a multi-stage pipeline which uses separate expert models to process body component (\eg, \textbf{E1}: HeadNet, \textbf{E2}: HandNet, \textbf{E3}: BodyNet) and fuse them to get the whole-body prediction in a copy-paste manner. The result (from~\cite{PavlakosGeorgios2020expose}) produces unnatural wrist poses. In contrast, our pipeline is a neat one-stage framework with a single encoder-decoder and can predict more accurately with natural meshes.}
    \vspace{0.7cm}
    \label{fig:teaser}
}]
\vspace{0.7cm}


%%%%%%%%% ABSTRACT
\begin{abstract}

%  final
Whole-body mesh recovery aims to estimate the 3D human body, face, and hands parameters from a single image. It is challenging to perform this task with a single network due to resolution issues, i.e., the face and hands are usually located in extremely small regions. Existing works usually detect hands and faces, enlarge their resolution to feed in a specific network to predict the parameter, and finally fuse the results. While this copy-paste pipeline can capture the fine-grained details of the face and hands, the connections between different parts cannot be easily recovered in late fusion, leading to implausible 3D rotation and unnatural pose. In this work, we propose a one-stage pipeline for expressive whole-body mesh recovery, named OSX, without separate networks for each part. Specifically, we design a Component Aware Transformer (CAT) composed of a global body encoder and a local face/hand decoder. The encoder predicts the body parameters and provides a high-quality feature map for the decoder, which performs a feature-level upsample-crop scheme to extract high-resolution part-specific features and adopt keypoint-guided deformable attention to estimate hand and face precisely. The whole pipeline is simple yet effective without any manual post-processing and naturally avoids implausible prediction. Comprehensive experiments demonstrate the effectiveness of OSX. Lastly, we build a large-scale Upper-Body dataset (UBody) with high-quality 2D and 3D whole-body annotations. It contains persons with partially visible bodies in diverse real-life scenarios to bridge the gap between the basic task and downstream applications. 
%\footnote{The code and dataset will be released upon acceptance.\\
\vspace{0pt}
\blfootnote{$\S$ Work done during an internship at IDEA; ${\P}$~Corresponding author.}
\end{abstract}

\input{sec/intro}
\input{sec/related_work}
\input{sec/method}
\input{sec/data}
\input{sec/exp}
\input{sec/conclusion}
% {\small
% \bibliographystyle{ieee_fullname}
% \bibliography{egbib}
% }
\input{main.bbl}

{\small
\bibliographystyle{ieee_fullname}
}
\input{sec_sup/supp}

%%%%%%%%% REFERENCES


\end{document}
