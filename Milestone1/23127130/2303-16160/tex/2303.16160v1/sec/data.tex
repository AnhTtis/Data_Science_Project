

\section{UBody--An Upper Body Dataset}
\label{sec:ubody}
%

3D whole-body mesh recovery from videos is a basic computer vision task, where it can provide comprehensive motion, gesture, and expression information to understand how humans perceive and act.
%
However, existing datasets lack scenes of downstream tasks, such as sign language recognition, gesture generation, emotion recognition, and real-life scenarios recorded as VLOGs, making recent state-of-the-art methods hard to generalize well on these scenes.
%
Interestingly, these scenarios are more concerned with the representations of \emph{upper bodies}.
We take this insight and present a novel large-scale benchmark for the expressive \emph{upper body} mesh recovery as shown in Figure~\ref{fig:ubody}(f) to (t), named \dataname. Our annotation pipeline is in Figure~\ref{fig:ubody_annotation}.
%
\emph{Due to the page limit, we put the data collection, data annotation processes, and annotation visualization in Appendix.} 

% \vspace{-0.1cm}
\subsection{Quality Analysis}
\label{sec:ubody_quality}

Our annotation pipeline produces far better 3D pseudo-GT fits with a shorter running time than the previous optimization-based and learning-based methods~\cite{HanbyulJoo2022eft,Feng_2021_pixie,Pavlakos_2019smplx,Moon_2022NeuralAnnot,pavlakos2022multishot}.
%
Figure~\ref{fig:ubody_vis_2d}(a) compares our 2D annotation results with the two wildly used annotation methods (OpenPose~\cite{ZheCao2018OpenPoseRM} and MediaPipe~\cite{FanZhang2020MediaPipeHO}). The quality of our 2D annotations is much more accurate, especially in terms of hand details and the robustness of occlusion and blur.
%
Figure~\ref{fig:ubody_vis_2d}(b) compares the 3D annotation of ours with the SOTA NeuralAnnot method~\cite{Moon_2022NeuralAnnot} on COCO. The quality of our approach is also better for the naked eye in terms of the fit of the body shape and the whole-body poses.

\subsection{Data Characteristics}
\label{sec:ubody_feature}

Compared to the popular datasets illustrated in Figure~\ref{fig:ubody} (a) to (e) and the related human-centric datasets listed in Table~\ref{tab:datasets}, \dataname possesses unique features that present new challenges for future research.
%for existing methods.
%
Many videos are from edited media with highly diverse scenes and rich human actions and gestures. They have abrupt shot changes and dynamic camera viewpoints, leading to discontinuities between the frames. Close-up shots of humans cause severe truncation, making existing methods tend to fail. Meanwhile, they have varying degrees of interaction with objects and body components, subtitles, and special effects as occluded scenes. Also, there are high variations in background and light. Those conditions have not appeared in previous datasets.
%
All scenes in \dataname have rich hand gestures and facial expressions, making the recognition models pay more attention to these important body components. Lastly, all of these real-life videos provide audio as additional information to serve future multi-modality methods.
We also provide statistical comparisons between the key features of \dataname and the wildly used dataset AGORA~\cite{Patel_2021agora} in Figure~\ref{fig:statis}.
%
AGORA's hand/face bounding box area is generally small, while \dataname pays more attention to diverse hand and face scales as evidenced by its more dispersed area distribution. Meanwhile, \dataname has more visible face/hand keypoints, underscoring the importance of recognizing hand gestures and facial expressions. Lastly, \dataname's inclusion of  real-life videos provides new possibilities for subsequent spatio-temporal modeling that are not available in AGORA, which is an image-based dataset.


\vspace{-0.3cm}
\begin{figure}[t]
\begin{center}
\includegraphics[width=1\linewidth]{fig/statis.pdf}
\end{center}
\vspace{-0.6cm}
\caption{The statistical comparisons of the areas of the hand and face bounding boxes (upper row) and the number of 2D visible hand and face keypoints (lower row) with the logarithmic scale of the Y-axis. \dataname focuses on upper bodies exhibiting expressive gestures and facial expressions. 
}
\label{fig:statis}
\vspace{-0.6cm}
\end{figure}




