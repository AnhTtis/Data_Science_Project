\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{indentfirst} 
% Include other packages here, before hyperref.
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage[title]{appendix}
\usepackage{cuted}
\usepackage{subfigure}
\usepackage{marvosym}
% \usepackage[UTF8]{ctex}

\renewcommand{\tablename}{Table}
\renewcommand{\figurename}{Fig.}
\renewcommand{\appendixname}{Appendix}
\renewcommand{\refname}{References}
% -------------------------------------------------------------
% \usepackage{cjkhl}
\usepackage{multirow}
\usepackage{diagbox}
\usepackage{colortbl}  %彩色表格需要加载的宏包
\usepackage{array}   %对表列和表格线的设置需要用到array宏包
\usepackage{ulem}

% \usepackage{biblatex}
% \addbibresource{myref.bib}
\usepackage{cite}


% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}
%%%%%%%%% TITLE - PLEASE UPDATE
\title{Edge-aware Plug-and-play Scheme for Semantic Segmentation}  % **** Enter the paper title here

\author{Jianye Yi\thanks{These authors contributed to the work equally and should be regarded as co-first authors.}, Xiaopin Zhong\footnotemark[1],
Weixiang Liu\textsuperscript{\Letter{}}, \\
Wenxuan Zhu, Zongze Wu, Yuanlong Deng\\
Lab. of Machine Vision and Inspection, College of Mechatronics and Control Engineering, \\
Shenzhen University,
\#3688 Nanhai Ave, Shenzhen, PR China\\
{\tt\small 2110296017@email.szu.edu.cn, xzhong@szu.edu.cn, \textsuperscript{\Letter{}}wxliu@szu.edu.cn,}\\ {\tt\small 2110296009@email.szu.edu.cn,zzwu@szu.edu.cn, dengyl@szu.edu.cn}}

\date{}
\maketitle
\thispagestyle{empty}
\setlength{\parindent}{2em}
\begin{abstract}
% 在语义分割任务中，加入边缘监督有利于提高模型的精度。
%In semantic segmentation tasks, incorporating edge supervision can improve the accuracy of the model. 
Semantic segmentation is a classic and fundamental computer vision problem dedicated to assigning each pixel with its corresponding class. 
Some recent methods introduce edge-based information for improving the segmentation performance. 
% 然而，目前相关研究提出的边缘监督方法都是具体而针对特定分割模型的，因此这些方法难以迁移到其他模型中使用。
%However, current edge supervision methods proposed in related research are specific and targeted towards certain segmentation models, making it difficult to apply these methods to other models. 
However these methods are specific and limited to certain network architectures, and they can not be transferred to other models or tasks. 
% 为此，我们提出了一种名为Edge-aware Plug-and-play Scheme（EPS）的抽象、普适、可以简单快速地应用于任何语义分割模型的边缘监督方法。
Therefore, we propose an abstract and universal edge supervision method called Edge-aware Plug-and-play Scheme (EPS), which can be easily and quickly applied to any semantic segmentation models. The core is edge-width/thickness preserving guided for semantic segmentation.
% EPS首先从Ground Truth (GT)中提取边缘厚度为$d_e$的Edge Ground Truth (Edge GT)，然后直接复制 decoder head 作为辅助任务，并以该Edge GT为监督信号。
%The EPS first extracts the Edge Ground Truth (Edge GT) with a predefined edge thickness of $d_e$ from the Ground Truth (GT), and then directly copies the decoder head as an auxiliary head, using the Edge GT as supervision. 
The EPS first extracts the Edge Ground Truth (Edge GT) with a predefined edge thickness from the training data; and then for any network architecture, it directly copies the decoder head for the auxiliary task with the Edge GT supervision.
% 为了更好地利用边缘厚度$d_e$这一先验知识，我们设计了一种基于边界的损失——Polar Hausdorff（PH）Loss。
%To better utilize the prior knowledge of the edge thickness $d_e$, we design a boundary-based loss, the Polar Hausdorff (PH) Loss.
To ensure the edge thickness preserving consistantly, we design a new boundary-based loss, called Polar Hausdorff (PH) Loss, for the auxiliary supervision.
We verify the effectiveness of our EPS on the Cityscapes dataset using 22 models. 
% 我们在Cityscapes数据集上使用了22个模型验证了EPS的有效性。
% 实验结果表明，EPS可以直接插入现有SOTA模型中而无需对Basline进行任何修改，并且能够进一步提高分割精度。
The experimental results indicate that the proposed method can be seamlessly integrated into any state-of-the-art (SOTA) models with zero modification, resulting in promising enhancement of the segmentation performance.


\end{abstract}

%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW
\section{Introduction}
% 语义分割旨在对每个像素进行密集的预测，实现像素级的分类。
Semantic segmentation aims to achieve pixel-level classification by providing dense predictions for each pixel.
% 随着卷积神经网络的快速发展以及Transformer\cite{vaswani2017attention}在视觉领域的应用，出现了一批又一批基于深度学习的语义分割模型，例如基于CNN的FCN\cite{long2015fully}、DeepLab\cite{chen2017deeplab}、PSPNet\cite{zhao2017pyramid}和CGNet\cite{wu2020cgnet}，以及基于ViT\cite{dosovitskiy2010image}的Segmenter\cite{strudel2021segmenter}和SegFormer\cite{xie2021segformer}等。
With the rapid development of convolutional neural networks and the application of Transformer\cite{vaswani2017attention} in the field of computer vision, a series of deep learning-based semantic segmentation models have emerged, such as CNN-based FCN\cite{long2015fully}, DeepLab\cite{chen2017deeplab}, PSPNet\cite{zhao2017pyramid}, CGNet\cite{wu2020cgnet}, and ViT-based Segmenter\cite{strudel2021segmenter} and SegFormer\cite{xie2021segformer}, etc.
% 可以发现研究者们致力于提出一种新的网络结构来提升语义分割的性能，他们总是从模型设计的角度出发去研究，因此设计出来的网络结构是具体的、独特的。
Researchers are always striving to propose new network structures to improve the performance of semantic segmentation. 
They usually approach the problem from the perspective of model design, resulting in specific and unique network structures. 
% 然而，这样难以跳出以往的网络设计观念，即设计一个完整的从backbone到decoder的分割模型。
However, this approach may lead to overfitting during training and may not be easily applicable to various applications.
% 但特定的网络模型一方面可能使训练过拟合，另一方面难以推广到各种应用。
% 因此我们认为设计一种适用于任何模型的、抽象的、通用的策略很可能比单纯的模型设计更有效。
Therefore, we believe that it is more effective to design a general and abstract scheme that is applicable to any model, rather than solely relying on model design.


% 目前，在有监督的语义分割任务中，大部分研究者直接使用原始标注数据进行监督，但是有少数研究者挖掘了原始数据的其他特征进行更有效的监督，例如加入边缘监督。
Currently, in supervised semantic segmentation tasks, most researchers directly use the original annotated data for supervision. 
However, a minority of researchers have explored other features of the original data for more effective supervision, such as adding edge supervision. 
% 边缘检测是一种提取图像边缘的任务\cite{marr1980theory}，近年来相关工作\cite{zheng2019elkppnet,zhang2019net,li2020improving,hatamizadeh2020edge,chen2020semeda,chen2016semantic}将边缘检测结果嵌入到语义分割中，证实了边缘监督确实可以有效提升分割模型的精度。
Edge detection is a task of extracting image edges\cite{marr1980theory}. 
In recent years, related works\cite{zheng2019elkppnet,zhang2019net,li2020improving,hatamizadeh2020edge,chen2020semeda,chen2016semantic} have embedded the results of edge detection into semantic segmentation and confirmed that edge supervision can effectively improve the accuracy of segmentation models.
% 由于基于CNN的框架具有局部性的归纳偏置，为了增大感受野，需要对特征图进行pooling，这导致了分割边界的模糊和不确定性\cite{zhou2014object,luo2016understanding}，最终使分割精度受限。
Due to the locality of CNN's inductive bias, it is necessary to perform pooling on the feature maps to increase the receptive field (RF), which leads to blurring and uncertainty of segmentation boundaries\cite{zhou2014object,luo2016understanding}, ultimately limiting segmentation accuracy. 
% 虽然基于ViT的分割模型具有全局感受野，目前也还没有相关的工作将边缘监督加入到基于ViT的分割模型中，但这并不意味着边缘监督对基于ViT的分割网络不重要。
Although ViT-based segmentation models have global RF, there is currently no related work on adding edge supervision to ViT-based segmentation models. However, this does not mean that edge supervision is not important for ViT-based segmentation networks.
% 无论是从空间几何的角度，将语义分割的对象分为边缘和主体，还是从频域的角度，分为高频和低频信息，这些分类都是根据人的经验进行的。
Whether from a spatial-geometric perspective, dividing the objects of semantic segmentation into edges and bodies, or from a frequency domain perspective, dividing them into high-frequency and low-frequency information, these classifications are based on human experience. 
% 这也一定程度上解释了为什么加入边缘监督这种先验知识可以提升模型精度。
This partly explains why adding edge supervision as prior knowledge can improve model accuracy.


% 为了利用边缘信息这一先验提升分割的性能，研究者们在网络中增加一个边缘监督的任务。
To leverage edge information as prior knowledge to improve segmentation performance, researchers have incorporated an edge supervision task into the network. 
% Li et al.\cite{li2020improving}将目标的边缘和主体进行解耦，然后分别对它们进行监督学习，最后再融合边缘和主体的分割结果。
Li et al.\cite{li2020improving} decoupled the edges and bodies of the targets and supervised them separately, and then fused the body feature and the residual edge feature.
% 然而，这种方法需要专门设计解耦器和融合器，不易迁移到其他分割模型中。
However, this approach requires specially designed decouplers and fusers, which are not easily transferable to other segmentation models. 
% Zhang et al.\cite{zhang2019net}根据CNN的多尺度特征，利用其前两层提取边缘特征来设计一个auxiliary decoder进行监督。
Zhang et al.\cite{zhang2019net} designed an auxiliary decoder that utilizes the edge features extracted from the first two layers of the CNN's multi-scale features for edge supervision. 
% 但是这种方法只适用于CNN网络，对于基于ViT的分割网络并不适用，因为ViT不具有多尺度特征。
However, this method is only suitable for CNN networks and is not applicable to ViT-based segmentation networks, as ViT does not have multi-scale features. 
% Chen et al.\cite{chen2020semeda}提出了一种边缘监督框架SEMEDA，并且设计了一种segmentic edge detection network来提取分割结果的边缘进行监督。
Chen et al.\cite{chen2020semeda} proposed a SEMEDA framework with a segmentic edge detection network to extract edges from segmentation results for supervision. 
% 但是这种结构是特定的，不一定在其他分割网络中有效。
However, this structure is specific and may not be effective in other segmentation networks. 
% As far as we know，当前所有的这类方法所增加的边缘监督任务都是利用特定设计的网络结构进行的，因此缺乏快速迁移和普遍适用的特性。
To the best of our knowledge, all existing techniques that integrate edge supervision tasks rely on network architectures tailored for this purpose and are deficient in rapid transfer and universal applicability attributes.
% 此外，他们使用的损失是基于分布的交叉熵损失\cite{ronneberger2015u}，基于分布的损失并不具备空间几何特点，因此不适合具有空间几何特征的边缘图像。
In addition, they use distribution-based cross-entropy loss, which does not have spatial-geometric characteristics and is therefore unsuitable for edge images with spatial-geometric features.


% 我们针对语义分割中边缘监督模块不具备快速plug-and-play和普遍适用特性的问题提出了Edge-aware Plug-and-play Scheme (EPS)，这种策略不仅仅适用于某个特定网络。
We propose an Edge-aware Plug-and-play Scheme (EPS) to address the issue of edge supervision modules lacking the characteristics of easy plug-and-play and general applicability in semantic segmentation. 
% 而且EPS只在训练过程中使用，不会影响模型推理时的模型大小和推理速度。
This scheme exhibits universal applicability across various networks and is solely utilized during the training phase, ensuring that the model size and inference speed remain unaltered during testing.
% 同时，我们提出了基于边界的损失函数Polar Hausdorff (PH) Loss，该损失是一种极坐标表示的简化的Hausdorff distance (HD) Loss。
Additionally, we propose a Polar Hausdorff (PH) Loss, a simplified version of the Hausdorff distance (HD) Loss represented in polar coordinates, to better utilize edge information. 
% 在给定边缘厚度$d_e$之后，EPS可以根据$d_e$计算kernel的大小来生成Edge GT，而PH Loss的优化目标则是对边缘分割结果中的边缘厚度进行约束，使其趋向于$d_e$。
With the given edge thickness $d_e$, EPS can calculate the kernel size to generate Edge GT, and the optimization target of PH Loss is to constrain the edge thickness in the edge segmentation result to approach $d_e$. 
% 我们使用Cityscapes数据集在MMSegmentation框架下进行了22个模型的实验，证明了EPS的有效性。
We conduct experiments on the Cityscapes dataset with 22 models in the MMSegmentation framework to demonstrate the effectiveness of EPS.
% 总的来说，我们的贡献和创新点如下：
Our contributions are summarized as follows:
% \begin{itemize}
%     \item 提出一种适用于任何语义分割模型（无论是CNN-based还是ViT-based模型）的策略EPS，使用该EPS可以快速有效地为分割网络提供边缘监督。
%     \item 为了更好地利用边缘信息，提出了一种新的基于边界的损失函数PH Loss，它可以约束边缘的厚度，以此提供更准确的边缘监督信号。
%     \item 通过实验证明，无需对Baseline作任何修改，EPS即可在现有SOTA模型上plug and play，并进一步提升模型精度。
% \end{itemize}
\begin{itemize}
    \item We introduce a novel scheme called EPS that offers effective edge supervision to any semantic segmentation model, regardless of whether it is based on CNN or ViT.
    \item In order to leverage edge information, we propose a novel boundary-based loss function, PH Loss, which restricts the thickness of edges and improves the accuracy of edge supervision signals.
    \item Our experiments show that EPS can be seamlessly integrated into the existing SOTA without any modification, leading to improved model accuracy.
\end{itemize}

%-------------------------------------------------------------------------
\section{Related Work}

\subsection{Edge-supervised Segmentation}
% （这里要说明为什么要使用边缘监督，同时也要提到他们虽然用了边缘监督，但是没有设计相关的边缘损失！！）
\begin{figure}[h]
    \centering
    \includegraphics[width=8cm]{image/edge_supervised.png}
    \caption{The left-hand side shows a parallel framework with edge supervision, while the right-hand side shows a serial framework with edge supervision. $x$ denotes the input image, $\hat{y}$ represents the GT, and $\hat{y}_e$ is the Edge GT. $E$ and $D$ denote Encoder and Decoder, respectively, while $D_e$ is the Edge Decoder.}
    \label{fig:edge_supervised}
\end{figure}

% 在语义分割任务中，目标的分割精度越高往往其边缘部分的分割也越准确，反之亦然。
In semantic segmentation tasks, the higher the segmentation accuracy of the target, the more accurate the segmentation of its edge parts tends to be, and vice versa.
% 因此，在分割模型中有效地加入边缘监督，可以提升网络的分割精度。
Therefore, effectively incorporating edge supervision in the segmentation model can improve the segmentation accuracy of the network.
% 目前在分割模型中加入边缘监督的做法大致可以分为两种，并联监督和串联监督（如图\ref{fig:edge_supervised}所示）。
Currently, there are two main approaches to incorporating edge supervision in segmentation models: parallel supervision and 
series supervision (as shown in Figure \ref{fig:edge_supervised}).


% 并联监督一般在主干外增加 Auxiliary head，其输入为原始输入图像$x$，使用边缘标签 $\hat{y}_e$进行监督，以提高主干上 decoder head 的分割精度。
The parallel supervision usually adds an auxiliary head outside the backbone, which takes the original input image $x$ as its input and uses the edge label $\hat{y}_e$ for supervision to improve the segmentation accuracy of the decoder head on the backbone.
% 例如，EG-CNN\cite{hatamizadeh2020edge}利用 edge gated layer 来重建目标的边缘，而ET-Net\cite{zhang2019net}则利用 CNN 前两层对边缘特征的提取能力，提取底层特征进行边缘监督。
For example, EG-CNN \cite{hatamizadeh2020edge} uses edge gated layers to reconstruct the edges of the target, while ET-Net \cite{zhang2019net} uses the feature extraction ability of the first two layers of CNN to extract low-level features map for edge supervision.
% 但是，这些方法都不适用于不具有多尺度特征的 ViT-based 的模型。Chen et al.\cite{chen2016semantic}将边缘检测任务和分割任务结合起来，通过一种融合网络 将边缘检测和分割的结果融合，以提高分割的精度。
However, these methods are not suitable for ViT-based models that do not have multi-scale features. Chen et al. \cite{chen2016semantic} combines edge detection tasks with segmentation tasks, and through a fusion network, fuses the results of edge detection and segmentation to improve the segmentation accuracy.
% 除此之外，Li et al.\cite{li2020improving}先将分割结果的边缘提取出来，再利用边缘监督和主体监督分别对边缘和主体两部分进行分割，并最终设计一个融合模型将两部分的结果进行融合。
Moreover, Li et al. \cite{li2020improving} first extracts the edges from the segmentation results, and then uses edge and body supervision to separately segment the edges and bodies, and finally designs a fusion model to merge the results of both parts.
% 然而，后两种方法都需要额外设计一个融合网络来利用边缘监督提升分割精度，因此，分别提取边缘和分割的结果再融合的做法是繁琐的。
However, the latter two methods require an additional fusion network to use edge supervision to improve segmentation accuracy. Therefore, the approach of extracting edges and segmentation results separately and then merging them is cumbersome.


% 串联监督直接在分割网络后增加一个边缘提取器，其输入是分割网络的预测结果$\hat{y}$。
The series supervision involves the attachment of an auxiliary edge detector to a segmentation network, with input provided by $\hat{y}$, the predicted output from the segmentation network. 
% 通过使用边缘标签$\hat{y}_e$进行监督，影响主干和解码器的边缘信息提取能力，从而提高分割精度。
Through supervision using edge labels $\hat{y}_e$, the information extraction capabilities for edges in the backbone and decoder are influenced, resulting in improved segmentation accuracy.
% 例如，KLPPNet\cite{zheng2019elkppnet}直接对分割的结果进行传统算法的边缘提取，并计算其与边缘标签$\hat{y}_e$的损失。
Zheng et al. proposed KLPPNet \cite{zheng2019elkppnet} that extracts edges through traditional algorithmic methods directly from the segmentation results and calculates its loss against edge labels $\hat{y}_e$.
% SEMEDA\cite{chen2020semeda}边缘监督框架提出了一种segmentic edge detection network，将其连接到decoder head之后，以利用边缘监督信息。
SEMEDA \cite{chen2020semeda}, on the other hand, introduced a segmentic edge detection network in series framework connected to the decoder head to exploit edge supervision information.
% 这种串联方式的监督会增加网络深度，可能会对边缘监督的反向传播产生不利影响，因此主干的边缘信息提取能力可能不会显著提高。
However, such a series approach increases the architecture's depth, which may trigger adverse effects on back-propagation outcomes during edge supervision and potentially lower the primary network's edge information extraction capacity.

% 在上述相关工作中，大部分都是为特定的网络设计特定的边缘监督模块，无论是并联监督还是串联监督。
Most of the previous works above are designed with specific edge supervision modules for certain networks, whether in parallel or series supervision. 
% 然而，这种特定的模块难以迁移至其他分割网络中，且不能确保其有效性。
However, such specific modules are difficult to transfer into other segmentation networks and their effectiveness cannot be guaranteed.

\subsection{Boundary-based Loss}
\begin{figure*}[h]
    \centering
    \includegraphics[width=14cm]{image/CopyHead_only_decoder_head.png}
    \caption{For a semantic segmentation model with only one decoder head, the EPS involves creating a new auxiliary head by completely copying the original decoder head, without changing any of its structure. Then, the Edge GT obtained from GT by edge extraction is used for edge supervision. For a semantic segmentation model that already has an auxiliary head, we directly replace the GT with Edge GT to perform edge supervision on its auxiliary head without any other operations.
    }
    \label{fig:CopyHead_only_decoder_head}
\end{figure*}

% 语义分割中的损失函数至关重要,一个好的损失函数可以使网络学习更加高效。
In semantic segmentation, the loss function plays a crucial role as it can significantly affect network learning efficiency.
% Ma et al.\cite{ref_Ma_Loss}和Jadon et al.\cite{ref_Jadon_survey}将现有的分割损失分类为四种，分别为基于分布的损失、基于区域的损失、复合损失和基于边界的损失。
Existing segmentation losses have been classified into four categories by Ma et al. \cite{ref_Ma_Loss} and Jadon et al. \cite{ref_Jadon_survey}: distribution-based losses, region-based losses, compound losses, and boundary-based losses.
% 不同类型的损失函数具有不同的优化目标和侧重点。例如，基于分布的损失旨在提高整体分类准确率，基于区域的损失旨在增加预测结果和真实标签的重叠程度，复合损失函数结合了这两种类型的优点。
Different types of loss functions have different optimization objectives and focuses, where distribution-based losses aim to improve overall classification accuracy, region-based losses aim to increase the overlap between predicted results and true labels, and compound losses combine the strengths of both types. 
% 而基于边界的损失则从spatial geomtry的角度出发，使用预测标签和真实标签之间的边界距离构建损失函数。
The boundary-based loss, on the other hand, approaches it from a spatial geometry perspective by using the distance between the predicted and ground truth labels' boundaries to construct the loss function.
% 本研究关注的是基于边界的损失函数，目前经典的该类损失函数包括Boundary (BD) Loss\cite{kervadec2019boundary}和Hausdorff distance (HD) Loss\cite{karimi2019reducing}。
This study is centered on boundary-based loss functions, wherein some of the premier functions within this classification encompass the Boundary (BD) Loss \cite{kervadec2019boundary} and the Hausdorff distance (HD) Loss \cite{karimi2019reducing}.


% \textbf{BD Loss}通过计算每个像素点到其真实标签区域上最近的边界像素之间的距离来度量边界的预测质量，其具体的计算公式可以定义为\cite{kervadec2019boundary}：
\textbf{BD Loss} measures the quality of boundary prediction by calculating the distance between each pixel and the nearest boundary pixel in GT. The specific calculation formula can be defined as  \cite{kervadec2019boundary}:
\begin{equation}
 \mathcal\phi_G(q) =\left\{
\begin{array}{rcl}
-D_G(q),       &      & {q \in G}\\
D_G(q),       &      & {q \not\in G}
\end{array} \right. ,     
\label{equ:phi_G(q)}
\end{equation}
\begin{equation}
\begin{array}{rcl}
    \mathcal L_{BD}=\int_{\Omega}\phi_G(q)S_\theta(q)dq,
\end{array}
    \label{equ:L_BD}
\end{equation}
% 式中，$\Omega$指整一个图像区域，$q \in \Omega$是图像上的任意一个像素点，$G \subseteq \Omega$是真实标签所在区域，在$G$上的二值像素点取值为$\{0,1\}$，$S_{\theta} \subseteq \Omega$是预测标签所在区域，在$S_{\theta}$上像素取值为$(0,1)$，$D_G(q)$是像素点$q$与区域$G$的轮廓上的最近像素点的距离。
where, $\Omega$ refers to the entire image area, $q \in \Omega$ is any pixel point on the image, $G \subseteq \Omega$ is the region where the GT exists, with binary pixel values of $\{0,1\}$, $S_{\theta} \subseteq \Omega$ is the predicted labeling area, with pixel values of $(0,1)$, and $D_G(q)$ is the distance between the pixel point $q$ and the nearest pixel points on the boundary of the region $G$.


% \textbf{HD Loss}则是通过计算预测边界和真实边界之间的Hausdorff距离来度量边界预测的准确度。其公式可以表示为：
\textbf{HD Loss} measures the accuracy of boundary prediction by computing the Hausdorff distance between predicted and GT boundaries. Its formula can be expressed as:
\begin{equation}
\begin{array}{rcl}
     d_{AB}=max_j(min_i(d(a_i,b_j))),
\end{array}
    \label{equ:d_NM}
\end{equation}
\begin{equation}
\begin{array}{rcl}
     d_{BA}=max_j(min_i(d(a_j,b_i))),
\end{array}
    \label{equ:d_NM}
\end{equation}
\begin{equation}
\begin{array}{rcl}
    \mathcal L_{HD} = max(d_{AB}, d_{BA})
\end{array}
    \label{equ:d_NM}
\end{equation}
% 式中，$A$是预测边界上的像素点总数，$a_i$是预测边界上的像素点，$B$是真实边界上的像素点总数，$b_j$是真实边界上的像素点，$d(a_i,b_j)$是像素点$a_i$和$b_j$之间的欧式距离。
where, $A$ is the total number of pixels on the predicted boundary, $a_i$ represents a pixel on it, $B$ is the total number of pixels on the GT boundary, $b_j$ represents a pixel on it, and $d(a_i,b_j)$ is the Euclidean distance between pixel $a_i$ and $b_j$.


% 由于边缘监督和基于边界的损失都是从空间几何的角度出发的，所以它们的出发点是一致的。
As both edge supervision and boundary-based losses are approached from a spatial-geometric perspective, their ideological origins are consistent.
% 然而据我们所了解，到目前为止，对于利用边缘监督进行语义分割的任务，还没有研究者结合基于边界的损失提出一种边缘监督策略。
However, to the best of our knowledge, no research has emerged that have proposed an edge supervision scheme in combination with boundary-based losses, for semantic segmentation tasks.
%-------------------------------------------------------------------------
\section{Methods}
\subsection{Edge-aware Plug-and-play Scheme}
% 针对前面提到的相关边缘监督工作不容易迁移到其他类型的语义分割网络中使用的问题，我们提出了一种Edge-aware Plug-and-play Scheme (EPS)。
To address the issue that the aforementioned relevant edge supervision methods are not easily applicable to other types of semantic segmentation networks, we propose an Edge-aware Plug-and-play Scheme (EPS).
% 它适用于任何语义分割网络，并且使用简单。
It is applicable to any semantic segmentation network and is easy to use.
% EPS主要包含两个步骤，分别是提取边缘厚度为$d_e$的Edge GT和Copy decoder head。
EPS mainly consists of two steps, which are to extract Edge GT with a thickness of $d_e$ and to copy decoder head.

% 首先，边缘厚度$d_e$可以反映Edge GT边缘粗细的程度，不同边缘厚度的Edge GT对边缘监督存在一定的影响\cite{zheng2019elkppnet}。
Firstly, the edge thickness $d_e$ can reflect the degree of edge coarseness, and Edge GT with different edge thicknesses has different  effects on edge supervision\cite{zheng2019elkppnet}. 
% 为了生成边缘厚度为$d_e$的Edge GT，EPS使用大小为$n\times n$的kernel来对GT图像进行最简单的边缘提取，$d_{e}$和n的关系以及kernel的计算方式如下：
In order to generate Edge GT with a thickness of $d_e$, EPS uses the simplest edge extraction method by using a kernel of size $n\times n$ to process the GT image. The relationship between $d_{e}$ and $n$, as well as the calculation method of the kernel, are as follows:
\begin{equation}
\begin{array}{rcl}
    n = 2d_e+1
\end{array}
    \label{equ:d_e}
\end{equation}
\begin{equation}
\begin{array}{rcl}\scriptsize
    kernel = 
    \begin{bmatrix}
    0 & ...&0 & -1 &0 & ... & 0 \\
    ... & ...&... & ... &... & ... & ... \\
    0 & ...&0 & -1 &0 & ... & 0 \\
    -1 & ...&-1 & 4d_e &-1& ... & -1 \\
    0 & ...&0 & -1 &0 & ... & 0 \\
    ... & ...&... & ... &... & ... & ... \\
    0 & ...&0 & -1 &0 & ... & 0 \\
    \end{bmatrix}
\end{array}
    \label{equ:kernel}
\end{equation}

% 其次，EPS将decoder head复制一遍，生成一个skip connection与decoder head完全相同的auxiliary head，其权重与decoder head不共享。
Secondly, EPS copies the decoder head to generate an auxiliary head with a skip connection identical to the decoder head, but its weights are not shared with the decoder head.
% 但是其监督信息是Edge GT（见图\ref{fig:CopyHead_only_decoder_head}）。
 However, its supervision information is Edge GT (see Figure \ref{fig:CopyHead_only_decoder_head}).
% 可以看出，EPS是一种抽象策略，具体的实现方式是根据语义分割网络而定的，因此具有普遍适用性，且易于实现，也是即插即用的。
It can be seen that EPS is an abstract strategy, and its specific implementation depends on the semantic segmentation network, so it has general applicability and is easy to implement, also plug-and-play.
% EPS仅在训练过程中参与模型参数的更新，在推理过程中完全可以舍弃，不会改变推理时的模型大小。
EPS only participates in the updating of model parameters during training and can be completely discarded during inference, without changing the size of the model during inference. 
% 尽管该策略十分简单，但我们的实验证明其非常有效。
Although this scheme is simple, our experiments have proven its effectiveness.


\subsection{Polar Hausdorff Loss}
% 在 EPS 中，我们将Edge GT的边缘厚度$d_{e}$ 定义为一个先验知识，其取值可以由kernel的大小反映。
In EPS, we define the edge thickness $d_{e}$ of Edge GT as prior knowledge, and its value can be reflected by the size of kernel.
% 例如，设置Edge GT的边缘厚度$d_{e}=3$，只需使用$7\times7$的kernel处理GT。
For example, to set the edge thickness of Edge GT to $d_{e}=3$, a $7\times7$ kernel is used to process GT.
% 由于基于分布的损失是对全局进行优化的，其并没有边缘厚度的概念，所以边缘分割的厚度是随机的和不确定的。
As the distribution-based loss optimizes globally, it doesn't have the concept of edge thickness, so the edge segmentation thickness is random and uncertain.
% 而EPS中提取出的Edge GT具有厚度为$d_e$的边缘，该边缘的厚度是明确的和等厚的，基于分布的损失并不能利用这一先验知识。
On the other hand, the extracted Edge GT in EPS has an explicit and equally-thick boundary with a thickness of $d_e$.
% 为了充分利用此先验知识，我们提出了一种基于边界的损失Polar Hausdorff (PH) Loss。
To fully utilize this prior knowledge, we propose a boundary-based loss called Polar Hausdorff (PH) Loss.
% PH Loss计算的是边缘预测图像$\hat{p}$中内部边缘和外部边缘之间的Hausdorff距离(见图\ref{fig:sample})，并使其趋于EPS中Edge GT的边缘厚度$d_e$。
PH Loss calculates the Hausdorff distance between the internal and external edges in the predicted image $\hat{p}$ (as shown in Fig.\ref{fig:sample}), and makes it tend to $d_e$, the edge thickness of Edge GT in EPS.
% 这也是其与HD Loss的区别，HD Loss计算的是预测图像和GT两者之间的Hausdorff距离。
This is different from HD Loss, which calculates the Hausdorff distance between the predicted image and GT.

\begin{figure}
\centering
    \begin{minipage}[t]{0.22\textwidth}
        \centering
        \includegraphics[width=3.5cm]{image/p1.png}
    \end{minipage}
    \begin{minipage}[t]{0.22\textwidth}
        \centering
        \includegraphics[width=3.5cm]{image/p2.png}
    \end{minipage}
    \caption{On the left is the edge prediction image $\hat{p}$. On the right is the edge image $\hat{p}_e$ of $\hat{p}$, which is obtained by processing $\hat{p}$ with a thickness of $d_e=1$.}
    \label{fig:sample}
\end{figure}
% 假设边缘预测图像$\hat{p}$为图\ref{fig:sample}左，提取该边缘预测图像$\hat{p}$厚度为1的边缘图像$\hat{p}_e$（如图\ref{fig:sample}右）。
Assuming the edge prediction image $\hat{p}$ is as shown in Fig. \ref{fig:sample} (left), the edge image $\hat{p_e}$ with thickness 1 of the predicted edge image $\hat{p}$ is extracted (Fig. \ref{fig:sample} right).
% 根据EPS，该图像的Edge GT的边缘厚度为设定好的$d_{e}$。
According to EPS, the edge thickness of Edge GT is defined as a preset value $d{e}$.
% 因此，在训练过程中，图\ref{fig:sample}右的内边像素点集$P$和外边像素点集$Q$之间的Hausdorff distance应该趋向于$d_{e}$，这就是PH Loss的优化目标。
Therefore, during training, the Hausdorff distance between the inner edge pixel set $P$ and the outer edge pixel set $Q$ of the image in Figure \ref{fig:sample} right should tend toward $d_{e}$, which is the optimization goal of PH Loss.
% 因此，PH Loss的具体定义为：
Thus, PH Loss is specifically defined as:
\begin{equation}
\begin{array}{rcl}
    \mathcal L_{PH} = |PHD_{P,Q}(\hat{p},n)- d_{e}|
\end{array}
    \label{equ:L_PH}
\end{equation}
% 式中，$PHD_{P,Q}(\hat{p},n)$指的是内外边之间的Polar Hausdorff distance，$d_{e}$的计算见式(\ref{equ:d_e})。
where, $PHD_{P,Q}(\hat{p},n)$ refers to the Polar Hausdorff distance between internal and external edges, and the calculation of $d_e$ is shown in equation (\ref{equ:d_e}).

 \begin{figure}[h]
    \centering
    \includegraphics[width=6.5cm]{image/P3.png}
    \caption{When computing the $PHD_{P,Q}$, the process involves drawing a ray from the polar coordinate center at an angle of $\theta=i\times 360^{\circ}/n$, and selecting the intersection points of this ray and the inner and outer edges.}
    \label{fig:polar_hausdorff}
\end{figure}

% PH Loss的计算难点是区分出边缘预测图像的边缘图像$\hat{p}_e$的内边和外边，因为不可能使用一个像素分类器将内边和外边进行区分，这会大大增加损失的计算量。
The computation of PH Loss is challenging in distinguishing the inner and outer edges of the edge image $\hat{p_e}$ for calculating the Polar Hausdorff distance between them since it is not feasible to classify them using one-pixel classifier, which can significantly increase the computational burden of the loss. 
% 为了解决这个问题，我们提出了一种更为简便的方法，使用极坐标系来区分内外边，并计算它们之间的Hausdorff Distacne，具体见算法\ref{method:calculate_polar_hausdorff_distance}所示。
To address this problem, we propose a more straightforward approach by utilizing the polar coordinate system to distinguish the inner and outer edges and compute their Hausdorff distance, as shown in Algorithm \ref{method:calculate_polar_hausdorff_distance}. 
% 结合图\ref{fig:polar_hausdorff}，我们首先计算出$\hat{p}_e$上$P\cup Q$的几何中心，再通过中心化将$P$和$Q$中所有像素点的坐标转换成极坐标。
Combining Fig.\ref{fig:polar_hausdorff}, we first determine the geometrical center of the set $P\cup Q$ on $\hat{p_e}$, and then use centering to convert the coordinates of all pixels in $P$ and $Q$ into polar coordinates.
% 我们引入了一个超参数$n$，从几何中心向外画出$n$条射线，这$n$条射线的极角$\theta$均匀地从$0^{\circ}$开始，每次增加$360^{\circ}/n$。
We introduce a hyperparameter $n$ and draw $n$ rays from the geometric center outwards, with their angles uniformly starting from $0^{\circ}$ and increasing by $360^{\circ}/n$ each time. 
% 接着计算极角为$\theta$的射线与内外边上的交点集合$$P\cup Q$_{\theta}$，计算每一个交点到极坐标中心的距离$\rho_{\theta}$。
Then, for each angle $\theta$, we calculate the set of intersection points $P_{\theta}\cup Q_{\theta}$ of the ray with angle $\theta$ and the inner and outer edges, and compute the distance $\rho_{\theta}$ from each intersection point to the center. 
% 选取其中最小值$\rho_{min}$，该最小值对应的交点$p$必然在内边交点集合$P_{\theta}$上。
We select the minimum value $\rho_{min}$, and the corresponding intersection points $p$ lies on the inner edge intersection set $P_{\theta}$. 
% 我们认为内边交点之间的距离小于阈值$\delta=2$，通过阈值挑选出所有的内边交点$P_{\theta}$，则剩余的交点$P_{\theta}\cup Q_{\theta}$为外边交点集合$Q_{\theta}$，至此，我们区分出了极角为$\theta$的射线与$P\cup Q_{\theta}$之间交点的内交点集合$P_{\theta}$和外交点集合$Q_{\theta}$。
We consider that the distances among the intersection points in $P_{\theta}$ are less than the threshold $\delta=2$, and select all the inner edge intersections $P_{\theta}$ via thresholding, while the remaining intersections $P_{\theta}\cup Q_{\theta}$ form the outer edge intersection set $Q_{\theta}$. 
Thus, we have distinguished the inner intersection sets $P_{\theta}$ and the outer intersections set $Q_{\theta}$ of the ray with angle $\theta$ between $P_{\theta}\cup Q_{\theta}$.
% 计算$P_{\theta}$中距离极坐标中心最远的点和$Q_{\theta}$中距离极坐标中心最近的点之间的欧式距离，该距离为$\theta$角的Hausdorff distance $d_{ph}$。
By traversing each angle $\theta$ of the rays, finally, we calculate the Euclidean distance $d_{ph}(\theta)$ between the farthest points in $P_{\theta}$ and the nearest points in $Q_{\theta}$.
% 通过遍历所有角度的射线，可以选取出$n$个$d_{ph}$，选取其中最大值作为Polar Hausdorff distance $PHD_{P,Q}(\hat{p},n)$。
The ultimate step is to select the maximum value from all of  $\{d_{ph}(\theta)\}$ as the Polar Hausdorff distance $PHD_{P,Q}$.

% PH Loss是结合EPS 提出的一种边缘监督损失，其中涉及了两个超参数。
The PH Loss is a proposed edge-supervision loss combined with EPS, which involves two hyperparameters.
% 一个是用于提取$\hat{p}_e$的边缘厚度的超参数$d_e$，该超参数也是PH Loss中超参数。
One is the hyperparameter for extracting the edge thickness $d_e$ of $\hat{p}_e$, which is also a hyperparameter in PH Loss.
% 另一个是PH Loss中从极坐标中心射出的射线的条数$n$，但是在后续的实验中发现，$n$具有鲁棒性，即$n$的选取对结果影响不大，我们推荐$n=8$。
The other is the number of rays from the polar coordinate center in PH Loss, denoted as $n$. However, in subsequent experiments, it was found that $n$ had robusness, meaning that the choice of $n$ has little effect on the results. We recommend setting $n=8$.

%-------------------------------------------------------------------------
\section{Experiments}
 \begin{figure*}[h]
    \centering
    \includegraphics[width=17cm]{image/output.png}
    \caption{For the purpose of visualizing the results of semantic segmentation using CGNet, the images are presented in a top-to-bottom order, including the GT images, the baseline result, and the result obtained after applying EPS.}
    \label{fig:output}
\end{figure*}
\subsection{Experimental Settings}
% 我们使用 Cityscapes 数据集验证了我们的方法。Cityscapes is a driving dataset for semantic segmentation consisting of 5000 fine-annotated high resolution images with 19 categories.
Our proposed method was evaluated using the Cityscapes dataset, a well-known benchmark for semantic segmentation, which comprises 5000 high-resolution images with 19 categories. 
% 在硬件方面，我们使用一台配备有 I7 12700K CPU 和两个 24G RTX3090Ti GPU 的 Linux 服务器进行训练。
For hardware, we trained our models on a Linux server equipped with an I7 12700K CPU and two 24G RTX3090Ti GPUs.
%在软件框架方面，我们使用基于 PyTorch 的语义分割框架 MMSegmentation 进行所有的训练和测试。
In terms of software framework, we utilized the PyTorch-based semantic segmentation framework MMSegmentation for all training and testing.

% 为了公平比较实验结果，所有的模型都使用 MMSegmentation 官方默认参数进行训练，例如learning rate，momentum等。
To ensure fair comparisons of experimental results, all models were trained with the official default parameters of MMSegmentation, such as the learning rate and momentum. 
% 实验中没有作损失函数类型声明的部分均使用CE Loss，PH Loss由于单独训练不稳定，我们直接将PH Loss与CE Loss结合使用。
For the loss function, we utilized the Cross-Entropy (CE) Loss as the base and combined it with the Polar Hausdorff (PH) Loss to achieve better segmentation accuracy.
% 同时，We use the standard mean Intersection over Union (mIoU) and mean Accuracy (mAcc) metric to report segmentation accuracy.
We reported segmentation accuracy using the standard mean Intersection over Union (mIoU) and mean Accuracy (mAcc) metrics.

\IncMargin{1em}
    \begin{algorithm}\small \SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up} \SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress} \SetKwInOut{Input}     {input}\SetKwInOut{Output}{output}
        \Input{$\hat{p}$ with size $w\times h$, $\sigma=0.1$, $\delta=2$,  $n$} 
	\Output{$PHD_{P, Q}$}
	\BlankLine 
        
        $d_{ph}=[\ ]$\;
        
	   \lIf{$\hat{p}$>0.5}
	        {$\hat{p}$ $=$ 1}
	   \lElse{$\hat{p}=$ 0}
          Get edge images $\hat{p}_{e}$ of $\hat{p}$ with $d_e=1$\;
          Get pixel index $(x,y)$ of $\hat{p}_{e}$=1\; 
        %   $(x,y) \in P\cup Q$ \;
          $(x_{p},y_{p})=$ $(x,y) - $mean($(x,y)$)\;
          $\rho = \sqrt{x_{p}^2+y_{p}^2}$\;
          $(cos(\alpha),sin(\alpha)) = (\frac{x_{p}}{\rho}, \frac{y_{p}}{\rho})$\;

	   \For{$j$ in arrange($n$)}
            { 
            $d_P=[\ ]$, $d_Q=[\ ]$, $d_{P\cup Q}=[\ ]$\;
	 	 \For{$(x_{i},y_{i})$ in $(x_{p},y_{p})$}
                {
                    \lIf{|$\alpha_i-j\pi/180|<\sigma$}
                    { Append $\rho_{i}$ to $d_{P\cup Q}$}
 		 	}
                $d_{min} = $Min($d_{P\cup Q}$)\;
                \For{$d_i$ in $d_{P\cup Q}$}
                {
                    \lIf{$d_i-d_{min}<\delta$}
                    { Append $d_{i}$ to $d_{P}$}
                    \lElse{Append $d_{i}$ to $d_{Q}$}
 		 	}
                Append Min($d_{Q}$) - Max($d_{P}$) to $d_{ph}$\;
 	 	}
            $PHD(P, Q) = $Max($d_{ph}$)\;
 	 	  \caption{Calculate $PHD_{P,Q}(\hat{p},n)$}
 	 	  \label{method:calculate_polar_hausdorff_distance} 
    \end{algorithm}
 \DecMargin{1em} 
 
\subsection{Performance Comparison}
\begin{table}\footnotesize
    \centering
    \setlength{\tabcolsep}{4pt}
    \caption{Comparing the results of baseline with EPS across different segmentation models.}
    \begin{tabular}{cccccc}
    \toprule  %添加表格头部粗线
    %——————————————————————————————
    \multirow{2}{*}{Model} &Size& \multicolumn{2}{c}{Baseline}  & \multicolumn{2}{c}{EPS} \\
    &Params& mIoU & mAcc  & mIoU & mAcc \\
    %——————————————————————————————
    \midrule  %添加表格中横线
    CGNet\cite{wu2020cgnet} & 496.32k & 66.84 & 80.12 & 68.68$\uparrow$ & 81.94$\uparrow$\\
    ERFNet\cite{romera2017erfnet} & 2.08M &66.08& 74.65 &70.08$\uparrow$ & 78.9$\uparrow$\\
    MobileNetV3\cite{Howard_2019_ICCV} & 3.28M & 58.12 & 67.76 & 65.82$\uparrow$ & 76.71$\uparrow$\\
    SegFormer\cite{xie2021segformer} & 3.72M & 76.28 & 83.89 & 76.88$\uparrow$ & 84.77$\uparrow$\\
    HRNet\cite{SunXLW19} & 9.64M &68.98& 77.8 & 70.09$\uparrow$ & 78.99$\uparrow$\\
    OCRNet\cite{YuanCW20} & 12.08M & 58.64 & 76.84 & 64.73$\uparrow$ & 82.54$\uparrow$\\
    ICNet\cite{zhao2018icnet} & 14.8M & 68.44 & 77.45 & 68.46$\uparrow$ & 78.27$\uparrow$\\
    STDC\cite{fan2021rethinking} & 25.17M & 53.30 & 62.55 & 58.62$\uparrow$ & 68.98$\uparrow$\\
    BiSeNetV2\cite{yu2021bisenet} & 28.5M & 64.22 & 71.19 & 65.35$\uparrow$ & 74.03$\uparrow$\\
    UNet\cite{ronneberger2015u} & 29.06 & 56.27 & 64.04 & 56.43 $\uparrow$ & 62.95\\
    PointRend\cite{kirillov2020pointrend} & 30.34M & 61.04 & 70.28 & 63.26$\uparrow$ & 71.94$\uparrow$\\
    EncNet\cite{Zhang_2018_CVPR} & 35.89M & 68.95 & 77.74 & 72.59 $\uparrow$ & 80.28 $\uparrow$\\
    EMANet\cite{li2019expectation} & 42.09M & 64.10 & 71.53 & 65.20 $\uparrow$ & 75.37 $\uparrow$\\
    ANN\cite{zhu2019asymmetric} & 46.23M & 51.26 & 63.21 & 57.17 $\uparrow$ & 66.32 $\uparrow$\\
    PSPNet\cite{zhao2017pspnet} & 48.98M & 70.32 & 78.13 & 68.51 & 76.09\\
    CCNet\cite{huang2018ccnet} & 49.83M & 60.01 & 66.88 & 60.89 $\uparrow$ & 72.78 $\uparrow$\\
    DANet\cite{fu2018dual} & 49.85M & 74.12 & 83.53 & 75.23 $\uparrow$ & 84.62 $\uparrow$\\
    NonLocal Net\cite{wang2018non} & 50.02M & 66.54 & 72.93 & 69.20 $\uparrow$ & 76.21 $\uparrow$\\
    APCNet\cite{He_2019_CVPR} & 56.36M & 45.38 & 58.45 & 51.2 $\uparrow$ & 64.72 $\uparrow$\\
    DMNet\cite{He_2019_ICCV} & 53.18M & 67.65 & 75.94 & 66.96 & 74.4 \\
    DeepLabV3\cite{chen2017rethinking} & 68.11M & 62.95 & 75.78 & 70.09 $\uparrow$ & 81.75  $\uparrow$\\
    FastFCN\cite{wu2019fastfcn} & 68.71M & 72.88 & 81.26 & 71.58 & 81.41 $\uparrow$\\
    % GCNet\cite{cao2019gcnet} & 49.63M & 68.28 & 75.58 & 67.18 & 74.85\\
    % ISANet\cite{huang2019isa} & 37.71M & 61.96 & 79.28 & 61.07 & 78.97\\
    \bottomrule %添加表格底部粗线
    \end{tabular}
    \label{table:compare_EPS}
\end{table}

\begin{table}\footnotesize
    \centering
    \setlength{\tabcolsep}{2pt}
    \caption{Comparing the results of baseline with EPS $+$ PH Loss across different segmentation models.}
    \begin{tabular}{ccccccc}
    \toprule  %添加表格头部粗线
    %——————————————————————————————
    \multirow{2}{*}{Model} & \multicolumn{2}{c}{Baseline}  & \multicolumn{2}{c}{EPS} & \multicolumn{2}{c}{EPS+PH}\\
    & mIoU & mAcc  & mIoU & mAcc & mIoU & mAcc \\
    %——————————————————————————————
    \midrule  %添加表格中横线
    CGNet\cite{wu2020cgnet} & 66.84 & 80.12 & 68.68$\uparrow$ & 81.94$\uparrow$ & 70.16$\upuparrows$ & 82.26$\upuparrows$\\
    ERFNet\cite{romera2017erfnet} &66.08& 74.65 &70.08$\uparrow$ & 78.9$\uparrow$ & 71.87$\upuparrows$ & 80.84$\upuparrows$\\
    SegFormer\cite{xie2021segformer} & 76.28 & 83.89 & 76.88$\uparrow$ & 84.77$\uparrow$ & 77.03$\upuparrows$ & 85.03$\upuparrows$\\
    STDC\cite{fan2021rethinking} & 53.30 & 62.55 & 58.62$\uparrow$ & 68.98$\uparrow$ & 77.62$\upuparrows$ & 85.11$\upuparrows$\\
    
    \bottomrule %添加表格底部粗线
    \end{tabular}
    \label{table:compare_EPS_PH}
\end{table}


% 为了验证EPS可以适用于各种语义分割模型，我们在实验中使用kernel=$5\times5$生成Edge GT来进行训练。
To verify the versatility of EPS across different semantic segmentation models, we conducted experiments where our models were trained using Edge GT generated by a $5\times5$ kernel. 
% 我们几乎测试了MMSegmentation内所有的语义分割模型，里面包含Only decoder head的 CGNet, ERFNet, HRNet, MobileNetV3等，以及with auxiliary head的ANN, APCNet, BiSeNetV2, CCNet等。
We assessed nearly all semantic segmentation models within MMSegmentation, including both those with and without auxiliary heads, such as CGNet, MobileNetV3, ANN, BiSeNetV2, and others. 
% 具体使用的模型和实验结果见表\ref{table:compare_EPS}所示。
The specific models utilized and corresponding experimental outcomes are presented in Table \ref{table:compare_EPS}. 
% 我们发现几乎所有的SOTA模型在使用了EPS策略后，无论是mIoU还是mAcc都有一定程度的提升。
We observed a noticeable improvement in both mIoU and mAcc for almost all state-of-the-art models after implementing the EPS strategy. 
% 这表明EPS适用于各种语义分割模型，并且其plug-and-play的属性使其可以直接使用，无需考虑模型自身的特点。
This signifies the compatibility of EPS with various semantic segmentation models and its plug-and-play nature, which enables its direct use without any consideration of the model's unique attributes.

% 我们选取了四个模型（CGNet、ERFNet、SegFormer和STDC）进一步探索在EPS中使用PH Loss之后的实验结果见表\ref{table:compare_EPS_PH}。
We selected four models, namely CGNet, ERFNet, SegFormer, and STDC, to further explore the experimental results of using PH Loss in EPS.The results are presented in Table \ref{table:compare_EPS_PH}. 
% 可以发现，虽然对SOTA的Baseline使用了EPS已经提升许多了，但是在加上PH Loss之后模型的性能还能进一步提升。
Based on our analysis, it can be inferred that the utilization of EPS has resulted in substantial enhancements in the performance of the SOTA. Furthermore, the incorporation of PH Loss has demonstrated a superior improvement in the model's accuracy.

\subsection{Ablation Studies}
% 我们提出的PH Loss是与EPS框架配合使用的，其中有两个超参数，分别是Edge GT的边缘厚度$d_e$和PHD中候选距离$d_{ph}$的个数$n$。
Our proposed PH Loss is designed to be used in conjunction with the EPS framework, with two hyperparameters: the edge thickness $d_e$ of the Edge GT and the number $n$ of candidate distances $d_{ph}$ in the $PHD_{P,Q}(\hat{p},n)$.
% 为了探究两个超参数选取的影响，我们继续选取CGNet、ERFNet、SegFormer和STDC进行了一系列的消融实验。
In order to investigate the effects of these two hyperparameters, we conducted a series of ablation experiments on CGNet, ERFNet, SegFormer, and STDC.

% 通过分析表\ref{table:ablation_de_EPS}，我们发现超参数kernel的选取并没有明显的规律，不同的模型最佳的kernel都不相同。
After conducting an analysis of Table \ref{table:ablation_de_EPS}, we observe that there is no evident regularity for selecting the hyperparameter kernel, and the optimal kernel varies among different models.
% 但是当kernel选取$5\times5$和$7\times7$时，效果都不会太差。
However, the performance is relatively favorable when selecting the kernel as $5\times5$ and $7\times7$.
% 并且无论使用多大的kernel，只要使用了EPS，最终的mIoU都有所提升。
Additionally, employing EPS led to an improvement in mIoU, irrespective of the kernel size.
% 分析表\ref{table:ablation_de_EPS_PH}，我们发现即使使用了PH Loss，不同的模型最佳的kernel也是不相同的。
Analysis of Table \ref{table:ablation_de_EPS_PH} revealed that even with PH Loss, the optimal kernel varied across different models. 
% 再对比表\ref{table:ablation_de_EPS}中相同kernel相同模型下的结果，我们发现几乎使用了PH Loss的实验都比未使用的效果好。
Comparing the results of the same kernel and model in Table \ref{table:ablation_de_EPS}, it was observed that almost all experiments using PH Loss performed better than those without PH Loss. 
% 对于部分使用了PH Loss的EPS的结果不如直接使用CE Loss的EPS的情况，我们认为可能是由于训练的iteration不够大导致的。
In instances where the results of EPS with PH Loss were inferior to those of EPS with CE Loss, the cause may be attributed to insufficient training iterations.
% 最后，分析表\ref{table:ablation_n_EPS_PH}，我们发现超参数$n$的选取对结果的影响并不大，但是$n$越大，模型的计算量越大。
Finally, by analyzing Table \ref{table:ablation_n_EPS_PH}, we found that the impact of selecting hyperparameter $n$ on the results is not significant, but as $n$ increases, the computational complexity of the model also increases.
% 因此我们推荐选取较小的$n$，例如$n=8$
Consequently, it is recommended to select a smaller value for $n$, such as $n=8$.


\begin{table}\footnotesize
    \centering
    \setlength{\tabcolsep}{1.5pt}
    \caption{Comparing the impact of hyperparameter $d_e$ on EPS.}
    \begin{tabular}{cccccccc}
    \toprule  %添加表格头部粗线
    %——————————————————————————————
    \multirow{2}{*}{Method}& \multirow{2}{*}{$d_e$}& \multirow{2}{*}{kernel}& \multicolumn{4}{c}{mIoU} \\

    & & & CGNet & ERFNet &SegFormer &STDC\\
    %——————————————————————————————
    \midrule  %添加表格中横线
    Baseline & - & - & 66.84 & 66.08 & 76.28 & 76.37 \\
    \midrule  %添加表格中横线
    \multirow{4}{*}{EPS} & 1 & 3$\times$3 & \textbf{69.18} & 66.45 & 75.38 & 76.75 \\
     & 2 & 5$\times$5 & 68.68 & \textbf{70.08} & \textbf{76.88} & 76.92  \\
     & 3 & 7$\times$7 & 68.98 & 65.51 & 75.93 & \textbf{77.48} \\
     & 5 & 11$\times$11 & 67.55 & 67.56  & 76.12  & 76.77  \\
    
    \bottomrule %添加表格底部粗线
    \end{tabular}
    \label{table:ablation_de_EPS}
\end{table}

\begin{table}\footnotesize
    \centering
    \setlength{\tabcolsep}{1.5pt}
    \caption{Comparing the impact of hyperparameter $d_e$ on EPS with PH Loss ($n$=100).}
    \begin{tabular}{cccccccc}
    \toprule  %添加表格头部粗线
    %——————————————————————————————
    \multirow{2}{*}{Method}& \multirow{2}{*}{$d_e$}& \multirow{2}{*}{kernel}& \multicolumn{4}{c}{mIoU} \\

    & & & CGNet & ERFNet &SegFormer &STDC\\
    %——————————————————————————————
    \midrule  %添加表格中横线
    Baseline & - & - & 66.84 & 66.08 & 76.28 & 76.37 \\
    \midrule  %添加表格中横线
     & 1 & 3x3 & 67.74 & 70.10 & 76.58 & \textbf{77.29}  \\
    EPS & 2 & 5x5 & 68.27 & 70.71 & \textbf{77.03} & 76.81 \\
    +PH Loss & 3 & 7x7 & \textbf{70.16} & 70.43 & 76.98 & 76.77 \\
    & 5 & 11x11 & 69.05 & \textbf{71.87} & 76.90  & 76.85 \\
    \bottomrule %添加表格底部粗线
    \end{tabular}
    \label{table:ablation_de_EPS_PH}
\end{table}

\begin{table}\footnotesize
    \centering
    \setlength{\tabcolsep}{1.5pt}
    \caption{Comparing the impact of hyperparameter $n$ on EPS with PH Loss ($d_e=5$).}
    \begin{tabular}{ccccccc}
    \toprule  %添加表格头部粗线
    %——————————————————————————————
    \multirow{2}{*}{Method}& \multirow{2}{*}{$n$}& \multicolumn{4}{c}{mIoU} \\
    % \cline{3-6}
    & & CGNet & ERFNet &SegFormer &STDC\\
    %——————————————————————————————
    \midrule  %添加表格中横线
    \multirow{2}{*}{EPS}& 100  & 69.05 & 71.87 & 76.90  & 76.85 \\
    \multirow{2}{*}{+PH Loss}& 32 & 67.18 & 71.35 & 76.90 & 77.25 \\
    & 8 & 69.07 & 71.69 & 76.87 & 77.62\\
    \bottomrule %添加表格底部粗线
    \end{tabular}
    \label{table:ablation_n_EPS_PH}
\end{table}

%-------------------------------------------------------------------------
\section{Conclusion}
% 我们在研究语义分割任务中的边缘监督方法时发现了一个问题，即这些方法无法快速简单地拓展到其他语义分割模型。
Our study investigated the limitations of edge supervision methods for semantic segmentation tasks, specifically the difficulty in adapting these methods to different models.
% 为了解决这个问题，我们提出了一种边缘监督策略EPS，并结合EPS提取Edeg GT时加入边缘厚度$d_e$这一先验知识，提出了一种新的基于边界的损失PH Loss。
%To address this challenge, we propose a novel edge supervision scheme, termed as EPS. By integrating the prior knowledge of edge thickness, we develop a boundary-based loss function, known as the PH Loss, which shows promising results in addressing the aforementioned challenge.
To address this challenge, we propose a novel edge supervision scheme, EPS, which duplicates the architecture decoder head for the auxiliary task with the edge supervision. By integrating the prior knowledge of edge thickness, we develop a boundary-based loss function for the thickness preserving task, which shows promising results in addressing the aforementioned challenge.
% EPS的最大优势是可以快速地插入任何语义分割模型，这种从策略角度出发去设计所有模型通用的方法的想法是创新的。
The key advantage of our EPS is its ability to seamlessly and easily integrate into any semantic segmentation model, reflecting an innovative approach to developing universally applicable strategies. 
% 我们在Cityscapes数据集上进行了22个模型的实验，证明了EPS可以在SOTA模型上进一步提升。
Our experiments, conducted on 22 models using the Cityscapes dataset, demonstrate that EPS can improve upon the state-of-the-art models. 
% 然而，我们对EPS的研究还存在至少二个局限：第一，缺乏PH Loss的稳定性和鲁棒性分析及相关实验；第二，仅在一个数据集上进行实验是不够充分的。
However, we acknowledge that there are still limitations to our study of EPS, including the lack of stability and robustness analysis of PH Loss and the need for more comprehensive experiments across multiple datasets. 
% 在未来的工作中，可以探讨类似EPS的其他Plug-and-play Scheme，例如加入纹理监督等；
In future research, we plan to explore additional Plug-and-play schemes in depth, such as incorporating texture supervision,
% 在技术上可以优化PH Loss的计算以及进一步探索PH Loss的作用机理；
optimizing the calculation of PH Loss, investigating the mechanism of PH Loss;  
% 可以将EPS拓展到实例分割，目标检测任务中；也可以在医学图像领域、自动驾驶或者工业缺陷检测领域中应用EPS。
to extend EPS to other tasks, eg. instance segmentation and object detection; and to apply EPS in various fields, including medical imaging, autonomous driving, and industrial defect detection.

%-------------------------------------------------------------------------


{\scriptsize
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}
\end{document}
