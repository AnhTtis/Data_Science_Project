\documentclass[12pt]{article}
\usepackage{amsthm,amsmath,amssymb,bbm}
\usepackage{natbib}
\usepackage{multirow}
\usepackage[pdftex]{graphicx}
\usepackage{subfigure}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{array}
\usepackage{url}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{bm}
\usepackage{wrapfig}
\usepackage{lipsum}
\usepackage{mathrsfs}
\usepackage{dsfont}
\usepackage{titling}
\usepackage{color}
\usepackage{multirow}
\usepackage[flushleft]{threeparttable}
\usepackage{changepage}
\usepackage{tabularx,ragged2e,booktabs,caption}
\usepackage{comment}
\usepackage[margin=1in]{geometry}
\renewcommand{\baselinestretch}{1.35}
\usepackage[colorlinks=true,allcolors=blue]{hyperref}%



\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\bcA}{\bm{\mathcal{A}}}
\newcommand{\bcB}{\bm{\mathcal{B}}}

\newcommand{\balpha}{{\bm\alpha}}
\newcommand{\bbeta}{{\bm\beta}}
\newcommand{\blambda}{{\bm\lambda}}
\newcommand{\bfeta}{{\bm\eta}}
\newcommand{\bmu}{{\bm\mu}}
\newcommand{\btheta}{{\bm\theta}}
\newcommand{\bDelta}{{\bm\Delta}}
\newcommand{\bPhi}{{\bm\Phi}}
\newcommand{\bPsi}{{\bm\Psi}}
\newcommand{\bGamma}{{\bm\Gamma}}
\newcommand{\bOmega}{{\bm\Omega}}
\newcommand{\bLambda}{{\bm\Lambda}}
\newcommand{\bSigma}{{\bm\Sigma}}
\newcommand{\bTheta}{{\bm\Theta}}
\newcommand{\dd}{\mathrm{d}}

\def\a{{\bm a}}
\def\b{{\bm b}}
\def\c{{\bm c}}
\def\d{{\bm d}}
\def\e{{\bm e}}
\def\g{{\bm g}}
\def\m{{\bm m}}
\def\u{{\bm u}}
\def\v{{\bm v}}
\def\w{{\bm w}}
\def\x{{\bm x}}
\def\z{{\bm z}}


\def\A{{\bm A}}
\def\B{{\bm B}}
\def\C{{\bm C}}
\def\D{{\bm D}}
\def\E{{\bm E}}
\def\G{{\bm G}}
\def\N{{\bm N}}
\def\H{{\bm H}}
\def\I{{\bm I}}
\def\M{{\bm M}}
\newcommand{\bP}{\mathbf{P}}
\def\Q{{\bm Q}}
\def\T{{\bm T}}
\def\X{{\bm X}}
\def\U{{\bm U}}
\def\V{{\bm V}}
\def\W{{\bm W}}
\def\X{{\bm X}}
\def\Y{{\bm Y}}
\def\Z {{\bm Z}}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}


\begin{document}

\title{Learning Brain Connectivity in Social Cognition with Dynamic Network Regression}


\author{
Maoyu Zhang$^1$, Biao Cai$^2$, Wenlin Dai$^1$, Dehan Kong$^3$, \\
Hongyu Zhao$^2$ and Jingfei Zhang$^4$ \medskip \\
$^1$ {\normalsize Institute of Statistics and Big Data, Renmin University of China}\\ 
$^2$ {\normalsize Biostatistics Department,Yale University}\\ 
$^3$ {\normalsize Department of Statistical Sciences, University of Toronto }\\
$^4$ {\normalsize Goizueta Business School, Emory University}\\
}
\date{}
\maketitle
\blfootnote{$^*$The first two authors contributed equally to this work.}


\vspace{-0.5in}
\renewcommand{\baselinestretch}{1.15}
\begin{abstract}
Dynamic networks have been increasingly used to characterize brain connectivity that varies during resting and task states. In such characterizations, a connectivity network is typically measured at each time point for a subject over a common set of nodes representing brain regions, together with rich subject-level information. A common approach to analyzing such data is an edge-based method that models the connectivity between each pair of nodes separately. However, such approach may have limited performance when the noise level is high and the number of subjects is limited, as it does not take advantage of the inherent network structure. To better understand if and how the subject-level covariates affect the dynamic brain connectivity, we introduce a semi-parametric dynamic network response regression that relates a dynamic brain connectivity network to a vector of subject-level covariates. A key advantage of our method is to exploit the structure of dynamic imaging coefficients in the form of high-order tensors. We develop an efficient estimation algorithm and evaluate the efficacy of our approach through simulation studies. Finally, we present our results on the analysis of a task-related study on social cognition in the Human Connectome Project, where we identify known sex-specific effects on brain connectivity that cannot be inferred using alternative methods. 
\end{abstract}


\newpage
\baselineskip=21.5pt
\section{Introduction}\label{intro}
%\subsection{Background}
%Social cognition, specifically the ability to reason about mental states, known as Theory of Mind (ToM), is intimately related to the development of human, everyday use, and potentially even evolution. ToM is a composite function that includes memory, joint attention, sophisticated perceptual recognition, language, executive functions, emotion processing-recognition, empathy, and imitation. Consequently, ToM is a prime example of the complex interaction between the social environment and brain development \citep{korkmaz2011theory}.

Social cognition, which refers to how individuals process, memorize, and use information in social contexts to explain and predict their own behavior and that of others \citep{fiske1991social}, is a crucial aspect of human functioning and has been extensively studied in the field of psychology and neuroscience \citep{lieberman2007social,saxe2013people}. The use of neuroimaging techniques, particularly functional magnetic resonance imaging (fMRI), has enabled a better understanding of the neural mechanisms underlying social cognition \citep{saxe2013people}. Previous studies using fMRI have shown that specific brain regions, such as the medial prefrontal cortex, the temporoparietal junction, and the superior temporal sulcus, are consistently activated during tasks related to social cognition \citep{castelli2000movement,gallagher2003functional}. 
While significant progress has been made in uncovering the neural mechanisms underlying social cognition, our understandings of the coordination between brain regions during social cognition and how it relates to individual differences in social behavior remain limited \citep{adolphs2009social}.

The social cognition study in the Human Connectome Project (HCP) \footnote{\url{https://www.humanconnectome.org/}} provided a unique opportunity for advancing our understandings of the brain connectivity underlying social cognition. In this study, imaging scans are collected using fMRI from a set of subjects as each subject goes through a sequence of cognitive tasks and rest states. In addition, it also collects subject features such as sex and social covariates (e.g., social distress). See more details in Section \ref{sec:hcp}. Based on the imaging scans, a dynamic connectivity network, characterizing activation and deactivation of connections between brain regions during task and rest states, can be constructed for each subject, with nodes corresponding to a common set of brain regions, and the edges encoding dynamic functional associations between the regions. 
From this study, it is of fundamental scientific interest to understand which brain regions are co-activated during the cognitive tasks. In addition, it is important to understand whether there are sex differences in brain connectivity during cognitive tasks, and if so, how social covariates influence these differences.

There is some recent literature on modeling a collection of networks, including dynamic networks. However, these methods may not flexibly associate dynamic network connectivity with external covariates while taking into account the structure of the network and smoothness in the dynamic brain connectivity.
%Although the literature on the statistical inference of dynamic networks is still relatively new, much effort has been made to advance the research on this topic \citep{xu2014dynamic,pensky2016dynamic,matias2017statistical,ZhangCao2017}. 
%The majority of current methods are developed under a discrete-time stochastic block model framework, which may limit their adaptability when used with dynamic networks . 
Specifically, \cite{xu2014dynamic,pensky2016dynamic,ZhangCao2017,zhang2020mixed} proposed several approaches based on stochastic block models. These methods cannot associate network connectivity with external covariates. 
\cite{wang2017bayesian} proposed a Bayesian network model with covariates, which is flexible but can be computationally intensive, especially for large networks or a large number of covariates. \cite{kong2020l2rm,hu2021nonparametric,zhang2022generalized} studied matrix or network response regressions but they focused on non time-varying networks.
%\my{non time-varying [Dr. Zhao said he is not familiar with this phrase, and I think it is fine.]}
\cite{zhang2017tensor,hao2021sparse,zhou2021partially,tang2020individualized} considered tensor regressions that can be formulated to tackle our problem by stacking the dynamic networks observed at different time points into a tensor, but these approaches could not account for the temporal smoothness in the dynamic brain connectivity. 

%Matrix and tensor data analysis has another line of related works. Notable examples include the matrix response linear regression model \citep{kong2020l2rm}, the non-parametric matrix response regression model \citep{hu2021nonparametric}, and the generalized matrix response regression model \citep{zhang2022generalized}. These models were designed to handle matrix responses, with various structures imposed on the coefficients. In a similar vein, tensor predictor models were investigated, where the tensor was considered as a predictor and the response variable was a scalar \citep{zhang2017tensor,tang2020individualized}.


%Network based analysis is a useful tool for examining the structural and functional connectivity of the brain and has proven to be effective in numerous neuroscience studies \citep{bullmore2009complex,bullmore2011brain,zhang2020mixed,zhang2022generalized}. 

%Brain networks represent the connectivity between different ROIs, and are related to the functional and structural architecture of the brain \citep{varoquaux2013learning}. Among the many connectivity measures available in the existing literature \citep{smith2013functional}, popular options are the covariance, pearson correlation \citep{zhang2022generalized} and partial correlation \citep{ZhangCao2017} between locations, %calculated by averaging the time dimension, 
%and the choice of the measure depends on the ultimate goal of the analysis. 
%In the HCP tfMRI, the brain connectivity of a subject went through many task-related changes in the scanning session. As such, the functional brain connectivity is commonly encoded by a dynamic network \citep{bassett2011dynamic}.
%especially the multiple-subject dynamic network data. Specifically, a dynamic connectivity network is measured over a common set of nodes for each subject, such as the error-related negativity (ERN)  from electroencephalogram (EEG) data, \cite{ozdemir2014multiple} introduced a co-regularized multiview spectral clustering approach to determine the modules underlying the functional brain networks about this data. \cite{wu2021dynamic} investigated the distributed network properties associated with subthalamic nucleus in patients with advanced Parkinson’s Disease (PD) from the rsfMRI dynamic networks. In this paper, we apply the moving window method to estimate the correlation matrices in each window to construct the dynamic brain connectivity network from the tfMRI, yielding a dynamic network for each subject; see more details in Section \ref{sec:4}.



%There is still a lack of a systematic and flexible framework for the statistical inference of dynamic networks with possible covariates, despite the fact that dynamic networks are becoming more and more accessible in many scientific domains, such as neurology and genetic studies. Existing dynamic network models cannot adequately address these questions. First, the majority of existing dynamic network models are variants of stochastic block model with a network community detection as their primary goal \citep{ZhangCao2017,relion2019network}, which is not directly related to our research objective. Moreover, the block structure assumption could be unrealistic in practice. Second, existing models are mostly formulated to analyze a single network and hence are not directly applicable to the multiple-subject dynamic network problem \citep{zhang2022generalized}. Third, existing methods focus on unsupervised learning of network structures, and cannot incorporate any subject covariates \citep{gao2017achieving}. 
%In this article, we investigate a scientifically important question, how  subject characteristics, such as gender and clinical covariates (e.g., social stress), affect the task-evoked brain connectivity. 

To model the dynamic brain connectivity in the social cognition study, we propose a new semi-parametric dynamic network model for a collection of dynamic networks with subject-level covariates. We adopt the form of generalized linear model (GLM) and assume the connectivity between a pair of regions, after a proper transformation, is the sum of two functional components. The first component is the baseline time-varying connectivity shared by all subjects and the second component involves time-varying slopes and models the effects of subject-level covariates on the time-varying brain connectivity. 
To estimate the unknown functional coefficients, we consider a nonparameteric estimation via B-spline approximations. Under such approximations, we can then write our model in the form of a dynamic network regression, where the response is the dynamic connectivity matrix and the predictors are subject covariates. With the B-spline basis, the baseline connectivity can be characterized using an intercept tensor and the covariate effect using a slope tensor. We assume the intercept tensor is low-rank and the slope tensors are structurally sparse. We discuss the benefit of placing different assumptions on these two tensor coefficients in Section \ref{sec:model}. These structural hypotheses significantly reduce the number of free parameters, facilitate model interpretability and estimability, and are commonly considered in scientific applications \citep{bi2018multilayer,zhang2022generalized}.

For estimation, we propose an efficient alternating gradient descent algorithm with a fast iterative shrinkage-thresholding method to estimate the sparse slope tensor. 
In Section \ref{sec:3}, we demonstrate in simulation studies that our method can accurately estimate the model coefficients and identify nonzero covariate effects whereas other methods fail to offer accurate estimates. 
In Section \ref{sec:4}, we apply our proposed method to the social cognition study and identify sex differences both in the baseline connectivity and social covariate effects. The majority of our results agree with the existing findings in the neuroscience literature. 
We also implement an element-wise (i.e., edge-based) method, where the results are highly noisy and lack interpretability, and a method designed for non time-varying networks \citep{zhang2022generalized}, where the results are highly sparse and cannot identify areas that are known to be engaged in social cognition. Finally, we consider a permutation based procedure to evaluate the identified sex-specific differences from our analysis.

Taken together, our work proposes a new dynamic network regression for analyzing task-evoked brain connectivity with subject-level covariates that exploits the structure in the brain network and the temporal smoothness in the time-varying connectivity. We demonstrate in simulations and real data analysis that the proposed method usually performs better than element-wise methods that model the connectivity between each pair of nodes separately. Next, we discuss in detail the motivating scientific problem and the research questions to be addressed. 

%Our proposed method exploits the unique structures of multiple-subject dynamic networks to tackle the intrinsic high-dimensionality of the problem. With the resultant dynamic network as a tensor response and the subject covariates serving as predictors, we build a dynamic network response model. As a result, after a suitable transformation, the population-level connection is represented as the sum of two high-dimensional components. The intercept tensor, the first component, is thought to have a low-rank structure. The slope coefficient tensor, which is expected to be sparse and describes the effects of covariates on connectivity, and the corresponding covariates make up the second part. These structural hypotheses which are commonly considered in the scientific applications \citep{bi2018multilayer}, significantly reduces the amount of free parameters and facilitates interpretability and estimability. 


%Our work significantly advances both methodologies and applications in a number of ways. First, for characterization of subjective human experience, and for understanding the association between brain regions and cognitive outcomes, we first present a methodical and adaptable method to offer a systematic solution to this family of problems, which preserves the network's inherent properties and makes scale computation easier. Specifically, the proposed model adopts the dynamic network regression framework yet accounts for additional covariates (e.g., gender and social scores), which can help develop novel treatments for anxiety, autism, and other disorders. Notably, examining sex variations in brain connectivity through tasks can also shed light on why males and females behave differently. Second, much of existing task-related brain studies focus on individual regions. Our proposed model contributes to the comprehension of the organization of the brain by investigating the entire brain as an interconnected system, which can clearly identify the associations between various brain regions. Furthermore, although our motivating application is brain connectivity research, our methodology may be used to solve a variety of other issues. For instance, genetic research used single-cell samples to examine the links between gene-gene networks for gene regulation \citep{dai2019cell}.


%Growing evidence from developmental research indicates that maturation of functional and structural networks in the human brain underlies key aspects of cognitive and emotional development \citep{stevens2009age,zuo2010growing}. Many related studies have been performed to investigate the effects of some important social cognitive and behavioral variables on the brain structure and functions, or vice versa. For example, \cite{bassett2009cognitive} demonstrated the relationship between brain networks and pathophysiological models of schizophrenia, \cite{alcala2018computing} investigated the effect of social cognition on brain neural activity by studying the social brain, and \cite{schurz2021toward} proposed a hierarchical model to investigate the relation between brain activation, brain organization and behavior and social cognitive processes. Meanwhile, many works also investigated the gender difference in brain connectivity through various ToM-related tasks \citep{walker2005gender,devine2013silent,ingalhalikar2014sex}.

%explore the development of functional and structural brain connectivity by detecting brain activity changes induced by various tasks, such as motor, sensory, cognitive and emotional processes \citep{gray2003neural,song2008brain,hariri2002amygdala}. For example, 

%Researches on the anatomy of the brain have tremendously benefited from neuroimaging technologies, which have been central to advancing our understanding of the development of the brain. Massive neuroimaging data have been collected in typical connectivity studies, such as structural magnetic resonance imaging \citep[sMRI]{frisoni2010clinical} and functional magnetic resonance imaging \citep[fMRI]{good2001cerebral}. In general, fMRI contains two main categories: resting state fMRI \citep[rsfMRI]{zhou2014brain} and task-evoked fMRI \citep[tfMRI]{barch2013function}. Task-evoked fMRI is a scanning session in which subjects are asked to complete tasks designed to activate various cortical and subcortical regions, which helps understand the relationship between brain connectivity and human function. Notably, voxel-based methods \citep{shen2010whole,zhou2014brain} and surface-based methods \citep{burgaleta2014cognitive,bathelt2016structural} are important tools commonly used to analyze cortical or subcortical regions in brain images. 

%While the complex, high-order, high-resolution nature of imaging data makes it difficult to identify relationships between social cognition and brain structures. Using imaging voxels as independent objects to directly quantify intensity differences between case and control groups is the most popular method for analyzing this problem.  These techniques are simple to use and could yield insightful conclusions regarding the brain regions of interest (ROIs). The majority of existing methods summarise neuroimaging data at a high level (e.g., aggregation or averaging), which could  possibly ignore potential associations between various anatomical regions of the brain or at boundaries, since neuroimaging data may contain rich spatial and structural information about the brain. Therefore, it is urgently necessary to develop an efficient statistical method that can make use of the raw yet valuable information found in neuroimaging data.



%In the HPC study, the brain connectivity of a subject went through many task-related changes in the scanning session. As such, the functional brain connectivity is commonly encoded by a dynamic network \citep{bassett2011dynamic},especially the multiple-subject dynamic network data. Specifically, a dynamic connectivity network is measured over a common set of nodes for each subject, for example, the error-related negativity (ERN)  from electroencephalogram (EEG) data \citep{ozdemir2014multiple}, and the Parkinson’s Disease (PD) from the rsfMRI \citep{wu2021dynamic}. 


%Among the many connectivity measures available in the existing literature \citep{smith2013functional}, popular options are the Pearson correlation coefficient \citep{zhang2022generalized} and partial correlations \citep{ZhangCao2017} between locations, calculated by averaging the time dimension, and the choice of the measure depends on the ultimate goal of the analysis.


\begin{comment}
a moving window approach can be used to develop cross thresholded correlation matrices which results in binary edges. It is also possible to take into account more complex estimating techniques discussed in \cite{song2009keller} and \cite{ qiu2016joint}. In this paper, the tfMRI data has been pre-processed as a $68 \times 263$ spatial-temporal matrix for each subject, which corresponds to 68 brain ROIs from the Anatomical Automatic Labeling (AAL) atlas, and the scan (or frame) length is 263 (in 180 seconds); see more details in Section \ref{pre-pro}. %\my{the pre-process part may be moved to the Supplementary materials? or move Section \ref{pre-pro} to this part?}. \zc{We probably do not need the data preprocessing details here. We also do not really need Figure 1. It is not that informative.}
For each subject, the spatial-temporal matrix is summarized in the form of a binary dynamic network of 30 scans, with the nodes corresponding to 68 ROIs, and the edges recording the binary indicator of the thresholded correlations, encoding functional or structural associations between the regions. To be more specific, %in order to guarantee that the data become roughly stationary after de-trending, we first de-trend the original $68 \times 263$ spatial-temporal matrix. Then,
47 time windows of length 30 are created by sliding 5 scans each time. %Afterwards, for each time window, a correlation matrix is calculated and then truncated as a binary matrix with a threshold of 0.5. 
To this end, we obtain a dynamic network with 68 nodes and 47 snapshots for each subject. %, as illustrated in Figure \ref{pre}. 
The data takes the form of a multidimensional array, one mode of which is time, and another mode is subject, thus leading to multiple-subject dynamic network.
%Neuroimaging data studies are now ubiquitous in a wide range of scientific applications, especially the multiple-subject dynamic network data, in which a dynamic connectivity network is measured over a common set of nodes for each individual subject, for example, the error-related negativity (ERN)  from electroencephalogram (EEG) data \citep{ozdemir2014multiple}, the Parkinson’s Disease (PD) from the resting-state functional magnetic resonance imaging (rs-fMRI) \citep{wu2021dynamic}, and our motivating  task-related fMRI data. 

\begin{figure}[h!]
		\centering
		\includegraphics[width=\linewidth]{Presentation.pdf}
	\caption{Illustration of adjacency matrix generation: red blocks are mental video block, green blocks are random video block and others are represented by blue block.} \label{pre}
\end{figure}
\end{comment}



%identify the connections between individual variations in cognitive and affective processing and both functional and structural connectivity.


%Many related studies have been performed to explore the development of functional and structural brain connectivity by detecting brain activity changes induced by various tasks, such as motor, sensory, cognitive and emotional processes \citep{gray2003neural,song2008brain,hariri2002amygdala}. %There is growing evidence that the variation in human structural and functional connectivity is associated with changes in important cognitive and behavioral variables that affect real-world function \citep{bassett2009cognitive,song2008brain,van2009efficiency}, for example, \cite{ingalhalikar2014sex} show that there are important sex differences in this pattern of connectivity. 
%Characterizing brain connectivity at both the population- and subject-levels, and determining how subject characteristics modulate the subject-level connectivity changes are scientific questions of great interest. Notably, the central to the development of personalized treatments for neurological disorders is the characterization of the personalized network of brain connections \citep{sylvester2020individual}.


%Massive neuroimaging data have been collected in typical connectivity studies, such as structural magnetic resonance imaging (sMRI), functional magnetic resonance imaging (fMRI), diffusion tensor imaging (DTI), and diffusion-weighted imaging (DWI), etc. We are particularly interested in fMRI, which is an image acquisition modality used to study the brain in-vivo. fMRI is concerned with the blood-oxygen-level-dependent (BOLD) responses in blood flow associated with brain function \citep{ogawa1990brain} and allows us to indirectly and non-invasively measure brain function in different states, such as in the naturalistic paradigm, at rest and under specific tasks. In general, fMRI contains two main categories: resting state fMRI (rsfMRI) and task-based fMRI (tfMRI). fMRI has been used for brain activity mapping under different tasks, such as visual processing, self-regulation, sustained attention and social cognition, etc \citep{barch2013function}. To study the brain functional connectivity, network based analysis has been a crucial tool  successfully used under a variety of tasks \citep{bullmore2009complex,bullmore2011brain,finn2015functional,zhang2022generalized}, since complex systems such as the human brain are well characterized by networks, especially by dynamic networks \citep{bassett2011dynamic}.

%two scientifically important questions are yet to be addressed for this type of studies. \textit{First}, which brain regions are activated during these cognitive social tasks and how do these regions function together, and whether there are gender differences. \textit{Second}, if and how subject clinical covariates, such as, social stress, affects the task-evoked brain connectivity.  




%The Human Connectome Project (HCP) is a project that outlines typical patterns of structural and functional connectivity in the brain of healthy adults, which usually uses task-related functional magnetic resonance imaging (tfMRI) to help delineate the relationship between individual differences in the neurobiological substrates of mental processing and functional and structural connectivity. Here we focus on the setting motivated by the social cognition task-related HCP data, and two scientifically important questions are yet to be addressed for this type of studies. \textit{First}, which brain regions are activated during these cognitive social tasks and how do these regions function together, and whether there are gender differences. \textit{Second}, if and how subject clinical covariates, such as, social stress, affects the task-evoked brain connectivity.  



%There is another line of related works in matrix and tensor data analysis. Notably, %\cite{sun2017store} developed a tensor response regression model, \cite{kong2020l2rm} proposed a matrix response linear regression model,  \cite{hu2021nonparametric} considered a matrix response regression based on nonlinear kernels, and \cite{zhang2022generalized} proposed a generalized matrix response regression model. These models were designed to handle a matrix response, and imposed different structures on the coefficients. Relatedly, \cite{zhang2017tensor,li2017parsimonious,tang2020individualized,zhang2019tensor} studied tensor predictor models, where the tensor was treated as a predictor and the response variable was a scalar.


%There is growing evidence that the variation in human structural and functional connectivity is associated with changes in important cognitive and behavioral variables that affect real-world function \citep{bassett2009cognitive,song2008brain,van2009efficiency}. For example, findings from \cite{ingalhalikar2014sex} suggest that there are significant sex differences in this pattern of connectivity. Therefore, in this paper, we focus on the setting motivated by the social cognition tfMRI data, and propose a dynamic network model to address an scientifically important question: how subject characteristics, such as gender and clinical covariates (e.g., social stress) affect the task-evoked brain connectivity. 

%Our suggested approach investigates the entire brain as an integrated system and thus aids the understanding of the organization of the brain. In addition, studying the effects of covariates can help develop novel treatments for anxiety, autism and other disorders. And studying sex differences in brain connectivity through tasks can help explain the sex differences in behaviors.

%The Human Connectome Project (HCP) is a project that outlines typical patterns of structural and functional connectivity in the brain of healthy adults, which usually uses tfMRI to help identify the connections between individual variations in cognitive and mental processing and both functional and structural connectivity. The research data are motivated by an engaging and validated video task HCP, which is chosen as a measure of social cognition, and has been proved that it generates robust task related activation in brain regions associated with social cognition and is reliable across subjects \citep{castelli2000movement,castelli2002autism,wheatley2007understanding,white2011developing}. which includes behavioral and 3T MR imaging data from 970 healthy adult participants collected from 2012 to spring 2015. We focus on the 843 subjects out of the 970 which have the social cognition task related fMRI data. %In each session, a participant was presented with several short videos of objects interacting \citep{castelli2000movement} and the fMRI data are collected over 274 evenly spaced scans.  After each video clip, participants judge whether the objects had a mental interaction (an interaction that appears as if the shapes are taking into account each others feelings and thoughts), not sure, or no interaction (i.e., there is no obvious interaction between the shapes and the movement appears randomly). 

\subsection{The HCP social cognition study and research questions}\label{sec:hcp}

The social cognition study in the HCP data collected behavioral and task-related fMRI data from 850 healthy adult subjects. In each session, a participate was presented with several short videos of objects (squares, circles, triangles) interacting \citep{castelli2000movement} and the fMRI data were collected on 274 evenly spaced time points. These videos were developed by either Castelli and colleagues \citep{castelli2000movement} or Martin and colleagues \citep{wheatley2007understanding}. Specifically, two types of video clips were shown to the subjects including mental (objects interact in some way) and random (objects move randomly). Figure \ref{fig1} shows an example of the mental video block. For each participant, there were 5 video blocks (3 mental and 2 random), with each video task and rest duration taking up 23 seconds and 15 seconds, respectively. We focus our analysis on the $N=843$ subjects who were shown videos in the sequence of mental, mental, random, mental and random. Additionally, social related traits such as social distress, social support and companionship were measured for each subject via self-reported questionnaires. See more details in Section \ref{sec:4}.

\begin{figure}[!t]
\centering
\includegraphics[trim=0 1cm 0 0, scale=0.75]{vid.pdf}
\caption{The still illustration of a mental video. The captions, taken from \citet{castelli2000movement}, have been added for clarification and are not part of the video and are not suggested to the viewer.}\label{fig1}
\end{figure}

In our analysis, the fMRI data are preprocessed and summarized as a $68\times 274$ spatial-temporal matrix for each subject using the Desikan-Killiany Atlas \citep{desikan2006automated} with $n = 68$ regions of interest (ROIs; see Table \ref{68region}). As each subject goes through various tasks and rest states during the scanning session and activation/deactivation of brain regions measured via fMRI are typically lagged \citep{scholvinck2010neural}, it is more appropriate to study the brain connectivity as a dynamic network. Specifically, for each subject, the dynamic network is constructed by calculating a sequence of connectivity matrices over $T$ sliding windows, each summarizing the connectivity between 68 brain regions in a given window. While there are many choices of connectivity measures \citep{smith2013functional}, the most commonly used one is perhaps the marginal Pearson correlation coefficient. We follow the vast majority of the neuroscience literature and measure connectivity in each individual by calculating Pearson correlations using samples from a pair of regions. The correlation matrix is then converted into a binary network to represent networks amongst ROIs. See more details in Section \ref{sec:4}. In our analysis, we have also considered partial correlation matrices \citep{meinshausen2006high}, and found that our main results and qualitative findings remain similar. 


%To construct the dynamic brain connectivity network, a moving window approach can be used to obtain cross covariance matrices (which result in continuous edges) or thresholded precision matrices (which result in binary edges). More sophisticated estimation methods such as \cite{song2009keller, qiu2016joint} can also be considered. 

A number of scientifically important questions are to be addressed for this study. 
\textit{First}, which brain regions are activated during these cognitive social tasks and how do these regions function together. 
\textit{Second}, if and how subject's social covariates, such as social distress, affect the task-evoked brain connectivity. 
\textit{Third}, whether sex differences in brain connectivity during cognitive tasks exist, and if so, how do social covariates influence these differences.

We organize our paper as follows. Section \ref{sec:2} introduces the dynamic network response model and the estimation algorithm. Section \ref{sec:3} presents the simulations, and Section \ref{sec:4} analyzes the task-related study on social cognition and discusses our findings in answering the aforementioned research questions. Section \ref{sec:dis} concludes the paper with a short discussion. 



\section{Model}\label{sec:2}
\subsection{Notation}
Throughout this paper, we employ the following notation. 
Let $\circ$ denote the outer product and $[k]=\{1,2\dots,k\}$.
For a vector $\b\in\mathbb{R}^{d_1}$, let $\|\b\|_2$ denote its Euclidean norm. 
For a matrix $\B\in\mathbb{R}^{d_1\times d_2}$, let $\B_{i\cdot}$ and $\B_{\cdot j}$ denote its $i$-th row and $j$-th column, respectively. %$i\in[d_1]$ and $j\in[d_2]$. 
%Let $\|\B\|_2$ and $\|\B\|_F$ denote its spectral norm and Frobenius norm, respectively. 
%Let $\text{SVD}_r(\B)$ denote the rank-$r$ singular value decomposition of $\B$ such that $\text{SVD}_r(\B)=[\U,\bSigma,\V]$, where $\bSigma\in\mathbb{R}^{r\times r}$ is a diagonal matrix with the largest $r$ singular values of $\B$ on the diagonal, and $\U\in\mathbb{R}^{d_1\times r},\V\in\mathbb{R}^{d_2\times r}$ collect the corresponding left and right singular vectors, respectively. 
For a tensor $\bcB \in \mathbb{R}^{d_1\times d_2\times d_3}$, let $\bcB_{ijk}$ denotes its $(i,j,k)$th entry, $\bcB_{ij\cdot}$ denote the $(i,j)$th tube fiber, and $\bcB_{\cdot\cdot k}$ denote the $k$th frontal slice. %, $i\in[d_1]$, $j\in[d_2]$ and $k\in[d_3]$. 
%Let $\|\bcB\|_F$ denote the tensor Frobenius norm, which is defined as $\|\bcB\|_F=\sqrt{\sum_{ijk}\bcB^2_{ijk}}$, and $\|\bcB\|_0$ denote the number of nonzero entries in $\bcB$. 
For $\b\in\mathbb{R}^{d_3}$ and $\bcB \in \mathbb{R}^{d_1\times d_2\times d_3}$, we define the tensor vector multiplication as 
\begin{equation}\label{eqn:tvprod}
\bcB\times_{3}\b=\sum_{k=1}^{d_3} \b_k\bcB_{\cdot\cdot k}.
\end{equation}
%and define the tensor matrix inner product as $\langle\B,\bcB\rangle=\sum_{ijk}\bcB_{ijk}\B_{ij}$ for $\B\in\mathbb{R}^{d_1\times d_2}$ and $\bcB \in \mathbb{R}^{d_1\times d_2\times d_3}$. \cb{Where do we use tensor matrix inner product? \my{We really don't use it and we can delete it.}}


\subsection{The Dynamic Network Response Model}\label{sec:model}
Consider dynamic networks denoted by $\mathcal{G}_i(\mathcal{V}, \mathcal{E}_i(t))$, $i\in[N]$, observed from $N$ subjects, where $\mathcal{V} $ represents the common set of $n$ nodes and $ \mathcal{E}_i(t) $ represents the set of edges at time point $t$ for subject $i$. 
For each subject, we also observe a $p$-vector of covariates, denoted by $ \x_i=(x_{i1},\ldots, x_{ip})^T$.  
At each time point $ t $, the network $\mathcal{G}_i(\mathcal{V}, \mathcal{E}_i(t))$ can be uniquely represented by its $ n\times n $ adjacency matrix $ \A^{(i)}(t) $, where $ \A^{(i)}_{jj'}(t)$ denotes the edge between nodes $ j $ and $ j' $ at time point $t$ in subject $ i $. 
%, $j,j'\in[n] $ and $i\in[N]$. 
The edges can be %directed or undirected, 
continuous, binary or nonnegative integers.
Without loss of generality, we assume $ t\in [0,1] $, and $\A^{(i)}(t)$ are observed at $T$ %equally spaced 
time points $\{t_1,t_2,\ldots,t_T\}$ such that $ 0= t_1\leq t_2\leq \ldots \leq t_T=1 $. 

Let $\bmu^{(i)}(t)=\mathbb{E}(\A^{(i)}(t)|\x_i)$, where the expectation $\mathbb{E}(\cdot)$ is applied element-wise to entries in $\A^{(i)}(t)$.
We assume that, conditioning on $\x_i$, the entries in $\A^{(i)}(t)$ are independent and follow an exponential distribution with a canonical link function that
\begin{equation}\label{model2}
g(\bmu^{(i)}(t))=\B_0(t)+\sum_{l=1}^p x_{il}\B_l(t),\quad i=1,\ldots,N,
\end{equation}
%$ * $ denotes scalar multiplication and 
where $\B_0(t)\in\mathbb{R}^{n\times n}$ characterizes the population-level time-varying network connectivity and $\B_l(t)\in\mathbb{R}^{n\times n}$ characterizes the time-varying effects of the $l$-th covariate on the network connectivity. 
The function $g(\cdot)$ is an invertible link function, as commonly used in GLMs \citep{mccullagh1989generalized}, and is applied element-wise to entries in $\bmu^{(i)}(t)$.
%The choice of $g(\cdot)$ depends on the data type of $\A^{(i)}(t)$, as commonly adopted in generalized linear models \citep{mccullagh1989generalized}. For example, if the edges are binary, we choose a logit link function, and if the edges are continuous, we choose the identity link.



Let $\B_{ljj'}(t)$ denote the $(j,j')$th element of $\B_l(t)$. 
% for $j,j'\in[n]$ and $l\in\{0\}\cup[p]$. 
To estimate the unknown functions $\B_{ljj'}(t)$'s, we consider a nonparametric estimation using B-spline approximations. 
%We assume that $\B_{ljj'}(t)$'s belong to some smooth function class $\mathcal{H}$ to be specified later \my{$\mathcal{H} \in \mathcal{C}_2,$ where $\mathcal{C}_2$ is the set of differentiable and integrable functions.} \cb{I am not sure if we need a specific definition for this class. If needed, you can check Section 2.1 in \url{https://arxiv.org/pdf/1008.3654.pdf} or Section 2 in \url{https://arxiv.org/pdf/1904.00479.pdf}.\my{Thanks, if we need a specific definition, maybe define it as a Hilbert space?}}
Specifically, we approximate $\B_{ljj'}(t)$'s using a $K$-dimensional basis denoted by $ {\boldsymbol \phi}(t)=(\phi_1(t),\ldots, \phi_K(t))^T $ such that 
$ \B_{ljj'}(t)={\boldsymbol \phi}^T(t)\times\b_{ljj'}+r_{ljj'}(t)$, where $\b_{ljj'}\in\mathbb{R}^K$ and $r_{ljj'}(\cdot)$ is the approximation residual. 
%We allow the dimension $K$ to increase with the number of subjects $N$. 
Defining $ \mathcal{B}_l\in\mathbb{R}^{n\times n\times K}$ such that $\mathcal{B}_{ljj'}= \b_{ljj'}$ for all $j,j'$ and $l$, model (\ref{model2}) can be rewritten as
\begin{equation}\label{approximatemodel}
g(\bmu^{(i)}(t))=\mathcal{B}_0\times_3 {\boldsymbol \phi}(t)+\sum_{l=1}^p x_{il}(\mathcal{B}_l\times_3 {\boldsymbol \phi}(t)), 
\end{equation}
where $\times_3$ is defined as in \eqref{eqn:tvprod}, $\mathcal{B}_0,\ldots,\mathcal{B}_p$ are unknown tensor coefficients of dimension $n\times n\times K$. A graphical illustration of model \eqref{approximatemodel} is given in Figure \ref{Fig:MODEL}. 
%We briefly comment that our model is fundamentally different from the tensor regression model studied in \cite{zhou2013tensor}, which is a static model that considers scalars as responses and high-order tensors as predictors.

\begin{figure}[t!]
\centering
\includegraphics[trim=0 1cm 0 0, width=\linewidth]{FIGURE1_updated1.pdf}
\caption{An illustration of the dynamic network response model.} \label{Fig:MODEL}
\end{figure}


%We next specify our choices for the high-dimensional components $\mathcal{B}_0,\ldots,\mathcal{B}_p$.
One challenge in estimating model \eqref{approximatemodel} is the inherent high-dimensionality of the tensor coefficients. In our analysis of the HCP social cognition study, each coefficient tensor $\mathcal{B}_l$ is of dimension $68\times 68\times 10=46,240$, far exceeding the number of subjects in the study. Thus, it is imperative to employ effective dimension reduction assumptions that can facilitate estimability and interpretability. Next, we move to discuss the dimension reduction assumptions placed on the baseline effect coefficient tensor $\mathcal{B}_0$ and the covariate effect coefficient tensors $\mathcal{B}_1,\ldots,\mathcal{B}_p$. We also discuss the need for considering different assumptions for these two types of effects. 

\smallskip\noindent
\textbf{Low-rankness on $\mathcal{B}_0$.}
The component $\mathcal{B}_0$ is the baseline coefficient tensor and we assume that it possesses a low-rank structure. 
This specification assumes that there is a low-dimensional structure in the baseline time-varying network connectivity, such that both the nodes and the basis coefficients have lower dimensional representations. 
This is similar to, but more general than, for example, the stochastic blockmodel \citep{holland1983stochastic}, a well-studied network model that assumes the nodes form a number of groups and after reorganizing by group membership, the connecting probability matrix is a block matrix. 

In our data problem, the low-rank assumption effectively reduces the number of parameters and increases computational efficiency.
Specifically, we assume that $\mathcal{B}_0$ admits the following rank-$R$ CP decomposition \citep{kolda2009tensor}: 
$$
\mathcal{B}_0=\sum_{r=1}^R w_{r}\u_{1r} \circ \u_{1r} \circ \u_{3r},
$$
where $w_r\in\mathbb{R}^+$, $\u_{1r}\in\mathbb{R}^n$ and $\u_{3r}\in\mathbb{R}^K$. %\cb{$w_r$ should be a positive scalar.}
For identifiability, we assume $\u_{1r}$'s and $\u_{3r}$'s are unit length vectors.  
We note that the above formulation is for undirected networks.
When the networks are directed, we can write $\mathcal{B}_0=\sum_{r=1}^R w_{r}\u_{1r} \circ \u_{2r} \circ \u_{3r}$, where $\u_{2r}\in\mathbb{R}^n$ is a unit length vector.


\smallskip\noindent
\textbf{Structured sparsity in $\mathcal{B}_1,\ldots, \mathcal{B}_p$.} We assume that the subject covariates have sparse effects on the dynamic network connectivity, that is, the effects concentrate on a small number of regions. 
This is scientifically plausible, as brain connections are energy consuming and biological units tend to minimize energy-consuming activities \citep{bullmore2009complex}. Sparsity also greatly reduces the number of free parameters and improves interpretation of the resulting model.
Specifically, we assume that $ \mathcal{B}_l$, $l\in[p]$, is structurally sparse in that it has sparse nonzero tube fibers, corresponding to sparse nonzero time-varying effects $\B_{ljj'}(t)$, $l\in[p]$. 
To encourage structural sparsity, we consider the group lasso \citep{yuan2006model} penalty, defined as
\begin{equation}\label{eqn:gl}
\mathcal{P}(\mathcal{B}_1,\ldots,\mathcal{B}_p ) = \sum_{l=1}^{p}\sum_{j\neq j'}^n\|\mathcal{B}_{ljj'\cdot}\|_2.
\end{equation} 


\smallskip\noindent
\textbf{Different assumptions on $\mathcal{B}_0$ and $\mathcal{B}_1,\ldots, \mathcal{B}_p$.} We briefly discuss the benefits and necessity of imposing separate structures on $\mathcal{B}_0$ and $\mathcal{B}_1,\ldots, \mathcal{B}_p$. 
It is natural to think that one could stack $\mathcal{B}_0, \mathcal{B}_1,\ldots, \mathcal{B}_p$ into one higher-order coefficient tensor of size $n\times n\times K\times (p+1)$, and specify it to be both low-rank and sparse. However, assuming $\mathcal{B}_0$ to be sparse may not be plausible in the GLM setting. 
For instance, when the network edges are binary and $g(\cdot)$ is the logit link, $g(0)$ yields a connecting probability of 0.5; when the network edges are counts and $g(\cdot)$ is the log link, $g(0)$ is not well defined. Correspondingly, a sparse $\mathcal{B}_0$ does not necessarily imply sparsity in the baseline connectivity, and may not even be well defined. This issue is unique in using sparse GLM to model edges in a network. 
Finally, more complex structures on $\mathcal{B}_1,\ldots, \mathcal{B}_p$ can be incorporated (for example, $\mathcal{B}_1,\ldots, \mathcal{B}_p$ are low-rank and sparse), which can further reduce the number of effective parameters. However, such assumptions are expected to incur a much higher computational cost and also involve more tuning parameters on, for example, the rank of each coefficient. To balance model complexity and feasibility, we focus on the current assumption that assumes $\mathcal{B}_1,\ldots, \mathcal{B}_p$ have structured sparsity.



\subsection{Estimation}
Recall that $\mathcal{B}_0=\sum_{r=1}^R w_{r}\u_{1r} \circ \u_{1r} \circ \u_{3r}$. Denote $\w=(w_1,\ldots,w_R)$, $\U_{1}=(\u_{11},\ldots,\u_{1R})\in\mathbb{R}^{n\times R}$, $\U_{3}=(\u_{31},\ldots,\u_{3R})\in\mathbb{R}^{K\times R}$ and $\bGamma=(\mathcal{B}_1,\ldots,\mathcal{B}_p)\in\mathbb{R}^{n\times n\times K\times p}$.
Under model \eqref{approximatemodel}, the negative loglikelihood function, up to a constant, can be written as
\begin{equation}
\label{loglikelihood2}
\ell(\w,\U_1,\U_3,\bGamma)=-\frac{1}{N}\sum^N_{i=1}\sum^n_{j< j'}\sum^T_{h=1}\left[\A^{(i)}_{jj'}(t_h)\bfeta^{(i)}_{jj'}(t_h)-\psi\left\{\bfeta^{(i)}_{jj'}(t_h)\right\}\right],
\end{equation}
where $\bm\eta^{(i)}(t)=\mathcal{B}_0\times_3 {\boldsymbol \phi}(t)+\sum_{l=1}^p x_{il}(\mathcal{B}_l\times_3 {\boldsymbol \phi}(t))$, and $\psi(\cdot)$ is the cumulant function with its first derivative $\psi'(\cdot) = g(\cdot)^{-1}$ \citep{mccullagh1989generalized}.
%For the case $\mathcal{B}_0$ is low rank and $\mathcal{B}_1,\ldots,\mathcal{B}_p$ are sparse, 
We estimate the parameters $\w,\U_1,\U_3,$ and $\bGamma$ by solving the following optimization problem,
\begin{equation}
\label{obj1}
\min_{\w,\,\U_1,\,\U_3,\,\bGamma}\ell(\w,\U_1,\U_3,\bGamma)+\lambda \mathcal{P}(\mathcal{B}_1,\ldots,\mathcal{B}_p ),
\end{equation}
where $\mathcal{P}(\cdot)$ is as defined in \eqref{eqn:gl} and $\lambda$ is a tuning parameter.



The optimization problem in \eqref{obj1} is computationally challenging, as the size of the networks, the dimension of the covariates and the number of basis functions can be large in practice. The GLM loss function further increases the computation burden due to its nonlinearity. While \eqref{obj1} is nonconvex, the conditional optimization with respect to $\u_{1r}$, while fixing all other parameters, is convex, and the same holds for $\w$, $\u_{r3}$'s and $\mathcal{B}_j$'s. This observation permits an alternating minimization algorithm. One potential issue in such an approach is that solving for $\bGamma$, conditional on all other parameters, is a regularized optimization problem of dimension $n\times n\times K\times p$. This can be computationally expensive when the network size $n$, the number of splines $K$ and the dimension of the covariates $p$ are large. To tackle this challenge, we consider a proximal gradient descent algorithm that is easy to implement and computationally efficient. Our estimation procedure is summarized in Algorithm \ref{algo3}. %\cb{One question in Step 2. In the update of $\bm{\omega}$, I think it should be $\w^{(t+1)}=\text{Norm}(\tilde\U_1^{(t+1)})^2\text{Norm}(\tilde\U_3^{(t+1)})$. Could you check again why we need $\w^{(t)}$ and do not square $\text{Norm}(\tilde\U_1^{(t+1)})$ here? Another question is that we update these parameters rank by rank or all of them together.}\my{In my code, it is $\w^{(t+1)}=\w^{(t)}\text{Norm}(\tilde\U_1^{(t+1)})^2\text{Norm}(\tilde\U_3^{(t+1)})$. We update these parameters rank by rank. }
%\cb{For Prof. Zhang, I discussed with Maoyu, the update of $U_m$ and $\omega$ is from rank $1$ to $R$. However, this algorithm looks like it update all rank together. I am wondering if we need to specify this rank by rank update in the algorithm.}\zc{please make the edit to by rank}\my{Sure, I edited it in Algorithm 2 in my understanding of the code, maybe you could re-check it.}.

%\begin{algorithm}[!t]
%\caption{Optimization procedure of \eqref{obj1}}
%\begin{algorithmic}\normalsize{
%\STATE \textbf{Input}: %Sample loss function $\ell(\w,\mathcal{U},\ldots,\mathcal{B}_p)$,
%rank $R$, tuning parameter $\lambda$ and step size $\eta$.
%\STATE\hspace{0.15in} \textit{Step 1}: initialize $\w^{(0)},\U_1^{(0)},\U_3^{(0)},\mathcal{B}^{(0)}_1,\ldots,\mathcal{B}^{(0)}_p$. %\my{ We have not defined $\mathcal{U}$ above, could we write as $\U_1^{(0)}$ and $\U_3^{(0)}$?}\zc{sure, please edit}.
%\STATE\hspace{0.15in} {\bf Repeat} Steps 2-5 for $t=0,1,\ldots$ until convergence.
%\STATE\hspace{0.15in} \textit{Step 2}: $\tilde\U_1^{(t+1)}=\arg\min_\U\ell(\w^{(t)},\U,\U_3^{(t)},\bGamma^{(t)})$,\\
%\hspace{0.6in} $\tilde\U_3^{(t+1)}=\arg\min_\U\ell(\w^{(t)},\U_1^{(t)},\U,\bGamma^{(t)})$,\\
%\U_j^{(t-1)}-(\nabla^2_{\U_j}\ell(\U_j,\w^{(t-1)},\mathcal{B}^{(t-1)}_{1},\ldots,\mathcal{B}^{(t-1)}_p))^{-1}\nabla_{\U_j}\ell(\U_j,\w^{(t-1)},$ \\$\mathcal{B}^{(t-1)}_{1},\ldots,\mathcal{B}^{(t-1)}_p)$, 
%\hspace{0.59in} $\w^{(t+1)}=\w^{(t)}\text{Norm}(\tilde\U_1^{(t+1)})^2\text{Norm}(\tilde\U_3^{(t+1)})$, $\U^{(t+1)}_j=\text{Unit}(\tilde\U_j^{(t+1)})$,\,\,$j=1,3$,\\
%\STATE\hspace{0.15in} \textit{Step 3}: set $\bGamma^{(t,0)}=\bGamma^{(t)}$, $\bLambda^{(t,0)}=\bGamma^{(t)}$, $h_0=1$.
%\STATE\hspace{0.15in} \textit{Step 4}: {\bf repeat} the following steps for $s=0,1,\ldots$ until convergence.
%\STATE 
%\hspace{0.6in} $\bGamma^{(t,s+1)}=\mathcal{S}_{\lambda\eta}(\bLambda^{(t,s)}-\eta\nabla_\bLambda\ell(\w^{(t+1)},\U^{(t+1)}_1,
%\U^{(t+1)}_3,\bLambda)\mid_{\bLambda=\bLambda^{(t,s)}})$,\\
%\hspace{0.6in} $h_{s+1}=(1+\sqrt{1+4h_s^2})/2$,\\
%\hspace{0.6in}
%$\bLambda^{(t,s+1)}=\bGamma^{(t,s+1)}+\frac{h_s-1}{h_{s+1}}(\bGamma^{(t,s+1)}-\bGamma^{(t,s)})$. 
%\STATE\hspace{0.15in} \textit{Step 5}: set $\bGamma^{(t+1)}=\bGamma^{(t,s)}$.
%$(\mathcal{B}^{(t)}_1,\ldots,\mathcal{B}^{(t)}_p)=\text{Truncate}[(\mathcal{\tilde B}_1,\ldots,\mathcal{\tilde B}_p),(1-\lambda\eta/Norm(]$.\\
%\STATE \textbf{Output}: $\hat{\w},\hat\U_1,\hat\U_3,\hat\bGamma$.}
%\end{algorithmic}
%\label{algo3}
%\end{algorithm}

\begin{algorithm}[!t]
\caption{Optimization procedure of \eqref{obj1}}
\begin{algorithmic}\normalsize{
\STATE \textbf{Input}: %Sample loss function $\ell(\w,\mathcal{U},\ldots,\mathcal{B}_p)$,
rank $R$, tuning parameter $\lambda$ and step size $\eta$.
\STATE\hspace{0.15in} \textit{Step 1}: initialize $\w^{(0)},\U_1^{(0)},\U_3^{(0)},\mathcal{B}^{(0)}_1,\ldots,\mathcal{B}^{(0)}_p$. %\my{ We have not defined $\mathcal{U}$ above, could we write as $\U_1^{(0)}$ and $\U_3^{(0)}$?}\zc{sure, please edit}.
\STATE\hspace{0.15in} {\bf Repeat} Steps 2-5 for $t=0,1,\ldots$ until convergence.
\STATE\hspace{0.25in} \textit{Step 2}: {\bf repeat} the following steps for $r=1,2,...R.$\\
\hspace{0.7in} 
$\tilde\u_{1r}^{(t+1)}=\arg\min_{\u}\ell(\w^{(t)},\u_{11}^{(t+1)},\dots,\u_{1(r-1)}^{(t+1)},\u, \dots, \u_{1R}^{(t)},\u_{31}^{(t)}, \dots, \u_{3R}^{(t)},\bGamma^{(t)})$,\\
\hspace{0.7in} $\tilde\u_{3r}^{(t+1)}=\arg\min_\u\ell(\w^{(t)},\u_{11}^{(t+1)}, \dots, \u_{1R}^{(t+1)}, \u_{31}^{(t+1)}, \dots, \u_{3(r-1)}^{(t)},\u, \dots , \u_{3R}^{(t)},\bGamma^{(t)})$.\\
%\U_j^{(t-1)}-(\nabla^2_{\U_j}\ell(\U_j,\w^{(t-1)},\mathcal{B}^{(t-1)}_{1},\ldots,\mathcal{B}^{(t-1)}_p))^{-1}\nabla_{\U_j}\ell(\U_j,\w^{(t-1)},$ \\$\mathcal{B}^{(t-1)}_{1},\ldots,\mathcal{B}^{(t-1)}_p)$, 
\STATE\hspace{0.25in} \textit{Step 3}: $\tilde\U_{j}^{(t+1)}=(\tilde\u_{j1}^{(t+1)},\ldots,\tilde\u_{jR}^{(t+1)})$,\,\,$j=1,3$,\\
\hspace{0.7in} $\w^{(t+1)}=\w^{(t)}\text{Norm}(\tilde\U_1^{(t+1)})^2\text{Norm}(\tilde\U_3^{(t+1)})$,\\ 
\hspace{0.7in} $\U^{(t+1)}_j=\text{Unit}(\tilde\U_j^{(t+1)})$,\,\,$j=1,3$.\\
\STATE\hspace{0.25in} \textit{Step 4}: set $\bGamma^{(t,0)}=\bGamma^{(t)}$, $\bLambda^{(t,0)}=\bGamma^{(t)}$, $h_0=1$.
\STATE\hspace{0.25in} \textit{Step 5}: {\bf repeat} the following steps for $s=0,1,\ldots$ until convergence.
\STATE 
\hspace{0.7in} $\bGamma^{(t,s+1)}=\mathcal{S}_{\lambda\eta}(\bLambda^{(t,s)}-\eta\nabla_\bLambda\ell(\w^{(t+1)},\U^{(t+1)}_1,
\U^{(t+1)}_3,\bLambda)\mid_{\bLambda=\bLambda^{(t,s)}})$,\\
\hspace{0.7in} $h_{s+1}=(1+\sqrt{1+4h_s^2})/2$,\\
\hspace{0.7in}
$\bLambda^{(t,s+1)}=\bGamma^{(t,s+1)}+\frac{h_s-1}{h_{s+1}}(\bGamma^{(t,s+1)}-\bGamma^{(t,s)})$. 
\STATE\hspace{0.25in} \textit{Step 6}: set $\bGamma^{(t+1)}=\bGamma^{(t,s)}$.
%$(\mathcal{B}^{(t)}_1,\ldots,\mathcal{B}^{(t)}_p)=\text{Truncate}[(\mathcal{\tilde B}_1,\ldots,\mathcal{\tilde B}_p),(1-\lambda\eta/Norm(]$.\\
\STATE \textbf{Output}: $\hat{\w},\hat\U_1,\hat\U_3,\hat\bGamma$.}
\end{algorithmic}
\label{algo3}
\end{algorithm}






%This is a very challenging optimization problem, as we need to develop an alternating procedure that iteratively updates $\mathcal{B}_0$ and $\mathcal{B}_1,\ldots,\mathcal{B}_p$. \cb{This is not clear. Why do we need this alternative procedure? This is a non-convex function, because of the constraints on CP decomposition (You can double check this). This is one possible reason. Or we do not explain this and use the same way in Section 3 of \url{https://arxiv.org/pdf/1810.03192.pdf}}.\my{Thanks, this is a non-convex function, as you suggested, we could use ``We propose to estimate the parameters $\mathcal{B}_0$ and $\mathcal{B}_1,\ldots,\mathcal{B}_p$ through a non-convex regularized optimization."} \cb{Maybe we can write it as ``This optimization problem is non-convex and this non-convexity can bring significant challenges in the estimation. The key idea of our estimation is spliting the non-convex problem into a sequence of conditional optimization problem, which is convex and easy to estimate. Motivated by this idea, we develop an alternating estimation method that iteratively updates $\mathcal{B}_0$ and $\mathcal{B}_1,\ldots,\mathcal{B}_p$ while others fixed.''} Additionally, tensor decomposition, i.e., estimating $\mathcal{U}$, is considerably more complex and computationally costly than matrix decomposition \citep{hillar2013most}. The standard alternating least squares procedure for tensor factorization is computationally inhibitive in our problem, as each iteration would require numerical optimization due to the generalized linear model formulation. 


%To tackle these challenges, we propose an alternating block gradient descent algorithm; see details in  Algorithm~\ref{algo3}.
In Step 2, $\tilde\u_{jr}$'s are solved using a Newton-type algorithm \citep{schnabel1985modular} and the gradients are given in Section \ref{sec:gr} in the supplement. In Step 3, we define two matrix operators for $\U$. Norm$(\U)$ calculates the $\ell_2$ norms of columns in a matrix $\U$ and Unit$(\U)$ rescales the columns of a matrix into unit vectors. That is,
\begin{equation*}
\text{Norm}(\U) = \left[\|\U_{.1}\|_2, \|\U_{.2}\|_2, \ldots, \|\U_{.R}\|_2\right]^T \text{ and } \text{Unit}(\U) = \left[\frac{\U_{.1}}{\|\U_{.1}\|_2}, \frac{\U_{.2}}{\|\U_{.2}\|_2}, \ldots, \frac{\U_{.R}}{\|\U_{.R}\|_2}\right].
\end{equation*}
%The matrix operator Norm$(\U)$ calculates the $\ell_2$ norms of columns in a matrix $\U$, $\text{Norm}(\U) = \left[\|\U_{.1}\|_2, \|\U_{.2}\|_2, \ldots, \|\U_{.R}\|_2\right]^\top,$ and Unit$(\U)$ rescales the columns of a matrix into unit vectors, $\text{Unit}(\U) = \left[\frac{\U_{.1}}{\|\U_{.1}\|_2}, \frac{\U_{.2}}{\|\U_{.2}\|_2}, \ldots, \frac{\U_{.R}}{\|\U_{.R}\|_2}\right]$. %\cb{It might be more straightforward to provide mathematical formula for these two operators.}\zc{please make the edit}\my{Sure, please double check.}
In Step 5, we employ the fast iterative shrinkage-thresholding method \citep[FISTA,][]{beck2009fast} under group lasso penalty. Specifically, we define the shrinkage operator by $\mathcal{S}_{\lambda\eta}(\bGamma)=(\mathcal{T}_{\lambda\eta}(\mathcal{B}_1),\ldots,\mathcal{T}_{\lambda\eta}(\mathcal{B}_p))\in\mathbb{R}^{n\times n\times K\times p}$, where
$$
\mathcal{T}_{\lambda\eta}(\mathcal{B}_{l})_{jj'\cdot}=\left(1-\frac{\lambda\eta}{\|\mathcal{B}_{ljj'\cdot}\|_2}\right)_{+}\mathcal{B}_{ljj'\cdot},
$$
and $(x)_+=\max(0,x)$. 
In the FISTA algorithm and at step $s+1$, the iterative shrinkage
operator $\mathcal{S}_{\lambda\eta}(\cdot)$ is not directly applied to the previous point $\bGamma^{(t,s)}$, but rather at the point $\bLambda^{(t,s)}$ which
uses a specific linear combination of the previous two points $\bGamma^{(t,s)}$ and $\bGamma^{(t,s-1)}$. The FISTA algorithm has been shown to enjoy a fast global rate of convergence \citep{beck2009fast} and is easy to implement. 
The stepsize $\eta$ is typically chosen as the Lipschitz constant of $\nabla_\bGamma\ell(\w,\U_1,\U_3,\bGamma)$, which can be approximately calculated given the initial values.
%sgn$(\cdot)$ return the signs of $b_{ljj'}=\sqrt{\sum_k\mathcal{B}^2_{ljj' k}}$
%$\bar{{\B}}_{l}$ is the $n \times n$ matrix and $\mathbf{1}_{K}$ is a length-$K$ vector with all entries equal to 1. 
%\zc{The previous algorithm in Step 4 is ISTA not FISTA. I changed it to FISTA. The numerical results should be the same with faster convergence when using FISTA. Maoyu, please update the code when you have time. We do not need to rerun experiments.\my{Sure.}}


\smallskip\noindent
\textbf{Initialization.} 
In Algorithm \ref{algo3}, we need to determine the initial values for the alternating minimization procedure. To obtain a good initial estimate, we first estimate $\mathcal{ B}^{(0)}_0, \mathcal{B}^{(0)}_1,\dots,\mathcal{B}^{(0)}_p$ via an element-wise generalized spline regression; see \eqref{eqn:initial}. We then estimate $\w^{(0)}, \U_1^{(0)}, \U_3^{(0)}$ via a $\mathrm{CP}$ decomposition of the estimated $\mathcal{ B}^{(0)}_0$. In our experiments, this initialization procedure leads to a good numerical performance of Algorithm \ref{algo3}. The accuracy of this initialization procedure is evaluated in Section \ref{sec:3}. 

%For initialization, we let $\mathcal{B}_1=\cdots=\mathcal{B}_p=\mathbf{0}$ and estimate $\tilde{\mathcal{B}}_0^{(0)}$ via entry-wise spline regression and initialization $\boldsymbol{w}^{(0)}, \mathcal{U}^{(0)}$ via the $\mathrm{CP}$ decomposition of $\tilde{\mathcal{B}}_0^{(0)}$. 
%To further improve the estimation accuracy of $\mathcal{B}_1,\ldots,\mathcal{B}_p$, we re-estimate the non-zero position of them by entry-wise GLM with spline basis after Algorithm~\ref{algo3}. 
%we estimate $\mathcal{\tilde B}^{(0)}_0,\dots,\mathcal{\tilde B}^{(0)}_p$ via the entry-wise spline regression, which fits a GLM with spline basis to each entry of $\A_{jj'}$, and initialize $\w^{(0)},\mathcal{U}^{(0)}$ via the CP decomposition of $\mathcal{\tilde B}^{(0)}_0$.

\smallskip\noindent
\textbf{Parameter tuning.} The rank $R$ and regularization parameter $\lambda$ are two tuning parameters in our algorithm. 
We choose these parameters using the eBIC criterion that was first developed for variable selection in the diverging dimension regime in \cite{chen2012extended}. 
It has been demonstrated that 
the eBIC function is effective as a heuristic criterion to balance model fitting and complexity when used in low-rank estimation problems \citep{srivastava2017expandable,cai2021jointly,zhang2022generalized}.
%the eBIC function has been utilised in low-rank estimation issues and has been proven to perform well as a heuristic criterion to balance model fitting and complexity.
Specifically, we choose the combination of $(R, \lambda)$ that minimizes,
$$N\times\ell(\hat\w,\hat\U_1,\hat\U_3,\hat\bGamma)+[\log\left(n^{2} NT/2\right)+ \log\left(n^{2} K(p+1)/2\right)]\times [R(n+K)+\sum_{l=1}^p||\hat{\mathcal{B}_l}||_0/2],$$
where $\ell$ is the loss function in (\ref{loglikelihood2}), and $\hat\w,\hat\U_1,\hat\U_3,\hat\bGamma$ are the estimates of $\w,\U_1,\U_3,\bGamma$ under the working rank and regularization parameter.
In our numerical experiments, the above eBIC is found to be minimized at the true rank and sparsity level under the selected $\lambda$.


\begin{comment}
a group truncation operator $\text{Gtruncate}[(\mathcal{B}_1,\ldots,\mathcal{B}_p),s]$ such that $(\mathcal{\hat B}_1,\ldots,\mathcal{\hat B}_p)=\text{Gtruncate}[(\mathcal{B}_1,\ldots,\mathcal{B}_p),s]$ and
$$
\mathcal{\hat B}_{ljj'\cdot}=
 \begin{cases}
    \mathcal{B}_{ljj'\cdot}       & \quad \text{if } (l,j,j')\in \text{supp}[(\mathcal{B}_1,\ldots,\mathcal{B}_p),s],\\
    \textbf{0}  & \quad \text{otherwise},
  \end{cases}
$$
where $\text{supp}[(\mathcal{B}_1,\ldots,\mathcal{B}_p),s]$ is the set of indices corresponding to $s$ tube fibers with the largest $\ell_1$ norm in $\mathcal{B}_1,\ldots,\mathcal{B}_p$. 
\end{comment}



\section{Simulation}\label{sec:3}
We conduct simulations to investigate the performance of our proposed method. We focus on symmetric networks, and compare our proposed dynamic network response regression method, referred as $\rm DNetReg$, with two alternative element-wise approaches. 

The first element-wise approach, referred as $\rm EdgeReg$, fits element-wise GLMs at each time point $t_k$. That is, for any $j,j'\in [n], h\in [T]$, consider
\begin{equation}\label{eqn:initial0}
g(\bmu^{(i)}_{j j'}(t_h))=\B_{0j j'}(t_h)+\sum_{l=1}^p x_{il}\B_{lj j'}(t_h),\quad i\in [N].
\end{equation}
This element-wise approach ignores both the network structure and the temporal smoothness in the dynamic brain connectivity. 
%In fact, this model degenerates to the regular generalized linear model over $n \times n \times T$ entries.\zc{Add some details on how TPR and FPR are obtained from this approach.\my{Sure, I added some details below.}} 
The second element-wise approach, referred as $\rm DEdgeReg$, fits a generalized spline regression to each entry in $\boldsymbol{A}_{j j'}(t)$. Specifically, for any $j,j'\in [n]$, consider
\begin{equation}\label{eqn:initial}
g(\bmu^{(i)}_{j j^{\prime}}(t))=\mathcal{B}_{0j j'\cdot}^\top{\boldsymbol \phi}(t)+\sum_{l=1}^p x_{il}\mathcal{B}_{lj j'\cdot}^\top\boldsymbol \phi(t), \quad i\in [N].
\end{equation}
A Newton-type algorithm is employed to estimate the parameters in the above model. 
The method $\rm DEdgeReg$ is used to find the initial values in Algorithm \ref{algo3}.

%We select the rank $R$ and the regularization parameter $\lambda$ using the eBIC criterion in all simulations.
%, and have found our method performs competitively in all settings.
%We have found our method performs competitively in all settings. In all simulations, we tune the rank $R$ and the regularization parameter $\lambda$ using the eBIC criterion.


\begin{table}[!t]
\small
\centering
\setlength{\tabcolsep}{2pt}
\caption{Simulation results under the generalized dynamic network response model with $N=50$ and varying numbers of nodes $n$, rank $R$ and sparsity proportion $s_0$. Marked in boldface are those achieving the best evaluation criteria in each setting.}\label{result_sim}
\begin{tabular}{|c|c|c|llllll|}
\hline $n$ & $R$ & $s_0$ & Method & Error of $\boldsymbol{\mu}^{(i)}(t)$ & Error of $\mathcal{B}_0$ & Error of $\mathcal{B}_1$ &TPR &FPR  \\\hline
 \multirow{12}{*}{50} & \multirow{6}{*}{2}         & \multirow{3}{*}{0.05}   &$\rm EdgeReg$ & 31.986(0.759)  & -  &  -   &   0.010(0.051) &0        \\
                            &   &   & $\rm DEdgeReg$ & 8.767(0.850)  & 25.010(9.601)  &  14.599(1.256)   &  -  &-      \\
                            &   &   & $\rm DNetReg$ & \bf  2.410(0.306)  & \bf 5.925(1.048)  &  \bf 7.054(0.727)   &   \bf 1.000(0.000) &   0.016(0.019)       \\
                       \cline{3-9} 
                                               &                                              & \multirow{3}{*}{0.1}   &$\rm EdgeReg$ & 31.912(0.724)  & -  &  -   &   0.012(0.072) &0        \\
                            &   &   & $\rm DEdgeReg$ & 8.636(0.235)  & 25.588(7.593)  &  17.394(1.279)   &  -  &-      \\
                            &   &   &  $\rm DNetReg$ & \bf 3.067(0.448)  & \bf 6.545(1.026)  &  \bf 9.774(0.886)   &   \bf 1.000(0.000) &  0.017(0.016)       \\
                       \cline{2-9} 
                                              & \multirow{6}{*}{5}                  & \multirow{3}{*}{0.05} & $\rm EdgeReg$  &  29.921(0.718)  & -  &  -   &  0.001( 0.005) &0        \\
                             &   &   & $\rm DEdgeReg$ & 8.225(0.213)  & 35.912(11.527) &  16.348(1.328)  &  -   &-    \\
                            &   &   &  $\rm DNetReg$ & \bf 2.875(0.203)  & \bf 7.896(0.935)  & \bf7.546(0.791)   & \bf 1.000(0.000)& 0.020(0.025)       \\
                       \cline{3-9} 
                                               &                                              & \multirow{3}{*}{0.1} & $\rm EdgeReg$  &  29.878(0.799)  & -  &  -   &  0.006(0.031) &0        \\
                             &   &   & $\rm DEdgeReg$ & 8.340(0.213)  & 36.304(11.432) &  18.528(1.652)   &  -   &-    \\
                            &   &   &  $\rm DNetReg$ & \bf 3.436(0.146)  & \bf 8.428(1.114)  & \bf 10.833(1.317)   & \bf 1.000(0.000)& 0.021(0.021)       \\
\cline{1-9} 
  \multirow{12}{*}{100}  & \multirow{6}{*}{2} &  \multirow{3}{*}{0.05}   & $\rm EdgeReg$ & 64.302(1.125)  & -  &  -   & 0.000(0.000) &0        \\
    &   &   & $\rm DEdgeReg$ & 17.461(0.532)  & 52.495(18.720)  & 28.717(1.847)   &  -    &-    \\
    &   &   &  $\rm DNetReg$ & \bf 4.556(0.371)  & \bf 10.441(1.991)  &  \bf 14.095(1.289)   &  \bf 1.000(0.000) & 0.016(0.014)  
\\
\cline{3-9} 
                           &   & \multirow{3}{*}{0.1}   & $\rm EdgeReg$ & 64.170(1.081)  & -  &  -   & 0.000(0.000) &0        \\
    &   &   & $\rm DEdgeReg$ & 17.372(0.396)  & 50.158(10.227)  & 31.699(1.893)   &  -    &-    \\
    &   &   &  $\rm DNetReg$ & \bf 5.617(0.295)  & \bf 10.844(1.658)  &  \bf 19.895(1.818)   &  \bf 1.000(0.000) & 0.015(0.014)  
\\
                       \cline{2-9} 
                                               & \multirow{6}{*}{5}                  & \multirow{3}{*}{0.05}   &$\rm EdgeReg$ &  59.413(1.667)  & -  &  -   & 0.000(0.000) &0         \\
                       
                           &   &   & $\rm DEdgeReg$ & 16.491(0.353)  & 68.531(12.035)  &  32.981(1.898)   &  -     &-   \\
                       
                           &   &   &  $\rm DNetReg$ & \bf 5.359(0.435)  & \bf 11.945(2.530)  &  \bf 15.242(1.551)   &  \bf 1.000(0.000) &0.020(0.019)        \\
                       \cline{3-9} 
                                               &                                              & \multirow{3}{*}{0.1}   &$\rm EdgeReg$ &  59.554(1.463)  & -  &  -   & 0.000(0.000) &0         \\
                       
                           &   &   & $\rm DEdgeReg$ & 16.978(2.029)  & 68.683(11.474)  &  34.618(2.946)   &  -     &-   \\
                       
                           &   &   &  $\rm DNetReg$ & \bf 6.418(0.472)  & \bf 12.361(2.131)  &  \bf 21.451(1.961)   &  \bf 1.000(0.000) &0.019(0.015)        \\
                       \hline
   \end{tabular}
\end{table}                    


\begin{table}[!t]
\small
\centering
\setlength{\tabcolsep}{2pt}
\caption{Simulation results under the generalized dynamic network response model with $N=100$ and varying numbers of nodes $n$, rank $R$ and sparsity proportion $s_0$. Marked in boldface are those achieving the best evaluation criteria in each setting.}\label{result_sim_100}
\begin{tabular}{|c|c|c|llllll|}
\hline $n$ & $R$ & $s_0$ & Method & Error of $\boldsymbol{\mu}^{(i)}(t)$ & Error of $\mathcal{B}_0$ & Error of $\mathcal{B}_1$ &TPR &FPR  \\\hline
 \multirow{12}{*}{50} & \multirow{6}{*}{2}         & \multirow{3}{*}{0.05}   &$\rm EdgeReg$  & 31.976 (0.783)  & -  &   -  &  0.010 (0.054)&     0   \\
                            &   &   & $\rm DEdgeReg$  & 8.695 (0.202)  & 23.381 (2.607)  & 14.344 (0.898)    & - &  -      \\
                            &   &   & $\rm DNetReg$  & \bf 1.833(0.202)  &\bf 4.150 (1.022)   &  \bf  4.772(0.384)   & \bf 1.000 (0.000)  &   0.017(0.018)     \\
                       \cline{3-9} 
                                               &    & \multirow{3}{*}{0.1}   &$\rm EdgeReg$  & 31.928 (0.746)  &-   & -    & 0.012 (0.073) & 0       \\
                            &   &   & $\rm DEdgeReg$  & 8.680 (0.200)  & 23.153 (2.358)  & 14.835 (0.873)    & - & -       \\
                            &   &   &  $\rm DNetReg$ &  \bf 2.256 (0.217) & \bf 5.010 (1.505)  & \bf 6.796 (0.497)    &  \bf 1.000 (0.000)  &  0.018(0.014)        \\
                       \cline{2-9} 
                                              & \multirow{6}{*}{5} & \multirow{3}{*}{0.05} & $\rm EdgeReg$  &  29.982 (0.725)  & -  &  -   & 0.006 (0.038)&0        \\
                             &   &   & $\rm DEdgeReg$ &  8.243 (0.204) & 33.525 (6.680)  & 16.416 (1.254)    & -& -       \\
                            &   &   &  $\rm DNetReg$  & \bf 2.369 (0.277)  &\bf 6.896 (0.823)   &\bf 5.437 (0.585)     & \bf 1.000 (0.000) & 0.014 (0.015)       \\
                       \cline{3-9} 
                                               &     & \multirow{3}{*}{0.1} & $\rm EdgeReg$  & 29.888 (0.745)  & -  &  -   & 0.002 (0.004) &0        \\
                             &   &   & $\rm DEdgeReg$  & 8.240 (0.194)  & 34.872 (9.490)  & 17.173 (1.386)    &-  & -       \\
                            &   &   &  $\rm DNetReg$  & \bf 2.605 (0.162)  & \bf 7.068 (1.163)   &  \bf 7.722 (0.794)   & \bf 1.000 (0.000)  & 0.013 (0.014)       \\
\cline{1-9} 
  \multirow{12}{*}{100}  & \multirow{6}{*}{2} &  \multirow{3}{*}{0.05}   & $\rm EdgeReg$  & 64.305(1.136)  & -  & -    &  0& 0       \\
    &   &   & $\rm DEdgeReg$  &  17.428 (0.384) & 48.244 (5.731)  & 28.645 (1.863)     & - & -       \\
    &   &   &  $\rm DNetReg$  & \bf 3.749 (0.448)  &\bf 9.012 (1.235)   & \bf 9.742 (0.810)    &\bf 1.000 (0.000)  & 0.017(0.013)       \\
\cline{3-9} 
                           &   & \multirow{3}{*}{0.1}   & $\rm EdgeReg$ & 64.149 (1.105)  & -  &   -  & 0 &0        \\
    &   &   & $\rm DEdgeReg$ & 17.376 (0.395)  & 49.194 (7.075)  &  29.801 (1.871)   &-  & -       \\
    &   &   &  $\rm DNetReg$  & \bf 4.455 (0.390)  & \bf 10.170(1.383)   & \bf 13.701 (0.924)    &  \bf 1.000 (0.000) &    0.016 (0.011)     \\
                       \cline{2-9} 
                                               & \multirow{6}{*}{5}      & \multirow{3}{*}{0.05}  & $\rm EdgeReg$  &  59.190 (1.891)  & -  &  -   & 0 &  0      \\
                           &   &   & $\rm DEdgeReg$  & 16.418 (0.344)  & 65.339 (8.567)  & 33.260 (1.676)    &-  &  -      \\
                       
                           &   &   &  $\rm DNetReg$ &\bf  4.320 (0.503) &\bf 10.991 (1.779)   & \bf 11.374 (1.327)  & \bf 1.000 (0.000)    & 0.016 (0.011)         \\
                       \cline{3-9} 
                                               &   & \multirow{3}{*}{0.1}   &$\rm EdgeReg$  &58.110 (1.934)   & -  &  -   & 0 &  0      \\
                       
                           &   &   & $\rm DEdgeReg$  &  16.624 (0.327) & 66.029 (7.007)  & 33.824 (1.849)    &-  &-        \\
                       
                           &   &   &  $\rm DNetReg$ &\bf 5.088 (0.346)   &\bf 11.906(2.445)   & \bf 15.679 (1.423)    & \bf 1.000 (0.000) & 0.014 (0.009)        \\
                       \hline
   \end{tabular}
\end{table}             


We simulate $N$ binary dynamic networks of size $n\times n$ in $[0,1]$ from model (\ref{approximatemodel}), where $\A_{jj'}(t)$, $t\in[0,1]$, follows a Bernoulli distribution and $g(\cdot)$ is taken to be the logit link function. 
The covariates $x_{i}$'s are generated independently from $\mathcal{N}(0,1)$ and we standardize the columns of the design matrix to have zero mean and unit standard deviation. 
For $\mathcal{B}_0=\sum_{r=1}^R w_{r}\u_{1r} \circ \u_{1r} \circ \u_{3r}$, we first generate the entries of $\u_{1r}$ and $\u_{3r}$ from $\mathcal{N}(0,1)$, set $w_{r}=||\u_{1r}||^2||\u_{3r}||$, and then we standardize $\u_{1r}$ and $\u_{3r}$ as unit length vectors. 
For $\mathcal{B}_1$, we randomly set $s_{0}$ proportion of its entries to be 1 and the rest to zero, such that $s_{0}=\|\mathcal{B}_1\|_0 /\left(n^{2} K\right)$. The basis functions in $\bm\phi(t)$ are set to B-spline basis with $K = 8$ equally spaced knots in $[0,1]$.
%\cb{It is not clear about randomly setting the proportion. Maybe we can write it as ``Given the sparsity parameter $s_0$ for $\bcB_l$, we randomly let $s_0*n^2K$ elements in $\bcB_l$ to be 1 and other elements are set as 0.''} 
%\zc{How are the time-varying network connectivity generated? Did you specify $\phi(t)$ anywhere?\my{We simulate $N$ binary dynamic networks of size $n\times n$ from model (\ref{approximatemodel}). More specifically, we generate $jj'$-th entry of $A^{(i)}(t)$ from the binomial  distribution with probability $g(\bmu_{jj'}^{(i)}(t))$ in model (\ref{approximatemodel}), where $g(\cdot)$ is taken to be the logit link function, and $\phi(t)$ is the B-spline basis with $K = 8$. }}

To evaluate the estimation accuracy, we report estimation errors $\|\mathcal{B}_0-\hat{\mathcal{B}}_0\|_{F}$, $\|\mathcal{B}_1-\hat{\mathcal{B}}_1\|_{F}$, and $\sum_{i=1}^{N}\|\boldsymbol{\mu}^{(i)}(t)-\hat{\boldsymbol{\mu}}^{(i)}(t)\|_{F}/N$, where $\hat{\boldsymbol{\mu}}^{(i)}(t)=g^{-1}\left(\hat{\mathcal{B}_0}\times_3 {\boldsymbol \phi}(t)+x_{i}(\hat{\mathcal{B}_1}\times_3 {\boldsymbol \phi}(t))\right)$. Furthermore, to evaluate the edge selection accuracy from our method, we report the %the $\mathrm{F} 1$ score
true positive rate (TPR) and false positive rate (FPR) in identifying the nonzero entries in $\mathcal{B}_1$. %which is calculated as $2 \mathrm{TP} /(2 \mathrm{TP}+\mathrm{FP}+\mathrm{FN})$, where $\mathrm{TP}$ is the true positive count, $\mathrm{FP}$ is the false positive count, and $\mathrm{FN}$ is the false negative count. 
The first element-wise approach $\rm EdgeReg$ does not estimate spline coefficients $\mathcal{B}_0$ and $\mathcal{B}_1$, and thus their estimation errors are not reported.
%, since this method could only estimate $\boldsymbol{\mu}^{(i)}(t)$, where our model structure assumption is not satisfied. 
%since the method of entry-wise spline regression ($\rm DEdgeReg$) does not include entry-wise sparsity, its TPR and FPR are not reported. As the method of entry-wise GLM regression ($\rm EdgeReg$) could only estimate $\boldsymbol{\mu}^{(i)}(t)$, where our model structure is not satisfied, thus the estimation errors for $\mathcal{B}_0$ and $\mathcal{B}_1$ are not reported, 
While estimates from $\rm EdgeReg$ are not sparse, the $p$-values for $\B_{ljj'}(t_h)$'s are directly available from standard GLM model fitting. In our evaluations, we apply Bonferroni correction to these p-values and then calculate the TPR and FPR in identifying the edges modulated by $x_1$, that is, entries $(j,j')$'s with nonzero time-varying covariate effects $\B_{1jj'}(t)$'s. 
%Instead, the sparsity of $\rm EdgeReg$ is provided by taking into account entry-wise GLM with Bonferroni-adjusted $p$-value; for an entry, the related edge is regarded significant if the minimum adjusted $p$-value within $T$ time points is less than 0.05, and not significant, otherwise. 
Specifically, we define $\mathcal{P}^{BC} \in \mathbb{R}^{n \times n \times T}$, where $\mathcal{P}^{BC}_{jj'h}$ is the $p$-value in evaluating the significance of $\B_{1jj'}(t_h)$ from \eqref{eqn:initial0}, after the Bonferroni correction of $n \times n \times T$ tests. Defining $\bm H \in \mathbb{R}^{n \times n}$ with $\bm H_{jj'}=1{\{\min(\mathcal{P}^{BC}_{jj'.})\le 0.05\}}$, and $\bm H^{\text{true}} \in \mathbb{R}^{n \times n}$ with $\bm H^{\text{true}}_{jj'}=1{\{\int_t|\B_{1jj'}(t)|\neq 0\}}$.
The FPR and TPR are calculated as
$${\rm TPR}=\frac{\|\bm H*\bm H^{\text{true}}\|_0}{n^2s_0},\quad {\rm FPR}=\frac{\|\bm H\|_0-\|\bm H*\bm H^{\text{true}}\|_0}{n^2s_0},$$
where $*$ denotes the element-wise product. 
The second element-wise approach $\rm DEdgeReg$ does not give sparse estimates and there are no readily available inference results to calculate $p$-values, and hence their TPRs and FPRs are not reported. %\cb{Bonferroni is the most conservative adjustment for p value. People may think the poor performance of EdgeReg in TPR and FPR is from this adjustment. Maoyu told me she also tried fdr adjustment and the results are similar. I am wondering if we need mention that we also consider other p value adjustment like fdr and it gives a similar result.}
%\zc{please make the edit.}\my{Sure.}

We set the number of subjects $N = 50$, the number of equally spaced time points $T=100$, and consider the number of nodes $n = 50,100$, rank $R = 2, 5$, and the sparsity proportion $s_0 = 0.05, 0.1$, respectively. 
Tables \ref{result_sim} and \ref{result_sim_100} report the average accuracy measures over 50 replications with sample size $N=50,100$, respectively, with the standard deviations shown in parentheses.
It is seen that our proposed method achieves the best performance among all competing methods, in terms of both estimation accuracy and selection accuracy, and this holds for different sample sizes $N$, numbers of nodes $n$, ranks $R$ and sparsity levels $s_0$. Moreover, the estimation error of our method $\rm DNetReg$ decreases as network size $n$, rank $R$ and sparsity proportion $s_0$ decrease, and as sample size $N$ increases. %\cb{Do we have the results when we increase the sample size?\my{Since there are more combinations of parameters, we did not consider the variation of the sample size, because the estimation will certainly get better as the sample size increases.}} \zc{I recommend adding results from $N=200$. Our current simulation setting is a bit short.\my{Could we add results from $N=50$? Because I tried $N=200$ before, the server ran out of memory when $n=100$.} \zc{$N=50$ is good.} \my{Sorry, I checked the code and the saved result, and found the current table is for $N=50$, and I will add the table for $N=100$ later since it takes too long time in the server.}}For $\rm DNetReg$, the estimation accuracy improves with the number of nodes $n$. For a fixed $n$, the estimation accuracy of $\mathcal{B}_0$ and $\mathcal{B}_1$ increases when the model becomes simpler (smaller $R$ or $s_0$). The primary explanation for this performance is that as $R$, $s_0$, or $n$ decreases, the structure of $\mathcal{B}_0$ or $\mathcal{B}_1$ in the proposed model becomes clearer, resulting in a reduction of model complexity and an increase of estimation accuracy. 
Estimation errors from $\rm EdgeReg$ and $\rm DEdgeReg$ are not sensitive to $R$ or $s_0$, as they are element-wise approaches and do not consider the low-rank and sparsity structure in the tensor coefficients. In terms of edge selection accuracy,  %$\rm DNetReg$ correctly picks out significant edges, with $\rm TPR=1$ and FPR almost 0. Since 
$\rm EdgeReg$ is overly conservative after the Bonferroni correction, and its TPRs are close to zero. 
In our analysis, we also considered FDR (or BH) correction \citep{benjamini1995controlling} for $p$-value corrections and the results are similar. 




                       
\begin{comment}
  \begin{table}[!t]
\small
\centering
\begin{tabular}{|c|c|c|c|ccccc|}
\hline$N$ & $T$ & $R$ & $s_0$ & Method & Error of $\boldsymbol{\mu}^{(i)}(t)$ & Error of $\mathcal{B}_0$ & Error of $\mathcal{B}_1$ & F1 score \\\hline                     
\multirow{32}{*}{200} & \multirow{16}{*}{100} & \multirow{8}{*}{2}         & \multirow{4}{*}{0.1}   &$\rm EdgeReg$ & 22.508(0.421)  & -  &  -   &  0.789(0.022)         \\
                        &    &   &   & $\rm DEdgeReg$ & 6.287(0.156)  & 19.991(8.250)  &  11.059( 0.622)   &  -        \\
                         &    &   &   & $\rm GLM_{ENP}$ & 13.531(1.891)  & 25.133(5.215)  &  33.903(5.699)   &  0.861(0.043)        \\
                         &    &   &   &  $\rm DNetReg$ & \bf 4.296(0.646)  &  \bf 7.678(1.446)  &  \bf 10.779(0.934)   &  \bf 0.982(0.013)        \\
                       \cline{4-9}
                       &                        &                                              & \multirow{4}{*}{0.2}    & $\rm EdgeReg$ & 22.301(0.394)  & -  &  -  &  0.792(0.012)            \\
                        &    &   &   & $\rm DEdgeReg$ & \bf 6.231(0.157)  & 19.812(3.709)  &  \bf 13.660(1.047)   &  -        \\
                         &    &   &   & $\rm GLM_{ENP}$ & 15.316(2.119)& 27.688(5.576)  & 42.794(6.831)  &   0.843(0.039)     \\
                        &    &   &   &  $\rm DNetReg$ & 6.990(1.309)  &\bf 15.175(3.423)  &  13.744(1.059)   &  \bf 0.963(0.016)       \\
                       \cline{3-9} 
                       &                        & \multirow{8}{*}{5}                  & \multirow{4}{*}{0.1} & $\rm EdgeReg$  &  20.940(0.559)  & -  &  -   &  0.802(0.019)          \\
                         &    &   &   & $\rm DEdgeReg$ & 5.919(0.147)  & 26.852(8.534)  &  13.049(0.984)   &  -        \\
                          &    &   &   & $\rm GLM_{ENP}$ & 19.367(1.151)  & 39.289(8.722)  &  52.996(4.094)   &  0.790(0.061)        \\
                        &    &   &   &  $\rm DNetReg$ &  \bf 5.099(0.459)  & \bf 10.904(1.899)  &  \bf 12.016(1.012)   & \bf 0.964(0.025)        \\
                       \cline{4-9} 
                       &                        &                                              & \multirow{4}{*}{0.2} & $\rm EdgeReg$ & 41.935(0.914)  & -  &  -   &   0.790(0.017)            \\
                        &    &   &   & $\rm DEdgeReg$ & \bf 8.325(0.195)  & 25.369(4.604)  &  \bf 16.424(1.375)   &  -      \\
                        &    &   &   & $\rm GLM_{ENP}$ & 26.591(2.137)  & 39.912(5.256)  &  57.635(5.553)   &  0.776( 0.054)        \\
                        &    &   &   &  $\rm DNetReg$ & 9.442(0.545)  & \bf 15.580(1.943)  &  17.979(3.581)   &  \bf 0.957(0.025)        \\
\cline{2-9}
& \multirow{16}{*}{200}  & \multirow{8}{*}{2} &  \multirow{4}{*}{0.1}   & $\rm EdgeReg$ & 31.854(0.578)  & -  &  -  &   0.654(0.019)        \\
&    &   &   & $\rm DEdgeReg$ & 6.673(0.233)  & 16.017(2.519)  &  8.071(0.774)   &  -       \\
&    &   &   & $\rm GLM_{ENP}$ & 11.318(1.350)  & 19.488(3.584)  &  22.412(3.869)   &  0.764(0.055)        \\
&    &   &   &  $\rm DNetReg$ & \bf 4.917(0.962)  & \bf 7.550(1.361)  &  \bf 7.985(1.238)   &   \bf 0.981(0.029) 
\\
\cline{4-9} 
                       &                        &                                              & \multirow{4}{*}{0.2}   & $\rm EdgeReg$ &31.814(0.384)  & -  &  -   &  0.672(0.011)        \\
                       
                       &    &   &   & $\rm DEdgeReg$ & \bf 6.643(0.229)  & 15.392(1.687)  &  \bf 10.201(0.769)   & - \\
                       &    &   &   & $\rm GLM_{ENP}$ & 14.884(1.103)  & 20.854(2.648)  &  33.712(3.453)   &  0.743(0.049) \\
                        &    &   &   &  $\rm DNetReg$ & 7.561(0.915)  & \bf 8.553(1.443)  &  11.779(1.983)   &  \bf 0.965(0.110) \\
                       \cline{3-9} 
                       &                        & \multirow{8}{*}{5}                  & \multirow{4}{*}{0.1}   &$\rm EdgeReg$ & 29.730(0.844)  & -  &  -   &  0.673(0.020)         \\
                       &    &   &   & $\rm DEdgeReg$ & 6.204(0.221)  & 20.384(5.967)  &  9.557(1.338)   &  -        \\
                        &    &   &   & $\rm GLM_{ENP}$ & 22.343(1.35)  & 28.538(6.012)  &  33.240(3.801)   &  0.689(0.061)        \\
                       &    &   &   &  $\rm DNetReg$ & \bf 5.218(0.529)  & \bf 8.350(1.895)  &  \bf 9.059(2.02)   & \bf 0.963(0.019)        \\
                       \cline{4-9} 
                       &                        &                                              & \multirow{4}{*}{0.2}   & $\rm EdgeReg$ &29.607(0.784)  & -  &  -   &  0.688(0.012)     \\
                        &    &   &   & $\rm DEdgeReg$ & \bf 6.270(0.146)  & 19.580(3.078)  &  \bf 12.703(2.418)   &  -       \\
                        &    &   &   & $\rm GLM_{ENP}$ & 16.803(4.907)  & 30.165(4.907)  &  38.734(4.287)   &   0.742(0.051)        \\
                         &    &   &   &  $\rm DNetReg$ & 9.617(0.803)  & \bf 11.301(1.553)  & 17.436(1.938)   &  \bf 0.999(0.000)        \\
                       \hline
                       
\end{tabular}
\caption{Simulation results}
\end{table}
\end{comment}   

%\newpage
\section{Application to the social cognition study in the Human Connectome Project}\label{sec:4}

%\subsection{Data pre-processing}\label{pre-pro}
The social cognition study in the HCP study collects task-related fMRI data from $N=843$ healthy adult subjects. Specifically, the fMRI data are collected on 274 evenly spaced time points covering an initiation countdown (5 seconds) followed by 5 video blocks (23 seconds each) with fixation blocks in between (15 seconds each). 
The first 11 scans in the initiation countdown period are removed in our analysis. 
The fMRI data are then preprocessed and summarized as a $68\times 263$ spatial-temporal matrix for each subject using the Desikan-Killiany Atlas \citep{desikan2006automated} with $n = 68$ ROIs (see Table \ref{68region}). For each subject, the dynamic network is constructed by calculating a sequence of connectivity matrices of dimension $68\times 68$ over $T$ sliding windows, each summarizing the connectivity between the 68 brain regions in a given window. We let the number of samples in each window and the overlap between adjacent windows be 30 and 5, respectively, giving a total of $T=47$ networks per subject. 
%\my{While there are many choices of connectivity measures \citep{smith2013functional}, the most commonly used one is perhaps the marginal correlation coefficient. 
%, though some work suggested that partial correlation can be a better measure of connectivity \citep{varoquaux2013learning}. 
%We follow the vast majority of the neuroscience literature and measure connectivity in each individual by calculating Pearson correlations using samples from a pair of regions. \my{this is a bit redundant to that in the last paragraph in red on page 3, maybe we could write it as 
We determine connectivity in each individual by computing Pearson correlations between samples from a pair of regions, and create binary networks by setting $\A_{jj'}(t_h)=1$ if the computed correlation value is greater than 0.5 and $\A_{jj'}(t_h)=0$ otherwise, and this gives an average network density about 15\%. 
%\zc{Maoyu, can you compute this? \my{Yes, I compute the average network density for the $843 \times 68 \times 68 \times 47$ dynamic networks, by taking an average of the 843 subjects and 47 time points. I have found that the network density of each subject varies considerably with the 47 time points, as in Figure \ref{density}. In fact, because there were missing values in 850 subjects, after processing we only used 843 subjects, of which 469 were female and 374 were male.}} 
This procedure can eliminate weak functional connectivity and is commonly employed in existing neuroscience literature \citep{power2011functional}. 
In our analysis, we have also considered partial correlation matrices \citep{meinshausen2006high} and applied other thresholding values, such as 0.6, to the Pearson correlation matrix, and found that our main results and qualitative findings remain similar. 
%\zc{Have we tried other thresholding values before? Are the results sensitive to thresholding values? \my{Yes, we have tried the MB estimator in R package huge, and the results are not sensitive; Also, I have tried the other thresholding values before, it is also not sensitive.}}
%\begin{figure}[t!]
%	\centering
%	\subfigure[male]{
%		\centering
%		\includegraphics[width=0.45\linewidth]{Rplot03.pdf}}
%	\subfigure[female]{
%		\centering
%		\includegraphics[width=0.45\linewidth]{Rplot02.pdf}}
%	\centering
%	\caption{The network density for two subjects.} \label{density}
%\end{figure}


%We first eliminate the beginning 11 scans since they may contain elements that are unrelated to the task, resulting in the $68 \times 263$ spatial-temporal fMRI matrix for each subject, which corresponds to 68 brain ROIs from the Anatomical Automatic Labeling (AAL) atlas, and the scan (or frame) length is 263 (in 180 seconds). Next, we remove the linear and cyclic patterns found in this fMRI data. A comparison of the raw and de-trended fMRI data for the left inferior parietal region is shown in Figure \ref{detrend}. The raw fMRI data contains periodic trends of brain connections; while, after de-trending, it is more like white noise, with a relatively stationary behavior. This ensures that our study is unaffected by the objective brain activity cycles. 
%To have the multiple-subject dynamic network from the fMRI, a moving window approach can be used to develop cross thresholded correlation matrices which results in binary edges. It is also possible to take into account more complex estimating techniques discussed in \cite{song2009keller} and \cite{qiu2016joint}. 
%In this paper, the tfMRI data has been pre-processed as a $68 \times 263$ spatial-temporal matrix for each subject, which corresponds to 68 brain ROIs from the Anatomical Automatic Labeling (AAL) atlas, and the scan (or frame) length is 263 (in 180 seconds). %\my{the pre-process part may be moved to the Supplementary materials? or move Section \ref{pre-pro} to this part?}. \zc{We probably do not need the data preprocessing details here. We also do not really need Figure 1. It is not that informative.}
%For each subject, the spatial-temporal matrix is summarized in the form of a binary dynamic network of 30 scans, with the nodes corresponding to 68 ROIs, and the edges recording the binary indicator of the thresholded correlations, where we set the threshold as $\pm 0.5$ to convert the correlation matrix into a binary dynamic network, encoding functional or structural associations between the regions. To be more specific, 
%47 time windows of length 30 are created by sliding 5 scans each time. %Afterwards, for each time window, a correlation matrix is calculated and then truncated as a binary matrix with a threshold of 0.5. 
%To this end, we obtain a dynamic network with 68 nodes and 47 snapshots for each subject. %, as illustrated in Figure \ref{pre}. 
%The data takes the form of a multidimensional array, one mode of which is time, and another mode is subject, thus leading to multiple-subject dynamic network.
%Neuroimaging data studies are now ubiquitous in a wide range of scientific applications, especially the multiple-subject dynamic network data, in which a dynamic connectivity network is measured over a common set of nodes for each individual subject, for example, the error-related negativity (ERN)  from electroencephalogram (EEG) data \citep{ozdemir2014multiple}, the Parkinson’s Disease (PD) from the resting-state functional magnetic resonance imaging (rs-fMRI) \citep{wu2021dynamic}, and our motivating  task-related fMRI data. 


%In order to produce the $68 \times 263$ spatial-temporal fMRI, \cb{It looks little confused here, because we already have a spatial temporal matrix. I suggest to move some data introduction here and then explain why we need this pre-processing procedure.\my{We could discuss this point online.}} we first eliminate the beginning 11 scans since they may contain elements that are unrelated to the task. Next, we remove the linear and cyclic patterns found in this fMRI data. A comparison of the raw and de-trended fMRI data for the left inferior parietal region is shown in Figure \ref{detrend}. 
%The raw fMRI data contains periodic trends of brain connections; while, after de-trending, it is more like white noise, with a relatively stationary behavior. This ensures that our study is unaffected by the objective brain activity cycles. Then, as described in Section \ref{intro}, we determine the matching Pearson correlation matrix for each window, and set the threshold as $\pm 0.5$ to convert the correlation matrix into a binary dynamic network.

%\begin{figure}[t!]
%	\centering
%	\subfigure[raw fMRI]{
%		\centering
%		\includegraphics[width=0.45\linewidth]{trend.pdf}}
%	\subfigure[de-trend fMRI]{
%		\centering
%		\includegraphics[width=0.45\linewidth]{detrend.pdf}}
%	\centering
%	\caption{The original fMRI data of left inferior parietal region and the de-trend fMRI data.} \label{detrend}
%\end{figure}



%\subsection{Results from fitting the dynamic network response model}
%In our analysis, we focus on the task of social cognition for 843 individuals, with
In the social cognition study, there are 374 males and 469 females, aged between 22 and 36 years old. In addition, social covariates, such as companionship, social support, perceived hostility and rejection scores, are also collected for each subject. 
Our preliminary analysis finds that there are correlations between the covariates, ranging between 0.4 and 0.6.
%\zc{how large are these correlations? \my{about 0.4-0.6}}. 
Correspondingly, we choose to include the self-reported perceived hostility score (e.g., how often people argue with me, yell at me, or criticize me) in our analysis. %, and this measure is reported by the participants themselves. 
A higher perceived hostility shows increased social distress, which is the extent to which an individual perceives his/her daily social interactions as negative or distressing \citep{lieberman2007social}. 

The goal of our analysis is to characterize the baseline brain connectivity in tasks, to ascertain how social covariates modulate the subject-level connectivity changes and to examine whether there are any sex-specific differences. We apply our proposed model to the dynamic connectivity networks from males and females, respectively. The social covariate is standardized to have mean zero and variance one, and we consider B-spline basis with $K=10$ equally spaced knots. Using the eBIC function, the rank was selected as $R=7$ and the sparsity proportion as $s_0=0.12$ for males, and $R=9$ and $s_0=0.19$ for females. 


%The range of perceived hostility score is from 33.6 to 85.6, which represents an aspect of social distress, the higher the the more stressful. Social distress is a concept within the social relationships subdomain of emotion and the extent to which an individual perceives his/her daily social interactions as negative or distressing \citep{gomez2012hormone,lieberman2007social}.
%, which has been investigated in many studies \citep{gomez2012hormone,lieberman2007social}. 


%We apply our proposed model to this tfMRI data separately for males and females with a logit link function, use the B-spline basis with $K=10$, and scale the covariate to have unit standard error. The rank is selected as $R = 7$ and the sparsity proportion as $s_0=0.12$ based on eBIC for males, and $R = 9$ and $s_0=0.19$ for females.


\begin{table}[!t]
	\caption{The anatomic regions of interest in the identified communities.}
	\label{community}
	\centering
	\begin{tabular}{|l|p{12cm}|}
		\hline
		1&Caudalanteriorcingulate, isthmuscingulate, paracentral, posteriorcingulate, transversetemporal, insula \\
	\hline
	2&  Cuneus, lingual, pericalcarine, postcentral, precentral, precuneus, rostralmiddlefrontal, superiorfrontal, supramarginal\\
	\hline
	3& Entorhinal, parahippocampal, temporalpole \\
	\hline
	4&Bankssts, caudalmiddlefrontal, fusiform, inferiorparietal, inferiortemporal, lateraloccipital, middletemporal, parsopercularis, parstriangularis, superiorparietal, superiortemporal\\
	\hline
	5&Lateralorbitofrontal, medialorbitofrontal, parsorbitalis, rostralanteriorcingulate, frontalpole\\
			\hline
	\end{tabular}
\end{table}



\begin{figure}[t!]
	\centering
	\subfigure[male]{
		\centering
		\includegraphics[width=0.35\linewidth]{male_alpha.pdf}}
	\subfigure[female]{
		\centering
		\includegraphics[width=0.35\linewidth]{female_alpha.pdf}}
	\centering
	\caption{Heatmaps of the $68 \times 68$ matrix
$g^{-1}(\sum_{t=1}^T\hat{\mathcal{B}}_0\times_3 {\boldsymbol \phi}(t))$ with rows and columns ordered according to the $K$-means clustering result. Left and right hemispheres are marked in the plot. The red dashed lines mark the boundaries of the identified groups. Left and right panels are for male and female, respectively.} \label{alpha1}
\end{figure}



\smallskip\noindent
\textbf{Baseline brain connectivity.} We start by examining the estimated baseline connectivity coefficient $\hat{\mathcal B}_0$. %According to our knowledge, it is crucial to study the communities in the brain's structural connection networks. 
Figure \ref{alpha1} plots the baseline connectivity averaged over time, i.e., $g^{-1}(\sum_{h=1}^T\mathcal{\hat B}_0\times_3 {\boldsymbol \phi}(t_h)$), where $g(\cdot)$ is the logit link function and nodes are organized by results from a K-means clustering. 
Specifically, we apply $K$-means clustering based on SVD of the average connectivity matrix $\sum_{h=1}^T\mathcal{\hat B}_0\times_3 {\boldsymbol \phi}(t_h)$ for male, and identify five clusters among the 68 ROIs. The members of each cluster are given in Table \ref{community}. 
While clustering results using $\mathcal{B}_0$ estimated for females are similar, we use the same clustering labels to facilitate comparisons.
%number of clusters are selected based on the elbow plot, 
%\zc{Did you do K-means for males and females separately? \my{yes} Do they have the same results? \my{They do not have the same results, and I choose the results for males to represent, since we should choose the same cluster to compare and I think this cluster is reasonable. If this cluster is not suitable enough and needs the other cluster result to present, I will try. }}
Anatomically, the first community contains mostly nodes in the cingulate gyrus, the second and fifth communities contain nodes from the frontal lobe, the third community contains nodes from the temporal lobe, and the fourth community contains nodes from the frontal, parietal, occipital and temporal lobes (see Tables \ref{community} and \ref{68region}). 
Many of the 68 anatomic ROIs in the Desikan Atlas overlap with the resting-state functional modules. 
%We learn more about the probable roles for these five communities by examining such overlaps. 
We find that community 1 is associated with emotion formation and processing, community 2 is related to visual, attention, and emotion regulation modules, and community 4 is enriched with visual and object identification. 
The lateral occipital gyrus in community 4, lingual gyrus in community 2, and pericalcarine gyrus in community 2 are from the occipital lobe, a region responsible for interpreting the visual world \citep{goldenberg1991contributions}, and is seen to be active for both males and females.
%Moreover, community 5 is related to the attention and default mode, while the size of community 3 is relatively small and its functions are yet to be identified. 
%Figure \ref{alpha1} shows the heatmaps of the $g^{-1}(\sum_{t=1}^T\hat{\mathcal{B}}_0\times_3 {\boldsymbol \phi}(t))$, with the nodes reordered according to the cluster membership. Here the function $g^{-1}(\cdot)$ maps a value from the real line to $[0, 1]$ so to facilitate data visualization. 
For both males and females, we find that connectivity between communities 2 and 4 is more active both within and between the two hemispheres, especially the temporal parietal junction, superior temporal cortex regions, and occipital gyrus, which are all relevant in social cognition. This is in line with previous research which showed that mental animations stimulate these regions \citep{castelli2000movement,barch2013function}. 
Within each hemisphere, males have higher connectivity within communities 2 and 4, 
%which are responsible for attention, e.g., right middle frontal gyrus \citep{japee2015role}, 
and this is consistent with the existing findings that males have increased intrahemispheric connectivity \citep{ingalhalikar2014sex}. %In addition, the brain of male is more active between hemispheres of group 2. 

\begin{figure}[h!]
	\centering
	\subfigure[male]{
		\centering
		\includegraphics[width=0.35\linewidth]{male_beta_threshold.pdf}}
	\subfigure[female]{
		\centering
		\includegraphics[width=0.35\linewidth]{female_beta_threshold.pdf}}
	\centering
	\caption{Heatmaps of $\hat{\mathcal{B}}_{1\cdot\cdot1}$ with rows and columns ordered according to the $K$-means clustering result. Left and right hemispheres are marked in the plot. The red dashed lines mark the boundaries of the identified communities within hemispheres, the black dashed lines mark the intrahemispheric connectivity between communities 2 and 4, and the blue dashed lines mark the interhemispheric connecitivity between communities 2 and 4.} \label{beta_heat}
\end{figure}



\smallskip\noindent
\textbf{Social effects on brain connectivity and sex differences.} We next examine the estimated covariate effect coefficient $\hat{\mathcal{B}}_1$. 
Figure \ref{beta_heat} plots the heatmap of estimates for males and females, where we show $\hat{\mathcal{B}}_{1\cdot\cdot1}$, the first frontal slice of $\hat{\mathcal{B}}_1$, representing the covariate effect on brain connectivity during a mental video. The values are thresholded at $\pm 0.1$ to facilitate presentation. A different view based on anatomical structure can be found in Figure \ref{beta1}.
%Without losing the essential information, we choose the first frontal slice and construct the brain network using the threshold $\pm 0.1$. 
%\zc{Why do we use only the 1st of the 10 spline coefficients? \my{I used to try to show the different positions of the signal.} If the first coefficient is negative, that does not mean all the rest are negative. We cannot really say increased or decreased connectivity just based on the first coefficient. The same question applies to Figure 5. 
%\my{Do you mean Figure \ref{DEdgeReg}? Figure \ref{beta1_trend} plots the $\mathcal{B}_1 \times_3 {\boldsymbol \phi}(t_h)$ when $h=12,17,22$.}\zc{Yes, I mean figure 8.}
%\zc{Have we considered plotting $\sum_{h=1}^T\mathcal{\hat B}_1\times_3 {\boldsymbol \phi}(t_h)$?\my{Yes, Figure \ref{beta_phi} plots the $\sum_{h=1}^T\mathcal{\hat B}_1\times_3 {\boldsymbol \phi}(t_h)/T$ without thresholding. Keep this? }}
%\zc{Also why do we need to use a threshold at 0.1? I thought $\mathcal{B}_1$ is already sparse. \my{I use a threshold for $\mathcal{B}_1$ at 0.1 since without thresholding it will look very messy and some of them may be false signals as in Figure \ref{diff}.}}
%\zc{I feel Fig5 that shows the averaged time varying coefficient is what we should present, as opposed to only the first coefficient. I am a little concerned that there does not seem to be much difference between males and females in Fig 5, likely even after thresholding.\my{Yes, there is little difference between males and females in Fig 5, even after thresholding. If we only want to show the different positions of males and females, and do not concern about the negative or positive, maybe Figure \ref{beta_heat} is enough?}}


%\begin{figure}[h!]
%	\centering
%	\subfigure[male]{
%		\centering
%		\includegraphics[width=0.35\linewidth]{mean_B1_phi_male.pdf}}
%	\subfigure[female]{
%		\centering
%		\includegraphics[width=0.35\linewidth]{mean_B1_phi_female.pdf}}
%	\centering
%	\caption{Heatmaps of the $\sum_{h=1}^T\mathcal{\hat B}_1\times_3 {\boldsymbol \phi}(t_h)/T$ with rows and columns ordered  according to the $K$-means clustering result. Left and right hemispheres are marked in the plot. The red dashed lines mark the boundaries of the identified communities within hemispheres, the black dashed lines mark the boundaries of the graphs between communities 2 and 4 within hemispheres, and the blue dashed lines mark the boundaries of the graphs between communities 2 and 4  between hemispheres.} \label{beta_phi}
%\end{figure}









\begin{figure}[t!]
	\centering
	\subfigure[mental video (male)]{
		\centering
		\includegraphics[width=0.3\linewidth]{male_t=12.pdf}}
	\subfigure[rest (male)]{
		\centering
		\includegraphics[width=0.3\linewidth]{male_T=17.pdf}}
	\centering
		\subfigure[random video (male)]{
		\centering
		\includegraphics[width=0.3\linewidth]{male_t=22.pdf}}
		\subfigure[mental video (female)]{
		\centering
		\includegraphics[width=0.3\linewidth]{female_t=12.pdf}}
	\subfigure[rest (female)]{
		\centering
		\includegraphics[width=0.3\linewidth]{female_t=17.pdf}}
	\centering
		\subfigure[random video (female)]{
		\centering
		\includegraphics[width=0.3\linewidth]{female_t=22.pdf}}
	\caption{Dynamic covariate effect on brain networks. The top panel plots $\hat{\mathcal{B}}_1 \times_3 {\boldsymbol \phi}(t_h)$, $h=12,17,22$, for males, and the bottom pnale plots $\hat{\mathcal{B}}_1 \times_3 {\boldsymbol \phi}(t_h)$, $h=12,17,22$, for females.} \label{beta1_trend}
\end{figure}


It is seen that the social effects on connectivity show different patterns in males and females. 
Specifically, the estimated $\hat{\mathcal{B}}_1$ has sparsity portions equal to 0.19 and 0.12 for females and males, respectively. 
%\my{Dr. Zhao: is there an easy way to see the difference between 0.19 and 0.12 is statistically significant? \my{Maybe we can add the permutation results for the sparsity? but the sparsity results from the  permutation could not see this statistically significance, since the average sparsity for males is 0.2431, and 0.2892 for females, and the variation is large. So, I have no better idea about this.}}\zc{let's not worry about this}
Hence, the social effect on connectivity is more sparse in males, and such differences are observed in within- and between-community connectivity within and across hemispheres.
%This is consistent with the findings that males report significantly lower emotional awareness than females, and males have lower stress reactivity while females have greater reactivity \citep{goldfarb2019sex}. 
Compared to males, the social covariate is seen to more notably decrease the connectivity between communities 2 and 4 within the right hemisphere and also across hemispheres in females, suggesting that the task-related brain connectivity in females is more sensitive to social stress.
This supports existing findings that social stress influences brain connectivity and emotional perception differently for males and females \citep{mather2010sex}.
%This observation agrees with the finding that frontal, parietal, and temporal lobes have significantly higher participation coefficients in females \citep{ingalhalikar2014sex}. 
In general, the perceived hostile social distress covariate has a negative impact on the connection response for females both within and between communities, particularly for community 4, while it tends to have a positive impact on the connection response for males. The above findings on sex-specific difference are interesting, and they may be linked to existing research on sex differences in neural response to psychological stress \citep{wang2007gender}.

%From the description of perceived hostility, people with score high are very sensitive to the reactions of others. Both theoretical and empirical studies have revealed that the stress coping strategies of men and women are qualitatively different \citep{tamres2002sex,taylor2000biobehavioral}. 
%This is consistent with the finding that females often adopt passive coping strategies while males prefer active coping \citep{bale2015sex}, i.e., females with high scores are typically vulnerable groups in real life and sensitive to the reactions of others, so that they are frequently reluctant to be more active in the network connectivity and have difficulty with identifying interactions in task videos. While males with high scores prefer active coping, leading to more active network connectivity.



%females preferentially engage a “tend-and-befriend” response to stressors, whereas males are more likely to express a “fight or flight” response \citep{taylor2000biobehavioral}, and females often adopt passive coping strategies while males prefer active coping \citep{bale2015sex}, i.e., females with high score are usually vulnerable groups in real life and sensitive to the reactions of others, so that they are often reluctant to be more active in the network connectivity and have difficulty identifying with interactions in task videos. While males with high score prefer active coping, leading to more active network connectivity .



%Moreover, females have more activities in the right hemisphere, since more inter hemispheric connectivity in females will facilitate the integration of intuitive information processing in the right hemisphere, \cite{ingalhalikar2014sex} has shown that females outperform males on attention and social cognitive tests. 



 





Finally, Figure \ref{beta1_trend} shows the social effects on brain connectivity in males and females during different periods of the experiments including watching a mental video, resting and watching a random video. 
%An example of the brain networks at different time points is shown in Figure \ref{beta1_trend}, which may be summarized as four main stages of video watching. 
It is seen that during a mental video, the connectivity within- and between- temporal and occipital lobes in females is more affected by social stress. The temporal lobe plays an important role in visual perception and processing emotions, and the occipital lobe is related to visual processing, containing most of the anatomical region of the visual cortex \citep{goldenberg1991contributions}. This finding suggests some interesting patterns that warrant further investigation and validation.

%It starts at the attention which actives some parts of frontal lobe \citep{japee2015role}. Then visual part should be activated when they are watching videos and the occipital lobe is the visual processing center of the mammalian brain containing most of the anatomical region of the visual cortex \citep{streletz1981visual,goldenberg1991contributions}. Next, the shape recognition should be involved and the fusiform gyrus is a large region in the inferior temporal cortex that plays important roles in object and face recognition temporal lobe \citep{schwarzlose2005separate}. At last, the participants should judge based on their interpretation and the corresponding parietal lobe is concerned with integrating sensory input, primarily with the visual system \citep{lynch1977parietal,johnson1996cortical}.
%\zc{Maoyu, could you try just estimate one network all over 274 observations (no dynamic) and apply GLSNet (from the JCGS paper)? Hopefully the results are not very good.\my{Sure, I will try, only real data? or both simulation and real data?} \zc{Just real data is fine. Maybe you can also try the elementwise approach in real data.}\my{OK, please see the following.}}



\subsection{A permutation based procedure to examine sex differences}\label{sec:per}
Developing the asymptotic distribution of the estimated $\mathcal{B}_1$ under the CP low-rank and sparsity constraints in our model is challenging. In this section, we conduct an ad-hoc permutation based procedure to examine whether the previously identified sex-specific differences are meaningful. 
%It is important to assess also the significance of  the estimated subject covariate effect coefficients $\hat{\mathcal{B}}_1$ of males and females induced by the current group. %If a random group can produce similar results to the current partition, we cannot fully confident of the findings in the current results. To check statistical significance, permutation inference is an important tool \citep{gagnon2019classification}.
\begin{comment}
\begin{figure}[!t]
		\centering
	\subfigure[true]{
		\centering
		\includegraphics[width=0.4\linewidth]{union_beta_true.pdf}}
			\centering
	\subfigure[permute]{
		\centering
		\includegraphics[width=0.4\linewidth]{union_beta_permute.pdf}}
			\centering
	\caption{Position differences for $\mathcal{B}_{1\cdot \cdot1}$ (a) based on the true gender group, (b) the permutation group. Red is the position where the two sets overlap, black is the position where the two sets differ.} \label{trend2}
\end{figure}
\end{comment}

\begin{figure}[!t]
		\centering
	\subfigure[$\D^{\text{obs}}$]{
		\centering
		\includegraphics[width=0.3\linewidth]{diff_obs.pdf}}
			\centering
	\subfigure[$\D^{\text{per}}$]{
		\centering
		\includegraphics[width=0.3\linewidth]{diff_per.pdf}}
			\centering
			\subfigure[$\bm S$]{
		\centering
		\includegraphics[width=0.3\linewidth]{TPC.pdf}}
	\caption{Heatmaps of matrices $\D^{obs}$, $\D^{\text{per}}$ and $\bm S$.
 %based on (a) the observed gender group and (b) average differences of the 100 permutations (c) the significant positions of $\d^{\text{obs}}$.
 }\label{diff}
\end{figure}


Specifically, we randomly permute the sex labels across subjects 100 times. In each permutation $i$, we divide the $N=843$ samples into two groups based on the permuted sex labels, 
 %, keeping the sample size of the two groups as 374 and 469, respectively. 
and apply the proposed model to the male and female groups, respectively.
We denote the coefficient tensors as $\mathcal{B}_0^{\text{male},i}$ (or $\mathcal{B}_0^{\text{female},i}$) and $\mathcal{B}_1^{\text{male},i}$ (or $\mathcal{B}_1^{\text{female},i}$) in permutation $i$, $i\in[100]$. 
%Also, we denote the coefficient tensors induced by the observed groups as $\mathcal{B}_0^{\text{male/female}}$ and $\mathcal{B}_1^{\text{male/female}}$. 
%Here, we focus on the difference between $\mathcal{B}_1$'s induced by the observed and permuted groups. 
To quantify the difference in $\mathcal{B}_1$ between males and females, we calculate the $\ell_2$ distance between the coefficient vectors for each $(j,j')$. 
%Then, for the observed gender groups and the $i$-th permuted groups, we have
Specifically, we write
\begin{equation}\label{l2dis}
\D^{obs}_{jj'}=\|\mathcal{B}^{\rm male}_{1jj'\cdot}-\mathcal{B}^{\rm female}_{1jj'\cdot}\|_2 \quad \text{and}\quad  \D^{\text{per,i}}_{jj'}=\|\mathcal{B}^{\text{ male},i}_{1jj'\cdot}-\mathcal{B}^{\text{ female},i}_{1jj'\cdot}\|_2, 
\quad j,j'\in[n],
\end{equation}
where $\mathcal{B}^{\rm male}_1, \mathcal{B}^{\rm female}_1$ are estimated based on the observed data, and 
$\mathcal{B}_1^{\text{male},i}, \mathcal{B}_1^{\text{female},i}$ are estimated based on data with the permuted sex labels. 
%Finally, we define $\D^{\text{per}}$ as $\D^{\text{per}}=\sum_{i=1}^{100}\D ^{\text{per},i}/100$.
Figures \ref{diff} (a)-(b) show the heatmaps of $\D^{obs}$ and $\D^{\text{per}}=\sum_{i=1}^{100}\D^{\text{per,i}}/100$, respectively. 
%which indicates that there are indeed significant gender differences in the effects of covariates on brain connectivity activity. 
We define a binary matrix $\bm S\in\mathbb{R}^{n\times n}$ 
%\my{$\bm S$ has been defined in the simulation part of TPR and FPR.} as
$$
\bm S_{jj'}=1\left(\sum_{i=1}^{100}1(\D^{\text{obs}}_{jj'}>\D^{\text{per},i}_{jj'})\ge 95\right),
%\|\mathcal{B}^{\text{ male},i}_{1jj'\cdot}-\mathcal{B}^{\text{ female},i}_{1jj'\cdot}\|_2)>50*0.95
$$
where $1(\cdot)$ is the indicator function. 
Correspondingly, $\bm S_{jj'}=1$ if the observed sex difference is the same as or greater than the 95th percentile of permuted sex difference. Figure \ref{diff} (c) plots $\bm S$, which further illustrates that the sex differences within community 4 and between communities 2 and 4 are likely significant (regions in the blue and black dashed lines), affirming the findings in Figure \ref{beta_heat}. 
We also consider comparing results based on subgraphs of interests, shown in Figure \ref{boxplot}, where sex-specific differences from observed data are consistently greater than those from permuted data. 




\begin{comment}
\begin{figure}[!t]
  \centering
	\subfigure[male]{
		\centering
		\includegraphics[width=0.3\linewidth]{EW0_male.pdf}}
	\subfigure[female]{
		\centering
		\includegraphics[width=0.3\linewidth]{EW0_female.pdf}}
	\caption{Heatmaps of $\sum_{h=1}^T\mathcal{\hat B}_1\times_3 {\boldsymbol \phi}(t_h)/T$ estimated by DEdgeReg, with rows and columns ordered the same as Figure 4. \my{Without thresholding.} \zc{This looks a bit odd. What happened to all the within community activity? They all seem to be zero.} 
\my{After computing $\sum_{h=1}^T\mathcal{\hat B}_1\times_3 {\boldsymbol \phi}(t_h)/T$, the value within community is very small; Figure \ref{DEdgeReg_B} plots the first frontal slice of $\hat{\mathcal{B}}_1$ estimated by DEdgeReg without thresholding, i.e., the original value of Figure \ref{DEdgeReg}, maybe we can keep Figure \ref{DEdgeReg_B}?} }\label{DEdgeReg_phi}
\end{figure}
\end{comment}




\subsection{Results using existing methods}
We evaluate the performance of two alternative methods including an elementwise method DEdgeReg, evaluated in Section \ref{sec:3}, and GLSNet \citep{zhang2022generalized}, a non time-varying matrix response regression model. Since GLSNet is not designed to model dynamic networks, we directly calculate the connectivity matrix based on all $263$ scans using the same procedure that binarizes the Pearson correlation matrix. Using GLSNet and the recommended eBIC function in \cite{zhang2022generalized}, the rank is selected as $R = 5$ and the sparsity proportion as $s_0 = 0.025$ for males, and $R=13$ and $s_0 = 0.0359$ for females. 

%Since GLSNet method can not handle the multiple-subject dynamic networks, we directly calculate the thresholded correlation for the de-trended fMRI of 263*68, and set the threshold as $\pm 0.5$ to convert the 68*68 correlation matrix into a binary dynamic network for each subject. 

\begin{figure}[!t]
	\centering
	\subfigure[male (w/o thresholding)]{
		\centering
		\includegraphics[width=0.3\linewidth]{EW0_Male_B1.pdf}}
	\subfigure[female (w/o thresholding)]{
		\centering
		\includegraphics[width=0.3\linewidth]{EW0_female_B1.pdf}}\\
  \subfigure[male (w/ thresholding)]{
		\centering
		\includegraphics[width=0.3\linewidth]{B1_EW0_male_0.1.pdf}}
	\subfigure[female (w/ thresholding)]{
		\centering
		\includegraphics[width=0.3\linewidth]{B1_EW0_female_0.1.pdf}}
	\caption{Heatmaps of $\hat{\mathcal{B}}_{1\cdot\cdot1}$ estimated by DEdgeReg, with rows and columns ordered the same as Figure 4. The top and bottom panels show the results without and with thresholding, respectively.} \label{DEdgeReg}
\end{figure}



\begin{figure}[!t]
	\centering
	\subfigure[male]{
		\centering
		\includegraphics[width=0.3\linewidth]{B1_GLSNet_male.pdf}}
	\subfigure[female]{
		\centering
		\includegraphics[width=0.3\linewidth]{B1_GLSNet_female.pdf}}
	\caption{Heatmaps of $\hat{{\B}}_1$ estimated by GLSNet, with rows and columns ordered the same as Figure 4. } \label{GLSNet}
\end{figure}



Figure \ref{DEdgeReg} shows $\hat{\mathcal{B}}_{1\cdot\cdot1}$ (representing the effect during a mental block) estimated by DEdgeReg with or without threshlding at $\pm 0.1$. 
%Without losing the essential information, we choose the first frontal slice and construct the brain network using the threshold $\pm 0.1$. 
%\zc{I have the same question as before on using only the first spline coefficient \my{Since the $\hat{\mathcal{B}}_1$ estimated by DEdgeReg is very dense if I do not use a threshold of 0.1, as in Figure \ref{DEdgeReg_phi}. Figure \ref{DEdgeReg_phi} plots $\sum_{h=1}^T\mathcal{\hat B}_1\times_3 {\boldsymbol \phi}(t_h)/T$.}}
%Obviously, DEdgeReg does not capture the relationship information between brain connectivity and the social cognitive covariate for both males and females. 
It is seen that the estimates from the elementwise method DEdgeReg are very noisy and they identify a large number of regions with relatively small signals. 
The estimated social score effect coefficients $\hat{{\B}}_{1}$ from GLSNet 
are shown in Figure \ref{GLSNet}. %\my{Figure \ref{GLSNet} shows $\hat{{\B}}_{1}$ without thresholding. }. 
%Finding helpful signals is especially challenging in males using GLSNet, non-sparse entries are disorganizedly distributed, 
For both males and females, the estimates are highly sparse.
In males, several areas associated with social cognition, such as the temporal parietal junction, superior temporal cortical regions, and occipital gyrus, do not appear to be engaged. This can potentially due to the fact that GLNet ignores the dynamic changes of brain connectivity during the experiments.
%For females, the inferior parietal and superior temporal regions of community 4 are just two examples of the few relationships between brain connectivity and social cognition that have been discovered. However, these findings are insufficient to investigate how social cognition affects brain activity and the gender gap. 
%Notably, GLSNet is unable to capture the dynamic trends in brain activity that emerge as the task progresses, which is a problem worth investigating. 




\begin{comment}
\begin{table}[!b] 
  \renewcommand\arraystretch{1.5}
  \centering  
  \caption{Average $L_2$ distances of the $\mathcal{B}_1$ based on true gender groups and permuted groups across the 7 GOIs.
  \textcolor{red}{[Can you add standard errors for $\bar{d}^{\text{per}}$? Here, I first calculate the average $\d^{\text{per}}$, and then calculate the $\bar{d}^{\text{per}}$ using $\d^{\text{per}}$ (only one value), thus I counld not give the standard errors of $\bar{d}^{\text{per}}$, but I can give the standard error matrix of $\d^{\text{per}}$. In fact, I try to calculate $\d^{\text{per},i}_{jj'}={\|\mathcal{B}^{\text{ male},i}_{1jj'\cdot}-\mathcal{B}^{\text{ female},i}_{1jj'\cdot}\|_2}$, and get the $\bar{d}^{\text{per},i}=\frac{\sum_{jj' \in S}\d^{\text{per},i}_{jj'}}{\sum_{jj' \in S}1(\d^{\text{per},i}_{jj'}>0)}$ each time, and then average them, where I present the mean and standard errors in Table 4. We could delete Tabel 3 and keep Table 4 or Figure \ref{boxplot} or Figure \ref{boxplot1}.]  }} 
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
  	%\toprule
  	%\vspace{0.5em}\hline
  	%window& 1  & 2  & 3&4&5&6 \\
  	\hline
  	  & GOI 1 & GOI 2 & GOI 3 & GOI 4& GOI 5 &GOI 6&GOI 7 \\
  	\hline
  	 $\bar{d}^{\text{obs}}$ & 0.231 & 0.248 & 0.190 & 0.283 & 0.291& 0.226& 0.208\\
  	\hline
  	$\bar{d}^{\text{per}}$ & 0.079 & 0.126& 0.115& 0.127& 0.135& 0.077&0.095 \\
  	\hline
  \end{tabular}
  \label{tab:dis}
\end{table}


\begin{table}[!b] 
  \renewcommand\arraystretch{1.5}
  \centering  
  \caption{Average $L_2$ distances of the $\mathcal{B}_1$ based on true gender groups and permuted groups across the 7 GOIs.} 
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
  	%\toprule
  	%\vspace{0.5em}\hline
  	%window& 1  & 2  & 3&4&5&6 \\
  	\hline
  	  & GOI 1 & GOI 2 & GOI 3 & GOI 4& GOI 5 &GOI 6&GOI 7 \\
  	\hline
  	 $\bar{d}^{\text{obs}}$ & 0.231 & 0.248 & 0.190 & 0.283 & 0.291& 0.226& 0.208\\
  	 \hline
  	 \multirow{2}{*}{$\bar{d}^{\text{per}}$} & 0.185 & 0.161 &  0.158&  0.200& 0.223& 0.182& 0.183 \\
  	 & (0.018) & (0.018)& (0.021) & (0.031) &(0.032) &(0.026) & (0.022)\\
  	\hline
  \end{tabular}
  \label{tab:dis2}
\end{table}

\end{comment}




\section{Discussion}\label{sec:dis}
In this paper, we study the task-evoked brain connectivity by introducing a new semi-parametric dynamic network response regression that relates a dynamic brain connectivity network to a vector of subject-level covariates.  A key advantage of our method is to exploit the structure of dynamic
imaging coefficients in the form of high-order tensors. 
We briefly comment on potential future research. In our model setup, we assume that the tensor coefficients $\B_1,\ldots,\B_p$ are sparse. More complex structures such as the low-rank or fused structures can be considered as well, though they will increase the computation time and complexity in tuning. In Section \ref{sec:per}, we consider an ad-hoc permutation procedure to evaluate the identified sex-specific differences. A more rigorous approach would be to derive the asymptotic distribution of $\mathcal{B}_1$ and carry out hypothesis testing. This is not a trivial task due to the involvement of both low-rank and sparse constraints on the model parameters. We leave this investigation to future research. 



\bibliographystyle{asa}
\bibliography{main.bbl}


\newpage
\renewcommand{\thesection}{S\arabic{section}}
\renewcommand{\theequation}{S\arabic{equation}}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\setcounter{section}{0}
\setcounter{equation}{0}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{page}{1}


\begin{center}
{\large\bf Supplementary Materials for ``Learning Brain Connectivity in Social Cognition with Dynamic Network Regression"} \\
\bigskip
\end{center}




\section{Gradients}\label{sec:gr}
We present the analytical forms of the gradients in Algorithm 1:
$$
\begin{aligned}
\ell(\mathcal{B}_0,\ldots,\mathcal{B}_p)&=-\frac{1}{N}\sum^N_{i=1}\sum^n_{j\neq j'}\sum^T_{h=1}\Big[\A^{(i)}_{jj'}(t_h)\bfeta^{(i)}_{jj'}(t_h)-\psi\left\{\bfeta^{(i)}_{jj'}(t_h)\right\}\Big]\\
&=-\frac{1}{N}\sum^N_{i=1}\sum^n_{j\neq j'}\sum^T_{h=1}\Big[\A^{(i)}(t_h)*\left\{\mathcal{B}_0\times_3 {\boldsymbol \phi}(t)+\sum_{l=1}^p x_{il}(\mathcal{B}_l\times_3 {\boldsymbol \phi}(t))\right\}\\
&-\log\left(1+\exp\left\{\mathcal{B}_0\times_3 {\boldsymbol \phi}(t)+\sum_{l=1}^p x_{il}(\mathcal{B}_l\times_3 {\boldsymbol \phi}(t))\right\}\right)\Big],\\
\end{aligned}
$$


$$
\frac{\partial l}{\partial u_{1r}}=-\frac{1}{N}\sum_{i=1}^N\sum_{t=1}^T\left(A^{(i)}(t)-{\boldsymbol \psi}'\left(\mathcal{B}_0\times_3{\boldsymbol \phi}(t)+\sum_{l=1}^px_{il}\mathcal{B}_l\times_3{\boldsymbol \phi}(t)\right)\right)\left(w_ru_{1r}{\boldsymbol \phi}^T(t)u_{3r}\right),
$$

$$
\frac{\partial l}{\partial u_{3r}}=-\frac{1}{N}\sum_{i=1}^N\sum_{t=1}^T\left(A^{(i)}(t)-{\boldsymbol \psi}'\left(\mathcal{B}_0\times_3{\boldsymbol \phi}(t)+\sum_{l=1}^px_{il}\mathcal{B}_l\times_3{\boldsymbol \phi}(t)\right)\right)\left(w_ru_{1r}{\boldsymbol \phi}^T(t)u_{1r}\right),
$$

$$
\frac{\partial l}{\partial\mathcal{B}_l }=-\frac{1}{N}\sum_{i=1}^N\sum_{t=1}^T\left\{A^{(i)}(t)\circ\left(x_{il}{\boldsymbol \phi}(t)\right)-{\boldsymbol \psi}'\left(\mathcal{B}_0\times_3{\boldsymbol \phi}(t)+\sum_{l=1}^px_{il}\mathcal{B}_l\times_3{\boldsymbol \phi}(t)\right)\circ\left(x_{il}{\boldsymbol \phi}(t)\right)\right\},
$$
where ${\boldsymbol \psi}'(x)=1-1/(1+\exp(x))$.



\section{Additional results from real data analysis}
%Figure \ref{trend} shows dynamic trends of some important regions in $\mathcal{B}_0$ and $\mathcal{B}_1$ within $t=5,\cdots ,43$, respectively, since some objective or environmental circumstances cause the estimation of boundary to be oscillatory. Specially, all elements of $\mathcal{B}_0$ have similar dynamic trends as shown in the first row of Figure \ref{trend}. Besides the boundary part, there are two clear valleys and peaks which correspond to 2 mental and random video clips respectively. This indicates that the brain of participants are more active when watching mental video clips. Notably, the dynamic trends of some important regions in $\mathcal{B}_1$ have significant differences between males and females. Between right inferior and superior temporal gyrus, females show a similar trend as that for $\mathcal{B}_0$ with two peaks and valleys, while this similarity does not appear for males, which is consistent with that females have more activities in the right hemisphere as shown in Figure \ref{beta1} (f). Since the results in \cite{goldfarb2019sex} have shown there are more significant signals during the stress in lateral occipital cortex, we also plot the dynamic trend between left and right lateral occipital gyrus. 
%\my{[I could not find the related paper and not sure about this analysis.] We find that females have a more smooth trend than males do, which indicates that females may always be more active between the left and right lateral occipital gyrus.}


\begin{comment}
\begin{figure}[t!]
	\centering
	\subfigure[male $\mathcal{B}_0$]{
		\centering
		\includegraphics[width=0.22\linewidth]{42-63_alpha_male.pdf}}
	\subfigure[female $\mathcal{B}_0$]{
		\centering
		\includegraphics[width=0.22\linewidth]{42-63_alpha_female.pdf}}
			\centering
	\subfigure[male $\mathcal{B}_0$]{
		\centering
		\includegraphics[width=0.22\linewidth]{10-44_alpha_male.pdf}}
	\subfigure[female $\mathcal{B}_0$]{
		\centering
		\includegraphics[width=0.22\linewidth]{10-44_alpha_female.pdf}}
	\centering
		\subfigure[male $\mathcal{B}_1$]{
		\centering
		\includegraphics[width=0.22\linewidth]{42-63_beta_male.pdf}}
		\centering
		\subfigure[female $\mathcal{B}_1$]{
		\centering
		\includegraphics[width=0.22\linewidth]{42-63_beta_female.pdf}}
		\centering
		\subfigure[male $\mathcal{B}_1$]{
		\centering
		\includegraphics[width=0.22\linewidth]{10-44_beta_male.pdf}}
		\centering
		\subfigure[female $\mathcal{B}_1$]{
		\centering
		\includegraphics[width=0.22\linewidth]{10-44_beta_female.pdf}}
	\caption{Dynamic change of $\mathcal{B}_0$ and $\mathcal{B}_1$. The first two columns indicate the connection between right inferior temporal and right superior temporal gyrus, and the last two columns indicate the connection between left lateral and right lateral occipitals.} \label{trend}
\end{figure}
\end{comment}



\begin{figure}[t!]
			\centering
		\subfigure[whole]{
		\centering
		\includegraphics[width=0.3\linewidth]{male_beta_brain.pdf}}
			\centering
		\subfigure[left]{
		\centering
		\includegraphics[width=0.31\linewidth]{male_beta_left.pdf}}
			\centering
		\subfigure[right]{
		\centering
		\includegraphics[width=0.31\linewidth]{male_beta_right.pdf}}
	\subfigure[whole]{
		\centering
		\includegraphics[width=0.3\linewidth]{female_beta_brain.pdf}}
	\centering
		\subfigure[left]{
		\centering
		\includegraphics[width=0.31\linewidth]{female_beta_left.pdf}}
			\subfigure[right]{
		\centering
		\includegraphics[width=0.31\linewidth]{female_beta_Right.pdf}}
	\centering
	\caption{Brain network of the first frontal slice of $\hat{\mathcal{B}}_1$ based on the 6 main lobes of human brain. From the top to bottom panel, it is for male and female, respectively. Inter-lobe connections are shown in gray, and intra-lobe connections are shown in the same color as lobes. } \label{beta1}
\end{figure}

Figure \ref{beta1} visualizes the network connections of the human brain in terms of the 6 main lobes, i.e., frontal, parietal, temporal, occipital, insula and cingulate. We discover that females have greater activity in the across-lobe connectivity, particularly among the temporal, parietal, and occipital lobes \citep{ingalhalikar2014sex}, see Figures \ref{beta1} (a) and (d). 
%Additionally, \cite{ingalhalikar2014sex} have indicated that females outperform males on attention and social cognitive tests. This is likely due to the fact that females engage in more activities in the right hemisphere as shown in Figures \ref{beta1} (c) and (f), which could enhance the integration of intuitive information processing.





In the permutation procedure, we also define $L_2$ distances for graphs of interest (GOIs). Given a set of nodes $V_0$ as 
$$\bar{d}_{V_0}=\frac{\sum_{jj' \in V_0}\D_{jj'}}{\sum_{jj' \in V_0}1(\D_{jj'}>0)},$$
where $\D$ refers to the distance $\D^{\text{obs}}$ or $\D^{\text{per},i}$. We calculate $\bar{d}_{V_0}$ based on 7 GOIs, defined as
\begin{itemize}
    \item[] GOI 1: the entire brain
    \item[] GOI 2: community 4 within the right hemisphere
    \item[] GOI 3: community 4 within the left hemisphere
    \item[] GOI 4: community 2 within the right hemisphere
    \item[] GOI 5: community 2 within the left hemisphere
    \item[] GOI 6: between community 2, right hemisphere and community 4, left hemisphere
    \item[] GOI 7: between community 2, left hemisphere and community 4, right hemisphere.
\end{itemize}
%where GOIs 1 to 7 refer to the entire region, the community 4 (identified in Table \ref{community}) within the right hemispheres, the community 4 within the left hemispheres, the community 2 within the right hemisphere, the community 2 within the left hemisphere, the region between the community 2 in the right hemisphere and the community 4 in the left hemisphere, and the region between community 2 in left hemisphere and community 4 in right hemisphere, respectively. 
Figure \ref{boxplot} compares the $\bar{d}_{V_0}$'s calculated from the observed data and the permuted data across the above 7 GOIs. %where $\bar{d}^{\text{obs}}$ and $\bar{d}^{\text{per}}$ are calculated based on the observed gender groups and the permuted groups. 
It is seen that the sex-specific differences from the observed data are consistently greater than those from permuted data. 
%The gender differences of the coefficient $\mathcal{B}_1$ induced by the observed gender groups are significant in all the 7 regions, which again validate that our findings are meaningful and reliable. 

\begin{figure}[!t]
		\centering
		\includegraphics[width=0.7\linewidth]{boxplot.pdf}
			\centering
	\caption{The plots of $\bar{d}_{V_0}$ across 7 GOIs. Results from the permuted data are shown in black dots (with standard error bars) and the results from the observed data are shown in red triangles. 
	} \label{boxplot}
\end{figure}


\section{The ROIs in the Desikan-Killiany atlas}
%\cb{This could be written into one table. For example, it can introduce these regions by 6 brain zones in Figure 7.}
\begin{table}[t!]
	\caption{The 68 ROIs in the Desikan-Killiany atlas organized into 6 brain lobes: Temporal, Frontal, Occipital, Parietal, Cingulate, and Insula.}
	\label{68region}
	\centering
 
	\begin{tabular}{|l|p{12cm}|}
		\hline
		Temporal& 1-Left bankssts,%\zc{Maoyu, add the rest of region id in front of the region names.} 
  5-Left entorhinal, 6-Left fusiform, 8-Left inferior temporal, 14-Left middle temporal, 15-Left parahippocampal, 29-Left superior temporal, 32-Left temporal pole, 33-Left transverse temporal, 35-Right bankssts, 
  39-Right entorhinal, 40-Right fusiform, 42-Right inferior temporal, 48-Right middle temporal, 49-Right parahippocampal, 63-Right superior temporal, 66-Right temporal pole, 67-Right transverse temporal \\ 

	\hline
	Frontal & 3-Left caudal middle frontal, 11-Left lateral orbitofrontal, 13-Left medial orbitofrontal, 16-Left paracentral, 17-Left pars opercularis, 18-Left pars orbitalis, 19-Left pars triangularis, 23-Left precentral, 26-Left rostral middle frontal, 27-Left superior frontal, 31-Left frontalpole, 37-Right caudal middle frontal, 45-Right lateral orbitofrontal, 47-Right medial orbitofrontal, 50-Right paracentral, 51-Right parsopercularis, 52-Right parsorbitalis, 53-Right parstriangularis, 57-Right precentral, 60-Right rostral middle frontal, 61-Right superior frontal, 65-Right frontalpole \\
	\hline
	Occipital& 4-Left cuneus, 10-Left lateral occipital, 12-Left lingual, 20-Left pericalcarine, 38-Right cuneus, 44-Right lateral occipital, 46-Right lingual, 54-Right pericalcarine  \\
	\hline
	Parietal&7-Left inferior parietal, 21-Left postcentral, 24-Left precuneus, 28-Left superior parietal, 30-Left supramarginal, 41-Right inferior parietal, 55-Right postcentral, 58-Right precuneus, 62-Right superior parietal, 64-Right supramarginal \\
	\hline
	Cingulate &2-Left caudal anterior cingulate, 9-Left isthmus cingulate, 22-Left posterior cingulate, 25-Left rostral anterior cingulate, 36-Right caudal anterior cingulate, 43-Right isthmus cingulate, 56-Right posterior cingulate, 59-Right rostral anterior cingulate \\
			\hline
   Insula& 34-Left insula, 68-Right insula \\
   \hline
	\end{tabular}
\end{table}

\end{document}



\begin{comment}
\begin{itemize}
    \item 1 Left bankssts

\item 2 Left caudal anterior cingulate

\item 3 Left caudal middle frontal

\item 4 Left cuneus 

\item 5 Left entorhinal

\item 6 Left fusiform

\item 7 Left inferior parietal 

\item 8 Left inferior temporal 

\item 9 L isthmus cingulate 

\item 10 Left lateral occipital 

\item 11 Left lateral orbitofrontal

\item 12 Left lingual

\item 13 Left medial orbitofrontal 

\item 14 Left middle temporal 

\item 15 Left parahippocampal 

\item 16 Left paracentral 

\item 17 Left pars opercularis 

\item 18 Left pars orbitalis 

\item 19 Left pars triangularis 

\item 20 Left pericalcarine 

\item 21 Left postcentral 

\item 22 Left posterior cingulate 

\item 23 Left precentral 

\item 24 Left precuneus 

\item 25 Left rostral anterior cingulate 

\item 26 Left rostral middle frontal 

\item 27 Left superior frontal 

\item 28 Left superior parietal 

\item 29 Left superior temporal 

\item 30 Left supramarginal 

\item 31 Left frontalpole

\item 32 Left temporal pole 

\item 33 Left transverse temporal 

\item 34 Left insula 

\item 35 Right bankssts 

\item 36 Right caudal anterior cingulate

\item 37 Right caudal middle frontal 

\item 38 Right cuneus

\item 39 Right entorhinal 

\item 40 Right fusiform 

\item 41 Right inferior parietal 

\item 42 Right inferior temporal

\item 43 Right isthmus cingulate 

\item 44 Right lateral occipital 

\item 45 Right lateral orbitofrontal 

\item 46 Right lingual

\item 47 Right medial orbitofrontal

\item 48 Right middle temporal 

\item 49 Right parahippocampal 

\item 50 Right paracentral
 
\item 51 Right parsopercularis

\item 52 Right parsorbitalis

\item 53 Right parstriangularis 

\item 54 Right pericalcarine 

\item 55 Right postcentral 

\item 56 Right posterior cingulate 

\item 57 Right precentral 

\item 58 Right precuneus

\item 59 Right rostral anterior cingulate 

\item 60 Right rostral middle frontal 

\item 61 Right superior frontal

\item 62 Right superior parietal 

\item 63 Right superior temporal 

\item 64 Right supramarginal 

\item 65 Right frontalpole 

\item 66 Right temporalpole 

\item 67 Right transversetemporal 

\item 68 Right insula 

\end{itemize}
\end{comment}


%\end{supplement}








