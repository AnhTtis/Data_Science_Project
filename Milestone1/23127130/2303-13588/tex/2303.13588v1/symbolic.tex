\section{Power of Symbolic Reasoning}\label{sec:power}
In this section, we examine a few tasks beyond the feed-forward network verification. These tasks appear challenging for non-symbolic domains, but can be naturally solved with our framework. We can assign any computational component in the network with a symbol on demand without defining the abstract interpreter a priori. This flexibility contributes to the power of symbolic reasoning.

The major distinguished components of our framework are the symbolic domain and the quadratic relation. The symbolic domain has very flexible semantics. We can assign symbols to any computation component in the network, and define their semantics as needed. In the meantime, the quadratic relation is quite expressive, allowing us to exactly encode the verification problem of interest. We can then use algebraic manipulations and other mathematical tools to precisely analyze those problems. Moreover, using quadratic relations to exactly express the verification problem enables us to ask important theoretical questions about the verification task, which we will discuss in~\cref{sec:theory}. Now we demonstrate the practical benefits with the following examples.

\subsection{Metric Learning}
Metric learning models learn a metric that captures the semantic features. They map inputs into a low-dimensional space on which distance measures the similarity. This model is widely used in face recognition, information retrieval and phishing detection~\cite{phishNet,facenet,Wu_2017_ICCV}. The model structure is essentially the same as the feed-forward except for the final classification layer. Instead of outputting the class with the highest logit score, the model maps the output from the representation layer onto a unit sphere, and outputs the closest anchor's class. 

More formally, let $z$ be the output of the representation layer, and $\bar{z}$ be the normalized $z$, i.e., $\bar{z} = \frac{z}{\norm{z}_2}$. $O = \{o_i\}$ is a set of anchors on the unit sphere (so $\norm{o_i}_2=1$). To predict $x$, the model examines the $\ell_2$-distance between $\bar{z}$ and all the anchors, and outputs the class of the closest anchor.  

\cite{adv-metric} found that metric learning models are also susceptible to adversarial attacks. It appears difficult to verify the metric learning model using non-symbolic domains. Reinterpreting the normalization operation and the $\ell_2$-distance on a unit sphere can be particularly challenging for those domains. However, we demonstrate that with symbolic reasoning, verifying metric learning models is no different from the standard feed-forward model.

Let $o$ be the closest anchor, and $\Tilde{o}$ be another arbitrary anchor. Therefore, we want to minimize $(\bar{z}-\Tilde{o})^2-(\bar{z}-o)^2$ to see if this expression can be negative. With some arithmetical operations:
\[(\bar{z}-\Tilde{o})^2-(\bar{z}-o)^2 = \bar{z}^2+\Tilde{o}^2-\bar{z}^2-o^2+2(o-\Tilde{o})\bar{z}.\]

Because $o^2, \Tilde{o}^2, \bar{z}^2=1$, this is equivalent to minimizing $(o-\Tilde{o})\bar{z}$. Geometrically, this means whether the angle between $\bar{z}$ and $(o-\Tilde{o})$ is greater than $\frac{\pi}{2}$. Therefore, this is equivalent to whether $z$ can be perturbed to the other side of the half-space that is normal to $(o-\Tilde{o})$. 

Equivalently, we only need to minimize $(o-\Tilde{o})z$ to see whether this can be negative. Now assuming the metric learning model has only two layers as in~\cref{eq:2-network}, the quadratic program for metric learning is then:
\begin{align*}
    \min &\;(o-\Tilde{o})z\\ 
    s.t.\;\;\;\;  & z_i(z_i-y_i)\leq 0, \;z_i\geq y_i, \;z_i\geq 0, \;\forall i\in [n] \\
    &y_i = w_i x+b_{1i},\;\forall i\in [n] \\
    &\norm{x-a}_p\leq \epsilon .
\end{align*}

With symbolic reasoning, we can conclude that verifying metric learning models is essentially the same as the standard classification model. We can use a vector $v$ to denote $\Tilde{o}-o$, then the program is the same as in the standard feed-forward model.

\subsection{Deep Equilibrium Models}
Symbolic abstraction is a fundamental reasoning scheme and is used beyond program verification. It can be particularly elegant when reasoning the limiting behavior of recursions. We provide a probability theory example to show this reasoning in~\cref{sec:rec-prob}. We assign the symbol with semantics in the limiting state directly without handling fixed points. Now we demonstrate this reasoning in the verification setting.

We show that we can easily reason about the deep equilibrium (DEQ) model~\cite{deq_model}. DEQs use a single implicit layer to simulate a network with infinite depth. It is based on the observation that very deep models converge towards some fixed point, and the implicit layer solves this fixed point directly. It has been shown that DEQs have competitive performance compared to explicit deep models while consuming much less memory~\cite{multi-deq}.

The DEQ model $f:\R^m\rightarrow \R$ can be described with the following formula:
\[f(x) = vz+b_2, \;z = \act(Wz+Ux+b_1).\]
If we compare the DEQ model with the feed-forward model (see~\cref{eq:2-network}), the difference is that $z$ is also fed back to the input of the hidden layer, i.e., $z$ is a fixed point of the hidden layer equation. The model then uses the affine transformation of this fixed point to make predictions, i.e., $\class(f,x)=\argmax_{i\in[l]}Vz+b$, where $V$ is the weight matrix from the fixed point $z$ to the logit layer, and $b$ is the bias term.

If we assign a non-symbolic domain to capture the semantics of $x$, reasoning $z$ requires finding the fixed point within this domain, which can be very loose. Instead, we can assign symbols to denote the equilibrium behavior directly. We use the FGL estimation (see~\cref{sec:indept}) as an example. 

To derive the QP like~\cref{eq:formal}, the only difference between the DEQ model and the feed-forward DNN is that $\Delta y_i = w_i\Delta z + u_i\Delta z$, where $u_i$ is the $i$-th row of $U$. In other words, an input to the hidden layer ($\Delta y_i$) comes from both the input layer ($w_i\Delta x$) and the output of the hidden layer ($u_i\Delta z$). The rest remains the same. As a result, the QP for the FGL estimation of DEQ is:
\begin{align*}
\begin{split}
  \max &\;v\Delta z \\ 
    s.t.\;\;\;\;  & (\Delta z_i - \Delta y_i)\Delta z_i\leq 0, \;\forall i\in [n] \\
    & \Delta y_i = w_i \Delta x+u_i\Delta z, \;\forall i\in [n]\\
    &\norm{\Delta x}_p\leq 1.
\end{split}  
\end{align*}
%It is easy to see that to certify the robustness of an input for DEQ models, we only need to change~\cref{eq:first-layer} to
%\[
%y_i = w_i x + u_i z+ b_{1i}.
%\]

%\subsection{Transferring $\ell_\infty$-techniques}\label{sec:linf2l2}
%Most of the verification works are focused on the $\ell_\infty$-attacks. One of the reasons is that $\ell_\infty$-attacks are easy to express with linear relations. However, we can adapt some of the techniques designed for $\ell_\infty$-attacks to the $\ell_2$-ones with symbolic reasoning and quadratic relations. 

%For $\ell_\infty$-certification techniques, they often use $l$ and $u$ for each node to denote the lower and upper bounds, and then relate them to over-approximate the NN execution. From symbolic reasoning, we can view $l$ and $u$ as extra symbols, and then quantify them using quadratic relations. This allows us to transfer some of the $\ell_\infty$-techniques to the $\ell_2$-robustness certification. We provide some discussion in~\cref{sec:adapt}.

%For $\ell_infty$ attacks, the verification techniques usually associate two symbols $u$ and $l$ with each node in the network. The semantics of these two variables are each node's upper and lower bounds. Then the NN execution is defined with respect to the lower and upper bounds of each node. As a result, to adapt the $\ell_\infty$-techniques to the $\ell_2$-attacks, we only need to express $\ell_2$-balls with the $u_i$'s and $l_i$'s on the input layer. 

%More formally, suppose we want to express the $\ell_p$-ball centered at $a\in \R^m$ with radius $\epsilon$.

%For $\ell_\infty$-attacks, $u_i$ and $l_i$ can be calculated directly: $u_i=a_i-\epsilon$ and $l_i=a_i-\epsilon$. For $\ell_2$-attacks, if we calculate the concrete values that over-approximate the $\ell_2$-ball, this becomes the $\ell_\infty$-ball and a very loose over-approximation. However, if we view them as symbols rather than concrete values, we can easily express the $\ell_2$-ball and adapt the techniques for $\ell_\infty$-attacks. We provide a more detailed discussion on this in~\cref{sec:adapt}.
