To facilitate training and evaluation of fisheye semantic completion, we derive Cityscapes-BF and KITTI360-BF from the Cityscapes~\cite{cordts2016cityscapes} and KITTI-360~\cite{liao2022kitti} datasets.
To achieve this, we conduct a radial distortion of perspective images via the following equation~\cite{liao2020model}:
\begin{equation}
\begin{split}
    x_d = x_o(1 + k_1r^2_f + k_2r^4_f + k_3r^6_f + k_4r^8_f + ...) \\
    y_d = y_o(1 + k_1r^2_f + k_2r^4_f + k_3r^6_f + k_4r^8_f + ...),
\end{split}
\label{distortion-formula}
\end{equation}
where  $\boldsymbol{P}_o=(x_o,y_o)^T\in\mathbb{R}^{2\times1}$ is a pixel in the original pinhole image and $\boldsymbol{P}_d=(x_d,y_d)^T\in\mathbb{R}^{2\times1}$ is its corresponding pixel in distorted fisheye image. $[ k_1,k_2,k_3,k_4,...]$ are the radial distortion parameters and $r_f$ is the Euclidean distance between the distorted pixel and the distortion center $\boldsymbol{P}_c=(x_c,y_c)^T\in\mathbb{R}^{2\times1}$. 

Following the previous work of FisheyeEX~\cite{liao2022fisheyeex}, we use the same fourth order polynomial model to apply a distortion on original images.
Besides, we acquire a circular mask by applying a mask generator. It masks out a circular region of the ground-truth image, aiming to make our synthesized fisheye image like the natural fisheye images captured via a fisheye camera.
Therefore, our datasets are composed of: complete-FoV fisheye images, complete-FoV fisheye semantic labels, and circular masks.

