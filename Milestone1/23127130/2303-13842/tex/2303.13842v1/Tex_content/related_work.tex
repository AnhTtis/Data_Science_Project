\noindent\textbf{Image outpainting.} 
Image outpainting aims to generate the surrounding regions of the given visual content.
Early parameter-free methods~\cite{wang2014biggerpicture,zhang2013framebreak,shan2014photo} are data-driven and are based on very large image databases or require input reference frames, which retrieve relevant image features to warp and fill in  regions-of-interest.
Sabini~\etal~\cite{sabini2018painting} first present the learning-based image outpainting via GAN~\cite{goodfellow2020generative} to enable outpainting in the horizontal direction.
Subsequently, the SRN work by Wang~\etal~\cite{wang2019wide} proposes generating semantically coherent structures and textures using a context prediction network and a carefully designed loss function.
The framework of Teterwak~\etal\cite{teterwak2019boundless}, leverages semantic information extracted from a pretrained deep network to modulate the discriminator's behavior for image extension. 
Yao~\etal~\cite{yao2022outpainting} implemented a sequence-to-sequence outpainting approach that relies on a transformer-based backbone, where the outpainting proportion and the network structure are bound.
FlowLens~\cite{shi2022flowlens} introduces a temporal clip propagation mechanism to expand the FoV of the pinhole camera outwards and the spherical camera inwards, respectively.
RecRecNet~\cite{liao2023recrecnet} rectangles rectified wide-angle via curriculum learning with increasing degree of freedom.
The work most closely related to ours is presumably FisheyeEX~\cite{liao2022fisheyeex}, which leverages an outpainting method specifically  for elimination of blind areas in fisheye images.

Different from prior works, we focus on \textit{fisheye semantic completion}, that seeks to generate \textit{semantically coherent}  visual content beyond the fisheye FoV by jointly learning the scene semantics and pixel patterns and considering the fisheye polar distributions.
To the best of our knowledge, this is the first work that concurrently addresses the challenges of fisheye semantic segmentation and scene completion.

\noindent\textbf{Beyond-FoV semantic segmentation.}
Early fisheye semantic segmentation methods~\cite{deng2017cnn,saez2018cnn,sekkat2022comparative} generate synthetic fisheye datasets based on existing pinhole semantic segmentation methods.
These techniques employ focal length augmentation to enhance their adaptability to real-world scenarios.
In~\cite{blott2018semantic,ye2020universal}, the degree of freedom in generating synthetic fisheye images is enlarged, transforming rectilinear images to fisheye images in a more comprehensive way and enhancing the generalization on real fisheye images with various perspectives.
In~\cite{ahmad2022fisheyehdk,deng2019restricted,hu2022distortion_convolution,playout2021adaptable_deformable_convolutions}, deformable components in CNNs are investigated to better adapt to wide-angle images.
In~\cite{yang2019can,yang2019pass,yang2020dspass,xu2019semantic_synthetic,orhan2022semantic_outdoor}, the FoV is further expanded to 360{\textdegree} with panoramic or annular images.
In~\cite{yang2021capturing,yang2021context,zhang2022bending,zhang2022behind}, wide-FoV-driven visual attention and distortion-aware transformer models are designed to learn long-range dependencies in panoramic images.
In~\cite{kim2022pasts,yang2020omnisupervised,zheng2023complementary}, knowledge distillation is studied on panoramic images.
In~\cite{jang2022dada,ma2021densepass,kim2022pasts,shi2022unsupervised,zhang2021transfer}, large-FoV semantic segmentation is revisited from a domain adaptation perspective by adapting from label-rich pinhole images to label-scare images such as fisheye images, panoramic images, and images reflected by convex mirrors.
In~\cite{jaus2021panoramic,mei2022waymo,thioune2022fpdm}, semantic segmentation is extended to panoptic segmentation on wide-FoV images with instance predictions.
In~\cite{cheke2022fisheyepixpro,jaus2021panoramic,jaus2023panoramic}, pixel-level contrastive learning is studied for wide-angle segmentation.
In~\cite{arsenali2019rotinvmtl,eising2021near_field_perception,kumar2021syndistnet,kumar2021omnidet}, multi-task learning has been implemented on fisheye images such as object detection, depth estimation, and semantic segmentation.
In contrast to these works, our work tackles fisheye semantic completion, which provides dense semantic information not only for the original wide-angle fisheye images but also beyond the field of view, giving rich semantic understanding of the expanded scene. 