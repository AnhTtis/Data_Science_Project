\section{Implementation} \label{sec:implementation-appendix}

Our theoretical results regarding discrete representation of continuous signals are based on infinite signals, which may seem impractical to real models which work on finite images. However, the results apply in a setting in which we assume that the continuous signals are periodic, and we finitely sample a single period. These assumptions practically limit our discussion to robustness to circular translations, which is the same setting that was considered in previous works \citep{Zhang2019MakingAgain, Chaman2020TrulyNetworks}.
Next, we explain our implementation for the ``ideal LPF'', which was used in BlurPool and phase 3 of \Cref{algo:af-poly}, and for the ``reconstruction filter'', which was used in $\mathrm{Upsample}$ in step 1 of \Cref{algo:af-poly}.
Both of these filters can be implemented using multiplication in the Fourier domain, working with DFT, which is defined for a finite signal with length $N$ as
\begin{equation} \label{eq:dft}
    X^{D}[k] = \mathrm{DFT} \left( x \left[ n \right] \right) \left[ k \right] = \sum_{n=0}^{N-1} x \left[ n \right] e^{-\frac{j 2 \pi}{N}kn } \,.
\end{equation}
Similarly, the inverse of DFT is defined as:
\begin{equation} \label{eq:dft-inv}
    x \left[ n \right]=\mathrm{IDFT} \left( X^D \left[ k \right] \right) \left[ n \right] = \frac{1}{N} \sum_{k=0}^{N-1} X^{D} \left[ k \right] e^{\frac{j 2 \pi}{N}kn } \,.
\end{equation}
For simplicity, all our derivations are for 1-D signals. Our derivations trivially apply to the 2-D case by applying the filters separately on rows and on columns.%, the following operators are presented for 1-D signals. As for being separable in higher dimensions, the proposed filters can be translated to 2-D by 
%\[
%H_{2D} = H H^{T}
%\]
\paragraph{LPF}
\label{par:lpf}
We used a low-pass filter wherever it was necessary to prevent aliasing due to downsampling, namely in BlurPool layers that replace strided convolutions, and alias-free polynomial activations, before subsampling the polynomial results (\cref{algo:af-poly}). We used an ``ideal filter'', i.e.~a filter that eliminates all the frequencies above the cutoff ratio. Practically, this kind of filter can be implemented using multiplication in DFT domain: 
\begin{equation}
    \mathrm{LPF}_{\mathrm{cutoff},c}  \left( x \left[ n \right] \right) \left[ n \right] =   \mathrm{IDFT} \left(\mathrm{DFT} \left(x \left[ n \right] \right) \left[ k \right] H^{D}_{\mathrm{cutoff},c}\left[ k \right] \right) \left[ n \right]\,,
\end{equation}
% where $X^D$ is the DFT of $x \left[ n\right]$ and $H^{2D}$ is a ``rectangle filter'' defined for spatial dimension $N \times N$  and cutoff ratio $c \in \left[ 0,\ 1\right]$ as 
where $H^{D}_{\mathrm{cutoff, c}}$ is a ``rectangle filter'' defined for spatial dimension $N$  and cutoff ratio $c \in \left[ 0,\ 1\right]$ as 

\begin{equation}
% H^{2D} = H H^{T}, 
H^{D}_{\mathrm{cutoff,c}} \left[ k \right]=\begin{cases}
1 & 0\leq k<\frac{N}{2}c\,,\\
0 & \frac{N}{2}c \leq k \leq N - \frac{N}{2}c\,,\\
1 & N - \frac{N}{2}c < k\leq N-1\,.
\end{cases} \,.
\end{equation}

\paragraph{Downsampling}
As mentioned above, all downsampling operations were performed in an alias-free manner, using low-pass filters before subsampling. 
For subsampling at factor $s$, we used LPF with cutoff ratio $c = \frac{1}{s}$.
Then, we used subsampling with a fixed grid:
% \begin{equation}
%     x_{\mathrm{down}} \left[n,\ m \right] = x_{\mathrm{LPF}}[sn,\ sm]
% \end{equation}
\begin{equation}
    x_{\mathrm{down}} \left[n \right] = \mathrm{LPF}_{1/s} \left( x \left[ n \right] \right) \left[ sn \right]
\end{equation}


\paragraph{Upsampling}

In the proof of Algorithm 1, we assume we use ``ideal upsample'', which can be interpreted as a re-sampling in a higher rate of the continuous signal, which was restored using sinc interpolation:
\begin{equation}
    x_{\mathrm{up}_{I}} \left[ m \right] = \sum_{n} x \left[n \right] \mathrm{sinc} \left( \frac{m - nI}{I} \right)
\end{equation}
In practice, and specifically in a finite signal case, upsampling is performed in two steps:
First, we use zero padding and get the intermediate signal 
\begin{equation}
    x_{z}\left[m \right] = \begin{cases}
        x \left[ \frac{m}{I} \right ] &     m = kI\, , \\
       0                               & \text{otherwise.}
    \end{cases}
\end{equation}
Then, the zero-padded signal is convolved with sinc interpolation kernel. This step is equivalent to multiplication in Fourier domain with a rectangle, similarly to the LPF implementation.
% \begin{equation}
%     \mathrm{Upsample}_{I} \left( x \left[ n,\ m \right] \right) =   X_{z_{I}}^{D} \left[ k,\ l \right] H^{2D}_{\mathrm{upsample}_{I}}
% \end{equation}
% \begin{equation}
%     \mathrm{Upsample}_{I} \left( x \left[ n \right] \right) =  IDFT \left\{ DFT_{z_{I}}^{D} \left[ k,\ l \right] H^{2D}_{\mathrm{upsample},I}
% \end{equation}
\begin{equation}
\mathrm{Upsample}_{I}  \left( x \left[ n \right] \right)\left[ n \right] =   \mathrm{IDFT} \left( \mathrm{DFT} \left( x_z \left[ n \right] \right)\left[ k \right] H^{D}_{\mathrm{upsample}, I}\left[ k \right] \right) \left[ n \right]\,,
\end{equation}
Practically we used the following upsample kernel for a signal with spatial dimension $N$.
For even $N$:
\begin{equation}
    H^{D}_{\mathrm{upsample},I} \left[ k \right]=\begin{cases}
1 & 0\leq k<\frac{N}{2},\\
1 & N\left(I - \frac{1}{2}\right)+1\leq k\leq IN-1\\
0.5 & k=\frac{N}{2},k=N\left(I - \frac{1}{2}\right)\\
0 & \text{else}
\end{cases}
\end{equation}
For odd N:
\begin{equation}
H^{D}_{\mathrm{upsample}, I}\left[k\right]=\begin{cases}
1 & 0\leq k<\lfloor\frac{N}{2}\rfloor\\
1 & \lceil N\left(I - \frac{1}{2}\right) \rceil\leq k\leq2N-1\\
0 & \text{else}
\end{cases}	
\end{equation}
% and $H^{2D}_{\mathrm{upsample}_{I}} = HH^T$.
The reason for that is that in practice, we cannot assume the Nyquist condition holds. Specifically, for a finite signal $x\left[ n \right]$ with an even size $N$, we cannot assume that $X^{D} \left[ \frac{N}{2}\right] = X^{D} \left[ \frac{3N}{2}\right] = 0$. Note that for signals with even length, the $\frac{N}{2}$ component in the DFT domain represents the continual frequency of $\frac{\pi}{T}$, and thus, due to aliasing effect, we have
 $X^{D} \left[ \frac{N}{2}\right] = X^{D} \left[ \frac{3N}{2}\right] = X^F \left( \frac{\pi}{T} \right) + X^F \left( \frac{-\pi}{T} \right)$. 
 For a representation of the continuous signal with a higher sampling rate (e.g. the upsampled signal), the overlap in this frequency would not happen, hence we multiply this component by $\frac{1}{2}$ to get $\frac{1}{2} \left( X^F \left( \frac{\pi}{T} \right) + X^F \left( \frac{-\pi}{T} \right) \right) = X^F \left( \frac{\pi}{T} \right)$.
In this equation we use the assumption that $X^F \left( \frac{\pi}{T} \right) \in \mathbb{R}$. 
For a real signal The CTFT is conjugate symmetric, meaning 
$X^F \left( \frac{\pi}{T} \right) = X^F \left( \frac{-\pi}{T} \right)^{*} $. 
Therefore in case $X^F \left( \frac{\pi}{T} \right)$ has an imaginary component, it cannot be retrieved from the sum.
 A more detailed proof of this is given in appendix \cref{sec:implementation-proofs} below.
 % \daniel{A more detailed proof of this is given in appendix section XXX below.}


 