\section{Introduction}
Convolutional Neural Networks (CNNs) are the most common model in the image classification field. They were originally intended to have two properties:
\begin{enumerate}%\vspace{-4mm}
    \item Shift-invariant output: when we spatially translate the input image, their output does not change. %\vspace{-2mm}
    \item Shift-equivariant representation: when we spatially translate the input image, their internal representation translates in the same way.
\end{enumerate}%\vspace{-4mm}
Both these properties are thought to be beneficial for generalization (i.e., they are useful inductive biases), as we expect the image class not to change by an image translation, and its features to shift together with the image. Moreover, without the first property, the CNN might become vulnerable to adversarial attacks using image translations. Such attacks are real threats since they are very simple to execute in a ``black-box'' setting (where we do not know anything about the CNN). For example, consider a person trying to fool a CNN-based face scanner, by simply moving continuously until a face match is achieved.

It was commonly assumed that these useful properties were maintained since CNNs use only shift-equivariant operations: the convolution operation and component-wise non-linearities. However, CNN models typically also include downsampling operations such as pooling and strided convolution. Unfortunately, these operations violate equivariance, and this also leads to CNNs not being shift-invariant.
%\citep{Azulay2019WhyTransformations}. 
Specifically, \citet{Azulay2019WhyTransformations} have shown that shifting an input image by even one pixel can cause the output probability of a trained classifier to change significantly. This vulnerability can be further exploited in adversarial attacks, lowering classifiersâ€™ accuracy by more than 20\% \citep{Engstrom2017ExploringRobustness}.
Later, \citet{Zhang2019MakingAgain} has shown that this problematic behavior stems from an aliasing effect, taking place in downsampling operations such as pooling and strided convolutions, and non-linear operations on the downsampled signals.

Previous works have shown an improvement in CNN invariance to translations using partial solutions that reduced aliasing. For example, \citet{Zhang2019MakingAgain} has suggested adding a low-pass filter before the downsampling operations. This approach has been shown to reduce aliasing caused by downsampling, thus improving shift-invariance, as well as accuracy and noise robustness.
\citet{Karras2021Alias-FreeNetworks} have addressed aliasing in the generator within generative adversarial networks (GANs). 
They have shown that without proper treatment, aliasing in GANs leads to a decoupling of the high-frequency features (texture) from the low-frequency content (structure) in the generated images, thus limiting their applicability in smooth video generation. 
To alleviate this issue, \citet{Karras2021Alias-FreeNetworks} extended the low-pass filter approach and suggested a solution for the implicit aliasing caused by non-linearities. 
 Their method wraps the component-wise non-linear operations by upsampling and downsampling layers in an attempt to mimic the effect of applying the non-linear operations in the continuous domain, where they theoretically do not cause aliasing. 

Yet, none of the previous solutions completely eliminates aliasing, thus their suggested CNN architectures are not guaranteed to be shift-invariant.
A different approach to shift-invariant CNNs was suggested by \citet{Chaman2020TrulyNetworks}. 
They have proposed to use downsampling operations that dynamically choose the subsampling grid using a shift-equivariant decision rule.
Although it does not solve the aliasing problem, nor guarantees shift-equivariant representations, this approach enables the creation of CNNs whose outputs are completely invariant to integer circular shifts. 
However, this approach does not lead to invariance to subpixel shifts, which are common in real-world applications. 
For example, consider a case where the CNN receives input from a camera with some finite resolution. 
If we continuously shift the camera with respect to the scene, then the resulting shift in the CNN's discretely sampled input would rarely be integer-valued. % (since continuous values rarely have integer values). 
% Also, constraining to circular shifts may seem as another major limitation. However, it is not possible to guarantee robustness in translation types that include cause data loss at the image boundaries. In addition, circular shifts can be practically relevant, e.g.~in horizontal shifts for $360^{\circ}$ images (e.g.~see \cref{fig:panoram_shifts}).

Considering the anti-aliasing approach again, the problem with the solution suggested by \citet{Karras2021Alias-FreeNetworks} is that the aliasing resulting from non-linearities that increase the signal's bandwidth indefinitely (such as ReLU) can be avoided only when they are used in a continuous domain (i.e., with infinite resolution), which is impractical. 
However, this problem can be solved by replacing such non-linearities with alternatives whose effect does not lead to an indefinite increase in the signal's bandwidth --- such as polynomials.

\paragraph{Polynomial activations}
Despite their ease of computation, polynomials are not considered promising candidates for activation functions. 
The main practical reason for this is that polynomial activations have large (super-linear) magnitudes compared to standard activations (e.g., ReLU) and thus typically cause training instability (e.g., exploding gradients) \citep{Gottemukkula2019POLYNOMIALFUNCTIONS}. 
There seems also to be a theoretical disadvantage since shallow feedforward neural networks with polynomial activation functions are not universal approximators \citep{Hornik1989MultilayerApproximators}.
However, this last issue may not be a serious disadvantage: \citet{Kidger2020UniversalNetworks} have shown that feedforward neural networks with polynomial activations can become universal approximators with sufficient depth --- a regime more relevant for modern CNNs.
In addition, recent research \citep{Gottemukkula2019POLYNOMIALFUNCTIONS} has shown that by using normalization to truncate the dynamic range of the pre-activations, the training of Neural Networks with polynomial activations can be stabilized, and converge to reasonable results in simple image classification tasks (MNIST and CIFAR). 
% However, those results were shown on small-scale networks 
Yet, there are still a few significant challenges in using polynomial activations:
First, to the best of our knowledge, they were not shown to achieve competitive performance (similar to standard activations) on tasks of more realistic scales, such as ImageNet. In addition, the normalization method for dynamic range truncation causes the (truncated) polynomial to increase the signal's bandwidth indefinitely, which is not suitable for aliasing-free CNNs. This normalization was shown to be crucial for convergence even in small tasks and it is reasonable to expect that is even more important for larger tasks. %\vspace{4mm}

\paragraph{Contributions}
In this paper %\vspace{-3mm}
\begin{itemize}
    \item We propose the first Alias-Free Convnet (AFC). %\vspace{-1mm}
    \item We prove the AFC has both shift-invariant outputs and shift-equivariant internal representations --- even for fractional shifts, where previous models fail.%\vspace{-1mm} 
    \item We show how simple and easy ``black-box'' adversarial attacks built on fractional image translation can degrade a CNN performance, even when the CNN is invariant to integer shifts. In contrast, the AFC has certified robustness to such attacks and superior test accuracy in this regime.%\vspace{-1mm}
    % \todo{add a comment about superior performance in other regimes}
    % \item We show that the AFC has improved robustness to translations even when the certification conditions are not met.
    \item Specifically, the robustness of AFCs is certified for circular shifts and the ideal (Sinc) interpolation kernel. However, we show empirically that AFCs have improved robustness even with other types of translations.
    
    \item Interestingly, our model relies on polynomial activations, and we are the first to demonstrate competitive performance with such activations on ImageNet, to the best of our knowledge.%\vspace{-1mm}
\end{itemize}