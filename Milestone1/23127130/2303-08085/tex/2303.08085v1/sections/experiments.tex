\section{Experiments} \label{sec:experiments}
% We compare our Alias-Free Convnet (AFC) model to the baseline ConvNext model, and to previous shift-invariant methods in terms of accuracy and robustness. 
We compare our Alias-Free Convnet (AFC) model to the baseline ConvNeXt model and to the previous integer shift-invariant method Adaptive Polyphase Sampling (APS) \citep{Chaman2020TrulyNetworks}. 
We implemented all models with cyclic convolutions and trained them on ImageNet \citep{Deng2009ImageNet:Database} according to the ConvNeXt training regime \citep{Liu2022A2020s}. 
The experiments were conducted with circular translations similarly to the setting in previous works \citep{Zhang2019MakingAgain, Chaman2020TrulyNetworks}.
For sub-pixel translations, we used our ``ideal upsampling'' implementation \Cref{algo:Up-sample} (i.e., translation by $m/n$ pixels was conducted by upsampling by $n$, translating by $m$ pixels and downsampling by $n$).

\subsection{Shift equivariance}
Our model is designed to be not only shift-invariant (in terms of classification output), but also to have a Feature-Extractor that is shift-equivariant w.r.t.~to the continuous domain. 
We verified this property by examining the response of the output of each of the layers to a translation of $\frac{1}{2}$ pixel in the input image. 
This was done by propagating the two translated inputs and measuring the difference between their outputs in each layer, after upsampling back to the input's spatial size. 
The results in \Cref{fig:equivarance} show, in each layer, the normalized difference between the two translated layer outputs $y^0$ and $y^1$, after they were averaged across all $HW$ pixels (indexed by $i,j$) and $C$ channels (indexed by~$c$),
\begin{equation} \label{eq:diff}
    \mathrm{diff} \triangleq \frac{1}{CHW}\sum_{c,i,j} \frac{ \left| y^{0}_{c,i,j} - y^{1}_{c,i,j} \right|}{\max \left( \left| y^{0}_{c,i,j} \right|, \left| y^{1}_{c,i,j} \right|\right) + \varepsilon}\, ,
\end{equation}
% \daniel{here $\epsilon=...$.}
where $\varepsilon=10^{-9}$ was added in the denominator to avoid division by $0$.
The results show that ConvNeXt-AFC has only a negligible difference in the continuous representation of the translated responses at each layer, e.g.~$y^0 = y^1$, which means it is indeed shift-equivariant w.r.t.~the continuous domain (up to numerical error). 
In contrast, in the case of the baseline and APS models, the upsampled signals differ by more than 50\% across all the layers.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.45\linewidth]{images/shift_equivariance_trained_stats_half_64_o_plot.pdf}
   \caption{\textbf{Shift-equivariance measure w.r.t. continuous signal.}
   The averaged difference (\cref{eq:diff}) for $1/2$ pixel translated inputs (y-axis), across all layers (x-axis).
   This experiment was run on 64 random samples from the validation set.
    While the AFC model has practically 0 difference, the baseline and APS models have at least 50\% difference across all layers.}
   \label{fig:equivarance}
\end{figure}

% \subsection{ImageNet}
\subsection{Consistency and Classification accuracy}
The main measure used so far to quantify the shift-invariance of a model is called ``consistency'' \citep{Azulay2019WhyTransformations,Chaman2020TrulyNetworks}, which is the percentage of predictions changed on the test set following an image shift. 
Previously this measure has been used with integer shift values, however, in \Cref{table:aal-modifcations-accuracy} we test it also under sub-pixel shifts. 
We see that the changes we add to the baseline model gradually improve its consistency, until we reach 100\%.
% near 100\% (but not exactly, due to numerical accuracy)\daniel{why do we still have 99.99 for AFC in the table? Didn't you say it's more like 99.9999, so when we round it properly we get 100\%?}. 
% In contrast, the previous APS approach \citep{Chaman2020TrulyNetworks} is near 100\% consistent to integer shifts (due to numerical accuracy), but for fractional shifts, it actually has worse consistency than the baseline.
In contrast, the previous APS approach \citep{Chaman2020TrulyNetworks} is near 100\% consistent to integer shifts (due to numerical accuracy), but for fractional shifts, it only has slightly higher consistency than the baseline.
Even though the alias-free modifications in our model lead to perfect consistency, they cause a 1.08\% reduction in the (standard) test accuracy. 
We conclude that the main source of accuracy reduction is the modification of the normalization layer, as explained in \Cref{sec:implementation}. 
However, as we shall see next, despite such a reduction in accuracy, our model outperforms the previous models in adversarial shifts setting, due to its increased robustness.



\begin{table}[t]
\caption{\textbf{Alias-free modifications ImageNet accuracy and shift-consistency effect.}
Integer shift consistency is defined as the percentage of test samples that did not change their prediction following a random integer translation.
Fractional shift consistency is defined as the percentage of test samples that did not change their prediction following a random half-pixel translation. 
Consistency was averaged on five runs on ImageNet validation set with random seeds.
The final AFC model is 100\% consistent to both integer and fractional translations.
Note that though the APS  model \citep{Chaman2020TrulyNetworks} exhibits near 100\% integer shifts consistency (as expected), it has only slightly better consistency than the baseline model in terms of fractional shift consistency.}
  \label{table:aal-modifcations-accuracy}
\small
\centering
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{lcccccc}
\toprule
Model modification                  & \specialcell{Test\\accuracy} & Change & \specialcell{Integer\\shift consistency} & Change & \specialcell{Fractional \\shift consistency} & Change \\
\midrule
\specialcellleft{ConvNeXt-Baseline\\ \citep{Liu2022A2020s}}                    & 82.12         &        & 94.816                    &        & 92.034                    &        \\
+ Polynomial activation           & 81.77         & -0.35  & 95.126                    & 0.31   & 92.708                    & 0.67   \\
+ BlurPool                        & 78.99         & -3.12  & 96.635                    & 1.82   & 96.572                    & 4.54   \\
+ First layer activation          & 81.51         & -0.61  & 97.354                    & 2.54   & 97.347                    & 5.31   \\
+ AF LayerNorm                    & 80.66         & -1.46  & 97.030                    & 2.21   & 96.990                    & 4.96   \\
\specialcellleft{+ Activation upsample\\(ConvNeXt-AFC, ours)} & 81.04         & -1.08  & 100.000                   & 5.18   & 100.000                   & 7.97   \\
\midrule
\specialcellleft{ConvNeXt-APS\\ \citep{Chaman2020TrulyNetworks}}                     & 82.11         & -0.01  & 99.998                   & 5.18   & 93.227                    & 1.19  \\
\bottomrule
\end{tabular}
}
\end{table}


\begin{table}[t]
\caption{\textbf{Translation adversarial accuracy (ImageNet). }
Left column: Test accuracy. 
Right columns: adversarial accuracy defined as the percentage of correctly classified samples for each translation in the corresponding set: \cref{eq: T1}, \cref{eq: T2} or \cref{eq: T3} with $k=12$.}
\label{table:translation-robustness}
% \resizebox{1.0\linewidth}{!}{
\small
\centering
\begin{tabular}{lcccccc}
\toprule

model & \specialcell{Test} &  \specialcell{Adversarial\\integer grid} &  \specialcell{Adversarial\\ half-pixel grid } & \specialcell{Adversarial \\fractional grid}\\
\midrule
\specialcellleft{ConvNeXt-Baseline\\ \citep{Liu2022A2020s}}   & 82.12        &  76.63             & 73.65     & 77.82    \\
\specialcellleft{ConvNeXt-APS\\  \citep{Chaman2020TrulyNetworks}}      & 82.11        & 82.11              & 79.68     & 76.31    \\
ConvNeXt-AFC  (ours)       & 81.04          & 81.04             & 81.04       & 81.04     \\
\bottomrule
                           
\end{tabular}
% }
\end{table}

\subsection{Translation robustness}
Since standard models are not invariant to image translation, this might be exploited as a very easy form of a ``black-box'' adversarial attack: we simply move the image until we notice the prediction is changed.  
We examine this vulnerability, to assess each model's actual robustness to translations. 
For each sample, we performed all possible translations in some set $T$, and checked the resulting classification for each shift. 
We define the adversarial accuracy corresponding to $T$ as the portion of samples that are classified correctly for all translations in $T$.
We tested three types of basic translation grids --- Integer, Half pixel and Fractional:
    \begin{equation} \label{eq: T1}
              T_\mathrm{integer} = \left\{ \left( i,\ j \right)\,|\, 1 \leq i,j \leq 31 \right\}   
    \end{equation}
    \begin{equation} \label{eq: T2}
                T_\mathrm{half} = \left\{ \left( \frac{i}{2},\ \frac{j}{2}\right) \,|\, 1 \leq i,j \leq 63 \right\}
    \end{equation}
    \begin{equation} \label{eq: T3}        
        T_{\mathrm{frac}, k} = \left\{ \left(\frac{m_{1}}{n_{1}},\frac{m_{2}}{n_{2}}\right)\,|\, 1\leq m_{1,2}\leq n_{1,2}\leq k \right\} 
    \end{equation}  
In \Cref{table:translation-robustness} we observe the adversarial robustness with respect to these translation sets. 
In the baseline model the test accuracy of 82.1\% drops to 76.63\% for integer grid and to 73.65\% for half-pixel grid accuracy. 
This significant drop reflects that more than 10\% of the correctly classified test set samples may be misclassified due to translations.
The APS model \citep{Chaman2020TrulyNetworks} is, by construction, robust to integer translations and therefore has no accuracy reduction in the integer grid. 
However, it gets even worse results than the baseline in fractional adversarial accuracy (76.31\% vs 77.82\%).
In contrast, our AFC model is invariant to any of these shifts, and therefore its accuracy remains constant at 81.03\%, surpassing the other models. 
This robustness is `certified', and will not be compromised with larger translation sets, or other types of attacks (e.g., white box attacks) which can potentially decrease the performance of the other models even more.


% \begin{table*}[]
% \centering
% \begin{tabular}{l  l  l l  l l l}

% \toprule
% model         & \specialcell{Test} & \specialcell{Random integer \\ translation } & \specialcell{Adversarial integer\\grid} & \specialcell{Random sub-pixel \\translation} & \specialcell{Adversarial sub-pixel \\grid } & \specialcell{Adversarial \\fractional}\\
% \midrule


% ConvNeXt-baseline & 82.14        & 81.892                          & 76.63                               & 81.19                            & 73.65                  &        77.82       \\
% ConvNeXt-APS  & 82.11        & 82.11                           & 82.11                               & 81.06 & 79.68     & 76.31 \\
% ConvNeXt-AFC  & 80.6        & 80.6                           & 80.6                               & 80.6                           & 80.6 & 80.6                        \\

% \bottomrule
                           
% \end{tabular}



% \subsection{Fractional translation generalization}
% Our proposed model is robust to fractional translations by design. Practically, given that we don't have continuous image representation, this kind of fractional translations are generated by upsampling the discrete images, translate them and downsample to the original spatial size. 
% Our model robustness is guaranteed only for the above scheme, using ideal reconstruction filter, which is equivalent to the assumptions that (i) the discrete input image was sampeled without aliasing \hagay{is this true?}, and (ii) that the continuous representation is periodic. The latter is coming into effect in our and previous works \cite{Zhang2019MakingAgain, ChamanTrulyNetworks} settings, using cyclic convolutions.

% We evaluate our model on ``practical'' fractional shifts by using finite reconstruction filters. This setting may represent practical setting where aliasing effects in the input exists, and reduce the marginal effects induced by the cyclic setting.



\subsection{Out-of-distribution robustness}
While in our model shift-invariance is guaranteed, it is merely a learned property in other models, and thus may only be partially generalized to out-of-distribution images \citep{Azulay2019WhyTransformations}. 
To evaluate this hypothesis, We measured robustness to fractional translations on ImageNet-C \citep{Hendrycks2019BenchmarkingPerturbations}, which contains common corruptions of ImageNet images in ascending severity levels. 
We used fractional grid attack with a minimal translation of $1/7$ a pixel (\cref{eq: T3} with $k=7$).
The results are visualized in \Cref{fig:imagenet_c}. 
As our model's robustness to translations is guaranteed, it has no accuracy reduction caused by translations. 
In contrast, the other models' vulnerability to translation attacks increases with the severity of the corruption; ConvneXt-AFC relative accuracy degradation due to fractional translations increases from 5\% to as much as 23\% in the highest corruption severity. 
This indicates that the generalization of learned shift-invariance is limited in comparison to architectural shift-invariance.

% \hagay{I think we should repeat this with integer translation, hopefully convnext-circ remains worse. Otherwise one can think the problem is the interpolation errors of corrupted images.}

\begin{figure}[ht]
    \begin{center}
    \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/imagenet_c_fractional_maxup7_grid_acc_bar.pdf}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/imagenet_c_fractional_maxup7_grid_acc_degredation_plot.pdf}
    \end{subfigure}
   \caption{ \textbf{Adversarial accuracy with image corruptions.}
    \textbf{Left}: ImageNet-C accuracy (solid) vs. adversarial fractional grid accuracy (transparent). 
    \textbf{Right}: Accuracy vs. adversarial accuracy difference (percentage). 
    ConvNeXt-AFC (ours) ImageNet-C accuracy is not affected by translations, while in ConvNeXt-APS and ConvNeXt-Basline the relative accuracy degradation as a result of translations increases with the corruption severity.
  }
\label{fig:imagenet_c}

   \end{center}
   \vskip -0.2in
\end{figure}



% \begin{figure}
% \hspace*{\fill}%
% % \centering
% \begin{minipage}{.5\linewidth}
%   \centering
%   \vspace{0pt}
%   \includegraphics[width=0.9\linewidth]{images/imagenet_c_fractional_maxup7_grid_acc_bar.pdf}
% \end{minipage}%
% \hfill
% \begin{minipage}{.5\linewidth}
% \centering
%   \includegraphics[width=.9\linewidth]{images/imagenet_c_fractional_maxup7_grid_acc_degredation_plot.pdf}
% \end{minipage}
%    \caption{
%     Left: ImageNet-C accuracy (solid) vs. adversarial fractional grid accuracy (transparent). 
%     Right: accuracy vs. adversarial accuracy difference (percentage). 
%     ConvNeXt-AFC (ours) ImageNet-C accuracy is not affected by translations, while in ConvNeXt-APS and ConvNeXt-Basline the relative accuracy degradation as a result of translations increases with the corruption severity.
%   }
% \label{fig:imagenet_c}

% \end{figure}



\subsection{Robustness to other shifts}
We test the models' robustness to other types of translations, where our model's shift-invariance guarantee conditions are not satisfied.
\subsubsection{Zero-padding, bilinear-interpolation}
We tested the models' robustness to translation using the framework presented by \citet{Engstrom2017ExploringRobustness}, originally designed to test classification models to translations and rotations.
We zero-pad the images by $8$ pixels and translate by (a possibly fractional) amount limited by $8$ pixels, so there are no artifacts due to circular translations, nor data loss. The remaining parts are zero-padded and fractional translations are done using bilinear interpolation (see \Cref{fig:zero_pad_shifts}).
The results in \Cref{fig:crop-shift-bilinear} (left) show the models' adversarial accuracy to this attack with different grid sizes.
Although our model is not perfectly invariant to the performed translations due to the bilinear interpolation, it outperforms the other models by more than 4\% at the largest tested grid.


\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/attack_samples_zero_pad_original.pdf}
    \caption{Original image}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/attack_samples_zero_pad_shift.pdf}
    \caption{Shifted image}
    \end{subfigure}
\caption{
\textbf{  Visualization of shift attacks similar to the framework of \citet{Engstrom2017ExploringRobustness}.}
  (a) The original image is zero-padded in 8 pixels in each direction. 
  The attack is a translation of up to 8 pixels in each direction, e.g.~(b) is a translation of $6$ and $-2.5$ pixels in $x$ and $y$ axes respectively. Sub-pixel translations are done using bilinear interpolation.
  }
\label{fig:zero_pad_shifts}
\end{figure}


\subsubsection{Crop-shift}
In the experiments above, we used the common ImageNet input: the $224\times224$ center crop of the original $256\times256$ image. 
In contrast, in this experiment, we adversarially translated the cropped area, modeling translating a camera w.r.t.~the scene, as shown in \Cref{fig:circular_crop_shifts}(c).
We measure the adversarial accuracy of translations by up to $m$ integer pixels in each direction (i.e.~grid search at size $\left( 2m+1 \right) \times \left( 2m+1 \right)$). 
% and define the adversarial accuracy as the percentage of images that are correctly classified on the entire grid. 
The results in \Cref{fig:crop-shift-bilinear} (right) show that our model is more robust to this kind of translation, which is not cyclic, includes data loss, and is even integer-valued.
We additionally evaluate the original ConvNeXt model (zero-pad convolutions) which interestingly has the worst robustness in this setting.

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/attack_samples_original.pdf}
    \caption{Original image}
    \label{fig:circular_crop_shifts_a}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/attack_samples_cyclic_shift.pdf}
    \caption{Circular shifted image}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/attack_samples_crop_shift.pdf}
    \caption{Crop-shifted image}
    \end{subfigure}
\caption{\textbf{Visualization of used attacks.} 
(a) Original ImageNet \citep{Deng2009ImageNet:Database} validation-set image  --- 224 × 224 center crop of the
original 256 × 256 image. (b): Circular shift of 16 pixels in $x$ and $y$ axes. 
(c): ``Crop-shift'' of the original image of 16 pixels in $x$ and $y$ axes; the cropped area is shifted, modeling moving the camera with respect to the scene in the bottom-right direction. 
The top-left part of the circular shifted and crop-shifted images are equal to the bottom-right part of the original image.
The bottom and right edges of the circular shifted image consist of the top and left edges of the original image, causing unrealistic artifacts, while in the crop-shifted change we change the information from the scene.
}
\label{fig:circular_crop_shifts}
\end{figure}



% \begin{figure}[b!]
%   \centering

%   \includegraphics[width=0.45\linewidth]{images/imagenet_adversarial_crop_shift.pdf}
%    \caption{Crop-shift results. AFC is more robust for $m\geq2$. 
%    The accuracy improvement over the baseline and APS models reaches to $2.9\%$ and $2\%$ respectively for the strongest attack in our scope ($m=10$).
%    }
%    \label{fig:crop-shift}
% \end{figure}
% \todo{change convnext-circ to baseline in graph}


\begin{figure}[ht]
    \begin{center}
    \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/imagenet_adversarial_bilinear_zp.pdf}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/imagenet_adversarial_crop_shift.pdf}
    \end{subfigure}
\caption{\textbf{Adversarial accuracy for other types of shifts.} \textbf{Left}: Zero-padding, bilinear interpolation results. AFC is most robust model for all tested grid sizes. 
   \textbf{Right}: Crop-shift results. AFC is the most robust model for $m\geq2$. 
   The accuracy improvement over the baseline and APS models reaches to $2.9\%$ and $2\%$ respectively for the strongest attack in our scope ($m=10$).} 
   \label{fig:crop-shift-bilinear}
   \end{center}
   \vskip -0.2in
\end{figure}


% \begin{figure}
% \hspace*{\fill}%
% % \centering
% \begin{minipage}{.5\linewidth}
%   \centering
%   \vspace{0pt}
%   \includegraphics[width=0.9\linewidth]{images/imagenet_adversarial_crop_shift.pdf}
%   \caption{Crop-shift results. AFC is more robust for $m\geq2$. 
%    The accuracy improvement over the baseline and APS models reaches to $2.9\%$ and $2\%$ respectively for the strongest attack in our scope ($m=10$). \\
%    }
%    \label{fig:crop-shift}
% \end{minipage}%
% \hfill
% \begin{minipage}{.5\linewidth}
% \centering
%   \includegraphics[width=.9\linewidth]{images/imagenet_adversarial_bilinear_zp.pdf}
%   \caption{Zero-padding, bilinear interpolation results. AFC is more robust for $m\geq2$. 
%    The accuracy improvement over the baseline and APS models reaches to $2.9\%$ and $2\%$ respectively for the strongest attack in our scope ($m=10$).
%    }
% \end{minipage}
% \end{figure}



\begin{table}
\caption{\textbf{Test accuracy in models with polynomial activations.} }
  \label{table:polynomial-vit-results}

% \begin{tabular}{lllllll}
% \resizebox{1.0\linewidth}{!}{
\small
\centering
\begin{tabular}{llc}
\toprule
Task & Model & Test acc. \\ 
\midrule
ImageNet & ConvNeXt-tiny (GeLU) & 82.1 \\
ImageNet & ConvNeXt-tiny (Poly. deg 2) & 81.98 \\ \\

CIFAR10 & ViT (GeLU) & 97.04 \\
CIFAR10 & ViT (Poly. deg 2) & 97.08 \\
ImageNet & Deit-tiny (GeLU) & 72.29 \\
ImageNet & Deit-tiny (Poly. deg 4) & 71.96 \\

\bottomrule
\end{tabular}

  % }
  

\end{table}
