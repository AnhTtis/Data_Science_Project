\section{Formal shift-invariance proofs}
\subsection{Alias-Free polynomial activation function} \label{sec:shift-invariance-proof}
% hagay - this is the same algorithm from main paper. is there a way to print it here without rewriting / new caption?
% \begin{algorithm}
% \caption{Alias-free polynomial activation}
% \label{algo:af-poly}
% %\begin{algorithmic}
% Inputs: $x$ - input signal, $\mathrm{Poly}_{d}$ - polynomial of degree $d$.\\
% %\daniel{define here what is $d$. the bandwidth of $x$?}
% $x_{\mathrm{up}} \gets \mathrm{Upsample}_{\frac{d+1}{2}}\left(x\right)$\\
% $y_{\mathrm{poly}} \gets \mathrm{Poly}_{d} \left( x_{\mathrm{up}} \right)$ \\
% $y_{\mathrm{LPF}} \gets \mathrm{LPF}_{\frac{2}{d+1}}\left(y_{\mathrm{poly}}\right)$\\
% $y \gets \mathrm{Downsample}_{\frac{d+1}{2}}\left(y_{{\mathrm{LPF}}}\right)$\\
% Output $y$
% %\end{algorithmic}
% \end{algorithm}


In the paper, we presented a new alias-free activation function (described in \Cref{algo:af-poly}) that, together with alias-free downsampling layers, can completely solve the aliasing problem, and lead to perfectly shift-invariant CNNs. The validity of this solution relies on the following facts:
\begin{enumerate}
    \item \cref{prop:af-poly-invariance} in the paper (which we formally prove below) ensures the activations are shift-equivariant w.r.t.~continuous domain.
    \item Convolution and alias-free downsampling layers are indeed shift-equivariant w.r.t.~continuous domain (e.g., see proof in \citep{Karras2021Alias-FreeNetworks}).
    \item A composition of functions which are shift-equivariant w.r.t.~continuous domain remains shift-equivariant w.r.t.~continuous domain. %\hagay{do we actually need to show this? after looking again at the definition it seems straightforward  like regular equivalence }\daniel{I don't think so}
    \item Shift-invariance w.r.t.~continuous domain is implied from shift-equivariance w.r.t.~continuous domain, as was shown in \Cref{prop:cnn_equivariance_invariance}  of the paper.  
\end{enumerate}
% In section 2 we presented aliasing-free polynomial activation in Algorithm 1, following proposition 2:



% \begin{proposition}[2]\label{prop:af-poly-invariance}
%     The operator defined by \cref{algo:af-poly} is shift-equivariant w.r.t.~the continuous domain.
% \end{proposition}
% \textbf{Proposition 2} The operator defined by Algorithm 1 is shift-equivariant w.r.t. the continuous domain.
Therefore, all that remains is to prove \cref{prop:af-poly-invariance}. For convenience (to help visualize the proof), we show \Cref{fig:poly-alias} of the paper again (see \cref{fig:poly-alias-append}).


\begin{figure*}[t]
  \centering
   % \includegraphics[width=1.0\linewidth]{images/poly-relu-alias-ctft.png}
      \includegraphics[width=0.9\linewidth]{images/plot8.pdf}

   \caption{\textbf{A demonstration of the proposed non-linearities in the frequency domain.} The top plot at each panel represents the signal in the continuous domain, and the bottom represents the discrete domain.
   Where the input (a) is upsampled it shrinks its frequency response, expanding the allowed frequencies (b).
   Applying the polynomial activation expands the frequency response support by as factor $d$, without causing aliasing in the relevant frequencies (c.1). Thus, the discrete signal remains a faithful representation of the continuous signal after applying LPF (d1) and downsample back to the same spatial size (d2). 
   However, applying GeLU expands the support infinitely (c.2). This leads to an aliasing effect --- interference in the relevant frequencies marked in red in (c2). This causes the discrete signal not to be a correct representation of the continuous one, after LPF (d2) and downsampling (e2).}
   
   \label{fig:poly-alias-append}
\end{figure*}

% \paragraph{Proposition 2}
% %\label{prop:af-poly-invariance}
%     The operator defined by \cref{algo:af-poly} is shift-equivariant w.r.t.~the continuous domain.



\paragraph{Proof (\cref{prop:af-poly-invariance})}

We assume that the input $x$ is sampled from $x_{c}$, a $\frac{1}{T}$-band-limited signal at sample rate T, i.e. 
\begin{equation}
x\left[n\right]=x_{c}\left(nT\right)    .
\end{equation}
We denote the DTFT of $x\left[n\right]$ as:
\begin{equation}
    X^{f} \left( \theta \right) = \sum_{n = -\infty}^{\infty} x \left[ n \right] e^{-j\theta n} ,
\end{equation}
and the CTFT of $x_{c}$ as:
\begin{equation}\label{eq:ctft}
    X^{F}\left(\omega\right) = \int_{-\infty}^{\infty} x \left( t \right) e^{-j2\pi \omega t} \,dt .
\end{equation}
In addition, we define a reconstruction operator as a sinc interpolation of the discrete signal:
\begin{equation}
    \mathrm{Recon} \left( x \left[n \right] \right) \left( t \right) = \sum_{n\in \mathbb{Z}} x \left[ n \right] \mathrm{sinc} \left( \frac{t - nT}{T}\right) \,.
\end{equation}
It implies that:
\begin{equation}
    x_c \left(t \right) = \mathrm{Recon} \left( x \left[ n \right] \right) (t)\,.
\end{equation}
For easing the proof notation, we denote applying \Cref{algo:af-poly} as a whole on $x \left[ n \right]$ as $f\left( x \left[ n \right] \right)$.

A well-known relation between $X^{f} \left( \theta \right)$ and $X^{F} \left( \omega \right)$ for any continuous signal and its discrete representation is:
\begin{equation}
X^{f}\left(\theta\right)=\frac{1}{T}\sum_{k=-\infty}^{\infty}X^{F}\left(\frac{\theta+2\pi k}{T}\right) \,.
\end{equation}
This relation is represented in \Cref{fig:poly-alias-append} (a).
Since the support  of $X^{F}$ is limited by $\frac{1}{T}$, we can express
$X^{f}\left(\theta\right)$ in the frequency range $\theta\in\left[-\pi,\ \pi\right]$
as :
\begin{equation}
X^{f}\left(\theta\right)=X^{F}\left(\frac{\theta}{T}\right)    \,.
\end{equation}
From now on we will look at the DTFT domain in the range $\theta\in\left[-\pi,\ \pi\right]$,
since the effects on the rest of the replications are equal, i.e.:
\begin{equation}
\forall k\in\mathbb{Z},\ \forall\theta\in\left[-\pi,\ \pi\right]:\ X^{f}\left(\theta+2\pi k\right)=X^{f}\left(\theta\right)    \,;
\end{equation} 
this expression is true also for the DTFT of every signal from now on.

We will show that the operation presented in \Cref{algo:af-poly} on $x\left[n\right]$
is equivalent to applying polynomial activation in the continuous domain, following an LPF, i.e.
% \begin{equation}
% f \left( x \left[ n \right] \right) \left[ n \right] = \mathrm{LPF}_{\frac{2}{d+1}}\left(\mathrm{Poly}_{d}\left(  x_{c} \left( t \right) \right)\right) \left( nT \right)   = \mathrm{LPF}_{\frac{2}{d+1}}\left(\mathrm{Poly}_{d}\left( \mathrm{Recon} \left( x \left[ n \right] \right) \right)\right) \left( nT \right)   \,.
% \end{equation}
\begin{align}
f \left( x \left[ n \right] \right) \left[ n \right] &=
\mathrm{LPF}_{\frac{2}{d+1}}\left(\mathrm{Poly}_{d}\left(  x_{c} \left( t \right) \right)\right) \left( nT \right)  \\ &=
\mathrm{LPF}_{\frac{2}{d+1}}\left(\mathrm{Poly}_{d}\left( \mathrm{Recon} \left( x \left[ n \right] \right) \right)\right) \left( nT \right)   \,.
\end{align}

At step 1 of the algorithm, the signal is upsampled using sinc interpolation ($x_{\mathrm{up}}\gets\text{\ensuremath{\mathrm{Upsample}}}_{\frac{d+1}{2}}\left(x\right)$),
giving the expression 
% \begin{equation}
% x_{\mathrm{up}}\left[m\right]=\sum_{n\in\mathbb{Z}}x\left[n\right]h\left[m-nI\right]    \,,
% \end{equation}
% where 
% \begin{equation}
% h\left[m\right]=\mathrm{sinc}\left(\frac{m}{I}\right)    
% \end{equation}
% and $I=\frac{d+1}{2}$.
\begin{equation}
x_{\mathrm{up}}\left[m\right]=\sum_{n\in\mathbb{Z}}x\left[n\right] \mathrm{sinc}\left( \frac{m - nI}{I} \right) \,,
\end{equation}
where $I=\frac{d+1}{2}$.

The frequency response of upsampling is a contraction in the frequency axis:
\begin{equation}
X_{\mathrm{up}}^{f}\left(\theta\right)=X^{f}\left(\theta I\right)=\begin{cases}
X^{f}\left(\theta I\right) & \left|\theta\right|\leq\pi/I\\
0 & \left|\theta\right|>\pi/I 
\end{cases}    \,,
\end{equation}
which indeed represents a sample of the continuous signal at the rate $IT$, as can be seen in \cref{fig:poly-alias-append}(b).

At step 2 of the algorithm, $\mathrm{Poly}_{d}$ is applied on $x_{\mathrm{up}}$, giving $y_{\mathrm{poly}}$.
From the duality of multiplication and convolution in spatial and Fourier domains, we get that:
\begin{equation}
Y_{\mathrm{poly}}^{f} \left( \theta \right) = a_{0}+\sum_{k=1}^{d} a_{k} \left( \frac{1}{2 \pi} \right)^{k} \underbrace{X_{\mathrm{up}}^{f}\ast...\ast X_{\mathrm{up}}^{f}}_{k\ \text{times}} \left( \theta \right) \,.  
\end{equation}
Without loss of generality, we can assume for simplicity that $\mathrm{Poly}_{d}\left(x\right)=x^{d}$ and omit the constant factor $\left( \frac{1}{2 \pi} \right)^{k}$,
since the frequency expansion is determined solely by the highest degree of the polynomial.
Since the support of $\mathrm{Poly}_{d}\left(x\right)=x^{d}$
equals to the support of $x$ multiplied by $d$, and since the input support was contracted at factor $I=\frac{d+1}{2}$, we get that the support of $\underbrace{X_{\mathrm{up}}^{f}\ast...\ast X_{\mathrm{up}}^{f}}_{d\ \text{times}}$
is $\frac{\pi d}{I}$.

We get that the polynomial output support is:
\begin{equation} \label{eq:up-poly-support}
\frac{\pi d}{I}=\frac{2\pi d}{d+1}>\pi    \,,
\end{equation}
therefore aliasing occurs. The extension of the support beyond the range $\theta \in \left[ -\pi,\ \pi \right]$ is :
\begin{equation}
\frac{2\pi d}{d+1}-\pi=\frac{\pi d-\pi}{d+1}=\pi-\frac{2\pi}{d+1}=\pi-\frac{\pi}{I}    
\end{equation}
Hence, the replications due to the aliasing do not affect the frequency domain
of $\left|\theta\right|\leq\pi/I$, i.e.:
\begin{equation} \label{eq:up-poly-dtft}
Y_{\mathrm{poly}}^{f} \left( \theta \right) =\begin{cases}
\underbrace{X_{\mathrm{up}}^{f}\ast...\ast X_{\mathrm{up}}^{f}}_{d\ \text{times}}\left(\theta I\right) & \left|\theta\right|\leq\pi/I\\
\underbrace{X_{\mathrm{up}}^{f}\ast...\ast X_{\mathrm{up}}^{f}}_{d\ \text{times}}\left(\theta I\right)+\underbrace{X_{\mathrm{up}}^{f}\ast...\ast X_{\mathrm{up}}^{f}}_{d\ \text{times}}\left(\theta I-2\pi\right) & \theta>\pi/I\\
\underbrace{X_{\mathrm{up}}^{f}\ast...\ast X_{\mathrm{up}}^{f}}_{d\ \text{times}}\left(\theta I\right)+\underbrace{X_{\mathrm{up}}^{f}\ast...\ast X_{\mathrm{up}}^{f}}_{d\ \text{times}}\left(\theta I+2\pi\right) & \theta<-\pi/I
\end{cases}
\,,
\end{equation}
where the summations in the two bottom cases represent aliasing caused by the expansion of the near replications.
This partial aliasing effect caused by the polynomial is presented in \cref{fig:poly-alias-append}(c1).

At step 3, we use an $\mathrm{LPF}_{1/I}$, thus we eliminate all the
aliased frequencies, and get:
\begin{equation}
Y_{\mathrm{LPF}}^{f} \left( \theta \right) = \begin{cases}
\underbrace{X_{\mathrm{up}}^{f}\ast...\ast X_{\mathrm{up}}^{f}}_{d\ \text{times}}\left(\theta I\right) & \left|\theta\right|\leq\pi/I\\
0 & \left|\theta\right|>\pi/I
\end{cases} \,,
\end{equation}
which can be seen in \cref{fig:poly-alias-append}(d1).

At step 4, applying $\mathrm{Downsample}_{I}$ expands the frequency
domain, so we get 
\begin{equation}
Y^{f} \left( \theta \right) =\underbrace{X^{f}\ast...\ast X^{f}}_{d\ \text{times}}\left(\theta\right),\ \theta\in\left[-\pi,\pi\right] \,.
\end{equation}
We note again that this expression is true for the domain $\theta\in\left[-\pi,\pi\right]$, specifically because the actual support of $\underbrace{X^{f}\ast...\ast X^{f}}_{d\ \text{times}}\left(\theta\right)$
is larger. However, the frequencies beyond this range were eliminated
by the LPF, as can be seen in \cref{fig:poly-alias-append}(e1).

Recalling again that $X^{f}\left(\theta\right)=X^{F}\left(\frac{\theta}{T}\right)$,
we get that the CTFT of the continuous signal of the final expression $y$ is 
\begin{equation}
Y^{F}\left(\omega\right)=\begin{cases}
\underbrace{X^{F}\ast...\ast X^{F}}_{d\ \text{times}}\left(\omega\right) & \left|\omega\right|\leq\frac{1}{T}\\
0 & \left|\omega\right|>\frac{1}{T} \,,
\end{cases}
\end{equation}
which is equivalent to the signal we would get by applying $\mathrm{LPF}_{1/I}\left(\mathrm{Poly}_{d}\left(\cdot\right)\right)$
on $x_{c}$.

Shift-equivariance w.r.t.~continuous domain stems from this equivalence because we get that
\begin{equation}
f \left( x \left[ n \right] \right) \left[ n \right] =  \mathrm{LPF}_{\frac{2}{d+1}}\left(\mathrm{Poly}_{d}\left( \mathrm{Recon} \left( x \left[ n \right] \right) \right)\right) \left( nT \right)
\end{equation}

\begin{align}\label{eq:translation-continuous-representation}
    \Rightarrow  f \left( \tau x \left[ n \right] \right) \left[ n \right] &=  
    \mathrm{LPF}_{\frac{2}{d+1}}\left(\mathrm{Poly}_{d}\left( \mathrm{Recon} \left( \tau x \left[ n \right] \right) \right)\right) \left( nT \right)   \\ 
    &=    \mathrm{LPF}_{\frac{2}{d+1}}\left(\mathrm{Poly}_{d}\left( \mathrm{Recon} \left( x \left[ n \right] \right) \right)\right) \left( nT + \Delta \right) \label{eq:translation-continuous-representation-1}\\
     &= \tau f \left( x \left[ n \right] \right) \left[ n \right] \,.
\end{align}
    
% \hagay{explain, maybe define upsample and downsample to continuous domain}
% \begin{align}
% f \left( x \left[ n \right] \right) =  \mathrm{LPF}_{\frac{2}{d+1}}\left(\mathrm{Poly}_{d}\left( \mathrm{Recon} \left( x \left[ n \right] \right) \right)\right) \left( nT \right)   \\
%     \Rightarrow  f \left( \tau x \left[ n \right] \right) =  
%     \mathrm{LPF}_{\frac{2}{d+1}}\left(\mathrm{Poly}_{d}\left( \mathrm{Recon} \left( \tau x \left[ n \right] \right) \right)\right) \left( nT \right)   =
%     \mathrm{LPF}_{\frac{2}{d+1}}\left(\mathrm{Poly}_{d}\left( \mathrm{Recon} \left( \tau x \left[ n \right] \right) \right)\right) \left( nT + \Delta \right)   
% \end{align}
% f \left( \tau x \right) = \mathrm{LPF}_{I^{-1}}\left(\mathrm{Poly}_{d}\left( \tau x_c\right)\right) = \tau \mathrm{LPF}_{I^{-1}}\left(\mathrm{Poly}_{d}\left(x_c\right)\right) = \tau f \left( x \right)  



The transition in \cref{eq:translation-continuous-representation-1} is justified due to shift-equivariance w.r.t.~continuous domain of reconstruction and alias-free downsample operators, and shift-equivariance of point-wise operations in the continuous domain.


\subsection{LPF-Poly} \label{sec:lpf-poly-append}
% \daniel{we need to add an explanation why I=3/8. From the explanation here it seems BlurPool with 1-I=1/4 leads to I=3/4, not I=3/8.}
In \Cref{sec:shift-invariance-proof} we showed that our polynomial activation function, which is derived in \Cref{algo:af-poly}, is alias-free for any polynomial. 
Specifically, as can be seen in \Cref{algo:af-poly}, the required upsample rate to avoid aliasing is dependent on the polynomial degree and equals to $\frac{d+1}{2}$, where $d$ is the polynomial degree.
In this section, we generalize this concept to cases where we would like to avoid upsampling, e.g. in layers where the channels have large spatial extents, where it is too computationally expensive. 
In addition, we show that $\mathrm{LPFPoly_2}$ which was presented in the paper is indeed alias-free and shift-equivariant w.r.t.~continuous domain, using the proof concept regarding \Cref{algo:af-poly}.

We defined LPF-Poly as:
\begin{equation}
    \mathrm{LPFPoly}_2 \left( x \left[ n \right] \right) \left[n \right] = a_0 + a_1 x\left[n \right] + x\left[n \right] \cdot \mathrm{LPF}_{c}\left(x\left[n \right] \right)\left[n \right] \,.
\end{equation}
% Note that as opposed to the previous section, here $I$ is not an integer; it is a real number in the range $(0,1)$. 
% I is not necessarily integer above
Note that $c$ is a real number in the range $(0,1)$, representing the LPF's cutoff ratio. 
In addition, note that in the paper we omitted some of the $ \left[ n \right]$ in the notation for more compact writing. 
The output support is implied by the component of $x \cdot \mathrm{LPF}_{c}\left(x \right)$, and, similarly to the computation in \cref{eq:up-poly-support}, is equal to $\left(1 + c \right)\pi$.
% similarly to the notation in \cref{eq:up-poly-dtft}. \daniel{?}. 
We get that 
\begin{equation}
Y_{\mathrm{poly}}^{f} \left( \theta \right) =\begin{cases}
X^{f}\ast X_{\mathrm{\mathrm{LPF}}}^{f}\left(\theta\right) & \left|\theta\right|\leq\pi-\pi c\\
X^{f}\ast X_{\mathrm{\mathrm{LPF}}}^{f}\left(\theta\right)+X^{f}\ast X_{\mathrm{\mathrm{LPF}}}^{f}\left(\theta-2\pi\right) & \theta>\pi-\pi c\\
X^{f}\ast X_{\mathrm{\mathrm{LPF}}}^{f}\left(\theta\right)+X^{f}\ast X_{\mathrm{\mathrm{LPF}}}^{f}\left(\theta+2\pi\right) & \theta<-\left(\pi- \pi c\right)
\end{cases}
\,,    
\end{equation}
which means that the range $\left|\theta\right|\leq\pi(1-c)$ is alias-free. This was achieved without the need of upsampling.
Next, applying $\mathrm{LPF}_{1-c}$ gives:
\begin{equation}
Y_{\mathrm{LPF}}^{f} \left( \theta \right)=\begin{cases}
X^{f}\ast X_{\mathrm{\mathrm{LPF}}}^{f}\left(\theta\right) & \left|\theta\right|\leq\pi-\pi c\\
0                                                           & \left|\theta\right| > \pi-\pi c\\
\end{cases} \,,
\end{equation}
hence, the final output is alias-free. Shift-equivariance w.r.t.~continuous domain is derived from this, similarly to \cref{eq:translation-continuous-representation}.

