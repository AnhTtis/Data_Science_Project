\section{Related work}
% 
Modern Convolutional Neural Networks use downsampling operations such as pooling and strided convolutions to increase the net's receptive field, with lower computation cost than using larger kernels for that matter. 
It was shown that this architectural design breaks the shift-equivariance property of the convolution operation due to the aliasing effect \citep{Azulay2019WhyTransformations}, leading CNNs to be not shift-invariant. 
Even though it was shown this property can be partially learned using appropriate data augmentation \citep{Gunasekar2022GeneralizationAugmentations}, other works tried to architecturally regain shift-invariance. 

Another work \citep{Zhang2019MakingAgain} suggested shift-equivariance could be maintained by reducing aliasing using low-pass filters (LPFs) before downsampling \citep{oppenheim99}. 
Others \citep{Zou2020DelvingConvNets} improved the LPF method by using adaptive content-aware adaptive filters.
These changes were shown to improve convnets robustness to translations, as well as accuracy and generalization, yet another work showed that focusing on circular shifts may induce adversarial attack vulnerabilities \citep{Singla2021ShiftRobustness}.

Instead of tackling the aliasing problem, other works suggested solving shift variance by using adaptive subsampling grids \citep{Chaman2020TrulyNetworks, Rojas-Gomez2022LearnableNetworks, Xu2021GroupSubsampling}. 
This approach was shown ability to produce perfect shift-invariance in image classification tasks. 
Yet, as it does not eliminate the aliasing effects, it does not produce shift-invariance to fractional shifts, and it does not ensure shift-equivariance of the internal representations.

Since it is known that aliasing in discrete signals is caused by non-linearities in addition to subsampling, a few studies suggested methods for alias-free activation functions. 
\citet{Karras2021Alias-FreeNetworks} suggested using upsampling before non-linearities to reduce aliasing in generative models, which cause failure in embedding ``high-frequency features'' such as textures in their outputs. 
The idea of using polynomial non-linearities to battle aliasing has been mentioned previously \citep{oppenheim99, EmmyWei2022Aliasing-FreeFunctions}. \citet{Franzen2021GeneralCNNs} have recently shown this methodology can be used to improve rotation-equivariance. 
However, it has never been applied in a complete alias-free setting, nor in modern-scale deep networks. 
Other smooth activation functions have been suggested as well \citep{Hossain2021Anti-aliasingFunction, Vasconcelos2020AnNetworks}, yet they do not completely eliminate aliasing.

It is worth mentioning that other equivariance properties have been studied as well, such as rotation, reflection and group equivariance \citep{Delchevalerie2021AchievingNetworks, Bronstein2016GeometricData, Xu2021GroupSubsampling, Ning2022Scale-AwareEquivariance, Manfredi2020ShiftDetection, Romero2020AttentiveNetworks, Yeh2022EquivarianceParameter-Sharing, Weiler2019GeneralCNNs1,
Delchevalerie2021AchievingNetworks}. This work is focused on the specific property of shift-invariance in CNNs for image classification.