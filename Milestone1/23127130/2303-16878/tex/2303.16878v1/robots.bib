@STRING{aaai    = {Proc.~of the Conference on Advancements of Artificial 
Intelligence (AAAI)} }
@STRING{aaaiold = {Proc.~of the National Conference on Artificial Intelligence 
(AAAI)} }
@STRING{ac      = {IEEE Trans. on Automatic Control} }
@STRING{tro      = {IEEE Trans. on Robotics} }
@STRING{tog =  {ACM Trans. on Graphics} },
@STRING{acc     = {Proc.~of the IEEE American Control Conference (ACC)} }
@STRING{accv    = {Proc.~of the Asian Conf.~on Computer Vision (ACCV)} }
@STRING{acra    = {Proc.~of the Australasian Conf.~on Robotics and Automation 
(ACRA)} }
@STRING{acmgraphics = {ACM Transactions on Graphics} }
@STRING{addison = {Addison-Wesley Publishing Inc.} }
@STRING{advancedrobotics={Advanced Robotics} }
@STRING{ai      = {Artificial Intelligence} }
@STRING{ams     = {Proc.~of Autonome Mobile Systeme} }
@STRING{ar      = {Autonomous Robots} }
@STRING{arxiv   = {arXiv preprint} }
@STRING{bmvc    = {Proc.~of British Machine Vision Conference (BMVC)} }
@STRING{cacm    = {Communications of the ACM} }
@STRING{ccvw    = {Proc.~of the Croation Computer Vision Workshop (CCVW)} }
@STRING{cira    = {Proc.~of the IEEE Intl.~Symp. on Computer Intelligence in 
Robotics and Automation (CIRA)} }
@STRING{cogsys  = {Proc.~of the Intl.~Conf.~on Cognitive Systems (CogSys)} }
@STRING{cviu    = {Journal of Computer Vision and Image Understanding (CVIU)} }
@STRING{cvpr    = {Proc.~of the IEEE Conf.~on Computer Vision and Pattern 
Recognition (CVPR)} }
@STRING{cvprw    = {Proc.~of the IEEE Conf.~on Computer Vision and Pattern 
	Recognition Workshops (CVPR)} }
@STRING{cvvt    = {Proc.~of the Intl.~Workshop on Computer Vision in Vehicle 
Technology (CVVT)} }
@STRING{dagm    = {Proc.~of the Symposion of the German Association for Pattern 
Recognition (DAGM)} }
@STRING{icarcv = {Proc.~of the IEEE Intl.~Conf. on Control, Automation, Robotics and Vision (ICARCV)}}
@STRING{dagstuhl= {Proc.~of the Dagstuhl Seminar} }
@STRING{dgpf    = {Proc.~of the Conf.~of the German Society for Photogrammetry, 
Remote Sensing and Geoinformation (DGPF)} }
@STRING{eccv    = {Proc.~of the Europ.~Conf.~on Computer Vision (ECCV)} }
@STRING{ecmr    = {Proc.~of the Europ.~Conf.~on Mobile Robotics (ECMR)} }
@STRING{emav    = {Proc.~of the European Micro Aerial Vehicle Conference} }
@STRING{euros   = {Proc.~of the Europ.~Robotics Symp. (EUROS)} }
@STRING{fntr    = {Foundations and Trends in Robotics} }
@STRING{gcpr    = {Proc.~of the German Conf.~on Pattern Recognition (GCPR)} }
@STRING{humanoids={Proc.~of the IEEE Intl.~Conf.~on Humanoid Robots} }
@STRING{icar    = {Proc.~of the Intl.~Conf.~on Advanced Robotics (ICAR)} }
@STRING{iccv    = {Proc.~of the IEEE Intl.~Conf.~on Computer Vision (ICCV)} }
@STRING{iciap   = {Proc.~of the Intl.~Conf.~on Image Analysis and Processing 
(ICIAP)} }
@STRING{icip    = {Proc.~of the IEEE Intl.~Conf.~on Image Processing (ICIP)} }
@STRING{icra    = {Proc.~of the IEEE Intl.~Conf.~on Robotics \& Automation 
(ICRA)} }
@STRING{icuas   = {Proc.~of the Intl.~Conf.~on Unmanned Aircraft Systems 
(ICUAS)} }
@STRING{ieeepress={IEEE Computer Society Press} }
@STRING{ijcai   = {Proc.~of the Intl.~Conf.~on Artificial Intelligence (IJCAI)} 
}
@STRING{ijcv    = {Intl.~Journal~of Computer Vision (IJCV)} }
@STRING{ijgi    = {Intl.~Journal of Geo-Information} }
@STRING{ijhr    = {The Int.~Journal of Humanoid Robotics (IJHR)} }
@STRING{ijrr    = {Intl.~Journal~of Robotics Research (IJRR)} }
@STRING{imvip   = {Proc.~of the Irish Machine Vision and Image Processing 
Conference (IMVIP)} }
@STRING{iros    = {Proc.~of the IEEE/RSJ Intl.~Conf.~on Intelligent Robots and 
Systems (IROS)} }
@STRING{iser    = {Proc.~of the Intl.~Sym.~on Experimental Robotics (ISER)} }
@STRING{ismar   = {Proc.~of the Intl.~Symposium~on Mixed and Augmented Reality 
(ISMAR)} }
@STRING{isprsannals={ISPRS Annals of the Photogrammetry, Remote Sensing and 
Spatial Information Sciences} }
@STRING{isprsarchives={ISPRS Archives of the Photogrammetry, Remote Sensing and 
Spatial Information Sciences} }
@STRING{isrr    = {Proc.~of the Intl.~Symposium~on Robotic Research (ISRR)} }
@STRING{iv      = {Proc.~of the IEEE Intelligent Vehicles Symposium (IV)} }
@STRING{ivc     = {Journal on Image and Vision Computing (IVC)} }
@STRING{jair    = {Journal of Artificial Intelligence Research (JAIR)} }
@STRING{jbe     = {ASME Journal of Basic Engineering} }
@STRING{jfr     = {Journal of Field Robotics (JFR)} }
@STRING{jirs    = {Journal of Intelligent and Robotic Systems (JIRS)} }
@STRING{jmiv    = {Journal of Mathematical Imaging and Vision} }
@STRING{joe     = {IEEE Journal of Oceanic Engineering} }
@STRING{jprs    = {ISPRS Journal of Photogrammetry and Remote Sensing (JPRS)} }
@STRING{jra     = {IEEE Journal of Robotics and Automation} }
@STRING{jras    = {Journal on Robotics and Autonomous Systems (RAS)} }
@STRING{mcg     = {Proc.~of the Intl.~Conf.~on Machine Control and Guidance 
(MCG)} }
@STRING{mirage  = {Proc.~of the Intl.~Conf.~on Computer Vision/Computer 
Graphics Collaboration Techniques and Applications (MIRAGE)} }
@STRING{mitpress= {MIT Press} }
@STRING{ml      = {Machine Learning} }
@STRING{mobicom = {Proc.~of the {ACM} Intl.~Conf.~on Mobile Computing and 
Networking (MobiCom)} }
@STRING{mva     = {Proc.~of the IAPR Conf.~on Machine Vision Applications 
(MVA)} }
@STRING{nips    = {Proc.~of the Conf.~on Neural Information Processing Systems 
(NIPS)} }
@STRING{nipsjournal={Advances in Neural Information Processing Systems} }
@STRING{oceans  = {Proc.~of OCEANS MTS/IEEE Conference and Exhibition} }
@STRING{pami    = {IEEE Trans.~on Pattern Analysis and Machine Intelligence 
(TPAMI)} }
@STRING{pcv     = {Proc.~of the ISPRS Conference on Photogrammeric Computer 
Vision (PCV)} }
@STRING{pers    = {Photogrammetric Engineering and Remote Sensing (PE\&RS)} }
@STRING{pfg     = {Photogrammetrie -- Fernerkundung -- Geoinformation (PFG)} }
@STRING{phowo   = {Proc.~of the Photogrammetric Week (PhoWo)} }
@STRING{pia     = {Proc.~of the ISPRS Conference on Photogrammeric Image 
Analysis (PIA)} }
@STRING{pr      = {Pattern Recognition} }
@STRING{prl     = {Pattern Recognition Letters} }
@STRING{ral     = {IEEE Robotics and Automation Letters (RA-L)} }
@STRING{ram     = {IEEE Robotics and Automation Magazine (RAM)} }
@STRING{ras     = {Journal on Robotics and Autonomous Systems (RAS)} }
@STRING{rasmag  = {IEEE Robotics and Automation Magazine} }
@STRING{rs      = {Remote Sensing} }
@STRING{rss     = {Proc.~of Robotics: Science and Systems (RSS)} }
@STRING{rssbook = {Robotics: Science and Systems} }
@STRING{sensors = {IEEE Sensors Journal} }
@STRING{sice    = {Proc.~of the Annual Conference of the Society of Instrument 
and Control Engineers (SICE)} }
@STRING{smc     = {Proc.~of the IEEE Intl.~Conf.~on Systems, Man, and 
Cybernetics (SMC)} }
@STRING{snowbird= {Proc.~of the Learning Workshop (Snowbird)} }
@STRING{soave   = {Proc.~of the Workshop on Self-Organization of AdaptiVE 
behavior (SOAVE)} }
@STRING{spiesdvrs={Proc.~of SPIE Stereoscopic Displays and Virtual Reality 
Systems} }
@STRING{spiev   = {Proc.~of SPIE Videometrics} }
@STRING{springer= {Springer Verlag} }
@STRING{springerstaradvanced={STAR Springer Tracts in Advanced Robotics} }
@STRING{tarj    = {The Australian Rangeland Journal} }
@STRING{tits    = {IEEE Trans.~on Intelligent Transportation Systems (ITS)} }
@STRING{titsmag = {IEEE Trans.~on Intelligent Transportation Systems Magazine} }
@STRING{tpami   = {IEEE Trans.~on Pattern Analalysis and Machine Intelligence 
(TPAMI)} }
@STRING{tra     = {IEEE Trans.~on Robotics and Automation} }
@STRING{tro     = {IEEE Trans.~on Robotics (TRO)} }
@STRING{uai     = {Proc.~of the Conf.~on Uncertainty in Artificial Intelligence 
(UAI)} }
@STRING{uavg    = {Proc.~of the Intl.~Conf.~on Unmanned Aerial Vehicles in 
Geomatics} }
@STRING{uust    = {Proc.~of the Intl.~Symp.~on Unmanned Untethered Submersible 
Technology} }
@STRING{vc      = {The Visual Computer (VC)} }
@STRING{wafr    = {Intl.~Workshop on the Algorithmic Foundations of Robotics 
(WAFR)} }
@STRING{threedv = {Proc. of the International Conference on 3D Vision~(3DV)}}



@article{vysotska2019ral,
  author = {O. Vysotska and C. Stachniss},
  title = {{Effective Visual Place Recognition Using Multi-Sequence Maps}},
  journal = ral,
  volume = 4,
  issue =2,
  pages = {1730-1736},
  year = 2019,
  url = {http://www.ipb.uni-bonn.de/pdfs/vysotska2019ral.pdf},
}


@Article{naseer2018tro,
  author        = {T. Naseer and W. Burgard and C. Stachniss},
  title         = {{Robust Visual Localization Across Seasons}},
  journal       = tro,
  doi           = {10.1109/tro.2017.2788045},
  year          = {2018},
  keywords      = {Place Recognition, Localization},
  abstract      = {Localization is an integral part of reliable robot navigation and long-term autonomy requires robustness against perceptional changes in the environment during localization. In the context of vision-based localization, such changes can be caused by illumination variations, occlusion, structural development, different weather conditions and seasons. In this paper, we present a novel approach for localizing a robot over longer periods of time using only monocular image data. We propose a novel data association approach for matching streams of incoming images to an image sequence stored in a database. Our method exploits network flows to leverage sequential information to improve the localization performance and to maintain several possible trajectories hypotheses in parallel. To compare images, we consider a semi-dense image description based on HOG features as well as global descriptors from Deep Convolutional Neural Networks trained on ImageNet for robust localization. We perform extensive evaluations on a variety of datasets and show that our approach outperforms existing state-of-the-art approaches.},
}

@article{shi2021ral,
title={{Keypoint Matching for Point Cloud Registration using Multiplex Dynamic Graph Attention Networks}},
author={C. Shi and X. Chen and K. Huang and J. Xiao and H. Lu and C. Stachniss},
year={2021},
journal=ral,
url = {http://www.ipb.uni-bonn.de/pdfs/shi2021ral-iros.pdf},
codeurl = {https://github.com/chenghao-shi/MDGAT-matcher},
doi = {10.1109/LRA.2021.3097275},
issn = {2377-3766},
}

@article{chen2021auro,
author = {X. Chen and T. L\"abe and A. Milioto and T. R\"ohling and J. Behley and C. Stachniss},
title = {{OverlapNet: A Siamese Network for Computing LiDAR Scan Similarity with Applications to Loop Closing and Localization}},
journal = auro,
year = {2021}
}

@Article{trahaniasWebfair,
  author =   {P. Trahanias and W. Burgard and A. Argyros and D. H\"{a}hnel and H. Baltzakis and P. Pfaff and C. Stachniss},
  title =  {{TOURBOT} and {WebFAIR}: Web-Operated Mobile Robots for Tele-Presence in Populated Exhibitions},
  journal =  ram,
  year =   2005,
  Volume =   {12},
  number =   {2},
  pages =  {77--89},
  pdfurl =       {http://ieeexplore.ieee.org/iel5/100/31383/01458329.pdf?arnumber=1458329},
}


@InBook{springerbook-slamchapter,
  author =   {C. Stachniss and J. Leonard and S. Thrun},
  editor =   {B. Siciliano and O. Khatib},
  title =    {Springer Handbook of Robotics, 2nd edition},
  chapter =    {Chapt.~46: Simultaneous Localization and Mapping},
  publisher =    {Springer},
  year =   2016,
}

@article{vysotska2016ral,
  author =   {O. Vysotska and C. Stachniss},
  title =    {{Lazy Data Association For Image Sequences Matching Under Substantial Appearance Changes}},
  journal = ral,
  year = 2016,
  volume = 1,
  number = 1,
  pages = {213-220},
  url = {http://www.ipb.uni-bonn.de/pdfs/vysotska16ral-icra.pdf},
  keywords      = {Localization},
  abstract      = {Localization is an essential capability for mobile robots and the ability to localize in changing environments is key to robust outdoor navigation. Robots operating over extended periods of time should be able to handle substantial appearance changes such as those occurring over seasons or under different weather conditions. In this paper, we investigate the problem of efficiently coping with seasonal appearance changes in online localization. We propose a lazy data association approach for matching streams of incoming images to a reference image sequence in an online fashion. We present a search heuristic to quickly find matches between the current image sequence and a database using a data association graph. Our experiments conducted under substantial seasonal changes suggest that our approach can efficiently match image sequences while requiring a comparably small number of image to image comparisons.},
}
@article{perea16jras,
  author =    {D. Perea Str{\"o}m and  I. Bogoslavskyi and C. Stachniss},
  title =     {Robust Exploration and Homing for Autonomous Robots},
  journal = jras,
  year = 2016,
  }
 
 
@inproceedings{vysotska2016iros,
  title = {{Exploiting Building Information from Publicly Available Maps in Graph-Based SLAM}},
  author = {O. Vysotska and C. Stachniss},
  booktitle = iros,
  year = {2016},
  abstract = {[none]},
  url = {http://www.ipb.uni-bonn.de/pdfs/vysotska16iros.pdf},
  videourl = {https://www.youtube.com/watch?v=5RfRAEP-baM},
}


@InProceedings{vysotska2015icra,
  author        = {O. Vysotska and T. Naseer and L. Spinello and W. Burgard and C. Stachniss},
  title         = {{Efficient and Effective Matching of Image Sequences Under Substantial Appearance Changes Exploiting GPS Prior}},
  booktitle     = icra,
  year          = 2015,
  url           = {http://ais.informatik.uni-freiburg.de/publications/papers/vysotska15icra.pdf},
}

@InProceedings{vysotska2015icraws,
  author        = {O. Vysotska and C. Stachniss},
  title         = {{Lazy Sequences Matching Under Substantial Appearance Changes}},
  booktitle     = {Workshop on Visual Place Recognition in Changing Environments at the IEEE Int.~Conf.~on Robotics \& Automation},
  year          = 2015,
}

@inproceedings{chebrolu2020icra,
  title={Spatio-Temporal Non-Rigid Registration of 3D Point Clouds of Plants},
  author={N. Chebrolu and T. L\"abe and C. Stachniss},
  booktitle=icra,
  year={2020},
  url = {http://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/chebrolu2020icra.pdf},
}

@inproceedings{chen2019iros,
author = {X. Chen and A. Milioto and E. Palazzolo and P. Giguère and J. Behley and C. Stachniss},
title = {{SuMa++: Efficient LiDAR-based Semantic SLAM}},
booktitle = iros,
year = 2019,
url = {http://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/chen2019iros.pdf},
codeurl = {https://github.com/PRBonn/semantic_suma/},
videourl = {https://youtu.be/uo3ZuLuFAzk},
}

@inproceedings{chen2020rss,
author = {X. Chen and T. L\"abe and A. Milioto and T. R\"ohling and O. Vysotska and A. Haag and J. Behley and C. Stachniss},
title = {{OverlapNet: Loop Closing for LiDAR-based SLAM}},
booktitle = rss,
year = {2020},
url = {https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/chen2020rss.pdf},
codeurl = {https://github.com/PRBonn/OverlapNet/},
videourl = {https://youtu.be/YTfliBco6aw},
}


@InProceedings{palazzolo2019iros,
author = {E. Palazzolo and J. Behley and P. Lottes and P. Giguere and C. Stachniss},
title = {{ ReFusion: 3D Reconstruction in Dynamic Environments for RGB-D Cameras Exploiting Residuals}},
year = 2019,
booktitle = IROS,
}



@article{lu1997globally,
  title={Globally consistent range scan alignment for environment mapping},
  author={F. Lu and E. Milios},
  journal={Autonomous robots},
  volume={4},
  number={4},
  pages={333--349},
  year={1997},
  publisher={Springer}
}

%ia hbst for loop closures
@article{schlegel2018hbst,
  title={HBST: A hamming distance embedding binary search tree for feature-based visual place recognition},
  author={D. Schlegel and G. Grisetti},
  journal=ral,
  volume={3},
  number={4},
  pages={3741--3748},
  year={2018},
  publisher={IEEE}
}

@inproceedings{schlegel2019adding,
  title={Adding Cues to Binary Feature Descriptors for Visual Place 
  Recognition},
  author={D. Schlegel and G. Giorgio},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={5488--5494},
  year={2019},
 }

%ia dbow2
@article{galvez2012bags,
  title={Bags of binary words for fast place recognition in image sequences},
  author={D. G{\'a}lvez-L{\'o}pez and J. D. Tardos},
  journal=tro,
  volume={28},
  number={5},
  pages={1188--1197},
  year={2012},
}

%lidar ndt
@inproceedings{zaganidis2017semantic,
	title={Semantic-assisted 3D normal distributions transform for scan registration in environments with limited structure},
	author={A. Zaganidis and M. Magnusson and T. Duckett and G. Cielniak},
	booktitle=iros,
	pages={4064--4069},
	year={2017},
	organization={IEEE}
}


% lidar icp
@inproceedings{mendes2016icp,
	title={ICP-based pose-graph SLAM},
	author={E. Mendes and P. Kochand and S. Lacroix},
	booktitle={2016 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)},
	pages={195--200},
	year={2016},
	organization={IEEE}
}

%ia rovina??
@inproceedings{ziparo2013exploration,
  title={Exploration and mapping of catacombs with mobile robots},
  author={V.A. Ziparo and M. Zaratti and G. Grisetti and 
  T. M. Bonanni and J. Serafin and M. Di Cicco and 
  M. Proesmans and L. van Goola and O. Vysotska and I. Bogoslavskyi 
  and others},
  booktitle={2013 IEEE International Symposium on Safety, Security, and Rescue 
  Robotics (SSRR)},
  pages={1--2},
  year={2013},
  organization={IEEE}
}

@article{bradski2000opencv,
	title={OpenCV},
	author={G. Bradski and A. Kaehler},
	journal={Dr. Dobb’s journal of software tools},
	volume={3},
	year={2000}
}
 

% surf
@inproceedings{bay2006surf,
	title={Surf: Speeded up robust features},
	author={H. Bay and T. Tuytelaars and L. Van Gool},
	booktitle=eccv,
	pages={404--417},
	year={2006}
}

% superpoints
@inproceedings{detone2018superpoint,
	title={Superpoint: Self-supervised interest point detection and description},
	author={D. DeTone and T. Malisiewicz and A. Rabinovich},
	booktitle=cvprw,
	pages={224--236},
	year={2018}
}

%ia stanford dataset
@inproceedings{teichman2011towards,
  title={Towards 3D object recognition via classification of arbitrary object 
  tracks},
  author={A. Teichman and J. Levinson and S. Thrun},
  booktitle=icra,
  pages={4034--4041},
  year={2011},
  organization={IEEE}
}

%ia kitti dataset
@article{geiger2013vision,
  title={Vision meets robotics: The kitti dataset},
  author={A. Geiger and P. Lenz and C. Stiller and R. Urtasun},
  journal=ijrr,
  volume={32},
  number={11},
  pages={1231--1237},
  year={2013},
}

@article{pandey2011ford,
	title={Ford campus vision and lidar data set},
	author={G. Pandey and J. R. McBride and R. M. Eustice},
	  journal=ijrr,
	volume={30},
	number={13},
	pages={1543--1552},
	year={2011},
}

%ia oxford dataset
@article{maddern2017oxford,
  title={1 year, 1000 km: The Oxford RobotCar dataset},
  author={W. Maddern and G. Pascoe and C. Linegar and P. Newman},
  journal=ijrr,
  volume={36},
  number={1},
  pages={3--15},
  year={2017},
}

%ia kaist multispectral dataset
@article{choi2018kaist,
  title={KAIST multi-spectral day/night data set for autonomous and assisted 
  driving},
  author={Y. Choi and and N. Kim and S. Hwang and K. Park and 
  J. S. Yoon and K. An and I. S. Kweon},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={19},
  number={3},
  pages={934--948},
  year={2018},
}

%ia fast feature detector
@inproceedings{rosten2006machine,
  title={Machine learning for high-speed corner detection},
  author={E. Rosten and T. Drummond},
  booktitle=eccv,
  pages={430--443},
  year={2006},
  organization={Springer}
}

%ia harris corner detector
@inproceedings{harris1988combined,
  title={A combined corner and edge detector.},
  author={C.G. Harris and M. Stephens and others},
  booktitle={Alvey vision conference},
  volume={15},
  number={50},
  pages={10--5244},
  year={1988},
  organization={Citeseer}
}

%ia shi gfft
@inproceedings{shi1994good,
  title={Good features to track},
  author={J. Shi and others},
  booktitle=cvpr,
  pages={593--600},
  year={1994},
  organization={IEEE}
}

%ia book on opencv?
@book{bradski2008learning,
  title={Learning OpenCV: Computer vision with the OpenCV library},
  author={G. Bradski and A. Kaehler},
  year={2008},
  publisher={" O'Reilly Media, Inc."}
}

%ia sift descriptor
@article{lowe2004sift,
  title={Distinctive image features from scale-invariant keypoints},
  author={D. G. Lowe},
  journal={International journal of computer vision},
  volume={60},
  number={2},
  pages={91--110},
  year={2004},
}

%ia surf descriptor
@article{bay2008speeded,
  title={Speeded-up robust features (SURF)},
  author={H. Bay and A. Ess and T. Tuytelaars and L. Van Gool},
  journal={Computer vision and image understanding},
  volume={110},
  number={3},
  pages={346--359},
  year={2008},
}

%ia brisk binary descriptor
@inproceedings{leutenegger2011brisk,
  title={BRISK: Binary robust invariant scalable keypoints},
  author={S. Leutenegger and M. Chli and R. Y. Siegwart},
  booktitle=iccv,
  pages={2548--2555},
  year={2011},
  organization={IEEE}
}

%ia orb binary descriptor
@inproceedings{rublee2011orb,
  title={ORB: An efficient alternative to SIFT or SURF},
  author={E. Rublee and V. Rabaud and K. Konolige and G. Bradski},
  booktitle=iccv,
  pages={2564--2571},
  year={2011}
}

%ia freak binary descriptor
@inproceedings{alahi2012freak,
  title={Freak: Fast retina keypoint},
  author={A. Alahi and R. Ortiz and P. Vandergheynst},
  booktitle=cvpr,
  pages={510--517},
  year={2012},
  organization={IEEE}
}

%ia akaze binary descriptor
@article{alcantarilla2011fast,
  title={Fast explicit diffusion for accelerated features in nonlinear scale 
  spaces},
  author={P. F. Alcantarilla and T. Solutions},
  journal={IEEE Trans. Patt. Anal. Mach. Intell},
  volume={34},
  number={7},
  pages={1281--1298},
  year={2011},
}

%ia point-cloud semantic segmentation
@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and 
  segmentation},
  author={C. R. Qi and H. Su and K. Mo and L. J. Guibas},
  booktitle=cvpr,
  pages={652--660},
  year={2017}
}

@inproceedings{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a 
  metric space},
  author={C. R. Qi and L. Yi and H. Su and L. J. Guibas},
  booktitle=nips,
  pages={5099--5108},
  year={2017}
}

@inproceedings{wu2018squeezeseg,
  title={Squeezeseg: Convolutional neural nets with recurrent crf for real-time 
  road-object segmentation from 3d lidar point cloud},
  author={B. Wu and A. Wan and X. Yue and K. Keutzer},
  booktitle=icra,
  pages={1887--1893},
  year={2018},
  organization={IEEE}
}

@article{milioto2019rangenetpp,
  title={RangeNet ++: Fast and Accurate LiDAR Semantic Segmentation},
  author={A. Milioto and I. Vizzo and J. B. and C. Stachniss},
  journal=iros,
  year={2019},
  pages={4213-4220}
}

%ia sota v-slam
@article{mur2017orb,
  title={Orb-slam2: An open-source slam system for monocular, stereo, and rgb-d 
  cameras},
  author={R. Mur-Artal and J. D. Tard{\'o}s},
  journal=tro,
  volume={33},
  number={5},
  pages={1255--1262},
  year={2017},
}

%lidar slam, no intensity
@inproceedings{droeschel2018efficient,
	title={Efficient continuous-time SLAM for 3D lidar-based online mapping},
	author={D. Droeschel and S. Behnke},
	booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
	pages={5000--5007},
	year={2018},
	organization={IEEE}
}

@article{qin2018vins,
  title={Vins-mono: A robust and versatile monocular visual-inertial state 
  estimator},
  author={T. Qin and P. Li and S. Shen},
  journal=tro,
  volume={34},
  number={4},
  pages={1004--1020},
  year={2018},
}

% robust vpr
@INPROCEEDINGS{7989366,
	author={Z. {Chen} and A. {Jacobson} and N. {Sünderhauf} and B. {Upcroft} and L. {Liu} and C. {Shen} and I. {Reid} and M. {Milford}},
	journal=icra,
	title={Deep learning features at scale for visual place recognition}, 
	year={2017},
	volume={},
	number={},
	pages={3223-3230},
	doi={10.1109/ICRA.2017.7989366}}

%ia -------------------------------------------------------------------
%ia -------------------------- related works --------------------------
%ia -------------------------------------------------------------------

%ia camera based vpr
@article{lowry2015visual,
  title={Visual place recognition: A survey},
  author={S. Lowry and N. S{\"u}nderhauf and P. Newman and 
  J. J. Leonard and D. Cox and P. Corke and M. J. Milford},
  journal=tro,
  volume={32},
  number={1},
  pages={1--19},
  year={2015},
}

%ia precursor 1: spin images
@article{johnson1997spin,
  title={Spin-images: a representation for 3-D surface matching},
  author={A. E. Johnson},
  year={1997},
  publisher={Citeseer}
}

%ia precursor 2
@phdthesis{huber2002automatic,
  title={Automatic three-dimensional modeling from reality},
  author={D. F. Huber and M. Hebert},
  year={2002},
}

%ia nice features based on objects
@inproceedings{steder2009robust,
  title={Robust on-line model-based object detection from range images},
  author={B. Steder and G. Grisetti and M. Van Loock and 
  W. Burgard},
  booktitle=iros,
  pages={4739--4744},
  year={2009},
  organization={IEEE}
}

%ia point features search
@inproceedings{steder2010robust,
  title={Robust place recognition for 3D range data based on point features},
  author={B. Steder and G. Grisetti and W. Burgard},
  booktitle=icra,
  pages={1400--1405},
  year={2010},
  organization={IEEE}
}

%ia narf features
@inproceedings{steder2011point,
  title={Point feature extraction on 3D range scans taking into account object 
  boundaries},
  author={B. Steder and R. B. Rusu and K. Konolige and W. Burgard},
  booktitle=icra,
  pages={2601--2608},
  year={2011},
  organization={IEEE}
}

%ia improved point features search w/ BoW
@inproceedings{steder2011place,
  title={Place recognition in 3D scans using a combination of bag of words and 
  point feature based relative pose estimation},
  author={B. Steder and M. Ruhnke and S. Grzonka and 
  W. Burgard},
  booktitle=iros,
  pages={1249--1255},
  year={2011},
  organization={IEEE}
}

@inproceedings{calonder2010brief,
	title={Brief: Binary robust independent elementary features},
	author={M. Calonder and V. Lepetit and C. Strecha and P. Fua},
	booktitle=eccv,
	pages={778--792},
	year={2010},
	organization={Springer}
}

%ia NDT-based loop closures
@article{magnusson2009automatic,
  title={Automatic appearance-based loop detection from three-dimensional laser 
  data using the normal distributions transform},
  author={M. Magnusson and H. Andreasson and A. N{\"u}chter and 
  A. J. Lilienthal},
  journal=jfr,
  volume={26},
  number={11-12},
  pages={892--914},
  year={2009},
  publisher={Wiley Online Library}
}

%ia histograms similarity on depth images
@inproceedings{rohling2015fast,
  title={A fast histogram-based similarity measure for detecting loop closures 
  in 3-d lidar data},
  author={T. R{\"o}hling and J. Mack and D. Schulz},
  booktitle=iros,
  pages={736--741},
  year={2015},
}

%ia local histogram-based descriptor computed on intensity images (DELIGHT)
@inproceedings{cop2018delight,
  title={DELIGHT: An efficient descriptor for global localisation using LiDAR 
  intensities},
  author={K. P. Cop and P. VK Borges and R. Dub{\'e}},
  booktitle=icra,
  pages={3653--3660},
  year={2018},
}

%ia local descriptor combining depth and intensity data (ISHOT)
@article{guo2019local,
  title={Local descriptor for robust place recognition using LiDAR intensity},
  author={J. Guo and P. VK Borges and C. Park and A. Gawel},
  journal=ral,
  volume={4},
  number={2},
  pages={1470--1477},
  year={2019},
}

%ia netvlag holistic descriptors + pointnet
@inproceedings{arandjelovic2016netvlad,
  title={NetVLAD: CNN architecture for weakly supervised place recognition},
  author={R. Arandjelovicand and P. Gronat and A. Torii and T. Pajdla and J. Sivic},
  booktitle=cvpr,
  pages={5297--5307},
  year={2016}
}

%ia segment based matching for loop-closures detection
@inproceedings{dube2017segmatch,
  title={Segmatch: Segment based place recognition in 3d point clouds},
  author={R. Dub{\'e} and D. Dugas and E. Stumm and J. Nieto
  and R. Siegwart and C. Cadena},
  booktitle=icra,
  pages={5266--5272},
  year={2017},
}

%ia end-to-end CNN (pointnet) that computes vlad decriptors (from depth images)
@inproceedings{angelina2018pointnetvlad,
  title={Pointnetvlad: Deep point cloud based retrieval for large-scale place 
  recognition},
  author={M. Angelina Uy and G. Hee Lee},
  booktitle=cvpr,
  pages={4470--4479},
  year={2018}
}

%ia semantically-aided NDT histograms
@inproceedings{zaganidis2019semantically,
  author={A. {Zaganidis} and A. {Zerntev} and T. {Duckett} and G. {Cielniak}},
  booktitle=iros, 
  title={Semantically Assisted Loop Closure in SLAM Using NDT Histograms}, 
  year={2019},
  pages={4562-4568},
}
 
@InProceedings{linegar2015icra,
  author        = {C. Linegar and W. Churchill and P. Newman},
  title         = {{Work Smart, Not Hard: Recalling Relevant Experiences for Vast-Scale but Time-Constrained Localisation}},
  booktitle     = icra,
  year          = 2015,
  keywords      = {Localization, Mapping, Computer Vision for Robotics and Automation},
  abstract      = {This paper is about life-long vast-scale localisation in spite of changes in weather, lighting and scene structure. Building upon our previous work in Experience-based Navigation [1], we continually grow and curate a visual map of the world that explicitly supports multiple representations of the same place. We refer to these representations as experiences, where a single experience captures the appearance of an environment under certain conditions. Pedagogically, an experience can be thought of as a visual memory. By accumulating experiences we are able to handle cyclic appearance change (diurnal lighting, seasonal changes, and extreme weather conditions) and also adapt to slow structural change. This strategy, although elegant and effective, poses a new challenge: In a region with many stored representations which one(s) should we try to localise against given finite computational resources? By learning from our previous use of the experience-map, we can make predictions about which memories we should consider next, conditioned on how the robot is currently localised in the experience-map. During localisation, we prioritise the loading of past experiences in order to minimise the expected computation required. We do this in a probabilistic way and show that this memory policy significantly improves localisation efficiency, enabling long-term autonomy on robots with limited computational resources. We demonstrate and evaluate our system over three challenging datasets, totalling 206km of outdoor travel. We demonstrate the system in a diverse range of lighting and weather conditions, scene clutter, camera occlusions, and permanent structural change in the environment.},
}



@Article{milford2013ijrr,
  title         = {Vision-based place recognition: how low can you go?},
  author        = {M. Milford},
  journal       = ijrr,
  volume        = {32},
  number        = {7},
  pages         = {766--789},
  year          = {2013},
  publisher     = {SAGE Publications},
}


@InProceedings{milford2012icra,
  author        = {M. Milford and G.F. Wyeth},
  booktitle     = icra,
  title         = {{SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights.}},
  year          = {2012},
  keywords      = {Localization, Visual Navigation, Place Recognition},
}

@Article{valgren2010jras,
  author        = {C. Valgren and A.J. Lilienthal },
  title         = {{SIFT, SURF \& Seasons: Appearance-Based Long-Term Localization in Outdoor Environments}},
  journal       = jras,
  number        = 2,
  year          = 2010,
  volume        = {85},
  pages         = {149-156},
  keywords      = {Localization, Image Features},
}



@InProceedings{cummins2009rss,
  author        = {M. Cummins AND P. Newman},
  title         = {Highly scalable appearance-only {SLAM} - {FAB-MAP} 2.0},
  booktitle     = rss,
  year          = 2009,
  keywords      = {SLAM, Localization, Visual Navigation, Place Recognition},
}

@InProceedings{stumm2015icra,
  author        = {E. Stumm and C. Mei and S. Lacroix and M. Chli},
  title         = {{Location Graphs for Visual Place Recognition}},
  booktitle     = icra,
  year          = 2015,
  keywords      = {Visual Place Recognition, Autonomous Navigation, Mapping},
  abstract      = {With the growing demand for deployment of robots in real scenarios, robustness in the perception capabilities for navigation lies at the forefront of research interest, as this forms the backbone of robotic autonomy. Existing place recognition approaches traditionally follow the feature-based bag-of-words paradigm in order to cut down on the richness of information in images. As structural information is typically ignored, such methods suffer from perceptual aliasing and reduced recall, due to the ambiguity of observations. In a bid to boost the robustness of appearance-based place recognition, we consider the world as a continuous constellation of visual words, while keeping track of their covisibility in a graph structure. Locations are queried based on their appearance, and modelled by their corresponding cluster of landmarks from the global covisibility graph, which retains important relational information about landmarks. Complexity is reduced by comparing locations by their graphs of visual words in a simplified manner. Test results show increased recall performance and robustness to noisy observations, compared to state-of-the-art methods.},
}

@Article{bay2008cviu,
  author        = {H. Bay and A. Ess and T. Tuytelaars and L. Van Gool},
  title         = {Speeded-Up Robust Features ({SURF})},
  journal       = cviu,
  volume        = {110},
  number        = {3},
  year          = 2008,
  pages         = {346--359},
  keywords      = {Image Features},
}

@Article{lowe2004ijcv,
  author        = {D. G. Lowe},
  title         = {{Distinctive Image Features from Scale-Invariant Keypoints}},
  journal       = ijcv,
  volume        = {60},
  number        = {2},
  year          = 2004,
  issn          = {0920-5691},
  pages         = {91--110},
  numpages      = {20},
  keywords      = {Localization, Image Features},
}

%ia monte-carlo localization
@inproceedings{sun2020localising,
  title={Localising Faster: Efficient and precise lidar-based robot 
  localisation in large-scale environments},
  author={L. Sun and D. Adolfsson and M. Magnusson and H. Andreasson and I. Posner and T. Duckett},
  booktitle=icra,
  year={2020},
}

%ia lidar slam systems
@inproceedings{della2018general,
  title={A general framework for flexible multi-cue photometric point cloud 
  registration},
  author={B. Della Corte and I. Bogoslavskyi and C. Stachniss 
  and G. Grisetti},
  booktitle=icra,
  pages={1--8},
  year={2018},
}

@inproceedings{deschaud2018imls,
  title={IMLS-SLAM: scan-to-model matching based on 3D data},
  author={J. Deschaud},
  booktitle=icra,
  pages={2480--2485},
  year={2018},
}

@inproceedings{zhang2014loam,
  title={LOAM: Lidar Odometry and Mapping in Real-time.},
  author={J. Zhang and S. Singh},
  booktitle=rss,
  year={2014}
}

@inproceedings{zhang2015visual,
  title={Visual-lidar odometry and mapping: Low-drift, robust, and fast},
  author={J. Zhang and S. Singh},
  booktitle=icra,
  pages={2174--2181},
  year={2015},
}

%ia ICP based loop closures (very costly)
@inproceedings{behley2018efficient,
  title={Efficient Surfel-Based SLAM using 3D Laser Range Data in Urban 
  Environments.},
  author={J. Behley and C. Stachniss},
  booktitle=rss,
  year={2018}
}

%tof lidar power equation
@article{rasshofer2011influences,
	title={Influences of weather phenomena on automotive laser radar systems},
	author={H. Ralph Rasshofer and M. Spies and H. Spies},
	journal={Advances in Radio Science},
	volume={9},
	number={B. 2},
	pages={49--60},
	year={2011},
	publisher={Copernicus GmbH}
}

@inproceedings{mcmanus2012visual,
	title={Visual teach and repeat using appearance-based lidar},
	author={C. McManus and P. Furgale and B. Stenning and T.D. Barfoot},
	booktitle=icra,
	pages={389--396},
	year={2012},
	organization={IEEE}
}

@inproceedings{zywanowski2020comparison,
	title={Comparison of camera-based and 3D LiDAR-based place recognition across weather conditions},
	author={K. {\.Z}ywanowski and A. Banaszczyk and M. R. Nowicki},
	booktitle=icarcv,
	pages={886--891},
	year={2020},
	organization={IEEE}
}


%%%%% from here pure md slam %%%%%

@article{strasdat2010scale,
	title={Scale drift-aware large scale monocular SLAM},
	author={H. Strasdat and J. Montiel and A. J. Davison},
	journal={Robotics: Science and Systems VI},
	volume={2},
	number={3},
	pages={7},
	year={2010},
	publisher={}
}

@article{guadagnino2022hipe,
	author={T. Guadagnino and L. Di Giammarino and G. Grisetti},
	journal=ral, 
	title={HiPE: Hierarchical Initialization for Pose Graphs}, 
	year={2022},
	volume={7},
	number={1},
	pages={287-294},
	doi={10.1109/LRA.2021.3125046}}

@inproceedings{schops2019bad,
	title={Bad SLAM: Bundle adjusted direct RGBD-D SLAM},
	author={T. Schops and T. Sattler and M. Pollefeys},
	booktitle=cvpr,
	pages={134--144},
	year={2019}
}

@inproceedings{newcombe2011kinectfusion,
	title={Kinectfusion: Real-time Dense Surface Mapping and Tracking},
	author={R. A. Newcombe S. Izadi and O. Hilliges and D. Molyneaux and D. Kim and A. J. Davison and P. Kohi and J. Shotton and S. Hodges and A. Fitzgibbon},
	booktitle=ismar,
	pages={127--136},
	year={2011}
}


@inproceedings{keller2013pointfusion,
	title={Realtime 3D Reconstruction in Dynamic Scenes using Pointbased Fusion},
	author={M. Keller and D. Lefloch and M. Lambers and S. Izadi},
	booktitle=threedv,
	pages={1--8},
	year={2013}
}

@inproceedings{kerl2013dense,
	title={Dense visual SLAM for RGB-D cameras},
	author={C. Kerl and J. Sturm and D. Cremers},
	booktitle=iros,
	pages={2100--2106},
	year={2013}
}

@inproceedings{wang2016online,
	title={Dense visual SLAM for RGB-D cameras},
	author={H. Wang and J. Wang and L. Wang},
	booktitle=cvpr,
	year={2016}
}


@inproceedings{shan2018lego,
	title={LeGO-LOAM: Lightweight and Ground-optimized LiDAR Odometry and Mapping on Variable Terrain},
	author={T. Shan and B. Englot},
	booktitle=iros,
	pages={4758--4765},
	year={2018}
}

@article{stoyanov2012fast,
	title={Fast and Accurate Scan Registration through Minimization of the Distance between Compact 3D NDT Representations},
	author={T. Stoyanov and M. Magnusson and H. Andreasson  and A. J. Lilienthal},
	journal=ijrr,
	volume={31},
	number={12},
	pages={1377--1393},
	year={2012},
	publisher={Sage Publications Sage UK: London, England}
}

@inproceedings{velas2016collar,
	title={Collar Line Segments for Fast Odometry Estimation from Velodyne Point Clouds},
	author={M. Velas and M. Spanel and A. Herout},
	booktitle=icra,
	pages={4486--4495},
	year={2016}
}

@inproceedings{besl1992method,
	title={Method for registration of 3-D shapes},
	author={P.J. Besl and N.D. McKay},
	booktitle={Sensor fusion IV: control paradigms and data structures},
	volume={1611},
	pages={586--606},
	year={1992},
	organization={Spie}
}

@inproceedings{segal2009generalized,
	title={Generalized-ICP},
	author={A. Segal and D. Haehnel and S. Thrun},
	booktitle={Proc of Robotics: Science and Systems},
	year={2009}
}

@inproceedings{schlegel2018proslam,
	title={Proslam: Graph SLAM from a programmer's Perspective},
	author={D. Schlegel and M. Colosi and G. Grisetti},
	booktitle=icra,
	pages={3833--3840},
	year={2018},
	organization={IEEE}
}

@article{horn1988closed,
	title={Closed-form solution of absolute orientation using orthonormal matrices},
	author={B. Horn and H. Hilden and S. Negahdaripour},
	journal={JOSA A},
	volume={5},
	number={7},
	pages={1127--1135},
	year={1988},
	publisher={Optical Society of America}
}

@inproceedings{di2021visual,
	title={Visual place recognition using LiDAR intensity information},
	author={L. Di Giammarino and I. Aloise and C. Stachniss and G. Grisetti},
	booktitle=iros,
	pages={4382--4389},
	year={2021}
}


@article{grisetti2020least,
	title={Least squares optimization: From theory to practice},
	author={G. Grisetti and T. Guadagnino and I. Aloise and M. Colosi and B. Della Corte and D. Schlegel},
	journal={Robotics},
	volume={9},
	number={3},
	pages={51},
	year={2020},
	publisher={Multidisciplinary Digital Publishing Institute}
}

@inproceedings{nuchter2005heuristic,
	title={Heuristic-based laser scan matching for outdoor 6D SLAM},
	author={A. N{\"u}chter and K. Lingemann and J. Hertzberg and H. Surmann},
	booktitle={Annual Conf. on Artificial Intelligence},
	pages={304--319},
	year={2005}
}

@inproceedings{williams2007real,
	title={Real-time SLAM relocalisation},
	author={B. Williams and G. Klein I. and Reid},
	booktitle=iccv,
	pages={1--8},
	year={2007}
}

@article{kaess2008isam,
	title={iSAM: Incremental Smoothing and Mapping},
	author={M. Kaess and A. Ranganathan and F. Dellaert},
	journal=tro,
	volume={24},
	number={6},
	pages={1365--1378},
	year={2008},
	publisher={IEEE}
}

@inproceedings{grisetti2011g2o,
	title={g2o: A general framework for (hyper) graph optimization},
	author={G. Grisetti and R. K{\"u}mmerle and H. Strasdat and K. Konolige},
	booktitle=icra,
	pages={9--13},
	year={2011}
}


@inproceedings{engel2014lsd,
	title={LSD-SLAM: Large-scale direct monocular SLAM},
	author={J. Engel and T. Sch{\"o}ps and D. Cremers},
	booktitle=eccv,
	pages={834--849},
	year={2014}
}

@inproceedings{serafin2016fast,
	title={Fast and robust 3d feature extraction from sparse point clouds},
	author={J. Serafin, E. Olson and G. Grisetti},
	booktitle=iros,
	pages={4105--4112},
	year={2016}
}

@INPROCEEDINGS{ramezani2020newer,
	author={M. Ramezani and Y. Wang and M. Camurri and D. Wisth and M. Mattamala and M. Fallon},
	booktitle=iros, 
	title={The Newer College Dataset: Handheld LiDAR, Inertial and Vision with Ground Truth}, 
	year={2020},
	volume={},
	number={},
	pages={4353-4360},
	doi={10.1109/IROS45743.2020.9340849}}

@article{zhang2021multicamera,
	title={Multi-Camera LiDAR Inertial Extension to the Newer College Dataset. \textit{arXiv}, 2112.08854},
	author={L. Zhang and M. Camurri and M. Fallon},
	year={2021},
	eprint={2112.08854},
	archivePrefix={arXiv}
}

@inproceedings{sturm2012benchmark,
	title={A benchmark for the evaluation of RGB-D SLAM systems},
	author={J. Sturm and N. Engelhard and F. Endres and W. Burgard and D. Cremers},
	booktitle=iros,
	pages={573--580},
	year={2012}
}

@inproceedings{whelan2015elasticfusion,
	title={ElasticFusion: Dense SLAM without a pose graph},
	author={T. Whelan and S. Leutenegger and R. Salas-Moreno and B. Glocker and A. Davison},
	year={2015},
	booktitle=rss
}

@book{higham2002accuracy,
	title={Accuracy and Stability of Numerical Algorithms},
	author={N. J. Higham},
	year={2002},
	publisher={SIAM}
}


@article{liu2021balm,
	title={Balm: Bundle adjustment for lidar mapping},
	author={Z. Liu and F. Zhang},
	journal=ral,
	volume={6},
	number={2},
	pages={3184--3191},
	year={2021},
	publisher={IEEE}
}

@article{dai2017bundlefusion,
	title={Bundlefusion: Real-time globally consistent 3d reconstruction using on-the-fly surface reintegration},
	author={A. Dai and M. Nie{\ss}ner and M. Zollh{\"o}fer and S. Izadi and C. Theobalt},
	journal=tog,
	volume={36},
	number={4},
	pages={1},
	year={2017},
	publisher={ACM}
}

@inproceedings{di2022md,
	title={MD-SLAM: Multi-cue Direct SLAM},
	author={L. Di Giammarino and L. Brizi and T. Guadagnino and C. Stachniss and G. Grisetti},
	booktitle=iros,
	pages={11047--11054},
	year={2022},
	organization={IEEE}
}


@INPROCEEDINGS{ramezani2020newer,
	author={M. Ramezani and Y. Wang and M. Camurri and D. Wisth and M. Mattamala and M. Fallon},
	booktitle=iros, 
	title={The Newer College Dataset: Handheld LiDAR, Inertial and Vision with Ground Truth}, 
	year={2020},
	volume={},
	number={},
	pages={4353-4360},
	doi={10.1109/IROS45743.2020.9340849}}


@inproceedings{sturm2012benchmark,
	title={A benchmark for the evaluation of RGB-D SLAM systems},
	author={J. Sturm and N. Engelhard and F. Endres and W. Burgard and D. Cremers},
	booktitle=iros,
	pages={573--580},
	year={2012}
}

@book{higham2002accuracy,
	title={Accuracy and Stability of Numerical Algorithms},
	author={N. J. Higham},
	year={2002},
	publisher={SIAM}
}

@inproceedings{fantoni2012accurate,
	title={Accurate and automatic alignment of range surfaces},
	author={S. Fantoni and U. Castellani and A. Fusiello},
	booktitle={Second International Conference on 3D Imaging, Modeling, Processing, Visualization \& Transmission},
	pages={73--80},
	year={2012},
	organization={IEEE}
}

@inproceedings{klein2007parallel,
	title={Parallel tracking and mapping for small AR workspaces},
	author={G. Klein and D. Murray},
	booktitle={6th IEEE and ACM international symposium on mixed and augmented reality},
	pages={225--234},
	year={2007},
	organization={IEEE}
}

@article{forster2016svo,
	title={SVO: Semidirect visual odometry for monocular and multicamera systems},
	author={C. Forster and Z. Zhang and M. Gassner and M. Werlberger and D. Scaramuzza},
	journal=tro,
	volume={33},
	number={2},
	pages={249--265},
	year={2016},
	publisher={IEEE}
}

@inproceedings{delaunoy2014photometric,
	title={Photometric bundle adjustment for dense multi-view 3d modeling},
	author={A. Delaunoy and M. Pollefeys},
	booktitle=cvpr,
	pages={1486--1493},
	year={2014}
}

@article{goldlucke2014super,
	title={A super-resolution framework for high-accuracy multiview reconstruction},
	author={B. Goldl{\"u}cke and M. Aubry and K. Kolev and D. Cremers},
	journal=ijcv,
	volume={106},
	pages={172--191},
	year={2014},
	publisher={Springer}
}

@inproceedings{slavcheva2016sdf,
	title={SDF-2-SDF: Highly accurate 3d object reconstruction},
	author={M. Slavcheva and W. Kehl and N. Navab and S. Ilic},
	booktitle=eccv,
	pages={680--696},
	year={2016},
	organization={Springer}
}

@inproceedings{alismail2017photometric,
	title={Photometric bundle adjustment for vision-based slam},
	author={H. Alismail and B. Browning and S. Lucey},
	booktitle=accv,
	pages={324--341},
	year={2017},
	organization={Springer}
}


@inproceedings{demmel2020distributed,
	title={Distributed photometric bundle adjustment},
	author={N. Demmel and M. Gao and E. Laude and T. Wu and D. Cremers},
	booktitle=threedv,
	pages={140--149},
	year={2020},
	organization={IEEE}
}

@inproceedings{eriksson2016consensus,
	title={A consensus-based framework for distributed bundle adjustment},
	author={A. Eriksson and J. Bastian and T. Chin and M. Isaksson},
	booktitle=cvpr,
	pages={1754--1762},
	year={2016}
}

@inproceedings{triggs2000bundle,
	title={Bundle adjustment - a modern synthesis},
	author={B. Triggs and P. F. McLauchlan and R. I. Hartley and A. W. Fitzgibbon},
	booktitle={International Workshop on Vision Algorithms},
	pages={298--372},
	year={2000},
	organization={Springer}
}

@inproceedings{zhang2016degeneracy,
	title={On degeneracy of optimization-based state estimation problems},
	author={J. Zhang and M. Kaess and S. Singh},
	booktitle=icra,
	pages={809--816},
	year={2016}
}

@inproceedings{mactavish2015all,
  title={At all costs: A comparison of robust cost functions for camera correspondence outliers},
  author={K. MacTavish and T. D. Barfoot},
  booktitle={IEEE Trans. on Computer and Robot Vision},
  pages={62--69},
  year={2015}
}

@article{chen1992object,
	title={Object modelling by registration of multiple range images},
	author={Y. Chen and G. Medioni},
	journal={Image and Vision Computing},
	volume={10},
	number={3},
	pages={145--155},
	year={1992},
	publisher={Elsevier}
}
