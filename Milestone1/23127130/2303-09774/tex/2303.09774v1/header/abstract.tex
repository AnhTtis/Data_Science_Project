\begin{abstract}

With data pipeline tools and the expressiveness of SQL,
    managing 
        interdependent materialized views (MVs)
    are becoming increasingly easy.
These MVs 
        are updated repeatedly upon new data ingestion (e.g., daily),
        from which database admins can observe performance metrics
    (e.g., refresh time of each MV, size on disk)
    in a consistent way for different types of updates (full vs.~incremental)
        and for different systems (single node, distributed, cloud-hosted).
One missed opportunity is that
    existing data systems treat those MV updates 
        as independent SQL statements
            without fully exploiting their dependency information and performance metrics.
However,
    if we know that the result of a SQL statement will
        be consumed immediately after for subsequent operations,
    those subsequent operations do not have to wait until the early results
        are fully materialized on storage
    because the results are already readily available in memory.
Of course, this may come at a cost
    because keeping those results in memory (even temporarily)
        will reduce the amount of available memory;
    thus, our decision should be careful.

In this paper, we introduce a new system, called \system, which tackles this problem
  through \emph{efficient creation and update of a set of MVs with acyclic dependencies among them.}
\system judiciously uses bounded memory
    to reduce the end-to-end MV refresh time by
short-circuiting expensive reads and writes;
\system's objective function accurately estimates 
the time savings from
keeping intermediate data in memory for particular periods.
Our solution jointly optimizes an MV refresh order, 
what data to keep in memory, 
and when to release the data from memory.
At a high level, \system still materializes all data exactly as defined in MV definitions; 
thus, it does not impact any service-level agreements.
In our experiments with TPC-DS datasets (up to 1TB), 
we show that \system's optimization can speedup end-to-end runtime by 1.04$\times$--5.08$\times$
with (only) 1.6GB memory.


% To maximize compute reuse,
%     people use
%     materialized views are often
%         dependent on one another.
% For fast querying,
% people frequently employ 
%     materialized views (MVs) and/or intermediate tables,
%         which are often dependent one another.
% These MVs are updated repetitively
%     upon new data ingestion
%         according to 
% When updating such interdependent MVs,
%     existing data systems process
%         each MV update independently without special optimizations.
% Our idea is that
    

% By using materialized views (MVs),
% we can greatly speed up OLAP queries.
% % are effective in speeding up analytical queries;
% However, maintaining MVs can be costly.
% First, to avoid returning stale data,
% MVs need to be updated upon new data ingestion.
% Second, MVs are often defined on top of other MVs, 
% which requires cascade updates.
% Third, data volume and the diversity of query workloads 
% tend to increase over time,
% which makes MV maintenance increasingly expensive.
%
% Data transformation 
% services (e.g., Azure Data Factory, dbt, Matillion)
% accelerate this trend.
% Unfortunately, data warehouses (DWs) like Presto and SparkSQL are not 
% designed for efficient MV construction.
% That is, while DWs are good at processing
% individual queries,
% they are not optimized for updating a set
% of interdependent MVs.
% % of MVs 
% % with dependencies on one another.
% If we design a specialized engine for data transformation and materialization,
% there might be a chance for further optimizations we have missed.


% Compared to Presto+Parquet, 
% \system is 2.4$\times$--3.4$\times$ faster
% in updating all MVs.

% \system, a framework for speeding up end-to-end MV refresh runs which utilizes extra memory to reduce the I/O overhead by selectively storing intermediate tables.
% Tracking sizes and I/O costs of immediate tables, our proposed framework \textit{MemoryContainer} abstracts the visualization workflow as a dependency graph, and jointly computes the set of intermediate tables to store in memory and their execution order to maximize net time savings under the limited memory size.

% \todo{Yongjoo working here}

% We perform extensive experiments on the TPC-DS dataset using both the dataset's accompanying queries and realistic recurring jobs simulated with a data-driven query generator: 
% \textit{MemoryContainer} is able to reduce end-to-end job execution times by up to 50\% for simple and complex recurring jobs containing up to 100 intermediate table declarations alike.






\end{abstract}
