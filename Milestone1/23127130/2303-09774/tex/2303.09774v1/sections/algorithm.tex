\section{\optimizationproblem: Joint Optimization
}
\label{sec:joint_optimization}

We present our solution to \optimizationproblem. 
Unlike previous work on 
% While there exists works on both 
scheduling refresh order of a set of MVs~\cite{folkert2005optimizing,golab2009scheduling} 
and storing select intermediate data to reduce job latency~\cite{xin2021enhancing, wangtempura, jalaparti2018netco}, 
we are, to the best of our knowledge, the first to 
consider joint optimization of both items.

\optimizationproblem is NP-hard via a reduction from the 0-1 knapsack problem, which necessitates the usage of an efficient approximation algorithm. While \optimizationproblem has 2 distinct outputs flagged nodes $U$ and execution order $\tau$, standard alternating optimization~\cite{bezdek2002some} is not applicable due to improving $\tau$ while holding $U$ constant does not improve the objective function of total speedup score. We still decompose \optimizationproblem into 2 distinct subproblems and solve \optimizationproblem by starting from an initial execution order $\tau_0$ 
and an empty set of flagged nodes (i.e., $\mathcal{U}_0 = \emptyset$); however, differing from standard alternating optimization, we decompose \optimizationproblem into 2 subproblems with different objective functions:

\begin{problem}{\subproblemnodes}
\label{prof:optimization_nodes}
\begin{description}
\item[\normalfont Input:] Inputs of \optimizationproblem, \textbf{Execution order $\tau$}
\item[\normalfont Output:] Flagged nodes $\mathcal{U}$
\item[\normalfont Objective function:] Maximize total speedup score $\sum_{v_i \in \mathcal{U}} t_i$
\item[\normalfont Constraint:] Same as \optimizationproblem
\end{description}
\end{problem}

\begin{problem}{\subproblemorder}
\label{prof:optimization_order}
\begin{description}
\item[\normalfont Input:] Inputs of \optimizationproblem, \textbf{Flagged nodes $\mathcal{U}$}
\item[\normalfont Output:] Execution order $\tau$
\item[\normalfont Objective function:] Minimize average memory usage $\frac{1}{n}\sum_{i:v_i\in\mathcal{U}}(max_{(v_i, v_j)\in \mathcal{E}}\tau(j) - \tau(i))s_i)$
\item[\normalfont Constraint:] Same as \optimizationproblem
\end{description}
\end{problem}

Instead of improving the objective function, we 'relax the constraints' in \subproblemorder by using the average memory usage as its objective function, which we define as the average size of flagged nodes stored in \memory assuming unit job execution times ( illustrated as shaded regions in \cref{fig:dfs}).
A lower average memory usage corresponds to more efficient usage of \memory through a more timely release of flagged nodes, potentially allowing us to add more nodes into $\mathcal{U}$ in future iterations of alternating optimization.

We optimize for average memory usage in \subproblemorder despite peak memory usage being the constraint of \optimizationproblem due to the latter failing to meaningfully differentiate between execution orders.
\cref{fig:dfs} showcases an example: nodes $v_1, v_3, v_4, v_5$ are flagged. 
While both refresh orders have the same peak memory usage, the refresh order found by our solution to \subproblemorder (\solutionorder, \cref{sec:optimize_order}) attains the peak memory for a shorter period of time - hence having a lower average memory usage - allowing an additional node to be flagged in the next iteration of solving \subproblemnodes.

In the following subsections, we describe our solutions to \subproblemnodes (\Cref{sec:optimize_nodes}) and \subproblemorder (\Cref{sec:optimize_order}).
Finally, we explain
how we combine them to form our alternating optimization algorithm for solving  \optimizationproblem (\Cref{sec:optimize_all}).

\subsection{\subproblemnodes: Solution}
\label{sec:optimize_nodes}

We solve \subproblemnodes exactly by formulating it as a multidimensional 0-1 knapsack problem (MKP)~\cite{kellerer2004multidimensional}. We have also considered approximate solutions such as greedy algorithms; however, they exhibit considerably worse performance compared to our MKP formulation while having a negligible runtime advantage. (\Cref{sec:exp_algm})

\mypara{MKP Setup} For each node $v_i$ and execution order $\tau$, let $\mathcal{V}_i$ denote a set of nodes that, when flagged, will be kept in memory during the time of $v_i$'s execution.
According to the memory management scheme of \system, a flagged node $v_j$ is kept in memory at the time of $v_i$'s execution if there is at least 1 child of $v_j$ yet to be executed: 
\[
\mathcal{V}_i := \{v_j| \tau(j) \leq \tau(i) \leq max_{(v_j, v_k) \in \mathcal{E}}\tau(k)\}
\]\\[-1.5em]
The set of all $\mathcal{V}_i$s form the constraints of the MKP such that the total size of flagged nodes in each $\mathcal{V}_i$ does not exceed \memory size $M$.
Using speedup scores $\mathcal{T}$ as coefficients of the 
 MKP's objective function, we define \subproblemnodes in integer linear programming format\footnote{We round speedup scores to the nearest integer.} as follows:
 \vspace{-1mm}
\begin{equation*}
\begin{array}{ll@{}ll}
\text{maximize}  & \displaystyle\sum\limits_{i=1}^{n} &x_{i}t_{i} &\\
\text{subject to}& \displaystyle\sum\limits_{j:v_{j} \in \mathcal{V}_{i}}   &x_{j}s_{j} \leq M,  &i=1 ,\dots, n\\[-0.3em]
                 &                                                &x_{i} \in \{0,1\}, &i=1 ,\dots, n
\end{array}
\end{equation*}

\newlength{\textfloatsepsave} 
\setlength{\textfloatsepsave}{\textfloatsep} \setlength{\textfloatsep}{1pt}
\begin{algorithm}[t]
% \small
\caption{SimplifiedMKP \label{lm:computeflaggednodes}}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\Input{
  (1) Dependency graph $\mathcal{G} = \{\mathcal{V}, \mathcal{E}\}$ \\
  (2) Node sizes $\mathcal{S}$ and speedup scores $\mathcal{T}$ \\
  (3) \memory size $M$ \\
  (4) Execution order $\tau$
}
\Output{Set of flagged nodes $\mathcal{U}$}
Initialize $\mathcal{V}_{exclude} = \{v_i | s_i > M \lor t_i = 0\}$; \\
\texttt{constraint\_sets}$ = \texttt{GetConstraints}(\mathcal{G}, \mathcal{S}, \mathcal{V}_{exclude}, M, \tau)$; \\
Initialize $\mathcal{V}_{mkp} = \bigcup_{\mathcal{V}_i \in \texttt{constraint\_sets}}\mathcal{V}_i$; \\
Initialize $|$\texttt{constraint\_sets}$| = k, |\mathcal{V}_{mkp}| = l$;\\
Set profits $P_{1\times l} = [t_{i_1},...,t_{i_l}], v_{i_1},...,v_{i_l} \in \mathcal{V}_{mkp}$;\\
Set weights $W_{k\times l}, w_{xy} = (\text{if } v_{i_y} \in \mathcal{V}_x \text{ then } s_i \text{ else } 0),1\leq x\leq k, 1\leq y \leq l$;\\
Set capacities $C_{k\times 1} = [M,...,M]$;\\
$\mathcal{U} = \texttt{BinaryMKPSolver}(P, W, C)$;\\
$\mathcal{U} \leftarrow \mathcal{U} \cup (\mathcal{V} - \mathcal{V}_{mkp} - \mathcal{V}_{exclude})$;\\
\textbf{Return} the set of nodes to store in memory $\mathcal{U}$.
\end{algorithm}

\mypara{Simplifying the MKP} We proceed to simplify the MKP by identifying and removing redundant variables (nodes) present in the MKP. A node $v_i$ is redundant and does not need to be evaluated in the MKP if either:\begin{itemize}
    \item $s_i > M$: $v_i$ has size larger than \memory size ---flagging $v_i$ by itself violates the constraint
    \item $t_i = 0$: storing $v_i$ does not contribute to the objective
\end{itemize}
We can exclude such nodes from our constraint sets $\mathcal{V}_i$:
\begin{multline*}
\mathcal{V}_i := \{v_j| \tau(j) \leq \tau(i) \leq max_{(v_j, v_k) \in \mathcal{E}}\tau(k) \land v_j \not \in \mathcal{V}_{exclude}\}\\[-0.2em]
\text{where } \mathcal{V}_{exclude} := \{v_i |i: s_i > M \lor t_i = 0 \}
\end{multline*}
A constraint set $\mathcal{V}_i$ is redundant and does not need to be evaluated in the MKP if either:\begin{itemize}
    \item $\mathcal{V}_i$ is not maximal: $\exists~ \mathcal{V}_j s.t. \mathcal{V}_i \subsetneq \mathcal{V}_j$; the constraint set $\mathcal{V}_i$ is a strict subset of another constraint set $\mathcal{V}_j$
    \item $\mathcal{V}_i$ is trivial: $\sum_{j:v_j\in \mathcal{V}_i} s_j \leq M$; the constraint $\mathcal{V}_i$ cannot be violated even if all nodes in $\mathcal{V}_i$ are flagged
\end{itemize}

\ignore{
\paragraph{Example MKP simplification} Consider again the toy example in \cref{fig:toyexample}. Under execution order $\tau_2$ and \memory size $M = 100GB$, the constraint sets are as follows:
\begin{multicols}{2}
\begin{itemize}
    \item $\mathcal{V}_1 := \{v_1\}$
    \item $\mathcal{V}_2 := \{v_1, v_2\}$
    \item $\mathcal{V}_4 := \{v_1, v_2, v_4\}$
    \item $\mathcal{V}_3 := \{v_2, v_3, v_4\}$
    \item $\mathcal{V}_5 := \{v_2, v_3, v_4, v_5\}$
    \item $\mathcal{V}_6 := \{v_4, v_5, v_6\}$
\end{itemize}
\end{multicols}
Out of the constraint sets, $\mathcal{V}_1, \mathcal{V}_2, \mathcal{V}_3$ are not maximal, $\mathcal{V}_1, \mathcal{V}_2, \mathcal{V}_6$ are trivial, hence $\mathcal{V}_4$ and $\mathcal{V}_5$ are the only non-redundant constraints.
}


\mypara{Solving the MKP} 

We present our completed solution (\solutionnodes) to \subproblemnodes in \cref{lm:computeflaggednodes}.
The set of all relevant (maximal and non-trivial) constraint sets is efficiently computed with \texttt{GetConstraints} in linear time by a linear scan over the nodes (line 2).
Note that not every non-excluded node $v_i \in \mathcal{V} - \mathcal{V}_{exclude}$ appears in a constraint set. If a node does not appear in any constraint set and is also not in $\mathcal{V}_{exclude}$, it can be trivially flagged 
because doing so will not violate memory constraints; 
these nodes are manually added to the solution returned from the MKP solver (line 9).

We choose branch-and-bound method\footnote{Our \system implementation uses the BnB solver from Google OR-Tools~\cite{ortools}.} for subroutine \texttt{BinaryMKPSolver} (line 8). While the method has worst-case exponential time complexity, we empirically verify that \cref{lm:computeflaggednodes} has satisfactory scalability in general (\Cref{sec:exp_complexity}): it scales roughly linearly with the number of nodes in the dependency graph and takes on average 0.02 seconds to find the optimal set of nodes to flag in a 100-node graph.
\subsection{\subproblemorder: Solution}
\label{sec:optimize_order}

% The goal of solving 
% from solving \subproblemnodes so 
% Then, we can potentially add more nodes into $\mathcal{U}$ in future iterations of alternating optimization.

We solve \subproblemorder by formulating a \textit{memory-aware} DFS-based scheduling algorithm. 
We have experimented with other methods, such as hill-climbing~\cite{seitz2010contributions} and recursive graph separators~\cite{charikar2010l}\footnote{While there exists an ILP formulation for this problem, ~\cite{baruah2022ilp}, it contains $O(n^3)$ variables and constraints making it too inefficient for real-time scheduling. We defer exploration of this direction to future work.}, though we find them to be less effective in comparison. (\Cref{sec:exp_algm})
% which minimizes average memory usage at a conceptual level 
\mypara{Optimizing Average Memory Usage} 
The DFS-based scheduling algorithm aims to minimize the time between a node's execution and its children's by finishing a branch of execution before starting a new one, which 
minimizes average memory usage of flagged nodes by freeing them as soon as possible.
 \setlength{\textfloatsep}{\textfloatsepsave}
\subfile{plots/fig_dfs}
However, we find that off-the-shelf DFS-based sorts in existing work~\cite{marchal2018parallel} are insufficient in our case. 
In particular, DFS traversals must choose a path to proceed onto (tie-break) at branches, and a random selection without considering the node size can result in suboptimal performance. 
A random selection may keep large flagged nodes in memory for an extended period of time, which reduces the amount of memory space available for flagging additional nodes (see \cref{fig:dfs}). 
% for a demonstration).

\mypara{Memory-Aware DFS} To address this, we propose a \textit{memory-aware} DFS-based scheduling algorithm (\solutionorder),
    which prioritizes nodes with lower actual memory consumption to tie-break:
% % by incorporating the heuristic of actual memory consumption for tie-breaking. 
% For node sizes $\mathcal{S}$ and a set of flagged nodes $\mathcal{U}$, 
%     the actual memory consumption of a node $s'_i$ is defined as follows:
% $$s'_i := s_i \, \text{ if } \, v_i \in \mathcal{U}\, \text{ else }\, 0$$
A node's actual memory consumption is equal to its size if it is flagged and is equal to 0 otherwise.
% \solutionorder prioritizes 
% % computing 
% the nodes with lesser actual memory consumption.
% when performing 
% for tiebreaking with.
\solutionorder aims to compute the largest flagged dependencies (in terms of size) of a node last in order to minimize the time these large dependencies are kept in memory, which frees up memory space to potentially flag more nodes.

The toy example in \cref{fig:dfs} illustrates this idea.
We have \memory size $M=100GB$; for simplicity, assume the speedup score of a node is equal to its size in GB.
When performing tie-breaking between $v_2$ and $v_3$, \solutionorder schedules $v_2$ first as $v_3$ has higher actual memory consumption; despite being larger than $v_3$, $v_2$ is not flagged.
$v_3$ is kept in memory for only 3 node executions ($v_3$, $v_5$, $v_6$), freeing memory space for $v_6$ to be additionally flagged.
This would not be possible with a DFS-based sort with random tie-breaking in cases where it schedules $v_3$ instead of $v_2$ first. Such a sort would keep $v_3$ in memory for 5 node executions, taking up memory space that could have been used for flagging $v_6$.

% We use actual memory consumption instead of node size as large nodes which are not flagged either don't fit in extra memory or have a high opportunity cost associated with flagging:
% in the toy example, flagging $v_2$ restricts all nodes but $v_6$ from being flagged.
% Being able to hypothetically free these nodes earlier if they are flagged by scheduling them later in the execution order (i.e., scheduling $v_3$ as opposed to $v_2$ first in the example) contributes little to the optimization objective:
% these nodes are unlikely to be flagged in future iterations of solving \subproblemnodes due to the aforementioned issues.

We verify the validity of \solutionorder's execution order in each iteration of alternating optimization to preserve the memory constraint $M$.
In a rare case where \solutionorder outputs an infeasible execution order---violating the memory constraint $M$---we conclude that the execution order from the previous iteration of alternating optimization is optimal and terminate the alternating optimization algorithm.
While our solution may find locally optimal solutions, we empirically verify that the local optimums that our solution finds are still of high quality compared to solutions found by other methods. (\cref{sec:exp_algm})

\subsection{\optimizationproblem: Putting Everything Together}
\label{sec:optimize_all}

With solutions to both subproblems, we present our alternating optimization algorithm for solving \optimizationproblem in \cref{lm:jointoptimization}.

\setlength{\textfloatsep}{1pt}
\begin{algorithm}[t]
\caption{AlternatingOptimization} 
\label{lm:jointoptimization}
% \small
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\Input{(1) Dependency graph $\mathcal{G} = \{\mathcal{V}, \mathcal{E}\}$\\
(2) node sizes $\mathcal{S}$ and speedup scores $\mathcal{T}$\\
(3) \memory size $M$}
\Output{(1) Set of flagged nodes $\mathcal{U}$\\
(2) execution order $\tau$}
Initialize $\tau$ = $\texttt{GetTopologicalOrder(G)}$;\\
Initialize $\mathcal{U} = \emptyset$;\\
\While{the algorithm does not converge}{
    $\mathcal{U}_{new} = \texttt{SimplifiedMKP}(\mathcal{G}, \mathcal{S}, \mathcal{T}, M, \tau)$;\\
    \lIf{$\sum_{i:v_i\in \mathcal{U}_{new}} s_i \leq \sum_{i:v_i\in \mathcal{U}} s_i$}{
        \!\!\! \textbf{return} $\mathcal{U}, \tau$
    }
    $\mathcal{U} \leftarrow \mathcal{U}_{new}$;\\
    $\tau_{new} = \texttt{MA-DFS}(\mathcal{G}, \mathcal{S}, \mathcal{T}, M, \mathcal{U})$\\
    \lIf{$\texttt{PeakMemoryUsage}(\mathcal{G}, \mathcal{S}, \mathcal{U}, \tau_{new}) > M$}{
        \!\!\! \textbf{return} $\mathcal{U}, \tau$
    }
    $\tau \leftarrow \tau_{new}$;\\
}
\end{algorithm}

Any topological sorting algorithm can be used as the \texttt{GetTopologicalOrder} subroutine for obtaining the initial execution order on line 1.\footnote{Our implementation of \system uses the $\texttt{topological\_sort}$ function in the Python NetworkX package~\cite{networkx}.}
In each iteration of alternating optimization, \texttt{PeakMemoryUsage} on line 8 is efficiently computed in linear time by a linear scan over the nodes.
We alternate between solving \subproblemnodes and \subproblemorder we can no longer improve our outputs: \begin{itemize}
    \item No better set of flagged nodes $\mathcal{U}_{new}$ is found by \texttt{SimplifiedMKP} (line 5)
    \item The execution order $\tau_{new}$ found by \texttt{MA-DFS} violates the memory constraint $M$ (line 8)
\end{itemize}
Our solution is guaranteed to converge as the total speedup score of $\mathcal{U}$ must increase in each iteration for alternating optimization to continue. 
Our solution typically converges in $<$10 iterations for dependency graphs with up to 100 nodes. 
 \setlength{\textfloatsep}{\textfloatsepsave}
% \subsection{Hardness of \optimizationproblem}
% \label{sec:np_hardness}

% We briefly show the NP-hardness of \optimizationproblem via reduction from the optimization form of the 0-1 knapsack problem.
% %
% Consider $n$ items with weights $x_i$ and values $y_i$ and weight capacity $W$, we construct an instance of \optimizationproblem as follows:\begin{itemize}
%     \item The dependency graph $\mathcal{G} = \{\mathcal{V}, \mathcal{E}\}$ has $n+2$ nodes: $\mathcal{V} = \{v_{src}, v_{sink}\} \cup \{v_1,...,v_n\}$, and $ \mathcal{E} = \{(v_{src}, v_1),...,(v_{src}, v_n)\} \cup \{(v_1, v_{sink}),...,(v_n, v_{sink})\}$.
%     \item The speedup score of $v_i$ is $t_i = y_i$, and $t_{src} = t_{sink} = 0$.
%     \item The node size of $v_i$ is $s_i = x_i$, and $s_{src} = s_{sink} = 0$.
%     \item the available extra memory is $M = W$.
% \end{itemize}
% Any execution order must begin with $v_{src}$ and end with $v_{sink}$ with some permutation of $v_1,...,v_n$ in between. Since none of the nodes from $v_1$ to $v_n$ can be freed before $v_{sink}$ is executed, all execution orders are equivalent and the \optimizationproblem instance is simplified to finding the set of flagged nodes with a combined size less than $W$ with the highest combined total speedup score, which is precisely the 0-1 knapsack problem.