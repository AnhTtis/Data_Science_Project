\section{Conclusion and Future Work} 

Sequentially refreshing materialized views (MVs) 
    according to a topological order bears a noticeable overhead 
    as a result of the significant portion of intermediate I/O
        spent on reading and writing intermediate data.
%
In this paper, we propose a new system, \system, which aims to speed up MV refresh workloads 
    by selectively persisting intermediate data in bounded memory 
        during workload execution 
    to reduce the blocking I/O costs,
        thereby significantly reducing the
    wait times for reading and writing intermediate data from and to external storage.
%
We propose an effective and scalable algorithm
    to jointly optimize (1) a subset of intermediate data to persist and 
        (2) a topological order,
    in order to minimize the end-to-end MV refresh time under bounded memory.
%
\system is different from and complements existing MV refresh techniques as our approach is oblivious to individual MV refresh operations.
    % by achieving end-to-end speedup on the MV refresh workload as a whole.
We demonstrate that \system can reduce end-to-end MV refresh workload execution times by 1.04$\times$--5.08$\times$ with 1.6GB memory on a 100GB dataset.
Moreover, our optimization algorithm can easily handle complex workloads with 100 MVs.

In the future, we plan to generalize techniques presented in this paper to non-MV refresh recurring workloads containing individual jobs with acyclic dependencies.

% :
% many existing data pipelines (i.e. multi-stage image processing, ML pipeline debugging) contain repeated read/writes to intermediate storage and can benefit from \system's optimization.