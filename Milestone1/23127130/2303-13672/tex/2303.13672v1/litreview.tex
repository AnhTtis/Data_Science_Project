


\section{Introduction}\label{introduction}
After the birth of \acp{to} in the field of structural design \cite{Bendse1989}, efforts have been made to increase the effectiveness of such automated design approaches and allow for their deployment on a more general class of problems \cite{Sigmund2013,Guo2010}.   

A plethora of \ac{to} strategies exist through the literature, the most common of which being density-based methods using the so-called SIMP (Solid isotropic microstructure with penalization for intermediate densities) method \cite{Sigmund2001}. These involve varying a material distribution continuously 
between 0 and 1 to introduce an artificial representation of the
boundary. Although simple for basic structural problems, a way to represent intermediate design variables arising at
the boundary must be included, which becomes increasingly
complex in multi-physics applications and makes imposing
arbitrary boundary conditions non-trivial \cite{Yoon2014}. 

%para 4 : \ac{ls} topopt
An alternative technique that can overcome some of the problems presented by density methods and tackle a more general class of problems (e.g., interface-coupling multiphysics and problems that involve surface PDEs on boundaries) is the \ac{ls} \ac{to} method \cite{Osher1988,SethianJamesAlbert1999Lsma}
Using this approach, the boundary is
described by the zero iso-surface of a \ac{ls} function. It is instead this \ac{ls} function that is
varied to obtain optimized designs. A precise location of the boundary
is then available. 

A variety of alternative implementations of the \ac{ls} \ac{to} method
have been made \cite{vanDijk2013}. They can be distinguished, among other things, by how they update the topology at each iteration and their means of geometry mapping.
The methods to update geometries involve either updating the solution of Hamilton-Jacobi equations by a velocity field based on the sensitivity information \cite{Osher2001, Burman2018} or using a parameterization of the topology that is an explicit function of the design variables of a steepest descent optimization scheme. The latter approach allows one to leverage well-established nonlinear programming techniques and is the method selected for this work.
Types of geometry mappings include using the \ac{ls} function to define a conformal mesh to the boundary, see e.g. \cite{Ha2008,Yamasaki2011}, which requires re-meshing at each iteration, density-based mappings (see e.g. \cite{Allaire2004,Wang2003,Dugast2020}), which recover some of the issues related to density methods, or unfitted/immersed boundary techniques (see, e.g., \cite{Parvizian2011,Burman2015,badia_stokes_2018}). unfitted methods rely on a fixed background mesh and capture the precise location of the boundary in the model using integration on sub-triangulations aligned with the zero iso-surface of the \ac{ls} function. By doing so, re-meshing and the introduction of intermediate densities are avoided.

A known issue with unfitted techniques is the ill-conditioning problem associated with small cut elements. The common XFEM \cite{Kreissl2012,Villanueva2017} approach uses a \ac{fe} space restricted to the interior domain and cut cells for the solution and requires stabilization in the vicinity of the boundary by, for example, ghost penalty terms \cite{Burman2010} or cell aggregation \cite{badia_aggregated_2017,Badia2022-linking}. These methods are consistent and can provide high-order approximation \cite{Badia2022-high} however the support of the stabilization terms change depending on the location of the cut cells, leading to potential non-differentiability in the optimization problem which can harm the convergence of gradient-based optimization algorithms. The specific unfitted \ac{to} technique used in this work is instead a version of the \ac{fcm} \cite{Parvizian2011}, in which a non-consistent penalty term is added everywhere in the fictitious domain (outside the physical domain) to provide robustness. This stabilization is suitable for \ac{to} because it is differentiable with respect to the level set parameterization (see Section \ref{simulation}). An implementation of the \ac{fcm} for \ac{to} is made in \cite{Parvizian2011}, which uses a refined grid for the material boundary compared to the solution to capture fine-scale geometry. We instead use subgrid triangulations using the \ac{ls} function as in \cite{Kreissl2012} to capture fine-scale structure in the integration and thus avoid the need to increase the number of design variables parameterizing the geometry. The loss of consistency of the \ac{fcm} is not an issue in TO, where high-order approximations are not very relevant. 

It is natural to use a \ac{fe} function for a discrete representation of the \ac{ls}. Doing so, a parameterization is obtained with a user-controlled resolution. A common approach to the optimization problem is to take the  \acp{DOF} of this \ac{ls} as the design variables \cite{Kreissl2011,Kreissl2012,Dijk2012}. This choice, however, means that each parameter is only capable of a local influence on the \ac{ls} function to the surrounding cells. As an alternative, we introduce a
neural parameterization of the geometry. We set our design variables in
this case to be the parameters of a particular artificial \ac{nn} that outputs the \ac{ls} function  \acp{DOF}. Performing this step, we obtain control over the optimization
problem by controlling the connectivity of parameters, allowing them to influence cells spread across the domain. Although the expressivity is unchanged, since the \ac{ls}s are in the same space, the parameters controlling the evolution act to optimize the geometry at multiple scales. The ultimate objective is then for the optimization process to unveil regularized geometries with good performance. 

The combination of machine learning and \ac{to} was explored as early as the 1990s \cite{Adeli1995} but has gained massive momentum in recent years \cite{Zhang2021,Woldseth2022}. \acp{nn} and other ML techniques can be incorporated into the \ac{to} process in many ways.
Common data-driven approaches attempt to train networks to map problem descriptions directly to a geometry \cite{Hoang2022,Yu2018,Li2019,Zheng2021}. These however require pre-training on already optimized samples and suffer from a lack of generalisability \cite{Woldseth2022}. Others replace some or all of the optimization loop for accelerated convergence by training an auxiliary network \cite{Kallioras2020,Joo2021}. These approaches are based on the premise, which in general is not necessarily true, that early iterations of the optimization contain the information to produce performant optimal geometries. An alternative method is the inclusion of a \ac{nn} as an alternative parameterization of the geometry \cite{Deng2020,Chandrasekhar2020,Hoyer2019}. These approaches typically optimize the parameters of a \ac{nn} representing a continuous function that maps positions in space to a density. These approaches tend to focus on reducing the dimensionality of the design space assuming that \acp{nn} can efficiently achieve expressiveness with a small number of parameters \cite{Barron1994}. A reduction in parameters does not, however, necessarily lead to faster convergence for \acp{nn} \cite{Chandrasekhar2020} compared to the standard SIMP approach. 

Instead of focusing on a neural parameterization that reduces the dimensionality of the problem, we select a network description of the geometry which is specifically designed to learn effectively on problems involving the segmentation of a domain. The network used in this case is a modification of the U-Net convolutional network. The U-Net architecture was originally developed for biomedical
image segmentation tasks \cite{ronneberger2015unet} but has proven
successful for a variety of applications in which multi-scale features
and spatial correlation is important \cite{Ulyanov2020}. These networks are typically composed of encoding and decoding halfs. The encoding section maps the context of input images into a low dimensional latent space which is localized in the upsampling section to provide segmentation at the desired resolution. The work in \cite{Hoyer2019} exploited the properties of this network showing
improved performance with a U-Net density parameterization for a SIMP
structural optimization problem. Similar to \cite{Hoyer2019}, we
use a trainable input vector for the network and feed this into the
up-sampling half of the U-Net. In contrast to most applications of this
network, we have no input image and therefore do not need the
encoding of half of the network. It is the up-sampling (or decoding) part of
the network the one that provides the parameterization of the
multi-scale features which are important in this context.  

The Julia \cite{Julia-2017} programming language is used to implement all aspects of this project with the \ac{fe} toolbox Gridap \cite{Badia2020,Verdugo2022} being the main package utilized. We also use the Julia machine learning library Flux \cite{Flux.jl-2018} for the implementation of the U-Net. Using these foundations, we implement a routine combining \acp{nn} with an unfitted \ac{fe} based TO. The main contributions of this work are the presentation of:
\begin{itemize}
	\item An unfitted \ac{ls} \ac{to} method with a \ac{nn} parameterization that assists to achieve simple optimized geometries with similar or better performance compared to baseline methods and 
	\item a fully automatically differentiable unfitted \ac{ls} \ac{to} method for multiphysics problems with complex boundary conditions.
\end{itemize}
We present the overall framework as follows. First, in Section \ref{optimsation-problem}, we present the entire
optimization loop at a high level. We then go into more detail about
various stages in the loop. Details of the architecture of the neural
network are found in Section \ref{neural-architecture}, details of the geometry processing are presented in Section \ref{level-set-function-processing}, the numerical discretization of the problem is presented in Section \ref{simulation} and the gradient implementation in Section \ref{backwards-pass-implementation}. We then benchmark the method against baseline methods and show the generality of the method with an application to a multiphysics problem with complex boundary conditions in Section \ref{numerical-experiments}.
