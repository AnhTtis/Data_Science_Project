
\hypertarget{numerical-experiments}{%
\section{Numerical Experiments}\label{numerical-experiments}}

\hypertarget{benchmark-results}{%
\subsection{Benchmark Results}\label{benchmark-results}}

We first compare the optimized results obtained for benchmark problems against baseline methods using the model problems presented in Section \ref{simulation}.

The method presented in this work, the NN-LS method, is compared against its non-neural counterpart the Pixel \ac{ls} (Pixel-LS) method, that is, the same method without a neural prior where instead the nodal values of the level set function are taken as the optimization parameters. We also compare the method against the SIMP method of \ac{to} again using both a neural prior (NN-SIMP) and the standard approach (Pixel-SIMP). 
Following a standard SIMP implementation of the heat conduction problem, we use a conductivity based on the power law $k=\alpha_T + (1-\alpha_T)\rho^{\gamma}$ where $\rho$ is a design variable given by a \ac{fe} function constructed on the space $V_h^1$ where the \ac{DOF} values are the optimization parameters or output vector of the \ac{nn} in the Pixel-SIMP and NN-SIMP cases, respectively, and $\gamma$ is the penalization parameter, taken to be equal to $3$. 
Similarly, for the SIMP implementation of the structural problem, we use a Youngs Modulus $E=\alpha_d + (1- \alpha_T)\rho^{\gamma}$. 
To maintain a fair comparison between methods, we use the optimizers most widely regarded as suitable for the particular parameterization. Namely, we take the most commonly used MMA optimization strategy \cite{Svanberg1987} for the pixel parameterization and the ADAM strategy \cite{Kingma2014} for the \ac{nn}.

\subsubsection{Benchmark Problems}

\begin{figure}%
    \centering
	\begin{subfigure}[t]{0.49\textwidth}
		\centering\captionsetup{width=.9\linewidth}%
		\incfig[1]{heat_setup}
		\caption{Heat conduction problem setup. The top and left sides $\Gamma_D$ are given a Dirichlet condition and the bottom and left sides $\Gamma_N$ are given a Neumann condition.}
		\label{fig:heat-conduction-problem-setup}
	\end{subfigure}
	\begin{subfigure}[t]{0.49\textwidth}
		\centering\captionsetup{width=.9\linewidth}%
		\incfig[1]{MBB_setup}
		\caption{The right half of the MBB problem exploiting symmetry. The roller supports provide vertical restraint on the left-hand side and horizontal restraint in the bottom right corner. A downward force $F$ is prescribed on the top left corner.}
		\label{fig:MBB-problem-setup}
	\end{subfigure}
    \caption{Benchmark problems}
    \label{fig:benchmark-problems}
\end{figure}



The first problem studied is the Poisson equation to model heat conduction with the setup in Figure \ref{fig:heat-conduction-problem-setup} selected from \cite{GersborgHansen2006}. For this problem, we set $k_0 =1 m^2s^{-1}$, $\alpha_T=0.01$, $f=0.01Ks^{-1}$, use homogenous Dirichlet and Neumann conditions and use a mesh of $ 95 \times 95 $ with a $0.4$ volume fraction. For the \ac{nn}, we set the number of convolutional layers to $5$, $N_{\boldsymbol{\Theta}} = 64$, $w = (12,12,24,46,96,96)$, $l = (12,12,24,46,96,96)$ and $c = (16 , 128, 64, 32, 16, 1 )$.  %\hypertarget{implementation-aspects}{%

The second problem studied is the typical MBB problem described in \cite{Sigmund2001} with the setup as in Figure \ref{fig:MBB-problem-setup}. For this problem, we set $\nu=0.3$, $E=1 Pa$, $\alpha_d = 0.001$ and $F=1 N$ and use a mesh of $ 287 \times 95 $ with a $0.4$ volume fraction.  We use the same network as in the Poisson problem but set $w = (36,36,64,128,256,256)$

\sbcom{
The hyperparameters of the network are mainly selected to match those presented in \cite{Hoyer2019} with minor adjustments for the specific problem. The size of the convolutional filter chosen is appropriate for this scale of problem since we have achieved the required level of expressivity, as can be seen in the subsequent results, through learning complex enough templates whilst retaining a reasonable number of parameters. 
}

\subsubsection{Optimized Structures}
To compare the SIMP and \ac{ls} results, the optimized densities \sbcom{ from the SIMP procedure are converted to an \ac{ls} by taking the 0.5 iso-surface of the density and recomputing the objective function value using the unfitted machinery which integrates exactly on the cut cells. To evaluate the effect of the \ac{nn} parameterization, we also include the results obtained through the more standard methods of parameterization by taking the coefficients of the \ac{fe} function defining the geometry directly as the design variables.
}

\begin{table*}%[h!]
	\begin{center}
	  %\caption{Method comparison}
	  \label{fig:comparison}
	  \begin{tabular}{c c c c c } %c c c c }
	    & NN-LS & Pixel-LS & NN-SIMP & Pixel-SIMP \\
		    Heat &
	    \raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{./figures/NN_LS_heat.png}} & 
	    \raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{./figures/P_LS_heat.png}} &
	    \raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{./figures/NN_SIMP_heat.png}} &
	    \raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{./figures/P_SIMP_heat.png}} \\ 
	    
	    &  0.0\% & 20.3\% & 5.8\% & 15.7\% \\
	    MBB  & 
	    \raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{./figures/NN_LS_MBB.png}} & 
	    \raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{./figures/P_LS_MBB.png}}&%P_LS_MBB.png}} &
	    \raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{./figures/NN_SIMP_MBB.png}} &
	    \raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{./figures/P_SIMP_MBB.png}} \\ 
    
	    &  2.6\% & 1.7\% & 0.2\% & 0.0\% \\
    
	  \end{tabular}
	\end{center}
	\captionof{figure}{Optimized geometries for the various methods. The percentage under each geometry represents its performance relative to the best performing geometry in the row as measured by the objective function. \sbcom{The 0.0\% geometry is the best performing in the given row and the remainder are computed as the respective difference as compared to the best performing objective value.} } \label{table:mul-heat}
	\label{table:mul} 
      \end{table*}

The optimized geometries using the various methods are seen in Figure \ref{table:mul}. In all cases, the neural parameterization results in more regular geometries. The pixel-based methods could be regularized by augmenting the objective function with a penalization term although this would require manual tuning of a penalization parameter and may have an impact on the convergence. Simplistic structures could also be obtained for the pixel-based cases by controlling the filter radius and mesh resolution although this would prevent fine-scale structure. The NN-LS method instead allows for fine-scale features resolved in the final layer of the network but still produces performant regular geometries as the multi-scale influence of the parameters in the neural parameterization encourages globally performant structures to emerge. %occur rather than adding local features to a global structure fixed early in the optimization as seen most clearly in the comparison between the NN-SIMP and Pixel-SIMP results for the heat conduction problem in Figure \ref{fig:comparison} 
The use of the \ac{nn} is also seen to suppress numerical artifacts observed in the pixel-LS solutions. 
For the MBB problem, the compliance measurements for all methods fall within a few percent of each other. For this problem, the optimized solutions roughly share the location of the major members and are only slight variations from the optimal solution \cite{Rozvany1998}. 

For the heat conduction problem, however, the NN-LS method has the best performance by a fair amount followed by the NN-SIMP baseline. The regular geometries produced by the \ac{nn}s in these cases outperform their pixel counterparts by a significant amount in both the \ac{ls} and SIMP cases. The U-Net here seems able to find better minima because of its ability to focus on larger scale structures while the pixel-based parameterization makes improvements locally by adding finer scale branches to the geometry. Without handcrafting an initialisation close to the optimal solution, the addition of the neural network avoids sub-optimal branching structures and instead leads to the emergence of lamellar needles, the salient feature of optimal geometries for this problem \cite{Yan2018}.

\subsubsection{Convergence Plots}
The convergence of the methods is plotted for the heat conduction and MBB problems in Figure \ref{fig:convergence}. Since the use of the word iteration in the context of optimization is somewhat ambiguous, we plot the compliance against the number of objective function value calls for the process. For the ADAM and MMA optimizers, the ratio of function and gradient calls is 1:1.  
To compare the SIMP and \ac{ls} methods against each other, we bias the SIMP method using the optimized structures converted \ac{ls} once again. 
The bias is computed as the difference between the SIMP method's final objective value using the interpolated material and the SIMP method's final objective value using the converted \ac{ls}. This bias is applied to all of the series data in Figures \ref{fig:convergence} for the SIMP methods.   

\begin{figure}%
    \centering
    \begin{subfigure}{0.5\textwidth}
    \centering
		\includegraphics[width=0.99\linewidth]{./figures/its_heat_converted.pdf} 
        \caption{Heat conduction}
        \label{fig:heat-convergnce}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}
    \centering
		\includegraphics[width=0.99\linewidth]{./figures/its_MBB_converted.pdf} 
        \caption{MBB}
        \label{fig:MBB-convergence}
    \end{subfigure}
    \caption{Convergence plot comparison for the benchmark problems. The objective value at each objective function call is plotted. }
    \label{fig:convergence}
\end{figure}

For the heat conduction problem in Figure \ref{fig:heat-convergnce}, the pixel-SIMP method converges the fastest, albeit to an inferior solution. The rest of the methods converge at similar rates.  For the MBB problem in Figure \ref{fig:MBB-convergence}, the SIMP methods converge much faster than the \ac{ls} methods although the NN-SIMP method jumps out of the minimum at later iterations and stabilizes later on.
 
%\input{FSI.tex}

\hypertarget{FSI-problem}{%
\subsection{Interface Coupled Multiphysics Problem}\label{FSI-problem}}
\sbcom{
The design of a support in a fluid-structure problem is optimized in this section with the setup in \cite{Jenkins2016}. The structure is optimized under a forcing term from the fluid integrated on the evolving interface. The goal is to demonstrate the generality of the method which is shown here by its capacity to solve a multiphysics problem with interface coupling. Density methods do not extend naturally to handle such problems and are faced with difficulty in obtaining accurate coupling between the fluid and structure since the representation of the interface is spread across cells in the vicinity of the boundary. }

\begin{figure}
	\centering
	\incfig[0.55]{FSI-setup}
	\caption{The beam support problem setup. An inlet velocity is prescribed on the left side, a homogenous Dirichlet condition on the top and bottom walls and a homogenous Neumann condition on the right wall $\Omega_N$. 
	The design region supporting the beam in light grey can be either fluid or solid. 
	The solid domain $\Omega_{\mathrm{in}}$ is composed of the dark grey beam and the solid part of the design region.
	The fluid region $\Omega_{\mathrm{out}}$ is composed of the remainder of the channel, including the non-solid part of the design region.}
	\label{fig:FSISetup}
\end{figure}



The problem setup is seen in Figure \ref{fig:FSISetup}. 
For this problem, we set the fluid parameters as $\mu=1 m^2s^{-1}$ and $\alpha_u=2.5 \mu / 0.01^2 $ and use a parabolic velocity profile on the inlet with an average velocity of $0.01 ms^{-1}$.
For the structural parameters, we set $E=1 Pa$ and $\nu=0.3$ and use a $0.45$ volume fraction. 
We use the same network as in the poisson problem but set $w = (12,12,24,46,96,96)$ and $l = (24,24,48,96,192,192)$. The optimized geometry for problem is seen in Figure \ref{fig:FSI-result}.
	


%\begin{comment}
	\begin{figure}
		\centering
		\setlength{\abovecaptionskip}{-10pt plus 1pt minus 20pt }
		\incfig[1]{FSI_updated}%}{fsi9del}
		\caption{Optimized geometry for the beam support problem. Streamlines are plotted to represent the velocity field and pressure is indicated in the legend. } 
		\label{fig:FSI-result}
		\end{figure}
%\end{comment}
