As discussed in the paper, transforming a multivariate score could incur unexpected behaviors of the resulting density of the effective univariate running variable, such as discontinuity and zero density at the cutoff, violating key assumptions for local linear regressions to work. While density discontinuity can be tested using, for example, the \hyperref[M2008]{McCrary (2008)} test, checking zero density at a specific point in the support given only a finite sample is much harder. Lemma 1 gives a general characterization of bivariate densities that have a zero density at a given boundary point once the scores are collapsed to a univariate variable by taking the Euclidean distance to that boundary point. This characterization depends on the unobserved population joint density of the scores and is specific to the transformation chosen by the researcher. We also provide two examples where such issue can arise. In practice, problems of this kind are difficult to detect without knowing the true DGP.

\vspace{.5cm}

\noindent
\textbf{Lemma 1.} \textit{Let $(X_1,X_2)$ be a continuous bivariate score with joint density $f_{(X_1,X_2)}(x_1,x_2)$ over the support $\Omega(X_1,X_2)$. Given some cutoff point $(c_1,c_2) \in \Omega(X_1,X_2)$, consider the bivariate transformation $(X_1,X_2)\mapsto(E,V)$ where $E:=\sqrt{(X_1-c_1)^2+(X_2-c_2)^2}$ and $V:=X_1-c_1$ with joint support 
\begin{align*}
    \Omega(E,V)=\{(e,v)\in\mathbb{R}^2: e\in\left[0,\max_{(x_1,x_2)\in\Omega(X_1,X_2)}\sqrt{(x_1-c_1)^2+(x_2-c_2)^2}\right], v \in [l(e),u(e)]\},
\end{align*}
where $l(e)$ and $u(e)$ are lower and upper bounds of $v$ that potentially depend on $e$.\footnote{Without loss of generality, assume the max in the upper bound of $e$ is attained and the joint support of $(E,V)$ is a closed subset of $\mathbb{R}^2$.} Then the Euclidean distance $E$ has a zero density when evaluated at $e=0$, $f_E(0)=0$ if and only if
\begin{align*}
    \left(\left.\int_{l(e)}^{u(e)}\frac{e}{\sqrt{e^2-v^2}}\left[f_{(X_1,X_2)}(v+c_1,\sqrt{e^2-v^2}+c_2)+f_{(X_1,X_2)}(v+c_1,-\sqrt{e^2-v^2}+c_2)\right]dv\right)\right\rvert_{e=0}=0.
\end{align*}
}

\vspace{.8cm}

\noindent\textbf{Proof of Lemma 1.} Define $Z=(X_2-c_2)^2$. Consider the mapping $(X_1,Z)\mapsto(E,V)$, which is one-to-one. We can find the joint density of $(X_1,Z)$ by
\begin{align*}
    \mathbb{P}(X_1\leq x_1,Z \leq z) &=  \mathbb{P}\left(X_1\leq x_1, c_2-\sqrt{z}\leq X_2 \leq c_2+\sqrt{z} \right)\\
    &=F_{(X_1,X_2)}\left(x_1,c_2+\sqrt{z}\right)-F_{(X_1,X_2)}\left(x_1,c_2-\sqrt{z}\right)\\
    \implies f_{(X_1,Z)}(x_1,z)&=\frac{\partial^2{\mathbb{P}(X_1\leq x_1,Z \leq z)}}{\partial x_1\partial z}\\
    &=\frac{1}{2\sqrt{z}}\left[f_{(X_1,X_2)}\left(x_1,c_2+\sqrt{z}\right)+f_{(X_1,X_2)}\left(x_1,c_2-\sqrt{z}\right)\right].
\end{align*}
Since $X_1=V+c_1$ and $Z=E^2-V^2$, we have the Jacobian
\begin{align*}
    J_{(X_1,Z)}(e,v)=\begin{bmatrix}
        0&1\\
        2e&-2v
    \end{bmatrix}
\end{align*}
and $\lvert J_{(X_1,Z)}(e,v) \rvert=2e$. By the bivariate transformation theorem, 
\begin{align*}
    f_{(E,V)}(e,v)&=f_{(X,Z)}(x,z)\lvert J_{(X_1,Z)}(e,v) \rvert\\
    &=\frac{e}{\sqrt{e^2-v^2}}\left[f_{(X_1,X_2)}\left(v+c_1,c_2+\sqrt{e^2-v^2}\right)+f_{(X_1,X_2)}\left(v+c_1,c_2-\sqrt{e^2-v^2}\right)\right].
\end{align*}
This implies that the marginal distribution of $E$ is 
\begin{align*}
    f_E(e)=\int_{l(e)}^{u(e)}\frac{e}{\sqrt{e^2-v^2}}\left[f_{(X_1,X_2)}(v+c_1,\sqrt{e^2-v^2}+c_2)+f_{(X_1,X_2)}(v+c_1,-\sqrt{e^2-v^2}+c_2)\right]dv
\end{align*}
and the claim follows.\hfill $\square$

\vspace{.5cm}

\noindent\textbf{Example 1.} Let $(X_1,X_2)$ be uniformly distributed over $[-1,1]^2$. Then $f_{(X_1,X_2)}(x_1,x_2)=\frac{1}{4}$ over the support $\Omega(X_1,X_2)=[-1,1]^2$. First consider the boundary point at $(0,0)$. The bivariate transform $(E,V)$ in this case has joint support 
\begin{align*}
    \Omega(E,V)& =\left\{(e,v)\in \mathbb{R}^2: e\in [0,\sqrt{2}]\right., \\
    &\left.\qquad\qquad v \in [-e,e] \text{ if } e \in [0,1] \text{ and } v \in \left[\sqrt{e^2-1},1\right]\cup \left[-1,-\sqrt{e^2-1}\right] \text{ if } e \in \left(1,\sqrt{2}\right]\right\}.
\end{align*}
Then 
\begin{align*}
    f_E(e)&=\mathbf{1}\{e\in[0,1]\}\int_{-e}^e\frac{e}{2\sqrt{e^2-v^2}}dv \\
    &\qquad\qquad\qquad\qquad+ \mathbf{1}\{e\in(1,\sqrt{2}]\}\left(\int_{\sqrt{e^2-1}}^{1}\frac{e}{2\sqrt{e^2-v^2}}dv+\int_{-1}^{-\sqrt{e^2-1}}\frac{e}{2\sqrt{e^2-v^2}}dv\right).
\end{align*}
Following Lemma 1,
\begin{numcases}{f_E(e)=}
    \pi e/2, & \text{if } $e\in [0,1]$ \label{unif}\\
    e\left[\sin^{-1}(1/e)-\sin^{-1}(\sqrt{e^2-1}/e)\right], & \text{if } $e\in (1,\sqrt{2}]$\notag.
\end{numcases}
Hence $f_E(0)=0$. Note that this is not specific to the chosen boundary point, $(0,0)$. In fact, the issue remains for any boundary point $(c_1,c_2)\in [-1,1]\times[-1,1]$. To see this, suppose without loss of generality that $c_1,c_2>0$; other cases follow similarly. Then 
\begin{align*}
    E=\sqrt{(X_1-c_1)^2+(X_2-c_2)^2},\quad V=X_1-c_1,
\end{align*}
where
\begin{align*}
    |V|\leq E \leq \sqrt{V^2+(1+c_2)^2},\quad E\in\left[0,\sqrt{(1+c_1)^2+(1+c_2)^2}\right].
\end{align*}
Then the joint support of $(E,V)$ when $E$ takes value in $[0,1-c_1]$ is
\begin{align*}
    \Omega\left(E,V \,|\, E\in [0,1-c_1]\right)=\left\{(e,v)\in\mathbb{R}^2: e\in [0,1-c_1], v\in[-e,e]\right\}.
\end{align*}
The case where $E\in\left(1-c_1, \sqrt{(1+c_1)^2+(1+c_2)^2}\right]$ is irrelevant to deriving $f_E(0)$. Then Equation (\ref{unif}) still holds for $e\in [0,1-c_1]$ and therefore $f_E(0)=0$.

\vspace{.5cm}

\noindent\textbf{Example 2.} Let $(X_1,X_2)$ be independently normally distributed with mean $0$ and variance $\sigma^2$. Then $f_{(X_1,X_2)}(x_1,x_2)=\frac{1}{2\pi \sigma^2}\exp\{-x_1^2/2\sigma^2\}\exp\{-x_2^2/2\sigma^2\}$ over the support $\Omega(X_1,X_2)=\mathbb{R}^2$. First consider the boundary point at $(0,0)$. The bivariate transform $(E,V)$ in this case has joint support
\begin{align}
    \Omega(E,V)& =\left\{(e,v)\in \mathbb{R}^2: e\geq 0, v\in[-e,e]\right\}.\label{normal}
\end{align}
Then 
\begin{align*}
    f_E(e)&=\int_{-e}^e\frac{e}{\sqrt{e^2-v^2}}\frac{1}{\pi \sigma^2}\exp\left\{-e^2/2\sigma^2\right\}dv\\
    &=\frac{e}{\sigma^2}\exp\{-e^2/2\sigma^2\}
\end{align*}
Hence $f_E(0)=0$. Note that this is again not specific to the choice of the boundary point, as for any $(c_1,c_2)\in\mathbb{R}^2$, Equation (\ref{normal}) still holds.

