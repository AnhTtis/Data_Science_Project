% \vspace{-5mm}
\section{Related Work}
\label{sec:RELATED WORKS}
\subsection{Environment matting}
\label{Environment_matting}
Environment matting is introduced by~\cite{Zongker:1999:EM}, which extracts the environment matte and silhouettes from a series of projected horizontal and vertical stripe patterns. Subsequent works have been extended to multiple cameras~\cite{EME:Extensions}, natural images~\cite{chen2018tom,imageBasedEM}, wavelet domains~\cite{WaveletEM}, and frequency domain~\cite{FrequencyEM}. Meanwhile, it can be combined with compressive sensing theory~\cite{csEM} to reduce the number of used images. 
Unlike the above method, we adopt environment matting to capture environment matte and object masks and optimize the object geometries to fit them.
 
\subsection{Transparent Object Reconstruction}

Recovering the 3D geometry of transparent objects is a longstanding challenging problem~\cite{ihrke2010transparent}. 
To solve this difficult task, many works leverage specially designed hardware setups to provide more information encoding object geometries, including polarization~\cite{cui2017polarimetric, huynh2010shape,miyazaki2005inverse,shao2022polarimetric}, tomography~\cite{trifonov2006tomographic}, a moving point light source~\cite{chen2006mesostructure,morris2007reconstructing}, light field probes~\cite{wetzstein2011refractive} and gray-coded patterns~\cite{lyu2020differentiable,qian20163d,wu2018full}. 
Some methods~\cite{shan2012refractive,yue2014poisson} target the reconstruction of transparent objects with refractive or mirror-like surfaces.
Other methods, including ours, focus on solid transparent objects where most camera rays will refract on the surfaces twice. 
To reconstruct the geometry of transparent objects, there are many types of correspondences proposed, like multi-view ray-ray correspondences~\cite{qian20163d,rayRevealShape,wu2018full}, and ray-location correspondences~\cite{  lyu2020differentiable}. 
DRT~\cite{lyu2020differentiable} proposed to extract per-view ray-location correspondences by using the EnvMatt algorithm~\cite{Zongker:1999:EM}, and utilize the differentiable rendering
for progressively optimizing explicit meshes. 
Xu~\etal~\cite{xu2022hybrid} introduced ray-cell correspondence for reconstructing the full mode under natural light. Besides, Shao~\etal~{~\cite{shao2022polarimetric}} adopted polarimetric cues to reconstruct the full model of transparent objects~\cite{shao2022polarimetric}. 
    
Recently, data-driven-based methods have shown remarkable achievements in estimating the depth and normal maps of transparent objects~\cite{li2020through,sajjan2020clear,stets2019single}.
Li~\etal~\cite{li2020through} first predicted the rough geometry of the transparent objects and then leveraged Pointnet++~\cite{qi2017pointnet++} to further refine the rough geometry.
However, due to the domain gap between the synthetic and real data, Li~\etal~\cite{li2020through} failed to reconstruct real objects unseen in its training dataset.
More recently,  Bemana~\etal~\cite{bemana2022eikonal} leveraged NeRF for novel view synthesis of transparent objects and showed good performance to render novel views. However, since it targets novel view synthesis rather than reconstruction, it's difficult to extract reliable geometry from the method.
Unlike the above methods, We leverage volume rendering to simulate the refraction-tracing path for geometry optimization.
	
\subsection{Neural Implicit Representation}
\label{NIR}
Existing 3D representations can be roughly divided into four categories$:$ voxel-based representations~\cite{choy20163d}, point-based representations~\cite{achlioptas2018learning,fan2017point}, mesh-based representations~\cite{lyu2020differentiable,wang2018pixel2mesh}, and neural implicit representations~\cite{chen2019learning,mescheder2019occupancy,park2019deepsdf,saito2019pifu}. 
Recently, implicit neural representations have been applied to a variety of applications, including novel view synthesis~\cite{mildenhall2020nerf,zhang2020nerf++}, camera pose estimation~\cite{lin2021barf,wang2021nerf}, human~\cite{liu2021neural,peng2021neural} and multi-view 3D reconstruction~\cite{guo2022neural,long2022neuraludf,long2022sparseneus,niemeyer2020differentiable,oechsle2021unisurf,sun2022neural,wang2021neus,wang2022neuralroom,yariv2021volume,yariv2020multiview}, and achieved impressive successes. 
Recent research has shown that reconstructed results using implicit neural representation often produce higher quality than other 3D representations. 

For the task of 3D reconstruction from 2D images, some works combine implicit neural representation with surface rendering techniques. 
These works typically require additional constraints for optimization, such as object masks. 
Moreover, inspired by the seminal work NeRF~\cite{wang2021nerf}, more recent works apply volume rendering techniques to optimize the implicit neural representation encoded geometry.
In this work, we adopt an implicit signed distance function as geometry representation and leverage the volume rendering technique proposed in NeuS~\cite{wang2021neus} to optimize the geometries with the ray-location correspondences~\cite{lyu2020differentiable,qian20163d,wu2018full}.
	

	