\section{Experiments}

\subsection{Experimental Setup}
\textbf{Datasets.} We conduct evaluations on the DRT~\cite{lyu2020differentiable} dataset. The dataset contains eight transparent objects. Each transparent object contains 72 views with corresponding masks, ray-pixel correspondences, and extrinsic and intrinsic camera parameters. 
The view resolution is $960\times1280$ or $1080\times1920$.
Ground truth 3D models are also provided for the transparent models. 
\begin{table}[t]
  \centering
  % \caption{Add caption}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{ccccccc}
    \hline
        & \multicolumn{6}{c}{Sparsity=4}      
        \\ \hline
          & \multicolumn{2}{c}{Li~\etal~\cite{li2020through}} & \multicolumn{2}{c}{DRT\cite{lyu2020differentiable}} & \multicolumn{2}{c}{\textbf{Ours}}  
          \\ \hline        
          & Acc. / Com.$\downarrow$ & F-score$\uparrow$
          & Acc. / Com.$\downarrow$ & F-score$\uparrow$ 
          & Acc. / Com.$\downarrow$& F-score$\uparrow$  
          \\ \hline

    
    Pig &0.90 / 1.14 & 0.47  & 0.73 / 0.75 & 0.65  & \textbf{0.70 / 0.64} & \textbf{0.65 } \\
    Dog &0.83 / 0.95 & 0.53  & 1.01 / 1.02 & 0.48  & \textbf{0.80 / 0.71} & \textbf{0.61 } \\
    Mouse &1.68 / 1.69 & 0.28  & 1.16 / 1.39 & 0.40  & \textbf{0.78 / 0.70} & \textbf{0.50 } \\
    Monkey &1.32 / 1.24 & 0.34  & 1.03 / 1.10 & 0.37  & \textbf{0.86 / 0.78} & \textbf{0.43 } \\
    Horse   &  / &   /    & 0.65 / 0.57 & 0.83  & \textbf{0.66 / 0.47} & \textbf{0.85 } \\
     Tiger  & /   &    /   & 1.01 / 0.87 & 0.68  & \textbf{0.73 / 0.58} & \textbf{0.79 } \\
     Ribbit & /     & /      & 0.69 / 0.72 & 0.66  & \textbf{0.61 / 0.51} & \textbf{0.79 } \\
     Hand  & /   &   /    & 0.84 / 1.01 & 0.43  & \textbf{0.63 / 0.49} & \textbf{0.71 } \\ \hline
    Avg. &1.18 / 1.25 & 0.40  & 0.89 / 0.92 & 0.56  & \textbf{0.72 / 0.61} & \textbf{0.66 } \\
     \hline
    \end{tabular}%
    }
    \caption{Evaluation of reconstruction with $sparsity=4$ (18 views).  
    Compared with Li~\etal~\cite{li2020through} and DRT~\cite{lyu2020differentiable}, our method achieves the best performance in all cases.
} 
\label{table:compare3}
% \vspace{-5mm}
  % \label{tab:addlabel}%
\end{table}%
\begin{figure}[t]
\centering
\begin{overpic}
[width=1.0\linewidth]{figure/ICCV/res_full_views2.pdf}
\put(2.5, -2.4){Ground Truth}
\put(37,-2.4){Ours}
\put(66,-2.4){DRT\cite{lyu2020differentiable}}
\end{overpic}
\caption{We show two groups of full views reconstruction results generated by ours and DRT~\cite{lyu2020differentiable}, respectively. Our method can faithfully reconstruct high-quality geometries with fewer errors.}
\label{figure-additiaonal-full}
% \vspace{-5mm}
\end{figure}


\textbf{Implementation Details.} The geometry function $g$ is modeled by an MLP, which consists of 8 hidden layers with a hidden size of 256. We use PyTorch ~\cite{paszke2017automatic} to implement our approach and use the Adam optimizer with a global learning rate $5e^{-4}$ for the network training. Our network architecture and initialization scheme are similar to those of prior works~\cite{wang2021neus,wang2022neuralroom}. We sample $512$ rays per batch and train our model for 300k iterations on a single NVIDIA RTX 2080Ti GPU. We extract explicit mesh from the learned SDF field via a marching cube algorithm~\cite{lorensen1987marching}.

A hierarchical sampling strategy is used to sample points along a ray in a coarse-to-fine manner for volume rendering. We first uniformly sample 64 points along the ray, and then iteratively conduct importance sampling~\cite{wang2021neus} to sample more points on top of coarse probability estimation for $4$ times. The positional encoding is applied to the spatial location with 5 frequencies. 
The hyper-parameters used in the experiments are set as $\omega_1=0.0001, \omega_2=0.1, \omega_3=0.1$. 
Following the prior work~\cite{wu2018full}, the IOR (index of refraction) of air is set to 1.0003 and the IOR of transparent material (glass) is set to 1.4723. 




