\subsection{Comparisons}

\textbf{Baselines.} 
We compare our method with the two strong state-of-the-art baselines: 1) DRT~\cite{lyu2020differentiable}, the most related work to ours, which also optimizes the geometry by the ray-location correspondences but it adopts explicit mesh as surface representation.
2) A data-driven deep learning based approach Li et al. [2020]~\cite{li2020through}. They generate a synthetic dataset of the transparent objects, and then learn geometric priors from the training data to reconstruct the objects.

 
\textbf{Evaluation Protocols.} 
To evaluate the quality of reconstructed models, we calculate the metrics, accuracy, completeness, precision, recall, and F-score between the reconstructed model and the ground truth model. 
It should be noted that our method and DRT adopt the same dataset provided by DRT, so the input images and the ground truth models adopted by ours and DRT are the same.
Although Li et al. experimented with transparent objects obtained from the same source, due to different manufacturing batches there are slight differences between the shapes, and therefore their results are compared to a different set of ground truth models.
For fairness, the ground truth models of the two types are reshaped into the same scale for evaluation.
We evaluate the reconstruction results with sparse views and with full dense views.

\begin{figure}[t]
\centering
\begin{overpic}
[width=1.0\linewidth]{figure/ICCV/res_full_views1.pdf}
\put(2.5, -2.4){Ground Truth}
\put(37.5,-2.4){Ours}
\put(67.5,-2.4){DRT\cite{lyu2020differentiable}}
\end{overpic}
\caption{We show two groups of full views reconstruction results generated by our proposed NeTO and DRT~\cite{lyu2020differentiable}, respectively. Our method can faithfully reconstruct high-quality geometries with fewer errors.}
%and needs to pay more attention to the maintenance of the full model
\label{figure-additiaonal-full}

\end{figure}

\begin{table}[tp]
% \toprule
\centering
\resizebox{\linewidth}{!}{
% 	\small
\begin{tabular}{c|cc|cc|cc}%l=left, r=right,c=center分别代表左对齐，右对齐和居中，字母的个数代表列数
\hline

\multicolumn{1}{c}{}  
& \multicolumn{2}{c}{Li~\etal~\cite{li2020through}} 		
& \multicolumn{2}{c}{DRT\cite{lyu2020differentiable}} 
& \multicolumn{2}{c}{Ours}\\ \cline{2-7}
% \Xcline{1-1}{0.4pt}
%  \Xhline{1pt}
\hline
& Acc $\downarrow$  & Comp $\downarrow$   & Acc $\downarrow$  & Comp $\downarrow$ & Acc $\downarrow$  & Comp $\downarrow$  \\
\hline
 Pig    & 1.4241  & 1.6470 & 0.6566 & 0.6863 & \textbf{0.5669} & \textbf{0.4689} \\
Dog    & 0.8333 & 0.9585 & 0.9072 & 0.8704  & \textbf{0.7601} & \textbf{0.6274}  \\
Mouse  & 1.6864  & 1.6986  & 0.8018 & 0.839 & \textbf{0.7788} & \textbf{0.6811}  \\
Monkey & 1.3265 & 1.2483 & 0.945 & 0.8923  & \textbf{0.8415} & \textbf{0.7467}  \\
Horse & /  & / & 0.6636 & 0.6095  &\textbf{0.6193} & \textbf{0.4099}  \\
Tiger & /  & / & 0.8191 & 0.723  &\textbf{0.7099} & \textbf{0.5705}  \\
Rabbit & / & / & 0.5971 & 0.6202  & \textbf{0.5839} & \textbf{0.4941}  \\
 Hand & / & / & 0.4792 & 0.5856  & \textbf{0.3920} & \textbf{0.3150}  \\
 
\hline
% \bottomrule		
\end{tabular}
}

\caption{Comparisons of reconstruction with full views. 
Our method obtains the best performance in all cases, and the full table is in the supplementary material. }
\vspace{-5mm}

\label{table:compare_full_views}
\end{table}

\begin{figure}[t]
\centering
\begin{overpic}
[width=1.0\linewidth]{figure/ICCV/real_object.pdf}
\put(21, -2.5){Ours}
\put(69, -2.5){\small DRT\cite{lyu2020differentiable}}
\end{overpic}
\caption{Comparison of a self-collected Bull object. Our method reconstructs high-quality surfaces, while the surfaces recovered by DRT contain lots of noises.}
\vspace{-5mm}
\label{figure:real_object}

\end{figure}


\textbf{Reconstructions with sparse views.} 
The quantitative comparisons are presented in Table~\ref{table:compare}.
As you can see, with sparse views (four views), our results outperform DRT and Li~et.al in terms of model completeness and accuracy. 
In addition to making quantitative comparisons, we render the model to visually observe the differences between our method and other methods. 
The qualitative comparisons are shown in Figure~\ref{compare_with_four_views}, and our method faithfully reconstructs the geometry with rich details, such as the tail of the Mouse , and the eyes of the Monkey. The reconstruction results produced by~\cite{li2020through} and~\cite{lyu2020differentiable} fail to reconstruct the rich geometric details and tend to over-smooth the surfaces.   
 
\begin{figure*}[t]
\centering
\begin{overpic}
[width=1.0\linewidth]{figure/ICCV/ablation/pig/ab_error_map3.pdf}
\put(8, -1){\small W/o $\mathcal{L}_{Eikonal}$}
 \put(33.5, -1){\small W/o $\mathcal{L}_{Refraction}$}
 \put(59, -1){\small W/o Self-occlusion}
\put(88,-1){Full}

\end{overpic}
\caption{Qualitative ablation study on the Pig model.
For better visualization, we measure and colorize the errors between the reconstructed models with the ground truth model.
The reds indicate large errors, and the blues indicate small errors.
}
\label{Ablation}

\end{figure*}

	
\textbf{Reconstruction with full views.}
When we make use of more views, e.g., full views, the reconstruction results of ours and DRT are improved compared with reconstructions with sparse views.
However, based on the quantitative results presented in Figure~\ref{figure-additiaonal-full} and the qualitative results shown in Table~\label{table:compare_full_views}, our method significantly outperform the other methods in terms of completeness and accuracy, and the reconstructed models contain more rich details and have fewer errors.
We further conduct evaluation on a self-collected real Bull object, as shown in Figure~\ref{figure:real_object}. Our method accurately recovers the geometry with clean and smooth surfaces, while DRT mistakenly reconstructs surfaces with noises.

\subsection{Ablation study and discussions.}

 \textbf{Ablation study.}
To better validate the effects of the self-occlusion checking strategy and the optimization terms, we conduct the ablation studies, full method, method without self-occlusion checking, method without Eikonal loss term, and method without refraction loss term.
The quantitative evaluation is shown in Table~\ref{table:a} and the qualitative evaluation is presented in Figure~\ref{Ablation}.
The experiments demonstrate that $\mathcal{L}_{Eikonal}$ plays the most important role, which encourages the SDF field to be continuous and smooth.
The reconstruction will become incomplete and distorted without the Eikonal loss term.
Without the refraction loss term, although our method can still reconstruct the rough shape relying on the silhouette information, the reconstruction becomes worse with larger errors.
Thanks to our proposed self-occlusion checking strategy, the quality of the self-occluded parts is improved with fewer errors, like the legs of the Pig model.

\begin{table}[t]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lccccc}	
    \hline
    
    Method &Acc $\downarrow$  &Comp $\downarrow$     &Recall $\uparrow$  &Prec $\uparrow$    &F-score $\uparrow$ \\ \hline
    
    W/o $\mathcal{L}_{Eikonal}$     & 3.3086 & 1.5212 & 0.4   & 0.5384 & 0.4597 \\
    W/o $\mathcal{L}_{Refraction}$     & 0.7579 & 0.7019 & 0.59  & 0.6452 & 0.618 \\
    W/o Self-occlusion     & 0.6530 & 0.5440 & 0.7319  & 0.7886 & 0.7592 \\
    full  & \textbf{0.5669} & \textbf{0.4689} & \textbf{0.83} & \textbf{0.867} & \textbf{0.8474} \\

    \hline
\end{tabular}
}
\caption{Ablation study on Pig model. We test the effect of the Eikonal loss, refraction loss and self-occlusion strategy used in the method. This analysis shows that the Full performs the best quantitatively.}
\label{table:a}	
\vspace{-5mm}
\end{table} 

\textbf{Different rendering techniques.} 
\label{surface_vs_Volume}
Both surface rendering~\cite{niemeyer2020differentiable} and volume rendering~\cite{wang2021neus} are used in neural rendering based reconstruction.
Through experiments, we find that optimization using volume rendering is more robust and stable than using surface rendering.
As shown in Figure~\ref{rendering}, the reconstructed model using surface rendering is over-smoothing and lacks detailed geometries, while the reconstruction model using volume rendering achieves much better quality with rich details.

\begin{figure}[t]
\centering
\begin{overpic}
[width=1.0\linewidth]{figure/ICCV/ablation/surface/surface_vs_volume.pdf}
\put(10, -2.6){Surface rendering}
\put(61,-2.6){Volume rendering}
% \put(72,-1.5){\small \small DRT\cite{lyu2020differentiable}}
\end{overpic}
\caption{Reconstruction using surface rendering or volume rendering. The F-score values of the two reconstructions (from left to right) are 0.4725 and 0.884, respectively.}
\label{rendering}
\vspace{-5mm}
\end{figure}
