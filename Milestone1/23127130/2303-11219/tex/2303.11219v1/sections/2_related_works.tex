% \vspace{-5mm}
\section{RELATED WORKS}
\label{sec:RELATED WORKS}
\subsection{Environment matting}
\label{Environment_matting}
Environment matting is introduced by~\cite{Zongker:1999:EM}, which extracts the environment matte and silhouettes from a series of projected horizontal and vertical stripe patterns. Subsequent works have been extended to multiple cameras~\cite{EME:Extensions}, natural images~\cite{imageBasedEM,chen2018tom}, wavelet domains~\cite{WaveletEM}, and frequency domain~\cite{FrequencyEM}. Meanwhile, it can be combined with compressive sensing theory~\cite{csEM} to reduce the number of used images. 
 In this work, we adopt environment matting for transparent object reconstruction and optimize the object geometries to fit the obtained environment matte and object masks.
 
\subsection{Transparent Object Reconstruction}

Recovering the 3D geometry of transparent objects is a longstanding challenging problem~\cite{ihrke2010transparent}. 
To solve this difficult task, many works leverage specially designed hardware setups to provide more information encoding object geometries, including polarization~\cite{miyazaki2005inverse,huynh2010shape,shao2022polarimetric,cui2017polarimetric}, tomography~\cite{trifonov2006tomographic}, a moving point light source~\cite{chen2006mesostructure,morris2007reconstructing}, light field probes~\cite{wetzstein2011refractive} and Gray-coded patterns~\cite{wu2018full, lyu2020differentiable,qian20163d}. 
Some methods~\cite{shan2012refractive,yue2014poisson} target the reconstruction of transparent objects with refractive or mirror-like surfaces.
Other methods including ours focus on solid transparent objects where most of the camera rays will refract on the surfaces twice. 
To reconstruct the category of transparent objects, there are many types of correspondences proposed, like multi-view ray-ray correspondences~\cite{rayRevealShape}, and ray-location correspondences~\cite{wu2018full, qian20163d, lyu2020differentiable}. 
DRT~\cite{lyu2020differentiable} proposes to extract per-view ray-location correspondences by using the EnvMatt algorithm in~\cite{Zongker:1999:EM}, and utilize the differentiable rendering
for progressively optimizing explicit meshes. 
Xu~\etal~\cite{xu2022hybrid} introduce ray-cell correspondence for reconstructing the full mode under natural light. Shao~\etal~{~\cite{shao2022polarimetric}} adopt polarimetric cues to reconstruct the full model of transparent objects~\cite{shao2022polarimetric}. 

    
Recently, data-driven based methods have shown remarkable achievements in estimating the depth and normal maps of transparent objects~\cite{stets2019single,sajjan2020clear,li2020through}.
Li~\etal~\cite{li2020through} first predict the rough geometry of the transparent objects and then leverage Pointnet++~\cite{qi2017pointnet++} to further refine the rough geometry.
However, due to the domain gap between the synthetic data and real data, Li~\etal~\cite{li2020through} fail to reconstruct real objects that are unseen in its training dataset.
More recently,  Bemana~\etal~\cite{bemana2022eikonal} leverage NeRF for novel view synthesis of transparent objects and show good performance to render novel views. However, since it targets novel view synthesis rather than reconstruction, it's difficult to extract reliable geometry from the method.
Different from the above methods, We leverage volume rendering to simulate the refraction-tracing path for geometry optimization.
	
\subsection{Neural Implicit Representation}
\label{NIR}
Existing 3D representations can be roughly divided into four categories$:$ voxel-based representations~\cite{choy20163d}, point-based representations~\cite{achlioptas2018learning,fan2017point}, mesh-based representations~\cite{wang2018pixel2mesh,lyu2020differentiable}, and neural implicit representations~\cite{park2019deepsdf,mescheder2019occupancy,chen2019learning,saito2019pifu}. 
Recently, implicit neural representations have been applied to a variety of applications, including novel view synthesis~\cite{mildenhall2020nerf,zhang2020nerf++}, camera pose estimation~\cite{lin2021barf,wang2021nerf}, human~\cite{liu2021neural,peng2021neural} and multi-view 3D reconstruction~\cite{yariv2020multiview,oechsle2021unisurf,niemeyer2020differentiable,yariv2021volume,sun2022neural,wang2021neus,guo2022neural,wang2022neuralroom,long2022sparseneus,long2022neuraludf}, and achieved impressive successes. 
Recent research has shown that reconstructed results using implicit neural representation often produce higher quality than other 3D representations. 

For the task of reconstruction from 2D images, some works combine implicit neural representation with surface rendering techniques. 
These works typically require additional constraints for optimization, such as object masks. 
Moreover, inspired by the seminal work NeRF~\cite{wang2021nerf}, more recent works apply volume rendering techniques to optimize the implicit neural representation encoded geometry.
In this work, we adopt implicit signed distance function as geometry representation, and leverage the volume rendering technique proposed in NeuS~\cite{wang2021neus} to optimize the geometries with the ray-location correspondences~\cite{wu2018full, lyu2020differentiable,qian20163d}.
	
	
	
	%-------------------------------------------------------------------------
	