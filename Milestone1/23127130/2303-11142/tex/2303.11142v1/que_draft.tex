\documentclass[10pt, oneside, dvipsnames]{article}      % use "amsart" instead of "article" for AMSLaTeX format
\usepackage[a4paper, margin=1in]{geometry}                       % See geometry.pdf to learn the layout options. There are lots.
                       % ... or a4paper or a5paper or ...
%\geometry{landscape}                       % Activate for rotated page geometry
\usepackage{stmaryrd}
\SetSymbolFont{stmry}{bold}{U}{stmry}{m}{n}
\usepackage{titlesec}
\usepackage[parfill]{parskip}           % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
% TeX will automatically convert eps --> pdf in pdflatex
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
%\usepackage{microtype}
\usepackage[shortlabels]{enumitem}
\usepackage{xcolor}
\usepackage[noadjust]{cite}
\usepackage{stackengine}
\usepackage{mathrsfs}
\usepackage{stmaryrd}
% \usepackage{cleveref}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{bbm}
\usepackage{bold-extra}
\usepackage[normalem]{ulem}
\usepackage{silence}
\usepackage{enumitem}
\WarningFilter[pdftoc]{hyperref}{Token not allowed in a PDF string}
% \allowdisplaybreaks
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    citecolor=RubineRed,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }

\urlstyle{same}
\allowdisplaybreaks
\newcommand{\defeq}{\mathrel{\mathop:}=}
\newcommand{\eqdef}{=\mathrel{\mathop:}}
\linespread{1.3}
\numberwithin{equation}{section}


\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}



\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{property}[theorem]{Property}
\newtheorem{corollary}[theorem]{Corollary}

% \theoremstyle{definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{Condition}[theorem]{Condition}
\newtheorem{Construction}[theorem]{Construction}

\newtheorem{innercustomthm}{Assumption}
\newenvironment{assumption}[1]
{\renewcommand\theinnercustomthm{#1}\innercustomthm}
{\endinnercustomthm}


\def\I{\mathcal I}
\def\II{\mathrm{II}}

\def\Im{\operatorname{Im}}
\def\Re{\operatorname{Re}}
\newcommand{\Tr}{\operatorname{Tr}}
\newcommand{\matn}{\operatorname{Mat}_N}

\def\e{\bm e}
\def\d{\mathrm d}
\def\m{m_\mathrm{sc}}
\def\q{\bm q}
\def\x{\bm x}
\def\y{\bm y}
\def\E{\mathbb E}
\def\Od{O_\prec(N^{-D})}
\def\R{\mathbb R}
\def\N{\mathbb N}
\def\P{\mathbb P}
\def\Z{\mathbb Z}
\def\T{\mathbb T}
\def\leq{\leqslant}
\def\le{\leqslant}
\def\geq{\geqslant}
\def\ge{\geqslant}
\def\err{\mathrm{err}}
\def\even{\mathsf{even}}
\def\odd{\mathsf{odd}}

\def\tilde{\widetilde}
\def\mathbf{\bm}
\def\bar{\overline}
\def\ra{R^{(a)}}
\def\rab{\bar R^{(a)}}

\def\rarr{\left(\ra A\rab\ra\right)}
\def\rr{\left(\ra\rab\right)}
\def\rar{\left(\ra A\rab\right)}

%%  end mathbb symbols


%% mathrm symbols
\def\Pemp{\mathcal{P}_{\mathrm{emp}}}
\def\Cov{\mathrm{Cov}}
\def\Var{\mathrm{Var}}
 %% mathrm symbols
\def\phi{\varphi}
\def\epsilon{\varepsilon}
\def\trans{\mathsf{T}}
\def\Tr{\operatorname{Tr}}


\newcommand{\zero}{{\boldsymbol{0}}}
\newcommand{\one}{{\boldsymbol{1}}}
\DeclareMathOperator*{\esssup}{ess\,sup}
\DeclareMathOperator*{\essinf}{ess\,inf}

\def\red{\textcolor{red}}
\def\blue{\textcolor{blue}}
\def\orange{\textcolor{orange}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\dm}[1]{\todo[inline]{#1}}
\newcommand{\iu}{\mathrm{i}}
\newcommand{\Oparity}[2]{O_{\prec,\mathsf{#1}}(#2)}
\newcommand{\Onum}[2]{O_{\prec,#1}(#2)}



\title{\scshape{Fluctuations in Quantum Unique Ergodicity at the Spectral Edge}}
\author{L. \textsc{Benigni}\\[-.7ex]\vspace{-0.25cm}\footnotesize{\it{Universit\'e de Montr\'eal}}\\\footnotesize{\it{lucas.benigni@umontreal.ca}}
\and N. \textsc{Chen}\\[-.7ex]\vspace{-0.25cm}\footnotesize{\it{University of Chicago}}\\\footnotesize{\it{nixiachen@uchicago.edu}} 
\and P. \textsc{Lopatto}\\[-.7ex]\vspace{-0.25cm}\footnotesize{\it{Brown University}}\\\footnotesize{\it{\text{patrick\textunderscore lopatto@brown.edu}}}
\and X. \textsc{Xie}\\[-.7ex]\vspace{-0.25cm}\footnotesize{\it{Brown University}}\\\footnotesize{\it{xiaoyu\textunderscore xie@brown.edu}}
}
 \date{}                           % Activate to display a given date or no date
\titleformat{\paragraph}[runin]{\itshape\normalsize}{\theparagraph}{}{}
\titleformat{\subparagraph}[runin]{\itshape\normalsize}{\theparagraph}{0em}{}
\titleformat{\section}[block]{\normalfont\filcenter}{\Large\thesection .}{.7em}{\Large\scshape}
\titleformat{\subsection}[runin]{\normalfont}{\large \bf \thesubsection .}{.5em}{\large\bf}[.]
\titleformat{\subsubsection}[runin]{\normalfont}{\bf \thesubsubsection .}{.5em}{\bf}[.]

\begin{document}
\maketitle
\section{Introduction}

%In mathematical physics, 
Quantum Unique Ergodicity (QUE) refers to the observation that for the quantization of a %classical
chaotic dynamical system, the eigenstates of the Hamiltonian become uniformly distributed in phase space in the high-energy limit.  This phenomenon has been intensely studied by both physicists and mathematicians, and we refer the reader to \cite{sarnak2012recent} for a survey.
%who have established this principle in special cases, and wide-reaching generalizations.
%, who have probed  its theoretical underpinnings and introduced wide-reaching generalizations. 
Recently, a number of works have investigated QUE, and other closely related principles, in the context of Wigner random matrices \cite{bourgade2017eigenvector,cipolloni2022normal, adhikari2023eigenstate,bao2021equipartition,cipolloni2023gaussian,BenLop22QUE,benigni2022fluctuations, cipolloni2022thermalisation, cipolloni2022rank}. Because such matrices are the simplest class of chaotic quantum Hamiltonians, they form a natural testbed for the study of these ideas. %To contextualize our work, we begin by summarizing some of these previous results. 

We recall that a Wigner matrix is a symmetric matrix $H=\{h_{ij} \}_{1 \le i, j \le N}$ of real random variables with mean zero and variance $N^{-1}$, such that the upper triangular elements $\{h_{ij}\}_{1\le i,j, \le N}$ are independent. 
%(See \Cref{def:wigner} below for a precise definition.)
The eigenvectors of Wigner matrices are \emph{delocalized}, meaning that their mass is spread approximately uniformly among their entries. The simplest manifestation of delocalization is the high-probability bound 
\begin{equation}\label{intro:deloc}
  \sup_{\alpha \in \llbracket 1, N \rrbracket} N \langle  \bm{q}_\alpha, \bm{u} \rangle^2 \le  N^{ \epsilon},
\end{equation}
which holds for any $\epsilon>0$, eigenvector $\bm{u}$, and orthonormal basis $( \bm{q}_\alpha )_{\alpha =1}^N$, for sufficiently large $N$ \cite{alex2014isotropic}.\footnote{All eigenvectors in this work are normalized so that $\| \bm{u} \|_2 =1$.} %In fact, the same bound holds when $\bm {u}$ is expressed in an arbitrary orthonormal basis. 
 %Delocalization is expected to be a genetic feature of mean-field random matrix models; it to other random matrix ensembles \cite{aggarwal2021goe, bauerschmidt2016local, erdos2013spectral, bourgade2018random}

QUE for Wigner matrices asserts a more refined form of delocalization, concerning the equidistribution of the eigenvector coordinates. % in an arbitrary basis. 
Let $\mathcal I \subset \llbracket 1, N \rrbracket$ be any determinstic subset of indices. Then for any eigenvector $\bm u$, we have the high-probability bound
\begin{equation}\label{intro:que}
\left|\sum_{\alpha\in\I}\left\langle \q_\alpha,\bm u\right\rangle^2-\frac{|\I|}{N}\right| \le %N^{-1+\epsilon} \cdot 
\frac{N^\epsilon\sqrt{|\mathcal{I}|}}{N}.
\end{equation}
%for any $\epsilon >0$ and sufficiently large $N$. %We observe that when $\{ \bm{q}_\alpha \}_{\alpha =1}^N$ is chosen to be the standard basis, \eqref{intro:que} is an improvement over the bound that results from applying \eqref{intro:deloc} to each term in the previous sum.
A weaker version of this claim was first established in \cite{bourgade2017eigenvector}, and the optimal error term stated in \eqref{intro:que} was shown in \cite{BenLop22QUE, cipolloni2022rank}. 

In this article, we consider the fluctuations around the leading-order term identified in \eqref{intro:que}. Based on explicit calculations with Gaussian random matrices \cite[Theorem~2.4]{o2016eigenvectors}, we expect that 
\begin{align}\label{i:CLT}
\begin{split}
    \sqrt{\frac{ N^3}{2|\I|\big(N-|\I|\big)}}\left(\sum_{\alpha \in \I}\left\langle \q_\alpha,\bm u \right\rangle^2 -\frac{|\I|}{N}\right) \rightarrow \mathcal{N}(0,1),
\end{split}
\end{align}
with convergence in distribution, for all Wigner matrices, whenever $| \mathcal I | \gg 1$. We observe that when $|\mathcal \I|\ll N$, the summands act as independent Gaussians, while correlations arising from the condition that $\|\bm{u} \|_2 =1$  are present when when $| \mathcal{I} |$ is of order $N$. It has been shown in the recent work 
\cite{cipolloni2022rank} that \eqref{i:CLT} is true for eigenvectors $\bm{u}$ corresponding to eigenvalues in the bulk of the spectrum in the following sense. Label the eigenvalues of $H$ in increasing order, $\lambda_1 \le \lambda_2 \le \dots \le \lambda_N$, and let $i = i_N$ be a sequence of indices such that $\min(i, N-i) > cN$, for some constant $c>0$ and all $N \in \mathbb{N}$. Then \eqref{i:CLT} holds for the eigenvectors $\bm{u}_i$.
%when $(\bm{u}_i)_{i=1}^\infty$ is the sequence of eigenvectors corresponding to $(\lambda_i)_{i=1}^\infty$ \cite{cipolloni2022rank}.%; see also \cite{cipolloni2022normal} for earlier results in the bulk.

%we elaborate on this below, in Section~\ref{s:background}.

At the edge of the spectrum, previous results are less complete. In \cite{BenLop22QUE}, it was shown that \eqref{i:CLT} holds for \emph{any} eigenvector $\bm{u}$, if $N^\tau \le | \mathcal I | \le N^{1-\tau}$ for some $\tau > 0$. However, this leaves open the case where $| \mathcal {I} |$ is proportional to $N$ where correlations between eigenvector entries arise. This case is of particular interest since it  parallels the original QUE conjecture, which concerned the mass of eigenstates on subsets containing a constant fraction of phase space. In this article, we address this regime and show that \eqref{i:CLT} holds for any $\mathcal I$ such that $|\mathcal I | \ge  N^{1-c}$ and any eigenvector $\bm{u}_i$ such that $\min(i, N-i) \le N^{1-\tau}$, where $\tau>0$ is an arbitrary constant, and $c(\tau)>0$ is a small constant depending on $\tau$. This completes the characterization of fluctuations in QUE for Wigner matrices at the spectral edge. 

Our work does not address the intermediate spectral regime where $ i/N$ tends to $0$ slower than any negative power of $N$. We expect that this regime can be handled by a routine modification of the arguments in \cite{cipolloni2022rank}, and in fact that the results there hold for all $i \in \llbracket  N^{1-c}, N - N^{1-c}\rrbracket$ if $c>0$ is chosen sufficiently small. Assuming this claim, our result, in conjunction with the previous results of \cite{cipolloni2022rank} and \cite{BenLop22QUE} mentioned above, completes the analysis of fluctuations in QUE for Wigner matrices throughout the entire spectrum.

\subsection{Main Results}
We first define Wigner matrices. 
\begin{definition}[Wigner matrix]\label{def:wigner}
A Wigner matrix $H=H_N = \{ h_{ij}\}_{1\le i,j, \le N}$ is a real symmetric or complex Hermitian $N \times N$ matrix whose upper triangular elements $\left\{h_{i j}\right\}_{1\le i \leqslant j \le N}$ are independent random variables that satisfy 
\begin{align}\label{hij}
\begin{split}
    \E [h_{ij}]=0\qquad \E \big[|h_{ij}|\big]^2=\frac{1+\delta_{ij}}{N}\,.
\end{split}
\end{align}
Further, we suppose that the normalized entries have finite moments, uniformly in $N$, $i$, and $j$, in the sense that for all $p \in \mathbb{N}$ there exists a constant $\mu_p$ such that
\begin{align}\label{finite-moment}
\begin{split}
    \mathbb{E}\left[\left|\sqrt{N} h_{i j}\right|^p \right]\leqslant \mu_p 
\end{split}
\end{align}
for all $N, i$, and $j$.
\end{definition}
\begin{remark}
The second condition in \eqref{hij} could be relaxed to requiring only that 
\begin{equation} \mathbb{E}\left[\left|h_{i j}\right|^2 \right] = \frac{1 + (d-1) \delta_{ij} }{N}
\end{equation}
for some constant $d > 0$. The modifications to the proofs in this case are straightforward, and we omit them for brevity.
\end{remark}

Our main theorem is the following central limit theorem for Wigner matrix eigenvectors. We let 
\begin{equation}
\mathbb S^{N-1} = \{ \bm{v} \in \mathbb{R}^N : \| \bm{v} \|_2 = 1 \}.
\end{equation}

\begin{theorem}[Central Limit Theorem]\label{thm:CLT}
Let $H$ be a Wigner matrix and fix $\tau\in(0,1)$. Then there exists $\delta(\tau) >0$ such that the following holds. Let $\I=\I_N \subset \llbracket  N^{1-\delta} , N \rrbracket$ be a deterministic sequence of subsets, let $\ell=\ell_N \in \llbracket 1, N^{1-\tau} \rrbracket\cup\llbracket N-N^{1-\tau},N\rrbracket$ be a sequence of indices, and let $\bm{u}=\bm{u}_{\ell_N}^{(N)}=(u(1),\ldots,u(N))$ be the corresponding sequence of $\ell^2$-normalized eigenvectors of $H$. Let $(\q^{(N)}_\alpha)_{\alpha\in\I}=(\q_\alpha)_{\alpha\in\I}$ be a deterministic sequence of sets of orthogonal vectors in $\mathbb S^{N-1}$. %Finally, 
% Let $\left(\bm{q}_\alpha\right)_{\alpha \in I}=\left(\bm{q}_\alpha^{(N)}\right)_{\alpha \in I}$ be a deterministic sequence of sets of orthogonal vectors in $\mathbb{S}^{N-1}$.
Then
\begin{align}\label{CLT}
\begin{split}
    \sqrt{\frac{\beta N^3}{2|\I|(N-|\I|)}}\left(\sum_{\alpha \in \I}\left\langle \q_\alpha,\bm u_{\ell_N}\right\rangle^2 -\frac{|\I|}{N}\right) \rightarrow \mathcal{N}(0,1),
\end{split}
\end{align}
with convergence in the sense of moments. Here $\mathcal{N}(0,1)$ is a standard real Gaussian random variable; we take $\beta=1$ if $H$ is real symmetric, or $\beta=2$ if it is complex Hermitian.
\end{theorem}
%\begin{remark}
%The previous theorem also holds if $\delta = N^{-c}$, where $c>0$ is a fixed, small constant that may depend on $\tau$ and the $\mu_p$. 
%\end{remark}
Because the Gaussian distribution is determined by its moments, the above theorem immediately implies that \eqref{CLT} also holds for convergence in distribution \cite[Theorem 30.2]{billingsley2008probability}. 

%For brevity, we focus on the case of real symmetric Wigner matrices in our proof of Theorem~\ref{thm:CLT}. The details for the complex Hermitian case are nearly identical, and hence omitted.
\subsection{Related Works}\label{s:background}


Delocalization estimates have received significant attention from the random matrix community over the past decade and a half. The estimate \eqref{intro:deloc} has a long history, and increasingly strong version of this statement were proved in \cite{erdos2009semicircle, erdos2009local, erdos2010wegner, tao2011random, tao2010random,erdos2012bulk, erdos2012rigidity,vu2015random, aggarwal2019bulk, gotze2018local, gotze2019local}. The optimal high-probability upper bound of  $\sqrt{(2+\epsilon)\log N}$ was recently established in \cite{BL22LInfinity}. Going beyond Wigner matrices, similar estimates have been shown for band matrices \cite{xu2022bulk,bourgade2018random,erdos2013local}, heavy-tailed random matrices \cite{bordenave2013localization,bordenave2017delocalization,aggarwal2021goe,aggarwal2022mobility}, and adjacency matrices of sparse random graphs \cite{bauerschmidt2016local,erdos2013spectral}. 
Fluctuations of individual eigenvector entries of Wigner matrices were first studied in \cite{bourgade2017eigenvector}, where they were shown to be Gaussian (see also \cite[Corollary B.18]{BL22LInfinity} and \cite{benigni2021fermionic}). Arbitrary finite collections of bulk eigenvector entries were shown to be jointly Gaussian in \cite{marcinek2022high}. 

As noted above, the first QUE estimate for Wigner matrices was shown in \cite{bourgade2017eigenvector}. Estimates of the form \eqref{intro:que} have also been shown for deformed Wigner matrices, \cite{benigni2020eigenvectors}, band matrices \cite{xu2022bulk,bourgade2018random}, sparse random matrices \cite{bauerschmidt2016local,bourgade2017sparse,anantharaman2019quantum,anantharaman2015quantum,anantharaman2008entropy}, and heavy-tailed random matrices \cite{aggarwal2021eigenvector}. Further, a more general version of \eqref{intro:que}, known as \emph{eigenvector thermalization}, has appeared recently (motivated by the phenomena surveyed in \cite{srednicki1994chaos,d2016quantum,deutsch1991quantum}). Let $A$ be a deterministic $N\times N$ matrix such that $\| A \| \le 1$, where $\| A \|$ denotes the spectral norm of $A$. Then for any eigenvector $\bm{u}$ of a Wigner matrix, we have the high-probability bound 
\begin{equation}\label{ETH}
\left| \langle \bm{u}, A \bm{u} \rangle -  \frac{1}{N} \Tr A \right| \le \frac{N^\epsilon}{\sqrt{N}},
\end{equation}
for any $\epsilon >0$ and sufficiently large $N$ \cite{cipolloni2021eigenstate}. Subsequently, fluctuations around the leading order term in \eqref{ETH} were identified in \cite{cipolloni2022normal}, and an optimal-order error term was established in \cite{cipolloni2022rank}. 

We expect that our proof strategy can be extended straightforwardly in two directions. One is to determine the fluctuations for the more general observables $\langle \bm{u}, A \bm{u} \rangle$ when $\bm{u}$ is an edge eigenvector and $A$ is essentially full-rank, i.e. $\frac{1}{N}\Tr(A^2)\geq N^{-\delta}\|A\|^2$ for some small $\delta>0$. The other is to yield the joint fluctuations for any finite edge eigenvectors, i.e. 
\begin{equation}
    \sqrt{\frac{N^3}{2|\I|(N-|\I|)}}\left(\sum_{\alpha \in \I}\left\langle \q_\alpha,\bm u_{\ell_1} \right\rangle^2 -\frac{|\I|}{N},\cdots,\sum_{\alpha \in \I}\left\langle \q_\alpha,\bm u_{\ell_k} \right\rangle^2 -\frac{|\I|}{N}\right)\rightarrow (Z_1,\cdots,Z_k),
\end{equation}
with convergence in distribution, where $\ell_1<\cdots<\ell_k\leq N^{1-\tau}$ and $Z_1,\ldots,Z_k$ are independent Gaussian random variables with zero mean and unit variance.
However,  we consider only the case \eqref{i:CLT} for brevity. 

\subsection{Proof Strategy}
Previous works determining the fluctuations in QUE have all followed the dynamical approach to random matrix universality (surveyed in \cite{erdHos2017dynamical}). This approach uses the following three steps.

\begin{enumerate} 

\item Establish various \emph{a priori} estimates on the eigenvalues and eigenvectors of Wigner matrices, such as \eqref{intro:deloc}, which are used as input in the following steps. 

\item Determine the fluctuations in QUE for random matrices of the form $H + \sqrt{ t} W$, where $H$ is an arbitrary Wigner matrix, $W$ is a Gaussian Wigner matrix, and $t \approx N^{-c}$ for some $c>0$. This is done by recognizing $H + \sqrt{ t} W$ as the evolution of a matrix Brownian motion with initial data $H$ until time $t$. Under this stochastic process, the moments of the QUE observable in \eqref{i:CLT} evolve according to a parabolic differential equation known as the \emph{eigenvector moment flow}. A detailed analysis of this evolution shows that these moment observables converge to their equilibrium states, the Gaussian moments, after time $t$. This convergence in moments establishes \eqref{i:CLT} for the matrix $H + \sqrt{ t} W$.

\item Transfer the conclusion from the previous step to all Wigner matrices. Given an arbitrary Wigner matrix $H$, there exists a Wigner matrix $H'$ such that the first three moments of $H$ and $H' + \sqrt{t} W$ match exactly, and the difference of the fourth moments is order $t$. By a moment matching argument similar to the one used in Lindeberg's proof of the central limit theorem (see \cite[Section 11]{benaych2016lectures}), one can show that this moment condition is enough to establish that $H$ has the same fluctuations in QUE as $H' + \sqrt{t} W$, completing the proof. 
\end{enumerate}

Thus far, obstacles related to Step 2 of the dynamical approach have blocked a proof of \eqref{i:CLT} for $|\mathcal I|$ proportional to $N$ at the spectral edge. The analysis of the eigenvector moment flow in \cite{BenLop22QUE} was applicable throughout the entire spectrum, but was only effective for index sets $\mathcal I$ with cardinality $| \mathcal I | \ll N$.  The works \cite{cipolloni2022normal,cipolloni2022rank} analyzed a variation of the eigenvector moment flow introduced in \cite{marcinek2022high}, called the \emph{colored eigenvector moment flow}, which allow them to access $\mathcal I$ with $|\mathcal I|$ proportional to $N$. However, these works depend on an intricate analysis of the colored evolution dynamics presented in \cite{marcinek2022high}, which was only given in the bulk. In principle, such an analysis could also be carried out at the edge. However, given the length and sophistication of \cite{marcinek2022high}, and additional complications that arise at the edge due to the curvature of the spectral density (the semicircle law, given in \eqref{e:semicircle} below), this extension seems far from straightforward. 

Instead, we adopt an argument that has no dynamical component, and uses only moment matching. 
We draw inspiration from \cite{KnoYin13}, which characterizes the joint eigenvector--eigenvalue distribution of Wigner matrices at the edge. Specifically, the authors show that given any finite collection of edge eigenvalues and entries of the corresponding eigenvectors, their joint distribution is asymptotically the same with the one for a Gaussian ensemble. In particular, any finite collection of such eigenvector entries is asymptotically distributed as independent Gaussians. The proof proceeds by a ``two moment matching'' argument, which shows that two random matrix ensembles who entries are independent, centered, and have the same variance matrix also have the same eigenvector--eigenvalue statistics at the edge. As an immediate consequence, the edge statistics of any Wigner matrix match those of a Gaussian Wigner matrix, which may be computed explicitly. The decay of spectral density at the edge is crucial to the proof, and renders it inapplicable to the bulk, where the full dynamical approach is necessary. 

We now give an overview of our proof. Let $H$ be a Wigner matrix. Our first step is to regularize the QUE observable in \eqref{i:CLT}. Let $f_n(H)$ denote a smooth approximation to $n$-th moment of the observable on the left side of \eqref{i:CLT}, 
corresponding to some eigenvector $\bm u$,
%and associated eigenvalue $\lambda_\ell$, 
which is differentiable in the matrix entries.\footnote{The observable itself is not differentiable in the matrix entries, which necessitates the smoothing.} 
We wish to proceed as follows. Fix indices $a,b\in\llbracket 1,N\rrbracket$.
Let $W$ denote the matrix such that $w_{ij} = h_{ij}$ for all $i,j \in \llbracket 1, N \rrbracket$ such that $(i,j)\notin\{ (a,b), (b,a)\}$, and such that $w_{ab} = w_{ba} = g$, where $g$ is a Gaussian variable with mean $0$ and variance $N^{-1}$. We observe that the first two moments of $g$ match those of $h_{ab}$. 
Finally, let $Q$ denote the matrix such that $q_{ij} = h_{ij}$ for all $i,j \in \llbracket 1, N \rrbracket$ such that  $(i,j)\notin\{ (a,b), (b,a)\}$, where $q_{ab} = q_{ba} = 0$. Then by Taylor expansion, we have 
\begin{equation*}
f_n(H) = f_n(Q) + \partial_{ab}f_n (Q)h_{ab} + \frac{1}{2}\partial_{ab}^2f_n (Q)h_{ab}^2 + \frac{1}{6}\partial_{ab}^3f_n (Q)h_{ab}^3 + \frac{1}{24}\partial_{ab}^4f_n(Q)h_{ab}^4 + X_H,
\end{equation*}
where $X_H$ is the error term in expansion. Subtracting the analogous expansion for $f_n(W)$, and taking expectations, we obtain
\begin{align*}
\E\big[f_n(H) -& f_n(W)\big] = \E\big[\partial_{ab}f_n (Q) (h_{ab} - w_{ab})\big] + \frac{1}{2}\E\big[\partial_{ab}^2f_n (Q)( h_{ab}^2 - w_{ab}^2)\big]\\
 +& \frac{1}{6}\E\big[\partial_{ab}^3f_n (Q)( h_{ab}^3 - w_{ab}^3)\big] +\frac{1}{24}\E\left[\partial_{ab}^4f_n (Q)(h_{ab}^4-w_{ab}^4)\right] + \E\big[(X_H - X_W)\big]
\\ =& \frac{1}{6}\E\big[\partial_{ab}^3f_n (Q)\big] \E\big[h_{ab}^3 - w_{ab}^3\big] +\frac{1}{24}\E\left[\partial_{ab}^4f_n (Q)\right]\E\left[h_{ab}^4-w_{ab}^4\right] + \E\big[(X_H - X_W)\big].
\end{align*}
In the previous equation, we observed that $Q$ is independent from $h_{ab}$ and $w_{ab}$, and used $\E[\partial_{ab}f_n(Q)(h_{ab} - w_{ab})] = 0$, which follows from $\E[h_{ab}] = \E[w_{ab}]$. We also used the analogous reasoning for the second-moment term. 

We consider the third-moment and fourth-moment terms, and neglect the error term for now. From the definition of a Wigner matrix, we have $\E\big[h_{ab}^3 - w_{ab}^3\big] = O(N^{-3/2})$ and $\E\left[h_{ab}^4-w_{ab}^4\right]=O(N^{-2})$. If we had the estimates 
\begin{align}\label{eqn:desired-estimates}
\begin{split}
    \E\big[\partial_{ab}^3f_n (Q)\big] \ll N^{-1/2},\quad \E\big[\partial_{ab}^4f_n(Q)\big]\ll1,
\end{split}
\end{align}
then $\E\big[f_n(H) - f_n(W)\big] \ll N^{-2}$. This estimates the error accrued when exchanging one entry of $W$ for a Gaussian. Since we need to exchange $O(N^2)$ entries, the total error will be $o(1)$, and the moments $\E[f_n(H)]$ will match those of a Gaussian random matrix in the large $N$ limit. Because \eqref{i:CLT} can directly be established for Gaussian matrices, this would complete the proof. 

The crux of the problem is then to produce a suitable regularization $f_n$ and demonstrate that its derivatives decay suitably in $N$ near the edge of the spectrum. While regularizations of \eqref{i:CLT} have appeared before, the necessary decay at the edge has not been established. For example, the regularized QUE observable in \cite{BenLop22QUE} was only shown to satisfy $\E\big[\partial_{ab}^3f_n(Q)\big] = O(1)$. %Instead, we adopt the regularization procedure used for individual eigenvector entries in \cite{KnoYin13,BloKnoYauYin16}. 
To illustrate how our regularization works, and how we achieve the additional gain at the edge, we begin by describing the regularization of a single eigenvector entry, as accomplished in \cite{KnoYin13,BloKnoYauYin16}. 


Let $\bm{u}_\ell$ be an eigenvector with associated eigenvalue $\lambda_\ell$, and let $\eta >0$ be chosen so that $\eta\ll\Delta_\ell$, where $\Delta_\ell$ is the typical size of the eigenvalue gap $\lambda_{\ell +1} - \lambda_{\ell}$. Recall the Poisson kernel identity
\begin{equation*}\frac{\eta}{\pi} \int_{\mathbb R} \frac{\d E}{(E - \lambda_\ell )^2 + \eta^2} = 1.
\end{equation*}
Fix $k\in\llbracket1,N\rrbracket$. We have the high probability estimate 
\begin{equation*}
\bm u_\ell(k)^2 = \frac{\eta}{\pi} \int_{\mathbb R} \frac{ \bm u_\ell(k)^2 \, \d E }{(E - \lambda_\ell)^2 + \eta^2 } \approx \frac{\eta}{\pi} \int_{I} \frac{ \bm u_\ell(k)^2 \, \d E }{(E - \lambda_\ell)^2 + \eta^2 } \approx \frac{\eta}{\pi} \int_{I}  \sum_{i=1}^N \frac{ \bm u_\ell(k)^2 \, \d E }{(E - \lambda_i)^2 + \eta^2 },
\end{equation*}
where $I$ is any interval centered at $\lambda_\ell$ such that $\eta\ll| I |\ll \Delta_{\ell} $, and we used $$ \max( \lambda_{\ell +1} - \lambda_{\ell},\lambda_{\ell} - \lambda_{\ell-1})\gg \eta$$ to neglect the terms with $i\neq \ell$ in the sum. Letting $G = (H - E - \mathrm{i} \eta)^{-1}$ denote the resolvent of $H$, we have by the spectral theorem that 
\begin{equation}\label{i:resolventreg}
\frac{\eta}{\pi} \int_{I}  \sum_{i=1}^N \frac{ \bm u_\ell(k)^2 \, \d E }{(E - \lambda_i)^2 + \eta^2 } =\frac{\eta}{\pi} \int_I (G\bar G)_{kk}\, \d E.
\end{equation}
For illustrative purpose, let us treat $I$ as a deterministic interval. Then, we see that 
\begin{align*}
\begin{split}
   f_n(H) \defeq  \left(\frac{N\eta}{\pi} \int_I (G\bar G)_{kk} \d E\right)^{n} \approx \left(\sqrt{N}\bm u_\ell(k)\right)^{2n},
\end{split}
\end{align*}
 is a smooth function of the matrix entries. We multiplied $\bm u_{\ell}(k)$ by $\sqrt{N}$ to make it an $O(1)$ quantity.

Letting $R=(Q-E-\iu\eta)^{-1}$ denote the resolvent of $Q$ and taking derivatives, one readily finds that\footnotemark
\footnotetext{There are multiple terms as a result of applying product rule, so we focus on one representative term for clarity.}
\begin{equation}\label{i:derivative}
    \partial_{ab}^m f_n(Q)\approx n(n-1)\cdots (n-m+1)(\sqrt{N}\bm u_\ell(k))^{2n-m} \int_{I}N\tilde P_m\,\d E+\cdots,
\end{equation}
where $\tilde P_m$ is a polynomial with constant number of terms, and  each term consists of one $(R\bar R)_{**}$ factor and $m$ $R_{**}$'s or $\bar R_{**}$'s.
Here $*\in\{a,b,k\}$ and different $*$ may take different values.

So far, we have not used the fact that $\lambda_\ell$ is an edge eigenvalue. The crucial use of this fact is that we are able to choose the spectral parameter $\eta$ such that $1\ll \Delta_\ell\eta^{-1}\ll (N\eta)^{1/4}$. Indeed, if $\lambda_\ell$ were in the bulk, we would have $\Delta_\ell=O\left(N^{-1}\right)$, and such choice would not be possible. Combined with standard local law for resolvents of Wigner matrices (see \eqref{eqn:2-resolvents} below), for any $\epsilon>0$, we have
\begin{align}\label{i:two-res-bound}
\begin{split}
    (R\bar R)_{ij}\leq N^{\epsilon}(N\eta)^{-2}
\end{split}
\end{align}
with high probability for all $i,j \in \llbracket 1, N \rrbracket$. Therefore, we have the bound
\begin{align}\label{i:p-integral}
\begin{split}
    \int_IN\tilde P_m \leq |I|N^{1+\epsilon} (N\eta)^{-2}\leq (N\eta)^{-1/2}\ll 1,
\end{split}
\end{align}
by the choice of $I$ and $\eta$. Inserting this into \eqref{i:derivative}, we have
\begin{align}
\begin{split}
    \big|\partial_{ab}^mf_n(Q)\big|\ll 1,
\end{split}
\end{align}
with high probability. Upon taking expectation, this establishes the second inequality in \eqref{eqn:desired-estimates}.

For the first inequality in \eqref{eqn:desired-estimates}, we need to exploit an additional cancellation that is introduced when taking expectation. To uncover this cancellation, we use the \textit{polynomialization} technique, which first appeared systematically in \cite{erdHos2013averaging}, and was further developed in \cite{yin2014local,BloKnoYauYin16}. The main idea is to write $\tilde P_m$ in the form
\begin{equation}
    \tilde P_m \approx \sum_{i_1,\ldots,i_d\neq a}\tilde P_{m,i_1,\ldots,i_d}^{(a)}h_{ai_1}\cdots h_{ai_d},
\end{equation}
where $\tilde P^{(a)}_{m,i_1,\ldots,i_d}$ is independent of $a$-th row and column of Q. When $d$ is an odd number, we have
\begin{align}\label{i:additional-gain}
\begin{split}
    \left|\E\big[\tilde P_m\big] \right|\lesssim N^{-1/2}\sqrt{\E\big[|\tilde P_m|^2\big]}.
\end{split}
\end{align}
To see why \eqref{i:additional-gain} is true, consider a simple case, where $\mathcal P=\sum_{i_1,i_2,i_3\neq a}h_{ai_1}h_{ai_2}h_{ai_3}$. Taking expectation forces $i_1,i_2,i_3$ to coincide, and therefore
\begin{align*}
\begin{split}
    \big|\E [\mathcal P]\big|=\left|\E\left[\sum_i h_{ai}^3\right]\right|\lesssim N^{-1/2}=N^{-1/2}\sqrt{\E\left[\sum_{i_1,i_2,i_3}h_{ai_1}^2h_{ai_2}^2h_{ai_3}^2\right]}\leq N^{-1/2}\sqrt{\E\left[|\mathcal P|^2\right]}.
\end{split}
\end{align*}
Moreover, it can be shown that, $\tilde P_m$ can be approximated by an odd polynomial as long as $m$ is odd and $a,b,k$ are distinct indices. Combining \eqref{i:additional-gain} with \eqref{i:derivative} and \eqref{i:p-integral}, we obtain the first inequality in \eqref{eqn:desired-estimates} for all indices $a,b$, expect for $O(n)$ pairs such that $a=b,a=k$ or $b=k$, which is sufficient for our purpose.


Regularizing the QUE observable in \eqref{i:CLT} can be accomplished similarly by replacing each term $\langle \bm q_\alpha, \bm u_\ell \rangle^2$ appearing there by the regularization given in \eqref{i:resolventreg}. However, to appropriately control the size of the resulting moments, we need to detect additional cancellations in the sum; it is not enough to bound each term individually. For this, we use \emph{multi-resolvent local laws}, which bound the quantities $(GA\overline{G})_{cd}$ and $(GA \overline{G} G)_{cd}$ for any choice of $c,d \in \llbracket 1 , N \rrbracket$ and  deterministic $N\times N$ matrix $A$ such that $\| A \| \le 1$ and $\Tr A = 0$; see Lemma~\ref{lem:three-resolvent-local-law} below. While such laws have been established previously \cite{cipolloni2022rank,CipErdSch22optimal,cipolloni2021eigenstate}, we prove a new version with improved error terms at the spectral edge. These improved estimates allow us to obtain sharper bounds in the moment matching argument, which are necessary to complete the proof. 



\subsection{Outline}
Section~\ref{s:preliminaries} introduces our notational conventions, and states several preliminary results from previous works that are used throughout this paper. Section~\ref{sec:regularized-observables} defines the smoothed QUE observables needed for our moment matching argument. Section~\ref{s:conclusion} proves our main result, Theorem~\ref{thm:CLT}, assuming two preliminary lemmas, Lemma~\ref{lem:three-resolvent-local-law}, and Lemma~\ref{lem:third-moment-terms}. Lemma~\ref{lem:third-moment-terms} is proved in Section~\ref{sec:poly}.
Lemma~\ref{lem:three-resolvent-local-law} is proved in Appendix~\ref{sec:local-law}.

\subsection{Acknowledgments}

The authors thank Antti Knowles for several helpful conversations. 
Patrick Lopatto was supported by the NSF postdoctoral
fellowship DMS-2202891. 
Xiaoyu Xie was supported by NSF grant DMS-1954351. 
Lucas Benigni and Patrick Lopatto also wish to acknowledge the NSF
grant DMS-1928930. This grant supported their participation in the Fall 2021 semester program at
MSRI in Berkeley, California titled, ``Universality and Integrability in Random Matrix Theory and
Interacting Particle Systems,'' where this project began.
\section{Preliminaries}\label{s:preliminaries}

%Throughout this work, we suppress the dependence of various constants in our results on the constants  $\mu_p$ in
%Definition~\ref{def:wigner}. This dependence does not affect our arguments in any substantial way.  
%\subsection{Outline of the paper}

\subsection{Conventions}\label{s:conventions}
For the remainder of the paper, we fix arbitrary constants $\tau\in(0,1)$, a sequence of deterministic subsets $\I=\I_N\subset\llbracket N^{1-\delta},N\rrbracket$, with $\delta\equiv\delta(\tau)=10^{-5}\tau$, and a sequence of deterministic indices $\ell=\ell_N \in \llbracket 1, N^{1-\tau} \rrbracket\cup\llbracket N-N^{1-\tau},N\rrbracket$. We also fix a deterministic sequence $(\q^{(N)}_\alpha)_{\alpha\in\I}=(\q_\alpha)_{\alpha\in\I}$ of sets of orthogonal vectors in $\mathbb S^{N-1}$, and a sequence of positive reals $(\mu_p)_{p=1}^\infty$. We assume that all Wigner matrices mentioned below satisfy Definition~\ref{def:wigner} with this sequence of constants. Our claims hold for any choices of these parameters. 

We also define the spectral domain
\begin{equation}\label{eqn:spectral-domain}
\bm S= \bm S( N)=\left\{z=E+\mathrm{i} \eta \in \mathbb{C}:|E| \leqslant \frac{10}{\tau}, N^{-1+\tau/10} \leqslant |\eta| \leqslant \frac{10}{\tau} \right\}.
\end{equation}
%In the following theorem, and all other stochastic domination statements in this work involving elements of $\bm S_\omega$, the numbers $N_0$ in Definition~\ref{def:stochasticDomination} may additionally depend on $\omega$. \red{(this $\omega$ will ultimately depend on $\tau$ as in Section \ref{s:conventions})}

%Finally, we fix $\omega=\tau/10$ in the definition of $\bm S_\omega$ \eqref{eqn:spectral-domain}, and use the notation $\bm S$ for this choice of spectral domain.

Throughout this article, we typically suppress the dependence of various constants in our results on the choices of $\tau$. These dependencies do not affect our arguments in any substantial way. Additionally, we focus on the case of real symmetric Wigner matrices in our proof of Theorem~\ref{thm:CLT}. The details for the complex Hermitian case are nearly identical, and hence omitted. 

\subsection{Notations and Definitions}




Let $\operatorname{Mat}_N$ be the set of $N \times N$ real symmetric matrices and $\{\e_i\}_{i=1}^N$ be the standard basis of $\R^N$. Let $\| M \|$ denote the spectral norm of $M$. We index the eigenvalues of matrices $M \in \operatorname{Mat}_N$ in increasing order, and denote them $\lambda_1 \leqslant \lambda_2 \leqslant \ldots \leqslant \lambda_N$. For $z \in \mathbb C\backslash\R$, the resolvent of $M \in \operatorname{Mat}_N$ is given by $G(z)=(M-z)^{-1}$. %, where $\mathrm{Id}= \mathrm{Id}_N$ is the identity matrix. 
The Stieltjes transform of $M$ is
$$
m_N(z)=\operatorname{Tr} G(z)=\frac{1}{N} \sum_i \frac{1}{\lambda_i-z} .
$$
The resolvent has the spectral decomposition
$$
G(z)=\sum_{i=1}^N \frac{\bm{u}_i \bm{u}_i^*}{\lambda_i-z},
$$
where we let $\bm{u}_i$ denote the eigenvector corresponding to the eigenvalue $\lambda_i$ of $M$ such that $\left\|\bm{u}_i\right\|_2=1$. We fix the sign of $\bm{u}_i$ arbitrarily by demanding that $\bm{u}_i(1) \geqslant 0$. For deterministic vectors $\bm x,\bm y$, we abbreviate $\langle\bm x,M\bm y\rangle$ by $M_{\bm x\bm y}$ and we abbreviate $M_{\bm x\bm y}$ further by $M_{i\bm y}$ or $M_{\bm xj}$ if $\bm x=\bm e_i$ or $\bm y=\bm e_j$ respectively.

The semicircle density and its Stieltjes transform are
\begin{equation}\label{e:semicircle}
\rho_{\mathrm{sc}}(E)=\frac{\sqrt{\left(4-E^2\right)_{+}}}{2 \pi}\, \mathrm{d} E, \qquad \m(z)=\int_{\mathbb{R}} \frac{\rho_{\mathrm{sc}}(x)}{x-z} \mathrm{d} x = \frac{-z + \sqrt{z^2 -4}}{2},
\end{equation}
for $E \in \mathbb{R}$ and $z \in \mathbb{C}\backslash \mathbb{R}$. The square root in $\sqrt{z^2 -4}$ is defined with a branch cut in $[-2,2]$, so that $\Im \m(z) >0$ for $\Im z>0$. 

For $i \in \llbracket 1, N \rrbracket$, we denote the $i$-th $N$-quantile of the semicircle distribution by $\gamma_i$ and define it implicitly by
$$
\frac{i}{N}=\int_{-2}^{\gamma_i} \rho_{\mathrm{sc}}(x) \, \mathrm{d} x .
$$
We will often differentiate functions of a matrix $M\in \matn$ with respect to some entry $m_{ab}$ of $M$. For example, we will consider quantities such as $\partial_{ab} f(M)$, where $\partial_{ab}$ means that we consider $M$ as a function of its upper-triangular elements $\{ m_{ij} \}_{1 \le i \le j \le N}$ and differentiate with respect to $m_{ab}$ when $a \le b$, or with respect to $m_{ba}$ when $b \le a$. Mostly commonly, we take $f$ to be the resolvent $f(M) = (M -z)^{-1}$, or some product of resolvents.



Finally, we adopt the convention that $\mathbb{N} = \{1,2,3,\dots\}$.
\subsection{Local law for resolvent and multi-resolvent}\label{sec:multi-resolvent-local-law}

We require the isotropic local law proved in \cite{alex2014isotropic} and multi-resolvent local law proved in \cite{CipErdSch22optimal}. We begin by recalling the notion of stochastic domination (which was introduced in \cite{erdos2013local}).

\begin{definition}[Stochastic domination]\label{def:stochasticDomination}
Let
$$
X=\left(X^{(N)}(u): N \in \mathbb{N}, u \in U^{(N)}\right), \quad Y=\left(Y^{(N)}(u): N \in \mathbb{N}, u \in U^{(N)}\right)
$$
be two families of nonnegative random variables, where $U^{(N)}$ is a possibly $N$-dependent parameter set. We say that $X$ is stochastically dominated by $Y$, uniformly in $u$, if for all (small) $\varepsilon>0$ and (large) $D>0$ we have
$$
\sup _{u \in U^{(N)}} \mathbb{P}\left[X^{(N)}(u)>N^{\varepsilon} Y^{(N)}(u)\right] \leqslant N^{-D}
$$
for large enough $N \geqslant N_0(\varepsilon, D)$. Unless stated otherwise, throughout this paper the stochastic domination will always be uniform in all parameters apart from  $\delta$, $\tau$, and the constants $\mu_p$ (which were fixed in Section~\ref{s:conventions});
%in \eqref{finite-moment} and $\tau,\delta$ in the statement of Theorem \ref{thm:CLT};
thus, $N_0(\varepsilon, D)$ also depends on $\mu_p,\tau,\delta$. If $X$ is stochastically dominated by $Y$, uniformly in $u$, we use the notation $X \prec Y$. Moreover, if for some complex family $X$ we have $|X| \prec Y$ we also write $X=O_{\prec}(Y)$
\end{definition}

We first introduce the isotropic local law for a single resolvent. 
\begin{theorem}[Isotropic local law]\label{thm:iso-single}
    Let $H$ be a Wigner matrix, let $G=(H-z)^{-1}$ be its resolvent.%, and fix $\omega >0$. Then 
    \begin{equation}\label{isotropic}
    \sup_{z\in \bm S}
\big|\langle\bm x, G(z) \mathbf{y}\rangle-\langle\bm x, \mathbf{y}\rangle \m(z)\big| \prec \sqrt{\frac{|\operatorname{Im} \m(z)|}{N \eta}}+\frac{1}{N \eta}
\end{equation}
%uniformly for $z=E+\iu\eta\in\bm S$ and
for any choice of deterministic vectors $\bm x,\bm y\in\mathbb S^{N-1}$, where $\eta = |\Im z|$. %In \eqref{isotropic}, the numbers $N_0$ in the definition of the $\prec$ notation (recall  Definition~\ref{def:stochasticDomination}) may additionally depend on $\omega$.
\end{theorem}
\begin{remark}\label{rmk:stochastic-continuation}
    In this and all following local laws, the high probability bound may be strengthened to hold simultaneously for all $z$ in the specified domain. For instance, \eqref{isotropic} may be strengthened to 
    \begin{align}
        \mathbb{P}\left[\bigcap_{z \in \mathbf{S}}\left\{\left|\langle\mathbf{x}, G(z) \mathbf{y}\rangle-\m(z)\langle\mathbf{x}, \mathbf{y}\rangle\right| \leqslant N^{\varepsilon}\left(\sqrt{\frac{\operatorname{Im} \m(z)}{N \eta}}+\frac{1}{N \eta}\right)\right\}\right] \geqslant 1-N^{-D},
    \end{align}
    for all $\epsilon>0,D>0$ and $N\geq N_0(\epsilon,D)$. It follows from a simple lattice argument combined with the Lipschitz continuity of $G,\m$ on $\bm S$. See \cite[Remark~2.7]{benaych2016lectures} for details.
\end{remark}

We next recall the definitions of a non-crossing partition and the Kreweras complement of a partition. We follow the notation of \cite{GW16}; see also \cite{kreweras1972partitions}.
\begin{definition}
For $k \in \mathbb{N}$, let $[k]$ denote the set $\{1,2,\dots, k\}$. A \emph{set partition} of $[k]$ is a set $\pi$ of disjoint subsets of $[k]$ whose union is $[k]$. The elements of $\pi$ are called \emph{blocks}. Given a set partition $\pi$, a \emph{bump} is an ordered pair $(i_1, i_2)$ such that $i_1$ and $i_2$ lie in the same block of $\pi$,  $i_1 < i_2$, and there is no $j$ in the same block with $i_1 < j < i_2$. We say that $\pi$ is a \emph{noncrossing partition} if for every pair of bumps $(i_1, i_2)$ and $(j_1, j_2)$ in $\pi$, it is not the case that $i_1 < j_1 < i_2 < j_2$. We let $\operatorname{NC}[k]$ denote the set of non-crossing partitions of $[k]$. %=\{1,\ldots,k\}$ arranged in in increasing order,
\end{definition}
\begin{definition}
Arrange the points in $[k]$ equidistantly on the boundary of the unit disk $\mathbb D$, with labels increasing counterclockwise. Label the arcs between adjacent points so that arc $i$ connects point $i$ to its neighbor in the counterclockwise direction. Given $\pi \in \operatorname{NC}[k]$, we define the \emph{Kreweras complement} $K(\pi)\in \operatorname{NC}[k]$ of $\pi$ to be the partition such that two points $x,y \in [k]$ belong to the same block of $K(\pi)$ if and only if the arcs $x,y$ are in the same connected component of $\mathbb D \setminus \cup_{B \in \pi} P_B$, where $P_B$ denotes the convex hull of the vertices in the block $B$.
\end{definition}


%Let $\operatorname{NC}[k]$ denote the non-crossing partitions of the set $[k]=\{1,\ldots,k\}$ arranged in in increasing order, and 

%$K(\pi)$ denote the Kreweras complement of $\pi$ \cite[Definition~2.4]{GW16}. 
Moreover, for $\pi \in \operatorname{NC}[k]$, and matrices $A_1, \dots, A_{k-1} \in \operatorname{Mat}_N$, we define the partial trace $\operatorname{pTr}_\pi$ associated to partition $\pi$ to be
\begin{align}
\begin{split}
    \operatorname{pTr}_\pi\left(A_1, \ldots, A_{k-1}\right)=\frac{1}{N}\prod_{B \in \pi \backslash B(k)}\Tr\left(\prod_{j \in B} A_j\right) \prod_{j \in B(k) \backslash\{k\}} A_j,
\end{split}
\end{align}
where $B(k)\in\pi$ denotes the unique block containing $k$. We recall that by convention, an empty product is equal to $1$.

For any subset $B\subset [k]$ we define 
\begin{align}
\begin{split}
    m[B]\defeq m_{\operatorname{sc}}\left[\{z_i\mid i\in B\}\right]=\int_{-2}^2\rho_{\operatorname{sc}}(x)\prod_{i\in B}\frac{1}{x-z_i}\, \mathrm{d}x.
\end{split}
\end{align}
For every $k \in \mathbb{N}$, let $m_\circ[\cdot]: 2^{[k]} \rightarrow \mathbb{C}$ denote the free-cumulant transform of $m[\cdot]$, which is defined implicitly by requiring that the relation
\begin{align}
\begin{split}
    m[B]=\sum_{\pi \in \operatorname{NC}(B)} \prod_{B^{\prime} \in \pi} m_{\circ}\left[B^{\prime}\right], \quad \forall B \subset[k].
\end{split}
\end{align}
holds for all $k$. 
For example, when $k=1$, we have $m_\circ[i] =m[i]$, and for $k=2$ we have $m_\circ[i,j] = m[i,j] -m[i]m[j]$. 
For further details, see the discussion following \cite[Definition 2.3]{cipolloni2022thermalisation}.

\begin{definition}
For arbitrary deterministic matrices $A_1,\ldots,A_{k-1}\in \operatorname{Mat}_N$ and spectral parameters $z_1,\ldots,z_k \in \mathbb{C} \backslash \mathbb{R}$, define
\begin{align}\label{Mdefinition}
\begin{split}
    M(z_1, A_1, \ldots, A_{k-1}, z_k):=\sum_{\pi \in \operatorname{NC}[k]} \operatorname{pTr}_{K(\pi)}\left(A_1, \ldots, A_{k-1}\right) \prod_{B \in \pi} m_{\circ}[B].
\end{split}
\end{align}
\end{definition}
We are now ready to state the multi-resolvent local laws necessary for our work.
%For positive quantities $f,g>0$, we write $f\lesssim g$ if there exists a constant $C>0$  such that $ f\le Cg$. 
\begin{lemma}[{\cite[Lemma 2.4]{CipErdSch22optimal}}]
Fix $k, m\in \mathbb{N}$ with $m\le k$ and a constant $C_0 >0$. Let $A_1,\dots, A_k \in \operatorname{Mat}_N$ be deterministic matrices such that $\left\|A_i\right\| \le C_0$ for all $1\le i \le k$, and suppose that 
%If %at least $m$  of these $k$ matrices %$B_1, \ldots, B_k$ with $\left\|B_i\right\| \lesssim 1$ 
%are traceless, i.e. 
$\Tr A_j=0$ holds for at least $m$ distinct indices $j$. Then there exists a constant $C=C(C_0,k)>0$ such that%(for some $0 \leq a \leq k$ ), then it holds that
\begin{equation}
\left| \Tr\left(M\left(z_1, A_1, \ldots, z_{k-1}, A_{k-1}, z_k\right) A_k\right)\right| \le \begin{cases}\frac{CN}{\eta^{k-1-\lceil m / 2\rceil}} & d \leq 1 \\
\frac{CN}{d^k} & d \geq 1\end{cases}\label{eqn:center-avg}
\end{equation}
and
\begin{equation}
\left\|M\left(z_1, A_1 \ldots, z_k, A_k, z_{k+1}\right)\right\| \le \begin{cases}\frac{C}{\eta^{k-\lceil m / 2\rceil}} & d \leq 1 \\
\frac{C}{d^{k+1}} & d \geq 1,\end{cases} \label{eqn:center-iso}
\end{equation}
where $\eta:=\min _j\left|\Im z_j\right|$ and $d:=\min _j \operatorname{dist}\left(z_j,[-2,2]\right)$.
\end{lemma}

\begin{theorem}[{\cite[Theorem 2.5]{CipErdSch22optimal}}]
Let $H$ be a $N\times N$ Wigner matrix and let $G=(H-z)^{-1}$ be its resolvent. Fix $m, k\in \mathbb{N}$ with $m \le k$ and $z_1, \ldots, z_{k+1} \in \bm S$. Fix $C_0>0$, and let $A_1, \ldots, A_k$ be deterministic matrices such that $\left\|A_j\right\| \le C_0$ for all $1 \le j \le k$, and $\Tr A_j=0$ for at least $m$ distinct indices $j$. 
%and such that at least $m$ of them are traceless for some $0 \leq m \leq k$. 
 Then %, we have %the optimal averaged local law
\begin{align}\label{eqn:avg}
\left| \Tr\left(G_1 A_1 \cdots G_k A_k-M\left(z_1, A_1, \ldots, A_{k-1}, z_k\right) A_k\right)\right| \prec \begin{cases}\frac{1}{ \eta^{k-m / 2}} & d \leq 1 \\ \frac{1}{ d^{k+1}} & d \geq 1,\end{cases}
\end{align}
and for any deterministic vectors $\boldsymbol{x}, \boldsymbol{y} \in \mathbb{R}^N$ such that $\|\boldsymbol{x}\|+\|\boldsymbol{y}\| \le C_0$, we have %the optimal isotropic local law
\begin{align}\label{eqn:iso}
\left|\left\langle\boldsymbol{x},\left(G_1 A_1 \cdots G_k A_k G_{k+1}-M\left(z_1, A_1, \ldots, A_k, z_{k+1}\right)\right) \boldsymbol{y}\right\rangle\right| \prec \begin{cases}\frac{1}{\sqrt{N} \eta^{k-m / 2+1 / 2}} & d \leq 1 \\ \frac{1}{\sqrt{N} d^{k+2}} & d \geq 1.\end{cases}
\end{align}
Here $G_j:=G\left(z_j\right)$, $\eta:=\min _j\left|\Im z_j\right|$, and $d:=\min_j\operatorname{dist}\left(z_j,[-2,2]\right)$. In \eqref{eqn:avg} and \eqref{eqn:iso}, the numbers $N_0$ in the definition of the $\prec$ notation (recall  Definition~\ref{def:stochasticDomination}) may depend on $k$ and $C_0$. 
\end{theorem}
\subsection{Central limit theorem for GOE}
We recall the following result from \cite[Theorems~2.3 and 2.4]{o2016eigenvectors}.
\begin{theorem}[Central Limit Theorem for GOE]\label{thm:GOE-CLT}
Let $H$ be drawn from Gaussian Orthogonal Ensemble and fix $\delta\in(0,1)$. For $N\geq 2$, let $\I=\I_N\in\llbracket N^{1-\delta},N\rrbracket$ be a deterministic sequence of subsets, let $\ell=\ell_N\in\llbracket1,N\rrbracket$ be a sequence of indices, and let $\bm u=\bm u_{\ell_N}^{(N)}$ be the corresponding sequence of $\ell^2$-normalized eigenvectors of $H$. Let $\left(\bm q_{\alpha}^{(N)}\right)_{\alpha\in\I}=\left(\bm q_\alpha\right)_{\alpha\in\I}$ be a deterministic sequence of sets of orthogonal vectors in $\mathbb S^{N-1}$. Then
\begin{equation}
\sqrt{\frac{ N^3}{2|\mathcal{I}|(N-|\mathcal{I}|)}}\left(\sum_{\alpha \in \mathcal{I}}\left\langle\boldsymbol{q}_\alpha, \boldsymbol{u}\right\rangle^2-\frac{|\mathcal{I}|}{N}\right) \rightarrow \mathcal{N}(0,1),
\end{equation}
with convergence in the sense of moments.
\end{theorem}
\subsection{Quantum Unique Ergodicity}
We also recall the following quantum unique ergodicity result from \cite[Theorem~1.4]{BenLop22QUE}.
\begin{theorem}
Let $H$ be a Wigner matrix. Let $\I=\I_N \subset \llbracket 1, N \rrbracket$ be a deterministic sequence of subsets, let $\ell=\ell_N\subset \llbracket 1, N \rrbracket$ be a sequence of indices, and let $\bm u=\bm u_{\ell_N}^{(N)}$ be the corresponding sequence of eigenvectors of $H$. Let $\left(\mathbf{q}_\alpha\right)_{\alpha \in I}=\left(\mathbf{q}_\alpha^{(N)}\right)_{\alpha \in \I}$ be a deterministic sequence of sets of orthogonal vectors in $\mathbb{S}^{N-1}$. Then
\begin{align}\label{eqn:que}
\begin{split}
    \left|\sum_{\alpha\in\I}\left\langle \q_\alpha,\bm u\right\rangle^2-\frac{|\I|}{N}\right|\prec \frac{\sqrt{|\I|}}{N}.
\end{split}
\end{align}
\end{theorem}



\section{Regularized observables}\label{sec:regularized-observables}



\subsection{Definitions}
We begin by defining notation for the self-overla{}ps and typical eigenvalue spacings.
\begin{definition}[Self-overlaps and spacings]\label{def:selfoverlap}
Let $H$ be a $N\times N$ Wigner matrix. % and fix $\delta,\tau\in(0,1)$.
%Let $\I=\I_N\subset\llbracket\delta N,N\rrbracket$ be a deterministic subset, $\ell=\ell_N \in \llbracket 1, N^{1-\tau} \rrbracket\cup\llbracket N-N^{1-\tau},N\rrbracket$ be a sequence of indices, and let $(\q^{(N)}_\alpha)_{\alpha\in\I}=(\q_\alpha)_{\alpha\in\I}$ be a deterministic sequence of sets of orthogonal vectors in $\mathbb S^{N-1}$. 
Define the self-overlap %of $k$-th $\ell^2$-normalized 
of the eigenvector $\bm u_k$ by
\begin{align}
\begin{split}
    p_k=p_k(\I)\defeq\sum_{\alpha \in \mathcal{I}}\left\langle\bm{q}_\alpha, \bm{u}_k\right\rangle^2-\frac{|\mathcal{I}|}{N}.
\end{split}
\end{align}
Denote the normalized $p_k$ as 
\begin{align}
    \widehat{p}_k := \sqrt{\frac{ N^3}{2|\mathcal{I}|(N-|\mathcal{I}|)}}p_k.
\end{align}
Denote the typical size of the $k$-th eigenvalue gap by
\begin{align}
\begin{split}
    \Delta_k=N^{-2/3}k^{-1/3}.
\end{split}
\end{align}
\end{definition}
We next define $v_\ell$, which serves as the regularization of a scaled version of $p_\ell$. 
\begin{definition}[Smoothed indicator function]
For any $E_1,E_2 \in\R$ with $E_1<E_2$, and $\eta >0$,
let $f_{E_1,E_2, \eta}$ denote %the characteristic function on $[a,b]$ smoothed on scale $\eta$, i.e.
a function such that
$f_{E_1,E_2,\eta}=1$ on $[E_1,E_2]$, $f_{E_1,E_2,\eta}=0$ on $\R\backslash[E_1-\eta,E_2+\eta]$, and $|f_{E_1,E_2,\eta}'|\leq C\eta^{-1}, |f_{E_1,E_2,\eta}''|\leq C\eta^{-2}$ on $\mathbb{R}$.
\end{definition}
\begin{definition}[Regularized self-overlap]\label{def:regularized}
%Retain the notation and assumptions of Definition~\ref{def:selfoverlap}.


Let $\delta_i>0$ for $1 \le i \le 5$ be parameters, and let $H$ be a Wigner matrix. Define 
\begin{equation}\label{regularizednotation}
\begin{gathered}
 \eta_\ell=\Delta_\ell N^{-\delta_1},\quad I_\ell=\left[\gamma_\ell-\Delta_\ell N^{\delta_2}, \gamma_\ell+\Delta_\ell N^{\delta_2}\right],\quad E^{\pm}=E \pm \Delta_\ell N^{-\delta_3}, \\
 f_E=f_{-3, E^{+},\Delta_\ell N^{-\delta_4}} ,\quad\tilde{\eta}_\ell=\Delta_\ell N^{-\delta_5}.
\end{gathered}
\end{equation}
Let $\tilde f=f_{-\frac{\kappa}{2},\frac{\kappa}{2},\frac{\kappa}{2}}$, where $\kappa=\left(\frac{\ell}{N}\right)^{2/3}$, and set $q=f_{\ell-\frac{1}{3},\ell+\frac{1}{3},\frac{1}{3}}$. 
Let $\tilde f=f_{-\frac{\kappa}{2},\frac{\kappa}{2},\frac{\kappa}{2}}$, where $\kappa=\left(\frac{\ell}{N}\right)^{2/3}$, and set $q=f_{\ell-\frac{1}{3},\ell+\frac{1}{3},\frac{1}{3}}$. 

% Fix $\epsilon >0$, by \eqref{eqn:que} we find $\delta_0(\epsilon, \delta)$ such that with high probability 
% \begin{equation}\label{eqn:quebound}
% |\widehat{p_k}|\leq N^{\delta_0}.
% \end{equation}

Define
\begin{equation}\label{eqn:regularized-x}
\begin{aligned}
x(E) \equiv x_\ell(E) & =\frac{\eta_\ell}{\pi} \sum_{i} \frac{\hat{p}_i}{\left(\lambda_i-E\right)^2+\eta_\ell^2} \\
& =\frac{\eta_\ell}{\pi} \sqrt{\frac{N^3}{2|\I|(N-|\I|)}} \left[\sum_{\alpha\in\I}\sum_iG_{\q_\alpha i}\bar G_{i\q_\alpha}-\sum_{\beta}\sum_iG_{\q_\beta i}\bar G_{i\q_\beta}\right] \\
& =\frac{\eta_\ell}{\pi} \sqrt{\frac{N^3}{2|\I|(N-|\I|)}}\left[\sum_{\alpha\in\I}\left(1-\frac{|\I|}{N}\right)(G\bar G)_{\q_\alpha\q_\alpha}-\sum_{\alpha\notin\I}\frac{|\I|}{N}(G\bar G)_{\q_\alpha\q_\alpha}\right] ,
\end{aligned}
\end{equation}
and
\begin{equation}\label{eqn:regularized-y}
\begin{aligned}
y(E) \equiv y_\ell(E)= & \frac{1}{2 \pi} \int_{\mathbb{R}^2} \mathrm{i} \sigma f_E^{\prime \prime}(e) \tilde f(\sigma) \operatorname{Tr} G(e+\mathrm{i} \sigma) \bm{1}\left(|\sigma|>\tilde{\eta}_\ell\right) \mathrm{d} e \mathrm{~d} \sigma \\
& +\frac{1}{2 \pi} \int_{\mathbb{R}^2}\left(\mathrm{i} f_E(e) \tilde f^{\prime}(\sigma)-\sigma f_E^{\prime}(e) \tilde f^{\prime}(\sigma)\right) \operatorname{Tr} G(e+\mathrm{i} \sigma)\, \mathrm{d} e \mathrm{~d} \sigma,
\end{aligned}
\end{equation}
Finally, set $\bm \delta = (\delta_1, \dots, \delta_5)$ and define the regularized observable %of suitably scaled $p_\ell$ as
\begin{equation}\label{eqn:regularized-observable}
v_\ell=v_\ell(\bm \delta, \mathcal I)=\int_{I_\ell} x(E) q\left(y_E\right) \mathrm{d} E.
\end{equation}
\end{definition}
Before stating the main lemma in this section, we need the following several results.
\begin{theorem}[Eigenvalue Rigidity {\cite[Theorem 2.2]{erdos2012rigidity}}] Let $H$ be a Wigner matrix. For all $i\in\llbracket1,N\rrbracket$, we have
\begin{equation}\label{eqn:rig}
|\lambda_i-\gamma_i|  \prec\Delta_i.
\end{equation}
\end{theorem}
\begin{proposition}[Level repulsion at the edge {\cite[Proposition 5.7]{BL22LInfinity}}] 
Let $H$ be a Wigner matrix. Then there exists $\epsilon_0>0$ such that for all $\epsilon\in(0,\epsilon_0)$, there exists constants $C=C(\epsilon)$ such that for any $i\in\llbracket1,\lfloor N/2\rfloor\rrbracket$,
\begin{align}\label{eqn:level-repulsion}
\begin{split}
    \P\left(\lambda_{i+1}-\lambda_i<N^{-2/3-\epsilon}i^{-1/3}\right)\leq CN^{-\epsilon}.
\end{split}
\end{align}
\end{proposition}
\begin{lemma}[{{\cite[Lemma~4.9]{BL22LInfinity}}}]With the definitions in Definition \ref{def:regularized}, for any $\epsilon>0$, there exists $C=C(\epsilon)$ such that\footnotemark
\begin{align}\label{eqn:small-remaining-terms}
\sum_{i:|i-\ell| \geqslant N^{\epsilon}} \frac{1}{\left(\lambda_i-\lambda_\ell\right)^2}  \prec N^{4 / 3-\epsilon} \ell^{2 / 3}.
\end{align}
\footnotetext{There is a misprint in \cite[Lemma~4.9]{BL22LInfinity}. The sign of the $\omega$ on the right hand side of the inequality should be negative.}
\end{lemma}\label{lem:bound-x-integral}
\begin{lemma}With $I_\ell$ defined in \eqref{regularizednotation} and $x(E)$ defined in \eqref{eqn:regularized-x}, we have
\begin{align}\label{eqn:bound-x-integral}
\begin{split}
    \int_{I_\ell}|x(E)|\chi(E)\,\d E\prec N^{\delta_2},
\end{split}
\end{align}
where $\chi(E)=\bm 1(\lambda_{\ell}\leq E^+\leq \lambda_{\ell+1})$.
\end{lemma}
\begin{proof}By the QUE bound \eqref{eqn:que}, it suffices to show
\begin{align}\label{eqn:bound-integral}
\begin{split}
    \sum_{i}\int_{I_\ell}\frac{\eta_\ell}{\pi}\frac{1}{(\lambda_i-E)^2+\eta_\ell^2}\chi(E)\,\d E\prec N^{\delta_2}.
\end{split}
\end{align}
We break the integral \eqref{eqn:bound-integral} into two parts, and find that it equals
\begin{align}\label{eqn:integral-break}
\begin{split}
    \sum_{i:|i-\ell|< N^{\delta_2}}\int_{I_\ell}\frac{\eta_\ell}{\pi}\frac{1}{(\lambda_i-E)^2+\eta_\ell^2}\chi(E)\, \d E+\sum_{i:|i-\ell|\geq N^{\delta_2}}\int_{I_\ell}\frac{\eta_\ell}{\pi}\frac{1}{(\lambda_i-E)^2+\eta_\ell^2}\chi(E)\, \d E.
\end{split}
\end{align}
For the first term in \eqref{eqn:integral-break}, using the integral
\begin{align}
\begin{split}
    \int\frac{\eta_\ell}{E^2+\eta_\ell^2}\d E=\pi,
\end{split}
\end{align}
we can bound it by 
\begin{align}\label{eqn:bound-integral-break-1}
\begin{split}
    \sum_{i:|i-\ell|< N^{\delta_2}}\int_{I_\ell}\frac{\eta_\ell}{\pi}\frac{1}{(\lambda_i-E)^2+\eta_\ell^2}\chi(E)\d E<2N^{\delta_2}.
\end{split}
\end{align}
For the second term in \eqref{eqn:integral-break}, using \eqref{eqn:small-remaining-terms}, it follows that
\begin{align}\label{eqn:bound-integral-break-2}
\begin{split}
    \sum_{i:|i-\ell|\geq N^{\delta_2}}\int_{I_\ell}\frac{\eta_\ell}{\pi}\frac{1}{(\lambda_i-E)^2+\eta_\ell^2}\chi(E)\d E\prec N^{-\delta_2-\delta_1}.
\end{split}
\end{align}
Combining \eqref{eqn:bound-integral-break-1} and \eqref{eqn:bound-integral-break-2}, the proof is complete.
\end{proof}
The following lemma is our main comparison result for the smoothed observable $v_\ell$. 
\begin{lemma}\label{lem:regularized-observable}
Let $H$ be a Wigner matrix and suppose that $\lambda_\ell$ satisfies level repulsion estimate \eqref{eqn:level-repulsion} with 
\begin{equation*}
\epsilon=\epsilon_1\defeq\min\{\epsilon_0/2,\tau/10000\}.
\end{equation*}
Fix parameters
\begin{align*}
\begin{split}
    \delta_1=2\epsilon_1,\,\delta_2=\frac{\epsilon_1}{\max\{C_0+1,100\}},\, \delta_3=\frac{\epsilon_1}{2},\,\delta_4=6\epsilon_1,\,\delta_5=8\epsilon_1.
\end{split}
\end{align*}
Fix $C_0> 0$, and let $g:\R\rightarrow\R$ be a smooth function satisfying
\begin{align}\label{eqn:poly-growth}
\begin{split}
    |g'(x)|\leq C_0(1+|x|)^{C_0}.
\end{split}
\end{align}
Then there exists a constant $c(\tau)>0$ such that 
% \blue{Under the assumption on $\ell$, we find constants $\epsilon$ and $a$ for $\lambda_\ell$ satisfying \eqref{eqn:level-repulsion} and constant $\delta_0$ from \eqref{eqn:quebound}. Let $\eta_\ell := \Delta_\ell N^{-\delta_1}$, where $\delta_1> \epsilon+(C_0+1)\delta_0$. Then for small enough constants $\delta_3 = \delta_3(a, \epsilon,\delta_1)$ and $ \delta_2 = \delta_2(\epsilon, a,\delta_3)$, there is
% some constant $c(\delta, \tau, C_0)>0$ such that}
\begin{align*}
\begin{split}
    \left| \E \left[g\left(\hat{p}_\ell(\mathcal I)\right)\right]-\E \big[g\big(v_\ell(\bm \delta, \mathcal I)\big) \Big] \right|\le c^{-1} N^{-c}.
\end{split}
\end{align*}
\end{lemma}
% \blue{I showed it for $N^{-c}=N^{-\delta_2}$, but I'm not sure if I should just leave it as $c$ for all the lemmas below. I left maybe a bit too much details for now because I'm not sure what information is necessary to keep. One idea of the simplification is to absorb all the $N^{\delta_0,\delta_1}$ into big $O$ or constant $C$, or simply use $O_\prec$.}\\
To prove Lemma \ref{lem:regularized-observable}, it suffices to establish Lemmas \ref{lem:reg-ob-1}, \ref{lem:reg-ob-2} and \ref{lem:reg-ob-3}. 
% We need the following theorems for the proof. 
% \begin{theorem}[Eigenvalue Rigidity {\cite[Theorem 2.2]{erdos2012rigidity}}] Let $H$ be a Wigner matrix. For all $i\in\llbracket1,N\rrbracket$, we have
% \begin{equation}\label{eqn:rig}
% |\lambda_i-\gamma_i|  \prec\Delta_i.
% \end{equation}
% \end{theorem}

% \begin{proposition}[Level repulsion at the edge {\cite[Proposition 5.7]{BL22LInfinity}}] 
% Let $H$ be a Wigner matrix. Then there exists $\epsilon_0>0$ such that for all $\epsilon\in(0,\epsilon_0)$, there exists constants $C=C(\epsilon)$ such that for any $i\in\llbracket1,\lfloor N/2\rfloor\rrbracket$,
% \begin{align}\label{eqn:level-repulsion}
% \begin{split}
%     \P\left(\lambda_{i+1}-\lambda_i<N^{-2/3-\epsilon}i^{-1/3}\right)\leq CN^{-\epsilon}.
% \end{split}
% \end{align}
% \end{proposition}

\begin{lemma}\label{lem:reg-ob-1}
    Maintain the notation and assumptions of Lemma \ref{lem:regularized-observable}.
    Recalling Definition \ref{def:regularized}, we have
\begin{align*}
\begin{split}
    \E [g(\widehat{p}_\ell)]-\E \left[g\left(\int_{I_\ell} x(E) \chi(E)\right)\right]=O(N^{-\epsilon_1/4}),
\end{split}
\end{align*}
where $\chi(E):= \bm1\left(\lambda_\ell\leq E^+ \leq \lambda_{\ell+1}\right)$.
\end{lemma}
\begin{proof}
We first write 
\begin{equation}\label{e0}
    \widehat{p_\ell}=\frac{\eta_\ell}{\pi}\int \frac{\widehat{p_{\ell}}}{(E-\lambda_\ell)^2+\eta_\ell^2}\;\mathrm{d} E. 
\end{equation}
%Let 
%\begin{equation}
%a \;\leq\; \lambda_\alpha^-,\;\;\;\;\;\; b \;\geq\; \lambda_\alpha^+\,,
%\end{equation}

By the assumption \eqref{eqn:poly-growth} on $g$, rigidity \eqref{eqn:rig}, and quantum unique ergodicity \eqref{eqn:que}, we write
\begin{align}\label{e0.1}
\begin{split}
    \E\left[g(\hat p_\ell)\right]=&\E\left[g\left(\frac{\eta_\ell}{\pi}\int_{E_1}^{E_2}\frac{\hat p_\ell}{(E-\lambda_\ell)^2+\eta_\ell^2}\d E\right)\right]+O_\prec(N^{-\delta_1+\delta_3})\\
    =&\E\left[g\left(\frac{\eta_\ell}{\pi}\int_{E_1}^{E_2}\frac{\hat p_\ell}{(E-\lambda_\ell)^2+\eta_\ell^2}\d E\right)\right]+O(N^{-\epsilon_1/2}),
\end{split}
\end{align}
where
\begin{align*}
\begin{split}
    E_1=\lambda_\ell^-,\quad E_2= \max\left\{\lambda_\ell^{+},\lambda_{\ell+1}^-\right\}.
\end{split}
\end{align*}
% Given $\alpha \;\leq\; \lambda_\ell^- $ and $ \beta \;\geq\; \lambda_\ell^+\,,$ by \eqref{eqn:quebound} with high probability
% \begin{equation*}
%      \widehat{p_\ell}=\frac{\eta_\ell}{\pi}\int_\alpha^\beta\frac{\widehat{p_{\ell}}}{(E-\lambda_\ell)^2+\eta_\ell^2} \;\mathrm{d} E + O(N^{\delta_0-\delta_3}).
% \end{equation*}
% Let $\alpha = \text{min}(\lambda_{\ell}^-, \lambda_{\ell-1}^+), \beta = \lambda_{\ell}^+$. Apply the mean value theorem on $g$ and \eqref{eqn:quebound}, we have 
% \begin{equation}
%         \E g(\widehat{p_\ell}) = \E g\left[\frac{\eta_\ell}{\pi}\int_\alpha^\beta \frac{\widehat{p_{\ell}}}{(E-\lambda_\ell)^2+\eta_\ell^2} \;\mathrm{d} E\right] + O(N^{(C_0+1)\delta_0-\delta_3}),
% \end{equation}
% where $\delta_3>(C_0+1)\delta_0$. 
We now show that the integral over $[E_1,E_2]$ can be approximated by integrating over $[\lambda_\ell^-, \lambda_{\ell+1}^-]$. From \eqref{eqn:level-repulsion} and the parameter choice $\delta_3=\epsilon_1/2$, we have
\begin{align*}
\begin{split}
\P\left(\lambda_{\ell+1}^-\leq \lambda_\ell^+\right)\leq N^{-\epsilon_1/2}.
\end{split}
\end{align*}
Decomposing the integral
\begin{align}\label{eqn:level-repulsion-specific}
\begin{split}
    \int_{E_1}^{E_2}=\int_{\lambda_{\ell}^-}^{\lambda_{\ell+1}^{-}}+\bm 1\left(\lambda_{\ell+1}^-\leq \lambda_\ell^+\right)\int_{\lambda_{\ell+1}^-}^{\lambda_{\ell}^+},
\end{split}
\end{align}
we have
\begin{align*}
\begin{split}
    \E\big[g(\hat p_\ell)\big]=&\E\left[g\left(\frac{\eta_\ell}{\pi}\int_{\lambda_\ell^-}^{\lambda_{\ell+1}^-}\frac{\hat p_\ell}{(E-\lambda_\ell)^2+\eta_\ell^2}\d E\right)\right]+O_\prec(\P\left(\lambda_{\ell+1}^-\leq \lambda_\ell^+\right))+O(N^{-\epsilon_1/2})\\
    =&\E\left[g\left(\frac{\eta_\ell}{\pi}\int_{\lambda_\ell^-}^{\lambda_{\ell+1}^-}\frac{\hat p_\ell}{(E-\lambda_\ell)^2+\eta_\ell^2}\d E\right)\right]+O(N^{-\epsilon_1/4})
\end{split}
\end{align*}
where we used the polynomial growth of $g$ \eqref{eqn:poly-growth} and the quantum unique ergodicity \eqref{eqn:que} in the first step and \eqref{eqn:level-repulsion-specific} in the second step.
% We first split the integral into
% \begin{align*}
% \int_\alpha^\beta \frac{\widehat{p_{\ell}}}{(E-\lambda_\ell)^2+\eta_\ell^2} \;\mathrm{d} E 
% &\;=\; \int_{\lambda_{\ell - 1}^+}^{\lambda_\ell^+} \frac{\widehat{p_{\ell}}}{(E-\lambda_\ell)^2+\eta_\ell^2} \;\mathrm{d} E + \textbf{1}(\ell_{\ell - 1}^+ > 
% \lambda_\ell^-)\int_{\lambda_\ell^-}^{\lambda_{\ell-1}^+}\frac{\widehat{p_{\ell}}}{(E-\lambda_\ell)^2+\eta_\ell^2} \;\mathrm{d} E\\
% &\;=\; \int_{\lambda_{\ell - 1}^+}^{\lambda_\ell^+} \frac{\widehat{p_{\ell}}}{(E-\lambda_\ell)^2+\eta_\ell^2} \;\mathrm{d} E +\textbf{1}(\lambda_{\ell - 1}^+ > 
% \lambda_\ell^-)O(|\widehat{p_{\ell}}|\eta_{\ell}^{-1}N^{-\delta_3}).
% \end{align*}
% The first term on the right hand side of \eqref{e0.1} becomes 
% \begin{align*}
% \E g\left[\frac{\eta_\ell}{\pi}\int_\alpha^\beta \frac{\widehat{p_{\ell}}}{(E-\ell_\ell)^2+\eta_\ell^2} \;\mathrm{d} E\right] &=\E g\left[\frac{\eta_\ell}{\pi}\int_{\lambda_{\ell - 1}^+}^{\ell_\ell^+} \frac{\widehat{p_{\ell}}}{(E-\lambda_\ell)^2+\eta_\ell^2} \;\mathrm{d} E\right]+\P(\lambda_{\ell - 1}^+ > 
% \lambda_\ell^-)\;O(N^{(C_0+1)\delta_0-\delta_3})\\
% &= \E g\left[\frac{\eta_\ell}{\pi}\int_{\lambda_{\ell - 1}^+}^{\lambda_\ell^+} \frac{\widehat{p_{\ell}}}{(E-\lambda_\ell)^2+\eta_\ell^2} \;\mathrm{d} E\right]+O(N^{(C_0+1)\delta_0-2\delta_3})\\
% &= \E g\left[\frac{\eta_\ell}{\pi}\int_{I_\ell}\frac{\widehat{p_{\ell}}}{(E-\lambda_\ell)^2+\eta_\ell^2}\chi(E) \;\mathrm{d} E\right]+O(N^{(C_0+1)\delta_0-2\delta_3}).
% \end{align*}
By rigidity \eqref{eqn:rig},
\begin{align*}
\begin{split}
    |\lambda_\ell-\gamma_\ell|\prec \Delta_\ell,\quad |\lambda_{\ell+1}-\gamma_\ell|\prec \Delta_\ell,
\end{split}
\end{align*}
we have
\begin{align}\label{e0.2}
\begin{split}
    \E\left[g(\hat p_\ell)\right]=\E\left[g\left(\frac{\eta_\ell}{\pi}\int_{I_\ell}\frac{\hat p_\ell}{(E-\lambda_\ell)^2+\eta_\ell^2}\chi(E)\d E\right)\right]+O(N^{-\epsilon_1/4}).
\end{split}
\end{align}
% We use \eqref{eqn:quebound} and the assumptions on $g$ to get the first equality. Setting $\delta_3<\min{(\delta_1-\epsilon,a/3)}$, by the level repulsion \eqref{eqn:level-repulsion}, we have  $\P(\lambda_{\ell - 1}^+ > 
% \lambda_\ell^-)\leq N^{-a}\leq N^{-\delta_3}$. The second equality follows. For the third equality, we recall that %$I_\ell=\left[\gamma_\ell-\Delta_\ell N^{\delta_2}, \gamma_\ell+\Delta_\ell N^{\delta_2}\right],$ $\chi(E):= \lambda_{k-1} \leq E^- \leq \lambda_k$, \\
% by the definition of $\chi(E)$ and $I_\ell$, we have $\lambda_{\ell-1}^+\leq E\leq \lambda_{\ell}^+$
% and $\gamma_{\ell-1}+\Delta_{\ell}N^{\delta_3}\leq E\leq \gamma_{\ell}+\Delta_{\ell}N^{\delta_3} $. By the rigidity of eigenvalues \eqref{eqn:rig}, we have $\chi(E)\subseteq I_{\ell}$ with high probability. Now \eqref{e0.1} becomes
% \begin{equation}\label{e0.2}
%     \E g(\widehat{p_k}) = \E g\left[\frac{\eta_\ell}{\pi}\int_{I_\ell}\frac{\widehat{p_{\ell}}}{(E-\lambda_\ell)^2+\eta_\ell^2}\chi(E) \;\mathrm{d} E\right]+O(N^{(C_0+1)\delta_0-\delta_3}).
% \end{equation}
Our next goal is to replace the first term on the right hand side of \eqref{e0.2} by the following.
\begin{align}%\label{eq1}
    \E g\left[\int_{I_{\ell}} x(E) \chi(E)\right] =\E g\bigg[\frac{\eta_\ell}{\pi}\int_{I_\ell}\frac{\hat p_\ell}{(E-\lambda_\ell)^2+\eta_\ell^2}\chi(E) \;\mathrm{d} E+\frac{\eta_\ell}{\pi}\sum_{i\neq\ell} \int_{I_{\ell}} \frac{\hat p_i}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\chi(E) \;\mathrm{d} E\bigg]. 
\end{align}
Using mean value theorem, \eqref{eqn:bound-x-integral} and \eqref{e0.2} in the first step, and \eqref{eqn:small-remaining-terms} and \eqref{eqn:que} in the second step, we have
\begin{align}\label{e1}
\begin{split}
    &\left|\E\left[g(\hat p_\ell)\right]-\E\left[g\left(\int_{I_\ell}x(E)\chi(E)\d E\right)\right]\right|\\
    \leq&\,O_\prec(N^{C_0\delta_2})\left|\E\left[\sum_{i\neq \ell}\int_{I_\ell}\frac{\eta_\ell}{\pi}\frac{\hat p_i}{(\lambda_i-E)^2+\eta_\ell^2}\chi(E)\d E\right]\right|+O(N^{-\epsilon_1/4})\\
    = &O_\prec(N^{C_0\delta_2})\E\left[\sum_{i:1\leq|i-\ell|<N^{\delta_2}}\int_{I_\ell}\frac{\eta_\ell}{\pi}\frac{1}{(\lambda_i-E)^2+\eta_\ell^2}\chi(E)\d E\right]+O_\prec(N^{C_0\delta_2-\delta_1})+O(N^{-\epsilon_1/4})\\
    =&O_\prec(N^{C_0\delta_2})\E\left[\sum_{i:1\leq|i-\ell|<N^{\delta_2}}\int_{I_\ell}\frac{\eta_\ell}{\pi}\frac{1}{(\lambda_i-E)^2+\eta_\ell^2}\chi(E)\d E\right]+O(N^{-\epsilon_1/4}).
\end{split}
\end{align}
% By the mean value theorem and the assumptions on $g$, we have 
% \begin{align}
% \begin{aligned}\label{e1}
%      &\quad \bigg|\E g(\widehat{p_k})-\E g\left[\int_{I_{\ell}} x(E) \chi(E)\right]\bigg|\\
%      &\leq C_0(1+|x|)^{C_0} \E \left[\frac{\eta_\ell}{\pi} \sum_{i\neq\ell} \int_{I_{\ell}} \frac{|\widehat{p_i}|}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\chi(E)\;\mathrm{d} E\right]+O(N^{(C_0+1)\delta_0-\delta_3}),
% \end{aligned}
% \end{align}
% where $|x|$ is bounded with high probability by 
% \begin{align}\label{eqn:sum-que-bound}
%     |x|\leq \frac{\eta_\ell}{\pi} &\sum_{i}^{N} \int_{I_{\ell}} \frac{|\widehat{p_i}|}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\;\mathrm{d} E \leq CN^{C_1\delta_2}
% \end{align}
% for some $C_1>0$. To prove \eqref{eqn:sum-que-bound}, We first break the sum into:
% \begin{align}
% \frac{\eta_\ell}{\pi} \sum_{i}^{N} \int_{I_{\ell}} \frac{|\widehat{p_i}|}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\;\mathrm{d} E 
% &=\frac{\eta_\ell}{\pi} \sum_{|i-l|\leq N^{C_1\delta_2}} \int_{I_{\ell}} \frac{|\widehat{p_i}|}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\;\mathrm{d} E \label{e1.1} \\ 
% &+\frac{\eta_\ell}{\pi} \sum_{|i-l| > N^{C_1\delta_2}} \int_{I_{\ell}} \frac{|\widehat{p_i}|}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\;\mathrm{d} E.\label{e1.2}   
% \end{align}
% For the right side of  \eqref{e1.1}. Since $\frac{\eta_\ell}{\pi}\int \frac{1}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\;\mathrm{d} E = 1$, by \eqref{eqn:quebound} we find with high probability
% \begin{align}\label{eqn:sum-que-bound0.1}
%     &\frac{\eta_\ell}{\pi} \sum_{|i-l|\leq N^{C_1\delta_2}} \int_{I_{\ell}} \frac{|\widehat{p_i}|}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\;\mathrm{d} E
%     %&\leq N^{\delta_0}N^{C_1\delta_2}\frac{\eta_\ell}{\pi}\int \frac{1}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\;\mathrm{d} E \\
%     \leq CN^{\delta_0 + C_1\delta_2}.
% \end{align}
%  By the eigenvalue rigidity bound \eqref{eqn:rig} and $|\gamma_i-\gamma_l|\geq c\big[\frac{|i-l|}{N}\big]^{\frac{2}{3}}$, for $C_1$ large enough and $E\in I_\ell$, we have $\frac{1}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\geq \big[\frac{|i-l|}{N}\big]^{\frac{2}{3}}$, where $|i-l| > N^{C_1\delta_2}$. Hence with high probability the bound for \eqref{e1.2} becomes 
% \begin{align}\label{eqn:sum-que-bound0.2}
% \frac{\eta_\ell}{\pi} \sum_{|i-l| > N^{C_1\delta_2}} &\int_{I_{\ell}} \frac{|\widehat{p_i}|}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\;\mathrm{d} E \nonumber
% \leq CN^{\delta_0+\delta_2}\Delta_{\ell}\sum_{|i-l| > N^{C_1\delta_2}}\frac{\eta_\ell}{\big[\frac{|i-l|}{N}\big]^{\frac{4}{3}}}\\
% &\leq C\Delta_{\ell}^2N^{\delta_0-\delta_2(C_1-1)-\delta_1+4/3} \leq CN^{\delta_0-C_1\delta_2-\delta_1}.%\leq CN^{-C_1\delta_2}?.
% \end{align}
% The last inequality follows by choosing $C_1\geq 1$ large enough. Since  $\delta_0<\delta_1$, by \eqref{eqn:sum-que-bound0.1} and \eqref{eqn:sum-que-bound0.2}, we conclude \eqref{eqn:sum-que-bound}.  
Next we would like to bound the expectation term in the right hand side of \eqref{e1}. 
We decompose it
into two parts.

Firstly, for $i>\ell$, we have
\begin{multline}\label{eqn:small-terms-1}
\E\left[\sum_{i:1\leq i-\ell<N^{\delta_2}}\int_{I_\ell}\frac{\eta_\ell}{\pi}\frac{1}{(\lambda_i-E)^2+\eta_\ell^2}\chi(E)\d E\right]\leq N^{\delta_2}\E\left[\int_{-\infty}^{\lambda_{\ell+1}^-}\frac{\eta_\ell}{\pi}\frac{1}{(\lambda_{\ell+1}-E)^2+\eta_\ell^2}\d E\right]\\
\prec N^{\delta_2-\delta_1+\delta_3}.
\end{multline}
Suppose now that $i<\ell$.
On the event $\mathcal B\defeq\bm 1(\lambda_\ell-\lambda_{\ell-1}>4\Delta_{\ell}N^{-\delta_3})$, we have
\begin{align*}
\begin{split}
    \chi(E)(E-\lambda_i)^2\geq (\lambda_{\ell}-\lambda_{i})^2-2\Delta_\ell N^{-\delta_3}(\lambda_\ell-\lambda_i)\geq \frac{1}{2}(\lambda_\ell-\lambda_i)^2\geq\frac{1}{2}(\lambda_\ell-\lambda_{\ell-1})^2.
\end{split}
\end{align*}
Therefore, 
\begin{align*}
\begin{split}
    \bm 1(\mathcal B)\chi(E)\frac{1}{(E-\lambda_i)^2+\eta_{\ell}^2}\leq \bm 1(\mathcal B)\chi(E)\frac{2}{(\lambda_\ell-\lambda_{\ell-1})^2+\eta_\ell^2}\leq \chi(E)\frac{N^{2\delta_3}}{8\Delta_\ell^2}.
\end{split}
\end{align*}
Now we have,
\begin{align}\label{eqn:small-terms-2}
\begin{split}
    \E\left[\sum_{i:1\leq \ell-i<N^{\delta_2}}\int_{I_\ell}\frac{\eta_\ell}{\pi}\frac{1}{(\lambda_i-E)^2+\eta_\ell^2}\chi(E)\d E\right]\prec\, N^{\delta_2}\P\left(\mathcal B^c\right)+N^{\delta_2}\eta_\ell\Delta_\ell\frac{N^{2\delta_3}}{\Delta_\ell^2}\leq\,N^{\delta_2-\frac{2}{3}\delta_3},
\end{split}
\end{align}
where we used $\lambda_{\ell+1}-\lambda_\ell\prec \Delta_\ell$ in the first inequality and \eqref{eqn:level-repulsion} in the second inequality.
Combining \eqref{eqn:small-terms-1} and \eqref{eqn:small-terms-2}, we have
\begin{align}\label{eqn:small-terms-all}
\begin{split}
    \E\left[\sum_{i:1\leq|i-\ell|<N^{\delta_2}}\int_{I_\ell}\frac{\eta_\ell}{\pi}\frac{1}{(\lambda_i-E)^2+\eta_\ell^2}\chi(E)\d E\right]\prec N^{\delta_2-\frac{2}{3}\delta_3}.
\end{split}
\end{align}

% We start by splitting the sum.
% \begin{align}
%     \E \left[\frac{\eta_\ell}{\pi} \sum_{i\neq\ell} \int_{I_{\ell}} \frac{\widehat{p_i}}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\chi(E)\;\mathrm{d} E\right] &=
%     \E \left[\frac{\eta_\ell}{\pi} \sum_{|i-l| \geq N^{C_1\delta_2}} \int_{I_{\ell}} \frac{\widehat{p_i}}{\left(\lambda_i-E\right)^2+\eta_\ell^2}\chi(E)\;\mathrm{d} E\right] \label{e2} \\
%     &+\E \left[\frac{\eta_\ell}{\pi} \sum_{i\neq l,|i-l| \leq N^{C_1\delta_2}}  \int_{I_{\ell}} \frac{\widehat{p_i}}{\left(\lambda_i-E\right)^2+\eta_{\ell}^2}\chi(E)\;\mathrm{d} E\right].\label{e2.1}
% \end{align}
% By applying the same argument as \eqref{eqn:sum-que-bound0.2}, we conclude \eqref{e2} is of $O(N^{\delta_0-C_1\delta_2-\delta_1})$. To bound \eqref{e2.1}, we break the sum into $i<l$ and $i>\ell$. For $i<\ell$, by \eqref{eqn:quebound}, we have
% \begin{equation}
% \begin{split}
%   \E \bigg[\frac{\eta_\ell}{\pi}& \sum_{i<l,|i-l| \leq N^{C_1\delta_2}}  \int_{I_{\ell}} \frac{\widehat{p_i}}{\left(\lambda_i-E\right)^2+\eta_{\ell}^2}\chi(E)\;\mathrm{d} E\bigg]\\
%   &\leq CN^{\delta_0+C_1\delta_2}\E \int_{\lambda_{\ell-1}^{+}}^{\infty} \frac{\eta_{\ell}}{\left(\lambda_{\ell-1}-E\right)^2+\eta_{\ell}^2}\;\mathrm{d} E 
%   %&\leq N^{\delta_0+C_1\delta_2}\eta_{\ell}(\eta_\ell N^{\delta_3})^{-1}\\
%   \leq CN^{\delta_0+C_1\delta_2-\delta_3}.\label{e3}
% \end{split}
% \end{equation}
% For $i>\ell$ we partition the interval $I_\ell$ into $I_\ell = I_1 \cup I_2$. We define $I_1$ as 
% \begin{equation*}
%     I_1 := \{E\in I,\; \exists i, \; \ell<i\leq \ell+N^{C_1\delta_2},\;|E-\lambda_\ell|\leq  \eta_\ell N^{\delta_3}\}.
% \end{equation*}
% Set $I_2 = I \setminus I_1.$ We have  on $I_2$
% \begin{equation}
% \begin{split}
% \E \left[\frac{\eta_\ell}{\pi} \sum_{i>\ell,|i-l| \leq N^{C_1\delta_2}}  \int_{I_2} \frac{\widehat{p_i}}{\left(\lambda_i-E\right)^2+\eta_{\ell}^2}\chi(E)\;\mathrm{d} E\right]
% \leq N^{\delta_0+ C_1\delta_2-\delta_3},
% \end{split}
% \end{equation}
% where we apply \eqref{eqn:quebound}. On $I_1$, we find
% \begin{equation}
% \begin{split}
% \quad\E \bigg[\frac{\eta_\ell}{\pi}  &\sum_{i>\ell,|i-l| \leq N^{C_1\delta_2}} \int_{I_1} \frac{\widehat{p_i}}{\left(\lambda_i-E\right)^2+\eta_{\ell}^2}\chi(E)\;\mathrm{d} E\bigg]\leq \eta_{\ell}^2 N^{\delta_0+C_1\delta_2+\delta_3}\;\E \left[\max_{i\in I_1}\frac{1}{(E-\lambda_i)^2+\eta_\ell^2}\chi_{E}\right]\\
% &\leq N^{\delta_0+C_1\delta_2+3\delta_3}\;\E \left[\frac{\eta_{\ell}^2}{(\lambda_{\ell-1}-\lambda_\ell)^2+\eta_\ell^2}\right]\\
% &\leq N^{\delta_0+C_1\delta_2+3\delta_3} \; \left[\frac{\eta_\ell^2}{\Delta_\ell^2N^{-2\epsilon}}+\P(|\lambda_{\ell-1}-\lambda_\ell|\leq \Delta_\ell N^{-\epsilon})\right]\leq N^{C_1\delta_2+3\delta_3-a}.\label{e3.1}
% \end{split}
% \end{equation}
% The first inequality follows from \eqref{eqn:quebound}, and the second and third inequality are from the definition of $I_1$ and $\chi(E)$. The last inequality follows from level repulsion \eqref{eqn:level-repulsion} and  $\delta_1 > \delta_0+\epsilon$.
% Combining \eqref{e3}, \eqref{e3.1} and the bound for \eqref{e2}, we have shown the right hand side of \eqref{e1} is of 
% \begin{align*}
%     &\quad O(N^{C_0C_1\delta_2}(N^{\delta_0-C_1\delta_2-\delta_1}+N^{\delta_0+C_1\delta_2-\delta_3}+N^{C_1\delta_2+3\delta_3-a}))+O(N^{(C_0+1)\delta_0-\delta_3}) \\
%     &= O(N^{C_0C_1\delta_2}N^{-(C_0C_1+1)\delta_2}+O(N^{(C_0+1)\delta_0-\delta_3}) = O(N^{-\delta_2}),
% \end{align*}
%  where $0<(C_0+1)\delta_0<\delta_3<\min{(a/3, \delta_1-\epsilon)}$, and $\delta_2\in(0,\delta_3)$. The first equality holds by further setting $(C_0C_1+1)\delta_2 < \min{(\delta_1-\delta_0, \delta_3-\delta_0, a-3\delta_2)}$. Then the second equality follows by setting $\delta_2<\delta_3-(C_0+1)\delta_0$. %Hence we have shown 
% %\begin{equation*}
%     %\E g\left[\widehat{p_k}\right]-\E g\left[\int_{I_{\ell}} x(E) \chi(E)\right]= O(N^{-\delta_2}).
%     %O( N^{(C_1+C)\delta_2-(C_1+C+c)\delta_2}) = O(N^{-c}). \label{e4}
% %\end{equation*}
Inserting \eqref{eqn:small-terms-all} into \eqref{e1}, we have
\begin{align*}
\begin{split}
    \left|\E\left[g(\hat p_\ell)\right]-\E\left[g\left(\int_{I_\ell}x(E)\chi(E)\d E\right)\right]\right|=O(N^{-\epsilon_1/4}).
\end{split}
\end{align*}
\end{proof}



\begin{lemma}\label{lem:reg-ob-2}
    Maintain the same assumptions as in Lemma \ref{lem:regularized-observable}.
    Using Definition \ref{def:regularized}, the following holds
\begin{equation}
    \E \left[g\left(\int_{I_\ell} x(E) \chi(E)\; \mathrm{d} E\right)\right] - \E \left[g\left(\int_{I_\ell} x(E) q\left(\Tr f_E(H)\right)\; \mathrm{d} E\right)\right]=O(N^{-\epsilon_1/2}), \label{e4}
\end{equation}
where $\chi(E):= \bm1\left(\lambda_\ell\leq E^+ \leq \lambda_{\ell+1}\right)$.
\end{lemma}
\begin{proof}
    Let $\theta:= \mathbf{1}_{[-3,E^+]}$ and $\mathcal B$ denote the event $\{\lambda_1\geq-3\}$. By the definition of $\chi(E)$, the first term becomes 
    \begin{align*}
    \begin{aligned}
        \bm 1(\mathcal B)\int_{I_\ell} x(E) \;\textbf{1}(\lambda_{\ell}\leq E^{+} \leq {\lambda_{\ell+1}}) \; \mathrm{d} E &=  \bm 1(\mathcal B)\int_{I_\ell} x(E)\; \textbf{1}({\cal N}(-\infty, E^+) = \ell) \;\mathrm{d} E\\
        &=\bm 1(\mathcal B)\int_{I_\ell} x(E) \; q(\Tr \theta(H)) \;\mathrm{d} E,
    \end{aligned}
    \end{align*}
where $\mathcal N(E_1,E_2)$ denotes the number of eigenvalues in $[E_1,E_2]$.

By the definition of $f_E=f_{-3,E^+,\Delta_\ell N^{-\delta_4}}$, we know 
\begin{equation}\label{e11}
    \bm 1(\mathcal B)|\Tr \theta(H) - \Tr f_E(H)| \leq {\cal N}(E^+, E^++\Delta_\ell N^{-\delta_4})=\sum_{i}\bm 1(|\lambda_i-E^+|\leq\Delta_\ell N^{-\delta_4}) .
\end{equation}
Hence we have
\begin{align}\label{eqn:smoothed-chi-1}
\begin{aligned}
&\bm 1(\mathcal B)\left|\int_{I_\ell} x(E)\chi(E)\;\mathrm{d}E-\int_{I_\ell} x(E)\; q(\Tr f_E(H))\; \mathrm{d} E\right| \\
=  &\bm 1(\mathcal B)\left|\int_{I_\ell} x(E)\; [q(\Tr \theta(H))-q(\Tr f_E(H))]\; \mathrm{d} E\right|\\
\leq& C\bm 1(\mathcal B)\int_{I_\ell}|x(E)|\;|\Tr \theta(H) - \Tr f_E(H)|\; \mathrm{d} E\\
\leq& C\sum_{i}\int_{I_\ell}|x(E)|\bm 1(|\lambda_i-E^+|\leq \Delta_\ell N^{-\delta_4})\d E\\
\prec &N^{-\delta_4/2}\Delta_\ell \sup_{E\in I_\ell}|x(E)|,
\end{aligned}
\end{align}
where we use the rigidity \eqref{eqn:rig} in the final step. By \eqref{eqn:que} and \eqref{eqn:small-remaining-terms} with $\epsilon=2\delta_2$, we have
\begin{align}\label{eqn:smoothed-chi-2}
\begin{split}
    \sup_{E\in I_\ell}|x(E)|\prec \Delta_{\ell}^{-1}N^{\delta_1+2\delta_2}.
\end{split}
\end{align}
Combining \eqref{eqn:smoothed-chi-1} and \eqref{eqn:smoothed-chi-2}, we obtain the desired bound on $\mathcal B$. On $\mathcal B^c$, we simply use the rigidity \eqref{eqn:rig} and \eqref{eqn:smoothed-chi-2}. The proof is complete.
% The first inequality follows from the mean value theorem, and $C$ depends on $|q'|$. The second inequality follows from the rigidity of eigenvalues \eqref{eqn:rig}  by choosing $C_1$ large enough. The last inequality follows by setting $\delta_4>(2C_1C_0+1)\delta_2+\delta_0+\delta_1$.
% Applying the mean value theorem, assumptions on $g$ and \eqref{eqn:sum-que-bound}, we conclude the lemma.
\end{proof}


\begin{lemma}\label{lem:reg-ob-3}
 Maintain the same assumptions as in Lemma \ref{lem:regularized-observable}. Using Definition \ref{def:regularized}, the following holds
    \begin{equation*}
        \E \left[g\left(\int_{I_\ell} x(E) q(\Tr f_E(H))\right)\right]-\E \left[g\left(\int_{I_\ell} x(E) q(y_E) \right)\right]=O(N^{-\epsilon_1/2}).
    \end{equation*}
\end{lemma}
\begin{proof}
    We first express $f_E(H)$ in terms of Green functions using Helffer-Sj\"{o}strand functional calculus (see Equation (B.12) of \cite{uni-sine-kernel}):
    \begin{equation*}
    f_E (\lambda) \;=\; \frac1{2\pi}\int_{\R^2}\frac{\mathrm{i} \sigma  f_E ''(e)\tilde f(\sigma)+ \mathrm{i}  f_E (e) \tilde f'(\sigma)-\sigma 
    f_E '(e)\tilde f'(\sigma)}{\lambda-e-\mathrm{i} \sigma} \; \mathrm{d} e \mathrm{~d} \sigma.
\end{equation*}

Let $G(z) = (H-z)^{-1}$ and recall $\tilde \eta_\ell=\Delta_\ell N^{-\delta_5}$, then we have:
 \begin{align*}
 \begin{aligned}
    \Tr f_E (H) &= \frac{1}{2\pi}\int_{\R^2} \left(\mathrm{i} \sigma  f_E ''(e)\tilde f(\sigma)+ \mathrm{i}  f_E (e) \tilde f'(\sigma)-\sigma f_E '(e)\tilde f'(\sigma) \right) \Tr G(e+\mathrm{i} \sigma) \; \mathrm{d} e \mathrm{~d} \sigma\\
    &= \frac{1}{2\pi}\int_{\R^2} \left(\mathrm{i}  f_E (e) \tilde f'(\sigma)-\sigma f_E '(e)\tilde f'(\sigma) \right) \Tr G(e+\mathrm{i} \sigma)\; \mathrm{d} e \mathrm{~d} \sigma\\
    &+\frac{\mathrm{1}}{2}\int_{|\sigma|>\tilde{\eta}_\ell}\int \mathrm{i} \sigma  f_E ''(e)\tilde f(\sigma) \Tr G(e+\mathrm{i} \sigma) \;\mathrm{d} e \mathrm{~d} \sigma\\
    &+\frac{1}{2\pi}\int_{|\sigma|<\tilde{\eta}_\ell}\int \mathrm{i} \sigma  f_E ''(e)\tilde f(\sigma) \Tr G(e+\mathrm{i} \sigma)\; \mathrm{d} e \mathrm{~d} \sigma.
 \end{aligned}
 \end{align*}
We show that the last term is negligible. From {\cite[Lemma 5.1]{KnoYin13}}, we know $\sigma \Tr G(e+\mathrm{i} \sigma) = O_\prec(1)$. Since $\int |f_E ''(e) | = O(\Delta_\ell^{-1}N^{\delta_4})$, the last term is bounded by:
\begin{equation*}
    \left|\frac{1}{2\pi}\int_{|\sigma|<\tilde{\eta}_\ell}\int \mathrm{i} \sigma  f_E ''(e)\tilde f(\sigma) \Tr G(e+\mathrm{i} \sigma)\; \mathrm{d} e \mathrm{~d} \sigma\right| = O_\prec(N^{\delta_4-\delta_5}).
\end{equation*}

Hence by the mean value theorem on $q$ and definition of $y_E$ (see \eqref{eqn:regularized-y}), we know $q(\Tr f_E(H))- q(y_E)=O_\prec(N^{\delta_4-\delta_5})$. Now by mean value theorem on $g$ and \eqref{eqn:bound-x-integral}, we have
\begin{align*}
\begin{split}
    \mathbb{E}\left[g\left(\int_{I_{\ell}} x(E) q\left(\operatorname{Tr} f_E(H)\right)\right)\right]-\mathbb{E}\left[g\left(\int_{I_{\ell}} x(E) q\left(y_E\right)\right)\right]=O_{\prec}\left(N^{(C_0+1)\delta_2+\delta_4-\delta_5}\right),
\end{split}
\end{align*}
which, by the choice of parameters, completes the proof.
\end{proof}

































%\newpage
\section{Two moment comparison and proof of the main theorem}\label{s:conclusion}

We retain the conventions stated in Section~\ref{s:conventions} and the choice of parameters made in the statement of Lemma~\ref{lem:regularized-observable}.
 \subsection{Preliminary Lemmas}

 For $z\in \mathbb{C}\backslash\R$, we define the control parameter
\begin{gather}\label{controlparameter}
\Psi(z)=\sqrt{\frac{\operatorname{Im} m_{\mathrm{sc}}(z)}{N \operatorname{Im} z}}+\frac{1}{N |\operatorname{Im} z|}.
\end{gather}

Let $H$ be a $N \times N$ Wigner matrix.
Fix $a,b\in\llbracket1,N\rrbracket$, and define 
$$Q = Q(a,b) = \{q_{ij}\}_{1 \le i,j \le N}\in\matn$$
as follows. Set $q_{ij} = h_{ij}$ if $(i,j) \notin \{ (a,b), (b,a) \}$, and set $q_{ij} = 0$ otherwise. In other words, $Q$ is the matrix obtained by starting with $H$ and replacing entries $h_{ab}$ and $h_{ba}$ by zeros. Given $z \in \mathbb{C} \setminus \mathbb{R}$, set 
\begin{equation}\label{GR}
G = (H - z)^{-1}, \qquad R = (Q - z )^{-1}.
\end{equation}
Let $x^G,x^R,y^G,y^R$ be the quantities in \eqref{eqn:regularized-x} and \eqref{eqn:regularized-y} defined using the resolvents $G$ or $R$, as indicated by the superscript. Finally, let $U=H-Q$.

We summarize some preliminary bounds in the following lemma.
\begin{lemma}\label{lem:prelim-bound}Let $H=\{h_{ij}\}_{i,j=1}^N,G,R,\Psi$ be as defined above. We have
\begin{gather}
    |h_{ij}|\prec N^{-1/2},\label{eqn:entry-bound}\\
    \|G(z)\|\leq \frac{1}{\eta},\label{eqn:absolute-bound-G}\\
    \|R(z)\|\leq \frac{1}{\eta},\label{eqn:absolute-bound-R}\\
    C^{-1}\tau^{1/4}N^{-1/2}\leq\Psi(z)\leq C\tau^{-1/4}N^{-\tau/20},\quad\forall\,z\in\bm S,\label{eqn:psi-bound}
\end{gather}
for some constant $C>0$, where $\eta=|\Im z|$.
Moreover, when $z=E+\iu\eta_\ell,\,z\in I_\ell$ (see Definition \ref{def:regularized}), there exists constant $C>0$ such that
\begin{align}\label{eqn:psi-bound-specified}
\begin{split}
    \Psi(z)\leq \frac{C}{N\eta_\ell}.
\end{split}
\end{align}
\end{lemma}
\begin{proof}
    Fix any $\epsilon>0,D>0$. By Markov's inequality and the moment assumption \eqref{finite-moment} on $h_{ij}$, we have
    \begin{equation*}
        \P\left(|\sqrt{N}h_{ij}|>N^\epsilon \right)=\P\left(|\sqrt Nh_{ij}|^p>N^{p\epsilon}\right)\leq \mu_pN^{-p\epsilon}\leq N^{-D},
    \end{equation*}
    for large enough $p$ and $N>N_0(\epsilon,D)$. This proves \eqref{eqn:entry-bound}.

    By spectral decomposition, we have
    \begin{equation*}
        G(z)=\sum_i\frac{\bm u_i\bm u_i^\trans}{\lambda_i-z},
    \end{equation*}
    where $\{\lambda_i\}_{i=1}^N$ and $\{\bm u_i\}_{i=1}^N$ are the corresponding eigenvalues and eigenvectors of $H$. Observe that 
    \begin{equation*}
        \left|\frac{1}{\lambda_i-z}\right|\leq \frac{1}{\eta}.
    \end{equation*}
    Pick any unit vector $\bm x$. We have 
    \begin{equation*}
        |\bm x^* G\bm x|\leq \frac{1}{\eta}\bm x^*\sum_i\bm u_i\bm u_i^\trans \bm x=\frac{1}{\eta}.
    \end{equation*}
    This proves \eqref{eqn:absolute-bound-G}. The inequality \eqref{eqn:absolute-bound-R} follows similarly.

    To obtain the lower bound of $\Psi(z)$, we use the following result (see \cite[Lemma~3.3]{benaych2016lectures}):
    \begin{equation}\label{eqn:bound-im-m}
        \begin{aligned}
        &c\sqrt{\kappa+\eta}\leq|\operatorname{Im} \m(z)|\leq c^{-1}\sqrt{\kappa+\eta} ,&\text{ if }|E|\leq 2,\\
        &\frac{c\eta}{\sqrt{\kappa+\eta}}\leq|\Im \m(z)|\leq\frac{c^{-1}\eta}{\sqrt{\kappa+\eta}},&\text{ if }|E|\geq 2,
        \end{aligned}
    \end{equation}
    for some constant $c>0$, where $E=\Re z$ and $\kappa\equiv\kappa(E)\defeq ||E|-2|$. 

    For $|E|\leq 2$, we have 
    \begin{equation*}
    \begin{aligned}
        &\Psi(z)\geq \sqrt{\frac{c\sqrt{\kappa+\eta}}{N\eta}}+\frac{1}{N\eta}\geq CN^{-1/2}\eta^{-1/4}\geq C\tau^{1/4}N^{-1/2},\\
        &\Psi(z)\leq \sqrt{\frac{c^{-1}\sqrt{\kappa+\eta}}{N\eta}}+\frac{1}{N\eta}\leq C\sqrt{\frac{\tau^{-1/2}}{NN^{-1+\tau/10}}}+\frac{1}{NN^{-1+\tau/10}}\leq C\tau^{-1/4}N^{-\tau/20},
    \end{aligned} 
    \end{equation*}
    where we used $z\in\bm S$ in the last step of the first line and in the second inequality of the second line.

    For $|E|\geq 2$, we have
    \begin{equation*}
    \begin{aligned}
        &\Psi(z)\geq\sqrt{\frac{c}{\sqrt{\kappa+\eta}N}}+\frac{1}{N\eta}\geq\left\{ \begin{aligned}
            CN^{-1/2}\eta^{-1/4}&\text{ if }\kappa\leq \eta\\
            CN^{-1/2}\kappa^{-1/4}&\text{ if }\kappa\geq \eta
        \end{aligned}\right\}\geq C\tau^{1/4}N^{-1/2},\\
        &\Psi(z)\leq \sqrt{\frac{c^{-1}}{\sqrt{\kappa+\eta}N}}+\frac{1}{N\eta}\leq C\sqrt{\frac{1}{N^{-1/2+\tau/20}N}}+\frac{1}{NN^{-1+\tau/10}}\leq CN^{-1/2-\tau/20},
    \end{aligned}
    \end{equation*}
    where we used $z\in\bm S$ in the last step of the first line and in the second inequality of the second line. This completes the proof of \eqref{eqn:psi-bound}.

    Finally, for $z=E+\iu\eta_\ell,\, E\in I_\ell$. We have
    \begin{align*}
    \begin{split}
        \Psi(z)\leq C\sqrt{\frac{\sqrt{\kappa+\eta_\ell}}{N\eta}}+\frac{1}{N\eta_\ell}.
    \end{split}
    \end{align*}
    Note that $\kappa\leq C(\ell/N)^{2/3}+N^{\delta_2}\Delta_\ell$. It is not hard to check that $\kappa+\eta_\ell\leq C(N\eta_\ell)^{-2}$. This completes the proof of \eqref{eqn:psi-bound-specified}.
\end{proof}

% \red{(I think the first appearance of the following lemma should be in Section \ref{sec:regularized-observables})}
% \red{Yes, I have the lemma, i'll put the reference once I'm done}
% \begin{lemma}\label{lem:xr-integral}
% Let $H$ be a Wigner matrix. Fix $\ell\in\N$, such that
% \begin{align}
% \begin{split}
% \int_{I_\ell}|x^R|\, \d E\prec N^{\delta_2}.
% \end{split}
% \end{align}
% \end{lemma}
% \begin{proof}
% By definition, we have
% \begin{align}
% \begin{split}
% x^R(E)=\frac{\eta_\ell}{\pi}\sqrt{\frac{N^3}{|\I|\left(N-|I|\right)}}\sum_{i}\frac{p_i}{(\lambda_i-E)^2+\eta_\ell^2}.
% \end{split}
% \end{align}
% \red{complete this proof}
% \end{proof}

In the next lemma, we collect several local laws, which will be used frequently for the current section and Section \ref{sec:poly}.
\begin{lemma}\label{lem:three-resolvent-local-law}
Let $H$ be a Wigner matrix, and let $S$ be either $G$ or $R$, as defined in \eqref{GR}.
\begin{enumerate}
\item For all $z \in \bm S$, we have 
\begin{equation}
\big|\langle\bm x,S\bm y\rangle- \langle\bm x,\bm y\rangle \m\big|\prec\Psi,\quad 
|(SS)_{\bm x\bm y}|\prec N\Psi^2,\quad |(S\bar S)_{\x\y}|\prec N\Psi^2\label{eqn:2-resolvents}.
\end{equation}
uniformly over all $\bm x, \bm y \in \mathbb{S}^{N-1}$.
\item Further,
if $z=E+\iu\eta \in \bm S$ satisfies
\begin{align*}
\begin{split}
    E\in I_\ell,\quad \eta=\eta_\ell.
\end{split}
\end{align*}
Then for any deterministic $A \in \matn$ such that $\|A\|\leq 1$ and $\Tr A=0$, we have
\begin{gather}
|(SA\bar S)_{cd}|\prec N^{1/2}\Psi,\label{eqn:2-resolvents-traceless}\\
|(SA\bar SS)_{cd}|\prec N^{3/2}\Psi^{9/4},\label{eqn:3-resolvents-traceless}
\end{gather}
uniformly over all $c,d\in\llbracket1,N\rrbracket$.
\end{enumerate}
\end{lemma}
The proof of Lemma \ref{lem:three-resolvent-local-law} is postponed to Appendix \ref{sec:local-law}.

The resolvent expansion formulae
\begin{align}\label{eqn:resolvent-expansion-original}
\begin{split}
G&=R-R U R+R U R U R-R U R U R U R+(R U)^4 G,\\
R&=G-GUG+GUGUG-GUGUGUG+(GU)^4R,
\end{split}
\end{align}
follow immediately from the definitions of $G$, $R$, and $U$. 
They imply
%From \eqref{eqn:resolvent-expansion-original}, we have
\begin{align}\label{eqn:resolvent-expansion}
\begin{split}
\begin{aligned}
G \bar{G}-R \bar{R}= & -R \overline{R U R}-R U R \bar{R} \\
& +R \overline{R U R U R}+R U R \overline{R U R}+R U R U R \bar{R} \\
& -R \overline{R U R U R U R}-R U R \overline{R U R U R}-R U R U R \overline{R U R}-R U R U R U R \bar{R} \\
& +R \overline{(R U)^4 G}+R U R \overline{(R U)^3 R}+(R U)^2 R \overline{(R U)^2 R}+(R U)^3 R \overline{R U R}+(R U)^4 G \bar{R}.
\end{aligned}
\end{split}
\end{align}
These identities facilitate resolvent expansions for the terms $x^G$  and $y^G$, which are stated in the following lemma. We recall that $\ell$ was fixed earlier in Section~\ref{s:conventions}, and that $I_\ell$ was defined in \eqref{regularizednotation}.
\begin{lemma}\label{lem:resolvent-expansion}
Let $H$ be a $N\times N$ Wigner matrix.
\begin{enumerate}
\item We have %the following resolvent expansion for $x^G-x^R$:
\begin{equation*}
x^G-x^R=\sum_{r=1}^3 x_r h_{a b}^r+x_{\mathrm{err}},
\end{equation*}
where
\begin{equation*}
 \left|x_i(E)\right| \prec N^{1+\delta/2}\Psi^{5/4}, \quad i=1,2,3, \quad
 \left|x_{\mathrm{err}}(E)\right| \prec N^{-1+\delta/2}\Psi^{5/4},
\end{equation*}
uniformly over $E\in I_\ell$. Moreover 
\begin{align*}
\begin{split}
    |x^R(E)|\prec N^{1+\delta/2}\Psi^{1/2},
\end{split}
\end{align*}
uniformly over $E\in I_\ell$.
\item We have
\begin{equation*}
\operatorname{Tr} G-\operatorname{Tr} R=\sum_{r=1}^3 J_r h_{a b}^r+J_{\text {err }}
\end{equation*}
where
\begin{equation*}
%\begin{aligned}
|J_i(z)|\prec N \Psi^2, \quad i=1,2,3, \quad
 |J_{\mathrm{err}}(z)|\prec N^{-2} \Psi^2 ,
%\end{aligned}
\end{equation*}
uniformly for  $z \in \bm S$.
\item We have
\begin{equation*}
y^G-y^R=\sum_{r=1}^3 y_r h_{a b}^r+y_{\mathrm{err}}
\end{equation*}
where
\begin{equation*}
%\begin{aligned}
 \left|y_i(E)\right| \prec \Psi, \quad i=1,2,3, \quad
 \left|y_{\mathrm{err}}(E)\right|\prec N^{-2}\Psi,
%\end{aligned}
\end{equation*}
uniformly over $E\in I_\ell$.
\end{enumerate}
\end{lemma}
\begin{proof}
We first present the proofs for the claims about $x_1$ and $x^R$. The others are similar. 

By \eqref{eqn:regularized-x} and \eqref{eqn:resolvent-expansion}, we have
\begin{align*}
\begin{split}
    x_1=\frac{\eta_\ell}{\pi}\sqrt{\frac{N^3}{2|\I|(N-|\I|)}}\frac{1}{1+\delta_{ab}}[(RA\bar RR)_{ab}+(RA\bar RR)_{ba}]+[C],
\end{split}
\end{align*}
where $[C]$ denotes the complex conjugate of the previous terms, and 
\begin{align}\label{eqn:traceless-A}
\begin{split}
A=\sum_{\alpha\in\I}\left(1-\frac{|\I|}{N}\right)\q_\alpha\q_\alpha^\trans -\sum_{\alpha\notin\I}\frac{|\I|}{N}\q_\alpha\q_\alpha^\trans.
\end{split}
\end{align}
Note that $\|A\|=\max\left\{1-|\I|/N,|\I|/N\right\}\leq 1$ and $\Tr A=0$. 
By Lemma \ref{lem:three-resolvent-local-law}, we have that
    $|x_1|\prec N^{1+\delta/2}\Psi^{5/4},$
where we used $|\I|\geq N^{1-\delta}$. For $x^R$ we have, 
% For $x_2$, again by \eqref{eqn:regularized-x} and \eqref{eqn:resolvent-expansion}, we have
% \begin{align}
% \begin{split}
%     x_2=\frac{\eta_\ell}{\pi}\sqrt{\frac{N^3}{2|\I|(N-|\I|)}}\left[\bar R_{bb}(\bar RAR\bar R)_{aa}+(R\bar R)_{bb}(\bar RAR)_{aa}\right]+[C].
% \end{split}
% \end{align}
% By \eqref{eqn:center-iso}, \eqref{eqn:iso} and Lemma \ref{lem:three-resolvent-local-law}, we have
% \begin{align}
% \begin{split}
%     |x_2|\prec N\Psi^{5/4}.
% \end{split}
% \end{align}

% Similarly for $x_3$, by \eqref{eqn:regularized-x} and \eqref{eqn:resolvent-expansion}, we have
% \begin{align}
% \begin{split}
%     x_3=\frac{\eta_\ell}{\pi}\sqrt{\frac{N^3}{2|\I|(N-|\I|)}}\left[\bar R_{aa}\bar R_{bb}(\bar RAR\bar R)_{ba}+\bar R_{aa}(R\bar R)_{bb}(RA\bar R)_{ab}\right]+[C].
% \end{split}
% \end{align}
% By \eqref{eqn:center-iso}, \eqref{eqn:iso} and Lemma \ref{lem:three-resolvent-local-law}, we have
% \begin{align}
% \begin{split}
%     |x_3|\prec N\Psi^{5/4}.
% \end{split}
% \end{align}
% For $x_\err$, we have
% \begin{align}
% \begin{split}
%     x_\err=\frac{\eta_\ell}{\pi}\sqrt{\frac{N^3}{2|\I|(N-|\I|)}}\left[\bar R_{aa}\bar R_{bb}^2(\bar SAR\bar R)_{aa}+\bar R_{aa}\bar R_{bb}(RA\bar R)_{aa}(R\bar R)_{bb}\right]h_{ab}^{4}+[C].
% \end{split}
% \end{align}
% By \eqref{eqn:center-iso}, \eqref{eqn:iso} and Lemma \ref{lem:three-resolvent-local-law}, we have
% \begin{align}
% \begin{split}
%     |x_\err|\prec N^{-1}\Psi^{5/4}.
% \end{split}
% \end{align}
\begin{equation*}
    x^R=\frac{\eta_\ell}{\pi}\sqrt{\frac{N^3}{2|\I|(N-|\I|)}}\Tr(RA\bar R).
\end{equation*}
By definition, we have $M(z,A,\bar z)=|\m(z)|^2A$ which is traceless and from \eqref{eqn:avg}, we have
%\begin{align}
%\begin{split}
    $|x^R|\prec N^{1+\delta/2}\Psi^{1/2}.$
%\end{split}
%\end{align}

By resolvent expansion, we have
\begin{align*}
\begin{split}
    \operatorname{Tr} S-\operatorname{Tr} R&=-\operatorname{Tr} R V R+\operatorname{Tr} R V R V R-\operatorname{Tr} R V R V R V R+\operatorname{Tr}(R V)^4 G=:\sum_{i=1}^3 J_i+J_\err.
\end{split}
\end{align*}
% Therefore,
% neglecting lower order terms, we have
% \begin{equation*}
% \begin{aligned}
% & J_1=-2\left(R^2\right)_{a b}, \quad J_2\approx\left(R^2\right)_{a a} R_{b b}+\left(R^2\right)_{b b} R_{a a}, \quad J_3\approx-2\left(R^2\right)_{a b} R_{a a} R_{b b}, \\
% & J_{\mathrm{err}}\approx\left[(G R)_{a a}\left(R_{b b}\right)^2 R_{a a}+(G R)_{b b}\left(R_{a a}\right)^2 R_{b b}\right] h_{a b}^4
% \end{aligned}
% \end{equation*}
Using the high probability bound \eqref{eqn:2-resolvents} we have
\begin{equation*}
\begin{aligned}
 |J_i|\prec N \Psi^2, \quad i=1,2,3, \quad{\text{and}}\quad
 |J_{\mathrm{err}}|\prec N^{-1}\Psi^2 .
\end{aligned}
\end{equation*}
\item 
Using the bound on $J_i$ from the second part, and notice that
\begin{align}
\begin{aligned}
y_i= & \frac{1}{2 \pi} \int_{\mathbb{R}^2} \mathrm{i} \sigma f_E^{\prime \prime}(e) \widetilde{f}(\sigma) J_i(e+\iu\sigma) \mathbf{1}\left(|\sigma|>\widetilde{\eta}_{\ell}\right) \mathrm{d} e \mathrm{~d} \sigma \\
& +\frac{1}{2 \pi} \int_{\mathbb{R}^2}\left(\mathrm{i} f_E(e) \widetilde{f}^{\prime}(\sigma)-\sigma f_E^{\prime}(e) \widetilde{f}^{\prime}(\sigma)\right) J_i(e+\iu\sigma) \mathrm{d} e \mathrm{~d} \sigma,\\
y_\err=& \frac{1}{2 \pi} \int_{\mathbb{R}^2} \mathrm{i} \sigma f_E^{\prime \prime}(e) \widetilde{f}(\sigma) J_\err(e+\iu\sigma) \mathbf{1}\left(|\sigma|>\widetilde{\eta}_{\ell}\right) \mathrm{d} e \mathrm{~d} \sigma \\
& +\frac{1}{2 \pi} \int_{\mathbb{R}^2}\left(\mathrm{i} f_E(e) \widetilde{f}^{\prime}(\sigma)-\sigma f_E^{\prime}(e) \widetilde{f}^{\prime}(\sigma)\right) J_\err(e+\iu\sigma) \mathrm{d} e \mathrm{~d} \sigma,
\end{aligned}
\end{align}
the proof of the bound on $y_i$ and $y_{\err}$ follows from the proof of \cite[Lemma~7.7]{BloKnoYauYin16}.
\end{proof}



Using Lemma \ref{lem:resolvent-expansion}, and Taylor expansion of $q(y^G)$ around $y^R$ up to order 3, we have
\begin{align}\label{resolvent-expansion-integral}
\begin{split}
    &\int_{I_\ell}x^Gq(y^G)\d E-\int_{I_\ell} x^Rq(y^R)\d E\\
    =&\int_{I_\ell}\left(x^R+\sum_{r=1}^3 x_r h_{a b}^r+x_{\mathrm{err}}\right)\cdot
    \left(q(y^R)+\sum_{k=1}^3\frac{q^{(k)}(y^R)}{k!}\left(\sum_{r=1}^3y_rh_{ab}^r+y_\err\right)^k\hspace{-.5em}+O_\prec(N^{-2}\Psi)\right)\d E\\
    &-\int_{I_\ell}x^Rq(y^R)\d E\\
    =&\sum_{\bm{l} \in \mathcal{L}} P_{\bm l} h_{a b}^{|\bm l|}+O_\prec(N^{-2-c}),
\end{split}
\end{align}
where we define
\begin{equation}
\begin{gathered}
 \mathcal{L}:=\left\{\bm{l}=\left(l_0, \ldots, l_k\right) \in \llbracket 0,3 \rrbracket \times \llbracket 1,3 \rrbracket^k: k \in \mathbb{N}, 1 \leqslant|\bm{l}| \leqslant 3\right\},
\quad|\bm{l}|:=\sum_{i=0}^k l_i, \\
 P_{\bm{l}}:=\int_{I_\ell} \frac{q^{(k)}\left(y^R\right)}{k !} x_{l_0} y_{l_1} \cdots y_{l_k} \mathrm{~d} E,
\end{gathered}
\end{equation}
and $c>0$ depends only on $\tau$. Here we denote $x_0\defeq x^R$.

Using \eqref{resolvent-expansion-integral}, for $g$ satisfying \eqref{eqn:poly-growth}, we have
\begin{multline}\label{eqn:resolvent-expansion-integral-poly}
 \mathbb{E} \left[g\left(\int_{I_\ell} x^G q\left(y^G\right) \mathrm{d} E\right)\right]-\mathbb{E} \left[g\left(\int_{I_\ell} x^R q\left(y^R\right) \mathrm{d} E\right)\right]
 =\mathbb{E} \left[\mathcal{A}\right]+O_{\prec}\left(N^{-2-c}\right) \\
 \quad+\mathbb{E} \left[h_{a b}^3\right] \mathbb{E} \left[\sum_{k=1}^3 \frac{1}{k !} g^{(k)}\left(P_{\bm{0}}\right) \sum_{\bm{l}_1, \ldots, \bm l_k \in \mathcal{L}} \bm{1}\left(\sum_{i=1}^k\left|\bm{l}_i\right|=3\right) \prod_{i=1}^k P_{\bm{l}_i}\right],
\end{multline}
where $P_{\bm 0}\defeq \int_{I_\ell}x^Rq(y^R)~\d E$, and $\E[\mathcal A]$ depends only on $R$ and the first two moments of $h_{ab}$.

We need the following lemma:
\begin{lemma}\label{lem:third-moment-terms}
Fix indices $a,b$ such that $a\neq b$. Let $Y$ denote any of the following terms:
\begin{equation}\label{eqn:third-moment-terms}
\begin{aligned}
& g^{(3)}\left(P_{\bm{0}}\right) P_{(1)}^m P_{(0,1)}^n \quad(m+n=3), \\
& g^{(2)}\left(P_{\bm{0}}\right)\left(P_{(2)}+P_{(0,2)}+P_{(1,1)}+P_{(0,1,1)}\right)\left(P_{(1)}+P_{(0,1)}\right), \\
& g^{(1)}\left(P_{\bm{0}}\right)\left(P_{(3)}+P_{(0,3)}+P_{(1,2)}+P_{(2,1)}+P_{(0,1,2)}+P_{(1,1,1)}+P_{(0,1,1,1)}\right).
\end{aligned}
\end{equation}
Then there is a constant $c>0$ such that
\begin{align}
\begin{split}
\big|\mathbb{E}[Y ]\big|\prec N^{-1/2-c}.
\end{split}
\end{align}
\end{lemma}
The lemma is proved in Section \ref{sec:poly}.

\subsection{Resolvent Comparison}
Given this lemma, we can conclude by standard Green's comparison argument.
\begin{proof}[Proof of Theorem \ref{thm:CLT}]
Let $W$ be drawn from the Gaussian Orthogonal Ensemble, and let $H$ be a Wigner matrix. By Theorem \ref{thm:GOE-CLT} and Lemma \ref{lem:regularized-observable}, it suffices to show
\begin{align}\label{eqn:comparison}
\begin{split}
\left|\mathbb{E}\left[g(v_{\ell}^W)-g(v_{\ell}^H) \right]\right|\leq c^{-1}N^{-c}
\end{split}
\end{align}
for some constant $c>0$, where $v_{\ell}^W$ and $v_{\ell}^H$ are corresponding regularized observables (see \eqref{eqn:regularized-observable}) for $W$ and $H$ respectively.

To this end, we fix a bijection
\begin{equation*}
\psi:\{(i, j): 1 \leqslant i \leqslant j \leqslant N\} \rightarrow \llbracket 1, \xi_N \rrbracket,
\end{equation*}
where $\xi_N=N(N+1)/2$,
and define the interpolating matrices $H^0,H^1,H^2,\ldots,H^{\xi_N}$ by
\begin{equation*}
h_{i j}^\xi= \begin{cases}h_{i j} & \text { if } \psi(i, j) >\xi, \\ w_{i j} & \text { if } \psi(i, j)\leq\xi,\end{cases}
\end{equation*}
for $i\leq j$. Therefore, $H^0=H$ and $H^{\xi_N}=W$. We may rewrite \eqref{eqn:comparison} as a telescopic summation,
\begin{align}\label{eqn:comparison-telescopic}
\begin{split}
\left|\mathbb{E}\left[g(v_{\ell}^W)-g(v_{\ell}^H) \right]\right|\leq \sum_{\xi=1}^{\xi_N}\left|\mathbb{E}\left[g\left(v_\ell^{H^{\xi}}\right)-g\left(v_\ell^{H^{\xi-1}}\right) \right]\right|
\end{split}
\end{align}

Fix some $\xi\in\llbracket 1,\xi_N\rrbracket$ and consider the indices $(a,b)$ such that $\psi(a,b)=\xi$. Let $Q^{\xi}$ be the matrix obtained from $H^{\xi}$ by setting $h^\xi_{ab}$ and $h^{\xi}_{ba}$ to zero. Note that $Q^{\xi}$ can also be obtained from $H^{\xi-1}$ by setting $h^{\xi-1}_{ab}$ and $h^{\xi-1}_{ba}$ to zero. We consider the following two cases.
\item First, suppose $a=b$. Lemma \ref{lem:bound-x-integral} and Lemma \ref{lem:resolvent-expansion} imply that, with $Y$ denoting any term from \eqref{eqn:third-moment-terms},
%\begin{align}
%\begin{split}
    $|Y|\prec N^{-\tau/30}$,
%\end{split}
%\end{align}
where we use the upper bound of $\Psi(z)$ (see \eqref{eqn:psi-bound-specified}).
Combining \eqref{eqn:resolvent-expansion-integral-poly}, we have
\begin{align*}
\begin{split}
\left|\mathbb{E}\left[g(v_{\ell}^{H^{\xi}})-g(v_{\ell}^{H^{\xi-1}}) \right]\right|\leq\left|\mathbb{E}\left[g(v_{\ell}^{H^{\xi}})-g(v_\ell^{Q^\xi}) \right]+\left[g(v_\ell^{Q^\xi})-g(v_{\ell}^{H^{\xi-1}}) \right]\right|\leq N^{-3/2-c},
\end{split}
\end{align*}
where we use the fact that the first two moments of Wigner matrices $H^{\xi}$ and $H^{\xi-1}$ are the same, and therefore $\E[\mathcal A]$ in \eqref{eqn:resolvent-expansion-integral-poly} is the same for both cases.

Now, if $a\neq b$. Combining Lemma \ref{lem:third-moment-terms} and \eqref{eqn:resolvent-expansion-integral-poly}, we have
\begin{align*}
\begin{split}
\left|\mathbb{E}\left[g(v_{\ell}^{H^{\xi}})-g(v_{\ell}^{H^{\xi-1}}) \right]\right|\leq\left|\mathbb{E}\left[g(v_{\ell}^{H^{\xi}})-g(v_\ell^{Q^\xi}) \right]+\left[g(v_\ell^{Q^\xi})-g(v_{\ell}^{H^{\xi-1}}) \right]\right|\leq N^{-2-c}
\end{split}
\end{align*}
for some $c>0$.
These two estimates conclude the proof in view of \eqref{eqn:comparison-telescopic}.
\end{proof}

































%\newpage
\section{Proof of Lemma \ref{lem:third-moment-terms}}\label{sec:poly}
We now fix indices $a,b\in\llbracket1,N\rrbracket$ such that $a\neq b$, and carry this choice throughout the current section. All of the bounds stated below are uniform in the choice of $a$ and $b$.

Recall from \eqref{e:semicircle} that $\m$ denotes the Stieltjes transform of the semicircle law, which is deterministic and satisfies
\begin{equation}\label{definingequation}
\m(z)+z+\frac{1}{\m(z)}=0.
\end{equation}
Recall from the discussion below \eqref{controlparameter} that $Q$ is the matrix obtained by setting $h_{a b}, h_{b a}$ in $H$ to 0, and $R$ is the resolvent of $Q$. Let $Q^{(a)}$ be the matrix obtained by setting $a$-th row and column of $H$ to $0$ and let $R^{(a)}$ be the resolvent of $Q^{(a)}$. Then it follows from the Schur complement formula that
\begin{equation}\label{eqn:ra-def}
        \left(R^{(a)}\right)_{ij}=\begin{cases}
            0,&\text{ if exactly one of }i,j\text{ is }0,\\
            -z^{-1},&\text{ if }i=j=0,\\
            R_{ij},&\text{ otherwise}.
        \end{cases}
    \end{equation}
% Let $Q^{(a)}$ be the matrix obtained by setting $a$-th row and column of $H$ to $0$ and let $\tilde R^{(a)}$ be the resolvent of $Q^{(a)}$. By Schur's complement formula, it follows that $\tilde R^{(a)}_{ij}$ 
% \red{In the following, I want to redefine $\ra$ to be equal to the $\ra$ above everywhere except at the entry $(a,a)$, where this new $\ra$ is $R_{aa}$ instead of $(-z)^{-1}$. This is for notational brevity. }
We state the following local laws for $R^{(a)}$, whose proof follows directly from the corresponding local laws in Lemma \ref{lem:three-resolvent-local-law} and \eqref{eqn:ra-def}, and is therefore omitted.
\begin{lemma}\label{lem:three-resolvent-local-law-ra}
    Let $H$ be a Wigner matrix.
    \begin{enumerate}
        \item For all $z\in\bm S$, we have
        \begin{equation}
            \left|\ra_{\x\y}-\langle\boldsymbol{x}, \boldsymbol{y}\rangle m_{\mathrm{sc}}\right| \prec \Psi, \quad\left|(\ra\ra)_{cd}\right| \prec N \Psi^2, \quad\left|(\ra\rab)_{cd}\right| \prec N \Psi^2 ,\label{eqn:2-resolvents-ra}
        \end{equation}
        uniformly over $\x,\y\in\mathbb S^{N-1}$ such that at least one of $\x,\y$ is $\e_s$ with some $s\neq a$, and $c,d\in\llbracket1,N\rrbracket$ such that $c,d\neq a$.
        \item Furthermore, if $z=E+\iu\eta\in\bm S$ satisfies
        \begin{equation*}
            E \in I_{\ell}, \quad \eta=\eta_{\ell} ,
        \end{equation*}
        then for any deterministic $A\in\operatorname{Mat}_N$ such that $\|A\|\leq 1$ and $\Tr A=0$, we have
        \begin{gather}
            \left|(\ra A \rab)_{c d}\right|  \prec N^{1 / 2} \Psi,\label{eqn:2-resolvents-traceless-ra} \\
            \left|(\ra A \rab \ra)_{c d}\right|  \prec N^{3/2} \Psi^{9 / 4},\label{eqn:3-resolvents-traceless-ra}
        \end{gather}
        uniformly over all $c,d\in\llbracket1,N\rrbracket$ such that $c,d\neq a$.
    \end{enumerate}
\end{lemma}
Finally, for conciseness, we let $A$ stand for the matrix defined in \eqref{eqn:traceless-A}, which satisfies
\begin{align*}
\begin{split}
\|A\|\leq 1,\qquad \Tr(A)=0.
\end{split}
\end{align*}
The main goal of this section is to rewrite the resolvent expansion terms $x_i$ and $ y_i$ from Lemma~\ref{lem:resolvent-expansion} into the polynomial form as introduced in \cite[Section~7]{BloKnoYauYin16}. For instance, we want to rewrite
\begin{equation*}
x_1 \approx\left(\sum_{i_1, \ldots, i_d\neq a} V_{i_1, \ldots, i_d} h_{i_1 a} \cdots h_{i_d a}\right) \cdot\left(\prod_{j=d+1}^{d+m} \sum_{i_j=1}^N V_{i_j}\left(h_{i_j a}^2-\frac{1}{N}\right)\right),
\end{equation*}
where the $V$ terms are $Q^{(a)}$-measurable. The reason to write it into this form is that, whenever $d$ is odd, we gain a factor of $N^{-1 / 2}$ upon taking the expectation (see Lemma \ref{lem:odd-poly} for the precise statement), which is essential in the proof of Lemma \ref{lem:third-moment-terms}.

Fixing a universal constant $C_0>0$ and following the set up in \cite{BloKnoYauYin16}, we make the following definitions.
\begin{definition}[Admissible weights]
Let $\varrho=\left(\varrho_i: i \in \llbracket 1, N \rrbracket\right)$ be a sequence of deterministic nonnegative real numbers. We say that $\varrho$ is an \emph{admissible weight} if
\begin{equation*}
\frac{1}{N^{1 / 2}}\left(\sum_i \varrho_i^2\right)^{1 / 2} \leqslant 1, \quad \frac{1}{N^{1 / 2}}\left(\sum_i \varrho_i^3\right)^{1 / 3} \leqslant N^{-1 / 6} .
\end{equation*}
\end{definition}

\begin{definition}[$O_{\prec,d}(\cdot)$]\label{def:od}
For a given degree $d \in \mathbb{N}$ let
\begin{equation*}
\mathcal{P}=\sum_{\substack{1\le i_1, \ldots, i_d \le N \\ i_1, \ldots, i_d \neq a}} V_{i_1 \cdots i_d} h_{a i_1} \cdots h_{a i_d}
\end{equation*}
be a polynomial in entries of the a-th row of $Q$. We write $\mathcal{P}=O_{\prec, d}(K)$ if the following conditions are satisfied.
\begin{enumerate}
\item $K$ is deterministic and $V_{i_1 \cdots i_d}$ is $Q^{(a)}$-measurable.
\item There exist admissible weights $\varrho^{(1)}, \ldots, \varrho^{(d)}$ such that
\begin{equation*}
\left|V_{i_1 \cdots i_d}\right| \prec K \varrho_{i_1}^{(1)} \cdots \varrho_{i_d}^{(d)} .
\end{equation*}
\item We have the deterministic bound $\left|V_{i_1 \cdots i_d}\right| \leqslant N^{C_0}$.
\end{enumerate}
The above definition also extends to $d=0$, where $\mathcal P=V$ is $Q^{(a)}$-measurable.
\end{definition}

\begin{definition}[$O_{\prec,\diamond}(\cdot)$]\label{def:odiamond}
Let $\mathcal{P}$ be a polynomial of the form
\begin{equation*}
\mathcal{P}=\sum_{i=1}^N V_i\left(h_{a i}^2-\frac{1}{N}\right).
\end{equation*}
We write $\mathcal{P}=O_{\prec, \diamond}(K)$ if $V_i$ is $Q^{(a)}$-measurable, $\left|V_i\right| \leqslant N^{C_0}$, and $\left|V_i\right| \prec K$ for some deterministic $K$.
\end{definition}

\begin{definition}[Graded polynomials]\label{def:graded-poly} We write $\mathcal{P}=O_{\prec, \even}(K)$ if $\mathcal{P}$ is a sum of at most $C_0$ terms of the form
\begin{equation*}
K \mathcal{P}_0 \prod_{s=1}^n \mathcal{P}_i, \quad \mathcal{P}_0=O_{\prec, 2 d}(1), \quad \mathcal{P}_i=O_{\prec, \diamond}(1)
\end{equation*}
where $d, n \leqslant C_0$ and $K$ is deterministic. Moreover, we write $\mathcal{P}=O_{\prec, \odd}(K)$ if $\mathcal{P}=\widehat{\mathcal{P}} \mathcal{P}_{\even}$, where $\widehat{\mathcal{P}}=O_{\prec, 1}(1)$ and $\mathcal{P}_\even=O_{\prec, \even}(K)$.
\end{definition}
\begin{remark}
    The graded polynomials satisfy simple algebraic rules by definition, which we state without proof:
    \begin{gather*}
        \Oparity{*}{K_1}+\Oparity{*}{K_2}=\Oparity{*}{K_1+K_2},\\
        \Oparity{*}{K_1}\Oparity{*}{K_2}=\Oparity{\even}{K_1K_2},\\
        \Oparity{\odd}{K_1}\Oparity{\even}{K_2}=\Oparity{\odd}{K_1K_2},
    \end{gather*}
    after possibly increasing $C_0$. Here $*$ represents either $\odd$ or $\even$. It should be noted that all of these operations can be done for an arbitrary, but finite, number of times (independent of $N$).
\end{remark}
\begin{remark}\label{rmk:dominationRefinement}
    Definitions \ref{def:od}-\ref{def:graded-poly} refine the stochastic domination notation \ref{def:stochasticDomination}. More precisely, it means that
    \begin{align}\label{eqn:refinement-implications}
        \mathcal{P}=O_{\prec, *}(K) \Longrightarrow \mathcal{P}=O_{\prec}(K),
    \end{align}
    where $*$ can represent $d,\diamond,\even$ or $\odd$. See lines under \cite[Equation~(7.56)]{BloKnoYauYin16} for details.
\end{remark}
We now state the following lemma proved in \cite[Lemma~7.13]{BloKnoYauYin16}.
\begin{lemma}\label{lem:odd-poly}
Let $\mathcal{P}=O_{\prec, \odd}(K)$ for some deterministic $K \leqslant N^{C_0}$. Then for any fixed $D>0$ we have
\begin{equation*}
\big|\mathbb{E} [\mathcal{P}]\big| \prec N^{-1 / 2} K+N^{-D}.
\end{equation*}
\end{lemma}
The following resolvent identities are standard (see \cite[Lemma~3.5]{benaych2016lectures} and \cite[Equation~(4.1)]{benaych2016lectures}):
\begin{gather}
R_{a a}=\frac{1}{-z-\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}}, \label{eqn:neu-series-1}\\
R_{a i}=-R_{a a} \sum_{r \neq a} R_{i r}^{(a)} h_{a r}, \label{eqn:neu-series-2}\\
R_{i j}=R_{i j}^{(a)}+R_{a a} \sum_{r \neq a} R_{i r}^{(a)} h_{a r} \cdot \sum_{r \neq a} R_{j r}^{(a)} h_{a r} .\label{eqn:neu-series-3}
\end{gather}
In the next several lemmas, we write resolvents and multi-resolvents in terms of graded polynomials.
\begin{lemma}\label{lem:parity-r}
Fix $D>0$. For spectral parameter $z\in \bm S$, we have
\begin{gather}
    R_{a a}=O_{\prec, \even}(1)+O_{\prec}\left(N^{-D}\right),\label{eqn:parity-aa}\\
    R_{a b}=O_{\prec, \odd}(\Psi)+\Od,\label{eqn:parity-ab}\\
    R_{b b}=O_{\prec, \even}(1)+\Od,\label{eqn:parity-bb}\\
    \Tr(R)=\sum_{i\neq a}\ra_{ii}+\Oparity{\even}{N\Psi^2}+\Od.\label{eqn:parity-trace}
\end{gather}
\end{lemma}
\begin{proof}
We begin with some preliminary claims. 
Using \eqref{eqn:2-resolvents-ra} and the definition of graded polynomial, we have
\begin{equation}\label{eqn:quad-parity}
\begin{aligned}
\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}-\m & =\sum_{r \neq a} R_{r r}^{(a)}\left(h_{a r}^2-\frac{1}{N}\right)+\left(\frac{1}{N} \sum_{r \neq a} R_{r r}^{(a)}-\m\right)+\sum_{\substack{r \neq s \\
r, s \neq a}} R_{r s}^{(a)} h_{a r} h_{a s} \\
& =O_{\prec, 0}(1)+O_{\prec, 0}(\Psi)+O_{\prec, 2}(\Psi) \\
& =O_{\prec, \even}(1),
\end{aligned}
\end{equation}
and
\begin{equation}\label{eqn:quad}
\begin{aligned}
\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}-\m & =\sum_{r \neq a} R_{r r}^{(a)}\left(h_{a r}^2-\frac{1}{N}\right)+\left(\frac{1}{N} \sum_{r \neq a} R_{r r}^{(a)}-\m\right)+\sum_{\substack{r \neq s \\
r, s \neq a}} R_{r s}^{(a)} h_{a r} h_{a s} \\
& =O_{\prec}\left(N^{-1 / 2}\right)+O_{\prec}(\Psi)+O_{\prec}(\Psi) \\
& =O_{\prec}(\Psi) ,
\end{aligned}
\end{equation}
where we used the definition of graded polynomials and \eqref{eqn:refinement-implications} in the second step and \eqref{eqn:psi-bound} in the last step.

Note also that 
\begin{equation}\label{eqn:linear-parity}
\sum_{r \neq a} R_{i r}^{(a)} h_{r a}=R_{i i}^{(a)} h_{i a}+O_{\prec, \odd}(\Psi) .
\end{equation}
For any $n \in \mathbb{N}$, we have by \eqref{eqn:neu-series-1} that
\begin{equation}\label{eqn:expansion-aa}
\begin{aligned}
R_{a a}  =\frac{1}{-z-\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}}
& =\frac{1}{-z-\m+\left(\m-\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}\right)} \\
& =\frac{1}{1 / \m+\left(\m-\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}\right)} \\
& =\frac{\m}{1+\m\left(\m-\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}\right)} \\
& =\sum_{j=0}^n \m^{i+1}\left(\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}-\m\right)^j+O_{\prec}\left(\m^n \Psi^n\right) \\
& =O_{\prec, \even}(1)+O_{\prec}\left(\m^n \Psi^n\right),
\end{aligned}
\end{equation}
where we used \eqref{eqn:quad} in the second-to-last line and \eqref{eqn:quad-parity} in the last step.

% For $i\neq a$, by \eqref{eqn:neu-series-2},
% \begin{equation}\label{eqn:expansion-ia}
% \begin{aligned}
% R_{i a} & =\sum_{r \neq a} R_{i r}^{(a)} h_{a r} \cdot \frac{1}{z+\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}} \\
% & =\sum_{r \neq a} R_{i r}^{(a)} h_{a r} \cdot \frac{1}{z+\m+\left(\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}-\m\right)} \\
% & =-\sum_{r \neq a} R_{i r}^{(a)} h_{a r} \cdot \frac{\m}{1-\m\left(\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}-\m\right)} \\
% & =-\sum_{r \neq a} R_{i r}^{(a)} h_{a r} \cdot \sum_{j=0}^n \m^{j+1}\left(\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}-\m\right)^j+O_{\prec}\left(\m^n \Psi^n\right) \\
% & =R_{i i}^{(a)} h_{a i} O_{\prec, \even}(1)+O_{\prec, \odd}(\Psi)+O_{\prec}\left(\m^n \Psi^n\right),
% \end{aligned}
% \end{equation}
% where we used \eqref{eqn:quad} in the second last line and \eqref{eqn:quad-parity}, \eqref{eqn:linear-parity} in the last step.

% For $i,j\neq a$, by \eqref{eqn:neu-series-3},
% \begin{equation}\label{eqn:expansion-ij}
% \begin{aligned}
% R_{i j} & =R_{i j}^{(a)}-\sum_{r \neq a} R_{i r}^{(a)} h_{a r} \cdot \sum_{r \neq a} R_{j r}^{(a)} h_{a r} \cdot \frac{1}{z+\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}} \\
% & =R_{i j}^{(a)}-\sum_{r \neq a} R_{i r}^{(a)} h_{a r} \cdot \sum_{r \neq a} R_{j r}^{(a)} h_{a r} \cdot \frac{1}{z+\m+\left(\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}-\m\right)} \\
% & =R_{i j}^{(a)}+\sum_{r \neq a} R_{i r}^{(a)} h_{a r} \cdot \sum_{r \neq a} R_{j r}^{(a)} h_{a r} \cdot \frac{\m}{1-\m\left(\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}-\m\right)} \\
% & =R_{i j}^{(a)}+\sum_{r \neq a} R_{i r}^{(a)} h_{a r} \cdot \sum_{r \neq a} R_{j r}^{(a)} h_{a r} \cdot \sum_{j=0}^n \m^{j+1}\left(\sum_{r, s \neq a} R_{r s}^{(a)} h_{a r} h_{a s}-\m\right)^j+O_{\prec}\left(\m^n \Psi^n\right) \\
% & =R_{i j}^{(a)}+R_{i i}^{(a)} R_{j j}^{(a)} h_{i a} h_{j a} O_{\prec, \even}(1)+\left(R_{i i}^{(a)} h_{i a}+R_{j j}^{(a)} h_{j a}\right) O_{\prec,\odd}(\Psi)+O_{\prec, \even}\left(\Psi^2\right)+O_{\prec}\left(\m^n \Psi^n\right),
% \end{aligned}
% \end{equation}
% where we used \eqref{eqn:quad} in the second last line, and \eqref{eqn:quad-parity}, \eqref{eqn:linear-parity} in the last step.

By \eqref{eqn:neu-series-2} and \eqref{eqn:expansion-aa}, we have
\begin{align}\label{eqn:expansion-ab}
\begin{split}
    R_{ab}=R_{aa}\sum_{r\neq a}\ra_{rb}h_{ar}=\Oparity{\odd}{\Psi}+O_\prec(\m^n\Psi^{n+1}).
\end{split}
\end{align}
By \eqref{eqn:neu-series-3} and \eqref{eqn:expansion-aa}, we have
\begin{align}\label{eqn:expansion-bb}
\begin{split}
    R_{bb}=R_{bb}^{(a)}+R_{aa}\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)^2=\Oparity{\even}{1}+O_\prec(\m^n\Psi^{n+1}).
\end{split}
\end{align}

The lemma follows from \eqref{eqn:expansion-aa}, \eqref{eqn:expansion-ab}, and \eqref{eqn:expansion-bb} by choosing a sufficiently large $n\equiv n\left(\tau,D\right)$.
\end{proof}

\begin{lemma}\label{lem:parity-rr}
Fix $D>0$. For a spectral parameter $z\in\bm S$, we have
\begin{gather}
    (R\bar R)_{aa}=\Oparity{\even}{N\Psi^2}+O_\prec(N^{-D}),\label{eqn:parity-rr-aa}\\
    (R\bar R)_{ab}=\Oparity{\odd}{N\Psi^2}+O_\prec(N^{-D}),\label{eqn:parity-rr-ab}\\
    (R\bar R)_{bb}=\Oparity{\even}{N\Psi^2}+O_\prec\left(N^{-D}\right),\label{eqn:parity-rr-bb}\\
    \left(R^2\right)_{aa} =\Oparity{\even}{N\Psi^2}+O_{\prec}(N^{-D}),\label{eqn:parity-r1r-aa}\\
    \left(R^2\right)_{ab} =\Oparity{\odd}{N\Psi^2}+O_{\prec}(N^{-D}),\label{eqn:parity-r1r-ab}\\
    \left(R^2\right)_{bb} =\Oparity{\even}{N\Psi^2}+O_{\prec}(N^{-D}).\label{eqn:parity-r1r-bb}
\end{gather}
\end{lemma}
\begin{proof}We present only the proof of \eqref{eqn:parity-rr-aa}; the others can be done similarly. By the resolvent identity \eqref{eqn:neu-series-2},% and \eqref{eqn:neu-series-2}, we have
\begin{align}\label{eqn:expansion-rr-aa}
\begin{split}
    (R\bar R)_{aa}=\sum_{i\neq a}\left(R_{ai}\bar R_{ia}\right)+|R_{aa}|^2
    =&|R_{aa}|^2\sum_{i\neq a}\left(\sum_{r\neq a}\ra_{ri}h_{ar}\right)\left(\sum_{r\neq a}\rab_{ir}h_{ar}\right)+|R_{aa}|^2\\
    =&|R_{aa}|^2\left(\sum_{r,s\neq a}\rr_{rs}h_{ar}h_{as}+1\right).
\end{split}
\end{align}
Combining \eqref{eqn:psi-bound}, \eqref{eqn:2-resolvents-ra}, \eqref{eqn:parity-aa}, and \eqref{eqn:expansion-rr-aa}, we deduce \eqref{eqn:parity-rr-aa}.
\end{proof}

\begin{lemma}\label{lem:ortho-basis}
There exists an orthonormal basis $\{\bm w_i\}_{i=1}^N$ of $\R^N$ such that
\begin{align}\label{eqn:ortho-cond}
\begin{split}
    \bm w_i(j)\prec N^{-1/2}\text{ and }\left|\sum_{k}\e_j^\trans A\bm w_k\right|\prec 1,
\end{split}
\end{align}
uniformly over $i,j\in \llbracket 1,N\rrbracket$.
\end{lemma}
\begin{proof}
Let the matrix $W=[\bm w_1,\ldots,\bm w_N]$ %of orthonormal basis 
be uniformly distributed on the orthogonal group $O(n)$ with respect to Haar measure. Then the marginal distribution of each column vector $\bm w_i$ is uniform on the unit sphere $\mathbb S^{N-1}$. By a standard concentration result (see \cite[Theorem~3.4.6]{vershynin2018high}), we have 
\begin{align}\label{eqn:ortho-first}
\begin{split}
    \bm w_i(j)\prec N^{-1/2}.
\end{split}
\end{align}

Consider the function on $N\times N$ matrices defined by
\begin{align*}
\begin{split}
    \varphi(M)\defeq \e_j^\trans AW\bm 1,
\end{split}
\end{align*}
where $\bm 1$ has all entries equal to $1$. 
We claim that $\phi$ is Lipshitz with respect to the Frobenius norm with Lipshitz constant at most $N^{1/2}$. Indeed, with $\bm u\defeq A\e_j$,
\begin{align*}
\begin{split}
    |\phi(W)-\phi(\tilde W)|\leq \bigg|\sum_{i,k}u_i(w_{ik}-\tilde w_{ik})\bigg|
    &\leq \sum_i|u_i|\left(\sum_k(w_{ik}-\tilde w_{ik})^2\right)^{1/2}N^{1/2}\\
    &\leq N^{1/2}\|\bm u\|\|W-\tilde W\|_F\\
    &\leq N^{1/2}\|W-\tilde W\|_F,
\end{split}
\end{align*}
where we used the Cauchy--Schwarz inequality in the second and third inequalities, and we used $\|A\|\leq 1$ in the last inequality. By a standard concentration result for the orthogonal group (see \cite[Theorem~5.2.7]{vershynin2018high}), we have 
\begin{align}\label{eqn:ortho-second}
\begin{split}
\left|\varphi(W)\right|\prec 1.
\end{split}
\end{align}
By \eqref{eqn:ortho-first} and \eqref{eqn:ortho-second}, there exists an orthonormal basis satisfying \eqref{eqn:ortho-cond}.
\end{proof}

\begin{lemma}\label{lem:parity-rar-rarr}
Fix $D>0$. For a spectral parameter $z=E+\iu\eta$ satisfying 
\begin{align*}
    E\in\I_\ell,\quad \eta=\eta_\ell,
\end{align*}
we have
\begin{gather}
(R A \bar{R})_{a a}  =O_{\prec, \even}\left(N^{1 / 2} \Psi\right)+\Oparity{\odd}{\Psi}+O_\prec(N^{-D}),\label{eqn:parity-rar-aa} \\
(R A \bar{R})_{a b}  =\Oparity{\odd}{N^{1/2}\Psi}+\Oparity{\even}{\Psi}+O_{\prec}(N^{-D}),\label{eqn:parity-rar-ab} \\
(R A \bar{R})_{b b}  =\Oparity{\even}{N^{1/2}\Psi}+\Oparity{\odd}{\Psi^2}+O_\prec(N^{-D}),\label{eqn:parity-rar-bb} \\
\Tr\left(RA\bar R\right)=\Tr\rar+\Oparity{\even}{N^{3/2}\Psi^{9/4}}+\Oparity{\odd}{N\Psi^2}+O_\prec(N^{-D}),\label{eqn:parity-rar-trace}\\
(R A \bar{R} R)_{a a}  =\Oparity{\even}{N^{3/2}\Psi^{9/4}}+\Oparity{\odd}{N\Psi^2}+O_{\prec}\left(N^{-D}\right),\label{eqn:parity-rarr-aa}\\
(R A \bar{R} R)_{a b}  =\Oparity{\odd}{N^{3/2}\Psi^{9/4}}+\Oparity{\even}{N\Psi^2}+O_{\prec}\left(N^{-D}\right),\label{eqn:parity-rarr-ab}\\
(R A \bar{R} R)_{b b}  =\Oparity{\even}{N^{3/2}\Psi^{9/4}}+\Oparity{\odd}{N\Psi^3}+O_\prec\left(N^{-D}\right),\label{eqn:parity-rarr-bb}\\
(RA\bar RR)_{ba}=\Oparity{\odd}{N^{3/2}\Psi^{9/4}}+\Oparity{\even}{N\Psi^3}+O_\prec(N^{-D}).\label{eqn:parity-rarr-ba}
\end{gather}
\end{lemma}
\begin{proof}We present the proof of \eqref{eqn:parity-rar-aa}. The others can be shown similarly.

By the resolvent identity \eqref{eqn:neu-series-2}, we have
\begin{multline}\label{eqn:expansion-rar-aa}
(RA\bar R)_{aa}=|R_{aa}|^2\sum_{r,s\neq a}\left(R^{(a)}A\bar R^{(a)}\right)_{rs}h_{ar}h_{as}\\
+|R_{aa}|^2\left(\sum_{s\neq a}\left(A\rab\right)_{as}h_{as}+\sum_{r\neq a}\left(\ra A\right)_{ra}h_{ar}+A_{aa}\right).
\end{multline}
By the definition of graded polynomial (see Definition \ref{def:graded-poly}), \eqref{eqn:parity-aa} and \eqref{eqn:2-resolvents-traceless-ra}, the first line of \eqref{eqn:expansion-rar-aa} is
\begin{align}\label{eqn:rar-aa-first-line}
\begin{split}
|R_{aa}|^2\sum_{r,s\neq a}\left(R^{(a)}A\bar R^{(a)}\right)_{rs}h_{ar}h_{as}=\Oparity{\even}{N^{1/2}\Psi}+O_{\prec}(N^{-D}).
\end{split}
\end{align}
Select an orthonormal basis $\{\bm w_{i}\}_{i=1}^{N}$ of $\R^N$ according to Lemma \ref{lem:ortho-basis},
we have
\begin{align*}
\begin{split}
\left|\left(A\rab\right)_{as}\right|=\left|\sum_i\bm e_a^\trans A\bm w_i\bm w_i^\trans \rab\e_s\right|&\leq \left|\sum_i\e_a^\trans A\bm w_i\left(\left\langle \bm w_i,\e_s\right\rangle \m(z)+ \Psi\right)\right|\\
&\prec \left|\Psi\sum_i\e_a^\trans A\bm w_i\right|\prec \Psi,
\end{split}
\end{align*}
where we used \eqref{isotropic} in the first inequality, and $\Psi(z)>C\tau^{1/4}N^{-1/2}$ for $z\in\bm S$ in the second inequality.

Similarly, we have
%\begin{align}
%\begin{split}
$\left|\left(\ra A\right)_{ra}\right|\prec \Psi.$
%\end{split}
%\end{align}
Moreover, $|A_{aa}|\leq 1$ as a consequence of $\|A\|\leq 1$. Therefore, by definition of graded polynomial, the second line of \eqref{eqn:expansion-rar-aa} is
\begin{align}\label{eqn:rar-aa-second-line}
\begin{split}
|R_{aa}|^2\left(\sum_{s\neq a}\left(A\rab\right)_{as}h_{as}+\sum_{r\neq a}\left(\ra A\right)_{ra}h_{ar}+A_{aa}\right)=\Oparity{\odd}{\Psi}+\Oparity{\even}{1}+O_\prec(N^{-D}).
\end{split}
\end{align}
\eqref{eqn:parity-rar-aa} now follows from \eqref{eqn:rar-aa-first-line} and \eqref{eqn:rar-aa-second-line}.
\end{proof}
% Fix $k\neq a$. By \eqref{eqn:neu-series-2} and \eqref{eqn:neu-series-3}, we have
% \begin{align}\label{eqn:expansion-rar-ak}
% \begin{split}
% \left(RA\bar R\right)_{ak}=&|R_{aa}|^2\left(\sum_{r\neq a}\rab_{kr}h_{ar}\right)\left(\sum_{r,s\neq a}\left(\ra A\rab\right)_{rs}h_{ar}h_{as}\right)+R_{aa}\left(\sum_{r\neq a}\left(\ra A\rab\right)_{rk}h_{ar}\right)\\
% &+|R_{aa}|^2\left(\sum_{r\neq a}\rab_{kr}h_{ar}\right)\left(\sum_{r\neq a}\left(\left(\ra A\right)_{ra}+\left(A\rab\right)_{ar}\right)h_{ar}\right)+R_{aa}\left(A\rab\right)_{ak}\\
% &+|R_{aa}|^2A_{aa}\sum_{r\neq a}\rab_{rk}h_{ar}
% \end{split}
% \end{align}
% Therefore by definition of graded polynomials, in case $b\neq a$, we have 
% \begin{align}
% \begin{split}
%     \left(RA\bar R\right)_{ab}=\Oparity{\odd}{N^{1/2}\Psi}+\Oparity{\even}{\Psi}+O_\prec(N^{-D}),
% \end{split}
% \end{align}
% which proves \eqref{eqn:parity-rar-ab}.
% Fix $j,k\neq a$, by resolvent identities, we have
% \begin{align}\label{eqn:expansion-rar-jk}
% \begin{split}
%     (RA\bar R)_{jk}=&\left(\ra A\rab\right)_{jk}+R_{aa}\left(\sum_{r\neq a}\ra_{jr}h_{ar}\right)\left(\sum_{r\neq a}\left(\ra A\rab\right)_{rk}h_{ar}\right)\\
%     &+\bar R_{aa}\left(\sum_{r\neq a}\rab_{kr}h_{ar}\right)\left(\sum_{r\neq a}\left(\ra A\rab\right)_{jr}h_{ar}\right)\\
%     &+|R_{aa}|^2\left(\sum_{r\neq a}\ra_{jr}h_{ar}\right)\left(\sum_{r\neq a}\rab_{kr}h_{ar}\right)\left(\sum_{r,s\neq a}\left(\ra A\rab\right)_{rs}h_{ar}h_{as}\right)\\
%     &+\bar R_{aa}\left(\ra A\right)_{ja}\left(\sum_{r\neq a}\rab_{kr}h_{ar}\right)+|R_{aa}|^2\left(\sum_{r\neq a}\ra_{jr}h_{ar}\right)\left(\sum_{r\neq a}\rab_{kr}h_{ar}\right)\left(\sum_{r\neq a}\left(\ra A\right)_{ra}h_{ar}\right)\\
%     &+R_{aa}\left(A\rab\right)_{ak}\left(\sum_{r\neq a}\ra_{jr}h_{ar}\right)+|R_{aa}|^2\left(\sum_{r\neq a}\ra_{jr}h_{ar}\right)\left(\sum_{r\neq a}\rab_{kr}h_{ar}\right)\left(\sum_{r\neq a}\left(A\rab\right)_{ar}h_{ar}\right)\\
%     &+|R_{aa}|^2\left(\sum_{r\neq a}\ra_{jr}h_{ar}\right)\left(\sum_{r\neq a}\rab_{kr}h_{ar}\right).
% \end{split}
% \end{align}
% Therefore, by definition of graded polynomials, in case $b\neq a$, we have
% \begin{align}
% \begin{split}
%     \left(RA\bar R\right)_{bb}=\Oparity{\even}{N^{1/2}\Psi}+\Oparity{\odd}{\Psi^2}+O_\prec(N^{-D}),
% \end{split}
% \end{align}
% which proves \eqref{eqn:parity-rar-bb}.
% From \eqref{eqn:expansion-rar-aa} and \eqref{eqn:expansion-rar-jk}, we have
% \begin{align}
% \begin{split}
%     \Tr\left(RA\bar R\right)=&\sum_k\left(RA\bar R\right)_{kk}\\
%     =&\Tr\rar\\
%     &+R_{aa}\left(\sum_{r,s\neq a}\rarr_{rs}h_{ar}h_{as}\right)+\bar R_{aa}\left(\sum_{r,s\neq a}\left(\rab\ra A\rab\right)_{rs}h_{ar}h_{as}\right)\\
%     &+|R_{aa}|^2\left(\sum_{r,s\neq a}\rr_{rs}h_{ar}h_{as}\right)\left(\sum_{r,s\neq a}\rar_{rs}h_{ar}h_{as}+1\right)\\
%     &+\bar R_{aa}\left(\sum_{r\neq a}\left(\rab\ra A\right)_{ra}h_{ar}\right)+|R_{aa}|^2\left(\sum_{r,s\neq a}\rr_{rs}h_{ar}h_{as}\right)\left(\sum_{r\neq a}\left(\ra A\right)_{ra}h_{ar}\right)\\
%     &+R_{aa}\left(\sum_{r\neq a}\left(A\rab\ra\right)_{ar}h_{ar}\right)+|R_{aa}|^2\left(\sum_{r,s\neq a}\rr_{rs}h_{ar}h_{as}\right)\left(\sum_{r\neq a}\left(A\rab\right)_{ar}h_{ar}\right)\\
%     &+|R_{aa}|^2\sum_{r,s\neq a}\left(R^{(a)}A\bar R^{(a)}\right)_{rs}h_{ar}h_{as}+|R_{aa}|^2\left(\sum_{s\neq a}\left(A\rab\right)_{as}h_{as}+\sum_{r\neq a}\left(\ra A\right)_{ra}h_{ar}\right)
% \end{split}
% \end{align}
% which implies \eqref{eqn:parity-rar-trace} by the definition of graded polynomial.
% By \eqref{eqn:expansion-rar-ak} and \eqref{eqn:neu-series-2}, we have
% \begin{align}
% \begin{split}
%     &\sum_{k\neq a}\left(RA\bar R\right)_{ak}R_{ka} \\
%     =&R_{aa}^2\left(\sum_{r,s\neq a}\left(\ra A\rab \ra\right)_{rs}h_{ar}h_{as}\right)\\
%     &+R_{aa}|R_{aa}|^2\left(\sum_{r,s\neq a}\left(\ra\rab\right)_{rs}h_{ar}h_{as}\right)\left(\sum_{r, s \neq a}\left(R^{(a)} A \bar{R}^{(a)}\right)_{r s} h_{a r} h_{a s}\right)\\
%     &+R_{aa}|R_{aa}|^2\left(\sum_{r,s\neq a}\left(\ra\rab\right)_{rs}h_{ar}h_{as}\right)\left(\sum_{r \neq a}\left(\left(R^{(a)} A\right)_{r a}+\left(A \bar{R}^{(a)}\right)_{a r}\right) h_{a r}\right)\\
%     &+R_{aa}^2\left(\sum_{r\neq a}\left(A\rab\ra\right)_{ar}h_{ar}\right)+R_{aa}|R_{aa}|^2A_{aa}\left(\sum_{r,s\neq a}\left(\ra\rab\right)_{rs}h_{ar}h_{as}\right).
% \end{split}
% \end{align}
% Combined with \eqref{eqn:parity-rar-aa}, we have
% \begin{align}
% \begin{split}
%     \left(RA\bar RR\right)_{aa}&=\sum_{k\neq a}\left(RA\bar R\right)_{ak}R_{ka}+\left(RA\bar R\right)_{aa}R_{aa}\\
%     &=\Oparity{\even}{N^{3/2}\Psi^{9/4}}+\Oparity{\odd}{N\Psi^2}+O_{\prec}\left(N^{-D}\right),
% \end{split}
% \end{align}
% which proves \eqref{eqn:parity-rarr-aa}.
% The proof of \eqref{eqn:parity-rarr-ab}, \eqref{eqn:parity-rarr-bb} and \eqref{eqn:parity-rarr-ba} follows similarly.
% We have
    % \begin{align}
    % \begin{split}
    %     &\sum_{k\neq a}\left(RA\bar R\right)_{ak}R_{kb}\\
    %     =&|R_{aa}|^2\left(\sum_{r\neq a}\left(\ra\rab\right)_{br}h_{ar}\right)\left(\sum_{r, s \neq a}\left(R^{(a)} A \bar{R}^{(a)}\right)_{r s} h_{a r} h_{a s}\right)\\
    %     &+R_{aa}\left(\sum_{r\neq a}\left(\ra A\rab\ra\right)_{rb}h_{ar}\right)\\
    %     &+|R_{aa}|^2\left(\sum_{r\neq a}\left(\ra\rab\right)_{br}h_{ar}\right)\left(\sum_{r \neq a}\left(\left(R^{(a)} A\right)_{r a}+\left(A \bar{R}^{(a)}\right)_{a r}\right) h_{a r}\right)\\
    %     &+R_{aa}\left(A\rab\ra\right)_{ab}+|R_{aa}|^2A_{aa}\left(\sum_{r\neq a}\left(\ra\rab\right)_{br}h_{ar}\right)\\
    %     &+R_{aa}|R_{aa}|^2\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)\left(\sum_{r,s\neq a}\left(\ra\rab\right)_{rs}h_{ar}h_{as}\right)^2\\
    %     &+R_{aa}^2\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)\left(\sum_{r,s\neq a}\left(\ra A\rab\ra\right)_{rs}h_{ar}h_{as}\right)\\
    %     &+R_{aa}|R_{aa}|^2\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)\left(\sum_{r,s\neq a}\left(\ra\rab\right)_{rs}h_{ar}h_{as}\right)\left(\sum_{r \neq a}\left(\left(R^{(a)} A\right)_{r a}+\left(A \bar{R}^{(a)}\right)_{a r}\right) h_{a r}\right)\\
    %     &+R_{aa}^2\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)\left(\sum_{r\neq a}\left(A\rab\ra\right)_{ar}h_{ar}\right)\\
    %     &+R_{aa}|R_{aa}|^{2}A_{aa}\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)\left(\sum_{r,s\neq a}\left(\ra\rab\right)_{rs}h_{ar}h_{as}\right).
    % \end{split}
    % \end{align}
    % Combined with \eqref{eqn:expansion-rar-aa}, we have
    % \begin{align}
    % \begin{split}
    %     \left(RA\bar RR\right)_{ab}&=\sum_{k\neq a}\left(RA\bar R\right)_{ak}R_{kb}+\left(RA\bar R\right)_{aa}R_{ab}\\
    %     &=\Oparity{\odd}{N^{3/2}\Psi^{9/4}}+\Oparity{\even}{N\Psi^2}+O_{\prec}\left(N^{-D}\right).
    % \end{split}
    % \end{align}
    % which proves \eqref{eqn:parity-rarr-ab}.
    % Finally, we have
    % \begin{align}
    % \begin{split}
    %     &\sum_{k\neq a}\left(RA\bar R\right)_{bk}R_{kb}\\
    %     =&\rarr_{bb}+R_{aa}\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)\left(\sum_{r\neq a}\rarr_{rb}h_{ar}\right)\\
    %     &+\bar R_{aa}\left(\sum_{r\neq a}\rr_{br}h_{ar}\right)\left(\sum_{r\neq a}\rar_{br}h_{ar}\right)\\
    %     &+|R_{aa}|^2\left(\sum_{r\neq a}\ra_{br}h_{br}\right)\left(\sum_{r\neq a}\rr_{br}h_{ar}\right)\left(\sum_{r,s\neq a}\rar_{rs}h_{ar}h_{as}+1\right)\\
    %     &+\bar R_{aa}\left(\ra A\right)_{ba}\left(\sum_{r\neq a}\rr_{br}h_{ar}\right)+R_{aa}\left(A\rab \ra\right)_{ab}\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)\\
    %     &+|R_{aa}|^2\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)\left(\sum_{r\neq a}\rr_{br}h_{ar}\right)\left(\sum_{r\neq a}\left(\left(\ra A\right)_{ra}h_{ar}+\left(A\rab\right)_{ar}h_{ar}\right)\right)\\
    %     % &+|R_{aa}|^2\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)\left(\sum_{r\neq a}\rr_{br}h_{ar}\right)\left(\sum_{r\neq a}\left(A\rab\right)_{ar}h_{ar}\right)\\
    %     &+R_{aa}\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)\left(\sum_{r\neq a}\rarr_{br}h_{ar}\right)\\
    %     &+R_{aa}^2\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)^2\left(\sum_{r,s\neq a}\rarr_{rs}h_{ar}h_{as}\right)\\
    %     &+|R_{aa}|^2\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)\left(\sum_{r\neq a}\rar_{br}h_{ar}\right)\left(\sum_{r,s\neq a}\rr_{rs}h_{ar}h_{as}\right)\\
    %     &+R_{aa}|R_{aa}|^2\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)^2\left(\sum_{r,s\neq a}\rar_{rs}h_{ar}h_{as}\right)\left(\sum_{r,s\neq a}\rr_{rs}h_{ar}h_{as}+1\right)\\
    %     &+|R_{aa}|^2\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)\left(\ra A\right)_{ba}\left(\sum_{r,s\neq a}\rr_{rs}h_{ar}h_{as}\right)\\
    %     &+R_{aa}^2\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)^2\left(\sum_{r\neq a}\left(A\rab\ra\right)_{ar}h_{ar}\right)\\
    %     &+R_{aa}|R_{aa}|^2\left(\sum_{r\neq a}\ra_{br}h_{ar}\right)^2\left(\sum_{r,s\neq a}\rr_{rs}h_{ar}h_{as}\right)\left(\sum_{r\neq a}\left(\left(\ra A\right)_{ra}+\left(A\rab\right)_{ar}\right)h_{ar}\right).
    % \end{split}
    % \end{align}
    % Combined with \eqref{eqn:parity-rar-bb}, we have
    % \begin{align}
    % \begin{split}
    %     \left(RA\bar RR\right)_{bb}=&\sum_{k\neq a}\left(RA\bar R\right)_{bk}R_{kb}+\left(RA\bar R\right)_{ba}R_{ab}\\
    %     =&\Oparity{\even}{N^{3/2}\Psi^{9/4}}+\Oparity{\odd}{N\Psi^3}+O_\prec\left(N^{-D}\right),
    % \end{split}
    % \end{align}
    % which proves \eqref{eqn:parity-rarr-bb}.
\begin{remark}
    We note that the even graded polynomials in \eqref{eqn:parity-rarr-ab} and \eqref{eqn:parity-rarr-ba} are different by an order of $\Psi$. This should not be surprising, since we are expanding with respect to the $a$-th row and column in $Q$, but $a$ does not take a ``symmetric'' position in the multi-resolvents $(RA\bar RR)_{ab},(RA\bar RR)_{ba}$. This point will be exploited in Lemma \ref{lem:parity-x3}.
\end{remark}


Using Lemma \ref{lem:parity-r}, Lemma \ref{lem:parity-rr}, Lemma \ref{lem:parity-rar-rarr} and the definitions of $x_i,y_i$ in Lemma \ref{lem:resolvent-expansion}, we have the following lemma. We omit the proof, since it is straightforward.

\begin{lemma}\label{lem:parity-xy}
Let $x_i,i=1,2$ and $y_i,i=1,2,3$ be the resolvent expansion as in Lemma \ref{lem:resolvent-expansion}. For spectral parameter $z=E+\iu\eta$ satisfying
\begin{align}
\begin{split}
    E\in I_\ell,\quad \eta=\eta_\ell,
\end{split}
\end{align}
we have
\begin{gather*}
x_1=\Oparity{\odd}{N^{1+\delta/2}\Psi^{5/4}}+\Oparity{\even}{N^{1/2+\delta/2}\Psi}+O_\prec(N^{-D}),\\
x^R,x_2=\Oparity{\even}{N^{1+\delta/2}\Psi^{5/4}}+\Oparity{\odd}{N^{1/2+\delta/2}\Psi}+O_\prec(N^{-D}),\\
y_1,y_3=\Oparity{\odd}{\Psi}+O_\prec(N^{-D}),\\
y_2=\Oparity{\even}{\Psi}+O_\prec(N^{-D}).
\end{gather*}
\end{lemma}

To bound $x_3$, we need an extra lemma.
\begin{lemma}\label{lem:parity-x3}
Denote by 
%\begin{align*}
%\begin{split}
    $\Oparity{\odd,b}{K}\,$%,\Oparity{\odd,b}{K}
%\end{split}
%\end{align*}
 the graded polynomial with expansion in $b$-th row and column of $Q$ instead of $a$-th row and column. Then for spectral parameter $z=E+\iu\eta$ satisfying
\begin{align*}
\begin{split}
    E\in I_\ell,\quad \eta=\eta_\ell,
\end{split}
\end{align*}
we have
%\begin{align*}
%\begin{split}
\begin{multline}\label{eqn:parity-x3}
    x_3=\Oparity{\odd}{N^{1+\delta/2}\Psi^{5/4}}+\Oparity{\odd,b}{N^{1+\delta/2}\Psi^{5/4}}+
    \Oparity{\even}{N^{1/2+\delta/2}\Psi^2}\\+\Oparity{\even,b}{N^{1/2+\delta/2}\Psi^2}+\Od.
\end{multline}
%\end{split}
%\end{align*}
\end{lemma}
\begin{proof}
By definition, 
\begin{align}\label{eqn:x3}
\begin{split}
    &\sqrt{\frac{|\I|(N-|\I|)}{N^3\eta_\ell^2}}x_3
    \\&=-(RA\bar RR)_{ab}R_{aa}R_{bb}-(RA\bar RR)_{ba}R_{aa}R_{bb}-(RA\bar R)_{aa}(R\bar R)_{ab}R_{bb}-\left(RA\bar R\right)_{bb}(R\bar R)_{ba}R_{aa}\\
    &-(RA\bar R)_{ab}(R\bar R)_{aa}R_{bb}-(RA\bar R)_{ba}(R\bar R)_{bb}R_{aa}+[C]+[L],
\end{split}
\end{align}
where $[C]$ denotes the conjugate of the previous terms and $[L]$ refers to terms with smaller order for either parity (even or odd). 

For the first term in \eqref{eqn:x3}, using resolvent identities with respect to the $b$-th row and column as in the proof of Lemma \ref{lem:parity-r} and Lemma \ref{lem:parity-rar-rarr}, we have
\begin{gather*}
    (RA\bar RR)_{ab}=\Oparity{\odd,b}{N\Psi^{9/4}}+\Oparity{\even,b}{N^{1/2}\Psi^3}+\Od,\\
    R_{aa}=\Oparity{\even,b}{1}+\Od,\quad R_{bb}=\Oparity{\even,b}{1}+\Od.
\end{gather*}
The conclusion follows by applying Lemma \ref{lem:parity-r}, Lemma \ref{lem:parity-rr} and Lemma \ref{lem:parity-rar-rarr} to the remaining terms of \eqref{eqn:x3}.
\end{proof}
\begin{remark}
    Note that it is still legitimate to apply Lemma \ref{lem:odd-poly} to \eqref{eqn:parity-x3}. Since by linearity of expectation, we may apply Lemma \ref{lem:odd-poly} to $\Oparity{\odd}{K}$ and $\Oparity{\odd,b}{K}$ separately.
\end{remark}

By \eqref{eqn:parity-trace}, \eqref{eqn:parity-rar-trace}, Lemma \ref{lem:bound-x-integral} and Taylor expansion, we have
\begin{gather}
g^{(k)}\left(\int_{I_\ell}x^Rq(y^R)\d E\right)=\Oparity{\even}{N^{C_0\delta_2}}+\Oparity{\odd}{N^{-1/2+\delta/2+C_0\delta_2}},\quad k=1,2,3,\label{eqn:parity-g}\\
q^{(k)}(y^R)=\Oparity{\even}{1},\quad k=1,2,3\label{eqn:parity-q}
\end{gather}
for some constant $C>0$ which depends only on $g$. The same graded polynomial expansion holds for the expansion respect to $b$-th row and column.

We are now ready for the proof of Lemma \ref{lem:third-moment-terms}.
\begin{proof}[Proof of Lemma \ref{lem:third-moment-terms}]
Define
\begin{gather*}
    \Psi_\ell=(N\Delta_\ell)^{-1}\leq N^{-\tau/3},\quad\text{and}\quad
    \hat N=N^{2\delta_1+\delta_2+\delta/2}\ll N^{-\tau/1000}.
\end{gather*}
Combining Lemma \ref{lem:parity-xy}, Lemma \ref{lem:parity-x3}, definition of $P_{\bm l}$, Remark \ref{rmk:stochastic-continuation} and \eqref{eqn:psi-bound-specified}, we have
\begin{equation*}
\begin{gathered}
P_{(1)},P_{(0,1)}=\Oparity{\odd}{\hat N\Psi_\ell^{1/4}}+\Oparity{\even}{\hat NN^{-1/2}}+\Od,\\
P_{(2)},P_{(0,2)},P_{(1,1)},P_{(0,1,1)}=\Oparity{\even}{\hat N\Psi_\ell^{1/4}}+\Oparity{\odd}{\hat NN^{-1/2}}+\Od,\\
\end{gathered}
\end{equation*}
as well as 
\begin{multline*}
    P_{(0,3)},P_{(1,2)},P_{(2,1)},P_{(0,1,2)},P_{(1,1,1)},P_{(0,1,1,1)}\\=\Oparity{\odd}{\hat N\Psi_\ell^{5/4}}+\Oparity{\even}{\hat NN^{-1/2}\Psi_\ell}+\Od,
\end{multline*}
and
\begin{multline*}
        %\begin{aligned}
    P_{(3)}=\Oparity{\odd}{\hat N\Psi_\ell^{1/4}}+\Oparity{\odd,b}{\hat N\Psi_\ell^{1/4}}\\
+\Oparity{\even}{\hat NN^{-1/2}\Psi_\ell}+\Oparity{\even,b}{\hat NN^{-1/2}\Psi_\ell}+\Od.
    %\end{aligned}
\end{multline*}
Combining \eqref{eqn:parity-g} and Lemma \ref{lem:odd-poly}, we conclude the existence of $c\equiv c(\tau)>0$, such that
\begin{align*}
\begin{split}
    \E [Y]\prec N^{-1/2-c}+N^{-D}\leq N^{-1/2-c},
\end{split}
\end{align*}
when $Y$ represents any term in \eqref{eqn:third-moment-terms}.
\end{proof}























\appendix
%\newpage

\section{Proof of Lemma \ref{lem:three-resolvent-local-law}}\label{sec:local-law}
The proof is based on the cumulant expansion which can be found in \cite[Lemma 3.2]{lee2018local}.
%We will need the following cumulant expansion lemma in the proof, which is taken from \cite[Lemma~3.2]{lee2018local}.
\begin{lemma}[Cumulant expansion]\label{lem:cumulant-expansion}
Fix $T \in \mathbb{N}$ and let $F:\R\rightarrow\mathbb C^+$ be $T+1$ times continuously differentiable. Let $Y$ be a mean zero random variable with finite moments to order $T+2$. Then there exists a function $\Omega_T: \mathbb{C} \rightarrow \mathbb{C}$ such that
\begin{equation}\label{eqn:cumulant-theorem}
\mathbb{E}\big[Y F(Y)\big]=\sum_{r=1}^{T} \frac{\kappa^{(r+1)}(Y)}{r !} \mathbb{E}\left[F^{(r)}(Y)\right]+\mathbb{E}\Big[\Omega_{T}\big(Y F(Y)\big)\Big],
\end{equation}
where $\mathbb{E}$ denotes the expectation with respect to $Y, \kappa^{(r+1)}(Y)$ denotes the $(r+1)$-th cumulant of $Y$, and $F^{(r)}$ denotes the $r$-th derivative of the function $F$. Further, there exists a constant $C >0$ (not depending on $F$ or $Y$) such that %The error term $\Omega_{\ell}(Y F(Y))$ in (3.20) satisfies
\begin{equation*}
\begin{aligned}
\left|\mathbb{E}\Big[\Omega_{T}\big(Y F(Y)\big)\Big]\right| \leqslant \frac{(C T)^{T}}{T !} \cdot \mathbb{E}\left[|Y|^{T+2}\right] \sup_{t\in\R}\left|F^{(T+1)}(t)\right|.
\end{aligned}
\end{equation*}
%where $C_{T}$ satisfies $C_{T} \leqslant \frac{(C T)^{T}}{T !}$ for some numerical constant $C$.
\end{lemma}

% \begin{lemma}Let $H$ be a Wigner matrix, and $G(z)=(H-z)^{-1}$ be its Stieltjes transform. The spectral parameter $z=E+\iu\eta$ satisfies
% \begin{align}
% \begin{split}
%     E\in I_\ell,\quad \eta=\eta_\ell.
% \end{split}
% \end{align}
% Define
% \begin{align}
% \begin{split}
%     \Psi\defeq\frac{1}{N\eta_\ell}=N^{-1/3}\ell^{1/3}N^{\delta_1}\leq N^{-\tau/3+\delta_1}.
% \end{split}
% \end{align}
% Then for any deterministic traceless matrix $A$, with $\|A\|\leq 1$, and index $c,d\in\llbracket1,N\rrbracket$, we have
% \begin{align}
% \begin{split}
%     |(GA\bar GG)_{cd}|\prec N^{3/2}\Psi^{9/4}.
% \end{split}
% \end{align}

% \end{lemma}
\begin{proof}[Proof of Lemma \ref{lem:three-resolvent-local-law}]
First, we claim that it suffices to prove the local laws for the resolvent $G$, because the local laws for $R$ are straightforward consequences of the ones for $G$. We illustrate the procedure of deducing a local law for $R$ from the corresponding local law for $G$ for the first inequality in \eqref{eqn:2-resolvents}. The other deductions are similar. 

Pick any $z=E+\iu\eta\in\bm S$. By \eqref{eqn:resolvent-expansion-original}, we have 
\begin{equation*}
    R_{\bm x\bm y}=G_{\bm x\bm y}-(GUG)_{\bm x\bm y}+(GUGUG)_{\bm x\bm y}-((GU)^3G)_{\bm x\bm y}+((GU)^4R)_{\bm x\bm y}.
\end{equation*}
Combining the estimates $h_{ab}\prec N^{-1/2}$, $\|R\|\leq \eta^{-1}$, $\Psi\geq C\tau^{1/4}N^{-1/2}$ from Lemma~\ref{lem:prelim-bound} and the isotropic local law \eqref{isotropic} for $G$, the isotropic local law for $R$ follows.

In light of the previous discussion, we  focus only on the local laws for $G$.
By Theorem \ref{thm:iso-single}, we have
\begin{equation}\label{a3}
\begin{aligned}
    (G\bar G)_{\x\y}=\sum_k G_{\x k}\bar G_{k\y}&\prec \left|\sum_k\langle\x,\e_k\rangle\langle\e_k,\y\rangle\right|+\left|\sum_k\langle\x,\e_k\rangle\right|\Psi+\left|\langle\e_k,\y\rangle\right|\Psi+N\Psi^2\\
    &\leq |\langle\x,\y\rangle|+2N^{1/2}\Psi+N\Psi^2\prec N\Psi^2,
\end{aligned}
\end{equation}
where we use Cauchy inequality in the second last inequality and $\Psi\geq C\tau^{1/4}N^{-1/2}$ on $\bm S$ in the last step. Similarly we have
\begin{equation}\label{a4}
    (G^2)_{cd}\prec N\Psi^2.
\end{equation}
Then  \eqref{eqn:2-resolvents} follows from \eqref{isotropic}, \eqref{a3}, and \eqref{a4}.

Next, the expression \eqref{eqn:2-resolvents-traceless} is a direct consequence of \eqref{eqn:center-iso} and \eqref{eqn:iso} with two resolvents and one traceless matrix. It remains to prove \eqref{eqn:3-resolvents-traceless}.


We proceed by computing the moments of the quantity $\left(GA\bar GG\right)_{cd}$. For the rest of the proof, we assume the spectral parameter $z=E+\iu\eta\in\bm S$ satisfies $E\in I_\ell$ and $\eta=\eta_\ell$ as in the statement of Lemma \ref{lem:three-resolvent-local-law}.

Fix $D>1$, we have
\begin{equation}\label{eqn:multi-resolvent-moment}
\begin{aligned}
\mathbb{E} \left[z\left|(G A \bar{G} G)_{cd}\right|^{2 D}\right]= %& \mathbb{E} \left[z\left|\sum_{i, j,k} G_{c i}A_{ij} \bar{G}_{jk} G_{k d}\right|^{2 D}\right] \\
%= & \mathbb{E} \left[z \sum_{i, j,k}G_{c  i}A_{ij} \bar{G}_{jk} G_{k d }(G A \bar{G} G)_{c  d }^{D-1}(\bar{G} A G \bar{G})_{c  d }^D \right]\\
& \mathbb{E} \left[z (G A \bar{G} G)_{c  d }(G A \bar{G} G)_{c  d }^{D-1}(\bar{G} A G \bar{G})_{c  d }^D \right]\\
= & \mathbb{E} \left[\sum_{k} h_{c  k} (GA\bar GG)_{kd}(G A \bar{G} G)_{c  d }^{D-1}(\bar{G} A G \bar{G})_{c  d }^D\right] \\
& -\mathbb{E} \left[(A\bar{G} G)_{c  d }(G A \bar{G} G)_{c  d }^{D-1}(\bar{G} A G \bar{G})_{c  d }^D\right],
\end{aligned}
\end{equation}
where we used the identity $z G = HG -I$ in the last equality.

Let $\bm w_1,\ldots,\bm w_N$ be an orthonormal basis of $\R^N$, such that $\e_c^\trans A\bm w_1\leq 1$ and $\e_c^\trans A\bm w_i=0$ for $i=2,3,\cdots,N$.
We have the following high probability bound
\begin{align*}
\begin{split}
    \left|(A\bar GG)_{cd}\right|=\left| \sum_{i}\bm e_c^\trans A\bm w_i\bm w_i^\trans\bar GG\bm e_d\right|\leq(G\bar G)_{\bm w_1d}\prec N\Psi^2,
\end{split}
\end{align*}
where we used \eqref{eqn:2-resolvents} and \eqref{eqn:psi-bound} in the last step.

Using Young's inequality with powers $p=2D$ and $q=(2D)/(2D-1)$, the last line in \eqref{eqn:multi-resolvent-moment} can be bounded by
\begin{equation}\label{eqn:4th}
\left|\mathbb{E}\left[(A\bar{G} G)_{c d}(G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^D\right]\right| \leqslant N^{2 D \varepsilon} (N\Psi^2)^{2D}+N^{-\frac{2 D \varepsilon}{2 D-1}} \mathbb{E}\left[\left|(G A \bar{G} G)_{c d}\right|^{2 D}\right],
\end{equation}
for any small $\epsilon>0$.

Applying Lemma \ref{lem:cumulant-expansion} to the third line in \eqref{eqn:multi-resolvent-moment}, with $T=12D$, we have 
\begin{equation}\label{eqn:cumulant-expansion}
\begin{aligned}
& \mathbb{E} \left[\sum_k h_{c k}(G A \bar{G} G)_{k d}(G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^D\right] \\
= & \sum_{r=1}^{12D} \frac{1}{r ! N^{(r+1) / 2}} \sum_k \kappa_{r+1}^{c,k}\mathbb{E}\left[\partial_{c k}^r(G A \bar{G} G)_{k d}(G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^D\right]+\Omega,
\end{aligned}
\end{equation}
where $\kappa_{r}^{c,k}$ is the $r$-th cumulant of $\sqrt Nh_{ck}$ and $\Omega$ denotes the error term in \eqref{eqn:cumulant-theorem}.


We split the sum in \eqref{eqn:cumulant-expansion} into two cases and handle the error term $\Omega$ at the end.
\begin{enumerate}
\item When $r=1$, the summand is
\begin{align}\label{eqn:r=1}
\begin{split}
    \sum_{k}\frac{1+\delta_{ck}}{N}\mathbb{E}\left[\partial_{c k}(G A \bar{G} G)_{k d}(G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^D\right].
\end{split}
\end{align}
Note that 
\begin{align*}
\begin{split}
    (1+\delta_{ck})\partial_{ck}G_{ij}=-G_{ic}G_{kj}-G_{ik}G_{cj}.
\end{split}
\end{align*}
We have
\begin{align}\label{eqn:integration-by-parts}
\begin{split}
    &(1+\delta_{ck})\partial_{ck}\left[(GA\bar GG)_{kd}\left(GA\bar GG\right)_{cd}^{D-1}\left(\bar GAG\bar G\right)_{cd}^{D}\right]\\
    =&-[G_{kk}(GA\bar GG)_{cd}+G_{kc}(GA\bar GG)_{kd}+(GA\bar G)_{kc}(\bar GG)_{kd}+(GA\bar G)_{kk}(\bar GG)_{cd}\\
    &\qquad+(GA\bar GG)_{kc}G_{kd}+(GA\bar GG)_{kk}G_{cd}]\cdot\left(GA\bar GG\right)_{cd}^{D-1}\left(\bar GAG\bar G\right)_{cd}^{D}\\
    &-(D-1)\cdot[G_{cc}(GA\bar GG)_{kd}+G_{ck}(GA\bar GG)_{cd}+\left(GA\bar G\right)_{cc}\left(\bar GG\right)_{kd}+\left(GA\bar G\right)_{ck}\left(\bar GG\right)_{cd}\\
    &\qquad+\left(GA\bar GG\right)_{cc}G_{kd}+\left(GA\bar GG\right)_{ck}G_{cd}]\cdot\left(GA\bar GG\right)_{kd}\left(GA\bar GG\right)_{cd}^{D-2}\left(\bar GAG\bar G\right)_{cd}^{D}\\
    &-D\cdot[\bar G_{cc}\left(\bar GAG\bar G\right)_{kd}+\bar G_{ck}\left(\bar GAG\bar G\right)_{cd}+\left(\bar GAG\right)_{cc}\left(G\bar G\right)_{kd}+\left(\bar GAG\right)_{ck}\left(G\bar G\right)_{cd}\\
    &\qquad+\left(\bar GAG\bar G\right)_{cc}\bar G_{kd}+\left(\bar GAG\bar G\right)_{ck}\bar G_{cd}]\cdot(GA\bar GG)_{kd}\left(GA\bar GG\right)_{cd}^{D-1}\left(\bar GAG\bar G\right)_{cd}^{D-1}.
\end{split}
\end{align}
Inserting \eqref{eqn:integration-by-parts} into \eqref{eqn:r=1}, we have 
\begin{equation}\label{eqn:r=1organized}
\begin{aligned}
&\sum_{k}\frac{1+\delta_{ck}}{N}\partial_{ck} (GA\bar GG)_{kd}(G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^D \\
= & -m\left|(G A \bar{G} G)_{c d}\right|^{2 D} -\left(\sum_{i=1}^5 \alpha_i\right)(G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^D \\
& -(D-1)\left(\sum_{i=1}^6 \beta_i\right)(G A \bar{G} G)_{c d}^{D-2}(\bar{G} A G \bar{G})_{c d}^D  -D\left(\sum_{i=1}^6 \bar{\beta}_i\right)(G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^{D-1},
\end{aligned}
\end{equation}
where 
\begin{equation*}
\begin{gathered}
\alpha_1=\frac{1}{N}(G G A \bar{G} G)_{c d}, \quad\alpha_2=\frac{1}{N}(\bar{G} A G \bar{G} G)_{c d}, \quad\alpha_3=\frac{1}{N}(G \bar{G} A G G)_{c d}, \\
\alpha_4=\frac{1}{N} \operatorname{Tr}(G A \bar{G})(G \bar{G})_{c d}, \quad\alpha_5=\frac{1}{N} G_{c d} \operatorname{Tr}(G A \bar{G} G), \\
\beta_1=\frac{1}{N} G_{c c}(G \bar{G} A G G A \bar{G} G)_{d d}, \quad\beta_2=\frac{1}{N}(G A \bar{G} G)_{c d}(G G A \bar{G} G)_{c d}, \\
\beta_3=\frac{1}{N}(G A \bar{G})_{c c}(G \bar{G} G A \bar{G} G)_{d d}, \quad\beta_4=\frac{1}{N}(\bar{G} G)_{c d}(G A \bar{G} G A \bar{G} G)_{c d}, \\
\beta_5=\frac{1}{N}(G A \bar{G} G)_{c c}(G G A \bar{G} G)_{d d}, \quad\beta_6=\frac{1}{N} G_{c d}(G A \bar{G} G G A \bar{G} G)_{c d}.
\end{gathered}
\end{equation*}
% Recall the definition for $M$ in Section \ref{sec:multi-resolvent-local-law}.
% For our purpose, we pointed out two properties shared by $M$:
% \begin{enumerate}
% \item When $A$ is traceless,
% \begin{align}\label{eqn:traceless}
% \begin{split}
% M\left(z_1, A, z_2\right) & =A m_{\mathrm{sc}}\left(z_1\right) m_{\mathrm{sc}}\left(z_2\right);
% \end{split}
% \end{align}
% \item When $z_2\neq z_3$,
% \begin{align}\label{eqn:split}
% \begin{split}
%     M\left(z_1,B,z_2,I,z_3\right)=\frac{M\left(z_1,B,z_2\right)-M\left(z_1,B,z_3\right)}{z_2-z_3}.
% \end{split}
% \end{align}
% \end{enumerate}
% Also, it's useful to note that when the number of traceless matrices is odd, the isotropic fluctuation \eqref{eqn:iso} is larger than the size of centering \eqref{eqn:center-iso} and when the number of traceless matrices is even, the size of centering \eqref{eqn:center-iso} is larger than the isotropic fluctuation \eqref{eqn:iso}.

We used the fact that $G$ is symmetric, with $G_{ij} = G_{ji}$ for all $i,j \in \llbracket 1 , N \rrbracket$, in the above calculations. We now start to estimate $\alpha_i,\beta_i$. 
\begin{itemize}
\item By \eqref{eqn:center-iso} and \eqref{eqn:iso}, we have 
\begin{align*}
\begin{split}
    |\alpha_1|=\left|\frac{1}{N}(G G A \overline{G} G)_{cd}\right|\prec N^{-3/2}\eta^{-3}\leq N^{3/2}\Psi^3,
\end{split}
\end{align*}
where we used $1/(N\eta)\leq \Psi$ in the last inequality.
\item By \eqref{eqn:center-iso} and \eqref{eqn:iso}, we have
\begin{align*}
\begin{split}
    |\alpha_2|=\left|\frac{1}{N}(\overline{G} A G \overline{G} G)_{cd}\right|\prec N^{-3/2}\eta^{-3}\leq N^{3/2}\Psi^3.
\end{split}
\end{align*}
\item By the definition of $M$ in \eqref{Mdefinition}, we have
\begin{align*}
\begin{split}
    \Tr(M(z,A,\overline z)I)=\Tr(A|m_{\mathrm{sc}}(z)|^2)=0.
\end{split}
\end{align*}
Combining the previous equation with \eqref{eqn:avg}, we have
\begin{align*}
\begin{split}
    \left|\frac{1}{N}\Tr(GA\overline G)\right|\prec N^{-1}\eta^{-3/2}\leq N^{1/2}\Psi^{3/2}.
\end{split}
\end{align*}
Therefore
\begin{align*}
\begin{split}
    |\alpha_3|=\left|\frac{1}{N} \operatorname{Tr}(G A \overline{G})(G \overline{G})_{cd}\right|\prec N^{3/2}\Psi^{7/2},
\end{split}
\end{align*}
where we used $\left(G\overline G\right)_{cd}\prec N\Psi^2$ (from \eqref{eqn:2-resolvents}).
\item By the same arguments used to bound $\alpha_1$ and $\alpha_2$, we have
\begin{align*}
\begin{split}
    |\alpha_4|\prec N^{-3/2}\eta^{-3}\leq N^{3/2}\Psi^3.
\end{split}
\end{align*}
\item By definition of $M$ in \eqref{Mdefinition}, we have
\begin{align*}
\begin{split}
    \Tr(M(z,A,\overline z,I,z)I)&=\frac{1}{2\eta}\Tr(M(z,A,\overline z)I-M(z,A,z)I)\\
    &=\frac{1}{2\eta}\Tr(A|m_{\mathrm{sc}}(z)|^2-Am_{\mathrm{sc}}(z)^2)=0.
\end{split}
\end{align*}
Combining this equation with \eqref{eqn:avg}, we have
\begin{align*}
\begin{split}
    \left|\frac{1}{N}\Tr(GA\overline GG)\right|\prec N^{-1}\eta^{-5/2}\leq N^{3/2}\Psi^{5/2}.
\end{split}
\end{align*}
Therefore
\begin{align*}
\begin{split}
    |\alpha_5|=\left|\frac{1}{N} G_{cd} \operatorname{Tr}(G A \overline{G} G)\right|\prec N^{3/2}\Psi^{5/2}.
\end{split}
\end{align*}
\item For $\beta_1$, we cannot directly use \eqref{eqn:iso} since the operator norm of the deterministic part 
$$M(z,I,\overline z,A,z,I,z,A,\overline z,I,z)$$ 
is not small compared to its fluctuations. 

By \cite[Equation~(3.12)]{CipErdSch22optimal}, we have
\begin{align*}
\begin{split}
M(\bar z,A,z,I,z,A,\bar z,I,z)=\frac{1}{2\eta}\big(M(\bar z,A,z,I,z,A,\bar z)-M(\bar z,A,z,I,z,A, z)\big).
\end{split}
\end{align*}
By definition, we have
\begin{align*}
\begin{split}
&M(\bar z,A,z,I,z,A,\bar z)\\
=& \frac{1}{N} m_\circ[\bar z,z]m_\circ[z,\bar z]\Tr(A^2)I+A^2m_\circ[\bar z,z]m_\circ[z]m_\circ[\bar z]+A^2m_\circ^2[z]m_\circ^2[\bar z]\\
=&\frac{1}{N}\Tr(A^2)I \left(\m[\bar z,z]^2-2\m[z,\bar z]|\m(z)|^2+|\m(z)|^4\right)\\
&+A^2\m[\bar z,z]|\m(z)|^2,
\end{split}
\end{align*}
and similarly,
\begin{align*}
\begin{split}
&M(\bar z,A,z,I,z,A,z)\\
=&\frac{1}{N}m_\circ[\bar z,z]m_\circ[z,z]\Tr (A^2)I +A^2m_\circ[\bar z,z]m^2_\circ[z]+A^2m_\circ^3[z]m_\circ[\bar z]\\
=&\frac{1}{N}\Tr (A^2)I \left(\m[\bar z,z]\m[z,z]-\m[z,\bar z]\m^2(z)-\m[z,z]|\m(z)|^2 +\m^3(z)\m(\bar z)\right)\\
&+A^2\m[\bar z,z]\m(z)^2.
\end{split}
\end{align*}
By \cite[Equation (A.1)]{CipErdSch22optimal}, there exists a constant $C>0$ such that 
\begin{equation*}
\big|\m(z)\big| \le C, \quad \big|\m[\bar z,z]\big| \le C\eta^{-1}, \quad \big|\m[z,\bar z]\big|\le C\eta^{-1}, \quad \big| \m[z,z]\big| \le C\eta^{-1}.
\end{equation*}
%which is of order $\eta^{-2}$, are $(\Tr A^2) I$, and the remaining terms are of order at most $\eta^{-1}$. 
Since $\Tr( A^2) I$ is diagonal, the off-diagonal entries of $\overline GAGGA\overline GG$ are bounded by $N^{-1/2}\eta^{-7/2}\leq N^{3}\Psi^{7/2}$ with high probability by \eqref{eqn:iso}. Therefore, by the local law \eqref{isotropic} and \eqref{eqn:psi-bound-specified}, we have
\begin{align*}
\begin{split}
    \left|\left(G\overline GAGGA\overline GG\right)_{dd}\right|\leq \sum_{k=1}^N\left|G_{dk}\right|\left|\left(\overline GAGGA\overline GG\right)\right|_{kd}\prec N^{4}\Psi^{9/2}.
\end{split}
\end{align*}
Thus we have 
\begin{align*}
\begin{split}
    |\beta_1|=\left|\frac{1}{N} G_{cc}(G \bar{G} A G G A \bar{G} G)_{dd}\right|\prec N^{3}\Psi^{9/2}.
\end{split}
\end{align*}
\item By \eqref{eqn:center-iso} and \eqref{eqn:iso}, we have
\begin{align*}
\begin{split}
    |\beta_2|=\left|\frac{1}{N}(G A \bar{G} G)_{cd}(G G A \bar{G} G)_{cd}\right|\prec \frac{1}{N}(N^{-1/2}\eta^{-2})(N^{-1/2}\eta^{-3})\leq N^{3}\Psi^{5}.
\end{split}
\end{align*}
\item By \eqref{eqn:center-iso} and \eqref{eqn:iso}, we have
\begin{align*}
\begin{split}
    |\beta_3|=\left|\frac{1}{N}(G A \bar{G})_{cc}(G \bar{G} G A \bar{G} G)_{dd}\right|\prec \frac{1}{N}(N^{-1/2}\eta^{-1})(N^{-1/2}\eta^{-4})\leq N^{3}\Psi^{5}.
\end{split}
\end{align*}
\item By \eqref{eqn:center-iso}, \eqref{eqn:iso} and \eqref{eqn:psi-bound-specified}, we have
\begin{align*}
\begin{split}
    |\beta_4|=\left|\frac{1}{N}(\bar{G} G)_{cd}(G A \bar{G} G \bar{G} A G)_{cd}\right|\prec\frac{1}{N}(N\Psi^2)(\eta^{-3})\leq N^{3}\Psi^{5}.
\end{split}
\end{align*}
\item By the same argument that is used to bound $\beta_2$, we have
\begin{align*}
\begin{split}
    |\beta_5|=\left|\frac{1}{N}(G A \bar{G} G)_{cc}(G G A \bar{G} G)_{dd}\right|\prec N^{3}\Psi^{5}.
\end{split}
\end{align*}
\item By the same argument that is used to bound $\beta_1$, we have
\begin{align*}
\begin{split}
    |\beta_6|=\left|\frac{1}{N} G_{cd}(G A \bar{G} G G A \bar{G} G)_{cd}\right|\prec N^{3}\Psi^{9/2}.
\end{split}
\end{align*}
\end{itemize}
% From \eqref{eqn:r=1original} and using Young's inequality, we have, for arbibrary $\epsilon>0$,
% \begin{equation}\label{}
% \begin{aligned}
% \mathbb{E}(z+m)\left|(G A \bar{G} G)_{a b}\right|^{2 D} \leqslant & \sum_{i=1}^5\left|\alpha_i\right| \mathbb{E}\left|(G A \bar{G} G)_{a b}\right|^{2 D-1}+2D \sum_{i=1}^6\left|\beta_i\right| \mathbb{E}\left|(G A \bar{G} G)_{a b}\right|^{2 D-2} \\
% & +N^{2 D \varepsilon}\left(N \Psi^2\right)^{2 D}+N^{-\frac{2 D \varepsilon}{2 D-1}} \mathbb{E}\left|(G A \bar{G} G)_{a b}\right|^{2 D} \\
% \leqslant & \sum_{i=1}^5 N^{2 D \varepsilon}\left|\alpha_i\right|^{2 D}+2D \sum_{i=1}^6 N^{D \varepsilon}\left|\beta_i\right|^D+N^{2 D \varepsilon}\left(N \Psi^2\right)^{2 D} \\
% & +\left( 6N^{-\frac{2 D \varepsilon}{2 D-1}}+ 12N^{-\frac{D \varepsilon}{D-1}}\right) \mathbb{E}\left|(G A \bar{G} G)_{a b}\right|^{2 D}
% \end{aligned}
% \end{equation}
% Note that 
% \begin{align}
% \begin{split}
%     |z+m-1/m_{\operatorname{sc}}|\leq\left|z+m_{\operatorname{sc}}-1/m_{\operatorname{sc}}\right|+|m-m_{\operatorname{sc}}|\prec\Psi,
% \end{split}
% \end{align}
% we have $z+m$ is bounded away from $0$ with high probability. Moreover, since 
let $\epsilon>0$ be a parameter. In \eqref{eqn:r=1organized}, we use Young's inequality twice in the second inequality, with powers $p=2D$ and $q=(2D)/(2D-1)$ for terms containing $\alpha_i$'s and powers $p=D$ and $q=D/(D-1)$ for terms containing $\beta_i$'s, to show that 
\begin{equation}\label{eqn:r=1final}
\begin{aligned}
&\left|\E\left[m |(GA\bar GG)_{cd}|^{2D}+\sum_k \frac{1+\delta_{c k}}{N} \partial_{c k}(G A \bar{G} G)_{k d}(G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^D\right]\right|\\
\leqslant & \sum_{i=1}^5 \mathbb{E}\left[\left|\alpha_i\right|\left|(G A \bar{G} G)_{c d}\right|^{2 D-1}\right]+2 \sum_{i=1}^6 \mathbb{E}\left[\left|\beta_i\right|\left|(G A \bar{G} G)_{c d}\right|^{2 D-2}\right] \\
% +N^{2 D \varepsilon}\left(N \Psi^2\right)^{2 D}\\
% &+N^{-\frac{2 D \varepsilon}{2 D-1}} \mathbb{E}\left[\left|(G A \bar{G} G)_{c d}\right|^{2 D}\right] \\
\leqslant & \sum_{i=1}^5 N^{2 D \varepsilon}\E\left[\left|\alpha_i\right|^{2 D}\right]+2 \sum_{i=1}^6 N^{D \varepsilon}\E\left[\left|\beta_i\right|^D\right]+\left(5 N^{-\frac{2 D \varepsilon}{2 D-1}}+12 N^{-\frac{D \varepsilon}{D-1}}\right) \mathbb{E}\left[\left|(G A \bar{G} G)_{c d}\right|^{2 D}\right]\\
\prec &\, 20N^{2D\epsilon}N^{3D}\Psi^{9D/2}+20N^{-\frac{2D\epsilon}{2D-1}}\mathbb{E}\left[\left|(G A \bar{G} G)_{c d}\right|^{2 D}\right].
\end{aligned}
\end{equation}
\item Now we fix $r\geq 2$ in the cumulant expansion. In this case, we use the following relaxation of \eqref{eqn:center-iso} and \eqref{eqn:iso}. Since it is a direct consequence of these inequalities, we omit the proof.
\begin{corollary}[``Coarser'' isotropic local law]\label{thm:coarse}
Fix $k \in \mathbb{N}$,  and $z_1, \ldots, z_{k+1} \in \bm S$. Let $A_1, \ldots, A_k$ be deterministic matrices such that $\left\|A_j\right\| \le 1$, and $m$ of them satisfy  $\Tr A_j =0$ for some $0 \leqslant m \leqslant k$. %Let $\eta:=\min _j\left|\Im z_j\right|$ and $d:=\min _j \operatorname{dist}\left(z_j,[-2,2]\right)$
Suppose that 
$\min _j \operatorname{dist}\left(z_j,[-2,2]\right) \leqslant 1$.
Then for arbitrary deterministic vectors $\boldsymbol{x}, \boldsymbol{y}$ such that  $\|\boldsymbol{x}\|+\|\boldsymbol{y}\| \le 2$, we have %the optimal 
%isotropic local law
\begin{equation}\label{eqn:coarse}
\left|\left\langle\boldsymbol{x},\left(G_1 A_1 \cdots G_k A_k G_{k+1}\right) \boldsymbol{y}\right\rangle\right| \prec N^{k-\frac{m}{2}}
\end{equation}
with $G_j:=G\left(z_j\right)$.
\end{corollary}
We call a term of the form $\left(G_1 B_1 \cdots G_{s+1}\right)_{i j}$ a block. The effect of one differentiation operator $\partial_{a k}$ on a product of blocks is to increase the number of blocks and the number of $G$ 's by exactly one each, while keeping the number of $A$ unchanged. And from \eqref{eqn:coarse}, we know the effect of each traceless matrix $A$ is a contribution of a factor of $N^{-1 / 2}$.

\begin{itemize}
\item Suppose $r<2D-1$. Note that when using the product rule, $\partial_{ck}^r$ can at most operate on $r$ different blocks, there are at least $2D-r-1$ blocks of $(GA\bar GG)_{cd}$ or $(\bar GAG\bar G)_{cd}$ which are unaffected. In view of this, we have
\begin{align}\label{eqn:partial-bound-1}
\begin{split}
    &\left|\partial_{ck}^r\left[\left(GA\bar GG\right)_{kd} (G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^D\right]\right|\\
    \leq&\,\sum_{\substack{r_1+r_2=r\\r_1\leq D-1\\r_2\leq D}}\binom{D}{r_1}\binom{D-1}{r_2}\left|\partial_{ck}^r\left[\left(GA\bar GG\right)_{kd} (G A \bar{G} G)_{c d}^{r_1}(\bar{G} A G \bar{G})_{c d}^{r_2}\right]\right|\left|\left(GA\bar GG\right)_{cd}\right|^{2D-1-r}\\
    \leq &\,D^r\sum_{\substack{r_1+r_2=r\\r_1\leq D-1\\r_2\leq D}}\left|\partial_{ck}^r\left[\left(GA\bar GG\right)_{kd} (G A \bar{G} G)_{c d}^{r_1}(\bar{G} A G \bar{G})_{c d}^{r_2}\right]\right|\cdot\left|\left(GA\bar GG\right)_{cd}\right|^{2D-1-r}.
\end{split}
\end{align}
There are $1+r$ blocks, $3(r+1)$ $G$'s, and $1+r$ $A$'s in
\begin{align*}
 \begin{split}
     \left(GA\bar GG\right)_{kd} (G A \bar{G} G)_{c d}^{r_1}(\bar{G} A G \bar{G})_{c d}^{r_2}.
 \end{split}
 \end{align*}
and after the operation of $\partial_{ck}^r$, there are $2r+1$ blocks, $4r+3$ $G$'s and $1+r$ $A$'s. By Corollary \ref{thm:coarse}, we know
\begin{align}\label{eqn:partial-bound-2}
\begin{split}
    \left|\partial_{ck}^r\left(GA\bar GG\right)_{kd} (G A \bar{G} G)_{c d}^{r_1}(\bar{G} A G \bar{G})_{c d}^{r_2}\right|\prec N^{(4r+2)-(2r)-\frac{1+r}{2}}=N^{3(r+1)/2}.
\end{split}
\end{align}
Combining \eqref{eqn:partial-bound-1} and \eqref{eqn:partial-bound-2}, we deduce that a summand in \eqref{eqn:cumulant-expansion} with $2\leq r<2D-1$ can be bounded by
\begin{align}\label{eqn:r>1final1}
\begin{split}
    &\left|\frac{\kappa_{r+1}}{r ! N^{(r+1) / 2}} \sum_k \mathbb{E}\left[\partial_{c k}^r(G A \bar{G} G)_{k d}(G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^D\right]\right|\\
    \prec &\,D^{r+1}N^{r+2}\E\left[\left|\left(GA\bar GG\right)_{cd}\right|^{2D-1-r}\right]\\
    \leq &\, D^{r+1}N^{\frac{2D\epsilon}{r+1}+\frac{2D(r+2)}{r+1}}+D^{r+1}N^{-\frac{2D\epsilon}{2D-r-1}}\E\left[\left|\left(GA\bar GG\right)_{cd}\right|^{2D}\right],
\end{split}
\end{align}
for any small $\epsilon>0$, where we used Young's inequality in the last step.
\item Suppose $r\geq 2D-1$. There are initially $2D$ blocks, $6D$ $G$'s and $2D$ $A$'s in
\begin{align*}
\begin{split}
    (G A \bar{G} G)_{k d}(G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^D,
\end{split}
\end{align*}
and after the operation of $\partial_{ck}^r$, there are $2D+r$ blocks, $6D+r$ $G$'s and $2D$ $A$'s. Then by Corollary \ref{thm:coarse}, we have
\begin{align}\label{eqn:partial-bound-3}
\begin{split}
    \left|\partial_{ck}^r(G A \bar{G} G)_{k d}(G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^D\right|\prec N^{3D}.
\end{split}
\end{align}
Therefore, a summand in \eqref{eqn:cumulant-expansion} with $r\geq 2D-1$ can be bounded by
\begin{align}\label{eqn:r>1final2}
\begin{split}
    \left|\frac{\kappa_{r+1}}{r ! N^{(r+1) / 2}} \sum_k \mathbb{E}\left[\partial_{c k}^r(G A \bar{G} G)_{k d}(G A \bar{G} G)_{c d}^{D-1}(\bar{G} A G \bar{G})_{c d}^D\right]\right| &\prec C(D)N^{3D-\frac{r+1}{2}+1}\\&\leq C(D)N^{D+1}.
\end{split}
\end{align}
\end{itemize}
\item Finally, we consider the error term $\Omega$ in \eqref{eqn:cumulant-expansion}. 
Define $H_t^{(k)}$ by 
\begin{align*}
    \left(H_t^{(k)}\right)_{ij}=\begin{cases}
        t,&\text{ if }i=c,j=k,\\
        h_{ij},&\text{ otherwise.}
    \end{cases}
\end{align*}
By Lemma \ref{lem:cumulant-expansion}, 
\begin{equation}\label{eqn:error-term}
    \Omega\leq C_{12D}\sum_k\E\left[|h_{ck}|^{12D+2} \right] \E\left[\left|\partial_{ck}^{12D+1}(G_t^{(k)}A\bar G_t^{(k)}G_t^{(k)})_{kd}(G_t^{(k)}A\bar G_t^{(k)}G_t^{(k)})_{cd}^{D-1}(\bar G_t^{(k)}AG_t^{(k)}\bar G_t^{(k)})_{cd}^D \right|\right],
\end{equation}
where $G_t^{(k)}$ is the resolvent of $H_t^{(k)}$.

Originally, \eqref{eqn:error-term} has $2D$ blocks and $6D$ $G$'s, after taking $(12D+1)$-th derivatives, there are $14D+1$ blocks and $18D+1$ $G$'s. Using the moment assumption \eqref{finite-moment} and the trivial bound $\|G_t^{(k)}\|\leq \eta^{-1}\leq N$ from \eqref{eqn:absolute-bound-G}, we have
\begin{equation}\label{eqn:error-bound}
    \Omega\leq C(D)NN^{-6D-1}N^{(18D+1)-(14D+1)}=C(D)N^{-2D}.
\end{equation}
\end{enumerate}
Combining \eqref{eqn:multi-resolvent-moment}, \eqref{eqn:4th}, \eqref{eqn:cumulant-expansion}, \eqref{eqn:r=1final}, \eqref{eqn:r>1final1}, \eqref{eqn:r>1final2} and \eqref{eqn:error-bound}, we have
\begin{align*}
\begin{split}
&\left|\E\left[(z+m)|(GA\bar GG)_{cd}|^{2D}\right]\right|\\
\prec &\, C(D)N^{2D\epsilon}N^{3D}\Psi^{9D/2}+C(D)N^{-\frac{2D\epsilon}{2D-1}}\mathbb{E}\left[\left|(G A \bar{G} G)_{c d}\right|^{2 D}\right].
\end{split}
\end{align*}
Using the local law $|m-\m|\prec\Psi$ \cite[Theorem 2.6]{benaych2016lectures}, we have
\begin{equation*}
\begin{aligned}
    &(z+\m) \left|\E\left[|(GA\bar GG)_{cd}|^{2D}\right]\right|\\
\prec &\, C(D)N^{2D\epsilon}N^{3D}\Psi^{9D/2}+C(D)N^{-\frac{2D\epsilon}{2D-1}}\mathbb{E}\left[\left|(G A \bar{G} G)_{c d}\right|^{2 D}\right]+\Psi\cdot \E\left[|(GA\bar GG)_{cd}|^{2D}\right]
\end{aligned}
\end{equation*}
Since $z+\m=1/\m$ (recall \eqref{definingequation}), which is bounded away from $0$ (by \cite[Equation (3.2)]{benaych2016lectures}), and $\epsilon>0$ is arbitrary, we have
\begin{align*}
\begin{split}
\mathbb{E}\left[\left|(G A \bar{G} G)_{c d}\right|^{2 D}\right]\prec N^{3D}\Psi^{9D/2}.
\end{split}
\end{align*}
Since $D>1$ is arbitrary, we have
\begin{align*}
\begin{split}
|(GA\bar GG)_{cd}|\prec  N^{3/2}\Psi^{9/4}.
\end{split}
\end{align*}
This completes the proof of \eqref{eqn:3-resolvents-traceless}.
\end{proof}
%\newpage
% \orange{
% There are some further modifications needed to be done:
%     \begin{enumerate}
%         \item Explicit constant or implicit constant.
%         \item Where to define $\delta_i$'s.
%     % \item When taking expectation with respect to terms bounded in high probability (i.e. notation $\prec$), need to argue that those terms also have uniform bound $N^C$ for some constant $C$.
%     % \item Notation-wise: check if there is any notation conflicts
%     %\item Replace the bracket $\langle \cdot\rangle$ notation by Trace notation.
%     % \item Need to mention the connection between parity domination conditions (i.e. graded polynomials) and the stochastic domination condition (one can argue that the former implies the latter by large deviation inequality)
%     % \item Remark the arithmetic rule satisfied by parity notations
%     % \item Point out exactly where each local law is used (essentially in Section \ref{sec:poly})
%     % \item State the range of spectral parameter $z$ for all high probability bound. We should define the usually used spectral parameter set $\bm S$ also.
%     % \item Remark why one can replace $G$ by $R,R^{(a)}$ in all local laws. Use some perturbation argument.
%     % \item Need a stochastic continuation argument to extend pointwise stochastic domination to uniform stochastic domination.
%     %\item Add comments at the beginning of Section 3 on the choice of $\ell$ and $\tau>0$.
%     % \item Add a short explanation of controlling the lower order terms in the resolvent expansion in Lemma \ref{lem:resolvent-expansion}.
%     % \item Check if $\delta>0$ can be replaced by $N^{-c}$ for a small enough constant $c>0$.
%     % \item Add $t$-dependency for the error term in cumulant expansion \eqref{eqn:error-term}.
%     % \item Remove all $\omega$ and change them to $\tau/10$ in the paper.
%     \end{enumerate}
% }




















































%\newpage

\bibliographystyle{amsplain}
\bibliography{que_draft.bib}


\end{document}
























