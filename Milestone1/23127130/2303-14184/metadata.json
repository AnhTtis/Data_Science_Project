{
    "arxiv_id": "2303.14184",
    "paper_title": "Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior",
    "authors": [
        "Junshu Tang",
        "Tengfei Wang",
        "Bo Zhang",
        "Ting Zhang",
        "Ran Yi",
        "Lizhuang Ma",
        "Dong Chen"
    ],
    "submission_date": "2023-03-24",
    "revised_dates": [
        "2023-03-27"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "In this work, we investigate the problem of creating high-fidelity 3D content from only a single image. This is inherently challenging: it essentially involves estimating the underlying 3D geometry while simultaneously hallucinating unseen textures. To address this challenge, we leverage prior knowledge from a well-trained 2D diffusion model to act as 3D-aware supervision for 3D creation. Our approach, Make-It-3D, employs a two-stage optimization pipeline: the first stage optimizes a neural radiance field by incorporating constraints from the reference image at the frontal view and diffusion prior at novel views; the second stage transforms the coarse model into textured point clouds and further elevates the realism with diffusion prior while leveraging the high-quality textures from the reference image. Extensive experiments demonstrate that our method outperforms prior works by a large margin, resulting in faithful reconstructions and impressive visual quality. Our method presents the first attempt to achieve high-quality 3D creation from a single image for general objects and enables various applications such as text-to-3D creation and texture editing.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.14184v1"
    ],
    "publication_venue": "Project page: https://make-it-3d.github.io/"
}