{
    "arxiv_id": "2303.08577",
    "paper_title": "Investigating GANsformer: A Replication Study of a State-of-the-Art Image Generation Model",
    "authors": [
        "Giorgia Adorni",
        "Felix Boelter",
        "Stefano Carlo Lambertenghi"
    ],
    "submission_date": "2023-03-15",
    "revised_dates": [
        "2023-03-16"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.LG"
    ],
    "abstract": "The field of image generation through generative modelling is abundantly discussed nowadays. It can be used for various applications, such as up-scaling existing images, creating non-existing objects, such as interior design scenes, products or even human faces, and achieving transfer-learning processes. In this context, Generative Adversarial Networks (GANs) are a class of widely studied machine learning frameworks first appearing in the paper \"Generative adversarial nets\" by Goodfellow et al. that achieve the goal above. In our work, we reproduce and evaluate a novel variation of the original GAN network, the GANformer, proposed in \"Generative Adversarial Transformers\" by Hudson and Zitnick. This project aimed to recreate the methods presented in this paper to reproduce the original results and comment on the authors' claims. Due to resources and time limitations, we had to constrain the network's training times, dataset types, and sizes. Our research successfully recreated both variations of the proposed GANformer model and found differences between the authors' and our results. Moreover, discrepancies between the publication methodology and the one implemented, made available in the code, allowed us to study two undisclosed variations of the presented procedures.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.08577v1"
    ],
    "publication_venue": null
}