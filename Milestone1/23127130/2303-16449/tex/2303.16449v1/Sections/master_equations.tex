\section{Density operator master equations}
\label{s:doma}

Density operator master equations are a powerful tool to study the dynamics of quantum systems that interact weakly with their surrounding environment. Originally developed in the field of quantum optics to study light-matter interactions~\cite{Carmichael1999}, they are used to simulate a variety of quantum mechanical phenomena, such as noise models for quantum information processing~\cite{Nielsen2010}, transient emission and absorption spectra of optically active materials~\cite{Buchheit2016}, and electronic and nuclear spin resonance experiments~\cite{Goldfarb2018}.

The power of master equations resides in the choice of ignoring the environment's dynamics, often uncontrollable and inaccessible. By neglecting the environment's degrees of freedom, we can limit the scaling of the computational requirements to a polynomial of $d = \mathrm{dim}\mathcal{H}_\mathrm{S}$, where $\mathcal{H}_\mathrm{S}$ is the system's Hilbert space. In this section we introduce quantum master equations and focus on their numerical implementation and solution, providing direction for further readings. 

\subsection{Introduction to Lindblad master equation}
The paradigmatic example of a density operator master equation is the Gorini-Kossakowski-Sudarshan-Lindblad (GKSL) master equation~\cite{Milz2017}, often known as the \textit{Lindblad} master equation,
\begin{eqbox}
    \begin{equation}
        \label{eq:lindblad_master_equation}
        	\dot{{\rho}}(t) = -\frac{i}{\hbar}[H, {\rho(t)}] + \sum_{k}\gamma_k\bigg(L^\phdagger_k{\rho(t)}L_k^\dagger -\frac{1}{2}\Big\{ L_k^\dagger L_k^\phdagger, {\rho(t)} \Big\}\bigg),
    \end{equation}
\end{eqbox}
\noindent
where $\rho$ is the system's density operator\footnote{From now on we will drop the subscript $\mathrm{S}$ from the system's density operator, unless specified otherwise.}, $H$ is the system Hamiltonian, and $\{L_k\}$ are the \textit{Lindblad} operators\footnote{Also known as \textit{collapse} operators or \textit{jump} operators.} representing some non-unitary processes like relaxation or decoherence that occur at some rates $\{\gamma_k\}$. The operators $[.,.]$ and $\lbrace.,.\rbrace$ denote the commutator and anti-commutator of the operands. Note that, from now on $H$ will represent the system's Hamiltonian, unless specified otherwise.

Like the Hamiltonian generates coherent dynamics, the Lindblad operators\footnote{Formally, the Lindblad operators are dimensionless linear combinations of the basis operators in Liouville space~\cite{Breuer2002}, and therefore the index $k$ in the sum of Eq.~\eqref{eq:lindblad_master_equation} can be limited to $d^2-1$.} generate incoherent transitions in the space of states. Unlike the Hamiltonian, they do not need to be hermitian. For example, a decay transition from some excited state $\ket{e}$ to some ground state $\ket{g}$ is mediated by the Lindblad operator
\begin{equation}
    \label{eq:lindblad_op_example}
    L_\downarrow = \ketbra{g}{e}.
\end{equation}
Indeed, when we apply $L_\downarrow$ to $\ket{e}$ we obtain $\ket{g} = L_\downarrow\ket{e}$. Note that $L_\downarrow^\dagger = \ketbra{e}{g} \neq L_\downarrow$.

Eq.~\eqref{eq:lindblad_master_equation} is used to approximate the evolution of the density operator of a system $\mathrm{S}$ with Hamiltonian $H$ that is weakly coupled to a Markovian (memory-less) environment~\cite{Breuer2002}. The Lindblad master equation is the general form for a completely positive and trace-preserving (CPTP) Markovian and time-homogeneous map for the evolution of the system's density operator $\rho$~\cite{Breuer2002}. More on the motivation for the requirements of CPTP and Markovianity can be found in Refs.~\cite{Breuer2002,Milz2017}. Derivations of Eq.~\eqref{eq:lindblad_master_equation} can be found in Refs.~\cite{Breuer2002,Lidar2019,Manzano2020}. 

\subsection{The Liouville superoperator}
\label{ss:superoperator}

When solving Eq.~\eqref{eq:lindblad_master_equation}, it is convenient to express the master equation in a vector notation, 
\begin{equation}
\label{eq:superop_form}
\dot{\bm{\rho}} = \mathcal{L} \bm{\rho},
\end{equation}
known as \textit{superoperator} or \textit{Liouville} form, 
where $\bm{\rho} = \mathrm{vec}({\rho})$ is the \textit{vectorised} form of ${\rho}$, and $\mathcal{L}$ is the superoperator associated with the generator $\dot{\rho}$ of Eq.~\eqref{eq:lindblad_master_equation}. The matrix associated with the density operator ${\rho}$ can be reshaped into a vector in many equivalent ways\footnote{Column and row ordering are common choices.} resulting in different superoperators. Any reshaping is valid, as long as one keeps track of the ordering in the elements of the superoperator. The following is a \texttt{python} script that illustrates a reshaping via the \texttt{numpy} method \texttt{reshape}:

% ----- code for density matrix reshaping -----
\code{https://github.com/frnq/qme/blob/main/python/vectorising_rho.py}{Vectorising a density matrix}{code:vectorising_rho}{python}{Scripts/python/vectorising_rho.txt}
\noindent 
Similar methods are available in \texttt{Mathematica} and \texttt{MATLAB}. A robust implementation of the reshaping is implemented in \texttt{QuTiP} with the methods \texttt{operator\_to\_vector} and \texttt{vector\_to\_operator}.

\subsubsection{Constructing the Liouville superoperator}
\label{sss:constructing_superoperator}
While the superoperator $\mathcal{L}$ can be constructed ``by hand'' for small systems, it is advisable to have a systematic approach to compile it from some Hamiltonian $H$ and some Lindblad operators $\{L_k\}$. Two common ways are to either follow an index prescription for the superoperator tensor $\rho_{ab} = \sum_{cd}\mathcal{L}_{abcd}\rho_{cd}$, or to use the following linear algebra identity for the column-ordered form of $\mathrm{vec}(\rho)$~\cite{Barnett1990, Byron2012}:
\begin{equation}
\label{eq:row_ordered_identity}
	\mathrm{vec}({A}{X}{B}) = ({B}^\mathrm{T}\otimes{A})\mathrm{vec}({X}).
\end{equation}
To take advantage of the latter, we proceed inserting the identity operator $\mathbb{1}$ into Eq.~\eqref{eq:lindblad_master_equation}
\begin{equation}
\label{eq:lindblad_with_idenity}
\mathbb{1}\dot{{\rho}}\mathbb{1} = -\frac{i}{\hbar}\Big(H{\rho}\mathbb{1} - \mathbb{1}{\rho}H\Big) + \sum_k\gamma_k\bigg(L_k^\phdagger{\rho}L_k^\dagger -\frac{1}{2}\Big(L_k^\dagger L_k^\phdagger{\rho}\mathbb{1} + \mathbb{1}{\rho}L_k^\dagger L_k^\phdagger\Big)\bigg),
\end{equation}
from which the superoperator can be easily constructed using the tensor product structure discussed in Sec.~\ref{ss:composite systems}, and implemented with the \texttt{kron} method in \texttt{python} and \texttt{MATLAB} or the  \texttt{KroneckerProduct} function in \texttt{Mathematica}. Combining Eqs.~\eqref{eq:superop_form},~\eqref{eq:row_ordered_identity} and~\eqref{eq:lindblad_with_idenity}
we obtain
\begin{equation}
\label{eq:liouville_ordered}
\mathcal{L} = -\frac{i}{\hbar}\Big(\mathbb{1} \otimes H - H^\mathrm{T}\otimes\mathbb{1}\Big) + \sum_k\gamma_k \bigg( L_k^*\otimes L_k^\phdagger - \frac{1}{2} \Big(\mathbb{1}\otimes L_k^\dagger L_k^\phdagger + L_k^\mathrm{T} L_k^*\otimes\mathbb{1}\Big)\bigg).
\end{equation}
As discussed in the next sections, the power and advantage of the superoperator form consists in offering a direct pathway to solving Eq.~\eqref{eq:lindblad_master_equation}, based on the solution of a system of linear ordinary differential equations. The following \texttt{python} script implements Eq.~\eqref{eq:liouville_ordered} using \texttt{numpy} arrays. It is worth noting that the rates $\gamma_k$ are here embedded into the Lindblad operators via $L_k \to L'_k = \sqrt{\gamma_k} L_k$ for a simpler implementation. 
% ----- code for superoperators -----
\code{https://github.com/frnq/qme/blob/main/python/superoperator.py}{Constructing the superoperator}{code:superoperator_python}{python}{Scripts/python/superoperator.txt}
\noindent 

\subsection{Steady-state solution}
\label{ss:staeady_state}

Before looking at the dynamics $\rho(t)$ of the density operator, let us go through some methods to obtain the steady-state solution of Eqs.~\eqref{eq:lindblad_master_equation} and~\eqref{eq:superop_form}.

\subsubsection{Using the null space of Liouville superoperator}
Once we have expressed a linear master equation in the superoperator form, we can use the matrix $\mathcal{L}$ to study the behaviour of the system. Of immediate interest is the steady state solution ($\dot{{\rho}} = 0$) which is often measured directly in experiments. To find any steady state solutions we solve for the \textit{null space} of $\mathcal{L}$~\cite{Axler1997}, which is the subspace of all vectors $\bm{\rho}$ that satisfy the equation
\begin{equation}
\label{eq:null_space_equation}
	\mathcal{L}\bm{\rho}=0.
\end{equation}
Numerically, this can be done using the \texttt{NullSpace} function in \texttt{Mathematica}, the \texttt{null} function in \texttt{MATLAB}, or the \texttt{null\_space} method in the \texttt{numpy} library \texttt{scipy}. An analytic solution can also be sought with this approach with \texttt{Mathematica}, or \texttt{SymPy} in \texttt{python}. If there is a unique solution, solving for the null space will provide the corresponding steady state density matrix vector $\bm{\rho}(\infty)$ up to a constant factor, the value of which is given by the original normalization condition $\text{Tr}({\rho})=1$.
 
If there are multiple solutions, solving for the null space will give linearly independent vectors. In such case, the steady state depends on the initial state of the system. For example, let us consider a two-level system Hamiltonian\footnote{In Sec.~\ref{ss:two_level_atom_with_field} we outline how to obtain (\ref{eq:tl_hamiltonian}) for a two-level atom interacting with an electric field. } $H$ with energy splitting $\Delta$ and coupling $\Omega$, and Lindblad operators $L_\downarrow$ and $L_0$ associated with spontaneous relaxation and dephasing, respectively,
\begin{equation}
\label{eq:tl_hamiltonian}
	{H} = \hbar\begin{pmatrix}
	0 & \Omega\\
	\Omega & \Delta
	\end{pmatrix}, \;\;\;\ L_\downarrow = \sqrt{\gamma_\downarrow} \begin{pmatrix}
    0 & 1\\
    0 & 0
    \end{pmatrix}, 
    \;\;\;\ L_0 = \sqrt{\gamma_0} \begin{pmatrix}
    1 & 0\\
    0 & 1
    \end{pmatrix},
\end{equation}
where $\gamma_\downarrow$ and $\gamma_0$ are the rates associated with relaxation and dephasing.
In the following script, we construct $\mathcal{L}$ in \texttt{python} and solve for its null space for the case of (i) relaxation and no-driving limit $\Omega,\gamma_0=0$, and (ii) dephasing and driving, with no relaxation, $\gamma_\downarrow = 0$.

\code{https://github.com/frnq/qme/blob/main/python/null_space.py}{Solving for the null space of superoperator {\normalfont\textsf{(requires script~\ref*{code:superoperator_python})}}}{code:null_space}{python}{Scripts/python/null_space.txt}
\noindent
In the limit of relaxation and no-driving, there is a unique steady state $\bm{\rho}(\infty) = \begin{pmatrix} 1,0,0,0 \end{pmatrix}^\textrm{T}$, which is the ground state of the system, as expected for a two-state system undergoing spontaneous relaxation with no driving field. Instead, for the case of dephasing and driving, the \texttt{null} function returns two vectors that span the two-dimensional linear subspace associated with the null space of $\mathcal{L}$. In this case, the specific steady state depends on the choice of initial state. See Sec.~\ref{a:examples} for a \texttt{MATLAB} implementation of the method used in script~\ref{code:null_space}.

\subsubsection{Algebraic solution}
The steady state solution ${\rho}(\infty)$ for both linear and non-linear\footnote{A non-linear generator is such that $\mathcal{L}(\rho)$ depends on the state of the system. See Ref.~\cite{Breuer2002} for more on non-linear density operator master equations.} generators can be obtained by solving Eq.~\eqref{eq:lindblad_master_equation} for $\dot{{\rho}} = 0$ algebraically (or symbolically). In \texttt{python}, this can be done using the \texttt{solve} method of the \texttt{SymPy} library, as demonstrated in the script below for the case of $\Omega=0, \gamma_0 = 0$, with respect to Eq.~\eqref{eq:tl_hamiltonian}.
% -------- code: symbolic solution for the null space --------
\code{https://github.com/frnq/qme/blob/main/python/symbolic_solution.py}{Symbolic steady-state solution}{code:symbolic_matrix_solving_python}{python}{Scripts/python/symbolic_solution.txt}

\noindent
Algebraic solutions can also be sought in \texttt{MATLAB} with \texttt{solve}, or in \texttt{Mathematica}, using the \texttt{Solve} method. These provide a more straightforward approach to solving symbolic matrix equations. A \texttt{MATLAB} implementation of script~\ref{code:symbolic_matrix_solving_python} can be found in the Appendix in script~\ref{code:symbolic_matrix_solving}. 

\subsection{Solving the dynamics of the system}
\label{ss:solving_dynamics}

Let us now discuss how to solve Eq.~\eqref{eq:lindblad_master_equation} in order to obtain the state of the system $\rho(t)$ at any time $t$ from a given initial condition $\rho_0 = \rho(t_0)$. Let us represent the solution with the dynamical map $\rho(t) = \Lambda(t;t_0)[\rho_0]$. For linear, time-independent generators $\mathcal{L}$, the solution to Eq.~\eqref{eq:superop_form} can be obtained by calculating the following matrix exponential~\cite{Breuer2002},
\begin{equation}
    \label{eq:matrix_exp_superoperator}
    \bm{\rho}(t) = \exp\big[\mathcal{L} (t-t_0)\big]\bm{\rho}(t_0).
\end{equation}
The operator $P(t;t_0) = \exp\big[\mathcal{L} (t-t_0)\big]$ is called the propagator of the evolution. From the propagator, we can obtain the solution $\rho(t)$ by reshaping $\bm{\rho}(t)$ as described earlier in this section. See Ref.~\cite{Lidar2019} for details on how to obtain the dynamical map $\Lambda$ from $P$ using, for example, a Kraus operators representation. Eq.~\eqref{eq:matrix_exp_superoperator} is implemented in \texttt{python} using \texttt{scipy} in the following script, with the result shown in Fig.~\ref{fig:super_matrix_exp}.
% ------- code: super matrix exponential  --------
\code{https://github.com/frnq/qme/blob/main/python/super_matrix_exp.py}{Propagator using matrix exponential {\normalfont\textsf{(requires script~\ref*{code:superoperator_python})}} }{code:super_matrix_exp}{python}{Scripts/python/super_matrix_exp.txt}
\noindent
See script~\ref{code:solution_matlab_ode} for an implementation of Eq.~\eqref{eq:matrix_exp_superoperator} using \texttt{MATLAB}.
\begin{figure}
    \centering
    \includegraphics{Figures/propagation.pdf}
    \caption{Propagation using matrix exponential (\texttt{expm} from \texttt{numpy}), obtained using script~\ref{code:super_matrix_exp}. The propagated state $\rho(t)$ is obtained using Eq.~\eqref{eq:matrix_exp_superoperator}, and compared to the solution obtained using a finite-difference method (\texttt{mesolve} from \texttt{QuTiP}), implemented in script~\ref{code:mesolve_example}.}
    \label{fig:super_matrix_exp}
\end{figure}

It is worth pointing out that the approach used in script~\ref{code:super_matrix_exp} is by no mean optimised, and calculates a new propagator for every time step in the considered time domain. When working with evenly-spaced time steps we can reduce the computational cost by exploiting the composition rule of dynamical semigroups, as discussed in Sec.~\ref{ss:semigroup}. In \texttt{QuTiP}, instead, the solution is obtained using the sophisticated and powerful \texttt{mesolve} method, which by default uses \texttt{scipy}'s numerical integration library \href{https://docs.scipy.org/doc/scipy/tutorial/integrate.html}{\texttt{integrate}}. 

\subsubsection{Singular value decomposition of the Liouville superoperator}\label{sss:td:superop}

The superoperator $\mathcal{L}$ is generally a complex, non-Hermitian matrix. For this reason a spectral decomposition of $\mathcal{L}$ is not always guaranteed, that is, $\mathcal{L}$ may not admit the diagonal representation $\mathcal{L} = V D V^{-1}$. However, $\mathcal{L}$ always admits a singular value decomposition\footnote{The generalisation of the eigenvalue decomposition.} (SVD), and therefore can be represented in terms of its left and right-singular vectors, $\bm{L}_k$ and $\bm{R}_k$, respectively, and the set of complex singular values $\{\lambda_k\}$, that abide by the following relationships~\cite{Sacha2020},
\begin{align}
    \mathcal{L} \bm{R}_k &= \lambda_k \bm{R}_k, \label{eq:right_eig_vec}\\
    \bm{L}^\dagger_k \mathcal{L} &= \lambda_k \bm{L}^\dagger_k.  
    \label{eq:left_eig_vec}
\end{align}
Notice that both $\bm{R}_k$ and $\bm{L}_k$ are column vectors, hence $\bm{L}^\dagger_k$ is a row vector. Each left and right-singular vectors can be normalized via,
\begin{align}
    \hat{\bm{R}}_k &= \bm{R}_k\big/\sqrt{\bm{L}^\dagger_k\bm{R}_k}
    \label{eq:Norm_r}\\
    \hat{\bm{L}}^\dagger_k &= \bm{L}^\dagger_k\big/\sqrt{\bm{L}^\dagger_k\bm{R}_k}.
    \label{eq:norm_Ldag}
\end{align}
The normalized singular vector pairs then follow the usual orthonormalisation condition~\cite{Sacha2020},
\begin{equation}
\label{eq:bi-orthonormality}
    \hat{\bm{L}}^\dagger_i  \hat{\bm{R}}_j^\phdagger = \delta_{ij}. 
\end{equation}
 
The solution of Eq.~\eqref{eq:superop_form} for a system with time independent Liouville superoperator $\mathcal{L}$ can now be expressed as follows,
\begin{equation}
\label{eq:solution_svd}
    \bm{\rho}(t) = \sum_{k=1}^{d^2}  \hat{\bm{L}}^\dagger_k\bm{\rho}(t_0) \hat{\bm{R}}_k e^{\lambda_k (t-t_0)}
\end{equation}
where $d$ is the dimension of the Hilbert space. 

The advantage of expressing the time evolution in form of Eqs.~\eqref{eq:matrix_exp_superoperator} and~\eqref{eq:solution_svd} is that it is exact (when the singular values are found exactly) for all times and therefore does not depend on the step size or other operational details of the integration routine used to solve the differential equation. In the following \texttt{python} code, we use \texttt{scipy} to obtain the temporal solutions for a system with,
\begin{equation}
\label{eq:singular_value_problem}
	H = \hbar\begin{pmatrix}
	0 & \Omega\\
	\Omega & 0
	\end{pmatrix},
	\quad \quad
    L = \begin{pmatrix}
    0 & 1\\
    1 & 0
    \end{pmatrix}, \quad \textrm{and}\quad
    \bm{\rho}(0) = \begin{pmatrix}0, 0, 0, 1\end{pmatrix}^\textrm{T}
\end{equation}
using the singular value decomposition of $\mathcal{L}$.

% ------- code: python solution ---------
\code{https://github.com/frnq/qme/blob/main/python/dynamics_norm_svd.py}{Solution using normalized singular vectors {\normalfont\textsf{(requires script~\ref*{code:superoperator_python})}}}{code:temporal_python_solution}{python}{Scripts/python/dynamics_norm_svd.txt}

\noindent
The solution is shown in Fig.~\ref{fig:temporal_python_solution}. A \texttt{MATLAB} implementation of this method can be found in the Appendix in script~\ref{code:temporal_solution}.

\begin{figure}
    \centering
\includegraphics{Figures/solution_singluar_vectors.pdf}
    \caption{Dynamics of the state $\rho(t)$ for Eq.~\eqref{eq:singular_value_problem}, solving the Lindblad master equation using the normalised superoperator singular vectors, obtained with script~\ref{code:temporal_python_solution}. }
    \label{fig:temporal_python_solution}
\end{figure}

\subsubsection{Time-dependent generators}
\label{sss:time-dependent_generators}
If the Hamiltonian or the decoherence terms depend on time, Eqs.~\eqref{eq:superop_form} is generalised to
\begin{equation}
    \label{eq:time-dependent_generator}
    \dot{\bm{\rho}} = \mathcal{L}(t) \bm{\rho},
\end{equation}
where the Liouville generator $\mathcal{L}(t)$ now explicitly depends on time. In this case the solution of Eq.~\eqref{eq:matrix_exp_superoperator} is not valid. The general solution of Eq.~\eqref{eq:time-dependent_generator} is given by
\begin{equation}
    \label{eq:time-ordered_solution}
    \bm{\rho}(t) = \mathcal{T}\big\{ \exp[\textstyle\int_0^t ds \mathcal{L}(s)] \big\} \bm{\rho}(t_0),
\end{equation}
where $\mathcal{T}$ is the time-ordering operator, analogue to the Dyson series for time-dependent Hamiltonians and wavefunction propagation~\cite{Breuer2002,Schnell2020}. Eq.~\eqref{eq:time-ordered_solution} can be approximated, for instance, by means of a sequence of step-wise time-independent generators, before resorting to other means like numerical integration. 

If the generator $\mathcal{L}(t)$ is approximately \emph{piecewise time-independent}, then Eq.~\eqref{eq:matrix_exp_superoperator} can be applied to each time slice, using the result of the previous slice to provide the input state for the next slice. This scenario is common in many optical and spin resonance experiments. For example, it can be used to
compute the effect of applying a laser pulse resonant with an atomic transition, to then observing the behaviour of the system while the pulse is on and immediately after it has been turned off. 

For example, let us consider a system with Hamiltonian $H = H_0 + v(t) H_1$, where $H_0 = \omega_0\sigma_z/2$, $H_1 = \omega_0\sigma_x/2$, $v(t) = \cos(\omega t)$, and a Lindblad dephasing operator $J = \ketbra{g}{g} =(\mathbb{1}-\sigma_z)/2$, with dephasing rate $\gamma$. The generator $\mathcal{L}(t) = \mathcal{L}_0+\mathcal{L}_1(t)$ can be split into a time-independent part $\mathcal{L}_0$, associated with $H_0$ and $L_0$, and a time-dependent part $\mathcal{L}_1(t)$. To reduce the computational cost when propagating this system, we can update the propagator by updating only the time-dependent part.
The following \texttt{python} script generalises the solution of Eq.~\eqref{eq:matrix_exp_superoperator} to the case of time-dependent generators, by updating the superoperator at each time $t$; the solution is shown in Fig.~\ref{fig:td_propagation}. Note that for this approach to be accurate, the time step $\delta t$ has to be sufficiently small so that $v(t+\delta t)\approx v(t)+\mathcal{O}(\delta t^2)$. For rapidly varying time-dependent Hamiltonians other methods are required. If $H(t)$ is periodic, a solution can be found using an effective time-independent Hamiltonian, obtained using Floquet theory, as discussed in Sec.~\ref{s:oscillatory}.

% ------- code: time-dependent generator ---------
\code{https://github.com/frnq/qme/blob/main/python/time_dependent_generator.py}{Solution of time-dependent generator {\normalfont\textsf{(requires script~\ref*{code:superoperator_python})}}}{code:time_dependent_generator}{python}{Scripts/python/time_dependent_generator.txt}
\begin{figure}
    \centering
    \includegraphics{Figures/td_propagation.pdf}
    \caption{Solution of time-dependent generator using piecewise time-independent propagator, for the system considered in  script~\ref{code:time_dependent_generator}. The evolution is generated by a time-dependent Hamiltonian $H(t) = \omega_0\sigma_z/2 + v(t)\omega_0\sigma_x/2$, with $v(t)=\cos(\omega t)$, and a time-independent Lindblad dephasing operator $J = (\mathbb{1}-\sigma_z)/2$, associated with rate $\gamma$. The solution is obtained for $\omega_0 = 1$, $\omega =  3$ and $\gamma = 0.3$.}
    \label{fig:td_propagation}
\end{figure}

Note that in practice, especially when using theoretical system parameters, it is often possible to get exact cancellations which may have no physical grounding but can result in degenerate eigenvectors. While there are mathematical techniques which deal with these situations, it is often easier to just add an infinitesimal (numerically of order machine precision) imaginary term $i\varepsilon$, $\varepsilon\ll1$, to each element of the matrix. This can remove the degeneracy, even if the term is made suﬃciently small to have no perceivable effect on the resulting calculations. 


\subsubsection{Propagation via semigroup composition}
\label{ss:semigroup}

The dynamical maps generated by a linear Markovian quantum master equation like Eq.~\eqref{eq:lindblad_master_equation} are a family of single-parameter maps $\Lambda_t$ that have the following composition property,
\begin{equation}
    \label{eq:quantum_dynamical_semigroup}
    \Lambda_s \circ \Lambda_t = \Lambda_{s+t}, \;\;\;\; t,s \geq 0,
\end{equation}
and, therefore, are known as a \textit{quantum dynamical semigroup} (QDS).
The above can also be expressed as $\Lambda_s[\Lambda_t[\rho]]=\Lambda_{s+t}[\rho]$. For more on QDS see Ref.~\cite{Breuer2002}. Eq.~\eqref{eq:quantum_dynamical_semigroup} can be expressed in the superoperator form as
\begin{equation}
    \label{eq:superoperator_semigroup}
    P(s)P(t) = P(s+t), \;\;\;\; t,s \geq 0,
\end{equation}
which follows directly from the properties of the exponential and the fact that $[\mathcal{L}s,\mathcal{L}t]=0$. Note that the above does not generally hold for time-dependent $\mathcal{L}(t)$ and non-linear generators $\mathcal{L}(\rho(t))$.

When propagating a system in time over an evenly-spaced time set $\{k\delta t\}_{k=1}^{m}$ we can exploit the composition rule of dynamical semigroups to vastly reduce the computational cost of propagation. Instead of calculating a new propagator $P(t_k)$ for each time step $t_k = t_0 +k\delta t$, we can calculate a single propagator $P_1 = P(\delta t)$ and obtain all the others using
\begin{equation}
    \label{eq:propagator_semigroup}
    P(t_k) = \prod_{j=1}^{k} P_1 = P_1^k.
\end{equation}
The following \texttt{python} script implements Eq.~\eqref{eq:propagator_semigroup}, and the results are shown in Fig.~\ref{fig:propagation_semigroup}.
% -------- code: semigroup propagator ---------
\code{https://github.com/frnq/qme/blob/main/python/semigroup_propagator.py}{Propagation using dynamical semigroup composition {\normalfont\textsf{(requires script~\ref*{code:superoperator_python})}}}{code:semigroup_propagator}{python}{Scripts/python/semigroup_propagator.txt}

This approach is particularly useful when propagating for very long times or when using large time-steps, in which cases \texttt{scipy}'s \texttt{integrate} methods usually tend to accumulate large numerical errors. When propagating over several orders of magnitude, it may be convenient to break each timescale into evenly-spaced time sets to resolve the details of different dynamical transients. For example, this is useful when looking at dynamics from the femtosecond to the nanosecond timescales.
\begin{figure}[h]
    \centering
    \includegraphics{Figures/propagation_semigroup.pdf}
    \caption{Propagation using semigroup decomposition, obtained using script~\ref{code:semigroup_propagator}, compared to that obtained by computing a new propagator for each time-step.}
    \label{fig:propagation_semigroup}
\end{figure}

\subsubsection{Baker–Campbell–Hausdorff \& Zassenhaus formula}
\label{ss:zassenhaus_BCH}

Hamiltonians and superoperators are often sums of two or more terms, such as $W = U+V$. As briefly noted in Sec.~\ref{ss:semigroup}, when the terms commute with each other $[U,V]=0$, the solution can be obtained from the composition of individual terms. For example, let $\mathcal{L} = \mathcal{L}_1 + \mathcal{L}_2$, with $[\mathcal{L}_1 ,\mathcal{L}_2] = 0$, then
\begin{equation}
    \label{eq:composition_commuting}
    P(t) = \exp(\mathcal{L} t) = \exp(\mathcal{L}_1 t)\exp(\mathcal{L}_2 t).
\end{equation}
Instead, when considering pairs of non-commuting operators $[X,Y]\neq 0$, we have $\exp(X+Y)\neq\exp(X)\exp(Y) = \exp(Z)$. The solution to the latter equation for $Z$ is known as the Baker-Campbell-Hausdorff (BCH) formula~\cite{Rossmann2002}, and reads,
\begin{equation}
    \label{eq:BCH}
    Z = X + Y + \frac{1}{2}[X,Y] + \frac{1}{12}\bigg( [X,[X,Y]] + [Y,[Y,X]]\bigg) + \cdots.
\end{equation}
The BCH solution finds application when used in the Zassenhaus formula, which allows us to decompose a matrix exponential $\exp[(X+Y)t]$, where $t$ is a scalar parameter, in terms of a product series,
\begin{equation}
    \label{eq:zassenhaus}
    \exp[(X+Y)t] = \exp[Xt]\exp[Yt]\exp\bigg[-\frac{1}{2}[X,Y]t^2\bigg]\exp\bigg[\frac{1}{3}\Big([Y,[X,Y]]+\frac{1}{2}[X,[X,Y]]\Big)t^3\bigg]\cdots.
\end{equation}
The formula becomes useful when the product series can be truncated or approximated to a certain set of terms. This is for example particularly useful when the generator is time-dependent $\mathcal{L}_t$ and $[\mathcal{L}_t,\mathcal{L}_s]\neq 0$: By choosing a sufficiently small time step $\delta t$ such that $s = t+\delta t$, the series of Eq.~\eqref{eq:zassenhaus} can be truncated to terms in $\mathcal{O}(\delta t^m)$ for some $m>1$, as discussed in the next section.

\subsubsection{Suzuki-Trotter expansion}
\label{ss:suzuki-trotter}

A consequence of the Zassenhaus formula is that, for \textit{small} time steps $\delta t$, Eq.~\eqref{eq:zassenhaus} can be truncated to the first order in $\delta t$ with errors of the order of $O(\delta t^2)$
\begin{equation}
    \label{eq:limit_zassenhaus}
    \exp[(X+Y)\delta t] = \exp[X\delta t]\exp[Y\delta t] + O(\delta t^2).
\end{equation}
This can be used to obtain the solution for long times using the product series,
\begin{equation}
    \exp[(X+Y)\delta t] = \lim_{n \to \infty} \bigg[ \exp\bigg(X \frac{t}{n}\bigg)\exp\bigg(Y\frac{t}{n}\bigg) \bigg]^n,
\end{equation}
also known as \textit{Suzuki–Trotter expansion} or \textit{Lie product formula}~\cite{Rossmann2002}. This approach is particularly useful when studying the dynamics of interacting many body systems or time-dependent generators. The following \texttt{python} script uses the Suzuki–Trotter expansion to propagate a system by separating the contribution of the two non-commuting superoperators. The results are shown in Fig.~\ref{fig:suzuki_trotter}.
% -------- code: suzuki-trotter ---------
\code{https://github.com/frnq/qme/blob/main/python/suzuki.py}{Propagation using Suzuki-Trotter expansion {\normalfont\textsf{(requires script~\ref*{code:superoperator_python})}}}{code:suzuki}{python}{Scripts/python/suzuki.txt}

\begin{figure}[h]
    \centering
    \includegraphics{Figures/suzuki_trotter.pdf}
    \caption{Propagation using Suzuki-Trotter expansion for different amounts $m = 50,100,1000$ of time steps, obtained using script~\ref{code:suzuki}.}
    \label{fig:suzuki_trotter}
\end{figure}

\subsubsection{Numerical solution with finite-difference methods}

While the matrix exponential is a powerful tool to obtain exact solution of Eq.~\eqref{eq:superop_form}, it may be less computationally expensive to compromise some precision in favor of less demanding time and memory requirements. Not only finite-difference methods can prove efficient at solving density operator master equations, but they can also be used to solve the dynamics of non-linear and time-dependent generators.
In this case, the approach consists in solving the set of coupled differential equations obtained by element-wise comparison of the left and right hand sides of Eq.~\eqref{eq:lindblad_master_equation}. 

The following script is a continuation of script~\ref{code:temporal_python_solution}, and solves the dynamics of the same two-level system using the 4-5th order Runge-Kutta differential equation method. The method is implemented using the initial-value problem solver \texttt{solve\_ivp} from \texttt{scipy.integrate} library for \texttt{python}. The solution is shown in Fig.~\ref{fig:solution_rk45}. A \texttt{MATLAB} implementation of the same code can be found in script~\ref{code:solution_matlab_ode} in the Appendix.

% ------- code: runge kutta method ---------
\code{https://github.com/frnq/qme/blob/main/python/dynamics_finite_diff.py}{Solution with finite-difference method {\normalfont \textsf{(requires script~\ref*{code:temporal_python_solution})}}}{code:solution_python_ode}{python}{Scripts/python/dynamics_finite_diff.txt}

\begin{figure}[h]
    \centering
    \includegraphics{Figures/solution_rk45.pdf}
    \caption{Propagation using finite-difference approach, based on the 4-5th order Runge-Kutta method. The solution is obtained using script~\ref{code:solution_python_ode}, and compared to that obtained using script~\ref{code:temporal_python_solution}, based on the singular value decomposition.}
    \label{fig:solution_rk45}
\end{figure}

\subsubsection{Solution using the stochastic wavefunction method}
\label{ss:swfm}

Since the amount of complex floating point numbers required to represent superoperators like $\mathcal{L}$ and $P$ scales as $d^4$, memory may become an issue for large systems. To circumvent this problem we can propagate a density operator using the stochastic wavefunction method~\cite{Carmichael1999}, also known as \textit{Monte Carlo wavefunction} method or \textit{master equation unravelling}. Originally developed for quantum optics, the method is an adaptation of the kinetic Monte Carlo method~\cite{Bortz1975} to the solution of Eq.~\eqref{eq:lindblad_master_equation}. 

Instead of propagating a density operator solving Eq.~\eqref{eq:superop_form}, the method provides a procedure to propagate a state vector $\ket{\psi_0}$ under the influence of some generator $\mathcal{L}$, by sampling a sufficiently large amount $N$ of stochastic trajectories $\Psi_j = \{\ket{\psi_j(t)}\}$, to then obtain the time-evolved density operator $\rho(t)$ by averaging over them,
\begin{equation}
    \label{eq:MCWF_rho_average}
    \rho(t) = \sum_{j=1}^{N} \ketbra{\psi_j(t)}{\psi_j(t)}.
\end{equation}

Let $H$ be the Hamiltonian of the system, and $\{L_k\}_{k=1}^{M}$ a collection of Hermitian\footnote{The method can be implemented with non-Hermitian Lindblad operators too, upon some adaptations to avoid division-by-zero errors in the normalisation steps.} Lindblad operators. In the simplest form of the method, each trajectory $\Psi_j$ is sampled according to the following steps:
\begin{enumerate}
    \item The probabilities associated with any of the $k$ incoherent transitions mediated by the $L_k$ jump operators is calculated, 
    \begin{equation}
        \label{eq:MCWF_prob_array}
        \delta p_k = \delta t \braket{\psi(t)|L_k^\dagger L_k^\phdagger|\psi(t)}\geq0,
    \end{equation}
    with $\delta p = \sum_{k=1}^{M}\delta p_k$.
    \item A uniform random number $u\in(0,1]$ is sampled. 
        \begin{enumerate}
            \item If $\delta p < u$, then no jump occurs and the state $\ket{\psi(t)}$ at time $t$ is evolved by means of the non-Hermitian effective Hamiltonian $H_\textrm{eff} = H - i\hbar \sum_{k=1}^M L_k^\dagger L_k^\phdagger /2$,
            \begin{equation}
                \label{eq:MCWF_non-hermitian_prop}
                \ket{\widetilde{\psi}(t+\delta t)} = \bigg(1-\frac{i}{\hbar} H_\textrm{eff}^\dagger \delta t\bigg)\ket{\psi(t)},
            \end{equation}
            where $\ket{\widetilde{\psi}}$ indicates that the state vector may not be normalised. 
            \item If $\delta p\geq u$, a jump occurs. A new uniform random number $u'\in(0,1]$ is sampled. The event that occurs is chosen finding the first $k$ such that $Q_k > u'$, where $Q_k = \sum_{j=1}^{k}\delta p_j/\delta p$. The state is propagated to be
            \begin{equation}
                \label{eq:MCWF_jump occurs}
                \ket{\widetilde{\psi}(t+\delta t)} = L_k \ket{\psi(t)}.
            \end{equation} 
        \end{enumerate}
    \item The state is normalised $\ket{\widetilde{\psi}(t+\delta t)}\to\ket{\psi(t+\delta t)} = \ket{\widetilde{\psi}(t+\delta t)}/\sqrt{\braket{\widetilde{\psi}(t+\delta t)|\widetilde{\psi}(t+\delta t)}}$.
\end{enumerate}
Note that in this approach no superoperator is assembled and no matrix exponential is calculated. Furthermore, since the trajectories $\Psi_j$ are completely independent of each other, this method can be trivially parallelised by running $N$ trajectories over $N$ different processing nodes to cut down the computational time by a factor of $N$.

A \texttt{python} implementation is presented in the script below, for a two-level system with $H = \sigma_z$ and Lindblad operators $\{ \sigma_z/2, \sigma_x/5\}$, with initial state $\ket{\psi}= (\ket{0}+\ket{1})/\sqrt{2}$ in the $\sigma_z$ basis. The results are shown in Fig.~\ref{fig:mcwf}. Note that the time-step $\delta t$ can be chosen to be a fraction of some operator norm of the Hamiltonian, such that $\delta t \ll \| H\|_\mathrm{op}^{-1}$. An equivalent \texttt{Mathematica} implementation can be found in script~\ref{code:mcwf} in the Appendix. A robust implementation of the stochastic wavefunction method is also available in \texttt{QuTiP}.
% -------- code: mcwf ---------
\code{https://github.com/frnq/qme/blob/main/python/mcwf.py}{Propagation using stochastic wavefunction method}{code:mcwf_python}{python}{Scripts/python/mcwf.txt}

\begin{figure}
    \centering
    \includegraphics{Figures/mcwf.pdf}
    \caption{Propagation with stochastic wavefunction method with $N=10,100,1000$ trajectories, using script~\ref{code:mcwf_python} with \texttt{sample} $=N$. The stochastic wavefunction solution approaches the exact one in the limit of large $N$. Here, the solution is compared to that obtained with \texttt{QuTiP}'s finite-difference method \texttt{mesolve}.}
    \label{fig:mcwf}
\end{figure}

\subsubsection{Sparse solvers}
\label{ss:sparse_solvers}
When dealing with very large systems, it is worth thinking about sparseness of superoperator and states, since finding its singular value decomposition may become prohibitively expensive.
A number of different techniques can be used to treat sparse and large superoperators, such as
\begin{itemize}
    \item using methods for sparse arrays (\texttt{SparseArray} in \texttt{Mathematica}), such as null-space solvers. A library of linear algebra methods for sparse arrays for \texttt{MATLAB} is available at Ref.~\cite{Davis2006}; 
    \item using Krylov subspace methods to solve for $\mathrm{exp}(\mathcal{L}t)\bm{\rho}_0$ directly~\cite{Vo2017}; Packages \href{https://github.com/weinbe58/expokitpy}{\texttt{expokitpy}} and \href{https://krypy.readthedocs.io/en/latest/#}{\texttt{KryPy}}~\cite{Gaul2014} offer Krylov method implementations for \texttt{python}.
    \item taking the action of the exponential on a given sparse initial state. In \texttt{Mathematica} this can be done with \texttt{MatrixExp} as follows,
    \begin{codeline}{Mathematica}
        \footnotesize
            \begin{minted}[linenos=false]{Mathematica}
                Pt = MatrixExp[M t, psi]
            \end{minted}
    \end{codeline}
    \item using the Arnoldi method~\cite{knap2011emission}. This can be done in \texttt{Mathematica} using the \texttt{Eigensystem} function in combination with \texttt{"Arnoldi"},
        \begin{codeline}{Mathematica}
        \footnotesize
            \begin{minted}[linenos=false]{Mathematica}
                {evals,evecs} = Eigensystem[M t, k, Method -> "Arnoldi"] 
            \end{minted}
        \end{codeline}
    where \texttt{k} represents the index of the eigenvalue (or singular value) to be calculated.
\end{itemize}
However, sometimes the simplest option may be to implement a finite difference method like Runge-Kutta with sparse linear algebra, as it is often just as fast as more sophisticated methods.

\subsection{Correlation functions}
\label{ss:correlation_functions}
Correlation functions measure the relationship between microscopic quantities across time, space and other observables. In statistical mechanics, they are used to calculate the ensemble properties of stochastic processes, and determine the degree of order or randomness in a system. For example, the effect of atmospheric turbulence on the propagation of light beams can be modelled from the correlation functions $C(t,t',\bm{r},\bm{r}') = \braket{n(t,\bm{r})n(t',\bm{r}')}$ of the refractive index $n(t,\bm{r})$~\cite{Paterson2005}. Similarly, the magnetic properties of materials can be inferred from the spatial correlation functions between spins~\cite{Gutzwiller1963}.

In quantum stochastic processes, correlation functions are used to determine the magnitude of decoherence and relaxation processes, as we will discuss in depth in Sec.~\ref{s:bloch-redfield}. The macroscopic properties of a variety of systems can be indeed calculated from the correlation functions of their microscopic features. Of particular importance are, emission and absorption spectra in light-matter interaction (see Sec.~\ref{sss:emiss_abs}), noise power spectra and relaxation rates, bunching and anti-bunching statistics of photons~\cite{Hennrich2005}, electrons~\cite{Emary2012} and other particles. Here, we will examine the basics of correlation functions and show how these can be calculated from the master equation governing the evolution of the density operator. We will then apply these results to calculate the emission spectrum in a simple example of a two-level system interacting with the electromagnetic field. 

\subsubsection{Quantum regression theorem}\label{sss:quantum_regression_theorem}
Linear systems are amply studied in physics because of their simplicity and exact solvability. The equations of motion of the averages of the operators of such systems are often linear, as for the case of Eq.~\ref{eq:superop_form}. 
For these systems, it can be shown that the averages of their two-time correlation functions obey exactly the same equations of motion. This result, first derived by \emph{Lax}, is known as the \emph{quantum regression theorem}~\cite{ficek2005quantum,gardiner2004quantum}, and it provides a method for calculating any two-time correlation function $\braket{A(t)B(t')}$, i.e., involving any two observables at different points in time, for a system whose dynamics are prescribed by a quantum master equation $\dot{\rho} = \mathcal{L}_t[\rho]$~\cite{ficek2005quantum}. 

Suppose that for a certain set of operators $\{A_i\}$, the linear master equation~\eqref{eq:superop_form} yields the following closed system of linear ordinary differential equations to their averages~\cite{Breuer2002},
\begin{equation} \label{Eq:QRT1}
    \frac{d}{d t}\langle A_i(t)\rangle = \sum_j G_{ij}\langle A_j(t) \rangle,
\end{equation}
for some coefficients $G_{ij}$.
Then, their two-point correlation functions
\begin{equation}
    \label{eq:corre_functions}
    \langle A_i(t+\tau)A_l(t)\rangle  = \mathrm{Tr}\big[ A_i \Lambda(t+\tau;t)[A_l\rho(t)]\big],
\end{equation}
where $\Lambda(t;t_0)$ is the dynamical map from time $t_0$ to time $t$, associated with the the master equation $\dot{\rho} = \mathcal{L}_t[\rho]$,
observe the same dynamics, 
\begin{equation} \label{Eq:QRT2}
	\frac{d}{d t}\langle A_i(t+\tau) A_l(t)\rangle = \sum G_{ij} \langle A_j(t+\tau)A_l(t) \rangle.
\end{equation}
Note how the right-hand side of (\ref{eq:corre_functions}) corresponds to the average of $A_i$ at time $t+\tau$ with the choice of initial density operator $\rho\to A_l\rho(t)$~\cite{gardiner2004quantum}.

Any two-time correlation function $\langle A(t+\tau)B(t)\rangle$ can then be simplified using (\ref{eq:corre_functions}) as \cite{Johansson2012},
\begin{align}\label{Eq:TT_corr_simp}
	\langle A(t+\tau)B(t)\rangle &= \mathrm{Tr}[A \Lambda(t+\tau;t)[B\rho(t)]\rbrace], \\ 
 &= \mathrm{Tr}[A \Lambda(t+\tau;t)[B \Lambda(t;0)[  \rho(0)]]].
\end{align}
When calculating $\langle A(t+\tau)B(t)\rangle$ numerically, we can first obtain $\rho(t) = \Lambda(t;0)[\rho(0)]$ with $\rho(0)$ as the initial state. We then propagate $B\rho(t)$ using the dynamical map, to obtain $\Lambda(t + \tau,t)[B\rho(t)]$, and conclude by taking the trace of the resulting operators. If we are interested in steady-state properties, the two-time correlation functions simplify further. By replacing $\rho(0)$ with $\rho(\infty) = \lim_{t\to\infty}\Lambda(t;0)[\rho(0)]$, we can calculate 
$\braket{A(t+\tau)B(t)}$ as
\begin{align}
    \label{eq:steady_state}
    \braket{A(t+\tau)B(t)} &= \tr[A\Lambda(t+\tau;t)[B\rho(\infty)]], \\
    & = \tr[A\Lambda(\tau;0)[B\rho(\infty)]], \\
    & = \braket{A(\tau)B(0)}.
\end{align}

\subsubsection{Emission and absorption spectra}\label{sss:emiss_abs}

Emission and absorption spectra of an optical material can be calculated from the two-time correlation functions of the transition operators associated with the emission and absorption of photons, respectively. For example, an atomic medium given by an ensemble of non-interacting $d$-level systems that interact with the electromagnetic field, will emit light when excited. Its spectrally-resolved intensity is proportional to its emission spectrum $E(\omega)$, which measures the likelihood of transition between eigenstates $\ket{\phi_i}\to\ket{\phi_j}$ with energy difference $\omega$. In first-order perturbation theory, $E(\omega)$ can be calculated using the Fermi golden rule~\cite{Breuer2002}. Line-broadening effects caused by decoherence and relaxation processes can be calculated in second-order perturbation theory using two-point correlation functions and the quantum regression theorem. 

Let us consider a generic two-level emitter with Hamiltonian $H = \Omega\sigma_z/2$ to illustrate how the emission spectrum is calculated. The system can emit a photon via the transition operator $\sigma_- = (\sigma_x-i\sigma_y)/2$ and absorb a photon via its Hermitian conjugate $\sigma_-^\dagger = \sigma_+ = (\sigma_x+i\sigma_y)/2$. Let the system be in a stationary state $\rho(\infty)$. Then, its emission spectrum is calculated from the correlation function of the transition operators $\braket{\sigma_-^\dagger(\tau)\sigma_-(0)}$ as~\cite{Breuer2002},
\begin{align}\label{Eq:TLA_emission_spectrum}
	E(\omega) & \propto \mathcal{F}(\omega)[\braket{\sigma_-^\dagger(\tau)\sigma_-^{\phdagger}(0)}], \\
 & = \int_{-\infty}^{\infty}d\tau e^{-i\omega\tau}\langle{\sigma^\dagger_-}(\tau){\sigma_-^{\phdagger}}(0)\rangle \\ 
 \label{eq:real_form}
 &= 2\;\mathrm{Re}\left\lbrace\int_{0}^{\infty}d\tau e^{-i\omega\tau}\langle{\sigma^\dagger_-}(\tau){\sigma_-^{\phdagger}}(0)\rangle\right\rbrace,
\end{align}
where $\mathcal{F}(\omega)$ is the Fourier transform.
Eq.~(\ref{eq:real_form}) follows from decomposing the limits of the Fourier transform in Eq.~\eqref{Eq:TLA_emission_spectrum} at $t=0$, followed by the use of relation $\langle{\sigma^\dagger_-}(-\tau_+){\sigma_-^{\phdagger}}(0)\rangle  =   \langle{\sigma^\dagger_-}(\tau_+){\sigma_-^{\phdagger}}(0)\rangle^*$, where $\tau_-$ denotes $\tau<0$ and $\tau_+$ denotes $\tau \geq0$~\cite{Breuer2002}.
The generalisation to the emission spectra of a multi-level emitters is obtained by generalisation of Eq.~(\ref{Eq:TLA_emission_spectrum}) as discussed in Ref.~\cite{Hapuarachchi2022}. The emission spectrum $E(\omega)$ is calculated as a sum of all the contributions from the possible transitions $\ket{i}\to\ket{j}$ between the eigenstates of the system with $i>j$, modelled by the operators $\sigma_{ij} = \ketbra{\phi_j}{\phi_i}$,
\begin{equation}
    \label{eq:d-level_emission}
    E(\omega) \propto \sum_{i>j} \mathcal{F}(\omega)[\braket{J_{ij}^\dagger(\tau) J_{ij}^{\phdagger}(0)}],
\end{equation}
with $J_{ij} = \sqrt{\gamma_{ij}}\sigma_{ij}$, for some rates $\gamma_{ij}$.

If the emitter is illuminated by a tunable probe field with angular frequency $\omega_\mathrm{p}$, whose amplitude is assumed to be weak as to not significantly perturb the atom's Hamiltonian, the steady-state probe absorption spectrum can be obtained as follows~\cite{zhou1996absorption, tanas1998analytical, xu2013frontiers},
\begin{equation}\label{Eq:TLA_absorption_spectrum}
	A(\nu) \propto \mathrm{Re}\left\lbrace \int_{0}^{\infty} d\tau e^{i\nu\tau}\langle [\sigma_+^\dagger(\tau),\sigma_+^{\phdagger}(0)]\rangle  \right\rbrace,
\end{equation}
where $\nu = \omega_\mathrm{p}-\omega$ is the detuning of the probe beam relative to the driving laser.

We refer the reader to references \cite{Carmichael1999, meystre2007elements, nation2011qutip} for further details on correlation functions and spectra. We have included the step-by-step implementation of an example of two-level system emission spectrum using (\ref{Eq:TLA_emission_spectrum}) below. The resulting time-domain emission correlation and spectrum are depicted in Fig.\ \ref{Fig:Correlation_spectrum}, alongside the corresponding \texttt{QuTiP} version of the same calculation. 

%%%%%%%% FIGURE %%%%%%%%% 
\begin{figure*}[h!]
	\includegraphics[width=\textwidth]{Figures/correlations.pdf}
	\centering
	\caption{ (\textit{Left}) Real and imaginary part of the steady-state correlation function $C(t) = \braket{\sigma_+(\tau)\sigma_-^{\phdagger}(0)}_{ss}$ for a two-level system $H=\Omega\sigma_z/2$, with Rabi frequency $\Omega$ and decay rate $\Gamma = \Omega/10$. (\textit{Right}) Emission spectrum $E(\omega)$ of the considered two-level system associated with transition operator $\sigma_-^{\phdagger}=\ketbra{e}{g}=\sigma_+^\dagger$. The peaks coincide with the transition frequencies $\omega_{ij} = \omega_i - \omega_j$, associated with transitions $\ket{i}\to\ket{j}$ as shown by the labels. The emission spectrum calculated using the semigroup composition rule is compared with the one obtained using \texttt{QuTiP}, using script~\ref{code:emission_qutip}.}
 \label{Fig:Correlation_spectrum}
\end{figure*}
%%%%%%%% FIGURE %%%%%%%%%


% -------- code: Corr ---------
\code{https://github.com/frnq/qme/blob/main/python/emission_spectrum.py}{Emission spectrum of a two-level atom}{code:emission_spectrum}{python}{Scripts/python/emission_spectrum.txt}