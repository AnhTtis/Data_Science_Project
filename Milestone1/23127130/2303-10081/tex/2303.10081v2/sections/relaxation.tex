%!TEX root = ../main.tex
\section{Semidefinite Relaxation}
\label{sec:sdprelax}
We now apply semidefinite relaxations to solve the verification problem (Section~\ref{sec:sdpverify}) and the synthesis problem (Section~\ref{sec:sdpsynthesis}). \HYedit{Most of the results presented in this section are adapted from existing techniques proposed in~\cite{lasserre01siopt-global,lasserre11jgo-minmaxpop}. Our contribution here is to draw connections, for the first time, from global optimization of (min-max) POPs to verification and synthesis of robust CBFs. We hope these connections will inspire researchers working on similar problems.} 

Before diving into the details, we add $s_0 := 1$ into POP~\eqref{eq:standardpop} and assume the following conditions. 
\begin{assumption}[\kscedit{Feasible and Archimedean sets}]
    \label{assume:archimedeanness}
    For any $\theta \in \Theta$, (i) the feasible set of POP~\eqref{eq:standardpop} is non-empty; (ii) there exists $M_y > 0$ such that $M_y - \norm{y}^2 = \sum_{i=1}^{l_h} \mu_i h_i + \sum_{i=0}^{l_s} \sigma_i s_i$ holds for some polynomials $\{\mu_i \}_{i=1}^{l_h}$ and sum-of-squares (SOS) polynomials $\{ \sigma_i \}_{i=0}^{l_s}$ in $y$.
\end{assumption}

\HYedit{
   Assumption~\ref{assume:archimedeanness} is very general. First, the feasible set of~\eqref{eq:standardpop} is non-empty as long as $\partial \calC = \{x\in \Real{n} \mid b(x,\theta) = 0\}$ is non-empty, which can be satisfied via the design of $b(x,\theta)$. Second, if we know \emph{a priori} a bound $M_y$ on $y$, then adding a redundant constraint $M_y - \norm{y}^2 \geq 0$ to~\eqref{eq:standardpop} makes the Archimedean condition trivially satisfied. Because $\partial \calC$ and $\bbU$ are compact, it is easy to see that both $x$ and $u^\star$ are bounded. From~\eqref{eq:zlift} we observe $z$ is bounded because $z^2$ is a smooth function of $x$ (and $x$ belongs to a compact set). The next Proposition gives sufficient conditions for when the optimal dual variable $\zeta^\star$ is also bounded. 

\begin{proposition}[Bounded $\zeta^\star$]
    \label{prop:boundeddual}
If $\bbU$ is one of the following:
\begin{enumerate}[label=(\roman*)]
    \item Polytope: $c_{u,i}(u) = w_i\tran u + d_i \leq 0, i=1,\dots, l_u$ with no degenerate extreme points; 
    \item Box: $c_{u,i} (u) = u_i^2 - w_i^2, i=1,\dots,m$ with $w_i > 0$;
    \item Ellipsoid: a single $c_{u} = u\tran W u - 1$ with $W \succ 0$, 
\end{enumerate}
then there exists a constant $M_\zeta$ such that $\norm{\zeta^\star} \leq M_\zeta$.
\end{proposition}
\begin{proof}
    See Appendix~\ref{app:proof:prop:boundeddual}. \hfill \qedsymbol
\end{proof}
Section~\ref{sec:experiments} computes specific bounds for our test problem.}

\subsection{Verification: Lasserre's Hierarchy}
\label{sec:sdpverify}
We apply Lasserre's hierarchy of moment-SOS semidefinite relaxations~\cite{lasserre01siopt-global} to solve the POP~\eqref{eq:standardpop}. Due to space constraints, we only give a brief overview and refer the interested reader to~\cite{lasserre01siopt-global} or~\cite[Section 2.2]{yang22pami-certifiably} for details. 

Let $t_{\max} = \max\{\deg{\varphi}, \{\deg{h_i}\}_{i=1}^{l_h}, \{ \deg{s_i} \}_{i=0}^{l_s}  \}$ be the maximum degree of the POP~\eqref{eq:standardpop} with a fixed $\theta$, $\kappa \in \bbN$ be any integer such that $2\kappa \geq t_{\max}$, and $\kappa_0$ be the smallest such $\kappa$. Denote by $[y]_\kappa$ the vector of monomials in $y$ with degree up to $\kappa$, and by $Y_{\kappa} = [y]_\kappa [y]_\kappa\tran$ the moment matrix in $y$ of order $\kappa$. Further, let
\bea 
S_i = s_i(y,\theta) \cdot Y_{\kappa - \ceil{\deg{s_i}/2}},i=1,\dots,l_s
\eea
be the localizing matrix associated with $s_i$ (so that all the monomials in $S_i$ have degree at most $2\kappa$). With $Y = (Y_\kappa, S_1,\dots,S_{l_s})$, consider the semidefinite program (SDP):
\bea \label{eq:sdpverify}
\rho_{\kappa} = \min_{Y} \{ \inprod{C}{Y} \mid Y \succeq 0,\ \ \calA(Y) = e \}
\eea
where $C = (C_0,C_1,\dots,C_{l_s})$ is constant, has the same size as $Y$, and $\inprod{C}{Y} = \varphi(y,\theta)$;\footnote{$\inprod{C}{Y} := \trace{C_0 Y_0} + \dots + \trace{C_{l_s} S_{l_s}}$. We can have $C_1 = \dots = C_{l_s} = 0$ and $C_0$'s entries be the coefficients of $\kscedit{\varphi(y,\theta)}$.} $\calA(Y) = e$ collects all linear dependencies in $Y$ (\eg entries of $S_i$ are linear combinations of entries of $Y_\kappa$). It is clear that SDP~\eqref{eq:sdpverify} is a convex relaxation of the POP~\eqref{eq:standardpop} because every feasible point $y$ of the POP can generate a $Y$ that is feasible for the SDP via the moment and localizing matrices. The following theorem states that, as $\kappa \rightarrow \infty$, solving the SDP can recover the global optimizers of the POP.

\begin{theorem}[Lasserre's hierarchy~\cite{lasserre01siopt-global,henrion05-detecting}]
\label{thm:lasserre}
Let $\rho_\kappa^\star$ and $Y^\star = (Y_\kappa^\star, S_1^\star,\dots,S_{l_s}^\star)$ be the optimal value and one optimal solution of the SDP~\eqref{eq:sdpverify}, then
\begin{enumerate}[label=(\roman*)]
    \item $\rho_\kappa^\star \leq V(\theta)$ for any $\kappa$, and $\rho_\kappa^\star \rightarrow V(\theta)$ as $\kappa \rightarrow \infty$;
    \item if $Y_\kappa^\star$ satisfies the flatness condition, \ie $r=\rank{ Y_{\kappa' - \kappa_0}^\star } = \rank{ Y_{\kappa'}^\star }$ for some $\kappa_0 \leq \kappa' \leq \kappa$, then $\rho^\star_\kappa = V(\theta)$ and the relaxation is said to be tight or exact. Furthermore, $r$ global optimizers of the POP~\eqref{eq:standardpop} can be extracted from $Y_\kappa^\star$.
\end{enumerate}
\end{theorem}

Although the convergence in Theorem~\ref{thm:lasserre} is asymptotic, many practical problems~\cite{yang22mp-inexact} \kscedit{observe finite convergence}, \ie $\rho_\kappa^\star$ coincides with the global optimum of the original POP at a finite (and often small) relaxation order $\kappa$, and this can be proved with additional assumptions of the POP~\cite{nie14mp-optimality}. For the purpose of verification, $\rho^\star_\kappa \geq 0$ for some $\kappa$ is sufficient to certify the correctness of a robust CBF. 

% \red{In Section~\ref{sec:experiments}, we will show that, when $b(x,\theta)$ is not a valid CBF, solving the POP to global optimality helps us find an $x$ that refutes $b(x,\theta)$.} 

\subsection{Synthesis: Polynomial Approximation}
\label{sec:sdpsynthesis}
A naive approach to synthesize a robust CBF $b(x,\theta)$ is to randomly sample parameters $\theta \in \Theta$ until $V(\theta) \geq 0$. This approach can work well if $\Theta$ is a finite set. Another potential approach is to employ differentiable optimization, \ie computing $\partial V(\theta) / \partial \theta$ after solving the verification problem and performing gradient ascent to optimize $\theta$. Since the verification problem is a nonconvex POP, the convergence of this approach in solving the min-max synthesis problem is unclear (differentiable optimization typically works well when the inner problem is convex~\cite{bennett22mp-hierarchical}). In the following, we introduce \HYedit{the method proposed in~\cite{lasserre11jgo-minmaxpop} that is based on polynomial approximation}. The goal is to use a set of polynomials to lower bound $V(\theta)$, and use Lasserre's hierarchy to maximize the polynomial lower bounds. 
% As a result, this approach is a two-stage semidefinite relaxation.
% Let $\tldTheta \subset \Real{k}$ be a \emph{simple} set, \eg a box or a ball, that contains $\Theta$, and let $\tldTheta$ be defined by polynomial inequalities:
% \bea
% \tldTheta = \{ \theta \in \Real{k} \mid s_i(\theta) \geq 0,i=l_s + 1,\dots,\tldl_s \}.
% \eea 

Let $\psi$ be the uniform distribution supported on $\Theta$ so that 
\bea \label{eq:computemoments}
\gamma_{\beta} = \int_{\Theta} \theta^\beta d\psi(\theta) , \quad \beta \in \bbN^k
\eea
can be computed for any monomial $\theta^\beta = \theta_1^{\beta_1} \theta_2^{\beta_2}\cdots \theta_k^{\beta_k}$.\footnote{If $\gamma_\beta$ cannot be computed on $\Theta$, then one can augment $\Theta$ into a simple set $\tldTheta \supset \Theta$ (\eg a box or a ball) such that $\gamma_\beta$ is easy to compute on $\tldTheta$.}
% We make the following assumption on $\tldTheta$, and will show it holds for our test problem in Section~\ref{sec:experiments}.
% \begin{assumption}[Nonempty feasible set]
%     \label{assume:nonempty}
%     For any $\theta \in \tldTheta$, the feasible set of the POP~\eqref{eq:standardpop} is nonempty.
% \end{assumption}
Let $\nu \in \bbN$ such that $2\nu$ is no smaller than the maximum degree of the POP~\eqref{eq:standardpop}, and let $\nu_0$ be the smallest such $\nu$.\footnote{Note that in general $\nu_0 \neq \kappa_0$ introduced in Section~\ref{sec:sdpverify}. This is because $\theta$ is considered as constant when counting the maximum degree of the POP~\eqref{eq:standardpop} for verification, while considered the same as $y$ as an unknown variable when performing synthesis. For example, $\psi(y,\theta) = y^2 \theta^4$ has degree $2$ in $y$, but degree $6$ in $[y;\theta]$.} Denote by $\bbN^{k}_{2\nu}$ the set of $k$-dimensional integers summing up to $2\nu$.
Consider the following sum-of-squares (SOS) problem
\bea \label{eq:soslowerbound}
\hspace{-4mm} \max_{\lambda,\sigma,\mu} & \sum_{\beta \in \bbN^{k}_{2\nu}} \lambda_\beta \gamma_\beta \\
\hspace{-4mm} \subject & \substack{ \varphi(y,\theta) - \sum_{\beta \in \bbN^k_{2\nu}} \lambda_\beta \theta^\beta = \\ \sum_{i=0}^{\tldl_s} \sigma_i(y,\theta) s_i(y,\theta) + \sum_{i=1}^{l_h} \mu_i(y,\theta) h_i(y,\theta)  } \\
& \sigma_i \in \Sigma[y,\theta],\deg{\sigma_i s_i} \leq 2\nu, i=0,\dots,\tldl_s \\
& \mu_i \in \poly{y,\theta}, \deg{\mu_i h_i} \leq 2\nu, i=1,\dots,l_h
\eea
where $\poly{y,\theta}$ (resp. $\Sigma[y,\theta]$) is the set of real polynomials (resp. SOS polynomials) in $[y;\theta]$.
Let $\lambda^\star$ be \kscedit{its global optimizer (or one of its global optimizers)}. Denote
\bea \label{eq:polylowerbound}
V_{\nu}(\theta) := \sum_{\beta \in \bbN^k_{2\nu}} \lambda^\star_\beta \theta^\beta, \quad \nu \geq \nu_0
\eea 
as the polynomial in $\theta$ whose coefficients are $\lambda^\star$. The following theorem states that $V_{\nu}(\theta)$ is a polynomial lower bound for the unknown (and usually nonsmooth) $V(\theta)$. Moreover, $V_{\nu}(\theta)$ converges to $V(\theta)$ as $\nu$ increases.

\begin{theorem}[Global Convergence~\cite{lasserre11jgo-minmaxpop}]
    \label{thm:globalconvergence}
    Let Assumption~\ref{assume:archimedeanness} hold and $V_\nu (\theta)$ be as in \eqref{eq:polylowerbound}, we have 
    \begin{enumerate}[label=(\roman*)]
        \item $V_\nu(\theta) \leq V(\theta)$ for all $\theta \in \Theta$ and $\nu \geq \nu_0$;
        \item $\int_{\Theta} \abs{V(\theta) - V_\nu(\theta)} d\psi(\theta) \rightarrow 0$ as $\nu \rightarrow \infty$;
        \item let $\tldV_{\nu}(\theta) := \max\{ V_{\nu_0}(\theta),\dots,V_\nu(\theta) \}$, then $V_\nu(\theta) \leq \tldV_\nu(\theta) \leq V(\theta)$ for all $\theta \in \Theta$ and $\tldV_\nu(\theta) \rightarrow V(\theta)$, $\psi$-almost uniformly on $\Theta$ as $\nu \rightarrow \infty$.
    \end{enumerate}
    Furthermore, let 
    \bea \label{eq:maxlowerbound}
    V_\nu^\star := \max_{\theta \in \Theta} V_\nu(\theta), \quad \nu \geq \nu_0
    \eea 
    and $\theta^\star_\nu$ be a global optimizer. Denote
    \bea \label{eq:bestmaximizer}
    \hatV_{\nu}^\star := \max_{\nu_0 \leq l \leq \nu} V^\star_l = V_{\tau(\nu)}(\theta_{\tau(\nu)}^\star).
    \eea 
    for some $\tau(\nu) \in \{ \nu_0,\dots,\nu \}$. Then we have 
    \begin{enumerate}[label=(\roman*)]
        \setcounter{enumi}{3}
        \item $\hatV_{\nu}^\star \rightarrow V^\star$ in~\eqref{eq:cbfsynthesis} as $\nu \rightarrow \infty$
        \item if $V(\theta)$ is continuous on $\Theta$ then $V^\star = V(\theta^\star)$ for some $\theta^\star \in \Theta$; and any accumulation point $\bar{\theta}$ of the sequence $(\theta_{t(\nu)}^\star) \subset \Theta$ is a global optimizer of~\eqref{eq:cbfsynthesis}. In particular, if $\theta^\star$ is unique, then $\theta_{t(\nu)}^\star  \rightarrow \theta^\star$ as $\nu \rightarrow \infty$. 
    \end{enumerate}
\end{theorem}

A few remarks are in order about Theorem~\ref{thm:globalconvergence}. First, each $V_{\nu}(\theta)$ is a valid lower bound for $V(\theta)$ on the set $\Theta$ and as $\nu$ increases, $\int_{\Theta} \abs{V(\theta) - V_\nu(\theta)} d\psi(\theta)$ tends to zero. Second, assume one has computed a sequence of $V_{l}(\theta)$ for $l=\nu_0,\dots,\nu$, then the point-wise maximum $\tldV_{\nu}(\theta) = \max_{\nu_0 \leq l \leq \nu} V_l (\theta)$ is a tighter lower bound for $V(\theta)$ in that $\tldV_\nu (\theta)$ converges to $V(\theta)$ almost everywhere on $\Theta$. Third, if one can compute the global maximizers of the sequence of lower bounds $\{ V_{l}(\theta) \}_{l=\nu_0}^{\nu}$, then the best maximizer (\cf~\eqref{eq:bestmaximizer}) converges to the global optimizer of the min-max POP. To compute the global maximizer in~\eqref{eq:maxlowerbound}, we use Lasserre's hierarchy introduced in Section~\ref{sec:sdpverify}. Because~\eqref{eq:maxlowerbound} is a low-dimensional POP only in $\theta$, empirically it is easy to solve~\eqref{eq:maxlowerbound} to global optimality. Fourth, unlike Theorem~\ref{thm:lasserre} which states that it is possible to detect and certify global optimality via the flatness condition, Theorem~\ref{thm:globalconvergence} does not tell us how to numerically detect when $V^\star = \hatV^\star_{\nu}$ happens. This implies that our algorithm cannot claim the non-existence of a valid robust CBF in $\{b(x,\theta) \mid \theta \in \Theta \}$. Last but not the least, assuming $\{ \theta \mid V_\nu(\theta) \geq 0 \}$ is non-empty for some $\nu$, then the lower bound polynomial $V_\nu (\theta)$ enables us to choose a parameter $\theta$ that optimizes some performance metric $\Psi(\theta)$ via solving the POP ``$\min_{\theta \in \Theta}\{ \Psi(\theta) \mid V_\nu (\theta) \geq 0 \}$''. For example, as we will show in Section~\ref{sec:experiments}, $\Psi(\theta)$ can be chosen as (inversely) proportional to the volume of the set $\calC$. 