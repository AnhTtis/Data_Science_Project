{
    "arxiv_id": "2303.15488",
    "paper_title": "On the Importance of Feature Separability in Predicting Out-Of-Distribution Error",
    "authors": [
        "Renchunzi Xie",
        "Hongxin Wei",
        "Yuzhou Cao",
        "Lei Feng",
        "Bo An"
    ],
    "submission_date": "2023-03-27",
    "revised_dates": [
        "2023-03-29"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG"
    ],
    "abstract": "Estimating the generalization performance is practically challenging on out-of-distribution (OOD) data without ground truth labels. While previous methods emphasize the connection between distribution difference and OOD accuracy, we show that a large domain gap not necessarily leads to a low test accuracy. In this paper, we investigate this problem from the perspective of feature separability, and propose a dataset-level score based upon feature dispersion to estimate the test accuracy under distribution shift. Our method is inspired by desirable properties of features in representation learning: high inter-class dispersion and high intra-class compactness. Our analysis shows that inter-class dispersion is strongly correlated with the model accuracy, while intra-class compactness does not reflect the generalization performance on OOD data. Extensive experiments demonstrate the superiority of our method in both prediction performance and computational efficiency.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15488v1"
    ],
    "publication_venue": null
}