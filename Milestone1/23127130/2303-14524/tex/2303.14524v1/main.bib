@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}
@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}
@inproceedings{sun2020lara,
  title={LARA: Attribute-to-feature adversarial learning for new-item recommendation},
  author={Sun, Changfeng and Liu, Han and Liu, Meng and Ren, Zhaochun and Gan, Tian and Nie, Liqiang},
  booktitle={Proceedings of the 13th international conference on web search and data mining},
  pages={582--590},
  year={2020}
}

@article{zhu2021cross,
  title={Cross-domain recommendation: challenges, progress, and prospects},
  author={Zhu, Feng and Wang, Yan and Chen, Chaochao and Zhou, Jun and Li, Longfei and Liu, Guanfeng},
  journal={arXiv preprint arXiv:2103.01696},
  year={2021}
}
@article{fu2022gptroadmap,
  title   = "How does GPT Obtain its Ability? Tracing Emergent Abilities of Language Models to their Sources",
  author  = "Fu, Yao; Peng, Hao and Khot, Tushar",
  journal = "Yao Fu’s Notion",
  year    = "2022",
  month   = "Dec",
  url     = "https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1"
}

@article{zhang2021language,
  title={Language models as recommender systems: Evaluations and limitations},
  author={Zhang, Yuhui and Ding, Hao and Shui, Zeren and Ma, Yifei and Zou, James and Deoras, Anoop and Wang, Hao},
  year={2021}
}
@inproceedings{geng2022recommendation,
  title={Recommendation as language processing (rlp): A unified pretrain, personalized prompt \& predict paradigm (p5)},
  author={Geng, Shijie and Liu, Shuchang and Fu, Zuohui and Ge, Yingqiang and Zhang, Yongfeng},
  booktitle={Proceedings of the 16th ACM Conference on Recommender Systems},
  pages={299--315},
  year={2022}
}
@article{liu2023pre,
  title={Pre-train, Prompt and Recommendation: A Comprehensive Survey of Language Modelling Paradigm Adaptations in Recommender Systems},
  author={Liu, Peng and Zhang, Lemei and Gulla, Jon Atle},
  journal={arXiv preprint arXiv:2302.03735},
  year={2023}
}
@misc{VisualChatGPT,
  doi = {10.48550/ARXIV.2303.04671},
  
  url = {https://arxiv.org/abs/2303.04671},
  
  author = {Wu, Chenfei and Yin, Shengming and Qi, Weizhen and Wang, Xiaodong and Tang, Zecheng and Duan, Nan},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models},
  
  publisher = {arXiv},
  
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{lecun2022path,
  title={A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27},
  author={LeCun, Yann},
  journal={Open Review},
  volume={62},
  year={2022}
}

@article{Wei2022EmergentAO,
  title={Emergent Abilities of Large Language Models},
  author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed Huai-hsin Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
  journal={ArXiv},
  year={2022},
  volume={abs/2206.07682}
}

@article{Wei2022ChainOT,
  title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Ed Huai-hsin Chi and Quoc Le and Denny Zhou},
  journal={ArXiv},
  year={2022},
  volume={abs/2201.11903}
}

@article{Wei2021FinetunedLM,
  title={Finetuned Language Models Are Zero-Shot Learners},
  author={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V. Le},
  journal={ArXiv},
  year={2021},
  volume={abs/2109.01652}
}

@misc{schick2023toolformer,
      title={Toolformer: Language Models Can Teach Themselves to Use Tools}, 
      author={Timo Schick and Jane Dwivedi-Yu and Roberto Dessì and Roberta Raileanu and Maria Lomeli and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},
      year={2023},
      eprint={2302.04761},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{parisi2022talm,
      title={TALM: Tool Augmented Language Models}, 
      author={Aaron Parisi and Yao Zhao and Noah Fiedel},
      year={2022},
      eprint={2205.12255},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{petroni2019language,
  title={Language models as knowledge bases?},
  author={Petroni, Fabio and Rockt{\"a}schel, Tim and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander H and Riedel, Sebastian},
  journal={arXiv preprint arXiv:1909.01066},
  year={2019}
}

@misc{yu2023generate,
      title={Generate rather than Retrieve: Large Language Models are Strong Context Generators}, 
      author={Wenhao Yu and Dan Iter and Shuohang Wang and Yichong Xu and Mingxuan Ju and Soumya Sanyal and Chenguang Zhu and Michael Zeng and Meng Jiang},
      year={2023},
      eprint={2209.10063},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{xu2021fusing,
      title={Fusing Context Into Knowledge Graph for Commonsense Question Answering}, 
      author={Yichong Xu and Chenguang Zhu and Ruochen Xu and Yang Liu and Michael Zeng and Xuedong Huang},
      year={2021},
      eprint={2012.04808},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{khashabi2020unifiedqa,
      title={UnifiedQA: Crossing Format Boundaries With a Single QA System}, 
      author={Daniel Khashabi and Sewon Min and Tushar Khot and Ashish Sabharwal and Oyvind Tafjord and Peter Clark and Hannaneh Hajishirzi},
      year={2020},
      eprint={2005.00700},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{chen2019personalized,
  title={Personalized fashion recommendation with visual explanations based on multimodal attention network: Towards visually explainable recommendation},
  author={Chen, Xu and Chen, Hanxiong and Xu, Hongteng and Zhang, Yongfeng and Cao, Yixin and Qin, Zheng and Zha, Hongyuan},
  booktitle={Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={765--774},
  year={2019}
}

@inproceedings{li2020generate,
  title={Generate neural template explanations for recommendation},
  author={Li, Lei and Zhang, Yongfeng and Chen, Li},
  booktitle={Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
  pages={755--764},
  year={2020}
}

@article{li2021personalized,
  title={Personalized transformer for explainable recommendation},
  author={Li, Lei and Zhang, Yongfeng and Chen, Li},
  journal={arXiv preprint arXiv:2105.11601},
  year={2021}
}

@inproceedings{shi2019adaptive,
  title={Adaptive feature sampling for recommendation with missing content feature values},
  author={Shi, Shaoyun and Zhang, Min and Yu, Xinxing and Zhang, Yongfeng and Hao, Bin and Liu, Yiqun and Ma, Shaoping},
  booktitle={Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
  pages={1451--1460},
  year={2019}
}

@inproceedings{yuan2021one,
  title={One person, one model, one world: Learning continual user representation without forgetting},
  author={Yuan, Fajie and Zhang, Guoxiao and Karatzoglou, Alexandros and Jose, Joemon and Kong, Beibei and Li, Yudong},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={696--705},
  year={2021}
}

