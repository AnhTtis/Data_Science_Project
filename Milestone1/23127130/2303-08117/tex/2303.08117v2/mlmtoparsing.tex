\section{Probing Masked Language Models for Parsing Information}\label{sec:mlmtoparsing}
%\rong{It's not very clear to me what this title is trying to say; maybe something like ``Probing Masked Language Model for Parsing Information''?}

\looseness=-1 \cref{sec:construction} shows that transformers can execute the Inside-Outside algorithm and contain syntactic information in their intermediate states. These results are existential, and it is unclear if models pre-trained under MLM possess similar information. 
%, such as information about spans in the parsing tree and marginal probabilities computed by the Inside-Outside algorithm. %what remains to be answered are: (1) whether the models trained with masked language modeling loss contain syntactic information, and (2) whether the models learn to ``execute'' the algorithm when trained with masked language modeling loss. 

\looseness=-1 One difficulty in answering this question is that syntactic probes on BERT-like models may leverage semantic cues to parse. To address this concern, we pre-train multiple RoBERTa models on synthetic datasets derived from English PCFG (\Cref{sec:pretrain-pcfg}), which eliminates semantic dependencies. We then probe the models for parse tree construction (\Cref{sec:parse}) and marginal probabilities (\Cref{sec:probe-marginal-probs}) to verify if they capture information computed by the Inside-Outside algorithm.
%Interestingly, we find probing patterns that indicate the existence of these span probabilities inside the contextual embeddings.
%, and thus do well on parsing and MLM (\Cref{thm:hard_attnt,thm:soft_attnt,thm:io-optimal-mlm}). The remaining questions are: Do attention models trained using masked language modeling really contain syntactic information? Do these models contain information computed by the Inside-Outside algorithm as shown by \Cref{thm:io-optimal-mlm}?


\subsection{Pre-training on PCFG}\label{sec:pretrain-pcfg}
%\haoyu{maybe pertaining details can be put into the appendix, and only briefly mention it here?}
\looseness=-1 We pre-train RoBERTa models with varying attention heads and layers on synthetic PCFG data. We denote the models with A$i$L$j$, where $i$ and $j$ indicate the number of attention heads and layers, respectively. Additional pre-training details are available in~\Cref{sec:pretraining-details}. \Cref{tab:pretraining-ppl} shows the perplexity for various models. We find that except for models with too few layers (A12L1) and too few attention heads (A3L12), other models have nearly the same perplexity. Further increasing depth and number of heads does not appear to improve the result.

\begin{table}[!t]
    \centering
    \footnotesize
    \begin{tabular}{|c|c|c|}
        \hline
        Model & Training ppl. & Validation ppl. \\
        \hline
        A12L12 & 106.16 & 106.68 \\
        A12L1 & 111.8 & 110.57 \\
        A12L3 & 108.09 & 105.79 \\
        A12L6 & 105.78 & 104.58 \\
        A3L12 & 120.52 & 117.39 \\
        A24L12 & 106.28 & 104.5 \\
        \hline
    \end{tabular}
    \caption{\looseness=-1 Perplexity of different models trained on synthetic PCFG data. A$i$L$j$  refers to a model with $i$ attention heads and $j$ layers. Except for models with few layers (A12L1) and  few attention heads (A3L12), trained models have nearly the same perplexity.}
    \label{tab:pretraining-ppl}
\end{table}

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.7\linewidth]{figs/probe_parsing.pdf}
    \caption{Comparison between different probes (linear or a 2-layer neural net) under different settings. 2-layer probes achieve better parsing performance, compared to linear probes. %We also report the 
    The large performance gap of the probes on layer 0's embeddings from A12L12 and the best layer shows the existence of meaningful syntactic information in the contextualized embeddings.
    %The probe is set to be linear or a 2-layer neural net, and the input to the probe is layer 0's embedding from A12L12 or the embeddings from the layer that achieves the highest F1 score.
    }
    \label{fig:probe-parsing-comparison}
\end{figure}

\begin{table*}[!th]
    \centering
    \footnotesize
    \begin{tabular}{|c|c|c|ccccccc|}
    \hline
         & & & IO & A12L12 & A12L1 & A12L3 & A12L6 & A3L12 & A24L12 \\
    \hline
        \multirow{6}{*}{\rotatebox[origin=c]{90}{Linear}}& \multirow{2}{*}{\begin{turn}{90} \dataset{PCFG} \end{turn}} & Sent. F1 & 81.61 &  \textbf{71.34} & 63.16 & 69.96 & \textbf{71.23} & 64.71 & \textbf{70.76} \\
        & & Corpus F1 & 71.65 & \textbf{63.01} & 54.24 & 61.54 & \textbf{62.57} & 55.36 & \textbf{62.56} \\
        \cline{2-10}
        & \multirow{2}{*}{\begin{turn}{90} \dataset{PTB} \end{turn}} & Sent. F1 & 78.77 &  \textbf{69.31} & 62.99 & 68.22 & 68.13 & 61.56 & \textbf{68.79} \\
        & & Corpus F1 & 75.90 & \textbf{65.01} & 59.96 & \textbf{65.21} & \textbf{65.01} & 58.31 & \textbf{65.97} \\
        \cline{2-10}
        & \multirow{2}{*}{\begin{turn}{90} OOD \end{turn}} & Sent. F1 & 81.61 & \textbf{64.26} & 57.96 & 63.22 & \textbf{63.89} & 58.00 & \textbf{63.88} \\
        & & Corpus F1 & 71.65 & \textbf{60.98} & 54.29 & 59.79 & \textbf{60.58} & 54.39 & \textbf{60.62} \\
        \hline
        \multirow{6}{*}{\rotatebox[origin=c]{90}{2-layer NN}}& \multirow{2}{*}{\begin{turn}{90} \dataset{PCFG} \end{turn}} & Sent. F1 & 81.61 &  \textbf{73.71} & 64.80 & 72.62 & \textbf{73.60} & 62.55 & \textbf{73.27} \\
        & & Corpus F1 & 71.65 & \textbf{66.18} & 57.16 & \textbf{65.36} & \textbf{66.01} & 53.36 & \textbf{65.92} \\
        \cline{2-10}
        & \multirow{2}{*}{\begin{turn}{90} \dataset{PTB} \end{turn}} & Sent. F1 & 78.77 & \textbf{71.32} & 64.89 & 70.15 & \textbf{70.33} & 63.23 & \textbf{70.59} \\
        & & Corpus F1 & 75.90 & \textbf{68.07} & 62.09 & \textbf{67.25} & \textbf{67.31} & 60.59 & \textbf{67.93} \\
        \cline{2-10}
        & \multirow{2}{*}{\begin{turn}{90} OOD \end{turn}} & Sent. F1 & 81.61 & \textbf{66.99} & 59.89 & \textbf{66.21} & \textbf{66.56} & 57.60 & \textbf{67.18} \\
        & & Corpus F1 & 71.65 & \textbf{63.89} & 56.74 & 63.30 & 63.81 & 54.60 & \textbf{64.54} \\
        \hline
    \end{tabular}
    \caption{Parsing results for different models under different settings using Linear and 2-layer neural net probes, when compared to Inside-Outside algorithm (IO). We report the best F1 score achieved using any of the layer's embeddings. 
    %IO denotes the results using t%A$i$L$j$ denotes the model with $i$ attention heads and $j$ layers. 
    Scores within 1\% of the max (except IO) in each row are highlighted. %The numbers come from a single run since the probe is stable across multiple runs.
    Models except A12L1 and A3L12 give decent parsing F1 scores, and models with more layers or heads tend to get better F1 scores in general.
    }
    \label{tab:parsing-results}
\end{table*}

\begin{table*}
    \centering
    \footnotesize
    \begin{tabular}{|c|cccccc|}
    \hline
         \makecell{Span \\Length} & A12L12 & A12L1 & A12L3 & A12L6 & A3L12 & A24L12 \\
    \hline
        $\ell = 2$ &  .88 / \textbf{.93} & .83 / .88 &  .88 / .91  &  .88 / \textbf{.92}  &  .86 / .88 & .87 / \textbf{.92} \\
        $\ell = 3$ &  .79 / \textbf{.90} & .74 / .84 &  .80 / .88  &  .79 / \textbf{.89}  &  .77 / .84 & .79 / \textbf{.89}  \\
        $\ell = 4$ &  .69 / \textbf{.86} & .65 / .77 &  .69 / .82  &  .69 / .84  &  .66 / .78 & .69 / \textbf{.85}  \\
        $\ell = 5$ &  .62 / .79 & .57 / .70 &  .62 / .77   &  .61 / \textbf{.81} &  .58 / .69 & .62 / .79  \\
        $\ell = 10$ & .51 / \textbf{.77} & .48 / .68 & .51 / .75 & .51 / \textbf{.78} & .51 / .61 & .51 / .73 \\
        \hline
    \end{tabular}
    \caption{Probing for the ``normalized'' marginal probabilities of spans at different lengths on different pre-trained models. We report the Pearson correlation between the predicted probabilities  and the span marginal probabilities computed by the Inside-Outside algorithm on \dataset{PTB} datasets, for both the linear and the 2-linear net probes (separated by /). 
    %Two numbers in each entry denote the correlations with a linear probe and a 2-layer neural net probe respectively on the final layer of the model. 
    The high correlation indicates that the MLM pre-trained models approximately encode the marginal span probabilities of the Inside-Outside algorithm during pre-training. 
    %The numbers come from a single run since the probe is stable across multiple runs.
    }
    \label{tab:probe-probs-ptb}
\end{table*}


\subsection{Probing for constituency parse trees}\label{sec:parse}

\looseness=-1 We probe the language models pre-trained on synthetic PCFG data and show that these models indeed capture the ``syntactic information'', in particular, the structure of the constituency parse trees. % underlying the input sentences.

%In this part, we probe the pre-trained language models trained on PCFG data and show that simple probes can parse decently well, verifying that pre-training on mask language modeling captures the synthetic information.

\looseness=-1 \paragraph{Experiment setup} We mostly follow the probing procedure in \citet{vilares2020parsing} that predicts the relative depth of common ancestors between different token pairs and then constructs the constituency tree. Given a sentence $w_1w_2\dots w_L$ with parse tree $T$, we denote $\text{depth}(i,i+1)$ the depth of the least common ancestor of $w_i,w_{i+1}$ in the parse tree $T$. We want to find a probe $f^{(\ell)}$ to predict the relative depth $\text{tar}(i) = \text{depth}(i,i+1) - \text{depth}(i-1,i)$ for position $i$. In \citet{vilares2020parsing}, the probe $f^{(\ell)}$ is linear, and the input to the probe $f^{(\ell)}$ at position $i$ is the concatenation of the embeddings at position $i$ and the BOS (or EOS) token. Besides the linear probe $f^{(\ell)}$, we also experiment with the probe where $f^{(\ell)}$ is a 2-layer neural network with 16 hidden neurons. We consider three settings for probing: train and test the probe on synthetic PCFG data (\dataset{PCFG}); train and test on \dataset{PTB} dataset (\dataset{PTB}); and train on the synthetic PCFG data while test on \dataset{PTB} (out of distribution, OOD). The OOD setting serves as a baseline for a syntactic probe on \dataset{PTB} since semantic relations do not appear in the pre-trained model or the probe.
\iffalse
In \dataset{PCFG} setting, we train and test the probe $f^{(\ell)}$ on the synthetic PCFG data we generated, and in \dataset{PTB} setting we train on \dataset{PTB} sections 02-21 and test on \dataset{PTB} section 22~\citep{marcus1993building} without removing the punctuations. In OOD setting we train the probe on the synthetic \dataset{PCFG} dataset, but test on the \dataset{PTB} section 22, excluding nearly all the semantic information contained in the probe itself.
\fi

\iffalse
\begin{table*}[]
    \centering
    \scriptsize
    \begin{tabular}{|c|c|c|ccccccc|}
    \hline
         & & & IO & A12L12 & A12L1 & A12L3 & A12L6 & A3L12 & A24L12 \\
    \hline
        \multirow{6}{*}{\rotatebox[origin=c]{90}{Linear}}& \multirow{2}{*}{\begin{turn}{90} \dataset{PCFG} \end{turn}} & Sent. F1 & 81.61 &  30.50 / \textbf{71.34} & 30.69 / 63.16 & 31.04 / 69.96 & 31.01 / \textbf{71.23} & 30.80 / 64.71 & 31.09 / \textbf{70.76} \\
        & & Corpus F1 & 71.65 &  22.27 / \textbf{63.01} &  22.19 / 54.24 & 22.37 / 61.54 & 22.79 / \textbf{62.57} & 22.37 / 55.36 & 22.64 / \textbf{62.56} \\
        \cline{2-10}
        & \multirow{2}{*}{\begin{turn}{90} \dataset{PTB} \end{turn}} & Sent. F1 & 78.77 &  30.54 / \textbf{69.31} & 30.58 / 62.99 & 30.33 / 68.22 & 30.34 / 68.13 & 30.16 / 61.56 & 31.09 / \textbf{68.79} \\
        & & Corpus F1 & 75.90 & 27.01 / \textbf{65.01} &  27.33 / 59.96 & 27.06 / \textbf{65.21} & 27.01 / \textbf{65.01} & 26.94 / 58.31 & 27.70 / \textbf{65.97} \\
        \cline{2-10}
        & \multirow{2}{*}{\begin{turn}{90} OOD \end{turn}} & Sent. F1 & 81.61 & 25.55 / \textbf{64.26} & 25.74 / 57.96 & 25.47 / 63.22 & 25.57 / \textbf{63.89} & 25.33 / 58.00 & 25.44 / \textbf{63.88} \\
        & & Corpus F1 & 71.65 & 21.77 / \textbf{60.98} & 21.91 / 54.29 & 21.69 / 59.79 & 21.73 / \textbf{60.58} & 21.54 / 54.39 & 21.74 / \textbf{60.62} \\
        \hline
        \multirow{6}{*}{\rotatebox[origin=c]{90}{2-layer NN}}& \multirow{2}{*}{\begin{turn}{90} \dataset{PCFG} \end{turn}} & Sent. F1 & 81.61 &  39.06 / \textbf{73.71} & 41.11 / 64.80 & 36.93 / 72.62 & 40.65 / \textbf{73.60} & 32.06 / 62.55 & 40.88 / \textbf{73.27} \\
        & & Corpus F1 & 71.65 & 29.53 / \textbf{66.18}  & 30.89 / 57.16 & 28.06 / \textbf{65.36} & 30.43 / \textbf{66.01} & 24.25 / 53.36 & 30.70 / \textbf{65.92} \\
        \cline{2-10}
        & \multirow{2}{*}{\begin{turn}{90} \dataset{PTB} \end{turn}} & Sent. F1 & 78.77 & 39.31 / \textbf{71.32} & 40.48 / 64.89 & 38.37 / 70.15 & 38.88 / \textbf{70.33} & 38.14 / 63.23 & 38.74 / \textbf{70.59} \\
        & & Corpus F1 & 75.90 & 36.50 / \textbf{68.07} & 37.62 / 62.09 & 35.28 / \textbf{67.25} & 36.08 / \textbf{67.31} & 35.35 / 60.59 & 36.04 / \textbf{67.93} \\
        \cline{2-10}
        & \multirow{2}{*}{\begin{turn}{90} OOD \end{turn}} & Sent. F1 & 81.61 & 33.33 / \textbf{66.99} & 38.19 / 59.89 & 34.00 / \textbf{66.21} & 37.21 / \textbf{66.56} & 33.95 / 57.60 & 29.83 / \textbf{67.18} \\
        & & Corpus F1 & 71.65 & 29.27 / \textbf{63.89} & 33.82 / 56.74 & 30.31 / 63.30 & 32.88 / 63.81 & 29.49 / 54.60 & 26.69 / \textbf{64.54} \\
        \hline
    \end{tabular}
    \caption{The parsing results (unlabelled F1 score) for different models under different settings. Linear and 2-layer NN denote the classifier for the probes respectively. The 2 scores in each entry denote the F1 score using the (un-contextualized) embeddings of the zeroth layer ($\ell = 0$) and the best F1 score achieved using one of the layer's (contextualized) embeddings. The IO column denotes the results for parsing using the Inside-Outside algorithm. A$i$L$j$ denotes the model with $i$ attention heads and $j$ layers. We highlight the scores that are within 1\% to the max in each row.}
    \label{tab:parsing-results}
\end{table*}
\fi


\looseness=-1 \paragraph{Experiment results}  \Cref{fig:probe-parsing-comparison} reveals a substantial difference between the probing outcomes of layer 0 embeddings and those of the best layer in all settings.  Both probing approaches profit greatly from the representations of subsequent layers. %bes are both sensitive to syntactic information we want to test.

\looseness=-1\Cref{tab:parsing-results} shows probing results for different settings (\dataset{PCFG}, \dataset{PTB}, and OOD), different probes (linear or a 2-layer neural net) on different models. Except for A12L1 and A3L12, the linear and neural net probes give decent parsing scores (> 70\% sentence F1 for neural net probes) in both \dataset{PCFG} and \dataset{PTB} settings. As for the OOD setting, the performances achieved by the best layer drop by about 5\% compared with \dataset{PCFG} and \dataset{PTB}, but they are still much better than the performance achieved by the $0$-th layer embeddings. In this setting, there is no semantic information even in the probe itself and thus gives a baseline for the probes on \dataset{PTB} dataset that only uses syntactic information. As a comparison, the naive baseline, Right-branching (RB), reaches $<40\%$ for both sentence and corpus F1 score~\citep{li2020empirical} on \dataset{PTB} dataset, and if we use layer 0's embeddings to probe, the sentence F1 is $<41\%$ in all settings for all models. Our positive results on syntactic parsing support the claim that pre-training language models using MLM loss can indeed capture the structural information of the underlying constituency parse tree.

%\looseness=-1The A12L12 model achieves 69.31\% and 71.32\% unlabelled F1 for linear and 2-layer neural net probes in the \dataset{PTB} setting. These results are lower than the labeled sentence F1 achieved by BERT and RoBERTa models pre-trained on natural language, which are 78.2\% and 82.6\%, respectively~\citep{vilares2020parsing,arps2022probing}. 
%This gap suggests that models pre-trained on natural language contain semantic cues that aid in parsing.

%, since in the \dataset{PTB} setting, the probes may also leverage the semantic information, and the only difference comes from the embeddings used to probe.

%As for the OOD setting, the performances achieved by the best layer drop by about 5\% compared with \dataset{PCFG} and \dataset{PTB}, but they are still much better than the performance achieved by the $0$-th layer embeddings. In this setting, there is no semantic information even in the probe itself, and thus gives a baseline for the probes on \dataset{PTB} dataset that only uses syntactic data. Our positive results on syntactic parsing support the claim that pretraining language models on masked language models can indeed capture syntactic information.

%\haoyu{currently I think the following discussion can be put into the appendix. then in the appendix, i will show more plots and results on the probes with 3 adjacent tokens as input.}

%\haoyu{we may discuss some potential problems for probes here, e.g., one can get high F1 by getting correct on very short spans.}

%\haoyu{third exp: TBA. compare the parsing results using the embeddings from different layers}

\begin{figure}[!th]
\begin{subfigure}[t]{0.49\textwidth}
    \centering
    \includegraphics[width=0.7\linewidth]{figs/probe_prob_comparison.pdf}
    \caption{Compare linear/2-layer NN probes under \dataset{PTB} setting. We observe: (a) 2-layer NN probe has better performance, and (b) the probes give better performance on 12th-layer embeddings.} 
    %the input comes from the $0$-th/$12$-th layer, and the probe is linear/2-layer neural net. A 2-layer neural net is a better probe for marginal probabilities compared with a linear model, while their }
    \label{fig:probe-prob-comparison}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.49\textwidth}
    \centering
    \includegraphics[width=0.7\linewidth]{figs/probe_prob_setting_comparison.pdf}
    \caption{Performance of 2-layer neural net probe on the $12$-th layer embeddings under different settings. The closer correlation performance of the probe across  settings (including OOD) indicates true marginal probabilities captured by the trained probe. }
    %The correlations results indicate the 12-th layer contains the syntactic information computed by the Inside-Outside algorithm and is not overfitting to the training dataset.}
    \label{fig:probe-prob-setting-comparison}
\end{subfigure}
\caption{Comparison between different probes for marginal probabilities on the A12L12 model. The y-axis denotes correlation between the prediction and the target, and the x-axis denotes probes for different lengths.}
\end{figure}

\subsection{Probing for the marginal probabilities}\label{sec:probe-marginal-probs}
%In the previous part, we show that pre-training using MLM can capture syntactic data. In this part, we want to understand more about how pre-training on MLM can capture syntactic information. We probe the pre-trained language models trained on PCFG data and show that the models also contain syntactic information like the marginal probabilities computed by the Inside-Outside algorithm, thus empirically verifying \Cref{thm:io-optimal-mlm} that pre-training on MLM may implicitly execute some approximated version of Inside-Outside algorithm, and thus can do well on parsing task.

\looseness=-1\Cref{sec:parse} verifies that language models can capture structure information of the parse trees, but we still don't know if the model executes the Inside-Outside algorithm proposed in \Cref{sec:construct-io,sec:mlmandio}.
%\Cref{sec:construct-io,sec:mlmandio} suggest that a possible mechanism is to execute the Inside-Outside algorithm pr
In this subsection, we test if model representations can be used to predict marginal probabilities computed in the Inside-Outside algorithm. 

\looseness=-1\paragraph{Experiment setup} We train a probe to predict the normalized marginal probabilities for spans with a specific length. Fix the span length $\ell$, for each sentence $w_1w_2\dots w_L$, denote $\ve_1, \ve_2,\dots,\ve_L$ the embeddings from the last layer of the pre-trained language model. We want to find a probe $f^{(\ell)}$ such that for each span $[i,i+\ell-1]$ with length $\ell$, the probe $f^{(\ell)}([\ve_i;\ve_{i+\ell-1}])$ predicts the normalized marginal probability of span $[i,i+\ell-1]$, i.e. $\text{tar}(i,i+\ell-1) = s(i,i+\ell-1) / \max_{j,j'}s(j,j')$,
where $s(i,j) = \max_A \mu(A,i,j)$ is the marginal probability of span $[i,j]$ and $\mu(A,i,j)$ is given by eq.~\ref{eq:marginal_probability}.
The input to the probe $[\ve_i;\ve_{i+\ell-1}]\in\R^{2d}$ is the concatenation of $\ve_i$ and $\ve_{i+\ell-1}$. To test the sensitivity of our probe, we also take the embeddings from the $0$-th layer as input to the probe $f^{(\ell)}$.

\looseness=-1We give two options for the probe $f^{(\ell)}$: (1) linear, and (2) a 2-layer neural network with 16 hidden neurons, since the relation between the embeddings and the target may not be a simple linear function. Similar to the \Cref{sec:parse}, we also consider three settings: \dataset{PCFG}, \dataset{PTB}, and OOD.
%(1) \dataset{PCFG}, where we train and test $f^{(\ell)}$ on the synthetic \dataset{PCFG} dataset, (2) \dataset{PTB}, where we train and test $f^{(\ell)}$ on the \dataset{PTB} dataset, and (3) OOD, where we train $f^{(\ell)}$ on the synthetic \dataset{PCFG} dataset and test on the \dataset{PTB} dataset.


\paragraph{Experiment results} 

\looseness=-1\Cref{fig:probe-prob-comparison} reports the correlation between the span marginal probabilities and the predictions of the 4 different probes for A12L12 model. For both linear and 2-layer neural net probes, changing the input from layer 0 to layer 12 drastically increases the predicted correlation, which again suggests that the uncontextualized embeddings don't contain enough information about the marginal probabilities. Besides, the neural net can predict better on layer 12 embeddings, but performs nearly the same on layer 0, suggesting that the neural network is a better probe in this setting. % (more sensitive to the information).

\looseness=-1\Cref{fig:probe-prob-setting-comparison} compares the probing results under three different settings. Surprisingly, we find that the probe can achieve high correlation with the real marginal probabilities under all settings. Furthermore, we observe that there is almost no drop in performance when changing the test dataset from \dataset{PCFG} to \dataset{PTB} (\dataset{PCFG} setting and OOD setting). This result implies that the probe, along with the embeddings, indeed contains the syntactic information computed by the Inside-Outside algorithm and is not overfitting to the training dataset.

\looseness=-1\Cref{tab:probe-probs-ptb} shows the probing results on different pre-trained models. The results show that the neural network probe is highly correlated with the target for most pre-trained models, except for A12L1 and A3L12 models. Surprisingly, even for length $10$ spans, the neural network probe still achieves an F1 score of up to 78\% for the best model. The high correlation suggests that the pre-trained models contain certain syntactic information computed by the Inside-Outside algorithm. Overall, the results indicate that MLM training may incentivize the model to approximate the Inside-Outside algorithm, thus validating our constructions in \Cref{sec:construction}.

\iffalse
\begin{table*}
\begin{subtable}[h]{\textwidth}
    \centering
    \scriptsize
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \makecell{Length\\ of span} & \dataset{PTB} & \makecell{\dataset{PTB}\\ sent length $\le 10$} & \makecell{\dataset{PTB}\\ $11 \le$ sent length $\le 20$} & \makecell{\dataset{PTB}\\ $21 \le$ sent length $\le 30$} & \makecell{\dataset{PTB}\\ $31 \le$ sent length $\le 40$} \\
    \hline 
    2 & .86 / .88 / .87 & .88 / .88 / .88 & .87 / .88 / .87 & .86 / .88 / .87 & .87 / .89 / .87 \\
    3 & .77 / .79 / .79 & .84 / .83 / .85 & .78 / .79 / .79 & .78 / .79 / .80 & .78 / .79 / .80 \\
    4 & .66 / .69 / .69 & .77 / .76 / .75 & .68 / .70 / .70 & .67 / .69 / .69 & .67 / .70 / .71 \\
    5 & .58 / .62 / .62 & .77 / .77 / .74 & .60 / .64 / .63 & .58 / .62 / .61 & .60 / .63 / .63 \\
    \hline
    \end{tabular}
    \caption{Linear probing for the ``normalized'' marginal probabilities at different lengths. The three numbers in each entry denote the results of models with 3, 12, and 24 attention heads respectively. All models have 12 layers and 768 embedding dimensions.}
    \label{tab:lp-probs-ptb-attn}
\end{subtable}

\begin{subtable}[h]{\textwidth}
    \centering
    \scriptsize
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \makecell{Length\\ of span} & \dataset{PTB} & \makecell{\dataset{PTB}\\ sent length $\le 10$} & \makecell{\dataset{PTB}\\ $11 \le$ sent length $\le 20$} & \makecell{\dataset{PTB}\\ $21 \le$ sent length $\le 30$} & \makecell{\dataset{PTB}\\ $31 \le$ sent length $\le 40$} \\
    \hline 
    2 & .83 / .88 / .88 / .88 & .84 / .89 / .88 / .88 & .84 / .89 / .89 / .88 & .82 / .88 / .88 / .88 & .83 / .89 / .88 / .89 \\
    3 & .74 / .80 / .79 / .79 & .83 / .84 / .83 / .83 & .75 / .80 / .79 / .79 & .75 / .80 / .79 / .79 & .75 / .81 / .79 / .79 \\
    4 & .65 / .69 / .69 / .69 & .73 / .76 / .77 / .76 & .67 / .70 / .70 / .70 & .65 / .69 / .70 / .69 & .65 / .71 / .70 / .70 \\
    5 & .57 / .62 / .61 / .62 & .76 / .76 / .75 / .77 & .60 / .63 / .63 / .64 & .58 / .61 / .62 / .62 & .58 / .63 / .62 / .63 \\
    \hline
    \end{tabular}
    \caption{Linear probing for the ``normalized'' marginal probabilities at different lengths. The four numbers in each entry denote the results of models with 1, 3, 6, and 12 layers respectively. All models have 12 attention heads and 768 embedding dimensions.}
    \label{tab:lp-probs-ptb-layer}
\end{subtable}

\begin{subtable}[h]{\textwidth}
    \centering
    \scriptsize
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \makecell{Length\\ of span} & \dataset{PTB} & \makecell{\dataset{PTB}\\ sent length $\le 10$} & \makecell{\dataset{PTB}\\ $11 \le$ sent length $\le 20$} & \makecell{\dataset{PTB}\\ $21 \le$ sent length $\le 30$} & \makecell{\dataset{PTB}\\ $31 \le$ sent length $\le 40$} \\
    \hline 
    2 & .88 / .93 / .92 & .74 / .88 / .88 & .88 / .94 / .93 & .90 / .93 / .93 & .89 / .93 / .93 \\
    3 & .84 / .90 / .89 & .49 / .84 / .86 & .82 / .90 / .90 & .86 / .90 / .90 & .86 / .91 / .90 \\
    4 & .78 / .86 / .85 & .09 / .81 / .83 & .79 / .85 / .82 & .82 / .85 / .85 & .74 / .88 / .86 \\
    5 & .69 / .79 / .79 & .10 / .76 / .89 & .67 / .84 / .80 & .66 / .80 / .77 & .74 / .83 / .78 \\
    \hline
    \end{tabular}
    \caption{Probing for the ``normalized'' marginal probabilities at different lengths with a 2-layer neural net. The three numbers in each entry denote the results of models with 3, 12, and 24 attention heads respectively. All models have 12 layers and 768 embedding dimensions.}
    \label{tab:nnp-probs-ptb-attn}
\end{subtable}

\begin{subtable}[h]{\textwidth}
    \centering
    \scriptsize
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \makecell{Length\\ of span} & \dataset{PTB} & \makecell{\dataset{PTB}\\ sent length $\le 10$} & \makecell{\dataset{PTB}\\ $11 \le$ sent length $\le 20$} & \makecell{\dataset{PTB}\\ $21 \le$ sent length $\le 30$} & \makecell{\dataset{PTB}\\ $31 \le$ sent length $\le 40$} \\
    \hline 
    2 & .88 / .91 / .92 / .93 & .89 / .91 / .90 / .88 & .89 / .93 / .93 / .94 & .88 / .91 / .93 / .93 & .89 / .92 / .93 / .93 \\
    3 & .84 / .88 / .89 / .90 & .86 / .88 / .84 / .84 & .84 / .85 / .90 / .90 & .85 / .90 / .90 / .90 & .86 / .88 / .90 / .91 \\
    4 & .77 / .82 / .84 / .86 & .80 / .90 / .84 / .81 & .80 / .86 / .87 / .85 & .80 / .84 / .84 / .85 & .78 / .84 / .84 / .88 \\
    5 & .70 / .77 / .81 / .79 & .87 / .88 / .80 / .76 & .74 / .83 / .83 / .84 & .73 / .80 / .81 / .80 & .73 / .79 / .79 / .83 \\
    \hline
    \end{tabular}
    \caption{Probing for the ``normalized'' marginal probabilities at different lengths with a 2-layer neural net. The four numbers in each entry denote the results of models with 1, 3, 6, and 12 layers respectively. All models have 12 attention heads and 768 embedding dimensions.}
    \label{tab:nnp-probs-ptb-layer}
\end{subtable}
\caption{Probing for the ``normalized'' marginal probabilities at different lengths with a linear model or a 2-layer neural net. We show the Pearson correlation between the predicted probabilities and the probabilities computed by the Inside-Outside algorithm on \dataset{PTB} datasets and its subsets partitioned by different lengths of sentences.}
\label{tab:probe-probs-ptb}
\end{table*}
\fi

\subsection{Control tasks}\label{sec:control-task-main}


\begin{table*}
    \footnotesize
    \centering
    \begin{tabular}{|c|c|ccccccccccccc|}
    \hline
         & & L0 & L1 & L2 & L3 & L4 & L5 & L6 & L7 & L8 & L9 & L10 & L11 & L12 \\
         \hline
        \multirow{3}{*}{\rotatebox[origin=c]{90}{Linear}} & pred. rel. depth & .606 & .760 & .789 & .796 & .800 & .803 & .803 & .803 & .802 & .801 & .800 & .800 & .799 \\
         & control task & .758 & .677 & .645 & .626 & .620 & .610 & .608 & .617 & .599 & .595 & .612 & .606 & .608 \\
         & selectivity & -.152 & .083 & .144 & .170 & .180 & .193 & .195 & .186 & .203 & \textbf{.206} & .188 & .194 & .191 \\
         \hline
        \multirow{3}{*}{\rotatebox[origin=c]{90}{NN}} & pred. rel. depth & .616 & .771 & .804 & .810 & .814 & .807 & .815 & .802 & .795 & .810 & .806 & .803 & .776 \\
         & control task & .861 & .793 & .758 & .667 & .728 & .653 & .653 & .668 & .678 & .693 & .680 & .697 & .687 \\
         & selectivity & -.245 & -.022 & .046 & .143 & .086 & .154 & \textbf{.162} & .134 & .117 & .117 & .126 & .106 & .089 \\ 
         \hline
    \end{tabular}
    \caption{Computing the selectivity of constituency parsing probes with linear and 2-layer NN architectures (see \cref{sec:parse} and \cref{sec:control-task-main}). The ``pred. rel. depth'' rows denote the probing results for the relative depth of common ancestors in the constituency parse tree using different layers' representations of A12L12. We report the predicting accuracy under the \dataset{PTB} setting where the probe is trained and tested on \dataset{PTB} dataset. The ``control task'' rows denote the predicting accuracy for the control task on \dataset{PTB} dataset using different layers' representations of A12L12. The selectivity is the difference between the original task performance and the control task performance. We can observe that for all layers representations, the probe with a linear classifier has a larger selectivity.}
    \label{tab:parsing-control-task}
\end{table*}

\looseness=-1In probing experiments, it is crucial to ensure that the probing performance accurately reflects the presence of the specific information we intend to test. 
Consequently, it is undesirable for the probe to possess excessive power and be capable of learning all aspects (see \cref{sec:preliminary} for further discussions). 
\citet{chen2021probing} utilize ``sensitivity'' to assess the extent to which the probe captures the targeted information. The ``sensitivity'' of a probe is defined as the difference in probing performance between the layer of interest and the 0-th layer.
% (see \cref{sec:parse} and \cref{sec:probe-marginal-probs} for further details). 
Intuitively, a large gap indicates that the probe fails to perform adequately using representations from the 0-th layer but achieves better performance when utilizing representations from a later layer, thus confirming the presence of the targeted information. 
%In situations where there are two probe choices (e.g., a linear classifier or a 2-layer neural network), the option exhibiting greater ``sensitivity'' should be selected as it captures a relatively higher amount of the targeted information.

\looseness=-1\citet{hewitt2019designing} introduced another metric, known as ``selectivity'', to assess the degree to which the probe captures the targeted information. Broadly speaking, \citet{hewitt2019designing} devised a specific task referred to as the ``control task'' to evaluate the probe's capability to align with specific types of random labels. Subsequently, ``selectivity'' is defined as the difference in performance between the probe for the original task, utilizing the layer of interest, and the probe for the control task, also utilizing the layer of interest. Intuitively, a large gap suggests that the probe lacks sufficient expressive power, resulting in the performance boost originating from the representations of the layer being probed. %thus confirming the presence of specific information. 
%Similarly, in scenarios involving two probe choices (e.g., a linear classifier or a 2-layer neural network), the option exhibiting greater ``selectivity'' should be preferred as it captures a relatively higher amount of the targeted information.

\looseness=-1Note that a probe with higher ``sensitivity'' does not necessarily imply larger ``selectivity''. Nevertheless, as demonstrated in the subsequent parts (and appendix), the metrics of ``sensitivity'' and ``selectivity'' align for both the constituency parsing probes and the marginal probability probes (\cref{sec:control-task}). We sketch the control task design and results for the constituency parsing probe, and defer the preliminaries of control tasks in~\citet{hewitt2019designing} and the control tasks experiments for marginal probabilities probe to \cref{sec:control-task}.

\paragraph{Control task for constituency parsing } For the constituency parsing in \cref{sec:parse}, we follow the design of control task for sequence labeling problems~\citep{hewitt2019designing}.
Specifically, we have $y_i = \text{tar}(i) = \text{depth}(i,i+1) - \text{depth}(i-1,i)$ for position $i$. Then for the control task, for each word $w$, we uniformly sample $\phi(w) \in \{-1,0,1\}$, and then define the labels for the control task as $\hat y_{1:T} = [\phi(x_1), \phi(x_2),\dots,\phi(x_T)]$.

\paragraph{\emph{Selectivity} is aligned with \emph{Sensitivity}}

\cref{tab:parsing-control-task} provides a summary of the performance of the constituency parsing probe, employing different architectures (linear classifier and a 2-layer neural network with 16 hidden neurons), on the original task, control task, as well as the selectivity.

\looseness=-1From \cref{tab:parsing-control-task}, the probe with a 2-layer NN achieves slightly higher accuracy in predicting the relative depth of common ancestors, leading to a higher F1 score in parsing. However, its performance on the control task surpasses that of the probe with a linear classifier by a significant margin. This suggests that when using the ``selectivity'' metric, the linear probe outperforms the 2-layer neural network probe in recovering the constituency parse tree, aligning with the conclusions drawn using the ``sensitivity metric'' (see Figure \ref{fig:probe-parsing-comparison}, where the sensitivity of the linear probe is greater than that of the 2-layer NN probe). Experiment results for marginal probability control task (\Cref{sec:control-task}) also support the alignment of \emph{Selectivity} and \emph{Sensitivity}.