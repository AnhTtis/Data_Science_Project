% MAX 7 pages + references

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai23}

%
\usepackage{times}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{multirow}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\usepackage{natbib}
\usepackage{pdfpages} 
\input{macros}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\usepackage{xcolor} 
\newcommand\pawel[1]{{\color{red} [\bf PW: #1]}}
\newcommand\lukasz[1]{{\color{blue} [\bf ≈ÅL: #1]}}

\pdfinfo{
/TemplateVersion (IJCAI.2023.0)
}

% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\begin{document}

\enlargethispage{-15cm}

\title{Reinforcement learning for optimization of energy trading strategy \\ Supplementary material}

\maketitle

In this supplementary material, we present details of our experiments and analyze the behavior of bidding strategies designated by the CMA-ES evolutionary algorithm and FARL. 

\appendix 

\section{Black-box strategy opitmized with A2C} 

Parameters of the A2C algorithm are presented in Table~\ref{tab:a2c-settings}.  

\begin{table}[!h]
\centering
\begin{tabular}{l | r}
Timesteps & 4 500 000 \\
Evaluation frequency & 9 000 \\
Episode length & 90 \\
\hline
Action space & 96, range $[-3, 3]$ \\
Observation space with weather data & 117, normalized \\
Observation space without weather data & 69, normalized \\
Reward space & $(-\infty, \infty)$ \\
\hline
Learning rate (\textit{learning\_rate}) & 0.0001 \\
Number of update steps (\textit{n\_steps}) & 90 \\
Discount (\textit{gamma}) & 0.9 \\
GAE coefficient (\textit{gae\_lambda}) & 1.0 \\
Entropy coefficient (\textit{ent\_coef}) & 0.1 \\
Value function coefficient (\textit{vf\_coef}) & 0.5 \\
RMSprop as optimizer (\textit{use\_rms\_prop}) & True \\
RMSprop epsilon (\textit{rms\_prop\_eps}) & 0.00001 \\
Use gSDE (\textit{use\_sde}) & False \\
\hline
Hidden layers neurons (\textit{net\_arch}) & 200 \\
Normalize input (\textit{normalize\_images}) & False \\
Activation function (\textit{activation\_fn}) & tanh \\
Orthogonal initialization (\textit{ortho\_init}) & True
\end{tabular}
\caption{Parameters of the A2C algorithm used for experiments. Names in brackets are taken from the Stable-Baselines3 library \citep{stable-baselines3}. Parameters not present in this table use default values. Neural network architecture is the same for actor and critic networks.}
\label{tab:a2c-settings}
\end{table}

\section{Simple Timing strategy} 

The Simple timing strategy based on buying the same amount at night and selling in the afternoon works reasonably, as presented in Figures \ref{fig:timing}. However, it is not able to adapt sufficiently to the circumstances, hence its performance is noticeably worse than that of A2C. 

\newpage 

\section{Opportunistic strategy} 

The more elaborate Opportunistic strategy achieves a~better return than its simple Timing counterpart. Its behavior is reasonable: It buys mostly at 0 am (at low prices) and sells mostly at 8 am and 4 pm (at high prices). However, it is still not able to, on average, improve the results over the reference balance. Also, the range of returns of this strategy is noticeably larger than those of other strategies. This strategy usually tries to place selling bids with low prices and high volumes and buying bids with high prices and low volumes. The wide range of returns between runs indicates that the optimization of this strategy is susceptible to getting stuck in local optima. Therefore, it is unlikely that this strategy's globally optimal parameters have been found with the CMA-ES algorithm. Its performance is presented in Figures \ref{fig:opportunistic}.

\section{FARL}

The FARL algorithm \citep{dong2021strategic} optimizes discrete actions, so to use it with our environment, we performed action discretization in two ways ($b$ is equal to maximum battery capacity divided by four):
\begin{itemize}
    \item eleven capacity levels ($0, \frac{b}{10}, \frac{2b}{10}, ..., \frac{8b}{10}, \frac{9b}{10}, b$), eleven price levels ($0, \frac{\bar p}{5}, \frac{2\bar p}{5}, ..., \frac{8\bar p}{5}, \frac{9\bar p}{5}, +\inf$), separate bids for buying and selling, which gives $11 \cdot 11 \cdot 2 = 242$ different actions. Note that many actions refer to doing nothing, e.g. buying/selling zero capacity for different prices.
    \item single "zero" action, six capacity levels ($\frac{b}{6}, \frac{2b}{6}, \frac{3b}{6}, \frac{4b}{6}, \frac{5b}{6}, b$), six price levels ($0, \frac{\bar p}{3}, \frac{2\bar p}{3}, \bar p, \frac{4\bar p}{3}, +\inf$), separate bids for buying and selling, which gives $1 + 6 \cdot 6 \cdot 2 = 73$ different actions. Here, there is only one action that allows for doing nothing - "zero" action. 
\end{itemize}
We discretized observations of the environment's state in the following way:
\begin{itemize}
    \item price from the same hour of the previous day ($p_p$) is converted to one-hot vector with one on index $\lfloor 10 \frac{p_p - p_{min}}{p_{max} - p_{min} + 1} \rfloor + 1$, with $p_{min}, p_{max}$ being minimum and maximum prices from the previous day (10 values)
    \item action from the previous hour ($a_{t-1}$) is converted to one-hot vector with one on $a_{t-1} - 1$ (73 or 242 values, depending on action discretization)
    \item battery state at the current hour ($b_t$) is converted to one-hot vector with one on index $\lfloor 10 b_t \rfloor$ if $b_t < 1$ else $9$ (10 values)
    \item current hour ($t$) is converted to one-hot vector with one on index $t$ (24 values)
\end{itemize}
We have also prepared a wrapper for our original environment, which converts actions and observations between original and discretized forms and allows the FARL algorithm to be executed with timesteps representing one hour instead of one day.

Parameters of the FARL algorithm are presented in Table~\ref{tab:farl-settings}. The discount is set to 1 to match it with the original paper. The number of timesteps is set so that it matches the number of days seen throughout the training, as the environment for FARL uses hours as timesteps, instead of days. 

\begin{table}[!h]
\centering
\begin{tabular}{l | r}
Timesteps & 108 000 000 \\
Evaluation frequency & 216000 \\
Episode length & 2160 \\
\hline
Action space & 73 or 242, discrete \\
Observation space & 117 or 286, binarized \\
Reward space & $(-\infty, \infty)$ \\
\hline
Learning rates ($\alpha$, $\beta$) & 0.0001 \\
Discount ($\gamma$) & 1.0 \\
\hline
\multirow{2}{*}{Exploration rate ($\varepsilon$)} & 1.0 - 0.1, linear decrease during \\
&10\% of timesteps, later constant \\
\end{tabular}
\caption{Parameters of the FARL algorithm used for experiments. }
\label{tab:farl-settings}
\end{table}

Bidding strategies optimized by the FARL algorithm  are presented in Figures \ref{fig:farl_73} and \ref{fig:farl_242}, for two different discretization settings of bidding prices and volumes. We can see that there is a possibility of an agent not placing any bids, as in Figure \ref{fig:farl_242}. This will allow the agent to earn from unscheduled sales, but in the end, the profits end up significantly lower than achievable. Also, FARL strategies keep the battery level very high which usually leads to unscheduled sell actions. 

\begin{figure*}
    \centering
    \begin{tabular}{c c}
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/battery_timing.png}} &\!\!\!\!\!
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/unscheduled_timing.png}} \\%&\!\!\!\!\!
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/amounts_timing.png}} &\!\!\!\!\!
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/prices_timing.png}} \\%&\!\!\!\!\!
    \end{tabular}
    \vspace{-1em}
    \caption{Plots for the Timing strategy trained with the CMA-ES algorithm. {\it Left-top:} Battery level. {\it Right-top:} Unscheduled energy buying/selling. {\it Left-bottom:} Bid volumes. {\it Right-bottom:} Bid prices (infinite buy bids prices were converted to 2000 PLN to make them visible on the plot).}
    \label{fig:timing}
\end{figure*}

\begin{figure*}
    \centering
    \begin{tabular}{c c}
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/battery_opportunistic.png}} &\!\!\!\!\!
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/unscheduled_opportunistic.png}} \\%&\!\!\!\!\!
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/amounts_opportunistic.png}} &\!\!\!\!\!
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/prices_opportunistic.png}} \\%&\!\!\!\!\!
    \end{tabular}
    \vspace{-1em}
    \caption{Plots for the Opportunistic strategy trained with the CMA-ES algorithm. {\it Left-top:} Battery level. {\it Right-top:} Unscheduled energy buying/selling. {\it Left-bottom:} Bid volumes. {\it Right-bottom:} Bid prices.}
    \label{fig:opportunistic}
\end{figure*}

\begin{figure*}
    \centering
    \begin{tabular}{c c}
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/battery_FARL_73.png}} &\!\!\!\!\!
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/unscheduled_FARL_73.png}} \\%&\!\!\!\!\!
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/amounts_FARL_73.png}} &\!\!\!\!\!
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/prices_FARL_73.png}} \\%&\!\!\!\!\!
    \end{tabular}
    \vspace{-1em}
    \caption{Plots for the strategy trained with the FARL algorithm \citep{dong2021strategic} with 73 different actions. {\it Left-top:} Battery level. {\it Right-top:} Unscheduled energy buying/selling. {\it Left-bottom:} Bid volumes. {\it Right-bottom:} Bid prices.}
    \label{fig:farl_73}
\end{figure*}

\begin{figure*}
    \centering
    \begin{tabular}{c c}
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/battery_FARL_242.png}} &\!\!\!\!\!
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/unscheduled_FARL_242.png}} \\%&\!\!\!\!\!
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/amounts_FARL_242.png}} &\!\!\!\!\!
    \scalebox{.85}{\includegraphics[width=0.48\textwidth]{images/prices_FARL_242.png}} \\%&\!\!\!\!\!
    \end{tabular}
    \vspace{-1em}
    \caption{Plots for the strategy trained with the FARL algorithm \citep{dong2021strategic} with 242 different actions. {\it Left-top:} Battery level. {\it Right-top:} Unscheduled energy buying/selling. {\it Left-bottom:} Bid volumes. {\it Right-bottom:} Bid prices.}
    \label{fig:farl_242}
\end{figure*}

\section{Battery capacity optimization}

Figure \ref{fig:balances_batteries} presents wallet balances on test simulations with different maximum battery capacities. The agent gains most of its income from selling its energy surplus. However, having a larger battery allows it to gain additional income on arbitration, i.e., buying electricity at low prices, keeping it in the battery, and selling at high prices. 

\begin{figure*}[!htb]
    \centering
    \scalebox{.85}{\includegraphics[width=\textwidth]{images/balance_batteries.png}}
    \vspace{-1em}
    \caption{Wallet balances achieved on testing data for different maximum battery capacities with A2C-optimized strategy with weather forecasts. Graphs are mean values averaged over 5 test runs, while streaks around them represent a range of achieved values.}
    \label{fig:balances_batteries}
\end{figure*}

\bibliographystyle{named} 
\input{main_supplementary.bbl}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

