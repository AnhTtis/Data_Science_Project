{
    "arxiv_id": "2303.16266",
    "paper_title": "On-line reinforcement learning for optimization of real-life energy trading strategy",
    "authors": [
        "Łukasz Lepak",
        "Paweł Wawrzyński"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2023-06-23"
    ],
    "latest_version": 2,
    "categories": [
        "cs.LG",
        "q-fin.TR"
    ],
    "abstract": "An increasing share of energy is produced from renewable sources by many small producers. The efficiency of those sources is volatile and, to some extent, random, exacerbating the problem of energy market balancing. In many countries, this balancing is done on the day-ahead (DA) energy markets. This paper considers automated trading on the DA energy market by a medium size prosumer. We model this activity as a Markov Decision Process and formalize a framework in which an applicable in real-life strategy can be optimized with off-line data. We design a trading strategy that is fed with the available environmental information that can impact future prices, including weather forecasts. We use state-of-the-art reinforcement learning (RL) algorithms to optimize this strategy. For comparison, we also synthesize a simple parametric trading strategy and optimize it with an evolutionary algorithm. Results show that our RL-based strategy generates the highest market profits.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16266v1",
        "http://arxiv.org/pdf/2303.16266v2"
    ],
    "publication_venue": null
}