% \vspace{-8mm}
\subsection{Related Work}\label{sec:related_work}

\noindent
{\bf Learning over combinations.}
%
To place structure on the space of combinations, we use tools from the theory of learning (sparse) Boolean functions, in particular, the Fourier transform. 
%
Sparsity of the Fourier transform as a complexity measure was proposed by \citet{karpovsky1976finite}, and was used by \cite{brandman1990spectral} and others to characterize and design learning algorithms for low-depth trees, low-degree polynomials, and small circuits. 
%
Learning Boolean functions is now a central topic in learning theory, and is closely related to many important questions in ML more broadly; see e.g.~\cite{mossel2003learning} for discussion of the $k$-Junta problem and its relation to relevant feature selection. 
%
We refer to \citet[Chapter 3]{o2008some} for further background on this area. 
%
In this paper, our focus is on general-purpose statistical procedures for learning sparse Boolean functions with noise. 
%
We build on the work of \cite{negahban2012learning} on variants of the Lasso procedure, and the works of \cite{breiman2017classification,syrgkanis2020estimation,klusowski2020sparse,klusowski2021universal} and others on CART. 
%
In particular, we highlight the works of \cite{negahban2012learning} and \cite{syrgkanis2020estimation} which respectively show that Lasso and CART can be used to efficiently learn sparse Boolean functions.
%
Recent work \cite{bravohermsdorff2023intervention} has also explored the use of graphical models to learn across combinations. 

\noindent {\bf Matrix completion.}  
%
Previous works have shown that imputing counterfactual outcomes with latent factor structure and potential unobserved confounding can be equivalently expressed as low-rank matrix completion with missing not at random data \citep{bai2019matrix, athey2021matrix, agarwal2020synthetic, agarwal2021causalmatrix}.
%
The observation that low-rank matrices may typically be recovered from a small fraction of the entries by nuclear-norm minimization has had a major impact on modern statistics \cite{candes2010power,recht2011simpler,candes2012exact}. 
%
In the noisy setting, proposed estimators have generally proceeded by minimizing risk subject to a nuclear-norm penalty, such as in the SoftImpute algorithm of \citep{mazumder2010spectral}, or minimizing risk subject to a rank constraint as in the hard singular-value thresholding (HSVT) algorithms analyzed by \cite{keshavan2009matrix,keshavan2010matrix,gavish2014optimal, chatterjee2015matrix}.
%
We refer the reader to \cite{ieee_matrix_completion_overview, nguyen2019low} for a comprehensive overview of this vast literature. 
%


\noindent
{\bf Causal latent factor models.}
%
There is a rich literature on how to learn personalized treatment effects for heterogeneous units. 
%
This problem is of particular importance in the social sciences and in medicine, where experimental data is limited, and has led to several promising approaches including instrumental variables, difference-in-differences, regression discontinuity, and others; see \cite{angrist1996identification,imbens2015causal} for an overview.
%
Of particular interest is the synthetic control method  \cite{abadie2010synthetic}, which exploits an underlying factor structure to effectively impute outcomes under control for treated units.
%
Building on this, recent works \citep{agarwal2020synthetic, agarwal2021causalmatrix} have shown how to use latent factor representations to efficiently share information across heterogeneous units and treatments.
%%
This paper generalizes these previous works to where a treatment is a combination of interventions and {\em most treatments have no units that receive it}.
%
To do so, we impose latent structure across combinations of interventions. 

%
In doing so, we aim to bridge such latent factor models with highly practical settings where multiple interventions are delivered simultaneously, such as slate recommendations, medicine (e.g. basket trials, combination therapies), conjoint analysis in surveys \cite{egami2019causal,haimmueller2014causal,goplerud2023estimating}, and factorial design experiments (e.g., multivariate tests in digital experimentation) \citep{duflo2007using,dasgupta2015causal,wu2011experiments,zhao2022regression} .
%
For example, structure across combinations is often assumed in the analysis of factorial design experiments, where potential outcomes are generally assumed to only depend on main effects and pairwise interactions between interventions \citep{bertrand2004emily,delaCuesta2021ImprovingTE,eriksson2014employers,george2005statistics}.
%
We discuss factorial design experiments in detail in Section \ref{sec:combinatorial_inference_applications}.
%



%{\color{red} Add some cites from factorial design (e.g., Peng Ding) \& conjoint analysis literature (e.g., Imai, Hainmuller) --- Ask Peng for right papers to cite.}



