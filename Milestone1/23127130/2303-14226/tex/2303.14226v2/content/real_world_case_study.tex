\section{Real World Case Study}
\label{sec:real_world_case_study}
This section details a real-world data experiment on recommendation systems for sets of movie ratings, comparing \method~to the algorithms listed above.
%
Further, we empirically validate that our key modeling assumptions (i.e., low-rank condition of $\mathcal{A}$ and sparsity of donor unit Fourier coefficients) hold in this dataset. 
%
For all methods, hyper-parameters are chosen via $5-$fold CV.
%
Additionally, the donor set $\mathcal{I}$ is chosen via the procedure described in Section \ref{sec:estimator_descripton}.

\noindent \textbf{Data and Experimental Set-up.} We use data collected in \cite{sharma2019sets} which consists of user ratings of sets of movies. 
%
Specifically, users were asked to provide a rating of $1$-$5$ on a set of $5$ movies chosen at random. 
%
This resulted in a total of ratings from $854$ users over $29,516$ sets containing $12,549$ movies.
%
$80\%$ of each user's ratings are chosen as the training set, and the other $20\%$ as the test set.
%



\noindent \textbf{Results.} We measure the RMSE averaged over 5 repetitions for all methods, and display the results in the Table below. 
with  \method~outperforming all other approaches.
%
The performance gap between \method~and other methods demonstrates the benefit of only performing the horizontal regression on the units with sufficient observations (i.e., the donor units), and using PCR for the non-donor units that have an insufficient number of measurements.

\begin{table} [H]
\centering
\footnotesize
\begin{tabular}{lrrrr}
\toprule
Method   & \textbf{\method} & \texttt{SoftImpute} & \texttt{IterativeSVD} & Lasso \\
\midrule
RMSE & \textbf{0.30} $\pm$ 0.03 &  0.38 $\pm$ 0.02  &  0.38 $\pm$ 0.02 & 0.43 $\pm$ 0.05 \\
\bottomrule
\end{tabular}
\label{tab:ratings_results}
\caption{\method~outperforms other approaches for the real-world experiment on sets of ratings for movies.}
\end{table}

\noindent \textbf{Key Assumptions of \method~hold.} We also verify that our two key modeling assumptions (i.e., low-rankness and sparsity of $\mathcal{A}$) hold in this dataset. 
%
For the low-rank condition,the singular value spectrum of movies rated by all users is plotted on a log-scale in Figure \ref{fig:singular_spectrum}. 
%
The plot shows the outcomes (and hence the Fourier coefficients) are low-rank. 
%
To investigate sparsity, we examine $\hat{\balpha}_u$ for the donor set. 
%
The MSE averaged across all donor units on the test set was 0.22, indicating that the estimated Fourier coefficient is an accurate representation of the true underlying Fourier coefficient. 
%
Further, the estimated donor unit Fourier coefficients are indeed sparse, and on average have 8.7\% non-zero coefficients. 


\begin{figure}[htbp]
    \centering
    \includegraphics [width = 0.6\textwidth]{figures/singular_value_spectrum.png}
    \caption{Singular value spectrum of user ratings on sets of movies. Inspecting the singular spectrum shows that the matrix of observed ratings is low-rank.}
    \label{fig:singular_spectrum}
\end{figure}

%the gap between \method~and the Lasso shows the benefit of first estimating the outcomes of the donor set, and then transferring these estimated outcomes to non-donor units which have a number of insufficient measurements.

%that highlight the empirical effectiveness of our approach. 
%The data is publicly available at \url{https://grouplens.org/datasets/learning-from-sets-of-items-2019/}, and more details about the data collection process can be found in \cite{sharma2019sets}. 
%


%\noindent \textbf{Comparison Methods.} As in the numerical simulations, we compare \method~to matrix completion algorithms: \texttt{SoftImpute} \cite{mazumder2010spectral}, and \texttt{IterativeSVD} \cite{troyanskaya2001missing}. 
%
%These methods require that the rank of the underlying matrix be provided as a hyper-parameter. This was chosen via $5$-fold cross-validation (CV). 
%
%We also compare \method~to the Lasso, where we tune the regularization parameter $\lambda$ via $5$-fold CV. 
%
%For \method, we tune all hyper-parameters via $5$-fold CV. 
%
%Additionally, we choose the donor set via the approached outlined in the manuscript.
%two of the key assumptions, the low-rank condition on the matrix of outcomes and sparsity of donor unit Fourier coefficients, hold in this real-world dataset. 
% (using a log-scale for the magnitude of the spectrum) \textbf


%For the sparsity condition, we investigate the Lasso model that was learnt for the donor units. 
%