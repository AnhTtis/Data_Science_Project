\section{Identification of Potential Outcomes}
\label{sec:identification}
\vspace{-2mm}
%
We show $\E[Y^{(\pi)}_{n} \mid \mathcal{A}]$ can be written as a function of observed outcomes, i.e., we establish identification of our target causal parameter.
%
As discussed earlier, our model allows for \emph{unobserved confounding}: whether or not a unit is seen under a combination may be correlated with its potential outcome under that combination due to unobserved factors, as long as certain conditions are met.  
%
We introduce necessary notation and assumption required for our result. 
%
For a unit $n \in [N]$, denote the subset of combinations we observe them under as $\Pi_n \subseteq \Pi$. 
%
%Recall from Section \ref{sec:notation} that $\bchi^{\pi} \in \mathbb{R}^{2^p}$ refers to the vector of Fourier characteristics for a given combination $\pi$. 
%
For $\pi \in \Pi$, let $\tilde{\bchi}^{\pi}_n \in \mathbb{R}^{2^p}$ denote the restricted Fourier characteristic vector where we zero out all coordinates of $\bchi^{\pi} \in \mathbb{R}^{2^p}$ that correspond to the coefficients of $\balpha_n$ which are zero. 
%
For example, if $\balpha_n = (1,1,0,0,\ldots 0)$ and $\bchi^{\pi} = (1,1,\ldots 1)$, then  $\tilde{\bchi}^{\pi}_n = (1,1,0, \ldots 0)$. 
%
We then make the following assumption.
%(recall the definition from Section \ref{sec:notation})


%Additionally, we let $P_{n,S}$ be the projection matrix to the subspace spanned by the non-zero coordinates of $\bm{\alpha}_n$, and for any vector $\bm{x} \in \mathbb{R}^{2^p}$, denote $\Tilde{\bm{x}} = P_{n,S}\bm{x}$.


\begin{assumption}[Donor Units]
\label{ass:donor_set_identification} Assume there exists a set of ``donor units'' $\mathcal{I} \subset [N]$, such that the following two conditions hold: 
\vspace{-2mm}
\begin{enumerate}[leftmargin=*]
 \item [(a)] Horizontal span inclusion: For any donor unit $u \in \mathcal{I}$ and combination $\pi \in \Pi$, suppose  $\tilde{\bchi}_u^{\pi} \in  span(\tilde{\bchi}_u^{\pi_i}: \pi_i \in \Pi_u)$. That is, there exists $\bbeta_{\Pi_u}^{\pi} \in \mathbb{R}^{|\Pi_{u}|}$ such that $\tilde{\bchi}_u^{\pi} = \sum_{\pi_{i} \in  \Pi_{u}} \beta_{\pi_i}^{\pi} \tilde{\bchi}_u^{\pi_i}.$
\vspace{-2mm}
 \item [(b)]  Linear span inclusion: For any unit $n  \in [N] \setminus \mathcal{I}$, suppose $\balpha_{n} \in span(\balpha_{u} : u \in \mathcal{I})$. That is, there exists $\bw^{n}$ such that $\balpha_{n} = \sum_{u \in \mathcal{I}}w_{u}^{n}\balpha_{u}$
\end{enumerate}
%
\end{assumption}
%
\vspace{-1.5mm}
%
Horizontal span inclusion requires that the set of observed combinations for any ``donor'' unit is ``diverse'' enough that the projection of the Fourier characteristic for a target intervention is in the span of characteristics of observed interventions for that unit. 
%
Linear span inclusion requires that the donor unit set is diverse enough such that the Fourier coefficient of any ``non-donor'' unit is in the span of the Fourier coefficients of the donor set. 
%

\noindent \textbf{Motivating example.} 
%
The following serves as motivation for existence of a donor set $\mathcal{I}$ satisfying Assumption \ref{ass:donor_set_identification}. 
%
Suppose Assumption \ref{ass:observation_model} holds and that  each unit belongs to one of $r$ \emph{types}.
%
That is, for all $n \in [N]$,
$\balpha_n \in \{\balpha(1),\balpha(2),\ldots,\balpha(r)\} \subset \mathbb{R}^{2^p},$ where each $\balpha(i)$ is $s$-sparse. 
%
Having only $r$ distinct sets of Fourier coefficients implies the low-rank property in Assumption \ref{ass:observation_model} (a). 
%
Suppose the donor set $\mathcal{I} \subset [N]$ is chosen by sampling a subset of units independently and uniformly at random with size satisfying $\Omega(r\log(r/\gamma))$. 
%
Similarly, sample $\Pi_\mathcal{I} \subset \Pi$ combinations independently and uniformly at random with size satisfying $\Omega(s\log(r|\mathcal{I}|/\gamma))$, and assign all donor units this set of combinations. 
%
Then, the following result shows this sampling scheme ensures both horizontal and linear span inclusion are satisfied with high probability as long as there are $\Omega(N)$ units of each type.
%

\begin{proposition}
\label{prop:motivating_example}
Let Assumptions \ref{ass:observation_model} and Assumptions \ref{ass:selection_on_fourier} hold. Moreover, suppose that for some $c > 0$, there are at least $cN/r$ units of each type. Then, under the proposed sampling scheme described above, Assumption \ref{ass:donor_set_identification} is satisfied with probability at least $1 - \gamma$.  
\end{proposition}
%
Proposition \ref{prop:motivating_example} shows that (ignoring logarithmic factors) sampling $r$ units and assigning these units $s$ combinations at random is sufficient to induce a valid donor set. 
%
In Section \ref{sec:experimental_design}, we show that Assumption \ref{ass:donor_set_identification} holds even when we relax our assumption that there are only $r$ types of units. 
%
Specifically, it is established that a randomly selected donor set of size $\omega(r\log(rs))$ will satisfy linear span inclusion as long as the $r$ non-zero singular values of the matrix $\mathcal{A}$ are of similar magnitude (see Assumption \ref{ass:balanced_spectrum} below).
%
Note that the motivating example discussed above does not induce unobserved confounding since the treatment mechanism is completely randomized (i.e., $\mathcal{D}$ does not depend on $\mathcal{A}$).
%
Hence, next we present a simple but representative example that both induces unobserved confounding and satisfies Assumption \ref{ass:donor_set_identification}.


\noindent \textbf{Natural model of unobserved confounding.} For any unit $n$, suppose  $\balpha_n \in \{\balpha(1) = (1, 1, 4, 0 \ldots, 0), \ \balpha(2) =(1, 1, 5, 0 \ldots, 0), \ \balpha(3) = (0.5, 0.5, 2, 0 \ldots, 0), \ \balpha(4) = (0.5, 0.5, 2.5, 0 \ldots, 0)\}$.
%
One can verify $\text{rank}(\mathcal{A}) = 2 $.
%
Define the treatment assignment to be such that combination $\pi$ for unit $n$ is observed only if $| \langle \balpha_n, \bchi^{\pi} \rangle | \geq 2$ (i.e., $| \mathbb{E}[Y^{(\pi)}_{n}] | \ge 2$).
%
Missingness patterns where only outcomes with large absolute values are observed is common in applications such as recommendation engines, where one is only likely to observe ratings for combinations that users either strongly like or dislike.
%
For units of type $\{\balpha(3),\balpha(4)\}$, we verify in Appendix \ref{subsec:proofs_natural_model} that they do not satisfy horizontal span inclusion (i.e., Assumption \ref{ass:donor_set_identification} (a) does not hold). 
%
For units of type $\{\balpha(1),\balpha(2)\}$, combinations $\{\pi_1,\pi_2,\pi_3,\pi_4\}$ with the following binary representations $\{v(\pi_1) = (1,1,1,1,\ldots,1), v(\pi_2) = (1,-1,-1,1,\ldots,1)\},v(\pi_3) = (1,-1,1,1,\ldots,1),v(\pi_4) = (1,1,-1,1,\ldots,1)$ are observed. 
%
These combinations have associated restricted Fourier characteristics $\Tilde{\bchi}^\pi$ as follows: $\{\Tilde{\bchi}^{\pi_1} = (1,1,1,0,\ldots,0), \Tilde{\bchi}^{\pi_4} = (1,-1,-1,0,\ldots,0)\}, \Tilde{\bchi}^{\pi_3} = (1,-1,1,0,\ldots,0),\Tilde{\bchi}^{\pi_2} = (1,1,-1,0,\ldots,0)$. 
%
One can verify that these observed combinations ensure that horizontal span inclusion holds for units with type $\{\balpha(1),\balpha(2)\}$.
%
Since $\text{rank}\{\balpha(1),\balpha(2)\} =2$, vertical span inclusion also holds.
%
It is straightforward to generalize this example to setting with $r$ types.


\vspace{-3mm}
\subsection{Identification Result}
\vspace{-2mm}
\noindent Given these assumptions, we now present our identification theorem. 
\label{subsec:identification_theorem}

\begin{theorem}
\label{thm:identification}
Let Assumptions \ref{ass:observation_model}, \ref{ass:selection_on_fourier}, and \ref{ass:donor_set_identification} hold. Given $\bbeta_{\Pi_u}^{\pi}$ and $\bw_u^{n}$ defined in Assumption \ref{ass:donor_set_identification}, we have
\noindent

\noindent (a) Donor units: For $u \in \mathcal{I}$, and $\pi \in \Pi$, 
$
 \E[Y^{(\pi)}_{u} ~ | ~ \mathcal{A}]  =  \sum_{\pi_u \in \Pi_{u}} \beta_{\pi_{u}}^{\pi}
 \E[Y_{u,\pi_{u}} \ | \  \mathcal{A}, \ \mathcal{D}].
$

\noindent
(b) Non-donor units: For $n \in [N] \setminus \mathcal{I}$, and $\pi \notin \Pi_n$,
$
\E[Y^{(\pi)}_{n} ~ | ~ \mathcal{A}] = \sum_{u \in \mathcal{I},\pi_u \in \Pi_u}w_{u}^{n}  \beta_{\pi_{u}}^{\pi}  \E[Y_{u,\pi_u} \ | \  \mathcal{A}, \ \mathcal{D}].
$
\end{theorem}
% %

\noindent Theorem \ref{thm:identification} gives conditions under which the donor set $\mathcal{I}$ and the treatment assignments $\mathcal{D}$ are sufficient to recover the full set of unit specific potential outcomes $\E[Y_n^{(\pi)}|\mathcal{A}]$ in the noise-free limit.
%
Part (a) establishes that for every donor unit $u \in \mathcal{I}$, the causal estimand can be written as a function of its \emph{own} observed outcomes $\E[\bY_{\Pi_u}]$, given knowledge of $\bbeta^{\pi}_{\Pi_u}$. 
%
Part (b) states that the target causal estimand $\E[Y_n^{(\pi)}]$ for a non-donor unit and combination $\pi$ can be written as a linear combination of the outcomes of the donor set $\mathcal{I}$, given knowledge of $\bw_n^n$.
%
Previous work that establishes identification under a latent factor model  requires a growing number of donor units to be observed under all treatments \cite{agarwal2021causalmatrix}.
%
This is infeasible in our setting because \emph{the vast majority of combinations have no units that receive it}.
%
As a result, one has to first identify the outcomes of donor units under all combinations (part (a)), before transferring them to non-donor units (part (b)).
%
In order to do so, Theorem \ref{thm:identification} suggests that the key quantities in estimating $\E[Y_n^{(\pi)}]$ for any unit-combination pair $(n,\pi)$ are $\bbeta_{\Pi_u}^{\pi}$ and $\bw_u^n$. 
%
In the following section, we propose an algorithm to estimate both $\bbeta_{\Pi_u}^{\pi}$ and $\bw_u^n$, as well as concrete ways of determining the donor set $\mathcal{I}$. 




%ormally verify Assumption \ref{ass:donor_set_identification} under a natural model of unobserved confounding.
%


% \textcolor{blue}{
% \textbf{Observational settings.}
% Theorem  \ref{thm:identification} allows for non-experimental data with unobserved confounding in the following sense: the observation pattern $\mathcal D$ may depend on the unit-specific latent variables $\mathcal{A} ]= [\balpha_n]_{n \in [N]}$, which in turn determine the potential outcomes $\E[Y_n^{(\pi)}|\mathcal{A}]$, so long as Assumption \ref{ass:donor_set_identification} holds.
% %
%  Indeed, if (a) and (b) are satisfied then we may recover $\balpha$. If selection on latent factors holds, that is, $\E[\epsilon^\pi_n|\mathcal{A}]=0$, we then have $\langle \balpha_n, \bm{\chi}^\pi \rangle = \E[Y_n^{(\pi)}|\mathcal{A}]$.
% %
% In experimental settings, we can formally verify that assumptions (a) and (b) hold given a sufficient number of observations; see the example above for an illustration and Section \ref{sec:experimental_design} for details. In observational settings, one may need to observe more unit-treatment combinations in order to satisfy assumptions (a) and (b); however, we verify in simulation experiments that our estimator performs well under certain forms of unobserved confounding; see Appendix \ref{sec:app_sims}. }


%$| \langle \balpha(3), \bchi^{\pi} \rangle | \leq 3/8$ and $| \langle \balpha(4), \bchi^{\pi} \rangle | \leq 1/2$ for all combinations $\pi \in \Pi$.
%
%Hence, units with Fourier coefficient type belonging to $\{\balpha(3),\balpha(4)\}$ do not satisfy horizontal span inclusion (i.e., Assumption \ref{ass:donor_set_identification} (a))
%
%For units with type belonging to $\{\balpha(1),\balpha(2)\}$, we observe at least the combinations $\{\pi_1, \pi_2,\pi_3\}$ with associated Fourier characteristics: $\{\bchi^{\pi_1} = (1,1,1,1,\ldots,1), \bchi^{\pi_2} = (-1,1,1,1,\ldots,1), \bchi^{\pi_3} = (1,-1,1,1,\ldots,1)$. 
%
%One can check that these observed combinations ensure that horizontal span inclusion holds for  for units with type $\{\balpha(1),\balpha(2)\}$.
%
%Further, since $\text{rank}\{\balpha(1),\balpha(2)\} =2$, vertical span inclusion also holds.}
%