{
    "arxiv_id": "2303.14358",
    "paper_title": "Multi-view knowledge distillation transformer for human action recognition",
    "authors": [
        "Ying-Chen Lin",
        "Vincent S. Tseng"
    ],
    "submission_date": "2023-03-25",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Recently, Transformer-based methods have been utilized to improve the performance of human action recognition. However, most of these studies assume that multi-view data is complete, which may not always be the case in real-world scenarios. Therefore, this paper presents a novel Multi-view Knowledge Distillation Transformer (MKDT) framework that consists of a teacher network and a student network. This framework aims to handle incomplete human action problems in real-world applications. Specifically, the multi-view knowledge distillation transformer uses a hierarchical vision transformer with shifted windows to capture more spatial-temporal information. Experimental results demonstrate that our framework outperforms the CNN-based method on three public datasets.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.14358v1"
    ],
    "publication_venue": null
}