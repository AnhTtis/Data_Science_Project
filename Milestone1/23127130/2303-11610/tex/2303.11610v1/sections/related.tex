%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related work}

%-----------------------------------
\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{images/method/main_chart.pdf}
    \vspace{-.6cm}
    \caption{Overview of \ourmethod.
    We random augment the input point cloud twice and extract point-level features $\mathcal{F}$ with the shared model $f_\xi$. 
    $\mathcal{F}$ are used to obtain pseudo-labels in the online pseudo-labelling. 
    We forward $\mathcal{F}$ to a novel $f_n$ and a base $f_b$ segmentation layer to output the novel and base predictions, respectively. We optimise our network by minimising a global objective function based on cross entropy.}
    \label{fig:main_chart}
\end{figure*}
%-----------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent \textbf{Point cloud semantic segmentation} can be performed at the point level~\cite{qi2017pointnet++}, on range view maps~\cite{ronneberger2015u}, and by voxelising the input points~\cite{zhou2018voxelnet}. 
Point-level networks process the input without intermediate representations. Examples of these include PointNet~\cite{qi2017pointnet}, PointNet++~\cite{qi2017pointnet++}, RandLA-Net~\cite{hu2020randla}, and KPConv~\cite{thomas2019kpconv}.
PointNet~\cite{qi2017pointnet} and PointNet++~\cite{qi2017pointnet++} are based on a series of multi-layer perceptron where PointNet++ introduces global and local feature aggregation at multiple scales. 
RandLA-Net~\cite{hu2020randla} uses random sampling, attentive pooling, and local spatial encoding. 
KPConv~\cite{thomas2019kpconv} employs flexible and deformable convolutions in a continuous input space. 
Point-level networks are computationally inefficient when large-scale point clouds are processed. 
Range view architectures~\cite{milioto2019rangenet++} and voxel-based approaches~\cite{choy20194d} are more computationally efficient than their point-level counterpart. 
The former requires projecting the input points on a 2D dense map, processing input maps with 2D convolutional filters~\cite{ronneberger2015u}, and re-projecting predictions to the initial 3D space. 
SqueezeSeg networks~\cite{wu2018squeezeseg, wu2019squeezesegv2}, 3D-MiniNet~\cite{alonso2020MiniNet3D}, RangeNet++~\cite{milioto2019rangenet++}, and PolarNet~\cite{zhang2020polarnet} are examples of this category. 
Although they are more efficient, these approaches tend to lose information during the projection and re-projection phase.
The latter includes 3D quantisation-based approaches that discretise the input points into a 3D voxel grid and employ 3D convolutions~\cite{zhou2018voxelnet} or 3D sparse convolutions~\cite{SubmanifoldSparseConvNet, choy20194d} to predict per-voxel classes. VoxelNet~\cite{zhou2018voxelnet}, SparseConv~\cite{SubmanifoldSparseConvNet, 3DSemanticSegmentationWithSubmanifoldSparseConvNet}, MinkowskiNet~\cite{choy20194d}, Cylinder3D~\cite{zhu2021cylindrical}, and (AF)$^2$-S3Net~\cite{ran2021af2s3net} are architectures belonging to this category. These approaches tackle point cloud segmentation in the supervised settings, whereas we tackle novel class discovery with labelled base classes and unlabelled novel classes.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent \textbf{Novel class discovery} (NCD) is explored for 2D classification~\cite{han2019learning, zhong2021neighborhood, fini2021unified, joseph2022novel, roy2022class, jia2021joint, zhong2021openmix, vaze2022generalized, yang2022divide} and 2D segmentation~\cite{zhao2022novel}. 
NCD is more complex than standard semi-supervised learning~\cite{souly2017semi, zhang2020wcp, tang2016large}. In semi-supervised learning, labelled and unlabelled samples belong to the same classes, while in NCD, novel and base samples belong to disjoint classes. 
Han et al.~\cite{han2019learning} pioneered the NCD problem for 2D image classification. 
A classification model is pre-trained on a set of base classes and used as feature extractor for the novel classes. 
They then train a classifier for the novel classes using the pseudo-labels produced by the pre-trained model. 
Zhong et al.~\cite{zhong2021neighborhood} introduced neighbourhood contrastive learning to generate discriminative representations for clustering. 
They retrieve and aggregate pseudo-positive pairs with contrastive learning, encouraging the model to learn more discriminative representations. 
Hard negatives are obtained by mixing labelled and unlabelled samples in the feature space.
UNO~\cite{fini2021unified} unifies the two previous works by using a unique classification loss function for both base and novel classes, where pseudo-labels are processed together with ground-truth labels. 
NCD without Forgetting~\cite{joseph2022novel} and FRoST~\cite{roy2022class} further extend NCD to the incremental learning setting. 
EUMS~\cite{zhao2022novel} is the only approach analysing the NCD problem for semantic segmentation. Unlike image classification, the model has to classify each pixel and handle multiple classes in each image. EUMS consists of a multi-stage pipeline using a saliency model to cluster the latent representations of novel classes to produce pseudo-labels. Moreover, entropy-based uncertainty and self-training are used to overcome noisy pseudo-labels while improving the model performance on the novel classes. In this work, we tackle the problem of NCD in 3D point cloud semantic segmentation. Unlike previous works, our problem inherits the challenges from the fields of 2D semantic segmentation~\cite{deeplabv3plus2018, chen2017deeplab} and 3D point cloud segmentation~\cite{choy20194d, saltori2022cosmix, milioto2019rangenet++}. From 2D semantic segmentation, it inherits the additional challenges of multiple novel classes in the same image and the strong class unbalance. From 3D point cloud segmentation, we inherit the sparsity of input data, the different density of point cloud regions and the inability to identify foreground and background. The latter are not present in 2D segmentation~\cite{zhao2022novel}. 
Unlike \cite{zhao2022novel} that use K-Means, we formulate clustering as an optimal transport problem to avoid degenerate solutions (i.e.~all data points may be assigned to the same label and learn a constant representation)~\cite{Asano2020, mei2022data}.
Lastly, related to EUMS, REAL is proposed for open-world 3D semantic segmentation~\cite{cen2022open}, where both known and unknown points have to be segmented.
Unlike NOPS, all the unknown points belong to a single class and it is the task of a human annotator to separately label the novel classes.
Then, these labels are used to update the base model by incrementally learning the novel classes.

 