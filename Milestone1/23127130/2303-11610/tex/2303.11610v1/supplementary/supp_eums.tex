\section{Adapting NCD for 2D images to 3D} \label{sec:eums_3D}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{images/supplementary/EUMS.pdf}
    \caption{Overview of EUMS$^\dag$, our adaptation of the method proposed by Zhao et al.~\cite{zhao2022novel}. We first pre-train $f_\xi$ and $f_b$ considering only the base points in each point cloud. Using $f_\xi$, we extract the features of the novel points in each scene, that are filtered with the selection function $\Psi(\cdot)$. Then, we produce the pseudo-labels for the selected novel points by using the k-means algorithm. Lastly, we plug a new segmentation head $f_c$ into $f_\xi$ and fine-tune the complete model on both novel and base points, considering pseudo-labels and ground-truth labels respectively.}
    \label{fig:eums_chart}
\end{figure*}

One of our contribution is the adaptation of EUMS~\cite{zhao2022novel}, proposed for NCD in 2D image semantic segmentation, to 3D data. 
As some of the EUMS assumptions for the 2D case do not hold in the 3D point cloud domain, we introduce some changes in the proposed baseline. 
We name this adapted version as EUMS$^\dag$.

As in the original implementation, EUMS$^\dag$ consists of three consecutive steps: i) pre-training, ii) pseudo-labelling and iii) fine-tuning. 
The block diagram of EUMS$^\dag$ is illustrated in Fig.~\ref{fig:eums_chart}.
We first pre-train our model $f_\xi \circ f_b$ on the base classes only, where $f_\xi$ is the feature extractor, $f_b$ is the segmentation head for the base classes and $\circ$ is the composition operator.
Then, we generate the pseudo-labels considering the features extracted by $f_\xi$ and filtered with the selection function $\Psi(\cdot)$ working on the whole dataset, where $\Psi$ is a random selection function.
Lastly, we fine-tune the architecture $f_\xi \circ f_c$ jointly on the labelled base points and on the pseudo-labelled novel points, where $f_c$ is the segmentation head for both base and novel classes.
Here below each step is described in detail.

\noindent \textbf{Pre-training.} EUMS assumes that the novel classes belong to the foreground. Then, the novel classes are merged with the background class (considered as base in all the dataset splits) during the pre-training phase. The foreground pixels are obtained by an auxiliary saliency detection model~\cite{qin2019basnet}. The background pixels are just the output of the pre-trained model. 
The portion of the image belonging to both the foreground and the background masks contains the novel pixels.
Because in point clouds there is no concept of foreground/background and saliency for 3D data cannot be leveraged as easily as for 2D data \cite{Ran2021}, we consider the novel points as the unlabelled points and we discard them during the pre-training phase. 
Therefore, the pre-training stage of EUMS$^\dag$ considers only the base points in each scene $\mathcal{X}_b$ and optimises $f_\xi \circ f_b$ by considering the objective function $\ell(\hat{\mathcal{Y}}_b, \mathcal{Y}_b)$, where $\hat{\mathcal{Y}}_b$ are the network predictions $ \hat{\mathcal{Y}}_b = (f_\xi \circ f_b) (\mathcal{X}_b)$ and $\mathcal{Y}_b$ are the ground-truth annotations for the base points.

\noindent \textbf{Pseudo-labelling.} EUMS assumes that each image contains at most one novel class, allowing to compute a unique pseudo-label for each image. 
Authors in \cite{zhao2022novel} propose to first average pool the features of the novel pixels in each image and then collect the image-level representations for the whole dataset. Finally, the hard pseudo-labels for all the novel points in each image are obtained by propagating the clustering affiliation of each image-level feature vector, determined by using the k-means algorithm.

In semantic segmentation for 3D point clouds, multiple novel classes usually occur in the same scene. Therefore, in EUMS$^\dag$ we propose to extract the per-point features $\mathcal{F}_{n, i}$ with $f_\xi$ for all the novel points $\mathcal{X}_{n, i}$ contained in the $i$-th scene of the dataset. 
However, a large amount of novel points is difficult to handle due to hardware constrains.
We randomly select a subset of point-level vectors using $\Psi$ from each scene by setting a ratio (i.e.~$30\%$) with an upper bound (i.e.~1K) on the number of points to select. 
Finally, we apply k-means clustering on the set of features collected over the whole dataset and obtain the pseudo-labels $\tilde{\mathcal{Y}}_{n, i}$ for the selected novel points in $\mathcal{X}_{n, i}$. To further enrich the pseudo-labels, we propagate the pseudo-label of each novel point to its nearest neighbour in the coordinate space. This allows us to increase the number of pseudo-labelled novel points.

\noindent \textbf{Fine-tuning.} During the last step of the EUMS$^\dag$, we fine-tune the complete model following the same strategy used in \cite{zhao2022novel}: given a point cloud $\mathcal{X}$, we compute the class predictions $\hat{\mathcal{Y}}$ as  $\hat{\mathcal{Y}} = (f_\xi \circ f_c)(\mathcal{X})$ and we optimise the network considering the loss $\ell(\hat{\mathcal{Y}}, \tilde{\mathcal{Y}})$, where $\tilde{\mathcal{Y}} = \mathcal{Y}_b \cup \tilde{\mathcal{Y}}_n$.

