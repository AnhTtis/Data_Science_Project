\section{Conclusion}
In this paper, we propose two novel methods, DFConv and DPLR, that complement missing annotations in the existing weakly-labeled sign language datasets. 
To the best of our knowledge, we are the first to propose a method to extract manual and non-manual features individually by designing a task-specific convolution without any additional networks or annotations.
In addition, we introduce DPLR module that does not require additional networks during the pseudo-labeling process and demonstrate its effectiveness through various experiments.
The experimental results show that our framework achieves state-of-the-art performance on two large-scale benchmarks among RGB-based methods, and also outperforms or is comparable to methods based on multi-modality.
