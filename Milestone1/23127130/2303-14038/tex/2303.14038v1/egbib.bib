@article{li2019visualbert,
  title={Visual{BERT}: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint},
  url={https://arxiv.org/pdf/1908.03557},
  year={2019}
}
@inproceedings{tan-bansal-2019-lxmert,
    title = "{LXMERT}: Learning Cross-Modality Encoder Representations from Transformers",
    author = "Tan, Hao  and
      Bansal, Mohit",
    booktitle = "Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2019",
    url = "https://www.aclweb.org/anthology/D19-1514",
}
@inproceedings{cubuk2020randaugment,
  title={Randaugment: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  year={2020}
}
@inproceedings{kamath2021mdetr,
  title={MDETR-modulated detection for end-to-end multi-modal understanding},
  author={Kamath, Aishwarya and Singh, Mannat and LeCun, Yann and Synnaeve, Gabriel and Misra, Ishan and Carion, Nicolas},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2021}
}
@article{raffel2020exploring,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of Machine Learning Research (JMLR)},
  year={2020}
}
@inproceedings{cho2021unifying,
  title={Unifying vision-and-language tasks via text generation},
  author={Cho, Jaemin and Lei, Jie and Tan, Hao and Bansal, Mohit},
  booktitle = {International Conference on Machine Learning (ICML)},
  year={2021}
}
@inproceedings{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  url={https://papers.nips.cc/paper/8297-vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks.pdf},
  year={2019}
}
@inproceedings{su2019vl,
  title={{VL-BERT}: Pre-training of Generic Visual-Linguistic Representations},
  author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
  booktitle={International Conference on Learning Representations (ICLR)},
  url={https://arxiv.org/pdf/1908.08530},
  year={2019}
}
@article{hendricks2021decoupling,
  title={Decoupling the Role of Data, Attention, and Losses in Multimodal Transformers},
  author={Hendricks, Lisa Anne and Mellor, John and Schneider, Rosalia and Alayrac, Jean-Baptiste and Nematzadeh, Aida},
  journal={Transactions of the Association for Computational Linguistics (TACL)},
  year={2021}
}
@article{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc V and Sung, Yunhsuan and Li, Zhen and Duerig, Tom},
  journal={arXiv preprint},
  year={2021}
}
@inproceedings{chen2020uniter,
  title={{UNITER}: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2020},
  url={https://arxiv.org/pdf/1909.11740}
}
@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={European Conference on Computer Vision (ECCV)},
  url={https://arxiv.org/pdf/2004.06165},
  year={2020}
}
@inproceedings{zhang2021vinvl,
  title={{VinVL}: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}


@article{pires2019multilingual,
  title={How multilingual is Multilingual {BERT}?},
  author={Pires, Telmo and Schlinger, Eva and Garrette, Dan},
  journal={arXiv preprint},
  url={https://arxiv.org/pdf/1906.01502},
  year={2019}
}
@inproceedings{dou2021word,
  title={Word Alignment by Fine-tuning Embeddings on Parallel Corpora},
  author={Dou, Zi-Yi and Neubig, Graham},
  booktitle={Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (EACL)},
  year={2021}
}
@inproceedings{voita-titov-2020-information,
    title = "Information-Theoretic Probing with Minimum Description Length",
    author = "Voita, Elena  and
      Titov, Ivan",
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2020",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.14",
}
@inproceedings{wang-etal-2020-maf,
    title = "{MAF}: Multimodal Alignment Framework for Weakly-Supervised Phrase Grounding",
    author = "Wang, Qinxin  and
      Tan, Hao  and
      Shen, Sheng  and
      Mahoney, Michael  and
      Yao, Zhewei",
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2020",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.159",
}
@inproceedings{devlin2018bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Conference of the North {A}merican Chapter of the Association for Computational Linguistics (NAACL)",
    year = "2019",
    url = "https://www.aclweb.org/anthology/N19-1423",
}


@inproceedings{sup1,
  title={Grounding of textual phrases in images by reconstruction},
  author={Rohrbach, Anna and Rohrbach, Marcus and Hu, Ronghang and Darrell, Trevor and Schiele, Bernt},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2016},
  url={https://arxiv.org/pdf/1511.03745}
}
@inproceedings{sup2,
  title={Rethinking Diversified and Discriminative Proposal Generation for Visual Grounding},
  author={Yu, Zhou and Yu, Jun and Xiang, Chenchao and Zhao, Zhou and Tian, Qi and Tao, Dacheng},
  booktitle={Proceedings of the International Joint Conferences on Artificial Intelligence Organization (IJCAI)},
  url={https://www.ijcai.org/Proceedings/2018/0155.pdf},
  year={2018}
}
@inproceedings{sup3,
  title={Learning Cross-Modal Context Graph for Visual Grounding.},
  author={Liu, Yongfei and Wan, Bo and Zhu, Xiaodan and He, Xuming},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  url={https://arxiv.org/pdf/1911.09042},
  year={2020}
}
@inproceedings{weak1,
  title={Grounding of textual phrases in images by reconstruction},
  author={Rohrbach, Anna and Rohrbach, Marcus and Hu, Ronghang and Darrell, Trevor and Schiele, Bernt},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2016},
  url={https://arxiv.org/pdf/1511.03745}
}
@inproceedings{weak2,
  title={Unsupervised textual grounding: Linking words to image concepts},
  author={Yeh, Raymond A and Do, Minh N and Schwing, Alexander G},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  url={http://openaccess.thecvf.com/content_cvpr_2018/papers/Yeh_Unsupervised_Textual_Grounding_CVPR_2018_paper.pdf},
  year={2018}
}
@inproceedings{weak3,
  title={Knowledge aided consistency for weakly supervised phrase grounding},
  author={Chen, Kan and Gao, Jiyang and Nevatia, Ram},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  url={http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Knowledge_Aided_Consistency_CVPR_2018_paper.pdf},
  year={2018}
}
@article{xie2019visual,
  title={Visual entailment: A novel task for fine-grained image understanding},
  author={Xie, Ning and Lai, Farley and Doran, Derek and Kadav, Asim},
  journal={arXiv preprint},
  url={https://arxiv.org/pdf/1901.06706},
  year={2019}
}
@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={Annual Meeting of the Association for Computational Linguistics (ACL)},
  url={https://www.aclweb.org/anthology/P18-1238.pdf},
  year={2018}
}
@inproceedings{nce1,
  title={Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author={Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  url={http://www.jmlr.org/proceedings/papers/v9/gutmann10a/gutmann10a.pdf},
  year={2010}
}
@article{nce2,
  title={Exploring the limits of language modeling},
  author={Jozefowicz, Rafal and Vinyals, Oriol and Schuster, Mike and Shazeer, Noam and Wu, Yonghui},
  journal={arXiv preprint},
  url={https://arxiv.org/pdf/1602.02410.pdf},
  year={2016}
}
@article{bugliarello-etal-2020-multimodal,
    title = "Multimodal Pretraining Unmasked: {U}nifying the Vision and Language {BERT}s",
    author = "Bugliarello, Emanuele  and
      Cotterell, Ryan and
      Okazaki, Naoaki and
      Elliott, Desmond",
    journal = "Transactions of the Association for Computational Linguistics (TACL)",
    year = "2021",
    url = "https://arxiv.org/abs/2011.15124",
}
@inproceedings{weak4,
  title={Phrase Localization Without Paired Training Examples},
  author={Wang, Josiah and Specia, Lucia},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  url={http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Phrase_Localization_Without_Paired_Training_Examples_ICCV_2019_paper.pdf},
  year={2019}
}
@inproceedings{weak5,
  title={Unsupervised Discovery of Multimodal Links in Multi-image, Multi-sentence Documents},
  author={Hessel, Jack and Lee, Lillian and Mimno, David},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  url={https://arxiv.org/pdf/1904.07826},
  year={2019}
}

@inproceedings{cao2020behind,
  title={Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language Models},
  author={Cao, Jize and Gan, Zhe and Cheng, Yu and Yu, Licheng and Chen, Yen-Chun and Liu, Jingjing},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  url={https://arxiv.org/pdf/2005.07310},
  year={2020}
}

@inproceedings{kazemzadeh2014referitgame,
  title={Referitgame: Referring to objects in photographs of natural scenes},
  author={Kazemzadeh, Sahar and Ordonez, Vicente and Matten, Mark and Berg, Tamara},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  url={https://www.aclweb.org/anthology/D14-1086.pdf},
  year={2014}
}
@inproceedings{li2020does,
  title={What Does {BERT} with Vision Look At?},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  url={https://www.aclweb.org/anthology/2020.acl-main.469.pdf},
  year={2020}
}
@inproceedings{antol2015vqa,
  title={{VQA}: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={International Conference on Computer Vision (ICCV)},
  url={http://openaccess.thecvf.com/content_iccv_2015/papers/Antol_VQA_Visual_Question_ICCV_2015_paper.pdf},
  year={2015}
}
@article{chen2015microsoft,
  title={Microsoft {COCO} {C}aptions: Data collection and evaluation server},
  author={Chen, Xinlei and Fang, Hao and Lin, Tsung-Yi and Vedantam, Ramakrishna and Gupta, Saurabh and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  journal={arXiv preprint},
  url={https://arxiv.org/pdf/1504.00325},
  year={2015}
}

@article{krishna2017visual,
  title={Visual {G}enome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International Journal of Computer Vision (IJCV)},
  year={2017},
  url={https://link.springer.com/article/10.1007/S11263-016-0981-7}
}
@article{ren2015faster,
  title={Faster {R-CNN}: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  year={2016},
  url={https://ieeexplore.ieee.org/iel7/34/4359286/07485869.pdf?casa_token=lVQqGQcyZaMAAAAA:C5IsxOq5J16PZeRG9kM7i32Pxbkj5c_ASp_NSNYbyzfFZbwwG1E7a8xiIqGCcxe4qqE1543m},
}
@inproceedings{goyal2017making,
  title={Making the {V} in {VQA} matter: Elevating the role of image understanding in Visual Question Answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  url={http://openaccess.thecvf.com/content_cvpr_2017/papers/Goyal_Making_the_v_CVPR_2017_paper.pdf},
  year={2017}
}

@inproceedings{yu2018mattnet,
  title={Mattnet: Modular attention network for referring expression comprehension},
  author={Yu, Licheng and Lin, Zhe and Shen, Xiaohui and Yang, Jimei and Lu, Xin and Bansal, Mohit and Berg, Tamara L},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1307--1315},
  url={http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_MAttNet_Modular_Attention_CVPR_2018_paper.pdf},
  year={2018}
}

@inproceedings{lin2014microsoft,
  title={Microsoft {COCO}: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European Conference on Computer Vision (ECCV)},
  url={https://link.springer.com/content/pdf/10.1007/978-3-319-10602-1_48.pdf},
  year={2014}
}
@inproceedings{plummer2015flickr30k,
  title={Flickr30k {E}ntities: Collecting region-to-phrase correspondences for richer image-to-sentence models},
  author={Plummer, Bryan A and Wang, Liwei and Cervantes, Chris M and Caicedo, Juan C and Hockenmaier, Julia and Lazebnik, Svetlana},
  booktitle={International Conference on Computer Vision (ICCV)},
  url={http://openaccess.thecvf.com/content_iccv_2015/papers/Plummer_Flickr30k_Entities_Collecting_ICCV_2015_paper.pdf},
  year={2015}
}
@inproceedings{doersch2015unsupervised,
  title={Unsupervised visual representation learning by context prediction},
  author={Doersch, Carl and Gupta, Abhinav and Efros, Alexei A},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  url={https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Doersch_Unsupervised_Visual_Representation_ICCV_2015_paper.pdf},
  year={2015}
}
@inproceedings{xie2020fast,
  title={A fast proximal point method for computing exact wasserstein distance},
  author={Xie, Yujia and Wang, Xiangfeng and Wang, Ruijia and Zha, Hongyuan},
  booktitle={Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI)},
  year={2020},
  url={http://proceedings.mlr.press/v115/xie20b/xie20b.pdf},
}
@inproceedings{deng2018visual,
  title={Visual grounding via accumulated attention},
  author={Deng, Chaorui and Wu, Qi and Wu, Qingyao and Hu, Fuyuan and Lyu, Fan and Tan, Mingkui},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  url={https://openaccess.thecvf.com/content_cvpr_2018/papers/Deng_Visual_Grounding_via_CVPR_2018_paper.pdf},
  year={2018}
}
@inproceedings{sun2019videobert,
  title={Video{BERT}: A joint model for video and language representation learning},
  author={Sun, Chen and Myers, Austin and Vondrick, Carl and Murphy, Kevin and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  url={http://openaccess.thecvf.com/content_ICCV_2019/papers/Sun_VideoBERT_A_Joint_Model_for_Video_and_Language_Representation_Learning_ICCV_2019_paper.pdf},
  year={2019}
}

@inproceedings{peters2018deep,
  title={Deep Contextualized Word Representations},
  author={Peters, Matthew and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  booktitle={Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  url={https://www.aclweb.org/anthology/N18-1202.pdf},
  year={2018}
}
@inproceedings{pathak2016context,
  title={Context encoders: Feature learning by inpainting},
  author={Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  url={http://openaccess.thecvf.com/content_cvpr_2016/papers/Pathak_Context_Encoders_Feature_CVPR_2016_paper.pdf},
  year={2016}
}

@inproceedings{hubert2017learning,
  title={Learning robust visual-semantic embeddings},
  author={Hubert Tsai, Yao-Hung and Huang, Liang-Kang and Salakhutdinov, Ruslan},
  booktitle={International Conference on Computer Vision (ICCV)},
  url={http://openaccess.thecvf.com/content_ICCV_2017/papers/Tsai_Learning_Robust_Visual-Semantic_ICCV_2017_paper.pdf},
  year={2017}
}
@inproceedings{hill2014learning,
  title={Learning abstract concept embeddings from multi-modal data: Since you probably canâ€™t see what I mean},
  author={Hill, Felix and Korhonen, Anna},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  url={https://www.aclweb.org/anthology/D14-1032.pdf},
  year={2014}
}

@inproceedings{silberer2014learning,
  title={Learning grounded meaning representations with autoencoders},
  author={Silberer, Carina and Lapata, Mirella},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  url={https://www.aclweb.org/anthology/P14-1068.pdf},
  year={2014}
}
@inproceedings{ngiam2011multimodal,
  title={Multimodal deep learning},
  author={Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and Lee, Honglak and Ng, Andrew Y},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  url={https://openreview.net/pdf?id=Hk4OO3W_bS},
  year={2011}
}
@inproceedings{loshchilov2018decoupled,
  title={Decoupled Weight Decay Regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}
@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  url={http://openaccess.thecvf.com/content_cvpr_2018/papers/Anderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.pdf},
  year={2018}
}
@inproceedings{li2020unicoder,
  title={Unicoder-vl: A universal encoder for vision and language by cross-modal pre-training},
  author={Li, Gen and Duan, Nan and Fang, Yuejian and Gong, Ming and Jiang, Daxin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2020}
}
@inproceedings{cohn2016incorporating,
  title={Incorporating Structural Alignment Biases into an Attentional Neural Translation Model},
  author={Cohn, Trevor and Hoang, Cong Duy Vu and Vymolova, Ekaterina and Yao, Kaisheng and Dyer, Chris and Haffari, Gholamreza},
  booktitle={Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  url={https://www.aclweb.org/anthology/N16-1102.pdf},
  year={2016}
}
@article{hu2020explicit,
  title={Explicit Alignment Objectives for Multilingual Bidirectional Encoders},
  author={Hu, Junjie and Johnson, Melvin and Firat, Orhan and Siddhant, Aditya and Neubig, Graham},
  journal={arXiv preprint},
  url={https://arxiv.org/pdf/2010.07972.pdf},
  year={2020}
}




@inproceedings{kim2021vilt,
  title={{ViLT}: Vision-and-language transformer without convolution or region supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}
@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@inproceedings{jiang2020defense,
  title={In defense of grid features for visual question answering},
  author={Jiang, Huaizu and Misra, Ishan and Rohrbach, Marcus and Learned-Miller, Erik and Chen, Xinlei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10267--10276},
  year={2020}
}
@article{liu2019roberta,
  title={Ro{BERT}a: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint},
  year={2019}
}

@inproceedings{lan2019albert,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}
@inproceedings{clark2020electra,
  title={Electra: Pre-training text encoders as discriminators rather than generators},
  author={Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}
@article{he2020deberta,
  title={De{BERT}a: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint},
  year={2020}
}

@article{shen2021much,
  title={How Much Can CLIP Benefit Vision-and-Language Tasks?},
  author={Shen, Sheng and Li, Liunian Harold and Tan, Hao and Bansal, Mohit and Rohrbach, Anna and Chang, Kai-Wei and Yao, Zhewei and Keutzer, Kurt},
  journal={arXiv preprint},
  year={2021}
}
@inproceedings{suhr2018corpus,
  title={A corpus for reasoning about natural language grounded in photographs},
  author={Suhr, Alane and Zhou, Stephanie and Zhang, Ally and Zhang, Iris and Bai, Huajun and Artzi, Yoav},
  booktitle={Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2019}
}
@article{krishna2016visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International Journal of Computer Vision (IJCV)},
  year={2017},
}
@inproceedings{yu2018deep,
  title={Deep layer aggregation},
  author={Yu, Fisher and Wang, Dequan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}
@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}
@inproceedings{bapna2018training,
  title={Training Deeper Neural Machine Translation Models with Transparent Attention},
  author={Bapna, Ankur and Chen, Mia Xu and Firat, Orhan and Cao, Yuan and Wu, Yonghui},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2018}
}
@inproceedings{dou2018exploiting,
  title={Exploiting Deep Representations for Neural Machine Translation},
  author={Dou, Zi-Yi and Tu, Zhaopeng and Wang, Xing and Shi, Shuming and Zhang, Tong},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2018}
}
@inproceedings{jawahar2019does,
  title={What Does {BERT} Learn about the Structure of Language?},
  author={Jawahar, Ganesh and Sagot, Beno{\^\i}t and Seddah, Djam{\'e}},
  booktitle={Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2019}
}
@inproceedings{yu2020gradient,
  title={Gradient Surgery for Multi-Task Learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2020}
}
@inproceedings{wang2020gradient,
  title={Gradient Vaccine: Investigating and Improving Multi-task Optimization in Massively Multilingual Models},
  author={Wang, Zirui and Tsvetkov, Yulia and Firat, Orhan and Cao, Yuan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}
@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}
@inproceedings{van2017neural,
  title={Neural discrete representation learning},
  author={van den Oord, Aaron and Vinyals, Oriol and Kavukcuoglu, Koray},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2017}
}
@inproceedings{liu2019text,
  title={Text Summarization with Pretrained Encoders},
  author={Liu, Yang and Lapata, Mirella},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2019}
}
@inproceedings{selvaraju2017grad,
  title={Grad-{CAM}: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2017}
}
@inproceedings{wang2018glue,
  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}
@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2009},
}
@inproceedings{ordonez2011im2text,
  title={Im2text: Describing images using 1 million captioned photographs},
  author={Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2011}
}

@inproceedings{karpathy2015deep,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3128--3137},
  year={2015}
}

@inproceedings{li2021align,
  title={Align before Fuse: Vision and Language Representation Learning with Momentum Distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath R and Gotmare, Akhilesh Deepak and Joty, Shafiq and Xiong, Caiming and Hoi, Steven},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2021}
}
@inproceedings{xue2021probing,
  title={Probing Inter-modality: Visual Parsing with Self-Attention for Vision-Language Pre-training},
  author={Xue, Hongwei and Huang, Yupan and Liu, Bei and Peng, Houwen and Fu, Jianlong and Li, Houqiang and Luo, Jiebo},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2021}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
 booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}
@article{touvron2021going,
  title={Going deeper with image transformers},
  author={Touvron, Hugo and Cord, Matthieu and Sablayrolles, Alexandre and Synnaeve, Gabriel and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint},
  year={2021}
}
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009}
}
@inproceedings{changpinyo2021conceptual,
  title={Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@article{yuan2021florence,
  title={Florence: A New Foundation Model for Computer Vision},
  author={Lu Yuan and Dongdong Chen and Yi-Ling Chen and Noel Codella and Xiyang Dai and Jianfeng Gao and Houdong Hu and Xuedong Huang and Boxin Li and Chunyuan Li and Ce Liu and Mengchen Liu and Zicheng Liu and Yumao Lu and Yu Shi and Lijuan Wang and Jianfeng Wang and Bin Xiao and Zhen Xiao and Jianwei Yang and Michael Zeng and Luowei Zhou and Pengchuan Zhang},
  journal={arXiv preprint},
  year={2021}
}
@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2021}
}
@article{yuan2021volo,
      title={VOLO: Vision Outlooker for Visual Recognition}, 
      author={Li Yuan and Qibin Hou and Zihang Jiang and Jiashi Feng and Shuicheng Yan},
      journal={arXiv preprint},
      year={2021},
}
@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2017}
}
@inproceedings{sennrich2016neural,
  title={Neural Machine Translation of Rare Words with Subword Units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  booktitle={Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2016}
}
@article{bao2021beit,
  title={{BEiT}: BERT Pre-Training of Image Transformers},
  author={Bao, Hangbo and Dong, Li and Wei, Furu},
  journal={arXiv preprint},
  year={2021}
}
@article{touvron2020deit,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Hugo Touvron and Matthieu Cord and Matthijs Douze and Francisco Massa and Alexandre Sablayrolles and Herv\'e J\'egou},
  journal={arXiv preprint},
  year={2020}
}
@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}
@article{huang2020pixel,
  title={Pixel-{BERT}: Aligning image pixels with text by deep multi-modal transformers},
  author={Huang, Zhicheng and Zeng, Zhaoyang and Liu, Bei and Fu, Dongmei and Fu, Jianlong},
  journal={arXiv preprint},
  year={2020}
}

@article{wang2021simvlm,
  title={SimVLM: Simple Visual Language Model Pretraining with Weak Supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={arXiv preprint},
  year={2021}
}

@inproceedings{gan2020large,
  title={Large-scale adversarial training for vision-and-language representation learning},
  author={Gan, Zhe and Chen, Yen-Chun and Li, Linjie and Zhu, Chen and Cheng, Yu and Liu, Jingjing},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@inproceedings{li2020unimo,
  title={Unimo: Towards unified-modal understanding and generation via cross-modal contrastive learning},
  author={Li, Wei and Gao, Can and Niu, Guocheng and Xiao, Xinyan and Liu, Hao and Liu, Jiachen and Wu, Hua and Wang, Haifeng},
  booktitle={Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2021}
}

@inproceedings{huang2021seeing,
  title={Seeing Out of tHe bOx: End-to-End Pre-training for Vision-Language Representation Learning},
  author={Huang, Zhicheng and Zeng, Zhaoyang and Huang, Yupan and Liu, Bei and Fu, Dongmei and Fu, Jianlong},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@inproceedings{li2022grounded,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10965--10975},
  year={2022}
}

@article{yao2021filip,
  title={Filip: Fine-grained interactive language-image pre-training},
  author={Yao, Lewei and Huang, Runhui and Hou, Lu and Lu, Guansong and Niu, Minzhe and Xu, Hang and Liang, Xiaodan and Li, Zhenguo and Jiang, Xin and Xu, Chunjing},
  journal={arXiv preprint arXiv:2111.07783},
  year={2021}
}

@article{yu2022coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}

@article{wang2022image,
  title={Image as a foreign language: Beit pretraining for all vision and vision-language tasks},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  journal={arXiv preprint arXiv:2208.10442},
  year={2022}
}
@inproceedings{wang2022vlmixer,
  title={VLMixer: Unpaired Vision-Language Pre-training via Cross-Modal CutMix},
  author={Wang, Teng and Jiang, Wenhao and Lu, Zhichao and Zheng, Feng and Cheng, Ran and Yin, Chengguo and Luo, Ping},
  booktitle={International Conference on Machine Learning},
  pages={22680--22690},
  year={2022},
  organization={PMLR}
}
@article{zeng2021multi,
  title={Multi-Grained Vision Language Pre-Training: Aligning Texts with Visual Concepts},
  author={Zeng, Yan and Zhang, Xinsong and Li, Hang},
  journal={arXiv preprint arXiv:2111.08276},
  year={2021}
}
@inproceedings{dou2022empirical,
  title={An empirical study of training end-to-end vision-and-language transformers},
  author={Dou, Zi-Yi and Xu, Yichong and Gan, Zhe and Wang, Jianfeng and Wang, Shuohang and Wang, Lijuan and Zhu, Chenguang and Zhang, Pengchuan and Yuan, Lu and Peng, Nanyun and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18166--18176},
  year={2022}
}
@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}
@article{bitton2021data,
  title={Data efficient masked language modeling for vision and language},
  author={Bitton, Yonatan and Stanovsky, Gabriel and Elhadad, Michael and Schwartz, Roy},
  journal={arXiv preprint arXiv:2109.02040},
  year={2021}
}
@article{li2021supervision,
  title={Supervision exists everywhere: A data efficient contrastive language-image pre-training paradigm},
  author={Li, Yangguang and Liang, Feng and Zhao, Lichen and Cui, Yufeng and Ouyang, Wanli and Shao, Jing and Yu, Fengwei and Yan, Junjie},
  journal={arXiv preprint arXiv:2110.05208},
  year={2021}
}
@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}
@article{byun2022grit,
  title={GRIT-VLP: Grouped Mini-batch Sampling for Efficient Vision and Language Pre-training},
  author={Byun, Jaeseok and Hwang, Taebaek and Fu, Jianlong and Moon, Taesup},
  journal={arXiv preprint arXiv:2208.04060},
  year={2022}
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer.},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J and others},
  journal={J. Mach. Learn. Res.},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}
@inproceedings{wang2022ofa,
  title={Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  booktitle={International Conference on Machine Learning},
  pages={23318--23340},
  year={2022},
  organization={PMLR}
}
@article{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@inproceedings{du2022glm,
  title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling},
  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={320--335},
  year={2022}
}
@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}
@article{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  journal={arXiv preprint arXiv:2201.12086},
  year={2022}
}

@inproceedings{hu2022scaling,
  title={Scaling up vision-language pre-training for image captioning},
  author={Hu, Xiaowei and Gan, Zhe and Wang, Jianfeng and Yang, Zhengyuan and Liu, Zicheng and Lu, Yumao and Wang, Lijuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17980--17989},
  year={2022}
}

@article{bao2022vl,
  title={Vl-beit: Generative vision-language pretraining},
  author={Bao, Hangbo and Wang, Wenhui and Dong, Li and Wei, Furu},
  journal={arXiv preprint arXiv:2206.01127},
  year={2022}
}
@article{wettig2022should,
  title={Should you mask 15\% in masked language modeling?},
  author={Wettig, Alexander and Gao, Tianyu and Zhong, Zexuan and Chen, Danqi},
  journal={arXiv preprint arXiv:2202.08005},
  year={2022}
}