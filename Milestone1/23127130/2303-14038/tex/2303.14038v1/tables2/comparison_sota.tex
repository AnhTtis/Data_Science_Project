\begin{table*}[!t]
\footnotesize
\centering
% \tablestyle{8pt}{1.0}
% \def\w{10pt} 
\scalebox{1.0}{
\setlength{\tabcolsep}{1.2 mm}{
  \begin{tabular}{llccccccccc}
    \toprule
    \multirow{2}{*}{\bf Model} & \multirow{2}{*}{\bf Pretrain. Task} & {\bf Pretrain. Time} &  \multicolumn{2}{c}{\bf VQAv2} & \multicolumn{2}{c}{\bf NLVR$^2$} &  \multicolumn{4}{c}{\bf COCO Captioning} \\
     & & (GPU Days) & \bf test-dev & \bf test-std & \bf dev & \bf test & \bf BLEU\@4 & \bf METEOR & \bf CIDEr & \bf SPICE \\
    % \shline

\midrule
% ####################### <10M ##############
\multicolumn{3}{l}{ { \it{\textbf{Pre-trained with $<$10M images}} } }\\
    % \hline
  UNITER$_{\text{LARGE}}$  ~\cite{chen2020uniter}  & MLM, ITM, MVM, WRA & 152 (V100) & 73.82 & 74.02  & 79.12 & 79.98 & - & -  \\
  UNIMO$_{\text{LARGE}}$~\cite{li2020unimo} & MLM, MVM, ITC & 640 (V100) & 75.06 & 75.27  & - & - &  - & {-}   \\
  OSCAR & MLM, ITM & 220 (V100) & 73.61 & 73.82 & 79.12 & 80.37 & 37.4 & \textbf{30.7} & 127.8 & 23.5 \\
  VinVL$_{\text{BASE}}$~\cite{zhang2021vinvl} & MLM, ITM & 320 (V100) & { 75.95}& 76.12 &  82.05 &  {83.08} & 38.2 & 30.3& 129.3 &23.6 \\
VinVL$_{\text{LARGE}}$~\cite{zhang2021vinvl} & MLM, ITM & 320 (V100) & { 76.52 }& 76.60 &  \underline{82.67} &  \textbf{83.98} & 38.5 & \underline{30.4} & {130.8} & 23.4 \\
  % PixelBERT~\cite{huang2020pixel} & MLM, ITM & - & 74.45 & 74.55 & 76.5 & 77.2 & - & - & -   \\
  CLIP-ViL~\cite{shen2021much} & MLM, ITM, VQA & 40 (A100) & 76.48 & { 76.70} & - & - & \demph{40.2$^*$} & \demph{29.7$^*$} & \demph{134.2$^*$} & \demph{23.8$^*$} \\
   
  ViLT~\cite{zhang2021vinvl} & MLM, ITM, WRA& 192 (V100)  &71.26 & - & 75.70 & 76.13 & - & - & \\
  ALBEF (4M)~\cite{li2021align} & MLM, ITM & 28 (A100) & 71.40 & - & - & 77.51 & - & - \\
  ALBEF (4M)~\cite{li2021align} & MLM, ITM, ITC & 28 (A100) & 74.54 & 74.70 & 80.24 & 80.50 & - & - \\
  
  METER$_{\text{BASE}}$~\cite{dou2022empirical}  & MLM, ITM & 64 (A100) & 77.68 &  77.64 & {82.33} & {83.05} & \underline{38.8} &30.0 &128.2 &23.0 \\

\rowcolor{Gray}
{Ours$_{\text{LARGE}}$ (4M)} & FLM &  18 (V100) & \underline{77.80} & \underline{77.84} & 81.77 & 81.83 & 38.3 & 30.2 & \underline{130.9} & -\\
\midrule
\multicolumn{3}{l}{ { \it{\textbf{Pre-trained with 10M$\sim$100M images}} } }\\
ALBEF (14M)~\cite{li2021align} & MLM, ITM, ITC &  140 (A100) & 75.84 & 76.04 & 82.55 & {83.14} & - & - \\
BLIP (14M)~\cite{li2022blip} & AR, ITM, ITC & 112 (A100)& {77.54} & {77.62} & {82.67} & 82.30 & {38.6} & - & {129.7} & - \\
\rowcolor{Gray}
{Ours$_{\text{LARGE}}$ (13M)} & FLM & {\color{black} 75 (V100)} & \textbf{78.18} & \textbf{78.24} & \textbf{82.90} & \underline{83.86}  & \textbf{39.1} & 30.3 & \textbf{132.7} & -\\
    \midrule
  \multicolumn{3}{l}{ \demph{ \it{\textbf{Pre-trained with $>$100M images}}}}\\
    % \hline    
    \demph{SimVLM$_{\text{BASE}}$ (1.8B)~\cite{wang2021simvlm}} & \demph{PrefixLM} & \demph{-} & \demph{77.87} & \demph{78.14} & \demph{81.72} & \demph{81.77} & \demph{39.0} & \demph{32.9} & \demph{134.8} & \demph{24.0} \\
    \demph{SimVLM$_{\text{HUGE}}$ (1.8B)~\cite{wang2021simvlm}} & \demph{PrefixLM} & \demph{-} & \demph{80.03} & \demph{80.34} & \demph{84.53} & \demph{85.15} & \demph{40.6} & \demph{33.7} & \demph{143.3} & \demph{25.4} \\
    \demph{LEMON (400M)}& \demph{MLM} & \demph{-}& \demph{-} & \demph{-}  & \demph{-}  & \demph{-} & \demph{40.3} & \demph{30.2} & \demph{133.3} & \demph{23.3} \\
\bottomrule
  \end{tabular}
}
}
\vspace{-.5em}
\caption{Comparisons with models on visual question answering, visual reasoning, and image captioning tasks. The best scores are in \textbf{bold}, and the second best scores are in \underline{underlined}.  MVM, ITC, ITM, and WRA represent masked vision modeling, image-text contrast, image-text matching, and word-region alignment, respectively. Ours$_{\rm LARGE}$ is trained with 30k/100k steps on 4M/13M data, respectively. 
The pretraining time of compared methods is provided by the original paper or estimated from open-sourcing code.}
\label{tab:sota}
\vspace{-2mm}
\end{table*}