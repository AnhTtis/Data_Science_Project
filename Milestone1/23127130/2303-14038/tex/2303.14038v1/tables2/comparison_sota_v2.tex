\begin{table*}[!t]
\tablestyle{1pt}{1.0}
\def\w{20pt} 
\scalebox{1.0}{
  \begin{tabular}{llc|cccccc|cccccc}
    \toprule
    %\toprule
    \multirow{2}{*}{\bf Model} & \multirow{2}{*}{\bf Pretrain. Task} & {\bf Pretrain. Time} & \multicolumn{6}{c|}{\bf Flickr30k} & \multicolumn{6}{c}{\bf COCO}  \\
     & & (GPU Days) & \bf IR@1  & \bf IR@5  & \bf IR@10 & \bf TR@1 & \bf TR@5 & \bf TR@10 &  \bf IR@1  & \bf IR@5  & \bf IR@10 & \bf TR@1 & \bf TR@5 & \bf TR@10 \\
    \midrule
    \multicolumn{10}{l}{ { \it{\textbf{Pre-trained with $<$10M images}} } }\\
    UNITER$_{\text{LARGE}}$~\cite{chen2020uniter} & MLM, ITM, MVM, WRA & 152 (V100) & 75.56 & 94.08 & 96.76 & 87.30 & 98.00 & 99.20 & 52.93 & 79.93 & 87.95 & 65.68 & 88.56 & 93.76 \\
    UNIMO$_{\text{LARGE}}$~\cite{li2020unimo} &MLM, MVM, ITC&640 (V100)& 78.04 & 94.24 & 97.12 & 89.40 & 98.90 & \underline{ 99.80} & - & - & - & - & - & - \\
  VinVL$_{\text{LARGE}}$~\cite{zhang2021vinvl} &MLM, ITM& 320 (V100) & - & - & - & - & - & -  & \bf 58.8 & \bf 83.5 & \bf 90.3 & \underline{ 75.4} & \underline{ 92.9} & \underline{ 96.2} \\
  PixelBERT~\cite{huang2020pixel} &MLM, ITM & - & 71.5 & 92.1 & 95.8 & 87.0 & 98.9 & 99.5 & 50.1 & 77.6 & 86.2 & 63.6 & 87.5 & 93.6 \\
  ViLT~\cite{zhang2021vinvl} & MLM, ITM, WRA & 192 (V100)  & 64.4 & 88.7 & 93.8 & 83.5 & 96.7 & 98.6 & 42.7 & 72.9 & 83.1 & 61.5 & 86.3 & 92.7 \\
  ALBEF (4M)~\cite{li2021align} &MLM, ITM, ITC &28 (A100)& \underline{82.8} & \underline{96.7} & \underline{98.4} &  \underline{94.3} & { 99.4} &{ 99.8}  & 56.8 & 81.5 & 89.2 & 73.1 & 91.4 & 96.0\\
  METER$_{\text{BASE}}$~\cite{dou2022empirical} & MLM, ITM &64 (A100)& {82.22} &  {96.34} &  98.36 & \underline{94.30} & \bf 99.60 & \bf 99.90 & \underline{ 57.08} & \underline{ 82.66} & \underline{90.07} & \bf 76.16 & \bf 93.16 & \bf 96.82 \\
  \rowcolor{Gray}
  Ours$_{\text{LARGE}}$ (4M) &FLM& 18 (V100)&  74.53 & 93.96 & 97.26 & 88.10 & 98.30 & 99.60 & 46.46 & 75.43 & 85.09 & 62.84 & 86.64 & 93.00 \\
  \rowcolor{Gray}
  Ours$_{\text{LARGE}}$ (4M) &FLM, ITM& 57 (V100)& \textbf{83.40} & \textbf{97.04} & \textbf{98.72} & \bf 95.00 & \underline{99.50} & \bf 99.90 & 56.55 & 82.02 & 89.63 & 73.52 & 91.95 & 95.97 \\

  %########################## >10M images ##################
    \midrule
    \multicolumn{10}{l}{ \demph{ \it{\textbf{Pre-trained with $>$10M images}} } }\\
    \demph{ALBEF (14M)~\cite{li2021align}} & \demph{MLM, ITM, ITC} & \demph{60 (A100)} & \demph{85.6} & \demph{97.5} & \demph{98.9} & \demph{95.9} & \demph{99.8} & \demph{100.0} & \demph{60.7} & \demph{84.3} & \demph{90.5} & \demph{77.6} & \demph{94.3} & \demph{97.2}\\
    \demph{BLIP (14M)} & \demph{AR, ITM, ITC} & \demph{112 (A100)}  & \demph{87.2} & \demph{97.5} & \demph{98.8} & \demph{96.6} & \demph{99.8} & \demph{100.0} & \demph{63.1} & \demph{85.3} & \demph{91.1}& \demph{80.6} & \demph{95.2} & \demph{97.6}  \\
  \bottomrule
  \end{tabular}
  }
  \vspace{-.5em}
  \caption{Performance comparisons with models pre-trained on Flickr30k and COCO image retrieval (IR) and text retrieval (TR) tasks in the finetuning setting. The best scores are in \textbf{bold}, and the second best scores are in \underline{underlined}. }
  \label{tab:results2}
   \vspace{-4mm}
\end{table*}