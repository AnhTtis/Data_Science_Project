\begin{table}[]
    \centering
    \small
    \setlength{\tabcolsep}{1.0 mm}{
    \begin{tabular}{lc|cccccc}
    \toprule
    \multirow{2}{*}{Method} & \multirow{2}{*}{Mask Ratio} & \multicolumn{6}{c}{Training Steps} \\
    & & 10k & 20k & 30k & 50k & 80k & 100k \\
    \midrule
        MLM & 0.2 & 51.07 & 74.38 & 76.83 & 77.65 & 78.20  &  78.21 \\
        MLM & 0.4 & 51.69 & 76.14 & 77.59 & \textbf{78.46} & \textbf{78.64} & \textbf{78.30} \\
        MLM & 0.6 & \textbf{62.62} & \textbf{76.69} & \textbf{78.01} & 77.97 & 78.33 & 77.91 \\
        MLM & 0.8 & 51.07 & 76.32 & 77.24 & 78.04 & 77.78 & 78.20 \\
\bottomrule
    \end{tabular}
    }
    \caption{NLVR$^2$ performance of different mask ratios in MLM. All models are trained with a maximum of 100k steps on 4M data.}
    \label{tab:mlmmaskrate}
\end{table}


\begin{table}[]
\small
\center
    \renewcommand\arraystretch{1.0}
    \setlength{\tabcolsep}{2.5 mm}{
    \begin{tabular}{cccc}
    \toprule
    Method & $r_{\rm corr}$ & $r_{\rm pred}$ & NLVR$^2$ \\
        \midrule
       PrefixLM & 12.5\% & 25\% &  75.00 \\
       PrefixLM & 25.0\% & 50\% &  76.17 \\
       PrefixLM & 37.5\% & 75\% &   76.78 \\
       PrefixLM & 50.0\% & 100\% &  76.29 \\
\bottomrule
    \end{tabular}
    }
    \caption{Varying $r_{\rm corr}$ and $r_{\rm pred}$ of PrefixLM. It is achieved by modifying the distribution of prefix length. All models are trained with a maximum of 30k steps on 4M data.
    }
    \label{tab:prefixLM}
\end{table}


\begin{table}[]
    \centering
    \small
    \setlength{\tabcolsep}{2.2 mm}{
    \begin{tabular}{l|cccccc}
    \toprule
    \multirow{2}{*}{Method} & \multicolumn{3}{c}{Zero-shot  Captioning} & \multicolumn{3}{c}{Finetuned Captioning} \\
    & B@4 & M & C & B@4 & M & C \\
    \midrule
        AR & \textbf{24.9} & \textbf{21.6} & \textbf{80.3} & 35.70 & 28.86 & 120.6  \\
        PrefixLM &  22.6 & 20.2 & 73.3 & 35.50 & 28.79 & 119.4 \\
        FLM & 20.7 & 19.6 & 70.3  & \textbf{36.68} & \textbf{29.17} & \textbf{123.0} \\
\bottomrule
    \end{tabular}
    }
    \caption{Image captioning performance of different pretraining objectives on COCO. B@4, M, C are short for BLEU@4, METEOR, CIDEr, respectively.}
    \label{tab:zscap}
\end{table}
