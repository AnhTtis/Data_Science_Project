\begin{figure}[b!]
% \vspace{-5px}
    \centering
    \includegraphics[width=\linewidth]{Figures/mole_eg.png}
    % \vspace{-10px}
    \caption{The user aligns the controller against a table surface to place the game platform (A). They can tap on the table and receive haptic feedback (B) as they hit the virtual moles in the Whack-a-Mole game (C).}
    \label{fig:demo-table}
\end{figure}


\section{In-the-Wild User Study}
We tested with 8 participants (male: 5; female: 3; mean age 21.4; all with VR experience) and paid each a \$15 gift card. Participants used their own Meta Quest (first or second generation) and performed the tasks remotely at their homes or offices. 
%We chose one scenario from each mobility category (see Appendix, Figures 2–5, and Video Figure for detailed description) for our study: 
The three scenarios created for the study include “Whack-a-mole” where the participants hit the mole 10 times, “Pet a cat” where the participants rub the cat’s belly 10 times, and “Shoot monsters”, where the participants aim and hit 20 monsters. There were two conditions: the {\it control, no-haptics condition} which every task was performed in mid-air, and the {\it haptic condition} where participants followed instructions in VR to configure the physical objects. The order of the scenarios and conditions was counterbalanced. Following the instructions in a Google Doc, participants set up the Quest headset for hand tracking and drew the guardian boundary in a space where "there is a clean tabletop surface, a moveable chair, and a small cushion or pillow" (the exact instruction given). After each task, they took off the headset and filled out a seven-question Likert-scale questionnaire about the task in a Google Form. Finally, the investigator conducted a semi-structured interview via voice call where participants elaborated on their preferences and experiences during the setup process and interactive scenarios.

