
\documentclass{article}
\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
%\usepackage[a4paper, margin=2cm]{geometry}
%\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\graphicspath{{media/}}     % organize your images and other figures under media/ folder


% Figures and Tables
\usepackage{graphicx}
\usepackage[most]{tcolorbox}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{longtable}


% Mathematics 
\usepackage{amsmath,amssymb,amsfonts}

\usepackage{textcomp}

\usepackage{verbatim}

\usepackage{xcolor}
\usepackage{url}
\usepackage{xr-hyper}
\usepackage{hyperref}
\usepackage{pdfpages} 
\usepackage{bm}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{array}
\newcolumntype{L}{>{\arraybackslash}m{3cm}}

\usepackage{fullpage}
\usepackage{rotating}
\usepackage{stmaryrd}
\usepackage{proof}


%% Tikz 
\usepackage{tikz}
\usetikzlibrary{bayesnet}
\usetikzlibrary{decorations.pathmorphing} % noisy shapes
\usetikzlibrary{fit}% fitting shapes to coordinates
\usetikzlibrary{backgrounds}	

% Theorem 
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}

% Algorithms 
\usepackage[ruled]{algorithm2e}
\usepackage{algorithmic} %% Used in Chapter 1 


% References 
\usepackage[style=numeric,sorting=none,firstinits=true]{biblatex}
\addbibresource{references.bib}




%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

% Update your Headers here
\fancyhead[LO]{Numerai Paper Series 2}
% \fancyhead[RE]{Firstauthor and Secondauthor} % Firstauthor et al. if more than 2 - must use \documentclass[twoside]{article}

  
%% Title
\title{Understanding Model Complexity for temporal tabular and multi-variate time series, case study with Numerai data science tournament
%%%% Cite as
%%%% Update your official citation here when published 
\thanks{\textit{\underline{Citation}}: 
\textbf{Authors. Title. Pages.... DOI:000000/11111.}} 
}

\author{
  Thomas Wong \\
  Imperial College London \\
  London\\
  \texttt{mw4315@ic.ac.uk} \\
  %% examples of more authors
   \And
  Prof. Mauricio Barahona \\
  Imperial College London \\
  London\\
  \texttt{m.barahona@imperial.ac.uk} \\
}


\begin{document}
\maketitle


\begin{abstract}
In this paper, we explore the use of different feature engineering and dimensionality reduction methods in multi-variate time-series modelling. Using a feature-target cross correlation time series dataset created from Numerai tournament, we demonstrate under over-parameterised regime, both the performance and predictions from different feature engineering methods converge to the same equilibrium, which can be characterised by the reproducing kernel Hilbert space. We suggest a new Ensemble method, which combines different random non-linear transforms followed by ridge regression for modelling high dimensional time-series. Compared to some commonly used deep learning models for sequence modelling, such as LSTM and transformers, our method is more robust (lower model variance over different random seeds and less sensitive to the choice of architecture) and more efficient. An additional advantage of our method is model simplicity as there is no need to use sophisticated deep learning frameworks such as PyTorch. The learned feature rankings are then applied to the temporal tabular prediction problem in the Numerai tournament, and the predictive power of feature rankings obtained from our method is better than the baseline prediction model based on moving averages. 
\end{abstract}




% keywords can be removed
\keywords{Machine Learning, Time-Series Prediction, }


\section{Introduction} 
%% Complexity of Financial Data 
Financial data are often available in the form of time series. These time series are often high dimensional with complex relationships between them. 

The complexity of financial data can be demonstrated in different aspects. Firstly, training data are often limited and the number of features that researchers can create is often much greater than the number of observations. In some research, such as \cite{kelly2022virtue}, the model complexity, defined as the feature-observation ratio can increase up to hundreds for financial instruments with a limited amount of history. Traditional setups in machine learning are not well-equipped for these data-scarce environments. Secondly, multicollinearity is very common in financial data and choosing suitable regularisation methods is a key part of model training. Thirdly, distribution shifts in data also hinder learning robust model parameters over time. It is well-known in finance that regime shifts can invalidate trading strategies. Therefore any robust machine learning models for financial forecasts require ways to deal with the non-stationarity of data. Moreover, the correlation structure between features is often hard to estimate. For example, estimating the correlation structure of a basket of assets is non-trivial as the number of assets can easily exceed the length of the price history. Dimensionality reduction methods are often required to simplify the problem. 

%% Double Descent 
Researchers do not have a consensus on the best approach to handle the complexity of financial time series. The classical view on the bias-variance trade-off suggests using simple models to avoid over-fitting, especially for environments with a low signal-to-noise ratio. However, recent research \cite{kelly2022virtue} suggests using complex models through extensive feature engineering and model ensembling to take advantage of the "double descent" phenomenon of the curve of test loss with respect to the number of model parameters (as a measure of model complexity) in deep learning \cite{NakkiranPreetum2021Dddw} and classic statistical learning models such as ridge regression \cite{Hastie19,LiangTengyuan2020JiK}. Using results from random matrix theory \cite{tao2012topics}, theoretical bounds on Out-of-Sample MSE are derived for special cases where the data generation process follows strong assumptions such as features are generated from latent space or simple non-linear models such as perceptron with ReLU activation function \cite{Hastie19}. For mis-specified models, it is possible to achieve lower test error under over-parameterised regime than the classic under-parameterised regime. A significant limitation is that real data generation process often do not follows assumptions of Gaussian distribution and independence, especially in finance where data demonstrates fat-tailed behaviours. 

%% Existing methods to model time series
Many statistical/machine learning methods have been proposed to model time series data, see \cite{lim2021time,torres2021deep} for a review of both classical and recent methods in time series modelling. Financial time series can be treated directly using classic methods such as ARIMA models \cite{percival_walden_2020} and more recently through deep learning methods such as Temporal Fusion Transformers \cite{Bryan19}. However, such deep learning methods are easily over-fitted and lead to expensive retraining for financial data, which are inherently affected by regime changes and high stochasticity. Alternatively, one can use various feature engineering methods to transform these time series into \emph{tabular form} through a process sometimes called `de-trending' in the financial industry, where the characteristics of a financial asset at a particular time point, including features from its history, are represented by a single dimensional data row (i.e., a vector). In this representation, the time dimension is not considered explicitly, as the state of the system is captured through transformed features at each time point and the continuity of the temporal dimension is not used. For example, we can summarise the time series of the return of a stock with the mean and standard deviation over different look-back periods. Grouping these data rows for various financial assets into a table at a given time, we obtain a \emph{tabular dataset}. If the features are informative, this representation can be used for prediction tasks at each time point, and allow us to employ robust and widely tested ML algorithms that are applicable to tabular data.  

% Some researchers suggest using random feature projections to create a large number of features from price time-series and then apply ridge regression to select the relevant ones  \cite{kelly2022virtue} 

%% How is the work different 
In this study, we build on top of the work in \cite{kelly2022virtue} which proposed the term `Virtue of Complexity' to describe over-parameterised models that can perform well out-of-sample. The major difference is that their work only models \textbf{univariate}  time-series and used a single feature engineering method, Random Fourier transforms. In this work, we model \text{multi-variate} time-series in parallel and consider four different feature engineering methods, including both deterministic and random ones, which will be described in detail in Section ~\ref{section:feature-eng-multi}. The purpose of their work is to offer a better theoretical understanding of the `Virtue of Complexity' phenomenon while our work is to offer an in-depth empirical study on the impact of model complexity on different feature engineering methods and machine learning models. In particular, to study the quantitative and qualitative behaviours of predictions obtained from different feature engineering methods. Models are also benchmarked against commonly used deep learning methods for sequential data, which is not investigated in the study in \cite{kelly2022virtue}. 

%Finally, we also provide open source code with new datasets used in this study (which can be shared freely as it is derived from Numerai datasets \cite{numerai-datav4.1}) \footnote{It is unlikely that the authors of \cite{kelly2022virtue} will provide datasets and code due to commercial interests as one of them is working in a hedge fund}. 

% Connection with previous work
This study is done in parallel to another work performed by the same authors on the Numerai tournament \cite{ThomasW23}. There are key differences between the two papers, with different datasets and methodologies presented.  In this paper, we worked on \textbf{time series} datasets and used different feature engineering methods to transform a sequence modelling problem into a standard supervised learning problem in tabular format, where ridge regression can be used. In the other paper, we used the dataset provided by Numerai, which is a temporal \textbf{tabular} dataset.


% Structure of the paper 
The study is organised as follows. Section ~\ref{section:paper2B-background} sets up the problem of extracting features from multi-variate time series. Section ~\ref{section:feature-eng-multi} describes and discusses different feature engineering methods that can be applied to multivariate time-series.  Section~\ref{section:application-numerai-ts} describes the machine learning model training pipeline and performances of models trained from features created from various feature engineering methods. 



\section{Background}
\label{section:paper2B-background}

In this section, we set up the problem of extracting features from an arbitrary length multi-variate time series. 

% Extract features 
\paragraph{Multi-variate time-series}
A multi-variate time-series $X$ of $T$ steps and $N$ channels can be represented as $X = (\bm{x}_1, \bm{x}_2, \dots, \bm{x}_i, \dots, \bm{x}_T) $, with $1 \leq i \leq T$ and each vector $\bm{x}_i \in \mathbb{R}^N$ represents the values of the $N$ channels at time $i$. The number of channels of the time series is assumed to be fixed throughout time with regular and synchronous sampling, i.e. the values in each vector from multiple channels arrive at the same time at a fixed frequency. 

\paragraph{Feature extraction}
Feature extraction methods are defined as functions that map the two-dimensional time-series $X \in \mathbb{R}^{T \times N}$ to a one-dimensional feature space $f(X) \in \mathbb{R}^K$ where $K$ is the number of features. Feature extraction methods reduce the dimension and noise in time-series data. With feature extraction methods, traditional machine learning models such as gradient boosting decision trees can be used without relying on advanced neural network architectures such as Recurrent Neural Networks (RNN), Long-Short-Term-Memory (LSTM) Networks or Transformers \cite{Bryan19}. 
% Computational resources can be reduced as simpler machine-learning models with fewer parameters can be used. 

%% Look-back windows
\paragraph{Look-back windows}
For time series which can potentially grow with infinite size (such as price data in finance), a look-back window is used to restrict the data size when calculating features from time series. To avoid look-ahead bias, features that represent the state of time-series at time $i$ can only be calculated using values obtained up to time $i$, which is $(\bm{x}_1, \bm{x}_2, \dots, \bm{x}_i)$. In most use cases, data collected more recently often have more importance than data collected from a more distant past. Therefore, analysis is often restricted to use the most recent $k$ data points only, which are $(\bm{x}_{i-k}, \bm{x}_{i+1-k}, \dots, \bm{x}_i)$. This represents the state of the time series at time $i$ with a look-back window of size $k$. Feature extraction methods are applied on data within the look-back window only. In practice, multiple look-back windows are used to extract features corresponding to short-term and long-term price trends. At each time $i$, features extracted with different look-back windows are concatenated to represent the state of the time series.  


%% Methods for univariate Time Series Feature Engineering 
\section{Feature Engineering Methods for univariate Time Series Prediction}

In this section, I review some feature engineering methods designed for univariate time-series predictions. 

% Catch 22 
\paragraph{Catch22} 
%% explain what kinds of features are included, and how they are different to statistical features, and the others you use} 
%% {For the thesis, include the table of Catch22 features are describe in detail what needs to be used} 
Catch22 \cite{Lubba2019} is a general-purpose time-series feature extraction method. It is an optimised set of 22 features based on the 4791 features proposed in highly comparative time-series analysis (hctsa) \cite{hctsa}. Catch22 creates a set of diverse and interpretable features of time series in which all computations are deterministic. The computed features are scale-invariant, namely, it does not capture the location (mean) and spread (variance) properties of time series. Catch22 uses interdisciplinary methods to derive features of different themes, including data distribution, temporal statistics, linear and non-linear auto-correlations and entropy. Data distribution refers to statistical properties derived from histogram of numerical values in the time series. Temporal statistics refers to basic statistical properties of temporal trends in the time series such as the longest period of consecutive values above the mean. Linear and non-linear auto-correlations refer to different ways to measure auto-correlations in the time series with ideas from the Fourier spectrum and Auto Mutual Information. Entropy refers to Shannon entropy and other complexity measures. The detailed description of how each of the features in Catch22 is calculated can be found in Table 1 in \cite{Lubba2019}. The feature selection process is based on 93 time series classification datasets from UCR time series archive \cite{Bagnall19}.


\paragraph{Rocket and MiniRocket} 
Rocket \cite{Dempster2020} uses 10000 random convolutional kernels to extract features from time series for classification tasks. The length, weights and dilation of the convolutional kernels are determined randomly. Two aggregation functions are applied on the feature maps obtained from each of the convolutional kernels, namely Global Max Pooling and the proportion of positive values in the feature map. No non-linear transforms such as ReLU are applied on the aggregated features. MiniRocket \cite{dempster_etal_2021} uses almost-deterministic random convolution kernels. It is an improvement of Rocket by removing most of the randomness in Rocket algorithm to speed up the calculation of features. The kernel length, weights and bias are tuned using the 40 development datasets used in \cite{Dempster2020}. 

\paragraph{Limitations} 
Applying the above univariate feature engineering methods to multivariate time series can be done by applying the method \textbf{independently} on each of the time series. A significant drawback of the above feature engineering methods when applied to \textbf{multivariate} time series prediction tasks is that relationship between time series are not considered. As these methods are tuned on a small selection of datasets and to use the learned parameters/features for all other unseen datasets. Another drawback is that some of the methods for univariate time series prediction takes a long computational time on large \textbf{multivariate} time series (where the number of time series $N > 20$) and thus are not practical to use. 


\section{Feature Engineering Methods for multivariate Time Series Prediction}
\label{section:feature-eng-multi}

To model multivariate time series effectively, better methods which can be applied on multiple time-series in parallel are needed. In this study, both deterministic and random transformations are considered to create tabular features for the prediction task. 

% Signatures
\subsubsection{Signature Transforms} 
Signature transforms \cite{Lyons07, Chevyrev16, Terry22} are \textbf{deterministic} transformations based on rough path theory which can be used to extract features from multi-variate time series. Signature transforms are applied on continuous paths. A path $X$ is defined as a continuous function from a finite interval $[a,b]$ to $\mathbb{R}^d$ with $d$ the dimension of the path. $X$ can be parameterised in coordinate form as $X_t = (X_t^1,X_t^2,\dots,X_t^d)$ with each $X_t^i$ being a single dimensional path. 

% Iterated Integrals 
For each index $ 1 \leq i \leq d$, the increment of $i$-th coordinate of path at time $t \in [a,b]$, $S(X)_{a,t}^i$, is defined as 
\begin{equation*}
    S(X)_{a,t}^i = \int_{a<s<t} \mathrm{d}X_s^i = X_t^i - X_a^i
\end{equation*}
As $S(X)_{a,\cdot}^i$ is also a real-valued path, the integrals can be calculated iteratively. A $k$-fold iterated integral of $X$ along the indices $i_1,\dots,i_k$ is defined as 
\begin{equation*}
    S(X)_{a,t}^{i_1,\dots,i_k} = \int_{a<t_k<t} \dots \int_{a<t_1<t_2}   \mathrm{d}X_{t_1}^{i_1}  \dots \mathrm{d}X_{t_k}^{i_k} 
\end{equation*}

% Definition of Signature 
The Signature of a path $X: [a,b] \mapsto \mathbb{R}^d$, denoted by $S(X)_{a,b}$, is defined as the infinite series of all iterated integrals of $X$, which can be represented as follows 
\begin{align*}
    S(X)_{a,b} &= (1, S(X)_{a,b}^1, \dots, S(X)_{a,b}^d,  S(X)_{a,b}^{1,1}, \dots ) \\
                &=  \bigoplus_{n=1}^{\infty} S(X)_{a,b}^n
\end{align*}

An alternative definition of signature as the response of an exponential nonlinear system is given in \cite{Terry22}. 

% Log Signature 
Log Signature can be computed by taking the logarithm on the formal power series of Signature. No information is lost as it is possible to recover the (original) Signature from Log Signature by taking the exponential \cite{Chevyrev16,Terry22}. Log Signature provides a more compact representation of the time series than Signature. 
\begin{equation*}
    log S(X)_{a,b} =  \bigoplus_{n=1}^{\infty}  \frac{(-1)^{(n-1)}}{n} S(X)_{a,b}^{\bigotimes n} 
\end{equation*}


%%% Theoretical properties of signatures 
%%% Multiplicative Functional 
%%% Universal Property of Signature in predictions (flexible) 
Signatures can be computed efficiently using the Python package signatory \cite{kidger2021signatory}. The signature is a multiplicative functional in which Chen's identity holds. This allows quick computation of signatures on overlapping slices in a path. Signatures provide a unique representation of a path which is invariant under reparameterisation \cite{Chevyrev16, Terry22}. Rough Path Theory suggests the signature of a path is a good candidate set of linear functionals which captures the aspects of the data necessary for forecasting. In particular, continuous functions of paths are approximately linear on signatures \cite{pmlr-v130-lemercier21a}. This can be considered as a version of universal approximation theorem \cite{cybenko1989approximation} for signature transforms. 




%% Interpretation of Signatures
% Level 1 Signature corresponds to the difference of two series (tail-head). When log price series are given as input, it corresponds to log return 
% Basic Statistical features can be recovered from signatures 

\paragraph{Limitations for Signature in High Dimensional Datasets}
The number of signatures and log-signatures increases exponentially with the number of channels. For time series with a large number of channels, random sampling can be applied to select a small number ($5 < N < 20$) of time-series with replacement from the original time series which signature transforms are applied on. The random sampling can be repeated for a given number of times to generate representative features of the whole multivariate time series. Similar ideas are considered in \cite{James20}, in which random projections on the high dimensional time series is used to reduce dimensionality before applying signature transforms.  

%% Lookback window
Let $\tilde{X}$ be a multivariate time series with $T$ time-steps and $d$ dimensional features, denote $\tilde{X}_s \in \mathbb{R}^d$ be the observation of the time series at timestep $s$. Procedure \ref{alg:lookback} cab be used to obtain paths, which are slices of time-series with different lookback windows. Random Signature transforms \ref{alg:randomsig} can then be used to compute the signature of the path, which summarises the information of the time series. 

\begin{algorithm}[hbt!]
\caption{Lookback Window Slicing}\label{alg:lookback}
\KwIn{time series $\tilde{X} \in \mathbb{R}^{T \times d}$, lookback $\delta$}
\KwOut{paths $X_t \in \mathbb{R}^{t \times d}$}
\For{$1 \leq t \leq T$}{
    Set start of slice $s_1 = \max(1, t - \delta)$ \;
    Set end of slice $s_2 = t$ \;
    $X_t = (\tilde{X}_{s_1},\tilde{X}_{s_1+1}, \dots, \tilde{X}_{s_2}) $ \;
}
\end{algorithm}


%% Random Signature Transform Algorithms 
\begin{algorithm}[hbt!]
\caption{Random Signature Transform}\label{alg:randomsig}
\KwIn{path $X_t \in \mathbb{R}^{t \times d}$, level of signature $L$, number of channels $C$, number of feature sets $p$,} 
where $d > C$ \;
\KwOut{log signatures $s_t \in \mathbb{R}^{pN}$ }
Define $N= \text{Number of Log Signatures of a path with } C \text{ channels up to level }  L $ \;
\For{$1 \leq i \leq p$}{
    Sample with replacement $C$ Columns from $X_t$, defined as $\tilde{X}^i_t$ \;
    Compute the Log Signatures $s_t^i \in \mathbb{R}^N$ of $\tilde{X}^i_t$ \;
}
Combine all log signatures $s_t = (s_t^1, \dots, s_t^p)$ 
\end{algorithm}



% Random Projection Kernel 
\subsection{Random Projection Kernels} 
Random projection kernels in different forms \cite{belkin2019reconciling,Dempster2020,Kelly22deep,kelly2022virtue,Gavrikov23} have been used in deep learning models to model tabular, time-series and image datasets. In the following, different implementations of random projection kernels for \text{multivariate} time series are presented, which can be computed efficiently for high dimensional time series. 

The algorithm for Random Linear Projection Kernel is presented in \ref{alg:rck}. The key idea is to use random projections to reduce the dimensionality of the time series and then taking a simple average over time dimension for a path with a given lookback size, which can be considered as assigning equal importance to each time-step in the look-back window. The implementation is much simpler than the random convolutional kernel implemented in Rocket \cite{Dempster2020}. Non-linear transformation such as ReLU can be applied on the output from the random linear projection kernel, as demonstrated in Algorithm \ref{alg:rck2}. The model is a special case of a two layer Multi-Layer Perceptron (MLP) network with the fixed weights in the first layer by random.  


%% Random Projection Kernel Transform 
\begin{algorithm}[hbt!]
\caption{Random Linear Projection Kernel}\label{alg:rck}
\KwIn{path $X_t \in \mathbb{R}^{t \times d}$, number of features sets $p$,  }
\KwOut{transformed vector $s_t \in \mathbb{R}^{p}$ }
\For{$1 \leq i \leq p$}{
    Sample feature weights $w_i \sim \mathcal{N}(0, I_{d\times d}) \in \mathbb{R}^d$ \;
    Define Weighted Time Series $Y_t = X_t w_i \in \mathbb{R}^t$ \;
    Calculate Average over weighted time series over the look-back $s_{i} = \frac{1}{t} \sum_{\tau=1}^t Y_{t,\tau} $
}
\end{algorithm}

%% Random ReLU transform 
\begin{algorithm}[hbt!]
\caption{Random Projection Kernel with ReLu Activation}\label{alg:rck2}
\KwIn{path $X_t \in \mathbb{R}^{t \times d}$, number of features sets $p$,  }
\KwOut{transformed vector $s_t \in \mathbb{R}^{p}$ }
\For{$1 \leq i \leq p$}{
    Sample feature weights $w_i \sim \mathcal{N}(0, I_{d\times d}) \in \mathbb{R}^d$ \;
    Sample bias $b_i \sim U(0,1)$ \;
    Define Weighted Time Series $Y_t = X_t w_i \in \mathbb{R}^t$ \;
    Calculate Average over weighted time series over the look-back $z_{i} = \frac{1}{t} \sum_{\tau=1}^t Y_{t,\tau} $
    Apply Non-Linear transform $s_{i} = ReLU(z_i +b_i) $
}
\end{algorithm}


Random Fourier Transforms is used in \cite{kelly2022virtue} to model return of financial price time series.

A price time series $P_t \in \mathbb{R}^T$ is first transformed into a return series $X_t \in \mathbb{R}^{T \times d} $ by taking the percentage change of price at different lookback intervals. Let $\delta_1, \dots, \delta_d \in \mathbb{N}$ be a given a list of lookback intervals, 
\begin{equation*}
    X_{t,\delta_i} = \frac{P_t - P_{t-\delta_i}}{P_{t-\delta_i}}
\end{equation*}
where $1 \leq t \leq T$ and $1 \leq i \leq d$ 

Random Fourier Transforms is then applied on the return series at each time step as in Algorithm \ref{alg:rft}. The key idea is to approximate a mixture model of Gaussian kernels with trigonometric functions \cite{Sutherland15}.  

%% Random Fourier Transform Algorithms 
\begin{algorithm}[hbt!]
\caption{Random Fourier Transform \cite{kelly2022virtue}}\label{alg:rft}
\KwIn{signal vector $x_t \in \mathbb{R}^d$, number of features sets $p$, }
\KwOut{transformed vector $s_t \in \mathbb{R}^{14p}$ }
\For{$1 \leq i \leq p$}{
    Sample $w_i \sim \mathcal{N}(0, I_{d\times d})$ \;
    Set grid $(\gamma_i)_{i=1}^14 = (0.1, 0.5, 1, 2, 4, 8, 16, 0.1, 0.5, 1, 2, 4, 8, 16)$ \;
    \For{$1 \leq j \leq 7$}{
        Set $ s_{t,14i+j} = \frac{1}{\sqrt{7p}} \sin(\gamma_j w_i^T x_t)$
    }
    \For{$8 \leq j \leq 14$}{
        Set $ s_{t,14i+j} = \frac{1}{\sqrt{7p}} \cos(\gamma_j w_i^T x_t)$
    }
}
\end{algorithm}



\section{Application to High Dimensional Financial Datasets} 
\label{section:application-numerai-ts}

\paragraph{Datasets} 
A temporal tabular dataset is a collection of matrices $\{ X_i \}_{1 \leq i \leq T}$ collected over time steps 1 to $T$. Each matrix $X_i$ represents data available at era $i$ with shape $N_i \times M$, where $N_i$ is the number of data samples (number of stocks here) in era $i$ and $M$ is the number of features describing the samples. Note that the features are fixed throughout the eras, in the sense that the same computational formula is used to compute the features in each week. On the other hand, the number of data samples (stocks) $N_i$ does not have to be constant across time. For each feature matrix $X_i$ a corresponding target $y_i$ is provided and $y_i \in \mathbb{R}^{N_i}$. Datasets from Numerai \cite{numerai-datav4.1} is an example of temporal tabular datasets in which the time steps are called Eras. In our previous paper \cite{ThomasW23}, we explored how to use different machine learning methods to build prediction models for the tournament. 

%%% Why is common to have multicollinearity in temporal tabular dataset: 
When creating features from financial time series, it is common to have multicollinearity in the features created. Consider an scenario where a continuous observation $X(t)$ is given, such as a price time series, the return series is obtained by taking differences with different lookback periods. For example , the 52-day return and the 252-day return is defined as $r_{t,52} = \frac{X(t) - X(t-52)}{X(t-52)}, r_{t,252} = \frac{X(t) - X(t-252)}{X(t-252)}$. These features will be highly correlated. 

In this study, we will group features that demonstrate high multicollinearity and replace those features with their Median and Range (called as `Group X Median' and `Group X Range'). A reason to use Median and Range instead of Mean and Standard deviation is to preserve the binned data structures (as each feature are binned values between $-2$ to $2$). 
%While not used here, if there are larger group of features, higher statistical moments can also be used.

The v4.1 of the Numerai dataset \cite{numerai-datav4.1}, which consists of a total of 1586 features is used to create the time series. The method described above is used to reduce multicollinearity of the data. The features can be separated into two different sets. One of the set consists of 1445 features which can be grouped in 289 groups by the multicollinearity criteria as these features have a high correlation (>0.9) consistently in different eras. Each group consists of an equal number of 5 features. These features demonstrate a consistent relationship due to the dataset creation process.%\footnote{This is common when creating financial signals from time-series data and well recognised by participants}. 
This set of 1445 features is called \textbf{Set A} in the rest of the chapter. The other set consists of 141 features that cannot be grouped by the multicollinearity criteria. This set of 141 features is called  \textbf{Set B} in the rest of the chapter. For features in \textbf{Set A}, we compute the median of each group to reduce the dimension of the data. This group of 289 Median features and the \textbf{Set B} features, in total 430 features are then used to perform time series modelling. 


%%% Creation of Time Series Dataset 
A time-series dataset is created using the temporal tabular dataset from Numerai \cite{numerai-datav4.1} by calculating the cross correlations between features and target. A cross correlation is defined between a matrix $X \in \mathbb{R}^{a \times b}$ and a vector $y \in \mathbb{R}^b$ is defined as a vector $\rho \in \mathbb{R}^{a}$ where $\rho_i = corr(X_i,y)$, which is pairs wise correlation of each column in the matrix with the target. The cross-correlation time-series can be considered as a `return' time-series obtained from factors data such as \cite{JensenKellyPedersen2022}. 


\begin{algorithm}[hbt!]
\caption{Cross Correlation between features and target}\label{alg:cross-corr}
\KwIn{A temporal tabular dataset $\{ X_i \}_{1 \leq i \leq T}$ of $M$ features with targets $\{ y_i \}_{1 \leq i \leq T}$ }
\KwOut{Multi-variate time series $\Omega \in \mathbb{R}^{T \times M}$ }
\For{$1 \leq i \leq T$}{
    Calculate Cross Correlation in each time step $\Omega_i = corr(X_i,y_i) \in \mathbb{R}^M$ 
}
\end{algorithm}

Applying the above procedure to the temporal tabular dataset from Numerai \cite{numerai-datav4.1}, we obtain a multi-variate time-series of 1040 time-steps (Eras) and 430 features. A key challenge of modelling the financial time series is that feature-target cross correlation is not stationary. In other words, the return of factors(alternative risk premia in stock trading) depends on market regime and is not constant over time. 




\paragraph{Prediction Task} 

The prediction task is to perform \textbf{simultaneous} forecast of the multi-variate time series using historical values. The time-series modelling task have a data embargo period of 6, meaning to predict value of time series $X(t)$ at time $t$, information up to $X(t-6)$ can be used \footnote{This is by design as the time-series represents forward return of a factor and therefore the target is resolved with suitable time lags}. 

The scoring of the task is not based on Mean Square Error as it is not a good measure of portfolio performance \cite{kelly2022virtue} \footnote{MSE and related metric such as R-Squared can be poor for a model even portfolio return is positive}. As multiple predictions are predicted at each time step, we compare the \textbf{ranking} of the predicted values and the actual returns, which is done by correlation between the predicted and actual values. Ranking is a metric that is relevant for trading since a widely used investment technique, factor timing, would require the investor to pick factors that they want to go long/short depending on recent performances. In this case, the \textbf{relative} performance of factors is more important than the \textbf{absolute} performance of the factors. To summarise the performance of predictions in the test period, the average of ranking correlations over the time steps are calculated. 


Due to missing values in the first 200 time-steps for some features \footnote{It is due to data collection process of Numerai}, we do not use data from this period in the following analysis. We split the data into training, validation and test periods as follows. 
\begin{itemize}
    \item Training: 2007-01-12 - 2015-06-12 % (Era 211 - Era 650)
    \item Validation: 2015-08-28 - 2019-04-12 % Era 661 - Era 850
    \item Test: 2020-01-03 - 2023-01-06 % Era 888 - Era 1045 
\end{itemize}

We also created three data scenario by using only a subset of features of the above time-series in each scenario
\begin{itemize}
    \item Scenario 1: All the 430 features
    \item Scenario 2: All the 289 features from Set A
    \item Scenario 3: All the 141 features from Set B
\end{itemize}




\paragraph{High Dimensional Regression} 
As the above feature engineering methods can easily create features such that the number of features are way more than the number of observations, ridge regression with regularisation is used to deal with the high dimensionality of features created. Ridge regression, with a wide range of the strength of regularisation, from ridgeless to heavily regularised, have demonstrated robust performances when feature complexity is high. A detailed theoretical justification of this can be found in \cite{Hastie19,LiangTengyuan2020JiK} and empirical illustrations in finance from \cite{kelly_malamud_2021,welch2008comprehensive}. 


\paragraph{Model Training Pipeline}

In the following, we summarise the pipeline for training machine learning models. A major difference between our study and the ones in \cite{kelly2022virtue}, is that we do not use a new regression model for each prediction step, as we believe it is unnecessary to refit model at this high frequency. We will demonstrate models can generalise well into test period even with just a single training. 

%\footnote{For studies involving longer time-scales, re-training is necessary but not at every time-step as it will leads to high instability of model coefficients. The optimal frequency to update/refit models would be open to further research}. 

\begin{enumerate}
    \item Split data into training/validation/test as above
    \item Run Feature Engineering and Machine Learning Pipeline 
        \begin{itemize}
            \item Apply Feature Engineering for multi-variate time series data: Random Signature Transforms, Random Projection Kernel, Random ReLU Kernel, Random Fourier Kernel
            \item Run Ridge Regression with different values of L2-regularisation (alpha), the value of alpha controls the smoothness of solution when the model can perfectly fits on the training data in the over-parameterised regime. 
        \end{itemize}
    \item Train Models with different complexity, over different random seeds and get predictions in validation and test period
    \item Evaluate Performances
        \begin{itemize}
            \item Model Performances based on the correlation of predicted and actual ranking of features in validation and test period
            \item The robustness(variance) of model performances
            \item Construct factor-timing portfolio 
        \end{itemize}
\end{enumerate}



\paragraph{Studying the impact on complexity on model performances} 

Machine Learning models demonstrates qualitative different behaviours under different complexity regimes, as suggested in the double descent phenomenon for deep learning and ridge regressions \cite{belkin2019reconciling,Teresa22}. For Feature Engineering methods, there is a natural definition of model complexity which is by the number of features.

In the following we consider 4 different cases which are representative of different model complexity. Each test cases uses 10 times more features than the previous ones. 

\begin{enumerate}
    \item Case 1: 140 features for Random Kernel based methods, 3 sets of random signature transforms (each with 7 random columns and truncated at second level of signatures) 
    \item Case 2: 1400 features for Random Kernel based methods, 30 sets of random signature transforms (each with 7 random columns and truncated at second level of signatures) 
    \item Case 3: 14000 features for Random Kernel based methods, 300 sets of random signature transforms (each with 7 random columns and truncated at second level of signatures) 
    \item Case 4: 140000 features for Random Kernel based methods, 3000 sets of random signature transforms (each with 7 random columns and truncated at second level of signatures) 
\end{enumerate}

For a given feature set, we perform the following analysis. For each complexity, we use 5 different L2-regularisation constant $\alpha = (1e-1, 1e+1, 1e+3, 1e+5, 1e+7)$ and average over 10 random seeds and select the $\alpha$ which gives the best average validation performance. Tables \ref{table:ts-validate-S1} and \ref{table:ts-test-S1} list the prediction performance, measures by average correlation of factor rankings in the validation and test period for each of the feature engineering methods. The \textbf{ensemble} method combines features from Random ReLU Transform, Random Fourier Transform and Signature Transform.  

 

%% For each feature engineering method, bold the row of complexity which have the best validation performances

\begin{table}[]
\resizebox{\columnwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
       & Linear & Linear & ReLU & ReLU & Fourier & Fourier & Signature & Signature & Ensemble & Ensemble \\ \hline
       & Mean               & S.D.               & Mean        & S.D.        & Mean           & S.D.           & Mean      & S.D.      & Mean     & S.D.     \\ \hline
Case 1 & 0.0627   & 0.0009    & 0.0629    & 0.0009    & 0.0665     & 0.0181    & 0.0656    & 0.0052    & 0.0670  &  0.0169   \\ \hline
Case 2 & 0.0666   & 0.0009    & 0.0679    & 0.0010    & 0.0668     & 0.0121    & 0.0660    & 0.0032    & 0.0662  &  0.0112   \\ \hline
Case 3 & 0.0630   & 0.0001    & 0.0632    & 0.0001    & 0.0727     & 0.0008    & 0.0648    & 0.0004    & 0.0728  &  0.0007   \\ \hline
Case 4 & 0.0661   & 0.0001    & 0.0675    & 0.0001    & 0.0715     & 0.0014    & 0.0633    & 0.0004    & 0.0699  &  0.0013   \\ \hline
\end{tabular}
}
\caption{Ranking Corr of regression models created with different feature engineering methods in the validation period for Scenario 1}
\label{table:ts-validate-S1}
\end{table}



\begin{table}[]
\resizebox{\columnwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
         & Linear & Linear & ReLU & ReLU & Fourier & Fourier & Signature & Signature & Ensemble & Ensemble \\ \hline
       & Mean               & S.D.               & Mean        & S.D.        & Mean           & S.D.           & Mean      & S.D.      & Mean     & S.D.     \\ \hline
Case 1 & 0.1624        & 0.0022        & 0.1630      & 0.0018    & 0.1535    & 0.0200    & 0.1607    & 0.0091    & 0.1540  &  0.0193   \\ \hline
Case 2 & 0.1535        & 0.0022        & 0.1555      & 0.0022    & 0.1437    & 0.0182    & 0.1358    & 0.0147    & 0.1402  &  0.0178   \\ \hline
Case 3 & 0.1622        & 0.0002        & 0.1626      & 0.0002    & 0.1665    & 0.0020    & 0.1593    & 0.0014    & 0.1655  &  0.0020   \\ \hline
Case 4 & 0.1556        & 0.0003        & 0.1571      & 0.0003    & 0.1566    & 0.0021    & 0.1444    & 0.0012    & 0.1519  &  0.0020   \\ \hline
\end{tabular}
}
\caption{Ranking Corr of regression models created with different feature engineering methods in the test period for Scenario 1}
\label{table:ts-test-S1}
\end{table}



There are two key observations from the above performances. 

First, for each feature engineering methods, the performance (Mean Corr) under different feature complexity does not significantly differ under the selection of optimal $\alpha$. However, as the number of features increases, the standard deviation of performances (over 10 different random seeds) significantly decreases. This suggests the 'virtue of complexity' is in fact a variance reduction effect by averaging contributions from different features, so that not a single feature dominates. Increasing the number of features allows multiple candidate models to be fitted and L2-regularisation chooses the model that is the smoothest, which can be characterised as the 'average' of these candidate models. 


Secondly, none of the methods outperform others consistently in the test period. We apply the Mann-Whitney U test for each pair of performances from different feature engineering methods in the test period. The p-values are all greater than 0.1 for all pairs, suggesting the null hypothesis that different feature engineering methods performed the same on average cannot be rejected. As there is no clear winner of the feature engineering methods, using an ensemble of different feature engineering methods provides more robust performances in both validation and test period. 



%In practice, we would select both the optimal L2-regularisation in Ridge Regression and the feature engineering method. Ensemble of feature engineering methods have the highest validation performances in Scenario 1.  Inspecting test period performances: In Scenario 1, Random Fourier transforms outperforms others. In Scenario 2, Random Linear and Random ReLU perform significantly better than Random Fourier. In Scenario 3, Random Fourier perform better than Signature methods. 




\paragraph{Comparing with Deep Learning Models} 

We run the above prediction pipeline using different deep learning models for sequence predictions. We consider three different types of recurrent neural networks (RNN,LSTM,GRU), Temporal Convolutional Network (TCN) \cite{TCNModel} and transformer \cite{Transformer17} implemented in DARTS \cite{DARTS}. 

We fix the architectures of different deep learning models to be sufficient large and then change the number of training epochs, without applying any early stopping. The architecture of the deep learning models is given in Supplementary information Section \ref{SI:deep-learning}. As suggested in \cite{NakkiranPreetum2021Dddw}, choosing a large neural network enables training to be within the over-parameterised regime and model complexity can be controlled by varying the number of training epochs using a constant learning rate without rate decay. 

We then perform a grid search over different model complexity for each deep learning model. 4 different cases of model complexity are considered where we double the amount of epochs from each previous case. 

\begin{enumerate}
    \item Case 1: 100 epochs
    \item Case 2: 200 epochs
    \item Case 3: 400 epochs
    \item Case 4: 800 epochs
\end{enumerate}

The performances in validation and test period over 10 random seeds are reported in \ref{table:dl-validate-S1} and \ref{table:dl-test-S1}. The standard deviation of model performances within the 10 random seeds increases when model complexity increases, suggesting the lack of convergence of model performances, unlike the ridge regression models with different feature engineering methods. With the exception of TCN models, other deep learning models performed worse than ridge regression models and have a higher variance. The most recent developed (and most complicated) model, Transformer performed the worst among all deep learning models. 

%% Connection between TCN with random projections 
As random projection kernels can be considered as a TCN network with frozen random weights, it suggests convolutional filter offers good inductive bias for the problem at hand. Regardless of weights being learned (as in the TCN model) or randomly initialised (as in the ridge regression models), convolutional filters can effectively summarise information in the time series. 


% The double descent hypothesis does not hold within the computational budget considered.

\begin{table}[]
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
       & LSTM & LSTM & RNN & RNN & GRU & GRU & TCN & TCN & Transformer & Transformer\\ \hline
       & Mean               & S.D.               & Mean        & S.D.        & Mean           & S.D.           & Mean      & S.D.      & Mean     & S.D.     \\ \hline
Case 1 & 0.0419  & 0.0180  & 0.0421  & 0.0130  & 0.0434     & 0.0121     & 0.0552 & 0.0042     & 0.0461 & 0.0079    \\ \hline
Case 2 & 0.0259  & 0.0248  & 0.0079  & 0.0214  & 0.0295     & 0.0163     & 0.0604 & 0.0019     & 0.0330 & 0.0155    \\ \hline
Case 3 & 0.0347  & 0.0385  & 0.0165  & 0.0318  & 0.0315     & 0.0145     & 0.0487 & 0.0312     & 0.0276 & 0.0361    \\ \hline
Case 4 & 0.0385  & 0.0225  & 0.0068  & 0.0227  & 0.0280     & 0.0157     & 0.0436 & 0.0201     & 0.0300 & 0.0296    \\ \hline
\end{tabular}
\caption{Ranking Corr of regression models created with different deep learning models in the validation period for Scenario 1}
\label{table:dl-validate-S1}
\end{table}



\begin{table}[]
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
       & LSTM & LSTM & RNN & RNN & GRU & GRU & TCN & TCN & Transformer & Transformer\\ \hline
       & Mean               & S.D.               & Mean        & S.D.        & Mean           & S.D.           & Mean      & S.D.      & Mean     & S.D.     \\ \hline
Case 1 & 0.1300  & 0.0481  & 0.0962  & 0.0504  & 0.1436     & 0.0182     & 0.1587 & 0.0114     & 0.1374 & 0.0223    \\ \hline
Case 2 & 0.0378  & 0.1149  & 0.0604  & 0.0321  & 0.1085     & 0.0443     & 0.1798 & 0.0026     & 0.0943 & 0.0586    \\ \hline
Case 3 & 0.1119  & 0.1104  & 0.0416  & 0.0401  & 0.1131     & 0.0537     & 0.1434 & 0.1153     & 0.0529 & 0.1361    \\ \hline
Case 4 & 0.1426  & 0.0666  & 0.0382  & 0.0362  & 0.0984     & 0.0540     & 0.1363 & 0.0578     & -0.0003 & 0.1022    \\ \hline
\end{tabular}
\caption{Ranking Corr of regression models created with different deep learning models in the test period for Scenario 1}
\label{table:dl-test-S1}
\end{table}



\paragraph{Convergence of model predictions} 

We then study the correlations of the predictions from ridge regression models with different feature engineering methods and TCN deep learning model. For each machine learning method, the best model complexity and regularisation (for ridge regression) based on validation period performances is used. Model predictions are highly correlated ($ \rho>0.7$) as show in Figure \ref{fig:correlations_predictions}. 

%% Add a heatmap for correlations between model performances? 
\begin{figure}
    \centering
    \includegraphics[width=0.7\columnwidth]{figure/chapter3/predcitions_correlations.png}
    \caption{Heatmap of correlations between different machine learning models}
    \label{fig:correlations_predictions}
\end{figure}

\begin{comment}
    Universal approximation theorem for MLP (Make use of Stoneâ€“Weierstrass theorem) 
    Signature transforms have linear universal approximation 
    Gradient-Boosted Decision Trees (Decision Trees are simple functions and by the-simple-function-approximation-theorem, cite the 2001 Greedy Function Approximation: A Gradient Boosting Machine paper) 
    RNN as universal approximator of dynamical system (https://www.researchgate.net/publication/295975293_Recurrent_neural_networks_are_universal_approximators) 
\end{comment}


Building on top of previous theoretical and empirical analysis of different over-parameterised machine learning models \cite{Hastie19,NakkiranPreetum2021Dddw,Teresa22}, we suggest the following hypothesis: 

\begin{proposition}[Convergence of Over-Parameterised models] ~\\ 
Under over-parameterised conditions, well-defined training processes on a parameterised classes of machine learning models that supports universal function approximation (such as MLP \cite{cybenko1989approximation} or Signature transforms \cite{Lyons07}) will converge to a stable solution. The stable solution can be characterised by the reproducing kernel Hilbert space or any equivalent families of functions. This can be considered as a stronger variant of No Free Lunch Theorem \cite{ho2002simple} under asymptotic conditions, which specified not just performances of machine learning models but also the predictions from the learned models. 

The convergence of training process under the over-parameterised conditions depends on various factors such as learning rates, data size, signal-to-noise ratio of the dataset and whether the models are well-specified or mis-specified, detailed discussion on how these factors jointly affect the convergence of training process can be found in \cite{Hastie19,NakkiranPreetum2021Dddw,Teresa22}.

A simple heuristic to detect convergence in model training process is to inspect the standard deviation of model performances over runs of different random seeds (while keeping all other parameters the same). 

\end{proposition}




\begin{comment}
    A reason to use over-parameterised conditions to train MLP,Gradient-Boosted model,etc is that we can detect convergence by running the training process long enough (and then truncate the number of ensembles/save snapshots of NN at different epochs to get many models for ensembling for free) 

    Traidtional methods that uses earlying stopping of epochs restricts learning to the classic regime (which is very sensitive to initial parameters and parameter-searches, as it is a local optimum for the test loss). 
    The Double Descent theory suggests there is NO need to use weight regularisation (as the ridgeless limit of min-norm solution is good enough) or no need to use dropout in NN under over-parameterised models. Ridgeless cases are explored in theory in depth by many papers (such as Hastie19). However in practise using ridge regression would be helpful (as my examples shown) For NN, similar problem on 
    whether using weight norm in loss func or dropout is also an open question. Understanding the interactions between different regularisation techniques under over-parameterised regime (not the classic one) would be important in developing autoML tools that select the parameters during model training process. 

\end{comment}




\paragraph{Predictive Power of factor timing models}

In the following we demonstrate the connection between the \textbf{time series} prediction task considered above and the \textbf{tabular} prediction task presented in the Numerai tournament \cite{numerai}. 

In particular, we create factor-timing models based on predicted rankings of features from the time series models as shown in Algorithm \ref{alg:factor-timing}. The raw predicted values from the time-series models are converted into normalised rankings which can be used as weights of a linear factor-timing model. 

%% Factor Timing Portfolio  
\begin{algorithm}[hbt!]
\caption{Factor Timing model }\label{alg:factor-timing}
\KwIn{For a timestep $t$ in test period, predicted values from time series model $\hat{y}_t \in \mathbb{R}^d$, temporal tabular dataset $X_t \in \mathbb{R}^{N_t \times d}$ }
\KwOut{factor timing model $\hat{z}_t \in \mathbb{R}^{N_t}$ }
Calculate normalised ranking of features $\hat{r}_t$ from predictions of the time series model 
\begin{equation*}
    \hat{r}_t = \text{rank}(\hat{y}_t) - 0.5
\end{equation*}
where rank is the function which calculates the percentile rank of a values within a vector.  $\hat{r}_t$ are ranged between $-0.5$ and $0.5$ \\
Calculate linear factor-timing predictions $\hat{z}_t = X_t \hat{r}_t $ 
\end{algorithm}


%%% Results 
We compute the performances in test period using the best prediction models selected by feature engineering and deep learning methods for the original \textbf{tabular} prediction task, which is based on correlation of the predicted and actual rankings, details can be found in \cite{ThomasW23}. Figure \ref{fig:factor-timing} shows the cumulative performances of the ridge regression model with \textbf{Ensemble} feature engineering (Feature Engineering), Temporal Convolutional Network (Deep Learning) and a baseline prediction model based on lagged moving averages. Prediction performances from Feature Engineering and Deep Learning models are very similar with Feature Engineering models performed slightly better. The factor-timing portfolios produced predictions better than a simple model based on moving averages. 

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.7\columnwidth]{figure/chapter3/factor_timing.png}
    \caption{Performances of factor timing models based on Feature Engineering (with ridge regression) and Deep Learning (TCN) approaches. The baseline Moving Averages models is also shown. }
    \label{fig:factor-timing}
\end{figure}


\begin{table}[hbt!]
\begin{tabular}{|l|l|l|l|l|l|}
\hline
                    & Mean   & Vol    & Max Draw & Sharpe & Calmar \\ \hline
Feature Engineering & 0.0193 & 0.039  & 0.238    & 0.4955 & 0.0811 \\ \hline
Deep Learning       & 0.0182 & 0.039  & 0.2391   & 0.4661 & 0.0761 \\ \hline
Moving Averages     & 0.0124 & 0.0391 & 0.9751   & 0.3184 & 0.0127 \\ \hline
\end{tabular}
\caption{Summary performances of factor timing models based on Feature Engineering (with ridge regression) and Deep Learning (TCN) approaches. The baseline Moving Averages models is also shown. }
\label{table:factor-timing-performances}
\end{table}



\newpage 
\section{Supplementary Information}

\subsection{Performances of feature engineering and deep learning models in different scenarios}
\label{SI:performances-paper2B}

In tables \ref{table:ts-validate-S2}, \ref{table:ts-test-S2}, \ref{table:ts-validate-S3}, \ref{table:ts-test-S3}, we provide the performances of different feature engineering methods in validation and test period in Scenario 2 and 3. 

In tables \ref{table:dl-validate-S2}, \ref{table:dl-test-S2}, \ref{table:dl-validate-S3}, \ref{table:dl-test-S3}, we provide the performances of different deep learning methods in validation and test period in Scenario 2 and 3. 



\begin{table}[hbt!]
\resizebox{\columnwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
       & Linear & Linear & ReLU & ReLU & Fourier & Fourier & Signature & Signature & Ensemble & Ensemble \\ \hline
       & Mean               & S.D.               & Mean        & S.D.        & Mean           & S.D.           & Mean      & S.D.      & Mean     & S.D.     \\ \hline
Case 1 & 0.0491        & 0.0004        & 0.0491      & 0.0004      & 0.0540         & 0.0066         & 0.0525    & 0.0061    & 0.0541  &  0.0064  \\ \hline
Case 2 & 0.0533        & 0.0007        & 0.0535      & 0.0007      & 0.0488         & 0.0006         & 0.0485    & 0.0002    & 0.0489  &  0.0006  \\ \hline
Case 3 & 0.0492        & 0.0001        & 0.0491      & 0.0001      & 0.0530         & 0.0011         & 0.0520    & 0.0006    & 0.0531  &  0.0011  \\ \hline
Case 4 & 0.0529        & 0.0001        & 0.0530      & 0.0001      & 0.0488         & 0.0001         & 0.0485    & 0.0000    & 0.0489  &  0.0001  \\ \hline
\end{tabular}
}
\caption{Ranking Corr of regression models created with different feature engineering methods in the validation period for Scenario 2}
\label{table:ts-validate-S2}
\end{table}



\begin{table}[hbt!]
\resizebox{\columnwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
         & Linear & Linear & ReLU & ReLU & Fourier & Fourier & Signature & Signature & Ensemble & Ensemble \\ \hline
       & Mean               & S.D.               & Mean        & S.D.        & Mean           & S.D.           & Mean      & S.D.      & Mean     & S.D.     \\ \hline
Case 1 & 0.0848        & 0.0006        & 0.0848      & 0.0006      & 0.0781         & 0.0084         & 0.0826    & 0.0075    & 0.0788  &  0.0084   \\ \hline
Case 2 & 0.0852        & 0.0011        & 0.0853      & 0.0009      & 0.0839         & 0.0007         & 0.0845    & 0.0003    & 0.0839  &  0.0007   \\ \hline
Case 3 & 0.0847        & 0.0001        & 0.0846      & 0.0001      & 0.0831         & 0.0011         & 0.0861    & 0.0008    & 0.0833  &  0.0010   \\ \hline
Case 4 & 0.0858        & 0.0001        & 0.0858      & 0.0001      & 0.0841         & 0.0000         & 0.0844    & 0.0000    & 0.0842  &  0.0000   \\ \hline
\end{tabular}
}
\caption{Ranking Corr of regression models created with different feature engineering methods in the test period for Scenario 2}
\label{table:ts-test-S2}
\end{table}




\begin{table}[hbt!]
\resizebox{\columnwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
       & Linear & Linear & ReLU & ReLU & Fourier & Fourier & Signature & Signature & Ensemble & Ensemble \\ \hline
       & Mean               & S.D.               & Mean        & S.D.        & Mean           & S.D.           & Mean      & S.D.      & Mean     & S.D.     \\ \hline
Case 1 & 0.0838        & 0.0004        & 0.0851      & 0.0067      & 0.0846         & 0.0058         & 0.0745    & 0.0001    & 0.0844  &  0.0057   \\ \hline
Case 2 & 0.0746        & 0.0000        & 0.0762      & 0.0039      & 0.0873         & 0.0105         & 0.0797    & 0.0084    & 0.0853  &  0.0107   \\ \hline
Case 3 & 0.0829        & 0.0009        & 0.0850      & 0.0008      & 0.0808         & 0.0006         & 0.0746    & 0.0000    & 0.0804  &  0.0006  \\ \hline
Case 4 & 0.0750        & 0.0003        & 0.0778      & 0.0004      & 0.0873         & 0.0013         & 0.0788    & 0.0008    & 0.0855  &  0.0013   \\ \hline
\end{tabular}
}
\caption{Ranking Corr of regression models created with different feature engineering methods in the validation period for Scenario 3}
\label{table:ts-validate-S3}
\end{table}



\begin{table}[hbt!]
\resizebox{\columnwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
         & Linear & Linear & ReLU & ReLU & Fourier & Fourier & Signature & Signature & Ensemble & Ensemble \\ \hline
       & Mean               & S.D.               & Mean        & S.D.        & Mean           & S.D.           & Mean      & S.D.      & Mean     & S.D.     \\ \hline
Case 1 & 0.0819        & 0.0173        & 0.0904      & 0.0140      & 0.1720         & 0.0161         & 0.1891    & 0.0001    & 0.1706  &  0.0168   \\ \hline
Case 2 & 0.1891        & 0.0000        & 0.0851      & 0.0092      & 0.1180         & 0.0250         & 0.0841    & 0.0172    & 0.1124  &  0.0247   \\ \hline
Case 3 & 0.0873        & 0.0040        & 0.0932      & 0.0037      & 0.1803         & 0.0009         & 0.1890    & 0.0000    & 0.1791  &  0.0009   \\ \hline
Case 4 & 0.0828        & 0.0011        & 0.0843      & 0.0012      & 0.1325         & 0.0045         & 0.0816    & 0.0017    & 0.1268  &  0.0045   \\ \hline
\end{tabular}
}
\caption{Ranking Corr of regression models created with different feature engineering methods in the test period for Scenario 3}
\label{table:ts-test-S3}
\end{table}




\begin{table}[hbt!]
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
       & LSTM   & LSTM   & RNN    & RNN    & GRU    & GRU    & TCN    & TCN    & Transformer & Transformer \\ \hline
       & Mean   & S.D.   & Mean   & S.D.   & Mean   & S.D.   & Mean   & S.D.   & Mean        & S.D.        \\ \hline
Case 1 & 0.0365 & 0.0144 & 0.0280 & 0.0120 & 0.0318 & 0.0179 & 0.0337 & 0.0056 & 0.0326      & 0.0081      \\ \hline
Case 2 & 0.0270 & 0.0140 & 0.0055 & 0.0106 & 0.0236 & 0.0155 & 0.0396 & 0.0019 & 0.0278      & 0.0129      \\ \hline
Case 3 & 0.0349 & 0.0181 & 0.0034 & 0.0278 & 0.0179 & 0.0078 & 0.0418 & 0.0034 & 0.0287      & 0.0123      \\ \hline
Case 4 & 0.0252 & 0.0200 & 0.0092 & 0.0225 & 0.0166 & 0.0104 & 0.0343 & 0.0064 & 0.0058      & 0.0191      \\ \hline
\end{tabular}
\caption{Ranking Corr of regression models created with different deep learning models in the validation period for Scenario 2}
\label{table:dl-validate-S2}
\end{table}



\begin{table}[hbt!]
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
       & LSTM   & LSTM   & RNN    & RNN    & GRU    & GRU    & TCN    & TCN    & Transformer & Transformer \\ \hline
       & Mean   & S.D.   & Mean   & S.D.   & Mean   & S.D.   & Mean   & S.D.   & Mean        & S.D.        \\ \hline
Case 1 & 0.0661 & 0.0217 & 0.0753 & 0.0112 & 0.0718 & 0.0155 & 0.0763 & 0.0072 & 0.0726      & 0.0082      \\ \hline
Case 2 & 0.0651 & 0.0239 & 0.0317 & 0.0246 & 0.0692 & 0.0132 & 0.0857 & 0.0022 & 0.0604      & 0.0108      \\ \hline
Case 3 & 0.0556 & 0.0351 & 0.0316 & 0.0306 & 0.0580 & 0.0127 & 0.0881 & 0.0046 & 0.0428      & 0.0461      \\ \hline
Case 4 & 0.0526 & 0.0242 & 0.0391 & 0.0229 & 0.0588 & 0.0147 & 0.0852 & 0.0099 & 0.0483      & 0.0266      \\ \hline
\end{tabular}
\caption{Ranking Corr of regression models created with different deep learning models in the test period for Scenario 2}
\label{table:dl-test-S2}
\end{table}




\begin{table}[hbt!]
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
       & LSTM & LSTM & RNN & RNN & GRU & GRU & TCN & TCN & Transformer & Transformer\\ \hline
       & Mean               & S.D.               & Mean        & S.D.        & Mean           & S.D.           & Mean      & S.D.      & Mean     & S.D.     \\ \hline
Case 1 & 0.0257  & 0.0522  & 0.0195  & 0.0482  & 0.0190     & 0.0260     & 0.0682 & 0.0116     & 0.0222  & 0.0375    \\ \hline
Case 2 & 0.0168  & 0.0429  & 0.0411  & 0.0302  & 0.0203     & 0.0303     & 0.0735 & 0.0032     & 0.0201  & 0.0430    \\ \hline
Case 3 & 0.0324  & 0.0532  & 0.0208  & 0.0460  & 0.0272     & 0.0239     & 0.0498 & 0.0448     & 0.0080  & 0.0471    \\ \hline
Case 4 & 0.0263  & 0.0398  & 0.0313  & 0.0579  & 0.0206     & 0.0355     & 0.0429 & 0.0468     & -0.0089 & 0.0239    \\ \hline
\end{tabular}
\caption{Ranking Corr of regression models created with different deep learning models in the validation period for Scenario 3}
\label{table:dl-validate-S3}
\end{table}


\begin{table}[hbt!]
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
       & LSTM & LSTM & RNN & RNN & GRU & GRU & TCN & TCN & Transformer & Transformer\\ \hline
       & Mean               & S.D.               & Mean        & S.D.        & Mean           & S.D.           & Mean      & S.D.      & Mean     & S.D.     \\ \hline
Case 1 & 0.0895  & 0.1485  & 0.0585  & 0.1005  & 0.0401     & 0.0665     & 0.1869 & 0.0113     & 0.0366  & 0.1187    \\ \hline
Case 2 & 0.0282  & 0.1668  & 0.0847  & 0.0624  & 0.0740     & 0.0847     & 0.1951 & 0.0075     & 0.0227  & 0.1309    \\ \hline
Case 3 & 0.0607  & 0.1716  & 0.0115  & 0.0566  & 0.0731     & 0.0884     & 0.1330 & 0.1316     & 0.0762  & 0.0975    \\ \hline
Case 4 & 0.0183  & 0.1494  & 0.0296  & 0.0326  & 0.0420     & 0.0561     & 0.1027 & 0.1590     & -0.0112 & 0.1023    \\ \hline
\end{tabular}
\caption{Ranking Corr of regression models created with different deep learning models in the test period for Scenario 3}
\label{table:dl-test-S3}
\end{table}




\newpage 
\subsection{Hyper-parameters for deep learning models}
\label{SI:deep-learning}

\begin{figure}[hbt!]
\begin{itemize}
    \item Deep Learning
    \begin{itemize}
        \item LSTM/RNN/GRU
        \begin{itemize}
            \item input chunk length:50
            \item output chunk length: 1 
            \item batch size: 32
            \item number of rnn layers: 5 
            \item hidden dimension: 50 
            \item dropout: 0.01 
        \end{itemize}     
    \end{itemize}    
    \begin{itemize}
        \item TCN
        \begin{itemize}
            \item input chunk length:50
            \item output chunk length: 1 
            \item batch size: 32
            \item number of layers: 5 
            \item kernel size: 3 
            \item number of filters: 3
        \end{itemize}     
    \end{itemize} 
    \begin{itemize}
        \item Transformer 
        \begin{itemize}
            \item input chunk length:50
            \item output chunk length: 1 
            \item batch size: 32
            \item d model: 16
            \item nhead: 4  
            \item number of encoder layers: 2
            \item number of decoder layers: 2 
            \item dimension of feedforward layer: 512 
        \end{itemize}     
    \end{itemize} 
\end{itemize}
\caption{Hyper-parameters for deep learning models used, where the names of parameters followed darts \cite{DARTS}. For parameters not named, default values from darts are used.}    
\label{numerai-signals-hyperspace-1}
\end{figure}




\newpage 
\section{Acknowledgments}
This was was supported in part by the Wellcome Trust under Grant 108908/B/15/Z and by the EPSRC under grant EP/N014529/1 funding the EPSRC Centre for Mathematics of Precision Healthcare at Imperial. 


%Bibliography
\newpage
\printbibliography


\end{document}
