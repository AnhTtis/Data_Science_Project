%%%%%%%%%%%%%%%% Project 3 

%% Causlaity 

https://plato.stanford.edu/entries/kant-hume-causality/ 



%% Our Paper 
@misc{ThomasW23,
  doi = {10.48550/ARXIV.2301.00790},
  url = {https://arxiv.org/abs/2301.00790},
  author = {Wong, Thomas and Barahona, Mauricio},
  title = {Robust machine learning pipelines for trading market-neutral stock portfolios},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}






%% Random matrix Theory 
@book{tao2012topics,
  title={Topics in random matrix theory},
  author={Tao, Terence},
  volume={132},
  year={2012},
  publisher={American Mathematical Soc.}
}



%% Review on TS modelling 
@article{lim2021time,
  title={Time-series forecasting with deep learning: a survey},
  author={Lim, Bryan and Zohren, Stefan},
  journal={Philosophical Transactions of the Royal Society A},
  volume={379},
  number={2194},
  pages={20200209},
  year={2021},
  publisher={The Royal Society Publishing}
}

@article{torres2021deep,
  title={Deep learning for time series forecasting: a survey},
  author={Torres, Jos{\'e} F and Hadjout, Dalil and Sebaa, Abderrazak and Mart{\'\i}nez-{\'A}lvarez, Francisco and Troncoso, Alicia},
  journal={Big Data},
  volume={9},
  number={1},
  pages={3--21},
  year={2021},
  publisher={Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New~…}
}




%%% Double deep descent 
@article{NakkiranPreetum2021Dddw,
issn = {1742-5468},
journal = {Journal of statistical mechanics},
language = {eng},
number = {12},
pages = {124003-},
title = {Deep double descent: where bigger models and more data hurt},
volume = {2021},
year = {2021},
author = {Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
}


@article{belkin2019reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={32},
  pages={15849--15854},
  year={2019},
  publisher={National Acad Sciences}
}

@article{Teresa22,
author = {TeresaHuang, Ningyuan and Hogg, David W. and Villar, Soledad},
title = {Dimensionality Reduction, Regularization, and Generalization in Overparameterized Regressions},
journal = {SIAM Journal on Mathematics of Data Science},
volume = {4},
number = {1},
pages = {126-152},
year = {2022},
doi = {10.1137/20M1387821},
}



@misc{Couto22,
  doi = {10.48550/ARXIV.2211.10322},
  url = {https://arxiv.org/abs/2211.10322},
  author = {Sa-Couto, Luis and Ramos, Jose Miguel and Almeida, Miguel and Wichert, Andreas},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Understanding the double descent curve in Machine Learning},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



%%% Universal approximation theorem 
@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}


@article{ZHOU2020787,
title = {Universality of deep convolutional neural networks},
journal = {Applied and Computational Harmonic Analysis},
volume = {48},
number = {2},
pages = {787-794},
year = {2020},
issn = {1063-5203},
doi = {https://doi.org/10.1016/j.acha.2019.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S1063520318302045},
author = {Ding-Xuan Zhou},
keywords = {Deep learning, Convolutional neural network, Universality, Approximation theory},
}


@inproceedings{schafer2006recurrent,
  title={Recurrent neural networks are universal approximators},
  author={Sch{\"a}fer, Anton Maximilian and Zimmermann, Hans Georg},
  booktitle={Artificial Neural Networks--ICANN 2006: 16th International Conference, Athens, Greece, September 10-14, 2006. Proceedings, Part I 16},
  pages={632--640},
  year={2006},
  organization={Springer}
}





%%% No Free Lunch 
@article{ho2002simple,
  title={Simple explanation of the no-free-lunch theorem and its implications},
  author={Ho, Yu-Chi and Pepyne, David L},
  journal={Journal of optimization theory and applications},
  volume={115},
  pages={549--570},
  year={2002},
  publisher={Springer}
}


%%%% Lottery ticket hypothesis 


@inproceedings{
frankle2018the,
title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
author={Jonathan Frankle and Michael Carbin},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rJl-b3RcF7},
}

@inproceedings{NEURIPS2019_a4613e8d,
 author = {Morcos, Ari and Yu, Haonan and Paganini, Michela and Tian, Yuandong},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers},
 url = {https://proceedings.neurips.cc/paper/2019/file/a4613e8d72a61b3b69b32d040f89ad81-Paper.pdf},
 volume = {32},
 year = {2019}
}




%%% Virtue of Complexity/ Ridge Regression

@article{kelly2022virtue,
  title={The Virtue of Complexity Everywhere},
  author={Kelly, Bryan T and Malamud, Semyon and Zhou, Kangying},
  journal={Available at SSRN},
  year={2022}
}

@article{kelly_malamud_2021,
 title={The virtue of complexity in machine learning portfolios},
 DOI={10.2139/ssrn.3984925}, 
 journal={SSRN Electronic Journal}, 
 author={Kelly, Bryan T. and Malamud, Semyon},
 year={2021}
 } 


 @article{welch2008comprehensive,
  title={A comprehensive look at the empirical performance of equity premium prediction},
  author={Welch, Ivo and Goyal, Amit},
  journal={The Review of Financial Studies},
  volume={21},
  number={4},
  pages={1455--1508},
  year={2008},
  publisher={Society for Financial Studies}
}



 @misc{Hastie19,
  doi = {10.48550/ARXIV.1903.08560},
  url = {https://arxiv.org/abs/1903.08560},
  author = {Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J.},
  keywords = {Statistics Theory (math.ST), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Surprises in High-Dimensional Ridgeless Least Squares Interpolation},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{LiangTengyuan2020JiK,
author = {Liang, Tengyuan and Rakhlin, Alexander},
address = {Hayward},
copyright = {Copyright Institute of Mathematical Statistics Jun 2020},
issn = {0090-5364},
journal = {The Annals of statistics},
keywords = {Asymptotic methods ; Covariance ; Datasets ; Eigenvalues ; Kernel functions ; Mathematical functions ; Nonlinear systems ; Regression analysis ; Regularization ; Upper bounds},
language = {eng},
number = {3},
pages = {1329-},
publisher = {Institute of Mathematical Statistics},
title = {Just interpolate: Kernel “Ridgeless” regression can generalize},
volume = {48},
year = {2020},
}




%% Randomness in NN 
@misc{Picard21,
  doi = {10.48550/ARXIV.2109.08203},
  url = {https://arxiv.org/abs/2109.08203},
  author = {Picard, David},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Torch.manual_seed(3407) is all you need: On the influence of random seeds in deep learning architectures for computer vision},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}


@article{huang2017snapshot,
  title={Snapshot ensembles: Train 1, get m for free},
  author={Huang, Gao and Li, Yixuan and Pleiss, Geoff and Liu, Zhuang and Hopcroft, John E and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1704.00109},
  year={2017}
}


@misc{Moosavi16,
  doi = {10.48550/ARXIV.1610.08401},
  author = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Universal adversarial perturbations},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@InProceedings{pmlr-v162-pezeshki22a,
  title = 	 {Multi-scale Feature Learning Dynamics: Insights for Double Descent},
  author =       {Pezeshki, Mohammad and Mitra, Amartya and Bengio, Yoshua and Lajoie, Guillaume},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {17669--17690},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/pezeshki22a/pezeshki22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/pezeshki22a.html},
}


 


%% Deep Regression Ensemble 

@misc{Kelly22deep,
author = {Didisheim, Antoine and Kelly, Bryan and Malamud, Semyon},
  %doi = {10.48550/ARXIV.2203.05417},
  %url = {https://arxiv.org/abs/2203.05417},
  %keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Regression Ensembles},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Zero v1.0 Universal}
}






%%%%%%%%%% Transformation 


%% Catch22 
@Article{Lubba2019,
author={Lubba, Carl H.
and Sethi, Sarab S.
and Knaute, Philip
and Schultz, Simon R.
and Fulcher, Ben D.
and Jones, Nick S.},
title={catch22: CAnonical Time-series CHaracteristics},
journal={Data Mining and Knowledge Discovery},
year={2019},
month={Nov},
day={01},
volume={33},
number={6},
pages={1821-1852},
issn={1573-756X},
doi={10.1007/s10618-019-00647-x},
url={https://doi.org/10.1007/s10618-019-00647-x}
}

%% hctsa
@article{hctsa,
publisher = {Royal Society, The},
title = {Highly comparative time-series analysis: the empirical structure of time series and their methods},
year = {2013-Apr},
author = {Fulcher, BD and Little, MA and Jones, NS},
keywords = {Science & Technology},
language = {eng},
}


%%% Signature Transforms 

@misc{Chevyrev16,
  doi = {10.48550/ARXIV.1603.03788},
  url = {https://arxiv.org/abs/1603.03788},
  author = {Chevyrev, Ilya and Kormilitzin, Andrey},
  title = {A Primer on the Signature Method in Machine Learning},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Terry22,
  doi = {10.48550/ARXIV.2206.14674},
  url = {https://arxiv.org/abs/2206.14674},
  author = {Lyons, Terry and McLeod, Andrew D.},
  title = {Signature Methods in Machine Learning},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{James20,
  doi = {10.48550/ARXIV.2006.00873},
  url = {https://arxiv.org/abs/2006.00873},
  author = {Morrill, James and Fermanian, Adeline and Kidger, Patrick and Lyons, Terry},
  title = {A Generalised Signature Method for Multivariate Time Series Feature Extraction},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{
kidger2021signatory,
title={Signatory: differentiable computations of the signature and logsignature transforms, on both {\{}CPU{\}} and {\{}GPU{\}}},
author={Patrick Kidger and Terry Lyons},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=lqU2cs3Zca}
}

@inproceedings{Lyons07,
publisher = {Springer Berlin Heidelberg},
series = {École d'Été de Probabilités de Saint-Flour, 1908},
title = {Differential Equations Driven by Rough Paths : Ecole d’Eté de Probabilités de Saint-Flour XXXIV-2004 },
year = {2007},
author = {Lyons, Terry J.},
address = {Berlin, Heidelberg},
edition = {1st ed. 2007.},
isbn = {1-280-85347-6},
keywords = {Mathematical analysis},
language = {eng},
}



@InProceedings{pmlr-v130-lemercier21a,
  title = 	 { Distribution Regression for Sequential Data },
  author =       {Lemercier, Maud and Salvi, Cristopher and Damoulas, Theodoros and Bonilla, Edwin and Lyons, Terry},
  booktitle = 	 {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3754--3762},
  year = 	 {2021},
  editor = 	 {Banerjee, Arindam and Fukumizu, Kenji},
  volume = 	 {130},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--15 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v130/lemercier21a/lemercier21a.pdf},
  url = 	 {https://proceedings.mlr.press/v130/lemercier21a.html},
}







%%% Random Transforms


@misc{Sutherland15,
  author = {Sutherland, Danica J. and Schneider, Jeff},
  %keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
 %doi = {10.48550/ARXIV.1506.02785},
  %url = {https://arxiv.org/abs/1506.02785},
  title = {On the Error of Random Fourier Features},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{Xu20,
  author = {Xu, Zhenlin and Liu, Deyi and Yang, Junlin and Raffel, Colin and Niethammer, Marc},
  %doi = {10.48550/ARXIV.2007.13003},
  %url = {https://arxiv.org/abs/2007.13003},
  %keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Robust and Generalizable Visual Representation Learning via Random Convolutions},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license},
}

@Article{Dempster2020,
author={Dempster, Angus
and Petitjean, Fran{\c{c}}ois
and Webb, Geoffrey I.},
title={ROCKET: exceptionally fast and accurate time series classification using random convolutional kernels},
journal={Data Mining and Knowledge Discovery},
year={2020},
month={Sep},
day={01},
volume={34},
number={5},
pages={1454-1495},
issn={1573-756X},
doi={10.1007/s10618-020-00701-z},
url={https://doi.org/10.1007/s10618-020-00701-z}
}

@inproceedings{dempster_etal_2021,
  author    = {Dempster, Angus and Schmidt, Daniel F and Webb, Geoffrey I},
  title     = {{MiniRocket}: A Very Fast (Almost) Deterministic Transform for Time Series Classification},
  booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  publisher = {ACM},
  address   = {New York},
  year      = {2021},
  pages     = {248--257}
}


@misc{Horn19,
  doi = {10.48550/ARXIV.1901.07329},
  url = {https://arxiv.org/abs/1901.07329},
  author = {Horn, Franziska and Pack, Robert and Rieger, Michael},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {The autofeat Python Library for Automated Feature Engineering and Selection},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}




@misc{Gavrikov23,
  author = {Gavrikov, Paul and Keuper, Janis},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Rethinking 1x1 Convolutions: Can we train CNNs with Frozen Random Filters?},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}








%% TimeSeries Deep Models 


@book{percival_walden_2020, 
place={Cambridge}, 
series={Cambridge Series in Statistical and Probabilistic Mathematics}, 
title={Spectral Analysis for Univariate Time Series}, 
%DOI={10.1017/9781139235723}, 
publisher={Cambridge University Press},
author={Percival, Donald B. and Walden, Andrew T.}, 
year={2020}, 
collection={Cambridge Series in Statistical and Probabilistic Mathematics},
}


@misc{Bryan19,
  doi = {10.48550/ARXIV.1912.09363},
  url = {https://arxiv.org/abs/1912.09363},
  author = {Lim, Bryan and Arik, Sercan O. and Loeff, Nicolas and Pfister, Tomas},
  title = {Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}




@article{DARTS,
  author  = {Julien Herzen and Francesco LÃ¤ssig and Samuele Giuliano Piazzetta and Thomas Neuer and LÃ©o Tafti and Guillaume Raille and Tomas Van Pottelbergh and Marek Pasieka and Andrzej Skrodzki and Nicolas Huguenin and Maxime Dumonal and Jan KoÅ›cisz and Dennis Bader and FrÃ©dÃ©rick Gusset and Mounir Benheddi and Camila Williamson and Michal Kosinski and Matej Petrik and GaÃ«l Grosch},
  title   = {Darts: User-Friendly Modern Machine Learning for Time Series},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {124},
  pages   = {1-6},
  url     = {http://jmlr.org/papers/v23/21-1177.html}
}



@misc{TCNModel,
  doi = {10.48550/ARXIV.1803.01271},
  url = {https://arxiv.org/abs/1803.01271},
  author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@misc{Transformer17,
  doi = {10.48550/ARXIV.1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Attention Is All You Need},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}







%% Clustering
@Article{Traag2019,
author={Traag, V. A.
and Waltman, L.
and van Eck, N. J.},
title={From Louvain to Leiden: guaranteeing well-connected communities},
journal={Scientific Reports},
year={2019},
month={Mar},
day={26},
volume={9},
number={1},
pages={5233},
%issn={2045-2322},
%doi={10.1038/s41598-019-41695-z},
%url={https://doi.org/10.1038/s41598-019-41695-z}
}



@article{Barahona14,
  author={Lambiotte, Renaud and Delvenne, Jean-Charles and Barahona, Mauricio},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={Random Walks, Markov Processes and the Multiscale Modular Organization of Complex Networks}, 
  year={2014},
  volume={1},
  number={2},
  pages={76-90},
  %doi={10.1109/TNSE.2015.2391998}
}


@article{Barahona19,
  title = {Multiscale dynamical embeddings of complex networks},
  author = {Schaub, Michael T. and Delvenne, Jean-Charles and Lambiotte, Renaud and Barahona, Mauricio},
  journal = {Phys. Rev. E},
  volume = {99},
  issue = {6},
  pages = {062308},
  numpages = {18},
  year = {2019},
  month = {Jun},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.99.062308},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.99.062308}
}





%%% Datasets 
@online{numerai-datav4.1,
  author="Numerai",
  title="{Numerai Hedge Fund}",
  url="https://numer.ai/data/v4.1",
  note="(2023, Feb 15)",
}

@article{JensenKellyPedersen2022,
   author = {Jensen, Theis Ingerslev and Kelly, Bryan T and Pedersen, Lasse Heje},
   journal = {Journal of Finance, Forthcoming},
   title = {Is There A Replication Crisis In Finance?},
   year = {2022}
}


@ARTICLE{Bagnall19,
  author={Dau, Hoang Anh and Bagnall, Anthony and Kamgar, Kaveh and Yeh, Chin-Chia Michael and Zhu, Yan and Gharghabi, Shaghayegh and Ratanamahatana, Chotirat Ann and Keogh, Eamonn},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={The UCR time series archive}, 
  year={2019},
  volume={6},
  number={6},
  pages={1293-1305},
  %doi={10.1109/JAS.2019.1911747},
  }
