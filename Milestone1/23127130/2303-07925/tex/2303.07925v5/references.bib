%%%%%%%%%%%%%%%% Project 3 



%% Introduction 
@inproceedings{song2018situ,
  title={In-situ ai: Towards autonomous and incremental deep learning for iot systems},
  author={Song, Mingcong and Zhong, Kan and Zhang, Jiaqi and Hu, Yang and Liu, Duo and Zhang, Weigong and Wang, Jing and Li, Tao},
  booktitle={2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)},
  pages={92--103},
  year={2018},
  organization={IEEE}
}

@article{buczak2015survey,
  title={A survey of data mining and machine learning methods for cyber security intrusion detection},
  author={Buczak, Anna L and Guven, Erhan},
  journal={IEEE Communications surveys \& tutorials},
  volume={18},
  number={2},
  pages={1153--1176},
  year={2015},
  publisher={IEEE}
}


@article{zhu2021class,
  title={Class-incremental learning via dual augmentation},
  author={Zhu, Fei and Cheng, Zhen and Zhang, Xu-Yao and Liu, Cheng-lin},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14306--14318},
  year={2021}
}


@inproceedings{NEURIPS2022_c8ac22c0,
 author = {Pei, Yixuan and Qing, Zhiwu and CEN, Jun and Wang, Xiang and Zhang, Shiwei and Wang, Yaxiong and Tang, Mingqian and Sang, Nong and Qian, Xueming},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {31002--31016},
 publisher = {Curran Associates, Inc.},
 title = {Learning a Condensed Frame for Memory-Efficient Video Class-Incremental Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/c8ac22c0d4b263618f2a4f4657948912-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inproceedings{NEURIPS2022_ae817e85,
 author = {Zou, Yixiong and Zhang, Shanghang and Li, Yuhua and Li, Ruixuan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {27267--27279},
 publisher = {Curran Associates, Inc.},
 title = {Margin-Based Few-Shot Class-Incremental Learning with Class-Level Overfitting Mitigation},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/ae817e85f71ef86d5c9566598e185b89-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}


@article{arulkumaran2017deep,
  title={Deep reinforcement learning: A brief survey},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={26--38},
  year={2017},
  publisher={IEEE}
}


@article{deng2016deep,
  title={Deep direct reinforcement learning for financial signal representation and trading},
  author={Deng, Yue and Bao, Feng and Kong, Youyong and Ren, Zhiquan and Dai, Qionghai},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={3},
  pages={653--664},
  year={2016},
  publisher={IEEE}
}





@inproceedings{NEURIPS2022_d112fdd3,
 author = {Hong, Yitian and Jin, Yaochu and Tang, Yang},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {32438--32449},
 publisher = {Curran Associates, Inc.},
 title = {Rethinking Individual Global Max in Cooperative Multi-Agent Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/d112fdd31c830900d1f2e4ccebffb54f-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inproceedings{NEURIPS2022_eb4898d6,
 author = {Bastani, Osbert and Ma, Jason Yecheng and Shen, Estelle and Xu, Wanqiao},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {36259--36269},
 publisher = {Curran Associates, Inc.},
 title = {Regret Bounds for Risk-Sensitive Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/eb4898d622e9a48b5f9713ea1fcff2bf-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}



@inproceedings{NEURIPS2020_77441296,
 author = {Zhang, Kaiqing and SUN, TAO and Tao, Yunzhe and Genc, Sahika and Mallya, Sunil and Basar, Tamer},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {10571--10583},
 publisher = {Curran Associates, Inc.},
 title = {Robust Multi-Agent Reinforcement Learning with Model Uncertainty},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/774412967f19ea61d448977ad9749078-Paper.pdf},
 volume = {33},
 year = {2020}
}



@inproceedings{NEURIPS2021_0d5bd023,
 author = {Acuna, David and Philion, Jonah and Fidler, Sanja},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {1686--1699},
 publisher = {Curran Associates, Inc.},
 title = {Towards Optimal Strategies for Training Self-Driving Perception Models in Simulation},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/0d5bd023a3ee11c7abca5b42a93c4866-Paper.pdf},
 volume = {34},
 year = {2021}
}



@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}



@inproceedings{arndt2020meta,
  title={Meta reinforcement learning for sim-to-real domain adaptation},
  author={Arndt, Karol and Hazara, Murtaza and Ghadirzadeh, Ali and Kyrki, Ville},
  booktitle={2020 IEEE international conference on robotics and automation (ICRA)},
  pages={2725--2731},
  year={2020},
  organization={IEEE}
}


@inproceedings{higgins2017darla,
  title={Darla: Improving zero-shot transfer in reinforcement learning},
  author={Higgins, Irina and Pal, Arka and Rusu, Andrei and Matthey, Loic and Burgess, Christopher and Pritzel, Alexander and Botvinick, Matthew and Blundell, Charles and Lerchner, Alexander},
  booktitle={International Conference on Machine Learning},
  pages={1480--1490},
  year={2017},
  organization={PMLR}
}

@inproceedings{ma2018improved,
  title={Improved robustness and safety for autonomous vehicle control with adversarial reinforcement learning},
  author={Ma, Xiaobai and Driggs-Campbell, Katherine and Kochenderfer, Mykel J},
  booktitle={2018 IEEE Intelligent Vehicles Symposium (IV)},
  pages={1665--1671},
  year={2018},
  organization={IEEE}
}


@article{mott2019towards,
  title={Towards interpretable reinforcement learning using attention augmented agents},
  author={Mott, Alexander and Zoran, Daniel and Chrzanowski, Mike and Wierstra, Daan and Jimenez Rezende, Danilo},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}


@article{naimi2018stacked,
  title={Stacked generalization: an introduction to super learning},
  author={Naimi, Ashley I and Balzer, Laura B},
  journal={European journal of epidemiology},
  volume={33},
  pages={459--464},
  year={2018},
  publisher={Springer}
}


@misc{chen2023learning,
      title={Learning Capacity: A Measure of the Effective Dimensionality of a Model}, 
      author={Daiwei Chen and Weikai Chang and Pratik Chaudhari},
      year={2023},
      eprint={2305.17332},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



%% Fama French 
@article{fama2015five,
  title={A five-factor asset pricing model},
  author={Fama, Eugene F and French, Kenneth R},
  journal={Journal of financial economics},
  volume={116},
  number={1},
  pages={1--22},
  year={2015},
  publisher={Elsevier}
}



@misc{li2020learning,
      title={Learning to Rank for Active Learning: A Listwise Approach}, 
      author={Minghan Li and Xialei Liu and Joost van de Weijer and Bogdan Raducanu},
      year={2020},
      eprint={2008.00078},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}







%% Textbooks

@book{pml1Book,
 author = "Kevin P. Murphy",
 title = "Probabilistic Machine Learning: An introduction",
 publisher = "MIT Press",
 year = 2022,
 url = "probml.ai"
}



@book{bonferroni1936teoria,
  title={Teoria statistica delle classi e calcolo delle probabilit{\`a}},
  author={Bonferroni, C.E.},
  series={Pubblicazioni del R. Istituto superiore di scienze economiche e commerciali di Firenze},
  url={https://books.google.co.uk/books?id=3CY-HQAACAAJ},
  year={1936},
  publisher={Seeber}
}



%% Our Paper 
@misc{wong2023dynamic,
      title={Dynamic Feature Engineering and model selection methods for temporal tabular datasets with regime changes}, 
      author={Thomas Wong and Mauricio Barahona},
      year={2023},
      eprint={2301.00790},
      archivePrefix={arXiv},
      primaryClass={q-fin.CP}
}


%% Online Mean
@article{WelfordB.P.1962NoaM,
language = {eng},
number = {3},
pages = {419-420},
publisher = {Taylor & Francis Group},
title = {Note on a Method for Calculating Corrected Sums of Squares and Products},
volume = {4},
year = {1962},
author = {Welford, B. P.},
copyright = {Copyright Taylor & Francis Group, LLC 1962},
issn = {0040-1706},
journal = {Technometrics},
}




%% Tools for NN 

@inproceedings{Paszke_PyTorch_An_Imperative_2019,
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
pages = {8024--8035},
publisher = {Curran Associates, Inc.},
title = {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
year = {2019}
}

@software{Abadi_TensorFlow_Large-scale_machine_2015,
author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jozefowicz, Rafal and Jia, Yangqing and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mané, Dan and Schuster, Mike and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viégas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
doi = {10.5281/zenodo.4724125},
license = {Apache-2.0},
month = {11},
title = {{TensorFlow, Large-scale machine learning on heterogeneous systems}},
year = {2015}
}


@inproceedings{blondel2020fast,
  title={Fast differentiable sorting and ranking},
  author={Blondel, Mathieu and Teboul, Olivier and Berthet, Quentin and Djolonga, Josip},
  booktitle={International Conference on Machine Learning},
  pages={950--959},
  year={2020},
  organization={PMLR}
}


@software{Falcon_PyTorch_Lightning_2019,
author = {Falcon, William and {The PyTorch Lightning team}},
doi = {10.5281/zenodo.3828935},
license = {Apache-2.0},
month = {3},
title = {{PyTorch Lightning}},
url = {https://github.com/Lightning-AI/lightning},
version = {1.4},
year = {2019}
}



%% Sparse MLP
@software{SparseLinear,
  author = {Hyeonwoo Daniel Yoo},
  month = {12},
  title = {{SparseLinear}},
  url = {https://github.com/hyeon95y/SparseLinear},
  version = {0.0.5},
  year = {2020}
}



@article{Zimmer_Auto-PyTorch_Tabular_Multi-Fidelity_2021,
author = {Zimmer, Lucas and Lindauer, Marius and Hutter, Frank},
doi = {10.1109/TPAMI.2021.3067763},
pages = {3079--3090},
title = {{Auto-PyTorch Tabular: Multi-Fidelity MetaLearning for Efficient and Robust AutoDL}},
year = {2021}
}





%% Random matrix Theory 
@book{tao2012topics,
  title={Topics in random matrix theory},
  author={Tao, Terence},
  volume={132},
  year={2012},
  publisher={American Mathematical Soc.}
}



%% Review on TS modelling 
@article{lim2021time,
  title={Time-series forecasting with deep learning: a survey},
  author={Lim, Bryan and Zohren, Stefan},
  journal={Philosophical Transactions of the Royal Society A},
  volume={379},
  number={2194},
  pages={20200209},
  year={2021},
  publisher={The Royal Society Publishing}
}

@article{torres2021deep,
  title={Deep learning for time series forecasting: a survey},
  author={Torres, Jos{\'e} F and Hadjout, Dalil and Sebaa, Abderrazak and Mart{\'\i}nez-{\'A}lvarez, Francisco and Troncoso, Alicia},
  journal={Big Data},
  volume={9},
  number={1},
  pages={3--21},
  year={2021},
  publisher={Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New~…}
}




%%% Double deep descent 
@article{NakkiranPreetum2021Dddw,
issn = {1742-5468},
journal = {Journal of statistical mechanics},
language = {eng},
number = {12},
pages = {124003-},
title = {Deep double descent: where bigger models and more data hurt},
volume = {2021},
year = {2021},
author = {Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
}


@article{belkin2019reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={32},
  pages={15849--15854},
  year={2019},
  publisher={National Acad Sciences}
}

@article{Teresa22,
author = {TeresaHuang, Ningyuan and Hogg, David W. and Villar, Soledad},
title = {Dimensionality Reduction, Regularization, and Generalization in Overparameterized Regressions},
journal = {SIAM Journal on Mathematics of Data Science},
volume = {4},
number = {1},
pages = {126-152},
year = {2022},
doi = {10.1137/20M1387821},
}



@misc{Couto22,
  doi = {10.48550/ARXIV.2211.10322},
  url = {https://arxiv.org/abs/2211.10322},
  author = {Sa-Couto, Luis and Ramos, Jose Miguel and Almeida, Miguel and Wichert, Andreas},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Understanding the double descent curve in Machine Learning},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



%%% Universal approximation theorem 
@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}


@article{ZHOU2020787,
title = {Universality of deep convolutional neural networks},
journal = {Applied and Computational Harmonic Analysis},
volume = {48},
number = {2},
pages = {787-794},
year = {2020},
issn = {1063-5203},
doi = {https://doi.org/10.1016/j.acha.2019.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S1063520318302045},
author = {Ding-Xuan Zhou},
keywords = {Deep learning, Convolutional neural network, Universality, Approximation theory},
}


@inproceedings{schafer2006recurrent,
  title={Recurrent neural networks are universal approximators},
  author={Sch{\"a}fer, Anton Maximilian and Zimmermann, Hans Georg},
  booktitle={Artificial Neural Networks--ICANN 2006: 16th International Conference, Athens, Greece, September 10-14, 2006. Proceedings, Part I 16},
  pages={632--640},
  year={2006},
  organization={Springer}
}





%%% No Free Lunch 
@article{ho2002simple,
  title={Simple explanation of the no-free-lunch theorem and its implications},
  author={Ho, Yu-Chi and Pepyne, David L},
  journal={Journal of optimization theory and applications},
  volume={115},
  pages={549--570},
  year={2002},
  publisher={Springer}
}


@ARTICLE{Wolpert1997,
  author={Wolpert, D.H. and Macready, W.G.},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={No free lunch theorems for optimization}, 
  year={1997},
  volume={1},
  number={1},
  pages={67-82},
  doi={10.1109/4235.585893}
}
  



%%%% Lottery ticket hypothesis 


@inproceedings{
frankle2018the,
title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
author={Jonathan Frankle and Michael Carbin},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rJl-b3RcF7},
}

@inproceedings{NEURIPS2019_a4613e8d,
 author = {Morcos, Ari and Yu, Haonan and Paganini, Michela and Tian, Yuandong},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers},
 url = {https://proceedings.neurips.cc/paper/2019/file/a4613e8d72a61b3b69b32d040f89ad81-Paper.pdf},
 volume = {32},
 year = {2019}
}




%%% Virtue of Complexity/ Ridge Regression

@article{kelly2022virtue,
  title={The Virtue of Complexity Everywhere},
  author={Kelly, Bryan T and Malamud, Semyon and Zhou, Kangying},
  journal={Available at SSRN},
  year={2022}
}

@article{kelly_malamud_2021,
 title={The virtue of complexity in machine learning portfolios},
 DOI={10.2139/ssrn.3984925}, 
 journal={SSRN Electronic Journal}, 
 author={Kelly, Bryan T. and Malamud, Semyon},
 year={2021}
 } 


@article{welch2008comprehensive,
  title={A comprehensive look at the empirical performance of equity premium prediction},
  author={Welch, Ivo and Goyal, Amit},
  journal={The Review of Financial Studies},
  volume={21},
  number={4},
  pages={1455--1508},
  year={2008},
  publisher={Society for Financial Studies}
}



@misc{Hastie19,
  doi = {10.48550/ARXIV.1903.08560},
  url = {https://arxiv.org/abs/1903.08560},
  author = {Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J.},
  keywords = {Statistics Theory (math.ST), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Surprises in High-Dimensional Ridgeless Least Squares Interpolation},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{LiangTengyuan2020JiK,
author = {Liang, Tengyuan and Rakhlin, Alexander},
address = {Hayward},
copyright = {Copyright Institute of Mathematical Statistics Jun 2020},
issn = {0090-5364},
journal = {The Annals of statistics},
keywords = {Asymptotic methods ; Covariance ; Datasets ; Eigenvalues ; Kernel functions ; Mathematical functions ; Nonlinear systems ; Regression analysis ; Regularization ; Upper bounds},
language = {eng},
number = {3},
pages = {1329-},
publisher = {Institute of Mathematical Statistics},
title = {Just interpolate: Kernel “Ridgeless” regression can generalize},
volume = {48},
year = {2020},
}




%% Randomness in NN 
@misc{Picard21,
  doi = {10.48550/ARXIV.2109.08203},
  url = {https://arxiv.org/abs/2109.08203},
  author = {Picard, David},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Torch.manual_seed(3407) is all you need: On the influence of random seeds in deep learning architectures for computer vision},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}


@article{huang2017snapshot,
  title={Snapshot ensembles: Train 1, get m for free},
  author={Huang, Gao and Li, Yixuan and Pleiss, Geoff and Liu, Zhuang and Hopcroft, John E and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1704.00109},
  year={2017}
}


@misc{Moosavi16,
  doi = {10.48550/ARXIV.1610.08401},
  author = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Universal adversarial perturbations},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@InProceedings{pmlr-v162-pezeshki22a,
  title = 	 {Multi-scale Feature Learning Dynamics: Insights for Double Descent},
  author =       {Pezeshki, Mohammad and Mitra, Amartya and Bengio, Yoshua and Lajoie, Guillaume},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {17669--17690},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/pezeshki22a/pezeshki22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/pezeshki22a.html},
}



%%% Deep Learning Tabular Review 

@misc{Arlind21,
  doi = {10.48550/ARXIV.2106.11189},
  url = {https://arxiv.org/abs/2106.11189},
  author = {Kadra, Arlind and Lindauer, Marius and Hutter, Frank and Grabocka, Josif},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Well-tuned Simple Nets Excel on Tabular Datasets},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{Leo22,
  doi = {10.48550/ARXIV.2207.08815},
  url = {https://arxiv.org/abs/2207.08815},
  author = {Grinsztajn, Léo and Oyallon, Edouard and Varoquaux, Gaël},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Methodology (stat.ME), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Why do tree-based models still outperform deep learning on tabular data?},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{Shwartz21,
  doi = {10.48550/ARXIV.2106.03253},
  url = {https://arxiv.org/abs/2106.03253},
  author = {Shwartz-Ziv, Ravid and Armon, Amitai},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Tabular Data: Deep Learning is Not All You Need},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{Shereen21,
  doi = {10.48550/ARXIV.2101.02118},
  url = {https://arxiv.org/abs/2101.02118},
  author = {Elsayed, Shereen and Thyssens, Daniela and Rashed, Ahmed and Jomaa, Hadi Samer and Schmidt-Thieme, Lars},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Do We Really Need Deep Learning Models for Time Series Forecasting?},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@article{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@inproceedings{Florian20,
title	= {Hyperparameter Ensembles for Robustness and Uncertainty Quantification},
author	= {Florian Wenzel and Jasper Snoek and Dustin Tran and Rodolphe Jenatton},
year	= {2020},
URL	= {https://papers.nips.cc/paper/2020/hash/481fbfa59da2581098e841b7afc122f1-Abstract.html},
booktitle	= {Neural Information Processing Systems (NeurIPS)}
}


@article{zaidi2021neural,
  title={Neural ensemble search for uncertainty estimation and dataset shift},
  author={Zaidi, Sheheryar and Zela, Arber and Elsken, Thomas and Holmes, Chris C and Hutter, Frank and Teh, Yee},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={7898--7911},
  year={2021}
}


@misc{mcelfresh2023neural,
      title={When Do Neural Nets Outperform Boosted Trees on Tabular Data?}, 
      author={Duncan McElfresh and Sujay Khandagale and Jonathan Valverde and Vishak Prasad C and Ganesh Ramakrishnan and Micah Goldblum and Colin White},
      year={2023},
      eprint={2305.02997},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
 


%% Deep Regression Ensemble 

@misc{Kelly22deep,
author = {Didisheim, Antoine and Kelly, Bryan and Malamud, Semyon},
  %doi = {10.48550/ARXIV.2203.05417},
  %url = {https://arxiv.org/abs/2203.05417},
  %keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Regression Ensembles},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Zero v1.0 Universal}
}






%%%%%%%%%% Transformation 


%% Catch22 
@Article{Lubba2019,
author={Lubba, Carl H.
and Sethi, Sarab S.
and Knaute, Philip
and Schultz, Simon R.
and Fulcher, Ben D.
and Jones, Nick S.},
title={catch22: CAnonical Time-series CHaracteristics},
journal={Data Mining and Knowledge Discovery},
year={2019},
month={Nov},
day={01},
volume={33},
number={6},
pages={1821-1852},
issn={1573-756X},
doi={10.1007/s10618-019-00647-x},
url={https://doi.org/10.1007/s10618-019-00647-x}
}

%% hctsa
@article{hctsa,
publisher = {Royal Society, The},
title = {Highly comparative time-series analysis: the empirical structure of time series and their methods},
year = {2013-Apr},
author = {Fulcher, BD and Little, MA and Jones, NS},
keywords = {Science & Technology},
language = {eng},
}


%%% Signature Transforms 

@misc{Chevyrev16,
  doi = {10.48550/ARXIV.1603.03788},
  url = {https://arxiv.org/abs/1603.03788},
  author = {Chevyrev, Ilya and Kormilitzin, Andrey},
  title = {A Primer on the Signature Method in Machine Learning},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Terry22,
  doi = {10.48550/ARXIV.2206.14674},
  url = {https://arxiv.org/abs/2206.14674},
  author = {Lyons, Terry and McLeod, Andrew D.},
  title = {Signature Methods in Machine Learning},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{James20,
  doi = {10.48550/ARXIV.2006.00873},
  url = {https://arxiv.org/abs/2006.00873},
  author = {Morrill, James and Fermanian, Adeline and Kidger, Patrick and Lyons, Terry},
  title = {A Generalised Signature Method for Multivariate Time Series Feature Extraction},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{
kidger2021signatory,
title={Signatory: differentiable computations of the signature and logsignature transforms, on both {\{}CPU{\}} and {\{}GPU{\}}},
author={Patrick Kidger and Terry Lyons},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=lqU2cs3Zca}
}

@inproceedings{Lyons07,
publisher = {Springer Berlin Heidelberg},
series = {École d'Été de Probabilités de Saint-Flour, 1908},
title = {Differential Equations Driven by Rough Paths : Ecole d’Eté de Probabilités de Saint-Flour XXXIV-2004 },
year = {2007},
author = {Lyons, Terry J.},
address = {Berlin, Heidelberg},
edition = {1st ed. 2007.},
isbn = {1-280-85347-6},
keywords = {Mathematical analysis},
language = {eng},
}



@InProceedings{pmlr-v130-lemercier21a,
  title = 	 { Distribution Regression for Sequential Data },
  author =       {Lemercier, Maud and Salvi, Cristopher and Damoulas, Theodoros and Bonilla, Edwin and Lyons, Terry},
  booktitle = 	 {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3754--3762},
  year = 	 {2021},
  editor = 	 {Banerjee, Arindam and Fukumizu, Kenji},
  volume = 	 {130},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--15 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v130/lemercier21a/lemercier21a.pdf},
  url = 	 {https://proceedings.mlr.press/v130/lemercier21a.html},
}







%%% Random Transforms


@misc{Sutherland15,
  author = {Sutherland, Danica J. and Schneider, Jeff},
  %keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
 %doi = {10.48550/ARXIV.1506.02785},
  %url = {https://arxiv.org/abs/1506.02785},
  title = {On the Error of Random Fourier Features},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{Xu20,
  author = {Xu, Zhenlin and Liu, Deyi and Yang, Junlin and Raffel, Colin and Niethammer, Marc},
  %doi = {10.48550/ARXIV.2007.13003},
  %url = {https://arxiv.org/abs/2007.13003},
  %keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Robust and Generalizable Visual Representation Learning via Random Convolutions},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license},
}

@Article{Dempster2020,
author={Dempster, Angus
and Petitjean, Fran{\c{c}}ois
and Webb, Geoffrey I.},
title={ROCKET: exceptionally fast and accurate time series classification using random convolutional kernels},
journal={Data Mining and Knowledge Discovery},
year={2020},
month={Sep},
day={01},
volume={34},
number={5},
pages={1454-1495},
issn={1573-756X},
doi={10.1007/s10618-020-00701-z},
url={https://doi.org/10.1007/s10618-020-00701-z}
}

@inproceedings{dempster_etal_2021,
  author    = {Dempster, Angus and Schmidt, Daniel F and Webb, Geoffrey I},
  title     = {{MiniRocket}: A Very Fast (Almost) Deterministic Transform for Time Series Classification},
  booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  publisher = {ACM},
  address   = {New York},
  year      = {2021},
  pages     = {248--257}
}




@misc{Gavrikov23,
  author = {Gavrikov, Paul and Keuper, Janis},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Rethinking 1x1 Convolutions: Can we train CNNs with Frozen Random Filters?},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}











%% TimeSeries Deep Models 


@book{percival_walden_2020, 
place={Cambridge}, 
series={Cambridge Series in Statistical and Probabilistic Mathematics}, 
title={Spectral Analysis for Univariate Time Series}, 
%DOI={10.1017/9781139235723}, 
publisher={Cambridge University Press},
author={Percival, Donald B. and Walden, Andrew T.}, 
year={2020}, 
collection={Cambridge Series in Statistical and Probabilistic Mathematics},
}


@Article{HochSchm97,
  author      = {Sepp Hochreiter and Jürgen Schmidhuber},
  journal     = {Neural Computation},
  title       = {Long Short-Term Memory},
  year        = {1997},
  number      = {8},
  pages       = {1735--1780},
  volume      = {9},
  optdoi      = {10.1162/neco.1997.9.8.1735},
  opteprint   = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
  opturl      = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
}


@misc{Bryan19,
  doi = {10.48550/ARXIV.1912.09363},
  url = {https://arxiv.org/abs/1912.09363},
  author = {Lim, Bryan and Arik, Sercan O. and Loeff, Nicolas and Pfister, Tomas},
  title = {Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}




@article{DARTS,
  author  = {Julien Herzen and Francesco LÃ¤ssig and Samuele Giuliano Piazzetta and Thomas Neuer and LÃ©o Tafti and Guillaume Raille and Tomas Van Pottelbergh and Marek Pasieka and Andrzej Skrodzki and Nicolas Huguenin and Maxime Dumonal and Jan KoÅ›cisz and Dennis Bader and FrÃ©dÃ©rick Gusset and Mounir Benheddi and Camila Williamson and Michal Kosinski and Matej Petrik and GaÃ«l Grosch},
  title   = {Darts: User-Friendly Modern Machine Learning for Time Series},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {124},
  pages   = {1-6},
  url     = {http://jmlr.org/papers/v23/21-1177.html}
}



@misc{TCNModel,
  doi = {10.48550/ARXIV.1803.01271},
  url = {https://arxiv.org/abs/1803.01271},
  author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@misc{Transformer17,
  doi = {10.48550/ARXIV.1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Attention Is All You Need},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Hinton22,
  doi = {10.48550/ARXIV.2212.13345},
  url = {https://arxiv.org/abs/2212.13345},
  author = {Hinton, Geoffrey},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {The Forward-Forward Algorithm: Some Preliminary Investigations},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}





%% Tabular Models 


%% Gradient Boosting paper 
@article{FriedmanJeromeH.2001GfaA,
year = {2001},
author = {Friedman, Jerome H.},
copyright = {Copyright 2001 Institute of Mathematical Statistics},
issn = {0090-5364},
journal = {The Annals of statistics},
keywords = {62-02 ; 62-07 ; 62-08 ; 62G08 ; 62H30 ; 68T10 ; boosting ; decision trees ; Function estimation ; robust nonparametric regression},
language = {eng},
number = {5},
pages = {1189-1232},
publisher = {The Institute of Mathematical Statistics},
title = {Greedy function approximation: A gradient boosting machine},
volume = {29},
}

@article{B_hlmann_2007,
	doi = {10.1214/07-sts242},
	year = 2007,
	month = {nov},
	publisher = {Institute of Mathematical Statistics},
	volume = {22},
	number = {4},
	author = {Peter Buhlmann and Torsten Hothorn},
	title = {Boosting Algorithms: Regularization, Prediction and Model Fitting},
	journal = {Statistical Science}
}

@article{FREUND1997119,
title = {A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting},
journal = {Journal of Computer and System Sciences},
volume = {55},
number = {1},
pages = {119-139},
year = {1997},
issn = {0022-0000},
doi = {https://doi.org/10.1006/jcss.1997.1504},
url = {https://www.sciencedirect.com/science/article/pii/S002200009791504X},
author = {Yoav Freund and Robert E Schapire},
}


@article{Kotsiantis2011DecisionTA,
  title={Decision trees: a recent overview},
  author={Sotiris B. Kotsiantis},
  journal={Artificial Intelligence Review},
  year={2011},
  volume={39},
  pages={261-283}
}




@inproceedings{XGBoost,
author = {Chen, Tianqi and Guestrin, Carlos},
title = {XGBoost: A Scalable Tree Boosting System},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939785},
doi = {10.1145/2939672.2939785},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {785–794},
numpages = {10},
keywords = {large-scale machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}


@inproceedings{LightGBM,
 author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {LightGBM: A Highly Efficient Gradient Boosting Decision Tree},
 url = {https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{CatBoost,
 author = {Prokhorenkova, Liudmila and Gusev, Gleb and Vorobev, Aleksandr and Dorogush, Anna Veronika and Gulin, Andrey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {CatBoost: unbiased boosting with categorical features},
 url = {https://proceedings.neurips.cc/paper/2018/file/14491b756b3a51daac41c24863285549-Paper.pdf},
 volume = {31},
 year = {2018}
}



@article{Arik_Pfister_2021, 
title={TabNet: Attentive Interpretable Tabular Learning}, 
volume={35}, 
url={https://ojs.aaai.org/index.php/AAAI/article/view/16826}, 
number={8}, 
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Arik, Sercan Ö. and Pfister, Tomas}, 
year={2021}, 
month={May}, 
pages={6679-6687}
}

@inproceedings{AutoInt_Song_2019,
	doi = {10.1145/3357384.3357925},
	url = {https://doi.org/10.11452F3357384.3357925},
	year = 2019,
	month = {nov},
	publisher = {{ACM}},
	author = {Weiping Song and Chence Shi and Zhiping Xiao and Zhijian Duan and Yewen Xu and Ming Zhang and Jian Tang},
  	title = {{AutoInt}},
	booktitle = {Proceedings of the 28th {ACM} International Conference on Information and Knowledge Management}
}


@misc{TabTransformer,
  doi = {10.48550/ARXIV.2012.06678},
  url = {https://arxiv.org/abs/2012.06678},
  author = {Huang, Xin and Khetan, Ashish and Cvitkovic, Milan and Karnin, Zohar},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {TabTransformer: Tabular Data Modeling Using Contextual Embeddings},
  publisher = {arXiv},
  year = {2020},
  copyright = {Creative Commons Zero v1.0 Universal}
}

@misc{NODE,
  doi = {10.48550/ARXIV.1909.06312},
  url = {https://arxiv.org/abs/1909.06312},
  author = {Popov, Sergei and Morozov, Stanislav and Babenko, Artem},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data},
  publisher = {arXiv},
  year = {2019},
  copyright = {Creative Commons Attribution 4.0 International}
}




@misc{Horn19,
  doi = {10.48550/ARXIV.1901.07329},
  url = {https://arxiv.org/abs/1901.07329},
  author = {Horn, Franziska and Pack, Robert and Rieger, Michael},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {The autofeat Python Library for Automated Feature Engineering and Selection},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@INPROCEEDINGS{James15,
  author={Kanter, James Max and Veeramachaneni, Kalyan},
  booktitle={2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Deep feature synthesis: Towards automating data science endeavors}, 
  year={2015},
  volume={},
  number={},
  pages={1-10},
  doi={10.1109/DSAA.2015.7344858},
}



@inproceedings{gulin2011winning,
  title={Winning the transfer learning track of yahoo!’s learning to rank challenge with yetirank},
  author={Gulin, Andrey and Kuralenok, Igor and Pavlov, Dimitry},
  booktitle={Proceedings of the Learning to Rank Challenge},
  pages={63--76},
  year={2011},
  organization={PMLR}
}



@article{zimmer-tpami21a,
  author = {Lucas Zimmer and Marius Lindauer and Frank Hutter},
  title = {Auto-PyTorch Tabular: Multi-Fidelity MetaLearning for Efficient and Robust AutoDL},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {2021},
  note = {also available under https://arxiv.org/abs/2006.13799},
  pages = {3079 - 3090}
}



%% Clustering
@Article{Traag2019,
author={Traag, V. A.
and Waltman, L.
and van Eck, N. J.},
title={From Louvain to Leiden: guaranteeing well-connected communities},
journal={Scientific Reports},
year={2019},
month={Mar},
day={26},
volume={9},
number={1},
pages={5233},
%issn={2045-2322},
%doi={10.1038/s41598-019-41695-z},
%url={https://doi.org/10.1038/s41598-019-41695-z}
}


@article{Barahona14,
  author={Lambiotte, Renaud and Delvenne, Jean-Charles and Barahona, Mauricio},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={Random Walks, Markov Processes and the Multiscale Modular Organization of Complex Networks}, 
  year={2014},
  volume={1},
  number={2},
  pages={76-90},
  %doi={10.1109/TNSE.2015.2391998}
}

@article{Barahona19,
  title = {Multiscale dynamical embeddings of complex networks},
  author = {Schaub, Michael T. and Delvenne, Jean-Charles and Lambiotte, Renaud and Barahona, Mauricio},
  journal = {Phys. Rev. E},
  volume = {99},
  issue = {6},
  pages = {062308},
  numpages = {18},
  year = {2019},
  month = {Jun},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.99.062308},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.99.062308}
}


%%% Rebalancing 
@article{hoffstein2020rebalance,
  title={Rebalance timing luck: the (dumb) luck of smart beta},
  author={Hoffstein, Corey and Faber, Nathan and Braun, Steven},
  journal={Available at SSRN 3673910},
  year={2020}
}


%%% Datasets 
@online{numerai-datav4.1,
  author="Numerai",
  title="{Numerai Hedge Fund}",
  url="https://numer.ai/data/v4.1",
  note="(2023, Feb 15)",
}

@online{numerai-corr,
  author="Numerai",
  title="{Numerai Hedge Fund}",
  url="https://docs.numer.ai/tournament/correlation-corr",
  note="(2023, Apr 19)",
}


@article{JensenKellyPedersen2022,
   author = {Jensen, Theis Ingerslev and Kelly, Bryan T and Pedersen, Lasse Heje},
   journal = {Journal of Finance, Forthcoming},
   title = {Is There A Replication Crisis In Finance?},
   year = {2022}
}


@ARTICLE{Bagnall19,
  author={Dau, Hoang Anh and Bagnall, Anthony and Kamgar, Kaveh and Yeh, Chin-Chia Michael and Zhu, Yan and Gharghabi, Shaghayegh and Ratanamahatana, Chotirat Ann and Keogh, Eamonn},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={The UCR time series archive}, 
  year={2019},
  volume={6},
  number={6},
  pages={1293-1305},
  %doi={10.1109/JAS.2019.1911747},
  }
