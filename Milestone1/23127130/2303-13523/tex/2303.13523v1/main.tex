
\documentclass[conference]{IEEEtran}
\pdfoutput=1
\usepackage[nolist]{acronym}
\usepackage{amsmath, bm}
\usepackage{amssymb}
\usepackage[table,xcdraw,dvipsnames]{xcolor}
\usepackage{algpseudocode}
\usepackage{balance}
\usepackage{tabularx}
\usepackage{subcaption}
\usepackage{multirow,array}
\usepackage{url}
\usepackage{textcomp}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{amsmath}
\usepackage{amsfonts} 
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
%\newcolumntype{L}{>{\centering\arraybackslash}m{.32\columnwidth}}
%\newcolumntype{M}{>{\centering\arraybackslash}m{.27\columnwidth}}
\usepackage{lipsum}
\usepackage{stfloats}
\usepackage{easyReview}
% \long\def\authornote#1{%
%         \leavevmode\unskip\raisebox{-3.5pt}{\rlap{$\scriptstyle\diamond$}}%
%         \marginpar{\raggedright\hbadness=10000
%         \def\baselinestretch{0.8}\tiny
%         \it #1\par}}
% \newcommand{\Nima}[1]{\authornote{\color{Maroon}{NA: #1}}}
% \newcommand{\Hamed}[1]{\authornote{\color{PineGreen}HA: #1}}
% \newcommand{\AuthorC}[1]{\authornote{AC: #1}}
% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
%\usepackage[pdflatex]{graphicx}
%\usepackage{graphicx}
\usepackage[margin=0.9in]{geometry}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
%\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex




%\hyphenation{op-tical net-works semi-conduc-tor}
\renewenvironment{IEEEbiography}[1] 
{\IEEEbiographynophoto{#1}}
{\endIEEEbiographynophoto}


\begin{document}
%\title{Efficient Deployment and Decomposition of Microservice-based Virtual Network Functions Using a Deep Reinforcement Learning Approach}
\title{Dynamic Prioritization and Adaptive Scheduling using Deep Deterministic Policy Gradient for Deploying Microservice-based VNFs\\}
%\title{Deep Reinforcement Learning For Efficient Decomposition and Deployment of Microservices In 6G Networks}

\author{\IEEEauthorblockN{Swarna B. Chetty, Hamed Ahmadi
\IEEEmembership{Senior Member,~IEEE}, Avishek Nag \IEEEmembership{Senior Member,~IEEE}}
%\thanks{Swarna B. Chetty is with the School of Electrical and Electronic Engineering, University College Dublin, Ireland}
%\thanks{Hamed Ahmadi is with the Department of Electronic Engineering, University of York, UK}
%\thanks{Avishek Nag is with the School of Electrical and Electronic Engineering, University College Dublin, Ireland}
%\thanks{Massimo Tornatore is with the Department of Electronics and Information in Politecnico di Milano, Italy}}

}

\maketitle
\bstctlcite{IEEEexample:BSTcontrol}
\begin{abstract}
The \ac{NFV}-\ac{RA} problem is NP-Hard. Traditional deployment methods revealed the existence of a starvation problem, which the researchers failed to recognize. Basically, starvation here, means the longer waiting times and eventual rejection of low-priority services due to a `time out'.
The contribution of this work is threefold: a) explain the existence of the starvation problem in the existing methods and their drawbacks, b) introduce \ac{AdSch} which is an `intelligent scheduling' scheme using a three-factor approach (priority, threshold waiting time, and reliability), which proves to be more reasonable than traditional methods solely based on priority, and c) a \ac{DyPr}, allocation method is also proposed for unseen services and the importance of macro- and micro-level priority. 
We presented a zero-touch solution using \ac{DDPG} for adaptive scheduling and an online-\ac{RR} model for dynamic prioritization. The \ac{DDPG} successfully identified the `Beneficial and Starving' services, efficiently deploying twice as many low-priority services as others, reducing the starvation problem. Our online-\ac{RR} model learns the pattern in less than 100 transitions, and the prediction model has an accuracy rate of more than 80\%. 

%\highlight{Definition of Starvation: The preference for high-priority services results in a longer waiting time for low-priority services, resulting in service rejection due to insufficient resources or exceeding expiration time; this is referred to as the Starvation Problem. }


%In this paper
%6G mobile networks are expected to support new and highly advanced applications such as \acp{DT}/Cybertwins, which demand diverse requirements like high data rates, reliability, and low latency. \ac{DT} will revolutionize \ac{IoT}, industrial applications, and services through \ac{AI} and \ac{ML}. To support the emerging services with high and dynamic demands, the \ac{NFV} approach is well suited; but the main challenge in the \ac{NFV} approach is the \ac{NFV}-\ac{RA} problem which is $NP$-Hard. To efficiently solve the \ac{NFV}-\ac{RA} problem as well as to meet the \ac{QoS} of emerging applications like \ac{DT}, the microservices-based approach is becoming popular.  

%The Internet of Things (IoT) universe will continue to expand with the advent of 6G, which is expected to support applications and services with higher data rates, ultra-reliability, and lower latency compared to 5G. These new demanding 6G applications will introduce heavy load and strict performance requirements on the network. Network Function Virtualisation (NFV) is a promising approach to handling these challenging requirements, but it also poses significant Resource Allocation (RA) challenges. Especially since 6G network services will be highly complicated and comparatively short lived, network operators will be compelled to deploy these services in a flexible, on-demand, and agile manner. To address the aforementioned issues, microservice approaches are being investigated, in which the services are decomposed and loosely coupled, resulting in increased deployment flexibility and modularity. This study investigates a new RA approach for microservices-based NFV for efficient deployment and decomposition of  Virtual  Network  Functions (VNF) onto substrate networks. Decomposition of VNFs involves additional overheads, which have a detrimental impact on network resources; hence, finding the right balance of when and how much decomposition to allow is critical. Thus, we develop a criterion for determining the potential/candidate VNFs for decomposition and also the granularity of such decomposition. The joint problem of decomposition and efficient embedding of microservices is challenging to model and solve using exact mathematical models. Therefore, we implemented a Reinforcement  Learning model, using Double  Deep  Q-Learning, which revealed an almost 50\%  more normalized Service Acceptance Rate (SAR) for the microservice approach over the monolithic deployment of VNFs. 


\end{abstract}
\begin{IEEEkeywords}
6G, Machine Learning, Internet of Things, Resource allocation
\end{IEEEkeywords}
%\vspace{-0.2in}
\section{Introduction}
Although \ac{5G} is presently providing the fundamental support for the \ac{IoE} and \ac{URLLC}, it is debatable if the current \ac{5G} systems can smoothly handle applications like \ac{DT}, connected robotics, autonomous systems, \ac{AR}/ \ac{VR}/ \ac{MR}, and Blockchain and Trust technologies ~\cite{saad2019vision, DTpaper21}. These upcoming applications are envisioned to request services with stringent standards, such as high reliability, low latency, and significant data rates~\cite{saad2019vision}. Due to this debate, there has been a significant research progress towards \ac{6G}.%consequently alters the heterogeneous networks' experience by varying the load and is expected to serve new services along with the existing ones instantly. %A radical
The \ac{6G} must be tailored to support the upcoming service types like \ac{COC}, \ac{CAeC}, and \ac{EDuRLLC} in addition to \ac{eMBB}, \ac{URLLC}, and \ac{mMTC} services~\cite{letaief2019roadmap}.

There are several initiatives on both the access and the network side to facilitate the transition towards the \ac{6G}.  On the network side, the \ac{NFV} architecture, introduced in 2012~\cite{NFVproposal}, is pushing towards the microservices-based architecture~\cite{9306098,chowdhury2019re}. %,8806705,moro2020framework
The \ac{NFV} framework virtualizes the \acp{NF} from their dedicated proprietary substrate appliances by allowing them to run as softwarized \acp{NF} (say, \acp{VNF}) on commodity hardware. This enables freedom, flexibility, and agility for \acp{VNF} to migrate from one server to another in response to dynamic variations in resource demand. Although \ac{NFV} is a promising technology, it can be challenging when various applications coexist, and simultaneously the underlying infrastructure requires guaranteed resources for all the arriving \ac{SFC}\footnote{Usually, multiple \acp{VNF} that are required by a service are `chained' in the order in which they are accessed by a service. This is called a \ac{SFC}.}. This is an NP-Hard problem and is known as the \ac{NFV}-\ac{RA}. 
In this type of \ac{NFV}-\ac{RA}, due to the affinity and anti-affinity constraints\footnote{Affinity and anti-affinity constraints refer to the ability to embed a \ac{VNF} on a particular node (affinity) and the converse of it (anti-affinity)}, the complexity grows further, hindering effortless software updates and routine maintenance. To address this, microservices offer an increased degree of freedom in the scalability, flexible upgrades and maintenance of \acp{VNF}. 
%In this approach, the monolithic \acp{VNF} are decomposed into several loosely coupled micro-independent \acp{VNF}, providing additional benefits like manageable vertical and horizontal resource scaling and re-use of the micro-\acp{VNF}. 
This cutting-edge `\ac{NFV}-\ac{RA} + Microservies' strategy ppromises to offer a solution  (theoretically) closer to the optimum, despite having an intensified design and deployment complexity. % which caused some challenges. %Some of these challenges were resolved with the involvement of the DRL approach. 
%A deeper study on this hypothesis and the criteria for performing dynamic decomposition is provided by our earlier work. This serves as our foundation as we examine the merits of embedding an \ac{SFC} over others and the significance of admission control in this paper.
In \cite{9923918} we provided a detailed analysis of this approach and the criteria for executing dynamic decomposition, of which, Section~\ref{subsec:4} provides an overview.

%Considering, this as our foundation, 
We examine a deeper analysis of the criteria for dynamically prioritizing the online \acp{SFC}, the merits of embedding an \ac{SFC} over others and the significance of admission control. Most research to date has concentrated exclusively on deploying \acp{SFC} using \ac{FIFO}. Realistically, not all \acp{SFC} fall under the same priority group and cannot be addressed equally. The traditional method, \ac{FIFO}, failed to recognize and give emergency \acp{SFC} higher preference than non-emergency ones, causing the rejection of highly critical \acp{SFC}. In a modified approach, the priority-based approach is established to prefer the high-priority \acp{SFC} first over the lower ones~\cite{cappanera2019vnf, mohamad2020psvshare}, which overcomes the \ac{FIFO} drawback. Nevertheless, this introduced `starvation for lower-priority services, causing a significant biasness in the system - an unfair design to the users. To dismiss this biasness, the critical \ac{SFC} should not be classified based on priority levels but rather with other essential attributes. Thus, requiring an `intelligent fair system'. Moreover, with the lack of requested service information, predicting the types of arriving \acp{SFC} and their priority level will be challenging considering future communications. Thus, we need to dynamically classify the online services. 
%The majority of research to date has concentrated exclusively on deploying \acp{SFC} using FIFO. Realistically, not all \acp{SFC} fall under the same priority group and cannot, therefore, be addressed equally. The traditional method, FIFO, failed to recognize and give emergency services higher preference than non-emergency ones, causing the rejection of highly critical \acp{SFC}. The priority-based approach is established to serve the high-priority services over the lower ones to overcome the FIFO drawback and introduces `starvation for lower-priority services'. These techniques caused biasnes -- an unfair system to the users. 
%We have proposed a `Dynamic Prioritization' and an `Adaptive scheduling’ module for the arriving \acp{SFC} using the Rigid and \ac{DDPG} approach, respectively,  to diminish the ‘starvation’ situation and provide a fair scheduling principle.  
%\begin{figure}
%\centering
%\includegraphics[width=0.3\textwidth]{Figures/SFC_vnf5.PNG}
%\includegraphics[width=0.25\textwidth]{Figures/vnfpersfc_5.pdf}
%\caption{Monolithic SFC}
%\label{fig:monoSFC}
%\end{figure}
%
%\begin{figure}
%\centering
%\includegraphics[width=0.3\textwidth]{Figures/SFC_vnf5_decomp.PNG}
%\includegraphics[width=0.25\textwidth]{Figures/decomp_vnfpersfc_5.pdf}
%\caption{Decomposed SFC}
%\label{fig:decompSFC}
%\end{figure}

%In this paper, in the quest to provide seamless support to more realistic services for future networks, we have proposed a `Dynamic Prioritization’ and an ‘Adaptive scheduling’ module for the arriving \acp{SFC} using the Rigid and \ac{DDPG} approach, respectively,  to diminish the ‘starvation’ situation and provide a fair scheduling principle. Our proposed \ac{DDPG}-based algorithm identifies and understands the importance of embedding the `beneficial SFC’ or `critical SFC' over others. The criteria and methods for assessing the priority of the online service have also not been specified in the literature; instead, a static approach has been adopted. Thus we have firstly proposed a standard for estimating the priority of \ac{SFC} dynamically by using the ML technique. Using the estimated priority and other QoS attributes, we trained the our \ac{DDPG}-based model for preferring the most urgent and needed SFC to be deployed first and so on. And later on, SFC has to go through the admission control module, which provides permission for deployment or rejection based on the waited time by the SFCs.This research is an extension of our `NFV-RA + Microservices' strategy, which looks at the performance of the \ac{DDQL} model in conjunction with microservices & re-architecture.

In this paper, to provide seamless support to more realistic services for future networks, we propose a \ac{DyPr} and an \ac{AdSch} module for arriving \acp{SFC} using the \ac{RR} model and \ac{DDPG} approach, respectively, to diminish the `Starvation’ situation and provide a fair scheduling principle. Our proposed \ac{DDPG}-based algorithm identifies and understands the importance of embedding the `Beneficial SFC’ or `Starving SFC’ over others. The criteria and methods for assessing the priority of the online service have also not been specified in the literature; instead, a static approach has been adopted. Thus we have first proposed a standard for estimating the priority of an \ac{SFC} dynamically by using the \ac{ML} technique. Using the achieved priority and other \ac{QoS} attributes, we trained our \ac{DDPG}-based model to rank the arriving \acp{SFC} based on their urgency and requirements. Based on the \ac{SFC}’s rank, the rescheduling for deployment occurs; later on, the \ac{SFC} has to go through the admission control module, which provides permission or rejection for deployment based on the waited time by the \acp{SFC} in the queue. 
%As mentioned earlier, this research is an extension of our `\ac{NFV}-\ac{RA} + Microservices’ strategy, which performed the deployment based on the \ac{DDQL} model in conjunction with the microservices re-architecture concept.
In summary, the main contributions of this paper are:
\begin{itemize}
    \item Establish a dynamic priority estimation criteria for all the online services using the \ac{RR} model.
    \item Develop a \ac{DDPG}-based framework for recognizing and understanding the importance of preferring an \ac{SFC} (say, `Beneficial and Starving \ac{SFC}’) over others.
    \item Establish an admission control approach, based on the \ac{SFC}'s waiting time in the queue before being deployed.
    \item  Adapting the deep \ac{QL} model along with microserives concept for \ac{VNF} embedding. 
\end{itemize}
%The rest of the paper is organized as follows. Section~\ref{sec:2} and Section~\ref{sec:3} present the related literature review and the system model. Our results are presented in Section~\ref{sec:4}, and finally, we conclude in Section~\ref{sec:5}. 
%Now with proposals to decompose monolithic \acp{VNF} to microservices, the \ac{NFV}-\ac{RA} problem becomes more interesting and the solution (theoretically) becomes closer to the optimum.
%
%A new generation of diverse applications is emerging to satisfy the increased demands of users owning multiple smart gadgets, i.e. the `smart world' surge. 
%\ac{IoT} and Industry 4.0 are some of the main applications of \ac{5G}, and they will continue to be important as the technology progresses towards \ac{6G}. As \ac{IoT} and Industry 4.0 become more mature, they drive the emergence of more modern applications like \ac{DT}, connected robotics, autonomous systems, \ac{AR}/ \ac{VR}/ \ac{MR}, Blockchain and Trust technologies, and wireless brain-computer interfaces \cite{saad2019vision}, \cite{DTpaper21}.
%Furthermore, other driving applications of \ac{6G} such as connected robotics, autonomous systems, \ac{AR}/\ac{VR}/\ac{MR}, Blockchain and Trust technologies, and wireless brain-computer interfaces \cite{saad2019vision} could demand higher levels of KPIs beyond what is achievable by \ac{5G} \cite{saad2019vision}. For example, applications like autonomous driving and immersive \ac{AR}/\ac{VR}/\ac{MR} with high definition $360^{\circ}$ video streaming for navigation and/or entertainment are expected to require $99.999\%$ reliability and one millisecond latency \cite{park2019wireless}.
%,belongs to the \ac{6G} which provides higher data rate, greater reliability, and lower latency by \ac{5G}. 
%\ac{6G}, with its ambitious \acp{KPI}, enables an environment where a comprehensive digital representation of the physical world can be created and maintained through \acp{DT} of various objects. 
%A \ac{DT} is a real-time evolving digital duplicate of a physical entity, a system or a process. It provides a digital representation of the entity and its dynamic history \cite{DT_def}.
%object or a process that contains all of its history \cite{DT_def}.
%\ac{DT} enables/facilitates the inclusion of \ac{AI} and \ac{ML} in designing new industrial and \ac{IoT} applications and services. \ac{6G} mobile networks will facilitate the emergence of variety of \ac{DT} applications that would rely on \ac{AI} and \ac{ML} techniques.
%It is not just \acp{DT}, but several new applications would emerge from the transition of \ac{5G} to \ac{6G} that would require more ubiquity of \ac{AI} and \ac{ML}. 
%
%Higher data rates, lower latency, and a seamless end-to-end connection are only some perpetual demands of the surging applications in \ac{IoT} and Industry 4.0 resulting in increased network operations scope and scale, as well as higher operational expenses. 
%
%Because of the rising demand, a surge in network complexity will continue, creating highly heterogeneous networks. The complexity grows even further with the introduction of `Short-lived Network Services'\footnote{It is predicted, the lifespan of the upcoming requested network service will be shorter than standard.} \cite{mijumbi2015network}. 
%The connections between Machine-to-human and machine-to-machine are required, 
%
% This will be
% %
% transforming the future network from \emph{connected things} to \emph{connected intelligence} \cite{letaief2019roadmap}. 
% %
%This will further load the network and push for serving the variety of new services and applications instantaneously in addition to the existing ones.
%To support this evolution towards \ac{6G}, the \ac{NFV} architecture is also evolving towards a microservices-based architecture \cite{9306098,8806705,moro2020framework,chowdhury2019re}. \emph{Microservices} are a standard software design paradigm that decomposes monolithic systems into several smaller (micro) individual and independent fragments. These micro-fragments are loosely coupled software codes, providing the advantage of easy maintenance like upgrading and scaling the micro-fragments. Due to their independence, the testing and migration become manageable and allow the re-use the micro-fragments~\cite{microservicesWB}. 
%ref: https://skelia.com/articles/5-major-benefits-microservice-architecture/
%The microservice concept has proven to be an effective strategy in cloud-based applications such as Netflix \cite{Netflix} and Amazon \cite{amazon} and, since the telecom networks are becoming `cloud-native', the microservices-based \ac{NFV} framework promises to serve the future networks well. The virtualization approach allows various applications to coexist and simultaneously use the same resource infrastructure, which is at the core of the cloud computing architecture~\cite{rost2020hardness}.
%For this reason, 5G-and-beyond communication networks aim to serve a variety of new and existing network services, technologies, and applications.
%
%Traditionally, the network operator specifies the Network Service (NS) like web services according to the promised SLAs. These NSs are composed of a set of Network Functions (NFs), each of which is generally incorporated onto a dedicated hardware device (or middle-box) to execute a specialized function, such as a firewall, router, or Network Address Translation (NAT). Network operators had to purchase, configure, and manage middle-boxes to launch new services or update current ones, limiting the flexibility and agility of NFs \cite{mijumbi2015network}. This leads to a substantial increase in the deployment of the middle-boxes, causing increased Operating Expenditures (OPEX) and Capital Expenditures (CAPEX) \cite{herrera2016resource}. For ultra-high-heterogeneous networks, this traditional approach would not be a viable solution. Particularly when short-lived NSs frequently arrive, requiring the middle-boxes to be constantly re-located and re-configured, which will further increase the expenses and reduce scalability. This characterizes the deployment process as a rigid method. As a result, a novel framework is required to handle on-demand and short-lived services with the flexibility of instant and seamless NFs migration. 
%
%The 'virtualization' approach; Network Function Virtualization (NFV), efficiently encourages the implementation of NFs onto the infrastructures. The NFV framework isolates NFs from their dedicated proprietary dependencies and allowing them to run as softwarized NFs on shared hardware. There are a few benefits of using NFV-based network: 1) NF virtualization reduces CAPEX and OPEX by running several VNFs on a single high-volume server, lowering hardware costs and simplifying maintenance, 2) It reduces the deployment time for newly arriving network services as contrast to the traditional technique; this is purely due to the availability of high-volume servers on the networks, 3) NFV-based networks enable flexible migration of VNFs from one server to another in response to dynamic alteration in resource demand. Thus these softwarized NFs, also known as Virtual Network Functions (VNFs), provide network operators with the freedom and agility to embed and re-embed VNFs and Service Function Chaining (SFC).
%An existing approach for the networks to effectively satisfy the higher demands without requiring significant increase in the network hardware is virtualising network functions. 
%Virtualising network functions is an existing approach for the networks to effectively satisfy the higher demands without requiring a significant increase in the network hardware. 
%\ac{NFV} provides the flexibility to deploy and manage monolithic and microservices across different substrate infrastructures.
%\vspace{-0.1in}
%\subsection{\ac{NFV} as we know}
%Traditionally, the \ac{NFV} framework isolates the \acp{NF} from their dedicated and proprietary substrate appliance %dependencies and allows them to run as softwarized \acp{NF} on commodity hardware. %shared hardware. \ac{NFV}-based networks enable flexible migration of \acp{VNF} from one server to another in response to dynamic variation in resource demand. These softwarized \acp{NF} provide network operators with the freedom and agility to embed and re-embed \acp{VNF} and \ac{SFC} to satisfy resource scaling (eg., vertical scaling, horizontal scaling) and migration requests in response to variation in the resource demand.
%
%\begin{figure}
%\centering
%\includegraphics[width=0.55\textwidth]{Figures/VNF-FG .PNG}
%\caption{Service Function Chain}
%\label{fig:SFC}
%\end{figure}

%An \ac{SFC} is a collection of various \acp{VNF} and their corresponding \acp{VL} with varying resource demands (e.g., CPU, memory, bandwidth) that should be satisfied by the underlying infrastructure. %must meet for a successful deployment. The complexity grows even further for the constrained SFC (e.g., affinity and anti-affinity constraints). The \acp{VNF} in an SFC are connected in a specific chronological order; their deployment should follow the same order, satisfying the resource requirements while increasing complexity. This is the case for each SFC. The \ac{SFC}'s major goal is to offer users with guaranteed \acp{SLA}, which is accomplished in three stages: \ac{VNF}-\ac{CC}, \ac{VNF}-\ac{FG}\footnote{It is a graphical representation of VNFs that are sequentially chained and deliver an end-to-end network service.}, and \ac{VNF}-\ac{SCH}. Our work is restricted to stages 2 and 3 only; we consider stage 1 as a predetermined factor provided by the network~operator.
%Besides the advantages, \ac{NFV}-based networks have their own set of obstacles, such as the dynamic composition and deployment of the \acp{VNF} and \acp{VL} to execute a fast and reliable \ac{SFC}. 
%\subsection{Microservices decomposed NFVs}
%The \ac{NFV}-based network provides considerably more flexibility for the placement of the online arriving services but exploiting this flexibility mapping can cause a significant computational problem.
%One of the main challenges is `\ac{NFV}-\ac{RA}’, which is described as  the provisioning of guaranteed  resources by the network or the underlying infrastructure to the requested \acp{SFC} for an effective deployment. 
%in three stages. Stage 1: As previously stated, an SFC is a collection of VNFs which is chained in a specific chronological order (according to QoS), and the process is known as VNFs-Chain Composition (VNFs-CC). As illustrated in Figure \ref{fig:SFC}. Stage 2: Under the specific resource limitations, these chained VNFs are optimally deployed onto substrate nodes. The VNF-Forwarding Graph (VNF-FG) is a graphical representation of VNFs that are sequentially chained and deliver an end-to-end network service. The process of deploying these graphs on the network is termed VNF-FG Embedding (VNF-FGE), which is branched out into two sub-problems: Virtual Node mapping and Virtual Link mapping, as shown in Figure~\ref{fig:VNF-FGE}. Stage 3 concentrates on minimizing the VNF-FG's overall deployment time by providing a time-slotted strategy for the arrival of VNF, this is called VNF Scheduling (VNF-SCH). Our work in this paper is restricted to stages 2 and 3 only, we consider stage 1 as a predetermined factor provided by the network~operator.
%\begin{figure}
%\centering
%\includegraphics[width=0.5\textwidth]{Figures/VNFE.png}
%\caption{VNF-FG~Embedding}
%\label{fig:VNF-FGE}
%\end{figure}
%Because of the extensive interdependencies between various factors, the VNF-FGE and network dynamism add to the NFV-RA problem's complexity. Indeed, the NFV-RA issue is classified as $NP$-Hard problem. This severe problem can be handled using mathematical optimization approach; however, the computation time would be considerably high \cite{herrera2016resource}. For denser networks, this computational time will grow exponentially. Researchers have used sub-optimal solutions such as heuristics and meta heuristics-based ways to address this, with a trade-off between run-time and the global optimal solution. For dynamic systems with constantly changing restrictions and objectives, this strategy is considered a downside as the heuristic model must be continuously updated \cite{quang2019deep}
%The VNF-FGs may be efficiently placed using a zero-touch network. As a result, for the placement of dynamically incoming VNF-FGs, we are investigating Deep Reinforcement Learning (DRL) strategies in this study.
%In an environment where the network conditions change vigorously, learning from the past experiences is a beneficial factor for decision-making. In general, the RL approach has been proven to provide better solutions than supervised learning for $NP$-Hard problems \cite{quang2018single}. Additionally, while solving the VNF-FGE problem, we are also examining the performance of the DRL under monolithic and decomposed VNFs. 
%\ac{NFV}-\ac{RA}, due to its requirements and constraints, normally becomes an $NP$-hard problem~\cite{9025750}. To efficiently address the \ac{NFV}-\ac{RA}, different heuristics and machine-learning-based approaches have been investigated in the literature (discussed in the next section in detail with appropriate references).
%Now with proposals to decompose monolithic \acp{NF} to microservices, the \ac{NFV}-\ac{RA} problem becomes more interesting and the solution (theoretically) becomes closer to the optimum. %Just to clarify and with a little misuse of the concept, imagine a knapsack problem in which the bigger objects can be decomposed into smaller objects which can have shared functionality/values. %The loosely coupled micro-\acp{VNF} (\emph{m}\ac{VNF}), give the freedom of migration, scalability, maintenance, and software update without disrupting the neighbouring \acp{VNF}, which is a significant advantage over monolithic architectures. %It also has a higher fault tolerance~\cite{9306098, microservicesWB}. However, these benefits come with new costs and constraints.
%as there have been proposals to further decompose the \acp{VNF} into smaller fragments called microservices~\cite{9306098,8806705,moro2020framework,chowdhury2019re}.
%\textcolor{blue}{[include 4-5 references here including some of Dr Nag's coauthored papers on microservices, giacomo verticale's work, and Raouf Boutaba's work]}. 
%In this paper, to address the more complex challenges that \ac{DT} introduces to the network, we propose an innovative microservices-based \ac{NFV}-\ac{RA} approach.


%Deployment and architectural complexity intensify when this microservice concept is implemented on the \ac{VNF}-\ac{FG} embedding problem~\cite{9306098} as the decomposed micro-functionalities seek more resources like bandwidth and latency. % as shown in Figure~\ref{fig:decompSFC}. 
%\highlight{show the figure before and after decomp for better clarity}
%For example, Fig.~\ref{fig:monoSFC} illustrates an SFC composed of 5 VNFs and 7 VLs ((0,4), (1,4), (2,1), (2,3), (3,1), (4,0), (4,1)), based on the granularity criteria (which is explained later in Section \ref{gc}) this SFC is further disintegrated at a finer-granular level, as shown in Fig.~\ref{fig:decompSFC}. 
%In the given example, each monolithic~\ac{VNF} (hereafter, the standard VNFs will be defined as monolithic VNFs) is decomposed into 5 independent and modular deployable micro-functionalities,  generating in a total of 25 \emph{m}\acp{VNF}, and 100 micro-\acp{VL} (\emph{m}\acp{VL}) driving a higher amount of resource consumption. As a result, decomposition of all \acp{VNF} is an ineffective approach; hence, identifying the best decomposing scenario for each \ac{SFC} is vital.
%causing a new updated \acp{VL} ((4,20), (9,20), (14,5), (14,15), (19,5), (24,0), (24,5)). 
%Apart from this drawback, these loosely coupled micro-VNFs, give the freedom of migration, scalability, maintenance, and software update without disrupting the neighbouring \acp{VNF}, which is a significant advantage over monolithic architectures. It also has a higher fault tolerance~\cite{9306098, microservicesWB}.
%[\textcolor{blue}{cite martin fowler's blog on microservices here and dr nag's co-authored paper on microservices}].



%\textcolor{red}{Hamed: This paragraph is very important but not clear. I tried to rewrite it but I think you need to work on it. }
%The microservice concept has been an efficient technique in a cloud-based application. However, when the microservices concept is applied to the \ac{VNF}-\ac{FG} problem, the primary issue is, a few of these decomposed \acp{VNF} are common (say, redundant micro-\acp{VNF}) across the \ac{SFC}. Therefore, the deployment of these redundant micro-\acp{VNF} will enhance the processing overheads and will consume unnecessary resources. To eliminate this limitation, the decomposed \acp{VNF} needs to be re-architectured. These micro-\acp{VNF} are light-weight, reusable, i.e., self-contained by performing a specific task. Thus these characteristics encourage the scalability and migration of micro\ac{VNF} or \acp{VNF} in a much more manageable way. 
%\highlight{add little more on microservices}
%During the deconstruction of monolithic \acp{VNF}, a substantial number of standard functionalities are replicated; they are referred to as redundant \emph{m}\acp{VNF}. These redundant \emph{m}\acp{VNF} will increase the processing overheads and will consume resources unnecessarily, wasting the CPU cycles. To eliminate this limitation, the decomposed \ac{VNF}-\ac{FG} needs to be re-architectured \cite{chowdhury2019re} accordingly. Since the \emph{m}\acp{VNF} are lightweight and reusable, i.e., self-contained by performing a specific task, they can be scalable and easily migratable. 

%In this paper, in the quest of having more agile and fast-orchestrated future networks, we solve a deep-reinforcement-learning-based \ac{NFV}-\ac{RA} problem allowing the \acp{VNF} to be decomposed to microservices dynamically when the substrate nodes have limited resources to embed the \acp{VNF} and also re-architecting the decomposed \ac{VNF}-\ac{FG} before deploying.  The main goal of our work is to propose an algorithm which identifies and understands the importance of embedding the 'beneficial \ac{SFC}' over other \acp{SFC}. 

%In this paper, in the quest to provide seamless support to more realistic services for future networks, we have proposed an algorithm that identifies and understands the importance of embedding the `beneficial SFC’ over others. This research is an extension of our “NFV-RA + Microservices” strategy, which looks at the performance of the DDQN model in conjunction with microservices & re-architecture.

%Since the \acp{VNF} are sequentially chained, further decomposition will make the \ac{VNF}-\ac{FG} even more complex as \ac{VNF}-\ac{FG} becomes denser in terms of connected nodes and links. 
%This problem is challenging as the \acp{VNF} themselves are chronologically chained in the \acp{SFC}, and if the \acp{VNF} within an \ac{SFC} are further decomposed into microservices, the \ac{VNF}-\ac{FG} becomes even more complex. This is due to the interdependencies of the decomposed \acp{VNF}, also described as a functional dependency graph. To be precise, a \ac{VNF}-\ac{FG} becomes denser in terms of connected nodes and links when the \acp{VNF} of an \ac{SFC} are decomposed into microservices. 
%Optimal embedding of such decomposed \acp{SFC} on the substrate network, keeping all physical resource constraints and the interdependencies of the microservices, is difficult to be modelled as an exact mathematical optimization problem. 
%In this paper, we have successfully addressed it using Deep Reinforcement Learning (DRL) for the first time to the best of our knowledge. We chose DRL, as a solution tool, because it provides the right balance between optimality, computational times, and the ability to decide a change in the problem settings (i.e., decomposition of monoliths to microservices in between episodes) and adapt to that change \cite{massimo_DRL}. 
%Our overall endeavour can prove to be a significant pillar for enabling future applications like \acp{DT}, connected robotics, autonomous systems, \ac{AR}/\ac{VR}/\ac{MR} over \ac{6G} networks.  



%\vspace{-0.1in}
\section{Literature review}\label{sec:2}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%As mentioned above, future generations are anticipated to demand stringent service requirements. 
To meet the \acp{SLA} of next generation networks, \ac{NFV} has received a lot of attention. The majority of the research has focused on the placement of arriving \acp{SFC} in a \ac{FIFO} fashion. For instance, \cite{mijumbi2015design, agarwal2019vnf} formulated the problem based on the exact optimization method; however, the solutions are delivered using heuristic or meta-heuristic models due to the high computational cost. \ac{ML} techniques are commonly proposed as an effective technique for handling complicated problems like \ac{NFV}-\ac{RA}. Authors in~\cite{yuan2020q, sciancalepore2018z, quang2019deep, chetty2020virtual, chetty2021virtual} proposed reinforcement learning-based approaches. In a realistic scenario, each service has its own level of importance based on its type and requirements. Following the \ac{FIFO} technique can cause failure in deploying emergency services over best-effort ones. %Authors~\cite{cappanera2019vnf} and \cite{mohamad2020psvshare} classified the \acp{SFC} as either \ac{Pr} or \ac{BE}, yielding only two cardinalities. 
Methods that classify \acp{SFC} as either \ac{Pr} or \ac{BE}, constantly prioritizes \ac{Pr} services over the \ac{BE} ones, resulting in severe service deprivation for low-priority services~\cite{cappanera2019vnf}. \cite{malandrino2019reducing} and \cite{jalalitabar2016service} demonstrated the effectiveness of mapping the services depending on the priority of \acp{VNF}. The authors of \cite{malandrino2019reducing} discuss three types of priority: per-service, per-\ac{VNF}, and per-flow, where service prioritization is based on the delay attribute and per \ac{VNF} priority is assigned randomly. This is an iterative process that adjusts the solution after each iteration, which is not scalable considering future requirements. Also the predefined number of flows that a \ac{VNF} can handle, ignores the operational dynamics.

Priority-based scheduling and deployment is still an issue requiring an `intelligent' system to dynamically establish the online service priority and re-schedule the services according to the urgency and benefit. Researchers have proposed \ac{ILP} or heuristic models in the literature, which are either computationally costly or produce sub-optimal solutions. To overcome this drawback, we propose \ac{ML}-based algorithms to dynamically assign priority to online services and train the model to re-arrange the scheduling queue according to the needs. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-0.1in}
%\textcolor{blue}{Comment: This section can be reduced a lot. No need of so much detailed text describing the references, Table 1 is enough to focus on the main highlights. Moreover, in this paper focus more on the literature on microservices and how they are solved and then say how our approach is better. You can cut short on other literature that talks on the general NFV-RA problem.}
%\highlight{Asked to remove this sentence!!}
%Traditionally deployment of  network services was considered as a Bin-Packing problem, which has been thoroughly investigated \cite{quang2019deep}. Based on the characteristics of the problem, multiple approaches like \ac{ILP}, \ac{MILP} have been implemented to address the online \ac{VNF}-\ac{FGE} problem. 
%Due to the increased dynamism and complexity of the networks, obtaining a global solution within a reasonable time is not viable. Hence, %approaches were modelled using the exact method, but 
%heuristics or meta-heuristic algorithms were applied to reach a near-optimal solution in an acceptable computing time.

%Researchers like~\cite{luizelli2015piecing,chowdhury2017revine} adopted the \ac{ILP} approach for embedding the \acp{VNF}. 
%
%
%A few researchers made some strong assumptions about network latency and loss rate to reduce the computing cost~\cite{xie2016service}. 
%Like, the optimization in~\cite{dehury2019dyvine} is based on local and global fitness values, which are estimated on the rational rule, where only a subset of the substrate network is considered to reduce execution time, limiting the model's performance.
%where the local value depicts the Virtual Machine's availability towards the arriving services, and the global value is estimated based on the structure and resource requirements of the incoming services.  
%The authors in~\cite{agarwal2019vnf} used a queuing-based approach that decouples the \ac{VNF}-\ac{FGE} problem and implements it in a sequential system. %Firstly, placing all of the service's VNFs onto the substrate nodes and then determining the physical path based on the propagation delay. Finding an optimal solution for trivial instances is a straightforward and unrealistic process. The~authors 
%and neglected the significance of the topology's complexity which is more inclined towards the pragmatic scenario. 
%However, 
%The authors of~\cite{nejad2018vspace} adopted the \ac{MILP} model to produce a joint optimization for \ac{VNF} mapping and scheduling for denser and more complicated networks. 
%Being a heuristic model, it only provides a sub-optimal solution. 
%The authors of~\cite{mijumbi2015design} have established a strong foundation on the \ac{VNF}'s online mapping and scheduling based on meta-heuristic algorithms.
%The authors introduced some greedy and a meta-heuristic algorithms. 
%However, due to the repetitive procedure, the technique is non-scalable for larger networks and moreover, \cite{mijumbi2015design} overlooked the virtual link mapping and its associated delays. 
%Link latency must be included in order to create a more realistic environment.
%Greedy Fast Processing (GFP), Greedy Best Availability (GBA), and Greedy Least Loaded (GLL) are the three greedy algorithms that are used to evaluate the performance of online mapping and scheduling. Aside from these methods, the authors introduced Tabu Search, a meta-heuristic algorithm used to remove local minimum solutions by keeping track of all previously visited solutions.  
%\highlight{In addition to heuristic- or meta-heuristic-based approaches or linear formulations, machine learning was frequently recommended as a powerful technique for solving this issue. Like, the authors of}~\cite{9042229} \highlight{have suggested a genetic algorithm to solve the VNF-placement problems called GASVIT (Genetic Algorithm for Service mapping with VIrtual Topology design) for optical networks.} 

%Authors of~\cite{yuan2020q} and ~\cite{sciancalepore2018z} presented a model based on \ac{QL}. There are a few other works on applying different variants of \ac{RL} and \ac{DRL}.
%The authors of~\cite{yuan2020q} are primarily interested in maximizing the income by renting the available resources, which is achieved using the reward function. %This reward function is based on the shortest distance technique. 
%The authors of \cite{sciancalepore2018z}, used the k-Means clustering method, %the VNFs are grouped according to the KPIs (say, requested resources). %The placement is done based on these VNF's profiles. 
%For example, authors of~\cite{quang2019deep} implemented an \ac{$E^2D^2PG$}, based on \ac{DRL} but they did not explore microservices concept.
%address overfitting or underfitting caused by a large number of hidden neurons. 
%Furthermore, the model used the shortest-distance technique to find the path between nodes, resulting in a highly imbalanced load on specific links and a disrupted topology.

%A majority of the researchers have preferred to solve the \ac{VNF}-\ac{FGE} problem based on heuristic or meta-heuristic methods, which resulted in a sub-optimal solution. %with reasonable computation time. 
%This indicates a definite trade-off between solution quality and computation time. Even the \ac{RL} model could not deliver the optimal solution because of the complexity of the problem. As a result, solving the \ac{VNF}-\ac{FGE} problem effectively is still an open issue. In this study, to unravel this open issue, we investigate advanced \ac{RL} model, \ac{DDQL}, to improve these sub-optimal solutions, where learning from prior experience by upgraded models can be advantageous.
% made the point We are still considering the VNF-FGE problem...

%Traditionally, the deployment and update of monolithic~\acp{VNF} restrict agility and introduce unnecessary network processing overheads, causing excessive resource consumption and time. Considering the advantage of microservice technology, the researchers proposed this approach as a way to eliminate these induced restrictions, by decomposing monolithic \acp{VNF} into loosely coupled micro\acp{VNF}. 
%In the context of microservices-based \ac{NFV}, the studies in~\cite{8806705}, \cite{moro2020framework}, and \cite{fu2019service} investigated the deployment of decomposed \acp{VNF-FG}. Based on the traffic demands, authors in~\cite{moro2020framework} suggested a \ac{MILP} model to determine the best decomposition for each \ac{SFC} from the pool of already decomposed \acp{SFC}. Authors of~\cite{fu2019service} used the \ac{DRL} model for the embedding decomposed \acp{VNF} but did not explain the micro-segmentation criteria for each \ac{VNF}. 
%In the above works, the authors' have pre-acquired knowledge on the structure of the decomposed \ac{VNF} or \emph{m}\acp{VNF-FG}; nevertheless, this is not a viable option for online \ac{VNF} mapping when the arrival of \ac{VNF} or the \ac{SFC} type is unknown to the network. As a result, with respect to these works in this study, we propose a dynamic decomposition method based on network availability; the detailed description is presented in the later section.


%In our previous works we have investigated the QL models for solving the VNF-FGE problem~\cite{chetty2020virtual}, \cite{chetty2021virtual}. QL is a resilient off-policy model-free algorithm that practices an iterative approach to find the best solution. As network complexity and density grow, the model's performance suffers. In this case, the optimal solution is achievable with an extensive high computation time. To overcome this, in~\cite{chetty2021virtual} we have adopted an advanced RL model, i.e., DQL. The paper addressed the following challenges: ($1)$ the problem of overfitting or underfitting generated by neural networks; ($2)$ by obtaining a better sub-optimal solution in an acceptable amount of time; ($3)$ Maintaining equilibrium throughout the topology by opting for a more realistic link selection technique; and ($4)$ Rather than random resource initialization, we evaluated a more realistic relationship between the CPU and RAM (nodal resources). 

%Furthermore, in literature, the most authors employed the shortest-distance technique to discover the path between the substrate nodes to deploy the \acp{VNF} and \emph{m}\acp{VNF}, resulting in a highly uneven load on certain links. 
%The \ac{RL} models for solving the \ac{VNF}-\ac{FGE} problem have been studied in \cite{chetty2020virtual} and \cite{chetty2021virtual}, where the authors have maintained an equilibrium throughout the topology by opting for a practical link-selection technique and considered a  more realistic relationship between the CPU and RAM. 
%Thus, to maintain equilibrium across the topology, our studies \cite{chetty2020virtual} and \cite{chetty2021virtual} opt for a practical link-selection technique and consider a more realistic relationship between the CPU and RAM (nodal resource), which are embraced in this work also.
%The primary goal of this study is to improve model learning by implementing an enhanced \ac{DQL} version called \ac{DDQL} that eliminates the over-estimation problem caused by \ac{QL} models. %Moreover, introducing the microservice and re-architecture of network services approaches ways to utilize network resources efficiently. 
%Our decomposition model first uses analytical criteria for discovering the potential/candidate \acp{VNF} for decomposition from the arriving network services and later determines the degree of micro-segmentation. The current availability of the network and requested resources by \acp{VNF} define these analytical criteria, making it suitable for an independent and intelligent zero-touch system. Thus, our decomposition occurs online (say dynamically), unlike in the literature, where the structure of the decompositions are static or pre-defined by the engineers. However, our model does not have any prior information on the decomposition structure for the potential/candidate \ac{VNF}, making this model more pragmatic.
%Our model has used analytical criteria for the decomposition of the candidate \acp{VNF}. The current availability of the network determines this analytical criteria; thus, our decomposition occurs online. The model does not have any prior information on the decomposition structure, making our model more pragmatic. 
%Table~\ref{table*:comp} summarizes related works. %, where Rel. CPU and RAM, BW, and~PD represents Relationship between the CPU and RAM, Bandwidth and~Propagation Delay, respectively.
%\vspace{-0.1in}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{System Model}\label{sec:3} 
The physical topology is modelled as a directed graph $\textbf{G} = (\textbf{H}, \textbf{N})$, where $\textbf{H} = [\textbf{h}_{0},\ldots,\textbf{h}_{|H|-1}]$ and $\textbf{N} = [\textbf{n}_{0},\ldots,\textbf{n}_{|N|-1}]$ represent the set of physical nodes (say high-volume servers) and physical links of the topology, respectively.  Each physical node $\textbf{h}_{x'} = [h_{x', 0},\ldots, h_{x', J_{node}-1} ]$ denotes the amount of available nodal resources like CPU core, RAM, etc, and $J_{node}$ is the number of nodal resource types indexed from $0, 1,\ldots,J_{node}-1$. Similarly, each physical link $\textbf{n}_{y'} = [n_{y',0},\ldots,n_{y',J_{link}-1}]$ signifies the amount of link resources like bandwidth, latency, etc. $J_{link}$ stands for the number of link resource types, the available resource for physical link.
The \ac{VNF-FG} or \ac{SFC}~(${\Psi}$) is represented as a directed graph $\textbf{G}_{\Psi}'=(\textbf{V}_{\Psi},\textbf{B}_{\Psi})$ with the set of \acp{VNF} ($\textbf{V}_{\Psi} = [\textbf{v}_{\Psi, 0},\ldots,\textbf{v}_{\Psi, |V|-1}]$) and \acp{VL} ($\textbf{B}_{\Psi} = [\textbf{b}_{\Psi, 0},\ldots,\textbf{b}_{\Psi, |b|-1}]$) , that delivers an end-to-end service. Deploying these graphs onto the physical topology is termed as the \ac{VNF-FGE} problem. Each \ac{VNF} ($\textbf{v}_{\Psi, x} = [r_{\Psi,x,0},\ldots,r_{\Psi,x,J_{node}-1}]$) and \ac{VL} ($\textbf{b}_{\Psi, y} = [l_{\Psi,y,0},\ldots,l_{\Psi,y,J_{link}-1}]$) comprises of set of requested resources like CPU core, delay, bandwidth etc. %, according to the service type. 
%A similar description is applied to the microservices; refer to our previous work for more details. 
The computing resources initialization in most related works, is done in a random manner, disregarding the high correlation between the CPU core and RAM. This work outlines the link between the CPU core and RAM as in~\cite{gupta2018service}. In addition, we also considered delay, jitters, packet loss, reliability and threshold waiting time as some of the \ac{QoS} attributes, thus making the $J_{node} = 6$ in our case. Similarly, $J_{link} = 2$ in our studies, considering latency and bandwidth. 

%The literature shows that the services arrive with pre-determined priority levels/classes. Moreover, these priority levels are either categorized as Premium or Best Effort classes. 
%From the literature, the service priority is categorized as \ac{Pr} or \ac{BE} classes, giving more importance to the \ac{Pr} ones introduces bias in the system. This approach has two flaws, which are significant discussion in this paper. 

%\vspace{-0.1in}
\subsection{Dynamic Prioritization}\label{subsec:1} 
A major drawback of commonly-used methods of binary classification of services into \ac{Pr} and \ac{BE} is that, the pre-determined priority levels for the arriving services are randomly allocated and the co-relation between the service requirements and priority are ignored. In a realistic scenario, the allocation of service priority should be based on various factors of QoS, flow type, etc. Determining the priority levels for the existing or well-aware services is trivial. The complexity induces when future communications system expects frequent unseen `short-lived' services with instant placement requirements. To fulfil this need, an intelligent and \ac{DyPr} model is anticipated rather than a static or conventional method.
In the \ac{DyPr} model, we investigate the relationship between the requested \ac{QoS} factors of the arriving service and, based on it, a dynamic priority level is assigned. This problem is viewed as a multiple regression task with various independent variables $A[0]\dots A[p]$ (like \ac{QoS} factors with $p$ as the number of factors), to predict a dependent continuous variable $Y'$ as referred in Eqn. (\ref{eq:multiR}). Here $W$ and $B$ are the regression coefficient and residual term respectively, which are learned during the training. The adopted model discovers the linearity between the dependent and independent variables. In our case, these independent variables are threshold jitters, delay, and packet loss, which a service can tolerate, and the dependent variable denotes the appropriate priority level. However, the multiple regression data suffers from multi-colinearity, which causes the estimation of regression coefficients to be inaccurate. As a result, its existence reduces the model’s performance by causing the predicted value to differ significantly from the actual value. One way to diminish this is by adopting the \ac{RR} model, which performs L2 regularization, due to which the model is more restricted and causes less over-fitting \cite{introML}. The objective is to minimize the cost function mentioned in~(\ref{eq:costRid}), where $M$ is the number of samples (services per run), $Y_\Psi$ is the actual value.  The $\lambda$ (penalty term) regularizes the coefficients in such a way that the optimization function is penalized if the coefficients assume high values. 
\begin{equation}\label{eq:multiR}
   \footnotesize Y'_\Psi = W[0]\times A_\Psi[0]+ \dots + W[p]\times A_\Psi[p] +B
\end{equation}
%where, A[0] to A[p] are the variable, and p = 3 in our case. W and B are the parameters of the model and $Y'_{\Psi}$ is the predicted value for sfc ($\Psi$).
\vspace{-0.189in}
\begin{equation}\label{eq:costRid}
   \footnotesize \sum_{\Psi = 0}^{M} (Y_\Psi - Y'_\Psi)^2 = \sum_{\Psi = 1}^{M} (Y_\Psi - \sum_{j = 0}^{p}W_j\times A_{\Psi,j})^2 + \lambda \sum_{j = 0}^{p} W_{j}^2
\end{equation} 

%Ridge Regression is supervised learning, where the pre-existing datasets are used for training purposes. Our study evaluates the model’s performance for unseen services. To support this dynamism, we have modified the Ridge Regression model by adding an observation phase before the learning phase, which helps in constructing our training datasets. In this phase, due to the unavailability of arriving service information, the model saves (observes) the online services in a buffer until it is full. During this time, the allocation of priority is performed uniformly. Later, the learning phase uses the current and saved transitions for model training, these saved transition are 
The \ac{RR} model is supervised learning, which uses pre-existing datasets for training purposes. Our study evaluates the model's performance for future unseen services; hence, we assume no helpful service information is available to us. The traditional \ac{RR} model would not provide enough support due to the lack of sufficient datasets. To support the dynamism, we have modified it by adding an observation phase before the learning phase. This helps in constructing our training datasets, making an `Online-\ac{RR}' model. In the observation phase, due to the unavailability of service information, the model saves (observes) the online services in a memory buffer until the minimal transitions is achieved to begin the training phase. During this time, the allocation of priority is performed uniformly. Later, once the saved transition threshold is surpassed, the learning phase starts, which uses the current and saved transitions for model training. These saved transitions (batch transitions) are selected randomly from the memory to avoid any chance of overfitting (co-relation between the transitions). The model's accuracy is checked periodically. Once the model reaches the desired accuracy, the trained model state changes from `Train' to `Predict'. The overview of \ac{DyPr} is shown in Fig.~\ref{fig:Overview}.
Moreover,  this model was chosen after a thorough evaluation of model performances using several methodologies, including \ac{ANN} and Lasso. Of all the models, the online-\ac{RR} model outperformed expectations. This model is constructed with an envision to support future unseen services by introducing a zero-touch cognitive system. 
\begin{figure}[h]
%\vspace{-0.2in}
    \centering
    \includegraphics[width=0.75\textwidth]{Figures/Presentation1.pdf}
    %\vspace{-0.4in}
    \caption{Overview of the \ac{DyPr} scheme.}
    %\vspace{-0.15in}
    \label{fig:Overview}
\end{figure}
Traditionally, the services are categorized into two cardinalities, which diminishes the value of services relative to one another within a class. Most research has ignored the intra-class priority aspect; however, given the future demands, it should be considered. To overcome this, a service priority is ranked between 0.0 to 1.0, with
0.0 represents the least essential service, and 1.0 being the most crucial. Each priority level is expressed in macro-class priority and micro-class priority. While the micro-class priority establishes the priority status inside a class, the macro-class priority categorizes the class to which it belongs. For example, the priority of \ac{SFC} A and \ac{SFC} B is 0.79 and 0.72, respectively. Though both the \acp{SFC} belong to the same class (i.e., macro-class is 7), \ac{SFC} A with a micro-class as 9 will be prioritized over the \ac{SFC} B with a micro-class as 2, due to the higher value. 
This delivers more details about the importance of services within the class, which is beneficial, especially for time-Sensitive or critical applications and for the adaptive scheduling phase. Therefore, in our work, the \ac{DyPr} is considered as a Regression model rather than classification. 

% Defination: Multicollinearity, or collinearity: the existence of near-linear relationships among the independent variables.

% Things can be included: (Future)
% 1) model performance with various approaches, 
% 2) proof of Multicollinearity using correlation matrix. 
% 3) performance of Ridge model with various alpha value (since is an important parameter for Ridge model, incorrect value may make the model work as linear model. )
%4) Training and testing performances.
%\vspace{-0.2in}
\subsection{Adaptive Scheduling}\label{subsec:2} 
Conventionally, high-priority services are preferred over others, leaving the low-priority services to wait for extended periods of time, resulting in their starvation. This highlights the second drawback of conventional binary classification of services. A biased scheduling system, which raises the questions like, `Can the priority attribute be the most effective scheduling decision-making factor?' `Will the decision be more optimal by considering additional factors, such as service waiting time or reliability?' 
%`Will additional factors, such as service waiting times or reliability, make the scheduling more prone to an unbiased system?'
%
In a search for an unbiased scheduling system, we have proposed an intelligent Adaptive Scheduling module using the \ac{DDPG} approach. This approach weighs more than one factor and provides an optimal decision. Let us say, that a high-priority \ac{SFC}~A has a higher waiting threshold than a lower-priority \ac{SFC}~B (which is about to expire soon). According to the traditional model, \ac{SFC}~A will be selected, ignoring the \ac{SFC}~B to expire, affecting the \ac{QoE}. However, our model, which considers more than one factor, prefers \ac{SFC}~B over \ac{SFC}~A, understanding that there will not be any negative impact on \ac{SFC}~A if it waits in a queue a little longer, providing scheduling optimality.

\ac{DDPG} is an actor-critic \ac{RL} model, trained  %whose primary aim is 
to identify `Beneficial and Starving' services based on 3-factors: \ac{TWT}~$(T)$, Reliability~$(\Gamma)$, and Priority~$(P)$ of the service.   %described as the state-space. 
%Here, the environment is the online services and 
The state-space for the requested service $\Psi$ is represented as $(T_{\Psi}, \Gamma_{\Psi}, P_{\Psi})$.
Based on these factors, the \ac{DDPG} agent determines a rank for each service (i.e., action-space~$(A_{\Psi})$), indicating the significance of deploying the service. With a higher rank, the necessity to deploy the service is significant, resulting in a rank-based scheduling method. %, which is ordered in ascending order. To train a RL model, the reward function plays a crucial role; since the environment provides feedback at each step, which is based on a points system. 
%
%The reward function is essential for training DDPG model since the environment offers feedback to the agent based on the given action. %on a points system at each step. 
%In order to train the DDPG model, an adequately constructed reward function is essential since it provides feedback to the agent based on the action taken. 
In order to train the \ac{DDPG} model, an appropriate reward function is essential since it provides feedback to the agent based on the given action's effectiveness. %of the action.
%
Equation (\ref{eq:rDDPG}) describes the reward function $R(\cdot)$, which comprises two parts: Beneficial-cost $(\Upsilon)$ and Starvation-cost $(\Phi)$, providing a trade-off between the high-priority, starvation, and high-reliable services. The $R(\cdot)$ is a point-based function; depending upon the significance of factors, the reward points $(\theta_{pts})$ are scaled, as in Eqns. (\ref{eq:bencost}) and (\ref{eq:starcost}), where $n(\cdot)$ is the normalized function.
\begin{equation}\label{eq:rDDPG}
   \footnotesize R(\Psi) = \Upsilon_\Psi + \Phi_\Psi,
\end{equation}
\begin{equation}\label{eq:bencost}
    \footnotesize \Upsilon_\Psi = [(1 -n(T_{\Psi})\times\theta_{pts}) + (\Gamma_{\Psi}\times\theta_{pts}) + (P_{\Psi}\times\theta_{pts})],
\end{equation}
\begin{equation}\label{eq:starcost}
   \footnotesize \Phi_\Psi = \zeta_{\Psi}\times\theta_{pts},
\end{equation}
\begin{equation}\label{eq:starRate}
    \footnotesize \zeta_{\Psi} = 
    \begin{cases}
      \alpha(1-\epsilon)^\kappa,& \text{if } Z_{\Psi} = 1\\
       0,              & \text{otherwise},
    \end{cases}
\end{equation}
\begin{equation}\label{eq:potentialS}
     \footnotesize  Z_{\Psi} = 
    \begin{cases}
      1,& \text{if } P_{\Psi} \leq 0.2\\
       0,              & \text{otherwise},
    \end{cases}
\end{equation}
Equation (\ref{eq:starcost}) introduces the biasness to diminish the starvation issue, where $\zeta_{\Psi}$ represents the starvation factor, which decays exponentially with the \ac{SFC}'s rank. %in Fig. \ref{fig:StarR}. % for service $\Psi$. 
According to Eqn. (\ref{eq:potentialS}), our algorithm determines if the arriving service qualifies as a `Potential Starving' service or not. On affirmative, the algorithm checks its placement position $\kappa$ in the adaptive scheduling queue, which impacts the starvation cost. $\kappa$ is determined using the exponential decay formula, with $\alpha$ as 1 and decay rate ($1-\epsilon$) as 0.1. The decay rate induces greediness in the system when the service is positioned at the beginning by giving higher rewards than others. Thus, making the agent position the starving services at the beginning. 

% \begin{figure}
% \centering
% \includegraphics[width=0.3\textwidth]{Figures/Plot_Decay rate.pdf}
% \caption{Starvation Rate}
% \label{fig:StarR}
% \end{figure}
%\vspace{-0.15in}
\subsection{Admission Control}\label{subsec:3} 
After achieving an optimal scheduling queue, we constructed an admission-control model to evaluate the extent to which the `Potential Starving' and `High-priority' services are deployed before expiration. This determines the trade-off between starvation and traditionally-preferred services. 
When a service is under placement, the waiting period $(\Delta)$ for the reminder services is recorded, which is illustrated in a 2-D matrix as below. A scheduling queue, for instance, is $[SFC_0, SFC_1, SFC_2, SFC_3]$.  When $SFC_0$ is placed, the remainder services' waiting span is $x_0$, which is the deployment time of $SFC_0$. With the deployment of $SFC_1$, the waiting time for $SFC_2$ and $SFC_3$ is increased by $x_1$ and so on. $\Delta_{\Psi,\Psi}$ depicts the total waited time by the service $\Psi$ in the queue. 
%\vspace{-0.05in}
 \[\scriptsize
   \Delta = 
     \bordermatrix{ & SFC_0 & SFC_1 & SFC_2 & SFC_3  \cr
       SFC_0 & \Delta_{0,0} & \Delta_{0,1} & \Delta_{0,2} & \Delta_{0,3} \cr
       SFC_1 & \Delta_{1,0} & \Delta_{1,1} & \Delta_{1,2} & \Delta_{1,3} \cr
       SFC_2 & \Delta_{2,0} & \Delta_{2,1} & \Delta_{2,2} & \Delta_{2,3} \cr
       SFC_3 & \Delta_{3,0} & \Delta_{3,1} & \Delta_{3,2} & \Delta_{3,3}} \qquad
 \]
%\vspace{-0.1in}
 \[\scriptsize
   \Delta = 
     \bordermatrix{ & SFC_0 & SFC_1 & SFC_2 & SFC_3  \cr
       SFC_0 & 0 & x_{0} & x_{0}       & x_{0}       \cr
       SFC_1 & 0 & x_{0} & x_{0}+x_{1} & x_{0}+x_{1} \cr
       SFC_2 & 0 & x_{0} & x_{0}+x_{1} & x_{0}+x_{1}+x_{2} \cr
       SFC_3 & 0 & x_{0} & x_{0}+x_{1} & x_{0}+x_{1}+x_{2}} \qquad
 \]
To initiate the placement, the service must satisfy the requirement as in Eqn. (\ref{eq:AC}).

\vspace{1.5in}
\begin{equation}\label{eq:AC}
       \footnotesize \Xi_{\Psi} = 
    \begin{cases}
      1,& \text{if } \Delta_{\Psi,\Psi} \leq T_{\Psi}\\
       0,              & \text{otherwise},
    \end{cases}
\end{equation}
%\vspace{-0.2in}


\subsection{VNF-FGE Problem Formulation}\label{subsec:4} 
Result of \cite{9923918} show that the \ac{DDQL} model solves the \ac{NFV}-\ac{RA} problem efficiently, intending to embed maximum \acp{SFC} onto the substrate network under certain defined constraints. 
%; according to RL, the agent observes a state in the environment and responds with a suitable action based on a policy. Based on the achieved action, the environment provides the agent with feedback (reward or penalty).]Briefly, in the DDQN model, 
In \cite{9923918} we considered the physical topology as an environment comprised of high-volume servers. Each \ac{VNF}-\ac{FG} and its resource requirements are represented as state-space ($S$). The amount of physical nodes/servers present in the topology is described as the action-space ($A$). The Local reward function (i.e., the Eqn. (13) in~\cite{9923918}) has been modified as Eqn. (\ref{ConlocR}) , which is constructed based on the four attributes: 

\begin{enumerate}
    \item $R_{quality,y}$, the quality of the selected node ($y$) for deploying the \ac{VNF}, ($x$) is the ratio of available resources ($Ar_{y}$) in the node to the initialized resources ($Ir_{y}$), as in Eqn. (\ref{eq:Qnode}). The availability of resources in a physical node determines its quality.
        \begin{equation}\label{ConlocR}
            \footnotesize   L_{reward}(x)= 
            \begin{cases}
               \boldsymbol{R_{vnf}},& \text{if } \Phi_{x}^{y} = 1\\
               P^{pt}_{vnf},              & \text{otherwise}
            \end{cases}
        \end{equation}
        \begin{equation}\label{eq:Lreward}
           \footnotesize \boldsymbol{R_{vnf}} = R_{quality,y} + R_{priority} + R_{rel} + R_{placement}
        \end{equation}
        \begin{equation}\label{eq:Qnode}
           \footnotesize R_{quality, y} = \frac{Ar_{y}}{Ir_{y}}\times R^{pt}_{vnf}
        \end{equation}
        \begin{equation}\label{eq:RPr}
           \footnotesize R_{priority} = P_{\Psi}\times R^{pt}_{vnf} 
        \end{equation}
        \begin{equation}\label{eq:Rrel}
           \footnotesize R_{rel} = \Gamma_{\Psi}\times R^{pt}_{vnf} 
        \end{equation}
        \begin{equation}\label{eq:Rplacement}
          \footnotesize  R_{placement} = J^{x}_{y}\times R^{pt}_{vnf} 
        \end{equation}
        
    \item Based on the service priority ($R_{priority}$), as in Eqn. \eqref{eq:RPr}.
    \item Based on the requested service reliability ($R_{rel}$), as Eqn. \eqref{eq:Rrel}.
    \item Time taken by the \ac{DDQL} model to find an appropriate node for the placement ($J^{x}_{y}$), Eqn. \eqref{eq:Rplacement} represents the placement reward function ($R_{placement}$).
\end{enumerate}
%Microservices further adds complexity to the state and action space. The standards to identify `potential' decomposable \acp{VNF} and their fine-granularity, as well as the removal of redundant micro-\acp{VNF} using the re-architecture method, are additional details that interested readers can find in our earlier work \cite{9923918}. 

Algorithm \ref{algo1} describes the overall model. %For more details on \ac{DDPG} can be found in~\cite{lillicrap2015continuous} and for the deployment algorithm in~\cite{9923918}.

%\vspace{-0.1in}

%\subsection{Overview of Proposed model}
%Algorithm \ref{algo1} describes an overview of the proposed model. Lines 1 to 4 define the initialization of the necessary attributes for constructing the Primary and Target \ac{NN} and replay memory for stable learning. At the start of each episode, the environment is restored to its original state with abundant resources, as seen in lines 5-7. Once the agent observes the state and, based on it, the action is determined using $\epsilon$-Greedy Exploration-Exploitation strategy (lines~9-18). The agent earns rewards or penalties depending on whether the chosen action satisfies or dissatisfies the demanded resources (lines 19-31).
%On an unsuccessful attempt, the model inspects for decomposition opportunities. If possible, the model initiates the decomposition phase; otherwise, a penalty is applied (lines 21-29). All these transitions are stored in the replay buffer (line 33), later on, target Q values and loss are estimated (lines 38-39), and finally, the primary and target \ac{NN} are updated at the defined rate (lines 40-42). Our model's performance is not confined to the parameters provided, but it can also be trained for other use-cases such as URLLC or eMBB.

%Our model is not restricted only for the specified parameters but rather it can be trained for different usecases like \ac{URLLC} or \ac{eMBB}. 

\begin{algorithm}[!]\footnotesize
\SetAlgoLined
Initialize DDPG Model: Critic, Actor, Target Critic, Target Actor Networks, \ac{DDPG} Replay Buffer$B_{DDPG}$\\
Initialize \ac{RR} Memory Buffer $B_{RR}$\\
    \ForEach{episode i = 1... epi} 
    {
    Reset the Environment\\
    Initialize substrate node resource $R_H$, substrate link $R_N$ \\
    Received arriving T services \\
        \While{for all T services}
        {
        Using \ac{DyPr} method; online-\ac{RR} model \\
        \eIf{status = "Train"} 
            {\eIf{Transition $<$ Threshold Transition}
                {Priority is selected randomly}
                {Online-$\ac{RR}$ model gets trained}
            }
            {Prediction: using Trained model}
            
        Using \ac{AdSch} method; \ac{DDPG} model\\
            Achieve the Rank for each services \\
            %Select action, using current policy and exploration noise \\
            %Execute action (Rank), observe rewards, and new state \\
            %Store transitions in $B_{DDPG}$\\
            %Randomly sample U transitions from $B_{DDPG}$ \\
            %Estimate Target Value\\
            %Update Critic, Actor, target networks \\
        }
    Sort the T service in ascending order (T'), according to achieved rank \\
    \ForEach{time-step t' = 1...T'}
    {
        Admission Control  \\   
        Deployment initiate \\
    }
    } 
\caption{DyPr and AdSch }\label{algo1}
%\vspace{-0.05 in}
\end{algorithm}
%\vspace{-0.1in}
%\vspace{-0.5 in}
%\begin{algorithm}[!]\small
%\SetAlgoLined
%\eIf{all \acp{VNF}/ \emph{m}\acp{VNF} are deployed}
%            {
%                $x_0$ $\leftarrow$ source \acp{VNF}/ \emph{m}\acp{VNF}, \\
%                $x_j$ $\leftarrow$ Destination \acp{VNF}/ \emph{m}\acp{VNF}\\
%%                Estimate all path $\textbf{P}$ between $x_0$, and $x_j$\\
%                \ForEach{substrate path p = 1... P}
%                {
%                    \While{b = j}
%                        {Estimate Latency ($x_0$,$x_b$)\\
%                        \eIf{$Latency (x_0,x_b) \leq Latency$}
%                        {Reward is given\\}
%                        {Penalty is given\\}
%%                    }
%                }
%            }
%            {Penalty is given\\}
%        Store transition ($s_t, a_t, r_t, s_{t+1}$)  
% \caption{Virtual Link~Placement}\label{algo3}
%\end{algorithm}
%\vspace{-0.1 in}
\section{Simulation results}\label{sec:4} 

In this section, the effectiveness of the \ac{DDPG} and \ac{RR} models for \ac{AdSch} and \ac{DyPr} are examined under various conditions, for NetRail (7 nodes, 10 links) and BtEurope (24 nodes, 37 links) topologies, under diverse substrate nodal and link capacities (i.e., from highly available resource topology to easily exhausted). The online services are constructed using the Erdős--Rényi model with different structural complexity and resource requirements. 
Each run consists of 2000 episodes, and each episode is expected to have a maximum of 100 services. 
%Each run consists of 3000 episodes with 100 time-steps per episode, and each time-step produces a distinct \ac{VNF}-\ac{FG} with a diverse set of resource requirements, as mentioned above. 
The \ac{DDPG} and Ridge model is designed in Python language using the PyTorch library, and the simulations are run on an Intel Core i7 processor with 64 GB RAM. Table \ref{table:DDPG} lists the parameters applied to develop the models and services. 
%
%Table~\ref{table:DDPG} describes the parameters used to construct the DDPG model.
%\vspace{-0.1 in}
\begin{table}[h]
\caption{Parameters}
\begin{tabular*}{\hsize}{@{}@{\extracolsep{\fill}}cc@{}}
 %\toprule
 \hline
 \multicolumn{2}{c}{\textbf{DDPG Model}} \\
 \hline
 Alpha & 0.0001 \\
 Beta & 0.001 \\
 Gamma & 0.99 \\
 Batch Size & 64 \\
 Optimizer & Adam \\
 Memory Size & 50000 \\
 Hidden Layers & 6 \\ 
 Neurons per Layer & 300 \\ 
 Neural Network & 2 \\
 Activation function & Sigmoid \\
 \hline
%  \multicolumn{2}{c}{\textbf{Topology}} \\
%  \hline
%  Netrail & 7 Nodes, 10 Links \\
%  BtEurope & 24 Nodes, 37 Links \\
%  \hline
 %\bottomrule
\end{tabular*}
\label{table:DDPG}
%\vspace{-0.1in}
\end{table}

In this work, we are considering a `worse-case' scenario, where maximum of 100 services arrive at once, imposing a significant load and high variation on the topology. Moreover, most arriving services need to be deployed sooner, as their threshold waiting time is considerably less, which adds to the system's complexity. Our model's efficiency is compared with traditional queuing models like \ac{FIFO}, \ac{WFQ}, and High-Priority-based scheduling. 
%\vspace{-0.15 in}
\subsection{Need for Priority}
Figures~\ref{fig:FIFO_netrail} represents the deployment of high and low-priority \acp{SFC} in a \ac{FIFO} manner for Netrail and BtEurope. The model deploys the services as it comes, unable to distinguish between emergency and non-emergency services as the deployment occurrs without any guidelines or prior knowledge of the service. As a result, less than 6\% of urgent/emergency services are preferred, causing considerable rejection of them. This shows the need for priority which is predicted by the online-\ac{RR} model. %
%
\begin{figure}
\centering
\begin{center}
    \includegraphics[width=0.7\columnwidth]{Figures/Plot_FIFO_perf_Netrail_BtEurope00.pdf}
    \caption{Performance of FIFO}
    \label{fig:FIFO_netrail}
    %\vspace{-0.2 in}
\end{center}
\end{figure}
%
%\begin{figure}
%\centering
%\begin{center}
%    \includegraphics[width=0.65\columnwidth]{Figures/Plot_FIFO_perf_BtEurope_12_8.pdf}
%    \caption{FIFO: BtEurope: 12-8 scenario}
%    \label{fig:FIFO_BtEurope}
%    \vspace{-0.2 in}
%end{center}
%end{figure}
%
\begin{figure}[h]
\centering
\begin{center}
 \includegraphics[width=0.7\columnwidth]{Figures/Plot_Ridge_PerformaceError_Percent.pdf}
\caption{Performance of Online Ridge Regression Model}
\label{fig:Training}   
%\vspace{-0.2 in}
\end{center}
\end{figure}
%

Figure~\ref{fig:Training} shows the training phase and Prediction phase of the online-\ac{RR} model. The model gets trained until its accuracy exceeds 80\%, however we only displayed for episode 0 for training phase. Initially, the model observed the \ac{SFC} till 32 iterations; later, it commenced learning by discovering a logistical approach. Figure~\ref{fig:Training} depicts the prediction for last episode of a run. It is evident that the model performed well in predicting the priority, as the error\% between the predicted and target priority values are less than 10\%. Thus, the predicted model's accuracy was also above 80\%.

%\vspace{-0.2in}
\subsection{Existence of Starvation}
The effectiveness of the high-priority-based scheduling paradigm is seen in Fig.~\ref{fig:netrail_12_4_SAR}. Here, the model favours high-priority \acp{SFC} above others to avoid the problems caused by \ac{FIFO}. This triggers a prolonged wait for low-priority \acp{SFC} to be deployed, creating a `Starvation' experience and a low acceptance rate. Even with the large nodal resource or higher density topology, as seen in Figure~\ref{fig:netrail_12_4_SAR}, starvation still exists. This starvation gap might slightly get reduced over time for much denser topologies with ample available resources. However, this is unrealistic topology due to the dynamism, where the plentiful resources is not always available.
\begin{figure}
\centering
%\begin{center}
 \includegraphics[width=0.7\columnwidth]{Figures/Plot_FIFO_perf_starvation.pdf}
\caption{Priority Algorithm Netrail SAR: 12-4 scenario}
\label{fig:netrail_12_4_SAR}   
%\end{center}
\end{figure}
%\vspace{-0.2in}
%
%\begin{figure}
%\centering
%\begin{center}
% \includegraphics[width=0.55\columnwidth]{Figures/Plot_BtEurope_12_4.pdf}
%\caption{Starvation: BtEurope SAR: 12-4 scenario}
%label{fig:netrail_12_8_SAR}   
%\end{center}
%\end{figure}
%\vspace{-0.15in}
\subsection{Diminish of Starvation}
Figure \ref{fig:DDPG_HM} represents the \ac{SAR} (contains all priority levels, excluding lower-priority \acp{SFC}), and Figure \ref{fig:DDPG_Star} depicts the \ac{SAR} exclusive for low-priority \acp{SFC} for Netrail and BtEurope topologies with 12-4 and 12-8 CPU cores. In Figure \ref{fig:DDPG_HM}, the \ac{WFQ} and high-priority-based models embed a large number of high-priority \acp{SFC} to establish a deploying rule. This pattern is repeated when topological density or nodal capacity increases. From the figures, the \ac{WFQ} and high-priority-based models established a deploying rule by embedding only beneficial \acp{SFC}. This pattern is repeated when topological density or nodal capacity increases. 
The \ac{DDPG} model, on the other hand, discovered a trade-off between high and low-priority \acp{SFC} by identifying `Beneficial and Starving' \acp{SFC}, resulting in a higher rate of deployment of low-priority \acp{SFC} than other models. \ac{DDPG}, like Netrail 12-4 CPU cores, was able to deploy five times more low-priority \acp{SFC} than \ac{WFQ} at the expense of three less high-priority \acp{SFC}. However, in the remaining scenarios (Netrail 12-8; BtEurope 12-4, and BtEurope 12-8), there is a 100\% increase in the deployment of low-priority services (Fig.\ref{fig:DDPG_Star}).
This affected high-priority service deployment, with a 30\% reduction in Netrail and a 25\% reduction in BtEurope (Fig.\ref{fig:DDPG_HM}) respectively. 

%The remaining ones, on the other hand, have deployed twice as many low-priority \acp{SFC} (i.e., a more than 100\% increase) at the cost of less than 30\% for Netrail and 25\% for the BtEurope topology of other \acp{SFC}.

%Our model considers the services' priority, reliability and threshold waiting time, thus offering first preference to the `Beneficial and Urgent' Service. This produced a trade-off between serving High-priority  and reducing `starvation.' 
%\vspace{-0.1in}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\columnwidth]{Figures/Plot_High_and_Meduim_services_00.pdf}
    \caption{SAR: Deploying Beneficial services}
    \label{fig:DDPG_HM}
    %\vspace{-0.1in}
\end{figure}

\begin{figure}[h]
%\vspace{-0.2in}
    \centering
    \includegraphics[width=0.7\columnwidth]{Figures/Plot_Starvation_services.pdf}
    \caption{SAR: Deploying Starving services}
    \label{fig:DDPG_Star}
\end{figure}
%\vspace{-0.1in}

\section{Conclusions}\label{sec:5}
The main aim of this study was to showcase the existence of the starvation problem, which the researchers have neglected. In this work, we have explained the existence of the starvation problem in the current scheduling methods and how the scheduling process should not be based only on priority but also on other important factors like threshold waiting time and reliability. With a motive to propose an intelligent scheduling scheme, our model \ac{DDPG} has performed efficiently by deploying twice as many low-priority services as others. The \ac{DDPG} agent successfully identified the `Beneficial and Starving' services, which caused a reduction in the starvation of low-priority services. Moreover, we have proposed a method to define dynamic priority for the upcoming services without hindrance. Our online-\ac{RR} model learns the pattern within 100 transitions, and the accuracy rate for the prediction model is above 80\%. The presence of these problems can have a negative impact in the future if not addressed correctly.
%\vspace{-0.05in}
%\highlight{add here and in result section why deployment rate is low: its because of the admission control and because we are loading the network with less waiting threshold services!!}
%
\input{Acron}
%\balance
\bibliographystyle{IEEEtran}
\bibliography{myref.bib}
\end{document}

