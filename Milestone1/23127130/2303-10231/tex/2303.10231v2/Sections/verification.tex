\section{Algorithmic Verification of $\delta$-Robustness 
% with Application to Robotic Walking
}

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{Figures/alg_results.pdf}
    \vspace{-0.6cm}
    \caption{Results of the algorithmic approach to Opt. \eqref{eq: optdelta} for the gaits shown in Fig. \ref{fig: motivation} with the maximum allowable $\chi$ set to $50$. As shown, the gaits were determined to be $\delta$-robust for $\delta^* = 0$ and $\delta^*=6$mm, respectively.}
    \label{fig: algresults}
    \vspace{-0.5cm}
\end{figure}

% This section seeks to answer the question: How do we check $\delta$-robustness of a given periodic orbit $\O$?  
\new{Finally, to verify the $\delta$-robustness of a given periodic orbit $\O$, we will synthesize an optimization framework that leverages the previously presented robust Lyapunov conditions.}
% derive conditions for $\delta$-robustness through the 
% use robust Lyapunov functions (as introduced in the previous section).  
% In particular, we will synthesize an optimization framework for verifying $\delta$-robustness. 

\newsec{Problem Setup}  
% We begin by setting the stage for the proposed verification technique.   In particular, 
Assume the existence of a stable periodic orbit $\O$ and so $x_{k+1} = \P (x_k, 0)$ has an exponentially stable fixed point $x^*$.  For simplicity we will take $x^* = 0$ (achieved via the simple coordinate transformation $x \mapsto x - x^*$).  As a result, the linearization: 
$$
x_{k + 1} = A x_k  := D\P(0,0) x_k
$$
is exponentially stable. The Lyapunov matrix $P = P^T > 0$ is obtained by solving the discrete-time \new{Lyapunov} equation: 
$$
A^T P A - P = - Q
$$
for $Q = Q^T > 0$.   The end result is that the discrete-time Lyapunov function $V(x) = x^T P x$ satisfies:
\begin{align}
\label{eqn:lyap1lin}
    \lambda_{\min}(P) \| x  \|^2 \leq V(x)  & \leq \lambda_{\max}(P)  \|   x \|^2  \\
  V(A x) - V(x) &  \leq - \lambda_{\min}(Q) \|  x  \|^2. 
  \label{eqn:lyap2lin}
\end{align}
and thereby establishes exponential stability of the linear system (and the nonlinear system locally).  Unlike stability, it is not guaranteed that this Lyapunov function can be used to establish robustness.  Yet we will use it as a ``guess'' for a robust Lyapunov function in order to develop an algorithm to establish the robustness of a given gait $\O$. 

\newsec{Optimization Problem}  Recall that the invariant set used to establish $\delta$ robustness was defined in Lemma \ref{lem:levelset}, namely $\Omega_{r(\delta)}$.  In this case: 
$$
\Omega_{r(\delta)} = \{ x \in \R^n | V(x) = x^T P x \leq r(\delta) := k_2 (\chi \delta) ^c \}.
$$
Per the proof of Lemma \ref{lem:levelset} we therefore have:
$$
B_{r_1}(0) \subset \Omega_{r(\delta)}  \subset B_{r_2}(0), 
$$
with:
$$
r_1 := \chi \delta, \qquad  r_2 := \left(\frac{\lambda_{\max}(P)}{\lambda_{\min}(P)}\right)^{\frac{1}{2}} \chi \delta. 
$$
Then with the goal of finding the largest $\delta^* > 0$ such that $\O$ is $\delta$ robust, we formulate the following optimization problem: 
\begin{align}
    \label{eq: optdelta}
    (\delta^*,\chi^*) = \argmax_{\delta, \chi > 0} & ~ \delta \\
    \text{s.t. }  & V(\P(x,d)) - V(x)  \leq - k\|  x   \|^2  \notag \\
                  & \quad \forall ~ r_1  < \| x \| < r_2 , \quad \forall ~  d \in [-\delta,\delta], \notag
\end{align}
where $k \in (0,1)$ is a user-defined variable, and we take $Q = I$ (wherein $\lambda_{\min}(Q) = 1$) to remove decision variables.  
%

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{Figures/lyapunov_condition.pdf}
    \vspace{-0.6cm}
    \caption{Illustration of the Lyapunov condition in \eqref{eq: optdelta} for 100 random samples $x \in B_{r_1}(0)$ with $d \sim U(-6\textrm{mm},6\textrm{mm})$. As shown, the Lyapunov condition is satisfied for the gait identified as being $\delta$-robust for $\delta = 6$mm with $\chi = 34$ (the corresponding ISS bound is illustrated in Fig. \ref{fig: issresults}).}
    \label{fig: lyapcondition}
    \vspace{-0.2cm}
\end{figure}

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{Figures/ISSResults.pdf}
    \vspace{-0.6cm}
    \caption{Verification of $\delta$-robustness for $\delta^* = 6$mm and $\chi^* = 34$ (selected based on the algorithm results shown in Fig. \ref{fig: algresults}). As shown in the figure, Gait 1 was not $\delta$-robust while Gait 2 was $\delta$-robust with $M$, $\gamma$, and $\alpha$ defined using the relationships derived in Theorem \ref{thm:main} and $V(x) = x^TPx$.}
    \label{fig: issresults}
    \vspace{-0.5cm}
\end{figure}

\new{
Since this optimization problem is bilinear and nonconvex, it is easier to approach algorithmically. Concretely, as outlined in Algorithm\footnote{The implementation of the algorithm, as well as its application towards evaluating the $\delta$-robustness of bipedal walking gaits, is provided in the repository: \url{https://github.com/maegant/deltaRobustness.git}} \ref{alg: optdelta}, this procedure consists of slowly increasing $\chi$ for each candidate $\delta$ and checking the Lyapunov condition in \eqref{eq: optdelta} for random samples $x \in B_{r_1}(0)$.
The advantage of this approach is that it is guaranteed to identify sets $\{\chi,\delta\}$ that certify $\delta$-robustness (assuming one exists and that $\Delta \chi$ is sufficiently small).} 
We demonstrate the algorithm for each of the two gaits illustrated in Fig. \ref{fig: motivation} with the results provided in Fig. \ref{fig: algresults}. As expected, the second gait illustrated in Fig. \ref{fig: motivation} and Fig. \ref{fig: exampleissbound} was verified to be $\delta$-robust, with $\delta^* = 6$mm. \new{Notably, this value is smaller than the 15mm ground heights empirically demonstrated in Fig. \ref{fig: motivation} due to the worst-case guarantees afforded by ISS.
% Using a probabilistic approach to ISS, \cite{culbertson2023input} yielded a more reasonable esimate of $\delta^* = 30$mm.
} A visualization of the Lyapunov condition for 100 random samples ($x \in B_{r_1}(0)$) is provided in Fig. \ref{fig: lyapcondition} with the corresponding ISS bound in Fig. \ref{fig: issresults}. 


\begin{figure}[tb]
\vspace{-5mm}
\centering
\begin{algorithm}[H]
\scriptsize
\caption{Algorithmic Approach to \eqref{eq: optdelta}}\label{alg: optdelta}
\begin{algorithmic}[1]
% {$\delta > 0$, $d^-_{\delta} := \inf\{h(x) \mid \B_{\delta}(x^*)\}$, $d^+_{\delta} := \sup\{h(x) \mid \B_{\delta}(x^*)\}$}
\STATE $\delta = 0$, $\chi_0 = 1$, $N$ = num. samples, $\{\Delta \delta, \Delta \chi, \chi_{\max}\} \in \R_{>0}$
\PROCEDURE{TestDelta}{$\delta$, $\chi_{\delta}$}
\FOR {$i = [1,\dots,N]$}
\STATE Sample $x' = x - x^*$ such that $\|x'\| = \chi_{\delta} \delta $
\IF {$V(\P(x',d)) - V(x') \leq -k\|x'\|^2, ~\forall d \in [-\delta,\delta]$}
    \STATE Repeat TestDelta($\delta + \Delta\delta$,$1$) 
\ELSE
    \IF {$\chi_{\delta} + \Delta \chi > \chi_{\max}$}
        \STATE Terminate with $\delta^* = \delta-\Delta\delta$, $\chi^* = \chi_{\delta^*}$
    \ELSE 
        \STATE Repeat TestDelta($\delta$,$\chi_{\delta} + \Delta\chi$)
    \ENDIF
\ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}
\vspace{-10mm}
\end{figure}








% ---------------------------------------------
\begin{comment}
\textcolor{red}{Maegan: I think the optimization problem in \eqref{eq: optdelta} lends itself easier to be put into an algorithm.  In particular, you could perhaps simplify to only checking equality on with $r_1$: 
\begin{align}
    \label{eq: optdeltaguess}
    (\delta^*,\chi^*) = \argmax_{\delta, \chi > 0} & ~ \delta \\
    \text{s.t. }  & V(\P(x,d)) - V(x)  \leq - \|  x   \|^2  \notag \\
                  & \quad \forall \| x \| = \chi \delta, \quad \forall  d \in [-\delta,\delta] \notag
\end{align}
This, of course, becomes only an optimization problem of $\delta$ if you set $\chi = 1$:
\begin{align}
    \label{eq: optdeltaguess2}
    \delta^* = \argmax_{\delta  > 0} & ~ \delta \\
    \text{s.t. }  & V(\P(x,d)) - V(x)  \leq - \|  x   \|^2  \notag \\
                  & \quad \forall \| x \| =  \delta, \quad \forall  d \in [-\delta,\delta] \notag
\end{align}
although I am not sure if this is reasonable---we might need $\chi$ to scale $x$ relative to the disturbances. 
}
\end{comment}




% \newsec{Optimization Problem Old}  Given $\delta > 0$, let: 
% $$
% r(\delta) := \max\{ r \geq 0 ~ | ~ \Omega_r \subset S_{[-\delta,\delta]}\}
% $$
% where here $\Omega_r = \{ x \in \R^n | V(x) \leq r\}$ is the Lyapunov level set of $V(x) = x^T P x$.  Then with the goal of finding the largest $\delta^* > 0$ such that $\O$ is $\delta$ robust, we formulate the following optimization problem: 
% \begin{align}
%     \label{eq: optold}
%     \delta^* = \argmax_{\delta > 0} & ~ \delta \\
%     \text{s.t. }  & V(\P(x,d)) - V(x)  \leq - \|  x   \|^2  + \frac{1}{2} |d|^2  \notag \\
%                   & \quad \forall x \in \Omega_{r(\delta)}, \quad  d \in [-\delta,\delta] \notag
% \end{align}
% where here we take $Q = I$ (wherein $\lambda_{\min}(Q) = 1$) and $\sigma = 1$ to remove decision variables. 
% %We can, moreover, take $Q = I$ wherein $\lambda_{\min}(Q) = 1$.
% Finally, note that implicit in this formulation is that $\P(x,d)$ is well defined for all $x \in \Omega_{r(\delta)}$ and $d \in [-\delta,\delta]$, wherein it follows that $\Omega_{r(\delta)} \subset B_{\rho}(0)$.  




% Then begin by considering a function $V : \R^n \to \R$ satisfying: 
% $$
% k_1 \| x - x^* \|^2 \leq V(x) \leq k_2 \| x - x^*  \|^2, 
% $$
% for $k_1,k_2 > 0$.  Than to 
