{
    "arxiv_id": "2303.08011",
    "paper_title": "Large-scale statistical forecasting models reassess the unpredictability of chaotic systems",
    "authors": [
        "William Gilpin"
    ],
    "submission_date": "2023-03-13",
    "revised_dates": [
        "2023-04-28"
    ],
    "latest_version": 2,
    "categories": [
        "cs.LG",
        "physics.comp-ph"
    ],
    "abstract": "Chaos and unpredictability are often considered synonymous, yet recent advances in statistical forecasting suggest that large machine learning models gain unexpected insight from extended observation of complex systems. We perform a large-scale comparison of 24 state-of-the-art multivariate forecasting methods on a crowdsourced database of 135 distinct low-dimensional chaotic systems. Large, domain-agnostic time series forecasting methods consistently exhibit the strongest performance, producing accurate predictions lasting up to two dozen Lyapunov times. The best-performing models contain no inductive biases for dynamical systems, and include hierarchical neural basis functions, transformers, and recurrent neural networks. However, physics-based hybrid methods like neural ordinary differential equations and reservoir computers perform more strongly in data-limited settings. Diverse forecasting methods correlate despite their widely-varying architectures, yet the Lyapunov exponent fails to fully explain variation in the predictability of different chaotic systems over long time horizons. Our results show that a key advantage of modern forecasting methods stems not from their architectural details, but rather from their capacity to learn the large-scale structure of chaotic attractors.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.08011v1",
        "http://arxiv.org/pdf/2303.08011v2"
    ],
    "publication_venue": "5 pages, 3 figures"
}