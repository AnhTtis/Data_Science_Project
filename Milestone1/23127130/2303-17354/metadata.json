{
    "arxiv_id": "2303.17354",
    "paper_title": "ISSTAD: Incremental Self-Supervised Learning Based on Transformer for Anomaly Detection and Localization",
    "authors": [
        "Wenping Jin",
        "Fei Guo",
        "Li Zhu"
    ],
    "submission_date": "2023-03-30",
    "revised_dates": [
        "2023-04-17"
    ],
    "latest_version": 3,
    "categories": [
        "cs.CV",
        "cs.LG"
    ],
    "abstract": "In the realm of machine learning, the study of anomaly detection and localization within image data has gained substantial traction, particularly for practical applications such as industrial defect detection. While the majority of existing methods predominantly use Convolutional Neural Networks (CNN) as their primary network architecture, we introduce a novel approach based on the Transformer backbone network. Our method employs a two-stage incremental learning strategy. During the first stage, we train a Masked Autoencoder (MAE) model solely on normal images. In the subsequent stage, we apply pixel-level data augmentation techniques to generate corrupted normal images and their corresponding pixel labels. This process allows the model to learn how to repair corrupted regions and classify the status of each pixel. Ultimately, the model generates a pixel reconstruction error matrix and a pixel anomaly probability matrix. These matrices are then combined to produce an anomaly scoring matrix that effectively detects abnormal regions. When benchmarked against several state-of-the-art CNN-based methods, our approach exhibits superior performance on the MVTec AD dataset, achieving an impressive 97.6% AUC.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17354v1",
        "http://arxiv.org/pdf/2303.17354v2",
        "http://arxiv.org/pdf/2303.17354v3"
    ],
    "publication_venue": null
}