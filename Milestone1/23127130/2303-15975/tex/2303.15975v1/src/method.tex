\section{Method}
\label{sec:method}

\noindent\textbf{Problem Formulation.} As illustrated in Fig.~\ref{fig:setting_comparison}d, a \newsetting model is trained continuously over $T$ sequential \ncd tasks, each of which presents an unlabelled data set $\data\tst = \{\vx\tst_i\}^{N\tst}_{i=1}$ with $N\tst$ instances containing $\classes\tst$ novel classes that correspond to a label set $\Y\tst$. As in prior works~\cite{troisemaine2023novel}, we assume that novel classes in $\data\tsi$ and $\data\tsj$ are disjoint, \ie, $\Y\tsi \cap \Y\tsj = \emptyset$. During each discovery step $t$, we only have access to $\data\tst$. The aim of \newsetting is to discover semantically meaningful categories in $\data\tst$ and accurately group the instances into the discovered clusters, without compromising its performance on the instances from $\data\tsone$ to $\data\tstminus$. In other words, a \newsetting model comprises a unified mapping function $f \colon \X \to \bigcup_{t=1}^{T} \Y\tst$ that can group any test image $\vx$ into the categories $\bigcup_{t=1}^{T} \Y\tst$ discovered from the unlabelled task sequence $\taskb=\{\task\tsone, \task\tstwo, \cdots, \task\tsend\}$ without the help of task-id (or task agnostic inference).

\noindent

\subsection{Overall Framework}
\label{sec:method_overall_framework}


In this work our goal is to address \newsetting by leveraging the Large-scale Pre-trained models (LsPt). To this end we propose two strong baselines, namely \ours and \ourspp that internally use the LsPt. The \ours and \ourspp are marked by two training steps, which are described below.  

\noindent
\textbf{Discovery Step.}
In the first discovery task $\task\tsone$ (see pink box in Fig.~\ref{fig:method_framework}), we learn a mapping function $f\tsone \colon \X\tsone \to \Y\tsone$ in a self-supervised manner (\ie, using the Sinkhorn-Knopp cross-view pseudo-labelling~\cite{Caron2020UnsupervisedLO}) to discover the $\classes\tsone$ categories contained in the given unlabelled data set $\data\tsone$. The mapping function $f\tsone$ is modeled by a \textit{frozen} feature extractor $g(\cdot)$ and a \textit{\cosnormed} linear layer $h\tsone(\cdot)$ as task-specific classifier. $g(\cdot)$ is initialized by the self-supervised large-scale pre-trained weights $\theta_{g}$~\cite{Caron2021EmergingPI}, while $h\tsone(\cdot)$ is randomly initialized.
In order to fully take advantage of the stable feature extractor, \ourspp additionally uses the learned model $f\tsone = h\tsone \circ g$ to compute pseudo per-class feature prototypes $\protomean_{\hat{c}\tsone}$ and the variances $\protovar_{\hat{c}\tsone}$ as \textit{proxies} for the novel classes in the current dataset $\data\tsone$ for future incremental steps.
 
\noindent
\textbf{Incremental Discovery Step.}
After the first discovery step, $\data\tsone$ is discarded, and access to only $\data\tstwo$ is given in the first incremental discovery step $\task\tstwo$ (see see blue box Fig.~\ref{fig:method_framework}). Same as the first step, we train a task-specific mapping function modeled by $f\tstwo = h\tstwo \circ g$. $h\tstwo$ is newly initialized for the $\classes\tstwo$ novel classes of $\data\tstwo$, while the \textit{frozen} $g$ is shared across tasks. Thanks to the \textit{frozen} feature extractor and \textit{\compcntitle} (\compcn), \ours easily forms a unified model $f\tstotwo = h\tstotwo \circ g$ by sharing the feature extractor $g$, and concatenating the two task-specific heads $h\tstotwo(\cdot) = h\tsone(\cdot) \oplus h\tstwo(\cdot)$ for task-agnostic inference. 

Furthermore, to improve the cross-task class-discrimination capability of the unified model, our \ourspp replays the features of the $\classes\tsone$ discovered classes sampled from Gaussian distributions, which uses the stored $\protomean_{\hat{c}\tsone}$ and $\protovar_{\hat{c}\tsone}$, to fine-tune $h\tstotwo(\cdot)$. We call this simplified replay mechanism as \textit{\compfrtitle} (\compfr). Lastly, $\protomean_{\hat{c}\tstwo}$ and $\protovar_{\hat{c}\tstwo}$ are again computed and stored for future steps. For further incremental steps ($t > 2$), the same training steps are repeated, in the same order as described.

\noindent
\textbf{Task-agnostic Inference.} After training, the inference on the test samples, belonging to any class presented in $\taskb$, is carried out with the final unified model $f\tstot = h\tstot \circ g$ in a task-agnostic manner (see see green box Fig.~\ref{fig:method_framework}).

\begin{figure}[!t]
\begin{center}
\includegraphics[width=\linewidth]{fig/framework_vert.pdf}
\end{center}
\vspace{-4mm}
\caption{Overview framework of our methods. In \textbf{discovery step (pink box)}, \ours discovers the novel classes contained in $\data\tsone$ with a clustering objective ($\mathcal{L}_\mathrm{baseline}$). Pseudo per-class prototypes are computed and stored. In \textbf{incremental discovery step (blue box)}, \ours conducts the same discovery training, after which \textbf{task-agnostic inference (green box)} is performed by simply concatenating the two learned task-specific classifiers. \ourspp further fine-tunes the concatenated classifier with $\mathcal{L}_\mathrm{past}$ and $\mathcal{L}_\mathrm{current}$ to strength class-discrimination among tasks.}
\label{fig:method_framework}
\vspace{-5mm}
\end{figure}

\subsection{Why Use Large-scale Pre-trained Models?}
Before delving into the specifics of our method, we first validate the benefits of leveraging Large-scale Pre-trained models (LsPt) for \ncd, where supervised pre-training is the standard practice. Specifically, we conduct experiments with our \ours method under traditional \ncd setting and splits~\cite{fini2021unified} on three benchmarks~\cite{krizhevsky2009learning,wah2011caltech}, comparing three pre-training strategies: (i) supervised pre-training on the base set from scratch (as in Fig.~\ref{fig:setting_comparison}b), (ii) large-scale pre-trained initialization only (\eg, DINO~\cite{Caron2021EmergingPI}, a \textit{self-supervised} model), (iii) large-scale pre-trained initialization and supervised fine-tuning. In Tab.~\ref{tab:ncd_pretraining} we can see that the LsPt-DINO, a model trained without any supervision, performs significantly better in discovering novel classes compared to the supervised counterpart, which is trained on the highly related base classes. Additionally, fine-tuning LsPt-DINO on the labelled base classes only gives limited accuracy gain, with the LsPt-DINO performing reasonably at-par. Guided by these observations, we propose using strong~\cite{Dosovitskiy2020AnII} LsPt models (\eg, DINO~\cite{Caron2021EmergingPI}) as a new starting point for \ncd, eliminating the dependence on the labelled data.

\begin{table}[!t]
\small
\renewcommand{\arraystretch}{0.8}
\begin{center}
\resizebox{\columnwidth}{!}{%
    \begin{tabular}{lcccc}
        \toprule
        \multirow{2}{*}{Pre-training} & CIFAR-10 & CIFAR-100 & CUB-200 & \multirow{2}{*}{Avg.}\\
        & (5-5) & (50-50) & (100-100)&\\
        \hline
        Supervised & 82.1 & 32.4 & 12.8 & 42.4\\
        LsPt-DINO & \textbf{95.0} & 65.6 & 36.1 & 65.6\\
        LsPt-DINO + Supervised & 94.5 & \textbf{67.2} & \textbf{42.5} & \textbf{68.1}\\
     \bottomrule
    \end{tabular}
}
\end{center}
\vspace{-3mm}
\caption{Analysis of novel class discovery accuracy of using the same backbone (\vitbsixteen) with different pre-training settings.}
\label{tab:ncd_pretraining}
\vspace{-5mm}
\end{table}

\subsection{Strong Baselines for MSc-iNCD}
\label{sec:method_discovery}
In this section we describe in detail the two proposed baselines, \ours and \ourspp, for solving the \newsetting task. Both the baselines use LsPt models, as backbone, that are general purpose and publicly available. Additionally, the \ourspp uses latent feature replay. Both the baselines have been designed to preserve stability on the \textit{past} novel classes, while being flexible enough to discover the \textit{current} novel classes.

\vspace{-.05in}
\begin{tcolorbox}[colback=gray!30,halign=center,valign=center,height=0.2in]
\textbf{Baseline}
\end{tcolorbox}
\vspace{-.05in}

\noindent
\textbf{Self-supervised Training for Discovery.} Starting from a frozen feature extractor $g$, initialized with the weights from DINO~\cite{Caron2021EmergingPI}, we optimize a \textit{self-supervised} clustering objective to directly discover the novel categories at each step. In details, first a learnable linear layer $h\tst$ is randomly initialized as the task-specific classifier for the $\classes\tst$ novel classes contained in the unlabelled set $\data\tst$. Following the \ncd literature, we assume the number of novel classes $\classes\tst$ at each step is known as \textit{a-priori}. To learn the task-specific network $f\tst$ for discovery, \ours employs the Sinkhorn-Knopp cross-view pseudo-labeling algorithm~\cite{Caron2020UnsupervisedLO}. In details we optimize the following \textit{swapped} prediction problem, where the `code' $\vy_1$ of one view is computed from the representation of another view $\vz_2$, derived from the same image $\vx$, and vice-versa:

\vspace{-2mm}
\begin{equation}
\small
    \mathcal{L}_{\ours}= \ell(h\tst(\vz_2), \vy_1) + \ell(h\tst(\vz_1), \vy_2)
    ,
\label{eqn:ce}
\end{equation}
where $\ell(\cdot, \cdot)$ is the standard cross-entropy loss. The codes (or \textit{soft-targets}) $\vy_1$ and $\vy_2$ are obtained by using the \sinkhorn algorithm. 
Note that, we freeze the entire feature extractor $g$ during optimizing $\mathcal{L}_\ours$ as a straightforward way to prevent future forgetting.

\noindent
\textbf{Multi-step Class-Incremental Discovery.} Our ultimate goal is to learn a unified mapping function $f\tstoend \colon \X \to \bigcup_{t=1}^{T} \Y\tst$. If all the training data are available, an ideal clustering objective for $f\tstoend$ can be achieved by minimizing an adequate loss $\mathcal{L}\tstoend$ at the end of the task sequence:
\begin{equation}
\small
\label{eqn:ideal}
    \mathcal{L}\tstoend =
    \E_{\task\tst\sim\taskb}
    \mathcal{L}\tst.
\end{equation}
However, due to the data unavailability of past tasks in \newsetting, we can only pursue an approximation of this ideal joint objective defined by Eq.~\ref{eqn:ideal}. In this work, unlike most of the \il solutions~\cite{wang2023comprehensive}, we pursue a better approximation from a new perspective: balancing the individual clustering objectives in each task to a unified importance. To be more specific, the proposed \ours adopts \textit{frozen feature extractor} with \textit{cosine normalized classifier} to unify the clustering objectives across tasks.

\noindent\textit{\textbf{Frozen Feature Extractor.}} In \ours we freeze the entire large-scale initialized feature extractor $g$ by introducing $\Vert \theta_{g}\tst - \theta_{g}\tstminus \Vert^{2} = 0$, $ t \in \{1, \ldots, T\}$ as a constraint. This enables to leverage the power of the large-scale pre-trained $g$ by all tasks, without  introducing bias towards any particular task, \textit{i.e.}, \textit{model drift} issue in \il literature~\cite{wu2022class}.

\noindent\textit{\textbf{Cosine Normalization.}} The frozen feature extractor not only preserves the powerful prior knowledge from the large-scale data, but also maintains the cooperative mechanism between $g$ and each individual classifier $h\tst$. Having the stable cooperative mechanism, the test data can be directly routed to the corresponding task-specific function network $f=h\tst \circ g$, if the task-id $t$ is available. However, task-id is not allowed in \newsetting. To achieve simple task-agnostic inference, we propose to apply \textit{\compcntitle} (\compcn)~\cite{Luo2017CosineNU, Hou2019LearningAU} on each individual linear classifier $h\tst$. This enables the learned weight vectors to output scores of the same scale, avoiding significant imbalance between the past and current novel classes. 

Formally, given an input vector $\vx$, the L2 normalization operation can be defined as $\widetilde{\vx} = L2Norm(\vx) = \nicefrac{\vx}{\Vert \vx \Vert} = \nicefrac{\vx}{\sqrt{\vx\vx^{T} + \epsilon}}$, where $\epsilon$ is a small value to avoid division by zero and is set to 1e$^{-12}$ in this work.
At every discovery step, $L2Norm(\cdot)$ is continuously applied to both the input feature embedding $\vz$ and each weight vector $\theta_{h}^{i}$ of the task-specific linear classifier $h\tst$. $\theta_{h}^{i} \in \R^{k}$ is the $i$-th column of the classifier weight matrix $\theta_{h}$, corresponding to one semantic cluster. Consequently, the $i$-th output logit from the classifier is then computed as:
\begin{equation}
\small
\label{eqn:normlogits}
    \vl^{i} = \widetilde{\theta}_{h}^{i T} \widetilde{\vz} = \frac{\theta_{h}^{i T} \vz}{\Vert \theta_{h}^{i} \Vert \Vert \vz \Vert} = cos(\theta_{h}^{i}),
\end{equation}
where $\Vert \theta_{h\tst}^{i} \Vert = \Vert \vz \Vert = 1$ and $cos(\theta_{h\tst}^{i})$ is the cosine similarity between the feature vector $\vz$ and the $i$-th weight vector $\theta_{h\tst}^{i}$. We thus use the term \textit{\compcn} for this operation.
The magnitude of the output logits $\vl$ is thereby unified to the same scale $[-1,1]$ for all classifiers from different step.

\noindent
\textbf{Task-agnostic Inference.} Having the balanced classifier weights, we can then build a unified classification head $h\tstoend$ by simply concatenating the task-specific heads learned at each step $h\tstoend = h\tsone \oplus h\tstwo \oplus \ldots \oplus h\tsend$. By means of the frozen feature extractor and feature normalization, all the feature embedding $\widetilde{\vz}$ are mapped to the uniform feature space under the same scale. Incorporating with the normalized classifier weights in $h\tstoend$, task-agnostic inference can be fairly achieved using $f\tstoend=h\tstoend \circ g$ for all the discovered classes so far.

\vspace{-.05in}
\begin{tcolorbox}[colback=gray!30,halign=center,valign=center,height=0.2in]
\textbf{Baseline++}
\end{tcolorbox}
\vspace{-.05in}

\noindent
\textbf{Knowledge Transfer with Robust Feature Replay.} To fully leverage the stability offered by the frozen feature extractor, \ourspp further incorporates the Knowledge Transfer with Robust Feature Replay (\compfr) strategy to jointly optimize the concatenated classifier $h\tstoend$ with the replayed feature prototypes. To recall, at each previous discovery step $t \in \{1, \ldots, T-1\}$, \ourspp computes and stores a set $\Mu\tst = \{\mathcal{N}(\protomean_{\hat{c}_{j}\tst}, \protovar_{\hat{c}_{j}\tst})\}_{j=1}^{\classes\tst}$ that contains pseudo per-class feature prototype distributions derived from the unlabelled set $\data\tst$. Here, $\protomean_{\hat{c}_{j}\tst}$ and $\protovar_{\hat{c}_{j}\tst}$ are the calculated mean and variance of the feature embedding predicted by the task-specific model $f\tst$ as pseudo class $\hat{c}_{j}\tst$. Since the feature prototype set $\Mu\tst$ can represent and simulate the novel classes discovered at each previous step, \ourspp can further train the concatenated model $f\tstoend=h\tstoend \circ g$ by replaying the per-class features sampled from the saved Gaussian distributions in $\{\Mu\tsone, \ldots, \Mu\tstminuscap\}$ with the objective defined as:
\begin{equation}
\small
\label{eqn:loss_past}
    \begin{split} \mathcal{L}_\mathrm{past}=&- \E_{\Mu\tst \sim \Mu\tstoendminusone}\E_{(\vz^{\hat{c}\tst}, \hat{\vy}^{\hat{c}\tst}) \sim \mathcal{N}(\protomean_{c\tst}, \protovar_{c\tst})}\\
    &\sum_{j=1}^{\classes\tst}\hat{\vy}^{\hat{c}_{j}\tst} \log \sigma(\frac{h\tstoend(\vz^{\hat{c}_{j}\tst})}{\tau}),
    \end{split}
\end{equation}
where, $\sigma (\cdot)$ is a softmax function and $\tau$ is the temperature. By optimizing the objective defined in Eq.~\ref{eqn:loss_past}, \ourspp can better approximate the ideal objective defined in Eq.~\ref{eqn:ideal} by simulating the past data distribution. Furthermore, to maintain the clustering performance for the current novel classes in $\data\tsend$, we also transfer the knowledge from the current task-specific head $h\tsend$ to $h\tstoend$. In details, using the pseudo-labels $\hat{\vy}_{i}\tsend$ computed by the learned $f\tsend$, we can build a pseudo-labelled data set $\data_{PL}\tsend = \{\vx_{i}\tsend, \hat{\vy}_{i}\tsend\}_{i=1}^{N\tsend}$. The task-specific knowledge stored in the pseudo-labels can be then transferred to the unified classifier by optimizing the following objective:
\begin{equation}
\small
\label{eqn:loss_now}
\begin{split}
\mathcal{L}_\mathrm{current}=&-\E_{(\vx\tsend, \hat{\vy}\tsend) \sim \data_{PL}\tsend}
    \sum^{C\tsend}_{j=1} \hat{y}_{j}^{c\tsend} \log \sigma(\frac{h\tstoend(g(\vx^{c\tsend}))}{\tau}).
\end{split}
\end{equation}
The final \textit{past-current} objective for \compfr training at step $T$ of \ourspp is formulated as:
\begin{equation}
\small
\label{eqn:loss_all}
    \mathcal{L}_\mathrm{\ourspp} = \mathcal{L}_\mathrm{past} + \mathcal{L}_\mathrm{current}.
\end{equation}