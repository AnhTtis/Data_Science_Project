\section{Implementation Details.}
\label{sec:app-impl-det}
In this section, we present the implementation details of image pre-processing and data augmentation, our baselines, and the adapted methods for \cincd. In Sec.~\ref{sec:supp_dataaug}, the employed image pre-processing technique and data augmentation for the experiments are elaborated. Sec.~\ref{sec:supp_ours} offers an in-depth account of the training and inference processes for our \ours and \ourspp using Pytorch-like pseudo-code. Subsequently, Sec.~\ref{sec:supp_bounds} explores the development of the reference methods for the \cincd setting. Ultimately, the adaption specifics and hyperparameters for the compared methods originating from \incd and \il fields are described in Sec.~\ref{sec:supp_incd} and Sec.~\ref{sec:supp_il}, correspondingly.

In order to maintain equitable evaluation, all methods examined in this work use the same \vitbsixteen~\cite{Dosovitskiy2020AnII} backbone, as employed by our \ours and \ourspp.

\subsection{Image Pre-processing and Data Augmentation}
\label{sec:supp_dataaug}
In order to utilize the publicly accessible pre-trained DINO-\vitbsixteen, it is necessary to adjust the input images to a fixed resolution of 224 $\times$ 224. In accordance with~\cite{Vaze2022GeneralizedCD}, the input images are initially upsampled to a resolution of 224 $\times$ 224 / 0.875 employing trilinear interpolation, followed by a center-crop of the upsampled images to achieve a 224 $\times$ 224 resolution for all the experiments. Subsequent to the aforementioned pre-processing procedure, SimCLR-like~\cite{Chen2020ASF} stochastic augmentations are predominantly employed throughout the experiments for all the methods.

\subsection{Simple yet Strong Baselines for \cincd}
\label{sec:supp_ours}
In the present section, a thorough exposition of the training and inference procedures for both \ours and \ourspp is provided, accompanied by Pytorch-like pseudo-code, to effectively demonstrate the simplicity of our methods.

\begin{algorithm}[!h]
\caption{Pseudo-code of our \ours training for the discovery task $\task\tst$ in a PyTorch-like style.}
\label{alg:ours_train}
% \algcomment{\fontsize{7.2pt}{0em}\selectfont \texttt{bmm}: batch matrix multiplication; \texttt{mm}: matrix multiplication; \texttt{cat}: concatenation.
% %\vspace{-1.em}
% }
\definecolor{codeblue}{rgb}{0.25,0.5,0.8}
\lstset{
  backgroundcolor=\color{white},
  basicstyle=\fontsize{7.2pt}{7.2pt}\ttfamily\selectfont,
  columns=fullflexible,
  breaklines=true,
  captionpos=b,
  commentstyle=\fontsize{7.2pt}{7.2pt}\color{codeblue},
  keywordstyle=\fontsize{7.2pt}{7.2pt},
%  frame=tb,
}
\begin{lstlisting}[language=python]
# g: frozen ViT-B/16 encoder network initialized by DINO weights, output 768-dimensional embedding
# h_t: task-specific linear classifier with randomly initialized weights
# temp: temperature
# C_t: number of novel classes present in task t

for x in train_loader:    # load a minibatch x with N samples
    x1 = aug(x)     # randomly augmented view 1
    x2 = aug(x)     # randomly augmented view 2

    # normalize weights
    with torch.no_grad():
        # temporarily store the weight vectors: C_tx768
        w_temp = h_t.linear_layer.weight.data.clone()
        w_temp = normalize(w_temp, dim=1, p=2)
        h_t.linear_layer.weight.copy_(w_temp)

    # extract feature embeddings
    z1 = g.forward(x1)      # Nx768
    z2 = g.forward(x2)      # Nx768

    # output logits
    l1 = h_t.forward(z1)    # NxC_t
    l2 = h_t.forward(z2)    # NxC_t

    # generate pseudo labels
    y1 = sinkhorn(l1)       # NxC_t
    y2 = sinkhorn(l2)       # NxC_t

    # swap prediction problem of the two views
    # cross-entropy loss, Eq.1
    loss1 = CrossEntropyLoss(l1/temp, y2)
    loss2 = CrossEntropyLoss(l2/temp, y1)
    loss = loss1 + loss2

    # SGD update: task-specific classifier
    loss.backward()
    update(h_t.params)
\end{lstlisting}
\end{algorithm}

\noindent
\textbf{Discovery Training.} Algo.~\ref{alg:ours_train} presents the pseudo-code for the shared discovery training loop employed by our \ours and \ourspp. For each unlabelled sample $\vx$, we generate two views of $\vx$ by applying the stochastic transformation delineated in Sec.~\ref{sec:supp_dataaug}. Prior to forwarding the input to the model, we perform cosine normalization on the task-specific classifier $h\tst$ through L2 normalization of the weight matrix $\theta_{h\tst}$ (feature-level L2 normalization is performed in $h\tst$). Subsequently, the two views are sequentially input into the frozen feature extractor $g$ and classifier $h\tst$ to produce the output logits. To optimize the objective defined in Eq.1 for the \textit{swapped} prediction problem, the \sinkhorn~\cite{Caron2020UnsupervisedLO} algorithm is employed to generate the pseudo-labels for the two views as soft-targets that are sawpped. The temperature parameter is set at 0.1. A total of 200 epochs of training are conducted for the discovery of both \ours and \ourspp.

\noindent
\textbf{Task-agnostic Inference.} After the discovery step for task $\task\tst$, our \ours can execute task-agnostic inference by simply concatenating the newly learned task-specific classifier $h\tst$ with the previous unified classifier $h\tstotminus$ to form a new unified classifier $h\tstot$, as described in Algo.~\ref{alg:ours_inference}.

\begin{algorithm}[!h]
\caption{Pseudo-code of our \ours inference for the task sequence $\taskb=\{\task\tsone, \task\tstwo, \cdots, \task\tsend\}$ in a PyTorch-like style.}
\label{alg:ours_inference}
% \algcomment{\fontsize{7.2pt}{0em}\selectfont \texttt{bmm}: batch matrix multiplication; \texttt{mm}: matrix multiplication; \texttt{cat}: concatenation.
% %\vspace{-1.em}
% }
\definecolor{codeblue}{rgb}{0.25,0.5,0.8}
\lstset{
  backgroundcolor=\color{white},
  basicstyle=\fontsize{7.2pt}{7.2pt}\ttfamily\selectfont,
  columns=fullflexible,
  breaklines=true,
  captionpos=b,
  commentstyle=\fontsize{7.2pt}{7.2pt}\color{codeblue},
  keywordstyle=\fontsize{7.2pt}{7.2pt},
%  frame=tb,
}
\begin{lstlisting}[language=python]
# g: frozen ViT-B/16 encoder network initialized by DINO weights, output 768-dimensional embedding
# h_prev: unifeid classifier saved for the previous tasks (t=1, ..., t=t-1)
# h_t: newly learned task-specific classifier for task t
# h_tot: unified classifier for all the tasks seen so far (t=1, ..., t=t)
# C_tot: total number of novel classes discovered until task t.

# concatenate classifiers
h_tot = cat([h_prev, h_t], dim=0)     # C_totx768

# perform task-agnostic inference
for x in test_loader:    # load a minibatch x with N samples
    # extract feature embeddings
    z = g.forward(x)        # Nx768

    # output logits
    l = h_tot.forward(z)    # NxC_tot

    # take the cluster-id with maximum logit value as prediction
    prediction = max(l, dim=1)   # N
\end{lstlisting}
\end{algorithm}

\noindent
\textbf{\compfr Training.} As expounded in the primary manuscript, our \ourspp incorporates \textit{\compfrlong} (\compfr) training to jointly optimize the concatenated classifier $h\tstot$ further. Algo.~\ref{alg:ourspp_train} describes the \compfr training loop specifics. For each unlabelled sample $\vx$, the same stochastic transformation (see Sec.~\ref{sec:supp_dataaug}) is employed to generate two views of $\vx$. The \textit{cosine normalization} operation is applied to the unified classifier before forward propagation to maintain the weight vectors on the same scale. Subsequently, generative pseudo feature replay is utilized to replay an equal number of past feature embeddings from the preserved pseudo per-class prototype Gaussian distributions $\Mu$ as the current mini-batch size. The loss, as defined in Eq. 4 for past novel classes, is calculated using the output logits of the replayed embeddings from $h\tstot$. To also preserve the discriminative capability for current novel classes, knowledge is transferred from $h\tst$ to $h\tstot$ using the pseudo-labels generated by $h\tst$ for the two views. The loss, as defined in Eq. 5 for the current novel classes, is then computed using the output logits of the two views' embeddings from $h\tstot$ and the pseudo-labels. The ultimate \textit{past-current} objective (refer to Eq. 6) for \ourspp training is optimized by aggregating the two individual losses to update the parameters $\theta_{h\tstot}$ of the unified classifier $h\tstot$.

\begin{algorithm}[!h]
\caption{Pseudo-code of the \compfr training in \ourspp during task $\task\tsend$ in a PyTorch-like style.}
\label{alg:ourspp_train}
% \algcomment{\fontsize{7.2pt}{0em}\selectfont \texttt{bmm}: batch matrix multiplication; \texttt{mm}: matrix multiplication; \texttt{cat}: concatenation.
% %\vspace{-1.em}
% }
\definecolor{codeblue}{rgb}{0.25,0.5,0.8}
\lstset{
  backgroundcolor=\color{white},
  basicstyle=\fontsize{7.2pt}{7.2pt}\ttfamily\selectfont,
  columns=fullflexible,
  breaklines=true,
  captionpos=b,
  commentstyle=\fontsize{7.2pt}{7.2pt}\color{codeblue},
  keywordstyle=\fontsize{7.2pt}{7.2pt},
%  frame=tb,
}
\begin{lstlisting}[language=python]
# concatenate classifiers
h_tot = cat([h_prev, h_t], dim=0)     # C_totx768

# load a minibatch x with N samples
for x in train_loader:
    x1 = aug(x)     # randomly augmented view 1
    x2 = aug(x)     # randomly augmented view 2

    # normalize weights
    with torch.no_grad():
        # temporarily store the weight vectors: C_totx768
        w_temp = h_tot.linear_layer.weight.data.clone()
        w_temp = normalize(w_temp, dim=1, p=2)
        h_tot.linear_layer.weight.copy_(w_temp)

        
    # generatively replay saved prototypes fro past classes
    z_past, y_past = replay(M)  # Nx768, Nx1

    # output logits for past embeddings from unified classifier
    l_past = h_tot.forward(z_past)  # NxC_tot
    
    # cross-entropy loss for past classes, Eq.4
    loss_past = CrossEntropyLoss(l_past/temp, y_past)

    # extract feature embeddings
    z1 = g.forward(x1)      # Nx768
    z2 = g.forward(x2)      # Nx768

    # output logits
    l1 = h_T.forward(z1)    # NxC_t
    l2 = h_T.forward(z2)    # NxC_t

    # generate pseudo labels by using the task-specific classifier prediction
    y1 = max(l1, dim=1) + C_tot - C_t   # Nx1
    y2 = max(l2, dim=1) + C_tot - C_t   # Nx1

    # concatenate feature embeddings
    z_current = cat([z1, z2], dim=0)    # 2Nx768
    
    # concatenate pseudo labels
    y_current = cat([y1, y2], dim=0)    # 2Nx1

    # output logits for current embeddings from unified classifier
    l_now = h_tot.forward(z_current)    # 2NxC_tot
    
    # cross-entropy loss for current classes, Eq.5
    loss_current = CrossEntropyLoss(l_now/temp, y_current)
    
    # swap prediction problem of the two views
    # cross-entropy loss, Eq.6
    loss = l_past + loss_current

    # SGD update: task-specific classifier
    loss.backward()
    update(h_tot.params)
\end{lstlisting}
\vspace{+10mm}
\end{algorithm}

\subsection{Building Reference Methods}
\label{sec:supp_bounds}
Since there is no prior work has investigated \cincd setting, we build reference methods for the comparison in this work.

\noindent
\textbf{K-means~\cite{Arthur2007kmeansTA}.} We utilize the K-means algorithm to create a 'pseudo' \textit{lower-bound} reference. Specifically, we extract the 768-dimensional deep features $\vz \in \R^{768}$ of the given images using DINO-\vitbsixteen~\cite{Caron2021EmergingPI} as the feature extractor. Then, we perform K-means clustering on the $\vz$ extracted from the joint training datasets $\bigcup_{t=1}^{T} \data\tst$ to form $\bigcup_{t=1}^{T} \classes\tst$ semantic clusters at the end of a given task sequence. The maximum number of iterations is set to 300 for all the experiments. However, these \textit{lower-bound} results are only for reference as the K-means algorithm uses access to previous training data to form the clusters for task-agnostic evaluation and cannot accurately represent the minimum performance of \cincd.

\noindent
\textbf{Joint (frozen) and Joint (unfrozen).} In accordance with the supervised \cil practice~\cite{wang2023comprehensive}, we construct two \textit{upper-bound} reference methods. The first method, denoted as $\upperb$, performs joint training on the unified model $f\tstoend = h\tstoend \circ g$ of \ours after task-specific discovery training, utilizing all the training data $\bigcup_{t=1}^{T} \data\tst$ up to the current step. The second method, denoted as $\upperbpp$, further unfreezes the last transformer block during both the discovery and joint training of $\upperb$. Notably, $\upperbpp$ does not unfreeze the last block at the beginning of the training since we observe in experiments that saturating the classifier $h\tst$ first and then fine-tuning the last block of $g$ yields better performance.

\subsection{Adapting \incd Methods to \cincd}
\label{sec:supp_incd}

% In this section, we describe the implementation details of ResTune~\cite{liu2022residual} and FRoST~\cite{Roy2022ClassincrementalNC}, which are adapted to \cincd from \incd.
Since \cincd setting does not allow the use of any labelled data, we need to adapt the two compared \incd solutions, ResTune\footnote {\url{https://github.com/liuyudut/ResTune}}~\cite{liu2022residual} and FRoST\footnote {\url{https://github.com/OatmealLiu/class-iNCD}}~\cite{Roy2022ClassincrementalNC}, to work without the supervised pre-training on the labelled data. To accomplish this, we initialize the feature extractors $g(\cdot)$ of ResTune and FRoST with the same self-supervised pre-trained weights $\theta_{g}$ (DINO~\cite{Caron2021EmergingPI}), instead of using supervised pre-training on labelled data. This enables ResTune and FRoST to perform continuous novel class discovery under the \cincd setting with their own components to discover novel categoires and prevent forgetting.

\noindent
\textbf{ResTune} is an \incd solution that combines architecture-based and regularization-based \il techniques to prevent forgetting. ResTune grows a new block at each incremental step to learn new knowledge with a clustering objective~\cite{Xie2015UnsupervisedDE}, while adjusting the shared basic feature extractor for the new data under the regularization of a knowledge distillation objective~\cite{li2017learning}. The adapted ResTune in this work uses the first eleven transformer blocks of \vitbsixteen as the shared basic feature extractor, with only the last (11th) block unfrozen, while creating a new unfrozen transformer block branch initialized by DINO-weights to learn the residual feature at each step. The weight $\beta$ for the knowledge distillation objective is set to 1 for all the experiments, as in the original work.

\noindent
FRoST is a \cincd solution that combines regularization-based and rehearsal-based \il techniques to prevent forgetting, and it is based on ranking statistics~\cite{han2020automatically}. In this work, we strictly follow the configuration used in the original work~\cite{Roy2022ClassincrementalNC} for the hyperparameters. However, since there are no labels available in the \cincd setting, we adapt the supervised feature replay of FRoST to the unsupervised pseudo feature replay by using the same approach in \ourspp.

\subsection{Adapting \il Methods to \cincd}
\label{sec:supp_il}

% In this section, we describe the implementation details of EwC~\cite{kirkpatrick2017overcoming}, LwF~\cite{li2017learning}, and DER~\cite{buzzega2020dark}, which are adapted to \cincd from \il.
To evaluate the effectiveness of our proposed methods in preventing forgetting, we also compare their performance with that of traditional \il techniques. For this purpose, we adapt two regularization-based methods (EwC~\cite{kirkpatrick2017overcoming} and LwF~\cite{li2017learning}) and one rehearsal-based method (DER~\cite{buzzega2020dark}) to \cincd by using the publicly available \il framework codebase\footnote{\url{https://github.com/aimagelab/mammoth}}~\cite{buzzega2020dark,boschini2022class} in our experiments. However, unlike the \incd methods, these \il methods are originally designed for supervised settings and are not capable of discovering novel categories from unlabelled data. Therefore, we apply the same discovery strategy as our \ours to all the adapted \il methods. Specifically, we initialize the feature extractor $g$ with DINO~\cite{Caron2021EmergingPI} pre-trained weights and optimize the clustering objective defined in Eq.1 using the \sinkhorn cross-view pseudo-labelling algorithm~\cite{Caron2020UnsupervisedLO} to discover the novel classes contained in the given unlabelled data set $\data\tst$. Different from our \ours, we unfreeze the last transformer block of $g$ to adapt the model to the data present at each step in all the experiments. To prevent forgetting, we maintain the \il components in the original methods.

\noindent
\textbf{EwC} is a weight regularization \il method, which penalizes the model parameters selectively based on their importance for the past tasks using the calculated Fisher information matrix~\cite{kirkpatrick2017overcoming}. In the experiments, we set the hyperparameter $\lambda$ to 8000 to control the relative importance of past tasks compared to the new one, and the Fisher matrix fusion parameter $\alpha$ to 0.5.

\noindent
\textbf{LwF} is a function regularization \il solution that uses a knowledge distillation~\cite{Gou2020KnowledgeDA} objective function to prevent forgetting by constraining the current model output to not deviate too much from the old model~\cite{li2017learning}. In our experiments, we save the old model $f\tstotminus = h\tstotminus \circ g\tstminus$ to compute the LwF loss at each step $t$. The LwF loss weight $\lambda$, which determines the balance between the old and new tasks, is set to 1.0 for all experiments.

\noindent
\textbf{DER} is a rehearsal-based \il solution that involves storing a fixed-size buffer of old training samples with past model responses as proxies of old tasks to prevent forgetting~\cite{buzzega2020dark}. For our experiments, the adapted DER maintains a buffer of 500 old samples for each step, with the \textit{not-forgetting} loss weight $\alpha$ set to 0.5.