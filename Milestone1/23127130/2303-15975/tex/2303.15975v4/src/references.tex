\begin{thebibliography}{8}
% \bibitem{ref_article1}
% Author, F.: Article title. Journal \textbf{2}(5), 99--110 (2016)

% \bibitem{ref_lncs1}
% Author, F., Author, S.: Title of a proceedings paper. In: Editor,
% F., Editor, S. (eds.) CONFERENCE 2016, LNCS, vol. 9999, pp. 1--13.
% Springer, Heidelberg (2016). \doi{10.10007/1234567890}

% \bibitem{ref_book1}
% Author, F., Author, S., Author, T.: Book title. 2nd edn. Publisher,
% Location (1999)

% \bibitem{ref_proc1}
% Author, A.-B.: Contribution title. In: 9th International Proceedings
% on Proceedings, pp. 1--2. Publisher, Location (2010)

\bibitem{Arthur2007kmeansTA} Arthur, D., Vassilvitskii, S.: k-means++: the advantages of careful seeding. In: ACM-SIAM Symposium on Discrete Algorithms (2007)

\bibitem{Boschini2022TransferWF} Boschini, M., Bonicelli, L., Porrello, A., Bellitto, G., Pennisi, M., Palazzo, S., Spampinato, C., Calderara, S.: Transfer without forgetting. In: ECCV (2022)

\bibitem{buzzega2020dark} Buzzega, P., Boschini, M., Porrello, A., Abati, D., Calderara, S.: Dark experience for general continual learning: a strong, simple baseline. In: NeurIPS (2020)

\bibitem{Cao2021OpenWorldSL} Cao, K., Brbic, M., Leskovec, J.: Open-world semi-supervised learning. In: ArXiv (2021)

\bibitem{Caron2020UnsupervisedLO} Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., Joulin, A.: Unsupervised learning of visual features by contrasting cluster assignments. In: NeurIPS (2020)

\bibitem{Caron2021EmergingPI} Caron, M., Touvron, H., Misra, I., J’egou, H., Mairal, J., Bojanowski, P., Joulin, A.: Emerging properties in self-supervised vision transformers. In: ICCV (2021)

\bibitem{Chang2017DeepAI} Chang, J., Wang, L., Meng, G., Xiang, S., Pan, C.: Deep adaptive image clustering. ICCV (2017)

\bibitem{Chen2020ASF} Chen, T., Kornblith, S., Norouzi, M., Hinton, G.E.: A simple framework for contrastive learning of visual representations. In: ArXiv (2020)

\bibitem{Cuturi2013SinkhornDL} Cuturi, M.: Sinkhorn distances: Lightspeed computation of optimal transport. In: NeurIPS (2013)

\bibitem{Deng2009ImageNetAL} Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale hierarchical image database. In: CVPR (2009)

\bibitem{Dizaji2017DeepCV} Dizaji, K.G., Herandi, A., Deng, C., Cai, W.T., Huang, H.: Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization. In: ICCV (2017)

\bibitem{Dosovitskiy2020AnII} Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., Houlsby, N.: An image is worth 16x16 words: Transformers for image recognition at scale. In: ArXiv (2020)

\bibitem{Fei2022XConLW} Fei, Y., Zhao, Z., Yang, S.X., Zhao, B.: Xcon: Learning with experts for fine-grained category discovery. In: BMVC (2022)

\bibitem{Fini2021SelfSupervisedMA} Fini, E., Costa, V., Alameda-Pineda, X., Ricci, E., Karteek, A., Mairal, J.: Self-supervised models are continual learners. In: CVPR (2022)

\bibitem{fini2021unified} Fini, E., Sangineto, E., Lathuilière, S., Zhong, Z., Nabi, M., Ricci, E.: A unified objective for novel class discovery. In: ICCV (2021)

\bibitem{fomenko2022learning} Fomenko, V., Elezi, I., Ramanan, D., Leal-Taixé, L., Osep, A.: Learning to discover and detect objects. In: NeurIPS (2022)

\bibitem{French1999Catastrophic} French, R.: Catastrophic forgetting in connectionist networks. Trends in cognitive sciences (1999)

\bibitem{Han2019LearningTD} Han, K., Vedaldi, A., Zisserman, A.: Learning to discover novel visual categories via deep transfer clustering. In: ICCV (2019)

\bibitem{han2020automatically} Han, K., Rebuffi, S.A., Ehrhardt, S., Vedaldi, A., Zisserman, A.: Automatically discovering and learning new visual categories with ranking statistics. In: ICLR (2020)

\bibitem{He2015DeepRL} He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: CVPR (2015)

\bibitem{Hou2019LearningAU} Hou, S., Pan, X., Loy, C.C., Wang, Z., Lin, D.: Learning a unified classifier incrementally via rebalancing. In: CVPR (2019)

\bibitem{Hsu2017LearningTC} Hsu, Y.C., Lv, Z., Kira, Z.: Learning to cluster in order to transfer across domains and tasks. In: ArXiv (2017)

\bibitem{Hsu2019MulticlassCW} Hsu, Y.C., Lv, Z., Schlosser, J., Odom, P., Kira, Z.: Multi-class classification without multi-class labels. In: ArXiv (2019)

\bibitem{Jain2008DataC5} Jain, A.K.: Data clustering: 50 years beyond k-means. In: PRL (2008)

\bibitem{Jia2021JointRL} Jia, X., Han, K., Zhu, Y., Green, B.: Joint representation learning and novel category discovery on single- and multi-modal data. In: ICCV (2021)

\bibitem{Joseph2022NovelCD} Joseph, K.J., Paul, S., Aggarwal, G., Biswas, S., Rai, P., Han, K., Balasubramanian, V.N.: Novel class discovery without forgetting. In: ECCV (2022)

\bibitem{kirkpatrick2017overcoming} Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A.,
Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., Hassabis, D., Clopath, C., Kumaran, D., Hadsell, R.: Overcoming catastrophic forgetting in neural networks. Proceedings of the National Academy of Sciences (2016)

\bibitem{krizhevsky2009learning} Krizhevsky, A., Hinton, G., et al.: Learning multiple layers of features from tiny images (2009)

\bibitem{le2015tiny} Le, Y., Yang, X.: Tiny imagenet visual recognition challenge. CS 231N (2015)

\bibitem{li2017learning} Li, Z., Hoiem, D.: Learning without forgetting. In: TPAMI (2017)

\bibitem{lin2022continual} Lin, Z., Wang, Y., Lin, H.: Continual contrastive learning for image classification. In: 2022 IEEE International Conference on Multimedia and Expo (ICME) (2022)

\bibitem{liu2022residual} Liu, Y., Tuytelaars, T.: Residual tuning: Toward novel category discovery without labels. In: TNNLS (2022)

\bibitem{Luo2017CosineNU} Luo, C., Zhan, J., Wang, L., Yang, Q.: Cosine normalization: Using cosine similarity instead of dot product in neural networks. In: ArXiv (2017)

\bibitem{madaan2022representational} Madaan, D., Yoon, J., Li, Y., Liu, Y., Hwang, S.J.: Representational continuity for unsupervised continual learning. In: ICLR (2022), \url{https://openreview.net/forum?id=9Hrka5PA7LW}

\bibitem{masana2022class} Masana, M., Liu, X., Twardowski, B., Menta, M., Bagdanov, A.D., Van De Wei-jer, J.: Class-incremental learning: survey and performance evaluation on image classification. IEEE Transactions on Pattern Analysis and Machine Intelligence (2022)

\bibitem{Naseer2021IntriguingPO} Naseer, M., Ranasinghe, K., Khan, S.H., Hayat, M., Khan, F.S., Yang, M.H.: Intriguing properties of vision transformers. In: NeurIPS (2021)

\bibitem{Radford2021LearningTV} Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., Sutskever, I.: Learning transferable visual models from natural language supervision. In: ICML (2021)

\bibitem{Rebuffi2016iCaRLIC} Rebuffi, S.A., Kolesnikov, A., Sperl, G., Lampert, C.H.: icarl: Incremental classifier and representation learning. In: CVPR (2016)

\bibitem{riz2023novel} Riz, L., Saltori, C., Ricci, E., Poiesi, F.: Novel class discovery for 3d point cloud semantic segmentation. In: CVPR (2023)

\bibitem{Roy2022ClassincrementalNC} Roy, S., Liu, M., Zhong, Z., Sebe, N., Ricci, E.: Class-incremental novel class discovery. In: ArXiv (2022)

\bibitem{Tan2019TheHC} Tan, K.C., Liu, Y., Ambrose, B.A., Tulig, M.C., Belongie, S.J.: The herbarium challenge 2019 dataset. In: ArXiv (2019)

\bibitem{troisemaine2023novel} Troisemaine, C., Lemaire, V., Gosselin, S., Reiffers-Masson, A., Flocon-Cholet, J., Vaton, S.: Novel class discovery: an introduction and key concepts. In: arXiv (2023)

\bibitem{Vaze2022GeneralizedCD} Vaze, S., Han, K., Vedaldi, A., Zisserman, A.: Generalized category discovery. In: CVPR (2022)

\bibitem{wang2023comprehensive} Wang, L., Zhang, X., Su, H., Zhu, J.: A comprehensive survey of continual learning: Theory, method and application. In: arXiv (2023)

\bibitem{wah2011caltech} Welinder, P., Branson, S., Mita, T., Wah, C., Schroff, F., Belongie, S., Perona, P.: Caltech-ucsd birds 200 (2010)

\bibitem{wu2022class} Wu, T.Y., Swaminathan, G., Li, Z., Ravichandran, A., Vasconcelos, N., Bhotika, R., Soatto, S.: Class-incremental learning with strong pre-trained models. In: CVPR (2022)

\bibitem{Wu2019LargeSI} Wu, Y., Chen, Y., Wang, L., Ye, Y., Liu, Z., Guo, Y., Fu, Y.R.: Large scale incremental learning. In: CVPR (2019)

\bibitem{Xie2015UnsupervisedDE} Xie, J., Girshick, R.B., Farhadi, A.: Unsupervised deep embedding for clustering analysis. In: ArXiv (2015)

\bibitem{Yang2016TowardsKS} Yang, B., Fu, X., Sidiropoulos, N., Hong, M.: Towards k-means-friendly spaces: Simultaneous deep learning and clustering. In: ICML (2016)

\bibitem{Yang2016JointUL} Yang, J., Parikh, D., Batra, D.: Joint unsupervised learning of deep representations and image clusters. In: CVPR (2016)

\bibitem{Yang2022DivideAC} Yang, M., Zhu, Y., Yu, J., Wu, A., Deng, C.: Divide and conquer: Compositional experts for generalized novel class discovery. In: CVPR (2022)

\bibitem{Zhao2021NovelVC} Zhao, B., Han, K.: Novel visual category discovery with dual ranking statistics and mutual knowledge distillation. In: ArXiv (2021)

\bibitem{zhong2021neighborhood} Zhong, Z., Fini, E., Roy, S., Luo, Z., Ricci, E., Sebe, N.: Neighborhood contrastive learning for novel class discovery. In: CVPR (2021)

\bibitem{Zhong2020OpenMixRK} Zhong, Z., Zhu, L., Luo, Z., Li, S., Yang, Y., Sebe, N.: Openmix: Reviving known knowledge for discovering novel visual categories in an open world. In: CVPR (2020)


%%%%%%%%% SUPP only
\bibitem{boschini2022class} Boschini, M., Bonicelli, L., Buzzega, P., Porrello, A., Calderara, S.: Class-incremental continual learning into the extended der-verse. In: TPAMI (2022)

\bibitem{Gou2020KnowledgeDA} Gou, J., Yu, B., Maybank, S.J., Tao, D.: Knowledge distillation: A survey. In: IJCV (2020)

\bibitem{Madaan2021RepresentationalCF} adaan, D., Yoon, J., Li, Y., Liu, Y., Hwang, S.J.: Representational continuity for unsupervised continual learning. In: ICLR (2021)

\bibitem{grill2020bootstrap} Grill, J.B., Strub, F., Altché, F., Tallec, C., Richemond, P., Buchatskaya, E., Doersch, C., Avila Pires, B., Guo, Z., Gheshlaghi Azar, M., et al.: Bootstrap your own latent-a new approach to self-supervised learning. In: NeurIPS (2020)

\end{thebibliography}