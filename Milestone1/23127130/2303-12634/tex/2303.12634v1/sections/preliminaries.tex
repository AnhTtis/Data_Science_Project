
% A counterfactual explanation of a prediction describes the smallest change to the feature values that changes the prediction to a different output.  Let ${\lbrace X_i, y_i\rbrace}_{i=1\dots N}$, represent the classification dataset, $y_i\in\lbrace 1,\dots\ell\rbrace$, $\ell$ is the number of classes in the dataset.\newline
\vspace{-2mm}
Let $\mathcal{D} = {\lbrace \mathbf{x}_i, y_i\rbrace}_{i=1\dots N}$ be the supervised 
data set where $\mathbf{x}_i\in \mathcal{X}$ is $d$-dimensional input feature space for a classifier and $ y_i \in \mathcal{Y} = \{1, 2, \dots, \ell\}$ is the set of outputs for a classifier. Throughout this paper we assume the existence of a black box classifier $h: \mathcal{X} \to \mathcal{Y}$ trained on $\mathcal{D}$ such that
$
\hat{y} = h(\mathbf{x}) = \arg\max_{c\in\mathcal{Y}} p(y= c \mid \mathbf{x}, \mathcal{D})
$
where $ p(y= c \mid \mathbf{x}, \mathcal{D})$ is prediction score/probability for class $c$ with an input $\mathbf{x}$. 
% Based on references \cite{wachter2017counterfactual}, \cite{dhurandhar2018explanations} and \cite{van2019interpretable}, the problem of finding a counterfactual explanation for an instance $\mathbf{x}_0 \in \mathcal{X} $ with the tag $ y_0= t_0$ can be formulated as
% the following optimization problem:
% \begin{equation}\label{eq:wachter_counterfactual}
% \mathbf{x}^{cfe} = \arg \min_{\mathbf{x}} L(\mathbf{x}_0, t_0, t, \mathbf{x}, h(\mathbf{x}))
% \end{equation}
% where $t \in \mathcal{Y}$ is the target class and $L$ is a loss function defined based on the desired qualities of counterfactual explanations.
% A counterfactual explanation should change the feature values such that model changes the prediction to a different output or a target output. However, the changes to original instance $\mathbf{x}_0$ should be minimal. The change in a feature vector is measured using a distance metric $\textsc{Dist}: \mathcal{X} \times \mathcal{X} \to \mathbb{R}_{\geq 0}$ and the corresponding change in the prediction of a classifier is measured using a prediction loss metric $\textsc{PredLoss}: \mathcal{X} \times \mathcal{X} \times \mathcal{Y} \to \mathbb{R}$. The loss function $L$ can be expressed as a linear combination of prediction loss and a distance metric given by
% \begin{equation}\label{eq:wachter_counterfactual}
% L =  c \cdot \textsc{PredLoss}(\mathbf{x}_0, \mathbf{x}, t, \kappa) + \textsc{Dist}(\mathbf{x}_0,\mathbf{x})
% \end{equation}
% where the \textsc{PredLoss} function encourages classifier’s score on target class, represented by $[h(\mathbf{x})]_{t}$ to be to be higher than any
% other class by at least a margin of $\kappa \geq 0$, i.e.,
% \begin{eqnarray}\label{eq:pred_loss_target}
% L_{pred} & =& \textsc{PredLoss}(\mathbf{x}_0, \mathbf{x}, t, \kappa) \nonumber\\
% & =& \max \begin{Bmatrix}\max_y[h(\mathbf{x})]_{y \neq t} - [h(\mathbf{x})]_{t}, -\kappa\end{Bmatrix} 
% \end{eqnarray}
% For applications where target class $t$ is not pre-defined then the \textsc{PredLoss} function encourages classifier’s predicted class $\hat{y}= h(\mathbf{x})$ to be different from the predicted class of the original instance $t_0$, hence 
% \begin{eqnarray}\label{eq:pred_loss}
% L_{pred} & =& \textsc{PredLoss}(\mathbf{x}_0, \mathbf{x},  \kappa) \nonumber\\
% & =& \max \begin{Bmatrix}[h(\mathbf{x})]_{t_0} - \max_y[h(\mathbf{x})]_{y \neq t_0} , -\kappa\end{Bmatrix} 
% \end{eqnarray}
% Similar to \cite{van2019interpretable}, \textsc{Dist} can be defined using elastic net regularizer as
% \begin{eqnarray}\label{eq:pred_loss}
% L_{sparsity} & =& \textsc{Dist}(\mathbf{x}_0,\mathbf{x}) \nonumber \\
% &=& \beta \cdot \|\mathbf{x}- \mathbf{x}_0\|_1+ \|\mathbf{x}- \mathbf{x}_0\|_2
% \end{eqnarray}
% another options \textsc{Dist} have been proposed by \cite{wachter2017counterfactual} and \cite{mothilal2020explaining}, which factor in variability of feature values and incorporate the categorical nature of some features.\newline
Based on \cite{wachter2017counterfactual}, counterfactual explanations can be generated by trading off between prediction loss and sparsity. This is achieved by optimizing a linear combination of the prediction loss ($L_{pred}$)  and loss of sparsity ($L_{sparsity}$) as $L= c \cdot L_{pred} + L_{sparsity}$. Prediction loss typically measures the distance between current prediction and the target class, whereas sparsity loss function measures the perturbation from the initial instance $\mathbf{x}_0$ with class tag $t_0$. This approach generates counterfactual explanations which can reach their target class with a sparse perturbation to the initial instance. However, they need not necessarily respect the input data distribution of the classifier, hence, resulting in unreasonable values 
for $\mathbf{x}^{cfe}$. 

Authors in \cite{dhurandhar2018explanations} addressed this issue through incorporation of $L_2$ reconstruction error for $\mathbf{x}^{cfe}$ evaluated through an autoencoder (AE) trained on the input data $\mathcal{X}$ as 
$L_{recon}^{\mathcal{X}} (\mathbf{x}) =  \|\mathbf{x}- AE_{\mathcal{X}}(\mathbf{x})\|_2^2$
where $AE_{\mathcal{X}}$ represents the auto-encoder trained on entire training dataset $\mathcal{X}$. The auto-encoder loss function $L_{recon}^{\mathcal{X}}$ penalizes counterfactual explanations which do not lie within the data-distribution. However, \cite{van2019interpretable}
illustrated that incorporating $L_{recon}^{\mathcal{X}}$ in $L$ may result in counterfactual explanations which lie inside the input data-distribution but they may not be interpretable.
To this end, \cite{van2019interpretable} proposes addition of a prototype loss function $L_{proto}^{\mathcal{X}}$ to $L$ to make $\mathbf{x}^{cfe}$ more interpretable and improve the counterfactual search process through prototypes in the latent space of auto-encoder. $L_{proto}^{\mathcal{X}}$  is the $L_2$ error between the latent encoding of $\mathbf{x}$  and cluster centroid of the target class in the latent space of the encoder defined as $\text{proto}_t$ (short for target prototype) as $
L_{proto}^{\mathcal{X}} (\mathbf{x}, \text{proto}_t) =  \|ENC_{\mathcal{X}}(\mathbf{x}) - \text{proto}_t\|_2^2
$,
where $ENC_{\mathcal{X}}$ represents encoder part of the auto-encoder $AE_{\mathcal{X}}$  and $ENC_{\mathcal{X}}(\mathbf{x})$ represents the projection of $\mathbf{x}$ on to the latent space of the auto-encoder. Given a target $t$, the corresponding $\text{proto}_t$ can be defined as 
\vspace{-5mm}
\begin{eqnarray}\label{eq:target_proto}
\text{proto}_t =  \frac{1}{K} \sum_{k=1}^K ENC_{\mathcal{X}}(\mathbf{x}_k^t)
\end{eqnarray}
where $\mathbf{x}_k^t$ represent the input instances corresponding to the class $t$ such that $\{ENC_{\mathcal{X}}(\mathbf{x}_k^t)\}_{k=1, \dots, K}$ are the $K$  nearest  neighbors of $ENC_{\mathcal{X}}(\mathbf{x}_0)$. For applications where target class $t$ is not pre-defined, a suitable replacement for $\text{proto}_t$ is evaluated by finding the nearest prototype $\text{proto}_j$ of class $j \neq t_0$ to the encoding of $\mathbf{x}_0$, given by
$
j = \arg\min_{i \neq t_0} \|ENC_{\mathcal{X}}(\mathbf{x}_0) - \text{proto}_i\|_2
$. Then prototype loss $L_{proto}$ can be defined as $L_{proto}(\mathbf{x}, \text{proto}_j) =  \|ENC_{\mathcal{X}}(\mathbf{x}_0) - \text{proto}_j\|_2^2$. According to \cite{van2019interpretable} the loss function  $L_{proto}$ explicitly guides the encoding of the counterfactual explanation to the target prototype (or the nearest protoytpe $\text{proto}_{i \neq t_0}$). Thus we have a loss function $L$ given by
\vspace{-2mm}
\begin{eqnarray}\label{unsupervised_loss}
L = c\cdot L_{pred} + L_{sparsity}+ \gamma \cdot L^{\mathcal{X}}_{recon} + \theta\cdot L_{proto}^{\mathcal{X}}
\end{eqnarray}
where $c$, $\gamma$ and $\theta$ are hyper-parameters tuned globally for each data set. For detailed descriptions of these parameters and their impact on the counterfactual search, we refer the readers to \cite{alibi_doc}. In this paper, we propose an alternate version of this loss function. The constituent loss functions $L^{\mathcal{X}}_{recon}$ and $L^{\mathcal{X}}_{proto}$ are based on an auto-encoder trained in an unsupervised fashion.  In the next section we motivate the use of an auto-encoder trained using class tagged data in a semi-supervised fashion.
\vspace{-3mm}
