{
    "arxiv_id": "2303.17230",
    "paper_title": "KOO approach for scalable variable selection problem in large-dimensional regression",
    "authors": [
        "Zhidong Bai",
        "Kwok Pui Choi",
        "Yasunori Fujikoshi",
        "Jiang Hu"
    ],
    "submission_date": "2023-03-30",
    "revised_dates": [
        "2023-03-31"
    ],
    "latest_version": 1,
    "categories": [
        "math.ST",
        "stat.ME"
    ],
    "abstract": "An important issue in many multivariate regression problems is eliminating candidate predictors with null predictor vectors. In large-dimensional (LD) setting where the numbers of responses and predictors are large, model selection encounters the scalability challenge. Knock-one-out (KOO) statistics have the potential to meet this challenge. In this paper, the strong consistency and the central limit theorem of the KOO statistics are derived under the LD setting and mild distributional assumptions (finite fourth moments) of the errors. These theoretical results lead us to propose a subset selection rule based on the KOO statistics with the bootstrap threshold. Simulation results support our conclusions and demonstrate the selection probabilities by the KOO approach with the bootstrap threshold outperform the methods using Akaike information threshold, Bayesian information threshold and Mallow's C$_p$ threshold. We compare the proposed KOO approach with those based on information threshold to a chemometrics dataset and a yeast cell-cycle dataset, which suggests our proposed method identifies useful models.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17230v1"
    ],
    "publication_venue": null
}