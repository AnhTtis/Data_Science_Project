{
    "arxiv_id": "2303.09975",
    "paper_title": "MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation",
    "authors": [
        "Saikat Roy",
        "Gregor Koehler",
        "Constantin Ulrich",
        "Michael Baumgartner",
        "Jens Petersen",
        "Fabian Isensee",
        "Paul F. Jaeger",
        "Klaus Maier-Hein"
    ],
    "submission_date": "2023-03-17",
    "revised_dates": [
        "2023-07-24"
    ],
    "latest_version": 4,
    "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
    ],
    "abstract": "There has been exploding interest in embracing Transformer-based architectures for medical image segmentation. However, the lack of large-scale annotated medical datasets make achieving performances equivalent to those in natural images challenging. Convolutional networks, in contrast, have higher inductive biases and consequently, are easily trainable to high performance. Recently, the ConvNeXt architecture attempted to modernize the standard ConvNet by mirroring Transformer blocks. In this work, we improve upon this to design a modernized and scalable convolutional architecture customized to challenges of data-scarce medical settings. We introduce MedNeXt, a Transformer-inspired large kernel segmentation network which introduces - 1) A fully ConvNeXt 3D Encoder-Decoder Network for medical image segmentation, 2) Residual ConvNeXt up and downsampling blocks to preserve semantic richness across scales, 3) A novel technique to iteratively increase kernel sizes by upsampling small kernel networks, to prevent performance saturation on limited medical data, 4) Compound scaling at multiple levels (depth, width, kernel size) of MedNeXt. This leads to state-of-the-art performance on 4 tasks on CT and MRI modalities and varying dataset sizes, representing a modernized deep architecture for medical image segmentation. Our code is made publicly available at: https://github.com/MIC-DKFZ/MedNeXt.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09975v1",
        "http://arxiv.org/pdf/2303.09975v2",
        "http://arxiv.org/pdf/2303.09975v3",
        "http://arxiv.org/pdf/2303.09975v4"
    ],
    "publication_venue": "Accepted at MICCAI 2023"
}