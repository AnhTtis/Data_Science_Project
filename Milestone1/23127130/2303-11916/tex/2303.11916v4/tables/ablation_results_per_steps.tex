\begin{table}[h]
\small
\centering
\setlength{\tabcolsep}{3pt}
\resizebox{\textwidth}{!}{
\begin{tabular}{c|cccccccc|cccc}
\toprule
Step & 1 & 2 & 3 & 4 & 5 & 10 & 50 & 100 & Pic2Word & SEARLE & ARTEMIS & Combiner \\
\midrule
Avg(R@10, R@50) & 21.52 & 29.22 & 37.63 & \best{41.08} & \best{42.17} & \best{42.33}& 42.45 & 42.65 & 34.20 & 35.90 & 40.61 & 41.84 \\
Time (sec) & 0.02 & 0.05 & 0.07 & \best{0.09} & \best{0.12} & \best{0.23} & 1.08 & 2.02 & 0.02 & 0.02 & 0.005 & 0.006 \\
GPU Memory (bs 1) & \multicolumn{8}{c|}{2.60 GB} & {0.97 GB} & {1.32 GB} & {0.26 GB} & {0.54 GB} \\
GPU Memory (bs 256) & \multicolumn{8}{c|}{5.80 GB} & {2.99 GB} & {3.24 GB} & {2.82 GB} & {1.95 GB} \\
\bottomrule
\end{tabular}
}
\caption{\small \textbf{Performances vs. inference time by varying the number of denoising steps.} Numbers are measured on the FashionIQ validation split. \ours (ViT-L) in \cref{tab:main} is equivalent to 10 steps, but using 5 steps is a practical alternative. The inference time was measured on a single A100 GPU with a batch size of 1. GPU memories are the pick-allocated memory measured on batch sizes of 1 and 64, respectively. Note that ARTEMIS cannot support efficient batch operation for inference because its forward path needs triplet information, not an image-instruction pair; here, we report ARTEMIS information with training triplets.}
\label{tab:denoising_steps}
\end{table}


