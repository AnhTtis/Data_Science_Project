
\begin{table*}[t]
\small
\centering
\begin{tabular}{lrrr}
\toprule
& Stage1 & Stage2 & Fine-tuning \\
\midrule
Diffusion steps & 1000 & 1000 & 1000 \\
Noise schedule & cosine & cosine & cosine \\
Sampling steps & 10 & 10 & 10 \\
Sampling variance method & DDIM \cite{song2020denoising} & DDIM \cite{song2020denoising} & DDIM \cite{song2020denoising} \\ \midrule
Dropout & 0.1 & 0.1 & 0.1 \\
Weight decay & 6.0e-2 & 6.0e-2 & 6.0e-2 \\
Batch size & 4096 & 2048 & 2048 \\
Iterations & 1M & 200K & 50K \\
Learning rate & 1e-4 & 1e-5 & 1e-5 \\
Optimizer & AdamW \cite{loshchilov2017decoupled} & AdamW \cite{loshchilov2017decoupled} & AdamW \cite{loshchilov2017decoupled} \\
EMA decay & 0.9999 & 0.9999 & 0.9999 \\ \midrule
Input tokens & $z_i^{(t)}$, t & $z_i^{(t)}$, t & $z_i^{(t)}$, t \\
Conditions & $z_{c_T}$ & $z_{c_T}$, $z_{i_R}$, $z_{c_M}$ & $z_{c_T}$, $z_{i_R}$ \\
Training dataset & LAION 2B English \cite{schuhmann2022laion} & LAION 2B English \cite{schuhmann2022laion}, Our dataset & FashionIQ \cite{fashioniq} or CIRR \cite{cirr} trainset \\
Image encoder & CLIP-L/14 \cite{radford2021clip} & CLIP-L/14 \cite{radford2021clip} & CLIP-L/14 \cite{radford2021clip} \\
Text encoder & CLIP-L/14 \cite{radford2021clip} & CLIP-L/14 \cite{radford2021clip} & CLIP-L/14 \cite{radford2021clip} \\
Denoiser depth & 12 & 12 & 12 \\
Denoiser heads & 16 & 16 & 16 \\
Denoiser head channels & 64 & 64 & 64 \\
\bottomrule
\end{tabular}
\vspace{.5em}
\caption{\small {\bf Hyperparameters.} A model trained by Stage 1 and Stage 2 is equivalent to ``Zero-shot'' in the main table. A ``supervised model'' is the same as the fine-tuned version.}
\label{tab:parameters}
\end{table*}