{
    "arxiv_id": "2303.13739",
    "paper_title": "MoWE: Mixture of Weather Experts for Multiple Adverse Weather Removal",
    "authors": [
        "Yulin Luo",
        "Rui Zhao",
        "Xiaobao Wei",
        "Jinwei Chen",
        "Yijie Lu",
        "Shenghao Xie",
        "Tianyu Wang",
        "Ruiqin Xiong",
        "Ming Lu",
        "Shanghang Zhang"
    ],
    "submission_date": "2023-03-24",
    "revised_dates": [
        "2023-03-27"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Currently, most adverse weather removal tasks are handled independently, such as deraining, desnowing, and dehazing. However, in autonomous driving scenarios, the type, intensity, and mixing degree of the weather are unknown, so the separated task setting cannot deal with these complex conditions well. Besides, the vision applications in autonomous driving often aim at high-level tasks, but existing weather removal methods neglect the connection between performance on perceptual tasks and signal fidelity. To this end, in upstream task, we propose a novel \\textbf{Mixture of Weather Experts(MoWE)} Transformer framework to handle complex weather removal in a perception-aware fashion. We design a \\textbf{Weather-aware Router} to make the experts targeted more relevant to weather types while without the need for weather type labels during inference. To handle diverse weather conditions, we propose \\textbf{Multi-scale Experts} to fuse information among neighbor tokens. In downstream task, we propose a \\textbf{Label-free Perception-aware Metric} to measure whether the outputs of image processing models are suitable for high level perception tasks without the demand for semantic labels. We collect a syntactic dataset \\textbf{MAW-Sim} towards autonomous driving scenarios to benchmark the multiple weather removal performance of existing methods. Our MoWE achieves SOTA performance in upstream task on the proposed dataset and two public datasets, i.e. All-Weather and Rain/Fog-Cityscapes, and also have better perceptual results in downstream segmentation task compared to other methods. Our codes and datasets will be released after acceptance.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13739v1"
    ],
    "publication_venue": null
}