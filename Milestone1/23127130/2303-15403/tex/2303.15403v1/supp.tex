% \ifx \supp \undefined
%     \documentclass[10pt,twocolumn,letterpaper]{article}
%     \usepackage[review]{cvpr}
    
%     % Include other packages here, before hyperref.
%     \usepackage{xcolor}
%     \usepackage{graphicx}
%     \usepackage{amsmath}
%     \usepackage{amssymb}
%     \usepackage{floatpag}
%     \usepackage{enumitem}
%     \usepackage{mathtools}
%     \usepackage{multirow}

%     \usepackage[pagebackref,breaklinks,colorlinks,bookmarks=false]{hyperref}
    
%     % Support for easy cross-referencing
%     \usepackage[capitalize]{cleveref}
%     \crefname{section}{Sec.}{Secs.}
%     \Crefname{section}{Section}{Sections}
%     \Crefname{table}{Table}{Tables}
%     \crefname{table}{Tab.}{Tabs.}
    
    
%     %%%%%%%%% PAPER ID  - PLEASE UPDATE
%     \def\cvprPaperID{2833} % *** Enter the CVPR Paper ID here
%     \def\confName{CVPR}
%     \def\confYear{2023}
    
%     \input{cvpr2023-author_kit-v1_1-1/latex/macros}

%     \begin{document}
% \fi




% \title{Supplementary Materials for \\  }

\maketitle
\thispagestyle{empty}


\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\thefigure}{S\arabic{figure}}
\setcounter{figure}{0}
\setcounter{table}{0}

\twocolumn[{
\renewcommand\twocolumn[1][]{#1}
\centering  
\Large
\textbf{Training-free Style Transfer Emerges from h-space in Diffusion models} \\
\vspace{0.5em}Supplementary Material \\
\vspace{1.0em}
}]
% \appendix %
% \mtcsettitle{minitoc}{}
\appendix
\addcontentsline{toc}{section}{Supple}
\renewcommand{\contentsname}{}
\renewcommand{\partname}{} % remove "Part"
\renewcommand{\thepart}{} % remove p
\renewcommand{\ptcSfont}{\small\bf}
% \addtocontents{parttoc}{\protect\setlength{\parskip}{-3.0pt}\protect\setlength{\parindent}{-3.0pt}} % Remove spacing before parttoc
\part{} %
\parttoc %

% We provide the following supplementary materials:
% \begin{enumerate}[label=\Alph*, nosep]
%     \item Implementation details
%     \item Varying the strength of content injection
%     \item Effect of style calibration
%     \item More results and comparison
%     \item More analyses of Slerp
%     \item Discussion details
%     \item $\gamma{}$ scheduling
%     \item More related work
%     \item Stable diffusion experiment details
    
    % \item Derivation of the approximation and choice of $\lambda_t$.
    % \item Analyses on the sampling calibration
        % \begin{enumerate}
        %     \item Choice of the interval for \dtscaling{}
        %     \item Excessive $\lambda_t$
        % \end{enumerate}
        % \begin{enumerate}
        %     \item More qualitative results 
        %     \item Comparison with SOTA methods
        % \end{enumerate}
% \end{enumerate}

\section{Implementation details}
\label{supp:implement}
To perform the reverse process for figures, we used 1000 steps, while for tables and plots, we used 50 steps.
% We use 50 inference steps for efficiency, not 1000, in all figures, tables, and plots.
% We apply quality boosting~\cite{kwon2022diffusion} except style transfer with artistic references for all figures in the paper and use 1000 timesteps for inference. 
During inference, we injected $\vht{}$ sparsely only at the timesteps where the content injection was applied within the 50 inference steps. For the remaining timesteps, we used the original DDIM sampling. This approach enabled us to achieve the same amount of content injection across different inference steps.

For local style mixing, we spatially applied Slerp on $\vht$, which has a dimension of $8 \times 8 \times 256$, as demonstrated in \fref{fig:spatial_slerp}. In face swapping, we used a portion of $\vht{}$ that corresponds to the face area for Slerp. In \sref{sec:method}, we used the editing interval [$T$=1000, $t_{edit}$=400], and did not use quality boosting to eliminate stochasticity for comparison purposes, i.e., $\tboost=0$. 
% The reasoning behind choosing $t_{edit}$ will be discussed further in \sref{sec:analyses}.

% As we use 1000 steps for inference, we sparsely inject $\vht{}$ only at the timesteps where the content injection is applied in 50 inference steps and replace the rest of timesteps with the original DDIM sampling. As a result, we could get the same amount of content injection in different inference steps.
% % There are two options to acquire the same amount of content injection in different inference steps. 1) If we want to use the same $\gamma{}$ evaluated in 50 timesteps for 1000 inference steps, we could sparsely inject $\vht{}$ only at the time steps where the content injection is applied in 50 inference steps and replace the rest of timesteps with original DDIM sampling. 
% % % The same $\gamma{}$  with the same injection time steps brings a similar amount of changes in content. 
% % 2) If we do not want to skip some timesteps for content injection, properly scaled $\gamma{}$ could be a solution. In \cite{kwon2022diffusion}, if the sum of $\delta_{h}$ is preserved, the same amount of change can be expected in different inference steps. Similarly, if we choose an adequate small $\gamma{}$ value compared to the one evaluated in 50 steps, we can perform the same amount of content injection in 1000 inference steps. Nonetheless, we do not use the second method since we can hardly expect the total amount of content injection. Content injection is conducted recursively at every injection steps which makes the change of content seriously sensitive to $\gamma{}$. More injection steps increase the sensitivity and accurate calibration of $\gamma{}$ is required.
% For the local content injection, we apply Slerp spatially on $\vht{}$ as shown in \fref{fig:spatial_slerp}. Note that $\vht{}$ has a dimension of $8 \times 8 \times 256$. For face swapping, a part of $\vht{}$ corresponding to a face area is used for Slerp.
% In \sref{sec:method}, we opt to use the editing interval [$T$=1000, $t_{edit}$=400], and not to use quality boosting to eliminate stochasticity for comparison, i.e., $\tboost=0$. The choice of $t_{edit}$ will be discussed further in \sref{sec:analyses}.
%First, we make a feature mask which has same dimension with $\vht{}$ and fill a part of the mask where we want to inject contents with 1 and the rest with 0.  

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=1\linewidth]{./figures/supple_mask_illustration.pdf}
%     \vspace{-0.5em}
%     \caption{\textbf{Illustration of local content injection.} A mask $m$ determines the area of Slerp. }
%     % \caption{Overview of Asyrp++}
%     \label{afig:mask_illustration}
% \end{figure}


\section{Varying the strength of content injection}
% with varying $\gamma$}
% controls strength of content injection }
\label{supp:gamma}

\fref{afig:gamma} illustrates the results of content injection with different values of $\gamma{}$. As observed in \fref{fig:gamma_id_style} (b), there is a positive correlation between $\gamma{}$ and amount of content change. However, increasing $\gamma{}>0.6$ barely leads to any content change but instead, it degrades the quality of images with distortions and artifacts.
As the recursive injection of content by $\gamma{}$ exponentially decreases the original $\vht{}$ component along the reverse process, according to \eref{eq:cumulative}, we expect linear change of content in the image by linearly controlling $\alpha$ that specifies $\gamma=\alpha^{1/T}$. Note that we did not consider the influence of the networks for the approximation.
% we observe positive correlation between $\gamma$ and amount of the content change. However, increasing  barely leads to content change, but only degrades the quality of images with distortion and artifacts.
% From \fref{fig:gamma_id_style}-(b), we suppose that the higher $\gamma$ brings more content injection up to $\gamma=0.6$.
% In other words, $\gamma$ can determine how much content will be injected. After $\gamma=0.6$, ID similarity between a content image and the resulting image decreases, which means that content injection is saturated. 
% \fref{afig:gamma} shows the results of content injection with respect to different values of $\gamma{}$. We observe that if we use $\gamma{}$ larger than $0.6$, increasing $\gamma{}$ barely changes content representations, but only degrades the quality of images with distortion and artifacts. 
% \fref{afig:gamma_horn} shows that the trend of the variance of $\vx_t$ changes with respect to $\gamma$ during sampling process. Larger $\gamma$ pushes the variance further from the reconstruction leading to inferior image quality. \js{We observe that sampling away from the distribution of DDIM reconstruction causes artifacts in resulting images.}
% \fref{afig:gamma_horn} explains the quality problem caused by excessive values of $\gamma{}$. The inconsistency of the distributions from the original distribution reflects $\gamma{}$. The larger $\gamma{}$ we use, the larger inconsistency we get. It is one of the main causes of quality degradation.
% As recursively injecting content by $\gamma$ exponentially decreases the $\vht$ component along the reverse process according to \eref{eq:cumulative}, we may expect linear visual change of content by linearly controlling $\alpha$ that specifies $\gamma=\alpha^{1/T}$. Note that we does not take the influence of the networks into account for the approximation. \todo{}


% Nevertheless, we should compensate for the gap due to the disturbance through the networks. Hence, \eref{eq:cumulative} is only an approximation.




\begin{figure}[!t]
    \centering
    \includegraphics[width=1\linewidth]{./figures/supple_mask_illustration.pdf}
    \vspace{-0.5em}
    \caption{\textbf{Illustration of spatial content injection methods} Mask $m$ determines the area of feature map. Slerp of masked $\vht$ enables content injection into designated space.}
    % \caption{Overview of Asyrp++}
    \vspace{-0.5em}
    \label{fig:spatial_slerp}
\end{figure}


\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{./figures/supple_slerp_ratio_extend.pdf}
    \captionof{figure}{$\gamma$ controls how much content will be injected. We do not use other techniques such as quality boosting for comparison.}
    \label{afig:gamma}
\end{figure*}





% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.9\linewidth]{./figures/slerp_ratio_horn.pdf}
%     \vspace{-0.5em}
%     \caption{\textbf{Effect of increasing $\gamma$}. We report the standard deviation of $\vx_t$ in different $\gamma$. }
%     % \caption{Overview of Asyrp++}
%     \vspace{-0.5em}
%     \label{afig:gamma_horn}
% \end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{./figures/style_calibration_qual.pdf}
    \vspace{-0.5em}
    \caption{\textbf{Effect of increasing $\omega{}$}. Increasing $\omega{}$ reflects style elements stronger and $\omega{}=0$ shows the result without style calibration.}
    % \caption{Overview of Asyrp++}
    \vspace{-0.5em}
    \label{afig:omega_qual}
\end{figure}



\section{Effect of style calibration}
\label{supp:omega}

In this section, we present an analysis of the parameter $\omega{}$ which controls the strength of the style element. \fref{afig:omega_qual} displays the resulting images with sweeping $\omega{}$. As $\omega{}$ increases, the style elements become more prominent. When $\omega{}$ equals 0, the result is without style calibration. We note that style calibration with $\omega{}=0$ is not rigorously defined. In \fref{fig:warigari_quan}, we observe a trade-off between Gram loss and ID similarity, as well as FID, depending on the value of $\omega{}$. However, despite this trade-off, increasing $\omega{}$ results in more effective style transfer.


% In this section, we provide an analysis of the parameter $\omega$. \fref{afig:omega_qual} shows resulting images with varying values of $\omega$.
% As $\omega{}$ increases, the style elements become more prominent. When $\omega{}=0$, the result is without style calibration. Note that style calibration with $\omega{}=0$ is not strictly defined.
% % Increasing $\omega{}$ led to increasing style elements and $\omega{}=0$ shows the result without style calibration. Note that strictly, style calibration with $\omega{}=0$ is not defined.

% \fref{fig:warigari_quan} shows there is a trade-off relationship between Gram loss and ID similarity as well as FID depending on the value of $\omega$. 
% However, increasing $\omega{}$ resulted in more effective style transfer, despite the trade-off between Gram loss and ID similarity as well as FID.

\begin{figure}[!t]
    \centering
    \includegraphics[width=1\linewidth]{./figures/warigari_quan.pdf}
    % \vspace{-1.6em}
    \caption{\textbf{Quantitative results of style calibration with varying $\omega{}$.}
    \warigari{} facilitates style transfer while minimizing content injection loss and maintaining the quality of the resulting images.
    }
    \vspace{-1em}
    \label{fig:warigari_quan}
\end{figure}  

\section{More results and comparison}


\subsection{More qualitative results}
\label{supple:moreresults}

We provide more qualitative results of CelebA-HQ, AFHQ, \metfaces{}, LSUN-church, and LSUN-bedroom in \fref{fig:supple_celeba}-\ref{fig:supple_style_transfer_more} (located at the end for compact arrangement).

\begin{table}[b]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{l|l|c}
                        % \hline
                        & Method               & Preference (\%) \\
                        \hline
\multirow{2}{*}{Content injection}       & Swapping Autoencoder~\cite{park2020swapping} & 40.11      \\
                        & Ours                 & \textbf{59.89}      \\
                        \hline
\multirow{2}{*}{Local content injection} & StyleMapGAN~\cite{kim2021exploiting}          & 33.56      \\
                        & Ours                 & \textbf{66.44}      \\
                        \hline
\multirow{3}{*}{Artistic style transfer} & StyTr$^2$~\cite{deng2021stytr}            & 20.89      \\
                        & CCPL~\cite{wu2022ccpl}                 & 21.44      \\
                        & Ours                 & \textbf{57.67}     \\
                        % \hline
\end{tabular}
}
\caption{User study with 90 participants.}
\label{atab:comparison}
\end{table}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{./figures/lerp_slerp_compare_qual.pdf}
    % \vspace{-1.5em}
    \captionof{figure}{\textbf{Comparison between Slerp and Lerp.} Slerp reduces artifacts and distortions in Lerp. Note that We do not use other techniques such as quality boosting to evaluate the effect of Slerp only.}
    % \vspace{2.0em}
    \label{afig:compare_lerp_slerp}
\end{figure*}

\subsection{Comparison with the other methods.}
\label{supp:qualitative}

\tref{atab:comparison} presents the results of a user study conducted with 90 participants to compare our method with existing methods. The participants were asked a question: ``Which image is more natural while faithfully reflecting the style and the content?". We randomly selected ten images for content injections and thirty images for style transfer without any curation. The example images are shown in \fref{fig:supple_swapping_autoencoder}-\ref{fig:supple_styletransfer_comparison} (located at the end for clear spacing). Even though \ours{} works on pretrained diffusion models without further training for the task, our method outperformed the others. We selected the recent methods from the respective tasks for comparison.
 % We randomly chose ten images for content injections, and thirty images for style transfer without curation. The example images are shown in \fref{fig:supple_swapping_autoencoder}-\ref{fig:supple_styletransfer_comparison} (located at the end for clear spacing). Our method outperforms the others even though \ours{} works on pretrained diffusion models and does not involve any further training for the task. We chose the recent methods from the respective tasks for comparison. 

\subsection{Comparison with a concurrent work}
% \fref{fig:rebuttal} (a) shows the superiority of our method in reflecting the style and preserving the content compared to DiffuseIT. \cite{kwon2022diffuseIT} Furthermore, DiffuseIT requires extra supervision using DINO while ours simply modify the intermediate variables. 
We also provide more qualitative comparison with DiffuseIT \cite{kwon2022diffuseIT} in \fref{fig:supple_diffuseIT}. \ours{} 
 shows comparable results without extra supervision using DINO ViT \cite{caron2021emerging} used by DiffuseIT. As shown in the figure, \ours{} is highly proficient at accurately and authentically reflecting the style color while avoiding artificial contrast, especially when there is a significant difference in color between the content and the style (e.g., black and white). In contrast, DiffuseIT may not be able to fully capture the style color in these scenarios. This discrepancy is due to the starting point of the reverse process. DiffuseIT utilizes the inverted $\xT$ of the content image to sample and manipulates noise to match the target style element. The large gap in color distribution between the content and style images makes it challenging for DiffuseIT to overcome this difference entirely. Conversely, \ours{} initially samples from the inverted $\xT$ of the style image, making it easier to maintain the color of the style image. The style elements which start from $\xT$ pass through the skip connection.
 
 % and remains effective in producing desirable results even when faced with substantial variations in color distribution between the style and content. 
% We report the result of the user study with 90 participants for the quantitative result (\tref{atab:comparison}). Although \ours{} does not train for specific tasks, \ours{} achieves higher scores than other methods. For content injection, we used FFHQ \cite{karras2019style} for a fair comparison with Swapping AutoEncoder. We carefully made masks for StyleMapGAN for a fair comparison. We provide qualitative results in \fref{fig:supple_swapping_autoencoder}-\ref{fig:supple_styletransfer_comparison} (located at the end for clear spacing). We randomly select ten images for content injections, respectively, and thirty images for style transfer. We use a simple question: "Which image looks more natural and well reflects style and content?"
% "Images generated with style and content references. Which image is better?".

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./figures/large_gap_norms.pdf}
    \vspace{-0.5em}
    \caption{We choose $\vht{}$ from top 20 and bottom 20 samples in their norms among 500 samples. 
    % To validate Slerp, we divide samples into two groups.
    Each line represents a trajectory of $\lVert h \rVert_{2}$ during the reconstruction of a sample.
}
    % \caption{Overview of Asyrp++}
    \vspace{-0.5em}
    \label{afig:large_gap_norms}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./figures/norm_visualize.pdf}
    \vspace{-0.5em}
    \caption{Visual comparison of Slerp and Lerp. The larger difference in norms of $\vht$ and $\vhtcon$ leads to a larger gap between the results. Lerp followed by normalization is closer to Slerp than Lerp.
    % The more difference in norm there is, the more difference between Slerp and Lerp becomes. We observe that using Lerp followed by normalization has a similar result to Normalized Slerp.
}
    % \caption{Overview of Asyrp++}
    \vspace{-0.5em}
    \label{afig:norm_visualize}
\end{figure}


\section{More analyses of Slerp}
\subsection{Comparison with Lerp}
\label{supp:lerp}

The intuition behind using Slerp is that we should preserve the correlation between $\vht$ and its matching skip connection (\sref{sec:slerp}). Here, we explore an alternative: Lerp.
When $\vht$ and $\vhtcon$ have different norms, using Lerp results in more artifacts in the final image as shown in \fref{afig:compare_lerp_slerp}. This difference in norms of $\vht$ is reported in \fref{afig:large_gap_norms}.
\fref{afig:norm_visualize} illustrates the difference between Slerp, Lerp, and Lerp followed by normalization. Lerp may change the norm of $\textbf{f}(\vht, \vhtcon, \gamma)$ when the norm of $\vht$ and $\vhtcon$ are different, leading to a decrease in image quality. However, Lerp followed by normalization produces results similar to Slerp. Still, we choose Slerp because it is easier to implement and less prone to errors.


% According to the analysis on the relationship between $\vht{}$ and its skip connection, we opt to use normalized spherical interpolation of two $\vht{}$'s for content injection. As mentioned above, the norm of $\vht{}$ should be maintained along the asymmetric reverse process. Content injection via Slerp allows the norm to move along the trajectory supposed to follow. If the difference in the norms of two objectives $\vht{}$'s is not huge, normalized Slerp works as similar as Lerp. However, if we choose $\vht{}$'s that have huge difference norms, Slerp shows more robustness than Lerp. To validate Slerp, we divide samples into two groups, one with large $\vht{}$ norms and the other with small $\vht{}$ norms (\fref{afig:large_gap_norms}). After that, we inject the contents of one group into another with Lerp and Slerp. The qualitative comparison of Lerp and Slerp is in \fref{afig:compare_lerp_slerp}. As shown in the figure, we could find more artifacts in the results of Lerp compared to Slerp.



\subsection{Cumulative content injection}
\label{supp:cumulative}
In addition to improving the quality of images, our approach allows us to control the amount of content injection by adjusting the $\vht\text{-to-}\vhtcon$ ratio through Slerp parameter $\gamma_t$. A small $\gamma_t$ results in a smaller amount of content injection. As mentioned in \sref{sec:replace}, preserving the $\vht$ component improves quality. However, there is a trade-off between the content injection rate and quality, and therefore, the value of $\vht$ needs to be constrained. Further experiments to determine the proper range of $\gamma{}$ are discussed in \sref{sec:gamma}.
% Small $\gamma{}$ means a small portion of content injection. \js{From \sref{sec:replace}, we suggest that preserving $\vht$ improves quality. Since there is trade-off relation ship between content injection rate and quality, the value of $\gamma{}$ should be constrained. \sref{sec:gamma} provides further experiment to find proper range of $\gamma$} 
 
 Note that the effects of Slerp are cumulative along the reverse process as the content injection at $t$ affects the following reverse process in $[t-1,\tedit]$.
% As content injection is defined for $t\in[T,\tedit]$, $\vhtcon$ is repeatedly injected during this interval. 
We provide an approximation of the total amount of injected content as follows. Assuming that the angle between $\vht$ and $\vhtcon$ is close to 0 and the results of content injection at $t$ are directly passed to the next \thspace{} at $t-1$ without any loss, then
% Assume the optimal case that the angle between $\vht$ and $\vhtcon$ is close to 0 and the results of content injection at $t$ are directly passed to the next \thspace{} at $t-1$ without any loss, then
$$\tildeh_{t} = (1-\gamma) \vht + \gamma \vhtcon \approx{} f(\vht, \vhtcon, \gamma)$$
and $$ \vh_{t-1} \approx{} \tildeh_t.$$
Along the reverse process, $\tildeh_t$ is recursively fed into the next stage.
After $n$ content injections, we get 

\begin{equation}
\label{eq:cumulative}
\tildeh_{t-n} \approx{} (1-\gamma)^n \vh_t + \gamma \sum_{i=1}^{n} (1-\gamma)^{i-1} h_{t-i}^{content}.
\end{equation}
As $0 \leq \gamma \leq 1$, the proportion of $\vht$ decreases exponentially and the proportion of $\vhtcon$ accumulates during the content injection stage. It indicates that a large proportion of content is injected compared to $\gamma{}$ of Slerp. For further details regarding the ablation study on $\gamma{}$, please refer to \sref{sec:gamma}.
%the proportion of injected content is larger than $\gamma_t$ of Slerp.  Please refer to \sref{sec:gamma} for the ablation study on $\gamma{}$. 



% Following \eref{eq:cumulative}, the part of $\vhtone$ decreases in proportion to the exponential of $(1-\gamma)$. And the rest of the part is filled with the information of $\vhttwo$. If \eref{eq:cumulative} is correct, we could expect linear content manipulation by exponentially adjusting $\gamma$. 
% However, it only holds in the optimal case where the results of content injection are delivered to the next timestep without any loss. In the real world, content injection is decoded and encoded by DMs to get to the next timestep. Therefore, we could only approximate $\gamma$ by \eref{eq:cumulative} to measure how much content will be injected.

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.9\linewidth]{./figures/limitation_ood.pdf}
    % \vspace{-1.6em}
    \caption{\textbf{Content image from unseen domain} Other than style images, $\vhtcon{}$ obtained from unseen domain results in poor images.}
    % \vspace{-1.5em}
    \label{fig:limitation_ood}
\end{figure}


\begin{figure}[!t]
    \centering
    \includegraphics[width=0.9\linewidth]{./figures/limitation_mask3.pdf}
    % \vspace{-1.6em}
    \caption{\textbf{Local style mixing with various feature map mask sizes.} Adjusting the size and position of feature map mask enables to handle the area of content injection, facilitating control of local style mixing.}
    % \vspace{-1.5em}
    \label{fig:limitation_mask}
\end{figure}



\section{Discussion details}
\label{appendix:limitations}

As mentioned in \sref{sec:conclusion}, \fref{fig:limitation_ood} shows that using out-of-domain images as content leads to completely distorted results. It implies that $\vht$ cannot be considered a universal representation for all types of content. 
% \fref{fig:limitation_ood} shows the constraint.

\fref{fig:limitation_mask} shows the local style mixing with various feature map mask sizes. By using the feature map mask, we can designate the specific area where content injection is applied. 
Unfortunately, the \thspace{} has small spatial dimensions, limiting the resolution of the mask for local style mixing.
% Nonetheless, the \thspace{} has a small dimension, which restricts local style mixing to the resolution of the \thspace{} mask.
% Unfortunately, the \thspace{} has a small dimension and local editing is limited to the resolution of the \thspace{} mask.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\linewidth]{./figures/gradually_schedule.pdf}
    % \vspace{-10pt}
    \vspace{-1.0em}
    \caption{\textbf{Various interpolation ratio schedule.} $\gamma{}$ is content injection rate.}
    % \caption{Overview of Asyrp++}
    % \vspace{-1em} %공간부족해지면 넣기.
    \label{fig:rebuttal}
\end{figure}

\section{$\gamma{}$ scheduling}
\label{appendix:gamma_scheduling}

\fref{fig:rebuttal} provides the results from alternative schedules. 
Gradually decreasing the injection along the generative process enhances realism, however, it may not accurately represent the content.
Conversely, gradually increasing the injection better preserves the content but results in more artifacts. We kept the total amount of injection fixed in this experiment.


% \section{Other diffusion-based concurrent work}
% \fref{fig:rebuttal} (a) shows the superiority of our method in reflecting the style and preserving the content compared to DiffuseIT. \cite{kwon2022diffuseIT} Furthermore, DiffuseIT requires extra supervision using DINO while ours simply modify the intermediate variables. 




\section{More related work}
After \cite{ho2020denoising,song2020score} proposed a universal approach for Diffuson models (DMs), subsequent works have focused on controlling the generative process of DMs ~\cite{zhang2023adding,parmar2023zero,li2023gligen,couairon2022diffedit,gal2022image,yang2022paint,kumari2022multi,xie2022smartbrush,choi2021ilvr,meng2021sdedit,avrahami2022blended,mokady2022null,kim2021diffusionclip,wallace2022edict}. Especially, \cite{park2023unsupervised,kwon2022diffusion,zhu2023boundary,tumanyan2022plug,baranchuk2021label} have uncovered the role of intermediate feature maps of diffusion models and utilized it for image editing, segmentation, and translation. However, we are the first to analyze the role of the latent variables $\vx_t$ in DMs and apply it to style transfer.

The research on controlling the generative process has been done in other generative models such as GANs~\cite{goodfellow2020generative}. \cite{gatys2015neural,isola2017image} introduce style transfer and image-to-image translation with GANs and there have been a number of works that focused on the style of images ~\cite{hoffman2018cycada,choi2020stargan,choi2018stargan,yoo2019photorealistic,baek2021rethinking,park2019semantic,wang2018high}. After StyleGAN~\cite{karras2019style,karras2018progressive,karras2020analyzing}, more diverse methodologies have been proposed~\cite{kim2021exploiting,karras2020analyzing,choi2018stargan,kim2021exploiting,chong2022jojogan}. However, most of them require training.

% Research on image editing through the manipulation of semantic latent space has been done in other generative models such as GANs.~\cite{goodfellow2020generative,ling2021editgan,harkonen2020ganspace,chefer2021image,shen2020interfacegan,yuksel2021latentclr,patashnik2021styleclip,gal2021stylegan,dai2019style} 
% There have been a number of works that renovate GANs focusing on styles.~\cite{huang2017arbitrary,gatys2016image,dumoulin2016learned,chen2017stylebank} And it is known that a semantic latent space is available for style transfers.~\cite{huang2017arbitrary,yanai2017conditional,an2020real,huang2018multimodal,johnson2016perceptual,lin2021drafting,kim2021exploiting,karras2020analyzing,choi2018stargan,kim2021exploiting,chong2022jojogan} However, most of them require training. Note that \ours{} does not.

\section{Stable diffusion experiment details}
\label{supple:stable}

We provide more details of experiments with Stable diffusion. In \fref{fig:stablediffusion}, we use conditional random sampling with Stable diffusion v2.  In order to apply \ours{} on Stable diffusion, there are 3 options with conditional guidance. 1) content injection only with unconditional output, 2) content injection only with conditional output, 3) content injection with both conditional/unconditional outputs. 
We noticed that using only the unconditional output for content injection resulted in poor outcomes, while the other two options produced similar results. Thus, we used only the conditional output for content injection in \fref{fig:stablediffusion}.

Moving on to the implementation details for Stable diffusion, we set the scale to 9.0, used 50 steps for DDIM sampling, and employed the following prompts: for style image, ``a highly detailed epic cinematic concept art CG render digital painting artwork: dieselpunk steaming robot" and for content image: ``digital painting artwork: a cube-shaped robot with big wheels", for style image: ``8k, wallpaper car" and for content image: ``concept, 8k, wallpaper sports car, ferrari bg", for style image: ``a realistic photo of a woman." and 
for content image, ``a realistic photo of a muscle man.", style image: ``A digital illustration of a small town, 4k, detailed, animation, fantasy" and content image: ``A digital illustration of a dense forest, trending in artstation, 4k, fantasy."


% \input{iccv2023AuthorKit/dt_scaling}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







% \begin{figure}[t]
%     \centering
%     \includegraphics[width=1\linewidth]{./figures/warigari_qual_v2.pdf}
%     % \vspace{-10pt}
%     \vspace{-2.0em}
%     \caption{\textbf{Qualitative results of \dtscaling{}}}
%     % \caption{Overview of Asyrp++}
%     % \vspace{-1em} %공간부족해지면 넣기.
%     \label{fig:warigari_qual}
% \end{figure}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{./figures/swapping_autoencoder_comparison.pdf}
    \captionof{figure}{\textbf{Qualitative comparison of content injection on FFHQ.} \ours{} is shown to be effective in reflecting content elements while preserving overall style elements. }
    \label{fig:supple_swapping_autoencoder}
    \vspace{-1em}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{./figures/stylemapgan_comparison.pdf}
    \captionof{figure}{\textbf{Qualitative comparison of local style mixing on CelebA-HQ.} Despite providing StyleMapGan with detailed segmentation guidance, there are noticeable artifacts in the resulting images, especially at the border lines of the mask. Furthermore, due to the differences in pose between the content and style images, StyleMapGan struggles to seamlessly integrate the two images, resulting in less than optimal outcomes.}
    \label{fig:supple_stylemapgan}
    \vspace{-1em}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{./figures/styletransfer_comparison.pdf}
    \captionof{figure}{\textbf{Qualitative comparison of style transfer with artistic references on CelebA-HQ.} \ours{} allows using images from unseen domain as style images, enabling style transfer with artistic references. \ours{} produces harmonization-like effect without severe content distortion. Some styles are better reflected by \ours{}  than the others.}
    \label{fig:supple_styletransfer_comparison}
    \vspace{-1em}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=0.7\linewidth]{./figures/supp_diffuseIT_v3.pdf}
    \captionof{figure}{\textbf{More qualitative comparison with DiffuseIT.} \ours{} excels in fully and naturally reflecting the style color without creating artificial contrast, particularly when there is a significant gap between the content color and the style color (e.g., black and white). In contrast, DiffuseIT may not fully capture the style color in such cases.}
    \label{fig:supple_diffuseIT}
    \vspace{-1em}
\end{figure*}


\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{./figures/supple_celeba.pdf}
    \captionof{figure}{Qualitative results of content injection on CelebA-HQ.}
    \label{fig:supple_celeba}
    \vspace{-1em}
\end{figure*}
\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{./figures/supple_celeba_mask.pdf}
    \captionof{figure}{Qualitative results of local editing on CelebA-HQ.}
    \label{fig:supple_celeba_mask}
    \vspace{-1em}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{./figures/supple_afhq.pdf}
    \captionof{figure}{Qualitative results of content injection on AFHQ. }
    \label{fig:supple_afhq}
    \vspace{-1em}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{./figures/supple_metface.pdf}
    \captionof{figure}{Qualitative results of content injection on \metfaces{}.}
    \label{fig:supple_metface}
    \vspace{-1em}
\end{figure*}


\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{./figures/supple_church.pdf}
    \captionof{figure}{Qualitative results of content injection on LSUN-church.}
    \label{fig:supple_church}
    \vspace{-1em}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{./figures/supple_bedroom.pdf}
    \captionof{figure}{Qualitative results of content injection on LSUN-bedroom.}
    \label{fig:supple_bedroom}
    \vspace{-1em}
\end{figure*}


\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{./figures/style_transfer_more.pdf}
    \captionof{figure}{Qualitative results of style transfer with artistic references on CelebA-HQ.}
    \label{fig:supple_style_transfer_more}
    \vspace{-1em}
\end{figure*}


\clearpage

% \ifx \supp \undefined
%     {\small
%     \bibliographystyle{ieee_fullname}
%     \bibliography{egbib}
%     }
% \end{document}