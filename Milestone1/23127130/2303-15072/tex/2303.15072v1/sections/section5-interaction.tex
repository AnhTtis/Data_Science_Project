\section{Interaction of Neurons}

%Based on the previous findings, we can summarize that storing neurons and triggering neurons contain the token information and position information respectively at $t = T - 1$. Next, we want to discuss how the model combines these two information to activate the outputting neurons at $t = T$. %Here, we also state our conclusion first, and then explain the experiment details to support our statement. \textbf{Finding 5: Triggering neurons can control whether storing neurons can transfer its information to the outputting neurons.}

%\subsection{Storing neurons can influence outputting neurons only when $r[store]$ is large and $z[output]$ is small}

%Next, we want to discuss, under what circumstances, the information that originally existed in the storage neuron before $t = T$ can be successfully passed to the outputting neuron at $t = T$?
In this section, we want to discuss how the storing neurons and triggering neurons interact to activate the outputting neurons at $t = T$.
We start from a side-findings that, although the GRU decoder takes the previous state $h_{t-1}$ and the new embedded token $x_{t}$ (as shown in Figure \ref{structure}) as two inputs,  $x_{t}$'s role is negligible in token-positioning as we find that the positioning accuracy remains 98.0\% when all $x_t$ are replaced by random tokens. %This means that all the information needed to control the token-positioning task is stored in $h_t$.
Consequently, we can modify the equation of GRU by eliminating the effects from external inputs $x$ and the constant bias terms to create a simplified version as Equation \ref{GRU'}: % , based on our \emph{Finding 5}.
%The original formulation of GRU can then be simplified to Eq. \ref{GRU'}:

% \begin{small}
%\noindent\begin{minipage}{0.5\textwidth}
\begin{equation}
GRU\begin{cases}
    z_t = \sigma(W_{z}x_t + U_{z}h_{t-1} + b_z)  \\
    r_t = \sigma(W_{r}x_t + U_{r}h_{t-1} + b_r) \\
    \widetilde{h_t} = \text{tanh}(W_{h}x_t + U_{h}(r_t \odot h_{t-1}) + b_h)  \\ 
    h_t = z_t \odot h_{t-1} + (1 - z_t) \odot \widetilde{h}_t \\
    \end{cases} 
    \label{GRU}
\end{equation} 
%\end{minipage}%
%\begin{minipage}{0.5\textwidth}
\begin{equation}
GRU^{'}\begin{cases}
    z_t = \sigma(U_{z}h_{t-1})  \\
    r_t = \sigma(U_{r}h_{t-1}) \\
    \widetilde{h_t} = \text{tanh}(U_{h}(r_t \odot h_{t-1})) &  \\
    h_t = z_t \odot h_{t-1} + (1 - z_t) \odot \widetilde{h}_t\\
    \end{cases}
    \label{GRU'}
\end{equation}
%\end{minipage}\vskip1em
\begin{comment}
\begin{equation*}
\begin{aligned}
GRU\begin{cases}
    z_t = \sigma(W_{z}x_t + U_{z}h_{t-1} + b_z)  \\
    r_t = \sigma(W_{r}x_t + U_{r}h_{t-1} + b_r) \\
    \widetilde{h_t} = \text{tanh}(W_{h}x_t + U_{h}(r_t \odot h_{t-1}) + b_h)  \\ 
    h_t = z_t \odot h_{t-1} + (1 - z_t) \odot \widetilde{h}_t \\
    \end{cases} &
    \quad
GRU^{'}\begin{cases}
    z_t = \sigma(U_{z}h_{t-1})  \\
    r_t = \sigma(U_{r}h_{t-1}) \\
    \widetilde{h_t} = \text{tanh}(U_{h}(r_t \odot h_{t-1})) &  \\
    h_t = z_t \odot h_{t-1} + (1 - z_t) \odot \widetilde{h}_t\\
    \end{cases} &  \\
    \label{GRU'}
& (2) & (3)
%\label{GRU_Formula}
\end{aligned}
\end{equation*}
\end{comment}
% \end{small}
% \caption{The original formulation of GRU and its simplified version}


where $z_t, r_t, h_t, \widetilde{h}_t$ are the \emph{update gate}, \emph{reset gate}, \emph{activation}, and \emph{candidate activation}, respectively. 
%Given the fact that $x_t$ has very few influence, and the bias term can also be omitted because it is a constant at all times, we can simplify the formula to $GRU^{'}$ (equation \ref{GRU'}). 
We can then view the operation inside the $\sigma(\cdot)$ function as a linear transformation of $h_{t-1}$ to $z_t, r_t$ or $h_t$. Therefore, $U_z, U_r, U_h$ can be regarded as the weights corresponding to the importance of neurons.
We already know that for $h_T[output]$ to generate the target token at step T, it needs to be significantly different from $h_{T-1}[output]$ (otherwise the target token will appear at time $T-1$), meaning that $z_t[output]$ has to be small and $\hat{h}_t[output]$ needs to be far away from zero according to the last part of Equation \ref{GRU'}.
Furthermore, in order to output the correct token, storing neurons need to be effective. It implies that $r_T[store]$ needs to be far from zero so that $h_{T-1}[store]$ can be influential. % when $r_t[store]$ is far from zero, where $r$ has a range of 0 to 1. Secondly, $h_t[output]$ can only be updated by $\hat{h}_t[output]$ when $z_t[output]$ is small, where $z$ also has a range of 0 to 1. 
To sum up, only with large $r[store]$ and small $z[output]$, the token information can be passed from storing neurons to outputting neurons.

Then, we state our hypothesis as follows: it is the \emph{set of triggering neurons} that increases $r[store]$ and decreases $z[output]$ at the same time in order to prompt storing neurons to exert influence on outputting neurons.
We verify this hypothesis by conducting the following experiments. We mask out all neurons \emph{except triggering neurons} in $h_{t=T-1}$ to examine its impact $U_zh_{T-1}[output]$, and found that the values becomes negative, which causes $z_t[output] = \sigma({U_zh_{T-1}})[output]$ close to zero. We conducted similar experiments to verify that the triggering neurons can indeed increase $r[store]$.
Take the token "i" as an example, when triggering neurons are masked, the average of $z[output]$ increases from 0.067 to 0.410, and $r[store]$ drops from 0.860 to 0.594. It shows that although triggering neurons only occupy a small number of neurons, they can play most of the roles. More details are shown in Appendix D.

%As shown in Figure \ref{z_impact} that triggering neurons is the main reason for making z smaller. Similarly, triggering neurons can increase $r[store]$, and we leave the detailed explanation in Appendix D.
%We can further visualize the neuron interaction process  in Figure \ref{interaction}. 


\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/appendix_trig_vis.png}
    \caption{Visualization of neurons interaction. (a) Multiplying $U_z$ and triggering neuron decreases $z_{output}$. (b) Multiplying $U_r$ and triggering neuron increases $r_{store}$. (c) Large $r_{store}$ causes $h_{store}$ to become influential. (d) Small $z_{output}$ let $h_t[output]$ be updated by $\hat{h}$}
    \label{interaction}
\end{figure}

\begin{comment}
\begin{figure}[h]
\begin{center}
         \centering
         \includegraphics[width=0.5\textwidth]{figures/appendix_z_impact.png}
          \caption{X-axis are top outputting neurons. Y-axis is the value of $(U_zh)[x]$ when only left triggering neurons (blue bars) or only left other neurons (red bars). Most blue bar values is negative represents that triggering neurons can decrease $z[output]$ while other (red) cannot.}
    \end{center}
    \label{z_impact}
\end{figure}

\end{comment}
