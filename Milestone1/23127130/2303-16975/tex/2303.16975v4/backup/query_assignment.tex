\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{graphicx}
\newcommand*{\Perm}[2]{{}^{#1}\!P_{#2}}%
\usepackage {dsfont}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }
\DeclareMathOperator*{\argmax}{arg\,max}

\title{Task tracking and grounding from egocentric videos}
% \author{Rishi Hazra}
% \date{November 2022}

\begin{document}
\maketitle
\begin{abstract}
Tracking actions and state changes from an egocentric view is essential for assisting people with day-to-day activities. Consider, for instance, an agent assisting an user to prepare a recipe from a cookbook. The agent would be required to (i) generate the steps of the recipe (\textit{plan generation}) and (ii) track the user's actions to see if the plan was successfully executed (\textit{plan verification}). We formulate this as a Video Entailment problem, wherein, given an egocentric video of a agent/human performing a task (premise) and a Natural Language task description (hypothesis), the objective is to learn a model to track whether the given task was successfully executed in the video. An ideal model must also be able to seamlessly generalize to novel compositions (of actions and objects) unseen during training.

To this end, we generate a novel Vision-Language dataset on the AI2-THOR simulator to study compositional and abstraction-based generalization. Our dataset provides effective evaluation measures in a controlled setting, while closely reflecting the diversity of real-world events. We implement and train a variety of end-to-end models based on existing state-of-the-art approaches. We empirically demonstrate that neural models suffer from overfitting and cannot effectively generalize to novel compositions of actions, objects and scenes. To address this problem, we propose an end-to-end Neuro-Symbolic (NeSy) framework that performs plan generation and verification. At the heart of our approach is the hypothesis that symbolic models are good at capturing compositional substructure, while neural models are good at learning representations from sensory data. 
% In general, existing NeSy-based methods are limited to datasets with static objects and fully-observable states. We extend 
\end{abstract}

% \maketitle
\section{Introduction}
\label{section:introduction}
\paragraph{Text Module:} We train a t5-small transformer module to generate partial order-order plans for each hypothesis ($h \in \mathcal{H}$), represented by a directed acyclic graph $G = (V,E)$, where vertices $n_i \in V$ represent queries, and edges $e_i \in E$ are ordering constraints. To train the transformer, the partial-order plan is represented in DOT language. The queries are represented in a domain specific language (DSL), wherein each query captures a state transition (StateQuery) or a relation (RelationQuery). For instance, StateQuery($apple, hot$) tracks whether the state of $apple$ changed to $hot$ at a specific stage in the video premise. During training, the weights of the t5-small model is kept frozen (as represented by the dotted lines in Figure~\ref{fig:nesy_module}).

\paragraph{Vision Module:} The input video premise $v$ is decomposed into segments of length $16s$. Each segment is then processed using a Multiscale Vision Transformer (MViT) to obtain segment features $\in \mathds{R}^{768}$. After adding a positional encoding to each segment feature (based on their temporal order), it is fed to a Multihead Attention layer to obtain contextual segment features $\langle x_t | 0 \leq t \leq S-1 \rangle$, where, each $x_t \in \mathds{R}^d$ is d-dimensional feature representing a temporal segment in the video. The MViT is pretrained on the Kinetics 400 dataset, and we freeze its weights during the training process (as represented by the dotted lines in Figure~\ref{fig:nesy_module}).

\paragraph{Query Module:} As stated, the nodes in graph $G$ represent queries in a DSL. Queries can be of two types: (i) StateQuery(\textit{arg1, arg2}), (ii) RelationQuery(\textit{arg1, arg2, arg3}). The former captures state transitions (\textit{arg2: hot, cold, slice, clean}) of the target object (\textit{arg1}), and the latter captures relations (\textit{arg3: in, leftof, rightof}) between target objects (\textit{arg1, arg2}). For instance, when a node query $n_i =$ StateQuery(\textit{apple, hot}) is executed on a segment feature $x_t$, a neural network (Stateof) computes $p(n_i, x_t) \in [0,1]$ signifying the probability of state of \textit{apple} transitioning to \textit{hot} in segment $x_t$. As shown in Figure~\ref{fig:nesy_module}, the inputs to the neural network are segment feature ($x_t$) and token embedding of the arguments ($\{apple, hot\}$). Upon executing all node queries $n_i \in V$ on features $\langle x_t | 0 \leq t \leq S-1 \rangle$, we obtain a probability $p(h) = \prod_{n_i, x_t} p(n_i, x_t)$ signifying the probability of the premise $v$ entailing the hypothesis $h$

\begin{figure*}
    \centering
    \includegraphics[width=0.6\paperwidth]{nesy_module.png}
    \caption{Dotted lines represent modules with frozen weights.}
    \label{fig:nesy_module}
\end{figure*}


\section{Query Assignment Problem}
\label{section:query_assignment}

Given a processed input sample comprising:
\begin{itemize}
    \item a temporal sequence $\langle x_t | 0 \leq t \leq S-1 \rangle$ where, each $x_t \in \mathds{R}^d$ is d-dimensional feature representing a temporal segment in the video. The number of feature representations $=S$.
    \item partial-order plan for hypothesis ($h$) represented by a directed acyclic graph $G = (V,E)$, where vertices $n_i \in V$ represent queries, and edges $e_i \in E$ are ordering constraints. The number of vertices $|V|=N$. We assume that $S \geq N$. 
\end{itemize}

 On executing a node-query $n_i$ on feature representation $x_t$, we obtain a probability $p(n_i, x_t) \in [0,1]$. The probability of entailment $p(h)$ is the product of $p(n_i, x_t)$ over a specific assignment of $N$ queries over $S$ features\footnote{For instance, given $S=3$ and $N=2$, one possible value of $p(h) = p(n_0, x_0) \times p(n_1, x_1)$.}. Our objective is to obtain an assignment $Y \in \{0,1\}^{N \times S}$ such that probability $p(h)$ is maximized. 

We formulate it as a linear optimization problem (over log probabilities) of the form (Figure~\ref{fig:constraints}):

\begin{align*}
    & \text{Objective:} \;\; \max_{Y \in \{0,1\}^{N \times S}} \sum_{i,j} \log p(n_i, x_j) Y_{ij}; && \text{subject to} \\
    % & \sum_{i=0}^{N-1} Y_{ij} \in \{0, 1\} \; \forall \; 0 \leq j \leq S-1; && \text{at most one query per feature}\\
    & \sum_{ij}Y_{ij} = N; && \text{all queries must be executed}
\end{align*}

Denoting by $V^{*}(n_{0:N-1}, x_{0:S-1})$, the solution of the optimization problem, let $V^{*}(n_{i:N-1}, x_{t:S-1})$ be the maximum log probability of querying nodes $\{n_i\}_{i}^{N-1}$ on temporal sequence $\langle x_t | t \leq S-1 \rangle$. The optimal solution can be computed using the following equation:
\begin{equation}
    V^{*}(n_{i:N-1}, x_{t:S-1}) = \max \big[ \log p(n_i, x_t) + V^{*}(n_{i+1:N-1}, x_{t+1:S-1}),  V^{*}(n_{i:N-1}, x_{t+1:S-1}) \big]
    \label{Eq:dp}
\end{equation}


\begin{figure*}
    \centering
    \includegraphics[width=0.5\paperwidth]{constraints2.png}
    \caption{Constraints in Query assignment problem. [Left]: All queries must be executed; [Right]: Ordering constraints between from topological sorting.}
    \label{fig:constraints}
\end{figure*}

Since optimal solution requires decomposition into simpler sub-problems, this can be solved using dynamic programming. Note, that the aforementioned equation guarantees a solution only for graphs where the nodes are linearly sequenced. However, as shown in Figure~\ref{fig:nesy_module}, we have partial ordering (i.e. $n_1$ \& $n_2$ can be executed in any order). To this end, we use topological sorting to obtain all possible linear sequences of the actions. We then maximize the probability over all sequences using the Equation~\ref{Eq:dp} (i.e. if $n_u < n_v$ in the sorted sequence, $n_u$ should be executed before $n_v$).


% we introduce an additional \textit{ordering} constraint that decomposes the graph nodes into $L$ levels and imposes ordering constraints between them, while allowing nodes within a level to be executed in any order. Denoting mapping $l: n_i \mapsto l_i$ which assigns a level to each node, all queries corresponding to nodes in $l_i$ must be executed before those in $l_j$ if $i < j$. 
\begin{align*}
    & n_u < n_v \implies Y_{uj} \neq 1 \; \forall \; j > \argmax_{k} Y_{vk}; && \text{ordering constraints from topological sorting}
\end{align*}

%  Now, we calculate the value function over levels instead of nodes, given as:

% \begin{equation*}
%     V^{*}(l_{i:L-1}, x_{t:S-1}) = \max_k \big[\log p(l_i, x_{t:k}) + V^{*}(l_{i+1:L-1}, x_{k+1:S-1})) \big]
% \end{equation*}

% Here, $p(l_i, x_{t:k})$ denotes the probability of executing all queries in level $l_i$ on temporal sequence $\{x_t\}_{t}^{k}$. For $k \in \{t+c_i, \dots, S-1\}$, we obtain multiple values of $p(l_i, x_{t:k})$ corresponding to $\Perm{c_i}{k-t}$ permutations of queries in level $l_i$ over features $\{x_t\}_{t}^{S-1}$. Here, $c_i$ is the number of nodes in level $l_i$. The number of permutations can be reduced by pre-computing an upper limit of $k$ given as: $\bar{k} = S - 1 - \sum_{t=i+1}^{L-1} c_{i}$, such that we now have $\Perm{c_i}{\bar{k}-t}$ permutations.

\end{document}
