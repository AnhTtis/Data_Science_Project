% \begin{abstract}
%  Towards next generation of assistants, our goal is 
%  \rd{TODO: abstract}
%  to make progress towards egocentric agents capable of tracking and verifying everyday tasks specified in natural language. Such agents should be able to reason about various ways of doing multi-step tasks, decompose the tasks into relevant actions, state changes, object interactions, and any necessary causal relationships. To that end, we propose a benchmark and dataset called Egocentric Task Verification (EgoTV) using a photo-realistic, embodied simulator called AI2-THOR. EgoTV contains multi-step tasks with ordering constraints and abstracted task descriptions with the omission of low-level task details. We also introduce a novel Neuro-Symbolic Grounding (NSG) approach to enable the core reasoning capability for EgoTV. We demonstrate NSG's capability on our synthetic EgoTV dataset and a real-world dataset derived from Crosstask. Our contributions include EgoTV, NSG, and the release of both datasets and models for future egocentric task tracking and verification research.
% \end{abstract}

\begin{abstract}
To enable progress towards egocentric agents capable of understanding everyday tasks specified in natural language, we propose a benchmark and a synthetic dataset called Egocentric Task Verification (\etv). \etv contains multi-step tasks with multiple sub-task decompositions, state changes, object interactions, and sub-task ordering constraints, in addition to abstracted task descriptions that contain only partial details about ways to accomplish a task. We also propose a novel Neuro-Symbolic Grounding (NSG) approach to enable the causal, temporal, and compositional reasoning of such tasks. We demonstrate NSG's capability towards task tracking and verification on our \etv dataset and a real-world dataset derived from CrossTask~\cite{cross_task} (CTV). Our contributions include the release of the \etv and CTV datasets, and the NSG model for future research on egocentric assistive agents. \etv's source code is publicly available.
% \footnote{ \url{https://github.com/facebookresearch/EgoTV}}
\end{abstract}