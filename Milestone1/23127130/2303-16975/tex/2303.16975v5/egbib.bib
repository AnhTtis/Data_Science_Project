@article{ai2thor,
  author={Eric Kolve and Roozbeh Mottaghi and Winson Han and
          Eli VanderBilt and Luca Weihs and Alvaro Herrasti and
          Daniel Gordon and Yuke Zhu and Abhinav Gupta and
          Ali Farhadi},
  title={{AI2-THOR: An Interactive 3D Environment for Visual AI}},
  journal={arXiv},
  year={2017}
}

@inproceedings{zhou2018towards,
  title={Towards automatic learning of procedures from web instructional videos},
  author={Zhou, Luowei and Xu, Chenliang and Corso, Jason},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{huang2019neural,
  title={Neural task graphs: Generalizing to unseen tasks from a single video demonstration},
  author={Huang, De-An and Nair, Suraj and Xu, Danfei and Zhu, Yuke and Garg, Animesh and Fei-Fei, Li and Savarese, Silvio and Niebles, Juan Carlos},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8565--8574},
  year={2019}
}

@inproceedings{shen2021learning,
  title={Learning to segment actions from visual and language instructions via differentiable weak sequence alignment},
  author={Shen, Yuhan and Wang, Lu and Elhamifar, Ehsan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10156--10165},
  year={2021}
}

@article{mao2023action,
  title={Action Dynamics Task Graphs for Learning Plannable Representations of Procedural Tasks},
  author={Mao, Weichao and Desai, Ruta and Iuzzolino, Michael Louis and Kamra, Nitin},
  journal={arXiv preprint arXiv:2302.05330},
  year={2023}
}

@inproceedings{qian2022svip,
  title={SVIP: Sequence VerIfication for Procedures in Videos},
  author={Qian, Yicheng and Luo, Weixin and Lian, Dongze and Tang, Xu and Zhao, Peilin and Gao, Shenghua},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19890--19902},
  year={2022}
}

@inproceedings{lin2022learning,
  title={Learning to recognize procedural activities with distant supervision},
  author={Lin, Xudong and Petroni, Fabio and Bertasius, Gedas and Rohrbach, Marcus and Chang, Shih-Fu and Torresani, Lorenzo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13853--13863},
  year={2022}
}

@inproceedings{bansal2022my,
  title={My View is the Best View: Procedure Learning from Egocentric Videos},
  author={Bansal, Siddhant and Arora, Chetan and Jawahar, CV},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XIII},
  pages={657--675},
  year={2022},
  organization={Springer}
}

@inproceedings{fathi2013modeling,
  title={Modeling actions through state changes},
  author={Fathi, Alireza and Rehg, James M},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2579--2586},
  year={2013}
}

@inproceedings{tang2019coin,
  title={Coin: A large-scale dataset for comprehensive instructional video analysis},
  author={Tang, Yansong and Ding, Dajun and Rao, Yongming and Zheng, Yu and Zhang, Danyang and Zhao, Lili and Lu, Jiwen and Zhou, Jie},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1207--1216},
  year={2019}
}

@INPROCEEDINGS{clevr_dataset,
  author={Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Zitnick, C. Lawrence and Girshick, Ross},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning}, 
  year={2017},
  volume={},
  number={},
  pages={1988-1997},
  doi={10.1109/CVPR.2017.215}}

@article{visual_genome,
author = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A. and Bernstein, Michael S. and Fei-Fei, Li},
title = {Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},
year = {2017},
issue_date = {May       2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {123},
number = {1},
issn = {0920-5691},
url = {https://doi.org/10.1007/s11263-016-0981-7},
doi = {10.1007/s11263-016-0981-7},
journal = {Int. J. Comput. Vision},
month = {may},
pages = {32–73},
numpages = {42}
}

@INPROCEEDINGS{gqa_dataset,
  author={Hudson, Drew A. and Manning, Christopher D.},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering}, 
  year={2019},
  volume={},
  number={},
  pages={6693-6702},
  doi={10.1109/CVPR.2019.00686}}

@inproceedings{clevrer,
  author    = {Kexin Yi and
               Chuang Gan and
               Yunzhu Li and
               Pushmeet Kohli and
               Jiajun Wu and
               Antonio Torralba and
               Joshua B. Tenenbaum},
  title     = {{CLEVRER:} Collision Events for Video Representation and Reasoning},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  url       = {https://openreview.net/forum?id=HkxYzANYDB},
  timestamp = {Thu, 07 May 2020 17:11:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/YiGLK0TT20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{flickr30k,
  author = {{Plummer}, B. A. and {Wang}, L. and {Cervantes}, C. M. and {Caicedo}, J. C. and {Hockenmaier}, J. and {Lazebnik}, S.},
  biburl = {https://www.bibsonomy.org/bibtex/2d7874dca41004be97d7fc817fa9477c7/nosebrain},
  booktitle = {2015 IEEE International Conference on Computer Vision (ICCV)},
  description = {Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models - IEEE Conference Publication},
  doi = {10.1109/ICCV.2015.303},
  interhash = {0d506ec7cb5b56cf2437fc495a0df9f3},
  intrahash = {d7874dca41004be97d7fc817fa9477c7},
  issn = {2380-7504},
  keywords = {flickr localisation nlp object paper-dzhi text},
  month = dec,
  pages = {2641-2649},
  timestamp = {2020-01-20T10:04:10.000+0100},
  title = {Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models},
  url = {https://ieeexplore.ieee.org/document/7410660},
  year = 2015
}

@InProceedings{charades_dataset,
author="Sigurdsson, Gunnar A.
and Varol, G{\"u}l
and Wang, Xiaolong
and Farhadi, Ali
and Laptev, Ivan
and Gupta, Abhinav",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="510--526",
isbn="978-3-319-46448-0"
}


@ARTICLE{epic_kitchens,
   title={The EPIC-KITCHENS Dataset: Collection, Challenges and Baselines},
   author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria  and Fidler, Sanja and 
           Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan 
           and Perrett, Toby and Price, Will and Wray, Michael},
   journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
   year={2021},
   volume={43},
   number={11},
   pages={4125-4141},
   doi={10.1109/TPAMI.2020.2991965}
} 

 @inproceedings{action_genome,
          title={Action Genome: Actions As Compositions of Spatio-Temporal Scene Graphs},
          author={Ji, Jingwei and Krishna, Ranjay and Fei-Fei, Li and Niebles, Juan Carlos},
          booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
          pages={10236--10247},
          year={2020}
        }

@inproceedings{cater_dataset,
    title = {{CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning}},
    author = {Girdhar, Rohit and Ramanan, Deva},
    booktitle = {ICLR},
    year = 2020
}

@INPROCEEDINGS{movie_qa,  author={Tapaswi, Makarand and Zhu, Yukun and Stiefelhagen, Rainer and Torralba, Antonio and Urtasun, Raquel and Fidler, Sanja},  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={MovieQA: Understanding Stories in Movies through Question-Answering},   year={2016},  volume={},  number={},  pages={4631-4640},  doi={10.1109/CVPR.2016.501}}

@article{snli_ve_dataset,
  title={Visual Entailment: A Novel Task for Fine-grained Image Understanding},
  author={Xie, Ning and Lai, Farley and Doran, Derek and Kadav, Asim},
  journal={arXiv preprint arXiv:1901.06706},
  year={2019}
}

@article{violin_dataset,
  title={Violin: A Large-Scale Dataset for Video-and-Language Inference},
  author={J. Liu and Wenhu Chen and Yu Cheng and Zhe Gan and Licheng Yu and Yiming Yang and Jingjing Liu},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  pages={10897-10907}
}


@InProceedings{causal_vid_qa,
    author    = {Li, Jiangtong and Niu, Li and Zhang, Liqing},
    title     = {From Representation to Reasoning: Towards both Evidence and Commonsense Reasoning for Video Question-Answering},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022}
}


@INPROCEEDINGS{social_iq,  author={Zadeh, Amir and Chan, Michael and Liang, Paul Pu and Tong, Edmund and Morency, Louis-Philippe},  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Social-IQ: A Question Answering Benchmark for Artificial Social Intelligence},   year={2019},  volume={},  number={},  pages={8799-8809},  doi={10.1109/CVPR.2019.00901}}


@inproceedings{mscoco_dataset,
  author    = {Tsung{-}Yi Lin and
               Michael Maire and
               Serge J. Belongie and
               James Hays and
               Pietro Perona and
               Deva Ramanan and
               Piotr Doll{\'{a}}r and
               C. Lawrence Zitnick},
  editor    = {David J. Fleet and
               Tom{\'{a}}s Pajdla and
               Bernt Schiele and
               Tinne Tuytelaars},
  title     = {Microsoft {COCO:} Common Objects in Context},
  booktitle = {Computer Vision - {ECCV} 2014 - 13th European Conference, Zurich,
               Switzerland, September 6-12, 2014, Proceedings, Part {V}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8693},
  pages     = {740--755},
  publisher = {Springer},
  year      = {2014},
  url       = {https://doi.org/10.1007/978-3-319-10602-1\_48},
  doi       = {10.1007/978-3-319-10602-1\_48},
  timestamp = {Thu, 23 Jun 2022 19:55:44 +0200},
  biburl    = {https://dblp.org/rec/conf/eccv/LinMBHPRDZ14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{tvqa_dataset,
    title = "{TVQA}: Localized, Compositional Video Question Answering",
    author = "Lei, Jie  and
      Yu, Licheng  and
      Bansal, Mohit  and
      Berg, Tamara",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1167",
    doi = "10.18653/v1/D18-1167",
    pages = "1369--1379"
}

@inproceedings{howto100m,
   title={How{T}o100{M}: {L}earning a {T}ext-{V}ideo {E}mbedding by {W}atching {H}undred {M}illion {N}arrated {V}ideo {C}lips},
   author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
   booktitle={ICCV},
   year={2019},
}

@INPROCEEDINGS{cross_task,  author={Zhukov, Dimitri and Alayrac, Jean-Baptiste and Cinbis, Ramazan Gokberk and Fouhey, David and Laptev, Ivan and Sivic, Josef},  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Cross-Task Weakly Supervised Learning From Instructional Videos},   year={2019},  volume={},  number={},  pages={3532-3540},  doi={10.1109/CVPR.2019.00365}}

@INPROCEEDINGS{i3d,  author={Carreira, João and Zisserman, Andrew},  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset},   year={2017},  volume={},  number={},  pages={4724-4733},  doi={10.1109/CVPR.2017.502}}

@inproceedings{glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}

@inproceedings{proscript,
    title = "pro{S}cript: Partially Ordered Scripts Generation",
    author = "Sakaguchi, Keisuke  and
      Bhagavatula, Chandra  and
      Le Bras, Ronan  and
      Tandon, Niket  and
      Clark, Peter  and
      Choi, Yejin",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.184",
    doi = "10.18653/v1/2021.findings-emnlp.184",
    pages = "2138--2149"
}

@inproceedings{cophy_dataset,
title={CoPhy: Counterfactual Learning of Physical Dynamics},
author={Fabien Baradel and Natalia Neverova and Julien Mille and Greg Mori and Christian Wolf},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SkeyppEFvS}
}

@inproceedings{regionclip,
  title={Regionclip: Region-based language-image pretraining},
  author={Zhong, Yiwu and Yang, Jianwei and Zhang, Pengchuan and Li, Chunyuan and Codella, Noel and Li, Liunian Harold and Zhou, Luowei and Dai, Xiyang and Yuan, Lu and Li, Yin and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16793--16803},
  year={2022}
}

@book{integer_programming,
  title={Integer programming},
  author={Wolsey, Laurence A},
  year={2020},
  publisher={John Wiley \& Sons}
}

@inproceedings{glip,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10965--10975},
  year={2022}
}

@Article{metric_ff,
  author = 	 {J{\"o}rg Hoffmann},
  title = 	 {The {M}etric-{FF} Planning System: Translating ``Ignoring Delete Lists'' to Numeric State Variables},
  journal = {Journal of Artificial Intelligence Research},
  year = {2003},
  volume = {20},
  pages = {291-341}
}

@STRING{jair  = "Journal of Artificial Intelligence Research"}

@inproceedings{10.5555/3326943.3327039,
author = {Yi, Kexin and Wu, Jiajun and Gan, Chuang and Torralba, Antonio and Kohli, Pushmeet and Tenenbaum, Joshua B.},
title = {Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {1039–1050},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{ged,
author = {Abu-Aisheh, Zeina and Raveaux, Romain and Ramel, Jean-Yves and Martineau, Patrick},
title = {An Exact Graph Edit Distance Algorithm for Solving Pattern Recognition Problems},
year = {2015},
isbn = {9789897580765},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0005209202710278},
doi = {10.5220/0005209202710278},
booktitle = {Proceedings of the International Conference on Pattern Recognition Applications and Methods - Volume 1},
pages = {271–278},
numpages = {8},
keywords = {Graph Matching, Classification., Pattern Recognition, Graph Edit Distance},
location = {Lisbon, Portugal},
series = {ICPRAM 2015}
}

@article{voice_assistants,
author = {Matthew B. Hoy},
title = {Alexa, Siri, Cortana, and More: An Introduction to Voice Assistants},
journal = {Medical Reference Services Quarterly},
volume = {37},
number = {1},
pages = {81-88},
year  = {2018},
publisher = {Routledge},
doi = {10.1080/02763869.2018.1404391},
    note ={PMID: 29327988},

URL = {https://doi.org/10.1080/02763869.2018.1404391},
eprint = {https://doi.org/10.1080/02763869.2018.1404391}
}
@inproceedings{word2vec,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  booktitle={arXiv preprint arXiv:1301.3781},
  year={2013}
}
@inproceedings{jia2022egotaskqa,
    title = {EgoTaskQA: Understanding Human Tasks in Egocentric Videos},
    author = {Jia, Baoxiong and Lei, Ting and Zhu, Song-Chun and Huang, Siyuan},
    booktitle = {The 36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks},
    year = {2022}
}
@inproceedings{videoclip,
  title={VideoCLIP: A Cross-Attention Model for Fast Video-Text Retrieval Task with Image CLIP},
  author={Li, Yikang and Hsiao, Jenhao and Ho, Chiuman},
  booktitle={Proceedings of the 2022 International Conference on Multimedia Retrieval},
  pages={29--33},
  year={2022}
}
@article{soldan2021mad,
	title        = {Mad: A scalable dataset for language grounding in videos from movie audio descriptions},
	author       = {Soldan, Mattia and Pardo, Alejandro and Alc{\'a}zar, Juan Le{\'o}n and Heilbron, Fabian Caba and Zhao, Chen and Giancola, Silvio and Ghanem, Bernard},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2112.00431}
}
@article{clip_hitchiker,
  title={A CLIP-Hitchhiker's Guide to Long Video Retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  journal={arXiv preprint arXiv:2205.08508},
  year={2022}
}

@article{coca,
title={CoCa: Contrastive Captioners are Image-Text Foundation Models},
author={Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
url={https://openreview.net/forum?id=Ee277P3AYC},
note={}
}

@InProceedings{llm_zero_shot_planning,
  title = 	 {Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents},
  author =       {Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {9118--9147},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR}
}


@inproceedings{nscl,
	title={{The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision}},
	author={Mao, Jiayuan and Gan, Chuang and Kohli, Pushmeet and Tenenbaum, Joshua B. and Wu, Jiajun},
	booktitle={International Conference on Learning Representations},
	year={2019},
	url={https://openreview.net/forum?id=rJgMlhRctm}
}

@inproceedings{codeaspolicies,
    title={Code as Policis: Language Model Programs for Embodied Control},
    author={Jacky Liang and Wenlong Huang and Fei Xia and Peng Xu and Karol Hausman and Brian Ichter and Pete Florence and Andy Zeng},
    booktitle={arXiv preprint arXiv:2209.07753},
    year={2022}
}

@article{progprompt,
  title={{ProgPrompt}: Generating Situated Robot Task Plans using Large Language Models}, 
  author={Ishika Singh and Valts Blukis and Arsalan Mousavian and Ankit Goyal and Danfei Xu and Jonathan Tremblay and Dieter Fox and Jesse Thomason and Animesh Garg},
  year={2022},
  eprint={2209.11302},
  archivePrefix={arXiv},
  primaryClass={cs.RO}
}

@inproceedings{innermonologue,
    title={Inner Monologue: Embodied Reasoning through Planning with Language Models},
    author={Wenlong Huang and Fei Xia and Ted Xiao and Harris Chan and Jacky Liang and Pete Florence and Andy Zeng and Jonathan Tompson and Igor Mordatch and Yevgen Chebotar and Pierre Sermanet and Noah Brown and Tomas Jackson and Linda Luu and Sergey Levine and Karol Hausman and Brian Ichter},
    booktitle={arXiv preprint arXiv:2207.05608},
    year={2022}
}

@inproceedings{youCook,
  title={Towards automatic learning of procedures from web instructional videos},
  author={Zhou, Luowei and Xu, Chenliang and Corso, Jason},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{activity_net_captions,
  title={Dense-captioning events in videos},
  author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Carlos Niebles, Juan},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={706--715},
  year={2017}
}

@article{thumos2017,
  title={The thumos challenge on action recognition for videos “in the wild”},
  author={Idrees, Haroon and Zamir, Amir R and Jiang, Yu-Gang and Gorban, Alex and Laptev, Ivan and Sukthankar, Rahul and Shah, Mubarak},
  journal={Computer Vision and Image Understanding},
  volume={155},
  pages={1--23},
  year={2017},
  publisher={Elsevier}
}
@article{Faster_rcnn,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{llms_for_translating_to_goal,
  title={Translating Natural Language to Planning Goals with Large-Language Models},
  author={Xie, Yaqi and Yu, Chen and Zhu, Tongyao and Bai, Jinbin and Gong, Ze and Soh, Harold},
  journal={arXiv preprint arXiv:2302.05128},
  year={2023}
}

@inproceedings{saycan,
    title={Do As I Can and Not As I Say: Grounding Language in Robotic Affordances},
    author={Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng},
    booktitle={arXiv preprint arXiv:2204.01691},
    year={2022}
}

@article{li2020hero,
  title={Hero: Hierarchical encoder for video+ language omni-representation pre-training},
  author={Li, Linjie and Chen, Yen-Chun and Cheng, Yu and Gan, Zhe and Yu, Licheng and Liu, Jingjing},
  journal={arXiv preprint arXiv:2005.00200},
  year={2020}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@article{nesy-survey,
  author    = {Md. Kamruzzaman Sarker and
               Lu Zhou and
               Aaron Eberhart and
               Pascal Hitzler},
  title     = {Neuro-Symbolic Artificial Intelligence: Current Trends},
  journal   = {CoRR},
  volume    = {abs/2105.05330},
  year      = {2021},
  url       = {https://arxiv.org/abs/2105.05330},
  eprinttype = {arXiv},
  eprint    = {2105.05330},
  timestamp = {Tue, 22 Mar 2022 08:12:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-05330.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{gScan,
  title={A benchmark for systematic generalization in grounded language understanding},
  author={Ruis, Laura and Andreas, Jacob and Baroni, Marco and Bouchacourt, Diane and Lake, Brenden M},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={19861--19872},
  year={2020}
}

@inproceedings{blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{socratic,
title={Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language},
author={Andy Zeng and Maria Attarian and brian ichter and Krzysztof Marcin Choromanski and Adrian Wong and Stefan Welker and Federico Tombari and Aveek Purohit and Michael S Ryoo and Vikas Sindhwani and Johnny Lee and Vincent Vanhoucke and Pete Florence},
booktitle={International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=G2Q2Mh3avow}
}

@inproceedings{VLMbag-of-words,
title={When and why Vision-Language Models behave like Bags-of-Words, and what to do about it?},
author={Mert Yuksekgonul and Federico Bianchi and Pratyusha Kalluri and Dan Jurafsky and James Zou},
booktitle={International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=KRLUvxh8uaX}
}

@inproceedings{winoground,
  title={Winoground: Probing vision and language models for visio-linguistic compositionality},
  author={Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5238--5248},
  year={2022}
}

@article{gao2020systematic,
  title={Systematic generalization on gSCAN with language conditioned embedding},
  author={Gao, Tong and Huang, Qi and Mooney, Raymond J},
  journal={arXiv preprint arXiv:2009.05552},
  year={2020}
}

@article{kuo2020compositional,
  title={Compositional networks enable systematic generalization for grounded language understanding},
  author={Kuo, Yen-Ling and Katz, Boris and Barbu, Andrei},
  journal={arXiv preprint arXiv:2008.02742},
  year={2020}
}

@inproceedings{attention_pooling,
  title={Set transformer: A framework for attention-based permutation-invariant neural networks},
  author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
  booktitle={International conference on machine learning},
  pages={3744--3753},
  year={2019},
  organization={PMLR}
}

@article{lstm,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@article{closure,
    author = {Bogin, Ben and Subramanian, Sanjay and Gardner, Matt and Berant, Jonathan},
    title = "{Latent Compositional Representations Improve Systematic Generalization in Grounded Question Answering}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {9},
    pages = {195-210},
    year = {2021},
    month = {03},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00361},
    url = {https://doi.org/10.1162/tacl\_a\_00361},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00361/1924225/tacl\_a\_00361.pdf},
}

@inproceedings{dcl,
title={Grounding Physical Concepts of Objects and Events Through Dynamic Visual Reasoning},
author={Zhenfang Chen and Jiayuan Mao and Jiajun Wu and Kwan-Yee Kenneth Wong and Joshua B. Tenenbaum and Chuang Gan},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=bhCDO_cEGCz}
}

@InProceedings{nsvr,
  title = 	 {Neuro-Symbolic Visual Reasoning: Disentangling ``{V}isual" from ``{R}easoning"},
  author =       {Amizadeh, Saeed and Palangi, Hamid and Polozov, Alex and Huang, Yichen and Koishida, Kazuhito},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {279--290},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/amizadeh20a/amizadeh20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/amizadeh20a.html}
}


@inproceedings{nsvqa,
author = {Yi, Kexin and Wu, Jiajun and Gan, Chuang and Torralba, Antonio and Kohli, Pushmeet and Tenenbaum, Joshua B.},
title = {Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {1039–1050},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@INPROCEEDINGS{9710490,
  author={Chen, Junwen and Golisano, Yu Kong},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Explainable Video Entailment with Grounded Visual Evidence}, 
  year={2021},
  volume={},
  number={},
  pages={2001-2010},
  doi={10.1109/ICCV48922.2021.00203}}

@article{tf_transformer,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1-67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@INPROCEEDINGS{resnet,  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Deep Residual Learning for Image Recognition},   year={2016},  volume={},  number={},  pages={770-778},  doi={10.1109/CVPR.2016.90}}

@inproceedings{bidaf,
  author    = {Min Joon Seo and
               Aniruddha Kembhavi and
               Ali Farhadi and
               Hannaneh Hajishirzi},
  title     = {Bidirectional Attention Flow for Machine Comprehension},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2017},
  url       = {https://openreview.net/forum?id=HJ0UKP9ge},
  timestamp = {Thu, 25 Jul 2019 14:25:45 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/SeoKFH17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{del-fol,
  title={Neuro-symbolic visual reasoning: Disentangling},
  author={Amizadeh, Saeed and Palangi, Hamid and Polozov, Alex and Huang, Yichen and Koishida, Kazuhito},
  booktitle={International Conference on Machine Learning},
  pages={279--290},
  year={2020},
  organization={PMLR}
}

@InProceedings{clip,
  title = 	 {Learning Transferable Visual Models From Natural Language Supervision},
  author =       {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8748--8763},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/radford21a/radford21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/radford21a.html}
}

@inproceedings{pascal_text_entailment,
  title={The pascal recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment: First PASCAL Machine Learning Challenges Workshop, MLCW 2005, Southampton, UK, April 11-13, 2005, Revised Selected Papers},
  pages={177--190},
  year={2006},
  organization={Springer}
}

@inproceedings{text_entailment,
  title={Recognising textual entailment with logical inference},
  author={Bos, Johan and Markert, Katja},
  booktitle={Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing},
  pages={628--635},
  year={2005}
}


@InProceedings{mvit,
    author    = {Fan, Haoqi and Xiong, Bo and Mangalam, Karttikeya and Li, Yanghao and Yan, Zhicheng and Malik, Jitendra and Feichtenhofer, Christoph},
    title     = {Multiscale Vision Transformers},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {6824-6835}
}

@InProceedings{s3d,
author="Xie, Saining
and Sun, Chen
and Huang, Jonathan
and Tu, Zhuowen
and Murphy, Kevin",
editor="Ferrari, Vittorio
and Hebert, Martial
and Sminchisescu, Cristian
and Weiss, Yair",
title="Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification",
booktitle="Computer Vision -- ECCV 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="318--335",
isbn="978-3-030-01267-0"
}


@article{distil_bert,
  author    = {Victor Sanh and
               Lysandre Debut and
               Julien Chaumond and
               Thomas Wolf},
  title     = {DistilBERT, a distilled version of {BERT:} smaller, faster, cheaper
               and lighter},
  journal   = {CoRR},
  volume    = {abs/1910.01108},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.01108},
  eprinttype = {arXiv},
  eprint    = {1910.01108},
  timestamp = {Tue, 02 Jun 2020 12:48:59 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-01108.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bert_model,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}

@InProceedings{behavior_benchmark,
  title = 	 {BEHAVIOR: Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments},
  author =       {Srivastava, Sanjana and Li, Chengshu and Lingelbach, Michael and Mart\'in-Mart\'in, Roberto and Xia, Fei and Vainio, Kent Elliott and Lian, Zheng and Gokmen, Cem and Buch, Shyamal and Liu, Karen and Savarese, Silvio and Gweon, Hyowon and Wu, Jiajun and Fei-Fei, Li},
  booktitle = 	 {Proceedings of the 5th Conference on Robot Learning},
  pages = 	 {477--490},
  year = 	 {2022},
  editor = 	 {Faust, Aleksandra and Hsu, David and Neumann, Gerhard},
  volume = 	 {164},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {08--11 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v164/srivastava22a/srivastava22a.pdf},
  url = 	 {https://proceedings.mlr.press/v164/srivastava22a.html}
}

@inproceedings{roberta,
    title = "A Robustly Optimized {BERT} Pre-training Approach with Post-training",
    author = "Zhuang, Liu  and
      Wayne, Lin  and
      Ya, Shi  and
      Jun, Zhao",
    booktitle = "Proceedings of the 20th Chinese National Conference on Computational Linguistics",
    month = aug,
    year = "2021",
    address = "Huhhot, China",
    publisher = "Chinese Information Processing Society of China",
    url = "https://aclanthology.org/2021.ccl-1.108",
    pages = "1218--1227"
}

@article{luo2022clip4clip,
  title={CLIP4Clip: An empirical study of CLIP for end to end video clip retrieval and captioning},
  author={Luo, Huaishao and Ji, Lei and Zhong, Ming and Chen, Yang and Lei, Wen and Duan, Nan and Li, Tianrui},
  journal={Neurocomputing},
  volume={508},
  pages={293--304},
  year={2022},
  publisher={Elsevier}
}

@article{MAD_dataset,
	title        = {Mad: A scalable dataset for language grounding in videos from movie audio descriptions},
	author       = {Soldan, Mattia and Pardo, Alejandro and Alc{\'a}zar, Juan Le{\'o}n and Heilbron, Fabian Caba and Zhao, Chen and Giancola, Silvio and Ghanem, Bernard},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2112.00431}
}
@article{regneri2013grounding,
	title        = {Grounding action descriptions in videos},
	author       = {Regneri, Michaela and Rohrbach, Marcus and Wetzel, Dominikus and Thater, Stefan and Schiele, Bernt and Pinkal, Manfred},
	year         = 2013,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	volume       = 1,
	pages        = {25--36}
}

@inproceedings{t1,
	title        = {Tall: Temporal activity localization via language query},
	author       = {Gao, Jiyang and Sun, Chen and Yang, Zhenheng and Nevatia, Ram},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE international conference on computer vision},
	pages        = {5267--5275}
}
@inproceedings{t2,
	title        = {Temporally grounding natural sentence in video},
	author       = {Chen, Jingyuan and Chen, Xinpeng and Ma, Lin and Jie, Zequn and Chua, Tat-Seng},
	year         = 2018,
	booktitle    = {Proceedings of the 2018 conference on empirical methods in natural language processing},
	pages        = {162--171}
}
@article{t3,
	title        = {Semantic conditioned dynamic modulation for temporal sentence grounding in videos},
	author       = {Yuan, Yitian and Ma, Lin and Wang, Jingwen and Liu, Wei and Zhu, Wenwu},
	year         = 2019,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 32
}
@inproceedings{t4,
	title        = {Cross-modal interaction networks for query-based moment retrieval in videos},
	author       = {Zhang, Zhu and Lin, Zhijie and Zhao, Zhou and Xiao, Zhenxin},
	year         = 2019,
	booktitle    = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages        = {655--664}
}

@inproceedings{t5,
	title        = {Multilevel language and vision integration for text-to-clip retrieval},
	author       = {Xu, Huijuan and He, Kun and Plummer, Bryan A and Sigal, Leonid and Sclaroff, Stan and Saenko, Kate},
	year         = 2019,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 33,
	number       = {01},
	pages        = {9062--9069}
}
@inproceedings{t6,
	title        = {Temporally grounding language queries in videos by contextual boundary-aware prediction},
	author       = {Wang, Jingwen and Ma, Lin and Jiang, Wenhao},
	year         = 2020,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 34,
	number       = {07},
	pages        = {12168--12175}
}
@inproceedings{miech2020end,
	title        = {End-to-end learning of visual representations from uncurated instructional videos},
	author       = {Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {9879--9889}
}
@inproceedings{t7,
	title        = {Proposal-free temporal moment localization of a natural-language query in video using guided attention},
	author       = {Rodriguez, Cristian and Marrese-Taylor, Edison and Saleh, Fatemeh Sadat and Li, Hongdong and Gould, Stephen},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
	pages        = {2464--2473}
}
@inproceedings{t8,
	title        = {To find where you talk: Temporal sentence localization in video with attention based location regression},
	author       = {Yuan, Yitian and Mei, Tao and Zhu, Wenwu},
	year         = 2019,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 33,
	number       = {01},
	pages        = {9159--9166}
}
@article{t9,
	title        = {Tripping through time: Efficient localization of activities in videos},
	author       = {Hahn, Meera and Kadav, Asim and Rehg, James M and Graf, Hans Peter},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1904.09936}
}
@inproceedings{t10,
	title        = {Language-driven temporal activity localization: A semantic matching reinforcement learning model},
	author       = {Wang, Weining and Huang, Yan and Wang, Liang},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {334--343}
}
@inproceedings{t11,
	title        = {Dense regression network for video grounding},
	author       = {Zeng, Runhao and Xu, Haoming and Huang, Wenbing and Chen, Peihao and Tan, Mingkui and Gan, Chuang},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {10287--10296}
}
@inproceedings{t12,
	title        = {Cascaded prediction network via segment tree for temporal video grounding},
	author       = {Zhao, Yang and Zhao, Zhou and Zhang, Zhu and Lin, Zhijie},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {4197--4206}
}
@inproceedings{shou2016temporal,
	title        = {Temporal action localization in untrimmed videos via multi-stage cnns},
	author       = {Shou, Zheng and Wang, Dongang and Chang, Shih-Fu},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {1049--1058}
}
@inproceedings{escorcia2016daps,
	title        = {Daps: Deep action proposals for action understanding},
	author       = {Escorcia, Victor and Caba Heilbron, Fabian and Niebles, Juan Carlos and Ghanem, Bernard},
	year         = 2016,
	booktitle    = {European conference on computer vision},
	pages        = {768--784},
	organization = {Springer}
}
@misc{MagicLeap,
        key = {Magic Leap},
	title = {Four Optics Breakthroughs to Power Enterprise AR - Magic Leap},
	howpublished = {\url{https://www.magicleap.com/en-us/}}
}
@misc{mexaction2,
        key = {Mexaction2},
	title = {MEXaction2: action detection and localization dataset},
	howpublished = {\url{http://mexculture.cnam.fr/xwiki/bin/view/Datasets/Mex+action+dataset}}
}
@inproceedings{gao2020accurate,
  title={Accurate temporal action proposal generation with relation-aware pyramid network},
  author={Gao, Jialin and Shi, Zhixiang and Wang, Guanshuo and Li, Jiani and Yuan, Yufeng and Ge, Shiming and Zhou, Xi},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  pages={10810--10817},
  year={2020}
}
@inproceedings{yang2022temporal,
  title={Temporal action proposal generation with background constraint},
  author={Yang, Haosen and Wu, Wenhao and Wang, Lining and Jin, Sheng and Xia, Boyang and Yao, Hongxun and Huang, Hujie},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={36},
  pages={3054--3062},
  year={2022}
}

@misc{jiang2014thumos,
	title        = {THUMOS challenge: Action recognition with a large number of classes},
	author       = {Jiang, Yu-Gang and Liu, Jingen and Zamir, A Roshan and Toderici, George and Laptev, Ivan and Shah, Mubarak and Sukthankar, Rahul},
	year         = 2014,
	howpublished = {\url{http://crcv.ucf.edu/THUMOS14/}}
}
@inproceedings{human_activity_understanding,
	title        = {A large-scale video benchmark for human activity understanding},
	author       = {Heilbron, FC and Escorcia, V and Ghanem, B and Niebles, J},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Boston, 2015. 961},
	volume       = 970
}
@article{ungureanu2020hololens,
  title={Hololens 2 research mode as a tool for computer vision research},
  author={Ungureanu, Dorin and Bogo, Federica and Galliani, Silvano and Sama, Pooja and Duan, Xin and Meekhof, Casey and St{\"u}hmer, Jan and Cashman, Thomas J and Tekin, Bugra and Sch{\"o}nberger, Johannes L and others},
  journal={arXiv preprint arXiv:2008.11239},
  year={2020}
}
@inproceedings{change_it,
    title={Look for the Change: Learning Object States and State-Modifying Actions from Untrimmed Web Videos},
    author={Sou\v{c}ek, Tom\'{a}\v{s} and Alayrac, Jean-Baptiste and Miech, Antoine and Laptev, Ivan and Sivic, Josef},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2022}
}

@INPROCEEDINGS{ego_4d,  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and Martin, Miguel and Nagarajan, Tushar and Radosavovic, Ilija and Ramakrishnan, Santhosh Kumar and Ryan, Fiona and Sharma, Jayant and Wray, Michael and Xu, Mengmeng and Xu, Eric Zhongcong and Zhao, Chen and Bansal, Siddhant and Batra, Dhruv and Cartillier, Vincent and Crane, Sean and Do, Tien and Doulaty, Morrie and Erapalli, Akshay and Feichtenhofer, Christoph and Fragomeni, Adriano and Fu, Qichen and Gebreselasie, Abrham and González, Cristina and Hillis, James and Huang, Xuhua and Huang, Yifei and Jia, Wenqi and Khoo, Weslie and Koláĭ, Jáchym and Kottur, Satwik and Kumar, Anurag and Landini, Federico and Li, Chao and Li, Yanghao and Li, Zhenqiang and Mangalam, Karttikeya and Modhugu, Raghava and Munro, Jonathan and Murrell, Tullie and Nishiyasu, Takumi and Price, Will and Puentes, Paola Ruiz and Ramazanova, Merey and Sari, Leda and Somasundaram, Kiran and Southerland, Audrey and Sugano, Yusuke and Tao, Ruijie and Vo, Minh and Wang, Yuchen and Wu, Xindi and Yagi, Takuma and Zhao, Ziwei and Zhu, Yunyi and Arbeláez, Pablo and Crandall, David and Damen, Dima and Farinella, Giovanni Maria and Fuegen, Christian and Ghanem, Bernard and Ithapu, Vamsi Krishna and Jawahar, C. V. and Joo, Hanbyul and Kitani, Kris and Li, Haizhou and Newcombe, Richard and Oliva, Aude and Park, Hyun Soo and Rehg, James M. and Sato, Yoichi and Shi, Jianbo and Shou, Mike Zheng and Torralba, Antonio and Torresani, Lorenzo and Yan, Mingfei and Malik, Jitendra},  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Ego4D: Around the World in 3,000 Hours of Egocentric Video},   year={2022},  volume={},  number={},  pages={18973-18990},  doi={10.1109/CVPR52688.2022.01842}}

@inproceedings{msr-vtt,
  title={Msr-vtt: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5288--5296},
  year={2016}
}

@inproceedings{vatex,
  title={Vatex: A large-scale, high-quality multilingual dataset for video-and-language research},
  author={Wang, Xin and Wu, Jiawei and Chen, Junkun and Li, Lei and Wang, Yuan-Fang and Wang, William Yang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4581--4591},
  year={2019}
}

@inproceedings{msvd,
  title={Collecting highly parallel data for paraphrase evaluation},
  author={Chen, David and Dolan, William B},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies},
  pages={190--200},
  year={2011}
}

@inproceedings{teach_alexa,
  title={Teach: Task-driven embodied agents that chat},
  author={Padmakumar, Aishwarya and Thomason, Jesse and Shrivastava, Ayush and Lange, Patrick and Narayan-Chen, Anjali and Gella, Spandana and Piramuthu, Robinson and Tur, Gokhan and Hakkani-Tur, Dilek},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  pages={2017--2025},
  year={2022}
}

@inproceedings{ALFRED20,
  title ={{ALFRED: A Benchmark for Interpreting Grounded
           Instructions for Everyday Tasks}},
  author={Mohit Shridhar and Jesse Thomason and Daniel Gordon and Yonatan Bisk and
          Winson Han and Roozbeh Mottaghi and Luke Zettlemoyer and Dieter Fox},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2020},
  url  = {https://arxiv.org/abs/1912.01734}
}

@inproceedings{star_situated_reasoning,
author = {Wu, Bo and Yu, Shoubin and Chen, Zhenfang and Tenenbaum, Joshua B and Gan, Chuang},
title = {STAR: A Benchmark for Situated Reasoning in Real-World Videos},
booktitle = {Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS)},
year = {2021}
}

@INPROCEEDINGS{activity_net_dataset,
  author={Heilbron, Fabian Caba and Escorcia, Victor and Ghanem, Bernard and Niebles, Juan Carlos},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={ActivityNet: A large-scale video benchmark for human activity understanding}, 
  year={2015},
  volume={},
  number={},
  pages={961-970},
  doi={10.1109/CVPR.2015.7298698}}

@InProceedings{next_qa_dataset,
    author    = {Xiao, Junbin and Shang, Xindi and Yao, Angela and Chua, Tat-Seng},
    title     = {NExT-QA: Next Phase of Question-Answering to Explaining Temporal Actions},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {9777-9786}
}

@INPROCEEDINGS{agqa_dataset,
  author={Grunde-McLaughlin, Madeleine and Krishna, Ranjay and Agrawala, Maneesh},
  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={AGQA: A Benchmark for Compositional Spatio-Temporal Reasoning}, 
  year={2021},
  volume={},
  number={},
  pages={11282-11292},
  doi={10.1109/CVPR46437.2021.01113}}

@inproceedings{chain-of-thought,
title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and brian ichter and Fei Xia and Ed H. Chi and Quoc V Le and Denny Zhou},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=_VjQlMeSB_J}
}

@article{gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@misc{chatGPT,
  author = {OpenAI},
  url = {https://openai.com/blog/chatgpt}
}

@inproceedings{virtual-agent,
  title={Episodic memory question answering},
  author={Datta, et al. , Samyak },
  booktitle={CVPR},
  pages={19119--19128},
  year={2022}
}