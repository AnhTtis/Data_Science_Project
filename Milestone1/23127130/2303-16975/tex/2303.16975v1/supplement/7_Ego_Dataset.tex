
\section{\etv Dataset}
\subsection{Task-video Generation using PDDL Planner}
\label{appendix:etv_taskvideogen}
To generate \etv tasks, we encode the final state of the objects achieved by an \etv task as the ``goal state" for the Planning Domain Definition Language (PDDL) planner. Note that the ordering constraints of the tasks aren't captured when the tasks are encoded as goal states for the PDDL planner in this manner. For instance, the tasks of~\emph{clean\_then\_heat(apple)} and ~\emph{clean\_and\_heat(apple)} would have the same PDDL goal states. Consequently, we enforce ordering constraints for a given task using ``pre-conditions" in PDDL. In the above example task of~\emph{clean\_then\_heat(apple)}, the \emph{clean} sub-task would thus be the pre-condition for the \emph{heat} sub-task. Apart from the tasks and object states, the agent state and environment dynamics -- e.g., the \emph{heat} sub-task changes the state of the target object to be hot -- are also encoded in PDDL. 

For each task, a random kitchen scene is picked and the agent is spawned in the corresponding AI2-THOR scene. The planner leverages the initial state and action definitions to generate a sequence of sub-tasks required to achieve the goal state. Rather than simply selecting the best plan, which may not always reflect human-like behavior, we aim to mimic the less-than-optimal decision-making of humans by randomly selecting a plan from the top-$k$ plans. This approach enables the inclusion of sub-tasks that may not be strictly necessary for achieving the ultimate goal. Furthermore, the partial-ordered nature of tasks enables different plan generations to achieve the same task, thus promoting diversity in the dataset. We use the Fast Forward (FF) planner~\cite{metric_ff} to generate plans. 

Apart from sequencing the sub-tasks appropriately for achieving a given task, the planner also ensures that the agent can navigate to the correct locations for each sub-task. For instance, to execute the~\emph{clean} sub-task, an agent typically requires using the sink in the kitchen and hence must navigate there. The generated plans thus consist of navigation and object interaction actions.

% the initial state of the agent is obtained by randomly spawning it in an agent is randomly spawned in an AI2-THOR scene for each \etv task. The planner computes a sequence of sub-tasks, which renders the initial state of the agent to the desired final state for each task. Apart from sequencing the sub-tasks appropriately for achieving a given task, the planner also ensures that the agent can navigate to the correct locations for each sub-task. For instance, to execute the~\emph{clean} sub-task, an agent typically requires using the sink in the kitchen and hence must navigate there. The generated plans thus consist of navigation and object interaction actions.


% We further leverage the partial-ordered nature of tasks in our dataset to generate multiple, valid plans for a given task instead of a single, best plan. For instance, for the task of~\emph{clean\_and\_heat\_then\_slice(apple)}, we generate two plans and for the task of~\emph{clean\_and\_heat\_and\_slice(apple)}, we generate six plans corresponding to all the valid permutations. 


\subsection{\etv Task-description Generation}
\label{appendix:task_templates}
The task descriptions corresponding to negative samples, where the task videos are not entailed by their descriptions, are created by either altering the sequence of sub-tasks in the positive template or by replacing some of them with alternative sub-tasks picked randomly from the remaining repertoire of sub-tasks (see Figure~\ref{figure:dataset} where \textit{heat} is replaced with \textit{cool}).  To ensure the practicality of an assistive agent that aids a human, we maintain the target object in the negative samples but vary the sub-tasks, as negative task descriptions on the sub-task level are more relevant than on the object level. For abstraction we (i) omit the low-level details like \textit{clean \underline{in the sinkbasin}, cool \underline{in the fridge}}; (ii) (some) task-oriented descriptions are changed to goal-oriented descriptions (\textit{apple is heated and cleaned} $\mapsto$ \textit{hot, clean apple}). 

An example template of task descriptions corresponding to the task \emph{cool\_then\_clean} is [`\{obj\} is cooled in a Fridge, then cleaned in a SinkBasin',  `\{obj\} is cleaned in a SinkBasin after cooling in a Fridge', `\{obj\} is cooled in a Fridge before cleaning in a SinkBasin']



\subsection{Dataset Analysis and Statistics}
\label{appendix:dataset_analysis_and_statistics}
See Figure~\ref{figure:video-text-analysis} for a comparison of video lengths and task description lengths across different splits. It can be observed that the Novel Tasks split has the longest videos ($\approx 1.6$ minutes) and task descriptions ($\approx 12$ words) owing to its compositional tasks. Additionally, the Abstraction split has the shortest task description ($\approx 5$ words), even for longer videos due to abstraction. We include all tasks of \etv in Table~\ref{tab:list_of_tasks} at the end of the supplement.
% We also perform a detailed analysis of each split as shown in Figures~\ref{figure:train_analysis}~\ref{figure:novel_tasks_analysis}~\ref{figure:novel_steps_analysis}~\ref{figure:novel_scenes_analysis}~\ref{figure:abstraction_analysis}. 



\input{tables/Tab_1_full}
\input{figures/sup/video-text_analysis}
