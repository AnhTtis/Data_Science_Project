\section{Conclusion}
To address various challenges towards the development of egocentric assistants that can track and verify the accomplishment of everyday tasks, including reasoning about causal and temporal constraints in tasks, visual grounding, and compositional generalization, we introduce Egocentric Task Verification (EgoTV), a benchmark and dataset containing partially-ordered, multi-step tasks with natural language task specifications. We also present NSG, a novel neuro-symbolic approach that enables order-aware visual grounding, and demonstrate its effectiveness on both the EgoTV dataset and a real-world dataset CTV. We hope our contributions will help in advancing research on egocentric assistants that can aid users in everyday tasks.

% (iii) count-based events like ``slice two apples" that require repetitive actions are also harder to model
% and cater to the needs of future egocentric assistants.
% We will release our datasets and models for further research in this area.  

% \red{RH: Limitations}: (1) overlapping actions, (2) count-based actions like slice two apples. \bc{(3) Multiple action in one segment (4) assume different actions have similar temporal length (window size)}
