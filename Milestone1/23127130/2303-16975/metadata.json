{
    "arxiv_id": "2303.16975",
    "paper_title": "EgoTV: Egocentric Task Verification from Natural Language Task Descriptions",
    "authors": [
        "Rishi Hazra",
        "Brian Chen",
        "Akshara Rai",
        "Nitin Kamra",
        "Ruta Desai"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-05-03"
    ],
    "latest_version": 4,
    "categories": [
        "cs.CV"
    ],
    "abstract": "To enable progress towards egocentric agents capable of understanding everyday tasks specified in natural language, we propose a benchmark and a synthetic dataset called Egocentric Task Verification (EgoTV). EgoTV contains multi-step tasks with multiple sub-task decompositions, state changes, object interactions, and sub-task ordering constraints, in addition to abstracted task descriptions that contain only partial details about ways to accomplish a task. We also propose a novel Neuro-Symbolic Grounding (NSG) approach to enable the causal, temporal, and compositional reasoning of such tasks. We demonstrate NSG's capability towards task tracking and verification on our EgoTV dataset and a real-world dataset derived from CrossTask (CTV). Our contributions include the release of the EgoTV and CTV datasets, and the NSG model for future research on egocentric assistive agents.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16975v1",
        "http://arxiv.org/pdf/2303.16975v2",
        "http://arxiv.org/pdf/2303.16975v3",
        "http://arxiv.org/pdf/2303.16975v4"
    ],
    "publication_venue": null
}