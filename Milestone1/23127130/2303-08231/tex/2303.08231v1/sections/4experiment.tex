\section{Experiment}
\label{sec:experiment}
We evaluate \OURS{} on both rigid~(3DMatch~\cite{zeng20173dmatch} \& 3DLoMatch~\cite{huang2021predator}) and non-rigid~(4DMatch~\cite{li2022lepard} \& 4DLoMatch~\cite{li2022lepard}) benchmarks. For the rigid matching, we further evaluate our correspondences on the registration task, where RANSAC~\cite{fischler1981random} is used for pose estimation. Implementation details are introduced in the Appendix.

\renewcommand\arraystretch{0.75}
\begin{table}[ht!]
\small
\centering
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{lcc|cc}
\toprule
&\multicolumn{2}{c}{\textbf{3DMatch}} &\multicolumn{2}{c}{\textbf{3DLoMatch}}\\
\# Samples=5,000 &Origin &Rotated &Origin &Rotated\\
\midrule
\midrule

&\multicolumn{4}{c}{\textit{Feature Matching Recall} (\%) $\uparrow$} \\
\midrule
SpinNet~\cite{ao2021spinnet}  &97.4 &{97.4}  &75.5 &75.2 \\
Predator~\cite{huang2021predator}  &96.6 &96.2 &78.6  &73.7 \\
CoFiNet~\cite{yu2021cofinet}  &\underline{98.1} &{97.4} &{83.1} &{78.6}\\
YOHO~\cite{wang2022you} &\textbf{98.2} &{97.8} &79.4 &77.8\\
RIGA\cite{yu2022riga}~ &97.9 &\textbf{98.2}  &{85.1} &{84.5}\\
Lepard~\cite{li2022lepard} &98.0 &97.4 &{83.1} &{79.5}\\
GeoTrans~\cite{qin2022geometric} &97.9 &97.8 &\underline{88.3} &\underline{85.8}\\
\OURS{}~(\textit{Ours}) &98.0 &\textbf{98.2} &\textbf{89.6} &\textbf{89.4} \\
\midrule

&\multicolumn{4}{c}{\textit{Inlier Ratio} (\%) $\uparrow$}\\
\midrule
SpinNet~\cite{ao2021spinnet} &48.5 &48.7 &25.7 &{25.7}\\
Predator~\cite{huang2021predator} &58.0 &{52.8}  &26.7 &22.4\\
CoFiNet~\cite{yu2021cofinet} &49.8 &46.8 &24.4  &21.5\\
YOHO~\cite{wang2022you} &{64.4} &{64.1} &25.9 &23.2\\
RIGA~\cite{yu2022riga}  &{68.4} &\underline{68.5} &{32.1} &{32.1}\\
Lepard~\cite{li2022lepard} &58.6 &53.7 &{28.4} &{24.4}\\
GeoTrans~\cite{qin2022geometric} &\underline{71.9} &68.2 &\underline{43.5} &\underline{40.0}\\
\OURS{}~(\textit{Ours}) &\textbf{82.6} &\textbf{82.3} &\textbf{54.3} &\textbf{53.2} \\
\midrule

&\multicolumn{4}{c}{\textit{Registration Recall} (\%) $\uparrow$} \\
\midrule
SpinNet~\cite{ao2021spinnet}  &88.8 &\underline{93.2}  &58.2 &61.8\\
Predator~\cite{huang2021predator}  &{89.0} &92.0  &59.8 &58.6\\
CoFiNet~\cite{yu2021cofinet}  &{89.3} &92.0  &{67.5} &{62.5}\\
YOHO~\cite{wang2022you} &{90.8} &92.5 &65.2 &{66.8}\\
RIGA~\cite{yu2022riga}~ &{89.3} &{93.0}  &{65.1} &{66.9}\\
Lepard~\cite{li2022lepard} &\textbf{92.7} &84.9 &{65.4} &49.0\\
GeoTrans~\cite{qin2022geometric} &\underline{92.0} &92.0 &\textbf{75.0} &\underline{71.8}\\
\OURS{}~(\textit{Ours}) &91.9 &\textbf{94.7} &\underline{74.8} &\textbf{77.2}\\
\bottomrule
\end{tabular}}
\vspace{-0.25cm}
\caption{Quantitative results on (Rotated) 3DMatch \& 3DLoMatch. 5,000 points/correspondences are used for the evaluation.}
\label{tab:3dmatch}
\vspace{-0.65cm}
\end{table}

\begin{figure*}
  \includegraphics[width=0.98\textwidth]{figures/visualization_indoor.pdf}
  \vspace{-0.3cm}
  \caption{Qualitative results on 3DLoMatch. GeoTrans~\cite{qin2022geometric} is used as the baseline. Columns (b) and (c) show the correspondences, while columns (d) and (e) demonstrate the registration results. Green/red lines indicate inliers/outliers. More cases are shown in the Appendix.}
  \label{fig:vis_indoor}
  \vspace{-0.55cm}
\end{figure*}


\subsection{Rigid Indoor Scenes: 3DMatch \& 3DLoMatch}
\noindent\textbf{Dataset.}
3DMatch~\cite{zeng20173dmatch} collects 62 indoor scenes, among which 46 are used for training, 8 for validation, and 8 for testing. We use the data processed by~\cite{huang2021predator} where the 3DMatch data is spilt as 3DMatch~($>30\%$ overlap) and 3DLoMatch~($10\%\sim 30\%$ overlap). To evaluate robustness to arbitrary rotations, we follow~\cite{yu2022riga} for creating the rotated benchmarks, where full-range rotations are individually added to the two frames of each point cloud pair.

\noindent\textbf{Metrics.} We follow~\cite{huang2021predator} to use three metrics for evaluation: (1).~\textit{Inlier Ratio}~(IR) that computes the ratio of putative correspondences whose residual distance is smaller than a threshold~(\ie., 0.1m) under the ground-truth transformation; (2).~\textit{Feature Matching Recall}~(FMR) that calculates the fraction of point cloud pairs whose IR is larger than a threshold~(\ie., 5\%); (3).~\textit{Registration Recall}~(RR)~\footnote{We follow~\cite{yu2022riga} to calculate the RR strictly with RMSE $<$ 0.2m on the rotated data, which is slightly different from the RR on the original data.} that counts the fraction of point cloud pairs that are correctly registered~(\ie., with RMSE $<$ 0.2m). See the Appendix for the detailed definition.

\noindent\textbf{Comparison with the State-of-the-Art.}
We compare \OURS{} with 7 state-of-the-art methods, among which Predator~\cite{huang2021predator}, CoFiNet~\cite{yu2021cofinet}, Lepard~\cite{li2022lepard}, and GeoTrans~\cite{qin2022geometric} are rotation-sensitive models, while SpinNet~\cite{ao2021spinnet}, YOHO~\cite{wang2022you}, and RIGA~\cite{yu2022riga} guarantee the rotation invariance by design. In Tab.~\ref{tab:3dmatch} we demonstrate the matching and registration results on 3DMatch and 3DLoMatch, as well as on their rotated versions, with 5,000 sampled points/correspondences. Regarding IR, \OURS{} outperforms all the others by a large margin on both datasets, which indicates our method matches points more correctly. For FMR, we significantly surpass all the others on 3DLoMatch, while staying on par with CoFiNet and YOHO on 3DMatch, which indicates that our model is good at coping with hard cases, \ie., we find at least 5\% inliers on more test data. For the registration evaluation in terms of RR, \OURS{} achieves comparable performance with GeoTrans and Lepard on 3DMatch, but leads the board together with GeoTrans on 3DLoMatch with an overwhelming advantage over the others. Our stability against additional rotations is further demonstrated on the rotated data, where we outperform all the others with a substantial margin. Qualitative results can be found in Fig.~\ref{fig:vis_indoor}.

\renewcommand\arraystretch{0.95}
\begin{table}[ht!]
\centering

\resizebox{0.48\textwidth}{!}{
\begin{tabular}{lccccc|ccccc}
\toprule
 &\multicolumn{5}{c}{\textbf{3DMatch}}  &\multicolumn{5}{c}{\textbf{3DLoMatch}}\\
\# Samples &5000 &2500 &1000 &500 &250 &5000 &2500 &1000 &500 &250 \\
\midrule
\midrule
&\multicolumn{10}{c}{\textit{Feature Matching Recall} (\%) $\uparrow$}\\
\midrule
SpinNet~\cite{ao2021spinnet} &97.4 &97.0 &96.4 &96.7 &94.8 &75.5 &75.1 &74.2 &69.0 &62.7\\
Predator~\cite{huang2021predator} &96.6 &96.6 &96.5 &96.3 &96.5 &{78.6} &{77.4} &{76.3} &{75.7} &{75.3}\\
CoFiNet~\cite{yu2021cofinet} &\underline{98.1} &\textbf{98.3} &\textbf{98.1} &\textbf{98.2} &\textbf{98.3} &{83.1} &{83.5} &{83.3} &{83.1} &{82.6}\\

YOHO~\cite{wang2022you} &\textbf{98.2} &97.6 &97.5 &{97.7} &96.0 &79.4 &78.1 &76.3 &73.8 &69.1\\
RIGA~\cite{yu2022riga} &97.9 &{97.8} &{97.7} &{97.7} &{97.6} &{85.1} &{85.0} &{85.1} &{84.3} &{85.1}\\
GeoTrans~\cite{qin2022geometric} &97.9 &97.9 &\underline{97.9} &97.9 &97.6 &\underline{88.3} &\underline{88.6} &\underline{88.8} &\underline{88.6} &\underline{88.3}\\
\OURS{}~(\textit{Ours}) &98.0 &\underline{98.0} &\underline{97.9} &\underline{98.0} &\underline{97.9} &\textbf{89.6} &\textbf{89.6} &\textbf{89.5} &\textbf{89.4} &\textbf{89.3}\\
\midrule
&\multicolumn{10}{c}{\textit{Inlier Ratio} (\%) $\uparrow$}\\
\midrule
SpinNet~\cite{ao2021spinnet} &48.5 &46.2 &40.8 &35.1 &29.0 &25.7 &23.7 &20.6 &18.2 &13.1\\
Predator~\cite{huang2021predator} &58.0 &58.4 &{57.1} &{54.1} &{49.3}  &{26.7} &{28.1} &{28.3} &{27.5} &{25.8}\\
CoFiNet~\cite{yu2021cofinet} &49.8 &51.2 &{51.9} &{52.2} &{52.2} &{24.4} &{25.9} &{26.7} &{26.8} &{26.9}\\
YOHO~\cite{wang2022you} &{64.4} &{60.7} &55.7 &46.4 &41.2 &25.9 &23.3 &22.6 &18.2 &15.0 \\
RIGA~\cite{yu2022riga}  &{68.4} &{69.7} &{70.6} &{70.9} &{71.0} &{32.1}  &{33.4} &{34.3} &{34.5} &{34.6}\\
GeoTrans~\cite{qin2022geometric} &\underline{71.9} &\underline{75.2} &\underline{76.0} &\underline{82.2} &\textbf{85.1} &\underline{43.5} &\underline{45.3} &\underline{46.2} &\underline{52.9} &\textbf{57.7}\\
\OURS{}~(\textit{Ours}) &\textbf{82.6} &\textbf{82.8} &\textbf{83.0} &\textbf{83.0} &\underline{83.0} &\textbf{54.3} &\textbf{54.6} &\textbf{55.1} &\textbf{55.2} &\underline{55.3}\\
\midrule

&\multicolumn{10}{c}{\textit{Registration Recall} (\%) $\uparrow$}\\
\midrule
SpinNet~\cite{ao2021spinnet} &88.8 &88.0 &84.5 &79.0 &69.2 &58.2 &56.7 &49.8 &41.0 &26.7\\
Predator~\cite{huang2021predator}&89.0 &{89.9} &{90.6} &{88.5} &{86.6} &{59.8} &{61.2} &{62.4} &{60.8} &{58.1}\\
CoFiNet~\cite{yu2021cofinet} &{89.3} &{88.9} &{88.4} &{87.4} &{87.0} &{67.5} &{66.2} &{64.2} &{63.1} &{61.0}\\

YOHO~\cite{wang2022you}&{90.8} &{90.3} &{89.1} &{88.6} &84.5 &{65.2} &{65.5} &63.2 &56.5 &48.0\\

RIGA~\cite{yu2022riga} &{89.3} &88.4 &{89.1} &{89.0} &{87.7}&{65.1} &{64.7} &{64.5} &{64.1} &{61.8}\\
GeoTrans~\cite{qin2022geometric} &\textbf{92.0} &\textbf{91.8} &\textbf{91.8} &\textbf{91.4} &\textbf{91.2} &\textbf{75.0} &\textbf{74.8} &\underline{74.2} &\underline{74.1} &\underline{73.5}\\
\OURS{}~(\textit{Ours}) &\underline{91.9} &\underline{91.7} &\textbf{91.8} &\textbf{91.4} &\underline{91.0} &\underline{74.7} &\textbf{74.8} &\textbf{74.8} &\textbf{74.2} &\textbf{73.6}\\
\bottomrule
\end{tabular}}
\vspace{-0.2cm}
\caption{Quantitative results on 3DMatch \& 3DLoMatch with a varying number of points/correspondences. See the results on rotated data in the Appendix.}
\label{tab:scene}
\vspace{-0.55cm}

\end{table}


\noindent\textbf{Analysis on the Number of Correspondences.} We further analyze the influence of a varying number of correspondences. As illustrated in Tab.~\ref{tab:scene}, \OURS{} shows outstanding performance on both datasets with various correspondences, proving its stability when only a few correspondences are accessible. The same test on the rotated benchmarks is given in the Appendix.




\subsection{Deformable Objects: 4DMatch \& 4DLoMatch}

\noindent\textbf{Dataset.} 4DMatch~\cite{li2022lepard} contains 1,761 animations randomly selected from DeformingThings4D~\cite{li20214dcomplete}. The 1,761 sequences are divided into 1,232/176/353 as train/val/test, where the test set is further split into 4DMatch and 4DLoMatch based on an overlap ratio threshold of 45$\%$.

\noindent\textbf{Metrics.}
We follow~\cite{li2022lepard} to use two different metrics: (1).~\textit{Inlier Ratio}~(IR) which is defined as same as the IR on 3DMatch, but with a different threshold~(\ie., 0.04m); (2). \textit{Non-rigid Feature Matching Recall}~(NFMR) that measures the fraction of ground-truth matches that can be successfully recovered by the putative correspondences. The details of the metrics are given in the Appendix.

\renewcommand\arraystretch{0.9}
\begin{table}[ht!]
\centering
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{c|l|cc|cc}
\toprule
& &\multicolumn{2}{c}{\textbf{4DMatch}} &\multicolumn{2}{c}{\textbf{4DLoMatch}}\\
Category & Method &NFMR(\%) $\uparrow$ &IR(\%) $\uparrow$ &NFMR(\%) $\uparrow$ &IR(\%) $\uparrow$\\
\midrule
\midrule
\multirow{2}{*}{Scene Flow}&PWC~\cite{wu2019pointpwc}  &21.6 &20.0 &10.0 &7.2\\
&FLOT~\cite{puy2020flot} &27.1 &24.9 &15.2 &10.7\\

\midrule
\multirow{4}{*}{Feature Matching}
&Predator~\cite{huang2021predator} &{56.4} &{60.4} &32.1 &27.5\\
&GeoTrans~\cite{qin2022geometric} &\underline{83.2} &82.2 &65.4 &\underline{63.6}\\
&Lepard~\cite{li2022lepard} &\textbf{83.7} &\underline{82.7} &\underline{66.9} &{55.7}\\
&\OURS{}~(\textit{Ours}) &{83.0} &\textbf{84.4} &\textbf{69.4} &\textbf{67.6} \\
\bottomrule
\end{tabular}}
\vspace{-0.2cm}
\caption{Quantitative results on 4DMatch \& 4DLoMatch.}

\label{tab:4dmatch}
\vspace{-0.2cm}
\end{table}
\noindent\textbf{Comparison with the State-of-the-Art.} We compare \OURS{} with 5 baselines, among which PWC~\cite{wu2019pointpwc} and FLOT~\cite{puy2020flot} are scene flow-based methods, while Predator~\cite{huang2021predator}, Lepard~\cite{li2022lepard}, GeoTrans~\cite{qin2022geometric} are based on feature matching. The results shown in Tab.~\ref{tab:4dmatch} indicate that although our rotation-invariance is mainly designed for rigid scenarios, \OURS{} could also achieve outstanding performance in the non-rigid matching task, which further confirms the superiority of our model design. Qualitative results are demonstrated in Fig.~\ref{fig:vis_4d}.

\subsection{Ablation Study}

\noindent\textbf{Local Attention.} We first replace our PPFTrans with PointTransformer~(PT)~\cite{zhao2021point} in Tab.~\ref{tab:ablation}~(a.1), which leads to a sharp performance drop. We then ablate by embedding our PPF-based local coordinates into PT~(Tab.~\ref{tab:ablation}~(a.2)) and by adopting the relative coordinates, \ie., $\mathbf{p}_j - \mathbf{p}_j$, used by PT in our PAM~(Tab.~\ref{tab:ablation}~(a.3)). Our local coordinate representation significantly boosts the performance of PT in the task of point cloud matching and meanwhile makes it rotation-invariant, although its performance is still far behind ours. However, the relative coordinates fail to work in our PAM, as we adopt a more efficient attention mechanism~\cite{vaswani2017attention} that learns a scalar attention value for each feature $\mathbf{x}\in\mathbb{R}^c$ and is consequently hard to work under varying poses with a rotation-sensitive design. As a comparison, PT learns a per-channel vector attention $\mathbf{a}\in \mathbb{R}^c$ for the same feature $\mathbf{x}$ and could deal with the pose variations, but at the cost of the efficiency as shown in Fig.~\ref{fig:runtime}. When the number of channels is increased, our advantage in terms of efficiency is enlarged. As we achieve that with more parameters, the gap becomes more significant when runtime is normalized with the number of parameters in the right figure. With our PPF-based local coordinate, the scalar attention could focus on the pose-agnostic pure geometry and therefore achieves the best performance shown in Tab.~\ref{tab:ablation}~(a.4).

\begin{figure}
\includegraphics[width=0.48\textwidth]{figures/visualization_deform.pdf}
\vspace{-0.5cm}
\caption{\small Qualitative results of non-rigid matching on 4DLoMatch with Lepard~\cite{li2022lepard} as the baseline. Green/red lines indicate inliers/outliers. See the Appendix for more examples.}
\label{fig:vis_4d}
\vspace{-0.7cm}
\end{figure}


\noindent\textbf{Abstraction Layer.}
We ablate our Attentional Abstraction Layer~(AAL) by replacing it with the pooling-based abstraction design used in~\cite{qi2017pointnet,qi2017pointnet++,zhao2021point}. We test the max pooling in Tab.~\ref{tab:ablation}~(b.1) and the average pooling in Tab.~\ref{tab:ablation}~(b.2), both showing a degrading performance compared with our AAL, which demonstrates our superiority.

\noindent \textbf{Backbone.} In Tab.~\ref{tab:ablation}~(a.1) we have shown our superiority compared with PT~\cite{zhao2021point}. We further replace our PPFTrans with the KPConv-based backbone network which is widely used in previous deep matchers~\cite{huang2021predator,yu2021cofinet,qin2022geometric}. 
The fact that KPConv falls behind our design demonstrates the advantage of PPFTrans in geometry encoding.

\noindent \textbf{Global Transformer.} We replace our design with the global transformer of GeoTrans~\cite{qin2022geometric} which performs state-of-the-art but without the cross-frame spatial awareness. The dropping results in Tab.~\ref{tab:ablation}~(d.1) proves the excellence of our design with the cross-frame position awareness.

\noindent \textbf{The Number of Global Transformers.} To demonstrate the importance of being globally aware, we first remove the global transformer. The substantial performance drop confirms the significance of global awareness. Then we add one global transformer and observe an increased performance. In our default setting with 3 global transformers, the model performs the best. However, when the number is increased to 5, the model shows a slight performance drop, which we owe to overfitting. As the data augmentation of rotations has less effect on an intrinsically rotation-invariant method, more data is required for training a larger model.


\begin{figure}
  \includegraphics[width=0.46\textwidth]{figures/time.pdf}
  \vspace{-0.2cm}
  \caption{\small \textbf{Left}: Runtime comparison between our PPF attention Module~(PAM) and the local attention in PointTransformer~\cite{zhao2021point}. \textbf{Right}: Runtime normalized by aligning the number of parameters. }
  \label{fig:runtime}
  \vspace{-0.55cm}
\end{figure}



\renewcommand\arraystretch{0.8}
\begin{table}[ht!]
\vspace{-0.25cm}
\centering
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{ll|cccccc}
\toprule
& &\multicolumn{3}{c}{\textbf{Origin}}&\multicolumn{3}{c}{\textbf{Rotated}}\\
Category & Model &FMR &IR &RR  &FMR &IR &RR\\
\midrule
\midrule
\multirow{4}{*}{a. Local}
 &\;\ 1. PT~\cite{zhao2021point} &79.0&36.5&61.6 &76.5&34.7&60.0 \\
&*2. PPF+PT~\cite{zhao2021point} &87.0 &49.9 &69.9 &86.8 &49.4 &71.2\\
& \; 3. $\Delta$xyz+Ours &-&-&-&-&-&-\\
& *4. \textit{Ours}  &\textbf{89.6} &\textbf{54.3} &\textbf{74.7} &\textbf{89.4} &\textbf{53.2} &\textbf{77.2}\\
\midrule
\multirow{3}{*}{b. Aggregation}& *1. max pooling &85.2&50.1&70.5&85.4&50.2&71.9\\
& *2. avg pooling  &87.8&52.6&73.8&87.2&52.5&74.7\\
& *3. \textit{Ours} &\textbf{89.6} &\textbf{54.3} &\textbf{74.7} &\textbf{89.4} &\textbf{53.2} &\textbf{77.2}\\
\midrule
\multirow{2}{*}{c. Backbone}&\;\ 1. KPConv~\cite{thomas2019kpconv}  &85.2 &44.4 &70.6 &83.0 &42.3 &71.5 \\
& *2. \textit{Ours}  &\textbf{89.6} &\textbf{54.3} &\textbf{74.7} &\textbf{89.4} &\textbf{53.2} &\textbf{77.2}\\
\midrule
\multirow{2}{*}{d. Global} &*1. GeoTrans~\cite{qin2022geometric}  &87.7&53.6&73.0 &87.5&\textbf{53.2} &75.1\\
&*2. \textit{Ours}  &\textbf{89.6} &\textbf{54.3} &\textbf{74.7} &\textbf{89.4} &\textbf{53.2} &\textbf{77.2}\\
\midrule
\multirow{4}{*}{e. \#Global}
& *1. $g=0$  &87.2 &37.6 &70.7 &87.5 &37.6 &72.7 \\
& *2. $g=1$  &87.1 &42.1 &70.8 &86.8 &42.1 &73.0 \\
& *3. $g=3$~(\textit{Ours}) &\textbf{89.6} &\textbf{54.3} &\textbf{74.7} &\textbf{89.4} &\textbf{53.2} &\textbf{77.2}\\
& *4. $g=5$ &87.1 &52.5 &72.1 &87.0&52.4&73.3\\

\bottomrule
\end{tabular}}
\vspace{-0.2cm}
\caption{\small Ablation study on (rotated) 3DLoMatch. 5,000 points/correspondences are leveraged. * indicates the methods with intrinsic rotation invariance. See the Appendix for the results on (rotated) 3DMatch.}
\label{tab:ablation}
\vspace{-0.55cm}
\end{table}







\iffalse
\renewcommand\arraystretch{0.9}
\begin{table}[ht!]
\centering
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{ll|cccccc|cccccc}
\toprule
& &\multicolumn{6}{c|}{\textbf{3DMatch}} &\multicolumn{6}{c}{\textbf{3DLoMatch}}\\
\midrule
& &\multicolumn{3}{c|}{\textbf{Origin}} &\multicolumn{3}{c|}{\textbf{Rotated}} &\multicolumn{3}{c|}{\textbf{Origin}}&\multicolumn{3}{c}{\textbf{Rotated}}\\
Category & Model &FMR &IR &RR  &FMR &IR &RR  &FMR &IR &RR  &FMR &IR &RR \\
\midrule
\midrule
\multirow{4}{*}{a. Local}
 &\;\ 1. PT~\cite{zhao2021point}&96.7&71.0&87.6&96.4&69.5&90.5 &79.0&36.5&61.6 &76.5&34.7&60.0 \\
&*2. PPF+PT~\cite{zhao2021point} &97.9 &80.1 &91.2&97.8 &79.8 &93.9 &87.0 &49.9 &69.9 &86.8 &49.4 &71.2\\
& \; 3. $\Delta$xyz+Ours &-&-&-&-&-&-&-&-&-&-&-&-\\
& *4. \textit{Ours} &\textbf{98.0} &\textbf{82.6} &\textbf{91.9} &\textbf{98.2} &\textbf{82.3} &\textbf{94.7} &\textbf{89.6} &\textbf{54.3} &\textbf{74.7} &\textbf{89.4} &\textbf{53.2} &\textbf{77.2}\\
\midrule
\multirow{3}{*}{b. Aggregation}& *1. max pooling &97.9&80.8&90.7&97.8&80.8&94.1&85.2&50.1&70.5&85.4&50.2&71.9\\
& *2. avg pooling  &\textbf{98.1} &81.8&\textbf{92.1}&\textbf{98.2} &81.8 &\textbf{94.8} &87.8&52.6&73.8&87.2&52.5&74.7\\
& *3. \textit{Ours} &98.0 &\textbf{82.6} &91.9 &\textbf{98.2} &\textbf{82.3} &94.7 &\textbf{89.6} &\textbf{54.3} &\textbf{74.7} &\textbf{89.4} &\textbf{53.2} &\textbf{77.2}\\
\midrule
\multirow{2}{*}{c. Backbone}&\;\ 1. KPConv~\cite{thomas2019kpconv} &97.9&74.6&91.1&97.3&72.8&94.3 &85.2 &44.4 &70.6 & & & \\
& *2. \textit{Ours} &\textbf{98.0} &\textbf{82.6} &\textbf{91.9} &\textbf{98.2} &\textbf{82.3} &\textbf{94.7} &\textbf{89.6} &\textbf{54.3} &\textbf{74.7} &\textbf{89.4} &\textbf{53.2} &\textbf{77.2}\\
\midrule
\multirow{3}{*}{d. Global}&*1. GeoTrans~\cite{qin2022geometric} &97.9 &82.6 &90.8 &98.0 &82.3 &94.5 &87.7&53.6&73.0 &87.5&53.2&75.1\\
&\;\ 2. Lepard~\cite{li2022lepard} &&&&&&&&&&&&\\
&*3. \textit{Ours} &98.0 &82.6 &91.9 &98.2 &82.3 &94.7 &89.6 &54.3 &74.7 &89.4 &53.2 &77.2\\
\midrule
\multirow{4}{*}{e. \#Global}
& *1. $g=0$ &98.5 &65.8 &90.9 &98.3 &65.9 &93.7 &87.2 &37.6 &70.7 &87.5 &37.6 &72.7 \\
& *2. $g=1$ &98.4 &74.8 &90.8 &98.5 &74.8 &94.2  &87.1 &42.1 &70.8 &86.8 &42.1 &73.0 \\
& *3. $g=3$~(\textit{Ours}) &98.0 &82.6 &91.9 &98.2 &82.3 &94.7 &89.6 &54.3 &74.7 &89.4 &53.2 &77.2\\
& *4. $g=5$ &98.1&82.0&91.7 &98.0 &82.0 &94.6 &87.1 &52.5 &72.1 &87.0&52.4&73.3\\

\bottomrule
\end{tabular}}
\vspace{-0.2cm}
\caption{\small Ablation study on (rotated) 3DMatch \& 3DLoMatch. 5,000 points/correspondences are leveraged. * indicates the methods with intrinsic rotation invariance.}
\label{tab:ablation}
\vspace{-0.5cm}
\end{table}
\fi

%\subsection{Limitation}
%Although \OURS{} achieves remarkable performance on both the rigid and non-rigid scenarios, we also notice the drawbacks of our method. The first is due to the intrinsic rotation invariance, it totally loses the ability to match symmetric structures. Moreover, it mainly relies on the feature distinctiveness to implicitly filter out the occluded areas during the matching procedure, which makes it fail in cases with extremely limited overlap. Finally, as normal data augmentation cannot work on intrinsically rotation invariant methods, more data is required to train a larger model.  Failed cases are illustrated in the Appendix.