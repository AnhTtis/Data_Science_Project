
\section{Conclusion}
\label{sec:conclusion}
We introduce \OURS{} - an intrinsically rotation-invariant model for point cloud matching. We proposed PAM~(PPF Attention Module) that embeds PPF-based local coordinates to encode rotation-invariant local geometry. This module lies at the core of AAL~(Attention Abstraction Layer), PAL~(PPF Attention Layer), and TUL~(Transition Up Layer) which are consecutively stacked to compose PPFTrans~(PPF Transfomer) for highly-representative and pose-agnostic geometry description. We further enhanced features with the global context by introducing a novel global transformer architecture, which ensures the rotation-invariant cross-frame spatial awareness.
%The global context is then aggregated for feature enhancement via the global transformer structure with the rotation-invariant cross-frame spatial awareness. 
Extensive experiments are conducted on both rigid and non-rigid benchmarks to demonstrate the superiority of our approach, especially the remarkable robustness against arbitrary rotations. However, as \OURS{} does not explicitly handle the occlusion, it may fail in cases with extremely limited overlap. We further discuss limitations in the Appendix. In the future, we would like to incorporate RGB information to cope with symmetric structures. 