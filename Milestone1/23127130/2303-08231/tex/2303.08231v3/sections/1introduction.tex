\vspace{-0.5cm}
\section{Introduction}
\label{sec:intro}
The correspondence estimation between a pair of partially-overlapping point clouds is a long-standing task that lies at the core of many computer vision applications, such as tracking~\cite{huang2016volumetric,huang2017tracking}, reconstruction~\cite{newcombe2011kinectfusion,newcombe2015dynamicfusion,tang2021learning}, pose estimation~\cite{huang2021predator,yu2021cofinet,qin2022geometric} and 3D representation learning~\cite{xie2020pointcontrast, hou2021exploring,hou2021pri3d}, etc. In a typical solution, geometry is first encoded into descriptors, and correspondences are then established between two frames by matching the most similar descriptors. As the two frames are observed from different views, depicting the same geometry under different transformations identically, \ie., the pose-invariance, becomes the key to success in the point cloud matching task. %identically while the different geometry antithetically under pose variances becomes the key to success in the point cloud matching task.
\begin{figure}
  \includegraphics[width=0.48\textwidth]{figures/teaser.pdf}
  \vspace{-0.6cm}
  \caption{\textit{Feature Matching Recall}~(FMR) on 3DLoMatch~\cite{huang2021predator} and Rotated 3DLoMatch. Distance to the diagonal represents the robustness against rotations. Among all the state-of-the-art approaches, \OURS{} not only ranks first on both benchmarks but also shows the best robustness against the enlarged rotations.}
  \label{fig:teaser}
  \vspace{-0.6cm}
\end{figure}

Since the side effects caused by a global translation can always be easily eliminated, \eg., by aligning the barycenter with the origin, the attention naturally shifts to coping with the rotations. 
In the past, handcrafted local descriptors~\cite{rusu2008aligning,rusu2009fast,drost2010model,tombari2010unique} were designed to be rotation-invariant so that the same geometry observed from different views can be correctly matched. With the emergence of deep neural models for 3D point analysis, \eg., multilayer perceptrons~(MLPs)-based like PointNet~\cite{qi2017pointnet,qi2017pointnet++}, convolutions-based like KPConv~\cite{thomas2019kpconv,choy20194d}, and the attention-based like PointTransformer~\cite{zhao2021point,saleh2022cloudattention}, recent approaches~\cite{zeng20173dmatch,deng2018ppfnet,deng2018ppf,gojcic2019perfect,choy2019fully,saleh2020graphite,ao2021spinnet,huang2021predator,yu2021cofinet,qin2022geometric,li2022lepard,yew2022regtr,yu2022riga} propose to learn descriptors from raw points as an alternative to handcrafted features that are less robust to occlusion and noise. The majority of deep point matchers~\cite{zeng20173dmatch,deng2018ppfnet,choy2019fully,huang2021predator,yu2021cofinet,saleh2022bending,qin2022geometric,li2022lepard,yew2022regtr,zhang2022pcr} is sensitive to rotations. Consequently, their invariance to rotations  must be obtained extrinsically via augmented training to ensure that the same geometry under different poses can be depicted similarly.  However, as the training cases can never span the continuous $SO(3)$ space, they always suffer from instability when facing rotations that are rarely seen during training. This can be observed by a significant performance drop under enlarged rotations at inference time.~(See Fig.~\ref{fig:teaser}.) 

There are other works~\cite{deng2018ppf,gojcic2019perfect,saleh2020graphite,ao2021spinnet,wang2022you} that only leverage deep neural networks to encode the pure geometry with the intrinsically-designed rotation invariance.  However, the intrinsic rotation invariance comes at the cost of losing global context. For example, a human's left and right halves are almost identically described, which naturally degrades the distinctiveness of features. Most recently, RIGA~\cite{yu2022riga} is proposed to enhance the distinctiveness of the rotation-invariant descriptors by incorporating a global context, \eg., the left and right halves of a human become distinguishable by knowing there is a chair on the left while a table on the right. %However, since it lacks a highly-representative rotation-invariant geometry encoder, it has no choice but to use a simple PointNet~\cite{qi2017pointnet} which accounts for an ineffective local geometry description. 
However, it lacks a highly-representative geometry encoder since it relies on PointNet~\cite{qi2017pointnet}, which accounts for an ineffective local geometry description.
Moreover, as depicting the cross-frame spatial relationships is non-trivial, previous works~\cite{huang2021predator,yu2021cofinet,saleh2022bending,qin2022geometric} merely leverage the contextual features in the cross-frame context aggregation, which neglects the positional information. Although RIGA proposes to learn a rotation-invariant position representation by leveraging an additional PointNet, this simple design is hard to model the complex cross-frame positional relationships and leads to less distinctive descriptors.

In this paper, we present \textbf{Ro}tation-\textbf{I}nvariant \textbf{Tr}ansformer (\OURS{}) to tackle the problem of point cloud matching under arbitrary pose variations. %the pose variances in point cloud matching. 
By using Point Pair Features~(PPFs) as the local coordinates, we propose an attention mechanism to learn the pure geometry regardless of the varying poses. Upon it, attention-based layers are further proposed to compose the encoder-decoder architecture for highly-discriminative and rotation-invariant geometry encoding. We demonstrate its superiority over PointTransformer~\cite{zhao2021point}, a state-of-the-art attention-based backbone network, in terms of both efficiency and efficacy in Fig.~\ref{fig:runtime} and Tab.~\ref{tab:ablation}~(a), respectively. On the global level, the cross-frame position awareness is introduced in a rotation-invariant fashion to facilitate feature distinctiveness. We illustrate its significance over the state-of-the-art design~\cite{qin2022geometric} in Tab.~\ref{tab:ablation}~(d). Our main contributions are summarized as:
\begin{itemize}

\item An attention mechanism designed to disentangle the geometry and poses, which enables the pose-agnostic geometry description.
\vspace{-0.2cm}
\item An attention-based encoder-decoder architecture that learns highly-representative local geometry in a rotation-invariant fashion.
\vspace{-0.2cm}
\item A global transformer with rotation-invariant cross-frame position awareness that significantly enhances the feature distinctiveness. 

\end{itemize}
\vspace{-0.3cm}