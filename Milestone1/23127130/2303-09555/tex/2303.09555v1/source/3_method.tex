\section{SoftZoo}
\label{sec:softzoo}


\subsection{Overview}
\label{ssec:overview}
% \begin{itemize}
%     \item Briefly introduce the features of \namenospace.
%     \item Make a table to compare with existing platforms.
% \end{itemize}

\name is a soft robot co-design platform for locomotion in diverse environments. It supports varied, naturally-inspired materials that can construct environments including ground, desert, wetland, clay, ice, shallow water, and ocean. The task set consists of fast locomotion, agile turning, and path following. The suite provides a seamless and flexible interface of robot design that specifies robot geometry, body stiffness, and muscle placement, and accepts common 3D representations such as point clouds, voxel grids, or meshes. The robot can then be controlled according to muscle groups. The underlying physics engine also supports differentiability that provides model-based gradients, which gains increasing attention in soft robot control and design.  In the following, we walk through high-level components of \namenospace: simulation engine, environment setup, and locomotion tasks. % We leave more implementation and technical details to the Appendix.


\subsection{Simulation Engine}
\label{ssec:simulation_engine}
% \begin{itemize}
%     \item Brief introduction of MPM; mention the idea of Eulerian and Lagrangian space, p2g, g2p, since we use the concept of particle and grid later on.
%     \item Differentiability and gradient checkpointing.
%     \item Contact model between terrain (mesh) and other material (particles).
%     \item Multi-material simulation. Refer to appendix for more detailed explanation.
% \end{itemize}

In this section, we briefly introduce the underlying simulation technique to facilitate later-on discussion. \name is implemented using the Taichi library \citep{hu2019taichi}, which compiles physical simulation code (and its reverse-mode autodifferentiated gradients) for efficient parallelization on GPU hardware. Continuum mechanics in \name follows the discretization of Moving Least Squares Material Point Method (MLS-MPM) \citep{hu2018moving}, a variant of B-spline MPM \citep{stomakhin2013material} with improved efficiency. Multimaterial simulation and signed-distance-function-based boundary conditions for terrain are implemented to construct diverse environments. % Please refer to the Appendix for a more in-depth and detailed description.

\noindent\textbf{Material Point Method (MPM).} The material point method is a hybrid Eulerian-Lagrangian method, where both Lagrangian particles and Eulerian grid nodes are used to transfer simulation state information back-and-forth. At a high level, MPM is comprised of three major steps: particle-to-grid transfer (P2G), grid operation, and grid-to-particle transfer (G2P). Material properties, including position \rebuttal{$\mathbf{x}_p$}, velocity \rebuttal{$\mathbf{v}_p$}, mass \rebuttal{$m_p$}, deformation gradients \rebuttal{$\mathbf{F}_p$}, and affine velocity field \rebuttal{$\mathbf{C}_p$}, are stored in Lagrangian particles that move through space and time. 
% This information is transferred to grid nodes via P2G, followed by a grid operation that handles interparticle interaction and collision with rigid bodies.  The time-stepped grid states are finally transferred back to particles by G2P. 
MPM allows large deformation, automatic treatment of self-collision and fracture, and simple realization of multi-material interaction, and is hence well-suited for soft robots in diverse environments. We show the governing equations used by MPM and more implementation details in Appendix~\ref{sec:sim}.

\noindent\textbf{Contact Model.} The terrain in \name is represented as meshes that interact with either the robot body or other ground cover materials such as snow or sand. We employ a grid-based contact treatment \citep{stomakhin2013material} to handle particle terrain-particle collision, using a Coulomb friction model. We compute the surface normal of the terrain to measure the signed distance function (SDF) and construct boundary conditions for velocity in grid space.

\noindent\textbf{Multiphysical Materials.}
We present a set of environments with multiphysical material support. The materials cover a diverse set of physical phenomena, including hyperelasticity, plasticity, fluidity, and inter-particle friction.  These phenomena combine to model common real-world materials such as sand, snow, rubber, mud, water, and more.  We list all environments with their corresponding multiphysical materials in Appendix~\ref{sec:material}. In addition to categorical choices of environments, we also provide a set of elastic constitutive models (\textit{e.g.}, St. Venant-Kirchhoff, corotated linear, neo-Hookean, etc.) and expose their parameters so that the practitioners can easily fine-tune the material behaviors. In our experiments, we use neo-Hookean material since it \textit{a)} is known to be accurate for modeling silicone-rubber-like materials common in real-world soft robots, \textit{b)} skips the costly calculation of singular value decomposition (SVD) and \textit{c)} results in an improvement in simulation speed and numerical stability and reduces gradient instability caused by singular value degeneracy.

\noindent\textbf{Actuation Model.} We define our actuation model as an anisotropic muscle installed along specified particles. Each muscular element generates a directional force along a unit fiber vector \rebuttal{$\mathbf{f}$}. We realize this actuation model using the anisotropic elastic energy from~\cite{ma2021diffaqua}  $\Psi=s\left\|l-a\right\|^2$, where \rebuttal{$l=\|\mathbf{F}\mathbf{f}\|^2$}, $\mathbf{F}$ is the deformation gradient, $s$ is a muscular stiffness parameter, and $a$ is the actuation signal provided by a controller.  This energy is added to the constitutive material energy of particles along which the muscle fiber is installed.

%After the installation of the muscles, the MPM solver fuses them into the passive materials and actuates the robot using provided activation signals.

% \subsection{Environment Setup}
% \label{ssec:environment_setup}
% % \begin{itemize}
% %     \item Procedural terrain generation.
% %     \item (on-aqua) randomly place material particle on the terrain.
% %     \item Place the robot on top of the terrain (potentially covered with material).
% %     \item (Aqua) Add water without overlapping with robot body.
% % \end{itemize}
% All environments adopt similar construction steps that follow terrain generation, robot placement, and material covering. First, we perform procedural terrain generation using Perlin noise with user-defined height range and other parameters for roughness. The generated height map is converted to a mesh for ground surface. We then place the robot with specified design randomly or at a fixed pre-defined position on the terrain. Then, we compute an occupancy map in the Eulerian grid in MPM based on particles of robot body and terrain’s SDF. Finally, we layer ground cover material on top of the terrain using its surface normal, filtered by the occupancy map to avoid placement in non-free space.

\begin{table}[t] 
    \centering
    \caption{Large-scale benchmark of biologically-inspired designs in \namenospace. Each entry shows results from differentiable physics (left) and RL (right). The higher the better.}
    \vspace{-2mm}
    \begin{adjustbox}{width=1\columnwidth}
    \begin{tabular}{c|c|ccccccc}
        \toprule
        \multirow{2}{*}{\textbf{Task}} & \multirow{2}{*}{\textbf{Animal}} & \multicolumn{7}{c}{\textbf{Environment}} \\
        & & \textbf{Ground} & \textbf{Ice} & \textbf{Wetland} & \textbf{Clay} & \textbf{Desert} & \textbf{Snow} & \textbf{Ocean} \\
        \midrule 
        \multirow{4}{*}{\makecell{Movement\\Speed}} & Baby Seal & 0.122 / \rebuttal{\textbf{0.154}} & \textbf{0.048} / \rebuttal{0.010} & 0.032 / \rebuttal{0.020} & 0.012 / \rebuttal{0.005} & 0.059 / \rebuttal{0.034} & 0.039 / \rebuttal{0.016} & 0.033 / \rebuttal{0.029}  \\
        & Caterpillar & 0.080 / \rebuttal{0.032} & 0.023 / \rebuttal{0.006} & \textbf{0.052} / \rebuttal{0.016} & 0.032 / \rebuttal{0.015} & 0.053 / \rebuttal{0.032} & 0.047 / \rebuttal{0.017} & 0.134 / \rebuttal{\textbf{0.181}} \\
        & Fish & 0.053 / \rebuttal{0.033} & 0.029 / \rebuttal{0.011} & 0.026 / \rebuttal{0.013} & \textbf{0.037} / \rebuttal{0.014} & \textbf{0.115} / \rebuttal{0.022} & \textbf{0.087} / \rebuttal{0.042} & 0.084 / \rebuttal{0.151} \\
        & Panda & 0.046 / \rebuttal{0.019} & 0.038 / \rebuttal{0.006} & 0.016 / \rebuttal{0.008} & 0.019 / \rebuttal{0.005} & 0.023 / \rebuttal{0.009} & 0.031 / \rebuttal{0.004} & 0.024 / \rebuttal{0.007} \\
        \midrule
        \multirow{4}{*}{Turning} & Baby Seal & 0.067 / \rebuttal{\textbf{0.077}} & \textbf{0.058} / \rebuttal{0.024} & 0.014 / \rebuttal{0.008} & 0.021 / \rebuttal{0.011} & \textbf{0.051} / \rebuttal{0.026} & 0.047 / \rebuttal{0.028} & 0.059 / \rebuttal{0.020} \\
        & Caterpillar & 0.053 / \rebuttal{0.021} & 0.021 / \rebuttal{0.009} & \textbf{0.040} / \rebuttal{0.006} & \textbf{0.027} / \rebuttal{0.005} & 0.034 / \rebuttal{0.015} & \textbf{0.069} / \rebuttal{0.006} & 0.195 / \rebuttal{\textbf{0.358}} \\
        & Fish & 0.032 / \rebuttal{0.047} & 0.023 / \rebuttal{0.012} & 0.023 / \rebuttal{0.010} & 0.015 / \rebuttal{0.007} & 0.021 / \rebuttal{0.019} & 0.028 / \rebuttal{0.029} & 0.041 / \rebuttal{0.013} \\
        & Panda & 0.064 / \rebuttal{0.014} & 0.023 / \rebuttal{0.003} & 0.009 / \rebuttal{0.004} & 0.008 / \rebuttal{0.001} & 0.014 / 0.003 & 0.013 / \rebuttal{0.002} & 0.035 / \rebuttal{0.031} \\
        \midrule
        \multirow{4}{*}{\makecell{Velocity\\Tracking}} & Baby Seal & 0.343 / \rebuttal{0.410} & 0.257 / \rebuttal{0.194} & 0.249 / \rebuttal{0.222} & 0.231 / \rebuttal{0.205} & 0.290 / \rebuttal{0.265} & 0.215 / \rebuttal{0.198} & 0.379 / \rebuttal{0.068} \\
        & Caterpillar & 0.502 / \rebuttal{0.368} & 0.101 / \rebuttal{0.156} & 0.426 / \rebuttal{0.192} & 0.282 / \rebuttal{0.058} & 0.441 / \rebuttal{0.376} & 0.379 / \rebuttal{0.133} & 0.555 / \rebuttal{\textbf{0.714}} \\
        & Fish & 0.216 / \rebuttal{0.256} & 0.416 / \rebuttal{0.319} & 0.221 / \rebuttal{0.236} & 0.234 / \rebuttal{\textbf{0.303}} & \textbf{0.457} / \rebuttal{0.311} & \textbf{0.638} / \rebuttal{0.307} & 0.657 / \rebuttal{0.574} \\
        & Panda & \textbf{0.575} / \rebuttal{0.424} & \textbf{0.555} / \rebuttal{0.383} & \textbf{0.536} / \rebuttal{0.534} & 0.153 / \rebuttal{0.195} & 0.450 / \rebuttal{0.359} & 0.472 / \rebuttal{0.288} & 0.395 / \rebuttal{0.220} \\
        \midrule
        \multirow{4}{*}{\makecell{Waypoint\\Following}} & Baby Seal & -0.012 / \rebuttal{-0.014} & -0.018 / \rebuttal{-0.027} & -0.018 / \rebuttal{-0.027} & \textbf{-0.020} / \rebuttal{-0.026} & -0.012 / \rebuttal{-0.025} & -0.014 / \rebuttal{-0.026} & -0.010 / \rebuttal{-0.026} \\
        & Caterpillar & -0.013 / \rebuttal{-0.016} & -0.019 / \rebuttal{-0.028} & \textbf{-0.016} / \rebuttal{-0.028} & \textbf{-0.020} / \rebuttal{-0.027} & -0.013 / \rebuttal{-0.027} & -0.018 / \rebuttal{-0.026} & \textbf{-0.002} / \rebuttal{-0.019} \\
        & Fish & -0.004 / \rebuttal{-0.016} & -0.016 / \rebuttal{-0.026} & -0.022 / \rebuttal{-0.029} & -0.024 / \rebuttal{-0.027} & \textbf{-0.007} / \rebuttal{-0.024} & \textbf{-0.003} / \rebuttal{-0.024} & -0.005 / \rebuttal{-0.023} \\
        & Panda & \textbf{-0.003} / \rebuttal{-0.014} & \textbf{-0.014} / \rebuttal{-0.025} & -0.021 / \rebuttal{-0.027} & -0.023 / \rebuttal{-0.028} & -0.010 / \rebuttal{-0.024} & -0.008 / \rebuttal{-0.025} & -0.013 / \rebuttal{-0.026} \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \label{tab:benchmark}
    \vspace{-4mm}
\end{table}

\subsection{Environment Setup}
\label{ssec:task_representation}

\noindent\textbf{Initialization.} Environment construction requires three steps: terrain generation, robot placement, and material covering. First, we procedurally generate terrain height-maps using Perlin noise with user-defined height range and other parameters for roughness. The generated height map is converted to a mesh for ground surface. We then instantiate a robot using specified design parameters.  A user may choose to have the robot placed randomly or at a fixed pre-defined position on the terrain. Then, we compute an occupancy map in the Eulerian grid in MPM based on particles of robot body and terrain’s SDF. Finally, we use the terrain's surface normal to layer particles of specified terrain materials atop it, using the occupancy map to avoid particle placement in non-free space.

A co-design algorithm consists of \textit{1)} a design optimizer that proposes a robot design at the start of a simulation trial (an ``episode'' in reinforcement learning terminology) and \textit{2)} a control optimizer that specifies a controller that determines robot actuation based on its observed state. Accordingly, each task interfaces with the algorithm through the \textit{robot design interface}, \textit{observation}, \textit{action}, and \textit{reward}. We introduce each element as follows.

\noindent\textbf{Robot Design Interface.} Robot design involves specification of geometry, stiffness, and muscle placement. We integrate these design specifications into Lagrangian particles in MPM simulation. Geometry is modeled by mass \rebuttal{$m_p\in\mathbb{R}$} (clamping regions of sufficiently low mass to $0$); stiffness is modeled by a \rebuttal{the Young's modulus in elastic material $s_p\in\mathbb{R}$}. We remove non-existing (zero-mass) particles to eliminate their effect.  (Low and zero mass particles cause numerical instabilities during simulation.) For muscle placement \rebuttal{$\mathbf{r}_p\in\mathbb{R}^K$} on a robot with at most $K$ actuators, we augment each actuated particle with a $K$-dimensional unit-vector where the magnitude of component $i$  specifies the contribution of actuator $i$ to that particle as well as a 3-dimensional unit-vector to specify muscle direction \rebuttal{$\mathbf{f}_p\in\mathbb{R}^3$}. 
%and muscle placement can exhibit varying number of actuators by setting non-zero entries at a subset of dimensions. 
While a robot is represented as a particle set in the simulator, \name allows common 3D representations other than point clouds such as voxel grids or meshes. We instantiate a set of particles in a bounding base shape (\textit{e.g.}, a box or ellipsoid), which defines the workspace of a robot design \rebuttal{with position $\{\mathbf{x}_p\}$, velocity $\{\mathbf{v}_p\}$, and other attributes required in MPM}. For voxel grids, we utilize a voxelizer to transfer voxel occupancy to particle mass that resides in that voxel. For meshes, we compute SDF for particles in the bounding base shape and assign non-zero mass to sub-zero level set (those with negative signed distance).
% For meshes, we compute SDF of the base particle set and assign mass based on sub-zero level set. Note that to fully describe robot design, meshes need to be coupled with other 3D representation as it only captures information on the surface. \todo{TBU}

\noindent\textbf{Observation.} Robot state observations, which are fed to controllers, are computed at every step in an episode, consisting of robot proprioceptive information, environmental information, and task-related information. For robot proprioceptive information, considering states of all particles in robot body is unrealistic from both the perspective of sensor placement and computational tractability. Instead, we compute the position and velocity centroids of the robot body, or of pre-defined body parts. The environment is summarized as a \textit{semantic occupancy map}; from the MPM Eulerian grid, a 3D voxel grid is constructed in with each voxel indicates occupancy of terrain (below the SDF boundary), terrain material particles, or the robot. 
%Particle occupancy is obtained by scattering semantic information through the similar process in P2G with a quadratic B-spline function. This observation remains well-structured regardless of deforming or even shape-shifting robot body. 
Finally, task-related information provides sufficient specifications in order to solve certain task, \textit{e.g.}, target waypoints to be followed.

\noindent\textbf{Action.} At each time step, the simulator queries the robot controller for an action vector \rebuttal{$\mathbf{u}\in\mathbb{R}^K$}. (Note that the time step is at the time scale of a robot controller, different from simulation steps often referred to as substeps.) We use the same action vector for all simulation steps within an environment time step. The returned action vector is of length as $K$, the maximal number of actuators. 
%Whether a dimension of the action vector takes effect depends on the existence of the actuator in robot body (\textit{i.e.}, whether there is more than one particle in the robot body with a non-zero entry of actuator placement at that dimension). 
The action space bound is set to achieve reasonable robot motion without easily causing numerical fracture of robot body. We use $[-0.3,0.3]$ as coordinate-wise bound in this paper.

\noindent\textbf{Reward.} A robot's task performance is quantitatively measured by a scalar-valued reward function. The reward definition is task-specific and computed at every time step to provide feedback signal to the robot. Please refer to \secref{ssec:locomotion_tasks} for detailed descriptions of reward for every tasks. 


\begin{figure*}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{asset/interesting_motion}
        \vspace{-1mm}

    \caption{Unique motions arising from morphology and environment to achieve locomotion.}
    \label{fig:interplay}
    \vspace{-6mm}
\end{figure*}

\subsection{Locomotion Tasks}
\label{ssec:locomotion_tasks}

We only mention the high-level goal of each task. Please refer to \secref{sec:appendix_locomotion_tasks} for more details.

\noindent\textbf{Movement Speed.} In this task, the robot aims to move as fast as possible along a target direction. 

\noindent\textbf{Turning.} In this task, the robot is encouraged to turn as fast as possible counter-clockwise about the upward direction of robot's canonical pose.

\noindent\textbf{Velocity Tracking.} In this task, the robot is required to track a series of timestamped velocities. 

\noindent\textbf{Waypoint Following.} In this task, the robot needs to follow a sequence of waypoints.
