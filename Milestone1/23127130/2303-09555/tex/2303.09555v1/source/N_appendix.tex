\appendix

\rebuttal{
\section{Notations}
\tabref{tab:notations} shows a list of notations used in the description of \namenospace, where the subscript $p$ indicates association with particles. Note that actuation is defined per particle and action vector is defined as the output of controllers (which can be very low-dimensional such as $\mathbb{R}^{10}$), i.e., $a_p=\mathbf{u}\cdot \mathbf{f}_p$.
\begin{center}
    \label{tab:notations}
    \begin{tabular}{ c|c|l } 
        \toprule
        Symbol & Type & Description \\
        \hline
        $m_p$ & scalar & mass \\
        $s_p$ & scalar & stiffness \\
        $a_p$ & scalar & actuation \\
        $\mathbf{u}$ & vector & action vector \\
        $\mathbf{x}_p$ & vector & position \\
        $\mathbf{v}_p$ & vector & velocity \\
        $\mathbf{r}_p$ & vector & muscle placement / membership \\
        $\mathbf{f}_p$ & vector & muscle direction \\
        $\mathbf{F}_p$ & matrix & deformation gradient \\
        $\boldsymbol{\sigma}_p$ & matrix & Cauchy stress \\
        $\boldsymbol{C}_p$ & matrix & affine velocity field \\
        \bottomrule
    \end{tabular}
\end{center}
}

\section{Locomotion Tasks}
\label{sec:appendix_locomotion_tasks}

\subsection{Movement Speed}
In this task, the goal of the robot is to move as fast as possible along a pre-defined direction. We compute the average velocity of all existing (non-zero-mass) particles on robot body and project it to the target direction to obtain a scalar estimate.
\rebuttal{
We thus write the metric per timestep as,
\begin{align*}
    r_{\text{speed}} = \sum_p m_p (\mathbf{v}_p \cdot \mathbf{t})
\end{align*}
where $m_p$ is mass, $\mathbf{v}_p$ is velocity, and $\mathbf{t}$ is a pre-defined target direction.
}

\subsection{Turning} In this task, the robot is encouraged to turn as fast as possible counter-clockwise about the upward direction of robot's canonical pose. We first compute the relative position of all particles on robot body with respect to its center of mass. We then compute the cross product of the upward direction followed by unit-vector normalization to obtain tangential directions for all particle while turning. Finally, we compute velocity projection of every particle along the tangent and return the average as the measure of turning performance.
\rebuttal{
We thus write the metric per timestep as,
\begin{align*}
    r_{\text{turning}} = \sum_p m_p (\mathbf{v}_p \cdot \frac{\mathbf{d} \times \mathbf{v}_p}{||\mathbf{d} \times \mathbf{v}_p||})
\end{align*}
where $m_p$ is mass, $\mathbf{v}_p$ is velocity, and $\mathbf{d}$ is the up direction (defined manually based on robot canonical forward direction).
}

\subsection{Velocity Tracking} In this task, the robot is required to track a series of timestamped velocities. We use quintic polynomials formulated as a function of time for path parameterization since it generates smooth trajectories with easy access to different orders of derivative. A path can be fully specified with start and target position \rebuttal{$\mathbf{x}_s$,$\mathbf{x}_t$}, velocity \rebuttal{$\mathbf{v}_s$, $\mathbf{v}_t$}, and acceleration \rebuttal{$\mathbf{a}_s$, $\mathbf{a}_t$}.
\rebuttal{
We can then obtain the quintic polynomial as,
\begin{align*}
    \mathbf{x}_{\text{path}}(t) &= \mathbf{c}_0 + \mathbf{c}_1 t + \mathbf{c}_2 t^2 + \mathbf{c}_3 t^3 + \mathbf{c}_4 t^4 + \mathbf{c}_5 t^5
\end{align*}
where $t$ is time and $\mathbf{c}_0,\mathbf{c}_1,\mathbf{c}_2,\mathbf{c}_3,\mathbf{c}_4,\mathbf{c}_5\in \mathbb{R}^3$ are coefficients.
}
After setting a target state, we query the first-order derivative of the polynomial at each environment time step as the target velocity,
\rebuttal{
\begin{align*}
    \mathbf{v}_{\text{path}}(t) &= \mathbf{c}_1 + 2\mathbf{c}_2 t + 3\mathbf{c}_3 t^2 + 4\mathbf{c}_4 t^3 + 5\mathbf{c}_5 t^4
\end{align*}
We write target velocity at a time instance as $\mathbf{v}_{\text{target}}$ for the following.
}
Furthermore, due to the deforming nature of soft robot, we need to estimate the heading of the robot in order compare it with the target velocity. We manually label particles corresponding to a head and a tail of the robot \textit{a priori} \rebuttal{$p_{\text{head}}, p_{\text{tail}}$ based on its canonical heading direction.
\begin{align*}
    \mathbf{d} = \frac{\mathbf{x}_{p_{\text{head}}} - \mathbf{x}_{p_{\text{tail}}}}{|| \mathbf{x}_{p_{\text{head}}} - \mathbf{x}_{p_{\text{tail}}} ||}
\end{align*}
} During robot motion, we extract rotation from deformation gradient of these particles and inversely transform them back to material space to compute heading direction. 
\rebuttal{
\begin{align*}
    \mathbf{F}_p &= \mathbf{U}_p\mathbf{R}_p^T \\
    \mathbf{v}_p^{\text{proj}} &= (\mathbf{R}_p^T \mathbf{v}_p \cdot \mathbf{d}) \mathbf{d}
\end{align*}
where $\mathbf{F}_p$ is deformation gradient, $\mathbf{U}_p,\mathbf{R}_p^T$ are the results of polar decomposition.
}
Velocities of all particles on robot body are then projected to the heading direction and averaged in order to compare to the target velocity.
We separate the measurement of magnitude and direction as this allows different weighting of the two terms. 
\rebuttal{
We can then write the metric per timestep as,
\begin{align*}
    r_{\text{vel-track}} &= \alpha_{\text{mag}}r_{\text{mag},p} + \alpha_{\text{dir}}r_{\text{dir},p}, \\
    \text{where } r_{\text{mag},p} &= -(||\mathbf{v}_{\text{target}}|| - || \bar{\mathbf{v}}^{\text{proj}} ||)^2 \\
    r_{\text{dir},p} &= \mathbf{v}_{\text{target}} \cdot \frac{\bar{\mathbf{v}}^{\text{proj}}}{|| \bar{\mathbf{v}}^{\text{proj}} ||} \\ 
    \bar{\mathbf{v}}^{\text{proj}} &= \sum_p m_p \mathbf{v}_p^{\text{proj}}
\end{align*}
where $\alpha_{\text{mag}},\alpha_{\text{dir}}$ are coefficients of magnitude and direction term respectively and we set $\alpha_{\text{mag}}=0.1$ and $\alpha_{\text{dir}}=0.9$.
}
We put more emphasis on the alignment of direction since it better indicates maneuverability.

\subsection{Waypoint Following} In this task, the robot needs to follow a sequence of waypoints. The waypoints are generated by the above-mentioned quintic polynomial method \rebuttal{$\mathbf{x}_{\text{path}}(t)$}. We compute root mean squared error between robot center of mass and the target waypoint for each time step. 
\rebuttal{
We denote target position at a time instance as $\mathbf{x}_{\text{target}}$. We can then write the metric per timestep as,
\begin{align*}
    r_{\text{waypoint}} = (\mathbf{x}_{\text{target}} - \sum_p m_p \mathbf{x}_p )^2
\end{align*}
}
Remark that well-performing velocity tracking can induce large waypoint following error but trace out similar-shaped yet different-scaled trajectories. Both serve a role as distinct aspects of evaluating path following.

\section{Platform comparison}
\label{sec:appendix_platform_comparison}

A comprehensive comparison to existing soft robot platform is shown in \tabref{tab:comparison}.

\begin{table}[h]
    \scriptsize
    % \footnotesize
    \centering
    \caption{Comparison to existing soft robot platforms.}
    \label{tab:comparison}
    \begin{tabular}{c|c|c|c|c|c|c}
        \toprule
        Platform & \makecell{Simulation \\ Method} & Tasks & Design & Control &  Differentiability & \makecell{Multiphysical \\ Materials} \\
        \midrule
        SoMoGym \citep{graule2022somogym} & \makecell{Rigid-link System} & \makecell{Mostly\\ Manipulation} & & \checkmark & \\
        \midrule
        DiffAqua \citep{ma2021diffaqua} & FEM & Swimmer & \checkmark & \checkmark & \checkmark & \\
        \midrule
        EvoGym \citep{bhatia2021evolution} & \makecell{2D Mass-spring\\ System} & \makecell{Locomotion \\ Manipulation} & \checkmark & \checkmark & \\
        \midrule
        \name (Ours) & MPM & Locomotion & \checkmark & \checkmark & \checkmark & \checkmark \\
        \bottomrule
    \end{tabular}
\end{table}

\section{Continuum Mechanics Simulation}
\label{sec:sim}

We formulate the continuum mechanics simulation in the framework of the moving least squares material point method (MLP-MPM)~\citep{hu2018moving}, whose governing equations are characterized by:
\begin{align}
    \rho\frac{D\mathbf{v}}{Dt}&=\nabla\cdot\bm{\sigma}+\rho\mathbf{f}_\text{ext}\\
    \rho\frac{D\rho}{Dt}&=-\rho\nabla\cdot\mathbf{v},
\end{align}
where $\rho$ is the density of the material, $\mathbf{v}$ is the velocity, $\bm{\sigma}$ is the Cauchy stress of the energy, and $\mathbf{f}_\text{ext}$ is the external forces applied, which is the gravity in our cases. We solve these equations for an equilibrium between different materials coupled in our environments. We will not dive further into continuum mechanics and point the interested reader to \cite{gonzalez2008first} for more details. In terms of the implementation of the differentiable physics-based simulation, we massively use DiffTaichi~\citep{hu2019difftaichi} as the backbone.

\begin{table}[t]
\centering
\small
\caption{The physical phenomenons that each environment covered in our multiphysical simulation.}
\begin{tabular}{c|cccc}
\toprule
\textbf{Environment}   & \textbf{Elasticity} & \textbf{Plasticity} & \textbf{Fluid} & \textbf{Friction} \\ \midrule
Ground        &            &            &       &     High     \\ \midrule
Desert        &      \checkmark      &      \checkmark     &       &          \\ \midrule
Wetland       &       \checkmark    &      \checkmark    &   Mixed   &          \\ \midrule
Clay          &      \checkmark     &     \checkmark     &       &          \\ \midrule
Ice           &            &            &       &    Low      \\ \midrule
Snow          &     \checkmark    &     \checkmark    &       &          \\ \midrule
Shallow Water &            &            &   Shallow   &          \\ \midrule
Ocean         &            &            &    Deep  &          \\ \bottomrule
\end{tabular}
\label{tab:material}
\end{table}


\section{Multiphysical Materials}
\label{sec:material}

For result validation and visual entertainment, we present a diverse set of environments spanned by different material setups and tasks. Here we illustrate the materials that each environment covered in Table~\ref{tab:material}. Note that even though \textit{Desert}, \textit{Clay}, and \textit{Snow} share the same composition of material types, we distinguish their elastoplasticity by imposing different parameters and models (\textit{e.g.}, friction cone). We will release the code-level implementation of all materials for reproducibility.

% Writeup.
% \begin{itemize}
%     \item More detailed description (including math) for multi-material simulation. (Provide a set of general math formulae of MPM, followed by modified formulation for different material)
%     \item Pseudo code of gradient checkpointing.
%     \item Configuration of all environments.
%     \item More detailed description of all baselines.
%     \item Controller.
% \end{itemize}

\section{Gradient Checkpointing}

Simulating environments like ocean, desert, etc requires a significant amount of particles. This poses a challenge in differentiation as the computation graph needs to be cached for backward pass, leading to considerably high memory usage. Accordingly, we implement gradient checkpointing that allows very large-scale simulation with gradient computation. Instead of caching simulation state at every single step, we only store data every $N$ steps. When doing backward pass at $i\times N$ steps, we perform recomputation of forward pass from $(i-1) \times N$ to $i\times N$ to reconstruct the computation graph in-between for reverse-mode automatic differentiation. % \todo{Add pseudo code}

\section{Optimization}

In this section, we describe the implementation details of each optimization method.

\subsection{Differentiable Physics}

Model-based gradient provides much accurate searching direction and thus considerably more efficient optimization. However, gradient information is susceptible to local optimum and often leads to bad convergence without proper initialization. Hence, we adopt a simple yet effective approach that samples 8 random seeds, performs optimization with differentiable physics for all runs, and picks the best result.
\rebuttal{
More formally we write as,
\begin{align*}
    \theta^* &= F(\mathcal{L}; \underset{\theta_0}{\argmin}~F(\mathcal{L}, \theta_0))
\end{align*}
where $\theta$ are the model parameters, $\theta_0$ is the initialization of a model, $\mathcal{L}$ is a cost function, $F$ summarizes the optimization that follows the gradient update $\theta_{k+1} = \theta_k - \eta h(\nabla \mathcal{L})$, $\eta$ is the learning rate, and $h$ is a function that specifies different gradient descent variants.
}
For the large-scale benchmark with biologically-inspired design (\tabref{tab:benchmark}), we use learning rate $0.1$ and training iterations $30$. For all control-only and design-only optimization, we use learning rate $0.01$ and training iterations $100$. For co-design, we use learning rate $0.01$ for both control and design with training iterations $250$. We use Adam as the optimizer.

\subsection{Reinforcement Learning}

RL is only used in control optimization. We use Proximal Policy Optimization (PPO) \citep{schulman2017proximal} with the following hyperparameters: number of timesteps $10^5$, buffer size $2048$, batch size $32$, GAE coefficient $0.95$, discounting factor $0.98$, number of epochs $20$, entropy coefficient $0.001$, learning rate $0.0001$, clip range $0.2$. We use the same controller parameterization as all other experiments throughout the paper.

\subsection{Evolution Strategy}

We implement a fully-ES-based method as a co-design baseline. The genome fitness function is set as the episode reward of the environment. We pose a constraint on connected component of robot body. For CPPN, we use a set of activation functions including \textit{sigmoid}, \textit{tanh}, \textit{sin}, \textit{gaussian}, \textit{selu}, \textit{abs}, \textit{log}, \textit{exp}. The inputs of CPPN include x, y, z coordinates along with distance along xy, xz, yz planes and radius from the body center. We use HyperNEAT \citep{stanley2009hypercube} for design optimization and CMA-ES \citep{hansen2003reducing} for control optimization with initial standard deviation as $0.1$. We don't use an inner-outer-loop scheme for co-design. Instead, HyperNEAT and CMA-ES share the same set of population with population size as $10$. We run ES for 100 generations for the co-design baseline.

\section{Controller Parameterization}
\label{sec:appendix_controller}

Locomotion often exhibits cyclic motion and thus control optimization can significantly benefit from considering periodic functions in controller parameterization. Specifically, we use a set of sine functions with different frequency and phase (offset) as bases. The controller is hence parameterized with a set of weights on these bases along with bias terms. 
\rebuttal{
\begin{align*}
    \bar{u}(x,t) &= \sum_{ij} \alpha_{ij} \phi_{ij}(x,t) + \beta_{ij},~~~\phi_{ij}(t) = \text{sin}(\omega_i(x) t + \varphi_j(x))
\end{align*}
where $\phi_{ij}$ are the bases, $\alpha_{ij}$ and $\beta_{ij}$ are learnable weights and biases, $x$ is controller inputs, $\omega_i(x),\varphi_j(x)$ can be either learnable (as neural network) or pre-defined. The control signal is then modulated by a tanh function multiplied by a pre-defined constant to ensure satisfication of control bound.
}
We use 4 different phases with frequency 20 and 80 $rad/s$ throughout the paper. While all experiments presented are not confined to using this sinewave basis controller, we empirically found it extremely efficient to generate reasonable results \rebuttal{in comparison to other controller parameterizations like a generic neural network or trajectory optimization}.

\section{Design Space Representation}
\label{sec:appendix_design_space_repr}

In this section, we provide more implementation details of design space representations.
\rebuttal{
We first recall the notation of robot design interface. $m_p\in \mathbb{R}$ is geometry modeled by mass. $s_p \in \mathbb{R}$ is stiffness. $\mathbf{r}_p \in \mathbb{R}^{K}$ is muscle placement (muscle group assignment) with $K$ as the maximal number of actuators/muscles. $\mathbf{f}_p \in \mathbb{R}^3$ is muscle direction represented in Euler angle. $\tau_m$ is the cutoff threshold of excluding low mass regions for numerical stability. Note that the subscript $p$ indicates attributes associated with a particle. 
%To facilitate further discussion, we then define additional notation. 
$\text{MLP}_{a\veryshortarrow b}(\cdot; \theta)$ denotes a multi-layer perceptron with $a$ inputs, $b$ outputs, and $\theta$ as parameters (we omit hidden layers for clean notation and the output layer is linear). $m_0,s_0\in \mathbb{R}$ are pre-defined and constant reference mass and stiffness respectively. Geometry of all methods are processed by the following formula for numerical stability,
\begin{align*}
    m_p &= \mathbbm{1}_{\hat{m}_p \geq \tau_m} \hat{m}_p
\end{align*}
where $\mathbbm{1}_{\cdot}$ is an indicator function. $\hat{\mathbf{x}}_p\in \mathbb{R}^3$ is a centered and standardized position $\mathbf{x}_p \in \mathbb{R}^3$.  We denote the position of a base particle set $\{\hat{\mathbf{x}}_p\}$ as a point cloud representation that span the robot design workspace, which is a natural representation of continuum material in MPM. Next, we describe each design space representation individually.
}

\subsection{Particle-based Representation.} Given a base particle set \rebuttal{$\{\hat{\mathbf{x}}_p\}$}, we instantiate two trainable scalars followed by sigmoid for geometry and stiffness, and a $K$-dimensional vector followed by softmax for muscle placement with a fixed muscle direction along the canonical heading direction.
\rebuttal{
\begin{align*}
    \hat{m}_p^{\text{PBR}} &= m_0 \cdot \text{Sigmoid}(\tilde{m}_p) \\
    s_p^{\text{PBR}} &= s_0 \cdot \text{Sigmoid}(\tilde{s}_p) \\
    \mathbf{r}_p^{\text{PBR}} &= \text{Softmax}(\tilde{r}_p) \\
    \mathbf{f}_p^{\text{PBR}} &= \mathbf{f}_p^{(0)}
\end{align*}
where $\{ \tilde{m}_p\in \mathbb{R}, \tilde{s}_p \in \mathbb{R}, \tilde{r}_p\in \mathbb{R}^K \}$ are learnable parameters associated with $\hat{\mathbf{x}}_p$, and $\mathbf{f}_p^{(0)}$ is the fixed muscle direction along the canonical heading direction.
}

\subsection{Voxel-based Representation.} We voxelize the given base particle set to obtain a voxel grid and follows similar modelling technique to particle-based representation in voxel level.
\rebuttal{
\begin{align*}
    \hat{m}_p^{\text{VBR}} &= m_0 \cdot \text{Sigmoid}(\text{V2P}(\tilde{m}_v)) \\
    s_p^{\text{VBR}} &= s_0 \cdot \text{Sigmoid}(\text{V2P}(\tilde{s}_v)) \\
    \mathbf{r}_p^{\text{VBR}} &= \text{Softmax}(\text{V2P}(\tilde{r}_v))
\end{align*}
where $\text{V2P}$ is a mapping from voxel space to particle space (e.g., suppose we use a $2\times 2\times 2$ voxel grid to represent $10^3$ particles, we may associate the voxel coordinate $(0,0,0)$ to first $5^3$ particles), $\{ \tilde{m}_v\in \mathbb{R}, \tilde{s}_v \in \mathbb{R}, \tilde{r}_v\in \mathbb{R}^K \}$ are learnable parameters, and the muscle direction is of the same definition as particle-based representation $\mathbf{f}_p^{\text{VBR}}=\mathbf{f}_p^{\text{PBR}}$. In comparison to particle-based representations, in practice the voxel-based representations have much fewer parameters that need to be learned.
}

\subsection{Implicit Function}

We extend the idea of OccupancyNet \citep{mescheder2019occupancy} to predicting robot geometry, stiffness, and muscle placement. It is modeled by a multi-layer perceptron (MLP) with 2 layers and 32 dimensions for each. We use \textit{tanh} activation. The MLP takes in x, y, z coordinates, distance along xy, xz, yz planes and radius from the body center. The network outputs occupancy as geometry using sigmoid, stiffness multiplier using sigmoid, and a $K$-dimensional vector using softmax for muscle placement.
\rebuttal{
We describe in formula as,
\begin{align*}
    \hat{m}_p^{\text{IF}} &= m_0 \cdot \text{Sigmoid}(\text{MLP}_{3\veryshortarrow 1}(\hat{\mathbf{x}}_p;\theta_m)) \\
    s_p^{\text{IF}} &= s_0 \cdot \text{Sigmoid}(\text{MLP}_{3\veryshortarrow 1}(\hat{\mathbf{x}}_p;\theta_s)) \\
    \mathbf{r}_p^{\text{IF}} &= \text{Softmax}(\text{MLP}_{3\veryshortarrow K}(\hat{\mathbf{x}}_p;\theta_\mathbf{r}))
\end{align*}
where $\{\theta_m, \theta_s, \theta_\mathbf{r}\}$ are learnable parameters formulated as neural networks, and the muscle direction is of the same definition as particle-based representation $\mathbf{f}_p^{\text{IF}}=\mathbf{f}_p^{\text{PBR}}$. This representation has inherent spatial continuity due to the use of smooth functions $\text{MLP}$ with spatial coordinate $\hat{\mathbf{x}}_p$ as inputs.
}

\subsection{Diff-CPPN}

\textit{Diff-CPPN} is a differentiable version of Compositional Pattern Producing Networks  (CPPN) \citep{stanley2007compositional}, following similar concept in \citep{fernando2016convolution}. CPPN is a graphical model \rebuttal{$\mathcal{G}=\{\mathcal{N}, \mathcal{E}\}$} composed of a set of activation functions \rebuttal{$\Sigma$} with interesting geometric properties (e.g., sine, tanh) that takes in particle or voxel coordinates and output occupancy or other properties. \rebuttal{Each node $n_i\in \mathcal{N}$ has a set of input edges $e_i\in \mathcal{E}$ that can be changed by evolution, and an activation function $\sigma_i\in\sum$. The input-output relationship of a layer can be then written as,
\begin{align*}
    n^{\text{out}}_i &= \sigma_i(\sum_{e_j\in\mathcal{E}}w_j n_j^{\text{in}})
\end{align*}
}
It is originally designed to be optimized with varying graph topologies. We use a meta graph to allow gradient flow and mimic the augmenting topolgies process in NEAT yet in a differentiable manner\rebuttal{
, i.e., the varying topology $w_j\in\{0,1\}$ is softened to $w_j\in \mathbb{R}$. Remark the similarity of the above construction with a layer in regular MLP except for varying activation function across neurons. We then can define,
\begin{align*}
    \hat{m}_p^{\text{Diff-CPPN}} &= m_0 \cdot \text{Sigmoid}(\text{MLP}_{3\veryshortarrow 1}^{\text{CPPN}}(g(\hat{\mathbf{x}}_p);\theta_m)) \\
    s_p^{\text{Diff-CPPN}} &= s_0 \cdot \text{Sigmoid}(\text{MLP}_{3\veryshortarrow 1}^{\text{CPPN}}(g(\hat{\mathbf{x}}_p);\theta_s)) \\
    \mathbf{r}_p^{\text{Diff-CPPN}} &= \text{Softmax}(\text{MLP}_{3\veryshortarrow K}^{\text{CPPN}}(g(\hat{\mathbf{x}}_p);\theta_\mathbf{r}))
\end{align*}
where each layer of $\text{MLP}^{\text{CPPN}}$ follows the aforementioned input-output relationship, $\{\theta_m, \theta_s, \theta_\mathbf{r}\}$ are learnable parameters, and $g(\cdot)$ is a function of expanding position to additional spatial coordinates such as distance to the center (which is normally used in CPPN). We use a fixed muscle direction.
}
The model takes in x, y, z coordinates, distance along xy, xz, yz planes and radius from the body center, and outputs occupancy as geometry using sigmoid, stiffness multiplier using sigmoid, and a $K$-dimensional vector using softmax for muscle placement. We use \textit{sin} and \textit{sigmoid} activation functions with 3 hidden layers and 20 graph nodes in each layer.

\subsection{SDF-Lerp}

Given a base particle set \rebuttal{$\{\hat{\mathbf{x}}_p\}$}, we compute \rebuttal{the linear interpolation among a set of pre-defined design primitives $\{\Psi_i\}_{i=1}^N$, where $N$ is number of design primitives}. The shape of the robot design \rebuttal{$m_p$} is then determined by a set of coefficients weighting the SDFs from design primitives. In other words, the trainable parameters for robot geometry only construct a $N$-dimensional vector. We then compute weighted sum of the SDF bases and extract robot body with the final SDF smaller or equal to zero. We use a low-temperature sigmoid in implementation to keep gradient flow. For stiffness \rebuttal{$s_p$}, we can directly perform linear interpolation. For muscle group membership \rebuttal{$\mathbf{r}_p$}, we use linear interpolation upon the one-hot vectors from design primitives and effectively realize a soft muscle group assignment. For muscle direction \rebuttal{$\mathbf{f}_p$}, we adopt interpolation designed for rotation matrices \citep{bregier2021deep}.
\rebuttal{
Formally,
\begin{align*}
    \hat{m}_p^{\text{SDF-Lerp}} &= m_0 \cdot \frac{1}{1 + e^{-T\sum_{i=1}^N \hat{\alpha}_i \Psi_i^{\text{SDF}}(\hat{\mathbf{x}}_p)}},~~~\hat{\alpha}_i=\frac{\alpha_i}{\sum_j \alpha_j} \\
    s_p^{\text{SDF-Lerp}} &= \sum_{i=1}^N \hat{\beta}_i \Psi_i^s(\hat{\mathbf{x}}_p),~~~\hat{\beta}_i=\frac{\beta_i}{\sum_j \beta_j}\\
    \mathbf{r}_p^{\text{SDF-Lerp}} &= \sum_{i=1}^N \hat{\gamma}_i \Psi_i^\mathbf{r}(\hat{\mathbf{x}}_p),~~~\hat{\gamma}_i=\frac{\gamma_i}{\sum_j \gamma_j}\\
    \mathbf{f}_p^{\text{SDF-Lerp}} &= \text{M2E}(\underset{\mathbf{R}\in \text{SO}(3)}{\argmin}|| \mathbf{R} - \sum_{i=1}^N \hat{\kappa}_i \text{E2M}(\Psi_i^\mathbf{f}(\hat{\mathbf{x}}_p)) ||_F^2),~~~\hat{\kappa}_i=\frac{\kappa_i}{\sum_j \kappa_j}
\end{align*}
where $\{\alpha\in \mathbb{R}^N, \beta\in \mathbb{R}^N, \gamma\in \mathbb{R}^N, \kappa\in \mathbb{R}^N\}$ are learnable coefficients of the interpolation, $\Psi_i^{\text{SDF}}, \Psi_i^{s}, \Psi_i^{\mathbf{r}}, \Psi_i^{\mathbf{f}}$ are the SDF, stiffness, muscle placement, and muscle direction of a design primitive respectively, $T$ is temperature (where we set to $-1000$ to mimic $\text{SDF} \leq 0$), $\text{E2M}$ is conversion from an Euler angle to a rotation matrix, $\text{M2E}$ is conversion from a rotation matrix to an Euler angle, $||\cdot||_F$ is Frobenius norm. The computation of muscle direction $\mathbf{f}_p^{\text{SDF-Lerp}}$ follows rotation matrix interpolation using special Procrustes method, detailed in \citep{bregier2021deep}. In comparison to the above methods, \textit{SDF-Lerp} leverages prior knowledge of design primitives $\Psi_i$ that can provide more structure to the optimization from design space representation.
}

\subsection{Wasserstein Barycenter}

This method also uses design primitives \rebuttal{$\{\Psi_i\}_{i=1}^N$}. First, it adopts the same approach for stiffness and muscle placement as \textit{SDF-Lerp} \rebuttal{, $s_p^{\text{Wass}}=s_p^{\text{SDF-Lerp}}, \mathbf{r}_p^{\text{Wass}}=\mathbf{r}_p^{\text{SDF-Lerp}}$}. We use a fixed muscle direction along the canonical heading direction. The major difference is the way to represent robot geometry. Following \citep{ma2021diffaqua}, we define a probability simplex (i.e., a set of coefficients with length as the number of design primitives) that serves as a weighting in the sense of Wasserstein distance among different shapes.
\rebuttal{
It can be written as,
\begin{align*}
    \hat{m}_p^{\text{Wass}} &= m_0 P_\alpha(\hat{\mathbf{x}}_p)
\end{align*}
where $P_\alpha$ is the Wasserstein barycenter with coefficients $\alpha$ (intuitively, with some abuse of notation, we can view it as probability density function that determines the particle existence), defined as,
\begin{align*}
    P_\alpha &= \underset{P}\sum_i \alpha_i \mathcal{W}_2^2(P, \Psi_i) \\
    \mathcal{W}_2(P, Q) &= \left[ \underset{\pi\in \prod(P,Q)}{\text{inf}}  \iint (\mathbf{x}_p - \mathbf{x}_q)^2 d\pi(\mathbf{x}_p,\mathbf{x}_q) \right]^{\frac{1}{2}}
\end{align*}
where $\mathcal{W}_2$ is 2-Wasserstein distance and $\Psi_i$ is shape primitive. This representation}
better preserves the volume from the shape of design primitives. We refer the reader to the original paper for more details.

\rebuttal{
\section{Full RL Results}
\label{sec:appendix_rl_results}
In \tabref{tab:benchmark}, we show large-scale benchmark of biologically-inspired designs in \namenospace. The comparison includes optimization using differentiable physics and RL. We use 5 random seeds for RL results yet only report average performance due to space limit. In \tabref{tab:benchmark_rl}, we report the full RL results with both mean and standard deviation among all seeds.
\begin{table}[t] 
    \centering
    \caption{\rebuttal{Full RL results of \tabref{tab:benchmark}. Each entry is the mean and standard deviation of 5 random seeds. The higher the better.}}
    \begin{adjustbox}{width=1\columnwidth}
    \begin{tabular}{c|c|ccccccc}
        \toprule
        \multirow{2}{*}{\textbf{Task}} & \multirow{2}{*}{\textbf{Animal}} & \multicolumn{7}{c}{\textbf{Environment}} \\
        & & \textbf{Ground} & \textbf{Ice} & \textbf{Wetland} & \textbf{Clay} & \textbf{Desert} & \textbf{Snow} & \textbf{Ocean} \\
        \midrule 
        \multirow{4}{*}{\makecell{Movement\\Speed}} & Baby Seal & 0.154 $\pm$ 0.096 & 0.010 $\pm$ 0.010 & 0.020 $\pm$ 0.004 & 0.005 $\pm$ 0.002 & 0.034 $\pm$ 0.010 & 0.016 $\pm$ 0.011 & 0.029 $\pm$ 0.003  \\
        & Caterpillar & 0.032 $\pm$ 0.020 & 0.006 $\pm$ 0.005 & 0.016 $\pm$ 0.005 & 0.015 $\pm$ 0.004 & 0.032 $\pm$ 0.004 & 0.017 $\pm$ 0.003 & 0.181 $\pm$ 0.014 \\
        & Fish & 0.033 $\pm$ 0.012 & 0.011 $\pm$ 0.009 & 0.013 $\pm$ 0.003 & 0.014 $\pm$ 0.003 & 0.022 $\pm$ 0.005 & 0.042 $\pm$ 0.017 & 0.151 $\pm$ 0.011 \\
        & Panda & 0.019 $\pm$ 0.008 & 0.006 $\pm$ 0.005 & 0.008 $\pm$ 0.002 & 0.005 $\pm$ 0.001 & 0.009 $\pm$ 0.002 & 0.004 $\pm$ 0.001 & 0.007 $\pm$ 0.003 \\
        \midrule
        \multirow{4}{*}{Turning} & Baby Seal & 0.077 $\pm$ 0.020 & 0.024 $\pm$ 0.009 & 0.008 $\pm$ 0.003 & 0.011 $\pm$ 0.001 & 0.026 $\pm$ 0.011 & 0.028 $\pm$ 0.009 & 0.020 $\pm$ 0.026 \\
        & Caterpillar & 0.021 $\pm$ 0.007 & 0.009 $\pm$ 0.005 & 0.006 $\pm$ 0.002 & 0.005 $\pm$ 0.003 & 0.015 $\pm$ 0.008 & 0.006 $\pm$ 0.005 & 0.358 $\pm$ 0.024 \\
        & Fish & 0.047 $\pm$ 0.010 & 0.012 $\pm$ 0.009 & 0.010 $\pm$ 0.006 & 0.007 $\pm$ 0.002 & 0.019 $\pm$ 0.008 & 0.029 $\pm$ 0.019 & 0.013 $\pm$ 0.005 \\
        & Panda & 0.014 $\pm$ 0.007 & 0.003 $\pm$ 0.003 & 0.004 $\pm$ 0.000 & 0.001 $\pm$ 0.000 & 0.002 $\pm$ 0.002 & 0.003 $\pm$ 0.002 & 0.031 $\pm$ 0.001 \\
        \midrule
        \multirow{4}{*}{\makecell{Velocity\\Tracking}} & Baby Seal & 0.410 $\pm$ 0.236 & 0.194 $\pm$ 0.079 & 0.222 $\pm$ 0.026 & 0.205 $\pm$ 0.024 & 0.265 $\pm$ 0.024 & 0.198 $\pm$ 0.041 & 0.068 $\pm$ 0.051 \\
        & Caterpillar & 0.368 $\pm$ 0.081 & 0.156 $\pm$ 0.358 & 0.192 $\pm$ 0.034 & 0.058 $\pm$ 0.028 & 0.376 $\pm$ 0.047 & 0.133 $\pm$ 0.221 & 0.714 $\pm$ 0.072 \\
        & Fish & 0.256 $\pm$ 0.113 & 0.319 $\pm$ 0.123 & 0.236 $\pm$ 0.026 & 0.303 $\pm$ 0.070 & 0.311 $\pm$ 0.157 & 0.307 $\pm$ 0.127 & 0.574 $\pm$ 0.141 \\
        & Panda & 0.424 $\pm$ 0.049 & 0.383 $\pm$ 0.139 & 0.534 $\pm$ 0.082 & 0.195 $\pm$ 0.063 & 0.359 $\pm$ 0.034 & 0.288 $\pm$ 0.073 & 0.220 $\pm$ 0.268 \\
        \midrule
        \multirow{4}{*}{\makecell{Waypoint\\Following}} & Baby Seal & -0.014 $\pm$ 0.008 & -0.027 $\pm$ 0.002 & -0.027 $\pm$ 0.001 & -0.026 $\pm$ 0.001 & -0.025 $\pm$ 0.002 & -0.026 $\pm$ 0.001 & -0.026 $\pm$ 0.001 \\
        & Caterpillar & -0.016 $\pm$ 0.004 & -0.028 $\pm$ 0.003 & -0.028 $\pm$ 0.000 & -0.027 $\pm$ 0.000 & -0.027 $\pm$ 0.001 & -0.026 $\pm$ 0.001 & -0.019 $\pm$ 0.007 \\
        & Fish & -0.016 $\pm$ 0.005 & -0.026 $\pm$ 0.002 & -0.029 $\pm$ 0.003 & -0.027 $\pm$ 0.003 & -0.024 $\pm$ 0.001 & -0.024 $\pm$ 0.001 & -0.023 $\pm$ 0.000 \\
        & Panda & -0.014 $\pm$ 0.004 & -0.025 $\pm$ 0.004 & -0.027 $\pm$ 0.001 & -0.028 $\pm$ 0.000 & -0.024 $\pm$ 0.001 & -0.025 $\pm$ 0.001 & -0.026 $\pm$ 0.000 \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \label{tab:benchmark_rl}
\end{table}
}

\section{Visualization of Biologically-inspired Design}
\label{sec:appendix_vis_design}

In this section, we demonstrate the biologically-inspired designs used in this paper. In \figref{fig:animal_visualization}, we show the four animals used in the main paper, including \textit{Baby Seal}, \textit{Caterpillar}, \textit{Fish}, and \textit{Panda}. In \figref{fig:fish_visualization}, we show the set of design primitives used in \textit{SDF-Lerp} and \textit{Wasserstein Barycenter}.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{asset/animal_visualization}
    \caption{Visualization of animals for biologically-inspired design.}
    \label{fig:animal_visualization}
\end{figure*}


\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{asset/fish_visualization}
    \caption{Visualization of fish-like design primitives.}
    \label{fig:fish_visualization}
\end{figure*}
