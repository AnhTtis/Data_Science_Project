
\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}
\iclrfinalcopy

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}

% added packages
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{booktabs}
\usepackage{caption}
% \usepackage{subcaption}
\usepackage{amsfonts}

\usepackage{color}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{float}

\usepackage{subfigure}
\usepackage{lipsum}
\usepackage{tabularx}
\usepackage{makecell}

% \usepackage{subcaption}
\usepackage{cleveref}

\usepackage{natbib}
\usepackage{wrapfig}
\usepackage{xspace}
\usepackage{gensymb}

\usepackage{array}


% color
\definecolor{jycolor}{RGB}{0,51,124}
\definecolor{mtcolor}{RGB}{0,0,255}
\definecolor{wscolor}{RGB}{54,47,217}
\definecolor{hscolor}{RGB}{197,0,94}

\newcommand{\ie}{\textit{i}.\textit{e}.}
\newcommand{\eg}{\textit{e}.\textit{g}.}
\newcommand{\jy}[1]{\textcolor{jycolor}{#1}} % junyoung
\newcommand{\mt}[1]{\textcolor{mtcolor}{#1}} % mathew
\newcommand{\ws}[1]{\textcolor{wscolor}{#1}} % wooseok
\newcommand{\hs}[1]{\textcolor{hscolor}{#1}} % hyeonsu
\newcommand{\paragrapht}[1]{\noindent\textbf{#1}}  %

\title{Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

% \author{Antiquus S.~Hippocampus, Natalia Cerebro \& Amelie P. Amygdale \thanks{ Use footnote for providing further information
% about author (webpage, alternative address)---\emph{not} for acknowledging
% funding agencies.  Funding acknowledgements go at the end of the paper.} \\
% Department of Computer Science\\
% Cranberry-Lemon University\\
% Pittsburgh, PA 15213, USA \\
% \texttt{\{hippo,brain,jen\}@cs.cranberry-lemon.edu} \\
% \And~~~Hyoungwon Cho
% Ji Q. Ren \& Yevgeny LeNet \\
% Department of Computational Neuroscience \\
% University of the Witwatersrand \\
% Joburg, South Africa \\
% \texttt{\{robot,net\}@wits.ac.za} \\
% \AND
% Coauthor \\
% Affiliation \\
% Address \\
% \texttt{email}
% }

\author{Junyoung Seo\thanks{Equal contribution.} $\,^\text{1}$~~~~Wooseok Jang\footnotemark[1] $\,^\text{1}$~~~~Min-Seop Kwak\footnotemark[1] $\,^\text{1}$~~~~Hyeonsu Kim$^\text{1}$~~~~Jaehoon Ko$^\text{1}$ \\
\textbf{Junho Kim}$^\text{2}$~~~~\textbf{Jin-Hwa Kim}\thanks{Co-corresponding author.} $\,^\text{2,3}$~~~~\textbf{Jiyoung Lee}\footnotemark[2] $\,^\text{2}$~~~~\textbf{Seungryong Kim}\footnotemark[2] $\,^\text{1}$\\
\\
$^\text{1}$Korea University~~~~~~$^\text{2}$NAVER AI Lab~~~~~~$^\text{3}$AI Institute of Seoul National University
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\newcommand{\ours}{\texttt{\textbf{3DFuse}}\xspace}

%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle
\vspace{-15pt}
\begin{abstract}   
\vspace{-10pt}
Text-to-3D generation has shown rapid progress in recent days with the advent of score distillation sampling (SDS), a methodology of using pretrained text-to-2D diffusion models to optimize a neural radiance field (NeRF) in a zero-shot setting. However, the lack of 3D awareness in the 2D diffusion model often destabilizes previous methods from generating a plausible 3D scene. To address this issue, we propose \ours, a novel framework that incorporates 3D awareness into the pretrained 2D diffusion model, enhancing the robustness and 3D consistency of score distillation-based methods. Specifically, we introduce a consistency injection module which constructs a 3D point cloud from the text prompt and utilizes its projected depth map at given view as a condition for the diffusion model. The 2D diffusion model, through its generative capability, robustly infers dense structure from the sparse point cloud depth map and generates a geometrically consistent and coherent 3D scene. We also introduce a new technique called semantic coding that reduces semantic ambiguity of the text prompt for improved results. Our method can be easily adapted to various text-to-3D baselines, and we experimentally demonstrate how our method notably enhances the 3D consistency of generated scenes in comparison to previous baselines, achieving state-of-the-art performance in geometric robustness and fidelity. Project page is available at \textnormal{\url{https://ku-cvlab.github.io/3DFuse/}}
\vspace{-10pt}
\end{abstract}


\input{1_introduction}

\begin{figure}[t]
\centering
\renewcommand{\thesubfigure}{}
\subfigure[(a) Naive score distillation]
{\includegraphics[width=0.49\textwidth]{fig/fig2_donkey_a.pdf}}
\label{fig:fig2_a}
\vspace{-5pt}
\subfigure[(b) 3D aware score distillation (Ours)]
{\includegraphics[width=0.49\textwidth]{fig/fig2_donkey_b.pdf}}
\label{fig:fig2_b}
\vspace{-5pt}\\
    \caption{\textbf{Motivation.} (a) Previous methods~\citep{poole2022dreamfusion,song2020score} solely use noised rendered images and text prompt for score distillation, often resulting in scenes with poor 3D consistency. Our \ours addresses this issue by giving diffusion models 3D awareness through consistency injection module, achieving drastic improvement in 3D consistency of generated scenes.     }
    \label{fig:fig2}\vspace{-5pt}
\end{figure}

\input{2_related_work}

\section{Preliminary}
\input{3_preliminaries}

\section{Method}
\input{4_methology}

\section{Experiments}
\input{5_experiments}

\section{Conclusion}
\input{6_conclusion}

\bibliography{iclr2024_conference}
\bibliographystyle{iclr2024_conference}

\newpage
% \begin{appendix}
% \appendix
\input{appendix}

\end{document}
