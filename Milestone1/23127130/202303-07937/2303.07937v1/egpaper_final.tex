\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{booktabs}
\usepackage{caption}
\usepackage{amsfonts}

\usepackage{color}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{float}

\usepackage{subfigure}
\usepackage{lipsum}

\usepackage[breaklinks=true,bookmarks=false]{hyperref}
\usepackage{cleveref}
\pagenumbering{arabic}
\iccvfinalcopy

\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}


\newcommand\ours{\texttt{3DFuse}\xspace}

\begin{document} 

\title{Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation}

\author{Junyoung Seo\thanks{Equal contribution.} $\,^\text{1}$~~~~Wooseok Jang\footnotemark[1] $\,^\text{1}$~~~~Min-Seop Kwak\footnotemark[1] $\,^\text{1}$~~~~Jaehoon Ko$^\text{1}$~~~~Hyeonsu Kim$^\text{1}$ \\
Junho Kim$^\text{2}$~~~~Jin-Hwa Kim\thanks{Co-corresponding author.} $\,^\text{2}$~~~~Jiyoung Lee\footnotemark[2] $\,^\text{2}$~~~~Seungryong Kim\footnotemark[2] $\,^\text{1}$\\
\\
$^\text{1}$Korea University~~~~~~$^\text{2}$NAVER AI Lab
}


\twocolumn{
\maketitle
}



%%%%%%%%% ABSTRACT
\begin{abstract}
Text-to-3D generation has shown rapid progress in recent days with the advent of score distillation, a methodology of using pretrained text-to-2D diffusion models to optimize neural radiance field (NeRF) in the zero-shot setting. However, the lack of 3D awareness in the 2D diffusion models destabilizes score distillation-based methods from reconstructing a plausible 3D scene. To address this issue, we propose \ours, a novel framework that incorporates 3D awareness into pretrained 2D diffusion models, enhancing the robustness and 3D consistency of score distillation-based methods. We realize this by first constructing a coarse 3D structure of a given text prompt and then utilizing projected, view-specific depth map as a condition for the diffusion model. Additionally, we introduce a training strategy that enables the 2D diffusion model learns to handle the errors and sparsity within the coarse 3D structure for robust generation, as well as a method for ensuring semantic consistency throughout all viewpoints of the scene. Our framework surpasses the limitations of prior arts, and has significant implications for 3D consistent generation of 2D diffusion models. Project page is available at \textnormal{\url{https://ku-cvlab.github.io/3DFuse/}}.
\end{abstract}

\input{1_introduction}


\begin{figure}[t]
\centering
\renewcommand{\thesubfigure}{}
\subfigure[(a) Naive score distillation]
{\includegraphics[width=0.49\textwidth]{fig/fig2_a}}
\label{fig:fig2_a}
\vspace{-5pt}\\
\subfigure[(b) 3D-aware score distillation (Ours)]
{\includegraphics[width=0.49\textwidth]{fig/fig2_b}}
\label{fig:fig2_b}
\vspace{-10pt}\\
    \caption{\textbf{Motivation.} (a) Previous methods~\cite{poole2022dreamfusion,song2020score} only use noisy rendered images and prompt itself for score distillation through diffusion model, resulting in poor 3D coherence. (b) Our \ours addresses this issue and shows robust performance in recovering 3D-consistent scene.}
    \label{fig:fig2}\vspace{-5pt}
\end{figure}



\input{2_related_work}


\section{Preliminaries}
\input{3_preliminaries}
\begin{figure*}[t]
\begin{center}
\includegraphics[width=1\textwidth,]{fig/fig3.pdf}
\end{center}
\vspace{-15pt}
\caption{\textbf{Overall architecture of \ours.} In the framework, semantic code is sampled to reduce the text prompt ambiguity by generating an image based on the text prompt and then optimizing the prompt's embedding to match the generated image. Our consistency injection module receives this semantic code to synthesize view-specific depth maps as a condition to the diffusion U-net. The module also consists of a sparse depth injector to implicitly incorporate 3D awareness by utilizing an external 3D prior, and LoRA~\cite{hu2021lora} layers to maintain semantic consistency. 
}
\label{fig:network_overall}
\end{figure*}


\section{Method}
\input{4_methology}

\section{Experiments}
\input{5_experiments}

\input{6_conclusion}

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
