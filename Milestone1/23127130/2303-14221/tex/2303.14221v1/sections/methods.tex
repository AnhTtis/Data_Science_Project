\section{Methods}

In this section, we highlight the key steps of our pipeline for constructing the model for stock price prediction. In particular, we focus on the phase in which we use different techniques for getting textual information representations that served as part of the model input. We emphasize the prediction quality depends on the formed feature space and provide a framework for fair comparison and selection of the optimal configuration. An overall scheme of processes to make a stock close price prediction is described in Figure \ref{fig:schema}. It consists of three main steps:

\begin{itemize}
    \item \textbf{Data retrieval and preprocessing}. As the initial data, we take a corpus of Twitter posts related to the selected group of companies and the historical values of their stock prices and trading volumes. Tweets are subject to data cleaning. Financial data are modified through the volume feature being smoothed. After all, a business day resampling is applied to get our attributes at the same time frequency. 
    \item \textbf{Model input formation}. Depending on the experiment, we pass the Twitter dataset either through the sentiment extractor or embedding generator to get the part of the input, which is responsible for the outside world information. Calendar holidays, trading volumes, and preceding close prices constitute the rest part.
    \item \textbf{Model prediction}. Data samples described with the composed feature space are fed into the TFT model. After a training process, a $N$ steps ahead prediction for the close price is made. 
\end{itemize}

\begin{figure}[!ht]
  \includegraphics[scale=0.5]{pdf/model_upd2.pdf}
  \centering
  \caption{Pipeline for comparison of utilizing either text sentiments or embeddings within the stock price prediction problem statement. There are three main steps in the scheme: (1) preprocessing of the collected Twitter and financial datasets, (2) obtaining either tweet sentiments or tweet embeddings, and (3) making prediction of stock close prices for $N$ steps ahead.}
  \label{fig:schema}
\end{figure}

\subsection{Data preparation}
To get accurate price prediction for the next $N$ steps, we need to properly prepare initial data. We construct the predictions on the basis of Twitter and financial datasets. From tweets, we can get either sentiment or semantic information. Also, we consider historical financial information as a part of model input. Moreover, for further deep market analysis, we provide the formula for the price volatility evaluation. 

\subsubsection{Data}\label{data}

For Twitter data, we use the dataset from Kaggle published in 2020 \cite{9378170}. This dataset contains tweets related to 5 companies: Amazon, Apple, Google, Microsoft, and Tesla from 2015 to 2020. Raw data contains over 3 million tweets and information on the tweet author, post date, tweet text body, and the number of comments, likes, and retweets. For the preprocessing steps, a simple spam and duplicate tweet reduction was performed. All the preprocessing steps in more detail are described in the Appendix.

The financial data were collected with yfinance python library \cite{yfinance} using Yahoo! Finance's API for the same time period as the tweet data. Adjusted Close, High, Low, Open, Close, and Volume features were collected. In Figure \ref{fig:close_price_normalized}, we demonstrate the normalized adjusted close prices in order to compare the pace of each company's changes. As we can see, Amazon had the most marked growth in capitalization during the analyzed period. After analysis of Twitter data, we found out that Amazon had lower tweet activity compared to Tesla and Apple, which received much more attention from Twitter users. Despite this fact, Amazon rose nearly six times in price. Hence, we can conclude that the number of tweets is not the key feature affecting stock price movements. We need to dive into tweet semantics to get more relevant information for price movement predictions.

\begin{figure}[!ht]
  \includegraphics[width=0.7\textwidth]{pdf/close_price_normalized_upd.pdf}
  \centering
  \caption{Adjusted close price movements for five companies and price values of NASDAQ index for the five-year period. All prices are scaled for comparative purposes.}
  \label{fig:close_price_normalized}
\end{figure}

\subsubsection{Sentiment information}

The initial dataset with Twitter posts related to the particular group of companies did not contain information about the sentiment of the tweets. First, we had to extract sentiment polarity from the tweets in order to use them as a feature in a predictive model for comparison purposes. The following pre-trained models were applied to extract sentiment data from the tweets:

\begin{itemize}
    \item FinBERT sentiment \cite{DBLP:journals/corr/abs-1908-10063} built by further training the BERT language model on a large financial corpus and thereby adopting it for financial sentiment classification. The sentiment model is fine-tuned on 10000 manually annotated sentences collected from analyst reports about S\&P500 firms; 
    \item RoBERTa-base model fine-tuned on the Stocktwits dataset \cite{Roberta-fine-tuned}, which contains 3.2 million comments with the user labelled tags: 'Bullish' or 'Bearish'.
\end{itemize}

The latter performed better upon the comparative analysis of results for 300 tweets and was chosen for our sentiment-based solution. 
% Further we describe the results and prepossessing of the extracted raw sentiment polarity in Section \ref{sent-explore} before it is fed into the model.

% \subsection{Sentiment score evaluation}\label{eval}

As a result of the sentiment extraction procedure, we get either 1 or 0 as labels for each tweet. Label 1 is associated with positive sentiment, while label 0 - with negative sentiment. However, before feeding obtained information into the predictive model, we need to group sentiment labels by their relation to company and date. Then, we suggest two types of scores, which reflect the ultimate sentiment of the group of tweets:
\begin{itemize}
    \item $Sentiment\;Score\;1 = negative /(negative + positive),$
    \item $Sentiment\;Score\;2 = negative / positive,$
\end{itemize}
where $Sentiment\;Score\;1$ shows the share of negative tweets in the total number of tweets, while $Sentiment\;Score\;2$ evaluates the ratio of the number of negative tweets to the number of positive tweets. $Sentiment\;Score\;2$ provided us with better metrics on the validation dataset in the task of price prediction. Thus, it is selected as the primary score for the final pipeline and is denoted $Sentiment\;Score$ in the subsequent discussion. Although, we included the behavior comparison of $Sentiment\;Score\;1$ and $Sentiment\;Score\;2$ in Section \ref{sent-explore}.

To get more a pronounced sentiment score trend instead of highly fluctuating values, three-week smoothing was applied. We compared the results of using simple rolling mean and Exponential Weighted Moving Average (EWMA) implemented in pandas library \cite{reback2020pandas}. We selected the EWMA method because of the much faster response to the downtrend in comparison with the rolling mean reaction. It happens due to the fact that EWMA algorithm contains a weight decay parameter that allows focusing more on the recent prices than on a long series of data points.  
% It is caused by weights decay that were chosen to be span-related in our case.

% \begin{center}
%     \begin{equation}\label{EWMA}
%         EWMA_i = \alpha s_{i} + (1 - \alpha)  EWMA_{i-1},
%     \end{equation}
% \end{center}

% where $EWMA$ - exponential weighted moving average; $\alpha$ - constant weight; $s_i$ - sentiment score value for i-th day

% \begin{figure}[!ht]
%   \includegraphics[width=0.5\textwidth]{arxiv_art/png/sentiment_amazon.png}
%   \centering
%   \caption{Sentiment score smoothing with 15 day window comparing EWMA and rolling mean approach with raw input}
%   \label{fig:sentiment_ema}
% \end{figure}
Furthermore, we have to deal with the fact that the stock market works only during business days. As a result, there are no market data for the weekends. On the other side, sentiments have daily frequency. Options on how to unify the multiple series are the following:

\begin{enumerate}
    \item Impute market data using forward fill with previous values for gaps in a daily frequency.
    \item Convert daily frequency of tweet data to business day frequency;
\end{enumerate}

Second option was chosen in order not to introduce a series of useless values that bring no information. Sentiment score values achieved during weekends were summed up to the next business day. 

\subsubsection{Semantic information}\label{embeddings}
Another option for the representation of information from tweets is embeddings. Embedding is obtained by converting each tweet into a vector using sentence transformer model “all-MiniLM-L6-v2” \cite{all-MiniLM-L6-v2}. It maps our sentences to 384-dimensional dense vector space. To make up the representation for a single trading day, we average all vectors related to that day. In the embedding approach, we face the same problem of the absence of market prices on the weekends. To overcome that, we concatenate weekend embeddings vectors with vectors related to the next business day. 

\subsubsection{Financial information}
The predictions for future stock prices are made on the basis of historical price values. We consider open, close, high, and low prices of stocks for a particular day. Open price is a selling price of a stock at the time the exchange opens. Close price is the last price during a trading session. High and low prices are the maximum and minimum prices during a session, correspondingly. In addition, we leverage trading volume as a feature, which shows a number of shares that have been bought or sold during the trading day. 

\subsubsection{Volatility}

In the following discussion, we mean Average True Range measure under the volatility concept. Average True Range is defined according to the formula:

% \begin{center}
    % \begin{equation}\label{ATR}4
$$
        {ATR}_t = \frac{n-1}{n}ATR_{t-1} + \frac{1}{n}\Bigl( max(H_t, C_{t-1}) - min(L_t, C_{t-1}) \Bigr),
$$
    % \end{equation}
% \end{center}

where $t$ - given day; $ATR_t$ - Average True Range in day $t$; $n$ - considered number of periods; $H_t$ - highest price in day $t$; $L_t$ - lowest price in day $t$; $C_{t-1}$ - close price in day $t - 1$.

\subsection{Predictive model parameters}\label{model_params}

At the stage of selecting architecture for price prediction purposes, multiple models implemented in Darts \cite{JMLR:v23:21-1177} python library were tested. The best performance showed the implementation of Temporal Fusion Transformer \cite{https://doi.org/10.48550/arxiv.1912.09363}, which was chosen to become the core predictive model in the final pipeline.  
% N-Linear \cite{https://doi.org/10.48550/arxiv.2205.13504} 
Instead of a univariate approach that implies the creation of a distinct model for each company, multiple time-series training is considered. This allows to train multiple time-series objects in one go, simplifying the training and forecasting process. 

As the input history length of the model, previous three business weeks (15 days) were chosen. Such length for the lookback window was achieved during grid-search and mentioned in the Appendix. The shorter lookback windows introduce certain limitations. In particular, the sentiment reaction to the event requires time, and extreme shortening of the observed history may lead to information loss. The output prediction length was set equal to 3 days for the main experiments. For the train/test split 80\% was given for the training dataset and 20\% for testing.

A common target variable in all experiments is close price. To test an effect of different input compositions, three groups were identified:

\begin{itemize}
    \item HLOV - High, Low, Open, Volume attributes. In this case, we test out the model performance only working with market data as input.
    \item HLOVS - the same as above, but with adding $Sentiment\;Score$ attribute.
    \item HLOVE - market data and embedding vectors as model input
\end{itemize}

\subsection{Loss function}
In order to prevent overfitting, a custom loss function is introduced. It is built on top of one of the most popular loss functions for regression tasks - Mean Squared Error (MSE) loss, but with the addition of a directional component. MSE does not consider whether the direction of the predicted close price is correct, just focusing on the difference between true and predicted prices. However, the direction of price movement is an essential factor in the financial world. Multiple values from 10 to $10^4$ of $\alpha$ were tested in the loss function. Lower values of $\alpha$ did not punish the directional errors enough to make a difference in comparison with standard MSE loss, while having $\alpha$ set to $10^4$ only prolonged the loss convergence time. In the end, we come up with the following loss function:
% \begin{center}
% \begin{equation}\label{DMSE}
$$
DMSE = \frac{1}{n}\sum_{i=1}^{n}\alpha(x_i-y_i)^2, \quad \text{where} \hspace{0.5em}
\begin{cases}
    \alpha = 1,& \text{if } (x_i - x_{i-1})(y_i - y_{i-1}) \geq 0,\\
    \alpha = 10^3,              & \text{otherwise},
\end{cases}
$$
% \end{equation}
% \end{center}

% $$ 
% DMSE = \frac{1}{n}\sum_{i=1}^{n}\alpha(x_i-y_i)^2
% \begin{cases}
%     \alpha = 1,& \text{if } (x_i - x_{i-1})(y_i - y_{i-1}) \geq 0,\\
%     \alpha = 10^3,              & \text{otherwise}.
% \end{cases}
% $$

where $DMSE$ - Directional Mean Squared Error; $n$ - number of data points; $x_{i}$ - true values; $y_{i}$ - predicted values.

% \subsection{Features}\label{features}

% The features used in model training can be divided as follows.

% \begin{spacing}{0.5}
% \begin{itemize}
%     \item Market features. Open price is a selling price of a stock at the time the exchange opens. Close price is the last price during a trading session. High and low prices are the maximum and minimum prices during a session, correspondingly. We also utilize volume as feature, which shows number of shares that have been bought or sold during the trading day.
%     \item Sentiment features. $SS2$ that is calculated according to formula from the section~\ref{eval}.
%     \item Embedding features. Embedding is obtained by converting each tweet into vector using state-of-the-art sentence transformer model “all-MiniLM-L6-v2” \cite{all-MiniLM-L6-v2}. It maps our sentences to 384 dimensional dense vector space. Then we calculate an average vector for a trading day.
%     \end{itemize}
% \end{spacing}


% \begin{table}[!ht]
%     \centering
%     \caption{Feature correlation EWMA / No EWMA. Demonstrates Pearson correlation between the features with and without application of 3 week window smoothing}
%     \begin{tabular}{ccccc}
%     \toprule
%     {}Not using EWMA &     Close &    Volume &  Volatility &  Sentiment score \\
%     \midrule
%     Close           &  1.000000 & -0.360573 &    0.591806 &         0.250214 \\
%     Volume          & -0.360573 &  1.000000 &    0.315195 &         0.098544 \\
%     Volatility      &  0.591806 &  0.315195 &    1.000000 &         0.353214 \\
%     \bottomrule
%     \end{tabular}
    
%     \begin{tabular}{ccccc}
%     \toprule
%     {} \hspace{0.2cm}Using EWMA\hspace{0.2cm} &     Close &    Volume &  Volatility &  Sentiment score \\
%     \midrule
%     Close           &  1.000000 & -0.427143 &    0.591806 &         0.439749 \\
%     Volume          & -0.427143 &  1.000000 &    0.307785 &         0.058316 \\
%     Volatility      &  0.591806 &  0.307785 &    1.000000 &         0.592164 \\
%     \bottomrule
%     \end{tabular}
%     \label{table:EMA_correlation}
% \end{table}



