\section{Results}

In this section, we present the findings from our study on the relationships between Twitter sentiments, stock prices, and volatility. Also, we perform metrics achieved from predictive model development using sentiment labels and sentence embeddings. 

\subsection{Daily return analysis}

Histograms of daily stock return values for all five companies in a five-year period are presented in Figure \ref{fig:return distribution}. Here $\sigma$ is calculated as the sum of squares of deviations of daily return values from 0. As we can observe, Tesla is a clear outlier among five other companies having much greater daily return oscillations. One can infer that this stock has a higher risk/reward ratio. This shows that no matter that all the described stocks are traded inside the same NASDAQ index, there is still evidence of them behaving in a different way caused by the other factors.

\begin{figure}[!ht]
  \includegraphics[width=0.9\textwidth]{pdf/volatility_upd.pdf}
  \centering
  \caption{Histograms of daily stock return values for the companies during a five-year period. NASDAQ daily stock returns are given for comparison purposes. Tesla is the most volatile among the analyzed five companies.}
  \label{fig:return distribution}
\end{figure}

\subsection{Relation between tweet sentiments and stock market}\label{sent-explore}

% During exploration of sentiment score feature we achieved results confirming that the social network sentiment is a great indicator for stock price and movement prediction.

Before the construction of the predictive model on the basis of Twitter data, our goal is to explore the direct connection between price variables and Twitter sentiments. Figure \ref{fig:sent_price} demonstrates stock prices as well as sentiment scores calculated in both ways for Apple and Amazon. Visually, we can observe a great amount of resemblance between price and sentiment variables, especially in the case of Amazon. 
% After evaluation of Pearson correlation between prices and $Sentiment\:Score$, we get that Apple correlation value is 0.1994, while Amazon has 0.3942. 

\begin{figure}[!ht]
    \centering
    \subfigure[Apple]{\includegraphics[width=8cm]{pdf/sentiment_aapl.pdf}}
    \subfigure[Amazon]{\includegraphics[width=8cm]{pdf/sentiment_amzn.pdf}}
    % \hfill
    \caption{Sentiment scores and closing prices comparison with a constant multiplier applied to sentiment scores for visualization purposes. Left side is denoted to the moving of Apple prices and sentiments, while Amazon patterns are demonstrated on the right side.}
    \label{fig:sent_price}
\end{figure}

\begin{figure}[!ht]
    \centering
    \subfigure[Sentiment score and volatility behavior]{\includegraphics[width=8cm]{pdf/sent_vol_aapl.pdf}}
    % \hfill
    \subfigure[Scatter plot for sentiment score and volatility]{\raisebox{4.2mm}{\includegraphics[width=8cm]{pdf/scatter_sent_vol_aapl.pdf}}}
    \caption{Sentiment score and volatility comparison for Apple with Min-Max scaling applied to both features. There is a comparison of behaviour of sentiment scores and volatility overtime on the left side. We can observe a time lag of sentiment reaction to volatility. The right side is denoted to the scatter plot of sentiment score and volatility to discover hidden patterns.}
    \label{fig:sent_volatility}
\end{figure}

If we compare stock volatility with EWMA smoothed sentiment score in Figures \ref{fig:sent_volatility} and \ref{fig:sent_volatility_scatter}, we observe the same phenomenon of significant similarity but now between the shape of volatility curve and Twitter sentiment scores. Amazon again has a greater correlation between considered values. It is noteworthy that Apple has a clear time lag between public reaction and stock volatility. Volatility tends to precede public sentiment response. For Amazon, in turn, the situation is slightly different. Sentiment changes are more synchronized with the volatility making it a greater predictor of price movement. Analyzing scatter plots in Figures \ref{fig:sent_volatility} and \ref{fig:sent_volatility_scatter}, we can ascertain the presence of principle direction in sentiment-volatility dependence. 


\begin{figure}[!ht]
    \centering
    \subfigure[Sentiment score and volatility behavior ]{\includegraphics[width=8cm]{pdf/sent_vol_amzn.pdf}}
    % \hfill
    \subfigure[Scatter plot for sentiment score and volatility]{\raisebox{4.2mm}{\includegraphics[width=8cm]{pdf/scatter_sent_vol_amzn.pdf}}}
    % \hfill
    \caption{Sentiment score and volatility comparison for Amazon with Min-Max scaling applied to both features. There is a comparison of behaviour of sentiment scores and volatility overtime on the left side. We can observe quite synchronized directional movements. The right side is denoted to the scatter plot of sentiment score and volatility to explore hidden patterns in more detail.}
    \label{fig:sent_volatility_scatter}
\end{figure}

To conduct a more comprehensive correlation analysis between different variables, we consider Google company and calculate pairwise Spearman correlation coefficients between close price, volume, volatility, and sentiment score. The results are given in Table \ref{table:EMA_correlation}. We applied three-week EWMA smoothing to volume and sentiment score in order to get a more meaningful correlation with the stock close price. After comparing with non-smoothed calculations, we found out that smoothing indeed helped to improve correlation indicators. It happens because we smoothed out short-term fluctuations and consequently captured the underlying trends.
% The correlation between close price and volume increased by 18.46\% after the use if EWMA, whereas correlation between close price and sentiment score grew by 75.75\% . Correlation of sentiment score with volatility had an increase of 40.35\%.

\begin{table}[!ht]
    \centering
    \caption{Spearman correlation between different variables with and without application of three-week window smoothing to volatility and sentiment score}
    \begin{tabular}{ccccc}
    \toprule
    Using EWMA & Close & Volume & Volatility & Sentiment Score \\
    \midrule
    Close &  1.000 & -0.464 &  0.626 & 0.401 \\
    Volume & -0.464 &  1.000 & 0.295 & 0.085 \\
    Volatility  &  0.626 &  0.295 & 1.000 & 0.508 \\
    Sentiment Score & 0.401& 0.084 & 0.508 & 1.000 \\
    \bottomrule
    \end{tabular}
    \label{table:EMA_correlation}
\end{table}


% Therefore, we claim that there is a clear statistical relationship between observed variables. However, the question whether the relationship is cause-effect
% is still open.

\subsection{Connection of sentiments and embeddings}
After exploring of relationships between sentiment scores and financial indicators, we became interested in the interdependency of other entities, namely tweets' sentiments and their embeddings. 
As mentioned, tweet sentiments were extracted with a pre-trained RoBERTa-base model, and tweet embeddings were generated by sentence transformers. We hypothesize the presence of an underlying connection between these two representations. To check this, we fitted a linear regression model on vector embeddings, for which corresponding sentiment scores were set as targets. The prediction quality was estimated with $R^2$ metric. The results of such experiment are given in Table \ref{tab:sklearn-table}. For a better understanding of the magnitude of the effect that embedding encompasses sentiment knowledge, we generate vectors of random variables with a dimension equal to the 
size of embedding vectors. Then, we try to predict sentiment scores from obtained pointless vectors. 

% In Section \ref{features} it is mentioned that vector embedding feature is achieved by grouping up each tweet embeddings into a matrix and than taking a mean value of this matrix $y$ axis to receive a single vector. Sentiment score is also achieved by daily aggregation of sentiment values for each tweet. Although this features were derived from the same prepossessed tweet text data they were then extracted by the different algorithms: 

% % \begin{spacing}{1}
% \begin{itemize}
%     \item Tweet sentiment was extracted by pretrained inference RoBERTa base model;
%     \item Tweet embeddings were generated by a sentence transformer.
% \end{itemize}
% % \end{spacing}


% \begin{table}[!ht]
%     \centering
%     \caption{$R^2$ values for each company achieved after fitting a linear regression model on embedding vector and sentiment score. The true column demonstrates high $R^2$, while the artificial column denotes a randomly generated vector of same size for comparison purpose}
%     \begin{tabular}{lcc}
%         \toprule
%         Company &      True &  Artificial \\
%         \midrule
%         Apple     &  0.8 &    0.344 \\
%         Amazon    &  0.821 &    0.352 \\
%         Google    &  0.778 &    0.358 \\
%         Microsoft &  0.804 &    0.381 \\
%         Tesla     &  0.891 &    0.396 \\
%         \bottomrule 
%     \end{tabular}
%     \label{table:sklearn-table}
% \end{table}


\begin{table}[!ht]
    \centering
    \caption{$R^2$ values for each company achieved after fitting a linear regression model on embeddings as features and sentiment scores as targets. $R^2$ scores for the case when predictions are made from randomly generatedvectors are given for comparison purpose.}
    % \begin{tabular}{p{5cm}p{2cm}p{2cm}p{2cm}p{2cm}p{2cm}}
    \begin{tabular}{cccccc}
        \toprule
       $R^2$ for $Sentiment\:Score$ prediction &  Apple &  Amazon &  Google & Microsoft & Tesla \\
        % \midrule
          from embeddings (random vectors) &  0.800 (0.344) & 0.821 (0.352) & 0.778 (0.358) & 0.804 (0.381) & 0.891 (0.396) \\
   
        \bottomrule
    \end{tabular}
    \label{tab:sklearn-table}
\end{table}


For the majority of companies, $R^2$ values are greater than 0.8. Thus, there is a strong relationship between the vector embeddings and the sentiment scores. High metrics for the linear regression model indicate that the feature variable is a strong predictor of the response variable. 

% R-squared measures the proportion of variance in the response variable that is explained by the predictor variable. In this case, around 80\% of the variance in the sentiment score can be explained by the vector embedding. A high R-squared value indicates that the linear regression model has a good fit to the data and that the predictor variable is a strong predictor of the response variable. This means that changes in the predictor variable are associated with significant changes in the response variable and the model has captured a significant portion of the underlying relationship between the two variables.

\subsection{Price prediction results and sensitivity analysis}\label{prediction_results}

When choosing price prediction models to include in the final pipeline, several candidates were tested. Moreover, we experimented with different horizons. All details and results of intermediate experiments are given in Appendix. For the main experiments, we took the model and forecast horizon that proved themselves in the best way during the selection phase. We stopped at the TFT model with the forecast horizon equal to 3. 


% For the Baseline solution the Naive Seasonal model was chosen, which returned the close price of the stock n time steps before the prediction date, where n is a prediction horizon and equal to five in our case. Overall TFT model performed better than N-Linear for all companies in the dataset. It contradicts the claim of the researchers, but can be explained due to the differences in benchmark datasets, most of them in the paper \cite{https://doi.org/10.48550/arxiv.2205.13504} have strong seasonal component and repetitive behaviour (ETT, Traffic, Electricity, Weather, etc.). N-Linear model also had drastic performance drop when embedding vector was used as a feature, without any additional covariates it performed better, which goes in line with their research.

% \subsection{Sensitivity analysis on prediction window size and vector dimension}
The aim of the experiments is to compare metrics for a three-day prediction period when using sentence embedding or sentiments as features. We basically compare the effect by considering two feature sets: HLOVS and HLOVE, which are described in \ref{model_params}. The metrics are performed in Table \ref{table:grouped-error-table}. As we wanted to make a generalizable conclusion, we examined embeddings that are generated by one more language model. We considered Microsoft model - all-mpnet-base-v2 \cite{all-mpnet-base-v2}. It has twice the number of dimensions compared with the approach mentioned in \ref{embeddings}. The feature set with embeddings obtained with this model is denoted as HLOVE2 in Table \ref{table:grouped-error-table}. However, the accuracy of closing price prediction dropped significantly for such embeddings.

\begin{table}[!ht]
    \centering
    \caption{Metrics for three-day forecast horizon considering five companies. The predictions are made with TFT model using feature sets including either sentiments (HLOVS) along with financial data or embeddings (HLOVE, HLOVE2).}
    \begin{tabular}{llccccccc}
    \toprule
          &  Model          &    MAPE &     MAE &      $R^{2}$ &    RMSE &     MSE &   SMAPE \\
    \midrule
        Apple & \textbf{tft\_HLOVS} &        1.7602 &  \textbf{0.8932} &  \textbf{0.9648} &  \textbf{1.2014} &  \textbf{1.4434} &  1.7502 \\
              & tft\_HLOVE &        \textbf{1.7557} &  0.8947 &  \textbf{0.9648} &  1.2023 &  1.4455 &  \textbf{1.7492} \\
              & tft\_HLOVE2 &       3.9357 &  1.6854 &  0.7368 &  2.1665 &  4.6938 &  3.8641 \\
              \\
        Amazon & \textbf{tft\_HLOVS} &       \textbf{1.0544} &  \textbf{0.5605} &  \textbf{0.8535} &  \textbf{0.7469} &  \textbf{0.5579} &  \textbf{1.0526} \\
              & tft\_HLOVE &       1.1442 &  0.6078 &  0.8334 &  0.7965 &  0.6344 &  1.1408 \\
              & tft\_HLOVE2 &      1.9503 & 1.0404 & 0.4551 & 1.5635 &  2.4446 & 1.9184 \\
              \\
        Google & \textbf{tft\_HLOVS} &       1.6830 &  0.9044 &  \textbf{0.8326} &  \textbf{1.2160} &  \textbf{1.4786} &  1.6807 \\
              & \textbf{tft\_HLOVE} &      \textbf{1.6824} &  \textbf{0.9039} &  0.8323 &  1.2171 &  1.4814 &  \textbf{1.6781} \\
              & tft\_HLOVE2 &       2.9347 & 2.3175 & 0.4988 & 2.6873 & 2.9715 & 3.3174 \\
              \\
        Microsoft & \textbf{tft\_HLOVS} &       \textbf{1.2687} &  \textbf{0.8267} &  \textbf{0.9626} &  \textbf{1.0643} &  \textbf{1.1327} &  \textbf{1.2721} \\
              & tft\_HLOVE &      1.3059 &  0.8503 &  0.9615 &  1.0798 &  1.1660 &  1.3086 \\
              & tft\_HLOVE2 &       3.9615 & 1.6081 & 0.7412 & 3.5431 & 2.9846 & 3.0965 \\
              \\
        Tesla & \textbf{tft\_HLOVS} &       \textbf{3.5182} &  \textbf{1.3833} &  \textbf{0.8923} &  \textbf{1.9810} &  \textbf{3.9242} &  \textbf{3.5386} \\
              & tft\_HLOVE &       3.5717 &  1.4020 &  0.8915 &  1.9880 &  3.9523 &  3.5994 \\
              & tft\_HLOVE2 &       4.5540 & 1.9531 & 0.5735 & 2.3948 &  5.7354 &  4.4676 \\
    \bottomrule
    \end{tabular}
    \label{table:grouped-error-table}
\end{table}

If we look at prediction qualities for Apple company in Table \ref{table:grouped-error-table}, we observe that for some metrics embedding approach shows better performance. However, the difference from the sentiment approach is not substantial, and HLOVS set gives better results for 4 out of 6 metrics. For Microsoft, sentiment representations clearly perform better. Another company that has nearly similar results for both feature sets is Google, and the difference in metrics is negligible - only 0.036\% for MAPE. For Amazon and Tesla sentiments again prove to be an optimal feature for all metrics. To sum up, although embeddings seem to contain more information, sentiment solution remains a strong baseline that is hard to beat. 

If we analyze MAPE metric, models with embedding feature show better results only in two cases out of five - for Apple and Google. However, this prevalence is minor. During the analysis of volatility and close price correlations with sentiment score, these companies had one of the lowest scores among the considered five. It might be the reason why Twitter sentiments do not have such a performance-enhancing impact for these two companies. For Amazon, Google and Tesla sentiment score method outperforms embedding vector solutions.

