In summary, we combine the aforementioned \Cref{eq:beta-loss,eq:constraint} to formulate the optimization problem as
\begin{align}
\label{eq:opt-problem}
    \min_{\boldsymbol{\theta}\in\Theta}\quad \mathcal{L}_{Beta}(\boldsymbol{\theta}) \quad \text{subject to} \quad g(\boldsymbol{\theta})\leq \gamma,
\end{align}
where $\gamma>0$ is the independence criterion relaxation.
Previous methods, such as regularization or projection, can handle the constraint in \Cref{eq:opt-problem} with near-optimal solutions but do not directly provide primal solutions. It may even fail to produce any useful information for static bias. 
 
To better solve the problem, we develop the primal-dual average scheme update method. 
Specifically, we apply an averaging scheme to the primal sequence $\{\boldsymbol{\theta}^{(m)}\}_{m=1}^\infty$ to approximate primal optimal solutions, where $m$ represents the index of an iteration. In particular, the sequence $\{\Tilde{\boldsymbol{\theta}}^{(m)}\}_{m=1}^\infty$ is defined as the averages of the previous vectors through $\boldsymbol{\theta}^{(0)}$ to $\boldsymbol{\theta}^{(m-1)}$, \ie,
\begin{align}
\label{eq:primal-avg}
    \Tilde{\boldsymbol{\theta}}^{(m)} = \frac{1}{m} \sum\nolimits_{i=1}^{m-1}\boldsymbol{\theta}^{(i)}, \quad \forall m\geq 1.
\end{align}
The primal feasible iterate $\boldsymbol{\theta}^{(m)}$ is given in \Cref{eq:primal-solution}. 
To simplify, we abuse the notation $\mathcal{L}_{Beta}(\boldsymbol{\theta})$ with $\mathcal{L}(\boldsymbol{\theta})$ in the rest of the paper.
\begin{align}
\label{eq:primal-solution}
    \boldsymbol{\theta}^{(m)} \leftarrow \arg\min_{\boldsymbol{\theta}\in\Theta} &\Big\{\mathcal{L}(\boldsymbol{\theta}^{(m-1)}) + \lambda^{(m-1)}\Big(g(\boldsymbol{\theta}^{(m-1)})-\gamma\Big)\nonumber\\
    &-\frac{\delta}{2}\Big(\lambda^{(m-1)}\Big)^2\Big\},
    % F(\boldsymbol{\theta}^{(m-1)},\lambda^{(m-1)}),
\end{align}
where $\delta>0$ is a constant determined by analysis. Accordingly, the parameter $\lambda$ in dual solutions is updated as
\begin{align}
\small
\label{eq:dual-solution}
    \lambda^{(m)} \leftarrow \max\Big\{\Big[\lambda^{(m-1)}+\eta_2\Big(g(\Tilde{\boldsymbol{\theta}}^{(m)})-\gamma-\delta\lambda^{(m-1)}\Big)  \Big], 0\Big\},
\end{align}
where $\eta_2>0$ is a constant learning rate of the dual step.
By updating the dual parameter, $\lambda$, our optimization efficiently approaches the optimal model $\boldsymbol{\theta}^\ast$ arbitrarily close within a small finite number of steps $m$. 
% Thus the primal and dual parameters are updated interactively, where the primal parameters regard model accuracy and dual parameters adjust model debiasing.
For better understanding, the above algorithm is summarized in \Cref{alg:algor}.

\subsection{Theoretical Analysis}
%In previous sections, we introduce the principle components of the proposed framework and propose an average scheme primal-dual algorithm. In machine learning and deep learning, however, many problems of interest have a non-convex loss landscape due to the non-linearity of activation functions, where theoretical analysis is challenging. Nevertheless, algorithms originally developed for convex losses, such as gradient descent, have shown promising results in practical non-convex settings. Taking inspiration from these successes, in this section, we provide a comprehensive analysis of the statistical guarantees of our solution in \cref{eq:primal-solution,eq:dual-solution}. 
To derive the bound on the feasibility violation and the primal cost of the running averages, we analyze the statistical guarantees of the solutions in \Cref{eq:primal-solution,eq:dual-solution}. We first make the following assumption.
\begin{assumption} (Regularity and Feasibility).
\label{assump1}
The convex set $\Theta$ is compact (\ie, closed and bounded). For any $\boldsymbol{\theta}\in\Theta$, $\mathcal{L}(\boldsymbol{\theta})$ and $g(\boldsymbol{\theta})$ are convex real-valued and bounded functions, where $\inf_{\boldsymbol{\theta}\in\Theta} g(\boldsymbol{\theta})=0$ and, for any $\boldsymbol{\theta}\notin \Theta$, \normalfont{dom}$(g(\boldsymbol{\theta}))=\emptyset$.
\end{assumption}
% \textcolor{red}{This assumption is largely standard in ...}
Recall that in the proposed \cref{alg:algor} used to approximate pairs of primal-dual parameters at each iteration $m$, for the averaged primal sequence $\{\Tilde{\boldsymbol{\theta}}^{(m)}\}$, we show that it always converges when $\Theta$ is compact.

\begin{proposition}(Convergence of Averaged Primal Sequence)
\label{prop1}
Under \Cref{assump1}, when the convex set $\Theta$ is compact, let the approximate primal sequence $\{\Tilde{\boldsymbol{\theta}}^{(m)}\}_{m=1}^{\infty}$ be the running averages of the primal iterates in \Cref{eq:primal-avg}. Then $\{\Tilde{\boldsymbol{\theta}}^{(m)}\}_{m=1}^{\infty}$ can converge to its limit $\Tilde{\boldsymbol{\theta}}^*$.
\end{proposition}
 
Next we provide bounds on the feasibility violation $g(\Tilde{\boldsymbol{\theta}}^{(m)})$ and the primal cost of the running averages $\mathcal{L}(\Tilde{\boldsymbol{\theta}}^{(m)})$, where the bounds are given per iteration $m$. 

\begin{proposition}(Bounds for $\mathcal{L}(\Tilde{\boldsymbol{\theta}}^{(m)})$ and the violation of $g(\Tilde{\boldsymbol{\theta}}^{(m)})$~\cite{averagedDS-SJO-2009})
\label{prop:prop2}
Let the dual sequence $\{\lambda^{(m)}\}_{m=1}^{\infty}$ be generated through \Cref{eq:dual-solution} and $\{\Tilde{\boldsymbol{\theta}}^{(m)}\}_{m=1}^{\infty}$ be the averages in \Cref{eq:primal-avg}. Under \cref{assump1}, we have
\begin{enumerate}[leftmargin=*,topsep=0pt,itemsep=0ex,partopsep=0ex,parsep=0ex]
    \item An upper bound on the amount of constraint violation of $\Tilde{\boldsymbol{\theta}}^{(m)}$ that $\big\lVert \big[g(\Tilde{\boldsymbol{\theta}}^{(m)})\big]_+\big\rVert \leq \frac{\lambda^{(m)}}{m\eta_2}$.
    \item An upper bound on $\mathcal{L}(\Tilde{\boldsymbol{\theta}}^{(m)})$ that $\mathcal{L}(\Tilde{\boldsymbol{\theta}}^{(m)}) \leq f^*+\frac{(\lambda^{(0)})^2}{2m\eta_2}+\frac{\eta_2 L^2}{2}$, where $\big\lVert g(\Tilde{\boldsymbol{\theta}}^{(m)})\big\rVert<L$ and $L>0$.
    \item A lower bound $\mathcal{L}(\Tilde{\boldsymbol{\theta}}^{(m)}) \geq f^*-\lambda^*\cdot\big\lVert \big[g(\Tilde{\boldsymbol{\theta}}^{(m)})\big]_+\big\rVert$.
\end{enumerate}
where $[u]_+$ denotes the projection of $[u]$ on the nonnegative orthant. $f^*$ is the optimal solution of \Cref{eq:opt-problem} and $\lambda^\ast$ denotes the optimal value of the dual variable.
\end{proposition}

% \textbf{Analysis Discussion}: 
\Cref{prop1,prop:prop2} demonstrate the convergence of the primal solution sequence and give bounds for both the loss function and debiasing constraint in \sysname{}. The detailed proof is given in the Appendix.

% we denote a feasible primal solution set $\mathcal{C}\subset\Theta$ of \cref{eq:primal-solution}) and its corresponding dual feasible set $\mathcal{M}=\{\lambda|\lambda\in\mathbb{R}^+\}$ of \cref{eq:dual-solution}.

\begin{algorithm}[t!]
\small
\caption{Primal-Dual Average Scheme Update}
\label{alg:algor}
\textbf{Input}: $\boldsymbol{\theta}^{(0)}\in\Theta, \lambda^{(0)}\in\mathbb{R}_+$: primal and dual parameters\\
\textbf{Require}: $\eta_1,\eta_2> 0$: learning rates
% \textbf{Require}: $q>0$: a small number of subgradient update steps
\begin{algorithmic}[1]
% \State $\mu_t^0 \leftarrow \mu$, $\theta_t^0 \leftarrow \theta$
\State Initialize an empty buffer $B=[\:]$ to store $\boldsymbol{\theta}^{(m)}$
% \Repeat
    \For{$m=1,2,...$}
        \State \multiline{%
            $L(\boldsymbol{\theta},\lambda) := \mathcal{L}(\boldsymbol{\theta}) + \lambda(g(\boldsymbol{\theta})-\gamma)-\frac{\delta}{2}\lambda^2$ }
        \State \multiline{% 
            \textbf{Primal Update:} \\ 
            $\boldsymbol{\theta}^{(m)} \leftarrow \text{Adam}\Big\{L\Big(\boldsymbol{\theta}^{(m-1)},\lambda^{(m-1)}\Big), \eta_1, \boldsymbol{\theta}^{(m-1)}\Big\}$ }
        \State Add $\boldsymbol{\theta}^{(m)}$ in $B$ 
        \State \multiline{% 
            \textbf{Average Scheme:} 
            $\Tilde{\boldsymbol{\theta}}^{(m)} = \frac{1}{|B|}\sum_{i=1}^{|B|-1}\boldsymbol{\theta}^{(i)}$}
        \State Update $\boldsymbol{\theta}^{(m)}\leftarrow \Tilde{\boldsymbol{\theta}}^{(m)}$
        \State $L'(\boldsymbol{\theta},\lambda):=\lambda + \eta_2 \Big(g(\boldsymbol{\theta})-\gamma-\delta\lambda\Big)$
        \State \multiline{% 
            \textbf{Dual Update:}\\
            $\lambda^{(m)} \leftarrow \max\Big\{L'\Big(\Tilde{\boldsymbol{\theta}}^{(m)},\lambda^{(m-1)}\Big), 0\Big\}$ }
    \EndFor
% \Until{convergence.}
\end{algorithmic}
\end{algorithm}
% \setlength{\textfloatsep}{5pt}% Remove \textfloatsep

\subsection{Novelty Score Estimation}
\label{sec:novelty_estimation}
During inference, we aim to detect novel actor(s) with single or multiple unknown action(s). According to \Cref{eq:element-wise-sl}, we develop four novelty quantification scores based on either uncertainty or belief of an actor.
To this end, we incorporate the actor's estimated subjective opinions $\{\omega_i\}_{i=1}^K$ for its actions, where $\omega_i=(b_i,d_i,u_i,a_i)$.

\textbf{Uncertainty-based novelty score.} 
As described in \Cref{sec:edl}, the predicted positive and negative evidence pair $\{(\alpha_i,\beta_i)\}_{i=1}^K$ are used to estimate uncertainty $u$ of an actor with $K$ actions. 
A value of $u$ close to $1$ indicates novelty. Three uncertainty-based novelty score estimation mechanisms are introduced by using positive (PE) or negative (NE) evidence only and aggregating them (PNE), \ie,
\begin{equation}
\small   %
\label{eq:novelty-scores}
%\left\{
\begin{aligned}
     \text{PE}: u =& \frac{2}{1+\exp({\sum\nolimits_i^K \alpha_i-K})}, \\
     \text{NE}: u =& \frac{2}{1+\exp({K-\sum\nolimits_i^K \beta_i})}-1, \\
    \text{PNE}: u =& \frac{2K}{\sum\nolimits_i^K (\alpha_i+\beta_i)}.
\end{aligned}
%\right.
\end{equation}

\textbf{Belief-based novelty score.} 
Another novelty detection scheme is to estimate its belief value $b$ using the binomial co-multiplication operator (denoted as $\ast$)~\cite{Audun2006BeliefCalculus} for all actions, 
% \ie,
\begin{align}
    &b = b_1\ast\cdots\ast b_K, \\
    &\text{where } b_i * b_j := b_i+b_j-b_i\cdot b_j, \forall i,j\in\{1,\cdots K\}, i\neq j, \nonumber
\end{align}
% $b = b_1\ast\cdots\ast b_K$, where $b_i * b_j := b_i+b_j-b_i\cdot b_j, \forall i,j\in\{1,\cdots K\}, i\neq j$.
$b_i\in[0,1]$ is a class-wise belief estimated using its corresponding positive and negative evidence values $\alpha_i$ and $\beta_i$ in \Cref{eq:element-wise-sl}. A belief value $b$ close to $0$ indicates novelty. 

\subsection{Relation with Existing Evidential Learning}
Although our method shares the basic concept of evidential learning with DEAR~\cite{bao-2021-ICCV}, it has a significant difference in three aspects.
\begin{itemize}[leftmargin=*,topsep=0pt,itemsep=0ex,partopsep=0ex,parsep=0ex]
    \item \textit{The Beta distribution in \Cref{eq:beta-loss} is generalized from the Dirichlet distribution in ENNs.} In other words, to detect an actor with multiple novel actions, we improve original ENNs~\cite{sensoy-2018-nips,bao-2021-ICCV} by using $K$ Beta distributions. If $K=1$, our loss function is reduced to the counterpart in DEAR~\cite{bao-2021-ICCV} (see the proof in the Appendix).
    %\vspace{-7mm}
    \item \textit{The \sysnameedc{} in \Cref{eq:constraint} simultaneously mitigates direct and indirect bias.} In contrast, the contrastive evidence debiasing module in DEAR~\cite{bao-2021-ICCV} only considers dependencies of predictive outcome $Z$ on the sensitive feature $X$ through the causal path $X\rightarrow H$. This is viewed as a sub-path of the indirect dependency $X\rightarrow H\rightarrow Z$, resulting in inferior performance.
    %\vspace{-3mm}
    \item \textit{Our optimization method in \Cref{alg:algor} provides optimal hyper-parameter search for robust learning.} DEAR~\cite{bao-2021-ICCV} views the debiasing constraint as a regularization term with the empirically set Lagrange multiplier.
    In contrast, an optimal multiplier $\lambda^\ast$ is automatically found as a dual variable by \Cref{alg:algor}. Iterative update between the primal and dual variable guarantees the achievement of a small duality gap.
\end{itemize}

\textbf{Discussion.} Dirichlet densities-based ENNs for open set action recognition focus on detecting actors with a single action. Such methods assume action probability follows a prior Dirichlet distribution. In contrast, in our \sysname{}, Beta distributions are more general to adapt to different applicable scenarios where a video contains either a single ($N=1$) or multiple ($N>1$) actor(s) associated with a single ($K=1$) or multiple ($K>1$) action(s).