\section{Examples and case studies}
\label{sec:ex_cases}

\subsection{Doctor Who's Tardis Attack}

Two robots, the Cyberman C and the Dalek D, attack Doctor Who's Tardis once a day between them. C has a probability of 1/2 of a successful attack, while D has a probability of 3/10 of a successful attack. C attacks more often than D, with a probability of 3/5 on a particular day (and so D attacks with a probability of 2/5 on that day). What is the probability that there will be a successful attack today?

We model the problem in our probabilistic programming in the definition below.
\begin{definition}[Doctor Who's Tardis Attack]
  \label{def:dwta}
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dwta.thy\#L22}
  \begin{align*}
    & Attacker ::= C | D \\ 
    & Status :: = S | F \\ 
    & \isakwmaj{alphabet}\ dwtastate = r::Attacker \qquad a::Status \\
    & dwta \defs 
    % \begin{array}[]{l}
      \ppchoice{3/5} 
      {\left(\pseq{\left(\passign{r}{C}\right)}{\left(\ppchoice{1/2}{\passign{a}{S}}{\passign{a}{F}}\right)}\right)}
      {\left(\pseq{\left(\passign{r}{D}\right)}{\left(\ppchoice{3/10}{\passign{a}{S}}{\passign{a}{F}}\right)} \right) }
        %       \end{array}
  \end{align*}
\end{definition}
We define the attackers $C$ and $D$ of type $Attacker$, and $S$ and $F$ of type $Status$ for a successful or failed attacker. The observation space of this program is $dwtastate$ containing two variables $r$ and $a$ to record the attacker and the attack status. The problem is modelled as a program $dwta$, composed of probabilistic choice, assignment, and sequential composition.

Using the reasoning framework and the algebraic laws mechanised in Isabelle, $dwta$ is simplified and proved semantically equal to a probabilistic program shown below.
\begin{thm}[Simplified program]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dwta.thy\#L129}
  \begin{align*}
    & dwta = \rvprfunsym{\usexpr{
      \begin{array}[]{l}
        3/10 * \ibracket{r' = C \land a' = S} + 
        3/10 * \ibracket{r' = C \land a' = F} + \\
        6/50 * \ibracket{r' = D \land a' = S} + 
        14/50 * \ibracket{r' = D \land a' = F} 
      \end{array}
    }} 
  \end{align*}
\end{thm}
This law shows $C$ has a probability of 3/10 of a successful or failed attack, while $D$ has a probability of 6/50 of a successful attack and 14/50 of a failed attack. We note that this simplified program is a distribution of the final state because the sum of the probabilities of these combinations equals 1: $3/10+3/10+6/50+14/50=1$.

With this simplified program, we can use it to answer interesting quantitative queries using sequential composition. The answer to the question ``What is the probability of a successful attack?'', for example, is 21/50.

\begin{thm}
  \label{thm:dwta_success}
  % \begin{align*}
  $ \pseq{\prrvfunsym{dwta}}{{\ibracket{a = S}}} = {\usexpr{21/50}}$
  % \end{align*}
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dwta.thy\#L167}
\end{thm}

\subsection{The Monty Hall problem}

%The problem~\cite{Wikipedia2023} is a puzzle based on an American television game show \emph{Let's Make a Deal}. It is named after its original host, Monty Hall. Suppose you are the contestant and are given a choice of opening one of three doors. Behind one door is a car, and behind the others are goats. You pick a door, say No. 1, and the host, who knows what is behind each door, opens another door, say No. 3 and reveals a goat. He then asks, ``Do you want to pick door No. 2 instead of your original choice?'' The problem is simple: should you change your choice to maximise your chance to win a car?

We model the problem in the program below, where the doors are numbered as natural numbers: 0, 1, and 2.

\begin{definition}[Monty hall]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L14}
  \begin{align*}
    \isakwmaj{alphabet}\ &mhstate = p::\nat \qquad c::\nat \qquad m::\nat\\
    init & \defs \pseq{\uniformdist{p}{\{0 \upto 2\}}}{\uniformdist{c}{\{0 \upto 2\}}} \\
    mc & \defs {\left(\ppchoice{1/2}{\left(\passign{m}{(c+1) \mod 3}\right)}{\left(\passign{m}{(c+2) \mod 3}\right)}\right)} \\
    mha & \defs \pcchoice{c = p}{mc}{\passign{m}{3 - c - p}} \\
    mha\_nc & \defs \pseq{\pseq{init}{mha}}{\pskip}\tag*{(no change strategy)} \label{thm:monty_mha_nc}\\
    mha\_c & \defs \pseq{init}{\pseq{mha}{\passign{c}{3 - c -m}}}\tag*{(change strategy)} \label{thm:monty_mha_c}
  \end{align*}
\end{definition}
The observation space $mhstate$ contains three variables of type $\nat$: $p$ for the number of the prize door, $c$ for the contestant's choice, and $m$ for the door Monty opens. The $init$ is the initial configuration of the problem where the values of $p$ and $c$ follow a uniform distribution from an interval between 0 and 2 inclusive, so the prize and the contestant's choice are random.  The $mha$ models if the contestant's choice is the prize ($c=p$), the Monty randomly (with probability 1/2) chooses $m$ from the other two doors, denoted as $(c+1) \mod 3$ and $(c+2) \mod 3$. Otherwise, the prize is not revealed, and then Monty chooses the one that is not $p$ (he knows the value of $p$, the prize door) where $3-c-p$ guarantees that $m$ is different from both $c$ and $p$.  The $mha\_nc$ models a no-change strategy, and the $mha\_c$ models a change strategy after Monty reveals one.

We simplify $init$ according to the law below.
\begin{thm}[Initial]
  $init = \rvprfunsym{ \usexpr{ \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' \in \{0 \upto 2\}} * \ibracket{m' = m} / 9 }}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L143}
\end{thm}
In the initial configuration, the combinations of $p$ and $c$ have an equal probability $1/9$ with $m$ unchanged. The $init$ is also a distribution: the summation over its final states equals 1.

The $mha\_nc$ is proved to be equal to the program below.

\begin{thm}[No change strategy]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L550}
  \begin{align*}
    & mha\_nc =  \rvprfunsym{
      \usexpr{
      \begin{array}[]{l}
        \ibracket{c' = p'} * \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' \in \{0 \upto 2\}} * \ibracket{m' = (c'+1)\mod 3} / 18\ + \\
        \ibracket{c' = p'} * \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' \in \{0 \upto 2\}} * \ibracket{m' = (c'+2)\mod 3} / 18\ + \\
        \ibracket{c' \neq p'} * \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' \in \{0 \upto 2\}} * \ibracket{m' = 3 - c' - p'} / 9 \\
      \end{array}
    }}
  \end{align*}
\end{thm}

The $mha\_c$ is also proved to be equal to the program below.

\begin{thm}[Change strategy]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L1273}
  \begin{align*}
    & mha\_c =  \rvprfunsym{
      \usexpr{
      \begin{array}[]{l}
        \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' = 3 - p' - m'} * \ibracket{m' = (p'+1)\mod 3} / 18\ + \\
        \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' = 3 - p' - m'} * \ibracket{m' = (p'+2)\mod 3} / 18\ + \\
        \ibracket{c' = p'} * \ibracket{p' \in \{0 \upto 2\}} * \ibracket{3 - p' - m' \neq p'} * \ibracket{3 - p' - m' \leq 2} *  \ibracket{3 - p' - m' \geq 0} / 9 \\
      \end{array}
    }}
  \end{align*}
\end{thm}

With these laws, we can answer questions like the probability of winning for each strategy and whether you change the choice. 
\begin{thm}[Winning probability]
  \hfill \isaref{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L928}
  and 
  \isaref{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L1633}
  \begin{align*}
    & \pseq{\prrvfunsym{mha\_nc}}{{\ibracket{c = p}}} = {\usexpr{1/3}} \tag*{(winning probability of no-change strategy)} \label{thm:monty_nc_winning} \\
    & \pseq{\prrvfunsym{mha\_c}}{{\ibracket{c = p}}} = {\usexpr{2/3}}  \tag*{(winning probability of change strategy)} \label{thm:monty_c_winning} 
  \end{align*}
\end{thm}
The above law shows that the winning probabilities are $1/3$ for the no-change strategy and $2/3$ for the change strategy, so you should change the choice because you have a {higher} probability of winning.

\subsection{The forgetful Monty}
\label{ssec:cases_forgetful_monty}
%uppose now that Monty forgets which door has the prize behind it. He opens either of the doors not chosen by the contestant. The contestant switches their choice to that door if the prize is revealed ($m'=p'$).  So the contestant will surely win. However, should the contestant switch if the prize is not revealed ($m' \neq p'$)?  
The new problem is modelled below.
\begin{definition}[Forgetful Monty]
  \label{def:forgetful_monty}
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L2000}
  \begin{align*}
    & forgetful\_monty \defs \pseq{init}{mc} \tag*{(the forgetful Monty)} \label{def:monty_forgetful}\\
        %         & learn\_fact \defs \pparallel{\prrvfunsym{forgetful\_monty}}{\ibracket{m' \neq p'}} \tag*{[Learn new fact that the prize is not revealed]} \label{def:monty_forgetful_learn}\\
    & learn\_fact \defs \pparallel{{forgetful\_monty}}{\rvprfunsym{\ibracket{m' \neq p'}}} \tag*{(learn new fact that the prize is not revealed)} \label{def:monty_forgetful_learn}
  \end{align*}
\end{definition}
After initialisation, the forgetful Monty randomly chooses one from the other two doors. The learned new fact that the prize is not revealed ($m'\neq p'$) is fed into the program by parallel composition as shown in the definition of $learn\_fact$. The program equals the one below, and the winning probability is queried.
\begin{thm}
  \hfill \isaref{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L2615} and \isaref{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L2424} 
  \begin{align*}
    & learn\_fact = \rvprfunsym{
      \usexpr{
      \begin{array}[]{l}
        \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' \in \{0 \upto 2\}} * \ibracket{m' = (c'+1)\%3} * \ibracket{m' \neq p'} / 12\ + \\
        \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' \in \{0 \upto 2\}} * \ibracket{m' = (c'+2)\%3} * \ibracket{m' \neq p'} / 12
      \end{array}
    }}\\
    & \pseq{\prrvfunsym{learn\_fact}}{{\ibracket{c = p}}} = {\usexpr{1/2}} \tag*{(winning probability of learning new fact)} \label{thm:monty_learn_winning}
  \end{align*}
\end{thm}
The probability of winning is now $1/2$ and so if Monty is forgetful, and the contestant happens to choose a door with no prize, it does not matter whether the contestant sticks or switches because they have the equal probability of $1/2$.

\subsection{Robot localisation}
\label{ssec:cases_robot_localisation}
%A circular room has two doors and a wall. A robot with a noisy door sensor maps position to $\clz door$ or $\clz wall$. Doors are at positions 0 and 2; position 1 is a blank wall.  We define a predicate $door(p) \defs p = 0 \lor p = 2$ and introduce a program variable $bel \in \{0 \upto 2\}$ to denote the position of the robot that we believe. When the reading of the door sensor is $\clz door$, it {is} four times more likely to be right than wrong {and likewise when the reading is wall}. 
The likelihood functions are defined below.

\begin{definition}[Likelihood functions]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L24}
\begin{align*}
    & scale\_door \defs  \usexpr{3 * \ibracket{door(bel')} + 1} \\
    & scale\_wall \defs  \usexpr{3 * \ibracket{\lnot door(bel')} + 1} 
\end{align*}
\end{definition}

We are interested in questions like how many measurements and moves are necessary to estimate the robot's location accurately.

\subsubsection{Initialisation}
Initially, the robot is randomly placed, and so a uniform distribution. This is defined below by the program $init$.

\begin{definition}[Initialisation]
%\begin{align*}
    $ init \defs \uniformdist{bel}{\{0 \upto 2\}} $ 
%\end{align*}
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L20}
\end{definition}

\subsubsection{First sensor reading}

The sensor detects a door. We learn new knowledge and update our beliefs accordingly using parallel composition.  The prior probability distribution (prior) is $init$, and the likelihood function is $scale\_door$. The posterior probability distribution is given in the theorem below.  \begin{thm}[First posterior]
      %       \begin{align*}
  $ \pparallel{init}{scale\_door} = \rvprfunsym{4/9 * \ibracket{bel' = 0} + 1/9 * \ibracket{bel' = 1} + 4/9 *  \ibracket{bel' = 2}}$ % \tag*{(first posterior)} \label{thm:robot_local_belief1}
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L91}
      %       \end{align*}
\end{thm}
We have a high probability of $4/9$ to believe the robot is in front of a door at position 0 or 2. 

\subsubsection{Move one space to the right}
Now the robot takes an action to move one space to the right, and the belief position is shifted one to the right. This is defined as $move\_right$ below.
\begin{definition}[Move to the right]
      %       \begin{align*}
  $move\_right \defs \left(\passign{bel}{(bel + 1) \mod 3}\right) $
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L30}
      %       \end{align*}
\end{definition}

An action updates the belief using sequential composition. The posterior probability distribution after the move is given as follows.  \begin{thm}[Posterior after the first move]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L116}
  \begin{align*}
    & \pseq{\left(\pparallel{init}{scale\_door}\right)}{move\_right}  = \rvprfunsym{4/9 * \ibracket{bel' = 0} + 4/9 * \ibracket{bel' = 1} + 1/9 *  \ibracket{bel' = 2}} %\tag*{[First move to the right]} \label{thm:robot_local_move1}
  \end{align*}
\end{thm}
We observe that the probability values are not changing, but the positions are shifted in the distribution.

\subsubsection{Second sensor reading}
The sensor detects a door again. The posterior probability distribution is updated accordingly. 
\begin{thm}[Second posterior]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L514}
  \begin{align*}
    & \pparallel{\left(\pseq{\left(\pparallel{init}{scale\_door}\right)}{move\_right}\right)}{scale\_door} = \rvprfunsym{2/3 * \ibracket{bel' = 0} + 1/6 * \ibracket{bel' = 1} + 1/6 *  \ibracket{bel' = 2}} %\tag*{[Learnt second knowledge]} \label{thm:robot_local_belief2}
  \end{align*}
\end{thm}
We have a high probability of $2/3$ to believe the robot is in front of a door at position 0 and a low probability of $1/6$ in the other two positions.

\subsubsection{Move one space to the right}

Another action is to move the robot to its right, and the posterior probability distribution is shifted accordingly.

\begin{thm}[Posterior after the second move]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L603}
  \begin{align*}
    & \pseq{\left(\pparallel{\left(\pseq{\left(\pparallel{init}{scale\_door}\right)}{move\_right}\right)}{scale\_door}\right)}{move\_right} \\
    = \,& \rvprfunsym{1/6 * \ibracket{bel' = 0} + 2/3 * \ibracket{bel' = 1} + 1/6 *  \ibracket{bel' = 2}} %\tag*{[Second move]} \label{thm:robot_local_move2}
  \end{align*}
\end{thm}

\subsubsection{Third sensor reading}

The learn sensor detects a wall. The posterior probability distribution is updated accordingly. 

\begin{thm}[Third posterior]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L994}
  \begin{align*}
    & \pparallel{\left(\pseq{\left(\pparallel{\left(\pseq{\left(\pparallel{init}{scale\_door}\right)}{move\_right}\right)}{scale\_door}\right)}{move\_right}\right)}{scale\_wall} \\
    = \,& \rvprfunsym{1/18 * \ibracket{bel' = 0} + 8/9 * \ibracket{bel' = 1} + 1/18 *  \ibracket{bel' = 2}} %\tag*{[Learnt third knowledge]} \label{thm:robot_local_belief3}
  \end{align*}
\end{thm}
After three sensor readings and two moves, our beliefs about the robot's position are $8/9$ at position 1 and $1/18$ at position 0 or 2. We plot the beliefs in Fig.~\ref{fig:robot_localisation_belief} where each position has six updates corresponding to the initial prior (I1), the three sensor readings (door - D2 and D4, and wall - W6), and the two moves to the right (M3 and M5).  The diagram shows that the difference between the highest and lowest probability for each update becomes big or stays the same: from 0 for I1 to 15/18 ($=8/9-1/18$) for W6. So the robot gains more knowledge in each update.  From the diagram, we are confident of (probability $8/9$) the robot's localisation after three measurements and two moves.
% reference: https://tex.stackexchange.com/questions/275797/how-to-draw-multiple-bar-charts-each-one-with-multiple-different-series 
\makeatletter
\pgfplotsset{
  calculate offset/.code={
    \pgfkeys{/pgf/fpu=true,/pgf/fpu/output format=fixed}
    \pgfmathsetmacro\testmacro{(\pgfplotspointmeta*10^\pgfplots@data@scale@trafo@EXPONENT@y)*\pgfplots@y@veclength)}
    \pgfkeys{/pgf/fpu=false}
  },
  every node near coord/.style={
    /pgfplots/calculate offset,
    yshift=-\testmacro,
  },
  name node/.style={
    every node near coord/.append style={
      name=#1-\coordindex
    }}
}    
% 
\pgfplotstableread{
  0 0.3333 0.4444	0.4444	0.6667	0.1667	0.0556	
  1 0.3333 0.1111	0.4444	0.1667	0.6667	0.8889	
  2 0.3333 0.4444 0.1111  0.1667  0.1667  0.0556
}\dataset
% 
\begin{figure}[!ht]
  \begin{center}
    \begin{tikzpicture}
      \begin{axis}[ybar,
        width=12cm,
        % height=10cm,
        ymin=0,
        ymax=1,
        xmin=-0.5,
        xmax=2.5,
        ylabel={Probability},
        xtick=data,
        xticklabels = {
          0,
          1,
          2,
        },
        xticklabel style={yshift=-1ex},
        major x tick style = {opacity=0},
        minor x tick num = 1,
        minor tick length=0ex,
        every node near coord/.append style={ anchor=north,font=\scriptsize }
        ]
        \addplot[draw=none,fill=blue!50!black!60, name node=1, nodes near coords=I1] table[x index=0,y index=1] \dataset; 
        \addplot[draw=none,fill=orange!70!black, name node=2, nodes near coords=D2] table[x index=0,y index=2] \dataset;
        \addplot[draw=none,fill=gray!80, name node=3, nodes near coords=M3] table[x index=0,y index=3] \dataset;
        \addplot[draw=none,fill=yellow, name node=4, nodes near coords=D4] table[x index=0,y index=4] \dataset;
        \addplot[draw=none,fill=blue!60, name node=5, nodes near coords=M5] table[x index=0,y index=5] \dataset;
        \addplot[draw=none,fill=green!80, name node=6, nodes near coords=W6] table[x index=0,y index=6] \dataset;
      \end{axis}
      % \foreach \i in{1,...,3}{
      % \foreach \j in{0,1,...,2}{
      % \node[anchor=east,rotate=90] at (\i-\j){parameter\kern0.5ex};}}  
    \end{tikzpicture}
  \end{center}
  \caption{The update of the robot's belief at different positions after three measurements and two moves with a prior.}
  \label{fig:robot_localisation_belief}
\end{figure}
% 

\subsection{Classification - COVID-19 diagnosis}
\label{ssec:cancer_diagnosis}

%We consider people using a COVID-19 test to diagnose if they may or may not have contracted COVID-19. The test result is binary and could be positive or negative. The test, however, is imperfect. It doesn't always give a correct result. We are interested in several questions. How likely is a randomly selected person to have COVID-19 if the first test result is positive?  Is it necessary to have the second test to reassure the result? How much can the second test contribute to the diagnosis?

We define the state space $cdstate$ of this example as follows.
\begin{definition}[State space]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L24}
  \begin{align*}
    & CovidTest ::= Pos | Neg \\ 
    &\isakwmaj{alphabet}\ cdstate = c::\bool \qquad ct::CovidTest
  \end{align*}
\end{definition}
Whether a person has COVID or not is recorded in a boolean variable $c$: true for COVID and false for no COVID. The test result is recorded in a variable $ct$ of type $CovidTest$ whose value could be $Pos$itive or $Neg$ative.

The prior probability of a randomly selected person having COVID is $p_1$ of type $\ureal$. The prior probability distribution, therefore, is a probabilistic choice, defined below.
\begin{definition}[Prior]
  $Init \defs \ppifchoice{p_1}{\passign{c}{True}}{\passign{c}{False}}$
\end{definition}
So the probability of a person having COVID is $p_1$ and having no COVID is $(1-p_1)$.

The test is imperfect. Its sensitivity (true positive) is $p_2$, and specificity (true negative) is $1-p_3$. It means if a person with COVID is tested, the probability of a positive result is $p_2$, and if a person without COVID is tested, the probability of a negative result is $1-p_3$. We, therefore, define the action of a test as below.

\begin{definition}[Test]
  $TestAction \defs \pcchoice{c}
  {(\ppchoice{p_2}{\passign{ct}{Pos}}{\passign{ct}{Neg}})}
  {(\ppchoice{p_3}{\passign{ct}{Pos}}{\passign{ct}{Neg}})}$ 
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L58}
\end{definition}
It is a conditional choice between two probabilistic choices, defining the probabilities of true positive, false negative, false positive, and true negative. A positive test result is a new learned evidence, defined as follows.
\begin{definition}
  $TestResPos \defs \ibracket{ct' = Pos}$ 
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L67}
\end{definition}
It, essentially, is an Iverson bracket expression of a relation $ct'=Pos$ stating that the test result $ct$ is positive.

We conduct the first test and learn its positive result, modelled as the program below.
\begin{definition}[First test]
  $FirstTestPos \defs \pparallel{\left(\pseq{Init}{TestAction}\right)}{TestResPos}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L110}
\end{definition}
As usual, the action $TestAction$ is sequentially composed, and the evidence is learned in parallel.  We show the posterior in the theorem below.
\begin{thm}[Posterior after the first test]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L390}
  \begin{align*}
    FirstTestPos = \usexpr{\left(
    \begin{array}[]{l}
      \ibracket{c'}*\ibracket{ct'=Pos}*p_1*p_2 + \\
      \ibracket{\lnot c'}*\ibracket{ct'=Pos}*(1-p_1)*p_3
    \end{array}
    \right) / \left(p_1*p_2+(1-p_1)*p_3\right)}
  \end{align*}
\end{thm}
From the theorem, we know that the probability that the person has COVID, given a positive test, is 
\begin{align*}
  &\left(p_1*p_2\right)/\left(p_1*p_2+(1-p_1)*p_3\right)
\end{align*}
Provided $p_1=0.002$, $p_2=0.89$, and $p_3=0.05$, the probability of the person having COVID is 0.0344 (much less than we may think?), and so the probability without COVID is 0.9656.

If a second test is conducted, the result is still positive, and so new evidence is learned again.
\begin{definition}[Second test]
  $SecondTestPos \defs \pparallel{\left(\pseq{FirstTestPos}{TestAction}\right)}{TestResPos}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L132}
\end{definition}
We show the posterior after the second test with the learned fact in the theorem below. 
\begin{thm}[Posterior after the second test]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L661}
  \begin{align*}
    SecondTestPos = \usexpr{\left(
    \begin{array}[]{l}
      \ibracket{c'}*\ibracket{ct'=Pos}*p_1*p_2^2 + \\
      \ibracket{\lnot c'}*\ibracket{ct'=Pos}*(1-p_1)*p_3^2
    \end{array}
    \right) / \left(p_1*p_2^2+(1-p_1)*p_3^2\right)}
  \end{align*}
\end{thm}
From the theorem, we know that the probability that the person has COVID, given a positive test, is 
\begin{align*}
  &\left(p_1*p_2^2\right)/\left(p_1*p_2^2+(1-p_1)*p_3^2\right)
\end{align*}
Provided $p_1=0.002$, $p_2=0.89$, and $p_3=0.05$, the probability of the person having COVID is 0.3884, so the probability without COVID is 0.6116.  With the second test, it is more likely (38.84\% vs. 3.44\%) that the person may have COVID. In this case, a second test should be conducted, given the first test is positive.

\subsection{(Parametrised) coin flip}
\label{ssec:cases_coin}
% FOUNDATIONS OF PROBABILISTIC PROGRAMMING 

The program $flip$ in Definition~\ref{def:coin_flip} is for an unbiased coin (a Bernoulli distribution with $p=1/2$), and $pflip$ below defines a parametrised program where the parameter $p$ denotes the probability to have its outcome as heads (a Bernoulli distribution with probability $p$). So it could be a biased coin.

\begin{definition}[Parametrised coin]
    %     \begin{align*}
    %       & Tcoin ::= hd | tl \\ 
    %       & flipbody \defs \ppchoice{1/2}{c := hd}{c := tl} \\
    %       & flip \defs \pwhile{c = tl}{flipbody} \\
    %       & flip \defs \pwhile{c = tl}{\ppchoice{1/2}{c := hd}{c := tl}} \\
  $ pflip (p)\defs \pwhile{c = tl}{\ppchoice{p}{\passign{c}{hd}}{\passign{c}{tl}}} $
            %           \end{align*}
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L485}
\end{definition}

Both $flip$ and $pflip$ contain probabilistic loops. We use the unique fixed point theorem~\ref{thm:rec_unique} to give semantics to them where $P$ in the theorem is $cflip$ here for $flip$. Previously, we have shown that $cflip$ is a distribution. And obviously, the observation space $cstate$ is finite (two elements $hd$ and $tl$), so the product $cstate \cross cstate$ is also finite.  We also show that the differences in iterations from top and bottom tend to 0, which is illustrated in Fig.~\ref{fig:coin_t_prob_iteration}.
\begin{thm}
  \label{thm:cflip_iterdiff_0}
  $\forall s:cstate\cross cstate @ \left(\lambda n @ \prrvfunsym{\iterdiff\left(n, c=tl, cflip\right)}(s)\right) \tendsto 0$ 
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L389}
\end{thm}
Additionally, $\rvprfunsym{\ibracket{c'=hd}}$ is a fixed point of the loop function.
\begin{thm}
  \label{thm:cflip_fp}
  $\lfun^{c = tl}_{cflip}\left(\rvprfunsym{\ibracket{c'=hd}}\right) = \rvprfunsym{\ibracket{c'=hd}}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L407}
\end{thm}
All four assumptions of Theorem~\ref{thm:rec_unique} are now established. The $flip$, therefore, is semantically (surprisingly) just the fixed point $\rvprfunsym{\ibracket{c'=hd}}$.
\begin{thm}
  \label{thm:flip_sem}
  $flip = \rvprfunsym{\ibracket{c' = hd}}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L432}
\end{thm}
The $flip$ terminates almost surely and is almost impossible for non-termination.
\begin{thm}
  \label{thm:flip_sem_termination}
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L447}
  \begin{align*}
    & \pseq{\prrvfunsym{flip}}{{\ibracket{c = hd}}} = {\usexpr{1}} \tag*{(termination probability)} \label{thm:coin_flip_term}\\
    & \pseq{\prrvfunsym{flip}}{{\ibracket{\lnot c = hd}}} = {\usexpr{0}} \tag*{(non-termination probability)} \label{thm:coin_flip_nonterm}
  \end{align*}
\end{thm}
This theorem shows the probability of the final state $c'$ being $hd$ is 1 and is not $hd$ is 0. This is equivalent to the termination probability.

We also show $pflip(p)$ is semantically equal to $flip$ if $p$ is not 0.
\begin{thm}
  \label{thm:pflip_sem}
  $ p \neq 0 \implies pflip(p) = \rvprfunsym{\ibracket{c' = hd}}$ 
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L655}
\end{thm}
If $p$ is 0, we know this program $pflip$ is non-terminating because the probabilistic choice in the loop body always chooses $tl$, and so not possible to terminate.

Though $flip$ and $pflip(p)$ are semantically equal, we expect there are differences between the two programs in other aspects, such as average termination time. Consider a biased coin with probability $p=0.75$ to see heads. Then we know, on average, it needs fewer flips than an unbiased coin to see heads. In other words, $pflip(p)$ has a smaller average termination time than $flip$. This is modelled in Hehner's work~\cite{Hehner2011} by a time variable $t$ of type natural numbers to count iterations in a loop. In our language, it is defined below.

\begin{definition}[Coin flip with time]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L668}
  \begin{align*}
    & \isakwmaj{alphabet}\ cstate\_t = t::\nat \qquad c::Tcoin \\
    & flip\_t \defs \pwhile{c = tl}{\pseq{\left(\ppchoice{1/2}{\passign{c}{hd}}{\passign{c}{tl}}\right)}{\passign{t}{t + 1}}} 
  \end{align*}
\end{definition}

The new state space is $cstate\_t$ with an additional variable $t$ of $\nat$, and the loop $flip\_t$ will increase $t$ by 1 in each iteration.  After the introduction of $t$, we use Theorem~\ref{thm:rec_unique_fin} to prove the semantics of $flip\_t$ is

\begin{thm}
  \label{thm:flip_t_sem}
  $ flip\_t = \rvprfunsym{\usexpr{
      \begin{array}[]{l}
        \ibracket{c=hd}*\ibracket{c'=hd}*\ibracket{t'=t}+\\
        \ibracket{c=tl}*\ibracket{c'=hd}*\ibracket{t'\geq t+1}*(1/2)^{t'-t}
      \end{array}
    }}$ 
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L1008}
\end{thm}
% If we set the start time $t$ as 0, then it is simplified to 
% \begin{align*}
    %     & flip_t = \ibracket{c=tl}*\ibracket{c'=hd}*\ibracket{t'\geq 1}*(1/2)^{t'}+\ibracket{c=hd}*\ibracket{c'=hd}*\ibracket{t'=0}
            %   \end{align*}

If the initial value of $c$ is $hd$ (that is, $c=hd$), $flip\_t$ terminates immediately ($t'=t$) and its final value of $c$ is $hd$ ($c'=hd$).  If the initial value of $c$ is $tl$ ($c=tl$), $flip\_t$ terminates ($c'=hd$) only when $t'$ is larger than or equal to $t+1$, that is, at least one flip of the coin. The probability that $flip\_t$ terminates at time $t'$ is given by $(1/2)^{t'-t}$ which can be regarded as $t'-t-1$ tails followed by heads: The termination probability of $flip\_t$ is the sum of $(1/2)^{t'-t}$ over natural numbers starting from 1: $\Sigma_{t'=t+1}^{\infty}(1/2)^{t'-t}=\Sigma_{n=1}^{\infty}(1/2)^n$. It is a geometric series with a common ratio $1/2$, and so its sum is equal to $(1/(1-(1/2))) - 1 = 1$. This is shown in the theorem below.

\begin{thm}
  \label{thm:flipt_sem_termination}
  $ \pseq{\prrvfunsym{flip\_t}}{{\ibracket{c = hd}}} = {\usexpr{1}}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L1024}
\end{thm}

With $t$, we can quantify the expected value of $t$ (the number of flips on average to get the loop terminated) by sequential composition.
\begin{thm}
  \label{thm:flipt_sem_expected_t}
  $ \pseq{\prrvfunsym{flip\_t}}{t} = {\usexpr{\ibracket{c=hd}*t+\ibracket{c=tl}*{(t+2)}}}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L1081}
\end{thm}
The expectation of $t$ given the distribution by $flip\_t$ is $t$ itself (terminate immediately) if the initial value of $c$ is $hd$, and $t+2$ (2 flips on average) otherwise.

We consider the parametrised version with $t$ where $p$ is a \ureal\ number.
\begin{definition}[Parametrised coin flip with time]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L1214}
  \begin{align*}
    & pflip\_t(p)\defs \pwhile{c = tl}{\pseq{\left(\ppchoice{p}{\passign{c}{hd}}{\passign{c}{tl}}\right)}{\passign{t}{t + 1}}} 
  \end{align*}
\end{definition}

We show its semantics below.
\begin{thm}
  \label{thm:pflip_t_sem}
  $ p \neq 0 \implies pflip\_t(p) = \rvprfunsym{\usexpr{
      \begin{array}[]{l}
        \ibracket{c=hd}*\ibracket{c'=hd}*\ibracket{t'=t}+\\
        \ibracket{c=tl}*\ibracket{c'=hd}*\ibracket{t'\geq t+1}*(1-\ur{p})^{t'-t-1}*\ur{p}
      \end{array}
    }}$ 
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L1518}
\end{thm}

If $p$ is not 0, then the probability that $pflip\_t(p)$ terminates at $t'$ now is $(t'-t-1)$ tails (probability $(1-\ur{p})^{t'-t-1}$, $\ur{p}$ is the conversion of $p$ to $\real$) and followed by heads (probability $\ur{p}$) when the initial $c$ is $tl$.  The following theorem shows the program $pflip\_t(p)$ terminates almost surely.

\begin{thm}
    \label{thm:flipt_p_sem_termination}
    $ p \neq 0 \implies \pseq{\prrvfunsym{pflip\_t(p)}}{{\ibracket{c = hd}}} = {\usexpr{1}}$
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L1530}
\end{thm}

Its expected termination time is $1/\ur{p}$ flips, shown below.
\begin{thm}
  \label{thm:flipt_p_sem_expected_t}
  $ p \neq 0 \implies \pseq{\prrvfunsym{pflip\_t(p)}}{t} = {\usexpr{\ibracket{c=hd}*t+\ibracket{c=tl}*{(t+1/\ur{p})}}}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L1610}
\end{thm}

In essence, the proof of this theorem is the calculation of the following summation.
\begin{align*}
  \left(\infsum v_0 | c_v(v_0) = hd \land Suc(t) \leq t_v(v_0) @ (1-\ur{p})^{(t_v(v_0) - Suc(t))} * \ur{p}*t_v(v_0) \right)
\end{align*}
where $c_v(v_0)$ and $t_v(v_0)$ extract the values of the variables $c$ and $t$ from the state $v_0$. The calculation involves several important steps:
\begin{enumerate}[labelindent=\parindent,leftmargin=*,label=(\arabic*).]
\item find an injective function to reindex the summation over $v_0$ into the summation over $n$ of natural numbers: $\left(\infsum n:\nat @ f(n)\right)$ where $f(n) \defs ((1-\ur{p})^n * \ur{p}* (Suc(t)+n)$;
\item prove $f(n)$ is summable using the ratio test for convergence by supplying a constant ratio $c$ that is less than 1 and a natural number $N$ so that for all numbers larger than $N$, the ratio $f(n+1)/f(n)$ is less than $c$; 
\item because $f(n)$ is summable, we can assume $f(n+1)$ sums to $l$, then $f(n)$ must sum to $l+f(0)=l+\ur{p}*Suc(t)$; 
\item alternatively, $f(n+1)=(1-\ur{p})^{n+1} * \ur{p}* (Suc(t)+n+1)=f(n)*(1-\ur{p})+(1-\ur{p})^{n} * \ur{p} * (1-\ur{p})$, and so $\left(\infsum n:\nat @ f(n+1)\right)=\left(\infsum n:\nat @ f(n)* (1-\ur{p})\right)+ \left(\infsum n:\nat @ (1-\ur{p})^{n} * \ur{p} * (1-\ur{p})\right)$;
  \begin{itemize}
  \item $\left(\infsum n:\nat @ (1-\ur{p})^{n} * \ur{p} * (1-\ur{p})\right)$ is a geometric series and equal to $\ur{p} * (1-\ur{p}) * \left(1/(1-(1-\ur{p}))\right)=1-\ur{p}$
  \end{itemize}
\item get an equation $l = (l+\ur{p}*Suc(t))*(1-\ur{p}) + (1 - \ur{p})$, solve this equation and we get the result of $l$, then we know $f(n)$ sums to $\left(t + 1/\ur{p}\right)$.
\end{enumerate}

% The expectation of $t$ given the distribution by $flip\_t$ is $t$ itself (terminate immediately) if the initial value of $c$ is $hd$, and $t+2$ (2 flips on average) otherwise.
% Here $t'$ corresponds to the iteration index $n-1$ in \ref{thm:F_b_P_clip_bot}. 
% The expected value of $t'$ is   
% \begin{align*}
%     & flipt_t ; t \\
%   = &\left(\ibracket{c=tl}*\ibracket{c'=hd}*\ibracket{t'\geq t+1}*(1/2)^{t'-t}+\ibracket{c=hd}*\ibracket{c'=hd}*\ibracket{t'=t}\right);t \\
%   = & \left(
%   \begin{array}[]{l}
%     \infsum v_0 @ \ibracket{c=tl}*\ibracket{c_0=hd}*\ibracket{t_0\geq t+1}*(1/2)^{t_0-t}*t[t_0/t] + \\
%     \infsum v_0 @ \ibracket{c=hd}*\ibracket{c_0=hd}*\ibracket{t_0=t}*t_0 \\
%   \end{array}
%   \right) \\
%   = & \left(
%   \begin{array}[]{l}
%       \infsum t_0:\{t+1..\} @ \ibracket{c=tl}*\ibracket{hd=hd}*(1/2)^{t_0-t}*t_0 + \\
%       \ibracket{c=hd}*\ibracket{hd=hd}*\ibracket{t=t}*t \\
%   \end{array}
%   \right) \\
%   % from wolframalpha
%   % input: sum (1/2)^(t0-t)*t0, t0 from t+1 to infty
%   % result: sum_(t0=1 + t)^∞ (1/2)^(t0 - t) t0 = t + 2
%   = &~\ibracket{c=tl}* (t+2)+ \ibracket{c=hd}* t 
% \end{align*}
% So, on average, it takes two (or zero) flips to get heads if, initially, $c$ is tails (or heads).
% The semantics of $pflip(p)$ is 
% \begin{align*}
%     & pflip_t(p) = \ibracket{c=tl}*\ibracket{c'=hd}*\ibracket{t'\geq t+1}*(1-p)^{t'-t-1}*p+\ibracket{c=hd}*\ibracket{c'=hd}*\ibracket{t'=t} 
% \end{align*}
% The expected value of $t'$ is   
% % from wolframalpha 
% % input: sum (1-p)^(t0-t-1)*p*t0, t0 from t+1 to infty 
% % output: sum_(t0=t + 1)^∞ p t0 (1 - p)^(-t + t0 - 1) = (p t + 1)/p when abs(1 - p)<1
% \begin{align*}
%     & pflip_t(p);t = \ibracket{c=tl}*{\left(t+1/p\right)} + \ibracket{c=hd} * t
% \end{align*}
% so on average, it takes $1/p$ flips to get heads if initially, $c$ is tails. When $p=3/4$, it takes $4/3$ flips which is less than two flips for $flip$. This is consistent with our expectations. Our analysis, however, gives an exact quantitative result.

We also note that the parameter $p$ is not present in the semantics (see Theorem~\ref{thm:pflip_sem}) of $pflip$ as long as $p$ is larger than 0. We have seen that the average termination time $1/\ur{p}$ is a function of the parameter $p$, which entitles us to reason about parametric probabilistic models intrinsically, not like approximation and limitations in probabilistic model checking~\cite{Daws2005,Hahn2011}.\footnote{\url{https://www.prismmodelchecker.org/manual/RunningPRISM/ParametricModelChecking}}

% It is worth mentioning that introducing $t$ would make the observation space of $flip$ infinite. Our work presented in this paper, specifically fixed point theorems in Sect~\ref{sec:rec}, cannot deal with that model because its observation space contains countable but infinite states to have probabilities larger than 0. This is part of our future work to extend our reasoning framework about probabilistic loops to infinite state space. 

\subsection{Dice}
\label{sec:ex_cases:dice}
This example~\cite{Hehner2011} is about throwing a pair of dice till they have the same outcome. The $dice$ program is defined below.
\begin{definition}
  \label{def:dice}
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L41}
  \begin{align*} 
    Tdice & ::= \{1..6\}\\ 
    \isakwmaj{alphabet}\ & fdstate = d_1::Tdice \qquad d_2::Tdice \\
    throw & \defs {\pseq{\rvprfunsym{\uniformdist{d_1}{Tdice}}}{\rvprfunsym{\uniformdist{d_2}{Tdice}}}} \\
    dice & \defs \pwhile{d_1 \neq d_2}{throw}
  \end{align*}
\end{definition}
The outcome of a die is from 1 to 6 as given in $Tdice$. The observation space of this program is $fdstate$, containing two variables $d_1$ and $d_2$ of type $Tdice$, denoting the outcome of each dice in an experiment. The program $throw$ is the sequential composition of two uniform distributions to choose $d_1$ and $d_2$ independently, and $dice$ models the example: continue throwing till the outcomes of two dice are equal ($d_1=d_2$).

We use the unique fixed point theorem~\ref{thm:rec_unique} to give semantics. First, $throw$ is a distribution. 
\begin{thm}
  $\isfinaldist(\prrvfunsym{throw})$ 
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L409}
\end{thm}
Second, the observation space $Tdice$ is finite, and sct $fdstate \cross fdstate$ is also finite.
Third, the differences of iterations from top and bottom tend to 0.
\begin{thm}
  \label{thm:dice_iterdiff_0}
  $\forall s:fdstate\cross fdstate @ \left(\lambda n @ \prrvfunsym{\iterdiff\left(n, d_1 \neq d_2, throw\right)}(s)\right) \tendsto 0$ 
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1221}
\end{thm}
Finally, we define $H$, 
\isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L389}
\begin{align*}
  H & \defs \usexpr{\ibracket{d_1 = d_2} * \ibracket{d_1' = d_1 \land d_2' = d_2} + \ibracket{d_1 \neq d_2} * \ibracket{d_1' = d_2'} / 6}
\end{align*}
and prove it is a fixed point.
\begin{thm}
  \label{thm:dice_H}
  $\lfun^{d_1\neq d_2}_{throw}\left(\rvprfunsym{H}\right) = \rvprfunsym{H}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1239}
\end{thm}

The $H$ gives the distribution on the final states. If initially, $d_1$ is equal to $d_2$; it has probability 1 to establish that both $d_1'$ and $d_2'$ are equal to their initial states, so they are identical too. This is the semantics of $\pskip$. However, if $d_1$ is not equal to $d_2$ initially, it has a probability $1/6$ to establish $d_1'=d_2'$. Because there are six combinations of the equal values of $d_1'$ and $d_2'$, the total probability is still 1 ($6*1/6$), so $H$ is a distribution.

All four assumptions of Theorem~\ref{thm:rec_unique} are now established. The $dice$, therefore, is semantically just the fixed point $\rvprfunsym{H}$.

\begin{thm}
  \label{thm:dice_sem}
  $dice = \rvprfunsym{H}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1361}
\end{thm}

The $dice$ terminates almost surely and is almost impossible for non-termination.
\begin{thm}
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1379}
  \begin{align*}
    & \pseq{\prrvfunsym{dice}}{{\ibracket{d_1 = d_2}}} = {\usexpr{1}} \tag*{(termination probability)} \label{thm:dice_term}\\
    & \pseq{\prrvfunsym{dice}}{{\ibracket{d_1 \neq d_2}}} = {\usexpr{0}} \tag*{(non-termination probability)} \label{thm:dice_nonterm}
  \end{align*}
\end{thm}

We now consider the dice program with a time variable $t$.
\begin{definition}[Dice with time]
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1430}
  \begin{align*}
    & \isakwmaj{alphabet}\ dstate\_t = t::\nat \qquad d_1::Tdice \qquad d_2::Tdice \\
    & throw\_t \defs {\pseq{\pseq{\rvprfunsym{\uniformdist{d_1}{Tdice}}}{\rvprfunsym{\uniformdist{d_2}{Tdice}}}}{\passign{t}{t + 1}}} \\
    & dice\_t \defs \pwhile{d_1 \neq d_2}{throw\_t}%{\pseq{\pseq{\rvprfunsym{\uniformdist{d_1}{Tdice}}}{\rvprfunsym{\uniformdist{d_2}{Tdice}}}}{\passign{t}{t + 1}}} 
  \end{align*}
\end{definition}

{
% Additionally, we define the function below.
% \begin{definition}[Alternative definition]
%     \label{def:dice_t_throw_t_altdef}
%     \begin{align*}
%     throw\_t\_altdef \defs {\ibracket{d_1' \in \{1..6\}} * \ibracket{d_2' \in \{1..6\}} * \ibracket{t'=t+1} / 36}
%     \end{align*}
% \end{definition}

We show that 
\begin{thm}
  \label{thm:dice_pt}
  %${\pseq{\pseq{\rvprfunsym{\uniformdist{d_1}{Tdice}}}{\rvprfunsym{\uniformdist{d_2}{Tdice}}}}{\passign{t}{t + 1}}} = \ibracket{d_1' \in \{1..6\}} * \ibracket{d_2' \in \{1..6\}} * \ibracket{t'=t+1} / 36$
  %$throw\_t = \rvprfunsym{\ibracket{d_1' \in \{1..6\}} * \ibracket{d_2' \in \{1..6\}} * \ibracket{t'=t+1} / 36}$
  %$throw\_t = \rvprfunsym{throw\_t\_altdef}$
  $throw\_t = \rvprfunsym{\ibracket{t'=t+1} / 36}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1883}
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1903}
\end{thm}

The ${\ibracket{t'=t+1} / 36}$ is a distribution.
\begin{thm}
  \label{thm:dice_pt_distr}
  %$\isfinaldist({\ibracket{d_1' \in \{1..6\}} * \ibracket{d_2' \in \{1..6\}} * \ibracket{t'=t+1} / 36})$
  $\isfinaldist(\ibracket{t'=t+1} / 36)$
  %$\isfinaldist(throw\_t\_altdef)$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1941}
\end{thm}

So the conversion of $throw\_t$ to real-valued functions is just the distribution.
\begin{thm}
  \label{thm:dice_pt_inverse}
  ${\prrvfunsym{throw\_t}} = {\ibracket{t'=t+1} / 36}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1952}
\end{thm}
\begin{proof}
   This can be proved using Theorems~\ref{thm:prrvfun_inverse}, \ref{thm:dice_pt_distr}, and \ref{thm:final_distribtion}.
\end{proof}
}

We define $Ht$.
\begin{definition}[$Ht$]
    \label{def:Ht}
\begin{align*}
  Ht & \defs \usexpr{
       \begin{array}[]{l}
         \ibracket{d_1 = d_2} * \ibracket{t'=t \land d_1' = d_1 \land d_2' = d_2} + \\
         \ibracket{d_1 \neq d_2} * \ibracket{d_1' = d_2'} * \ibracket{t'\geq t+1}*(5/6)^{t'-t-1}*(1/36)
       \end{array}}
  \tag*{\isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1686}}
\end{align*}
\end{definition}

{
    The $Ht$ is a distribution. 
\begin{thm}
  \label{thm:dice_ht_distr}
  $\isfinaldist(Ht)$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L2018}
\end{thm}

\begin{thm}
  \label{thm:dice_ht_inverse}
  ${\prrvfunsym{\left(\rvprfunsym{Ht}\right)}} = Ht$
\end{thm}
\begin{proof}
   This can be proved using Theorems~\ref{thm:prrvfun_inverse}, \ref{thm:dice_ht_distr}, and \ref{thm:final_distribtion}.
\end{proof}
}

The $Ht$ is proved to be a fixed point of $dice\_t$.\footnote{We note that our $Ht$ is different from that of~\cite{Hehner2011} where the probability of having $d_1'=d_2'$ is $1/6$ (instead of $1/36$ in ours). After a careful comparison of our mechanised proof and the pencil-and-paper proof in~\cite{Hehner2011}, we figured out the mistake is introduced in a step of the proofs in~\cite{Hehner2011}.}
\begin{thm}
  \label{thm:dice_Ht}
  %$\lfun^{d_1\neq d_2}_{\pseq{\pseq{\rvprfunsym{\uniformdist{d_1}{Tdice}}}{\rvprfunsym{\uniformdist{d_2}{Tdice}}}}{\passign{t}{t + 1}}}\left(\rvprfunsym{Ht}\right) = \rvprfunsym{Ht}$
  $\lfun^{d_1\neq d_2}_{throw\_t}\left(\rvprfunsym{Ht}\right) = \rvprfunsym{Ht}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L2053}
\end{thm}
{
\begin{proof}
\begin{align*}
    & \lfun^{d_1\neq d_2}_{throw\_t}\left(\rvprfunsym{Ht}\right) \\
= & \cmt{Law~\ref{thm:lfun_altdef}} \\
  & \rvprfunsym{{\ibracket{d_1\neq d_2}}*\prrvfunsym{\left(\pseq{throw\_t}{\rvprfunsym{Ht}}\right)} + \ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  = & \cmt{Definition~\ref{def:prob_programs} for $\pseq{}{}$} \\
  & \rvprfunsym{{\ibracket{d_1\neq d_2}}*\prrvfunsym{\left(\rvprfunsym{\fseq{\prrvfunsym{throw\_t}}{\prrvfunsym{\left(\rvprfunsym{Ht}\right)}}}\right)} + \ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  = & \cmt{Theorems~\ref{thm:dice_pt_inverse} and \ref{thm:dice_ht_inverse}} \\
  %& \rvprfunsym{{\ibracket{d_1\neq d_2}}*\prrvfunsym{\left(\rvprfunsym{\fseq{{throw\_t\_altdef}}{Ht}}\right)} + \ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  & \rvprfunsym{{\ibracket{d_1\neq d_2}}*\prrvfunsym{\left(\rvprfunsym{\fseq{{\ibracket{t'=t+1} / 36}}{Ht}}\right)} + \ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  = & \cmt{Definition~\ref{def:prob_programs} for $\fseq{}{}$} \\
  & \rvprfunsym{{\ibracket{d_1\neq d_2}}*\prrvfunsym{\left(\rvprfunsym{{{\infsum \vv'' @ {\left(\ibracket{t'=t+1} / 36\right)}[\vv''/\vv'] * {Ht}[\vv''/\vv]}}}\right)} + \ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  = & \cmt{Definitions~\ref{def:Ht}, substitution, and omit $\ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}$} \\
  & \rvprfunsym{{\ibracket{d_1\neq d_2}}*\prrvfunsym{\left(\rvprfunsym{{{\infsum \vv'' @ 
      \begin{array}[]{l}
      {\left(\ibracket{t''=t+1} / 36\right)} * \\
      {\left(
       \begin{array}[]{l}
         \ibracket{d_1'' = d_2''} * \ibracket{t'=t'' \land d_1' = d_1'' \land d_2' = d_2''} + \\
         \ibracket{d_1'' \neq d_2''} * \ibracket{d_1' = d_2'} * \ibracket{t'\geq t''+1}*(5/6)^{t'-t''-1}*(1/36)
       \end{array}\right)}
      \end{array}
  }}}\right)} + \cdots} \\%\ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  = & \cmt{Multiplication distributive over addition} \\
  & \rvprfunsym{{\ibracket{d_1\neq d_2}}*\prrvfunsym{\left(\rvprfunsym{{{\infsum \vv'' @ 
      \begin{array}[]{l}
      {\left(\ibracket{t''=t+1} / 36\right)} * \ibracket{d_1'' = d_2''} * \ibracket{t'=t'' \land d_1' = d_1'' \land d_2' = d_2''} + \\
      {\left(\ibracket{t''=t+1} / 36\right)} * \\{
       \begin{array}[]{l}
         \ibracket{d_1'' \neq d_2''} * \ibracket{d_1' = d_2'} * \ibracket{t'\geq t''+1}*(5/6)^{t'-t''-1}*(1/36)
       \end{array}}
      \end{array}
  }}}\right)} + \cdots} \\%\ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  = & \cmt{Law~\ref{thm:summation_add} and proofs of summable omitted } \\
  & \rvprfunsym{{\ibracket{d_1\neq d_2}}*\prrvfunsym{\left(\rvprfunsym{{{
      \begin{array}[]{l}
      \left(\infsum \vv'' @ {\left(\ibracket{t''=t+1} / 36\right)} * \ibracket{d_1'' = d_2''} * \ibracket{t'=t'' \land d_1' = d_1'' \land d_2' = d_2''}\right) + \\
      \infsum \vv'' @ {\left(\ibracket{t''=t+1} / 36\right)} * \\{
       \begin{array}[]{l}
         \ibracket{d_1'' \neq d_2''} * \ibracket{d_1' = d_2'} * \ibracket{t'\geq t''+1}*(5/6)^{t'-t''-1}*(1/36)
       \end{array}}
      \end{array}
  }}}\right)} + \cdots} \\%\ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  = & \cmt{In the first summation, only one state $\vv''[t''=t+1,d_1''=d_1',d_2''=d_2']$ satisfies the predicates }\\% in Iverson brackets, and so the summation is removed. } \\
  & \rvprfunsym{{\ibracket{d_1\neq d_2}}*\prrvfunsym{\left(\rvprfunsym{{{
      \begin{array}[]{l}
        {\ibracket{d_1' = d_2'} * \ibracket{t'=t+1} / 36} + \\
      \infsum \vv'' @ {\left(\ibracket{t''=t+1} / 36\right)} * \\{
       \begin{array}[]{l}
         \ibracket{d_1'' \neq d_2''} * \ibracket{d_1' = d_2'} * \ibracket{t'\geq t''+1}*(5/6)^{t'-t''-1}*(1/36)
       \end{array}}
      \end{array}
  }}}\right)} + \cdots} \\%\ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  = & \cmt{There are 30 states $\vv''[t+1/t'',x/d_1'',y/d_2'']$ where $x \neq y$ satisfies the predicates }\\% in Iverson brackets, and so the summation is removed. } \\
  & \rvprfunsym{{\ibracket{d_1\neq d_2}}*\prrvfunsym{\left(\rvprfunsym{{{
      \begin{array}[]{l}
        {\ibracket{d_1' = d_2'} * \ibracket{t'=t+1} / 36} + \\
        {
         \ibracket{d_1' = d_2'} * \ibracket{t'\geq t+1+1}*(5/6)^{t'-(t+1)-1}*30*(1/36)*(1/36)
        }
      \end{array}
  }}}\right)} + \cdots} \\%\ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  = & \cmt{$30/36=5/6$}\\% in Iverson brackets, and so the summation is removed. } \\
  & \rvprfunsym{{\ibracket{d_1\neq d_2}}*\prrvfunsym{\left(\rvprfunsym{{{
      \begin{array}[]{l}
        {\ibracket{d_1' = d_2'} * \ibracket{t'=t+1} / 36} + \\
        {
         \ibracket{d_1' = d_2'} * \ibracket{t'\geq t+2}*(5/6)^{t'-t-1}*(1/36)
        }
      \end{array}
  }}}\right)} + \cdots} \\%\ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  = & \cmt{ Merged }\\% in Iverson brackets, and so the summation is removed. } \\
  & \rvprfunsym{{\ibracket{d_1\neq d_2}}*\prrvfunsym{\left(\rvprfunsym{{{
      \begin{array}[]{l}
        {
         \ibracket{d_1' = d_2'} * \ibracket{t'\geq t+1}*(5/6)^{t'-t-1}*(1/36)
        }
      \end{array}
  }}}\right)} + \cdots} \\%\ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  = & \cmt{Theorems~\ref{thm:prrvfun_inverse}, \ref{thm:dice_ht_distr}, and \ref{thm:final_distribtion}, and the omitted}\\% in Iverson brackets, and so the summation is removed. } \\
  & \rvprfunsym{{\ibracket{d_1\neq d_2}}*{\left({{{
      \begin{array}[]{l}
        {
         \ibracket{d_1' = d_2'} * \ibracket{t'\geq t+1}*(5/6)^{t'-t-1}*(1/36)
        }
      \end{array}
  }}}\right)} + \ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}} \\%\ibracket{\lnot d_1\neq d_2} * {\ibracket{\II}}}\\
  = & \cmt{ Definition~\ref{def:uskip} }\\% in Iverson brackets, and so the summation is removed. } \\
  & \rvprfunsym{Ht}
\end{align*}
\end{proof}
}


% {We note that our $Ht$ is different from Hehner's~\cite{Hehner2011} where $1/6$ (instead of $1/36$ in our $Ht$) in his hypothesis for the dice example.
% \begin{align*}
%   (u'=v')* (t'\geq t+1) * (5/6)^{t'-t-1} * (1/6)
% \end{align*}
% for the dice example in Hehner's paper~\cite{Hehner2011}. In his proof, the error is introduced in the following step.
% \begin{align*}
%   & \Sigma u'',v'',t''. \left(
%     \begin{array}[]{l}
%       (1 \leq u'' \leq 6) * (1 \leq u'' \leq 6)* (t''=t+1)/36 * \\
%       \left(u''=v''\right) * \left(u'=u''\right) * \left(v'=v''\right) * \left(t'=t''\right) 
%     \end{array}
%   \right) \\
%   = & \ (u'=v')*(t'=t+1)/36 \tag*{(Correct)}\\ 
%   \neq &\ 6*(u'=v')*(t'=t+1)/36 \tag*{(Incorrect)} 
% \end{align*}
% There is only one intermediate state, $(u''=u',v''=u',t''=t+1)$, satisfying the predicate, so it should be one instead of 6.
% }

Using Theorem~\ref{thm:rec_unique_fin}, we prove the semantics of $dice\_t$ is just $Ht$.
\begin{thm}
  \label{thm:dice_t_sem}
  $dice\_t = \rvprfunsym{Ht}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L2380}
\end{thm}

\changed[\C{1}]{We note that the semantics of $pflip\_t$ in Theorem~\ref{thm:pflip_t_sem} has a pattern 
\begin{align*}
    \ibracket{c=tl}*\ibracket{c'=hd}*\ibracket{t'\geq t+1}*(5/6)^{t'-t-1}*(1/6) 
\end{align*}
if $p=1/6$, and the semantics of $dice\_t$ here has a pattern 
\begin{align*}
    \ibracket{d_1 \neq d_2} * \ibracket{d_1' = d_2'} * \ibracket{t'\geq t+1}*(5/6)^{t'-t-1}*(1/36) 
\end{align*}
The $(1/6)$ or $(1/36)$ above denotes the success probability of each experiment in terms of a particular valuation of the variables in the observation space. For example, $(1/6)$ denotes the probability of $\ibracket{c'=hd}$ for a particular $t'$ and $c'$ (where $c'=hd$ is the only value to establish $\ibracket{c'=hd}$), and $(1/36)$ denotes the probability of $\ibracket{d_1' = d_2'}$ for a particular $t'$, $d_1'$, and $d_2'$ (where for each $t'$, there are overall 6 values of $d_1'$ and $d_2'$ to establish $\ibracket{d_1' = d_2'}$, that is, both take the same value from 1 to 6).
} 

The $dice\_t$ terminates almost surely.
\begin{thm}
  \label{thm:dice_t_terminate}
  $ \pseq{\prrvfunsym{dice\_t}}{{\ibracket{d_1 = d_2}}} = {\usexpr{1}}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L2395}
\end{thm}

On average, the $dice\_t$ takes six dice throws to get an equal outcome.
\begin{thm}
  \label{thm:dice_t_expectation}
  $ \pseq{\prrvfunsym{dice\_t}}{t} = \usexpr{\ibracket{d1=d2}*t + \ibracket{d1 \neq d2}*(t+6)}$
  \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/6a4419b8674b84988065a58696f15093d176594c/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L2431}
\end{thm}

% \subsection{One dimensional random walker}
% % One and two-dimensional random walker is recurrent at every point, but three-dimensional is not recurrent.
% \begin{definition}{}
%     \label{def:srw}
% \begin{align*}
%     x := m; t:=0; \text{while}(x > 0) \{x := x - 1 \pchoice{p} x := x + 1 ; t:=t+1\} \tag*{(TPSRW)} \label{eqn:TPSRW}
% \end{align*}
% \end{definition}
% 
% \begin{definition}{}
%     \label{def:srw:ht}
% \begin{align*}
%     Ht\defs &\ibracket{\lnot x> 0}*\ibracket{x'=x}*\ibracket{t'=t} + \ibracket{x > 0}*\ibracket{x'=0} * \\ 
%     &\left(
%     \begin{array}[]{l}
%         \ibracket{t'-t\geq x}*\ibracket{((t'-t)-x)\%2=0}*\mu(x-1, t'-t-1)*q +\\ 
%         \ibracket{t'-t\geq x+2}*\ibracket{((t'-t)-(x+2))\%2=0}*\mu(x+1, t'-t-1)*p
%     \end{array}\right)
%     %&\ibracket{x > 0}*\ibracket{x'=0}*\ibracket{t'-t\geq x}*\ibracket{((t'-t)-x)\%2=0}*\mu(x-1, t'-t-1)*q +\\ 
%     %&\ibracket{x > 0}*\ibracket{x'=0}*\ibracket{t'-t\geq x+2}*\ibracket{((t'-t)-(x+2))\%2=0}*\mu(x+1, t'-t-1)*p
% \end{align*}
% \end{definition}
% 
% Let $ P \defs \{x := x - 1 \pchoice{p} x := x + 1 ; t:=t+1\}$
% \begin{proof}
% \begin{align*}
%     & \lfun^{x>0}_{P}\left(\rvprfunsym{Ht}\right) \\
% %= & \cmt{Law~\ref{thm:lfun_altdef}} \\
% = & \cmt{Law~\ref{thm:lfun_altdef}} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\pseq{P}{\rvprfunsym{Ht}}\right)} + \ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Definition~\ref{def:prob_programs} for $\pseq{}{}$} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{\fseq{\prrvfunsym{P}}{\prrvfunsym{\left(\rvprfunsym{Ht}\right)}}}\right)} + \ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Inverse} \\
%   %& \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{\fseq{{P\_altdef}}{Ht}}\right)} + \ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{\fseq{p{\ibracket{x'=x+1}}{\ibracket{t'=t+1}}+q{\ibracket{x'=x-1}}{\ibracket{t'=t+1}}}{Ht}}\right)} + \ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Definition~\ref{def:prob_programs} for $\fseq{}{}$ and $\ibracket{\lnot x>0}  {\ibracket{\II}}$ is omitted} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{\infsum \vv'' @ {\left(p{\ibracket{x'=x+1}}{\ibracket{t'=t+1}}+q{\ibracket{x'=x-1}}{\ibracket{t'=t+1}}\right)}[\vv''/\vv']  {Ht}[\vv''/\vv]}}}\right)}} \\
%   = & \cmt{Definitions~\ref{def:srw:ht}, substitution} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{\infsum \vv'' @ 
%       \begin{array}[]{l}
%           {\left(p{\ibracket{x''=x+1}}{\ibracket{t''=t+1}}+q{\ibracket{x''=x-1}}{\ibracket{t''=t+1}}\right)} \\
%     \left(
%     \begin{array}[]{l}
% \ibracket{\lnot x''> 0}\ibracket{x'=x''}\ibracket{t'=t''} + \ibracket{x'' > 0}\ibracket{x'=0}  \\ 
%     \left(
%     \begin{array}[]{l}
%         \ibracket{t'-t''\geq x''}\ibracket{((t'-t'')-x'')\%2=0}\mu(x''-1, t'-t''-1)q +\\ 
%         \ibracket{t'-t''\geq x''+2}\ibracket{((t'-t'')-(x''+2))\%2=0}\mu(x''+1, t'-t-1)p
%     \end{array}\right)
%       \end{array}
%     \right)
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Multiplication distributive over addition} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{\infsum \vv'' @ 
%       \begin{array}[]{l}
% p{\ibracket{x''=x+1}}{\ibracket{t''=t+1}}\ibracket{\lnot x''> 0}\ibracket{x'=x''}\ibracket{t'=t''}+\\ 
% q{\ibracket{x''=x-1}}{\ibracket{t''=t+1}}\ibracket{\lnot x''> 0}\ibracket{x'=x''}\ibracket{t'=t''}+\\ 
% p{\ibracket{x''=x+1}}{\ibracket{t''=t+1}}\ibracket{x'' > 0}\ibracket{x'=0}\\\quad\ibracket{t'-t''\geq x''}\ibracket{((t'-t'')-x'')\%2=0}\mu(x''-1, t'-t''-1)q +\\ 
% p{\ibracket{x''=x+1}}{\ibracket{t''=t+1}}\ibracket{x'' > 0}\ibracket{x'=0}\\\quad\ibracket{t'-t''\geq x''+2}\ibracket{((t'-t'')-(x''+2))\%2=0}\mu(x''+1, t'-t-1)p\\
% q{\ibracket{x''=x-1}}{\ibracket{t''=t+1}}\ibracket{x'' > 0}\ibracket{x'=0}\\\quad\ibracket{t'-t''\geq x''}\ibracket{((t'-t'')-x'')\%2=0}\mu(x''-1, t'-t''-1)q +\\ 
% q{\ibracket{x''=x-1}}{\ibracket{t''=t+1}}\ibracket{x'' > 0}\ibracket{x'=0}\\\quad\ibracket{t'-t''\geq x''+2}\ibracket{((t'-t'')-(x''+2))\%2=0}\mu(x''+1, t'-t-1)p\\
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Summation distributive over addition} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
% \infsum \vv'' @ p{\ibracket{x''=x+1}}{\ibracket{t''=t+1}}\ibracket{\lnot x''> 0}\ibracket{x'=x''}\ibracket{t'=t''}+\\ 
% \infsum \vv'' @ q{\ibracket{x''=x-1}}{\ibracket{t''=t+1}}\ibracket{\lnot x''> 0}\ibracket{x'=x''}\ibracket{t'=t''}+\\ 
% \infsum \vv'' @ p{\ibracket{x''=x+1}}{\ibracket{t''=t+1}}\ibracket{x'' > 0}\ibracket{x'=0}\\\quad\ibracket{t'-t''\geq x''}\ibracket{((t'-t'')-x'')\%2=0}\mu(x''-1, t'-t''-1)q +\\ 
% \infsum \vv'' @ p{\ibracket{x''=x+1}}{\ibracket{t''=t+1}}\ibracket{x'' > 0}\ibracket{x'=0}\\\quad\ibracket{t'-t''\geq x''+2}\ibracket{((t'-t'')-(x''+2))\%2=0}\mu(x''+1, t'-t-1)p\\
% \infsum \vv'' @ q{\ibracket{x''=x-1}}{\ibracket{t''=t+1}}\ibracket{x'' > 0}\ibracket{x'=0}\\\quad\ibracket{t'-t''\geq x''}\ibracket{((t'-t'')-x'')\%2=0}\mu(x''-1, t'-t''-1)q +\\ 
% \infsum \vv'' @ q{\ibracket{x''=x-1}}{\ibracket{t''=t+1}}\ibracket{x'' > 0}\ibracket{x'=0}\\\quad\ibracket{t'-t''\geq x''+2}\ibracket{((t'-t'')-(x''+2))\%2=0}\mu(x''+1, t'-t-1)p\\
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Summation} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           0+q\ibracket{\lnot x-1> 0}\ibracket{x'=x-1}\ibracket{t'=t+1}+\\ 
% p\ibracket{x+1 > 0}\ibracket{x'=0}\\\quad\ibracket{t'-(t+1)\geq (x+1)}\ibracket{((t'-(t+1))-(x+1))\%2=0}\mu(x, t'-(t+1)-1)q +\\ 
% p\ibracket{x+1 > 0}\ibracket{x'=0}\\\quad\ibracket{t'-(t+1)\geq x+1+2}\ibracket{((t'-(t+1))-(x+1+2))\%2=0}\mu(x+2, t'-(t+1)-1)p\\
% q\ibracket{x-1 > 0}\ibracket{x'=0}\\\quad\ibracket{t'-(t+1)\geq (x-1)}\ibracket{((t'-(t+1))-(x-1))\%2=0}\mu(x-2, t'-(t+1)-1)q +\\ 
% q\ibracket{x-1 > 0}\ibracket{x'=0}\\\quad\ibracket{t'-(t+1)\geq (x-1)+2}\ibracket{((t'-(t+1))-(x-1+2))\%2=0}\mu(x, t'-(t+1)-1)p\\
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Summation} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           0+q\ibracket{x \leq 1}\ibracket{x'=x-1}\ibracket{t'=t+1}+\\ 
% p\ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2)}\ibracket{((t'-t)-(x+2))\%2=0}\mu(x, t'-t-2)q +\\ 
% p\ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+4}\ibracket{((t'-t)-(x+4))\%2=0}\mu(x+2, t'-t-2)p\\
% q\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x}\ibracket{((t'-t)-x)\%2=0}\mu(x-2, t'-t-2)q +\\ 
% q\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2}\ibracket{((t'-t)-(x-2))\%2=0}\mu(x, t'-t-2)p\\
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Case split} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           q\ibracket{x = 1}\ibracket{x'=0}\ibracket{t'=t+1}+\\ 
%           {\color{red} p\ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t= x+2)}\ibracket{((t'-t)-(x+2))\%2=0}\mu(x, t'-t-2)q} +\\ 
%           {\color{red} p\ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+4)}\ibracket{((t'-t)-(x+2))\%2=0}\mu(x, t'-t-2)q} +\\ 
% p\ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+4}\ibracket{((t'-t)-(x+4))\%2=0}\mu(x+2, t'-t-2)p\\
% {\color{brown}q\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t= x}\ibracket{((t'-t)-x)\%2=0}\mu(x-2, t'-t-2)q} +\\ 
% {\color{brown}q\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2}\ibracket{((t'-t)-x)\%2=0}\mu(x-2, t'-t-2)q} +\\ 
% q\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2}\ibracket{((t'-t)-(x-2))\%2=0}\mu(x, t'-t-2)p\\
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{$(y+2)\%2=(y-2)\%2=y\%2$ and combination} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           q\ibracket{x = 1}\ibracket{x'=0}\ibracket{t'=t+1}+\\ 
%           {\color{red} p\ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t= x+2)}\ibracket{((t'-t)-(x+2))\%2=0}\mu(x, t'-t-2)q} +\\ 
%           p\ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+4)}\ibracket{((t'-t)-(x+2))\%2=0}\left(
%       \begin{array}[]{l}
%           \mu(x, t'-t-2)q + \\
%           \mu(x+2, t'-t-2)p
%       \end{array}
%           \right)\\
%         {\color{brown}q\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t= x}\ibracket{((t'-t)-x)\%2=0}\mu(x-2, t'-t-2)q} +\\ 
%         q\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2}\ibracket{((t'-t)-x)\%2=0}\left(
%       \begin{array}[]{l}
%         \mu(x-2, t'-t-2)q + \\
%         \mu(x, t'-t-2)p\\
%       \end{array}\right)
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{$\mu(m, n) = q*\mu(m-1,n-1) + p*\mu(m+1,n-1)$} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           q\ibracket{x = 1}\ibracket{x'=0}\ibracket{t'=t+1}+\\ 
%           {\color{red} p\ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t= x+2)}\ibracket{((t'-t)-(x+2))\%2=0}\mu(x, t'-t-2)q} +\\ 
%           p\ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+4)}\ibracket{((t'-t)-(x+2))\%2=0} \mu(x+1, t'-t-1) + \\
%         {\color{brown}q\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t= x}\ibracket{((t'-t)-x)\%2=0}\mu(x-2, t'-t-2)q} +\\ 
%         q\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2}\ibracket{((t'-t)-x)\%2=0}
%         \mu(x-1, t'-t-1) \\
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Rewrite} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           q\ibracket{x = 1}\ibracket{x'=0}\ibracket{t'=t+1}+\\ 
%           {\color{red} p\ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t= x+2)}\ibracket{((t'-t)-(x+2))\%2=0}\mu(x, x)q} +\\ 
%           p\ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+4)}\ibracket{((t'-t)-(x+2))\%2=0} \mu(x+1, t'-t-1) + \\
%         {\color{brown}q\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t= x}\ibracket{((t'-t)-x)\%2=0}\mu(x-2, x-2)q} +\\ 
%         q\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2}\ibracket{((t'-t)-x)\%2=0}
%         \mu(x-1, t'-t-1) \\
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{$\mu(y,y)=q^y$ and $\mu(y,x)q=\mu(y+1,y+1)$ } \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           q\ibracket{x = 1}\ibracket{x'=0}\ibracket{t'=t+1}+\\ 
%           {\color{red} \ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t= x+2)}\ibracket{((t'-t)-(x+2))\%2=0}\mu(x+1,x+1)p} +\\ 
%           {\color{brown}\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t= x}\ibracket{((t'-t)-x)\%2=0}\mu(x-1,x-1)q} +\\ 
%           p\ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+4)}\ibracket{((t'-t)-(x+2))\%2=0} \mu(x+1, t'-t-1) + \\
%         q\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2}\ibracket{((t'-t)-x)\%2=0} \mu(x-1, t'-t-1) \\
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{$$ Rewrite } \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           q\ibracket{x = 1}\ibracket{x'=0}\ibracket{t'=t+1}+\\ 
%           {\color{brown}\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t= x}\ibracket{((t'-t)-x)\%2=0}\mu(x-1,t'-t-1)q} +\\ 
%           {\color{brown}\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2}\ibracket{((t'-t)-x)\%2=0}\mu(x-1, t'-t-1)q}+ \\
%           {\color{red} \ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t= x+2)}\ibracket{((t'-t)-(x+2))\%2=0}\mu(x+1,t'-t-1)p} +\\ 
%           {\color{red} \ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+4)}\ibracket{((t'-t)-(x+2))\%2=0} \mu(x+1, t'-t-1)p}
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Combination and the first one corresponds to $\mu(1,1)$, which is not covered in other two} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           q\ibracket{x = 1}\ibracket{x'=0}\ibracket{t'=t+1}+\\ 
%           {\color{brown}\ibracket{x-1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x}\ibracket{((t'-t)-x)\%2=0}\mu(x-1, t'-t-1)q}+ \\
%           {\color{red} \ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2)}\ibracket{((t'-t)-(x+2))\%2=0} \mu(x+1, t'-t-1)p}
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Rewrite and $\mu(0,0)=1$} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           {\color{brown}\ibracket{x = 1}\ibracket{x'=0}\ibracket{t'-t= x}\ibracket{((t'-t)-x)\%2=0}\mu(x-1, t'-t-1)q}+ \\
%           {\color{brown}\ibracket{x > 1}\ibracket{x'=0}\ibracket{t'-t\geq x}\ibracket{((t'-t)-x)\%2=0}\mu(x-1, t'-t-1)q}+ \\
%           {\color{red} \ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2)}\ibracket{((t'-t)-(x+2))\%2=0} \mu(x+1, t'-t-1)p}
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Rewrite} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           {\color{brown}\ibracket{x = 1}\ibracket{x'=0}\ibracket{t'-t\geq x}\ibracket{((t'-t)-x)\%2=0}\mu(x-1, t'-t-1)q}+ \\
%           {\color{brown}\ibracket{x > 1}\ibracket{x'=0}\ibracket{t'-t\geq x}\ibracket{((t'-t)-x)\%2=0}\mu(x-1, t'-t-1)q}+ \\
%           {\color{red} \ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2)}\ibracket{((t'-t)-(x+2))\%2=0} \mu(x+1, t'-t-1)p}
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{Combination} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           {\color{brown}\ibracket{x \geq 1}\ibracket{x'=0}\ibracket{t'-t\geq x}\ibracket{((t'-t)-x)\%2=0}\mu(x-1, t'-t-1)q}+ \\
%           {\color{red} \ibracket{x+1 > 0}\ibracket{x'=0}\ibracket{t'-t\geq x+2)}\ibracket{((t'-t)-(x+2))\%2=0} \mu(x+1, t'-t-1)p}
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{True predicates $\ibracket{True}=1$} \\
%   & \rvprfunsym{{\ibracket{x>0}}\prrvfunsym{\left(\rvprfunsym{{{
%       \begin{array}[]{l}
%           {\color{brown}\ibracket{x'=0}\ibracket{t'-t\geq x}\ibracket{((t'-t)-x)\%2=0}\mu(x-1, t'-t-1)q}+ \\
%           {\color{red} \ibracket{x'=0}\ibracket{t'-t\geq x+2)}\ibracket{((t'-t)-(x+2))\%2=0} \mu(x+1, t'-t-1)p}
%       \end{array}
%   }}}\right)}} \\%\ibracket{\lnot x>0}  {\ibracket{\II}}}\\
%   = & \cmt{ Definition~\ref{def:uskip} }\\% in Iverson brackets, and so the summation is removed. } \\
%   & \rvprfunsym{Ht}
% \end{align*}
% \end{proof}

