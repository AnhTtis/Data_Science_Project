\section{Examples and case studies}
\label{sec:ex_cases}

\subsection{Doctor Who's Tardis Attack}
Two robots, the Cyberman C and the Dalek D, attack Doctor Who's Tardis once a day between them. C has a probability 1/2 of a successful attack, while D has a probability 3/10 of a successful attack. C attacks more often than D, with a probability of 3/5 on a particular day (and so D attacks with a probability of 2/5 on that day). What is the probability that there is a successful attack today?

We model the problem in our probabilistic programming in the definition below.
\begin{definition}[Doctor Who's Tardis Attack]
    \label{def:dwta}
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dwta.thy\#L22}
\begin{align*}
    Attacker & ::= C | D \\ 
    Status & :: = S | F \\ 
    \isakwmaj{alphabet}\ & dwtastate = r::Attacker \qquad a::Status \\
    dwta & \defs 
    %\begin{array}[]{l}
        \ppchoice{3/5} 
        {\left(\pseq{\left(\passign{r}{C}\right)}{\left(\ppchoice{1/2}{\passign{a}{S}}{\passign{a}{F}}\right)}\right)}
        {\left(\pseq{\left(\passign{r}{D}\right)}{\left(\ppchoice{3/10}{\passign{a}{S}}{\passign{a}{F}}\right)} \right) }
    %\end{array}
\end{align*}
\end{definition}
We define the attacker $C$ and $D$ of type $Attacker$, and $S$ and $F$ of type $Status$ for a successful or failed attacker. The observation space of this program is $dwtastate$ containing two variables $r$ and $a$ to record the attacker and the attack status. The problem is modelled as a program $dwta$, composed of probabilistic choice, assignment, and sequential composition. 

Using the reasoning framework and the algebraic laws mechanised in Isabelle, $dwta$ is simplified and proved to be semantically equal to a probabilistic program shown below.
\begin{thm}[Simplified program]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dwta.thy\#L129}
    \begin{align*}
        & dwta = \rvprfunsym{\usexpr{
            \begin{array}[]{l}
                3/10 * \ibracket{r' = C \land a' = S} + 
                3/10 * \ibracket{r' = C \land a' = F} + \\
                6/50 * \ibracket{r' = D \land a' = S} + 
                14/50 * \ibracket{r' = D \land a' = F} 
            \end{array}
        }} \\ 
    \end{align*}
\end{thm}
This law shows $C$ has a probability 3/10 of a successful or failed attack, while $D$ has a probability 6/50 of a successful attack and 14/50 of a failed attack. We note that this simplified program is a distribution of the final state because the summation of the probabilities of these all combinations is equal to 1: $3/10+3/10+6/50+14/50=1$. 

With this simplified program, we can use it to answer interesting quantitative queries using sequential composition. The answer to a question ``what is the probability of a successful attack?'', for example, is 21/50. 
\begin{thm}
   \label{thm:dwta_success}
   %\begin{align*}
       $ \pseq{dwta}{\rvprfunsym{\ibracket{a = S}}} = \rvprfunsym{\usexpr{21/50}}$
   %\end{align*}
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dwta.thy\#L167}
\end{thm}

\subsection{The Monty hall problem}
The problem~\cite{Wikipedia2023} is a puzzle based on an American television game show \emph{Let's Make a Deal}. It is named after its original host, Monty Hall. Suppose you are the contestant and you are given a choice of opening one of three doors. Behind one door is a car, behind the others, goats. You pick a door, say No. 1, and the host, who knows what is behind each of the doors, opens another door, say No. 3 and reveals a goat. He then says to you, ``Do you want to pick door No. 2 instead of your original choice?'' The problem is simple: should you change your choice to maximise your chance to win a car?

We model the problem in the program below where the doors are numbered as natural numbers: 0, 1, and 2.
\begin{definition}[Monty hall]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L14}
    \begin{align*}
        \isakwmaj{alphabet}\ &mhstate = p::\nat \qquad c::\nat \qquad m::\nat\\
        init & \defs \pseq{\uniformdist{p}{\{0 \upto 2\}}}{\uniformdist{c}{\{0 \upto 2\}}} \\
        mha & \defs \pcchoice{c = p}{\left(\ppchoice{1/2}{\left(m := (c+1) \mod 3\right)}{\left(m := (c+2) \mod 3\right)}\right)}{m := 3 - c -p} \\
        mha\_nc & \defs \pseq{\pseq{init}{mha}}{\pskip}\tag*{(no change strategy)} \label{thm:monty_mha_nc}\\
        mha\_c & \defs \pseq{init}{\pseq{mha}{c := 3 - c -m}}\tag*{(change strategy)} \label{thm:monty_mha_c}
    \end{align*}
\end{definition}
The observation space $mhstate$ contains three variables of type $\nat$: $p$ for the number of the prize door, $c$ for the contestant's choice, and $m$ for the door Monty opens. The $init$ is the initial configuration of the problem where the values of $p$ and $c$ follow a uniform distribution from an interval between 0 and 2 inclusive, and so the prize and the contestant's choice are random.
The $mha$ models if the contestant's choice is the prize ($c=p$), the Monty randomly (with probability 1/2) chooses $m$ from the other two doors, denoted as $(c+1) \mod 3$ and $(c+2) \mod 3$. Otherwise, the prize is not revealed and then the Monty chooses the one that is not $p$ (he knows the value of $p$, the prize door)  where $3-c-p$ guarantees that $m$ is different from both $c$ and $p$.
The $mha\_nc$ models a no-change strategy and the $mha\_c$ models a change strategy after the Monty reveal one.

We simplify $init$ according to the law below.
\begin{thm}[Initial]
   $init = \rvprfunsym{ \usexpr{ \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' \in \{0 \upto 2\}} * \ibracket{m' = m} / 9 }}$
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L143}
\end{thm}
In the initial configuration, the combinations of $p$ and $c$ have an equal probability $1/9$ with $m$ unchanged. The $init$ is also a distribution: the summation over its final states is equal to 1.

The $mha\_nc$ is proved to be equal to a program below.
\begin{thm}[No change strategy]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L550}
    \begin{align*}
        & mha\_nc =  \rvprfunsym{
            \usexpr{
            \begin{array}[]{l}
                \ibracket{c' = p'} * \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' \in \{0 \upto 2\}} * \ibracket{m' = (c'+1)\mod 3} / 18\ + \\
                \ibracket{c' = p'} * \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' \in \{0 \upto 2\}} * \ibracket{m' = (c'+2)\mod 3} / 18\ + \\
                \ibracket{c' \neq p'} * \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' \in \{0 \upto 2\}} * \ibracket{m' = 3 - c' - p'} / 9 \\
            \end{array}
        }}
    \end{align*}
\end{thm}

The $mha\_c$ is also proved to be equal to a program below.
\begin{thm}[Change strategy]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L1273}
    \begin{align*}
        & mha\_c =  \rvprfunsym{
            \usexpr{
            \begin{array}[]{l}
                \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' = 3 - p' - m'} * \ibracket{m' = (p'+1)\mod 3} / 18\ + \\
                \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' = 3 - p' - m'} * \ibracket{m' = (p'+2)\mod 3} / 18\ + \\
                 \ibracket{c' = p'} * \ibracket{p' \in \{0 \upto 2\}} * \ibracket{3 - p' - m' \neq p'} * \ibracket{3 - p' - m' \leq 2} *  \ibracket{3 - p' - m' \geq 0} / 9 \\
            \end{array}
        }}
    \end{align*}
\end{thm}

With these laws, we can answer questions like what is the probability of winning for each strategy and should you change the choice? 
\begin{thm}[Winning probability]
    \hfill \isaref{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L928}
    and 
    \isaref{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L1633}
   \begin{align*}
       & \pseq{mha\_nc}{\rvprfunsym{\ibracket{c = p}}} = \rvprfunsym{\usexpr{1/3}} \tag*{(winning probability of no-change strategy)} \label{thm:monty_nc_winning} \\
       & \pseq{mha\_c}{\rvprfunsym{\ibracket{c = p}}} = \rvprfunsym{\usexpr{2/3}}  \tag*{(winning probability of change strategy)} \label{thm:monty_c_winning} 
   \end{align*}
\end{thm}
The above law shows the winning probabilities are $1/3$ for the no-change strategy and $2/3$ for the change strategy, and so you should change the choice because you have a high probability to win.

\subsection{The forgetful Monty}
\label{ssec:cases_forgetful_monty}
Suppose now that Monty forgets which door has the prize behind it. He just opens either of the 
doors not chosen by the contestant. If the prize is revealed ($m'=p'$), then obviously the contestant switches their choice to that door. 
So the contestant will surely win. However, if the prize is not revealed ($m' \neq p'$), should the contestant switch?
The new problem is modelled below.
\begin{definition}[Forgetful Monty]
    \label{def:forgetful_monty}
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L2000}
    \begin{align*}
        & forgetful\_monty \defs \pseq{init}{\left(\ppchoice{1/2}{\left(m := (c+1) \mod 3\right)}{\left(m := (c+2) \mod 3\right)}\right)} \tag*{(the forgetful Monty)} \label{def:monty_forgetful}\\
        %& learn\_fact \defs \pparallel{\prrvfunsym{forgetful\_monty}}{\ibracket{m' \neq p'}} \tag*{[Learn new fact that the prize is not revealed]} \label{def:monty_forgetful_learn}\\
        & learn\_fact \defs \pparallel{{forgetful\_monty}}{\rvprfunsym{\ibracket{m' \neq p'}}} \tag*{(learn new fact that the prize is not revealed)} \label{def:monty_forgetful_learn}
    \end{align*}
\end{definition}
After initialisation, the forgetful Monty randomly chooses one from the other two doors. The learned new fact that the prize is not revealed ($m'\neq p'$) is fed into the program by parallel composition as shown in the definition of $learn\_fact$. The program is proved to be equal to the program below and the winning probability is then queried.
\begin{thm}
    \hfill \isaref{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L2615} and \isaref{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_monty_hall.thy\#L2424} 
    \begin{align*}
        & learn\_fact = \rvprfunsym{
            \usexpr{
            \begin{array}[]{l}
                \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' \in \{0 \upto 2\}} * \ibracket{m' = (c'+1)\%3} * \ibracket{m' \neq p'} / 12\ + \\
                \ibracket{p' \in \{0 \upto 2\}} * \ibracket{c' \in \{0 \upto 2\}} * \ibracket{m' = (c'+2)\%3} * \ibracket{m' \neq p'} / 12
            \end{array}
        }}\\
       & \pseq{learn\_fact}{\rvprfunsym{\ibracket{c = p}}} = \rvprfunsym{\usexpr{1/2}} \tag*{(winning probability of learning new fact)} \label{thm:monty_learn_winning}
    \end{align*}
\end{thm}
The probability of wining is now $1/2$ and so if Monty is forgetful, and the contestant happens to choose a door with no prize, it does not matter whether the contestant sticks or switches because they have the equal probability $1/2$.

\subsection{Robot localisation}
\label{ssec:cases_robot_localisation}
A circular room has two doors and a wall. A robot is equipped with a noisy door sensor which maps position to $\clz door$ or $\clz wall$. Doors are at position 0 and 2, and position 1 is a blank wall. 
We define a predicate $door(p) \defs p = 0 \lor p = 2$ and introduce a program variable $bel \in \{0 \upto 2\}$ to denote the position of the robot that we believe. 
When the reading of the door sensor is $\clz door$, it has four times more likely to be right than wrong. The likelihood functions are defined below.

\begin{definition}[Likelihood functions]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L24}
\begin{align*}
    & scale\_door \defs  \usexpr{3 * \ibracket{door(bel')} + 1} \\
    & scale\_wall \defs  \usexpr{3 * \ibracket{\lnot door(bel')} + 1} 
\end{align*}
\end{definition}

We are interested in questions like how many measurements and moves are necessary to get a confident estimation of the robot's location? 

\subsubsection{Initialisation}
Initially, the robot is randomly placed and so a uniform distribution. This is defined below by the program $init$.

\begin{definition}[Initialisation]
%\begin{align*}
    $ init \defs \uniformdist{bel}{\{0 \upto 2\}} $ 
%\end{align*}
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L20}
\end{definition}

\subsubsection{First sensor reading}
The sensor detects a door. We learn new knowledge and update our belief accordingly using parallel composition.
The prior probability distribution (prior) is $init$, and the likelihood function is $scale\_door$. The posterior probability distribution is given in the theorem below.
\begin{thm}[First posterior]
    %\begin{align*}
        $ \pparallel{init}{scale\_door} = \rvprfunsym{4/9 * \ibracket{bel' = 0} + 1/9 * \ibracket{bel' = 1} + 4/9 *  \ibracket{bel' = 2}}$ % \tag*{(first posterior)} \label{thm:robot_local_belief1}
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L91}
    %\end{align*}
\end{thm}
We have a high probability $4/9$ to believe the robot is in front of a door at position 0 or 2. 

\subsubsection{Move one space to the right}
Now the robot takes an action to move one space to the right, and the belief position is shifted one to the right. This is defined as $move\_right$ below.
\begin{definition}[Move to the right]
    %\begin{align*}
       $move\_right \defs \left(bel := (bel + 1) \mod 3\right) $
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L30}
    %\end{align*}
\end{definition}

An action updates the belief using sequential composition. The posterior probability distribution after the move is given as follow. 
\begin{thm}[Posterior after the first move]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L116}
    \begin{align*}
        & \pseq{\left(\pparallel{init}{scale\_door}\right)}{move\_right}  = \rvprfunsym{4/9 * \ibracket{bel' = 0} + 4/9 * \ibracket{bel' = 1} + 1/9 *  \ibracket{bel' = 2}} %\tag*{[First move to the right]} \label{thm:robot_local_move1}
    \end{align*}
\end{thm}
We observe that the probability values are not change but the positions are shifted in the distribution.

\subsubsection{Second sensor reading}
The sensor detects a door again. The posterior probability distribution is updated accordingly. 
\begin{thm}[Second posterior]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L514}
    \begin{align*}
        & \pparallel{\left(\pseq{\left(\pparallel{init}{scale\_door}\right)}{move\_right}\right)}{scale\_door} = \rvprfunsym{2/3 * \ibracket{bel' = 0} + 1/6 * \ibracket{bel' = 1} + 1/6 *  \ibracket{bel' = 2}} %\tag*{[Learnt second knowledge]} \label{thm:robot_local_belief2}
    \end{align*}
\end{thm}
We have a high probability $2/3$ to believe the robot is in front of a door at position 0 and a low probability $1/6$ in either the other two positions.

\subsubsection{Move one space to the right}
Now another action to move the robot to its right and the posterior probability distribution is shifted accordingly. 
\begin{thm}[Posterior after the second move]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L603}
    \begin{align*}
        & \pseq{\left(\pparallel{\left(\pseq{\left(\pparallel{init}{scale\_door}\right)}{move\_right}\right)}{scale\_door}\right)}{move\_right} \\
        = \,& \rvprfunsym{1/6 * \ibracket{bel' = 0} + 2/3 * \ibracket{bel' = 1} + 1/6 *  \ibracket{bel' = 2}} %\tag*{[Second move]} \label{thm:robot_local_move2}
    \end{align*}
\end{thm}

\subsubsection{Third sensor reading}
The learn sensor detects a wall. The posterior probability distribution is updated accordingly. 
\begin{thm}[Third posterior]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_robot_localisation.thy\#L994}
    \begin{align*}
        & \pparallel{\left(\pseq{\left(\pparallel{\left(\pseq{\left(\pparallel{init}{scale\_door}\right)}{move\_right}\right)}{scale\_door}\right)}{move\_right}\right)}{scale\_wall} \\
        = \,& \rvprfunsym{1/18 * \ibracket{bel' = 0} + 8/9 * \ibracket{bel' = 1} + 1/18 *  \ibracket{bel' = 2}} %\tag*{[Learnt third knowledge]} \label{thm:robot_local_belief3}
    \end{align*}
\end{thm}
After three sensor readings and two moves, our beliefs about the position of the robot are $8/9$ at position 1, and $1/18$ at position 0 or 2. We plot the beliefs in Fig.~\ref{fig:robot_localisation_belief} where each position has six updates corresponding to the initial prior (I1), the three sensor readings (door - D2 and D4, and wall - W6), and the two moves to the right (M3 and M5). 
From the diagram, we observe that the difference between the highest probability and the lowest probability for each update becomes big or at least stay the same: from 0 for I1 to 15/18 ($=8/9-1/18$) for W6, and so the robot gains more knowledge in each update.
From the diagram, we are confident of (probability $8/9$) the robot's localisation after three measurements and two moves.
% reference: https://tex.stackexchange.com/questions/275797/how-to-draw-multiple-bar-charts-each-one-with-multiple-different-series 
\makeatletter
\pgfplotsset{
      calculate offset/.code={
        \pgfkeys{/pgf/fpu=true,/pgf/fpu/output format=fixed}
        \pgfmathsetmacro\testmacro{(\pgfplotspointmeta*10^\pgfplots@data@scale@trafo@EXPONENT@y)*\pgfplots@y@veclength)}
        \pgfkeys{/pgf/fpu=false}
         },
    every node near coord/.style={
        /pgfplots/calculate offset,
         yshift=-\testmacro,
       },
    name node/.style={
    every node near coord/.append style={
        name=#1-\coordindex
    }}
}    
%
\pgfplotstableread{
    0 0.3333 0.4444	0.4444	0.6667	0.1667	0.0556	
    1 0.3333 0.1111	0.4444	0.1667	0.6667	0.8889	
    2 0.3333 0.4444 0.1111  0.1667  0.1667  0.0556
}\dataset
%
\begin{figure}[!ht]
    \begin{center}
\begin{tikzpicture}
    \begin{axis}[ybar,
           width=12cm,
           %height=10cm,
           ymin=0,
           ymax=1,
           xmin=-0.5,
           xmax=2.5,
           ylabel={Probability},
           xtick=data,
           xticklabels = {
           0,
           1,
           2,
           },
          xticklabel style={yshift=-1ex},
          major x tick style = {opacity=0},
          minor x tick num = 1,
          minor tick length=0ex,
          every node near coord/.append style={ anchor=north,font=\scriptsize }
         ]
    \addplot[draw=none,fill=blue!50!black!60, name node=1, nodes near coords=I1] table[x index=0,y index=1] \dataset; 
    \addplot[draw=none,fill=orange!70!black, name node=2, nodes near coords=D2] table[x index=0,y index=2] \dataset;
    \addplot[draw=none,fill=gray!80, name node=3, nodes near coords=M3] table[x index=0,y index=3] \dataset;
    \addplot[draw=none,fill=yellow, name node=4, nodes near coords=D4] table[x index=0,y index=4] \dataset;
    \addplot[draw=none,fill=blue!60, name node=5, nodes near coords=M5] table[x index=0,y index=5] \dataset;
    \addplot[draw=none,fill=green!80, name node=6, nodes near coords=W6] table[x index=0,y index=6] \dataset;
   \end{axis}
   % \foreach \i in{1,...,3}{
   % \foreach \j in{0,1,...,2}{
   % \node[anchor=east,rotate=90] at (\i-\j){parameter\kern0.5ex};}}  
 \end{tikzpicture}
    \end{center}
    \caption{The update of the robot's belief at different positions after three measurements and two moves with a prior.}
    \label{fig:robot_localisation_belief}
\end{figure}
%

\subsection{Classification - cancer diagnosis}
\label{ssec:cancer_diagnosis}
Consider a hospital uses a laboratory test to diagnose if a patient may or may not have a cancer. The test result is binary and could be positive or negative. The test, however, is imperfect. It doesn't not always give a correct result. We are interested in several questions. How likely a randomly selected patient has cancer if the first test result is positive?  Is it necessary to have the second test to reassure the result? How much can the second test contribute to the diagnosis?

We define the state space $cdstate$ of this example as follows.
\begin{definition}[State space]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/bb296824b0b92b23205e48c51ec786ee035c46c8/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L24}
    \begin{align*}
        & LabTest ::= Pos | Neg \\ 
        &\isakwmaj{alphabet}\ cdstate = c::\bool \qquad lt::LabTest
    \end{align*}
\end{definition}
Whether a patient has cancer or not is recorded in a boolean variable $c$: true for cancer and false for no cancer. The test result is recorded in a variable $lt$ of type $LabTest$ whose value could be $Pos$itive or $Neg$ative.

The prior probability of a randomly selected patient having cancer is $p_1$ of type $\ureal$. The prior probability distribution, therefore, is a probabilistic choice, defined below.
\begin{definition}[Prior]
    $Init \defs \ppifchoice{p_1}{c := True}{c := False}$
\end{definition}
So the probability of a patient having cancer $True$ is $p_1$ and having no cancer $False$ is $(1-p_1)$.

The test is imperfect. Its sensitivity (true positive) is $p_2$ and its specificity (true negative) is $1-p_3$. It means if a patient with cancer is tested and the probability of a positive result is $p_2$, and if a patient without cancer is tested, the probability of a negative result is $1-p_3$. We, therefore, define the action of a test as below.

\begin{definition}[Test]
    $TestAction \defs \pcchoice{c}
                        {(\ppchoice{p_2}{\passign{lt}{Pos}}{\passign{lt}{Neg}})}
                        {(\ppchoice{p_3}{\passign{lt}{Pos}}{\passign{lt}{Neg}})}$ 
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/bb296824b0b92b23205e48c51ec786ee035c46c8/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L58}
\end{definition}
It is a conditional choice between two probabilistic choices, defining the probabilities of true positive, false negative, false positive, true negative. A positive test result is a new learned evidence, defined as follows.
\begin{definition}
    $TestResPos \defs \ibracket{lt' = Pos}$ 
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/bb296824b0b92b23205e48c51ec786ee035c46c8/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L67}
\end{definition}
It, essentially, is an Iverson bracket expression of a relation $lt'=Pos$ stating that the test result $lt$ is positive.

We conduct the first test and learn its result is positive, modelled as the program below.
\begin{definition}[First test]
    $FirstTestPos \defs \pparallel{\left(\pseq{Init}{TestAction}\right)}{TestResPos}$
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/bb296824b0b92b23205e48c51ec786ee035c46c8/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L110}
\end{definition}
As usual, the action $TestAction$ is sequentially composed and the evidence is learned in parallel.
We show the posterior in the theorem below. 
\begin{thm}[Posterior after the first test]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/bb296824b0b92b23205e48c51ec786ee035c46c8/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L390}
    \begin{align*}
        FirstTestPos = \usexpr{\left(
            \begin{array}[]{l}
                \ibracket{c'}*\ibracket{lt'=Pos}*p_1*p_2 + \\
                \ibracket{\lnot c'}*\ibracket{lt'=Pos}*(1-p_1)*p_3
            \end{array}
            \right) / \left(p_1*p_2+(1-p_1)*p_3\right)}
    \end{align*}
\end{thm}
From the theorem, we know that the probability that the patient has cancer, given a positive test, is \[\maincolor\left(p_1*p_2\right)/\left(p_1*p_2+(1-p_1)*p_3\right)\] 
Provided $p_1=0.002$, $p_2=0.89$, and $p_3=0.05$, the probability of the patient having cancer is 0.0344 (much less than we may think?), and so the probability without caner is 0.9656.

If a second test is conducted, the result is still positive and so new evidence is learned again.
\begin{definition}[Second test]
    $SecondTestPos \defs \pparallel{\left(\pseq{FirstTestPos}{TestAction}\right)}{TestResPos}$
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/bb296824b0b92b23205e48c51ec786ee035c46c8/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L132}
\end{definition}
We show the posterior after the second test with the learned fact in the theorem below. 
\begin{thm}[Posterior after the second test]
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/bb296824b0b92b23205e48c51ec786ee035c46c8/probability/probabilistic_relations/Examples/machine_learning_examples/utp_prob_rel_cancer_diagnosis.thy\#L661}
    \begin{align*}
        SecondTestPos = \usexpr{\left(
            \begin{array}[]{l}
                \ibracket{c'}*\ibracket{lt'=Pos}*p_1*p_2^2 + \\
                \ibracket{\lnot c'}*\ibracket{lt'=Pos}*(1-p_1)*p_3^2
            \end{array}
            \right) / \left(p_1*p_2^2+(1-p_1)*p_3^2\right)}
    \end{align*}
\end{thm}
From the theorem, we know that the probability that the patient has cancer, given a positive test, is \[\maincolor\left(p_1*p_2^2\right)/\left(p_1*p_2^2+(1-p_1)*p_3^2\right)\] 
Provided $p_1=0.002$, $p_2=0.89$, and $p_3=0.05$, the probability of the patient having cancer is 0.3884, and so the probability without caner is 0.6116.
With the second test, it is more likely (38.84\% vs. 3.44\%) that the patient may have cancer. In this case, a second test should be conducted, given the first test is positive.

\subsection{(Parametrised) coin flip}
\label{ssec:cases_coin}
% FOUNDATIONS OF PROBABILISTIC PROGRAMMING 
The program $flip$ in Definition~\ref{def:coin_flip} is for a unbiased coin (a Bernoulli distribution with $p=1/2$) and $pflip$ below defines a parametrised program where the parameter $p$ denotes the probability to have its outcome as head (a Bernoulli distribution with probability $p$) and so it could be a biased coin.
\begin{definition}[Parametrised coin]
    %\begin{align*}
        %& Tcoin ::= head | tail \\ 
        %& flipbody \defs \ppchoice{1/2}{c := head}{c := tail} \\
        %& flip \defs \pwhile{c = tail}{flipbody} \\
        %& flip \defs \pwhile{c = tail}{\ppchoice{1/2}{c := head}{c := tail}} \\
        $ pflip (p)\defs \pwhile{c = tl}{\ppchoice{p}{c := hd}{c := tl}} $
    %\end{align*}
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L478}
\end{definition}

Both $flip$ and $pflip$ contain probabilistic loops. We use the unique fixed point theorem~\ref{thm:rec_unique} to give semantics to them where $P$ in the theorem is $cflip$ here for $flip$. Previously, we have shown that $cflip$ is a distribution. And obviously the observation space $cstate$ is finite (two elements $hd$ and $tl$) and so the product $cstate \cross cstate$ is also finite.
We also show that the differences of iterations from top and bottom tend to 0, which is illustrated in Fig.~\ref{fig:coin_t_prob_iteration}.
\begin{thm}
    \label{thm:cflip_iterdiff_0}
    $\forall s:cstate\cross cstate @ \left(\lambda n @ \prrvfunsym{\iterdiff\left(n, c=tl, cflip, \ufone\right)}(s)\right) \tendsto 0$ 
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L388}
\end{thm}
Additionally, $\rvprfunsym{\ibracket{c'=hd}}$ is a fixed point of the loop function.
\begin{thm}
    \label{thm:cflip_fp}
    $\lfun^{c = tl}_{cflip}\left(\rvprfunsym{\ibracket{c'=hd}}\right) = \rvprfunsym{\ibracket{c'=hd}}$
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L406}
\end{thm}
All four assumptions of Theorem~\ref{thm:rec_unique} are now established. The $flip$, therefore, is semantically (surprisingly) just the fixed point $\rvprfunsym{\ibracket{c'=hd}}$.
\begin{thm}
    \label{thm:flip_sem}
        $flip = \rvprfunsym{\ibracket{c' = head}}$
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L431}
\end{thm}
The $flip$ terminates almost surely and it is almost not possible for non-termination.
\begin{thm}
    \label{thm:flip_sem_termination}
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L442}
    \begin{align*}
        & \pseq{flip}{\rvprfunsym{\ibracket{c = head}}} = \rvprfunsym{\usexpr{1}} \tag*{(termination probability)} \label{thm:coin_flip_term}\\
        & \pseq{flip}{\rvprfunsym{\ibracket{\lnot c = head}}} = \rvprfunsym{\usexpr{0}} \tag*{(non-termination probability)} \label{thm:coin_flip_nonterm}
    \end{align*}
\end{thm}
This theorem shows the probability of the final state $c'$ being $hd$ is 1 and being not $hd$ is 0. This is equivalent to the termination probability.

We also show $pflip(p)$ is semantically equal to $flip$ if $p$ is not 0.
\begin{thm}
    \label{thm:pflip_sem}
        $ p \neq 0 \implies pflip(p) = \rvprfunsym{\ibracket{c' = head}}$ 
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_coin.thy\#L648}
\end{thm}
If $p$ is 0, we know this program $pflip$ is non-terminating because the probabilistic choice in the loop body always chooses $tl$ and so not possible to terminate.

Though $flip$ and $pflip(p)$ are semantically equal, we expect there are differences between the two programs in other aspects, such as average termination time. Consider a biased coin with probability $p=0.75$ to see a head, then we know on average it needs less flips than a unbiased coin to see a head. In other words, $pflip(p)$ has smaller average termination time than $flip$. This is modelled in Hehner's work~\cite{Hehner2011} by a time variable $t$ of type extended natural numbers $\{0..\infty\}$ to count iterations in a loop. 
After the introduction of $t$, the semantics of $flip$ is 
\begin{align*}
    & flip_t = \ibracket{c=tl}*\ibracket{c'=hd}*\ibracket{t'\geq t+1}*(1/2)^{t'-t}+\ibracket{c=hd}*\ibracket{c'=hd}*\ibracket{t'=t}
\end{align*}
%If we set the start time $t$ as 0, then it is simplified to 
%\begin{align*}
%    & flip_t = \ibracket{c=tl}*\ibracket{c'=hd}*\ibracket{t'\geq 1}*(1/2)^{t'}+\ibracket{c=hd}*\ibracket{c'=hd}*\ibracket{t'=0}
%\end{align*}
Here $t'$ corresponds to the iteration index $n-1$ in \ref{thm:F_b_P_clip_bot}. 
The expected value of $t'$ is   
\begin{align*}
    & flipt_t ; t \\
  = &\left(\ibracket{c=tl}*\ibracket{c'=hd}*\ibracket{t'\geq t+1}*(1/2)^{t'-t}+\ibracket{c=hd}*\ibracket{c'=hd}*\ibracket{t'=t}\right);t \\
  = & \left(
  \begin{array}[]{l}
    \infsum v_0 @ \ibracket{c=tl}*\ibracket{c_0=hd}*\ibracket{t_0\geq t+1}*(1/2)^{t_0-t}*t[t_0/t] + \\
    \infsum v_0 @ \ibracket{c=hd}*\ibracket{c_0=hd}*\ibracket{t_0=t}*t_0 \\
  \end{array}
  \right) \\
  = & \left(
  \begin{array}[]{l}
      \infsum t_0:\{t+1..\} @ \ibracket{c=tl}*\ibracket{hd=hd}*(1/2)^{t_0-t}*t_0 + \\
      \ibracket{c=hd}*\ibracket{hd=hd}*\ibracket{t=t}*t \\
  \end{array}
  \right) \\
  % from wolframalpha
  % input: sum (1/2)^(t0-t)*t0, t0 from t+1 to infty
  % result: sum_(t0=1 + t)^∞ (1/2)^(t0 - t) t0 = t + 2
  = &~\ibracket{c=tl}* (t+2)+ \ibracket{c=hd}* t 
\end{align*}
so on average it takes two (or zero) flips to get a head if initially $c$ is a tail (or a head).
The semantics of $pflip(p)$ is 
\begin{align*}
    & pflip_t(p) = \ibracket{c=tl}*\ibracket{c'=hd}*\ibracket{t'\geq t+1}*(1-p)^{t'-t-1}*p+\ibracket{c=hd}*\ibracket{c'=hd}*\ibracket{t'=t} 
\end{align*}
The expected value of $t'$ is   
% from wolframalpha 
% input: sum (1-p)^(t0-t-1)*p*t0, t0 from t+1 to infty 
% output: sum_(t0=t + 1)^∞ p t0 (1 - p)^(-t + t0 - 1) = (p t + 1)/p when abs(1 - p)<1
\begin{align*}
    & pflip_t(p);t = \ibracket{c=tl}*{\left(t+1/p\right)} + \ibracket{c=hd} * t
\end{align*}
so on average it takes $1/p$ flips to get a head if initially $c$ is a tail. When $p=3/4$, it takes $4/3$ flips which is less than 2 flips for $flip$. This is consistent with our expectation. Our analysis, however, gives an exact quantitative result.

We also note that the parameter $p$ is not present in the semantics of $pflip$ as long as $p$ is larger than 0, but it is present in $pflip_t$. We have seen that the average termination time $1/p$ is a function of the parameter $p$, which entitles us to reason about parametric probabilistic models intrinsically, not like approximation and limitations in probabilistic model checking.

It is worth mentioning that the introduction of $t$ would make the observation space of $flip$ infinite. Our work presented in this paper, specifically fixed point theorems in Sect~\ref{sec:rec}, cannot deal with that model because its observation space contains countable but infinite states to have their probabilities larger than 0. This is part of our future work to extend our reasoning framework about probabilistic loops to infinite state space. 

\subsection{Dice}
This example~\cite{Hehner2011} is about throwing a pair of dice till they have the same outcome. The $dice$ program is defined below.
\begin{definition}
    \label{def:dice}
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L40}
    \begin{align*}
        Tdice & ::= \{1..6\}\\ 
    \isakwmaj{alphabet}\ & fdstate = d_1::Tdice \qquad d_2::Tdice \\
    throw & \defs {\pseq{\rvprfunsym{\uniformdist{d_1}{Tdice}}}{\rvprfunsym{\uniformdist{d_2}{Tdice}}}} \\
        dice & \defs \pwhile{d_1 \neq d_2}{throw}
    \end{align*}
\end{definition}
The outcome of a dice is from 1 to 6 as given in $Tdice$. The observation space of this program is $fdstate$, containing two variables $d_1$ and $d_2$ of type $Tdice$, denoting the outcome of each dice in an experiment. The program $throw$ is sequential composition of two uniform distributions to choose $d_1$ and $d_2$ independently, and $dice$ models the example: continue throwing till the outcomes of two dice are equal ($d_1=d_2$).

We use the unique fixed point theorem~\ref{thm:rec_unique} to give semantics. First, $throw$ is a distribution. 
\begin{thm}
    $\isfinaldist(\prrvfunsym{throw})$ 
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L405}
\end{thm}
Second, the observation space $Tdice$ is finite and so the product $fdstate \cross fdstate$ is also finite.
Third, the differences of iterations from top and bottom tend to 0.
\begin{thm}
    \label{thm:dice_iterdiff_0}
    $\forall s:fdstate\cross fdstate @ \left(\lambda n @ \prrvfunsym{\iterdiff\left(n, d_1 \neq d_2, throw, \ufone\right)}(s)\right) \tendsto 0$ 
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1217}
\end{thm}
Finally, we define $fp$, 
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L385}
    \begin{align*}
        fp & \defs \usexpr{\ibracket{d_1 = d_2} * \ibracket{d_1' = d_1 \land d_2' = d_2} + \ibracket{d_1 \neq d_2} * \ibracket{d_1' = d_2'} / 6}
    \end{align*}
and prove it is a fixed point.
\begin{thm}
    \label{thm:dice_fp}
    $\lfun^{d_1\neq d_2}_{throw}\left(\rvprfunsym{fp}\right) = \rvprfunsym{fp}$
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1235}
\end{thm}
The $fp$ gives the distribution on the final states. If initially $d_1$ is equal to $d_2$, it has probability 1 to establish both $d_1'$ and $d_2'$ are equal to their initial states and so they are equal too. This is the semantics of $\pskip$. However, if initially $d_1$ is not equal to $d_2$, it has probability $1/6$ to establish $d_1'=d_2'$. Because there are 6 combinations of the equal values of $d_1'$ and $d_2'$, the total probability is still 1 ($6*1/6$) and so $fp$ is a distribution.

All four assumptions of Theorem~\ref{thm:rec_unique} are now established. The $dice$, therefore, is semantically just the fixed point $\rvprfunsym{fp}$.
\begin{thm}
    \label{thm:dice_sem}
    $dice = \rvprfunsym{fp}$
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1357}
\end{thm}

The $dice$ terminates almost surely and it is almost not possible for non-termination.
\begin{thm}
    \isalink{https://github.com/RandallYe/probabilistic_programming_utp/blob/5558d7350b75fd5c1914dd8618d95bfad9e2f789/probability/probabilistic_relations/Examples/utp_prob_rel_lattice_dices.thy\#L1370}
    \begin{align*}
        & \pseq{dice}{\rvprfunsym{\ibracket{d_1 = d_2}}} = \rvprfunsym{\usexpr{1}} \tag*{(termination probability)} \label{thm:dice_term}\\
        & \pseq{dice}{\rvprfunsym{\ibracket{d_1 \neq d_2}}} = \rvprfunsym{\usexpr{0}} \tag*{(non-termination probability)} \label{thm:dice_nonterm}
    \end{align*}
\end{thm}

% \subsection{One dimensional random walker}
% One and two-dimensional random walker is recurrent at every point, but three-dimensional is not recurrent.
