\section{Introduction}
Probabilistic programming is a programming paradigm that combines general computer programming, statistical inference, and formal semantics to help systems to made decisions when facing uncertainty. Probabilistic programs are ubiquitous and believed to have a major impact on machine intelligence. While many probabilistic algorithms have been used in practice, for example, in autonomous robots, self-driving cars, and artificial intelligence in many domains, for a very long time, its automated verification based on formal semantics is still a relatively new research area. In the last two decades, it has been attracting a lot of interest. Many challenges, however, still remain. 

What's the mathematical meaning of a probabilistic program? Are probabilistic programming languages expressive enough to capture rich features in real-world applications, such as epistemic and aleatoric uncertainty, discrete and continuous distributions, and real-time? How two programs are compared? How can an abstract probabilistic specification be developed into concrete probabilistic programs? Can formal verification be largely automated and scaled to large systems without sacrificing accuracy? Does a probabilistic program almost surely terminate? What's the expected runtime of this program? Our work presented in this paper, probabilistic relations, takes a step into our vision to tackle these challenges.  

Uncertainty is an essential part in cyber-physical systems, particularly in autonomous robotics. Such systems are subjected to various sources of uncertainties including real-world environments and physical robotic platforms, which present major challenges for robots.
To address these challenges, robots usually are equipped with probabilistic control algorithms to deal with these uncertainties. For example, a modern robot may use SLAM for localisation and mapping, the value iteration algorithm for probabilistic planning~\cite{Thrun2005}.

Probabilistic algorithms are intrinsically more difficult to program and analyse than non-probabilistic algorithms. For a certain input, the output of a probabilistic algorithm might be a distribution (different probabilities for all possible outputs), not just a single output. The outputs with low probabilities (rare) might not even be observed obviously, and therefore not able to be tested for these algorithms. Furthermore, probabilistic behaviour might not always be easily captured and modelled correctly because assumptions might be implicit and not obvious, and so finally are unstated. Finally, specifying the probabilistic behaviour of autonomous robots shall not be ambiguous because these robots carry out their missions without human intervention and may impose safety-critical issues on humans and their living environments. Probabilistic programs with formal syntax and semantics, therefore, are necessary to cope with these challenges. These programs also should be equipped with verification techniques in order to ensure they behave as expected in a real-world environment.

Recently, we presented a probabilistic extension~\cite{Ye2022} to RoboChart~\cite{Miyazawa2019}, a state machine-based DSL for robotics, to allow the modelling of probabilistic behaviour in robot control software. We also developed plugins for RoboTool,\footnote{\url{www.cs.york.ac.uk/robostar/robotool/}} an accompanying tool for RoboChart, to support automated verification through probabilistic model checking using PRISM~\cite{Kwiatkowska2011}. 

We also pursue automated verification using theorem proving~\cite{Woodcock2019,Ye2021}. We mechanised probabilistic designs, the denotational semantics for the probabilistic sequential programming language \emph{pGCL}~\cite{McIver2005} in Isabelle/UTP~\cite{Foster2020}, an implementation of Unifying Theories of Programming (UTP)~\cite{Hoare1998,Woodcock2004} in Isabelle/HOL. Probabilistic designs are an embedding of standard non-probabilistic designs into the probabilistic world. 

Both probabilistic RoboChart and probabilistic designs model aleatoric uncertainty describing the natural randomness of physical processes. Another category of uncertainty is called epistemic uncertainty, due to the lack of knowledge of information, which is reducible by gaining more knowledge.  
% Many machine learning algorithms such as Naive Bayes Classification, \ldots 
In this paper, we present a probabilistic programming language, called \emph{probabilistic relations}, based on Hehner's probabilistic predicative programming~\cite{Hehner2004,Hehner2011}, to model both aleatoric and epistemic uncertainty. In this programming, the subjective Bayesian approach is used to reason about epistemic uncertainty.

% TBD: Should I introduce the benefits of Hehner's work here?

In Hehner's original work~\cite{Hehner2011}, a probabilistic program is given relational semantics, and its syntax is a mixture of relations and arithmetic. The presentation of syntax and semantics in the paper is not formal. For example, the semantics of a probabilistic \emph{ok} (skip) is given as $ok = \left(x' = x\right) \times \left(y' = y\right)$. There is a benefit to introducing semantics using examples, but it lacks formalisation. The operators like $=$ and $\times$ are not formally defined and also the types for variables and expressions are not given. The lack of this information makes the paper not easily accessible for readers and particularly for researchers aiming to use the work for automated reasoning of probabilistic programs. Our first contribution of this paper, therefore, is to formalise its syntax and semantics. Particularly, we introduce a notation called Iverson brackets, such as $\ibracket{r}$, to establish a correspondence between relations $r$ and arithmetic ($0$ or $1$). For \emph{ok}, we could formalise it as $\ibracket{v' = v}$ where $v$ denotes the state space (composed of all variables) of a program. This notation separates relations ($v'=v$) with arithmetic, and so expressions and operators in a program all have clear meanings or definitions depending on their contexts (relations or arithmetic) where the contexts can be easily derived because of the separation. 

In addition to the form of syntax and semantics, the semantics for probabilistic loops is not formally presented and argued. Hehner proposed a simpler but stronger (than total correctness) approach~\cite{Hehner1999}: partial correctness + time, to deal with the termination of loops (for conventional programs) with extra information about run-time (where the stronger means). In his approach, a time variable $t$ is introduced with a healthiness condition, strict incremental for each iteration. The variable $t$ can be discrete or continuous, and is an extended natural number or real number to have $\infty$ for nontermination. The same approach is also applied to probabilistic programs~\cite{Hehner2011}, but the partial correctness of probabilistic loops is not formally reasoned about. 
%cannot be constructed from the semantics for other constructs like conditional and sequential composition. 
%Mechanisation of the semantics of probabilistic programs in theorem prover, therefore, cannot be achieved. 
For this reason, our second contribution of this paper is to bridge the semantics gap for probabilistic loops by establishing its semantics using fixed-point theorems: specifically the Kleene fixed-point theorem, to construct the fixed points using iterations. The advantage of having an iterative (or constructive) fixed point includes both theoretical semantics and practical computation or approximation. A hint of this would be possible to verify probabilistic loops using both theorem proving and model checking (based on approximation). 

To give the semantics using the fixed-point theorem, we define a complete lattice $\left([0,1], \leq\right)$ over the unit real interval (the real numbers between 0 and 1 inclusive). We restrict to the unit interval simply because probability values are between 0 and 1. In order to apply the Kleene theorem, we prove the loop function is Scott-continuous for the state space in which only finite states have positive probabilities. Then we define the semantics of loops as the least fixed point (lfp) of the function where lfp can be calculated iteratively as the supremum of the ascending Kleene chain (from the bottom of the complete lattice) of the function. This bridges the semantics gap, but it is still not easy to calculate lfp because the chain is infinite. We, therefore, also present the strongest fixed point (gfp) of the function, calculated iteratively as the infimum of the descending Kleene chain (from the top of the complete lattice) of the function. We prove a unique fixed point theorem where lfp and gfp are the same based on particular assumptions. The unique fixed point theorem makes reasoning about loops much easier because now it is not necessary to calculate lfp. Instead, a fixed point needs to be constructed and proved with corresponding proved assumptions of the unique fixed point theorem. This, eventually, is consistent with the loop semantics using Hehner's simpler approach. In particular, our semantics can be mechanised and automated.

In the Kleene theorem, the ascending and descending chains start from a pointwise constant function 0 and 1 (the bottom and the top of the complete lattice). The two pointwise functions are not distributions (where probabilities of the state space sum to 1). Indeed, the pointwise function 0 is a subdistribution (the probabilities sum to less than or equal to 1) and the pointwise function 1 is a superdistribution (the probabilities sum to larger than or equal to 1).  For this reason, our third contribution is to extend the semantics domain of the probabilistic programming language from distributions to subdistributions and superdistributions. Eventually, constructs like conditional, probabilistic choice, and sequential composition will not be restricted to programs that are distributions. This brings us the required semantics to use Kleene iterations for the semantics of loops. 

The introduction of Iverson brackets also has another benefit in that the relations inside the brackets can be easily characterised using alphabetised relations in UTP because relations in both Hehner's work and UTP are of the predicative style. Relations in our probabilistic programs are truly UTP alphabetised relations, which allows us to reason about probabilistic programs using the existing theorem prover Isabelle/UTP for UTP. Our final contribution, therefore, is to mechanise the semantics of the probabilistic programming language in Isabelle/UTP. Thanks to the variety of relation tactics in Isabelle/UTP, our reasoning is largely automated. Six examples, presented in this paper, are all verified.
All definitions and theorems in this paper are mechanised and accompanying icons (\isalogo) link to corresponding repository artefacts.

The remainder of this paper is organised as follows. We review related work in Sect.~\ref{sec:relwork}. Section~\ref{sec:prelim} provides necessary background for further presentation of our work in the subsequent sections. In Sect.~\ref{sec:ureal}, we define the complete lattice over the unit interval, and then lift it to a complete lattice over pointwise functions. Section~\ref{sec:program} formalises our probabilistic programming with Iverson brackets defined. We also present proven algebraic laws for each construct. In Sect.~\ref{sec:rec}, we present the semantics of probabilistic loops and the fixed point theorem. Afterwards, we illustrate our reasoning approach using six examples, of them two are classification problems in machine learning and two contain probabilistic loops, in Sect.~\ref{sec:ex_cases}. Finally, we conclude and discuss future work in Sect.~\ref{sec:concl}. 
