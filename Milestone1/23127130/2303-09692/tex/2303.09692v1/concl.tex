\section{Conclusion}
\label{sec:concl}
Previous work~\cite{Ye2022,Ye2021} has shown the modelling of aleatoric uncertainty in RoboChart based on the semantics of MDP and in \emph{pGCL} based on the theory of probabilistic designs, and the automated verification of probabilistic behaviours using probabilistic model checking and theorem proving.
This work presents \emph{probabilistic relations}, a probabilistic programming to cover the modelling of both aleatoric and epistemic uncertainties, and the automated verification of probabilistic systems exhibiting both uncertainties using theorem proving.

We have based our work on Hehner's predicative probabilistic programming and addressed obstacles to the application of his work by formalising and mechanising its semantics in Isabelle/UTP. We have introduced an Iverson bracket notation to give a separation of arithmetic semantics from relational semantics, and so that reasoning about a probabilistic program can reuse existing reasoning techniques for both arithmetic and relational semantics. 
We have used the UTP's alphabetised relational calculus to formalise its relational semantics and so probabilistic programs benefit from automated reasoning in Isabelle/UTP. 
We have used the summations over topological space of real numbers for arithmetic semantics and so probabilistic programs also benefit from mechanised theories in Isabelle/HOL for reasoning. We have enriched the semantics domains from probabilistic distributions to subdistributions and superdistributions in order to use the constructive Kleene fixed point theorem to give semantics to probabilistic loops based on the least fixed point and derive a unique fixed point theorem to largely simplify the reasoning of probabilistic loops. With the formalisation and mechanisation, we have reasoned about six examples of probabilistic programs. 

% Infinite state space
Our fixed point theorems, such as Theorems~\ref{thm:rec_least_fixed_point}, \ref{thm:rec_great_fixed_point}, and \ref{thm:rec_unique} for probabilistic loops, cannot deal with the observation space that has infinite states with positive probabilities. For example, the introduced time variable $t$ for the coin flip as discussed in Sect.~\ref{ssec:cases_coin} will result in countably infinite states with positive probabilities. The restriction is introduced in Theorems~\ref{thm:incseq_limit_is_lub_all} and \ref{thm:decseq_limit_is_glb_all} which are used to prove continuity theorems~\ref{thm:continuity_lfun_bot} and \ref{thm:continuity_lfun_top}, and eventually for the least and greatest fixed point theorms \ref{thm:rec_least_fixed_point} and \ref{thm:rec_great_fixed_point}. Our immediate future work is to extend our fixed point theorem to support such countably infinite state space, which will enable us to give a semantics to such programs and quantify over average termination time. Our approach is to use Cousot's constructive version of the Knasterâ€“Tarski fixed-point theorem~\cite{Cousot1979}, to weaken continuity to monotonicity and treat the least fixed point as the stationary limit of transfinite iteration sequences. 
With this extension, our semantics is able to tackle more general probabilistic programs that have countably infinite state space such as the one- or two-dimensional symmetric random walker, and probabilistic loops with time $t$ (to count loops) in order for the reasoning of distributions over time, such as average termination time. So the coin flip and the die throw examples will be revisited to give new semantics with time and their average termination time will be analysed.

% Continuous distributions
The probabilistic programming we present in this paper only considers discrete probabilistic distributions. One of our future work is to support continuous distributions such as normal or Gaussian distributions, uniform distributions, and exponential distributions, which are naturally presented in many physical systems, in our semantics. In (absolute) continuous distributions, each individual point just has zero probability and so the probability mass functions for discrete distributions could not describe them. Instead, they are described by probability density functions, which requires  measure theory to deal with probabilities and integration~\cite{Dahlqvist2020} over intervals. We, therefore, will introduce measure theory to our semantics and mechanise it in Isabelle/UTP based on the measure theory in Isabelle. After these lines of future work are complete, our probabilistic programming is capable of modelling a wide range of probabilistic systems and reasoning about them automatically. 

% Unification of semantics
With UTP and probabilistic relations, we could bring different approaches to handling uncertainty, such as epistemic mu-calculus and probabilistic synthesis, together and unify these approaches. Our semantics for probabilistic relations are denotational, which could underpin the operational semantics for other approaches. By unifying these theories, we could link different tools. For example, one model could be analysed using our theorem prover, and it could also be transformed to another probabilistic programming language and analysed by the supported tools for it, such as PRISM. This will be beneficial for analysis by leveraging the advantages of different tools.

% Nondeterminism

% Real-time and reactive 
