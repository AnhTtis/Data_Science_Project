\section{Related Work}


{\noindent \bf Generative Models} can roughly be classified into two main branches: GANs and diffusions. 
As the early representatives, GANs~\cite{gan, mirza2014conditional,isola2017image,zhu2017unpaired,karras2019style,brock2018large,karras2020analyzing} have the advantage of generating realistic and diverse data that are similar to the original. They can also learn complex and high-dimensional distributions without explicit density estimation. Such properties allow GANs to enjoy success in image generation~\cite{karras2019style}, image-to-image translation~\cite{zhu2017unpaired,huang2018multimodal,isola2017image}. However, they are hard to train stably. Without careful tuning of hyperparameters, they usually suffer from mode collapse, \ie, only generating a few modes of data distribution. 
In contrast, diffusion models~\cite{sohl2015deep,ddpm,song2019generative,song2020score,dhariwal2021diffusion,nichol2021improved, ddim} have recently broken the long-term dominance of GANs and raised the bar for generative modeling. Compared with GANs, they are friendly for using, without need for adversarial training. Besides, they also achieve state-of-the-art image quality and fidelity on various datasets~\cite{dhariwal2021diffusion}.
Benefited from such advantages, diffusion models have been applied to various generative tasks, such as text-to-image generation~\cite{nichol2021glide, ramesh2022hierarchical, saharia2022photorealistic, ldm}, colorization~\cite{saharia2022palette}, super-resolution~\cite{saharia2022image}, inpainting~\cite{esser2021imagebart, lugmayr2022repaint}, and semantic editing~\cite{choi2021ilvr, meng2021sdedit}.



Nevertheless, all above methods focus on preliminary generation tasks. In this paper, we explore the significance of generative pre-training models for discriminative tasks. The insight is that generative models are pre-trained to contain both low-level knowledge and high-level semantic relations.
Among all generative models, we choose diffusion models as representatives, for their impressive performance.













\begin{figure*}[t]
    \centering
    \vspace{-0.2cm}
    \includegraphics[width=0.97\textwidth]{sec/image/framework.pdf}
    \vspace{-0.2cm}
    \caption{We use pre-trained diffusion models to synthesize extensive data, helping the model training, then evaluated on real images. 
    \textbf{(1) The Synthesis Stage.} We synthesize free image-mask pairs, where mask generation is solved leveraging cross- and self- attention by AttentionCut.
    \textbf{(2) The Exploitation Stage.} We extract knowledge 
    using diffusion inversion, then only one lightweight decoder is trained for object discovery on synthetic data.
    } 
    \label{fig:framework}
\end{figure*}




\vspace{0.2cm}
{\noindent \bf Object Discovery} aims at detecting and segmenting salient objects in the natural scenes, consisting of two popular sub-tasks: saliency segmentation and object localization. 
Existing methods have two settings: supervised and unsupervised.
The supervised methods~\cite{hou2016deeply, zhao2019pyramid, qin2020u2, yun2022selfreformer} are trained with large-scale pixel-level human annotations, which are time-consuming and expensive to acquire. 


By contrast, the unsupervised setting without any labor labels, has received increasing attentions. Concretely, most methods embrace discriminative-based pre-trained models for help. 
LOST~\cite{lost}, Deep Spectral~\cite{MelasKyriazi2022DeepSM}, and TokenCut~\cite{tokencut} leverage features from self-supervised ViTs~\cite{dino} with contrastive learning~\cite{ouali2020autoregressive, ji2019invariant, ju2023constraint, ju2022adaptive} that exhibit object segmentation potential, after which a heuristic strategy or a graph-based method~\cite{shi2000normalized} is employed. SelfMask~\cite{selfmask} revisits the spectral clustering on image features from various self-supervised models, \eg, MoCo~\cite{moco}, SwAV~\cite{caron2020unsupervised}, DINO~\cite{dino}, to obtain pseudo-labels, which are then used to train one salient object detector.
FreeSOLO~\cite{Wang2022FreeSOLOLT} proposes to generate correlation maps which are then ranked and filtered by maskness scores. 
DINOSAUR~\cite{seitzer2022bridging} reconstructs features from self-supervised models for object-centric representations. Different with all above methods only using discriminative pre-training, this paper proves that generative-based pre-training is also or even more valuable for mainstream discriminative tasks, by a synthesis-exploitation strategy.












































