%\section{Methods}
\section{2D RNNs}
\label{sec:2DRNN}

Our main aim is to study topological properties of Hamiltonians using an RNN wave function ansatz. Since the quantum systems we study are stoquastic~\cite{bravyi2015monte}, we consider an ansatz with positive amplitudes to model the ground state wave function~\cite{RNNWF}. Complex extensions of RNN wave functions for non-stoquastic Hamiltonians have been explored in Refs.~\cite{RNNWF, roth2020iterative}. To model a positive RNN wave function, we write our ansatz in the computational basis as:
\begin{equation*}
   \Psi_{\bm{\theta}}(\bm{\sigma}) = \sqrt{p_{\bm{\theta}}(\bm{\sigma})},
\end{equation*}
where $\bm{\theta}$ denotes the variational parameters of the ansatz $\ket{\Psi_{\bm{\theta}}}$, and $\bm{\sigma} = (\sigma_1, \sigma_2, \ldots, \sigma_N)$ is a basis state configuration. A key characteristic of the RNN wave function is its ability to estimate observables with uncorrelated samples through autoregressive sampling~\cite{RNNWF, Ferris_2012}. This is achieved by parameterizing the joint probability $p_{\bm{\theta}}(\bm{\sigma})$ with its conditionals $p_{\bm{\theta}}(\sigma_i | \sigma_{<i})$, through the probability chain rule
\begin{equation*}
    p_{\bm{\theta}}(\bm{ \sigma})= p_{\bm{\theta}}(\sigma_1)p_{\bm{\theta}}(\sigma_2|\sigma_1) \cdots p_{\bm{\theta}}(\sigma_N|\sigma_{N-1}, \dots, \sigma_2, \sigma_1).
\end{equation*}
The conditionals are given by
\begin{equation*}
    p_{\bm{\theta}}(\sigma_i | \sigma_{<i}) = \bm{y}_i \cdot \bm{\sigma}_i,
\end{equation*}
where $\bm{y}_i = \text{Softmax}(U \bm{h}_{i} + \bm{c})$ and `$\cdot$' is the dot product operation. The hidden state $\bm{h}_{i}$ is calculated recursively as~\cite{lipton2015}
\begin{equation}
    \bm{h}_{i} = f\!(W [\bm{\sigma}_{i-1};\bm{h}_{i-1}] + \bm{b}),
    \label{eq:1DRNN}
\end{equation}
where the input $\bm{\sigma}_{i-1}$ is a one-hot encoding of $\sigma_{i-1}$ and the symbol $[. ; .]$ corresponds to the concatenation of two vectors. Furthermore, $U, W, \bm{b}$, and $\bm{c}$ are learnable weights and biases and $f$ is an activation function. The sequential operation of the RNN is shown in  Fig.~\ref{fig:RNN}(a), where the RNN cell, i.e., the recurrent relation in Eq.~\eqref{eq:1DRNN}, is depicted as blue square. As each of the conditionals $p_{\bm{\theta}}(\sigma_i | \sigma_{<i})$~\cite{RNNWF} is normalized, the distribution $p_{\bm{\theta}}$, and thus the quantum state $|\Psi_{\bm{\theta}}\rangle$, are normalized. Notably, by virtue of the sequential structure built into the RNN ansatz, it is possible to obtain exact samples from $p_{\bm{\theta}}$ by sampling the conditionals $p_{\bm{\theta}}(\sigma_i | \sigma_{<i})$ sequentially as illustrated in Fig.~\ref{fig:RNN}(b). The sampling scheme is parallelizable and can produce fully uncorrelated samples distributed according to $p_{\bm{\theta}}$ without the use of potentially slow Markov chains~\cite{RNNWF, roth2020iterative}.

As our aim is to study 2D quantum systems with periodic boundary conditions, we use 2D RNNs~\cite{graves2007multidimensional, RNNWF}, through the modification of the 1D relation in Eq.~\eqref{eq:1DRNN} to a recursion that encodes the 2D geometry of the lattice, i.e.,
\begin{align}
    \bm{h}_{i,j} &= f\! \Big(
    W[\bm{\sigma}_{i-1,j} ; \bm{\sigma}_{i,j-1}; \bm{\sigma}_{\text{mod}(i+1,L_x),j}; \bm{\sigma}_{i,\text{mod}(j+1, L_y)}; \nonumber\\
    &\bm{h}_{i-1,j} ; \bm{h}_{i,j-1}; \bm{h}_{\text{mod}(i+1,L_x),j}; \bm{h}_{i,\text{mod}(j+1, L_y)}]
    +  \bm{b} \Big).
    \label{eq:2DPRNN}
\end{align}
$L_x, L_y$ are respectively the width and the length of the 2D lattice. In our study, we choose $L_x = L_y = L$. Additionally, $\bm{h}_{i,j}$ is a hidden state with two indices for each site in the 2D lattice, which is computed based on the inputs and the hidden states of the nearest neighbouring sites. Since $\bm{h}_{i,j}$ contains information about of the history of generated variables $\sigma_{i,j}$, it can be used to compute the conditionals
\begin{equation}
    p_{\bm{\theta}}(\sigma_{i,j}| \sigma_{<i,j}) = \text{Softmax}(U \bm{h}_{i,j} + \bm{c}) \cdot \bm{\sigma}_{i,j}.
    \label{eq:prob_softmax}
\end{equation}
The additional variables $\bm{\sigma}_{\text{mod}(i+1,L_x),j}$, $\bm{\sigma}_{i,\text{mod}(j+1, L_y)}$ and hidden states $\bm{h}_{\text{mod}(i+1,L_x),j}$, $\bm{h}_{i,\text{mod}(j+1, L_y)}$ allows to model systems with periodic boundary conditions such that the ansatz accounts for the correlations between physical degrees of freedom across the boundaries. This approach has been also suggested and implemented in Ref.~\cite{luo2021gauge}. We note that during the process of autoregressive sampling, if either of the input vectors, in Eq.~\eqref{eq:2DPRNN}, have not been encountered yet, we initialize them to a null vector so that we preserve the autoregressive nature of the RNN wave function, as illustrated in Fig.~\ref{fig:RNN}(b). Furthermore, Fig.~\ref{fig:RNN}(c) illustrates the autoregressive sampling path in 2D as well as how information is being transferred among RNN cells. Importantly, we use an advanced version of 2D RNNs which incorporates a gating mechanism as previously done in Refs.~\cite{RNNWF, Vieijra2021, luo2021gauge, RNNAnnealing}. Additional details can be found in Appendix.~\ref{app:GRU}. We also note that implementing lattice symmetries in our RNN ansatz can be done to improve the variational accuracy as shown in Refs.~\cite{RNNWF,RNNAnnealing}, however we do not pursue this direction in our study. 

\begin{figure*}
    \centering
    \includegraphics[width =\linewidth]{figs/RNN.pdf}
    \caption{(a) An illustration of the positive RNN wave function. Each RNN cell (blue squares) receives  an input $\bm{\sigma}_{n-1}$ and a hidden state $\bm{h}_{n-1}$ and outputs a new hidden state $\bm{h}_n$. The latter is fed to a Softmax layer (denoted by S, red circle) that outputs a conditional probability $P_i$ (orange circle). The conditional probabilities are multiplied after taking a square root to obtain the wave function $\Psi_{\bm{\theta}}(\boldsymbol{\sigma}) $ (pink circle). (b) Illustration of the sampling scheme for an RNN wave function. After obtaining the probability vector $\bm{y}_i$ from the Softmax layer (S) at step $i$, we sample it to produce $\bm{\sigma}_i$ which is fed again to the RNN with the hidden state $\bm{h}_i$ to produce the next configuration $\bm{\sigma}_{i+1}$.(c) A 2D RNN with periodic boundary conditions. A bulk RNN cell receives two hidden states $\bm{h}_{i,j-1}$ and $\bm{h}_{i-1,j}$, as well as two input vectors $\bm{\sigma}_{i,j-1}$ and $\bm{\sigma}_{i-1,j}$ (not shown) illustrated by the black solid arrows. To handle periodic boundary conditions, RNN cells at the boundary receive  an additional $\bm{h}_{i,\text{mod}(j+1,L_y)}$ and $\bm{h}_{\text{mod}(i+1,L_x),j}$, as well as two input vectors $\bm{\sigma}_{i,\text{mod}(j+1,L_y)}$ and $\bm{\sigma}_{\text{mod}(i+1,L_x),j}$ (not shown) illustrated by green solid arrows. The sampling path is illustrated with red dashed arrows. The initial memory state $\bm{h}_0$ of the 2D RNN and the initial inputs $\bm{\sigma}_0$ (not shown) are taken as null vectors.}
    \label{fig:RNN}
\end{figure*}

\subsection{Supplementing RNNs optimization with annealing}
\label{sec:annealing}
To train the parameters of the RNN, we minimize the energy expectation value $E_{\bm{\theta}} = \bra{\Psi_{\bm{\theta}}} \hat{H}\ket{\Psi_{\bm{\theta}}}$ using Variational Monte Carlo (VMC)~\cite{becca_sorella_2017}, where $\hat{H}$ is a Hamiltonian of interest. In the presence of local minima in the optimization landscape of $E_{\bm{\theta}}$, the VMC optimization may get stuck in a poor local optimum~\cite{VNA2021, Bukov_2021}. To ameliorate this limitation, we supplement the VMC scheme with a pseudo-entropy whose objective is to help the optimization escape local minima~\cite{roth2020iterative, VNA2021, RNNAnnealing, Roth2022, Khandoker_2023}. The new objective function is defined as
\begin{equation}
    F_{\bm{\theta}}(n) = E_{\bm{\theta}} - T(n) S_{\rm classical} ( p_{\bm{\theta}} ),
    \label{eq:FreeEnergy}
\end{equation}
where $F_{\bm{\theta}}$ is a variational pseudo-free energy. The Shannon entropy $S_{\rm classical}$ of $p_{\boldsymbol{\theta}}\left(\boldsymbol{\sigma}\right)$ is given by
\begin{equation}
    S_{\rm classical} (p_{\bm{\theta}}) = - \sum_{\bm{\sigma}} p_{\bm{\theta}}(\bm{\sigma}) \ln\left(p_{\bm{\theta}}(\bm{\sigma})\right),
    \label{eq:vnEntropy}
\end{equation}
where the sum goes over all possible configurations $\{\bm{\sigma}\}$ in the computational basis. The pseudo-entropy $S_{\rm classical}$ and its gradients are  evaluated through sampling the RNN wave function. Furthermore $T(n)$ is a pseudo-temperature that is annealed from some initial value $T_0$ to zero as follows: $T(n) = T_0 (1-n/N_{\rm annealing})$ where $n \in [ 0, N_{\rm annealing} ]$ and $N_{\rm annealing}$ is the total number of annealing steps. This scheme is inspired from the regularized variational quantum annealing scheme in Refs.~\cite{roth2020iterative, VNA2021, RNNAnnealing}. More details about our training scheme are given in Appendix.~\ref{app:VMC}. We also provide the hyperparameters in Appendix.~\ref{app:hyperparams}.

\subsection{Topological entanglement entropy}
\label{sec:TEE}

A powerful tool to probe topologically ordered states of matter is through the so-called topological entanglement entropy (TEE)~\cite{Hamma2004,Hamma2005,LevinWen2006,KitaevPreskill2006, Hamma2009, Quasiparticle2012, TEE2011, TEE2017,kimUniversalLowerBound2023}. The TEE can be extracted by computing the entanglement entropy of a spatial bipartition of the system into $A$ and $B$, which together comprise the full system. For many phases of 2D matter, the Renyi-$n$ entropy $S_n(A) \equiv \frac{1}{1-n} \ln(\text{Tr}(\rho^n_A))$ satisfies the area law $S_n(A) = aL - \gamma + \mathcal{O}(L^{-1})$. Here $L$ is the size of boundary between $A$ and $B$, $\rho_A=\text{Tr}_B |\Psi \rangle \langle \Psi |$  is the reduced density matrix of subsystem $A$, $|\Psi\rangle$ is the state of the system, and $\gamma$ is the TEE. The latter detects non-local correlations in the ground state wave function and plays the role of an order parameter for topological phases similar to the notion of a local order parameter in phases displaying long-range order. Interestingly, a measure of specific non-zero values of $\gamma$ can be a clear signature of the existence of a topological order in a system of interest. Additionally, since the TEE is shown to be independent of the choice of Renyi index $n$ for a contractible region $A$~\cite{Hamma2009}, we can use the swap trick~\cite{EE2010} with our RNN wave function ansatz~\cite{RNNWF, EE2020} to calculate the second Renyi entropy $S_2$ and extract the TEE $\gamma$. 

To access the TEE $\gamma$, we can approximate the ground state of the system using an RNN wave function ansatz, i.e. $|\Psi_{\boldsymbol{\theta}}\rangle\approx |\Psi\rangle$ for different system sizes followed by a finite-size scaling analysis of the second Renyi entropy. We can also make use of a TEE construction, e.g., the Kitaev-Preskill construction~\cite{KitaevPreskill2006}.
\begin{figure}
    \centering
    \includegraphics[width =0.5\linewidth]{figs/TEE_constructions.pdf}
    \caption{A sketch of the parts $A$, $B$ and $C$ that we use for Kitaev-Preskill construction to compute the TEE in a system of interest.}
    \label{fig:TEE_constructions}
\end{figure}

The Kitaev-Preskill construction prescribes dividing the system into four subregions $A$, $B$, $C$ and $D$ as illustrated in Fig.~\ref{fig:TEE_constructions}. The TEE can be then obtained by computing
\begin{align*}
    \gamma &= -S_2(A)-S_2(B)-S_2(C)+S_2(AB)\\
    &+S_2(AC)+S_2(BC) - S_2(ABC),
\end{align*}
where $S_2(A)$ is the second Renyi entropy of the subsystem $A$, and $AB$ is the union of $A$ and $B$ and similarly for the other terms. Finite-size effects on $\gamma$ can be alleviated by increasing the size of the subregions $A, B$ and $C$~\cite{KitaevPreskill2006, Furukawa2007}. Finally, we highlight the ability of the RNN wave function to study systems with fully periodic boundary conditions as a strategy to mitigate boundary effects, as opposed to cylinders used in DMRG~\cite{Stoudenmire2012,Cylinders2014}, which may potentially introduce edge effects that can affect the values of the TEE~\cite{RydbergHarvard2021}.  