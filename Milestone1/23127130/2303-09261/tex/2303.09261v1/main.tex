
%\documentclass[anon,12pt]{colt2023} % Anonymized submission
\documentclass[final,12pt]{colt2023} % Include author names

\input{shortcuts.sty}
\usepackage{comment}
\usepackage{mathrsfs}
\usepackage{amssymb,amsmath,ntheorem,ifthen,amsfonts}
\usepackage{wrapfig}

% not sure how you denote the transpose --- feel free to modify
\newcommand{\TT}{\ensuremath{\mathsf{\tiny{T}}}}
\newcommand{\T}{^{\TT}}% define transpose

\newcommand{\eric}[1]{\textcolor{green}{#1}}
\newcommand{\sho}[1]{{\color{red}[SS] #1}}
\newcommand{\dan}[1]{{\color{red}[Daniil] #1}}
%\newtheorem{assumption}{A\hspace{-2pt}}
\newcommand{\tcr}[1]{\textcolor{red}{#1}}
\usepackage{cleveref,aliascnt}
\renewtheorem{theorem}{Theorem}
\crefname{theorem}{theorem}{Theorems}
\Crefname{Theorem}{Theorem}{Theorems}


\newaliascnt{lemma}{theorem}
\renewtheorem{lemma}[lemma]{Lemma}
\aliascntresetthe{lemma}
\crefname{lemma}{lemma}{lemmas}
\Crefname{Lemma}{Lemma}{Lemmas}

\newaliascnt{corollary}{theorem}
\renewtheorem{corollary}[corollary]{Corollary}
\aliascntresetthe{corollary}
\crefname{corollary}{corollary}{corollaries}
\Crefname{Corollary}{Corollary}{Corollaries}

\newaliascnt{proposition}{theorem}
\renewtheorem{proposition}[proposition]{Proposition}
\aliascntresetthe{proposition}
\crefname{proposition}{proposition}{propositions}
\Crefname{Proposition}{Proposition}{Propositions}

\newaliascnt{definition}{theorem}
\renewtheorem{definition}[definition]{Definition}
\aliascntresetthe{definition}
\crefname{definition}{definition}{definitions}
\Crefname{Definition}{Definition}{Definitions}




\newaliascnt{remark}{theorem}
\renewtheorem{remark}[remark]{Remark}
\aliascntresetthe{remark}
\crefname{remark}{remark}{remarks}
\Crefname{Remark}{Remark}{Remarks}


\renewtheorem{example}{Example}
\crefname{example}{example}{examples}
\Crefname{Example}{Example}{Examples}


\crefname{figure}{figure}{figures}
\Crefname{Figure}{Figure}{Figures}


\newtheorem{assumption}{\textbf{A}\hspace{-3pt}}
\Crefname{assumption}{\textbf{A}\hspace{-3pt}}{\textbf{A}\hspace{-3pt}}
\crefname{assumption}{\textbf{A}}{\textbf{A}}

\title[Orthogonal Directions Constrained Gradient Method]{Orthogonal Directions Constrained Gradient Method: from non-linear equality constraints to Stiefel manifold}
\usepackage{times}
% Near-optimal gradient-based infeasible method for non-convex optimization on a smooth manifold.
% Use \Name{Author Name} to specify the name.
% If the surname contains spaces, enclose the surname
% in braces, e.g. \Name{John {Smith Jones}} similarly
% if the name has a "von" part, e.g \Name{Jane {de Winter}}.
% If the first letter in the forenames is a diacritic
% enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

% Two authors with the same address
% \coltauthor{\Name{Author Name1} \Email{abc@sample.com}\and
%  \Name{Author Name2} \Email{xyz@sample.com}\\
%  \addr Address}

% Three or more authors with the same address:
% \coltauthor{\Name{Author Name1} \Email{an1@sample.com}\\
%  \Name{Author Name2} \Email{an2@sample.com}\\
%  \Name{Author Name3} \Email{an3@sample.com}\\
%  \addr Address}

% Authors with different addresses:
\coltauthor{%
 \Name{Sholom Schechtman} \Email{sholom.schechtman@telecom-sudparis.eu}\\
 \addr CMAP, SAMOVAR, Télécom Sudparis, Institut Polytechnique de Paris, 91120 Palaiseau, France
 \AND
 \Name{Daniil Tiapkin} \Email{dtyapkin@hse.ru}\\
 \addr HSE University, Pokrovsky Blvd, 11, Moscow, Russia, 109028%
 \AND
 \Name{Michael Muehlebach} \Email{michaelm@tuebingen.mpg.de} \\
 \addr{Max Planck Ring 4, 72076 Tuebingen, Germany}
 \AND
 \Name{{\'E}ric Moulines} \Email{eric.moulines@polytechnique.edu}\\
 \addr CMAP, {\'E}cole Polytechnique, Route de Saclay, 91128, Palaiseau
}

\begin{document}

\maketitle

\begin{abstract}
We consider the problem of minimizing a non-convex function over a smooth manifold $\cM$. We propose a novel algorithm, the \emph{Orthogonal Directions Constrained Gradient Method} (\algo)  which only requires computing  a projection onto a vector space. \algo\ is infeasible but the iterates are constantly pulled towards the manifold, ensuring the convergence of \algo\ towards $\cM$. 
\algo\ is much simpler to implement than the classical methods which require the computation of a retraction.  Moreover, we show that \algo\ exhibits the  near-optimal oracle complexities $\cO(1/\varepsilon^2)$ and $\cO(1/\varepsilon^4)$ in the deterministic and stochastic cases, respectively. Furthermore, we establish that, under an appropriate choice of the projection metric, our method recovers the \texttt{landing} algorithm of \citet{ablin2022fast}, a recently introduced algorithm for optimization over the Stiefel manifold. As a result, we significantly extend the analysis of \citet{ablin2022fast}, establishing near-optimal rates both in deterministic and stochastic frameworks. Finally, we perform numerical experiments which shows the efficiency of \algo\ in a high-dimensional setting.
%ace the commonly used retraction-based methods are often computationally intensive, in this paper, inspired by the recent work of \cite{muehlebach2022constraints}, we develop an infeasible method that avoids retractions but where the iterates are constantly pulled onto the manifold. An oracle of the proposed \emph{Orthogonal Directions Constrained Gradient Method} (\algo), requires to compute at most a projection onto a vector space (of the same dimension as the manifold) and has the same near-optimal $\cO(1/\varepsilon^2)$ oracle complexity as the projected gradient method. We also determine the rates in the stochastic setting, where we achieve a near-optimal $\cO(1/\varepsilon^4)$ oracle complexity. Furthermore, we establish that, under an appropriate choice of the projection metric, our method recovers the landing algorithm of \citet{ablin2022fast}, a recently introduced algorithm for optimization over the Stiefel manifold. As a result, we significantly extend the analysis of \citet{ablin2022fast}, establishing near-optimal rates both in deterministic and stochastic frameworks. Finally, we perform numerical experiments which shows the efficiency of \algo in a high-dimensional setting.

\begin{keywords}%
  constrained optimization, non-convex optimization, Riemannian optimization, stochastic optimization, Stiefel manifold
\end{keywords}
\end{abstract}




\input{intro}
\input{prel}


\input{main_res}
\input{comp_cheap}
\input{stiefel}
\input{numerics}
\input{conclusion}

\clearpage
\newpage


\bibliography{math}

\clearpage
\newpage
\appendix
\input{appendix_numerics}
\input{proof_main}
\input{proof_reduced}
\input{proof_stiefel}
\end{document}
