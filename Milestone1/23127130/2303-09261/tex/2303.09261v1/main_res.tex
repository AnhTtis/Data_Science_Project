
 \section{Main results}\label{sec:Main}
 \subsection{Continuous-time flow}\label{subsec:cont_time}
 In this section, we analyze the ordinary differential equation $\dot{\sx}(t) = \OF(\sx(t))$.  In all the remainder, we fix $r_1 >0$ and $K \subset \bbR^{n}$ with $ K = \{ x \in \bbR^n : \norm{h(x)} \leq r_1\}$.
Consider the following assumption:
 \begin{assumption}\label{hyp:cont_model}
   \begin{enumerate}[label=\roman*), nosep,leftmargin=15pt]
     \item\label{hyp:k_comp} The set $K$ is compact and $\nabla h$ is of full rank on $K$.
     \item\label{hyp:k_fullr}  It holds that $\nabla h^{\top} \nabla h A \in \bbR^{n_h \times n_h}$ is symmetric positive definite on $K$.
     \item\label{hyp:A_loclip} The function $A : K \rightarrow \bbR^{n_h \times n_h}$ can be extended to a locally Lipschitz continuous function on some neighborhood of $K$.
     \item\label{hyp:hA_eigenv}  There is $\alpha_m >0$ such that  $\inf_{x \in K} \lambda_m(x) > \alpha_m$, where $\lambda_m(x)$ is the minimal eigenvalue of $\nabla h^{\top}(x) \nabla h(x) A(x)$
   \end{enumerate}
 \end{assumption}
Note that as soon as $\cM$ is compact, there is always some $r_1 > 0$ such that \Cref{hyp:cont_model}-\ref{hyp:k_comp} holds. Moreover, \Cref{hyp:cont_model}-\ref{hyp:k_fullr}--\ref{hyp:A_loclip} are satisfied for the matrices $A$ given in~\Cref{ex:vanil,ex:mj_flow}.   As is often the case, to analyze the trajectory of an ordinary differential equation we need to find an energy (or Lyapunov) function. For $M > 0$, we define $\Lambda_M :\bbR^{n} \rightarrow \bbR$ as:
\begin{equation}\label{eq:def_LambdaM} \Lambda_M = f + M \norm{h} \, .
\end{equation}
The following theorem is our first main result, it shows that for $M$ large enough, $\Lambda_M$ decreases along any trajectory. This observation immediately implies the convergence of any bounded trajectory to the set of critical points. 
\begin{theorem}\label{th:cont_time}
  Assume \Cref{hyp:cont_model}.
  For any $x_0$ such that $\norm{h(x_0)} \leq r_1$ there is $\sx:\bbR_{+} \rightarrow \bbR^n$ a unique solution to 
  \begin{equation}
      \label{eq:orth_flow}
      \dot{\sx}(t) = \OF(\sx(t))
  \end{equation}
  starting at $x_0$. In addition, it holds that:
  \begin{enumerate}[nosep]
    \item For any $t \geq 0$, $\norm{h(\sx(t))} \leq \rme^{-\alpha_m t} \norm{h(x_0)}$,  where $\alpha_m$ is defined in \Cref{hyp:cont_model}-\ref{hyp:hA_eigenv}.
  \item For all $M \geq \overline{M}= M_1/\alpha_m$, with $M_1 = \sup_{x \in K} \norm{A^{\top} \nabla h^{\top}(\nabla f - \nabla h A h)}$, we get
  \begin{equation*}
    \inf_{0 \leq t \leq T} \norm{\OF(\sx(t))}^2= \inf_{0 \leq t \leq T} \norm{\dot{\sx}(t)}^2 \leq \frac{1}{T} \int_{0}^{T} \norm{\dot{\sx}(t)}^2 \rmd t \leq \frac{\Lambda_{M}(\sx(0)) - \Lambda_{M}(\sx(T))}{T} \, .
  \end{equation*}
  \item Let $x^*$ be in the limit set of $\sx$, i.e. there is $t_n \rightarrow + \infty$ such that $\sx(t_n) \rightarrow x^*$. Then $x^*$ is a critical point of \eqref{eq:main_opt_prob}.
  \end{enumerate}
\end{theorem}

\begin{proof}
 The existence and uniqueness of a local solution of \eqref{eq:orth_flow} follows from the fact that $\OF$ is locally Lipschitz continuous. As we shall see, such a solution must lie in $K$, which is compact by \Cref{hyp:cont_model}. This implies that the domain of a local solution can be extended to $\bbR_{+}$. Indeed, let $\sx$ be such a solution. Since for all $v \in V$, it holds that $\nabla h^{\top} v = 0$, we get using \Cref{hyp:cont_model}-\ref{hyp:hA_eigenv}:
\begin{equation}\label{eq:h_decrease_intm}
\frac{\dif}{ \dif t} \norm{h(\sx)}^2 = - 2 h^{\top}(\sx) \nabla h^{\top}(\sx) \nabla h(\sx) A(\sx) h(\sx)  \leq -2 \alpha_m \norm{h(\sx)}^2 \, ,
\end{equation}
 and GrÃ¶nwall's lemma implies that $\norm{h(\sx(t))} \leq \rme^{-\alpha_m t} \norm{h(\sx(0))} $, for $t \geq 0$.
 Therefore, any local solution stays away from the boundary of $K$ and can be extended to a global solution for which the first claim holds. We now prove the second claim. Denote $D_h = (\nabla h^{\top} \nabla h)^{-1}$. In order to simplify the notations we omit the dependence on $x$ (see Lemma~\ref{lm:aff_proj}), and get
\begin{equation}\label{eq:interm_OFA}
\OF= - \nabla f +  \nabla h \left(  D_h \nabla h^{\top} \nabla f - A h \right)  \, ,
\end{equation}
where $D_h := (\nabla h^{\top} \nabla h)^{-1}$. This implies $\nabla h^{\top} \OF = - \nabla h^{\top} \nabla hA h$. Therefore, we have
\begin{align}\label{eq:err_f}
    \begin{split}
      \norm{(\OF + \nabla f)^{\top} \OF} &= \norm{\left(  D_h\nabla h^{\top} \nabla f - A h \right)^{\top} \nabla h^{\top} \OF}
      \\
      &\leq \norm{ h^{\top} A^{\top} \nabla h^{\top} \nabla h Ah - \nabla f^{\top} \nabla h A h}  \leq M_1 \norm{h} \, .
    \end{split}
\end{align}
Finally, if $\sx \not \in \cM$, we have
\begin{equation}\label{eq:f_decrease}
  \frac{\dif}{\dif t}f(\sx) = \nabla f(\sx)^{\top} \dot{\sx} = - \norm{\dot{\sx}}^2 + (\dot{\sx} + \nabla f(\sx))^{\top}\dot{\sx}(t) \leq - \norm{\dot{\sx}}^2 + M_1 \norm{h(\sx)} \, .
\end{equation}
Therefore, using~\eqref{eq:h_decrease_intm} and \eqref{eq:f_decrease} we obtain
\begin{equation}\label{eq:strict_lyap}
  \frac{\dif}{\dif t} \Lambda_M(\sx) \leq - \norm{\dot{\sx}}^2  \leq - \norm{\nabla_{V}f(\sx)}^2\, ,
\end{equation}
where the last inequality comes from the fact that the projection of $\dot{\sx}(t)$ onto $V$ is  $\nabla_V f$.
Integrating the last inequality we obtain the second claim for $\sx$.

To establish the third claim, we notice that $\OF \neq 0$ as soon as $x \notin \cM$ or $x \in \cM$ and $\Grad (f) \neq 0$. Equation~\eqref{eq:strict_lyap} then shows that $\Lambda_M$ is a strict Lyapunov function for the ODE~\eqref{eq:orth_flow} and the set of critical points of \eqref{eq:main_opt_prob}. In particular, LaSalle's invariance principle (see e.g. \cite[Theorem 2.17]{har_dynsyst91}) then implies that any limit point of $\sx$ must be contained in the set of critical points of \eqref{eq:main_opt_prob}.
\end{proof}
\vspace{-10pt}
\subsection{Algorithm}\label{sec:det_alg}
In this section we analyze the algorithms provided by the discretization of ODE~\eqref{eq:orth_flow} both in the deterministic and stochastic settings.
  Consider a filtered probability space $(\Omega, \mcF, \{\mcF_k, k >0\},  \bbP)$. Fix $x_0 \in K$ and let $(\eta_{k})_{k \geq 1}$ be a sequence of random variables adapted to $(\mcF_k)$. Our method, \algo, produces iterates as follows:
 \begin{equation}\label{eq:orth_alg}
     x_{k+1} = x_k + \gamma_k v_k + \gamma_k \eta_{k+1} , \quad{} \textrm{ with } v_k = \OF(x_k)
 \end{equation} 
 and with $(\gamma_k)$ a sequence of positive step sizes. The perturbation $(\eta_k)$ allows to capture the case where $\nabla f(x)$ (and hence $\nabla_V f(x)$) is unknown. This covers both streaming data and finite-sum problems in machine learning; see \citep{lan2020first}.
Recall that $\bbE_k$ denotes the conditional expectation given $\mcF_k$ and consider the following assumptions.
\begin{assumption}\label{hyp:disc_model}
\begin{enumerate}[label=\roman*), nosep]
    \item\label{hyp:fh_Lipgrad}The function $f$ (respectively $h$) has $L_f$ (respectively $L_h$) Lipschitz gradients on $K$.
    \item\label{hyp:iter_bound}The iterates $(x_k)$ remain in $K$, $\bbP$-almost surely.
    \item\label{hyp:zer_mean} For every $k \in \bbN$, it holds that $\eta_{k+1} \in V(x_k)$ and $\bbE_k[\eta_{k+1}] = 0$.
    \item\label{hyp:var_bound} There is a constant $\sigma \geq 0$ such that for all $k \in \bbN$, $\bbE_k[\norm{\eta_{k+1}}^2] \leq \sigma^2$.
\end{enumerate}
\end{assumption}
 \begin{example}\label{ex:SA}
 In the stochastic approximation framework, it is assumed that there is a probability space $(\Xi, \mcT, \mu)$ and a $\mu$-integrable function $g: \bbR^n \times \Xi \rightarrow \bbR^n$ such that for each $x \in \bbR^n$, $\int g(x, s) \mu(\rmd s)  = \nabla f(x)$. Let $(\xi_k)_{k \geq 1}$ be a sequence of i.i.d random variables defined on $(\Omega, \mcF, \bbP)$, taking values in $\Xi$ and such that the distribution of $\xi_k$ is $\mu$. We consider the following recursion
 \begin{equation*} 
 x_{k+1} = x_k - \gamma_k \nabla h(x_k) A(x_k) h(x_k) - \gamma_k g_V(x_k, \xi_{k+1}) \, , \end{equation*}
where $g_V(x, \xi)$ denotes the orthogonal projection of $g(x, \xi)$ onto $V(x)$. Thus, if we denote $\eta_{k+1} :=\nabla_V f(x_k) - g_V(x_k, \xi_{k+1})$ and $\mcF_k:= \sigma(\xi_1, \dots, \xi_k)$, we obtain \eqref{eq:orth_alg}. Note also that in this case $\eta_{k+1} \in V(x_k)$, $\bbE_k[\eta_{k+1}] = 0$, and if for some $\sigma >0$, it holds that $\sup_{x \in \bbR^n} \bbE[\norm{g(x,\xi) - \nabla f(x)}^2] \leq \sigma^2$, then $\bbE_k[\norm{\eta_{k+1}}^2] \leq \sigma^2$. 
 \end{example}
The deterministic setting is recovered by setting $\sigma = 0$. If $A$ is defined only on $K$ (see  \Cref{ex:mj_flow}), then \Cref{hyp:disc_model}-\ref{hyp:iter_bound} is required for the recursions to be properly defined. However, for $A$ as in~\Cref{ex:vanil}, this assumption is not needed. Nevertheless, it is necessary for our convergence analysis, and we show in \Cref{proof:safe_step}, that, under mild assumptions, if the step-sizes are small enough \Cref{hyp:disc_model}-\ref{hyp:iter_bound} is automatically satisfied.

The following theorem is the discrete counterpart of \Cref{th:cont_time}. It shows that \algo\ converges to the set of the critical points essentially at the same rate than (unconstrained) gradient descent. 
%Convergence is measured through $\OF$ which is meaningful thanks to Lemma~\ref{lm:OF_crit}.


\begin{theorem}\label{th:gen_rates}
  Assume \Cref{hyp:cont_model}--\ref{hyp:disc_model}. For any $M \geq \overline{M}$, where $\overline{M}$ is defined in \Cref{th:cont_time}, denote $D_M := \Lambda_M(x_0) - \inf_{x \in K} \Lambda_M(x)$ and let $\gamma \leq \gamma_{\max}= \min\left(\alpha_m^{-1}, (L_f + M L_h)^{-1} \right)$. Then, the following holds.
  \begin{enumerate}[nosep,leftmargin=15pt]
      \item If $\sigma = 0$, and for all $k$, $\gamma_k \equiv \gamma$, then:
      \begin{equation}\label{eq:det_rates}
  \inf_{ 0 \leq k \leq N-1}  \norm{\OF(x_k)}^2= \inf_{0\leq k \leq N-1} \norm{v_k}^2 \leq \frac{2 D_M}{N\gamma} \, .
  \end{equation}
   Furthermore, it holds that $\OF(x_k) \rightarrow 0$ and any accumulation point $x^*$ of $(x_k)$ is a critical point of Problem~\eqref{eq:main_opt_prob}.
  \item Otherwise, fix some constant $\bar D >0$, $N >0$ and $\gamma := \min(\gamma_{\max}, \bar D(\sigma \sqrt{N})^{-1})$. If $\gamma_k \equiv \gamma$, and $\hat k$ is uniformly sampled in $\{0, \dots, N-1\}$, then:
  \begin{equation}\label{eq:sto_rate}
  \bbE\left[\norm{\OF(x_{\hat k})}^2\right] \leq \frac{2D_M(L_f + M L_h+ \alpha_m)}{N} + \frac{\sigma}{\sqrt{N}}\left( \bar D (L_f + M L_h) + \frac{2 D_M}{\bar D}\right) \, .
  \end{equation}
  \end{enumerate}
\end{theorem}
\begin{proof}
Using a Taylor expansion of $\Lambda_M$ and using the upper-bound on $\gamma_k$, we obtain
    \begin{equation}\label{eq:rem_decr}
    2\left(\bbE_k[\Lambda_M(x_{k+1})] - \Lambda_M(x_k)\right) \leq - \gamma\norm{v_k}^2 + L_f + M L_h \sigma^2 \gamma^2 \, .
  \end{equation}
  Our claims then follow by telescoping this inequality and applying a standard proof technique (see e.g. \citet[Chapter~6]{lan2020first}) both in the deterministic and stochastic framework. Further details are given in \Cref{proof:gen_rates}.
\end{proof}


The preceding theorem shows that the rate of convergence of our algorithm, measured through $\OF$, is identical to the one obtained by gradient descent in a non-convex framework: $\cO(\varepsilon^{-2})$ in the deterministic setting and $\cO(\varepsilon^{-4})$ in the stochastic setting. As recently shown in \cite{CarmonLowerBF, CarmonLowerBF_sto}, these rates are tight, which makes our algorithm near-optimal in both cases.
  
   The term $(L_f + M L_h)$ in the definition of $\gamma_{\max}$ is  the Lipschitz constant of $\nabla f + M \nabla h$, hence our bound on the step sizes is reminiscent of the $L_f^{-1}$ bound required for convergence of standard gradient descent.
Note also that only an upper bound on $\overline{M}$ is required to achieve such rates. Indeed, in the deterministic setting, we can combine our method with line search; see \Cref{rm:safe_step}.
%below, we can estimate this threshold on the way: We start with one candidate and double it, e.g., if equation~\eqref{eq:rem_decr} is not satisfied (i.e., $\Lambda_M$ does not decrease). In this way, our candidate for the upper bound of $\overline{M}$ is modified only a finite number of times, so our convergence rate is preserved.
In the stochastic framework, performing line search is not an option, but we note that the discussion of \citet[Corollary~2.2.]{gha_lan13} applies here as well. In particular, we can make an error of the order of $\sqrt{N}$ in estimating $(L_f + M L_h)$ while maintaining our rate of convergence of $\cO(\varepsilon^{-4})$. If all constants are known, then the optimal $\overline{D}$ in equation~\eqref{eq:sto_rate} is $\sqrt{2D_M/(L_f + M L_h)}$. Finally, a nonconstant choice of step sizes is possible without affecting the final results; see \cite[Chapter~6]{lan2020first}. The choice of step size is further discussed in \Cref{proof:safe_step}.
%Thanks to the last proposition and remark, we can now made the following assumption.
%\begin{assumption}\label{hyp:iterates_bounded}
 % The iterates $(x_k)$ produced by Algorithm~\eqref{eq:orth_alg} remain in $K$.
%\end{assumption}
