
\section{Limitations and Future Work} \label{sec:discussion}

Despite our best efforts, our research presents several limitations that we are cognizant of.
First, the models that we used for generating captions and VQA answers both have their own biases (many of which we describe in Section~\ref{subsec:bias-multimodal}), which we are unable to control for in our analyses. We aimed to compensate for these by leveraging multiple models and comparing their outputs, as well as by using less symbolic models such as BoVW.
%But in any case, any machine analysis of machine generated content will lack a social grounding through which to analyze such trends due to the fictive nature of the individuals depicted.
Second, while the open nature of the Stable Diffusion models makes us reasonably certain that we did not miss any major confounding factors in our comparative analysis, the same is not true of \DallE. Given that it is only available via an API, we were unable to control for any kind of prompt injection or filtering~\footnote{A blog post from the creators of \DallE in July 2022 stated that they added a technique to improve the diversity of its representations~\cite{dallesafety2022}, with many speculating that it is based on prompt injection~\cite{siddiqui2022metadata,sign-that-spells-offer-22}.}, or indeed whether we were at all prompting the same model on different days. We were therefore only able to compare the output of all three models on the assumption that the images they generate correspond to the model outputs based on the input prompts. %In general, efforts aiming to carry out systematic audits of any ML systems will be hindered both by a lack of access to the internal workings of the systems, making in-depth oversight of proprietary models difficult despite the importance of model auditing for promoting accountability and integrity~\cite{raji2020closing}. 
  %Automatic evaluation of social biases must look beyond commonly used diversity metrics that require assignment to a socially constructed group~\cite{lorber1991social,Jenkins1994RethinkingEI}. 
Third, our analyses are limited to a given set of social attributes in terms of gender and ethnicity, which, as we describe in Section~\ref{sec:methodology}, are attributes that are inherently fluid, multidimensional and non-discretizable. Finally, we recognize that none of the authors of this paper have primary academic 
backgrounds in scientific disciplines relevant to the social science dimensions of gender and ethnicity, and we do not have first-hand experiences for many of the identity characteristics that we refer to. We also recognized our bias towards discrimination axes that are relevant to the Western world, and the importance of extending this analysis to different cultures and different contexts.


We consider our work to be a first step in exploring societal biases in text-to-image models, with much follow up work needed to make this work more complete and nuanced. An important part of this work would be to keep exploring different dimensions and aspects of social bias, including age and visual markers of religion, as well as other target attributes that are tied to stereotypes and power dynamics. We hope that future work will continue to carefully consider the complex, interconnected nature of many types of biases and the fact that many attributes cannot be inferred visually from generated images. Finally, we believe that there is much potential work to be done in further developing  interactive tools such as those we created to support qualitative analysis and storytelling around the model biases, as well as empowering stakeholders and communities with less technical expertise to engage with and probe TTI systems and other ML artifacts.
% Another aspect that we started exploring in our work but have yet to make meaningful progress upon is the role of random seed selection on the behavior of model behavior and biases. For instance, in the case of open-access models such as Stable Diffusion, by keeping a random seed fixed and changing prompt attributes (such as adjectives), it is possible to carry out model `perturbations' and hone in on the aspects of the image that change and which ones stay fixed. Given the increased usage of these models in many contexts and use cases, we plan on continuing this work in order to better understand the limitations and capabilities of TTI models and the biases that they encode and transmit. 
\clearpage