%%%%%%%%%%%%%%%% Project 3 


%% Learn to Rank examples

@misc{li2020learning,
      title={Learning to Rank for Active Learning: A Listwise Approach}, 
      author={Minghan Li and Xialei Liu and Joost van de Weijer and Bogdan Raducanu},
      year={2020},
      eprint={2008.00078},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}



%% Textbooks

@book{pml1Book,
 author = "Kevin P. Murphy",
 title = "Probabilistic Machine Learning: An introduction",
 publisher = "MIT Press",
 year = 2022,
 url = "probml.ai"
}



@book{bonferroni1936teoria,
  title={Teoria statistica delle classi e calcolo delle probabilit{\`a}},
  author={Bonferroni, C.E.},
  series={Pubblicazioni del R. Istituto superiore di scienze economiche e commerciali di Firenze},
  url={https://books.google.co.uk/books?id=3CY-HQAACAAJ},
  year={1936},
  publisher={Seeber}
}



%% Our Paper 
@misc{ThomasW23,
  doi = {10.48550/ARXIV.2301.00790},
  url = {https://arxiv.org/abs/2301.00790},
  author = {Wong, Thomas and Barahona, Mauricio},
  title = {Robust machine learning pipelines for trading market-neutral stock portfolios},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}


%% Online Mean
@article{WelfordB.P.1962NoaM,
language = {eng},
number = {3},
pages = {419-420},
publisher = {Taylor & Francis Group},
title = {Note on a Method for Calculating Corrected Sums of Squares and Products},
volume = {4},
year = {1962},
author = {Welford, B. P.},
copyright = {Copyright Taylor & Francis Group, LLC 1962},
issn = {0040-1706},
journal = {Technometrics},
}




%% Tools for NN 

@inproceedings{Paszke_PyTorch_An_Imperative_2019,
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
pages = {8024--8035},
publisher = {Curran Associates, Inc.},
title = {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
year = {2019}
}

@software{Abadi_TensorFlow_Large-scale_machine_2015,
author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jozefowicz, Rafal and Jia, Yangqing and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mané, Dan and Schuster, Mike and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viégas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
doi = {10.5281/zenodo.4724125},
license = {Apache-2.0},
month = {11},
title = {{TensorFlow, Large-scale machine learning on heterogeneous systems}},
year = {2015}
}


@inproceedings{blondel2020fast,
  title={Fast differentiable sorting and ranking},
  author={Blondel, Mathieu and Teboul, Olivier and Berthet, Quentin and Djolonga, Josip},
  booktitle={International Conference on Machine Learning},
  pages={950--959},
  year={2020},
  organization={PMLR}
}


@software{Falcon_PyTorch_Lightning_2019,
author = {Falcon, William and {The PyTorch Lightning team}},
doi = {10.5281/zenodo.3828935},
license = {Apache-2.0},
month = {3},
title = {{PyTorch Lightning}},
url = {https://github.com/Lightning-AI/lightning},
version = {1.4},
year = {2019}
}



%% Sparse MLP
@software{SparseLinear,
  author = {Hyeonwoo Daniel Yoo},
  month = {12},
  title = {{SparseLinear}},
  url = {https://github.com/hyeon95y/SparseLinear},
  version = {0.0.5},
  year = {2020}
}



@article{Zimmer_Auto-PyTorch_Tabular_Multi-Fidelity_2021,
author = {Zimmer, Lucas and Lindauer, Marius and Hutter, Frank},
doi = {10.1109/TPAMI.2021.3067763},
pages = {3079--3090},
title = {{Auto-PyTorch Tabular: Multi-Fidelity MetaLearning for Efficient and Robust AutoDL}},
year = {2021}
}





%% Random matrix Theory 
@book{tao2012topics,
  title={Topics in random matrix theory},
  author={Tao, Terence},
  volume={132},
  year={2012},
  publisher={American Mathematical Soc.}
}



%% Review on TS modelling 
@article{lim2021time,
  title={Time-series forecasting with deep learning: a survey},
  author={Lim, Bryan and Zohren, Stefan},
  journal={Philosophical Transactions of the Royal Society A},
  volume={379},
  number={2194},
  pages={20200209},
  year={2021},
  publisher={The Royal Society Publishing}
}

@article{torres2021deep,
  title={Deep learning for time series forecasting: a survey},
  author={Torres, Jos{\'e} F and Hadjout, Dalil and Sebaa, Abderrazak and Mart{\'\i}nez-{\'A}lvarez, Francisco and Troncoso, Alicia},
  journal={Big Data},
  volume={9},
  number={1},
  pages={3--21},
  year={2021},
  publisher={Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New~…}
}




%%% Double deep descent 
@article{NakkiranPreetum2021Dddw,
issn = {1742-5468},
journal = {Journal of statistical mechanics},
language = {eng},
number = {12},
pages = {124003-},
title = {Deep double descent: where bigger models and more data hurt},
volume = {2021},
year = {2021},
author = {Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
}


@article{belkin2019reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={32},
  pages={15849--15854},
  year={2019},
  publisher={National Acad Sciences}
}

@article{Teresa22,
author = {TeresaHuang, Ningyuan and Hogg, David W. and Villar, Soledad},
title = {Dimensionality Reduction, Regularization, and Generalization in Overparameterized Regressions},
journal = {SIAM Journal on Mathematics of Data Science},
volume = {4},
number = {1},
pages = {126-152},
year = {2022},
doi = {10.1137/20M1387821},
}



@misc{Couto22,
  doi = {10.48550/ARXIV.2211.10322},
  url = {https://arxiv.org/abs/2211.10322},
  author = {Sa-Couto, Luis and Ramos, Jose Miguel and Almeida, Miguel and Wichert, Andreas},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Understanding the double descent curve in Machine Learning},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



%%% Universal approximation theorem 
@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}


@article{ZHOU2020787,
title = {Universality of deep convolutional neural networks},
journal = {Applied and Computational Harmonic Analysis},
volume = {48},
number = {2},
pages = {787-794},
year = {2020},
issn = {1063-5203},
doi = {https://doi.org/10.1016/j.acha.2019.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S1063520318302045},
author = {Ding-Xuan Zhou},
keywords = {Deep learning, Convolutional neural network, Universality, Approximation theory},
}


@inproceedings{schafer2006recurrent,
  title={Recurrent neural networks are universal approximators},
  author={Sch{\"a}fer, Anton Maximilian and Zimmermann, Hans Georg},
  booktitle={Artificial Neural Networks--ICANN 2006: 16th International Conference, Athens, Greece, September 10-14, 2006. Proceedings, Part I 16},
  pages={632--640},
  year={2006},
  organization={Springer}
}





%%% No Free Lunch 
@article{ho2002simple,
  title={Simple explanation of the no-free-lunch theorem and its implications},
  author={Ho, Yu-Chi and Pepyne, David L},
  journal={Journal of optimization theory and applications},
  volume={115},
  pages={549--570},
  year={2002},
  publisher={Springer}
}


@ARTICLE{Wolpert1997,
  author={Wolpert, D.H. and Macready, W.G.},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={No free lunch theorems for optimization}, 
  year={1997},
  volume={1},
  number={1},
  pages={67-82},
  doi={10.1109/4235.585893}
}
  



%%%% Lottery ticket hypothesis 


@inproceedings{
frankle2018the,
title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
author={Jonathan Frankle and Michael Carbin},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rJl-b3RcF7},
}

@inproceedings{NEURIPS2019_a4613e8d,
 author = {Morcos, Ari and Yu, Haonan and Paganini, Michela and Tian, Yuandong},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers},
 url = {https://proceedings.neurips.cc/paper/2019/file/a4613e8d72a61b3b69b32d040f89ad81-Paper.pdf},
 volume = {32},
 year = {2019}
}




%%% Virtue of Complexity/ Ridge Regression

@article{kelly2022virtue,
  title={The Virtue of Complexity Everywhere},
  author={Kelly, Bryan T and Malamud, Semyon and Zhou, Kangying},
  journal={Available at SSRN},
  year={2022}
}

@article{kelly_malamud_2021,
 title={The virtue of complexity in machine learning portfolios},
 DOI={10.2139/ssrn.3984925}, 
 journal={SSRN Electronic Journal}, 
 author={Kelly, Bryan T. and Malamud, Semyon},
 year={2021}
 } 


 @article{welch2008comprehensive,
  title={A comprehensive look at the empirical performance of equity premium prediction},
  author={Welch, Ivo and Goyal, Amit},
  journal={The Review of Financial Studies},
  volume={21},
  number={4},
  pages={1455--1508},
  year={2008},
  publisher={Society for Financial Studies}
}



 @misc{Hastie19,
  doi = {10.48550/ARXIV.1903.08560},
  url = {https://arxiv.org/abs/1903.08560},
  author = {Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J.},
  keywords = {Statistics Theory (math.ST), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Surprises in High-Dimensional Ridgeless Least Squares Interpolation},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{LiangTengyuan2020JiK,
author = {Liang, Tengyuan and Rakhlin, Alexander},
address = {Hayward},
copyright = {Copyright Institute of Mathematical Statistics Jun 2020},
issn = {0090-5364},
journal = {The Annals of statistics},
keywords = {Asymptotic methods ; Covariance ; Datasets ; Eigenvalues ; Kernel functions ; Mathematical functions ; Nonlinear systems ; Regression analysis ; Regularization ; Upper bounds},
language = {eng},
number = {3},
pages = {1329-},
publisher = {Institute of Mathematical Statistics},
title = {Just interpolate: Kernel “Ridgeless” regression can generalize},
volume = {48},
year = {2020},
}




%% Randomness in NN 
@misc{Picard21,
  doi = {10.48550/ARXIV.2109.08203},
  url = {https://arxiv.org/abs/2109.08203},
  author = {Picard, David},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Torch.manual_seed(3407) is all you need: On the influence of random seeds in deep learning architectures for computer vision},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}


@article{huang2017snapshot,
  title={Snapshot ensembles: Train 1, get m for free},
  author={Huang, Gao and Li, Yixuan and Pleiss, Geoff and Liu, Zhuang and Hopcroft, John E and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1704.00109},
  year={2017}
}


@misc{Moosavi16,
  doi = {10.48550/ARXIV.1610.08401},
  author = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Universal adversarial perturbations},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@InProceedings{pmlr-v162-pezeshki22a,
  title = 	 {Multi-scale Feature Learning Dynamics: Insights for Double Descent},
  author =       {Pezeshki, Mohammad and Mitra, Amartya and Bengio, Yoshua and Lajoie, Guillaume},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {17669--17690},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/pezeshki22a/pezeshki22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/pezeshki22a.html},
}



%%% Deep Learning Tabular Review 

@misc{Arlind21,
  doi = {10.48550/ARXIV.2106.11189},
  url = {https://arxiv.org/abs/2106.11189},
  author = {Kadra, Arlind and Lindauer, Marius and Hutter, Frank and Grabocka, Josif},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Well-tuned Simple Nets Excel on Tabular Datasets},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{Leo22,
  doi = {10.48550/ARXIV.2207.08815},
  url = {https://arxiv.org/abs/2207.08815},
  author = {Grinsztajn, Léo and Oyallon, Edouard and Varoquaux, Gaël},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Methodology (stat.ME), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Why do tree-based models still outperform deep learning on tabular data?},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{Shwartz21,
  doi = {10.48550/ARXIV.2106.03253},
  url = {https://arxiv.org/abs/2106.03253},
  author = {Shwartz-Ziv, Ravid and Armon, Amitai},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Tabular Data: Deep Learning is Not All You Need},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{Shereen21,
  doi = {10.48550/ARXIV.2101.02118},
  url = {https://arxiv.org/abs/2101.02118},
  author = {Elsayed, Shereen and Thyssens, Daniela and Rashed, Ahmed and Jomaa, Hadi Samer and Schmidt-Thieme, Lars},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Do We Really Need Deep Learning Models for Time Series Forecasting?},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


 


%% Deep Regression Ensemble 

@misc{Kelly22deep,
author = {Didisheim, Antoine and Kelly, Bryan and Malamud, Semyon},
  %doi = {10.48550/ARXIV.2203.05417},
  %url = {https://arxiv.org/abs/2203.05417},
  %keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Regression Ensembles},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Zero v1.0 Universal}
}






%%%%%%%%%% Transformation 


%% Catch22 
@Article{Lubba2019,
author={Lubba, Carl H.
and Sethi, Sarab S.
and Knaute, Philip
and Schultz, Simon R.
and Fulcher, Ben D.
and Jones, Nick S.},
title={catch22: CAnonical Time-series CHaracteristics},
journal={Data Mining and Knowledge Discovery},
year={2019},
month={Nov},
day={01},
volume={33},
number={6},
pages={1821-1852},
issn={1573-756X},
doi={10.1007/s10618-019-00647-x},
url={https://doi.org/10.1007/s10618-019-00647-x}
}

%% hctsa
@article{hctsa,
publisher = {Royal Society, The},
title = {Highly comparative time-series analysis: the empirical structure of time series and their methods},
year = {2013-Apr},
author = {Fulcher, BD and Little, MA and Jones, NS},
keywords = {Science & Technology},
language = {eng},
}


%%% Signature Transforms 

@misc{Chevyrev16,
  doi = {10.48550/ARXIV.1603.03788},
  url = {https://arxiv.org/abs/1603.03788},
  author = {Chevyrev, Ilya and Kormilitzin, Andrey},
  title = {A Primer on the Signature Method in Machine Learning},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Terry22,
  doi = {10.48550/ARXIV.2206.14674},
  url = {https://arxiv.org/abs/2206.14674},
  author = {Lyons, Terry and McLeod, Andrew D.},
  title = {Signature Methods in Machine Learning},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{James20,
  doi = {10.48550/ARXIV.2006.00873},
  url = {https://arxiv.org/abs/2006.00873},
  author = {Morrill, James and Fermanian, Adeline and Kidger, Patrick and Lyons, Terry},
  title = {A Generalised Signature Method for Multivariate Time Series Feature Extraction},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{
kidger2021signatory,
title={Signatory: differentiable computations of the signature and logsignature transforms, on both {\{}CPU{\}} and {\{}GPU{\}}},
author={Patrick Kidger and Terry Lyons},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=lqU2cs3Zca}
}

@inproceedings{Lyons07,
publisher = {Springer Berlin Heidelberg},
series = {École d'Été de Probabilités de Saint-Flour, 1908},
title = {Differential Equations Driven by Rough Paths : Ecole d’Eté de Probabilités de Saint-Flour XXXIV-2004 },
year = {2007},
author = {Lyons, Terry J.},
address = {Berlin, Heidelberg},
edition = {1st ed. 2007.},
isbn = {1-280-85347-6},
keywords = {Mathematical analysis},
language = {eng},
}



@InProceedings{pmlr-v130-lemercier21a,
  title = 	 { Distribution Regression for Sequential Data },
  author =       {Lemercier, Maud and Salvi, Cristopher and Damoulas, Theodoros and Bonilla, Edwin and Lyons, Terry},
  booktitle = 	 {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3754--3762},
  year = 	 {2021},
  editor = 	 {Banerjee, Arindam and Fukumizu, Kenji},
  volume = 	 {130},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--15 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v130/lemercier21a/lemercier21a.pdf},
  url = 	 {https://proceedings.mlr.press/v130/lemercier21a.html},
}







%%% Random Transforms


@misc{Sutherland15,
  author = {Sutherland, Danica J. and Schneider, Jeff},
  %keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
 %doi = {10.48550/ARXIV.1506.02785},
  %url = {https://arxiv.org/abs/1506.02785},
  title = {On the Error of Random Fourier Features},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{Xu20,
  author = {Xu, Zhenlin and Liu, Deyi and Yang, Junlin and Raffel, Colin and Niethammer, Marc},
  %doi = {10.48550/ARXIV.2007.13003},
  %url = {https://arxiv.org/abs/2007.13003},
  %keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Robust and Generalizable Visual Representation Learning via Random Convolutions},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license},
}

@Article{Dempster2020,
author={Dempster, Angus
and Petitjean, Fran{\c{c}}ois
and Webb, Geoffrey I.},
title={ROCKET: exceptionally fast and accurate time series classification using random convolutional kernels},
journal={Data Mining and Knowledge Discovery},
year={2020},
month={Sep},
day={01},
volume={34},
number={5},
pages={1454-1495},
issn={1573-756X},
doi={10.1007/s10618-020-00701-z},
url={https://doi.org/10.1007/s10618-020-00701-z}
}

@inproceedings{dempster_etal_2021,
  author    = {Dempster, Angus and Schmidt, Daniel F and Webb, Geoffrey I},
  title     = {{MiniRocket}: A Very Fast (Almost) Deterministic Transform for Time Series Classification},
  booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  publisher = {ACM},
  address   = {New York},
  year      = {2021},
  pages     = {248--257}
}




@misc{Gavrikov23,
  author = {Gavrikov, Paul and Keuper, Janis},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Rethinking 1x1 Convolutions: Can we train CNNs with Frozen Random Filters?},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}











%% TimeSeries Deep Models 


@book{percival_walden_2020, 
place={Cambridge}, 
series={Cambridge Series in Statistical and Probabilistic Mathematics}, 
title={Spectral Analysis for Univariate Time Series}, 
%DOI={10.1017/9781139235723}, 
publisher={Cambridge University Press},
author={Percival, Donald B. and Walden, Andrew T.}, 
year={2020}, 
collection={Cambridge Series in Statistical and Probabilistic Mathematics},
}


@Article{HochSchm97,
  author      = {Sepp Hochreiter and Jürgen Schmidhuber},
  journal     = {Neural Computation},
  title       = {Long Short-Term Memory},
  year        = {1997},
  number      = {8},
  pages       = {1735--1780},
  volume      = {9},
  optdoi      = {10.1162/neco.1997.9.8.1735},
  opteprint   = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
  opturl      = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
}


@misc{Bryan19,
  doi = {10.48550/ARXIV.1912.09363},
  url = {https://arxiv.org/abs/1912.09363},
  author = {Lim, Bryan and Arik, Sercan O. and Loeff, Nicolas and Pfister, Tomas},
  title = {Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}




@article{DARTS,
  author  = {Julien Herzen and Francesco LÃ¤ssig and Samuele Giuliano Piazzetta and Thomas Neuer and LÃ©o Tafti and Guillaume Raille and Tomas Van Pottelbergh and Marek Pasieka and Andrzej Skrodzki and Nicolas Huguenin and Maxime Dumonal and Jan KoÅ›cisz and Dennis Bader and FrÃ©dÃ©rick Gusset and Mounir Benheddi and Camila Williamson and Michal Kosinski and Matej Petrik and GaÃ«l Grosch},
  title   = {Darts: User-Friendly Modern Machine Learning for Time Series},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {124},
  pages   = {1-6},
  url     = {http://jmlr.org/papers/v23/21-1177.html}
}



@misc{TCNModel,
  doi = {10.48550/ARXIV.1803.01271},
  url = {https://arxiv.org/abs/1803.01271},
  author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@misc{Transformer17,
  doi = {10.48550/ARXIV.1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Attention Is All You Need},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Hinton22,
  doi = {10.48550/ARXIV.2212.13345},
  url = {https://arxiv.org/abs/2212.13345},
  author = {Hinton, Geoffrey},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {The Forward-Forward Algorithm: Some Preliminary Investigations},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}





%% Tabular Models 


@inproceedings{XGBoost,
author = {Chen, Tianqi and Guestrin, Carlos},
title = {XGBoost: A Scalable Tree Boosting System},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939785},
doi = {10.1145/2939672.2939785},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {785–794},
numpages = {10},
keywords = {large-scale machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}


@inproceedings{LightGBM,
 author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {LightGBM: A Highly Efficient Gradient Boosting Decision Tree},
 url = {https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{CatBoost,
 author = {Prokhorenkova, Liudmila and Gusev, Gleb and Vorobev, Aleksandr and Dorogush, Anna Veronika and Gulin, Andrey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {CatBoost: unbiased boosting with categorical features},
 url = {https://proceedings.neurips.cc/paper/2018/file/14491b756b3a51daac41c24863285549-Paper.pdf},
 volume = {31},
 year = {2018}
}



@article{Arik_Pfister_2021, 
title={TabNet: Attentive Interpretable Tabular Learning}, 
volume={35}, 
url={https://ojs.aaai.org/index.php/AAAI/article/view/16826}, 
number={8}, 
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Arik, Sercan Ö. and Pfister, Tomas}, 
year={2021}, 
month={May}, 
pages={6679-6687}
}

@inproceedings{AutoInt_Song_2019,
	doi = {10.1145/3357384.3357925},
	url = {https://doi.org/10.11452F3357384.3357925},
	year = 2019,
	month = {nov},
	publisher = {{ACM}},
	author = {Weiping Song and Chence Shi and Zhiping Xiao and Zhijian Duan and Yewen Xu and Ming Zhang and Jian Tang},
  	title = {{AutoInt}},
	booktitle = {Proceedings of the 28th {ACM} International Conference on Information and Knowledge Management}
}


@misc{TabTransformer,
  doi = {10.48550/ARXIV.2012.06678},
  url = {https://arxiv.org/abs/2012.06678},
  author = {Huang, Xin and Khetan, Ashish and Cvitkovic, Milan and Karnin, Zohar},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {TabTransformer: Tabular Data Modeling Using Contextual Embeddings},
  publisher = {arXiv},
  year = {2020},
  copyright = {Creative Commons Zero v1.0 Universal}
}

@misc{NODE,
  doi = {10.48550/ARXIV.1909.06312},
  url = {https://arxiv.org/abs/1909.06312},
  author = {Popov, Sergei and Morozov, Stanislav and Babenko, Artem},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data},
  publisher = {arXiv},
  year = {2019},
  copyright = {Creative Commons Attribution 4.0 International}
}




@misc{Horn19,
  doi = {10.48550/ARXIV.1901.07329},
  url = {https://arxiv.org/abs/1901.07329},
  author = {Horn, Franziska and Pack, Robert and Rieger, Michael},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {The autofeat Python Library for Automated Feature Engineering and Selection},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@INPROCEEDINGS{James15,
  author={Kanter, James Max and Veeramachaneni, Kalyan},
  booktitle={2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Deep feature synthesis: Towards automating data science endeavors}, 
  year={2015},
  volume={},
  number={},
  pages={1-10},
  doi={10.1109/DSAA.2015.7344858},
}



@inproceedings{gulin2011winning,
  title={Winning the transfer learning track of yahoo!’s learning to rank challenge with yetirank},
  author={Gulin, Andrey and Kuralenok, Igor and Pavlov, Dimitry},
  booktitle={Proceedings of the Learning to Rank Challenge},
  pages={63--76},
  year={2011},
  organization={PMLR}
}








%% Clustering
@Article{Traag2019,
author={Traag, V. A.
and Waltman, L.
and van Eck, N. J.},
title={From Louvain to Leiden: guaranteeing well-connected communities},
journal={Scientific Reports},
year={2019},
month={Mar},
day={26},
volume={9},
number={1},
pages={5233},
%issn={2045-2322},
%doi={10.1038/s41598-019-41695-z},
%url={https://doi.org/10.1038/s41598-019-41695-z}
}


@article{Barahona14,
  author={Lambiotte, Renaud and Delvenne, Jean-Charles and Barahona, Mauricio},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={Random Walks, Markov Processes and the Multiscale Modular Organization of Complex Networks}, 
  year={2014},
  volume={1},
  number={2},
  pages={76-90},
  %doi={10.1109/TNSE.2015.2391998}
}

@article{Barahona19,
  title = {Multiscale dynamical embeddings of complex networks},
  author = {Schaub, Michael T. and Delvenne, Jean-Charles and Lambiotte, Renaud and Barahona, Mauricio},
  journal = {Phys. Rev. E},
  volume = {99},
  issue = {6},
  pages = {062308},
  numpages = {18},
  year = {2019},
  month = {Jun},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.99.062308},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.99.062308}
}


%%% Rebalancing 
@article{hoffstein2020rebalance,
  title={Rebalance timing luck: the (dumb) luck of smart beta},
  author={Hoffstein, Corey and Faber, Nathan and Braun, Steven},
  journal={Available at SSRN 3673910},
  year={2020}
}


%%% Datasets 
@online{numerai-datav4.1,
  author="Numerai",
  title="{Numerai Hedge Fund}",
  url="https://numer.ai/data/v4.1",
  note="(2023, Feb 15)",
}

@online{numerai-corr,
  author="Numerai",
  title="{Numerai Hedge Fund}",
  url="https://docs.numer.ai/tournament/correlation-corr",
  note="(2023, Apr 19)",
}


@article{JensenKellyPedersen2022,
   author = {Jensen, Theis Ingerslev and Kelly, Bryan T and Pedersen, Lasse Heje},
   journal = {Journal of Finance, Forthcoming},
   title = {Is There A Replication Crisis In Finance?},
   year = {2022}
}


@ARTICLE{Bagnall19,
  author={Dau, Hoang Anh and Bagnall, Anthony and Kamgar, Kaveh and Yeh, Chin-Chia Michael and Zhu, Yan and Gharghabi, Shaghayegh and Ratanamahatana, Chotirat Ann and Keogh, Eamonn},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={The UCR time series archive}, 
  year={2019},
  volume={6},
  number={6},
  pages={1293-1305},
  %doi={10.1109/JAS.2019.1911747},
  }
