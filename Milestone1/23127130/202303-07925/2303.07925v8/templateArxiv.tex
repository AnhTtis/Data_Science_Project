
\documentclass[dvipsnames]{article}
\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
%\usepackage[a4paper, margin=2cm]{geometry}
%\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\graphicspath{{media/}}     % organize your images and other figures under media/ folder


% Figures and Tables
\usepackage{graphicx}
\usepackage[most]{tcolorbox}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{longtable}


% Mathematics 
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{textcomp}

\usepackage{verbatim}

\usepackage{xcolor}
\usepackage{url}
\usepackage{xr-hyper}
\usepackage{hyperref}
\usepackage{pdfpages} 
\usepackage{bm}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{array}
\newcolumntype{L}{>{\arraybackslash}m{3cm}}

\usepackage{fullpage}
\usepackage{rotating}
\usepackage{stmaryrd}
\usepackage{proof}


%% Tikz 
\usepackage{tikz}
\usetikzlibrary{bayesnet}
\usetikzlibrary{decorations.pathmorphing} % noisy shapes
\usetikzlibrary{fit}% fitting shapes to coordinates
\usetikzlibrary{backgrounds}	

% Theorem 
\usepackage{amsthm}
\usepackage{amsmath}
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}
\newtheorem*{definition*}{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem*{remark*}{Remark}




% Algorithms 
\usepackage[ruled]{algorithm2e}
\usepackage{algorithmic} %% Used in Chapter 1 


% References 
\usepackage[style=numeric,sorting=none,firstinits=true]{biblatex}
\addbibresource{references.bib}



%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

% Update your Headers here
\fancyhead[LO]{THOR Paper Series 2}
% \fancyhead[RE]{Firstauthor and Secondauthor} % Firstauthor et al. if more than 2 - must use \documentclass[twoside]{article}

\newcommand{\MB}[1]{\textcolor{Aquamarine}{\textbf{[MB: #1]}}}
\newcommand{\hl}[1]{\textcolor{magenta}{#1}}

%% Title
\title{Deep incremental learning for financial temporal tabular datasets with distribution shifts
%%%% Cite as
%%%% Update your official citation here when published 
%\thanks{\textit{\underline{Citation}}: \textbf{Authors. Title. Pages.... DOI:000000/11111.}} 
}

\author{
  Thomas Wong \\
  Imperial College London \\
  London\\
  \texttt{mw4315@ic.ac.uk} \\
  %% examples of more authors
   \And
  Mauricio Barahona \\
  Imperial College London \\
  London\\
  \texttt{m.barahona@imperial.ac.uk} \\
}


\begin{document}
\maketitle


\begin{abstract}
We present a robust deep incremental learning framework for regression-based ranking tasks on financial temporal tabular datasets which is built upon the incremental use of commonly available tabular and time series prediction models to adapt to distributional shifts typical of financial datasets.
%
The framework uses a simple basic building block (decision trees) to build hierarchical models of any required complexity to deliver robust performance under adverse situations such as regime changes, fat-tailed distributions, and low signal-to-noise ratios. 
%
As a detailed study, we demonstrate our scheme using XGBoost models trained on the Numerai dataset and show that a two layer deep ensemble of XGBoost models over different model snapshots delivers high quality predictions under different market regimes. We also show that the performance  of XGBoost models with different number of boosting rounds in three scenarios (small, standard and large) is monotonically increasing with respect to model size and converges towards the generalisation upper bound. We also evaluate the robustness of the model under variability of different hyperparameters, such as model complexity and data sampling settings. Our model has low hardware requirements as no specialised neural architectures are used and each base model can be independently trained in parallel.
\end{abstract}



\keywords{Machine Learning, Time Series Prediction, Deep Learning, }



\section{Introduction} 
\label{section:NumeraiSunshine-overview}

%% At the request of reviwers, need to add more references for background
%\subsection{Background on IL}


Many important applications of machine learning (ML), such as the Internet of Things (IoT) \cite{song2018situ} and cyber-security \cite{buczak2015survey}, involve data streams, where data is regularly updated and predictions are made \textit{point-in-time}. 
Such applications pose challenges to standard ML approaches, specifically with regard to the balance between model learning and their update in response to new data arrivals \cite{Gama14,}.

Incremental learning (IL) techniques~\cite{belouadah2021comprehensive,wu2019large,van2022three} are used to adapt deployed machine learning systems to changes in data streams. For example, in image classification systems, class incremental learning \cite{zhu2021class,NEURIPS2022_c8ac22c0,NEURIPS2022_ae817e85} is used where the categories of images cannot be known in advance. A key challenge in IL is the presence of distributional shifts in data (or concept drifts) \cite{Jie19,} which results in model degradation \cite{bayram2022concept,} during inference, i.e., deterioration of out-of-sample performance when the model learns relationships from the training set that significantly differ from those in the test set. 

Reinforcement Learning (RL) \cite{arulkumaran2017deep,NEURIPS2022_d112fdd3,NEURIPS2022_eb4898d6} provides an alternative approach to prediction tasks in systems under data innovation. In RL, a model (agent) learns a policy to optimise its reward by interacting and eliciting a response from the environment. 
RL is therefore useful when the actions of the model influence the environment, and when multiple agents interact with each other \cite{NEURIPS2020_77441296,}. However, if the actions of models have no influence on the data stream, 
%when the reward of agents is not used as input features. 
%In other words, the input features (environment) are \textit{independent} to the actions of the agent (predictions of the model) 
(i.e., there is no feedback between agent and environment), then RL reduces to incremental learning. 
Furthermore, applying trained RL agents to unknown situations (e.g., trading \cite{deng2016deep}, self-driving cars \cite{NEURIPS2021_0d5bd023}, or robotics \cite{kober2013reinforcement}) remains a challenge, and complex algorithms have been introduced to bridge the gap between controlled environments and real-life situations 
\cite{arndt2020meta,higgins2017darla}. Hence the applicability of RL models can suffer from lack of robustness\cite{ma2018improved} and interpretability \cite{mott2019towards,} of agent behaviour, and from the large amount of computational resources required. 

The deep incremental learning (DIL) framework introduced here is a hybrid approach which allows predictions from base learner models to be reused in future predictions for tasks on data streams. 
Unlike RL,  
%which allows flow of information between agent and environment in both directions, 
deep incremental learning only allows a single direction of information flow, from one layer to the next. 
%like a waterfall. 
Importantly, the \textit{point-in-time} nature of predictions is preserved so that no look-ahead bias is introduced. DIL can be thought of as an extension of model stacking \cite{naimi2018stacked,} but taking into account the stream nature of the data. 
Here, we consider an incremental problem in finance, which consists of ranking stocks for neutral portfolio optimisation applied to obfuscated data streams of tabular features and targets, corresponding to stocks and computed features. Such data sets are affected by strong non-stationarity and distribution shifts caused by regime changes in the market.  Here, we expand on our previous work \cite{wong2023online} and develop an IL framework that uses  different data and feature sampling schemes and deep incremental model ensemble techniques appropriate for data streams with a high level of concept drift and non-stationarity. 


%\paragraph{How IL is different from traditional machine learning} 
Adopting an IL approach is crucial for data streams, as traditional assumptions of machine learning algorithms are not applicable. For instance, 
single-pass cross-validation that splits the data into \textit{fixed} training, validation and test periods is not suitable. 
%Instead, an IL framework should be used to retrain and/or update model parameters. 
Under an IL framework, a model is represented by a continuous stream of parameters. Further, the procedure adds new hyperparameters to the model, such as training size and retrain period, which
%In practice, these hyperparameters could be selected based on computational resources available rather than optimised. The size of memory will limit the maximum training size and the amount of GPU or other processing units available will limit how often the models are retrained/updated. 
%When retrain period is greater than 1, there is an extra degree of freedom in when to start the IL procedure. For example, if models are retrained every 10th era, then starting the IL procedure at Era 1, Era 2, ... to Era 10 would give 10 different training procedures using different training sets. This choice could 
 have a non-negligible impact on prediction performances for non-stationary datasets \cite{hoffstein2020rebalance}.
%
The distinction between features, targets and predictions is also blurred in the IL setting, as predictions from models learnt from different spans of data  can be used as additional features when building other models, and targets can be created by subtracting against the predictions made. Therefore, model training is a \textit{multi-step} problem, rather than a \text{single-step} problem. For an illustration of these issues, see Fig.~\ref{fig:gantt}. 


\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figure/chapter3/gantt.png}
    \caption{Schematic of how model predictions are reused in an incremental learning model. Consider three models (Models 1-3) each trained over a training period of 4 eras (weeks) and with a lag of 1 era (week). Model 1 is trained using information (both features and targets)  up to Week 4 and after the 1-week lag, predictions are obtained for era 6 onwards. The features from Weeks 6-9 are combined with predictions from Model 1 to train Model 2. Similarly, Model 3 is trained using data from eras 11 to 14, plus predictions from Models 1 and 2. }
    \label{fig:gantt}
\end{figure}

Reusing model predictions within an IL framework provides a natural hierarchical structure, in which successive models can be interpreted as an improvement of previous ones in response to distributional shifts in data---this is akin to a feedback learning loop where model predictions correct themselves incrementally. Importantly, the prediction quality of each of the models can be inspected independently. Further, the IL setting allows models to process data streams with a finite memory usage by fixing the number of previous models that can be used by a model, so that the size of the training set (consisting of new features and predictions of previous models) remains bounded. 
%Information from previous eras can be passed indirectly to the latest machine learning models. 
There are many other possibilities for the design of IL models to deal with concept drifts in data. See \cite{Gama14,Jie19,} for a survey on recent methods in modelling data streams with different change detection and adaptive learning techniques.
 
Our framework applies this hierarchical IL setting to a \textit{collection} of machine learning models in parallel, which can be thought of as layers of models. 
 %The notion is borrowed from MLP, where each node within a layer is now an independently trained model. 
 %
However, in contrast to standard neural network architectures, such as the multilayer perceptron (MLP), the training is done in a single forward pass without back-propagation. This approach allows us to train complex model with reduced computational resources, as there is no need to put the whole model in distributed memory to pass gradients between layers. In this way, each model within a layer can be trained independently, and training becomes parallelised across GPUs without the need for specialised software packages to distribute data between GPUs.
% 
Recent work in deep learning suggests that backpropagation is not strictly necessary for model training \cite{Hinton22}. For instance, Deep Regression Ensemble (DRE) \cite{Kelly22deep} is built by training layers of ridge regression models with random feature projections.
%similar to an MLP where some layers have frozen weights. 
The deep incremental model presented here, on the other hand, focuses on data streams and temporal data and imposes no restrictions on the ML models used as building blocks forming the layers. 



\section{Temporal data formulations}
Our work deals with prediction tasks motivated by financial temporal data streams, whereby the ranking of a group of stocks needs to be predicted based on the information available at era $i$. Such temporal data streams are treated under different formulations. 

\subsection{Temporal Tabular Datasets}
Our temporal data is compiled into temporal tabular datasets, whereby the data at each time point is represented by features that have been computed from the time series up to that time. 

\begin{definition*}[Temporal Tabular Dataset]
%\paragraph{Temporal Tabular Datasets:}
A temporal tabular dataset is a set of matrices $\{ X_i, y_i \}_{1 \leq i \leq T}$ collected over time eras 1 to $T$. 
%
Each matrix $X_i$ represents data available at era $i$ with dimension $N_i \times M$, where $N_i$ is the number of samples in era $i$ and $M$ is the number of features describing the samples. 
%
The $y_i$ are the targets to be predicted from the features $X_i$, and can be single-dimensional or multi-dimensional.
%
The definition of the features is fixed throughout the eras, in the sense that the same computation is used to obtain the same number of features $M$ at each era. 
%In practical applications, the number of data samples in each era is assumed to be bounded. 
%
Although the features can be in different formats (i.e., numerical, ordinal or categorical), they are usually transformed into equal-sized or Gaussian-binned numerical (ordinal) values. %The datasets in this study are all standardised into discrete bins.
%
Note that the number of data samples $N_i$ does not have to be constant across time. 
%% Data Lag
%\paragraph{Data lag:} Unlike standard online learning problems, where newly arrived data are used immediately to generate predictions and to update the models, 
%
\end{definition*}

\begin{remark*}[Data Lag]
Unlike standard online learning problems, where newly arrived data are used immediately to generate predictions and to update the models, in financial applications there is usually a fixed time lag for the targets from an era to become known (also known as \textit{data embargo}). If the data embargo is, e.g., equal to $5$ eras, the targets of era $t$ become known at era $t+5$, and only then can they be used to calculate the quality of predictions according to a suitably chosen metric. 
%For many applications, the temporal tabular dataset can grow to \textit{infinite} size. 
\end{remark*}


\subsection{Time Series Data} 
In contrast, many traditional methods use time series directly to infer models for prediction. 

\begin{definition*}[Multivariate time series]
%\paragraph{Multivariate time series}
A multivariate time series of $T$ steps and $N$ channels can be represented as a matrix $\mathcal{X}_T = (\bm{x}_1, \bm{x}_2, \dots, \bm{x}_i, \dots, \bm{x}_T)  \in \mathbb{R}^{N \times T} $, where $1 \leq i \leq T$ and each (column) vector $\bm{x}_i \in \mathbb{R}^N$ contains the values of the $N$ channels at time $i$. In many applications, the number of channels $N$ is assumed to be fixed throughout time, with regular and synchronous sampling, i.e. the values in each vector from the $N$ channels arrive simultaneously at a fixed frequency. 
\end{definition*}

Although here we will concentrate on methods to predict temporal tabular datasets, there is a large variety of time series models that predict the time series directly.

\begin{definition*}[Time Series Model] 
%\paragraph{Time Series Model:}
Given a time series $ \mathcal{X}_T \in \mathbb{R^{N\times T}}$,  
%where $T$ is the size of the time dimension and $M$ is the number of features. 
a (one-step ahead) time series model is a function $f: \mathbb{R^{N\times T}} \mapsto \mathbb{R}^N$ that predicts the vector $\bm{x}_{T+1}$ from $X_T$. 
%
In practice, the function $f$ is often learned by training statistical or ML models using different instances of $\mathcal{X}_T$ obtained by shifting $T$ across the time dimension. 
\end{definition*}

A simple example of such a model, which will be used below, is the Exponential Moving Average (EMA).  Moving averages are commonly used to capture trends in time series as follows.

%\subsubsection{Exponential Moving Average (EMA)}
%\label{section:stats}

%Simple statistical rules can be applied on each feature time series \textit{independently} to summarise the history of the time series. 
 
%

\begin{definition*}[Exponential Moving Average]
Given a univariate time series $x_1,x_2,\dots,x_t,\dots$, the exponential moving average of the time series at time $t$ with decay $\alpha$ is defined as 
\begin{align}
\label{equation:EMA}
    y_t &= (1-\alpha) y_{t-1} + \alpha x_t
\end{align}
with initialisation $y_1 = x_1$.
\end{definition*}
%\end{color}

\begin{remark*}
    More complex time series models have been developed, including sequence models in deep learning, such as LSTM \cite{HochSchm97} and Transformers \cite{Bryan19}.  However, these models tend to be overparameterised and lack robustness to regime changes \cite{Shereen21}. They also involve heavy computational costs associated with the training and updating of models.
\end{remark*}



\subsection{Transforming time series into temporal tabular datasets: feature extraction} 
\label{section:NumeraiSunshine-feature-eng-multi}

There are a myriad of methods commonly used to transform multivariate time series into temporal tabular datasets. These feature engineering (FE) methods consist of feature extraction applied over a look-back window:

\begin{itemize}
\item Feature extraction: 
a function $f$ that maps the time series $\mathcal{X}_T \in \mathbb{R}^{N \times T}$ to a feature space $f(\mathcal{X}_T) \in \mathbb{R}^M$ where $M$ is the number of features. Feature extraction methods can help reduce the dimension and noise in time series data.

\item Look-back window:
%As time series can have unbounded length, 
Feature extraction is applied to data within a look-back window (memory) of fixed length $k$. 
%is used to restrict the data size when calculating features. %To avoid look-ahead bias, features are computed using only preceding values. % that represent the state of time series at time $i$ can only be calculated using values obtained up to time $i$, which is $(\bm{x}_1, \bm{x}_2, \dots, \bm{x}_i)$. For most IL tasks, 
%A usual assumption is  data collected more recently are more important than data collected from the past. Therefore, analysis is often restricted to use the most recent $k$ data points only, which are $(\bm{x}_{i-k}, \bm{x}_{i+1-k}, \dots, \bm{x}_i)$. This represents the state of the time series at time $i$ with a look-back window of size $k$. Feature extraction methods are applied to data within the look-back window only. 
Multiple look-back windows can also be used to extract features that capture short-term and long-term trends, and concatenated to represent the state of the time series.  
\end{itemize}


%% Look-back windows

%To model multivariate time series effectively, better methods which can be applied on multiple time series in parallel are needed. In this study, both deterministic and random transformations are considered to create tabular features for the prediction task. 

In this paper, we will employ two feature engineering methods that have been proposed for financial time series:
\begin{itemize}
    \item \textit{Signature Transform (ST)}:
% Signatures
%\subsubsection{Signature Transforms} 
STs \cite{Lyons07, Chevyrev16, Terry22} are deterministic transformations, recently proposed by Lyons, which can extract features at increasing orders of complexity from multivariate data, including time series.  See~\cite{Terry22} for a review of different applications of signature transforms in machine learning. For details on how STs are applied to the Numerai dataset, see Section \ref{section:NumeraiSunshine-tsalgos} in the Supplementary Information.

\item \textit{Random Fourier Transform (RFT)}:
%\subsubsection{Random Fourier Transforms} 
RFTs have been used in \cite{kelly2022virtue} to model the return of financial price time series but can also be applied to extract features from time series at each time step. The key idea is to approximate a mixture model of Gaussian kernels with trigonometric functions \cite{Sutherland15}.  Details on how RFTs are applied on the Numerai dataset are given in the Supplementary Information, see Algorithm~\ref{alg:rft} in Section \ref{section:NumeraiSunshine-tsalgos}.
\end{itemize}

\begin{remark*}
As discussed in Section~\ref{section:NumeraiSunshine-tabular-inc} in more detail, once feature extraction methods have been applied and temporal tabular datasets generated, traditional ML models such as ridge regression, gradient-boosting decision trees (GBDTs), and multi-layer perceptron (MLP) networks can be used to carry out predictions point-wise in time~\cite{wong2023online}, without relying on complex and expensive advanced neural network architectures such as Recurrent Neural Networks (RNN), Long-Short-Term-Memory (LSTM) Networks or Transformers \cite{Bryan19}.     
\end{remark*}



\begin{comment}
Most machine learning models can be expressed as a sequence of transformations between different tensors. Restricting to transformations between tabular and time series data only, 4 different basic transformations are obtained as follows:

% \begin{enumerate}
% %    \item Transformation from tabular data to tabular 
%  %   \begin{itemize}
% %        \item Standard tabular machine learning models which transform the given feature target pair $(X,y)$ into $y'$ where the first(data) dimension of $X,y,y'$ are equal dimensions and $y$ and $y'$ matches all dimensions. The transformations is performed \textit{point-wise}, where at inference each item can be predicted independently. There are many examples for this class of machine learning models, including (and not limited to) gradient-boosting decision trees, and multi-layer perceptron networks. 
%         % \item List-wise tabular machine learning models which transform the \textit{whole} list of items at a time. For a temporal tabular dataset, this means the item rankings are predicted \textit{all at once}. Examples include various list-wise models for learn-to-rank problems \cite{li2020learning}. 
%     % \end{itemize}
%     % \item Transformation from tabular data to time series
%     % \begin{itemize}
%     %     \item Deriving time series using the procedure defined in \ref{def:derivedts} or other suitable transformations. 
%     % \end{itemize}   
%     % \item Transformation from time series to tabular data 
%     % \begin{itemize}
%     %     \item Feature Engineering methods for time series data such as Signature transforms \cite{Terry22} and Random Fourier transforms \cite{Sutherland15} which transforms a slice of time series into a single dimensional tensor which captures the characteristics of the time series. 
%     % \end{itemize}       
%     % \item Transformation from time series to time series 
%     % \begin{itemize}
%     %     \item Sequence models in deep learning, such as LSTM \cite{HochSchm97} and Transformers \cite{Bryan19}. 
%     %\end{itemize}
% \end{enumerate}

\end{comment}




\section{Machine learning for temporal data}
\label{section:NumeraiSunshine-ML-TS}

Before describing our deep incremental learning approach, we give some relevant background and brief links to standard methods used for prediction of temporal tabular data. These methods will be used as the building blocks of our incremental learning approach. 

\subsection{Prediction of Temporal Tabular Datasets from time series data:  Factor-timing models }

Factor-timing models~\cite{haddad2020factor,} are a well-used approach to produce predictions for a temporal tabular dataset from time series, whereby
%
the raw predicted values from a time series model (e.g., the EMA~\eqref{equation:EMA}) are converted into normalised rankings, which are then used as weights for the linear factor-timing model (see Algorithm \ref{alg:factor-timing}).  
%
As baseline for comparison, we apply below factor-timing models to time series that are derived from temporal tabular datasets through a transformation, as follows.
\begin{definition*}[Derived Time Series]
 \label{def:derivedts}
A transformation $f$ is applied to the tabular features $X_t$  and targets $y_t$ at era $t$  to generate a multivariate time series: 
$\bm{\chi}_t = f(X_t,y_t)$, 
where $f:(\mathbb{R}^{N_i \times M}, \mathbb{R}^{N_i \times 1}) \mapsto \mathbb{R}^{M}$. For example, $f$ can be the Pearson correlation between feature and targets.
%where $X$ and $y$ are the features and targets, $N_i$ is the number of observations at era $i$, $M$ is the number of features. 
\end{definition*}  
This procedure generates a time series of  \textit{feature performances} from the temporal tabular dataset, which can be used within a factor-timing model, as in Algorithm~\ref{alg:factor-timing} avoiding look-ahead bias.   
%To avoid look-ahead bias, we restrict to transformations that can be applied to each era independently. 


  
%A major limitation of this assumption is that it precludes the use of feature engineering methods such as Auto-Encoders which are applied across eras. However this assumption can make sure there is no look-ahead bias in the model as these derived time series would be used to build time series models. 

%There are two approaches to model temporal tabular datasets. The first is to apply standard machine learning algorithms for tabular datasets as usual, taking into account the temporal order of data during data sampling. 
%The second is to convert the temporal tabular datasets into the derived time-series, defined as \ref{def:derivedts} and then apply different time-series prediction algorithms followed by factor-timing models. 
%In particular, we will apply different feature engineering methods, such as Signature transforms \cite{Terry22} and Random Fourier transforms \cite{Sutherland15} on the derived time-series to create tabular features for performing time-series forecast (which are different from the original temporal tabular dataset given). 

 
 
\begin{algorithm}[hbt!]
\caption{Factor Timing Model}
\label{alg:factor-timing}
\KwIn{At era $t$: predicted values $\hat{y}_t \in \mathbb{R}^M$ from a time series model, and temporal tabular dataset $X_t \in \mathbb{R}^{N_t \times M}$ where $M$ is the number of features}
\KwOut{Factor-timing model predictions $\hat{z}_t \in \mathbb{R}^{N_t}$ }
Calculate normalised ranking of features $\hat{r}_t$ from predictions of time series model 
\[
    \hat{r}_t = \text{rank}(\hat{y}_t) - 0.5 ,
\]
where the rank function calculates the percentile rank of a value within a vector, so that $-0.5 \leq \hat{r}_t \leq 0.5$. \\
If needed, given upper bound $u$ and lower bound $l$ $-0.5 < l < u <0.5$, apply truncation to $\hat{r}_t$:
\begin{equation*}
    r_t = \max(\min(\hat{r}_t,u),l).
\end{equation*} 
Calculate linear factor-timing predictions $\hat{z}_t = X_t r_t $ 
\end{algorithm}






\subsection{Machine Learning Models for Temporal Tabular Dataset prediction} 
\label{section:NumeraiSunshine-tabular-inc}

In contrast to factor-timing models, ML methods can be applied directly to temporal tabular datasets for prediction tasks.
There is a rich literature comparing different machine learning approaches on tabular datasets \cite{mcelfresh2023neural,Shwartz21,Leo22,Arlind21,}. 
%While  different views exist on which of GBDT or MLP models are more suitable for general purpose tabular regression/classification tasks, 
Several benchmarking studies \cite{mcelfresh2023neural,Shwartz21,Leo22,} have demonstrated that advanced deep learning methods, such as transformers \cite{Arik_Pfister_2021,} and other neural network (NN) models , underperform for  regression/classification tasks on tabular datasets relative to traditional approaches, such as GBDT or MLP models. In particular, recent research \cite{mcelfresh2023neural,} 
%even suggests it is not necessary to choose between GBDT and neural network (NN) models, as 
has shown that GBDTs with moderate hyperparameter tuning perform closely to much more complex NN models. 
%

Further, previous studies had focused on datasets with relatively small numbers of features and samples ($M < 200$ features,  $N_i < 10,000$ data rows or samples), whereas we are interested in large datasets with more than 1000 features and more than 200,000 data rows. For larger datasets, it has been shown~\cite{mcelfresh2023neural,} that GBDTs performed better than 11 neural-network-based approaches and 5 other baseline approaches, such as Support Vector Machines. GBDT models also display higher performance when feature distributions are skewed or heavy-tailed. 

Finally, our objective is the prediction of data streams that are not static or stationary, but rather dynamic and subject to  distribution shifts.  Previous work has shown that GBDTs and MLPs outperform other deep learning approaches for temporal tabular datasets, with higher robustness and lower computational requirements for training (and retraining) of models~\cite{wong2023online,Shwartz21,Leo22}. 


In this paper, GBDT and MLP models are studied in detail for tabular prediction, as both have demonstrated strong performances in benchmarking studies \cite{mcelfresh2023neural,Shwartz21,Leo22, wong2023online} and there exist efficient implementations that allow scalable model training and inference. Details of the GBDT and MLP models can be found in section \label{section:NumeraiSunshine-XGBoost} and \label{section:NumeraiSunshine-DL} in the Supplementary Information. 

\begin{comment}

\textcolor{magenta}
{
The above transformations are the building blocks of the deep IL model. For tabular prediction tasks, any chain of transformations starting with tabular features and ending with tabular targets can be used. This expands the class of models from standard tabular models to other multi-step models such as \textit{factor-timing} models described in \ref{section:NumeraiSunshine-ML-TS}.
%In factor-timing models, the features are first transformed into a time series, capturing the history of feature performances and then using the ranking of predicted feature performances to formulate a factor-timing portfolio. The time series model for predicting feature performances could be any of the above-mentioned methods. }
}

In this paper, rather than fixing different look-back sizes to compute the moving averages of time series, EMA models with varying weight decays are used to predict feature performances. This approach avoids the need for a warm-up period in computing traditional window-based moving averages. The formula to compute EMA is given as follows.     
\end{comment}


\section{Deep (hierarchical) Incremental Learning  algorithm for temporal data}

Our deep incremental learning model is built layer by layer, using component models of a given type (e.g., factor-timing models or GBDTs) composed hierarchically across layers, as follows.
%
At any time, we split our temporal dataset into segments of temporal history. Each segment is assigned to a layer, and for each layer we train an ensemble of models computed with different random seeds.  We thus define the number of layers $L$,  the sizes of the training data (`lookback window') for each layer $(a_1, \dots, a_L)$, and the number of models in the ensemble within each layer $(K_1, \dots, K_L)$. 

The models are learnt using information from different temporal segments sequentially and hierarchically, layer by layer, so that past predictions can be used to refine future predictions.
Operationally, at the start of the training in a layer $l$, we prepare the features and targets $\{ X_j^l, y_j^l \}$ that are shared by all $K_l$ component models within the layer using the most recent data from the specified lookback window. Importantly, the features used as inputs to a layer consist of both original features from the temporal tabular dataset plus predictions obtained from models trained in previous layers $i=1, \ldots, l-1$ (see Fig.~\ref{fig:gantt}).

Regarding the type of component models that form the ensemble in each layer, any model that uses tabular features as input and predicts tabular targets can be used. This expands the class of models from standard tabular models, such as GBDT and MLP, to other multi-step models, such as factor-timing models. 
The overall model is therefore a composition of such component models.
%each of which starts with tabular features and ends with tabular targets.

Each component model within a layer is trained in an incremental manner. This means that the model parameters are updated at regular intervals as new data arrives only using the data from the given lookback window. Other hyperparameters of the model (e.g., boosting rounds for GBDTs) remain unchanged. 
For example, if the dataset in total has 1000 eras and we update the models every 50 eras with lookback window equal to 600 eras we would obtain 9 models, with model training at Eras 600,650,700, \dots, 1000.
%Let the era of model update be era $X$, then data from era $X-600$ to $X-15$ are used for model training (which the data can be split further into training and validation if needed). 
%
%Predictions from each component are reused in future layers. In the stock ranking problem presented here, the predicted ranking are incrementally refined in each layer by combining with other predictions in the same or previous layers in the learning process. 
%
The component models within each layer can be trained in parallel, which allows the incremental learning model to be efficient and scalable.

The pseudocode in 
Algorithm \ref{alg:incremental-stack} outlines the overall structure of the computational framework.

\begin{algorithm}[H]
\caption{Deep IL model with model stacking}
\label{alg:incremental-stack}

\KwIn{Temporal Tabular Dataset $\{ X_i, y_i \}_{1 \leq i \leq T}$, number of layers $L$, the number of models within each layer $(K_1, \dots, K_L)$, sizes of training data in each layer $(a_1, \dots, a_L)$, data embargo $b$, }

%Build the feature importance time series using the given features and targets $\{ X_i, y_i \}$ for each era \\
\For{$1 \leq l \leq L$}{
    Assign the temporal window $w_l$ to layer $l$: $w_l=\{\sum_{w=1}^l (a_w+b) < j \leq \sum_{W=1}^{l-1} (a_w+b) + a_l \} $ \\ 
    Prepare training data for layer $l$: $\{ X_j^l, y_j^l \}_{j \in w_l}$, where the features $X_j^l$ can be any combinations of predictions from previous layers and the original features in the temporal tabular dataset. \\
    \For{$1 \leq k \leq K_L$}{
    Perform data and feature sub-sampling for each component model $\mathcal{M}_k^l$ \\
    Train component model $\mathcal{M}_k^l$ with regular updates\\
    Obtain predicted ranking of stocks using $\mathcal{M}_k^l$ from era $1+\sum_{w=1}^l (a_w+b)$ onward to be used in model training in subsequent layers \\
    }
    %Build the feature importance time series for the next layer using predictions from the models trained in the current layer starting at era $1+l(a+b)$ 
}
\end{algorithm}




\begin{comment}

\paragraph{Practical considerations} 
Unlike standard ML problems where model training is done offline, where memory and computational time is usually not a major consideration in model design, IL models deployed to live data streams would be limited by both the memory and computational time during inference and online retrain/update of model parameters. The exact requirements varied between problems and therefore it is not possible to offer a one-size-fits-all solution.

All models in this paper are trained on a single CUDA-enabled GPU of 10GB memory for model training. While this assumption precludes the use of very advanced deep learning methods, we can still build very complicated models using commonly used tabular and time series models as building blocks. The model can be designed to process an infinite data stream of temporal tabular data effectively without ever-growing memory consumption, by using only the latest values in the IL process.  

\end{comment}


This framework leads to a deep hierarchical ensemble of models, where each layer takes advantage of model ensembling, and the integration of information across layers through functional composition enables the incremental learning necessary to adapt to non-stationarity and regime changes.
%
We now discuss briefly some characteristics of the model:

\paragraph{Hierarchical nature of the model and self-similarity: }

The proposed framework is hierarchical: the ensemble of models in any given layer, which is used to generate predictions in time beyond the latest data arrival, integrates hierarchically both data and predictions obtained from the models in the preceding layers, themselves fitted to previous time periods. Indeed, the model has characteristics of self-similarity, since the layered structure can be seen as performing a functional composition of learning models of the same type, e.g., the component models within each layer can be chosen to be GBDTs (or MLPs) so that the learning mechanism of each individual component is similar to the overall model, and the structure is extended repeatedly in a self-similar manner by interpreting a component model as a base learner for another component model in a higher layer. 
%
%The IL model demonstrates a hierarchical nature in modelling. In some applications, the model also shows self-similarity with a fractal-like structure. In other words, the overall model shared a similar structure with each of its components. 

\paragraph{Universal Approximation Property:} 

It is well known that MLP and GBDT models have the universal function approximation property \cite{cybenko1989approximation}, and Deep Learning models for sequences, such as LSTM \cite{schafer2006recurrent}, also have the universal function approximation property for any dynamical system. Since the DIL model is a composition of models each of which has the universal function approximation property, it also has the universal approximation property for the underlying stochastic process that drives the data generation of the temporal tabular dataset. 




\paragraph{Model stacking: bagging and boosting across time} 
Our model can also be interpreted as a \textit{stacked model} with a total of $\sum_{i=1}^L K_i$ base learners,  such that $K_i$ base learners are trained in the $i$-th iteration, corresponding to each of the $L$ layers. Ideas from bagging and boosting are integrated within the model. Each layer consists of multiple models trained in parallel, as in bagging, so that variance is reduced by combining predictions from different models within a layer. Further, our model can be considered as a degenerate case of boosting, where the learning rate of the target is set to zero inter-layers, such that the target is not adjusted based on predictions from previous layers. However, the  architecture can be modified to allow for target adjustment (boosting) between layers if needed. 



\paragraph{Adaptive nature of the model} 
A key characteristic of the DIL model is that it is designed to support \textit{dynamic} model training, with parameters of each component model updated regularly to adapt to distributional shifts in data.
%
Under the traditional machine learning framework, hyperparameters are selected by cross-validation on splits of the training data. Yet optimal hyperparameters based on a single test period might not work in future. In the DIL model,  
%
predictions from previous layers based on different model hyperparameters are combined in the successive layer, corresponding to a later span of time, acting as a dynamic soft selection of hyperparameters. 
%Soft hyperparameter selection is also related to Bayesian methods of learning the regularisation hyperparameter of regression models. Instead of attempting to derive the posterior distributions of the model hyperparameters, which is difficult when there are no closed-form solutions, the weight parameters can be considered as an approximation to the posterior distribution. 
It has been shown that stacking of models with different random seeds \cite{lakshminarayanan2017simple}, hyperparameters \cite{Florian20} and architectures \cite{zaidi2021neural}  leads to robust performance for \textit{static} datasets.
The DIL model can thus be seen as an extension of stacking techniques to \textit{stream} datasets, so that models incrementally trained with incoming data streams are stacked to obtain more robust predictions. 


\begin{comment}

\MB{This part here... how does it really say about the DIL model?  Summarise with a focussed point $\longrightarrow$}

\begin{color}{magenta}

This framework is founded on heuristics motivated by analogies with other computational methods, which we discuss in the following.

\paragraph{Trees and Neural Networks are alike}

Gradient Boosting Decision Trees (GBDT) and neural networks are usually considered two distinct classes of ML models. However recent researches such as soft decision trees \cite{NODE} and transformers \cite{Transformer17} suggests it is possible to make neural network models more tree-like. Similarly, replacing the base learner in GBDT models with weakly trained shallow nets can make GBDT models more neural-like. 

A better way to understand ML models is to place each model in a \textit{continuous} spectrum of model density, from sparse to dense representations/structures, instead of assigning binary labels of tree or network. Under this framework, decision trees are examples of sparse models and neural networks are examples of dense models. Most ML models employ decision rules and regression with non-linear activation functions as the basic operations of learning. Depending on the exact algorithm used, a ML model will consist of a mix of dense and sparse structures, and thus a binary classification of the nature of the model is not suitable. 

In most applications, the choice of model depends on the nature of the input features. In general, sparse models are good for unstructured data or categorical features. Dense models are good for structured data (For example images, text) or numerical features. %The binned ordinal features for the temporal ranking task are somewhere in between, making both trees and networks good choices of models. 

The IL model can also be interpreted as a neural network model where each node is now a ML model instead of a parameter. As predictions from previous layers can be used as features for the following layers, this simulates the residual connections in some neural network architecture. Each layer in the model will refine the prediction as neural networks. 

\end{color}
\MB{$\longrightarrow$ Up to here needs rethiking/rewriting.}
\end{comment}







%The universal approximation provides a theoretical guarantee that if there is an infinite amount of computational resources then the above model can be used for any modelling tasks of temporal tabular datasets. In reality, a wide range of heuristics is applied to simplify the model design with our finite amount of computational resources so that the approximated model can be as close to the theoretical optimal as possible. 



\section{Prediction tasks for neutral portfolio optimisation using financial data from the Numerai competition}

\paragraph{Numerai dataset and prediction task} 
\label{section:numerai-sunshine-dataset} 


%%%%%% Things added here to this intro

As discussed above, financial time series data can be used directly for prediction~\cite{percival_walden_2020, Bryan19}, yet such methods tend to be overfitted, making them less robust to regime changes and to the high stochasticity inherent to financial data. Alternatively, feature engineering is applied at each era to compute features that capture different aspects of the time history over look-back periods. This approach leads to a temporal tabular dataset, which can be used for prediction without considering time explicitly. The Numerai competition is based on one such professionally curated temporal tabular dataset, formed by matrices $X_i$ that contain $M$ stock market features (computed by Numerai) for $N_i$ stocks updated weekly (i.e., eras are weeks). The definition and computation of the features is fixed throughout the eras. Importantly, the dataset is \textit{obfuscated}, 
%so that the proprietary data generation process from financial datasets is not known to the participants. It is 
i.e., the identity of the stocks present each week is unknown.  The task is then to predict the stock rankings each week, from lowest to highest expected return. This ranking is used to construct a market-neutral portfolio.



\paragraph{Features and Targets}

We use v4.1 of the Numerai dataset \cite{numerai-datav4.1}, starting on 2003-01-03 (Era 1) and extending up to 2023-02-10 (Era 1050). The dataset is weekly, i.e., eras correspond to weeks.
%The era number corresponds to the number of weeks that have passed since the start of the data (2003-01-03).  
Each week, Numerai makes public a matrix of 1586 features for a changing selection of (unidentified) stocks, selected according to risk management rules by the Numerai hedge fund, plus several targets corresponding to stock returns normalised by different proprietary statistical methods.
%
The features are normalised into 5 equal-sized integer bins, from -2 to 2, so that the bins have zero mean.
%Other targets are named similarly. The target labels are all 
The targets are scaled between 0 and 1, and grouped into 5 bins (0, 0.25, 0.5, 0.75, 1.0)
%For each normalisation method, the number of bins could be different, 5 to 7 bins are created for each target with the bin sizes 
following a Gaussian-like distribution, and then subtracting 0.5 to make the bins zero-mean.
%so that most stocks are within the central bin of 0.5 while only a small amount of stocks are in the tail bins of 0 and 1. 
For a more extended discussion of the Numerai dataset, including features and targets, see Ref.~\cite{wong2023online}.


\paragraph{Data Lag}

The data lag for predictions depends on the practicalities of the data pipeline. For Numerai, a lower bound for the scoring target to be resolved is 5 weeks (4 weeks of market data and 1 week for data processing). To take account into both the data lag for the data generation process from Numerai, and the time needed to train models, a conservative data lag of 15 weeks is used here. 

\paragraph{Scoring Function} 

%\MB{What are we using as our target?? This is what we had in the previous paper... $\rightarrow$} There are 28 target labels in the Numerai dataset which are derived from stock returns using 14 proprietary normalisation methods (nomi, jerome, janet, ben, alan, paul, george, william, arthur, thomas, ralph, tyler, victor, waldo) each over 2 forward-looking periods (20 trading days, 60 trading days). 
%To evaluate performance, we use the target nomi-v4-20, i.e., forward 20 trading days return with the nomi normalisation method.
%\MB{ $\rightarrow$ End of insert}
%A new target, 'target-cyrus-v4-20' is used for scoring the trained models. Common risk factors in stock trading are removed during the target construction process. As a result, feature projection \cite{wong2023online} is not necessary for models trained with this target and will not be used in the following analysis
%We then calculate the \textit{feature performances} over time, i.e., the Pearson correlation of each feature with the target in each era. 


Numerai calculates a variant of Pearson correlation for all predictions in a single era $t$, as follows~\cite{numerai-corr}:
%
Let $y_p$ be the predictions ranked between 0 and 1, $y_t$ the targets centred between -0.5 and 0.5, $\Phi(\cdot)$ the (cumulative) distribution function of a standard Gaussian, $\textbf{sgn}(\cdot)$ and $\textbf{abs}(\cdot)$ the element-wise sign and absolute value function, respectively, then the Numerai correlation score for era $t$, $\rho_t$, is given by: 
\begin{align*}
    y_g &= \Phi^{-1}(y_p) \\
    y_{g15} &= \textbf{sgn}(y_g) \cdot \textbf{abs}(y_g)^{1.5} \\
    y_{t15} &= \textbf{sgn}(y_t) \cdot \textbf{abs}(y_t)^{1.5} \\
    \rho_t &= \textbf{Corr}(y_{g15},y_{t15}) \, 
\end{align*}
where $\textbf{Corr}(\cdot,\cdot)$ is the Pearson correlation function. Note that the 3/2 power is taken to emphasise the contribution from the highest and lowest predictions. 
The correlation score $\rho_t$ is collected for each era $t$ over the test period to calculate the following portfolio metrics: 
\begin{itemize}
    \item Mean Corr: average of $\rho_t$ over all eras in the test period
    \item Maximum Drawdown: maximum difference between the cumulative peak (high watermark) and the cumulative sum of correlation scores in the test period 
    \item Sharpe ratio: ratio of Mean corr and standard deviation of $\rho_t$ over all eras in the test period
    \item Calmar ratio: ratio of Mean Corr and Maximum Drawdown 
\end{itemize}
We will use these metrics to score our models throughout the paper. Specifically, high values of `Mean Corr', `Sharpe ratio' and `Calmar ratio' are all indicative of good model performance.



\section{Incremental Learning for Numerai prediction: Non-hierarchical models}

%Here we present the results of training IL models made up from component models of different type for prediction tasks in the Numerai dataset. 


Before presenting results from our hierarchical (deep) incremental learning model, we develop non-hierarchical incremental learning models for the Numerai dataset. These types of models have been used in the literature \cite{kelly2022virtue,kelly_malamud_2021,zhao2023doubleadapt,}, and will serve here both as a baseline comparison and to guide some our choices in model type, training methods and hyperparameter selection. Although these models are updated incrementally (i.e., they do incorporate information of new data arrivals) they do not incorporate information hierarchically across multiple layers, and hence fail to generalise well, due to severe distribution shifts in the data.   
%

To enhance the breadth of our comparison, we study here two types of IL models: (i) factor-timing models that use explicit time series derived from the Numerai dataset, and (ii) ML algorithms (GBDTs, MLP) for tabular datasets which are used directly on the Numerai temporal tabular dataset.
 


\begin{comment}
%\subsubsection{Selection of Look-back Window} For all the feature engineering methods mentioned above, a look-back window needs to be selected. Choosing different sizes of look-back windows corresponds to extracting the dynamics of feature performances at different time scales in the data stream. The lookback can be set to a fixed size or be "infinite", which means using all the available history of the time series at the time of prediction. 
\end{comment}



\subsection{Factor Timing Models}
We generate three factor-timing (FT) models (based on Exponential Moving Average, Signature Transform, and Random Fourier Transform), all of which follow the setup in Algorithm~\ref{alg:factor-timing} but are generated using specific transformations of the data, as follows. 



To alleviate computational time and memory demands, for all FT models we first reduce the dimensionality of the feature space by taking the median over groups of correlated features:
%making use of the specific data structure of the dataset to reduce dimensionality of the dataset.
 % In the second method, we reduce the dimensionality of data making use of the feature importance's time series. This method makes use of the observed feature correlation structure in the Numerai dataset. The
 % features with high multicollinearity are grouped and replaced with their Median (called` Group X Median'). 
 %A reason to use Median instead of Mean is to preserve the binned data structures (as each feature is binned values between $-2$ to $2$ after making the mean zero). 
%is relevant here given the high collinearity in the data: 
1445 features that are consistently correlated across eras (multicollinearity criterion, Pearson correlation $>0.9$) are grouped into 289 groups of 5 features and replaced with their Median (`Group X Median'). We keep 
%This set of 1445 features is denoted as \textit{Set A}. 
the remaining 141 features as originally given, for a total of 430 features to generate a dimensionally reduced temporal tabular dataset $\{\tilde{X}_t,y_t\}_{t=1}^{1050}$, where $\tilde{X}_t \in \mathbb{R}^{N_i \times 430}$. 

We then obtain a multivariate time series from the temporal tabular dataset $\{\tilde{X}_t,y_t\}_{t=1}^{1050}$ as described in Section~\ref{def:derivedts}, i.e., we generate the time series $\{ \bm{\chi}_t\}_{t=1}^{1050}$, where each $\bm{\chi}_t \in \mathbb{R}^{430}$ is derived 
%from the dimensionally reduced temporal tabular dataset $\{X_t,y_t\}_{t=1}^{1050}$ 
by computing the correlation between each feature and the target $y_t$.

%\MB{Add here a step-by-step explanation of the three types of factor-timing models. Explain here what follows for EMA factor-timing models and for ST/RFT factor-timing models, in a sequence of what needs to be done.} 

Once the time series is computed, we train factor timing models at each era using all the available data up to that point, bar the data embargo of 15 eras. %For example, at Era X, we use $\{ \bm{\chi}_t\}_{t=1}^{X-15}$. 
%

We train the following FT models, one using an EMA model of the time series and two other using transforms that generate features from the time series:
%Different factor timing models are trained as described in Section \ref{section:NumeraiSunshine-ML-TS} are then trained on this slice of multi-variate time series. 
\begin{itemize}
\item
Exponential Moving Average factor-timing model: An EMA model~\eqref{equation:EMA} is computed for each of the 430 feature series independently.  This multivariate model is used to produced predictions $\hat{y}_t \in \mathbb{R}^420$ for each era $t$, which are then used within the FT model to produce model predictions $\hat{z}_t \in \mathbb{R}^{N_t}$, as given by Algorithm~\ref{alg:factor-timing}.  These predictions are then scored using our portfolio metrics. 
\item
Feature Transform factor-timing models: From a random subset of the 430 variables of the time series $\bm{\chi}_t$  we generate transformed features (ST or RFT) with lookback period using all available data.
This process is repeated for a varying number of randomly drawn subsets of the variables in $\bm{\chi}_t$ to explore the importance of model complexity $c$,  defined as the ratio of number of features and length of the time series (hyperparameter in Table~\ref{table:factor-timing_evaluation_period}). For example, for a time series of length $T=600$, we may wish to generate models with complexity $c=2$.  Therefore, we obtain $c \cdot T= 1200$ ST features by taking 60 subsets randomly sampled from $\bm{\chi}_t$, where each random subset of 4 time series generates 20 ST features (taking signatures up to level 2). An analogous procedure is followed for RFT.   

%The model complexity is explored as a hyperparameter (see Table~\ref{table:factor-timing_evaluation_period}). 
%to study different regimes, 
%the model complexity is varied between 0.1 and 10 to obtain models from under-parameterised to over-parameterised models. 
The $c \cdot T$ transformed features (ST/RFT) from all subsets are then concatenated, and ridge regression with L2-regularisation is applied to generate the linear model for $\hat{z}_t \in \mathbb{R}^{N_t}$. 
%
Following recent research in high dimensional ridgeless regression \cite{Hastie19,kelly2022virtue,},
we average the results of ridge regression over a range of regularisation parameters (0.01,0.1,1.0,10.0,100.0) that cover a spectrum of models, from dense to sparse. 
%it has which suggests we can obtain the minimum L2-norm model that interpolates the data by taking the limit of L2-regularisation towards zero.
% \textcolor{magenta}{
% \paragraph{Ridge Regression}
% Applying the above feature engineering methods, tabular features that have sizes greater than the number of observations is created. This results in an over-parameterised model where regularisation is required as there are multiple models that can perfectly fit the data. In this paper, ridge regression, which is a linear regression model with L2-regularisation is used. Ridge regression has closed-form solutions and there is an efficient implementation which can calculate ridge regression models with different L2-regularisation on the same dataset. 
% }
\end{itemize}


%\paragraph{Training set and hyperparameter optimisation over evaluation set}
The FT models are retrained at every era using all data available up to that point, hence by construction these models are all incremental. In Algorithm \ref{alg:Sunshine-FactorTiming}, we describe the incremental learning procedure to train FT models.



\begin{algorithm}[H]
\caption{Factor Timing Models}
\label{alg:Sunshine-FactorTiming}
\KwIn{Data embargo $b=15$}
\For{$1 \leq i \leq 1050$}{
    Calculate feature performances time series $\{ \bm{\chi}_t\}_{t=1}^{1050}$, where each $\bm{\chi}_t \in \mathbb{R}^{430}$ using the procedure described in Section~\ref{def:derivedts}
}
\For{$ 601 \leq i \leq 1050$}{
    Prepare training data by slicing the feature performances time series from Era $1$ to $D_i-b$ \\
    \For{$1 \leq j \leq 3$}{
        Train Factor Timing models, which can be one for EMA, Signature Transforms and Random Fourier Transforms model. \\
        Predict feature ranking $y_{i+1}$ for era $D_{i+1}$ \\
        Create factor timing predictions $z_{i+1}$ using Algorithm \ref{alg:factor-timing} \\
    }
}
\end{algorithm} 






%from the first 600 eras (weeks) spanning from 2003-01-03 (Era 1) and 2014-06-26 (Era 600), followed by 
To optimise key hyperparameters of the FT models (decay $\alpha$ for EMA models, and complexity $c$ for ST/RFT models), we evaluate their one-step ahead performance over the \textit{evaluation} period from 2014-07-04 (Era 601) to 2019-12-13 (Era 885).  
%
Table \ref{table:factor-timing_evaluation_period} shows the performances of the FT models in the evaluation period, 
%from 2014-07-04 (Era 601) to 2019-12-13 (Era 885).
%for factor timing models based on exponential moving averages, and the model performances in the evaluation period for signatures transforms, random Fourier transforms models, 
averaged over 5 different random seeds.  
From our numerics, we conclude that EMA FT models are superior to ST and RFT models, over a range of decays $\alpha \in [0.005,0.04]$, even allowing for a diversity of model complexities for ST and RFT models.   
The best performance over the evaluation period is obtained by the EMA FT model with decay  $\alpha=0.02$. 
%
%For signature transforms models, higher complexity gives slightly better performances but is not significant. For random Fourier transforms models, higher complexity gives poorer performances.










%%%% Eval Peirod FT Models 
\begin{table}[!htb]
(a) FT models based on EMA models over evaluation period (Eras 601-885)
\begin{center}
    \begin{tabular}{|l|c|c|c|}
    \hline
        Decay ($\alpha$) & Mean Corr & Sharpe & Calmar \\ \hline
        0.000625 & 0.0026 & 0.1635 & 0.0053 \\ \hline
        0.00125  & 0.0032 & 0.1927 & 0.0062 \\ \hline
        0.0025   & 0.0052 & 0.2841 & 0.0092 \\ \hline
        0.005    & 0.0065 & 0.3948 & 0.0187 \\ \hline
        0.01     & 0.0069 & 0.4483 & 0.0403 \\ \hline
        0.02     & \textbf{0.0074} & \textbf{0.4798} & \textbf{0.0646} \\ \hline
        0.04     & 0.0064 & 0.4153 & 0.0340 \\ \hline
        0.08     & 0.0057 & 0.3650 & 0.0254 \\ \hline
        0.16     & 0.0043 & 0.2798 & 0.0193 \\ \hline
    \end{tabular}
 %   \caption{Exponential Moving Averages models between Era 601 and 800}
 %   \label{table:stats}
\end{center}
\bigskip
(b) FT models based on Signature Transform features over evaluation period (Eras 601-885)
\begin{center}
    \begin{tabular}{|l|c|c|c|}
    \hline
        Complexity & Mean Corr & Sharpe  & Calmar  \\ \hline
        0.10    & 0.0048 $\pm$ 0.0008 & 0.2840 $\pm$ 0.0477 & 0.0120 $\pm$ 0.0030 \\ \hline
        0.25    & 0.0050 $\pm$ 0.0009 & 0.3006 $\pm$ 0.0604 & 0.0140 $\pm$ 0.0057 \\ \hline
        0.50    & 0.0052 $\pm$ 0.0011 & 0.3169 $\pm$ 0.0766 & 0.0164 $\pm$ 0.0101 \\ \hline
        0.75    & 0.0054 $\pm$ 0.0012 & 0.3274 $\pm$ 0.0823 & 0.0181 $\pm$ 0.0130 \\ \hline
        1.00    & 0.0056 $\pm$ 0.0013 & 0.3364 $\pm$ 0.0887 & 0.0192 $\pm$ 0.0138 \\ \hline
        2.50    & 0.0059 $\pm$ 0.0015 & 0.3618 $\pm$ 0.0994 & 0.0263 $\pm$ 0.0216 \\ \hline
        5.00    & 0.0062 $\pm$ 0.0015 & 0.3792 $\pm$ 0.1050 & 0.0287 $\pm$ 0.0216 \\ \hline
        7.50    & 0.0063 $\pm$ 0.0015 & 0.3889 $\pm$ 0.1057 & 0.0310 $\pm$ 0.0223 \\ \hline
        10.00   & 0.0064 $\pm$ 0.0015 & 0.3956 $\pm$ 0.1048 & 0.0323 $\pm$ 0.0222 \\ \hline
    \end{tabular}
%    \caption{Signature transform models between Era 601 and 800}
%    \label{table:signatures}
 \end{center}
\bigskip
(c) FT models based on Random Fourier Transform features over evaluation period (Eras 601-885)  
\begin{center}
    \begin{tabular}{|l|c|c|c|}
    \hline
        Complexity & Mean Corr  & Sharpe  & Calmar   \\ \hline
        0.10  & 0.0051 $\pm$ 0.0005 & 0.3084 $\pm$ 0.0313 & 0.0118 $\pm$ 0.0024 \\ \hline
        0.25  & 0.0051 $\pm$ 0.0004 & 0.3063 $\pm$ 0.0229 & 0.0111 $\pm$ 0.0012 \\ \hline
        0.50  & 0.0048 $\pm$ 0.0008 & 0.2916 $\pm$ 0.0456 & 0.0115 $\pm$ 0.0030 \\ \hline
        0.75  & 0.0047 $\pm$ 0.0006 & 0.2725 $\pm$ 0.0334 & 0.0089 $\pm$ 0.0014 \\ \hline
        1.00  & 0.0041 $\pm$ 0.0004 & 0.2427 $\pm$ 0.0236 & 0.0089 $\pm$ 0.0019 \\ \hline
        2.50  & 0.0042 $\pm$ 0.0007 & 0.2541 $\pm$ 0.0365 & 0.0112 $\pm$ 0.0031 \\ \hline
        5.00  & 0.0019 $\pm$ 0.0017 & 0.0934 $\pm$ 0.0886 & 0.0069 $\pm$ 0.0062 \\ \hline
        7.50  & 0.0010 $\pm$ 0.0011 & 0.0622 $\pm$ 0.0708 & 0.0037 $\pm$ 0.0044 \\ \hline
        10.00 & 0.0015 $\pm$ 0.0014 & 0.1010 $\pm$ 0.0893 & 0.0069 $\pm$ 0.0060 \\ \hline
    \end{tabular}
    \end{center}
\smallskip
    \caption{Performance of different factor-timing (FT) models over evaluation period (Eras 601-885)}
    \label{table:factor-timing_evaluation_period}
\end{table}


%%% Test Period FT Models 
\begin{table}[!htb]
(a) FT models based on EMA models over test period (Eras 901-1050)
\begin{center}
    \begin{tabular}{|l|c|c|c|}
    \hline
        Decay ($\alpha$) & Mean Corr & Sharpe & Calmar \\ \hline
        0.000625 & 0.0088 & 0.4691 & 0.0734 \\ \hline
        0.00125  & 0.0115 & 0.5554 & 0.0866 \\ \hline
        0.0025   & \textbf{0.0157} & 0.6829 & \textbf{0.1088} \\ \hline
        0.005    & 0.0126 & \textbf{0.6928} & 0.0941 \\ \hline
        0.01     & 0.0091 & 0.5653 & 0.0720 \\ \hline
        0.02     & 0.0078 & 0.4673 & 0.0453 \\ \hline
        0.04     & 0.0062 & 0.3504 & 0.0373 \\ \hline
        0.08     & 0.0040 & 0.1975 & 0.0167 \\ \hline
        0.16     & 0.0021 & 0.1003 & 0.0073 \\ \hline
    \end{tabular}
%    \label{table:statsall}
\ \end{center}
\bigskip
(b) FT models based on Signature Transform features over test period (Eras 901-1050)  
\begin{center}
    \begin{tabular}{|l|c|c|c|}
    \hline
        Complexity & Mean Corr & Sharpe  & Calmar  \\ \hline
        0.10  & 0.0131 $\pm$ 0.0005 & 0.6620 $\pm$ 0.0226 & 0.0857 $\pm$ 0.0068 \\ \hline
        0.25  & 0.0128 $\pm$ 0.0010 & 0.6521 $\pm$ 0.0289 & 0.0828 $\pm$ 0.0098 \\ \hline
        0.50  & 0.0128 $\pm$ 0.0011 & 0.6507 $\pm$ 0.0309 & 0.0806 $\pm$ 0.0092 \\ \hline
        0.75  & 0.0127 $\pm$ 0.0012 & 0.6464 $\pm$ 0.0392 & 0.0795 $\pm$ 0.0109 \\ \hline
        1.00  & 0.0126 $\pm$ 0.0013 & 0.6445 $\pm$ 0.0449 & 0.0789 $\pm$ 0.0125 \\ \hline
        2.50  & 0.0121 $\pm$ 0.0021 & 0.6211 $\pm$ 0.0869 & 0.0751 $\pm$ 0.0199 \\ \hline
        5.00  & 0.0114 $\pm$ 0.0031 & 0.5834 $\pm$ 0.1479 & 0.0692 $\pm$ 0.0253 \\ \hline
        7.50  & 0.0109 $\pm$ 0.0037 & 0.5588 $\pm$ 0.1855 & 0.0666 $\pm$ 0.0286 \\ \hline
        10.00 & 0.0105 $\pm$ 0.0041 & 0.5410 $\pm$ 0.2103 & 0.0646 $\pm$ 0.0306 \\ \hline
    \end{tabular}
%    \label{table:signaturesall}
 \end{center}
\bigskip
(c) FT models based on Random Fourier Transform features over test period (Eras 901-1050)  
\begin{center}
    \begin{tabular}{|l|c|c|c|}
    \hline
        Complexity & Mean Corr & Sharpe  & Calmar  \\ \hline
        0.10  & 0.0119 $\pm$ 0.0007 & 0.5696 $\pm$ 0.0247 & 0.0604 $\pm$ 0.0072 \\ \hline
        0.25  & 0.0110 $\pm$ 0.0026 & 0.5121 $\pm$ 0.1093 & 0.0510 $\pm$ 0.0165 \\ \hline
        0.50  & 0.0107 $\pm$ 0.0014 & 0.5307 $\pm$ 0.0533 & 0.0570 $\pm$ 0.0128 \\ \hline
        0.75  & 0.0103 $\pm$ 0.0010 & 0.4970 $\pm$ 0.0336 & 0.0482 $\pm$ 0.0082 \\ \hline
        1.00  & 0.0115 $\pm$ 0.0016 & 0.5544 $\pm$ 0.0476 & 0.0630 $\pm$ 0.0106 \\ \hline
        2.50  & 0.0090 $\pm$ 0.0024 & 0.4500 $\pm$ 0.0959 & 0.0457 $\pm$ 0.0107 \\ \hline
        5.00  & 0.0019 $\pm$ 0.0028 & 0.0978 $\pm$ 0.1390 & 0.0140 $\pm$ 0.0193 \\ \hline
        7.50  & 0.0028 $\pm$ 0.0019 & 0.1729 $\pm$ 0.1203 & 0.0242 $\pm$ 0.0214 \\ \hline
        10.00 & 0.0017 $\pm$ 0.0018 & 0.1037 $\pm$ 0.1046 & 0.0145 $\pm$ 0.0149 \\ \hline
    \end{tabular}
    \end{center}
\smallskip
    \caption{Performance of different factor-timing (FT) models over test period (Eras 901-1050)}
    \label{table:factor-timing_test_period}
\end{table}


\paragraph{Performance over test period:} Table~\ref{table:factor-timing_test_period} shows  the performance of the FT models over the test period between 2020-04-03 (Era 901) and 2023-02-10 (Era 1050).
Our numerics confirm that the EMA FT models have higher performance than ST/RFT models also on the test period, although the best performance for EMA models is achieved for smaller decays $\alpha$ of 0.0025-0.005.
%. EMA models with weight decay 0.005 has the highest Sharpe ratio and the second highest Mean Corr. However, EMA model with weight decay 0.0025 has the highest Calmar ratio. The optimal weight decay of EMA models in the test period is different from those in the evaluation period.
The RFT models are, again, the worst performing, whereas the ST models show improved performance over the test period (relative to the evaluation period).
%have similar performances over different model complexities. Signature transforms models performed better than random Fourier transforms models over different model complexities. 
Comparing the performances over the two periods
%performances between 2014-07-04 (Era 601) and 2019-12-13 (Era 885) and the test period performances between 2020-04-03 (Era 901) and 2023-02-10 (Era 1050) 
demonstrates why selecting model hyperparameters for IL tasks based on finite snapshots
of non-stationary data streams might not be robust over longer horizons. 
%Some hyperparameters might perform better than others over a short amount of time but not over longer observations.

%In summary, we find that EMA models with suitable weight decay parameters performed best of the FT models considered here for the Numerai dataset, 
%with good generalisation to the test period. 



%For models that depend on randomness, calculating model performances over different random seeds and then performing hypothesis tests can identify situations where the improvement of performances is not significant. Hypothesis tests can only be used to check if we can/cannot \textit{reject} the null hypothesis that performances between different hyperparameters are equal on average (equal with respect to different measures such as mean, and distribution depending on what hypothesis tests are used). 



\paragraph{Optimised prediction from a dynamical ensemble of EMA models}


%For models hyperparameters that do not depend on randomness, such as exponential moving averages or other rule-based trend indicators, hypothesis testing cannot be applied to select hyperparameters directly. Instead, we create a 

As discussed in\cite{wong2023online}, better prediction can be achieved by the creation of ensembles of models and the \textit{dynamic} combination of predictions from them. 
%
For instance, EMA models with different decays (akin to having different soft memory) can be ensembled to capture different time scales from the history of the data set. 
% 
To test this idea, 
%from EMA models incrementally. This can be interpreted as a soft selection of hyperparameters of the EMA models since rather than using a single optimal weight decay, we allocate weights towards different EMA models dynamically. 
%
%soft hyperparameter selection within an IL framework are used to find an optimal 
%%%%%%%%%  
%\MB{To be checked... Clearly incremental and dynamic?  But not well explained.}\hl{
an ensemble is created from the 9 EMA models in Table~\ref{table:factor-timing_test_period}(a) and combined dynamically and incrementally using XGBoost, as follows. For every 10th era, a shallow XGBoost model is trained using model predictions from the most recent 185 eras (with suitable data lag) imposing constraints to avoid assigning negative weights to model predictions.

% The XGBoost model has the following hyperparameters:
% %% Layer 2 XGBoost 
% Grow policy: Depth-wise; Number of boosting rounds: 20;  Early Stopping 20; Learning rate: 0.1; Max Depth: 8; Max Leaves: 128; Min Samples per node: 10; Data subsample: 0.75; Feature subsample by tree: 0.75; Feature subsample by level/node: 1; L1 regularisation: 0.001; L2 regularisation: 0.001.


Table \ref{table:EMADeep} shows the performance from the ensemble EMA XGBoost model, repeated with 5 different random seeds, compared to a simple average of the 9 EMA models in Table~\ref{table:factor-timing_test_period}(a).
%
There is a substantial improvement achieved through the XGBoost optimisation over simple averaging especially in terms of a reduced variance, highlighting the potential for the dynamic and incremental combination of EMA models with different decays through ensembling techniques.  

\begin{table}[htb!]
\begin{center}
       \begin{tabular}{|l|c|c|c|}
    \hline
        Ensemble of EMA models  & Mean Corr  & Sharpe & Calmar  \\ \hline
        Average                & 0.0087 $\pm$ 0.0043  & 0.4535 $\pm$ 0.2043  & 0.0602 $\pm$ 0.0353  \\ \hline
        XGBoost optimisation   & 0.0117 $\pm$ 0.0002  & 0.5669 $\pm$ 0.0078  & 0.0682 $\pm$ 0.0069  \\ \hline
    \end{tabular}
\end{center}
    \smallskip
       \caption{Performance of ensemble of EMA models 
       over test period (Eras 901-1050): average of the models in Table~\ref{table:factor-timing_test_period}(a), and a dynamical incremental ensemble XGBoost model with hyperparameters
%% Layer 2 XGBoost 
\textit{(Grow policy: Depth-wise; Number of boosting rounds: 20;  Early Stopping: 20; Learning rate: 0.1; Max Depth: 8; Max Leaves: 128; Min Samples per node: 10; Data subsample: 0.75; Feature subsample by tree: 0.75; Feature subsample by level/node: 1; L1 regularisation: 0.001; L2 regularisation: 0.001)}.}
    \label{table:EMADeep}
\end{table}



\subsection{IL model for XGBoost models} 

Two key hyperparameters for IL models are (i) training size, which for a temporal tabular dataset, the number of eras of data to be used in training and (ii) retrain periods, which governs how often the model are retrained/updated using the latest data. 


In this section, we train IL models with different training sizes and retrain periods, using XGBoost models with the optimised design choices, based on hyperparameter optimisation using data up to 2018-04-27 (Era 800).  We performed a grid search over hyperparameters for XGBoost and MLP models and concluded XGBoost models are better than MLP. XGBoost with shallow trees without regularisation also performed better than deeper trees with regularisation. The details of the hyperparameter optimisation procedure of the XGBoost and MLP models are described in Section \ref{section:NumeraiSunshine-HyperOpt} in SI.
\MB {This needs to be described better to explain what you have  done there.}

%\subsubsection{XGBoost models with different retrain periods (model update frequencies) and train sizes} 

We consider three different train sizes of models: 585,685,785. Numerai recommended a train set of size 574 \cite{numerai-datav4.1} and therefore we do not study in detailed train size smaller than 585. We consider three different retrain periods: 100,50,25, which represents updating model every 2,1,0.5 years respectively. The performance in the validation period (Era 801 to Era 885) are then used for training deep IL models in Section \ref{section:NumeraiSunshine-deepIL}. 


\paragraph{Validation}

Table~\ref{table:XGBIncvalidate} list the performances of the XGBoost models trained with the same optimised hyperparameters between validation period 2018-05-04 (Era 801) and 2019-12-13 (Era 885) over 5 different random seeds. For XGBoost models of a fixed training set size, retraining models more frequently improves model performances but the effect is not significant when the retrain period is shorter than 50. The best model performance is achieved using a train size of 585, suggesting more data does not always improve model performances. For a given train size, the best performances are obtained by setting the retrain period to be the smallest (25). 


\begin{table}[!ht]
 (a) Train size = 585
\begin{center}
    \begin{tabular}{|l|l|l|l|}
    \hline
    Retrain Period & Mean Corr & Sharpe & Calmar \\ \hline
    25  & 0.0226 $\pm$ 0.0011 & 1.2464 $\pm$ 0.0689 & 0.2360 $\pm$ 0.0313 \\ \hline
    50  & 0.0217 $\pm$ 0.0007 & 1.1857 $\pm$ 0.0663 & 0.2246 $\pm$ 0.0314 \\ \hline
    100 & 0.0201 $\pm$ 0.0010 & 1.0365 $\pm$ 0.0625 & 0.2081 $\pm$ 0.0324 \\ \hline
    \end{tabular}
\end{center}
\bigskip
(b) Train size = 685
\begin{center}
    \begin{tabular}{|l|l|l|l|l|l|l|}
    \hline
    Retrain Period & Mean Corr  & Sharpe & Calmar \\ \hline
    25        & 0.0211 $\pm$ 0.0006 & 1.1001 $\pm$ 0.0422 & 0.2493 $\pm$ 0.0239 \\ \hline
    50        & 0.0211 $\pm$ 0.0006 & 1.0808 $\pm$ 0.0376 & 0.2535 $\pm$ 0.0289 \\ \hline
    100       & 0.0203 $\pm$ 0.0007 & 1.0027 $\pm$ 0.0200 & 0.2484 $\pm$ 0.0284 \\ \hline
    \end{tabular}
\end{center}
\bigskip
(c) Train size = 785
\begin{center}
    \begin{tabular}{|l|l|l|l|}
    \hline
    Retrain Period & Mean Corr & Sharpe & Calmar \\ \hline
    25  & 0.0202 $\pm$ 0.0008 & 1.0260 $\pm$ 0.0596 & 0.1823 $\pm$ 0.0328 \\ \hline
    50  & 0.0201 $\pm$ 0.0008 & 0.9846 $\pm$ 0.0653 & 0.1777 $\pm$ 0.0342 \\ \hline
    100 & 0.0193 $\pm$ 0.0011 & 0.9267 $\pm$ 0.0735 & 0.1711 $\pm$ 0.0354 \\ \hline
    \end{tabular}
\end{center}
\smallskip
    \caption{Performance of XGBoost Models with different retrain periods for different train sizes over the validation period (Eras 801- 885)}
    \label{table:XGBIncvalidate}

\end{table}

\paragraph{Test}

Table \ref{table:XGBInctest} lists the performances of the XGBoost models trained with the same optimised hyperparameters between test period 2020-04-03 (Era 901) and 2023-02-10 (Era 1050) over 5 different random seeds. XGBoost models with a train size 585 are still performing the better than those with train sizes 685 and 785. There are no significant difference in performances between XGBoost models of train size 585 with a retrain period of 25 or 50. Setting the retrain period to be the smallest obtain the highest Mean Corr (for a given train size) when train size is 585 or 685, but not when train size is 785. 


\begin{table}[!htb]
(a) Train size = 585
\begin{center}   
\begin{tabular}{|l|l|l|l|}    \hline
    Retrain Period & Mean Corr & Sharpe & Calmar \\ \hline
    25  & 0.0240 $\pm$ 0.0004 & 1.0812 $\pm$ 0.0250 & 0.2850 $\pm$ 0.0464 \\ \hline
    50  & 0.0238 $\pm$ 0.0008 & 1.0978 $\pm$ 0.0323 & 0.2418 $\pm$ 0.0170 \\ \hline
    100 & 0.0222 $\pm$ 0.0006 & 1.0058 $\pm$ 0.0282 & 0.2256 $\pm$ 0.0170 \\ \hline
    \end{tabular}
\end{center}
\bigskip
(b) Train size = 685
\begin{center}
    \begin{tabular}{|l|l|l|l|}
    \hline
    Retrain Period & Mean Corr & Sharpe  & Calmar \\ 
    \hline
    25        & 0.0225 $\pm$ 0.0003 & 1.0540 $\pm$ 0.0386 & 0.2576 $\pm$ 0.0104 \\ \hline
    50        & 0.0219 $\pm$ 0.0003 & 1.0192 $\pm$ 0.0236 & 0.2558 $\pm$ 0.0376 \\ \hline
    100       & 0.0211 $\pm$ 0.0006 & 0.9465 $\pm$ 0.0196 & 0.2467 $\pm$ 0.0378 \\ \hline
    \end{tabular}
 %   \label{table:XGBInc685validate}
\end{center}
\bigskip
(c) Train size = 785
\begin{center}
    \begin{tabular}{|l|l|l|l|l|l|l|}
    \hline
    Retrain Period & Mean Corr & Sharpe & Calmar \\ 
    \hline
    25  & 0.0219 $\pm$ 0.0006 & 1.0134 $\pm$ 0.0263 & 0.2487 $\pm$ 0.0133 \\ \hline
    50  & 0.0231 $\pm$ 0.0004 & 1.1224 $\pm$ 0.0294 & 0.3144 $\pm$ 0.0411 \\ \hline
    100 & 0.0225 $\pm$ 0.0007 & 1.0799 $\pm$ 0.0390 & 0.3063 $\pm$ 0.0376 \\ \hline
    \end{tabular}
\end{center}
\smallskip
    \caption{Performance of XGBoost Models with different retrain periods for different train sizes over the test period (Eras 901- 1050)}
    \label{table:XGBInctest}
\end{table}


\paragraph{Discussion} 

For IL tasks, data sampling schemes has a significant impact on model performances. The above XGBoost models demonstrated a wide range of performances, with some sampling schemes better than others. All the XGBoost models have the \textit{same} hyperparameters except the training set sizes are different and how frequent the models are retrained. This suggests when bench-marking ML models for IL tasks, it is important to apply different data sampling settings to see if performances can be improved by choosing a better data sampling and model retraining procedure. 


A useful empirical rule to select training size is to ensure the training set is large enough to cover different data regimes in the past. Once the training set includes enough data samples from different regimes, further increase in train size will have little improvement to model performance. Setting a small retrain period (updating models more frequently) can improve model performances in most settings. However, this does not hold when train size is the largest (785).

The optimal data sampling scheme depends on the speed of distribution shifts in the data. For fast-moving drifts, sampling schemes that uses a shorter training size or more frequent model retrains/updates will give a better performances. For slow-moving or recurrent drifts \cite{Gama14}, sampling schemes that uses a longer training size or less frequent model retrains/updates will give more robust performances. 





\section{Deep IL Models}
\label{section:NumeraiSunshine-deepIL} 

We now deploy the full deep IL model with dynamic ensembling, which combines models trained with different data sampling methods and hyperparameters to obtain more robust predictions. 
%
This is inspired by our previous work on dynamic forecasting in financial data~\cite{wong2023online} and 
in weather forecasting~\cite{Thoppil2021,}, where ensemble forecasting has been used to improve robustness of predictions.
%Both stock market prediction and weather forecasting share similar challenges of working with temporal data that is inherently unpredictable over long enough horizons. Ensemble forecasting \cite{Thoppil2021,} is widely used in weather forecast to improve robustness of predictions. 
Instead of creating predictions based on a single set of data/parameters, multiple sets of data/parameters are used to capture a range of scenarios, which represent possible trajectories for the evolution of weather or financial systems. 


We establish the choice of the optimal XGBoost hyper-parameters based on validation data from Era 601 to 800. We then establish the optimal choice of training sizes (585 eras) and update frequency (every 50th era) using data up to Era 900. In the following, we present the out-of-samples of different deep IL models from Era 901 onward. 


%We study two methods to ensemble XGBoost models. One is to combine XGBoost models with different feature sampling schemes. The other is to combine XGBoost model snapshots with different model complexity.


\subsection{Deep IL XGBoost models} 

XGBoost models are trained without early-stopping in three different scenarios, with different number of boosting rounds and learning rates. To reduce computational time, each model is trained with 793 features ($50\%$ of the original features randomly sampled) as above. 

%% Why create 3 scenarios
Three scenarios, which represents different computational budget and model complexity are considered. Small XGBoost models require the least amount of computational resources to train. Large XGBoost models require the most amount of computational resources but also provide the best performance. We study different scenarios to demonstrate how deep IL can improve model performances over different assumptions on the base models, from simple models with sub-optimal performances to complex models with strong performances.  

\begin{itemize}
    \item Small:    XGBoost models with 500 boosting rounds and learning rate 0.1
    \item Standard: XGBoost models with 5000 boosting rounds and learning rate 0.01
    \item Large:    XGBoost models with 50000 boosting rounds and learning rate 0.001 
\end{itemize}

%% How to perform deep IL 
As we are not using early-stopping in model training, it is not necessary to reserve some data for validation in Layer 1 as above. For the given training set size of 585, we use the most recent $100\%$(all), $75\%$ and $50\%$ of the 585 eras of data to train XGBoost models. Foe each training set sizes, we train 5 models with different random seeds. For each XGBoost model, 10 model snapshots are collected at regular intervals of the training process as above in Section \ref{section:NumeraiSunshine-XGBModelSnapshots}. These model snapshots represent models with varying complexity. In total, we obtain 150 model snapshots. Each model in Layer 1 is retrained regularly every 50th era.

These 150 predictions are then combined in the second layer of the deep incremental model. For every 10th era, a shallow XGBoost model with the following hyperparameters is trained using model predictions from the most recent 185 eras (with suitable data lag). Monotonic constraints are imposed so that we do not assign negative weights to the model predictions. This procedure is repeated for 5 different random seeds. The hyperparameters of the XGBoost models in Layer 2 are as follows: (Grow policy: Depth-wise, Number of boosting rounds: 20, Learning rate: 0.1, Max Depth: 4, No Early Stopping, Min Samples per node: 10, Data subsample: 0.75, Feature subsample by tree: 0.75, Feature subsample by level/node: 1, L1 regularisation: 0, L2 regularisation: 0). 


%% Pseudo Code 
In Algorithm \ref{alg:Sunshine-deepIL-XGB} we summarise the steps to train the above deep IL XGBoost models. 

\begin{algorithm}[hbt!] 
\caption{Deep IL XGBoost models}
\label{alg:Sunshine-deepIL-XGB}
\KwIn{Number of boosting rounds $B$, Training size of Layer 1 $X_1=585$, Retrain Frequency $T=50$, Data embargo $b=15$}
Set starting Era $D_1=601$ \\
\For{$1 \leq i \leq 10$}{
    Prepare training data $\mathcal{D}_i$ from Era $D_1-X_1-b +T(i-1)$ to $D_1-b +T(i-1)$ \\
    Set Ansatz learning rate $L = \frac{50}{B}$ \\
    \For{$1 \leq s \leq 5$}{
        Define random seed $s$ \\
        \For{$1 \leq j \leq 3$}{
        Train Layer 1 XGBoost models $M_j^s$, using the most recent $100\%$, $75\%$ and $50\%$ of data $\mathcal{D}_i$ respectively with number of boosting rounds $B$ with learning rate $L$, other XGBoost hyperparameters are described as above. \\
        Obtain 10 model snapshot predictions for $M_j^s$ from Era $D_1$ to Era $D_1+T$ \\
        }
    }
    \If{$i \geq 4$}{
        \For{$1 \leq j \leq 5$}{
            Set $D_2 = D_1 +T(i-1) + 10(j-1)$ \\
            Train Layer 2 XGBoost model using the 150 model snapshots from Era $D_2-185-b$ to $D_2-b$ \\
            Obtain Layer 2 predictions for Era $D_2+1$ to $D_2+5$ \\
        }
    }
}
\end{algorithm}







%% Results 
In Table~\ref{table:XGBComplexity}, the performance of XGBoost models in Layer 1 of different training set sizes are reported with the average over all model snapshots and random seeds. The test period reported is Era 901 to Era 1050. We compare the deep XGBoost models in Layer 2 (Deep Incremental) with dynamic model selection from our previous study \cite{wong2023online,} (Dynamic Best), which selected the top 30 models (out of 150) based on recent performances. The average performances over those top 30 models are then reported. The criteria to select models is based on the highest Exponential Weighted Moving Averages (EWMA) Mean Corr with a weight decay of 0.001. Each selected top models have equal contribution. 


Using deep IL can improve model performances in all three scenarios. While for standard and large XGBoost models, deep IL models have a slightly lower Mean Corr than models trained with $100\%$ of training data from Layer 1, Calmar ratios are higher for deep IL models. Creating a dynamic ensemble can create models with a better risk profile, in particular lower drawdown risks at an acceptable cost on portfolio return, where the deep IL models retain at least $95\%$ of Mean Corr of the best models from Layer 1, the ones trained with $100\%$ of training data. 

Selecting the best models based on recent performances (Dynamic Best) did not improve any of the model performance metrics. The relationship between models trained with different settings, such as training set sizes and model complexities is highly non-linear and varying over time such that simple rule-based methods which select models based on recent performances underperformed. Dynamic model selection can be interpreted as assigning sparse weights to the candidate models (As only top 20\% of models are used to create the ensemble). On the other hand, deep IL creates a more flexible and dense model to capture the convoluted and evolving relationship between models trained with different settings. 


Figure \ref{fig:XGBSampling} shows the performance of XGBoost models with $100\%$ of training data from Layer 1 of all three scenarios in the test period (Era 901 to Era 1050). While over-parameterised models have a small drop in Mean Corr, Sharpe and Calmar ratio keep improving as model complexity increases. Model performances consistently increases with model sizes as expected. Large XGBoost models have the best model performances and also the least variance, suggesting randomness in model training can be reduced through training a large number of trees. 


\begin{table}[!ht]
 (a) Small XGBoost models (Max Boosting rounds = 500, Learning rate = 0.1)
\begin{center}
%    \caption{Small XGBoost models with different model complexity (500 boosting rounds)}
    \begin{tabular}{|l|l|l|l|}
        \hline
        Training Set Size     & Mean Corr & Sharpe & Calmar \\ \hline
        $50\%$& 0.0138 $\pm$ 0.0009 & 0.6911 $\pm$ 0.0518 & 0.1194 $\pm$ 0.0289 \\ \hline
        $75\%$& 0.0172 $\pm$ 0.0010 & 0.7972 $\pm$ 0.0649 & 0.1756 $\pm$ 0.0659 \\ \hline
        $100\%$& 0.0218 $\pm$ 0.0017 & 1.0149 $\pm$ 0.0988 & 0.2889 $\pm$ 0.1103 \\ \hline
        Deep Incremental      & 0.0240 $\pm$ 0.0003  & 1.0512 $\pm$ 0.0223 & 0.3343 $\pm$ 0.0090 \\ \hline
        Dynamic Best\cite{wong2023online}          & 0.0168   &  0.9359   & 0.2189     \\ \hline
        % Equal Weighted  & 0.0243 & 1.0113 & 0.3178 \\ \hline 
        %% Equal Weighted ($100\%$ only)  & 0.0261 & 1.0922 & 0.3318 \\ \hline
    \end{tabular}
%    \label{table:XGBComplexity500}
\end{center}
\bigskip
(b) Standard XGBoost models (Max Boosting rounds = 5000, Learning rate = 0.01)
\begin{center}
 %   \caption{Standard XGBoost models with different model complexity (5000 boosting rounds)}
    \begin{tabular}{|l|l|l|l|}
        \hline
        Training Set Size     & Mean Corr & Sharpe & Calmar \\ \hline
        $50\%$& 0.0179 $\pm$ 0.0005 & 0.7656 $\pm$ 0.0296 & 0.1498 $\pm$ 0.0404 \\ \hline
        $75\%$& 0.0204 $\pm$ 0.0008 & 0.8399 $\pm$ 0.0568 & 0.1807 $\pm$ 0.0511 \\ \hline
        $100\%$& 0.0253 $\pm$ 0.0007 & 1.0634 $\pm$ 0.0392 & 0.3243 $\pm$ 0.0892 \\ \hline
        Deep Incremental      & 0.0247 $\pm$ 0.0003   & 1.0447 $\pm$ 0.0156  & 0.3921 $\pm$ 0.0629 \\ \hline
        Dynamic Best\cite{wong2023online}          & 0.0205     & 0.9433    & 0.1983    \\ \hline
         % Equal Weighted  & 0.0243 & 0.9632 & 0.2203 \\ \hline 
         %% Equal Weighted ($100\%$ only)  & 0.0264 & 1.0937 & 0.2913 \\ \hline
    \end{tabular}
%    \label{table:XGBComplexity5000}
\end{center}
\bigskip
(c) Large XGBoost models (Max Boosting rounds = 50000, Learning rate = 0.001)
\begin{center}
 %   \caption{Large XGBoost models with different model complexity (50000 boosting rounds)}
    \begin{tabular}{|l|l|l|l|}
        \hline
        Training Set Size     & Mean Corr & Sharpe & Calmar \\ \hline
        $50\%$& 0.0178 $\pm$ 0.0003 & 0.7606 $\pm$ 0.0150 & 0.1515 $\pm$ 0.0269 \\ \hline
        $75\%$& 0.0210 $\pm$ 0.0005 & 0.8538 $\pm$ 0.0425 & 0.1737 $\pm$ 0.0348 \\ \hline
        $100\%$& 0.0259 $\pm$ 0.0005 & 1.0829 $\pm$ 0.0344 & 0.3361 $\pm$ 0.0903 \\ \hline
        Deep Incremental  & 0.0251 $\pm$ 0.0002   & 1.0723 $\pm$ 0.0053  & 0.4426 $\pm$ 0.0301 \\ \hline
        Dynamic Best\cite{wong2023online}         & 0.0211  & 0.9514  & 0.2123  
        % Equal Weighted  & 0.0243 & 0.9726 & 0.2283 \\ \hline 
        %% Equal Weighted ($100\%$ only)  & 0.0266 & 1.1020 & 0.3035 \\ \hline
        \\ \hline
    \end{tabular}
\end{center}
\smallskip
    \caption{Performance of (a) small, (b) standard and (c) large XGBoost Models of different complexity on test period  (Eras 901-1050)}
\label{table:XGBComplexity}
\end{table}




\begin{figure}[!hbt]
     \centering
      \resizebox{16cm}{!}{
        \subfloat[Mean Corr]{
          \includegraphics{figure/chapter3/XGBSampling_MeanCorr.pdf}
        }
        
        \subfloat[Sharpe]{
          \includegraphics{figure/chapter3/XGBSampling_Sharpe.pdf}
        }
        
        \subfloat[Calmar]{
          \includegraphics{figure/chapter3/XGBSampling_Calmar.pdf}
        }
    }
    \caption{Risk metrics, (a) Mean Corr, (b) Sharpe ratio and (c) Calmar ratio, of XGBoost models trained with all 585 eras of data with regular updates every 50 eras during test period (Era 901 to Era 1050). 10 different model snapshots are taken for XGBoost models of different number of boosting rounds (500,5000,50000). Model are trained with 5 different random seeds. 95\% confidence intervals of Mean Corr for each model are shown in the plot.}
    \label{fig:XGBSampling}
\end{figure}



To demonstrate the deep IL XGBoost models presented here are better than existing approaches, we compare the performances of our deep IL models with the Meta Model from Numerai in the test period, as shown in Table \ref{table:XGBComplexityMeta}. The Meta Model is a weighted average of the predictions from all the participants in the Numerai competition. The weighting is based on the amount of stakes that participants put in their models, which indicates their confidence towards the predictions. The deep IL XGBoost models achieved higher risk metrics than the Meta Model in all three scenarios. To further demonstrate our predictions are not just better than the Meta Model but also provide unique(orthogonal) signals with respect to the Meta Model, we then evaluate the ensemble performance of a prediction based on $50\%$ of the deep IL XGBoost models and $50\%$ of the Meta Model. The ensemble predictions are better than the deep IL model in all scenarios, which suggests the complementary nature of our deep IL models towards the Meta Model. 



\begin{table}[]
\begin{tabular}{|c|c|l|l|l|}
\hline
Scenarios & Strategy   & Mean Corr & Sharpe & Calmar \\ \hline
Meta Model &  & 0.0207 & 1.0073 & 0.3492   \\ \hline
\multirow{2}{*}{Small}    & deep IL  & 0.0240 $\pm$ 0.0003 & 1.0511 $\pm$ 0.0223 & 0.3344 $\pm$ 0.0090 \\ \cline{2-5}
                          & ensemble  & 0.0262 $\pm$ 0.0001 & 1.1398 $\pm$ 0.0111 & 0.4576 $\pm$ 0.0190 \\ \hline
\multirow{2}{*}{Standard} & deep IL  & 0.0247 $\pm$ 0.0002 & 1.0447 $\pm$ 0.0156 & 0.3921 $\pm$ 0.0629 \\ \cline{2-5}
                          & ensemble  & 0.0259 $\pm$ 0.0002 & 1.1202 $\pm$ 0.0091 & 0.4759 $\pm$ 0.0153 \\ \hline
\multirow{2}{*}{Large}    & deep IL  & 0.0251 $\pm$ 0.0001 & 1.0723 $\pm$ 0.0053 & 0.4426 $\pm$ 0.0301 \\ \cline{2-5}
                          & ensemble  & 0.0262 $\pm$ 0.0002 & 1.1348 $\pm$ 0.0036 & 0.4720 $\pm$ 0.0133 \\ \hline
\end{tabular}
\smallskip
    \caption{Performance of deep IL XGBoost Models in the three scenarios (Small,Standard and Large) on test period  (Eras 901-1050), compared with Meta Model along with the equal weighted combination of the deep IL models and Meta Model (ensemble).}
    \label{table:XGBComplexityMeta}
\end{table}




\subsection{Summary} 

%% Improvement by deep model ensemble
Model ensemble is an effective way to improve the robustness of model predictions, in particular when the base learners are not strong predictors on their own, such as the case with small XGBoost models. Different performance metrics (Mean Corr, Sharpe, Calmar) improved with variance reduced significantly also. As expected, improvement is more significant on small XGBoost models than standard and large XGBoost models. 

%% Tradeoff in model performances 
Studying models from three scenarios illustrates the trade-off between model performances and computational budget.  Using a deep ensemble of 15 small XGBoost models instead of a single large XGBoost model (with $100\%$ of training data) only leads not more than $10\%$ performance loss on Mean Corr. Noticing the number of boosting rounds increase by ten fold across scenarios, therefore training a single large XGBoost models would be equivalent to training 100 small XGBoost models in terms of model complexity. It suggests we are able to use only $15\%$ of the computational resources to achieve at least $90\%$ of model performances, along with the added benefit being able to train models in parallel (as training a single model based on boosting prevent parallelisation). 


%% Size of models 
XGBoost and other GBDT models are robust towards the number of boosting rounds. Unlike neural network models, where over-parameterised networks could be difficult to train and lead to performance deterioration. XGBoost models are monotonic increasing and converging with respect to the number of boosting rounds in the three scenarios studied above. Therefore, when choosing the number of boosting rounds for GBDT models, it is better to pick a large number that is within the computational budget and then apply a small learning rate to prevent early convergence. 

%% Different ways to combine model snapshots 
We consider two different ways to create model ensemble, (i) deep incremental learning as shallow XGBoost models are regularly trained to combine individual XGBoost models and (ii) dynamic model selection where a subset of XGBoost models are selected are based on recent performances. Deep incremental learning performs better than dynamic model selection in combining XGBoost models in all three scenarios.

Under the deep IL framework, model complexity is optimised dynamically in Layer 2. We demonstrated that instead of using models with a single complexity, as typically selected by hyperparameter optimisation, model performances can be improved by using models over the different stages of the training process, despite some model snapshots being sub-optimal on a standalone basis. Deep IL framework can be considered as a way of soft hyperparameter selection, where model weights are assigned across models trained with small differences in hyperparameters. Here, the hyperparameter being varied is model complexity, which is the number of boosting rounds. Soft hyperparameter selection are more flexible than traditional hard hyperparameter selection based on train/validation/test splits and this is why it can improve model performances. 





\section{Discussion} 

%% Summary
In this study, both traditional tabular and factor-timing models are studied for the IL problem on the temporal tabular dataset from Numerai. Traditional tabular models, if retrained regularly can adapt to distribution shifts in data. On the other hand, factor-timing models failed to adapt to distribution shifts in data. 

%% GBDT is a robust choice
\paragraph{GBDT are robust ML models}

We found that GBDT models is the best machine learning method for the Numerai datasets, agreeing with the findings of \cite{mcelfresh2023neural,}, which demonstrate the robust and superior performances of GBDT models on large datasets. This is also partly due to the nature of features, being binned values from continuous underlying measures, which favours models based on decision rules rather than regression. Some hyperparameters of XGBoost models, such as the depth of decision trees have significant effects on model performances. In particular, shallow trees without leaf weight regularisation are shown to have better performance than deep trees with regularisation. With suitable designs of the training process, such as a slow learning rate with a large number of boosting rounds, we can train XGBoost models with good performances, slowly converging to the theoretical optimal. 


\paragraph{Sampling schemes for data streams}

Data management and forgetting mechanism is an integrated part of an IL pipeline \cite{Gama14} to build robust prediction models on a data stream. Data sampling methods, such as training sizes and retrain periods can have significant effects on model performances. The impact of data sampling methods are usually over-looked in most quantitative finance research and even in hedge funds \cite{hoffstein2020rebalance}. This is an example of the stability-plasticity dilemma \cite{carpenter1993normal,} in incremental problems, which is the trade-off between the ability of ML models to adapt to new patterns and preserve existing knowledge. It is not known in advance which data sampling method will have the optimal performance and therefore it is better to select those dynamically based on walk-forward prediction performances or deep IL model presented here. The training size needs to be large enough to cover different data regimes in history and not too large to include old data that are no longer relevant. In general, increasing the model retrain period can improve model performances but the requirements on computational resources also increase. Therefore, trade-offs between computational costs and the marginal gain in model performances are made for practical IL systems. In this study, we use a training size of 585 and a retrain frequency of 50 based on a evaluation period (Era 801 - Era 885), balancing the needs of model performances and computational constraints. 


%When researchers are reporting model performances for prediction tasks on temporal tabular datasets, it is better to report the ensemble performances over different data sampling methods and random seeds to remove unwanted variances due to randomness in data. Combining models trained with different data sampling methods can improve the robustness of model performances even without changing any hyperparameters of the ML models. 

%% Random Feature Sampling as boostrap
%We use random feature sampling to study the variance in data generation process with little computational costs. Compared to other approaches in creating synthetic data, such as deep generative models, bootstrapping like sampling methods used here have the distinct advantage of not introducing any assumptions or bias on the data generation process, as the process is purely data driven. 


\paragraph{Model Complexity}

Not all methods of increasing model complexities can improve model performances. For factor-timing models, increasing the size of random feature sets or increasing the number of layers in transformers layers are inefficient ways of data learning. For transformer models, there is no clear relationship between model complexities and performances, results from hyperparameter optimisation are not robust and might not be useful for future predictions. For MLP models, increasing the number of layers does not always improve model performance. The optimal model complexity depends on both the architecture and training process. 

However, for XGBoost models with a shallow tree structure, increasing model complexity by disabling early-stopping can lead to improvement in model performances. Calmar ratios of XGBoost model snapshots improve as we increase model complexity by adding more trees to the model. Gradient boosting, with a small learning rate are very robust such that overfitting is unlikely within reasonable computational budgets.

For IL problems, more recent data can be used in model training if early-stopping is not used, as there is no need to reserve data to create a validation set. In Section \ref{section:NumeraiSunshine-XGB-EarlyStop} in the SI, we demonstrate using more recent data in training Layer 1 XGBoost models can indeed improve model performances compared to training Layer 1 XGBoost models following a more traditional cross-validation approach with early stopping. 

The Numerai datasets used in this paper showed that \textit{both} viewpoints on model complexity are incomplete pictures of the reality of data modelling. 

The classical viewpoint expects over-fitting of the model after a certain number of boosting rounds. In the test period (Era 901-Era 1050), Mean Corr drops slightly in the model snapshots obtained in the later part of the training process but the Sharpe ratio is not changed significantly. The robustness of models improves as the Calmar ratio increases when models become larger. This suggests rather than being an over-fitted model, larger models are more robust as it performs a tradeoff on some of the portfolio return (Mean Corr) with a lower downside risk. 

Modern ML viewpoint is also not correct as both deep factor-timing models based on Signature and random Fourier transforms under-performed simple trend-based models. Complex MLP architectures also under-performed a simple MLP model with 2 layers. This observation is unexpected since these methods are used as examples in research papers advocating the modern ML viewpoint \cite{kelly2022virtue,belkin2019reconciling,}. 

For the XGBoost model snapshots, model predictions are better and more robust when different snapshots are allowed to be combined.

There is no simple rule to select whether to use classic or over-parameterised ML models. The optimal model complexity depends on the training process and datasets for a \textit{static} machine learning problem. Within an IL framework, training multiple models with different complexities and then combine them is better than using cross-validation to select a \textit{single} set of 'optimal' hyperparameters. 


\paragraph{Connection with Model Stacking/Selection}

Stacking is a simple but highly effective technique to combine different ML model predictions. The concept of stacking is not limited to machine learning. In finance, portfolio optimisation are studied in detail to improve investment returns, where a convex optimisation is solved at each time step to find the linear combination of assets or strategies that maximise risk-adjusted return.

Under the IL framework, model stacking can be performed dynamically. Here, we combine the predicted rankings from different ML models at each era with different weights. Instead of considering model stacking as a \textit{separate} step to model training, model stacking can be incorporated as an integrated part in the IL framework, as an extra layer in the IL model.



\paragraph{Further Work}

In most practical applications, \textit{multiple} machine learning methods are used together to create an ensemble prediction. The IL model presented in this paper provides a comprehensive way to integrate different ML models in a consistent and systematic way to create point-in-time predictions. With a multi-layer structure and modularised design within each layer, the deep IL model can flexibly model datasets with different complexities and structures. Further work can be done by integrating different deep tabular models into the model and bench-marking different machine learning methods under the IL framework. 


%% 
Within our incremental learning framework, we retrain each XGBoost model from scratch without using any information from previous ones. Currently, new methods \cite{WANG2022288,liu2020diverse,} have been developed which adapt towards concept drift in data by adding a suitable amount of trees to existing GBDT models. Different approaches, such as reusing a certain amount of base learners (trees) from previous trained GBDT models or updating the weights of trees dynamically depending on the severity of concept drift can be explored in future work. 


%% Crowd-sourcing 
%For crowd-sourcing scientific projects in which submissions from the public are combined to form a meta-model, the deep IL model presented here provided a mechanism to combine many weak models into a strong ensemble. As each component model considered in this study has a very low hardware requirement (only a single GPU is required), this is accessible to most data scientists on Kaggle or other data science competitions. Indeed, the promising results shown in this paper using only standard approaches (XGBoost, MLP) on a dataset with real use cases suggests even if the data scientists in the crowd-sourcing projects might not be aware of the latest advances in machine learning, they can still contribute towards different projects in a meaningful way. 




\section{Acknowledgements}
This work was supported in part by the Wellcome Trust under Grant 108908/B/15/Z and by the EPSRC under grant EP/N014529/1 funding the EPSRC Centre for Mathematics of Precision Healthcare at Imperial. MB also acknowledges support by the Nuffield Foundation under the project ``The Future of Work and Well-being: The Pissarides Review". We thank Numerai GP, LLC for providing the datasets used in the study. 


\section{Data and Code Availability} 
The data and code used in this paper are available at \url{https://github.com/barahona-research-group/THOR-2}.



%Bibliography
\newpage
\printbibliography



\newpage 
\section{Supplementary Information}

\subsection{Algorithms of different benchmark machine learning models studied} 
\label{section:NumeraiSunshine-tsalgos}

\subsubsection{Signature Transforms} 

Signature transforms are applied on continuous paths. A path $X$ is defined as a continuous function from a finite interval $[a,b]$ to $\mathbb{R}^d$ with $d$ the dimension of the path. $X$ can be parameterised in coordinate form as $X_t = (X_t^1,X_t^2,\dots,X_t^d)$ with each $X_t^i$ being a single dimensional path. 

% Iterated Integrals 
For each index $ 1 \leq i \leq d$, the increment of $i$-th coordinate of path at time $t \in [a,b]$, $S(X)_{a,t}^i$, is defined as 
\begin{equation*}
    S(X)_{a,t}^i = \int_{a<s<t} \mathrm{d}X_s^i = X_t^i - X_a^i
\end{equation*}
As $S(X)_{a,\cdot}^i$ is also a real-valued path, the integrals can be calculated iteratively. A $k$-fold iterated integral of $X$ along the indices $i_1,\dots,i_k$ is defined as 
\begin{equation*}
    S(X)_{a,t}^{i_1,\dots,i_k} = \int_{a<t_k<t} \dots \int_{a<t_1<t_2}   \mathrm{d}X_{t_1}^{i_1}  \dots \mathrm{d}X_{t_k}^{i_k} 
\end{equation*}

% Definition of Signature 
The Signature of a path $X: [a,b] \mapsto \mathbb{R}^d$, denoted by $S(X)_{a,b}$, is defined as the infinite series of all iterated integrals of $X$, which can be represented as follows 
\begin{align*}
    S(X)_{a,b} &= (1, S(X)_{a,b}^1, \dots, S(X)_{a,b}^d,  S(X)_{a,b}^{1,1}, \dots ) \\
               &= \bigoplus_{n=1}^{\infty} S(X)_{a,b}^n
\end{align*}

An alternative definition of signature as the response of an exponential nonlinear system is given in \cite{Terry22}. 

% Log Signature 
Log Signature can be computed by taking the logarithm on the formal power series of Signature. No information is lost as it is possible to recover the (original) Signature from Log Signature by taking the exponential \cite{Chevyrev16,Terry22}. Log Signature provides a more compact representation of the time series than Signature. 
\begin{equation*}
    log S(X)_{a,b} =  \bigoplus_{n=1}^{\infty}  \frac{(-1)^{(n-1)}}{n} S(X)_{a,b}^{\bigotimes n} 
\end{equation*}


%%% Theoretical properties of signatures 
%%% Multiplicative Functional 
%%% Universal Property of Signature in predictions (flexible) 
Signatures can be computed efficiently using the Python package signatory \cite{kidger2021signatory}. The signature is a multiplicative functional in which Chen's identity holds. This allows quick computation of signatures on overlapping slices in a path. Signatures provide a unique representation of a path which is invariant under reparameterisation \cite{Chevyrev16, Terry22}. Rough Path Theory suggests the signature of a path is a good candidate set of linear functionals which captures the aspects of the data necessary for forecasting. In particular, continuous functions of paths are approximately linear on signatures \cite{pmlr-v130-lemercier21a}. This can be considered as a version of the universal approximation theorem \cite{cybenko1989approximation} for signature transforms. 


%% Interpretation of Signatures
% Level 1 Signature corresponds to the difference of two series (tail-head). When log price series are given as input, it corresponds to log return 
% Basic Statistical features can be recovered from signatures 

\paragraph{Limitations for signature transforms in high dimensional datasets}
The number of signatures and log-signatures increases exponentially with the number of channels. For time series with a large number of channels, random sampling can be applied to select a small number ($5 < N < 20$) of time series with replacement from the original time series on which signature transforms are applied. Random sampling can be repeated a given number of times to generate representative features of the whole multivariate time series. Similar ideas are considered in \cite{James20}, in which random projections on the high dimensional time series are used to reduce dimensionality before applying signature transforms.  

%% Lookback window
Let $\tilde{X}$ be a multivariate time series with $T$ time-steps and $d$ dimensional features, denote $\tilde{X}_s \in \mathbb{R}^d$ be the observation of the time series at timestep $s$. Procedure \ref{alg:lookback} can be used to obtain paths, which are slices of time series with different lookback windows. Random Signature transforms \ref{alg:randomsig} can then be used to compute the signature of the path, which summarises the information of the time series. 

\begin{algorithm}[hbt!]
\caption{Lookback Window Slicing}\label{alg:lookback}
\KwIn{time series $\tilde{X} \in \mathbb{R}^{T \times d}$, lookback $\delta$}
\KwOut{paths $X_t \in \mathbb{R}^{t \times d}$}
\For{$1 \leq t \leq T$}{
    Set start of slice $s_1 = \max(1, t - \delta)$ \;
    Set end of slice $s_2 = t$ \;
    $X_t = (\tilde{X}_{s_1},\tilde{X}_{s_1+1}, \dots, \tilde{X}_{s_2}) $ \;
}
\end{algorithm}


%% Random Signature Transform Algorithms 
\begin{algorithm}[hbt!]
\caption{Random Signature Transform}\label{alg:randomsig}
\KwIn{path $X_t \in \mathbb{R}^{t \times d}$, level of signature $L$, number of channels $C$, number of feature sets $p$,} 
where $d > C$ \;
\KwOut{log signatures $s_t \in \mathbb{R}^{pN}$ }
Define $N= \text{Number of Log Signatures of a path with } C \text{ channels up to level }  L $ \;
\For{$1 \leq i \leq p$}{
    Sample with replacement $C$ Columns from $X_t$, defined as $\tilde{X}^i_t$ \;
    Compute the Log Signatures $s_t^i \in \mathbb{R}^N$ of $\tilde{X}^i_t$ \;
}
Combine all log signatures $s_t = (s_t^1, \dots, s_t^p)$ 
\end{algorithm}



\subsubsection{Random Fourier Transforms} 
Random Fourier Transforms are used in \cite{kelly2022virtue} to model the return of financial price time series. They can be applied to the feature performance time series at each time step as in Algorithm \ref{alg:rft}. The key idea is to approximate a mixture model of Gaussian kernels with trigonometric functions \cite{Sutherland15}.  

\begin{comment}
A price time series $P_t \in \mathbb{R}^T$ is first transformed into a return series $X_t \in \mathbb{R}^{T \times d} $ by taking the percentage change of price at different lookback intervals. Let $\delta_1, \dots, \delta_d \in \mathbb{N}$ be a given a list of lookback intervals, 
\begin{equation*}
    X_{t,\delta_i} = \frac{P_t - P_{t-\delta_i}}{P_{t-\delta_i}}
\end{equation*}
where $1 \leq t \leq T$ and $1 \leq i \leq d$     
\end{comment}


%% Random Fourier Transform Algorithms 
\begin{algorithm}[hbt!]
\caption{Random Fourier Transform \cite{kelly2022virtue}}\label{alg:rft}
\KwIn{signal vector $x_t \in \mathbb{R}^d$, number of features sets $p$, }
\KwOut{transformed vector $s_t \in \mathbb{R}^{14p}$ }
\For{$1 \leq i \leq p$}{
    Sample $w_i \sim \mathcal{N}(0, I_{d\times d})$ \;
    Set grid $(\gamma_i)_{i=1}^14 = (0.1, 0.5, 1, 2, 4, 8, 16, 0.1, 0.5, 1, 2, 4, 8, 16)$ \;
    \For{$1 \leq j \leq 7$}{
        Set $ s_{t,14i+j} = \frac{1}{\sqrt{7p}} \sin(\gamma_j w_i^T x_t)$
    }
    \For{$8 \leq j \leq 14$}{
        Set $ s_{t,14i+j} = \frac{1}{\sqrt{7p}} \cos(\gamma_j w_i^T x_t)$
    }
}
\end{algorithm}



\subsubsection{Gradient Boosting Models} 
\label{section:NumeraiSunshine-XGBoost}

\paragraph{XGBoost Implementation}

XGBoost \cite{XGBoost} modifies the above "standard" gradient boosting algorithms with approximation algorithms in split finding. Instead of finding the best(exact) split by searching over all possible split points on all the features, a histogram is constructed where splitting is based on percentiles of features. XGBoost supports two different growth policies for the leaf nodes, where nodes closest to the root are split (depth-wise) or the nodes with the highest change of loss function are split (loss-guide). The default tree-growing policy is depth-wise and performs better in most benchmark studies. XGBoost also supports L1 and L2 regularisation of model weights. Other standard model regularisation techniques such as limiting the maximum depth of trees and the minimum number of data samples in a leaf node are also supported. 


\paragraph{Model Snapshots}

For GBDT models, it is easy to extract model snapshots, defined as the model parameters captured at the different parts of the training process. This can be done without any additional memory costs at inference.

Model snapshots of a GBDT model can be obtained as follows. The snapshots start with the first tree and the number of trees to be used is set to be $10\%,20\%,\dots,100\%$ of the number of boosting rounds. This trivially gives 10 different GBDT models representing different model complexities from a \textit{single} model. 

%To avoid early convergence of the learning process, the learning rate can be set to a small value. 


\subsubsection{Deep Learning Models} 
\label{section:NumeraiSunshine-DL}

\paragraph{Training process}

PyTorch Lightning \cite{Falcon_PyTorch_Lightning_2019} is used to build neural network models as it supports modular design and allows rapid prototyping. %The learning rate of neural networks is found by the Learning Rate Finder over a parameter grid of $(1e-3,0.1)$. 
Early stopping is applied based on the validation set based on a given number of rounds (patience). The batch size of the neural network is set to be the size of each era. The Adam optimiser in PyTorch with the default settings for the learning rate schedule is used. L2-regularisation on the model weights is also applied. Gradient clipping is also be applied to prevent the gradient explosion problem for correlation-based loss functions. 

\paragraph{Architecture}

The network architecture is a sequential neural network with two parts, firstly a "Feature Engineering" part which consists of multiple feature engineering blocks and then the "funnel" part which is a standard MLP with decreasing layer sizes. 

Each feature engineering block has an Auto-Encoder-like structure, where the number of features is unchanged after passing each block. Setting a neuron scale ratio of less than 1 corresponds to the case of introducing a bottleneck to the network architecture so as to learn a latent representation of data in a lower dimensional space. %Setting a neuron scale ratio greater than 1 corresponds to the case of introducing random combinations of features which are then refined during the model training process.
Algorithm \ref{alg:encoding} shows how to create the feature engineering part of the network.

Funnel architecture, as used in \cite{Zimmer_Auto-PyTorch_Tabular_Multi-Fidelity_2021} is an effective way to define the neuron sizes in a network for different input feature sizes. Algorithm \ref{alg:funnel} shows how to create the funnel part of the network. 

Each Linear layer is followed by a ReLU activation layer and dropout layer where $10\%$ of weights are randomly zeroed. %Batch Normalisation is not used. 

\begin{definition}[Linear Layer] ~\\
    A Linear Layer $(M_1,M_2)$ within a sequential neural network is a transformation $X_2 = f(X_1)$ with input tensor $X_1 \in \mathbb{R}^{N \times M_1}$ and output tensor $X_2 \in \mathbb{R}^{N \times M_2}$ where $N$ is the batch size of data. For a given non-linear activation function $\sigma(\cdot)$ such as ReLU, let $W \in \mathbb{R}^{M_2 \times M_1}$ be the weight tensor and $b \in \mathbb{R}^{M_2}$ be the bias tensor to be learnt in the training process, the Linear layer is defined as 
    \begin{equation*}
        f(X_1) = \sigma(X_1 W^T + b)
    \end{equation*}
    % where the addition of bias tensor is performed by broadcast multiplication 
\end{definition}


\begin{algorithm}[hbt!]
\caption{Feature Engineering network architecture}
\label{alg:encoding}
\KwIn{Input feature size $M$, Number of encoding layers $L$, neuron scale ratio $r$}
\KwOut{Sequential Feature Engineering Network Architecture}
\For{$1 \leq l \leq L$}{
    Encoding Layer $l$: Linear layer $(M,M*r)$ \\
    Decoding Layer $l$: Linear layer $(M*r,M)$ 
}
\end{algorithm}

\begin{algorithm}[hbt!]
\caption{Funnel network architecture}
\label{alg:funnel}
\KwIn{Input feature size $M$, Output feature size $K$, Number of intermediate layers $L$, neuron scale ratio $r$}
\KwOut{Sequential Funnel Network Architecture}
Input Layer: Linear layer (M, $M*r$) \\
\For{$1 \leq l \leq L$}{
    Intermediate Layer $l$: Linear layer $(M*r^{l}, M*r^{l+1})$ 
}
Output Layer: Linear layer $(M*r^{L+1},K)$ \\
\end{algorithm}


\paragraph{Feature projection and Loss Function} 

Pearson correlation calculated on the whole \textit{era} of target and predictions is used as the loss function at each training epoch. Feature projection, if needed, can be applied from the outputs of network architecture. The neutralised predictions are further standardised to zero mean and unit norm. The negative Pearson correlation of the standardised predictions and targets is then used as the loss function to train the network parameters. 


\newpage 
\subsection{Selecting ML models for Temporal Tabular Datasets} 
\label{section:NumeraiSunshine-HyperOpt}

% \MB{We need to say that subsampling is random for these models...}
% \hl{using either (i) random sub-sampling of features without replacement (down to, e.g., 50\%), or (ii) Random sub-sampling retains more features than taking the median over groups of correlated features and gives better results for MLP and GBDTs.}

%\MB{Are the NN model and XGBoost models presented in Tables 4-6 and Figure 2  --- 'incremental'??  Or are they fixed  and they only become incremental for XGBoost in Section 6.3??}

%\MB{It seems that all the models in Section 6.1 are 'incremental' since they are computed at every era, right?  But now are the models presented in 6.2 incremental or not?}


% Here, we describe the details of hyperparameter optimisation of the IL models used in the main text. We demonstrate XGBoost is better than MLP for our dataset and a shallow tree structure achieves the best performances, with the added benefit of shorter training time than deeper trees. 

For different tabular models introduced in section \ref{section:NumeraiSunshine-tabular-inc}, hyperparameter optimisation is performed using data before 2018-04-27 (Era 800). The training and validation set is data between 2003-01-03 (Era 1) and 2014-06-26 (Era 600), with the last $25\%$ of data (Era 451 - Era 600) as the validation set. 
%
Due to memory constraints, era sub-sampling is applied during model training. $25\%$ of the eras in the training period is used with sampling performed at regular intervals. The performance of the models in the evaluation period, from 2014-07-04 (Era 601) to 2018-04-27 (Era 800) is then used to select hyperparameters for the tabular models. The Mean Corr and Sharpe Ratio of the prediction ranking correlation in the evaluation period is reported. 
%
Due to memory issues for training neural network models, a global feature selection process is used to select $50\%$ of the 1586 features at the start of each model process by random. 


\paragraph{Multi-Layer Perceptron}

Multi-Layer Perceptron (MLP) models without feature projection are trained with different number of encoding and funnel layers using the architecture described in Section \ref{section:NumeraiSunshine-tabular-inc}. 

\begin{itemize}
    \item Number of Feature Eng Layers: 0,1,2,3,4
    \item Number of Funnel Layers: 1,2,3 
\end{itemize}

Other hyperparameters of the neural network models are fixed in the grid search as follows. 
\begin{itemize}
    \item Degree of Feature projection: 0.0
    \item Loss Function: Pearson Corr
    \item Number of epochs: 100 
    \item Early Stopping: 10
    \item Learning Rate: 0.001
    \item Dropout: 0.1
    \item Encoding Neuron Scale: 0.8
    \item Funnel Neuron Scale: 0.8 
    \item Gradient Clip: 0.5 
\end{itemize}


In Table \ref{table:MLP1} shows the performances of MLP models with different network architectures over 5 different random seeds.

The architecture with the highest Mean Corr is the model without feature engineering layers and a standard MLP model with 2 linear layers. When the number of funnel layers equals to 1, the MLP model is equivalent to a (regularised) linear model and has the worst performance. Increasing the number of feature engineering layers does not significantly improve Mean Corr. As model complexity increases, model performances are more varied over different random seeds, suggesting the lack of robustness of deep neural network models. 


\begin{table}[!ht]
    \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|}
    \hline
        Feature Eng Layers  & Funnel Layers & Mean Corr & Sharpe  & Calmar  \\ \hline
        \multirow{3}*{0}   & 1  & 0.0159 $\pm$ 0.0016   & 0.8042 $\pm$ 0.0631  & 0.0826 $\pm$ 0.0087 \\ 
         \cline{2-5}
          & 2  & \textbf{0.0235} $\pm$ 0.0001   & \textbf{1.1344} $\pm$ 0.0119  & \textbf{0.2692} $\pm$ 0.0201 \\ 
          \cline{2-5}
          & 3  & 0.0223 $\pm$ 0.0005   & 1.0478 $\pm$ 0.0372  & 0.2117 $\pm$ 0.0072 \\ \hline
        \multirow{3}*{1}  & 1  & 0.0222 $\pm$ 0.0003   & 1.0509 $\pm$ 0.0112  & 0.2118 $\pm$ 0.0068 \\ 
        \cline{2-5}
          & 2  & 0.0216 $\pm$ 0.0003   & 1.0061 $\pm$ 0.0377  & 0.2021 $\pm$ 0.0128 \\ \cline{2-5}
          & 3  & 0.0224 $\pm$ 0.0003   & 1.0575 $\pm$ 0.0121  & 0.2212 $\pm$ 0.0269 \\ \hline
        \multirow{3}*{2}  & 1  & 0.0217 $\pm$ 0.0004   & 1.0176 $\pm$ 0.0357  & 0.2104 $\pm$ 0.0178 \\ 
        \cline{2-5}
          & 2  & 0.0218 $\pm$ 0.0009   & 1.0346 $\pm$ 0.0571  & 0.2005 $\pm$ 0.0076 \\ 
          \cline{2-5}
          & 3  & 0.0226 $\pm$ 0.0006   & 1.0754 $\pm$ 0.0352  & 0.2348 $\pm$ 0.0242 \\ \hline
        \multirow{3}*{3}  & 1  & 0.0224 $\pm$ 0.0006   & 1.0467 $\pm$ 0.0402  & 0.2226 $\pm$ 0.0281 \\ 
        \cline{2-5}
          & 2  & 0.0221 $\pm$ 0.0009   & 1.0564 $\pm$ 0.0441  & 0.2332 $\pm$ 0.0291 \\ 
          \cline{2-5}
          & 3  & 0.0217 $\pm$ 0.0007   & 1.0245 $\pm$ 0.0414  & 0.2049 $\pm$ 0.0156 \\ 
          \hline
        \multirow{3}*{4}  & 1  & 0.0215 $\pm$ 0.0006   & 1.0131 $\pm$ 0.0192  & 0.1980 $\pm$ 0.0146 \\ 
        \cline{2-5}
          & 2  & 0.0219 $\pm$ 0.0010   & 1.0490 $\pm$ 0.0673  & 0.2229 $\pm$ 0.0309 \\ 
          \cline{2-5}
          & 3  & 0.0218 $\pm$ 0.0017   & 1.0459 $\pm$ 0.0880  & 0.2513 $\pm$ 0.0229 \\ \hline
    \end{tabular}
    \smallskip
        \caption{Neural Network models between  2014-07-04 (Era 601) and 2018-04-27 (Era 800)}
            \label{table:MLP1}
\end{table}


\paragraph{XGBoost}

Root Mean Square Error (RMSE), the standard loss function for regression problems is used to train the XGBoost models. Early-stopping based on Pearson correlation in the validation set is applied to control the model complexity if needed. A grid search is performed to select the data sub-sample and feature sub-sample ratios of the XGBoost models. 

\begin{itemize}
    \item Max Depth: 4,6,8 
    \item Data subsample: 0.25,0.5,0.75
    \item Feature subsample by tree: 0.25,0.5,0.75
    \item L1 regularisation: 0, 0.001, 0.01
    \item L2 regularisation: 0, 0.001, 0.01
\end{itemize}


Other hyperparameters of the XGBoost models are fixed as follows. 
%% Sensible Defaults for XGBoost 
\begin{itemize}
    \item Grow policy: Depth-wise
    \item Number of boosting rounds: 5000
    \item Learning rate: 0.01
    \item Early stopping: 250
    %\item Max Leaves: 128 
    \item Min Samples per node: 10 
    \item Feature subsample by level/node: 1
\end{itemize}


%% Comparison of XGBoost performances over different parameters 
Table \ref{table:XGB1} compares performances of XGBoost models by different data subsample ratios, feature subsample ratios and max depth, mean and standard deviation over 45 models of the 9 combinations of L1 and L2 regularisation each with 5 different random seeds are reported.

Calmar ratio is the performance metric with the most variance, suggesting selecting models based on Calmar ratio is not robust. Mean Corr is the least varied metric between random seeds and therefore we use it for hyperparameter selection. 

Models with data sub-sampling ratio of $75\%$ performed better than models with data sub-sampling ratio of $50\%$ and $25\%$, with a lower variance between model performances over different random seeds also. Models with feature sub-sampling ratio of $75\%$ also performed better. XGBoost models with max depth of 4 performed better than models with max depth of 6 and 8 for each fixed data and feature sub-sampling ratios. 

Table \ref{table:XGB2} compares performances of XGBoost models by different L1 and L2 regularisation and max depth with fixed data and feature sub-sampling ratio of $75\%$. Mean and standard deviation over 5 models with different random seeds are reported. There are no significant difference between model performances over different L1 and L2 regularisation when other model hyperparameters are fixed. Therefore, we set the L1 and L2 regularisation penalty to be zero when training XGBoost models.

We conclude the optimised hyperparameters as follows: Selection is based on having the highest Mean Corr in the evaluation period (Era 601- Era 800). 

\begin{itemize}
    \item Grow policy: Depth-wise
    \item Number of boosting rounds: 5000
    \item Learning rate: 0.01
    \item Early stopping: 250
    \item Min Samples per node: 10 
    \item Feature subsample by level/node: 1
    \item Max Depth: 4 
    \item Data subsample: 0.75
    \item Feature subsample by tree: 0.75
    \item L1 regularisation: 0
    \item L2 regularisation: 0
\end{itemize}



\begin{table}[!ht]
    \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
    \hline
    Data Sample & Feature Sample & Depth & Mean Corr  & Sharpe  & Calmar \\  \hline
    \multirow{9}*{0.25}        &  \multirow{3}*{0.25}          & 4     & 0.0242    $\pm$ 0.0014    & 1.2126 $\pm$ 0.0992 & 0.3451 $\pm$ 0.1237 \\ 
    \cline{3-6} &    & 6     & 0.0225    $\pm$ 0.0018    & 1.1502 $\pm$ 0.1034 & 0.3275 $\pm$ 0.0727 \\ 
     \cline{3-6} &           & 8     & 0.0187    $\pm$ 0.0015    & 1.0045 $\pm$ 0.0904 & 0.2227 $\pm$ 0.0858 \\ 
    \cline{2-6} &   \multirow{3}*{0.5}       & 4     & 0.0236    $\pm$ 0.0014    & 1.1929 $\pm$ 0.0706 & 0.2804 $\pm$ 0.0413 \\ 
    \cline{3-6} &            & 6     & 0.0222    $\pm$ 0.0014    & 1.1193 $\pm$ 0.0825 & 0.2495 $\pm$ 0.075  \\ 
    \cline{3-6} &               & 8     & 0.0189    $\pm$ 0.0012    & 0.9999 $\pm$ 0.066  & 0.23   $\pm$ 0.0791 \\ 
    \cline{2-6} &   \multirow{3}*{0.75}          & 4     & 0.0249    $\pm$ 0.0016    & 1.258  $\pm$ 0.1066 & 0.3501 $\pm$ 0.1275 \\ 
    \cline{3-6} &             & 6     & 0.0228    $\pm$ 0.0013    & 1.1414 $\pm$ 0.0666 & 0.2974 $\pm$ 0.0864 \\ 
    \cline{3-6} &          & 8     & 0.0188    $\pm$ 0.0023    & 0.9734 $\pm$ 0.1425 & 0.1848 $\pm$ 0.075  \\ 
    \hline
    %
    \multirow{9}*{0.5}        &  \multirow{3}*{0.25}
             & 4     & 0.0259    $\pm$ 0.0009    & 
    1.2751 $\pm$ 0.055  & 0.3641 $\pm$ 0.0809 \\ 
    \cline{3-6}
    &          & 6     & 0.0248    $\pm$ 0.0012    & 1.2453 $\pm$ 0.0768 & 0.3862 $\pm$ 0.1135 \\ 
     \cline{3-6}
    &           & 8     & 0.0217    $\pm$ 0.0018    & 1.1244 $\pm$ 0.1076 & 0.3684 $\pm$ 0.143  \\ 
     \cline{2-6}
    &  \multirow{3}*{0.5}       & 4     & 0.0267    $\pm$ 0.001     & 1.3394 $\pm$ 0.0908 & 0.4423 $\pm$ 0.1279 \\ 
     \cline{3-6}
     &               & 6     & 0.0255    $\pm$ 0.001     & 1.2733 $\pm$ 0.0603 & 0.4521 $\pm$ 0.1521 \\
     \cline{3-6}
    &             & 8     & 0.0224    $\pm$ 0.0011    & 1.1622 $\pm$ 0.063  & 0.4375 $\pm$ 0.1299 \\ 
    \cline{2-6}
    & \multirow{3}*{0.5}          & 4     & 0.0268    $\pm$ 0.0011    & 1.3173 $\pm$ 0.0842 & 0.413  $\pm$ 0.0998 \\ 
    \cline{3-6}
    &           & 6     & 0.0255    $\pm$ 0.0011    & 1.2716 $\pm$ 0.075  & 0.4429 $\pm$ 0.1468 \\ 
    \cline{3-6}
    &           & 8     & 0.0226    $\pm$ 0.0014    & 1.1566 $\pm$ 0.1021 & 0.4315 $\pm$ 0.146  \\ 
    \hline
    %
     \multirow{9}*{0.75}        &  \multirow{3}*{0.25}           & 4     & 0.0265    $\pm$ 0.0009    & 1.3146 $\pm$ 0.0605 & 0.4388 $\pm$ 0.0731 \\ 
     \cline{3-6}
     &           & 6     & 0.0268    $\pm$ 0.0009    & 1.3439 $\pm$ 0.0778 & 0.6006 $\pm$ 0.2169 \\ 
    \cline{3-6}
    &           & 8     & 0.0235    $\pm$ 0.0005    & 1.2071 $\pm$ 0.048  & 0.5044 $\pm$ 0.1404 \\ 
    \cline{2-6}
     & \multirow{3}*{0.5}          & 4     & 0.0270     $\pm$ 0.0007    & 1.3345 $\pm$ 0.0477 & 0.4345 $\pm$ 0.0665 \\ 
     \cline{3-6}
    &            & 6     & 0.0271    $\pm$ 0.0007    & 1.3469 $\pm$ 0.0479 & \textbf{0.6300}   $\pm$ 0.1526 \\ 
    \cline{3-6}
    &            & 8     & 0.0241    $\pm$ 0.0012    & 1.234  $\pm$ 0.0702 & 0.4843 $\pm$ 0.2099 \\ 
    \cline{2-6}
    & \multirow{3}*{0.75}           & 4     & \textbf{0.0273}    $\pm$ 0.0006    & \textbf{1.3624} $\pm$ 0.0485 & 0.4885 $\pm$ 0.1032 \\ 
    \cline{3-6}
    &            & 6     & 0.0267    $\pm$ 0.0009    & 1.3373 $\pm$ 0.0566 & 0.5509 $\pm$ 0.1314 \\ 
    \cline{3-6}
    &        & 8     & 0.0237    $\pm$ 0.0005    & 1.2369 $\pm$ 0.065  & 0.5501 $\pm$ 0.1776 \\ 
    \hline
    \end{tabular}
    \bigskip
       \caption{XGBoost models with different data subsample ratios, feature subsample ratios and max depths between  2014-07-04 (Era 601) and 2018-04-27 (Era 800)}
           \label{table:XGB1}
\end{table}



\begin{table}[!ht]
    \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
    \hline
    Max Depth & L2-reg & L1-reg & Mean Corr & Sharpe & Calmar \\ 
    \hline
       \multirow{9}*{4}        &  \multirow{3}*{0.0} 
            & 0.0    & \textbf{0.0276}    $\pm$ 0.0007    & \textbf{1.3829} $\pm$ 0.0515 & 0.5305 $\pm$ 0.1077 \\ 
    \cline{3-6}
             &    & 0.001  & 0.0274    $\pm$ 0.0006    & 1.3764 $\pm$ 0.0485 & 0.5161 $\pm$ 0.1213 \\ 
    \cline{3-6}
             &    & 0.1    & 0.0268    $\pm$ 0.0008    & 1.3283 $\pm$ 0.0627 & 0.4224 $\pm$ 0.0937 \\ 
    \cline{2-6}
             & \multirow{3}*{0.001}  & 0.0    & \textbf{0.0276}    $\pm$ 0.0007    & \textbf{1.3829} $\pm$ 0.0515 & 0.5305 $\pm$ 0.1077 \\ 
    \cline{3-6}
             &  & 0.001  & 0.0274    $\pm$ 0.0006    & 1.3764 $\pm$ 0.0485 & 0.5161 $\pm$ 0.1213 \\ 
    \cline{3-6}
             &  & 0.1    & 0.0268    $\pm$ 0.0008    & 1.3283 $\pm$ 0.0627 & 0.4224 $\pm$ 0.0938 \\ 
    \cline{2-6}
             & \multirow{3}*{0.1}   & 0.0    & 0.0271    $\pm$ 0.0002    & 1.3489 $\pm$ 0.0253 & 0.4771 $\pm$ 0.0824 \\ 
    \cline{3-6}
             &    & 0.001  & 0.0274    $\pm$ 0.0004    & 1.368  $\pm$ 0.0358 & 0.4977 $\pm$ 0.1186 \\ 
    \cline{3-6}
             &   & 0.1    & 0.0274    $\pm$ 0.0004    & 1.3694 $\pm$ 0.0362 & 0.4833 $\pm$ 0.0918 \\ 
    \hline
    \multirow{9}*{6}        &  \multirow{3}*{0.0} 
             & 0.0    & 0.0266    $\pm$ 0.0008    & 1.3354 $\pm$ 0.0453 & 0.5574 $\pm$ 0.1282 \\ 
    \cline{3-6}
             &    & 0.001  & 0.0267    $\pm$ 0.0011    & 1.3353 $\pm$ 0.061  & 0.5422 $\pm$ 0.1697 \\ 
    \cline{3-6}
             &    & 0.1    & 0.0267    $\pm$ 0.0011    & 1.3201 $\pm$ 0.0638 & 0.5665 $\pm$ 0.1578 \\ 
    \cline{2-6}
             & \multirow{3}*{0.001}  & 0.0    & 0.0265    $\pm$ 0.0007    & 1.3347 $\pm$ 0.0441 & 0.5711 $\pm$ 0.1244 \\ 
    \cline{3-6}
             &  & 0.001  & 0.0268    $\pm$ 0.0011    & 1.3403 $\pm$ 0.0657 & 0.5184 $\pm$ 0.1226 \\ 
    \cline{3-6}
             &  & 0.1    & 0.0267    $\pm$ 0.0011    & 1.3201 $\pm$ 0.0638 & 0.5665 $\pm$ 0.1578 \\ 
    \cline{2-6}
            & \multirow{3}*{0.1}    & 0.0    & 0.0269  $\pm$ 0.0009    & 1.3551 $\pm$ 0.0559 & \textbf{0.6187} $\pm$ 0.1823 \\ 
    \cline{3-6}
             &    & 0.001  & 0.0267    $\pm$ 0.0013    & 1.3307 $\pm$ 0.0818 & 0.4871 $\pm$ 0.1164 \\ 
    \cline{3-6}
             &    & 0.1    & 0.0269    $\pm$ 0.0009    & 1.3638 $\pm$ 0.0563 & 0.5304 $\pm$ 0.0598 \\ 
    \hline
    \multirow{9}*{8}        &  \multirow{3}*{0.0} 
            & 0.0    & 0.0237    $\pm$ 0.0008    & 1.2226 $\pm$ 0.0592 & 0.5127 $\pm$ 0.0875 \\ 
    \cline{3-6}
         &    & 0.001  & 0.0238    $\pm$ 0.0003    & 1.2445 $\pm$ 0.0623 & 0.5269 $\pm$ 0.1949 \\ 
    \cline{3-6}
         &    & 0.1    & 0.0237    $\pm$ 0.0004    & 1.2408 $\pm$ 0.0633 & 0.5298 $\pm$ 0.0905 \\ 
    \cline{2-6}
        & \multirow{3}*{0.001}  & 0.0    & 0.0238    $\pm$ 0.0007    & 1.243  $\pm$ 0.0942 & 0.5657 $\pm$ 0.2615 \\ 
    \cline{3-6}
        &  & 0.001  & 0.0238    $\pm$ 0.0004    & 1.2383 $\pm$ 0.0254 & 0.4905 $\pm$ 0.1505 \\ 
    \cline{3-6}
        &  & 0.1    & 0.0238    $\pm$ 0.0003    & 1.2429 $\pm$ 0.0748 & 0.6487 $\pm$ 0.1551 \\ 
    \cline{2-6}
        & \multirow{3}*{0.1}    & 0.0    & 0.0235    $\pm$ 0.0006    & 1.2102 $\pm$ 0.0655 & 0.6036 $\pm$ 0.2693 \\ 
    \cline{3-6}
        &    & 0.001  & 0.024     $\pm$ 0.0003    & 1.2461 $\pm$ 0.0552 & 0.53   $\pm$ 0.1934 \\ 
    \cline{3-6}
        &    & 0.1    & 0.0235    $\pm$ 0.0008    & 1.2438 $\pm$ 0.1056 & 0.5426 $\pm$ 0.2102 \\ 
    \hline
    \end{tabular}
    \smallskip
        \caption{XGBoost models with different L1 and L2 regularisation with fixed data and feature sub-sampling ratios of $75\%$ between  2014-07-04 (Era 601) and 2018-04-27 (Era 800)}
            \label{table:XGB2}
\end{table}




\paragraph{XGBoost model snapshots}
\label{section:NumeraiSunshine-XGBModelSnapshots}

Traditional machine learning research suggests there exists an optimal model complexity where the trade-off of bias and variance is optimal (for a loss function that behaves like the Mean-Squared error). However, modern machine learning research suggests using an over-parameterised model might improve performance in a test set even when model training loss cannot be further improved. The improvement is significant in cases where the model specification is incomplete and low signal-to-noise ratio in the given features. This counter-intuitive phenomenon is explored in different research papers \cite{Hastie19,NakkiranPreetum2021Dddw,Teresa22,chen2023learning,} from both theoretical and empirical perspectives. 

The two viewpoints are summarised as follows. 
\begin{itemize}
    \item Viewpoint 1: (Classical Approach): There exists an optimal model complexity which can be found by performing bootstrapping-like procedures, such as cross-validation. 
    \item Viewpoint 2: (Modern Approach): Over-parameterised model will outperform the optimal model under the classical approach. 
\end{itemize}


To study whether the above viewpoints are valid for our dataset, XGBoost models are trained without early-stopping for different number of boosting rounds and learning rates for 5 different random seeds. Three scenarios are considered: 
\begin{itemize}
    \item Small:    XGBoost models with 500 boosting rounds and learning rate 0.1
    \item Standard: XGBoost models with 5000 boosting rounds and learning rate 0.01
    \item Large:    XGBoost models with 50000 boosting rounds and learning rate 0.001 
\end{itemize}

%Note that in all three scenarios, the product of number of boosting rounds and learning rate is constant. In other words, we are studying the relationship between learning speed in the model training and its convergence. 

We keep other hyper-parameters of the XGBoost models the same as the optimal ones found above. (Grow policy: Depth-wise, Max Depth: 4, Min Samples per node: 10, Data subsample: 0.75, Feature subsample by tree: 0.75, Feature subsample by level/node: 1, L1 regularisation: 0, L2 regularisation: 0)


Model snapshots are created by running the first $10\%,20\%,\dots,100\%$ of boosting rounds during inference. In figure \ref{fig:XGBSnapshot}, various of risk metrics of XGBoost models over different stages of training process in the evaluation period: from 2014-07-04 (Era 601) to 2018-04-27 (Era 800) are reported. Detailed performances of model snapshots of the three scenarios are reported in Table \ref{table:XGBSnapshots}. 

In all three scenarios, increasing the number of boosting rounds beyond $60\%$ of the training process does not significantly improve Mean Corr and Sharpe ratio. However, Calmar ratio continues to improve as we continue adding new trees to the models. It suggests that over-parameterised models are be able to reduce the Max Drawdown and other downside risks in predictions. 

While the difference of Mean Corr and Sharpe ratio between standard and large XGBoost models is not significant over the training process. Large XGBoost models shown a significant improvement in Calmar ratio towards standard XGBoost models, especially for model snapshots obtained the later stages of the training process. 


\begin{figure}[!hbt]
     \centering
      \resizebox{16cm}{!}{
        \subfloat[Mean Corr]{
          \includegraphics{figure/chapter3/XGBSnapshot_MeanCorr.pdf}
        }
        
        \subfloat[Sharpe]{
          \includegraphics{figure/chapter3/XGBSnapshot_Sharpe.pdf}
        }
        
        \subfloat[Calmar]{
          \includegraphics{figure/chapter3/XGBSnapshot_Calmar.pdf}
        }
    }
    \caption{Risk metrics, (a) Mean Corr, (b) Sharpe ratio and (c) Calmar ratio, of XGBoost models between  2014-07-04 (Era 601) and 2018-04-27 (Era 800). 10 different model snapshots are taken for XGBoost models of different number of boosting rounds (500,5000,50000). Model are trained with 5 different random seeds. 95\% confidence intervals of each risk metric for each model are shown in the plot.}
    \label{fig:XGBSnapshot}
\end{figure}



\paragraph{Conclusion} 

%% Factor Timing models under-performed. 
Factor timing models, which are based on learning the dynamics of weights from the feature correlations on each era under-performed other tabular models such as XGBoost and MLP. In fact, feature engineering models do not perform better than simple rule-based models, such as EMA models, when evaluated over a long enough timeframe. EMA models have a strong and robust performance compared to other factor timing models despite their simplicity. The key hyperparameter, weight decay can be selected using a deep IL framework which adjusts dynamically over time. 

The Numerai dataset demonstrates a very strong non-stationary and non-linear nature such that the linear weights of the regression model trained on each era cannot be effectively used to predict future weights. In other words, linear relationships between features and target is not stable such that forecast cannot be made accurately using its history. It suggests the dataset would be better modelled with traditional tabular ML models, with regular updates on model weights, rather than using time series methods to learn the regression weights of a linear model for each era. 


%% Complex MLP models are not helpful 
Increasing complexity of MLP models cannot improve model performances as expected by the Modern ML viewpoint. The best performance is achieved by a standard MLP with two layers, which provides the minimal amount of non-linearity required so that the model does not degenerate to a ridge regression model. As suggested in \cite{Teresa22}, the performance of over-parameterised models are affected by a myriad of factors including model architecture and training process. It cannot be ruled out that there are other model architectures that can make deep learning models performing better than XGBoost. Only the most basic neural network architectures are considered here due to computational resources constraints. However, as suggested from research on bench-marking of tabular ML models \cite{Leo22}, recent deep learning models for tabular data such as TabNet does not always perform better than MLP models. It is unlikely there are advance neural network architectures that are efficient and performed better than MLP.  

%% XGBoost models performed better than MLP 
XGBoost models performed better than MLP models over a wide range of hyperparameters in the evaluation period. The binned nature of features favours the use of decision trees over neural networks, and this view is shared by different reviews on ML algorithms for tabular data \cite{Shwartz21,Leo22,}. Moreover, MLP models take longer computational time to train and suffers from memory constraints. Therefore, we do not consider the use of MLP in building deep model ensemble for the Numerai dataset below.  For similar reasons,  other advanced neural architectures are not explored here given their high computational resources requirement. These architectures are also known to have a high variation of performances over random seeds \cite{gundersen2023sources,} and their hyperparameters are difficult to tune. 


%% Early Stopping for XGBoost 
A key design choice for XGBoost models is whether to apply early-stopping, as it reflects two different viewpoints (Classical vs Modern) towards the optimal choice of model complexity. Unlike the case for deep learning models, over-parameterised XGBoost models did not lead to a drop of model performances. However, over-parameterised models lead to improvement of model performances in some model performance metrics. While Mean Corr and Sharpe ratio converges once reaching a certain threshold of model complexity, which is around  $60\%$ of the training process for the models considered here, Calmar ratio continues to improve over the whole training process. Over-parameterised models are effective ways to reduce model drawdown. Most hyperparameter optimisation in financial ML literature are based on portfolio return or Sharpe ratio \cite{sahu2023overview,nazareth2023financial,}, such that the benefits of using over-parameterised models are being overshadowed as other risk metrics, such as Calmar ratio are not considered. 

%% XGB Model Snapshots 
Models snapshots for GBDT models, such as XGBoost models considered here can be obtained without any additional memory costs, unlike snapshots for deep learning models \cite{huang2017snapshot,}.  Therefore, combining model snapshots from XGBoost or other GBDT models can create better predictions with little additional costs. This will be explored in detail in Section \ref{section:NumeraiSunshine-deepIL}. 






\newpage 
\subsection{XGBoost models without early stopping are better}
\label{section:NumeraiSunshine-XGB-EarlyStop}

To demonstrate the benefit of training XGBoost models without early stopping, we compare the deep IL XGBoost models using model snapshots (and thus without early stopping) with deep IL XGBoost models with early stopping as follows. 

We consider three scenarios with different computational budget as above. 

\begin{itemize}
    \item Small:    XGBoost models with 500 boosting rounds and learning rate 0.1
    \item Standard: XGBoost models with 5000 boosting rounds and learning rate 0.01
    \item Large:    XGBoost models with 50000 boosting rounds and learning rate 0.001 
\end{itemize}

The training of Layer 1 XGBoost models is different here. We train 50 XGBoost models with a training and validation size of 585 where each model is retrained every 50th era. The 585 eras of data are split into $75\%$ of training and $25\%$ of validation. Early Stopping is applied at $5\%$ of the maximum number of boosting rounds in each scenario. (Namely, 25 eras for Small, 250 eras for Standard and 2500 for Large). We perform global random feature sampling 10 times to create 10 feature subsets, each with $50\%$ of the 1586 features. For each feature subset, we train 5 models with different random seeds. In total we obtain 50 XGBoost models with different feature subset and random seed combinations. 

These 50 predictions are then combined in Layer 2 similar to the deep IL models above. For every 10th era, a shallow XGBoost model with the following hyperparameters is trained using model predictions from the most recent 185 eras (with suitable data lag). Monotonic constraints are imposed so that we do not assign negative weights to the model predictions. This procedure is repeated for 5 different random seeds. The hyperparameters of the XGBoost models in Layer 2 are as follows: (Grow policy: Depth-wise, Number of boosting rounds: 20, Learning rate: 0.1, Max Depth: 4, No Early Stopping, Min Samples per node: 10, Data subsample: 0.75, Feature subsample by tree: 0.75, Feature subsample by level/node: 1, L1 regularisation: 0, L2 regularisation: 0). 



In Table \ref{table:XGBEarlyStopping}, we show the performance of deep IL XGBoost models \textbf{with} early stopping in the three scenarios with different number of boosting rounds and learning rate. The Mean Corr is lower than that of deep IL XGBoost models  \textbf{without} early stopping in Section \ref{section:NumeraiSunshine-deepIL}. The Calmar ratio is also lower than the corresponding deep IL model in each scenario. It suggests early stopping cannot be used to improve model performances of XGBoost models with shallow trees structure. 


\begin{table}[hbt!]
\begin{tabular}{|c|c|l|l|l|}
\hline
Scenarios & Strategy   & Mean Corr & Sharpe & Calmar \\ \hline
\multirow{2}{*}{Small}    & Deep Incremental & 0.0232   $\pm$  0.0004    & 1.1238 $\pm$  0.0167 & 0.2251  $\pm$  0.0073 \\ \cline{2-5}
                          & Dynamic Best\cite{wong2023online}     & 0.0184        & 1.0174   & 0.1943   \\ \hline
\multirow{2}{*}{Standard} & Deep Incremental & 0.0238    $\pm$  0.0002    & 1.1434 $\pm$  0.0165 & 0.3454 $\pm$  0.0410 \\ \cline{2-5}
                          & Dynamic Best\cite{wong2023online}     & 0.0231     & 1.1671    & 0.3022   \\ \hline
\multirow{2}{*}{Large}    & Deep Incremental & 0.0236    $\pm$  0.0003   & 1.1505 $\pm$  0.0248 & 0.4147 $\pm$  0.0350\\ \cline{2-5}
                          & Dynamic Best\cite{wong2023online}     & 0.0233       & 1.1406   & 0.3398   \\ \hline
\end{tabular}
\smallskip
    \caption{Performance of deep IL XGBoost Models with early stopping in the three scenarios (Small,Standard and Large) on test period  (Eras 901-1050)}
    \label{table:XGBEarlyStopping}
\end{table}



\newpage


\section{Research questions} 


\begin{itemize}
    \item Question 1: Are there better ways to sample data within an era? As sizes of datasets are growing, can we reduce computational time by sampling data within an era without introducing a significant costs to model performances? 
    \item Question 2: Can we reduce correlation between base models in layer 1? Using Feature Set JackKnife Sampling, we train models by removing one of the feature sets at a time to reduce correlation between models. Would applying deep incremental learning on those models further improve performances compared to models trained directly with all the features? 
    \item Question 3: Are the learning rates optimal?  
\end{itemize}


In this section, we will use data from Era 201 onward to train XGBoost models. The training size of models is fixed to 600, including 15 eras of data for embargo. We then report model performances from Era 801 to Era 1070 by the following regimes. 

\begin{itemize}
    \item Validation: Era 801 - Era 885 
    \item Test: Era 901 - Era 1070
    \item Bull: Era 801 - Era 1050
    \item Bear: Era 901 - Era 1070 
\end{itemize}

The validation period is Era 801 to Era 885, which is used for selecting the optimal hyperparameters in the subsequent research questions. We also report performance based on market regimes defined post hoc to understand if models behave differently under different regimes. 



\subsection{Question 1:  Are there better ways to sample data within an era?}
\label{section:NumeraiRain-hyperopt}

Here, we explore two different \textbf{global} data sampling schemes that can be applied to data within an era independently. There are different benefits in using different data sampling schemes in model training. The first is to increase diversity of models. Applying data sampling \textbf{locally} during tree building are shown to improve diversity of trees efficiently. Similarly, applying data sampling  \textbf{globally} can enforce our assumptions on the data structure to the model training process to force models to be less correlated to each other by design. Another reason is to reduce computational time in model training, which is critical as iterative versions of the Numerai datasets has include more features and data eras. 

%% Sampling within era 
We define two different data sampling schemes $S_1,S_2$ as follows. 
\begin{itemize}
    \item $S_1$: Using all the stocks within an era
    \item $S_2$: Using all the stocks with target $y \neq 0.5$, which means select all the stocks that is not equal to the median value of target. On average we obtain around $45\%-55\%$ of stocks in each era. 
    %\item $S_3$: Using $50\%$ of stocks sampled by random within an era without replacement 
    %\item $S_4$: Using $25\%$ of stocks sampled by random within an era without replacement 
\end{itemize}

The reason to remove data with target values equal to the Median value is that these data provide little information in learning the ranking of stocks near the tails, which has a bigger impact on the trading portfolio. In practise, only stocks at the top and bottom of the rankings are traded due to transaction costs. Another reason to use $S_2$ is that it can reduce computational time by half, therefore allowing researchers to train more base models within a deep IL model. 

To demonstrate whether the new data sampling scheme $S_2$ can work well for a wide range of parameter settings for GBDT models, a grid search on two key hyperparameters namely feature sampling per tree and the depth of trees is performed for each data sampling scheme.
\begin{itemize}
    \item Tree depth: 4,6
    \item Ratio of feature sampling per tree: 0.1,0.25,0.5,0.75,0.9 
\end{itemize}
We set all other hyperparameters of the XGBoost models are set to the same as those used in training deep IL models in Chapter \ref{chapter:NumeraiSunshine}. As shown in Chapter \ref{chapter:NumeraiSunshine}, other hyperparameters considered has little impact on model performances, and therefore not included in the grid search. These hyperparameters are fixed as in Chapter \ref{chapter:NumeraiSunshine} Section \ref{section:NumeraiSunshine-HyperOpt}.  The Cartesian product over all combinations of the two hyperparameters gives 10 different hyperparameter settings $G_1, \dots G_{10}$.


The grid search procedure is described in algorithm \ref{alg:Rain-hyperopt}. 

\begin{algorithm}[H]
\caption{Grid Search on hyperparameter settings for XGBoost models}
\label{alg:Rain-hyperopt}
\KwIn{Number of boosting rounds $B$, Training size of Layer 1 $X_1=585$, Data embargo $b=15$}
Set starting Era $D_1=801$ \\
\For{$1 \leq j \leq 2$}{ 
    Prepare training data from Era $D_1-X_1-b$ to $D_1-b$ using one of the data sampling schemes $S_j$ \\
    Set Ansatz learning rate $L = \frac{50}{B}$ \\
    \For{$1 \leq i \leq 10$}{
        Train XGBoost model $M_{i,j}$ with learning rates $L$, hyperparameter setting $G_i$. \\
        Obtain Predictions of models from Era 801 to Era 1070. \\
    }
}
\end{algorithm} 

We run the above procedure for different number of boosting rounds $B$, with $B=500,1000,2500,5000$. Each hyperparameter setting is repeated over 4 times using $25\%$ of eras in training data regularly sampled. In Figure \ref{fig:Rain-EraSampling}, we show the risk metrics of the two data sampling schemes, averaged over 10 different hyperparameters settings under different market regimes for different $B$s. Sampling with all the data $S_1$ achieves better performances in the validation but is not significant in the test period. However, in the test period $S_2$ achieves a better Sharpe and Calmar ratio. 

We then compare the two data sampling schemes under the Bull and Bear market regime, which demonstrates the improvement from $S_2$ in the test period can be mostly attributed to improvement during the Bear market. 

Repeating the above analysis using the optimised model hyperparameters (Tree Depth = 4 and Ratio of feature sampling per tree = 0.75) only, as shown in Figure  \ref{fig:Rain-EraSampling-Ansatz} demonstrated a even smaller performance gap between model performances of $S_1$ and $S_2$. 

The above results suggests using sampling $S_2$ will not lead to a significant deterioration in model performances in bull market and offers valuable hedging benefits during bear market. % We would choose to use $S_2$ to reduce computational time in the following experiments when we need to train a large number of models or the size of models is big.


\begin{figure}[hbt!]
     \centering
        \subfloat[Mean Corr]{
          \includegraphics[width=17.5cm]{figure/chapter4/Rain_Mean_Corr_EraSampling.pdf}
        }
        \\
        \subfloat[Sharpe]{
          \includegraphics[width=17.5cm]{figure/chapter4/Rain_Sharpe_EraSampling.pdf}
        }
        \\
        \subfloat[Calmar]{
          \includegraphics[width=17.5cm]{figure/chapter4/Rain_Calmar_EraSampling.pdf}
        }
        \\
    \caption{Comparing the performances of two data sampling schemes with different number of boosting rounds $B=500,1000,2500,5000$ for risk metrics (a) Mean Corr, (b) Sharpe ratio, (c) Calmar ratio, under different market regimes, over 10 different hyperparameter settings}
    \label{fig:Rain-EraSampling}
\end{figure}




\begin{figure}[hbt!]
     \centering
        \subfloat[Mean Corr]{
          \includegraphics[width=17.5cm]{figure/chapter4/Rain_Mean_Corr_EraSampling_Ansatz.pdf}
        }
        \\
        \subfloat[Sharpe]{
          \includegraphics[width=17.5cm]{figure/chapter4/Rain_Sharpe_EraSampling_Ansatz.pdf}
        }
        \\
        \subfloat[Calmar]{
          \includegraphics[width=17.5cm]{figure/chapter4/Rain_Calmar_EraSampling_Ansatz.pdf}
        }
        \\
    \caption{Comparing the performances of two data sampling schemes with different number of boosting rounds $B=500,1000,2500,5000$ for risk metrics (a) Mean Corr, (b) Sharpe ratio, (c) Calmar ratio, under different market regimes, using the optimised hyperparameters Tree Depth = 4 and Ratio of feature sampling per tree = 0.75.}
    \label{fig:Rain-EraSampling-Ansatz}
\end{figure}





\end{document}



