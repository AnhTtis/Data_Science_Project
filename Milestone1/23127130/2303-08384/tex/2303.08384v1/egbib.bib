@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@inproceedings{jiang2018super,
  title={Super slomo: High quality estimation of multiple intermediate frames for video interpolation},
  author={Jiang, Huaizu and Sun, Deqing and Jampani, Varun and Yang, Ming-Hsuan and Learned-Miller, Erik and Kautz, Jan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9000--9008},
  year={2018}
}

@inproceedings{gao2020flow,
  title={Flow-edge guided video completion},
  author={Gao, Chen and Saraf, Ayush and Huang, Jia-Bin and Kopf, Johannes},
  booktitle={European Conference on Computer Vision},
  pages={713--729},
  year={2020},
  organization={Springer}
}

@inproceedings{sun2018optical,
  title={Optical flow guided feature: A fast and robust motion representation for video action recognition},
  author={Sun, Shuyang and Kuang, Zhanghui and Sheng, Lu and Ouyang, Wanli and Zhang, Wei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1390--1399},
  year={2018}
}

@article{horn1981determining,
  title={Determining optical flow},
  author={Horn, Berthold KP and Schunck, Brian G},
  journal={Artificial intelligence},
  volume={17},
  number={1-3},
  pages={185--203},
  year={1981},
  publisher={Elsevier}
}

@inproceedings{zach2007duality,
  title={A duality based approach for realtime tv-l 1 optical flow},
  author={Zach, Christopher and Pock, Thomas and Bischof, Horst},
  booktitle={Joint pattern recognition symposium},
  pages={214--223},
  year={2007},
  organization={Springer}
}

@inproceedings{chen2016full,
  title={Full flow: Optical flow estimation by global optimization over regular grids},
  author={Chen, Qifeng and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4706--4714},
  year={2016}
}

@inproceedings{dosovitskiy2015flownet,
  title={Flownet: Learning optical flow with convolutional networks},
  author={Dosovitskiy, Alexey and Fischer, Philipp and Ilg, Eddy and Hausser, Philip and Hazirbas, Caner and Golkov, Vladimir and Van Der Smagt, Patrick and Cremers, Daniel and Brox, Thomas},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2758--2766},
  year={2015}
}

@inproceedings{ilg2017flownet,
  title={Flownet 2.0: Evolution of optical flow estimation with deep networks},
  author={Ilg, Eddy and Mayer, Nikolaus and Saikia, Tonmoy and Keuper, Margret and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2462--2470},
  year={2017}
}

@inproceedings{sun2018pwc,
  title={Pwc-net: Cnns for optical flow using pyramid, warping, and cost volume},
  author={Sun, Deqing and Yang, Xiaodong and Liu, Ming-Yu and Kautz, Jan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8934--8943},
  year={2018}
}

@inproceedings{teed2020raft,
  title={Raft: Recurrent all-pairs field transforms for optical flow},
  author={Teed, Zachary and Deng, Jia},
  booktitle={European conference on computer vision},
  pages={402--419},
  year={2020},
  organization={Springer}
}

@inproceedings{ranjan2017optical,
  title={Optical flow estimation using a spatial pyramid network},
  author={Ranjan, Anurag and Black, Michael J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4161--4170},
  year={2017}
}

@inproceedings{jiang2021learning,
  title={Learning to estimate hidden motions with global motion aggregation},
  author={Jiang, Shihao and Campbell, Dylan and Lu, Yao and Li, Hongdong and Hartley, Richard},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9772--9781},
  year={2021}
}

@inproceedings{butler2012naturalistic,
  title={A naturalistic open source movie for optical flow evaluation},
  author={Butler, Daniel J and Wulff, Jonas and Stanley, Garrett B and Black, Michael J},
  booktitle={European conference on computer vision},
  pages={611--625},
  year={2012},
  organization={Springer}
}

@inproceedings{geiger2012we,
  title={Are we ready for autonomous driving? the kitti vision benchmark suite},
  author={Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  pages={3354--3361},
  year={2012},
  organization={IEEE}
}

@inproceedings{mayer2016large,
  title={A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation},
  author={Mayer, Nikolaus and Ilg, Eddy and Hausser, Philip and Fischer, Philipp and Cremers, Daniel and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4040--4048},
  year={2016}
}

@inproceedings{sun2021autoflow,
  title={Autoflow: Learning a better training set for optical flow},
  author={Sun, Deqing and Vlasic, Daniel and Herrmann, Charles and Jampani, Varun and Krainin, Michael and Chang, Huiwen and Zabih, Ramin and Freeman, William T and Liu, Ce},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10093--10102},
  year={2021}
}

@inproceedings{Radford2018ImprovingLU,
  title={Improving Language Understanding by Generative Pre-Training},
  author={Alec Radford and Karthik Narasimhan},
  year={2018}
}

@inproceedings{Radford2019LanguageMA,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019}
}

@article{Brown2020LanguageMA,
  title={Language Models are Few-Shot Learners},
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and T. J. Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeff Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.14165}
}

@article{He2021MaskedAA,
  title={Masked Autoencoders Are Scalable Vision Learners},
  author={Kaiming He and Xinlei Chen and Saining Xie and Yanghao Li and Piotr Doll'ar and Ross B. Girshick},
  journal={ArXiv},
  year={2021},
  volume={abs/2111.06377}
}

@article{Wei2021MaskedFP,
  title={Masked Feature Prediction for Self-Supervised Visual Pre-Training},
  author={Chen Wei and Haoqi Fan and Saining Xie and Chaoxia Wu and Alan Loddon Yuille and Christoph Feichtenhofer},
  journal={ArXiv},
  year={2021},
  volume={abs/2112.09133}
}

@article{Devlin2019BERTPO,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  journal={ArXiv},
  year={2019},
  volume={abs/1810.04805}
}

@article{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Wei, Furu},
  journal={arXiv preprint arXiv:2106.08254},
  year={2021}
}

@article{tong2022videomae,
  title={Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training},
  author={Tong, Zhan and Song, Yibing and Wang, Jue and Wang, Limin},
  journal={arXiv preprint arXiv:2203.12602},
  year={2022}
}

@inproceedings{sun2021loftr,
  title={LoFTR: Detector-free local feature matching with transformers},
  author={Sun, Jiaming and Shen, Zehong and Wang, Yuang and Bao, Hujun and Zhou, Xiaowei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8922--8931},
  year={2021}
}

@article{tang2022quadtree,
  title={Quadtree attention for vision transformers},
  author={Tang, Shitao and Zhang, Jiahui and Zhu, Siyu and Tan, Ping},
  journal={arXiv preprint arXiv:2201.02767},
  year={2022}
}

@inproceedings{truong2020glu,
  title={GLU-Net: Global-local universal network for dense flow and correspondences},
  author={Truong, Prune and Danelljan, Martin and Timofte, Radu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6258--6268},
  year={2020}
}

@inproceedings{dai2017scannet,
    title={ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes},
    author={Dai, Angela and Chang, Angel X. and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
    booktitle = {Proc. Computer Vision and Pattern Recognition (CVPR), IEEE},
    year = {2017}
}

@inproceedings{li2018megadepth,
  title={Megadepth: Learning single-view depth prediction from internet photos},
  author={Li, Zhengqi and Snavely, Noah},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2041--2050},
  year={2018}
}

@inproceedings{black1993framework,
  title={A framework for the robust estimation of optical flow},
  author={Black, Michael J and Anandan, Padmanabhan},
  booktitle={1993 (4th) International Conference on Computer Vision},
  pages={231--236},
  year={1993},
  organization={IEEE}
}

@inproceedings{hui2018liteflownet,
  title={Liteflownet: A lightweight convolutional neural network for optical flow estimation},
  author={Hui, Tak-Wai and Tang, Xiaoou and Loy, Chen Change},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8981--8989},
  year={2018}
}

@inproceedings{hur2019iterative,
  title={Iterative residual refinement for joint optical flow and occlusion estimation},
  author={Hur, Junhwa and Roth, Stefan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5754--5763},
  year={2019}
}

@article{lowe2004distinctive,
  title={Distinctive image features from scale-invariant keypoints},
  author={Lowe, David G},
  journal={International journal of computer vision},
  volume={60},
  number={2},
  pages={91--110},
  year={2004},
  publisher={Springer}
}

@article{revaud2019r2d2,
  title={R2D2: repeatable and reliable detector and descriptor},
  author={Revaud, Jerome and Weinzaepfel, Philippe and De Souza, C{\'e}sar and Pion, Noe and Csurka, Gabriela and Cabon, Yohann and Humenberger, Martin},
  journal={arXiv preprint arXiv:1906.06195},
  year={2019}
}

@inproceedings{sarlin2020superglue,
  title={Superglue: Learning feature matching with graph neural networks},
  author={Sarlin, Paul-Edouard and DeTone, Daniel and Malisiewicz, Tomasz and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4938--4947},
  year={2020}
}

@article{choy2016universal,
  title={Universal correspondence network},
  author={Choy, Christopher B and Gwak, JunYoung and Savarese, Silvio and Chandraker, Manmohan},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{rocco2018neighbourhood,
  title={Neighbourhood consensus networks},
  author={Rocco, Ignacio and Cimpoi, Mircea and Arandjelovi{\'c}, Relja and Torii, Akihiko and Pajdla, Tomas and Sivic, Josef},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{truong2020gocor,
  title={GOCor: Bringing globally optimized correspondence volumes into your neural network},
  author={Truong, Prune and Danelljan, Martin and Gool, Luc V and Timofte, Radu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14278--14290},
  year={2020}
}

@inproceedings{zhao2022global,
  title={Global Matching with Overlapping Attention for Optical Flow Estimation},
  author={Zhao, Shiyu and Zhao, Long and Zhang, Zhixing and Zhou, Enyu and Metaxas, Dimitris},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17592--17601},
  year={2022}
}

@inproceedings{xu2022gmflow,
  title={GMFlow: Learning Optical Flow via Global Matching},
  author={Xu, Haofei and Zhang, Jing and Cai, Jianfei and Rezatofighi, Hamid and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8121--8130},
  year={2022}
}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}

@inproceedings{savva2015semantically,
  title={Semantically-enriched 3D models for common-sense knowledge},
  author={Savva, Manolis and Chang, Angel X and Hanrahan, Pat},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={24--31},
  year={2015}
}


@article{tyszkiewicz2020disk,
  title={DISK: Learning local features with policy gradient},
  author={Tyszkiewicz, Micha{\l} and Fua, Pascal and Trulls, Eduard},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14254--14265},
  year={2020}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{smith2019super,
  title={Super-convergence: Very fast training of neural networks using large learning rates},
  author={Smith, Leslie N and Topin, Nicholay},
  booktitle={Artificial intelligence and machine learning for multi-domain operations applications},
  volume={11006},
  pages={369--386},
  year={2019},
  organization={SPIE}
}

@article{jaegle2021perceiver,
  title={Perceiver io: A general architecture for structured inputs \& outputs},
  author={Jaegle, Andrew and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Doersch, Carl and Ionescu, Catalin and Ding, David and Koppula, Skanda and Zoran, Daniel and Brock, Andrew and Shelhamer, Evan and others},
  journal={arXiv preprint arXiv:2107.14795},
  year={2021}
}

@article{huang2022flowformer,
  title={FlowFormer: A Transformer Architecture for Optical Flow},
  author={Huang, Zhaoyang and Shi, Xiaoyu and Zhang, Chao and Wang, Qiang and Cheung, Ka Chun and Qin, Hongwei and Dai, Jifeng and Li, Hongsheng},
  journal={arXiv preprint arXiv:2203.16194},
  year={2022}
}

@article{chen2022aspanformer,
  title={ASpanFormer: Detector-Free Image Matching with Adaptive Span Transformer},
  author={Chen, Hongkai and Luo, Zixin and Zhou, Lei and Tian, Yurun and Zhen, Mingmin and Fang, Tian and Mckinnon, David and Tsin, Yanghai and Quan, Long},
  journal={arXiv preprint arXiv:2208.14201},
  year={2022}
}

@inproceedings{katharopoulos2020transformers,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International Conference on Machine Learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}

@inproceedings{dong2022incremental,
  title={Incremental transformer structure enhanced image inpainting with masking positional encoding},
  author={Dong, Qiaole and Cao, Chenjie and Fu, Yanwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11358--11368},
  year={2022}
}

@article{cao2022mvsformer,
  title={MVSFormer: Learning Robust Image Representations via Transformers and Temperature-based Depth for Multi-View Stereo},
  author={Cao, Chenjie and Ren, Xinlin and Fu, Yanwei},
  journal={arXiv preprint arXiv:2208.02541},
  year={2022}
}

@inproceedings{sui2022craft,
  title={CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow},
  author={Sui, Xiuchao and Li, Shaohua and Geng, Xue and Wu, Yan and Xu, Xinxing and Liu, Yong and Goh, Rick and Zhu, Hongyuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17602--17611},
  year={2022}
}

@article{park2022vision,
  title={How Do Vision Transformers Work?},
  author={Park, Namuk and Kim, Songkuk},
  journal={arXiv preprint arXiv:2202.06709},
  year={2022}
}

@article{yang2019volumetric,
  title={Volumetric correspondence networks for optical flow},
  author={Yang, Gengshan and Ramanan, Deva},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{zhao2020maskflownet,
  title={Maskflownet: Asymmetric feature matching with learnable occlusion mask},
  author={Zhao, Shengyu and Sheng, Yilun and Dong, Yue and Chang, Eric I and Xu, Yan and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6278--6287},
  year={2020}
}

@article{wang2020displacement,
  title={Displacement-invariant matching cost learning for accurate optical flow estimation},
  author={Wang, Jianyuan and Zhong, Yiran and Dai, Yuchao and Zhang, Kaihao and Ji, Pan and Li, Hongdong},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15220--15231},
  year={2020}
}

@inproceedings{zhang2021separable,
  title={Separable flow: Learning motion cost volumes for optical flow estimation},
  author={Zhang, Feihu and Woodford, Oliver J and Prisacariu, Victor Adrian and Torr, Philip HS},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10807--10817},
  year={2021}
}

@article{hui2020lightweight,
  title={A lightweight optical flow  CNN-Revisiting data fidelity and  regularization},
  author={Hui, Tak-Wai and Tang, Xiaoou and Loy, Chen Change},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={8},
  pages={2555--2569},
  year={2020},
  publisher={IEEE}
}

@article{sun2019models,
  title={Models matter, so does training: An empirical study of cnns for optical flow estimation},
  author={Sun, Deqing and Yang, Xiaodong and Liu, Ming-Yu and Kautz, Jan},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={42},
  number={6},
  pages={1408--1423},
  year={2019},
  publisher={IEEE}
}

@inproceedings{schonberger2016pixelwise,
  title={Pixelwise view selection for unstructured multi-view stereo},
  author={Sch{\"o}nberger, Johannes L and Zheng, Enliang and Frahm, Jan-Michael and Pollefeys, Marc},
  booktitle={European Conference on Computer Vision},
  pages={501--518},
  year={2016},
  organization={Springer}
}

@article{black1996robust,
  title={The robust estimation of multiple motions: Parametric and piecewise-smooth flow fields},
  author={Black, Michael J and Anandan, Paul},
  journal={Computer vision and image understanding},
  volume={63},
  number={1},
  pages={75--104},
  year={1996},
  publisher={Elsevier}
}

@inproceedings{brox2004high,
  title={High accuracy optical flow estimation based on a theory for warping},
  author={Brox, Thomas and Bruhn, Andr{\'e}s and Papenberg, Nils and Weickert, Joachim},
  booktitle={European conference on computer vision},
  pages={25--36},
  year={2004},
  organization={Springer}
}

@article{bruhn2005lucas,
  title={Lucas/Kanade meets Horn/Schunck: Combining local and global optic flow methods},
  author={Bruhn, Andr{\'e}s and Weickert, Joachim and Schn{\"o}rr, Christoph},
  journal={International journal of computer vision},
  volume={61},
  number={3},
  pages={211--231},
  year={2005},
  publisher={Springer}
}

@inproceedings{revaud2015epicflow,
  title={Epicflow: Edge-preserving interpolation of correspondences for optical flow},
  author={Revaud, Jerome and Weinzaepfel, Philippe and Harchaoui, Zaid and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1164--1172},
  year={2015}
}

@InProceedings{Chai2022Any,
author="Chai, Lucy
and Gharbi, Micha{\"e}l
and Shechtman, Eli
and Isola, Phillip
and Zhang, Richard",
editor="Avidan, Shai
and Brostow, Gabriel
and Ciss{\'e}, Moustapha
and Farinella, Giovanni Maria
and Hassner, Tal",
title="Any-Resolution Training for High-Resolution Image Synthesis",
booktitle="Computer Vision -- ECCV 2022",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="170--188",
isbn="978-3-031-19787-1"
}

@article{Caelles_arXiv_2019,
      author    = {Sergi Caelles and
                   Jordi Pont-Tuset and
                   Federico Perazzi and
                   Alberto Montes and
                   Kevis-Kokitsi Maninis and
                   Luc {Van Gool}},
      title     = {The 2019 DAVIS Challenge on VOS: Unsupervised Multi-Object Segmentation},
      journal   = {arXiv},
      year      = {2019}
    }

@INPROCEEDINGS{Aleotti2021Learning,
  author={Aleotti, Filippo and Poggi, Matteo and Mattoccia, Stefano},
  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Learning optical flow from still images}, 
  year={2021},
  volume={},
  number={},
  pages={15196-15206},
  doi={10.1109/CVPR46437.2021.01495}}

@INPROCEEDINGS{Caron2021DINO,
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and Jegou, Herv√© and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Emerging Properties in Self-Supervised Vision Transformers}, 
  year={2021},
  volume={},
  number={},
  pages={9630-9640},
  doi={10.1109/ICCV48922.2021.00951}}

@inproceedings{Chu2021twins,
 author = {Chu, Xiangxiang and Tian, Zhi and Wang, Yuqing and Zhang, Bo and Ren, Haibing and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {9355--9366},
 publisher = {Curran Associates, Inc.},
 title = {Twins: Revisiting the Design of Spatial Attention in Vision Transformers},
 url = {https://proceedings.neurips.cc/paper/2021/file/4e0928de075538c593fbdabb0c5ef2c3-Paper.pdf},
 volume = {34},
 year = {2021}
}

@InProceedings{luo2022learning,
  title={Learning Optical Flow with Adaptive Graph Reasoning},
  author={Luo, Ao and Yang, Fan and Luo, Kunming and Li, Xin and Fan, Haoqiang and Liu, Shuaicheng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  year={2022},
}

@inproceedings{luo2022kpa,
  title={Learning Optical Flow With Kernel Patch Attention},
  author={Luo, Ao and Yang, Fan and Li, Xin and Liu, Shuaicheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8906--8915},
  year={2022}
}

@inproceedings{zheng2022dip,
  title={Dip: Deep inverse patchmatch for high-resolution optical flow},
  author={Zheng, Zihua and Nie, Ni and Ling, Zhi and Xiong, Pengfei and Liu, Jiangyu and Wang, Hao and Li, Jiankun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8925--8934},
  year={2022}
}

@article{sun2022skflow,
  title={SKFlow: Learning Optical Flow with Super Kernels},
  author={Sun, Shangkun and Chen, Yuanqi and Zhu, Yu and Guo, Guodong and Li, Ge},
  journal={arXiv preprint arXiv:2205.14623},
  year={2022}
}
