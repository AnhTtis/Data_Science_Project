@inproceedings{markov2022looper,
  title={Looper: An end-to-end {ML} platform for product decisions},
  author={Markov, Igor L and others},
  booktitle={KDD},
  pages={3513--3523},
  year={2022}
}

@article{kraft2020willump,
  title={Willump: A statistically-aware end-to-end optimizer for machine learning inference},
  author={Kraft, Peter and others},
  journal={MLSys},
  volume={2},
  pages={147--159},
  year={2020}
}

@inproceedings{kohavi1996scaling,
  title={Scaling up the accuracy of naive-{Bayes} classifiers: A decision-tree hybrid.},
  author={Kohavi, Ron and others},
  booktitle={KDD},
  volume={96},
  pages={202--207},
  year={1996}
}

@inproceedings{chen2016xgboost,
  title={{XGB}oost: A scalable tree boosting system},
  author={Chen, Tianqi and Guestrin, Carlos},
  booktitle={KDD},
  pages={785--794},
  year={2016}
}

@article{vu2021picasso,
  title={Picasso: Model-free Feature Visualization},
  author={Vu, Binh and Markov, Igor},
  journal={arXiv preprint arXiv:2111.12795},
  year={2021}
}

@article{shwartz2022tabular,
  title={Tabular data: Deep learning is not all you need},
  author={Shwartz-Ziv, Ravid and Armon, Amitai},
  journal={Information fusion},
  volume={81},
  pages={84--90},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{arik2021tabnet,
  title={{TabNet}: Attentive interpretable tabular learning},
  author={Arik, Sercan {\"O} and Pfister, Tomas},
  booktitle={AAAI conf. on artificial intelligence},
  volume={35},
  number={8},
  pages={6679--6687},
  year={2021}
}

@article{grinsztajn2022tree,
  title={Why do tree-based models still outperform deep learning on tabular data?},
  author={Grinsztajn, L{\'e}o and Oyallon, Edouard and Varoquaux, Ga{\"e}l},
  journal={arXiv preprint arXiv:2207.08815},
  year={2022}
}

@article{gorishniy2021revisiting,
  title={Revisiting deep learning models for tabular data},
  author={Gorishniy, Yury and Rubachev, Ivan and Khrulkov, Valentin and Babenko, Artem},
  journal={NeurIPS},
  volume={34},
  pages={18932--18943},
  year={2021}
}

@article{ding2005minimum,
  title={Minimum redundancy feature selection from microarray gene expression data},
  author={Ding, Chris and Peng, Hanchuan},
  journal={Journal of bioinformatics and computational biology},
  volume={3},
  number={02},
  pages={185--205},
  year={2005},
  publisher={World Scientific}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and others},
  journal={NeurIPS},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  pages={770--778},
  year={2016}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and others},
  journal={NeurIPS},
  volume={30},
  year={2017}
}

@misc{caglar,
  doi = {10.48550/ARXIV.2210.05189},
  url = {https://arxiv.org/abs/2210.05189},
  author = {Aytekin, Caglar},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Neural Networks are Decision Trees},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and others},
  journal={NeurIPS},
  volume={32},
  year={2019}
}

@inproceedings{abadi2016tensorflow,
  title={{TensorFlow}: a system for Large-Scale machine learning},
  author={Abadi, Mart{\'\i}n and others},
  booktitle={OSDI},
  pages={265--283},
  year={2016}
}

@inproceedings{amershi2019software,
  title={Software engineering for machine learning: A case study},
  author={Amershi, Saleema and others},
  booktitle={IEEE/ACM ICSE-SEIP)},
  pages={291--300},
  year={2019},
  organization={IEEE}
}

@article{carbune2018smartchoices,
  title={SmartChoices: hybridizing programming and machine learning},
  author={Carbune, Victor and others},
  journal={arXiv preprint arXiv:1810.00619},
  year={2018}
}

%   organization={IEEE}
@inproceedings{hazelwood2018applied,
  title={Applied machine learning at {Facebook}: A datacenter infrastructure perspective},
  author={Hazelwood, Kim and others},
  booktitle={HPCA},
  pages={620--629},
  year={2018},
}

@article{hermann2017meet,
  title={Meet Michelangelo: Uberâ€™s machine learning platform},
  author={Hermann, Jeremy and Del Balso, Mike},
  journal={URL https://eng. uber. com/michelangelo},
  year={2017}
}

@article{paleyes2020challenges,
  title={Challenges in deploying machine learning: A survey of case studies},
  author={Paleyes, Andrei and Urma, Raoul-Gabriel and Lawrence, Neil D},
  journal={ACM computing surveys (CSUR)},
  year={2020},
  publisher={ACM New York, NY}
}

@inproceedings{sklearn_api,
  author    = {Lars Buitinck and others},
  title     = {{API} design for machine learning software: experiences from the scikit-learn
               project},
  booktitle = {ECML PKDD workshop},
  year      = {2013},
  pages = {108--122},
}

@book{burkov2020machine,
  title={Machine learning engineering},
  author={Burkov, Andriy},
  volume={1},
  year={2020},
  publisher={True positive incorporated}
}

@book{huyen2022designing,
  title={Designing Machine Learning Systems},
  author={Huyen, Chip},
  year={2022},
  publisher={" O'Reilly Media, Inc."}
}

@article{raffa2022global,
  title={The global open source severity of illness score ({GOSSIS})},
  author={Raffa, Jesse D and others},
  journal={Critical care medicine},
  volume={50},
  number={7},
  pages={1040--1050},
  year={2022},
  publisher={Wolters Kluwer}
}

@article{orr2021managing,
  title={Managing {ML} pipelines: feature stores and the coming wave of embedding ecosystems},
  author={Orr, Laurel and others},
  journal={arXiv:2108.05053},
  year={2021}
}

@misc{Dua:2019 ,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@article{samie2020hierarchical,
  title={Hierarchical classification for constrained IoT devices: A case study on human activity recognition},
  author={Samie, Farzad and Bauer, Lars and Henkel, J{\"o}rg},
  journal={IEEE Internet of Things Journal},
  volume={7},
  number={9},
  pages={8287--8295},
  year={2020},
  publisher={IEEE}
}

@inproceedings{park2015big,
  title={Big/little deep neural network for ultra low power inference},
  author={Park, Eunhyeok and Kim, Dongyoung and Kim, Soobeom and Kim, Yong-Deok and Kim, Gunhee and Yoon, Sungroh and Yoo, Sungjoo},
  booktitle={2015 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ ISSS)},
  pages={124--132},
  year={2015},
  organization={IEEE}
}

@inproceedings{daghero2022two,
  title={Two-stage Human Activity Recognition on Microcontrollers with Decision Trees and CNNs},
  author={Daghero, Francesco and Pagliari, Daniele Jahier and Poncino, Massimo},
  booktitle={2022 17th Conference on Ph. D Research in Microelectronics and Electronics (PRIME)},
  pages={173--176},
  year={2022},
  organization={IEEE}
}

@inproceedings{daghero2021adaptive,
  title={Adaptive random forests for energy-efficient inference on microcontrollers},
  author={Daghero, Francesco and Burrello, Alessio and Xie, Chen and Benini, Luca and Calimera, Andrea and Macii, Enrico and Poncino, Massimo and Pagliari, Daniele Jahier},
  booktitle={2021 IFIP/IEEE 29th International Conference on Very Large Scale Integration (VLSI-SoC)},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@article{prokhorenkova2018catboost,
  title={CatBoost: unbiased boosting with categorical features},
  author={Prokhorenkova, Liudmila and Gusev, Gleb and Vorobev, Aleksandr and Dorogush, Anna Veronika and Gulin, Andrey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{ke2017lightgbm,
  title={Lightgbm: A highly efficient gradient boosting decision tree},
  author={Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{carlensstateof,
  title={State of Competitive Machine Learning in 2022},
  author={Carlens, H},
  journal={ML Contests},
  volume={},
  year={2023}
}

@article{gijsbers2019open,
  title={An open source AutoML benchmark},
  author={Gijsbers, Pieter and LeDell, Erin and Thomas, Janek and Poirier, S{\'e}bastien and Bischl, Bernd and Vanschoren, Joaquin},
  journal={arXiv preprint arXiv:1907.00909},
  year={2019}
}

@article{kadra2021well,
  title={Well-tuned simple nets excel on tabular datasets},
  author={Kadra, Arlind and Lindauer, Marius and Hutter, Frank and Grabocka, Josif},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={23928--23941},
  year={2021}
}