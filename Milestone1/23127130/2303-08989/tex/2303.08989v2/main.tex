\documentclass[a4paper]{article}

\usepackage[pages=all, color=black, position={current page.south}, placement=bottom, scale=1, opacity=1, vshift=5mm]{background}
\SetBgContents{
	%\tt This work is shared under a \href{https://creativecommons.org/licenses/by-sa/4.0/}{CC BY-SA 4.0 license} unless otherwise noted
}      % copyright

\usepackage[margin=1in]{geometry} % full-width

% AMS Packages
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

% Unicode
\usepackage[utf8]{inputenc}
\usepackage{hyperref}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{braket}
\usepackage{comment}
\usepackage{enumitem}
\hypersetup{
	unicode,
%	colorlinks,
%	breaklinks,
%	urlcolor=cyan, 
%	linkcolor=blue, 
	pdfauthor={Author One, Author Two, Author Three},
	pdftitle={A simple article template},
	pdfsubject={A simple article template},
	pdfkeywords={article, template, simple},
	pdfproducer={LaTeX},
	pdfcreator={pdflatex}
}

% Vietnamese
%\usepackage{vntex}

% Natbib
\usepackage[sort&compress,numbers,square]{natbib}
\bibliographystyle{mplainnat}

% Theorem, Lemma, etc
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}{Claim}[theorem]
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{hypothesis}[theorem]{Hypothesis}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{criterion}[theorem]{Criterion}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{principle}[theorem]{Principle}

\graphicspath{{fig/}}

%\usepackage[linesnumbered,ruled,vlined,commentsnumbered]{algorithm2e} % use algorithm2e for typesetting algorithms
\usepackage{mathrsfs} % for \mathscr command

% Author info
\title{Quantum Circuit Simulation by SGEMM Emulation on Tensor Cores and Automatic Precision Selection}
%\author{Author One$^1$\thanks{Author One was partially supported by Grant XXX} \and Author Two$^2$ \and Author Three$^1$}
\author{Hiroyuki Ootomo$^1$\and
Hidetaka Manabe$^2$ \and
Kenji Harada$^2$ \and
Rio Yokota$^1$
}

\date{
	$^1$Tokyo Institute of Technology \\ \texttt{ootomo.h@rio.gsic.titech.ac.jp, rioyokota@gsic.titech.ac.jp}\\%
	$^2$Kyoto University \\ \texttt{manabe@acs.i.kyoto-u.ac.jp, harada.kenji.8e@kyoto-u.ac.jp}\\[2ex]%
%	\today
}

\begin{document}
 \maketitle

 \begin{abstract}
 Quantum circuit simulation provides the foundation for the development of quantum algorithms and the verification of quantum supremacy.
Among the various methods for quantum circuit simulation, tensor network contraction has been increasing in popularity due to its ability to simulate a larger number of qubits. 
During tensor contraction, the input tensors are reshaped to matrices and computed by a GEMM operation, where these GEMM operations could reach up to 90\% of the total calculation time.
GEMM throughput can be improved by utilizing mixed-precision hardware such as Tensor Cores,
but straightforward implementation results in insufficient fidelity for deep and large quantum circuits.
Prior work has demonstrated that compensated summation with special care of the rounding mode can fully recover the FP32 precision of SGEMM even when using TF32 or FP16 Tensor Cores.
The exponent range is a critical issue when applying such techniques to quantum circuit simulation.
While TF32 supports almost the same exponent range as FP32, FP16 supports a much smaller exponent range.
In this work, we use the exponent range statistics of input tensor elements to select which Tensor Cores we use for the GEMM.
We evaluate our method on Random Circuit Sampling (RCS), including Sycamore's quantum circuit, and show that the throughput is 1.86 times higher at maximum while maintaining accuracy.

  \noindent\textbf{Keywords:} Quantum circuit simulation, Tensor Cores, Mixed precision
 \end{abstract}

 \section{Introduction}
Quantum circuit simulators are vital for the development of quantum algorithms and verification of \textit{quantum supremacy}, and are considered as one of the key applications for HPC systems in the Exa-scale era \cite{villalonga_establishing_2020,liu_closing_2021,nguyen_tensor_2021}.
In a quantum computer, all operations follow quantum mechanics: preparing qubits (a quantum version of classical bits), applying unitary gates, and measuring qubits to get classical data.
The goal of quantum circuit simulation is to reproduce the classical result obtained by these quantum operations only with a classical computer.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\linewidth]{./images/qc-intro.pdf}
    \caption{An image of quantum circuit simulation using tensor network simulation and the part of the computation that we improve.}
    \label{fig:qc-intro}
\end{figure}
There exist various types of quantum simulators\cite{suzuki_qulacs_2021,jones_quest_2019,treinish_qiskitqiskit_2022-1,guerreschi_intel_2020}. For general circuits dominated by non-Clifford gates, the two types of simulators: 1) state vector and 2) tensor network methods are widely used.
We choose these simulation methods according to the objectives.
The state vector simulations require $2^{n}$ complex values on memory, where $n$ is the number of qubits.
For instance, to simulate Google's Sycamore \cite{arute_quantum_2019-2}, which has 53 qubits, we would require 128 PB of memory.
Since the total memory capacity of the current largest supercomputers is in the order of a few PB, state vector methods are limited by memory capacity.
One advantage of state vector methods is that the computational complexity for a circuit of depth $d$ is $\mathcal{O}(2^{n} \times d)$ and scales linearly with $d$.
Furthermore, there are some studies to reduce the required memory size, such as by splitting the circuit \cite{chen_64-qubit_2018}.
On the other hand, the tensor contraction method \cite{markov_simulating_2008} can simulate several thousands of qubits with low-depth layers at a slightly higher computational cost.
Therefore, tensor contraction is the method of choice for many recent studies that aim to validate quantum supremacy in both quantum computing and high performance computing\cite{markov_quantum_2018,villalonga_establishing_2020,pan2022Simulation}.
In tensor contraction methods, the quantum circuit is represented as a tensor network, where each node represents a quantum gate, and the edge represents the quantum wire, as shown in Fig. \ref{fig:qc-intro}.
The appearance probability of an output bitstring is calculated through the contraction of the tensor network.
Since the computational complexity of the contraction heavily depends on its order of computation, many studies focus on finding the near-optimal contraction order \cite{huang2021Efficient,liang_fast_2021,gray_hyper-optimized_2021,pan2022Simulation}.

The simplest way to compute a tensor contraction is to form nested loops for each tensor index. In practice, the TTGT (Transpose-Transpose-GEMM-Transpose) algorithm is widely used since it can leverage the existing high performance GEMM implementations on various processors such as Intel MKL and NVIDIA cuBLAS.
In this algorithm, the input tensors are first reshaped into matrices, where rows or columns separate the contracted and non-contracted indices.
Then, it computes the matrix multiplication of the input matrices and transposes them to fit into the output tensor if necessary.
Although this approach requires additional memory to store the transposed tensors, it can leverage the high performance GEMM implementation, which can effectively utilize the hierarchical cache and memory of the target processor.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{./images/intro.pdf}
    \caption{{\bf Left:} The comparison of simulation accuracy of a $4 \times 4$ rectangular lattice Random Quantum Circuit simulation for each GEMM precision. TF32TCEC, FP16TCEC, and CUBLAS have single-precision mantissa accuracy, and TF32TC and FP16TC have half-precision. The circuit consists of a Hadamard gate layer ($1+$), $N$-CZ gate layers, and a Hadamard gate layer $(+1)$. {\bf Right:} The throughput comparison of each CGEMM implementation.}
    \label{fig:intro-top}
\end{figure}
The chain of GEMM operations in tensor contraction can be accelerated by improving both the algorithm and implementation.
In terms of algorithmic improvement, Huang \textit{et al.}\cite{huang_implementing_2018} applied Strassen's algorithm to tensor contraction and slightly reduced its computational complexity.
With respect to implementation, leveraging the existing high performance GEMM implementations on Tensor Cores would seem like a natural fit, but quantum circuit simulations require at least single precision accuracy, as we will show later.
Tensor Cores are mixed-precision matrix multiply-add units on NVIDIA GPUs, and have $7.5\sim 15\times$ throughput compared to the standard arithmetic units on NVIDIA A100 GPUs.
Although the data type of input matrices for multiplication are low-precision (FP16 or TF32), the computation inside Tensor Cores is performed in higher-precision (FP32).
However, when we compute an SGEMM on Tensor Cores, we need to convert the input matrices to low precision, which causes accuracy degradation.
Markidis \textit{et al.} propose a method to recover the accuracy through compensated summation, but their method cannot fully recover the FP32 accuracy \cite{markidis_nvidia_2018}.
Our previous study identified the cause of this problem as the rounding mode inside the Tensor Cores, and developed a method that circumvents this issue with minimal performance degradation \cite{ootomo_recovering_2022}.
As a result, this method outperforms the theoretical peak performance of FP32 SIMT Cores on NVIDIA A100 GPUs while the FP32 accuracy is fully recovered.
This method can be applied to TF32 Tensor Core error correction (TF32TCEC) and FP16 Tensor Core error correction (FP16TCEC).
The TF32 version supports almost the same exponent range as FP32, while the FP16 version supports only a limited exponent range but has higher throughput.
Therefore, there is a trade-off between the supported exponent range and throughput.
%left\footnote{Circuit depth $1+N+1$ means $1$ Hadamard layer, $N$ CZ layer and $1$ Hadamard layer\cite{boixo_characterizing_2018}.}ï¼Ž
In the case of quantum circuit simulation using tensor network contraction, it is difficult to compute the simulation in high precision on Tensor Cores without the error correction when the number of computations is large, as shown in Fig. \ref{fig:intro-top}.
Therefore, error correction is necessary when using Tensor Cores for the simulation.
However, it is difficult to determine which tensor contraction requires TF32TCEC or if FP16TCEC is sufficient.
To the extent of the authors' knowledge, there is no framework for automatically selecting between these two operations.
Although Liu \textit{et al.} use a dynamic scaling method for FP16 computation in the simulation, they select the parts to be computed with FP16 heuristically \cite{liu_closing_2021} by performing an analysis of the tensor network contraction a priori.
Furthermore, their method causes overflow in some cases, which causes the entire computation to fail.

In the present work, we drastically improve the throughput of quantum circuit simulation while retaining sufficient accuracy by using the SGEMM emulation on Tensor Cores and automatic precision selection.
To select between TF32TCEC and FP16TCEC for each tensor contraction, we use the exponent statistics of elements in the input matrices measured before the GEMM operation.
%The overhead of calculating the exponent statistics is enough smaller than the GEMM operation.
%Although we can use the scaling technique to reduce the underflow as \cite{liu_closing_2021}, it does not work when the exponent values of an input are widely distributed.
%And in general, we can not know the distribution before the computation.
%Therefore, we use the precision selection method to avoid the underflow for general quantum circuit simulation.

The summary of our contributions is as follows:
\begin{enumerate}
    \item We develop a library for SGEMM emulation on Tensor Cores, cuMpSGEMM, that can be used without any change to the source code of the target applications.
    This library intercepts SGEMM function calls of the cuBLAS dynamic library and executes the SGEMM emulation on Tensor Cores instead, and surpasses the performance of SGEMM while fully retaining the accuracy.
    This library is not limited to quantum circuit simulation and can be used for any other application that calls cuBLAS SGEMM, CGEMM, and their batched variants and is open-source and available on GitHub\footnote{\url{https://github.com/enp1s0/cuMpSGEMM}}.
    %The choice between TF32TCEC and FP16TCEC can be controlled through an environment variable.

    \item We develop a method to select the GEMM precision, TF32TCEC, FP16TCEC, or FP16TCEC with scaling, for improving the throughput by taking the exponent statistics of input matrix elements before the GEMM operation.
    We have tested our method on a random tensor network contraction and confirmed that it successfully avoids the underflow error with a slight overhead.
    \item We evaluate the accuracy and throughput of Random Circuit Sampling (RCS) simulation, including Sycamore's quantum circuit.
    In RCS, our method improves the throughput by $1.86$ times for a quantum circuit of $9 \times 9$, depth=$33$, and $1.44$ times for the Sycamore circuit while retaining the accuracy of the baseline implementation.
\end{enumerate}

\section{Background}


\subsection{NVIDIA Tensor Core and SGEMM emulation}
NVIDIA Tensor Core computes a matrix multiplication and addition,
\begin{equation}
    \mathbf{D}_\text{F32} \leftarrow \mathbf{A}_\text{low}\cdot\mathbf{B}_\text{low}+\mathbf{C}_\text{F32},
\end{equation}
where the subscript denotes the data type of the matrix: the ``low" is low-precision, FP16 or TF32, and ``F32" is FP32.
Although $\mathbf{A}_\text{low}$ and $\mathbf{B}_\text{low}$ are low-precision, the multiplications and additions are computed in FP32.
However, when it comes to computing single-precision matrix multiplication on Tensor Cores, we must convert the input matrices from single-precision to low-precision, which causes a loss of accuracy in the final computation result.
To recover the loss of accuracy, Markidis \textit{et al.} propose an error correction method based on compensated summation \cite{markidis_nvidia_2018}, but their method does not recover the full FP32 accuracy.
Our previous study improves upon this method by avoiding the rounding inside Tensor Cores and can recover the full FP32 accuracy with minimum overhead\cite{ootomo_recovering_2022}.
In our method, a single-precision matrix-multiplication $\mathbf{C}_\text{F32}\leftarrow\mathbf{A}_\text{F32}\cdot\mathbf{B}_\text{F32}$ is computed approximately as follows.
\begin{align}
    \mathbf{A}_\text{low} &\leftarrow \text{toLow}\left(\mathbf{A}_\text{F32}\right) \nonumber \\
    \Delta\mathbf{A}_\text{low} &\leftarrow \text{toLow}\left(\left(\mathbf{A}_\text{F32}-\text{toF32}\left(\mathbf{A}_\text{low}\right)\right)\times 2^{11}\right) \nonumber \\
    \mathbf{B}_\text{low} &\leftarrow \text{toLow}\left(\mathbf{B}_\text{F32}\right) \nonumber \\
    \Delta\mathbf{B}_\text{low} &\leftarrow \text{toLow}\left(\left(\mathbf{B}_\text{F32}-\text{toF32}\left(\mathbf{B}_\text{low}\right)\right)\times 2^{11}\right) \nonumber \\
    \label{eq:tcec-last}
    \mathbf{C}_\text{F32} &\approx \mathbf{A}_\text{low} \cdot \mathbf{B}_\text{low} + \left(\Delta\mathbf{A}_\text{low} \cdot \mathbf{B}_\text{low} + \mathbf{A}_\text{low} \cdot \Delta\mathbf{B}_\text{low}\right)/2^{11},
\end{align}
where ``toLow" is the conversion from FP32 to low-precision and ``toF32" is from low-precision to FP32.
In this scheme, each matrix element in $\mathbf{A}_\text{F32}$ and $\mathbf{B}_\text{F32}$ is split into two low-precision elements in $\mathbf{A}_\text{low}, \mathbf{B}_\text{low}$ and $\Delta\mathbf{A}_\text{low}, \Delta\mathbf{B}_\text{low}$, respectively.
Then the single-precision matrix multiplication is computed approximately in Eq. (\ref{eq:tcec-last}) using Tensor Cores, where the multiplication and addition are performed on specialized arithmetic units in a precision that is equivalent to FP32.
Furthermore, this method uses FP32 SIMT Cores for addition with RN (Round to Nearest, ties to even) mode for $\mathbf{A}_\text{low} \cdot \mathbf{B}_\text{low}$ to avoid the RZ (Round toward Zero) rounding inside Tensor Cores.
We show the matrix-matrix multiplication implementations and their supporting input accuracy in Table \ref{tab:gemm-implementation-table}.
When we use TF32 for the input type of Tensor Cores, we can emulate the single-precision matrix multiplication in both the mantissa and exponent (TF32TCEC).
On the other hand, when we use FP16 for the low-precision, the supported exponent range of the input matrices is limited (FP16TCEC).
However, the theoretical peak performance of FP16TCEC is higher than TF32TCEC, as shown in the table.
Therefore, there is a trade-off between the supported exponent range and the throughput.
We can achieve a higher throughput using FP16TCEC without loss of accuracy if the elements of the input matrices are in the supported representation range.
Furthermore, we can use these SGEMM emulation methods for a single-precision tensor contraction.
In the TTGT algorithm, the input tensors are reshaped to matrices, and the contraction is computed as matrix multiplication.
Thus, improving the throughput of GEMM leads to improving the throughput of tensor contraction.

\begin{table}[t]
\centering
\begin{tabular}{cc|cc}
                      &    & \multicolumn{2}{c}{Input type of Tensor Core}                                                                                                                                                              \\
                      &    & \multicolumn{1}{c|}{TF32}                                                                            & FP16                                                                                  \\
                      \hline
\multirow{4}{*}{\begin{tabular}[c]{@{}c@{}}Error \\ correction\end{tabular}} & Yes & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}{\bf TF32TCEC}\\ Exponent:FP32, Mantissa:FP32\\ {[}52 TFlop/s{]}\end{tabular}}  & \begin{tabular}[c]{@{}c@{}}{\bf FP16TCEC} \\Exponent:FP16, Mantissa:FP32\\ {[}104 TFlop/s{]}\end{tabular} \\ \cline{2-4} 
                      & No & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}{\bf TF32TC} \\Exponent:FP32, Mantissa:FP16\\ {[}156 TFlop/s{]}\end{tabular}} & \begin{tabular}[c]{@{}c@{}}{\bf FP16TC} \\Exponent:FP16, Mantissa:FP16\\ {[}312 TFlop/s{]}\end{tabular}      
\end{tabular}
\caption{The comparison of GEMM implementations using Tensor Cores on NVIDIA A100 GPU. Each throughput represents theoretical peak performance and is calculated by an assumption that the Tensor Core instruction is issued every clock.}

\label{tab:gemm-implementation-table}
\end{table}

\subsection{Quantum circuit simulation and tensor network contraction}
%A quantum circuit\footnote{See \cite{nielsen2010Quantum} for more information about quantum computation.} consists of quantum gates and wires, as shown in Fig. \ref{fig:qc-intro} (a), which is similar to a classical logic circuit.
A quantum circuit consists of quantum gates and wires, as shown in Fig. \ref{fig:qc-intro} (a), similar to a classical logic circuit.
A quantum state of $n$ qubits is represented as a normalized complex vector of length $2^n$.
For instance, a typical $1$-qubit state called \textit{computational basis states} is represented as $\ket{0}:=(1, 0)^\mathsf{T}$ and $\ket{1}:=(0, 1)^\mathsf{T}$.
The quantum gate for $k$ qubits is represented as a $2^k \times 2^k$ unitary matrix.
For instance, the Hadamard gate, which is one of the single-qubit gates, is represented as $\mathbf{H}=\begin{bmatrix}1 & 1 \\ 1 & -1\end{bmatrix}/\sqrt{2}$, and T gate is $\mathbf{T}=\begin{bmatrix} 1 & 0 \\ 0 & \text{exp}(i\pi/4)\end{bmatrix}$, where $i$ is the imaginary unit.
The change of the quantum states by applying a quantum gate is represented as a multiplication of the quantum gate matrix and the state vector of the quantum states.
For instance, applying the Hadamard gate to the quantum state $\ket{0}$, we obtain the new state as follows:
$$
    \ket\psi = \mathbf{H}\ket{0}=\frac{1}{\sqrt{2}}
\left(
\begin{array}{c}
1 \\
1 \\
\end{array}
\right).
$$
The quantum state is a superposition state, from which we can not extract information directly.
Instead, we conduct \textit{measurements} to get the information of the quantum state indirectly.
In the case of an $n$-qubits system, a quantum state $\ket{\phi}$ is a superposition of $2^n$ states, $\ket{00\cdots 00}, \ket{00\cdots 01}, \cdots, \ket{11\cdots 11}$ in the computational basis, and represented as follows:
$$
\ket{\phi} = \sum_{j=00\cdots 00}^{11\cdots 11} \alpha_j \ket{j},
$$
where $\alpha_j$ is called the \textit{amplitude} of the state $\ket{j}$ and $\sum_{j=00\cdots 00}^{11\cdots 11} |\alpha_j|^2 = 1$.
When measuring the state $\ket{\phi}$, we obtain an $n$-length bitstring $j$ with a probability $|\alpha_j|^2$.
We conduct the measurements many times and obtain the distribution of the output bitstrings to extract the information of the quantum state.
In contrast, the quantum circuit simulation directly calculates the amplitude of given bitstrings.
However, calculating the amplitude of a large qubit system and circuit generally requires large computational costs and memory.

%We can obtain some classical information about the quantum state by measurements. If we measure the quantum state $\ket\psi$ in the computational basis, bitstring $x$ is measured with the probability  $|\braket{x|\psi}|^2$, where $\ket{x}$ is the computational basis states. 

\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{./images_manabe/TN.pdf}
    \caption{An example of the tensor network diagram.}
    \label{fig:TN}
\end{figure}

One of the methods to compute the amplitude is tensor network contraction.
%A quantum circuit can be rewritten naturally as a tensor network \footnote{See \cite{bridgeman2017Handwaving} for an introduction to the tensor network method.}.
A simple example of tensor network formalism is shown in Fig. \ref{fig:TN}. A rank-$r$ tensor, which is an element of $\mathbb{C}^{d_1\times\cdots\times d_r}$ with indices of dimension $d_i$, is represented as a node with $r$ edges. The connection of the edges in a network corresponds to Einstein's summation over the corresponding index.
A quantum circuit can be represented as a tensor network.
The initial state $\ket{00 \cdots 00}$ and the measuring state $\ket{x}$ are a set of rank-$1$ tensors, $n$-qubits gates are rank-$2n$ tensors, and the wires represent contraction.
The amplitude is calculated by the contraction of the whole tensor network.
Therefore, the primary workload of the quantum circuit simulation by the tensor network contraction is GEMM.

The time complexity of a tensor network contraction strongly depends on its contraction order or \textit{contraction path}.
In the example in Fig. \ref{fig:TN}, calculating in order $$
\sum_{jkm=1}^dA_{ijk}B_{jlm}C_{km}=\sum_{km}C_{km}\left(\sum_{j}A_{ijk}B_{jlm}\right)
$$
requires computational complexity $\mathcal{O}(d^5)$.
On the other hand,
$$
\sum_{jkm=1}^dA_{ijk}B_{jlm}C_{km}=\sum_{j}\left(\sum_{km}A_{ijk}B_{jlm}C_{km}\right)
$$
requires only $\mathcal{O}(d^4)$.
In general, finding the optimal contraction path is NP-complete\cite{chi-chung1997Optimizing} and even contracting the entire tensor network is \#P-complete\cite{schuch2007Computational}.
Therefore, there is no evidence that quantum circuit simulators by the tensor network contraction method perform well.
However, in practice, by using advanced techniques such as hyperparameter optimization and hypergraph partitioning to find a near-optimal contraction order and by massively distributing the computation, the tensor network methods outperform the state vector method, especially for systems with large qubits and shallow circuits\cite{huang2021Efficient, gray_hyper-optimized_2021, liu_closing_2021,pan2022Solving}.
For instance, \cite{liu_closing_2021} performed the Sycamore simulation in only 304 seconds by carefully selecting the contraction path and parallelizing on tens of millions of CPU cores.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{./images/4x4-depth-eval.pdf}
    \caption{The evaluation of numerical error of $4\times 4$ Random Quantum Circuit simulation.}
    \label{fig:4x4-fidelity}
\end{figure}
The computation of tensor network contraction for quantum circuit simulation is performed in single precision.
For the computation of an $n$-qubit circuit simulation, it is required to be able to represent $2^{-(n-1)/2}$ by a floating point value at least to represent the resulting amplitude.
Therefore, FP16, which only has 5 bits of the exponent, is insufficient.
From the perspective of mantissa accuracy, we also need single precision.
We show the numerical accuracy of a quantum circuit simulation in Fig. \ref{fig:4x4-fidelity}, where the qubits are arranged in a $4 \times 4$ rectangular lattice, and the quantum circuit is RQC explained later in Sec. \ref{sec:rqc}.
%We use a quantum circuit where qubits are aligned as a $4 \times 4$ 2D lattice, and the gate sequence is generated for quantum supremacy evaluation \cite{boixo_characterizing_2018,markov_quantum_2018}.
Since the number of qubits $4 \times 4$ is small enough for using FP16 in terms of the exponent range, we can ignore the underflow error and evaluate only the effect of mantissa accuracy.
As we can see in the graph, the numerical errors of TF32TC and FP16TC are larger than the others.
This results in worse simulation accuracy (fidelity) in Fig. \ref{fig:intro-top}, even for relatively shallow circuits.
Therefore, using low-mantissa-length arithmetics without error correction is unsuitable for quantum circuit simulation.

\section{SGEMM emulation library on Tensor Cores}
\label{sec:sgemm-library}
We have implemented an SGEMM emulation library, cuMpSGEMM, that can be used in existing applications that call the NVIDIA cuBLAS SGEMM without modifying the source code of the applications.
The implementation is made from scratch using NVIDIA WMMA API (Tensor Core device API), and WMMA API extension library \cite{ootomo_reducing_2023}.
This library supports single-precision real and complex GEMM (SGEMM/CGEMM) and their batched variants.
We extend the SGEMM emulation to CGEMM by decomposing the real part and imaginary part of the input matrices and computing it as 4 SGEMMs as follows:
\begin{align*}
    \mathbf{C}_\text{F32}^\text{complex} \leftarrow& \mathbf{A}_\text{F32}^\text{complex} \cdot \mathbf{B}_\text{F32}^\text{complex} \\
    =& \left(\mathbf{A}_\text{F32}^\text{real} \cdot \mathbf{B}_\text{F32}^\text{real} - \mathbf{A}_\text{F32}^\text{imag} \cdot \mathbf{B}_\text{F32}^\text{imag}\right)
    +\left(\mathbf{A}_\text{F32}^\text{real} \cdot \mathbf{B}_\text{F32}^\text{imag} + \mathbf{A}_\text{F32}^\text{real} \cdot \mathbf{B}_\text{F32}^\text{imag}\right)i.
\end{align*}
This library intercepts the function calls to cuBLAS SGEMM functions and executes the SGEMM emulation functions instead of the original functions.
Therefore, we can use the SGEMM emulation without changing the source code of the target application if the application uses the cuBLAS dynamic library.
All we need to do is to build the library, set an environmental variable {\tt LD\_PRELOAD}, and execute the target application as usual.
We have confirmed that this library can intercept cuBLAS calls in PyTorch \cite{paszke_pytorch_2019}, CuPy \cite{okuta_cupy_2017}, and our custom applications just by following these steps.
The different implementations shown in Table \ref{tab:gemm-implementation-table} can be selected by defining an environment variable.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.85\linewidth]{./images/gemm-unit-eval.pdf}
    \caption{The accuracy and throughput of the CGEMM implementation on Tensor Cores using the error correction method.}
    \label{fig:gemm-eval}
\end{figure}
We perform a unit test for our CGEMM implementation as shown in Fig. \ref{fig:gemm-eval}.
We denote the shape of GEMM as $(m, n, k)$, which is the multiplication of $m \times k$ and $k \times n$ matrices.
To measure the accuracy, we calculate a relative error of a single-precision complex matrix-matrix multiplication $\mathbf{C}_\text{F32} \leftarrow \mathbf{A}_\text{F32} \cdot \mathbf{B}_\text{F32}$ as follows:
\begin{equation}
    \text{Relative Error} = ||\mathbf{C}_\text{F32} - \mathbf{C}_\text{F64}||_F/||\mathbf{C}_\text{F64}||_F,
\end{equation}
where $\mathbf{C}_\text{F64}$ is the result in FP64, and each element of $\mathbf{A}_\text{F32}$ and $\mathbf{B}_\text{F32}$ is chosen from a uniform distribution $(-1, 1)$.
Since the values are in the order of $10^{-7} \sim 10^{-6}$ for each matrix size, FP32 is sufficient, but FP16 is not.
To evaluate the throughput, we measure the computing time and calculate the throughput.
The maximum throughput of FP16TCEC and TF32TCEC are 54.2 [TFlop/s] and 31.0 [TFlop/s], respectively. This performance is almost identical to the TCEC-SGEMM implementation using NVIDIA CUTLASS \cite{ootomo_recovering_2022}.

\section{Automatic precision selection}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{./images/exp_stats-example.pdf}
    \caption{The overview of the automatic kernel selection by the exponent statistics of the input matrices.}
    \label{fig:exp-stats-example}
\end{figure}

Although FP16TCEC supports a limited exponent range compared to TF32TCEC, it is faster than TF32TCEC.
Therefore, we can improve SGEMM throughput by selecting FP16TCEC when its accuracy loss is permissible.
However, it is generally impossible to predetermine whether FP16TCEC is tolerable before the actual computation.
To check the tolerance, we take the statistics of the exponent distribution of the input matrices before the GEMM operation, as shown in Fig. \ref{fig:exp-stats-example}, and select the GEMM computing mode dynamically.
In addition to FP16TCEC and TF32TCEC, we can select {\bf FP16TCEC w/ scaling} mode.
This mode can be used when the required exponent range is sufficient for FP16, even when the values themselves are small enough to underflow in FP16.
This requires an additional overhead for scaling all elements in the input and output matrices.

The challenge in implementing the automatic precision selection method is to get the statistics correct while keeping its computational overhead negligibly small relative to the GEMM computing time.
To achieve this, we adopt two strategies as follows:
\begin{itemize}
    \item We check all elements in the matrix to take the statistics.
    Although we can reduce the overhead by sampling only part of the elements, this can lead to overflow in some cases.
    We check all elements to prevent overflow and compute the tensor contraction correctly.
    \item We do not transfer the statistics data from GPU to CPU to minimize the overhead.
    Although we need the exponent statistics to control which GEMM kernel we use, it results in an additional overhead for synchronizing CUDA kernels and sending the statistics data on the device memory to host memory.
    To reduce the overhead, we preemptively launch all CUDA kernels and kill some if they are not necessary instead of controlling the kernels to be launched.
\end{itemize}
We explain the detail of the two components above in the following sections.

\subsection{Exponent statistics and computing mode selection rule}
\label{sec:mode-selection-rule}
To determine that a given tensor can tolerate FP16TCEC or FP16TCEC w/ scaling, we take the exponent statistics of each element in two stages.
\begin{enumerate}[label=Stage \arabic*:, leftmargin=*]
    \item Obtain the number of elements that are larger than the minimum value of FP16 ($N_1$) and the max value of the exponent ($e_\text{max}$).
    When $N_1$ is larger than the underflow admissibility threshold, we mark the matrix that can tolerate FP16TCEC and skip the next stage.
    \item Obtain the number of elements within the shifted FP16 exponent range ($N_2$), where the range is shifted so that the maximum exponent becomes $14$, which is the maximum exponent value of FP16.
    When $N_2$ is larger than the threshold, we mark the matrix that can tolerate FP16TCEC w/ scaling; otherwise, we use TF32TCEC.
\end{enumerate}
The threshold is shared in the two stages above and can control the accuracy of the tensor contraction.
We check the tolerance for both input matrices.
When either input matrix can not tolerate FP16TCEC and FP16TCEC w/ scaling, we use TF32TCEC for the GEMM operation.
When either of the input matrices can not tolerate FP16TCEC, we use FP16TCEC w/ scaling.
Otherwise, we use FP16TCEC.
Note that we only check the underflow since the absolute values of all real and imaginary values of tensor elements in the quantum circuit simulation are smaller or equal to $1$. 

\subsection{Dynamic kernel selection}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{./images/automatic-kernel-selection-flow.pdf}
    \caption{
    The dynamic kernel selection mechanism to compute a tensor contraction (TTGT) using the {\tt mode flag buffer} on the device memory.
    }
    \label{fig:ttgt-w-exp-stats}
\end{figure}
We select the GEMM kernel function depending on the result of the exponent statistics of two input matrices.
The simplest way to realize this is to offload the statistics to the host and launch the selected GEMM kernel function.
However, this requires GPU-to-host data transfer and may result in throughput degradation.
Although NVIDIA provides the Dynamic Parallelism API for such situations that can launch a kernel function from another, we can not use this API since there is a limitation related to the dynamic shared memory size configuration we use.
Instead, we use another method: we launch all CUDA kernel functions possibly used and kill some if they are not.
For instance, we launch both TF32TCEC and FP16TCEC kernel functions, but one of them exits at the beginning of the execution by checking the computing mode flag on the device memory.
The entire flow of execution is shown in Fig. \ref{fig:ttgt-w-exp-stats}.
We use two buffers on the device memory to control the kernel execution, {\tt exp stats buffer} and {\tt mode flag buffer}.
The kernel function for taking the exponent statistics stores $N_1, N_2$ and $e_\text{max}$ on {\tt exp stats buffer} and the tolerance on {\tt mode flag buffer}.
Based on the {\tt mode flag}s of input matrices, the GEMM mode selection kernel ({\tt select kernel}) selects the computing mode by the selection rule in \ref{sec:mode-selection-rule}.
When the mode is FP16TCEC w/ scaling, the scaling kernel ({\tt scale}) scales the matrix elements so that the maximum exponent value becomes $14$, and after computing the GEMM operation in FP16TCEC, we scale the resulting matrix to balance out.
Note that we do not restore the scaled input matrices since they are not reused in the quantum circuit simulation\footnote{The library itself has an optional functionality to restore the scaled input matrices for general purpose.}.

\subsection{The overhead of the exponent statistics}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{./images/exp-stats-overhead.pdf}
    \caption{
    {\bf Left: } The bandwidth efficiency of the exponent statistics and scaling kernel function.
    {\bf Right: } The breakdown of the automatic precision selection in the case where FP16TCEC is selected.}
    \label{fig:exp-stats-overhead}
\end{figure}
The operations for taking the exponent statistics and scaling elements are memory bandwidth intensive.
We have measured their throughput efficiency shown on the left side of Fig. \ref{fig:exp-stats-overhead}.
When the matrix size is large, they achieve more than 90 \% of the theoretical peak throughput.
In the case of $n=2^{11}$, the throughput of the {\tt Scaling A/B} kernel function outperforms the theoretical bandwidth since the data is on the L2 cache, since it is loaded in the {\tt Exp stats 2} kernel function executed just prior to it.
We have also investigated the time breakdown of the automatic precision selection shown on the right of Fig. \ref{fig:ttgt-w-exp-stats}.
When the matrix size is small, the overheads of the automatic precision selection and the scaling operation are not negligible.
Therefore, we use the following rule for automatic precision selection when the matrix size is large:
\begin{itemize}
    \item When $m, n, k \geq 2048$: Use the automatic precision selection.
    \item Otherwise and when $m, n, k \geq 512$: Use TF32TCEC.
    \item Otherwise: Use cuBLAS.
\end{itemize}


\section{Experiment}
\subsection{Preparation}
\subsubsection{Quantum circuit simulation on GPU}
We use the Python library TensorNetwork \cite{roberts2019TensorNetwork}, and quimb \cite{gray_quimb_2018} for the quantum circuit simulation using the tensor network contraction, cotengra \cite{gray_hyper-optimized_2021}, kahypar \cite{schlag2022HighQuality} and  opt\_einsum \cite{g.a.smith2018Opt} for path optimization, and CuPy \cite{okuta_cupy_2017} for the computational backend on GPUs.
%The CuPy is a NumPy/SciPy-compatible scientific numerical computation library on GPU.
%To find a better contraction path of the tensor network, we search for the minimum computing time path based on the achieved Flop/s table instead of finding the minimum floating point operations path.
Although there are several quantum circuit simulators such as NVIDIA cuTensorNet\footnote{\url{https://docs.nvidia.com/cuda/cuquantum/cutensornet/index.html}}, it is not possible to perform a fair comparison against them since their method to avoid explicit transposing on device memory is not open-source.
While our method focuses on improving the CGEMM throughput after transposing input tensors, cuTensor, which is used in cuTensorNet for the tensor contraction, focuses on reducing data movement by avoiding explicit transposing on device memory, etc.
Therefore, technically, we can apply our method to cuTensorNet if it is open-source.
We have confirmed experimentally that cuTensorNet is faster than our methods depending on the problem sizes and contraction paths since the GEMM and transposition time ratio vary.

\subsubsection{Fast implementation for irregular shaped GEMM}
\label{sec:irregular-shaped-gemm}
In quantum circuit simulation, the irregular shape of GEMMs, for instance, $(2, 2^N, 2)$ and $(2^N, 2, 2)$ for $N \geq 10$, are computed many times for the contraction of a single-qubit gate tensor.
However, the cuBLAS CGEMM function for these shapes is not optimized.
The memory bandwidth bounds the throughput of the GEMMs for these shapes.
We have implemented specialized CGEMM kernel functions for these shapes and achieved up to $90$\% of the theoretical device memory bandwidth on A100 GPU, while that of cuBLAS is $10$\%.
We enable this kernel function in all experiments in all computing modes, including the baseline CUBLAS mode.


%\subsubsection{cuBLAS function profiling library}
%Identifying a target application's hotspots is critical to optimize its performance.
%We have implemented a library for measuring the computing time of cuBLAS functions.
%NVIDIA profilers such as Nsight Systems measure each kernel function's computing time.
%However, kernel functions with the same name are executed for different matrix sizes, and we can not determine which shape of GEMM takes how long of computing time using the profilers.
%We develop a library that measures the computing time for each cuBLAS function and can address the issue.
%It can be used only by setting the environmental variable {\tt LD\_PRELOAD}, as same as the SGEMM library in Sec. \ref{sec:sgemm-library}, and automatically measures the computing time.
%It is available on GitHub \footnote{\url{https://github.com/xxx/xxx}}.
\subsection{Exploratory experiment}
\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{./images/randtn-eval.pdf}
    \caption{The computing time (top) and accuracy (bottom) of a random tensor network contraction for different types of element initializations.}
    \label{fig:randtn-result}
\end{figure}
We check the behavior of the automatic precision selection on a tensor network contraction which is randomly constructed.
The tensor network consists of 10 nodes with $2 \sim 4$ degrees.
Each dimension of the tensors is 128, and all elements are initialized as follows.
\begin{enumerate}[label=Type-\arabic*:, leftmargin=*]
    \item With standard distribution $\mathcal{N}(0, 10^{-4})$.
    All computing modes can compute with high accuracy.
    \item After Type-1 initialization, all elements are scaled $10^{-6}$.
    FP16TCEC can not compute with high accuracy without scaling.
    \item After Type-2 initialization, set $10\sim 20$ elements $1$.
    FP16TCEC can not compute with high accuracy, even with scaling.
\end{enumerate}
The accuracy is the error relative to FP64 computation.
We denote our method as AUTO-$t$, where $t$ is the underflow tolerance threshold.
For instance, when $t=0$, the mode that can avoid all underflows is selected.
We show the computing time and accuracy in Fig. \ref{fig:randtn-result}.
Throughout all types, the AUTO modes select the proper computing mode to avoid underflow automatically, and their computing accuracy is close to the same level as the baseline (CUBLAS).
In Type-2, the computing time of AUTO-$0.5$ is shorter than AUTO-$0.1$ since it selects different computing modes while maintaining accuracy.
That implies that the underflow tolerance is being used in some cases.
However, it is not feasible to find an appropriate tolerance value $t$ since it is also related to the positional distribution of the input matrix elements, such as sparsity.
In Type-2 and 3, the accuracy of FP16TCEC underflows to zero.
Although the median error of TF32TCEC, AUTO, and FP16TCEC w/ scaling is larger than the baseline by about 2 bits of mantissa, we consider that the cause is computation order, and the accuracy is considered sufficiently single-precision.
However, each result of FP16TCEC w/ scaling sometimes underflows to zero or has low accuracy.
In summary, we have confirmed that the AUTO mode automatically selects high throughput computing mode while achieving the same level of accuracy as the baseline.

\subsection{Random Quantum Circuit simulation}
\label{sec:rqc}

%In this study, we treat random quantum circuits as an example of quantum circuit simulation.
We evaluate the automatic precision selection on the Random Circuit Sampling (RCS) problem\cite{boixo_characterizing_2018}, which is the task to demonstrate the so-called \textit{quantum advantage}\cite{preskill2012Quantum}.
In the RCS problem, we sample the output bitstrings of a random quantum circuit (RQC) $U$.
The bitstring $x$ follows the distribution:
%Given a set of random quantum circuits $\mathcal{U}$ on $n$ qubits and a circuit $U \in \mathcal{U}$, a bitstring $x$ of length $n$ is sampled according with a probability distribution:
\begin{equation}
    \label{eq:prob_dist}
    p_U(x):=|\braket{x|U|0}|^2,
\end{equation}
where $p_U(x)$ is the appearance probability of $x$.
On a quantum device, the sampling can be accomplished by preparing an initial zero state, applying a unitary circuit $U$, and measuring each qubit on a computational basis.
On the other hand, on a classical computer, we first decide a (random) bitstring and compute its appearance probability through Eq. \ref{eq:prob_dist}.
From the computed probability, we decide whether we accept the bitstring as the output of the quantum circuit or not.
Since the computation of one amplitude is independent of other amplitude computations, the throughput scales linearly with computing resources.
Generally, the sampling cost on a classical computer can be much higher than on a quantum device since we reject much more bitstrings than we accept.
However, in the case of RCS, the \textit{frugal reject sampling}\cite{markov_quantum_2018} technique can be used to sample them on a classical computer at about the same computational cost as on a quantum device by reducing the number of rejected bitstrings.
Therefore, many studies focus on improving the throughput of computing one amplitude.

We evaluate our method on the rectangular lattice RQC defined in \cite{boixo_characterizing_2018} and Sycamore circuit \cite{arute_quantum_2019-2}.
As mentioned above, all quantum circuits and measurements are represented as tensor networks, and one amplitude is obtained by contracting them.
Since the computational cost of the Sycamore circuit is high, we typically divide it into slices and merge the result of their contraction.
We measure the computing time for one amplitude for the rectangular lattice RQC and one slice for the Sycamore circuit.
The computation is conducted $10$ times for different output bitstrings, and we show their median.
%Note that the simulation of Sycamore circuits is very costly, so we calculate only one sliced tensor network of them. 

\subsubsection{Rectangular lattice RQC}
\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{./images/rqc-result.pdf}
    \caption{
    The computing time (top) and accuracy (center) of obtaining one amplitude for each RQC and the GEMM shape time breakdown in the CUBLAS mode (bottom) of the rectangular lattice RQCs.
    }
    \label{fig:rqc-result}
\end{figure}
The rectangular lattice RQC has $m \times n$ qubits arranged in a lattice, and we apply a specific set of quantum gates.
Furthermore, the quantum gates are also arranged in a rectangular lattice, and the number of the rectangular lattice layers is called ``depth".
We denote the depth $d=1 + X + 1$ since we apply the Hadamard gate for all qubits in the first ($1+$) and last (+1) stages of the circuit.
%The number of quantum gates in $m \times n$, depth $d$ circuit is $\mathcal{O}(mnd)$.
We have evaluated the automatic precision selection on four kinds of rectangular lattice RQCs, as shown in Fig. \ref{fig:rqc-result}.
Throughout all circuits, the AUTO modes avoid the underflow automatically and achieve the same level of accuracy as the baseline (CUBLAS) while achieving higher throughput than TF32TCEC.
The AUTO-$0.5$ mode has achieved up to $1.86$ times higher throughput than the baseline in the $9 \times 9$ quantum circuit, which has a small computing time ratio for the tensor transposition.
The TF32TCEC mode has not been selected in the AUTO modes since it has sufficed to use FP16TCEC w/ scaling in all cases.
Therefore, the throughput of the AUTO modes is almost the same as FP16TCEC w/ scaling mode.
Although the throughput of FP16TCEC is also higher than TF32TCEC, accuracy loss occurs due to the underflow when the qubit size is large.
We have also investigated the computing time breakdown for GEMM shapes in each quantum circuit.
In all circuits, a large shape of GEMM dominates the whole GEMM computing time.
In this case, we can improve the efficiency of our method since the SGEMM emulation methods achieve higher throughput, and the exponent statistics have a relatively lower overhead.

\subsubsection{Sycamore}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{./images/sycamore-eval.pdf}
    \caption{The computing time (left), accuracy (center), and GEMM shape time breakdown in the CUBLAS mode (right) of Google Sycamore sampling simulation.}
    \label{fig:sycamore-eval}
\end{figure}
In the Sycamore circuits, 53 qubits are arranged in 2-D, and we apply $(1+20+1)$-depth quantum gates layers.
The evaluation result of the Sycamore circuit is shown in Fig. \ref{fig:sycamore-eval}.
The AUTO modes have achieved $1.45$ times higher throughput than the baseline (CUBLAS) while achieving the same level of accuracy.
In this quantum circuit, the large shape GEMMs dominate the whole GEMM computing time, and we can efficiently improve the throughput of the simulation.
Although the underflow ratio of the elements in the large GEMMs has differed from the output strings, FP16TCEC w/ scaling is selected in all computations.
As we mentioned above, since the throughput of the RCS is proportional to the throughput of one amplitude computation, we believe our method improves the whole Sycamore circuit simulation to the same extent.

%In Table. \ref{table:RQC} we report relative residuals, times per 1 sampling, and time for GEMM, averaged over 10 random outcome bitstrings, for rectangular circuits and Sycamore.
%While FP16TCEC fails to compute with high accuracy in large qubit circuits, other methods, including auto precision selection, succeed in achieving the same accuracy as a single-precision calculation in all instances.
%Furthermore, the automatic precision selection method can sample faster than TF32TCEC in small qubit circuits.
%We have numerically demonstrated that our proposed automatic precision selection method can accelerate quantum circuit simulations without compromising the required accuracy.
\section{Conclusion}
We improve the throughput of the quantum circuit simulation using the SGEMM emulation method on Tensor Cores and automatic precision selection.
Our method automatically selects the GEMM computing modes in the tensor contractions to improve the throughput while avoiding accuracy loss due to underflow.
We have achieved up to $1.86$ times throughput in $9 \times 9$ RQC and $1.45$ times in Google Sycamore circuits compared to the baseline simulation using cuBLAS CGEMM while keeping the accuracy. Furthermore, we have also achieved up to $1.27$ times in $9 \times 9$ RQC, $1.11$ times faster throughput in the Sycamore circuit than SGEMM emulation using TF32 Tensor Core, which clearly can improve the throughput.
Through this study, we show an example that Tensor Core, which is developed for machine learning, can be used for another HPC field of research.

\subsubsection*{Acknowledgements}
This work was partially supported by JSPS KAKENHI JP22H03598, JP21J14694, and JP20K03766.
This work was partially supported by "Joint Usage/Research Center for Interdisciplinary Large-scale Information Infrastructures" in Japan (Project ID: jh220022-NAHI).

%\bibliographystyle{mplainnat}
%\bibliography{references}
\bibliography{refs, bibs_manabe}

\newpage
\appendix
\section{Appendix}
\subsection{Custom kernel function for irregular shaped GEMM}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/gemm_Mx2x2.pdf}
    \caption{Throughput comparison between the custom GEMM kernel for the irregular shape of GEMMs and cuBLAS.}
    \label{fig:gemm-2xMxM}
\end{figure}
As we mention in Sec. \ref{sec:irregular-shaped-gemm}, we have implemented a custom kernel function for the irregular shape of GEMMs since the cuBLAS implementation is not optimized.
We show the throughput comparison of our GEMM and cuBLAS in Fig. \ref{fig:gemm-2xMxM}.

\end{document}