@STRING{ICLR  = " ICLR"}
@STRING{ICML  = " ICML"}
@STRING{ICCV  = "ICCV"}
@STRING{MICCAI  = "MICCAI"}
@STRING{CVPR  = "CVPR"}
@STRING{CVPRW = "CVPRW"}
@STRING{ECCV  = "ECCV"}
@STRING{IJCAI = "IJCAI"}
@string{NIPS  = "NeurIPS"}
@string{BMVC  = "BMVC"}
@STRING{ICIP  = "ICIP"}
@STRING{ICPR  = "ICPR"}
@STRING{FG    = "FG"}
@STRING{ICASSP= "ICASSP"}
@STRING{ACMMM= "ACM MM"}
@STRING{AAAI= "AAAI"}
@STRING{ICPR= "ICPR"}
@STRING{ICIMCS= "ICIMCS"}
@STRING{ICRA= "ICRA"}

@STRING{TPAMI  = "IEEE TPAMI"}
@STRING{IJCV  = "IJCV"}
@STRING{CVIU  = "CVIU"}
@STRING{TNNLS   = "IEEE TNNLS"}
@STRING{TMM   = "IEEE TMM"}
@STRING{TIP   = "IEEE TIP"}
@STRING{TSP   = "IEEE TSP"}
@STRING{PIEEE = "Proc. of the IEEE"}
@STRING{PRL   = "PRL"}
@STRING{PR    = "Pattern Recognition"}
@STRING{NC    = "Neural Computation"}
@STRING{IVC   = "IVC"}
@STRING{IJRR  = "IJRR"}
@STRING{JMLR  = "JMLR"}

@STRING{TCSVT  = "IEEE TCSVT"}
@STRING{SPL  = "IEEE SPL"}
%interframe-based ZVOS
@inproceedings{WCS,
  title={Unsupervised video object segmentation with joint hotspot tracking},
  author={Zhang, Lu and Zhang, Jianming and Lin, Zhe and M{\v{e}}ch, Radom{\'\i}r and Lu, Huchuan and He, You},
  booktitle=ECCV,
  pages={490--506},
  year={2020}
}

@inproceedings{AGNN,
  title={Zero-shot video object segmentation via attentive graph neural networks},
  author={Wang, Wenguan and Lu, Xiankai and Shen, Jianbing and Crandall, David J and Shao, Ling},
  booktitle=ICCV,
  pages={9236--9245},
  year={2019}
}

@inproceedings{COSNet,
  title={See more, know more: Unsupervised video object segmentation with co-attention siamese networks},
  author={Lu, Xiankai and Wang, Wenguan and Ma, Chao and Shen, Jianbing and Shao, Ling and Porikli, Fatih},
  booktitle=CVPR,
  pages={3623--3632},
  year={2019}
}

@inproceedings{AGS,
  title={Learning unsupervised video object segmentation through visual attention},
  author={Wang, Wenguan and Song, Hongmei and Zhao, Shuyang and Shen, Jianbing and Zhao, Sanyuan and Hoi, Steven CH and Ling, Haibin},
  booktitle=CVPR,
  pages={3064--3074},
  year={2019}
}

@article{EPO,
  title={Exploiting geometric constraints on dense trajectories for motion saliency},
  author={Faisal, Muhammad and Akhter, Ijaz and Ali, Mohsen and Hartley, Richard},
  journal={arXiv preprint arXiv:1909.13258},
  volume={3},
  number={4},
  year={2019}
}

@inproceedings{PDB,
  title={Pyramid dilated deeper convlstm for video salient object detection},
  author={Song, Hongmei and Wang, Wenguan and Zhao, Sanyuan and Shen, Jianbing and Lam, Kin-Man},
  booktitle=ECCV,
  pages={715--731},
  year={2018}
}

%optical flow-based ZVOS
@inproceedings{GateNet,
  title={Suppress and balance: A simple gated network for salient object detection},
  author={Zhao, Xiaoqi and Pang, Youwei and Zhang, Lihe and Lu, Huchuan and Zhang, Lei},
  booktitle=ECCV,
  pages={35--51},
  year={2020}
}

@inproceedings{MP,
  title={Learning motion patterns in videos},
  author={Tokmakov, Pavel and Alahari, Karteek and Schmid, Cordelia},
  booktitle=CVPR,
  pages={3386--3394},
  year={2017}
}

@inproceedings{SFL,
  title={Segflow: Joint learning for video object segmentation and optical flow},
  author={Cheng, Jingchun and Tsai, Yi-Hsuan and Wang, Shengjin and Yang, Ming-Hsuan},
  booktitle=ICCV,
  pages={686--695},
  year={2017}
}

@inproceedings{MATNet,
  title={Motion-attentive transition for zero-shot video object segmentation},
  author={Zhou, Tianfei and Wang, Shunzhou and Zhou, Yi and Yao, Yazhou and Li, Jianwu and Shao, Ling},
  booktitle=AAAI,
  pages={13066--13073},
  year={2020}
}

@inproceedings{FSNet,
  title={Full-duplex strategy for video object segmentation},
  author={Ji, Ge-Peng and Fu, Keren and Wu, Zhe and Fan, Deng-Ping and Shen, Jianbing and Shao, Ling},
  booktitle=ICCV,
  pages={4922--4933},
  year={2021}
}

@inproceedings{AMCNet,
  title={Learning Motion-Appearance Co-Attention for Zero-Shot Video Object Segmentation},
  author={Yang, Shu and Zhang, Lu and Qi, Jinqing and Lu, Huchuan and Wang, Shuo and Zhang, Xiaoxing},
  booktitle=ICCV,
  pages={1564--1573},
  year={2021}
}

@inproceedings{RTNet,
  title={Reciprocal transformations for unsupervised video object segmentation},
  author={Ren, Sucheng and Liu, Wenxi and Liu, Yongtuo and Chen, Haoxin and Han, Guoqiang and He, Shengfeng},
  booktitle={CVPR},
  pages={15455--15464},
  year={2021}
}

%introduction
@inproceedings{jiyuan_mm,
  title={Weakly-Supervised Temporal Action Localization via Cross-Stream Collaborative Learning},
  author={Ji, Yuan and Jia, Xu and Lu, Huchuan and Ruan, Xiang},
  booktitle=ACMMM,
  pages={853--861},
  year={2021}
}

@inproceedings{DFMNet,
title={Depth quality-inspired feature manipulation for efficient RGB-D salient object detection},
author={Zhang, Wenbo and Ji, Ge-Peng and Wang, Zhuo and Fu, Keren and Zhao, Qijun},
booktitle=ACMMM,
pages={731--740},
year={2021}
}

@inproceedings{DANet,
  title={A single stream network for robust and real-time rgb-d salient object detection},
  author={Zhao, Xiaoqi and Zhang, Lihe and Pang, Youwei and Lu, Huchuan and Zhang, Lei},
  booktitle=ECCV,
  pages={646--662},
  year={2020}
}

@inproceedings{HDFNet,
   title={Hierarchical dynamic filtering network for RGB-D salient object detection},
  author={Pang, Youwei and Zhang, Lihe and Zhao, Xiaoqi and Lu, Huchuan},
  booktitle=ECCV,
  pages={235--252},
  year={2020}
}


@inproceedings{Unet,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle= MICCAI,
  pages={234--241},
  year={2015}
}

@inproceedings{FPN,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle= CVPR,
  pages={2117--2125},
  year={2017}
}


%related work
@inproceedings{PWC,
  title={PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume},
  author={Sun, D and Yang, X and Liu, MY and Kautz, J},
  booktitle= CVPR,
  pages={8934–8943},
  year={2018}
}

@inproceedings{MaskFlowNet,
  title={Maskflownet: Asymmetric feature matching with learnable occlusion mask},
  author={Zhao, Shengyu and Sheng, Yilun and Dong, Yue and Chang, Eric I and Xu, Yan and others},
  booktitle=CVPR,
  pages={6278--6287},
  year={2020}
}

@inproceedings{RAFT,
  title={Raft: Recurrent all-pairs field transforms for optical flow},
  author={Teed, Zachary and Deng, Jia},
  booktitle=ECCV,
  pages={402--419},
  year={2020}
}

@inproceedings{LVO,
  title={Learning video object segmentation with visual memory},
  author={Tokmakov, Pavel and Alahari, Karteek and Schmid, Cordelia},
  booktitle= ICCV,
  pages={4481--4490},
  year={2017}
}

@inproceedings{UVOS-Bilateral,
  title={Unsupervised video object segmentation with motion-based bilateral networks},
  author={Li, Siyang and Seybold, Bryan and Vorobyov, Alexey and Lei, Xuejing and Jay Kuo, C-C},
  booktitle=ECCV,
  pages={207--223},
  year={2018}
}

@inproceedings{MINNet,
  title={Multi-scale interactive network for salient object detection},
  author={Pang, Youwei and Zhao, Xiaoqi and Zhang, Lihe and Lu, Huchuan},
  booktitle=CVPR,
  pages={9413--9422},
  year={2020}
}

@article{RGBT1,
  title={Does Thermal Really Always Matter for RGB-T Salient Object Detection?},
  author={Cong, Runmin and Zhang, Kepu and Zhang, Chen and Zheng, Feng and Zhao, Yao and Huang, Qingming and Kwong, Sam},
  journal=TMM,
  year={2022}
}

@article{RGBT2,
  title={RGB-T salient object detection via fusing multi-level CNN features},
  author={Zhang, Qiang and Huang, Nianchang and Yao, Lin and Zhang, Dingwen and Shan, Caifeng and Han, Jungong},
  journal=TIP,
  volume={29},
  pages={3321--3335},
  year={2019}
}

@article{U2Net,
  title={U2-Net: Going deeper with nested U-structure for salient object detection},
  author={Qin, Xuebin and Zhang, Zichen and Huang, Chenyang and Dehghan, Masood and Zaiane, Osmar R and Jagersand, Martin},
  journal=PR,
  volume={106},
  pages={107404},
  year={2020}
}

@article{MSANet,
  title={Encoder deep interleaved network with multi-scale aggregation for RGB-D salient object detection},
  author={Feng, Guang and Meng, Jinyu and Zhang, Lihe and Lu, Huchuan},
  journal=PR,
  volume={128},
  pages={108666},
  year={2022}
}

@inproceedings{SSLSOD,
  title={Self-supervised pretraining for rgb-d salient object detection},
  author={Zhao, Xiaoqi and Pang, Youwei and Zhang, Lihe and Lu, Huchuan and Ruan, Xiang},
  booktitle=AAAI,
  year={2022}
}

@inproceedings{DCF,
  title={Calibrated RGB-D salient object detection},
  author={Ji, Wei and Li, Jingjing and Yu, Shuang and Zhang, Miao and Piao, Yongri and Yao, Shunyu and Bi, Qi and Ma, Kai and Zheng, Yefeng and Lu, Huchuan and others},
  booktitle=CVPR,
  pages={9471--9481},
  year={2021}
}

@article{JLSOD,
  title={Joint Learning of Salient Object Detection, Depth Estimation and Contour Extraction},
  author={Zhao, Xiaoqi and Pang, Youwei and Zhang, Lihe and Lu, Huchuan},
  journal=TIP,
  year={2022}
}

@inproceedings{SPNet,
  title={Specificity-preserving rgb-d saliency detection},
  author={Zhou, Tao and Fu, Huazhu and Chen, Geng and Zhou, Yi and Fan, Deng-Ping and Shao, Ling},
  booktitle=ICCV,
  pages={4681--4691},
  year={2021}
}

@inproceedings{RD3D,
  title={RGB-D salient object detection via 3D convolutional neural networks},
  author={Chen, Qian and Liu, Ze and Zhang, Yi and Fu, Keren and Zhao, Qijun and Du, Hongwei},
  booktitle=AAAI,
  pages={1063--1071},
  year={2021}
}

@inproceedings{D2F,
  title={Deep RGB-D saliency detection with depth-sensitive attention and automatic multi-modal fusion},
  author={Sun, Peng and Zhang, Wenhu and Wang, Huanyu and Li, Songyuan and Li, Xi},
  booktitle=CVPR,
  pages={1407--1417},
  year={2021}
}

@inproceedings{JLDCF,
  title={JL-DCF: Joint learning and densely-cooperative fusion framework for RGB-D salient object detection},
  author={Fu, Keren and Fan, Deng-Ping and Ji, Ge-Peng and Zhao, Qijun},
  booktitle=CVPR,
  pages={3052--3062},
  year={2020}
}

@inproceedings{DASNet,
  title={Is depth really necessary for salient object detection?},
  author={Zhao, Jiawei and Zhao, Yifan and Li, Jia and Chen, Xiaowu},
  booktitle=ACMMM,
  pages={1745--1754},
  year={2020}
}

@inproceedings{CoNet,
  title={Accurate RGB-D salient object detection via collaborative learning},
  author={Ji, Wei and Li, Jingjing and Zhang, Miao and Piao, Yongri and Lu, Huchuan},
  booktitle=ECCV,
  pages={52--69},
  year={2020}
}

@inproceedings{Gate-RGBD-SS,
 title={Bi-directional Cross-Modality Feature Propagation with Separation-and-Aggregation Gate for RGB-D Semantic Segmentation},
  author={Chen, Xiaokang and Lin, Kwan-Yee and Wang, Jingbo and Wu, Wayne and Qian, Chen and Li, Hongsheng and Zeng, Gang},
  booktitle=ECCV,
  pages={561--577},
  year={2020}
}

@inproceedings{PA-RGBD-SS,
  title={Pattern-affinitive propagation across depth, surface normal and semantic segmentation},
  author={Zhang, Zhenyu and Cui, Zhen and Xu, Chunyan and Yan, Yan and Sebe, Nicu and Yang, Jian},
  booktitle=CVPR,
  pages={4106--4115},
  year={2019}
}
@inproceedings{DA-RGBD-SS,
  title={Depth-aware cnn for rgb-d segmentation},
  author={Wang, Weiyue and Neumann, Ulrich},
  booktitle=ECCV,
  pages={135--150},
  year={2018}
}
@article{SS-RGBD-SS,
  title={RGB-D joint modelling with scene geometric information for indoor semantic segmentation},
  author={Liu, Hong and Wu, Wenshan and Wang, Xiangdong and Qian, Yueliang},
  journal={Multimedia Tools and Applications},
  volume={77},
  pages={22475--22488},
  year={2018}
}
@inproceedings{LS-RGBD-SS,
  title={Locality-sensitive deconvolution networks with gated fusion for rgb-d indoor semantic segmentation},
  author={Cheng, Yanhua and Cai, Rui and Li, Zhiwei and Zhao, Xin and Huang, Kaiqi},
  booktitle=CVPR,
  pages={3029--3037},
  year={2017}
}

@inproceedings{rgbd-tracking1,
  title={CDTB: A color and depth visual object tracking dataset and benchmark},
  author={Lukezic, Alan and Kart, Ugur and Kapyla, Jani and Durmush, Ahmed and Kamarainen, Joni-Kristian and Matas, Jiri and Kristan, Matej},
  booktitle=ICCV,
  pages={10013--10022},
  year={2019}
}

@article{rgbd-tracking2,
  title={Deep Attention Models for Human Tracking Using RGBD},
  author={Rasoulidanesh, Maryamsadat and Yadav, Srishti and Herath, Sachini and Vaghei, Yasaman and Payandeh, Shahram},
  journal={Sensors},
  volume={19},
  pages={750},
  year={2019}
}

@inproceedings{rgbd-tracking3,
  title={Online RGB-D tracking via detection-learning-segmentation},
  author={An, Ning and Zhao, Xiao-Guang and Hou, Zeng-Guang},
  booktitle=ICPR,
  pages={1231--1236},
  year={2016}
}

@inproceedings{BASNet,
  title={BASNet: Boundary-Aware Salient Object Detection},
  author={Qin, Xuebin and Zhang, Zichen and Huang, Chenyang and Gao, Chao and Dehghan, Masood and Jagersand, Martin},
  booktitle=CVPR,
  pages={7479--7489},
  year={2019}
}

@inproceedings{DSS,
  title={Deeply supervised salient object detection with short connections},
  author={Hou, Qibin and Cheng, Ming-Ming and Hu, Xiaowei and Borji, Ali and Tu, Zhuowen and Torr, Philip HS},
  booktitle=CVPR,
  pages={3203--3212},
  year={2017}
}

@inproceedings{SFN,
  title={Optical flow estimation using a spatial pyramid network},
  author={Ranjan, Anurag and Black, Michael J},
  booktitle=CVPR,
  pages={4161--4170},
  year={2017}
}
@inproceedings{liteflownet,
  title={Liteflownet: A lightweight convolutional neural network for optical flow estimation},
  author={Hui, Tak-Wai and Tang, Xiaoou and Change Loy, Chen},
  booktitle=CVPR,
  pages={8981--8989},
  year={2018}
}
@inproceedings{VCN,
  title={Volumetric correspondence networks for optical flow},
  author={Yang, Gengshan and Ramanan, Deva},
  booktitle=NIPS,
  pages={794--805},
  year={2019}
}

%Method
@inproceedings{ResNet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle=CVPR,
  pages={770--778},
  year={2016}
}

@inproceedings{depth3,
  title={Superdepth: Self-supervised, super-resolved monocular depth estimation},
  author={Pillai, Sudeep and Ambru{\c{s}}, Rare{\c{s}} and Gaidon, Adrien},
  booktitle=ICRA,
  pages={9250--9256},
  year={2019}
}
@article{depth4,
  title={Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer},
  author={Ranftl, Ren{\'e} and Lasinger, Katrin and Hafner, David and Schindler, Konrad and Koltun, Vladlen},
  journal= TPAMI,
  year={2020}
}
@article{depth5,
  title={RealMonoDepth: Self-Supervised Monocular Depth Estimation for General Scenes},
  author={Ocal, Mertalp and Mustafa, Armin},
  journal={arXiv preprint arXiv:2004.06267},
  year={2020}
}

@inproceedings{SSIM,
  title={Multiscale structural similarity for image quality assessment},
  author={Wang, Zhou and Simoncelli, Eero P and Bovik, Alan C},
  booktitle={The Thrity-Seventh Asilomar Conference on Signals, Systems \& Computers, 2003},
  volume={2},
  pages={1398--1402},
  year={2003},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%Metrics%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{colorcontrast_Fm,
  title     = {Frequency-tuned salient region detection},
  author    = {Achanta, Radhakrishna and Hemami, Sheila and Estrada, Francisco and S{\"u}sstrunk, Sabine},
  booktitle = CVPR,
  pages     = {1597--1604},
  year      = {2009},
}

@article{E-m,
  title   = {Enhanced-alignment measure for binary foreground map evaluation},
  author  = {Fan, Deng-Ping and Gong, Cheng and Cao, Yang and Ren, Bo and Cheng, Ming-Ming and Borji, Ali},
  journal = {arXiv preprint arXiv:1805.10421},
  year    = {2018},
}

@inproceedings{Fwb,
  title     = {How to evaluate foreground maps?},
  author    = {Margolin, Ran and Zelnik-Manor, Lihi and Tal, Ayellet},
  booktitle = CVPR,
  pages     = {248--255},
  year      = {2014},
}

@inproceedings{S-m,
  title     = {Structure-measure: A new way to evaluate foreground maps},
  author    = {Fan, Deng-Ping and Cheng, Ming-Ming and Liu, Yun and Li, Tao and Borji, Ali},
  booktitle = ICCV,
  pages     = {4548--4557},
  year      = {2017},
}

@inproceedings{MAE,
  title     = {Saliency filters: Contrast based filtering for salient region detection},
  author    = {Perazzi, Federico and Kr{\"a}henb{\"u}hl, Philipp and Pritch, Yael and Hornung, Alexander},
  booktitle = CVPR,
  pages     = {733--740},
  year      = {2012},
}

@inproceedings{BER,
  title     = {Leave-one-out kernel optimization for shadow detection},
  author    = {Vicente, Tom{\'a}s F Yago and Hoai, Minh and Samaras, Dimitris},
  booktitle = ICCV,
  pages     = {3388--3396},
  year      = {2015},
}
@article{BCE,
  title={A tutorial on the cross-entropy method},
  author={De Boer, Pieter-Tjerk and Kroese, Dirk P and Mannor, Shie and Rubinstein, Reuven Y},
  journal={Annals of operations research},
  volume={134},
  pages={19--67},
  year={2005}
}

@inproceedings{F3Net,
  title={F$^3$Net: fusion, feedback and focus for salient object detection},
  author={Wei, Jun and Wang, Shuhui and Huang, Qingming},
  booktitle=AAAI,
  pages={12321--12328},
  year={2020}
}

@inproceedings{CBAM,
  title={Cbam: Convolutional block attention module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle=ECCV,
  pages={3--19},
  year={2018}
}

@inproceedings{PRelu,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle= ICCV,
  pages={1026--1034},
  year={2015}
}

@inproceedings{ImageNet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle=CVPR,
  pages={248--255},
  year={2009}
}

%experiment
@inproceedings{davis16,
  title={A benchmark dataset and evaluation methodology for video object segmentation},
  author={Perazzi, Federico and Pont-Tuset, Jordi and McWilliams, Brian and Van Gool, Luc and Gross, Markus and Sorkine-Hornung, Alexander},
  booktitle= CVPR,
  pages={724--732},
  year={2016}
}
@inproceedings{youtube-objects,
  title={Learning object class detectors from weakly annotated video},
  author={Prest, Alessandro and Leistner, Christian and Civera, Javier and Schmid, Cordelia and Ferrari, Vittorio},
  booktitle=CVPR,
  pages={3282--3289},
  year={2012},
}
@article{FBMS,
  title={Segmentation of moving objects by long term video analysis},
  author={Ochs, Peter and Malik, Jitendra and Brox, Thomas},
  journal=TPAMI,
  volume={36},
  pages={1187--1200},
  year={2013}
}

@inproceedings{pytorch,
 title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
 author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
 booktitle = NIPS,
 volume = {32},
 year = {2019}
}

@inproceedings{MSAPS,
  title={Multi-source fusion and automatic predictor selection for zero-shot video object segmentation},
  author={Zhao, Xiaoqi and Pang, Youwei and Yang, Jiaxing and Zhang, Lihe and Lu, Huchuan},
  booktitle=ACMMM,
  pages={2645--2653},
  year={2021}
}

@inproceedings{NLPR,
  title={RGBD salient object detection: A benchmark and algorithms},
  author={Peng, Houwen and Li, Bing and Xiong, Weihua and Hu, Weiming and Ji, Rongrong},
  booktitle=ECCV,
  pages={92--109},
  year={2014}
}

@inproceedings{NJU2K,
  title={Depth saliency based on anisotropic center-surround difference},
  author={Ju, Ran and Ge, Ling and Geng, Wenjing and Ren, Tongwei and Wu, Gangshan},
  booktitle=ICIP,
  pages={1115--1119},
  year={2014}
}

@article{SIP,
  title={Rethinking RGB-D salient object detection: Models, data sets, and large-scale benchmarks},
  author={Fan, Deng-Ping and Lin, Zheng and Zhang, Zhao and Zhu, Menglong and Cheng, Ming-Ming},
  journal=TNNLS,
  volume={32},
  pages={2075--2089},
  year={2020}
}

@inproceedings{STERE,
  title={Leveraging stereopsis for saliency analysis},
  author={Niu, Yuzhen and Geng, Yujie and Li, Xueqing and Liu, Feng},
  booktitle=CVPR,
  pages={454--461},
  year={2012}
}

@inproceedings{DUTLF-D,
  title={Depth-induced multi-scale recurrent attention network for saliency detection},
  author={Piao, Yongri and Ji, Wei and Li, Jingjing and Zhang, Miao and Lu, Huchuan},
  booktitle=ICCV,
  pages={7254--7263},
  year={2019}
}

@inproceedings{RGBD135,
  title={Depth enhanced saliency detection method},
  author={Cheng, Yupeng and Fu, Huazhu and Wei, Xingxing and Xiao, Jiangjian and Cao, Xiaochun},
  booktitle=ICIMCS,
  pages={23},
  year={2014}
}

@article{AdamW,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{poly,
  title={Parsenet: Looking wider to see better},
  author={Liu, Wei and Rabinovich, Andrew and Berg, Alexander C},
  journal={arXiv preprint arXiv:1506.04579},
  year={2015}
}

@inproceedings{MotAdapt,
  title={Video object segmentation using teacher-student adaptation in a human robot interaction (hri) setting},
  author={Siam, Mennatullah and Jiang, Chen and Lu, Steven and Petrich, Laura and Gamal, Mahmoud and Elhoseiny, Mohamed and Jagersand, Martin},
  booktitle=ICRA,
  pages={50--56},
  year={2019},
}

@inproceedings{DFNet,
  title={Learning Discriminative Feature with CRF for Unsupervised Video Object Segmentation},
  author={Zhen, Mingmin and Li, Shiwei and Zhou, Lei and Shang, Jiaxiang and Feng, Haoan and Fang, Tian and Quan, Long},
  booktitle= ECCV,
  pages={445--462},
  year={2020}
}

@inproceedings{FST,
  title={Fast object segmentation in unconstrained video},
  author={Papazoglou, Anestis and Ferrari, Vittorio},
  booktitle=ICCV,
  pages={1777--1784},
  year={2013}
}
@inproceedings{COSEG,
  title={Semantic co-segmentation in videos},
  author={Tsai, Yi-Hsuan and Zhong, Guangyu and Yang, Ming-Hsuan},
  booktitle=ECCV,
  pages={760--775},
  year={2016}
}
@inproceedings{ARP,
  title={Primary object segmentation in videos based on region augmentation and reduction},
  author={Jun Koh, Yeong and Kim, Chang-Su},
  booktitle= CVPR,
  pages={3442--3450},
  year={2017}
}
@inproceedings{FSEG,
  title={Fusionseg: Learning to combine motion and appearance for fully automatic segmentation of generic objects in videos},
  author={Jain, Suyog Dutt and Xiong, Bo and Grauman, Kristen},
  booktitle=CVPR,
  pages={2117--2126},
  year={2017}
}
@inproceedings{SAGE,
  title={Saliency-aware geodesic video object segmentation},
  author={Wang, Wenguan and Shen, Jianbing and Porikli, Fatih},
  booktitle=CVPR,
  pages={3395--3402},
  year={2015}
}
 
@inproceedings{BBSNet,
  title={BBS-Net: RGB-D salient object detection with a bifurcated backbone strategy network},
  author={Fan, Deng-Ping and Zhai, Yingjie and Borji, Ali and Yang, Jufeng and Shao, Ling},
  booktitle=ECCV,
  pages={275--292},
  year={2020}
}

@article{VGG,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{Res2Net,
  title={Res2net: A new multi-scale backbone architecture},
  author={Gao, Shang-Hua and Cheng, Ming-Ming and Zhao, Kai and Zhang, Xin-Yu and Yang, Ming-Hsuan and Torr, Philip},
  journal=TPAMI,
  volume={43},
  pages={652--662},
  year={2019}
}

 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Methods%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%RGB SOD
@article{U2Net,
  title   = {U2-Net: Going deeper with nested U-structure for salient object detection},
  author  = {Qin, Xuebin and Zhang, Zichen and Huang, Chenyang and Dehghan, Masood and Zaiane, Osmar R and Jagersand, Martin},
  journal = {Pattern Recognition},
  volume  = {106},
  pages   = {107404},
  year    = {2020}
}

@inproceedings{R3Net,
  title     = {R3Net: Recurrent residual refinement network for saliency detection},
  author    = {Deng, Zijun and Hu, Xiaowei and Zhu, Lei and Xu, Xuemiao and Qin, Jing and Han, Guoqiang and Heng, Pheng-Ann},
  booktitle = IJCAI,
  pages     = {684--690},
  year      = {2018},
}

@inproceedings{SFCN,
  title     = {Salient Object Detection by Lossless Feature Reflection},
  author    = {Pingping Zhang and W. Liu and Huchuan Lu and Chunhua Shen},
  booktitle = IJCAI,
  pages     = {1149–1155},
  year      = {2018},
}

@inproceedings{BMPM,
  title     = {A bi-directional message passing model for salient object detection},
  author    = {Zhang, Lu and Dai, Ju and Lu, Huchuan and He, You and Wang, Gang},
  booktitle = CVPR,
  pages     = {1741--1750},
  year      = {2018},
}

@inproceedings{PiCANet,
  title     = {PiCANet: Learning Pixel-Wise Contextual Attention for Saliency Detection},
  author    = {Nian Liu and Junwei Han and Ming-Hsuan Yang},
  booktitle = CVPR,
  year      = {2018},
  pages     = {3089-3098},
}

@inproceedings{PAGRN,
  title     = {Progressive attention guided recurrent network for salient object detection},
  author    = {Zhang, Xiaoning and Wang, Tiantian and Qi, Jinqing and Lu, Huchuan and Wang, Gang},
  booktitle = CVPR,
  pages     = {714--722},
  year      = {2018},
}

@inproceedings{DGRL,
  title     = {Detect globally, refine locally: A novel approach to saliency detection},
  author    = {Wang, Tiantian and Zhang, Lihe and Wang, Shuo and Lu, Huchuan and Yang, Gang and Ruan, Xiang and Borji, Ali},
  booktitle = CVPR,
  pages     = {3127--3135},
  year      = {2018},
}

@inproceedings{RAS,
  title     = {Reverse attention for salient object detection},
  author    = {Chen, Shuhan and Tan, Xiuli and Wang, Ben and Hu, Xuelong},
  booktitle = ECCV,
  pages     = {234--250},
  year      = {2018},
}

@inproceedings{DEF,
  title     = {Deep embedding features for salient object detection},
  author    = {Zhuge, Yunzhi and Zeng, Yu and Lu, Huchuan},
  booktitle = AAAI,
  pages     = {9340--9347},
  year      = {2019},
}

@inproceedings{AFNet,
  title     = {Attentive feedback network for boundary-aware salient object detection},
  author    = {Feng, Mengyang and Lu, Huchuan and Ding, Errui},
  booktitle = CVPR,
  pages     = {1623--1632},
  year      = {2019},
}

@inproceedings{BASNet,
  title     = {BASNet: Boundary-Aware Salient Object Detection},
  author    = {Qin, Xuebin and Zhang, Zichen and Huang, Chenyang and Gao, Chao and Dehghan, Masood and Jagersand, Martin},
  booktitle = CVPR,
  pages     = {7479--7489},
  year      = {2019},
}

@inproceedings{MLMS,
  title     = {A Mutual Learning Method for Salient Object Detection With Intertwined Multi-Supervision},
  author    = {Wu, Runmin and Feng, Mengyang and Guan, Wenlong and Wang, Dong and Lu, Huchuan and Ding, Errui},
  booktitle = CVPR,
  pages     = {8150--8159},
  year      = {2019},
}

@inproceedings{CPD,
  title     = {Cascaded Partial Decoder for Fast and Accurate Salient Object Detection},
  author    = {Wu, Zhe and Su, Li and Huang, Qingming},
  booktitle = CVPR,
  pages     = {3907--3916},
  year      = {2019},
}

@inproceedings{Capsal,
  title     = {CapSal: Leveraging Captioning to Boost Semantics for Salient Object Detection},
  author    = {Zhang, Lu and Zhang, Jianming and Lin, Zhe and Lu, Huchuan and He, You},
  booktitle = CVPR,
  pages     = {6024--6033},
  year      = {2019},
}

@inproceedings{PoolNet,
  title     = {A simple pooling-based design for real-time salient object detection},
  author    = {Liu, Jiang-Jiang and Hou, Qibin and Cheng, Ming-Ming and Feng, Jiashi and Jiang, Jianmin},
  booktitle = CVPR,
  pages     = {3917--3926},
  year      = {2019},
}

@inproceedings{PSSOD,
  title     = {An Iterative and Cooperative Top-down and Bottom-up Inference Network for Salient Object Detection},
  author    = {Wang, Wenguan and Shen, Jianbing and Cheng, Ming-Ming and Shao, Ling},
  booktitle = CVPR,
  pages     = {5968--5977},
  year      = {2019},
}

@inproceedings{PASE,
  title     = {Salient object detection with pyramid attention and salient edges},
  author    = {Wang, Wenguan and Zhao, Shuyang and Shen, Jianbing and Hoi, Steven CH and Borji, Ali},
  booktitle = CVPR,
  pages     = {1448--1457},
  year      = {2019},
}

@inproceedings{PFA,
  title     = {Pyramid Feature Attention Network for Saliency Detection},
  author    = {Zhao, Ting and Wu, Xiangqian},
  booktitle = CVPR,
  pages     = {3085--3094},
  year      = {2019},
}

@inproceedings{SCRN,
  title     = {Stacked cross refinement network for edge-aware salient object detection},
  author    = {Wu, Zhe and Su, Li and Huang, Qingming},
  booktitle = ICCV,
  pages     = {7264--7273},
  year      = {2019},
}

@inproceedings{BANet,
  title     = {Selectivity or invariance: Boundary-aware salient object detection},
  author    = {Su, Jinming and Li, Jia and Zhang, Yu and Xia, Changqun and Tian, Yonghong},
  booktitle = ICCV,
  pages     = {3799--3808},
  year      = {2019},
}

@inproceedings{HRS,
  title     = {Towards High-Resolution Salient Object Detection},
  author    = {Zeng, Yi and Zhang, Pingping and Zhang, Jianming and Lin, Zhe and Lu, Huchuan},
  booktitle = ICCV,
  pages     = {7234--7243},
  year      = {2019},
}

@inproceedings{EGNet,
  title     = {EGNet: Edge guidance network for salient object detection},
  author    = {Zhao, Jia-Xing and Liu, Jiang-Jiang and Fan, Deng-Ping and Cao, Yang and Yang, Jufeng and Cheng, Ming-Ming},
  booktitle = ICCV,
  pages     = {8779--8788},
  year      = {2019},
}

@inproceedings{DUCRF,
  title     = {Structured modeling of joint deep feature and prediction refinement for salient object detection},
  author    = {Xu, Yingyue and Xu, Dan and Hong, Xiaopeng and Ouyang, Wanli and Ji, Rongrong and Xu, Min and Zhao, Guoying},
  booktitle = ICCV,
  pages     = {3789--3798},
  year      = {2019},
}

@inproceedings{TSPOANet,
  title     = {Employing Deep Part-Object Relationships for Salient Object Detection},
  author    = {Liu, Yi and Zhang, Qiang and Zhang, Dingwen and Han, Jungong},
  booktitle = ICCV,
  pages     = {1232--1241},
  year      = {2019},
}

@inproceedings{PFPN,
  title     = {Progressive feature polishing network for salient object detection},
  author    = {Wang, Bo and Chen, Quan and Zhou, Min and Zhang, Zhiqiang and Jin, Xiaogang and Gai, Kun},
  booktitle = AAAI,
  pages     = {12128--12135},
  year      = {2020},
}

@inproceedings{GCPANet,
  title     = {Global context-aware progressive aggregation network for salient object detection},
  author    = {Chen, Zuyao and Xu, Qianqian and Cong, Runmin and Huang, Qingming},
  booktitle = AAAI,
  pages     = {10599--10606},
  year      = {2020},
}

@inproceedings{F3Net,
  title     = {F$^3$Net: Fusion, Feedback and Focus for Salient Object Detection},
  author    = {Wei, Jun and Wang, Shuhui and Huang, Qingming},
  booktitle = AAAI,
  pages     = {12321--12328},
  year      = {2020},
}

@inproceedings{MSANet,
  title     = {Multi-type self-attention guided degraded saliency detection},
  author    = {Zhou, Ziqi and Wang, Zheng and Lu, Huchuan and Wang, Song and Sun, Meijun},
  booktitle = AAAI,
  pages     = {13082--13089},
  year      = {2020},
}

@inproceedings{MINet,
  title     = {Multi-Scale Interactive Network for Salient Object Detection},
  author    = {Pang, Youwei and Zhao, Xiaoqi and Zhang, Lihe and Lu, Huchuan},
  booktitle = CVPR,
  pages     = {9413--9422},
  year      = {2020},
}

@inproceedings{ITSD,
  title     = {Interactive Two-Stream Decoder for Accurate and Fast Saliency Detection},
  author    = {Zhou, Huajun and Xie, Xiaohua and Lai, Jian-Huang and Chen, Zixuan and Yang, Lingxiao},
  booktitle = CVPR,
  pages     = {9141--9150},
  year      = {2020},
}

@inproceedings{LDF,
  title     = {Label decoupling framework for salient object detection},
  author    = {Wei, Jun and Wang, Shuhui and Wu, Zhe and Su, Chi and Huang, Qingming and Tian, Qi},
  booktitle = CVPR,
  pages     = {13025--13034},
  year      = {2020},
}

@inproceedings{CSNet,
  title     = {Highly efficient salient object detection with 100k parameters},
  author    = {Gao, Shang-Hua and Tan, Yong-Qiang and Cheng, Ming-Ming and Lu, Chengze and Chen, Yunpeng and Yan, Shuicheng},
  booktitle = ECCV,
  pages     = {702--721},
  year      = {2020},
}

@inproceedings{GateNet,
  title     = {Suppress and balance: A simple gated network for salient object detection},
  author    = {Zhao, Xiaoqi and Pang, Youwei and Zhang, Lihe and Lu, Huchuan and Zhang, Lei},
  booktitle = ECCV,
  pages     = {35--51},
  year      = {2020},
}

@inproceedings{PFS,
  title     = {Pyramidal Feature Shrinking for Salient Object Detection},
  author    = {Mingcan Ma and Changqun Xia and Jia Li},
  booktitle = AAAI,
  pages     = {2311-2318},
  year      = {2021},
}

@inproceedings{KRN,
  title     = {Locate Globally, Segment Locally: A Progressive Architecture With Knowledge Review Network for Salient Object Detection},
  author    = {Xu, Binwei and Liang, Haoran and Liang, Ronghua and Chen, Peng},
  booktitle = AAAI,
  pages     = {3004--3012},
  year      = {2021},
}

@inproceedings{JSODCOD,
  title     = {Uncertainty-aware joint salient object and camouflaged object detection},
  author    = {Li, Aixuan and Zhang, Jing and Lv, Yunqiu and Liu, Bowen and Zhang, Tong and Dai, Yuchao},
  booktitle = CVPR,
  pages     = {10071--10081},
  year      = {2021},
}

@inproceedings{Auto-MSFNet,
  title     = {Auto-MSFNet: Search Multi-scale Fusion Network for Salient Object Detection},
  author    = {Zhang, Miao and Liu, Tingwei and Piao, Yongri and Yao, Shunyu and Lu, Huchuan},
  booktitle = {ACM MM},
  pages     = {667--676},
  year      = {2021},
}

@inproceedings{CTDNet,
  title     = {Complementary Trilateral Decoder for Fast and Accurate Salient Object Detection},
  author    = {Zhao, Zhirui and Xia, Changqun and Xie, Chenxi and Li, Jia},
  booktitle = {ACM MM},
  pages     = {4967--4975},
  year      = {2021},
}

@inproceedings{VST,
  title     = {Visual saliency transformer},
  author    = {Liu, Nian and Zhang, Ni and Wan, Kaiyuan and Shao, Ling and Han, Junwei},
  booktitle = ICCV,
  pages     = {4722--4732},
  year      = {2021},
}

@inproceedings{HRRN,
  title     = {Disentangled high quality salient object detection},
  author    = {Tang, Lv and Li, Bo and Zhong, Yijie and Ding, Shouhong and Song, Mofei},
  booktitle = ICCV,
  pages     = {3580--3590},
  year      = {2021},
}

@inproceedings{iNAS,
  title     = {iNAS: Integral NAS for Device-Aware Salient Object Detection},
  author    = {Gu, Yu-Chao and Gao, Shang-Hua and Cao, Xu-Sheng and Du, Peng and Lu, Shao-Ping and Cheng, Ming-Ming},
  booktitle = ICCV,
  pages     = {4934--4944},
  year      = {2021},
}

@inproceedings{SCA,
  title     = {Scene context-aware salient object detection},
  author    = {Siris, Avishek and Jiao, Jianbo and Tam, Gary KL and Xie, Xianghua and Lau, Rynson WH},
  booktitle = ICCV,
  pages     = {4156--4166},
  year      = {2021},
}

%%%%%%%%%%%%%%%%%%%RGB-D SOD

@inproceedings{PDNet_RGBDSOD,
  title     = {Pdnet: Prior-model guided depth-enhanced network for salient object detection},
  author    = {Zhu, Chunbiao and Cai, Xing and Huang, Kan and Li, Thomas H and Li, Ge},
  booktitle = {ICME},
  pages     = {199--204},
  year      = {2019},
}

@inproceedings{PCA_RGBDSOD,
  title     = {Progressively complementarity-aware fusion network for RGB-D salient object detection},
  author    = {Chen, Hao and Li, Youfu},
  booktitle = CVPR,
  pages     = {3051--3060},
  year      = {2018},
}

@article{AF_RGBD,
  title   = {Adaptive Fusion for RGB-D Salient Object Detection},
  author  = {Wang, Ningning and Gong, Xiaojin},
  journal = {IEEE Access},
  volume  = {7},
  pages   = {55277--55284},
  year    = {2019},
}

@article{cmSalGAN_RGBDSOD,
  title   = {cmsalgan: Rgb-d salient object detection with cross-view generative adversarial networks},
  author  = {Jiang, Bo and Zhou, Zitai and Wang, Xiao and Tang, Jin and Luo, Bin},
  journal = TMM,
  volume  = {23},
  pages   = {1343--1353},
  year    = {2020},
}

@article{MMCI_RGBDSOD,
  title   = {Multi-modal fusion network with multi-scale multi-path and cross-modal interactions for RGB-D salient object detection},
  author  = {Chen, Hao and Li, Youfu and Su, Dan},
  journal = PR,
  volume  = {86},
  pages   = {376--385},
  year    = {2019},
}

@article{TANet_RGBDSOD,
  title   = {Three-stream attention-aware network for RGB-D salient object detection},
  author  = {Chen, Hao and Li, Youfu},
  journal = TIP,
  volume  = {28},
  pages   = {2825--2835},
  year    = {2019},
}

@inproceedings{CPFP_RGBDSOD,
  title     = {Contrast Prior and Fluid Pyramid Integration for RGBD Salient Object Detection},
  author    = {Zhao, Jia-Xing and Cao, Yang and Fan, Deng-Ping and Cheng, Ming-Ming and Li, Xuan-Yi and Zhang, Le},
  booktitle = CVPR,
  pages     = {3922-3931},
  year      = {2019},
}

@inproceedings{DMRA_RGBDSOD,
  title     = {Depth-Induced Multi-Scale Recurrent Attention Network for Saliency Detection},
  author    = {Piao, Yongri and Ji, Wei and Li, Jingjing and Zhang, Miao and Lu, Huchuan},
  booktitle = ICCV,
  pages     = {7254--7263},
  year      = {2019},
}

@article{D3Net_RGBDSOD,
  title   = {Rethinking RGB-D salient object detection: Models, data sets, and large-scale benchmarks},
  author  = {Fan, Deng-Ping and Lin, Zheng and Zhang, Zhao and Zhu, Menglong and Cheng, Ming-Ming},
  journal = TNNLS,
  volume  = {32},
  pages   = {2075--2089},
  year    = {2020},
}

@article{ICNet_RGBDSOD,
  title   = {ICNet: Information Conversion Network for RGB-D Based Salient Object Detection},
  author  = {Li, Gongyang and Liu, Zhi and Ling, Haibin},
  journal = TIP,
  volume  = {29},
  pages   = {4873--4884},
  year    = {2020},
}

@article{DisenFuse_RGBDSOD,
  title   = {RGBD salient object detection via disentangled cross-modal fusion},
  author  = {Chen, Hao and Deng, Yongjian and Li, Youfu and Hung, Tzu-Yi and Lin, Guosheng},
  journal = TIP,
  volume  = {29},
  pages   = {8407--8416},
  year    = {2020},
}

@article{TDESDF_RGBDSOD,
  title   = {Improved saliency detection in RGB-D images using two-phase depth estimation and selective deep fusion},
  author  = {Chen, Chenglizhao and Wei, Jipeng and Peng, Chong and Zhang, Weizhong and Qin, Hong},
  journal = TIP,
  volume  = {29},
  pages   = {4296--4307},
  year    = {2020},
}

@article{DPANet_RGBDSOD,
  title   = {DPANet: Depth potentiality-aware gated attention network for RGB-D salient object detection},
  author  = {Chen, Zuyao and Cong, Runmin and Xu, Qianqian and Huang, Qingming},
  journal = TIP,
  volume  = {30},
  pages   = {7012--7024},
  year    = {2020},
}

@inproceedings{JL-DCF_RGBDSOD,
  title     = {Jl-dcf: Joint learning and densely-cooperative fusion framework for rgb-d salient object detection},
  author    = {Fu, Keren and Fan, Deng-Ping and Ji, Ge-Peng and Zhao, Qijun},
  booktitle = CVPR,
  pages     = {3052--3062},
  year      = {2020},
}

@inproceedings{UCNet_RGBDSOD,
  title     = {UC-Net: Uncertainty inspired RGB-D saliency detection via conditional variational autoencoders},
  author    = {Zhang, Jing and Fan, Deng-Ping and Dai, Yuchao and Anwar, Saeed and Saleh, Fatemeh Sadat and Zhang, Tong and Barnes, Nick},
  booktitle = CVPR,
  pages     = {8582--8591},
  year      = {2020},
}

@inproceedings{A2dele_RGBDSOD,
  title     = {A2dele: Adaptive and Attentive Depth Distiller for Efficient RGB-D Salient Object Detection},
  author    = {Piao, Yongri and Rong, Zhengkun and Zhang, Miao and Ren, Weisong and Lu, Huchuan},
  booktitle = CVPR,
  pages     = {9060--9069},
  year      = {2020},
}

@inproceedings{SSF_RGBDSOD,
  title     = {Select, Supplement and Focus for RGB-D Saliency Detection},
  author    = {Zhang, Miao and Ren, Weisong and Piao, Yongri and Rong, Zhengkun and Lu, Huchuan},
  booktitle = CVPR,
  pages     = {3472--3481},
  year      = {2020},
}

@inproceedings{S2MA_RGBDSOD,
  title     = {Learning Selective Self-Mutual Attention for RGB-D Saliency Detection},
  author    = {Liu, Nian and Zhang, Ni and Han, Junwei},
  booktitle = CVPR,
  pages     = {13756--13765},
  year      = {2020},
}

@inproceedings{CoNet_RGBDSOD,
  title     = {Accurate rgb-d salient object detection via collaborative learning},
  author    = {Ji, Wei and Li, Jingjing and Zhang, Miao and Piao, Yongri and Lu, Huchuan},
  booktitle = ECCV,
  pages     = {52--69},
  year      = {2020},
}

@inproceedings{CMWNet_RGBDSOD,
  title     = {Cross-modal weighting network for rgb-d salient object detection},
  author    = {Li, Gongyang and Liu, Zhi and Ye, Linwei and Wang, Yang and Ling, Haibin},
  booktitle = ECCV,
  pages     = {665--681},
  year      = {2020},
}

@inproceedings{BBSNet_RGBDSOD,
  title     = {BBS-Net: RGB-D salient object detection with a bifurcated backbone strategy network},
  author    = {Fan, Deng-Ping and Zhai, Yingjie and Borji, Ali and Yang, Jufeng and Shao, Ling},
  booktitle = ECCV,
  pages     = {275--292},
  year      = {2020},
}

@inproceedings{HDFNet_RGBDSOD,
  title     = {Hierarchical dynamic filtering network for RGB-D salient object detection},
  author    = {Pang, Youwei and Zhang, Lihe and Zhao, Xiaoqi and Lu, Huchuan},
  booktitle = ECCV,
  pages     = {235--252},
  year      = {2020},
}

@inproceedings{DANet_RGBDSOD,
  title     = {A single stream network for robust and real-time rgb-d salient object detection},
  author    = {Zhao, Xiaoqi and Zhang, Lihe and Pang, Youwei and Lu, Huchuan and Zhang, Lei},
  booktitle = ECCV,
  pages     = {646--662},
  year      = {2020},
}

@inproceedings{PGAR_RGBDSOD,
  title     = {Progressively guided alternate refinement network for RGB-D salient object detection},
  author    = {Chen, Shuhan and Fu, Yun},
  booktitle = ECCV,
  pages     = {520--538},
  year      = {2020},
}

@inproceedings{JLDCF_RGBDSOD,
  title     = {Jl-dcf: Joint learning and densely-cooperative fusion framework for rgb-d salient object detection},
  author    = {Fu, Keren and Fan, Deng-Ping and Ji, Ge-Peng and Zhao, Qijun},
  booktitle = CVPR,
  pages     = {3052--3062},
  year      = {2020},
}

@inproceedings{CMMS_RGBDSOD,
  title     = {RGB-D salient object detection with cross-modality modulation and selection},
  author    = {Li, Chongyi and Cong, Runmin and Piao, Yongri and Xu, Qianqian and Loy, Chen Change},
  booktitle = ECCV,
  pages     = {225--241},
  year      = {2020},
}

@inproceedings{CAS-GNN_RGBDSOD,
  title     = {Cascade graph neural networks for rgb-d salient object detection},
  author    = {Luo, Ao and Li, Xin and Yang, Fan and Jiao, Zhicheng and Cheng, Hong and Lyu, Siwei},
  booktitle = ECCV,
  pages     = {346--364},
  year      = {2020},
}

@inproceedings{ATSA_RGBDSOD,
  title     = {Asymmetric two-stream architecture for accurate rgb-d saliency detection},
  author    = {Zhang, Miao and Fei, Sun Xiao and Liu, Jie and Xu, Shuang and Piao, Yongri and Lu, Huchuan},
  booktitle = ECCV,
  pages     = {374--390},
  year      = {2020},
}

@inproceedings{DASNet_RGBDSOD,
  title     = {Is depth really necessary for salient object detection?},
  author    = {Zhao, Jiawei and Zhao, Yifan and Li, Jia and Chen, Xiaowu},
  booktitle = {ACM MM},
  pages     = {1745--1754},
  year      = {2020},
}

@inproceedings{FRDT_RGBDSOD,
  title     = {Feature reintegration over differential treatment: A top-down and adaptive fusion network for RGB-D salient object detection},
  author    = {Zhang, Miao and Zhang, Yu and Piao, Yongri and Hu, Beiqi and Lu, Huchuan},
  booktitle = {ACM MM},
  pages     = {4107--4115},
  year      = {2020},
}

@inproceedings{MMNet_RGBDSOD,
  title     = {Mmnet: Multi-stage and multi-scale fusion network for rgb-d salient object detection},
  author    = {Liao, Guibiao and Gao, Wei and Jiang, Qiuping and Wang, Ronggang and Li, Ge},
  booktitle = {ACM MM},
  pages     = {2436--2444},
  year      = {2020},
}

@article{HAINet_RGBDSOD,
  title   = {Hierarchical alternate interaction network for RGB-D salient object detection},
  author  = {Li, Gongyang and Liu, Zhi and Chen, Minyu and Bai, Zhen and Lin, Weisi and Ling, Haibin},
  journal = TIP,
  volume  = {30},
  pages   = {3528--3542},
  year    = {2021},
}

@article{CDNet_RGBDSOD,
  title   = {CDNet: Complementary Depth Network for RGB-D Salient Object Detection},
  author  = {Jin, Wen-Da and Xu, Jun and Han, Qi and Zhang, Yi and Cheng, Ming-Ming},
  journal = TIP,
  volume  = {30},
  pages   = {3376--3390},
  year    = {2021},
}

@article{UTA_RGBDSOD,
  title   = {RGB-D Salient Object Detection With Ubiquitous Target Awareness},
  author  = {Zhao, Yifan and Zhao, Jiawei and Li, Jia and Chen, Xiaowu},
  journal = TIP,
  volume  = {30},
  pages   = {7717--7731},
  year    = {2021},
}

@article{DSNet_RGBDSOD,
  title   = {Dynamic Selective Network for RGB-D Salient Object Detection},
  author  = {Wen, Hongfa and Yan, Chenggang and Zhou, Xiaofei and Cong, Runmin and Sun, Yaoqi and Zheng, Bolun and Zhang, Jiyong and Bao, Yongjun and Ding, Guiguang},
  journal = TIP,
  volume  = {30},
  pages   = {9179--9192},
  year    = {2021},
}

@inproceedings{RD3D_RGBDSOD,
  title     = {RGB-D Salient Object Detection via 3D Convolutional Neural Networks},
  author    = {Chen, Qian and Liu, Ze and Zhang, Yi and Fu, Keren and Zhao, Qijun and Du, Hongwei},
  booktitle = AAAI,
  pages     = {1063--1071},
  year      = {2021},
}

@inproceedings{DSA2F_RGBDSOD,
  title     = {Deep RGB-D Saliency Detection with Depth-Sensitive Attention and Automatic Multi-Modal Fusion},
  author    = {Sun, Peng and Zhang, Wenhu and Wang, Huanyu and Li, Songyuan and Li, Xi},
  booktitle = CVPR,
  pages     = {1407--1417},
  year      = {2021},
}

@inproceedings{DCF_RGBDSOD,
  title     = {Calibrated RGB-D Salient Object Detection},
  author    = {Ji, Wei and Li, Jingjing and Yu, Shuang and Zhang, Miao and Piao, Yongri and Yao, Shunyu and Bi, Qi and Ma, Kai and Zheng, Yefeng and Lu, Huchuan and others},
  booktitle = CVPR,
  pages     = {9471--9481},
  year      = {2021},
}

@inproceedings{CMINet_RGBDSOD,
  title     = {Rgb-d saliency detection via cascaded mutual information minimization},
  author    = {Zhang, Jing and Fan, Deng-Ping and Dai, Yuchao and Yu, Xin and Zhong, Yiran and Barnes, Nick and Shao, Ling},
  booktitle = ICCV,
  pages     = {4338--4347},
  year      = {2021},
}

@inproceedings{SPNet_RGBDSOD,
  title     = {Specificity-preserving RGB-D saliency detection},
  author    = {Zhou, Tao and Fu, Huazhu and Chen, Geng and Zhou, Yi and Fan, Deng-Ping and Shao, Ling},
  booktitle = ICCV,
  pages     = {4681--4691},
  year      = {2021},
}

@inproceedings{DFM-Net_RGBDSOD,
  title     = {Depth Quality-Inspired Feature Manipulation for Efficient RGB-D Salient Object Detection},
  author    = {Zhang, Wenbo and Ji, Ge-Peng and Wang, Zhuo and Fu, Keren and Zhao, Qijun},
  booktitle = {ACM MM},
  pages     = {731--740},
  year      = {2021},
}

@inproceedings{TriTransNet_RGBDSOD,
  title     = {Tritransnet: Rgb-d salient object detection with a triplet transformer embedding network},
  author    = {Liu, Zhengyi and Wang, Yuan and Tu, Zhengzheng and Xiao, Yun and Tang, Bin},
  booktitle = {ACM MM},
  pages     = {4481--4490},
  year      = {2021},
}

@inproceedings{CDINet_RGBDSOD,
  title     = {Cross-modality Discrepant Interaction Network for RGB-D Salient Object Detection},
  author    = {Zhang, Chen and Cong, Runmin and Lin, Qinwei and Ma, Lin and Li, Feng and Zhao, Yao and Kwong, Sam},
  booktitle = {ACM MM},
  pages     = {2094--2102},
  year      = {2021},
}


@inproceedings{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  booktitle=NIPS,
  pages={5998–6008},
  year={2017}
}