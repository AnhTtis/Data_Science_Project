@article{kollias2021mia, title={MIA-COV19D: COVID-19 Detection through 3-D Chest CT Image Analysis}, author={Kollias, Dimitrios and Arsenos, Anastasios and Soukissian, Levon and Kollias, Stefanos}, journal={arXiv preprint arXiv:2106.07524}, year={2021}}

@article{kollias2023, title={AI-ENABLED ANALYSIS OF 3-D CT SCANS FOR DIAGNOSIS OF COVID-19 & ITS SEVERITY}, author={Kollias, Dimitrios and Arsenos, Anastasios and and Kollias, Stefanos}, journal={arXiv preprint }, year={2023}}

@article{kollias2020deep, title={Deep transparent prediction through latent representation analysis}, author={Kollias, Dimitrios and Bouas, N and Vlaxos, Y and Brillakis, V and Seferis, M and Kollia, Ilianna and Sukissian, Levon and Wingate, James and Kollias, S}, journal={arXiv preprint arXiv:2009.07044}, year={2020}}

@inproceedings{kollias2020transparent, title={Transparent Adaptation in Deep Medical Image Diagnosis.}, author={Kollias, Dimitris and Vlaxos, Y and Seferis, M and Kollia, Ilianna and Sukissian, Levon and Wingate, James and Kollias, Stefanos D}, booktitle={TAILOR}, pages={251–267}, year={2020}}

@article{kollias2018deep, title={Deep neural architectures for prediction in healthcare}, author={Kollias, Dimitrios and Tagaris, Athanasios and Stafylopatis, Andreas and Kollias, Stefanos and Tagaris, Georgios}, journal={Complex \& Intelligent Systems}, volume={4}, number={2}, pages={119–131}, year={2018}, publisher={Springer}}


@INPROCEEDINGS{Tran2018,
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={A Closer Look at Spatiotemporal Convolutions for Action Recognition}, 
  year={2018},
  volume={},
  number={},
  pages={6450-6459},
  doi={10.1109/CVPR.2018.00675}}

@inproceedings{46330,
title	= {The Kinetics Human Action Video Dataset},
author	= {Andrew Zisserman and Joao Carreira and Karen Simonyan and Will Kay and Brian Zhang and Chloe Hillier and Sudheendra Vijayanarasimhan and Fabio Viola and Tim Green and Trevor Back and Paul Natsev and Mustafa Suleyman},
year	= {2017}
}

@article{kollias2022ai, title={AI-MIA: COVID-19 Detection \& Severity Analysis through Medical Imaging}, author={Kollias, Dimitrios and Arsenos, Anastasios and Kollias, Stefanos}, journal={arXiv preprint arXiv:2206.04732}, year={2022}}

@article{peeling2022,
    author = "Peeling, Rosanna W and Heymann, David L and Teo, Yik-Ying and Garcia, Patricia J",
    type = "Journal Article; Review",
    title = "Diagnostics for COVID-19: moving from pandemic response to control.",
    journal = "Lancet (London, England)",
    date = "2022 Feb 19",
    volume = "399",
    pages = "757-768",
    issn = "1474-547X (Electronic); 0140-6736 (Print); 0140-6736 (Linking)",
    abstract = "Diagnostics have proven to be crucial to the COVID-19 pandemic response. Thereare three major methods for the detection of SARS-CoV-2 infection and their rolehas evolved during the course of the pandemic. Molecular tests such as PCR arehighly sensitive and specific at detecting viral RNA, and are recommended by WHOfor confirming diagnosis in individuals who are symptomatic and for activatingpublic health measures. Antigen rapid detection tests detect viral proteins and,although they are less sensitive than molecular tests, have the advantages ofbeing easier to do, giving a faster time to result, of being lower cost, and ableto detect infection in those who are most likely to be at risk of transmittingthe virus to others. Antigen rapid detection tests can be used as a public healthtool for screening individuals at enhanced risk of infection, to protect peoplewho are clinically vulnerable, to ensure safe travel and the resumption ofschooling and social activities, and to enable economic recovery. With vaccineroll-out, antibody tests (which detect the host's response to infection orvaccination) can be useful surveillance tools to inform public policy, but shouldnot be used to provide proof of immunity, as the correlates of protection remainunclear. All three types of COVID-19 test continue to have a crucial role in thetransition from pandemic response to pandemic control.",
    year = "2022",
    doi = "10.1016/S0140-6736(21)02346-1",
    pmid = "34942102",
    own = "NLM",
    stat = "MEDLINE",
    dcom = "20220301",
    lr = "20220301",
    ip = "10326",
    lid = "S0140-6736(21)02346-1 [pii]; 10.1016/S0140-6736(21)02346-1 [doi]",
    ci = "Copyright © 2022 Elsevier Ltd. All rights reserved.",
    au = "Peeling RW; Heymann DL; Teo YY; Garcia PJ",
    ad = "Clinical Research Department, London School of Hygiene \& Tropical Medicine,London, UK; Medical Microbiology Department, University of Manitoba, Winnipeg,Manitoba, Canada. Electronic address: rosanna.peeling@lshtm.ac.uk.; Clinical Research Department, London School of Hygiene \& Tropical Medicine,London, UK.; Saw Swee Hock School of Public Health, National University of Singapore,Singapore.; School of Public Health, Universidad Peruana Cayetano Heredia, Lima, Peru;Department of Global Health, University of Washington, Seattle, WA, USA.",
    la = "eng",
    dep = "20211220",
    ta = "Lancet",
    jid = "2985213R",
    rn = "0 (Antibodies, Viral); 0 (Antigens, Viral); 0 (COVID-19 Vaccines); 0 (RNA, Viral)",
    sb = "IM",
    mh = "Antibodies, Viral/blood; Antigens, Viral/isolation \& purification; COVID-19/*diagnosis/epidemiology/transmission/virology; COVID-19 Testing/methods/*trends; COVID-19 Vaccines/administration \& dosage; Communicable Disease Control/methods/*organization \& administration/trends; Humans; Mass Screening/*organization \& administration/trends; Pandemics/*prevention \& control; RNA, Viral/isolation \& purification; SARS-CoV-2/genetics/immunology/isolation \& purification",
    pmc = "PMC8687671",
    cois = "Declaration of interests We declare no competing interests.",
    edat = "2021/12/24 06:00",
    mhda = "2022/03/03 06:00",
    crdt = "2021/12/23 20:11",
    phst = "2021/05/03 00:00 [received]; 2021/10/06 00:00 [revised]; 2021/10/20 00:00 [accepted]; 2021/12/24 06:00 [pubmed]; 2022/03/03 06:00 [medline]; 2021/12/23 20:11 [entrez]",
    pst = "ppublish",
    so = "Lancet. 2022 Feb 19;399(10326):757-768. doi: 10.1016/S0140-6736(21)02346-1. Epub2021 Dec 20.",
    aid = "S0140-6736(21)02346-1 [pii]"
}

@misc{who2021,
  title = {{Recommendations for national SARS-CoV-2 testing strategies and diagnostic capacities}},
  howpublished = {\url{https://www.who.int/publications/i/item/WHO-2019-nCoV-lab-testing-2021.1-eng}},
  author = {{World Health Organization}},
  date = "2021 June 25",
  note = {Accessed: 2022-06-27}
}

@article{seeram2018,
    author = "Seeram, Euclid",
    type = "Journal Article; Review",
    title = "Computed Tomography: A Technical Review",
    journal = "Radiologic Technology",
    date = "2018 Jan",
    volume = "89",
    pages = "279CT-302CT",
    issn = "1943-5657 (Electronic); 0033-8397 (Linking)",
    abstract = "Computed tomography (CT) is a technical and complex diagnostic imaging modality.Radiologic technologists must understand the technology well enough to optimizedose and image quality and provide excellent patient care. This article reviewsessential physical principles and technical aspects of CT, including physicsrelated to radiation attenuation and CT numbers along with general technicalconcepts. In addition, the article reviews multislice CT technology.",
    year = "2018",
    pmid = "29298954",
    own = "NLM",
    stat = "MEDLINE",
    dcom = "20180914",
    lr = "20180914",
    ip = "3",
    ci = "© 2018 American Society of Radiologic Technologists.",
    au = "Seeram E",
    la = "eng",
    pl = "United States",
    ta = "Radiol Technol",
    jid = "0401256",
    sb = "IM",
    mh = "Humans; Imaging, Three-Dimensional; Physics; Radiation Dosage; Radiation Protection; Radiographic Image Interpretation, Computer-Assisted; Tomography, X-Ray Computed/instrumentation/*methods",
    edat = "2018/01/05 06:00",
    mhda = "2018/09/15 06:00",
    crdt = "2018/01/05 06:00",
    phst = "2018/01/05 06:00 [entrez]; 2018/01/05 06:00 [pubmed]; 2018/09/15 06:00 [medline]",
    pst = "ppublish",
    so = "Radiol Technol. 2018 Jan;89(3):279CT-302CT.",
    aid = "89/3/279CT [pii]"
}

@article{harmon2020,
    author = "Harmon, Stephanie A. and Sanford, Thomas H. and Xu, Sheng and Turkbey, Evrim B. and Roth, Holger and Xu, Ziyue and Yang, Dong and Myronenko, Andriy and Anderson, Victoria and Amalou, Amel and Blain, Maxime and Kassin, Michael and Long, Dilara and Varble, Nicole and Walker, Stephanie M. and Bagci, Ulas and Ierardi, Anna Maria and Stellato, Elvira and Plensich, Guido Giovanni and Franceschelli, Giuseppe and Girlando, Cristiano and Irmici, Giovanni and Labella, Dominic and Hammoud, Dima and Malayeri, Ashkan and Jones, Elizabeth and Summers, Ronald M. and Choyke, Peter L. and Xu, Daguang and Flores, Mona and Tamura, Kaku and Obinata, Hirofumi and Mori, Hitoshi and Patella, Francesca and Cariati, Maurizio and Carrafiello, Gianpaolo and An, Peng and Wood, Bradford J. and Turkbey, Baris",
    type = "Journal Article",
    title = "Artificial intelligence for the detection of COVID-19 pneumonia on chest CT using multinational datasets",
    journal = "Nature Communications",
    number = "1",
    doi = "10.1038/s41467-020-17971-2",
    volume = "11",
    pages = "4080",
    url = "https://doi.org/10.1038/s41467-020-17971-2",
    year = "2020",
    abstract = "Chest CT is emerging as a valuable diagnostic tool for clinical management of COVID-19 associated lung disease. Artificial intelligence (AI) has the potential to aid in rapid evaluation of CT scans for differentiation of COVID-19 findings from other clinical entities. Here we show that a series of deep learning algorithms, trained in a diverse multinational cohort of 1280 patients to localize parietal pleura/lung parenchyma followed by classification of COVID-19 pneumonia, can achieve up to 90.8\% accuracy, with 84\% sensitivity and 93\% specificity, as evaluated in an independent test set (not included in training and validation) of 1337 patients. Normal controls included chest CTs from oncology, emergency, and pneumonia-related indications. The false positive rate in 140 patients with laboratory confirmed other (non COVID-19) pneumonias was 10\%. AI-based algorithms can readily identify CT scans with COVID-19 associated pneumonia, as well as distinguish non-COVID related pneumonias with high specificity in diverse patient populations.",
    issn = "2041-1723",
    da = "2020/08/14"
}

@article{doi:10.1148/radiol.2020200343,
author = {Xie, Xingzhi and Zhong, Zheng and Zhao, Wei and Zheng, Chao and Wang, Fei and Liu, Jun},
title = {{Chest CT for Typical Coronavirus Disease 2019 (COVID-19) Pneumonia:                     Relationship to Negative RT-PCR Testing}},
journal = {Radiology},
volume = {296},
number = {2},
pages = {E41-E45},
year = {2020},
doi = {10.1148/radiol.2020200343},
    note ={PMID: 32049601},

URL = { 
        https://doi.org/10.1148/radiol.2020200343
    
},
eprint = { 
        https://doi.org/10.1148/radiol.2020200343
    
}
,
    abstract = { Some patients with positive chest CT findings may present with negative results of real-time reverse-transcription polymerase chain reaction (RT-PCR) tests for coronavirus disease 2019 (COVID-19). In this study, the authors present chest CT findings from five patients with COVID-19 infection who had initial negative RT-PCR results. All five patients had typical imaging findings, including ground-glass opacity (five patients) and/or mixed ground-glass opacity and mixed consolidation (two patients). After isolation for presumed COVID-19 pneumonia, all patients were eventually confirmed to have COVID-19 infection by means of repeated swab tests. A combination of repeated swab tests and CT scanning may be helpful for individuals with a high clinical suspicion of COVID-19 infection but negative findings at RT-PCR screening. © RSNA, 2020 }
}


@INPROCEEDINGS{Hou2021,
  author={Hou, Junlin and Xu, Jilan and Feng, Rui and Zhang, Yuejie and Shan, Fei and Shi, Weiya},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, 
  title={CMC-COV19D: Contrastive Mixup Classification for COVID-19 Diagnosis}, 
  year={2021},
  volume={},
  number={},
  pages={454-461},
  doi={10.1109/ICCVW54120.2021.00055}
 }
 
 @article{Miron2021COVIDDI,
  title={{}COVID Detection in Chest CTs: Improving the Baseline on COV19-CT-DB}},
  author={Radu Miron and Cosmin Moisii and Sergiu-Andrei Dinu and Mihaela Breaban},
  journal={ArXiv},
  year={2021},
  volume={abs/2107.04808}
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@Article{fastai2,
AUTHOR = {Howard, Jeremy and Gugger, Sylvain},
TITLE = {{Fastai: A Layered API for Deep Learning}},
JOURNAL = {Information},
VOLUME = {11},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {108},
URL = {https://www.mdpi.com/2078-2489/11/2/108},
ISSN = {2078-2489},
ABSTRACT = {fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4&ndash;5 lines of code; a novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training; a new data block API; and much more. We used this library to successfully create a complete deep learning course, which we were able to write more quickly than using previous approaches, and the code was more clear. The library is already in wide use in research, industry, and teaching.},
DOI = {10.3390/info11020108}
}
@INPROCEEDINGS{resnet,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  doi={10.1109/CVPR.2016.90}}

@misc{Kinetics,
  doi = {10.48550/ARXIV.1705.06950},
  
  url = {https://arxiv.org/abs/1705.06950},
  
  author = {Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and Suleyman, Mustafa and Zisserman, Andrew},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {The Kinetics Human Action Video Dataset},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.com},
url={https://www.wandb.com/},
author = {Biewald, Lukas},
}

@misc{dropout,
  doi = {10.48550/ARXIV.1207.0580},
  
  url = {https://arxiv.org/abs/1207.0580},
  
  author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
  
  keywords = {Neural and Evolutionary Computing (cs.NE), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Improving neural networks by preventing co-adaptation of feature detectors},
  
  publisher = {arXiv},
  
  year = {2012},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@InProceedings{pmlr-v48-gal16,
  title = 	 {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
  author = 	 {Gal, Yarin and Ghahramani, Zoubin},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1050--1059},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/gal16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/gal16.html},
  abstract = 	 {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs – extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout’s uncertainty in deep reinforcement learning.}
}

@misc{adam,
  doi = {10.48550/ARXIV.1412.6980},
  
  url = {https://arxiv.org/abs/1412.6980},
  
  author = {Kingma, Diederik P. and Ba, Jimmy},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Adam: A Method for Stochastic Optimization},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@misc{smith2018,
  doi = {10.48550/ARXIV.1803.09820},
  
  url = {https://arxiv.org/abs/1803.09820},
  
  author = {Smith, Leslie N.},
  
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@INPROCEEDINGS {labelsmoothing,
author = {C. Szegedy and V. Vanhoucke and S. Ioffe and J. Shlens and Z. Wojna},
booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Rethinking the Inception Architecture for Computer Vision},
year = {2016},
volume = {},
issn = {1063-6919},
pages = {2818-2826},
keywords = {convolution;computer architecture;training;computational efficiency;computer vision;benchmark testing;computational modeling},
doi = {10.1109/CVPR.2016.308},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2016.308},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}

@misc{arxiv.2207.01579,
  doi = {10.48550/ARXIV.2207.01579},
  
  url = {https://arxiv.org/abs/2207.01579},
  
  author = {Hsu, Chih-Chung and Tsai, Chi-Han and Chen, Guan-Lin and Ma, Sin-Di and Tai, Shen-Chieh},
  
  keywords = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Spatiotemporal Feature Learning Based on Two-Step LSTM and Transformer for CT Scans},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{arxiv.2207.01758,
  doi = {10.48550/ARXIV.2207.01758},
  
  url = {https://arxiv.org/abs/2207.01758},
  
  author = {Hou, Junlin and Xu, Jilan and Feng, Rui and Zhang, Yuejie},
  
  keywords = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {FDVTS's Solution for 2nd COV19D Competition on COVID-19 Detection and Severity Analysis},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@INPROCEEDINGS{arsenos2022large,
  author={Arsenos, Anastasios and Kollias, Dimitrios and Kollias, Stefanos},
  booktitle={2022 IEEE 14th Image, Video, and Multidimensional Signal Processing Workshop (IVMSP)}, 
  title={{A Large Imaging Database and Novel Deep Neural Architecture for Covid-19 Diagnosis}}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/IVMSP54334.2022.9816321}}


@article{hofmanninger2020,
    author = "Hofmanninger, Johannes and Prayer, Forian and Pan, Jeanny and Röhrich, Sebastian and Prosch, Helmut and Langs, Georg",
    type = "Journal Article",
    title = "Automatic lung segmentation in routine imaging is primarily a data diversity problem, not a methodology problem",
    journal = "European Radiology Experimental",
    number = "1",
    doi = "10.1186/s41747-020-00173-2",
    volume = "4",
    pages = "50",
    url = "https://doi.org/10.1186/s41747-020-00173-2",
    year = "2020",
    abstract = "Automated segmentation of anatomical structures is a crucial step in image analysis. For lung segmentation in computed tomography, a variety of approaches exists, involving sophisticated pipelines trained and validated on different datasets. However, the clinical applicability of these approaches across diseases remains limited.",
    issn = "2509-9280",
    da = "2020/08/20"
}
@article{rister2020,
    author = "Rister, Blaine and Yi, Darvin and Shivakumar, Kaushik and Nobashi, Tomomi and Rubin, Daniel L.",
    type = "Journal Article",
    title = "CT-ORG, a new dataset for multiple organ segmentation in computed tomography",
    journal = "Scientific Data",
    number = "1",
    doi = "10.1038/s41597-020-00715-8",
    volume = "7",
    pages = "381",
    url = "https://doi.org/10.1038/s41597-020-00715-8",
    year = "2020",
    abstract = "Despite the relative ease of locating organs in the human body, automated organ segmentation has been hindered by the scarcity of labeled training data. Due to the tedium of labeling organ boundaries, most datasets are limited to either a small number of cases or a single organ. Furthermore, many are restricted to specific imaging conditions unrepresentative of clinical practice. To address this need, we developed a diverse dataset of 140 CT scans containing six organ classes: liver, lungs, bladder, kidney, bones and brain. For the lungs and bones, we expedited annotation using unsupervised morphological segmentation algorithms, which were accelerated by 3D Fourier transforms. Demonstrating the utility of the data, we trained a deep neural network which requires only 4.3 s to simultaneously segment all the organs in a case. We also show how to efficiently augment the data to improve model generalization, providing a GPU library for doing so. We hope this dataset and code, available through TCIA, will be useful for training and evaluating organ segmentation models.",
    issn = "2052-4463",
    da = "2020/11/11"
}

@misc{Hsu2022,
  doi = {10.48550/ARXIV.2207.01579},
  
  url = {https://arxiv.org/abs/2207.01579},
  
  author = {Hsu, Chih-Chung and Tsai, Chi-Han and Chen, Guan-Lin and Ma, Sin-Di and Tai, Shen-Chieh},
  
  keywords = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Spatiotemporal Feature Learning Based on Two-Step LSTM and Transformer for CT Scans},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{Hou2022,
  doi = {10.48550/ARXIV.2207.01758},
  
  url = {https://arxiv.org/abs/2207.01758},
  
  author = {Hou, Junlin and Xu, Jilan and Feng, Rui and Zhang, Yuejie},
  
  keywords = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {FDVTS's Solution for 2nd COV19D Competition on COVID-19 Detection and Severity Analysis},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{turnbull2022,
  doi = {10.48550/ARXIV.2207.12218},
  
  url = {https://arxiv.org/abs/2207.12218},
  
  author = {Turnbull, Robert},
  
  keywords = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences, I.2.10},
  
  title = {Cov3d: Detection of the presence and severity of COVID-19 from CT scans using 3D ResNets},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{liu2021,
  doi = {10.48550/ARXIV.2106.13230},
  
  url = {https://arxiv.org/abs/2106.13230},
  
  author = {Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Video Swin Transformer},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{Kienzle2022,
  doi = {10.48550/ARXIV.2206.15073},
  
  url = {https://arxiv.org/abs/2206.15073},
  
  author = {Kienzle, Daniel and Lorenz, Julian and Schön, Robin and Ludwig, Katja and Lienhart, Rainer},
  
  keywords = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {COVID Detection and Severity Prediction with 3D-ConvNeXt and Custom Pretrainings},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{scikit-image,
 title = {scikit-image: image processing in {P}ython},
 author = {van der Walt, {S}t\'efan and {S}ch\"onberger, {J}ohannes {L}. and
           {Nunez-Iglesias}, {J}uan and {B}oulogne, {F}ran\c{c}ois and {W}arner,
           {J}oshua {D}. and {Y}ager, {N}eil and {G}ouillart, {E}mmanuelle and
           {Y}u, {T}ony and the scikit-image contributors},
 year = {2014},
 month = {6},
 keywords = {Image processing, Reproducible research, Education,
             Visualization, Open source, Python, Scientific programming},
 volume = {2},
 pages = {e453},
 journal = {PeerJ},
 issn = {2167-8359},
 url = {https://doi.org/10.7717/peerj.453},
 doi = {10.7717/peerj.453}
}


@misc{focalloss,
  doi = {10.48550/ARXIV.1708.02002},
  
  url = {https://arxiv.org/abs/1708.02002},
  
  author = {Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollár, Piotr},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Focal Loss for Dense Object Detection},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Hou2016,
  doi = {10.48550/ARXIV.1611.05916},
  
  url = {https://arxiv.org/abs/1611.05916},
  
  author = {Hou, Le and Yu, Chen-Ping and Samaras, Dimitris},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Squared Earth Mover's Distance-based Loss for Training Deep Neural Networks},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}







@article{stoic,
author = {Revel, Marie-Pierre and Boussouar, Samia and de                             Margerie-Mellon, Constance and Saab, In\`{e}s and Lapotre, Thibaut and Mompoint, Dominique and Chassagnon, Guillaume and Milon, Audrey and Lederlin, Mathieu and Bennani, Souhail and Moli\`{e}re, S\'{e}bastien and Debray, Marie-Pierre and Bompard, Florian and Dangeard, Severine and Hani, Chahinez and Ohana, Micka\"{e}l and Bommart, S\'{e}bastien and Jalaber, Carole and El                             Hajjam, Mostafa and Petit, Isabelle and Fournier, Laure and Khalil, Antoine and Brillet, Pierre-Yves and Bellin, Marie-France and Redheuil, Alban and Rocher, Laurence and Bousson, Val\'{e}rie and Rousset, Pascal and Gr\'{e}gory, Jules and Deux, Jean-Fran\c{c}ois and Dion, Elisabeth and Valeyre, Dominique and Porcher, Raphael and Jilet, L\'{e}a and Abdoul, Hendy},
title = {Study of Thoracic CT in COVID-19: The STOIC Project},
journal = {Radiology},
volume = {301},
number = {1},
pages = {E361-E370},
year = {2021},
doi = {10.1148/radiol.2021210384},
    note ={PMID: 34184935},

URL = { 
    
        https://doi.org/10.1148/radiol.2021210384
    
    

},
eprint = { 
    
        https://doi.org/10.1148/radiol.2021210384
    
    

}
,
    abstract = { Background There are conflicting data regarding the diagnostic performance of chest CT for COVID-19 pneumonia. Disease extent at CT has been reported to influence prognosis. Purpose To create a large publicly available data set and assess the diagnostic and prognostic value of CT in COVID-19 pneumonia. Materials and Methods This multicenter, observational, retrospective cohort study involved 20 French university hospitals. Eligible patients presented at the emergency departments of the hospitals involved between March 1 and April 30th, 2020, and underwent both thoracic CT and reverse transcription–polymerase chain reaction (RT-PCR) testing for suspected COVID-19 pneumonia. CT images were read blinded to initial reports, RT-PCR, demographic characteristics, clinical symptoms, and outcome. Readers classified CT scans as either positive or negative for COVID-19 based on criteria published by the French Society of Radiology. Multivariable logistic regression was used to develop a model predicting severe outcome (intubation or death) at 1-month follow-up in patients positive for both RT-PCR and CT, using clinical and radiologic features. Results Among 10 930 patients screened for eligibility, 10 735 (median age, 65 years; interquartile range, 51–77 years; 6147 men) were included and 6448 (60\%) had a positive RT-PCR result. With RT-PCR as reference, the sensitivity and specificity of CT were 80.2\% (95\% CI: 79.3, 81.2) and 79.7\% (95\% CI: 78.5, 80.9), respectively, with strong agreement between junior and senior radiologists (Gwet AC1 coefficient, 0.79). Of all the variables analyzed, the extent of pneumonia at CT (odds ratio, 3.25; 95\% CI: 2.71, 3.89) was the best predictor of severe outcome at 1 month. A score based solely on clinical variables predicted a severe outcome with an area under the curve of 0.64 (95\% CI: 0.62, 0.66), improving to 0.69 (95\% CI: 0.6, 0.71) when it also included the extent of pneumonia and coronary calcium score at CT. Conclusion Using predefined criteria, CT reading is not influenced by reader's experience and helps predict the outcome at 1 month. ClinicalTrials.gov identifier: NCT04355507 Published under a CC BY 4.0 license. Online supplemental material is available for this article. See also the editorial by Rubin in this issue. }
}


