% $Id: introduction.tex $
% !TEX root = main.tex

\section{Introduction}
\label{sec:introduction}

\acf{RL} is a \ac{ML} approach in which an agent learns to solve 
a problem by trial and error in interaction with the environment. 
\ac{RL} formalizes the agentâ€™s goal, taking 
into account the set of environment states, and the set of possible 
actions to execute in each state. Agents have an associated reward 
model, so that for each given action taken at a given state, agents 
receive a scalar reward, reflecting the desirability of the outcome (\ie positive reward or a punishment). 
The purpose of the agent is to maximize the total cumulative reward 
received to reach its goal, from any given initial 
state~\cite{sutton98}.

In the last years, thanks to the development of open source libraries 
and methods that allow rapid prototyping, \ac{RL} has expanded as a 
tool in many disciplines, like data science, control theory, finance, 
chemistry, and neuroscience. However the rapid grow of these systems 
has lead to prototypes and projects to have very irregular structures 
as they are basically an heterogeneous set of libraries, components, 
program identifiers, data processing functions and training algorithms 
patched with glue code~\cite{jebnoun20}. These projects normally 
introduce \ac{RL} to improve on the processing power or accuracy of an 
existing solution as an immediate goal, but set aside middle and long 
term objectives (\eg easy debugging, maintenance, extensibility, 
future improvements). This loose structure contributes to code 
complexity and technical debt~\cite{sculley15}, which in turn can 
result in severe quality and performance issues of the entire software 
systems~\cite{seaman12, jebnoun20}.
One of the symptoms of poor implementations in software systems are 
code smells~\cite{chen18}. Code smells are bad patterns in source code 
that may signify a violation of fundamental design 
principles~\cite{suryanarayana14}. Code smells slow down software 
evolution due to code misunderstandings, bring maintenance 
difficulties, and increase the risk of defects~\cite{pdr22}. 
The presence of code smells negatively impacts
software quality and can indicate where to apply beneficial 
refactoring. The study of code smells in \ac{ML} projects~\cite{vanoort21, zhang22} 
highlights potential pitfalls that can be decremental for the 
efficiency of the algorithm or even introduce bugs in the program. 
Identified code smells in \ac{ML} projects include coding notation 
misused, coding omissions, errors in function calls, and problems in data 
processing. While current studies have identified the existence of 
general code smells and \ac{ML}-specific code smells, no evaluation 
dedicated to \ac{RL} exists.

In this paper we carry a preliminary empirical study of the code 
quality of \ac{RL} projects, through the identification of code 
smells. The purpose of this is to evaluate our hypothesis: 
\emph{\ac{RL} projects suffer from poor code quality, which may lead 
to maintenance and evolution problems}. We analyze \ac{RL}-based systems with respect to eight 
software quality metrics~\cite{lanza07} related to the code organization, 
abstraction, and expression of programs (\fref{sec:quality}). The 
calculated metrics serve as a proxy to assess the maintainability and 
evolution of \ac{RL}-based projects. We evaluate 24 GitHub \ac{RL}-based Python projects using 
Q-learning and \ac{DQN}, as the most popular and straight-forward \ac{RL} algorithms 
(\fref{sec:evaluation}). Our results identify a total of 1090 code smells across all projects. The most 
common smells found are related to the definition and access to the entities in \ac{RL} projects. This 
exposes a violation of the single responsibility principle, and bad modularization of the 
projects, which is directly related to problems in the maintainability 
and evolution of the projects.
 
The results obtained from the analysis support our hypothesis that \ac{RL}-based projects suffer 
from poor quality, pointing out to the need for specialized analysis 
tools and programming languages for the development of such projects. We conclude the study 
(\fref{sec:lang}) by proposing potential research avenues for addressing this shortcoming, through, 
\eg dedicated static analysis tools, or specialized programming languages. 


\endinput

RL algorithms can be model-based or model-free depending on the use of a transition model, which characterizes the environment and allows us to infer how the system will behave [2]. RL Models are used for planning, that is, considering possible future situations and deciding a course of action. Because of this, model-based RL algorithms may seem always desirable. However if it is very difficult to construct a sufficiently accurate model for a given environment, model-free RL algorithms can have advantages [2]. Additionally model- free methods are important building blocks of more complex model-based methods [2].