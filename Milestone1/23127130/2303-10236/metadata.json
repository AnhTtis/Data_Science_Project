{
    "arxiv_id": "2303.10236",
    "paper_title": "Prevalence of Code Smells in Reinforcement Learning Projects",
    "authors": [
        "Nicol√°s Cardozo",
        "Ivana Dusparic",
        "Christian Cabrera"
    ],
    "submission_date": "2023-03-17",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.SE"
    ],
    "abstract": "Reinforcement Learning (RL) is being increasingly used to learn and adapt application behavior in many domains, including large-scale and safety critical systems, as for example, autonomous driving. With the advent of plug-n-play RL libraries, its applicability has further increased, enabling integration of RL algorithms by users. We note, however, that the majority of such code is not developed by RL engineers, which as a consequence, may lead to poor program quality yielding bugs, suboptimal performance, maintainability, and evolution problems for RL-based projects. In this paper we begin the exploration of this hypothesis, specific to code utilizing RL, analyzing different projects found in the wild, to assess their quality from a software engineering perspective. Our study includes 24 popular RL-based Python projects, analyzed with standard software engineering metrics. Our results, aligned with similar analyses for ML code in general, show that popular and widely reused RL repositories contain many code smells (3.95% of the code base on average), significantly affecting the projects' maintainability. The most common code smells detected are long method and long method chain, highlighting problems in the definition and interaction of agents. Detected code smells suggest problems in responsibility separation, and the appropriateness of current abstractions for the definition of RL algorithms.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10236v1"
    ],
    "publication_venue": "Paper preprint for the CAIN2023 paper of the same name"
}