In this paper, we took a closer look at the behavior of protocols designed for adapting large-scale pretrained models to downstream datasets. While it is argued that adaptation protocols should be designed to mitigate feature distortion (e.g., \lpft) in order to improve ID and OOD generalization, we found that when additional aspects of safe generalization are evaluated (e.g., prediction calibration error, adversarial robustness etc.), mitigating feature distortion alone is not sufficient. We then considered the complementary perspective, that adaptation protocols should also mitigate simplicity bias. Using a synthetic dominoes dataset that allows for control over the correlation between simple and complex features, we found that protocols have varying levels of effectiveness in reducing reliance upon simple features. While, as expected, \ft, is most susceptible to simplicity bias, we see that \lpft~is able to balance both distortion and simplicity bias in settings where the correlation between simple and complex features is not too extreme. Motivated by the benefits of \lpft~and given the known relationship between simplicity bias and sub-optimal generalization, we used ``hardness-promoting'' \lp~initializations (virtual adversarial, uncertainty-driven perturbations, sparse soups) to further improve \lpft's performance. 
These modifications helped reduce \lpft's reliance upon simple features on the synthetic dataset. On three real-world datasets, these modified protocols led to some improvements in safety and generalization performance, further validating the need to consider both distortion and simplicity bias when designing adaptation protocols.