\begin{wrapfigure}{r}{0.35\textwidth}
\vspace{-0.2in}
\begin{center}
\includegraphics[width=0.35\textwidth]{FIGS_v3/IntroFigure.pdf}
\end{center}
\caption{\textbf{Strong and Safe Adaptation.}
Practical deployment in high risk applications requires that adapted models not only generalize well to in- and out-of distribution data of the downstream task, but they do so safely.}
\vspace{-0.2in}
\label{fig:teaser}
\end{wrapfigure}

Through the use of larger datasets~\citep{Yalniz19_BillionScaleSSL}, better architectures~\citep{zhai2022lit,chen2021outperform,steiner2021augreg,tolstikhin2021mixer}, and different self-supervised learning (SSL) approaches~\citep{He20_MoCo,Chen20_SimCLR,Grill20_BYOL,Swav_Caron20}, the quality of pretrained representations available for transfer learning tasks has dramatically improved. Indeed, representations from such high-quality SSL models have been found to be more robust \citep{Hendrycks19_SSLRobust,Liu21_SSLDatasetImbalance}, transferable \citep{Ericsson21_SSLTransfer} and semantically consistent \citep{DINO_caron21} than their supervised counterparts. In this regard, there is growing need for adaptation protocols that explicitly capitalize on these improved pretrained features to induce similar beneficial properties, \textit{e.g.,} inducing more than just high accuracy on the target task, after models have been trained on the downstream task.  

However, standard adaptation protocols that rely upon fine-tuning (\ft) all model parameters or training only a linear probe (\lp) while freezing the network parameters do not maximize the potential of high-quality representations. For example, while high-quality, pre-trained models have sufficiently expressive features to perform well on both in-distribution (ID) and out-of-distribution (OOD) data, \lp~and \ft~are not able to effectively induce this property in adapted models \citep{Andreassen21_EvolutionOOD}. Recently, however, \citet{Kumar22_FinetuningDistorts} proved that by modifying features only in the ID representation subspace, \ft~can lead to higher OOD error as it distorts directions outside the ID subspace that are needed for OOD generalization. As both ID and OOD subspaces are represented by the pretrained model, Kumar et al. demonstrate that limiting \textit{feature distortion}, or controlling updates towards the ID subspace, can lead to improved ID and OOD performance. To this end, they propose a new protocol which performs \lp~prior to \ft~(abbrev. \lp~\texttt{+}~\ft). By first performing \lp, this two-step process ensures that subsequent \ft~will remain in the vicinity of the original \lp~solution. This reduces the overall distortion towards the ID distribution subspace and improves performance.

While strong ID and OOD generalization on the target task is indeed an important aspect of transfer learning, practical, high-risk applications require that models are also safe~\citep{Hendrycks21_UnsolvedProblems}. For example, adapted models should also be well-calibrated, robust to corruptions or adversaries and able to reliably detect anomalous samples (see Figure \ref{fig:teaser}). Given that existing adaptation protocols are primarily focused on improving generalization, it is unclear how existing protocols utilize high-quality pretrained features to promote safe adaptation, and if current protocol design perspectives, such as mitigating feature distortion, will also enable safe generalization. 

\noindent\textbf{Our Work}: In this work, we seek to understand the factors relevant to the design of adaption protocols that promote effective \textit{and} safe generalization. We take the first step towards this aim by (i) demonstrating limitations in existing \lp,~\ft,~and \lpft~protocols through an extensive, joint evaluation, and (ii) studying adaptation protocols through the complementary lens of avoiding simplicity bias, \textit{i.e.}, the problematic tendency of deep neural networks (DNNs) to prefer simple, potentially brittle features over complex features~\citep{Soudry18_ImplicitBias,Gunasekar18,geirhos18_texturebias,Hermann20_OriginsTexture,Shah20_SimplicityBias}. Using the insights from our analysis, we propose three variants of the \lpft~protocol that jointly improve safety and generalization on three datasets. Our contributions can be summarized as follows:

\begin{itemize}[leftmargin=*]

\item \textbf{Joint Analysis of Adaptation Protocol Safety and Generalization (Sec.~\ref{sec:tradeoffs}).} We show that when adaptation protocols are evaluated with respect to both ID/OOD generalization and safety, \lpft~trails behind \lp~or \ft~on several safety metrics. This demonstrates that solely mitigating feature distortion may not be sufficient for safe generalization. We also observe that keeping subsequent \ft~close to \lp~solution is crucial for the improved OOD generalization of \lpft. This motivates us to focus on improving the \lp~initialization as a mechanism for improving both safety and OOD performance.

\item \textbf{Role of Simplicity Bias in (Unsafe) Adaptation (Sec.~\ref{sec:simplicity}).} To understand how protocols may induce safe adaptation, we study how different protocols avoid simplicity bias. While simplicity bias \citep{Shah20_SimplicityBias,geirhos18_texturebias} has been shown to underlie several problems in machine learning safety, to the best of our knowledge, we are the first to consider its role in adaptation settings. We demonstrate that protocols must not only reduce distortion, but also should mitigate simplicity bias for effective adaptation.  

\item\textbf{Improved Protocols for Mitigating Simplicity Bias and Distortion (Sec.~\ref{sec:hardness}).} We propose three, simple modified \lpft~protocols that help mitigate both simplicity bias and distortion (Sec.~\ref{sec:improved_protocols}). In particular, we consider modifying the \lp~step with uncertainty-driven perturbations~\citep{pagliardini22_udp}, virtual adversarial training~\citep{Miyato17_Vat} and model-soups \citep{wortsman22_modelsoup}, as they are simple and effective strategies. Across synthetic and real datasets, the modified protocols help improve safety and generalization to some extent.
\end{itemize}
