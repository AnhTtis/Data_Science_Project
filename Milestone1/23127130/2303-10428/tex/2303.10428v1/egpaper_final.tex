\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{makecell}

\usepackage{comment}
\usepackage{tabulary,multirow,overpic}
\usepackage{wrapfig}
\usepackage[table]{xcolor}

%\usepackage{blindtext}
%\usepackage{float}
%\usepackage{enumitem}
%\usepackage[table]{xcolor}
%\usepackage{tabulary,multirow,overpic}
%\usepackage{verbatim}
%\usepackage{color}
%\usepackage{multicol}
%\usepackage{dblfloatfix}
%\usepackage{pifont}%
%\usepackage[accsupp]{axessibility}  
%\usepackage{tikz}
%\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{pythonhighlight}
\usepackage[super]{nth}

%\usepackage{wrapfig}


\lstnewenvironment{PythonA}[1][]{\lstset{style=mypython, #1}}{}

\newcommand{\rulesep}{\color{blue} \unskip\ \vrule\ }
\newcommand{\dataset}{{\usefont{T1}{pzc}{m}{n} ART}}

\newcolumntype{x}[1]{>{\centering\arraybackslash}p{#1pt}}
\newcommand{\dt}[1]{\fontsize{8pt}{.1em}\selectfont \emph{#1}}
\newlength\savewidth\newcommand\shline{\noalign{\global\savewidth\arrayrulewidth
		\global\arrayrulewidth 1pt}\hline\noalign{\global\arrayrulewidth\savewidth}}
\newcommand{\tablestyle}[2]{\setlength{\tabcolsep}{#1}\renewcommand{\arraystretch}{#2}\centering\footnotesize}


\definecolor{baselinecolor}{gray}{.92}
\newcommand{\default}[1]{\cellcolor{baselinecolor}{#1}}

\definecolor{demphcolor}{gray}{.2}
\newcommand{\demph}[1]{\textcolor{demphcolor}{#1}}

\definecolor{demphcolor1}{gray}{.5}
\newcommand{\demphs}[1]{\textcolor{demphcolor1}{#1}}


\definecolor{citecolor}{RGB}{34,139,34}
\definecolor{citecolor2}{HTML}{0071bc}
\definecolor{Graylight}{gray}{0.9}
\definecolor{lightred}{RGB}{241,140,142}
\definecolor{pigment}{rgb}{0.2, 0.2, 0.6}

\newcommand{\bff}[1]{\textcolor{red}{BASURA: #1}}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{3467} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{Fine-Grained Regional Prompt Tuning for Visual Abductive Reasoning}

\author{Hao Zhang$^{\dagger}$, Basura Fernando$^{\dagger}$\\
\parbox{40em}{\centering $^{\dagger}$ Agency for Science, Technology and Research (A*STAR), Singapore}\\
{\tt\small \{zhang\_hao@ihpc.a-star.edu.sg, fernando\_basura@cfar.a-star.edu.sg\}}
}


%\author{Hao Zhang and
% Basura Fernando\\
%Institute of High Performance Computing (IHPC), Agency for Science, %Technology and Research (A*STAR)\\
%# 1 Fusionopolis Way, \#16-16 Connexis, Singapore 138632, Republic of Singapore\\
%{\tt\small firstauthor@i1.org}
% % For a paper whose authors are all at the same institution,
% % omit the following lines up until the closing ``}''.
% % Additional authors and addresses can be added with ``\and'',
% % just like the second author.
% % To save space, use either the email address or home page, not both
% Institute of High Performance Computing (IHPC), Agency for Science, Technology and Research (A*STAR)\\ 1 Fusionopolis Way, #16-16 Connexis, Singapore 138632, Republic of Singapore
% %First line of institution2 address\\
% %{\tt\small secondauthor@i2.org}
%}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi

%%%%%%%%% ABSTRACT
\begin{abstract}
Visual Abductive Reasoning (VAR) is an emerging vision-language (VL) topic where the model needs to retrieve/generate a likely textual hypothesis from a visual input (image or part of an image) using backward reasoning based on prior knowledge or commonsense.
Unlike in conventional VL retrieval or captioning tasks, where entities of texts appear in the image, in abductive inferences, the relevant facts about inferences are not directly visible in the input images. 
Besides, the inferences are causally relevant to regional visual hints and vary with the latter. Existing works highlight visual parts from a global background with specific prompt tuning techniques (e.g., colorful prompt tuning) on top of foundation models, like CLIP. 
However, these methods uniformly patchify ``regional hints'' and ``global context'' at the same granularity level and may lose fine-grained visual details significant for abductive reasoning. 

To tackle this, we propose a simple yet effective \textbf{Regional Prompt Tuning}, which encodes ``regional visual hints'' and ``global contexts'' separately at fine and coarse-grained levels. Specifically, our model explicitly upsamples, then patchify local hints to get fine-grained regional prompts. These prompts are concatenated with coarse-grained contextual tokens from whole images. We also equip our model with a new Dual-Contrastive Loss to regress the visual feature simultaneously toward features of factual description (a.k.a. clue text) and plausible hypothesis (abductive inference text) during training. Extensive experiments on the Sherlock dataset demonstrate that our fully fine-tuned RGP/RGP$_s$ with Dual-Contrastive Loss significantly outperforms previous SOTAs, achieving \textbf{the \nth{1} rank} on abductive reasoning leaderboards among all submissions, under all metrics (e.g., P@1$_{i\rightarrow t}$: \textbf{RGP$_s$ 38.78} \textit{vs} CPT-CLIP 33.44, higher=better). We would open-source our codes for further research.

\end{abstract}

%%%%%%%%% BODY TEXT
\input{sections/s1_intro.tex}
\input{sections/s2_related_works}
\input{sections/s3_problem}
\input{sections/s4_methods.tex}
\input{sections/s5_experiment.tex}
\input{sections/s6_conclusion}

%------------------------------------------------------------------------
%\section{Final copy}

%You must include your signed IEEE copyright release form when you submit
%your finished paper. We MUST have this form before your paper can be
%published in the proceedings.

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\clearpage
\newpage
\section*{Appendix}
\input{sections/s7_supple}

\end{document}
