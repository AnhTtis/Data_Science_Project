\begin{table}[htb!]
    \centering
    \tablestyle{2.0pt}{1.08}
    \resizebox{1.04\linewidth}{!}{
    \begin{tabular}{l|ccc|c|c}
    \multirow{2}*{\textit{RGP (Val-Set)}}&\multicolumn{3}{c|}{\textit{Retrieval}}& \textit{Localization} & \textit{Comparison} \\
    &{im$\rightarrow$txt ({\color{purple}$\downarrow$})}& {txt$\rightarrow$im
 ({\color{purple}$\downarrow$})} 
    & {P@1$_{i\rightarrow t}$ ({\color{purple}$\uparrow$})}  & GT/Auto-Box ({\color{purple}$\uparrow$})& Human Acc ({\color{purple}$\uparrow$})\\ 
    
    \hline		 
    %\rowcolor{baselinecolor}
    Context only, C=224$^2$ &{47.35}& {57.18}&{17.87}&{-} / {-}&{19.94}\\
    R=\textbf{16}$^2$,~~C=224$^2$ &{24.33}& {27.14}&{26.79}&{80.11} / {33.06}&{{21.92}}\\
    R=\textbf{48}$^2$,~~C=224$^2$ &{20.76}& {23.37}&{29.00}&{83.62} / {37.23}&{23.56}\\
    R=\textbf{112}$^2$, C=224$^2$ &{18.87}& {21.32}&{30.82}&{85.08} / {39.27}&{{24.64}}\\
    \hline
    Region only, R=224$^2$ &{25.20}& {24.79}&{28.72}&\textbf{85.54} / {41.79}&{20.90}\\
    R=224$^2$, C=\textbf{16}$^2$ &{23.89}& {24.08}&{29.03}&{85.24} / \textbf{42.06}&{{20.42}}\\
    R=224$^2$, C=\textbf{48}$^2$ &{23.69}& {25.00}&{28.81}&{84.86} / {40.86}&{21.59}\\   
    R=224$^2$, C=\textbf{112}$^2$ &{18.71}& {20.64}&{31.55}&{85.49} / {41.14}&{{23.22}}\\   
    \hline
    \rowcolor{baselinecolor}
    R=$224^2$, C=$224^2$ &\textbf{17.63}& \textbf{20.25}&\textbf{32.00}&{85.26} / {39.78}&{\textbf{25.65}}\\
    \end{tabular}
    }
    \caption{\textbf{Influcences of Input Resolutions (R=Region, C=Context Image) on Sherlock Val-Set}. We tested different settings on the \textit{General RGP} with CLIP ViT-B-16 backbone.
    The up arrow {\color{purple}$\uparrow$} (or down arrow {\color{purple}$\downarrow$}) indicates the higher (or lower), the better.
	}
    %\vspace{-10pt}
    \label{tab:res_rc}
    %\vspace{-10pt}
\end{table}