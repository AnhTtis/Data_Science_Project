\section{Conclusion}
We propose a new Regional Prompt Tuning with a Dual-Contrastive Loss for Visual Abductive Reasoning. Specifically, our method validates that curating fine-grained regional prompts is feasible for CLIP tuning, getting back local details, and benefiting abductive reasoning. We also reveal the positive relationships between the VAR and Vanilla Visual Retrieval tasks, unifying their training processes with the Dual-Contrastive Loss. Extensive experiments show that the RGP and the new loss are robust and effective for abductive reasoning and surpass previous SOTAs. The success of the two factors also paves future ways for exploring Multi-Grained, Chain-of-Thoughts Prompts, Visual Adatper, and other multiple relationships modeling on the VAR. 

