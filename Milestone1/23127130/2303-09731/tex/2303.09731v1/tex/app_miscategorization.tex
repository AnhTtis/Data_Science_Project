\section{Mis-categorization Attack Experiments}
\label{appendix:miscategorization}

\noindent$\bullet$\textbf{ Experimental Settings.} To implement mis-categorization attack, we follow the idea of \textbf{Physical} attack: we collected the PCs about objects which was labeled as pedestrian in the training set of KITTI, and kept the PCs with less than $200$ points as the basic data of mis-categorization attack. Then, during each time of mis-categorization attacks, we randomly chose a PC from the basic data and injected it into the target sample, then we further used PGD to change the positions of some points in this PC in order to increased its confidence scores and its classification probability of vehicles. Table \ref{tab:EXP3} reports the ASR of this mis-categorization attack on 3 different object detectors, and the performance of these 3 object detectors with and without our LOP.

\input{table/miscategorization_attack_table.tex}

\noindent$\bullet$\textbf{ Results \& Analysis.} As we can see from Table \ref{tab:EXP3}, LOP reduces the ASR of the mis-categorization attack to almost half of its origin in most cases. For example, LOP reduces at least $58.92\%$ of the original ASR on PointRCNN and reduces at least $49.46\%$ of the original ASR on PV-RCNN. An exception is the PointPillars, which seems to be more resilient against mis-categorization attacks and thus the defense effect of LOP is not as clear as the other two cases. In addition, we also notice a similar phenomenon as discussed in Section  of our original manuscript, that LOP can slightly increase the performance of the 3D object detectors in some cases. For example, on PointPillars, the AP increase by $1.13\%$, while the precision increases $7.52\%$ when the detector is deployed with LOP. In summary, the experimental results validate that LOP is also effective against mis-categorization attacks, and incurs almost no overhead on the performance of object detectors.