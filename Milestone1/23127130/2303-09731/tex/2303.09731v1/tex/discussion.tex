\section{Discussion}\label{sec:Discussion}




% Our current defense mainly focuses on appearing attacks, which form a popular attack class on LiDAR-based object detectors in ADS. Below, we discuss other attack classes which may threaten the detector's security and why our current work chooses the appearing attack as the main research target.


\noindent\textbf{Appearing Attacks vs. Disappearing Attacks.} Our current defense mainly focuses on appearing attacks, which form a popular attack class on LiDAR-based object detectors in ADS
In contrast to appearing attacks, a disappearing attack aims at hiding the existing objects from the prediction results of the victim 3D object detector \cite{dawn2018physical,shang2018shapeshifter,yue2019seeing}. To accomplish this purpose, the adversary would optimally generate a 3D-printing object to the target detector would not recognize it or its neighbouring object, and put the object on the road or near some objects to mount the attack. 
% Technically, the specific shape of the printed object is optimally chosen to guarantee the target detector would not recognize it or its neighbouring object in the prediction results, leading to its disappearance in the detector's output.  

In the previous literature, Cao et al. propose one of the earliest disappearing attacks on ADS, and successfully hide the printed objects from the LiDAR-based detection system of Baidu's Apollo by modeling its preprocessing and postprocessing phases into differentiable functions \cite{yulong2019advObj}.
Later, Tu et al. present a more general disappearing attack which breaks the state-of-the-art 3D object detectors including PointPillars and PointRCNN, and hide the car on which the printed object is positioned from the model's prediction results \cite{james2020physically}.
Recently, Cao et al. further devise a more powerful disappearing attack, MSF-ADV, which fools the image-based 2D object detectors and LiDAR-based 3D object detectors at the same time, and causes the fusion-based detection system of Baidu's Apollo to ignore the existence of the printed objects \cite{yulong2021invisible}.


Compared with appearing attack, we argue that a disappearing attack is not physical because it is untargeted and \textit{single-shot}, i.e., the attacker has to put a printed object on the road or near some objects in preparation. This indicates that he/she could hardly choose the victim ADS during the attack. Moreover, the printed object can only take effect once because it might be destroyed or recognized by the people nearby after the first accident happens. In contrast, in an appearing attack the attacker can choose the victim to fire the laser and forge non-existent cars as he/she wishes, making it difficult for others to note the attack due to the almost no evidence left in the accident scene. Nevertheless, considering the severe consequences if happening, how to mitigate disappearing attacks remains a meaningful direction to pursue.
% for future works.



\noindent\textbf{Extension to Other Attack Classes.} We further discuss the applicability of our defense for mitigating mis-categorization attacks, 
% which aims at changing the predicted class of the target objects in the prediction results of the victim 3D object detector. 
which aims at changing the predicted class of the target objects in the victim's detection results. 
In this sense, a mis-categorization attack can be seen as the combination of a disappearing attack and an appearing attack. In the above process, we observe that the crafted object would also be left with an abnormal density-depth characteristic which does not belong to the target class. 
% Therefore we modify the appearing attacks covered in our experiments into mis-categorization attacks, which selects the objects from the \textit{bicycle} or \textit{pedestrian} classes, and injecting a limited number of points around them to fool the victim 3D detector to mis-categorize them as vehicles, and evaluate the performance of our LOP when deployed alongside the 3D detector. The experimental results prove that our proposed defense is also effective against mis-categorization attacks due to the depth-density anomaly introduced by them.
Specifically, in Appendix \ref{appendix:miscategorization}, we modify the appearing attacks covered in our experiments into mis-categorization attacks, which selects the objects from the \textit{bicycle} or \textit{pedestrian} classes, and injecting a limited number of points around them to fool the victim 3D detector to mis-categorize them as vehicles,  and evaluate the performance of our LOP when deployed alongside the 3D detector. 
% The experimental results in Appendix \ref{appendix:miscategorization} show that our proposed defense is also effective against mis-categorization attacks. It is probably due to the depth-density anomaly introduced by the mis-categorization attack.
The experimental results in Appendix \ref{appendix:miscategorization} show that our proposed defense is also effective against mis-categorization attacks due to the depth-density anomaly introduced by them.

\noindent\textbf{Fusion Models as Defense Targets.}  We first clarify the relation between our proposed LOP and the fusion models. According to \cite{yulan2021deep}, the detection frequency of existing fusion models (including FPN, FCN and AVOD) is usually lower than $15$ FPS, and may be unsuitable for real-time self-driving systems due to the efficiency bottleneck. Besides, we suggest our defense is orthogonal to the fusion strategy. LOP in our defense provides a different view for the detectors to confirm their detection, while the fusion strategy incorporates new input modality to enhance robustness. Therefore, instead of viewing fusion models as a comparison group to our defense, we prefer to view the fusion models, which are by essence detectors, as our defense targets. In Appendix \ref{appendix:fusion}, we provide a preliminary study which validates that our LOP substantially improves the robustness of fusion models against appearing attacks. For example, the PointNet-based LOP would reduce the ASR of the \textit{Physical} attack on EPNet \cite{Huang2020EPNetEP} to $0\%$. In other words, we prefer not to view LOP as a competitor for the fusion models. Instead, LOP empirically improves the robustness of the fusion models, while, as no modifications is made on the image input branch, LOP would not hurt the benefits of fusion models in self-driving systems. For future works, it would be meaningful to systematically evaluate our proposed defense on more representative fusion and 3D object detection models. 

% Yet, we think that our LOP does not conflict with the fusion strategy, and the fusion model should be seen as a defense target as well as other 3D object detectors.


\noindent\textbf{Limitation and Future Directions.}  Finally, we discuss the potential limitations of our proposed defense:
% In Appendix \ref{appendix:FP}, we present a further case study on these false positives from our defense. We find the number of false positives with depth less than $10$ meters is only $1.60\%$ of the total real vehicles, and the number of false positives with depth less than $20$ meters is only $2.21\%$ of the total real vehicles. The results imply that our LOP may not recognize the forged obstacles well in some cases due to its uncertainty on distant vehicles.
According to the case study on the false positives from our defense, we find that our LOP may not recognize the forged obstacles well in some cases due to its uncertainty on distant vehicles. However, due to the existence of the MOT module, the self-driving system keeps refreshing the driving plan and corrects the mis-prediction of distant objects when the obstacle comes nearby. Moreover, MOT would prevent the self-driving system from ignoring a distant object only if LOP misses a distant object in several consecutive frames, the possibility of which is less than $0.1\%$ according to our calculation. Therefore, the negative influence of LOP on the normal performance of the detector would hardly influence the normal driving behaviors of the defense target. The similar results are also provided in our end-to-end experiments in Section \ref{sec:Experiment:results:real}.

Besides, due to our limited computing resources, we mainly prove the advantages of LOP in terms of computational overhead compared with SVF, while we admit the additional overhead may trade for better defense effectiveness and would not be a problem for most autonomous driving companies. Nevertheless, SVF as a retraining-based approach lies in a different defense category from our proposed plug-and-play defense module. A 3D object detection module which is enhanced by SVF can be further combined with our LOP for better defense effectiveness. As SVF still has a space for improvement in defense effectiveness \cite{jiachen2020towards}, it would be meaningful for future works to explore their combination in the future.

% We highly agree that there may be the potential tradeoff between the defense effectiveness and the training time, and the overhead of SVF during training phase is not a problem for most AD companies. Yet, from our perspective, we still think that the retraining-based approach SVF lies in a different defense category from our proposed plug-and-play defense module. A 3D object detection module which is enhanced by SVF can be further combined other plug-and-play defense methods, such as CARLO, Shadow-Catcher or our LOP, for better defense effectiveness. Meanwhile, the experiments in the work of SVF [1] show that it is still possible for the detectors enhanced by SVF to further improve their robustness. Therefore, we suggest to consider our LOP and SVF as two complementary methods to analyze the possibility of their combination rather.We plan to incorporate the above discussion with more details in the “Limitations and Future Directions” part of Section 6 of our revised manuscript. We prefer to leave the comparison with SVF in terms of defense effectiveness in the future work.

% Moreover, although we have D-Kit to perform real-car experiments, the lack of physical attack apparatus hinders us from evaluating LOP on D-Kit. 
% % As discussed in Appendix \ref{appendix:physical_equipment}, to
% To deploy such attacks physically, one needs the photodiode, the laser transmitter, lens and other electronic components. Among them, the laser transmitter for shooting the laser is the most important and expensive component in a physical attack, without which, it is almost impossible for us to reproduce experiments in the real world. Therefore, we leave the physical evaluation of LOP on D-Kit in future works.

% Moreover, though we have the D-Kit to perform the real car experiments, but there still exists some problems in producing it. Regardless of the others, the most critical problem is that we are short of the physical equipment for attacks. To deploy such attacks in the real world, we need the photodiode, the laser transmitter, some lens and other electronic components. Among them, the laser transmitter is the most important and expensive components, it is used to shoot the laser as the requirements of attacks and it is almost impossible for us to deploy these appearing attacks without it. Therefore, we can only leave the experiment on D-Kit in the future.

% We sincerely appreciate the comment that the end-to-end experiment on the D-kit is much more convincing than our simulation experiments. We are also eager to learn about the performance of our LOP on the D-Kit, but there still exists some problems in reproducing this experiment in the real world. Regardless of the others, the most critical problem is that we are short of the physical equipment for attacks, especially the laser transmitter which is used to shoot the laser as the requirements of attacks. Therefore, we plan to further explain the difficulties in producing real-world experiments in the “Limitations and Future Directions” part of Section 6 of our revised manuscript instead, and leave the experiment on D-Kit in the future work.


% Moreover
% \xqf{At last}, with the development of laser technology, the upper bound on the number of fake points generated by the attacker's equipment may keep increasing. In the future, the attacker may be capable to forge a car by copying all the points of a real car, which was almost impossible for LOP or other potential defenses to distinguish the difference. In this situation, it is almost impossible for a single LiDAR-based object detector and also the LOP to distinguish real and forged objects as their PCs are completely identical. Therefore, fusing multiple object detectors,
% which combines multi-modal information from different sensor sources (e.g., cameras, LiDARs, radars) and different DNN models for a comprehensive prediction \cite{xiaozhi2017mv3d, gregory2019lasernet++, anas2021seqFusion},
% is a promising way to alleviate the threats from appearing, disappearing and other attack classes detector \cite{Hallyburton2021SecurityAO}. Nevertheless, we should bear in mind that fusion is simply a mechanism which ensembles the capability of multiple DNN models and is orthogonal to our efforts in enhancing the robustness of the 3D object detection component. It is because, to break the fused detector, the attacker needs to manipulate the outputs of each component detector, the vulnerability of which would harm the security of the fused one \cite{yulong2021invisible}. Therefore, to enhance the security of fusion models as well as single detection modules is of equal importance and requires equal research efforts from our community.



% \xqf{Besides, There still remains some unsolved problems for the fused strategy to implement in the ADS. On the one hand, the detection frequency of existing fusion models is usually lower than $15$ FPS according to \cite{yulan2021deep}, and we are afraid but current fusion models may not be suitable for real-time self-driving system due to the efficiency bottleneck. On the other hand, to improve the robustness of each single component in the complex ADS is still meaningful and urging. For example, Cao et al. have already successfully broken a fused detector which combines image-based YOLO and Apollo's LiDAR-based object detector by disappearing attacks\cite{yulong2021invisible}. Therefore, we believe the fused strategy is not the final solution to the security of ADS, but a component of it just like the LOP.}

% Therefore, we believe that in order to eliminate the threat from appearing attack, other adversarial attacks or other attacks against object detectors, the most suitable way is to fuse multiple object detectors which take sampled data from different sensors, e.g. cameras, LiDARs and radars, as model's input \cite{xiaozhi2017mv3d, gregory2019lasernet++, anas2021seqFusion}.