\section{Our Defense: Local Objectness Detector}\label{sec:OurDefense}
\subsection{Insight of Existing Appearing Attacks}
Though these existing appearing attacks differ from one another in various aspect, we find that there are two common properties of them.

\subsubsection{Property 1: Inimitable Relation between Features}
Because most of existing appearing attacks focus on being a real threat in the real world, they are inevitably limited by attacker's goal and physical equipment: as we describe in Sec.\ref{sec:Limitation}, there are upper bounds for the number of added points and the distance between a fake object and LiDAR. Behind these two limitations, there is an unsolved problem remained for existing appearing attacks: with current method, it is hard to imitate the relation between the \textit{depth}, i.e. the distance between a object and the LiDAR, and the \textit{point density}, i.e. the ratio of the number of input points inside a object's bounding box over the volume of this bounding box, of a real object in the real world.

% Potential Graph: distribution of real objects and fake objects in a depth-density graph

Thus, we adopt a PC classifier to learn the relation between the depths and the point densities of real objects under different situation, and distinguish real objects and fake objects based on this relation.

\subsubsection{Property 2: Unnoticed Local Difference}
Except the category and the bounding box, 3D object detectors will also calculate a confidence score or an objectness score for each predicted object to quantify whether it is real into a numerical value. 3D object detectors in essence return the objects with higher scores as its final prediction. Therefore, most of existing appearing attacks focus on increasing the objectness score of fake objects, while they ignore the difference between the local part of real objects and fake objects.

% Potential Graph: local difference is much larger than the global difference

Besides, Chen's work has showed that with an appropriate strategy of spatial division, one single part of real objects contains enough spatial information and semantic information to predict the category, the bounding box and the objectness score of its related object\cite{qi2020object}. Thus, we split the input space into several equal-size pillars and predict whether the input points inside represented a part of a real object for each pillar. For each predicted objects, we choose the pillars intersected with its bounding box, and determine whether the predicted object is a real object by voting.

\subsection{Local Objetness Detector}
\subsubsection{Overview}
Based on the two common properties of existing appearing attacks, we propose a local objectness detector to determine whether a object in prediction is real or not. As shown in Fig.\ref{fig:local_objectness_detector}, the pipeline of our local objectness detector can be divided into three stages: sample Generating stage, training stage and detecting stage.

\begin{figure*}[htpb]
    \centering
    \includegraphics[width=2\columnwidth]{figs/placeholder.png}
    \caption{The pipeline of our local objectness detector.}
    \label{fig:local_objectness_detector}
\end{figure*}

\subsubsection{Sample Generating Stage}
At this stage, we focus on generating training set, which is based on the original training set of target 3D object detector without any auxiliary information, for our local objectness detector. 

For each sample in the original training set, we divide the input space into several equal-size pillars, which are equal to $1m\times1m$ grids in the x-y plane. We then turn each pillar with points inside into a training sample based on following ways:

\paragraph{Generating Feature} For each point inside this pillar, we first turn its $4$-dim feature vector $(x,y,z,int)$ into a $7$-dim feature vector$(dx,dy,x,y,z,int,dep)$, where $(x,y,z)$ is its 3D coordinates, $(dx,dy)$ is its 2D relative coordinates to the center of this pillar in x-y plane, $int$ is its intensity and $dep=\sqrt{x^2+y^2+z^2}$ is its depth. We then concatenate these new feature vectors to generate the feature tensor of size $(M,7)$, where $M$ is a fixed super-parameter\footnote{We choose $M=1024$ in our experiment.}. For those pillar with more than $M$ points inside, we randomly sample $M$ points; for those pillar with less than $M$ points inside, we apply zero padding.

\paragraph{Generating Label} We calculate the 2D Intersection over Union (IoU), the IoU on the x-y plane, of this pillar and each bounding box of the ground truth in original training sample, and store the max IoU over them. If the max IoU is greater than a fixed threshold $\alpha$, then we consider there is a part of real object including in this pillar and set 1 as its label\footnote{We choose $\alpha=1e^{-6}$ in our experiment.}. Otherwise, we set 0 as its label.

Finally, we collect all pairs of (feature, label) as the training set for our local objectness detector.

However, the \textit{positive samples}, i.e. the generated samples with 0 as label, are much more than the \textit{negative samples}, i.e. the generated samples with 1 as label. To keep data balance, we delete a part of negative samples in random to ensure that the ratio of positive samples and negative samples does not exceed $1:1.5$.

\subsubsection{Training Stage}
Due to the good performance of point-wise PC models on various 3D tasks, we implement a point-wise PC classifier as our local objectness detector. We choose Adam with learning rate $=1e^{-3}$ as the optimizer and focal loss as the loss function:

\begin{align}
FL(p,y)=-\alpha(1-p_y)^\gamma log(p_y) \label{equal:3}
\end{align}

where $\alpha,\gamma$ are super-parameters, $p$ is the probability vector returned by classifier and $y$ is the label of input data\footnote{We choose $\alpha=1,\gamma=2$ in our experiments.}. Finally, we train our local objectness detector on our collected training set until its convergence.

\subsubsection{Detecting Stage}
To identify the fake objects in prediction, we first divide the detection space into several equal-size pillars and generate their features similarly to the sample generating stage. Then we use our local objectness detector to generate $0/1$ objectness score for each pillar. 

For each object in the prediction, we find the pillars that the 2D IoU between them and the bounding box of this object is greater than a specified threshold $\beta$ and count the sum of their objectness scores\footnote{We choose $\beta=1e^{-3}$ in our experiment.}. Finally, we recognize the objects with the ratio of this sum over the number of counted pillars equal to or less than $50\%$ as fake objects and erase them from the prediction.