Many scientific fields use the language of Partial Differential Equations (PDEs; \citealp{evans2010partial}) to describe the physical laws governing observed natural phenomena with spatio-temporal dynamics. 
Typically, a PDE system is derived from first principles and a mechanistic understanding of the problem after experimentation and data collection by domain experts of the field.
Well-known examples for such systems include Navier-Stokes and Burgers' equations in fluid dynamics, Maxwell's equations for electromagnetic theory, and Schr\"{o}dinger's equations for quantum mechanics.
Solving a PDE model could provide users with crucial information on how a signal evolves over time and space, and could be used for both prediction and control tasks.

% While creating PDE-based models holds great value, it is still a difficult task in many cases.
% For many complex real-world phenomena, we might only know some of the dynamics of the system.
% For example, an expert might tell us that a  heat equation PDE has a specific functional form
% %such as
% %\begin{align}
% %\label{eq:pde_coeffs}
% %        \fder{f}{t}=a(x,t,f) \frac{\partial^2 f }{\partial x^2}  + b(x,t,f)\frac{\partial f }{\partial x} + c(x,t,f),
% %\end{align}
% but we do not know the values of the diffusion and drift coefficient functions. We focus mainly on this case.
%In this case, the PDE system at hand is not solvable by standard methods.
Creating PDE-based models holds great value, but it is a difficult task in many cases. For some complex real-world phenomena, only some part of the systems dynamics is known, such as its structure, or functional form. For example, an expert might tell us that a  signal obeys the dynamics of a heat equation, without specifying the diffusion and drift coefficient functions. We focus mainly on this case, as explained in detail below.

The current process of solving PDEs over space and time is by using numerical differentiation and integration schemes. However, numerical methods may require significant computational resources, making the PDE solving task feasible only for low-complexity problems, e.g., a small number of equations.
An alternative common approach is finding simplified models that are based on certain assumptions and can roughly describe the problem's dynamics. A known example for such a model are the Reynolds-averaged Navier-Stokes equations \cite{reynolds1995dynamical}.
Building simplified models is considered a highly non-trivial task that requires special expertise, and might still not represent the phenomenon to a satisfactory accuracy.

In recent years, with the rise of Deep Learning (DL; \citealp{lecun2015deep}), novel methods for solving numerically-challenging PDEs were devised.
These methods have become especially useful thanks to the rapid development of sensors and computational power, enabling the collection of large amounts of multidimensional data related to a specific phenomenon.
In general, DL based approaches consume the observed data and learn a black-box model of the given problem that can then be used to provide predictions for the dynamics.
While this set of solutions has been shown to perform successfully on many tasks, it still suffers from two crucial drawbacks: (1) It offers no explainability as to why the predictions were made, and (2) it usually performs very poorly when extrapolating to unseen data. 

% \begin{wrapfigure}{r}{0.6\textwidth}
%   \begin{center}
%     \includegraphics[width=0.5\textwidth]{Figures/experiments/mech_dd.png}
%   \end{center}
%     \caption{Different approaches to PDE modeling, characterized by their ability to utilize knowledge regarding the underlying PDE.}
%     \label{fig:experiments.mech_dd}
% \end{wrapfigure}
In this paper, we offer a new hybrid modelling \citep{kurz2022hybrid} approach that can benefit from both worlds: it can use the vast amount of data collected on one hand, and utilize the partially known PDEs describing the observed natural phenomenon on the other hand. In addition, it can learn several contexts, thus employing the generalization capabilities of DL models and enabling zero-shot learning \citep{palatucci2009zero}.

Specifically, our model is given a general functional form of the PDE (i.e., which derivatives are used), consumes the observed data, and outputs the estimated coefficient functions. 
Then, we can then use off-the-shelf PDE solvers (e.g., PyPDE\footnote{\url{https://pypde.readthedocs.io/en/latest/}}) to solve and create predictions of the given task forward in time for any horizon.

Another key feature of our approach is that it consumes the spatio-temporal input signals required for training in an unsupervised manner, namely the coefficient functions that created the signals in the train set are unknown. This is achieved by combining an autoencoder architecture (AE; \citealp{kramer1991nonlinear,hinton2006reducing}) with a loss defined using the functional form of the PDE. As a result, large amounts of training data for our algorithm can be easily acquired.
Moreover, our ability to generalize to data corresponding to a PDE whose coefficients did not appear in the train set, enables the use of synthetic data for training.
Although our approach is intended to work when the PDE functional form is known, it is not limited to that scenario only.
In cases where we are given a misspecified model (when experts provide a surrogate model for instance), our model can eliminate some of the discrepancies using the extra function that is not a coefficient of one of the derivatives (the $p_0(x,t,u)$ function in  \eqref{eq:general_PDE}).

On the technical side, we chose to apply a finite difference approach in order to integrate the knowledge regarding the structure of the PDE family. This approach enables us to consume training data without requiring the corresponding boundary conditions.

A natural question for this setup is whether we are able to extract the ``correct'' coefficients for the PDE. The answer depends on the identifiability of the system, a trait that does not hold for many practical scenarios. We therefore focus on finding the coefficients that best explain the data, making prediction of the signal forward in time possible. Practitioners will find the estimated coefficients useful even if they are not exact, since they may convey the shape, or dynamics, of unknown phenomena.

Our motivation comes from the world of electric vehicle batteries, where PDEs are used to model battery charging, discharging and aging. For a specific type of battery, the set of equations has a common form, with different coefficients for each battery instance. The data describing battery dynamics is gathered by battery management systems in the vehicle, and also in the lab. It is then used to calibrate the equation-based model, in order to later generate predictions and analyze battery behavior. Traditional techniques for model calibration are based on direct optimization, and suffer from two drawbacks: (1) they are extremely time consuming, (2) they do not leverage data from one battery in the dataset to another. Our approach solves both issues: model calibration is achieved by inference rather than optimization, and the learned context facilitates transfer of knowledge between batteries. The first improvement is straightforward, and the second one stems from the context-based architecture we introduce. This architecture enables us to estimate the coefficients of a given battery based on a smaller amount of data when compared to the traditional approach.

We summarize our contribution as follows:
\begin{enumerate}
    \item Harnessing the information contained in large datasets belonging to a phenomenon which is related to a PDE functional family in an unsupervised manner. Specifically, we propose a regression based method, combined with a finite difference approach.
    \item Proposing a DL encoding scheme for the context conveyed in such datasets, enabling generalization for prediction of unseen samples based on minimal input, similarly to zero-shot learning.
    \item Extensive experimentation with the proposed scheme, examining the effect of context and train set size, along with a comparison to different previous methods.
\end{enumerate}

The paper is organized as follows. In Section \ref{sec:related} we review related work. In Section \ref{sec:method} we present the proposed method and in Section \ref{sec:experiments} we provide experiments to support our method. Section \ref{sec:conclusions} completes the paper with conclusions and future directions.