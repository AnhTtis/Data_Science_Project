\section{PROBLEM FORMULATION}
\label{sec:problem-formulation}

 We consider a scenario where a team of robots must move from their initial locations to some goal locations.
More specifically, we are interested in a situation where the cost of traversal is affected by the presence and actions of other team members.
In the following, we will introduce the base graph, and then formulate how the edge cost changes based on the ``support'' provided by the teammate.
For conciseness, we will restrict the discussion to a two-agent team, but the idea will generalize to a larger team size.\footnote{The computational complexity will be an important consideration for scalability.} 
% Describe the problem we are trying to solve.\\

The environment is modeled as a graph where nodes represent key locations and the edges represent the traversability between them.
%\daigo{Figure 1 should really be discussed with the \egraph{} right?}
The \bgraph{} is denoted by \(\mathbb{G}=(\nodeset,\edgeset)\), where \(\nodeset\) is a set of nodes, and \(\edgeset\) is a set of edges, \(\edgeset\subset \nodeset\times \nodeset\). 
We assume $\mathbb{G}$ is strongly connected.
The starting positions of the agents are denoted by the node set $\nodeset_0 \subset \nodeset$.
The robots seek to reach a set of goal nodes $\nodeset_g\subset \nodeset$ while minimizing the cost of traversal.
%We have a multi-agent system with a set of starting nodes $V_1 \subset \nodeset$, where each robot has a different starting node. 
%The set of goal nodes are also known and given as $V_g \subset \nodeset$. 
The nominal cost for traversing the edge \(\edge{i}{j}\in \edgeset\) is a given constant, $\cost{i}{j}$ for $i,j\in \nodeset$. 
% \daigo{We can define the distance / cost of traversal $\psi$ (used in Lemma 1) here.}
% \xuan{If we define the notation of path here, we can introduce $\psi$ of that path. }
%We define the cost of traveling a path $I$ as $\psi_I$. 

Let $I_{ab}$ denote a path (set of edges) from $a\in \nodeset$ to $b \in \nodeset$.
We use $\psi_{a,b}$ to denote the minimum cost to move from $a$ to $b$:
\begin{equation}
    \psi_{a,b} = \min_{I_{ab}} \sum_{e_{i,j}\in I_{ab}} c_{i,j}.
\end{equation}
%
A standard path planning will simply consider this shortest path for each agent.

%\xuan{By `minimum' cost, we need to define `in which graph'. In Section III B, we have an environment graph, an ordinary graph, and a supporting graph. There, the $\psi$ is defined as the minimum cost from $a$ to $b$ on the \textbf{ordinary graph}. If there are multiple places we need notation $\psi$, we can define it here. If it is only used in Section IIIB, defining it there is clearer.}
%\sara{we do address minimum costs on each graph, so I think keeping this definition here}

We now define the \emph{\egraph{}}, which incorporates the notion of risk and support. Each edge $\edge{i}{j}$ is associated with a set of support nodes, $\supnodes{i}{j} \subseteq \nodeset$. If this set is non-empty, then an agent at $v\in\supnodes{i}{j}$ can provide support for the agent traversing $\edge{i}{j}$. 
The action set for an agent $n\in \{A,B\}$ at node $i$ is given as
$\actset{n}{i}=\{\{\act{}{i,}{j}\}_{j\in\mathcal{N}_i}, \act{}{}{s}\}$. 
Where $\mathcal{N}_i$ is the neighborhood of $i$, and $\act{}{i,}{j}$ is the action to move to node $j$ given that it is in the neighborhood of $i$. The action $\act{}{}{s}$ is the support. Note, if we were to consider a team size larger than two, we would have to explicitly denote which agent is being supported by $n$.

Let $\post{t}{} = (\post{t}{A},\post{t}{B})$ be the position of agents A and B at time $t$, and let $\act{t}{}{} = (\act{t}{A}{},\act{t}{B}{})$ be the actions agents A and B take at time $t$. The cost of an action for agent A is given as 
% 
\begin{equation}
\costn{t}{A}(\cdot)=
\begin{cases}
    \cost{i}{j},& \text{if } \act{}{A}{} = \act{}{i,}{j} \text { and } \post{}{B} \notin \supnodes{i}{j} \text{ or } \act{}{B}{} \neq \act{}{s}{}, \\
    \supmove{i}{j},& \text{if } \act{}{A}{} = \act{}{i,}{j} \text{, }\post{}{B} \in \supnodes{i}{j} \text{, and } \act{}{B}{}=\act{}{s}{}, \\
    \supcost, & \text{if } \act{}{A}{}=\act{}{s}{}, \\
    0, &\text{if } \act{}{A}{} \neq \act{}{s}{} \text{ and } \act{}{A}{} \neq \act{}{i,}{j},
\end{cases}
\end{equation}
where $(\cdot)$ represents the arguments $(\post{t}{},\act{t}{}{},\supnodes{i}{j})$.


% \daigo{Maybe explain this with Fig.~1, discussing different scenarios like A and B both moving vs. A staying and B moving.}\sara{see example below}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.40\textwidth]{figures/cost_cases.pdf}
    \caption{Illustrative example of an environment graph with a risk edge and supporting nodes. Case 1 has a high risk cost. Case 2 has a low risk cost.} 
    \label{fig: example}
\end{figure}

For example, in Fig. \ref{fig: example}, if at $t=1$ agent A is at node 2 (a supporting node) and provides support to agent B as the latter moves from node 1 to node 4, then the cost for agent A would be $\costn{1}{A}=\supcost$ and the cost for agent B would be $\costn{1}{B}=\supmove{1}{4}$. If both agents A and B move together from node 1 to node 4, the cost for the agents would be $\costn{1}{A}=\costn{1}{B}=\cost{1}{4}$.

In order to find the total cost at time $t$, we can simply sum the costs for both agents

\begin{equation}
\Cost{t}{}=\costn{t}{A}+\costn{t}{B}.
\end{equation}

Let $\pathset{n} = \{\paths{n}{1},...,\paths{n}{m}\}$ be the set of action sequences agent $n$ can take from start node to goal node. Where each sequence is the ordered set of actions taken from start to goal from $t=1$ to the time it takes for the agents to reach the goal state, $T$, i.e., $\paths{n}{m}=[\act{1}{n}{},...\act{T}{n}{}]$. 

%\marginXW{Do we only consider two agents? Yes.}

The sum of the costs for a given sequence of actions $\paths{A}{}\in\pathset{A}$, $\paths{B}{}\in\pathset{B}$ are
% 
\begin{equation}
F(\paths{A}{},\paths{B}{})= \sum_{t=1}^{T} \Cost{t}{}. 
\end{equation}
% 
The goal is to find a pair ($\paths{A*}{},\paths{B*}{}$) that minimizes the total cost, $F$:

\begin{equation} \label{5}
\min_{\paths{A}{}\in \pathset{A},\paths{B}{}\in \pathset{B}} F.
\end{equation}

% \daigo{The section should not end abruptly with an equation. In the least you can say what is coming next.}  \daigo{We can also mention different ways in which the pair can move to the goal with Fig.1 in mind, and lead to the following sections actually finding the optimal.} \daigo{Also, to tell the full story, it might be good to specifically mention where the goal is in Fig.1.} \sara{see this paragraph I've written}

%If agents A and B in Fig. \ref{fig: example} start from node 1 and want to reach the goal, node 5, they must decide whether they support each other in doing so. For example, they could traverse the edge $\edge{1}{4}$ while one supports the other, leading to a reduced total cost, and from there go to node 5. Or, they could take the longer route: 1, 2, 3, 4, then 5. Although they avoid the risk edge, they might possibly accrue more costs in doing so.
%In the following section, we introduce a method of transforming the environment graph to a graph of the joint state space to perform path planning on.

An illustrative example in Fig. \ref{fig: example}, where agents A and B need to reach goal node 5. To traverse the risk edge, they either use or do not use support depending on how costly, or risky, the edge is.
Agents demonstrate supporting behavior in Case 1.
If agent B traverses risk edge $\edges{1}{4}$ without support from A, the cost for B would be $\cost{1}{4}=5$.
With support from A, the reduced cost for B would be $\supmove{1}{4}=2$. The total cost at this time step $t$ is $\Cost{t}{}=\supmove{1}{4}+\supcost=2+1=3$. 
Thus, agents in this case accrue less costs by supporting each other.
Case 2 is a scenario where the agents do not show supporting behavior in a low risk situation. 
Since $\cost{1}{4}=3$, B can traverse $\edges{1}{4}$ without support from A. The total cost at this time step $t$ is $\Cost{t}{}=\cost{1}{4}+0=3+0=3$ without A's support.

One way to solve the minimization problem in (\ref{5}) is by posing it as an instance of MDP. However, we will introduce a simplification using the concept of Joint State Graph in the next section.
