\section{INTRODUCTION}

 % The study of multi-agent systems is continuously being explored, as this field offers a wide range of applications for both human-robot  and robot-robot cooperation. Interest in this research can be found in the manufacturing industry, warehouse management, intelligent transportation, and many more. 
 In this work, we are interested in designing coordinated group motion, where the safety or cost for one agent to move from one location to another may depend on the support provided by its teammate. As an example, let's say there are two robots traversing an environment represented as a graph in Fig. \ref{fig: intro-example}.
 Starting from 1, the robots face a wall, represented by a red edge. 
 The robots could either climb a ladder together and potentially fall and break (move from 1 to 4 together), or one robot could hold the ladder (support from 2) while the other moves up from 1 to 4. The former option is high risk, while the latter is low risk and preferable. 
 Alternatively, if the ladder is bolted to the ground, then climbing together can be low risk and preferable.
 This paper develops a framework to study when such coordination is beneficial.


%In this paper, we are interested in providing another way to solve for an objective function in a graph environment given a multi-robot system. We do this by formulating the graph problem, define the parameters and decision variables, and construct another graph that provides a high-level representation of the original graph.


%\daigo{One way to write an intro is to think about ``how we can explain the contributions of the paper clearly.'' So we can go backwards from the contributions that we want to explain. (Obviously, these come at the last paragraph, but we can write the earlier parts with this in mind.)}

%\daigo{Each paragraph can be focused on a single key takeaway. (Can you think of what each paragraph is trying to say?)} 

%\daigo{In relation to contribution (i), we can have a paragraph(s) talking about the existing works on multi-agent coordination with a focus on \emph{what people mean by coordination.} I believe many works consider \emph{task allocation/assignment}, and call it a coordination. In that context, coordination ends once the assignments are figured out at the beginning - there's not much ``coupling'' or interdependency between what individual robots are doing. The problem that we propose in this paper emphasizes this coupling by considering explicit model of ``support''.}

%\daigo{Just to make sure that we are aware of the literature, we can make note of different ways people incorporate ``risks''. Many consider stochasticity and take into account the probability of achieving a certain level of performance. Some work consider game theory to account for risks from the adversary (you can cite my IROS paper :) ). Yet, there are number of works that consider risks simply based on the ``cost'' of traversal.  In this initial work, we will take this approach to simplify the analysis.}

%\daigo{In relation to contribution (ii), we can use the references we have now to discuss the difference between distributed and centralized approaches. What are the claims in terms of optimality guarantee, computational complexity, type of coordination, etc.}

%\daigo{For (iii), we could potentially list some other works that do a similar decomposition of the problem to solve a bigger problem.}

%In \cite{le1990combination} \xuesu{I would suggest NOT to use citation numbers as part of the sentence: Le \cite{le1990combination} has recognized that... }, the authors recognize that implementing a central system makes scheduling and planning more efficient, but the problem is that it is not the best approach for coordinating the actions of mobile robots in a dynamic environment where there is uncertainty. Thus, they develop a mixed strategy combining the generation of an individual robot plan as well as the connection with a central task planned and scheduler when appropriate. Along the lines of scheduling and planning, \cite{durfee1999survey} \xuesu{Durfee et al. \cite{durfee1999survey} have focused... } focuses on how well agents in a distributed system can communicate with each other (what and when to communicate) in order to reach an agreement over the distribution of tasks and resources. The challenge here is the development of models that contain the mental state and the planning process. 

%Another research focusing in centralized planning done in \cite{kvarnstrom2011planning} applies single-agent planning for multi-agent domains using a hybrid of temporal partial order plan and forward-chaining planning. They construct a sequence of actions for each agent, then link it to other agents' actions by a partially ordered precedence relation with given requirements for precedence. The current implementation for this is not yet optimized with regards to performance and efficiency.
%Similarity, in \cite{crosby2014single}, the authors approach the problem of multi-agent planning by transforming it into a single-agent planning problem. Given concurrent actions and concurrent action constraints, the agents in the transformed problem can select joint actions that are associated with a single subset of objects at a time without violating these constraints. 

%Other research attempt to answer the question as to whether a multi-agent planning problem can be simplified to a single-agent problem. \cite{zhang2016formal} reach an approximate answer to determine if a planning problem can be solved with a single agent, since they show that an exact answer is intractable. They state that a multi-agent problem is considered to have required cooperation (RC) if the problem cannot be solved with a single agent. In their subsequent work in \cite{sreedharan2015first}, they design a complete but non-optimal centralized multi-agent planner for required cooperation scenarios. This planner uses the theory of RC to solve large multi-agent problems by reducing them into smaller problems in terms of the number of agents. They do this be rearranging the number of agents from n planning agents to m transformer agents (where $m<n$), where a transformer agent constitutes the planning tasks of multiple agents. By first solving these smaller problems then expanding to form a plan for the original problem, they improve the time efficiency of planning. 

%Reformulating or transforming the graph setup is another way researchers have been trying to solve multi-agent planning problems. In \cite{yu2013multi}, they reduce multi-agent path planning on graphs to network flow problems. This allows the implementation of combinatorial network flow algorithms to solve for the multi-agent planning problems. In \cite{jansen2008direction}, direction maps are used to learn the movements of agents in an environment, which produces implicit cooperation between agents. They are also concerned with producing paths that avoid collisions between the agents. \cite{luna2011push} also creates another algorithm that computes non-colliding paths. They do this by employing the two primitives "push" (agent moves towards goal) and "swap" (two agents swap positions without changing the configuration of other agents). \cite{liu2019task} create the Multi-agent Pickup and Delivery (MAPD) algorithm which computes one task sequence for each agent by solving a special traveling salesman problem and plan paths based on these task sequences. In order to avoid collision, they create a method called "reserving dummy paths". \cite{lim2020mams} introduce the Multi-Agent Multi-Scale A* (MAMS-A*), where each agent constructs a representation of its search space of the graph environment, communicates the results with the other agents, and refines its own results after receiving information from the other agents. This results in a subgraph that contains an optimal path.

%In this paper, we aim to simplify a multi-agent to a single-agent path planning problem by developing an algorithm that reconstructs the graph on which the agents traverse from an environment graph to a Joint State Graph. This new graph provides a new way to compute task and path planning problems, as the actions of the agents become implicit in the JSG structure. The algorithm for constructing a JSG is efficient with regards to the time it takes to compute. Moreover, applying a path planning algorithm on this JSG is also time efficient.

%Research done on team coordination tend to define it as a task allocation and path planning problem while taking into account collision avoidance.  

The terms cooperation and coordination take various meanings in different contexts. 
There is research done on the coordination of actions of agents to reach a state of order, such as consensus and formation control \cite{chandler2001uav, ren2005consensus, parker1993designing,lavretsky2002f, olfati2006flocking}. 
Others study cooperation in terms of simultaneously performing tasks in a spatially extended manner, like in surveillance \cite{chandler2001uav, liu2021team} and sampling \cite{bellingham2006autonomous}. 
Cooperation is also explored in problems where agents need to react locally to avoid conflict or collision, as can be seen in transportation systems on the road \cite{path2006california}, in the air \cite{tomlin1998conflict}, and in general robotic cooperation problems \cite{liu2019task,kvarnstrom2011planning, hart2020using}. 
%Many of the the types of problems mentioned so far are addressed in a distributed system, whereas we are interested in a more centralized approach.
%In task and path planning and multi-agent assignment problems \cite{liu2019task,kvarnstrom2011planning}, an agent only has to perform a set of tasks and avoid colliding with other agents. 
% In these types of problems, the coordination between the agents ends once the assignments are allocated and the paths are defined. 
We see in these situations that there is little coupling between the agents -- agents do not rely on each other to make progress, but simply need to not be in each other's paths. 
In this work, we are interested in tightly coupled agents that depend on each other for \emph{support} in order to meet their objective.
% A more sophisticated type of cooperation involves a group of agents and human operators that work together to perform a task \cite{karami2010human}.

%, monitoring \cite{traub2007terrestrial}, among others

%There is research done on the concept of consensus, such as synchronization or rendezvous, where the agents reach a common agreement to reach a certain state (location, time, etc.) \cite{chandler2001uav, ren2005consensus}.
%Another type of cooperation is formation, where agents coordinate to form predefined geometrical configuration \cite{parker1993designing,lavretsky2002f, olfati2006flocking,shishika2020game}.
%In surveillance, cooperative classification involves agents to work jointly to maximize the probability of classifying a target correctly \cite{chandler2001uav}.
%A mixed initiative cooperative problem involves a group of agents and human operators that work together to perform a task \cite{karami2010human}.
%Research in cooperation in a network of sensors that are positioned to maximize the amount of information gathered, such as in environmental sampling \cite{bellingham2006autonomous} and distributed aperture observing \cite{traub2007terrestrial}.
%There is also cooperation being studied for transportation systems for collision management on the road \cite{path2006california} and in the air \cite{tomlin1998conflict}.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.47\textwidth]{figures/intro_example.pdf}
    \caption{Example of an environment graph with risk edges and supporting nodes.} 
    \label{fig: intro-example}
\end{figure}

We study support in the context of mitigating some risks that exist in the environment. Such risk has been formulated and studied in various ways.
%\st{Different researchers define “risk” differently} based on the context of the problem they are trying to solve. 
For instance, probability of achieving certain levels of performance in a stochastic setting has been considered \cite{bertsekas2007dynamic, lim2012stochastic, xiao2019explicit, xiao2020robot}.
%For instance, \st{much of the research done in planning problems consider} stochasticity and consider the probability of achieving a certain level of performance \cite{bertsekas2007dynamic},\cite{lim2012stochastic}. 
Others have considered types of risk measures such as coherent risk measures \cite{artzner1999coherent}, like conditional value-at-risk (CVaR) \cite{ahmadi2021risk},\cite{ahmadi2020risk} and entropic value-at-risk (EVAR) \cite{ahmadi2012entropic}. Risk can also be characterized in terms of chance constraints \cite{yang2020chance}. Game theory is considered to account for the risk associated with the uncertainty in the adversary’s behavior \cite{shishika2020game}. Yet, risk can purely be described as the “cost” of traversal \cite{bertsekas2007dynamic}. In this work, we will only use this cost of traversal approach to simplify the analysis.


Cooperation has been studied both in centralized and distributed settings.
% Another element researchers in the field of cooperation consider is whether to use a centralized or a decentralized, or distributed, system. 
%Distributed systems are better when dealing with the coordination of mobile robots in a dynamic environment where there’s uncertainty \cite{le1990combination}, as agents can renegotiate parts of the plan during execution and do not need to fully collaborate \cite{kvarnstrom2011planning}. 
%On the other hand, a centralized system provides the knowledge of task interactions. 
%In addition, it allows the decomposition of the scheduling and planning given the characteristics of the problem, which improves both the efficiency and quality of execution of the planning process \cite{le1990combination}. Also, a centralized system simplifies the generation of high-quality plans and permits a centralized authority to modify a plan prior to execution \cite{kvarnstrom2011planning}. A centralized approach is better suited for tightly coupled agents that require a high degree of coordination \cite{luna2011push}. For that reason, we use a centralized approach in our work.
Decentralized systems are better at handling scalability and computational efficieny \cite{bhattacharya2010multi, wu2011online}. When it comes to Distributed Continual Planning (DCP) \cite{durfee1999survey}, plan generation and execution can happen concurrently. As it relies on communication between agents, it is better suited for online planning. On the other hand, centralized systems are better for offline planning \cite{loizou2002closed}. It is less likely to suffer from communication costs, information loss, and synchronization issues \cite{khonji2022multi}. A centralized approach is better suited for tightly coupled agents that require a high degree of coordination \cite{luna2011push}. For that reason, we use a centralized approach in our work.

Since we take a centralized approach, ensuring computational tractability becomes a challenge.
Approaches to simplifying a multi-agent planning problem have been widely studied, such as decomposition, graph reformulation, and others \cite{erol1994htn,yu2013multi,luna2011push}. 
% Plan decomposition methods, such as hierarchical task network (HTN) planning \cite{erol1994htn}, focus on a distributed system of agents with a possibly incomplete picture of other agents’ plans. Making the connection between multi-agent path planning collision-free unit-distance (CUG) and network flow \cite{yu2013multi} has shown promising results in terms of time efficiency and optimality in path planning. An algorithm for high levels of coordination to avoid collision \cite{luna2011push} has proven to be fast and provide completeness guarantees for graphs without making any assumptions on their topology. 
In our work, we develop a hierarchical decomposition method on a reformulated graph to solve a multi-agent path planning problem with high coordination.

%Lim and Tsiotras  employ a search algorithm where each agent builds its own search space of the environment, communicates with the other agents in the same environment, and updates its own search. This results in all agents acquiring a common subgraph that includes an optimal path. \cite{lim2020mams} 

%Luna and Berkis  develop an algorithm that employs a “push” operation (agents move towards their goal until no progress can be made) and “swap” operation (agents swap positions without changing the configuration of other agents). This algorithm works well for problems requiring high levels of coordination between hundreds of agents. \cite{luna2011push}

%To determine if cooperation is required, Zhang and Subbarao \cite{zhang2016formal} address two questions: what conditions need to be met for cooperation to be required, and how to determine the minimum number of agents required to solve the problem. They determined that, if none of these conditions hold, then the problem is single-agent solvable.

The contribution of the paper are: (i) the formulation of a new multi-agent coordination problem with strong coupling between teammembers' positions and action; (ii) a conversion of the problem into a simple single-agent path-planning problem; and (iii) development of a hierarchical decomposition scheme that alleviates the curse of dimensionality.


% The paper is structured as follows: in Sec.~\ref{sec:problem-formulation}, we present the problem formulation basis, where we define the environment graph and the objective function. In Sec.~\ref{sec:method}, we present the method which transforms the environment graph into the Joint State Graph (Subsec.~\ref{Sec_JSG}), and the construction of the Critical Joint State Graph (Subsec.~\ref{Sec_CJSG}). In Sec.~\ref{sec:numerical-results}, we show numerical results that confirm our belief that our algorithms are efficient and are able to provide optimal path planning results. Finally, in Sec.~\ref{sec:conclusion} we provide concluding remarks and possible future work. 
%\sara{what can we say about our algorithm? Efficient? Optimal planning?} \\

%\xuan{Notation: How about we use `mathcal' fonts for all sets? in my opinion, its clearer.}\daigo{Sounds good to me!}

% \edit{
% \begin{small}
% Notations (maybe remove for final version)
% \begin{itemize}
% \item[] $\nodeset$ - set of nodes in the environment graph
% \item[] $\edgeset$ - set of edges in the environment graph
% \item[] $\edge{i}{j}$ - edge connecting node $i$ and node $j$
% \item[] $\cost{i}{j}$ - edge cost in the environment graph
% \item[] $\costn{t}{n}$ - edge cost of agent $n$ at time $t$
% \item[] $\Cost{t}{AB}$ - sum of costs for both agents at time $t$
% \item[] $\post{t}{n}$ - position of agent $n$ at time $t$
% \item[] $\actset{n}{i}$ - set of actions of agent $n$ at node $i$
% \item[] $\act{t}{i}{j}$ - traverse from node $i$ to node $j$ at time $t$
% \item[] $\supnodes{i}{j}$ - set of support nodes in the environment graph
% \item[] $\pathset{n}$ - set of action sequences for agent $n$
% \item[] $\paths{n}{k}$ - a sequence of actions agent $n$ takes from start node to goal node
% \item[] $\mathcal{S}$ - set of nodes in the joint state graph
% \item[] $\mathcal{L}$ - set of edges in the joint state graph
% \item[] $C$ - edge cost in the joint state graph
% \item[] $\mathcal{E}_o$ - set of edges in the ordinary graph
% \item[] $\mathcal{E}_R$ - set of supported edges in the supporting graph
% \item[] $\psi_{ij}$ - minimum cost for one agent moving from node $i$ to node $j$
% \item[] $\mathcal{M}$ - set of nodes in the critical joint state graph
% \item[] $\mathcal{H}$ - set of edges in the critical joint state graph
% \item[] $H_{pq,r\ell}$ - edge cost of critical joint states $\state{p}{q}$ and $\state{r}{\ell}$
% \item[] $\pathsetJ$ - set of paths
% \item[] $u^{\star}$ - the optimal path for JSG
% \item[] $u^{\dagger}$ - the optimal path for CJSG
% \item[] $Q$ - the sum of the cost
% \end{itemize}
% \end{small}
% }


%\xuan{Let's reach a consensus on some terminologies and notations between Section II and Section III.\\
%1. We call the graph in Fig. 1 an environment graph, we agreed on this.  \\
%2. In section III, we decompose the environment graph into an ordinary graph and a supporting graph.
%3. In section II, there are some terms like 'base graph', 'support graph', and 'base environment graph', which confuses me to some extent. Is there a way that we associate these terms with 'ordinary graph' and 'supporting graph'? E.g. base=ordinary and support=supporting? I can simply change the names of graphs in my part but I want to double-check their distinctions before doing that.
%\\} \sara{I think I fixed this for sec II and sec III part A}
