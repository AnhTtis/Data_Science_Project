\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage{iccv}             
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath,bm}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{tabstackengine}
\usepackage{ctable}
\usepackage{threeparttable, tablefootnote}
\usepackage{array, caption, floatrow, makecell, booktabs}
\floatsetup[table]{capposition=top}
\TABstackMath
\TABstackMathstyle{\displaystyle}
\setstackgap{S}{12pt}
\setstacktabbedgap{7pt}
\TABbinary
% Include other packages here, before hyperref.
\newcommand{\tablestyle}[2]{\setlength{\tabcolsep}{#1}\renewcommand{\arraystretch}{#2}\centering\footnotesize}
% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{***} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ificcvfinal\pagestyle{empty}\fi


\newcommand{\authnote}[2]{$\ll$\textsf{\footnotesize #1 notes: #2}$\gg$}

\newcommand{\gu}[1]{{\color{orange}\authnote{Gu}{#1}}}
\newcommand{\yang}[1]{{\color{blue}\authnote{Yang}{#1}}}
\newcommand{\chuan}[1]{{\color{red}\authnote{Chuan}{#1}}}
\newcommand{\js}[1]{{\color{teal}[Jiaming: #1]}}



\begin{document}

%%%%%%%%% TITLE
\title{Seer: Language Instructed Video Prediction with Latent Diffusion Models}

\author{
Xianfan~Gu\textsuperscript{1}
\quad Chuan~Wen\textsuperscript{1,2,3}
\quad Jiaming Song\textsuperscript{4}
\quad Yang~Gao\textsuperscript{1,2,3}\\
\textsuperscript{1}Shanghai Qi Zhi Institute \quad \textsuperscript{2}IIIS, Tsinghua University \\
\textsuperscript{3}Shanghai Artificial Intelligence Laboratory \quad
\textsuperscript{4}NVIDIA\\
}
\maketitle
% Remove page # from the first page of camera-ready.
%\ificcvfinal\thispagestyle{empty}\fi
%%%%%%%%% ABSTRACT
\begin{abstract}
Imagining the future trajectory is the key for robots to make sound planning and successfully reach their goals. Therefore, text-conditioned video prediction (TVP) is an essential task to facilitate general robot policy learning, i.e., predicting future video frames with a given language instruction and reference frames. It is a highly challenging task to ground task-level goals specified by instructions and high-fidelity frames together, requiring large-scale data and computation. To tackle this task and empower robots with the ability to foresee the future, we propose a sample and computation-efficient model, named \textbf{Seer}, by inflating the pretrained text-to-image (T2I) stable diffusion models along the temporal axis. We inflate the denoising U-Net and language conditioning model with two novel techniques, Autoregressive Spatial-Temporal Attention and Frame Sequential Text Decomposer, to propagate the rich prior knowledge in the pretrained T2I models across the frames. With the well-designed architecture, Seer makes it possible to generate high-fidelity, coherent, and instruction-aligned video frames by fine-tuning a few layers on a small amount of data. The experimental results on Something Something V2 (SSv2) and Bridgedata datasets demonstrate our superior video prediction performance with around 210-hour training on 4 RTX 3090 GPUs: decreasing the FVD of the current SOTA model from 290 to 200 on SSv2 and achieving at least 70\% preference in the human evaluation. \url{https://seervideodiffusion.github.io/}
\end{abstract}

%%%%%%%%% BODY TEXT
\input{01-intro}
\input{02-relatedwork}
\input{03-method}
\input{04-exp}
\input{05-conclusion}

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\clearpage
\input{06-appendix}
\end{document}