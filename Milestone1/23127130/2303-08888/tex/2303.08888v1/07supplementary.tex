\section{Supplementary material}

\subsection{Metrics details}
The GED and HM-IoU metrics used in our work are computed as follows:

{\bf GED:} Let~$p_m$ be the distribution over samples generated by a model and $p_{gt}$ the distribution over possible ground-truth labels; the GED is computed as
\begin{align}
    \label{eq:ged}
    \text{GED}(p_m, p_{gt}) = &2\EX_{s\sim p_m,\hat{s}\sim p_{gt}}[d(s,\hat{s})] - \EX_{s,\hat{s}\sim p_{gt}}[d(s,\hat{s})] \nonumber\\
    & - \EX_{s,\hat{s}\sim p_m}[d(s,\hat{s})],
\end{align}
where the distance function $d(\cdot,\cdot) = 1 - \text{IoU}(\cdot,\cdot)$. 

{\bf HM-IoU:} Finds the optimal matching between ground truth and generated samples. Specifically, for $n$ generated samples, the ground-truth samples are duplicated to $n$. Then, the HM-IoU is defined as the maximum IoU possible, given that every generated sample is matched with a unique ground-truth label, found by minimizing
\begin{equation}
    \text{HM-IoU} = \min_X\sum_i\sum_j d(i,j)X_{i,j},
\end{equation}
where $X$ is a boolean matrix that assigns every row to a unique column using $d(\cdot,\cdot) = 1 - \text{IoU}(\cdot,\cdot)$.

\subsection{Sample diversity}

Sample diversity is the expected distance between generated samples, \ie,~$\EX_{s,\hat{s}\sim p_m}[d(s,\hat{s})]$, which corresponds to the last term of GED in Eq.~\eqref{eq:ged}.
We report the sample diversity for 16, 32, 50, and 100 samples for both LIDC splits in Tab.~\ref{tab:diversity1} and Tab.~\ref{tab:diversity2}. 

\begin{table}[ht]
\begin{center}
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{l|cccc}
\toprule
 & \multicolumn{4}{c}{\textbf{LIDCv1}}\\
\textbf{Method} & Div$_{16}$ & Div$_{32}$ & Div$_{50}$ & Div$_{100}$\\
\hline
CCDM & 0.491\tiny{$\pm$0.001} & 0.509\tiny{$\pm$0.001} & 0.515\tiny{$\pm$0.002} & 0.519\tiny{$\pm$0.002} \\
\bottomrule
\end{tabular}
%}  
}
\end{center}
\caption{Sample diversity for our method on LIDCv1.}
\label{tab:diversity1}
\end{table}

\begin{table}[ht]
\begin{center}
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{l|cccc}
\toprule
 & \multicolumn{4}{c}{\textbf{LIDCv2}} \\
\textbf{Method} & Div$_{16}$ & Div$_{32}$ & Div$_{50}$ & Div$_{100}$ \\
\hline
CCDM & 0.487\tiny{$\pm$0.003} & 0.503\tiny{$\pm$0.003} & 0.509\tiny{$\pm$0.003} & 0.515\tiny{$\pm$0.002} \\
\bottomrule
\end{tabular}
%}  
}
\end{center}
\caption{Sample diversity for our method on LIDCv2.}
\label{tab:diversity2}
\end{table}

\subsection{Model size}
While our 9M CCDM as reported in Tab.~\ref{tab:lidc} is of comparable size to most other baselines, we show in Tab.~\ref{tab:lidc_size} that by increasing the size of our CCDM from 9M to 41M, we get an increase in performance across all six metrics computed on LIDCv1. Additionally, the CCDM seems to benefit more from the increase in size than MoSE~\cite{Gao2022-zt}. While we already outperform the other baselines with our 9M model, this result suggests that we can improve the performance even further by using larger models.
\begin{table}[ht]
\begin{center}
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{lc|cccccc}
\toprule
 & \multicolumn{4}{c}{\textbf{LIDCv1}}\\
\textbf{Method} & \#params & GED$_{16}$ & GED$_{32}$ & GED$_{50}$ & GED$_{100}$ & HM-IoU$_{16}$ & HM-IoU$_{32}$\\
\hline
MoSE~\cite{Gao2022-zt} & 9m & 0.219 & - & 0.195 & 0.190 & 0.620 & - \\
MoSE~\cite{Gao2022-zt} & 42m & 0.218 & - & 0.195 & 0.189 & 0.624 & - \\
\midrule
CCDM & 9m & 0.212 & 0.194 & 0.187 & 0.183 & 0.623 & 0.631\\
CCDM & 41m & 0.207 & 0.189 & 0.182 & 0.177 & 0.629 & 0.636\\
\bottomrule
\end{tabular}
%}  
}
\end{center}
\caption{Performance of CCDM and MoSE on LIDCv1 with different model sizes.}
\label{tab:lidc_size}
\end{table}

\subsection{Training settings of baselines on Cityscapes}

On Cityscapes, all baselines were trained for $500$~epochs using the optimizer, learning rate schedule, and weight decay (denoted by~$w_d$) reported in their original publications. Tab.~\ref{tab:settings_cts} details these settings for each case. All models are trained using a cross-entropy loss.

\begin{table}[htb]
\centering
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{*7c}
    \toprule
    \multicolumn{2}{c}{Method}  &  \multicolumn{5}{c}{\textbf{Settings}}                     \\
    \cmidrule(r){1-2}               \cmidrule(l){3-7}
          Arch.   & Backbone                & Lr               & Decay        & $w_{d}$          & Batch Size    & Optim \\
    \midrule
    \mc{\hrn}\cite{HRNet}     & \mc{w$48$v$2$}          & $10^{-2}$        & polynomial   & $5\times10^{-5}$ & \mc{$32$}    & sgd \\ 
    \mc{\dv}\cite{DeepLabv3}      & \mc{ResNet$50/101$}     & $10^{-2}$        & polynomial   & $5\times10^{-5}$ & \mc{$32$}    & sgd \\ 
    \mc{UPerNet}\cite{UPerNet}  & \mc{ResNet$101$}        & $10^{-2}$        & polynomial   & $5\times10^{-5}$ & \mc{$32$}    & sgd \\
    \mc{UPerNet}\cite{Swin}  & \mc{Swin-T}             & $10^{-4}$        & warmup+linear       & $10^{-2}$        & \mc{$32$}    & AdamW \\
    % \mc{UNet}     & \mc{-}                         & $10^{-4}$        & linear       & \mc{-}           & \mc{$16/32$} & Adam \\
    % \mc{UNet}     & \mc{Dino-ViT-S} ($\dagger$)    & $10^{-4}$        & linear       & \mc{-}           & \mc{$16/32$} & Adam \\
    \bottomrule
\end{tabular}
} % resizebox  
\caption{Training settings of baselines on Cityscapes.
}
\label{tab:settings_cts} 
\end{table}

\subsection{Additional comparisons on Cityscapes}

\begin{table}[ht]
% \centering
\resizebox{80mm}{!}{
\begin{tabular}{*5c}
    \toprule
    \multicolumn{3}{c}{\textbf{Method}}             & \multicolumn{2}{c}{mIoU} \\
    \cmidrule(r){1-3}                                 \cmidrule(l){4-5}         
    Architecture       & \mc{Backbone}   & \#params     & \mc{$128\times256$}    &  \mc{$256\times512$}\\
    \midrule
    \mc{UNet} (CE) \cite{dmsBeatGans} & \mc{-}                      & 30m                & 48.7       &  61.0  \\ 


    \midrule
    \mc{CCDM} (ours) & \mc{-}     &  \quad          &  \quad        & \quad   \\  
    
    samples=1 & \mc{}             & 30m           &  53.2         & 60.3     \\  
    samples=5 & \mc{}             & 30m            &  55.4           & 62.0   \\  
    samples=10 & \mc{}            & 30m            & 56.2          &  62.4    \\  
  
    \midrule
    \mc{UNet (CE)} \cite{dmsBeatGans} & \mc{Dino ViT-S} ($\dagger$) & 30m + \textcolor{gray}{20M}                & 53.4       &  63.2   \\ 
    \midrule

    \mc{CCDM (ours)} & \mc{Dino ViT-S} ($\dagger$)             & \quad           &  \quad        & \quad   \\  
    samples=1 & \mc{}               & 30m + \textcolor{gray}{20M}           &  55.5         &  64.0     \\  
    samples=5 & \mc{}               & 30m + \textcolor{gray}{20M}           & \underline{56.9}           &  \underline{65.4}   \\  
    samples=10 & \mc{}              & 30m + \textcolor{gray}{20M}           & \textbf{57.3}          &  \textbf{65.8}    \\  
    \bottomrule
    
\end{tabular}}

\caption{Comparison of our method to UNet and UNet-Dino, trained with standard Cross-Entropy (CE) loss, on Cityscapes-val. \textbf{Bold} and \underline{underlined} indicate best and second best per column, respectively. ($\dagger$) indicates self-supervised pretraining of the backbone. \textcolor{gray}{Gray} indicates pretrained, non-finetuned parameters.}
\label{tab:cts_unet}
\end{table}

\begin{figure*}[]
\centering
\includegraphics[width=0.99\textwidth]{figures/fig_cts_qualitative_supp.png}
\caption[]{Qualitative comparisons of our method to competitive baselines on Cityscapes validation set.
}
\label{fig:quali_cts_2}
\end{figure*}

\begin{figure*}[h!]
\centering
\includegraphics[width=0.99\textwidth]{figures/fig_cts_forward_process_2.png}
\caption[]{Visualization of the forward diffusion process at different time steps.}
\label{fig:quali_cts_forward}
\end{figure*}

We evaluate the gains of CCDMs with respect to their backbone architectures when used as standalone segmentation models. To this end, we compare the performance of our CCDM trained as defined in Alg.~\ref{alg:training} and the UNet trained with a standard cross-entropy loss, both on the Cityscapes dataset. Similarly, we compare CCDM-Dino to its standalone backbone architecture DinoViT-S. In all cases, we adopt the same training settings as our method, namely, $800$~epochs, linearly decayed learning rate, batch size of~$32$ at $128\times256$ and $16$~at $256\times512$. As shown in Tab.~\ref{tab:cts_unet}, CCDM and CCDM-Dino outperform their respective standalone architectures.

We also provide additional qualitative comparisons of our method to competitive baselines in Fig.~\ref{fig:quali_cts_2}. Finally, Fig.~\ref{fig:quali_cts_forward} shows an example of the evolution of a Cityscapes label map under the forward diffusion process described by Eq.~\eqref{eq:q_xt_given_xt-1}.

