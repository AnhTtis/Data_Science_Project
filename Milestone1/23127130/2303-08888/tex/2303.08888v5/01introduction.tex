\section{Introduction}
\label{sec:introduction}

Semantic segmentation has significantly progressed in recent years due to powerful deep neural networks. For most methods, the key objective is to generate a single segmentation output that accurately matches the image's content.
However, this may not be suitable for safety-critical domains such as medical diagnostics and autonomous driving, as images in these applications often suffer from inherent ambiguity or annotations that have differences in opinion. In these cases, generating a single coherent segmentation may be hopeless to fully describe the set of correct labeling.

Instead, multiple possible correct segmentation maps may be required to reflect the true distribution of annotations.
For instance, Fig.~\ref{fig:intro} illustrates the task of lung nodule segmentation from CT scans where expert annotators provide multiple valid segmentation maps. In this context, stochastic semantic segmentation methods must learn to predict conditional distributions of labels given the image. Doing so is challenging, however, as the distribution is typically multimodal, the output space is high-dimensional, and annotation data is limited.

\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{figures/iccv_teaser.pdf}
    \caption{Examples from the LIDC dataset, where expert radiologists were asked to annotate lung nodules. Despite their expertise, they disagree significantly on many cases. Standard segmentation networks fail to capture these variations, thereby giving a false sense of confidence in model predictions. Our approach learns the distribution of possible labels, allowing us to generate realistic and diverse segmentations.}
    \label{fig:intro}
\end{figure}

Denoising Diffusion Probabilistic Models (DDPMs) appear well-suited to overcome these challenges. DDPMs have recently drawn strong interest in computer vision as a framework for learning complex distributions in high-dimensional spaces. After achieving state-of-the-art performance on image synthesis~\cite{dmsBeatGans}, they have been successfully extended to solve tasks such as text-to-image generation~\cite{saharia2022photorealistic}, counterfactual explanation generation~\cite{jeanneret2022diffusion}, inpainting ~\cite{lugmayr2022repaint}, but also image classification~\cite{zimmermann2021score} and semantic segmentation~\cite{amit2021segdiff,baranchuk2021label,wolleb2021diffusion} amongst others. 

% Problems with DDPM for segmentation
While DDPMs were originally formulated as probabilistic models able to learn high-dimensional data distributions of discrete and ordered variables (\eg,~RGB pixel values), re-formulations and modifications that allow for categorical variables (\eg,~labels)~\cite{hoogeboom2021argmax} are one of the key reasons why DDPMs are being explored in a broad range of computer vision tasks~\cite{croitoru2022diffusion}. Specifically, the ability to model the spatial distribution of categorical variables is well suited for numerous computer vision tasks, including semantic segmentation~\cite{chen2017deeplab, chen2018encoder, chu2021twins, fu2019dual, gu2022multi, harley2017segmentation, kirillov2019panoptic, li2022deep, long2015fully, zhang2022semantic, zhao2017pyramid}. Yet until now, segmentation methods using DDPMs have relied on the original discrete and ordered formulation and different heuristics to yield categorical outputs~\cite{amit2021segdiff, baranchuk2021label, wolleb2021diffusion}. Consequently, the potential advantages of adopting diffusion models of categorical variables for stochastic image segmentation are still unknown.

In light of the above, we propose a \emph{conditional categorical diffusion model}~(CCDM)~for semantic segmentation based on DDPMs, which models both the observed and the latent variables as categorical distributions. This enables the model to explicitly generate labels maps of discrete, unordered variables, thereby circumventing the need for switching between continuous and discrete domains, as in previous methods. The model is conditioned to the input image, making it possible to generate multiple segmentation label maps that account for the aleatoric uncertainty arising from image ambiguity. 
We show experimentally that our approach achieves state-of-the-art performance on LIDC, a stochastic semantic segmentation dataset, according to several performance measures. Moreover, when applied to the classical segmentation dataset Cityscapes, our method provides competitive results, outperforming established baselines.

In summary, our main contributions are the following: 
\begin{itemize}
    \item We propose a conditional categorical diffusion model capable of learning the label distribution given an input image that can be used to produce diverse segmentation samples that capture aleatoric uncertainty.
    \item For the task of learning a multi-rater semantic segmentation label distribution, our method achieves state-of-the-art performance on LIDC, being the first diffusion-based approach proposed for this task.
    \item We report competitive performance on a challenging semantic segmentation task, Cityscapes, outperforming several established baselines using a lightweight model that also leverages an off-the-shelf pre-trained feature extractor. 
\end{itemize}
%-------------------------------%
%-------------------------------%
