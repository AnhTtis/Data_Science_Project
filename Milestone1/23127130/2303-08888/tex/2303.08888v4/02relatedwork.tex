\section{Related work}

{\bf Stochastic segmentation:} Methods for stochastic semantic segmentation aim at capturing the aleatoric uncertainty and inherent unpredictability of the labels used for segmentation. Different frameworks have been proposed to yield segmentations according to the underlying label distribution. 

Initial works aimed at equipping a standard U-Net~\cite{ronneberger2015u} with a probabilistic element to generate multiple predictions for the same image, typically accomplished by adding a conditional variational autoencoder (cVAE)~\cite{sohn2015learning}, where the low-dimensional latent space of the cVAE encodes the possible segmentation variants. In \cite{Kohl2018-hp}, samples from this latent space are upscaled and concatenated at the last layer of the U-Net. Multiple methods extend this set-up to a hierarchical version ~\cite{baumgartner2019phiseg,kohl2019hierarchical,zhang2022a-probabilistic}. Other works use normalizing flows to allow for a more expressive distribution than the Gaussian distribution in the cVAE~\cite{selvan2020uncertainty,valiuddin2021improving}, switch to a discrete latent space~\cite{qiu2020modal}, or add variational dropout and use the inter-grader variability directly as a training target~\cite{hu2019supervised}.

Several other methods do not rely on the probabilistic U-Net. Monteiro \emph{et al.}~\cite{monteiro2020stochastic} propose a network that uses a low-rank multivariate normal distribution to model the logit distribution. Kassapis \emph{et al.}~\cite{kassapis2021calibrated} leverage adversarial training to learn possible label maps based on the logits of a trained segmentation network. Zhang \emph{et al.}~\cite{zhang2022b-pixelseg} employ an autoregressive PixelCNN to model the conditional distribution between pixels. Finally, Zhitong \emph{et al.}~\cite{Gao2022-zt} use a mixture of stochastic experts, where each expert network estimates a mode of the uncertainty, and a gating network predicts the probabilities that an input image is segmented by one of the experts. Our method is the first to explore the use of categorical diffusion models for this task.

{\bf Diffusion models:} 
Generative diffusion models~\cite{sohl2015deep} have drawn much attention following their popularization by~\cite{ho2020denoising}. Since then, diffusion models have been successfully applied to various domains, such as image generation, restoration, and super-resolution \cite{croitoru2022diffusion}. 

More central to the work presented here, a few methods have attempted to apply diffusion models to semantic segmentation. Baranchuk \emph{et al.}~\cite{baranchuk2021label} first train diffusion models to generate images, then use multilayer perceptrons (MLP) on its features to predict the class label. Other works focus on binary segmentation with conditional diffusion models~\cite{amit2021segdiff,wolleb2021diffusion}. These methods generate single-channel continuous samples conditioned on the input image and obtain binary segmentation masks by thresholding the result. Directly applying continuous diffusion is also done in ~\cite{wu2022medsegdiff,wu2023medsegdiff}. Chen \emph{et al.}~\cite{chen2022analog} generate discrete data with continuous diffusion models by encoding categorical data into bits and modeling these bits as real numbers. 

Hoogeboom \emph{et al.}~\cite{hoogeboom2021argmax} propose multinomial diffusion, a variation of diffusion models designed for categorical data. Subsequently, multinomial diffusion has been applied to discrete use cases, such as for tabular data~\cite{kotelnikov2022tabddpm}, the latent space of vector-quantized variational auto-encoders~\cite{cohen2022diffusion,hu2022global} or text~\cite{hoogeboom2021argmax}. They can also generate segmentation maps in the unconditional setting at a very small resolution ($32\times64$)~\cite{hoogeboom2021argmax}. Instead, we focus on the unexplored conditional case and demonstrate results at significantly higher resolutions (up to $256\times512$).