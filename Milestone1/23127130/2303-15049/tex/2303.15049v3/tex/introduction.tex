\section{Introduction}
\label{sec:introduction}

\noindent With the latest advancement of Conversational AI, end-to-end dialogue systems have been extensively studied \cite{zhang-etal-2020-dialogpt, adiwardana2020towards, roller-etal-2021-recipes}. 
One critical requirement is context awareness; robust dialogue systems must consider relevant parts in conversation history to generate pertinent responses \cite{serban2017hierarchical, mehri2019pretraining, bao-etal-2020-plato, zhou2021eva, xu-etal-2022-beyond}.
However, these systems still suffer from issues such as hallucination, inconsistency, or lacking commonsense \cite{bao2021plato}, hindering them from taking place in real applications.

Numerous admission interviews are given every year to students located in 100+ countries applying to colleges in the U.S., where the interviews are often conducted online. % and recorded in their entirety.
Those interviews are usually unscripted, with an emphasis on asking the applicants thought-provoking questions based on their interests and experiences. 
The main objective is to provide decision-makers (e.g., admissions officers, faculty members) with an unfiltered look at those students in a daily academic environment.

Building an interview chatbot, called InterviewBot, will save time and effort for the interviewers and provide foreign students with a cost-efficient way of practicing interviews when native speakers are unavailable.
Nonetheless, there are a few hurdles to developing an end-to-end InterviewBot.
First, it is hard to collect a sufficient amount of data covering dialogues crossing open \& closed domains (Section~\ref{sec:dataset}).
Second, most transformer-based encoder-decoder models adapted by current state-of-the-art systems are not designed to handle long contexts; thus, they often repeat or forget previously discussed topics (Section~\ref{sec:generation-model}).
Third, it is demanding to find appropriate people to interactively test such a dialogue system with the professional objective (Section~\ref{sec:evaluation}).


This paper presents an end-to-end dialogue system that interacts with international applicants to U.S. colleges.
The system questions critical perspectives, follows up on the interviewee's responses for in-depth discussions, and makes natural transitions from one topic to another until the interview ends, which lasts about 30 turns (5 mins for text-based, 10 mins for spoken dialogues).
To the best of our knowledge, it is the first real-time system using a neural model, completely unscripted, conducting such long conversations for admission interviews.
Our technical contributions are summarized as follows:

\begin{itemize}
    \item We have developed a contextualized neural model designed to perform diarization tasks on text transcripts alone.
    \item We have integrated a sliding window technique to overcome the input token limit and restore the completeness of the input in the latent space.
    \item We have integrated extracted topics from the conversation to address issues related to topic repetition, off-topic discussions, and premature endings in conversations.
\end{itemize}


\noindent The remaining sections are organized as follows: Section~\ref{sec:related-work} reviews current dialogue models, their applications, and limitations. Section~\ref{sec:materials_methods} describes datasets and our speaker diarization and InterviewBot model architectures in detail. Section~\ref{sec:evaluation} gives experiment results on diarization and InterviewBot dialogue generation. Section~\ref{sec:appendix} and Section~\ref{sec:conclusion} conduct discussions on the results and conclude the paper.







%With the latest advancement of deep learning in Conversational AI, generative conversational systems have been extensively studied and developed. 
%One of the critical elements in such systems is context awareness \cite{serban2017hierarchical}. 
%A well-performing conversational system generates responses taking both the current utterance and previous interactions into account. 
%Different deep learning approaches in learning contextual information have been proposed and experimented with in previous research \cite{mehri2019pretraining, zhou2021eva}. 
%Several challenges have been addressed with those end-to-end dialogue systems such as hallucination, inconsistency, or lacking commonsense \cite{bao2021plato}. 
%Specifically, pre-trained dialogue models and their variations \cite{zhang-etal-2020-dialogpt, adiwardana2020towards, bao-etal-2020-plato, xu-etal-2022-beyond} have shown superior performance in dialogue generations with integration of dialogue history. 
%However, previous dialogue models and systems haven shown limitations on taking arbitrarily long utterances and context in their entirety and avoiding repeated topic discussion in long conversations.
%
%In this paper, we propose a real-time generative dialogue system, Interviewbot, taking arbitrary-length utterances and context to handle long conversations in a college application interview setup. 
%During the interactions, the system generates questions on critical perspectives, follows up on interviewee's responses for in-depth discussions, and makes natural transitions from one topic to another until the conversation ends, which can last over 30 turns (about 5 minutes for text-based chats, 10+ minutes for spoken dialogues), evaluated both statically and through real-time interactions.
%This work makes three major contributions as follows:
%\begin{enumerate}
%\setlength\itemsep{0em}
%% \item A joint multi-task learning model is developed to correct speaker diarization errors in the automatic transcription (Section~\ref{sec:speaker-diarization}).
%\item A sliding-window technique is used to enable the encoding of arbitrary-length utterances and context.
%\item A real-time end-to-end dialogue system using context attention and topic storing is developed to adequately handle long conversations (Section~\ref{sec:generation-model}) and tested by diverse people for its adaptability in a real application (Section~\ref{sec:evaluation}).
%% \item A real-time system, InterviewBot, is built and tested by diverse people for its adaptability in a real application (Section~\ref{sec:evaluation}).
%\end{enumerate}


% chatbots have been integrated to practical applications for many purposes such as customer service \cite{baier2018conversational,nichifor2021artificial}, education \cite{cunningham2019review}, healthcare \cite{fan2021utilization,amiri2022chatbot}, etc.
% However, the notion of chatbots in general is perceived differently between industry and academic communities.
% Most commercial chatbots out there rely on pre-scripted dialogues where the flows are determined by selecting pre-defined options, thus require almost no natural language understanding, while academic research focuses on building end-to-end dialogue systems with deep-neural models.
% However, the models, including 
% Several challenges have been addressed with those end-to-end models such as hallucination, inconsistency, or lacking commonsense \cite{bao2021plato}, hindering them to take a place in real applications.
% Thus, collaborative efforts are needed among academic and industrial researchers to bring the latest Conversational AI technology into practice.
% In particular, numerous interviews are given every year to students located in 100+ countries applying to colleges in the U.S., where the interviews are often conducted online by designated parties. % and recorded in their entirety.
% These interviews are usually unscripted with an emphasis on asking the applicants thought-provoking questions based on their interests and experiences. 
% The main objective is to provide decision makers (e.g,. admissions officers, faculty members) with an unfiltered look at students' abilities to communicate in a daily academic environment in the U.S.

%Chatbots are trending in applications in many fields for different purposes, such as entertaining, guidance, task assistance, and so on.
%In general, chatbots can be categorized into closed-domain and open-domain systems \cite{ilievski2018goal}. Closed-domain chatbots requires strong support from sufficient domain knowledge in the system \cite{lian2019learning}. 
%Open-domain chatbots are designed to converse in multiple domains with natural transitions between domain topics \cite{adiwardana2020towards}. 
%While with this categorization methodology, it may be a fusion or alternations of closed domain and open domain conversations in occasions like particular interviews.
%Chatbots have been widely used to communicate with humans for information exchange or elicitation \cite{finch2020emora, li2017confiding, Kim2019Comparing}, crossing different domains, such as education \cite{okonkwo2021chatbots}, healthcare\cite{safi2020technical}, commodity \cite{khoa2021impact}, and so on.
%Recent advancing in applications of chatbots have shown their advantages in the effectiveness and flexibility in engaging users with open questions \cite{devlin-etal-2019-bert}. However, few models are built to conduct unscripted and effective interviews to elicit information from users for afterward decision makings. 
%Particularly, thousands of interviews are conducted and recorded each year with students who are applying to colleges in the U.S. 
%Student interviewees are located in more than 100 countries, and the interviews are conducted online by designated parties and recorded in their entirety. 
%The interviews are unscripted, with an emphasis on ensuring that the student is asked thought-provoking questions based on their interests and experiences. 
%The ultimate goal of the interview is to provide decision-makers—i.e., admissions officers and faculty members—with an unfiltered look at the ability of an applicant to communicate in an unscripted academic environment.

% Building an interview chatbot, called InterviewBot, will save time and effort of the interviewers, and provide foreign students a cost-efficient way of practicing interviews when native speakers are not available.
% Nonetheless, there are a few hurdles for developing an end-to-end InterviewBot.
% First, it is hard to collect a sufficient amount of training data that cover dialogues crossing open and closed domains.
% Second, these interviews are recorded in noisy environments usually with one channel such that automatic transcription becomes challenging.
% Third, transformer-based encoder-decoder models adapted by current state-of-the-art systems are not designed to handle long conversations; thus, they often repeat or forget previously discussed topics.
% However, traditional transformer-based encoder-decoder models adapted by current state-of-the-art systems are not designed to handle long conversations; this they often repeat or forget previously discussed topics.


%There are major hurdles for building such models. 
%First, there must be sufficient training data to cover hybrid conversations crossing both open and closed domains. 
%Second, data have to be examined, and potential issues in the data have to be discovered and corrected, before being fed into models.
%For example, speaker diarization is one of the critical topics in speech recognition and transcription \cite{anguera2012speaker}.
%Conversation data with diarization errors could lead to major faitures of conversational models.
%Third, models must have contextual awareness \cite{parthasarathi2018extending} to avoid repetitions of subjects of discussion, ensure topic coverage, maintain the natural fluency, and so on.

% This paper introduces a real-time end-to-end dialogue system that interacts with foreign students applying to US colleges.
% During the interview, the system questions on critical perspectives, follows up on interviewee's responses for in-depth discussions, and makes natural transitions from one topic to another until the conversation ends, which lasts about 30 turns (about 5 mins for text-based chats, 10+ mins for spoken dialogues).
% This work makes three major contributions as follows:
% This work makes two major contributions as follows:
% \begin{enumerate}
% \setlength\itemsep{0em}
% % \item A joint multi-task learning model is developed to correct speaker diarization errors in the automatic transcription (Section~\ref{sec:speaker-diarization}).
% \item An end-to-end dialogue model using context attention and topic storing is developed that adequately handles long conversations (Section~\ref{sec:generation-model}).
% \item A real-time system is built for the InterviewBot and tested by diverse people for its adaptability in a real application (Section~\ref{sec:evaluation}).
% \end{enumerate}

%In this paper, we conduct research on building an interviewbot to interact with student applicants to U.S. colleges. 
%During interviews, the interviewbot is designed to ask questions on critical perspectives and make discussions or comments following up on interviewees' responses, and naturally make transitions from one topic to the next until the end of a conversation (currently we hard-threshold the conversations to be 30 turns for evaluations). 
%This research consists of two major contributions to tackle two research problems. 
%First, the text transcriptions come from one-channel recordings, which in nature are noisy. 
%A main issue is that around 17\% of utterances in the dataset have diarization errors. 
%We propose a context-based joint-learning diarization model to automatically correct these errors in text transcriptions. 
%Second, we adopt and adapt the state-of-the-art blenderbot model to integrate previous interviewee's and generated interviewers' utterances,  and turn numerals,  for contextual awareness, while resolving the limitation of the length of input to the blenderbot model.


