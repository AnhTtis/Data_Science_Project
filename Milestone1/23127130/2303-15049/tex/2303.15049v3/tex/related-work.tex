\section{Related Work}
\label{sec:related-work}
% The application of chatbots is trending in many domains, such as education \cite{okonkwo2021chatbots}, healthcare\cite{safi2020technical}, commodity \cite{khoa2021impact}, and so on. In this section, we give a general review of the categories of chatbots and applications in different fields.

%End-to-end dialogue systems are trending in the frontier of research. 
%In this section, we give a brief review of the categories of, as well as the state of the art generative models for end-to-end dialogue systems.

%\subsection{Categorical Anatomy}
%\label{ssec:categorical-anatomy}

\noindent Dialogue systems can be categorized into closed- and open-domain systems \cite{ilievski2018goal}.
Closed-domain systems require efficient access to domain knowledge \cite{lian2019learning} and serve specific professions such as education \cite{cunningham2019review}, healthcare \cite{fan2021utilization,amiri2022chatbot}, or customer service \cite{baier2018conversational,nichifor2021artificial}.
Open-domain systems converse across multiple domains with natural transitions \cite{adiwardana2020towards} and conduct interactions in a broader horizon \cite{ahmadvand2018emory, wang2017emersonbot, finch2020emora}.
For admission interviews, however, the conversation is often a mixture of closed (job-related questions) and open-domain (general aspects of the applicant) dialogues, which makes it more challenging to build an end-to-end system.

Several dialogue systems have been developed to communicate with humans for information exchange or elicitation across multiple domains \cite{safi2020technical,khoa2021impact,okonkwo2021chatbots}. 
\cite{finch2020emora} built a conversational system to converse proactively on popular topics with Alexa users by providing them with the requested information as well as pre-crafted transitions.
\cite{li2017confiding} established a virtual interviewer to study on the effect of personality on confiding and listening to virtual agents.
\cite{Kim2019Comparing} studies the role of a chatbot in a survey setup. Although these dialogue systems have shown their effectiveness in achieving their goals, they all heavily rely on design templates.
Conversational agents for interviews have been experimented with for law enforcement \cite{minhas2022protecting}, healthcare \cite{ni2017mandy}, job application \cite{xiao2019should}, and psychology \cite{siddig2019psychologist}, among which most are proof of concept. 
A few interview bots have been developed on commercial platforms such as Google Dialogflow and IBM Watson Assistant, with the limitation of pre-scripted interviews; thus, they cannot proactively follow up on the user content.

Context and memory have been studied as key factors to affect model performance in context-heavy settings.
\cite{9681776} proposed a memory transformer to hierarchically employ memory to improve translation performance.
However, in a more complex conversation setup, dialogue flow is not only about correlations between sentences or words in the semantics but rather the proceeding of conversations with a depth of topics and transitions to other topics.
Other models such as \cite{raheja-tetreault-2019-dialogue} and \cite{9533452} have proposed context and external knowledge-based models in conversation-related tasks. 
Although, the effort was proven to improve based on specific metrics, still not sufficient to improve the overall dialogue flow of conversations.

Deep language models, such as Blenderbot \cite{roller-etal-2021-recipes} and Bart \cite{lewis2019bart}, have taken context into consideration. 
However, the limitation on the length of input tokens as well as conversation history has bottlenecked their applications in the real world.
Recent surges of large language models, such as ChatGPT \cite{openai2023gpt4} and LLaMa \cite{touvron2023llama}, have shown strong evidence of improvement with respect to context integration. 
Nevertheless, there are always limitations on the input length, as well as effective ways of integrating different contexts into a language model.


%\footnote{\url{cloud.google.com/dialogflow}}
%\footnote{\url{www.ibm.com/products/watson-assistant}}

%\subsection{Large-scale Pre-trained Generative Models}


%Pre-trained language models have achieved privileged performance in Natural Language Understanding, as well as Natural Language Generation.
%~\citet{zhang-etal-2020-dialogpt} developed and trained GPTDialogue on massive amount of Reddit data.
%~\citet{adiwardana2020towards} built Meena that advanced the generation of multi-turn conversation.
%Blenderbot 1.0 \cite{roller-etal-2021-recipes}, and Blenderbot 2.0 \cite{xu-etal-2022-beyond} are two consecutive dialogue system advancements that can maintain impressive context-aware interactions. 
%Plato and its variations \cite{bao-etal-2020-plato, bao2021plato} have achieved noticeable performance both on English and Chinese.
%
%In this paper, we take advantage of the pre-trained Blenderbot 1.0 and integrate arbitrary-length context into the dialogue generation. Although Blenderbot 2.0 is more advanced, the context integration serves different purposes and we proceeded by constructing our model based on Blenderbot 1.0.