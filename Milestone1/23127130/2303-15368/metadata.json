{
    "arxiv_id": "2303.15368",
    "paper_title": "2S-UDF: A Novel Two-stage UDF Learning Method for Robust Non-watertight Model Reconstruction from Multi-view Images",
    "authors": [
        "Jukai Deng",
        "Fei Hou",
        "Xuhui Chen",
        "Wencheng Wang",
        "Ying He"
    ],
    "submission_date": "2023-03-27",
    "revised_dates": [
        "2024-04-16"
    ],
    "latest_version": 2,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Recently, building on the foundation of neural radiance field, various techniques have emerged to learn unsigned distance fields (UDF) to reconstruct 3D non-watertight models from multi-view images. Yet, a central challenge in UDF-based volume rendering is formulating a proper way to convert unsigned distance values into volume density, ensuring that the resulting weight function remains unbiased and sensitive to occlusions. Falling short on these requirements often results in incorrect topology or large reconstruction errors in resulting models. This paper addresses this challenge by presenting a novel two-stage algorithm, 2S-UDF, for learning a high-quality UDF from multi-view images. Initially, the method applies an easily trainable density function that, while slightly biased and transparent, aids in coarse reconstruction. The subsequent stage then refines the geometry and appearance of the object to achieve a high-quality reconstruction by directly adjusting the weight function used in volume rendering to ensure that it is unbiased and occlusion-aware. Decoupling density and weight in two stages makes our training stable and robust, distinguishing our technique from existing UDF learning approaches. Evaluations on the DeepFashion3D, DTU, and BlendedMVS datasets validate the robustness and effectiveness of our proposed approach. In both quantitative metrics and visual quality, the results indicate our superior performance over other UDF learning techniques in reconstructing 3D non-watertight models from multi-view images. Our code is available at https://bitbucket.org/jkdeng/2sudf/.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15368v1",
        "http://arxiv.org/pdf/2303.15368v2"
    ],
    "publication_venue": "accepted to CVPR 2024"
}