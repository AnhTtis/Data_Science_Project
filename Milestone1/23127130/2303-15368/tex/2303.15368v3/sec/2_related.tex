\section{Related Work}
\textbf{3D Reconstruction from Multi-View Images.} Surface reconstruction from multi-view images has been a subject of study for several decades, and can generally be classified into two categories: voxel-based and point-based methods. Voxel-based methods~\cite{Bonet1999,Broadhurst2001,Ji2021,Kar2017,Sun2021} divide the 3D space into voxels and determine which ones belong to the object. These methods can be computationally expensive and may not be suitable for reconstructing complex surfaces.
Point-based methods~\cite{Galliani2015,Schonberger2016,Yao2019} use structure-from-motion~\cite{Hartley2004} to calibrate the images and generate a dense point cloud using multi-view stereo~\cite{Furukawa2015}. Finally, surface reconstruction methods (e.g.,  ~\cite{Bernardini1999,Kazhdan2013,Hou2022}) are used to generate a mesh. Since multi-view stereo requires dense correspondences to generate a dense point cloud, which are often difficult to compute, its results often contain various types of artifacts, such as noise, holes, and incomplete structures.

\textbf{Neural Volume Rendering.} Neural network-based 3D surface reconstruction has received attention in recent years with the emergence of neural rendering~\cite{Mildenhall2020}. Several methods have been proposed for volume rendering and surface reconstruction using neural networks. VolSDF~\cite{Yariv2021} uses the cumulative distribution function of Laplacian distribution to evaluate the density function from SDF for volume rendering and surface reconstruction.
NeuS~\cite{Wang2021} adopts an unbiased density function to the first-order approximation of SDFs for more accurate reconstruction.
SparseNeuS~\cite{Long2022SparseNeuS} extends NeuS to use fewer images for reconstruction.
HF-NeuS~\cite{Wang2022HFNeuSIS} improves NeuS by proposing a simplified and unbiased density function and using hierarchical multilayer perceptrons (MLPs) for detail reconstruction.
Geo-NeuS~\cite{Fu2022} incorporates structure-from-motion to add more constraints.
NeuralWarp~\cite{Darmon2022} improves the accuracy by optimizing consistency between warped views of different images.
PET-NeuS~\cite{Wang_2023_CVPR_PETNeuS} further improves the accuracy by introducing tri-planes into the SDF prediction module, incorporating with MLP.
All these methods learn SDFs, which can only reconstruct watertight models.
Recently, Long \emph{et al}. proposed NeuralUDF~\cite{Long2023} for learning UDF for reconstructing open models.
It adapts the S-shaped density function for learning SDF to UDFs by introducing an indicator function.
However, the indicator function is complicated to learn, and also introduces biases.
Liu \emph{et al}. proposed NeUDF~\cite{Liu2023NeUDF} adopting a bell-shaped density. However, to make it occlusion-aware, the density has to be unbounded resulting in an improper integral, which reduces accuracy.
Meng \emph{et al}. proposed NeAT~\cite{Meng2023} to learn SDF with validity so as to reconstruct open models from SDF.
However, it needs foreground masks for data.

\textbf{3D Reconstruction from Point Clouds.} There has been recent interest in surface representation using signed distance fields (SDFs) and occupation fields. Several methods have been proposed for learning SDFs~\cite{Park2019,Chabra2020,Sitzmann2020,Ma2021,Wang2022}, while occupation fields have been used in methods such as ~\cite{Mescheder2019,Chibane2020a}.
However, both SDFs and occupation fields can only represent watertight models.
To represent non-watertight models, some methods are proposed to learn UDF from 3D point clouds~\cite{Chibane2020b,Zhao2021,Zhou2022}. Our proposed method also uses UDF for non-watertight models representation, but we learn it directly from multi-view images, which is a challenging problem.
