@article{gan,
	title={Generative adversarial nets},
	author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	journal={NeurIPS},
	volume={27},
	year={2014}
}

@article{laion5b,
	title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
	author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
	journal={arXiv preprint arXiv:2111.02114},
	year={2021}
}

@InProceedings{webvid,
	author       = "Max Bain and Arsha Nagrani and G{\"u}l Varol and Andrew Zisserman",
	title        = "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval",
	booktitle    = "ICCV",
	year         = "2021",
}

@inproceedings{c3d,
	title={Learning spatiotemporal features with 3d convolutional networks},
	author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
	booktitle={ICCV},
	pages={4489--4497},
	year={2015}
}

@article{masked_flow,
	title={Masked autoregressive flow for density estimation},
	author={Papamakarios, George and Pavlakou, Theo and Murray, Iain},
	journal={NeurIPS},
	volume={30},
	year={2017}
}

@article{sr_dpm,
	title={Image super-resolution via iterative refinement},
	author={Saharia, Chitwan and Ho, Jonathan and Chan, William and Salimans, Tim and Fleet, David J and Norouzi, Mohammad},
	journal={PAMI},
	year={2022},
	publisher={IEEE}
}

@inproceedings{agustsson2020scale,
	title={Scale-space flow for end-to-end optimized video compression},
	author={Agustsson, Eirikur and Minnen, David and Johnston, Nick and Balle, Johannes and Hwang, Sung Jin and Toderici, George},
	booktitle={CVPR},
	pages={8503--8512},
	year={2020}
}

@article{yang2020hierarchical,
	title={Hierarchical autoregressive modeling for neural video compression},
	author={Yang, Ruihan and Yang, Yibo and Marino, Joseph and Mandt, Stephan},
	journal={arXiv preprint arXiv:2010.10258},
	year={2020}
}

@article{human_actions,
	title={Actions as space-time shapes},
	author={Gorelick, Lena and Blank, Moshe and Shechtman, Eli and Irani, Michal and Basri, Ronen},
	journal={PAMI},
	volume={29},
	number={12},
	pages={2247--2253},
	year={2007},
}

@article{fvd,
	title={Towards accurate generative models of video: A new metric \& challenges},
	author={Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Raphael and Michalski, Marcin and Gelly, Sylvain},
	journal={arXiv preprint arXiv:1812.01717},
	year={2018}
}

@article{is,
	title={Train sparsely, generate densely: Memory-efficient unsupervised training of high-resolution temporal gan},
	author={Saito, Masaki and Saito, Shunta and Koyama, Masanori and Kobayashi, Sosuke},
	journal={ICCV},
	volume={128},
	number={10},
	pages={2586--2606},
	year={2020},
	publisher={Springer}
}

@article{song2020score,
	title={Score-based generative modeling through stochastic differential equations},
	author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
	journal={arXiv preprint arXiv:2011.13456},
	year={2020}
}

@inproceedings{sky,
	title={Learning to generate time-lapse videos using multi-stage dynamic generative adversarial networks},
	author={Xiong, Wei and Luo, Wenhan and Ma, Lin and Liu, Wei and Luo, Jiebo},
	booktitle={CVPR},
	pages={2364--2373},
	year={2018}
}

@article{taichi,
	title={First order motion model for image animation},
	author={Siarohin, Aliaksandr and Lathuili{\`e}re, St{\'e}phane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
	journal={NeurIPS},
	volume={32},
	year={2019}
}

@article{ucf,
	title={A dataset of 101 human action classes from videos in the wild},
	author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
	journal={CRCV},
	volume={2},
	number={11},
	year={2012},
	publisher={Univ. of Central Florida}
}

@article{digan,
	title={Generating videos with dynamics-aware implicit generative adversarial networks},
	author={Yu, Sihyun and Tack, Jihoon and Mo, Sangwoo and Kim, Hyunsu and Kim, Junho and Ha, Jung-Woo and Shin, Jinwoo},
	journal={arXiv preprint arXiv:2202.10571},
	year={2022}
}

@article{dvd-gan,
	title={Adversarial video generation on complex datasets},
	author={Clark, Aidan and Donahue, Jeff and Simonyan, Karen},
	journal={arXiv preprint arXiv:1907.06571},
	year={2019}
}

@article{vqvae,
	title={Neural discrete representation learning},
	author={Van Den Oord, Aaron and Vinyals, Oriol and others},
	journal={NeurIPS},
	volume={30},
	year={2017}
}

@inproceedings{vqgan,
	title={Taming {T}ransformers for high-resolution image synthesis},
	author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
	booktitle={CVPR},
	pages={12873--12883},
	year={2021}
}

@inproceedings{vqdpm,
	title={Vector quantized diffusion model for text-to-image synthesis},
	author={Gu, Shuyang and Chen, Dong and Bao, Jianmin and Wen, Fang and Zhang, Bo and Chen, Dongdong and Yuan, Lu and Guo, Baining},
	booktitle={CVPR},
	pages={10696--10706},
	year={2022}
}

@article{transformer,
	title={Attention is all you need},
	author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	journal={NeurIPS},
	volume={30},
	year={2017}
}

@inproceedings{dual-dpm,
	title={Dynamic dual-output diffusion models},
	author={Benny, Yaniv and Wolf, Lior},
	booktitle={CVPR},
	pages={11482--11491},
	year={2022}
}

@article{vdm,
	title={Video diffusion models},
	author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
	journal={arXiv preprint arXiv:2204.03458},
	year={2022}
}

@inproceedings{styleganv2,
	title={Analyzing and improving the image quality of  {S}tyle{GAN}},
	author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
	booktitle={CVPR},
	pages={8110--8119},
	year={2020}
}

@inproceedings{stylegan,
	title={A style-based generator architecture for generative adversarial networks},
	author={Karras, Tero and Laine, Samuli and Aila, Timo},
	booktitle={CVPR},
	pages={4401--4410},
	year={2019}
}

@inproceedings{stylegan-v,
	title={Style{GAN}-{V}: A continuous video generator with the price, image quality and perks of {S}tyle{GAN}2},
	author={Skorokhodov, Ivan and Tulyakov, Sergey and Elhoseiny, Mohamed},
	booktitle={CVPR},
	pages={3626--3636},
	year={2022}
}

@inproceedings{mocogan,
	title={Mocogan: Decomposing motion and content for video generation},
	author={Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan},
	booktitle={CVPR},
	pages={1526--1535},
	year={2018}
}

@article{cogvideo,
	title={CogVideo: Large-scale pretraining for text-to-video generation via {T}ransformers},
	author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
	journal={arXiv preprint arXiv:2205.15868},
	year={2022}
}

@article{cogview,
	title={Cogview: Mastering text-to-image generation via {T}ransformers},
	author={Ding, Ming and Yang, Zhuoyi and Hong, Wenyi and Zheng, Wendi and Zhou, Chang and Yin, Da and Lin, Junyang and Zou, Xu and Shao, Zhou and Yang, Hongxia and others},
	journal={NeurIPS},
	volume={34},
	pages={19822--19835},
	year={2021}
}

@article{cogview2,
	title={CogView2: Faster and better text-to-image generation via hierarchical {T}ransformers},
	author={Ding, Ming and Zheng, Wendi and Hong, Wenyi and Tang, Jie},
	journal={arXiv preprint arXiv:2204.14217},
	year={2022}
}

@article{glide,
	title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
	author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
	journal={arXiv preprint arXiv:2112.10741},
	year={2021}
}

@inproceedings{ddpm-first,
	title={Deep unsupervised learning using nonequilibrium thermodynamics},
	author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
	booktitle={ICML},
	pages={2256--2265},
	year={2015},
}

@article{ddpm,
	title={Denoising diffusion probabilistic models},
	author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
	journal={NeurIPS},
	volume={33},
	pages={6840--6851},
	year={2020}
}

@article{ddim,
	title={Denoising diffusion implicit models},
	author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
	journal={arXiv preprint arXiv:2010.02502},
	year={2020}
}

@inproceedings{ddpm-var,
	title={Improved denoising diffusion probabilistic models},
	author={Nichol, Alexander Quinn and Dhariwal, Prafulla},
	booktitle={ICML},
	pages={8162--8171},
	year={2021}
}

@inproceedings{diffusion-clip,
	title={DiffusionCLIP: Text-guided diffusion models for robust image manipulation},
	author={Kim, Gwanghyun and Kwon, Taesung and Ye, Jong Chul},
	booktitle={CVPR},
	pages={2426--2435},
	year={2022}
}

@article{mcvd,
	title={Masked conditional video diffusion for prediction, generation, and interpolation},
	author={Voleti, Vikram and Jolicoeur-Martineau, Alexia and Pal, Christopher},
	journal={arXiv preprint arXiv:2205.09853},
	year={2022}
}

@inproceedings{come-closer,
	title={Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction},
	author={Chung, Hyungjin and Sim, Byeongsu and Ye, Jong Chul},
	booktitle={CVPR},
	pages={12413--12422},
	year={2022}
}

@article{tats,
	title={Long video generation with time-agnostic vqgan and time-sensitive transformer},
	author={Ge, Songwei and Hayes, Thomas and Yang, Harry and Yin, Xi and Pang, Guan and Jacobs, David and Huang, Jia-Bin and Parikh, Devi},
	journal={arXiv preprint arXiv:2204.03638},
	year={2022}
}

@article{rvd,
	title={Diffusion probabilistic modeling for video generation},
	author={Yang, Ruihan and Srivastava, Prakhar and Mandt, Stephan},
	journal={arXiv preprint arXiv:2203.09481},
	year={2022}
}

@article{imagen,
	title={Photorealistic text-to-image diffusion models with deep language understanding},
	author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S Sara and Lopes, Rapha Gontijo and others},
	journal={arXiv preprint arXiv:2205.11487},
	year={2022}
}

@article{nvidia-long,
	title={Generating long videos of dynamic scenes},
	author={Brooks, Tim and Hellsten, Janne and Aittala, Miika and Wang, Ting-Chun and Aila, Timo and Lehtinen, Jaakko and Liu, Ming-Yu and Efros, Alexei A and Karras, Tero},
	journal={arXiv preprint arXiv:2206.03429},
	year={2022}
}

@article{fdm,
	title={Flexible diffusion modeling of long videos},
	author={Harvey, William and Naderiparizi, Saeid and Masrani, Vaden and Weilbach, Christian and Wood, Frank},
	journal={arXiv preprint arXiv:2205.11495},
	year={2022}
}

@article{classifier-free,
	title={Classifier-free diffusion guidance},
	author={Ho, Jonathan and Salimans, Tim},
	journal={arXiv preprint arXiv:2207.12598},
	year={2022}
}

@article{dalle-2,
	title={Hierarchical text-conditional image generation with clip latents},
	author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
	journal={arXiv preprint arXiv:2204.06125},
	year={2022}
}

@article{videogpt,
	title={Videogpt: Video generation using vq-vae and {T}ransformers},
	author={Yan, Wilson and Zhang, Yunzhi and Abbeel, Pieter and Srinivas, Aravind},
	journal={arXiv preprint arXiv:2104.10157},
	year={2021}
}

@inproceedings{clip,
	title={Learning transferable visual models from natural language supervision},
	author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
	booktitle={ICML},
	pages={8748--8763},
	year={2021}
}

@article{fast-dpm,
	title={On fast sampling of diffusion probabilistic models},
	author={Kong, Zhifeng and Ping, Wei},
	journal={arXiv preprint arXiv:2106.00132},
	year={2021}
}

@article{score-match,
	title={Generative modeling by estimating gradients of the data distribution},
	author={Song, Yang and Ermon, Stefano},
	journal={NeurIPS},
	volume={32},
	year={2019}
}

@article{srdiff,
	title={Srdiff: Single image super-resolution with diffusion probabilistic models},
	author={Li, Haoying and Yang, Yifan and Chang, Meng and Chen, Shiqi and Feng, Huajun and Xu, Zhihai and Li, Qi and Chen, Yueting},
	journal={Neurocomputing},
	volume={479},
	pages={47--59},
	year={2022}
}

@inproceedings{latent-dpm,
	title={High-resolution image synthesis with latent diffusion models},
	author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
	booktitle={CVPR},
	pages={10684--10695},
	year={2022}
}

@article{unit-ddpm,
	title={Unit-ddpm: Unpaired image translation with denoising diffusion probabilistic models},
	author={Sasaki, Hiroshi and Willcocks, Chris G and Breckon, Toby P},
	journal={arXiv preprint arXiv:2104.05358},
	year={2021}
}

@article{dpm-beat-gan,
	title={Diffusion models beat gans on image synthesis},
	author={Dhariwal, Prafulla and Nichol, Alexander},
	journal={NeurIPS},
	volume={34},
	pages={8780--8794},
	year={2021}
}

@article{vgan,
	title={Generating videos with scene dynamics},
	author={Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
	journal={NeurIPS},
	volume={29},
	year={2016}
}

@inproceedings{tgan,
	title={Temporal generative adversarial nets with singular value clipping},
	author={Saito, Masaki and Matsumoto, Eiichi and Saito, Shunta},
	booktitle={ICCV},
	pages={2830--2839},
	year={2017}
}

@inproceedings{liu2022compositional,
	title={Compositional visual generation with composable diffusion models},
	author={Liu, Nan and Li, Shuang and Du, Yilun and Torralba, Antonio and Tenenbaum, Joshua B},
	booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XVII},
	pages={423--439},
	year={2022},
	organization={Springer}
}

