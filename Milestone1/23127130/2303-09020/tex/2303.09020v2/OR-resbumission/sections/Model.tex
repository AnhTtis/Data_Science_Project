We consider a process of a (large) group of \emph{authors} each submitting a paper to a prestigious \emph{conference}.
\dkdeletecomment{too much detail here? Also mentioned in discussion later, I think.}{This single conference can refer to multiple ``equivalent'' conferences, e.g., ICML/NeurIPS or AAAI/IJCAI or STOC/FOCS.}
We model the submission-reviewing process as a multi-round game \dkedit{between two types of players: the conference and the authors. 
First, the conference commits to an acceptance policy, which maps vectors of reviews to a decision to accept or reject a paper.
Subsequently, }
in each round, each author decides to submit the paper either to the \dkdelete{prestigious} conference or take the outside option. 
Upon submission, the \dkdelete{prestigious} conference \dkreplace{will send the paper out for review and, based on the reviews,}{obtains reviews and applies its acceptance policy to} decide to accept or reject.
If the paper is rejected from the prestigious conference, the author sees the reviews, and faces the same decision problem in the next round. 
\dkedit{More precisely, \fangedit{given parameters $(\ACCMAP, \NumReviews, \RevSigDist, \QualDist, \AuthSigDist, \TD)$, }\fangcomment{do we introduce $\NumNewPapers$?}the game proceeds as follows:
\dkcomment{I am not sure I like Fang-Yi's edits, adding the notation. I think that the roles of the parameters are pretty clear, and the overview is supposed to contextualize the later detailed subsections. I don't think we need to be fully formal here and psecify the distributions etc.}
\begin{enumerate}
    \item The conference commits to a number $\NumReviews$ of reviews that will be solicited, and an \emph{acceptance policy} $\ACCMAP$, which maps vectors of $\NumReviews$ reviews to an outcome from $\SET{\text{accept}, \text{reject}}$.
    Acceptance policies are discussed in detail in \cref{sec:model-acc-policy}.
    \item The author's paper quality $\Qual=\qual$ is realized from a commonly known distribution $\QualDist$; assumptions on the distribution are discussed in \cref{sec:paper-qualities-signals}.
    \item The authors observes a (possibly noisy) signal $\AuthSig$ about $\qual$ \fangedit{from $\AuthSigDist$}, as detailed in \cref{sec:paper-qualities-signals}.
    \item Based on the signal, the conference's policy, and past reviews (if any), the author decides whether to submit the paper to the conference or take the outside option. The decision process is detailed in \cref{sec:author-decision}.
    \label{enum:author-decision}
    \item If the paper was submitted, the conference obtains $\NumReviews$ reviews. These reviews are signals $\RevSig{i}$ drawn i.i.d.~from a commonly known family of distributions $\RevSigDist[q]$ conditioned on the true but unknown quality $q$ of the paper.
    \item The conference applies the acceptance policy $\ACCMAP$ to the vector of reviews to determine an outcome from $\SET{\text{accept}, \text{reject}}$.
    \item If the paper was submitted and rejected, the game returns to step (\ref{enum:author-decision}). Otherwise, the game ends.
 \end{enumerate}

 If the paper is accepted to the conference after $t$ prior rounds of rejection, the author's utility is $\TD^t \cdot \ConfValue$, where $\TD$ is the commonly known author time discount factor, and $\ConfValue$ is the (endogenous) conference prestige, determined by the qualities of accepted papers. If the author takes the outside option after $t$ prior rounds of rejection, her utility is $\TD^t$. The author's utility is discussed in more detail in \cref{sec:author-decision}.

 The conference's utility/quality is 1 plus the average quality of papers, averaged over all rounds, in the limit as the number of rounds grows large. The conference utility is discussed in detail in \cref{sec:model-acc-policy}.

 In addition to the conference and authors, we are also interested in the utility/cost of the reviewers, which is simply the total number of reviews per conference/paper. The concept of review burden, as well as the tradeoffs we study between the different parties' utilities, is discussed in detail in \cref{subsec:number-reviews}. We emphasize that while we are interested in the utility of the reviewers, they have no agency in our game-theoretic formulation: only the conference and authors make decisions.
}

\dkdeletecomment{now subsumed in the overview}{We will discuss the utilities of three parties: the conference committee, reviewers, and authors. However, in the game, only two of the main agents actually make decisions: the author of each paper and the prestigious conference;  the reviewers simply provide reviews.}


\subsection{\dkedit{Paper Qualities and Signals}}
\label{sec:paper-qualities-signals}

Each paper has a quality $\Qual$ drawn i.i.d.~from a commonly known prior paper quality distribution $\QualDist$ over the set of possible qualities. The support of $\QualDist$, i.e., the set of all possible paper qualities, is denoted by $\QualSet \subseteq \mathbb{R}$, and larger qualities correspond to better papers.
% We note that the assumption that $\QualDist$ is commonly known is not essential\textemdash it only matters that the conference (e.g., PC chair) knows the distribution.
Without loss of generality, there exist both negative and positive values in $\QualSet$; otherwise, the conference would simply accept/reject all papers without review. 
When the set of qualities is discrete, we write $\QualProb{q} = \Prob{\Qual = q}$; when it is continuous, we use $\QualDens{q}$ to denote the density of $\QualDist$ at $q$.
Because all papers' qualities are drawn from the same distribution, we will not need to reference a specific paper in our notation.

The conference cannot observe the true quality of the paper, but will solicit some number, $\NumReviews$, of reviews for each submission.  
Each review $S_j$, for $j = 1, \ldots, \NumReviews$, is a random variable drawn i.i.d.~from a distribution $\RevSigDist[q]$ where $q$ is the paper's quality. 
Thus, the reviews are independent conditioned on the paper's quality.
The outcome of the $j$th review is $\RevSig{j} \in \SigSet \subseteq \R$ where $\SigSet$ is the set of possible review scores, and a higher score denotes a more positive review. We assume that $\RevSigDist[q]$ has full support on $\SigSet$ for every $q$.
We write $\RevSigV$ for the vector of the $\NumReviews$ reviews. We let $U(\RevSigV) = \ExpectC[\Qual]{\Qual}{\RevSigV, \QualDist, \RevSigDist}$ denote the expected quality of a paper conditioned on the reviews $\RevSigV$.\footnote{Note that this notation of expected quality only depends on the quality prior and the review signal, but not the author's best response and resubmission. }
% We assume that the reviews are \emph{informative} about the paper's quality, in the sense of monotone likelihood ratio: 
Some of our results rely on the following assumption on the review signal.

\begin{definition}[\citet{karlin1956theory}] \label{def:informative}
The reviewer's family of signal distributions $\RevSigDist$ satisfies the monotone likelihood ratio (MLR) property if for any $q'>q$, whenever $\REVSIGP > \REVSIG$, the following holds: $\frac{\RevSigProb[q']{\REVSIGP}}{\RevSigProb[q]{\REVSIGP}} > \frac{\RevSigProb[q']{\REVSIG}}{\RevSigProb[q]{\REVSIG}}$.
\end{definition}
% \yichicomment{Need better name than "informative". 
% "Why not impose Definition 1 as a running assumption
% instead, or simply say “assume that reviewers’ signals satisfy MLRP.” (Imposing
% MLRP is sufficiently standard that the authors should not be concerned that
% this sounds overly technical or narrow.)"}

It is well known that a wide class of commonly used distributions --- including the Gaussian, Beta, and Exponential distributions --- have monotone likelihood ratios \citep{karlin:rubin,karlin1956theory}.

For some of our results, we assume that the authors perfectly observe $\Qual$, the paper's quality. This model has the advantage of being analytically tractable, because the authors do not learn new information from the reviews. We call such authors \emph{noiseless}.
For other results, we consider \emph{noisy} authors, who themselves only assess their papers' qualities approximately.
In this case, we assume that authors have noisy signals $\AuthSig$, which, similar to the conference's signals, are drawn according to some distribution $\AuthSigDist[q]$ for a paper of quality $q$Since our theoretical results are primarily derived in the noiseless setting, we do not impose any specific assumptions on the distribution of author noise. Instead, we investigate its effect through agent-based model simulations, using noise rates estimated from real data.
The author's signal is independent of the conference's signals conditioned on $\Qual$.
Noisy authors will update their beliefs about their papers' qualities based on the reviews in a Bayesian way. 

\dkedit{
\begin{remark}
We remark that our results for noiseless authors can be generalized to other settings in which the authors obtain no new information from observing reviews when their submission is rejected.
Perhaps the most natural way to model such a setting is to assume that each review signal $S_j$ is an i.i.d.~\emph{garbling} of the author's signal $\AuthSig$; in that case, authors learn no new information from reviews.
Because neither the author nor the conference can obtain any more information about a paper's quality beyond its conditional expected quality $\ExpectC{Q}{\AuthSig}$, we can simply treat this expectation itself as the paper's quality, and redefine the prior over paper qualities as the corresponding distribution over expected qualities based on signals. That is, if $\ExpectC{Q}{\sigma_q} = q$, then we define $p'_q = \sum_{q'} \QualProb{q'} \cdot \RevSigProb[q']{\sigma_q}$. Note that under the MLR property, the quality conditioned on a signal is strictly increasing (see \cref{lem:monotone_expected_quality}), so no two signals can have the same expected quality. In particular, $\sigma_q$ is in fact unique (if a $\sigma$ exists at all for a particular $q$).
With this reduction, our results carry over directly from the setting of noiseless authors. We stick to the model of noiseless authors here to avoid unnecessarily complex notation.
\end{remark}
}

We study categorical and continuous models in this paper, as defined next. When a result does not specify one of these models explicitly, it holds for both models.

\begin{description}
\item{\textbf{Categorical Model:}}
In a categorical model, both $\QualSet \subset \R$ and $\SigSet \subset \R$ are finite (and ordered by their natural order on $\R$).
% \dkcomment{I suggest deleting the discussion of Dawid-Skene here. Seems to waste 3 lines for a model which is really not that similar.}
% Such a model bears some similarity to the Dawid-Skene model \citep{dawid1979maximum}, although the latter typically does not assume an ordering on labels and thus also no \yzdelete{informativeness} requirement akin to monotone likelihood ratio.

\item{\textbf{Continuous Model:}} 
% \dkreplace{
% \dkreplace{
% \yichicomment{$\QualSet = \Sigma = \mathbb{R}$.}
% In the continuous model, we assume that both $\QualSet \subseteq \R$ and $\SigSet \subseteq \R$ are convex sets.\fangcomment{intervals?}\yichicomment{Sets can represent intervals, no?}\fangcomment{a convex set on $\R$ should be an interval}\gscomment{need that the cdf is strictly increasing over this interval.  this is kind of implied, but should make it explicit.}}{In the continuous model, we assume that both the quality distribution $\QualDist$ and the noise have atomless full support on all of $\R$, i.e., that $\QualSet = \SigSet = \R$ and that the cumulative distribution function (cdf) of $\QualDist$ is continuous and strictly increasing.}
% Furthermore, the reviewers' signals are obtained by adding to the true quality $\Qual$ a noise term drawn from a distribution $\REVNOISEDIST$ which is \emph{independent} of $\Qual$ and has zero mean.
% \dkedit{As mentioned above, $\REVNOISEDIST$, too, is continuous and strictly increasing.}
% \dkdelete{Specifically, let $\Sigma_X\subseteq \R$ be the domain of the zero-mean noise (an open and convex set), and $\REVNOISEDIST: \Sigma_X \to (0,1)$ be a monotone increasing bijection.\fangcomment{do we really need that $\Sigma_X$ is an open set and $\REVNOISEDIST$ is a bijection?}\yichiedit{yes, we will use the inverse of it to characterize the resubmission gap.}\fangcomment{If we need bijection, $F^{(r)}$ should be strictly increasing?}}
% \dkreplace{Then}{In other words}, the cdf of the distribution of reviewer signals conditioned on a quality $\Qual=q$ is $\RevNoiseDist{x-q}$.
% Note that the zero-mean assumption is without loss of generality so long as the noise distribution is independent of the quality $\Qual$, as any (known) bias could be subtracted from the reviews.}{
In the continuous model, we assume that both the quality distribution $\QualDist$ and the noise have atomless full support on all of $\R$, and are suitably continuous.
Thus, $\QualSet = \SigSet = \R$, and we make the following specific assumptions:
\begin{itemize}
    \item The cumulative distribution function (cdf) of $\QualDist$ is continuous and strictly increasing. In other words, the probability density function (pdf) is positive and finite: $\QualDens{q} \in (0,\infty)$ for all $q\in \QualSet$.
    \item The reviewers' signals are obtained by adding to the true quality $\Qual$ a noise term drawn from a distribution $\REVNOISEDIST$ which is \emph{independent} of $\Qual$, has a strictly positive and \emph{continuous} pdf, and has zero mean.
% \fangreplace{
%     Let $\REVNOISEDIST$ denote the cdf of this noise distribution, and $f^{(r)}$ the pdf.
%     Then, we assume that $f^{(r)}(x) \in (0, \infty)$ for all $x$, that $f^{(r)}(x)$ is a continuous function of $x$, and that $\int_x x \cdot f^{(r)}(x) \, d x = 0$.
%     The cdf of the distribution of reviewer signals conditioned on a quality $\Qual=q$ is $\RevNoiseDist{x-q}$.}
Specifically, let $\REVNOISEDIST$ and  $f^{(r)}$ denote the cdf and pdf of this noise distribution, respectively.  The cdf of the distribution of reviewer signals conditioned on a quality $\Qual=q$ is $\RevNoiseDist{x-q}$.  We assume that not only $F^{(r)}$, but also $f^{(r)}$ is continuous, with $f^{(r)}(x) \in (0, \infty)$ for all $x$, and $\int_x x \cdot f^{(r)}(x) \, d x = 0$.
\end{itemize}

Note that the zero-mean assumption is without loss of generality so long as the noise distribution is independent of the quality $\Qual$, as any (known) bias could be subtracted from the reviews by the conference.

\dkcomment{Rewrote this again to add continuity assumptions. I think that those might be needed. Maybe there is some very clever way to get around it and still have continuous expected quality in signals, but I don't see it right now. If someone sees a way to avoid it, please feel free to implement. Also, please definitely check my edits here!!!}
\yzcomment{Is it possible that some of these overlap with the MLR assumption? I briefly check and it doesn't seem to be the case, but one can take another look.}
\dkcomment{I was wondering, too, but did not immediately see a way to make it happen.
Though it may be true. I think that by setting $s'-q' = s-q$, one can prove that $(f(x))^2 > f(x-\delta) f(x+\delta)$ for all $x, \delta > 0$, which looks like a weaker form of log-concavity. Not sure if it implies log-concavity by repeated application, or maybe by using different pairs. Maybe MLR implies log-concavity more generally. If so, there may be known results that log-concavity implies continuity.}
\end{description}

\subsection{Conference Acceptance Policy and Quality}
\label{sec:model-acc-policy}

The conference's main lever of control is its acceptance policy.
We primarily focus on \emph{memoryless} acceptance policies.
Under a memoryless acceptance policy, (1) the author can submit a paper an unlimited number of times; 
(2) the same number of reviews $\NumReviews$ and decision policy are used in every round; and (3) in each round $t$ in which the author (re-)submits the paper, the conference's decision depends only on the reviews obtained in round $t$. In other words, each submitted paper is treated as a fresh paper. For that reason, we typically omit the round $t$ from the notation when discussing memoryless policies. 
We discuss alternatives to memoryless policies in \cref{sec:memory_policy}, in particular, limiting the number of times a paper can be submitted, and having old reviews follow a resubmission. 
Except for these sections, unless stated otherwise, all acceptance policies are memoryless.  
We call an acceptance policy \emph{non-trivial} if it neither accepts nor rejects all submissions with quality in $\QualSet$.

A memoryless acceptance policy is characterized by a function $\ACCMAP: \SigSet^m \to [0,1]$ which determines the probability with which each combination of review signals leads to a paper's acceptance.\fangcomment{Future note: we consider non-adaptive acceptance policy.  Alternatively, if one can change the acceptance policy based on the number of submission, this adaptive policy can have more power.}

We primarily focus on \emph{monotone} acceptance policies. 
A policy is monotone if for any two vectors $\RevSigV, \RevSigVP$ of reviews, a higher expected quality of a paper
$U(\RevSigV) \geq U(\RevSigVP)$ implies that a higher acceptance probability $\AccMap{\RevSigV} \geq \AccMap{\RevSigVP}$.
A particularly natural class of monotone acceptance policies prescribes a conditional expected quality threshold.  
We largely restrict our attention to threshold policies because 1) they comprise a natural set of policies, and other policies seem unlikely to arise in practice; 2) it is both conceptually and computationally easy to search over such policies; and 3) we will see that such policies are sufficiently rich to induce any author strategy that can be induced using any monotone acceptance policy.

\begin{definition} \label{def:threshold-policy}
A \emph{threshold acceptance policy} $\ACCMAP[\tau, r]$ is characterized by a threshold $\tau \in \mathbb{R} \cup \{-\infty, +\infty\}$ and a probability $r\in [0,1]$. It accepts a paper with reviews $\RevSigV$ when 
$U(\RevSigV) > \tau$, rejects the paper when 
$U(\RevSigV) < \tau$, and accepts the paper with probability $r$ when $U(\RevSigV) = \tau$.
\end{definition}

When the distribution $\Prob[\RevSigV]{U(\RevSigV)  = \tau}$ has no point mass for any $\tau$, the third (knife-edge) case is an event of probability 0; we then omit $r$ from the notation, and simply use $\ACCMAP[\tau]$ to denote the threshold acceptance policy with threshold $\tau$; in particular, this is true in the continuous model and some generalizations.

Once an acceptance policy $\ACCMAP$ is fixed, the probability of a submitted paper being accepted in a particular round is only a function of its underlying quality $q$. We denote this probability by $\AccP{\ACCMAP}{q}$.
The following proposition shows that when $\ACCMAP$ is monotone, $\AccP{\ACCMAP}{q}$ is monotone in $q$. We defer the proof to \cref{app:proof-monotone-prob}.

\begin{proposition} \label{prop:monotone-prob}
Assume that the reviewers' signals satisfy the  MLR property.
If $\ACCMAP$ is a monotone acceptance policy, then $\AccP{\ACCMAP}{q}$ is non-decreasing in $q$. Moreover, if $\ACCMAP[\tau,r]$ is a non-trivial threshold policy, then $\AccP{\ACCMAP[\tau,r]}{q}$ is strictly increasing in $q$, for any prior $\QualDist$.
\end{proposition}  
 
In round $t$ of (re-)submission, we suppose that the conference faces a (the same) number $\NumNewPapers$ of new papers as well as the previously rejected papers from the past $t-1$ rounds. 
We define the \emph{quality} $\CONFUTIL$ of the conference as the long-run expected total quality of accepted paper.  Formally, $\CONFUTIL$ is the expectation of the total value of accepted papers' quality normalized by $\NumNewPapers$ and the number of rounds $t$ with $t\to \infty$.\fangcomment{$t$ or $T$?} \dkcomment{Not sure. I thought we use $T$ for the conference's lever, but do we do so consistently?} As is typical in Stackelberg games, we assume that the authors best-respond; if there are multiple best responses, for convenience of analysis, we assume that we can prescribe a particular tie breaking.
Note that when $t \to \infty$, the expected number of submissions in round $t$ that have previously been submitted $\ell$ times converges for any $\ell \in \mathbb{N}$.

\subsection{Author Utility and Decisions}
\label{sec:author-decision}
\dkdeletecomment{Now subsumed earlier?}{
In terms of timing, first, the conference announces its review and acceptance policy; subsequently, in each round $t$, the author decides whether to submit the paper to the conference or take the side option.
% The game ends when the paper is accepted at the conference or at the ``sure bet'' option. 
The game ends when the paper is accepted at the conference or the author takes the side option.}

Two key factors affect the author's utility: their time discount factor $\TD$, capturing how patient they are, and the prestige $\ConfValue$ they ascribe to the conference.
When the paper is accepted at the conference in round $t$, the author's utility is therefore $\yichireplace{\AUTHUTIL}{u^{(a)}} = \TD^{t-1} \cdot \ConfValue$; when the author takes the side option in round $t$, her utility is $\TD^{t-1}$, i.e., the utility of the outside option is normalized to 1.
The $\TD^{t-1}$ term encodes exponential time discounting and models that authors would like their work to be published in a timely manner.
Besides the utility loss due to time discounting, rejection does not cause additional cost for the author.

We assume that the prestige $\ConfValue$ is 1 plus the average quality of the papers accepted by the conference, which is the reward to authors whose papers are accepted by the conference.\fangcomment{Future note: I feel this definition loses the control of conference's exogenous value.  Our result should hold under $V = 1+\mu+\lambda\E[q|accepted]$.} \dkcomment{Indeed, it seems like Fang-Yi's generalization might check out, and subsume both results.}
This assumption aligns the preference for papers between authors and the conference.
The conference aims to accept only positive-quality papers, while authors are attracted to the conference over the outside option only when the average quality of accepted papers is larger than 1.\footnote{While not included here, we also have shown that the results hold when $V > 1$ is a fixed constant, e.g., the prestige of the conference is based on its past reputation, and not directly affected by current decisions or accepted papers.}
We assume that $\Set{q\in \QualSet}{q>0}\neq \emptyset$, \dkreplace{meaning}{i.e., that some papers are of positive quality. This assumption implies that $\ConfValue$ can be made larger than the outside option, when only positive value paper are submitted and accepted; otherwise, no author would ever submit to the conference.}
\yzcomment{removed an assumption.}

The author's decisions depend on all available information, i.e., her own (possibly perfect) private signal $\AuthSig$ as well as all the reviews she has received for previous submissions.
We assume that the author is rational and Bayesian, so her decisions are based on posterior quality distributions taking into account all available information. 
She will submit to the conference in round $t$ if and only if her expected utility from doing so (over all future time steps $t' \geq t$) exceeds her expected utility from the side option (which is exactly $\TD^{t-1}$ at the point she is making the decision).
Notice that unless the author obtains a perfect signal, the reviews she obtains (in addition to her own signal $\AuthSig$) change her posterior conditional probability over the paper's quality, which in turn changes her belief of the probability distribution of future reviews. 

\begin{definition}
  The model in which authors have perfect information about their papers' qualities, and papers may be resubmitted an unlimited number of times, is called the model of \emph{noiseless authors with unlimited resubmissions}.
\end{definition}

Under the model of noiseless authors with unlimited resubmissions, a theoretical analysis becomes more tractable. This is because authors' beliefs of their papers' qualities will not be updated based on the reviews. As a result, the papers that are submitted in the first round will be repeatedly resubmitted until acceptance. In turn, this implies that the quality of the conference depends entirely on the authors' self-selection. 

\subsection{Review Burden and Tradeoffs}  
\label{subsec:number-reviews}
% % As we discussed in the introduction, we are primarily interested in the tradeoff between the conference's quality and the review burden, which is captured by the number of requested reviews imposed on the community. \yichicomment{Removed a footnote here.}
% \footnote{This downplays the utility of the authors, a fact which is discussed in \cref{sec:limitations}.} 
% We call this the QB-tradeoff. 
% We denote the expected number of reviews of a paper by $\PaperReviews$, which will be called the \emph{review burden}.
As we discussed in the introduction, we are primarily interested in the utility of the conference committee, the reviewers, and the authors.
The ``utility'' of the conference committee is essentially captured by the conference quality $\CONFUTIL$ as defined in \cref{sec:model-acc-policy}.
The utility of the authors, captured by the author welfare, $\AUTHUTIL$, is the sum of all authors' utilities conditioned on acceptance to the prestigious conference, and is denoted by $\AUTHUTIL$.\fangcomment{Future note.  Why don't we define the author welfare as the sum of all author's utility, but only those getting accepted to the prestigious one?}\yzcomment{I don't feel strongly about the difference. Maybe a note for future.}
We use the \emph{review burden} $\PaperReviews$ as a measure of the reviewers' utility, which is the expected number of reviews assigned to a random paper.
% \gscomment{I don't understand why author's welfare is conditioned on submitting.  Do we mean that their paper is yet to be accepted?  That might be a clearer way to state it.}\yzcomment{changed to conditioned on acceptance.}
To be precise, the conference's policy, along with an author's best response, determines a probability distribution $\NumSubmitDist$,
where $\NumSubmitProb{t} = \Prob{\text{The paper is submitted at least $t$ times}}$.
Then, $\PaperReviews = \NumReviews \cdot \sum_{t = 1}^{\infty}  \NumSubmitProb{t}$ is the expected number of reviews incurred by a submission.
In the limit as the number of rounds
% \gscomment{please double check this edit.}\yzcomment{I don't think this makes sense. What we require is a large number of rounds of resubmissions so that the accepted papers in this round contain resubmitted papers from many rounds ago, and the quality of accepted papers converges}\fangcomment{Are we using the number of review incurred by a submission or the number of review required in each round?  The former does not require $t\to \infty$.}\yzcomment{I think we want to claim these are the same if $t\to \infty$}\fangcomment{We define"$\PaperReviews$ as a measure of the reviewers' utility, which is the expected number of reviews assigned to a random paper."  Why do we the later?}\gscomment{looks okay now with Fang-Yi's edit.} 
becomes large, the reviewing load is spread out evenly over rounds. Therefore, with $\NumNewPapers$ new submissions in each round, the review burden on the community is $\NumNewPapers \PaperReviews$.

We focus on the tradeoffs between pairs of stakeholders, and in particular, we find the tradeoffs between conference quality and review burden, as well as between conference quality and author welfare, to be the most interesting. Intuitively, the tradeoff between review burden and author welfare is trivially dominated by the simple policy of accepting every paper without review.
Starting with the tradeoff between conference quality and review burden (QB-tradeoff), we say that a policy $\ACCMAP$ with $\CONFUTIL$ and $\PaperReviews$ \emph{weakly QB dominates} 
% \gscomment{seems like $\CONFUTIL \PaperReviews$ or $CR$ dominates would be a better term.  
% Also, this seems like a bit of a bandaid because we are too lazy to factor in author utility, which nearly always aligns with the above two.} 
another policy $\hat{\ACCMAP}$ with $\CONFUTILH$ and $\PaperReviewsH$ if (1) it has a higher (or equal) expected conference utility, $\CONFUTIL \geq \CONFUTILH$, and (2) the number of reviews is smaller (or equal), $\PaperReviews \leq \PaperReviewsH$.  
We say that a policy $\ACCMAP$ \emph{QB dominates} another policy $\hat{\ACCMAP}$ if it weakly QB dominates, and at least one of the inequalities is strict.
Given a set of policies, a policy is \emph{QB Pareto optimal} if it is not strictly QB dominated by any other policy in the set.
If policy $\ACCMAP$ and policy $\hat{\ACCMAP}$ do not induce unique conference qualities and review burdens (because they allow different best responses by the author), we say that $\ACCMAP$ (weakly) QB dominates $\hat{\ACCMAP}$ if every pair $(\CONFUTILH,\PaperReviewsH)$ induced by $\hat{\ACCMAP}$ is (weakly) dominated by a pair $(\CONFUTIL,\PaperReviews)$ induced by $\ACCMAP$.

We say that the QB-tradeoff in one setting \emph{weakly dominates} another if for any point (corresponding to a policy $\hat{\ACCMAP}$) of the second QB-tradeoff, there exists a point (corresponding to a policy $\ACCMAP$) in the first setting that weakly dominates it.

Typically, instead of optimizing over all memoryless acceptance policies, we will restrict our attention to memoryless threshold acceptance policies.  In such a case, we can look at the \emph{QB-tradeoff curve}, which maps out each point of the QB-tradeoff as the acceptance policy threshold $\tau$ increases from $-\infty$ to $+\infty$, and for $\tau$ where $\Prob[\RevSigV]{U(\RevSigV)  = \tau} > 0$, $r$ increases from 0 to 1.  

We say that one QB-tradeoff curve $\mathcal{C}$ \emph{(weakly) dominates} another QB-tradeoff curve $\hat{\mathcal{C}}$ if for any point on $\hat{\mathcal{C}}$ that does not correspond to accepting all papers or rejecting all papers, there exists a point on $\mathcal{C}$ which (weakly) dominates it.
Note that this implies that no point on the Pareto frontier of the QB-tradeoff curve $\mathcal{C}$ is dominated by any of the points on the QB-tradeoff curve $\hat{\mathcal{C}}$.  

The definition of the tradeoff between conference quality and author welfare (QA-tradeoff) is analogous --- replacing review burden with author welfare in all relevant concepts --- while noting that higher author welfare is preferred, just as lower review burden is preferred. We then use \emph{QA dominance} to refer to the relationship between two policies when considering conference quality and author welfare. When the context is clear, we omit the QA or QB qualifiers.