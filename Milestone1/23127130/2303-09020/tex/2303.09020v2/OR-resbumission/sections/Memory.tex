Most conferences' acceptance policies are memoryless, in the sense that resubmissions are treated the same as new submissions.
However, in part to deal with the large number of papers that are repeatedly resubmitted, several conferences have experimented with models that have ``institutional memory.''  We consider the following types of policies which are not memoryless and contain some institutional memory.

\begin{description}
\item[Time Limited, Fixed Threshold:] The simplest way to incorporate memory into the submission process is to limit the number of times the same paper can be submitted.
We call such a policy a \emph{$T$-round fixed-threshold policy.} 
% \fangcomment{It seems we already use $T$ for the number of runs  }\yzcomment{changed to $N$}

\item[Time Limited, Variable Threshold:] A generalization of $T$-round fixed threshold policies is to allow different acceptance thresholds for different rounds. This allows a conference to set higher/lower standards for resubmissions.
However, we require the conference to solicit the same number of reviews for each round. 
We do so for two reasons. First, this reduces the policy space\textemdash this is significant in terms of computation when optimizing over policies with memory. Second, it excludes highly unrealistic policies with very specific dependency on model parameters. For example, when authors are noiseless, the following unrealistic policy can achieve maximum conference quality with minimum review burden: the conference rejects all submissions $T-1$ times without review. In round $T$, one review is solicited, and the paper is accepted if and only if the expected quality conditioned on the review is larger than $\tau$; finally, in round $T+1$, the submission is accepted without review. A careful choice of $T$ and $\tau$, taking advantage of authors' patience (or lack thereof) and knowledge of their own paper's quality, ensures that no negative-quality papers are submitted, yet all positive-quality papers are submitted and eventually accepted.
% \yichicomment{This footnote is quite long. Is there a better solution? Make it an endnote?} \dkcomment{I think it actually works pretty well as the bulk of this paragraph.}

Formally, a \emph{round-dependent threshold policy} is defined by a threshold vector $\boldsymbol{\tau}=\left(\tau^{(1)},\tau^{(2)}, \ldots, \tau^{(T)}\right)$; in round $t \leq T$,  a paper with reviews $\RevSigV$ is accepted if and only if its expected quality conditioned on the most recent review vector $\RevSigV$ (not including reviews from earlier rounds) is at least $\tau^{(t)}$.


\item[Review Following:]
Under a \emph{$T$-round review-following threshold memory policy}, not only does the conference track the number of resubmissions; it also considers all past reviews as equal (additional) reviews of resubmissions. That is, reviews are treated identically regardless of which round they were provided in.
% \footnote{As such, they do not serve the purpose of verifying whether authors addressed concerns about previous versions of their paper.}
(As such, they do not serve the purpose of verifying whether authors addressed concerns about previous versions of their paper.)
Again, we have the conference obtain the same number of reviews in each round of resubmissions, i.e., $\NumReviews[t]=\NumReviews$ for all $t$.
The conference commits to a number $T$ of rounds and rejects any paper that has been submitted $T$ times. The conference also commits to a sequence of thresholds $\boldsymbol{\tau}=\left( \tau^{(1)}, \tau^{(2)}, \ldots, \tau^{(T)}\right)$, such that in round $t$, a paper with historical reviews $\left(\RevSigV[1], \ldots, \RevSigV[t]\right)$ is accepted if and only if its expected quality conditioned on $\left(\RevSigV[1], \ldots, \RevSigV[t]\right)$, $U(\RevSigV[1], \ldots, \RevSigV[t])$, is at least $\tau^{(t)}$.
\end{description}

All three policy types are time-limited, in that the number of times any particular paper can be submitted is capped.  This is similar to  certain National Science Foundation programs (e.g., CAREER), where the number of times a proposal (or sometimes author) can submit is limited. 
Time-limited policies with fixed threshold treat all submissions, whether initial or resubmitted, equally in each round, until they have reached their resubmission limit. In this section, we analytically investigate such review policies with a focus on how the limit on the number of resubmissions affects the QB-tradeoff. 
In contrast, the other two types of policies allow different thresholds in different rounds. In particular, the review-following model captures the increasingly popular policy of requiring resubmissions to be accompanied by previous reviews (e.g., at IJCAI).
These two generalizations are more complicated to analyze, and we use ABMs to investigate their QB-tradeoff.

Perhaps subtly, review-following policies do not fully subsume the other two policies, because past reviews cannot be treated differently from new reviews. For example, review-following policies cannot simulate a time-limited fixed threshold policy in which every round, a paper obtains two reviews and is accepted iff both reviews are positive. The reason is that a review-following policy cannot distinguish the case of having one positive review in each round (which should lead to rejection) from the case of having zero positive reviews in the first round and two positive reviews in the second round (which should lead to acceptance).

\subsection{Time-limited Policy With Fixed Acceptance Rule}
\label{sec:time_limited_policy}

We start by investigating policies under which in each round, the conference applies a fixed monotone acceptance rule. 
% We first show that when a conference merely restricts the number of times a paper can be submitted (to some value $T$), noiseless authors will respond exactly as if the conference allowed unlimited resubmissions. Next, based on this property, we show how $T$ affects the QB-tradeoff.
As for the case of unlimited resubmissions, we first establish theoretical results for noiseless authors, and then test their robustness to noise in the authors' signals with ABM experiments.

\subsubsection{Theoretical Results for Noiseless Authors}

We begin with a theoretical analysis for noiseless authors.
We first show that under this type of acceptance policy, a threshold strategy is still a best response for noiseless authors, i.e., there exists a de facto threshold $\theta$ for every monotone acceptance policy $\ACCMAP$. 

We begin by generalizing \cref{lem:author_response} to time-limited policies.

\begin{lemma}\label{lem:best-response-finite}
Consider a conference which allows a paper to be submitted at most $T$ times, and for each of these submissions independently decides whether to accept the paper, according to the same monotone policy $\ACCMAP$.
Suppose that the conference value $\ConfValue$ is fixed, and accordingly $\rho$ is fixed.
Then, the author's best response is to (re)submit the paper (in each round) if $\AccP{\ACCMAP}{\Qual} > 1/\rho$, and take the side option when $\AccP{\ACCMAP}{\Qual} < 1/\rho$.
The author is indifferent between submitting and not submitting if $\AccP{\ACCMAP}{\Qual} = 1/\rho$.
\end{lemma}

\proof{Proof of \cref{lem:best-response-finite}}
  The author will submit a paper with quality $\Qual = q$ if her expected utility is greater than 1, and not submit it if her expected utility is less than 1.
  We compute the expected utility for an author who submits the paper exactly $T$ times, akin to the proof of \cref{lem:author_response}:

\begin{align*}
    u^{(a)}(q,\ACCMAP, \ConfValue) & = 
    (\TD \cdot (1-\AccP{\ACCMAP}{q}))^T 
    + \ConfValue \cdot \sum_{t=1}^T \AccP{\ACCMAP}{q} \cdot  
    (\TD \cdot (1-\AccP{\ACCMAP}{q}))^{t-1}
    \\ & = 
    (\TD \cdot (1-\AccP{\ACCMAP}{q}))^T
    + \ConfValue \cdot \AccP{\ACCMAP}{q} \cdot 
    \frac{1 - (\TD \cdot (1-\AccP{\ACCMAP}{q}))^T}{1 - \TD \cdot (1-\AccP{\ACCMAP}{q})}
    \\ & = 
    \left(\frac{\ConfValue \cdot \AccP{\ACCMAP}{q}}{1 - \TD \cdot (1-\AccP{\ACCMAP}{q})} - 1 \right)
    \cdot \left( 1 - (\TD \cdot (1-\AccP{\ACCMAP}{q}))^T \right) + 1.
\end{align*}
To determine when this utility is strictly larger resp.~strictly smaller than 1, we need to determine when the product of the first two terms is positive resp.~negative. The second factor is always positive, and the first has the same sign as $\AccP{\ACCMAP}{q} - 1/\rho$, regardless of $T$.
This completes the proof. \Halmos
\endproof

\cref{lem:best-response-finite} shows that when the conference value is fixed, an authorâ€™s decision depends solely on the relationship between the acceptance probability $\AccP{\ACCMAP}{q}$ and the inverse of the conference attractiveness factor $1/\rho$, and is independent of the time limit $T$.
However, the attractiveness factor $\rho$ is itself determined by the authors' submission strategy as well as the conference acceptance policy and the time horizon $T$.

Consider a threshold strategy under which authors with quality $\Qual > \bar{q}$ submit and continue to resubmit up to $T$ times, those with $\Qual < \bar{q}$ immediately opt for the outside option, and those with $\Qual = \bar{q}$ submit and resubmit with probability $r$. We will show that, for a fixed conference policy $\ACCMAP$ and time horizon $T$, the attractiveness factor $\rho$ increases with the threshold $\bar{q}$. Consequently, $1/\rho$ decreases with $\bar{q}$, while the marginal acceptance probability $\AccP{\ACCMAP}{\bar{q}}$ increases with $\bar{q}$.
Building on this monotonicity, the results of \cref{prop:de_facto} will then extend naturally to the finite-$T$ setting using the same proof structure.

In order to prove monotonicity, we first introduce the following notation. 
If an author persistently submits a paper of quality $\qual$, the probability that it is eventually accepted under the acceptance policy $\ACCMAP$ is given by:
\begin{align*}
A(\qual, T, \ACCMAP) 
& = \sum_{t=0}^{T-1} (1-\AccP{\ACCMAP}{\qual})^t \cdot \AccP{\ACCMAP}{\qual}
= 1-(1-\AccP{\ACCMAP}{\qual})^T.
\end{align*}

As a result, $\lim_{T \to \infty} A(\qual, T, \ACCMAP) = 1$, corresponding to the fact that when an author resubmits a paper until acceptance, it will eventually be accepted.

The conference value under the threshold strategy \ACCMAP can be characterized as:
\begin{align*}
    \ConfValue(\bar{q}, r, T, \ACCMAP) 
    & = 1 + \frac{r\cdot \bar{q} \cdot \QualProb{\bar{q}} \cdot A(\bar{q}, T, \ACCMAP) 
    + \sum_{q \in \QualSet, q > \bar{q}} q \cdot \QualProb{q} \cdot A(q, T, \ACCMAP)}{r\cdot \QualProb{\bar{q}} \cdot A(\bar{q}, T, \ACCMAP) 
    + \sum_{q \in \QualSet, q > \bar{q}} \QualProb{q} \cdot A(q, T, \ACCMAP)} \tag{categorical model}\\
    \ConfValue(\bar{q}, T, \ACCMAP) 
    & = 1 + \frac{\int_{\bar{q}}^\infty q \cdot \QualProb{q} \cdot A(q, T, \ACCMAP) dq}{\int_{\bar{q}}^\infty \QualProb{q} \cdot A(q, T, \ACCMAP) dq}. \tag{continuous model}
\end{align*}

Fixing the acceptance policy $\ACCMAP$ and the time limit $T$, we see that the conference value is increasing in the submission threshold $\bar{q}$ and decreasing in the marginal submission probability $r$. Consequently, the conference attractiveness factor $\rho(\bar{q}, r, T, \ACCMAP)$ is also increasing in $\bar{q}$ and decreasing in $r$.

This implies that \cref{prop:de_facto} continues to hold for time-limited acceptance policies with a fixed acceptance rule.
The only difference is that in the characterization result, the conference's attractiveness $\rho$ now depends not only on the acceptance policy $\ACCMAP$, but also on $T$.
% \dkcomment{I found the preceding sentence very confusing. Either it holds, or it doesn't? I hope that I rephrased it correctly, i.e., that you only wanted to express the dependence on more parameters, not that the proof doesn't actually work after all.}
Furthermore, for threshold acceptance policies with threshold $\tau$ under the continuous model, the result from \cref{prop:gap-invariant} can also be directly generalized. 
That is, given a candidate threshold $\theta$, the acceptance threshold that induces it as a de facto threshold is the solution to the following equation:\fangcomment{need to fix $\tau_s$?}
\begin{align*}
  \tau 
  & = \theta + \left(\REVNOISEDIST\right)^{-1}{\left(1-\frac{1}{\rho(\theta, T, \ACCMAP[\tau])}\right)} 
  = \theta + \left(\REVNOISEDIST\right)^{-1}{\left(\frac{\ConfValue(\theta, T, \ACCMAP[\tau]) - 1}{\ConfValue(\theta, T, \ACCMAP[\tau]) - \TD}\right)},
\end{align*}
where $\ACCMAP[\tau]$ is the threshold acceptance policy with threshold $\tau$. This equation allows us to solve for either $\theta$ or $\tau$ given the other.


% \begin{proposition}\label{prop:best-response-finite}
% Consider a conference which allows a paper to be submitted at most $T$ times, and for each of these submissions independently decides whether to accept the paper, according to the same monotone policy \ACCMAP.

% Then, the author's best response is to submit the paper (in each round) if $\AccP{\ACCMAP}{\Qual} > 1/\rho$, and take the side option when $\AccP{\ACCMAP}{\Qual} < 1/\rho$.
% \end{proposition}

% Notice that while the author's expected \emph{utility} depends on $T$, her best \emph{response} does not. Hence, as with an unlimited number of submissions, an author will either submit as often as she is allowed to or not even submit once, and the author's threshold for doing so is the same as with an unlimited number of resubmissions. 

% The property we proved in \cref{prop:best-response-finite} allows us to characterize the expected value of the conference quality and the review burden.
We further characterize the expected value of the conference quality and the review burden.
For a given acceptance threshold $\tau$, let $\mathcal{S}_{\tau} \subseteq \QualSet$ be the set of paper qualities which an author will submit at this threshold.
When $\QualSet$ is discrete,
% \footnote{For continuous qualities, the corresponding quantities are obtained by replacing sums by integrals and probabilities by densities.}
the expected conference quality and review burden are as follows:
\begin{align*}
    \CONFUTIL(\tau) 
    & = \sum_{q\in \mathcal{S}_{\tau}} \QualProb{q} \cdot q \cdot 
    {\sum_{t=0}^{T-1} (1-\AccP{\tau}{q})^{t}\AccP{\tau}{q}}
%\\ & = 
\; = \; \sum_{q \in \mathcal{S}_{\tau}} 
    \QualProb{q} \cdot q \cdot A(q,T, \ACCMAP[\tau]).
    \end{align*}
\dkreplace{Note that $(1-\AccP{\tau}{q})^T$ is the probability of a paper with quality $q$ being rejected for all $T$ rounds; t}{T}hus, the expected conference quality is the expected value of papers in $\mathcal{S}_\tau$, weighted by the acceptance probabilities. For continuous qualities, the corresponding quantities are obtained by replacing sums by integrals and probabilities by densities.

To compute the review burden, recall that the expectation of a non-negative random variable $Z$ is $\Expect{Z} = \int_{0}^\infty \Prob{Z > z}\,dz$. For a paper of quality $q$, the number of submissions exceeds $z \geq 0$ with probability $(1-\AccP{\tau}{q})^{\lfloor z \rfloor}$ for $z < T$, and 0 otherwise. Therefore, the expected review burden is
\begin{align*}
    \PaperReviews(\tau) & = \NumReviews \cdot \sum_{q\in \mathcal{S}_{\tau}} \QualProb{q} \cdot 
    {\sum_{t=0}^{T-1} (1-\AccP{\tau}{q})^{t}}
    \; = \; \NumReviews \cdot \sum_{q\in \mathcal{S}_{\tau}} \QualProb{q} \cdot \frac{1}{\AccP{\tau}{q}} 
    \cdot A(q,T, \ACCMAP[\tau]).
\end{align*}

\subsubsection{ABM experiments for noisy authors}
We next test the robustness of our theoretical results by performing ABM experiments for authors who only receive noisy signals.

\cref{fig:tradeoff_T} (a) shows the QB-tradeoff for time-limited fixed-threshold policies in the continuous model. As expected, by lowering $T$, the conference reduces the maximum conference quality that can be reached by the review policy, but doing so can also reduce the review burden in cases where the desired conference quality is still reachable. 

% \begin{figure}[htb]
%      \centering
%      \begin{subfigure}[b]{0.6\textwidth}
%          \centering
%          \includegraphics[width=\textwidth]{Plots/Finite_round_memoryless_continuous.png}
%          \captionsetup{size=}
%      \end{subfigure}
%      \hfill
%      \caption{The Pareto optimal curves of the QB-tradeoff under $T$-round fixed threshold policies in the \emph{$\boldsymbol{(\sigma=0.5, \mu_{\QualDist} = 0, \sigma_{\QualDist} = 1, \NumReviews = 1, \ConfValue = 3, \TD = .7)}$-Double Gaussian noiseless-author model}. Pareto dominated points are shown as dashed lines, while undominated points are shown as solid lines.  \label{fig:tradeoff_continuous}}
% \end{figure}

\begin{figure}
     \FIGURE
     {\begin{subfigure}[b]{0.47\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Plots/QB_tradeoffs_continuous_T.pdf}
         \captionsetup{size=}
         \caption{Continuous model with noiseless authors.}
     \end{subfigure}
     \begin{subfigure}[b]{0.46\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Plots/QB_tradeoff_noisy_L6_vary_T.pdf}
         \captionsetup{size=}
         \caption{Categorical model with noisy authors.}
     \end{subfigure}}
     {The QB-tradeoff Curves under $\boldsymbol{T}$-round Fixed Threshold Policies in the (a) Continuous Model and (b) Categorical Model. \label{fig:tradeoff_T}}
     {The example is in (a) the \emph{$(\sigma=0.5, \mu_{\QualDist} = -1, \sigma_{\QualDist} = 2, \NumReviews = 1, \TD = 0.7)$-Double Gaussian noiseless-author model} and (b) the \emph{$(\lambda_A=1, \lambda_R=1, \NumReviews = 3,\TD=0.7)$-ICLR$^{2020, 6}$  model. \dkcomment{Left one does not say ``Number of rounds'' before the explanation of colors. Same in the next figure.}}
     % \fangcomment{Can I say if $T\to \infty$, the figure would match Figure EC.1(b) with $m=3$ }\yzcomment{Yes}
     % \dkcomment{Notice that the axis labels are different in both font size and whether the mathematical name of the axis is included (as well as whether we say ``Number of rounds'' in the legend). Make this consistent? Also maybe check other figures to be consistent across all figures in the paper?}
     }
\end{figure}

% \begin{figure}[htb]
%      \FIGURE
%      {\includegraphics[width=0.65\textwidth]{Plots/QB_tradeoffs_continuous_T.pdf}}
%      {The QB-tradeoff Curves under $\boldsymbol{T}$-round Fixed Threshold Policies in the Continuous Model. \label{fig:tradeoff_continuous}}
%      {The example is in the \emph{$(\sigma=0.5, \mu_{\QualDist} = -1, \sigma_{\QualDist} = 2, \NumReviews = 1, \TD = 0.7)$-Double Gaussian noiseless-author model}. Pareto-dominated points are shown as dashed lines, while undominated points are shown as solid lines.}
% \end{figure}

The ABM QB-tradeoff curves for the categorical model and noisy authors are presented in \cref{fig:tradeoff_T}(b). The same pattern can also be observed here: by comparing different colors of dots while fixing a threshold policy (captured by the index of the dot on its corresponding curve), we observe that the conference can reduce the review burden at the expense of quality by lowering $T$.
% \cref{fig:tradeoff_finite} shows results analogous to \cref{fig:tradeoff_continuous}, but in the categorical model, and further varying the number of solicited reviews and the acceptance threshold (to accept different categories of paper qualities).
% The same pattern can also be observed here: by comparing different colors of dots while fixing an $m$ (fixing a line), we observe that the conference can reduce the review burden at the expense of quality by lowering $T$.

% Additionally, when $T$ is small, a large number of reviews per submission contributes more to the conference quality. This can be seen by fixing a color and a shape of marker and looking at the dots on different types of the lines: solid lines ({one review}) result in the lowest conference quality when $T$ is small. The intuition is that when $\NumReviews$ is small, the conference has to apply a very strict acceptance threshold to discourage low-quality papers from being submitted. As a result, such a policy will need a large number of rounds to accept the good papers. 
% We conclude that if the conference severely limits the number of times a paper can be submitted, soliciting more reviews per paper will contribute more to a higher conference quality at the expense of additional reviews.

% \begin{figure}[htb]
%      \centering
%      \begin{subfigure}[b]{0.6\textwidth}
%          \centering
%          \includegraphics[width=\textwidth]{Plots/Finite_round_memoryless.png}
%      \end{subfigure}
%      \hfill
%      \caption{The Pareto optimal points of the quality-burden tradeoff under $T$-round fixed threshold policies in the \emph{$\boldsymbol{(\lambda_R=1, \NumReviews, \ConfValue=5, \TD=0.7)}$-ICLR$\boldsymbol{^{2020, 4}}$ noiseless-author model}. 
%      The colors of the markers distinguish $T$, and the shapes of the markers denote the accepted papers' qualities with $\boldsymbol{\Qual_1 < \Qual_2 < 0 < \Qual_3 < \Qual_4}$. 
%      Furthermore, we vary the number $\boldsymbol{\NumReviews}$ of reviews per paper, shown by the line type. \label{fig:tradeoff_finite}}
% \end{figure}

% \begin{figure}
%      \FIGURE
%      {\includegraphics[width=0.55\textwidth]{Plots/QB_tradeoff_noisy_L6_vary_T.pdf}}
%      {The Pareto Optimal Points of the QB-tradeoff under $\boldsymbol{T}$-round Fixed Threshold Policies in the Categorical Model with Noisy Authors\label{fig:tradeoff_finite}}
%      {The examples is in the \emph{$(\lambda_A=1, \lambda_R=1, \NumReviews = 3,\TD=0.7)$-ICLR$^{2020, 6}$  model}.}
% \end{figure}

\begin{figure}
     \FIGURE
     {\begin{subfigure}[b]{0.47\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Plots/QA_tradeoffs_continuous_T.pdf}
         \captionsetup{size=}
         \caption{Continuous model with noiseless authors.}
     \end{subfigure}
     \begin{subfigure}[b]{0.46\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Plots/QA_tradeoff_noisy_L6_vary_T.pdf}
         \captionsetup{size=}
         \caption{Categorical model with noisy authors.}
     \end{subfigure}}
     {The QA-tradeoff Curves under $\boldsymbol{T}$-round Fixed Threshold Policies in the (a) Continuous Model and (b) Categorical Model. \label{fig:QA_tradeoff_T}}
     {The example is in (a) the \emph{$(\sigma=0.5, \mu_{\QualDist} = -1, \sigma_{\QualDist} = 2, \NumReviews = 1, \TD = 0.7)$-Double Gaussian noiseless-author model} and (b) the \emph{$(\lambda_A=1, \lambda_R=1, \NumReviews = 3,\TD=0.7)$-ICLR$^{2020, 6}$  model}. \dkcomment{(b) does not have $U^{(c)}$ in the $y$-axis label. (a) is missing ``Number of rounds'' in description of colors.}}
\end{figure}

We present the analogous results for the QA-tradeoff curves in \cref{fig:QA_tradeoff_T}. Interestingly, varying $T$ does not reduce author welfare along the Pareto frontiers. While a smaller $T$ limits the number of resubmission opportunities --- potentially lowering the chance of acceptance --- it also enables the conference to adopt a more lenient acceptance threshold to maintain quality. This increases the acceptance probability in each individual round. 
That said, we also observe that smaller values of $T$ result in a lower maximum achievable conference quality.

\subsection{More Fine-Grained Institutional Memory, and Noisy Authors}
\label{sec:memory_noisy}

Next, we investigate the extent to which more fine-grained institutional memory --- different acceptance thresholds in different rounds and reuse of past reviews of a paper --- may further improve the QB-tradeoff for the conference.
We do so in the setting of noisy authors, and therefore --- as before --- use 
ABM experiments. 

\subsubsection{Agent-based Model Setup}

We use a simplified binary model to study review policies with more fine-grained institutional memory: in this model, both the paper quality and the review signal are binary.
This simplification is necessary: when authors know that the acceptance of their paper will depend on all historical reviews, their decisions (even under myopic strategies introduced in \cref{subsec:noisy_setup}), too, will depend on all historical reviews. 
This makes the simulations extremely computationally expensive for a large number of authors, especially for papers that have been rejected many times.
Considering a binary model greatly simplifies the decision-making process, allowing us to compute not only the myopic responses but also the optimal responses from authors.

The \emph{$(\AUTHSIGPROB, \REVSIGPROB, \NumReviews, \TD, T)$-binary model} is a categorical model in which there are two paper qualities $\{-1, +1\}$ and two review signals.  One paper quality is referred to as negative (``bad papers''), and the other as positive (``good papers''). The prior is such that each paper is equally likely to be bad or good. Authors receive the correct signal about their papers with probability $\AUTHSIGPROB$ and otherwise receive the opposite signal. Similarly, each reviewer receives the correct signal about their assigned paper with probability $\REVSIGPROB$ and otherwise receives the opposite signal. The parameters $\NumReviews$, $\TD$, and $T$ are the number of solicited reviews, the discount factor, and the number of times a paper can be submitted, respectively. 

As before, we incorporate the endogenous value of the conference by starting with a suitable $\ConfValue$, and iteratively updating it based on the value of the previous conference.
More specifically, we initialize the conference value $\ConfValue_1 = 2$ in the first round and iteratively update $\ConfValue_t = (1-\lambda_V) \cdot \ConfValue_{t-1} + \lambda_V \cdot \left(1+2 \cdot \ExpectC{Q_i}{\text{paper } i \text{ was accepted in round } t}\right)$, where $\lambda_V = 0.5$. The choice of multiplying by a factor of 2 is so that if all good papers are accepted, the conference value is larger than the initial value $\ConfValue_1$; alternatively, we could define the model as having paper qualities $\QualSet = \SET{-2,2}$ instead of $\SET{-1,1}$.

The \emph{optimal strategy} assumes that the authors are best-responding to the conference's policy. That is, given that the game lasts for $T$ rounds, the author uses backward induction with dynamic programming to optimize the decision. Specifically, she first reasons about the expected utility in round $T$ given all possible histories of reviews; she then similarly updates the reviews-utility mapping in rounds $T-1$, $T-2$, and so on. Eventually, she can infer the optimal action in the current round. 
% We set $T=10$ in our experiments due to running time concerns.

Our approach involves searching over policies with $T$ submissions per paper. Unfortunately, the number of such policies grows exponentially in $T$. We therefore restrict our experiments to $T = 5$, and set $\NumReviews = 3$ for the binary model.
% Computing the optimal strategy for authors in categorical or continuous models requires solving a dynamic program with a much larger state space; the resulting computational requirements prevent us from including such experiments.

We generate candidate policies by searching over different thresholds.
For $T$-round fixed-threshold policies, we select the $40$ candidate thresholds  $\tau \in \{-1, -0.95,\ldots, 0.95\}$; in each run, one of these thresholds is used for all rounds. 
For the other two types of policies, to reduce the number of samples, we only enumerate over the thresholds $\tau^{(t)}$ for the first three rounds while fixing $\tau^{(t)}$ for $t = 4, 5$. 
More precisely, we select $40^3$ candidate threshold vectors $\boldsymbol{\tau}$, as follows:
for each $t \in \{1, 2, 3\}$, we select $40$ thresholds $\tau^{(t)}$ from $\{-1, -0.95,\ldots, 0.95\}$ which gives us $40^3$ vectors of length $3$. 
For each $t=4, 5$, we fix $\tau^{(t)}$ such that the paper is accepted if and only if two of the three newly sampled reviews in round $t$ are positive. 

\subsubsection{Results}\label{sec:memory_noisy_result}

\Cref{fig:memory_policies} shows the Pareto optimal points of the QB-tradeoff for each of the three review policies. 
We summarize the main takeaways as follows:
\begin{itemize}
    \item Compared with time-limited fixed-threshold policies, round-dependent threshold policies (the variable-threshold policy and the review-following policy) tend to have dominating QB-tradeoffs. Our results suggest that having historical reviews follow submissions can help improve the QB-tradeoff. However, all review policies can achieve similar maximum conference quality (the review-following policy has a slightly higher maximum quality, while the improvement is rather marginal). The main advantage of the review-following policy seems to be a reduction in the review burden instead of improving the conference quality.
    \item We further observe that for both variable-threshold policies and review-following policies, with round-dependent thresholds, the Pareto optimal thresholds that lead to large conference qualities tend to have the following pattern: review papers strictly in the first two rounds and more leniently after that.
\end{itemize}

% \begin{figure}[htb]
%      \centering
%      \begin{subfigure}[b]{0.5\textwidth}
%          \centering
%          \includegraphics[width=\textwidth]{Plots/Review_following_m_3.png}
%          \captionsetup{size=}
%      \end{subfigure}
%      \hfill
%      \caption{The Pareto optimal points of the quality-burden tradeoff for three types of policy when authors are noisy in the \emph{$\boldsymbol{(\alpha = 0.75, \beta=0.75, m=3, V = 5, \TD=0.5, T=5)}$-binary model. The Pareto optimal points of the memoryless policy are also shown for comparison; the memoryless policy is approximated by setting a large $\boldsymbol{T=50}$.}\label{fig:memory_policies}}
% \end{figure}

\begin{figure}
     \FIGURE
     {\includegraphics[width=0.65\textwidth]{Plots/memory_policy_ABM.pdf}}
     {The Pareto Optimal Points of the QB-tradeoff With Noisy Authors in the Binary Model. \label{fig:memory_policies}}
     {The example is in the \emph{$(\alpha = 0.75, \beta=0.75, m=3, \TD=0.7, T=5)$-binary model}. }
\end{figure}

We provide some intuition for both results. Papers that are still being submitted after multiple rejections tend to be high-quality papers whose authors received strong positive signals. Variable-threshold policies can help reduce the review burden because the conference can induce a desired self-selection (where only the good papers are submitted) while relaxing the acceptance thresholds for papers that are resubmitted for a large number of rounds. This implies that variable-threshold policies can accept good papers within fewer rounds, which reduces the review burden.
Furthermore, in order to induce a desired self-selection, the conference should be strict for the first few rounds; this will cause more authors of low-quality papers to refrain from submitting. This leads to the pattern that the Pareto optimal threshold sequence tends to be strict at the beginning and more lenient later on.

\begin{remark}[Discussions and limitations of the binary model]
    We note that due to computational concerns, our conclusion here is largely based on the ABM experiments in the simplest binary model. Given that there seems to be general resistance to the idea of review-following (perhaps for fear that a bad, but erroneous, review may bring bias to the following reviews and doom a paper's chances for a long time), even if these modest gains generalize, this idea is unlikely to be a game changer.
\end{remark}

