\section{Conclusion}
We present a novel approach for EG3D inversion that achieves high-quality reconstructions with view consistency and can be run in close to real time on modern GPUs. 
We also show that directly utilizing tri-plane representation better estimates 3D structure compared to other approaches while preserving identity in the novel view.
Although our method achieves compelling results and is on par with optimization-based approaches, %
both visually and quantitatively, it has certain limitations.
For instance, it is limited by the range of yaw angles shown to EG3D during training and cannot model the background depth.
In addition, there is room for improvement of the temporal consistency and for supporting input images with extreme head poses.