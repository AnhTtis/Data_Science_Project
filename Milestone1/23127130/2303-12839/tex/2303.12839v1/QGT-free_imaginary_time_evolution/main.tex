% ****** Start of file apssamp.tex ******
%
%   This file is part of the APS files in the REVTeX 4.2 distribution.
%   Version 4.2a of REVTeX, December 2014
%
%   Copyright (c) 2014 The American Physical Society.
%
%   See the REVTeX 4 README file for restrictions and more information.
%

\documentclass[
 reprint,
 amsmath,amssymb,
 aps,
 % onecolumn,
 superscriptaddress
]{revtex4-2}

\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{braket}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[normalem]{ulem}

\newcommand{\bbra}[1]{\langle\!\langle#1|}
\newcommand{\kket}[1]{|#1\rangle\!\rangle}
\newcommand{\bbraket}[1]{\langle\!\langle #1 \rangle\!\rangle}
\newcommand{\argmin}[1]{\underset{#1}{\mathrm{argmin}}}
\newcommand{\argmax}[1]{\underset{#1}{\mathrm{argmax}}}
\newcommand{\tr}{\mathrm{Tr}}

\newcommand{\julien}[1]{{\color{blue} #1}}
\newcommand{\rr}[1]{{\color{cyan} #1}}
\newcommand{\rrc}[1]{{\color{cyan} \it [[#1]]}}
\newcommand{\rrs}[2]{{\color{cyan} \sout{#1}{#2}}}

\bibliographystyle{apsrev4-2}
\begin{document}

\preprint{APS/123-QED}

\title{Variational Quantum Time Evolution without the Quantum Geometric Tensor}

\author{Julien Gacon}
\affiliation{%
    IBM Quantum, IBM Research Europe – Zurich, CH-8803 Rüschlikon, Switzerland
}
\affiliation{%
    Institute of Physics, École Polytechnique Fédérale de Lausanne (EPFL), CH-1015 Lausanne, Switzerland
}
\author{Jannes Nys}
\affiliation{%
    Institute of Physics, École Polytechnique Fédérale de Lausanne (EPFL), CH-1015 Lausanne, Switzerland
}
\author{Riccardo Rossi}
\affiliation{%
    Sorbonne Universit\'e, CNRS, Laboratoire de Physique Th\'eorique de la Mati\`ere Condens\'ee, LPTMC, F-75005 Paris, France
}
\author{Stefan Woerner}
\affiliation{%
    IBM Quantum, IBM Research Europe – Zurich, CH-8803 Rüschlikon, Switzerland
}
\author{Giuseppe Carleo}
\affiliation{%
    Institute of Physics, École Polytechnique Fédérale de Lausanne (EPFL), CH-1015 Lausanne, Switzerland
}

\date{March 22, 2023}

\begin{abstract}
The real- and imaginary-time evolution of quantum states are powerful tools in physics and chemistry to investigate quantum dynamics, prepare ground states or calculate thermodynamic observables.
They also find applications in wider fields such as quantum machine learning or optimization.
On near-term devices, variational quantum time evolution is a promising candidate for these tasks, as the required circuit model can be tailored to trade off available device capabilities and approximation accuracy.
However, even if the circuits can be reliably executed, variational quantum time evolution algorithms quickly become infeasible for relevant system sizes. They require the calculation of the Quantum Geometric Tensor and its complexity scales quadratically with the number of parameters in the circuit.
In this work, we propose a solution to this scaling problem by leveraging a dual formulation that circumvents the explicit evaluation of the Quantum Geometric Tensor.
We demonstrate our algorithm for the time evolution of the Heisenberg Hamiltonian and show that it accurately reproduces the system dynamics at a fraction of the cost of standard variational quantum time evolution algorithms. As an application, we calculate thermodynamic observables with the QMETTS algorithm.
\end{abstract}

%\keywords{Suggested keywords}%Use showkeys class option if keyword
                              %display desired
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Quantum time evolution is a central task in physics. Real-time evolution provides detailed insight into properties of quantum mechanical systems, such as phase transitions~\cite{zhang_transitions_2017, dborin_gs_and_transitions_2022, ebadi_256atoms_2021} or thermalization~\cite{altman_thermalization_2018, dejong_thermalization_2022}.
Imaginary-time evolution is an important tool that enables the preparation of ground states or thermal states \cite{mcardle_variational_2019, motta_determining_2020}. These can, in turn, be used for the calculation of thermodynamic observables \cite{motta_determining_2020, getelina_qmetts_2023}. In particular, combining real- and imaginary-time evolution would allow the direct calculation of dynamical correlation functions at thermal equilibrium.

The range of applications of imaginary-time evolution extends beyond the field of physics.
Ground-state preparation with imaginary-time evolution for gapped, non-degenerate Hamiltonians is guaranteed to converge in the generic case of non-zero overlap between the ground state and the initial trial state. This makes it a promising candidate in settings where a good initial state can be constructed, e.g.\ in chemistry applications~\cite{barkoutsos_electronic_2018} or in classical optimization problems~\cite{zoufal_blackbox_2023}. 
In quantum machine learning, the preparation of Gibbs states with imaginary-time evolution is a subroutine for quantum Boltzmann machines, which can, for example, be used in distribution learning or classification~\cite{zoufal_variational_2021}.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{img/runtime.pdf}
    \caption{Estimated runtimes for variational imaginary-time evolution (VarQITE) and our proposed dual method (DualQITE) in dependence of the number of parameters $d$ of the variational model for 200 timesteps.}
    \label{fig:varqte_scaling}
\end{figure}

Since performing quantum time evolution generally requires representing the exponentially large wave function of a quantum system, quantum computers are a promising platform for developing efficient algorithms~\cite{miessen_dynamics_2023}. 
In fact, in 1996, the Trotter algorithm for real-time evolution was among the first proposed use cases for a quantum computer~\cite{lloyd_universal_1996}. 
However, the complexity of the quantum circuits required for the Trotter algorithm depends on the Hamiltonian, and the circuit depth scales with the simulation time and accuracy. This renders the algorithm currently unsuitable for general time evolution on near-term devices, which are characterized by limited qubit connectivity and coherence times. The imaginary-time counterpart of Trotter suffers from the same restriction~\cite{motta_determining_2020}.

Variational algorithms for quantum time evolution, on the other hand, allow to choose a parameterized circuit as an ansatz to approximate the wave function, that operates within the device's capabilities.
% Variational algorithms for quantum time evolution, on the other hand, allow to choose a circuit as parameterized ansatz that operates within the device capabilities.
Using a variational principle, variational quantum time evolution (VarQTE) maps the quantum state evolution to the evolution of parameters in the model \cite{yuan_varqte_2019}, both for \emph{real}-time evolution (VarQRTE) and \emph{imaginary}-time evolution (VarQITE).
The parameter update rules depend on the evaluation of the Quantum Geometric Tensor (QGT) and gradients of the current energy and state. For an ansatz with $d$ variational parameters, the number of circuits required to evaluate the QGT and gradients scale as $\mathcal{O}(d^2)$ and $\mathcal{O}(d)$, respectively. 
While this does not pose a problem for small systems, the evaluation of the QGT quickly becomes a bottleneck once the system size, and therefore the number of variational parameters, increases.

Figure~\ref{fig:varqte_scaling} shows a runtime estimation for VarQITE, assuming processor specifications of the \texttt{ibmq\_montreal} device~\cite{ibm_quantum} (see Appendix~\ref{app:runtime_estimates} for more details on the derivation). 
For a few tens of parameters the runtime is of the order of minutes, but the computation time for only 100 parameters is already around 24 hours, which renders this algorithm currently impractical.
With recent advances in processor sizes exceeding 100 qubits, such as the IBM Quantum Eagle or Osprey devices~\cite{eagle, osprey}, improving the resource requirements of quantum algorithms becomes crucial for finding practically relevant applications of quantum computers.

For real-time evolution, the projected variational quantum dynamics (p-VQD) algorithm~\cite{barison_pvqd_2021} provides a scalable alternative to VarQRTE if a single Trotter step can be efficiently implemented.
However, the required quantum circuit gates in p-VQD reflect the couplings of the Hamiltonian. This means that, for Hamiltonians with long-distance interactions or numerous Pauli terms (e.g. in molecular dynamics), even a single step could involve global connections or deep circuits hindering the execution on near-term devices.
Furthermore, the p-VQD algorithm is not directly applicable to imaginary-time evolution.

In this paper, we propose a novel variational algorithm for quantum time evolution that replaces the need of the QGT by solving a \emph{dual} optimization problem. This formulation applies to both real- and imaginary-time evolution, but we mainly focus on the former, as there is currently no optimization-based, scalable alternative available for it. We show that this new algorithm requires significantly fewer measurements and thereby drastically reduces the expected runtime compared to VarQTE. This is summarized in Fig.~\ref{fig:varqte_scaling}, where, under the same assumptions, our proposed method can reduce the expected runtimes from several weeks for VarQTE to only a few days. Following the naming conventions of VarQTE, we name the algorithm DualQTE with specifiers DualQITE for imaginary-time evolution and DualQRTE for real-time evolution.

The remainder of this paper is structured as follows.
In Sec.~\ref{sec:theory}, we recap VarQTE based on variational principles, derive the proposed dual formulation, and discuss how to implement it on a quantum computer. Then, in Sec.~\ref{sec:imaginary}, we demonstrate our proposed algorithm for the imaginary-time evolution of the Heisenberg model and investigate the resource requirements. As a practical application, we use the quantum minimally entangled typical thermal states method (QMETTS) to calculate thermodynamic observables. 
Sec.~\ref{sec:real} demonstrates the dual formulation for real-time evolution, including the calculation of variational error bounds.
Finally, Sec.~\ref{sec:conclusion} concludes the paper and gives an outlook on possible applications and further research directions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dual formulation of variational time evolution}
\label{sec:theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For a time-independent Hamiltonian $H$ acting on $n$ qubits, an initial quantum state $\ket{\Psi_0}$ and an evolution time $t$, the real-time evolved quantum state is
\begin{equation}
    \ket{\Psi(t)} = e^{-it H}\ket{\Psi_0}.
\end{equation}
% For an imaginary-time evolution of time $it$, the final state additionally has to be normalized, as the time evolution operator is not unitary,
For an imaginary-time evolution, the time evolution operator is non-unitary, and the normalized  state reads
\begin{equation}
    \ket{\Psi(t)} = \frac{1}{\sqrt{\braket{\Psi_0 | e^{-2tH} | \Psi_0}}} e^{-tH}\ket{\Psi_0}.
\end{equation}

Variational quantum time evolution maps the evolution of the quantum state $\ket{\Psi(t)}$ to the evolution of parameters $\theta(t) \in \mathbb{R}^d$ of a parameterized quantum state 
$\ket{\phi(\theta(t))}$. The parameters' dynamics can be derived with variational principles such as the Dirac-Frenkel, McLachlan, or time-dependent variational principle \cite{yuan_varqte_2019}.
In McLachlan's formulation, the derivatives of the parameters are determined by the linear system of equations
\begin{equation}\label{eq:lse}
    g(\theta(t))\,\dot{\theta}(t) = b(\theta(t)),
\end{equation}
where the matrix $g = \mathrm{Re}(G) \in \mathbb{R}^{d\times d}$ is the real part of the QGT, and we call $b \in \mathbb{R}^d$ the evolution gradient. 

The QGT is defined as
\begin{equation}\label{eq:qgt}
    G_{ij}(\theta) = \braket{\partial_i \phi(\theta)|\partial_j \phi(\theta)} - \braket{\partial_i \phi(\theta)|\phi(\theta)}\braket{\phi(\theta)|\partial_j \phi(\theta)},
\end{equation}
where we use the notation $\partial_i := \partial/(\partial \theta_i)$ and do not explicitly state the time dependence of the parameters.
The evolution gradient for VarQRTE is given by the expression
\begin{equation}\label{eq:b_real}
    b^\text{R}_i(\theta) = \mathrm{Im}\big(\braket{\partial_i\phi(\theta)|H|\phi(\theta)} -\braket{\partial_i\phi(\theta)|\phi(\theta)} E(\theta) \big), 
\end{equation}
whereas a VarQITE evolution yields the following 
\begin{equation}\label{eq:b_imag}
    b^\text{I}_i(\theta) = -\mathrm{Re}\big(\braket{\partial_i\phi(\theta)|H|\phi(\theta)}\big) = -\frac{\partial_i E(\theta)}{2},
\end{equation}
with the energy $E(\theta) = \braket{\phi(\theta)|H|\phi(\theta)}$. 
From hereon, we present general equations that apply to both real and imaginary-time evolution; thus, unless specified, we simply use $b$ without a specific superscript.

Note that these equations are introduced for a time-independent Hamiltonian, but they can also be applied to the time-dependent case $H = H(t)$.

\subsection{Dual formulation}

Instead of solving the linear system defined in Eq.~\eqref{eq:lse}, we propose to solve the dual formulation of the problem given by
\begin{equation}\label{eq:argmin_qgt}
   \dot\theta = \argmin{\dot\theta} \frac{\dot\theta^T g(\theta) \dot\theta}{2} - \dot\theta^T b(\theta).
\end{equation}
The term $\|\dot\theta\|^2_{g(\theta)} = \dot\theta^T g(\theta) \dot\theta$ is the squared norm of the parameter derivative in the metric of the QGT.
This quantity describes the magnitude of the derivative from an information geometric point of view and is derived from the Fubini-Study metric~\cite{stokes_qng_2020}.
For infinitesimal displacements $\delta\theta$, we have 
\begin{equation}\label{eq:qgt_approximation}
    \begin{aligned}
        ||\delta\theta||^2_{g(\theta)} &= \delta\theta^T g(\theta) \delta\theta \\
                                       &= 1 - |\braket{\phi(\theta)|\phi(\theta + \delta\theta)}|^2 + \mathcal{O}(\|\delta\theta\|_2^3),
    \end{aligned}
\end{equation}
where $\|\cdot\|_2$ is the $\ell_2$ norm.
By writing $\dot\theta = \delta\theta / \delta\tau$, for some time perturbation $\delta\tau > 0$, we can now reformulate the optimization in terms of the fidelity $F(\theta_1, \theta_2) = |\braket{\phi(\theta_1)|\phi(\theta_2)}|^2$ as
\begin{equation}\label{eq:argmin_dual}
    \begin{aligned}
   \delta\theta 
   &\approx \argmin{\delta\theta} \frac{1 - F(\theta, \theta+\delta\theta)}{2(\delta\tau)^2} - \frac{b^T\delta\theta}{\delta\tau} \\
   &= \argmin{\delta\theta} \frac{\mathcal{L}(\delta\theta)}{(\delta\tau)^2},
   \end{aligned}
\end{equation}
where we introduced the loss function 
\begin{equation}\label{eq:dual_cost}
\mathcal{L}(\delta\theta) = \frac{1 - F(\theta, \theta+\delta\theta)}{2} - \delta\tau \cdot b^T\delta\theta.
\end{equation}
In practice, the optimization problem can be solved without the factor $(\delta\tau)^{-2}$, which decouples the shape of the locally quadratic infidelity term from the time perturbation and improves the numerical stability of the optimization.

Note that this dual formulation can alternatively be obtained from the derivation of quantum natural gradients, which is detailed in Appendix~\ref{app:qng_derivation}. 
For an intuitive understanding of the relationship of the infidelity and QGT, Appendix~\ref{app:illustrative_example} demonstrates the effect of approximating $||\delta\theta||_{g(\theta)} \approx 1 - F(\theta, \theta + \delta\theta)$ in an illustrative example.

Instead of computing the QGT at each timestep, which requires $\mathcal{O}(d^2)$ circuit evaluations, we now have to solve an optimization problem where the loss function requires only one fidelity evaluation. 
The required resources of DualQTE per timestep are therefore $\mathcal{O}(d)$ for the computation of the evolution gradient $b$, times the number of iterations in the optimization. 
Thus, we improve upon the direct QGT approach if the number of iterations scales better than $\mathcal{O}(d)$, which, as we show in the following sections, is the case for the examples we investigate in this work.

\subsection{Evaluating the loss function}

The evaluation of the loss function $\mathcal{L}$, defined in Eq.~\eqref{eq:dual_cost}, requires the calculation of the evolution gradient $b$ and the fidelity of the ansatz $\ket{\phi(\theta)}$ for two different parameter sets. 
For imaginary-time evolution, the evolution gradient can, for example, be evaluated with analytic gradient rules, such as the parameter-shift rule or a linear combination of unitaries (LCU), or with finite difference methods~\cite{schuld_gradients_2019}.
In the case of real-time evolution, however, we are restricted to an LCU approach, as this is the only method that allows the calculation of the imaginary part of gradients~\cite{zoufal_variational_2021}. 

The fidelity $F$ can be estimated using the swap test~\cite{buhrman_swaptest_2001} and its variants~\cite{cincio_learning_2018}, where the states are prepared in separate qubit registers followed by entangling gates across these registers.
A more near-term-friendly option is the compute-uncompute method~\cite{havlicek_supervised_2019}, which does not introduce additional global operations.
If the states are given by $\ket{\phi(\theta)} = U(\theta)\ket{0}$, for a parameterized unitary $U$, the fidelity can be calculated by preparing $U^\dagger(\theta_1) U(\theta_2)\ket{0}$ and measuring the probability of obtaining $\ket{0}$ on all qubits. 
If the state $\ket{\phi(\theta)}$ has $n$ qubits and the preparing unitary $U$ has depth $m$, the swap test variants require a circuit width of 
$2n$ with depth of $m + \mathcal{O}(1)$, whereas the evaluated circuits for the compute-uncompute method are of only width $n$, but of depth $2m$.
To avoid doubling either circuit width or circuit depth, the overlap can also be estimated via randomized measurements of two independent state preparations~\cite{elben_overlap_2019}. However, this technique requires an exponential number of measurements.
Compared to VarQTE, the increased circuit complexity is one of the drawbacks of our methods.
In practice, a suitable parameterized quantum state $\ket{\phi(\theta)}$ must be selected, such that the circuits for the fidelity calculation can be executed reliably.

Depending on the topology and coherence times of the available hardware and the structure and size of the unitary, either method for gradient and fidelity calculations can be advantageous.
In this work, we focus on near-term friendly methods and use the parameter-shift rule for gradients (if possible) and the compute-uncompute method for the fidelity, as these do not require additional gate connections or an exponential number of measurements.

\subsection{Solving for the update step}

The infidelity-based loss function $\mathcal{L}$ is locally convex around $\delta\theta = 0$, as its Hessian at this point is $\nabla\nabla^T \mathcal{L}(0) = g/2$, and $g$ is positive semi-definite. To leverage this property, we use gradient descent as a local optimization routine, which also allows the use of analytic gradient formulas that have proven more stable in presence of shot noise.
The gradient of $\mathcal{L}$ with respect to the parameter update $\delta\theta$ is 
\begin{equation*}
    \nabla_{\delta\theta} \mathcal{L}(\delta\theta) = -\frac{\nabla_{\delta\theta} F(\theta, \theta + \delta\theta)}{2} - \delta\tau \cdot b.
\end{equation*}
The gradient of the fidelity can be evaluated with a parameter-shift rule
\begin{equation*}
    \frac{\partial F}{\partial (\delta\theta)_i} = \frac{F(\theta, \theta + \delta\theta + e_i s) - F(\theta, \theta + \delta\theta - e_i s)}{2\sin(s)},
\end{equation*}
where $e_i$ is the $i$-th unit vector and $s$ is the parameter shift, which can be chosen as, e.g., $\pi/2$ for single-qubit Pauli rotations \cite{schuld_gradients_2019}.

At each timestep, the gradient descent update for the update step $\delta\theta$ is
\begin{equation*}
    \delta\theta^{(k+1)} = \delta\theta^{(k)} - \eta_k \nabla \mathcal{L}\left(\delta\theta^{(k)}\right),
\end{equation*}
where $\eta_k > 0$ is the learning rate at step $k$.
This iteration is continued until a maximum number of iterations or a convergence criterion is met. An example of the latter is a minimum tolerance in the change of the cost function or the norm of the gradient.

An intuitive choice for the initial guess $\delta\theta^{(0)}$ is the zero vector, which corresponds to no change in the parameters. However, a more efficient choice can be to introduce momentum by warm starting the optimization with the update step from the previous timestep. This heuristic is motivated by the idea that, especially for small timesteps, we do not expect the parameter derivatives $\dot\theta$ to change significantly. 

Methods that approximate the gradient, such as finite difference or SPSA~\cite{spall_spsa_1998}, may face challenges in the optimization.
For small timesteps, the fidelity is close to $1$ and the noise in the readout, e.g. from finite sampling statistics or device noise, can easily mask changes in the cost function. Parameter-shift gradients suffer less from this problem, as they allow to evaluate the cost function over larger perturbations, and do not amplify the noise by dividing by a small constant.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Imaginary-time evolution}
\label{sec:imaginary}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}[htp]
    \centering
    \includegraphics[width=0.49\linewidth]{img/heisen/12q_heisen.pdf}
    \includegraphics[width=0.49\linewidth]{img/heisen/12q_resources.pdf}
    \caption{
    (a) The mean and standard deviation of DualQITE and VarQITE, each averaged over 5 independent experiments for a varying number of shots. 
    (b) The accuracy measured in integrated Bures distance $I_B$ (see Eq.~\eqref{eq:integrated_bures}) for DualQITE and VarQITE, with mean and standard deviation of 5 experiments. The resources are measured in total number of measurements and are shown for evaluation of gradients (and the QGT, in the case of VarQITE) using parameter-shift rules (dashed) or a LCU approach (solid lines).
    }
    \label{fig:heisen}
\end{figure*}

In this section, we show the results of DualQITE and investigate the circuit costs compared to VarQITE.
As an application, we use our algorithm as a subroutine to prepare typical thermal states of the Heisenberg model, which are then used to calculate the energy per site as a thermodynamic observable.
All circuits are constructed and simulated using Qiskit~\cite{qiskit}.

\subsection{Heisenberg model}

We simulate the imaginary-time evolution of the Heisenberg model with nearest-neighbor interaction on a 12-qubit circle in  a transverse field:
\begin{equation}\label{eq:heisencomb}
    H = J \sum_{\braket{ij}} \left( X_i X_j + Y_i Y_j + Z_i Z_j \right) + g \sum_i Z_i,
\end{equation}
with interaction strength $J=1/4$ and transversal field strength $g=-1$.
As a variational ansatz, we use a circuit with Pauli-$Y$ and Pauli-$Z$ single qubit rotation layers that alternate with pairwise CNOT entangling gates. The circuit structure is 
shown in Appendix~\ref{app:su2_circuit}. The initial state for the evolution is the equal superposition of all qubits, $\ket{+}^{\otimes n}$,
which we prepare by setting the rotation angles of the last Pauli-$Y$ layer to $\pi/2$ and the remaining angles to $0$.

The optimization problems in DualQITE are solved using gradient descent with a fixed learning rate of $\eta=0.1$ and time perturbation $\delta\tau = 0.01$. The initial iteration performs $100$ update steps and the subsequent, warmstarted iterations, only $10$. These values are motivated by the simulations shown in Appendix~\ref{app:warmstarting} and are partially heuristic, as a termination criterion is challenging to define with access only to noisy loss function and gradient evaluations. 
The parameters are integrated with an explicit Euler scheme with timestep $\Delta_t = 0.01$, i.e.
\begin{equation*}
    \theta(t + \Delta_t) = \theta(t) + \Delta_t\dot\theta(t) = \theta(t) + \Delta_t\frac{\delta\theta}{\delta\tau}.
\end{equation*}
Note that the integration timestep $\Delta_t$, which determines the accuracy of the time integration, can be chosen differently from the time perturbation $\delta\tau$, which affects the approximation error of the QGT metric with the infidelity.

We compare the performance to VarQITE with the same integration scheme and use an L-curve regularization~\cite{cultrera_lcurve_2020} 
for a stable solution of the linear system. Among all regularization techniques we attempted, such as adding a diagonal shift,
truncating small or negative singular values or solving on a stable subsystem, the L-curve regularization provided the most accurate and stable results.

In Fig.~\ref{fig:heisen}(a), we present the results for a varying number of shots along with the exact time evolution based
on matrix exponentiation. Already with as little as $100$ measurements per circuit evaluation (shots) on the $12$-qubit model, the dual time evolution is able 
to qualitatively follow the imaginary-time evolution and, up to time $t \approx 1$, even outperform VarQITE with $1024$ shots.
Increasing the number of measurements of DualQITE to $1024$ shots allows the dual method to closely track the exact solution towards the ground state, with a higher accuracy than VarQITE with $8192$ shots. 

\subsection{Resource requirements}

In the above experiment, DualQITE requires fewer circuit evaluations to achieve the same accuracy as VarQITE. To investigate the total resource requirements, 
we perform both DualQITE and VarQITE with different resources and compute the achieved error, calculated as the average integrated Bures distance to the exact solution over the time evolution,
\begin{equation}\label{eq:integrated_bures}
    I_B(T) = \frac{1}{T}\int_0^T D_B(t) \mathrm{d}t,
\end{equation}
with the Bures distance at time $t$
\begin{equation*}
    D_B(t) = \sqrt{2\left(1 - \left|\braket{\phi(\theta(t))|\Psi(t)}\right|\right)}.
\end{equation*}
The state fidelity is computed exactly, i.e., we compute the state vector of the model $\ket{\phi}$ at variational parameters $\theta(t)$, 
and take the inner product with the exact time-evolved state $\ket{\Psi(t)}$. 

The results for an integration time of $T=2$ are shown in Fig.~\ref{fig:heisen}(b). We show the integrated Bures distance with respect to the total number of measurements recorded during the time evolution.
In DualQITE, the resources can be split between using more optimization steps in each timestep or more shots to evaluate the gradients. The algorithm settings are detailed in Appendix~\ref{app:dual_resources}. Figure~\ref{fig:heisen}(b) shows the resource counts for gradient calculations via the parameter-shift rule and linear combination of unitaries.
We see that, on average, the dual algorithm requires about one order of magnitude fewer measurements to achieve the same accuracy as VarQITE. 
With an increasing number of parameters, we expect this difference to grow, since VarQITE scales as $\mathcal{O}(d^2)$ whereas our algorithm, with warm starting, only computes small corrections at each time step.

\subsection{Calculating thermodynamic observables}

As an application of imaginary-time evolution, we calculate thermodynamic observables using the quantum minimally entangled thermal states algorithm (QMETTS) \cite{stoudenmire_minimally_2010,motta_determining_2020}.
For an observable $A$ and inverse temperature $\beta$, the QMETTS algorithm generates samples $\{A_m\}_m$ using a Markov chain whose average approximate the 
ensemble average:
\begin{equation*}
    \braket{A}_\text{ens} = \frac{\tr(e^{-\beta H} A)}{\tr(e^{-\beta H})} \approx \frac{1}{M} \sum_{m=1}^{M} A_m.
\end{equation*}
The sampling process to obtain the sample $A_m$ is
\begin{enumerate}
    \item Start from a product state $\ket{\phi_m(t=0)}$.
    \item Evolve up to imaginary time $t = \beta/2$
    \begin{equation*}
        \ket{\phi_m(\beta/2)} \propto e^{-\beta H/2 }\ket{\phi_m(0)}.
    \end{equation*}
    \item Evaluate the observable to obtain the sample
    \begin{equation*}
        A_m = \braket{\phi_m(\beta/2) | A |\phi_m(\beta/2)}.
    \end{equation*}
    \item Measure $\ket{\phi_m(\beta/2)}$ in some basis to obtain
    the next random product state $\ket{\phi_{m+1}(0)}$.
\end{enumerate}

We investigate the Heisenberg model from Eq.~\eqref{eq:heisencomb} on a chain with $n=6$ spins
with parameters $J=1/4$ and $g=-1$. As a thermodynamic observable we 
compute the energy per site, $\braket{H}/n$.
To reduce the auto-correlation length in the QMETTS Markov chain, and for 
faster convergence to the ensemble average, it is favorable to measure in 
different bases in each step. 
Since the Heisenberg Hamiltonian conserves the number of qubits in the $\ket{1}$ state, avoiding the $Z$ basis greatly reduces the standard deviation of the Markov chain. Thus,
we here alternate between the $X$ and $Y$ basis for each sample. 

As ansatz for DualQITE, we use problem-inspired
circuits with pairwise CNOT couplings and $r=2$ repetitions of rotation and entanglement layers, plus a final rotation layer, see Appendix~\ref{app:su2_circuit} for a circuit diagram.
For evolutions of product states $\ket{\pm}$ in the $X$ basis, the rotation layers are single qubit $R_\mathrm{Y} R_\mathrm{Z}$ gates, and for the states
$\ket{\pm i}$ in the $Y$ basis, the layers implement $R_\mathrm{X} R_\mathrm{Z}$ gates.
The initial product states $\ket{\phi_m(0)}$ are prepared by setting the parameters in the final layer rotation layer of the ansatz as follows,
\begin{equation*}
    \begin{aligned}
        \ket{\pm} &\rightarrow R_\mathrm{Y}\left(\frac{\pm \pi}{2}\right) R_\mathrm{Z}(0), \\
        \ket{+i} & \rightarrow R_\mathrm{X}\left(\frac{\pi}{2}\right) R_\mathrm{Z}(\pi), \\
        \ket{-i} & \rightarrow R_\mathrm{X}\left(\frac{\pi}{2}\right) R_\mathrm{Z}(0).
    \end{aligned}
\end{equation*}
Each energy sample is evaluated with $1024$ measurements per basis.
The optimization problem in DualQITE is solved with a time perturbation $\delta\tau=0.01$ and gradient descent with a learning rate of $\eta=0.1$ and $100$ iterations in the first timestep, followed by $10$ iterations in the following, warmstarted timesteps.
We integrate with a fixed timestep of $\Delta_t = 0.01$.

\begin{figure}[htp]
    \centering
    \includegraphics[width=\linewidth]{img/qmetts/qmetts.pdf}
    \caption{Energy per site for the Heisenberg model on a 6-spin chain, comparing mean and standard deviation of  QMETTS with DualQITE (blue circle and errorbars) with a reference METTS implementation (black line and grey shade).}
    \label{fig:energy_per_site}
\end{figure}

Figure~\ref{fig:energy_per_site} shows the estimated energy per site, along with the standard deviation of the samples, for different inverse temperatures $\beta$. For the alternating $X-Y$ basis, the Markov chain converges quickly and $M=25$ samples suffice for an accurate estimate of the observable.
For the imaginary-time evolution, we compare DualQITE with the same settings as in the previous sections to an exact evolution performed with matrix exponentials. It shows that using the dual method allows to reliably reproduce the mean and standard deviation of the Markov chain samples compared to the exact reference METTS.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Real-time evolution}
\label{sec:real}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The focus of this paper is on imaginary-time evolution as, to date, no other QGT-free time evolution algorithms exist in this setting.
For real-time evolution, p-VQD has a similar structure as our algorithm and solves an optimization problem rather than evaluating the QGT.
However, there are key differences to the dual algorithm applied to real-time evolution.

The p-VQD algorithm \cite{barison_pvqd_2021} projects a single Suzuki-Trotter step onto the circuit model by solving the following optimization problem:
\begin{equation*}
    \theta(t + \Delta_t) = \argmax{\theta'} \big|\braket{\phi(\theta') | e^{-iH\Delta_t} | \phi(\theta(t))}\big|^2.
\end{equation*}
For Hamiltonians with many Pauli terms or long-range interactions, such as those arising in molecular dynamics, the single step might already lead to large circuits with non-local gates. 
In DualQRTE this does not pose a problem as we do not rely on the implementation of a Suzuki-Trotter step.
Furthermore, our dual time evolution allows the evaluation of error bounds at almost no additional cost, which is not possible in p-VQD.
Due to these differences, this section presents DualQRTE: the dual time evolution for real-time evolution.

\subsection{Heisenberg model}

We present the real-time evolution under the Heisenberg Hamiltonian of Eq.~\eqref{eq:heisencomb} on a linear chain with $n=4$ spins with parameters $J=1/4,\; g=-1$. 
As variational model, we use a circuit with alternating Pauli-$X$ and Pauli-$Y$ rotation layers, and Pauli-$ZZ$ entangling gates that reflect the connectivity of the spins.
The circuit structure is visualized in Appendix~\ref{app:real_heisen} and, in this experiment, all algorithms use $r=3$ repetitions of the rotation as well as entangling gates. To prepare the initial state, $\ket{+}^{\otimes 4}$, we set the parameters of the final Pauli-$Y$ rotations to $\pi/2$ and the rest to 0.

During the evolution, we track the average magnetization in the $X$ and $Z$ direction,
\begin{equation*}
    \braket{X} = \frac{1}{n} \sum_{i=1}^n X_i, ~~
    \braket{Z} = \frac{1}{n} \sum_{i=1}^n Z_i.
\end{equation*} 
Since this Heisenberg Hamiltonian preserves the qubit excitations, and the initial state is the equal superposition, the $\braket{Z}$ expectation value should remain $0$ throughout the evolution. 

The results of the different time evolution algorithms for an integration time of $T=2$ and timestep $\Delta_t = T/100$ are presented in Fig.~\ref{fig:magnetization}.
Both DualQRTE and p-VQD accurately track the observables using only 200 shots per circuit. With the same resources, VarQRTE, on the other hand, has lower accuracy and we need to use 1024 shots per circuit to match the result of the optimization-based algorithms.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/real/real_4q_heisen.pdf}
    \caption{Average magnetization in $X$ and $Z$ direction as tracked by different variational algorithms.}
    \label{fig:magnetization}
\end{figure}

\subsection{Error bounds}

In variational real-time evolution, the error due to restriction to the variational manifold can be expressed as~\cite{zoufal_errorbounds_2021}
\begin{equation}
    \begin{aligned}
        \dot\varepsilon &:= \big|\big| H\ket{\phi(\theta)} - \nabla_\theta \ket{\phi(\theta)}\big|\big|_2^2 \\
                          &= \mathrm{Var}(H | \phi(\theta)) + \dot\theta^T g(\theta) \dot\theta - 2 b^T(\theta) \dot\theta.
    \end{aligned}
\end{equation}
Up to the variance $\mathrm{Var}(H | \phi(\theta)) = \braket{\phi(\theta)|H^2|\phi(\theta)} - (\braket{\phi(\theta)|H|\phi(\theta)})^2$ , this error is proportional to the loss function used in DualQRTE. By using the same 
expansion $\dot\theta = \delta\theta / \delta\tau$ and using the infidelity to approximate the inner product with respect to the geometric tensor, we 
can rewrite the error as
\begin{equation}
    \begin{aligned}
    \dot\varepsilon &= \mathrm{Var}(H | \phi(\theta)) + \frac{1 - F(\theta, \theta + \delta\theta)}{(\delta\tau)^2} - \frac{2 b^T(\theta)\delta\theta}{\delta\tau} + \mathcal{O}(\delta\tau) \\
    &= \mathrm{Var}(H | \phi(\theta)) + \frac{2 \mathcal{L}(\delta\theta)}{(\delta\tau)^2} + \mathcal{O}(\delta\tau).
    \end{aligned}
\end{equation}
Note that the error scales linearly in time perturbation $\delta\tau$ as the infidelity approximation has a cubic error term \cite{stokes_qng_2020}, which is divided by the square of the perturbation. If we, for example, use a forward Euler rule with timestep $\Delta_t$ to integrate the variational error, the integration error scales as $\mathcal{O}(\Delta_t + T\delta\tau)$. This highlights the importance of differentiating between the timestep $\Delta_t$ for the integration, and the time-perturbation $\delta\tau$ to approximate the derivative.

In Fig.~\ref{fig:errorbounds}, we show the error bounds along with the true error for the time evolution of the Heisenberg model. The bounds are computed for different timesteps $\Delta_t$ for VarQRTE, and for DualQRTE for varying time perturbations $\delta\tau$ in exact simulations.
Firstly, we can verify that the error bounds hold.
Secondly, the larger the timestep relative to the time-perturbation, the more accurate the approximation of the dual time evolution, as the error $\mathcal{O}(\Delta_t + T\delta\tau)$ is dominated by the integration error. 

\begin{figure}[htp]
    \centering
    \includegraphics[width=\linewidth]{img/real/errorbounds.pdf}
    \caption{Error of the real-time evolution in Bures distance, plus error bounds obtained with VarQRTE and DualQRTE.}
    \label{fig:errorbounds}
\end{figure}

%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\label{sec:conclusion}
%%%%%%%%%%%%%%%%%%%%

In this paper, we present a novel algorithm for variational quantum time evolution that does not require the evaluation of the QGT, but instead solves a dual optimization problem in each timestep. The proposed dual time evolution algorithm, DualQTE, is particularly interesting for imaginary-time evolution, as there is currently no alternative variational algorithm able to circumvent the $\mathcal{O}(d^2)$ cost of VarQITE. For real-time evolution, p-VQD also offers an optimization-based approach by projecting a single Trotter step onto the variational form. In comparison, the dual time evolution has the advantage that no Suzuki-Trotter step has to be implemented, which could require deep circuits or non-local operations, depending on the Hamiltonian. Furthermore, our algorithm allows to evaluate variational error bounds \cite{zoufal_errorbounds_2021}, although how accurately they can be evaluated in the presence of shot noise remains an open question.

We demonstrated DualQTE for the imaginary-time evolution of a Heisenberg Hamiltonian on 12 qubits, 
and found that, in this setting, it requires about one order of magnitude less measurements to achieve the same accuracy as VarQITE. 
As a practical application of imaginary-time evolution, we calculated thermodynamic observables with the QMETTS algorithm and showed that the DualQITE is suitable to reproduce the sampling distributions.
Finally, we applied our algorithm to an illustrative example for real-time evolution, where it produced comparable results to p-VQD for the same amount of resources, while both algorithms outperformed VarQRTE.

In the presented experiments, we used standard gradient descent algorithms with a fixed learning rate.
We expect that the performance could be further improved by using more advanced optimization schemes, or methods that also take into account information from previous iterations.
Another possible improvement would be a suitable termination criterion for noisy evaluations of the loss function.
As for other optimization-based time evolution algorithms, such as p-VQD, 
it remains challenging to accurately measure the fidelity in the presence of hardware noise.
%another open question is how hardware noise influences the measurement of the fidelity.

In conclusion, the proposed DualQTE is an efficient variational algorithm for quantum time evolution that does not suffer from the quadratic complexity of evaluating the QGT.
This cost reduction enables scaling imaginary-time evolution to larger, practically relevant system sizes and allows the simulation and demonstration of a wide variety of important tasks such as Gibbs state preparation, mixed time evolution, or the evaluation of thermodynamic observables. 
Improving the resource requirements for near-term algorithms is an important step for scaling demonstrations to the full size of today's quantum computers and work towards practical applications.

% \section{Code availability}

% \julien{Make public on github.....}

\section{Acknowledgements}

We acknowledge the use of IBM Quantum services for this work. The views expressed are those of the authors, and do not reflect the official policy or position of IBM or the IBM Quantum team.

J.G. thanks Elena Peña Tapia and Alexander Miessen for insightful discussions and helpful comments on this manuscript.

\bibliography{refs} % Produces the bibliography via BibTeX.

\appendix
\onecolumngrid

\section{Runtime estimates of variational time evolution}\label{app:runtime_estimates}

If we know the total number of circuit executions for VarQTE the dual method, and we have an estimate
for the execution time of a circuit batch, we can estimate the total time taken for the time evolution.
In this idealized runtime estimation we use the following assumptions for both methods. 
We neglect the time it takes for the classical part of the update steps. 
For VarQTE this includes the solution of the linear system for the update step $\dot\theta$, which is dominated by the QPU overhead as the size of the linear system only polynomially. 
For DualQTE this is only the gradient descent update step, after the gradient has been evaluated.
Additionally we assume that both the circuit compilation overhead and QPU time does not increase with the number of parameters. 
In practice, however, we would expect this to increase as the circuits get deeper and have more qubits, but since this leads to a lower bound on the runtime estimate it is a valid assumption to show the infeasibility of VarQTE on current devices.

With the LCU approach to compute the real part of the QGT we can directly evaluate 
Eq.~\eqref{eq:qgt}. Since taking the real part of an expression is a linear operation we only have to evaluate the real parts of the Hessian $\braket{\partial_i \phi|\partial_j \phi}$ terms, which can be done using a single circuit, but since the phase fix terms $\braket{\partial_i \phi|\phi}$ are multiplied we need two circuits to compute both real and imaginary parts. Since the real part of the QGT is symmetric we need $d(d+1)/2$ circuits for the Hessian terms and $2d$ circuits for the phase fix.
Calculating the evolution gradient for imaginary-time evolution requires $kd$ circuits, where $k$ is the number of Pauli basis the Hamiltonian has to be measured. Here, techniques like grouping of Pauli terms can be used to reduce the number of bases $k$. In total we thus have
\begin{equation*}
    N^\text{VarQTE}_\text{LCU} = \frac{d(d + 5)}{2} + kd
\end{equation*}
circuit evaluations in each VarQTE timestep. 

Instead of the LCU approach the gradients can also be evaluated with a parameter-shift rule~\cite{schuld_gradients_2019}. 
In this case, the real part of the QGT is rewritten as Hessian of the fidelity
\begin{equation*}
    g_{ij}(\theta) = -\frac{1}{2}\frac{\partial^2}{\partial\theta_i \partial\theta_j} F(\theta', \theta) \bigg\vert_{\theta'=\theta}
\end{equation*}
where the terms are evaluated with a nested parameter shift.
Note that the parameter-shift rule cannot be used for real-time evolution as the imaginary part of the gradients 
cannot be evaluated.
An analogous derivation shows that in total 
\begin{equation*}
    N^\text{VarQITE}_\text{PS} = 2d(d + 1 + k)
\end{equation*}
circuits are executed at each timestep. 

The LCU approach uses less circuits, but requires an auxiliary qubit and controlled operations between this qubit and each of the parameterized gates. Depending on the available chip topology using parameter-shift might therefore still be favorable as only the parameters of the variational circuit are changed and no additional operations are required. In this runtime estimate we assume the ideal case of running LCU to get a lower bound on the number of required circuits.

For the dual time evolution we assume $K_0 = d$ iterations in the first optimization and a constant $K_{>0} = 10$ iterations for each following timestep. With the results from Fig.~\ref{fig:circuit_requirements} this is likely overestimating the number of required time step. In each timestep the evolution gradient has to be calculated, using either LCU or parameter-shift gradients, and for each optimization step the fidelity gradients. These can be evaluated either with a parameter-shift rule, or with a LCU if the fidelity is evaluated with the Hadamard test. 
In total, the number of circuits per timestep is 
\begin{equation*}
    \begin{aligned}
    N^\text{dual}_{\text{PS}, \cdot} &= 2kd + 2d K_\cdot  \\
    N^\text{dual}_{\text{LCU}, \cdot} &= kd + d K_\cdot,
    \end{aligned}
\end{equation*}
with the correct number of iterations $K_0$ or $K_{>0}$ depending on the timestep.

To obtain a runtime estimate for each circuit execution we run a collection of simple circuits with four qubits and CNOT depth of three on \texttt{ibmq\_montreal}. With a maximum batch size of $B=300$ circuits per job we find an overhead of $t_\text{overhead} = 19s$ per job due to sending circuits through the API and generating the waveforms and an average QPU rate of $f_\text{circuit} = 0.04s$ per circuit. 
The total runtime estimate is then given as 
\begin{equation*}
    N_\text{timesteps} \times 
    \left(\left\lceil \frac{N_\text{circuits}}{B} \right\rceil (t_\text{overhead} + B f_\text{circuit}) + 
    t_\text{overhead} + \left(N_\text{circuits} - B\left\lceil \frac{N_\text{circuits}}{B} \right\rceil\right) f_\text{circuit} \right).
\end{equation*}

\section{Derivation via quantum natural gradient descent}\label{app:qng_derivation}

VarQITE is inherently connected to the quantum natural gradient (QNG) algorithm~\cite{stokes_qng_2020}. In fact, this connection is a motivation for the convergence of the QNG as imaginary-time evolution is guaranteed to converge to the ground state, if there is sufficient initial overlap with it.

With a forward Euler integration the VarQITE update rule is
\begin{equation*}
    \theta_{t+1} = \theta_{t} + \Delta_t g^{-1}(\theta)\left(-\frac{\nabla E(\theta)}{2}\right).
\end{equation*}
This coincides with the QNG update step for the loss function $\ell(\theta) = E(\theta)/2$ and a learning rate of $\eta = \Delta_t$,
\begin{equation*}\label{eq:qng}
    \theta_{t+1} = \theta_{t} - \eta g^{-1}(\theta_t) \nabla\ell(\theta_t).
\end{equation*}
The natural gradients step can be expressed in a dual formulation as 
\begin{equation}
    \theta_{t+1} = \argmin{\theta} \braket{\nabla\ell(\theta_t), \theta - \theta_t} + \frac{1}{2 \eta} d^2(\theta, \theta_t),
\end{equation}
with a distance metric $d$. In this equation we see that the update step is going into the opposite direction of the gradient $\nabla\ell$, while the magnitude is limited by the distance metric and the learning rate.

Standard gradient descent uses the model-agnostic $\ell_2$ norm as distance metric. Natural gradients on the other hand limit the update step by the amount of change it induces in the model. To measure the induced change the metric $d$ is chosen to be the Fubini-Study metric, which, if locally approximated, yields the QGT:
\begin{equation*}
    \begin{aligned}
    d^2(\phi(\theta), \phi(\theta + \delta\theta)) &= \arccos^2|\braket{\phi(\theta)|\phi(\theta + \delta\theta)}| \\
    &= 1 - |\braket{\phi(\theta)|\phi(\theta + \delta\theta)}|^2 + \mathcal{O}(||\delta\theta||_2^4) \\
    &= \braket{\delta\theta, g(\theta)\delta\theta)} + \mathcal{O}(||\delta\theta||_2^3).
    \end{aligned}
\end{equation*}
The formulation in Eq.~\eqref{eq:qng} is then obtained by solving the minimization problem.

To circumvent the explicit evaluation of the QGT the natural gradient update can instead be calculated without the quadratic local approximation, and instead solve the optimization problem directly. If we use the infidelity as distance metric and generalize the loss function gradient to the evolution gradient $b$, we obtain the same update rule as the main text
\begin{equation}
    \theta_{t+1} = \argmin{\theta} \braket{b(\theta_t), \theta - \theta_t} + \frac{1 - F(\theta, \theta_t)}{2 \Delta_t}.
\end{equation}

\section{Illustrative example}\label{app:illustrative_example}

For an intuitive understanding of the approximations of the QGT norm,
we investigate an illustrative example with the variational model $\ket{\phi(\theta)} = R_\mathrm{Z}(\theta) R_\mathrm{Y}(\theta)\ket{0}$, the Hamiltonian $H = Z$ and a timestep of $\delta\tau = 1/2$. In Fig.~\ref{fig:illustrative} we compare the loss function $\mathcal{L}$ for imaginary-time evolution around $\theta=\pi/4$ obtained by using the metric $\braket{\delta\theta, g(\theta)\delta\theta}$ or the infidelity $1 - F(\theta, \theta + \delta\theta)$ as norm.

At $\delta\theta = 0$ the approximation is exact and in the vicinity the difference scales as $(\delta\theta)^3$. 
Note that the infidelity is periodic and bounded in $[0, 1]$ but the linear term $b^T\delta\theta$ is unbounded, which leads to the fact that the minimum of the infidelity-based loss function close to $\delta\theta = 0$ is not the global minimum.
This is well visible in Fig.~\ref{fig:illustrative} where the infidelity-based loss function achieves lower values for large $\delta\theta$ than the minimum of the QGT close to $\delta\theta = 0$.

Since we aim to find the same minimum as the QGT-based loss function using a local optimization routine, such as gradient descent, is crucial for the dual time evolution.

\begin{figure*}[htp]
    \centering
    \includegraphics[width=0.4\textwidth]{img/example/illustrative_losses.pdf}
    \includegraphics[width=0.4\textwidth]{img/example/difference.pdf}
    \caption{Values and difference of the QGT metric and the infidelity for the illustrative example.}
    \label{fig:illustrative}
\end{figure*}

The approximation error scales with the norm of $\delta\theta$ and, therefore, solving for the update step $\dot\theta = \delta\theta / \delta\tau$ with a smaller time perturbation $\delta\tau$ should result in a smaller error in the update step. Remembering the definition of the loss function
\begin{equation*}
    \mathcal{L}(\delta\theta) = \frac{1 - F(\theta, \theta+\delta\theta)}{2} - \delta\tau \cdot b^T \delta\theta,
\end{equation*}
we see that a smaller $\delta\tau$ moves the minimum closer to the minimum of the infidelity at $\delta\theta = 0$, leading to a smaller error. 
This is effect is visualized in Fig.~\ref{fig:tau_scaling} where we vary $\delta\tau$, present the effect on the loss landscape, and compute the difference between the exact QGT update step $\dot\theta$ and the dual approximation $\delta\theta / \delta\tau$.  
We find that the error in the update step scales approximately as $\mathcal{O}(\delta\tau)$, though in practice a smaller time perturbation requires a higher resolution of the fidelity and more measurements.

\begin{figure*}[htp]
    \centering
    \includegraphics[width=\textwidth]{img/example/landscapes_error.pdf}
    \caption{Error in calculating the parameter derivative $\dot\theta$, depending on the time perturbation $\delta\tau$.}
    \label{fig:tau_scaling}
\end{figure*}


\section{Imaginary-time evolution of the Heisenberg model}

\subsection{Circuit diagram}\label{app:su2_circuit}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{img/heisen/su2.pdf}
    \caption{The hardware efficient ansatz for the imaginary-time evolution experiments.
    In the QMETTS experiments the Pauli-$Y$ rotations is replaced by Pauli-$X$ rotations,
    if the evolution starts in the $Y$ basis states $\ket{\pm i}$.
    }
    \label{fig:efficient_su2}
\end{figure}

The circuit used as variational model is schematically presented in Fig.~\ref{fig:efficient_su2}. Each Pauli rotation gate has an independent parameter and the dotted box is repeated several times. For $r$ repetitions and $n$ qubits the total number of tunable parameters is thus $2n(r+1)$. The CNOT entangling gates are arranged in a pairwise manner to minimize the total depth to 2 per entangling layer.

\subsection{Termination and warmstarting}\label{app:warmstarting}

Termination criteria for gradient descent algorithms are typically defined as achieving a minimal threshold in the difference in the loss function between update steps or in the gradient norm.
However, if only noisy readout of the loss function is available these criteria become unreliable as the noise in the evaluation might prevent the termination criterion to be fulfilled even though the algorithm converged. 

One possible resolution would be to consider a moving average over a past batch of iterations. However, depending on the level of noise, this could require a large batchsize and therefore many iterations until the termination can be checked. 
Since the dual time evolution only has to compute small corrections, if small timesteps are performed and the optimization are warmstarted, 
we only expect a few iterations and a moving average is not a resource-efficient solution.
Therefore we use a heuristic where the first optimization uses a large number of steps and the subsequent ones perform a fixed number of few iterations.

To demonstrate the effectiveness of warmstarting and to calibrate the number of required steps for noisy evaluations we investigate the dual time evolution in an ideal setting with exact statevector simulations and no finite-sampling statistics.
First, we perform the time evolution for a Heisenberg Hamiltonian with periodic boundary conditions with $n=12$ sites, $J=1/4$, $g=-1$ and the initial state $\ket{+}^{\otimes  n}$. As circuit model we use the hardware efficient circuit from Fig.~\ref{fig:efficient_su2} with $r=6$ repetitions and optimize the update step with a gradient descent routine with a fixed learning rate of $\eta=0.1$. 
In each timestep we iterate until the change in loss function $\Delta\mathcal{L}$ is below the threshold of $10^{-4}\Delta_t = 10^{-6}$.
The results are presented in Fig.~\ref{fig:circuit_requirements}(a) and we observe that warmstarting drastically reduces the number of required iterations until the convergence criterion is reached.

In a second experiment we analyze how the required number of optimization steps scales with the system size. In Fig.~\ref{fig:circuit_requirements}(b) we repeat the above experiment for $n=3$ to 12 spins and track the number of steps in the first iteration and the mean and standard deviation of the warmstarted iterations.
We see that the number of steps scales sublinearly in the number of parameters $d$ and is almost constant for the warmstarted iterations. 

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.49\textwidth]{img/heisen/iterations_per_step.pdf}
    \includegraphics[width=0.49\textwidth]{img/heisen/iters_vs_size_grid.pdf}
    \caption{(a) The number of circuits required per timestep for different time evolution methods.
    (b) The number of iterations for different numbers of qubits and the first iteration and warmstarted iterations. The warmstarted points show mean and standard deviation of the number of iteration of all steps after the first. 
    }
    \label{fig:circuit_requirements}
\end{figure}

\subsection{Resource requirements for the dual time evolution}\label{app:dual_resources}

Table~\ref{tab:resources} shows the settings for VarQITE and the dual method for the resource estimation in Fig.~\ref{fig:heisen}(b).
For VarQITE we only varied the number of shots and in the dual method we additionally allowed to vary the number of iterations in the optimization in each time step. Especially the dual method has a lot of additional degrees of freedom that could be optimized, such as the kind of optimizer, in addition to settings shared with VarQITE, such as timestep size. 

\begin{table}[htp]
    \centering
    \begin{subtable}{0.49\textwidth}
    \centering
    \begin{tabular}{c|c|c}
        $I_B$ & shots & $N$ \\ \hline
        1.601 & 100 & $\sim 10^8$ \\
        0.558 & 1024 & $\sim 10^9$ \\
        0.149 & 8192 & $\sim 8 \cdot 10^9$
    \end{tabular}
    \caption{Settings for VarQITE.}
    \end{subtable}
    \hfill
    \begin{subtable}{0.49\textwidth}
    \centering
    \begin{tabular}{c|c|c|c|c}
        $I_B$ & shots & $K_0$ & $K_{>0}$ & $N$ \\ \hline
        0.937 & 100 & 100 & 10 & $\sim 2.5 \cdot 10^7$ \\
        0.735 & 100 & 200 & 20 & $\sim 5 \cdot 10^7$ \\
        0.305 & 1024 & 100 & 10 & $\sim 2.5 \cdot 10^8$ \\
        0.236 & 1024 & 200 & 20 & $\sim 5 \cdot 10^8$ \\
        0.153 & 2048 & 250 & 25 & $\sim 10^9$
    \end{tabular}
    \caption{Settings for dual imaginary-time evolution.}
    \end{subtable}
    \caption{Detailed settings for the resource comparison of VarQITE and dual imaginary-time evolution: the achieved Bures distance $D_B$, the number of shots per circuit and the total number of measurements $N$. The dual method additionally shows the number of iterations $K_0$ in the first optimization and $K_{>0}$ in the subsequent, warmstarted optimizations. Each optimization used gradient descent with a learning rate of $\eta = 0.1$.}
    \label{tab:resources}
\end{table}

\subsection{Resource scaling with system size}

In addition to the fixed-size model with 12 qubits, we investigate how the difference in resource requirements scales with 
system size. For that, we compare VarQITE and the dual imaginary-time evolution for the Heisenberg model from Eq.~\eqref{eq:heisencomb} with periodic boundary conditions and different number of spins $S$. 
We choose the same structure of the ansatz as in the experiment of Fig.~\ref{fig:heisen} where rotation and entanglement layers
are repeated $L=\lceil\log_2(S)\rceil$ times, plus a final rotation layer.

We then tune the settings of VarQITE and DualQITE to achieve a mean accuracy of $I_B \leq 0.1$ over 5 experiments and count the total number of required measurements $N$. This threshold corresponds to a per-timestep fidelity of 0.995. 
The results are presented in Fig.~\ref{fig:sizescaling}, which show the improved scaling of DualQITE compared to VarQITE. For small system sizes and few parameters, the overhead of solving the optimization problem in DualQITE is larger than evaluating the QGT. But, as we increase the problem size, the quadratic scaling of VarQITE takes over and our algorithm becomes more efficient.

\begin{figure}[htp]
    \centering
    \includegraphics[width=\textwidth]{img/heisen/sizescaling.pdf}
    \caption{Top panel: Total number of measurements required to achieve a mean accuracy of $I_B \leq 0.1$ over an average of 5 experiments.
    See Table~\ref{tab:resources_sizescaling} for the exact algorithm settings.
    Bottom panels: Mean accuracy and standard deviation of each point of the top panel.}
    \label{fig:sizescaling}
\end{figure}

\begin{table}[htp]
    \centering
    \begin{subtable}{0.49\textwidth}
    \centering
    \begin{tabular}{c|c}
        $n$ & shots \\ \hline
        4 & 500 \\
        6 & 1500 \\
        8 & 2500 \\
        10 & 6000 \\
        12 & 8000
    \end{tabular}
    \caption{Settings for VarQITE.}
    \end{subtable}
    \hfill
    \begin{subtable}{0.49\textwidth}
    \centering
    \begin{tabular}{c|c|c|c|c}
        n & shots & $K_0$ & $K_{>0}$ & $\eta$ \\ \hline
        4 & 500 & 100 & 20 & 0.1 \\
        6 & 600 & 200 & 25 & 0.07 \\
        8 & 1000 & 100 & 20 & 0.1 \\
        10 & 1500 & 200 & 25 & 0.12 \\
        12 & 2500 & 200 & 25 & 0.1 \\
    \end{tabular}
    \caption{Settings for dual imaginary-time evolution.}
    \end{subtable}
    \caption{Detailed settings for the resource comparison of VarQITE and dual imaginary-time evolution.}
    \label{tab:resources_sizescaling}
\end{table}


\section{Real-time evolution of the Heisenberg model}
\label{app:real_heisen}

\subsection{Circuit diagram}

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.49\textwidth]{img/real/alt.pdf}
    \caption{The circuit model used for the real-time evolution experiments.}
    \label{fig:alternating_ansatz}
\end{figure}

In the real-time evolution of the Heisenberg model we use the circuit sketched in Fig.~\ref{fig:alternating_ansatz}, which is the same model used in Ref.~\cite{barison_pvqd_2021}.
The dotted box is repeated three times and the rotation layer alternates between Pauli-$X$ rotations (starting from the first layer) and Pauli-$Y$ rotations.


\end{document}
%
% ****** End of file apssamp.tex ******
