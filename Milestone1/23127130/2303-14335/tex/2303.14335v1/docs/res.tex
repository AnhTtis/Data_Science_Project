\section{Experimental results}

\begin{figure}[tb!]
  \centering
  \includegraphics[width=.78\linewidth]{gpu}
  \caption{
    The hierarchical GPU acceleration model of our matrix cover algorithm.
  }
  \label{fig:mtxcover_gpu}
\end{figure}

The framework is implemented in C++ on an Intel Core 2.9-GHz Linux machine with Nvidia GeForce RTX 2080 GPU and nvcc 11.0 compiler.
Regarding kernel execution, we assign 32 threads per block with one block for each sub-graph.
We compare our results with the original EC~\cite{TPL-TCAD2017-Jiang}, OpenMPL EC~\cite{openmpl} on ISCAS benchmarks.
The ISCAS benchmarks are widely used in previous works. The minimum coloring spacing is set to 120 nm for the first ten cases and 100 nm for the last five cases, which are the same settings as \cite{TPL-TCAD2017-Jiang}, and \cite{openmpl}.
We show the results in \Cref{tab:results}, where the ``time(s)'' column is the total simplification and decomposition time of graphs which have redundant stitches to be removed.
The columns ``st\#'' and ``cn\#'' are the stitch and the conflict numbers.
Compared with original EC, our GPU-accelerated solver can achieve 17.6 $\times$ runtime speed-up with 2\% fewer stitches.
Compared with OpenMPL EC, our algorithm can achieve 20 $\times$ speed-up and 1\% fewer stitches with reasonable sacrifice on conflict number.
\input{docs/results_table.tex}

\begin{figure}[tb!]
  \centering
  \subfloat[]{\includegraphics[width=.42\linewidth]{bar-graph} \label{fig:bar-graph}} \hspace{2em}
  \subfloat[]{\includegraphics[width=.42\linewidth]{bar-large} \label{fig:bar-large}}
  \caption{
    (a) The result comparisons on first ten smaller cases of ISCAS benchmarks.
    (a) The result comparisons on last five larger cases of ISCAS benchmarks.
  }
\end{figure}

\section{Conclusion}

In this paper, we propose a GPU-accelerated matrix cover algorithm for multiple patterning layout decomposition problems.
Then we develop a set of GPU-efficient data structures and algorithms to accelerate the coloring process.
We leverage the CUDA programming model to implement the DLX algorithm on GPU in parallelization.
Compared with the state-of-the-art EC engine, our GPU-accelerated algorithm can achieve up to 17.6 $\times$ speed-up on large designs.

