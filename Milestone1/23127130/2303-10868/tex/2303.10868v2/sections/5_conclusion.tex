This survey reviews research that augments generative models by retrieving multi-modal information. Specifically, we categorize the current domain into enhancing with different modalities, including image, code, structured knowledge, speech, and video. 
% As many pretained models call for an external module to handle different formats, they often require further tuning or a tuned external retriever to interact with. 
With the emergence of large multi-modal models, we believe that this survey could serve as a comprehensive overview of an emerging and promising field. Moreover, we hope it could encourage future research in the domain, including retrieval-augmented multimodal reasoning, building a multi-modal knowledge index, and combining retrieval with pretraining.

\section{Limitations}

RAG also has some limitations. For example, there exists an attribution-fluency tradeoff \citep{aksitov2023characterizing} where the output quality is affected due to the added constraints of the retrieved knowledge.