
Audio RAG applications include audio data augmentation, music captioning, music and text generation, and speech recognition. It could be a promising future direction \citep{li2022survey}.
% There currently exist several research that use audio information to augment generation. 

\noindent\textbf{Text-audio data augmentation}~~~
For text-audio tasks, one of the most important challenges is the lack of training data on audio-text pairs. Therefore, retrieving audio and textual cues can alleviate the data scarcity problem and improve performance. In audio captioning, which aims at translating the input audio into its description, \citet{koizumi2020audio} retrieves guidance captions similar to the input audio from the training set. Then, the retrieved guidance captions are fed into a PLM to help generate new captions, which improves generation performance. To augment scarce speech translation (ST) data, \citet{zhao-etal-2023-generating} proposes SpokenVocab, a technique to convert machine translation (MT) data to synthetic ST data. To form synthetic speech, SpokenVocab retrieves and stitches audio snippets, corresponding to words in an MT sentence. Experiments show that stitched audio snippets can improve translation quality. \citet{kim2023prefix} leverages a PLM to tackle the data scarcity issue. It retrieves features from the input audio, maps them to continuous vectors using mapping networks, and uses vectors as prefixes for prefix tuning the PLM. With the additional information from retrieved audio, it outperforms previous methods. In text-to-audio generation, \citet{huang2023make} applies audio-text retrieval to get pseudo text prompts, which enhance audio generation in data-scarce scenarios. To augment the argumentation mining (AM) task in political debates, \citet{mestre-etal-2023-augmenting} integrates audio features into PLMs, which improves performance when data is scarce.

\noindent\textbf{Music captioning}~~~
Music captioning is the task of generating a text description or lyrics given the music audio. And RAG is explored to learn better audio-lyric alignment. \citet{manco2021muscaps} proposes the first music audio captioning model, MusCaps. Firstly, a pretrained multimodal encoder obtains audio representations that retrieve musical features in the input. As the pretraining bridges the gap between the audio modality and textual understanding, the method improves task performance. \citet{he2022recap} learns an audio-lyric alignment through contrastive learning, which results in a higher-quality generation of captions for music.
% When audio information is the input for the generation task, retrieval augmentation is explored to learn the audio and lyrics alignment through contrastive learning \citep{he2022recap}, which results in a higher-quality generation of captions for music. Moreover, retrieval of key/value pairs from the external knowledge catalog is used for automatic speech recognition tasks \citep{chan2023using}. 

\noindent\textbf{Music generation}~~~
\citet{royal2020deep} uses deep neural hashing to retrieve music building blocks and then performs generation by using the current music segment to retrieve the next. In automatic speech recognition (ASR), \citet{chan2023using} uses a k-nearest neighbor (KNN) approach to retrieve external knowledge related to the audio and text embeddings. The retrieved knowledge significantly reduces domain adaptation time for ASR.

% In cases where audio information is the output, retrieval is applied in a music generation system with deep neural hashing that encodes the music segments \citep{royal2020deep}. Audio-text retrieval is also applied to produce candidates in the process of pseudo prompt enhancement for text-to-audio generation \citep{huang2023make}. 
% Although there is a limited amount of research work which focuses on retrieval augmented generation tasks involving the audio, it could be a promising future direction \citep{li2022survey}.

The audio modality is closely intertwined with other modalities, such as video. Therefore, recent advancements in using
% in audio-text retrieval techniques  and uses of 
audio features for text-video retrieval \citep{falcon2022feature, mithun2018learning} can benefit RAG tasks involving other modalities. Moreover, although audio-text retrieval has been a long-standing task \citep{liu2015combining, milde-etal-2016-ambient, milde-etal-2016-demonstrating}, exploring recently discovered techniques \citep{hu2022audio, lou2022audio, koepke2022audio} could lead to further improvements.