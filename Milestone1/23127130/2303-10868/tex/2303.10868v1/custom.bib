% Introduction

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{driess2023palm,
  title={PaLM-E: An Embodied Multimodal Language Model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@misc{gpt4,
  doi = {10.48550/ARXIV.2303.08774},
  url = {https://arxiv.org/abs/2303.08774},
  author = {{OpenAI}
},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {GPT-4 Technical Report},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{nakano2021webgpt,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@article{he2022recap,
  title={RECAP: Retrieval Augmented Music Captioner},
  author={He, Zihao and Hao, Weituo and Song, Xuchen},
  journal={arXiv preprint arXiv:2212.10901},
  year={2022}
}

% Main body

@inproceedings{
liu2021retrievalaugmented,
title={Retrieval-Augmented Generation for Code Summarization via Hybrid {GNN}},
author={Shangqing Liu and Yu Chen and Xiaofei Xie and Jing Kai Siow and Yang Liu},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=zv-typ1gPxA}
}

@inproceedings{WenzelPN-TPHOLs08,
author={Makarius Wenzel and Lawrence C. Paulson and Tobias Nipkow},
title={The Isabelle Framework},
booktitle={Theorem Proving in Higher Order Logics (TPHOLs 2008)},
editor={Ait Mohamed and Munoz and Tahar},
publisher={Springer},series={LNCS},volume=5170,pages={33-38},year=2008}

@inproceedings{
wu2022autoformalization,
title={Autoformalization with Large Language Models},
author={Yuhuai Wu and Albert Qiaochu Jiang and Wenda Li and Markus Norman Rabe and Charles E Staats and Mateja Jamnik and Christian Szegedy},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=IUikebJ1Bf0}
}

@article{dpr,
  title={Dense passage retrieval for open-domain question answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2004.04906},
  year={2020}
}

@article{ding2022cocomic,
  title={CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file Context},
  author={Ding, Yangruibo and Wang, Zijian and Ahmad, Wasi Uddin and Ramanathan, Murali Krishna and Nallapati, Ramesh and Bhatia, Parminder and Roth, Dan and Xiang, Bing},
  journal={arXiv preprint arXiv:2212.10007},
  year={2022}
}

@article{hashimoto2018retrieve,
  title={A retrieve-and-edit framework for predicting structured outputs},
  author={Hashimoto, Tatsunori B and Guu, Kelvin and Oren, Yonatan and Liang, Percy S},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@book{mcconnell2004code,
  title={Code complete},
  author={McConnell, Steve},
  year={2004},
  publisher={Pearson Education}
}

@article{jin2023inferfix,
  title={InferFix: End-to-End Program Repair with LLMs},
  author={Jin, Matthew and Shahriar, Syed and Tufano, Michele and Shi, Xin and Lu, Shuai and Sundaresan, Neel and Svyatkovskiy, Alexey},
  journal={arXiv preprint arXiv:2303.07263},
  year={2023}
}

@article{hu2022fix,
  title={Fix Bugs with Transformer through a Neural-Symbolic Edit Grammar},
  author={Hu, Yaojie and Shi, Xingjian and Zhou, Qiang and Pike, Lee},
  journal={arXiv preprint arXiv:2204.06643},
  year={2022}
}

@article{zhou2022docprompting,
  title={Docprompting: Generating code by retrieving the docs},
  author={Zhou, Shuyan and Alon, Uri and Xu, Frank F and Wang, Zhiruo and Jiang, Zhengbao and Neubig, Graham},
  journal={arXiv preprint arXiv:2207.05987},
  year={2022}
}

@article{codex,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@unpublished{        
anonymous2023verify-and-edit:,        
title={Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework},        
author={Anonymous},        
journal={OpenReview Preprint},        
year={2023},        
note={anonymous preprint under review}    
}

@article{ye2023large,
  title={Large Language Models are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning},
  author={Ye, Yunhu and Hui, Binyuan and Yang, Min and Li, Binhua and Huang, Fei and Li, Yongbin},
  journal={arXiv preprint arXiv:2301.13808},
  year={2023}
}

@article{madaan2022language,
  title={Language models of code are few-shot commonsense learners},
  author={Madaan, Aman and Zhou, Shuyan and Alon, Uri and Yang, Yiming and Neubig, Graham},
  journal={arXiv preprint arXiv:2210.07128},
  year={2022}
}

@article{chen2022program,
  title={Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={arXiv preprint arXiv:2211.12588},
  year={2022}
}

@article{lyu2023faithful,
  title={Faithful Chain-of-Thought Reasoning},
  author={Lyu, Qing and Havaldar, Shreya and Stein, Adam and Zhang, Li and Rao, Delip and Wong, Eric and Apidianaki, Marianna and Callison-Burch, Chris},
  journal={arXiv preprint arXiv:2301.13379},
  year={2023}
}

@article{wei2022chain,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}

@article{gao2022pal,
  title={PAL: Program-aided Language Models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  journal={arXiv preprint arXiv:2211.10435},
  year={2022}
}

@inproceedings{10.1145/3377811.3380383,
author = {Zhang, Jian and Wang, Xu and Zhang, Hongyu and Sun, Hailong and Liu, Xudong},
title = {Retrieval-Based Neural Source Code Summarization},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380383},
doi = {10.1145/3377811.3380383},
abstract = {Source code summarization aims to automatically generate concise summaries of source code in natural language texts, in order to help developers better understand and maintain source code. Traditional work generates a source code summary by utilizing information retrieval techniques, which select terms from original source code or adapt summaries of similar code snippets. Recent studies adopt Neural Machine Translation techniques and generate summaries from code snippets using encoder-decoder neural networks. The neural-based approaches prefer the high-frequency words in the corpus and have trouble with the low-frequency ones. In this paper, we propose a retrieval-based neural source code summarization approach where we enhance the neural model with the most similar code snippets retrieved from the training set. Our approach can take advantages of both neural and retrieval-based techniques. Specifically, we first train an attentional encoder-decoder model based on the code snippets and the summaries in the training set; Second, given one input code snippet for testing, we retrieve its two most similar code snippets in the training set from the aspects of syntax and semantics, respectively; Third, we encode the input and two retrieved code snippets, and predict the summary by fusing them during decoding. We conduct extensive experiments to evaluate our approach and the experimental results show that our proposed approach can improve the state-of-the-art methods.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1385–1397},
numpages = {13},
keywords = {deep neural network, source code summarization, information retrieval},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK},
    url={https://www.cambridge.org/core/books/algorithms-on-strings-trees-and-sequences/F0B095049C7E6EF5356F0A26686C20D3}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}


@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005},
	url={https://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf}
}

@article{ct1965,
  title={An algorithm for the machine calculation of complex {F}ourier series},
  author={Cooley, James W. and Tukey, John W.},
  journal={Mathematics of Computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  url={https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf}
}

@article{liu2016recurrent,
  title={Recurrent neural network for text classification with multi-task learning},
  author={Liu, Pengfei and Qiu, Xipeng and Huang, Xuanjing},
  journal={arXiv preprint arXiv:1605.05101},
  year={2016}
}

@inproceedings{Yang2019XLNetGA,
  title={XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  author={Zhilin Yang and Zihang Dai and Yiming Yang and Jaime G. Carbonell and Ruslan Salakhutdinov and Quoc V. Le},
  booktitle={Neural Information Processing Systems},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{xie2022unifiedskg,
  title={Unifiedskg: Unifying and multi-tasking structured knowledge grounding with text-to-text language models},
  author={Xie, Tianbao and Wu, Chen Henry and Shi, Peng and Zhong, Ruiqi and Scholak, Torsten and Yasunaga, Michihiro and Wu, Chien-Sheng and Zhong, Ming and Yin, Pengcheng and Wang, Sida I and others},
  journal={arXiv preprint arXiv:2201.05966},
  year={2022}
}

@misc{liu2021pre,
  title={Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing (arXiv: 2107.13586). arXiv},
  author={Liu, P and Yuan, W and Fu, J and Jiang, Z and Hayashi, H and Neubig, G},
  year={2021}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}

@article{Raffel2019ExploringTL,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Colin Raffel and Noam M. Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.10683}
}

@article{qin2023chatgpt,
  title={Is ChatGPT a General-Purpose Natural Language Processing Task Solver?},
  author={Qin, Chengwei and Zhang, Aston and Zhang, Zhuosheng and Chen, Jiaao and Yasunaga, Michihiro and Yang, Diyi},
  journal={arXiv preprint arXiv:2302.06476},
  year={2023}
}

@article{zhou2023comprehensive,
  title={A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT},
  author={Zhou, Ce and Li, Qian and Li, Chen and Yu, Jun and Liu, Yixin and Wang, Guangjing and Zhang, Kai and Ji, Cheng and Yan, Qiben and He, Lifang and others},
  journal={arXiv preprint arXiv:2302.09419},
  year={2023}
}

@inproceedings{
qin2022lfpt,
title={{LFPT}5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5},
author={Chengwei Qin and Shafiq Joty},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=HCRVf71PMF}
}

@article{ding2022gpt,
  title={Is GPT-3 a Good Data Annotator?},
  author={Ding, Bosheng and Qin, Chengwei and Liu, Linlin and Bing, Lidong and Joty, Shafiq and Li, Boyang},
  journal={arXiv preprint arXiv:2212.10450},
  year={2022}
}

@article{qin2023learning,
  title={Learning to Initialize: Can Meta Learning Improve Cross-task Generalization in Prompt Tuning?},
  author={Qin, Chengwei and Joty, Shafiq and Li, Qian and Zhao, Ruochen},
  journal={arXiv preprint arXiv:2302.08143},
  year={2023}
}

@inproceedings{liu2022enhancing,
  title={Enhancing multilingual language model with massive multilingual knowledge triples},
  author={Liu, Linlin and Li, Xin and He, Ruidan and Bing, Lidong and Joty, Shafiq and Si, Luo},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={6878--6890},
  year={2022}
}



@inproceedings{liu2020k,
  title={K-bert: Enabling language representation with knowledge graph},
  author={Liu, Weijie and Zhou, Peng and Zhao, Zhe and Wang, Zhiruo and Ju, Qi and Deng, Haotang and Wang, Ping},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={03},
  pages={2901--2908},
  year={2020}
}

@inproceedings{jiang2022xlm,
  title={Xlm-k: Improving cross-lingual language model pre-training with multilingual knowledge},
  author={Jiang, Xiaoze and Liang, Yaobo and Chen, Weizhu and Duan, Nan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={10},
  pages={10840--10848},
  year={2022}
}


@inproceedings{gu2018search,
  title={Search engine guided neural machine translation},
  author={Gu, Jiatao and Wang, Yong and Cho, Kyunghyun and Li, Victor OK},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}


@inproceedings{wu2019response,
  title={Response generation by context-aware prototype editing},
  author={Wu, Yu and Wei, Furu and Huang, Shaohan and Wang, Yunli and Li, Zhoujun and Zhou, Ming},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={7281--7288},
  year={2019}
}


@inproceedings{xu2020boosting,
  title={Boosting neural machine translation with similar translations},
  author={Xu, Jitao and Crego, Josep-Maria and Senellart, Jean},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  pages={1570--1579},
  year={2020},
  organization={Association for Computational Linguistics}
}

@inproceedings{he2021fast,
  title={Fast and accurate neural machine translation with translation memory},
  author={He, Qiuxiang and Huang, Guoping and Cui, Qu and Li, Li and Liu, Lemao},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={3170--3180},
  year={2021}
}

@article{robertson2009probabilistic,
  title={The probabilistic relevance framework: BM25 and beyond},
  author={Robertson, Stephen and Zaragoza, Hugo and others},
  journal={Foundations and Trends{\textregistered} in Information Retrieval},
  volume={3},
  number={4},
  pages={333--389},
  year={2009},
  publisher={Now Publishers, Inc.}
}

@article{asai2022task,
  title={Task-aware retrieval with instructions},
  author={Asai, Akari and Schick, Timo and Lewis, Patrick and Chen, Xilun and Izacard, Gautier and Riedel, Sebastian and Hajishirzi, Hannaneh and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2211.09260},
  year={2022}
}

@article{mialon2023augmented,
  title={Augmented Language Models: a Survey},
  author={Mialon, Gr{\'e}goire and Dess{\`\i}, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozi{\`e}re, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and others},
  journal={arXiv preprint arXiv:2302.07842},
  year={2023}
}

@article{luan2021sparse,
  title={Sparse, dense, and attentional representations for text retrieval},
  author={Luan, Yi and Eisenstein, Jacob and Toutanova, Kristina and Collins, Michael},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={329--345},
  year={2021},
  publisher={MIT Press}
}

@inproceedings{guu2020retrieval,
  title={Retrieval augmented language model pre-training},
  author={Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Mingwei},
  booktitle={International conference on machine learning},
  pages={3929--3938},
  year={2020},
  organization={PMLR}
}

@inproceedings{borgeaud2022improving,
  title={Improving language models by retrieving from trillions of tokens},
  author={Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Van Den Driessche, George Bm and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  booktitle={International conference on machine learning},
  pages={2206--2240},
  year={2022},
  organization={PMLR}
}

@article{izacard2022atlas,
  title={Atlas: Few-shot learning with retrieval augmented language models},
  author={Izacard, Gautier and Lewis, Patrick and Lomeli, Maria and Hosseini, Lucas and Petroni, Fabio and Schick, Timo and Dwivedi-Yu, Jane and Joulin, Armand and Riedel, Sebastian and Grave, Edouard},
  journal={arXiv preprint arXiv},
  volume={2208},
  year={2022}
}

@article{he2022rethinking,
  title={Rethinking with Retrieval: Faithful Large Language Model Inference},
  author={He, Hangfeng and Zhang, Hongming and Roth, Dan},
  journal={arXiv preprint arXiv:2301.00303},
  year={2022}
}

@article{cheng2022binding,
  title={Binding language models in symbolic languages},
  author={Cheng, Zhoujun and Xie, Tianbao and Shi, Peng and Li, Chengzu and Nadkarni, Rahul and Hu, Yushi and Xiong, Caiming and Radev, Dragomir and Ostendorf, Mari and Zettlemoyer, Luke and others},
  journal={arXiv preprint arXiv:2210.02875},
  year={2022}
}

@article{pramanik2021uniqorn,
  title={UNIQORN: unified question answering over RDF knowledge graphs and natural language text},
  author={Pramanik, Soumajit and Alabi, Jesujoba and Roy, Rishiraj Saha and Weikum, Gerhard},
  journal={arXiv preprint arXiv:2108.08614},
  year={2021}
}

@article{jin2022heterformer,
  title={Heterformer: A Transformer Architecture for Node Representation Learning on Heterogeneous Text-Rich Networks},
  author={Jin, Bowen and Zhang, Yu and Zhu, Qi and Han, Jiawei},
  journal={arXiv preprint arXiv:2205.10282},
  year={2022}
}

@article{li2022opera,
  title={OPERA: Harmonizing Task-Oriented Dialogs and Information Seeking Experience},
  author={Li, Miaoran and Peng, Baolin and Gao, Jianfeng and Zhang, Zhu},
  journal={arXiv preprint arXiv:2206.12449},
  year={2022}
}

@article{thoppilan2022lamda,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}

@inproceedings{ye2022unreliability,
    title={The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning},
    author={Xi Ye and Greg Durrett},
    booktitle={Advances in Neural Information Processing Systems},
    editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
    year={2022},
    url={https://openreview.net/forum?id=Bct2f8fRd8S}
}

@article{creswell2022selection,
  title={Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning},
  author={Creswell, Antonia and Shanahan, Murray and Higgins, Irina},
  journal={arXiv preprint arXiv:2205.09712},
  year={2022}
}

@article{trivedi2022interleaving,
  title={Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions},
  author={Trivedi, Harsh and Balasubramanian, Niranjan and Khot, Tushar and Sabharwal, Ashish},
  journal={arXiv preprint arXiv:2212.10509},
  year={2022}
}

@article{lu2022learn,
  title={Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author={Lu, Pan and Mishra, Swaroop and Xia, Tony and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  journal={arXiv preprint arXiv:2209.09513},
  year={2022}
}

@article{zhang2023multimodal,
  title={Multimodal chain-of-thought reasoning in language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Zhao, Hai and Karypis, George and Smola, Alex},
  journal={arXiv preprint arXiv:2302.00923},
  year={2023}
}



@article{yang23vid2seq,
  author    = {Antoine Yang and
               Arsha Nagrani and
               Paul Hongsuck Seo and
               Antoine Miech and
               Jordi Pont{-}Tuset and
               Ivan Laptev and
               Josef Sivic and
               Cordelia Schmid},
  title     = {Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense
               Video Captioning},
  journal   = {CoRR},
  volume    = {abs/2302.14115},
  year      = {2023},
  url       = {https://doi.org/10.48550/arXiv.2302.14115},
}

@inproceedings{bogolin2022querybank,
  author    = {Simion{-}Vlad Bogolin and
               Ioana Croitoru and
               Hailin Jin and
               Yang Liu and
               Samuel Albanie},
  title     = {Cross Modal Retrieval with Querybank Normalisation},
  booktitle = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
               {CVPR}},
  pages     = {5184--5195},
  publisher = {{IEEE}},
  year      = {2022},
  url       = {https://doi.org/10.1109/CVPR52688.2022.00513},
}

@article{bogolin2022cap4video,
author    = {Wenhao Wu and
               Haipeng Luo and
               Bo Fang and
               Jingdong Wang and
               Wanli Ouyang},
  title     = {Cap4Video: What Can Auxiliary Captions Do for Text-Video Retrieval?},
  journal   = {CoRR},
  volume    = {abs/2301.00184},
  year      = {2023},
  url       = {https://doi.org/10.48550/arXiv.2301.00184},
  doi       = {10.48550/arXiv.2301.00184},
}


@article{xue2022clip-vip,
  author    = {Hongwei Xue and
               Yuchong Sun and
               Bei Liu and
               Jianlong Fu and
               Ruihua Song and
               Houqiang Li and
               Jiebo Luo},
  title     = {CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language
               Representation Alignment},
  journal   = {CoRR},
  volume    = {abs/2209.06430},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2209.06430},
  doi       = {10.48550/arXiv.2209.06430},
}


@inproceedings{wang2021t2vlad,
  author    = {Xiaohan Wang and
               Linchao Zhu and
               Yi Yang},
  title     = {{T2VLAD:} Global-Local Sequence Alignment for Text-Video Retrieval},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               2021, virtual, June 19-25, 2021},
  pages     = {5079--5088},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2021},
  url       = {https://openaccess.thecvf.com/content/CVPR2021/html/Wang\_T2VLAD\_Global-Local\_Sequence\_Alignment\_for\_Text-Video\_Retrieval\_CVPR\_2021\_paper.html},
  doi       = {10.1109/CVPR46437.2021.00504},
  timestamp = {Mon, 18 Jul 2022 16:47:40 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/WangZ021.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


% %%% multimodal learning sec.2.1
@article{baltruvsaitis2018multimodal,
  title={Multimodal machine learning: A survey and taxonomy},
  author={Baltru{\v{s}}aitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={2},
  pages={423--443},
  year={2018},
  publisher={IEEE}
}

@article{gao2020survey,
  title={A survey on deep learning for multimodal data fusion},
  author={Gao, Jing and Li, Peng and Chen, Zhikui and Zhang, Jianing},
  journal={Neural Computation},
  volume={32},
  number={5},
  pages={829--864},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

% success in vision, language, audio
@inproceedings{lanalbert,
  title={ALBERT: A Lite BERT for Self-supervised Learning of Language Representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{dosovitskiy2020vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal={International Conference on Learning Representations},
  pages={0--7},
  year={2021}
}
% swin transformer
@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}
@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}
% visual language learning for video/image
@inproceedings{ju2022prompting,
  title={Prompting visual-language models for efficient video understanding},
  author={Ju, Chen and Han, Tengda and Zheng, Kunhao and Zhang, Ya and Xie, Weidi},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXV},
  pages={105--124},
  year={2022},
  organization={Springer}
}

@inproceedings{alayracflamingo,
  title={Flamingo: a Visual Language Model for Few-Shot Learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

% visual language learning for language tasks
@inproceedings{zhou2020unified,
  title={Unified vision-language pre-training for image captioning and vqa},
  author={Zhou, Luowei and Palangi, Hamid and Zhang, Lei and Hu, Houdong and Corso, Jason and Gao, Jianfeng},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={07},
  pages={13041--13049},
  year={2020}
}

@inproceedings{lei2021less,
  title={Less is more: Clipbert for video-and-language learning via sparse sampling},
  author={Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L and Bansal, Mohit and Liu, Jingjing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7331--7341},
  year={2021}
}

% multimodal learning for other tasks
@inproceedings{tsai2019multimodal,
  title={Multimodal transformer for unaligned multimodal language sequences},
  author={Tsai, Yao-Hung Hubert and Bai, Shaojie and Liang, Paul Pu and Kolter, J Zico and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
  booktitle={Proceedings of the conference. Association for Computational Linguistics. Meeting},
  volume={2019},
  pages={6558},
  year={2019},
  organization={NIH Public Access}
}

@article{acosta2022multimodal,
  title={Multimodal biomedical AI},
  author={Acosta, Juli{\'a}n N and Falcone, Guido J and Rajpurkar, Pranav and Topol, Eric J},
  journal={Nature Medicine},
  volume={28},
  number={9},
  pages={1773--1784},
  year={2022},
  publisher={Nature Publishing Group US New York}
}

@article{nagrani2021attention,
  title={Attention bottlenecks for multimodal fusion},
  author={Nagrani, Arsha and Yang, Shan and Arnab, Anurag and Jansen, Aren and Schmid, Cordelia and Sun, Chen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14200--14213},
  year={2021}
}

% multimodal datasets
@inproceedings{elliott2016multi30k,
  title={Multi30K: Multilingual English-German Image Descriptions},
  author={Elliott, Desmond and Frank, Stella and Sima’an, Khalil and Specia, Lucia},
  booktitle={Proceedings of the 5th Workshop on Vision and Language},
  pages={70--74},
  year={2016}
}

@inproceedings{sheng2016dataset,
  title={A Dataset for Multimodal Question Answering in the Cultural Heritage Domain},
  author={Sheng, Shurong and Van Gool, Luc and Moens, Marie Francine},
  booktitle={Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
  pages={10--17},
  year={2016}
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={arXiv preprint arXiv:2302.04761},
  year={2023}
}

@inproceedings{davoudi2021toward,
  title={Toward Faithful Case-based Reasoning through Learning Prototypes in a Nearest Neighbor-friendly Space.},
  author={Davoudi, Seyed Omid and Komeili, Majid},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{duarte2021how2sign,
  title={How2sign: a large-scale multimodal dataset for continuous american sign language},
  author={Duarte, Amanda and Palaskar, Shruti and Ventura, Lucas and Ghadiyaram, Deepti and DeHaan, Kenneth and Metze, Florian and Torres, Jordi and Giro-i-Nieto, Xavier},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2735--2744},
  year={2021}
}



% multimodal pretraining models
@article{gan2022vision,
  title={Vision-language pre-training: Basics, recent advances, and future trends},
  author={Gan, Zhe and Li, Linjie and Li, Chunyuan and Wang, Lijuan and Liu, Zicheng and Gao, Jianfeng and others},
  journal={Foundations and Trends{\textregistered} in Computer Graphics and Vision},
  volume={14},
  number={3--4},
  pages={163--352},
  year={2022},
  publisher={Now Publishers, Inc.}
}

@article{uppal2022multimodal,
  title={Multimodal research in vision and language: A review of current and emerging trends},
  author={Uppal, Shagun and Bhagat, Sarthak and Hazarika, Devamanyu and Majumder, Navonil and Poria, Soujanya and Zimmermann, Roger and Zadeh, Amir},
  journal={Information Fusion},
  volume={77},
  pages={149--171},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{citation-0,
  title={VL-BERT: Pre-training of Generic Visual-Linguistic Representations},
  author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{li2021align,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={9694--9705},
  year={2021}
}

@inproceedings{wangsimvlm,
  title={SimVLM: Simple Visual Language Model Pretraining with Weak Supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

% multimodal generation models/works
@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@inproceedings{crowson2022vqgan,
  title={Vqgan-clip: Open domain image generation and editing with natural language guidance},
  author={Crowson, Katherine and Biderman, Stella and Kornis, Daniel and Stander, Dashiell and Hallahan, Eric and Castricato, Louis and Raff, Edward},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXVII},
  pages={88--105},
  year={2022},
  organization={Springer}
}


% works for retrieval augmented audio tasks-bao
@article{xu2022sescore2,
  title={SEScore2: Retrieval Augmented Pretraining for Text Generation Evaluation},
  author={Xu, Wenda and Qian, Xian and Wang, Mingxuan and Li, Lei and Wang, William Yang},
  journal={arXiv preprint arXiv:2212.09305},
  year={2022}
}

% works for retrieval augmented video tasks-bao
@article{chen2023retrieval,
  title={Retrieval Augmented Convolutional Encoder-Decoder Networks for Video Captioning},
  author={Chen, Jingwen and Pan, Yingwei and Li, Yehao and Yao, Ting and Chao, Hongyang and Mei, Tao},
  journal={ACM Transactions on Multimedia Computing, Communications and Applications},
  volume={19},
  number={1s},
  pages={1--24},
  year={2023},
  publisher={ACM New York, NY}
}

%%%%%% sec 2.1--end

@article{huang2023language,
  title={Language Is Not All You Need: Aligning Perception with Language Models},
  author={Huang, Shaohan and Dong, Li and Wang, Wenhui and Hao, Yaru and Singhal, Saksham and Ma, Shuming and Lv, Tengchao and Cui, Lei and Mohammed, Owais Khan and Liu, Qiang and others},
  journal={arXiv preprint arXiv:2302.14045},
  year={2023}
}

@article{wu2023visual,
  title={Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models},
  author={Wu, Chenfei and Yin, Shengming and Qi, Weizhen and Wang, Xiaodong and Tang, Zecheng and Duan, Nan},
  journal={arXiv preprint arXiv:2303.04671},
  year={2023}
}

@book{data-mining,
  author    = {Jure Leskovec and
               Anand Rajaraman and
               Jeffrey D. Ullman},
  title     = {Mining of Massive Datasets, 2nd Ed},
  publisher = {Cambridge University Press},
  year      = {2014},
  url       = {http://www.mmds.org/},
  isbn      = {978-1107077232},
}



@inproceedings{clip,
  author    = {Alec Radford and
               Jong Wook Kim and
               Chris Hallacy and
               Aditya Ramesh and
               Gabriel Goh and
               Sandhini Agarwal and
               Girish Sastry and
               Amanda Askell and
               Pamela Mishkin and
               Jack Clark and
               Gretchen Krueger and
               Ilya Sutskever},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {8748--8763},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/radford21a.html},
}



@inproceedings{chen-etal-2022-murag,
    title = "{M}u{RAG}: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text",
    author = "Chen, Wenhu  and
      Hu, Hexiang  and
      Chen, Xi  and
      Verga, Pat  and
      Cohen, William",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.375",
    pages = "5558--5570",
}

@inproceedings{RA-transformer,
  author    = {Sara Sarto and
               Marcella Cornia and
               Lorenzo Baraldi and
               Rita Cucchiara},
  title     = {Retrieval-Augmented Transformer for Image Captioning},
  booktitle = {{CBMI}},
  pages     = {1--7},
  publisher = {{ACM}},
  year      = {2022}
}

@inproceedings{Plug-and-Play,
  author    = {Anthony Meng Huat Tiong and
               Junnan Li and
               Boyang Li and
               Silvio Savarese and
               Steven C. H. Hoi},
  title     = {Plug-and-Play {VQA:} Zero-shot {VQA} by Conjoining Large Pretrained
               Models with Zero Training},
  booktitle = {{EMNLP} (Findings)},
  pages     = {951--967},
  publisher = {Association for Computational Linguistics},
  year      = {2022}
}

@article{RA-CM3,
  author    = {Michihiro Yasunaga and
               Armen Aghajanyan and
               Weijia Shi and
               Rich James and
               Jure Leskovec and
               Percy Liang and
               Mike Lewis and
               Luke Zettlemoyer and
               Wen{-}tau Yih},
  title     = {Retrieval-Augmented Multimodal Language Modeling},
  journal   = {CoRR},
  volume    = {abs/2211.12561},
  year      = {2022}
}

@article{Re-ViLM,
  author    = {Zhuolin Yang and
               Wei Ping and
               Zihan Liu and
               Vijay Korthikanti and
               Weili Nie and
               De{-}An Huang and
               Linxi Fan and
               Zhiding Yu and
               Shiyi Lan and
               Bo Li and
               Ming{-}Yu Liu and
               Yuke Zhu and
               Mohammad Shoeybi and
               Bryan Catanzaro and
               Chaowei Xiao and
               Anima Anandkumar},
  title     = {Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot
               Image Captioning},
  journal   = {CoRR},
  volume    = {abs/2302.04858},
  year      = {2023}
}

@inproceedings{A-OKVQA,
  author    = {Dustin Schwenk and
               Apoorv Khandelwal and
               Christopher Clark and
               Kenneth Marino and
               Roozbeh Mottaghi},
  title     = {{A-OKVQA:} {A} Benchmark for Visual Question Answering Using World
               Knowledge},
  booktitle = {{ECCV} {(8)}},
  series    = {Lecture Notes in Computer Science},
  volume    = {13668},
  pages     = {146--162},
  publisher = {Springer},
  year      = {2022}
}

@inproceedings{OK-VQA,
  author    = {Kenneth Marino and
               Mohammad Rastegari and
               Ali Farhadi and
               Roozbeh Mottaghi},
  title     = {{OK-VQA:} {A} Visual Question Answering Benchmark Requiring External
               Knowledge},
  booktitle = {{CVPR}},
  pages     = {3195--3204},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2019}
}

@inproceedings{WebQA,
  author    = {Yingshan Chang and
               Guihong Cao and
               Mridu Narang and
               Jianfeng Gao and
               Hisami Suzuki and
               Yonatan Bisk},
  title     = {WebQA: Multihop and Multimodal {QA}},
  booktitle = {{CVPR}},
  pages     = {16474--16483},
  publisher = {{IEEE}},
  year      = {2022}
}

@inproceedings{RA-VQA,
  author    = {Weizhe Lin and
               Bill Byrne},
  title     = {Retrieval Augmented Visual Question Answering with Outside Knowledge},
  booktitle = {{EMNLP}},
  pages     = {11238--11254},
  publisher = {Association for Computational Linguistics},
  year      = {2022}
}

@article{RAMM,
  author    = {Zheng Yuan and
               Qiao Jin and
               Chuanqi Tan and
               Zhengyun Zhao and
               Hongyi Yuan and
               Fei Huang and
               Songfang Huang},
  title     = {{RAMM:} Retrieval-augmented Biomedical Visual Question Answering with
               Multi-modal Pre-training},
  journal   = {CoRR},
  volume    = {abs/2303.00534},
  year      = {2023}
}

@inproceedings{KAT,
  author    = {Liangke Gui and
               Borui Wang and
               Qiuyuan Huang and
               Alexander Hauptmann and
               Yonatan Bisk and
               Jianfeng Gao},
  title     = {{KAT:} {A} Knowledge Augmented Transformer for Vision-and-Language},
  booktitle = {{NAACL-HLT}},
  pages     = {956--968},
  publisher = {Association for Computational Linguistics},
  year      = {2022}
}

@inproceedings{DALL-E,
  author    = {Aditya Ramesh and
               Mikhail Pavlov and
               Gabriel Goh and
               Scott Gray and
               Chelsea Voss and
               Alec Radford and
               Mark Chen and
               Ilya Sutskever},
  title     = {Zero-Shot Text-to-Image Generation},
  booktitle = {{ICML}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {8821--8831},
  publisher = {{PMLR}},
  year      = {2021}
}

@article{parti,
  author    = {Jiahui Yu and
               Yuanzhong Xu and
               Jing Yu Koh and
               Thang Luong and
               Gunjan Baid and
               Zirui Wang and
               Vijay Vasudevan and
               Alexander Ku and
               Yinfei Yang and
               Burcu Karagol Ayan and
               Ben Hutchinson and
               Wei Han and
               Zarana Parekh and
               Xin Li and
               Han Zhang and
               Jason Baldridge and
               Yonghui Wu},
  title     = {Scaling Autoregressive Models for Content-Rich Text-to-Image Generation},
  journal   = {CoRR},
  volume    = {abs/2206.10789},
  year      = {2022}
}

@article{flamingo,
  author    = {Jean{-}Baptiste Alayrac and
               Jeff Donahue and
               Pauline Luc and
               Antoine Miech and
               Iain Barr and
               Yana Hasson and
               Karel Lenc and
               Arthur Mensch and
               Katie Millican and
               Malcolm Reynolds and
               Roman Ring and
               Eliza Rutherford and
               Serkan Cabi and
               Tengda Han and
               Zhitao Gong and
               Sina Samangooei and
               Marianne Monteiro and
               Jacob Menick and
               Sebastian Borgeaud and
               Andrew Brock and
               Aida Nematzadeh and
               Sahand Sharifzadeh and
               Mikolaj Binkowski and
               Ricardo Barreira and
               Oriol Vinyals and
               Andrew Zisserman and
               Karen Simonyan},
  title     = {Flamingo: a Visual Language Model for Few-Shot Learning},
  journal   = {CoRR},
  volume    = {abs/2204.14198},
  year      = {2022}
}

@article{CM3,
  author    = {Armen Aghajanyan and
               Bernie Huang and
               Candace Ross and
               Vladimir Karpukhin and
               Hu Xu and
               Naman Goyal and
               Dmytro Okhonko and
               Mandar Joshi and
               Gargi Ghosh and
               Mike Lewis and
               Luke Zettlemoyer},
  title     = {{CM3:} {A} Causal Masked Multimodal Model of the Internet},
  journal   = {CoRR},
  volume    = {abs/2201.07520},
  year      = {2022}
}

@article{non-verbal-comm,
  author    = {Mehrabian, A. and Ferris, S. R. },
  title     = {Inference of attitudes from nonverbal communication in two channels},
  journal   = {Journal of Consulting Psychology},
  volume    = {31(3), 248–252},
  year      = {1967}
}
%code_start
@article{dsf,
  author    = {Xin Xia and
               Lingfeng Bao and
               David Lo and
               Pavneet Singh Kochhar and
               Ahmed E. Hassan and
               Zhenchang Xing},
  title     = {What do developers search for on the web?},
  journal   = {Empir. Softw. Eng.},
  volume    = {22},
  number    = {6},
  pages     = {3149--3185},
  year      = {2017},
  url       = {https://doi.org/10.1007/s10664-017-9514-4},
  doi       = {10.1007/s10664-017-9514-4},
  timestamp = {Tue, 25 Aug 2020 16:58:31 +0200},
  biburl    = {https://dblp.org/rec/journals/ese/XiaBLKHX17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{nashidretrieval,
  title={Retrieval-Based Prompt Selection for Code-Related Few-Shot Learning},
  author={Nashid, Noor and Sintaha, Mifta and Mesbah, Ali}
}
@inproceedings{codet5,
  author    = {Yue Wang and
               Weishi Wang and
               Shafiq R. Joty and
               Steven C. H. Hoi},
  editor    = {Marie{-}Francine Moens and
               Xuanjing Huang and
               Lucia Specia and
               Scott Wen{-}tau Yih},
  title     = {CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models
               for Code Understanding and Generation},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2021, Virtual Event / Punta Cana, Dominican
               Republic, 7-11 November, 2021},
  pages     = {8696--8708},
  publisher = {Association for Computational Linguistics},
  year      = {2021},
  url       = {https://doi.org/10.18653/v1/2021.emnlp-main.685},
  doi       = {10.18653/v1/2021.emnlp-main.685},
  timestamp = {Thu, 20 Jan 2022 10:02:24 +0100},
  biburl    = {https://dblp.org/rec/conf/emnlp/0034WJH21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{unixcoder,
  author    = {Daya Guo and
               Shuai Lu and
               Nan Duan and
               Yanlin Wang and
               Ming Zhou and
               Jian Yin},
  editor    = {Smaranda Muresan and
               Preslav Nakov and
               Aline Villavicencio},
  title     = {UniXcoder: Unified Cross-Modal Pre-training for Code Representation},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational
               Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
               May 22-27, 2022},
  pages     = {7212--7225},
  publisher = {Association for Computational Linguistics},
  year      = {2022},
  url       = {https://doi.org/10.18653/v1/2022.acl-long.499},
  doi       = {10.18653/v1/2022.acl-long.499},
  timestamp = {Mon, 01 Aug 2022 16:27:41 +0200},
  biburl    = {https://dblp.org/rec/conf/acl/GuoLDW0022.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{codereviewer,
  author    = {Zhiyu Li and
               Shuai Lu and
               Daya Guo and
               Nan Duan and
               Shailesh Jannu and
               Grant Jenks and
               Deep Majumder and
               Jared Green and
               Alexey Svyatkovskiy and
               Shengyu Fu and
               Neel Sundaresan},
  editor    = {Abhik Roychoudhury and
               Cristian Cadar and
               Miryung Kim},
  title     = {Automating code review activities by large-scale pre-training},
  booktitle = {Proceedings of the 30th {ACM} Joint European Software Engineering
               Conference and Symposium on the Foundations of Software Engineering,
               {ESEC/FSE} 2022, Singapore, Singapore, November 14-18, 2022},
  pages     = {1035--1047},
  publisher = {{ACM}},
  year      = {2022},
  url       = {https://doi.org/10.1145/3540250.3549081},
  doi       = {10.1145/3540250.3549081},
  timestamp = {Thu, 10 Nov 2022 12:19:51 +0100},
  biburl    = {https://dblp.org/rec/conf/sigsoft/LiLGDJJMGSFS22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/emnlp/HayatiOAYTN18,
  author    = {Shirley Anugrah Hayati and
               Raphael Olivier and
               Pravalika Avvaru and
               Pengcheng Yin and
               Anthony Tomasic and
               Graham Neubig},
  editor    = {Ellen Riloff and
               David Chiang and
               Julia Hockenmaier and
               Jun'ichi Tsujii},
  title     = {Retrieval-Based Neural Code Generation},
  booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural
               Language Processing, Brussels, Belgium, October 31 - November 4, 2018},
  pages     = {925--930},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
  url       = {https://doi.org/10.18653/v1/d18-1111},
  doi       = {10.18653/v1/d18-1111},
  timestamp = {Fri, 06 Aug 2021 00:40:21 +0200},
  biburl    = {https://dblp.org/rec/conf/emnlp/HayatiOAYTN18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/iclr/LiuCXS021,
  author    = {Shangqing Liu and
               Yu Chen and
               Xiaofei Xie and
               Jing Kai Siow and
               Yang Liu},
  title     = {Retrieval-Augmented Generation for Code Summarization via Hybrid {GNN}},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=zv-typ1gPxA},
  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/LiuCXS021.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/sp/YamaguchiGAR14,
  author    = {Fabian Yamaguchi and
               Nico Golde and
               Daniel Arp and
               Konrad Rieck},
  title     = {Modeling and Discovering Vulnerabilities with Code Property Graphs},
  booktitle = {2014 {IEEE} Symposium on Security and Privacy, {SP} 2014, Berkeley,
               CA, USA, May 18-21, 2014},
  pages     = {590--604},
  publisher = {{IEEE} Computer Society},
  year      = {2014},
  url       = {https://doi.org/10.1109/SP.2014.44},
  doi       = {10.1109/SP.2014.44},
  timestamp = {Tue, 16 Aug 2022 23:04:38 +0200},
  biburl    = {https://dblp.org/rec/conf/sp/YamaguchiGAR14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/emnlp/ZhuLZQZZ19,
  author    = {Jie Zhu and
               Junhui Li and
               Muhua Zhu and
               Longhua Qian and
               Min Zhang and
               Guodong Zhou},
  editor    = {Kentaro Inui and
               Jing Jiang and
               Vincent Ng and
               Xiaojun Wan},
  title     = {Modeling Graph Structure in Transformer for Better AMR-to-Text Generation},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural
               Language Processing and the 9th International Joint Conference on
               Natural Language Processing, {EMNLP-IJCNLP} 2019, Hong Kong, China,
               November 3-7, 2019},
  pages     = {5458--5467},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
  url       = {https://doi.org/10.18653/v1/D19-1548},
  doi       = {10.18653/v1/D19-1548},
  timestamp = {Thu, 07 Apr 2022 09:14:07 +0200},
  biburl    = {https://dblp.org/rec/conf/emnlp/ZhuLZQZZ19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/scam/LinHYL22,
  author    = {Lile Lin and
               Zhiqiu Huang and
               Yaoshen Yu and
               Yapeng Liu},
  title     = {Multi-Modal Code Summarization with Retrieved Summary},
  booktitle = {22nd {IEEE} International Working Conference on Source Code Analysis
               and Manipulation, {SCAM} 2021, Limassol, Cyprus, October 3, 2022},
  pages     = {132--142},
  publisher = {{IEEE}},
  year      = {2022},
  url       = {https://doi.org/10.1109/SCAM55253.2022.00020},
  doi       = {10.1109/SCAM55253.2022.00020},
  timestamp = {Mon, 23 Jan 2023 22:18:07 +0100},
  biburl    = {https://dblp.org/rec/conf/scam/LinHYL22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/emnlp/ShiW0DZHZ022,
  author    = {Ensheng Shi and
               Yanlin Wang and
               Wei Tao and
               Lun Du and
               Hongyu Zhang and
               Shi Han and
               Dongmei Zhang and
               Hongbin Sun},
  editor    = {Yoav Goldberg and
               Zornitsa Kozareva and
               Yue Zhang},
  title     = {{RACE:} Retrieval-augmented Commit Message Generation},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
               December 7-11, 2022},
  pages     = {5520--5530},
  publisher = {Association for Computational Linguistics},
  year      = {2022},
  url       = {https://aclanthology.org/2022.emnlp-main.372},
  timestamp = {Tue, 07 Feb 2023 17:10:51 +0100},
  biburl    = {https://dblp.org/rec/conf/emnlp/ShiW0DZHZ022.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{simfix,
  author    = {Jiajun Jiang and
               Yingfei Xiong and
               Hongyu Zhang and
               Qing Gao and
               Xiangqun Chen},
  title     = {Shaping program repair space with existing patches and similar code},
  booktitle = {{ISSTA}},
  pages     = {298--309},
  publisher = {{ACM}},
  year      = {2018}
}
@inproceedings{DBLP:conf/icse/QiMLDW14,
  author    = {Yuhua Qi and
               Xiaoguang Mao and
               Yan Lei and
               Ziying Dai and
               Chengsong Wang},
  title     = {The strength of random search on automated program repair},
  booktitle = {{ICSE}},
  pages     = {254--265},
  publisher = {{ACM}},
  year      = {2014}
}
@article{White2019SortingAT,
  title={Sorting and Transforming Program Repair Ingredients via Deep Learning Code Similarities},
  author={Martin White and Michele Tufano and Matias Martinez and Monperrus Martin and Denys Poshyvanyk},
  journal={2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  year={2019},
  pages={479-490}
}
@inproceedings{DBLP:conf/wcre/LiuZ18,
  author    = {Xuliang Liu and
               Hao Zhong},
  title     = {Mining stackoverflow for program repair},
  booktitle = {{SANER}},
  pages     = {118--129},
  publisher = {{IEEE} Computer Society},
  year      = {2018}
}
@article{Martinez2014DoTF,
  title={Do the fix ingredients already exist? an empirical inquiry into the redundancy assumptions of program repair approaches},
  author={Matias Martinez and Westley Weimer and Monperrus Martin},
  journal={Companion Proceedings of the 36th International Conference on Software Engineering},
  year={2014}
}
@article{joshi2022repair,
  title={Repair is nearly generation: Multilingual program repair with llms},
  author={Joshi, Harshit and Cambronero, Jos{\'e} and Gulwani, Sumit and Le, Vu and Radicek, Ivan and Verbruggen, Gust},
  journal={arXiv preprint arXiv:2208.11640},
  year={2022}
}
@article{clement2021long,
  title={Long-Range Modeling of Source Code Files with eWASH: Extended Window Access by Syntax Hierarchy},
  author={Clement, Colin B and Lu, Shuai and Liu, Xiaoyu and Tufano, Michele and Drain, Dawn and Duan, Nan and Sundaresan, Neel and Svyatkovskiy, Alexey},
  journal={arXiv preprint arXiv:2109.08780},
  year={2021}
}
%code_end
@inproceedings{MIPs,
  author    = {Ruiqi Guo and
               Philip Sun and
               Erik Lindgren and
               Quan Geng and
               David Simcha and
               Felix Chern and
               Sanjiv Kumar},
  title     = {Accelerating Large-Scale Inference with Anisotropic Vector Quantization},
  booktitle = {{ICML}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {119},
  pages     = {3887--3896},
  publisher = {{PMLR}},
  year      = {2020}
}


@inproceedings{GradCAM,
  author    = {Ramprasaath R. Selvaraju and
               Michael Cogswell and
               Abhishek Das and
               Ramakrishna Vedantam and
               Devi Parikh and
               Dhruv Batra},
  title     = {Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based
               Localization},
  booktitle = {{ICCV}},
  pages     = {618--626},
  publisher = {{IEEE} Computer Society},
  year      = {2017}
}

@article{math,
  title={Are NLP models really able to solve simple math word problems?},
  author={Patel, Arkil and Bhattamishra, Satwik and Goyal, Navin},
  journal={arXiv preprint arXiv:2103.07191},
  year={2021}
}

@article{dou2022coarse,
  title={Coarse-to-fine vision-language pre-training with fusion in the backbone},
  author={Dou, Zi-Yi and Kamath, Aishwarya and Gan, Zhe and Zhang, Pengchuan and Wang, Jianfeng and Li, Linjie and Liu, Zicheng and Liu, Ce and LeCun, Yann and Peng, Nanyun and others},
  journal={arXiv preprint arXiv:2206.07643},
  year={2022}
}

@article{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@article{chen2022re,
  title={Re-imagen: Retrieval-augmented text-to-image generator},
  author={Chen, Wenhu and Hu, Hexiang and Saharia, Chitwan and Cohen, William W},
  journal={arXiv preprint arXiv:2209.14491},
  year={2022}
}

@inproceedings{yang2022empirical,
  title={An empirical study of gpt-3 for few-shot knowledge-based vqa},
  author={Yang, Zhengyuan and Gan, Zhe and Wang, Jianfeng and Hu, Xiaowei and Lu, Yumao and Liu, Zicheng and Wang, Lijuan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={3},
  pages={3081--3089},
  year={2022}
}

@article{li2022survey,
  title={A Survey on Retrieval-Augmented Text Generation},
  author={Li, Huayang and Su, Yixuan and Cai, Deng and Wang, Yan and Liu, Lemao},
  journal={arXiv preprint arXiv:2202.01110},
  year={2022}
}

@article{chan2023using,
  title={Using External Off-Policy Speech-To-Text Mappings in Contextual End-To-End Automated Speech Recognition},
  author={Chan, David M and Ghosh, Shalini and Rastrow, Ariya and Hoffmeister, Bj{\"o}rn},
  journal={arXiv preprint arXiv:2301.02736},
  year={2023}
}

@inproceedings{royal2020deep,
  title={Deep composer: Deep neural hashing and retrieval approach to automatic music generation},
  author={Royal, Brandon and Hua, Kien and Zhang, Brenton},
  booktitle={2020 IEEE International Conference on Multimedia and Expo (ICME)},
  pages={1--6},
  year={2020},
  organization={IEEE}
}

@inproceedings{falcon2022feature,
  title={A Feature-space Multimodal Data Augmentation Technique for Text-video Retrieval},
  author={Falcon, Alex and Serra, Giuseppe and Lanz, Oswald},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={4385--4394},
  year={2022}
}

@inproceedings{mithun2018learning,
  title={Learning joint embedding with multimodal cues for cross-modal video-text retrieval},
  author={Mithun, Niluthpol Chowdhury and Li, Juncheng and Metze, Florian and Roy-Chowdhury, Amit K},
  booktitle={Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval},
  pages={19--27},
  year={2018}
}

@article{hu2022audio,
  title={Audio-Text Retrieval Based on Contrastive Learning and Collaborative Attention Mechanism},
  author={Hu, Tao and Xiang, Xuyu and Qin, Jiaohua and Tan, Yun},
  year={2022}
}

@article{huang2023make,
  title={Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models},
  author={Huang, Rongjie and Huang, Jiawei and Yang, Dongchao and Ren, Yi and Liu, Luping and Li, Mingze and Ye, Zhenhui and Liu, Jinglin and Yin, Xiang and Zhao, Zhou},
  journal={arXiv preprint arXiv:2301.12661},
  year={2023}
}

@inproceedings{lou2022audio,
  title={Audio-text retrieval in context},
  author={Lou, Siyu and Xu, Xuenan and Wu, Mengyue and Yu, Kai},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4793--4797},
  year={2022},
  organization={IEEE}
}

@article{koepke2022audio,
  title={Audio retrieval with natural language queries: A benchmark study},
  author={Koepke, A Sophia and Oncescu, Andreea-Maria and Henriques, Joao and Akata, Zeynep and Albanie, Samuel},
  journal={IEEE Transactions on Multimedia},
  year={2022},
  publisher={IEEE}
}

