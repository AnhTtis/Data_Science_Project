% one- Motivation

% LLM generation ability & becoming more multi-modal

Generative Artificial Intelligence (GAI) 
% \xl{GAI is better or generative AI is better? i am not so sure} I saw this term used in other papers (GAI)
has demonstrated impressive performances in tasks such as text generation \citep{ouyang2022training, chowdhery2022palm, brown2020language} and text-to-image generation \citep{DALL-E}. Powered by their abilities in modality-specific tasks, the recent incorporation of multimodality \citep{driess2023palm, gpt4, huang2023language} has opened up possibilities for generative models to serve as general-purpose learners in different formats of information. 

% limitations of generative models
However, generative models suffer from inevitable limitations, such as hallucinations \citep{ye2022unreliability}, arithmetic difficulties \citep{math}, and lack of interpretability. Thus, a promising solution for generative models is learning to interact with the external world and retrieve knowledge in different formats, thus augmenting their generation abilities \citep{mialon2023augmented}. 

% how it could be addressed by retrieval-based
Recently, there have been emerging studies focusing on retrieval-based approaches, which aim to provide generative models with more information. Among them, most \citep{nakano2021webgpt, guu2020retrieval} use textual information retrieved from the web or textual corpora. Although the textual format aligns with data used during pre-training and offers a natural medium for interaction, there is more world knowledge contained in other formats, such as images, videos, graphs, and audio. These types of information are often inaccessible, unavailable, or not describable in traditional textual corpora.

% thus retrieval multi-modal generation models
% Therefore, there exists prominent potential in augmenting generation with multimodal information. With the recent advances in Multimodal Large Language Models (MLLMs) \citep{huang2023language}, generative models have better access and improved abilities in handling multi-format information. As a result, we have witnessed an emerging trend in works that utilize retrieval-based and multimodal techniques, which effectively address limitations such as hallucination and lack of interpretability.
Recent advancements in Multimodal Large Language Models (MLLMs)~\citep{huang2023language, gpt4, driess2023palm} have improved the capability to handle multi-format information of generative models, demonstrating the significant potential in augmenting generation with multimodal knowledge. This has resulted in an emerging trend of work that utilizes retrieval-based and multimodal techniques to effectively address the limitations such as hallucination and lack of interpretability.

% two- our contribution

% classify and discuss in different modalities

In this survey, we review recent advancements in multimodal retrieval-augmented generation. Specifically, for each modality, there are often differences in retrieval and synthesis procedures, goals, and targeted tasks. Thus, we group relevant methods into different modalities, including image, code, structured knowledge, audio, and video. 

% a brief introduction of each modality
For each modality, we review the previous work, the current state, and future challenges. For example, in the image domain, retrieval-augmented methods have been used to better ground visual question-answering (VQA) tasks \citep{chen-etal-2022-murag, Plug-and-Play} and generate more factual captions \citep{Re-ViLM, RA-CM3}. In the code domain, retrieval-based works decouple logic and textual information, which results in more faithful and factual outputs \citep{lyu2023faithful, chen2022program}. To enhance factuality, some methods \citep{thoppilan2022lamda, cheng2022binding} also retrieve grounding contexts from structured knowledge, such as tables and knowledge graphs. Moreover, there are emerging works in combining audio and video retrieval in generative models \citep{he2022recap, bogolin2022querybank}.

% future directions discussion 
We believe that the emergence of multimodal retrieval-augmented generation contains the solution to many current challenges. To encourage more future research in this domain, we analyze several promising future directions, including retrieval-augmented multimodal reasoning, building a multimodal knowledge index, and combining retrieval with pre-training.

% continue adding and perfecting the survey
As the direction of multimodal retrieval-augmented generation is emerging, we will continue to add new works and expand the scope of our current survey.