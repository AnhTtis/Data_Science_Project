
There currently exist several works that use audio information to augment generation. 

When audio information is the input for the generation task, retrieval augmentation is explored to learn the audio and lyrics alignment through contrastive learning \citep{he2022recap}, which results in a higher-quality generation of captions for music. Moreover, retrieval of key/value pairs from the external knowledge catalog is used for automatic speech recognition tasks \citep{chan2023using}. 

In cases where audio information is the output, retrieval is applied in a music generation system with deep neural hashing that encodes the music segments \citep{royal2020deep}. Audio-text retrieval is also applied to produce candidates in the process of pseudo prompt enhancement for text-to-audio generation \citep{huang2023make}. Although there is a limited amount of research work which focuses on retrieval augmented generation tasks involving the audio, it could be a promising future direction \citep{li2022survey}.

It is worth noting that the audio modality is closely intertwined with other modalities. Therefore, recent advancements in audio-text retrieval techniques \citep{hu2022audio, lou2022audio, koepke2022audio} and uses of audio features for text-video retrieval \citep{falcon2022feature, mithun2018learning} can benefit retrieval augmented generation tasks involving other modalities.