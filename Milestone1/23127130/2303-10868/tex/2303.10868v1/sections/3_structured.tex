To increase factual grounding and reduce hallucinations, a promising direction is to incorporate more structured knowledge, such as knowledge graphs, tables, and databases. An open challenge in generative models is hallucination, where the model is likely to output seemingly plausible sentences that do not conform to the ground-truth facts. Researchers have denoted that language models, while only relying on internal knowledge (pre-trained weights), fail to recall accurate details when functioning as a knowledge base in question-answering tasks \citep{ye2022unreliability,creswell2022selection}. Thus, A potential solution is to ground generation with retrieved structured knowledge. Structured knowledge, such as knowledge graphs, tables, and databases, often represents how knowledge from different domains is integrated. They could function as a reliant source of truth to enhance factuality. 

As the format of structured knowledge departs from the natural texts seen by LLMs during pre-training, how to effectively retrieve and synthesize it for generation has been an open challenge. \citet{xie2022unifiedskg} represent an early attempt, where all formats of knowledge, including tables, triplets, and ontology, are linearized into text format and fed into the LLM without retrieval. Such methods, however, are limited to the acceptable context length of the PLM and are often computationally expensive.

Some works design task-specific queries to retrieve structured knowledge by fine-tuning. For example, Large language models such as LaMDA \citep{thoppilan2022lamda} have adopted such techniques. During fine-tuning, it learns to consult external knowledge sources before responding to the user, including an information retrieval system that can retrieve knowledge triplets and web URLs. \citet{li2022opera} propose a unified dialog model that learns to query pre-defined databases with belief states, which is a list of triplets.

Graph embeddings are used in works such as \citet{pramanik2021uniqorn}, where a context graph is built on-the-fly to retrieve question-relevant evidence from RDF datasets, including knowledge graphs, using fine-tuned BERT models. Similarly, Heterformer \citep{jin2022heterformer} retrieves relevant nodes from text-rich networks, such as academic graphs, product graphs, and social media. By combining GNNs and PLMs, it handles tasks such as link prediction and query-based retrieval.

Some works treat the generative model (often large language models) as black-box and retrieve structured information without fine-tuning. For example, BINDER \citep{cheng2022binding} uses in-context learning to output designed API calls that retrieve question-relevant columns from tables. \citet{he2022rethinking} retrieve from  knowledge graphs, such as Wikidata and Conceptnet, based on reasoning steps obtained from the chain-of-thought (CoT) prompting \citep{wei2022chain}.

By retrieving from relevant sources, the model not only improves its factual grounding but also provides the grounding contexts while generating, thus addressing interpretability and robustness concerns. 

With the potential to handle all types of information expanded by recent advances in LLMs \citep{gpt4}, we believe that there is much work to be done in this modality, which offers efficient solutions to factuality concerns. There are still many future challenges to be addressed. For example, there should be new designs for better retrieval systems that could promote efficient interactions suitable for diverse knowledge bases. Synthesizing this information correctly into the models is also an open challenge, where it is hard to decide which parts need augmenting in the textual outputs.