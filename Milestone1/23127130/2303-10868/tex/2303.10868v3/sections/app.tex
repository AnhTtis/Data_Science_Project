
\subsection{Search Criteria and Results}
\label{subsec:search}


For searching the ACL anthology articles, we use a keyword search over titles and abstracts. We strictly enforce the keyword ``retriev''. Then, we enforce either ``generat'' or ``ground'' to appear. For each modality, we then add modality-specific keywords: ``image'' for the image modality, ``code'' for the code modality, any one from ``structured knowledge/table/database/knowledge graph'' for the structured knowledge modality, any one from ``audio/speech'' for the audio modality, and ``video'' for the video modality.

For searching on Google Scholar, we add the keyword ``language models'' to select more NLP-related articles. We then perform manual filtering on the top 3 pages of returned results.

\input{sections/paper_stat_table}
\begin{figure}[t!]
    \centering
    \includegraphics[width=0.5\textwidth]{sections/stats.pdf}
  \caption{Paper trend analysis}
  \label{fig:trend_fig}
\end{figure}
The number of retrieved and analyzed research papers can be found in \Cref{tab:paper_stats}.

A trend analysis of how the number of papers change across time is shown in \Cref{fig:trend_fig} We could observe that the domain of multimodal retrieval-augmented generation has indeed developed a lot recently, with peaks reached around end of 2022. The observation is consistent with our hypothesis that multimodal RAG is especially important and helpful in the age of large-scale general-purpose models.